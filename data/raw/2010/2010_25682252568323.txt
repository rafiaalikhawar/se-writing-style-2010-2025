Automated Goal Operationalisation Based on Interpolation
and SAT Solving
Renzo DegiovanniDalal AlrajehyNazareno AguirreSebastian Uchitelyz
Departamento de Computaci√≥n, Universidad Nacional de R√≠o Cuarto and CONICET, Argentina
yDepartment of Computing, Imperial College London, UK
zDepartamento de Computaci√≥n, Universidad de Buenos Aires and CONICET, Argentina
{rdegiovanni, naguirre}@dc.exa.unrc.edu.ar, {dalal.alrajeh04, s.uchitel}@imperial.ac.uk
ABSTRACT
Goal oriented methods have been successfully employed for
eliciting and elaborating software requirements. When goals
are assigned to an agent, they have to be operationalised :
the agent's operations have to be rened, by equipping them
with appropriate enabling and triggering conditions, so that
the goals are fullled. Goal operationalisation generally de-
mands a signicant eort of the engineer. Although there
exist approaches that tackle this problem, they are either in-
formal or at most semi automated, requiring the engineer to
assist in the process. In this paper, we present an approach
for goal operationalisation that automatically computes re-
quired preconditions and required triggering conditions for
operations, so that the resulting operations establish the
goals. The process is iterative, is able to deal with safety
goals and particular kinds of liveness goals, and is based on
the use of interpolation and SAT solving.
Categories and Subject Descriptors
D2.1 [ Software Engineering ]: Requirements/Specications
General Terms
Design, Verication
Keywords
Requirements Engineering, Craig Interpolation, SAT solving
1. INTRODUCTION
Goal oriented methods (e.g., KAOS [14] and I[30]) have
been developed and successfully applied to the problem of
eliciting and elaborating software requirements. Such meth-
ods typically demand the renement of high level goals that
This work was partially supported by ANPCyT PICT
2010-1690, 2011-1774, 2012-0724 and 2012-1298; UBACYT
W0813; ERC StG PBM FIMBSE; and by the MEALS
project (EU FP7 MEALS - 295261).
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ICSE ‚Äô14, May 31 - June 7, 2014, Hyderabad, India
Copyright 14 ACM 978-1-4503-2756-5/14/06 ...$15.00.require agent cooperation to be achieved, into goals that can
be realised by individual agents [15]. A goal assigned to an
agent must be operationalised , i.e. mapped into operations
provided and executed by agents [17].
The problem of goal operationalisation has been studied
by various researchers. In the work of Letier and van Lam-
sweerde [17], a pattern based technique for deriving oper-
ational requirements from system goals is proposed. This
technique provides some templates to derive, from goals ex-
pressed in linear-time temporal logic (LTL) with certain syn-
tactic restrictions, a set of required pre/triggering conditions
for operations, such that these entail the goals. More re-
cently, Alrajeh et al. proposed an approach for semi-automa-
tically learning operational requirements from a set of goals
[2]. This approach uses model checking for verifying that a
given set of operational requirements satises the goals. If
verication fails, the user examines the counterexample gen-
erated by the model checker, identies a wrongly executed
operation, and provides positive scenarios illustrating\good"
occurrences of this operation. These scenarios are then used
by an inductive learning engine to automatically compute
new required pre/triggering conditions for the selected op-
eration. The obtained operational requirements ensure that
the counterexample is avoided and the behaviour described
by the positive scenarios is preserved. The approach of Al-
rajeh et al. is semi-automated since it requires engineers'
intervention for providing positive scenarios.
In this work, we present an approach for goal operationali-
sation, that automatically computes required pre/triggering
conditions for operations, in order to full a set of goals.
Moreover, this approach does not depend on user provided
scenarios and their characteristics, e.g., \richness" and cor-
rectness, as is the case with [2]. The renement process
is based on the use of interpolation and SAT solving. As
previous approaches [17, 2], our technique applies to safety
and time progress goals. Moreover, we are also able to deal
with a wide range of liveness goals, namely, those captured
by the reactivity pattern [23]. Our approach starts with
a model checking phase, for verifying whether the opera-
tional requirements specication satises the goals or not.
If the verication is successful, then the operational speci-
cation needs no renement. If the model checker produces
a counterexample, an interpolant from the counterexample
and the violated goal is computed, which is exploited to
strengthen or weaken required preconditions and required
triggering conditions, respectively, to remove the counterex-
ample. The approach performs various logical checks for
ensuring that the rened required conditions are consistentPermission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ICSE‚Äô14 , May 31 ‚Äì June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05...$15.00
http://dx.doi.org/10.1145/2568225.2568323
129
(in the sense of [17]) with the current operational specica-
tion. These checks are performed using SAT solving.
An interpolant for formulas AandBwhose conjunction
is inconsistent, is a formula that is implied by the rst, is in-
consistent with the second, and is expressed in the language
common to AandB. Interpolation has been widely used
in abstraction based verication [28], most notably for au-
tomatically rening abstract models of systems using corre-
sponding concrete models and abstract spurious counterex-
amples (violations of analysed properties). In this work, we
propose to use interpolation for a dierent, but related, pur-
pose. Essentially, an interpolant for a formula capturing a
trace and a violated goal is a property of the trace expressed
in the language that the trace and the goal have in common.
This interpolant can be seen as an explanation of why the
trace violates the goal. As we will show, interpolants can
be used to rene required conditions, in the process of goal
operationalisation.
The remainder of this article is organised as follows: Sec-
tion 2 introduces preliminary concepts necessary in the pa-
per. Section 3 presents a running example, used to present
our approach. Section 4 describes our approach in detail, for
the operationalisation of safety and time progress goals. Sec-
tion 5 extends the technique to deal with liveness goals. Sec-
tion 6 evaluates the approach, and compares with a closely
related one, on some case studies. Finally, we discuss related
work in Section 7, and present our conclusions in Section 8.
2. BACKGROUND
2.1 Labelled Transition Systems, FLTL and
Model Checking
Labelled Transition Systems (LTS) are typically used to
model the behaviour of interacting components [22]. For-
mally, an LTS Pis a quadruplehQ;A;;q 0i, whereQis a
nite set of states, Ais the alphabet ofP,QA[fgQ
is a transition relation, and q02Qis the initial state. The
semantics of an LTS Pcan be dened in terms of its exe-
cutions , i.e., the set of event sequences that Pcan perform,
starting in the initial state and following P's transitions.
Fluent Linear-time Temporal Logic (FLTL) [12] is a vari-
ant of LTL [23, 24], well suited for describing properties of
event-based discrete systems (e.g., LTSs) [22]. FLTL ex-
tends LTL by incorporating the possibility of describing ab-
stract states called uents , characterised by events of the
system. Formally, Fl=hIFl;TFl;Bidenes a uent Fl,
whereIFl;TFlAandIFl\TFl=;, andB2ftrue;falseg
indicates the initial value of Fl. When any event in IFloc-
curs, the uent starts to be true, and it becomes false again
when any event in TFloccurs. If the term Bis omitted then
Flis initially false.
A FLTL formula is an LTL formula where propositions are
uents. Given a set  of uents, a well-formed FLTL for-
mula is dened inductively using the standard boolean op-
erators and the temporal operators (next) andU(strong
until), in the following way: (i)everyfl2 is a formula,
and (ii)ifand are formulas, then so are :,_ ,
^ ,,U . We consider the usual denition for the
operators 2(always), 3(eventually) andW(weak until) in
terms of next and strong until, and boolean connectives.
Model checking [6] provides an automated method for de-
termining whether or not a property described by a (typi-
cally temporal) formula holds in the system's state graph.In our case, we will use Labelled Transition System Analyser
(LTSA), a verication tool for concurrent systems models.
A system in LTSA is modelled as a set of interacting nite
state machines (described by FSP processes [22]). LTSA
directly supports FLTL verication by model checking.
2.2 Interpolation
Given two formulas AandB, such that A^Bis incon-
sistent, an interpolant forAandBis a formula Iwith the
following properties: (i)AimpliesI,(ii)I^Bis unsatis-
able, and (iii)Iis inL(A)\L(B), i.e., the language that
AandBhave in common. For instance, consider Ap^q
andB:q^r. Then, an interpolant for AandBisIq.
In this work, we use the MathSAT [4] constraint solver.
This tool is behind various tasks, such as nding operations
that lead to certain states, querying about operation en-
abledness, etc. Most notably, MathSAT is able to compute
interpolants, which is a crucial mechanism underlying our
approach. Although MathSAT is an SMT solver, we do not
make use for any of our case studies of the theories Math-
SAT is equipped with. That is, we are using the tool only as
a SAT solver (with interpolation computation capabilities).
3. OPERATIONAL REQUIREMENTS FOR
GOAL MODELS
Goals are properties that the system should achieve. A
goal model is a decomposition of goals through AND/OR
renement links, which essentially capture how a goal can
be achieved in terms of simpler ones. Goal renement (the
decomposition of goals in subgoals) ends when each subgoal
at the bottom of the decomposition can be assigned to a sin-
gle agent. Agents perform operations, whose combined be-
haviours must full the goals. Operations characterise state
transitions in the system. Each operation is specied by its
signature (input and output variables), the domain pre- and
post-conditions ( DomPre and DomPost , respectively), and
therequired conditions. There are three dierent types of
required conditions. A required precondition ( ReqPre ) cap-
tures permission : under this condition the operation may be
executed. A triggering condition ( ReqTrig ) captures obliga-
tion: under this condition the operation must be executed.
Finally, the required postcondition ( ReqPost ) captures addi-
tional eects of executing the operation. A goal is correctly
operationalised by a set of operations ( operation model ), if
satisfying all required conditions in the set guarantees the
satisfaction of the goal [17].
It is possible to systematically obtain a behavioural model
from an operation model [20]. Requirements can be ex-
pressed using FLTL, by combining the \always" and \next"
operators, to capture required conditions, and introducing
further FLTL constraints to cope with the synchronous se-
mantics of KAOS. Then, an LTS that represents the sys-
tem behaviour can be automatically constructed. Using this
characterisation of the operation model, a model checker
(e.g., LTSA) can be employed to check if the system satis-
es the goals, if these are expressed as FLTL assertions.
Let us briey describe an operation model for a Mine
Pump Controller , introduced in [13]. We use this model
as a running example throughout the paper, and in particu-
lar in this section as a motivating example. The Mine Pump
system controls an alarm and a water pump in a mine, de-
pending on dierent levels of methane in the environment,130and water in the mine. The system monitors three environ-
mental variables: Methane (indicating whether methane is
present in the environment), and LowWater and HighWater
(indicating the level of water in the mine is low or high, re-
spectively), and two software variables that are controlled
by the system: PumpOn and Alarm , indicating whether the
water pump and the alarm are on or not, respectively.
The above mentioned monitored variables are modied by
environment events: belowLow ,aboveLow ,aboveHigh and
belowHigh modify the water level in the mine, while signal-
Methane andsignalNoMethane change accordingly the pres-
ence of methane in the environment. The system may ac-
tively control the state of the pump and the alarm with
the events switchPumpOn ,switchPumpOff ,raiseAlarm and
stopAlarm . Initially, the operations are enabled as long as
the domain precondition is true (i.e., the required precondi-
tion is true), and are not obliged to be executed in any state
(i.e., the required triggering condition is false).
Operation switchPumpOn Operation switchPumpOff
DomPre:PumpOn DomPre PumpOn
DomPost PumpOn DomPost:PumpOn
Operation switchAlarmOn Operation switchAlarmOff
DomPre:Alarm DomPre Alarm
DomPost Alarm DomPost:Alarm
Consider a goal PumpOffWhenMethane stating that \when
methane is present in the environment, the pump must be
switched o" . In order to check whether our operation model
guarantees that this goal is achieved, the approach presented
in [20] may be followed. The specication is mapped into
an event-based transition system, and a model checker is
used to check that the goals are satised. We express goals
as FLTL formulas, since we will use LTSA [22]. The above
goal is expressed in FLTL as follows:
2(tick!(Methane! (:tickW(tick^: PumpOn))))
The tick event is a means for capturing KAOS' synchronous
interpretation of an operation model under an asynchronous
interpretation which is used in LTSA [20]. The above for-
mula states that, if Methane is true when tick occurs, then
before the next tick the pump must be switched o. Having
the operation model captured as an LTS and goals as FLTL
formulas, it is possible to verify whether the specication
meets the goals or not. In our case, the goals can be vio-
lated, and the LTSA model checker produces the following
counterexample:
Trace to property violation in PumpOffWhenMethane:
tick (s0)
signalMethane Methane
tick Methane (s1)
switchPumpOn Methane ^PumpOn
tick Methane ^PumpOn (s2)
By examining the above counterexample, one can realise
that state s2does not satisfy the goal PumpOffWhenMethane .
The problem has to do with the operation switchPumpOn be-
ing able to occur when there is methane in the environment
(notice that the required precondition allows for this).
3.1 Using Interpolation for ReÔ¨Ånement
The above counterexample can be expressed as a formula
A, where system states are represented by variables (one per
uent in the specication), and these variables are replicated
3 times, for the 3 dierent states of the trace (i.e. s0,s1ands2), relating each one with the next according to what the
corresponding event indicates. Suppose that the goal can be
expressed as a state property B(e.g., this is straightforward
if the property is a safety property), referring to the last
state of the trace. Since the trace is a violation of B, clearly
A^Bis unsatisable. We can then try and use interpolation,
to see what the interpolant provides. In this case, the in-
terpolant is: Methane^PumpOn . This interpolant indicates
that the problem is that in the last state there is methane
in the environment and the pump is on, which causes a vi-
olation in the goal. Let us start going back from the state
previous to the last tick, trying to nd the rst place where
the violation might be avoided. We can compute the weak-
est precondition (WP) of the interpolant with respect to the
last action, i.e., switchPumpOn , obtaining:
WP( switchPumpOn ,Methane^PumpOn ) =Methane .
Notice that this last operation has the ability to change
the truth value of the interpolant. Thus, by preventing its
execution, we can get rid of the previous counterexample.
We have to check, however, whether this action is obliged
or not to be taken, when Methane is present. This can be
checked using some decision procedure (e.g., SAT solving),
to decide the formula Methane)ReqTrig (switchPumpOn ).
If it is the case, then the action cannot be prevented, and
we have to continue searching backwards in the counterex-
ample, for another way of removing the counterexample. If
it is not the case, we can get rid of the counterexample by
adding:Methane toswitchPumpOn 's required precondition.
4. REFINING OPERATIONAL
REQUIREMENTS
Let us describe our approach for rening operational re-
quirements in more detail. For the sake of simplicity, we
assume that goals are safety properties . Later on we extend
the approach to deal with Time Progress (TP) and reactiv-
ity properties [23]. Given a set G=fG1;:::;G ngof goals,
and an operational requirements specication Spec that may
not satisfyG, we propose an iterative approach that renes
Spec by constructing new required pre/triggering conditions
for operations, such that the resulting rened specication
satisesG. This approach can only rene Spec by weaken-
ing and strengthening required preconditions and required
triggering conditions of Spec's operations, respectively.
The approach consists of two phases, that are depicted in
Fig. 1. The Model Checking phase is concerned with verify-
ing whether Spec satises the goals Gor not. If the verica-
tion is successful, then the requirements specication needs
no further renement. If, on the other hand, the goals are
not satised by Spec, then the model checker detects a vio-
lation to at least one of the goals Gi, and produces a coun-
terexample as a witness of the violation. The Renement
phase automatically renes the operational requirements so
as to prevent the detected violation from occurring. To
achieve this, the approach uses interpolation and starts com-
puting an interpolant from the counterexample trace and the
violated goal Gi. This interpolant is exploited, using weak-
est precondition computations, to identify operations whose
guarding conditions may be altered to get rid of the obtained
counterexample. More precisely, the obtained interpolant,
with the aid of weakest precondition, produces the formulas
to be used to strengthen or weaken required pre/triggering
conditions, respectively, to remove counterexamples.131RenementModel
Checking +G
SpecSpec
j=
GreturnSpec
InterpolationRequirements
DerivationSpec
Gi(yes)
(no)
counterexample
IR
(fail)
no
renement
found
Figure 1: Overview of the iterative approach.
The rened specication, that incorporates new \more
precise" required conditions for some operations, removes
from its behaviours the violation found before. The process
is repeated until no violation is detected, obtaining a valid
operationalisation for G, or until we reach a point in which
a violation cannot be eliminated, meaning that the found
violation cannot be removed by rening required conditions
of the current operational requirements specication.
4.1 Model Checking Phase
The LTSA model checker has been used for analysing op-
erational requirements specications against goal models ex-
pressed in FLTL [20]. The state description of the system
is given with uent denitions (cf. Section 2). We follow
the approach presented in [20] for capturing KAOS opera-
tion models in LTSA, which makes use of a tick event to
explicitly represent the start and end of time intervals in
asynchronous FLTL. As an example, consider the following
goal for a model in which ticks are incorporated:
assert PumpOnWhenHighWaterANDNoMethane =
2(tick!((HighWater^:Methane)! (:tickW(tick^PumpOn))))
This formula expresses that, if at some time-point the level of
water is high and there is no methane, then the pump must
be switched on at the next time-point. We can use LTSA
for checking if the given Mine Pump specication satises
the goals. Initially we consider the weakest required precon-
dition (true) and the strongest required triggering condition
(false) for every operation. LTSA returns the following coun-
terexample for the goal PumpOnWhenHighWaterANDNoMethane :
Trace to property violation
in PumpOnWhenHighWaterANDNoMethane:
tick (s0)
aboveLow
tick (s1)
aboveHigh
tick HighWater (s2)
tick HighWater (s3)
Because of the way the property is expressed (in relation to
the tick event), the important states are those immediately
following tick events. This counterexample corresponds to
a case in which (s2) starts with the water pressure being
high, no methane in the environment and the pump o, and
by the next time-point the situation has not changed and
the pump remains o.
4.2 ReÔ¨Ånement Phase
The counterexamples generated by the model checker are
used to automatically and iteratively compute renementsduring the goal operationalisation process, which are guar-
anteed to remove the detected counterexamples.
Suppose we obtain a counterexample trace T, violating a
particular goal Gi. If we build a formula FTcapturing trace
T, and a formula FGicapturing the fact that Giholds at the
last state, clearly FT^FGiis unsatisable. We can then pro-
duce an interpolant from these formulas, i.e., a statement I,
in the intersection of the languages of the trace and the goal,
such thatFT)IandI^FGiis unsatisable. Intuitively,
the interpolant Irepresents a weaker\counterexample"than
T, a condition reachable from the initial state, which leads
to the violation of the goal. So, as long as we do not get rid
of the property I, we will not be able to stop violating the
goalGi. However, solely by removing I, we do not guar-
antee the satisfaction of Gi, but not removing it guarantees
its violation. Notice that calculating the interpolant Iis, in
some sense, a form of generalisation.
A counterexample may be removed either by prohibit-
ing the occurrence of an operation from certain states (i.e.,
strengthening the operation's required precondition) or by
forcing an operation to occur in certain states (i.e., weak-
ening its required triggering condition). The approach is
concerned with automatically detecting which of the above
cases is necessary, and using the interpolant to produce a
change in the corresponding condition. In the process of
rening required conditions of an operation model using in-
terpolants, weakest preconditions play an important role.
4.2.1 Strengthening Required Preconditions
By processing the counterexample trace backwards from
the last tick, we can compute the weakest precondition (WP)
of the interpolant with respect to the last operation, trying
to nd the rst place where the violation might be avoided.
LetIbe the interpolant and T=a1;a2;:::;akthe coun-
terexample trace. We can have two situations with respect
toWP(ak;I) =I0, the weakest precondition of the last oper-
ation and the interpolant. If :(I0)I), then the interpolant
does not hold before executing ak. Therefore, by forbidding
akto occur when I0holds, by adding :I0to the required
precondition of ak, we get rid of this counterexample. This
can be done as long as it does not contradict ak's required
triggering conditions, (i.e., if the operation is not obliged to
be executed when I0holds). IfI0)I, then by preventing
akfrom occurring we do not stop violating the goal, since I
still holds. In this case, as well as when adding :I0to the re-
quired precondition would contradict other conditions of ak,
we have to continue searching backwards in the trace, to try
to nd an operation whose occurrence causes the satisfac-
tion of the interpolant, and which can be\removed"from the
trace. The above modication to the required precondition
ofakdoes not guarantee that Gicannot be violated, it only
prevents its violation through akwhenI0holds. As an ex-
ample of required precondition strengthening, Consider the
following counterexample, violating PumpOffWhenLowWater :
Trace to property violation in PumpOffWhenLowWater:
tick LowWater (s0)
switchPumpOn LowWater ^PumpOn
tick LowWater ^PumpOn (s1)
In this case switchPumpOn is the only non-tick operation
executed, whose current required precondition and required
triggering condition are true and false , respectively. The
interpolant in this case is: LowWater^PumpOn . Going back-
wards from the last tick, we compute the weakest precon-132dition of this interpolant with respect to the last non-tick
operation, switchPumpOn , obtaining LowWater . Notice that
:(LowWater)LowWater^PumpOn ). Then, it is possible to
falsify the interpolant by preventing switchPumpOn from oc-
curring when LowWater . This is achieved simply by adding
:LowWater to the required precondition of switchPumpOn ,
as long as this does not contradict the operation's required
triggering condition. We then modify the required precon-
dition of switchPumpOn , which now becomes :LowWater .
In the process just described, we have to perform various
logical checks, namely checking whether a weakest precondi-
tion implies or not an interpolant and if a new conjunct of a
required precondition does not contradict a required trigger-
ing condition. We perform these checks using SAT solving.
In the particular case of checking whether a new identied
conjunct for a required precondition contradicts or not a
required triggering condition, we consider the formula:
ReqTrig.condition ^DomPre.condition )ReqPre.condition (1)
which must always hold (it is a meta-rule of the KAOS lan-
guage [15]). Notice that an operation is able to execute only
when its domain precondition holds. Then, if by modifying
a required precondition adding a new conjunct we violate
this property, we conclude that the conjunct is contradic-
tory with the current required triggering condition or the
domain precondition.
4.2.2 Weakening Required Triggering Conditions
In the above described situations, a counterexample is re-
moved by preventing an operation that appears in the trace
from occurring. In other situations, the solution to remove
the counterexample cannot be given in terms of preventing
an operation from occurring, but instead in terms of forcing
an operation that did not occur, to occur when it has to, i.e.,
by weakening the operations required triggering condition.
LetT=a1;:::;ai;tick;aj;:::;anbe the counterexample
trace andIthe interpolant computed for this counterexam-
ple. Suppose that we cannot get rid of this counterexam-
ple by strengthening some operation in aj;:::;an. Then,
as each operation in faj;:::;a ngcannot be prevented from
occurring, we will try to remove the counterexample by forc-
ing an operation to occur. Notice that the operation to be
triggered, say at, must meet the following two conditions:
atshould be able to be executed when interpolant Iholds:
I)DomPre (at)^ReqPre (at): (2)
at's execution must falsify the interpolant I:
(I^DomPost (at))):I: (3)
We evaluate every controlled operationatnot occurring in
aj;:::;an, checking whether it meets both of the above con-
ditions or not. If we nd such an operation at, we rene its
required triggering condition, as follows:
ReqTrig (at) =ReqTrigpre(at)_I;
where ReqTrigpre(at) isat's current required triggering con-
dition. Notice that adding the disjunct Itoat's required
triggering condition does not violate the KAOS meta-rule (1),
sinceatsatises condition (2).
If no operation satises conditions (2) and (3), we proceed to
look deeper in the counterexample trace T, going backwards
fromai, and using I0=WP(aj;:::;an;I) instead of I.Consider, for instance, the counterexample to the goal
PumpOnWhenHighWaterANDNoMethane , shown in Section 4.1.
This time,:Methane^HighWater^:PumpOn is the inter-
polant computed. Notice that in this case, no operation is
executed between the last two tick events. We have then
to check if there exists an operation that satises condi-
tions (2) and (3). Operation switchPumpOn is executable
when:Methane^HighWater^:PumpOn , and it falsies this
interpolant. Indeed, notice that, considering that :LowWater
andfalse areswitchPumpOn 's current required precondition
and required triggering condition, respectively, the following
formulas, corresponding to conditions (2) and (3), hold:
:Methane^HighWater^:PumpOn): PumpOn^:LowWater (4)
(:Methane^HighWater^:PumpOn )^
(PumpOn'^Methane'=Methane ^HighWater'=HighWater ) (5)
):(:Methane'^HighWater'^:PumpOn' )
Then, switchPumpOn 's required triggering condition is re-
ned as follows:
ReqTrig (switchPumpOn ) =:Methane^HighWater^:PumpOn
As for the case of strengthening required preconditions,
weakening required triggering conditions also involves logical
checks. We perform these logical checks using SAT solving.
4.3 Iterative ReÔ¨Ånement
The two phases described above correspond to a single
iteration of the renement approach. These phases are iter-
atively applied until no further violations are detected in the
model checking phase, i.e., until a specication that satises
the goals is reached, or until we reach a point from which, by
solely rening required preconditions and required triggering
conditions, the goals cannot be achieved.
LetOandGbe the initial operational specication and
a set of goals, respectively, consistent with respect to a set
of uentsD. Let us now discuss correctness, incompleteness
and termination of the approach.
Correctness and Incompleteness. When the approach n-
ishes, its outcome is Spec =O[Req, whereReq is the
set of required pre/triggering conditions obtained. Req is
guaranteed to be a consistent extension to Othat correctly
operationalises the goals in G. This is formalised as follows:
O[Req[G6j=DfalseO[Reqj=DG
Due to space restrictions, the proof of this claim is not re-
ported here. The justication has to do with each rene-
ment in the process being guaranteed to be sound, thanks
to the SAT checks we perform. For instance, in the case of
strengthening a required precondition, the validity of con-
dition (1) ensures that the new required precondition does
not contradict the current required triggering condition. In
addition, conditions (2) and (3), in the case of weakening a
required triggering condition, ensure that the KAOS meta-
rule (1) is not violated.
However, the proposed approach does not satisfy com-
pleteness. That is, if there exists a renement (modications
to the required conditions) that can satisfy the set of goals,
then the approach might fail in the process of nding that
renement. The main reason is related to the the fact that
goals can be competing, i.e., trying to full one goal may
prevent us from later on fullling another goal. Then, by133removing a counterexample the approach can remove edges
from the system's behaviour that later could be required to
be added to remove another counterexample (notice that we
cannot add edges, since postconditions are not modied, nor
new states are added, since the denition of variables, what
denes the state space, is not altered).
Termination. As we argued during the presentation of the
renement phase, a renement step removes the counterex-
ample from which the renement was constructed, in the
sense that the same execution cannot be obtained. How-
ever, there might be other traces violating the same goal.
Thus, termination is not straightforwardly guaranteed. Let
us argue about it, for the case of safety goals.
The model checking phase constructs a labelled transi-
tion system corresponding, essentially, to formula O^:G.
If this formula has satisfying traces, these are counterexam-
ples. First, notice that the labelled transition system O^:G
isnite : it has a nite number of states, and of course a nite
number of edges. We have to demonstrate that each rene-
ment of required conditions removes at least one transition,
since there exists the risks of adding redundant conjunct-
s/disjuncts, which would not remove any edge.
We have explained that, when a required precondition is
added, it is because an operation ahas been identied, which
is executable in a pre-state satisfying I0, leading to a post-
state in which a formula Iholds (the interpolant). Moreover,
this action aand condition I0come from a counterexample,
indicating that I0is a reachable condition, where acan be
executed. Then, when we add :I0to the required precondi-
tion ofawe remove this particular transition.
By weakening required triggering conditions, we also re-
move edges. When a required triggering condition is added,
it is because an operation ahas been identied, which is exe-
cutable in a state satisfying I, the interpolant, and whose ex-
ecution falsies the interpolant. Notice then that, by weak-
ening the triggering condition for a, we remove transitions
corresponding to tick. Indeed, while tick was executable in
the state satisfying I, it is no longer executable in that same
state due to the obligation of executing ainstead. Thus,
again the renement produces an edge removal.
Since the number of edges corresponding to O^:Gis
nite, and we alter this transition system only by deleting
edges, it is guaranteed that our renement process termi-
nates when it deals with safety goals.
5. DEALING WITH LIVENESS
5.1 Time Progress Property
In discrete-time systems, a common desired property is
the progress of time, usually specied as 23tick. This
property is called Time Progress (TP) and is a particular
kind of progress property. In this section, we show how the
approach can be extended to operationalise this particular
progress property.
In order to detect progress violations, we take into account
three assumptions: (i) KAOS' semantic preservation: all
initiating and terminating uent events can occur only once
between ticks; (ii) Maximum Progress (MP) assumption: a
common assumption in reactive systems that gives priority
to system events over all other events including ticks; and
(iii) Safety Guaranteed: we do not want to interfere in the
satisfaction of the safety goals to operationalise the times0 sl ske0 ek 1ek
Figure 2: Counterexample for reactivity properties.
progress property. So, the checking is performed over the
system that represents the composition of all domain/re-
quired conditions and the safety goals.
Time Progress violations are traces in which at some point
no tick event can be executed. Then, provided that we have
a nite number of events, and due to assumption (i), which
prohibits the repetition of events between ticks, these TP vi-
olations will be deadlocks. Basically, the main reason lead-
ing to these deadlocks is the way used for specifying the
properties, i.e., the goals should be satised in the states in
which tick occurs. Then, the non-progress of tick is due to
the fact that its execution will violate a goal, contradicting
the assumption (iii).
So, our approach to remove progress violations consists of
extending the obtained counterexample trace with a tick
event at the end, and proceeding to compute an interpolant
for the extended counterexample and the safety goals (that
will not hold in the last state due to tick is now being exe-
cuted). Intuitively, this interpolant explains the reasons why
tick does not progress, and gives us a reachable property of
the system that should be removed in order to contribute
with the the satisfaction of the safety goals and the time
progress property. To remove this counterexample, we fol-
low the technique just presented in Section 4.
5.2 Reactivity Properties
Liveness properties have been used for reactive systems
extensively, e.g., in the work of Manna and Pnueli [23].
In the context of goal oriented methods, liveness proper-
ties are typically restricted to bounded liveness . For in-
stance, Letier argues in [18] that responsiveness properties
for systems 2(trigger!3response ) (where response is con-
trolled by the software-to-be and trigger is monitored by
the system-to-be) should be bounded, since otherwise agents
may postpone their duties indenitely, without a nite ob-
servable violation. However, it is sometimes convenient for
these kinds of properties to abstract away the bound (be-
cause it is unknown , or because the bound, if large, may
make the system state space explode as the time units must
be explicitly counted in the model). When properties are
further away from the \machine/world" interface or encom-
pass many interactions between the world and the machine
(think of chained responsiveness patterns ), properties such
as (23As!23G) allow abstracting away from the bounded
behaviour that the system will have to achieve the goal.
It is then, in our opinion, worthwhile to deal with live-
ness in goal operationalisation. Our approach considers live-
ness properties that match the reactivity pattern ( 23As!
23G), where AsandGare non-temporal uent expressions.
This pattern is general enough to embrace many liveness
properties [23]. Moreover, it gives us information about the
shape of the counterexample, which gives us the opportunity
to use interpolation (see Fig. 2).
Liveness properties corresponding to the reactivity pat-
tern have two parts: the antecedent or assumptions (As),134and the consequent or goals (G). A violation of a property
of this kind consists of a prex (nite part) leading to a loop
in which the antecedent is satised, but not the consequent.
That is, at least one state sl:::skin the loop satises the
assumptions As, but no state satises the goal G. In order to
compute an interpolant for this counterexample, we encode
the reactivity goal in the following propositional formula:
P= (k_
i=lAsi))(k_
j=lGj)
where the expression Fimeans that Fholds insi. LetFT
be the formula that characterises the counterexample trace.
Clearly,FT^Pis unsatisable. Then, we can calculate an
interpolant Ifor these formulas. This interpolant is a weaker
representation of the loop part that explains what is wrong
in the loop. To remove this counterexample, we search for
an operation atthat can be executed at some point in the
loop, such that its execution reaches a states that does not
satisfy the interpolant (i.e., it \breaks" the loop):
si)DomPre (at)^ReqPre (at) (6)
(si^DomPost (at))):I (7)
If we nd such an operation that satises both (6) and (7),
then we rene at's triggering condition with the conjunction
of its required precondition and the negation of the goal:
ReqTrig (at) =ReqTrigpre(at)_(ReqPre (at)^:G)
Notice that we do not rene a new triggering condition based
on the interpolant. Worse, we may produce triggering con-
ditions that are weaker than needed. Still, we can guarantee
that the approach is correct and consistent with respect to
the operations's preconditions (including their previous re-
nements). So, the overall renement process would rst re-
move time-progress violations, second operationalise safety
goals, and nally deal with liveness goals.
6. DEMONSTRATING EXAMPLES
In this section, we report the experimental results of ap-
plying our approach to two models, namely the Mine Pump
Controller [13] and the Engineered Safety Feature Actuation
System (ESFAS) [19]. For the case of safety goals and the
time progress property, our approach is compared with the
framework based on Inductive Logic Programming (ILP) in-
troduced in [2], for evaluation and validation purposes. One
of the authors provided the positive scenarios needed for
ILP-based framework. These were produced manually fol-
lowing the guidelines provided in [1]. This human interven-
tion, however, was not required in our proposed approach
since it is fully automated. On the other hand, previous ap-
proaches to goal operationalisation do not deal with liveness
goals, so we do not have previous results to compare with, to
validate the technique. We argue about this problem later
on in this section.
Each model is accompanied by an informal description of
the system-to-be, a partial operational requirements speci-
cation, and a set of goals specied in FLTL. The experiments
can be reproduced by downloading:
http://dc.exa.unrc.edu.ar/staff/rdegiovanni/icse2014.zip
and following the instructions therein.6.1 Mine Pump Controller
This rst model was used as the running example in this
article (refer to Section 3 for details). In addition to the
already specied goals (Sections 3 and 4), we consider ad-
ditional objectives that should be achieved by the system:
assert PumpOffWhenLowWater =
2(tick!(LowWater! (:tickW(tick^:PumpOn))))
assert AlarmWhenMethane =
2(tick!(Methane! (:tickW(tick^Alarm))))
We have already discussed earlier in the article, in the
form of examples, various renements performed to the mine
pump's operational model. Let us see now how we remove
time progress violations. By performing a TP progress check
on the Mine Pump system, considering the needed assump-
tions, LTSA produces the following counterexample.
TP violation. Trace to DEADLOCK:
tick
switchPumpOn
raiseAlarm
aboveLow
signalMethane
Extending the counterexample with a tick event at the end,
the interpolant computed is: PumpOn^LowWater . It exhibits
a similar violation to the goal PumpOffWhenLowWater shown
in subsection 4.2, where we get rid of this counterexample
prohibiting the execution of switchPumpOn when LowWater
(renement (T1)). We follow the approach put forward
in [1], which proposes removing rst time progress violations
and then safety violations.
We now present a summary of the iterations performed
by our renement process, in which each iteration indicates
the required condition identied to be added to the oper-
ational specication. Required preconditions (T1)-(T4) re-
move time progress violations, and the required triggering
conditions (T5)-(T8) guarantee the satisfaction of the safety
goals.
ReqPre (switchPumpOn ) =:LowWater (T1)
ReqPre (stopAlarm ) =:Methane (T2)
ReqPre (switchPumpOn ) =:Methane (T3)
ReqPre (switchPumpOff ) =:(:Methane^HighWater ) (T4)
ReqTrig (raiseAlarm ) =:Alarm^Methane (T5)
ReqTrig (switchPumpOn ) =:PumpOn^:Methane^HighWater (T6)
ReqTrig (switchPumpOff ) =PumpOn^LowWater (T7)
ReqTrig (switchPumpOff ) =PumpOn^Methane (T8)
When compared with the requirements learned by the ap-
proach presented in [2], for this same model, we observe that
both approaches iterate exactly the same number of times.
Both approaches produce the same required conditions, ex-
cept for the required triggering condition produced in the
sixth iteration. The ILP-based framework learns a weaker
triggering condition for switchPumpOn , namely HighWater .
Due to this overgeneralisation problem of ILP, the learned
condition leads to the following deadlock in the system:
Trace to DEADLOCK:
tick (s0)
aboveLow
tick (s1)
aboveHigh
signalMethane
tick (s2)
belowHigh
signalNoMethane135The deadlock is produced because in the state (s2), both
HighWater andMethane are true. Then, the required precon-
dition from (T3) indicates that switchPumpOn cannot occur
when Methane , but the learned triggering condition obliges
switchPumpOn to occur when HighWater . In our case, the
required triggering condition rened in (T6) is stronger, re-
quiring methane to be false when the water level is above
high. On the other hand, to remove the deadlock, the ILP-
based framework is forced to backtrack to previous itera-
tions and requires the engineer to provide further scenarios
or manually produce the renement.
With respect to running times, it is worth mentioning
that, for this model, our approach is signicantly more ef-
cient. While the ILP-based framework requires aprox. 29
seconds per iteration, our approach takes less than 1 sec.
per iteration.
6.2 ESFAS
The Engineered Safety Feature Actuation System (ES-
FAS) was originally introduced by Courtois and Parnas in
[5]. Later on, Letier reported a KAOS specication of this
system in [19]. The ESFAS system of a nuclear power plant
prevents or mitigates damage to the core and coolant sys-
tem of the plant, on the occurrence of a fault such as a loss
of coolant. ESFAS monitors the water pressure, and a cou-
ple of switches for blocking and resetting, and it controls a
single boolean variable, indicating whether the safety injec-
tion system is on or o, with the events sendSignal and
stopSignal . Basically, the system must start safety injec-
tion when the pressure becomes too low. In addition, the
system can be \disengaged" via the switches, indicating that
its actions are overridden ( overrideSignal ,enableSignal ).
The goals that ESFAS has to satisfy are formalised in FLTL
as follows:
assert SafetyInjectionWhenLowWaterPressureAndNotOverridden =
2(tick!( (PressureBelowLow ^: Overridden)
! (:tickW(tick^SafetyInjection))))
assert SIEnabledWhenPressureAbovePermitOrManualReset =
2(tick!( (Occurs_reset_PressureAbovePermit)
! (:tickW(tick^: Overridden))))
assert SIOverriddenWhenBlockSwOnAndPressureLessThanPermit =
2(tick!( (Occurs_block^: PressureAbovePermit)
! (:tickW(tick^Overridden))))
Intuitively, the rst goal indicates that the safety injec-
tion signal should be on when the water pressure is below
`Low' and the safety injection is not overridden (this is the
main objective of the ESFAS). The second goal expresses
that the safety injection should become enabled when the
water pressure raises above `Permit' or when the reset but-
ton is pushed. And the third goal establishes that the safety
injection should become overridden when the block switch
is set on and the water pressure is lower than `Permit'. The
following uent denitions are considered for the ESFAS sys-
tem:
fluent Overridden = < overrideSignal, enableSignal, True>
fluent SafetyInjection = < sendSignal,stopSignal >
fluent PressureBelowLow =
< lowerPressureBelowLow, raisePressureAboveLow, True>
fluent PressureAbovePermit =
<raisePressureAbovePermit, lowerPressureBelowPermit>
fluent Occurs_block = < block,tock >
fluent Occurs_reset = < reset,tock >
Event tock is executed immediately after tick. This aux-
iliary event is introduced as a terminating action for the op-
erators' press-button actions (the actions corresponding tothe system operator pressing the reset and block buttons).
We assume true andfalse to be the initial required precon-
ditions and the required triggering conditions for the opera-
tions, respectively. In addition, we consider the next domain
preconditions for the controlled operations and two environ-
mental assumptions to indicate that the operator cannot
press the reset and block buttons at the same time:
DomPre (overrideSignal ) =:Overridden
DomPre (enableSignal ) =Overridden
DomPre (sendSignal ) =:SafetyInjection
DomPre (stopSignal ) =SafetyInjection
Assumption 1=2(tick^Occurs_block!: Occurs_reset )
Assumption 2=2(tick^Occurs_reset!: Occurs_block )
The process checks the validity of the TP property, and re-
nes 4 conditions to remove the violations.
ReqPre (stopSignal ) =:(:Overridden^PressureBelowLow )(R1)
ReqPre1(overrideSignal ) =:Occurs_reset (R2)
ReqPre2(overrideSignal ) =:PressureAbovePermit (R3)
ReqPre (enableSignal ) = (R4)
:(:PressureAbovePermit ^Occurs_block )
Now, the approach starts the renement process of Section 4
in order to full the safety goals. The rst counterexample
that LTSA reports is:
Trace to property violation in
SafetyInjectionWhenLowWaterPressureAndNotOverridden:
tick PressureBelowLow (s0)
tock PressureBelowLow
tick PressureBelowLow (s1)
This counterexample corresponds to a case in which the
water pressure is below low and the system is not over-
ridden, and in the next time-unit the safety injection sig-
nal is o. The process continues by computing an inter-
polant for the counterexample and the violated goal, obtain-
ing:SafetyInjection ^:Overridden^PressureBelowLow .
The weakest precondition of this interpolant with respect to
the last non-tick operation (i.e., tock), leads us to the same
formula (the interpolant). So, by preventing tock from oc-
curring we do not stop violating the goal. Thus, our ap-
proach attempts to remove the counterexample by forcing
the occurrence of an operation such that the operation's ex-
ecution avoids the interpolant. Operation sendSignal meets
the two conditions for required triggering condition rene-
ment, namely:
I): SafetyInjection ^true (A)
(I^SafetyInjection0^(Overridden0=Overridden )^ (B)
(PressureBelowLow0=PressureBelowLow ))):(I0)
whereIrepresents the above mentioned interpolant. Con-
dition (A) ensures that sendSignal can be executed when
:SafetyInjection ^:Overridden^PressureBelowLow , whi-
le condition (B) ensures that sendSignal 's execution avoids
the interpolant. Then, by forcing sendSignal to occur when
:SafetyInjection ^:Overridden^PressureBelowLow , the136counterexample is removed. The fth iteration nishes re-
ning sendSignal 's required triggering condition (R5):
ReqTrig (sendSignal ) = (R5)
:SafetyInjection^:Overridden^PressureBelowLow
ReqTrig1(enableSignal ) =Overridden^Occurs_reset (R6)
ReqTrig2(enableSignal ) =Overridden^PressureAbovePermit (R7)
ReqTrig (overrideSignal ) = (R8)
:Overridden^Occurs_block^:PressureAbovePermit
The rened required conditions of subsequent iterations
(R5)-(R8) of our process guarantee the satisfaction of the
safety goals. Notice that, for example in (R5), :Safety-
Injection is redundant in sendSignal 's required trigger-
ing condition, since :SafetyInjection is the domain pre-
condition of sendSignal . The approach guarantees that
overrideSignal 's required triggering condition (R8) does
not contradict overrideSignal 's required preconditions (R2)
and (R3), thanks to the rst environment assumption, which
expresses that Occurs_block): Occurs_reset . The sec-
ond assumption is used for justifying that enableSignal 's
required triggering conditions (R6) and (R7) do not contra-
dict enableSignal 's required precondition (R4).
The operational requirements specication obtained by
the above requirements achieves the ESFAS goals, so our
process successfully terminates.
When comparing our approach with the ILP-based frame-
work in [2], the rst dierence shows up in the fth iteration.
The ILP-based framework removes the same counterexam-
ple, but due to the problem of overgeneralisation of this
approach, it produces a weaker required triggering condi-
tion for sendSignal :PressureBelowLow (i.e., rather than
:Overridden^PressureBelowLow ). This condition forces
sendSignal to occur when the water pressure is below the
low threshold regardless of whether it is overridden or not.
In the sixth and seventh, both approaches produce the
same required conditions. In the eighth iteration however,
a second dierence is detected. The ILP-based framework
learns a weaker triggering condition for overrideSignal ,
namely Occurs_block . This learned required condition pro-
duces a deadlock in the system, for a reason similar to the
case of the Mine Pump. To remove the deadlock, the ILP-
based framework requires the engineer to backtrack to pre-
vious iterations and either manually rene the required con-
ditions or provide further positive and negative scenarios,
and rerun the operationalisation process.
Let us compare the running times of our approach with
those of the ILP-framework. Since both approaches use
LTSA, the critical part in time is interpolation plus SAT
vs. inductive learning. In the case of ILP, the time in-
creases from 6 seconds in the rst iteration to 18 seconds in
the eighth, because the set of examples gets bigger (the engi-
neer accumulates the positive scenarios from each iteration).
Our approach takes less than 1 second per iteration.
6.3 Analysing Reactivity Properties
Previous approaches to goal operationalisation do not deal
with liveness goals, so we do not have previous results or
case studies to compare with, to validate our technique. In
particular, Letier's patterns based approach classies these
goals as unrealisable [18]. So, the specications that we
use for evaluation (MinePump, ESFAS) do not have liveness
goals assigned to agents, to be operationalised.We then developed some liveness goals that, based on the
knowledge we have on the models, should be satised, al-
though these do not appear explicitly in the specications.
In addition, we do not use fairness assumptions, and we
have to assume certain liveness constraints on the environ-
ment (e.g. if the pump is on, eventually the water level
is not high), and to remove some safety goals that imply
our developed properties, so that liveness counterexamples
emerge.
For the Mine Pump Controller, the introduced property
is:\If innitely often there is no methane (so the pump can
be turned on), then innitely often the water level is not
high." We specify this property as:
2(PumpOn!3:HighWater)^(23:Methane!23:HighWater)
In order to obtain a counterexample for this goal, we remove
safety goals that lead to required conditions (T4) and (T6).
Then, a counterexample for the goal is obtained, which has
the following loop:
Violation of LTL property: @LivenessGoal
Trace to terminal set of states:
...
signalMethane HighWater ^Methane
Cycle in terminal set:
tick HighWater ^Methane (s3)
signalNoMethane HighWater
tick HighWater (s4)
signalMethane HighWater ^Methane
Notice that (s4) is the state in the loop that satises the
assumption:Methane , but neither (s3) nor(s4) satisfy the
goal:HighWater . Then, the interpolant computed for this
counterexample is the following:
(Methane3^HighWater3^: PumpOn3)
^(:Methane4^HighWater4^: PumpOn4)
This interpolant explains what is wrong in the loop. To re-
move this counterexample, we search for an operation that
can be executed at some point in the loop, such that its exe-
cution reaches a states that does not satisfy the interpolant.
switchPumpOn meets these two conditions. Then, the rene-
ment weakens the switchPumpOn 's required triggering con-
dition with the conjunction of its required precondition and
the negation of the goal, which correctly operationalises the
goal:
ReqTrig (switchPumpOn ) =:Methane^:LowWater^HighWater (L1)
For the ESFAS system, the developed property is: \If in-
nitely often the user does not override the system pressing
the block button, then innitely often the level of coolant
won't be low". The property to operationalise is:
2(SafetyInjection !: PressureBelowLow) ^
(23:Occurs_block!23:PressureBelowLow)
The counterexample found for this goal is:
Violation of LTL property: @LivenessGoal
Trace to terminal set of states:
...
tick PressureBelowLow
Cycle in terminal set:
tock PressureBelowLow
tick PressureBelowLow
Then, the renement process computes an interpolant and
weakens the required triggering condition for sendSignal
operation (in this case, weaker than (R5)), which correctly
operationalises the goal:
ReqTrig (sendSignal ) =::PressureBelowLow (L2)1377. DISCUSSION AND RELATED WORK
Goal-oriented requirements engineering (e.g., KAOS [14]
and I[30]) has been the focus of much research in the re-
quirements engineering community. An important aspect of
this approach to requirements engineering is the notion of
relating high-level goals achievable only through agent coop-
eration with lower level goals that can be assigned to specic
agents, some of which may be software to be built. Support
for rening goals has been studied extensively too (e.g. [3]).
Goal operationalisation aims to produce requirements on a
per-operation basis that will be provided by a specic agent
to guarantee it achieves a goal that has been assigned to it.
Approaches concerned with goal operationalisation are for
instance the NFR framework [25] and CREWS [29]. How-
ever, these either focus on non-functional requirements or
are informal and hence cannot be fully veried. More formal
approaches such as [10, 11] allow checking the correctness of
operationalisation rather than supporting the elaboration of
such operational requirements.
The use of generalisation techniques in the context of goal
models is not novel. For instance, [16] presents a method
for inferring declarative assertions from scenarios. It elicits
goals from tailored scenarios provided by stake-holders using
an inductive inference process based on Explanation-Based
Learning (EBL) [26]. Apart from not being used speci-
cally for operationalisation, the learning in [16] cannot con-
sider existing knowledge (e.g., existing goals or operational
requirements) during the inference process. Hence it is un-
sound and can produce inconsistent specications.
Interpolation has been used for software analysis purposes,
notably by McMillan [28], in combination with SAT-based
model checking, for circuit verication [27]. It has also been
employed for automated counterexample guided abstraction
renement [7]. Essentially, interpolation is used in the con-
text of the verication of abstract (imprecise) models. When
a counterexample is obtained, it must be checked whether
it is an actual counterexample or it arised due to the im-
precision of the model. If it is spurious, then when building
the conjunction of the model and the counterexample, one
arrives to an unsatisable formula. Interpolation explains
what is the dierence between the abstract and concrete
models of the system, that led to the spurious counterex-
ample. The interpolants obtained can be made part of the
abstract model to make it more concrete, and thus get rid of
the spurious counterexample. This process is iterated until
no further counterexamples are obtained or a real (non spuri-
ous) counterexample is produced. In this work, we proposed
using interpolation for a dierent, but related, purpose. Ba-
sically, from concrete counterexamples showing goal viola-
tions we produce unsatisable formulas so that interpolants
can be computed. These interpolants are used to rene the
concrete operation model. As opposed to abstraction rene-
ment, in our setting we do not have a model of reference to
be used for renement (the concrete model in the context
of abstraction renement); instead, we have an objective ,
namely to correctly and completely operationalise the goals.
The deviation from the objective is what guides our process
in the use of interpolation, for rening the operation model.
Other related approaches are the works on synthesis of
behaviour models (in form of LTS) from goals [8, 9, 21].
In contrast with our approach, which produces declarative
required pre/triggering conditions for controlled operations,these works based on synthesis produce operational rene-
ments for controlled operations.
There exist other approaches that deal with the problem
of goal operationalisation systematically. As mentioned in
Section 1, the approach introduced in this article is more
closely related to the framework presented in [2], which pro-
vides a semi-automated method that uses model checking for
analysing goal achievement and Inductive Logic Program-
ming (ILP) for learning operational requirements. There
are some important dierences between the two approaches.
[2] requires user intervention to provide positive scenarios
for the learning phase and hence its results are dependent
on the correctness and `richness' [1] of the scenarios given,
whereas this is not required by our presented approach. [2]
uses ILP which searches for the `most compressed' condi-
tions (i.e., fewest number of uent literals appearing in the
required conditions) and hence is prone to generating over-
generalised conditions. The approach introduced in this ar-
ticle, on the other hand, uses interpolation, which produces
more precise conditions, as the interpolant is necessarily im-
plied by the counterexample trace and it necessarily leads
to a violation of a goal. Exactly because of this, interpola-
tion based renement may require more iterations to reach
a valid operationalisation, compared to the ILP approach.
Finally, our approach is able to deal with a wide range of
liveness properties, which are not handled by previous ap-
proaches to goal operationalisation.
8. CONCLUSION AND FUTURE WORK
We presented an approach for goal operationalisation, that
automatically computes required pre/triggering conditions
for operations, in order to full a set of goals. Moreover,
this approach does not depend on user provided scenarios
and their characteristics, e.g., \richness" and correctness, as
is the case with [2]. This approach is based on interpolation
and SAT solving, and applies to safety goals and particu-
lar kinds of liveness goals, namely reactivity properties (a
general class that embraces many liveness properties). We
have evaluated our technique on some models taken from
the literature, and compared our approach with that of [2],
showing that in these cases our approach is able to produce
goal operatinalisations eectively and more eciently.
There are various lines for future work. We plan to carry
out case studies to validate our technique. This may, in par-
ticular, enable us to evaluate possible scalability issues with
our approach to goal operationalisation. In addition, we
plan to investigate what is the precise relationship between
operationalisations obtained by interpolation and those ob-
tained by inductive logic programming. In particular, we
are interested in analysing a possible notion of \most gen-
eral" operationalisation, and to assess whether interpolation
based renement enable us to reach such operationalisations.
We also plan to investigate a potential complementation be-
tween interpolation and inductive logic programming, for
goal operationalisation. Finally, since our approach heavily
relies on the calculation of interpolants, we plan to evalu-
ate alternative mechanisms for interpolant computation, to
analyse whether a particular interpolant computation ap-
proach better ts our purposes.1389. REFERENCES
[1] D. Alrajeh, J. Kramer, A. Russo and S. Uchitel,
Elaborating Requirements Using Model Checking and
Inductive Learning. IEEE Transactions on Software
Engineering 39(3): 361{383, 2013.
[2] D. Alrajeh, J. Kramer, A. Russo and S. Uchitel,
Learning Operational Requirements from Goal Models ,
in Proc. of ICSE 2009, IEEE, 2009.
[3] A. I. Anton, Goal Identication and Renement in the
Specication of Software-based Information Systems ,
PhD thesis, Georgia Institute of Technology, Atlanta,
GA, USA, 1997.
[4] R. Bruttomesso, A. Cimatti, A. Franz en, A. Griggio
and R. Sebastiani, The MathSAT 4 SMT Solver , in
Proc. of CAV 2008, LNCS 5123, Springer, 2008.
[5] P.J. Courtois and D. L. Parnas, Documentation for
safety critical software , in Proc. of 15th ICSE, pages
315-323, 1993.
[6] E. Clarke, Automatic verication of hardware and
software systems , ACM SIGSOFT Software
Engineering Notes 25(1): 41-42, 2000.
[7] E. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith.
Counterexample-guided abstraction renement for
symbolic Model Checking . J. ACM, 50(5):752{794,
2003.
[8] N. D'Ippolito, V. Braberman, N. Piterman, and
S. Uchitel, Synthesis of live behaviour models , in FSE
2010, ACM, 2010.
[9] N. D'Ippolito, V. Braberman, N. Piterman, and
S. Uchitel, Synthesis of live behaviour models for
fallible domains ,^ aA_I in ICSE 2011, ACM, 2011.
[10] A. Fuxman, J. Mylopoulos, M. Pistore, and
P. Traverso, Model checking early requirements
specications in TROPOS , in Proceedings of the 5th
IEEE International Symposium on Requirements
Engineering, pages 174^ a A S181, 2001.
[11] A. Fuxman, L. Liu, J. Mylopoulos, M. Pistore,
M. Roveri, and P. Traverso, Specifying and analyzing
early requirements in TROPOS , Requirements
Engineering, 9(2):132{150, 2004.
[12] D. Giannakopoulou and J. Magee, Fluent Model
Checking for Event-based Systems , in Proc. of
ESEC/FSE '03, ACM 1-58113-743-5/03/0009, 2003.
[13] J. Kramer, J. Magee and M. Sloman, Conic: An
integrated approach to distributed computer control
systems , in IEE Proc., Part E 130, 1{10, 1983.
[14] A. van Lamsweerde, A. Dardeene, D. Delcourt and F.
Dubisy, The KAOS Project: Knowledge Acquisition in
Automated Specication of Software , in Proc. of AAAI
Spring Symposium Series, Track: \Design of
Composite Systems", Stanford University, March 1991,
59{62.[15] A. van Lamsweerde, A. Dardeene and S. Fickas,
Goal-directed Requirements Acquisition , in Proc. of
Science in Computer Programming, Vol.20, 3{50,
1993.
[16] A. van Lamsweerde and L. Willemet, Inferring
declarative requirements specications from operational
scenarios , IEEE Transactions on Software
Engineering, 24(12):1089{1114, 1998.
[17] E. Letier and A. van Lamsweerde, Deriving
Operational Software Specications from System
Goals , in Proc. of 10th ACM SIGSOFT International
Symposium on Foundations of software engineering,
2002.
[18] E. Letier, Reasoning about Agents in Goal-Oriented
Requirements Engineering , PdD Thesis, D`partement
d'Ing`nierie Informatique, UCL, 2001.
[19] E. Letier, Goal-oriented elaboration of requirements
for a safety injection control system , technical report,
D`partement d'Ing`nierie Informatique, UCL, 2002.
[20] E. Letier, J. Kramer, J. Magee and S. Uchitel,
Deriving Event-Based Transition Systems from
Goal-Oriented Requirements Models , Journal of ASE,
15:175{206, 2008.
[21] E. Letier and W. Heaven, Requirements Modelling by
Synthesis of Deontic Input-Output Automata , in Proc.
of ICSE 2013, IEEE, 2013.
[22] J. Magee and J. Kramer, Concurrency : State Models
and Java Programs , John Wiley and Sons, 1999.
[23] Z. Manna and A. Pnueli, The temporal logic of reactive
and concurrent systems specication , Springer, 1992.
[24] Z. Manna and A. Pnueli, Temporal verication of
reactive systems - safety , Springer, 1995.
[25] J. Mylopoulos, L. Chung, and B. A. Nixon,
Representing and using non-functional requirements:
A process-oriented approach , IEEE Transactions on
Software Engineering, 18:483^ a A S497, 1992.
[26] T. Mitchell, Machine Learning , McGraw Hill, 1997.
[27] K. McMillan, Interpolation and SAT-Based Model
Checking , in Proc. of CAV 2003, LNCS 2725, Springer,
2003.
[28] K. McMillan, Applications of Craig Interpolants in
Model Checking , in Proc. of TACAS 2005, LNCS 3440,
2005.
[29] C. Rolland, C. Souveyet, and C. B. Achour, Guiding
goal modelling using scenarios , IEEE Transaction on
Software Engineering, 24(12):1055^ a A S1071, 1998.
[30] E. S. K. Yu, Towards Modelling and Reasoning
Support for Early-Phase Requirement Engineering ,
IEEE Int. Symp. on Requirements Eng. pp. 226-235,
1997.139