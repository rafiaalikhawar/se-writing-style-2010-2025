Managing Non-functional Uncertainty
via Model-Driven Adaptivity
Carlo Ghezzi, Leandro Sales Pinto, Paola Spoletiniy, and Giordano Tamburrelli
DeepSE, Politecnico di Milano, Italy. fghezzijpintojtamburrellig@elet.polimi.it
yUniversit `a dell’Insubria, Italy. paola.spoletini@uninsubria.it
Abstract —Modern software systems are often characterized by
uncertainty and changes in the environment in which they are
embedded. Hence, they must be designed as adaptive systems. We
propose a framework that supports adaptation to non-functional
manifestations of uncertainty. Our framework allows engineers
to derive, from an initial model of the system, a ﬁnite state
automaton augmented with probabilities. The system is then
executed by an interpreter that navigates the automaton and
invokes the component implementations associated to the states
it traverses. The interpreter adapts the execution by choosing
among alternative possible paths of the automaton in order
to maximize the system’s ability to meet its non-functional
requirements. To demonstrate the adaptation capabilities of the
proposed approach we implemented an adaptive application
inspired by an existing worldwide distributed mobile application
and we discussed several adaptation scenarios.
I. I NTRODUCTION
Modern software systems are characterized by an increased
complexity, for example, in terms of size as well as geo-
graphical distribution. Moreover, engineers increasingly design
systems by relying on components operated by third-party
organizations. All these factors introduce many sources of
uncertainty in designing software that should guarantee certain
quality requirements. For example, a component operated by
a third-party organization has an uncertain execution time
and failure rate. This means that, at design time, engineers
can make certain assumptions, but these may be invalidated
at run time. Indeed, uncertainty may subvert design-time
assumptions, jeopardizing the system’s ability to meet its
requirements. The execution time of a remote component
may increase unexpectedly affecting the response time of the
overall system or, similarly, a component failure may affect the
system’s reliability. Both cases may lead to potential violations
of non-functional requirements that cannot be tolerated.
To cope with uncertainty, software can be designed as an
adaptive system [4]. In practice, engineers typically design
systems by explicitly programming alternative behaviors and
by heavily using exception handling techniques to adapt the
execution to detected changes in the environment that reify the
sources of uncertainty. This is quite hard per-se and cannot
be done by inexperienced developers. In addition, using this
approach, such alternative behaviors cannot be kept separated
from each other and from the exception handling code. As a
result, the architecture and the code are hard to understand
and maintain.To overcome this limitation, we present ADAM:1a model-
driven framework conceived to support the development and
execution of software that tolerates manifestations of uncer-
tainty by self-adapting to changes in the environment, trying
to do its best to satisfy certain non-functional requirements.
In particular we support adaptation aimed at mitigating the
non-functional uncertainty concerning (1) response time and
(2) faulty behavior of components integrated in a composite
application. The proposed solution models the system as a
workﬂow of abstract functionalities. For each of them, one or
more implementations are provided.
The approach derives then a ﬁnite state automaton aug-
mented with probabilities in which each state of the automaton
represents an implementation of an abstract functionality of
the system, while paths represent all the possible execution
ﬂows of the system. The system execution is performed by an
ad-hoc interpreter that navigates the automaton state by state
and invokes the implementations associated with the states
it traverses. The interpreter is responsible for driving and
adapting the execution by choosing among alternative paths
of the automaton in order to maximize the system’s ability to
meet its non-functional requirements.
With this paper we contribute to research in self-adaptive
systems in two distinct ways:
1) We lay the foundations of a model-driven methodol-
ogy that supports the design of systems in terms of
abstract functionalities and delegates the execution to
an optimizing interpreter, which self-adapts to changes
by selecting the implementation variants to bind to
abstract functionalities in order to satisfy non-functional
requirements;
2) We present a novel technique to support non-functional
adaptation that exploits Probability Theory and Prob-
abilistic Model Checking [1]. The proposed technique
computes and assigns a probability to each possible
execution ﬂow of the system indicating their likelihood
to meet the desired non-functional requirements. In our
approach the interpreter relies on such values to drive
the execution;
The remainder of the paper is organized as follows. Sec-
tion II introduces a reference example we use throughout
the paper. Section III describes the ADAM approach in its
essential steps, presenting it also applied to the example,
1Adaptive M odel-driven execution978-1-4673-3076-3/13/$31.00 c2013 IEEE ICSE 2013, San Francisco, CA, USA33
highlighting several relevant scenarios. Section IV discusses
its advantages w.r.t. the state of the art. Section V evaluates
the performance of ADAM in several scenarios of growing
complexity. Finally, Section VI discusses related work, while
Section VII draws some concluding remarks.
II. T HESHOPREVIEW APPLICATION
ShopReview (hereafter referred to as SR) has been selected
as the adaptive application used throughout the paper to ex-
plain our approach. SR is a mobile application for smartphones
inspired by ShopSavvy,2an existing worldwide distributed
application, which allows users to share data concerning a
commercial product or query for data shared by others. Users
may use SR to publish the price of a product they have found
in a certain shop and, in response, the application provides the
users with more convenient prices offered by: ( i) nearby places
(i.e., LocalSearch ) or ( ii) on-line stores ( i.e., WebSearch ). The
unique mapping between the price signaled by the user and the
product is obtained by exploiting the product’s barcode. The
application starts by asking the user to scan a barcode with the
smartphone camera and to type the price of the product whose
barcode has been scanned. In response to these inputs the
applications: (1) recognizes the barcode number in the scanned
image, (2) looks up online the product associated to the
barcode number, (3) retrieves the user location, (4) performs
the WebSearch as well as the LocalSearch, (5) displays the
obtained results, and (6) allows the user to publish the price
of the product to be used by searches issued by other users.
Furthermore, we decide to implement the code for recogniz-
ing the barcode from a picture acquired through the camera,
which runs an ad-hoc developed component that encapsulates
an image recognition algorithm. Since such component exe-
cutes correctly only on devices with an autofocus camera and
does not work properly on other devices, this choice would
limit the usability of our application. For this reason, SR,
as for the original ShopSavvy app, is designed to provide
also an alternative recognition algorithm. Indeed, it detects
if the camera on the current device has autofocus and, if not,
it invokes an external service to process the acquired image
with an ad-hoc blurry decoder algorithm. In both cases, if the
barcode cannot be recognized ( e.g., the image is blurred), the
application asks the user to take the picture again.
In addition, let us assume that SR must satisfy the non-
functional requirements listed in Table I. R1, for example, is a
performance requirement typically imposed by several market-
places of mobile applications.3Notice that, in our application,
several features contribute—at large—to usability ( R2). For
example, to retrieve the user location, the GPS is preferable
over the NPS4because of its increased precision. Similarly,
presenting a sorted list (by price and distance) of the results
of WebSearch and LocalSearch, respectively, also increases
the app’s usability.
2http://shopsavvy.mobi/
3The Windows Phone Marketplace requires that applications unresponsive for more
than three seconds must display a visual progress or busy indicator: msdn.microsoft.com/
en-us/library/hh184840(v=vs.92)
4Network Positioning System.TABLE I
SHOPREVIEW NON -FUNCTIONAL REQUIREMENTS .
Description Metric Class
R1 After an input the application Response Threshold
shall respond in at most 3s. Time (RT) Based
R2 Maximize application usability Usability (U) Max
R3 Minimize battery consumption Energy Consumption (E) Min
ADAM supports two classes of non-functional require-
ments: (1) Threshold-Based and (2) Max/Min. The former
comprise requirements in the form: mthormth, where
mis a non-functional metric ( e.g., response time, energy,
etc.) andthis a threshold (see R1). The latter requires to
minimize/maximize a non-functional metric (see R2 R3).
SR is subject to several sources of uncertainty and, as a
consequence, run-time conditions may jeopardize the appli-
cation’s ability to meet its non-functional requirements. For
example, engineers may design SR to be compliant with R1
by estimating or experimentally measuring the response time
of the component implementing the WebSearch functionality,
which invokes a remote back-end. However, such response
time may increase unexpectedly during operation because
of the network latency or other external factors, causing
the system to violate R1. Such unexpected behavior, if left
unmanaged, may cause an unsatisfactory user experience or,
in the worst case, the rejection from the marketplace. Thus,
even with such a simple example, uncertainty management is
fundamental for a successful system design. It is important to
notice that the concepts illustrated through this paper apply
seamlessly to larger and more complex systems where the
beneﬁts of our approach are even more relevant.
III. T HEADAM A PPROACH
ADAM is a model-driven framework conceived to support
the development and run-time operation of self-adaptive sys-
tems, which can react to (1) unexpectedly higher response time
or (2) unexpected faults of the parts they rely upon.
Let us start by giving an overview of the approach, as
illustrated in Figure 1. First, developers provide a model
of the system in terms of abstract functionalities organized
in a workﬂow. In particular, we support systems modeled
by Activity Diagrams [8]. For each abstract functionality,
developers also provide one or more target implementations,
annotated with a description of their non-functional behaviors.
Annotations may concern, for example, the expected execution
time, cost, or the impact on energy consumption or on the
application’s usability. The supplied target implementations
display different non-functional qualities. The goal is to be
able to develop dynamic composition of target implementa-
tions that best match the overall application’s requirements.
We assume target implementations to be stateless components.
Given these inputs and a set of non-functional requirements
the system has to meet, the approach relies on two distinct
tools: (1) the Generator and (2) the Interpreter . The Gen-
erator analyzes the Activity Diagram and the corresponding
annotated target implementations and generates a ﬁnite state34Developer 
UML Activity Diagrams Implementations ----------- 
----------- 
----------- 
generates invokes 
executes uses annotates designs 
uses 
Embedded Model …… …………Interpreter PRISM uses 
Generator Fig. 1. The ADAM Approach.
automaton, called Embedded Model (EM). In the EM, each
state represents an implementation of an abstract functionality
of the system, while paths represent all the possible execution
ﬂows. The Interpreter is, instead, in charge of executing the
system by navigating the automaton state-by-state and by
invoking the chosen target implementations associated to the
states it traverses. In particular, it is responsible for driving and
adapting the execution by choosing among alternative paths
of the automaton in order to maximize the system’s ability
to meet its non-functional requirements. By this we mean
that the Interpreter ﬁrst measures the effects of non-functional
uncertainty ( e.g., the response time of invoked functionalities)
and consequently chooses the most convenient path in the
EM to maximize the likelihood of meeting all the system’s
requirements. This way, if the Interpreter detects that the
current execution is slower w.r.t. a certain performance re-
quirement, it may autonomously decide to drive the execution
by choosing a speciﬁc (fast) path in the EM that guarantees the
compliance with the performance requirement. The approach
comprises the following steps: (1) Modeling , (2) Transforma-
tion, (3) Model Manipulation , and (4) Execution . Hereafter,
we describe each of them in detail. For each step, we also
illustrate it referring to the SR example.
A. Modeling
As previously introduced, the system is initially conceived
in terms of abstract functionalities and modeled by one or more
UML Activity Diagrams, which organize them in workﬂows.
For each abstract functionality, engineers also provide one or
more corresponding alternative target implementations . The
design methodology to derive the set of target concrete func-
tionalities for each abstract one, given the overall requirements
and an uncertainty mitigation policy, is out of scope of the
present paper. We observe, however, that designing systems
in terms of alternative implementations corresponds to an
approach already used for complex software systems, even
if informally. For example, in mobile applications, the user
location is typically obtained by relying on two alternatives:
(1) the GPS sensor or (2) the NPS. Clearly, every abstract
functionality needs at least one corresponding implementation.
In addition, while modeling, engineers are allowed to annotate
a subset of the abstract functionalities as Optional . Usually,
optional functionalities are not essential for the correctness of
0.3 2: Photo 
Acquisition 1: Input Price 
5: Product 
Lookup 
8: Web Search 7: Local 
Search 
11 : Publish 
Price <<Optional>> 
10 : Result 
Ordering 3: Local 
Recognition 4: Remote 
Recognition [hasAutoFocus]
<<Optional>> 
9: Secondary 
Web Search 0.6 0.4 true false 
6: Location [recognized]
0.7 true false 13 : ShowMap 12 : NPS Location 
(NPS Alternative) Fig. 2. ShopReview UML Activity Diagram.
the ﬁnal result, but may, however, affect usability. If necessary,
they are sacriﬁced to accomplish more important goals. As
illustrated in the example, each non-functional requirement
predicates over a certain non-functional metric. As a conse-
quence, each implementation is annotated with the impact it
has w.r.t. these metrics. For example, an implementation of
an abstract functionality with an expected response time of
2seconds is annotated with responseTime=2s . Concrete
implementations that require user interaction cannot be an-
notated with an impact on response time, since they depend
on the user’s think time. They are therefore annotated with
@UI, whose meaning will become clear later on. Notice that
the annotation process occurs for each requirement metric on
all the implementations. Finally, ADAM requires engineers to
annotate each branch of decision nodes in the UML Activity
Diagram with the expected probability that an execution of the
system may take that branch. When not speciﬁed, branches are
considered to have the same probability.
Modeling the SR Application. The modeling step applied to
the SR example may produce the Activity Diagram illustrated
in Figure 2. For each abstract functionality, one or more con-
crete implementations are provided. For instance, concerning
ProductLookup , which translates a barcode into a product
name, SR relies on a remote service ( e.g., searchupc.com) as
one of the possible implementations. Alternatively, the appli-
cation may ask the user to directly provide the product’s name.
As for searching the Web for more convenient prices, SR
relies on a primary remote service ( e.g., shopzilla.com) and on
complementary services, represented by the abstract function-
alities WebSearch andSecondaryWebSearch , respectively. Note
that the SecondaryWebSearch is annotated as an Optional
functionality to represent the fact that it may be omitted at run-
time, if necessary. Similarly, the ResultOrdering functionality,
which sorts the results of WebSearch andLocalSearch by price
and distance, respectively, has been annotated as optional.
Concrete implementations are provided by Java methods
using the ad-hoc annotation @Implementation to refer to
the abstract functionality they implement. Moreover, the anno-
tation @Impact is used to specify the impact the implemen-35@Implementation (name= ” ProductLookup ” )
@Impact ( metrics= f” responseTime ” , ” energy ” , ” u s a b i l i t y ” g, values = f1, 2 , 1 g)
public S t r i n g automaticProductLookup ( S t r i n g barcode) f
/ / invoke h t t p : / / searchupc . com /
g
@Implementation (name= ” ProductLookup ” )
@Impact ( metrics= f” energy ” , ” u s a b i l i t y ” g, values = f1, 0g)
@UI
public S t r i n g manualProductLookup ( S t r i n g barcode) f
/ / ask the user to i n s e r t the product name
g
Listing 1. Implementations for the ProductLookup functionality.
tation has w.r.t. the requirements metrics. Listing 1 illustrates
two methods implementing the ProductLookup functionality,
as described earlier. Note that impacts may be objective values,
as for the response time, or subjective measures as for the
usability or energy consumption. For example, we annotate
with 2the expected energy consumption of the automat-
icProductLookup implementation to indicate that it requires
more energy ( i.e.,battery usage) w.r.t. the second alternative,
which is annotated with an impact equal to 1. Indeed, the
ﬁrst alternative includes the invocation to a remote service,
which implies a higher energy consumption. Alternatively,
the implementations may be annotated with the real energy
consumption they have. However, such values are difﬁcult to
measure and are also device dependent. By relying on the
proposed qualitative annotations, we do not need to necessarily
know the real power consumption of the two alternative
implementations, but only their relative difference .
Furthermore, being these impacts estimates and/or experi-
mental results, they may be also automatically updated and
reﬁned at run time as discussed for example in our previous
work [7], [9], [10]. Similarly, concerning usability, we annotate
the two implementations with different impacts to indicate
that the automatic alternative is preferable over the alternative
which asks the user with an explicit input.
Activities in the diagram may also map to sub-diagrams as
for the Location that maps to: (1) a concrete implementation
concerning the GPS alternative and (2) another activity dia-
gram as reported (in a dashed box) in Figure 2. According
to the second option, the user’s location is obtained by ﬁrst
invoking the NPS and then showing a map ( i.e., ShowMap )
centered in the obtained location for a manual reﬁnement. This
way we allow for a hierarchical composition of diagrams.
The last step in the modeling phase concerns the probability
annotations of decision nodes. Decision nodes guarded by the
conditions hasAutoFocus andrecognized have been
annotated with the probabilities reported in Figure 2. They
express, respectively, the fact that 40% of mobile devices do
not have an autofocus camera and, on average, 70% of bar-
codes contained in acquired pictures are correctly recognized.
B. Transformation
Activity Diagrams are translated into a formal representa-
tion, the Embedded Model (EM), which is a Markov Decision
Process (MDP) [18]. MDPs are ﬁnite state machines aug-
mented with probabilities and non-deterministic transitions.
The formal concepts concerning MDPs needed to understand
the rest of the paper are summarized in the Appendix.The translation of Activity Diagrams into an MDP is
performed by the Generator tool. It ﬁrst translates each abstract
functionality into a simple MDP with an initial state, a ﬁnal
state, and as many intermediate states as the number of
implementations associated with the abstract functionality. In
addition it adds a non-deterministic transition from the initial
state to each intermediate state that are, in turn, connected to
the ﬁnal state. The resulting MPDs are then merged in a single
MDP which represents the translation of the overall Activity
Diagram. Moreover, annotations attached to implementations
are also propagated into the EM by annotating each state in
the model with the same impact numbers as its corresponding
implementation. Notice that connections which participate in
decision nodes ( i.e.,connections labeled with probabilities) are
translated in the MDP as probabilistic transitions labeled with
the same probabilities as the originating connections.
Transforming the SR Activity Diagram. As we said above,
we ﬁrst translate each abstract functionality into a simple
MDP with an initial state, a ﬁnal state, and as many inter-
mediate states as the number of implementations associated
to the abstract functionality. For example, the ProductLookup
functionality, which has two corresponding implementations,
results in the MPD in Figure 3(a).
A functionality annotated as optional also requires the intro-
duction of a direct transition from the initial state to the ﬁnal
one. For example, if we have two alternative implementations
of the SecondaryWebSearch , which differ in the remote service
they invoke, we obtain the MDP in Figure 3(b).
The resulting MDPs are then composed together as follows.
Two MDPs corresponding respectively to two subsequent
nodes in the Activity Diagram are composed by merging the
ﬁnal state of the ﬁrst one with the initial state of the second
one. By merging such states we generate a symbolic state .
This process is exempliﬁed in Figure 3(c), where symbolic
states are highlighted in grey and labeled with a letter. Decision
nodes are translated similarly. The MDP corresponding to a
functionality that precedes a decision node has its ﬁnal state
merged to the initial state of all the MDPs corresponding to the
functionalities subsequent to the decision node. The merging
process generates a symbolic state as aforementioned.
Concerning nodes that also map to other diagrams, as for
theLocation node, we ﬁrst translate the node (as explained
so far) considering only its implementations ( e.g., the GPS
alternative). Subsequently, we add, as an alternative path from
the initial to the ﬁnal state, the MPD obtained by translating
the other diagrams ( e.g., the NPS sub-diagram).
The translation process applied to the Activity Diagram
of the SR application results in the EM reported in Fig-
ure 3(d). For intance, the functionality Location is represented
in the MDP by state 6a(i.e.,the GPS alternative) and states
12 f 13(i.e.,the translation of the NPS nested diagram).
At this stage we propagate the annotations attached to the
implementations into the EM. In Figure 3(d) we indicate them
withRT,E, andUfor response time, energy consumption,
and usability, respectively. For example, state 5b, which cor-365: Product 
Lookup 5a5b
..… ..…
Activity MDP (a) Alternative Implementations.
<<Optional>> 
9: Secondary 
WebSearch 9a9b
..… ..…
Activity MDP (b) Optional Functionality.
8Activity MDP 8: WebSearch ..… 
i
..… <<Optional>> 
9: Secondary 
Web Search 
9a9b (c) Composition of MDPs.
4
3
RT= 0.3s 
E=1 
U=1 10 
7 c g hRT=0.6s 
E=2 
U=1 
RT=0.5s 
E=2 
U=1 RT=0.3s 
E=1 
U=1 RT=0.6s 
E=1 
U=1 
RT=0.8s 
E=2 
U=1 RT=2s 
E=3 
U=1 
8 i
RT=0.6s 
E=2 
U=1 9a
9bj
RT=0.6s 
E=2 
U=1 RT=0.5s 
E=2 
U=1 
0.6 0.4 6a
12 e b
f 13 
RT=0s 
E=1 
U=0 1 2 a0.7 0.3 5a
5bRT=0s 
E=1 
U=0 
d
RT=0s 
E=1 
U=0 RT=0s 
E=1 
U=0 k 11 
RT=0s 
E=2 
U=1 
(d) ShopReview Embedded Model.
Fig. 3. Translation Process.
responds to the automaticProductLookup implementation (see
Listing 1), is annotated with its impact in terms of response
time ( i.e.,0:5s), energy consumption ( i.e.,2), and usability
(i.e.,1). Since symbolic state are artiﬁcially generated by the
translation process they are annotated with neutral values:
RT= 0,E= 0,U= 0. Notice that, by construction, the
obtained EM represents all the possible execution ﬂows of the
system in terms of target implementations. Indeed, starting
from its initial state, the MDP has multiple alternative paths
towards the ﬁnal state. The translation process performed by
the Generator hides the complexity of MDPs to developers.
A formal description of the automatic translation algorithm is
not given here for space reasons. It is based on the automatic
translation of an annotated Activity Diagram into a Markov
process that was presented in our previous work ( i.e.,[13]).
C. Model Manipulation
The annotations attached to the states of the EM represent
the impact of the corresponding implementation on quality
metrics. Formally, this information corresponds to rewards
in the MDP formalisms (see the Appendix). It can be used
to compute the minimum and maximum cumulative rewards
(indicated as minR (s)andmaxR (s)) from each state sto the
ﬁnal state in the model and for each quality metric. The com-
putation of such cumulative rewards may be arbitrarily com-
plex because of three characteristics of the model: (1) loops,
(2) probabilities attached to transitions, (3) a large number of
alternative paths. We rely on a probabilistic model checker,
such as PRISM [14], to compute them. Given these premises,
we manipulate the model by replacing impact numbers at-
tached to each state swith an intervalhminR (s);maxR (s)i
for every requirement metric of the system. It is important to
notice that such intervals represent forecasts of the impacts
necessary to complete the execution ( i.e.,reach the ﬁnal state)starting from a speciﬁc state sof the model. At execution
time, such values are used by the Interpreter to select the most
appropriate path towards the ﬁnal state, as illustrated in Section
III-D. Figure 4 illustrates the cumulative rewards obtained by
exploiting PRISM for some states of the EM. Notice that,
when cumulative rewards are computed for response time,
all the states characterized by user interaction ( i.e., whose
corresponding implementations are annotated with @UI) are
considered as ﬁnal states of the EM together with the original
ﬁnal states. Indeed, the requirements concerning response time
(e.g.,R1) predicate over the portions of the system in which
the computation occurs autonomously, i.e.,without user input.
9a
9bi... RT=<0.5; 1.1> 
E=<4; 5> 
U=<2; 3> 
RT=<0.6; 1.2> 
E=<4; 5> 
U=<2; 3> jRT=<0; 0.6> 
E=<2; 3> 
U=<1; 2> 
... 
Fig. 4. Model Execution Example.
Manipulating the SR Model. At this stage, we manipulate
each statesof the model in Figure 3(d) by replacing impact
numbers with intervals in the form hminR (s);maxR (s)i, for
every requirement metric, obtained by running the probabilis-
tic model checker, as explained above. For example, let us
focus on state 6aand usability. In this case the model checker
yields the following values: h4; 6i. These values indicate that
an execution reaching state 6awill have an additional usability
impact value in the interval h4; 6ito reach the ﬁnal state.
Similarly, for the response time and energy consumption we
obtainh2:9; 4:1iandh8; 11i, respectively.37D. Execution
At run time, given the annotated EM, the Interpreter is
in charge of executing the application, by navigating through
the state space. It invokes the corresponding implementation
and performs two additional tasks. First, it keeps track of
the cumulated impact of all the quality metrics. For example,
assuming that the Interpreter invoked two implementations that
executed in 1sand0:5s, its aggregated response time is 1:5s.
The run-time data structure that contains all these aggregated
values is called the Execution Context . Second, it selects one
of the alternative paths in the model. The choice among
alternative paths occurs if the current state has many outgoing
non-deterministic transitions, i.e., the next functionality to
be executed has many corresponding implementations and/or
is optional.5The choice is performed by the Interpreter as
described next.
Given a system with a set of non-functional requirements
R=fr1;:::;r ngand an execution that reached state sc
characterized by a set T=ft1;:::;t kgof non-deterministic
outgoing transitions, the Interpreter computes a Probability of
Success for each alternative transition ti. Such probability Pti
represents the likelihood that the system may complete the
execution meeting all the requirements by taking transition ti.
Letsibe the destination state of each outgoing transition
tiand let us focus initially on a threshold-based requirement
Req that predicates on response time, i.e.,RTth. We know
from the interval associated to each state sithat an execution
through that state has an expected response time included in
the intervalhai;bii, as computed in the model manipulation
step of the approach. In addition, we know from the Execution
Context that, to reach state w, the execution already cumulated
a response time cRT(i.e.,the execution spent cRTseconds to
reach statesc). Given these premises, we model the response
time associated with the execution from state sito the ﬁnal
state as a random variable xsiuniformly distributed over the
intervalhai;bii(i.e.,xsiU(ai;bi)). In this setting, the
ability of the system to meet Req boils down to choosing a
transition towards a state sisuch that the response time from
that state to the ﬁnal one is less than the requirement threshold
decreased by the time already consumed to reach the current
state:xsith cRT. In particular, the probability that this
may occur ( i.e.,P(xsith cRT)) corresponds to the area in
the Uniform Distribution comprised among aiandth cRT:
Pti;RT=P(xsith cRT) =(th cRT) ai
bi ai
Such value corresponds to the probability of success for
transitionticoncerning only response time. In particular, three
cases may occur that yield to a probability of success, as illus-
trated in Figure 5. Intuitively, if the threshold decreased by cRT
is greater than the interval that contains the expected values
of response time, probability of success is one. Conversely, if
5States with multiple outgoing transitions labeled with probabilities do not
represent a decision point among alternative paths since they correspond to
decision nodes in the Activity Diagram and the next state in the execution is
selected by evaluating run-time conditions ( e.g.,hasAutoFocus for SR).
th-c RT0 < P(RT≤ th)  < 1 
a bP(RT≤ th) th-c RT
a b
a b RTth-c RT
P(RT≤ th)  = 1 
P(RT≤ th)  = 0 RTRTP(RT≤ th) 
P(RT≤ th) b-a 1b-a 1
b-a 1Fig. 5. Probability of Success.
the threshold decreased by cRTis smaller than the interval,
the probability is zero. In all the other cases the probability is
in[0;1]accordingly to the relative position of the interval and
the quantity th cRT. Notice that requirements in the form
ofRTthare processed similarly by inverting the area
considered in computing the probability of success. We repeat
this procedure for all requirements in R. In particular, if we
havenrequirements and kpossible outgoing transitions, the
Interpreter builds a nkmatrix in which each element (i;j)
represents the probability that choosing transition tiwould
yield to an execution compliant with requirement rj(i.e.,
probabilities of success Pti;rj). The Interpreter is parametrized
with a vector w=w1;:::;w nof weights. Such vector is
used to aggregate the probabilities of success by computing a
weighted average of the values in each column of the matrix.
The result is a single value for each outgoing transition, which
represents the probability of satisfying all the requirements
according to the weight: Pti=P
1jn(wjPti;rj). The
Interpreter proceeds the execution by choosing the transition
tiwith the highest Pti. Notice that weights are used by the
designer to prioritize requirements.
Executing the SR Application. Let us consider requirement
R1and let us assume that the Interpreter reached state i(see
Figure 4). In this scenario, it has to choose among three
outgoing transitions ( i.e.,9a;9bandj). The probability of
success of the transition towards state 9acorresponds to the
probability that the execution terminates within 3s(R1). We
know from the interval associated to state 9athat the execution
through that state will terminate with a response time in the
intervalh0:5s; 1:1si. At this stage, we model the response time
of the execution through state 9aas a random variable x9auni-
formly distributed over the interval ( i.e.,x9aU(0:5;1:1)).
Furthermore, let us assume that the Execution Context contains
a cumulated value for the response time equal to cRT= 1:95s.
The Interpreter computes the probability that the response time
will be lower than the requirement threshold decreased by the
value in the Execution Context ( i.e.,3s 1:95s= 1:05s) as the
area in the Uniform Distribution in the interval h0:5s; 1:05si:
P(x9a3s) =1:05 0:5
1:1 0:5= 0:92. Similarly, for the outgoing
transitions to state 9bwe haveP(x9b3s) = 0:75. Finally,
for the outgoing transitions to state jwe haveP(xj3s) = 1
(i.e.,the third case of Figure 5).38Let us consider now requirement R2, which is a maximiza-
tion requirements and thus needs a slightly different process.
In this case the probability of success concerning usability
associated with the transition toward state 9a(i.e.,(P9a;U))
corresponds to the probability that the usability value obtained
by choosing it is greater than the usability value obtained
with the transitions to state 9band to state j. We know
that by choosing the transition to state 9ausability would
be in the interval in h2; 3i, while choosing the transitions to
state 9bandjwe obtain a usability value in the intervals
h2; 3iandh1; 2i, respectively. By modeling the usability of the
execution through state 9aas a random variable y9auniformly
distributed over the discrete interval ( i.e.,y9aU(2;3))
and the usability of the execution through states 9bandj
with random variables y9b,yjuniformly distributed over their
intervals ( i.e.,y9bU(2;3)andyjU(1;2)), we obtain
that the probability of success associated with the transition
toward state 9a(w.r.t.R2) is:
P9a;U=P(y9ay9b^y9ayj) =
X
(i;k;l )2AP(y9a=i^y9b=k^yj=l)
where:A=f(i;k;l )ji2h2; 3i;k2h2; 3i;l2h1; 2i;i
k;ilg. Considering y9a,y9bandyjare independent
variables we obtain P9a;U= 0:75. Similarly, we obtain:
P9b;U= 0:75andPj;U= 0:13. Finally, for requirement R3
(i.e.,a minimization requirement) we can apply a similar ap-
proach, with obvious changes, obtaining P9a;E= 0,P9b;E= 0
andPj;E= 1.
Let us conﬁgure the Interpreter with the following weight
vectorw=f0:4;0:4;0:2g, which corresponds to requirements
R1,R2, andR3respectively. This choice prioritizes R1 2
overR3. Given these weights the probabilities of success are:
P9a= 0:67,P9b= 0:6, andPj= 0:65. In this setting, the
Interpreter proceeds in the execution towards state 9a.
Notice that the approach, as described so far, uses only
uniform distributions. However, the concepts illustrated in the
paper apply seamlessly to other distributions that may adopted
in speciﬁc scenarios if needed. In addition, it is important
to notice that the proposed approach applies identically to
continuous ( e.g.,R1) as well discrete non-functional require-
ment ( e.g.,R2 3). The only difference is the mathematical
computation of probabilities.
IV. A DVANTAGES OF THE ADAM A PPROACH
The inability to manage at run time the consequences
of design-time uncertainty leads to system that may violate
their requirements. A non-adaptive implementation for SR,
when execution reaches a certain state—say, i—would proceed
by selecting the same transition—say, the transition towards
state 9a—irrespective of the time spent by the computation to
reach state i. The adaptive execution supported by ADAM
would, instead, select the transition towards state 9ain a
scenario where state iis reached in 1:95s(i.e.,cRT= 1:95s),
and select transition jin the case which state iis reachedin2s(i.e.,cRT= 2s). In the latter case, with cRT= 2s,
the probability of success associated with outgoing transi-
tions from state ichanges. In particular, by repeating the
calculations illustrated in the previous section, we obtain the
following values: P9a= 0:63,P9b= 0:57, andPj= 0:65.
As a consequence, the Interpreter proceeds the execution by
selecting transition j(i.e.,the highest probability).
This choice is reasonable since the new context ( i.e.,2s)
indicates a slower execution. In this situation the probability of
success of the outgoing transitions 9aand9bdecreases, mak-
ing the option that skips the SecondaryWebSearch functionality
(i.e., transition towards j) preferable. Indeed, skipping this
functionality speeds up such slower executions, minimizing the
risk of violating R1. Conversely, in faster executions, transition
jhas a lower probability of success because of its smaller
contribution to usability w.r.t. 9aand9b. The same adaptation
mechanisms apply to all of the EM non-deterministic choices;
for example, the choice between the GPS and NPS, which
require different execution times and offer different degrees
of usability and energy consumption.
A traditional strategy to manage uncertainty consists of
designing systems by explicitly programming alternative be-
haviors and by heavily using exception handling techniques to
adapt the execution to the manifestations of uncertainty. Let
us consider the case of the alternative implementations of the
Location functionality. A traditional adaptive implementation
would require engineers to write an ad-hoc adaptation logic
(e.g., cascaded if-else s to choose between the two implemen-
tations) and exception handling constructs aimed at managing
the potential failures of both the alternatives. Such logic, not
only results in convoluted solutions, but is also intertwined
with the application logic yielding to code that is hard to
read and maintain. Conversely, ADAM applications do not
require such adaptation logic (see Listing 1) and delegate
the adaptation management to the framework tools. As a
consequence of this simpliﬁcation, the implementations in
the form of distinct annotated methods result in code that
is easy to read, write, maintain, and evolve. Furthermore,
ADAM also increases reusability, since the same functionality
implementations can be reused across different applications.
ADAM also offers another source of adaptation against
uncertainty. In Section I we stated that ADAM not only
manages non-functional uncertainty in terms of higher re-
sponse time, but also handles unexpected faults. Indeed, the
system execution managed by the Interpreter introduces a
useful self-healing feature in ADAM applications. As soon
as the Interpreter catches a run-time exception while invoking
a functionality implementation, it redirects the execution—if
possible—towards another EM path that allows the system to
complete successfully. For example, if invoking the functional-
ity associated with state 9athe Interpreter catches an exception
indicating that the underlying Web service is unavailable, it
may backtrack the execution to the previous state ( i.e.,i) and
redirect the execution through an alternative path ( e.g., 9b).
Even if this is a simple self-healing mechanism, it is useful
to maximize the system reliability in many scenarios. For39example, in the mobile domain, the GPS may fail unexpectedly
and the NPS may be executed alternatively and transparently.
Finally, ADAM also achieves a clear separation among the
different aspects of the application: from the more abstract
ones, captured by Activity Diagrams, to those closer to the
technical domain, captured by the implementations. By relying
on such sharp separation of concerns, developers may ﬁrst
model the features they want to introduce in the system, ig-
noring how they will be implemented later on. Let us consider
again the Location functionality of the SR application. In the
inception phase, developers only focus on the fact the system
needs such feature and connect it to the other features by
relying on the Activity Diagram. Later on, they can implement
a ﬁrst prototype that leverages NPS and the manual input of
the user realizing that this solution needs to be improved in
terms of usability. The applications may gradually evolve, by
adding other implementations for this feature ( e.g., the GPS).
This process, in which the system design is decoupled from
the implementation, as enforced by the proposed approach, is
a widely recognized best practice in Software Engineering.
It is important to notice that the advantages provided by the
ADAM approach are obtained transparently w.r.t. to engineers,
who only have to produce one or more Activity Diagrams
and their corresponding implementations. Even the complexity
concerning the EM and MDPs is managed behind the scenes
by the ADAM tools.
V. V ALIDATING THE APPROACH
ADAM is implemented a publicly available open-source
tool.6Although our approach is general and applies with
limited technological modiﬁcations to other languages, we
focused on the Java language for our prototype. In this Section,
we discuss the validation of the ADAM approach, focusing
on its run-time overhead and scalability. The validation has
been carried out by performing a large simulation campaign.
Hereafter, we report the most signiﬁcant results and we refer
the reader to our prototype implementation for the replicability
of the presented data. Since ADAM requires additional run-
time computation, we start by discussing the overhead imposed
to navigate and execute the model. This includes the com-
putation of the probabilities of success for each alternative.
We developed an application that automatically generates
different models, and we used the ADAM prototype to execute
them. To test its performance under different situations, we
varied the number of abstract functionalities that are part
of the model and the number of alternative implementations
bound to them. Finally, we also varied the number of non-
functional requirements present in the model to be satisﬁed
during execution. Our evaluation was carried out on the
following hardware setting: i5-540M processor, 4GB of RAM,
Ubuntu Linux 11.10, and Oracle Java Runtime Environment
version 1.6.0 26. Moreover, each of the experiments was
repeated at least 30times. The ﬁrst experiment investigates
the overhead imposed by ADAM to execute a simple model
6http://code.google.com/p/adam-java/where each abstract functionality is associated with a single
implementation. To calculate the overhead, we compared an
ADAM execution with an equivalent (hard coded) sequence
of method calls to the same implementations.7We have varied
the number of used abstract functionalities (and, consequently,
the number of method calls) from 10to1000 . The measured
results are reported in Figure 6(a). These results show that the
way ADAM models are navigated and executed introduces a
negligible overhead, around 2:35%. For instance, for a large
model with 500 abstract components, the execution takes
in average 25:65s, while the Java execution with the same
number of method calls requires 25:06s. To further investigate
the overhead imposed by ADAM we extended the previous
experiment as follows. Let us consider a base scenario with the
following parameters: 500abstract functionalities, each with 3
alternative implementations, annotated with different impacts;
6non-functional requirements, 3of which are threshold based
and the remaining 3aremin/max requirements.
Figure 6(b) shows how the size of the model affects the
overall execution time. In this experiment, we consider the
base scenario increasing the size of the model from 10to
1000 . Note that these results differ from Figure 6(a) because
they include also the time to compute and choose the best
alternative. In general, the experiments show an overhead of
approximately 4 5%, which we still claim to be reasonable.
For instance, for a large model of 500abstract functionalities,
the execution time increases from 25:06sto26:15.
Figure 6(c) shows the time required to execute an ADAM
model in our base scenario with an increasing number of
alternatives bound to each abstract functionality from 1to5.
Note that we plotted with an horizontal black line the average
time for the Java execution. Even in the worst scenario, in
which we have 5alternatives for each abstract functionalities,
the overhead compared to the Java execution reaches an
acceptable value of 9%. Consider that this testbed included
a very large number of alternatives, 2500 in total, which is
far from what we expect from a realistic application. If we
consider that we typically have two alternatives, the average
execution takes 25:83sinstead of 25:06s.
Finally, Figure 6(d) shows, instead, how the execution time
is affected, in our base scenario, by increasing in the number
of requirements, which we varied from 2to10. Note that the
ADAM Interpreter scales very smoothly, allowing applications
to add multiple requirements without decreasing the ADAM
performance. In general, from the above assessment we may
conclude that the ADAM approach is feasible and its use
introduces an acceptable (often negligible) overhead in the
execution time of the overall application, especially when
compared to the advantages as discussed in the Section IV.
VI. R ELATED WORKS
Many existing works address the problem of uncertainty
management and investigate adaptive software systems. The
requirements engineering community has been particularly
7All the methods have a default implementation which sleeps for 50ms.40(a) Execution Overhead.
 (b) Execution Overhead: Increasing Model Size.
(c) Execution Overhead: Increasing Number of Alternatives.
 (d) Execution Overhead: Increasing Number of Requirements.
Fig. 6. ADAM Overhead.
active w.r.t. this research challenge [20]. For example RE-
LAX [24], a requirements language for adaptive systems,
explicitly addresses uncertainty by enabling engineers to cap-
ture uncertainty in the requirements deﬁnition. Differently
from our approach, RELAX achieves adaptation by relaxing
non-critical requirements instead of relying on alternative or
optional functionalities as in the ADAM approach. Souza et
al. [21], instead, enable adaptation by conceiving systems
in control loop in which a set of system parameters ( i.e.,
variability points) is tuned at run-time to satisfy the system
requirements. Finally, Wang et al. [23] describe a framework
that exploits software variability and goal models to allow self-
repair in cases of failure. From a model-driven perspective, we
can mention [17] and [16]. The former focuses on functional
adaptations and investigates the adoption of aspect oriented
programming to weave new system conﬁgurations together
with run-time models used to validate them. The latter also
exploits aspect oriented programming, but focuses on non-
functional properties of systems. It describes a middleware for
run-time adaptation that chooses between alternative applica-
tion variants. In addition, concerning the concept of Embedded
Model, we can mention the work by Balz et al. [2], [3], that
describes an approach to embed full model semantics into
source code. In this case, the ultimate goal of the authors
is to support the synchronization between the model and
the implementation. This approach may be considered as an
alternative solution to implement the ADAM concepts. From
an architectural viewpoint, we may mention the foundational
work on a three-layer architecture for software adaptation,
described in [15], [22], which focuses mainly on functional
adaptation. Cheng et al. in [5] investigate instead architecture-
based adaptation through resource prediction, that is similar to
the non-functional forecasts obtained via probabilistic modelchecking in ADAM, even if at architecture level. In addition,
concerning monitoring, it is important to mention the work
by Ehlers et al. [6], that propose an approach to localize
performance Anomalies and enable adaptations through a rule-
based expert system even if they focus only on response
time. In addition, Fleurey et al. [11] deﬁne the impact of
features (i.e., functionalities), as well as high-level adaptation
rules to choose among them according to the context and
achieve an adaptive behavior. In the same way, Floch et
al. [12] adopt utility functions to determine which component
implementation should be selected according to the context.
The work by Ramirez et al. [19] represents, instead, an
approach that may used to complement the ADAM solution.
Indeed, it allows the automatic discovery of combinations of
environmental conditions that produce requirements violations
and latent behaviors in an adaptive system. Such approach
may be used in ADAM to support engineers in designing
the alternative implementations needed to face the discovered
environmental conditions. All the mentioned approaches differ
from ADAM in many aspects. Some of them, for example, do
not consider non-functional aspects. Others, even if they focus
on non-functional adaptation, do not offer the same degree
of ﬂexibility provided in ADAM that, for example, not only
optimizes the non-functional behavior of the system, but also
maximizes its reliability, as described in Section IV.
VII. C ONCLUSIONS AND FUTURE WORK
In this paper we presented ADAM , a novel approach that
supports the effective development and operation of adaptive
systems. To demonstrate its advantages, we used the proposed
approach to implement a realistic mobile application and we
assessed the overhead introduced by the approach and its scal-
ability by performing a simulation campaign. In addition, to41encourage the adoption of the proposed approach and to allow
the replication of experiments, the ADAM implementation
has been released as an open-source tool. Finally, ADAM
currently supports parallelism only in the implementation
methods and not at the Activity Diagram level. We plan to
overcome this limitation in our future work.
ACKNOWLEDGMENTS
This research has been funded by the EU, Programme
IDEAS-ERC, Project 227977-SMScom and FP7-PEOPLE-
2011-IEF, Project 302648-RunMore.
REFERENCES
[1] C. Baier and J.-P. Katoen. Principles of Model Checking . The MIT
Press, 2008.
[2] M. Balz and M. Goedicke. Embedding process models in object-oriented
program code. In Proceedings of the 1st Workshop on Behaviour
Modelling in Model-Driven Architecture , page 7. ACM, 2009.
[3] M. Balz, M. Striewe, and M. Goedicke. Embedding behavioral models
into object-oriented source code. Software Engineering , 2009.
[4] B. Cheng, R. de Lemos, H. Giese, P. Inverardi, J. Magee, J. Andersson,
B. Becker, N. Bencomo, Y . Brun, B. Cukic, et al. Software engineering
for self-adaptive systems: A research roadmap. Software Engineering
for Self-Adaptive Systems , pages 1–26, 2009.
[5] S. Cheng, V . Poladian, D. Garlan, and B. Schmerl. Improving
architecture-based self-adaptation through resource prediction. Software
Engineering for Self-Adaptive Systems , pages 71–88, 2009.
[6] J. Ehlers, A. van Hoorn, J. Waller, and W. Hasselbring. Self-adaptive
software system monitoring for performance anomaly localization. In
ICAC . ACM, 2011.
[7] I. Epifani, C. Ghezzi, R. Mirandola, and G. Tamburrelli. Model evolution
by run-time parameter adaptation. In ICSE . IEEE, 2009.
[8] H. Eriksson and M. Penker. Business modeling with UML . Wiley, 2000.
[9] A. Filieri, C. Ghezzi, and G. Tamburrelli. Run-time efﬁcient probabilistic
model checking. In ICSE 2011 . ACM.
[10] A. Filieri, C. Ghezzi, and G. Tamburrelli. A formal approach to adaptive
software: continuous assurance of non-functional requirements. Formal
Aspects of Computing , pages 1–24, 2012.
[11] F. Fleurey and A. Solberg. A domain speciﬁc modeling language
supporting speciﬁcation, simulation and execution of dynamic adaptive
systems. Model Driven Engineering Languages and Systems , 2009.
[12] J. Floch, S. Hallsteinsen, E. Stav, F. Eliassen, K. Lund, and E. Gjorven.
Using architecture models for runtime adaptability. Software, IEEE ,
23(2):62–70, 2006.
[13] S. Gallotti, C. Ghezzi, R. Mirandola, and G. Tamburrelli. Quality
prediction of service compositions through probabilistic model checking.
Quality of Software Architectures. Models and Architectures , 2008.
[14] A. Hinton, M. Kwiatkowska, G. Norman, and D. Parker. Prism: A tool
for automatic veriﬁcation of probabilistic systems. TACAS , 3920, 2006.
[15] J. Kramer and J. Magee. Self-managed systems: an architectural
challenge. In FOSE 2007 .
[16] S. Lundesgaard, A. Solberg, J. Oldevik, R. France, J. Aagedal, and
F. Eliassen. Construction and execution of adaptable applications
using an aspect-oriented and model driven approach. In Distributed
Applications and Interoperable Systems , pages 76–89. Springer, 2007.
[17] B. Morin, O. Barais, G. Nain, and J. Jezequel. Taming dynamically
adaptive systems using models and aspects. In ICSE , 2009.
[18] M. Puterman. Markov decision processes. Handbooks in operations
research and management science , 2:331–434, 1990.
[19] A. Ramirez, A. Jensen, B. Cheng, and D. Knoester. Automatically
exploring how uncertainty impacts behavior of dynamically adaptive sys-
tems. In Automated Software Engineering (ASE), 2011 26th IEEE/ACM
International Conference on , pages 568–571. IEEE, 2011.
[20] P. Sawyer, N. Bencomo, J. Whittle, E. Letier, and A. Finkelstein.
Requirements-aware systems: A research agenda for re for self-adaptive
systems. In RE 2010 , pages 95–103. IEEE, 2010.
[21] V . Silva Souza, A. Lapouchnian, and J. Mylopoulos. System iden-
tiﬁcation for adaptive software systems: a requirements engineering
perspective. Conceptual Modeling–ER 2011 , pages 346–361, 2011.
[22] D. Sykes, W. Heaven, J. Magee, and J. Kramer. From goals to
components: a combined approach to self-management. In SEAMS 2008 .[23] Y . Wang and J. Mylopoulos. Self-repair through reconﬁguration:
A requirements engineering approach. In Proceedings of the 2009
IEEE/ACM International Conference on Automated Software Engineer-
ing, pages 257–268. IEEE Computer Society, 2009.
[24] J. Whittle, P. Sawyer, N. Bencomo, B. Cheng, and J. Bruel. Relax: a
language to address uncertainty in self-adaptive systems requirement.
RE, 2010.
APPENDIX
In this section we provide a brief introduction to the mathe-
matical concepts used throughout the paper: Markov Decision
Processes (MDPs) and rewards. MDPs are non-deterministic
Kripke structures with probabilistic transitions among states.
Formally, an MDP over a set of atomic propositions AP is a
tuplehS;s 0;F;Stepsi, where:
Sis a ﬁnite set of states, s02Sis the initial state and
FSis the set of ﬁnal states;
Steps is the transition function, such that for each s2S,
eitherSteps (s) =Dist(S)orSteps (s)22S, where
Dist(S) =f(s1;p1);:::; (sk;pk)g, withPk
j=1pj= 1,
is a discrete probability distribution over S.
Notice that, if, for a ﬁnal state sF2F,Steps (sF) =
f(sF;1)g, the self-edge is often not represented graphically.
MDPs may be augmented with rewards, through which one
can quantify a beneﬁt (or loss) due to the residence in a speciﬁc
state. A reward :S!R0is a non-negative value assigned
to a state. They can represent information such as average
execution time, power consumption or usability. In MDPs,
each statescan be also annotated with rewards cumulated
fromsto a ﬁnal state sF. Given a state s, there may be many
paths that connect it to one of the ﬁnal state sF. Each of
these paths cumulates as reward the sum of the rewards of
the states in the path. If sis such that Steps (s) =Dist(S),
the overall cumulated reward for sis given by the weighted
sum w.r.t.Dist(s)of the path cumulated rewards for the
paths starting from s. However, this quantity becomes an
interval because of the non-deterministic transitions. Indeed,
all the non-deterministic choices have associated a cumulative
rewards. To represent all these alternatives, each state sis
annotated with the interval hminR (s);maxR (s)iin which
all the non deterministic cumulative rewards are comprised.
These values are computed as follows. If sis a ﬁnal state,
minR (s) =(s), instead, if s2S F, whenSteps (s) =
f(s1;p1);:::; (sk;pk)g, i.e., the transitions outgoing from
sform a probability distribution, minR (s) =Pk
j=1pj
minR (sj), and, when Steps (s) =fs1;:::;s mg, i.e., the
transitions outgoing from srepresent a non deterministic
choice,minR (s) = min i2f1;:::;mgminR (si). If one of the
paths on which the cumulative reward is computed contains
loops, the above equations recall themselves recursively. Iter-
ative numerical methods are used to solve these equations.
The termination condition of such methods is obtained by
checking when the maximum difference of the solutions from
successive iterations drops below a ﬁxed threshold. The upper
bound of the interval, maxR (s), is computed analogously. A
comprehensive in-depth treatment of MDPs be found in [1].42