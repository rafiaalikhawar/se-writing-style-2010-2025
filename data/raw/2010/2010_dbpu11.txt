Synthesis of Live Behaviour Models for Fallible Domains∗
Nicolás D’Ippolito†+Victor Braberman+Nir Piterman‡Sebastián Uchitel†+
†Imperial College London
London, United Kingdom
su2@imperial.ac.uk+Universidad de Buenos Aires,
Buenos Aires, Argentina
{ndippolito, vbraber }@dc.uba.ar‡University of Leicester,
Leicester, United Kingdom
{np183@le.ac.uk
ABSTRACT
We revisit synthesis of live controllers for event-based op -
erational models. We remove one aspect of an idealised
problem domain by allowing to integrate failures of con-
troller actions in the environment model. Classical treat-
ment of failures through strong fairness leads to a very high
computational complexity and may be insuﬃcient for many
interesting cases. We identify a realistic stronger fairne ss
condition on the behaviour of failures. We show how to
construct controllers satisfying liveness speciﬁcations under
these fairness conditions. The resulting controllers exhi bit
the only possible behaviour in face of the given topology of
failures: they keep retrying and never give up. We then
identify some well-structure conditions on the environmen t.
These conditions ensure that the resulting controller will be
eager to satisfy its goals. Furthermore, for environments
that satisfy these conditions and have an underlying prob-
abilistic behaviour, the measure of traces that satisfy our
fairness condition is 1, giving a characterisation of the ki nd
of domains in which the approach is applicable.
Categories and Subject Descriptors
D.2 [Software Engineering ]
General Terms
Design, Algorithms
Keywords
controller synthesis, behavioural modelling
1. INTRODUCTION
We are interested in the automated construction of op-
erational event-based models from speciﬁcation of intende d
∗This work was partially supported by grants ERC PBM-
FIMBSE, CONICET PIP955, UBACYT X021, and PICT
PAE 2272.
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and the full citation on the ﬁrst page. To cop y otherwise, to
republish, to post on servers or to redistribute to lists, re quires prior speciﬁc
permission and/or a fee.
ICSE ’11, May 21–28, 2011, Waikiki, Honolulu, HI, USA
Copyright 2011 ACM 978-1-4503-0445-0/11/05 ... $10.00.system behaviour. This topic has been the subject of exten-
sive study in the software engineering community. Consider
for example the research on synthesis from scenario-based
(e.g. [27, 2]) and declarative (e.g. [17]) speciﬁcations. T he
aim is to provide an operational model that will support
requirements elicitation and analysis. Analysis techniqu es
may include model checking, simulation, animation and in-
spection (aided by automated slicing and abstraction).
Behaviour model synthesis is also used to automatically
construct plans that are then enacted by a software compo-
nent. For instance, synthesis of glue code and component
adaptors has been studied. The main aim of these stud-
ies has been to achieve safe composition at the architec-
ture level, and in particular in service oriented architect ures
(e.g. [13]). Also, there has been an increasing interest in a p-
plications toself-adaptivesystems[10, 26]. Allthesesys tems
rely heavily on controller synthesis techniques [24]. Such
techniques guarantee the satisfaction of safety and even li ve-
ness [22] requirements. The proposed solutions work within
theconstraintsenforcedbytheproblemdomain, thecapabil -
ities oﬀered by the self-adaptive system, and under fairnes s
and progress assumptions on the controller’s environment.
Recently, we suggested an approach for synthesis [6] in the
context of discrete event systems. Our work emphasises the
importance of explicit distinction, in controller synthes is,
between controlled and monitored actions [19] and between
descriptive and prescriptive behaviour [14]. We also pro-
vided appropriate methodological guidelines.
One of the limitations of existing synthesis techniques is
that they are designed to work in the context of idealised
problem domains. Situations in which the outcome of con-
troller actions are notguaranteedare dealtwith byassumin g
thatcontroller actionsneverfail (e.g. [6]), bynot-consi dering
liveness goals (e.g. [13, 26]), or by building controllers t hat
aim to be live but are not guaranteed to be so [10]).
In this paper we propose a technique for synthesising live
behaviour models in the context of problem domains in
which controlled actions can fail. The technique adapts and
extends our previous work on synthesis of controllers for di s-
crete event systems [6]. A key insight is the identiﬁcation
of a realistic fairness condition, strong independent fairness ,
which allows for a polynomial treatment of failures. In con-
trast, the complexity of the general problem is exponential .
Speciﬁcally, we consider models in the form of Labelled
Transition Systems (LTS). We distinguish controllable fro m
uncontrollable actions. In addition, some controllable ac -
tions have associated actions that constitute a success or a
failure. The synthesis problem calls for the construction o f amodel that when composed with its environment satisﬁes a
given speciﬁcation in FLTL [9]. The FLTL formulas we con-
sider have the form GI∧(/logicalandtextn
i=1GFAi→/logicalandtextm
j=1GFGj),
whereGIis a safety system goal, GFAirepresents a live-
ness assumption on the behaviour of the controller’s envi-
ronment, and GFGjmodels a liveness goal for the system.
The expressions AiandGjare non-temporal ﬂuent expres-
sions [9]. The system safety goal, I, is expressed as a Fluent
Linear Temporal Logic formula. We assume strong inde-
pendent fairness of the successes and failures with respect
to certain assumptions on the environment. Intuitively, th e
strong independent fairness condition states that every fa il-
ure and every assumption must occur fairly (inﬁnitely often
ifenabled inﬁnitelyoften) butalso independentlyofall ot her
failures and assumptions and of the state of the environment
and the controller. In other words, failures and assumpti-
ons cannot be coordinated. They must be “controlled” by
diﬀerent agents which must be oblivious to each other.
Technical contributions of this paper include (i)a discus-
sion of the fairness conditions required for problem domain s
with failures. In particular the observation that strong fa ir-
ness [8] of successful controlled actions may be insuﬃcient
to guarantee that reasonable controllers are synthesised; (ii)
novel fairness conditions, i.e. t-strong fairness and stro ng
independent fairness that are stronger than strong fairnes s
and are good ﬁts for realistic controller synthesis setting s,
(iii)the deﬁnition of a polynomial time LTS control prob-
lem, named RSGR(1) that supports safety and GR(1)-like
liveness properties; (iv)the restrictions that an environment
model requires in order to guarantee correctness of the syn-
thesis procedure and to avoid controllers that fulﬁll their
speciﬁcation by trivialising it (i.e. anomalous controlle rs);
and(v)a proof that if the environment can be thought
of as a grounding of a probabilistic environment with non-
zero probabilities on transitions, then the traces that are
not strong independent fair have probabilistic measure zer o,
thus providing a characterisation of the domains in which
our approach can be applied.
The paper is organised as follows. In Section 2 we mo-
tivate and present an overview of the approach. Section 3
includes the necessary background. In Section 4 we present
the technique for synthesising LTS controllers in the pres-
ence of failures: in subsection 4.1 we discuss the notion of
fairness required for the proposed controller synthesis te ch-
nique; in subsection 4.2 we formalise the control synthesis
problem that handles domains with failures and discuss how
it can be solved eﬃciently; in subsection 4.3 we discuss the
problem of anomalous controllers and how to avoid them;
and in subsection 4.4 we present a probabilistic argument to
show that behaviour that is not strong independent fair is
irrelevant in the context of our synthesis approach. Finall y,
we report on case studies, discussion, related work and con-
clusions. Proofs can be found in [5].
2. MOTIV ATION
In this section we discuss motivation for our approach.
Technical details are provided in the next sections.
Considerthefollowing simpliﬁedscenario: Atravelagency
wants to sell vacation packages on-line by orchestrating ex -
isting web-services for ﬂight purchase, car hire and hotel
booking. We want an automated or semiautomated tech-
nique for building the agency’s orchestration , based on the
known usage protocols for individual services and on the2
3
1 4
5 6car.query
car.reserve
car.paycar.resetcar.query.failedcar.query.succ
car.reserve.succcar.reserve.failed
car.pay.failedcar.pay.succ
Figure 1: Car Booking Service.
agency’s own requirements for the provision of packages.
An example of what the protocol for a car rental web-
service is the one depicted in Figure 2. The service requires
a query with information on dates, car type, and other pref-
erences (car.query ). The service can either respond with a
list of items satisfying the speciﬁed criteria ( car.query.succ )
or with not-found ( car.query.failed ). Subsequently, if a list
is retrieved, a particular item can be reserved ( car.reserve )
or the process can be aborted ( car.reset ). Reservation can
fail (car.reserve.failed ) or succeed ( car.reserve.succ ). In
the latter case, payment is enabled ( car.payment ) and can
succeed (car.payment.succ ) or fail (car.payment.failed ).
The web-service protocols for hotel and ﬂight bookings
will typically be similar to that of car rentals: a sequence
of actions is required to progress towards a purchase and a
number of problems may arise, which lead to the failure of
these actions (no ﬂights, communication errors, insuﬃcien t
funds, etc.). Without loss of generality, the protocol for
hotel and ﬂight bookings is analogous to that for cars with
actions such as flight.query andhotel.reserve.succ .
The problem for the travel agency orchestration is to co-
ordinate the individual services in order to provide a cohe-
sive comprehensive vacation package web-service. For in-
stance, it must attempt to avoid booking hotel and car
for a customer when no ﬂights are available for the de-
sired dates. Such a requirement can be formalised, for in-
stance, in temporal logic as I1=G(∀srv∈Services ·
TryToBuy (srv)⇒AllReserved ). Another requirement,
if the agency is charged for reservations, might be not to
reserve before all queries have returned viable items: I2=
G(∀srv∈Services ·TryToReserve (srv)⇒AllFound ).
The agency should coordinate the services to achieve its
own requirements. It should do that while following the pro-
tocols of the services and deal with the various failures tha t
may occur. For instance, if a failure occurs when reserving
a ﬂight, then the Flight service must be re-queried; but if
the result of the new query returns notFound then reserva-
tions for car and hotel must be cancelled (and the user may
consider a diﬀerent holiday).
Finally, thetravelagencyorchestration mustbelive. That
is, it must actually succeed in providing package holidays.
Of course this depends on actually having requests pend-
ing to be processed. Such a requirement should be for-
malised distinguishing the assumptions on the environment
(A1=GFPendingPackageRequests ) and prescriptions
on the orchestration ( G1=GFpackage.deliver ). We re-
quire that if the environment satisﬁes A1then the orches-
tration will satisfy G1.
We distinguish between the travel agency’s controlled and
monitored actions (double and single lines in ﬁgures, respe c-
tively). Actionssuchas car.query ,car.reset ,flight.reserve ,
andhotel.payment are controlled by the orchestrator for the
travel agency while the rest are monitored. With such dis-
tinction we apply controller synthesis. We attempt to pro-duce a controller such that, when interacting with the Car,
Flight andHotelservices, will achievesafety (e.g. I1,I2)and
liveness (e.g. G1) under relevant assumptions (e.g. A1).
Unfortunately, our previous approach [6] cannot produce
controllers that guarantee such goals. This is quite reason -
able as for achieving such a goal, the controller must rely on
a number of domain assumptions. For instance, it cannot be
the case that queries, reservations and payments always fai l.
Under such assumptions it would seem feasible to construct
a controller for the travel agency: the controller would hav e
to retry actions in the case of failures knowing that after
some number of reattempts it will succeed1. The assump-
tion mentioned (if the controller tries often enough, it wil l
eventually succeed) is a typical fairness condition someti mes
referred to as strong fairness [8]. Strong fairness is not su p-
portedbypolynomial timealgorithms suchas [6]. Itrequire s
exponential algorithms such as [7]. It could be argued that
many exponential worst case algorithms are well-behaved
in practice. Unfortunately, this is not the case here. The
best case complexity of all known algorithms that deal with
strong fairness is exponential [21]. More precisely, the si ze
of the controller is always N×k! whereNis the size of the
environment model and kis the number of strong fairness
conditions. The best time complexity of all known algo-
rithms isNk×k!. Again, the k! factor is never reduced. In
other words, unlike symbolic model checking in which many
practical settings are not worst case, here space and time
blow up in every reasonable sized example.
Interestingly, strong fairness assumptions on success of
queries, reservations andpaymentsare insuﬃcienttoachie ve
thegoals. The(strongfair) behaviourinwhichfailures “ta ke
turns” would prevent achieving the goal. Consider the sce-
nario in which the controller ﬁrst queries a car successfull y
and then fails querying for a hotel. The controller must re-
set the car service and re-query for cars and hotels. But
now the hotel query succeeds and the car query fails forcing
the controller to reset the hotel service, and so on. Thus, a
synthesis algorithm relying on strong fairness would decla re
that no controller realising this goal exists.
In conclusion, it would seem possible to build a reason-
able orchestration of theservices towards achievingthego als
of the travel agency. However, non-trivial assumptions on
the environment behaviour are required to guarantee such
goals are achieved by a reasonable controller. This lays out
two research questions. Firstly, how can an orchestration
for the travel agency be constructed automatically and sec-
ondly,what are the required assumptions , which will enable
to guarantee the goals.
In Section 4 we present a technique for automatically syn-
thesising controllers for settings such as the travel agenc y.
We handle cases where the environment can exhibit failures
to controller actions, and show what are the environment
assumptions required for such controllers to succeed.
3. BACKGROUND
In this section we present background for controller syn-
thesis in the context of event-based operational models. We
assume the problem domain for which a controller is to be
built is described as a labelled transition system.
1Notethateveninthissimpleexampleretryingisnottrivial .
For example, if a payment fails it is necessary to re-query
and re-reserve before re-attempting to pay.Definition 3.1. (Labelled Transition Systems) ALabel-
led Transition System (LTS) isP= (S, L,∆, s0), whereS
is a ﬁnite set of states, L⊆Actis itscommunicating alpha-
bet,∆⊆(S×L×S)is a transition relation, and s0∈Sis
the initial state. We denote ∆(s) ={s′|(s,a,s′)∈∆}. We
say an LTS is deterministic if (s,ℓ,s′)and(s,ℓ,s′′)are in
∆impliess′=s′′. An execution of Pis a words0,a0,s1,...
where(si,ai,si+1)∈∆. A wordπis trace ofPif there is
an execution εofPsuch thatε|L=π. We deﬁne tr(P)to
deﬁne the set of traces of P.
We describe speciﬁcations (e.g. the prescriptions for con-
troller) using Fluent Linear Temporal Logic (FLTL) [9].
Linear temporal logics (LTL) are widely used to describe
behaviour requirements [9]. FLTL is a linear-time tem-
poral logic for reasoning about ﬂuents. A ﬂuentﬂ is de-
ﬁned by a set of initiating actions Ifl, a set of terminat-
ing actions Tfl, and an initial value Initially fl. That is,
fl=/a\}bracketle{tIfl,Tfl/a\}bracketri}htinitiallyfl, whereIfl,Tfl⊆ActandIfl∩Tfl=
∅.When we omit Initially fl, we assume the ﬂuent is ini-
tiallyfalse. We use ˙ℓas short for the ﬂuent deﬁned as
fl=/a\}bracketle{tℓ,Act\{ℓ}/a\}bracketri}ht.
Given the set of ﬂuents Φ, an FLTL formula is deﬁned in-
ductively using the standard boolean connectives and tem-
poral operators X(next) and U(strong until) as follows:
ϕ::=fl| ¬ϕ|ϕ∨ψ|Xϕ|ϕUψ, wherefl∈Φ. We
introduce ∧,F(eventually), and G(always) as usual.
Let Π be the set of inﬁnite traces over Act. Forπ∈Π,
we writeπifor the suﬃx of πstarting at ai. The suﬃx πi
satisﬁes a ﬂuent fl, denotedπi|=fl, if and only if one of
the following conditions holds:
-Initiallyfl∧(∀j·0≤j≤i⇒aj/∈Tfl)
-∃j·(j≤i∧aj∈If)∧(∀k∈N·j<k≤i⇒ak/∈Tfl)
The problem of controller synthesis can be expressed as
follows: Given an LTS model Eof the environment, a set of
controllable actions Lc, assumptions Asiand goalsGiex-
pressed in FLTL, build an LTS Msuch that when composed
in parallel with E(i.e.E/bardblM), the controller does not block
all non-controlled actions in the environment and for every
trace ofE/bardblMif the trace satisﬁes the assumption Ai, then
the trace also satisﬁes the goal Gi.
We use a standard deﬁnition of parallel composition [12].
The parallel composition is the LTS that models the asyn-
chronous execution of composed models. It interleaves non-
shared actions and forces synchronisation on shared action s.
The notion of a controller that does not block the actions
of the environment that it does not control is built on that
oflegal environment for Interface Automata [3]. Intuitively,
it says that Mis a legal environment for Eif in every state
(m,e) ofM/bardblEwheremandeare states of MandEre-
spectively, if an action anot controlled by Mis enabled in
ethen it is also enabled in ( m,e).
Definition 3.2. (LTS Control) Given a speciﬁcation for
a problem domain in the form of an environment LTS E, a
set of controllable actions Lc, and a setHof pairs(Asi,Gi)
whereAsiandGiare FLTL formulas specifying assumpti-
ons and goals respectively, the solution for the LTS control
problem L=/a\}bracketle{tE,H,L c/a\}bracketri}htis to ﬁnd an LTS Mwith controlled
actionsLcand uncontrolled Lcsuch thatMis a legal en-
vironment for E,E||Mis deadlock free, and for every pair
(Asi,Gi)∈Hand for every trace πinM||Ethe following
holds: ifπ|=Asithenπ|=Gi.The problem with using FLTL as the speciﬁcation lan-
guage for assumptions and goals is that the synthesis prob-
lem is 2EXPTIME complete [23]. Nevertheless, restrictions
on the form of the goal and assumptions speciﬁcation have
been studied and found to be solvable in polynomial time.
For example, goal speciﬁcations consisting uniquelyofsaf ety
requirements can be solved in polynomial time, and so can
particular styles of liveness properties such as GR(1) [22] .
We have presented an adaptation of GR(1) in the context
of LTS in [6]. It is deﬁned as follows:
Definition 3.3. (SGR(1) LTS Control) An LTS control
problem L=/a\}bracketle{tE,H,L c/a\}bracketri}htis SGR(1) if Eis deterministic, and
H={(∅,I),(As,G)}, whereI=Gρ,As=/logicalandtextn
i=1GFφi,
G=/logicalandtextm
j=1GFγj, andρ,φiandγjare Boolean combina-
tions of ﬂuents.
4. SYNTHESIS FOR FALLIBLE DOMAINS
We now present a technique for synthesising controllers
even when their environment exhibits failures. In Subsec-
tion 4.1 we discuss the notion of fairness required for the
proposed controller synthesis technique. In Subsection 4. 2
we formalise the control synthesis problem and discuss how
it can be solved eﬃciently. We then discuss in Subsec-
tion 4.3 the problem of anomalous controllers and how to
avoid them, and ﬁnally in Subsection 4.4 we present a prob-
abilistic argument to show that non-fair environment be-
haviour is irrelevant in many realistic settings.
Note that the examples in this section are simplistic and
with obvious solutions to allow conveying the main issues
involved in controller synthesis in domains with failures.
4.1 Fair Environments
We consider controller synthesis in the context of environ-
ments that exhibit failures. We call this setting synthesis
with failures . We present examples showing that fairness of
failures and successes is both necessary and subtle. A mali-
cious environment typically cannot be controlled to achiev e
the goals. However, we propose realistic fairness assumpti -
ons that allow for controllers that behave as expected, i.e. ,
do not give up and keep retrying.
ConsiderE, the simple environment model in Figure 2,
where a ceramics cooking process is described. The aim of
the controller is to produce cooked ceramics by taking raw
pieces from the in-tray, placing them in the oven and mov-
ing them once cooked to a conveyor belt. A natural solution
for such a problem is to attempt to build a controller (using
SGR(1)) with a liveness goal G=GF ˙moveToBelt and an
assumption A=GF¬˙cooking. Note that the assumption
Ais required to ensure that the controller’s environment
progresses when cooking ceramics; without the assumption
no controller can guarantee production of ceramics. Indeed ,
a controller for this trivial problem is the one that chooses
tocookrather than be idle, and is constructed automat-
ically by solving the SGR(1) problem sg1=/a\}bracketle{tE,H,L c/a\}bracketri}ht,
whereH={(A,G)}andLc={idle,cook,moveToBelt }.
The solution to sg1is a controller Mthat (composed with
E) produces inﬁnitely many cooked pieces if the oven ﬁn-
ishes cooking inﬁnitely often (i.e. E/bardblM|=GFAimplies
E/bardblM|=GFG).
A slight twist to the ceramics cooking problem is the sce-
nario in which some pieces may break during cooking. The
reasons for why the pieces may break (e.g. impurities in the12
3idlecook
moveToBeltfinishedCooking
cooking
Figure 2: Ceramic Cooking Process.
1 2 34
56
cookidle
moveToBeltcookmoveToBelt
fix
cook
finishedCooking
cookingbroken
not.broken
Figure 3: Failing Ceramic Cooking Process ( E2).
ceramics, heat stability in oven, etc) are abstracted in the
model (Figure 3). Such abstraction of the causes for failure
is a common approach to behaviour modelling of problem
domains. The assumption is not that the controller’s envi-
ronment chooses whether the piece breaks, rather that the
choice is made by a number of factors that are beyond the
scope of the model.
We distinguish failures from other actions as follows. For
each control problem we deﬁne a set of try-response triples.
Such a triple captures the relation between controlled ac-
tions and their success or fail reactions. Note that we re-
quire 1) the “try” action to be controlled, 2) all actions in a
try-response triple to be unique with respect to other tripl es
in the set, 3) re-tries cannot occur before a response, 4) re-
sponses can only occur as a result of a try, 5) maximum of
one response occurs for everytry, and 6) thedecision of whe-
ther to fail or succeed cannot be enforced by other actions,
hence failure is enabled if and only if success is enabled.
Definition 4.1. (Try-Response) Given anLTS M =
(SM, LM,∆M, sM0), whereLC⊆LM, we say that a set
T={(tryi, suci, faili)}is atry-response set forMif the
following hold for all i:
1.tryi∈LC, suci,faili∈L\LCandsuci/\e}atio\slash=faili,
2.For allj/\e}atio\slash=i,{tryi,suci,faili}∩{tryj,sucj,failj}=∅,
3.¬(˙faili∨˙suci)W˙tryi,
4.G(˙tryi=⇒X(¬˙tryiW(˙faili∨˙suci))),
5.G((˙faili∨˙suci) =⇒X(¬(˙faili∨˙suci)W˙tryi)), and
6. For alls∈SM,failiis enabled from siﬀsuciis
enabled from s.
We returntothe ceramics cooking problem andadd afailure
to it. Consider the model of Figure 3 with the try-response
setT={(cook,not.broken,broken )}. The controller for
this problem is required to accomplish two things. First, to
produce cooked pieces and place them on the conveyor belt.
Second, to ensure that only unbroken pieces are placed on
the belt while broken pieces are ﬁxed and re-cooked.
A naive attempt to build a controller for the modiﬁed
problem simply adds a safety goal S=G ˙moveToBelt⇒ ¬Broken tosg1, whereBroken is a ﬂuent deﬁned as
/a\}bracketle{tbroken,cook/a\}bracketri}ht. In other words, attempting to solve sg2=
/a\}bracketle{tE2,H,Lc/a\}bracketri}ht, whereH={(∅,S),(A,G)}.
Unfortunately, sg2does not have a solution. Furthermore,
in general, there is no controller that will work if the envi-
ronment is malicious. A controller cannot succeed if its en-
vironment breaks all ceramics. In other words, for a contro-
ller to produce cooked unbroken ceramics we must assume
that if enough pieces are cooked, one will eventually not
break. Thatis, thattheresponse totrying cookisnotalways
the failure broken. This could be a reasonable assumption
for the problem domain. Another attempt at automatically
building a controller could be to strengthen the assumption
Ainsg2to beA′=GF¬˙cooking∧GF ˙not.broken . This
leads tosg3=/a\}bracketle{tE2,H,Lc/a\}bracketri}ht, whereH={(∅,S),(A′,G)}.
The problem with sg3is that it admits as a solution a
controllerMwhich only does idle. This is because by never
performing cook, the assumption A′and more speciﬁcally
GF ˙not.broken does not hold. Hence, the controller has
no obligation to achieve G. Formally, E2/bardblM|=GFAim-
pliesE2/bardblM|=GFGholds ifE2/bardblM/\e}atio\slash|=GFA. Clearly,
A′is not a reasonable assumption for the controller’s en-
vironment. The environment depends on the controller to
achieveA′. Or in van Lamsweerde’s terms [16], the assump-
tion is not realisable by the controller’s environment. As
we show in [6], unrealisable assumptions, in addition to not
following best practices in Requirements Engineering, can
lead to controllers that satisfy their goals vacuously. Jus t
like the controller that always idles in our example satisﬁe s
its speciﬁcation vacuously (see also Subsection 4.3).
In order to introduce an assumption that is realisable by
the controller’s environment, we must state that if pieces a re
cooked inﬁnitely often, not.broken is taken inﬁnitely often
(i.e.GF˙cook⇒GF ˙not.broken ). However, this condi-
tion amounts to requiring strong fairness [8] of not.broken
actions which cannot be encoded in SGR(1). Althoughmore
general controller synthesis techniques can deal with stro ng
fairness [7], these take the algorithmic complexity of syn-
thesis from polynomial (the SGR(1) case), to exponential.
Moreover, sometimes strongfairnessisnotsuﬃcientlystro ng
for synthesising controllers in simple, yet common, proble m
domains. This is shown in the next example.
Consider another variation of the ceramic cooking prob-
leminwhichpiecesmustbecookedtwicebeforebeingmoved
to the conveyor belt. A controller for such a problem will
need to “remember” how many successful consecutive cook’s
have occurred. Requiring strong fairness on try-response
triples ofT={(cook,not.broken,broken )}is insuﬃcient
to allow the construction of a controller that achieves its
goals. There is no controller that can deal with the case
in which pieces break at least once every two consecutive
attempts to cook them. For instance, consider Ma poten-
tial controller for the problem (Figure 4). It is possible to
construct a strongly fair trace by always succeeding in the
ﬁrst cook (taking the not.broken transition from state 3)
but always failing after the second cook (taking the broken
transition in state 7). If an inﬁnite number of cookare tried
thenGF˙cook⇒GF ˙not.broken holds, yet the controller
never succeeds in placing a twice cooked unbroken piece on
the conveyor belt.
The above example shows that a stronger notion of strong
fairness is required. Informally, it should state that ever y in-
dividual attempt to cook should be treated fairly. That is,2 3 5
1 4 8
9 7 6cookidle
fixcook
cook
moveToBeltfinishedCookingcooking
brokennot.broken
finishedCookingcooking
not.brokenbroken
Figure 4: Ceramics cook-twice controller.
attempting ﬁrst cook of a piece (transition from 1 to 2 in
Figure 3) inﬁnitely often should yield an inﬁnite number
of non broken once-cooked pieces (transition 3 to 5) and
attempting a second cook of a piece (transition 5 to 6) in-
ﬁnitely often should yield an inﬁnite number of non broken
twice-cooked pieces (transition 7 to 9).
This stronger notion of fairness is in fact tightly coupled
with the structure of the environment and controller be-
haviourmodels. Whatisneededisthatforeveryglobal state
(a state ofE2/bardblM), if a cook on that state is attempted in-
ﬁnitely often then the cooking process will not fail inﬁnite ly
often. An alternative intuition is that the decision whe-
ther to fail the cooking process should be fair and be taken
independently of state of the environment model or the con-
troller. In the two-cooks-a-piece example, the decision to
fail the second cook of a piece process should be fair and
independent of the ﬁrst cookon the same piece.
The following deﬁnition captures this stronger notion of
fairness. It requires that for every transition labelled wi th a
try, if it is taken inﬁnitely often then inﬁnitely often success
occurs before another try.
Definition 4.2. (t-strongfairness) Given an LTS Mand
a try-response TforM. A traceπ∈tr(M)ist-strong fair
with respect to MandTif for all (tryi,suci,faili)∈Tand
for all transitions t= (s,tryi,s′)the following holds: π′|=
GFtry′
i⇒GF(¬tryiUsuci), whereπ′=ε′|LM∪{try′
i},
ε′=ε|[s.tryi.s′/s.try i.try′
i.s′], andεis an execution of Msuch
thatε|LM=π.
Note thatw|Ais the projection of word wover the alpha-
betA, andw[v/v′]is the result of replacing in word wall
occurrences of word vwithv′.
One issue remains regarding the fairness conditions that
are relevant to enable automated synthesis with failures.
Consider the synthetic example in Figure 5. In this ex-
ampletryis the only controlled action, ( try,succ,fail ) the
only try-response triple, ℓis an arbitrary event, and Gand
Arepresent goals and assumptions respectively. The trace
try,success,ℓ,try,fail,A,try,success,ℓ,... is an example
of a trace that satisﬁes strong fairness and t-strong fairne ss,
the assumptions hold inﬁnitely often and yet the goal is
never achieved. Note that no controller could prevent this
trace astryis the only controlled action. The trace shows
some peculiar behaviour: the environment never chooses to
take the assumptions on state 3, and it can do so because it
relies on the fact that it fails sometimes and through failin g
achieves its assumptions.
Although contrived, the example shows that the assump-
tions and failures can be systematically combined to make a
controller unsuccessful: the environment can avoid assump -
tions when actions succeed (state 3 in Figure 5) and achieve
assumptions when actions fail (state 5). However, a nat-
ural expectation is that the assumptions on the environ-1 234
5trysucc
failℓ
AA
G
Figure 5: t-strong fairness is not enough.
ment should be independent of failures; particularly be-
cause the choice of failure or success is understood as non-
deterministic given that it abstracts the actual cause for
failure and success.
If required to construct a controller for Figure 5 what
should the controller do? Naturally, the controller should
keep taking tryhoping that eventually assumptions are not
coordinated with failures. A synthesis algorithm that only
assumes strong fairness or even t-strong fairness would say
that this is impossible and fail to produce a controller. Our
goal is then to come up with a setting in which such a con-
troller would be automatically generated by the synthesis
algorithm. In order to do so we formalise the notion that
assumptions and failures must be independent.
We formalise that assumptions and failures must be in-
dependent of each other in the following way. We restrict
traces of interest tothose thatsatisfy that assumptions mu st
be attainable inﬁnitely often without seeing failures. Or
more precisely, if the controller tries often enough, then n ot
only will it succeed but also it will succeed and all assump-
tions are fulﬁlled. That is, if assumptions and failures are
truly independent, trying often enough guarantees that at
some pointafter atry, nofailures will occur untilall assum p-
tions are satisﬁed.
Definition 4.3. (StrongIndependentFairness) Given an
LTSM, a try-response TforMandAa set of FLTL for-
mulas. A trace π∈tr(M)isStrong Independent Fair with
respect toAif for all (tryi,suci,faili)∈Tand for all tran-
sitiont= (s,tryi,s′)the following holds: π′|=GFtry′
i⇒
GF((¬tryiUsuci)∧(/logicalandtextn
i=1(¬(/logicalortextn
j=1failj)WAi))), where
π′=ε′|LM∪{try′
i},ε′=ε|[s.tryi.s′/s.try i.try′
i.s′], andεis an
execution of Msuch thatε|LM=π.
In the next subsection we formalise the control problem
with the fairness discussed above. We show that this prob-
lem can be solved eﬃciently by encoding it into the SGR(1)
control problem. The encoding relies on strong independent
fairness. Finally, as further motivation, we reason about
domains that are considered as probabilistic (with non-zer o
probabilities on all transitions). We show that in such do-
mains, if the environment is well structured, then the prob-
abilistic measure of traces that do not satisfy this fairnes s
conditions (andconsequentlythetraces for whichcontroll ers
have no obligations) is zero.
4.2 Recurrent Success Control Problem
We now formalise the recurrent success control problem .
For traces that are strong independent fair, it guarantees
general safety and liveness properties, which are GR(1)-li ke.
We extend the SGR(1) control problem we deﬁned in [6] by
introducing failures and expectations on the fairness of th e
environment.
Definition 4.4. (Recurrent Success) Given an SGR(1)
LTS control problem L=/a\}bracketle{tE,H,L C/a\}bracketri}htand a try-response TforL, the solution for the Recurrent Success control prob-
lemR=/a\}bracketle{tL,T/a\}bracketri}htis to ﬁnd an LTS Msuch thatMwith
controlled actions Lcand uncontrolled actions Lcis a le-
gal environment for E,E||Mis deadlock free, and for ev-
ery pair (Asi,Gi)∈H, for every (tryi,suci,faili)and for
strong independent fair trace πinM||Ethe following holds:
ifπ|=Asithenπ|=Gi.
Notice the requirementof independencebetween decisions
onwhentofail andwhentoachieveassumptions. Thisis key
to the tractable treatment of RSGR(1) problems: RSGR(1)
can be reduced to a SGR(1) problem leading to more eﬃ-
cient algorithms than those needed to solve strong fairness
in general.
Theorem 4.1.GivenR=/a\}bracketle{tL,T/a\}bracketri}htan RSGR(1) control
problem, it holds that there exists an SGR(1) control proble m
Ssuch that Ris realisable iﬀ Sis realisable. Furthermore,
the controller extracted from Scan be used to control R.
The reduction can be explained in two steps: RSGR(1)
can be solved by constructing a controller for an alternativ e
control problem named Finitely Many Failures (FMF). So-
lutions for FMF control problems construct controllers tha t
guarantee GFGon a trace if on the same trace GFAsi
holds and also a ﬁnite number of failures occur (i.e. FG
¬/logicalortext
jfailj). An FMF problem can be coded as an SGR(1)
problem where the goal is GF(G∨/logicalortext
jfailj).
The key to the coding of RSGR(1) into FMF is the strong
independent fairness requirement, and in particular what i t
adds on top of t-strong fairness: if a try-transition is taken
inﬁnitely often, then not only will it succeed inﬁnitely oft en
but also that inﬁnitely often no failures will be observed (f or
thattryor any other action that can potentially fail) until
all assumptions have occurred.
We sketch the proof that every solution to FMF is a so-
lution to RSGR(1). Suppose, by way of contradiction, that
Mis an FMF-controller that is not an RSGR(1)-controller.
Thentheremustbeastrongindependentfair trace πinE/bardblC
that satisﬁes the assumptions inﬁnitely but not the goals. I n
πthere must be an inﬁnite number of failures (otherwise it
would be a counter-example to Mbeing an FMF controller)
and hence there must be at least one try-transition taken
inﬁnitely often. As πis strong independent fair, the try-
transition must be successful and inﬁnitely often no failur es
occur before assumptions occur. Hence, there is cycle cov-
ered byπin which no failures occur, all assumptions do
occur and goals are not achieved. This cycle can be used
to construct a trace in E/bardblMwhich has ﬁnitely many faults
and in which goals are not achieved even though assumpti-
ons hold. This contradicts that Mwas assumed to be an
FMF-controller.
We give an alternative intuition of why RSGR(1) can be
reduced to FMF. In FMF the controller knows that at some
point there will be no more failures but does not know at
which point this will happen. It follows that its strategy is
toreattempt knowingthat eventuallyall its attempts will b e
successful. The same strategy works for RSGR(1). Indeed,
because of strong independent fairness, it may be the case
that failures are infrequent enough and non-systematicall y
occurring. In such cases eventually all the successes neede d
to achieve the goals will occur “consecutively” (i.e. with n o
failures occurring before reaching the goal).
The MTSA tool set[4] implements RSGR(1).1 23
456
78
try1 try2suc1
fail1G
Asuc2
fail2A
G
ℓ
Figure 6: Environment E.
4.3 Anomalous Controllers
Anomalous controllers, as we deﬁned in [6], are an impor-
tant issue to consider in the context of automatic controlle r
synthesis. Intuitively, an anomalous controller tries to d is-
charge its obligation of achieving goals by preventing the
environment from fulﬁlling its own obligations.
Werevisit theissue ofanomalous controllers for RSGR(1).
In RSGR(1) the controller may discharge its obligation to
achieve goals by either preventing assumptions from occur-
ring or by forcing non strong independent fair traces.
The following deﬁnition of best eﬀort controller extends
that of [6] for domains with failures. It states that a con-
troller for an RSGR(1) problem is best eﬀort if it prevents
inﬁnitely many occurrences of assumptions and strong in-
dependent fair traces “as least as possible”. That is, every
other controller prevents these cases as much as the best ef-
fort one or more. Informally, the deﬁnition states that for
every point at which it is no longer possible to satisfy the
assumptions inﬁnitelyoften or itis notastrongfair indepe n-
dent trace, the same would occur for every other controller.
Definition 4.5. (Best-Eﬀort Controller) LetRSbe an
RSGR(1) LTS control problem with assumptions As. We
say that a solution MforRSis abest eﬀort controller for
RSif for all ﬁnite traces σ∈traces(E/bardblM)such that for
allσ′whereσ.σ′∈traces(E/bardblM), we haveσ.σ′|= (¬/logicalandtextn
i=1
G FAi)orσ.σ′is not strong independent fair, then for
all other solutions M′toRSsuch thatσ∈traces(E/bardblM′),
everyσ′′such thatσ.σ′′∈traces(E/bardblM′)eitherσ.σ′′|=
(¬/logicalandtextn
i=1GFAi)orσ.σ′′is strong independent fair.
Consider the RSGR(1) LTS control problem R=/a\}bracketle{tL,T/a\}bracketri}ht
whereL=/a\}bracketle{tE,H,L c/a\}bracketri}ht, whereEis the LTS in Figure 6,
Lc={try1,try2,G},H={(As,Gs)},As=GF˙Aand
Gs=GF˙G. The controller enabling only try1, is a valid
controller for Rbut it forces the environment to fulﬁl its
assumptions by failing, while the controller enabling only
try2is also a valid controller for Rbut it doesn’t force the
environment to a place in which the only possibility to fulﬁl
its assumptions is by failing. Such a controller is more de-
sirable and is what we expect from a Best Eﬀort Controller
in the context of Recurrent Success control problems.
Notethat Rsatisﬁes thebesteﬀortconditiondeﬁnedin[6]
for SGR(1) but not the one above for RSGR(1).
In [6] a suﬃcient condition for ensuring best eﬀort is de-
ﬁned. It essentially dictates that it must be possible for
the environment to fulﬁll its assumptions regardless of how
a controller behaves. In the context of domains with fail-
ures and RSGR(1), this condition is not suﬃcient. For
RSGR(1), we must require that the environment be able
to achieve its assumptions independently of how the con-
troller behaves and how decisions on failures occur. The
assumptions-compatibility deﬁnition that follows is iden ti-
cal to that of [6] except that the set of controlled actions is
extended with failure actions. The deﬁnition states that th e
assumptions are compatible if there is no controller that ca nprevent assumptions from happening even when controlling
failures.
Definition 4.6. (Assumptions Compatibility) Given an
RSGR(1) LTS control problem R=/a\}bracketle{tL,T/a\}bracketri}ht, whereL=/a\}bracketle{tE,
H,Lc/a\}bracketri}htandH={(∅,I),(As,G)}, we say that the Asis
compatible with Eaccording to T, if for every state sin
Ethere is no solution for the SGR(1) LTS control problem
/a\}bracketle{tEs,H′,Lc∪F/a\}bracketri}ht, whereH′={(∅,I),(As,false)}, andEsis
the result of changing the initial state of EtosandFis the
set of allfailiinT.
It is straightforward to see that the environment Ein Fig-
ure 6 is not assumptions compatible with A. A controller M
which never takes try2norfail1forcesE/bardblMto not satisfy
GFA, whichmeans that thecontroller has noobligation of
satisfyingfalse. Hence, there is a solution for the problem
/a\}bracketle{tE,H,L c∪F/a\}bracketri}ht, whereH′={(∅,true),(A,false)}.
Similarly to [6], the assumptions-compatibility conditio n
is related to the deﬁnition of best eﬀort controller. Intu-
itively, if the domain is such that the environment can pro-
duceall itsassumptions withoutrequiringtheuseof failur es,
then every controller is best eﬀort.
Theorem 4.2.Given an RSGR(1) LTS control problem
R=/a\}bracketle{tL,T/a\}bracketri}htwith environment model Eand assumptions As,
ifAsis assumptions compatible with Eaccording to Tthen
all solutions to Rare best eﬀort controllers.
Proof. Refer to [5].
The theorem above is applicable for Ein Figure 6 since
Eis not assumptions compatible with A; in eﬀect, there are
non best eﬀort controllers for E. However, the orchestration
problem discussed in Section 2 is assumptions compatible,
thetheoremappliesandallsolutions totheRSGR(1)orches-
tration problem are best eﬀort. The environment for the or-
chestration problem is assumptions compatible because the
assumption A1requires there be package requests pending
to be processed inﬁnitely often. A controller (controlling
failures too, as in Deﬁnition 4.6) cannot impede the environ -
ment from achieving the assumptions because failures will
simply delay package processing and while a package is be-
ing processed that package is pending. On the other hand,
once the controller has processed the package, it is blocked
until a new package arrives. Hence, the environment is free
to deliver a new package request, which becomes pending
and which fulﬁls A1.
4.4 Unsupported Traces
In the previous subsection we discussed assumptions com-
patibility. Underthisconditionacontrollercannotdisch arge
obligations by either forcing assumptions not to occur or by
forcing strong independent fairness not to hold. However,
even in the case of satisfying the assumptions-compatibili ty
condition, the environment may still choose not to satisfy
strongindependentfairness. Clearly, for suchtraces thec on-
troller is not obligated to satisfy the goals. Consequently ,
applicability of our techniqueseverely depends on howmany
or how relevant are the traces in which goals are not neces-
sarily achieved?
More concretely, consider the example in Figure 5. As-
sumptionAis compatible with theenvironment. Thus, solu-
tions tothe control problem are guaranteed to be best eﬀort.
Consequently, a controller that repeatedly attempts tryis a
good controller: it does not trytoachieveits goals vacuous lyand succeeds in achieving its goals for all strong indepen-
dent fair traces. However, the trace try,success,ℓ,try,fail,
A,try, success,ℓ,... is not strong independent fair. Hence
the controller is not obliged to, and in fact does not, satisf y
its goals. How good is this controller? How relevant is it
that the controller does not achieve its goals for this trace ?
Are there other traces for which the controller’s obligatio ns
are discharged and how relevant are they?
We consider this question in contexts where the environ-
ment can be thought of as a probabilistic model in which
all transitions (or at least non-failing ones) have non-zer o
probability. We show that if we restrict our attention to
assumptions-compatible environments, then the measure of
the set of paths in which the environment progresses but the
controller has no obligations is zero. That is, when working
with assumptions-compatible models, the traces for which
the controller does not achieve the goals are negligible.
Consider an environment Efor an RSGR(1) problem R
that can be seen as an abstraction of a Markov Decision
Process [1] (MDP) Ep. It is possible to show that if Eis
assumptions compatible with respect to the assumptions of
Rthenthemeasure ofpathsthatarenotstrongindependent
inEpis zero. More formally:
Theorem 4.3.Given an RSGR(1) problem Rwith an
assumptions-compatible environment E, and an MDP Ep
such that the underlying LTS Ep↓is simulation equivalent
toEthen, for every controller M, for every fair scheduler
sofEpconsistent with M, the following holds: the measure
of the setB={π|πis a trace of Epunder scheduler sand
πmatches a trace of Ethat satisﬁes assumptions inﬁnitely
often but is not strong independent fair in M||E}is zero.
Proof. Refer to [5].
For instance, the MDP Epin Figure 7 is a model of the
Ceramic Cooking problem. It is straightforward to see that
the grounding of Ep(i.e.Ep↓) is simulation equivalent to
the LTSE2of Figure 3. In addition, E2is assumptions com-
patible with A=¬cooking as the only way of not achieving
theassumption isbyperforming cooking, whichis controlled
by the environment. So, by Theorem 4.3, controllers to the
RSGR(1)problemwith environment E2, assumption A, goal
moveToBelt , try-response triple ( cook,broken,not.broken )
and safety moveToBelt ⇒Cooked Twice ∧¬Broken are
besteﬀortandachievethegoals withprobabilityone. Trace s
that are not strong independentfair (e.g. if a piece is broke n
at least once in every two cooks) are negligible.
Consider now the orchestration problem of Section 2. Its
environment is compatible with the assumptions on pending
package request. The question to ask now is if the problem
domain can be thought of as an MDP for the theorem above
to be applicable. This amounts to validating if the envi-
ronment’s choices can be thought of as probabilistic choice s
over some memoryless probabilistic distribution. All choi ces
of the environment are related to failures: Queries on avail -
ability of cars, hotels and plains can fail; reservations on
these can fail; and so can payments. Modelling each query
failure/success as an independentprobabilistic choice en tails
the following. Either resources are transiently unavailab le
(e.g. cars of a certain model eventually become available)
or users will vary their criteria reasonably (e.g. making it
less restrictive) in order to succeed in queries. Hence, The o-
rem 4.3 is not free. Requiring an MDP model of the domain
means that the denotation of, for instance, failures must be4 8
6
1 2 10 3
9
7 5cookidle
cookingfinishedCooking env envbroken
not.brokenmoveToBeltcookmoveToBelt
fixcook 1
1
1−pp
11p1
1−p
111
111
Figure 7: MDP for Ceramic Cooking Problem.
compatible with probabilistic choice. In many setting such
a denotation is possible and realistic, as with the orchestr a-
tion problem, but this is not necessarily the case. If, for
instance, payment failure denotation includes failures du e
to incorrect program logic in one of the services, then as-
suming probabilistic behaviour of these failures may not be
valid. For example, the logic may be such that it consis-
tently fails once every npayments of the same client, where
nis the number of services that a package includes.
Summarising, Theorem 4.3 shows that the restriction to
strong independent fair paths is not severe if the problem
domain can be modelled probabilistically.
5. CASE STUDIES
In this section we report on a number of case studies. We
evaluate the applicability of our approach and the beneﬁts i t
provides with respect to existing synthesis techniques. Th e
case studies are taken from existing literature on behaviou r
model synthesis. Applicability is evaluated based on the fo l-
lowing criteria i) is RSGR(1) applicable to the case study
as described in the literature, ii) is RSGR(1) applicable to
richer versions, which introduce domain relevant failures .
Beneﬁts with respect to existing techniques is evaluated ba -
sed oni) the ability to generate controllers automatically,
ii) the guarantees provided by the resulting controller, and
iii) the degree of idealisation of the problem domain. For
the controller synthesis tool and all case studies, includi ng
the orchestration problem of Section 2, see [4].
Production Cell. In [6] we presented a control problem ba-
sed on the Production Cell [18]: a robotic arm coordinates
the application of various tools to construct a product fulﬁ ll-
ing some safety and liveness requirements. The liveness re-
quirement is that inﬁnitely many products are constructed.
The assumption is that if the controller is waiting for piece s
to construct a new product, it eventually receives them.
Both the original problem formulation and that of [6] take
an idealised view of the problem. They assume that all con-
trollable arm actions succeed. For instance, it is possible to
order an arm to lift a piece from the conveyor belt, and it
is assumed that this always succeeds. We reﬁned the prob-
lem in order to account for failed arm movement actions.
We deﬁne a set of try-success triples of the form ( put.tool i,
tooli.succ,tooli.fail) modelling the action of placing a piece
to be processed by tool iand the possible success or failure
of the action. The resulting model is a compatible envi-
ronment (see Deﬁnition 4.6) for the following assumption:
if the controller is waiting for pieces the environment pro-
vides then. Hence, the RSGR(1) problem is guaranteed to
produce a best eﬀort controller (see Theorem 4.2).
It could be argued that we model failures to our advan-
tage in order to obtain a compatible environment. However,
we ﬁnd it very natural that failures and assumptions (in
this case) are independent. Notice that failures can occuronly when the controller is busy working on existing pieces.
Hence, it would be impossible to “not satisfy” assumptions
when failures occur.
Another possible criticism could be that strong indepen-
dent fair traces are not suﬃcient in this domain. However,
for instance, suppose that failures are abstracting imprec i-
sion of arm movements. In such a case, arms miss the target
location for loading or unloading due to traction problems.
It is reasonable to assume that the imprecision measured in
millimetres is amemory-less randomvariable. Hence, failu re
would be related to the imprecision being above a certain
threshold. Consequently, the probability of a failure is in de-
pendent of the global state of the environment, that of the
controller, and of the history of previous failures.
Consider a denotation of failures such as the one above.
By Proposition 4.3 the traces for which the controller pro-
vides no guarantees have probabilistic measure zero. Obvi-
ously, if the failure denotes also the possibility of the arm
breaking or getting permanently stuck, then the measure of
such traces is not zero. In fact, under such scenarios no
controller could achieve its production goals (unless anot her
action repair or get-unstuck is added).
Pay & Ship. Pistore et al. synthesise a plan for composing
distributed web services and monitoring them [20]. More
speciﬁcally, a web-service coordinates purchase requests by
buying on a furniture-sales service and booking a shipping
service. The case study includes these failures: Both the
furniture-sales and shipping services may respond positiv ely
or negatively to a request by the controller-to-be.
The controller synthesised in [20] gives no guarantees that
the goal of satisfying purchase requests is achieved. In fac t,
achieving the goals stated in [20] requires assuming progre ss
on the environment and fairness conditions on the success
of operations on the furniture-sales and shipping services .
We modelled this case study as an RSGR(1) problem. In
our setting, it is possible to check that the model is a com-
patible environment with respect to the following assump-
tions. First, that the purchase requests occur inﬁnitely of -
ten. Second, that customers conﬁrm inﬁnitely many prod-
ucts and delivery options. Thus, the resulting controller i s
guaranteed to be best-eﬀort. Furthermore, the environment
assumptions under which it achieves its goals are explicit.
Finally, the probabilistic argument of Section 4.4 is appli ca-
ble: If failures are assumed, for instance, to be a result of
lack of periodically renewed resources (no stock of selecte d
furniture or no delivery trucks available at the moment of
request). If, on the other hand, failures denote the applica -
tion of a commercial policy related to the characteristics o f
the purchase, then a probabilistic argument may not apply.
Clearly, users of our technique have to analyze its adequacy
for their speciﬁc problem. They have to understand the
implications of assuming strong fair independece on traces
and the implications of deploying a service which does not
provide guarantees in these cases.
Autonomous Vehicles. Weconsider therobotics case study
originally presented in [11]. It presents a disaster recove ry
scenario in which a robot must travel within a collapsed
house taking supplies to people trapped in one of the rooms.
Inadditionanumberofobstacles mayintermittentlyimpede
movement of the robot. The synthesis algorithm presented
in [11] considers two types of failures as a result of move-
ments of the robot: i) the robot does not get to expected
position after moving, for instance due to roughness of theterrain, and ii) the package is dropped, as a result, for in-
stance, of sharp movements of the robot. The goal of the
controller is toget tothetarget location with supplies. Ho w-
ever, there is no guarantee that the controller achieves thi s
goal.
The environment model, as presented in [11], assumes the
following. First, the robot is loaded with supplies inﬁnite ly
often. Second, intermittent obstacles disappear inﬁnitel y of-
ten. We ﬁnd that the environment is compatible with these
assumptions. Thus, posing this case study as RSGR(1) pro-
duces a controller that is guaranteed to achieve its goals fo r
strong independent fair traces. Furthermore, if failures d ue
tomovementattempts areconsidered tobeindependent(i.e.
that the rubble may compromise an attempt at moving, but
that the robot does not encounter an unsurmountable (un-
modelled) obstacle such as a wall); and if the loss of supplie s
has a probability lower than one, then strong independent
fair traces have a probabilistic measure of one.
Note that in [6] an adaptation of the case study is pre-
sented. Due to the limitations of the technique in dealing
with failures, either failures must be restricted or remove d
altogether, or if fully speciﬁed, the technique reports tha t
no controller can be built.
Bookstore. We consider the web-service composition sce-
nario in [13], which structurally resembles Pay & Ship. Sim-
ilarly to Pay & Ship, two services are to be coordinated to
provide a more complex service. The diﬀerence is that no
explicit liveness properties are stated. Furthermore, an i de-
alised version of the services is provided in which no failur es
can occur. The introduction of failures to this problem re-
sults in a problem that is, in essence, the same as Pay &
Ship and which our approach can deal with.
6. DISCUSSION AND RELATED WORK
Our work builds on that of the controller synthesis com-
munity and particularly on the generalised reactivity syn-
thesis algorithm GR(1) [22]. In [6], we revisit GR(1) and
adapt it to a message passing communication model, rather
than for a shared memory model. The message passing
model matches the paradigm in behaviour modelling and
analysis in software engineering (e.g. requirements engin eer-
ing and architectural design). Speciﬁcally, in [6] a contro ller
synthesis algorithm, SGR(1), is studied for LTS and CSP-
like parallel composition [12]. In particular, we provided a
sound methodological approach to the deﬁnition of assump-
tions in order to avoid anomalous controllers. The techniqu e
presented herein extends both the controller synthesis alg o-
rithms and methodological deﬁnitions of [6] to account for
domains with failures.
Although numerous behaviour model synthesis techniques
have been studied (e.g. [2]) these are restricted to user-
deﬁned safety requirements. The exceptions that we are
aware of relate to the self-adaptive systems and planning.
Sykes et al. build plans for reachability (a limited form
of liveness) goals [26]. In their setting, the execution of t he
plan is restarted every time the environment behaves un-
expectedly. Hence there is an implicit assumption that the
environment behaves “well enough” for the system to even-
tually reach the goal state. As “well enough” is not deﬁned,
it is not clear what guarantees are provided by the resulting
plans. More generally, planning as model checking [10] sup-
ports CTL goals for kripke structures. Thus, the problemof environment-controller composition, distinction betw een
controllable and monitored actions and realizability are n ot
considered. In addition, as with [26], when failures are sup -
ported, there are noguarantees as to when goals are actually
achieved by plans.
In [13] the problem of constructing an adaptation strategy
is studied. However, it is limited to enforcing safety prop-
erties and uses a backward error propagation technique [25]
to construct controllers. The lack of explicit live conditi ons
makes failures and fairness conditions irrelevant.
Finally, our work is heavily inﬂuenced by the work on re-
quirements engineering by Jackson [14] van Lamsweerde [16]
and Parnas [19]. They have argued the importance of dis-
tinguishing between descriptive and prescriptive asserti ons,
between software requirements, system goals and environ-
ment assumptions, and the key role that the latter play in
the validation process.
7. CONCLUSIONS
We have presented a controller synthesis technique for
event-based operational models. Our technique supports
a restricted, yet expressive, form of liveness. It conforms
to foundational requirements engineering best practices: (i)
it makes explicit the assumptions on the environment be-
haviour and (ii) distinguishes between controlled and mon-
itored actions. Our technique integrates failures, allowi ng
less idealised environment models. In order to handle fail-
ures we introduce explicit fairness conditions that are re-
quired to guarantee controller goals. We provide method-
ological guidelines for providing well constructed assump ti-
ons, which are in line with standard realisability notions.
We show that these guidelines guarantee controllers that
are eager to satisfy goals and avoid discharging obligation s
by invalidating environment assumptions. Furthermore, fo r
environments that satisfy these guidelines and have an un-
derlying probabilistic behaviour, the measure of traces th at
satisfy our fairness condition is 1. This gives further evi-
dence to the usefulness of these guidelines.
A key aspect of our technique is that, unlike general con-
troller synthesis techniques, it remains within polynomia l
complexity. WerestrictuserstowritespeciﬁcationinGR(1 ),
which has beenused in complex problem settings such as au-
tonomous vehicles [15]. The fairness condition required in
our technique is crucial to reducing the problem to SGR(1)
andthenGR(1). Thetradeoﬀ betweenalgorithmic complex-
ity and expressiveness is captured by strong independent
fairness. Informally, strong independent fairness requir es
environments not to orchestrate failure occurrences and sa t-
isfaction of assumptions. As shown in discussions and case
studies, there are relevant problem domains in which envi-
ronments have such characteristics. In particular, there a re
problem domains where environment choices can be charac-
terised by memoryless probabilistic choices, which make ou r
technique even more appealing.
8. REFERENCES
[1] R. Bellman. A Markovian decision process. Journal of
Mathematics and Mechanics. , 6:679–684, 1957.
[2] Y. Bontemps, P. Schobbens, and C. L
”oding. Synthesis of open reactive systems from
scenario-based speciﬁcations. Fundamenta
Informaticae , 62(2):139–169, 2004.[3] L. de Alfaro and T. A. Henzinger. Interface automata.
InProceedings of the 8th European software
engineering conference held jointly with 9th ACM
SIGSOFT international symposium on Foundations of
software engineering , ESEC/FSE-9, pages 109–120,
New York, NY, USA, 2001. ACM.
[4] N. D’Ippolito, D. Fischbein, M. Chechik, and
S. Uchitel. MTSA: The modal transition system
analyser. In 23rd IEEE/ACM International
Conference on Automated Software Engineering, 2008.
ASE 2008 , pages 475–476. ACM, 2008.
[5] N. R. D’Ippolito. Technical Report.
http://www.doc.ic.ac.uk/ srdipi/tech.
[6] N. R. D’Ippolito, V. Braberman, N. Piterman, and
S. Uchitel. Synthesis of live behaviour models. In
Proceedings of the eighteenth ACM SIGSOFT
international symposium on Foundations of software
engineering , FSE ’10, pages 77–86, New York, NY,
USA, 2010. ACM.
[7] E. Emerson and C. Jutla. The complexity of tree
automata and logics of programs. In Proc. 29th
Symposium on Foundations of Computer Science .
IEEE, 1988.
[8] N. Francez. Fairness. Texts and Monographs in
Computer Science. Springer-Verlag, 1986.
[9] D. Giannakopoulou and J. Magee. Fluent model
checking for event-based systems. In Proceedings of the
9th European software engineering conference held
jointly with 11th ACM SIGSOFT international
symposium on Foundations of software engineering ,
ESEC/FSE-11, pages 257–266, New York, NY, USA,
2003. ACM.
[10] F. Giunchiglia and P. Traverso. Planning as model
checking. In Proc. 5th European Conference on
Planning , volume 1809 of Lecture Notes in Computer
Science, pages 1–20. Springer-Verlag, 2000.
[11] W. Heaven, D. Sykes, J. Magee, and J. Kramer. A
Case Study in Goal-Driven Architectural Adaptation.
Software Engineering for Self-Adaptive Systems , 2009.
[12] C. Hoare. Communicating sequential processes.
Communications of the ACM , 21(8):677, 1978.
[13] P. Inverardi and M. Tivoli. A reuse-based approach to
the correct and automatic composition of
web-services. In International workshop on
Engineering of software services for pervasive
environments: in conjunction with the 6th ESEC/FSE
joint meeting , page 33. ACM, 2007.
[14] M. Jackson. The world and the machine. In
Proceedings of the 17th international conference on
Software engineering , pages 283–292. ACM New York,
NY, USA, 1995.
[15] H. Kress-Gazit, D. Conner, H. Choset, A. Rizzi, and
G. Pappas. Courteous Cars: Decentralized Multiagent
Traﬃc Coordination. IEEE Robotics and Automation
Magazine on Multi-Agent Robotics , 15(1):30–38, 2008.
[16] A. V. Lamsweerde. Goal-oriented requirements
engineering: A guided tour. Requirements Engineering,
IEEE International Conference on , 0:0249, 2001.
[17] E. Letier, J. Kramer, J. Magee, and S. Uchitel.
Deriving event-based transition systems from
goal-oriented requirements models. Autom. Softw.
Eng., 15(2):175–206, 2008.[18] C. Lewerentz and T. Lindner, editors. Formal
Development of Reactive Systems - Case Study
Production Cell , volume 891 of Lecture Notes in
Computer Science . Springer, 1995.
[19] D. L. Parnas and J. Madey. Functional documents for
computer systems. Science of Computer Programming ,
25(1):41 – 61, 1995.
[20] M. Pistore, F. Barbon, P. Bertoli, D. Shaparau, and
P. Traverso. Planning and monitoring web service
composition. Artiﬁcial Intelligence: Methodology,
Systems, and Applications , pages 106–115, 2004.
[21] N. Piterman and A. Pnueli. Faster solutions of Rabin
and Streett games. In Logic in Computer Science,
2006 21st Annual IEEE Symposium on , pages
275–284. IEEE, 2006.
[22] N. Piterman, A. Pnueli, and Y. Sa’ar. Synthesis of
reactive (1) designs. Lecture notes in computer
science, 3855:364–380, 2006.
[23] A. Pnueli and R. Rosner. On the synthesis of a
reactive module. In Proceedings of the 16th ACM
SIGPLAN-SIGACT symposium on Principles of
programming languages , pages 179–190. ACM New
York, NY, USA, 1989.
[24] P. Ramadge and W. Wonham. The control of discrete
event systems. Proceedings of the IEEE , 77(1):81–98,
1989.
[25] S. Russell and P. Norvig. Artiﬁcial intelligence: a
modern approach. New Jersey , 1995.
[26] D. Sykes, W. Heaven, J. Magee, and J. Kramer.
Plan-directed architectural change for autonomous
systems. In Proceedings of the SAVCBS 2007 , pages
15–21. ACM New York, NY, USA, 2007.
[27] S. Uchitel, G. Brunet, and M. Chechik. Synthesis of
partial behavior models from properties and scenarios.
IEEE Trans. Software Eng. , 35(3):384–406, 2009.