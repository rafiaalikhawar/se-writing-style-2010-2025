See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/306395147
Staged Concu rrent Program Analysis
Conf erence Paper  · No vember 2010
DOI: 10.1145/1882291.1882301  · Sour ce: doi.acm. org
CITATIONS
50READS
283
2 author s, including:
Chao W ang
Univ ersity of Southern Calif ornia
190 PUBLICA TIONS    4,261  CITATIONS    
SEE PROFILE
All c ontent f ollo wing this p age was uplo aded b y Chao W ang  on 23 A ugust 2016.
The user has r equest ed enhanc ement of the do wnlo aded file.StagedConcurrent Program Analysis
Nishant Sinha, Chao Wang
NEC Labs America, Princeton, NJ,USA.
{nishants,chaowang}@nec-labs.com
ABSTRACT
Concurrent program veriﬁcation is challenging because it i nvolves
exploring a large number of possible thread interleavings t ogether
with complex sequential reasoning. As a result, concurrent pro-
gram veriﬁers resort to bi-modal reasoning, which alternat es be-
tweenreasoning over intra-thread(sequential) semantics and inter-
thread (concurrent) semantics. Such reasoning often invol ves re-
peatedintra-threadreasoningforexploringeachinterlea ving(inter-
threadreasoning)andleadstoinefﬁciency. Inthispaper,w epresent
a new two-stage analysis which completely separates intra- and
inter-thread reasoning. The ﬁrst stage uses sequential pro gram se-
mantics to obtain a precise summary of each thread in terms of
the global accesses made by the thread. The second stage per-
forms inter-thread reasoning by composing these thread-mo dular
summaries using the notion of sequential consistency. Asse rtion
violations and other concurrency errors are then checked in this
compositionwiththehelpofanoff-the-shelfSMTsolver. We have
implemented our approach in the FUSION framework for check-
ingconcurrentCprogramsshowsthatavoidingredundantbi- modal
reasoning makes the analysis more scalable.
Categories, Subject Descriptors: D.2.4 [Software/Program Veri-
ﬁcation]: Model Checking, FormalMethods.
General Terms: Algorithms, Veriﬁcation.
Keywords: Thread-modularSummarization,InterferenceAbstrac-
tion, Interference Skeleton, Staged Analysis, Sequential Consis-
tency, Axiomatic Composition, SMTsolvers.
1. INTRODUCTION
Checking properties of shared memory based concurrent pro-
gramsstaticallywithmodelcheckingisexpensivebecausei tamounts
toexploringlargenumberofinterleavingsoftheconcurren tthreads.
Methodsoftenamelioratethiscostbyusingpartialorderte chniques[5,
14, 11] and causal orderings imposed by synchronization pri m-
itives, e.g., locks. Unfortunately, most of the methods, wh ether
explicit[5,14,11]orsymbolic[29,13,21,20,34],resortt oredun-
dantbi-modal reasoning: theanalysis alternates betweenreasoning
over theintra-thread and the inter-thread semantics. For example,
consider twoconcurrent threads T1andT2asfollows:
T1: (x:= 3;t:=x;a:=t+ 1;b:=a+ 3;assert (b>4); )
T2: (x:= 5;)
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and thefull citation on the ﬁrstpage. Tocop y otherwise, to
republish, topostonserversortoredistribute tolists,re quires priorspeciﬁc
permission and/or afee.
FSE-18,November 7–11, 2010, Santa Fe,New Mexico, USA.
Copyright 2010 ACM 978-1-60558-791-2/10/11 ...$10.00.ThethreadT1containsanassertion (b>4);tocheckthisassertion,
variousinterleavingsof T1andT2mustbeconsidered(inter-thread
reasoning), based on when the statement (x:= 5)inT2is exe-
cuted. Oncethevalue of xisobtained(x∈ {3,5}), thestatements
(t:=x;a:=t+ 1;b:=a+ 3)inT1are composed via intra-
threadreasoningtochecktheassertion. Bi-modalreasonin gofthis
form is inherently wasteful because the analysis engine is f orced
to perform reasoning over similar intra-thread program reg ions re-
peatedly. Intra-thread (or thread-modular) program summa rization
is a possible solution to this problem. However, classical p rogram
summarization methods [31, 30] designed for sequential pro grams
are not applicable in a concurrent setting because of interf erences
onshared locations from concurrent threads.
In this paper, we present a stagedconcurrent analysis, which
avoids redundant bi-modal reasoning. The ﬁrst stage (summa riza-
tion) consists of a new algorithm to summarize the individua l pro-
gram threads in the presence of concurrency. The summary is r ep-
resented in form of an interference skeleton , which is a partially-
orderedsetofallglobalreadandwriteaccessesofprogramt hreads.
The second stage performs composition symbolically by enco ding
feasiblelinearizations of the above partial order using a sequen-
tial consistency (SC) criterion [1] on the global accesses. Finally,
we check property violations by using an SMT solver [9, 8] whi ch
searches fora linearizationthat violates the property. No te thatbe-
cause the two stages perform either intra- or inter-thread r eason-
ing, we achieve a complete separation between intra- and int er-
thread reasoning, and thus avoid costly bi-modal alternati on be-
tweenthem.
The key idea behind summarization in the ﬁrst stage is that of
interference abstraction : any read access to a shared memory lo-
cation (global read) in the program is abstracted by a fresh s ym-
bolicvariable. Thesefreshvariables(linearinthenumber ofreads)
model arbitraryinterference tothe sharedlocationvia wri tesinthe
same or aconcurrent thread. Interference abstraction, ine ffect,en-
ables thread-local summarization, while assuring us that t he inter-
ferences due to concurrent writes can be taken into account l azily
and preciselyinthe subsequent composition stage.
The second stage linearizes the skeleton by linkingthe read ac-
cesses with appropriate write accesses in the skeleton. Axiomatic
composition (AC) provides a natural way to do this (as oppose d
to introducing an explicit scheduler), i.e., we can use the s equen-
tial consistency (SC) axioms [1], speciﬁed in ﬁrst-order lo gic, to
enforce that the linearization corresponds to a feasible co ncurrent
program trace. AC has been employed to check consistency of
concurrent data structures under relaxed hardware memory m od-
els (e.g., [2]). In contrast, we propose to employ AC in the ne w
setting of high-level static analysis of concurrent progra ms. In this
setting, it is sufﬁcient to consider only the SC model of exec ution
for performing high-level static analysis (as opposed to mo re re-
laxedmodels). ThecentralproblemishowtoencodeSCefﬁcie ntly
to obtain a scalable analysis. To this goal, we propose a meth odtopruneredundant SC constraints by analyzing the interference
skeleton computed inthe ﬁrststage.
OurstagedanalysishandlesarbitraryconcurrentCprogram s(e.g.,
usingPthread libraries) using pointers and arrays with the help
of a precise memory representation [4]. As opposed to most co n-
current analyses, program threads need not be demarcated be fore-
hand; ouranalysishandles threadcreationanddestruction natively.
Analysisofgeneralrecursiveprogramsevenwithﬁnitedata isknown
to be undecidable. To analyze arbitrary C programs over inﬁn ite
data types, we transform the input programs to their structurally
bounded versions, where loops and recursive functions in the in-
put program are unrolled to a ﬁxed depth. Finite unrolling of this
form indirectly ﬁnitizes the number of threads, and also ﬁxe s the
size of heap that the bounded program mayaccess. Asa result, the
analysis of bounded programs becomes decidable.
WehaveimplementedourapproachintheFUSIONframework[34 ]
for veriﬁcation of concurrent C programs. Preliminary eval uation
showthatsummarizationandoptimizationsduringcomposit ionare
essential for scalable symbolic analysis of concurrent pro grams.
The key contributions of this paper are asfollows:
•A staged analysis algorithm for verifying concurrent pro-
grams consisting of (Stage 1) a precise thread-modular sum-
marization of individual threads, and (Stage 2) an optimize d
composition step over the summary using sequential consis-
tency axioms, followed by checking assertion violations us -
ingan SMTsolver.
•A thread-modular data ﬂow analysis based on interference
abstractiontosummarizestructurally-boundedconcurren tpro-
grams inform of aninterference skeleton.
•Optimized composition of the interference skeleton by sys-
tematically pruning redundant SC constraints between the
global accesses by staticanalysis of theskeleton.
1.1 Redundant bi-modal reasoning
Thread 1(T1) Thread2(T2)
1 ...
2 S1: a0 = x;
3 a1 = a0 + 1; z1 = a1;
4 a2 = a1 + 1; z2 = a2;
5 ...
6 a99 = a98 + 1; z99 = a99;
7 a100 = a99 + 1;
8 S2: x = a100;1 S3: x = 0;
2 ...
3 S4: x = 5;
4 ...
5 A: assert (x == 5
6 || x >= 105);
Consider the fragments of concurrent threads T1andT2shown
above; thevariables a0−a100arelocal,andtherest( x,z1−z99)
areshared; our goalistochecktheassertion Aatline5.T1andT2
may interleave in many possible ways; an efﬁcient analysis b ased
onsay,partialorderreduction[5,11]willconsiderarepre sentative
set of such interleavings, and compute the value of xat the asser-
tionA. Analyzingeachinterleavingamountstobi-modalreasonin g
whichalternates betweenintra- andinter-threadreasonin g. Forex-
ample, consider the interleaving S3-S4-S1-S2-A: the analy sis ﬁrst
considersT2, settingxto3and5at S3and S4successively (intra-
threadreasoning),andthenswitchesto T1(inter-threadreasoning),
successively computing a0−a100,z1−z99andx(intra-thread),
and ﬁnally, switches back to T2to checkAusing the computed
value ofx. This form of bi-modal reasoning is redundant , since
similarintra-threadreasoningisrepeatedforeachinterl eavingcon-
sidered. For example, note that a100 = (a0 + 100) irrespective
of the interleaving of T1andT2considered. However, to analyze
another interleaving, say S3-S1-S4-S2-A, the values a1−a100
must berecomputed becausea0 = 0now as opposed to a0 = 5
in the previous interleaving. Redundant intra-thread reas oning (or
composition) takes itstollonbothexplicit[5, 14, 11,36] a ndsym-
bolic [13, 21, 20, 34] analysis techniques, often decreasin g theirperformance by an order of magnitude. Although summarizati on
techniques are well-known for sequential program analysis [31,
30], they cannot be directly employed here: because of inter fer-
ence [26] onsharedlocations byconcurrent threads, the val ue read
from a shared location in a thread may not be the same as the pre -
vious value writtentothe locationinthe same thread.
There exist techniques that ameliorate this problem by collaps-
inga set of intra-thread transitions into a single one, e.g., pa th
reduction [36]. However, they can only collapse transition s in-
sidetransactions , i.e.,regions withoutanyconcurrent interference.
Givenatransactionbetweenlocations l1andl2,pathreductioncol-
lapses all the transitions between l1andl2to a single transition.
Unfortunately, these techniques are not effective across a rbitrary
program regions or transactions. In the above example, assi gn-
ments to shared variables z1−99represent locations where inter-
ference may occur, which alternate with assignments to vari ables
a0−a100. Therefore, pathreduction methods cannot collapse the
assignments toinfer that a100 = (a0 + 100).
Our method avoids this problem by using the idea of interfer-
ence abstraction, which, in turn, enables data-ﬂow based su mma-
rization. First, the value of shared variable xread at line 2inT1
is abstracted by a fresh symbolic variable, say r0. Since the as-
signments to variables a1−a100are not inﬂuenced by any other
interferences,ourdata-ﬂowpropagationsuccessfullycom putesthat
a100 =r0+ 100. Further, our method precisely summarizes all
localcontrolanddataﬂowintermsofglobalaccesses,e.g., assign-
menttoz1atline 3inT1givesrisetoaglobalaccessevent Z1with
valueval(Z1) =r0+ 1. Similarly,global accesses Z2−Z99are
computed withtheir relativeorder ( Z1≺Z2≺Z3...).
Lal and Reps [21] present address this problem in the setting of
context-bounded analysis (CBA) of programs with ﬁnite-dom ain
variables (extended to C programs in [20]). In CBA, a concur-
rent program is analyzed assuming only a ﬁxed number of conte xt
switches occur between threads. Context-bounding allows ﬁ xinga
set of context switch (CS) locations and model the interfere nce at
theCSlocationsonly. Thisisdone by guessing(orabstracting)the
value of the global state at each CS location. Since no interf erence
is possible between each pair of CS locations in a thread and t he
number of CS locations is ﬁnite, sequential summarization c an be
applied between each CS location pair. Guessing the global s tates,
however, involves unnecessary duplication of the shared state at
eachCSlocation. Thisisbecauseeachprogramlocationmaym od-
ifyonlyafewsharedvariables,andhenceitisextremelyine fﬁcient
toduplicate allshared variables at everylocation.
For example, the method [21] will duplicate all the global va ri-
ables (z1−z99,x) at all locations in thread T1and compute
summaries between all pairs of locations. This summarizati on is
quadratic in the number of thread locations and the global va ri-
ables and incurs a high overhead. Further, in the improved la zy
algorithm[21], thesummariescannot bereusedacross multi plein-
terleavings if the global state at a CS location is different across
interleavings, which causes redundant bi-modal reasoning . Incon-
trast,our method avoids bi-modal reasoning and the number o f the
global access events as well as the fresh variables introduc ed in
our summaries is linear in the number of shared variable acce sses,
thusenablingapracticalanalysis. Moreover,itispossibl etoobtain
CBAas aspecial casebyﬁxingthecontext bounds inour analys is.
2. OVERVIEW
CCFGs. We represent concurrent programs in form of concurrent
controlﬂowgraphs(CCFGs),whichcanbeviewedasanextensi on
of control ﬂow graphs (CFGs) for sequential programs to conc ur-
rentprograms. ACCFG= (V,E),consists of asetofnodes Vand
a set of edges E. Each edge in Eis labeled by a guard condition
ganda (possibly empty) setof assignments of form (lhs:=rhs).
Intuitively, the assignments are executed iff the guard con ditionholds. The set of nodes Vcontains two special nodes FORK and
JOIN, to model thread creation and termination, respective ly: a
FORK (JOIN) node has a single incoming (outgoing) edge, and
multiple outgoing (incoming) edges. Individual program th reads
are modeled as sub-graphs of the CCFG. Function calls are mod -
eled inthe standard way [31] withcall and return edges label ed by
assignments toparameters andreturnvariables respective ly.
Synchronizationconstructs,e.g.,mutex,conditionvaria bles,etc.,
aremodeledusingsharedvariables. Forexample,acquiring locklk
inthreadTiis modeled as anedge withguard (lk==0)andassign-
ment(lk:=i). Instantaneous test-and-set primitives are modeled
by marking the corresponding sub-graphs of the CCFG as atomic,
which are referred toas atomic regions. The assertions inth e orig-
inal program are transformed into error nodes while constructing
the CCFG; assertion checking reduces to checking if there ex ists a
feasible interleaving of concurrent thread paths in the CCF G that
terminates at the error node. We distinguish the two kinds of join
locations in the CCFG: the intra-thread joins occur due to path
merging inside a thread, while the inter-thread join corresponds to
the JOIN nodes. Anexample ispresented inthe next section.
Read and Write Accesses. We refer to each read or write to a
memory locationas a read or write access respectively. A mem ory
locationlissaidtobesharedifmorethanonethreadreadsorwrites
tol. In the following, we will mainly concern with accesses to
shared memory locations, called global accesses . Each global ac-
cesseis represented using a symbolic tuple (loc,val,occ ), where
loc(e)andval(e)correspondtothememorylocationandthevalue
that is read/written during the access e, andocc(e)is the neces-
sary condition for eto occur. A global access e1is said to inter-
ferewith another global access e2if one of them is a write and
loc(e1) =loc(e2)is satisﬁable. Note that every usage of the
phrase ‘globalaccess’inthispaperisimplicitlyidentiﬁe dwiththis
tuple representation (loc,val,occ ).
A Motivating Example. Consider the multi-threaded C program
based on the Pthread library shown in Fig. 1(a) . The program
contains a single shared variable x. Two threads are created from
the main thread, which read and write x. Fig. 1(b) shows the cor-
responding concurrent control ﬂow graph (CCFG). In the CCFG ,
FORK and JOIN represent thread creation and termination poi nts.
TheCCFGconsistsofsub-graphsforthreethreads,main(nod es:1,
FORK, Join, 10, ERR),t1(nodes: 2-9) andt2(nodes: 2'-9').
Forbrevity,wehavemergedmultipleconsecutive FORKandJO IN
nodes into a single node. Moreover, new assignments have bee n
added to ensure that each statement makes at most one global ac-
cess. Fig. 1(b) also shows the global accesses in the CCFG: W1,
W2,W3,W2′,W3′aretheglobalwrites,while R1,R2,R3,R1′,
R2′,R3′,R4are the global reads. Let us see how our stagedanal-
ysis works onthe given CCFG.
Stage 1. The ﬁrst stage performs a data ﬂow analysis (Sec. 4) on
the CCFG is used to compute a summary in form of a interfer-
ence skeleton (IS= (S,≺S)). TheISsummarizes the CCFG
in terms of global accesses Sand their partial order ≺S. Starting
fromtheentrynodeofCCFG,theanalysisiterativelycomput esand
propagates symbolic data consisting of a path condition and alo-
calstate. Duringpropagation, eachglobalreadaccessisassigneda
freshsymbolicvalue(interferenceabstraction),andtheg lobalwrite
accesses are computed in terms of these symbolic values. Fig . 1
shows the details of the global accesses in the skeleton IS. The
accessesR1,R2,R3areassignedsymbolic values r1,r2,r3. Note
thateventhough R1andR2areconsecutive accessesto x,theyare
assigneddifferentsymbolicvalues r1andr2. Thisallowsustotake
arbitraryinterference(writes)fromconcurrentthreadsi ntoaccount
during composition. The analysis also collects the path con ditions
under which the global accesses happen, e.g., W2occurs if the
conditionocc(W2) = (r1<1)holds.
The analysis merges the propagated data at the joinpoints in
a precise path-sensitive manner, to avoid (potentially exponential)path enumeration in the CCFG. At the intra-thread join point s (cf.
Sec. 2), e.g., node 9, the path conditions are disjuncted follow-
ingthestandardsequential semantics,whileattheinter-t hreadjoin
node (node JOIN), the path conditions are conjuncted to ensure
simultaneous reachability of the node by all threads. To che ck as-
sertion violations, we compute error conditions at the error nodes,
whichcorrespondtothecomputedpathconditionsatthenode ,e.g.,
φ= (r4/ne}ationslash= 3)at ERR node. These error conditions are checked
during the second stage. The analysis also computes a partia l or-
der≺S(see Fig. 1(c)) denoting the relative order of events. Note
thatISabstracts away all the thread-local control and data ﬂow
from the CCFG and only contains the global access informatio n.
Computing the interference skeleton is non-trivial for arb itrary C
programs (with pointers and complex data types); we present the
full algorithm inSec.4.
Stage2.Thesecondstageofouranalysisexploresthefeasiblecon-
current behaviors of the CCFG by performing inter-threadco mpo-
sition. Note that in the skeleton IScomputed above, the values of
the global reads are unconstrained symbolic variables. The com-
position step constrains these values by linkingthem to the global
writes (cf. Sec. 5). Note that we cannot link reads with write s
arbitrarily,because we onlydesire feasible program behav iors dur-
ing composition, e.g., the read access R2cannot be linked to W2
which follows R2in the program order. The notion of sequential
consistency (SC) [1] enables us to ﬁnd a suitable relation between
the reads and writes systematically: SC constraints enforc e that
each read access Rmust link with somewrite access, say W,such
thatbothaccessthesamememorylocation,thevaluewritten byW
isthe value readby R,andWmustbe the lastsuchwritethathap-
pensbeforeRinanexecutiontrace. Inordertocapturethefeasible
executions duringcomposition, weaddSCconstraints betwe enthe
reads and writes in IS(Sec. 5). For example, the SC constraints
relatingR2(loc= @x,val=r2,occ= (r1<1)) toW2′
(loc= @x,val= (r′
2+ 1),occ= (r′
1<1)) are of form:
copy(R2,W2′)⇒(r2=r′
2+ 1)∧(r′
1<1)∧HB(W2′,R2)
where the predicate copy(R2,W2′)denotes that R2is linked to
W2′andHB(W2′,R2)denotes that W2′must happen before
R2. Constraintsenforcingthatnoother writehappens between R2
andW2′and thatR2must link with some write are also added
(see Sec. 5). In Sec. 6 we show how to add SC constraints in an
optimized way to pruneredundant constraints. Finally, the error
conditionφ= (r4/ne}ationslash= 3)ischeckedforfeasibility,togetherwiththe
encoding ofISand SC constraints by an SMT solver [9, 8]. If the
constraints are satisﬁable, then a sequence of accesses in ISis ob-
tained, e.g., ( W1,R1,R1′,R2,W2,R2′,W2′,R4) for the above
example. This sequence is then mapped to the CCFG to obtain a
violation witness. By separating the intra-thread summari zation in
Stage 1 with inter-thread composition in Stage 2, our analys is is
able toavoidredundant bi-modal reasoning completely.
3. MODELING C PROGRAMS
WeﬁrstdescribehowtotransformanarbitraryconcurrentCp ro-
gram to a simpliﬁed intermediate program by adopting a memor y
representation which consists of a global memory map togeth er
with local memory maps for each program thread. The simpliﬁe d
program isthenstructurallybounded andrepresentedasa bounded
CCFG,whichisused inour analysis.
3.1 Program Transformation
InordertohandleCprogram constructslikepointers,array sand
structuresuniformly,weﬁxamemoryrepresentationforour analy-
sisinamannersimilartotheHAVOCtool[7,20]. Indirectmem ory
accesses are handled using a memory map Mem, which models the
program heap by mapping a memory location (address) to a sym-
bolic value. All variables and objects whose address can be t akenint x;
void add_global ()
{
if ( x < 1 ) x = x + 1;
else x = x + 2;
}
int main (int argc, char *argv[])
{
pthread_t t1, t2;
x = 0;
pthread_create(&t1, NULL, NULL,
add_global);
pthread_create(&t2, NULL, NULL,
add_global);
pthread_join(t1);
pthread_join(t2);
assert(x == 3);
}FORK
JOINx < 1 x≥1
tmp = x
x = tmp + 1 x = tmp + 2tmp = xx < 1 x≥1
tmp = x
x = tmp + 1x = tmp + 2tmp = x
ERRx/negationslash=3 x == 3x = 0W1
W2 W3W2’ W3’R1 R1’
R2 R3 R2’ R3’
R41
2
3 4
5 6
7 8
92’
3’ 4’
5’ 6’
7’ 8’
9’
10W1
R1 R1’
R2 R3 R2’ R3’
W2 W3 W2’W3’
R4
(c)
Access loc val occ
W1@x 0 true
R1@x r1 true
R2@x r2 r1<1
W2@xr2+ 1 r1<1
R3@x r3 r2≥1
W3@xr3+ 2 r2≥1
R4@x r4 true
(d)
(a) (b)
Figure 1: Example: (a) A multi-threadedC program withtwo th reads,(b) its concurrentcontrol ﬂow graph (CCFG), andits g lobal
summaryconsistingof(c)therelativeorderofglobalacces sesand(d)thevaluesoftheglobalaccesses. Thevaluesforo nlyunprimed
accesses are shown: primedaccess values are similar. Theme mory location for variable xisdenotedby @x.
are allocated on the heap. The address of a variable vis a ﬁxed
value denoted by @v. Letoffs (f)denote the integer offset of
the location of a ﬁeld finside its enclosing structure. Using the
above map, we can transform the program statements (denoted by
operator T)asfollows: (i) T(e→f)=Mem[T(e)+offs(f)],(ii)
T(∗e) =Mem[T(e)], (iii)T(&e→f) =T(e) +offs(f), (iv)
T(e[i]) =Mem[T(e) +i∗stride (e)], wherestride (e)denotes
the size of array e’s type. All C program statements with indirect
accesses canbe transformedusing the above rules [7,20].
Shared variables. To detect shared variable accesses in con-
current programs with pointers, we use a conservative ﬂow- a nd
context-insensitive pointer analysis algorithm by Steens gaard[32].
All the variables that are declared as globals in the program or be-
long to an Steensgaard equivalence class [32] containing at least
onegloballydeclaredvariable,aresaidtobe shared. Basedonthis,
we partition the single memory map Memabove into (i) a shared
memory map G,todenote themapcontainingthesharedvariables,
andmaps Lktodenotethelocalmemorymapforthreadwithiden-
tiﬁerk. The domains of GandLkmaps are disjoint from each
other (contain different memory locations), thus creating a valid
partition. In contrast to previous approaches which partit ion the
memorymapsbasedontype-orﬁeldsafety[7,20],theabovepa rti-
tionismoreﬁne-grainedandthereforeimprovesthestageda nalysis
by reducing the number of conﬂictingmemory accesses.
All program statements are rewritten in terms of the above pa r-
tition, e.g., a statement of form l = (*p);wherelandpare
local and shared respectively, is re-written as l = G[p]; . As a
result, we can now identify allglobal accesses inthe progra m syn-
tactically. Variables whose address is not taken in the prog ram are
referredtobytheirnames,asbefore. Moreover,werewritet hepro-
gram statements so that no statement may perform more than on e
global read or write, i.e., no statement may contain more tha n one
occurrence ofG.Forexample, suppose athread Tcontains astate-
mentx = ( *p);where bothpandxare shared variables; this
isrewrittenas lp = G[&p]; ap = G[lp]; G[&x] = ap;
wherelpandapare freshvariables local to T.
3.2 Structural Bounding
Analyzingconcurrentprogramswithrecursionisundecidab le. We,therefore, obtain decidability by structurally bounding the concur-
rent program by unrolling loops and recursive functions to ﬁ nite
depth. Structural bounding ensures ﬁnite number of threads and
heapsize;werefertotheCCFGoftheboundedprogramas bounded
CCFGs.Ourmethodthenanalyzes thesebounded CCFGsforcon-
current reachability properties (e.g., assertion violati ons or data
races). The presented analysis is sound and complete with re spect
to these bounded CCFGs. Note that although we only consider
bounded CCFGs, the CCFG representation is essential for mod el-
ing real-world programs since it allows specifying thread c reation
and destruction, andthe relative order between threads (cf . Fig.1).
Boththese aspects are not handled by most concurrent analys es.
4. THREAD-MODULARSUMMARIZATION
The ﬁrst stage of our analysis computes a thread-modular sum -
marizationofthe CCFG:summarization getsridofbothlocal con-
trol and data ﬂow in each thread and represents them precisel y in
terms of global accesses.
Global Skeleton. The analysis summarizes the CCFG in form of
a interference skeleton IS= (S,≺S), whereSconsists of the set
of global accesses in the CCFG and ≺Sdenotes a partial order on
elements ofS. Recall that each access einScontains the corre-
spondingsymboliclocation loc(e),valueval(e),andtheoccurring
conditionocc(e). Each access einSis global; hence, the loc(e)
values correspond tomemory locations inG.
Thread-modularsummarizationisdoneusingaprecisedataﬂ ow
analysisthatexplorestheCCFGinthestandardreversepost -order[24]
of the nodes while computing the symbolic data facts at each node
of the CCFGandpropagating the facts tothe successors.
Symbolic Data. The data computed at a node nis a tuple of form
/an}bracketle{tψ,L,E/an}bracketri}ht, where (i)ψis the path condition formula for the set of
pathsreaching n,(ii)Listhelocalmemorymapforthethreadthat
nbelongs to, and (iii) Edenotes the set of global accesses which
happen immediately before (reach) the current location. We use
programexpressions(orterms)torepresentboth ψandLprecisely
during the analysis. Intuitively, ψcaptures the reachability condi-
tion for the node n,Lcaptures the local state (map from memory
locations to their symbolic values) at nandEis used to computethe interference skeleton iteratively. We also refer to the above tu-
ple as the symbolic state s,and itsﬁelds as s.ψ,s.Lands.E.
Symbolic Summary. Given a fragment Fof the CCFG (e.g., a
function) having unique entry and exit nodes, the thread-mo dular
summaryofFconsistsof(i)ainterferenceskeleton IS= (S,≺S)
over global accesses SinF, and (ii) a symbolic state /an}bracketle{tψ,L,E/an}bracketri}htat
the exit node of F, whereψ,LandEdenote the path condition,
local map and the reaching accesses at the exit node, in terms of
the input state map at the entry of F. Note that in the case where
the fragment F(e.g.,afunction body) contains noglobal accesses,
thefunctionsummaryreduces tothetraditionalsequential function
summary [31, 30] of form /an}bracketle{tψ,L/an}bracketri}ht, which represents the function
outputs in terms of its inputs. For ease of presentation, we ﬁ rst
describe the analysis assuming that all function calls are i nlined in
the CCFG. Subsequently, we discuss the general inter-proce dural
summarization algorithm.
Error Conditions. Recall that assertions are transformed to error
nodemonitorsintheCCFG.Ouranalysisretainsthesenodes i nthe
skeletonISandcomputes the symbolic state satthese nodes. The
corresponding path condition s.ψis used to check precise reacha-
bilityof the nodes duringthe composition stage.
Data-ﬂow analysis. A well-known technique for precise program
exploration is symbolic execution [19], which assumes symb olic
values for program inputs and propagates the state (represe nted as
program expressions) along all feasible program paths. Our data-
ﬂow analysis may be viewed as a form of symbolic execution for
concurrent programs, with two key differences. First, we av oid
costly path enumeration (as in symbolic execution) by mergi ng
symbolic data at the join locations (intra- and inter-threa d joins,
see Sec. 2) in a precise path-sensitive manner. Second, we av oid
exploring exponential number of thread interleavings by pe rform-
ing interference abstraction: each global read access is as signed a
fresh symbolic variable (placeholder). These placeholder s model
arbitrary concurrent writes to the read location; propagat ing these
placeholdersenablessequential(thread-modular)summar izationin
the presence of concurrency. The analysis propagates only t he lo-
cal state through the CCFG; the computed global accesses are not
propagated butare used toconstruct the interference skele tonIS.
Figure2presents therulesforpropagatingdatathroughaCC FG
fragment tobe summarized. Theyconsist of rules for initial ization
(INIT) at the entry node of the CCFG, propagating data through
guardededges( GUARD),assignmentswithonlylocalaccesses( ASGN-
LOC),assignmentswithglobalaccesses( ASGN-GLB-R ,ASGN-GLB-
W), splitting data at the FORK node ( FORK), and merging data
at intra-thread ( INTRA-JOIN ) and inter-thread ( INTER-JOIN ) joins.
The incoming data at a node nis denoted by In(/an}bracketle{tψ,L,E/an}bracketri}ht); read-
/writeaccesses earerepresentedastuples (loc(e),val(e),occ(e)).
The summary of the fragment Fconsists of the skeleton ISto-
getherwiththedatacomputedattheexitstateof F. Letusconsider
these rulesinmore detail.
Assignments. Recall that CCFG assignments (cf. Sec. 3) either
performglobalaccessesviasharedmap G,orlocalaccessesviathe
mapL. Since no statement accesses Gmore than once, we con-
sider three kinds of assignments: (global) lhs:=G[e],G[e] :=
rhs, and (local) lhs:=rhs. Let us assume that a procedure
eval(e,L)evaluates expression ein the local memory map L:
this is done by employing the standard ﬁrst-order logic oper ators
select (L,l)andstore(L,l,v)for manipulating arrays (cf. [23]),
wherelranges over memory locations and vover values stored at
these locations. To handle a local assignment lhs:=rhs(ASGN-
LOC), the analysis ﬁrst obtains the location by evaluating lhsinL
(eval(lhs,L)),followedbyevaluating rhstoobtainthenewvalue
v, and ﬁnally computing the update store(L,l,v)which is propa-
gated. An assignment accessing the shared map (containing G[e])
is handled differently since it creates a global access even t. Sup-
pose anodenwithassignment G[e] :=rhshas the incomingdata
In(/an}bracketle{tψ,L,E/an}bracketri}ht). The rule ASGN-GLB-W handles this by creating aglobal write access W= (l,r,ψ)with location l=eval(e,L),
valuer=eval(rhs,L)andthe occuring condition ψ(pathcondi-
tion atn). Moreover, the skeleton ISis updated by adding Wand
partial orders between the reaching accesses in EandW. Simi-
larly, the rule ASGN-GLB-R for handling lhs:=G[e]updatesIS
with a global read R, where the value of Ris a fresh symbolic
variabler(interference abstraction).
Handling Pointers. Recall that we model indirect accesses via
pointersinanuniformmannerbyemployingaprecisememoryr ep-
resentation using maps GandL(cf. Sec. 3). Note that by using
selectandstoreoperatorsformanipulatingsymbolicdata,wecan
handle arbitrary indirect memory accesses to Lvia pointers or ar-
rays, in an implicit manner, without explicitly computing t he alias
sets of these pointers. Indirect memory accesses tothe shar ed map
Garecapturedbythelocationexpression loc(e)foreachglobalac-
cesse; the subsequent composition stage employs loc(e)to check
for interferingaccesses.
Forks and Joins. The analysis merges the data at joinlocations in
the CCFG in a precise path-sensitive manner. At intra-threa d joins
(INTRA-JOIN ), the incoming maps L1andL2are merged using an
if-then-else operator to retain path-sensitivity while the path con-
ditionsψ1andψ2are disjuncted. At inter-thread joins, the local
map for the child thread ( Lc) is discarded and the path conditions
ψpandψcconjuncted: this models the fact that both the parent
and the child threads must execute the join location togethe r. Note
that the analysis creates a new local map Lcfor the child thread at
the thread creation node ( FORK), which is discarded at the thread
destruction node (JOIN).
By handling statements, forks and joins precisely during da ta-
ﬂow analysis and using interference abstraction for global reads,
thealgorithmgetsridofalllocalcontrolanddataﬂowinthe CCFG:
they are summarized to precise relations between global rea d and
writeaccesses. Togetherwithprecisecompositioninthene xtstage,
ouranalysisbecomessoundandcompletewithrespecttotheb ounded
CCFG. Note that for the example in Sec. 1.1, summarization wi ll
be able toinfer that a100 = (a0 + 100) and hence repeated intra-
thread reasoning isavoidedduring composition.
Example. The analysis of CCFG in Fig. 1 proceeds as follows.
First, create a write access W1 = (@x,0,true)at node 1. At
the FORK node, initialize the local maps for thread t1andt2,
L1andL2, toM1andM2respectively. Consider the propaga-
tion along the thread t1, for example. At node 2, create access R1
=(@x,r1,true), addR1toISand updateEto{R1}; At node
3, update the path condition ψto(r1<1), add access R2 =
(@x,r2,(r1<1))toIS,add(R1,R2)to≺S,updateEto{R2},
and update map L1tostore(M1,@tmp,r 2). At node 5, add
W2 = (@x,V,(r1<1))toISwhereV= (1+select (L1,@tmp)),
i.e.,V= (1 +r2), and so on. At the intra-thread join node 9,
the incoming states are merged to obtain ψ= (r1<1∨r1≥
1) =trueandL1=store(M1,@tmp,ite (r1<1,r2,r3))and
E={W2,W3}. At inter-thread join node JOIN, the incom-
ing path conditions are conjuncted (trivially true) andEmerged.
Finally, the error condition is obtained from the path condi tion
(r4<3)fortheERRnode. ThecompletesummaryoftheCCFGis
giveninFig.1(c)and(d). Notethatwedonotpropagateanygl obal
readorwritesduringCCFGexploration: alltheglobalacces sesare
captured inIS. Although the data-ﬂow analysis algorithm works
on the complete CCFG, the analysis is thread-modular, i.e., each
thread isanalyzed independently using interference abstr action.
Function Summaries. The above algorithm can summarize arbi-
trary (bounded) concurrent programs assuming that functio ns are
inlined. However,inliningcausesblowupoftheanalyzedpr ogram
and makes it difﬁcult to exploit the modular sequential prog ram
structure. Wecanextendtheabovealgorithmtoperformasta ndard
interprocedural analysis [31, 30] based on computing summa ries
at function boundaries and reusing these summaries at the ca lling
contexts. A function summary consists of a interference ske letonINITn∈entry(CCFG )
In(/an}bracketle{ttrue,L 0,{}/an}bracketri}ht)GUARDng− →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)
ψg=eval(g,L)
I′
n(/an}bracketle{tψ∧ψg,L,E/an}bracketri}ht)ASGN-LOCnlhs:=rhs− − − − − − →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)
l=eval(lhs,L)v=eval(rhs,L)
I′
n(/an}bracketle{tψ,store (L,l,v),E/an}bracketri}ht)
ASGN-GLB-Rnlhs:=G[e]− − − − − − − →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)IS= (S,≺S)
l=eval(lhs,L)l′=eval(e,L)R= (l′,r,ψ)ris fresh
I′
n(/an}bracketle{tψ,store (L,l,r),{R}/an}bracketri}ht)IS= (S∪ {R},≺S∪{(e,R)|e∈E})
ASGN-GLB-WnG[e]:=rhs− − − − − − − →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)IS= (S,≺S)
l=eval(e,L)r=eval(rhs,L)W= (l,r,ψ)
I′
n(/an}bracketle{tψ,L,{W}/an}bracketri}ht)IS= (S∪ {W},≺S∪{(e,W)|e∈E})INTRA-JOINm→n m′→n(tid(m) =tid(m′) =tid(n))
Im(/an}bracketle{tψ1,L1,E1/an}bracketri}ht)I′
m(/an}bracketle{tψ2,L2,E2/an}bracketri}ht)
In(/an}bracketle{tψ1∨ψ2,ite(ψ1,L1,L2),E1∪E2/an}bracketri}ht)
FORKFORK (n)n→p n →c
tid(p) =tid(n)In(/an}bracketle{tψ,L,E/an}bracketri}ht)
Ip(/an}bracketle{tψ,L,E/an}bracketri}ht)Ic(/an}bracketle{tψ,Lc,E/an}bracketri}ht)Lcis freshINTER-JOINJOIN (n)p→n c →n tid (p) =tid(n)
Ip(/an}bracketle{tψp,Lp,Ep/an}bracketri}ht)Ic(/an}bracketle{tψc,Lc,Ec/an}bracketri}ht)
In(/an}bracketle{tψp∧ψc,Lp,Ep∪Ec/an}bracketri}ht)
Figure 2: Transformation rules for thread-modular summari zation of a CCFG fragment. For a node n,In(/an}bracketle{tψ,L,E/an}bracketri}ht)denotes the
incomingsymbolic state at n;tid(n)isthenumericidentiﬁerofthethreadcontaining n;iterepresentsthe if-then-else operator. The
summary consists of theinterferenceskeleton IS= (S,≺S)andIexcomputedat exit node exof thefragment.
(globalaccessesmadeinthefunction),togetherwiththelo calsym-
bolic state Lat the exit node of the function. Here, the exit state
Lis computed using a fresh symbolic input state Liat the func-
tion input. Incontrast to explicit summarization approach es which
depend on detecting transaction boundaries [28, 36], our me thod
can compute symbolic summaries for arbitrary program regio ns
across multiple transactions. The key problem is how to reus e pre-
computed summaries: givena callingcontext state L′,the interfer-
ence skeleton of the summary is duplicated and all global acc esses
evaluated inthe incoming state L′bysubstituting L′forLi.
THEOREM 1.Theinterferenceskeleton IS= (S,≺S)isapre-
cise thread-modular summary of the ﬁnite CCFG. Moreover, ≺S
respects the program order1.
5. AXIOMATICCOMPOSITION
We now describe the second stage of our analysis which com-
putes the inter-thread composition by using sequential con sistency
axioms that link the read and write accesses in the thread-mo dular
summaryIScorrectly.
5.1 Linearization ofthe GlobalSkeleton
Alinearization Lof a interference skeleton IS= (S,≺S)is a
tuple(S′,<S′),where(i)S′⊆S,(ii)<S′isatotalorder,and(iii)
for allrw1,rw2∈S′,rw1≺Srw2⇒rw1<S′rw2. In other
words, a linearization of ISis obtained by selecting a subset of
accesses from ISandimposingatotalorderamongthemsuchthat
the totalorder respects the partial order in IS. A linearization Lis
saidtobe programpath-consistent ifitsprojection ontotheCCFG
corresponds toa single pathfor each program threadinthe CC FG,
andLshould contain all the accesses in each path on which it is
projected. Program path-consistency allows us to obtain co ncrete
CCFG program paths from a linearization that leads to an erro r. A
linearization LofISissaidtobe feasibleifthereexistsaconcrete
interleaved execution of the program CCFG corresponding to L.
Notethatafeasiblelinearizationisalwaysprogrampath-c onsistent
but not vice-versa.
Althougheachconcreteexecutioncorrespondstosomelinea riza-
tionIS′of the skeleton IS, all linearizations may not be feasible
program traces. Infeasible linearizations IS′occur, because the
reads inIS′may not be linked to appropriate writes. In order to
derivetheseconstraintssystematically,wedeﬁnethe copyrelation.
1Allproofs are available inthe extended version of this pape r.Copy Relation. Letrandwbe a read and write access in a
read/write (total-ordered) sequence S. We say that rcopiesw, or
copy(r,w)holds, if (a)randwinterfere, i.e., (loc(r) =loc(w))
(b) the value read by ris the same as the value written by w,
(val(r) =val(w))and, (c) there are no interfering write accesses
w′toloc(w)inS, such thatw < Sw′andw′<Sr. The main
goalofcomposition, therefore,istoﬁndasuitablewrite wforeach
readrso thatrcan copyw. The notion of sequential consistency
(SC) [1] can be used to formally characterize this problem. A lin-
earizationIS′= (S,< S)is said to be sequentially consistent if
the followingaxioms hold:
•SC.1(Program Order) Let rw1andrw2be read/write ac-
cesses to the same location lin the sequence S. Ifrw2fol-
lowsrw1inthe executionorder of program P,i.e.,rw1≺P
rw2, thenrw1<Srw2.
•SC.2(Copy Some) Each read to location linSmust copy
somewriteinStol2.
Axiomatic composition (AC) using the above SC axioms guar-
antees thefeasibilityof linearizations of IS.
THEOREM 2.A program path-consistent linearization IS′of
ISis feasible iffitissequentially consistent.
Axiomatic composition (AC) has been previously used toveri fy
properties of concurrent data structures [2] executing on m odern
out-of-order processors. Here, AC was primarily used to pre cisely
model various (intra-thread) read/write reorderings allo wed by the
processor. In contrast, we employ AC in an entirely new setti ng,
i.e., static analysis of high-level programs. Here, the pro blem re-
duces to encoding only the SC constraints between reads/wri tes.
However, the central challenge is to obtain an efﬁcient enco ding
that enables ascalable analysis.
5.2 Copy Constraints
Note that by Theorem 1, any linearization of the interferenc e
skeletonISmust obey the program order SC.1. However, ad-
ditional constraints must be imposed on a linearization to s atisfy
SC.2. We refer to such constraints as copy constraints , denoted
byΦC. These constraints capture the copyrelation and are mod-
eled by a set of ﬁrst-order logic formula quantiﬁed over read s and
writes,consisting of Φ1
C,Φ2
CandΦ3
C.
2Theinitialvalue oflocation lisalsorepresentedbyawriteaccess
withafresh symbolic value.Φ1
C:∀r.occ(r)⇒ ∃w.copy (r,w)
Φ2
C:∀r,w.copy (r,w)⇒occ(r)∧occ(w)∧
(val(r) =val(w))∧(loc(r) =loc(w))∧HB(w,r)
Φ3
C:∀r,w.copy (r,w)⇒
∀(w′/ne}ationslash=w).(occ(w′)∧HBet(w,w′,r))⇒loc(w)/ne}ationslash=loc(w′)
ΦC=Φ1
C∧Φ2
C∧Φ3
C.
The constraints Φ1
Ccapture the conditions SC.2(Sec.5), i.e.,each
read (if it occurs) must copy some write access. The formula Φ2
C
capturesthedata-ﬂowconstraintsonthecopy,i.e.,thewri tewmust
occur (occ(w)), the values/locations of both randwshould be
same andwmust happen before rin the linearization. The pred-
icateHB(e1,e2)models a strictpartial order relation that denotes
thataccesse1musthappenbefore e2ineverylinearization. Inother
words, if a linearization contains both e1ande2thene1must pre-
cedee2. Theformula Φ3
Ccapturesthefactthatnointerferingwrite
w′may happen between the write wand a readrthat copies from
w. The predicate HBet(w,w′,r)denotes that w′may-happen-
betweenwandr, and is deﬁned as ( ¬HB(w′,w)∧ ¬HB(r,w′)).
Detailsofencoding HBarepresentedinthenextsection. Φ3
Cmod-
els that either w′does not happen between wandr, or does not
interfere with w(loc(w′)/ne}ationslash=loc(w)) ifw′occurs inbetween.
Example. Recall the example and its ISin Fig. 1. A linearization
L0= (W1, R1, R3, R2, W2, R1’, R2’, W2’, R4 ) of theISis not
program path-consistent, since it does not project to a sing le path
for threadt1. On removing R3fromL0, we obtain a lineariza-
tion (say,L1) which is path-consistent; however, L1is not feasi-
ble. To see this, note that because the reads R1′andR2′immedi-
atelyfollowthewrite W2inthelinearization,copyconstraints Φ1
C
andΦ3
Cimplythatboth copy(R1′,W2)andcopy(R2′,W2)must
hold. Now, since val(W2) = 1, the constraints Φ2
Cimply that
val(R1′) =r′
1=val(R2′) =r′
2=val(W2) = 1. This, how-
ever, implies that occ(R2′) = (r′
1<1) =false, which violates
Φ2
C. HenceR2′shouldnotoccurintheexecution(andthereforein
L1). Onreplacing R2’,W2’ byR3’,W3’ inL1,weobtainafeasible
linearization ( W1,R1, R2,W2, R1’,R3’, W3’,R4 ).
5.3 Encoding theComposition
We encode the set of sequentially consistent linearization s of a
interference skeleton ISas a formula in quantiﬁer-free ﬁrst-order
logic: theskeleton IS= (S,≺S)isencodedasaformula ΦIS,and
thecopyconstraintsas ΦC. Thesetoffeasiblelinearizationsof IS
is then represented as a formula Φ = Φ IS∧ΦC. Finally, given
an error location with the path condition ψ, we can check if the
error location is reachable via a feasible linearization by checking
the satisﬁabilityof the formula Φ∧ψusingan SMTsolver.
Encoding ΦISandHB.BothΦISandΦCdepend on the strict
partial order relation, HBbetween read/write accesses. To obtain
an efﬁcient encoding that avoids quantiﬁers, we encode the r ela-
tion using the integer theory with the strict partial order o perator
<. More precisely, we assign an integer clockvariableTeto each
accesse. Now,HB(e1,e2)is simply encoded as Te1< T e2. The
accesses inISare encoded in a straightforward manner: for each
read/write access, we create three variables loce,valeandocce
and add constraints that equate each variable to the corresp onding
value. To model arbitrary initial values for locations in th e map G
lazily, we add a ﬁnite set of initial symbolic writes in ISas many
as the number of reads in IS. Finally, we encode the partial order
≺Susing the must-happen-before predicate, HB.
Encoding ΦC.The quantiﬁed constraints in Sec. 5.2 can directly
serve as input to an SMT solver that supports quantiﬁers, usi ng
interpreted functions for loc,valandocc. In practice, however,
SMT solvers have difﬁculty in instantiating quantiﬁers efﬁ ciently.Therefore,weinstantiatethecopyconstraintsexplicitly forallpos-
sible read and writes in ISusing the corresponding loc,valand
occvariables for each access. Modeling copy(r,w)directly will
introduce Boolean variables of form copy_r_w, quadratic in num-
ber of reads/writes, which we want to avoid. Therefore, we cr eate
an integer identiﬁer variable IDefor each access e, and assign a
unique constant to IDwfor each write access w. Now,copy(r,w)
is encoded as ( IDr=IDw), which holds when the identiﬁer to
ris same as that for w. This encoding takes advantage of the fact
that a readcanonly copy a single write.
Still, this explicit instantiation of ΦCfor all reads/writes is too ea-
gerandmayresultinaformulathatiscubicinsizeoftheread /write
access set. The next section discusses optimizations to ove rcome
the bottlenecks due tothis eager encoding.
THEOREM 3.Suppose we have an sequentially consistent en-
coding Φfor a CCFG Cand apath condition φfor an error loca-
tione. If (Φ∧φ) is satisﬁable, then there exists a feasible inter-
leaved executionof Ctothe location e.
Example. Recalltheprogramanditsskeleton ISinFig.1. Check-
ingthepathcondition (r4/ne}ationslash= 3)fortheERRnodetogetherwith ΦIS
andcopyconstraints ΦCleadstoasolutionwitha HBrelationthat
reﬁnes ≺S(cf. Fig. 1) by adding pairs (R1,R1′),(R1′,R2)and
(W2,R2′). The accesses R3,W3,R3′,W3′do not occur, i.e.,
theiroccevaluates to false, and they can be ignored. As a result,
we obtain a linearization (W1,R1,R1′,R2,W2,R2′,W2′,R4)
that witness the assertionviolation.
6. INTERFERENCE PRUNING
Eager instantiation of the copy constraints ΦCfor all pairs of
reads and writes in large programs proves to be a signiﬁcant b ur-
den on the SMT solver during satisﬁability check. Moreover, in
case of indirect accesses, it is not clear upfront if a read rcannot
interferewithawrite w,i.e.,loc(r) =loc(w)isunsatisﬁable,thus
making the search more complex. However, many of these copy
constraints may be redundant , i.e.,¬copy(r,w)holds. For exam-
ple, note that the constraints corresponding to Φ2
Cmay reduce to
¬copy(r,w)if the right hand side (RHS) of the formula is unsat-
isﬁable for some randw. This may happen due to a number of
reasons. For example, a read rcannot copy a write wthat follows
rin the program ( R2,W2in Fig. 1), or a read rin a child thread
cannotcopyawrite wthatoccursintheparentthreadafterthechild
thread terminates. Also, rcan only copy from wifrandwmay
interfere, i.e., loc(r) =loc(w)is satisﬁable. In other words, each
read may copy from only a restricted set of writes, and it is wa ste-
ful to add copy constraints for the writes not in the set. A lar ge
number oftheseredundant constraints canbedetectedstati callyby
analyzingtheinterferenceskeleton ISandremovedtooptimizethe
composition (cf. Sec. 7). We now present a systematic method to
prunethese copy constraints, basedon the followingnotions.
MHP and Kill Set. Given an interference skeleton IS= (S,≺S
), let≺∗
Sdenote the transitive closure of ≺S. We say that two
accessese1ande2may-happen-in-parallel , i.e.,MHP (e1,e2)if
bothe1≺∗
Se2ande2≺∗
Se1do not hold. If a write wfollows
another write w′in the same thread, and winterferes with w′(i.e.,
loc(w) =loc(w′)) in all program executions, then we say that w
killsw′. More formally, the set of writes killedbywis given by
Kill(w) ={w′|w′≺∗
Sw∧loc(w′)⇒loc(w)}. Note that for
symbolicvalues loc(w)andloc(w′),loc(w′)⇒loc(w)musthold
ifwkillsw′inall executions.
Reaching writes. We say that a write wmay reach a read r, if
(i)MHP (r,w), or (ii)whappens before rand for allw′≺∗
Sr
(w′/ne}ationslash=w),w/ne}ationslash∈Kill(w′)holds. We denote the set of writes that
mayreachrbyΠ(r). Wecompute Π(r)foreachread rasfollows.
First, we compute the transitive closure ≺∗
Sfor the given skeleton
IS. Computing (i) MHP (r,w)requires checking if both (r,w)or(w,r)do not belong to ≺∗
S. In order to compute the writes that
are not killed, we perform a light-weight Gen-Kill [24] analysis
of the partial order graph for ≺S(cf. Fig. 1). Starting from the
node corresponding to the initial write, the analysis compu tes and
propagates the set of reaching writes to each location in the graph
(i.e.,for each access in IS): each location that generates a write w
may kill the incoming writes w′that belong to Kill(w). Note that
checkingloc(w′)⇒loc(w)precisely is expensive if both loc(w)
andloc(w′)are symbolic values. So, we estimate the kill set con-
servativelybycheckingif loc(w)andloc(w′)areexactlythesame.
May-CopySet. Inorder toprune theredundant constraints in ΦC,
we deﬁne the may-copy setC(r)for eachrby restricting Π(r)to
interfering writeswthat can occur, i.e., C(r) ={w|w∈Π(r)∧
(loc(r) =loc(w))∧occ(w)}. Again,computing C(r)preciselyis
expensive: we syntactically check if occ(w)or(loc(r) =loc(w))
is unsatisﬁable. Finally, we instantiate Φ1
C,Φ2
CandΦ3
Conly for
pairsrandw, wherew∈ C(r).
Instantiating the inner quantiﬁer in Φ3
Cfor all possible writes
w′may still produce redundant constraints. We prune such con-
straints by checking if (a) the write w′cannot occur ¬(occ(w′),
or (b) cannot happen between wandr,¬(HBet(w,w′,r)), or (c)
loc(w′) =loc(w)is unsatisﬁable. We check (a) and (c) syntac-
tically. To check (b), we use the ≺∗
ISrelation computed above,
i.e.,w′cannot happen between wandrif eitherw′≺∗
ISwor
r≺∗
ISw′. Ourencodingcanbefurtheroptimizedtohandle atomic
regionsandtoperformacontext-bounded[27,21]analysis(seefull
version of the paper). Our experiments in the next section sh ow
thatpruningredundant constraints asabove leadstosigniﬁ cantim-
provement of solver run times.
7. EXPERIMENTS
We implemented the staged analysis approach in the FUSION
veriﬁcationsystem[34]forconcurrentCprogramsbasedon PThreads .
The FUSIONsystem combines dynamic and symbolic veriﬁcatio n
techniques inorder to verifyproperties of concurrent prog rams. In
the ﬁrst step of its execution, FUSION instruments the given con-
currentprogramandthenrunstheprogram Ptoobtainasliceof P.
The slice is represented as a CCFG [34] and contains the threa ds
created and the original program statements that each threa d ex-
ecuted during the run. The slices themselves can grow quite l arge
dependingonthenumberofstatementsexecutedin Pandthenum-
ber of threads created, and are suitable for preliminary eva luation
of our approach.
In order to evaluate our approach, our implementation focus ed
on checking assertions as well as data races in the concurren t pro-
gram slices obtained from benchmarks using FUSION. We ﬁrst
performed data ﬂow analysis on the slices to obtain an interf er-
ence skeleton and computed a pruned set of sequential consis tency
constraints over this skeleton. To check assertion violati ons at an
error location, we add the feasibility path condition for th e error
location and employ the Yices SMT solver [9] to check if the se t
ofconstraintscanbesatisﬁed. Tocheckdataracesbetweent wolo-
cations, weaddconstraintsmodelingthatthe correspondin g global
accesses are simultaneously reachable, and again check for satis-
ﬁability using the solver. All experiments are conducted on a PC
with 2.4Ghz Intel Core2Quad processor with 2GB memory limit
running Fedora 10.
Our evaluation consists of two parts. First, we compared our
stagedanalysiswithapreviousapproachthatusesconcurre ntsingle-
static assignments (CSSA) (cf. [34]) for encoding concurre nt pro-
grams. CSSA is an extension of single static assignments to c on-
current programs to handle both intra-thread data ﬂow (each vari-
able must be assigned only once) as well interference (value s of
all concurrent writes are propagated to each read). The CSSA rep-
resentation retains all the local control and data ﬂow; more over, a
large number of fresh variables are introduced (in each thre ad) tomodeljoinsandinterference. Duetothepresenceofcomplex local
control and data ﬂow, the approach performs repeated intra- thread
reasoningforeachinterleavingoftheprogramthreads. Sec ond,we
evaluated the efﬁciency of optimizations when encoding com posi-
tion using sequential consistency. More precisely, our goa l was to
estimate the impact of pruning redundant interferences.
We evaluated our approach using the following benchmarks ob -
tained from the public domain. The ﬁrst set of benchmarks con -
sist of the C implementation of the indexer example [11] using
Pthread library, parametrized by the number of threads. In this
example, multiple threads read and write to a hash table with 128
entries. Asthe number ofthreads increases beyond 12, thenu mber
ofsharedaccessesalsoincreasesrapidlyduetohashcollis ions. We
checkthepropertythatnocollisionhappensonaparticular entryof
the hash table. We evaluated the effectiveness of our approa ch for
handling increasing number of threads as compared to the CSS A
based implementation which does not perform summarization . We
experimented with CCFGs with up to 32 threads to evaluate the
scalability of our approach. The second set of benchmarks ar e ob-
tained from traces of a bank account program (account) and a s yn-
chronization based module (SynchBench). Boththese benchm arks
were checked symbolically for existence of data races. The b ench-
marks are marked in the name-(#T) format where #Tdenotes the
number of threads.
Fig. 3 shows the comparison of various modes of our tool with-
/without summarization and optimized composition. The mod e
Old(+O) denotes an implementation of the symbolic checks ba sed
on CSSA encoding [34]. This implementation has been optimiz ed
extensively to reduce the number of redundant constraints ( similar
to Sec. 6), but does not use summarization. In the next mode (+ S-
O),we perform summarization but composition is done eagerl y by
instantiatingcopyconstraints forallpairsof reads andwr ites. This
eagerinstantiationleadstoalargenumberofredundantcon straints.
Finally,(+S+O)denotesourapproachwithbothsummarizati onand
optimized composition. We do not present results for the mod e
without summarization or optimization (-S-O) because of it s poor
performance.
Our experiments show that mode (+S+O) outperforms all other
modes on our benchmarks. For example, as the number of thread s
in theindexer example is increased successively from 20 to 31,
both Old(+O) and (+S-O) modes scale much worse than (+S+O)
mode. Themode(+S-O)withoutoptimizationsperformsveryp oorly
since the eager instantiation of sequential consistency (S C) con-
straints allows each global read to link with all global writ es, e.g.,
intheindexer (32)example,eachreadcancopyfrom 1856writes.
The SMT solver is not able to handle such a large number of copy
constraintseffectivelyandtimeoutsin(+S-O)mode for25o rmore
threads. This shows that a naive encoding of SC constraints i s not
useful for analyzing real-life benchmarks; an optimized en coding
that avoids redundant constraints is needed. Similarly, th e mode
with optimized composition but without summarization Old( +O)
timeouts for 31 and 32 threads. In contrast, the mode with bot h
summarizationandoptimizedcomposition(+S+O)ﬁnishesan alyz-
ingindexer (32)inonly 104s.
For theaccount benchmark (similarly for the SynchBench ex-
ample),weagainobservethatsummarization(+S+O)leadsto faster
run times as the number of threads increase from 11to21. This
supports the fact that performing repeated intra-thread re asoning
whenexploringlargenumberofthreadinterleavingstakesa signif-
icant toll on the overall efﬁciency of the solver. We observe d that
theaveragenumberofwritesthatareadmaycopy(cf. Sec.6)a fter
optimized composition in(+S+O) mode is 2−3for all the bench-
marks (maximum varies between 10−20). The results show that
both summarization and optimized composition are indispen sable
for scaling up the analysis, and summarization can make veri ﬁca-
tion tractable in cases where optimized composition is not s ufﬁ-
cient. Moreover, note that the encoding used in context-bou ndedBm |N| |E| |R| |W|Old(+O) +S-O +S+O
SynchBench(2) 108 107 6 19 1 1 1
SynchBench(13) 723 722 270 289 9 711 3
indexer(20) 1312 1439 110 291 0.1 355 0.1
indexer(27) 2142 2355 284 707 23>1800 0.3
indexer(28) 2294 2523 322 797 97>1800 4
indexer(29) 2446 2691 360 887 129>1800 6
indexer(30) 2859 3149 468 1104 517>1800 7
indexer(31) 3398 3747 594 1332 >1800>1800 13
indexer(32) 4585 5065 888 1856 >1800>1800 104
account1 (11) 906 905 134 372 1 121 1
account2 (21) 1748 1747 260 708 25>1800 10
Figure 3: Experiments comparing (a) CSSA-based algorithm [ 34], without summarization, with optimizations (Old+O) (b ) with
summarization, no optimization (+S-O) (c) our method with s ummarization and optimization (+S+O). |N|(|E|) = total number of
nodes(edges) intheCCFGanalyzed. |R|(|W|)=total numberof global reads(writes). Allrun-timesare in seconds.
methods [21, 20] roughly corresponds to the (+S-O) mode wher e
each global read may link with all possible shared variable w rites.
Therefore,theprevious encodingisimpracticalforlargep rograms.
8. RELATED WORK
Context-bounded Analysis. A number of approaches check con-
current software under a ﬁxed context bound [27] since the ve riﬁ-
cation problem is both decidable and practically useful [25 ]. Both
symbolic [29, 21, 20] and explicit [25] approaches have been pro-
posedforCBA.Arecentapproach[21]transformsaconcurren t re-
cursiveBooleanprogram(withﬁnitedata)underacontextbo undto
asequentialprogram,whichisthenanalyzedusingsequenti alanal-
ysis. [20] extend the method to perform context-bounded ana lysis
of concurrent C programs by unrollingloops and recursion ﬁn itely
to obtain decidability and employing a precise memory repre sen-
tation for C programs. In contrast, our goal is to verify real -life
concurrent Cprograms where both(i)variable domains maybe in-
ﬁnite and (ii) arbitrary context switches are allowed, (iii ) without
any redundant bi-modal reasoning. To achieve the condition (i)
we need to structurally bound the loops and recursion in our p ro-
grams, similar to [20]. Although [21] can be extended to achi eve
(ii) and avoid bi-modal reasoning, such an extension is impr acti-
cal. More precisely, the extension will have to (a) duplicat e and
abstract all global state variables at eachpotential context switch
location and (b) compute summaries for each pair of intra-th read
locations [22], resulting in an extremely inefﬁcient metho d. In
contrast, our staged analysis abstracts interference by in troducing
freshvariablesatglobalreadlocationsonly. Further,bys tructurally
bounding theprogram(whichisunavoidableduetodecidabil ityis-
sues), wenot onlyavoidredundant bi-modal reasoning, but i nfact,
separate the intra-and inter-threadreasoning completely .
Thread-modularsummarization. Pathcompressiontechniques[36]
relyon identifying interference-free transactions and are unable to
summarize data facts across multiple transactions, causin g redun-
dant bi-modal reasoning. The Zing model checker employs fun c-
tion summarization [28] in presence of interference by iden tify-
ing transactions during path-enumeration based explicit-state ex-
ploration. Incontrast, our method performs precise summar ization
symbolically based on symbolic memory accesses as opposed to
potentially inﬁnite number of concrete-valued accesses. F urther,
wedonotneedtoidentifytransactionsandavoidpath-enume ration
by mergingsymbolic data facts at program joinlocations.
Thread-modular veriﬁcation. Thread-modular or rely-guarantee
techniques for software include the initial deductive meth ods [26,
18] followed by more recent methods that employ iterative co m-
positional reﬁnement [12, 17, 3, 6] or methods for handling h eap-
manipulating programs [15, 33]. Iterative reﬁnement techn iques
ﬁrst abstract the transition relation [12] or the reachable states [6]
of the individual threads, by over-approximating the relation be-tween global accesses in each thread. If the composition of t hese
abstractions is not suitably precise to prove the given prop erty, the
methodsreﬁnetheabstractionsiteratively,e.g.,basedon counterex-
amples [17, 6] from the property check. Interference abstra ction
alsomakesourthread-modularsummariesover-approximate ;how-
ever, because our summaries contain the exact relation betw een
non-concurrent reads and writes, we can obtain the fully pre cise
system in one step by linking the reads to the writes during co m-
position. This is in contrast to the previous methods where a large
number of iterations may be required before the abstraction s are
made suitably precise for proving a property. Instead of per form-
ing rely-guarantee reasoning [18] as in [12, 17, 6], our focu s is on
compositional minimization [5, 16]: we use summaries tosep arate
intra-andinter-threadanalysisandobtainacompactrepre sentation
of threads before composition.
ConcurrentDataFlowAnalysis. Mostconcurrentdataﬂowanal-
yses (cf. [10]) employ a ﬁnite-height data domain and perfor m re-
dundant bi-modal reasoning by repeated intra-thread propa gation
of new symbolic domain values while exploring all relevant i n-
terleavings explicitly. In contrast, our staged analysis performs
summarization over inﬁnite domains using program expressi ons
(terms), followed by symbolic exploration of interleavings inside
anSMT solver [9,8].
OtherSymbolicEncodings. AnothersetofmethodsuseSAT/SMT
solvers to check concurrent programs with an encoding that d oes
notemployanexplicitscheduler[13,34]. Noneoftheseappr oaches
employ thread-modular summarization and therefore perfor m re-
dundant bi-modal reasoning: the solver must reason over con cur-
rent interleavings as well as complex local transitions alt ernately.
TheencodingpresentedinFSE2009[34]isbasedontransform ing
a (bounded) program into a concurrent single static assignm ents
(CSSA)formandisrestrictedtohandlingsimpleintegerpro grams,
in contrast to ours, which handles arbitrary C programs and p er-
forms summarization. The idea of interference abstraction is em-
ployed implicitly in the CSSA representation, but not explo ited to
compute summaries.
Veriﬁcationofconcurrentdatastructuresunderrelaxedlo w-level
hardware memory models [2] employ axioms specifying the al-
lowed load/store event orderings to the hardware memory, in or-
der to precisely model the concurrent interleavings. Our me thod,
instead targets high-level static analysis of C programs; f or high-
level analysis, it is sufﬁcient to consider only sequential ly consis-
tent(SC)orderingsofreadsandwrites,asopposedtomorere laxed
memory orderings considered in [2]. As a result of this restr ic-
tion,ourmethodfocusesonencodingSCefﬁcientlyinsidean SMT
solver, whichis not considered in[2].
9. CONCLUSIONSWe presented a staged analysis for verifying concurrent C pr o-
grams which separates intra- and inter-thread reasoning an d ex-
ploits sequential summarization to solve the pervasive pro blem of
redundant bi-modal reasoning. The key contribution is a thr ead-
modular program summarization algorithm which abstracts a way
all the local control and data ﬂow in terms of global accesses . The
summarizedinterferenceskeletonisthenusedforinter-th readanal-
ysis by employing sequential consistency axioms over the gl obal
accesses. Experimental results on benchmarks show our appr oach
is more scalable than previous bi-modal methods because it a voids
repeated intra-thread reasoning. Future work will focus on scaling
our approach to larger concurrent systems: the key problem i s to
further minimize the set of quantiﬁer instantiations, whic h are cu-
bic inthe size of reads and their may-copy sets,which causes blow
up on larger benchmarks. Another approach is toavoidexplic it in-
stantiation by using quantiﬁed SC axioms inside the solver. Our
method can also be extended to perform data ﬂow analysis on le ss
precise domains thanterms,e.g.,polyhedra.
Acknowledgements. WewouldliketothanktheVeriﬁcationgroup
atNECandtheanonymousreviewersfortheirinvaluablefeed back.
10. REFERENCES
[1] S.V. Adve and K.Gharachorloo. Sharedmemory
consistency models: A tutorial. IEEEComputer ,
29(12):66–76, 1996.
[2] S.Burckhardt, R.Alur,and M.M. K. Martin.Checkfence:
checking consistency of concurrent data types on relaxed
memory models. In PLDI,pages 12–21, 2007.
[3] S.Chaki, J.Ouaknine, K. Yorav,and E.M.Clarke.
Automated compositional abstraction reﬁnement for
concurrent C programs: A two-level approach. In SoftMC,
2003.
[4] Shaunak Chatterjee, Shuvendu K.Lahiri,and Shaz Qadeer .
A reachabilitypredicate for analyzing low-level software . In
TACAS.Springer,2007.
[5] E.M. Clarke, O.Grumberg, and D.Peled. Model Checking .
MIT Press,Cambridge, 2000.
[6] A.Cohen and K.S.Namjoshi. Local proofs for global safet y
properties. Formal Methods inSystem Design ,
34(2):104–125, 2009.
[7] J. Condit,B. Hackett, S.K. Lahiri,andS.Qadeer. Unifyi ng
type checking andproperty checking for low-level code. In
POPL,pages 302–314, 2009.
[8] L.de Moura and N.Bjørner. Z3: Anefﬁcientsmt solver. In
TACAS,pages 337–340, 2008.
[9] Bruno Dutertreand Leonardo de Moura. Afast
linear-arithmeticsolver forDPLL(T).In CAV,pages 81–94,
2006.
[10] A.Farzanand P.Madhusudan. Causal dataﬂow analysis fo r
concurrent programs. In TACAS,pages 102–116, 2007.
[11] C.Flanagan andP.Godefroid. Dynamic partial-order
reduction for model checking software. In POPL,pages
110–121, 2005.
[12] C.Flanaganand S.Qadeer. Thread-modular model checki ng.
InSPIN,pages 213–224, 2003.
[13] M. K.Ganai and A.Gupta. Efﬁcientmodeling of concurren t
systems inBMC. In SPIN,pages 114–133, 2008.
[14] P.Godefroid. Partial-Order Methods for the Veriﬁcationof
Concurrent Systems: AnApproach tothe State-Explosion
Problem.Springer-VerlagNew York,Inc., Secaucus, NJ,
USA,1996.
[15] AlexeyGotsman, Josh Berdine, ByronCook, andMooly
Sagiv. Thread-modular shape analysis. In PLDI,pages
266–277, 2007.
[16] S.Graf andB.Steffen. Compositional minimization of ﬁ nitestate systems. In CAV’90, pages 186–196, London, UK,
1991. Springer-Verlag.
[17] Thomas A. Henzinger, Ranjit Jhala, andRupak Majumdar.
Race checking by context inference. SIGPLANNot. ,
39(6):1–13, 2004.
[18] CliffB.Jones. Tentative steps toward a development me thod
for interferingprograms. ACM Trans.Program. Lang. Syst. ,
5(4):596–619, 1983.
[19] James C.King. Symbolic execution and program testing.
Commun. ACM ,19(7):385–394, 1976.
[20] S.K.Lahiri,S.Qadeer, and Z.Rakamaric. Staticandpre cise
detection ofconcurrency errors insystems code using smt
solvers. In CAV,pages 509–524, 2009.
[21] A.Lal andT. W.Reps.Reducing concurrent analysis unde r a
context bound tosequential analysis. In CAV,pages 37–51,
2008.
[22] A.Lal,T. Touili,N.Kidd, andT. W.Reps. Interprocedur al
analysis of concurrent programs under a context bound. In
TACAS,pages 282–298, 2008.
[23] John McCarthy. A Basisfor a Mathematical Theory of
Computation. InP.Braffort andD.Hirschberg, editors,
Computer Programming and Formal Systems , pages 33–70.
North-Holland, Amsterdam, 1963.
[24] S.S.Muchnick. Advanced Compiler Design and
Implementation . M. Kaufmann, 1997.
[25] M. Musuvathi and S.Qadeer. Iterativecontext bounding for
systematic testingof multithreaded programs. In PLDI,
pages 446–455, 2007.
[26] S.S.Owickiand D.Gries.Verifyingproperties of paral lel
programs: Anaxiomatic approach. Commun. ACM ,
19(5):279–285, 1976.
[27] S.Qadeer and J.Rehof. Context-bounded model checking of
concurrent software. In TACAS,pages 93–107, 2005.
[28] Shaz Qadeer, SriramK.Rajamani, and Jakob Rehof.
Summarizingprocedures inconcurrent programs. In POPL,
pages 245–255, 2004.
[29] I.Rabinovitz andO. Grumberg. Bounded model checking o f
concurrent programs. In CAV,pages 82–97, 2005.
[30] Thomas Reps, SusanHorwitz, andMooly Sagiv. Precise
interprocedural dataﬂow analysis via graphreachability. In
POPL,pages 49–61, New York, NY,USA,1995. ACM.
[31] M. Sharirand A.Pnueli.Twoapproaches tointerprocedu real
data ﬂow analysis. In Program FlowAnalysis: Theory and
Applications , volume 5, pages 189–234. PrenticeHall,1981.
[32] B.Steensgaard. Points-toanalysis inalmost linear ti me.In
POPL,1996.
[33] ViktorVafeiadis and Matthew J.Parkinson. A marriage o f
rely/guarantee and separationlogic. In CONCUR ,pages
256–271, 2007.
[34] C.Wang, S.Chaudhuri, A.Gupta, and Y.Yang. Symbolic
pruning of concurrent program executions. In
ESEC/SIGSOFTFSE ,pages 23–32, 2009.
[35] C.Wang, S.Kundu, M. K. Ganai,and A.Gupta. Symbolic
predictive analysis for concurrent programs. In FM, pages
256–272, 2009.
[36] K.Yoravand O.Grumberg. Staticanalysis for state-spa ce
reductions preserving temporal logics. Form. Methods Syst.
Des.,25(1):67–96, 2004.Summarization. Fig. 4 (next page) presents the complete set
of rules for thread-modular summarization of a CCFG. For a no de
n,In(/an}bracketle{tψ,L,E/an}bracketri}ht)denotes the incomingsymbolic stateat n;tid(n)
is the numeric identiﬁer of the thread containing n;iterepresents
theif-then-else operator. On analyzing each function f, we obtain
an interference skeleton ISforfhaving global accesses contained
inf. Note thatISin the above rules denotes the skeleton for the
function containing the CCFGnode being analyzed.
Most rules are same as those in the Fig. 2 except the new rules:
INIT-F, MK-SUMMARY and FUNC-CALL.At the entry location
entry(f)of each function f, the INIT rule initializes the local
memory to Lf
0and the interference skeleton ISforfto an empty
set. The rule MK-SUMMARY is used to construct the summary
χffor a function fat its exit node n=exit(f) consisting of the
skeletonIScomputed for fand the state In.
TheruleFUNC-CALLisusedtoevaluateandreuseapreviously
computedsummaryfor fatacallnode nusingtheevaluationoper-
atorΓ. Supposewehaveasummary χf= (ISf,If)forafunction
fwhereISf= (Sf,≺Sf)andIf=/an}bracketle{tψf,Lf,Ef/an}bracketri}htsuch that both
ISfandIfarerepresentedintermsoftheinputlocalmemorymap
L0
ftof. Givenapartialorder ≺,weuse ⊤(≺)and⊥(≺)todenote
the set of maximal(top) and minimal(bottom) elements in ≺. To
evaluateχfunder the calling context represented by the map L,
the function ΓsubstitutesL0
fbyLin all components of χf. Fur-
ther, all read placeholder values (due to interference abst raction)
are substituted by fresh placeholders in all components of χf. Af-
ter the above substitutions on χf, we obtain a skeleton (S′,≺S′),
path condition ψ′and memory map L′. The data propagated to
function returnnode n′inthe FUNC-CALLrule is now given by
/an}bracketle{tψ∧ψ′,L′,⊤(≺S′)/an}bracketri}ht
where, the path condition is computed by conjoining the inco ming
path condition ψwithψ′, the new local map is L′and the set of
last events contains the set of top events ⊤(≺S′)inS′. Moreover,
thecurrentinterferenceskeleton ISisupdatedtoaddpartialorders
between allevents in Eand set ⊥(≺S′)of bottom events in S′.
THEOREM 1.Theinterferenceskeleton IS= (S,≺S)isapre-
cise thread-modular summary of the ﬁnite CCFG. Moreover, ≺S
respects the program order.
Proof.Followsbyconstruction ofthedata ﬂowanalysis algorithm.
All the transformers and joins are precise. The set Emaintains the
program order and is usedtoconstruct ≺S.
THEOREM 2.A program path-consistent linearization IS′of
ISisfeasible iffitis sequentially consistent.
Proof.
(⇐) A sequential consistent linearization L, by deﬁnition, always
correspondstoasetofconcreteexecutiontraces. Let Tbeonesuch
trace. SinceLisprogrampath-consistent, Tcanbeobtainedbyin-
terleavingpaths fromtheindividual threadsintheCCFG.He nceL
is feasible.
(⇒) By deﬁnition, if a linearization IS′is feasible then it corre-
sponds to a concrete interleaved execution of the CCFG. All c on-
crete executions are sequentiallyconsistent. Hence, IS′issequen-
tiallyconsistent.
THEOREM 3.Suppose we have an sequentially consistent en-
coding Φfor a CCFG Cand a path condition φfor an error loca-
tionl. If(Φ∧φ)issatisﬁable, thenthereexistsafeasibleexecution
ofCtothe location l.
Proof.LetΦ = Φ IS∧ΦC. Letus associate a dummyglobal write
accesswwith location l, so thatocc(w) =φ. IfΦ∧φis satisﬁ-
able,thenwegetapartialorderrelation HBontheaccessesin IS.Remove the global accesses that don’t occur, i.e., occ(e)is false,
and those that happen after wfromHB. Collapse the partial or-
derHBinto a linearization Larbitrarily. Since ΦCis satisﬁed, so
Lis sequentially consistent. If Lis program path consistent also,
then by Theorem above, Lis feasible, and there exists a feasible
execution of Cthat ends at access w, i.e., location l. It remains
to show that Lis program path consistent. We show that Lcorre-
sponds to exactly one path for each thread sub-graph in betwe en a
FORK-JOIN node pair. We can concatenate such paths to obtain a
projectionof LonthefullCCFG C. Notethatsincepathcondition
φis satisﬁable, and path conditions are conjuncted at JOIN no des
for encoding ΦIS,Lmust correspond to at least one path for each
thread in the sub-graph. It remains to show that Lcannot contain
accesses from multiple paths in a thread. Consider a basic co n-
ditional branch-join sub-graph in a thread and the outgoing paths
fromthebranchnode. Duetotheencoding ΦIS,eitherallaccesses
on these paths occur, or don’t occur. So,exactly one outgoin g path
is feasible. By concatenating such feasible paths at each br anch
node, we obtainexactlyone feasible paththrough the thread .
Context-bounded analysis. We can restrict the solver to search
for executions limited to a ﬁxed context bound by adapting th e
encoding in [35] to our setting. More precisely, we introduc e a
new predicate Ctx(e)for each access e; We setCtx(w) = 0
for all initial writes w. Given two accesses e1ande2, we set
Ctx(e1)≤Ctx(e2)ife1ande2belong to the same thread and
e1≺ISe2. Otherwise,we addconstraints of the form
copy(r,w) =⇒(Ctx(r)< Ctx (w))
for each read rthat may-copy write wandMHP (r,w)holds.
These constraints ensure that if a read rcopies a concurrent write
w, then at least one context switch must happen in between. Let
theglobalaccess efbesuchthat ∀e∈S.(e≺Sef)(ifefdoesnot
exist,wecreateanewdummyaccess). Finally,torestrictth esearch
toagivenbound k,weaddtheconstraint Ctx(ef)≤k. Theproof
ofcorrectnessofthisencodingisastraightforwardextens ionofthe
proofin[35]andisomitted. Notethatourapproachdoesnotd upli-
cate the complete global state at each context switch locati on as in
previous approaches [21], whose cost is proportional to pro duct of
the number of global variables and the number of thread locat ions.
Instead, new placeholders are introduced lazilyonly at eac h global
readlocation, makingthecostlinearinthenumber ofglobal reads.INIT-Fn∈entry(f)
In(/an}bracketle{ttrue,L0
f,{}/an}bracketri}ht)IS= ({},{})GUARDng− →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)
ψg=eval(g,L)
I′
n(/an}bracketle{tψ∧ψg,L,E/an}bracketri}ht)ASGN-LOCnlhs:=rhs− − − − − − →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)
l=eval(lhs,L)v=eval(rhs,L)
I′
n(/an}bracketle{tψ,store (L,l,v),E/an}bracketri}ht)
ASGN-GLB-Rnlhs:=G[e]− − − − − − − →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)IS= (S,≺S)
l=eval(lhs,L)l′=eval(e,L)R= (l′,r,ψ)ris fresh
I′
n(/an}bracketle{tψ,store (L,l,r),{R}/an}bracketri}ht)IS= (S∪ {R},≺S∪{(e,R)|e∈E})
ASGN-GLB-WnG[e]:=rhs− − − − − − − →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)IS= (S,≺S)
l=eval(e,L)r=eval(rhs,L)W= (l,r,ψ)
I′
n(/an}bracketle{tψ,L,{W}/an}bracketri}ht)IS= (S∪ {W},≺S∪{(e,W)|e∈E})INTRA-JOINm→n m′→n(tid(m) =tid(m′) =tid(n))
Im(/an}bracketle{tψ1,L1,E1/an}bracketri}ht)I′
m(/an}bracketle{tψ2,L2,E2/an}bracketri}ht)
In(/an}bracketle{tψ1∨ψ2,ite(ψ1,L1,L2),E1∪E2/an}bracketri}ht)
FORKFORK (n)n→p n →c
tid(p) =tid(n)In(/an}bracketle{tψ,L,E/an}bracketri}ht)
Ip(/an}bracketle{tψ,L,E/an}bracketri}ht)Ic(/an}bracketle{tψ,Lc,E/an}bracketri}ht)Lcis freshINTER-JOINJOIN (n)p→n c →n tid (p) =tid(n)
Ip(/an}bracketle{tψp,Lp,Ep/an}bracketri}ht)Ic(/an}bracketle{tψc,Lc,Ec/an}bracketri}ht)
In(/an}bracketle{tψp∧ψc,Lp,Ep∪Ec/an}bracketri}ht)
MK-SUMMARYnreturn− − − − − →n′n=exit(f)In(/an}bracketle{tψ,L,E/an}bracketri}ht)
χf= (IS,/an}bracketle{tψ,L,E/an}bracketri}ht)
FUNC-CALLncallf− − − − →n′In(/an}bracketle{tψ,L,E/an}bracketri}ht)IS= (S,≺S) ((S′,≺S′),ψ′,L′) = Γ(χf,L)
I′
n(/an}bracketle{tψ∧ψ′,L′,⊤(≺S′)/an}bracketri}ht)IS= (S∪S′,≺S∪{(e,e′)|e∈E∧e′∈ ⊥(≺S′)})
Figure4: Complete set of summarization rules.
View publication stats