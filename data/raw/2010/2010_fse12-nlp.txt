Automated Extraction of Security Policies from
Natural-Language Software Documents
Xusheng Xiao1Amit Paradkar2Suresh Thummalapenta3Tao Xie1
1Dept. of Computer Science, North Carolina State University , Raleigh, NC, USA
2IBM T. J. Watson Research Center, Hawthorne, NY , USA
3IBM Research, Bangalore, India
1xxiao2@ncsu.edu,2paradkar@us.ibm.com,3surthumm@in.ibm.com,1xie@csc.ncsu.edu
ABSTRACT
Access Control Policies (ACP) specify which principals suc h as
users have access to which resources. Ensuring the correctn ess
and consistency of ACPs is crucial to prevent security vulne rabil-
ities. However, in practice, ACPs are commonly written in Na tu-
ral Language (NL) and buried in large documents such as requi re-
ments documents, not amenable for automated techniques to c heck
for correctness and consistency. It is tedious to manually e xtract
ACPs from these NL documents and validate NL functional re-
quirements such as use cases against ACPs for detecting inco nsis-
tencies. To address these issues, we propose an approach, ca lled
Text2Policy, to automatically extract ACPs from NL softwar e doc-
uments and resource-access information from NL scenario-b ased
functional requirements. We conducted three evaluations o n the
collected ACP sentences from publicly available sources al ong with
use cases from both open source and proprietary projects. Th e re-
sults show that Text2Policy effectively identiﬁes ACP sent ences
with the precision of 88.7% and the recall of 89.4%, extracts ACP
rules with the accuracy of 86.3%, and extracts action steps w ith the
accuracy of 81.9%.
Categories and Subject Descriptors
D.4.6 [ Operating Systems ]: Security and Protection — Access
Control; D.2.1 [ Software Engineering ]: Requirements/Speciﬁcations
Keywords
Access control, natural language processing, requirement s analysis
1. INTRODUCTION
Access control is one of the most fundamental and widely used
privacy and security mechanisms. Access control is often go verned
by an Access Control Policy (ACP) [36] that includes a set of r ules
specifying which principals (such as users or processes) ha ve ac-
cess to which resources. ACPs are crucial in preventing secu rity
vulnerabilities, since decisions (such as accept ordeny) on user re-
quests are based on ACPs. In ACP practice, there exist two maj or
issues that can result in serious consequences such as allow ing an
Permission to make digital or hard copies of part or all of thi s work for
personal or classroom use is granted without fee provided th at copies are not
made or distributed for proﬁt or commercial advantage and th at copies bear
this notice and the full citation on the ﬁrst page. Copyright s for components
of this work owned by others than ACM must be honored. Abstrac ting with
credit is permitted. To copy otherwise, to republish, to pos t on servers or to
redistribute to lists, requires prior speciﬁc permission a nd/or a fee.
SIGSOFT’12/FSE-20, November 10 - 18 2012, Cary, NC, USA
Copyright 2012 ACM 978-1-4503-1614-9/12/11 ...$15.00.unauthorized user to access protected resources: incorrec t speciﬁ-
cation of ACPs and incorrect enforcement of ACP speciﬁcatio ns in
the system implementation.
The ﬁrst issue of incorrect speciﬁcation of ACPs is primaril y
due to two reasons. First, ACPs contain a large number of com-
plex rules to meet various security and privacy requirement s. One
way to ensure the correctness of such complex rules is to leve rage
systematic testing and veriﬁcation approaches [20, 29] tha t accept
ACPs in a form of formal speciﬁcation. In practice, ACPs are c om-
monly written in Natural Language (NL) and are supposed to be
written in security requirements, a type of non-functional require-
ments. However, often ACPs are buried in NL documents such as
requirement documents. For example, consider the followin g ACP
sentence (i.e., sentence describing ACP rules) for iTrust [ 5, 41], an
open source health-care application: “The Health Care Personnel
(HCP) does not have the ability to edit the patient’s securit y ques-
tion and password” . This ACP sentence is not amenable for auto-
mated veriﬁcation, requiring manual effort in extracting t he ACP
from this sentence into an enforceable format such as the eXt en-
sible Access Control Markup Language (XACML) [3]. Second,
NL software documents could be large in size, often consisti ng of
hundreds or even thousands of sentences (iTrust consists of 37 use
cases [23] with 448 use-case sentences), where a portion of t he sen-
tences describing ACPs (117 sentences in iTrust) are buried among
other sentences. Thus, it is very tedious and error-prone to man-
ually inspect these NL documents for identifying and extrac ting
ACPs for policy modeling and speciﬁcation.
The second issue of incorrect enforcement of ACP speciﬁcati ons
is primarily due to the inherent gap between ACPs speciﬁed us -
ing domain concepts and the actual system implementation de vel-
oped using programming concepts. Functional requirements , such
as scenario-based requirements (e.g., use cases) that spec ify se-
quences of action steps1, bridge the gap, since they describe func-
tionalities to be implemented by developers using domain co ncepts.
For example, an action step “The patient chooses to view his or her
access log. ” in Use Case 8 of iTrust implies that the system shall
have the functionality for patient (domain concepts) to vie w his
or her access log. These action steps typically describe tha t actors
(principals) access different resources for achieving som e function-
alities and help developers determine what system function alities
to implement. Therefore, policy authors can validate actio n steps
against provided ACPs to detect inconsistencies of resourc e access,
also helping the policy authors construct consistent ACPs f or the
system. In practice, manually inspecting large functional require-
ments to extract resource-access information is also labor -intensive
and tedious. For example, a proprietary IBM enterprise appl ication
1We use the term of an action step rather than action to distinguish
the term from an action in the access control model described later.(that we used in our evaluations) includes 659 use cases with 8,817
sentences.
In general, like other types of NL documents, NL requirement s
written in English are unstructured and can be ambiguous or i n-
clude implicit information, posing signiﬁcant challenges for Natu-
ral Language Processing (NLP). However, in software docume nts
such as functional and non-functional requirements, ACP se ntences
(i.e., NL security requirements for describing ACP rules) t end to
follow speciﬁc styles such as: [subject] [can/cannot/is allowed to]
[action] [resource] for role-based ACPs [16]. For example, based
on our manual inspection of 217 ACP sentences collected from the
iTrust requirements and various security requirements in p ublished
articles and web sites [6], about 85% of the ACP sentences fol low
this style. Similarly, to provide communication values, fu nctional
requirements such as use cases are usually written in a relat ively
simple, consistent, and straightforward style [12, 24].
To tackle the problem, in this paper, we propose a novel ap-
proach, called Text2Policy, which adapts NLP techniques de signed
around a model (such as the ACP model and the action-step mode l)
to automatically extract model instances from NL software d oc-
uments and produce formal speciﬁcations. Our general appro ach
consists of three main steps: (1) apply linguistic analysis to parse
NL documents and annotate words and phrases in sentences fro m
NL documents with semantic meanings, (2) construct model in -
stances using annotated words and phrases in the sentences, and
(3) transform these model instances into formal speciﬁcati ons.
Speciﬁcally, we provide techniques to concretize our gener al ap-
proach for extracting role-based ACPs and action steps from NL
software documents and functional requirements, respecti vely. From
the extracted ACPs, our approach automatically generates m achine-
enforceable ACPs in speciﬁcation languages such as XACML. T hese
ACPs can be used by automatic testing and veriﬁcation approa ches [20,
29] for checking policy correctness or serve as an initial ve rsion of
ACPs for policy authors to improve. From each extracted acti on
step, our approach automatically derives an access control request.
An example request could be that a principal requests access to a
resource with the expected permit or deny decision. Such der ived
requests can be used for automatic validation against speci ﬁed or
extracted ACPs for detecting inconsistencies.
This paper makes the following main contributions:
•A novel approach, called Text2Policy, which provides a gen-
eral framework that incorporates syntactic and semantic NL
analyses to extract model instances from NL software docu-
ments and produces formal speciﬁcations. Our work demon-
strates that manual effort can be reduced with automated ex-
traction of security policies from NL documents in a spe-
ciﬁc domain such as security requirements written in speciﬁ c
styles.
•Analysis techniques that concretize our general approach f or
extracting role-based ACP rules and action steps from NL
documents and functional requirements (such as use cases),
respectively.
•Three evaluations of Text2Policy on 37 iTrust [5, 41] use
cases, 25 use cases from a module in a proprietary IBM enter-
prise application (in the ﬁnancial domain), and the collect ed
115 ACP sentences from 18 publicly available sources (pub-
lished papers and public web sites). The results show that (1 )
Text2Policy effectively identiﬁes ACP sentences from 927
use-case sentences with the precision of 88.7% and the re-
call of 89.4%, (2) Text2Policy effectively extracts ACP rul es
from 241 ACP sentences with the accuracy of 86.3%, (3)ACP-1: An HCP should not change a patient’s account.
ACP-2: An HCP is disallowed to change a patient’s
account.
Figure 1: Example ACP sentences written in NL.
Text2Policy effectively extracts action steps from 767 act ion-
step sentences with the accuracy of 81.9%,2and (4) Text2Policy
helps us identify a name inconsistency of iTrust use cases us -
ing the extracted ACP rules and action steps.
2. BACKGROUND AND EXAMPLES
In this section, we ﬁrst introduce the background of the ACP
model used for representing ACPs in our approach, and then de -
scribe the background of the action-step model used for repr esent-
ing action steps in our approach.
2.1 ACP Model and XACML
This section provides the background information about our ACP
model and XACML.
2.1.1 ACP Model
An ACP consists of a set of ACP rules. A typical role-based
ACP rule consists of four elements: subject, action, resour ce, and
effect [3, 16]. Figure 1 shows two example ACP rules. The subj ect
element describes a principal such as a user or process that m ay
request to access resources (e.g., an HCP in ACP-1). The action
element describes an action (e.g., change in ACP-1) that the prin-
cipal may request to perform. The resource element describe s the
resource (e.g., a patient’s account in ACP-1) to which access is re-
stricted. A rule can have one of various effects (i.e., permi t, deny,
oblige, or refrain). In this paper, we focus on permit rules a nd deny
rules (i.e., rules with permit or deny effects), which are co mmonly
used in various software systems for granting or blocking ac cesses
to protected resources. A permit rule allows a principal to access a
resource, whereas a deny rule, such as ACP-1 and ACP-2, prevents
a principal from accessing a resource.
2.1.2 XACML
The eXtensible Access Control Markup Language (XACML) [3]
is an XML-based general-purpose language used to describe p oli-
cies, requests, and responses for ACPs, recognized as a stan dard by
the Organization for the Advancement of Structured Informa tion
Standards (OASIS). XACML is designed to replace applicatio n-
speciﬁc and proprietary ACP languages, thus enabling commu ni-
cation among applications created by different applicatio n vendors.
In an application deployed with XACML-based access control ,
before a principal can perform an action on a particular reso urce,
a Policy Enforcement Point (PEP) sends a request formulated in
XACML to the Policy Decision Point (PDP) that stores princip al-
speciﬁc XACML ACP rules. The PDP determines whether the
request should be permitted or denied by evaluating the poli cies
whose subject, action, and resource elements match the requ est.
Finally, the PDP formulates its decision in the XACML respon se
language and sends it to the PEP, which enforces the decision .
Currently, XACML has been widely supported by all the main
platform vendors and extensively used in a variety of applic ations [28].
Recent research also provides systematic testing and veriﬁ cation
approaches [20,29] for ensuring the correct speciﬁcation o f XACML
rules. There also exist XACML-based research tools used in v ari-
2The evaluation artifacts and detailed results of the iTrust use cases
and the collected ACP sentences are publicly available on ou r
project web site [6].AS-1: An HCP creates an account.
AS-2: He edits the account.
AS-3: The system updates the account.
AS-4: The system displays the updated account.
Figure 2: An example use case.
ous agencies/labs and companies [21]. Thus, we choose XACML
as the formal speciﬁcation to model ACP.
2.2 Action-Step Model
Use cases [22] are scenario-based requirements speciﬁcati ons
that consist of sequences of action steps for illustrating b ehaviors of
software systems. These action steps describe how actors in teract
with software systems for exchanging information. Actors a re en-
tities outside software systems (such as users) that intera ct with the
systems by providing input to the systems (e.g., in Action St ep AS-
2 shown in Figure 2) or receiving output from the systems (e.g .,
in AS-4 shown in Figure 2). Since action steps describe how ac -
tors access or update information (resources) of the system s, each
action step can be considered to encode an access control req uest
that an actor requests to access the resources and expect the request
to be permitted. Using the access control requests with expe cted
permit decisions derived from action steps, we can automati cally
validate such requests with expected decisions against spe ciﬁed or
extracted ACPs to detect inconsistencies.
We represent the contents of use cases (sequences of action s teps)
in a formal representation. The content of a NL use case conta ins a
list of sentences, each of which in turn contains one or more a ction
steps initiated by some actor (e.g., an HCP in AS-1 shown in Figure
2). Each action step has an action associated with a classiﬁc ation,
such as the INPUT classiﬁcation for the action of providing i nfor-
mation (e.g., edits in AS-2 shown in Figure 2) and the OUTPUT
classiﬁcation for the action of receiving information (e.g .,display
in AS-4 shown in Figure 2). An action step is also associated t o
one or more actors and has a set of parameters. These paramete rs
represent the resources created, modiﬁed, or used by the act ions. In
Figure 2, AS-2 shows a resource account that is modiﬁed.
3. CHALLENGES AND EXAMPLES
In this section, we ﬁrst describe the technical challenges f aced by
ACP extraction and action-step extraction. We next use exam ples
to illustrate how Text2Policy extracts ACPs and action step s from
NL documents and NL use cases, respectively.
3.1 Technical Challenges
As a common technical challenge for both ACP extraction and
action-step extraction, TC1-Anaphora refers to identifying and re-
placing pronouns with noun phrases based on the context. For ex-
ample, the pronoun hein AS-2 shown in Figure 2 needs to be re-
placed with the HCP from AS-1. For ACP extraction, there are two
unique technical challenges: (1) TC2-Semantic-Structure Variance.
ACP-1 and ACP-2 in Figure 1 use different ways (semantic stru c-
tures) to describe the same ACP rule; (2) TC3-Negative-Meaning
Implicitness . An ACP sentence may contain negative expressions,
such as ACP-1. Additionally, the verb in the sentence may hav e
negative meaning, such as disallow in ACP-2. For action-step ex-
traction, there are two unique challenges: (1) TC4-Transitive Actor .
AS-3 implies that an HCP (the actor from AS-2) is the initiating
actor of AS-3; (2) TC5-Perspective Variance . AS-4 implies that an
HCP views the updated account , requiring a conversion to replace
the actor and action of AS-4.
To address TC1-Anaphora , we adapt the technique Anaphora
Resolution , specializing the anaphora algorithm introduced by Kenned y<Policy PolicyId="2" RuleCombAlgId="...">
<Target/>
<Rule Effect="Deny" RuleId="rule-1">
<Target>
<Subjects><Subject>
<SubjectMatch MatchId="string-equal">
<AttrValue> HCP</AttrValue>
<SubjectAttrDesignator AttrId="subject:role"/>
</SubjectMatch></Subject></Subjects>
<Resources><Resource>
<ResourceMatch MatchId="string-equal">
<AttrValue> patient.account </AttrValue>
<ResourceAttrDesignator AttrId="resource-id"/>
</ResourceMatch></Resource></Resources>
<Actions><Action>
<ActionMatch MatchId="string-equal">
<AttrValue> UPDATE</AttrValue>
<ActionAttriDesignator AttrId="action-id"/>
</ActionMatch></Action></Actions></Target>
</Rule></Policy>
Figure 3: Generated XACML ACP for ACP-2 in Figure 1.
et al. [27] to identify and replace pronouns with noun phrase s based
on the context. To address TC2-Semantic-Structure Variance , we
propose a technique, called Semantic-Pattern Matching , which uses
different semantic patterns based on the grammatical funct ions (sub-
ject, main verb, and object) to match different semantic str uctures
of ACP sentences. To address TC3-Negative-Meaning Implicitness ,
we propose an inference technique, called Negative-Meaning Infer-
ence, which infers negative meaning by using patterns to identif y
negative expressions and a domain dictionary to identify ne gative
meaning of verbs. To address TC4-Transitive Actor , we propose
an analysis technique, called Actor-Flow Tracking . This technique
ﬁrst tracks non-system actors in action steps. Later, when t he anal-
ysis encounters action steps that have only system actors, i t re-
places system actors with tracked non-system actors. To add ress
TC5-Perspective Variance , we propose an analysis technique, Per-
spective Conversion . This technique tracks non-system actors of
action steps. Later when the analysis encounters action ste ps that
have only system actors and output information from the syst em,
it replaces the system actors with tracked non-system actor s and
replaces output actions with read actions (such as view).
3.2 Example of ACP Extraction
Text2Policy adapts NLP techniques that incorporate syntac tic
and semantic analyses to parse NL software documents, const ructs
ACP model instances, and produces formal speciﬁcations.
In particular, Text2Policy ﬁrst applies shallow parsing [3 2] that
annotates sentences with phrases, clauses, and grammatica l func-
tions of phrases, such as subject, main verb, and object. For exam-
ple, the shallow-parsing component parses ACP-1 in Figure 1 as
[subject: An HCP ] [main verb group: should not change ] [object:
a patient’s account. ]. Text2Policy then uses the domain dictionary
to associate verbs with pre-deﬁned semantic classes. For ex ample,
in ACP-2, the domain dictionary is used to associate change with
the UPDATE semantic class, and disallow with the NEGATIVE
semantic class.
To determine whether a sentence describes an ACP rule (i.e., is
an ACP sentence) and extract elements of subject, action, an d re-
source, Text2Policy composes semantic patterns using the i denti-
ﬁed grammatical functions of phrases and clauses extracted by the
shallow-parsing component. For example, ACP-1 can be match ed
by the semantic pattern Modal Verb in Main Verb Group , and the
constructed model instance of ACP-1 is [Subject: HCP ] [Action:
change - UPDATE ] [Resource: patient.account ].
To infer the effect for an ACP rule, Text2Policy checks wheth er
the corresponding sentence contains any negative expressi on and
whether the main verb group is associated with the NEGATIVEFigure 4: An example action step.
semantic class. For example, Text2Policy identiﬁes the neg ative
expression of should not change in ACP-1 and infers the effect of
ACP-1 as deny.
Using the extracted ACP-model elements and the inferred ef-
fect, Text2Policy constructs an ACP model instance for each ACP
sentence and generates ACP rules in XACML. Figure 3 shows the
generated XACML ACP for ACP-2.
3.3 Example of Action-Step Extraction
Action-step extraction uses similar linguistic analyses a s ACP
extraction. First, the techniques of shallow parsing and do main dic-
tionary are used to parse and annotate each sentence in use ca ses.
Next, the technique of anaphora resolution is used to identi fy and
replace pronouns (from the sentence) with the noun phrases b ased
on the context. For example, Hein AS-2 is replaced with HCP .
Text2policy then uses a syntactic pattern to check whether t he sen-
tence has required elements (subject, main verb group, and o bject)
for constructing an action step, and constructs a model inst ance if
all the elements are found.
Consider the example use case shown in Figure 2. Since all sen -
tences include the required elements, Text2policy constru cts model
instances of these action steps associated with actors (the system ,
HCP ), action types representing the classiﬁcation of the actio ns
(e.g., the classiﬁcation of display in AS-4 as OUTPUT), and pa-
rameters (the account ). For example, the model instance of AS-1
is shown in Figure 4. In addition, since AS-3 and AS-4 have the
system as the actor, Text2policy further applies the techniques fo r
TC4-Transitive Actor andTC5-Perspective Variance on AS-3 and
AS-4 to replace the actors and actions.
4. APPROACH
In this section, we describe our general approach for extrac ting
model instances from NL documents and producing formal spec -
iﬁcation. Our approach consists of three main steps: Lingui stic
Analysis, Model-Instance Construction, and Transformati on.
Figure 5 shows the overview of our approach. Our approach ac-
cepts NL software documents as input and applies linguistic anal-
ysis to parse the NL software documents and annotates their s en-
tences with semantic meanings for words and phrases. Using t he
annotated sentences, our approach constructs model instan ces. Based
on provided transformation rules, our approach transforms the model
instances to formal speciﬁcations, which can be automatica lly checked
for correctness and consistencies.
4.1 Linguistic Analysis
The linguistic-analysis component includes adapted NLP te ch-
niques that incorporate syntactic and semantic NL analyses to parse
the NL software documents and annotate the words and phrases in
the document sentences with semantic meaning. We next descr ibe
the common linguistic-analysis techniques used for both AC P ex-
traction and action-step extraction, and describe the uniq ue analysis
techniques proposed for ACP extraction and action-step ext raction,
respectively.
Figure 5: Overview of our approach.
4.1.1 Common Linguistic-Analysis Techniques
In this section, we describe the common linguistic-analysi s tech-
niques used in our general approach: shallow parsing and dom ain
dictionary.
Shallow Parsing. Shallow parsing determines the syntactic struc-
tures of sentences in NL documents. Research [18, 40] has sho wn
the efﬁciency of shallow parsing based on ﬁnite-state techn iques
and the effectiveness of using ﬁnite-state techniques for l exical lookup,
morphological analysis, Part-Of-Speech (POS) determinat ion, and
phrase identiﬁcation. Sinha et al.’s work [39] also shows th at the
shallow-parsing analysis is effective and efﬁcient for sem antic and
discourse processing. Therefore, our approach chooses a sh allow
parser that is fully implemented as a cascade of several Fini te-State
Transducers (FSTs), described in detail by Boguraev [8].
In the shallow parser, an FST identiﬁes phrases, clauses, an d
grammatical functions of phrases by recognizing patterns o f POS
tags and already identiﬁed phrases and clauses in the text. T he
lowest level of the cascade recognizes simple Noun Group (NP )
and Verb Group (VG) grammars. For example, ACP-1 is parsed as
[NP: An HCP ] [VG: should not change ] [NP: patient’s account. ].
Later stages of the cascade try to build complex phrases and i den-
tify clause boundaries based on patterns of already identiﬁ ed tokens
and phrases. For example, to change patient’s account in ACP-2 is
recognized as a to-inﬁnitive clause. The ﬁnal set of FSTs mar ks
grammatical functions such as subjects, main verb group, an d ob-
jects. As an example, the shallow parser ﬁnally parses and an no-
tates ACP-1 as [subject: An HCP ] [main verb group: should not
change ] [object: patient’s account. ].
Domain Dictionary. The domain dictionary is used to associate
verbs with pre-deﬁned semantic classes. There are two beneﬁ ts
of associating verbs with semantic classes. The ﬁrst beneﬁt is to
help address TC3-Negative-Meaning Implicitness . Consider ACP-
2 shown in Figure 1. Without the NEGATIVE semantic class asso -
ciated with the main verb group ( is disallowed ), our analysis would
incorrectly infer the effect as permit instead of deny. The second
beneﬁt is to identify verb synonyms, such as change andupdate .
During validation of action-step information against ACPs , our ap-
proach uses verb synonyms to match access requests (transfo rmed
from action steps) with an applicable ACP rule.
The domain dictionary is used to associate each verb entry wi th
a semantic class. Besides the NEGATIVE class that we mention ed
earlier, a verb entry can be associated with a semantic class that is
a kind of operation [38, 39], e.g., OUTPUT ( view ordisplay ) and
UPDATE ( change oredit). To achieve so, we populate the domain
dictionary with an initial set of commonly used verb entries and
their respective semantic classes. We then use WordNet [15] , a
large lexical database of English, to further expand the ent ries with
their synonyms.
Currently, we implement the domain dictionary as an extensi ble
and externalizable XML Blob and the content is populated man u-
ally. One major limitation of using an XML Blob is that unmatc hed
verbs (i.e., ones without matched entries in the dictionary ) are as-Table 1: Identiﬁed subject, action, and resource elements i n sentences matched with semantic patterns for ACP sentence s.
Semantic Pattern Examples
Modal Verb in Main Verb GroupAn HCP [subject ]can view [action]the patient’s account [resource ].
An admin [subject ]should not update [action]patient’s account [resource ].
Passive V oice followed by To-inﬁnitive PhraseAn HCP [subject ]is disallowed to update [action]patient’s account [resource ].
An HCP [subject ]is allowed to view [action]patient’s account [resource ].
Access ExpressionAn HCP [subject ]has read [action]access to patient’s account [resource ].
A patient’s account [resouce ]is accessible [action]toan HCP [subject ].
Ability ExpressionAn HCP [subject ]is able to read [action]patient’s account [resource ].
An HCP [subject ]has the ability to read [action]patient’s account [resource ].
signed with the UNCLASSIFIED semantic class. In future work ,
we plan to extend our technique to query WordNet dynamically
when an unmatched verb or adjective is encountered. For exam -
ple, by querying WordNet for synonyms, we can assign to an un-
matched verb the semantic class of its most similar verb amon g its
matched synonyms. Alternatively, we can assign to an unmatc hed
verb the semantic class that is most common among the unmatch ed
verb’sk-nearest neighbors.
Anaphora Resolution. To address TC1-Anaphora , our approach
includes the anaphora-resolution technique to identify an d replace
pronouns with the noun phrases that they refer to. To resolve anaphora
encountered during use-case parsing, we adapt the anaphora algo-
rithm introduced by Kennedy et al. [27] with an additional ru le: a
pronoun in the position of a subject is replaceable only by no un
phrases that also appear as subjects of a previous sentence. As an
example, hein AS-2 shown in Figure 2 is replaced by the HCP , the
actor of AS-1.
4.1.2 ACP Linguistic Analysis
In this section, we describe unique linguistic-analysis te chniques
proposed for ACP extraction.
Semantic-Pattern Matching. To address TC2-Semantic-Structure
Variance , we provide the technique of semantic-pattern matching
to identify whether a sentence is an ACP sentence. We compose
different semantic patterns based on the grammatical funct ion of
phrases identiﬁed by shallow parsing. These semantic patte rns are
more general and more accurate than templates written using low-
level syntactical structures, such as POS tags [14]. Our app roach
uses this technique while identifying subject, action, and resource
elements for an ACP rule.
Table 1 shows the semantic patterns used in our approach. The
text in bold shows the part of a sentence that matches a given s e-
mantic pattern. The ﬁrst pattern, Modal Verb in Main Verb Group ,
identiﬁes sentences whose main verb contains a modal verb. T his
pattern can identify ACP-1 shown in Figure 1. The second patt ern,
Passive Voice followed by To-inﬁnitive Phrase , identiﬁes sentences
whose main verb group is passive voice and is followed by a to-
inﬁnitive phrase. This pattern can identify ACP-2 shown in F igure
1. The third pattern, Access Expression , captures different ways of
expressing that a principal can have access to a particular r esource.
The fourth pattern, Ability Expression , captures different ways of
expressing that a principal has the ability to access a parti cular re-
source. Using the semantic patterns, our approach ﬁlters ou t NL-
document sentences that do not match with any of these provid ed
patterns.
Negative-Expression Identiﬁcation. Negative expressions in
sentences can be used to determine whether the sentences hav e neg-
ative meaning. To identify negative expressions in a senten ce, ourapproach composes patterns to identify negative expressio ns in a
subject and main verb group. For example, “ No HCP can edit pa-
tient’s account. ” has noin the subject. As another example, “ An
HCP can never edit patient’s account. ” has never in the main verb
group. ACP-1 in Figure 1 contains a negative expression in th e
main verb group. Our approach uses the negative-expression iden-
tiﬁcation while inferring policy effect for an ACP rule.
4.1.3 Use-Case Linguistic Analysis
In this section, we describe a unique linguistic-analysis t ech-
nique proposed for action-step extraction.
Syntactic-Pattern Matching. To identify whether a sentence
is an action-step sentence (i.e., describing an action step ), our ap-
proach includes the technique of syntactic-pattern matchi ng that
identiﬁes sentences with syntactic elements (subject, mai n verb
group, and object) required for constructing an action step . To im-
prove precision in identifying sentences describing users access-
ing resources, our approach further checks whether the subj ect is
a user of the system and whether the object is a resource deﬁne d
in the system. For example, our approach ignores the sentenc e
“The prescription list should include medication, the name of the
doctor. . . ” [5, 41], since its subject prescription list is not a user
of the system. Moreover, our approach also uses the techniqu e
of negative-meaning inference (described later in Section 4.3.1)
to ﬁlter out sentences that contain negative meaning, since these
negative-meaning sentences tend not to describe action ste ps.
4.2 Model-Instance Construction
After our approach uses linguistic-analysis techniques to parse
the input NL documents, words and phrases in the sentences of the
NL documents are annotated with semantic meaning. For examp le,
shallow parsing annotates phrases as subjects, main verb gr oups,
and objects. To construct model instances from these senten ces,
our approach uses the annotated information of words and phr ases
to identify necessary elements for a given model.
4.2.1 ACP-Model Construction
To construct model instances for ACP rules, our approach ide n-
tiﬁes subject, action, resource elements based on the match ed se-
mantic patterns and infers the policy effect based on the pre sence
or absence of negative expressions in sentences.
Model-Element Identiﬁcation. Based on the matched semantic
patterns, our approach identiﬁes subject, action, resourc e elements
from different syntactic structures in sentences.
Table 1 shows the identiﬁed subject, action, and resource el e-
ments (underlined words) in the sentences matched with sema ntic
patterns. For a sentence that matches the ﬁrst pattern, Modal Verb
in Main Verb Group , our approach identiﬁes the subject of the sen-tence as a subject element, the verb (not the modal verb) in th e main
verb group as an action element, and the object of the sentenc e as
a resource element. For a sentence that matches the second pa t-
tern, Passive Voice followed by To-inﬁnitive Phrase , our approach
identiﬁes the subject of the sentence as a subject element an d iden-
tiﬁes action and resource elements from the verb and object i n the
to-inﬁnitive phrase, respectively. For the ﬁrst example of the third
pattern, Access Expression , our approach identiﬁes the subject of
the sentence as a subject element, the noun read in the main verb
group as an action element, and the noun phrase patient’s account
in the prepositional phrase to patient’s account as a resource ele-
ment. For the second example of the third pattern, our approa ch
identiﬁes the subject patient’s account as the resource element, the
adjective accessible as an action, and the object HCP as the sub-
ject element. For the sentences that match the fourth patter n, our
approach identiﬁes the subject of the sentence as a subject e lement
and identiﬁes action and resource elements from the verb and ob-
ject in the to-inﬁnitive phrase, respectively.
Policy-Effect Inference. To address TC3-Negative-Meaning Im-
plicitness , our approach includes the technique of negative-meaning
inference. If an ACP sentence contains negative meaning, we infer
the policy effect to be deny (permit otherwise). To infer whe ther a
sentence has negative meaning, the technique of negative-m eaning
inference considers two factors: negative expression and n egative-
meaning words in the main verb group. Recall that negative ex -
pressions is identiﬁed using the technique of negative-exp ression
identiﬁcation in Section 4.1.2. ACP-1 in Figure 1 contains a nega-
tive expression in the main verb group. To determine whether there
are negative meaning words in the main verb group, our approa ch
checks the semantic class associated with the verb in the mai n verb
group. If the semantic class is NEGATIVE, we consider the sen -
tence has negative meaning. ACP-2 has a negative meaning wor d,
disallow , in the main verb group, and therefore its inferred policy
effect is deny.
Model-Instance Construction. Using the identiﬁed elements
(subject, action, and resource) and inferred policy effect , our ap-
proach constructs an ACP-model instance for an ACP sentence .
Moreover, our approach provides techniques to deal with a po sses-
sive noun phrase, such as patient’s account orthe account of pa-
tient. Our approach extracts the possessor as an entity and the pos -
sessed item as its property. As a complete example, the const ructed
model instance of ACP-2 is [Subject: HCP ] [Action: change -
UPDATE ] [Resource: patient.account. ] [Effect: deny]. Here the
technique of domain dictionary associates the verb change with the
semantic class UPDATE.
4.2.2 Action-Step-Model Construction
To construct model instances for action steps described in s en-
tences, our approach identiﬁes actor, action, and paramete r ele-
ments based on the use-case patterns. Our approach includes two
additional new techniques to address TC4-Transitive Actor andTC5-
Perspective Variance .
Model-Element Identiﬁcation. Our approach uses known pat-
terns of use-case action steps to identify action, actor, an d param-
eter elements for action steps. We devise these patterns bas ed on
industry use cases [39], iTrust use cases, and use cases coll ected
from published articles [35]. One of the most used patterns i s to
identify the subject of a sentence as an actor element, the ve rb in
the main verb group as an action element, and the object of the
sentence as a parameter element. These patterns could be eas ily
updated or extended based on the domain characteristics of t he use
cases for improving the precision of extracting actor, acti on, and
parameter elements.Model-Instance Construction. Using the identiﬁed actor, ac-
tion, and parameter elements in a sentence, our approach con structs
action-step model instances for action steps described in t he sen-
tence. For example, the model instance for A patient views access
logis [Actor: patient ] [Action: view - READ ] [Parameter: access
log]. Here the technique of domain dictionary associates the ve rb
view with the semantic class READ.
Algorithm 1 Actor-Flow Tracking
Require: ASs for action steps in a use case
1:trackedActor =NULL
2:forASinASs do
3:Actors=getActors (AS)
4:onlySystemActor =TRUE
5: foractor inActors do
6: if!isSystemActor (actor)then
7: onlySystemActor =FALSE
8: break
9: end if
10: end for
11: if!onlySystemActor then
12: trackedActor =getNonSystemActor (Actors)
13: continue
14: end if
15: iftrackedActor ! =NULL then
16: replaceActors (AS,trackedActor )
17: end if
18:end for
Actor-Flow Tracking. To address TC4-Transitive Actor , we ap-
ply data-ﬂow tracking on non-system actors of an action step . We
consider subjects (such as the system in AS-3) with some speciﬁc
names as system actors. Non-system actors can usually be obt ained
from the glossary of requirements documents. Algorithm 1 sh ows
the Actor-Flow Tracking (AFT) algorithm.
We next illustrate the algorithm using the example shown in F ig-
ure 1. AFT ﬁrst checks AS-1 and tracks the actor of AS-1 since i ts
actor is a non-system actor ( HCP ) (satisfying the condition at Line
11). AFT then checks AS-2 and tracks the actor of AS-2 ( HCP ,
replaced by anaphora resolution) since its actor is also HCP . When
AFT checks AS-3, AFT ﬁnds that AS-3 has only the system as its
actor (satisfying the condition at Line 15) and replaces the system
with HCP as the actor of AS-3.
Perspective Conversion. To address TC5-Perspective Variance ,
we use a similar algorithm as AFT. The only difference is to re -
place the condition at Line 15 as trackActor ! =NULL AND
getActionType (AS) ==OUTPUT , and to replace the state-
ment at Line 16 as convertPerspective (AS,trackActor ). Con-
sider the same example shown in Figure 1. When the algorithm
reaches AS-4, the tracked actor is HCP . Since AS-4 has system as
its only subject and its action type is OUTPUT ( displays ), our ap-
proach converts AS-4 into An HCP views the updated account by
replacing its actor elements with the tracked actors and its action
element with a verb entry whose classiﬁcation is READ in the d o-
main dictionary, such as view. Such conversion helps our approach
to correctly extract access requests from action steps.
4.3 Transformation
With the formal model of ACPs, our approach can use differ-
ent transformation rules to transform model instances into formal
speciﬁcations, such as XACML [3].
ACP Model. Currently, our approach supports the transforma-
tion of each ACP rule into an XACML policy rule. Our approachTable 2: Metrics for addressing research questions.
RQ Metrics
RQ1Precision =TP
TP+FP,Recall=TP
TP+FN,F1-Score=2∗Precision ∗Recall
Precision +Recall
TP: True positives, FP: False positives, FN: False negatives
RQ2 Accuracy =C
TC: Number of correct ACP rules extracted by Text2Policy
T: Total number of ACP rules
RQ3 Accuracy =C
TC: Number of correct action-step sentences extracted by Text 2Policy
T: Total number of action-step sentences
transforms subject, action, and resource elements as the co rrespond-
ing subject, action, and resource sub-elements of the targe t element
for an XACML policy rule. Our approach then assigns the value of
the effect element to the value of the effect attribute of the XACML
policy rule to complete the construction of an XACML policy r ule.
Figure 3 shows the extracted XACML rule of ACP-2. More exam-
ples can be found on our project web site [6]. With more trans-
formation rules, our approach can easily transform the ACP m odel
instances into other speciﬁcation languages, such as EPAL [ 7].
Action-Step Model. Currently, our approach supports the trans-
formation of each action step into an XACML request [3] with t he
expected permit decision. For each action step, our approac h trans-
forms actor, action, and parameter elements as subject, act ion, and
resource elements of the request, respectively.
5. EV ALUATIONS
In this section, we present three evaluations conducted to a ssess
the effectiveness of Text2Policy. For our evaluations, we c ollected
use cases from an open source project iTrust [5, 41], 115 ACP s en-
tences from 18 sources (published papers, public web sites, and
iTrust), and 25 use cases from a module in a proprietary IBM en -
terprise application. We speciﬁcally seek to answer the fol lowing
research questions:
•RQ1 : How effectively does Text2Policy identify ACP sen-
tences in NL documents?
•RQ2 : How effectively does Text2Policy extract ACP rules
from ACP sentences?
•RQ3 : How effectively does Text2Policy extract action steps
from action-step sentences (i.e., sentences describing ac tion
steps)?
Table 2 shows metrics used to address our research questions .
To address RQ1, we used three metrics: precision, recall, an d F1-
Score. The ﬁrst row in Table 2 shows formulas for computing th ese
metrics. In these formulas, TP represents the number of correct
ACP rules identiﬁed by Text2Policy, whereas FP andFN repre-
sent the number of incorrect and missing ACP rules, respecti vely,
identiﬁed by Text2Policy. To address RQ2 and RQ3, we used the
accuracy metric shown in the second and third rows of Table 2,
respectively.
5.1 Subjects and Evaluation Setup
In our evaluations, we used three categories of subjects for ad-
dressing the three research questions. First, we used 37 use cases
from iTrust [5,41]. iTrust is an open source health-care app lication
that provides various features such as maintaining medical history
of patients, storing communications with doctors, identif ying pri-
mary caregivers, and sharing satisfaction results. The req uirements
documents and source code of iTrust are publicly available o n its
web site. iTrust requirements speciﬁcation has 37 use cases , 448use-case sentences, 10 non-functional-requirement sente nces, and
8 constraint sentences. The iTrust requirements speciﬁcat ion also
has a section, called Glossary, that describes the roles of u sers who
interact with the system.
We preprocessed the iTrust use cases so that the format of the use
cases can be processed by Text2Policy. In particular, we rem oved
symbols (e.g., [E1] and [S1]) that cannot be parsed by our ap-
proach. We replaced some names with comments quoted in paren -
thesis. For example, when we see A user (an LHCP or patient) , we
replaced A user with an LHCP or patient . We separated sentences
by replacing / with or. We also separated long sentences that span
more than 2 or 3 lines, since such style affects the precision of shal-
low parsing. The preprocessed documents of the iTrust use ca ses
are available on our project web site [6].
Second, we collected 100 ACP sentences from 17 sources (pub-
lished articles and public web sites). These ACP sentences a nd 117
NL ACP rules from the iTrust use cases are the subjects for our
evaluation to address RQ2. The document that contains the co l-
lected ACP sentences and their original sources can be downl oaded
from our project web site [6].
Third, we used 25 use cases from a module in a proprietary IBM
enterprise application. Due to conﬁdentiality, we refer to this ap-
plication as IBMApp . This module belongs to the ﬁnancial domain.
We next discuss the results of our evaluations in terms of the
effectiveness of Text2Policy in identifying ACP sentences and ex-
tracting ACP rules from NL documents and in extracting actio n
steps from use cases.
5.2 RQ1: ACP-Sentence Identiﬁcation
In this section, we address the research question RQ1 of how
effectively Text2Policy identiﬁes ACP sentences in NL docu ments.
To address this question, we ﬁrst manually inspected the use cases
of iTrust to identify ACP sentences. We then applied Text2Po licy to
identify ACP sentences and compared those results with our r esults
of manual inspection to identify the numbers of true positiv es, false
positives, and false negatives. We further computed precis ion and
recall values based on these numbers.
Among 448 use-case sentences in the iTrust use cases, we man-
ually identiﬁed 117 ACP sentences. Among 479 use-case sen-
tences in the IBMApp use cases, we manually identiﬁed 24 ACP
sentences. We then manually classiﬁed these ACP sentences i den-
tiﬁed by Text2Policy as correct sentences and false positiv es, and
manually identiﬁed false negatives.
Table 3 shows the results of RQ1 for both the subjects. Column
“Subjects” lists the name of the subjects. Columns “# Sent.” and
“# ACP Sent.” show the number of use-case sentences and the
number of ACP sentences. Column “# Ident.” shows the number
of identiﬁed ACP sentences, and Columns “ FP” and “FN” show
the numbers of false positives and false negatives. Based on these
numbers, Columns “ Prec ”, “Rec”, and “F1” show the computed
precision, recall, and F1-score. For iTrust, the results show that
Text2Policy identiﬁed 119 sentences with 16 false positive s and 14Table 3: Evaluation results of RQ1.
Subjects # Sent. # ACP Sent. # Ident. FPFNPrec Rec F1
iTrust 448 117 119 16 14 86.6% 88.0% 87.3
IBMApp 479 24 23 0 1100.0% 95.8% 97.9
Total 927 141 142 16 15 88.7% 89.4% 89.1
Table 4: Evaluation results of RQ2.
Subjects # ACP Sent. # Extracted Accu.
iTrust 217 187 86.2%
IBMApp 24 21 87.5%
Total 241 208 86.3%
false negatives. For IBMApp , Text2Policy identiﬁed 23 sentences
with 0 false positive and 1 false negative. The results show t hat our
semantic patterns help identify ACP sentences more precise ly on
theIBMApp use cases. One explanation could be that proprietary
use cases are often of higher quality compared to open-sourc e use
cases and conform to simple grammatical patterns.
We ﬁrst provide an example to describe how Text2Policy cor-
rectly identiﬁes ACP sentences. One of the ACP sentences tha t
Text2Policy correctly identiﬁes ACP rules is “ HCPs can modify or
delete the ﬁelds of the ofﬁce visit information. ” [5,41]. Our seman-
tic pattern Modal Verb in Main Verb Group helps identify that the
main verb contains the modal verb canand correctly identify the
sentence as an ACP sentence.
We next provide some examples to describe how Text2Policy
produces false positives and negatives. One false positive produced
by Text2Policy is “ The instructions can contain numbers, charac-
ters. . . ” [5, 41], which matches the pattern Modal Verb in Main
Verb Group . However, this sentence describes a requirement on
password setting, instead of an ACP rule. These false positi ves can
be reduced by expanding the domain dictionary to include com -
monly used nouns that are unlikely to be systems or system ac-
tors. The sentence that cannot be identiﬁed by Text2Policy i s “The
LHCP can select a patient to obtain additional information a bout
a patient. ” [5, 41]. Due to precision in parsing long phrases, the
underlying shallow parser fails to identify to obtain additional in-
formation about a patient as a to-inﬁnitive phrase, causing a false
negative for our approach. These false negatives can be redu ced by
improving the underlying shallow parser using more trainin g cor-
pus in future work.
5.3 RQ2: Accuracy of ACP Extraction
In this section, we address the research question RQ2 of how e f-
fectively Text2Policy extracts ACP rules from ACP sentence s. To
address this question, we manually extracted ACP rules from these
ACP sentences. We next applied Text2Policy and compared the
results with our manually extracted results. We compute the ac-
curacy of the ACP extraction using the number of ACP sentence s
from which Text2Policy correctly extracts ACPs and the tota l num-
ber of ACP sentences.
Table 4 shows the results of RQ2. Column “Subject” lists the
name of the subjects. Columns “# ACP Sent.” and “# Extracted”
show the total number of ACP sentences and the number of ACP
sentences from which Text2Policy correctly extracts ACPs. The
statistics shown by these two columns are used to compute the ac-
curacy shown in Column “Accu.”. Among 217 ACP sentences of
iTrust (including 117 from iTrust use cases), Text2Policy c orrectly
extracts ACP rules from 187 ACP sentences, achieving the acc u-
racy of 86.2%. Among 24 ACP sentences in the 25 use cases of
IBMApp , Text2Policy correctly extracts ACP rules from 21 ACP
sentences, achieving the accuracy of 87.5%.Table 5: Evaluation results of RQ3.
Subjects # AS Sent. # Extracted Accu.
iTrust 312 258 82.7%
IBMApp 455 370 81.3%
Total 767 628 81.9%
We ﬁrst provide an example to describe how Text2Policy cor-
rectly extracts some ACP rules. One of the sentences from whi ch
Text2Policy correctly extracts ACP rules is “ The administrator is
not allowed through the system interface to delete an existi ng en-
try.” [5, 41]. Our semantic pattern Passive Voice followed by To-
inﬁnitive Phrase helps correctly identify this ACP sentence, and
correctly extract subject ( administrator ), action ( delete ), and re-
source ( an existing entry ) elements. Our technique of negative-
meaning inference also correctly infers the policy effect t o be deny.
We next provide examples to describe how Text2Policy fails t o
extract some ACP rules. One of the sentences from which Text2 Policy
cannot correctly extract ACP rules is “ Any subject with an e-mail
name in the med.example.com domain can perform any action on
any resource. ” [4]. The subject of this sentence Any subject is a
noun phrase followed by two prepositional phrases ( with an e-mail
name andin the med.example.com domain ). These two preposi-
tional phrases constrain the subject Any subject , which is not cor-
rectly handled by our current implementation. Moreover, du e to
the imprecision in parsing long phrases, Text2Policy fails to extract
some resources from ACP sentences. In future work, we plan to
develop techniques to analyze the effects of prepositional phrases
and long phrases for improving the accuracy of ACP extractio n.
5.4 RQ3: Accuracy of Action-Step Extraction
In this section, we address the research question RQ3 of how
effectively Text2Policy extracts action steps from action -step sen-
tences. First, we manually extracted actions steps from the se action-
step sentences. We next used Text2Policy to automatically e xtract
actions steps and compared the results with our manually ext racted
results. We computed the accuracy of the action-step extrac tion by
using the number of correctly extracted action-step senten ces and
the total number of action-step sentences.
Table 5 shows the results of RQ3. Column “Subject” lists the
name of the subjects. Columns “# AS Sent.” and “# Extracted”
show the total number of action-step sentences and the numbe r of
action-step sentences from which Text2Policy correctly ex tracts ac-
tion steps. The statistics shown by these two columns are use d
to compute the accuracy shown in Column “Accu.”. Among 312
action-step sentences in the iTrust use cases, Text2Policy correctly
extracts action steps from 258 action-step sentences, resu lting in an
accuracy of 82.7%. Among 455 action-step sentences in the 25 use
cases of IBMApp , Text2Policy correctly extracts action steps from
370 action-step sentences, resulting in an accuracy of 81.3 %.
We next provide examples to describe how Text2Policy fails t o
extract action steps. One of the action-step sentences from which
Text2Policy fails to extract action steps is “ The HCP must provide
instructions, or else they cannot add the prescription. ” [5,41]. The
reason is that the current implementation of our approach do es not
handle the subordinate conjunctions or else . Another example sen-
tence is “ The public health agent can send a fake email messageto the adverse event reporter to gain more information about the
report. ” [5,41]. For such long sentences with prepositional phrase s
to the adverse event reporter to gain more information about the
report after the object of the sentence a fake email message , the
underlying shallow parser of our approach cannot correctly iden-
tify the grammatical functions. We plan to study more use cas es on
health-care applications and improve the underlying shall ow parser
with more patterns to identify grammatical functions of act ion-step
sentences.
5.5 Detected Inconsistency
Our approach validates the extracted access requests again st the
extracted ACPs. Although our approach does not detect viola tions
of the extracted ACPs in our evaluations, our approach ident iﬁes a
few action steps that do not match any extracted ACPs. To stud y
why these action steps do not match any ACPs, we further apply
union on the speciﬁcations of action steps to collect the inf ormation
of what users perform what actions on what resources. From th is
information, we ﬁnd that editor , one of the system users, is not
matched with any subjects in the extracted ACPs. We then chec k
the glossary of the iTrust requirements and the use-case dia gram.
We conﬁrm that editor in fact refers to HCP ,admin , and all users
in use cases 1, 2, and 4, respectively. Such name inconsisten cies
can be easily identiﬁed by combining validation of ACP rules and
using the union information of extracted action steps.
6. THREATS TO V ALIDITY
The threats to external validity include the representativ eness of
the subjects and the underlying shallow parser used by the cu rrent
implementation of our approach. To evaluate ACP extraction and
action-step extraction from use cases, we applied our appro ach on
37 use cases of iTrust. The iTrust use cases were created base d
on the use cases in the U.S. Department of Health & Human Ser-
vice (HHS) [2] and Ofﬁce of the National Coordinator for Heal th
Information Technology (ONC) [1], and evolved and revised b y
about 70 students and teaching assistants as well as instruc tors each
semester since the iTrust requirements were initially crea ted. Al-
though the public availability and activeness make the iTru st use
cases suitable for our subjects, we evaluated our approach o nly on
these limited use cases. To reduce the threats, for the evalu ation
of ACP extraction, we further collected 100 ACP sentences fr om
other 17 publicly available sources. Furthermore, we also a pplied
our approach on 25 use cases of a module in a proprietary IBM
enterprise application that belongs to the ﬁnancial domain .
The threats to internal validity include human factors for d eter-
mining correct identiﬁcation of ACP sentences from NL softw are
documents, correct extraction of ACP rules from these sente nces,
and correct extraction of action steps from use cases. In our eval-
uations, we inspected the whole subject documents and manua lly
identiﬁed ACP sentences, and extracted ACPs and action step s as
the comparison base in the evaluations. To reduce the human-
factor threats, we did the extraction carefully and referre d to exist-
ing ACPs and other use cases for determining correct identiﬁ cation
of ACP sentences, and correct extraction of ACPs and action s teps.
These threats could be further reduced by involving two or mo re
people who have experiences on ACPs to manually extract ACPs
and action steps and integrating their manual-extraction r esults with
our manual-extraction results as the comparison base.
7. DISCUSSION AND FUTURE WORK
In this section, we discuss applications and limitations of our
current approach and propose directions for future work.Construction of Complete ACPs. From the extracted ACPs,
our approach automatically generates formal speciﬁcation s of ACPs.
These formal ACPs can assist the construction of complete AC Ps
in three ways: (1) these formal ACPs can be used to validate ma nu-
ally speciﬁed ACPs for identifying inconsistencies; (2) th ese formal
ACPs can serve as an initial version of ACPs for policy author s to
improve, greatly reducing manual effort in extracting ACPs from
NL software documents; (3) combined with speciﬁed ACPs, the se
formal ACPs can be fed to automated ACP-veriﬁcation approac hes
for checking correctness, such as static veriﬁcation [20] a nd dy-
namic veriﬁcation via access-request generation [29, 30].
ACP Modelling in the Absence of Security Requirements. In
the absence of security requirements, our approach can stil l provide
a solution to assist policy authors to model ACPs for a system . Our
approach ﬁrst extracts deny ACPs and action steps from funct ional
requirements. Besides deriving access requests from actio n steps,
we can also derive a permit ACP rule from each action step. Wit h
the extracted and derived ACPs, policy authors have two ways to
model ACPs: (1) the policy authors can apply the extracted de ny
ACPs and add a policy rule to permit all other accesses; (2) th e pol-
icy authors can combine the extracted deny ACPs and the deriv ed
permit ACPs, and add a policy rule to deny all other accesses.
Cooperation Between Tool and Human. The extracted poli-
cies can serve as an initial version of ACPs for policy author s to
improve, advocating cooperation between the tool and the us er [42,
43]: the tool reports policies extracted with low conﬁdence and the
user can reﬁne them to get better results. Currently, our imp le-
mentation is built on an Eclipse-based IDE and can provide vi sual
feedback of extracted policies, e.g., extracted subjects, actions, and
resources. We plan to improve the IDE to better support the co -
operation between the tool and the user. In addition, to impr ove
the precision of the semantic analysis (such as anaphora res olu-
tion), we can apply ambiguity-analysis techniques [11, 44] on the
NL software documents to identify nocuous ambiguities, and ask
the user to resolve the ambiguities before our approach is ap plied
to extract policies.
ACP-Rule Ordering. Our current approach extracts ACP rules
from sentences without considering the ordering of the rule s. Do-
ing so may cause security holes in the extracted ACP rules. We
plan to study the extracted ACP rules and develop new techniq ues
to extract ordering for the ACP rules.
Context-aware Analysis in Action-Step Extraction. A sequence
of action steps may have several state transitions. The tech niques
of actor-ﬂow tracking and perspective conversion in our app roach
partially address the context-aware analysis in action-st ep extrac-
tion. For example, a customer may not pay the order if he has no t
selected an order. We plan to develop techniques to deal with state
transitions during action-step extraction.
Other Policy Models. In our evaluations, we encountered some
ACP sentences that describe conditions for ACP rules. For ex am-
ple, the ACP sentence “ During the meeting phase, reviewer can
read the scores for paper if reviewer has submitted a review f or
paper. ” [13] contains an if-condition to constrain the ACP rule.
Without correct extraction of the condition, the produced s peciﬁ-
cation of ACP rules is incomplete and requires policy author s to
manually ﬁx the incompleteness issue. Besides the issue of c ondi-
tions, our current approach cannot handle multi-level mode ls [17]
or workﬂow models [37] for access control. We plan to extend o ur
approach to support these new models and provide new semanti c
patterns for identifying new styles. In addition, our appro ach can
be extended to support privacy policies, such as HIPAA priva cypolicies3. Supporting extraction of HIPPA policies requires more
sophisticated semantic models to address new challenges, s uch as
condition rules, rule combination, and rule ordering. We pl an to
investigate techniques to deal with new challenges of extra cting
HIPAA privacy policies.
8. RELATED WORK
Manual Extraction of ACPs from NL Documents. He and An-
ton [19] propose a manual approach, called Requirements-ba sed
Access Control Analysis and Policy Speciﬁcation (ReCAPS), to
extract ACPs from various NL documents, including requirem ents
documents, design documents and database design, and secur ity
and privacy requirements. During the extraction, their app roach
also clariﬁes ambiguities in requirements documents and id enti-
ﬁes inconsistencies among requirements documents and data base
design. Their objective is to derive a comprehensive set of A CP
rules, similar to our approach. However, our approach adapt s NLP
techniques and provides new analysis techniques to automat e the
process of ACP extraction, while their approach is manual.
Template Matching. Etzioni et al. [14] propose an approach
to extract lists of named entities found on the web using a set of
patterns. Their approach is related to the ACP extraction of our ap-
proach, since both use patterns to extract information. How ever,
their patterns are based on the low-level POS tags (such as NP
and NPList), while our semantic patterns are based on gramma tical
functions of phases (such as subject, main verb group, and ob ject).
Our semantic patterns are more general and provide high prec ision
in identifying ACP sentences as shown in our evaluations.
NLP to Analyze API Documents. Pandita et al. [34] propose
an approach that analyzes the meta-data of API descriptions , pro-
gramming keywords, and semantic patterns from POS tags to in fer
method speciﬁcations from API documents. Zhong et al. [45] p ro-
pose an approach that builds action-resource pairs from API docu-
ments via NLP analysis based on machine learning, and infers au-
tomata for resources from action-resource pairs and class/ interface
hierarchies. Both of these approaches focus on parsing API d oc-
uments, and use the speciﬁc characteristics of API document s to
improve the NLP analysis. For example, different parts of AP I doc-
uments can be mapped to different parts of code structures, s uch as
class/method names, return values, and parameter names. Ho w-
ever, the contents of requirements documents usually canno t be
mapped directly to code structures, thus making their appro aches
inappropriate on analyzing requirements documents. Moreo ver,
these two approaches do not include techniques to address th e unique
challenges of ACP extraction and action-step extraction, s uch as
TC3-Negative-Meaning Implicitness ,TC4-Transitive Actor , and TC5-
Perspective Variance .
NLP to Assist Privacy-Policy Authoring. The SPARCLE Pol-
icy Workbench [9, 10, 25, 26] employs the shallow-parsing te ch-
nique [32] to parse privacy rules and extract the elements of privacy
rules based on a pre-deﬁned syntax. These elements are then u sed
to form policies in a structured form, so that policy authors can
review it and then produce policies in a machine-readable fo rm,
such as EPAL [7] and XACML [3, 33] with a privacy-policy pro-
ﬁle. Michael et al. [31] propose an approach to map NL policy
statements to an equivalent computational format suitable for fur-
ther processing by a policy workbench. However, neither of t hese
approaches can identify sentences describing a policy rule . These
approaches parse all the input statements for policy extrac tion by
assuming that the input statements are policy statements, w hile our
approach identiﬁes ACP sentences from requirements docume nts
3http://crypto.stanford.edu/privacy/HIPAA/using semantic patterns. Both of these approaches provide s imple
templates to extract elements for constructing policy rule s, while
our approach provides more general semantic patterns. Addi tion-
ally, their approaches cannot infer negative meaning of sen tences.
Use-Case Analysis. Sinha et al. [38, 39] adapt NLP techniques
to parse and represent use-case contents in use-case models . The
extraction of use-case contents to formal models is similar to the
action-step extraction in our approach. However, our appro ach
focuses on extracting access requests for validation again st speci-
ﬁed and extracted ACPs and provides corresponding analysis tech-
niques to address the TC4-Transitive Actor andTC5-Perspective
Variance challenges.
9. CONCLUSION
In this paper, we have proposed an approach, called Text2Pol icy,
which extracts ACPs from NL software documents and produces
formal speciﬁcations. Our approach incorporates syntacti c and se-
mantic NL analyses around models such as ACP and action-step
models and extracts model instances from NL software docume nts.
From the extracted ACPs, our approach automatically genera tes
machine-enforceable ACPs (in formal languages such as XACM L)
that can be automatically checked for correctness. From the ex-
tracted action steps, our approach automatically extracts resource-
access information, which can be used for automatic validat ion
against speciﬁed or extracted ACPs for detecting inconsist encies.
We conducted evaluations on iTrust use cases, ACP sentences col-
lected from 18 sources, and 25 proprietary use cases. The eva lua-
tion results show that with customized NLP techniques, auto mated
extraction of security policies from NL documents in a speci ﬁc do-
main helps effectively reduce manual effort and assist poli cy con-
struction and understanding.
Acknowledgment
This work is supported in part by NSF grants CCF-0845272, CCF -
0915400, CNS-0958235, ARO grant W911NF-08-1-0443, an NSA
Science of Security Lablet grant, and a NIST grant.
10. REFERENCES
[1] Ofﬁce of the National Coordinator for Health Informatio n
Technology (ONC). http://www.hhs.gov/healthit/.
[2] U.S. department of Health & Human Service (HHS).
http://www.hhs.gov/.
[3] eXtensible Access Control Markup Language (XACML),
2005. http://www.oasis-open.org/committees/xacml.
[4] eXtensible Access Control Markup Language (XACML)
speciﬁcation, 2005.
http://docs.oasis-open.org/xacml/2.0/access_control -xacml-
2.0-core-spec-os.pdf.
[5] iTrust: Role-based healthcare, 2008.
http://agile.csc.ncsu.edu/iTrust/wiki/.
[6] Text2Policy, 2012.
http://research.csc.ncsu.edu/ase/projects/text2poli cy/.
[7] P. Ashley, S. Hada, G. Karjoth, C. Powers, and M. Schunter .
Enterprise privacy architecture language (EPAL 1.2), 2003 .
http://www.w3.org/Submission/EPAL/.
[8] B. K. Boguraev. Towards ﬁnite-state analysis of lexical
cohesion. In Proc. INTEX-3 , 2000.
[9] C. Brodie, C.-M. Karat, J. Karat, and J. Feng. Usable
security and privacy: A case study of developing privacy
management tools. In Proc. SOUPS , pages 35–43, 2005.[10] C. A. Brodie, C.-M. Karat, and J. Karat. An empirical stu dy
of natural language parsing of privacy policy rules using th e
sparcle policy workbench. In Proc. SOUPS , pages 8–19,
2006.
[11] F. Chantree, B. Nuseibeh, A. de Roeck, and A. Willis.
Identifying nocuous ambiguities in natural language
requirements. In Proc. RE , pages 56–65, 2006.
[12] A. Cockburn. Writing Effective Use Cases . Addison-Wesley
Longman Publishing Co., Inc., 1st edition, 2000.
[13] D. J. Dougherty, K. Fisler, and S. Krishnamurthi. Speci fying
and reasoning about dynamic access-control policies. In
Proc. IJCAR , pages 632–646, 2006.
[14] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu,
T. Shaked, S. Soderland, D. S. Weld, and A. Yates.
Unsupervised named-entity extraction from the web: An
experimental study. Artif. Intell. , pages 91–134, 2005.
[15] C. Fellbaum, editor. WordNet An Electronic Lexical
Database . The MIT Press, 1998.
[16] D. F. Ferraiolo, R. Sandhu, S. Gavrila, D. R. Kuhn, and
R. Chandramouli. Proposed NIST standard for role-based
access control. TISSEC , 4(3):224–274, 2001.
[17] M. I. Gofman, R. Luo, J. He, Y . Zhang, and P. Yang.
Incremental information ﬂow analysis of role based access
control. In Security and Management , pages 397–403, 2009.
[18] G. Grefenstette. Light parsing as ﬁnite state ﬁltering . In
A. Kornai, editor, Extended ﬁnite state models of language ,
pages 86–94. Cambridge University Press, 1999.
[19] Q. He and A. I. Antón. Requirements-based access Contro l
Analysis and Policy Speciﬁcation (ReCAPS). Inf. Softw.
Technol. , 51(6):993–1009, 2009.
[20] V . C. Hu, D. R. Kuhn, T. Xie, and J. Hwang. Model checking
for veriﬁcation of mandatory access control models and
properties. IJSEKE , 21(1):103–127, 2011.
[21] J. Hwang, T. Xie, V . C. Hu, and M. Altunay. ACPT: A tool
for modeling and verifying access control policies. In Proc.
POLICY , pages 40–43, 2010.
[22] I. Jacobson. Object-Oriented Software Engineering: A Use
Case Driven Approach . Addison Wesley Longman
Publishing Co., Inc., 2004.
[23] I. Jacobson, M. Christerson, P. Jonsson, and G. Overgaa rd.
Object-Oriented Software Engineering: A Use Case Driven
Approach . Addison Wesley Longman Publishing Co., Inc.,
1992.
[24] D. Jagielska, P. Wernick, M. Wood, and S. Bennett. How
natural is natural language?: How well do computer science
students write use cases? In Proc. OOPSLA , pages 914–924,
2006.
[25] C.-M. Karat, J. Karat, C. Brodie, and J. Feng. Evaluatin g
interfaces for privacy policy rule authoring. In Proc. CHI ,
pages 83–92, 2006.
[26] J. Karat, C.-M. Karat, C. Brodie, and J. Feng. Designing
natural language and structured entry methods for privacy
policy authoring. In Proc. INTERACT , pages 671–684, 2005.
[27] C. Kennedy. Anaphora for everyone: Pronominal anaphor a
resolution without a parser. In Proc. COLING , pages
113–118, 1996.
[28] A. X. Liu, F. Chen, J. Hwang, and T. Xie. XEngine: a fast
and scalable XACML policy evaluation engine. In Proc.SIGMETRICS , pages 265–276, 2008.
[29] E. Martin, J. Hwang, T. Xie, and V . Hu. Assessing quality of
policy properties in veriﬁcation of access control policie s. In
Proc. ACSAC , pages 163–172, 2008.
[30] E. Martin and T. Xie. A fault model and mutation testing o f
access control policies. In Proc. WWW , pages 667–676,
2007.
[31] J. B. Michael, V . L. Ong, and N. C. Rowe. Natural-languag e
processing support for developing policy-governed softwa re
systems. In Proc. TOOLS , pages 263–274, 2001.
[32] M. S. Neff, R. J. Byrd, and B. K. Boguraev. The talent
system: Textract architecture and data model. Nat. Lang.
Eng., 10(3-4):307–326, 2004.
[33] OASIS. Privacy policy proﬁle of XACML v2.0., 2005.
http://docs.oasis-
open.org/xacml/2.0/privateproﬁle/access_control-xac ml-2.0-
privacy_proﬁle-specos.pdf.
[34] R. Pandita, X. Xiao, H. Zhong, T. Xie, S. Oney, and
A. Paradkar. Inferring method speciﬁcations from natural
language API descriptions. In Proc. ICSE , pages 815–825,
2012.
[35] C. Rolland and C. B. Achour. Guiding the construction of
textual use case speciﬁcations. Data Knowl. Eng. ,
25(1-2):125–160, 1998.
[36] P. Samarati and S. D. C. d. Vimercati. Access control:
Policies, models, and mechanisms. In Proc. FOSAD , pages
137–196, 2001.
[37] A. Schaad, V . Lotz, and K. Sohr. A model-checking approa ch
to analysing organisational controls in a loan origination
process. In Proc. SACMAT , pages 139–149, 2006.
[38] A. Sinha, S. M. S. Jr., and A. Paradkar. Text2Test:
Automated inspection of natural language use cases. In Proc.
ICST , pages 155–164, 2010.
[39] A. Sinha, A. M. Paradkar, P. Kumanan, and B. Boguraev. A
linguistic analysis engine for natural language use case
description and its application to dependability analysis in
industrial use cases. In Proc. DSN , pages 327–336, 2009.
[40] M. Stickel and M. Tyson. FASTUS: A cascaded ﬁnite-state
transducer for extracting information from natural-langu age
text. In Proc. Finite-State Language Processing , pages
383–406, 1997.
[41] L. Williams and Y . Shin. Work in progress: Exploring
security and privacy concepts through the development and
testing of the iTrust medical records system. In Proc. FIE ,
pages 30–31, 2006.
[42] X. Xiao, T. Xie, N. Tillmann, and J. de Halleux. Precise
identiﬁcation of problems for structural test generation. In
Proc. ICSE , pages 611–620, 2011.
[43] T. Xie. Cooperative testing and analysis: Human-tool,
tool-tool, and human-human cooperations to get work done.
InProc. SCAM , Keynote, 2012.
[44] H. Yang, A. de Roeck, V . Gervasi, A. Willis, and
B. Nuseibeh. Extending nocuous ambiguity analysis for
anaphora in natural language requirements. In Proc. RE ,
pages 25–34, 2010.
[45] H. Zhong, L. Zhang, T. Xie, and H. Mei. Inferring resourc e
speciﬁcations from natural language API documentation. In
Proc. ASE , pages 307–318, 2009.