Which Conﬁguration Option Should I Change?
Sai Zhang Michael D. Ernst
Department of Computer Science & Engineering
University of Washington, USA
{szhang, mernst }@cs.washington.edu
ABSTRACT
Modern software often exposes conﬁguration options that enable
users to customize its behavior. During software evolution, devel-
opers may change how the conﬁguration options behave. When
upgrading to a new software version, users may need to re-conﬁgure
the software by changing the values of certain conﬁguration options.
This paper addresses the following question during the evolution
of a conﬁgurable software system: which conﬁguration options
should a user change to maintain the software’s desired behavior?
This paper presents a technique (and its tool implementation, called
ConfSuggester) to troubleshoot conﬁguration errors caused by soft-
ware evolution. ConfSuggester uses dynamic proﬁling, execution
trace comparison, and static analysis to link the undesired behav-
ior to its root cause — a conﬁguration option whose value can be
changed to produce desired behavior from the new software version.
We evaluated ConfSuggester on 8 conﬁguration errors from 6
conﬁgurable software systems written in Java. For 6 errors, the root-
cause conﬁguration option was ConfSuggester’s ﬁrst suggestion.
For 1 error, the root cause was ConfSuggester’s third suggestion.
The root cause of the remaining error was ConfSuggester’s sixth
suggestion. Overall, ConfSuggester produced signiﬁcantly better
results than two existing techniques. ConfSuggester runs in just a
few minutes, making it an attractive alternative to manual debugging.
Categories and Subject Descriptors : D.2.5 [Software Engineer-
ing]: Testing and Debugging.
General Terms: Reliability, Experimentation.
Keywords: Conﬁguration error diagnosis, Software evolution.
1. INTRODUCTION
Many modern software systems support a range of conﬁguration
options for users to customize their behavior. This ﬂexibility has
a cost: a small conﬁguration error may cause hard-to-diagnose
behavior.
Software conﬁguration errors are errors in which the software
code and the input are correct, but the an incorrect value is used
for a conﬁguration option so that the software does not behave
as desired. Such errors may lead the software to crash, produce
erroneous output, or simply perform poorly. In practice, software
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’14, May 31 ­ June 7, 2014, Hyderabad, India
Copyright 14 ACM 978­1­4503­2756­5/14/05 ... $5.00.conﬁguration errors are prevalent ,severe , and hard to debug , but
they are actionable for users to ﬁx.
Prevalent. A recent analysis of Yahoo’s mission-critical Zookeeper
service showed that software misconﬁgurations accounted for the
majority of all user-visible failures [52]. Conﬁguration-related is-
sues caused about 31% of all failures at a commercial storage com-
pany [69]. The vast majority of production failures at Google arise
not due to bugs in the software, but bugs in the conﬁguration settings
(i.e., conﬁguration errors) that control the software [15].
Severe. Conﬁguration errors can have disastrous impacts. For
example, an outage in Facebook due to an incorrect conﬁguration
value left the website inaccessible for about 2 hours [14]. The entire
.sedomain of Sweden was unavailable for about 1 hour, due to
a DNS misconﬁguration problem [49]. A misconﬁguration made
Microsoft’s public cloud platform, Azure, unavailable for about two
and a half hours [40]. Each such incident affected millions of users.
Hard to debug. Conﬁguration errors are difﬁcult to diagnose.
They usually require great expertise to understand the error root
causes. For example, a conﬁguration error in the CentOS kernel
prevented a user from mounting a newly-created ﬁle system [69].
The user needed deep understanding about the exhibited symptom,
and had to re-install kernel modules and also modify conﬁguration
option values in several places to get it to work. Techniques to help
escape from “conﬁguration hell” are highly demanded [15].
Actionable. Unlike software bugs, which can only be ﬁxed by ex-
perienced software developers, ﬁxing a software conﬁguration error
isactionable for software end-users or system administrators. These
users are not the software developers, and cannot access (much less
understand) the source code; but they can ﬁx a conﬁguration error
by simply changing the values of certain conﬁguration options.
1.1 Conﬁguration Evolution
Continual change is a fact of life for software systems. Among
software changes, conﬁguration changes are prevalent. We studied
8 real-world conﬁgurable software systems (Section 2), and found
conﬁguration changes in every studied version of each system. In
many cases, reusing the old version’s conﬁguration can lead the new
software version to exhibit undesired behaviors, even if the software
is working exactly as designed .
Take the popular JMeter performance testing tool as an example.
In version 2.8, the testing report is saved as an XML ﬁle after run-
ning an example command ( jmeter -n -t ../threadgroup.jmx -l
../output.jtl -j ../test.log ) from the user manual. However,
after upgrading to version 2.9, the same command saves the testing
report in a CSV ﬁle. Further, all JMeter regression tests pass on the
updated version. The new JMeter version behaves as designed but
differently than a user was expecting.
Our technique (and its tool implementation ConfSuggester) can
help diagnose conﬁguration errors. For the JMeter example, a userPermission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ICSE’14 , May 31 – June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05...$15.00
http://dx.doi.org/10.1145/2568225.2568251
152
ﬁrst demonstrates the different behaviors on two ConfSuggester-
instrumented JMeter versions. Then, ConfSuggester analyzes the
recorded execution traces produced by the two instrumented ver-
sions, and outputs a ranked list of suspicious conﬁguration op-
tions that may need to be changed. At the top of the list is the
outputformat option with a default value of CSVin version 2.9. To
resolve this problem, users only need to change its value to XML.
1.2 Conﬁguration Option Recommendation
Broadly speaking, diagnosing a conﬁguration error can be divided
into three separate tasks: reproducing the error, recommending
which speciﬁc conﬁguration option is responsible for the undesired
behavior, and determining a better value for the conﬁguration option
to ﬁx the error. ConfSuggester addresses the second task: recom-
mending the root-cause conﬁguration option.
ConfSuggester speciﬁcally focuses on software conﬁguration er-
rors and aims to help two types of users: software end-users who
may have problems with software installed on their personal comput-
ers, and system administrators who are responsible for maintaining
production systems. They can use ConfSuggester to diagnose an
unexpected conﬁguration problem during software evolution.
The key idea of ConfSuggester is to approximate program behav-
ioral differences by control ﬂow differences between two executions
(by running the old and new program versions, respectively), and
then reason about the control ﬂow differences to identify conﬁgura-
tion options that might cause such differences. It uses three steps,
as illustrated in Figure 5, to link the undesired behavior to speciﬁc
root-cause conﬁguration options:
•Instrumentation and Proﬁling. ConfSuggester instruments both
the old and new program versions to monitor the execution of
each statement as well as the evaluation result of every predicate.
Then, it asks the user to demonstrate the different behaviors on
the two instrumented program versions.
•Execution Trace Comparison. ConfSuggester analyzes the two
execution traces to identify the control ﬂow differences. Conf-
Suggester identiﬁes program predicates that behave differently
between the two versions. These behaviorally-deviated predicates
and their affected program statements provide evidence about
which parts of a program might be behaving abnormally and why.
•Conﬁguration Option Recommendation. ConfSuggester uses
a lightweight static dependence analysis technique, called thin
slicing [53], to attribute control ﬂow differences to speciﬁc con-
ﬁguration options. Finally, it outputs a ranked list of suspicious
options to the users.
Compared to existing error diagnosis techniques [4 –6, 47, 55, 63,
66, 74], ConfSuggester differs in four key aspects:
•It diagnoses conﬁguration errors caused by software evolu-
tion. Most existing conﬁguration error diagnosis techniques iden-
tify errors from a single program version [4 –6, 47, 55, 63, 66, 74].
By contrast, ConfSuggester is cognizant of software evolution and
works on two different versions of the same program. It uses the
desired behavior of the old software version as a baseline against
which to compare new program behavior, and only reasons about
the behavioral differences.
•It requires no testing oracle . Some previous work [6,47,55,66]
requires the user to answer difﬁcult questions like “is the soft-
ware currently working?” or “why is the software not working?”
by writing a testing oracle to check the software behavior. By
contrast, ConfSuggester only requires users to demonstrate the
different behaviors on two versions. ConfSuggester uses the exe-
cution trace produced by the old version as an approximate oracle
to reason about the undesired behavior on the new version.•It determines likely root-cause options . Many error diagnosis
and debugging techniques [71,75] primarily focus on determining
what causes the undesired behaviors, e.g., a snippet of code —
they leave the more challenging question of how to ﬁx the unde-
sired behaviors unanswered. The user must manually inspect the
analysis report to infer the root cause, e.g., a conﬁguration option.
By contrast, ConfSuggester makes reports in terms that end-users
can act on: it explicitly guides users to speciﬁc conﬁguration
options that may ﬁx the error.
•It requires no OS-level support . ConfSuggester does not need
alterations to the JVM, operating system, or standard library.
This makes ConfSuggester more portable and distinguishes it
from related techniques, such as OS-level conﬁguration error
diagnosis [55, 66].
1.3 Evaluation
We implemented ConfSuggester for Java software and empiri-
cally evaluated its effectiveness using 8 conﬁguration errors from
6 open-source conﬁgurable Java software systems. We used Conf-
Suggester to recommend conﬁguration options whose values can be
changed to ﬁx each error. ConfSuggester successfully recommended
correct conﬁguration options for all 8 errors. For 6 errors, the correct
option was ConfSuggester’s ﬁrst suggestion. For 1 error, the correct
option was ConfSuggester’s third suggestion. The root cause of the
remaining error was ConfSuggester’s sixth suggestion. ConfSug-
gester is fast enough for practical use, taking less than 3.1 minutes,
on average, to diagnose each conﬁguration error. ConfSuggester’s
accuracy and speed make it a promising technique.
We compared ConfSuggester to two existing conﬁguration er-
ror diagnosis techniques, called ConfDiagnoser [74] and ConfAna-
lyzer [47]. ConfDiagnoser assumes the existence of some correct
execution traces on the new program version; by contrast, ConfSug-
gester eliminates the assumption. ConfAnalyzer exclusively focuses
on diagnosing crashing conﬁguration errors; by contrast, ConfSug-
gester can diagnose both crashing errors and non-crashing errors.
Our experiments show that ConfSuggester signiﬁcantly outperforms
these two existing techniques.
Finally, we evaluated two internal design choices of ConfSug-
gester. First, we showed that using thin slicing [53] is a better choice
than traditional full slicing [22] to reason about root-cause conﬁgu-
ration options. Second, we showed that ConfSuggester outperforms
an alternative approach that solely uses predicate behavior change
to reason about the root-cause conﬁguration options.
1.4 Contributions
This paper makes the following main contributions:
•Study of conﬁguration changes. We describe an empirical study
of 8 conﬁgurable software systems. Our study indicates that
conﬁguration changes are frequent during software evolution
(Section 2).
•Technique. We present a technique to diagnose conﬁguration
errors for evolving software. Our technique links undesired be-
haviors to speciﬁc responsible conﬁguration options (Section 3).
•Implementation. We implemented our technique in a tool, called
ConfSuggester, for Java software (Section 4). It is publicly avail-
able at:http://config-errors.googlecode.com .
•Evaluation. We applied ConfSuggester to 8 conﬁguration errors
from 6 conﬁgurable software systems, and compared it with
existing techniques. The results show the accuracy and efﬁciency
of ConfSuggester (Section 5).153Program Versions Years LOC (latest version) Language
MySQL 5.1, 5.5, 5.6, 5.7 3 1565212 C/C++
Apache 2.0, 2.2, 2.4 3 139178 C/C++
Firefox 7.0–22.0 (16 versions) 3 8237915 C/C++
Randoop 1.2.1, 1.3.2, 1.3.3 6 19511 Java
Weka 3.4, 3.5, 3.6, 3.7 2 288369 Java
JChord 1.0, 2.0, 2.1 4 26617 Java
Synoptic 0.04, 0.05, 0.1 2 19153 Java
JMeter 2.6, 2.7, 2.8, 2.9 2 91979 Java
Figure 1: The open-source software systems we studied and
their characteristics. Column “Years” is the active develop-
ment period for the selected versions.
Program # Added Options # Deleted Options # Modiﬁed Options
MySQL 26 24 23
Apache 5 0 10
Firefox 28 7 56
Randoop 37 26 2
Weka 72 4 13
JChord 13 10 5
Synoptic 3 0 2
JMeter 17 3 12
Total 201 70 123
Figure 2: The total number of new, deleted, and modiﬁed con-
ﬁguration options for each subject program.
2. REAL­WORLD CONFIGURATION
CHANGES
In the software engineering literature, despite a rich body of
software change analysis work [11, 12, 35, 58, 70, 77], software
conﬁguration changes across multiple versions are less studied. Do
conﬁguration changes arise during software evolution in practice?
This section describes an initial study of 8 real-world conﬁgurable
systems to answer this question.
2.1 Subject Programs and Study Methodology
Figure 1 lists 8 open-source conﬁgurable systems used in our
study. MySQL [41] is a popular relational database management
system. Apache [1] has been the dominant HTTP server on the
Internet since 1996. Firefox [16] is an open-source browser available
on multiple platforms. Randoop [48] is an automated test generator
for Java programs. Weka [65] is a toolkit that implements machine
learning algorithms. JChord [25] is a program analysis platform that
enables users to design and implement static and dynamic program
analyses for Java. Synoptic [57] mines a ﬁnite state machine model
representation of a system from logs. JMeter [27] is a tool to load-
test functional behavior and measure performance. Each program is
highly conﬁgurable, and has evolved over a considerable amount of
time for the selected versions (2–6 years).
In our study, we manually examined the revision history of each
subject program, and searched for 5 keywords (“conﬁguration op-
tion”, “add option”, “delete option”, “rename option”, and “change
option”) in commit messages and in the change logs. We searched
7022 commit messages and 28 change log entries, in which 422
commit messages and 28 change log entries were matched. For each
match, we read the description of the change and the “diff” of the
original ﬁle to check whether a conﬁguration option is changed. We
collected 394 distinct conﬁguration changes in total.
2.2 Findings
Figure 2 summarizes the identiﬁed conﬁguration changes for
each subject program. Figure 4 further classiﬁes the conﬁgurationChange Type Description
Bugs Fix existing bugs
Renaming Change the option name
Features Add, remove, or modify features
Reliability Improve reliability or performance
Figure 3: Types of conﬁguration changes identiﬁed in our study
from the subject programs in Figure 1.
Program # Changed Conﬁguration Options
Bugs Renaming Features Reliability
MySQL 0 15 55 3
Apache 0 0 11 4
Firefox 28 0 55 8
Randoop 0 2 62 1
Weka 1 0 81 8
JChord 0 2 24 2
Synoptic 0 5 0 0
JMeter 7 0 18 7
Total 36 24 301 33
Figure 4: The number of conﬁguration changes of each type.
changes into four categories shown in Figure 3 (each change belongs
to a single category)1.
As shown in Figure 2, conﬁguration changes occur in the evolu-
tion of every subject program. In fact, they occur in every version of
each subject program (not shown in Figure 2, due to space limits).
As shown in Figure 4, feature-related conﬁguration changes are
the largest group across all subject programs. These changes in-
clude adding new conﬁguration options, deleting existing options,
or modifying the default value of an option.
Conﬁguration evolution can have unexpected impacts on program
behavior. After conﬁguration changes, reusing an old conﬁguration
may yield a misconﬁguration, causing different results on the new
version. Section 5 shows concrete examples.
2.3 Threats to Validity
Our ﬁndings apply in the context of our subject programs and
methodology; they might not apply to arbitrary programs.
The conﬁguration changes identiﬁed by our methodology are
certainly not complete. Our keyword search might have missed
some conﬁguration changes. Our methodology only studies changes
that are directly made to a software conﬁguration option. We may
miss code or environment changes that indirectly affect the software
behavior and require users to re-conﬁgure the new software version.
3. TECHNIQUE
ConfSuggester models a conﬁguration as a set of key-value pairs,
where the keys are strings and the values have arbitrary type.
3.1 Overview
ConfSuggester is based on two key insights. First, a program’s
control ﬂow, rather than data ﬂow, often propagates the majority of
the effects of a conﬁguration option. In other words, a conﬁguration
option is mainly used as a “ﬂag” that affects the program behavior
by changing the runtime execution path. Second, the control ﬂow
differences between two execution traces approximate the behavioral
differences of two versions; they provide evidence about which parts
of the program are behaving abnormally and why.
Based on these two insights, ConfSuggester uses three steps to
link different behaviors across program versions to speciﬁc con-
1The “Bugs” change type in Figure 3 represents that ﬁxing some
bugs led to changes in conﬁgurations rather than ﬁxing some buggy
conﬁgurations.154Figure 5: The architecture of our ConfSuggester technique. The instrumented program versions and two execution traces are
produced by the step in Section 3.2. The “Execution Trace Comparison” step is described in Section 3.3. The “Conﬁguration Option
Recommendation” step is described in Section 3.4.
ﬁguration options that cause the difference. Figure 5 sketches the
high-level workﬂow of ConfSuggester. In the ﬁrst step, ConfSug-
gester asks the user to demonstrate the different behaviors, using the
same input and conﬁguration, on two ConfSuggester-instrumented
program versions (Section 3.2). Then, ConfSuggester identiﬁes
the control ﬂow differences between the two execution traces pro-
duced by user demonstration. In particular, ConfSuggester identiﬁes
program predicates that behave differently across the two execu-
tions (Section 3.3). After that, ConfSuggester uses a lightweight
dependence analysis technique, called thin slicing [53], to statically
reason about which conﬁguration options may cause the control
ﬂow differences. Finally, ConfSuggester reports a ranked list of
suspicious conﬁguration options to the user (Section 3.4).
3.2 Instrumentation and Demonstration
ConfSuggester ﬁrst instruments both the old and new program ver-
sions to monitor the program execution at runtime. ConfSuggester
directly instruments the bytecode. The instrumentation consists of
two parts:
•For each program predicate (i.e., a branch instruction in bytecode),
ConfSuggester inserts one probe before and one probe after it to
monitor how frequently the predicate is executed and how often
the predicate evaluates to true. In our context, a predicate is a
Boolean expression in a conditional or loop statement, whose
evaluation result affects the program control ﬂow by determining
whether to execute the following statement or not.
•For each of the other statements, ConfSuggester inserts one probe
before it to monitor whether the statement gets executed or not
at runtime. The statement execution information is used to calcu-
late the number of executed statements controlled by a predicate
(Section 3.4).
After instrumentation, ConfSuggester asks the user to demon-
strate the different behaviors on the two instrumented program ver-
sions, using the same input and conﬁguration. Demonstration is one
of the simplest ways for an end-user to describe her problem; and it
is easier than writing speciﬁcations or scripts of any form.
Executing the instrumented program produces an execution trace,
which consists of a sequence of executed statements as well as
the execution count and evaluation result of each predicate. The
execution trace captured by ConfSuggester is by no means complete
in recording the full program behavior; it only captures the control
ﬂows a program is taking. As demonstrated in our experiments,
such control ﬂow information serves as a good approximation to
diagnose the undesired program behavior.
3.3 Execution Trace Comparison
In this step, ConfSuggester compares two execution traces from
two program versions and identiﬁes the control ﬂow differencesbetween them. ConfSuggester focuses on the recorded behavior of
each predicate. First, it statically matches each predicate in the old
source code to its counterpart in the new source code (Section 3.3.1).
Then, it identiﬁes all predicates that behave differently across the
execution traces (Section 3.3.2).
3.3.1 Matching Predicates across Versions
For each predicate recorded in the old execution trace, ConfSug-
gester matches it in the new program version to identify its possibly-
updated counterpart. The predicate-matching process proceeds in
two steps. First, ConfSuggester ﬁnds corresponding methods. Then,
ConfSuggester matches predicates within matched methods.
To match methods, ConfSuggester uses the ﬁrst of these two
strategies that succeeds:
1.Identical method name. Return a method with the identical
fully-qualiﬁed name in the new version.
2.Similar method content. Return the method with the most simi-
lar content in the new version. Given a method in the old program
version, ConfSuggester uses the algorithm shown in Figure 6
(details are discussed below) to match it to every method in the
new program version, and then chooses the method in the new
program version with the most matched statements.
After running the matching algorithm, ConfSuggester further
checks the ratio of matched statements in the old method, and
discards method candidates whose matching ratio is below a
threshold (default value: 0.9).
If there is no match for the declaring method in the new pro-
gram version, ConfSuggester concludes that the predicate cannot be
matched. Otherwise, ConfSuggester runs the algorithm in Figure 6
(or looks up a cached version of the result) to establish the mapping
between instructions, and then returns the matched instruction of
the predicate (or null if the predicate cannot be matched).
Statement-matching algorithm. The algorithm in Figure 6 is in-
spired by the JDiff program differencing algorithm [3]. The original
JDiff algorithm is based on a method-level representation (called
hammocks) that models object-oriented features. It works in a hier-
archical way by ﬁrst identifying matched classes and then matched
method pairs, and uses textual similarity to compare two program
statements. By contrast, our algorithm directly works on the byte-
code, using the program control ﬂow graph representation to estab-
lish the matching between statements.
In Figure 6, ConfSuggester ﬁrst constructs the control ﬂow graphs
of two given methods (lines 2–3), then pushes their entry nodes
(a synthetic node for each method) onto a worklist stack (line 5),
which retains the next statement pair for comparison. The algorithm
repeatedly pops a statement pair from the stack (line 7) and decides155Auxiliary functions :
matches( s,s′): return whether two statements sands′are matched.
Details are explained in Section 3.3.1.
BFS( s,cfg,d): return a list of statements reachable from statement
sincfgwithin dgraph edges in Breath-First Search (BFS) order.
ﬁrstMatchedPair( stmtList 1,stmtList 2): return the ﬁrst matched
statement pair/an}bracketle{ts,s′/an}bracketri}htsuch that s∈stmtList 1,s′∈stmtList 2, and
matches( s,s′) return true. Return null if no such pair exists.
Input : two methods from two software versions: moldandmnew,
a maximum lookahead value lh. (Our experiment uses lh=5.)
Output : matched statements between moldand mnew.
matchStatements( mold,mnew,lh)
1:matchedStmts←new Map/an}bracketle{tStatement, Statement /an}bracketri}ht
2:cfgold←constructControlFlowGraph( mold)
3:cfgnew←constructControlFlowGraph( mnew)
4:stack←new Stack/an}bracketle{tPair/an}bracketle{tStatement, Statement /an}bracketri}ht/an}bracketri}ht
5:stack .push( cfgold.entry ,cfgnew.entry )
6:while stack is not empty do
7:/an}bracketle{tstmt old,stmt new/an}bracketri}ht← stack .pop()
8: ifmatchedStmts .keys().contains( stmt old)
||matchedStmts .values().contains( stmt new)then
9: continue
10: end if
11: matchedPair←null
12: ifmatches( stmt old,stmt new)then
13: matchedStmts [stmt old]←stmt new
14: matchedPair←/an}bracketle{tstmt old,stmt new/an}bracketri}ht
15: else
16: stmtList old←BFS( stmt old,cfgold,lh)
17: stmtList new←BFS( stmt new,cfgnew,lh)
18:/an}bracketle{tsold,snew/an}bracketri}ht← ﬁrstMatchedPair( stmtList old,stmtList new)
19: if/an}bracketle{tsold,snew/an}bracketri}ht/ne}ationslash=nullthen
20: matchedStmts [sold]←snew
21: matchedPair←/an}bracketle{tsold,snew/an}bracketri}ht
22: end if
23: end if
24: ifmatchedPair/ne}ationslash=nullthen
25: foreach sin BFS( matchedPair .ﬁrst(), cfgold, 1)do
26: foreach s′in BFS( matchedPair .second(), cfgnew, 1)do
27: stack .push(/an}bracketle{ts,s′/an}bracketri}ht)
28: end for
29: end for
30: end if
31:end while
32:return matchedStmts
Figure 6: Algorithm for matching statements from two meth-
ods.
whether the two statements are matched (line 12). Each statement
appears at most once in the result (lines 8–9).
The algorithm decides whether two statements are matched by
using the matches( s,s′) auxiliary function. Method matches( s,s′)
returns true if both sands′have the same statement type (i.e., the
same instruction type in bytecode), and if sands′are ﬁeld-accessing
or method-invoking statements, the same ﬁeld or method is accessed
or invoked by both statements. Such approximate matching tolerates
small differences between two versions, such as changes to constant
values.
If two statements are matched, the algorithm saves them in the
result map (line 13). Otherwise, the algorithm compares each state-
ment reachable within lhcontrol ﬂow graph edges (lines 16–22).
Doing so permits the algorithm to tolerate some small changes in the
method code, and attempts to match as many statements as possible.When two matched statements are found (stored in the matchedPair
variable in lines 14 or 21), the algorithm pushes every pair of their
successor statements onto the stack (line 27). It terminates after
every statement has been attempted to match.
3.3.2 Identifying Behaviorally­Deviated Predicates
Using the predicate matching information, ConfSuggester next
identiﬁes predicates that behave differently between two versions.
Given an execution trace T, ConfSuggester characterizes a predi-
cate p’s behavior by how often it is evaluated (i.e., the number of
observed executions) and how often it evaluates to true (i.e., the “true
ratio”). The true ratio is an important characteristic of a predicate’s
behavior, but it is less dependable the fewer times the predicate has
been executed.
ConfSuggester combines the true ratio and number of executions
by computing their harmonic mean.
φ(p,T)=2
1
trueRatio (p,T)+1
totalExecNum (p,T)
Inφ(p,T),trueRatio (p,T)returns the proportion of executions of
the predicate pthat evaluated to true in T, and totalExecNum (p,T)
returns the the total number of observed executions of predicate pin
T. To smooth corner cases, φ(p,T)returns 0, if a predicate pis not
executed in T(i.e., totalExecNum (p,T)=0) or a predicate p’s true
ratio is 0 (i.e., trueRatio (p,T)=0). We let φ(null,T)=0for all T.
Given two matched predicates p1andp2from two different exe-
cution traces T1andT2, ConfSuggester uses the deviation function
deﬁned in Figure 7 to compute the behavioral deviation value. In
Figure 7, the deviation function discards a predicate pair whose be-
havioral deviation value is less than a pre-deﬁned threshold (line 2).
This is for tolerating small non-determinism during program execu-
tion and making ConfSuggester focus on predicates with substantial
behavioral differences.
The identiﬁed behaviorally-deviated predicates indicate different
control ﬂow taken between two versions under the same input and
conﬁguration. Such control ﬂow differences are useful in explaining
which part of the program might be behaving unexpectedly.
3.4 Conﬁguration Option Recommendation
In this step, ConfSuggester attributes the control ﬂow differences
to one or more root-cause conﬁguration options. The key idea is
to identify conﬁguration options that may affect the behaviorally-
deviated predicates, and then rank these options by the deviation
value (computed by the deviation function in Figure 7) and the
number of executed statements they control (computed by the get-
ExecutedStmtNum auxiliary function in Figure 7).
To identify the conﬁguration options that can affect a predicate, a
straightforward way is to use program slicing [64] to compute a for-
ward slice from the initialization statement of a conﬁguration option,
and then check whether the predicate is in the slice. Unfortunately,
traditional full slicing [64] would produce unusably large slices due
to its conservatism.
To address this limitation, ConfSuggester uses thin slicing [53] to
identify conﬁguration options that directly affect a predicate. Dif-
ferent from traditional full slicing, thin slicing only follows the data
ﬂow dependencies from the slicing criterion (i.e., the initialization
statement of a conﬁguration option) and ignores control ﬂow de-
pendencies as well as uses of base pointers. Using thin slicing,
ConfSuggester separates pointer computations from the ﬂow of
conﬁguration option values and naturally connects a conﬁguration
option with its affected statements by the data ﬂow dependencies.
Section 5.3.4 empirically demonstrates that using traditional full
slicing will decrease the accuracy of ConfSuggester.156Auxiliary functions:
getPredicates( T): return all executed predicates in the execution
trace T.
getAffectingOptions( p,V): use thin slicing [53] to compute all
conﬁguration options that may affect predicate pin the software
version V.
getExecutedStmtNum( p,V,T): return the number of executed state-
ments (controlled by predicate p) in trace Tfrom software version
V.
deviation( p1,T1,p2,T2):
1:result←|φ(p1,T1)−φ(p2,T2)|
{δis a pre-deﬁned threshold with default value: 0.1 }
2:ifresult<δthen
3: result = 0
4:end if
5:return result
Input : two software versions: VoldandVnew.
two execution traces: ToldandTnew, on the respective versions.
a map of matched statements between VoldandVnew:stmtMap .
Output : a ranked list of likely root-cause conﬁguration options
recommendOptions( Vold,Vnew,Told,Tnew,stmtMap )
1:optionMap←new Map/an}bracketle{tOption, Float/an}bracketri}ht
{Each entry of optionMap is initialized to 0.}
2:foreach poldin getPredicates( Vold)do
3: d←deviation( pold,Told,stmtMap [pold],Tnew)
4: options old←getAffectingOptions( pold,Vold)
5: w←d×getExecutedStmtNum( pold,Vold,Told)
6: foreach Option option inoptions olddo
7: optionMap [option ]←optionMap [option ] +w
8: end for
9:end for
10:foreach pnewin getPredicates( Vnew)do
11: d←deviation( stmtMap−1[pnew],Told,pnew,Tnew)
12: options new←getAffectingOptions( pnew,Vnew)
13: w←d×getExecutedStmtNum( pnew,Vnew,Tnew)
14: foreach Option option inoptions newdo
15: optionMap [option ]←optionMap [option ] +w
16: end for
17:end for
18:return optionMap .sortedKeys()
Figure 7: Algorithm for recommending conﬁguration options.
Function deviation is a helper function to compute the devia-
tion value between two predicates p1and p2, and function φ
used in deviation is deﬁned in Section 3.3.2.
To reason about the root-cause conﬁguration options, ConfSug-
gester associates each conﬁguration option with a weight, which
represents the strength of the causal relationship between the conﬁg-
uration option and the execution differences. A larger weight value
indicates that a conﬁguration option potentially contributes more to
the control ﬂow differences as its value propagates in the program,
and thus the conﬁguration option is more likely to be the root cause.
Figure 7 presents the conﬁguration option recommendation al-
gorithm. For each behaviorally-deviated predicate in an execution
trace, ConfSuggester ﬁrst attributes the deviated behavior to its af-
fecting conﬁguration options (lines 4 and 12). Then, ConfSuggester
computes the number of executed statements controlled by that pred-
icate (lines 5 and 13). To do so, the getExecutedStmtNum auxiliary
function ﬁrst statically examines the source code to compute the
immediate post-dominator statement [61] of a predicate, and then
traverses the execution trace to count the number of statements that
are executed between the predicate and its post-dominator statement.ConfSuggester multiples a predicate’s deviation value by the num-
ber of executed statements, and then updates the weight of each
affecting conﬁguration option (lines 5–8 and 13–16). Finally, Conf-
Suggester ranks all affecting conﬁguration options in decreasing
order by weight, outputting a ranked list of suspicious options that
might be responsible for the behavioral differences (line 18).
If two conﬁguration options have the same weights, ConfSug-
gester prefers the conﬁguration option affecting more statements
in its thin slice. This heuristic is based on the intuition that conﬁg-
uration options affecting more statements seem more likely to be
relevant to the behavioral differences.
3.5 Discussion
We next discuss some design issues in ConfSuggester.
Fixing conﬁguration errors vs. Localizing regression bugs. The
problem addressed in this paper is signiﬁcantly different than the
traditional regression bug localization problem [71,75]. A regression
bug occurs when developers have made a mistake, which causes the
software to violate its speciﬁcation after a session of code changes.
By contrast, in our context, the software behavior on the new version
is still as designed by the developers but undesired by the users.
Why not use a dynamic analysis to recommend conﬁguration op-
tions? ConfSuggester uses thin slicing to statically identify respon-
sible conﬁguration options for a behaviorally-deviated predicate.
An alternative is to use a pure dynamic analysis to assess how a
conﬁguration option may affect the control ﬂow. Techniques such as
Delta Debugging [71], value replacement [76], and dual slicing [56]
use a similar idea: they repeatedly replace a variable value with
other alternatives, and then re-execute the program to check whether
the outcome is desired. There are two major challenges that prevent
these dynamic analyses from being used. First, it can be difﬁcult
to ﬁnd a valid replacement value for a non-Boolean conﬁguration
option, such as a string or regular expression. Second, automati-
cally checking program outcomes requires a testing oracle, which
is often not available in practice, and end-users should not be ex-
pected to provide it. To address these challenges, ConfSuggester
approximates the program behavioral differences by the control ﬂow
differences of two executions, and then statically reasons about the
responsible conﬁguration options.
ConfSuggester’s current limitations. There are three major limi-
tations in the our ConfSuggester technique. First, ConfSuggester
assumes the different behaviors of two program versions are not
caused by non-determinism. For non-deterministic behaviors, Conf-
Suggester could potentially leverage a deterministic replay sys-
tem [23,26] to faithfully reproduce the behaviors. Second, ConfSug-
gester only matches one predicate in the old program version to one
predicate in the new program version. If a predicate evolves into
multiple predicates in the new version, ConfSuggester may output
less useful results. Third, ConfSuggester focuses on identifying
root-cause conﬁguration options that can change the functional be-
haviors of the target program. Conﬁguration options that affect the
underlying OS or runtime system, such as the -Xmx option used to
specify JVM’s heap size when launching a Java program, are not
supported by ConfSuggester.
4. IMPLEMENTATION
ConfSuggester uses the WALA framework [62] to perform ofﬂine
bytecode instrumentation. The instrumentation code records the exe-
cution of every statement and the evaluation result of each predicate.
ConfSuggester also uses WALA to analyze Java bytecode statically
to identify the affecting conﬁguration options for each predicate that
behaves differently across versions.157Program Old Version New Version LOC (new version) ∆LOC #Options
Randoop 1.2.1 1.3.2 18571 1893 57
Weka 3.6.1 3.6.2 275035 1458 14
Synoptic 0.05 0.1 19153 1658 37
JChord 2.0 2.1 26617 3085 79
JMeter 2.8 2.9 91979 3264 55
Javalanche 0.36 0.40 25144 9261 35
Figure 8: All subject programs used in the evaluation. Column
“∆LOC” shows the number of changed lines of code between
the old and new versions. Column “#Options” shows the num-
ber of conﬁguration options supported in the new program ver-
sion.
Like other existing conﬁguration error diagnosis tools [47, 74],
ConfSuggester does not instrument libraries such as the JDK, since
a conﬁguration option set in the client software usually does not
affect the behaviors of its dependent libraries.
5. EV ALUATION
We evaluated 4 aspects of ConfSuggester’s effectiveness, answer-
ing the following research questions:
1.How accurate is ConfSuggester in identifying the root-cause
conﬁguration options? That is, what is the rank of the actual
root-cause conﬁguration option in ConfSuggester’s output (Sec-
tion 5.3.1)?
2.How long does it take for ConfSuggester to diagnose a conﬁgura-
tion error (Section 5.3.2)?
3.How does ConfSuggester’s effectiveness compare to existing
approaches (Section 5.3.3)?
4.How does ConfSuggester’s effectiveness compare to two variants?
The ﬁrst variant uses full slicing in identifying suspicious conﬁgu-
ration options, and the second variant only uses predicate behavior
changes to recommend conﬁguration options (Section 5.3.4).
5.1 Subject Programs
We evaluated ConfSuggester on 6 Java programs listed in Figure 1.
The ﬁrst 5 subject programs are the 5 Java programs studied in
Section 2, and the remaining subject program is Javalanche [24],
which is a mutation testing framework.
We included Javalanche because one of its real users provided us
a conﬁguration error he encountered when using Javalanche.
5.1.1 Conﬁguration Errors
For the 5 Java programs studied in Section 2, we manually exam-
ined all deleted and modiﬁed conﬁguration options listed in Figure 2.
(The added conﬁguration options are unlikely to cause a miscon-
ﬁguration.) For each change, based on our own understanding, we
wrote a test driver to cover it, and then checked whether the test
driver could reveal different behaviors on two versions. For those
5 programs, we collected 7 errors as listed in Figure 9 (the ﬁrst 7
errors). For the Javalanche program, we reproduced the reported
conﬁguration error. In Figure 9, errors #3 and #4 can be repro-
duced together in a single execution, and each of the other errors is
reproduced in one execution.
Our methodology of collecting conﬁguration errors is different
from what was used in collecting software regression bugs in the
literature [71, 75]. Software regression bugs often can be found in
well-maintained bug databases. By contrast, ﬁnding recorded con-
ﬁguration errors is much harder, mainly because most conﬁguration
errors have not been documented rigorously [69]. Usually, after
a session of code changes, when regression tests pass, developers
may treat the software behaviors as having been validated. Further,because the software misconﬁgurations are user-driven, the “ﬁxes”
may be recorded simply as pointers to manuals or other documents.
5.2 Evaluation Procedure
For each subject program, we used ConfSuggester to instrument
both versions. For each conﬁguration error, we used the same
input and conﬁguration to reproduce the different behaviors on two
instrumented versions.
The average size of the execution traces is 40MB, and the largest
one (Randoop’s trace) is 140MB.
When using ConfSuggester to diagnose a conﬁguration error, we
manually specify the initialization statement of each conﬁguration
option as the thin slicing criterion. This manual, one-time-cost
step took 20 minutes on average per subject program. After that,
ConfSuggester works in a fully-automatic way: it analyzes two
program versions and two execution traces, and outputs a ranked list
of conﬁguration options. Future work should automate this manual
step.
Our experiments were run on a 2.67GHz Intel Core PC with
4GB physical memory (2GB was allocated for the JVM), running
Windows 7.
5.3 Results
5.3.1 Accuracy
As shown in Figure 9, ConfSuggester is highly effective in identi-
fying the root-cause conﬁguration options that should be changed
in the new program version. The average rank of the root cause
in ConfSuggester’s output is 1.8. For 6 errors, the root-cause con-
ﬁguration option ranks ﬁrst in ConfSuggester’s output; for 1 error,
the root-cause conﬁguration option ranks third in ConfSuggester’s
output; and the root-cause option ranks sixth for the remaining error.
ConfSuggester is successful because of its ability to identify the
behaviorally-deviated predicates with substantial impacts through
execution trace comparison. The top-ranked deviated predicates
often provide useful clues about what parts of a program have per-
formed differently.
Summary. ConfSuggester recommends correct conﬁguration op-
tions with high accuracy for evolving conﬁgurable software systems
with non-trivial code changes.
5.3.2 Performance of ConfSuggester
We measured ConfSuggester’s performance in two ways: the
performance overhead introduced by instrumentation when demon-
strating the conﬁguration error, and the time cost of recommending
conﬁguration options. Figure 10 shows the results.
The performance overhead to demonstrate the error varies among
programs. The current implementation imposes an average 8 ×
and 12.8×slowdown in a ConfSuggester-instrumented old and
new program version, respectively. This is due to ConfSuggester’s
inefﬁcient instrumentation code that monitors the execution of every
instruction. The overhead could be reduced by instrumenting at
basic block granularity instead. Even so, except for two errors
(errors #5 and #6) in JChord, all other errors can be reproduced in
less than 30 seconds. Errors #5 and #6 require about 20 minutes to
reproduce.
ConfSuggester spends an average of 3.1 minutes to recommend
conﬁguration options for one error (including the time to compute
thin slices and the time to suggest suspicious options). Computing
thin slices for all conﬁguration options is non-trivial. However, this
step is one-time cost per program and the results can be precom-
puted. The time used for suggesting conﬁguration options is roughly158Error ID. Error Description Root-Cause #Options Rank of the Root-Cause Conﬁguration Option
Program Conﬁguration Option ConfSuggester ConfDiagnoser [74] ConfAnalyzer [47]
1. Randoop Poor performance in test generation usethreads 57 1 N X
2. Weka A different error message when Weka crashes mnumFolds 14 1 9 1
3. Synoptic Initial model not saved dumpInitialGraphDotFile 37 1 N X
4. Synoptic Generated model not saved as JPEG ﬁle dumpInitialGraphPngFile 37 6 N X
5. JChord Bytecode parsed incorrectly chord.ssa 79 1 3 X
6. JChord Method names not printed in the console chord.print.methods 79 1 N X
7. JMeter Results saved to a ﬁle with a different format outputformat 55 1 1 X
8. Javalanche No mutants generated project.tests 35 3 4 X
Average 49.1 1.8 15.3 47.5
Figure 9: All conﬁguration errors used in the evaluation and the experimental results. Only the 2nd error is a crashing error, and
all the other errors are non-crashing errors. Column “Root-Cause Conﬁguration Option” shows the actual root-cause conﬁguration
option. Column “#Options” shows the number of conﬁguration options supported in the new program version, taken from Figure 8.
Column “Rank of the Root-Cause Conﬁguration Option” shows the absolute rank of the actual root-cause conﬁguration option in
each technique’s output (lower is better). “X” means the technique is not applicable (i.e., requiring a crashing point), and “N” means
the technique does not identify the actual root cause. When computing the average rank, each “X” or “N” is treated as half of the
number of conﬁguration options, because a user would need to examine on average half of the available options to ﬁnd the root cause.
Column “ConfSuggester” shows the results of using our technique. Columns “ConfDiagnoser” and “ConfAnalyzer” show the results
of using two existing techniques as described in Section 5.3.3.
Error ID. Run-time Slowdown ( ×) ConfSuggester time (s)
Program Old Version New Version Slicing Suggestion
1. Randoop 20.1 4.1 90 295
2. Weka 1.6 1.6 80 49
3. Synoptic 1.7 4.7 48 42
4. Synoptic 1.7 4.7 48 42
5. JChord 18.7 44.3 20 38
6. JChord 17.6 41.1 23 29
7. JMeter 1.3 1.4 51 63
8. Javalanche 1.4 1.5 430 265
Average 8.0 12.8 99 91
Figure 10: ConfSuggester’s performance. The “Run-time Slow-
down” column shows the cost of reproducing the error in an
ConfSuggester-instrumented version of the subject program.
The “ConfSuggester time (s)” column shows the time taken by
ConfSuggester to diagnose conﬁguration errors in seconds. Col-
umn “Slicing” is the cost of computing thin slices on both old
and new program versions.
proportional to the size of the execution trace rather than the size of
the subject program.
Summary. ConfSuggester recommends conﬁguration options for
diagnosing conﬁguration errors with reasonable time cost.
5.3.3 Comparison with Two Existing Approaches
This section compares ConfSuggester with two existing approaches,
ConfDiagnoser [74] and ConfAnalyzer [47]. ConfDiagnoser and
ConfAnalyzer are among the most precise conﬁguration error diag-
nosis techniques in the literature.
ConfDiagnoser , proposed in our previous work [74], is an auto-
mated software conﬁguration error diagnosis technique. ConfDi-
agnoser is notcognizant of software evolution, and it diagnoses
conﬁguration errors from a single program version. ConfDiagnoser
assumes the existence of a set of correct execution traces, which are
used to compare against the undesired execution trace to identify
the abnormal program parts. When comparing the undesired execu-
tion trace with a correct execution trace, ConfDiagnoser only uses
a predicate’s deviation value to reason about the most suspicious
options, while ignoring the statements controlled by a predicate’s
evaluation result.
To compare ConfSuggester with ConfDiagnoser, we reused the
pre-built execution trace databases for the 4 shared subject programs
(Randoop, Synoptic, JChord, and Weka) from [74]. Each exist-ing trace database contains 6–16 correct execution traces. For the
remaining two subject programs (JMeter and Javalanche), we manu-
ally built an execution trace database for each of them by running
correct examples from their user manuals. The databases contain 6
and 8 execution traces for JMeter and Javalanche, respectively.
ConfAnalyzer , proposed by Rabkin and Katz [47], is a lightweight
static conﬁguration error diagnosis technique. ConfAnalyzer tracks
the ﬂow of labeled objects through program control ﬂow and data
ﬂow, and treats a conﬁguration option as a root cause if its value
may ﬂow to a crashing point. Since ConfAnalyzer cannot diagnose
non-crashing errors, we can only apply it to diagnose the crashing
error in Weka (error #2 in Figure 9).
Results. Columns “ConfDiagnoser” and “ConfAnalyzer” in Fig-
ure 9 show the experimental results.
ConfSuggester produces signiﬁcantly more accurate results than
ConfDiagnoser, primarily for two reasons. First, ConfDiagnoser
focuses on diagnosing erroneous program behaviors and identiﬁes
their responsible conﬁguration options. However, for the problem
addressed in this paper, the new software version that exhibits un-
desired behavior (after applying the same conﬁguration used in the
old version) is working exactly as designed . In other words, the
execution trace obtained by running the new program version is
stillcorrect . Therefore, just comparing execution traces obtained
from the new program version is not effective in identifying the “ab-
normal” behavior. By contrast, ConfSuggester compares execution
traces from two different versions and directly reasons about the
execution differences. Second, ConfDiagnoser only focuses on the
predicate behavior changes, while ignoring the statements poten-
tially impacted by the affected predicate. This makes ConfDiagnoser
fail to distinguish predicates whose behavioral changes can have
different impacts. Section 5.3.4 further evaluates this design choice,
showing that considering the number of controlled statements can
substantially increase the diagnosis accuracy.
ConfAnalyzer outputs the correct result for the crashing error
in Weka, but cannot identify root causes for other non-crashing
errors. The crashing error in Weka occurs soon after the program is
launched. ConfAnalyzer correctly identiﬁes its root cause because a
small number of conﬁguration options are initialized and only one
of them ﬂows to the crashing point.
ConfSuggester is not directly comparable to other related con-
ﬁguration error diagnosis approaches [4, 6, 55, 63, 66, 68]. Existing
approaches target a rather different problem than ConfSuggester,159Error ID. Rank of the Root-Cause Conﬁguration Option
Program ConfSuggester Full Slicing Predicate Behavior
1. Randoop 1 32 7
2. Weka 1 7 1
3. Synoptic 1 16 3
4. Synoptic 6 17 8
5. JChord 1 19 5
6. JChord 1 30 5
7. JMeter 1 N 1
8. Javalanche 3 N 13
Average 1.8 20.7 5.4
Figure 11: Experimental results of evaluating two design
choices of ConfSuggester. Column “ConfSuggester” shows
ConfSuggester’s results, taken from Figure 9. Column “Full
Slicing” shows the results of replacing thin slicing with full slic-
ing in ConfSuggester. “N” means the technique does not iden-
tify the actual root cause. Column “Predicate Behavior” shows
the results of ConfSuggester, if it only considers predicate be-
havior change. When computing the average rank, each “N” is
treated as half of the number of conﬁguration options.
or require different inputs than ConfSuggester. For example, X-
Ray [4] diagnoses conﬁguration errors on a single program version.
PeerPressure [63] and RangerFixer [68] only support conﬁguration
options deﬁned by certain speciﬁc feature models. General soft-
ware fault localization techniques [28, 37] are not well-suited for
conﬁguration error diagnosis, since such techniques often focus on
identifying the buggy code or invalid input values. This has been
empirically validated in our previous work [74].
Summary. Conﬁguration error diagnosis techniques designed for
asingle program version achieve less accurate results in diagnos-
ing conﬁguration errors introduced in software evolution. Conf-
Suggester reasons about the behavioral differences between two
program versions, and produces more accurate results.
5.3.4 Evaluating Two Design Choices
This section evaluates two design choices in ConfSuggester.
Slicing algorithms. ConfSuggester uses thin slicing to identify
conﬁguration options whose values may affect a predicate. We
next evaluate a variant that replaces thin slicing with the traditional
full slicing [22]. This variant changes the getAffectingOptions
auxiliary function in Figure 7, by using full slicing to compute all
conﬁguration options that may affect a predicate. Figure 11 (Column
“Full Slicing”) shows the results.
ConfSuggester achieves substantially less accurate results when
using full slicing. The primary reason is that full slicing identi-
ﬁes many irrelevant conﬁguration options that indirectly affect a
predicate of interest. Such conﬁguration options are not pertinent
to the task of error diagnosis. Linking them to the exhibited dif-
ferent behavior would degrade ConfSuggester’s accuracy. Further,
computing full slices is much more expensive than computing thin
slices. WALA’s full slicing algorithm failed to scale to two subject
programs (JMeter and Javalanche).
Predicate behavioral change metrics. ConfSuggester considers
both the predicate behavior change and the number of affected
statements in diagnosing conﬁguration errors. We next evaluate a
variant that only uses the predicate behavior change to diagnose
errors. This variant changes the getExecutedStmtNum auxiliary
function in Figure 7, by making it always return 1. Figure 11
(Column “Predicate Behavior”) shows the results.
ConfSuggester’s accuracy degrades substantially when ranking
predicates based on its behavioral changes without considering
the number of affected statements. The primary reason is thatbehaviorally-deviated predicates occur all over the execution traces,
but each predicate may have different impacts to the overall program
behavior change. ConfSuggester uses the number of statements
determined by the predicate evaluation result to approximate such
potential impacts.
Summary. Full slicing includes too many irrelevant program state-
ments due to its conservatism and only using a predicate’s behavior
change is not enough to identify the root-cause conﬁguration op-
tions. ConfSuggester, using thin slicing and considering both the
predicate behavior change and the impacted statements, is a better
choice in diagnosing conﬁguration errors.
5.4 Discussion
Threats to validity. There are several threats to validity of our evalu-
ation. First, the 6 Java programs might not be representative, though
some of them have been used in previous research. Likewise, the
8 conﬁguration errors might not be representative, even though we
evaluated every error we found. We only evaluated ConfSuggester
on errors caused by one conﬁguration option. It is unclear whether
ConfSuggester would produce useful results if ﬁxing a particular
conﬁguration error requires changing values of two dependent con-
ﬁguration options. Second, our evaluation focused on conﬁguration
errors rather than software regression bugs, as all regression tests
between two versions pass. We have not evaluated whether Conf-
Suggester would help users work around buggy program versions.
Third, ConfSuggester’s effectiveness depends on the effectiveness
of the predicate-matching algorithm. In our experiments, on average
12% of lines are changed between the program versions. ConfSug-
gester may yield less useful results for programs with signiﬁcant
code changes. However, different algorithms can be plugged into
ConfSuggester. Fourth, our evaluation only compared ConfSug-
gester with two other approaches. Comparing with other analyses
or tools might yield different observations.
Experimental conclusions. We have three chief ﬁndings. (1) Conf-
Suggester is highly effective in diagnosing conﬁguration errors
introduced by software evolution; (2) ConfSuggester produces more
accurate results than approaches designed to diagnose errors on a
single program version; and (3) ConfSuggester outperforms two
variants that use full slicing and only a predicate’s behavior change
in error diagnosis, respectively.
6. RELATED WORK
The most closely related work falls into three categories: (1) tech-
niques for supporting software evolution; (2) software conﬁguration
error diagnosis techniques; and (3) conﬁguration-aware software
analysis techniques.
6.1 Supporting Software Evolution
As software evolves, its behavior must be validated. Regression
test selection [19] indicates which tests need to be executed for a
changed program. Program differencing techniques [11, 13, 18, 26,
29, 33, 43, 60, 67] identify changes between two program versions
and present the change list to developers for inspection. Change
impact analysis techniques [35], which are often built on top of
program differencing techniques, identify not only the changes, but
also code fragments that are affected by the changes. Different than
ConfSuggester’s predicate-matching algorithm (Section 3.3.1), ex-
isting program differencing techniques primarily focus on matching
program elements at the method level [11, 13, 29, 33, 39, 43, 67, 72],
or matching program statements on the source code based on textual
similarity [21]. By contrast, ConfSuggester’s matching algorithm,
inspired by the JDiff algorithm [3], is speciﬁcally designed to match160the evolved predicate in the new program version. (See Section 3.3.1
for a detailed comparison with JDiff.) The algorithm directly works
on the bytecode of two program versions without any additional
information from users, such as a software revision history [39].
Nagarajan et al. [42] developed a technique to match control ﬂows
of two program versions running with the same input. Different
from ConfSuggester, their work assumes semantically-equivalent
program versions (e.g., optimized and unoptimized), while Conf-
Suggester compares two versions that include functional changes.
Many techniques have been developed to identify failure-inducing
code changes for evolving software [7, 20, 36, 44]. For example,
Delta Debugging aims to ﬁnd a minimal subset of changes that
still makes the test fail [71]. Test minimization techniques [20, 73]
simplify the failed test to ease comprehension for developers. Conf-
Suggester differs from these techniques in three aspects. First, exist-
ing techniques focus on helping software developers localize a bug,
while ConfSuggester targets software conﬁguration errors ﬁxable
by software end-users. As we have discussed in Section 3.5, con-
ﬁguration errors are fundamentally different than regression bugs.
They are mostly user-driven and do not indicate problems in the
source code. Second, most of the existing techniques identify what
(e.g., a snippet of code) causes the regression bug, but do not answer
the question of how (e.g., which conﬁguration option should a user
change?) to ﬁx the error. By contrast, ConfSuggester explicitly
guides users to suspicious conﬁguration options. Third, most of the
regression failure localization techniques [71] require a testing ora-
cle for automated correctness checking. However, such oracles are
often absent in practice. By contrast, ConfSuggester eliminates this
requirement by approximating the software behavioral difference as
the control ﬂow differences.
6.2 Software Conﬁguration Error Diagnosis
Software conﬁguration errors are time-consuming and frustrat-
ing to diagnose. To reduce the time and human effort needed to
troubleshoot software misconﬁgurations, prior research has applied
different techniques to the problem of conﬁguration error diagno-
sis [5, 6, 31, 47, 63, 66, 68]. For example, Chronus [66] relies on a
user-provided testing oracle to check the system behavior, and uses
virtual machine checkpoint and binary search to ﬁnd the point in
time where the program behavior switched from correct to incorrect.
AutoBash [55] ﬁxes a misconﬁguration by using OS-level specula-
tive execution to try possible conﬁgurations, examine their effects,
and roll them back when necessary. PeerPressure [63] statistically
compares conﬁguration states in the Windows Registry on different
machines. When a registry entry value on a machine exhibiting
erroneous behavior differs from the value usually chosen by other
machines, PeerPressure ﬂags the value as a potential error. More
recently, ConfAid [6] and X-Ray [4] use dynamic taint analysis to
diagnose conﬁguration errors by monitoring causality within the
program binary as it executes. ConfAnalyzer [47] uses dynamic
information ﬂow analysis to precompute possible conﬁguration error
diagnoses for every possible crashing point in a program.
ConfSuggester is signiﬁcantly different from the existing ap-
proaches. First, ConfSuggester is cognizant of software evolution
while most previous approaches are not [5, 6, 47, 66]. Second, Conf-
Suggester supports diagnosing both crashing and non-crashing er-
rors while most techniques can only diagnose conﬁguration errors
that lead to a crash or assertion failure [5, 6, 47, 66]. Third, un-
like several approaches [6, 66], ConfSuggester does not assume the
existence of a testing oracle. Fourth, ConfSuggester uses platform-
independent ofﬂine instrumentation and requires no alternation to
the underlying operating system or runtime environment. This dif-
fers from existing OS-level diagnosis techniques [55, 66]. Fifth,approaches like PeerPressure [63] and RangeFixer [68] beneﬁt from
the known schema of the Windows Registry and feature models, but
cannot diagnose conﬁguration errors that lie outside these speciﬁc
domains. Our technique of analyzing the execution traces is more
general.
6.3 Conﬁguration­Aware Software Analysis
Software conﬁguration management is a central component of
software product lines. Many conﬁguration-aware software analysis
techniques have been developed to analyze conﬁgurable software
systems [9, 30, 34, 38], improve software conﬁguration manage-
ment [8, 10, 17, 46, 59], and understand and test the behavior of a
conﬁgurable software system [2, 32, 45, 50, 51, 54].
Compared to ConfSuggester, these techniques have rather differ-
ent goals. They primarily focus on reducing the burden of conﬁgu-
ration management and preventing certain errors from happening,
or creating test suites to ﬁnd new errors in a conﬁgurable software
system earlier. They cannot diagnose an exhibited conﬁguration er-
ror during software evolution. By contrast, ConfSuggester links the
behavioral differences to a small number of conﬁguration options
and explicitly guides software end-users to the root causes.
7. CONCLUSION AND FUTURE WORK
This paper describes ConfSuggester, a technique to help software
users to troubleshoot conﬁguration errors. ConfSuggester focuses
on errors caused by software evolution, and recommends conﬁg-
uration options whose values should be changed to produce the
desired behavior on the new software version. In our experiments,
ConfSuggester accurately identiﬁed the root causes of 8 conﬁgura-
tion errors in 6 real-world software systems. The source code of
ConfSuggester is publicly available at: http://config-errors.
googlecode.com .
As future work, we plan a user study to evaluate ConfSuggester’s
usefulness to end-users. A challenge will be ﬁnding study partici-
pants who are familiar with only the old versions of given subject
programs. We also plan to develop techniques to automatically
distinguish software bugs from conﬁguration errors, when a soft-
ware system exhibits undesired behavior. Such techniques can help
formulate guidance regarding when the user should give up on Conf-
Suggester and assume the error is not related to conﬁguration.
8. ACKNOWLEDGMENTS
We thank Lingming Zhang for providing the conﬁguration error
in Javalanche and helpful discussion about using Javalanche. This
work was supported in part by NSF grants CCF-1016701 and CCF-
0963757.
9. REFERENCES
[1] Apache Server. http://httpd.apache.org/ .
[2] S. Apel, C. Kastner, and C. Lengauer. FEATUREHOUSE:
Language-independent, automated software composition. In
ICSE , 2009.
[3] T. Apiwattanapong, A. Orso, and M. J. Harrold. A
differencing algorithm for object-oriented programs. In ASE,
2004.
[4] M. Attariyan, M. Chow, and J. Flinn. X-ray: automating
root-cause diagnosis of performance anomalies in production
software. In OSDI , 2012.
[5] M. Attariyan and J. Flinn. Using causality to diagnose
conﬁguration bugs. In USENIX ATC , 2008.161[6] M. Attariyan and J. Flinn. Automating conﬁguration
troubleshooting with dynamic information ﬂow analysis. In
OSDI , 2010.
[7] A. Banerjee, A. Roychoudhury, J. A. Harlie, and Z. Liang.
Golden implementation driven software debugging. In FSE,
2010.
[8]J. Barreiros and A. Moreira. A model-based representation of
conﬁguration knowledge. In FOSD , 2009.
[9]E. Bodden, T. Tol ˆedo, M. Ribeiro, C. Brabrand, P. Borba, and
M. Mezini. SPLLIFT: statically analyzing software product
lines in minutes instead of years. In PLDI , 2013.
[10] D. Cooray, S. Malek, R. Roshandel, and D. Kilgore. Resisting
reliability degradation through proactive reconﬁguration. In
ASE, 2010.
[11] B. Dagenais and M. P. Robillard. Recommending adaptive
changes for framework evolution. In ICSE , 2008.
[12] C. R. B. de Souza and D. F. Redmiles. An empirical study of
software developers’ management of dependencies and
changes. In ICSE , 2008.
[13] D. Dig, C. Comertoglu, D. Marinov, and R. Johnson.
Automated detection of refactorings in evolving components.
InECOOP , 2006.
[14] R. Johnson. More details on today’s outage. https:
//www.facebook.com/notes/facebook-engineering/
more-details-on-todaysoutage/431441338919 .
[15] V olatile and Decentralized.
http://matt-welsh.blogspot.com/2013/05/
what-i-wish-systems-researchers-would.html .
[16] FireFox.
http://www.mozilla.org/en-US/firefox/new/ .
[17] B. J. Garvin, M. B. Cohen, and M. B. Dwyer. Using feature
locality: can we leverage history to avoid failures during
reconﬁguration? In ASAS , 2011.
[18] O. Giroux and M. P. Robillard. Detecting increases in feature
coupling using regression tests. In FSE, 2006.
[19] M. J. Harrold, J. A. Jones, T. Li, D. Liang, A. Orso,
M. Pennings, S. Sinha, S. A. Spoon, and A. Gujarathi.
Regression test selection for Java software. In OOPSLA , 2001.
[20] K. J. Hoffman, P. Eugster, and S. Jagannathan.
Semantics-aware trace analysis. In PLDI , 2009.
[21] S. Horwitz. Identifying the semantic and textual differences
between two versions of a program. In PLDI , 1990.
[22] S. Horwitz, T. Reps, and D. Binkley. Interprocedural slicing
using dependence graphs. In PLDI , 1988.
[23] J. Huang, C. Zhang, and J. Dolby. CLAP: recording local
executions to reproduce concurrency failures. In PLDI , 2013.
[24] Javalanche.
https://github.com/david-schuler/javalanche/ .
[25] JChord. http://pag.gatech.edu/chord/ .
[26] W. Jin and A. Orso. BugRedux: reproducing ﬁeld failures for
in-house debugging. In ICSE , 2012.
[27] JMeter. http://jmeter.apache.org/ .
[28] J. A. Jones, M. J. Harrold, and J. Stasko. Visualization of test
information to assist fault localization. In ICSE , 2002.
[29] T. Kamiya, S. Kusumoto, and K. Inoue. CCFinder: a
multilinguistic token-based code clone detection system for
large scale source code. IEEE Trans. Softw. Eng. ,
28(7):654–670, July 2002.
[30] K. C. Kang, M. Kim, J. Lee, and B. Kim. Feature-oriented
re-engineering of legacy systems into product line assets: a
case study. In SPLC , 2005.[31] L. Keller, P. Upadhyaya, and G. Candea. ConfErr: A tool for
assessing resilience to human conﬁguration errors. In DSN ,
2008.
[32] C. H. P. Kim, D. Marinov, S. Khurshid, and D. Batory. SPLat:
Lightweight dynamic analysis for reducing combinatorics in
testing conﬁgurable systems. In FSE, 2013.
[33] M. Kim, D. Notkin, D. Grossman, and G. Wilson Jr.
Identifying and summarizing systematic code changes via rule
inference. IEEE Trans. Softw. Eng. , 39(1):45–62, Jan. 2013.
[34] I. H. Kr ¨uger, R. Mathew, and M. Meisinger. From scenarios to
aspects: exploring product lines. In SCESM , 2005.
[35] B. Li, X. Sun, H. Leung, and S. Zhang. A survey of
code-based change impact analysis techniques. Software
Testing, Veriﬁcation and Reliability , 2012.
[36] C. Liu, J. Yang, L. Tan, and M. Haﬁz. R2Fix: Automatically
generating bug ﬁxes from bug reports. In ICST , 2013.
[37] S. McCamant and M. D. Ernst. Predicting problems caused by
component upgrades. In ESEC/FSE , 2003.
[38] T. Mende, F. Beckwermert, R. Koschke, and G. Meier.
Supporting the grow-and-prune model in software product
lines evolution using clone detection. In CSMR , 2008.
[39] S. Meng, X. Wang, L. Zhang, and H. Mei. A history-based
matching approach to identiﬁcation of framework evolution.
InICSE , 2012.
[40] Conﬁguration error brings down the Azure cloud platform.
http://www.evolven.com/blog/
configuration-error-brings-down-the-azure-cloud\
-platform.html .
[41] MySQL. http://www.mysql.com/ .
[42] V . Nagarajan, R. Gupta, X. Zhang, M. Madou, and
B. De Sutter. Matching control ﬂow of program versions. In
2007 , 2007.
[43] T. T. Nguyen, H. A. Nguyen, N. H. Pham, J. Al-Kofahi, and
T. N. Nguyen. Recurring bug ﬁxes in object-oriented
programs. In ICSE , 2010.
[44] D. Qi, A. Roychoudhury, Z. Liang, and K. Vaswani. Darwin:
an approach for debugging evolving programs. In FSE, 2009.
[45] X. Qu, M. B. Cohen, and G. Rothermel. Conﬁguration-aware
regression testing: an empirical study of sampling and
prioritization. In ISSTA , 2008.
[46] R. Rabiser, P. Gr ¨unbacher, and M. Lehofer. A qualitative study
on user guidance capabilities in product conﬁguration tools. In
ASE, 2012.
[47] A. Rabkin and R. Katz. Precomputing possible conﬁguration
error diagnoses. In ASE, 2011.
[48] Randoop. http://code.google.com/p/randoop/ .
[49] Misconﬁguration brings down entire .se domain in Sweden.
http://www.circleid.com/posts/misconfiguration_
brings_down_entire_se_domain_in_sweden .
[50] W. Shang, Z. M. Jiang, H. Hemmati, B. Adams, A. E. Hassan,
and P. Martin. Assisting developers of big data analytics
applications when deploying on hadoop clouds. In ICSE ,
2013.
[51] N. Siegmund, S. S. Kolesnikov, C. K ¨astner, S. Apel, D. Batory,
M. Rosenm ¨uller, and G. Saake. Predicting performance via
automated feature-interaction detection. In ICSE , 2012.
[52] Y . J. Song, F. Junqueira, and B. Reed. Bft for the skeptics. In
Proc. ACM SOSP’09 Work in Progress Session .
[53] M. Sridharan, S. J. Fink, and R. Bodik. Thin slicing. In PLDI ,
2007.
[54] M. Staats, M. W. Whalen, and M. P. Heimdahl. Programs,162tests, and oracles: the foundations of testing revisited. In
ICSE , 2011.
[55] Y .-Y . Su, M. Attariyan, and J. Flinn. AutoBash: improving
conﬁguration management with operating system causality
analysis. In SOSP , 2007.
[56] W. N. Sumner and X. Zhang. Comparative causality:
explaining the differences between executions. In ICSE , 2013.
[57] Synoptic. http://code.google.com/p/synoptic/ .
[58] Y . Tao, Y . Dang, T. Xie, D. Zhang, and S. Kim. How do
software engineers understand code changes?: an exploratory
study in industry. In FSE, 2012.
[59] M. H. Ter Beek, H. Muccini, and P. Pelliccione. Guaranteeing
correct evolution of software product lines: setting up the
problem. In SERENE , 2011.
[60] S. Thummalapenta, L. Cerulo, L. Aversano, and M. Di Penta.
An empirical study on the maintenance of source code clones.
Empirical Softw. Engg. , 15(1), Feb. 2010.
[61] L. Torczon and K. Cooper. Engineering A Compiler . Morgan
Kaufmann Publishers Inc., San Francisco, CA, USA, 2nd
edition, 2011.
[62] WALA. http://sourceforge.net/projects/wala/ .
[63] H. J. Wang, J. C. Platt, Y . Chen, R. Zhang, and Y .-M. Wang.
Automatic misconﬁguration troubleshooting with
PeerPressure. In OSDI , 2004.
[64] M. Weiser. Program slicing. In ICSE , 1981.
[65] Weka. www.cs.waikato.ac.nz/ml/weka/ .
[66] A. Whitaker, R. S. Cox, and S. D. Gribble. Conﬁguration
debugging as search: ﬁnding the needle in the haystack. In
OSDI , 2004.[67] Z. Xing and E. Stroulia. UMLDiff: an algorithm for
object-oriented design differencing. In ASE, 2005.
[68] Y . Xiong, A. Hubaux, S. She, and K. Czarnecki. Generating
range ﬁxes for software conﬁguration. In ICSE , 2012.
[69] Z. Yin, X. Ma, J. Zheng, Y . Zhou, L. N. Bairavasundaram, and
S. Pasupathy. An empirical study on conﬁguration errors in
commercial and open source systems. In SOSP , 2011.
[70] A. T. T. Ying, G. C. Murphy, R. Ng, and M. C. Chu-Carroll.
Predicting source code changes by mining change history.
IEEE Trans. Softw. Eng. , 30(9):574–586, Sept. 2004.
[71] A. Zeller. Yesterday, my program worked. today, it does not.
why? SIGSOFT Softw. Eng. Notes , 24(6):253–267, 1999.
[72] L. Zhang, M. Kim, and S. Khurshid. Localizing
failure-inducing program edits based on spectrum information.
InICSM , 2011.
[73] S. Zhang. Practical semantic test simpliﬁcation. In ICSE
(NIER Track) , 2013.
[74] S. Zhang and M. D. Ernst. Automated diagnosis of software
conﬁguration errors. In ICSE , 2013.
[75] S. Zhang, Y . Lin, Z. Gu, and J. Zhao. Effective identiﬁcation
of failure-inducing changes: a hybrid approach. In PASTE ,
2008.
[76] S. Zhang, C. Zhang, and M. D. Ernst. Automated
documentation inference to explain failed tests. In ASE, 2011.
[77] T. Zimmermann, P. Weisgerber, S. Diehl, and A. Zeller.
Mining version histories to guide software changes. In ICSE ,
2004.163