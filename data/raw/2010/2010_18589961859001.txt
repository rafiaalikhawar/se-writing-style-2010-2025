Analyzing Security Architectures
Marwan Abi-Antoun
Department of Computer Science
Wayne State University
mabiantoun@wayne.eduJeffrey M. Barnes
Institute for Software Research
Carnegie Mellon University
jmbarnes@cs.cmu.edu
ABSTRACT
We present a semi-automated approach, Secoria , for an-
alyzing a security runtime architecture for security and fo r
conformance to an object-oriented implementation. Type-
checkable annotations describe architectural intent with in
the code, enabling a static analysis to extract a hierarchic al
object graph that soundly reﬂects all runtime objects and
runtime relations between them. In addition, the annota-
tions can describe modular, code-level policies. A separat e
analysis establishes traceability between the extracted o b-
ject graph and a target architecture documented in an ar-
chitecturedescription language. Finally, architectural types,
properties, and logic predicates describe global constrai nts
on the target architecture, which will also hold in the imple -
mentation. We validate the Secoria approach by analyzing
a 3,000-line pedagogical Java implementation and a runtime
architecture designed by a security expert.
Categories and Subject Descriptors
D.2.11 [Software Engineering ]: Software Architectures
General Terms
Design, Security, Veriﬁcation
1. INTRODUCTION
Companies such as Boeing and Microsoft have been us-
ingthreat modeling [38] as a lightweight approach to reason
about security, to capture and reuse security expertise and
to ﬁnd security design ﬂaws during development. Propo-
nents of threat modeling have employed it in a number of
industrial-scale projects and report impressive results. Mi-
crosoft, for example, claims that threat modeling led to a
50% reduction in security vulnerabilities [16], and around
1,500 data ﬂow diagrams (DFDs) were manually reviewed
during the development of Windows Vista.
When a security expert asks a developer to build a se-
curity architecture for a system under study, the developer
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and the full citation on the ﬁrst page. To cop y otherwise, to
republish, to post on servers or to redistribute to lists, re quires prior speciﬁc
permission and/or a fee.
ASE’10, September 20–24, 2010, Antwerp, Belgium.
Copyright 2010 ACM 978-1-4503-0116-9/10/09 ...$10.00.typically produces a diagram mostly from his recollection
of how the system works, with little tool support to ex-
tract such an architecture from the code. Then, during the
security review, the experts study the architecture, assig n
to the components diﬀerent architectural properties such a s
trustLevel orprivacyLevel , and enumerate all possible com-
munication between the more trusted and the less trusted
components of the system. They also analyze the commu-
nication between components that contain personally iden-
tiﬁable information, and those that do not.
One potential hurdle to achieving signiﬁcantly better de-
fect reduction is that the architecture may not show all the
communication that is present in the system. As a result, an
architectural-level analysis may be incomplete. While any
architecture-based approach suﬀers from these problems, s e-
curity architectures pose special challenges.
A security architecture1is an example of a runtime archi-
tecture, which shows runtime components and connectors,
useshierarchicaldecomposition, andpartitionsasystemi nto
tiers [8]. Today, the tools for extracting and analyzing con -
formance of runtime architectures are immature [22, 11],
compared to tools for the code architecture [31].
Moreover, a security analysis must consider the worst and
not the typical case of possible component communication.
The analysis results are valid only if the architecture re-
veals all objects and relations that may exist at runtime—in
any program run. This requires a static analysis, which can
capture all possible executions. In contrast, a dynamic ana l-
ysis, which extracts an architecture or analyzes conforman ce
basedononeor more programruns[34], maymiss important
objects or relations that arise only in other executions.
The contributions of this paper are:
•The ﬁrst architecture-centric approach, Secoria2,
that enables both reasoning at the level of a security
runtime architecture, and relating it to the code at the
same time, as compared to previous approaches which
do one or the other. The approach can enforce both
code-level and global architectural constraints.
•An end-to-end validation of Secoria using a real,
3,000-line Java implementation of a runtime architec-
ture designed by a security expert.
1Threat modeling typically uses a data ﬂow diagram , which
describes how data enters, leaves and traverses the system,
shows data sources and destinations, trust boundaries and
processes that data goes through [38]. Here, a security ar-
chitecture shows points-to rather than data ﬂow connectors.
2Secoria stands for Se curity c onformance of o bject-
oriented r untime vi ews of architecture.
3
Secoria specializes the Scholia approach by Abi-Antoun
and Aldrich to analyze, at compile time, communication
integrity between arbitrary object-oriented code and a hi-
erarchical, target runtime architecture [2]. Communication
integrity [25]meansthateachcomponentintheimplementa-
tion may only communicate directly with the components to
which it is connected in the architecture. Scholia requires
adding typecheckable annotations, to establish traceabil ity
between the target architecture and the code.
Ourdesign intent–basedanalysis involves an iterative pro -
cess with two main stages: the conformance stage (Sect. 2),
which relates a security architecture to code, and the en-
forcement stage (Sect. 3), which enforces architectural in-
tent. We evaluate the Secoria approach by applying it to a
real system (Sect. 4). Finally, we conclude with a discussio n
(Sect. 5) and a brief survey of related work (Sect. 6).
2. CONFORMANCE STAGE
Architectural reasoning about security is best accom-
plished with a runtimearchitecture rather thana code archi -
tecture. Unfortunately, extracting the runtime architect ure
is diﬃcult. At runtime, an object-oriented system can be
represented as an object graph : nodes correspond to objects,
and edges correspond to relations between objects. Taking
a snapshot of the heap at runtime reveals the structure at
that instant in great detail, but the profusion of objects
makes it diﬃcult to get a high-level picture, without exten-
sive graph summarization and manipulation [28]. Moreover,
such a snapshot shows only one or more executions, mean-
ing the developer may miss important objects or relations
that arise only in other executions. On the other hand, a
sound static analysis can extract an object graph that cap-
tures all executions. But previous static analyses produce
non-hierarchical object graphs that explain runtime inter -
actions in detail but convey little architectural abstract ion.
A ﬂat object graph mixes low-level objects such as HashMap
with architecturallyrelevantobjects suchas CryptoReceipt ,
and a developer has no easy way to distinguish them. Even
for a small program, a ﬂat object graph typically does not
conveysuﬃcientarchitecturalabstractiontobeusedforco n-
formance analysis.
2.1 Ownership Domain Annotations
A central diﬃculty is that architectural hierarchy is not
readily observable in arbitrary code. To achieve hierarchy in
an object graph, Scholia requires that a developer pick a
top-level object as a starting point, then use modular own-
ership annotations in the code [6] to impose a conceptual
hierarchy on objects.
The annotations specify object encapsulation, logical con -
tainment and architectural tiers within the code, construc ts
which are not explicit in most programming languages. The
Scholia toolsuseexistinglanguagesupportforannotations.
In addition, the annotations implement a type system, so a
typechecking tool can validate the annotations and identif y
inconsistencies between the annotations and the code.
Anownership domain is a conceptual group of objects
with an explicit name and explicit policies that govern how
a domain can reference objects in other domains [6]. Each
object is assigned to a single domain that does not change
at runtime. A developer indicates the domain of an object
by annotating each reference to that object in the program.The annotations deﬁne two kinds of object hierarchy, log-
ical containment and strict encapsulation, deﬁned below.
Logical Containment. A public domain provides logical
containment , thus making an object conceptually “part of”
another object. Having access to an object gives the ability
to access objects inside all its public domains. For example ,
LocalKeyStore has a public domain, KEYS, to holdLocalKey
objects (Fig. 1).
Strict Encapsulation. A private domain provides strict
encapsulation . Thus, a publicmethod cannot return an
alias to an object in a private domain, even though the Java
type system allows returning an alias to a ﬁeld marked pri-
vate. For example, LocalKeyStore stores the ArrayList of
LocalKey objects,keys, in a private domain, OWNED(Fig. 1).
2.2 Object Graph Extraction
Scholia extracts an Ownership Object Graph (OOG)
that provides architectural abstraction by ownership hier ar-
chy, by showing architecturally signiﬁcant objects near th e
top of the hierarchy and data structures further down. An
object graph can also provide abstraction by types, by col-
lapsing objects further based on their declared types.
The visualization uses box nesting to indicate contain-
ment of objects inside domains and domains inside objects
(Fig. 1). Dashed-border, white-ﬁlled boxes represent do-
mains. Solid-ﬁlled boxes represent objects. Solid edges re p-
resent ﬁeld references. An object labeled obj:Tindicates an
object reference objof typeT, which we then refer to either
as“object obj”or as“Tobject,”meaning“an instance of the
Tclass.” E.g., LocalKey is inside KEYS. A private domain
has a thick, dashed border; a public domain, a thin one. A
(+) symbol on an object or a domain indicates that it has a
collapsed substructure.
An extracted object graph is soundin two respects. First,
each runtime object has exactly one representative in the
object graph. Second, the object graph has edges that cor-
respond to all possible runtime points-to relations betwee n
those objects. Soundness is important for an architectural -
level security analysis. For instance, if an architecture
showed the same runtime object as two components in the
architecture, an analysis could assign those two component s
diﬀerent values for the key trustLevel property and poten-
tially invalidate the analysis results.
In addition, ownership-parametric library code, such as
ArrayList , often creates interesting architectural relation-
ships in application objects, when formal parameters are
bound to actual domains on speciﬁc objects created by the
application. The object graph resolves these parameters to
ensure that the relevant object relations appear at the leve l
of the global application object structures; hence, there i s
an edge from keystolocalKey (Fig. 1).
2.3 Communication Integrity
To analyze communication integrity using Scholia , a
developer follows the extract-abstract-check strategy [3 1],
as follows: (1) the developer documents the designed run-
time architecture; (2) she adds annotations to the code and
typechecks them using ArchCheckJ ; (3) then, she uses
ArchRecJ toextractan object graph; (4) she then uses
ArchCog toabstract an object graph into a built architec-
ture; (5) ﬁnally, she uses ArchConf to structurally compare
the built and the designed architectures, and checkand en-
forcecommunication integrity in the designed architecture.
4 KEYS OWNEDlocalKey:
LocalKeykekSpec(+):
SecretKeySpeckeys(+):
ArrayList<LocalKey>
keyStore:
LocalKeyStore
Figure 1: The LocalKeyStore OOG.
A developer can perform any of the following: (a) Re-
ﬁne the annotations iteratively based on visual inspection of
an extracted object graph before it is abstracted; (b) Fine-
tune the abstraction of an object graph into an architec-
ture; (c) Manually guide the comparison of the built and
the designed architecture, if the structural comparison fa ils
to perform the proper match; (d) Correct the code if she de-
cides that the designed architecture is correct, but that th e
implementation violates the architecture; or (e) Update th e
designed architecture if she determines that the implemen-
tation highlights an important omission in the architectur e.
Following Murphy’s terminology [31], the analysis ﬁnds:
•Convergence: a node or an edge that is in boththe
built architecture and the designed architecture;
•Divergence: a node or an edge that is in the built
architecture, but notin the designed architecture;
•Absence: a node or an edge that is in the designed
architecture, but notin the built architecture.
When adding annotations and extracting OOGs, the goal
is to minimize the number of annotation warnings and the
number of objects in the top-level domains. When analyzing
communication integrity, the goal is to minimize the number
of divergences and absences, or to ensure that they do not
correspond to cases where the implementation violates the
architectural intent.
3. ENFORCEMENT STAGE
Having analyzed conformance and established traceabil-
ity between target architecture and code, Secoria now re-
quires us to identify implementation-level violations of a rch-
itectural intent by enriching the designed architecture wi th
types, properties, and constraints.
3.1 Code-Level Constraints
At the code level, we use annotations to enforce local,
modular constraints, i.e., ones that are checked one class at
a time. A domain link annotation speciﬁes policies that gov-
ern how a domain can reference objects in other domains [6],
which we illustrate by example. A Listassumes that its
owning domain can access the list elements stored in the
ELTSdomain parameter. In turn, when a LocalKeyStore
instantiates a List, and binds ELTStoKEYS,LocalKeyStore
must satisfy that assumption. Hence, LocalKeyStore de-
clares adomain link fromOWNEDtoKEYS.
3.2 Architectural Description
We describe the target architecture in an ArchitectureDe-
scription Language (ADL) and set architectural types, prop -
erties, and predicates to enforce global constraints as wel l
as security design intent. We use Acme, a general-purpose
ADL with mature, publicly available tool support [12].
Most ADLs support the following elements. A component
is a unit of computation and state. A connector represents
an interaction between components. A component can op-tionally be decomposed into a nested subarchitecture. A
property is a name-and-value pair associated with an ele-
ment. A groupis a named set of elements, such as a tier. To
specify architectural intent, architectural types, prope rties
and constraints can be set.
Architectural Types. Many ADLs, including Acme, sup-
port a type system for architectural elements. Thus, there
may be many component instances that all belong to a sin-
glecomponent type , which deﬁnes properties and constraints
that are common to all instances, and likewise for connec-
tor types. Acme’s type system for architectural elements
supports inheritance, so one element type may inherit from
another. Types are helpful for architectural description n ot
only because they save work (by abstracting out constraints
common to multiple instances), butalso because they match
the way architects naturally think about software systems.
These element types are used to build up families, which en-
capsulate element types that are applicable to a whole class
of software architectures, such as all multi-tier architec tures
or all pipe-and-ﬁlter architectures.
InSecoria , we model a DFD as a component-and-
connector runtime architecture [8, pp. 364–365]. A DFD has
a ﬁxed set of component types: Process,HighLevelProcess ,
DataStore andExternalInteractor [36]. AProcessrepresents
a task in the system that processes data or performs some
action based on the data. A DataStore represents a reposi-
tory where data is saved or retrieved but not changed, such
as a database or ﬁle. An ExternalInteractor represents an en-
tity that exists outside the system being modeled and which
interacts with the system at an entry point: it is either the
source or destination of data. Typically, a human who in-
teracts with the system is modeled as an ExternalInteractor .
One connector type, DataFlow , represents data transferred
between elements.
DFDs used in threat modeling often separate elements
that have diﬀerent privilege levels using a Boundary to de-
scribe locations where an adversary could mount a privilege
impersonation attack, or where a machine or process bound-
ary may be crossed [36, p. 90]. Here, we model a Boundary
as an architectural runtime tier, which is represented in th e
annotations as a domain.
InahierarchicalDFD,a HighLevelProcess isexpandedinto
a lower-level DFD. Typically, a context diagram shows the
entire functionality of the system represented as a single
node. That node is then broken into multiple elements in a
Level-0 diagram. From there, diagrams at Level-1, Level-2,
and so on can more precisely model security-critical proces s-
ing [15, p. 76]. This model naturally ﬁts with a hierarchical
representation of runtime architecture.
Fig. 4(a) shows several element type deﬁnitions from the
Acme DFD family. The component type DataStore inher-
its from DFDComponent , which in turn inherits from DFD-
TypeT, a base element type that deﬁnes common properties
such astrustLevel andhowFound . Similarly, we deﬁned prop-
erty types (mostly, enumerated types), properties and rule s
(predicates) that use properties and types to analyze and
enforce security qualities. The DFD family is reusable for
other systems, and is available in an online appendix [1].
Architectural Properties. Secoria assigns element-level
properties to the various architectural component instanc es.
For example, several rules for checking information disclo -
sure rely on a key trustLevel property. Because all DFD
elements must have such a property, the property is deﬁned
5on the base architectural type, and thus inherited by all its
subtypes. Usually, distinct component instances have diﬀe r-
ent values for architectural properties such as trustLevel .
In addition to the common properties, there are type-
speciﬁc properties. For instance, DataStore -speciﬁc proper-
ties include readProtection ,writeProtection ,secrecyMethod ,
andintegrityMethod . Many of these properties are enumera-
tionswithpre-deﬁnedvaluesandadefaultvalueof Unknown .
If no meaningful value for a property is speciﬁed and if
providing that additional information can enable addition al
checks, the analysis requests more information from the
users, e.g., bysuggesting theyenteravalueforthe trustLevel .
Well-Formedness Constraints. A DFD must obey sev-
eral well-formedness rules. Forexample, two DataStore scan-
not be connected directly. Indeed, data cannot travel from
oneDataStore to another without the aid of a Process.
Information Flow Constraints. Threat modeling looks
for vulnerabilities in the areas of S pooﬁng, T ampering,
Repudiation, I nformation Disclosure, D enial of Service, and
Elevation of Privilege (STRIDE) [15, pp. 83–87].
Theconstraints analyzethearchitecturefor securityﬂaws .
The analysis checks the provided properties and automati-
cally requests more information where applicable. At a high
level, the analysis works as follows:
1.Analyze threats: one rule checks for the threat of
tampering. For example, an attacker can tamper with
the contents of a DataStore whosetrustLevel isHigh.
2.Analyze mitigations: for the tampering rule, the
analysis checks if readProtection andwriteProtection
areSystemACLs . In that case, the threat of tampering
is reduced.
3.Suggest remedies : for the tampering rule, the anal-
ysis checks if readProtection andwriteProtection are
None. In that case, the analysis suggests the following
remedy: “Use access control lists.” A remedy is often
just an informational message for the modeler. Unless
the remedy requires changing the DFD or its security
properties, the analysis cannot always check that the
remedy is performed.
We formalized constraints that focus mostly on global in-
formation ﬂow vulnerabilities (Spooﬁng, Tampering, Infor -
mation Disclosure). Checkingfor ﬂaws suchas Denial ofSer-
vice or Elevation of Privilege requires tracking state chan ges
in the system, which the extracted architecture does not
presently have. A description of the full set of rules cur-
rently implemented is in a companion technical report [4].
General Constraints. First-order logic predicates [29] en-
force structural, application-speciﬁc constraints such a s:
•Component sc1andc2are never connected directly:
!connected(c1, c2)
•NoComponent of typeT1directly connects to one of
typeT2;
forall c1: Component in self.COMPONENTS |
forall c2: Component in self.COMPONENTS |
connected(c1,c2) -> !(declaresType(c1,T1)
AND declaresType(c2,T2));
•No component in Groupg1communicates directly with
any component in Groupg2.
forall m1 in g1.members |
forall m2 in g2.members | !connected(m1, m2);
During this stage, the goal is to reduce the number of
violations of architectural types and constraints.Enforcing predicates at thearchitectural level is not nove l.
But since Secoria has the traceability between architecture
and code, these architectural constraints enforce global c on-
straints on the application structure in the code.
3.3 Constraining Evolution
During software evolution, it is common for developers
to introduce architectural violations that may lead to se-
curity vulnerabilities. Relating the target architecture and
the code, together with eﬀective change management, can
help detect unwanted architectural violations more eﬀec-
tively than inspecting the program, with or without anno-
tations. In the unannotated program, changing the runtime
architecture is as simple as storing or passing a reference
to an object. The ownership annotations help to constrain
the evolution of the program somewhat. But a developer
can still add communication paths, e.g., by adding domain
links. Admittedly, manual code inspections could be used to
audit more closely revisions that modify domain link anno-
tations. Even so, the annotations can enforce only modular
constraints. So it is still necessary to identify code modiﬁ ca-
tions that impact the global architectural structure, idea lly
using an automated approach.
Extracting the up-to-date built architecture, analyzing i ts
conformance to a target architecture, and checking arch-
itectural constraints can make it easier to trigger an arch-
itectural review. Structural constraints in the target arc hi-
tecture can enforce various security policies. Indeed, emp iri-
calevidencesuggeststhatsuchpoliciesarefrequentlynee ded
during software evolution. For instance, a study using a
well-designed framework showedthatstudentssubvertedth e
framework’s design by passing to and storing additional ob-
jects in theconstructors ofclasses thatimplementedtheco re
framework interfaces [20]. Such unconstrained evolution o f
a system might lead to serious architectural violations, an d
as a result, to security vulnerabilities.
4. EV ALUATION
We validate the end-to-end Secoria approach using
CryptoDB, a secure database system designed by security
expert Kevin Kenan [19]. CryptoDB follows a database ar-
chitecture that provides cryptographic protections again st
unauthorized access, and includes a 3,000-line sample impl e-
mentation inJava. The presence ofboth a Java implementa-
tion and an informal architectural description makes Cryp-
toDB an appropriate choice to demonstrate our approach.
4.1 Conformance Stage
During this stage, we iterated the process of annotating
the code and extracting OOGs until an extracted OOG and
the target architecture had roughly similar tiers, similar hi-
erarchical decomposition, and a similar number of compo-
nents in each tier. We then modeled the target architecture,
analyzed its communication integrity and established trac e-
ability to the code.
4.1.1 Gather Available Documentation
We studied the architectural documentation available for
CryptoDB, which included DFDs (e.g., Fig. 2) and accom-
panying, explanatorytext[19]. Weusedthesematerials onl y
as a guide, as the implementation departed from this docu-
mentation in some respects (see Sect. 4.1.4 for an example).
We mined the diagrams for the architecturally signiﬁcant
6elements, the top-level tiers, and the hierarchical system de-
composition. The latter was based on the decomposition of
the system into several Level- nDFDs.
It soon became apparent that the documentation and the
code used diﬀerent terminology. For example, the docu-
mentation referred to a “key manager,” but the code had
aKeyTool. Here, we use the names from the implemen-
tation.Scholia uses a structural comparison to compare
the built and the target architecture, so the names need
not match exactly. For example, the relation between the
DFD (Fig. 2) and the OOG (Fig. 3) is as follows: keyAlias
corresponds to KeyManifest ,ciphertoEngine,provider to
CryptoProvider ,mgrtoCryptoConsumer , andcryptoReceipt
toReceipts. The full mapping between the two terminologies
is in the companion report [3].
4.1.2 Annotate the Code
We organized instances of the core types into four top-
level domains, as follows:
•CONSUMERS : hasCustomerManager , andEncryption -
Requests, such as CustomerInfo andCreditCardInfo ;
•PROVIDERS: hasProvider ,EngineWrapper ;
•KEYSTORAGE: hasKeyAlias es andLocalKeyStore ;
•KEYMANAGEMENT: has aKeyTool object.
For several classes Ci, we also deﬁned nested public domains
Di, which we refer to using the Ci::Dinotation:
•CustomerManager ::RECEIPTS hasCryptoReceipt s;
•LocalKeyStore ::KEYShas instances of LocalKey ,
SecretKeySpec , etc. (Fig. 1);
•Provider ::RCPTMGR hasCompoundReceipt objects.
4.1.3 Extract Object Graphs
We then used ArchRecJ to extract an OOG from the
annotated code. An OOG illustrates some of the key diﬀer-
ences between a code and a runtime architecture. For ex-
ample, inside the Provider ’sRCPTMGR domain, a Compound -
Receipt encapsulates a HashMap that maps String to
CryptoReceipt objects. In turn, each EncryptionRequest
in theCONSUMERS domain has a HashMap that maps Strings
toStrings. Thus, an OOG may show distinct Hashtable
objects, whereas a class diagram would show only one
Hashtable class.
Abstraction by Types. In addition to conveying arch-
itectural abstraction by ownership hierarchy, an OOG can
abstract objects by their types. To use that technique,
a developer speciﬁes which types are more architecturally
signiﬁcant than others. Based on this optional input, an
OOG merges closely related objects in a given domain,
based on their declared types. For example, without ab-
straction by types, the OOG would show CustomerInfo
andCreditCardInfo as two objects in the CONSUMERS do-
main. In order to make the OOG comparable to the tar-
get architecture, which has only one component to repre-
sent“protected data,”we use abstraction by types to merge
these two objects into one. Indeed, both CustomerInfo and
CreditCardInfo implement the EncryptionRequest inter-
face, so we made it an architecturally signiﬁcant type.
Hierarchy. Hierarchy allows both high-level and detailed
understanding, by expanding or collapsing selected ele-
ments. The most detailed graph of CryptoDB, the Level-2
OOG (Fig. 3), has all substructures expanded, such as those
formgr,provider ,engine, etc. A Level-1graph (notshown)Business
Logic
Storage
Data
Result
Write
ReadWrite
ReadCrypto
Consumer
ResultData
ResultRequestLookup
Crypto
Result
ResultResultRequest
RequestRequest
Initializer
EngineEncoderReceipt
Manager
ProviderKey IDKey ManifestDataProtectedReceipts
Figure 2: Level-2 DFD for CryptoDB [19, Fig. 6.1].
 PROVIDERS RCPTMGR owned owned owned
 ENGINE
 CONSUMERS RECEIPTS owned ownedreceipts(+):
HashMap
receipts:
CompoundReceipt(+)
provider:
Providerengine:
EngineWrapper
cryptoReceipt2:
CryptoReceiptencryptionRequest:
EncryptionRequest(+)
cipher(+):
Cipher
(+)
mgr:
CustomerManagerplaintexts(+):
HashMap
Figure 3: CryptoDB OOG.
7FamilyDFD = { // Snippets from security family DFD.acme
Property Type TrustLevelT =
Enum{Low, Medium, High, None, Unknown};
Property Type HowFoundT =
Enum{HardCoded, FromPointer, Mixed, Unknown};
...
Element Type DFDTypeT = {
Property trustLevel : TrustLevelT;
Property howFound : HowFoundT;
Property owner : OwnerT;
Property name :string;
...
}
Component Type DFDComponent extends DFDTypeT;
Component Type DataStore extends DFDComponent with{
Property readProtection : DataAccessProtectionT;
Property writeProtection : DataAccessProtectionT;
Property secrecyMethod : InformationSecrecyT;
Property integrityMethod : InformationIntegrityT;
...
}
analysis notFoundFromPointer(c:DFDComponent): boolean =
hasValue (c.howFound) AND!(c.howFound==FromPointer);
ruleNoComponentsFoundFromPointer = heuristic
forallc: DFDComponent in self.COMPONENTS |
declaresType (c,DFDComponent)->notFoundFromPointer(c)
<<label : string="Ensure there is no pointer that
would allow one entity to spoof another." ;>>;
...
}
(a) Type deﬁnitions from our DFD family description.
SystemCryptoDBTarget: SyncFamily, DFD = new... {
...
Component KeyVault : DataStore = newDataStore ... {
Property label = "KeyVault" ;
Property trustLevel = High;
Property howFound = HardCoded;
Property owner = ThisComponent;
...
}
}
(b) A component from our CryptoDB system description.
Figure 4: Excerpts from our Acme speciﬁcation.
has these substructures collapsed, while the Level-0 graph
shows only the top-level domains (Fig. 6).
4.1.4 Model the Target Architecture
We then documented the target architecture for Cryp-
toDB using Acme, basing it largely on the aforementioned
DFDs. We also represented the subarchitectures corre-
sponding to second-level DFDs. We used Acme groups to
partition the architecture into broad areas of responsibil ity.
We added directional connectors based on the text describ-
ing thearchitecture. Inmanycases, thepoints-toconnecto rs
were the reverse of the data ﬂow connectors in the DFDs.
We used the DFD Acme family (Section 3.2). Fig. 4(b)
shows the Acme description of the CryptoDB KeyVault , il-
lustrating how the architectural types are instantiated an d
the properties set on the individual component instances.
SyncFamily is a “mix-in” family used by the conformance
analysis. In particular, SyncFamily deﬁnes properties that
maintain the traceability between the target architecture
and the code. The full Acme speciﬁcation of the CryptoDB
target architecture is in an online appendix [1].
Getting the target architecture right required a process
of iteration. This was due in large measure to the ways in
which the implementation departed from the architecture.The implementation, in our case, was a demonstrative im-
plementation found in a security book, not a fully faithful
implementation of the design. In particular, the implemen-
tation was simpliﬁed in many respects. For instance, Kenan
identiﬁes in principle a number of subcomponents of the
cryptographic provider: an initializer, an encoder, a rece ipt
manager, an engine interface, and others [19, §6.1]. In the
implementation, the provider was nearly monolithic; few of
these distinct responsibilities were actually allocated t o sep-
arate objects. We had to modify our target architecture to
accommodate the casual way in which the implementation
realized the described architecture. (If we had not done so,
we would have had to deal with these discrepancies later in
the conformance stage.) In a system in which the imple-
mentation more faithfully realized the design, less iterat ion
would be required.
This iteration was also necessitated by the mismatch be-
tweenconceptualandimplementation-levelarchitectures . In
Acme, a component may have a representation , which is a
decomposition of that component into its constituent parts .
Thus, acomponentmaybeasubsystemwithitsowninternal
structure. In an OOG, and the resulting built architecture,
there is also a natural notion of decomposition—a compo-
nent collapses one or more objects, which are its constituen t
parts—but it is governed by ownership and type structures.
Another change we made in the process of iteration was to
delete the external interactors. Although useful for showi ng
the endpoints of the system, they did not correspond to any
code elements (since they were, of course, external to the
system), so they were always going to show up as absences.
4.1.5 Analyze Communication Integrity
We then analyzed communication integrity using Arch-
Conf. The resulting conformance view of the target archi-
tecture (Fig. 5) shows convergences, divergences, and ab-
sences (see Sect. 2.3) and enables tracing from each arch-
itectural element to the corresponding lines of code.
4.2 Enforcement Stage
4.2.1 Deﬁne Code-Level Constraints
We deﬁned domain links and assumptions, as discussed
in Sect. 3.1. The resulting domain link declarations in
the top-level class were largely expected (Fig. 6). There
were bidirectional links between PROVIDERS andCONSUMERS .
But the links were unidirectional from PROVIDERS andKEY-
MANAGEMENT toKEYSTORAGE . There were no links from CON-
SUMERStoKEYSTORAGE . Note that domain link permissions
are not transitive.
4.2.2 Set Architectural Types
We then imported the DFD security family into the Cryp-
toDB system, and assigned to components and connectors
in the system the corresponding types we had deﬁned ear-
lier. For example, we assigned to the component instance
KeyVault theDataStore type. In Acme, an element can have
multiple types. See Fig. 4(b).
4.2.3 Set Architectural Properties
By assigning to the component KeyVault theDataStore
type, all the properties deﬁnedon the DataStore type and its
supertypes, e.g., howFound , become available on KeyVault
8Figure 5: CryptoDB conformance view in Acme-
Studio, showing convergences ( ), divergences ( ),
and absences ( ).
and their values can be set independently on each instance.
For example, we set the trustLevel to beHigh(see Fig. 4(b)).
4.2.4 Set Architectural Constraints
Security Constraints. Similarly, once we import the
family and assign types to architectural elements, all the
security-related predicates are immediately enforced.
Application-Speciﬁc Constraints. For CryptoDB, we
found several restrictions on the communication allowed in
the architecture. We formalized these as constraints and
added them to the target architecture. Some of the con-
straints include:
1.KeyManager should not connect to EngineWrapper ;
2.KeyVault should not point to KeyManifest ;
3. OnlyKeyManager andEngineWrapper should have ac-
cess toKeyVault .
All these constraints reﬂect our understanding of the se-
curity requirements of the target architecture, and indeed
 KEYSTORAGE  CONSUMERS
 PROVIDERS  KEYMANAGEMENT
Figure 6: CryptoDB object graph (Level-0).they are all derived from commentary in Kenan’s book [19].
For example, constraint 3 is an adaptation of the following
remark: “Access to the key vault [...] should be granted to
only security oﬃcers and the cryptographic engine”(p. 71).
The key manager is the component through which security
oﬃcers access the system, hence we arrive at constraint 3.
We formalized these constraints using the Acme predicate
language [29]:
1.forall c: Component in KeyManagement.MEMBERS |
!connected(c, EngineWrapper)
2.!pointsTo(KeyVault, KeyManifest)
3.forall c : SyncCompT in self.COMPONENTS |
pointsTo(c, KeyVault)
-> c.label == "KeyManager"
or c.label == "EngineWrapper"
4.3 Evaluation Summary
We successfully related the security architecture and the
implementation.
Renames. Because Scholia uses a structural compari-
son algorithm to compare the built and designed architec-
tures, we were able to analyze conformance despite naming
discrepancies—e.g., KeyManager versusKeyTool.
Conformance Findings. Overall, the top-level com-
ponents in the target architecture and the implementation
were mostly consistent, as indicated by the large number of
convergences (Fig. 5).
One interesting divergence corresponds to communication
in the implementation that is omitted from the target ar-
chitecture, namely the reference from CryptoProvider to
CustomerInfo . This divergence really exists in the imple-
mentation and is not a false positive. We traced the edge to
the code and realized that the provider maintains a list of
all theEncryptionRequest objects it receives.
Looking inside some of the top-level components revealed
more interesting diﬀerences. For example, a Level-2 DFD
(Fig. 2) shows an Encoder component inside the Provider .
However, the Encoder is implemented using a helper class
Utils, which is never instantiated, hence the corresponding
absence in the conformance view. We could resolve this
absence by modifying the code to instantiate a singleton
Utilsobject without aﬀecting the system behavior.
While modeling the target architecture, we confronted
several architecture–implementation discrepancies of th is
nature. We ultimately dealt with them, in most cases, by
modifying the target architecture to match the implemen-
tation. This was necessary because of the departures that
theCryptoDBimplementation madefrom thecryptographic
database architecture. Had we not reconciled the diﬀerence s
at that stage, we would have had much more noise to sort
through in the conformance operation.
For example, we could have added the external interactors
to the target architecture. However, because external inte r-
actors represent components that are outside of the system,
theywill always showupas absences. Inthe end, we decided
to exclude the external interactors.
Naturally, distinguishing between deliberate departures
from the architecture and genuine architecture violations re-
quires careful judgment. However, we view it as a strength
of our approach that architects have the opportunity to ex-
ercise their judgment to exclude uninteresting violations .
In other cases, we reﬁned the annotations. For instance,
we had initially modeled all instances of CryptoReceipt and
9CompoundReceipt in aRECEIPTS domain inside Customer -
Manager. As a result, the analysis ﬂagged the Receipt-
Manager insideCryptoProvider as an absence. Then
we looked more carefully at how the Provider and the
CustomerManager exchanged these objects. This led us to
deﬁne a RCPTMGR domain inside provider forCompound -
Receipts, and left the CryptoReceipt s in theRECEIPTS do-
main inside mgr(Fig. 3).
Constraint Violations. We then added the aforemen-
tioned constraints (Section 4.2.4) to the target architect ure
and used the AcmeStudio tool to verify them. The tool thus
gave us a positive assurance that the implementation had no
architectural violations.
4.4 Defect Prevention
To further validate our approach, we manually injected a
manufacturedarchitectureviolationintotheCryptoDBcod e
to conﬁrm that our constraints would catch it. Speciﬁcally,
we coupled the Provider and theLocalKeyStore . Accord-
ing to constraint 3 above, the Provider is not allowed to
point to the LocalKeyStore in this way. In the architec-
ture, access to the KeyVault is highly restricted due to the
sensitivity of the contents.
When we modiﬁed the code in this way and ran our anal-
ysis, the conformance view showed an additional divergence
betweenprovider andkeyVault , and the predicate raised a
warningaboutthearchitecturalviolationintheconforman ce
view. In this case, the domain link checks alone would not
have caught this violation. Both engineandprovider are
peers in the same PROVIDERS domain (Fig. 3). So, there was
already a domain link from PROVIDERS toKEYSTORAGE for
engineto access keyStore . But we did not want provider
to access keyStore .
Admittedly, the annotations could place provider and
enginein separate domains, and use domain links to enforce
restrictions. However, putting each object in a separate do -
main means losing a key abstraction that domains provide,
namely grouping related objects into tiers. In addition, th is
would require annotations that are more verbose.
5. DISCUSSION
Validity. Internal threats may indicate that factors other
than the technique determined the results. External threats
limit the extent to which the results can be generalized.
Internal Validity. One threat to internal validity is
whether the security runtime architecture Secoria uses
truly serve the purposes of threat modeling. For the target
architecture to be comparable to the one Scholia extracts
from the implementation, it must follow certain convention s.
There could be some DFDs that are not easily expressible
in this manner. For instance, we currently restrict a given
DFDProcessto belong to a single Boundary . In addition,
there could be boundaries that may not be expressible using
domains or tiers, e.g., network boundaries, if they are not
directly visible in the implementation.
TheSecoria security analysis covers only a small sub-
set of architectural defects and design ﬂaws. Only defects
related to local or global, structural connectivity in the r un-
time architecture are in scope. When conducted by humans,
threat analysis incorporates more subtle checks, admitted ly
in a much more informal or ad-hoc way. The goal of any
architecture-level analysis is not to replace a review by se -
curity experts. Threat model analysis can be only partiallyautomated since it still requires human creativity and intu -
ition to uncover subtle security ﬂaws that cannot easily be
generalized. Nevertheless, Secoria can help identify many
of the small issues, provide suggestions on how to ﬁx them in
some cases, and encourage designers to focus on the complex
interactions between subsystems.
External Validity. Can the approach ﬁnd architectural
violations in other systems? The underlying Scholia ap-
proach has beenevaluated on several systems, some of which
are at least an order of magnitude larger than CryptoDB.
So we are conﬁdent that the architectural extraction and
conformance analysis can scale.
In order to evaluate the security analysis, however, the
challenge is to ﬁnd an implementation together with a non-
proprietary security runtime architecture, ideally one th at is
documented by a domain expert. Moreover, the tools that
currently support the approach—while not Java-speciﬁc—
are implemented in the Java Eclipse development environ-
ment. On the other hand, the biggest producer of DFDs,
Microsoft, uses mostly the Visual Studio development envi-
ronment for C++and C/sharpprogramming.
Limitations. Secoria suﬀers from several limitations.
Annotation Overhead. The main eﬀort in Secoria is
in adding the annotations. Inferring the annotations auto-
matically, while still an open research problem, is becomin g
increasingly feasible. Still, even without inference, the cost
of applying Secoria may be justiﬁed for a security archi-
tecture, since security exploits can be quite expensive. Fo r
example, the Microsoft Security Response Center estimates
that a security bug which requires a security bulletin may
cost Microsoft alone hundreds of thousands of dollars [15].
Distributed Systems. A technical limitation of Seco-
riais that the underlying Scholia approach cannot extract
the built architecture of a distributed system. It is precis ely
such systems that exhibit many security vulnerabilities.
Scalability. Admittedly, evaluating Secoria on a 3-
KLOC system does not demonstrate scalability. However,
thescalabilityof Secoria islimited mostlybythatof Scho-
lia’s whole-program static analysis for extracting the as-
built runtime architecture. The static analysis of runtime
architecture is much less mature than that of code architec-
tures. For example, even 3,000 lines of code is considered
out of reach for some heavyweight static analyses.
6. RELATED WORK
Previous Work. In earlier work [2], Abi-Antoun and
Aldrich presented the Scholia approach to extract a hi-
erarchical object graph, abstract it and use it to analyze
conformance. Secoria specializes Scholia to security run-
time architectures and focuses on enforcement at the code
andarchitectural levels, once thearchitectureand theimp le-
mentation have been related. Scholia analyzes communi-
cation integrity. Secoria reasons about security using arch-
itectural types, properties and constraints that the previ ous
architectures did not have. For instance, the CryptoDB sys-
tem was designed and documented by a security expert, un-
like some of the previous systems which were documented
by university professors. This increases the external vali dity
of the result.
Also in earlier work [5], Abi-Antoun, Wang and Torr
deﬁned a model for reasoning about security at the
architectural-level, following the STRIDE methodology
10commonly used in threat modeling. The previous security
model and checker were implemented using custom code.
Secoria formalizes thesame securitymodel using ADLsup-
port for architectural types and properties, and deﬁnes the
checks as predicates. Using an ADL gives the beneﬁt of hav-
ing a declarative model, with less room for error compared
to custom code. Moreover, with a declarative model, power
users can add properties and predicates to extend or cus-
tomize the security analysis, something they cannot do with
a monolithic tool. Finally, this enables Secoria to reap
additional beneﬁts when representing an extracted archite c-
ture in an ADL. By enriching the target architecture with
the security model, Secoria can ﬁndsecurityvulnerabilities
in the implementation.
Architectural Extractors. With the exception of ob-
ject graph analysis, points-to analysis and shape analysis ,
which we discuss below, most static extractors do not track
objects precisely. Instead, they represent structural inf or-
mation with respect to ﬁles, directories, packages or class es,
rather than objects. For example, they express that a class
is part of some package, or a package is nested inside another
package. In Scholia , ownership type annotations provide
containment information at the level of objects, i.e., an ob -
ject is “part of” another object. Scholia can thus distin-
guish between diﬀerent instances of the same class that are
in diﬀerent domains. Many papers often implicitly use the
term “component” to mean a “package,”“module” or a col-
lection of classes [11].
Static Analysis. A number of existing approaches ex-
tract, fully automatically, various non-hierarchical obj ect
graphs [17]. While these approaches can be useful for show-
ing object interactions, they share a fundamental scalabil ity
limitation: for programs of any size, they produce a dia-
gram with so many objects that, in practice, the diagram is
unusable for architectural purposes.
Many of these approaches rely on points-to analysis, a
fundamental static analysis to determine the set of ob-
jects whose addresses may be stored in variables or ﬁelds
of objects. All previous points-to analyses produce non-
hierarchical graphs [37, 27]. Also, most points-to analyse s
achieve a granularity that is no coarser than an object or a
set of objects. Shape analysis is a kind of points-to analy-
sis that summarizes possible relationships among objects a t
run-time in a precise way [33]. A shape graph also does not
collapse some objects underneath other objects.
Security Testing. Analysis oﬀers substantial beneﬁts
beyond those of testing alone. Perhaps most signiﬁcantly,
sinceSecoria is based on static analysis, it can reveal in-
formation about all possible runs of a program, while test-
ing is limited to a small number of runs. This diﬀerence is
particularly important in the security domain. Similar to
testing is dynamic conformance analysis, which instrument s
and monitors a system [35, 34].
Conformance Analysis. There are many approaches
for analyzing architecture conformance to a code architec-
ture (see Knodel and Popescu [21] for a comparative anal-
ysis, as well as the extensive survey by Ducasse and Pol-
let [11]). Indeed, Scholia is modeled after, and comple-
ments, Reﬂexion Models (RM) [31]. RM, however, cannot
handle runtime architectures [2].
Consistency Management. Many approaches analyze
inconsistencies between diﬀerent but related views, that a re
typically at the same level of abstraction, such as a UMLclass diagram and a corresponding UML sequence diagram.
That is a problem in horizontal conformance [11]. Here,
we check conformance between views at diﬀerent levels of
abstraction, namely an implementation and a target archi-
tecture, which is a problem in vertical conformance [11].
Code Generation. SecureUML [24] recommends a
model-driven approach in which security constraints are im -
posed on a model that is later elaborated into code. Like all
model-driven approaches, it is useful only for constructio n
of new systems, not for analysis of existing implementation s.
Our approach is appropriate for use on existing code, requir -
ing only annotations. Another diﬀerence is that SecureUML
is based on a code architecture.
Architectural Analysis. Various architectural-level se-
curity analyses have been proposed [30, 10]. For example,
UMLsec [18] extends UML with secrecy, integrity and au-
thenticity, to allow design-level analysis of security wea k-
nesses. However, conformance between the architecture and
the implementation is achieved using code generation, code
analysis and test sequence generation. Code generation,
while potentially guaranteeing the correct reﬁnement of an
architecture into an implementation, is often too restrict ive
and cannot account for legacy code. Secoria can analyze
an existing system after the fact.
Code-Level Analyses. Architectural analysis matches
the way experts reason about security or privacy better than
a purely code-based strategy. Secoria complements, and
does not supplant, code-level analyses. Moreover, the trac e-
ability between a security architecture and the code that
our approach derives can beneﬁt other static analyses. Un-
til now, due to the lack of traceability, much of the security
design intent generated during threat modeling has not been
easily accessible to other code quality tools. For instance ,
a static analysis checking for buﬀer overruns [13] can use
this traceability to assign to its warnings more appropriat e
priorities based on a more holistic view of the system.
Many code-level analyses use type systems to track infor-
mation ﬂow or check other security properties [32]. Secoria
is a complementary, architecture-centric analysis.
Design Enforcement. Many approaches can enforce lo-
cal, modular, code-level constraints, e.g., [14]. Secoria is
complementaryandcanenforce structuralconstraintsonth e
global architectural structure, which may not correspond t o
any explicitly declared code structure.
Threat Modeling Tools. Microsoft has made pub-
licly available a threat modeling tool [36, 26]. Similarly,
the EU-funded CORAS Project [9] proposed its description
and tool support for threat modeling. While these tools re-
cently added enhanced architectural-level analyses, neit her
tool currentlyrelates a securityarchitecturetoanimplem en-
tation. Moreover, the tools implement their analyses using
custom code, rather than declarative types and predicates.
We believe Secoria signiﬁcantly improves the current state
of the art in threat modeling tools.
Operating Systems. The operating systems research
community has developed information ﬂow control tech-
niques to provide for the security of applications built fro m
potentially untrusted components [39, 23, 7]. This work is
similar to ours in motivation but quite diﬀerent in approach .
These approaches rely on the introduction of new operating
systems designed to enforce security requirements, while w e
approach the problem at the application level by tying ar-
chitecture to implementation.
117. CONCLUSION
We presented the ﬁrst approach, Secoria , to analyze,
entirely statically, a security runtime architecture for s ome
information ﬂow vulnerabilities and for conformance to an
object-oriented implementation.
Our evaluation showed how Secoria can detect code
changes that introduce architectural violations on a real s ys-
tem.Secoria ’sarchitecture-basedanalysismatchestheway
experts reason about security during threat modeling, and
nicely complements other code-oriented strategies.
Acknowledgements. Abi-Antoun was supported by his
faculty startup fund at Wayne State University. Barnes
was supported in part by the Oﬃce of Naval Research,
United States Navy, N000140811223, as part of the HSCB
project under OSD; by the US Army Research Oﬃce under
grant numbers DAAD19-02-1-0389 to Carnegie Mellon Uni-
versity’s CyLab and DAAD19-01-1-0485; by the National
Science Foundation under grant 0615305; and by the Soft-
ware Engineering Institute at CMU.
8. REFERENCES
[1]www.cs.wayne.edu/~mabianto/cryptodb/ , 2010.
[2] M. Abi-Antoun and J. Aldrich. Static extraction and
conformance analysis of hierarchical runtime
architectural structure using annotations. In
OOPSLA , 2009.
[3] M. Abi-Antoun and J. M. Barnes. Enforcing
conformance between security architecture and
implementation. Technical Report CMU-ISR-09-113,
Carnegie Mellon Univ., 2009.
[4] M. Abi-Antoun and J. M. Barnes. STRIDE-based
security model in Acme. Technical Report
CMU-ISR-10-106, Carnegie Mellon Univ., 2010.
[5] M. Abi-Antoun, D. Wang, and P. Torr. Checking
threat modeling data ﬂow diagrams for
implementation conformance and security. In ASE,
pages 393–396, 2007. Short paper/poster.
[6] J. Aldrich and C. Chambers. Ownership domains:
Separating aliasing policy from mechanism. In
ECOOP, 2004.
[7] A. Bittau, P. Marchenko, M. Handley, and B. Karp.
Wedge: Splitting applications into reduced-privilege
compartments. In NSDI, 2008.
[8] P. Clements et al. Documenting software architectures:
views and beyond . Addison-Wesley, 2003.
[9] CORAS. http://coras.sourceforge.net , 2006.
[10] Y. Deng, J. Wang, J. J. P. Tsai, and K. Beznosov. An
approach for modeling and analysis of security system
architectures. Knowledge & Data Eng. , 15(5), 2003.
[11] S. Ducasse and D. Pollet. Software architecture
reconstruction: a process-oriented taxonomy. TSE,
35(4), 2009.
[12] D. Garlan, R. Monroe, and D. Wile. Acme:
architectural description of component-based systems.
InComponent-based systems . Cambridge Univ., 2000.
[13] B. Hackett et al. Modular checking for buﬀer overﬂows
in the large. In ICSE, 2006.
[14] H. J. Hoover and D. Hou. Using SCL to specify and
check design intent in source code. TSE, 32(6), 2006.
[15] M. Howard and D. LeBlanc. Writing secure code .
Microsoft Press, 2nd edition, 2003.[16] M. Howard and S. Lipner. The security development
lifecycle. Microsoft Press, 2006.
[17] D. Jackson and A. Waingold. Lightweight extraction
of object models from bytecode. TSE, 27(2), 2001.
[18] J. J ¨urjens.Secure systems development with UML .
Springer, 2004.
[19] K. Kenan. Cryptography in the database .
Addison-Wesley, 2006. Code at http://kevinkenan.
blogs.com/downloads/cryptodb_code.zip .
[20] D. Kirk, M. Roper, and M. Wood. Identifying and
addressing problems in object-oriented framework
reuse.Empirical Softw. Eng. , 12(3), 2006.
[21] J. Knodel and D. Popescu. A comparison of static
architecture compliance checking approaches. In
WICSA, 2007.
[22] R. Koschke. Architecture reconstruction: Tutorial on
reverse engineering to the architectural level. In Intl.
Summer School on Software Engineering , 2008.
[23] M. Krohn et al. Information ﬂow control for standard
OS abstractions. In SOSP, 2007.
[24] T. Lodderstedt, D. A. Basin, and J. Doser.
SecureUML: A UML-based modeling language for
model-driven security. In UML, 2002.
[25] D. C. Luckham and J. Vera. An event-based
architecture deﬁnition language. TSE, 21(9), 1995.
[26] Microsoft threat modeling tool.
http://msdn.microsoft.com/en-us/security/
sdl-threat-modeling-tool.aspx , 2007.
[27] A. Milanova, A. Rountev, and B. G. Ryder.
Parameterized object sensitivity for points-to analysis
for Java. TOSEM, 14(1), 2005.
[28] N. Mitchell, E. Schonberg, and G. Sevitsky. Making
sense of large heaps. In ECOOP, 2009.
[29] R. Monroe. Capturing software architecture design
expertise with Armani. Technical Report
CMU-CS-98-163R, Carnegie Mellon Univ., 2001.
[30] M. Moriconi, X. Qian, R. A. Riemenschneider, and
L. Gong. Secure software architectures. In IEEE
Security & Privacy , 1997.
[31] G. C. Murphy, D. Notkin, and K. J. Sullivan. Software
reﬂexion models: Bridging the gap between design and
implementation. TSE, 27(4), 2001.
[32] A. C. Myers. JFlow: Practical mostly-static
information ﬂow control. In POPL, 1999.
[33] M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape
analysis via 3-valued logic. In POPL, 1999.
[34] B. Schmerl, J. Aldrich, D. Garlan, R. Kazman, and
H. Yan. Discovering architectures from running
systems. TSE, 32(7), 2006.
[35] M. Seﬁka, A. Sane, and R. H. Campbell. Monitoring
compliance of a software system with its high-level
design models. In ICSE, 1996.
[36] F. Swiderski and W. Snyder. Threat modeling .
Microsoft Press, 2004.
[37] P. Tonella and A. Potrich. Reverse engineering of
object-oriented code . Springer, 2004.
[38] P. Torr. Demystifying the threat-modeling process.
IEEE Security & Privacy , 3(5), 2005.
[39] N. Zeldovich, S. Boyd-Wickizer, and D. Mazi` eres.
Securing distributed systems with information ﬂow
control. In NSDI, 2008.
12