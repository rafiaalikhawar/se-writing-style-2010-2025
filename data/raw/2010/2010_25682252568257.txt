Vejovis: Suggesting Fixes for JavaScript Faults
Frolin S. Ocariza, Jr. Karthik Pattabiraman Ali Mesbah
Electrical and Computer Engineering
University of British Columbia
Vancouver, BC, Canada
{frolino, karthikp, amesbah}@ece.ubc.ca
ABSTRACT
JavaScript is used in web applications for achieving rich user in-
terfaces and implementing core functionality. Unfortunately, Java-
Script code is known to be prone to faults. In an earlier study, we
found that over 65% of such faults are caused by the interaction of
JavaScript code with the DOM at runtime (DOM-related faults). In
this paper, we Ô¨Årst perform an analysis of 190 bug reports to un-
derstand Ô¨Åxes commonly applied by programmers to these DOM-
related faults; we observe that parameter replacements and DOM
element validations are common Ô¨Åx categories. Based on these
Ô¨Åndings, we propose an automated technique and tool, called V E-
JOVIS , for suggesting repairs for DOM-based JavaScript faults. To
evaluate V EJOVIS , we conduct a case study in which we subject
VEJOVIS to 22 real-world bugs across 11 applications. We Ô¨Ånd
that V EJOVIS accurately suggests repairs for 20 out of the 22 bugs,
and in 13 of the 20 cases, the correct Ô¨Åx was the top ranked one.
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging ‚Äì Testing
Tools
General Terms
Design, Algorithms, Experimentation
Keywords
JavaScript, fault repair, Document Object Model (DOM)
1. INTRODUCTION
JavaScript is used extensively in modern web applications to ma-
nipulate the contents of the webpage displayed on the browser and
to retrieve information from the server by using HTTP requests. To
alter the contents of the webpage, JavaScript code manipulates a
data structure known as the Document Object Model (DOM) . The
DOM contains all the webpage elements (e.g., div,table , etc.)
hierarchically ordered as a tree, where each element contains spe-
ciÔ¨Åc properties, such as styling information. Through the use of
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ICSE ‚Äô14, May 31 ‚Äì June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05 ...$15.00.DOM API methods, the JavaScript code is capable of retrieving el-
ements from the DOM, as well as changing the DOM by modifying
element properties, adding elements, and deleting elements.
Due to the dynamic nature of the JavaScript language and the
interaction with the DOM, JavaScript-based web applications are
prone to errors. In a recent empirical study we conducted on Java-
Script bug reports [13], we found that around 65% of JavaScript
faults are DOM-related , meaning the error leading to the fault even-
tually propagates into a parameter value of a DOM API method
call (or to the assignment value of a DOM element property assign-
ment) before causing the failure. In addition, we found that 80%
of the highest impact JavaScript faults i.e., those that cause data
loss, hangs, and/or security vulnerabilities, are DOM-related. Fi-
nally, we found that DOM-related faults require more time to Ô¨Åx
than other JavaScript faults. These results point to the prevalence,
impact, and complexity of DOM-related JavaScript faults in web
applications.
In this paper, our goal is to facilitate the process of Ô¨Åxing DOM-
related JavaScript faults , by providing suggestions to the program-
mer during web application testing and debugging tasks. To this
end, we Ô¨Årst perform a study of real-world JavaScript faults to un-
derstand the common patterns in how programmers Ô¨Åx such faults.
Then, based on these common Ô¨Åx patterns, we propose an auto-
matic approach for suggesting repairs. In this paper, we use the
term repair to encompass both Ô¨Åxes and workarounds for the fault,
similar to other related work [12, 16].
Our approach starts from the wrong DOM API method/property,
and uses a combination of static and dynamic analysis to identify
the lines of code in the backward slice of the parameters or assign-
ment values of DOM methods/properties. Once these lines are lo-
calized, it uses a string solver to Ô¨Ånd candidate replacement DOM
elements, and propagates the candidate values along the backward
slice to Ô¨Ånd the Ô¨Åx.
We implement our approach in an open-source tool called V E-
JOVIS .1VEJOVIS is deployed on a web application after the occur-
rence and subsequent localization of a JavaScript fault [14]. It re-
quires neither speciÔ¨Åcations/annotations from the programmer nor
any changes to the JavaScript/DOM interaction model, and can
hence be deployed on unmodiÔ¨Åed web applications.
Prior work on suggesting repairs for web application faults has
focused on server-side code (e.g., PHP) [12, 16], including workaro-
unds for web API calls [5]. Other work [8] automatically trans-
forms unsafe eval calls in JavaScript code to safe alternatives.
None of these techniques, however, deal with DOM-related Java-
Script faults. To the best of our knowledge, VEJOVIS is the Ô¨Årst
technique to automatically suggest repairs for DOM-related Java-
Script faults in web applications .
1VEJOVIS is the Roman god of healing.Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ICSE‚Äô14 , May 31 ‚Äì June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05...$15.00
http://dx.doi.org/10.1145/2568225.2568257
837
We make the following contributions in this paper:
We categorize common Ô¨Åxes applied by web developers to
DOM-related JavaScript faults, based on an analysis of 190
online bug reports. We Ô¨Ånd that Ô¨Åxes involving modiÔ¨Åcations
of DOM method/property parameters or assignment values
into valid replacement values (i.e., values consistent with the
DOM) are the most common, followed by those involving
validation of DOM elements before their use;
Based on the above study, we present an algorithm for Ô¨Ånd-
ingvalid replacement parameters passed to DOM API meth-
ods, which can potentially be used to replace the original
(and possibly erroneous) parameter used to retrieve elements
from the DOM. The replacements are found based on the
CSS selector grammar, and using information on the DOM
state at the time the JavaScript code executed. The aim is to
suggest replacements that are valid in the current DOM, and
to suggest as few replacements as possible;
We present an algorithm for suggesting repairs in the form
ofactionable messages to the programmer based on code-
context. The actionable messages contain detailed directions
prompting the programmer to make modiÔ¨Åcations to the code
so as to eliminate the ‚Äúsymptoms‚Äù observed during the pro-
gram‚Äôs failure run;
We describe the implementation, called V EJOVIS , which in-
tegrates the previous two contributions. We evaluate our
technique on 22 real-world JavaScript bugs from 11 web ap-
plications. In our case study, V EJOVIS was able to provide
correct repair suggestions for 20 of the 22 bugs. Further, the
correct Ô¨Åx was ranked Ô¨Årst in the list of repairs for 13 of the
20 bugs. We also found that limiting the suggestions to those
that are within an edit distance of 5 relative to the original
selector can decrease the number of suggestions in the other
7 bugs to 3 per bug, while reducing the number of correct
Ô¨Åxes to 16 (from 20).
2. BACKGROUND AND CHALLENGES
The DOM is a standard object model, used internally by web
browsers to represent the HTML state of a webpage at runtime.
Changes made to the structure, contents or styles of the DOM ele-
ments are directly manifested in the browser‚Äôs display. Client-side
JavaScript2is used primarily to interact with i.e., to access, tra-
verse, or manipulate the DOM. In most modern web applications,
these interactions are used to incrementally update the browser dis-
play with client-side state changes without initiating a page load.
Note that this is different from what happens during URL-based
page transitions where the entire DOM is repopulated with a new
HTML page from the server.
JavaScript provides DOM API methods and properties that allow
direct and easy retrieval of DOM elements. For instance, elements
can be accessed based on their tag name, ID, and class names, and
the DOM can be traversed using the parentNode andchildNodes
properties. In addition, modern browsers provide APIs such as
querySelector for retrieving DOM elements using patterns called
CSS selectors . CSS selectors follow a well-deÔ¨Åned grammar [17],
and serve as a uniÔ¨Åed way of retrieving DOM elements; for exam-
ple, retrieving a DIV DOM element with ID "news" translates to
"DIV#news" in CSS selector syntax. Table 1 shows some of the
commonly used components that make up a CSS selector.
Once an element is retrieved using the CSS selector, JavaScript
code can use the reference to that element to access its properties,
2For simplicity, we refer to client-side JavaScript as JavaScript.Table 1: List of commonly used CSS selector components.
Component Description
Tag Name The name of the tag associated with an element. Examples :div,
span ,table , etc.
ID The id associated with an element. This is preÔ¨Åxed with the #
symbol. Example : If a divelement has an id of ‚ÄúmyID‚Äù, a CSS
selector that can retrieve this element is div#myID .
Class Name The name of a class to which an element belongs. This is pre-
Ô¨Åxed with a period. Example : If a span element belongs to the
‚ÄúmyClass‚Äù class, a CSS selector that can retrieve this element is
span.myClass .
Is Descendant A space character indicating that the element described by the
right selector is a descendant of the element described by the
left selector. Example : To Ô¨Ånd all table elements belonging to
class ‚ÄúmyClass‚Äù that are descendants of a divelement, we use
the selector div table.myClass .
Is Child The ‚Äú>‚Äù character, which indicates that the element described by
the right selector is a child of the element described by the left
selector. Example : To Ô¨Ånd all trelements that are children of the
table element with id ‚ÄúmyID‚Äù, we use the selector table#myID
> tr .
Is Next Sibling The ‚Äú+‚Äù character, which indicates that the element described by
the right selector is the next sibling of the element described by
the left selector. Example : To Ô¨Ånd all trelements that follow
another trelement, we use the selector tr + tr .
1function pagerSetup () {
2var display = " catalog_view ";
3var content = "p.pages span";
4 appendTo(display , content);
5}
6
7function appendTo(display , content) {
8var view_selector = "div#view -display -id -" +  -
display;
9var content_selector = view_selector + " > " +  -
content;
10 var pageToAdd = "<div >New Content </div >";
11 var pages = $( content_selector );
12 var oldContent = pages [0]. innerHTML;
13 pages [0]. innerHTML = oldContent + pageToAdd;
14}
Figure 1: JavaScript code of the running example.
add new or remove/modify existing properties, or add/remove ele-
ments to/from the DOM tree.
Running Example. Here, we describe the running example that
we will be using throughout this paper to simplify the description
of our design. The running example is based on a bug in Drupal in-
volving jQuery‚Äôs Autopager [1] extension, which automatically ap-
pends new page content to a programmer-speciÔ¨Åed DOM-element
A snippet of the simpliÔ¨Åed JavaScript code is shown in Figure 1. In
thepagerSetup() function, the programmer has set the display ID
sufÔ¨Åx to ‚Äúcatalog_view‚Äù (line 2), and the DOM element where the
page is added as ‚Äúp.pages span‚Äù (line 3). These inputs are passed
to the appendTo() function, which sets up the full CSS selector
describing where to add the new page through a series of string
concatenations (lines 8-9). In this case, the full CSS selector ends
up being ‚Äúdiv#view-display-id-catalog_view > p.pages span‚Äù.
The above JavaScript code runs when the DOM state is as shown
in Figure 2. Note that in this case, the CSS selector will notmatch
any element in the DOM state. As a result, $()returns an empty
set in line 11; hence, when retrieving the old content of the Ô¨Årst
matching element via innerHTML (line 12), an ‚ÄúundeÔ¨Åned‚Äù excep-
tion is thrown. The undeÔ¨Åned exception prevents the Autopager to
successfully append the contents of the new page (line 10) to the
speciÔ¨Åed element in line 13.
For this particular bug, the Ô¨Åx applied by the programmer was to
change the string literal ‚Äúdiv#view-display-id-‚Äù to ‚Äúdiv#view-id-‚Äù
in line 8. This, in turn, changes the full CSS selector to ‚Äúdiv#view-838bodydivID = "view-id-catalog_view"pclass="pages"h1divID = "view-display-id-catalog_page"pclass = "pages"divclass="container"spanh1divclass="container"spanFigure 2: The DOM state during execution of the JavaScript
code in the running example. For simplicity, only the elements
under body are shown.
id-catalog_view > p.pages span‚Äù, which is valid in the DOM in
Figure 2.
Challenges. The interaction between two separate languages (i.e.,
the DOM and the JavaScript code) makes web applications highly
error-prone. JavaScript errors are prominent and can lead to the
impairment of major functionalities of a webpage, even in the case
of popular and well-engineered production web applications [15].
In a recent empirical study of over 300 JavaScript bug reports [13],
we found that approximately 65% of JavaScript faults are DOM-
related . This means that the majority of JavaScript faults originate
from errors that eventually propagate into the parameter or assign-
ment value of a DOM method/property. The running example pro-
vides an example of a DOM-related fault, as the error present in the
example eventually propagates into the DOM method $(), which
retrieves DOM elements through CSS selectors.
DOM-related faults, by deÔ¨Ånition, involve the propagation of the
error to a DOM method/property‚Äôs parameter or assignment value.
Therefore, the Ô¨Åx likely involves altering the code responsible for
setting up this parameter or assignment value. The challenge, of
course, is in answering the following question: how should the code
be modiÔ¨Åed to repair the fault? Answering this question requires
knowledge of (1) the location in the code that needs to be altered;
and (2) the speciÔ¨Åc modiÔ¨Åcation that needs to be applied to that
location. For the Ô¨Årst task, the origins (i.e., the backward slice)
of the parameter or assignment value must be traced. For the sec-
ond task, the speciÔ¨Åc replacement parameter or replacement assign-
ment value must be inferred, and the way in which this replacement
should be incorporated into the code must be determined.
While these challenges are difÔ¨Åcult and sometimes impossible to
tackle with arbitrary method parameters or assignment values (be-
cause they require programmer intent to be inferred), parameters
and assignment values to DOM methods/properties ‚Äì as well as the
DOM itself ‚Äì are more structured. Hence, for these kinds of pa-
rameters or assignment values, the problem of inferring program-
mer intent reduces to Ô¨Ånding replacements that satisfy this struc-
ture. Therefore, we study common patterns in how programmers
Ô¨Åx DOM-related faults, to prioritize the Ô¨Åx suggestions we infer.
This study is presented in the next section.
3. COMMON DEVELOPER FIXES
To better understand how programmers implement Ô¨Åxes to DOM-
related JavaScript faults, we analyze 190 Ô¨Åxed bug reports repre-Table 2: List of applications used in our study of common Ô¨Åxes.
Application Description
Moodle Learning Management System
Joomla Content Management System
WordPress Blogging
Drupal Content Management System
Roundcube Webmail
WikiMedia Wiki Software
TYPO3 Content Management System
TaskFreak Task Organizer
jQuery JavaScript Library
Prototype.js JavaScript Library
MooTools JavaScript Library
Ember.js JavaScript Library
senting DOM-related faults and analyze the developer Ô¨Åxes applied
to them. Our goal is to answer the following research questions:
RQ1 (Fix Categories): What are the common Ô¨Åx types applied by
programmers to Ô¨Åx DOM-related JavaScript faults?
RQ2 (Application of Fixes): What modiÔ¨Åcations do programmers
make to JavaScript code to implement a Ô¨Åx and eliminate
DOM-related faults?
The above questions will help us determine how programmers
typically deal with DOM-related faults. This understanding will
guide us to design our automated repair algorithm.
3.1 Methodology
We perform our analysis on 190 Ô¨Åxed JavaScript bug reports
from eight web applications and four JavaScript libraries (see Ta-
ble 2). Note that these bug reports are a subset of the bug reports
we explored in a recent empirical study [13]. However, the analysis
conducted here is new and is not part of our previous study.
In our earlier study, we analyzed a total of 317 Ô¨Åxed JavaScript
bug reports. Of these, about 65%, or 206 of the bugs were DOM-
related JavaScript faults. Further, we found that in 92% of these
DOM-related JavaScript faults (or 190 bugs), the Ô¨Åx involved a
modiÔ¨Åcation of the client-side JavaScript code. We consider only
these 190 bugs in this study, as our goal is to Ô¨Ånd repairs for DOM-
related JavaScript faults that involve the JavaScript code.
To answer the research questions, we perform a qualitative anal-
ysis of the Ô¨Åxes applied by the programmers to each bug report.
To do so, we manually read the portions of each bug report doc-
umenting the Ô¨Åx applied (e.g., developer comments, discussions,
initial report descriptions, Ô¨Åx descriptions, patches, etc.). Based on
this analysis, we devise a classiÔ¨Åcation scheme for the bug report
Ô¨Åxes so that we can group the Ô¨Åxes into different, well-deÔ¨Åned cat-
egories, to answer RQ1. Our analysis of the code patches and/or
Ô¨Åx descriptions helps us answer RQ2.
3.2 Results
Fix Categories. We found that the Ô¨Åxes that programmers apply to
DOM-related JavaScript faults fall into the following categories.
Parameter ModiÔ¨Åcation, where a value that is eventually used
in the concatenation of a DOM method/property parameter
or assignment value is modiÔ¨Åed. This is done either by di-
rectly modifying the value in the code, or by adding calls to
modiÔ¨Åer methods (e.g., adding a call to replace() so that
the string value of a variable gets modiÔ¨Åed). This category
makes up 27.2% of the Ô¨Åxes.
DOM Element Validation, where a check is added so that the val-
ue of a DOM element or its property is compared with an
expected value before being used. This category makes up
25.7% of the Ô¨Åxes.839Method/Property ModiÔ¨Åcation, where a call to a DOM API meth-
od (or property) is either added, removed, or modiÔ¨Åed in
the JavaScript code. Here, modiÔ¨Åcation refers to changing
themethod (or property) originally called, not the param-
eter (e.g., instead of calling getElementsByClassName , the
method getElementsByTagName is called instead). This cat-
egory makes up 24.6% of the Ô¨Åxes.
Major Refactoring, where signiÔ¨Åcantly large portions of the Java-
Script code are modiÔ¨Åed and restructured to implement the
Ô¨Åx. This category makes up 10.5% of the Ô¨Åxes.
Other/Uncategorized, which make up 12% of the Ô¨Åxes.
As seen in the above Ô¨Åx categories, the most prominent cate-
gories are Parameter ModiÔ¨Åcation and DOM Element Validation,
which make up over half (52.9%) of the Ô¨Åxes. Therefore, we fo-
cus on these categories in our work. Although we do not consider
Method/Property ModiÔ¨Åcations in our repair approach, our algo-
rithm can be adapted to include this class of errors, at the cost of
increasing its complexity (see Section 7).
Application of Fixes. We next describe how programmers modify
the JavaScript code to apply the Ô¨Åxes. We discuss our Ô¨Åndings for
the three most prominent Ô¨Åx categories ‚Äì Parameter ModiÔ¨Åcation,
DOM Element Validation, and Method/Property ModiÔ¨Åcation.
Parameter ModiÔ¨Åcation : We found that 67.3% of Ô¨Åxes belong-
ing to the Parameter ModiÔ¨Åcation Ô¨Åx category involve the modiÔ¨Å-
cation of string values. The vast majority (around 70%) of these
string value modiÔ¨Åcations were direct modiÔ¨Åcations of string liter-
als in the JavaScript code. However, we also found cases where
the string value modiÔ¨Åcation was applied by adding a call to string
modiÔ¨Åcation methods such as replace() .
We also analyzed the DOM methods/properties whose parame-
ters are affected by the modiÔ¨Åed values. For string value modiÔ¨Åca-
tions, the methods/properties involved in multiple bug report Ô¨Åxes
aregetElementById() ,$()andjQuery() ; together, Ô¨Åxes involv-
ing these methods comprise 51.4% of all string value modiÔ¨Åcations.
For non-string value modiÔ¨Åcations, Ô¨Åxes involved modiÔ¨Åcation of
the numerical values assigned to elements‚Äô style properties, partic-
ularly their alignment and scroll position.
DOM Element Validation : 75.5% of Ô¨Åxes belonging to this cat-
egory are applied by simply wrapping the code using the pertinent
DOM element within an ifstatement that performs the necessary
validation (so that the code only executes if the check passes).
Other modiÔ¨Åcations include (1) adding a check before the DOM
element is used so that the method returns if the check fails; (2)
adding a check before the DOM element is used such that the value
of the DOM element or its property is updated if the check fails;
(3) encapsulating the code using the DOM element in an if-else
statement so that a backup value can be used in case the check
fails; and Ô¨Ånally (4) encapsulating the code in a try-catch state-
ment. The most prevalent checks are null /undefined checks, i.e.,
the code has been modiÔ¨Åed to check if the DOM element is null or
undefined before it is used, which constitutes 38.8% of the Ô¨Åxes
in the DOM Element Validation category.
Method/Property ModiÔ¨Åcation : 53.2% of these Ô¨Åxes involve
changing the DOM method or property being called/assigned; the
rest involve either the removal of the method call or the property
assignment (e.g., remove a setAttribute call that changes the
class to which an element belongs), or the inclusion of such a call
or assignment (e.g., add a call to blur() to unfocus a particular
DOM element). Of the Ô¨Åxes where the DOM method/property was
changed, around 44% involve changing the event handler to which
a function is being assigned (e.g., instead of assigning a particular
method to onsubmit , it is assigned to onclick instead).
Data Collector(box a)Direct DOM AccessWeb Application URLSymptom Analyzer(box b)TreatmentSuggester(box c)SupplementaryInformationSymptomsDataPossible Sicknesses
List of WorkaroundSuggestionsFigure 3: High-level block diagram of our design.
Summary of Findings. Our study shows that the most prominent
Ô¨Åx categories are Parameter ModiÔ¨Åcation and DOM Element Vali-
dation. Our analysis also shows the prevalence of string value mod-
iÔ¨Åcations and null /undefined checks when applying Ô¨Åxes. In ad-
dition, most parameter modiÔ¨Åcations are for values eventually used
in DOM methods that retrieve elements from the DOM, particu-
larly the $(),jQuery() andgetElementById() methods. These
results motivate our fault model choice in Section 4 as well as our
choice of possible sickness classes in Section 5.2.
4. FAULT MODEL
In this work, we focus on DOM API methods that retrieve an el-
ement from the DOM using CSS selectors, IDs, tag names, or class
names, as we found that these were the common sources of mis-
takes made by programmers (Section 3). These DOM API methods
include getElementById() ,getElementsByTagName() ,getEl-
ementsByClassName() ,querySelector() , and querySelect-
orAll() . We also support DOM API wrapper methods made avail-
able by commonly used JavaScript libraries including those in jQuery
(e.g., $() andjQuery() ); Prototype (e.g., $$() and$()); and
tinyMCE (e.g., get() ), among others. For simplicity, we will refer
to all these DOM API methods as the direct DOM access .
We further focus on code-terminating DOM-related faults, which
means the DOM API method returns null ,undefined , or an empty
set of elements, eventually leading to a null or an undeÔ¨Åned excep-
tion (thereby terminating JavaScript execution). However, our de-
sign can also be extended to apply to output-related DOM-related
faults, i.e., those that lead to incorrect output manifested on the
DOM. Such faults would require the programmer to manually spec-
ify the direct DOM access. In contrast, with code-terminating DOM-
related faults, the direct DOM access can be determined automat-
ically using the A UTOFLOXtool proposed in our prior work [14].
Thus we focus on this category of faults in this work.
The running example introduced in Section 2 is an example of
a fault that is encompassed by the fault model described above.
Here, the direct DOM access is the call to the $()method in line
11, which returns an empty set of elements. It is code-terminating
because the fault leads to an undeÔ¨Åned exception in line 12.
5. APPROACH
In this section, we describe our approach for assisting web de-
velopers in repairing DOM-related faults satisfying the fault model
described in the previous section. Figure 3 shows a block diagram840of our design, which consists of three main components: (1) the
data collector ; (2) the symptom analyzer ; and (3) the treatment
suggester . These components are described in Sections 5.1‚Äì5.3.
Our approach assumes the parameter (or the array index) of the
direct DOM access is incorrect. This is inspired by the results pre-
sented in Section 3, which demonstrated the prevalence of Param-
eter ModiÔ¨Åcation Ô¨Åxes. As such, our approach attempts to Ô¨Ånd
valid replacements for the original parameter or array index, where
a valid replacement is a parameter that matches at least one element
in the DOM. Once the valid replacements are found, our approach
analyzes the code context to determine what actionable message to
suggest as a potential repair to the programmer.
5.1 Data Collector
The main purpose of the data collector module is to gather dy-
namic data that may reveal the symptoms present in the web ap-
plication. In general, symptoms are deÔ¨Åned as any indications of
abnormalities in the intended behaviour of the program with regard
to DOM accesses. We consider the following as symptoms in our
design based on our fault model:
Symptom 1 : The direct DOM access is returning null ,und-
efined , or an empty set of elements. This leads to a ‚Äúnull‚Äù
or ‚ÄúundeÔ¨Åned‚Äù exception eventually.
Symptom 2 : The index used to access an element in the
list of elements returned by the direct DOM access is out
of bounds. This is only applicable to DOM methods that
retrieve a list of elements (e.g., getElementsByTagName() ,
$(), etc.). This eventually leads to an ‚ÄúundeÔ¨Åned‚Äù exception.
The data collector collects the direct DOM access‚Äô line number,
and the name of the function containing it. This data is provided by
the user (manually) or gathered automatically using a tool such as
AUTOFLOX[14]. The data collector module also collects the fol-
lowing supplementary information , which can help infer the con-
text under which a particular symptom is appearing:
The dynamic execution trace of the JavaScript program, with
each trace item containing the line number of the executed
line, the name of the function containing the line, and the
names and values of all in-scope variables at that line. It also
includes the lines in the body of a loop, and a list of forloop
iterator variables (if any). The data describing which lines
are part of a loop are used by the treatment suggester to infer
code context, to determine what actionable repair message to
provide to the programmer; more details are in Section 5.3.
The state of the DOM when the direct DOM access line is
executed. For instance, in the running example, the DOM
state in Figure 2 is retrieved; The DOM state will be used
by the symptom analyzer to determine possible replacements
for the direct DOM access parameter (if any); in particular,
if the direct DOM access is returning null orundefined
(i.e., Symptom 1), this means that the parameter to the di-
rect DOM access does not correspond to any element in the
current DOM state, so our technique can look at the current
DOM state to see if there are any reasonable replacements
thatdomatch an element (or a set of elements) in the DOM.
5.2 Analyzing Symptoms
Thesymptom analyzer (Figure 3, box b) uses the data gathered
by the data collector to come up with a list of possible sicknesses
that the web application may have. Each possible sickness belongs
to one of the following classes:String : A [variable |expression |string literal] has a string
value of X, but it should probably have string value Y. This
sickness triggers Symptom 1.
Index : An array index has a numerical value of X, but it
should fall within the allowed range [Y-Z] . This sickness
triggers Symptom 2.
Null/UndeÔ¨Åned : A line of code Xaccessing a property/method
of the DOM element returned by the direct DOM access
should not execute if the DOM element is [ null | undefined ].
This sickness can trigger both Symptoms 1 and 2.
These classes are based on the results of our study of common
bug report Ô¨Åxes. In particular, the ‚ÄúString‚Äù and ‚ÄúNull/UndeÔ¨Åned‚Äù
classes account for Parameter ModiÔ¨Åcation and DOM Element Val-
idation Ô¨Åxes, respectively. The ‚ÄúIndex‚Äù class is included because in
some cases, an undeÔ¨Åned exception occurs not because of retriev-
ing the incorrect element, but because of using an out-of-bounds
index on the returned array of DOM elements.
The symptom analyzer takes different actions depending on the
symptom in Section 5.1 as follows:
1.String Replacement : Assume that the program suffers from
Symptom 1. This implies that the string parameter being
passed to the direct DOM access does notmatch any element
in the DOM ‚Äì i.e., the program may be suffering from the
‚ÄúString‚Äù sickness class, as described above. Our design will
look for potential replacements for these parameters, where
the replacements are determined based on the current DOM
state. Each potential replacement represents a possible sick-
ness belonging to the ‚ÄúString‚Äù class.
2.Index Replacement : Assume that the program suffers from
Symptom 2. This implies that the program may be suffering
from the ‚ÄúIndex‚Äù sickness class, as described above. This
step is only taken if the direct DOM access corresponds to a
method that returns a setof DOM elements. Our approach
will determine the allowed range of indices, representing a
possible sickness belonging to the ‚ÄúIndex‚Äù class.
3.Null/UndeÔ¨Åned Checks : By default, our design addition-
ally assumes a possible sickness belonging to the ‚ÄúNull/Un-
deÔ¨Åned‚Äù class.
Each of the above cases will be described in detail. Because
CSS selectors provide a uniÔ¨Åed way of retrieving elements from
the DOM, we will only describe how the possible sicknesses are
determined for the case where the parameter to the direct DOM
access is a CSS selector (as in the case of the running example).
Case 1: String Replacement. The main assumption here is that
the string parameter passed to the direct DOM access is incorrect;
we call this parameter the erroneous selector . Hence, the goal is
to (1) look for potential replacement parameters that match an ele-
ment (or a set of elements) in the current DOM state (i.e., are valid
replacements ), and (2) suggest only the most viable replacements
so as to not overwhelm the programmer; therefore our approach as-
sumes that the replacement will be relatively close to the original,
erroneous selector (i.e., only one component of the original selec-
tor is assumed incorrect by any given replacement). Algorithm 1
shows the pseudocode for this step. The sub-steps are described
below in more detail.
Dividing Components : The Ô¨Årst step is to divide the erroneous
selector into its constituent components, represented by C(line 1).
In essence, Cis an ordered set, where each element cicorresponds
to a selector component ( ci:comp ); its matching component type
(ci:type; see Table 1); and its level in the selector, where each
level is separated by a white space or a >character ( ci:level ). The841Algorithm 1: Parameter Replacement
Input :trace : The dynamic execution trace
Input :dda: The direct DOM access
Input :dom: The current DOM state
Output :listOfpossibleSicknesses : A list of possible sicknesses
1C {c1,c2, ...,cN};
2GSS {(s1,l1), (s2,l2), ..., ( sK,lK)};
3foreach ci2Cdo
4 LSS i match( ci,GSS);
5end
6VS /0;
7foreach ci2Cdo
8 PVE {dom.root};
9 forj 0 to c i:level do
10 nextElems /0;
11 foreach e2PVE do
12 all e.getElementsByTagName(‚Äú*‚Äù);
13 foreach f2alldo
14 iffmatches level jof erroneous selector then
15 nextElems .add( f);
16 end
17 end
18 end
19 PVE nextElems ;
20 end
21 foreach e2PVE do
22 newElems /0;
23 iflevel after c i:level is the ‚Äúdescendant‚Äù then
24 newElems getAllDescendants( e);
25 end
26 else if level after c i:level is the ‚Äúchild‚Äù then
27 newElems getAllChildren( e);
28 end
29 else if level after c i:level is the ‚Äúnext sibling‚Äù then
30 newElems getNextSibling( e);
31 end
32 foreach f2newElems do
33 iffhas c i:type then
34 newSelector dda.erroneousSelector .replace( ci:comp ,
ci:type off);
35 VS.add( newSelector );
36 end
37 end
38 end
39 foreach selector2VSdo
40 ife selector(dom) =2dom then
41 VS.remove( selector );
42 end
43 end
44end
45PR replacementsFinder( VS,LSS 1,LSS 2, ...,LSS N);
46foreach rep2PRdo
47 possibleSickness craftPossibleSickness( rep);
48 listOfPossibleSicknesses .add( possibleSickness );
49end
erroneous selector itself is retrieved from the direct DOM access
(dda) which is input to the algorithm. For example, consider the
erroneous selector in the running example: ‚Äúdiv#view-display-id-
catalog_view > p.pages span‚Äù. This selector contains the following
components: (1) the tag name ‚Äú div‚Äù; (2) the ‚Äúhas ID‚Äù identiÔ¨Åer
‚Äú#‚Äù; (3) the ID name ‚Äú view-display-id-catalog_view ‚Äù; (4) a
‚Äú>‚Äù character indicating that the next component is a child of the
previous; (5) the tag name ‚Äú p‚Äù; (6) the ‚Äúhas class‚Äù identiÔ¨Åer ‚Äú .‚Äù
(i.e., a dot character); (7) the class name ‚Äú pages ‚Äù; (8) whitespace
indicating that the next component is a descendant of the previous
one; and (9) the tag name ‚Äú span ‚Äù.
Finding the Global String Set : The next step is to determine
thestring set corresponding to each component (lines 2-5). The
string set refers to the list of locations, in the JavaScript code, of
the origins of all the parts that make up a particular string value.
For instance, consider the erroneous selector in the running exam-
ple, whose Ô¨Ånal string value is ‚Äúdiv#view-display-id-catalog_view> p.pages span‚Äù. This entire string is made up of a concatenation of
the following strings: (1) ‚Äú div#view-display-id- ‚Äù in Figure 1,
line 8; (2) ‚Äú catalog_view ‚Äù in line 2; (3) ‚Äú >‚Äù in line 9; and (4)
‚Äúp.pages span ‚Äù in line 3.
The algorithm Ô¨Årst determines the global string set , which refers
to the string set of the entire erroneous selector; in Algorithm 1,
this is represented by GSS (line 2). The global string set is found
by recursively extracting the dynamic backward slice of each con-
catenated string value that makes up the erroneous selector (using
the dynamic execution trace) until all the string literals that make
up the erroneous selector have been included in the string set. Note
that the slice extraction process is a dynamic one, and is hence
precise. However, it may be unable to resolve the origin of every
variable in the code e.g., because a variable gets its value from an
external XML Ô¨Åle. Unresolved portions of the erroneous selector
are left as ‚Äúgaps‚Äù in the string set.
TheGSS consists of an ordered set of tuples of the form ( si,li),
where siis a string value and liis the location in the JavaScript
code where that value originated (i.e., line number and enclosing
function). Each tuple represents an element in the string set. In
the running example, given the string set of the erroneous selector
just described above, the ordered set of tuples will be as follows:
{(‚Äúdiv#view-display-id- ‚Äù, 8), (‚Äú catalog_view ‚Äù, 2), (‚Äú >‚Äù, 9),
(‚Äúp.pages span ‚Äù, 3)}.3Note that a gap in the string set is likewise
represented as a tuple; the string value siis retained, but the location
liis left undeÔ¨Åned, and a special variable is used to store the earliest
expression from which the unresolved string value originated.
Finding the Local String Sets : Once the global string set is
found, the local string set of each component ‚Äì represented by
LSS i‚Äì is inferred (lines 3-5). In essence, this procedure matches
each erroneous selector component ciwith the corresponding ele-
ments in the global string set (line 4). For example, consider the
id name component ‚Äú view-display-id-catalog_view ‚Äù in the
running example. If startIndex andendIndex refer to the index
range of the characters from the global string set element that be-
long to the local string set, then the string set of this component
is {((‚Äú div#view-display-id- ‚Äù, 8), startIndex : 4,endIndex : 19),
((‚Äúcatalog_view ‚Äù, 2), startIndex : 0,endIndex : 11)}.
Finding Valid Selectors : Lines 6-44 of Algorithm 1 looks for
valid selectors (VS) in the current DOM state. This portion of the
algorithm iterates through each component ciof the erroneous se-
lector and assumes that ciis incorrect; it then traverses the current
DOM state‚Äôs tree to see if it can Ô¨Ånd new CSS selectors (i.e., those
in which the component assumed to be erroneous is replaced by a
different value) that match an element in the current DOM state.
This procedure is carried out for each component of the erroneous
selector; hence, by the end of this procedure, each component will
have a corresponding set of CSS selectors (may be empty).
Precisely, to Ô¨Ånd the valid selectors, the algorithm Ô¨Årst looks for
possibly valid elements, represented by PVE (lines 8-20). These
are the elements that match the original selector up to and includ-
ingthe the selector level ci:level , neglecting the component being
assumed erroneous. For instance, suppose in the running example,
the tag component ‚Äú p‚Äù of the erroneous selector is assumed as in-
correct by our design. This component is found in level 2 of the
erroneous selector. Hence, our design traverses the DOM to look
for elements that match the selector up to level 2 neglecting ‚Äúp‚Äù ‚Äì
i.e., elements that match ‚Äú div#view-display-id-catalog_view
> .pages ‚Äù.
Once PVE is found, the algorithm (lines 21-38) checks if the
element does indeed contain a corresponding replacement for the
3Due to space constraints, we omit the enclosing functions.842component that was assumed to be incorrect (e.g., if an ID is be-
ing replaced, the element must have an ID) (line 32-37). In our
example, ‚Äúp‚Äù ‚Äì which is a tag component ‚Äì was assumed incorrect
so the veriÔ¨Åcation will pass for all elements in PVE because ev-
ery element has a tag name. It also checks if the element contains
any descendants, children, or siblings, depending on the structure
of the erroneous selector (lines 22-31). Again, in the running ex-
ample, the next level (level 3) of the erroneous selector must be the
‚Äúdescendant‚Äù of the Ô¨Årst two levels, because of the whitespace be-
tween the level 2 components and the level 3 components; hence,
the check will pass for an element if it contains any descendants.
If both checks pass, the corresponding component is used to create
a new selector; each new selector is stored in VS. Finally, for each
new selector, a Ô¨Ånal veriÔ¨Åcation step is carried out to ensure that
the new selector is indeed valid in dom (lines 39-43).
In summary, for the running example, our design looks for match-
ing selectors of the form ‚Äúdiv#view-display-id-catalog_view > < N-
EW-TAG >.pages span‚Äù. Similarly, if the ID component ‚Äúview-
display-id-catalog_view‚Äù were assumed incorrect, the algorithm lo-
oks for matching selectors of the form ‚Äúdiv#< NEW-ID > > p.pages
span‚Äù. In the latter case, two matching valid selectors are found:
‚Äúdiv#view-id-catalog_view > p.pages span‚Äù and ‚Äúdiv#view-display-
id-catalog_page > p.pages span‚Äù
Inferring Possible Replacements : To determine the possible sick-
ness, our design determines if any element of the local string set
of each component ( LSS 1,LSS 2, ..., LSS N) can be replaced to
match one of the valid selectors in VS. This is accomplished by the
replacementsFinder() function (line 45). The basic idea is as
follows: for each component string set element, assume that this
element is incorrect, then determine if any of the valid selectors
can provide a replacement string value for that element. We ac-
complish this matching with the valid selectors through the use of
a string constraint solver (see Section 5.4).
Let us go back to the running example. Suppose the design
is currently considering the ‚Äú view-display-id-catalog_view ‚Äù
component, whose local string set was found earlier. Also, as men-
tioned, two valid replacement selectors were found for this compo-
nent. Our design goes through each element in the local string set to
look for possible replacements. First, it assumes that the Ô¨Årst string
set element ‚Äì namely ((‚Äú div#view-display-id- ‚Äù, 8), startIndex :
4,endIndex : 19) ‚Äì is incorrect; hence, it checks if any of the valid
selectors is of the form ‚Äú div#< NEW-STRING >catalog_view > -
p.pages span ‚Äù ‚Äì i.e., the erroneous selector with the string ‚Äúview-
display-id-‚Äù replaced. In this case, the constraint solver will Ô¨Ånd
one matching selector: ‚Äú div#view-id-catalog_view > p.pages
span ‚Äù. Next, our design will move on to the second local string
set element and perform the same procedure to Ô¨Ånd the follow-
ing matching selector: ‚Äú div#view-display-id-catalog_page
> p.pages span ‚Äù.
Case 2: Index Replacement. In this step, our design assumes
that the index used to access the list of elements returned by the
direct DOM access is incorrect. To check whether this assumption
holds, our approach records the size of the array returned by the
direct DOM access; this is determined based on the value of an
instrumented variable added to the JavaScript code to keep track of
the size. The erroneous array index used, if any, is also recorded.
The erroneous array index is compared with the size to see if
it falls within the allowed range of indices (i.e., [0‚Äìsize-1]). If
not, our approach will package the following as a possible sick-
ness (belonging to the ‚ÄúIndex‚Äù sickness class), to be added to the
list of possible sicknesses: ‚ÄúAn array index has a numerical
value of X that does not fall within the range [0-Z] ‚Äù;
here, Xis the erroneous array index, and Zissize-1 .Case 3: Null/UndeÔ¨Åned Checks. By default, our design packages
a possible sickness belonging to the ‚ÄúNull/UndeÔ¨Åned‚Äù class to ac-
count for cases where the repair is a DOM Element Validation. In
essence, this means the line of code must be wrapped in an ifstate-
ment that checks whether the DOM element being used is null or
undefined . If code termination was caused by a null exception
(or undeÔ¨Åned exception), the following is packaged and added to
the list of possible sicknesses: ‚ÄúA line of code X accessing
a property/method of the DOM element returned by the
direct DOM access should (probably) not execute if
the DOM element is null (or undefined)‚Äù .
5.3 Suggesting Treatments
Once the symptom analyzer has found a list of possible sick-
nesses, each of these possible sicknesses is examined by the treat-
ment suggester (Figure 3, box c). The goal of the treatment sug-
gester is as follows: given a possible sickness, create an actionable
repair message that would prompt the programmer to modify the
JavaScript code in such a way that the symptom represented by
the possible sickness would disappear. In order to accomplish this,
the code context, as inferred from the supplementary information
retrieved by the data collector, is analyzed. This module handles
each possible sickness class separately, as described below.
String class. Possible sicknesses belonging to the ‚ÄúString‚Äù class
require the string value Xat some line in the JavaScript code to be
replaced by another string value Y. If applied correctly, this would
cause the parameter at the direct DOM access to be valid, so the di-
rect DOM access would no longer output null ,undefined , nor an
empty set of elements (i.e., Symptom 1 disappears). As we discov-
ered in Section 3.2, most Parameter Replacement Ô¨Åxes are direct
string literal replacements; hence, at Ô¨Årst, it may seem straight-
forward to simply output a message prompting the programmer to
directly perform the replacement. However, there are several cases
that may make this suggestion invalid, for example:
1. The string value is not represented by a string literal, but
rather, by a variable or an expression. Recall that when cal-
culating the string set, gaps may exist in this string set due to
string values originating from sources external to the Java-
Script code, or due to values not originating from string lit-
erals. Hence, a simple ‚Äúreplace‚Äù message would be inappro-
priate to give out as a suggested repair;
2. The string value may be in a line that is part of a loop. Here,
a ‚Äúreplace‚Äù message may also be inappropriate, since the re-
placement would affect other (possibly unrelated) iterations
of the loop, thereby possibly causing unwanted side effects.
To account for these cases, before outputting a repair message,
our approach Ô¨Årst examines (a) the string set element type (i.e.,
is it a variable, expression, or string literal?), and (b) the location
(i.e., inside a loop?). Through this analysis, the treatment suggester
can provide a suggested repair message. The algorithm essentially
performs a ‚Äúbackground check‚Äù on the code suffering from the bug
to determine what message to output. For example, if our design
Ô¨Ånds that a string set element is in a line inside a loop, and this line
executed multiple times a message such as ‚Äúreplace at iteration‚Äù
or ‚Äúoff by one‚Äù ‚Äì will be given. The complete list of messages is
presented in Table 3.
When the running example is subjected to the treatment sug-
gester algorithm, the possible sicknesses found by the symptom
analyzer will lead to two REPLACE messages being suggested,
one of which is the Ô¨Åx described in Section 2: Replace the string
literal ‚Äúdiv#view-display-id-‚Äù with ‚Äúdiv#view-id-‚Äù in line 8 . The843Table 3: List of output messages.
Type Description
REPLACE Replace the string literal X with Y in line L
REPLACE AT ITERA-
TIONWrap line L in an if statement so that the string literal
X instead has value Y at iteration I
OFF BY ONE AT BE-
GINNINGChange the lower bound of the for loop containing
line L so that the original Ô¨Årst iteration does not exe-
cute
OFF BY ONE AT END Change the upper bound of the for loop containing
line L so that the original last iteration does not exe-
cute
MODIFY UPPER
BOUNDChange the upper bound of the for loop containing
line L so that the loop only iterates up to iteration I
(inclusive)
EXCLUDE ITERATION Skip iteration I of the for loop containing line L by
adding a ‚Äòcontinue‚Äô
ENSURE Ensure that the string value at line L has value Y in-
stead of X . This is a fall back message which is given
if a precise modiÔ¨Åcation to the code cannot be in-
ferred by the suggester. Thus, our suggester is con-
servative in that it only provides a particular sugges-
tion if it is certain that the suggestion will lead to a
correct replacement.
other message is a spurious suggestion: Replace the string literal
‚Äúcatalog_view‚Äù with ‚Äúcatalog_page‚Äù in line 2 .
Index and Null/UndeÔ¨Åned class. For the ‚ÄúIndex‚Äù class, the sug-
gestion is always as follows: Modify the array index in line L to
some number within the range [0‚ÄìZ] . For the ‚ÄúNull/UndeÔ¨Åned‚Äù
class, the suggestion depends on whether the exception was a null
exception or an undeÔ¨Åned exception. If the exception is a null ex-
ception, the following message is given: Wrap line L in an if state-
ment that checks if expression E is null . Here the expression E is
inferred directly from the error message, which speciÔ¨Åes which ex-
pression caused the null exception. An analogous message is given
if the exception is ‚ÄúundeÔ¨Åned‚Äù.
5.4 Implementation: Vejovis
We implemented our approach in a tool called V EJOVIS , which
is freely available for download [2].
The data collector is implemented by instrumenting the JavaScript
code using R HINO and running the instrumented application us-
ing C RAWLJAX [11]. For the symptom analyzer, we use the string
constraint solver H AMPI [9] for replacementFinder() (see Al-
gorithm 1, line 45), which looks for viable replacements among
the valid parameters found. The symptom analyzer treats the valid
parameters found as deÔ¨Åning the context-free grammar (CFG).
In keeping with our goal of providing as few suggestions as pos-
sible, V EJOVIS allows the users to modify a parameter called the
edit distance bound . The edit distance bound is a cutoff value that
limits the suggested replacement strings to only those whose edit
distance with the original string is within the speciÔ¨Åed value. We
use Berico‚Äôs [4] implementation of the Damerau-Levenshtein algo-
rithm to calculate the edit distance.
6. EV ALUATION
To evaluate the efÔ¨Åcacy of V EJOVIS in suggesting repairs for
DOM-related faults, we answer the following research questions.
RQ3 (Accuracy) : What is the accuracy of V EJOVIS in suggest-
ing a correct repair?
RQ4 (Performance) : How quickly can V EJOVIS determine pos-
sible replacements? What is its performance overhead?
We perform a case study in which we run V EJOVIS on real-world
bugs from eleven web applications. To determine accuracy (RQ3),
we measure both the precision and recall of our tool. To calculatethe performance (RQ4), we compare the runtimes of V EJOVIS with
and without instrumentation.
6.1 Subject Systems
The bugs to which we subject V EJOVIS come from eleven open-
source web applications, studied also in Section 3; hence, these
bugs represent real-world DOM-related faults that occurred in the
subject systems. We choose two bug reports randomly from the
set of bugs that satisfy our fault model, for each of the eleven
web applications, for a total of 22 bugs. Note that TaskFreak is
not included among the applications studied, as we only found 6
JavaScript bugs from that application, none of which Ô¨Åt the fault
model described in Section 4. Descriptions of the bugs and their
corresponding Ô¨Åxes (henceforth called the actual Ô¨Åxes ) can be found
online [2]. It took programmers an average of 47 days to repair
these bugs after being triaged, indicating that they are not trivial to
Ô¨Åx. We had to restrict the number of bugs to two per application as
the process of deploying the applications and replicating the bugs
was a time and effort intensive one. In particular, most of the bugs
were present in older versions of the web applications. This pre-
sented difÔ¨Åculties in installation and deployment as some of these
earlier versions are no longer supported.
6.2 Methodology
Accuracy. We measure accuracy based on both recall andpreci-
sion. In the context of this experiment, recall refers to whether our
tool was able to suggest the ‚Äúcorrect Ô¨Åx‚Äù ‚Äì that is, whether one of
the suggestions provided by V EJOVIS matches the actual developer
Ô¨Åx described in the corresponding bug report. Hence, in this case,
recall is a binary metric (i.e., either 0% or 100%), because the ac-
tual Ô¨Åx either appears in the list of suggestions, or it does not. Note
that in some cases, the suggested Ô¨Åx is not an exact match of the
applied Ô¨Åx, but is semantically equivalent to it, and is considered a
match. Precision refers to the number of suggestions that match the
actual Ô¨Åx divided by the number of suggestions provided by V E-
JOVIS . Again, since there is only one matching Ô¨Åx, precision will
be either 0 (if the correct Ô¨Åx is not suggested), or1
#Suggestions. This
metric is a measure of how well V EJOVIS prunes out irrelevant/in-
correct Ô¨Åxes.
To measure the above metrics, we Ô¨Årst replicated the bug, and
ran V EJOVIS with the URL of the buggy application and the direct
DOM access information (i.e., line number and enclosing function)
as input; for the libraries, the bugs are replicated by using the test
applications described in the bug reports. V EJOVIS outputs a list
of suggestions for the bug, which we compare with the actual de-
veloper Ô¨Åx to see if there is a match. Based on this comparison,
we calculated the recall and precision for that particular attempt. In
our experimental setup, the suggestions are sorted according to the
edit distance of the replacement string with respect to the original
string, where replacements with smaller edit distances are ranked
higher. Suggestions for ‚Äúnull‚Äù or ‚ÄúundeÔ¨Åned‚Äù checks are placed
between suggestions with edit distance 5 and those with edit dis-
tance 6. In the event of a tie, we assume the worst case i.e., the
correct Ô¨Åx is ranked lowest among the suggestions with the same
edit distance.
To test our assumption that the replacement parameter closely re-
sembles the original parameter, we control the edit distance bound
(deÔ¨Åned in Section 5.4) for V EJOVIS . We Ô¨Årst run our experiments
with an edit distance bound of inÔ¨Ånity , which, means the sugges-
tions given do not have to be within any particular edit distance
relative to the original string being replaced (i.e., no edit distance
bound assigned). Then, to observe how this bound affects V EJO-844Table 4: Accuracy results, with edit distance bound set to inÔ¨Ån-
ity i.e., no bound assigned. BR1 refers to the Ô¨Årst bug report,
and BR2, the second bug report (from each application). Data
in parentheses are the results for when the edit distance bound
is set to 5.
Application Accurate? Precision
BR1 BR2 BR1 BR2
Drupal 3(7)3(7) 3% (0%) 25% (0%)
Ember.js 3(3)3(3) 50% (50%) 33% (100%)
Joomla 3(3)3(3) 1% (25%) 1% (100%)
jQuery 3(3)7(7) 1% (25%) 0% (0%)
Moodle 3(3)3(3) 3% (33%) 3% (100%)
MooTools 3(7)3(3) 50% (0%) 50% (50%)
Prototype 3(3)3(3) 17% (50%) 50% (50%)
Roundcube 3(3)7(7) 1% (25%) 0% (0%)
TYPO3 3(3)3(3) 1% (100%) 100% (100%)
WikiMedia 3(7)3(3) 4% (0%) 1% (100%)
WordPress 3(3)3(3) 3% (7%) 1% (50%)
VIS‚Äô accuracy, we re-run our experiments with a smaller edit dis-
tance bound of 5. We choose the value 5 based on a pilot study.
Performance. For each bug, we measure the performance over-
head introduced by V EJOVIS ‚Äô instrumentation by comparing the
corresponding web application with and without instrumentation.
This evaluates the performance of the data collection phase of V E-
JOVIS . We also measure the time it takes for V EJOVIS to generate
the repair suggestions. This evaluates the performance of the symp-
tom analysis and treatment suggestion phases of V EJOVIS .
6.3 Results
Accuracy. Table 4 shows the results of our experiments when the
edit distance bound is set to inÔ¨Ånity i.e., no bound is assigned (num-
bers outside parentheses). The ‚ÄúAccurate‚Äù column of Table 4 indi-
cates, for each bug, whether the actual Ô¨Åx appears among the list
of repairs suggested by V EJOVIS (i.e., the recall was 100%). As
the results show, assigning no bound causes V EJOVIS to accurately
suggest repairs for 20 out of the 22 bugs, for an overall recall of
91%. The only unsuccessful cases are the second bugs in Round-
cube, where, the correct replacement selector is ‚Äú:focus:not(body)‚Äù,
and jQuery, where the correct replacement selector is ‚Äú[id=‚Äúnid‚Äù]‚Äù;
VEJOVIS does not currently support these CSS selector syntax .
Note that in three of the successful cases, the repair suggestion
does not exactly match the actual Ô¨Åx, but rather is equivalent to (or
close to) the actual Ô¨Åx.
First, in the second TYPO3 bug, the actual Ô¨Åx documented in the
bug report is to add a check to ensure that the NodeList valueObj ,
which is populated by a direct DOM access call to getElementsBy-
Name() , has a length greater than 0, thereby preventing the use of
valueObj[0].value from throwing an undeÔ¨Åned exception. V E-
JOVIS , in contrast, suggested an alternate but equivalent Ô¨Åx with
no side effects, namely adding a check to see if the expression
valueObj[0] is undeÔ¨Åned before trying to access one of its prop-
erties.
Second, in both the Ô¨Årst Moodle bug and the second Prototype
bug, V EJOVIS provides the fallback ‚ÄúENSURE‚Äù suggestion. In the
Moodle bug, V EJOVIS suggests the following: Ensure the value of
variable itemid is ‚Äúid_itemname‚Äù instead of ‚Äúitemname‚Äù ; this
is because the string literal ‚Äúitemname‚Äù originated from an anony-
mous function, which our implementation currently does not sup-
port, leaving a gap in the string set. Nonetheless, this simpliÔ¨Åes
the debugging task for the programmer, as it points her directly to
the problem ‚Äì i.e., the string ‚Äúitemname‚Äù, located somewhere in
the JavaScript code, needs to be changed to ‚Äúid_itemname‚Äù. Sim-
ilarly, in the Prototype bug, V EJOVIS suggests the following: En-Table 5: Rank of the correct Ô¨Åx when suggestions are sorted by
edit distance. The denominator refers to the total number of
suggestions. Top ranked suggestions are in bold.
Application Rank
BR1 BR2
Drupal 31 / 40 01 / 04
Ember.js 01 / 02 01 / 03
Joomla 01 / 88 01 / 88
jQuery 02 / 108 ‚Äì
Moodle 02 / 37 01 / 37
Moodle 02 / 02 01 / 02
Prototype 01 / 06 01 / 02
Roundcube 04 / 79 ‚Äì
TYPO3 01 / 187 01 / 01
WikiMedia 06 / 24 01 / 71
WordPress 13 / 30 01 / 170
sure the expression id.replace(/[\.:]/g, ‚Äú\\$0‚Äù) has
value ‚Äúouter.div‚Äù instead of ‚Äúouter\\$0div‚Äù . Again, while V EJO-
VISis not able to provide the exact Ô¨Åx, it points the programmer
to the relevance of the replace() method in the Ô¨Åx. These results
show that even in cases when V EJOVIS is unable to fully resolve
the origins of the erroneous selector‚Äôs string values, it still provides
meaningful suggestions that facilitate debugging and are hence use-
ful to the programmer.
Among the successful cases, the average precision (‚ÄúPrecision‚Äù
column of Table 4) is approximately 2%; on average, this trans-
lates to V EJOVIS providing 49 suggestions for each bug, with a
maximum of 187 total suggestions for the Ô¨Årst TYPO3 bug. The
high number of suggestions motivated us to implement the simple
ranking scheme based on edit distance (Section 6.2).
Table 5 shows, for each bug, the rank of the actual Ô¨Åx among the
list of suggestions provided by V EJOVIS ; only the cases where the
actual Ô¨Åx appears among the list of suggestions are considered. As
shown in the table, the correct Ô¨Åx appears as the Ô¨Årst suggestion
in 13 out of the 20 cases, and as the second suggestion in three
more cases. In fact, for the WordPress bug, the correct Ô¨Åx is tied
for Ô¨Årst place among 13 bugs; we listed its rank as 13 because we
consider the worst case. Hence, despite providing a large number
of suggestions on average when the edit distance bound is set to
inÔ¨Ånity, our simple ranking scheme based on edit distance ranked
most of the actual Ô¨Åxes near the top of the list of suggestions .
As mentioned, the above results were obtained with an edit dis-
tance bound of inÔ¨Ånity. To quantify the effects of using a Ô¨Ånite
bound, we re-ran the above accuracy experiment with an edit dis-
tance bound of 5. The results are shown in parentheses in Table 4.
As the results show, assigning a bound of 5 decreases the number of
successful cases from 20 to 16, where four additional cases became
unsuccessful because the actual Ô¨Åx required replacing the original
parameter with another parameter that is more than an edit distance
of 5 away. However, the precision jumps dramatically to 36% with
this bound, which translates to around 3 suggestions given for each
bug on average. Hence, assigning a Ô¨Ånite edit distance bound can
signiÔ¨Åcantly decrease the number of suggestions, which makes the
list of suggestions more manageable; however, this comes at the
cost of lower recall of 73% (as compared to 91%).
Performance. There are two sources of performance overhead in
VEJOVIS : (1) instrumentation overhead, and (2) symptom analysis
and treatment suggestion overhead. Table 6 shows the results. The
time taken with and without instrumentation during the data collec-
tion phase of V EJOVIS are shown in the second and third columns
of the table. The time varies per application, ranging from 16.3 to
85.0 seconds, for an average of 39.3 seconds. The time in the symp-
tom analysis and treatment suggestion phases is shown in the last845Table 6: Performance results.
Application Crawl Crawl Average
Time w/o Time with Treatment
Instrumentation (s) Instrumentation (s) Time (s)
Drupal 28.5 49.6 1.8
Ember.js 10.8 16.3 0.8
Joomla 57.0 85.0 6.1
jQuery 12.0 19.0 4.1
Moodle 46.9 59.6 7.4
MooTools 13.3 19.1 0.9
Prototype 12.0 17.4 8.6
Roundcube 25.1 34.7 3.4
TYPO3 39.9 72.8 6.5
WikiMedia 15.9 24.8 5.4
WordPress 20.2 33.8 7.0
Average - 39.3 4.7
column. The average time for these phases is 4.7 seconds, ranging
from 0.8 to 7 seconds. Thus, on average, V EJOVIS takes less than
one minute (44 seconds) to Ô¨Ånd the correct Ô¨Åx, with a worst-case
time of 91.1 seconds for Joomla.
7. DISCUSSION
Extensions. First, V EJOVIS suggests treatments belonging to the
Parameter ModiÔ¨Åcation and DOM Element Validation categories
as mentioned in our empirical study of common Ô¨Åxes in Section 3.
While these together constitute more than half of the Ô¨Åx types we
found in the study, another common Ô¨Åx category is Method/Prop-
erty ModiÔ¨Åcation, in which a DOM API method or property is
added, removed or replaced with another method/property. We do
not incorporate this Ô¨Åx category in our design; however V EJOVIS
can be extended to account for this category. For instance, it is
possible, in some cases, to reduce the problem of replacing DOM
methods to replacing CSS selectors. As an example, replacing
getElementById(‚Äústr‚Äù) with getElementsByClassName(‚Äúst-
r‚Äù) can be thought of as replacing the CSS selector ‚Äú#str‚Äù with
‚Äú.str‚Äù.
Second, the results of our evaluation show that while V EJOVIS
accurately predicts the actual Ô¨Åx in almost all of the bug reports
analyzed, the number of suggestions provided can be large, thereby
lowering its precision. In our evaluation, we showed that ranking
the Ô¨Åxes based on edit distance makes the actual Ô¨Åx rank high in
many cases. We are currently exploring more intelligent ways to
perform this ranking; for example, based on the textual patterns of
the strings.
Threats to Validity. Anexternal validity threat is that the bugs we
analyzed come from only 11 web applications. However, the sys-
tems considered were developed for different purposes and hence,
represent a reasonable variety. Further, the corresponding bug re-
ports have been Ô¨Åxed by the developers, and are therefore represen-
tative of the issues encountered in practice.
Aninternal threat to validity is that we have assumed the Ô¨Åxes
described in the bug reports are correct as many experienced de-
velopers are typically involved with providing patches for these
bugs. Nonetheless, to mitigate this threat, we carefully analyzed
the patches provided in the bug reports and have tested the Ô¨Åxes on
our own platforms to see if they are sound.
Additionally, the bugs we considered in our evaluation were taken
from the bug report study in Section 3, which may be a potential
source of bias. This threat can be mitigated by considering other
applications, which we plan to do in the future. As for repeata-
bility, V EJOVIS is available [2], and the experimental subjects are
open source, making our case study fully repeatable.8. RELATED WORK
Program Repair. Program repair refers to the act of Ô¨Åxing bugs
through automated techniques. Perhaps the best-known application
of program repair is to data structures. Demsky et al. [6] use formal
speciÔ¨Åcations to suggest Ô¨Åxes for data structures. Elkareblieh et al.
[7] use programmer speciÔ¨Åed assertions for data structure repair.
However, these techniques are limited to repairing data-structures,
and do not Ô¨Åx the underlying defect that produced the erroneous
structure. While the DOM can be considered a data-structure, V E-
JOVIS goes beyond the DOM and actually can suggest ways to
modify the JavaScript code based on the defective DOM access.
Generating Ô¨Åxes at the source code level has gained attention
recently [3, 18, 19]. Weimer et al. [19] propose the use of genetic
algorithms for repairing C programs. The main idea is to copy other
parts of the program to the faulty portion of the program and check
if the modiÔ¨Åed program passes the existing test cases. However, it
is not clear how this technique could be applied to web applications,
where the code base includes different languages such as JavaScript
and HTML/DOM.
In recent work, Zhang et al. [20] propose FlowFixer, a technique
to repair broken workÔ¨Çows in Java-based GUI applications. Similar
to V EJOVIS , FlowFixer attempts to Ô¨Ånd repairs for errors that arise
due to a mismatch between the code and the GUI state. However,
there are two main differences between V EJOVIS and FlowFixer.
First, FlowFixer is concerned with correcting the sequence of user
actions applied to the GUI; in contrast, V EJOVIS is concerned with
correcting the code that drives the functionality of the application.
Second, FlowFixer uses random testing to Ô¨Ånd replacements; V E-
JOVIS is different in that it performs a systematic traversal of the
DOM to Ô¨Ånd valid replacement selectors.
Web Application Repair. There has been limited work on explor-
ing fault repair for web applications. Carzaniga et al. [5] propose
automatic workarounds for web applications that experience errors
in using APIs by replacing the buggy API call sequence with a
functionally equivalent, but correct sequence. Samimi et al. [16]
have proposed a technique for PHP code to Ô¨Åx errors that result in
the generation of webpages with malformed HTML; similar work
has been done by Zheng et al. [21]. Neither of these techniques con-
sider JavaScript code, nor do they apply to DOM-related JavaScript
faults. In recent work, Jensen et al. [8] and Meawad et al. [10] in-
troduce techniques to transform unsafe evalcalls in JavaScript code
to functionally equivalent, but safe constructs. This is more of a
prevention than repair technique. However, they do not consider
JavaScript errors, and in particular DOM-related errors.
9. CONCLUSION
JavaScript interacts extensively with the DOM to create respon-
sive applications; yet, such interactions are prone to faults. In this
paper, we attempt to understand common Ô¨Åxes applied by program-
mers to DOM-related faults. Based on these Ô¨Åndings, we propose
an automated technique for providing repair suggestions for DOM-
related JavaScript faults. Our technique, implemented in a tool
called V EJOVIS , is evaluated through a case study of 22 bugs based
on real-life bug reports. We Ô¨Ånd that V EJOVIS can accurately pre-
dict the repair in 20 out of the 22 bugs, and that the correct Ô¨Åx
appears Ô¨Årst in the list of Ô¨Åx suggestions for 13 of the 20 bugs.
10. ACKNOWLEDGMENTS
This research was supported in part by an NSERC Strategic Proj-
ect Grant, a Four Year Fellowship (FYF) from UBC, and a research
gift from Intel Corporation. We thank the anonymous reviewers of
ICSE 2014 for their feedback to improve the paper.84611. REFERENCES
[1] Autopager jQuery extension.
http://code.google.com/p/jquery-autopager/ .
[2] Vejovis.
http://ece.ubc.ca/~frolino/projects/vejovis/ .
[3] A. Arcuri and X. Yao. A novel co-evolutionary approach to
automatic software bug Ô¨Åxing. In Proceedings of World
Congress on Evolutionary Computation (CEC) , pages 162
‚Äì168. IEEE Computer Society, 2008.
[4] Berico. Damerau-Levenshtein Java implementation.
http://www.gettingcirrius.com/2011/06/
calculating-similarity-part-3-damerau.html .
[5] A. Carzaniga, A. Gorla, N. Perino, and M. Pezz√®. Automatic
workarounds for web applications. In Proceedings of the
International Symposium on Foundations of Software
Engineering (FSE) , pages 237‚Äì246. ACM, 2010.
[6] B. Demsky and M. Rinard. Data structure repair using
goal-directed reasoning. In Proceedings of the International
Conference on Software Engineering (ICSE) , pages
176‚Äì185. ACM, 2005.
[7] B. Elkarablieh, I. Garcia, Y . L. Suen, and S. Khurshid.
Assertion-based repair of complex data structures. In
Proceedings of the International Conference on Automated
Software Engineering (ASE) , pages 64‚Äì73. ACM, 2007.
[8] S. H. Jensen, P. A. Jonsson, and A. M√∏ller. Remedying the
eval that men do. In Proceedings of the International
Symposium on Software Testing and Analysis (ISSTA) , pages
34‚Äì44. ACM, 2012.
[9] A. Kiezun, V . Ganesh, P. J. Guo, P. Hooimeijer, and M. D.
Ernst. Hampi: a solver for string constraints. In Proceedings
of the International Symposium on Software Testing and
Analysis (ISSTA) , pages 105‚Äì116. ACM, 2009.
[10] F. Meawad, G. Richards, F. Morandat, and J. Vitek. Eval
begone!: semi-automated removal of eval from JavaScript
programs. In Proceedings of the International Conference on
Object Oriented Programming Systems Languages and
Applications (OOPSLA) , pages 607‚Äì620. ACM, 2012.
[11] A. Mesbah, A. van Deursen, and S. Lenselink. Crawling
Ajax-based web applications through dynamic analysis of
user interface state changes. ACM Transactions on the Web
(TWEB) , 6(1):3:1‚Äì3:30, 2012.
[12] H. V . Nguyen, H. A. Nguyen, T. T. Nguyen, and T. N.
Nguyen. Auto-locating and Ô¨Åx-propagating for HTML
validation errors to PHP server-side code. In Proceedings ofthe International Conference on Automated Software
Engineering (ASE) , pages 13‚Äì22. IEEE Computer Society,
2011.
[13] F. Ocariza, K. Bajaj, K. Pattabiraman, and A. Mesbah. An
empirical study of client-side JavaScript bugs. In
Proceedings of the International Symposium on Empirical
Software Engineering and Measurement (ESEM) , pages
55‚Äì64. IEEE Computer Society, 2013.
[14] F. Ocariza, K. Pattabiraman, and A. Mesbah. AutoFLox: An
automatic fault localizer for client-side JavaScript. In
Proceedings of the International Conference on Software
Testing, VeriÔ¨Åcation and Validation (ICST) , pages 31‚Äì40.
IEEE Computer Society, 2012.
[15] F. Ocariza, K. Pattabiraman, and B. Zorn. JavaScript errors
in the wild: An empirical study. In Proceedings of the
International Symposium on Software Reliability
Engineering (ISSRE) , pages 100‚Äì109. IEEE Computer
Society, 2011.
[16] H. Samimi, M. Schafer, S. Artzi, T. Millstein, F. Tip, and
L. Hendren. Automated repair of HTML generation errors in
PHP applications using string constraint solving. In
Proceedings of the International Conference on Software
Engineering (ICSE) , pages 277‚Äì287. IEEE Computer
Society, 2012.
[17] W3C. Cascading style sheets level 2 revision 1 speciÔ¨Åcation:
Selectors, 2011.
http://www.w3.org/TR/CSS2/selector.html .
[18] Y . Wei, Y . Pei, C. A. Furia, L. S. Silva, S. Buchholz,
B. Meyer, and A. Zeller. Automated Ô¨Åxing of programs with
contracts. In Proceedings of the International Symposium on
Software Testing and Analysis (ISSTA) , pages 61‚Äì72. ACM,
2010.
[19] W. Weimer, T. Nguyen, C. Le Goues, and S. Forrest.
Automatically Ô¨Ånding patches using genetic programming.
InProceedings of the International Conference on Software
Engineering (ICSE) , pages 364‚Äì374. IEEE Computer
Society, 2009.
[20] S. Zhang, H. L√º, and M. D. Ernst. Automatically repairing
broken workÔ¨Çows for evolving gui applications. In
Proceedings of the International Symposium on Software
Testing and Analysis (ISSTA) , pages 45‚Äì55. ACM, 2013.
[21] Y . Zheng, X. Zhang, and V . Ganesh. Z3-str: a z3-based string
solver for web application analysis. In Proceedings of the
International Symposium on Foundations of Software
Engineering (FSE) , pages 114‚Äì124. ACM, 2013.847