Towards an Intelligent
Domain-SpeciÔ¨Åc Traceability Solution
Jin Guo, Natawut Monaikul, Cody Plepel, and Jane Cleland-Huang
Systems and Requirements Engineering Center
School of Computing, DePaul University
Chicago, IL USA
jguo9@cdm.depaul.edu; natawutmo@gmail.com; plepel.cody@gmail.com;
jhuang@cs.depaul.edu
ABSTRACT
State-of-the-art software trace retrieval techniques are un-
able to perform the complex reasoning that a human analyst
follows in order to create accurate trace links between arti-
facts such as regulatory codes and requirements. As a result,
current algorithms often generate imprecise links. To ad-
dress this problem, we present the Domain-Contextualized
Intelligent Traceability Solution (DoCIT), designed to mimic
some of the higher level reasoning that a human trace ana-
lyst performs. We focus our eorts on the complex domain
of communication and control in a transportation system.
DoCIT includes rules for extracting \action units" from soft-
ware artifacts, a domain-specic knowledge base for relating
semantically similar concepts across action units, and a set
of link-creation heuristics which utilize the action units to
establish meaningful trace links across pairs of artifacts. Our
approach signicantly improves the quality of the generated
trace links. We illustrate and evaluate DoCIT with exam-
ples and experiments from the control and communication
sector of a transportation domain.
Categories and Subject Descriptors
D.2.1 [ Software Engineering ]: Requirements/ Specica-
tions; I.2.7 [Computing Methodologies]: Natural Lan-
guage Processing | Text Analysis
Keywords
Traceability; Intelligent System; Domain Ontology
1. INTRODUCTION
Software traceability is an essential component in the de-
velopment of any non-trivial software system. It is dened
by the Center of Excellence for Software Traceability (Co-
EST) as \the ability to interrelate any uniquely identiable
software engineering artifact to any other, maintain required
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission
and/or a fee. Request permissions from permissions@acm.org.
ASE‚Äô14, September 15-19, 2014, Vasteras, Sweden.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3013-8/14/09 ...$15.00.
http://dx.doi.org/10.1145/2642937.2642970 .links over time, and use the resulting network to answer
questions of both the software product and its development
process" [1]. In safety-critical systems regulated by bodies
such as the US Food and Drug Administration or the Fed-
eral Aviation Authority [28], it is specically required as
part of the assessment, approval, and certication process
[19]. In all domains, software traceability can provide use-
ful support for a variety of software engineering activities
including compliance verication, impact analysis, and test-
case regression analysis. Despite its importance, numerous
studies have shown that achieving eective traceability is
challenging, primarily because creating and maintaining ac-
curate trace links for large and/or complex projects is eort-
intensive, arduous, and error-prone [7, 22, 27, 23].
To address these problems, researchers have developed
and evaluated techniques that use standard information re-
trieval methods to automate, or semi-automate, the process
of trace link creation. Techniques include the Vector Space
Model (VSM), Latent Semantic Indexing (LSI), and prob-
abilistic networks [3, 14]. Other techniques involve instru-
menting the project environment and conguration manage-
ment tools to prospectively capture trace links as a byprod-
uct of the development process [5]. Unfortunately, while
such techniques are often able to return 85-90% of the tar-
geted links, precision rates are often quite low, ranging from
10-50% depending on the characteristics of the project and
its software artifacts [14]. Industry demands more precise
results before they are willing to integrate trace retrieval
techniques into their software development tools and pro-
cesses [6], and therefore these low accuracy problems have
hindered the adoption of trace retrieval practices in industry.
1.1 Term Mismatches
The major barrier is caused by the mismatch of terms that
occurs frequently across software artifacts to be traced [10].
For example, consider the following system requirement for
a Driver-Optional Highway System (DOHS) that states: the
Highway Wayside Segment shall monitor signal, road work
directive, and hazard detector information from eld devices
and the related system design artifact that states: during
lamp-out conditions the WIU shall send the current state of
the highway signal. Even though the two artifacts exhibit al-
most no shared terms, the fact that the WIU is an acronym
ofHighway Wayside Interface Unit, that WIUs are located
in the Highway Wayside Segment and are connected to eld
devices, and that monitoring of eld devices is supported
by data, mean that these two artifacts are related and a
755
Source Artifact  
Target Artifact  
     Ontology  Source 
Action Unit  
Target 
Action Unit  Action -Unit 
Extraction  
Term -based artifact matching  
(with Vector Space Model)  Link Creation 
Heuristics For each pair of 
source/target 
action units.  Link Not a link  
Generated Trace Links 
ordered by likelihood       High confidence 
DoCIT  Links 
merged with lower confidence VSM links and pushed to the top of the list.  ÔÇå ÔÇç 
ÔÇé ÔÇê 
ÔÇè 
         Human evaluates DoCIT  generated links.  
Ontology and link creation heuristics updated accordingly.  ÔÇë 
       Human vets 
and uses the generated links  Retrieve rules for 
constructing action units  Retrieve relationships between concepts and link creation rules.  
ÔÇí Target Artifact  
Target Artifact  Figure 1: The DoCIT process showing its primary components and execution context.
trace link should be created. Current term-based trace re-
trieval algorithms are incapable of understanding these con-
cepts and would therefore be unlikely to precisely create the
corresponding link [10]. On the other hand, most human
domain experts performing the tracing task manually would
be able to look beyond the mismatch of terms, reason about
the concepts in the domain, and correctly establish a trace
link between a source and target artifact.
Approaches that attempt to solve this problem through
the use of ontologies alone fail to take into consideration
specic roles played by dierent concepts [20, 18]. They
therefore do not handle the nuances of why two artifacts with
similar terms, or even terms related through the ontology,
should or should not be linked. Approaches that rely purely
on ontology therefore may improve recall but still fail to
adequately address the precision problem [20].
1.2 DoCIT Solution
Our work delivers a Domain-Contextualized Intelligent
Traceability (DoCIT) system, capable of performing human-
like reasoning for the highly focused area of communication
and control within a transportation domain. While there
are non-trivial costs involved in creating a DoCIT system for
even a single regulatory domain, this initial outlay must be
balanced against the far greater costs of establishing a su-
cient set of trace links to demonstrate compliance and safety
for such systems. Our experiences of working in this domain
have shown that traceability costs for a single project can
easily exceed $1 Million (US) [6]. Fortunately, as regulations
apply across multiple projects, the DoCIT knowledge base
can be reused in projects that need to comply to the same
regulatory codes.
1.3 Overview
The remainder of the paper is laid out as follows. Sec-
tions 2 and 3 provide an overview of DoCIT and the tar-
geted domain. Sections 4, 5, and 6 describe action units,
link heuristics, and the knowledge base respectively. Section
7 describes the process we used for constructing the initial
knowledge base and the way we implemented DoCIT in con-
junction with a term-based approach. Section 8 describes
a series of experiments we conducted to evaluate DoCIT.
Finally, Section 9 discusses threats to validity, Section 10
presents related work, and Section 11 summarizes our nd-
ings and lays out directions for future work.2. DOCIT
The various elements of DoCIT are depicted in Figure 1.
DoCIT takes as input a source artifact (e.g. a regulatory
code) and a set of target artifacts (e.g. system level require-
ments) to be traced. Trace links are built around action
units extracted from source and target artifacts ¬¨. Link
heuristics dene the conditions under which the properties
of two action units determine that a link should be created
between their associated source and target artifacts ¬≠. Both
the action unit extraction process and the application of link
heuristics are supported by a domain-specic ontology ¬Æ.
While DoCIT tends to deliver more precise trace links
than term-based algorithms, it depends on a relatively com-
plete and correct set of action unit denitions, action unit
extraction rules, link heuristics, and supporting ontology.
We refer to these collectively as the DoCIT knowledge base
from now on. Given that we cannot guarantee complete-
ness of this knowledge base, especially when tracing new
datasets, we deploy DoCIT within the `safety-net' of the
popular, term-based Vector Space Model (VSM) ¬Ø. By
merging DoCIT generated links with term-based generated
ones, we push the more precise DoCIT links towards the top
of the merged list of candidate links. Furthermore, we lever-
age the VSM similarity scores to create an ordered ranking
of DoCIT links ¬∞.
Finally, we incorporate human feedback into our process.
This facilitates ongoing renements in the DoCIT knowledge
base¬±, and assigns the human analyst the nal task of
vetting the generated trace links ¬≤.
The work we present in this paper builds on our previous
proof-of-concept [13]. However, our earlier work relied upon
a human analyst to manually map artifacts onto a simple set
of seven trace creation heuristics, and utilized a rudimentary
ontology. In contrast, the work in this paper makes very sig-
nicant advances in moving toward our longer-range goal of
complete automation. Knowledge is now represented in a
formal ontology language. The novel concept of action units
and their associated extraction rules are introduced, allow-
ing us to automatically parse and analyze non-trivial in-
dustrial requirements. Furthermore, the previous high-level
link heuristics are discarded and replaced with 33 heuristics
centered around the new notion of action units. Given an
underlying knowledge base, these link heuristics allow us to
automate the task of generating a relatively precise set of
trace links.
7563. TRANSPORTATION DOMAIN
The purpose of this paper is to demonstrate that a DoCIT
solution can be used eectively in a complex regulated do-
main. We focus our eorts on the communication and con-
trol aspects of the transportation domain for several reasons.
First, it represents a regulated safety-critical industry for
which traceability is required. Second, its projects tend to
grow very large with tens of thousands of trace links and
therefore the tracing task can be particularly costly and
arduous. Finally, we have access to two large industrial
datasets from our collaborators. Due to the proprietary
nature of the project, we are not able to disclose its ex-
act domain, and therefore all of our examples in this paper
have been disguised under the domain of communication and
control for the Driver-Optional Highway System (DOHS).
We established a one-to-one mapping between terms in our
domain and terms in the DOHS. The DOHS provides en-
vironmental controls used by both manned and unmanned
vehicles to propose routing, to prevent vehicles from entering
accident zones, and to provide a wide range of directives.
The dataset includes 242 System Requirement Specica-
tion artifacts (SRS), 963 System Design Description arti-
facts (SDD), and 583 SubSystem Requirement Specication
artifacts (SSRS). Our industrial collaborators provided two
validated trace matrices which included 583 trace links from
SRS to SDD, and 700 trace links from SSRS to SDD.
4. ACTION UNITS
The action unit represents a novel and fundamental build-
ing block of our approach. In this section we explain what
an action unit is, how it is dened, and nally how it is
instantiated through a natural language extraction process.
4.1 Action Unit DeÔ¨Ånition
Each action unit is dened in terms of a verb syntactic
group, a set of properties , and a set of mapping rules which
identify a part of speech to be mapped to each property.
A verb syntactic group represents a group of verbs which
belong together because they tend to be used in similar ways.
For example, the verbs transmit, broadcast, indicate, upload ,
and deliver do not mean exactly the same thing, but they
do exhibit the same syntactical usage pattern. As a result
they also exhibit similar part-of-speech dependencies. For
example, we can say that when one of these verbs is found in
a sentence, the recipient of the action is normally identied
as the noun phrase which is the object of the preposition to
associated with the verb.
Syntactic 
group  transmit, upload, convey, 
forward, grant, display, 
report, broadcast , indicate  Properties  
Action Unit Definition  
Properties  The Wayside Segment shall transmit Wayside Status Messages (WSMs) to the Automobile Segment. 
Semantic Group   Transmissive  
Instance of an Action Unit  Action   transmit  Agent  Theme  Recipient  Subject (nsubj ) 
Passive Agent (agent)  
Direct Object (dobj ) 
Passive Subject (nsubjpass ) 
Prepositional Object (prep_to ) 
 
Agent  Theme  Recipient  wayside segment  
wayside status message  
automobile segment  
Figure 2: A denition of an action unit showing sam-
ple properties and an example instantiationThe action unit's properties are then dened in terms of
thematic roles [26], which represent a standard set of roles
that a noun phrase can play with respect to a verb. While
linguistic theories have recognized over 1000 dierent types
of thematic roles, we observed six of them in the data set
from which the knowledge base was constructed. These are:
Agent: The initiator of some action, capable of acting
with volition, as in \The DOHS system shall send..."
Theme : The entity which is moved by an action, as in
\...shall send a message "
Recipient: The object which receives or gains something
as a result of the action, as in \...send a message to a sub-
system"
Instrument: The object with which or by which the ac-
tion is performed, as in \...send a message through an in-
terface "
Location : The place in which the action is completed, as
in \...send a message within the limits "
Initial Location : The place in which the action is ini-
tiated, as in \...leave the area". This role was created to
account for sentences containing two locations, as in \tran-
sition from A to B".
The work in this paper is based on these six observed roles,
however DoCIT algorithms are extensible to accommodate
additional roles as needed.
Finally, the action unit denition provides a set of map-
ping rules which describe the part-of-speech dependencies
that must be mapped to each property. Dierent denitions
use various combinations of properties and dependencies.
For example, in Figure 2, an action unit denition is given
for a syntactic group related to the set of actions transmit,
upload ,convey , etc. The denition prescribes the need to
identify an agent ,theme, and recipient and species that
these roles are played by the subject (nsubj), direct object
(dobj), and prepositional object of to(prep to) respectively.
The same gure shows an instantiated action unit pop-
ulated through parsing the artifact \The Wayside Segment
shall transmit Wayside Status Messages (WSMs) to the Au-
tomobile Segment." The action transmit was recognized as
a member of the Transmissive semantic group, and the noun
phrases wayside segment, wayside status message , and au-
tomobile segment were mapped to the agent, theme, and
recipient properties respectively. We discuss the purpose of
the semantic group in the next section.
4.2 Instantiated Action Units
An action unit needs to be identied and extracted au-
tomatically from the text in an artifact. The challenging
aspect of this task is that artifacts, such as requirements
and regulatory codes, are written in natural language, of-
ten describe multiple features, carry extraneous information
such as rationales, denitions, and other forms of descrip-
tion, often describe complex constraints and conditions, and
are not always grammatically well-formed.
Action unit extraction is a natural language processing
(NLP) task. We used the Stanford parser for this task be-
cause its unlexicalized PCFG Parser [17] can achieve rela-
tively accurate parsing results with fast processing speed.
We now provide an overview of the parsing process.
4.2.1 Preprocessing
The text from the artifact is rst preprocessed by re-
placing terms such as (/) with or, and removing superu-
757Figure 3: Parsed Tree of Sample Artifact
Table 1: Dependencies extracted from the parse tree
det(Segment-3, The-1) nn(Messages-8, Status-7)
nn(Segment-3, Wayside-2) dobj(transmit-5, Messages-8)
nsubj(transmit-5, Segment-3) det(Segment-12, the-10)
aux(transmit-5, shall-4) nn(Segment-12, Automobile-11)
root(ROOT-0, transmit-5) prep to(transmit-5, Segment-12)
nn(Messages-8, Wayside-6)
ous characters such as (-) which confuse the parsing pro-
cess. In addition, unhelpful, frequently occurring parts of
the sentence, such as provide [a mechanism] for were re-
moved through a string pattern matching process. Such
patterns have been added to our knowledge base.
4.2.2 Parse Tree
The Stanford parser was used to produce a POS (Part-of-
Speech) tree as illustrated in Figure 3. Each node is labeled
with a POS tag. We limited our approach to support only
noun phrases (NP) as they have been shown to play the
most crucial role in the tracing process [34]. NPs such as all
critical data can be identied by extracting nodes labeled
NPin the parsed tree. Phrases which have similar mean-
ings but dierent structures, such as signal state and state
of signal, are transformed into a standard form using tree
pattern analysis and matching techniques.
Overall, we processed basic noun phrases, lists of noun
phrases, and also prepositional phrases, verb phrases, and
clauses found within a noun phrase. From this tree, the
Stanford parser generated a dependency set, as depicted in
Table 1, which provides the information needed to auto-
matically map POS to the properties dened in each appli-
cable action unit denition. Thus, a dependency such as
nsubj(transmit-5, Segment-3) relates (Automobile) Segment
as the subject of transmit. In general, the NP in the nsubj
dependency with the verb transmit, along with any other
verb in its syntactic group, should be considered the agent
of the verb. From the dependency set, we may then extract
an instance of the action unit from an artifact in an auto-
mated fashion as each relevant dependency links a verb to
nouns that get mapped onto action unit properties.
4.2.3 Semantic Verb Groups
There is one nal step in the action unit instantiation
process. While properties and their mappings are driven
by the usage patterns of the verb, the link creation process
is driven by their semantics . The nal step in the process
therefore involves looking up the semantic group of the verb.
Our current knowledge base includes 24 distinct semanticgroups such as Armative ,Calculative, Evasive, and Re-
ceptive. While standard semantic groupings do exist (i.e.
in WordNet), they tend to focus on quite commonly used
verbs and do not include many of the verbs found in our
transportation domain. Furthermore, in many cases, no ap-
propriate grouping exists in which a new verb can be added.
We therefore developed our own semantic groupings follow-
ing the process described in Section 7.1 of this paper.
The end result of the extraction process is that each arti-
fact is represented by one or more instantiated action units.
It is these action units which are then used in the trace link
generation process.
5. LINK HEURISTICS
Trace links are created by comparing two action units ex-
tracted from a source and target artifact respectively. Cur-
rently, a trace link is established between the source and tar-
get artifact whenever a relationship is established between
a pair of their action units. However, in future implemen-
tations we plan to take all pairs of action units for a source
and target artifact into account simultaneously in order to
reason more eectively about conditions and constraints.
5.1 Link Heuristic DeÔ¨Ånition
Each link heuristic provides a set of guidelines for evalu-
ating whether two action units of specied semantic groups
should be linked or not. For this reason, most heuristics are
named according to a semantic pair, for example: motive-
permissive, transmissive-administrative or transmissive- re-
ceptive. The transmissive-receptive heuristic can only be
applied when one action unit is of type transmissive, and
the other is of type receptive, and so on. Currently, the
only exception is the basic heuristic, which can be applied
whenever two action units share the same semantic group.
Link heuristics also specify rules for comparing the action
unit properties. For example, a heuristic might specify a rule
that the themes of two action units must be the same, or
that the agent of one action unit must match the recipient
of another. Such matches can be either exact orhierar-
chical. An exact match means that two elements are the
same or equivalent, while a hierarchical match means that
two elements are related through the is-a or compositional
hierarchy of the ontology. For example, a Wayside Inter-
face Unit is part of the Wayside Segment . Such hierarchical
and compositional relationships are captured in the domain
ontology which we describe in Section 6.
5.2 Sample Link Heuristics
We illustrate our approach with three dierent link heuris-
tics. Each is dened in terms of its semantic groups, as well
as the rules by which the elements must match, where an
element is dened as the terms assigned to a property in
the action unit. For example, WIU might be the element
assigned to a theme property.
There are currently four types of matching criteria (MC)
dened as follows for a pair of elements:
MC 0 : If both elements are present, then they must match
(exact or hierarchical). However, if one or both of the ele-
ments are missing, the MC can be ignored.
MC 1 : If one element is present, the other must be present
too and must match (exact or hierarchical). If neither ele-
ment is present, the MC can be ignored.
758MC 2 : Both elements must be present and must match
(exact or hierarchical).
MC 3 : Both elements must be present and must match
exactly.
5.2.1 Basic Link
The basic heuristic is applicable when the semantic group
in both action units are the same. A link is established if
and only if agents ,recipients , and instruments are matched
at MC level 0, and themes andlocations are matched at MC
level 1. We provide the following illustrative example:
A1: Any critical failure during the Disengaged Mode
will force the OBM to enter the Failed Mode.
Action enter
Semantic Group Motive
Themes obm
Location fail mode
A2: The VehicleGuard DOH System shall have a
Failed Mode where the Automobile segment transi-
tions if a vital hardware or software failure is detected.
Action transition
Semantic Group Motive
Themes automobile segment
Location fail mode
In this case all the criteria for the heuristic are met. Both ac-
tion units belong to the Motive semantic group. The OBM
(i.e. Onboard Module) is part of the automobile segment;
therefore, the themes match at the hierarchical level. Fi-
nally, the two locations exhibit an exact match. Therefore
a trace link is established.
5.2.2 Transmissive-Receptive
This heuristic applies when the semantic group in one ac-
tion unit is Transmissive and the other is Receptive. A link
is established if and only if agents ,recipients ,instruments ,
and locations match at MC level 0, and themes match at
MC level 2. We provide the following example.
A1: The OBM shall support reception and decompo-
sition of Wayside Status Messages (WSM).
Action reception
Semantic Group Receptive
Recipients obm
Themes wayside status message
A2: The Wayside Segment shall transmit information
to the Automobile Segment in the form of Wayside
Status Messages (WSMs).
Action transmit
SemanticGroups Transmissive
Agents wayside segment
Recipients automobile segment
Themes wayside status message
In this case the semantic groups are Transmissive andRecep-
tiveand so the heuristic is applicable. Checking the prop-
erty pairs, we see that agents, instruments , and locations
are missing and therefore ignored. Furthermore, the recipi-
ents property is present in both cases, and OBM stands for
Onboard Module , which is a part of the Automobile Segment
and therefore hierarchically linked through the ontology. Fi-nally, both action units contain the same theme of Wayside
Status Message. As a result, a link is created.
5.2.3 Motive-Permissive:
This heuristic applies when the semantic group in one ac-
tion unit is Motive and the other is Permissive . A link is
established if and only if locations match at MC level 3, and
themes match at MC level 0. We illustrate this with a nal
example.
A1: The Cut-Out mode is entered automatically from
the self-test mode.
Action enter
SemanticGroups Motive
Location Cut-Out Mode
InitialLocation Self Test Mode
A2: The VehicleGuard DOH System shall be forced
into cut-out mode by selecting the cut-out mode set-
ting on the sealed mode switch on the OBM unit.
Action force
SemanticGroups Permissive
Themes VehicleGuard DOH System
Location Cut-Out Mode
In this example, the semantic groups are Motive andPer-
missive ;location properties are an exact match, and as the
theme property is present on only one side, it is ignored. A
link is therefore created.
Our current knowledge base includes 33 link heuristics, each
of which is summarized in Figure 4.
6. ONTOLOGY
Both the action units and link heuristics are supported
by an underlying ontology. Without the ontology we would
be unable to understand conceptual relationships between
dierent terms and would therefore be constrained by the
same problems as more basic term-matching approaches.
A knowledge base is an information repository used to
collect, organize, and search data [16, 29]. Many KBs are
built in a manner that supports automated deductive rea-
soning. Such KBs are composed of a set of data that includes
basic terms that dene the vocabulary of the domain, and
a set of sentences that describe the relationships between
those terms. The data is often represented in the form of
an ontology in which knowledge is constructed using logi-
cal operators such as AND and OR, as well as implication
and negation operators to build complex ideas from more
primitive concepts [16].
Our KB performs two primary functions for tracing pur-
poses: using the knowledge in the KB to compare two arti-
facts and mapping elements of software artifacts to concepts
in the ontology. We also store syntactic group information
and semantic group information in the knowledge base so
that given a verb, we can determine which groups it belongs
to.
The DoCIT KB was created using OWL 2 Web Ontology
Language, a formally dened ontology language developed
by W3C for the Semantic Web [2]. OWL 2 is capable of rep-
resenting complex knowledge about things, groups of things,
and relationships between those things. OWL 2 ontologies
provide classes, properties, individuals, and data values, all
759Semantic Groups  
 Agent  
 Theme  
 Recipient  
 Instrument  
 Location  
 Init Loc. 
 Agent1/Recip.2 
 Recip.1/Agent2 
 Instrum.1/Theme2 
 Init Loc.1/Loc.2 
 Loc.1/Theme2 
 Agent1/Theme2 
Basic (Groups must match)  ÔÇã ÔÇå ÔÇã ÔÇã  ÔÇå ÔÇã             
Affirmative- Inclusive  ÔÇã ÔÇç             
Calculative -Inclusive  ÔÇã ÔÇç                     
Descriptive -Transmissive    ÔÇç                     
Enforcive -Calculative (1)  ÔÇç               ÔÇç       
Enforcive -Calculative (2)  ÔÇã ÔÇç ÔÇã ÔÇã ÔÇã 
Enforcive -Enforcive  ÔÇç               ÔÇç       
Enforcive -Receptive    ÔÇç         ÔÇã           
Enforcive -Regulative (1)  ÔÇå                   ÔÇç   
Enforcive -Regulative (2)  ÔÇã ÔÇç   
Inceptive -Inceptive  ÔÇã ÔÇç   ÔÇã ÔÇã               
Inceptive -Receptive    ÔÇç         ÔÇã           
Inceptive -Transgressive  (1)   ÔÇç     ÔÇé               
Inceptive -Transgressive  (2)         ÔÇé             ÔÇç 
Inspective -Respective            ÔÇã    ÔÇç        
Motive -Motive          ÔÇé               
Necessitative -Receptive              ÔÇã   ÔÇç       
Permissive -Motive    ÔÇã     ÔÇé               
Permissive -Permissive          ÔÇé               
Preservative -Inceptive  ÔÇç ÔÇç                     
Preservative -Preservative  ÔÇã ÔÇç ÔÇã ÔÇã ÔÇã ÔÇã             
Receptive -Receptive    ÔÇç           ÔÇé         
Receptive -Transmissive  (1)   ÔÇç         ÔÇé           
Receptive -Transmissive  (2) ÔÇã ÔÇç ÔÇã ÔÇã ÔÇã 
Regulative -Inclusive  ÔÇã ÔÇé ÔÇã ÔÇã ÔÇã               
Regulative -Transmissive    ÔÇç         ÔÇå           
Transgressive -Motive    ÔÇã     ÔÇç               
Transgressive -Permissive          ÔÇé               
Transmissive -Administrative    ÔÇã         ÔÇç           
Transmissive -Enforcive    ÔÇã         ÔÇç           
Transmissive -Inceptive  ÔÇç ÔÇç                     
Transmissive -Permissive    ÔÇç           ÔÇé         
Transmissive -Transmissive  ÔÇã ÔÇç                     
ÔÇã = If both elements are present, they must match  (exact or hierarchical).  
ÔÇå = If one element is present, the other must also be, & match (exact or hier.) 
ÔÇç = Both elements must be present and must match  (exact or hierarchical)  
ÔÇé = Both elements must be present  and must exhibit an exact match.  Figure 4: Trace Link Heuristics specied in terms
of semantic pairs and required matches.
of which are stored as Semantic Web documents. We cre-
ated our initial KB using Prot eg e, an open source ontology
editor [31], and saved it in an OWL (.owl) format for use
during the tracing process.
6.1 Knowledge Structure
The KB contains general concepts, which are expected
to be reusable across multiple domains, and also domain-
specic knowledge which is designed solely for use in a spe-
cic regulatory domain, e.g., communications and control
for the transportation sector of our case study.
The general section of our KB includes facts about verbs
and verbs used as nouns , such as reception orintegration .
These are represented as individual elements in the ontol-
ogy. Every identied verb belongs to one or more semantic
groups representing its functionality. For example, the verb
enter is used in two functionally distinct ways across the set
of observed artifacts: rst, as in \The system should enter
the Failure Mode when a vital error occurs" (the Motivegroup), and second, as in \The driver should be able to en-
ter the current date into the system from the HMI" (the
Transmissive group).
Each verb is also categorized under one or more syntactic
groups based on how it interacts with the surrounding noun
phrases. Reexamining the previous example, we see that
theFailure Mode is a location that the system should enter ,
while the current date is something the driver should enter ,
which gets received by the system . Despite having similar
syntactic distributions, the arguments of enter in each case
play dierent roles in determining the main function con-
tained in each sentence.
The second part of the ontology describes domain-specic
taxonomic relations between objects, such as names of sys-
tems, subsystems, operating modes, and message types used
by components of the system.
6.2 Querying the KB
For an ontology to be useful, it needs to provide a mech-
anism for supporting queries and returning relevant infor-
mation. The DoCIT ontology therefore provides a query
function which can accept either a single term or a noun
phrase and return a set of related concepts as well as a set
of relations. For example, if we issue a simple query for the
term update, the KB returns the information that update is
an action and belongs to the regulative semantic group and
syntactic group # 3 (as syntactic groups are labeled by ID
only).
Similarly, a query issued for the noun phrase Power-On
Self Test returns a rich set of hierarchically related terms,
among other things, specifying that the Power-On Self Test
is a kind of relay test, which in turn is a kind of self-diagnostic
test. This information is critical for enabling traceability
between artifacts which may use dierent terms that are
related through a hierarchy of concepts.
7. DoCIT IN PRACTICE
Deploying DoCIT required construction of the knowledge
base and development of a functioning prototype.
7.1 Building a Knowledge Base
Our current version of DoCIT requires the presence of a
knowledge base composed of action units, link heuristics,
and a domain ontology. In this section, we describe the sys-
tematic approach we followed to build the knowledge base
needed to support automated trace link generation in our
domain of study. We worked closely with a domain expert
from our collaborating industry to ensure that our reasoning,
and the subsequent results, were well-founded. Articulating
these steps is an important precursor towards complete au-
tomation of ontology building for tracing in a given software
engineering domain.
Step 1. Create Syntactic and Semantic Groups:
The Stanford parser was used to identify verbs and verbs
represented as nouns. For each identied verb we manually
checked whether an appropriate syntactic group and seman-
tic group existed. To identify relevant syntactic groups we
asked, \Is there an existing syntactic group which contains
verbs conveying similar behavior?" To identify relevant se-
mantic groups we asked,\Is there an existing semantic group
which contains verbs conveying similar meaning?" If not, we
created a new syntactic and/or semantic action group.
760Step 2. Create Action Unit Construction Rules:
For each new syntactic group, we created a set of action unit
construction rules. These rules specify the relevant proper-
ties (i.e. thematic roles such as location, agent, etc.) and
the appropriate dependent POS which should, if present, be
associated with the property.
Let us assume that no existing syntactic group exists for
the verb send. First, we run the Stanford parser to iden-
tify verbs and their dependencies. We then inject a human
reasoning step. For example, we might determine that the
action \send" requires a direct object, i.e. \send what?" Fur-
thermore, this direct object is generally an entity that is
moved by the action. We therefore add \theme" as a prop-
erty to the action unit and specify that the direct object
serves this role. A similar process is used to add other rele-
vant properties and their associated parts-of-speech.
Step 3. Create Link Heuristics: Link heuristics are
built around pairs of semantic groups. The occurrence of
a previously unseen pair of semantic groups will trigger the
need for a new link heuristic to be created through analyz-
ing the likely thought process of a human analyst. First we
determine the rationale for the link, and secondly we for-
mulate this in terms of the thematic roles. We frequently
engaged our industrial collaborator in this process so that
he could conrm or refute our rationales for each link.
It is worth noting that our current implementation takes
a rather greedy approach to constructing the various rules,
heuristics, and concepts. Each of these elements is added to
the knowledge base if it benets the currently evaluated ar-
tifact and/or trace link. While, we considered implementing
a \do no harm" policy, i.e. not adding new information if it
harmed previous trace links, we rejected this idea in favor of
a more global optimization to be explored in future work.
7.2 Integration with Term-based Approach
As previously explained, we implemented DoCIT in con-
junction with the Vector Space Model (VSM) [14].
7.2.1 Vector Space Model
The VSM algorithm computes similarity between two doc-
uments. Each query and each document is represented as
a term vector dened in the space of all terms found in
the set of queries T = t1; t2; ::::; t n. More formally, a docu-
ment dis represented as a vector ~d= (w 1;d; w2;d; :::; w n;d),
where wi;drepresents the term weight associated with term
ifor document d. A query is similarly represented as ~ q=
(w1;q; w2;q; ::::; w n;q). Each term tis assigned a weight using
a standard weighting scheme known as tf id f[15], where tf
represents the term frequency, and id fthe inverse document
frequency.
Term frequency with respect to document dis often com-
puted as tf(ti; d) = ( freq(ti; d))=(jdj), where freq(ti; d) is
the frequency of the term in the document, and jdjis the
length of the document. Inverse document frequency id f, is
usually computed as id fti=log2(n=n i) where nis the to-
tal number of documents in the traceable collection, and ni
is the number of documents in which term tioccurs. The
individual term weight for term iin document dis then
computed as wid=tf(ti; d)id fti.
A similarity score sim(d; q ) is computed between docu-
ment dand query qas follows:sim(d; q ) =(Pn
i=1wi;dwi;q)pPn
i=1wi;dpPn
i=1wi;q (1)
Any query-document pair receiving a similarity score over
a threshold value is treated as a candidate traceability link.
7.2.2 Merging Results
To use VSM in conjunction with DoCIT, the DoCIT ap-
proach is rst applied to the source and target artifacts to
produce a list of candidate links referred to from now on as
candidate DoCIT-links. VSM is then applied to the same
source and target artifacts to produce a ranked list of can-
didate VSM-links.DoCIT tends to produce fewer, but more
accurate links than VSM. Therefore, a merged list of can-
didate links is created by placing DoCIT links at the top of
the list ordered according to their VSM rankings, and then
adding all remaining VSM-Links in their original order to
the bottom of the merged list.
7.2.3 Learning New Facts and Rules
The process of discovering and specifying link heuristics is
ongoing, and therefore any knowledge base needs the ability
to grow and expand over time as new information, acronyms,
or sentence structures are seen for the rst time. We there-
fore developed a GUI tool which incrementally displays links
which were missed by DoCIT but ranked highly by VSM.
These links provide an ideal opportunity for eliciting knowl-
edge from the domain expert who is performing the tracing
task. The source and target artifacts of the link are parsed
and action units are displayed. The tool then provides a
GUI to help the user to construct new link heuristics.
8. EV ALUATION
To evaluate DoCIT's ability to support trace link gener-
ation we designed and executed four dierent experiments
labeled E1 to E4. The rst evaluated DoCIT's ability to
correctly identify and retrieve action units from both the
SRS and SDD datasets. The second and third experiments
evaluated DoCIT's ability to generate trace links correctly
with varying degrees of support from the knowledge base,
and nally the fourth one analyzed the ecacy of the link
heuristics. An alpha level of 0.05 was used for all statistical
tests.
8.1 E1: Action Unit Extraction
Our DoCIT solution is intended to work in complex soft-
ware systems with real requirements. The rst experiment
was therefore designed to address the research question (RQ
1:)\Can DoCIT extract action units correctly and consis-
tently from complex industrial requirements?"
0510152025303540
Correct Parser Error Complex Sentence Missing VerbAction Units per Category  SDD
SRS
Figure 5: Analysis of Generated Action Units
7618.1.1 Experimental Design
To answer this question we used DoCIT to extract action
units from 20 randomly selected SRS artifacts and 20 ran-
domly selected SDD artifacts. Each action unit was then
evaluated by two researchers in our team. Action units that
were correctly extracted according to the denitions in the
action unit were classied as Correctly parsed . In ad-
dition, when the mapping was not successful, we classied
the failure causes into the following three categories: (1)
Parser errors i.e. the parser generated an incorrect tree
structure or incorrectly assigned part-of-speech tags and as
a result the retrieved action unit was incorrect, (2) Convo-
luted sentence i.e. the sentence was very confusing and
produced multiple action units. As a result each action unit
was too sparse to support eective link creation. An exam-
ple of a convoluted sentence is \The system should provide
the functionality by which the subsystem under its control
can perform.....", (3) Missing verb i.e. a verb identied
by the parser cannot be found in the set of verb syntactic
groups.
8.1.2 Results and Analysis
Results are reported in Figure 5. The SDD sample pro-
duced 51 action units, while the SRS dataset produced 35,
reecting the fact that SDD artifacts in this dataset tend to
contain longer, more complex descriptions than SRS ones.
Of the 51 SDD action units, 39 were correct, 8 failed due
to parser errors, 3 due to convoluted sentences, and 1 due to
incomplete verb knowledge in the knowledge base. Of the
35 SRS action units, 34 were correct and the single failure
was due to a parser error. Action units were constructed for
each identied verb, and no missing ones were observed.
These results show that DoCIT was able to correctly ex-
tract 76.5% of the action units from SDD and 97% from
SRS. The main cause of failure in both cases was parser er-
rors, which can be addressed in future work through adding
additional pattern matching rules to the knowledge base.
8.2 E2: When the KB is Relatively Complete
The second experiment evaluated DoCIT's ability to gen-
erate trace links when the knowledge base was customized
for the dataset. This represents an ideal scenario in which
the knowledge base provides relatively complete coverage of
the concepts in a dataset. We addressed the research ques-
tion(RQ 2:) \Given a relatively complete knowledge base
can DoCIT return an accurate set of trace links?"
8.2.1 Metrics
Results were evaluated using three standard metrics. Re-
call measures the fraction of relevant links that are retrieved
while precision measures the fraction of retrieved links that
are relevant. A third metric, Mean Average Precision (MAP),
measures the extent to which correct lists are returned at the
top of a ranked list. MAP requires an ordered ranking of the
links and so is only reported for results that include VSM.
As our implementation of MAP examines all correct links
it achieves recall of 1.0. The use of MAP as a traceability
measure has been advocated in numerous papers [32].
First, the average precision (AP) of each correct link is
computed as follows:
AP=PN
r=1(Precision (r)isRelevant(r ))
jRelevantDocuments j(2)
E2: SRS1-SDD E3: SRS2-SDD E3: SSRS-SDD
VSM Only 0.590 0.560 0.550
VSM+DoCIT 0.822 0.667 0.7090.00.20.40.60.81.0Mean Average Precision  Figure 6: MAP by query and link for each of the
three datasets in Experiments 2 and 3.
00.10.20.30.40.50.60.70.80.91
0 0.2 0.4 0.6 0.8 1Recall  
Precision  VSM Only
VSM+DoCITWhen using 
VSM+DoCIT, the DoCIT -alone 
recall of 0.774  serves as a lower  
bound on achievable recall.  
Figure 7: Precision versus recall for Experiment #1
where ris the rank of the target artifact in an ordered list of
links, isRelevant () is a binary function assigned 1 if the link
is relevant (i.e. marked as correct in the reference set) and
0 otherwise, P(r) is the precision computed after truncating
the list immediately below that ranked position, and Nis
the total number of documents. We compute MAP scores
at recall values of 1.00 across all queries as follows:
MAP @recall=1:00 =PQ
q=1AP(q)
Q(3)
where, qis a single query and Qis the total number of
queries. Please note that all subsequent references to MAP
imply scores at 100% recall.
8.2.2 Experimental Design
For this experiment we randomly selected 31 SRS artifacts
and the complete set of SDDs with links from any SRS arti-
fact. This resulted in 241 SDD artifacts, producing a total of
7,471 potential links. Of these 205 were included in the trace
matrix created and provided by our industrial collaborators.
We refer to this subset of the dataset as SRS1 .
Starting with the initial knowledge base, two researchers
on the team systematically evaluated the 205 trace links, and
following the greedy process prescribed in Section 7.1, sys-
tematically added additional concepts to the knowledge base
and created new link heuristics. Once each link had been ex-
762amined and the knowledge base expanded, trace links were
generated for the 31 SRS using both VSM and DoCIT.
8.2.3 Results
MAP scores are reported in Figure 6 and show that VSM
alone returned a MAP of 0.59 compared to 0.82 when used
in conjunction with DoCIT. A Wilcoxon Signed Rank test
showed a signicant dierence when the VSM MAP score
was compared against VSM+Docit MAP scores for each
query at p<0.001. Figure 7 reports precision at various
recall levels and also shows a marked improvement in ac-
curacy when VSM+DoCIT is used instead of just VSM. For
example, at recall levels of approximately 0.80, VSM returns
precision of only 0.17 compared to 0.71 for VSM+DoCIT.
This is a non-trivial improvement in accuracy and supports
our overall conjecture that a more intelligent domain-specic
system has the ability to far outperform a term-based ap-
proach such as VSM. We chose to not compare our approach
against alternate ontology-based tracing techniques as pub-
lished results have shown inconsistent improvements over
VSM [20].
8.2.4 Towards Even Greater Accuracy
Our goal is for DoCIT to ultimately achieve MAP scores
close to 1.00 (i.e. to place all of the correct links close to the
top of a ranked list) when the underlying knowledge base
is complete. However, while DoCIT signicantly improves
MAP and precision, there is still room for improvement.
We therefore analyzed both false positives and false nega-
tives and make the following observations listed in order of
their impact: (1) Errors of commission (i.e. false positives)
were primarily caused by the fact that DoCIT generates a
link if even one pair of action units are related by the link
heuristics. This approach fails to lter out links that should
have been rejected when leading or trailing conditions do
not match. (2) Errors in omission (i.e. false negatives) were
primarily caused by incomplete knowledge in the knowledge
base. (3) A few errors were caused by parsing mistakes as
previously discussed in Section 8.1. All three error types will
be addressed in the next phases of our work.
8.3 E3: When the KB is Incomplete
Software projects are rarely static. New artifact types
are added, and new domain concepts including syntactic
and semantic verb groups may be introduced as the project
evolves. As a result we can never expect, and certainly not
guarantee, a complete knowledge base. This introduces the
research question (RQ3:) \When a knowledge base is in-
complete does DoCIT still improve trace accuracy?"
8.3.1 Experimental Design
We conducted an experiment against two dierent datasets
for which the KB provided only partial coverage.
For the rst dataset we randomly selected 31 dierent SRS
artifacts (i.e. not ones used in the previous experiment) and
the same complete set of 241 SDDs. This produced a total
of 7,471 potential links of which 157 were marked as correct
by our industrial collaborators. We refer to this subset of
the dataset as SRS2 . Because the initial KB was constructed
through examining a dierent subset of SRS-SDD trace links
(i.e. SRS1), we would expect partial knowledge coverage of
concepts in SRS2 in the KB.
00.10.20.30.40.50.60.70.80.91
0 0.2 0.4 0.6 0.8 1Recall 
Precision  VSM Only
VSM+DoCIT
00.10.20.30.40.50.60.70.80.91
0 0.2 0.4 0.6 0.8Recall 
Precision  VSM Only
VSM+DoCITSRS2 -SSD SSRS- SSD Figure 8: Incomplete knowledge for Experiment #3.
For the second dataset we selected 10 SSRS artifacts and
traced them to the same 241 SDDs. SSRS represented a
completely new type of artifact from the transportation dataset
that had not been previously been used to build the Knowl-
edge Base. There were a total of 21 correct trace links out of
the potential set of 2,410. We refer to this dataset as SSRS.
As SSRS represents an entirely new artifact type that was
not used in the KB construction, we expect less knowledge
coverage than for SRS2.
The tracing experiment was conducted in the same way
as the previous one, with the important dierence that no
new information was added to the knowledge base. Traces
were generated based purely upon previously dened facts
in the knowledge base.
8.3.2 Results and Analysis
Results are also reported in Figure 6. In the case of SRS2,
MAP increased from 0.560 to 0.667 and for SSRS it increased
from 0.550 to 0.709. Results for SSRS were better than we
had anticipated because DoCIT improved ve of the ten
queries, and in three of these cases returned perfect MAP
scores. A Wilcoxon Signed Rank test showed a signicant
dierence for SRS2 at p=0.013, but did not show signicance
for SSRS at p=0.056. Improvements in precision vs. recall
were not as marked as the improvements for SRS1, however,
as depicted in Figure 8. At xed recall values precision was
markedly higher for VSM+DoCIT than for DoCIT alone
in both datasets. We therefore conclude that even though
DoCIT's knowledge base was incomplete with respect to the
two datasets, the quality of the links still showed marked
improvements.
8.4 E4: Greedy Link Heuristic Construction
Given our greedy approach to the construction of link
heuristics, we explored the research question (RQ4:) \Are
all existing link heuristics globally eective?". To answer
this question we simply counted the number of times each
heuristic was applied for datasets SRS1 and SRS2, versus
the number of times it resulted in a correct link.
Results show that 51% produced correct links with 100%
accuracy, an additional 35% produced correct links with at
least 70% accuracy, and the remaining 14% produced correct
links with at least 33% accuracy. Even in the worst case of
33% accuracy, they tend to outperform the accuracy of term-
based retrieval approaches. Nevertheless this needs further
investigation and global optimization will be addressed in
future work.
7639. THREATS TO V ALIDITY
Our results show that integrating DoCIT with VSM led
to signicant improvements in accuracy of the generated
trace links, especially when an adequate knowledge base was
present. Construct validity threats were primarily addressed
through using utilizing metrics broadly accepted to dieren-
tiate between high and low quality links [14]. The generated
links were compared against a golden-answer set provided by
our industrial collaborators. In cases where additional links
were identied as potentially valid, they were reviewed by
the industrial collaborators, and when deemed correct, were
added to the answer set. Nevertheless, it is possible that
additional correct links exist but were not found. Similarly
internal validity was addressed through conducting a con-
trolled experiment to compare results obtained using VSM
alone versus VSM plus DoCIT.
The major threat of our study focuses around external va-
lidity which speaks to the generalizability of the approach.
Our end goal is to build an intelligent traceability system
that can be reused across a very narrow set of systems in
the same regulatory domain. However, given the signicant
time and eort it took to obtain the datasets, to compare
alternate techniques and ultimately develop a solution based
on action units and link heuristics, to build a domain ontol-
ogy, and then to carefully validate results, we only able to
conduct our study for a single project in a highly focused
domain. The two primary threats to generalizability are
(1) whether our action unit extractor will work on a variety
of artifacts and styles, across other projects, and in other
domains, and (2) whether the link heuristics can be gener-
alize across other projects. On the other hand, we do not
yet claim generalizability. The goal of this research was to
demonstrate that an intelligent traceability solution could
signicantly improve trace results in a case project. We
leave the task of generalizability to future work.
10. RELATED WORK
Related work falls under two major categories of trans-
forming unstructured text into formal specications and use
of ontology to support the tracing process.
Breaux, Anton, et al. have developed techniques for trans-
forming natural language text into formal or semi-formal
representations [9, 24]. Their focus has been on the areas of
security, privacy [9], and accessibility [8] and has emphasized
elements such as rights ,obligations , and permissions . Their
work evaluated compliance of industrial requirements to ac-
cessibility standards by extracting requirements from the
standards using an approach they refer to as the frame-based
method, and then performing a gap analysis between the two
sets of requirements [8]. While they have made some at-
tempts to automate the extraction of various elements from
text, their approach is primarily manual in nature, and does
not address the issues of automating the traceability process.
Spanoudakis et al. [30] developed a rule-based approach for
generating traceability relations between artifacts; however
their rules were primarily syntactical in nature and did not
attempt the kind of semantic analysis used by DoCIT.
Several researchers have previously explored the use of
ontology for tracing purposes. Kof et al. [18] extracted
domain-specic concepts from the set of traceable artifacts,
and then used WordNet to nd synonyms in order to map
similar concepts and to establish trace links [18]; howeverthey did not provide a rigorous analysis to evaluate whether
the use of the ontology actually improves the quality of the
generated trace links. Li et al. also explored the use of an
ontology for traceability purposes [20]. Their approach used
knowledge from the ontology to establish connections be-
tween concepts in source and target artifacts. The strength
of the dependency was related to the distance between con-
cepts in the ontology, and the overall similarity score be-
tween pairs of artifacts was increased accordingly. Both
Kof and Li therefore used ontology to augment the basic
approach that computes the similarity between two arti-
facts based on the similarity of their terms. However, un-
like DoCIT, their approach did not attempt to establish
semantically-aware link heuristics.
Existing tracing tools such as Poirot [21] include capabil-
ities to expand acronyms and utilize lists of matching words
in an attempt to bridge the semantic gap. However, they
fail to capture the rich set of relationships and inference
rules that can be modeled in an expert system. Zhang et
al. published a paper entitled \Ontological approach for the
semantic recovery of trace links between software artefacts"
[33]; however the ontology is used only to represent con-
cepts such as design patterns ,sentences ,paragraphs , and
classes , as opposed to domain concepts such as vehicle or
signal found in the domain being traced. Assawamekin et
al. utilized Natural Language Processing techniques to con-
struct separate ontologies to represent dierent stakeholder
perspectives and then to discover mappings between them
[4]. The ontology is expressed in rst-order logic and the
mapping is solved by a SAT-solver. However the authors
provided only a simple example, and did not empirically
evaluate their approach.
Ontologies have been used in the requirements domain for
several dierent purposes, and several techniques therefore
exist for extracting an ontology from a requirements speci-
cations [12, 11, 25, 4]. We plan to examine these automated
ontology extracting techniques in our future work.
11. CONCLUSION
The work described in this paper has tackled the signi-
cant challenge of automating the creation of trace links in a
safety-critical, communication and control domain. We suc-
cessfully demonstrated that within a large industrial project,
given a knowledge base with sucient coverage of the con-
cepts, DoCIT was able to signicantly improved the accu-
racy of generated trace links. These results support our
earlier conjecture that intelligent traceability provides a vi-
able approach for overcoming the term-mismatch barrier of
existing tracing techniques and ultimately of delivering auto-
mated tracing techniques that can be eective for industry.
In ongoing work, we are developing techniques for au-
tomating the creation and expansion of a DoCIT knowledge
base for new domains. Our work will focus on discovering
the right semantic and syntactic groupings, correct depen-
dency mappings, new relationships, and appropriate trace
link heuristics in a more dynamic way for a given domain.
We also plan to evaluate the ecacy across multiple domains
in order to demonstrate broader generalizability.
12. ACKNOWLEDGMENTS
The work in this paper was partially funded by the US
National Science Foundation Grant CCF:1319680.
76413. REFERENCES
[1] CoEST: Center of excellence for software traceability,
http://www.CoEST.org.
[2] Owl2 web ontology language primer, June 2013.
[3] G. Antoniol, G. Canfora, G. Casazza, A. De Lucia,
and E. Merlo. Recovering traceability links between
code and documentation. IEEE Trans. Softw. Eng. ,
28(10):970{983, 2002.
[4] N. Assawamekin, T. Sunetnanta, and
C. Pluempitiwiriyawej. Ontology-based
multiperspective requirements traceability framework.
Knowl. Inf. Syst. , 25(3):493{522, 2010.
[5] H. Asuncion and R. N. Taylor. Capturing custom link
semantics among heterogeneous artifacts and tools. In
Traceability in Emerging Forms of Software
Engineering, 2009.
[6] B. Berenbach, D. Gruseman, and J. Cleland-Huang.
Application of just in time tracing to regulatory codes.
InProceedings of the Conference on Systems
Engineering Research , 2010.
[7] E. Bouillon, P. M ader, and I. Philippow. A survey on
usage scenarios for requirements traceability in
practice. In Requirements Engineering: Foundation for
Software Quality , volume 7830 of Lecture Notes in
Computer Science , pages 158{173. Springer, 2013.
[8] T. D. Breaux, A. I. Ant on, K. Boucher, and
M. Dorfman. Legal requirements, compliance and
practice: An industry case study in accessibility. In
RE, pages 43{52, 2008.
[9] T. D. Breaux, A. I. Ant on, and J. Doyle. Semantic
parameterization: A process for modeling domain
descriptions. ACM Trans. Softw. Eng. Methodol. ,
18(2):5:1{5:27, Nov. 2008.
[10] J. Cleland-Huang and J. Guo. Towards more
intelligent trace retrieval algorithms. In (RAISE)
Workshop on Realizing Articial Intelligence Synergies
in Software Engineering, 2014.
[11] R. Gacitua and P. Sawyer. Ensemble methods for
ontology learning - an empirical experiment to
evaluate combinations of concept acquisition
techniques. In ACIS-ICIS, pages 328{333, 2008.
[12] R. Gacitua, P. Sawyer, and P. Rayson. A exible
framework to experiment with ontology learning
techniques. Knowl.-Based Syst. , 21(3):192{199, 2008.
[13] J. Guo, J. Cleland-Huang, and B. Berenbach.
Foundations for an expert system in domain-specic
traceability. In RE, 2013.
[14] J. H. Hayes, A. Dekhtyar, and S. K. Sundaram.
Advancing candidate link generation for requirements
tracing: The study of methods. IEEE Trans. Softw.
Eng., 32(1):4{19, 2006.
[15] J. H. Hayes, A. Dekhtyar, and S. K. Sundaram.
Advancing candidate link generation for requirements
tracing: The study of methods. IEEE Trans. Software
Eng., 32(1):4{19, 2006.
[16] P. Jackson. Introduction To Expert Systems (3 ed.) .
Addison Wesley, 1998.
[17] D. Klein and C. D. Manning. Accurate unlexicalized
parsing. In Proceedings of the 41st Annual Meeting on
Association for Computational Linguistics - Volume 1 ,
ACL '03, pages 423{430, Stroudsburg, PA, USA, 2003.
Association for Computational Linguistics.[18] L. Kof, R. Gacitua, M. Rounceeld, and P. Sawyer.
Concept mapping as a means of requirements tracing.
InMaRK'10) , 2010.
[19] N. G. Leveson. Safeware, System Safety and
Computers . Addison Wesley, 1995.
[20] Y. Li and J. Cleland-Huang. Ontology-based trace
retrieval. In Traceability in Emerging Forms of
Software Engineering (TEFSE2013, San Francisco,
USA, May 2009.
[21] J. Lin, C. C. Lin, J. Cleland-Huang, R. Settimi,
J. Amaya, G. Bedford, B. Berenbach, O. B. Khadra,
C. Duan, and X. Zou. Poirot: A distributed tool
supporting enterprise-wide automated traceability. In
RE, pages 356{357, 2006.
[22] P. M ader, O. Gotel, and I. Philippow. Motivation
matters in the traceability trenches. In Proceedings
17th International Conference on Requirements
Engineering, pages 143{148. IEEE, 2009.
[23] P. M ader, P. L. Jones, Y. Zhang, and
J. Cleland-Huang. Strategic traceability for
safety-critical projects. IEEE Software , 30(3):58{66,
2013.
[24] J. Maxwell and A. Anton. Developing production rule
models to aid in acquiring requirements from legal
texts. In Requirements Engineering Conference, 2009.
RE '09. 17th IEEE International , pages 101{110,
2009.
[25] A. D. Nicola, M. Missiko, and R. Navigli. A software
engineering approach to ontology building. Inf. Syst. ,
34(2):258{275, 2009.
[26] T. Parsons. Thematic relations and arguments.
Linguistic Inquiry , 26(4):635{662, 1995.
[27] P. Rempel, P. M ader, and T. Kuschke. An empirical
study on project-specic traceability strategies. In
21st Intn'l Requirements Engineering Conference
(RE'13) , Rio de Janeiro, Brasil, July 2013.
[28] P. Rempel, P. M ader, T. Kuschke, and
J. Cleland-Huang. Mind the gap: Assessing the
conformance of software traceability to relevant
guidelines. In 36th Intn'l Conf. on Software
Engineering (ICSE) , 2014.
[29] P. Shvaiko and J. Euzenat. Ontology matching: State
of the art and future challenges. IEEE Trans. Knowl.
Data Eng. , 25(1):158{176, 2013.
[30] G. Spanoudakis, A. Zisman, E. P erez-Mi~ nana, and
P. Krause. Rule-based generation of requirements
traceability relations. Journal of Systems and
Software, 72(2):105{127, 2004.
[31] Stanford. Prot eg e: Open source ontology editor, 2013.
[32] S. K. Sundaram, J. H. Hayes, A. Dekhtyar, and E. A.
Holbrook. Assessing traceability of software
engineering artifacts. Requir. Eng. , 15:313{335,
September 2010.
[33] Y. Zhang, R. Witte, J. Rilling, and V. Haarslev.
Ontological approach for the semantic recovery of
traceability links between software artefacts. Software,
IET, 2(3):185 {203, june 2008.
[34] X. Zou, R. Settimi, and J. Cleland-Huang. Improving
automated requirements trace retrieval: a study of
term-based enhancement methods. Empirical Software
Engineering, 15(2):119{146, 2010.
765