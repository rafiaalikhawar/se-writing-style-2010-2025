Change-Point Detection for Black-Box Services
Ilenia Epifani
Politecnico di Milano
Dipartimento di Matematica
Piazza L. da Vinci 32, 20133
Milano, Italy
ilenia.epifani@polimi.itCarlo Ghezzi
Politecnico di Milano
Dipartimento di Elettronica e
Informazione
Piazza L. da Vinci 32, 20133
Milano, Italy
ghezzi@elet.polimi.itGiordano Tamburrelli
Politecnico di Milano
Dipartimento di Elettronica e
Informazione
Piazza L. da Vinci 32, 20133
Milano, Italy
tamburrelli@elet.polimi.it
ABSTRACT
Modern software systems are increasingly built out of ser-
vices that are developed, deployed, and operated by indepen-
dent organizations, which expose them for use by potential
clients. Services may be directly invoked by clients. They
may also be composed by service integrators, who in turn
expose the composite artifact as a new service. Continu-
ous change is typical of this world. Providers may change
services and the deployment infrastructure to meet continu-
ously changing requirements and be more competitive. Clients
may change their operational proles. Changes have a severe
impact on the quality of services.
In this paper we address the problem of identifying changes
concerning the non-functional behavior of software services
managed by external organizations, and consequently con-
sidered as black-box artifacts. We dene the concept of
change-point and provide a statistical technique aimed at
identifying it, given an execution trace produced by client in-
vocations. Change-point detection is key to reasoning about
changes, diagnosing their cause, and suitably reacting to
their occurrence.
Categories and Subject Descriptors
C.4 [Computer Systems Organization ]: Performance
of Systems| Modeling techniques, Performance attributes ;
D.2.4 [ Software Engineering ]: Software/Program Veri-
cation| Reliability
General Terms
Performance, Reliability
1. INTRODUCTION
1.1 The Context
Software design and development radically changed in the
last decade. Software systems were traditionally designed to
operate in a completely known and immutable environment.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
FSE-18, November 7‚Äì11, 2010, Santa Fe, New Mexico, USA.
Copyright 2010 ACM 978-1-60558-791-2/10/11 ...$10.00.Their development was managed by a single coordinating
authority, which was responsible for the overall quality of
the resulting application and had full ownership of the ap-
plication. Every single piece was under its control and full
visibility of the process and product was possible. Whenever
software had to be changed, to improve its quality or to meet
new requirements, a maintenance lifecycle{design, develop-
ment, and deployment of a new version of the system{had
to be planned. This approach led to costly maintenance
activities and an unsatisfactory time-to-market.
Internet, standardization, time-to-market constraints and
other factors shifted software design from this scenario to
theopen world setting [1]. By this we mean that software
systems are increasingly built out of application fragments,
called services , that are developed, deployed, and operated
by independent service providers , who expose their artifacts
through the network for use to potential clients. Services
may be directly invoked by end users to achieve their per-
sonal goals. They may also be composed as a dynamically
adaptable and evolvable aggregate of components to achieve
more complex functionality. This supports the new role of
service integrators , who can then expose integrated artifacts
as new services for potential clients. It is common to refer
to the above scenario as service-oriented computing (SOC).
SOC can bring unprecedented exibility both in the way
software is built and in the way it is structured. Flexibility,
however, also generates potential risks. SOC leads to dier-
ent degrees of ownership, control and visibility of the dier-
ent parts that compose an application. Applications become
reliant on external services that are developed, evolved, and
run by independent organizations.
To guarantee an adequate level of dependability, it is of-
ten assumed that the relationship between a service provider
and a client is regulated by a service-level agreement (SLA).
SLAs dene a contract [23] between the two parties. The
contract denes the obligations of each of them. In partic-
ular, it species the quality of service (QoS) the provider
promises to ensure. SLAs are especially critical in the case
of service integrators. A SLA is subscribed by a service in-
tegrator with each service provider it relies upon. In turn,
a SLA must be subscribed between a service integrator and
its clients concerning the quality of the integrated service.
In this paper, we focus on quantitatively dened, non-
functional quality attributes, such as reliability or perfor-
mance. We also focus on quantitatively dened QoS. Guar-
anteeing and verifying satisfaction of SLAs is especially crit-
ical in an open-world setting. Quality uctuations are in
fact continuous over time, dicult to understand, predict,
227
and control, because of the plethora of dierent and inter-
twined phenomena that may occur in the real world. The
approach we describe here aims at providing support to rea-
soning about changes and diagnosing their causes.
1.2 The Problem and Its Motivations
Our contribution focuses on the problem of change-point
detection for black-box services. We observe services as black
boxes, that is, without accessing their internals, but instead
monitoring and analyzing the data that ow through their
interface. Service internals are in fact normally unaccessible
to clients, and even service providers|who do have access
to them|may nd it useful to be able to analyze services
without accessing the complex internal details of their im-
plementation.
Observations are data streams, collected by probes at the
service interface, which describe the behavior of the service
concerning a specic quality of interest and from a specic
viewpoint. If performance is the quality of interest, obser-
vations may be sequences of timestamped invocations with
the associated response time. If instead reliability is the
quality of interest, they may be sequences of timestamped
invocations with an associated result indicating whether the
invocation was served successfully or not. Furthermore, ob-
servations may express the viewpoint of (and be collected on
behalf of) the client , who monitors the calls issued to exter-
nal services (e.g., see [2] for a monitoring approach). This is
called client-side analysis Alternatively, in server-side anal-
ysis, data are collected by service providers , who monitor
the QoS of the exported service, which may be used concur-
rently by several clients.
More precisely, assume we are interested in reliability, and
suppose it is measured as a service's failure rate. Given a set
of observations in a time interval, our change-point detection
method can detect (1) if a relevant change took place, (2)
the point in time when the change occurred, and (3) the
new value of the failure rate after the change occurred. For
example, consider Figure 1. Suppose that a change-point is
detected at the 12 thobservation of the stream. We can de-
duce that a relevant change in the system occurred at a time
twhich is greater than the the timestamp associated with
the 11thobservation and less than the timestamp associated
with the 12 thobservation.
ChangeService SService S'1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ....InvocationsChangepoint
Figure 1: Change-point example.
Change-point detection may be a useful tool for the client.
If the detected change implies a SLA violation, the exact
knowledge of when the change occurred may be used as a
proof of evidence in a dispute with the provider. Detected
change(s) may also suggest re-binding to a dierent provider,
who may provide a better service [17]. Change-point detec-
tion may also be a useful tool for the provider. The provider,
in fact, may trace back from the point in time when an un-
expected change in quality occurred to the actions that mayhave caused that change. By reasoning about the change-
point, one might point to the installation of a new library
component, which substituted a previously installed compo-
nent and may be responsible for the unexpected change. An
important special case is when the client is a service inte-
grator, who oers an added value service to its clients by
aggregating existing third-party services. In this case, the
detected change-points and (following the previous exam-
ple) the updated value of reliability of third-party services
may be used to compute an updated value of reliability for
the composite service, to assess whether this jeopardizes its
ability to satisfy the contracts with clients. This kind of
analysis may be performed as discussed in [9].
This paper focuses on change-point detection , i.e., on iden-
tifying when a potential problem occurred. Understanding
its originating cause and planning for reactions which might
behave as remedies are outside its scope, and will be the
goal of further investigations. Our main contributions are
the denition of the concept of change-point, the illustration
of its relevance in service-oriented systems, and the devel-
opment of a statistical framework supporting change-point
detection. We also provide an initial assessment of its eec-
tiveness and limitations by numerical simulations.
The remainder of the paper is organized as follows: Sec-
tion 2 illustrates the case study in which we apply our ap-
proach. Section 3 provides a detailed description of the pro-
posed approach. Section 4 illustrates the simulations which
validate the proposed approach. Finally, Section 5 discusses
related work and Section 6 concludes the paper describing
the current limitations of our approach and future work.
2. A RUNNING EXAMPLE
Let us consider a service for image editing, called Image-
Modder , which provides a set of APIs to manipulate, trans-
form, and save images in dierent formats. ImageModder
represents a real-world case study1. It supports a wide range
of applications, such as: (1) healthcare applications{which
usually require sophisticated image enhanchement techniques
for diagnosis purposes{or (2) web applications that oer
on-line photo editing. The actual implementation of Im-
ageModder resides on a server and interaction with clients
is performed through a publicly available Web service or
through a downloadable software component in charge of
masking the remote interaction with the server. The API
provided by ImageModder comprises the primitives listed in
Table 1. A complete documentation of the API is beyond
the scope of this paper. Due to the lack of space we fo-
cus on the description of the essential concepts needed to
understand the basic features of ImageModder.
Clients must rst authenticate. If authentication suc-
ceeds, clients can upload and modify images in an virtual le
system organized in folders. Initially, clients must: (1) set
their working folder (potentially creating a new one) and (2)
set their current image (potentially importing a new one).
Afterwards, Imagemodder is ready to work. Each opera-
tion invoked by clients directly aects the working folder
or the current image. Image transformations are performed
through the application of lters . A lter is a transforma-
1ImageModder was inspired by the API provided by an ex-
isting on-line application: Picnik [24] currently adopted by
several clients (e.g., Flickr [10]) to support photo editing of
user generated content.
228Table 1: ImageModder API.
Type Name Description Parameters
General login Authenticates the user and opens a session Username and Password
General logout Closes the current session N/A
Folder createFolder Creates a new folder in the current one The name of the folder
Folder setCurrentFolder Sets the current folder The absolute path of the folder
Folder renameCurrentFolder Renames the current folder The new name of the folder
Image import Loads a le in the current folder The le to be uploaded
Image export Returns the current image N/A
Image setCurrentImage Selects the current image The absolute path of the image
Image renameCurrentImage Renames the current image The new name of the image
Image filter Applies the lter to the current image The lter name
Image delete Deletes the current image N/A
Image save Saves the current image N/A
tion that modies the current image (e.g., histogram equal-
ization, gamma correction, etc.). Finally, users can save or
export their modied image. ImageModder oers to clients
up-to-date image processing techniques; the library of exist-
ing lters is constantly maintained and updated.
Application developers who need image editing features
may exploit ImageModder instead of developing in-house
equivalent techniques. Relying on a third-party service, how-
ever, may cause the problems we described in Section 1. The
behavior of a service may change over time, possibly inval-
idating the assumptions made when that was chosen. We
show how change-point detection can be used by a client
to identify changes in the non-functional qualities of Image-
Modder and estimate the new values. The updated esti-
mates may be used by ImageModder clients to decide if the
new behavior is compliant with their requirements or if it is
necessary to re-bind their system to another service provider
or promote an in-house development of these features.
3. CHANGE-POINT DETECTION
As we said in Section 1, our approach focuses on identi-
fying changes in non-functional behavior of black-box ser-
vices given run-rime data extracted by running instances of
systems that exploit such services. We consider (1) reliabil-
ity, expressed as probability of failure and (2) performance
expressed as response-time distribution. The proposed ap-
proach exploits models to represent the non-functional be-
havior of the component under analysis. In particular we
adopt Discrete Time Markov Chains (DTMCs). Section
3.1 introduces DTMCs and Section 3.2 describes how these
models are used to detect change points of software services.
3.1 Discrete Time Markov Chains
DTMCs are stochastic processes with the Markov prop-
erty. They are dened as state-transition systems augmented
with probabilities. States represent possible congurations
of the system. Transitions among states occur at discrete
time and have an associated probability. Formally, a se-
quence of random variables X0;X1;:::is a DTMC with tu-
ple (S;sinit;M) if:
P(X0=sinit) = 1and if the following Markov property holds:
P(Xn+1=s0jXn=s;X 1;:::;Xn 1) =
=P(Xn+1=s0jXn=s) =ms;s0;(1)
where
Sis a nite set of states: S=f1;:::;kg;
sinit2Sis the initial state;
M:SS![0;1] is a transition probability matrix;
its element ms;s0represents the probability of passing
from statesto states0andP
s02Sms;s0= 1.
Markov property (1) means that the probability of going
from statestos0is independent of the past transitions. In
our approach, DTMCs are used to model both probability
of failure and discrete distributions of response time. They
are specied by the set of states Sand the transition proba-
bility matrix Mwhich contains probabilities that represent,
for example, the probability of failure associated with an
operation provided by a service. Equally, DTMCs are rep-
resented by their diagrammatic notation or by transition
probabilities matrices. We will use the former notation for
readability purposes and the latter for the formal descrip-
tion of the statistical technique for change-point detection
in Section 3.3.
3.2 Service Modeling for Change-Point Detec-
tion
Consider a service for which we wish to perform client-side
change-point analysis. Let us rst focus on reliability . As a
rst step, we need to build a DTMC model of the service.
The structure of such model is generated by analyzing: (1)
the service's specication (API, interaction protocol) and
the associated SLA, (2) expected usage prole of service
invocations (i.e., how the client expects or predicts to use
the service). Typically, the DTMC comprises one state for
every operation provided by the service plus a set of auxil-
iary states representing potential failure states. Transitions
describe the possible sequences of service invocations (and
possible failures). They may be annotated with probabilities
representing: (1) probabilities of success or failure, derived
from the SLA or (2) the usage prole. In the case of per-
formance , for each operation exported by the API, we build
an additional DTMC representing the expected discretized
229distribution of its response time. Transition probabilities, as
in the previous model, can be derived from the SLA. Server-
side analysis is similar. The main dierences in the latter
case may be in the level of detail of the models, which may
be more ne-grain, and in the usage proles, which account
for all users accessing the service.
The reliability model derived for ImageModder by analyz-
ing its documentation2, API, and by predicting a possible
usage prole, is shown in Figure 2(a). This model contains:
(1) a state for each operation provided by the ImageModder
component, (2) several auxiliary states, such as the ready
state, which represent the state of the service after the ini-
tialization in which the user sets its current image and work-
ing directory, and (3) several additional states{highlighted
in grey{which represent potential failures associated with
specic operations. In this example, we consider only fail-
ures associated with operations having an explicit access to
repositories (e.g., import ,save, etc.). We also consider a
failure associated with the login operation to model poten-
tial denial of service of the ImageModder component (e.g.,
in case of too many concurrent requests). The DTMC in
Figure 2(a) takes into account the usage prole predicted
by the client; for instance, the probability of creating a new
folder (i.e., the value labeling the transition from state 0
to state 3) instead of selecting a pre-existing folder after the
initial login (i.e., value labeling the transition from state 0 to
state 2). Other probabilities are instead extracted from the
SLA subscribed by the ImageModder provider, such as the
probability of failure associated with the login state. This
probability of failure represents the availability of the ser-
vice, i.e., an information typically declared by on-line service
providers.
Performance models can be derived for ImageModder in
a similar manner. Figure 2(b) shows the DTMC modeling
response time of the save operation (normalized by the size
of the saved image). The number of discretizing intervals
is equal to the number of states reachable from the initial
state. The probability that the response time is in a given
time interval is associated with the transition from the ini-
tial state to the state representing that interval. Notice that
the number of intervals (and hence states) aects the accu-
racy of the model. However, the approach does not directly
depends on the size of the model, but only on the number
of transitions under scrutiny.
Our change-point detection method, as discussed later
in Section 3.3 in detail, uses execution traces collected by
a monitor to gure out whether the actual behavior of a
service complies with a given model and, if not, when the
change occurred and which are the new values that charac-
terize the model after the change occurred. For example,
should the actual performance model of the save operation
change during the utilization of the service with respect to
the model in Figure 2(b), the change-point detection method
would provide: (1) a rened and accurate version of the
model representing the service before the change, (2) a dif-
ferent model representing the service after the change, and
(3) an estimate for the change-point in the trace.
The initial models fed to the change-point detection method
may reect our limited and uncertain a-priori knowledge of
the system. Both usage prole and probabilities of failure
2Due to the lack of space we cannot provide a complete
reference documentation of the service. All the crucial in-
formation information is reported in Section 2.are in fact hard to predict accurately and SLAs may be in-
accurate. As we will see, however, our method is robust : it
works correctly also in the case where the initial model is in-
accurate, since it can derive accurate estimates from actual
observations.
3.3 A Bayesian technique for Change-Point De-
tection
This section illustrates the mathematical background of
our method, which exploits a Bayesian statistical technique
for change-point detection and involves a Monte Carlo inte-
gration method called Gibbs sampling .
We assume that the interaction between a client and the
service is captured by an execution trace . An execution trace
xis a sequence of triplets (r,s,t) , whereris the unique iden-
tier of the operation, sis the time when the invocation is
issued,tis the time when the invocation is completed (if
the invocation succeeds), or the special value FAIL (if the
invocation fails). From an execution trace, we can derive
a reliability trace, used to detect change-points in reliabil-
ity, and performance traces, used to detect change-points
in performance. For simplicity, and space reasons, the way
to derive such traces is only informally described hereafter
through examples.
Areliability trace is obtained by scanning the execution
trace from left to right and mapping it into sequences of
paths on the reliability model, each of which represents an
interaction with the service. For example, the sequence of
paths (0;3;4;0;2;5;7;11;14;11;10;11;19) on the DTMC of
Figure 2(a) represents the sequence of two interactions with
the service. The former tries to create a folder and then fails.
The latter sets the current folder, imports an image, lters,
saves, and logs out. Similarly, a performance trace for an
operationOpis built by projecting the execution trace onto
a sequence of non-failing Opinvocations. The dierence
between the response time and the invocation time for each
Opcall is then mapped onto the corresponding transition on
Op's performance model. For instance in the case of the save
operation the sequence of paths (0 ;1;0;1;0;2;0;3;0;1) rep-
resents the performance trace projected from an execution
trace that contains subsequent calls of the save operation of
duration: (0 :1;0:05;0:3;0:7;0:07). Summing up, each trace
is a stream of sequences{representing paths in their corre-
sponding DTMC{into which we search for change-points.
From a mathematical viewpoint the change-point detec-
tion method works as follows. Given initial distributions
for: (1) two random matrices AandB, which model the
service before and after the change, respectively and (2) a
random point in the trace that identies the change point,
our approach generates updated estimates for A,B, and
exploiting the information provided by the trace x3.
The change-point detection method requires the user to
provide prior knowledge on A,B, and. MatrixAcor-
responds to the DTMC that models the initially expected
behavior of the service (matrix Ain Figure 2(a) if reliability
is our focus). For , we may assume an arbitrary point of
the trace. Finally, for Bone can choose arbitrary values or,
for example, a \pessimistic" version ofA(e.g., where all fail-
ure probabilities are overestimated). As already mentioned,
3The procedure applies identically to performance models
(and performance traces) and to reliability models (and re-
liability traces) since they are both represented in the same
mathematical framework.
2300.13111
1110.020.010.0302setCurrentFolderLogin8setCurrentImage73111518Ô¨Ålter1410
12logout20ready
136
169
deleteexportsave1921renameCurrentFolderrenameImage
150.30.650.0510.960.040.50.50.02import0.98
10.970.980.02110.970.02
0.980.990.120.140.130.110.110.120.141117
createFolder0.98folderSelected4(a) Reliability Model.
0RT<0.2save0.5<RT<0.812340.2<RT<0.5
RT>0.80.20.30.30.2 (b) Performance
Model for the save
operation.
Figure 2: DTMCs for the ImageModder Component.
our method works correctly no matter which initial values
we chose for the statistical procedure of change-point anal-
ysis. Such values are just initial seeds that do not aect its
correctness, but just the size of the trace that must be ana-
lyzed to make the correct prediction. We will give evidence
of this property later in Section 4.
The method assumes the structure of the model to be
immutable and focuses on its parameters, which may change.
Thus the cardinalities of AandBare known, equal, and
correspond to the structure of the model provided initially
by the system designer. In the case of ImageModder, both A
andBare 2222 matrices for the reliability model and 5 5
matrices for the performance model of the save operation
(see Figure 2).
Following a Bayesian approach, we consider A;B; as ran-
dom elements characterized by a prior distribution and we
proceed to updating them by computing the joint posterior
distribution of A,Bandgiven data x:P(A;B;jx), and
the marginal posterior laws: P(Ajx),P(Bjx), andP(jx).
In particular, by exploiting the marginal posterior law P(jx),
we are able to decide, for a given trace x, if a change-point
has taken place in the modeled system and when. For ex-
ample, if the trace length is nandP(=njx)> 100%,
then we are -condent that no change-point is present in
our trace and the modeled system is still regulated by ma-
trixA. In this setting, =n(and= 1) mean no change .
By computing the mean value of the posterior distribution
P(jx) we obtain an estimate of the change-point. In par-
ticular, by estimating the change-point with the posterior
mean we minimize the quadratic Bayesian risk [3].
As for the prior law of A;B; , we assume them to be
statistically independent. Moreover, we choose independent
Dirichlet distributions for each row in AandBand a uni-
form distribution for . Consequently, considering a system
modeled with a DTMC with pstates (i.e., AandBare com-
posed byprows andpcolumns) we have the following prior
probability distribution for A:
P(A) =pY
i=1D(ai;i) (2)
where ai= (ai;1;:::;ai;p) is theithrow ofAandD(ai;i)is a Dirichlet distribution of parameters i= (i;1;:::;i;p)
as follows:
D(ai;i) = (Pp
j=1i;j)Qp
j=1 (i;j)pY
j=1ai;j 1
i;j
For matrix Bwe have a similar formulation:
P(B) =pY
i=1D(bi;i)
where biis theithrow ofBandD(bi;i) is a Dirichlet
distribution of parameters i. Finally, the prior distribution
foris:
P() =1
n;  = 1;2;:::;n (3)
By an appropriate choice of parameters i,i, Dirichlet
distributions capture in a simple and well-established way
the prior knowledge and beliefs regarding the structures of
transitions matrices A;B. There are no alternative multi-
variate distributions that are analytically tractable and have
well known structural properties as Dirichlet distributions.
The likelihood of data xis:
f(xjA;B; ) =pY
i=1pY
j=1aNi;j()
i;jbMi;j()
i;j; (4)
whereNi;j() is the number of transitions in the trace among
stateiand statejuntil the change-point andMi;j() is
the number of transitions from state itojafter. From
Bayes' Theorem we know that:
P(A;B;jx)/f(xjA;B; )P(A)P(B)P() (5)
The desired probability P(jx) can be obtained by integrat-
ing (5) with respect to AandB. This can be extremely
dicult to evaluate analytically or even numerically. Gibbs
sampling4comes into play to solve this issue [5, 6, 15, 27],
since it allows us to extract samples from P(jx), without
4A description of the Gibbs sampling is beyond the scope of
this paper, a brief introduction to this topic can be found in
the Appendix.
231requiring an explicit computation of it, but exploiting the
following marginal conditional distributions:
P(AjB;;x ); P(BjA;;x ); P(jA;B;x )
Let us rst compute P(AjB;;x ). By applying Bayes' The-
orem we obtain:
P(AjB;;x ) =P(A;B;jx)
P(B;jx)=P(A)f(xjA;B; )R
f(xjA;B; )P(dA)(6)
Using the expression of the likelihood given in (4) and the
prior distribution for Agiven in (2), for the numerator in
(6) we obtain:
P(A)f(xjA;B; )/pY
i;j=1ai;j+Ni;j() 1
i;j bMi;j()
i;j
So that:
P(AjB;;x )/pY
i;j=1aNi;j()+i;j 1
i;j
We conclude that, conditionally on andx,AandBare
independent, i.e. P(AjB;;x ) =P(Aj;x), and
P(Aj;x) =pY
i=1D(ai;i+Ni()); (7)
whereNi() is the total number of transitions from iuntil
. Reasoning in the same manner for B, we obtain:
P(BjA;;x ) =P(Bj;x) =pY
i=1D(bi;i+Mi());(8)
whereMi() is the number of transitions from iafter.
Concerning instead , it follows from Bayes' Theorem
that:
P(jA;B;x ) =f(xjA;B; )P()Pn
=1f(xjA;B; )P()
=f(xjA;B; )Pn
=1f(xjA;B; )(9)
where (9) holds if P() is the uniform distribution given in
(3).
By exploiting Equations (7)-(9) and providing starting
values forA,Bandwe can build a Gibbs sequence for
each row of AandBand for:
ak
iD(ai;i;j+Ni;j(k 1))
bk
iD(bi;i;j+Mi;j(k 1))
kP(jAk;Bk;x)
where ak
i,bk
i, andkcorrespond to the kthsample of the
Gibbs sequence. Iterating this sampling process Ntimes,
we obtain a sequence: ( 1;a1
i;b1
i;:::;N;aN
i;bN
i) that con-
verges toP(A;B;jx). In particular for Nlarge enough the
last values m+1;:::;N, wherem<N , can be considered
asN msamples from P(jx) and can be used to estimate .
In the same manner, the sequence ( am+1
i;:::;aN
i)1ipcan
be considered as N msamples from P(Ajx) and
(bm+1
i;:::;bN
i)1ipasN msamples from P(Bjx) used
to estimate AandB, respectively.Table 2: Performance: Discrete Distribution of Re-
sponse Time (RT).
RT Before change-point After change-point
RT < 0:2 0.1 0.4
0:2<RT < 0:5 0.4 0.1
0:5<RT < 0:8 0.4 0.1
RT > 0:8 0.1 0.4
It is important to notice that we conceived an approach
based on the Bayesian estimation theory since simpler ap-
proaches cannot achieve the same level of precision. For ex-
ample, approaches based on rolling averages computed over
the streams of data are dependent on the size of the win-
dow used to compute the average, which is dependent on
the variance of the data (an unknown parameter in our do-
main). Moreover, simpler approaches based on computing
and comparing P(Ajx) againstP(Bjx) are less precise since
they do not provide any estimate for .
4. VALIDATION
A Java implementation of the change-point detection method
presented in this paper has been publicly released5. The
method has been validated by simulation using the Image-
Moder case study. Precisely, we developed a client applica-
tion that invokes the ImageModder service, we collected exe-
cution traces, and we analyzed them. The simulated service
can be instructed to change its behavior, by setting change-
points that aect its performance and/or reliability. In the
real world, the changes may be consequences of software up-
dates. In this section, we describe a signicant subset of the
simulations we performed to validate the approach.
Due to the lack of space, we report on a limited number
of cases and restrict our discussion to only one quality at-
tribute, namely performance of the save operation, which
is modeled by the DTMC in Figure 2(b). In the experi-
ments we describe below, we changed the server's response
time distribution after specic invocations and thus simu-
lating change-points. Afterwards, we ran a program that
implements our change-point analysis approach in dierent
scenarios and with dierent settings as explained hereafter.
The results we report hold for traces of 400 invocations to
thesave operation tracing the response time, normalized by
the size of the saved image. For each case we discuss below,
we ran 1000 simulations. The ndings obtained by focusing
on performance of this operation apply identically to any
other operation and to the reliability model. The interested
reader may repeat our experiments and perform others by
using our downloadable tool.
Single Change-point Detection. We rst report on sim-
ulations which consider a single change-point occurring in
the observation period. As for the Gibbs sampling, we used
the Single Sequence approach and a sequence of length 1000
with a burn-in of length 700. As for prior parameters iand
iof the Dirichlet distribution of AandBwe used, respec-
tively, the DTMC in Figure 2(b) and a DTMC with equally
distributed probabilities attached to all outgoing transitions
from state 0.
5http://home.dei.polimi.it/tamburrelli/changepoint/
232Table 3: Characteristics of Posterior Distribution.
Gibbs Sequence Length Min Median Mean Max Average Error Max Error P(140160jx)
100 141 151 151.8227 162 0.01215141 0.01316296 0.999967
1000 140 151 151.8181 165 0.01212084 0.01540741 0.9999689
!"!#!$"!#%"!#%$"!#&"!#&$"!#'"!#'$"
%&("%'("%)("%$("%*("!"#$%$&'&()*+,%-./01#&-(*+,%-./01#&-(*!#2(/"&#"*3&2("&$45#-*
Figure 3: Average Posterior Distributions of with
change-point at 150.
The latter two choices represent the worst possible sce-
nario in which we have no clue about where the change-point
will potentially take place and which will be the new per-
formance model. Finally, we changed the server's response
time distribution in the 150 thinvocation as shown in Table
2 (i.e., the 150 thinvocation represents the change-point).
By running our change-point analysis method in the afore-
mentioned scenario we obtained the average posterior dis-
tribution for illustrated in Figure 3 over 1000 simulations.
The posterior distribution of is concentrated around 150,
as expected. More precisely, it presents the characteristics
listed in row 2 of Table 3. By synthesizing an estimation for
with the mean value of the posterior distribution, we ob-
tain an average estimate equal to 151 :8181. By computing
the posterior probability P(140160jx), as shown in
last column of Table 3, we are at least 99% condent that a
change-point took place between 140 and 160.
Gibbs Sequence Length. We now report on simulations
concerning the length of the Gibbs sequence. Intuitively, the
longer the sequences are the more precise our distribution
and our estimate will be. As shown in Table 3, sequences of
length equal to 1000 give a very accurate result. However, we
performed the same testbed with shorter sequences to stress
the robustness of the approach (we decreased the number
of samples down to 100). In this extreme case, illustrated
in row 1 of Table 3, the mean value (i.e., the change-point
02004006008000.012120.012140.01216
Sequence LengthAverage Changepoint Estimation Error
Figure 4: Average Estimation Error.
(a) Transition 0-1 of Matrix A.
(b) Transition 0-1 of Matrix B.
Figure 5: Average Posterior Distribution for Tran-
sition 0-1.
estimate) remains close to 150. Generally speaking, the ac-
curacy of estimates begins to decay using sequences shorter
then 400, as shown in Figure 4, where the estimation error
(E) is computed as:
E=jec-rcj
rc(10)
ecbeing the estimated change-point and rcbeing the real
change-point. Notice that the average estimation error with
sequences longer then 400 is always less then 0 :01214. From
Table 3, we can conclude that our approach is quite robust,
since the average and maximum estimation errors are almost
negligible. Finally, the appropriate Gibbs sequence length
can be automatically determined by adopting the Potential
Scale Reduction Factor as described in [16].
Estimates of AandB.The considerations made for the
estimate of holds also for the estimates of AandB. Figure
5(a) shows the histogram of the transition from state 0 to
state 1, with response time <0:2, over 1000 simulations. It
corresponds to the mean value of the posterior distribution
computed exploiting samples in the Gibbs sequence. Notice
how the average estimate is concentrated around the real
value which generated data (i.e., 0 :1). Figure 5(b) shows the
same data obtained for the transition from state 0 to state
1 in matrix B, which is concentrated around the desired
value 0:4. By adopting again the mean value of the posterior
distribution to estimate transition probabilities, we obtain
233an average value of 0 :096 for transition 0  1 before the
change point, with respect to the real value of 0 :1, which
corresponds to an average estimation error equal to 0 :04.
!"!#!$"!#!%"!#!&"!#!'"!#("!#($"!#(%"!#(&"!#('"!#$"
("&"(("(&"$("$&")(")&"!"#$%$&'&()*+,%-./01#&-(*+,%-./01#&-(*!#2(/"&#"*3&2("&$45#-*
Figure 6: Average Posterior Distributions of with
change-point at 5.
Change-point Location. We made experiments to assess
the robustness of the change-point detection method with
respect to the location of the occurrence of the change-point
in the trace. Figure 6 shows the posterior distribution of
when the change described in Table 2 occurs at the 5 th
invocation of the save operation. The distribution is cor-
rectly centered around the expected value of 5 and thus it
is possible to correctly estimate the presence of a change-
point in this position by adopting again the mean value of
the posterior distribution.
No Change-point. Let us now consider the scenario in
which no change-point occurs in the trace; i.e., the service
constantly behaves as described by the second column in Ta-
ble 2. In this setting, by running the change-point detection
we obtained the posterior distribution illustrated in Figure
7. As we said in Section 3.3, =1 or=nindicate that
no change occurred in the trace. Figure 7 shows that the
posterior distribution is centered around the beginning of
the trace, which approximates = 1 and thus indicates no
change.
!"!#!$"!#!%"!#!&"!#!'"!#("!#($"!#(%"
("&"(("(&"$("$&")(")&"!"#$%$&'&()*+,%-./01#&-(*+,%-./01#&-(*!#2(/"&#"*3&2("&$45#-*
Figure 7: Average Posterior Distributions with no
change-point.
Sensitivity to the Initial Model Values. In the previ-
ous experiments, the initial values for matrix Ba DTMC
are equally distributed probabilities attached to all outgo-
ing transitions from state 0, which represent the worst pos-
sible scenario in which we have no clue about which will
be the new performance model. Figure 5(b) shows that the
change-point detection algorithm produces precise estimates
of transitions in matrix Beven though such initial valuesreect inaccurate knowledge. The initial value of matrix A
also does not aect the robustness of the method. In fact, we
rst ran the detection method by initializing matrix Awith
the data of columns 2 in Table 2, which correspond to the
actual initial values of performance of the save operation (a
\perfect knowledge" situation), and then we ran the method
with opposite initial values, i.e. (0 :4;0:1;0:1;0:4). Figure
8 shows the convergence of the Gibbs sequence which esti-
mates transition 0  1 of matrix A. The gure shows that
the convergence proceeds similarly in both cases, except for
initial uctuations in the case of inaccurate initial values.
!"!#$%!"!&%!"!&$%!"'%!"'!$%!"''%!"''$%
'%(%$%)%&%''%'(%'$%')%'&%*'%*(%*$%*)%*&%!"#$%#&'()*%'"+#&'(,-.(/01&*0(23%'40-5&+'6(
7%$580"(!"#$%#&'(9+63(:+;0*0'6(<'+#%8(!"#$%60(+,-./%+012./%3425.6-%7+589-:14-%+012./%3425.6-7%
Figure 8: Estimation of transition 0-1 of matrix A
with dierent initial values.
Multiple Change-points. We performed simulations to
check the behavior of the method if multiple change-points
occur in the observation period. We injected a change-point
at invocations 150 and 250, over the 400 invocations. Figure
9 shows that as a result of simulations, the posterior distri-
bution ofis clearly a bi-modal distribution: each peak in
the distribution indicates a change-point. Once these peaks
are identied, it is possible to divide the trace in two dis-
tinct traces which separate the peaks and, by re-running
the change-point detection, we can reduce the problem to
the case of a single change-point.
!"!#!$"!#!%"!#!&"!#!'"!#!("!#!)"$"$*"&&"'+")(",$"+*"$$&"$%+"$'("$)$"$**"$+&"%!+"%%("%'$"%(*"%*&"%,+"&!("&%$"&&*"&(&"&)+"&,("'!$"!"#$%$&'&()*+,%-./01#&-(*+,%-./01#&-(*!#2(/"&#"*3&2("&$45#-*
Figure 9: Average Posterior Distributions with mul-
tiple change-points.
Performance and Multiple Sequence Gibbs Sampling.
The proposed approach is quite ecient. The computation
of a single Gibbs sequence of length 1000 with a burn-in of
700 requires about 3 :5 seconds to analyze a trace of 400 invo-
cations on a conventional workstation6. Execution time can
be reduced by examining shorter sequences and by applying
the Multiple Sequence variant. It is possible to show (but
6Intel RCore 2 Duo with 4Gb RAM. Implementation in Java
v1.6.
234space reasons do not permit it) that the variant produces
estimates of equal accuracy, but improves time eciency.
For example, the same workstation can execute the paral-
lel computation of two Gibbs sequences of length 500 with a
burn-in of 300 in about 1 :7 second to analyze the same trace
of length 400.
5. RELATED WORK
Change-points are abrupt variations in the generative pa-
rameters of a data stream. Their identication has found
important application in several disciplines, such as nance,
biometrics, and robotics (e.g., see [20] or [28]). In particular
many works in the area of intrusion detection systems aim at
detecting when a change/violation occurs given a trace log
and exploiting bayesian techniques as described for example
in [4]. To the best of our knowledge, no existing work ap-
plied these concepts to software reliability and performance,
and in particular to SOC.
DTMCs and other stochastic models are increasingly used
to assess dependability of software artifacts (e.g., see [19])
and to predict service performance and reliability (e.g., see
[25]). The problem of dealing with changes in the external
services used by a composite service, and adapting the pa-
rameters of its quality model accordingly, is studied in [9,
18]. A framework for component reliability prediction in
presented in [8], whose objective is to construct and solve
a stochastic reliability model, through which software ar-
chitects may explore competing designs. In particular, the
authors tackle the denition of reliability models at archi-
tectural level and the problems related to parameter estima-
tion. Other complementary approaches investigate alterna-
tive methods for calibrating model parameters at run time
in the context of performance models [29].
The problem of quality of service in SOC is studied by
several authors, who focus on how quality can be specied
and how it can be the basis for veriable SLAs. A lan-
guage for SLAs has been proposed by [26]. Other related ar-
eas deal with monitoring and verifying services and service
compositions [2, 13, 14]. Run-time verication is another
closely related research area (for example, see [7]). Sev-
eral approaches have been proposed in literature that deal
with non-functional aspects of services and their composi-
tion. In particular, [22] illustrates a framework for mod-
eling and evaluating service-oriented applications and [21]
describes performance prediction in the SOC domain ex-
ploiting Queuing Networks.
An approach for verifying service compositions starting
from UML descriptions and then transforming them into a
specic representation that allows validation with respect
to concurrency properties is presented in [12]. A similar ap-
proach is described in [11], which shows how to verify service
integrations in case of resource constraints, with respect to
safety and liveness properties.
Concerning the statistical techniques we adopted for change-
point detection, Carlin et al. in [5] provide a hierarchical
Bayesian analysis of change-point problems that inspired our
work and suggested the adoption of Gibbs sampling. In par-
ticular, concerning this integration method, Casella et al. in
[6] provide a complete discussion about its properties by ex-
amples.
Gibbs sequenceBurn-inSamples from f(x,y)(a) Gibbs sampling via single
sequence.
Samples from f(x,y)Gibbs sequenceLast sample............Gibbs sequenceLast sampleGibbs sequenceLast sample(b) Gibbs sampling via mul-
tiple sequences.
Figure 10: Gibbs sampling techniques.
6. CONCLUSION AND FUTURE WORK
In this paper we addressed the problem of identifying
changes concerning the non-functional behavior of software
services managed by third-party entities and considered as
black-box artifacts. We dened the concept of change-point
and provided a statistical technique aimed at identifying
them given an execution trace extracted by running instances
of the system. Change-point detection was performed con-
cerning reliability and performance through the adoption of
DTMCs. We implemented a tool supporting change-point
analysis as part of the KAMI framework{a toolset which is
illustrated in [9, 18]. The tool has been used to validate the
method via simulations. We performed extended simula-
tions, but for space reasons we could only report on selected
cases. For instance, we omitted some interesting results con-
cerning the relation between the length of the trace and the
range of values of probabilities appearing in the models, and
the relation between the length of the trace and the distance
between dierent change-points (in a multiple change-point
setting).
In the future, we plan to complement the simulation-based
validation with analysis of existing on-line services, to obtain
quantitative result in a real-world setting. In addition, we
will investigate how and when change-point detection can
be run to support on-line reactions to detected changes and,
more generally, we will explore the trade-os between on-line
and o-line change detection and their dependence on the
temporal behavior of the application. Further work may also
apply change-point analysis to other models such as Queuing
Networks or continuous Markov chains.
Appendix: Gibbs Sampling
Gibbs sampling is an integration method aimed at com-
puting characteristics (such as the mean or variance) of
the marginal density f(x) of a joint density f(x;y1;:::;ym)
without requiring to actually compute the integral f(x) =R
R
f(x;y1;:::;ym)dy1dy2:::dymwhich can be extremely
dicult to perform analytically or even numerically. In
particular, Gibbs sampling allows for generating a sample
X1;:::;Xnfromf(x), without calculating f(x). This is
because Gibbs sampling works with the (univariate) condi-
tional distributions of every random variable X;Y 1;:::;Ym
given all the other ones: f(xjy1;:::;ym);f(y1jx;y2;:::;ym),
. . . ,f(ymjx;y1;:::;ym 1). To briey illustrate how Gibbs
sampling works, let us consider the simple two-variables case
in which we extract samples from the marginal distribution
f(x) of a joint density f(x;y), by sampling from the uni-
variate conditional densities f(xjy) andf(yjx). The sam-
pler starts with some initial value y0and generates x0by
sampling from f(xjy=y0). Thus the sampler uses x0to
generate a new value y1, drawing from f(yjx=x0). Hence,
235the sampler proceeds as follows:
xif(xjy=yi 1)
yif(yjx=xi)
By iterating this sampling process ktimes, we obtain a Gibbs
sequence of lengthk: (x1;y1);:::; (xk;yk). If we think of
each (xi;yi) as a realization of a random vector ( Xi;Yi),
then, under mild conditions, as k! 1 the distribution
of (Xk;Yk) converges to the joint density f(x;y) (indepen-
dently of the starting value y0) and hence the distribution of
Xkconverges to marginal distribution f(x) (see for example
[27]). Hence, for large enough k, the last values xh+1;:::;xk
(h < k ) of the Gibbs sequence can be considered as k h
samples from f(x). It is important to repeat the sampling
process a sucient number of times to have a large Gibbs
sequence and to ignore (as shown by Figure 10(a)) the initial
samples ( burn-in removal ) which are not distributed accord-
ing tof(x;y) and are inuenced by the starting values. Al-
ternatively, instead of collecting samples from a large enough
Gibbs sequence, Gelfand et al. in [15] suggest the genera-
tion ofmindependent Gibbs sequences of length kand then
using themnal values of these sequences, as shown by
Figure 10(b). The choice of kand alternative approaches
to extracting information from the Gibbs sequence, are dis-
cussed in [6]. A complete description of the Gibbs sampling
is beyond the scope of this paper, further details can be
found in [5, 6, 15, 27]. We explicitly briey introduced and
justied it because it is a crucial component of our solution.
Acknowledgments
This research has been partially funded by the European
Commission, Programme IDEAS-ERC, Project 227977-SMScom.
7. REFERENCES
[1] L. Baresi, E. Di Nitto, and C. Ghezzi. Toward
open-world software: Issue and challenges. Computer ,
39(10):36{43, 2006.
[2] L. Baresi and S. Guinea. Towards Dynamic
Monitoring of WS-BPEL Processes. ICSOC '05 , 2005.
[3] J. O. Berger. Statistical Decision Theory and Bayesian
Analysis . Springer, 2 edition, 1985.
[4] D.J. Burroughs, L.F. Wilson, and G.V. Cybenko.
Analysis of distributed intrusion detection systems
using bayesian methods. Performance, Computing,
and Communications Conference, 2002. 21st IEEE
International , 0:329{334, 2002.
[5] B.P. Carlin, A.E. Gelfand, and A.F.M. Smith.
Hierarchical Bayesian analysis of changepoint
problems. Applied Statistics , pages 389{405, 1992.
[6] G. Casella and E.I. George. Explaining the Gibbs
sampler. American Statistician , pages 167{174, 1992.
[7] F. Chen, T.F. Serbanuta, and G. Rosu. jPredictor: a
predictive runtime analysis tool for java. In ICSE '08 ,
pages 221{230. ACM New York, NY, USA, 2008.
[8] L. Cheung, R. Roshandel, N. Medvidovic, and
L. Golubchik. Early prediction of software component
reliability. In ICSE '08, Leipzig, Germany, May 10-18,
2008, pages 111{120. ACM, 2008.[9] I. Epifani, C. Ghezzi, R. Mirandola, and
G. Tamburrelli. Model evolution by run-time
adaptation. In ICSE '09 , Vancouver, Canada, 2009.
[10] Flickr. http://www.ickr.com/.
[11] H. Foster, W. Emmerich, J. Kramer, J. Magee,
D. Rosenblum, and S. Uchitel. Model checking service
compositions under resource constraints. In
ESEC-FSE '07 , NY, USA, 2007. ACM.
[12] H Foster, S. Uchitel, J. Magee, and J. Kramer.
Model-based verication of web service compositions.
ASE, 0:152, 2003.
[13] X. Fu, T. Bultan, and J. Su. Analysis of interacting
BPEL web services. In WWW , pages 621{630. ACM
New York, NY, USA, 2004.
[14] X. Fu, T. Bultan, and J. Su. Synchronizability of
Conversations among Web Services. IEEE TSE , 2005.
[15] A.E. Gelfand and A.F.M. Smith. Sampling-based
approaches to calculating marginal densities. Journal
of the American Statistical Association , 85(410), 1990.
[16] A. Gelman and D.B. Rubin. Inference from Iterative
Simulation Using Multiple Sequences. Statistical
Science , 7:457{472, 1992.
[17] C. Ghezzi, A. Motta, V. Panzica La Manna, and
G. Tamburrelli. Qos driven dynamic binding
in-the-many. 2010.
[18] C. Ghezzi and G. Tamburrelli. Reasoning on
non-functional requirements for integrated services. In
RE '09 , Atlanta, USA, 2009.
[19] S. S. Gokhale. Architecture-based software reliability
analysis: Overview and limitations. IEEE Trans.
Dependable Sec. Comput. , 4(1):32{40, 2007.
[20] T.D. Johnson, R.M. Elasho, and S.J. Harkema. A
Bayesian change-point analysis of electromyographic
data: detecting muscle activation patterns and
associated applications. Biostatistics , 4(1), 2003.
[21] Y. Liu, I. Gorton, and L. Zhu. Performance prediction
of service-oriented applications based on an enterprise
service bus. Computer Software and Applications
Conference, Annual International , 1:327{334, 2007.
[22] D.A. Menasc e. QoS Issues in Web Services. IEEE
INTERNET COMPUTING , pages 72{75, 2002.
[23] B. Meyer. Applying" design by contract". IEEE
Computer , 25(10):40{51, 1992.
[24] Picnik. http://www.picnik.com.
[25] N. Sato and K. S. Trivedi. Stochastic modeling of
composite web services for closed-form analysis of
their performance and reliability bottlenecks. In
ICSOC '07 , pages 107{118, Berlin, Heidelberg, 2007.
Springer-Verlag.
[26] J. Skene, D. Lamanna, and W. Emmerich. Precise
service level agreements. In ICSE '04 , pages 179{188.
IEEE Press, 2004.
[27] L. Tierney. Markov chains for exploring posterior
distributions. the Annals of Statistics , 1994.
[28] B. Western and M. Kleykamp. A Bayesian change
point model for historical time series analysis. Political
Analysis , 12(4):354{374, 2004.
[29] T. Zheng, J. Yang, M. Woodside, M. Litoiu, and
G. Iszlai. Tracking time-varying parameters in
software systems with extended kalman lters. In
CASCON '05 , pages 334{345. IBM Press, 2005.
236