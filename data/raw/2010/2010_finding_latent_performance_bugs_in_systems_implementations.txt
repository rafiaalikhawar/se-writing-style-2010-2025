Finding Latent Performance Bugs in Systems
Implementations
Charles Killian Karthik Nagaraj Ryan Braud James W. Anderso n
Salman Pervez Ranjit Jhala
Purdue University University of California, San Diego
{ckillian, knagara, spervez}@cs.purdue.edu {rbraud, jwa nderson, jhala}@cs.ucsd.edu
ABSTRACT
Robust distributed systems commonly employ high-level rec ov-
ery mechanisms enabling the system to recover from a wide va-
riety of problematic environmental conditions such as node fail-
ures, packet drops and link disconnections. Unfortunately , these
recovery mechanisms also effectively mask additional seri ous de-
sign and implementation errors, disguising them as latent perfor-
mance bugs that severely degrade end-to-end system performance.
These bugs typically go unnoticed due to the challenge of dis tin-
guishing between a bug and an intermittent environmental co ndi-
tion that must be tolerated by the system. We present techniq ues
that can automatically pinpoint latent performance bugs in systems
implementations, in the spirit of recent advances in model c hecking
by systematic state space exploration. The techniques proc eed by
automating the process of conducting random simulations, i denti-
fying performance anomalies, and analyzing anomalous exec utions
to pinpoint the circumstances leading to performance degra dation.
By focusing our implementation on the M ACE toolkit, M ACEPC
can be used to test our implementations directly, without mo diﬁ-
cation. We have applied M ACEPC to ﬁve thoroughly tested and
trusted distributed systems implementations. M ACEPC was able to
ﬁnd signiﬁcant, previously unknown, long-standing perfor mance
bugs in each of the systems, and led to ﬁxes that signiﬁcantly im-
proved the end-to-end performance of the systems.
Categories and Subject Descriptors
D.4.7 [ Operating Systems ]: Organization and Design— Distributed
Systems ; D.2.5 [ Software Engineering ]: Testing and Debugging—
Testing tools
General Terms
Performance
Keywords
Mace, MacePC, performance, debugging, distributed system s
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and the full citation on the ﬁrst page. To cop y otherwise, to
republish, to post on servers or to redistribute to lists, re quires prior speciﬁc
permission and/or a fee.
FSE-18, November 7–11, 2010, Santa Fe, New Mexico, USA.
Copyright 2010 ACM 978-1-60558-791-2/10/11 ...$10.00.1. INTRODUCTION
It is hard to build correct, high-performance distributed s ystems.
As with any concurrent setting, the nastiest bugs are those t hat are
caused by the unexpected temporal interleavings of events. Dis-
tributed settings compound this problem by exploding the nu mber
of interleavings drastically through their node failures, message re-
ordering, etc.Thus, in addition to designing communication proto-
cols and data structures that work in the common case, the dev el-
oper must account for the fact that nodes participating in th e system
may join, leave or fail at any moment, and that the network sub -
strate may corrupt, reorder, or drop messages sent between n odes.
As a result, the most pernicious problems arise, not from alg orith-
mic issues which affect every execution and hence are amenable
to proﬁling, but from relatively rare corner-case node inte ractions
or unexpected packet delays or drops. The resulting perform ance
anomalies are difﬁcult to reproduce, and hence, to ﬁnd and to ﬁx.
Recently, several authors have proposed techniques to ﬁnd [ 7,
13, 29] and debug [6, 17] corner-case correctness problems in dis-
tributed systems. While ensuring the correctness of distri buted sys-
tems is a necessity, performance is crucial for these system s and
ﬁnding and ﬁxing performance bugs can be as important and cha l-
lenging. Speciﬁc challenges in performance debugging incl ude:
First, due to the importance of guaranteeing correctness an d re-
liability in the face of all possible event interleavings, d evelop-
ers typically build fail-safes into the system—worst-case recovery
mechanisms that periodically kick in and restore the system to a
consistent and stable conﬁguration. Unfortunately, these recovery
mechanisms sweep serious design and implementation ﬂaws un der
the rug, by disguising them as latent performance anomalies that
severely affect the responsiveness, availability, and end -to-end be-
havior of the system. Second, the standard means of debuggin g
distributed systems is to add code that logs the sequence of e vents
along each execution. Unfortunately, the amount of logging re-
quired to accurately correlate events across multiple node s can im-
pact the performance characteristics of a given live or simu lated ex-
ecution which makes it hard to use log analysis to ﬁnd perform ance
bugs. Third, even if one could generate high ﬁdelity logs wit h low
overhead, performance problems often only manifest in long ex-
ecutions, not the short correctness violations returned by model
checking [19, 22] or symbolic execution [2, 8]. Thus, to isol ate
the performance bug, the programmer must undertake the daun ting
task of wading through hundreds of megabytes of logs compris ing
tens of thousands of events spread across multiple nodes, ma nually
tracing the complex communication and control ﬂow.
In this paper, we present the M ACE Performance Checker, a tech-
nique that automates the process of ﬁnding latent performance bugs
in event-based distributed systems implementations, and a utomates
the process of isolating the root cause of the error. M ACEPC isbased upon the insight that a class of performance bugs manif est
asanomalous executions [5], i.e. executions whose performance is
much worse than the expected performance observed along oth er
executions. Consequently, we reduce ﬁnding performance bu gs to
three tasks: (i) determining expected performance of the sy stem,
(ii) ﬁnding executions whose performance is much worse than ex-
pected, and (iii) sifting through anomalous executions to p inpoint
circumstances causing the performance degradation.
MACEPC carries out these tasks by marrying state-space explo-
ration with time-based event simulation. First, we show how by
sampling the state space of the unmodiﬁed implementation we can
construct Event Duration Distributions (EDDs)—probability dis-
tributions that describe how long each low-level event take s to ex-
ecute. By combining EDDs with a programmer-speciﬁed stopping
condition that describes when the desired task is completed, M A-
CEPC is able to develop a proﬁle of the expected system perfor-
mance. Second, we show how to combine systematic testing wit h
the EDDs to ﬁnd anomalous executions that take much longer th an
expected to reach the stopping condition, i.e., whose perfo rmance
deviates signiﬁcantly from expected performance. Third, w e show
how to analyze the executions explored to isolate the root ca use of
the performance degradation. We narrow the circumstances w ith an
algorithm that characterizes the divergence point of an anomalous
execution—the point along the execution such that before the diver-
gence, some alternate execution achieves acceptable perfo rmance,
but immediately after the divergence, executions of the system have
bad performance. We then demonstrate how collecting event p ro-
ﬁles of executions can simplify debugging, by correlating c ertain
types of events with bad performance. Together, these techn iques
can save programmers a substantial amount of time devoted to di-
agnosing and ﬁxing the performance bug.
While the techniques behind M ACEPC could be used with other
event-simulators to ﬁnd performance problems in simulatio n, we
focus our implementation on the M ACE toolkit [12]. M ACE is a
language and toolkit for building a broad class of event-bas ed dis-
tributed systems. We have implemented more than ten signiﬁc ant
systems in M ACE, most of which were proposed by others. This
set includes distributed hash tables [24, 26, 27], applicat ion layer
multicast and ﬁle distribution [3,11,14], network measure ment ser-
vices [4], and consensus protocols [16] ready to run over the Inter-
net. M ACE has been in development for seven years, is publicly
available for download, and has been used by researchers at P urdue,
UCSD, EPFL, Cornell, UT-Austin, UCLA, HP Labs, MSR (Red-
mond, Silicon Valley, and Asia), and a handful of other unive rsities
worldwide in support of their own research and development. MA-
CEPC leverages the M ACE toolkit, allowing us to test unmodiﬁed,
deployable M ACE distributed systems implementations .
Finally, we present results from applying our techniques to ﬁve
real, complex distributed systems. We discuss the applicat ion of
our tool to the systems, subtle performance bugs we found, an d our
solutions. Many of these bugs are instances of correctness b ugs
masked by periodic corrective protocols. Importantly, the imple-
mentations were already thoroughly tested and had been run a cross
the Internet for several years. Further, while we had been aw are
of intermittent performance issues and had attempted to dia gnose
them on multiple occasions, we were unable to do so without M A-
CEPC. On using M ACEPC to Distributed Hash Table (DHT) sys-
tems, we improved the worst case ring stabilization time for a PAS-
TRY [26] implementation by a factor of 50, and in a highly-tuned
BAMBOO [24] implementation we improved both the consitency
and latency of Key-Value lookups by 15-30%.Figure 1: Motivating Example. An example scenario seen in
our random tree protocol. (1) Nodes AandCinitially attempt
to join the tree at node B. (2) Because node Awas more ﬁt to
be the root of the tree than node B, nodeBtold node Ato be
the root and attempted to join under it. (3) Meanwhile, upon
receiving a Join from node C, nodeBchanges its state to joined
since it accepts a child. Later (6), node Brejects the JoinReply
from node Aas it is already joined. This leaves the system in
a state with two trees, corrected only later during the recov ery
protocol. Note that if either join completed before the othe r
began, this bug would not have occurred.
2. BACKGROUND
Our goal is to automatically isolate latent performance bug s that
arise due to corner-case conditions that escaped the develo per’s at-
tention during system design and implementation. These bug s are
particularly hard to ﬁnd and ﬁx because they cannot be easily de-
tected in the presence of recovery code, nor reproduced due t o their
infrequency. In particular, we do not aim to automatically d iscover
algorithmic bottlenecks arising from poor design; these errors are
easier to detect as they hinder every execution’s performance.
As a motivating example, consider the scenario illustrated in Fig-
ure 1 that arose deploying a ﬁle distribution application. T he appli-
cation used an overlay tree as the basic reliable multicast c ommuni-
cation channel. Under some circumstances, the application stalled
when the overlay tree took too long to stabilize. Upon painst akingly
sifting through logs from system runs we found that network l aten-
cies caused unexpected re-ordering of events, disconnecti ng certain
nodes from the remainder. Later, a recovery protocol restor ed the
system, triggered by its coarse-grained timeout.
Note that the recovery protocol eventually restores the sys tem to
a consistent state, and hence there is no correctness error, per se .
Moreover, existing correctness checkers like [7, 13, 19, 22 ], ignore
quantitative system aspects like time, and hence cannot be u sed to
ﬁnd latent performance bugs such as the above.
In this section, we ﬁrst describe the basic system model of a d is-
tributed system execution, suitable for model checking. We then
describe the timed system model, which integrates the timin g in-
formation of a time-based simulator with the basic system mo del.
2.1 Basic System Model
We consider distributed systems implemented as atomic even t-
driven state-machines. The entire distributed system ther efore com-
prises processes running at the individual nodes together w ith the
network layer that the nodes use to exchange events .
The execution of an individual node can be viewed as a state ma -
chine that moves from one state to the next by executing the tran-
sition triggered by reception of events. Events typically come fro m
an application, the network or the timer scheduler. When a no de
receives an event, it executes a transition by executing the handler
function registered to receive the callback. The handler is an ar-bitrary piece of non-blocking code which executes atomical ly, and
may in turn trigger events asynchronously on other system no des.
The state of a node is the set of all variables of the state ma-
chine at that node. The state of all nodes together, combined with
the network, timer, and application simulator state compri se the
system state . An execution of the distributed system is an initial
system state and an ordered set of pairs: /angbracketleftnode,event/angbracketright. Intuitively,
the system evolves as follows: at each step, the system trigg ers
(event)on(node), executing at node the corresponding transition
and taking the entire system into a new state.
2.2 Timed System Model
Our goal is to isolate bugs that adversely affect the end-to- end
performance of a given distributed system, i.e. bugs that ad versely
affect the time taken to carry out the tasks for which the system was
built. Thus, we must extend our system model to track the pass age
of time, as other time-based simulators do.
In an event driven system, there are two ways in which time ad-
vances. The ﬁrst is the time that elapses between the sending and
reception of an event. This includes (1) the passage of time ( due to
network latency) between the instants a network event is sen t and
received, and, (2) the passage of time between the instants a timer
event is scheduled and ﬁres. The second is the time it takes to exe-
cute the transition corresponding to a given event, i.e. to e xecute the
code of the event’s handler. While our system model requires event
handlers be non-blocking (thus implying they are fast), in p rac-
tice they take a non-negligible amount of time. To be consist ent, a
node’s time must be updated according to both of these factor s.
To account for time, we include a per-node clock, and extend t he
notion of an execution as an initial system state and set of tuples:
/angbracketleftnode,event,start,duration /angbracketright
ordered by the element start . Intuitively, the system evolves as fol-
lows. At each step, the system picks the next tuple, and updat es the
system clock for node to be the maximum of its current value and
start . Next, the system triggers event onnode , thereby executing
atnode the corresponding transition. At the end of the transition,
thenode system clock is incremented by duration and thus the
whole system moves to a new state.
For simplicity, in the initial state assume all nodes share t he same
start time . We deﬁne the system time as the average node time
across all the system’s nodes. We deﬁne the running time as the
difference between the system time and the start time. To for mal-
ize the notion of performance we require that the developer p rovide
astopping condition , a predicate over the system state that is true
once the end-to-end task is accomplished. In the motivating exam-
ple above, our stopping condition is that the system form a sp anning
tree across all nodes. Thus, the performance of a particular execu-
tion is formalized as the execution time —the running time when
the system satisﬁes the stopping condition.
3. ALGORITHM
We now present our algorithm that uses developer-speciﬁed, high-
level stopping conditions to ﬁnd performance bugs. Figure 2 shows
the three phases of the algorithm: (1) Training, including both (a)
Event Duration Training, where we determine the CPU time of
each type of (atomic) event-transition, and (b) Performance Train-
ing,where we use the event durations to determine the “normal” ex -
ecution time; (2) Anomaly Detection, where we search the space of
behaviors to ﬁnd poor performing executions, i.e. whose exe cution
time is signiﬁcantly higher than normal; and ﬁnally, (3) Anomaly
Analysis, including both (a) Divergence Detection, where we an-
alyze the anomalous execution to determine the divergence p oint,
Unmodiﬁed System Training 
Search 
Anomaly 
Analysis Event Duration 
Distributions 
< ... > 
< ... > 
< ... > 
.Anomalous 
Execution 
Path 
Anomalous 
Execution Log Similar Fast
Execution Log 
Manual Debugging Event 
Frequencies Average 
Time 
Figure 2: System Architecture. First, M ACEPC is trained on
the unmodiﬁed system: a synthetic set of event duration dis-
tributions (EDD) are used to create realistic EDD, which are
then used to sample the execution space to learn what an “aver -
age” execution is. Next, the system and EDD are input into the
Explorer algorithm, and it continues until an anomalous execu-
tion is found. Finally, our anomaly analysis algorithm loca tes
the most similar “average” execution, and updates the event
frequencies, reporting any correlations to execution time . At
this point, any debugging tool or user process can be used to
compare the two executions until the source of the bug is foun d.
narrowing the search for the performance degradation cause , and
(b) Frequency Correlation, where we determine if certain event be-
haviors are related to the performance degradation.
3.1 Ingredients
We start by presenting the key ingredients of our technique, the
notion of an event duration distribution, and the two proced ures
Simulator andExplorer that are used across multiple phases.
Event Duration Distributions. For the purpose of simulation, we
represent the time taken to handle each event type (e.g. the t ime
taken to execute a transition or deliver a message) with a pro bability
distribution generated from actual executions of the syste m. We
call these the event duration distributions (EDD) . There are three
main advantages EDDs offer over the naive approach of using r aw
execution times observed during simulation.
Repeatability: After each event, the simulator determines the event
duration by randomly sampling the event’s distribution. By record-
ing the sequence of random numbers used for sampling, we en-
sure execution repeatability with exactly the same executi on time,
regardless of variability in events’ actual time. Conseque ntly,
even after subsequently modiﬁed code—e.g., to add logging, per-form time-intensive testing, etc.—the performance observed by
the simulator remains the same as the original, unmodiﬁed co de.
Coverage: EDD sampling allows exploration of executions with
event timing combinations never seen in a single run. This al -
lows the simulator to explore more variations in timing beha vior,
including potentially hard-to-ﬁnd corner cases.
Malleability: Timing distributions for each event enable exploring
“what if” scenarios with event times, by changing the distri bution
for events to see the effects on average execution duration. This
allows speculatively evaluating effects of different algo rithms,
buffering strategies, etc., without actual implementations.
We could construct similar distributions for network laten cy and
bandwidth observed on a particular real-world topology. Cu rrently
we take a simpler approach of randomized latencies (cf. Sect ion 4).
Algorithm 1 Simulator
Input: SystemS
Input: Stopping condition C
Input: SetEDD of timing distributions
events:/angbracketleftnode,event,start/angbracketrightQueue
timedEvents :/angbracketleftnode,event,start,duration /angbracketrightQueue
realTimes :/angbracketleftevent,realTime /angbracketrightQueue
Initialize Sandevents
whileCnot satisﬁed bySdo
/angbracketleftnode,event,start/angbracketright=events.pop()
node.time=max(node.time,start)
startTime =RealTime ()
Simulate event onnode
realTime =RealTime ()−startTime
duration =EDD[event][rand()]
node.time=node.time+duration
timedEvents .push(/angbracketleftnode,event,start,duration /angbracketright)
realTimes .push(/angbracketleftevent,realTime /angbracketright)
return/angbracketlefttimedEvents ,realTimes /angbracketright
Algorithm 1: Simulator implements the core simulation mecha-
nism. This algorithm takes three input parameters: a system to
be simulated, a stopping condition, and a set of EDDs. The al-
gorithm constructs three queues: (i) events , which holds the cur-
rently pending events, (ii) timedEvents , which records the se-
quence of already executed events, and their sampled durations,
(iii)realTimes , which records the sequence of already executed
events, and their realdurations. events is initialized with a small
set of events used to bootstrap the system (typically an appl ication
initializing event on each node), and timedEvents andrealTimes
are initially empty. Next, the simulator enters a loop in whi ch it
keeps executing pending events until the stopping conditio n be-
comes true. At each iteration, the algorithm pops the ﬁrst pe nd-
ing event (i.e. with the smallest start time) off the events queue.
The node running the chosen event sets its clock to the maximu m
of its current clock value and the scheduled start time of the event.
Next, the algorithm records the real time and executes the ev ent at
the chosen node, potentially causing other events to be enqu eued
(e.g., in the case where a new timer or network event is sched-
uled). To determine how long the event transition took, the a l-
gorithm randomly samples the EDD for the chosen event and as-
signs the result to duration . Further, the chosen node advances
its clock by duration . Next, the algorithm records the event ex-
ecution by adding the tuples /angbracketleftnode,event,start,duration /angbracketrightand
/angbracketleftevent,realTime /angbracketrightto thetimedEvents andrealTimes queues re-
spectively. When the stopping condition is satisﬁed, the si mulation
stops and returns timedEvents andrealTimes . Note that we cantrivially ensure there is a pending event by adding a dummy ti mer
that repeatedly ﬁres at long periods. Similarly, we ensure t he simu-
lation terminates by encoding a timeout in the stopping cond ition.
Algorithm 2 Explorer
Input: SystemS
Input: Stopping condition C
Input: SetEDD of timing distributions
Input: IntegerN
execs:/angbracketleftexecution /angbracketrightQueue
eventTimes :/angbracketleftevent,realTime /angbracketrightQueue
fori= 1toNdo
Reset system
/angbracketleftex,times/angbracketright=Simulator (S,C,EDD)
Addextoexecs
Add each element of times toeventTimes
return/angbracketleftexecs,eventTimes /angbracketright
Algorithm 2: Explorer implements a search of the space of exe-
cutions, via repeated calls to Simulator . This algorithm takes four
input parameters: a system to be analyzed, a stopping condit ion,
a set of EDDs, and an integer Ncorresponding to the number of
executions to be explored. The algorithm constructs two que ues:
(i)execs , which holds the explored executions, (ii) eventTimes ,
which holds the recorded times for different events along th e ex-
plored executions. Both queues are initially empty. The alg o-
rithm iterates Ntimes. In each iteration, it calls Simulator and
adds the returned execution to theexecs queue, and each event-
(real)duration tuple to the eventTimes queue. After the loop, it ter-
minates and returns the set of observed executions execs and event-
duration tuples. Between each invocation of Simulator , the algo-
rithm resets the system state, which includes tasks such as c learing
the simulated network of messages, instantiating new nodes for the
next execution, removing scheduled timers, and resetting t he ran-
dom number generator state. Since Simulator is randomized, each
invocation of Simulator returns a (possibly) different execution.
Event Duration Independence. Our approach to simulating the
passage of time assumes that within a node, event durations a re in-
dependent, i.e. the durations of different events are uncor related.
Different EDDs can be provided for nodes, modeling nodes at d if-
ferent speeds, but our implementation does not support temp orally
correlated durations (e.g. caused by resource competition from short-
lived background processes). Nevertheless, this simple ap proach
sufﬁces to explore naturally occurring variations in event orderings
and timings, unearthing many interesting performance bugs . We
leave modeling potential temporal correlations to future w ork.
Deterministic Replay. A key property of our simulator is deter-
ministic execution replay. By recording each event tuple du ring the
search phase, the simulator has a path describing the comple te ex-
ecution, and can later replay this path by executing each eve nt on
the appropriate node at the time indicated. To provide consi stent
executions when replaying a path, the simulator must contro l all
sources of non-determinism. We address non-determinism in event
orderings by using a simulated source of time, as discussed a bove.
In addition to the event orderings, real systems often make u se of
non-determinism within event handlers for randomized algorithms.
When executing in the simulator, systems should use a determ inis-
tic simulated random number generator.
3.2 Finding Performance Bugs
Next, we describe each of the phases of our algorithm.Phase 1a: Event Duration Training. First, we build EDDs that
describe how long each type of event-transition takes to exe cute.
To compute these distributions, we pick a value Nsuch that N
random executions “cover” all events (i.e. each event occur s in at
least one of the Nexecutions). If we later determine coverage was
incomplete, we can either increase Nand re-train, or substitute a
similar event’s distribution. We deﬁne a seed EDD for each ev ent,
where its duration is distributed uniformly over some ﬁxed i nterval
(such as 1-10ms). Next, we execute the Explorer on the system,
the stopping condition, the seed EDDs, and N. When the search
is complete, we discard the returned set of executions, and u se
the/angbracketleftevent,realTime /angbracketrighttuples (returned in realTimes ), to compute
EDDs for each event using the cumulative frequency distribu tion.
Phase 1b: Performance Training. Next, we use the EDDs com-
puted in phase 1a to quantify what should be deemed as anoma-
lous performance. To this end, we determine the “typical” ti me
it takes the system to carry out its high-level task, i.e. ave rage
time taken to reach the stopping condition. Concretely, we i nvoke
theExplorer algorithm on the system, the stopping condition, the
EDDs computed in phase 1a and another N. We discard the re-
turned set of event-time tuples and use the returned set of ex ecu-
tionsexecs to compute the values of the ﬁrst and third quartiles of
the execution time. We use the deﬁnition of “mild outliers” [ 18]
(Q3+1.5×(Q3−Q1)) to ﬂag anomalous executions.
Phase 2: Anomaly Detection. In phase 2 we explore the space
of behaviors to ﬁnd executions with poor performance, i.e. w hose
execution time is anomalous as computed by phase 1b. Concret ely,
we runExplorer with the same parameters as before, except we
use a large N, and terminate the search when we ﬁnd an execu-
tion that falls outside the bounds determined in phase 1b. Th e use
of different random number generator implementations allo w var-
ious search algorithms to be employed. For example, our prio r
work on the M ACE Model Checker (M ACEMC) [13] used an it-
erative bounded depth-ﬁrst-search generator for exhausti ve testing,
which is impractical when simulating microsecond-granula rity tim-
ings. In our experience, a basic randomizing generator is su fﬁcient
to detect many performance bugs. We leave to future work furt her
exploration of other generators such as a best-ﬁrst generat or.
Phase 3a: Divergence Detection. An anomalous execution can
consist of tens of thousands of events. The prospect of sifti ng
through all these events to ﬁnd the performance bug would dau nt
the hardiest systems developer. In this phase, we analyze th e ex-
ecution to pinpoint the divergence point , the ﬁrst event along the
execution that leads to stable performance degradation. By doing
so, the developer may skip past execution preﬁxes which may l ead
to good performance, focusing on the remainder.
Divergence detection is an adaptation of the technique for ﬁ nding
a critical transition pioneered in M ACEMC. The insight behind the
algorithm is as follows. Many performance problems are caus ed by
corner-case race conditions which cause latent performanc e bugs.
Prior to the race condition occurring in an execution, branc hing the
execution and following a different path avoiding the race c ondition
leads to a good execution. Thus we identify preﬁxes of the exe cu-
tion which have notexperienced the race condition, and narrow
down where the race condition takes place. Our experience in di-
cates that knowing the divergence point can allow the progra mmer
to ignore large portions of the execution trace: in one case n early
62% of the 22000 events could be ignored, saving many hours of
debugging time. More precision is not provided by this techn ique
because what it identiﬁes in the execution is where the race c ondi-
tion ﬁnished being enqueued onto the pending events list, no t when
it actually occurs.Figure 3: We ﬁrst perform an exponential search (shown above
the anomalous execution) to determine bounds for the diver-
gence point, then a binary search (shown below the anomalous
execution) to isolate the divergence point. Note that to avo id
ﬁnding cases which are only slightly non-anomalous, any exe -
cution exceeding Q3 will be considered a performance failur e.
As illustrated in Figure 3, we begin by initializing the preﬁx
length to one event, replaying the portion of the path overla pping
with the preﬁx, and then performing up to krandom walks. If any
of the random walks satisﬁes the timing constraint the race c ondi-
tion has not occurred, so we double the preﬁx length and repea t.
Eventually, we reach a part of the path where none of the krandom
executions satisfy the timing constraint, and thus we have l ower
and upper bounds on the divergence point. Note that for the ti ming
constraint we use the third quartile rather than the outlier thresh-
old. Otherwise the analysis will ﬁnd branches that perform o nly
slightly under the outlier threshold, distracting rather t han enhanc-
ing the debugging. Though this can further decrease the prec ision
of the analysis, the goal is to conﬁdently identify states wh ich are
safe to ignore. The algorithm’s second phase isolates the di ver-
gence point by conducting a binary search of the lower and upp er
bounds. The algorithm terminates, producing an execution s atis-
fying the timing constraint with the longest common preﬁx to the
anomalous execution.
Phase 3b: Frequency Correlation. To further simplify the debug-
ging process, we also collect event frequencies and the exec ution
time for executions simulated during phases 2 and 3a. Comput ing
this data is straightforward from the eventTimes queue returned
with each execution.
We automatically compute the correlation and scatter plot o f
each type of event with the execution time. This information can
quickly direct developers’ attention to the events whose pr esence
or absence is related to the performance bug. In the three sit uations
we have applied this technique thus far, after manually disc ard-
ing event types that are trivially correlated with path leng th, such
as periodic timer expiration, remaining high correlations were di-
rectly or indirectly related to the bug, drawing developer a ttention
to important parts of the implementation.
An example of using event frequencies is shown in Figure 4.
This plot is from the motivating example in Figure 1. It shows a
correlation between the event described by "receiving a Joi nReply
and sending a Remove message" and the execution time. Had thi s
tool been available when we ﬁrst diagnosed this bug, we would
have seen quickly that this event is correlated with longer p aths,
which would have helped us ﬁnd the bug more quickly.
4. IMPLEMENTATION DETAILS
While the techniques behind M ACEPC can be applied to arbi-
trary event-driven systems implementations and simulator s, our im-
plementation targets systems implemented using the M ACE frame-work [12]. Focusing on M ACE signiﬁcantly simpliﬁed the effort
in building M ACEPC, particularly given M ACEMC as a starting
point. M ACE structures each system component as a service im-
plemented using C++ objects. Each service object is structu red as
a state machine whose states correspond to valuations of the ob-
ject’s member ﬁelds. Each event’s transition is implemente d as
an atomically executed, non-blocking C++ method call, whic h can
asynchronously send events to itself through timers, or non -local
nodes through network messaging. Finally, M ACE combines the
high-level service object speciﬁcations with “scaffoldin g code” that
handles event dispatch, serialization, callbacks, timers ,etc.to gen-
erate C++ code that is ready to run on live networks.
In the remainder of this section, we describe the necessaril y im-
plementation changes to enable the implementation of M ACEPC.
Note that unlike many discrete event simulators, the goal of MA-
CEPC is not the accurate simulation of the distributed system, but
instead to be accurate enough to expose interesting perform ance
bugs. This allows us to keep our event-simulator quite simpl e.
Scalable Network Simulation
Like other distributed systems simulators, M ACEPC must simu-
late network delays. M ACEPC seeks a middle-ground between us-
ing a complete network simulator modeling congestion, and u sing a
simplistic model which only considers access link bandwidt h. We
also considered using measured delay distributions as for e vents,
but found a simple model was sufﬁcient to expose interesting bugs.
The time taken to send a message from a source to a receiver
is computed as the sum of four factors: (i) a propagation delay
ﬁxed based on conﬁguration, that models the delay to transfe r data
from source to destination, (ii) a transmission delay that models
the bandwidth between the source and receiver and the number of
simultaneous ﬂows sharing the link, and (iii) a random delay drawn
from a Pareto distribution, to model router queues.
By default, the propagation delay is set to 1ms, and the band-
width between peers at 8000 Kbps. However, each of these is co n-
ﬁgurable for different node pairs. To simulate the common ca se
where a node’s ﬁrst-hop link is the bottleneck, we count the n um-
ber of active outgoing ﬂows the node has to all other nodes abo ve
a certain size, and use this value to divide the available ban dwidth.
For example, if the bandwidth is conﬁgured at 8000 Kbps, and t here
are two simultaneous ﬂows, the transmission delay for a mess age
corresponds to the time it takes to send the message over a 400 0
Kbps link. We assume that all ﬂows with a certain threshold nu m-
ber of bytes in transmission are receiving their “fair share ” from
TCP. In particular, we exclude “light” ﬂows from this equati on, to
avoid equally penalizing these ﬂows. In our current impleme nta-
tion, this threshold is set to 300 bytes.
While the above does not perfectly mirror the behavior of net -
works, it allows M ACEPC to simulate the network with enough
efﬁciency and ﬁdelity to unearth tricky performance bugs. W e also
validated that M ACEPC could ﬁnd a known topology-speciﬁc bug
by conﬁguring the latencies accordingly across system node s.
Time-based Simulation
Since we were adapted M ACEMC to build M ACEPC, we had to
add time to its execution model. In doing so, a pending event q ueue
was added in place of querying simulators for possible event s at
each step. This modiﬁcation had a dramatic effect on simulat ion
complexity, enabling M ACEPC to run simulations at much larger
scale than is practical using M ACEMC.
Random Number Generators
All non-determinism in the implementations is mapped to cal ls
to the M ACE random number generator library, including selec-
tion of which event to execute. As a result, we can explore dif fer-ent search techniques for the state space by implementing di fferent
random number generators. When we ﬁrst developed M ACEPC,
it used the default M ACEMC random number generator that con-
ducted a bounded depth-ﬁrst-search. However, the degree of ran-
domness in simulating microsecond level times rendered the search
ineffective. Next, we explored a search technique which emu lated
the other random number generator by picking a ﬁxed number of
random candidates to explore in every step rather than an exh aus-
tive search. This was more practical, but added complexity w ith-
out providing any sort of guarantees about coverage. Curren tly,
we use a uniform random number generator, which provides sta te
space sampling rather than exhaustive search. We leave as fu ture
work using a best-ﬁrst random number generator that intenti onally
pushes the system into poor performing states.
Preparing a System for M ACEPC
Finally, to use M ACEPC to ﬁnd performance bugs, the user must
write: (i) one or more “test harnesses" or driver applicatio ns that
are used by M ACEPC to execute initialize and execute the appli-
cation, and (ii) a stopping condition that is used by M ACEPC to
determine when the system has completed its task. For exampl e, to
ﬁnd performance anomalies in a ﬁle distribution system, the user
could write (i) a driver application in which one node publis hes the
ﬁle and the other nodes request the ﬁle, and (ii) a stopping co ndition
that holds when each (receiver) node has ﬁnished downloadin g the
ﬁle. The compiled driver application is linked with the M ACE sys-
tem object ﬁles and simulator speciﬁc M ACE libraries for message
queuing and delivery, system time, timer scheduling and ran dom
number generation, and M ACEPC uses the resulting system to ﬁnd
performance bugs.
5. EXPERIENCES
We ran M ACEPC on M ACE implementations of B ULLET′[14],
PASTRY [26], B AMBOO [24], C HORD [27], and a random tree pro-
tocol (R AND TREE) as described below, and found signiﬁcant, pre-
viously unsolved performance issues with each. The followi ng ex-
amples are intended to give an understanding of the types of b ugs
we were able to ﬁnd and the utility of the tool. We try to descri be
only enough of the system being executed to understand the bu gs
described and the stopping conditions used.
All the systems we evaluated have been extensively tested in
live runs, and P ASTRY , BAMBOO , CHORD , and R AND TREE were
tested for correctness using M ACEMC. The B ULLET′implementa-
tion, though not checked with M ACEMC, was signiﬁcantly perfor-
mance tuned as a major differentiator relative to contempor aneous
systems.
The experiments below were run in a variety of network conﬁgu -
rations. M ACEPC ran on a single machine with an Intel Core2Duo
processor at 3GHz with 4GB of RAM. R AND TREE was tested at
small scale and yielded fast executions. B AMBOO was tested on 20-
40 nodes, and the remaining systems were tested in conﬁgurat ions
of 40-100 nodes. Note that it is impractical to perform any ki nd
of exhaustive search using standard model checking techniq ues on
systems of this size. Executions run in M ACEPC took anywhere
from 8 seconds to 3 minutes. This execution time is highly var iable
based on two primary factors: (1) the length of a path reachin g the
stopping condition, and (2) the per-event processing in M ACEPC.
For some systems, such as P ASTRY , the stopping condition, a per-
event processing task, has a complexity of O(n2logn)fornnodes,
so paths take much longer to explore as the size of the conﬁgur ation
grows.
The time spent searching for anomalous executions varied de -
pending on the number of paths M ACEPC had to search beforeﬁnding an anomaly, but the bugs we found appeared relatively early.
The longest part of M ACEPC execution was the divergence detec-
tion phase, which has to run O(klogs)steps, where kis the num-
ber of random paths at each step (a parameter impacting the er ror),
andsis the depth of the divergence point. Anomaly analysis range d
from 1 hour to 22 hours to run. Though 22 hours is on the long sid e,
the search was unattended, and did allow us to ignore nearly 6 2%
of the 22000 events in the anomalous execution.
5.1 BULLET′
BULLET′is a mesh-based, peer-to-peer ﬁle distribution protocol
similar in functionality to B ITTORRENT [1]. Each node contacts a
source node, receives a set of initial peers to join, and then begins
downloading a ﬁle in parallel from other nodes. Before discu ssing
the bugs we found, there are a few relevant implementation de -
tails to discuss. First, B ULLET′uses two transports – one for data
and a second for control messages. The data transport is conﬁ g-
ured to only buffer one block’s worth of data at a time, while t he
control transport is conﬁgured to buffer an unbounded numbe r of
messages. The TCP transport in M ACE has the ability to buffer
messages so that it can send them asynchronously without usi ng
service resources. Limiting the buffer length allows B ULLET′to
quickly react to changing network conditions and applicati on re-
quests, since buffered messages cannot be cancelled. B ULLET′ac-
tively detects when message blocks will not ﬁt in the queue, a nd
schedules a timer to send them later. However, “Diff” messag es, or
those that inform a peer about blocks a node possesses, are al so sent
over the data transport, and are not similarly protected aga inst a full
buffer. Second, B ULLET′is structured on top of R ANSUB[15], a
gossip protocol that periodically delivers a changing rand om subset
of mesh participants to each node.
Stopping Condition. The stopping condition for B ULLET′is sim-
ple – all nodes should complete downloading the ﬁle.
Anomalies. In the ﬁrst experiment with B ULLET′, we used a setup
of 100 nodes downloading a 20MB ﬁle. M ACEPC found the ﬁrst
anomaly after 134 runs, representing an 11 second execution which
exceeded the 9.5 second upper bound (as computed in Section 3 .2).
Each execution took approximately 18 seconds of real time, a nd
terminated in between 56000-57000 simulator steps.
After examining the times that each individual node took in t his
execution, we determined that only one slow node limited ove rall
system performance. Anomaly analysis showed that the discr ep-
ancy was based on the timing of one particular message the slo w
node sent to one of its peers. Upon further investigation, we real-
ized that in the “good” execution, the slow node’s message ca used
a Diff to be sent to it successfully, which happened to contai n infor-
mation about two blocks that were never successfully sent by any
other node. The slow node was then able to request these block s
from this peer and complete the ﬁle download. In the anomalou s
execution, the message was timed such that the Diff message s ent
from the slow node’s peer was dropped by a full transport. As a
result, the slow node never learned about the two blocks, lea ving
it stuck since it did not know about any peers who had the miss-
ing blocks. Eventually, R ANSUBdelivered a new set of candidate
nodes, and the slow node was able to join one of them and retrie ve
the missing blocks. However, waiting on R ANSUBwas responsible
for the delay, causing the anomalous execution.
The second experiment with B ULLET′used only a 2MB ﬁle, but
MACEPC found the second anomaly in less than 10 executions.
In this case, the anomalous execution took around 5.5 second s,
whereas a normal execution took no more than 2 seconds of simu -
lated time. To debug this case, we once again examined indivi dual
node completion times to learn that only a few nodes were slow .The ﬁrst thing obvious from inspecting the slow nodes’ logs w as
that no blocks were received until approximately 5 seconds i nto the
run, then they quickly retrieved all the blocks. We found tha t the
node did not acquire any peers for the ﬁrst 5 seconds. The slow
node did receive a list of candidate peers from the source whe n it
joined. However, its attempts to join each of them failed bec ause
no candidate could accept another peer. Thus, the node waite d 5
seconds for R ANSUBto deliver it a set of new peers.
Improvements. To ﬁx our ﬁrst anomalous condition, we simply
changed Diff messages to be sent over the control transport i nstead
of the data transport. This eliminated the problem of Diffs b eing
dropped by the transport, and ensured that all nodes receive d all
intended Diff messages.
The second performance problem was based on the fact that
when a node is rejected by potential peers, it could have to wa it
for R ANSUBto deliver it new ones. To overcome this idle time, we
changed the JoinReject message to contain the list of the rej ecting
node’s peers. Then, when a node receives the JoinReject mess age,
it has a set of other nodes it can try to join.
Note that in both cases, the overall system execution was correct .
However, just as corner cases in execution can lead to errors , sim-
ilar corner cases can lead to unexpectedly slow performance . Au-
tomated state space exploration techniques appear to be wel l suited
to automatically ﬁnd both types of conditions.
5.2 PASTRY
PASTRY is a well-known Distributed Hash Table (DHT) protocol
that enables nodes to self-organize into a ring structure. E ach node
in the ring takes an address in a circular address space, and b ecomes
responsible for the address space in the immediate vicinity of its
own address. The P ASTRY protocol organizes the ring to enable
routing to any address using a path of no more than log(n)hops.
The primary functionality we are concerned with is the stabi liza-
tion of the P ASTRY network. P ASTRY ’s performance can be mea-
sured by how long it takes nodes to ﬁnish their self-organiza tion
protocol. This protocol includes two basic components. The ac-
tive join component allows a joining node to connect to an existing
node and follows a protocol to ﬁnd where in the network it shou ld
insert itself. A node Njoins by routing a “join” message to its
closest peer in the address space, who tells Nof its address-space
neighbors by sending Nits “leafset”. Along the way, it also gath-
ers information about other nodes in the system. This protoc ol will
execute correctly as long as only one node is joining at a time , and
in the absence of departing nodes.
To handle multiple simultaneous node joins and departures, the
maintenance component periodically exchanges leafset informa-
tion with peers to ensure that each node’s state is accurate. This
protocol component can correct a wide variety of errors, mis takes,
and dropped messages, and therefore mask many performance b ugs.
Stopping Condition. The P ASTRY stopping condition is the time
all nodes’ routing information has stabilized to a consiste nt state.
This involves checking both that each node knows its immedia te
neighbors (important for correctness and fault tolerance) , and that
the routing distance between all pairs of nodes is logarithm ic in the
number of nodes.
Anomalies. During the training of P ASTRY anomaly conditions,
we stopped the training early. In the ﬁrst 6 paths, the averag e exe-
cution times for the 40 pastry nodes (in simulated seconds) w ere:
(60.0073,60.0061,60.0085,40.0051,20.0369,20.0313)
Variations of this magnitude were immediate indicators of a per-
formance problem. We re-ran M ACEPC having it save any execu-
tion that took longer than 50 (simulated) seconds. 22 of the ﬁ rst40 paths took longer than 50 seconds, the longest taking 100.0044
seconds in 8848 simulator steps. All executions were within a sec-
ond of a multiple of 20 seconds, a clue that the execution time was
being dominated by the behavior of a system timer ﬁring every 20
seconds.
Anomalies such as these were not unexpected. In earlier expe ri-
ments, we had observed that the P ASTRY implementation required
either a long stabilization period after ﬁrst being started , or an ex-
tended stagger-start period where nodes are slowly started over the
ﬁrst 30 seconds of the experiment. Running M ACEMC over P AS-
TRY did not ﬂag these problems because P ASTRY was still even-
tually reaching the stopping condition. We also did not attempt to
extensively debug this performance problem in live executi ons be-
cause of the difﬁculties of debugging a distributed system, and the
knowledge that we could just wait for it to stabilize before c onduct-
ing other experiments using P ASTRY .
Anomaly analysis on the longest path indicated that the perf or-
mance had not diverged before step 5681. In both fast and slow
executions, all nodes are trying to join at once. Since the bo otstrap
node does not add a joining node until after each joining node has
conﬁrmed that it is ﬁnished joining, multiple simultaneous joining
nodes will initially believe they are in a 2-node ring with ju st them
and the bootstrap node. (Each contacts the bootstrap node, w ho ini-
tially knows no one. It responds, telling them about just its elf, and
does not add them to its leafset until after they conﬁrm they h ave
ﬁnished joining.) Then all nodes nearly simultaneously ann ounce
themselves as new members of this small ring, largely oblivi ous to
the other recently-arrived nodes.
In the ensuing mayhem of the active join protocol, the nodes
closest in the address space to the bootstrap node are succes sful,
while the state of other nodes further away depends on the pre cise
order in which nodes are added and removed from the leafset of the
bootstrap node. Unlucky nodes take one or more executions of the
periodic maintenance protocol to ﬁnally correct their stat e. Each
time the periodic protocol executes, a node will move kneighbors
nearer to their correct position in the ring. If nnodes join simulta-
neously, and n >> k , this can take a very long time.
Improvements. The basic problem is that waiting 20 seconds for
each execution of the periodic protocol is a huge performanc e penalty
during ring construction. Scheduling the protocol more fre quently
would help, at the added cost of higher overhead in the common
case (such ﬁxes are only required during times of high node ch urn).
An adaptive timer could be used, though its design would like ly in-
volve difﬁcult and network-speciﬁc tuning parameters.
After exploring a range of options, we settled on the followi ng
solution. The problems essentially occur for nodes who are r e-
placed in the bootstrap node’s leafset but know nothing abou t nodes
near them in the address space. Thus, we notify a node with the cur-
rent leafset when removing it from the leafset. When it receives the
leafset, it will be informed of several nodes which are close r to its
correct place in the ring. This same information would be rec eived
at a later time when the maintenance protocol runs, but at tha t point
the information will be more out-of-date and less relevant. It is
important that the node get this particular version of the le afset, be-
cause the later version will only contain nodes close to the b ootstrap
node, not to the evicted node. After making these improvemen ts,
all execution times varied in length from 1.5-2 (simulated) seconds.
5.3 BAMBOO
BAMBOO is an enhancement to the original P ASTRY protocol,
designed to better handle network churn and cause lower netw ork
overheads than the very verbose P ASTRY active join protocol. Assuch, the performance metrics of interest and the stopping c ondi-
tion are the same.
BAMBOO accomplishes its lower overhead by shortening the ac-
tive join protocol to only contain information about the lea fset,
rather than other information gathered along the way. It als o re-
duces the amount of state in the maintenance protocol, thus r educ-
ing overhead while still converging to good routing paths.
We used M ACEPC on our B AMBOO implementation and found
three interesting performance bugs. We describe two below:
•BAMBOO keeps track of successors and predecessors, but
does not always know which one a node will be. If there is
a poor balance of node identiﬁers, a node initially suspecte d
to be a predecessor could later end up in the successor set.
To accommodate this, there was code in B AMBOO to take a
node pushed out of one set and check to see if it belongs in
the other set. However, a bug caused the variables maintain-
ing the boundary of the set to be updated before checking
to see if the boundary belonged in the other set. Thus, this
caused such nodes to be forgotten, and the problem to be later
corrected by the maintenance protocol.
•Despite this active join change, unusual orders of joining
nodes sometimes cause peers to not learn of each other. Again ,
this is because each peer ﬁrst gathers information, then an-
nounces its liveness. This causes immediate neighbors to
sometimes be wrong until the maintenance protocol executes .
To ﬁx this problem, we added an extra ﬁeld to the “inform”
message the B AMBOO implementation uses to conﬁrm that
it is alive. This additional ﬁeld indicates whether the info r-
mant believes it is adjacent to the informed. If any informed
node disagrees with this adjacency information, it trigger s
the maintenance protocol early to ﬁll in gaps.
After implementing these ﬁxes, M ACEPC was unable to ﬁnd any
executions which take longer than 1 second. Encouraged by th is
improvement, we conducted a real evaluation similar to the o ne de-
scribed in the B AMBOO paper [24] comparing the original M ACE
BAMBOO implementation with our ﬁxed implementation. In this
test, we ran a set of 300 instances of B AMBOO using ModelNet [28]
on a cluster of 5 machines, each with 16 GB of RAM, dual, 64-bit
quad-core Intel Xeon CPUs, and 4 Gigabit Ethernet connectio ns,
running Gentoo Linux 2.6.27. The experiment measures the co n-
sistency and latency of B AMBOO routing lookup information as
the median session time of a node ranges from 84 seconds to 672
seconds. To measure consistency, every set of 10 nodes share a
common lookup schedule, and lookups are considered consist ent
if a majority of responses indicate the same target node. The re-
sults are shown in Figures 5 and 6. The version produced by ﬁxi ng
the bugs found using M ACEPC allowed us to deliver better con-
sistency, eliminating roughly 15−30% of inconsistent lookups,
while also reducing latency by up to 15% under high degrees of
churn. These results demonstrate that the bugs we ﬁx using M A-
CEPC translate to actual improvements in the protocols we test , not
just arcane nuances tickled by rare execution paths.
5.4 CHORD and RAND TREE
We have also applied M ACEPC to the M ACE implementations
of C HORD and R AND TREE, and have found performance bugs in
each. These include the example bug illustrated in Figure 1. The
CHORD bugs were similar in ﬂavor to the P ASTRY bugs, with sim-
ilar solutions. The R AND TREE bugs were similar types of prob-
lems to the one in Figure 1, and caused the recovery protocol t o
correct them. The recovery protocol only executes every 10- 60 40 50 60 70 80 90 100
 80  100  120  140  160  180  200  220Execution Length (sec)
JoinReply -> Remove (frequency)
Figure 4: Positive correlation between ex-
ecution length and erroneous event. 94 95 96 97 98 99 100
 0  100  200  300  400  500  600  700Percent Consistency
Median Session Time (sec)Mace Bamboo (unmodified)
Mace Bamboo (fixed)
Figure 5: Percentage of lookups returning
a consistent result. 320 340 360 380 400 420 440 460 480
 0  100  200  300  400  500  600  700Mean Latency (msec)
Median Session Time (sec)Mace Bamboo (unmodified)
Mace Bamboo (fixed)
Figure 6: Mean latency of consistent
lookups.
seconds in a typical installation, since it is only supposed to cor-
rect for network partitions, and not protocol bugs. Thus, th e bugs
in R AND TREEwere responsible for very slow tree formation when
many nodes join at once, and correcting them allowed these sc e-
narios to proceed in under 1 (simulated) second rather than t ens of
seconds.
6. LIMITATIONS
While this approach to ﬁnding performance bugs has been suc-
cessful and seems quite promising, it is not a panacea. We des cribe
some limitations of our approach.
First, we run the real system under particular workloads. Th us,
our system can only ﬁnd performance bugs manifested by those
particular workloads, though the use of randomized simulat ion al-
lows us to exercise multiple behaviors for each workload.
Second, because our systematic exploration considers exec utions
based on realistic distributions of event timings under a pa rticular
environment, it will not cover as many code paths as a traditi onal
model checker [7, 13, 19, 22, 29]. This means it may have to be r un
separately under different deployment environments (e.g. , different
network conditions, etc.). The alternative approach of con sidering
all possible performance conditions appears impractical.
Thus, our present implementation has not considered compli -
cated execution search strategies or temporal correlation s between
individual event timings, because they have not yet been nee ded.
The design supports these possibilities, and we anticipate that ad-
ditional performance bugs may be isolated with additional d etail.
7. RELATED WORK
MACEPC is related to several techniques for ﬁnding errors in
software systems.
Fault Isolation. Our work is related to ideas in the fault isola-
tion literature such as delta debugging [30] which systematically
searches a space of possible faults to isolate the one that tr iggers
a particular bug. A variant of this idea is predicate switching [31]
which ﬂips branches along a path in order to explore alternat e exe-
cutions, thereby isolating the branch that exposes a partic ular bug.
These techniques focus on correctness problems, and ﬁnd bug s that
cause well deﬁned “crashes"; in contrast, our work attempts to iso-
late performance problems by ﬁnding executions that take an oma-
lously long.
Systematic Execution Exploration. MACEPC is closely related
to tools which ﬁnd correctness bugs by systematically execu ting
different paths through unmodiﬁed implementations. V ERISOFT
views the entire system as several processes communicating through
message queues, semaphores and other IPCs. It schedules the seprocesses and traps calls that access shared resources. By c hoosing
the process to execute at each such trap point, the scheduler can ex-
haustively explore all possible interleavings of the proce sses’ exe-
cutions using a stateless search , thereby ﬁnding a variety of errors.
CMC [19], also directly executes the code and explores diffe rent
executions by interposing at the OS scheduler level. M ODIST[29]
also directly executes the code, and is focused on transpare nt execu-
tion and checking of fail-stop and divergence errors. CHESS [22]
improves the effectiveness of systematic exploration usin g itera-
tive context bounding [20] and fair stateless search [21]. J AVAP-
ATHFINDER [10] checks Java programs by interposing at the JVM
level, in a manner analogous to CMC. M ACEMC [13] combines
VERISOFT -style stateless search with random walks to ﬁnd live-
ness bugs. Furthermore, M ACEMC uses a binary search over the
erroneous execution to pinpoint the critical transition before which
the system could have recovered to a live state, but after whi ch the
recovery becomes impossible. Our notion of a divergence poi nt is
an adaption that differs in that it is easier to tell whether a state is
dead (i.e. can never recover to a live state) than whether per for-
mance has degraded. To be conservative, our technique ﬁnds t he
divergence point when paths begin to show signs of degradati on.
All the above ignore time and hence cannot be used to ﬁnd error s
related to performance anomalies.
Performance Tracking. PIP[23] is a concurrent, complementary
technique for ﬁnding bugs in distributed systems. P IPis an annota-
tion language and an expectation checker which can be applie d to
executions. P IPprovides a way to visualize distributed path-ﬂow
in a system, and to write expectations to validate system pat hs. By
writing a set of execution validators, the idea is that you ca n ﬁnd
performance bugs by looking at any non-validated paths. M ACEPC
is easier to use as (i) it does not require a live deployment of the sys-
tem, (ii) it can automatically test a wide variety of executi ons, and
(iii) it does not require careful manual examination of ever y possi-
ble distributed path-ﬂow. X-T RACE [25] allows developers to bet-
ter understand the performance of their system by using exte nsions
to the existing protocol stack to trace the ﬂow of messages ac ross
protocol layers, networks and applications. Like P IP, X-T RACE is
focused on debugging particular live live executions, wher eas M A-
CEPC automatically ﬁnds executions with anomalous performan ce.
Finally, T REND -PROF [9] allows users to measure the empirical
computational complexity of implementations by plotting t he per-
formance of the system across a range of input sizes. Diverge nces
in expected behavior can pinpoint bottlenecks in the code e. g. func-
tions whose run-times grow faster than linearly with input s ize. It
is not clear if such techniques can be adapted to the uncertai n envi-
ronment of distributed systems.8. CONCLUSIONS
We have presented M ACEPC, a technique that ﬁnds andiso-
lates performance bugs in unmodiﬁed distributed systems code by
searching the execution space for executions that perform f ar worse
than is typical. M ACEPC starts by training itself using the run-
times of actual events from real executions. Next, M ACEPC uses
the distributions to explore a large number of executions, l ook-
ing for executions that take abnormally long to complete. Fi nally,
upon ﬁnding an anomalous execution, M ACEPC carries out sys-
tematic search for the most similar execution that does not e xhibit
the performance bug. The two executions, along with an autom at-
ically identiﬁed divergence point—the step after which it b ecomes
impossible for the execution to achieve acceptable perform ance—
serve dually to direct the developer to a portion of the execu tion
believed to contain the bug, and to attest that the bug does no t oc-
cur before the divergence point. Further, event frequency d ata is
available to the programmer, and its correlation with perfo rmance
can help guide the developer to focus on relevant types of eve nts.
We have applied M ACEPC to ﬁve mature systems, ﬁnding long-
standing performance bugs in each. Relative to running expe ri-
ments on nodes spread across the Internet, or even on a local- area
network emulator, we have found that our performance checke r sig-
niﬁcantly simpliﬁes and speeds the task of performance debu gging
and does not require expensive, manually inserted logging t hat of-
ten obfuscates the underlying bug.
Acknowledgements. We would like to thank Amin Vahdat for useful
discussions and feedback on the paper and techniques. This w ork
was supported by the National Science Foundation under Gran t
Nos. CCF-0644361, CNS-0720802, and a gift from Microsoft Re -
search.
9. REFERENCES
[1] Bittorrent. http://bitconjurer.org/BitTorrent.
[2] C ADAR , C., D UNBAR , D., AND ENGLER , D. R. Klee:
Unassisted and automatic generation of high-coverage test s
for complex systems programs. In OSDI (2008).
[3] C ASTRO , M., D RUSCHEL , P., K ERMARREC , A.-M.,
NANDI , A., R OWSTRON , A., AND SINGH , A. SplitStream:
High-bandwidth content distribution in cooperative
environments. In SOSP (2003).
[4] D ABEK , F., C OX, R., K AASHOEK , F., AND MORRIS , R.
Vivaldi: A decentralized network coordinate system. In
SIGCOMM (Portland, Oregon, 2004).
[5] E NGLER , D. R., C HEN, D. Y., AND CHOU , A. Bugs as
inconsistent behavior: A general approach to inferring err ors
in systems code. In SOSP (2001), pp. 57–72.
[6] G EELS , D., A LTEKAR , G., M ANIATIS , P., R OSCOE , T.,
AND STOICA , I. Friday: Global comprehension for
distributed replay. In NSDI (2007).
[7] G ODEFROID , P. Model checking for programming
languages using Verisoft. In POPL (1997).
[8] G ODEFROID , P., K LARLUND , N., AND SEN, K. Dart:
directed automated random testing. In PLDI (2005).
[9] G OLDSMITH , S., A IKEN , A., AND WILKERSON , D. S.
Measuring empirical computational complexity. In
ESEC/SIGSOFT FSE (2007), pp. 395–404.
[10] H AVELUND , K., AND PRESSBURGER , T. Model checking
Java programs using Java Pathﬁnder. Software Tools for
Technology Transfer (STTT) 2(4) (2000), 72–84.
[11] J ANNOTTI , J., G IFFORD , D. K., J OHNSON , K. L.,
KAASHOEK , M. F., AND JAMES W. O’T OOLE , J. Overcast:Reliable Multicasting with an Overlay Network. In OSDI
(2000).
[12] K ILLIAN , C., A NDERSON , J. W., B RAUD , R., J HALA , R.,
AND VAHDAT , A. Mace: Language support for building
distributed systems. In PLDI (2007).
[13] K ILLIAN , C., A NDERSON , J. W., J HALA , R., AND
VAHDAT , A. Life, death, and the critical transition:
Detecting liveness bugs in systems code. In NSDI (2007).
[14] K OSTI ´C, D., B RAUD , R., K ILLIAN , C., V ANDE KIEFT, E.,
ANDERSON , J. W., S NOEREN , A. C., AND VAHDAT , A.
Maintaining high bandwidth under dynamic network
conditions. In USENIX ATC (2005).
[15] K OSTI ´C, D., R ODRIGUEZ , A., A LBRECHT , J., B HIRUD ,
A., AND VAHDAT , A. Using Random Subsets to Build
Scalable Network Services. In USITS (2003).
[16] L AMPORT , L. The part-time parliament. ACM Trans.
Comput. Syst. 16 , 2 (May 1998), 133–169.
[17] L UI, X., L IN, W., P AN, A., AND ZHANG , Z. Wids checker:
Combating bugs in distributed systems. In NSDI (2007).
[18] M OORE , D. S., AND MCCABE, G. P. Introduction to the
Practice of Statistics , 3rd ed. W.H. Freeman, New York,
1999.
[19] M USUVATHI , M., P ARK, D., C HOU , A., E NGLER , D., AND
DILL, D. CMC: A pragmatic approach to model checking
real code. In OSDI (2002).
[20] M USUVATHI , M., AND QADEER , S. Iterative context
bounding for systematic testing of multithreaded programs .
InPLDI (2007).
[21] M USUVATHI , M., AND QADEER , S. Fair stateless model
checking. In PLDI (2008).
[22] M USUVATHI , M., Q ADEER , S., B ALL, T., B ASLER , G.,
NAINAR , P. A., AND NEAMTIU , I. Finding and reproducing
heisenbugs in concurrent programs. In OSDI (2008).
[23] P ATRICK REYNOLDS , CHARLES KILLIAN , J. L. W. J. C.
M. M. A. S., AND VAHDAT , A. Pip: Detecting the
unexpected in distributed systems. In NSDI (2006).
[24] R HEA, S., G EELS , D., R OSCOE , T., AND KUBIATOWICZ ,
J. Handling churn in a dht. In USENIX ATC (2004).
[25] R ODRIGO FONSECA , GEORGE PORTER , R. H. K. S. S.,
AND STOICA , I. X-trace: A pervasive network tracing
framework. In NSDI (2007).
[26] R OWSTRON , A., AND DRUSCHEL , P. Pastry: Scalable,
distributed object location and routing for large-scale
peer-to-peer systems. In Middleware (2001).
[27] S TOICA , I., M ORRIS , R., K ARGER , D., K AASHOEK , F.,
AND BALAKRISHNAN , H. Chord: A scalable peer to peer
lookup service for internet applications. In SIGCOMM
(2001).
[28] V AHDAT , A., Y OCUM , K., W ALSH , K., M AHADEVAN , P.,
KOSTI ´C, D., C HASE , J., AND BECKER , D. Scalability and
Accuracy in a Large-Scale Network Emulator. In OSDI
(2002).
[29] Y ANG , J., C HEN, T., W U, M., X U, Z., L IU, X., L IN, H.,
YANG , M., L ONG , F., Z HANG , L., AND ZHOU , L.
MODIST: Transparent Model Checking of Unmodiﬁed
Distributed Systems . In NSDI (2009).
[30] Z ELLER , A. Yesterday, my program worked. today, it does
not. why? In ESEC / SIGSOFT FSE (1999), pp. 253–267.
[31] Z HANG , X., G UPTA , N., AND GUPTA , R. Locating faults
through automated predicate switching. In ICSE (New York,
NY , USA, 2006), ACM, pp. 272–281.