Enhancing Symbolic Execution with Built-In Term
Rewriting and Constrained Lazy Initialization‚àó
Pietro Braione
University of Milano-Bicocca
Milano, Italy
braione@disco.unimib.itGiovanni Denaro
University of Milano-Bicocca
Milano, Italy
denaro@disco.unimib.itMauro Pezz√®
University of Milano-Bicocca
and University of Lugano
Italy / Switzerland
pezze@disco.unimib.it
ABSTRACT
Symbolic execution suers from problems when analyzing
programs that handle complex data structures as their in-
puts and take decisions over non-linear expressions. For
these programs, symbolic execution may incur invalid in-
puts or unidentied infeasible traces, and may raise large
amounts of false alarms. Some symbolic executors tackle
these problems by introducing executable preconditions to
exclude invalid inputs, and some solvers exploit rewrite rules
to address non linear problems. In this paper, we discuss
the core limitations of executable preconditions, and ad-
dress these limitations by proposing invariants specically
designed to harmonize with the lazy initialization algorithm.
We exploit rewrite rules applied within the symbolic execu-
tor, to address simplications of inverse relationships fos-
tered from either program-specic calculations or the logic of
the verication tasks. We present a symbolic executor that
integrates the two techniques, and validate our approach
against the verication of a relevant set of properties of the
Tactical Separation Assisted Flight Environment. The em-
pirical data show that the integrated approach can improve
the eectiveness of symbolic execution.
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging
General Terms
Verication
Keywords
Software analysis, Symbolic execution
‚àóWe provide an artifact ( http://www.lta.disco.unimib.
it/pietro.braione ) to experience with the approach pre-
sented in this paper and replicate our results. The artifact
has been successfully evaluated by the ESEC/FSE artifact
evaluation committee and found to meet expectations.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ESEC/FSE ‚Äô13, August 18‚Äî26, 2013, Saint Petersburg, Russia
Copyright 2013 ACM 978-1-4503-2237-9/13/08 ...$15.00.1. INTRODUCTION
Symbolic execution is at the core of many modern ap-
proaches to software testing and verication [21, 11, 31, 16,
27, 1, 8]. In a nutshell, symbolic execution is the process of
executing programs using symbols instead of concrete values
as input, to generalize the computation over the input do-
mains [22]. The attractiveness of symbolic execution for pro-
gram analysis is its ability to yield precise (though bounded)
representations of the program state space, exploiting ow
sensitiveness and reference aliasing to full extent.
Symbolic execution addresses ow sensitiveness by track-
ing the satisability of the path conditions , i.e., the logical
assumptions over the input values that must hold for exe-
cuting specic program paths, and relies on lazy initializa-
tion to systematically account for reference aliasing across
the input domain [21, 11]. Both these approaches introduce
challenging approximations into the analysis, often inducing
large amounts of false alarms, as we further discuss below.
Symbolic executors must be able to compute the satisa-
bility of path conditions, to avoid engaging into the analysis
of infeasible paths. To this end, symbolic executors use con-
straint solvers [10, 30]. With state-of-art solvers, symbolic
executors can deal eciently with path conditions that con-
tain linear integer arithmetics and operations with bitvec-
tors, but cannot deal well with expressions that refer to other
theories. For instance, although notable research advances
in constraint solvers to handle some classes of nonlinear con-
straints ([10, 19, 5]), it is still very unlikely to eciently solve
constraints over polynomials of arbitrary degree or trigono-
metric functions. Giannakopoulou et al. report a study of
using the SPF symbolic executor ([1]) for the analysis of
a component of TSAFE (the Tactical Separation Assisted
Flight Environment, which we also use as a benchmark in
this paper) where SPF generates path conditions that are
too complex for the constraint solvers to solve [15]. In fact,
the conservative over-approximation of assuming the non-
solvable path conditions as potentially satisable may drive
the symbolic executors into the extensive exploration of mas-
sive sets of infeasible traces, questioning the general appli-
cability of the technique for practical programs. To mitigate
these problems, some modern solvers exploit term rewriting,
based on equivalences between the mathematical interpre-
tation of terms in dierent reference theories, to substitute
intractable terms through the formulas and possibly achieve
tractable formulas eventually [32, 19, 5, 2]. In this paper
we propose to engineer term rewriting within the symbolic
executor, before calling the constraint solving services. We
nd this particularly benecial to suitably identify and sim-Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ESEC/FSE‚Äô13 , August 18‚Äì26, 2013, Saint Petersburg, Russia
Copyright 2013 ACM 978-1-4503-2237-9/13/08...$15.00
http://dx.doi.org/10.1145/2491411.2491433
411
plify inverse relationships that may depend on either specic
calculations in the analyzed program or the additional logic
of the verication tasks. While in principle a constraint
solver might be able to exploit these relationships, we found
that this is not always the case for formulas resulting from
multiple subsequent symbolic manipulations. On the con-
trary by incrementally matching the relevant relationships
as rewrite rules during symbolic execution, we can recognize
the applicable simplications earlier on simpler formulas.
Lazy initialization consists of assigning an unknown value
to the references in the initial state, and computing proper
values when the references are rst accessed. The algorithm
resolves the unknown reference values as any possible refer-
ence compatible with the initial state, including the null
value, any alias of type-compatible objects in the initial
state, and the address of a fresh (symbolic) object of any
compatible concrete subtype. This exhaustive enumeration
of all possible values of the references may lead invalid ini-
tial states in the context of programs that take complex data
structures as input, since these typically assume class or do-
main invariants to be accounted for. For instance, while re-
solving references between the nodes of a doubly linked list,
all reference values that do not ensure the class invariant on
the integrity between the next and previous associations
represent invalid states. Modern symbolic executors aug-
ment the program under analysis with executable precondi-
tions that can be used to rule out invalid initial states [31,
11, 28]. In this paper we discuss some core limitations of us-
ing executable preconditions, and propose invariants speci-
cally designed to harmonize with lazy initialization that can
identify and eliminate invalid inputs more generally.
This paper makes the following original contributions:
‚óèIt proposes a novel way to characterize valid input
states by means of program invariants specied as con-
straints over the lazy initialization process, aiming to
address the core limitations of current approaches based
on executable preconditions (section 2).
‚óèIt proposes to augment symbolic execution with term
rewriting mechanisms that incrementally match and
simplify the symbolic expressions, allowing to exploit
deductions enabled by the logic of the program and
the verication tasks (section 3).
‚óèIt describes a case study based on the Tactical Separa-
tion Assisted Flight Environment (TSAFE) where we
formalize a set of relevant verication properties for
this system (section 4).
‚óèIt presents a symbolic executor that integrates the two
proposed techniques and describes the experimental
results obtained with this symbolic executor on a pub-
licly available implementation of TSAFE (section 5).
The symbolic executor discussed in this paper is built by ex-
tending the Java Bytecode Symbolic Executor (JBSE) that
we developed in previous work [7]. We discuss the related
work in section 6 and our conclusions in section 7.
2. LAZY INITIALIZATION CONSTRAINTS
Symbolic execution of programs with non primitive in-
puts relies on lazy initialization that consists of assigning
an unknown value to the references in the initial state, and
computing proper values when the references are rst ac-
cessed [21, 11]. To avoid exploring invalid traces, it is im-
portant to prevent the lazy initialization algorithm from re-solving symbolic references to values that violate invariants
or preconditions of the program under analysis.
We illustrate the problem referring to the symbolic ex-
ecution of a Java program that takes as an input an ob-
ject of class java:util:LinkedList . This class implements
a doubly-linked list, maintaining the invariant that the list
handler, eld header , is always a reference to a dummy sen-
tinel node placed between the last and the rst data nodes.
According to lazy initialization, the value of the eld head of
the input list in the initial state is an unspecied (symbolic)
reference. The rst time that the program dereferences the
eld header , the lazy initialization algorithm resolves the
possible values of the reference and, in absence of informa-
tion about the invariant, produces both a successor state
where header==null and a successor state where header
points to a fresh node of the list. The former initialization
violates the class invariant, and yields false alarms along
symbolic traces that execute the LinkedList methods that
dereference header:next directly, as these methods correctly
rely on the existence of the sentinel.
Current Approaches
The problem of controlling the validity of the data structures
that undergo lazy initialization during symbolic execution is
well known [21, 31, 11, 28]. The current solutions encode the
relevant invariants and preconditions over the input objects
asexecutable predicates (pure methods) referred to as repOk
methods. The repOk methods inspect the data structures
to identify violations of their representation invariants, and
return either false ortrue to indicate the presence of ab-
sence of violations, respectively. The solutions dier on how
they intertwine the execution of the repOk methods with the
symbolic execution of the target program in order to restrict
the scope of the analysis to valid input states only [31, 11,
28]. Here, we give additional details of the current solutions,
to highlight the limitations and motivate the need of a novel
approach to this problem.
Some authors rely on symbolically executing the repOk
predicates of the input data structures before executing the
program under analysis [11, 28]. For a program Pthat takes
as input the data structures ini, whose representation invari-
ants are encoded as repOki, this approach reduces to symbol-
ically executing the program if(/uni22C0irepOki)P(in1;:::; inn).
As main shortcoming, this approach can enforce the initial-
ization of symbolic references never accessed in the target
code, thus competing with the main purpose of a lazy ini-
tialization, that is, to unfold only the portion of the input
space dynamically accessed by the program under analysis.
In the worst cases when the repOk iterates over a data struc-
ture, the reduction of laziness determines by itself the need
of bounding the size of the data structure to be explored.
Let us consider for instance the symbolic execution of the
program foothat takes as input an object class LinkedList .
Figure 1 shows the code of program fooand a possible repOk
method for the class LinkedList that we borrowed from the
SIR repository [13]. The repOk method returns false if (1)
theheader isnull, (2) the next and previous references
do not match properly between the data nodes, or (3) the
value of the eld size diers from the count of data nodes.
In the considered approach, the symbolic executor invokes
foothrough the driver code if(list:repOk ())foo(list ), to
enforce the assumption that the input is well-formed. With
a bound of 9 data nodes in the input list and the repOk412class LinkedList f. . .
int s i z e = 0;
Entry header = new Entry ( ) ;
class Entry fEntry next , previous ; . . . g
boolean repOk () f
i f( header == null )return false ;
Entry e = header ;
int pos = 0;
dof
i f( e . next == null )return false ;
i f( e . next . previous != e ) return false ;
e = e . next ;
i f( e != header ) pos++;
gwhile ( e != header ) ;
return pos == s i z e ;
g
g
void foo ( LinkedList l i s t , boolean a ,boolean b)f
Object item1 = null , item2 = null ;
try f
i f( a ) item1 = l i s t . getLast ( ) ;
i f(b) item2 = l i s t . g e t F i r s t ( ) ;
gcatch ( NoSuchElementException e ) freturn ;g
i f( item1 != item2 ) a s s e r t ( l i s t . s i z e () <9 ) ;
g
Figure 1: Class LinkedList with a repOk method and
a sample program that takes a LinkedList as input
method reported in the gure, the symbolic executor nds
10 valid traces that reach the entry of foo, a trace for each
(fully initialized) linked list with 0 and up to 9 data nodes,
respectively. While executing foo, these traces incur further
branching when executing the ifstatements and when lazy
initializing the references to the data objects extracted from
the list, resulting in a total of 91 traces that exit foo. If
we increase the heap bound, the number of traces increases
accordingly. Note also that a bound lower than 9 does not
allow to detect a legal counterexample that violates the as-
sertion in the program. The example illustrates the bad
eect that may derive from the interference between lazy ini-
tialization and the anticipated evaluation of the executable
constraints. In fact, program fooaccesses at most two ob-
jects in the list and reasons on the value of the scalar eld
size, which does not require the expansion of additional
data nodes to be symbolically evaluated.
To summarize, executing the repOk method to discard in-
valid inputs before executing the target code entails the risks
of (1) over-constraining the symbolic inputs, (2) nullifying
the ability of lazy initialization to contrast the path explo-
sion problem in symbolic execution, and (3) hindering the
ability of generalization of the technique.
Visser et al. propose an alternative approach that evalu-
ates the executable preconditions during and not before the
symbolic execution, to validate the outcomes of the lazy ini-
tialization algorithm rather than unfolding all valid inputs
in advance [31]. The technique relies on the concept of con-
servative executable precondition that can be evaluated on
partially initialized structures. Figure 2 shows the conserva-
tive version of the repOk of the class LinkedList , adapted
from the code in Figure 1 along the lines of the proposal
of Visser et al., that is, evaluating the representation con-
straints against the initialized elds only. Let us ignore the
code in the gray-box for now. For convenience we use to
denote a query to the symbolic executor to ask whether a
reference holds a symbolic non-initialized value in the cur-
rent state. This approach has the distinctive advantage ofnot anticipating the resolution of the symbolic references
before their rst actual access, but may easily incur false
positives, that is, unrecognized invalid initializations. While
the proponents of the technique already acknowledge that
the eectiveness largely depends on how the conservative
predicates are written, we show that its impact can be quite
deeper than one might expect.
For instance, let us consider the symbolic execution of the
program barin the bottom box of Figure 2, which as rst
instruction accesses an input list backwardly, and thus fos-
ters the lazy initialization algorithm to resolve the reference
header:previous . In this case, the conservative repOk
nds that header:next is not yet initialized and fails to dis-
card the invalid state header:previous ==null. Generaliz-
ing, if conservative repOk iterates over the list in one di-
rection only, it cannot enforce the invariant when the target
code accesses the list nodes in the opposite direction.
To show that the issue is not incidental, we augmented
conservative repOk according to the code in the gray-box
of Figure 2, to test the invariant properties through both a
forward and reverse traversal of the list nodes. Despite the
changes, we experience problems when analyzing the second
instruction of program barthat accesses the list forward un-
tilheader:next:next. Since header:next:previous has not
initialized yet, the conservative repOk fails to discard the
invalid state header:next:next==header:next, and incurs
an innite loop during the evaluation of conservative repOk .
Despite there exist solutions to this further issue (we may
build a worklist of traversed nodes and detect invalid circu-
larities), this example questions whether such approach is
truly the best choice.
As a nal note, repOk predicates typically describe the
structural consistency of a single data structure, but do not
describe constraints that involve two or more data struc-
tures. For example, in the case of the last instruction of
program barin Figure 2, to exclude the invalid state where
list1‚â†list2 and list1:header==list2:header , we need
a precondition that predicates over both lists. In general,
dening a precondition that excludes aliasing between a
given input reference and any other input object might be
impossible for some programs.
The LICS Approach
Our approach solves these issues by specifying invariants
over the integrity of interrelated input objects as constraints
over the lazy initialization process, rather than executable
predicates over the shape of the data structures. At the
purpose, we dene a language, the Lazy Initialization Con-
straint System (LICS), based on pattern matching and reg-
ular expressions. Figure 3 present the syntax of LICS. Here,
we describe the language referring to the excerpt of the spec-
ication in Figure 4 that exemplies the invariants of class
LinkedList written in LICS.
A LICS specication /uni27E8spec/uni27E9consists of a list of resolve
clauses /uni27E8resolve /uni27E9. A resolve clause denes the resolution
mode /uni27E8resMode /uni27E9of the symbolic references that are in-
stances of class /uni27E8class /uni27E9and possibly originate from the ab-
solute path /uni27E8pathAbs /uni27E9.
An absolute path identies a nested eld /uni27E8fieldPath /uni27E9of
the object denoted as {ROOT }, that is, the this object or a
named input parameter of the method under analysis. The
special name {RANY}can be used to match any pattern of
consecutive eld names from an input object. Field paths413boolean conservative repOk () f
int pos1 = 0 , pos2 = 0;
i f( !( header )) f
i f( header == null )return false ;
Entry e = header ;
dof
i f(( e . next )) break ;
i f( e . next == null )return false ;
i f( !( e . next . previous ) &&
e . next . previous != e ) return false ;
e = e . next ;
i f( e != header ) pos1++;
gwhile ( e != header ) ;
i f( !( header . next ) && e == header )
return pos1 == s i z e ;
e = header ;
dof
i f(( e . previous )) break ;
i f( e . previous == null )return false ;
i f( !( e . previous . next ) &&
e . previous . next != e ) return false ;
e = e . previous ;
i f( e != header ) pos2++;
gwhile ( e != header ) ;
i f( !( header . previous ) && e == header )
return pos2 == s i z e ;
g
return pos1 + pos2 <= s i z e ;
g
void bar ( LinkedList l i s t 1 , LinkedList l i s t 2 ) f
Object item1 = l i s t 1 . getLast ( ) ;
Object item2 = l i s t 1 . get ( 1 ) ;
Object item3 = l i s t 2 . g e t F i r s t ( ) ;
. . .
g
Figure 2: Conservative version(s) of LinkedList :repOk
and a program that takes a LinkedList as input
are specied as sequences of /slash.left-separators and eld names,
possibly using regular expression operators. For example, at
line 9 of Figure 4, the absolute path {RANY}/slash.leftheader matches
the eld header of any linked lists associated with the inputs
at any nesting level.
LICS includes relative paths /uni27E8pathRel /uni27E9that can be useful
to specify the resolution mode of a matched reference. A
relative path starts from the reference that is currently be-
ing resolved, denoted as {$REF}, or from the input eld that
matched {RANY}in the current resolve clause, denoted as
{$RANY}. Relative eld paths can be navigated back to the
object that contains a reference, denoted as {UP}. For in-
stance, at lines 17{18 of Figure 4, while resolving references
that match some e:next:previous eld pattern, the relative
path {$REF}/slash.left{UP}/slash.left{UP}matches the object e.
The resolution of the symbolic references can be specied
according to a /uni27E8resMode /uni27E9as follows. Modes not null (Fig-
ure 4, line 10), expands to nothing (line 16) and aliases
nothing (line 12) indicate that a reference must never be
resolved as null, as a fresh object or as alias of compatible
objects, respectively. The mode aliases /uni27E8path/uni27E9indicates
that a reference can be resolved as alias of only objects that
match either an absolute or a relative path. The keyword
maxselects the longest reference that matches a path. As an
example, max{$RANY}/slash.leftheader (/slash.leftnext )‚àómatches the right-
most expanded next element of the list (line 34). The modes
aliases instanceof and expands to instanceof (line 40)
restrict the resolution by expansion or aliasing to objects
compatible with a given class type only./uni27E8spec /uni27E9 ::= resolve begin /uni27E8resolve /uni27E9(;/uni27E8resolve /uni27E9)*end
/uni27E8resolve /uni27E9 ::= [ /uni27E8pathAbs /uni27E9]instanceof /uni27E8class /uni27E9 /uni27E8resMode /uni27E9
/uni27E8resMode /uni27E9 ::= not null
/divides.alt0 expands to nothing
/divides.alt0 expands to instanceof /uni27E8class /uni27E9[/uni27E8assume /uni27E9]
/divides.alt0 aliases nothing
/divides.alt0 aliases instanceof /uni27E8class /uni27E9[/uni27E8assume /uni27E9]
/divides.alt0 aliases [max]/uni27E8path /uni27E9[/uni27E8assume /uni27E9]
/uni27E8path /uni27E9 ::= /uni27E8pathAbs /uni27E9 /divides.alt0 /uni27E8pathRel /uni27E9
/uni27E8pathAbs /uni27E9 ::= ( {ROOT}[‚à∂/uni27E8param /uni27E9]/divides.alt0 {RANY})/uni27E8fieldPath /uni27E9
/uni27E8pathRel /uni27E9 ::= ( {$REF} /divides.alt0 {$RANY})(/slash.left({UP} /divides.alt0 /uni27E8fieldPath /uni27E9))*
/uni27E8fieldPath /uni27E9::= A regular expression over a set of ( /slash.left/uni27E8field /uni27E9)
/uni27E8assume /uni27E9 ::= A code block, may include assume statements
/uni27E8field /uni27E9 ::= A eld name
/uni27E8class /uni27E9 ::= A class name
/uni27E8param /uni27E9 ::= A parameter name
Figure 3: Specication of LICS
Resolutions by expansion and aliasing can be further spec-
ied, /uni27E8assume /uni27E9, to enforce further assumptions on the in-
volved objects. This feature aims to handle the consistency
of scalar elds that depend on the resolved references. For
example, the class LinkedList maintains the integer-typed
eld size to count the number of elements in the list. Thus,
upon assuming some new lists (Figure 4, line 4) we initial-
ize by increment the assumptions on eld size, while upon
assuming additional nodes in a list (line 38), we rene by
increment the assumptions on eld size.
As a whole, the invariant of class LinkedList in Figure 4
species (1) the integrity of the header dummy node that
must always exist as a fresh non-aliased object (lines 9{12),
(2) the correspondence of next and previous references be-
tween the nodes of the list (lines 15{22), (3) the representa-
tion of completely unfolded lists (lines 25{35), and (4) the
relation between the eld size and the number of items as-
sumed in the list (lines 4{6 and 38{42).
We have extended JBSE to accept LICS specications and
account for the LICS constraints within the lazy initializa-
tion algorithm. Upon resolving a symbolic reference, JBSE
matches the type and eld name of the reference against
the specied patterns, and applies the resolve clauses corre-
spondingly.
3. TERM REWRITING
Symbolic executors rely on solvers to check the satisabil-
ity of the path conditions, and face the challenge of nding
reasonable ways to cope with decision problems that are not
addressed by the theories implemented by the solvers. Us-
ing symbolic execution for (bounded) verication requires to
handle conservatively any undecided path condition, which
means assuming those path conditions as potentially satis-
able, and then extensively checking the related program
traces for violations of the properties of interest. Wrong as-
sumptions on the satisability of the path conditions lead to
spurious results and possibly false alarms, such as signaling
violations on infeasible traces.
Term rewriting simplies decision problems over combina-
tions of theories by substituting formulas in a given theory
with equivalent formulas easier to address automatically [2].
Admissible rewritings are specied as rewrite rules in the
forml‚Üír, meaning that the occurrences of lin a formula
can be rewritten as r. Term rewriting improves constraint
solving when it substitutes a formula that cannot be de-
cided automatically in the theory accepted in the solvers
with a formula that can be decided within the theory ac-4141‚àí‚àíRepresentation invariant of c l a s s LinkedList
2resolve begin
3instanceof List
4 expands to instanceof LinkedList f
5 f$REF g.m i n s i z e = 0
6 assume ( f$REF g. size>=0) g,
7
8‚àí‚àíHeader e x i s t s as a fresh object
9 fRANY g/ header instanceof LinkedList$Entry
10 not null ,
11 fRANY g/ header instanceof LinkedList$Entry
12 aliases nothing ,
13
14 ‚àí‚àíAll e : e . next . previous=e , e . previous . next=e
15 fRANY g/ header (/ next)+/ previous instanceof
16 LinkedList$Entry expands to nothing ,
17 fRANY g/ header (/ next)+/ previous instanceof
18 LinkedList$Entry aliases f$REF g/fUPg/fUPg,
19 fRANY g/ header (/ previous )+/next instanceof
20 LinkedList$Entry expands to nothing ,
21 fRANY g/ header (/ previous )+/next instanceof
22 LinkedList$Entry aliases f$REF g/fUPg/fUPg,
23
24 ‚àí‚àínext/prev not null , may a l i a s l e f t / rightmost
25 fRANY g/ header (/ next j/ previous)+
26 instanceof java / u t i l / LinkedList$Entry
27 not null ,
28 fRANY g/ header (/ next)+
29 instanceof LinkedList$Entry
30 aliases max f$RANY g/ header (/ previous ) ‚àóf
31 assume ( f$RANY g. s i z e== f$RANY g.m i n s i z e ) g,
32 fRANY g/ header (/ previous)+
33 instanceof LinkedList$Entry
34 aliases max f$RANY g/ header (/ next ) ‚àóf
35 assume ( f$RANY g. s i z e== f$RANY g.m i n s i z e ) g,
36
37 ‚àí‚àís i z e>= count of assumed fresh e ntr i es
38 fRANY g/ header (/ next j/ previous ) ‚àó
39 instanceof LinkedList$Entry
40 expands to instanceof LinkedList$Entry f
41 f$RANY g.m i n s i z e++
42 assume ( f$RANY g. size>=f$RANY g.m i n s i z e ) g
43end
Figure 4: Invariants of class LinkedList in LICS
cepted by the available solvers. Many modern constraint
solvers exploit rewrite rules, for example, to handle non-
integral domains by transformation to bit-vectors, to lin-
earize polynomials by expanding the involved variables over
nite domains, or to turn bit-vector arithmetics into boolean
satisability problems [32, 19, 5].
Term rewriting approaches embedded in the constraint
solvers cannot take into account the specicity of the ap-
plication domain. Our experience with symbolic execution
suggests that some verication problems entail the power
to ascertain inverse formulas over calculations done by pro-
grams. Thus, when using symbolic execution in such con-
texts, we may benet from being able to identify and sim-
plify symbolic expressions that include inverse relationships.
Figure 6 exemplies the problem by showing a contradictory
path condition clause that no constraint solver was able to
decide in the context of the experiment reported in section 5,
and that has been easily addressed after a suitable rewrit-
ing of inverse transformations: in fact, after unfolding the
arithmetics between the polynomials in the formula, this
path condition reduces to the inequality 0 >0, which is triv-
ially unsatisable. The insight of this paper is to show that
a tight interweave of term rewriting and symbolic execution
for a limited, yet crucially relevant, set of simplications and
inversion relationships, can simplify the cost of proofs and
improve the scalability of symbolic execution.C (c1) TOLAT(TOX(0;1);TOY(0;1))‚Üí0
(c2) TOLON(TOX(0;1);TOY(0;1))‚Üí1
(c3) TOX(TOLAT(0;1);TOLON(0;1))‚Üí0
(c4) TOY(TOLAT(0;1);TOLON(0;1))‚Üí1
P (p1)a00‚ãÖa11‚Üí(a0a1)(01)‚Ä†
(p2)a0+a1‚Üí(a0+a1)‚Ä†‚àó
(p3) (‚àëaii)‚ãÖa‚Ä≤‚Ä≤‚Üí‚àë(aii‚ãÖa‚Ä≤‚Ä≤)‚Ä†
(p4)a‚Ä≤‚Ä≤‚ãÖ(‚àëaii)‚Üí‚àë(a‚Ä≤‚Ä≤‚ãÖaii)‚Ä†
(p5)‚àëiaii‚Ä≤/slash.left‚àëkakk‚Ä≤‚Üí‚àëiaii/slash.left‚àëkakk‚Ä†
M (m1) abs()+>0‚Üí>0
(m2) abs()+‚â•0‚Üítrue
(m3) abs()+‚â§0‚Üí‚â§0
(m4) abs()+<0‚Üífalse
(m5) abs()‚àí>0‚Üí<0
(m6) abs()‚àí‚â•0‚Üítrue
(m7) abs()‚àí‚â§0‚Üí‚â•0
(m8) abs()‚àí<0‚Üífalse
(m9) ‚àíabs()+/uni22DB0‚Üíabs()‚àí/uni22DA0
(m10) ‚àíabs()‚àí/uni22DB0‚Üíabs()+/uni22DA0
(m11) sqrt(‚ãÖ)‚Üíabs()
(m12) sin()‚ãÖsin()+cos()‚ãÖcos()‚Üí1
(m13) exp()>0‚Üítrue
(m14) abs()‚â•0‚Üítrue
(m15) sqrt()‚â•0‚Üítrue
(m16) acos()‚â•0‚Üítrue
(m17) cos(sin())>0‚Üítrue
(m18) cos(cos())>0‚Üítrue
(m19) cos(atan())>0‚Üítrue
(m20) cos(asin())‚â•0‚Üítrue
‚Ä†,i,‚Ä≤denote monomial terms, that is, products of scalar
symbols and uninterpreted functions. ai,a‚Ä≤denote scalar literals.
‚àóThe rewriting engine identies and sums the similar terms by
scanning the formulas through. Two terms are similar if they
consist of exactly the same set of scalar symbols and uninterpreted
functions.
Figure 5: Rewrite rules implemented in JBSE
Figure 5 lists the rewrite rules that we have implemented
into our symbolic executor, and used in the experiments re-
ported in the next section. For reference purposes, the table
groups together the rules that address homogeneous types of
rewritings. The rules in group C apply inverse formulas over
uninterpreted functions that represent conversions between
polar and Cartesian coordinates of two dimensional points,
according to the names that the program under analysis uses
to denote the conversion operations. The rules in group P
foster simplications of polynomials, based on normal forms
and operations between similar terms (for example, these
allow our symbolic executor to handle the path condition of
Figure 6). The rules in group M apply known deductions for
square roots, absolute values, sine and cosine operations.
The rules in group C exemplify rewritings dened in ad-
hoc fashion for the analysis of a specic program, where
some pure methods of the program (for instance, the meth-
odstoLat ,toLon ,toXand toYof class SimpleCalculator )
are handled as uninterpreted functions (respectively, TOLAT,
TOLON,TOXand TOY). The rewrite rules codify valid de-
ductions over these functions. With our symbolic executor,
JBSE, users can annotate program methods to indicate that
they can be overridden with the application of prescribed
uninterpreted functions; JBSE provides a suitable API to
extend the symbolic executor with rewrite rules over such
uninterpreted functions. As we discuss in section 5, in the
context of our experiment, the rules in group C allowed us
to successfully analyze methods that accept points in polar
coordinates, convert them to the Cartesian plane to perform
geometric calculations, and then recast the results into polar
coordinates.415sin(track:heading )>((((track:lat‚àí
trajSynth:calc:minLat )‚ãÖ111194:92+sin(track:heading )‚ãÖ
track:speed‚ãÖtrajSynth:params:tsTimeHorizon )/slash.left111194:92+
trajSynth:calc:minLat‚àítrajSynth:calc:minLat )‚ãÖ111194:92‚àí
(track:lat‚àítrajSynth:calc:minLat )‚ãÖ111194:92)/slash.left
(track:speed‚ãÖtrajSynth:params:tsTimeHorizon )
Figure 6: A contradictory path condition clause
The symbolic executor can apply the rewrite rules incre-
mentally, whenever the symbolic execution of a program
statement results to a matching symbolic expression, rather
than only lately on the path conditions, which depend on
(possibly several) symbolic transformations from sets of state-
ments. This results in a better exploitation of the power of
rewrite rules. Moreover, these rewrite rules are designed
to address a limited set of inverse mathematical relation-
ships, also in consideration of domain specic idioms as in
the above exemplied case of the coordinate conversions,
while constraint solvers usually favor the ability of solving
most formulas in the scope of a general theory.
The results of the experiments reported in the next sec-
tions indicate that term rewriting at the symbolic execu-
tion level is eective to simplify the combination of direct
and inverse transformations over some symbolic structures,
for underlying theories out of the scope of state-of-the-art
constraint solvers. In our experience, combining constraint
solving and term rewriting built in the symbolic executor in-
creases the number of decided path conditions, up to mark-
ing the frontier between success and failure to address a
verication problem.
4. CASE STUDY
We investigate the eectiveness of the methods proposed
in this paper to improve the applicability of sumbolic exe-
cution experimentally by verifying a set of relevant correct-
ness properties of a prototype implementation of the Tactical
Separation Assisted Flight Environment (TSAFE). TSAFE
is a software application that assists air trac controllers in
monitoring the aircraft in an airspace and in avoiding safety
critical violations and conicts [14]. Below we describe the
functionality of TSAFE and the correctness properties that
we have addressed.
TSAFE
TSAFE systems are research prototypes not deployed in the
eld yet. We experimented with a prototype TSAFE sys-
tem produced as a joint research eort of the Nasa Ames
Research Center and the Massachusetts Institute of Tech-
nology [12]. The analyzed implementation consists of 19,328
lines of Java code. The computation handled by the proto-
type in a typical run of the system proceeds as follows: It
begins by invoking method start of class TsafeEngine , and
iterates through the tasks of route tracking ,conformance
monitoring and trajectory synthesis , which we further sum-
marize below along with the relevant domain terminology.
Route tracking amounts to determine the so called route
track of an aircraft, i.e., the portion of the planned route
(the ight plan) that best matches the current ight track
(as for coordinates, altitude, speed and heading) of the air-
craft. Route tracking starts with the invocation of method
findRouteTrack of class RouteTracker and goes throughdetermining the point of the route at minimal distance from
the ight track. This point is named as the snap-back point ,
and is computed by the method snapPointToRouteSegment
of class RouteTracker .
Conformance monitoring evaluates whether the ight track
and the route track dier beyond a given threshold as for
coordinates, altitudes, speeds and headings. Conformance
monitoring starts by invoking the method isBlundering of
class ConformanceMonitor . Non-conforming ights are said
to be blundering .
Trajectory synthesis starts by invoking either the method
getDeadReckoningTrajectory or the method getRouteTra -
jectory of class TrajectorySynthesizer for ights that
are blundering or not, respectively. Dead reckoning indi-
cates the activity of guessing the trajectory of a blunder-
ing ight, by assuming a straight movement according to its
current ight track, for a prescribed time horizon . Conform-
ing ights are assigned a route trajectory that assumes that
the aircraft moves along the planned route from the current
route track, until the time horizon or the end of the route.
TSAFE periodically scans all ights in the airspace, com-
putes their conformance status and populates a list of their
estimated trajectories. These data are meant to feed the
conict detection modules that are yet to be implemented
in the prototype.
Correctness Properties
We devised 13 domain-specic correctness properties by in-
specting the documentation of the operational concept of
the TSAFE prototype as described in [12]. Below we present
these properties informally and group them in three sets, ac-
cording to whether they address the correctness of the route
tracker when computing the snap-back point (RT.S prop-
erties), the correctness of the trajectory synthesizer when
computing the dead reckoning trajectory (TS.D properties)
or the route trajectory (TS.R properties). We report the
full formalization for the RT.S properties in the appendix,
as a sample of the concrete verication tasks entailed by
these properties, while the full detail of all properties and
the related experimental results is available in the replica-
bility artifact associated with this paper.
The RT.S properties state necessary conditions for the
snap-back point of a ight track with respect to a route
segment to be correctly computed. Informally:
‚óèRT.S.1 states that the snap-back point must lay on the
same straight line as the concerned route segment;
‚óèRT.S.2 states that the snap-back point can result ei-
ther in an endpoint of the concerned route segment or
in the projection of the ight track on that segment.
Both properties refer to method snapPointToRouteSegment .
This method takes as inputs the endpoints of a route seg-
ment (parameters fix1 and fix2) and the coordinates of
the ight track (parameter flightPoint ), and returns the
coordinates of the corresponding snap-back point.
These properties assume as precondition a context of in-
vocation of the method where the references to the input ob-
jects are neither null nor aliases of each other. We formalize
each property as a postcondition that asserts the character-
istics of collinearity (for RT.S.1), and equality or orthogonal-
ity (for RT.S.2) relatively to the input and output points. In
compliance with the documentation, we compute collinear-416ity and orthogonality relying on converting from the po-
lar, latitude-longitude coordinates of the points to suitable
Cartesian coordinates, according to the same planar approx-
imation of the earth used by the snap-point calculations.
The TS.D properties state necessary conditions for the
dead reckoning trajectory to be correctly computed. Infor-
mally:
‚óèTS.D.1 states that the dead reckoning trajectory con-
sists of exactly 2 points that correspond to the origin
and the endpoint of the foreseen movement;
‚óèTS.D.2 states that the dead reckoning trajectory orig-
inates from the current ight track of the aircraft;
‚óèTS.D.3 states that the dead reckoning trajectory ends
after time horizon units of time;
‚óèTS.D.4 states that the dead reckoning trajectory forms
the same angle as the current heading of the aircraft;
‚óèTS.D.5 states that the dead reckoning trajectory keeps
a stable altitude as the current altitude of the aircraft;
‚óèTS.D.6 states that the foreseen movement is the dis-
tance that the aircraft can cover in time horizon units
of time.
The method getDeadReckoningTrajectory , referred by
these properties, takes as input the current ight track of
the aircraft as track , and returns the dead reckoning tra-
jectory correspondingly. All TS.D properties assume as pre-
condition a context of invocation of the method where the
references to the input objects are not null, and both the
current speed and the time horizon are positive numbers.
They map to straightforward postconditions.
The TS.R properties state necessary conditions for the
route trajectory to be correctly computed. Informally:
‚óèTS.R.1 states that the route trajectory originates from
the current route track of the aircraft;
‚óèTS.R.2 states that all the intermediate destinations of
the route trajectory are the same as in the planned
route;
‚óèTS.R.3 states that the route trajectory either ends ex-
actly after time horizon units of time or reaches the
nal destination of the route;
‚óèTS.R.4 states that the route trajectory keeps a stable
altitude as the current altitude of the aircraft;
‚óèTS.R.5 states that the estimated time at each destina-
tion of the route trajectory matches the speed of the
aircraft and the distance between the covered destina-
tions.
These properties refer to the method getRouteTrajectory
that takes as input the current route track as track and
the ight plan as route , and returns the route trajectory
correspondingly. Note that the route track object contains
the snap-back point ( track:lat,track:lon) as well as the
endpoints track:prevFix and track:nextFix of the route
segment where the snap-back point lays.
These properties assume as precondition a context of in-
vocation of the method where the references to the input
objects are not null, both the current speed and the timehorizon are positive numbers, and the route track object is
well formed, meaning that the snap-back point lays on the
route segment, and the segment with edges track:prevFix
and track:nextFix exists in route . We formalize the re-
quirements of each property as postconditions that, for some
properties, quantify over the collections of destinations in
the route trajectory and/or in the planned route. Checking
the quantied formulas maps to assertions over the elements
of the collections while iterating through them. Of them,
we defer the control on the precondition stating the exis-
tence of segment track:prevFix -track:nextFix inroute to
the rst moment when TSAFE scans the route segments,
rather than enforcing it from the beginning. The reason of
this choice is the same that motivates the LICS approach|
avoiding the early branching due to all possible initializa-
tions of the symbolic references in route , and optimizing
the number of traces to be explored.
We assume a bound on the number of destinations in the
planned route (no more than 3) only for the TS.R proper-
ties, to prevent the case of nonterminating searches through
innitely many destinations.
5. RESULTS
We extended the JBSE symbolic executor to support both
LICS and term rewriting, and used the extended executor
to verify the properties RT.S, TS.D and TS.R. The data
reported in this section show that, in the context of this
experiment, the approach proposed in this paper plays a
crucial role to verify the properties with no false alarm. The
experiment consists of a setup phase and a measurement
phase.
Setup Phase
In this phase, we iterated the analysis of each property sev-
eral times in exploratory fashion, and incrementally identi-
ed the rewrite rules and the LICS constraints needed to
rule out false alarms. For each property, we started from
a baseline experiment where we used JBSE congured with
no LICS constraints and no rewrite rules. We manually in-
spected the path condition of the rst reported failure trace
(if any) to conrm it as either a true failure or a false alarm.
We documented the true failures and xed them in the code.
We tracked the false alarms to spurious input congurations
generated by lazy initialization or contradictory path con-
dition clauses undetected by the solver. We specied LICS
invariants or congured rewrite rules to handle the problem-
atic inputs and clauses, and re-ran the analysis accordingly.
Throughout this process, we identied a fault in the sub-
ject TSAFE, wrote a LICS specication suitable for the
analysis of the concerned properties, and devised the set
of rewrite rules presented in section 3. The identied fault
concerns the synthesis of the route trajectory of a conform-
ing aircraft, which can be incorrectly computed due to a
boundary fault when iterating over the destinations of the
planned route. The fault leads to a failure if the expected
route trajectory shall end in between the last and last but
one destinations, and leads TSAFE to compute a trajec-
tory shorter than the prescribed time-horizon, thus violating
property TS.R.3.
Figure 7 lists the LICS invariants that we specied to
avoid spurious inputs during the symbolic execution of the
subject TSAFE. This specication constrains the resolution
of abstract references of type List andEngineCalculator as4171resolve begin
2‚àí‚àíResolve abstract references as concrete c l a s s e s
3instanceof java / u t i l / List expands to instanceof java / u t i l / LinkedList ,
4instanceof t s a f e / engine / EngineCalculator expands to instanceof t s a f e /main/ SimpleCalculator ,
5
6‚àí‚àíList route . f i x e s contains d i s t i n c t fresh Fix o b j e c t s
7 fROOT g/ route / f i x e s / header (/ next j/ previous )+/element instanceof java / lang / Object not null ,
8 fROOT g/ route / f i x e s / header (/ next j/ previous )+/element instanceof java / lang / Object aliases nothing ,
9 fROOT g/ route / f i x e s / header (/ next j/ previous )+/element instanceof java / lang / Object
10 expands to instanceof t s a f e /data/Fix ,
11
12 ‚àí‚àíLinkedList o b j e c t s s a t i s f y the invariants from Figure 4
13end
Figure 7: The LICS specication for the analysis of TSAFE
objects of suitable concrete classes, that is, class LinkedList
from the Java library and class SimpleCalculator that is
responsible for the geometric calculations in the considered
TSAFE prototype, respectively. It enforces the input object
route to include a list ( route:fixes ) of valid and distinct
destinations of class Fix. Object route:fixes has to satisfy
the representation invariant of class LinkedList specied in
Figure 4 as well.
Table 1 indicates the properties for which we found a de-
pendency between the ability of JBSE to correctly decide
the verication problem and the extensions proposed in this
paper, that is, the ability of controlling lazy initialization af-
ter a LICS specication or simplifying path conditions based
on rewrite rules. We observe that the LICS specication im-
pacts on the verication of all TS.R properties, while it is
not needed to verify the RT.S and TS.D properties. The
rewrite rules impact on the verication of 4 out of 13 prop-
erties. Both extensions are needed for verifying property
TS.R.6, and only 5 (TS.D) properties can be veried by
the baseline JBSE with no extensions. With reference the
the rewrite rules outlined in Figure 5, the most frequently
needed groups of rewrite rules are coordinate conversions
(C) and simplications of polynomials (P), both needed for
verifying 4 properties. Almost all rewrite rules are needed
for the analysis of properties TS.D.6 and TS.R.5.
Measurement Phase
In this phase, we measured the impact of the approach pro-
posed in this paper on the ability of symbolic execution to
eectively decide verication problems. Before the experi-
ments, we xed the bug identied in the setup phase. Table 2
compares the performance of the analysis of the properties
(listed in column 1) when we use JBSE with no extensions
(columns from 2 to 4), JBSE with LICS invariants but no
rewrite rule (columns from 5 to 7), JBSE with both LICS
invariants and rewrite rules (columns from 8 to 10) and SPF
(columns from 11 to 13). SPF is a symbolic executor from
Nasa Ames that implements state of the art symbolic execu-
tion for Java [1, 21, 25]. For all the experiments, we report
the total number of symbolically executed traces (columns
#Traces ), the number of traces reported as violating the
property under analysis that correspond to false alarms,
since we removed all fault found in the setup phase (column
#Alarms ), and the time to complete the analysis (column
Time ). Overall, these data provide empirical evidence of the
benecial impact of constraining lazy initialization according
to domain invariants and using rewrite rules: Symbolic ex-
ecution augmented with the new features (constrained lazy
initialization and rewrite rules) does not report false alarms,Table 1: Properties with verication outcome im-
pacted by the LICS specication and the rewrite
rules (grouped as in Figure 5)
Rewrite rules
Properties LICS C P M
RT.S.1{2 √ó √ó
TS.D.1{5
TS.D.6 √ó √ó √ó
TS.R.1{4 √ó
TS.R.5 √ó√ó √ó √ó
Total 5 4 4 2
and thus concludes that, once xed the faults identied in
the setup phase, TSAFE satises all TS.D and RT.S prop-
erties, and does not violate any TS.R property within the
considered analysis bounds. Both JBSE without the new
features and SPF cannot reach the same conclusions.
JBSE without the new features and SPF verify 5 and 4
properties, respectively, but signal several alarms for the
other properties. We inspected samples of the alarms and
conrmed all these as false alarms. For all RT.S properties
and for the properties TS.D.6 and TS.D.4, this last being
veried by JBSE but not by SPF, JBSE without the new
features and SPF compute unsatisable path conditions that
are not detected by the constraint solvers. For instance, the
clause that we already illustrated in Figure 6 is part of an
unsatisable path condition computed by SPF for property
TS.D.6. Giannakopoulou et al. experienced similar prob-
lems in an independent study of using SPF for the analysis
of a TSAFE component [15]. JBSE extended with the con-
strained lazy initialization and the rewrite rules proposed in
this paper veries all TS.D and RT.S properties.
For all the TS.R properties, JBSE without the new fea-
tures and SPF raise exceptions along many traces.1Manual
inspection reveals that these exceptions are due to badly-
formed ight plan objects generated by the baseline lazy
initialization algorithm implemented in both tools. For in-
stance, since ight plans are handled as LinkedList ob-
jects that generically refer the ight destinations as ele-
ments of type Object , the baseline lazy initialization algo-
rithm explores several invalid associations between destina-
tions and initial objects of dierent types, causing several
1The dierent execution times and numbers of traces yielded
by JBSE and SPF depend on the relative strength and per-
formance of the constraint solvers used by the tools. Re-
gardless of the solver, both tools produce huge sets of false
alarms for all TS.R properties.418ClassCastExceptions . Extended with the ability of han-
dling LICS specications as proposed in this paper, JBSE
veries all TS.R properties, but property TS.R.5 that can
be veried when using both the LICS specication and the
rewrite rules.
JBSE with the new features handles all properties in rea-
sonable time, with a maximum of about 14 minutes in the
case of property TS.R.2. Comparing the execution time of
JBSE without the new features with JBSE without the new
features (columns 4 and 7 of Table 2), we observe that ac-
counting for LICS has a negligible impact on the perfor-
mance of the lazy initialization algorithm, when none of the
invariants matches the resolved references, and may improve
on the overall performance if it leads to explore less traces.
Comparing with the execution time of SPF (column 10), the
use of the rewrite rules reduce the performance by a factor
that range from from 1.5 to 9 times in the context of our
experiment, but is resolute to decide one third of the veri-
cation problems.
Threats to Validity
The scale of the investigated subjects may entail threats to
the internal validity of our experiment. To address these
issues, we have selected a subject program developed by a
third-party team for a safety-critical application, and have
confronted symbolic execution with arguably dicult ver-
ication properties of this program. The size of the code
under analysis is reasonable and comparable to other re-
lated experiments in the eld literature, while the diculty
of compelling symbolic execution to the verication of this
program has been conrmed by other researchers [15]. Ex-
tended JBSE completes the analysis of all properties in rea-
sonable time: The cost of applying rewrite rules is not negli-
gible, but pays back reports with no false alarms, which we
regard as a strong achievement. Scalability to larger pro-
grams remains to be studied as future work.
The quality of the measurements depends on the reliabil-
ity of the symbolic executors used in the experiment. We
have been developing and testing JBSE for several years by
now, and SPF has been extensively used in many research
projects so far. Both tools achieve similar results in con-
verging and signaling alarms across the analyzed properties,
which support the trustability of the baseline data. To vali-
date the results achieved with the approach proposed in this
paper, we have analyzed several alarms raised by the base-
line tools and discarded by extended JBSE, and we have
been able to conrm all these as false alarms. We are now
working to reproducing the baseline experiment with the Bo-
gor/Kiasan symbolic executor [11] to increase coverage with
respect to the state of the art in symbolic execution.
We are aware that the result of a single experiment cannot
be directly generalized. Our future plans include extending
the approach to programming languages dierent than Java
and beyond the experimental samples of this paper.
6. RELATED WORK
Several modern constraint solvers use term rewriting to
simplify formulas across (combinations of) theories [32, 19,
5, 2]. These approaches share the common idea to pre-
process the formulas sent to the constraint solver: They
identify mathematical structures that the solver cannot na-
tively cope with, and that can be rewritten to a solver-
friendly theory, typically by (re-)interpreting some of theincluded variables over a lower-level nite domain. Our
approach exploits term rewriting into the symbolic execu-
tion process, rather than at the interface between the sym-
bolic executors and the constraint solving services of use.
In this way, we can identify and handle symbolic expres-
sions while they are incrementally built during symbolic ex-
ecution, which we argue is best suited to simplify inverse
relationships that arise in many verication problems espe-
cially in the context of program-specic calculations, and is
conrmed by our experiments.
Sinha describes a symbolic execution algorithm augmented
with term rewriting [29]. The algorithm performs program
traversals using a work-list based approach in the style of
dataow analysis, and generates huge symbolic states due
to merging values from multiple paths. To mitigate this ef-
fect, it exploits rewrite rules that simplify symbolic values
guarded by disjoint path conditions. The rewrite rules de-
ned in this paper address the complementary objective of
simplifying symbolic formulas generated by rich computa-
tions along a path. They encompass arithmetics of polyno-
mials, properties of mathematical functions, and customiz-
able systems of equalities over program-specic uninterpreted
functions. To the best of our knowledge, no previous work
addresses these simplications.
Dynamic symbolic execution approximates all path condi-
tions as decidable formulas by substituting concrete values
in place of the symbolic (sub-)expressions that escape the
reference theories known to the solvers [16, 27]. P as areanu
et al. propose a mixed concrete-symbolic procedure with
several heuristics to address non-linear path conditions aug-
mented with uninterpreted functions [26]. These approaches
eectively support the generation of test cases that exercise
feasible paths, at the cost of missing traces that are likely
to challenge the constraint solver. In this respect, they do
not satisfy the requirements for bounded verication.
Belt et al. precede the invocation of the constraint solver
with an intermediate Lightweight Decision Procedure that
accumulates facts extracted from the constraints incremen-
tally identied as satisable, and may directly decide new
constraints based on the maintained facts [4]. Although
such procedure may partially overlap with some rewrite rule
proposed in this paper, the two approaches are most likely
amenable of complementary use.
Some previous research addresses the problem of testing
and verifying object oriented programs with invariants or
contracts over structured inputs. In Section 2 we have ex-
tensively illustrated the limitations of the approaches that
rely on executable preconditions [31, 11, 28]. Bounded ex-
haustive testing uses contracts to generate test cases by enu-
merating all satisfying inputs within user-dened bounds [6,
23, 20]. The viability of these approaches is often limited by
the extremely large size of the resulting test suites. Among
these approaches, TestEra uses Alloy to specify and handle
the program invariants [20, 18]. We aim to evaluate the fea-
sibility and convenience of replacing LICS with Alloy within
our approach as future work.
Software model checkers based on the CEGAR (Counter-
Example Guided Abstraction Renement) approach incre-
mentally over-approximate the programs under verication
as nite-state systems at increasing level of detail, and ex-
haustively search these systems for violations of safety prop-
erties [3, 17]. CEGAR model checkers have been success-
fully demonstrated for verifying device drivers in C against419Table 2: Performance of JBSE with and without LICS and rewrite rules, and in comparison to SPF
JBSE: No LICS, no rw JBSE: LICS, no rw JBSE: LICS, rw SPF
Prop #Traces #Alarms Time #Traces #Alarms Time #Traces #Alarms Time #Traces #Alarms Time
RT.S.1 60 9 7‚Ä≤‚Ä≤60 9 7‚Ä≤‚Ä≤51 0 1‚Ä≤02‚Ä≤‚Ä≤73 40 8‚Ä≤16‚Ä≤‚Ä≤
RT.S.2 173 36 35‚Ä≤‚Ä≤173 36 35‚Ä≤‚Ä≤137 0 4‚Ä≤39‚Ä≤‚Ä≤345 202 107‚Ä≤01‚Ä≤‚Ä≤
TS.D.1 7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤9 0 2‚Ä≤‚Ä≤
TS.D.2 7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤9 0 5‚Ä≤‚Ä≤
TS.D.3 7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤9 0 3‚Ä≤‚Ä≤
TS.D.4 7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤13 4 4‚Ä≤‚Ä≤
TS.D.5 7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤9 0 3‚Ä≤‚Ä≤
TS.D.6 8 1 <1‚Ä≤‚Ä≤8 1 <1‚Ä≤‚Ä≤7 0 <1‚Ä≤‚Ä≤11 2 3‚Ä≤‚Ä≤
TS.R.1 24487 14775 11‚Ä≤15‚Ä≤‚Ä≤6259 0 3‚Ä≤39‚Ä≤‚Ä≤5935 0 8‚Ä≤33‚Ä≤‚Ä≤3312 2808 88‚Ä≤35‚Ä≤‚Ä≤
TS.R.2 24487 14775 27‚Ä≤00‚Ä≤‚Ä≤6259 0 8‚Ä≤59‚Ä≤‚Ä≤5935 0 13‚Ä≤53‚Ä≤‚Ä≤3344 2808 102‚Ä≤33‚Ä≤‚Ä≤
TS.R.3 80863 65034 18‚Ä≤43‚Ä≤‚Ä≤6865 0 4‚Ä≤05‚Ä≤‚Ä≤6367 0 11‚Ä≤07‚Ä≤‚Ä≤3248 2808 80‚Ä≤22‚Ä≤‚Ä≤‚Ä≤
TS.R.4 24487 14775 10‚Ä≤36‚Ä≤‚Ä≤6259 0 3‚Ä≤08‚Ä≤‚Ä≤5935 0 9‚Ä≤11‚Ä≤‚Ä≤3336 2808 75‚Ä≤26‚Ä≤‚Ä≤
TS.R.5 29347 19635 12‚Ä≤50‚Ä≤‚Ä≤7795 1536 4‚Ä≤04‚Ä≤‚Ä≤5935 0 9‚Ä≤13‚Ä≤‚Ä≤3339 2850 71‚Ä≤27‚Ä≤‚Ä≤
JBSE integrates the constraint solver SICStus Prolog 3.12.10, http://sicstus.sics.se . SPF is updated at revision 419 of
jpf-symbc and revision 734 of jpf-core, and integrates the constraint solver CORAL [30]. The experiments were run on a
MacBook Pro equipped with a 2.66 GHz Intel Core 2 Duo, 8 GB of DDR3 memory and OSX 10.6.8.
paradigmatic properties, such as lock/unlock behaviors and
request dispatching patterns, but do not t well the ver-
ication of object-oriented programs, mostly because the
CEGAR approach badly copes with reference aliasing and
graphs of input objects. YOGI combines the CEGAR ap-
proach with dynamic analysis to improve performance and
eectiveness [24]. CBMC realizes bounded model check-
ing of C programs based on SAT solving technology [9].
Both YOGI and CBMC share similar limitations as CEGAR
model checkers with respect to object-oriented programs.
7. CONCLUSIONS
The increasing availability of computing resources at af-
fordable costs and the recent advances in constraint solv-
ing technologies foster a renewed interest in software anal-
ysis based on symbolic execution. In this paper, we have
discussed the dependencies of eective symbolic execution
on the ability to both account for domain invariants and
simplify intermediate symbolic expressions in the process
of identifying infeasible path conditions. We have demon-
strated the limitations of current approaches to address the
former issue. We have described a prototype symbolic ex-
ecutor that accepts domain invariants in a suitable language
to specify constraints over the lazy initialization process, and
applies a set of rewrite rules to simplify the symbolic expres-
sions incrementally during the analysis. We have reported
the results of an experience of using this symbolic executor
for the verication of a realistic safety-critical application.
The reported experimental data provide empirical evi-
dence that the traditional embodiment of symbolic execu-
tion may incur large amounts of false alarms to a degree
that questions the usability of the technique. Our proposed
solutions enabled successful verication of a meaningful set
of safety properties, demonstrating that symbolic execution
can successfully address verication properties of realistic
applications.
8. SUPPLEMENTARY INFORMATION
Below we report the full formalization for the RT.S prop-
erties introduced in Section 4.RT.S.1 pre RTS‚áísnapPointCollinearWithRouteSegment
RT.S.2 pre RTS‚áí(snapPointIsAVertex ‚à®
snapPointProjectsFlightPointOnRouteSegment )
Apply to the invocation
Point2D flightPt ;fix1;fix2;
Point2D snapPt =
routeTracker :snapPointToRouteSegment (flightPt;fix1;fix2);
Where
preRTSdef=routeTracker ‚â†null‚àßrouteTracker :calc‚â†
null‚àßflightPnt ‚â†null‚àßfix1‚â†null‚àßfix2‚â†null‚àßfix1‚â†
fix2‚àßflightPnt ‚â†fix1‚àßflightPnt ‚â†fix2
snapPointCollinearWithRouteSegmentdef=
collinear (routeTracker :calc;fix1;fix2;snapPnt )
snapPointIsAVertexdef=
(snapPnt:lat=fix1:lat‚àßsnapPnt:lon=fix1:lon)‚à®
(snapPnt:lat=fix2:lat‚àßsnapPnt:lon=fix2:lon)
snapPointProjectsFlightPointOnRouteSegmentdef=
orthogonal (routeTracker :calc;fix1;fix2;snapPnt;flightPnt )
collinear (EngineCalculator calc ;Point2D a;Point2D b;
Point2D c )def=aXY:x(bXY:y‚àícXY:y)+bXY:x(cXY:y‚àíaXY:y)+
cXY:x(aXY:y‚àíbXY:y)=0
orthogonal (EngineCalculator calc ;Point2D a;Point2D b;
Point2D c;Point2D d )def=(aXY:x‚àíbXY:x)(cXY:x‚àídXY:x)+
(aXY:y‚àíbXY:y)(cXY:y‚àídXY:y)=0
aXYdef=calc:toXY(a);bXYdef=calc:toXY(b);
cXYdef=calc:toXY(c);dXYdef=calc:toXY(d)
9. ACKNOWLEDGEMENTS
This work is partially supported by the European Union
FP7 project PINCETTE (grant agreement n. 257647).42010. REFERENCES
[1] S. Anand, C. S. P as areanu, and W. Visser. JPF-SE: A
symbolic execution extension to Java PathFinder. In
International Conference on Tools and Algorithms for
the Construction and Analysis of Systems , LNCS
4424. Springer, 2007.
[2] A. Armando, M. P. Bonacina, S. Ranise, and
S. Schulz. New results on rewrite-based satisability
procedures. ACM Transactions on Computational
Logic , 10(1), 2009.
[3] T. Ball and S. K. Rajamani. Automatically validating
temporal safety properties of interfaces. In SPIN
workshop on Model checking of software , LNCS 2057.
Springer, 2001.
[4] J. Belt, Robby, and X. Deng. Sireum/Topi LDP: A
lightweight semi-decision procedure for optimizing
symbolic execution-based analyses. In ACM SIGSOFT
symposium on The foundations of software
engineering . ACM, 2009.
[5] C. Borralleras, S. Lucas, A. Oliveras,
E. Rodr guez-Carbonell, and A. Rubio. SAT modulo
linear arithmetic for solving polynomial constraints.
Journal of Automated Reasoning , 48(1), 2012.
[6] C. Boyapati, S. Khurshid, and D. Marinov. Korat:
automated testing based on java predicates. In
International symposium on Software testing and
analysis . ACM, 2002.
[7] P. Braione, G. Denaro, B. K rena, and M. Pezz e.
Verifying LTL properties of Bytecode with symbolic
execution. In 2nd Workshop on Bytecode Semantics,
Verication, Analysis and Transformation , 2008.
[8] C. Cadar, D. Dunbar, and D. Engler. KLEE:
Unassisted and automatic generation of high-coverage
tests for complex systems programs. In USENIX
Symposium on Operating Systems Design and
Implementation , 2008.
[9] E. Clarke, D. Kroening, and F. Lerda. A tool for
checking ANSI-C programs. In Tools and Algorithms
for the Construction and Analysis of Systems , LNCS
2988. Springer, 2004.
[10] L. de Moura and N. Bjorner. Z3: An ecient smt
solver. In Tools and Algorithms for the Construction
and Analysis of Systems , LNCS 4963. Springer, 2008.
[11] X. Deng, J. Lee, and Robby. Bogor/Kiasan: A
k-bounded symbolic execution for checking strong
heap properties of open systems. In International
Conference on Automated Software Engineering , 2006.
[12] G. D. Dennis. TSAFE: Building a trusted computing
base for air trac control software. Master's thesis,
Massachusetts Institute of Technology, 2003.
[13] H. Do, S. G. Elbaum, and G. Rothermel. Supporting
controlled experimentation with testing techniques:
An infrastructure and its potential impact. Empirical
Software Engineering: An International Journal ,
10(4), 2005.
[14] H. Erzberger. The automated airspace concept. In Air
Trac Management R&D Seminar , 2001.
[15] D. Giannakopoulou, D. H. Bushnell, J. Schumann,
H. Erzberger, and K. Heere. Formal testing for
separation assurance. Annals of Mathematics and
Articial Intelligence , 63(1):5{30, 2011.
[16] P. Godefroid, N. Klarlund, and K. Sen. DART:directed automated random testing. In ACM
Conference on Programming language design and
implementation . ACM, 2005.
[17] T. A. Henzinger, R. Jhala, R. Majumdar, and
G. Sutre. Lazy abstraction. In ACM Symposium on
Principles of Programming Languages , 2002.
[18] D. Jackson. Software Abstractions: Logic, Language,
and Analysis . The MIT Press, 2006.
[19] S. Jha, R. Limaye, and S. A. Seshia. Beaver:
Engineering an ecient smt solver for bit-vector
arithmetic. In International Conference on Computer
Aided Verication , LNCS 5643. Springer, 2009.
[20] S. A. Khalek, G. Yang, L. Zhang, D. Marinov, and
S. Khurshid. Testera: A tool for testing java programs
using alloy specications. In International Conference
on Automated Software Engineering , 2011.
[21] S. Khurshid, C. S. P as areanu, and W. Visser.
Generalized symbolic execution for model checking
and testing. In Tools and Algorithms for Construction
and Analysis of Systems , LNCS 2619. Springer, 2003.
[22] J. C. King. Symbolic execution and program testing.
Communications of the ACM , 19(7):385{394, 1976.
[23] D. Marinov and S. Khurshid. Testera: A novel
framework for automated testing of java programs. In
International Conference on Automated Software
Engineering , 2001.
[24] A. V. Nori and S. K. Rajamani. An empirical study of
optimizations in YOGI. In International Conference
on Software Engineering . ACM, 2010.
[25] C. S. P as areanu, P. C. Mehlitz, D. H. Bushnell,
K. Gundy-Burlet, M. Lowry, S. Person, and M. Pape.
Combining unit-level symbolic execution and
system-level concrete execution for testing NASA
software. In International Symposium on Software
Testing and Analysis . ACM, 2008.
[26] C. S. P as areanu, N. Rungta, and W. Visser. Symbolic
execution with mixed concrete-symbolic solving. In
International Symposium on Software Testing and
Analysis , 2011.
[27] K. Sen, D. Marinov, and G. Agha. CUTE: a concolic
unit testing engine for C. In European Software
Engineering Conference and ACM Symposium on
Foundations of Software Engineering , 2005.
[28] J. H. Siddiqui and S. Khurshid. Staged symbolic
execution. In ACM Symposium on Applied Computing ,
2012.
[29] N. Sinha. Symbolic program analysis using term
rewriting and generalization. In International
Conference on Formal Methods in Computer-Aided
Design , pages 19:1{19:9. IEEE, 2008.
[30] M. Souza, M. Borges, M. d'Amorim, and C. S.
P as areanu. Coral: Solving complex constraints for
symbolic pathnder. In NASA Formal Methods , 2011.
[31] W. Visser, C. S. P as areanu, and S. Khurshid. Test
input generation with Java PathFinder. In
International Symposium on Software Testing and
Analysis . ACM, 2004.
[32] H. Zankl and A. Middeldorp. Satisability of
non-linear (ir)rational arithmetic. In International
Conference on Logic for Programming, Articial
Intelligence, and Reasoning . Springer, 2010.421