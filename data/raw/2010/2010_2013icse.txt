GuideArch: Guiding the Exploration of
Architectural Solution Space under Uncertainty
Naeem Esfahani
Department of Computer Science
George Mason University
Fairfax, Virginia, USA
nesfaha2@gmu.eduSam Malek
Department of Computer Science
George Mason University
Fairfax, Virginia, USA
smalek@gmu.eduKaveh Razavi
Department of Computer Science
George Mason University
Fairfax, Virginia, USA
srazavi2@gmu.edu
Abstract ‚ÄîA system‚Äôs early architectural decisions impact its
properties (e.g., scalability, dependability) as well as stakeholder
concerns (e.g., cost, time to delivery). Choices made early on are
both difÔ¨Åcult and costly to change, and thus it is paramount that
the engineer gets them ‚Äúright‚Äù . This leads to a paradox, as in
early design, the engineer is often forced to make these decisions
under uncertainty, i.e., not knowing the precise impact of those
decisions on the various concerns. How could the engineer make
the‚Äúright‚Äù choices in such circumstances? This is precisely the
question we have tackled in this paper. We present GuideArch , a
framework aimed at quantitative exploration of the architectural
solution space under uncertainty. It provides techniques founded
on fuzzy math that help the engineer with making informed
decisions.
Index Terms ‚ÄîSoftware Architecture, Uncertainty, Decision
Making
I. I NTRODUCTION
A software system‚Äôs early architecture is the set of prin-
cipal decisions made at the outset of a software engineering
project. Early architecture encompasses choices at application,
system, and hardware level that could have an impact on
the software system‚Äôs properties. A candidate architecture
results from selecting a viable alternative for each and every
decision. A common practice is to carefully assess the system‚Äôs
early architecture for its ability to satisfy functional and non-
functional requirements, as well as other stakeholder concerns,
such as cost and time to delivery.
Early architectural decisions are crucial, as they determine
the scope of capabilities and options that can be exercised later
in the system‚Äôs life cycle. Given the crucial impact of early
architectural decisions on the system‚Äôs properties, changing
them in subsequent phases of the engineering process are
often both difÔ¨Åcult and costly. At the same time, making such
decisions is a complex task mired with lots of uncertainty.
Getting them ‚Äúwrong‚Äù poses a risk to any software engineering
project.
One of the major thrusts of the software engineering re-
search has been to transform the process of making such
decisions from an art form exercised successfully by a select
few to a repeatable process guided through scientiÔ¨Åc reasoning
and formal analysis. A few notable examples include ATAM
[5], CBAM [13], and ArchDesigner [1]. Such efforts have not
aimed to replace the engineer‚Äôs experience and knowledge,but to rather augment it through provisioning of appropriate
methods and tools.
While great strides have been made, the existing approaches
do not provide adequate support for dealing with uncertainty in
early architecture [11]. In fact, there is no quantitative method
of even comparing two architectures under uncertainty, let
alone selecting the ‚Äúright‚Äù architecture from the many possible
candidates [1], [11].
In this paper, we describe GuideArch, a quantitative frame-
work and accompanying tool aimed at guid ing the e xploration
of arch itectural solution space under uncertainty. It allows
the architect to make informed decisions using imperfect
information. This alleviates the architect from manually sifting
through an often large solution space, and instead allows her to
focus on the decisions that are critical to the system‚Äôs success.
Unlike any existing approach [1], [5], [13], GuideArch
explicitly represents the inherent uncertainty in the knowledge
and incorporates that in the analysis. It enables an incre-
mental method of making and reÔ¨Åning architectural decisions
throughout the engineering process. As the rough estimates
in the early stages give way to precise estimates in the later
stages, GuideArch allows the architect to reÔ¨Åne the models
and explore other suitable alternatives.
GuideArch employs fuzzy mathematical methods [24] to
reason about uncertainty. We have devised a novel fuzzy oper-
ator that forms the foundation for quantitatively comparing ar-
chitectural candidates under uncertainty. The fuzzy operator is
then used to develop advanced analysis techniques, including
optimization and ranking of architectures, and identiÔ¨Åcation of
critical design decisions.
The remainder of this paper is organized as follows. Sec-
tion II describes a case study and uses it to motivate the
research. Section III provides an intuitive description of the
approach, while Sections IV-VI present the details. Section VII
provides a thorough evaluation of the research. Section VIII
outlines the related research. The paper concludes with a
discussion of limitations and future research.
II. M OTIVATION AND RESEARCH OBJECTIVE
We use a mobile software system, called Situational Aware-
ness System (SAS), to motivate, describe, and evaluate our
research. SAS is developed in collaboration with a government978-1-4673-3076-3/13/$31.00 c2013 IEEE ICSE 2013, San Francisco, USA 41TABLE I
OVERVIEW OF SAS C ASE STUDY .
Decisions H Alternatives H
Location
Finding1: GPS
2: Radio triangulation
File Sharing
Package1: OpenIntents
2: In house
Report
Synchronization1: Explicit
2: Implicit
Chat
Protocol1: XMPP (Open Fire)
2: In house
Map
Access1: On demand (Google)
2: Cached on Server
3: Preloaded (ESRI)
Hardware
Platform1: Nexus 1 (HTC)
2: Droid (Motorola)
Connectivity1: Wi-Fi
2: 3G on Nexus 1
3: 3G on Droid
4: Bluetooth
Database1: MySQL
2: sqlLite
Architectural
Pattern1: Facade
2: Peer-to-peer
3: Push-based
Data Exchange
format1: XML
2: Compressed XML
3: Unformatted dataProperties H
Battery
Usage
Response
Time
Reliability
Ramp up
Time
Cost
Development
Time
Deployment
Time
agency for the deployment of personnel in emergency response
scenarios. SAS is intended to allow the emergency crew
carrying Android devices to share and obtain an assessment of
the situation in real-time (e.g., interactive overlay on maps),
and coordinate with one another (e.g., send reports, chat,
and share video streams). We seized the development of this
software system as an opportunity to perform our study.
In architecting the SAS application, a team, consisting of
academics and engineers from the agency, was formed to
decide among the early design decisions. TABLE I shows
the decisions and alternatives that comprised the SAS project.
The requirements posed by the entities within the agency
sponsoring the project also called for several areas of concern,
which the team derived over several project meetings with the
various stakeholders. The concerns are referred to as properties
of the architecture/system. Although not depicted in the table,
some of the decisions depend on one another. For instance,
the choice of Connectivity depended on the selected Hardware
Platform .
Fig. 1 illustrates the relationship between decisions, al-
ternatives, and properties. Each decision consists of several
viable alternatives, the selection of which results in different
candidate architectures. Each architecture in turn exhibit its
own unique properties, e.g., Response Time andBattery Usage
in Fig. 1 are two such properties. Our experiences with SAS
and other systems show that precisely predicting the impact
of an architectural alternative on the system‚Äôs properties is
extremely difÔ¨Åcult, particularly in early phases of engineering.
This difÔ¨Åculty is due to uncertainty.
Previous approaches targeted at early architecting [1], [5],
[13] have ignored uncertainty, and assumed the impact of
early architectural decisions can be quantiÔ¨Åed precisely. We
collectively refer to them as the traditional approaches in this
Fig. 1. Architectural Pattern decision along with its alternatives and their
impact on the properties in SAS‚Äôs early architecture.
paper. A body of literature (e.g., [3], [6], [16]) has investigated
the use of probabilistic models for representing uncertainty in
the system‚Äôs architecture, but such approaches are only useful
in settings where probabilistic information is available (e.g., at
runtime), which is often not the case in the early architecture
phase.
The challenge motivating this research is how to enable
the architect make informed decisions in such circumstances?
Answering this question requires us to Ô¨Årst understand how the
practitioners make these decisions. Although an architect may
not be able to precisely quantify the impact of decisions on
the system‚Äôs properties, surely she must have some intuition or
rough estimate of their impact, as no successful system comes
to existence through random decisions [20]. This intuition
may be based on the data available from similar designs
in other systems, architect‚Äôs prior knowledge, manufacturer
speciÔ¨Åcation, scientiÔ¨Åc publication, expert judgment, etc. For
instance, as depicted in Fig. 1, when presented with two
alternative architectural patterns for the system, the architect
may be able to distinguish between the two by classifying
one‚Äôs impact on Response Time to be Low, and the other one
asMedium . In some other cases, the architect may have more
speciÔ¨Åc knowledge of the situation and specify the impact as a
range of values. In the example of Fig. 1, the architect speciÔ¨Åes
the impact on Battery Usage as a range. This paper presents
a novel quantitative framework and supporting tool that given
such loosely deÔ¨Åned estimates help the architect with making
the best decisions.
III. A PPROACH
In this section, we Ô¨Årst deÔ¨Åne the scope of our research,
followed by an intuitive description of our approach.
A. DeÔ¨Ånition and Scope of Uncertainty
Before delving into the approach, it is important to clarify
what we mean by uncertainty. The scope of uncertainty dealt
with in our paper has to do with not knowing the exact
impact of architectural alternatives on properties of interest,
i.e., not being able to precisely specify the impact as a crisp
value. However, there are other sources of uncertainty in early
architecting that are not tackled in our work. Consider for
instance the uncertainty introduced by the following questions:42Fig. 2. Evolution of how the architect expresses impact on properties: (a)
enumerated values, where the bold one represents the one that is selected, (b)
range of concrete values, and (c) convergence towards a crisp value.
Have all of the properties of concern been elicited? Have all
of the decisions and alternatives been identiÔ¨Åed? [19] While
the ability to answer such questions is clearly crucial, they fall
outside the scope of our research.
B. Representing Uncertainty in Alternatives
As alluded to in Section II, the architect may estimate the
impact of an alternative on the properties in two ways: (1)
Range: When the architect has a rough estimate of the value,
the architect could specify it as a range, e.g., a particular choice
is anticipated to have 10 Jof battery usage, with 8 Jand
14Jin optimistic and pessimistic situations, respectively. (2)
Enumeration: Sometimes the architect may have no way of
quantifying the impact, even as a range. In such cases, the
architect abstractly speciÔ¨Åes the impact of an alternative in
relation to other alternatives through enumeration, e.g., certain
alternative is likely to have a Low response time. Here, ‚ÄúLow‚Äù
may not say much about the actual values (e.g., seconds),
but nevertheless carries useful information that inÔ¨Çuences the
decisions early on. These two mechanisms are aligned with the
way humans in general conceptualize uncertainty and provide
an intuitive method of modeling the architect‚Äôs imperfect
knowledge.
The key contribution of GuideArch is the ability to pro-
vide quantitative analysis of the trade-offs given such loose
speciÔ¨Åcations. We achieve this by representing the uncertainty
as a fuzzy value . A fuzzy value is founded on the concept
offuzzy set [24]. In a fuzzy set, the elements have a de-
gree of membership. Degree of membership, also known as
possibility , is a value between zero and one: a value of zero
indicates the element is certainly not a member of the set, a
value of one indicates it is certainly a member, and a value in
between indicates the extent of certainty it is a member. Fuzzy
math is grounded in possibility theory [22], which provides
an alternative to that of probability theory, and has shown to
be particularly useful in settings where uncertainty is due to
ambiguity, rather than variability. A common misconception
is that fuzzy math is imprecise. On the contrary, fuzzy math,
just like probability, provides a precise and sound method of
dealing with uncertainty.
We take slightly different approaches to transform the enu-
merated values and range of values to the corresponding fuzzy
representations. As shown in Fig. 2a, the enumerated value
is simply mapped to fuzzy values that divide the normalized
domain equally. We do this because the architect has no way
of quantifying the impact of alternatives on the properties,
yet has some intuitions as to how alternatives compare to one
another. On the other hand, when the architect can specify the
impact as a range (Fig. 2b), we assign the possibility of 1 to
Fig. 3. Uncertainty modeled as fuzzy values using possibility theory: (a)
the fuzzy values for Response Time andBattery usage ; (b) their summation
to determine the architecture‚Äôs total value; and (c) the total value for three
hypothetical architectures.
theanticipated (most likely) value, and possibility of 0 to the
optimistic andpessimistic , respectively. We let the possibility
to decrease linearly from the anticipated to the optimistic and
pessimistic points.
As a software project progresses, the architectural models
become more concrete and enriched with information collected
from simulations and prototypes, subsequently increasing the
accuracy with which impact of alternatives can be estimated.
Thus, as depicted in Fig. 2, we expect to see the impact
of alternatives expressed mostly through enumeration at the
outset of a project to give way to ranges of values in later
iterations, and eventually converge to crisp values toward the
end.
C. Calculating Uncertainty in a Candidate
Using the above approach, the impact of any given alterna-
tive on each property is modeled as a triangular fuzzy value
[24]. As we detail in Section IV-B, these low level measures
of uncertainty are combined to calculate the uncertainty in
the properties of candidate architectures. For instance, Fig. 3a
depicts the fuzzy values corresponding to the Response Time
(P1) and Battery Usage (P2) for an architectural candidate.
We use ‚Äú^‚Äù, ‚Äú<‚Äù, ‚Äú>‚Äù to represent anticipated, optimistic,
and pessimistic, respectively. Due to uncertainty, the actual
value of the property may be anywhere in that range.
Given the fuzzy impact of candidates on properties, we can
quantify the overall value of a given architecture. Assuming
the properties have been normalized to a value in [0,1] range,
and that all properties have the same importance, the total
value for an architecture Arch can be calculated as fuzzy
summation [12] of the impact of candidates on the proper-
ties. When fuzzy numbers are summed up, the pessimistic,
anticipated, and optimistic values are added independently of
each other to arrive at a new fuzzy value. For instance, adding
fuzzy values for Response Time andBattery Usage in Fig. 3a
results in the fuzzy value shown in Fig. 3b, which represents43the total value of the corresponding architecture Arch .1Since
an architecture with a lower value is preferred, we call the
situation in which the actual value is between anticipated and
pessimistic the negative consequence of uncertainty (risk), and
the situation in which the actual value is between anticipated
and optimistic the positive consequence of uncertainty (oppor-
tunity).
D. Comparing Candidate Architectures
Fuzzy summation allows us to transform the multi-
dimensional problem into a single scalar value, where the
architectures can be compared with one another. However,
since the scalar value itself is fuzzy, comparing the archi-
tectural solutions remains a challenge. When comparing two
fuzzy numbers, the one with the ‚Äúbetter‚Äù range is superior.
We say the fuzzy value of one architecture is better than
another if it has a: (C1) smaller anticipated value, (C2) larger
positive consequence of uncertainty, and (C3) smaller negative
consequence of uncertainty [10].
Fig. 3c shows the total value of the properties for three
hypothetical architectures ( A,B, and C), which are represented
as fuzzy values. Using Fig. 3c we describe two possible
scenarios that may occur in comparing architectures this way.
The Ô¨Årst scenario occurs when a given architecture is inferior
to others with respect to all three criteria. For instance, in
Fig. 3c, architecture Ais inferior to architectures Band C
with respect to all three criteria. The second scenario occurs
when there are trade-offs. For instance, architectures BandC
present a trade-off, as architecture Bis superior to architecture
Cwith respect to C2 and C3, and inferior with respect to C1.
Section V describes in detail how we can resolve such trade-
offs. The ability to compare architectures under uncertainty
provides the basis for exploration and making architectural
decisions.
IV. E ARLY ARCHITECTURE SELECTION PROBLEM
Equipped with a basic understanding of the problem and
approach from the previous section, we now delve into the
details. Here, we formally specify the problem of making early
architectural decisions under uncertainty.
A. Decisions and Alternatives
We denote the set of architectural decisions as setD. Each
decisiond2Dhas several alternatives , which we denote
as setAd. We deÔ¨Åne the set of all alternatives as follows:
A=S
d2DAd. The architecture space is a proper subset of
the alternatives, where for each decision there exist one and
only one alternative that is selected as follows:
ASfarchAj8d2D: (9a2Ad:a2arch)^
(8a2arch;a2Ad:@b2Ad:b6=a^b2arch)g
Thus, the size of the architecture space is:Q
8d2DjAdj. For
example, in our case study shown in TABLE I, we have a total
of26334 = 6;912possible architectural candidates.
1The fuzzy summation used here is deÔ¨Åned in [12], which has proven to
produce another proper possibility distribution.For each design alternative a2A, we introduce a binary
decision variable xa, which takes the value of 1 if the
alternative is selected, and 0 otherwise: xai= 1,ai2arch .
B. Properties and CoefÔ¨Åcients
We denote the properties stakeholders are interested in as
setP. For alternative a2Aand property p2Pwe use
~cp;ato denote the effect of design alternative aon property p
and we call it a coefÔ¨Åcient . The tilde accent ‚Äú ‚Äù indicates
that the coefÔ¨Åcient is a fuzzy value. The set of properties
Pis partitioned into two subsets Pmin andPmax, indicating
properties that need to be minimized (e.g., battery usage) and
maximized (e.g., reliability), respectively.
~sp(arch)deÔ¨Ånes the estimate of property p2Pfor a given
architecture arch2AS. This function needs to combine the
impact of individual alternatives on pto estimate the impact of
the candidate architecture on pas a whole. The way this can
occur depends on the nature of the property and the structure
of the candidate architecture.
Certain properties, such as the total battery usage ( bu2P)
of a candidate architecture, can be quantiÔ¨Åed by summing the
coefÔ¨Åcients (impact) of the selected alternatives as follows:
~sbu(arch) =PjAj
i=1(~cbu;aixai). But for some other prop-
erties (e.g., availability), simply summing the contributions
of individual alternatives does not result in a meaningful
quantiÔ¨Åcation of the corresponding candidate‚Äôs property. De-
tailed treatment of such differences is beyond the scope of
this paper. We have relied on the previous work [17] that
has developed mathematical templates for quantifying several
commonly encountered QoS properties at the architectural
level. We simply use our fuzzy operators in the context of
their templates to deal with uncertainty.
As detailed later in the paper, we would like to reason about
the impact of alternatives on several properties with different
units/scales, and thus we normalize ~spas follows:
~nsp(arch) = (~sp(arch) minp)=(maxp minp)
In cases where the absolute minimum and maximum values are
known (e.g., reliability, where minimum is 0% and maximum
is 100%), they could be simply used. Otherwise, Ô¨Årst, for
eachd2D,p2P, we letmaxp;dbe equal to the most
optimistic/pessimistic value of the alternative a2Adthat
achieves the maximum value for p; next,maxpis calculated
by summing all maxp;dvalues.minpcan be calculated in an
inverse of the way maxpis calculated.
C. Priorities
Stakeholders are typically concerned about some properties
more than others. Identifying their concerns and prioritizing
them in terms of risk and importance is the centerpiece of
modern software engineering processes [21]. To that end, for
each property p2P, we deÔ¨Åne an integer p2[0;10]
indicating the priority of property pto stakeholders. The
higher the priority, the more important that property is to
the stakeholders. We chose this particular representation of
priority to be consistent with the existing literature [1], [21],44which gives us some conÔ¨Ådence that stakeholders can indeed
priorities their concerns in this fashion.
D. Total Value of a Candidate Architecture
We let ~s(arch)represent the total value of a candidate
architecture arch2AS, which is calculated by subtracting
the total value of the properties that need to be maximized
from those that need to be minimized as follows:
~s(arch) =X
p2Pminp~nsp(arch) X
p2Pmaxp~nsp(arch)
The goal is to Ô¨Ånd an architecture arch2AS with the
lowest value of ~s(arch), as it results in minimizing the Pmin
and maximizing the Pmax. Here contribution of each property
is controlled by its priority p. Since fuzzy math is closed
under these operations, the total value is also a triangular fuzzy
number.
E. Dependencies, ConÔ¨Çicts, and Constraints
Some architectural candidates may not be valid. An alter-
native from one decision may depend on alternative(s) from
other decisions, requiring them to be enabled. For instance,
as mentioned in Section II, in the case of SAS, Connectivity
decision depends on the choice of Hardware Platform (e.g.,
since GPS capability is not available on certain devices). We
model these dependencies using the function Dep :A!2A,
which given an alternative returns a set of alternatives that are
dependent on it. The dependency constraint for arch2ASis
then formally speciÔ¨Åed as follows:
8a2arch :xaQ
2Dep(a)x (1)
An alternative may also conÔ¨Çict with alternative(s) from
other decisions, requiring them to be disabled Ô¨Årst, and vice
versa. We model these conÔ¨Çicts using the function Con :A!
2A, which given an alternative returns a set of alternatives that
conÔ¨Çict with it. We formalize these constraints for arch2AS
as follows:
8a2arch :xaP
2Con(a)x= 0 (2)
A property may have certain thresholds (i.e., limitations).
For instance, battery usage may be required to be less than 100
J. Given the set Thd representing those property constraints,
we formally specify these relationships as follows:
8p2Pmax:Thdp~sp(arch)
8p2Pmin: ~sp(arch)Thdp(3)
V. C OMPARING ARCHITECTURES
Recall from Section IV-D that a smaller value of ~sindicates
a better architecture. We say between two valid architectures
arch 1;arch 22AS,arch 1is better than arch 2, if:
~s(arch 1)~s(arch 2) (4)
This is a fuzzy comparison [7], [10], since the two sides
are fuzzy numbers. Here we are comparing the fuzzy range
of possible values for the two architectures. We formal-
ize this by breaking down the fuzzy operator into three
comparisons. Let zaS^represent the anticipated value,
Fig. 4. Intuition behind fuzzy comparison operator.
zpjS^ S<jrepresent the positive consequence of un-
certainty, and znjS> S^jrepresent the negative conse-
quence of uncertainty. Fig. 4 provides the intuition behind
the three comparisons, where a smaller value of zaandzn,
and a larger value of zpare collectively considered to be
representative of a smaller fuzzy value, and thus a better
architecture. We thus rewrite Equation 4 as:
~s(arch 1)~s(arch 2),za1za2;zp1zp2;zn1zn2(5)
The three comparisons on the right are formal representa-
tions of the three criteria from Section III-D.
Our fuzzy comparison operator is an instance of a multi-
dimensional comparison [4], and to decide which range is
lower, we Ô¨Årst need to transform it to an equivalent single-
dimensional comparison. This is necessary to allow us to
reason about the trade-offs, such as those depicted in Fig. 3c.
The transformation process entails (1) normalizing the values
being compared, (2) combining the comparison dimensions,
and (3) if necessary, weighting the comparisons differently. In
the remainder of this section, we provide a detailed description
of these three steps.
A. Normalizing the Values Being Compared
Since thezvalues are deÔ¨Åned differently in terms of
~s(arch), they are not comparable. Therefore, before combin-
ing the comparisons, we Ô¨Årst have to normalize the zvalues.
We use normalizing linear membership function [14], which
is a function that maps each zto a value between 0 and 1:
8i2fa;p;ng: (zi:dom(zi) ![0;1]).
This allows us to have zvalues with the same range.
For deÔ¨Åning each function , we Ô¨Årst need to determine the
two extremums for each z: the extremum minimizing zis
called Positive Ideal Solution (PIS), and the one maximizing
zis called Negative Ideal Solution (NIS). We can obtain
these values by performing the following optimizations, where
argmin andargmax Ô¨Ånd the minimum and maximum values
respectively:
zPIS
aargmin (arch2AS)za;zNIS
aargmax (arch2AS)za
zPIS
pargmax (arch2AS)zp;zNIS
pargmin (arch2AS)zp
zPIS
nargmin (arch2AS)zn;zNIS
nargmax (arch2AS)zn
Note that the NIS and PIS deÔ¨Ånitions for zaandznare
reverse of that of zpdue to their semantic differences (i.e.,
we prefer a solution with small zaandzn, and largezp). We
specifyto return 0 for the PIS value, 1 for the NIS value,
and proportionally linear between the two extremums:45za8
>>>>>>>>><
>>>>>>>>>:0 za<zPISa
za zPIS
a
zNISa zPISazPISaza
zazNISa
1 zNISa<zazp8
>>>>>>>>><
>>>>>>>>>:1 zp<zNISp
zPIS
p zp
zPISp zNISpzNISpzp
zpzPISp
0 zPISp<zp
znis speciÔ¨Åed similar to za. Fig. 5 shows instances of za
andzpthat normalize the outputs of zaandzp, respectively.
Since the deÔ¨Ånitions of NIS and PIS are reversed, the nor-
malizing function zaandznare increasing, while zpis
decreasing.
DeÔ¨Åning the normalization functions this way also allows
us to Ô¨Çip the comparison for zp. In other words, zp1zp2becomes the normalized equivalent of zp1zp2. Thus, we
rewrite Equation 5 using the normalized values as follows:
~s(arch 1)~s(arch 2),8i2fa;p;ng:zi1zi2(6)
B. Combining the Comparisons
Given that now we are dealing with three comparisons that
have the same range and direction (i.e., less than or equal), we
use a conventional technique [14], [23] to transform the multi-
dimensional comparison of Equation 6 to a single-dimensional
form. We deÔ¨Åne 'to be the maximum of the three normalized
values as follows:
'=maxi2fa;p;ngzi (7)
Therefore, ~s(arch 1)~s(arch 2),'1'2. While this
transformation may not hold for three arbitrary comparisons,
since here the numbers are constrained by the triangular
relationship that comprises a fuzzy value, the transformation
is universally valid (see [23]). Hence, if the value of '1for
arch 12ASis less than the value of '2forarch 22AS, we
concludearch 1has a lower range, and more desirable. For
all practical purposes, it is also possible to use the summation
of the normalized values as a collective approximation of the
extent in which one architecture is better than the other [10].
C. Weighting the Comparisons
In the above formulation, the three comparisons have the
same importance, which is not necessarily the case in certain
domains. For instance, in risk-averse domains, it is typically
desirable to put more emphasis on reducing the negative
consequence of uncertainty (risk) and achieve some level of as-
surance. Thus, a conservative architecture, where minimizing
zntakes precedence over others, is preferable. We achieve this
by assigning weights wa,wp,wn, wherewa+wp+wn= 1,
to normalized values za,zp, andzn, respectively. The
weights specify the importance of each comparison relative to
Fig. 5. Linear Membership Function for (a) zaand (b) zp.others. Thus, we rewrite Equation 7 by including the weights
as follows:
'=maxi2fa;p;ngwizi
VI. E XPLORING THE SOLUTION SPACE
The ability to compare architectures under uncertainty pro-
vides the foundation for architectural exploration. We now
describe four ways in which GuideArch helps with this.
A. Identifying Valid Architectures and Critical Constraints
GuideArch allows us to identify the subset of architectural
solutions that are ‚Äúvalid‚Äù, even when there is uncertainty in
the knowledge. An architecture is valid, if it satisÔ¨Åes the
constraints presented in Section IV-E. An issue is how to check
the property constraints, since they involve comparing the crisp
value (i.e.,Thd) with a fuzzy value (i.e., ~sp(arch)). Consider
for instance a constraint for the cost of realizing an architecture
(which is one of the properties as you may recall Table I) to be
less than $10,000. Evaluation of this constraint is challenged
by the fact that the estimated cost of realizing the architecture
is a fuzzy value.
Constraints, including those speciÔ¨Åed on properties, are
intended to be treated as absolute limitations, and thus we
consider the worst case, which occurs at the pessimistic
point (i.e.,s>
p). Thus, we rewrite the property constraints of
Equation 3 as follows:
8p2Pmax:Thdps>
p(arch)
8p2Pmin:s>
p(arch)Thdp(8)
Comparing the threshold with the worst case ensures an
architectural candidate is valid, even when the negative con-
sequence of uncertainty takes effect.
The ability to identify valid architectures not only ensures
the architect does not pick a solution that is invalid, but can
also be used to provide useful statistical measures. GuideArch
provides the percentage of architectures in the solution space
that are disqualiÔ¨Åed by each constraint. This allows the archi-
tect to identify the limiting constraints, and to explore their
trade-offs. If certain trade-offs are deemed appropriate, they
could be communicated to other stakeholders, and thereby set
the stage for revising the constraints through negotiations.
B. Finding the Optimal Architecture
GuideArch could also be used to Ô¨Ånd the optimal ar-
chitecture under uncertainty. An architecture is optimal for
a given problem if it achieves the minimum value of '
and satisÔ¨Åes the three types of constraints described in Sec-
tion IV-E. We deÔ¨Åne this as a linear programming problem of
argmin (arch2AS)'arch, which is subject to the constraints of
Equations 1, 2, and 8
Here, the solver uses the approach described in Section V
to compare the total value of properties between the candidate
solutions. The architecture with the minimum value of 'is
the one that achieves the best combination of small anticipated
value, small risk, and large opportunity.46C. Ranking the Architectures
The ability to Ô¨Ånd the optimal solution is complemented
with the ability to see a ranking of candidates. There are
several reasons for this. First of all, architects bring valuable
domain expertise and experience that cannot be represented in
existing tools, including GuideArch. Thus, it is possible that
an architect may select an architecture that is slightly worse
than optimal for reasons that are not modeled in the tool.
Reasons for such decisions could range from unfounded biases
(e.g., preference for not purchasing products from a particular
company) to technical intuitions (e.g., emerging standards).
Secondly, the ability to see the top ranked candidates allows
the architect to gain insights into why GuideArch selected a
solution as optimal. Such rankings could help the architect
gain a better understanding of the trade-offs, and increase her
conÔ¨Ådence in the analysis.
GuideArch uses the ability to compare architectures, de-
scribed in Section V, to also rank them from best (top) to worst
(bottom). We let Rrepresent the ranking of top tarchitectures
as an ordered list:
Rharch 1;:::;arch tiwherearchi2AS^
(8archi2R:@c2AS^c =2R: ~s(c)~s(archi))^
(8archi;archk2R;ik: ~s(archi)~s(archk))
Value oftis a conÔ¨Ågurable threshold in GuideArch. Here,
candidates with better (lower) range appear at the top.
D. Identifying and Ranking the Critical Decisions
Modern software processes advocate an iterative approach,
where in each iteration the decisions made in the previous
cycles are assessed and risks are mitigated [21]. Generally, it
is desirable to resolve decisions that pose a high risk early
on, and architecture is typically considered to provide the
appropriate level of abstraction to enable such analysis [21].
GuideArch helps the architect identify decisions that are
likely to be critical to the success of the project, and thus
pose the greatest risk. The insight is that a decision dis likely
to be crucial if it satisÔ¨Åes the following two criteria:
1)Magnitude of Impact : The selected alternatives from a
decision have a big impact on the properties of top
ranked architectures. This is reasonable, as the architect
is likely to select one of the top ranked architectures,
and if a particular decision contributes heavily to those
architectures, it is likely to be a crucial decision, i.e.,
getting it ‚Äúwrong‚Äù results in a large error.
2)Uncertainty of Impact : The impact of selected alterna-
tives from decision don the top ranked architectures is
highly uncertain. When there is a lot of uncertainty in
the impact of a decision on the top ranked architectures,
there is an increased possibility of error.
When the two criteria are present in a decision, we say that
the decision is critical, as it is both signiÔ¨Åcant and risky.
We quantify the impact of an alternative a2Aon the
properties as follows:
~Ea=P
p2Pmin
p~cp;a
maxp
 P
p2Pmax
p~cp;a
maxpWe then deÔ¨Åne the impact of a decision d2Don the
properties of the top tranked architectures as follows:
~Ed=Pt
r=1~Eawherea2archr^a2Ad
~Edis the magnitude of impact due to decision don the
top ranked architectures. This approach gives equal weight
to the choices made in the ranked architectures. However,
since the architect is more likely to select from architectures
that are ranked at the top, over those that are ranked at
the bottom, we discount the inÔ¨Çuence based on the order.
Thus, we reformulate the above equation by incorporating a
logarithmic decay to discount the inÔ¨Çuence of alternatives as
we traverse from the top to bottom of ranked architectures:
~Ed=Pt
r=1~Eae rwheree ris the formulation of
logarithmic decay, and is the decay factor. The larger ,
the more emphasis is placed on the alternatives appearing
at the top of the ranking. This is a heuristic that per our
experience most naturally captures the increased likelihood
of the architect selecting the higher ranked architectures, but
using other decay factors (e.g., linear decay ) is also possible.
Unlike the ranking of architectural candidates, where we
are interested in the best solutions, here we are interested in
Ô¨Ånding the most critical (worst) decisions. We use the fuzzy
comparison operator to rank the decisions from worst (top)
to best (bottom). Recall from Section V that this operator not
only measures the magnitude of impact, but also the range of
uncertainty. Let Lbe the ranking of nmost critical decisions
as an ordered list:
Lhd1;:::;dniwheredi2D^
(8di2L:@c2D^c =2L:~Ec~Edi)^
(8di;dk2L;ik:~Edi~Edk)
The top ranked decisions are good candidates to be inves-
tigated further to mitigate risk. Based on this information, the
architect may take a number of actions, such as expanding
the critical decisions by allowing for additional alternatives,
or simply reducing the uncertainty by investing resources and
time (e.g., prototyping) to develop a better understanding of
the alternatives‚Äô impact.
VII. E VALUATION
Evaluation of software architecture research is difÔ¨Åcult, as
it often hinges on industry participation. We feel fortunate to
have had a unique opportunity to employ and evaluate our
research in the context of a real world project. GuideArch
was used by a team of engineers and academics to explore
the architectural space of the SAS project. In addition, we
have tried to augment our experiences in the real-world with
the experiments performed in the laboratory.
The study was supported by an interactive tool realizing
GuideArch. Fig. 6 shows two snapshots of the tool: in the
back we have the screen used for getting the architect‚Äôs
input as to the expected range of impact each alternative
may have on the system properties (recall ~cp;a), while in the
front we have the screen displaying the critical decisions and
their impact (recall ~Ed) on the properties of the top ranked
architectures. The tool is web-accessible to facilitate sharing,47Fig. 6. Snapshots of GuideArch in action showing the coefÔ¨Åcients (back) and
critical decisions (front).
collaboration, and negotiation among the various stakeholders.
We used Microsoft RSilverlightTMas our platform, which has
appropriate plug-ins for mainstream web browsers. The tool is
integrated with Microsoft RSolver Foundation for optimization
purposes. The tool also provides several features to enable ex-
ploration of the architectural space, including color coding to
indicate the importance of decisions and measure the quality of
candidate architectures, and ranking of the architectures based
on various tunable parameters. For the sake of readability, we
do not use snapshots of the tool for presenting the evaluation
results, and refer the reader to the project site to access the
tool and case study data.2
In this section, we Ô¨Årst describe some of the salient out-
comes of this study, followed by the results obtained through
additional experiments in the laboratory.
A. Critical Constraints
One of the early requirements posed by the client in SAS
was to keep the cost of a single handheld device (includes
the cost of the hardware and off-the-shelf software packages)
below $750. While the team already had a hunch that the
requirement was overly constraining, there was no method of
establishing the extent of it. In particular, since the impact of
most alternatives on properties was uncertain, the team had
no way of knowing exactly what portion of the architectural
space would be disqualiÔ¨Åed by such a constraint. Using the
technique described in Section VI-A, GuideArch showed that
this constraint alone disqualiÔ¨Åes 5,040 candidates out of 6,912
potential solutions. This allowed the stakeholders to obtain a
quantitative, yet intuitive, assessment of the cost constraint
on the choices. In a series of negotiations the stakeholders
agreed to relax the constraint by increasing the limit to $1,000.
This increased the number of valid architectures, which in turn
resulted in Ô¨Ånding better candidates. However, even the relaxed
2Available at http://mason.gmu.edu/ nesfaha2/Projects/GuideArch.constraint disqualiÔ¨Åed 4,032 architectures and remained as the
critical constraint in the project. In the remainder of analyses
and experiments reported here, the relaxed cost constraint was
used.
B. Ranking
Fig. 7 shows the (Ô¨Çattened) triangular fuzzy value of 10
sample SAS architectures calculated by GuideArch. The hor-
izontal axis marks the architectures‚Äô rankings. As you may
recall from Section V, one architecture is better than another if
it has a lower zaandzn, and a larger zp. In SAS, we gave equal
weights to the satisfaction of each of those conditions (i.e.,
wa=wn=wp= 1=3). Looking at Fig. 7 we can gain insights
into the analysis performed by GuideArch. For instance, 1st
architecture, which is picked as optimal by GuideArch, has
the best combination of three zvalues, i.e., it has a lower
za, smallerzn, and larger zpthan the majority of candidates.
As a result, while 1st architecture may be slightly inferior to
some candidates with respect to one of the three conditions,
it achieves the best set of trade-offs.
C. Optimal Architecture
To illustrate the beneÔ¨Åts of GuideArch, we compare it
against what we call the traditional approach. Recall from
Section II that by traditional approach we collectively refer
to any prior research that performs the analysis based on
point estimates (i.e., ignores uncertainty). More speciÔ¨Åcally,
here we compare the results of GuideArch against that of
ArchDesigner [1], which has aimed to solve a similar problem
as that described in this paper, albeit without considering
uncertainty.
We observed that the traditional approach would have
selected the 486th candidate in Fig. 7 as the optimal solution.
Traditional approaches only minimize the anticipated value
(za). Comparing the difference between 1st and 486th candi-
dates sheds light on the contributions of GuideArch. 486th ar-
chitecture achieves the lowest zaamong all valid architectures,
including the 1st architecture. However, 486th architecture has
a very large negative consequence of uncertainty, which has
been ignored by the traditional approach. On the other hand,
GuideArch selects a solution that has a slightly inferior za,
but with a better range of uncertainty.
Fig. 7. The triangular fuzzy value of 10 architectural candidates in SAS.48Fig. 8. Critical decisions: (a) comparing the decisions in the Ô¨Årst iteration and
(b) improvement in the optimal architecture after revising the critical decision
in the subsequent iteration.
D. Critical Decisions
GuideArch was also used to identify the critical decisions.
Fig. 8a shows the estimated impact of decisions (i.e., ~Ed) as
well as the ranges of uncertainty in those estimates, which as
you may recall from Section VI-D determine their criticality.
We can see Location Finding is the most critical decision, since
(1) it has a large effect on the ranked architectures, indicated
by high y-axis position, and (2) has a very large range of
uncertainty, indicated by the span of the arrow. If we use
the fuzzy comparison operator (recall Section V), Location
Finding ‚Äôs~Edis larger than all other decisions.
This analysis formed the Ô¨Årst iteration of using GuideArch.
It helped the team identify the critical decisions early on,
and focus additional efforts on studying them. As a result,
the team came across an advanced state-of-the-art variation
of the traditional radio triangulation [15] that presented the
project with a new alternative for Location Finding . Given that
a prototype of this solution had been developed, evaluated,
and published [15], the new alternative was estimated to have
signiÔ¨Åcantly smaller battery usage, faster response time, and
smaller range of uncertainty. GuideArch was applied to the
revised problem. Fig. 8b shows the range of total value (i.e.,
~s) for the best candidate architecture picked by GuideArch in
this second iteration, compared to the best candidate picked
in the Ô¨Årst iteration. As Fig. 8b shows, the introduction of
the new alternative (i.e., smart radio triangulation) improved
the total value of the optimal architecture, and reduced the
uncertainty.
E. Tuning GuideArch
In the SAS project, we gave the same weight to the three
comparisons (i.e., wa=wn=wp= 1=3). However, recall from
Section V-C that weights could be used to tune GuideArch to
be more conservative or bold in its analysis. We performed a
set of experiments on the SAS model to assess the impact of
weights on the optimal architecture selected by GuideArch.
To allow for comparison, in Fig. 9, we show the result
for the balanced weight assignment (i.e., [1/3,1/3,1/3]), which
corresponds to the candidate ranked 1st in Fig. 7. Also note
that when wa= 1 andwn=wp= 0, GuideArch behaves
exactly like the traditional approach. Therefore, the optimal
architecture for that weight assignment in Fig. 9 (i.e., [0,1,0])is the same as candidate ranked 486th in Fig. 7. This is because
the consequence of uncertainty is ignored.
As expected, in the two experiments with high wn,
GuideArch selects a conservative solution, i.e., puts more em-
phasis on minimizing the negative consequence of uncertainty.
In the two experiments with high wp, GuideArch selects a
risky solution, i.e., puts more emphasis on maximizing the
positive consequence of uncertainty. Both approaches come
at the cost of achieving mediocre anticipated total value.
While in our experiments a balanced weight assignment has
shown to achieve the most appropriate trade-offs, we can
envision situations in which placing emphasis on one of
the comparisons may be more appropriate, which GuideArch
allows for naturally.
VIII. R ELATED WORK
Making architectural decisions is a problem that has been
studied from both design-time and run-time perspectives. The
uncertainty issues in the latter have been mainly researched in
the area of autonomic computing [8]. Here we discuss only
those targeted at design-time, since that has been the focus of
our work.
ArchDesigner [1] is an approach to Ô¨Ånd an optimal ar-
chitecture that meets conÔ¨Çicting stakeholders‚Äô quality goals.
ArchDesigner uses linear programming to Ô¨Ånd the optimal
architecture. CBAM [13] is a quantitative approach for eco-
nomic modeling of software engineering decisions, which
builds upon ATAM [5]. CBAM provides the cost and beneÔ¨Åt
of different architectural candidates. ArcheOpterix [2] is a tool
for optimizing an embedded system‚Äôs architecture. It uses evo-
lutionary algorithms for multi-objective optimization of such
systems. While many of these approaches acknowledge the
challenges posed by uncertainty, none addresses it explicitly
and via a mathematical framework.
Palladio [3] uses information about components comprising
the architecture to derive analytical models and simulate the
system‚Äôs performance. Random variables are used to specify
uncertainty in service demands and iterations. Meedeniya et al.
[16] estimate the reliability of a given software architecture by
combining reliability of its elements (expressed as probability
distributions) using Monte Carlo simulation. These approaches
are complementary to GuideArch, as they could be used in
the later phases of software architecting, where probabilistic
Fig. 9. The optimal architecture for different weights.49information about the components comprising a software
system can be obtained (e.g., from prototypes).
Doyle et al. [6] present an approach to compare candidate
architectures, assuming the availability of a probability dis-
tribution representing the response time of each architecture.
Instead of fuzzy math, they rely on extensive integration to
compare the distributions, which are computationally expen-
sive, making their approach inapplicable to large systems.
Noppen et al. [18] use design tree to navigate in the
design space, which may include imperfect information. They
consider each alternative independent of others. GuideArch,
on the other hand, considers all alternatives inÔ¨Çuencing the
system‚Äôs properties at the same time.
Finally, in a short position paper [9], we have argued for
the utility of fuzzy logic in addressing the uncertainty issues
in early architecture.
IX. C ONCLUSION
In any software project, early architectural decisions repre-
sent some of the most crucial decisions engineers ever make.
Yet there is a lack of techniques and tools for helping the
engineers to make those decisions. We presented GuideArch,
a novel framework that guides the engineers in making the best
choices possible under uncertainty. It provides a combination
of capabilities, such as ranking the architectures, Ô¨Ånding the
optimal, and identifying the critical decisions, that collectively
help with the exploration of the solution space. GuideArch is
tunable, allowing the engineer to set the analysis to be as
conservative as desired.
While thorough evaluation of GuideArch in the context of
a case study as well as laboratory experiments allowed us to
experience its beneÔ¨Åts Ô¨Årsthand, it also revealed several areas
of future improvement. One area of future work is to extend
the current model from a uniÔ¨Åed stakeholder perspective to
amultiple stakeholder perspective. We currently assume all
stakeholders have agreed on the impact of alternatives on
properties and their priorities. However, this may not always
be the case, presenting GuideArch with yet another source of
uncertainty. Future work also includes extending GuideArch
to deal with the other types of uncertainty discussed in
Section III-A. Moreover, GuideArch currently represents un-
certainty as a triangular fuzzy value , which is not only the
most widely used fuzziÔ¨Åcation approach, but also universally
applicable. However, in our future work, we also plan to
experiment with alternative representations (e.g., trapezoidal
and Gaussian ) that seem to offer some unique trade-offs.
ACKNOWLEDGEMENTS
We would like to thank Thabet Kacem and Ehsan Kourosh-
far for their help and the anonymous ICSE reviewers for
their feedback. This work is supported in part by awards
P010033816 and P010033886 from Science Applications In-
ternational Corporation, D11AP00282 from the Defense Ad-
vanced Research Projects Agency, CCF-1217503 and CCF-
1252644 from the National Science Foundation. Any opinions
and conclusions expressed in this material are those of the
authors and do not reÔ¨Çect the views of the funding agencies.REFERENCES
[1] T. Al-Naeem, I. Gorton, M. A. Babar, F. Rabhi, and B. Benatallah, ‚ÄúA
quality-driven systematic approach for architecting distributed software
applications,‚Äù in Int‚Äôl Conf. on Software Engineering , St. Louis, Mis-
souri, May 2005, pp. 244‚Äì253.
[2] A. Aleti, S. Bjornander, L. Grunske, and I. Meedeniya, ‚ÄúArcheOpterix:
an extendable tool for architecture optimization of AADL models,‚Äù
inICSE Workshop on Model-Based Methodologies for Pervasive and
Embedded Software , Vancouver - Canada, May 2009, pp. 61‚Äì71.
[3] S. Becker, H. Koziolek, and R. Reussner, ‚ÄúThe palladio component
model for model-driven performance prediction,‚Äù J. Syst. Softw. , vol. 82,
no. 1, pp. 3‚Äì22, Jan. 2009.
[4] S.-J. Chen and C.-L. Hwang, Fuzzy Multiple Attribute Decision Making:
Methods and Applications , 1st ed. Springer, Feb. 1992.
[5] P. Clements, R. Kazman, and M. Klein, Evaluating Software Architec-
tures: Methods and Case Studies . Addison-Wesley Professional, Nov.
2001.
[6] G. S. Doyle, ‚ÄúA methodology for making early comparative architecture
performance evaluations,‚Äù Ph.D. dissertation, George Mason University,
Dec. 2010. [Online]. Available: http://hdl.handle.net/1920/6361
[7] D. Dubois and H. Prade, ‚ÄúRanking fuzzy numbers in the setting of
possibility theory,‚Äù Information Sciences , vol. 30, no. 3, pp. 183‚Äì224,
Sep. 1983.
[8] N. Esfahani, E. Kouroshfar, and S. Malek, ‚ÄúTaming uncertainty in
self-adaptive software,‚Äù in Int‚Äôl Symp. on the Foundations of Software
Engineering , Szeged, Hungary, Sep. 2011, pp. 234‚Äì244.
[9] N. Esfahani, K. Razavi, and S. Malek, ‚ÄúDealing with uncertainty in early
software architecture,‚Äù in Int‚Äôl Symp. on the Foundations of Software
Engineering , Cary, North Carolina, Nov. 2012.
[10] G. Facchinetti and R. Ghiselli Ricci, ‚ÄúA characterization of a general
class of ranking functions on triangular fuzzy numbers,‚Äù Fuzzy Sets and
Systems , vol. 146, no. 2, pp. 297‚Äì312, Sep. 2004.
[11] D. Garlan, ‚ÄúSoftware engineering in an uncertain world,‚Äù in FSE/SDP
Wrkshp. on the Future of Software Engineering Research , Santa Fe, New
Mexico, Nov. 2010, pp. 125‚Äì128.
[12] A. Kaufmann and M. M. Gupta, Fuzzy mathematical models in engi-
neering and management science . North-Holland, 1988.
[13] R. Kazman, J. Asundi, and M. Klein, ‚ÄúQuantifying the costs and beneÔ¨Åts
of architectural decisions,‚Äù in Int‚Äôl Conf on Software Engineering ,
Toronto, Canada, May 2001, pp. 297‚Äì306.
[14] Y .-J. Lai and C.-L. Hwang, ‚ÄúA new approach to some possibilistic linear
programming problems,‚Äù Fuzzy Sets Syst. , vol. 49, no. 2, pp. 121‚Äì133,
Jul. 1992.
[15] K. Lin, A. Kansal, D. Lymberopoulos, and F. Zhao, ‚ÄúEnergy-accuracy
trade-off for continuous mobile device location,‚Äù in Int‚Äôl Conf. on Mobile
systems, applications, and services , San Francisco, California, Jun. 2010,
pp. 285‚Äì298.
[16] I. Meedeniya, I. Moser, A. Aleti, and L. Grunske, ‚ÄúArchitecture-based
reliability evaluation under uncertainty,‚Äù in Int‚Äôl Conf on the Quality of
Software Architectures , Boulder, CO, Jun. 2011, pp. 85‚Äì94.
[17] D. A. Menasce, J. P. Sousa, S. Malek, and H. Gomaa, ‚ÄúQoS architec-
tural patterns for self-architecting software systems,‚Äù in Int‚Äôl Conf. on
Autonomic Computing , Washington, DC, Jun. 2010, pp. 195‚Äì204.
[18] J. Noppen, P. van den Broek, and M. Aksit, ‚ÄúSoftware development
with imperfect information,‚Äù Soft Comput. , vol. 12, no. 1, pp. 3‚Äì28,
Aug. 2007.
[19] M. Nowak, C. Pautasso, and O. Zimmermann, ‚ÄúArchitectural decision
modeling with reuse: challenges and opportunities,‚Äù in ICSE Wrkshp
on Sharing and Reusing Architectural Knowledge , Cape Town, South
Africa, May 2010, pp. 13‚Äì20.
[20] D. Tofan, M. Galster, and P. Avgeriou, ‚ÄúCapturing tacit architectural
knowledge using the repertory grid technique,‚Äù in Int‚Äôl Conf on Software
Engineering , Waikiki, Honolulu, Hawaii, May 2011, pp. 916‚Äì919.
[21] Y . Yang and B. Boehm, ‚ÄúImproving process decisions in COTS-based
development via risk-based prioritization,‚Äù Software Process: Improve-
ment and Practice , vol. 12, no. 5, pp. 449‚Äì460, Sep. 2007.
[22] L. A. Zadeh, ‚ÄúFuzzy sets as a basis for a theory of possibility,‚Äù Fuzzy
Sets Syst. , vol. 100, pp. 9‚Äì34, Jun. 1999.
[23] H. J. Zimmermann, ‚ÄúFuzzy programming and linear programming with
several objective functions,‚Äù Fuzzy Sets and Systems , vol. 1, no. 1, pp.
45‚Äì55, Jan. 1978.
[24] H.-J. Zimmermann, Fuzzy Set Theory and its Applications (4th Edition) ,
4th ed. Springer, Oct. 2001.50