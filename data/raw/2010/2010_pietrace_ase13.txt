PIEtrace: Platform Independent Executable Trace
Yonghwi Kwon, Xiangyu Zhang, and Dongyan Xu
Department of Computer Science, Purdue University
West Lafayette, Indiana, USA
{kwon58,xyzhang,dxu }@cs.purdue.edu
Abstract —To improve software dependability, a large number
of software engineering tools have been developed over year s.
Many of them are difﬁcult to apply in practice because their
system and library requirements are incompatible with thos e
of the subject software. We propose a technique called platform
independent executable trace . Our technique traces and virtualizes
a regular program execution that is platform dependent, and
generates a stand-alone program called the trace program . Run-
ning the trace program re-generates the original execution . More
importantly, trace program execution is completely indepe ndent
of the underlying operating system and libraries such that i t can
be compiled and executed on arbitrary platforms. As such, it
can be analyzed by a third party tool on a platform preferred
by the tool. We have implemented the technique on x86 and
sensor platforms. We show that buggy executions of 10 real-
world Windows and sensor applications can be traced and
virtualized, and later analyzed by existing Linux tools. We also
demonstrate how the technique can be used in cross-platform
malware analysis.
I. I NTRODUCTION
To improve software dependability, researchers and engi-
neers have developed a large number of software engineering
tools over years. Although many of them have very advanced
capabilities, they do not gain popularity in practice. One o f the
issues is that they often require certain environmental sup port,
such as speciﬁc operating system, libraries, and the presen ce of
some infrastructure (e.g. Valgrind). These requirements m ay be
incompatible with those of the subject software. For instan ce,
Windows software cannot make use of the large body of
Linux tools. A subject software that requires a new version o f
libc can hardly use a runtime tool based on an older version
oflibc . In our personal conversation with researchers and
engineers from CoverityR/circlecopyrt, one of the most successful software
testing and debugging service providers, it was mentioned t hat
making Coverity’s tools run on the customers’ machines and
their software is one of the most prominent challenges. They
indeed have a team of developers whose responsibilities are
solely in ensuring compatibility. The team is even larger th an
most of their tool development teams.
Compatibility and platform independence are not a new
challenge in our discipline. In fact, people have made a lot
of progress in mitigating such problems in recent years. The
invention of virtual machines allows running different gue st
operating systems on a singe host operating system. However ,
virtualization is performed at the machine level and hence
applying a cross-platform software engineering tool is sti ll
difﬁcult. For example, one cannot apply an existing Linux to ol
on a Windows program execution even with the help of VMtechniques. We also have excellent cross-platform analysi s in-
frastructures such as Pin that support both Linux and Window s
such that a Pin tool developed for Linux programs only needs
small modiﬁcations to adapt to Windows programs. However,
only tools developed on Pin can beneﬁt from this feature.
Moreover, Pin only supports a very limited set of instructio n
sets. For example, one cannot use Pin tools to analyze sensor
program execution. Programs and tools written in languages
such as Java are by their nature platform-independent due
to the presence of Java Virtual Machine. However, there are
many programs that run natively without any virtual machine
support. PIEtrace is focused on those programs.
Modern compiler infrastructures, e.g. LLVM, also try hard
to improve portability and mitigate cross-platform issues . They
can compile code written in different languages and for diff er-
ent platforms to the same intermediate representation (IR) such
thatstatic program analysis written on these infrastructures can
be used to analyze software from different platforms. Howev er,
it is only good for static analysis. The execution of a progra m
compiled by these infrastructures is platform dependent. I n
other words, these infrastructures offer limited help in cr oss-
platform application of dynamic analysis tools.
In this paper, we propose a novel technique called platform
independent executable trace (PIEtrace). Our technique traces
and virtualizes a regular program execution (or part of it) t hat
is platform dependent, and generates a program called the
trace program . A trace program is a stand-alone program that
can be compiled and executed on other platforms. Running
a trace program re-generates the original execution. More
precisely, it reproduces an execution that exhibits the same
user-space control ﬂow, values and program dependences as
the original execution . Trace program execution is completely
independent of the underlying operating system and any li-
brary such that it can be on arbitrary platforms. The applica tion
scenario is as follows. We provide a tracing/virtualizatio n
component for each platform that we support. Such compo-
nents are written in infrastructures such as Pin and sensor
emulators. Executing a program on the component produces
the corresponding trace program. The trace program can be
compiled and executed on any environment that a third party
tool prefers. For example, one can compile and execute a
trace program generated from a sensor program execution on
a Linux platform such that Linux runtime tools can be applied .
Our technique also supports projecting the analysis result s
back to the original platform, to facilitate in-context hum an
inspection.978-1-4799-0215-6/13 c2013 IEEE ASE 2013, Palo Alto, USA
Accepted for publication by IEEE. c2013 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/
republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.48Compared to the traditional tracing techniques [24], [47], we
do not require tools to support a speciﬁc trace format. Exist ing
third party tools on various platforms that analyze program
execution can be used to analyze trace program execution. Th is
would greatly improve tool applicability. Moreover, our te ch-
nique does not require the physical presence of trace, which
is very resource consuming. Compared to traditional loggin g
and replay techniques [6], [33], trace program execution ca n be
cross-platform (even cross-instruction set), without req uiring
the original OS or libraries. Trace programs execute on thei r
own, without any replay runtime support.
Our contributions are summarized as follows.
•We propose the novel concept of platform independent
executable trace , which can be considered as an adaptor
for existing dynamic analysis tools.
•We address the underlying technical challenges. Trace
program is not a simple recording of the sequence of
executed instructions. It is more like a transformation
of the original program. An instruction in the original
program has only one virtualized copy in the trace
program even though it may be executed many times.
Our technique suppresses dependences on the underlying
hardware, operating systems, and libraries, leveraging a
novel lazy-logging method. The method does not require
the tracing component to understand any system/library
interfaces to achieve independence. Our technique en-
sures that execution of the trace program generates the
original control ﬂow by handling direct, indirect, and even
unexpected control ﬂow transfers caused by interrupts and
exceptions. It also guarantees the same values and data
ﬂow to be reproduced by properly virtualizing memory
and registers of the original program.
•We have implemented PIEtrace on x86 and sensor plat-
forms. We evaluate PIEtrace by tracing/virtualizing buggy
executions of 10 real-world Windows and sensor ap-
plications including Acrobat Reader . We then use
existing Linux debugging tools to identify the root causes
of these bugs. We also show case that our technique
can be used to virtualize Windows malware execution
including packed malware so that the malware trace
programs can be executed and analyzed as many times as
desired. PIEtrace and its benchmarks are available at [23]
Limitations. PIEtrace guarantees to reproduce the user space
behavior of the original execution. Library function execu tion
is in the user space and hence faithfully reproduced. In
contrast, system level behavior, such as the execution insi de
a system call is invisible to PIEtrace. PIEtrace does not kno w
the semantics of system calls either, as it does not need to.
However, it faithfully records system call invocations. PI Etrace
has limited support for multi-threaded executions. It gene rates
a trace program for each thread. Although it faithfully capt ures
individual thread executions, analyzing thread interleav ing
requires additional work. PIEtrace currently has non-triv ial
runtime overhead.II. D EMONSTRATIVE EXAMPLE
In this section, we use a Windows malware example
to demonstrate our technique. It is a Browser Helper Ob-
ject(BHO) malware [41] executing on Internet Explorer(IE) .
BHO is a plug-in of IE that can register callbacks for importa nt
events. The malware monitors all visited URL so that an
advertisement is displayed when some particular URLs are
detected. In this case study, we want to identify and underst and
the malicious payload of the BHO plug-in.
Firstly, we observe that the DLL binary ﬁle of the plug-
in has a non-trivial size (300kb) and complex structure. The
left side of Fig. 1 shows the static call graph generated by
IDA, the most popular binary analysis tool used in malware
analysis. The graph has 222 nodes and 1330 edges. It is
difﬁcult for a human to determine the malicious payload insi de
the complex graph. Besides, the graph is incomplete, missin g
many call edges through function pointers due to the difﬁcul ty
of static analysis. The plug-in has a lot of benign functions
for initialization and normal processing.
An alternative is to observe the plug-in execution. However ,
the plug-in has to execute as part of IE. That implies a tool
has to load and monitor the IE execution, which is highly
complex and expensive to monitor. In an execution in which
we load 3 pages with one of them triggering the advertisement ,
the execution of the IE process is 151 times larger than the
sub-execution of the plug-in. Furthermore, to the best of ou r
knowledge, there is not an existing scalable and publically
available Windows dynamic analysis tool that we can easily
leverage to understand the malware.
Therefore, in this case study, we use PIEtrace to trace and
virtualize the execution of the plug-in. We then use a Valgri nd
based tool Callgrind on Linux to generate the dynamic call
graph of the trace program, whose execution regenerates the
original plug-in execution. To further determine the malic ious
payload, we use a simple approach to prune the benign be-
havior. Particularly, we trace and virtualize two IE execut ions,
one accessing the full set of pages including the one that
could trigger the advertisement and the other accessing the two
benign pages only. We acquire the two trace programs with
sizes of 453KB and 1.7MB. We execute them on Callgrind and
generate two call graphs for comparison. The right hand side
of Fig. 1 shows the result. The shaded nodes are the functions
that uniquely appear in the execution with the advertisemen t.
There are totally 16 such functions and we suspect they
are the malicious payload. Since our trace program contains
information of calls to external APIs, we are able to underst and
the behavior of some of the functions by observing the extern al
API calls in these functions.
In particular, the malware ﬁrst checks if there are other
loaded BHOs. If so, it unloads them in order to gain ex-
clusive control of the browser(in node A). Then, it shows
an advertisement dialog on the screen (in node B) and stops
the current navigation of the browser(in node C). While the
behavior of (B) and (C) corresponds to the observed symptoms
of the malware, the graph also reveals its stealth behavior
(A). It calls CConnectionPoint::EnumConnection49A call graph from IDA has 
222 nodes, 1330 edges, 3356 crossings
main
 0x09A229F7
 0x09A2C168
 0x09A23421
0x09A2A7D2
0x09A25FDE
C. CIEFrameAuto::Stop
(ieframe.dll)
0x09A26437
0x09A2AD13
0x09A24BA7
0x09A370FC
0x77E2CF41
0x77E1EB36
0x9A36AC0
A. CConnectionPoint::
EnumConnection
(ieframe.dll)
B. ShowWindow
(user32.dll)
0x09A2C168`
0x09A25132
0x09A23A28
...
0x09A2629A
0x09A36DAF
0x0DCE6BA1
0x09A2DE14
 0x09A2DDFD
...
Fig. 1. BHO call graphs. The one on the right is generated by ou r analysis. Shaded nodes denote malicious behavior.
inieframe.dll . Although this interface is supposed to
be called by the browser to manage registered BHOs, the
malicious BHO uses it to disable other BHOs.
III. B ASIC DESIGN
Program P ::=s
Stmt s ::=s1;s2|skip|r:=ℓe|r:=ℓR(ra)|
Wℓ(ra,rv)|gotoℓ(ℓ1)|if(rℓ)then goto (ℓ1)|
syscallℓ()|depinstℓ()|r:=mallocℓ(rs)|
freeℓ(r)|callℓ(ℓ1)|retℓ
Operator op ::= +| − | ∗ | /|...
Expr e ::=r|c|a|r1opr2|ropc
Register r ::={sp,r1,r2,r3,...}
Const c ::={true,f alse,0,1,2,...}
Addr a ::={0,1,2,...}
Label ℓ::={ℓ1,ℓ2,ℓ3,...}
Fig. 2. Language
Language. To facilitate discussion, we introduce a low level
language to model binary executables. For simplicity, we on ly
model enough to illustrate the key ideas. The language and th e
discussion are general, not bounded to a speciﬁc instructio n
set. The syntax is presented in Fig. 2.
Memory reads and writes are modeled by R(ra) and W(ra,
rv) with raholding the address and rvthe value. Since it is
a low level language, we do not model conditional or loop
statements, but rather jumps using goto and guarded goto;
syscall () denotes system calls1;depinst () represents instruc-
tions that depend on the speciﬁc platform; malloc (r) and
free(r) represent heap allocation and deallocation. Function
invocations and returns are modeled by call(ℓ) and ret. Note
that we use spto denote the stack pointer register and we
assume all platforms have such a register.
Our technique executes the original program P. During
execution, it constructs another program P′that is platform-
independent, not depending on any OS, libraries, input ﬁles ,
1We do not model their parameters as our technique does not req uire such
information.or network connections. Running P′regenerates the original
execution. More precisely, it regenerates an execution that has
the same user-space control ﬂow, data ﬂow, and values as
the original execution . To simplify our discussion, one can
consider P′a program in a sub-language of the one in Fig. 2.
In particular, P′will not have any system call instructions,
platform speciﬁc instructions, heap memory management in-
structions, or registers except the stack register.
Next, we elaborate the technique from different aspects.
A. Control Flow Tracing and Virtualization
The ﬁrst aspect focuses on ensuring the trace program will
regenerate the same control ﬂow when it executes. For each
executed instruction in the original program, we record it
in a buffer. For control transfer instructions (e.g. jumps a nd
calls), we patch the control transfer target to ensure corre ct
control ﬂow. If an instruction gets executed multiple times ,
our technique keeps only one copy of its virtualized version
to minimize the size of the trace program.
Upon execution of an instruction, the technique checks if
it is executed for the ﬁrst time. If so, it is stored in the
buffer. At the end, the buffer is the trace program. In the
tracing/virtualization rules in Table I, function AddStmt (ℓ,s)
(deﬁned in Fig. 3) is called upon execution of any instructio n
(with label ℓ) to record the instruction. Parameter sdenotes
the virtualized version of the instruction, which may conta in
more than a few instructions to achieve platform independen ce.
We use a VirtualLabelMap V L (Fig. 3) to map an instruction
in the original executable to its virtualized version in the
trace program. Hence inside AddStmt (), we ﬁrst test if the
instruction has been traced before by checking VL. If not, the
instruction is attached to the end of the trace program and th e
mapping is updated.
For jump and call instructions (rules JUMP and CALL),
we look up the new label of the jump/call target using functio n
GetLabel (ℓ)and redirect the control to the new position. Note
that when we call GetLabel , the target instruction may not50P′∈Program ::=s
V L∈VirtualLabelMap ::=Label→Label
VA∈VirtualAddrMap ::=Addr→Addr
M∈MemStore ::=Addr→Const
REG∈RegStore ::=Register→Const
SM∈ShadowMemory ::=Addr→Const
ACC∈Accessed ::=Addr→Boolean
LS∈LogStorage ::=LogId→LogEntry
id∈LogId ::=<ℓ,z>
E∈LogEntry ::=MEMLOG (a,c)|
REGLOG (csp,c1,c2,c3,...cn)
HC∈HitCount ::=Label→Z
V R(r)represents the global var. in the trace program representin gr
GetLabel (ℓ) ::=
ifV L(ℓ)is empty then
return the end position o f P′;
else
return V L (ℓ);
AddStmt (ℓ,s) ::=
ifV L(ℓ)is empty then
VL(ℓ):=the end position o f P′;
P′:=P′·s;
LogRead (ℓ,a) ::=
HC(ℓ)++ ;
ifa/ne}ationslash=null then
ifSM(a)/ne}ationslash=M(a)then
LS(<ℓ,HC(ℓ)>):=MEMLOG (a,M(a));
SM(a):=M(a);
Concretize (ℓ) ::=
HC(ℓ)++ ;
t:=LS(<ℓ,HC(ℓ)>)
ift≡MEMLOG (a,c)then
W(VA(a),c)
ift≡REGLOG (csp,c1,...,cn)then
VR(sp):=csp;...;V R(rn):=cn
Fig. 3. Deﬁnitions for virtualization rules
be executed and virtualized yet. In this case, the function
returns the end position of the trace buffer, at which the tar get
instruction will be put.
We also take special care of call and return instructions. In
particular, we cannot simply use call and return instructio ns in
the trace program because they entail implicit stack operat ions.
Upon a function call, the return address (i.e. the address of
the instruction immediately following the call instructio n) is
implicitly pushed to the stack. Upon return, the return address
is loaded from the stack. If we use a call instruction in P′
to virtualize a call in P, the address pushed to the stack is
the neighboring instruction in P′, which does not necessarily
correspond to the instruction immediately succeeding the c all
instruction in P, leading to incorrect control ﬂow upon return.
Therefore, as shown in rule C ALL, our solution is to explicitly
push the original return address, i.e. ℓ+1, and then use a jump
instruction to virtualize the call. Upon return (rule R ET), the
original return address is read and then translated at runtime
using VL.
B. Data Flow Tracing and Virtualization
In the second aspect, we discuss how to ensure execution
of the trace program reproduces the same data ﬂow in a
platform-independent fashion. This is achieved by virtual izing
memory layout, memory management, and registers, whichare platform dependent. For example, the typical stack addr ess
of Linux applications is not available in Windows because it
is reserved for the Windows kernel. To virtualize memory,
we track all the memory locations and regions accessed in
the original execution and then declare these locations and
regions as global buffers in the trace program. The original
accesses are redirected to these buffers. One critical prop erty
we want to ensure is that all the original user space memory
accesses, including their addresses and the values accesse d,
can be preserved by our virtualization. This is critical for
cross-platform debugging as unsafe accesses such as buffer
overﬂows are preserved too. Registers need to be virtualize d
too as different platforms support different registers. We use
a set of global variables to represent registers.
We use a mapping ACC that maps an address to a boolean
value to denote if the address has ever been accessed during
execution. Hence, in rules R EAD, W RITE , CALL, the mapping
is set. In a call instruction, the stack memory is implicitly
accessed to store the return address. Observe in these rules ,
VR(r)denotes the global variable in the trace program that
is used to represent register r;REG is the register store and
hence REG(r)denotes the current value in r.
After the original execution terminates, we process the ACC
mapping to divide all the accessed addresses to a number of
regions. Ideally, we can allocate one variable in the trace
program for each unique accessed address. However, this
requires maintaining a very large address translation tabl e
to map an original address to its corresponding variable in
the trace program. On the other hand, we can allocate a
large buffer to denote the entire virtual space in the origin al
execution. In such a case, although we only need to perform
linear address translation, the space consumption is large .
Hence, we divide the accessed addresses to a few regions to
achieve a good tradeoff between the memory overhead and
the address translation overhead. In particular, we consider
any two addresses with a distance less than a predeﬁned
threshold (256 in this case) belong to the same region . For
each identiﬁed region, we declare a global buffer in the trac e
program. During execution of the trace program, a memory
address is translated on the ﬂy right before it is accessed, b y
ﬁrst performing a range query to determine the buffer for its
region and then offsetting to the right location.
In rule R EAD, the second instruction added by AddStmt ()
translates the address to be read VR(ra), which is an address
in the original execution, to aby calling VA(), which performs
a range query and then offsetting. Its details are elided. Ru le
WRITE is similar.
Doing so, our scheme does not rely on any platform speciﬁc
memory layout or memory management policy. Intuitively,
trace programs do not allocate any heap memory as heap
allocation and deallocation functions are platform depend ent.
The original stack manipulations are virtualized and emula ted
on a global region.
Example . Assume 0 x08000400, 0 x08000432, 0 x080004 b0 and
0x8000900 are accessed. We determine the ﬁrst three form a
region and the last forms another region. We allocate a buffe r51TABLE I
TRACING /VIRTUALIZATION RULES .
Statement Action Rule
r:=ℓR(ra) ACC(REG(ra))= true;LogRead (ℓ,REG(ra)); READ
AddStmt (ℓ,“Concretize (ℓ);a:=VA(VR(ra));V R(r):=R(a);”);
Wℓ(ra,rv) ACC(REG(ra))= true;AddStmt (ℓ,“a:=VA(V R(ra));W(a,V R(rv));”); WRITE
gotoℓ(ℓ1) ℓ′:=GetLabel (ℓ1);AddStmt (ℓ,“goto(ℓ′);”); JUMP
if(rℓ)then goto (ℓ1) AddStmt (ℓ,“if(V R(r))then goto (VL(ℓ1));”); COND -JUMP
syscallℓ()|depinstℓ() LS(<ℓ,++HC(ℓ)>):=REGLOG (REG(sp),REG(r1),...,REG(rn));AddStmt (ℓ,“Concretize (ℓ);”); SYSDEP
mallocℓ(r)|freeℓ(r) skip HEAP
callℓ(ℓ1) ACC(REG(sp)−1)=true;ℓ′:=GetLabel (ℓ1); CALL
AddStmt (ℓ,“sp′:=sp′−1; W(sp′,ℓ+1);goto(ℓ′);”);
retℓAddStmt (ℓ,“t:=R(sp′++) ;goto(VL(t));”); RET
Register sp′is the stack pointer register in the trace program. Note that the actions in the second column are performed during
the original execution, whereas the statements added by AddStmt ()constitute the trace program and will be executed separatel y.
Awith the size (0 x80004 b0+4-0 x8000400) for the ﬁrst region.
Assume during execution of the trace program 0 x08000432
is about to be accessed, the translation identiﬁes that Ais its
buffer as it falls in the range of [0x08000400 ,0x080004 b4].
Its actual address to access is hence & A+(0x8000432−
0x08000400 )./square
In our design, the entire stack footprint (i.e. the maximum
stack consumption) of the original execution is often deter -
mined as a large region, as stack accesses tend to be close
to each other. The heap is often divided into smaller regions .
A region identiﬁed by our analysis may not correspond to
an allocated heap region. However, this does not affect the
soundness of our technique.
Theorem 1. All user space memory accesses, including buffer
overﬂows, in the original execution are preserved. Particu larly,
the same sequence of addresses and accessed values is re-
generated by trace program execution.
Intuitively, all addresses are maintained and manipulated in
their original form during execution of the trace program.
They are only translated right before the access. Hence,
assume in the original run a buffer Ais overﬂowed and
thus its neighboring buffer Bis overwritten. The write to the
address within buffer Bis faithfully reproduced as the same
faulty pointer manipulation that overﬂows Awill be faithfully
replayed. It is independent of the region identiﬁcation in o ur
virtualization process. Note that some memory related exce p-
tions such as null pointer dereferences will explicitly ter minate
the tracing process, they are essentially preserved by the
termination of the trace program. The formal proof is omitte d.
Maintaining identical original addresses during trace pro gram
execution is critical, even though they are not accessible. Some
functions such as printf() andfprintf() take different
execution paths according to the pointers. Also, the execut ion
path ofEncodePointer() andDecodePointer() in
Windows depends on the given address. Furthermore, some
instructions require memory alignment. In x86, SSE and MMX
instructions such as MOV APS and MOVNTPS are examples.
To handle them, we align all the base addresses of virtualize d
memory regions according to the original base addresses.Since the least common multiple (LCM) of alignments of SSE
and MMX is 16-byte, PIEtrace also applies 16-byte alignment .
C. System-level Dependence Elimination
A real execution is most likely system dependent. For
instance, it may have to perform system speciﬁc I/O by system
calls (e.g. read from a speciﬁc device); it may execute syste m-
dependent instructions such as CPUID. We have to eliminate
such dependences in order to run the trace program on a
different platform. Note that libraries are not a problem fo r
PIEtrace as we are able to trace into library execution. In ot her
words, library execution will be part of the trace program.
We also need to handle non-deterministic instructions such as
RDTSC (read current timestamp). Otherwise, they will cause
execution differences. Currently, we have limited support for
concurrency. PIEtrace generates a trace program for each
thread. While trace programs capture the user-space behavi or
of individual threads, PIEtrace does not currently support
reasoning about thread interleavings.
A typical solution to handle system calls by many existing
logging and replay tools [33], [38], [2], [6] is to record the
values read/written by system calls (e.g. the packet receiv ed
by a socket read). During replay, instead of interacting wit h
the real device, it simply restores the recorded values from the
log. Despite its simplicity, such a design is platform-depe ndent
because the logging and replay has to be aware of the entire
system call interface, such as which part of memory is being
updated during a socket read.
We develop a new solution. Instead of directly tracking
system calls or platform dependent instructions. We develo p a
lazy-logging approach. During tracing, we maintain a shadow
memory that can be considered as parallel to the normal
memory. When a user-space instruction of the original pro-
gram updates the memory, which is visible to our tracing
system, we update the shadow memory in the same way.
When a kernel-space instruction (inside a system call) upda tes
the memory, the shadow memory cannot be updated because
such writes are invisible to PIEtrace. Later, when the memor y
updated by the system call is read, the discrepancy between t he
normal memory and the shadow memory suggests the previous52invisible update. We then log the value in the memory. It
will be restored during trace program execution. Besides
system calls, the method also naturally handles other platf orm-
dependent instructions and non-deterministic instructio ns in-
cluding remote thread reads and writes.
As shown by rule R EAD in Table I, function LogRead ()
is called with the address. The function is deﬁned in Fig. 3.
It ﬁrst updates the hit count of the instruction, which count s
the number of instances of the instruction. It then compares
the shadow memory and the actual memory. If they differ, a
log entry identiﬁed by the instruction label and its hit coun t
is added. The hit count is to handle the case that a read
instruction gets executed many times and only some instance s
have their values updated by system calls. Others have their
values updated by user-space instructions and hence can be
re-computed during the trace program execution. They do not
need to be logged.
As part of the rule, a call to function Concretize ()is added
to the trace program, which will be executed when the trace is
replayed. Symmetric to LogRead (), it also ﬁrst increases the
hit count, and then it checks if there is a log entry associate d
with the current instance identiﬁed by the label and the hit
count. If so, it sets the corresponding memory or registers t o
the recorded values.
In rule S YSDEP, even though we do not need to log any
values in memory due to the lazy logging strategy, we do
log the current register values. The reason is that register
values may be changed by system calls or platform dependent
instructions and such changes need to be captured.
IV. I MPLEMENTATION
To make the technique practical, we also need to address a
number of implementation challenges.
Handling Indirect Control Flow Transfer and Long/Set
Jumps. Indirect control ﬂow transfer and long/set jumps are
commonly used in x86 executables. Indirect control ﬂow
transfers are used to support function pointers, virtual fu nction
calls in object oriented programs, and jump tables compiled
fromswitch-case statements. Long/set jumps are usually
used to implement control transfer to exception handlers. T hey
share the same characteristics that the control transfer ta rget of
a jump/call instruction is a runtime value. For example, the y
may be in the form of “ goto(r)” with rthe register holding
the dynamic target. Hence, the control transfer rules J UMP,
COND -JUMP, and C ALL in Table I are insufﬁcient as their
targets are a constant program label. Our solution is to look
up the new target from the virtual label map VLduring the
trace program execution. For example, we have the following
rule for the indirect jump statements.
Statement Action
gotoℓ(r) AddStmt (ℓ,“goto(VL(V R(r));”);
Indirect calls are similarly handled. Note that our techniq ue
guarantees values generated in the virtualized registers d uring
trace program execution, e.g. in VR(r), are identical to those
generated in the real registers in the original execution. T his
guarantees the correctness of the above indirect jump rule. Theuse of the VLmap in the trace program also implies that we
need to provide it as part of the trace program. We declare it
as a global array.
Symbolic Information Preservation. An important design
goal is to allow the trace program to be analyzed by different
tools on various platforms. However, we want to interpret th e
analysis results on the original system. As such, we need to
preserve the symbolic information of the original program i n
the trace program. In particular, during the tracing/virtu alizing
process, we generate an ofﬂine dictionary. It maps each
instruction in the trace program to an instruction in the ori ginal
program, whose symbolic information can be looked up from
the original executable. For each variable accessed in the
original run (as captured by ACC), we also preserve the
mapping from its buffer address in the trace program to the
variable.
Supporting Different Instruction Sets. Besides x86, PIEtrace
can also trace Mica2 sensor program execution and generate
trace programs in x86 so that the wealthy set of x86 tools can
be used to analyze sensor program execution. The additional
challenge lies in eliminating the instruction set differen ces. For
Mica2 instructions that do not have direct correspondence i n
x86, for example SBIC, we provide functions written in x86
to emulate them.
V. E VALUATION
We evaluate PIEtrace with real world applications on x86
and sensor platforms. For x86, we run 5 real world buggy
programs on Windows and collected the trace programs of
the faulty runs for cross-platform analysis. The ﬁve Window s
programs are downloaded from a vulnerability database [35] .
Note that although the database lists many vulnerabilities ,
most of them do not provide the exploit inputs or the ex-
ploits cannot be reproduced. After we randomly inspected
a large set of the listed vulnerabilities of COTS software,
we found these ﬁve that have the inputs available and can
be reproduced. We execute the subject programs with the
provided vulnerable inputs to get the trace programs. In the
ﬁve applications, CastRipper is a recording program and
Microsoft HTML Help is the default HTML help ﬁle
loader.PowerTabEditor is a guitar note editor program
andFreeAmp is a music player.
For the sensor platform, we run 5 buggy sensor applications
on an emulator called ATEMU [31], The supported instruction
set isATMega128 , a kind of RISC instruction set. The op-
erating system is TinyOS. The ﬁve sensor buggy applications
are mainly collected from existing literature [17], [25], [ 45].
We also evaluate PIEtrace on three malwares to show
that we can effectively help malware analysis, even when a
malware is packed. The IE-BHO case discussed in Section II
is one of them.
The set of subject programs and the corresponding bugs are
presented in the second column and the last column of Table II ,
respectively. PIEtrace and the test benchmarks are publica lly
available at [23]. We also run PIEtrace on SPECINT 2000
programs to study overhead. These programs are bug free.53TABLE II
BENCHMARKS AND VIRTUALIZATION RESULTS .
Platform Subject Software # of Inst. Program size Log size Bug
(Dynamic/Static) (Originala/Trace-program) (Plaintext/Compressedb)
x86 Acrobat Reader 9.3 208M / 506K 342KB / 31MB 78MB / 31MB Memory corruption
x86 CastRipper 103M / 230K 564KB / 13MB 25MB / 4MB Buffer overﬂow
x86 Microsoft HTML Help 7M / 117K 11 KB / 6MB 4MB / 1MB Buffer overﬂow
x86 PowerTabEditor 37M / 186K 2.16 MB / 10MB 8MB / 2MB SEH/EIP corruption
x86 FreeAmp 67M/ 120K 272 KB / 6MB 16MB / 4MB Buffer overﬂow
ATMega128cSensor node by [17] 8M / 2K 31KB / 204KB 2MB / 1MB Buffer overﬂow
ATMega128 MultihopOscilloscope [25] 7 M / 2K 54KB / 214KB 2MB / 1MB Data race
ATMega128 CntToLedRfm [45] 3 M / 1K 18KB / 155KB 700KB / 57KB Concurrency bug
ATMega128 BlinkFail [39] 32K / 461 6KB / 78KB 22KB / 3KB Memory safety
ATMega128 RfmToLed [30] 679K / 1K 17KB / 154KB 923KB / 75KB Zero length packets
x86 Packed-Malware 246M / 239K 887 KB / 19MB 22MB / 8MB
x86 Multi-Packed Malware 322M / 263K 977 KB / 20MB 47MB / 12MB
x86 BHO 4M / 33K 264 KB / 1MB 312KB / 123KB
a.application binary only, not including dynamic libraries; b.7zip utility was used; c.ATMega128 is a sensor instruction set.
TABLE III
EXISTING ANALYSIS TOOLS TESTED ON OUR SYSTEM .
Name Tested extensions or functionalities
Pin Program slicing tool and Memtrace
Valgrind Memcheck+ and Callgrind
DynamoRIO Instrcalls
OllyDebugger WatchMan, OllyScript, HitTrace
Immunity Debugger FullDisasm and Ariadne
Windbg PyDbgEng and Windbg Script
gdb Reverse debugging (reverse-step, reverse-continue)
A. Virtualization Results
The virtualization results can be found in Table II. The thir d
column shows the number of executed instructions (static) a nd
their instances (dynamic). The static number is also the num -
ber of instructions that get virtualized. Column four shows the
size of programs including the original and the correspondi ng
trace programs. Observe that the trace programs are usually
much larger than the original programs. That is because an
instruction is usually virtualized to a few instructions an d a
trace program includes all the libraries used including tho se
dynamically loaded. Furthermore, we have to include the
virtual label mapping VLand the virtual address mapping VA
(deﬁned in Fig. 3) as part of the trace programs. However, our
later experiment will show that the trace program size does n ot
change much over time.
Column ﬁve shows the log size. More detailed results about
the instructions that trigger logging and their effects are pre-
sented in Table IV. The “Data” columns present the numbers
of instruction instances (dynamic) and unique instruction s
(static) that need logging because of invisible system leve l
memory writes. Their percentages (over the total number of
dynamic and static instructions, respectively) are also pr e-
sented. The “Control Flow Change” columns show logging
caused by unexpected control ﬂow changes. The “Platform-
Dependent Inst.” columns present logging for platform depe n-
dent instructions (e.g. CPUID). The last two columns show
the total. Observe that for most cases, only a small percenta ge
of all executed instructions triggers logging except for tw o
sensor cases. That is because those two cases are very I/O
bound. For Windows cases, most loggings are caused by data
differences whereas for sensor cases, most are caused byplatform-dependent instructions. That is because sensors use
the platform-dependent instructions IN and OUT to perform
one byte hardware read and write. Another observation is tha t
unexpected control ﬂow happens very often at a very small
number of places. That is due to the event driven execution
model (i.e. program execution is trapped to kernel through
interrupt instructions and various user mode handlers may g et
called depending on the events).
B. Cross-Platform Analysis
An important goal of PIEtrace is to enable cross-platform
dynamic analysis, namely, using a tool on a speciﬁc platform
to analyze an execution on a different platform. In this expe ri-
ment, we apply a set of tools as shown in Table III to the trace
program executions. The ﬁrst column shows the infrastructu res
of the tools. The second column shows the tools, which are
usually implemented as infrastructure extenstions. Pin (L inux
x86), Valgrind (Linux x86), and DynamoRIO (Windows)
are dynamic binary instrumentation engines. OllyDebugger ,
Immunity Debugger, Windbg, and gdb are debuggers that are
widely used on Windows or Linux.
We applied two Pin tools, namely, a dynamic slicing
tool [21] and the Memtrace tool, to the trace program exe-
cutions. The slicer detects both data and control dependenc es
during execution and performs backward/forward slicing gi ven
a slicing criterion. Since PIEtrace preserves user-space d e-
pendences, the slicer produces the same slices as the ones
generated when it is applied to the original executions. Not e
that the slices contain some instructions that are for the
purpose of virtualization (and hence not present in the orig inal
programs). These instructions can be pruned by the symbolic
information mapping mentioned in Section IV. Memtrace is
a tool that traces all memory addresses. As the addresses
accessed in trace program execution are the global memory
regions generated by virtualization, PIEtrace has a script
that translates such addresses back to the original address es,
leveraging the address mapping VA.
We applied two Valgrind tools: Memcheck+ and Callgrind.
Memcheck is a tool that detects memory safety problems such
as buffer overﬂows and null pointer accesses. We modiﬁed the
Memcheck tool to print recent memory read operations as well54TABLE IV
INSTRUCTIONS CAUSING LOGGING .
Subject Software Data Control Flow Change Platform-Dependent Inst. Total
Dynamic Static Dynamic Static Dynamic Static Dynamic Static
Acrobat Reader 9.3 3M(1.8%) 9K(1.9%) 19Ka3a21Ka9K(1.9%) 3M(1.8%) 9K(1.9%)
CastRipper 703Ka6K(3%) 147Ka3a147Ka6K(3%) 998K(1%) 6K(3%)
MS HTML Help 226K(3.1%) 3K(3.4%) 952a4a1Ka3K(3.4%) 229K(3.1%) 3K(3.4%)
PowerTabEditor 261Ka6K(3.2%) 36Ka3a36Ka6K(3.2%) 335Ka6K(3.2%)
FreeAmp 753K(1.1%) 4K(3.5%) 18Ka1a19Ka4K(3.5%) 791K(1.2%) 4K(3.5%)
Sensor node by [17] 8Ka18a9Ka9a1.6M(18.6%) 26(3.7%) 1.6M(18.8%) 103(5%)
MultihopOscilloscope 9Ka21a554a9a1.4M(20.8%) 6(3%) 1.4M(20.9%) 110(4%)
CntToLedRfm 8Ka18(1%) 3Ka6a5Ka7(2.9%) 17Ka75(4.2%)
BlinkFail 177a7(1.5%) 169a1a1K(4.2%) 6(4.1%) 1K(5.3%) 27(5.8%)
RfmToLed 8K(1.2%) 22(1.2%) 7K(1%) 5a10K(1.5%) 8(2.8%) 26K(3.8%) 76(4.3%)
Packed Malware 1Ma7K(3.1%) 5Ka2a5Ka7K(3.1%) 1Ma7K(3.1%)
Multi-Packed Malware 2Ma5K(2.2%) 6Ka2a7Ka5K(2.2%) 2Ma5K(2.2%)
BHO 15Ka1K(4.7%) 59a4a45a1K(4.7%) 15Ka1K(4.7%)
a.Its percentage is less than 1%.
as instructions that deﬁned the values that are read. We call
this new tool Memcheck+ as it is a simple extension of the
Memcheck code base. Callgrind is a tool to generate dynamic
call graph. We applied two DynamoRIO tools. Memtrace is
similar to Pin-Memtrace. Instcalls is a tool that logs funct ion
invocations and returns.
Besides the above tools, we have also applied a number
of debugger plugins that provide advanced debugging and
proﬁling capabilities. They are very similar to instrument ation
tools. Instead of using instrumentation, they use breakpoi nts
as the mechanism to monitor and inspect program state. For
instance, HitTrace logs program state automatically at giv en
breakpoints. Reverse debugging is an advanced feature in x8 6
gdb that allows reverse execution (e.g. step backward and
reverse-continue).
All these tools run correctly with our trace program execu-
tions. Next we show a few case studies.
Acrobat Reader 9.3 Acrobat Reader 9.3 on Windows can
be crashed by a null pointer dereference when provided with
a crafted pdf ﬁle. There is not any published explanation
of the crash. In this case study, we want to use our simple
extension of Linux Valgrind-Memcheck, called Memcheck+,
to understand the causality of the crash. We generate the
trace program from the crashing execution. We then use
Memcheck+ to back-track from the null pointer step by step.
We identify the deﬁnition point of the value at each step and
backtrack to the deﬁnition point, till we get to the ﬁrst such
deﬁnition. Since Acrobat Reader is highly complex and it doe s
not have any symbolic information, the identiﬁed chain is lo ng
and crosses a few functions and DLLs, we simplify it in Fig. 4.
The boxes on the left show the Memcheck+ output at each
step. Each box reports a read instruction including its PC,
source location in the trace program, value, and the deﬁniti on.
The corresponding read and write (i.e. the deﬁnition) in the
original program are shown in the middle. The right column
shows the corresponding function and its DLL. At the end,
we identify that the deﬁnition of the null pointer starts in t he
acroform.api DLL. As shown on the top, the loading of this
DLL is guarded by a predicate with branch target 0x4E6180A.
Its branch outcome is determined by the input on the right,which is a line in the crafted pdf. We conﬁrm the ﬁnding by
the fact that any changes to this line makes the crash disappe ar.
Searching it on the Internet, the keywords in the line seems
to indicate it is an invalid acrobat form.
Sensor Case. In [17], Qijun Gu et al. show that malicious
packets can compromise sensor nodes. We use their program
that has a buffer overﬂow vulnerability and can propagate
the malicious packet to other nodes automatically. Using th e
provided input, the sensor program crashes on an invalid ret urn
address. We use PIEtrace to generate the trace program of
the crashing run. And then we run the trace program inside
a Pin-based dynamic slicer [21]. Speciﬁcally, we compute
the backward slice from the faulty return address, which
contains all the executed instructions that have directly o r
indirectly contributed to the given faulty value through da ta
and control dependences. The slice has 227 instructions.
The data slice (i.e. a slice computed by considering data
dependences only) has 38 instructions. The data slice is
sufﬁcient to explain the crash. Part of it is shown in the
left-hand side of Fig. 5. The corresponding source code is
shown on the right. We ﬁnd that the invalid return address
is dependent on Receive.receive() (on the bottom),
stackCreator() , andstrcpy() (i.e., crashed when re-
turning from the function). This clearly identiﬁes the caus al
path of the exploit. The malicious packet is received by
Receive.receive() . It is passed to stackCreator() ,
which calls strcpy() . The buffer overﬂow occurs inside
strcpy() , corrupting the return address. Note that in a trace
program, the original packets become concretized values th at
are loaded from a ﬁle. Hence, the bottom box of Fig. 5 actually
corresponds to several IN instructions in TinyOS kernel.
Packed Malware Cases. PIEtrace has the following two main
advantages in malware analysis. First, since trace program s
do not have any system calls, one can analyze their execution
without any concerns about harmful side-effects. Second, s ince
the technique records all executed instructions, it can be
naturally used to analyze packed malwares, which unpack
themselves during execution. Compared to existing unpacki ng
techniques [32], [28], [20], [7] that rely on speciﬁc heuris tics
or target speciﬁc packers, our technique is very general and55RD: 0438172C  <re_func17.S, 22760>
- Contents: 0, Written By <re_func17.S, 22772>RD: 09CF4DC8 <re_func17.S, 22772>
- Contents: 0, Written By <re_func17.S, 22329>RD: 09CF7C28 <re_func17.S, 18071>
- Contents: 0, Written By <re_func17.S, 18044>
WR: /*[0x544E8ED1]*/ push dword ptr [edi]
RD: /*[0x545A6B4A]*/ mov eax, dword ptr [eax]WR: /*[0x5455809C]*/push dword ptr [ebp-0x10]
RD: /*[0x544E8ED1]*/push dword ptr [edi]WR: /*[0x04EB8BF1]*/ push ebx 
RD: /*[0x04EB8D80]*/ pop ebx 0x4E6180A: … call    0x4E6189E
…
0x4E6189E: … call    0x4E61CE0 ; PlugInMain test    al, al 
jz      0x4E6180A
VM_call_imm( ..., 0x4E61CE0, 0x04E61ADB)VM_call_imm( ..., 0x4E6189E, 0x04E6184C)jz Func_04E6180A The branch outcome is determined by input 
"<< /AcroType /Btn"
Call LoadLibraryEx to load 
"acroform.api" which is vulnerable.
At 0x4EB8BE0 + 0x11 in acrord32.dll 
At 0x4EB8BE0 + 0x1A0 in acrord32.dll 
At 0x54557FEE + 0xAE in acroform.api 
At 0x544E8EBF + 0x12 in acroform.api 
At 0x544E8EBF + 0x12 in acroform.api 
Crash at 0x545A6B46 + 0x4 in acroform.api … … 
… … … … 
Fig. 4. Analysis results from the Acrobat Reader case study
…ret(re_func.S:3814)
Func_22F2(strcpy)
Func_0A7E(stackCreator)
Func_0010AC
(scheduler...runTask)
eventmessage_t*Receive.receive(...){
…
stackCreator(rcm+2);
...voidstackCreator(uint8_t*str){
...
stringCopy(str);
...voidstringCopy(uint8_t*str){
...
strcpy(ch,str);
...
Concretizedvalues
(incomingmaliciouspackets)…
… …
… …
… …Backwardslicingresult Correspondingsourcecode
Fig. 5. Backward program slicing on a sensor node.
easily applicable.
In this experiment, we use a Java runtime installer mal-
ware [23] that downloads and installs another malware to
the victim machine. The malware is packed by an unknown
version of the UPX [27] executable compressor.
We run the packed malware twice on PIEtrace, one with
Internet connection and the other not. In the second executi on,
the malicious payload is not executed. We get two trace
programs. Then, we use the WinMerge tool [26] to compare
the two trace programs. The result shows that the ﬁrst approx -
imately 10,000 basic blocks of the two programs are identica l,
which implies they belong to the packer and the malware
initialization. The differences (about 40,000 basic block s)
denote the malicious payload. From the trace programs, we ca n
also easily observe that the ﬁrst 678 basic blocks belong to a
large loop. Cross checking with the original malware indica tes
that they belong to the packer and the original malware entry is
at the 679th basic block. We can directly execute the malware
by putting a goto statement that jumps to the entry. Note that ,
with our technique, we can easily identify about 9,000 basic
blocks that are in the malware but do not perform malicious
actions, which cannot be achieved by existing approaches.
In addition, most universal unpackers [32], [20], [7] are no t
able to handle binaries packed multiple times. We call them
the multi-packed malware. PIEtrace can directly handle suc h
malware. Hence, in this experiment, we use XPack [19] to
further pack the previous packed sample. During execution,the unpacking routines of XPack and UPX are executed
sequentially. We repeat the previous process to get two trac e
programs. By comparing them, we ﬁnd that they share about
15,000 basic blocks. The differences (the identiﬁed malici ous
payload) are the same as the previous case. The malware entry
point can be easily spotted at the 6781st basic blocks at the
end of two large loops.
C. Performance and Scalability
We use SPECINT 2000 to evaluate the performance and
scalability of PIEtrace We could not use the programs in
Table II because they are mostly interactive. We run the SPEC
programs on test inputs and measure the slow-down of the
virtualization component. The results are shown in Fig. 6.
For most tests, our system incurs approximately 2000x slow-
down or less except parser andcrafty . Further inspection
shows that their executions constantly perform I/O, causin g a
lot of data logging. The average overhead is 2523x. We also
evaluate scalability by showing the changes of trace progra m
size and log size over a duration of execution (1,000 million
instructions). The results are shown in Fig. 7 and 8. We can
observe that the trace program size quickly reaches a ﬁxed
point whereas the log size slowly grows over time except
vortex . Further inspection shows that vortex performs
more I/O than others in that duration. While we believe we
can reduce the runtime overhead by optimization, PIEtrace i s
a heavyweight technique that may not be used in a production
setting. It is suitable for cases where the runtime overhead is
less a concern (e.g. in-house debugging), but rather the mis sing
capabilites on the current platform. Such capabilities cou ld be
provided by cross-platform tools.
VI. R ELATED WORK
Logging and Replay. Logging and replay has been widely
studied [2], [37], [36], [43], [6], [29], [44], [40], [12], [ 15],
[33]. However, most of these existing techniques do not sup-
port cross-platform replay. Most of them work by intercepti ng
and logging system calls. Replay is by executing the same
program , with the support of a replay runtime that again
intercepts system calls and then loads values from the log. T he
replayed execution requires the same set of libraries and th e56Fig. 6. Slowdown on SPEC INT2000
0246810 12 14 16 MB bzip 
crafty 
eon 
gcc 
gzip 
mcf
parser
perlbmk 
twolf
vortex 0246810 12 14 16 MB bzip 
crafty 
eon 
gcc 
gzip 
mcf
parser
perlbmk 
twolf
vortex 
vpr
Fig. 7. Trace program size variation.
same platform. In contrast, we generate a trace program that
can be compiled and executed on its own, without any speciﬁc
platform or runtime support. TRANSPLAY [38] allows replay-
ing a trace on different platforms. However, execution can o nly
be replayed inside a replayer. Hence, debugging a replayed
execution discloses the state of the replayer, not the origi nal
execution. A replayer has to be developed for each platform.
It has to map system calls and library calls across platforms .
Creating such mappings requires a lot of manual efforts. In
contrast, PIEtrace suppresses platform dependences by con -
cretization. It does not need to understand either the origi nal
system interface or the target system interface. S2E [11] al lows
cross-platform driver execution. Similar to TRANSPLAY , it
requires a mapping between kernel APIs across platforms.
Xu et al. [42] proposed to use compiler to generate two
instrumented versions of a program: one for logging and the
other for replay. It works on Java programs and assumes the
same set of libraries. In contrast, PIEtrace does not requir e
compilers, and directly works on binaries, which entails a
different set of challenges.
Tracing. Traditional tracing techniques generate traces [24],
[47], [3], [8] that can be analyzed in a cross-platform fashi on.
020 40 60 80 100 MB bzip 
crafty 
eon 
gcc 
gzip 
mcf
parser
perlbmk 
twolf
vortex 
vpr020 40 60 80 100 MB bzip 
crafty 
eon 
gcc 
gzip 
mcf
parser
perlbmk 
twolf
vortex 
vpr
Fig. 8. Log size variationHowever, analysis tools have to support the speciﬁc trace
formats, which precludes most third party tools. Storing tr aces
is also very expensive.
Virtualization and VM Introspection. There are many virtual
machines [4], [13] and emulation infrastructures [31], [1] , [10]
that allow cross-platform execution. Their main disadvant age
is that a subject program has to execute along with their
system. It is hence difﬁcult to apply any third party tools
to the execution of the subject program. Virtual machine
introspection [5], [18], [34] is a kind of technique that aim s
to observe guest OS state from the host OS. Virtuoso [14]
and [16] virtualize utility commands, e.g. ls, in the guest
OS and make them executable on the host OS so that one
can directly observe the state of the guest OS by running such
commands on the host OS. These techniques need to be aware
of the system interfaces of both OS’s and they do not support
cross-platform replay of application programs.
Binary Extraction and Reuse. Inspector gadget [22] is a
technique that uses dynamic slicing to extract a part of a
malware, called a gadget, which can be replayed for behavior
analysis. BCR [9] tries to extract components of an executab le,
such as the decryption/encryption function of a malware, th at
can be reused in other programs. The extracted gadgets and
components are essentially sub-programs that can take inpu ts
and perform certain functionalities such as downloading ﬁl es.
They are platform dependent. Gadget execution also require s
support from speciﬁc runtime. TOP [46] is a framework that
decompiles a binary to C code by executing it. The generated
C code can take different inputs as the original binary, wher eas
PIEtrace only focuses on reproducing a speciﬁc execution.
TOP is not platform independent since it requires the pres-
ence of the same set of libraries, kernel interfaces, extern al
resources and devices.
VII. C ONCLUSION
We propose a novel technique called platform independent
executable trace. It generates a standalone trace program f rom
a normal program execution that relies on speciﬁc operating
system, libraries, hardware, and instruction set. The trac e
program is platform independent, without relying on any
operating system or libraries. It can be compiled and execut ed
on any x86 platform. Running the trace program generates the
original execution. As such, the large body of existing thir d
party tools can be applied to analyze trace program executio n
on the platforms those tools prefer. We have implemented
the technique on x86 and sensor platforms. We show that
leveraging our technique, Linux tools can be used to analyze
Windows and sensor program executions including packed
malware executions.
ACKNOWLEDGEMENT
This research has been supported in part by DARPA under
contract 12011593 and by NSF under awards 0917007 and
1320326. Any opinions, ﬁndings, and conclusions in this pap er
are those of the authors only and do not necessarily reﬂct the
views of DARPA and NSF.57REFERENCES
[1] Daniel J. Abadi, Don Carney, Ugur C ¸ etintemel, Mitch Che rniack,
Christian Convey, Sangdon Lee, Michael Stonebraker, Nesim e Tatbul,
and Stan Zdonik. Aurora: a new model and architecture for dat a stream
management. The VLDB Journal , 12(2):120–139, August 2003.
[2] Gautam Altekar and Ion Stoica. Odr: output-determinist ic replay for
multicore debugging. In SOSP ’09 , 2009.
[3] Andrew Ayers, Richard Schooler, Chris Metcalf, Anant Ag arwal, Jungh-
wan Rhee, and Emmett Witchel. Traceback: ﬁrst fault diagnos is by
reconstruction of distributed control ﬂow. In PLDI ’05 , 2005.
[4] Fabrice Bellard. Qemu, a fast and portable dynamic trans lator. In ATEC
’05, 2005.
[5] Chris Benninger, Stephen W. Neville, Yagiz Onat Yazir, C hris Matthews,
and Yvonne Coady. Maitland: Lighter-weight vm introspecti on to
support cyber-security in the cloud. In CLOUD ’12 , 2012.
[6] Sanjay Bhansali, Wen-Ke Chen, Stuart de Jong, Andrew Edw ards, Ron
Murray, Milenko Drini´ c, Darek Mihoˇ cka, and Joe Chau. Fram ework for
instruction-level tracing and analysis of program executi ons. In VEE
’06, 2006.
[7] Lutz Boehne. Pandora’s bochs: Automated malware unpack ing. Master’s
thesis, RWTH Aachen University, January 2008.
[8] Michael D. Bond, Nicholas Nethercote, Stephen W. Kent, S amuel Z.
Guyer, and Kathryn S. McKinley. Tracking bad apples: report ing the
origin of null and undeﬁned value errors. In OOPSLA ’07 , 2007.
[9] Juan Caballero, Noah M. Johnson, Stephen Mccamant, and D awn
Song. Binary code extraction and interface identiﬁcation f or security
applications. In ISOC NDSS10 , 2010.
[10] Anton Chernoff and Ray Hookway. Digital fx!32 running 3 2-bit x86
applications on alpha nt. In NT’97 , 1997.
[11] Vitaly Chipounov, V olodymyr Kuznetsov, and George Can dea. S2e: a
platform for in-vivo multi-path analysis of software syste ms.SIGPLAN
Not., 46(3):265–278, March 2011.
[12] Jim Chow, Tal Garﬁnkel, and Peter M. Chen. Decoupling dy namic
program analysis from execution in virtual environments. I nATC ’08 ,
pages 1–14, 2008.
[13] Bob Cmelik and David Keppel. Shade: a fast instruction- set simulator
for execution proﬁling. SIGMETRICS Perform. Eval. Rev. , 22(1):128–
137, May 1994.
[14] Brendan Dolan-Gavitt, Tim Leek, Michael Zhivich, Jona thon Gifﬁn, and
Wenke Lee. Virtuoso: Narrowing the semantic gap in virtual m achine
introspection. In SP ’11 , 2011.
[15] George W. Dunlap, Samuel T. King, Sukru Cinar, Murtaza A . Basrai,
and Peter M. Chen. Revirt: enabling intrusion analysis thro ugh virtual-
machine logging and replay. SIGOPS Oper. Syst. Rev. , 36(SI):211–224,
December 2002.
[16] Yangchun Fu and Zhiqiang Lin. Space traveling across vm : Automat-
ically bridging the semantic gap in virtual machine introsp ection via
online kernel data redirection. In SP ’12 , 2012.
[17] Qijun Gu and Rizwan Noorani. Towards self-propagate ma l-packets in
sensor networks. In WiSec ’08 , 2008.
[18] Xuxian Jiang, Xinyuan Wang, and Dongyan Xu. Stealthy ma lware detec-
tion through vmm-based ”out-of-the-box” semantic view rec onstruction.
InCCS ’07 , 2007.
[19] Joko. Xcomp/xpack download page. http://www.soft-la b.de/JoKo/.
[20] Min Gyung Kang, Pongsin Poosankam, and Heng Yin. Renovo : a hidden
code extractor for packed executables. In WORM ’07 , 2007.
[21] Dohyeong Kim. Dualslicing. http://www.cs.purdue.ed u/homes/kim1051/.
[22] Clemens Kolbitsch, Thorsten Holz, Christopher Kruege l, and Engin
Kirda. Inspector gadget: Automated extraction of propriet ary gadgets
from malware binaries. In SP ’10 , 2010.
[23] Yonghwi Kwon. Platform independent trace project webs ite.
https://sites.google.com/site/pitprj12/, May 2013.
[24] James R. Larus. Whole program paths. In PLDI ’99 , 1999.[25] Peng Li and John Regehr. T-check: bug ﬁnding for sensor n etworks. In
IPSN ’10 , 2010.
[26] Christian List, Dean Grimm, Gal Hammer, Jochen Tucht, K immo Varis,
Alexander Skinner, Takashi Sawanaka, Tim Gerundt, Marcel G osselin,
and Denis Bradford. Winmerge. http://winmerge.org/.
[27] Oberhumer Markus Franz Xaver Johannes, Molnr Lszl, and
Reiser John F. Upx: the ultimate packer for executables.
http://upx.sourceforge.net/.
[28] L. Martignoni, M. Christodorescu, and S. Jha. Omniunpa ck: Fast,
generic, and safe unpacking of malware. In ACSAC ’07 , 2007.
[29] Satish Narayanasamy, Gilles Pokam, and Brad Calder. Bu gnet: Contin-
uously recording program execution for deterministic repl ay debugging.
InISCA ’05 , 2005.
[30] Joe Polastre. [tinyos-contrib-commits] cvs: tinyos-
1.x/contrib/ucb/tos/cc1000pulse cc1000radiointm.nc, 1 .2, 1.3.
http://mail.millennium.berkeley.edu/pipermail/tinyo s-contrib-commits/
2005-May/001909.html.
[31] Jonathan Polley, Dionysys Blazakis, Jonathan Mcgee, D an Rusk, and
John S. Baras. Atemu: A ﬁne-grained sensor network simulato r. In
IEEE SECON ’04 , 2004.
[32] Paul Royal, Mitch Halpin, David Dagon, Robert Edmonds, and Wenke
Lee. Polyunpack: Automating the hidden-code extraction of unpack-
executing malware. In ACSAC ’06 , 2006.
[33] Yasushi Saito. Jockey: a user-space library for record -replay debugging.
InAADEBUG’05 , 2005.
[34] Christian Schneider, Jonas Pfoh, and Claudia Eckert. A universal
semantic bridge for virtual machine introspection. In ICISS ’11 , 2011.
[35] Offensive Security. Exploits database by offensive se curity.
http://www.exploit-db.com/.
[36] Stelios Sidiroglou, Oren Laadan, Carlos Perez, Nicola s Viennot, Jason
Nieh, and Angelos D. Keromytis. Assure: automatic software self-
healing using rescue points. In ASPLOS ’09 , 2009.
[37] Sudarshan M. Srinivasan, Srikanth Kandula, Christoph er R. Andrews,
and Yuanyuan Zhou. Flashback: a lightweight extension for r ollback
and deterministic replay for software debugging. In ATEC ’04 , 2004.
[38] Dinesh Subhraveti and Jason Nieh. Record and transplay : partial
checkpointing for replay debugging across heterogeneous s ystems. In
SIGMETRICS ’11 .
[39] Berkeley WEBS: Wireless Embedded Systems. download.
http://webs.cs.berkeley.edu/tos/download.html.
[40] Amit Vasudevan, Ning Qu, and Adrian Perrig. Xtrec: Secu re real-time
execution trace recording on commodity platforms. In HICSS ’11 , 2011.
[41] VirusTotal. Antivirus scan.
https://www.virustotal.com/ﬁle/5900e4073c57b2246724 b581eba9eed76
787fb54b38f7119d301f6713856ee0a/analysis/.
[42] Guoqing Xu, Atanas Rountev, Yan Tang, and Feng Qin. Efﬁc ient
checkpointing of java software using context-sensitive ca pture and
replay. In ESEC-FSE , 2007.
[43] Min Xu, Rastislav Bodik, and Mark D. Hill. A ”ﬂight data r ecorder”
for enabling full-system multiprocessor deterministic re play. In ISCA
’03, 2003.
[44] Min Xu, Vyacheslav Malyugin, Jeffrey Sheldon, Ganesh V enkitachalam,
Boris Weissman, and Vmware Inc. Retrace: Collecting execut ion trace
with virtual machine deterministic replay. In MoBS ’07 , 2007.
[45] Jing Yang, Mary Lou Soffa, Leo Selavo, and Kamin Whiteho use.
Clairvoyant: a comprehensive source-level debugger for wi reless sensor
networks. In SenSys ’07 , 2007.
[46] Junyuan Zeng, Yangchun Fu, Kenneth Miller, Zhiqiang Li n, Xiangyu
Zhang, and Dongyan Xu. Obfuscation resilient binary code re use
through trace-oriented programming. In CCS ’13 , 2013.
[47] Xiangyu Zhang and Rajiv Gupta. Whole execution traces. InMICRO
’04, 2004.58