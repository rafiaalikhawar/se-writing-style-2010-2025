LEAP: Lightweight Deterministic Multi-processor Replay of
Concurrent Java Programs
Jeff Huang, Peng Liu, and Charles Zhang
Department of Computer Science and Engineering
The Hong Kong University of Science and T echnology
{smhuang, lpxz, charlesz }@cse.ust.hk
ABSTRACT
The technique of deterministic record and replay aims at
faithfully reenacting an earlier program execution. For con-current programs, it is one of the most important techniquesfor program understanding and debugging. The state ofthe art deterministic replay techniques face challenging ef-
ﬁciency problems in supporting multi-processor executions
due to the unoptimized treatment of shared memory ac-
cesses. We propose LEAP: a deterministic record and re-
play technique that uses a new type of local order w.r.t.
the shared memory locations and concurrent threads. Com-pared to the related work, our technique records much less
informationwithoutlosingthereplaydeterminism. Thecor-rectness of our technique is underpinned by formal modelsand a replay theorem that we have developed in this work.
Through our evaluation using both benchmarks and real
world applications, we show that LEAPis more than 10x
faster than conventional global-order based approaches and,in most cases, 2x to 10x faster than other local-order based
approaches. Our recording overhead on the two large open
source multi-threaded applications TomcatandDerbyis less
than 10%. Moreover, as the evidence of the deterministicreplay, LEAPis able to deterministically reproduce 7 out of
8r e a lb u g si n Tomcatand Derby, 13 out of 16 benchmark
bugs in IBM ConTest benchmark suite, and 100% of therandomly injected concurrency bugs.
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging—
Debugging aids; Tracing; Diagnostics
General Terms
Algorithms, Performance, Reliability
1. INTRODUCTION
As concurrency becomes the major programming model
of the performance improvement of software in the multi-
core era, it is also the culprit of many so-called Heisenbugs ,
such as data races, deadlocks, and atomicity violations, that
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies arenot made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁcpermission and/or a fee.
FSE-18, November 7–11, 2010, Santa Fe, New Mexico, USA.
Copyright 2010 ACM 978-1-60558-791-2/10/11 ...
$5.00.are easy to hatch but diﬃcult to detect and to ﬁx. One
of the most eﬀective ways for combating these bugs is the
technique of record and replay [5, 14, 10, 25, 24, 1, 23, 7,
16, 12, 17, 19, 27]. The record and replay technique aimsat fully reenacting the problematic execution of concurrent
programs, thus giving the programmers both the context
and the history information to dramatically expedite the
process of bug ﬁx.
A crucial design factor of record and replay solutions is
the degree of recording ﬁdelity, i.e., the amount of data to
be recorded, for the suﬃcient reproduction of problematic
program executions. Simply speaking, the degree of record-ing ﬁdelity is proportional to the degree of faithfulness inreplay, unfortunately, also to the runtime overhead of us-ing the technique. This characteristic is less problematic for
the hardware-based record and replay solutions [30, 20, 16,
12, 17], in which special chips share the cost of the record-ing computation. For the software-only solutions [19, 27]on uni-processors, the replay of concurrent programs can be
achieved deterministically with low overhead by capturing
the thread scheduling decisions. However, for software-onlysolutions on multi-processors , making the best trade-oﬀ be-
tween how much to record and how faithful to replay is stilla very challenging problem, drawing intense research atten-
tions [10, 25, 5, 14, 24, 1, 23].
Ourresearchisalsoconcernedwiththesoftware-onlyrecord
and replay solutions. Our general observation is that the
state of the art does not achieve the recording eﬃciency and
the replay determinism
1at the same time. Conventional de-
terministic multi-processor replay techniques usually incur a
signiﬁcantruntimeoverheadof10xto100x[14, 5, 7, 6], mak-ing them unattractive for production use or even for testingpurposes. For instance, Dejavu[5] is aglobal clock based ap-
proach that is capable of deterministically replaying concur-
rent systems on multi-processors by assigning a global order
to all “critical events”, including both the synchronizationpoints and the shared memory accesses. As indicated by
the authors, the enforcement of the global order on variable
accesses across multiple threads incurs a large runtime over-head on multi-processors. The research of lightweight recordand replay techniques [10, 25, 24, 1, 23] has successfully low-ered the recording overhead, however, at the cost of sacri-
ﬁcing the determinism in reproducing buggy runs. JaRec
[10] and RecPlay[25] abolish the idea of global ordering and
1We deﬁne replay determinism as the faithful reenactment
of all program state transitions experienced by a previous
execution. A more complete and formal model is presented
in Section 3.
207useLamport clock [13] to maintain partial thread access or-
ders w.r.t. only the monitor entry and exit events, thus,
making the recording process lightweight. However, with-
out tracking the shared memory accesses, their approaches
cannot deterministically reproduce problematic runs for thefact that a large majority of shared memory accesses are notsynchronized, either due to programming errors or becausethey are harmless [21].
As also pointed out in [26], to deterministically replay
a concurrent system on multi-processors, it is necessary torecord the thread access orders of the shared memory loca-tions, a method commonly believed to be too expensive to
bepractical[10, 25, 24, 1, 23]. Inthispaper, wedemonstrate
that it is possible to achieve eﬃciency in this approach by
observing that, given the same program input, it is suﬃcientto deterministically replay the program execution by record-ing partial thread access information local to the individual
shared variables. Based on this observation, we have de-
signed and implemented LEAP, a replay tool that addresses
both the recording eﬃciency and the replay determinism.The replay determinism is underpinned by a semantic model
and formal theorems. To achieve eﬃciency, we use a ﬁeld-
based approach to statically identify shared variables, thus,avoiding the cost of runtime identiﬁcation. In addition, wemake extensive use of static analysis to provide a close ap-proximation of the necessary program locations that need to
be monitored and, thus, to prune away a large percentage
of otherwise redundant recording operations.
The idea of the local-order based recording can be rooted
back to InstantReplay [14], which enables the deterministic
replay by recording the access history of all the shared ob-jects w.r.t. a particular thread. This technique does not suitour design objectives of being both deterministic and eﬃ-cient. First, InstantReplay requires the unique identiﬁcation
of shared objects dynamically, a task hard to be eﬃciently
and correctly implemented in practice. Second, InstantRe-
playuses a complex computation model based on the CREW
protocol, making the recording process very costly. Third,
there are important soundness issues with the local-order
based approaches that must be formally proved. Another
local-order based approach is the use of Lamport clock thattracks the partial order of critical events that each thread
sees[10, 25]. Our technique tracks the order of thread ac-
cesses that each shared variable sees , which is operationally
simpler than the use of Lamport clock.
We evaluate the runtime performance of LEAPby com-
paring to the related techniques including the use of globalclock, InstantReplay , andLamportclock. Ourmicro-benchmark
shows that LEAPis more than 10x faster than the global
clock based approach, more than 5x faster than InstantRe-
play, and at least 2x faster than the use of Lamport clock.
On real world large open source multi-threaded applicationssuch as TomcatandDerby,LEAPis 5x to 10x faster than the
related approaches, measured by third-party benchmarks.The average runtime overhead of LEAPis less than 10% on
Tomcatand Derby. Moreover, as the evidence of the replay
correctness, LEAPis able to deterministically reproduce 7
out of 8 real concurrency bugs in Tomcatand Derby,1 3o u t
of 16 benchmark bugs in IBM ConTest benchmark suite [8],
and 100% of the randomly injected concurrency bugs.
In summary, this paper makes the following contributions:1. We present a new local-order based deterministic and
eﬃcient record and replay technique, LEAP. We provide aFigure 1: Example code with races
Thread t1{
1: x=1 ;Thread t2{1:    x=1 ;
2:    y= 1;
3: if( x<0)5:    y= 0;
6:    if( y==1)3:    if(x<0)
4:        ERROR ;
}7:        x= -1;
}}
Execution schedule :1,5,2,6,7,3,4
x.vec:t1/g3t2/g3t1
212Access vectors:
y.vec:/g3t2/g3t1/g3t2
formal model of the concurrent program execution and use
it to prove the soundness of our technique.
2. We describe the implementation of LEAPthat uses
static analysis and bytecode instrumentation to transpar-
ently provide the capability of the deterministic replay forJava programs without any user intervention.
3. We evaluate LEAPby ﬁrst quantifying its diﬀerences
compared to the state of the art recording techniques, in-
cluding global clock, InstantReplay and Lamport clock. We
then conduct thorough experiments to evaluate the correct-
ness of LEAPby reproducing real and randomly injected
bugs, using popular and computation-intensive concurrentapplications.
The rest of the paper is organized as follows: Section 2
presents the technical details of LEAP; Section 3 presents
the semantic model and proofs; Section 4 describes the im-
plementation of LEAP; Section 5 evaluates LEAP;S e c t i o n6
reviews related work and Section 7 summarizes this paper.
2. LEAP: LOCAL-ORDER BASED DETER-
MINISTIC REPLAY
LEAPprovides a general technique for the determinis-
tic replay of concurrent programs on multi-processors. The
main idea of LEAPis that each shared variable tracks the
order of thread accesses it sees during execution. In this
section, we present the core techniques of LEAP.
2.1 LEAP overview
We ﬁrst use a simple example to show the main technique
ofLEAPand draw its diﬀerences as compared to the con-
ventional global-order based approach to the deterministic
replay. In Figure 1, we show a race condition that triggers
anERRORat line 4 following the interleaved execution or-
der<1,5,2,6,7,3,4> . The global-order based approaches
record this schedule and use it to re-execute the program
at the cost of 7 global synchronization operations. Our ob-
servation is that thread accesses to diﬀerent shared vari-ables need not to be tracked together. Instead of enforcinga global order, we claim that it is suﬃcient to record thethread access order that each shared variable sees. In our
example, instead of the global order vector, we use two ac-
cess vectors (x.vecand y.vec) for the shared variables x
and yand record <t1,t2,t1> and <t2,t1,t2> respectively.
We require zero global synchronization operations and two
groups of local synchronization operations executed in par-
allel. During replay, we associate xand ywith conditional
variables to enforce the access order of threads be identicalto what is recorded in their respective access vectors.
Althoughourtechniquecanbeeasilyillustrated, toensure
208determinism and eﬃciency, there are many tough challenges
that we must tackle:
1.Static shared variable localization. How to eﬀectively
locate shared variables statically? What will happen if we
miss some shared variables, or some local variables are mis-takenly recognized to be shared?
2.Consistent shared variable and thread identiﬁcation across
runs.How to match the identities of shared variables and of
threads between the recording run and the replay run? Forexample, the deterministic replay would fail if the sharedvariable xat record is incorrectly recognized as yat replay,
or the thread t1is mistakenly recognized as t2.
3.Non-unique global order. Keen readers may point out
that, by only recording the thread access orders each vari-
able sees, LEAPwill permit a global thread schedule that is
diﬀerent from the recording run. For instance, in our exam-ple, LEAPalso permits the global order <5,1,2,6,7,3,4> .
Will this aﬀect the faithfulness of the replay?
In the rest of the section, we focus on discussing the ﬁrst
two issues. The soundness of our approach associated withthethirdissueisfundamentaltoourtechnique. InSection3,
we provide a formal semantic model and proofs to show this
phenomenon does not aﬀect the faithfulness of the replay.
2.2 Locating shared variable accesses
Precisely locating shared variables is generally undecid-
able [4]. We therefore compute a complete over-approxi-
mation using a static escape analysis in the Soot2framework
calledThreadLocalObjectAnalysis [11].ThreadLocalObject-
Analysis provides on demand answers to whether a vari-
able can be accessed by multiple threads simultaneously or
not. However, there are a few important issues with thisanalysis. First, static analysis is inherently conservative, aslocal variables might be reported as shared. We show in
Section 3 (Corollary 1) that this type of conservativeness
does not aﬀect the correctness of the deterministic replay.Second,ThreadLocalObjectAnalysis does not distinguish be-
tween read and write accesses. For shared immutable vari-ables, of which the values never change after initialization,
we do not need to address them for they cannot cause non-
determinism. Third, we discover that static variables are
all conservatively reported as escaped in ThreadLocalObject-
Analysis . Since the static variables might also be accessed
only by one thread, we wish them to be analyzed in thesame way as the instance variables, in order to obtain amorepreciseresult. Thus, wemaketwoenhancementstotheThreadLocalObjectAnalysis : 1. we further reﬁne the analy-
sis results of ThreadLocalObjectAnalysis so that we do not
record accesses to shared immutable variables; 2. we modifyThreadLocalObjectAnalysis to treat static variables in the
same way as instance variables.
2.3 Field-based shared variable identiﬁcation
For Java programs, since the standard JVMs do not sup-
port the consistent object identiﬁcation across runs, we can-
not use the default object hash-code. We use a static ﬁeld-based shared variable identiﬁcation scheme, applied to the
following three categories of variables, which are collectively
referred to as the shared program elements (SPE): 1. vari-
ables that serve as monitors; 2. class variables; 3. threadescaped instance variables. These SPEs include both Java
2http://www.sable.mcgill.ca/sootFigure 2: The instrumentation of SPE accesses
class Account
{SPE name index{
intbalance1 ;                                                    
intbalance2 ;balance1 Account. balance1 1
balance2 Account balance2 2 intbalance2 ;
Bl 1…balance2 Account .balance2 2
getBalance1getBalance1
{
tmp=balance1 ;getBalance1
{
thread _id=getThreadId ();tmp balance1 ;
return tmp;
}_ g ()
get_lock( 1);
accessSPE( thread_id ,1);
bl 1
setBalance2
{}
tmp = balance1;
release_lock( 1);
return tmp; {
…
balance2 = value;                                                    return tmp;
}
}
}
monitorsandsharedﬁeldvariablesthatmaycausenondeter-
minism. SPEs are uniquely named as follows: for category1, it is the name of the declaring type of the object variable;for category 2 and 3, it is the variable name, combined withthe name of the class, in which the variable is declared.
After obtaining all the SPEs in the program, LEAPas-
signsoﬄineto each SPE a numerical index as its runtime
identiﬁer. For example, in Figure 2, suppose the two ﬁeld
variable balance1 and balance2 of the Account class are
identiﬁed as shared, they are mapped to the numerical IDs1and 2.
The static ﬁeld-based shared variable identiﬁcation re-
mains consistent across runs and does not incur runtimeoverhead. Moreover, compared to the object level identiﬁ-
cation approaches [14], this approach is more ﬁne-grained
as diﬀerent ﬁelds of the same object are mapped to diﬀer-ent indices. Consequently, accesses to diﬀerent ﬁelds of thesame object do not need to be serialized at the runtime.
There are a few issues with our ﬁeld-based shared vari-
able identiﬁcation. First, our approach does not staticallydistinguish between diﬀerent instances of the same type. Asa result, accesses to the same shared ﬁeld variable of dif-ferent instances of the same type would be serialized and
recorded into the same access vector. For this concern, we
formally prove in Section 3 (Corollary 2) that the deter-ministic replay is also guaranteed, if the thread accesses todiﬀerent shared variables are recorded globally into a single
access vector. Second, we cannot uniquely identify scalar
variables that are alias to shared array variables. To dealwith this issue, we perform an alias analysis for all of thescalar array variables in the program and represent all thealiases with the same SPE, ignoring the indexing operations.
This treatment guarantees that the nondeterminism caused
by array aliases can be correctly tracked, however, at thecost of reducing the degree of concurrency. Fortunately, inour experiment, we ﬁnd very few such cases in large Java
multi-threaded applications. A good object-oriented pro-
gram rarely manipulates shared array data directly, so theyare rarely escaped.
2.4 Unique thread identiﬁcation
Since the thread identity is the only information recorded
into the access vectors, we must make sure that a thread at
209the recording phase is correctly recognized during replay. A
naivewayistokeepamappingbetweenthethreadnameandthe thread ID during recording and use the same mapping
for replay. However, diﬀerent parent threads can race with
each other on creating their child threads. Therefore, thethread ID assignment is not ﬁxed across runs.
To address this problem, LEAPintroduces additional syn-
chronizationoperationsatthethreadcreationtimetoensure
the same thread creation order across the recording run and
the replay run. More speciﬁcally, LEAPmaintains a list that
records the IDs of the parent threads in the global order oftheir thread creation operations. The list is used to direct
the thread creation order at replay.
2.5 Handling early replay termination
Our local-order based approach permits diﬀerent global
schedules for threads that do not aﬀect each other’s pro-
gram states. One caveat of this approach is that it gives
rise to the possibility of early termination: a program crash
action, compared to the original one, might be performed
“earlier” in the replay execution, thus, making the replayedrun not fully identical to the recording run in terms of its
behavior. To faithfully replay all the thread execution ac-
tions, we ensure that every thread in the replay executionp e r f o r m st h es a m en u m b e ro fS P Ea c c e s s e sa si td o e si nt h erecording execution. Consequently, we guarantee that thereplay execution does not terminate until all the recorded
actions in the original execution are performed, thus mak-
ing the ﬁnal state of the replayed execution the same as that
of the original one.
3. A THEOREM OF LOCAL ORDERING
In this section we formally prove the soundness of our
local-order based approach for the deterministic replay of
shared memory races. We also use two corollaries to showthe soundness the ﬁeld-based shared variable identiﬁcation
approach and the soundness of using an unsound but com-
plete static escape analysis for the deterministic replay.
3.1 Modeling concurrent program execution
To provide a basis for our proof, we ﬁrst deﬁne the exe-
cution semantics of concurrent programs in a style similar
to [9]. We consider a program comprised of a set of con-
currently executing threads T={t1,t2,...}, communicating
through a global store σ. The global store consists of a set
of variables S={s1,s2,...}that are shared among threads,
and we use σ[s] to denote the value of the shared variable
son the global store. Each thread has also its own local
storeπ, consisting of the local variables and the program
counter to the thread. Each thread executes by performing
a sequence of actions on the global store and its own local
store. Each action αis a single indivisible access3on a sin-
gle variable. We use Γ( α) to denote the owner thread of
actionαandvar(α) the variable accessed by α.I fvar(α)
is a shared variable, we call αaglobal action , otherwise it is
alocal action . The program state is deﬁned as Σ = ( σ,Π),
whereσis the global store and Π is a mapping from thread
identiﬁers tito the local store πiof each thread.
3The access could be a read, a write, a lock acquisition, a
lock release, a message sending or a message receiving [22].
Nevertheless, in our setting, we do not necessarily need to
distinguish between diﬀerent access types.The program execution is modeled as a sequence of tran-
sitions deﬁned over the program state Σ. Let αkbe the
kthaction in the global order of the program execution and
Σk−1be the program state just before αkis performed (Σ0
is the initial state), the state transition sequence is:
Σ0α1
−−→Σ1α2
−−→Σ2α3
−−→...
Given a concurrent system described above, we next for-
mally deﬁne the execution semantics of action α.T og i v ea
precise deﬁnition, we ﬁrst introduce some additional nota-
tions similar to [9]:
•σ[s:=v]i si d e n t i c a lt o σexcept that it maps the
variable sto the value v.
•Π[ti:=πi]i si d e n t i c a lt oΠe x c e p tt h a ti tm a p st h e
thread identiﬁer titoπi.
Let the relation σα−→σ/primemodels the eﬀect of performing
an action αon the global store σ,a n dπα−→π/primemodels the
eﬀect of performing αon the local store π. The execution
semantics of performing αare deﬁned as:
var(α)/∈S Γ(α)=ti πiα−→π/prime
i
(σ,Π)α−→(σ,Π[ti:=π/prime
i])
var(α)=s∈SΓ(α)=tiπiα−→π/prime
iσ[s]α−→σ/prime[s]
(σ,Π)α−→(σ[s:=σ/prime[s]],Π[ti:=π/prime
i])
These semantics simply take diﬀerent kinds of actions into
consideration. The ﬁrst case means that when a local actionis performed by a thread, only the local store of the thread
is changed to a new state determined by its current state.The global store and the local stores of other threads remain
the same. The second case means that when a global action
is performed by a thread t
ion the shared variable s,o n l ys
andπiare changed to new states. The states of other shared
variables on the global store as well as the local stores of
other threads remain the same. Also, consider the action
sequence local to each thread, since the program counter is
included in the local store, the next action of tishould be
determined by ti’s current local store πi.
The execution semantics deﬁned above conform to a gen-
eral concurrent execution model with deterministic input.
Although dynamic thread creation and dynamic shared vari-able creation are not explicitly supported by the semantics,
they can be modeled within the semantics in a straightfor-
ward way [9].
3.2 Equivalence of execution schedules
The action sequence /angbracketleftαk/angbracketrightof a program execution is called
anexecution schedule denoted by δ. Suppose there is an ex-
ecution schedule δof sizeNthat drives the program state to
ΣN, our goal is to have another execution schedule δ/primethat is
able to produce the same program state as ΣN. Obviously,
this can be achieved if δ/prime=δholds. However, this is too
strong a condition. We show a relaxed and suﬃcient condi-
tion based on the access vectors of all the shared variables.
To state precisely, let δsbe the sequence of actions w.r.t.
sprojected from δ,τsbe the sequence of thread identiﬁers
picked out from δs,a n dτbe the mapping from stoτsfor
∀s∈S(τis the access vectors of all the shared variables),
we prove:
210Theorem 1.Under the execution semantics deﬁned in
Section 3.1, two execution schedules δandδ/primeof the same
concurrent program have the same ﬁnal state ΣN=Σ/primeNif
Σ0=Σ/prime0∧τ=τ/prime.
The core of the proof is to prove the following lemma:
Lemma 1.For any action α/primek(k≤N) in the replay
execution δ/prime, suppose it is the pthaction on a shared variable
s,t h e nα/primekis equal to the pthaction on sin the original
execution δ.
For two actions to be equal here, they need to read and
write the same values, not just do the same operation on
the same shared variable. Next, we ﬁrst deﬁne a notion of
“happened-before”, and then we prove Lemma 1 using this
notion.
Consider the “happened-before” order of the original exe-
cution. The“happened-before”relationisdeﬁnedasfollows:
(a) if action αiimmediately preceded action αjin the same
thread, then αihappened-before αj;
(b) if action αiand action αjby diﬀerent threads are con-
secutive actions on a shared variable s, without any in-
tervening actions on s,t h e nαihappened-before αj;
(c) “happened-before” is reﬂexive and transitive.
More accurately, rules (a) and (b) deﬁne “happened-immedi-
ately-before” and “happened-before” is the reﬂexive transi-
tive closure of “happened-immediately-before”.
Proof. Let’s say the “happened-before” tree of an ac-
tion is the tree of all the actions that “happened-before” it,
we next prove Lemma 1 by induction on the depth of the
“happened-before” tree.
Base case : Consider an action on the shared variable
s, with a “happened-before” tree of depth 1. This means
that the current action does not depend on anything that
happened-before it involving shared variables. Because the
ﬁrst action on a shared variable is performed by the samethread in both the original and the replay execution, and be-cause that thread is deterministic, the replay action should
be identical to the one in the original execution.
Induction : Now assuming that Lemma 1 holds for all
actions with happened-before depth ≤n, we prove it for n+
1. Consideranaction α
ionasharedvariable s,w h e r eαihas
a tree of happened-before depth n+1. Let’ssay αiis thepth
action on s.T h e(p-1)thaction on shas a lower happened-
before depth so it is an equal action in both the original and
the replay execution. Additionally, every action αjthat
“happened-immediately-before” αihas a happened-before
tree of depth n, therefore it is equal to a similarly numbered
action in the original execution (i.e., if αjis thekthaction
on a shared variable v,t h e nαjis equal to the kthaction
onvin the original execution). Now action αionly depends
on all the αjactions. So, since our approach enforces that
thepthaction on sis performed by the same thread in both
executions, and since the thread is deterministic and everyvalue that α
ic a nd e pe n do nh a st obee q u a lt oe a c ho t h e r ,i t
follows that action αiis also equal in the original and replay
executions.
Lemma 1 is proved. If we apply Lemma 1 to the last
actionα/primeNin the replay execution, we can get Σ/primeN=ΣN.
Thus, Theorem 1 is proved.With Theorem 1, we have proved the soundness of local-
order based approaches for the deterministic replay that isable to reach the same program state as the original execu-
tion, by only recording the access vectors for all the shared
variables.
Whileτ=τ
/primeis a rather relaxed condition, we can surely
add more information that also guarantees the determinis-
tic replay. For example, if the local variable accesses are
recorded, the deterministic replay is still guaranteed as long
as we do not miss any shared variable accesses. Followingwe derive two corollaries:
Corollary 1.The deterministic replay holds as long as
τ=τ
/prime, regardless of whether accesses to local variables are
recorded or not.
Corollary 2.Recording diﬀerent shared variable accesses
into a single access vector does not aﬀect the correctness ofthe deterministic replay.
As noted in Section 2.2, the static escape analysis is con-
servative such that local variables might be mistakenly cat-egorized as shared. Corollary 1 ensures that this conserva-tiveness does not aﬀect the correctness of the determinis-tic replay as long as all the shared variables are correctly
identiﬁed. Corollary 2 is easy to understand as the thread
access orders on diﬀerent shared variables can be consideredas a global order on a single variable abstracted from these
shared variables. To be more clear, assuming all thread ac-
cesses are recorded into a global access vector, it is a global
order of the execution schedule and the determinism musthold. AsnotedinSection2.3, Corollary2ensuresthesound-ness of our ﬁeld-based shared variable identiﬁcation.
4. LEAP IMPLEMENTATION
We have implemented LEAPusing the Soot2framework.
Figure3showstheoverviewofthe LEAPinfrastructure, con-
sisting of the transformer, the recorder, and the replayer.
The transformer takes the bytecode of an arbitrary Javaprogram and produces two versions: the record version and
the replay version. Started by a record driver, LEAPcollects
the access vector for each SPE during the execution of the
record version. When the recording stops, LEAPsaves both
the access vectors and the thread creation order information
Figure 3: The overview of LEAP infrastructure
TfRecorder
Trans former
SPE Access Recorder
Rd
SPE LocatorThread Creation Order 
RecorderRecord
version
SPE Access 
InstrumentorReplay Driver GeneratorOriginal
program
Instrumentor
Record versionAccessvectorReplay
driver
Thread
creation
order
Record version
Generator Replayer
Replay
version
Replay version 
GeneratorTrace Loader
Thread Schedulerversion
Thread Scheduler
211and generates a replay driver. To replay, the LEAPreplayer
uses the generated replay driver as the entry point to run the
replay version of the program, together with recorded infor-
mation. The replayer takes control of the thread scheduling
to enforce the correct execution order of the threads w.r.t.the SPEs. We now introduce each of the components inturn.
4.1 The LEAP transformer
The LEAPtransformer performs the instrumentation on
Jimple, an intermediate representation of Java bytecode in
thethree-addressform. Fortherecordversion, afterlocatingall the SPEs in the program, the transformer visits eachJimple statement and performs the following tasks:
Instrumenting SPE accesses If the SPE is not a Java
monitor object, we insert a LEAPmonitoring API invoca-
tion before the Jimple statement to collect both the thread
ID and the numeric SPE ID. Both the API call and the SPE
access are wrapped by a lock speciﬁc to the accessed SPE
to ensure we collect the right thread accessing order seen bythe SPE. If the SPE is a Java monitor object, we insert themonitoring API call afterthemonitorentry andbeforethe
monitorexit instructions. The API call is also inserted be-
fore notify/notifyAll /thread start operations and after
wait/thread join operations. Figure2showsasource-code
equivalent view of the instrumentation on the read/write ac-
cessestothesharedﬁeldvariables. Theboxontheleftshows
the original method getBalance1 , inside of which the shared
variable balance1 is read. The box on the right shows the
transformed version of getBalance1 . For multiple shared
variable accesses in a method, the thread ID needs only to
be obtained once. Also, to remove the unnecessary record-
ing overhead, we do not need to instrument the SPEs that
are always protected by the same monitor.
Instrumenting thread initialization To capture the
thread identity information, as described in Section 2.4,
the transformer inserts the instrumentation code inside the
Thread constructor to synchronize and to collect the threadcreation order.
Instrumenting recording end points To enable the
deterministic replay, we insert the recording end points to
save the recorded runtime information and to generate the
replaydriver. Currently, LEAPsupportsthreetypesofrecord-
ing end points. First, we add a ShutDownHook to the JVM
Runtimeintherecorddriverasarecordingendpoint. When
the program ends, the ShutDownHook will be invoked to
perform the saving operations. Second, we insert a try-catch block into the mainthread and the runmethod of
each Java Runnable class. We then add a method invo-cation in the catch block to capture the uncaught runtime
exceptions as the recording end points. Third, LEAPalso
supports the user speciﬁed recording end points by allowing
the annotation-based speciﬁcation of end points. During thetraversal of the program statements, the transformer will re-
place the annotation with a method invocation, indicating
the end of recording.
To generate the replay version, the transforming process
is largely identical to the record version with a few diﬀer-ences: 1. since the order of synchronization operations on
e a c hS P Ei sc o n t r o l l e db yt h e LEAPreplayer during replay,
we need to insert the API call beforethe original synchro-
nization operations in the program, i.e, monitorenter and
wait, to avoid deadlock; 2. the inserted API call is boundto a diﬀerent implementation from the one used during the
recording phase; 3. since we need to ensure that the replayexecution does not terminate until all recorded actions inthe original execution have been executed (See Section 2.5),we insert extra API invocations aftereach SPE access so
that we can check whether a thread has performed all its
recorded actions in the original execution or not.
4.2 The LEAP recorder
When executing the record version of the target program,
theLEAPmonitoring API will be invoked on each critical
event to record the ID of the executing thread into the ac-
cess vector of the accessed SPE. To reduce the memoryrequirement, we use a compact representation of the ac-
cess vectors by replacing consecutive and identical thread
IDs with a single thread ID and a corresponding counter.
For example, suppose the access vector of a SPE contains
<t1,t1,t2,t2,t2> ,i ti sr e p l a c e db y <t1,t2> and a corre-
sponding counter <2,3>. This compact representation pro-
duces much smaller log size compared to the related ap-
proaches in our experiment.
Onceanewthreadiscreated, weaddtheparentthreadID
to the thread creation order list. Once a program end point
is detected, the LEAPrecorder will then save the recorded
data, i.e, the recorded access vectors, and the thread cre-
ation order list, and generate the replay driver.
4.3 The LEAP replayer
The LEAPreplayer controls the scheduling of threads to
enforce a deterministic replay using both the access vectors
andthethreadidentityinformation. Toenabletheuserlevel
thread scheduling, the replayer associates each thread in re-play with a semaphore maintained in a global data struc-
ture, so that each thread can be suspended and resumed ondemand.
To replay, the replay driver ﬁrst loads both the saved ac-
cess vectors and the thread creation order list and startsexecuting the replay version of the program. Before a newthread is created, the ID of the parent thread is compared
to the ID at the head of the thread creation order list. If
they are the same, the new thread is allowed to be createdand the head of the list is removed. In this way, the iden-
t i ﬁ c a t i o no fe a c ht h r e a di sg u a r a n t e e dt ob et h es a m ea sthat of the recording phase. Before each SPE access, the
threads use their semaphores to coordinate with each other
in order to obey the access order deﬁned in the access vec-tor of the SPE. Also, to make sure that the replay executiondoes not terminate “early”, the thread also counts the total
number of SPE accesses it has performed so far after each
SPE access. The thread suspends itself if it ﬁnds that it hasalready executed all its SPE accesses in the original execu-tion, as recorded in the access vector, until all threads haveﬁnished their recorded actions. Since the threads accessing
diﬀerent SPEs can execute in parallel, the replaying process
is also faster than that of a global order scheduler, whichc a no n l ye x e c u t eo n et h r e a de a c ht i m e .
5. EV ALUATION
5.1 Evaluation methodology
We assess the quality of LEAPby quantifying both its
recording overhead and the correctness of the determinis-
tic replay. To properly compare our technique to the state
212of the art, we have also implemented the following tech-
niques: the Dejavuapproach based on the global clock [5],
t h et e c h n i q u ep r e s e n t e db y InstantReplay [14], and the JaRec
approach based on the Lamport clock [13]. Because none of
these tools are publicly available, we faithfully implementedthem according to their representative publications. SinceJaRecis not a deterministic replay technique, we extended
its capability to tracking shared memory races, in order to
make it comparable to our technique. Our implementations
are publicly available
4.
For the evaluation, we ﬁrst design a micro-benchmark
to conduct controlled experiments for quantifying various
runtime characteristics of the evaluated techniques. We
then use real complex Java server programs and third-partybenchmarks to assess the recording overhead of LEAPin
comparison to the related approaches. We use the bug re-producibility as a way to verify if our technique can faith-
fully and deterministically reproduce problematic concur-
rent runs. All experiments are conducted on two 8-core3.00GHzIntelXeonmachineswith16GBmemoryandLinuxversion 2.6.22. We now present these experiments in detail.
Figure 4: The runtime characteristic of LEAP and
other techniques on our microbenchmark with the
number of SPE ranges from 1 to 500. The mi-crobenchmark starts 10 threads running on 8 pro-cessors.
0 50 100 150 200 250 300 350 400 450 5000123456x 105
Number of SPETime <ms>Processor number = 8
Thread number = 10Base
LEAP
Lamport
Global
Instant
5.1.1 Micro-benchmarking
We have designed a micro-benchmark to quantify the run-
time characteristics of LEAPa n dt h er e l a t e dr e c o r da n d
replay techniques. The benchmark consists of concurrent
threads that randomly update shared variables in a loop.
For each experiment, we can control the number of threads
and shared variables. In our experiments, we set the numberof threads ranging from 1 to 100, and the number of sharedvariables ranging from 1 to 1000, we then measure the timeneeded for all the threads to ﬁnish a ﬁxed total number of
updating operations under diﬀerent settings.
Figure 4 and 5 show the runtime characteristics of LEAP
and the related techniques on our micro-benchmark. In the
ﬁgures,Baserefers to the native execution. Global,Lam-
4http://www.cse.ust.hk/prism/leapFigure 5: The runtime characteristic of LEAP and
other techniques on our microbenchmark with the
number of threads ranges from 1 to 80 running on
8 processors. The number of SPE is set to 1000.
0 10 20 30 40 50 60 70 8000.511.522.533.54x 105
Number of ThreadsTime <ms>Processor number = 8
SPE number = 1000
Base
LEAP
Lamport
Global
Instant
portandInstantrefer to the recorded execution using global
clock, Lamport clock and InstantReplay respectively. Figure
4 shows that the performance of the LEAPinstrumented ver-
sion is close to the base version. By ﬁxing the number of
threads to 10, as the number of SPE increases from 10 to
500, LEAPis more than 10x faster than global clock, more
than 5x faster than InstantReplay , and at least 2x faster than
Lamport clock. Global clock is the slowest among the four
techniques. The main reason is that the use of global clock
requires a global synchronization on every shared variable
access, which signiﬁcantly aﬀects the degree of concurrency.Figure 5 shows a similar performance trend as the numberof threads increases from 10 to 80 and the number of SPEsis ﬁxed to 1000.
5.1.2 Benchmarking with third-party systems
To perform the unbiased evaluation, we ﬁrst use LEAP
on two widely used complex server programs, Derbyand
Tomcat,w i t ht h e PolePosition5database benchmark and the
SPECWeb-20056web workload benchmark. Each bench-
mark starts with 10 threads and we measure the time for ﬁn-
ishing a total number of 10000 operations. We also selected
a suite of third-party benchmarks, among which Avroraand
Lusearch are from the dacapo-9.12-bach benchmark suite7,
and MolDyn,MonteCarlo and RayTracer are from the Java
Grande multi-thread benchmark suite.
Table 1 shows some of the relevant static attributes of
the benchmarked programs as well as the associated run-
time overhead of the evaluated record and replay techniques.
We report the total number of ﬁeld variable accesses in the
program ( Total), the total number instrumented SPE ac-
cesses (SPE), the number of SPEs ( SPESize ), the log size
(KB/sec) of the related approaches ( Log), the log size of
LEAP(LogCmp), and the runtime overhead ( LEAP,Lam-
port,InstantandGlobal). Overall, the percentage of SPE
5http://polepos.sourceforge.net
6http://www.spec.org/web2005
7http://dacapobench.org
213Table 1: The runtime overhead of LEAP and the state-of-the-art techniques
Application LOC Total SPE SPESize LEAP Lamport Instant Global
Avrora 93K16003 1725(11%) 113 626% 1697% 1821% 1036%
Lusearch 69K11497 1140(9.9%) 75 74% 308% 379% 227%
Derby 1.51M 48356 1433(3.0%) 264 9.9% 68% 113% 52%
Tomcat 535K 23046 654(2.6%) 163 7.3% 39% 44% 34%
MolDyn 864 821634(77%) 66 64% 2776% 3567% 9960%
MonteCarlo 3128 427104(24%) 18 7.5% 7.9% 8.6% 9.1%
RayTracer 1431 442223(50%) 19 18% 39% 43% 94%
accessesoverthetotalnumberofﬁeldvariableaccessesvaries
f r o ml e s st h a n3 %o n Derbyand Tomcatto around 10% on
Avroraand Lusearch.A s MolDyn (77%), MonteCarlo (24%)
and RayTracer (50%) are relatively small applications ded-
icated for multi-threaded benchmarking, the percentage of
their SPE accesses is large.
Log size By using our compact representation of the ac-
cess vectors, the log size of LEAPis much smaller than the
related approaches, from 3x in MolDyn to as large as 164x
inDerby. We recognize that the log size in LEAPis still
considerable ranging from 51 to 37760 KB/sec. With theincreasing disk capacity and disk write performance, as alsoobserved by other researchers [24], moderate log size doesnot pose serious problem. For long running programs, we
can reset logs through the use of checkpoints.
Recording overhead LEAPis the fastest on all the eval-
uated applications. It is even more than 150x faster thanglobal clock on MolDyn.F o r Derbyand Tomcat,LEAPis
5x to 10x faster than all the related approaches. The sheerruntime overhead of LEAPonDerbyandTomcatis less than
10% (9.9% and 7.3% respectively). LEAP’s overhead is large
onAvrora(626%), the reason is that there are several SPEs
inAvrorathat are frequently accessed in hot loops.
5.1.3 Concurrency bug reproduction
One of the major motivating forces for the record and re-
play technique is to help reproducing so-called Heisenbugs.
We believe that the ability of deterministically reproduc-
ing a concurrency-related bug is a strong indicator of the
replay correctness, because it requires the program stateto be correctly restored for the bug to be triggered. Tocompare the bug reproducibility, we have also implemented
JaRecforthecomparison. Weﬁrstcompare LEAPandJaRec
for their capabilities of reproducing real-world concurrency
b u g sh a p p e n e di nc o m p l e xs e r v e rs y s t e m sa sw e l la san u m -ber of benchmark bugs widely used in concurrency testing.To proper quantify the bug reproducibility, we have alsodesigned a bug injection technique that injects atomic setviolations into our micro-benchmark. We then assess how
many of the violations can be deterministically replayed byLEAPand JaRec.
Random bug injection
Our bug injection technique is based on the problematic
thread interleaving patterns presented in [29]. We intro-duce 10 dummy shared variables into the program and di-
vide them into 5 groups, each group representing an atomic
set as deﬁned in [29]. During the recording phase, on eachcritical event, the thread also randomly performs a writeor
readaccess on one of the introduced variables. We use the
same random seed for each thread across record and replay.After each random access, if one of the problematic thread
interleaving patterns occurs, the program stops and the re-play data are exported. Given the same program input, adeterministic replay technique should be able to recreate theoccurred bug pattern.
To compare the concurrency bug reproducibility between
LEAPandJaRec, we use 100 diﬀerent random seeds to inject
100 concurrency bugs into our micro-benchmark. For eachrun, we initialize 10 threads in the program. LEAPis able to
deterministically reproduce 100% of these bugs, while JaRec
cannot deterministically reproduce any of them. The reasonis that JaRecdoes not record shared memory races, while
all these bug patterns are generated on shared memory ac-cesses.
Table 2: Summary of the evaluated real bugs
Bug Id Version LOC Exception Type
Derby230 Derby-10.1 1.34M DuplicateDescriptor
Derby1573 Derby-10.2 1.52M NullPointerException
Derby2861 Derby-10.3 1.51M NullPointerException
Derby3260 Derby-10.2 1.52M SQLException
Tomcat728 Tomcat-3.2 150K NullPointerException
Tomcat4036 Tomcat-3.3 184K NumberFormatException
Tomcat27315 Tomcat-4.1 361K ConcurrentModiﬁcation
Tomcat37458 Tomcat-5.5 535K NullPointerException
Table 3: Summary of the evaluated benchmark bugs
Bug Name LOC Bug Description
BubbleSort 362Not-atomic, Orphaned-Thread
AllocationVector 286Weak-reality, two stage access
AirlineTickets 95 Not-atomic interleaving
PingPong 272 Not-atomic
BuﬀerWriter 255 Wrong or no-Lock
RandomNumbers 359 Blocking-Critical-Section
Loader 130 Initialization-Sleep Pattern
Account 155 Wrong or no-Lock
LinkedList 416 Not-atomic
BoundedBuﬀer 536 Notify instead of notifyAll
MergeSort 375 Not-atomic
Critical 73 Not-atomic
Deadlock 135 Deadlock
DeadlockException 255 Deadlock
FileWriter 311 Not-atomic
Manager 236 Not-atomic
Real and benchmark concurrency bugs
Table 2 and 3 show the description of the real concurrency
bugs and the benchmark bugs used in our experiments. Allthe 8 real bugs in Table 2 are extracted from the Derbyand
214Tomcatbug repositories8that were reported by users. The
16 benchmark bugs in Table 3 are from the IBM ConTest
benchmark suite [8], which cover the major types of concur-
rency bugs, including data races, atomicity violation, order
violation, and deadlocks. We also run both JaRecandLEAP
on these buggy programs to compare the bug reproducibilitybetween them.
For the 8 real world concurrency bugs, LEAPis able to de-
terministically reproduce 7 of them (88%), except the bugtomcat4036 ,a n d JaRecreproduced none ofthem. Forthe 16
benchmark bugs, LEAPcan reproduce 13 of them (81%), ex-
cept BufferWriter ,Loader,a n d DeadlockException , while
JaReccan only reproduce one of them ( Deadlock ). The
reason for LEAPto miss tomcat4036 is that the bug is trig-
gered by races of the internal data of the underlying JDK
library java.text.DateFormat ,w h i c h LEAPdoes not in-
strument. And because all these real bugs are related to
shared memory races, JaRecare not able to reproduce any
of them. For the three benchmark cases LEAPcannot re-
produce, two of them are related to random numbers and
the other one makes LEAP OutOfMemory because too many
threads ( >5000) are involved in loops.
5.2 Discussion
The evaluation results have clearly demonstrated the su-
perior runtime performance of LEAPas well as its much
higher concurrency bug reproducibility, compared to exist-
ing approaches. Through our experiments with real world
large multi-threaded applications, we observed several limi-
tations of LEAPthat we plan to address in our future work:
Input nondeterminism AsLEAPonlycapturesthenon-
determinism brought by thread inter-leavings, it may not re-produce executions containing input nondeterminism, e.g.,
programs with nondeterministic I/O. The two benchmark
bugsthat LEAPcannotreproducebothcontainrandomnum-
ber generators that use the current system time as the ran-dom seed. Since it is not likely to keep the random num-
bers the same across record and replay without saving them,
LEAPmay not reproduce executions that contain such ran-
dom issues. A way to overcome these issues is to save theprogram states of some key nondeterministic events, e.g.,the value of random seeds. We set this as our future work.
JDK library LEAPdoes not record shared variable ac-
cesses in the underlying JDK library. If an execution con-tains races of the internal data of these APIs, LEAPmight
not be able to reproduce it. The bug tomcat4036 is an ex-
ample of this limitation. In fact, we can also instrument theunderlying Java Runtime, but as the JDK library is usedfrequently, it would incur large runtime overhead. An im-plementation of LEAPon the JVM should relieve this issue
as the JVM environment enables eﬃciently tracing the in-ternal data of the JDK library. We also set this as our future
work.
Long running programs LEAPcurrently has to replay
from the beginning of the program execution. For long run-
ning programs, it might not be convenient to replay the
whole program execution concerning the long replay timeand the large log size. We plan to extend LEAPto use
a lightweight checkpoint scheme that only replays the pro-gram from the last checkpoint to the recording end point.
8https://issues.apache.org6. RELATED WORK
As the deterministic replay of concurrent programs is of
such signiﬁcant importance, there have been enumerable re-
search eﬀorts on this topic. In this section we brieﬂy review
some of the other key software-only related work.
Record/replay PRES[24] and ODR[1] are two recent
projects that use record/replay for the reproduction of con-
currency bugs. PRESproposes a novel technique that uses
a feedback replayer to explore thread interleaving space,
which reduces the recording overhead at the price of morereplay attempts. ODRproposes a new concept, output-
deterministic replay, that focuses on replaying the same pro-gram output, and uses a similar idea as PRESthat depends
on oﬄine inference to help recording less online. SMP-ReVirt
[7] makes use of hardware page protection to detect shared
memory accesses, aiming at replaying multi-processor vir-
tual machines, but its overhead can increase upto 10x onmulti-processors. To avoid the overhead of recording mem-ory races, RecPlay[25] and Kendo[23] provide deterministic
multi-threading of concurrent programs that perfectly syn-
chronized using locks. Unfortunately, most real world con-
current applications may contain benign or harmful dataraces, making these approaches unattractive. Though Rec-
Playand Kendoboth use a data race detector during replay
toensurethedeterministicreplayupuntiltheﬁrstrace, theysuﬀer from the limitation that they cannot replay past thedata race. For instance, while debugging using a replayer,a programmer might want to understand the after eﬀects ofa benign data race, which is not possible with RecPlay and
Kendo.
Deterministic by default There are also approaches
to the nondeterminism in concurrency by making concur-rent programs deterministic by default. In this direction,
there have been language design approaches [3, 2] as well
as hardware ones [6, 31]. For example, languages such asDPJ[3] guarantee deterministic semantics by providing a
type and eﬀect system to perform compile-time type check-ing. The problem with language level approaches is that
they often require nontrivial programmer annotations orhave a limited class of concurrency semantics. Hardware ap-
proaches such as DMP[6] make inter-thread communication
fully deterministic by imposing a deterministic commit or-
der among processors. PSet[31] eliminates untested thread
inter-leavings by enforcing the runtime to follow a tested
interleaving via processor support. Because hardware ap-proaches rely on non-standard hardware support, they arelimited to proprietary platforms. Though DMP[6] also pro-
poses a software-only algorithm, its overhead is more than10x.
Code analysis tools Another line of approaches is to
use code analysis tools [15] or model checkers [18] to try
to eliminate concurrency bugs oﬄine. Code analysis tools
suﬀer from inaccuracies and false positives. Model checkersstatically explore all thread schedules, which is hard to scaleto large programs. Though CHESS[18] employs a context-
bounded way to reduce the search space, it may miss most of
the concurrency bugs in theory. RaceFuzzer [28] is another
representative technique that given a potential race pair it
controls a race directed random thread scheduler to activelycreaterealraces. As RaceFuzzer hasonlypartialinformation
oftheraces, itsuﬀersfromthelimitationofnondeterminism.
2157. CONCLUSION
We have presented LEAP, a new local-order based ap-
proach that deterministically replays concurrent program
executions on multi-processors with low overhead. Our ba-
sic idea is to capture the thread access history of each shared
variable, and we use theoretic models to guarantee its cor-
rectness. We have implemented LEAPas an automatic pro-
gram transformation tool that provides the deterministic re-
play support to arbitrary Java programs. To evaluate ourtechnique, we make use of both benchmarks and real worldconcurrent applications. We extensively quantiﬁed the run-
time overhead of using LEAPas well as the correctness of the
LEAP-based replay through reproducing concurrency bugs.
Our evaluation shows that, compared to the state of the art,
LEAPincurs much lower runtime overhead and has much su-
perior capability of correctly reproducing concurrency bugs.
For real world applications that we evaluated, the overheadof using LEAPis under 10%, exhibiting the great potential
for the production use. We have also discussed some limi-tations that we have observed during our experimentation,
and these limitations are the focus of our future work.
8. ACKNOWLEDGEMENT
The authors wish to express deep appreciation to the
anonymous FSE reviewers for their insightful and construc-
tive comments on an early draft of this paper. This research
has been supported by RGC GRF grant 622208. The au-
thors are very grateful for this support.
9. REFERENCES
[1] Gautam Altekar and Ion Stoica. Odr: output deterministic
replay for multicore debugging. In SOSP, pages 193–206.
ACM, 2009.
[2] Emery D. Berger, Ting Yang, Tongping Liu, and Gene
Novark. Grace: safe multithreaded programming for
c/c++. In OOPSLA , pages 81–96. ACM, 2009.
[3] Robert L. Bocchino, Jr., Vikram S. Adve, Danny Dig,
Sarita V. Adve, Stephen Heumann, Rakesh Komuravelli,
Jeﬀrey Overbey, Patrick Simmons, Hyojin Sung, and
Mohsen Vakilian. A type and eﬀect system for deterministicparallel java. In OOPSLA , pages 97–116. ACM, 2009.
[4] Eric Bodden and Klaus Havelund. Racer: eﬀective race
detection using aspectj. In ISSTA, pages 155–166. ACM,
2008.
[5] Jong-Deok Choi and Harini Srinivasan. Deterministic
replay of java multithreaded applications. In SPDT, pages
48–59. ACM, 1998.
[6] Joseph Devietti, Brandon Lucia, Luis Ceze, and Mark
Oskin. Dmp: deterministic shared memory
multi-processing. In ASPLOS , pages 85–96. ACM, 2009.
[7] George W. Dunlap, Dominic G. Lucchetti, Michael A.
Fetterman, and Peter M. Chen. Execution replay of
multiprocessor virtual machines. In VEE, pages 121–130.
ACM, 2008.
[8] Eitan Farchi, Yarden Nir, and Shmuel Ur. Concurrent bug
patterns and how to test them. In IPDPS, page 286.2.
IEEE Computer Society, 2003.
[9] Cormac Flanagan and Stephen N Freund. Atomizer: a
dynamic atomicity checker for multithreaded programs. InPOPL, pages 256–267. ACM, 2004.
[10] A. Georges, M. Christiaens, M. Ronsse, and
K. De Bosschere. Jarec: a portable record/replay
environment for multi-threaded java applications. Software
Practice and Experience , 34(6):523–547, 2004.
[11] Richard L. Halpert, Christopher J. F. Pickett, and Clark
Verbrugge. Component-based lock allocation. In PACT,
pages 353–364. IEEE Computer Society, 2007.[12] Derek R. Hower and Mark D. Hill. Rerun: Exploiting
episodes for lightweight memory race recording. In ISCA,
pages 265–276. IEEE Computer Society, 2008.
[13] Leslie Lamport. Time, clocks, and the ordering of events in
a distributed system. Communications of the ACM ,
21(7):558–565, 1978.
[14] T. J. LeBlanc and J. M. Mellor-Crummey. Debugging
parallel programs with instant replay. IEEE Transactions
on Computers , 36(4):471–482, 1987.
[15] Shan Lu, Soyeon Park, Chongfeng Hu, Xiao Ma, Weihang
Jiang, Zhenmin Li, Raluca A. Popa, and Yuanyuan Zhou.
Muvi: automatically inferring multi-variable accesscorrelations and detecting related semantic and
concurrency bugs. In SOSP, pages 103–116. ACM, 2007.
[16] Pablo Montesinos, Luis Ceze, and Josep Torrellas.
Delorean: Recording and deterministically replaying
shared-memory multi-processor execution eﬃciently. InISCA, pages 289–300. IEEE Computer Society, 2008.
[17] Pablo Montesinos, Matthew Hicks, Samuel T. King, and
Josep Torrellas. Capo: a software-hardware interface for
practical deterministic multi-processor replay. In ASPLOS ,
pages 73–84. ACM, 2009.
[18] Madanlal Musuvathi, Shaz Qadeer, Thomas Ball, G´ erard
Basler, Piramanayagam A. Nainar, and Iulian Neamtiu.Finding and reproducing heisenbugs in concurrent
programs. In OSDI, pages 267–280, 2008.
[19] Satish Narayanasamy, Cristiano Pereira, Harish Patil,
Robert Cohn, and Brad Calder. Automatic logging of
operating system eﬀects to guide application-level
architecture simulation. In SIGMETRICS , pages 216–227.
ACM, 2006.
[20] Satish Narayanasamy, Gilles Pokam, and Brad Calder.
Bugnet: Continuously recording program execution for
deterministic replay debugging. In ISCA, pages 284–295.
IEEE Computer Society, 2005.
[21] Satish Narayanasamy, Zhenghao Wang, Jordan Tigani,
Andrew Edwards, and Brad Calder. Automatically
classifying benign and harmful data racesallusing replay
analysis. In PLDI, pages 22–31. ACM, 2007.
[22] Robert O’Callahan and Jong-Deok Choi. Hybrid dynamic
data race detection. In PPoPP, pages 167–178. ACM, 2003.
[23] Marek Olszewski, Jason Ansel, and Saman Amarasinghe.
Kendo: eﬃcient deterministic multithreading in software. In
ASPLOS , pages 97–108, New York, NY, USA, 2009. ACM.
[24] Soyeon Park, Yuanyuan Zhou, Weiwei Xiong, Zuoning Yin,
Rini Kaushik, Kyu H. Lee, and Shan Lu. Pres:probabilistic replay with execution sketching on
multi-processors. In SOSP, pages 177–192. ACM, 2009.
[25] Michiel Ronsse and Koen De Bosschere. Recplay: a fully
integrated practical record/replay system. ACM TOCS ,
17(2):133–152, 1999.
[26] Michiel Ronsse, Koen De Bosschere, Mark Christiaens,
Jacques Chassin de Kergommeaux, and DieterKranzlm¨ uller. Record/replay for nondeterministic program
executions. Communications of the ACM , 46(9):62–67,
2003.
[27] Mark Russinovich and Bryce Cogswell. Replay for
concurrent non-deterministic shared-memory applications.InPLDI, pages 258–266. ACM, 1996.
[28] Koushik Sen. Race directed random testing of concurrent
programs. In PLDI, pages 11–21. ACM, 2008.
[29] Mandana Vaziri, Frank Tip, and Julian Dolby. Associating
synchronization constraints with data in an object-oriented
language. In POPL, pages 334–345. ACM, 2006.
[30] Min Xu, Rastislav Bodik, and Mark D. Hill. A ”ﬂight data
recorder” for enabling full-system multiprocessor
deterministic replay. In ISCA, pages 122–135. ACM, 2003.
[31] Jie Yu and Satish Narayanasamy. A case for an interleaving
constrained shared-memory multi-processor. In ISCA,
pages 325–336. ACM, 2009.
216