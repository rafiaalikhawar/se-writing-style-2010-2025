See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/221554398
Precise Calling Context Encoding
Conf erence Paper    in  IEEE T ransactions on Softw are Engineering  · May 2010
DOI: 10.1145/1806799.1806875  · Sour ce: DBLP
CITATIONS
53READS
161
4 author s, including:
William N. Sumner
Simon F raser Univ ersity
16 PUBLICA TIONS    358 CITATIONS    
SEE PROFILE
Dasar ath Weer atung e
Purdue Univ ersity West Laf ayette
7 PUBLICA TIONS    223 CITATIONS    
SEE PROFILE
Xiang yu Zhang
Taiyuan Univ ersity of T echnolog y
312 PUBLICA TIONS    11,649  CITATIONS    
SEE PROFILE
All c ontent f ollo wing this p age was uplo aded b y William N. Sumner  on 02 Mar ch 2014.
The user has r equest ed enhanc ement of the do wnlo aded file.Precise Calling Context Encoding
William N. Sumner, Yunhui Zheng, Dasarath Weeratunge, Xiangyu Zhang
Department of Computer Science, Purdue University
{wsumner,zheng16,dweeratu,xyzhang}@cs.purdue.edu
ABSTRACT
Calling contexts are very important for a wide range of ap-
plications such as proﬁling, debugging, and event logging.
Most applications perform expensive stack walking to re-
cover contexts. The resulting contexts are often explicitly
represented as a sequence of call sites and hence bulky. We
propose a technique to encode the current calling context
of any point during an execution. In particular, an acyclic
call path is encoded into one number through only integer
additions. Recursive call paths are divided into acyclic sub-
sequences and encoded independently. We leverage stack
depth in a safe way to optimize encoding: if a calling con-
text can be safely and uniquely identiﬁed by its stack depth,
we do not perform encoding. We propose an algorithm to
seamlessly fuse encoding and stack depth based identiﬁca-
tion. The algorithm is safe because diﬀerent contexts are
guaranteed to have diﬀerent IDs. It also ensures contexts
can be faithfully decoded. Our experiments show that our
technique incurs negligible overhead (1.89% on average). For
most medium-sized programs, it can encode all contexts with
just one number. For large programs, we are able to encode
most calling contexts to a few numbers.
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging—
Monitors, Testing tools
General Terms
Reliability, Security, Performance, Experimentation
Keywords
Calling Context, Dynamic Context Sensitivity, Proﬁling
1. INTRODUCTION
The goal of calling context encoding is to uniquely repre-
sent the current context of any execution point using a small
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’10, May 2-8 2010, Cape Town, South Africa
Copyright 2010 ACM 978-1-60558-719-6/10/05 ...$10.00.number of integer identiﬁers (IDs), ideally just one. Such
IDs are supposed to be automatically generated at runtime
by program instrumentation. Eﬃcient context encoding is
important for a wide range of applications.
Event logging is essential to understanding runtime inter-
actions between diﬀerent components of large distributed or
parallel systems. However, diﬀerent modules in these sys-
tems tend to use the same library to communicate, e.g.,
sending a message using a socket library. Simply logging
these communication events often fails to record the intents
of these events. Recording their contexts would be very in-
formative, but on the other hand, expensive and bulky, as it
often implies walking stack frames to reconstruct a context
and explicitly dumping the context as a sequence of sym-
bolic function names. It has been shown in [22] that context
sensitive event logging is critical for event reduction, which
speeds up execution replay by removing events in a replay
log that are not relevant to producing a failure. In that
work, context information was retrieved through expensive
stack walks. Calling contexts have also been used to reverse
engineer the format of program input in Autoformat [11].
In aspect oriented programming, properties of calling con-
texts may be used to precisely locate aspects and have been
used to support gathering execution information for debug-
ging and unit test generation [19]. Context information has
been shown to be very useful in testing sensor network ap-
plications in [9].
Context encoding can also improve bug reporting. The
backtrace of a failure, itself a context, is a very useful com-
ponent in a bug report. With context encoding, succinct
bug reports can be generated. Moreover, it is also possible
to collect contexts of additional execution points besides the
failure point. For programs without symbolic information
(for the sake of intellectual property protection), context
encoding provides a way to anonymously represent contexts
and allows them to be decoded at the developers’ site.
Context sensitive proﬁling is very important to program
optimization [23, 3, 5]. It annotates program proﬁles, such
as execution frequencies, dependences, and object life times,
with context information. Stack walking is too expensive
when proﬁle information is generated at a high frequency.
Context sensitive optimizations [21, 7] often specify how pro-
grams should behave in various contexts to achieve eﬃciency.
For example, region-based memory management [7] tries to
cluster memory allocations into large chunks, called regions,
so that they can be explicitly managed; context sensitive
region-based memory management speciﬁes in which region
an allocation should be performed under various contexts.
525Such analyses need to disambiguate the diﬀerent contexts
reaching a program point at runtime to decide if the current
context is one of those speciﬁed. Context encoding is highly
desirable in this case.
Realizing the importance of context encoding, in recent
years, a few encoding methods have been proposed. In [5],
a technique is proposed to instrument call sites to cumu-
latively compute a hash of the function and line number
containing the call site. The same encoding is guaranteed
to be produced if the same context is encountered because
the hash function is applied over the same data in the same
order. The technique lacks a decoding component, meaning
the context cannot be directly decoded from the computed
hash. Note that such capability is essential to applications
that require inspecting and understanding contexts. More-
over, diﬀerent contexts may have the same encoding.
In [13], an approach is proposed to change stack frame
sizes by allocating extra space on stack frames such that
the stack oﬀset, which is essentially the aggregation of stack
frame sizes, disambiguates the contexts. This approach is
not safe either, especially in the presence of recursion. The
reason is that the number of stack frames at runtime could
be arbitrary such that the aggregated size cannot be stati-
cally analyzed or safely proﬁled. Hence, the extra space on
individual stack frames cannot be safely determined. The
technique relies on oﬄine training to generate a decoding
dictionary. Both the inherent imprecision and incomplete-
ness in the training set may lead to failure of decoding. The
reported failure rate could be as high as 27% [13].
In this paper, we leverage the Ball-Larus (BL) control ﬂow
encoding algorithm to solve the context encoding problem.
The scenario of encoding contexts has diﬀerent constraints
such that a more eﬃcient algorithm can be devised. The
basic idea is to instrument function calls with additions to
an integer ID such that the value of the ID uniquely iden-
tiﬁes contexts. Our algorithm is safe, uniquely identifying
diﬀerent contexts. It can precisely recover a context from its
encoding. It has low overhead and handles function pointers,
stack allocations, recursion, and so on.
Our main contributions are summarized as follows.
•We leverage the BL algorithm to encode acyclic con-
texts. The algorithm is more eﬃcient as it exploits the
unique characteristics of calling context encoding.
•We propose an algorithm to encode recursive contexts.
Recursive contexts are divided into acyclic sub-sequences
that are encoded independently. The sub-sequence en-
codings are stored to a stack. A featherweight generic
compression further reduces the stack depth.
•We propose an algorithm to safely leverage stack depths
to disambiguate contexts. Instead of allocating ex-
tra space on stack to distinguish contexts, we use our
acyclic encoding algorithm in a lazy fashion, meaning
that we apply it to contexts that cannot be safely dis-
ambiguated through stack oﬀsets.
•We have a publicly available prototype implementa-
tion [1]. We evaluate it on a set of SPEC benchmarks
and other large real world benchmarks. Our experi-
ments show that our technique has very low overhead
(1.89% on average) and it can encode all contexts of
most medium-sized programs with just one 32 bits in-
teger. For large programs, it can encode most runtime
contexts with a few numbers.2. MOTIVATION
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g76/g73/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g83/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g76/g73/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g83/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g40/g81/g87/g85/g92
/g40/g91/g76/g87/g76/g71/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g76/g73/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g83/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g72/g79/g86/g72/;#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g73/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g83/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g72/g79/g86/g72/;#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g83/g68/g87/g75/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g76/g71/;#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g86/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
Figure 1: Example for Ball-Larus path encoding. Instru-
mentation is marked on control ﬂow edges. Node annota-
tions (rounded boxes at the corners) represent the number
of paths starting from the annotated point.
Background: Ball-Larus Path Encoding. In the semi-
nal paper [4], Ball and Larus proposed an eﬃcient algorithm
(referred to as the BL algorithm) to encode intra-procedural
control ﬂow paths taken during execution. The basic BL
algorithm translates an acyclic path encoding into instru-
mentation on control ﬂow edges. At runtime, a sequence of
instrumentation is executed following a control ﬂow path,
resulting in the path identiﬁer being computed. All instru-
mentation involves only simple additions. The idea can be
illustrated by the example in Fig. 1. The code is shown on
the left and the control ﬂow graph is shown on the right.
Instrumentation is marked on control ﬂow edges. Before the
ﬁrst statement, idis initialized to 0. If the false branch is
taken at line 1, idis incremented by 2. If the false branch is
taken at line 5, idis incremented by 1. As shown on bottom
left, executions taking diﬀerent paths lead to diﬀerent values
inid.S i m p l y , idencodes the path.
The algorithm ﬁrst computes the number of paths leading
from a node to the end of the procedure. For example, node
1 has four paths reaching Exit. Such numbers are annotated
as rounded boxes in Fig. 1. Given a node with npaths, the
instrumentation from the node to Exitgenerates IDs falling
into the range of [0, n) to denote the paths. For instance,
the instrumentation in Fig. 1 generates paths with IDs in
[0,4). In particular, the instrumentation on 1 →4 separates
the range into two sub-ranges: [0,2) and [2,4), denoting the
paths following edges 1 →2a n d1 →4, respectively. The
instrumentation on 5 →8 further separates the two paths
from 5 to Exit.
More details about the BL algorithm can be found in [4].
The algorithm has become canonical in control ﬂow encoding
and been widely used in many applications [10, 6, 16].
Inadequacy of BL for Context Encoding. Although
the BL algorithm is very eﬃcient at encoding control ﬂow
paths, we observe that it is inadequate for encoding call-
ing contexts, which are essentially paths in a call graph.
Consider the example in Fig. 2. The code is shown on the
left. Figures (b) and (c) show the call graph with two en-
coding schemes. The BL encoding is presented in (b), and
(c) shows more eﬃcient encoding. Nodes in a call graph
represent functions and edges represent function calls. BL
encoding is designed to encode statement granularity paths
526/g76/g81/g87/;#23#23#23/g38/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g94
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g39/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g171/;#23#23#23
/g96
/g76/g81/g87/;#23#23#23/g39/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g94
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g40/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g41/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g96/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g76/g81/g87/;#23#23#23/g36/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g94
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g37/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g38/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g96
/g76/g81/g87/;#23#23#23/g37/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g94
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g171/;#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g39/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g96/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36
/g37 /g38
/g39
/g40 /g41/g76/g71/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g70/g82/g81/g87/g72/g91/g87/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g76/g71
/g36/g37/g39/g40 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37/g39/g41 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g38/g39/g40 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g38/g39/g41 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g171/g171/;#23#23#23/g36
/g37 /g38
/g39
/g40 /g41/g76/g71/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g70/g82/g81/g87/g72/g91/g87/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g76/g71
/g36/g37/g39/g40 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g38/g39/g40 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37/g39/g41 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g38/g39/g41 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37/g39 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g38/g39 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g38 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g68/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/g38/g82/g71/g72 /;#23#23#23#23#23#23#23#23#23#23#23/g69/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/g37/g47/;#23#23#23/g72/g81/g70/g82/g71/g76/g81/g74 /;#23#23#23#23#23#23#23#23#23#23#23/g70/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/g50/g88/g85/;#23#23#23/g72/g81/g70/g82/g71/g76/g81/g74
Figure 2: The inadequacy of the BL algorithm for encoding contexts./g81/g83/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /g83/g80 /g83/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g80/g68/g76/g81
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/g81/g88/g80/g38/g38/;#23#23#23#23#23#23#23#23#23#23#23/g83 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/g81/g88/g80/g38/g38/;#23#23#23#23#23#23#23#23#23#23#23/g81/;#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23/;#23#23#23/g520/g81/g88/g80/g38/g38/;#23#23#23#23#23#23#23#23#23#23#23/g83 /g76/;#23#23#23#23#23#23#23#23#23#23#23#23
/g76/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g171/g80/g76/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23/g80/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23/;#23#23#23/g520/g81/g88/g80/g38/g38/;#23#23#23#23#23#23#23#23#23#23#23/g83 /g76/;#23#23#23#23#23#23#23#23#23#23#23#23
Figure 3: Intuition of our algorithm.
leading from the entry of a function to the end of it. The
criterion is that each of these paths has a unique encoding.
As shown in Figure (b), all the paths leading from AtoEor
Fhave diﬀerent encodings. However, context encoding has
a diﬀerent criterion, that is, all unique paths leading from
the root to a speciﬁc node have unique encodings, because we
only need to distinguish the diﬀerent contexts with respect to
that node. In other words, there are no constraints between
the encodings of paths that end at diﬀerent nodes. It is ﬁne
if two paths that end at diﬀerent nodes have the same en-
coding. For example, paths ABDEand ABDFhave the same
encoding 0 according to the scheme in (c). As a result, al-
though the encoding in Figure (c) has less instrumentation
(on 2 edges versus 3 in (b)) and requires a smaller encoding
space (the maximum ID is 1 versus 3 in (b)), it still clearly
distinguishes the various contexts of any node.
Our technique is based on the above observation. It han-
dles recursive calls and function pointers. It also leverages
stack oﬀset, namely, the oﬀset of the stack pointer regarding
the stack base, to achieve eﬃciency. More important, our
algorithm is precise, meaning it ensures that each context
has a unique encoding, and it allows decoding.
3. DEFINITIONS
Definition 1.A call graph (CG) is a pair /angbracketleftN,E/angbracketright.Nis
a set of nodes with each node representing a function. Eis a
set of directed edges. Each edge e∈Eis a triple /angbracketleftn, m, /lscript /angbracketright,i n
which n, m ∈N, represent a caller and callee, respectively,
and/lscriptrepresents a call site where ncallsm.
In the above deﬁnition of call graph, call edges are mod-
eled as a triple instead of a caller and callee pair because
we want to model cases in which a caller may have multiple
invocations of the callee.
Definition 2.The calling context (CC) of a given func-
tion invocation m, is a path in the CG leading from the root
node to the node representing m.
The context of an execution point can be computed by
concatenating the context of its enclosing function invoca-
tion and the program counter (PC) of the point.
Definition 3.A valid calling context encoding scheme is
a function En:CC→Zsuch that
∀n∈N,∀x, y∈{the CCs of n }∧x/negationslash=y,En(x)/negationslash=En(y)Any encoding scheme that generates unique encodings,
i.e., integer sequences ( Zrepresents a sequence of integers),
for unique contexts of the same function is a valid encoding
scheme. For example, a na ¨ıve but valid encoding scheme is
to use the sequence of call site PCs to denote a context.
Our research challenge is to devise a highly eﬃcient valid
encoding scheme which also allows precise decoding. Fig. 2
(c) presents an example of such a scheme.
4. ENCODING ACYCLIC GRAPHS
In this section, we introduce an algorithm to encode call-
ing contexts that do not involve recursion. The basic idea is
illustrated in Fig. 3. Assume function numCC (n)r e p r e s e n t s
the number of contexts of a node nsuch that numCC (n)=P
i=1 ...mnumCC (pi) where for i∈[1,m],p iare the par-
ents of n. A critical invariant of our technique is that the
numCC (n)contexts of nshould be encoded by the numbers
in the range of [0, numCC (n)).To do so, the edge instru-
mentation should separate the range into mdisjoint sub-
ranges, with [0 , numCC (p1)) representing the numCC (p1)
contexts along edge p1→n,[numCC (p1), numCC (p1)+
numCC (p2)) representing the numCC (p2) contexts along
p2→n,a n d[P
j=1 ...(i−1)numCC (pj),P
j=1 ...inumCC (pj))
encoding the numCC (pi) paths along pi→n. As shown in
Fig. 3, this can be achieved by instrumenting an edge pi→n
with “ id+=P
j=1 ...(i−1)numCC (pj)”.
Algorithm 1 Encoding for Acyclic CGs.
1:Annotate (N,E){
2: forn∈Nin topological order do:
3: for each parent pofndo:
4: numCC [n]←numCC [n]+numCC [p]
5:}
6:Instrument (N,E){
7: Annotate (N,E)
8: forn∈Ndo:
9: s←0
10: for each e=/angbracketleftp, n, /lscript /angbracketrightinEdo:
11: annotate ewith “+ s”
12: insert id=id+sbefore /lscript
13: insert id=id−safter /lscript
14: s←s+numCC [p]
15:}
The algorithm is presented in Algorithm 1. It ﬁrst com-
putes the number of calling contexts for each node (stored in
numCC ). It then traverses each node nin the main loop in
lines 8-14. For each edge e=/angbracketleftp, n, /lscript /angbracketright, the following instru-
mentation is added: before the invocation at /lscript, the context
identiﬁer idis incremented by the sum sof the numCC so f
527/g70/g82/g81/g87/g72/g91/g87/;#23#23#23/;#23#23#23/g76/g71/g36
/g37 /g45
/g39
/g41/g42/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/g37 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g45 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37/g39 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g45/g39 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37/g40 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g45/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g37/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g36/g45/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g171/;#23#23#23/g44/g40
/g43/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
Figure 4: Example for acyclic en-
coding. Label“+ c”means“ id+=c”
is added before the invocation and
“id−=cis added after; superscript
onDis to disambiguate call sites./g36
/g37 /g38
/g39
/g41/g42
/g40
/g43/g85/g72/g70/g88/g85/g86/g76/g82/g81/g36
/g37 /g38
/g39
/g41/g42
/g40
/g43/g39/g56/g48/g48/g60
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g89/g82/g76/g71/;#23#23#23/g36/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g94
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g37/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g171/;#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g38/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g171
/g96/g89/g82/g76/g71/;#23#23#23/g41/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g94
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g90/g75/g76/g79/g72/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g94
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g83/g88/g86/g75/;#23#23#23#23#23#23#23#23#23#23#23/g31/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /g79/g33/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g76/g71/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g79/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g38/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g76/g71/g32/g83/g82/g83/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g73/g76/g85/g86/g87/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g171
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g96
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g43/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g171/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g171/;#23#23#23
/g96 /g71/g88/g80/g80/g92/;#23#23#23/g72/g71/g74/g72
/;#23#23#23#23#23#23#23#23#23#23#23/g68/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g50/g85/g76/g74/g76/g81/g68/g79/;#23#23#23/g38/g68/g79/g79/;#23#23#23/g42/g85/g68/g83/g75 /;#23#23#23#23#23#23#23#23#23#23#23/g69/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g55/g85/g68/g81/g86/g73/g82/g85/g80/g72/g71/;#23#23#23/g42/g85/g68/g83/g75 /;#23#23#23#23#23#23#23#23#23#23#23/g70/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g44/g81/g86/g87/g85/g88/g80/g72/g81/g87/g68/g87/g76/g82/g81
Figure 5: Example for encoding cyclic CGs.
all preceding callers; after the invocation, idis decremented
by the same amount to restore its original value.
Consider the example in Fig. 4. Node annotations (i.e.
numbers in boxes) are ﬁrst computed. In the ﬁrst three
steps of the topological traversal, nodes A,B,a n d Jare an-
notated with 1, meaning these functions have only one con-
text; node D’s annotation is the sum of those of Band J,
denoting there are two possible contexts when Dis called;
the remaining nodes are similarly annotated. The program
is instrumented based on the annotations. Consider the in-
vocations to I, which are from F,G,a n d J. The empty label
on edge FImeans that the invocation is instrumented with
“id+ = 0” and “ id−= 0” before and after the call, respec-
tively. This instrumentation is optimized away. The edge
GIhas the label “+4”, meaning the instrumentation before
and after comprises “ id+ = 4” and “ id−= 4”. Note that 4
is the annotation of F. Similarly, since the sum of the anno-
tations of Fand Gare 4+3=7, edge JIhas the label “+7”.
Other edges are similarly instrumented. At runtime, the in-
strumentation yields the encodings as shown in the table in
Fig. 4.
In applications such as context sensitive proﬁling and con-
text sensitive logging, context IDs are emitted as part of the
proﬁle. In order to facilitate human inspection, decoding is
often needed. The decoding algorithm is presented in Algo-
rithm 2. The algorithm traverses from the given function in
a bottom-up fashion and recovers the context by comparing
the encoding with edge annotations. In particular, at line 2,
the recovered context ccis initialized with the given func-
tionm, which is the leaf node of the ﬁnal context. Lines
4-10 compose the main process, which terminates when the
the root node is reached. In the inner loop from lines 5 to 9,
the algorithm traverses edges ending at the current function
n. At line 6, it tests if the encoding falls in the encoding
range of the contexts along the current edge. If so, the edge
is taken; the caller pand the call site /lscriptare attached to the
recovered context at line 7. Symbol ‘ •’ represents concate-
nation. At line 8, the encoding is updated by subtracting
the edge annotation. This essentially reverses one step of
encoding. The process continues by treating the caller as
the new current function at line 10.
Consider the example in Fig. 4. Assume the ID 6 is gen-
erated at function I. The algorithm starts from I.S i n c e
En(GI)≡4≤6<7≡En(GI)+numCC (G), the contextmust have followed the edge GI. The edge is taken and the
encoding is decremented by 4 to the value 2. At G,s i n c e
En(JG)≡2≤2<3≡En(JG)+numCC (J), edge JGis
taken. Finally, edge AJis taken, yielding the context AJGI.
Algorithm 2 Decode a context Id.
Input: the encoding id; the function mat which the encoding was
emitted; the edge set E; the edge annotations En.
Output : the explicit context cc.
1:Decode (id,m,E,En){
2: cc←“m”
3: n←m
4: while n/negationslash=root do:
5: for each e=/angbracketleftp, n, /lscript /angbracketrightinEdo:
6: ifEn(e)≤id < En (e)+numCC [p]then:
7: cc←“p/lscript”•cc
8: id←id-En(e)
9: break
10: n←p
11:}
5. ENCODING WITH RECURSION
In the presence of recursion, a context may be of un-
bounded length, making encoding using a bounded number
infeasible. We propose to use a stack to encode contexts with
recursion. The basic idea is to encode the acyclic sub-paths
of a recursive context. When a recursion occurs, the current
acyclic encoding is pushed to the stack and the following
acyclic sub-path is encoded with a new id. The numbers on
stack and the current ID together represent the context. In
order to perform correct acyclic sub-path encoding, recur-
sive CGs need to be transformed.
Our solution is presented in Algorithm 3. The ﬁrst step
deals with CG transformation (in AnnotateRecursive() ). A
dummy root node is introduced. A dummy edge is intro-
duced between the new root and the original root. Dummy
edges are further introduced between the new root and any
nodes that are the target of a back edge. Note that only one
dummy edge is introduced even if there are multiple back
edges to the same node. A dummy edge is always the ﬁrst
edge in the edge set of a node. In the transformed graph,
back edges are removed to allow acyclic encoding. Con-
sider the example in Fig. 5. The recursion FCis removed
and dummy edges are introduced between the dummy root
and the original root A, as well as between the dummy root
528and the recursive edge target C. Intuitively, after transfor-
mation, acyclic sub-sequences of a recursive context become
valid contexts in the transformed CG. Hence, they can be
taken into account in the annotation computation. In Fig. 5
(b), the dummy edge from DUMMY toCmakes the acyclic sub-
paths, such as CDFandCGF, become valid contexts and have
unique encodings in the transformed graph. Note that paths
that do not involve recursion, such as ACGFH , are not divided
into sub-paths, even if they contain a node that may be the
target of a back edge, such as Cin this case.
The instrumentation algorithm is shown in function In-
strumentRecursive() . The instrumentation is performed on
the original graph, which may have back edges. Since the
transformed graph shares the same node set as the original
graph (except the dummy root), the acyclic node annota-
tions on the transformed graph are also annotations on the
original graph and hence used in instrumentation. Similar
to the previous algorithm, smaintains the sum of contexts
of callers that precede the one being processed. At line 12,
it is initialized to 1 if the node could be a back edge target,
0 otherwise. Setting to 1 respects the numbering caused
by the dummy edge on the transformed graph. Lines 14-17
handle non-back-edges, and they are the same for acyclic
graphs. Lines 19-21 handle back edges. Speciﬁcally, before
a recursive invocation, the current idand the call site are
pushed to the stack, and idi sr e s e tt o0 . R e s e t t i n g idin-
dicates that the algorithm starts to encode the next acyclic
sub-path. After the invocation, idis restored to its previous
value. Fig. 5 (c) shows the instrumentation for functions A
and F, which are the callers of C.
Algorithm 3 Handling Recursion.
Description:
/angbracketleftN/prime,E/prime/angbracketrightrepresents the transformed CG;
stack is the encoding stack.
1:AnnotateRecursive (N,E){
2: N/prime←{DUMMY}∪N
3: E/prime←E∪{ /angbracketleft DUMMY , root, −/angbracketright}
4: for each back edge e=/angbracketleftp, n, /lscript /angbracketrightinEdo:
5: E/prime←E/prime-e
6: E/prime←E/prime∪{ /angbracketleft DUMMY ,n ,−/angbracketright}
7: Annotate( N/prime,E/prime)
8:}
9:InstrumentRecursive (N,E){
10: AnnotateRecursive (N,E)
11: forn∈Ndo:
12: s←(nhas a dummy edge in E/prime)?1:0
13: for each edge e=/angbracketleftp, n, /lscript /angbracketrightinEdo:
14: ifeis not a back edge then:
15: insert id=id+sbefore /lscript
16: insert id=id−safter /lscript
17: s←s+numCC (p)
18: else:
19: insert push( /angbracketleftid, /lscript/angbracketright)before /lscript
20: insert id=0before /lscript
21: insert id=p o p ( ) .first after /lscript
22:}
23:DecodeStack (id,stack,m,E/prime,EnE/prime){
24: /lscript←Ø
25: while true do:
26: Decode (id,m,E/prime,EnE/prime)
27: wcc←cc•wcc
28: ifstack.empty ()then:
29: break
30: /angbracketleftid, /lscript/angbracketright←stack.pop ()
31: m←the residence function of /lscript
32:}Consider the example context ACGFCDE .I ti se n c o d e da sa
sub-path with ID 3 on the stack and the current sub-path
id= 1. The encoding 3 is pushed to the stack before Fcalls
C. After the idvalue is pushed, it is reset to 0. As a result,
taking the remaining path CDEleads to id= 1. Assume the
execution returns from E,D,C, and then calls C,D,F,a n d H,
yielding the context of ACGFCDFH . The context is encoded as
3 on the stack and current id=0 .
The decoding algorithm for recursive CGs is presented in
function DecodeStack() . It takes the numbers on the stack,
the current sub-path encoding, and the current function as
part of its inputs. Intuitively, it decodes one acyclic sub-
path of the recursive context at a time, until all encodings
on the stack are decoded. Decoding an acyclic sub-path is
done by calling the acyclic decoding algorithm on the trans-
formed graph at line 26. The resulting acyclic sub-path cc
is concatenated with the whole recovered context wcc.A t
line 31, the call site label /lscriptis used to identify the method
in which the idwas pushed to the stack, which is also the
starting point of the next round of decoding.
Consider an example. Assume we want to decode a con-
text represented by the stack having an entry /angbracketleft3,FtoC/angbracketright,t h e
current id= 1, and the current function E. After the ﬁrst
iteration, i.e. Decode (1,E, ...), the sub-path CDEis decoded.
Function Fis decided as the starting point of the next round
of decoding, according to the call site on the stack. After the
round, the value 3 on the stack is decoded to the sub-path
ACGF. The two sub-paths constitute the context.
Our design can easily handle very deep contexts caused
by highly repetitive recursive calls. In such cases, contexts
are a string with repetitive substring patterns such as ACGF
CGF CGF CGF ... in Fig. 5. Such redundancy is not directly
removable without relatively expensive compression. With
encoding, the repetitive patterns are encoded into repetitive
integers and can be further encoded as a pair of ID and
frequency. The above context can be encoded to two pairs
3:1a n d2:3 ,w i t ht h ef o r m e rr e p r e s e n t i n g ACGFand the
latter representing the three repetitions of CGF.
6. SAFE HYBRID ENCODING LEVERAG-
ING STACK OFFSETS
The encoding algorithms we have discussed so far explic-
itly produce a unique id for each calling context. We call
themexplicit encoding techniques. At runtime, it is often
the case that the stack oﬀset, namely, the value of the cur-
rent stack pointer subtracted by the base of the entire stack,
can disambiguate the current context. Consider the example
in Fig. 2 (c). Previously, updates to idhad to be inserted on
edge CDto distinguish the two contexts of D. Let the stack
oﬀset at the entry of Din the context of ABDbexand the
oﬀset in the context of ACDbey.I fxdoes not equal y,
the two contexts can be disambiguated without any explicit
encoding. We call such stack oﬀset based encoding implicit
encoding as explicit instrumentation is not needed.
In reality, a few factors make applying implicit encod-
ing diﬃcult. First of all, there may be multiple contexts
that alias to the same implicit encoding, i.e., they have the
same stack oﬀset. Consider the example in Fig. 4. The
two contexts ABD1Fand ABD2Fmay have the same stack oﬀ-
set because the same sequence of functions are called. Sec-
ond, programming languages such as C/C++ allow declar-
ing variable-size local arrays. Gccallocates such arrays on
529/g59 /g60
/g61/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g179/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g180/g59 /g60
/g61/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g179/g76/g73/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g180/g59 /g60
/g61/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g179/;#23#23#23/g180/g44/g80/g38/g38 /g59/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96/g44/g80/g38/g38 /g60/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96
/;#23#23#23#23#23#23#23#23#23#23#23/g68/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g44/g80/g38/g38 /g61/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g404/g61/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96/g44/g80/g38/g38 /g59/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96/g44/g80/g38/g38 /g60/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96
/;#23#23#23#23#23#23#23#23#23#23#23/g69/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23/g32/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23/g95/g44/g80/g38/g38 /g59/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g60/g95/g32/g32/g81/g88/g80/g38/g38/;#23#23#23#23#23#23#23#23#23#23#23/g59/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g60/;#23#23#23#23#23#23#23#23#23#23#23#23/g44/g80/g38/g38 /g61/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g404/g61/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g38 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g404/g61/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96 /g44/g80/g38/g38 /g61/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g404/g61/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g38 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g404/g61/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96/g44/g80/g38/g38 /g59/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96/g44/g80/g38/g38 /g60/g32/g94/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g314/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g96
/;#23#23#23#23#23#23#23#23#23#23#23/g70/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23/g32/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23/g95/g44/g80/g38/g38 /g60/g95/;#23#23#23#23/g32/g81/g88/g80/g38/g38/;#23#23#23#23#23#23#23#23#23#23#23/g60/;#23#23#23#23#23#23#23#23#23#23#23#23
Figure 6: Intuition of Hybrid Encoding.
/g70/g82/g81/g87/g72/g91/g87/;#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23/g82/g73/g73/g86/g72/g87/;#23#23#23/g36
/g37 /g45
/g39
/g41/g42/g36/g37/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/g44
/g36/g45/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/g44
/g36/g37/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/g44
/g36/g45/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/g44
/g36/g37/g39/g42/g44
/g36/g45/g39/g42/g44
/g36/g45/g42/g44
/g36/g45/g44
/g36/g37/g39/g42
/g36/g45/g39/g42
/g36/g45/g42/g44/g40
/g43/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23 /;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g179/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g180
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/g179/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g180/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g179/g76/g73/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g76/g71/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g180/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g70/g82/g81/g87/g72/g91/g87/;#23#23#23/;#23#23#23/g82/g73/g73/g86/g72/g87/;#23#23#23
/g36/g37/g39
/g36/g45/g39
/g36/g37/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41
/g36/g45/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41
/g36/g37/g39/g42
/g36/g45/g39/g42
/g36/g37/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/g44
/g36/g45/g39/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g41/g44
/g36/g37/g39/g42/g44
/g36/g45/g39/g42/g44
/g36/g45/g44/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g81/g82/g71/g72/g44/g80/g38/g38
/g39
/g41
/g42
/g44/g76/g71
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23/g69/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g49/g72/g90/;#23#23#23/g72/g81/g70/g82/g71/g76/g81/g74/;#23#23#23/g86/g70/g75/g72/g80/g72 /;#23#23#23#23#23#23#23#23#23#23#23/g68/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g44/g80/g83/g79/g76/g70/g76/g87/;#23#23#23/g70/g82/g81/g87/g72/g91/g87/g86 /;#23#23#23#23#23#23#23#23#23#23#23/g70/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/g38/g82/g81/g87/g72/g91/g87/;#23#23#23/g72/g81/g70/g82/g71/g76/g81/g74/g86
Figure 7: Example of Hybrid Encoding. Edge instrumentations are quoted and stack frame oﬀsets are not.
stack. Stack allocations make stack oﬀsets variable, and
hence implicit encoding is infeasible. Third, in the pres-
ence of recursion, stack oﬀsets cannot be statically reasoned
about, which makes it inapplicable.
In order to address the aforementioned issues, we propose
a hybrid encoding algorithm that performs explicit encoding
when implicit encoding is not applicable. The algorithm is
safe, meaning that it uniquely encodes each possible context.
The intuition of the hybrid algorithm is presented in Fig. 6.
Besides the number of contexts, each node is also annotated
with a set of implicit contexts, denoted as ImCC , which rep-
resents a set of contexts of the node having distinct and ﬁxed
stack oﬀsets. It is a mapping from contexts to their oﬀsets.
For instance, the implicit context set of node Xin Fig. 6
contains context C1and its stack oﬀset 3 (symbol /mapsto→rep-
resents the maps-to relation). Each edge is annotated with
two pieces of information. The ﬁrst piece is the stack frame
oﬀset, which is the diﬀerence between the stack pointer and
the base of the current stack frame when the invocation de-
noted by the edge occurs. The stack oﬀset of a context can
be computed by aggregating the edge oﬀsets along the con-
text. The second annotation is the instrumentation, which
is quoted. Symbol ‘ •’ represents concatenation.
The ﬁgure presents three cases. In case (a), the two im-
plicit contexts of Zhave a conﬂicting oﬀset, namely, 3+4 ≡
2+5. We cannot implicitly encode both. In such a case, we
implicitly encode the context along edge XZand explicitly
encode that from YZ.H e n c e , ImCC Zis set to contain the
context from edge XZandidis increased by numCC (X)=1
along edge YZ. The instrumentation has the same eﬀect of
separating the encoding space as in previous algorithms. In
case (b), the two implicit contexts do not conﬂict and all
contexts of Xand Ycan be implicitly encoded, implied by
the sub-condition |ImCC X/Y|≡numCC (X/Y). In such a
case, no explicit encoding is needed and the ImCC set ofZcontains both. In case (c), the two implicit contexts of
Zdo not conﬂict but the contexts of Yare heterogeneously
encoded, denoted by |ImCC Y|/negationslash=numCC (Y). It implies
thatidmay be non-zero at Y, depending on the context at
runtime. If idis not zero, explicit encoding must have been
used, and the new context of Zshould be explicitly encoded.
Hence, idis increased by numCC (X)=1 .I f idis zero, the
context of Yis one of the contexts in ImCC Y. Because the
corresponding context of Zdoes not have conﬂicts and can
be implicitly encoded, no update to idis needed. The above
logic is realized by the guarded instrumentation on edge YZ
in Fig. 6 (c).
The algorithm is presented in Algorithm 4. Variable ImCC
represents the set of contexts that are implicitly encoded
for each node. Function extend (ImCC [p],n) extends the
implicit contexts in ImCC [p] along the invocation p→n.
This is done by concatenating nto the contexts in ImCC [p]
and increasing the corresponding stack oﬀsets by the stack
frame oﬀset of p→n. Function conﬂict (ImCC x,ImCC y)
tests if two implicit context sets conﬂict. This is done by
checking if there are two contexts in the two respective sets
alias to the same stack oﬀset.
The instrumentation algorithm is described in function In-
strument() . Here we only present the algorithm for acyclic
graphs. The extension to recursion can be achieved in a way
similar to explicit encoding and hence omitted. The algo-
rithm traverses the nodes in the topological order. It ﬁrst
resets the ImCC for the current node nat line 3. It then
traverses the set of invocations to n, denoted by edges of
the form /angbracketleftp, n, /lscript /angbracketright,w i t h pthe caller and /lscriptthe call site. It ex-
tends ImCC [p]t onat line 6, and then tests if the extended
set conﬂicts with the implicit contexts of nthat have been
computed so far. If there is no conﬂict, the extended set is
admitted and aggregated to the implicit set of nat line 8.
Line 9 checks if all contexts of pare implicit. If so, the afore-
530Algorithm 4 Hybrid Encoding.
Definitions:
ImCC [ ] an array of implicit contexts indexed by nodes;
extend (ImCC [p],n)=
{C•n/mapsto→t+oﬀset(p, n)|C/mapsto→t∈ImCC [p]}
in which oﬀset(p,n) is the stack frame oﬀset of the call to ninp.
conﬂict (ImCC x,ImCC y)=
j
1∃C1/mapsto→t∈ImCC x∧C2/mapsto→t∈ImCC y
0otherwise
1:Instrument (N,E){
2: forn∈Nin topological order do:
3: ImCC [n]←Ø
4: s←0
5: for each edge e=/angbracketleftp, n, /lscript /angbracketrightinEdo:
6: ImCC/prime←extend (ImCC [p],n)
7: ifnotconﬂict (ImCC [n],ImCC/prime)then:
8: ImCC [n]←ImCC [n]∪ImCC/prime
9: if|ImCC [p]|/negationslash=numCC [p])then:
10: /*case (c) in Fig. 6, otherwise case (b)*/
11: replace the call /lscript:n(...)inpwith
12:if(id){
id=id+s;
n(...);
id=id−s;
}elsen(...);
13: else:
14: /*case (a) */
15: insert id=id+sbefore /lscript
16: insert id=id−safter /lscript
17: s←s+numCC [p]
18:}
mentioned case (b) in Fig. 6 is encountered. There is no need
to instrument the invocation. If not, case (c) is encountered,
namely, the contexts of pmay be explicitly encoded. Hence,
the instrumentation should decide at runtime if the context
has been explicitly encoded. If so, the instrumentation will
continue to perform explicit encoding as shown by the boxes
in lines 11-12. If the extended implicit set incurs conﬂict,
case (a) is encountered. In lines 15-16, the edge is explicitly
encoded.
Encoding Example. Consider the earlier example in Fig. 4.
Fig. 7 (b) shows the graph with stack frame oﬀset annota-
tions and instrumentation (quoted). For instance, when Bis
called inside A, the stack frame oﬀset is 1; when Dis called
inside B, the frame oﬀset is 2. Hence, the stack oﬀset of the
context ABDis the sum of the two, which is 3. Similarly, the
stack oﬀset of AJDis 1+3=4. The two diﬀerent oﬀsets dis-
ambiguate the two contexts, and thus the implicit context
set of D, as shown in Fig. 7 (a), contains both contexts. No
instrumentation is needed.
Now let us consider F. When the ﬁrst edge is processed,
extend (ImCC [D1],F) is computed as {ABD1F/mapsto→4,AJD1F/mapsto→
5}at line 6, and it is assigned to ImCC [F]a tl i n e8 .W h e n
the second edge is processed, extend (ImCC [D2],F) is com-
puted as {ABD2F/mapsto→4,AJD2F/mapsto→5}. The conﬂict test at line
7 fails, so ImCC (F) only contains the set extended along the
edge D1F, as shown in Fig. 7 (a). Moreover, the algorithm
instruments the edge D2Faccording to lines 15-16.
When Iis considered, the extensions from ImCC [F],ImCC [G]
andImCC [J] do not conﬂict. However, contexts to Gmay
be explicitly encoded as |ImCC [G]|=2/negationslash=4 = numCC [G].
The instrumentation has to be guarded as shown on the edgeGI. Sample encodings can be found in Fig. 7 (c). Compared
to the instrumentation in Fig. 4, in which 5 edges need to be
instrumented with each instrumentation comprising one ad-
dition and one subtraction (2 reads and 2 writes), the hybrid
version instruments 3 edges. Furthermore, the instrumen-
tation on edge GImay need just one read (the read in the
predicate).
Decoding Example. The decoding algorithm is elided for
brevity. We will use examples to intuitively explain the idea.
The encoding of a context under the hybrid algorithm is
a triple, which comprises the stack oﬀset, the explicit ID,
and the current function. Note that only the explicit ID is
computed by instrumentation, the other two can be inferred
at any execution point. Assume we are given the encoding of
offset =5 ,id= 0 and the current function G. The explicit
encoding id= 0 means that the context is not explicitly
encoded and can be looked up from the ImCC set. From
ImCC [G], we recover the context as AJDG.
Assume we are given the encoding offset =5 ,id=6a n d
the current function I. The nonzero explicit encoding means
that explicit encoding is used. From the encoding graph in
Fig. 7 (b), we know that explicit IDs at Iin range [4, 7)
represent contexts along the edge GI. We reverse both the
stack oﬀset and the explicit encoding along this edge and
getoffset =5−1=4a n d id=6−4 = 2. The IDs at Gin
range [2,3) represent contexts along JG. Backtracking along
the edge leads to offset =4−3=1a n d id=2−2=0 .
Now with id= 0, we know that the remaining part of the
context can be looked up, yielding AJ. Here we recover the
whole context AJGI.
7. HANDLING PRACTICAL ISSUES
Handling Insuﬃcient Encoding Space. Since our tech-
nique uses a 32 bit ID, it allows a function to have a max-
imum of 232diﬀerent contexts. We observe for some large
programs a function may have more than 232contexts. For
example, in GCC, there are a few functions that are called
by a few thousand other functions, leading to an overﬂow
in the encoding space. In order to handle such cases, we
propose a selective reduction approach. We use proﬁles to
identify hot and cold call edges. Cold edges are replaced
with dummy edges such that sub-paths starting with these
cold edges can be separately encoded. As a result, the over-
all encoding pressure is reduced. At runtime, extra pushes
and pops are needed when the selected cold edges are taken.
Handling Function Pointers. If function pointers are
used, points-to analysis is needed to identify the targets of
invocations. Due to the conservative nature of points-to
analysis, the possible targets may be many. We employ a
simple and safe solution. We proﬁle the set of targets for a
function pointer invocation with a number of runs. Edges
are introduced to represent these proﬁled targets and then
instrumented normally. During real executions, if a callee is
out of the proﬁled set, push and pop are used.
Handling setjmp/longjmp. Setjmp allows a developer
to mark a position in the calling context that a successive
use of longjmp can then automatically return to, unwind-
ing the calling context to the marked point. Our approach
safely handles such unwinding by detecting when a setjmp is
encountered and storing a copy of the context stack height
and current context identiﬁer within the local variables of
531the function containing setjmp. When longjmp unwinds the
calling context, these values are then safely restored from
the local copies, unwinding the context encoding as well.
Handling Stack Allocations. Implicit encoding is not
possible when stack allocation is used, e.g., when allocating
a variable-size array on the stack. We use static analysis
to identify all functions that have stack local allocation and
prohibit implicit encoding for those functions.
8. EVALUATION
We have implemented our approach in OCaml using the
CIL source-to-source instrumentation infrastructure [14]. The
implementation has been made available on our project web-
site [1]. All experiments were performed on an Intel Core 2
2.1GHz machine with 2GB RAM and Ubuntu 9.04.
Note that because we use source level analyses for our im-
plementation, we do not have as much information as would
be available were the analysis within the actual compilation
phase. In particular, we don’t know if the compiler even-
tually inlines a function, resulting in indistinguishable stack
frame sizes. Hence, we disabled inlining during our experi-
ments. Observe that this is not a limitation of our algorithm
but rather an outcome of our infrastructure selection. An
implementation inside a compiler after functions are inlined
can easily handle the issue.
Table 1 presents the static characteristics of the programs
we use. Since CIL only supports C programs, our imple-
mentation currently supports C programs. We use SPECint
2000 benchmarks and a set of open source programs. Some
of them are large, such as 176.gcc ,alpine ,a n d vim. Three
SPECint programs, 252.eon ,254.gap and253.perlbmk are
not included because CIL failed to compile them due to their
use of C++ or unsupported types. For each program, the
table also details lines of code (LOC), the number of nodes
in the call graph (CG nodes), the number of edges in the
call graph (CG edges), the number of recursive calls or back
edges in the call graph (recursions), the number of func-
tion pointer invocations, and the maximum ID required in
the call graph under the original BL numbering scheme (BL
max ID) and our scheme (our max ID).
We can observe that most programs make use of recursion
and function pointers. In particular, 176.gcc has 1800 re-
cursive invocations and uses function pointers at 128 places.
We are able to encode the contexts of all programs smaller
than 100K LOC in a 32-bit ID. For the larger programs,
overﬂows are observed and selective reduction (Section 7) is
performed to reduce encoding pressure and ﬁt the ID into
32 bits. The numbers below the table show the number
of nodes on which selective reduction is performed for each
large programs. Observe, the maximum ID for the original
BL encoding scheme is often a few times larger than ours.
Fig. 8 illustrates the runtime overhead of our encoding al-
gorithms. We use reference inputs for SPEC programs and
random inputs for the rest. In particular, we use training
inputs to proﬁle SPEC programs. The runtime for alpine
2.0cannot be accurately measured as it is an interactive
program. The slow down is not humanly observable though.
The times for vimwere collected in batch mode. We normal-
ize the runtime of two encoding algorithms: one is the basic
algorithm that handles recursion and the other the hybrid
algorithm. From the ﬁgure, we observe that our technique
is very eﬃcient, the average overheads are 3.64% and 1.89%for the two respective algorithms. The hybrid algorithm
improves over the basic algorithm by 48.1%. 176.gcc and
255.vortex have relatively higher overhead due to the extra
pushes and pops caused by selective reduction.
programsMax Depth 90% Depth dynamic
ours plain ours plain contexts
cmp 2.8.7 0 3 0 3 9
diﬀ 2.8.7 0 7 0 5 34
sdiﬀ 2.8.7 0 5 0 4 44
ﬁnd 4.4.0 2 12 1 12 186
locate 4.4.0 0 9 0 9 65
grep 2.5.4 0 11 0 8 117
tar 1.16 3 40 2 31 1346
make-3.80 6 82 3 43 1789
alpine 2.0 11 29 6 18 7575
vim 6.0 10 31 5 10 3226
164.gzip 0 9 0 7 258
175.vpr 0 9 0 6 1553
176.gcc 19 136 2 15 169090
181.mcf 14 42 0 2 12920
186.crafty 34 41 10 2327103471
197.parser 36 73 11 28 3023011
255.vortex 7 43 2 12 205004
256.bzip2 1 8 0 8 96
300.twolf 4 11 0 5 971
Average 8.78 39.22 2.17 13.72 1795292
Table 2: Dynamic context characteristics.
Table 2 presents the dynamic properties. The second
and third columns compare our encoding stack depth (ours)
to the plain calling stack depth (plain), i.e., the call path
length. The third and fourth columns show the stack size
needed to cover 90% of contexts at runtime. The last column
presents the number of unique contexts encountered. We ob-
serve that our maximum encoding stacks are substantially
shorter than the corresponding maximum plain stacks. For
most utility programs, the encoding stack is empty, mean-
ing the contexts can be encoded into one ID without using
the stack. We also observe that some programs need maxi-
mum encoding stacks with a non-trivial depth, e.g. 176.gcc ,
181.mcf ,186.crafty and 197.parser . However, when we
look at the 90% cutoﬀs, 176.gcc and 181.mcf require en-
coding stacks of depth 2 and 0, respectively. To precisely
evaluate our technique, we also contrast the full frequency
distributions for our encoding stacks and the correspond-
ing plain stacks. Due to space limit, we only present some
of the results in Fig. 9. Each diagram corresponds to one
of the benchmarks considered. The x-axis corresponds to
stack depth and y-axis shows the cumulative percentage of
dynamic context instances during execution that can be rep-
resented in a given stack depth. Thus, if a curve ascends
to 100% very quickly, it means that most contexts for that
benchmark could be stored with a small encoding stack, pos-
sibly even size zero. The graph for 164.gzip is very typical
for medium sized programs. Our stack is always empty while
the plain stack gradually ascends. Observe the diagram of
176.gcc . Even though the maximum encoding stack has the
size of 19, our curve quickly ascends over the 90% bar with
the stack depth 2. The diagrams for other large programs
such as 255.vortex ,vimand alpine 2.0 are similar. Fi-
nally, the diagram of 197.parser shows that our technique
is relatively less eﬀective. The reason is that parser im-
plements a recursive descent parsing engine [2] that makes
intensive recursive calls based on the syntactic structure of
input. The recursion is mostly irregular, so our simple com-
pression does not help much. 186.crafty is similar.
532Table 1: Static program characteristics.
programs LOC CG nodes CG edges recursions fun pointers our max ID BL max ID
cmp 2.8.7 6681 68 162 0 5 44 156
diﬀ 2.8.7 15835 147 465 6 8 645 3140
sdiﬀ 2.8.7 7428 90 281 0 5 242 684
ﬁnd 4.4.0 39531 567 1362 28 33 1682 5020
locate 4.4.0 28393 320 688 3 19 251 1029
grep 2.5.4 26821 193 665 17 10 17437 44558
tar 1.16 58301 791 2697 19 46 1865752 4033519
make 3.80 29882 271 1294 61 7 551654 1543113
alpine 2.0 556283 2880 26315 302 1570 4294967295* 4.5e+18
vim 6.0 154450 2365 15822 1124 274291329441* 8.7e+18
164.gzip 11121 154 426 0 2 536 1283
175.vpr 29807 327 1328 0 2 1848 13047
176.gcc 340501 2255 22982 1801 128 4294938599* 9.1e+18
181.mcf 4820 93 208 2 0 6 96
186.crafty 42203 179 1533 17 0 188589 650779
197.parser 27371 381 1676 125 0 2734 14066
255.vortex 102987 980 7697 41 154294966803* 1.5e+13
256.bzip2 8014 133 396 0 0 131 609
300.twolf 49372 240 1386 9 0 1051 3766
*Selective reduction is applied to 288 nodes in alpine 2.0 , 300 in 176.gcc ,3 3i n 255.vortex , and 877 in vim.
Figure 8: Normalized runtime comparison of benchmarks with no instrumentation, basic encoding instrumentation, and the
hybrid encoding instrumentation. Times are normalized against the native runtime.
9. RELATED WORK
Explicit context encoding. The most direct approach
to identifying calling contexts is to explicitly record the en-
tire call stack. There are two main approaches for doing
so.Stack walking involves explicitly traversing the program
stack whenever a context is requested in order to construct
the full identiﬁer for the context [15]. Compared to our ap-
proach, stack walking is more expensive and hence less de-
sirable. Maintaining the calling context tree [17, 19] involves
explicitly unfolding a CG into a tree at runtime, with each
tree path representing a context. Tree nodes are allocated
and maintained on the ﬂy. The current position in the tree is
maintained by a traversal action at each call site. While call
trees are very useful in proﬁling, our technique is more gen-
eral as it provides more succinct representation of contexts
and has less overhead. Moreover, our encoding technique is
complementary to call trees because a compressed tree can
be constructed using encoding by denoting tree sub-paths
as individual nodes.
Path encoding. In [4], Ball and Larus developed an algo-
rithm to encode control ﬂow paths. Our technique is inspired
from theirs. In comparison, our algorithm is more compact
for context encoding as it encodes in a diﬀerent (backward)
direction. The BL algorithm breaks loop paths at control
ﬂow back edges and our algorithm similarly separates recur-
sive contexts into acyclic subsequences and encode indepen-
dently. However, due to the characteristics of contexts, our
recursive encoding relies on a stack. Furthermore, we safelyleverage stack oﬀset to remove unnecessary encodings. In
[12], the BL algorithm was extended to encode control ﬂow
paths across function boundaries. In [20], it was proposed
that the BL algorithm can be used to encode calling con-
texts. However, the approach was not fully developed. It
does not encode/decode recursive contexts, and it was not
implemented.
In [8], edge proﬁles are used to avoid considering cold
paths and to infer paths without numbering where possible.
If only a subset of paths are known to be of interest, [18] uses
this information to construct minimal identiﬁers for the in-
teresting paths, while allowing uninteresting paths to share
identiﬁers when advantageous. Similar to these approaches,
our technique uses proﬁling to guide instrumentation, im-
prove eﬃciency and reduce encoding space pressure. If it
were known that only a subset of calling contexts were of
interest, we could further reduce both our instrumentation
and identiﬁer size, but we leave this open as future work.
Probabilistic contexts. It may be acceptable that con-
text identiﬁers are not unique. That is, some arbitrary
contexts may be merged with low probability. In such sce-
narios, probabilistic calling contexts c a nb eu s e dt ov e r ye f -
ﬁciently identify calling contexts with high probability of
unique identiﬁers. In [5], calling contexts are hashed to nu-
meric identiﬁers via hashes computed at each function call.
Decoding is not supported in this technique. More recently,
[13] uses the height of the call stack to identify calling con-
texts and mutates the size of stack frames to diﬀerentiate
conﬂicting stack heights with empirically high probability.
533Figure 9: Context encoding stack size distributions
Our approach also uses the height of the call stack to dis-
ambiguate calling contexts, but in contrast, we only use it to
eliminate instrumentation and path numbering where it can
be shown that it is safe to do so. Their decoding is achieved
by oﬄine dictionary lookup. The dictionary is generated
through training, and hence the actual calling contexts can-
not always be decoded. In contrast, our approach guaran-
tees safety and easy decoding. Furthermore, their approach
is unsafe with stack allocation.
Sampling based proﬁling. In [23], adaptive sampling
is used to guide context sensitive proﬁling, thus reducing
the number of times contexts are even needed. While this
is useful when performing hot-context proﬁling, it does not
generalize to other uses of contexts where coverage guaran-
tees are important.
10. CONCLUSIONS
We propose a technique that encodes the current calling
context at any point during execution. It encodes an acyclic
call path into a number and divides a recursive path into
sub-sequences to encode them independently. It leverages
stack depth to remove unnecessary encoding. The technique
guarantees diﬀerent contexts have diﬀerent IDs and a con-
text can be decoded from its ID. Our results show that the
technique is highly eﬃcient, with 1.89% overhead on aver-
age. It is also highly eﬀective, encoding contexts of most
medium-sized programs into just one number and those of
large programs in a few numbers in most cases.
11. ACKNOWLEDGEMENT
We thank the anonymous reviewers for their insightful
comments. We are grateful to Ben Wiedermann for his feed-
back on early drafts. This research is supported, in part,
by the National Science Foundation (NSF) under grants
0917007, 0847900, and 0845870. Any opinions, ﬁndings, con-
clusions, or recommendations in this paper are those of the
authors and do not necessarily reﬂect the views of NSF.
12. REFERENCES
[1]http://www.cs.purdue.edu/~wsumner/research/cc .
[2] A. Aho, R. Sethi, and J. Ullman. Compilers: Princiles,
Techniques, and Tools . Addison-Wesley, 1986.[3] G. Ammons, T. Ball, and J. Larus. Exploiting hardware
performance counters with ﬂow and context sensitive proﬁling.
InPLDI’97 .
[4] T. Ball and J. Larus. Eﬃcient path proﬁling. In MICRO-29 ,
December 1996.
[5] M. D. Bond and K. S. McKinley. Probabilistic calling context.
InOOPSLA’07 .
[6] T. M. Chilimbi, B. Liblit, K. Mehra, A. V. Nori, and
K. Vaswani. Holmes: Eﬀective statistical debugging via eﬃcient
path proﬁling. In ICSE’09 .
[7] R. Jones and C. Ryder. A study of java object demographics.
InISMM’08 .
[8] R. Joshi, M. D. Bond, and C. Zilles. Targeted path proﬁling:
Lower overhead path proﬁling for staged dynamic optimization
systems. In CGO’04 .
[9] Z. Lai, S. C. Cheung, and W. K. Chan. Inter-context
control-ﬂow and data-ﬂow test adequacy criteria for nesc
applications. In FSE’08 .
[10] James R. Larus. Whole program paths. In PLDI’99 .
[11] Z. Lin, X. Jiang, D. Xu, and X. Zhang. Automatic protocol
format reverse engineering through context-aware monitored
execution. In NDSS’08 .
[12] D. Melski and T. Reps. Interprocedural path proﬁling. In
CC’99 .
[13] T. Mytkowicz, D. Coughlin, and A. Diwan. Inferred call path
proﬁling. In OOPSLA’09 .
[14] G.C. Necula, S. McPeak, S.P. Rahul, and W. Weimer. Cil:
Intermediate language and tools for analysis and
transformation of c programs. In CC’02 .
[15] N. Nethercote and J. Seward. Valgrind: A framework for
heavyweight dynamic binary instrumentation. In PLDI’07 .
[16] T. Reps, T. Ball, M. Das, and J. Larus. The use of program
proﬁling for software maintenance with applications to the year
2000 problem. In FSE’97 .
[17] J. M. Spivey. Fast, accurate call graph proﬁling. Softw. Pract.
Exper. , 34(3):249–264, 2004.
[18] K. Vaswani, A.V. Nori, and T.M. Chilimbi. Preferential path
proﬁling: compactly numbering interesting paths. In POPL’07 .
[19] A. Villazon, W. Binder, and P. Moret. Flexible calling context
reiﬁcation for aspect-oriented programming. In AOSD’09 .
[20] B. Wiedermann. Know your place: Selectively executing
statements based on context. Technical Report TR-07-38,
University of Texas at Austin, 2007.
[21] X. Zhang, A. Navabi, and S. Jagannathan. Alchemist: A
transparent dependence distance proﬁling infrastructure. In
CGO’09 .
[22] X. Zhang, S. Tallam, and R. Gupta. Dynamic slicing long
running programs through execution fast forwarding. In
FSE’06 .
[23] X. Zhuang, M. Serrano, H. Cain, and J. Choi. Accurate,
eﬃcient, and adaptive calling context proﬁling. In PLDI’06 .
534
View publication stats