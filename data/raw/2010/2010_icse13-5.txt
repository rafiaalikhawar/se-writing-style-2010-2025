Departures from Optimality: Understanding Human
Analyst’s Information Foraging in Assisted
Requirements Tracing
Nan Niu∗, Anas Mahmoud∗, Zhangji Chen∗, and Gary Bradshaw†
∗Department of Computer Science and Engineering, Mississippi State University, USA
†Department of Psychology, Mississippi State University, USA
niu@cse.msstate.edu, {amm560, zc140 }@msstate.edu, glb2@psychology.msstate.edu
Abstract —Studying human analyst’s behavior in automated
tracing is a new research thrust. Building on a growing body of
work in this area, we offer a novel approach to understandingrequirements analyst’s information seeking and gathering. We
model analysts as predators in pursuit of prey — the relevant
traceability information, and leverage the optimality models to
characterize a rational decision process. The behavior of real
analysts with that of the optimal information forager is thencompared and contrasted. The results show that the analysts’
information diets are much wider than the theory’s predictions,
and their residing in low-proﬁtability information patches ismuch longer than the optimal residence time. These uncovered
discrepancies not only offer concrete insights into the obstacles
faced by analysts, but also lead to principled ways to increasepractical tool support for overcoming the obstacles.
Index T erms —Traceability, requirements engineering, study of
human analysts, information foraging.
I. I NTRODUCTION
Following the life of a requirement and tracking the in-
formation in the requirements traceability matrix (RTM) arecrucial to many software engineering activities, such as ver-iﬁcation and validation, risk assessment, and regression testselection [1]. Research has shown that information retrievaltechniques can be effectively applied to help recover thetraceability information in an automated fashion [1, 2, 3, 4, 5].In this way, plausible links can be generated between softwareartifacts, e.g., between requirements and test cases.
One area that traceability is indispensable is the engineering
of mission- or safety-critical software systems. For example,
the U.S. Federal Aviation Administration’s software certifyingstandard [6] speciﬁes that at each development stage “develop-ers must be able to demonstrate traceability of designs againstrequirements”. Under these circumstances, a human analystmust vet (e.g., browse and validate) the candidate RTM offeredby the tool [7]. V etting is thus a central activity in assisted
requirements tracing , in which a human analyst engages with
an automated tracing tool to perform the assigned tracingtask [8].
Studies of human behavior [7, 8, 9, 10] showed that,
in interacting with the tracing tool to prepare their ﬁnalRTM, the analysts made both errors of omission (threw outcorrect links) and errors of commission (added incorrect links).A thoroughly conducted experiment by Dekhtyar et al. [8]tested 11 vetting variables. The results revealed that only the
accuracy of the initial RTM and the analyst effort expendedin validating offered links had statistically signiﬁcant effectson the ﬁnal RTM, while the other 9 factors (e.g., tool used,tracing experience, effort on searching for omitted links, etc.)did not make a difference [8]. A qualitative study by Kong et
al.[10] provided additional insights into analysts’ behavior.
For example, all the analysts were observed to make multiplecorrect decisions in a row, and such correct-decision boutswere interleaved with streaks of incorrect decisions [10].
Currently, empirically observing analysts’ behavior is
adopted as the main methodology for researching the humanfactors in assisted requirements tracing. Observational studiesare particularly valuable in answering “ what ” questions by
uncovering behavioral patterns. However, little is known about“why ” analysts behave in a certain way and “ how ” to improve
the analysts’ tracing performance in a principled manner. Ad-dressing these knowledge gaps is of vital importance because,
with a deeper theoretical understanding about the fundamentalmechanisms underlying the analysts’ behavior, the empiricalobservations can be related more coherently and the keyfactors can be tested more completely.
In this work, we explore the theoretical underpinning of an-
alyst’s requirements tracing behavior based on Pirolli’s infor-
mation foraging theory [11]. The theory uses our animal ances-
tors’ “built-in” food-foraging mechanisms [12] to understandhuman information seeking and gathering in the vastness of the
Web. Lawrance and colleagues [13, 14, 15, 16] have recentlypioneered the application of information foraging theory tothe debugging domain, and presented encouraging results that
matched the theory’s predictions with the developers’ actualcode navigations. Building on their inﬂuential work, we aimto investigate human analysts’ requirements tracing strategies
in light of foraging theory’s constructs and principles.
This paper reports an exploratory study that examines two
of foraging theory’s foundational models [11] in the contextof tracing:
1)the diet model optimizes the decision related to
what kinds of information to consume and what to ignore;and
2)the patch model determines the optimal time to spend
in an information patch. These optimality models allow us
to deﬁne the behavioral problems that are posed by therequirements tracing environments, and therefore allow us to978-1-4673-3076-3/13 c2013 IEEE ICSE 2013, San Francisco, CA, USA
Accepted for publication by IEEE. c2013 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/
republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.572Time Gain 
tB tW t* 
g(tW) R* Forager’s search Gain 
/g652n 
R(n)  /g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3
/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3/g3
       1  2  …  k  (k+1)   …    n 
 
Patches ranked by profitability Patch 1 
Between-patch 
search time ( tB)Patch 2 
Within-patch
search time ( tW)
(a) (b) (c)
Fig. 1. (a)Illustration of patchy environment where a hypothetical bird forages in patches containing berry clusters. (b)The optimal diet shall include the
khighest proﬁtability prey-patches as the rate of gain, R(k), is greater than the proﬁtability of the next prey-patch, πk+1.(c)Charnov’s Marginal V alue
Theorem [12] states that the rate-maximizing time to spend in patch, t∗, occurs when the slope of the within-patch gain function g(tW)is equal to the
average rate of gain, which is the slope of the tangent line R∗.
determine how well an optimal forager (analyst) performs
on those problems. We then compare the behavior of real
analysts with that of the optimal forager. In particular, the
theory’s predictions are confronted with the tracing behaviorof 6 analysts who validated the links between requirementsand code of a software system in the healthcare domain. Thedepartures from optimality revealed by the comparison notonly offer concrete insights into the obstacles faced by thehuman analysts, but also lead to principled ways to overcomethe obstacles.
The contributions of our work lie in the analysis of op-
timality within the shaping limits placed by the task andthe information environments. Our work advances the funda-mental understanding about analysts’ information seeking inlight of the adaptiveness of human behavior. This improvedunderstanding, in turn, enables principled ways to increasepractical support for software traceability. In what follows,we present background information on foraging theory andassisted requirements tracing in Section II. We then detailour research methodology in Section III. Sections IV and Vdescribe the empirical study’s design and results respectively.The implications of our work are discussed in Section VI, andﬁnally, Section VII concludes the paper.
II. B
ACKGROUND AND RELA TED WORK
A. Optimal F oraging Theory
Animals adapt, among other reasons, to increase their rate of
energy intake. To do this they evolve different methods: a wolfhunts for prey, but a spider builds a web and allows the prey tocome to it. Optimal foraging theory is developed in biology for
analyzing the adaptive value of food-foraging strategies [12].Optimality here refers to the strategy that maximizes the gainper unit cost. Central to optimal food foraging are the diet
model and the patch model .
The diet model deals with the tradeoffs when a predator
forages in an environment in which food is distributed ina patchy manner. Fig. 1a illustrates the patchy environmentby presenting a hypothetical bird foraging in berry clusters.The forager must expend some amount of between-patch time(t
B) arriving at a prey-patch, and tWdenotes the within-patch
foraging time. In Fig. 1c, g(tW)represents a deceleratingexpected net gain function. The amount of energy gained per
unit time of foraging is therefore R=g(tW)/(tB+tW).
Following Stephens and Krebs [12], we use π=g/tWto
denote the patch’s proﬁtability and use λ=1/tBto denote
the patch’s encounter rate.
The optimal diet selection follows the principle of lost
opportunity [12]. Intuitively, the principle states that the prey-patch is predicted to be ignored if its proﬁtability is less thanthe expected rate of gain of continuing search for other prey-patches. Formally, as shown in Fig. 1b, let the patches beranked by proﬁtability, π
i=gi/tWi, such that π1>π 2>...>
πn. The optimal diet can be expanded by adding prey-patches
in order of decreasing proﬁtability (i.e., from 1 to n) until the
rate of gain for a diet of the top kprey-patches is greater than
thek+1st prey-patch’s proﬁtability,
/parenleftbigg
R(k)=/summationtextk
i=1λi·gi
1+/summationtextk
i=1λi·tWi/parenrightbigg
>/parenleftbigggk+1
tWk+1=πk+1/parenrightbigg
. (1)
The left side of the inequality concerns the rate of gain
obtained by the diet of the khighest proﬁtability prey-patches,
whereas the right side concerns the proﬁtability of the k+1st
prey-patch. In Fig. 1b, the optimal diet contains {prey-patch 1,
prey-patch 2, ..., p r e y-patch k}, and therefore {prey-patch k+1,
..., p r e y-patch n}are predicted to be ignored by the forager.
Once a prey-patch is selected to be part of the forager’s
diet, the patch model deals with predictions of the amount of
time to spend within the patch. The basic idea is illustratedin Fig. 1c. As the forager gains energy, the amount of fooddiminishes or depletes. Consequently, there will be a pointat which the expected gains from foraging within the currentprey-patch become less than the expected gains that could bemade by leaving for a new one. Fig. 1c shows that the rate-maximizing time, t
∗, occurs when the derivative of g(tW)is
equal to the slope of the tangent line R∗.
In a nutshell, the simple rule in optimal foraging theory is:
“do not expend more energy ﬁnding the food than the foodprovides.” Animals (including humans) have evolved somevery sophisticated and fascinating food-seeking mechanisms.
Optimal foraging theory has been proven to be productive and573resilient in addressing food-searching behavior in the ﬁeld and
the lab, whereby the adequacy of the tenets (e.g., the patchmodel and the diet model) is tested to account for the evolutionof given structures or behavioral traits [12].
B. F oraging Theory Applied to Web and Code Navigation
Humans seeking information adopt various strategies, some-
times with striking parallels to those of animal foragers.The wolf-prey strategy bears some resemblance to classicinformation retrieval [17], and the spider-web strategy is likeinformation ﬁltering [18]. Pirolli [11] developed information
foraging theory by laying out the basic analogies between food
foraging and information seeking: predator (human in need ofinformation) forages for prey (the useful information) alongpatches of resources and decides rationally on a diet (whatinformation to consume and what to ignore). By adopting theoptimality models and adding details where necessary, Pirolliraised foraging theory from the physical and biological levelsto the knowledge and rational levels.
The main application area of information foraging theory is
the study of users’ information seeking on the Web. DuringWeb navigation, users operate in two environments [11]. Thetask environment embodies a goal, problem, or task that
drives human behavior, whereas the information environment
structures users’ interactions with the content. An optimal Webuser’s navigation is then calculated according to the notion ofinformation scent [19], a subjective sense of value and cost of
accessing an information source based on perceptual cues. The
WUFIS (Web User Flow by Information Scent) algorithm [20]represents one of the most rational and effective computational
models of information scent by considering both environmentsin its computation:
1)a spreading activation network [21] that
represents user’s goal memory in the task environment; and 2)
an inter-word correlation representation used to approximate
user’s conception of word synonymy [22] in the information
environment. Computing the Web user’s “information diet”provides remarkable insights into issues like link selection anddecision to leave a webpage. As a result, information foragingtheory has become extremely useful as a practical tool forwebsite design and evaluation [23].
Inspired by human’s adaptive interaction with information
on the Web, researchers began to apply foraging theory insoftware engineering. Ko et al. [24] were among the ﬁrst
to relate information foraging to developers’ seeking relevant
code in software maintenance. In recent years, Lawranceet al. [13, 14, 15, 16] have made tremendous strides in
understanding programmer navigation during debugging byviewing programmer as predator and bug-ﬁx as prey. Build-ing on Pirolli’s work, Lawrance et al. [14] developed the
PFIS (Programmer Flow by Information Scent) model bycombining:
1)a spreading activation over the source code’s
topology (analogous to links on webpages); and 2)a word
similarity measure between the bug report and the sourcecode (computed as vector space model’s cosine similarityusing the TF-IDF weighting schema [17]). Extending beyondPirolli’s work, Lawrance et al. [15] presented the PFIS2 modelwhich incorporated the incremental changes in programmers’
conception of the navigation goals during debugging. More
recent work [25] focused on empirically assessing programmernavigation models’ predictive accuracy and optimally compos-ing single factors (e.g., recency, spatial proximity, etc.) into afamily of PFIS3 models.
In summary, information foraging theory [11] provides
an evolutionary-ecological approach to understanding human
information-seeking on the Web. Applying the theory insoftware engineering has also been fruitful as the foraging-theoretic approach provides a foundation for studying devel-opers’ navigation around the code base [26]. Building andexpanding upon Lawrance and colleagues’ seminal work ondebugging [13, 14, 15, 16], we investigate an important butdifferent information-intensive software engineering task —assisted requirements tracing.
C. Assisted Requirements Tracing
When dealing with a software system’s traceability informa-
tion, a requirements traceability matrix (RTM) establishes themapping between elements of one artifact (e.g., requirements-level use cases) and elements of the other artifact (e.g.,implementation-level classes). Any RTM that exists before thetracing process is complete is called a candidate RTM [7]. The
ﬁnal RTM is the one approved (or “certiﬁed”) by a human
analyst [7, 10].
Because manually building the RTM can be tedious and
error-prone, modern tools employ information retrieval (IR)methods for automated support [1, 2, 3, 4, 5]. These methodssearch for documents (i.e., candidate traceability links) andretrieve those that are relevant to the query (i.e., element tobe traced). Extensive empirical studies have been conductedto evaluate the effectiveness of different IR-based traceabilitylink recovery methods. Converging evidence indicates that all
the exploited methods so far are equivalent in that they are
able to capture almost the same traceability information [27].In most cases, a recall of 90% is achievable at precision
levels of 5-30% [1, 2, 3, 4, 5, 27, 28], where recall is
deﬁned as the percentage of correct links that are retrievedand precision is deﬁned as the percentage of retrieved links
that are correct [17].
Although IR-based tools automate the RTM generation to a
large extent, in coping with mission- or safety-critical softwaresystems, the human analyst must vet the candidate RTMproduced by the tool and add and remove links as necessaryto arrive at the ﬁnal RTM [7]. It is important to emphasize
that traceability is not an end in itself but a means towards
some other end. The analyst who vets the candidate RTM maybe involved in risk assessment, criticality analysis, regulatorycompliance, or some other software engineering activities. Asa result, the analyst can always override any tool’s output
and has the ﬁnal say on whether or not the traceability is
correct [9].
Assisted requirements tracing, thus, refers to the process in
which the human analyst becomes actively involved and makes574decisions concerning the automated tool’s output. The founda-
tional work in this area was laid by Hayes and Dekhtyar [9]where they elucidated the need to study human interaction(reaction) with the tracing tool’s results. Since then, a seriesof studies [7, 8, 10] investigated analyst behavior and revealedthat human tended to degrade the accuracy of the RTMprovided by the tool. Among the important ﬁndings, a rathersurprising one was that incorrect decisions were often madeif the analyst spent much time on the links [10]. In orderto understand the ﬁndings like this, it was suggested that wemight need to experimentally study one variable at a time [29].Eleven variables were then examined by Dekhtyar et al. [8].
The work represents one of the most signiﬁcant empiricaldiscoveries to date.
In essence, assisted requirements tracing is aimed at provid-
ing the best of both worlds, allowing human and automatedtool to do what they do best [8]. While recent empiricalcontributions have enlightened the vital role of human factors,we believe gaining a theoretical understanding can furtheradvance the ﬁeld. A foraging-theoretic exploration can shedlight on the mechanisms underlying the human’s adaptiveinteraction with the information presented in the tracing tool.
This is precisely the focus of our research.
III. R
ESEARCH METHODOLOGY
Assisted requirements tracing shares many characteristics
with1)IR-based Web search and 2)navigation along the
software entities. As both are domains to which informationforaging theory applies (cf. Section II-B), we contend that theanalyst’s seeking and gathering traceability information canbe mathematically modeled in light of the “built-in” foragingmechanisms. In this way, the human analyst can be viewedas a predator in pursuit of prey — the relevant traceabilityinformation.
The overall goal of our research is to explore the differences
between the analyst’s actual information foraging behavior
and that deﬁned by the optimality models. Our comparisonconcentrates on the information diet selection (the diet model)and the residence time within a selected information patch (thepatch model). Before formulating speciﬁc research questionsin Section III-B, we detail how an optimal analyst’s decisions
are made based on the rational analysis of information forag-
ing.
A. Rational Analysis
Anderson’s rational analysis [30] is built upon the principle
ofoptimization under constraints . The basic idea is that the
constraints of the environment place important shaping limits
on the optimization that is possible [11]. Applied to debugging,
the principle implies that optimal programmers will make thebest possible navigational choices, given the information theintegrated development environment (IDE) like Eclipse makesavailable to them at each moment [16]. Similarly, the humananalyst’s optimal behavior in tracing must be rationalized by
scrutinizing the information that the automated tool makesavailable at each moment.Fig. 2a shows a screenshot of the automated requirements
tracing tool used in our study. We call the tool “ART-Assist” to
emphasize the integral yet supportive role it plays in assistedrequirements tracing, in which the human analyst must beactively involved [9]. The foremost aim in developing ART-Assist was to obtain functional adequacy of state-of-the-art
tracing tools. To that end, we surveyed the basic features ofRETRO [1], ADAMS [3], and Poirot [31], and also reviewed
our own experience from building the TraCter tool [32]. Asdifferent IR-based traceability recovery methods show compa-rable performance [27], the back-end of ART-Assist adopts thevector space model with TF-IDF weighting [1, 2]. The front-end uses the ordered list to display the retrieved traceabilitylinks according to the similarity score computed by the IR al-gorithm. ART-Assist ranks traceability links much like searchengines like Google rank search results in response to a user’squery. To support the best practice of in-place traceability [33]
which advocates tracing-related artifacts being managed withintheir native environments, each page of ART-Assist presents10 retrieved links (or more accurately, the links’ snippets) asif they reside in Google’s search result page (SRP).
Several design decisions about ART-Assist’s information
handling are worth discussing. We restrict the discussionto the RTM between requirements-level use cases andimplementation-level classes, as this is the granularity levelat which our empirical study is conducted.
•What information is used for retrieval? ART-Assist ex-
tends our indexer [34] to process both source code
and use case descriptions. Three steps are carried out:tokenizing, ﬁltering (i.e., removing stop words like the
andint ), and stemming (i.e., reducing a word to its
inﬂectional root: “patients” →“patient”). The resulting
indices, which contain the artifacts’ partial and important
information, are then used for retrieval.
•How much retrieved traceability information to keep? A
basic tenet of IR-based methods is that the list of retrievedlinks contains a higher density of correct traceability linksin the upper part of the list and a much lower density ofsuch links in the bottom part of the list [35]. ART-Assisttherefore presents the human analyst with 70% of themost similar links, a threshold used in prior work [34].
•What information is included in the snippet? The snippet
design is informed by our recent study on topical local-
ity[36] where we found that class name along with header
comments conveyed class body’s topic. In addition, theclass path offers the ﬁle hierarchy information and canact as the URL for the retrieved link. Thus, ART-Assistdisplays a 3-line snippet in the SRP: the class name,the class header trimmed in 1 line, and the class path.An innovative design in ART-Assist is that a mouse-hover over a link’s snippet pops up the full class headercomments, as shown in Fig. 2a.
•How to interact with the traceability information? ART-
Assist’s interaction design philosophy is to fulﬁll ana-575/g3
F2F1 S0 SRP 1 F1
SRP 1 F2
SRP 1 F3
F4 SRP 1 F4
SRP 1 F5
F6 S0 SRP 2 F6
SRP 2 F7
SRP 2 F8
S0 SRP 3 F9
SRP 3 F10
F7 S0 SRP 2 F7
S0 SRP 4Patch 1
Patch 3Patch 2
Patch 2
Patch 4
Approve & Submit
(a) (b)
Fig. 2. (a)Screenshot of ART-Assist, the automated requirements tracing tool used in our study. To protect anonymity, the analyst’s name and the actual tracing
time are not released. (b)Problem behavior graph that demonstrates the proper mapping of each ART-Assist’s page to an information patch. Time in the graph
proceeds left to right and top to bottom. Boxes are states. Arrows are moves (transitions). Double vertical lines are returns to a previous state. Dott ed enclosing
box shows the patch’s boundary. The states S 0, SRP i, and F jrepresent the initial state, the ithsearch result page (SRP), and the information item (traceability
link) respectively. Every F jstate is annotated with an ART-Assist icon that indicates the speciﬁc operation performed by the human analyst: “magnifying
glass” means “view”, “ +” means “select”, and “ ×” means “deselect”. F j: link (source code ﬁle) correspondences are as follows: F 1: SurveyBean.java, F 2:
SurveyResultBean.java, F 3: SurveyResultDAO.java, F 4: HCPDiagnosisBean.java, F 5: GetUserNameAction.java, F 6: PersonnelBean.java, F 7: Role.java, F 8:
ViewVisitedHCPsAction.java, F 9: PrescriptionReportBean.java, and F 10: ViewOfﬁceVisitAction.java.
lyst’s tracing goal while keeping the operations straight-
forward, accessible, and responsive. Direct navigation toa certain SRP is enabled by clicking the correspondingpage number. The highlighted page number shows whichSRP is currently displayed. Clicking the class name in thesnippet or the “magnifying glass” icon allows the entire
class ﬁle to be viewed in a new window. A link can be
selected or deselected via “ +” (add) or “ ×” (remove).
A shopping-cart-like area in ART-Assist’s upper-rightcorner enables the explicit management of selected links.Once a link is selected, its snippet is yellow highlighted.
Once the ﬁnal RTM is approved, the “submit” button shall
be pressed.
Understanding how ART-Assist works is necessary for
modeling the way the information environment structures anoptimal analyst’s foraging. Due to the information needs of the
human analyst, navigation in ART-Assist has two fundamentaldifferences from both navigation on the Web and navigationin an IDE such as Eclipse. First, what counts as a hyperlink is
well-deﬁned in a website [11] and can be readily modeled bythe one-click link built in Eclipse [14, 15]. In contrast, onlya single hyperlink type is deﬁned in ART-Assist, namely, theclick that enables the viewing of the complete source code ﬁle.
Second, Web and program navigations can be of great depthbecause many information items can be reached via clickablehyperlinks. In contrast, the depth of ART-Assist navigationsis rather limited because the analyst is primarily interested in
viewing and (de-)selecting a traceability link. Such differences
suggest that the hyperlink topology in a website or a modernIDE is much richer and denser than the one deﬁned in ART-Assist. For this reason, we apply foraging theory’s optimalitymodels directly instead of adopting the spreading activationtechnique used in WUFIS [20] and PFIS [14].
We model each page retrieved by ART-Assist as an infor-
mation patch in which the prey might hide [15]. A patch then
contains the SRP and the enclosed information items (trace-
ability links) that can be viewed and collected. The key forinstantiating “patch”, one of foraging theory’s core constructs,
is to preserve the locality such that there are more transitions
within a patch than between patches. In Web navigation [11],for instance, a website is treated as an information patchsince it is easier to navigate information within the samepatch (website) than to navigate information across patches(websites). To assess our patch selection, Fig. 2b uses a576problem behavior graph to visualize an analyst’s interaction
with ART-Assist when tracing the use case shown in Fig. 2a(‘View Physician Satisfaction Survey Results’). A problembehavior graph, which is the foundation for Web behaviorgraph [11] and code navigation graph [26], is particularly goodat showing the structure of human’s problem solving. Fig. 2b
not only illustrates ART-Assist navigation’s limited depth,but also supports patch selection’s locality property. Amongthe total of 36 sessions in our empirical study presentedlater, the average ratio of within- to between-patch operations(transitions) is 4.2. This ratio is comparable to the values foundin Web navigation (ratio=3.7 [11]) and in code navigation(ratio=4.4 [26]).
Fig. 3 illustrates how to apply the principle of lost oppor-
tunity [11] to determine an optimal forager’s information diet.For each of the 5 patches given in Fig. 3a, the informationgain (g) is deﬁned by precision. To characterize the within-
patch foraging time ( t
W), we leverage MAP (mean average
precision), a metric widely accepted in the IR community.
MAP measures “the quality across the recall levels” [17].The formal deﬁnition of MAP can be found in the standardIR reference [17] and the traceability-speciﬁc literature [37].Intuitively, the higher the MAP , the closer the correct linksare to the top of the information patch and therefore the less
within-patch foraging time ( t
W) an optimal analyst would
need. Thus, we deﬁne an information patch’s proﬁtability as:π=g/t
W= precision ·MAP . The optimal diet can then
be selected according to the relationship speciﬁed in equation(1); here, the encounter rate of all patches is assumed to be a
single unit (i.e., λ=1) as ART-Assist allows each patch to be
accessed by a single click on the page number. Fig. 3b showshow the theoretical diet (D
Th) is iteratively expanded and
optimized in order to counteract the lost opportunity [11].
To analyze the optimal residence time within a patch, we
apply Charnov’s Theorem [11, 12] to examine how muchinformation value the forager acquires over time t:
g(t)=N
R·t
NT·ts+NR·th. (2)
In this equation, NRis the number of relevant information
items the forager handles, NTis the total number of informa-
tion items encountered, tsis the scanning time, and this the
handling time. We instantiate the value of these parametersbased on analysts’ actual tracing sessions. This allows fortheoretically determining the optimal within-patch residencetime (cf. Fig. 1c) which we denote by t
∗Th.
B. Research Questions
The research questions addressed in our work are the
differences and discrepancies between D Th (optimal diet
in theory) and D Ac (analyst’s actual information diet), and
those between t∗Th (optimal within-patch residence time in
theory) and t∗Ac (analysts’ actual within-patch residence
time). Speciﬁcally, we are interested in understanding realPatch Precision ( g) MAP ( 1/tW) Proﬁtability ( π)
Patch 1 0.40 0.67 0.27
Patch 2 0.30 0.81 0.24
Patch 3 0.20 1.00 0.20
Patch 4 0.20 0.83 0.17
Patch 5 0.10 1.00 0.10
(a)
kR(k)πk+1 DTh (optimal diet in theory)
0– – {Patch 1}
1 0.16 0.24 {Patch 1, Patch 2}
2 0.19 0.20 {Patch 1, Patch 2, Patch 3}
3 0.19 0.17 {Patch 1, Patch 2, Patch 3}
// Following equation (1), the optimal diet selection
// terminates because R(3)>π 4.
(b)
Fig. 3. (a)Optimal diet selection considers information patches in order of
decreasing proﬁtability. (b)The optimal diet (D Th) is obtained by iteratively
adding Patch kas long as the gain of the diet is not greater than the proﬁtability
of the next patch, R(k)≤πk+1.
analysts’ deviations and departures from optimality from two
complementary perspectives.
•Structural . To what extent is an information patch’s
selection affected by its proﬁtability and quality? While
proﬁtability ( π=precision ·MAP ) is computed only if
the answer set of true links is known, quality of a patchcan be measured by its internal cohesion [38].
•Behavioral . To what degree is an information patch’s se-
lection affected by the residence time and the navigationbehavior of the human analysts?
The answers to the research questions will enable not
only a systematic assessment of the factors suggested byinformation foraging theory, but also a coherent account for
unifying the observations that would otherwise not be linkedin a meaningful way. For example, with the foraging-theoreticfoundation we speculate that
(i)the interleave of analyst’s
correct- and incorrect-decision streaks [10] might be due tothe inclusion of both optimal and non-optimal informationpatches in the actual diet, and
(ii)the incorrect decisions after
a long foraging period [10] might be attributed to the excessiveresidence time within a patch.
IV . E
MPIRICAL STUDY SETUP
To answer the research questions, we conducted an assisted
requirements tracing experiment by using the iTrust dataset
(http://agile.csc.ncsu.edu/iTrust). iTrust is a Java applicationaimed at providing patients with a means to keep up withtheir medical records, as well as to communicate with theirdoctors. Although originated as a course project, iTrust hasexhibited real-world relevance and served as a traceability
testbed for understanding the importance of security andprivacy requirements in the healthcare domain [39].
The iTrust dataset has 46 use cases (UCs) and 226 Java
classes. The requirements-to-source-code traceability matrixis of size 10,396. The answer set, prepared by iTrust’s de-
velopers, contains 314 true links. Since we wanted to observe577TABLE I
REQUIREMENTS TRACES USED IN THE EXPERIMENT
ID (our Title |true|true links
study) (iTrust ID) links | retrieved|
UC1 Document Ofﬁce Visit (UC-11) 26 25
UC2 Maintain a Hospital Listing (UC-18) 4 4
UC3 Maintain Standards Lists (UC-15) 13 12
UC4 Safe Drug Prescription (UC-37) 20 17
UC5 View Physician Satisfaction Survey 8 8
Results (UC-25)
UC6 View Patients (UC-28) 4 4
analyst’s navigation behavior, only the UCs with more than
1 true link deﬁned in the answer set were considered. Weidentiﬁed 32 such UCs, among which 6 were randomlyselected. Table I lists these requirements tracing tasks. Notethat ART-Assist keeps 70% of the most similar links in theretrieval results. Table I shows that, in some cases, not everytrue link is presented in ART-Assist.
We recruited 6 upper-division students in computing science
from Mississippi State University, including 2 seniors and
4 graduate students. None of the participants knew iTrust
before the experiment, but all of them reported being familiarwith the healthcare domain. The participants had all learnedabout traceability and reported a median of 0.25 years tracingexperience (mainly done manually).
During the experiment, each participant (analyst) worked
alone in a lab and began by signing the consent form andby learning how to use the ART-Assist tool. The analyst was
then given hard copies of the UC descriptions and was toldto use only ART-Assist and not to use internet or any otherresources in the experiment. We asked the analyst to trace
all 6 UCs and to carry out the tracing tasks in any orderthey would prefer. A researcher was present to run the ART-
Assist tutorial, to encourage the analyst to think aloud duringtracing, and to conduct an informal exit interview to elicitthe analyst’s feedback about their tracing experience. Eachexperiment session lasted approximately 1 hour.
V. R
ESULTS AND ANALYSIS
ART-Assist logs ﬁne-grained, time-stamped user interac-
tions. In order to extract the analyst’s actual diet (D Ac) from
the logs, we analyze the task environment by modeling theproblem space of tracing. Fig. 4 shows the state-transitiondiagram that depicts the lifecycle of an information item(namely, a traceability link). The analyst may view (scan)the item as it is presented in ART-Assist’s retrieval page(patch), and further pursue the prey (link) if she regards it asrelevant. The analyst may reﬁne an item’s (de-)selection forseveral times, during which the item can be viewed optionally.Upon analyst’s approval, the item becomes part of the ﬁnallysubmitted RTM.
Modeling the task environment is critical to deﬁning the
variables of rational analysis (cf. Section III-A), especiallythose appeared in equation (2). In our study, t
s(scanning
time) denotes the view time for an item that is not selected.In another word, t
srefers to the time the leftmost, self-looped
“View ” transition in Fig. 4 takes. The other 4 transitions inRemove 
Add
Approve
View View 
Retrieve dSelected
Submitted
Fig. 4. State-space of an information item (traceability link) as a human
analyst with the tracing task interacts with the ART-Assist tool. Boxes show
states. Arrows show state transitions annotated with icons representing theART-Assist operations (cf. Fig. 2).
Fig. 4 represent operations on what the analyst believes to
be a relevant link. Thus, the time transitioned to and fromthe “Selected” state in Fig. 4 gives rise to t
h— the handling
time. Based on this, we deﬁne the analyst’s actual diet to be theset of patches containing handled items, i.e., D
Ac={Patch
P|∃linkl∈Psuch that ‘the analyst handles las a relevant
link at some point during tracing’ }.
For the comparison of D Ac with D Th, Fig. 5a shows
the average case in which the trace’s information environmentshapes the optimal diet selection. Fig. 5b provides D
Th
speciﬁc to each UC, along with the total number of patches(pages) retrieved by ART-Assist. On average, only 13.5% ofthe available patches are included in D
Th. In contrast, D Ac
is much less selective as it is composed of an average of 45.0%available patches. For all 6 tracing tasks, D
Th is a proper
subset of D Ac, which implies that the theory’s predictions are
highly accurate. To evaluate the matching degree with D Th,
we expand upon the work of Lawrance et al. [13] and use the
analysts’ consensus to further categorize the patches in D Ac.
•Match refers to the overlap between D Ac and D Th.
We deﬁne the match is large if the patch appears in over
half of the analysts’ actual diets (i.e., ≥3 analysts’ diets
in our study); otherwise, the match is slight .
•Departure refers to the difference of D Ac and D Th.
We say the departure is large if the patch is handled by
over half of the analysts as they pursue relevant prey inthe patch; otherwise, the departure is slight .
Table II shows the structural and behavioral aspects of
requirements analyst’s information foraging. Descriptive statis-tics are given in terms of
(mean ±standard deviation) . Infer-
ential statistics are performed via the Mann-Whitney test [40],a non-parametric test which was also used by Lawranceet al. [13] for assessing software developer’s information
foraging. It is evident from Table II that the matched dietsare more proﬁtable than the departed ones. This should notbe surprising since the optimal diet (D
Th) is selected based
on the descending order of proﬁtability ( π). However, the
analysts did pursue in a greater number of low-proﬁtableprey-patches than in theoretically high-proﬁtable ones (Mann-
Whitney, U =32.5,p<0.05). On one hand, this may account
for the quality degradation on the RTM after human vettedthe retrieved links [7, 8, 9, 10]. On the other hand, this maysuggest that analysts needed to consume the “bad” in order torecognize the “good”. In this sense, the correct and incorrectdecisions were indeed interdependent.578Gain
0.000.150.300.45
Patch index 1 4 7 10 13 16 19 Profitability
 Rate of gain
R(n)/g652n Use 
Case# of 
patches
(total)D_Th
(optimal 
diet)D_Ac  (human analysts’ actual information diets) 
Largely matched 
with D_Th Slightly matched 
with D_Th Slightly departed from 
D_Th Largely departed 
from D_Th 
UC 1 17 {P 1, P2, P3} {P 1} {P 2, P3} {P 6, P8, P11, P12, P16} {P 4, P5}
UC 2 19 {P 1} {P 1} /g301 {P3, P4, P11, P19} {P 2}
UC 3 15 {P 1, P2, P3} {P 1, P2, P3} /g301 {P7, P8, P13} {P 4, P6}
UC 4 12 {P 1, P2} {P 1, P2} /g301 {P4} {P 3}
UC 5 13 {P 1} {P 1} /g301 {P2, P3, P4, P5} /g301
UC 6 14 {P 1, P2} {P 1} {P 2} {P 5, P6, P7, P13} {P 3, P4}
(a) (b)
Fig. 5. (a)Applying the diet model (cf. Fig. 1b) to the experimental tracing tasks. R(n)andπnare both averaged over the 6 UCs. (b)Comparing optimal
forager’s diet (D Th) with real analysts’ diets (D Ac). P idenotes Patch irepresenting the ithpage retrieved by ART-Assist.
TABLE II
ASSESSING HUMAN ANALYST ’S INFORMA TION FORAGING FROM STRUCTURAL AND BEHA VIORAL PERSPECTIVES
DAc Structural Properties Navigational Behaviors (all time values are in seconds)
Categories π(proﬁtability) cohesion # of revisits ts th t∗Ac Δt∗=t∗Ac−t∗Th
Match Large 0.32±0.130.61±0.250.45±0.096.11±1.304.95±1.0829.50±22.81 9.55±3.01
with D Th Slight 0.27±0.180.40±0.340.33±0.076.05±1.136.27±2.8535.29±17.3413.19±5.53
Departure Slight 0.09±0.060.35±0.191.94±1.387.97±2.189.58±3.4490.03±46.7256.07±24.49
from D Th Large 0.12±0.070.53±0.211.05±0.637.31±2.698.08±3.1455.64±23.2648.40±31.72
Proﬁtability ( π) is computed based on the answer set
that deﬁnes the true links for each requirement. Under non-experimental settings where no answer set is available, Duanand Cleland-Huang [38] argued that internal metrics, such ascoupling and cohesion, could be used to assess the quality ofthe cluster-patch. We adapt this idea and compute the patch
cohesion as the average pairwise TF-IDF differences of all
the information items in a given patch. Table II shows thatgreater consensus (largely matched and largely departed) wasachieved on more cohesive patches. Further comparison re-veals that the cohesion of analysts’ handled patches (i.e., thosein D
Ac) is signiﬁcantly greater than that of the patches the
analysts did not view as relevant (Mann-Whitney, U =271.0,
p<0.01). Thus, analysts seem to use cohesion to judge an
information patch’s relevance; testing this hypothesis requiresfuture research.
As far as the navigation behavior is concerned, the patches
matched with D
Th were visited mostly once. However, the
DTh-departed patches received a surprisingly high number
of revisits. This shows analysts’ struggles with deciding the
relevance of certain prey-patches. Even when relevance wasdetermined, the struggles with D
Th-departed patches contin-
ued as analysts expended more time handling the links ( th).
Interestingly, the scanning time ( ts) stayed roughly the same
across the D Ac categories.
Our ﬁnal analysis is concerned with analysts’ within-patch
residence time (t∗Ac) and how it differs from the optimal
residence time (t∗Th). As shown in Table II, t∗Ac exhibits
considerable variation among D Ac categories, but in all
the cases, the actual residence time is greater than t∗Th.
Such deviations from optimality ( Δt∗) were observed to be
substantially greater in D Th-departed diets than in D Th-
matched ones (Mann-Whitney, U =744.5,p<0.01). Fig. 6 uses
the navigation steps to illustrate Δt∗. To reduce clutter, only
one sample Δt∗(largely matched) is given in Fig. 6.012
02468 1 0 1 2Match (large)
Match (slight)Departure (large)
Departure (slight)
t*_Th t*_Ac/g507t*
Fig. 6. Applying the patch model (cf. Fig. 1c) to plot the average information
gain (y-axis) per navigation step (x-axis). The value of the <ts,th>pair (cf.
equation (2)) is instantiated by the average time according to the analysts’
actual navigations reported in Table II.
VI. D ISCUSSION
As our results indicate that discrepancies exist between
human analyst’s information seeking and the behavior deter-
mined via foraging theory’s optimality models, we suggestdesign guidelines for tools supporting analysts in performingrequirements tracing. We then relate our work to other models
and discuss the limitations of our study.
A. Implications for Tool Support
Our objective of uncovering the gaps from optimality is to
enable principled ways to reduce the gaps. Our study showsseveral important discrepancies that provide concrete insights
into the behavioral traits of and the obstacles faced by humananalysts.
First, although the low-proﬁtable, non-optimal patches (i.e.,
D
Th-departed patches) turned out to be indispensable for an-
alysts’ information diets, the analysts did struggle to determinethe relevance of those patches. The primary reason, based onour interviews, was the lack of contextual information whenthe analysts navigated from one patch (page) to another. Infact, the analysts often unintentionally returned to locations579that had already been visited. Most agreed that such revisits
were wasted interactions since they had to repeat the relevancejudgments. One way to alleviate the struggles is to introduceexplicit tagging or rejecting the patch as a whole, as designedin the work of Duan and Cleland-Huang [38]. Another supportis to leverage advanced information scent modeling tech-niques, such as exploiting analyst’s navigation recency [15],to generate reactive navigation recommendations.
Second, while the scanning time ( t
s) remained approxi-
mately constant, the handling time ( th) was longer for D Th-
departed diets than for D Th-matched ones. During tracing,
more than half of the analysts expressed uncertainty aboutwhether a link should be placed in the shopping-cart forcheckout. Some suggested that the gathering of traceabilityinformation could be diversiﬁed. For example, a black listof irrelevant links and a working area for storing to-be-determined links could be added to the tracing tool.
Third, the analysts invariably overspent the within-patch
time (t
∗Ac>t∗Th), especially when foraging in D Th-
departed patches. Enabling analysts to correctly reason aboutthe patch proﬁtability can help them to shorten the timedifference ( Δt
∗). However, it is not possible to expect the
analysts to have the perfect knowledge about the informationenvironment. Our study implies that patch cohesion, one ofthe internal quality indicators, can be of much practical value.In this way, cohesion acts as the perceived proﬁtability [13]
and its improvement via clustering [38, 41] has already led toremarkable enhancements in tracing.
B. Relationship to Other Models
Models of Information Seeking and Gathering .K o et
al.[24] suggested that software maintainers’ seeking rele-
vant code follows an iterative ‘Search-Relate-Collect’ process.While in line with Ko’s model, assisted requirements tracingis also related to Web search (e.g., the initiation, selection,and collection stages described by Hearst [42]). Although it iswell known that Web users view only the ﬁrst few search resultpages (e.g., Jansen et al. [43] reported that 80% of the users
viewed only the ﬁrst 2 pages), our results show that humananalysts did go as far as the last page to collect the relevanttraceability information.
Foraging-Theoretic Approaches to Code Navigation .
Table III situates our study within the previous research
investigating programmer navigation. Because tracing is anew domain for applying foraging theory, our mapping of aninformation patch is different from the prior work. The mostimportant difference, in our opinion, is the use of the dietmodel in our study to determine D
Th, which represents a
novel mechanism for assessing D Ac.
Studies of Human Factors in Tracing . Our work comple-
ments the studies of analyst’s tracing performance based onthe ﬁnal RTM’s quality (e.g., [7, 8, 9]). In our study, both theRTM decision and the rational decision-making process are
examined. While our work demonstrates the value of optimalforaging models, how to expand the analysis to account forthe predictable level of human fallibility [29] and to balanceTABLE III
COMPARING OUR WORK WITH OTHER FORAGING -THEORETIC MODELS
Fundamentals of infor-
mation foraging theory Patches Scent Diet
Seminal work [13] Classes Textual similarity DAc
Textual similarity,
PFIS [14] Classes Program topology DAc
Program topology,
PFIS2 [15] Methods Navigation recency DAc
Single factors,
PFIS3 [25] Methods Optimal composites DAc
Pages Textual DAc,
Our work retrieved similarity DTh
the economics of maintaining and utilizing the requirements
traces [44, 45] remains an open question.
C. Study Limitations
The applicability of this study’s results may be limited
by ART-Assist’s design, operationalization of analyst’s actualdiet, and participants’ unfamilarity with the subject system.
ART-Assist provides basic features commonly found in IR-
based tracing tools. The 70% threshold ﬁlters out certain truelinks. Adjusting this value, statically or dynamically, may
alter the analyst’s information foraging behavior. A similarlimitation applies to structuring 10 links per page.
When deﬁning D
Ac, we adopted a behavioral viewpoint by
focusing on how to operate a link (cf. Fig. 4) rather than what
links were approved in the end. Shifting D Ac’s deﬁnition
to the ﬁnal RTM’s perspective would modify an importantassumption of the decision problem. Once assumptions likethis are updated, they can feed back into the rational analysisof the information forager.
Our work with student participants limits how the results
could be generalized. Egyed et al. [45] note that in many
industrial settings people have no intimate system knowledgeduring trace recovery. There is also precedence in traceabilitywork: prior studies have used students with low levels ofindustry experience to represent new people joining a com-pany [7, 8, 10, 45]. Nevertheless, it would be interesting tostudy how familiarity levels may alter the tracing behavior.
VII. C
ONCLUSIONS
The main contributions of this paper are the evolutionary-
ecological understanding of the fundamental mechanisms un-derlying human analysts’ requirements tracing behaviors, thetheoretical analysis of optimality within the shaping limits
placed by tracing’s task and information environments, the
empirical evaluation of the matches and mismatches betweentheory’s predictions and analysts’ actual behaviors, and theconcrete insights of the principled ways to increase practicalsupport for software traceability.
Building on the extensive research on the IR-based candi-
date link recovery methods [1, 2, 3, 4, 5], the study of humananalysts represents a milestone in the traceability literature,as we now have reached a general consensus regarding theequivalence of the underlying IR methods [27]. The success ofrequirements tracing, as measured by the ﬁnal RTM’s quality,580therefore hinges largely on the analysts’ interactions with and
decisions about the tool’s output. Building on the growingbody of work on human factors [7, 8, 9, 10], it is hoped that ourwork contributes a step towards understanding the ecologicallyvalid ways to “design a fast, accurate and certiﬁable tracingprocess” [29].
A
CKNOWLEDGEMENT
We thank all the participants of our study, as well as Tanmay
Bhowmik and Sandeep Reddivari for comments on earlier drafts
of this paper. The work is funded by the U.S. NSF (National
Science Foundation) Grant CCF-1238336 and the Mississippi State
University’s Cross-disciplinary Research Facilitation Grant Program.
REFERENCES
[1] J. H. Hayes, A. Dekhtyar, and S. K. Sundaram, “Advancing candidate
link generation for requirements tracing: the study of methods,” IEEE
TSE , vol. 32(1), pp. 4–19, 2006.
[2] G. Antoniol, G. Canfora, G. Casazza, A. De Lucia, and E. Merlo,
“Recovering traceability links between code and documentation,” IEEE
TSE , vol. 28(10), pp. 970–983, 2002.
[3] A. De Lucia, F. Fasano, R. Oliveto, and G. Tortora, “Recovering trace-
ability links in software artifact management systems using information
retrieval methods,” ACM TOSEM , vol. 16(4), 2007.
[4] X. Zou, R. Settimi, and J. Cleland-Huang, “Improving automated re-
quirements trace retrieval: a study of term-based enhancement methods,”
Empir Softw Eng , vol. 15(2), pp. 119–146, 2010.
[5] X. Chen and J. Grundy, “Improving automated documentation to code
traceability by combining retrieval techniques,” in ASE , 2011, pp. 223–
232.
[6] U.S. Federal Aviation Administration, “RTCA/DO-178B Software Con-
siderations in Airborne Systems and Equipment Certiﬁcation,” 1992.
[7] D. Cuddeback, A. Dekhtyar, and J. H. Hayes, “Automated requirements
traceability: the study of human analysts,” in RE, 2010, pp. 231–240.
[8] A. Dekhtyar, O. Dekhtyar, J. Holden, J. H. Hayes, D. Cuddeback, and
W.-K. Kong, “On human analyst performance in assisted requirements
tracing: statistical analysis,” in RE, 2011, pp. 111–120.
[9] J. H. Hayes and A. Dekhtyar, “Humans in the traceability loop: can’t
live with ’em, can’t live without ’em,” in TEFSE , 2005, pp. 20–23.
[10] W.-K. Kong, J. H. Hayes, A. Dekhtyar, and J. Holden, “How do we trace
requirements? an initial study of analyst behavior in trace validation
tasks,” in CHASE , 2011, pp. 32–39.
[11] P . Pirolli, Information F oraging Theory: Adaptive Interaction with
Information . Oxford University Press, 2007.
[12] D. W. Stephens and J. R. Krebs, F oraging Theory . Princeton University
Press, 1986.
[13] J. Lawrance, R. Bellamy, and M. Burnett, “Scents in programs: does in-
formation foraging theory apply to program maintenance?” in VL/HCC ,
2007, pp. 15–22.
[14] J. Lawrance, R. Bellamy, M. Burnett, and K. Rector, “Using information
scent to model the dynamic foraging behavior of programmers inmaintenance tasks,” in CHI , 2008, pp. 1323–1332.
[15] J. Lawrance, M. Burnett, R. Bellamy, C. Bogart, and C. Swart, “Reactive
information foraging for evolving goals,” in CHI , 2010, pp. 25–34.
[16] J. Lawrance, C. Bogart, M. Burnett, R. Bellamy, K. Rector, and S. D.
Fleming, “How programmers debug, revisited: an information foraging
theory perspective,” IEEE TSE , (accepted).
[17] C. D. Manning, P . Raghavan, and H. Sch ¨utze, Introduction to Informa-
tion Retrieval . Cambridge University Press, 2008.
[18] U. Shardanand and P . Maes, “Social information ﬁltering: algorithms
for automating “word of mouth”,” in CHI , 1995, pp. 210–217.
[19] P . Pirolli, “Computational models of information scent-following in a
very large browsable text collection,” in CHI , 1997, pp. 3–10.[20] E. H. Chi, P . Pirolli, K. Chen, and J. E. Pitkow, “Using information scent
to model user information needs and actions on the Web,” in CHI , 2001,
pp. 490–497.
[21] J. R. Anderson and P . Pirolli, “Spread of activation,” Journal of Exper-
imental Psychology , vol. 10, pp. 791–798, 1984.
[22] H. Sch ¨utze, “Dimensions of meaning,” in SC, 1992, pp. 787–796.
[23] J. M. Spool, C. Perfetti, and D. Brittan, Designing for the Scent of
Information . User Interface Engineering, 2004.
[24] A. J. Ko, B. A. Myers, M. J. Coblenz, and H. H. Aung, “An exploratory
study of how developers seek, relate, and collect relevant informationduring software maintenance tasks,” IEEE TSE , vol. 32(12), pp. 971–
987, 2006.
[25] D. Piorkowski, S. D. Fleming, C. Scafﬁdi, L. John, C. Bogart, B. E.
John, M. M. Burnett, and R. K. E. Bellamy, “Modeling programmer
navigation: a head-to-head empirical evaluation of predictive models,”
inVL/HCC , 2011, pp. 109–116.
[26] N. Niu, A. Mahmoud, and G. Bradshaw, “Information foraging as a
foundation for code navigation,” in ICSE , 2011, pp. 816–819.
[27] R. Oliveto, M. Gethers, D. Poshyvanyk, and A. De Lucia, “On the
equivalence of information retrieval methods for automated traceability
link recovery,” in ICPC , 2010, pp. 68–71.
[28] J. H. Hayes and A. Dekhtyar, “A framework for comparing requirements
tracing experiments,” IJSEKE , vol. 15(5), pp. 751–782, 2005.
[29] D. Cuddeback, A. Dekhtyar, J. H. Hayes, J. Holden, and W.-K. Kong,
“Towards overcoming human analyst fallibility in the requirements
tracing process (NIER Track),” in ICSE , 2011, pp. 860–863.
[30] J. R. Anderson, The Adaptive Character of Thought . Lawrence Erlbaum
Associates, 1990.
[31] J. Lin, C. C. Lin, J. Cleland-Huang, R. Settimi, J. Amaya, G. Bedford,
B. Berenbach, O. B. Khadra, C. Duan, and X. Zou, “Poirot: a distributed
tool supporting enterprise-wide automated traceability,” in RE, 2006, pp.
356–357.
[32] A. Mahmoud and N. Niu, “TraCter: a tool for candidate traceability link
clustering,” in RE, 2011, pp. 335–336.
[33] J. Cleland-Huang, B. Berenbach, S. Clark, R. Settimi, and E. Romanova,
“Best practices for automated traceability,” IEEE Computer , vol. 40(6),
pp. 27–35, 2007.
[34] A. Mahmoud and N. Niu, “Source code indexing for automated tracing,”
inTEFSE , 2011, pp. 3–9.
[35] A. De Lucia, R. Oliveto, and G. Tortora, “IR-based traceability recovery
processes: an empirical comparison of “one-shot” and incremental
processes,” in ASE , 2008, pp. 39–48.
[36] N. Niu, J. Savolainen, T. Bhowmik, A. Mahmoud, and S. Reddivari, “A
framework for examining topical locality in object-oriented software,”
inCOMPSAC , 2012, pp. 219–224.
[37] H. Sultanov, J. H. Hayes, and W.-K. Kong, “Application of swarm
techniques to requirements tracing,” REJ , vol. 16, pp. 209–226, 2011.
[38] C. Duan and J. Cleland-Huang, “Clustering support for automated
tracing,” in ASE , 2007, pp. 244–253.
[39] A. Meneely, B. Smith, and L. Williams, “iTrust electronic health care
system: a case study,” in Software and Systems Traceability , J. Cleland-
Huang, O. Gotel, and A. Zisman, Eds. Springer, 2012.
[40] W. J. Conover, Practical Nonparametric Statistics . Wiley, 1999.
[41] N. Niu and A. Mahmoud, “Enhancing candidate link generation for
requirements tracing: the cluster hypothesis revisited,” in RE, 2012, pp.
81–90.
[42] M. A. Hearst, Search User Interfaces . Cambridge University Press,
2009.
[43] B. J. Jansen, A. Spink, J. Bateman, and T. Saracevic, “Real life
information retrieval: a study of user queries on the Web,” ACM SIGIR
F orum , vol. 32(1), pp. 5–17, 1998.
[44] A. Egyed, P . Gr ¨unbacher, M. Heindl, and S. Bifﬂ, “V alue-based require-
ments traceability: lessons learned,” in RE, 2007, pp. 115–118.
[45] A. Egyed, F. Graf, and P . Gr
¨unbacher, “Effort and quality of recovering
requirements-to-code traces: two exploratory experiments,” in RE, 2010,
pp. 221–230.581