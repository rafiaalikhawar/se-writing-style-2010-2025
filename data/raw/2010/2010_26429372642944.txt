The Conï¬dence in our k-Tails
Hila Cohen and Shahar Maoz
School of Computer Science
Tel Aviv University, Israel
ABSTRACT
k-Tails is a popular algorithm for extracting a candidate
behavioral model from a log of execution traces. The use-
fulness of k-Tails depends on the quality of its input log,
which may include too few traces to build a representative
model, or too many traces, whose analysis is a waste of re-
sources. Given a set of traces, how can one be condent that
it includes enough, but not too many, traces? While many
have used the k-Tails algorithm, no previous work has yet
investigated this question.
In this paper we address this question by proposing a novel
notion of log completeness. Roughly, a log of traces, ex-
tracted from a given system, is k-complete, i adding any
new trace to the log will not change the resulting model k-
Tails would build for it. Since the system and its full set of
traces is unknown, we cannot know whether a given log is
k-complete. However, we can estimate its k-completeness.
We call this estimation k-condence .
We formalize the notion of k-condence and implement its
computation. Preliminary experiments show that k-condence
can be eciently computed and is a highly reliable estimator
for k-completeness.
General Terms
Algorithms, Design, Experimentation
Keywords
Dynamic specication mining; probabilistic approach
1. INTRODUCTION
Dynamic specication mining algorithms extract candi-
date specications from logs of execution traces. One such
well-known algorithm is k-Tails, rst introduced in [6]. k-
Tails input consists of a set of traces and a positive number
k. Its output is a nite state automaton, approximating
the behavior of the system from which the traces have been
extracted. It works by starting with a most rened model
and iteratively coarsening it by merging states whose future
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proï¬t or commercial advantage and that copies bear this notice and the full cita-
tion on the ï¬rst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciï¬c permission
and/or a fee. Request permissions from permissions@acm.org.
ASEâ€™14, September 15-19, 2014, Vasteras, Sweden.
Copyright 2014 ACM 978-1-4503-3013-8/14/09 ...$15.00.
http://dx.doi.org/10.1145/2642937.2642944.kstates are equivalent. Over the last two decades, the al-
gorithm has been implemented and used, in many variants,
e.g., [4,7,17,21,22,28].
The usefulness of a specication mining algorithm in gen-
eral and of k-Tails in particular depends on the quality of
its input log. On the one hand, if there are too few traces,
the constructed model may not be a good representation
of the behavior of the system under investigation. On the
other hand, if there are many traces, perhaps some are re-
dundant, and executing the algorithm over all of them is a
waste of resources. Given a set of traces, how can one know
whether it includes enough, but not too many, traces, to
build a representative model? While many have used the k-
Tails algorithm, no previous work has yet investigated this
question.
In this paper we address this question by proposing a novel
notion of log completeness. Roughly, a log of traces, ex-
tracted from a given system, is k-complete, i adding any
new trace to the log will not change the resulting model k-
Tails would build for the log. Since the system and its full set
of traces is unknown, we cannot know whether a given log is
k-complete. However, we can estimate the probability that
the log is k-complete. We call this estimation k-condence .
A low k-condence of, say, 0.3, hints that the model which
may be built by the k-Tails algorithm is probably far from
characterizing the behavior of the system under investiga-
tion. There is high probability that additional traces will
change the model which k-Tails would build. Given a log
with such a low k-condence, one should better look for ad-
ditional traces. A very high k-condence, of say, 0.95, hints
that the model which may be built by the k-Tails algorithm
is probably very close to correctly characterize the behavior
of the system under investigation. There is very low proba-
bility that additional traces will change this model.
We compute the k-condence of a set of traces, by esti-
mating the probability that it includes all possible sequences
of lengthkthat the system under investigation can generate.
The estimation is based on the appearances of the sequences
in the specic traces we see in the log and on their frequen-
cies. It does not require running the k-Tails algorithm.
An interesting and important feature of k-condence is
its non-monotonicity. Specically, as traces are added to a
log, its k-condence may increase or decrease. Indeed, in
the absence of additional information, e.g., about the order
in which traces are produced, a new trace may introduce
new information, which should lead us to revise our previous
estimations. Note, however, that the k-condence of a log
does not depend on the order of traces in the log.
605
We have implemented the computation of k-condence
and evaluated it over several models. The evaluation shows
that k-condence can be eciently computed and is a highly
reliable estimator for k-completeness. Thus, it can be eec-
tively used by engineers using the k-Tails algorithm.
The next section presents two examples. Sect. 3 presents
the formal denitions and the computation of k-condence.
Sect. 4 presents a preliminary evaluation and Sect. 5 dis-
cusses design decisions and limitations of our work. Sect. 6
discusses related work and Sect. 7 concludes.
2. EXAMPLES
We use an example to demonstrate k-condence usage and
another one as a running example for this paper. The traces
and models described below are available in [1].
We consider the example CVS client, presented by Lo and
Khoo in [16]. The client provides the following interaction
scenarios: initialization, multiple-le upload, download, and
deletion, multiple-directory creation and deletion. Consider
an engineer having a log of 23 traces from this system, trying
to extract a model of its behavior. Fig. 1 shows the model
suggested by k-Tails with k= 1 for this log (the dashed
transitions login tostoreFile ,rename tologout and re-
moveDir toremoveDir arenotpart of the model suggested
by k-Tails for this 23 traces log). Can she be condent that
this model is a good representation of the system's behavior?
Perhaps the model is partial and more traces are needed?
Indeed, adding 25 more traces, and feeding the resulting log
of 48 traces to k-Tails, results in a revised model as shown
in Fig. 1 (including the dashed transitions).
Our tool computes a k-condence of 0.36 to the rst log
of 23 traces and a k-condence of 0.96 to the second log of
48 traces (for k= 2). These k-condences are essentially the
probabilities that the logs are k-complete, computed solely
based on the traces themselves.
On the one hand, if the engineer has set a minimum k-
condence threshold of 0.95 (which we suggest to be a rea-
sonable choice), she would not have stopped analyzing traces
too soon, i.e., before nding the additional transitions.
On the other hand, should the engineer continue to an-
alyze more traces of this system? Given the computed k-
condence of 0.96, the probability that additional traces will
reveal new behaviors is very small. Indeed in our example,
an extension of the log with 28 additional traces (many of
them new traces, not duplicates of any of the traces seen
before), resulted in a slightly higher k-condence of 0.99 but
in the same model as was suggested by k-Tails for the sec-
ond log of 48 traces. Thus, by stopping the analysis when
k-condence passed the 0.95 threshold, the engineer saved
the resources required in order to produce and analyze the
additional traces, yet did not lose any information.
As a running example for this paper we consider a simpler
model representing a le reading protocol. The model and
8 randomly generated traces from it are shown in Fig. 2.
3. K-COMPLETENESS AND K-CONFIDENCE
3.1 Basic Deï¬nitions
A trace over an alphabet  is a nite word
=he1;e2;:::;e miwheree1;:::;e m2. Forj1 we use
(j) to denote the jth element in .
Figure 1: CVS model as mined by k-Tails from the log of 23
traces (without the dashed transitions) and from the log of
48 traces (including the dashed transitions)
LetMbe a model over an alphabet . We use T(M)
to denote all traces accepted by the model M. A log ofM,
lT(M) is a nite set of traces from T(M). We denote
the set of all possible logs of MbyL(M ).
We characterize the k-Tails algorithm using a property we
call `k-directly-follows'. Roughly, the property `k-directly-
follows' for a sequence of events es=he1;e2;:::;e kiholds
in a trace i the sequence appears somewhere in the trace.
We formalize the `k-directly-follows' property using a pair
of functions. The rst function Ktrmaps every trace and
a sequence esto a value inf0;1g(intuitively, Ktrassigns a
value to the relation between the k-directly-follows property
and the trace). The second function Klogmaps subsets of
f0;1gtof0;1g, aggregating the results of Ktrper sequence,
from the trace level to the log level.
The formal denitions of the two functions follow the se-
mantics of `k-directly-follows'. Formally:
Denition 1 (k-directly-follows property) .
Ktr(;he1;e2;:::;e ki) =(19jV
1mk(j+m 1) =em
0otherwise
Klog(S) =
1 12S
0otherwise
Example 1. Fortr1andtr3shown in Fig. 2, k= 2, and the
sequences of length khopen;readi,hread;readi,hopen;openi
we have
Ktr(tr1;hopen;readi) = 1,Ktr(tr3;hopen;readi) = 1,
Ktr(tr1;hread;readi) = 0, Ktr(tr3;hread;readi) = 1,
Ktr(tr1;hopen;openi) = 0, Ktr(tr3;hopen;openi) = 0.
For a logftr1;tr3gand the same three sequences we have
Klog(fKtr(tr1;hopen;readi);K tr(tr3;hopen;readi)g) = 1
Klog(fKtr(tr1;hread;readi);K tr(tr3;hread;readi)g) = 1
Klog(fKtr(tr1;hopen;openi);K tr(tr3;hopen;openi)g) = 0.
606tr1:open,read,close
tr2:open,read,read,close
tr3:open,read,read,close,open,read,read,close,open,read,close
tr4:open,read,read,close
tr5:open,read,read,close,open,read,read,read,read,read,close,open,read,close
tr6:open,read,close,open,read,close
tr7:open,read,close,open,read,read,close,open,read,close
tr8:open,read,read,close
Figure 2: A simple example model and 8 randomly generated traces
3.2 K-Completeness
We say that a log l2L(M ) is k-complete if the informa-
tion one may extract about the k-directly-follows property
from the log lis equal to the information one may extract
about this property from any log that includes l(and thus
specically from all the traces in T(M)). Formally:
Denition 2 (k-completeness) .A logl2L(M ) is k-complete
i8l02L(M ) s.t.ll0,8es2k
Klog(fKtr(;es )j2lg) =Klog(fKtr(;es )j2l0g).
The intuition behind this denition is as follows. Consider
a model produced by k-Tails for a log, and a new trace whose
all subtraces of length k+ 1 appear in the produced model.
Applying k-Tails to a new log that consists of the original
log and the new trace, produces the same model.
Example 2. For the logs l=ftr1g,l0=ftr1;tr3g, and the
sequencehread;readi:Klog(fKtr(;hread;readi)j2lg)6=
Klog(fKtr(;hread;readi)j2l0g). Thus,l=ftr1gis not
2-complete.
3.3 K-Conï¬dence: Estimating K-Completeness
For a xed number kand a logl2L(M ), our goal is to
compute the probability that lis k-complete, i.e., to compute
l's k-condence. We dene a random variable Y() over 
 =
T(M), which maps a trace to its k-directly-follows property
results. Formally:
Y() :Y()[es] =Ktr(;es ):
Example 3. To continue our example from Fig. 2, the trace
tr1and the sequences hopen;readiandhread;readi, we have
Y(tr1)[hopen;readi] = 1 andY(tr1)[hread;readi] = 0.
Fory2f0; 1gjjkwe denote the probability that Yequals
yby(y):
(y) =P[Y=y]:
ycan be viewed as a k-dimensional array over f0;1g:
(y) is the probability that in a random trace from T(M)
we get the values of the k-directly-follows property as they
are encoded in y. It is determined by MbutMis considered
unknown.
We consider all traces from a log lto be samples from Y.
We assume that traces are randomly and independently cho-
sen fromT(M). Ifjlj=nwe denote them by Y1;Y2;:::;Y n.
These are independent, identically distributed random vari-
ables, versions of Y. Another random variable we dene
isYn, which aggregates all these samples to the k-directly-
follows values of the entire log:
Yn:Yn[es] =Klog(fYi[es]j1ing)
We now dene the true, but unknown, k-directly-follows
values,f(), in order to later compute the probability that
Ynis equal to it:
f() :f()[es] =Klog(fy[es]j(y)>0g):Example 4. For the model shown in Fig. 2 and the se-
quencehread;readi, since there are traces in T(M) where
the sequence appears and others where it does not appear,
we havef()[hread;readi] = Klog(fy[hread;readi]j (y)>
0g) =Klog(f0;1g) = 1: For the same model and the seqe-
uncehread;openi, since the sequence does not appear in any
trace inT(M), we havef()[hread;openi] =
Klog(fy[hread;openi]j (y)>0g) =Klog(f0g) = 0:
Note thatMdetermines f() (it is independent of any
specic log). We can now write Def. 2 using the above no-
tation as follows: a log lof sizenis k-complete i
Yn=f():
Recall that our goal is to compute the probability that l
is k-complete. Using the notation dened above, what we
are looking for is P[Yn=f()].
Denition 3 (k-condence) .The k-condence of a log of
sizen,l2L(M ) isP[Yn=f()].
3.4 Computing K-Conï¬dence
We useesto denote the sequence he1;e2;:::;e ki. Since it
is xed, we omit from the formulas below.
The probability that the k-directly-follows property does
not hold in the model but appears in one of the traces is zero.
Thus, we only need to consider the other case, where the
sequence of length kdoes not appear in the traces ( Yn[es] =
0) but is possible in the model ( f[es] = 1). Formally:
P[Yn=f] = 1 P[9es:Yn[es] = 0^f[es] = 1]
1 
esP[Yn[es] = 0^f[es] = 1]
P[Yn[es] = 0^f[es] = 1] =
P[Yn[es] = 0]f[es] = 1
0 f[es] = 0
=(Q
1inP[Yi[es] = 0]f[es] = 1
0 f[es] = 0
We useqesto denote the probability that the k-directly-
follows property for esholds on a random trace from T(M),
i.e., that the sequence he1;e2;:::;e kiappears somewhere in
the trace. When f[es] = 1 we have qes>0 andQ
1inP[Yi[es] = 0] = (1 qes)n.
Sinceqesis unknown, we estimate it using the average of
thenrandom variables Yi
^qes=nX
i=1Yi[es]
n(1)
and so overall, we have
P[Yn=f]1 X
fesj^qes>0g(1 ^qes)n: (2)
607es n= 1 n= 2 n= 3 n= 4 n= 5 n= 6 n= 7 n= 8
close;read 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00)
close;open 0.00 (-0.00) 0.00 (-0.00) 0.33 (-0.30) 0.25 (-0.32) 0.40 (-0.08) 0.50 (-0.02) 0.57 (-0.00) 0.50 (-0.00)
open;read 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00)
open;open 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00)
open;close 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00)
read;open 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00)
read;read 0.00 (-0.00) 0.50 (-0.25) 0.67 (-0.04) 0.75 (-0.00) 0.80 (-0.01) 0.67 (-0.00) 0.71 (-0.00) 0.75 (-0.00)
read;close 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00) 1.00 (-0.00)
close;close 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00) 0.00 (-0.00)
2-condence 1 0.75 0.67 0.68 0.92 0.98 0.99 0.99
Table 1: Example k-condence computation for the log of 8 traces shown in Fig. 2, with k= 2. If we are using a 0 :95 threshold, we stop the
computation after 6 traces have been analyzed. See Sect. 3.5.
3.5 Example Computation
We demonstrate a k-condence computation on our run-
ning example model and generated traces shown in Fig. 2.
For these traces, Table 1 shows the computation of k-
condence for k= 2. Each row corresponds to a dierent
sequencees, e.g., the rst row corresponds to the property
`close directly follows read'. Each column corresponds to
the addition of a new trace to the accumulating log. The
table cell for row esand column n=jshows the value
^qesfrom Equ. 1. At the bottom line of each column we
show the accumulating total P[Yn=f], which represents
the probability that the set of traces analyzed so far is k-
complete, i.e., k-condence as dened in Equ. 2. Thus, the
table shows the intermediate k-condence values.
As an example, for n= 3, the computed value ^ qclose;open =
0:33 (see Equ. 1) is the probability to have an instance of
close;open in a random trace, given the 3 traces analyzed so
far. Since this is the third trace already, the negative contri-
bution to the accumulating k-condence is (1  0:33)3= 0:30
(see Equ. 2). That's the probability that in a random log of
size 3, close;open will not occur.
Given a threshold of 0 :95, in this example one could stop
after analyzing only 6 traces from the original log, and have
high condence that the model built by k-Tails for this 6
traces log will not change if additional traces are considered.
Note that in our example, as traces are added, k-condence
may increase or decrease. In fact, the rst computed k-
condence is (always) already 1; however, in general, the
larger the log, the lesser the expected decrease in k-condence
when a new trace is added (we demonstrate it in this exam-
ple by showing the computed values for n= 7 andn= 8).
In Sect. 5 we discuss this non-monotonicity and the need for
a minimal number of traces to produce useful results.
4. EV ALUATION
We have implemented the computation of k-condence.
The implementation gets as input a log (a set of traces) and
a numberk. Note that the k-condence computation does
not need to run the k-Tails algorithm. Given a log l, for
each trace2l, and for each sequence of length k es, we
computeKtr(;es ). The computed values are used as input
for the computation of the log's k-condence.
We conducted preliminary experiments to check whether
k-condence can be used as an eective proxy for true k-
completeness. All logs, models, and implementation code
described in this paper are available for inspection and re-
production together with documentation from [1].4.1 Methodology
We use two measures to evaluate the eectiveness of k-
condence, k-reliability and k-redundancy. We dene the
k-reliability of a log to be 1 if the log is k-complete and 0
otherwise. For a set of logs L, a mean k-reliability close to 1
hints that most of the logs are k-complete. We dene the k-
redundancy of a log to measure how close is it to its minimal
prex log which is k-complete (assuming an arbitrary xed
order of traces). For a set of logs L, a mean k-redundancy
close to 0 and a low standard deviation hint that the logs
do not include much redundant traces. Formally:
Denition 4 (k-reliability). The k-reliability of a log lis
rel(l) =
1lis k-complete
0otherwise.
Denition 5 (k-redundancy) .Given a log l(in a xed ar-
bitrary order), let imin(l) be the minimal index of traces in l
such that the set of traces 1;2;:::; imin2lis k-complete.
The k-redundancy of lisred(l ) = 1 imin(l)
jlj.
Example 5. Consider our running example and the results
of computing its 2-condence (Fig. 2 and Table 1). This log's
2-reliability is rel(l) = 1. Since it reaches 2-completeness
already after the 3rd trace and we stopped the computation
when reaching the 0.95 threshold after the 6th trace, its 2-
redundancy is red(l ) = 1 3=6 = 0:5.
Note that to calculate k-reliability and k-redundancy, as
in the above example, one must know the system from which
the traces were extracted, so that she can compute the true
value for each sequence. This is typically unknown in a real-
world setting, but it is known in our controlled evaluation.
4.2 Experiment Design
For each model we used the following experiment proto-
col. We rst generated traces from the model using the trace
generator of [21] with high state coverage. We then cre-
ated an initial log by randomly selecting a minimal number
of 10 traces, and iteratively computed the current log's k-
condence and added a trace to it. We kept adding traces to
the current log until we reached a xed k-condence thresh-
old of 0.95 (or we ran out of traces to add). Finally, we
computed the k-reliability and k-redundancy of the nal log
(we checked true k-completeness using a model-checker, i.e.,
by expressing the k-directly-follows properties in temporal
logic and verifying them against the model). We used k= 2.
We repeated the above protocol for each model 200 times
and computed the mean of k-reliability and k-redundancy
for the sets of 200 logs.
608Model jj # s # t a.l.
java.net.DatagramSocket 29 9 82 15
java.net.MultiCastSocket 16 7 36 12
java.net.Socket 42 16 209 21
java.net.URL 17 7 61 9
java.util.Formatter 8 6 15 7
java.util.StringTokenizer 7 6 18 2
Table 2: Models used in our evaluation, taken from Pradel et al. [25].
For each model we report the size of the alphabet , the number of
states (# s), the number of transitions (# t), and the average length
of the generated traces used in the logs (truncated).
Model jljc. m rel. m red. m/sd
java.net.DatagramSocket 1121 0.94 1 0.53/0.10
java.net.MultiCastSocket 467 0.97 0.99 0.63/0.17
java.net.Socket 1891 0.83 0.98 0.39/0.16
java.net.URL 509 0.96 1 0.58/0.11
java.util.Formatter 120 0.96 0.99 0.62/0.16
java.util.StringTokenizer 1808 0.97 0.94 0.65/0.22
Table 3: Experiment results. Each experiment was repeated 200
times for each of the models. For each model we report the average
number (truncated) of traces required to reach k-condence >0:95,
the mean of the calculated k-condence (c. m), k-reliability (rel. m),
and the mean and standard deviation of k-redundancy (red. m/sd).
Traces generated using the trace generator of [21].
4.3 Results
We used 6 nite-state automaton models from Pradel et
al. [25]. Table 2 lists the models we used. For each model we
report the size of the alphabet , the number of states and
transitions, and the average length of the generated traces
used in the logs. Table 3 shows the experiment results on
the models listed in Table 2.
The results show that our k-condence computation
is highly reliable . In only one case (java.net.Socket) we
ran out of traces to add before k-condence reached the 0.95
threshold. On the other hand, k-redundancy is not
always low , which hints to the conservative nature of the
k-condence denition.
All experiments were executed on an ordinary laptop com-
puter, Intel i7 CPU 3.0GHz, 8GB RAM with Windows 7
64-bit OS, Java 1.7.0 09 64-bit. For all models, in all our
experiments, k-condence computation never exceeded 15
milliseconds. This shows that the k-condence com-
putation is fast. It is not surprising as the computation
is, by denition, linear in the number of traces in the log.
4.4 Threats to Validity
We now discuss threats to the validity of our results. First,
the selection of models in our evaluation may not represent
typical systems. We used publicly available models taken
from [25]. Yet, we do not know if these are representative of
real-world systems.
Second, in our evaluation we used a publicly available
trace generator, from [21], with high state coverage. It is
possible that one may get dierent results if a dierent trace
generator or a dierent coverage criteria are used.
Finally, the selection and order of traces in the log af-
fect the point where the analysis may reach the condence
threshold and thus aect the point used to compute re-
dundancy (although, by denition, the k-condence and k-
completeness of a log do notdepend on the order of traces in
it). We mitigated this by using randomization in the selec-
tion of traces and in the order in which they were analyzed,
and by repeating all evaluation experiments 200 times.5. DISCUSSION AND LIMITATIONS
We now discuss some important design decisions and sev-
eral limitations of our present work.
An important assumption underlying our work is that the
traces are randomly and independently chosen from T(M).
If this is not the case, e.g., if one uses a biased trace generator
which favors some system features over others, and the bias
isknown, it may be possible to account for this bias in the
computation of the qess and improve it.
One may be concerned about the non-monotonicity of our
notion of k-condence; as traces are added to a log, its k-
condence may increase or decrease. However, we consider
this non-monotonicity an advantage; in the absence of addi-
tional information, e.g., about the order in which traces are
produced, a new trace may introduce new information (i.e.,
reveal a new k-length sequence), which should lead us to re-
vise our previous estimations (see, e.g., in Table 1, the con-
dence decreases when the 3rd trace introduces the sequence
close;open ). Moreover, as ngrows, the probability that
a sequence that is possible in the system has not yet been
seen decreases, and so, roughly, the larger the log, the lesser
the expected decrease in k-condence when a new trace is
added, and the expectation of a decrease approaches zero at
the limit (a formalization and proof for this claim is outside
the scope of this paper). Still, in contrast, it is important to
note that our notion of k-completeness is monotonic, i.e., by
denition, any extension of a k-complete log is k-complete.
Also, by its denition, the k-condence of a log does not
depend on the order of traces in it.
Finally, another limitation relates to the size of the log.
Our experience shows that for very small logs, e.g., under 5
traces, k-condence results are very sensitive and uctuate
much, so they are practically useless. In general, the larger
the alphabet, the more traces are required in order to get
useful results (and reduce the risk that additional traces
decrease the computed k-condence). Still, note that this
limitation is typically not a problem in practice because real-
world logs consist usually of many traces.
6. RELATED WORK
Dynamic approaches to specication mining look for can-
didate specications in execution traces (see, e.g., [5, 9{15,
19,20,22,23,26,27,29,30]). None of these, to the best of our
knowledge, has considered the condence one could have in
the completeness of the input logs.
In [8], Dallmeier et al. consider dynamic specication min-
ing and ask the following question: what makes us believe
that we have seen suciently many executions? Indeed, it
seems that in our present work we ask a similar question.
However, our work and Dallmeier et al. work dier funda-
mentally. Dallmeier et al. look for the answer in test case
generation and in static specication mining. In their work,
a partial set of traces is enriched in order to explore pre-
viously unobserved aspects of the execution space, includ-
ing more general behavior and more exceptional behavior.
In contrast, we consider a black box setting and address
this question by providing a formal probabilistic measure to
the notion of `suciently many traces'. We do not suggest
ways to make an incomplete log more complete. Instead,
we provide a probabilistic measure of k-condence, which
allows engineers who use the k-Tails algorithm to assess the
k-completeness of the traces they have.
609Hee et al. [24] presented a probabilistic approach to log
completeness in the context of the -algorithm [3], which
mines Petri nets, in particular workow nets [2], and is used
extensively in the eld of process mining. Our work is in-
spired by the work of Hee et al. and extends it: we present
a notion of log condence for the well known k-Tails algo-
rithm, with preliminary evaluation of its eectiveness in the
context of real-world models.
To the best of our knowledge, no other work has consid-
ered the question of estimating log completeness with regard
to k-Tails specically or with regard to other dynamic spec-
ication mining algorithms.
7. CONCLUSION AND FUTURE WORK
We presented k-condence, as a novel means to estimate
the k-completeness of a log of traces, i.e., whether additional
traces may change the model that k-Tails builds for the log.
Our preliminary implementation and evaluation show that
k-condence is an eective proxy for true k-completeness.
Thus, it can be used to help engineers decide whether ad-
ditional traces are required. No other work in the area of
specication mining has addressed this question before.
We are working on a major extension and generalization
of the present work, which goes beyond the k-Tails algorithm
and denes a black-box probabilistic framework with a gen-
eral notion of log condence in the context of dynamic spec-
ication mining. We plan to apply this framework to addi-
tional dynamic specication mining algorithms, e.g., Synop-
tic [5] and mining of scenario-based triggers and eects [18].
We hope to report on this framework in a future paper.
8. ACKNOWLEDGMENTS
Hila Cohen was supported in part by the Israel Science
Foundation (grant No. 476/11).
9. REFERENCES
[1] Supporting materials on log completeness.
http://smlab.cs.tau.ac.il/logcompleteness.
[2] Wil M. P. van der Aalst. The Application of Petri
Nets to Workow Management. Journal of Circuits,
Systems, and Computers , 8(1), 1998.
[3] Wil M. P. van der Aalst, T. Weijters, and
L. Maruster. Workow mining: Discovering process
models from event logs. IEEE Trans. Knowl. Data
Eng., 16(9), 2004.
[4] M. Acharya, T. Xie, J. Pei, and J. Xu. Mining API
patterns as partial orders from source code: from
usage scenarios to specications. In ESEC/SIGSOFT
FSE, 2007.
[5] I. Beschastnikh, Y. Brun, S. Schneider, M. Sloan, and
M. D. Ernst. Leveraging existing instrumentation to
automatically infer invariant-constrained models. In
SIGSOFT FSE , 2011.
[6] A. W. Biermann and J. A. Feldman. On the synthesis
of nite-state machines from samples of their
behavior. IEEE Trans. Comput. , 21(6), June 1972.
[7] J. E. Cook and A. L. Wolf. Discovering models of
software processes from event-based data. ACM
Trans. Softw. Eng. Methodol. , 7(3), 1998.
[8] V. Dallmeier, N. Knopp, C. Mallon, G. Fraser,
S. Hack, and A. Zeller. Automatically generating testcases for specication mining. IEEE Trans. Software
Eng., 38(2), 2012.
[9] F. C. de Sousa, N. C. Mendon ca, S. Uchitel, and
J. Kramer. Detecting implied scenarios from execution
traces. In WCRE, 2007.
[10] M. El-Ramly, E. Stroulia, and P. G. Sorenson. From
run-time behavior to usage scenarios: an
interaction-pattern mining approach. In KDD, 2002.
[11] M. Ernst, J. Cockrell, W. Griswold, and D. Notkin.
Dynamically discovering likely program invariants to
support program evolution. TSE, 27(2), 2001.
[12] D. Fahland, D. Lo, and S. Maoz. Mining
branching-time scenarios. In ASE, 2013.
[13] M. Gabel and Z. Su. Online inference and enforcement
of temporal properties. In ICSE , 2010.
[14] S. Kumar, S.-C. Khoo, A. Roychoudhury, and D. Lo.
Mining message sequence graphs. In ICSE, 2011.
[15] C. Lee, F. Chen, and G. Rosu. Mining parametric
specications. In ICSE , 2011.
[16] D. Lo and S.-C. Khoo. Quark: Empirical assessment
of automaton-based specication miners. In WCRE,
2006.
[17] D. Lo and S.-C. Khoo. SMArTIC: towards building an
accurate, robust and scalable specication miner. In
SIGSOFT FSE , 2006.
[18] D. Lo and S. Maoz. Mining scenario-based triggers
and eects. In ASE, 2008.
[19] D. Lo and S. Maoz. Scenario-based and value-based
specication mining: better together. In ASE, 2010.
[20] D. Lo, S. Maoz, and S.-C. Khoo. Mining modal
scenario-based specications from execution traces of
reactive systems. In ASE, 2007.
[21] D. Lo, L. Mariani, and M. Santoro. Learning extended
FSA from software: An empirical assessment. Journal
of Systems and Software , 85(9), 2012.
[22] D. Lorenzoli, L. Mariani, and M. Pezz e. Automatic
generation of software behavioral models. In ICSE,
2008.
[23] L. Mariani, S. Papagiannakis, and M. Pezz e.
Compatibility and regression testing of
COTS-component-based software. In ICSE, 2007.
[24] Kees M. van Hee, Z. Liu, and N. Sidorova. Is my event
log complete? - a probabilistic approach to process
mining. In RCIS, 2011.
[25] M. Pradel, P. Bichsel, and T. R. Gross. A framework
for the evaluation of specication miners based on
nite state machines. In ICSM, 2010.
[26] M. Pradel and T. R. Gross. Automatic generation of
object usage specications from large method traces.
InASE, 2009.
[27] J. Quante and R. Koschke. Dynamic protocol
recovery. In WCRE, 2007.
[28] S. P. Reiss and M. Renieris. Encoding program
executions. In ICSE, 2001.
[29] N. Walkinshaw and K. Bogdanov. Inferring nite-state
models with temporal constraints. In ASE, 2008.
[30] J. Yang, D. Evans, D. Bhardwaj, T. Bhat, and
M. Das. Perracotta: mining temporal API rules from
imperfect traces. In ICSE, 2006.
610