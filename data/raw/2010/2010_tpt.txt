Termination Proofs from Tests
Aditya V. Nori
Microsoft Research India
adityan@microsoft.comRahul Sharma∗
Stanford University
sharmar@stanford.com
ABSTRACT
We show how a test suite for a sequential program can be
proﬁtably used to construct a termination proof. In partic-
ular, we describe an algorithm TpT for proving termination
of a program based on information derived from testing it.
TpT iteratively calls two phases: (a) an infer phase, and
(b) a validate phase. In the infer phase, machine learning, in
particular, linear regression is used to eﬃciently compute a
candidate loop bound for every loop in the program. These
loop bounds are veriﬁed for correctness by an oﬀ-the-shelf
checker. If a loop bound is invalid, then the safety checker
provides a test or a counterexample that is used to generate
more data which is subsequently used by the next infer phase
to compute better estimates for loop bounds. On the other
hand, if all loop bounds are valid, then we have a proof
of termination. We also describe a simple extension to our
approach that allows us to infer polynomial loop bounds
automatically.
We have evaluated TpT on two benchmark sets, micro-
benchmarks obtained from recent literature on program ter-
mination, and Windows device drivers. Our results are
promising – on the micro-benchmarks, we show that TpT
is able to prove termination on 15% more benchmarks than
any previously known technique, and our evaluation on Win-
dows device drivers demonstrates TpT’s ability to analyze
and scale to real world applications.
Categories and Subject Descriptors
D.2.4 [ Software/Program Veriﬁcation ]: Statistical meth-
ods
General Terms
Testing, Veriﬁcation
∗This author performed the work reported here during a
summer internship at Microsoft Research India.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ESEC/FSE ’13, August 18-26, 2013, Saint Petersburg, Russia
Copyright 13 ACM 978-1-4503-2237-9/13/08 ...$15.00.Keywords
Machine learning; Software model checking; Termination
1. INTRODUCTION
Proving termination of sequential programs is a hard and
important problem whose solutions can broadly improve soft-
ware reliability and programmer productivity. There is a
huge body of work that is based on a number of inter-
esting techniques such as abstract interpretation [4, 7, 39],
bounds analysis [17, 18], ranking functions [5, 6, 10], recur-
rence sets [20,22] and transition invariants [25,32]. In spite
of these techniques, much progress has to be made to design
an eﬃcient and scalable technique for program termination.
In the world of safety checking, there are a number of
eﬃcient and scalable techniques that use tests for proving
safety properties of programs [3,13,16,21,28,35–37]. This is
advantageous as most programs have test suites that ensure
quality, and more importantly, these tests are a rich source of
reachability information (in other words, information from
tests gives reachability information for free without the need
for any static analysis).
Unfortunately, there are no analogous techniques for prov-
ing termination or liveness properties of programs. We ask
the following question: Can a test suite for a program be used
proﬁtably for constructing termination proofs? In this pa-
per, we answer this question in the aﬃrmative, and present
an algorithm TpT that uses information from tests to con-
struct a sound proof of termination of a program.
TpT is based on the insight that information from tests
can be used to eﬃciently learn loop bounds for every loop in
a program W. If every loop in Whas a sound loop bound,
then this is a proof of termination of W. The algorithm
iteratively calls two phases: (a) an infer phase, and (b)
a validate phase. In the infer phase, machine learning, in
particular, linear regression is used to eﬃciently compute a
candidate loop bound for every loop in the program. These
loop bounds are veriﬁed for correctness by an oﬀ-the-shelf
checker. If a loop bound is invalid, then the safety checker
provides a test or a counterexample that is used to gener-
ate more data which is subsequently used by the next infer
phase. On the other hand, if all loop bounds are valid, then
we have a proof of termination. This separation of the in-
fer phase from the validate phase allows our approach to
handle more expressive syntax than previous approaches for
termination of numerical programs. Being driven by tests
also allows us to easily extend TpT to infer polynomial loop
bounds automatically (see Section 5). TpT is easy to im-
plement. In fact, the infer phase of TpT is implemented by1g c d ( int x,int y)
2{
3a s s u m e ( x >0& &y >0) ;
4 while (x != y) {
5 if(x>y) x = x −y;
6 if(y>x) y = y −x;
7 }
8 return x;
9}
Figure 1: Computing GCD.
1g c d ( int x,int y)
2{
3a s s u m e ( x >0& &y >0) ;
4 // instrumented code
5a = x ; b = y ; c = 0 ;
6 while (x != y) {
7 // instrumented code
8c = c + 1 ;
9w r i t e L o g ( a , b , c , x , y ) ;
10 if(x>y) x = x −y;
11 if(y>x) y = y −x;
12 }
13 return x;
14}
Figure 2: Instrumented GCD program.
just one line of MATLAB code, while the validate phase is
an oﬀ-the-shelf safety checker.
The contributions of this paper are as follows:
•We describe TpT, a novel termination prover for se-
quential programs that is based on information derived
from tests. This information is analyzed to automati-
cally learn loop bounds.
•We present an empirical evaluation of TpT on various
benchmarks from recent papers on program termina-
tion and our results are encouraging. On these bench-
marks, TpT is able to prove termination on 15% more
benchmarks than any previously known technique. We
also evaluate TpT on Windows device drivers and the
results are positive. There are two drivers in this set
of drivers for which TpT is able to successfully prove
termination, whereas the Terminator tool [9] fails.
This demonstrates TpT’s ability to analyze and scale
to real world applications.
The rest of the paper is organized as follows: Section 2
informally illustrates the TpT algorithm with the help of a
motivating example. In Section 3 we review background ma-
terial necessary for this paper. Section 4 formally describes
theTpT algorithm, and Section 5 extends the algorithm
to the non-linear case. Section 6 describes our experimen-
tal evaluation. In Section 7, we discuss related work, and
ﬁnally, Section 8 concludes the paper.
2. OVERVIEW OF THE TECHNIQUE
LetL=while BdoSbe a loop deﬁned over the variables
x1,...,x n. Our goal is to ﬁnd an expression τ(x1,...,x n)
deﬁned over the initial values of the variables x1,...,x nsuch
that the maximum number of iterations of Lover all possible1g c d ( int x,int y)
2{
3a s s u m e ( x >0& &y >0) ;
4a = x ; b = y ; c = 0 ;
5 while (x != y) {
6 // annotation
7f r e e invariant(c <=a + b −x−y);
8 // annotation
9a s s e r t ( c <=a + b −2) ;
10 c = c +1;
11 if(x>y) x = x −y;
12 if(y>x) y = y −x;
13 }
14 return x;
15}
Figure 3: Annotated GCD program.
values of x1,...,x nis bounded above by τ(x1,...,x n). It
is easy to see that such a bound τ(x1,...,x n) will imply
termination of L. Therefore, for an arbitrary program, a
termination proof is a loop bound τifor every loop Liin the
program.
We will illustrate our technique on the gcdprogram shown
in Figure 1. We also assume the availability of a test suite Γ
for this program. This program has a loop (lines 4 – 7) which
performs the greatest common divisor (GCD) computation.
Our objective is to automatically compute an upper bound
on the number of iterations of the loop (over all inputs x,yto
the program) by testing the program. To collect data from
these tests, we instrument the program – the instrumented
GCD program is shown in Figure 2. The ghost variables
variables aandb(in line 5) record the initial values of the
variables xandyrespectively and are not modiﬁed by the
loop. The variable cis a loop counter which is initialized to
zero in line 5.
The loop counter cis incremented in every iteration of the
loop (line 8). The values of the variables a,b,c,xandyare
recorded at the beginning of the loop in line 9 via the call to
the function writeLog . The function writeLog records the
program state (speciﬁcally, the values of variables that are
its arguments) to a log ﬁle. We want to bound the number of
loop iterations cby a linear expression τ(a, b) over the inputs
aandb. In particular, we want to compute w1,w2,w3∈R
such that τ(a, b)=w1a+w2b+w3, and c≤τ(a, b).
Next, TpT executes the instrumented program over test
inputs, and accumulates the resulting data via calls to the
logging function writeLog . Using the log ﬁle, TpT con-
structs two data matrices AandCdeﬁned as follows: In
addition to the all-ones column (the ﬁrst column), the ma-
trixAcontains the test input values to the program in each
row (one row for every program state generated before exe-
cuting the loop body) and the matrix Ccontains the corre-
sponding value of the loop counter c. Assume that we test
the program on inputs ( x, y)={(1,2),(2,1),(1,3),(3,1)}.
As a result, we have:A=1ab
112
121
113
113
131
131C=c
1
1
1
2
1
2(1)
The rows generated by each input have been partitioned.
Each input generates as many rows as the number of itera-
tions. The problem of learning an upper bound on the loop
counter ccan be looked upon as a linear regression problem
in machine learning [27]. In linear regression, we are given
a set of input-output pairs as input, and the goal is to learn
a function which maps the inputs to the outputs. In our
setting, the inputs are the rows of A, the outputs are the
corresponding rows of C, and we want to learn a function B
that maps the rows of Ato the rows of C.
For our purpose, we use a variant of linear regression to
learn a bound on c. Conventional linear regression aims
to ﬁnd w=(w1,w2,w3) such that c≈w1a+w2b+w3
(cis a linear function of the parameters wwhich is why
the regression is called “linear”). This can be obtained by
solving the following optimization problem:
min￿
i(w1ai+w2bi+w3−ci)2(2)
where (1 ,ai,bi) is the ithrow of A, and ciis the ithrow of
C. Since we want an upper bound on c, we add additional
constraints w1ai+w2bi+w3≥ci, for all i– this results in
the following quadratic programming problem [29]:
min￿
i(w1ai+w2bi+w3−ci)2
s.t. Aw ≥C
For the matrices Aand Cin Equation 1, ( w1,w2,w3)=
(1,1,−2) is a solution to this optimization problem. There-
foreTpT returns τ(a, b)=a+b−2 as the candidate loop
bound.
Next, in the validate phase, we check whether τ(a, b) is in-
deed a valid loop bound. Since the tests represent an under-
approximation of program behaviors, it is possible that there
is a yet unseen test that executes the loop for more than
τ(a, b) iterations. To handle this, we annotate the program
with an assertion encoding the soundness of this bound and
check it using an oﬀ-the-shelf safety checker. For our ex-
ample, the annotated program is shown in Figure 3. If the
safety checker is able to verify the assertion of line 9, then
we have veriﬁed that the program terminates.
For proving soundness of the loop bound, a safety checker
will also need a loop invariant. Unfortunately, these invari-
ants can be quite hard to infer. For our example, the loop
invariant is a bound on the loop counter cthat is a linear ex-
pression over the values of the program variables a,b,xand
y. Once again, this is a linear regression problem. Using the
log ﬁle generated by the instrumented program in Figure 2
on inputs ( x, y)={(1,2),(2,1),(1,3),(3,1)}, we constructthe following matrices:
ˆA=1abxy
11212
12121
11313
11312
13131
13121ˆC=c
1
1
1
2
1
2(3)
Matrix ˆAis the same as Ain Equation 1, except that it
also contains values for the program variables xandy.The
problem of computing a loop invariant translates to the fol-
lowing linear regression problem: ﬁnd w=(w1,w2,w3,w4,w5)
such that ι(a, b, x, y )=w1a+w2b+w3x+w4y+w5, and
c≤ι(a, b, x, y ). Thus we want to solve the following opti-
mization problem:
min￿
i(w1ai+w2bi+w3xi+w4yi−ci)2
s.t. ˆAw≥ˆC
This optimization problem is also a quadratic program which
can be eﬃciently solved using an oﬀ-the-shelf solver. For
our example, we obtain ι(a, b, x, y )= a+b−x−y, and
thus c≤a+b−x−yis the desired loop invariant. Once
again, since this invariant has been computed from an under-
approximation of program behaviors, it is just a candidate
invariant and thus has to be checked for validity. Therefore,
this inferred invariant is marked as a “free invariant” [2] in
line 7 of Figure 3. A free invariant is just a candidate in-
variant that can potentially be useful to the safety checker.
If the free invariant is invalid, then the safety checker can
simply ignore it. On the other hand, if the safety checker is
able to prove that the free invariant is an invariant, then it
can use this candidate invariant to prove the assertion.
Indeed, in our experiments (see Section 6), on all the
benchmarks for which TpT is able to prove termination, the
free invariants were actual invariants. However, it is often
the case that these candidate invariants had to be strength-
ened by our safety checker to make them inductive. For the
program in Figure 3, we observe that our safety checker uses
the free invariant to obtain the following inductive invariant:
c≤a+b−x−y∧x>0∧y>0( 4 )
This invariant is suﬃcient to prove the assertion of Figure 3,
and therefore, TpT is able to prove the termination of the
gcdprogram in Figure 1.
3. PRELIMINARIES
W.l.o.g., we consider while programs Wwhich are deﬁned
by the following grammar:
W ::= x:=Ea
|W;W
|ifEbthen Welse Wfi
|while EbdoW
where xis a variable, Eais an arithmetic expression, and
Ebis a boolean expression.
3.1 Algebra
Amonomial α:x1×...×xn→Ris an expression of
the form α(x1,...,x n)= xk1
1xk2
2...xknn. The degree of amonomial xk1
1xk2
2...xknnis deﬁned as￿n
i=1ki.Apolynomial
f:x1×...×xn→Ris a weighted sum of monomials:
f(x1,...,x n)=￿
kwkxk1
1xk2
2...xkn
n=￿
kwkαk(5)
where αk=xk1
1xk2
2...xknnis a monomial. The degree of
a polynomial is the maximum degree over its constituent
monomials:
degree (f)def=max k{degree (αk)|wk￿=0} (6)
LetA∈Rm×nbe a matrix deﬁned over the set of real
numbers Rwith mrows and ncolumns. Let x∈Rndenote a
vector . The vector xcan also be represented as a row matrix
xT∈R1×n, where Tis the matrix transpose operator. In
general, the transpose of a matrix A, denoted ATis obtained
by interchanging the rows and columns of A. In other words,
∀A∈Rm×n,(AT)ij=Aji.
Given two matrices A∈Rm×pandB∈Rp×n, their prod-
uctABis a matrix C∈Rm×nwith each entry Cijdeﬁned
as follows:
Cij=n￿
k=1AikBkj (7)
The inner product ￿x, y￿of two vectors xand yis the
product of the matrices corresponding to xTandywhich is
deﬁned as:
xTy=n￿
i=1xiyi (8)
3.2 Linear Regression and Quadratic Program-
ming
Given a matrix X∈Rm×nand a column vector Y∈Rm,
linear regression is the problem of learning a function fsuch
that f(Xi)=Yi, where Xiis the ithrow of XandYiis the
ithrow of Y. Speciﬁcally, the function fis a “linear” ex-
pression over model parameters θ∈Rnsuch that for each
i,f(Xi)= ￿θ,X i￿, and Yi=f(Xi). In general, such a
function fmight not exist, in which case linear regression
aims to compute a function fsuch that f(Xi) best approx-
imates Yi. This approximation is formally characterized by
the following optimization problem:
min￿
i(XT
iθ−Yi)2(9)
In other words, we would like to minimize a quadratic func-
tion of θ. From an implementation point of view (see Sec-
tion 6), it is convenient to write Equation 9 in matrix nota-
tion as follows:
min1
2θTXTXθ−θT(XTY)( 1 0 )
Consider the data points (represented by +) shown in Fig-
ure 4. These data points correspond to rows of the ma-
trixXin Equation 10. Linear regression attempts to ﬁnd
a “best-ﬁt” line (as deﬁned by the optimization problem in
Equation 10) for these points – speciﬁcally, linear regression
ﬁnds θ0andθ1such that y=θ0+θ1xis the best linear ap-
proximation of f. As we will see in Section 4.1, for proving
termination, it is useful to further constrain the parameters
θby inequality constraints Xθ≥Yas follows:
min1
2θTXTXθ−θT(XTY)
s.t. Xθ ≥Y(11)✲ ✛✻
❄xy
++
++
✟✟✟✟✟✟✟✟✟
Figure 4: Finding the best-ﬁt line using linear re-
gression.
✲ ✛✻
❄xy
++
++
✟✟✟✟✟✟✟✟✟
Figure 5: A solution to the quadratic program in
Equation 11.
Equation 11 is an instance of quadratic programming [29]
which is deﬁned as follows:
min1
2θTHθ+θTf
s.t. Mθ ≤N(12)
By replacing HwthXTX,fwith −XTY,Mwith −X,
andNwith −Yin Equation 12, we obtain the constrained
linear regression problem in Equation 11. For the data in
Figure 4, solving the quadratic program in Equation 11 re-
sults in the line shown in Figure 5. An interesting feature of
this solution line is that f(x)≥yfor all data points ( x, y),
which is precisely the property that we require for estimating
loop bounds.
4. ALGORITHM
The TpT algorithm is described in Figure 6. The algo-
rithm takes a while program Was input together with a test
suite Γ for W. Assume that the program Whasl(possibly
nested) loops L1,...,L l. For every loop Lk,1≤k≤l,TpT
returns a loop bound τk. Note that a valid loop bound for
each loop in Wdeﬁnes a proof of termination for W.A s
previously illustrated by Figure 2, in line 1, the call to the
function Instrument datainstruments the program so that in-
formation from testing the program Wis recorded to a log
ﬁle. The program Wis instrumented as follows:
Consider a loop Lfrom {Lk}l
k=1.L e t x1,...,x nbe the
variables in the scope of the loop L.F o re a c h xi,1≤i≤n,
create a ghost variable gi, and let cbe a variable representing
a loop counter. Every ghost variable girecords the value of
its corresponding variable xibefore the program enters the
loop L. The loop counter cis also initialized to zero before
the program enters L. At the beginning of each iteration
of the loop L, the values of all the variables in the scope
ofL(including the newly introduced ghost variables and
loop counter) are written to a log. The value of cis also
incremented before writing to the log ensuring that it is
incremented in every iteration of the loop. Formally, if L≡TpT(W: While-Program, Γ: Test-Suite)
Returns : A loop bound τforW.
1:WI:=Instrument data(W)
2:logﬁle :=Test(WI,Γ)
3:∆: = ∅
4:repeat
5: logﬁle :=logﬁle ::Test(WI,∆)
6: {(Ak,Ck)}l
k=1:=DataMatrix LoopBound (logﬁle )
7: {(ˆAk,ˆCk)}l
k=1:=DataMatrix FreeInvariant (logﬁle )
8: {τk}l
k=1:=QP({(Ak,Ck)}l
i=k)
9: {ιk}l
k=1:=QP({ˆAk,ˆCk}l
k=1)
10: forτ∈{τk}l
k=1do
11: ifFail(τ)then
12: τ:=RoundOrPartition (τ,{(Ak,Ck)}l
k=1)
13: end if
14: end for
15: Wcheck :=Instrument check(W,{τk}l
k=1,{ιk}l
k=1)
16: (done, ∆) := Check (Wcheck)
17:until done
18:return {τi}l
i=1
Figure 6: The TpT algorithm for a while program.
while EbdoSod, then the instrumented loop LIis deﬁned
as follows:
gi:=xi,1≤i≤n;
c:= 0;
while Ebdo
c:=c+1 ;
writeLog (g1,...,g n,x1,...,x n,c);
S
od(13)
Therefore, the instrumented program WIis the program W
with all loops instrumented as described in Equation 13.
The call to writeLog returns a sequence of concrete states.
In this case, a concrete state maps all the variables passed
as arguments to writeLog to their corresponding values.
The program WIis ﬁrst executed over all tests in the test
suite Γ (line 2) and the results are stored in logﬁle . IfTest
executes WI, on some test, for more iterations than a user
speciﬁed time-out then the loop is classiﬁed as “potentially
non-terminating”and the proof fails. Lines 4–18 perform the
main computation of the algorithm which primarily consists
of two phases (analogous to the abstraction and reﬁnement
phases of CEGAR based model checking tools [8]):
1.Infer phase (lines 5–14): this phase processes logﬁle to
compute the data matrices AiandCifor every loop
Li, using which a candidate loop bound τiis estimated
(line 6), as well as the data matrices ˆAiand ˆCiusing
which the free invariant ιiis estimated (line 7).
2.Validate phase (line 15–16): this phase uses an oﬀ-
the-shelf safety checker for checking the validity of the
candidate loop bounds computed in the infer phase.
The function DataMatrix LoopBound (line 6) constructs from
logﬁle two matrices Akand Ckfor every loop Lkin the
program W.L e t σ(Lk) denote the total number of times
the entry of the loop Lkis executed over all tests in the test
suite Γ. Every row in the matrix Akrepresents a concretestate for all the ghost variables in Lk. Therefore, the ( i, j)th
entry of Akis the value of the jthghost variable obtained
when the entry of Lkis executed the ithtime by tests from
Γ. The ithentry of the matrix Ckis the corresponding value
of the loop counter for the same execution. Therefore, Ak
has dimension σ(Lk) by the number of ghost variables for
Lk, and Ckhas dimension σ(Lk) by one.
The function DataMatrix FreeInvariant (line 7) constructs from
logﬁle two matrices ˆAkand ˆCkfor every loop Lkin the pro-
gram W. Every row in the matrix ˆAkrepresents a concrete
state for all variables (including the ghost variables) in Lk.
Therefore, the ( i, j)thentry of ˆAkis the value of the jth
variable obtained when the entry of Lkis executed the ith
time over all tests from Γ. The ithentry of the matrix ˆCk
is the corresponding value of the loop counter for the same
test. Therefore, ˆAkhas dimension σ(Lk) by the number of
variables for Lk, and ˆCkhas dimension σ(Lk) by one. To
summarize, Akis a sub-matrix of ˆAkand ˆCk≡Ck.
Next, in line 8, the call to the function QPsolves lquadratic
programming instances, one for each loop Lk,1≤k≤l
in the program W. This is done by using an oﬀ-the-shelf
quadratic programming solver for each instance, thereby
computing a candidate loop bound τkfor each loop Lk.A s
we will see in Section 4.1, the candidate loop bound τkcan
be eﬃciently computed from AkandCk. If the loop bound
computation fails (lines 11 – 13), then appropriate correc-
tive measures are taken (details in Section 4.3). The loop
bound computation is said to have failed when the bound
obtained does not have integral coeﬃcients. The computa-
tion in line 9 is similar to that in line 8, but results in the
calculation of the free invariant for every loop. The candi-
date loop bounds {τk}l
k=1together with the free invariants
{ιk}l
k=1are given to the checking procedure Check in line 16.
The procedure Check uses an oﬀ-the-shelf safety checker to
check whether the instrumented program Wcheck is correct.
IfL≡while EbdoSodis a loop in Wwith candidate loop
bound τ, free invariant ι, and variables in scope x1,...,x n,
then the instrumented loop Lcheck is deﬁned as follows:
gi:=xi,1≤i≤n;
c:= 0;
while Bdo
free invariant (c≤ι)
assert (c≤τ);
c:=c+1 ;
S
od(14)
The result Wcheck of the function call Instrument check in line
15 is the program Wwith all loops instrumented as de-
scribed in Equation 14.
If the program Wcheck is safe, then τkfor every loop Lkis
an upper bound, and TpT terminates by returning a termi-
nation proof {τk}l
k=1. Otherwise, Check returns a set ∆ of
counterexamples or tests that explain why some candidate
loops bounds are not valid – the computation in lines 5 –
16 is repeated with these new tests ∆ (line 5), and the pro-
cess continues until we have found a sound upper bound for
every loop in W.
To summarize, the infer and validate phases of TpT oper-
ate iteratively, and in each iteration if the actual bound for
every loop cannot be derived, then the algorithm automati-
cally ﬁgures out the reason for this, and appropriate action
in the form of corrective measures (Section 4.3) or generat-ing more tests (this corresponds to the case where the data
generated is insuﬃcient) is taken.
4.1 The Infer Phase
LetLbe a loop, and let AandCbe its corresponding
data matrices for the loop bound calculation (computed in
line 6 of Figure 6). Let the data matrix A=[a1,...,a m]T,
and the data matrix C=[c1,...,c m]T, then any valid loop
bound τ≡￿w,g￿over ghost variables g=[g1,...g n], for L,
with w∈Rn, is such that:
Aw≥C (15)
We would also like our candidate loop bound τforLto be
predictive. In other words, if we run the program on more
test inputs, then the bound should still be satisﬁed. There-
fore, we employ machine learning techniques for generating
a predictive bound. We describe these techniques next.
Linear regression ﬁnds a wsuch that Aw≈C. It has been
successfully used to derive predictive answers in a variety
of applications. More formally, linear regression ﬁnds a w
which minimizes the following quantity:
min￿
1≤i≤m(aT
iw−ci)2(16)
In our setting, using a wcomputed by linear regression
naively has the following problem: There is no guarantee
that wis an upper bound. That is, it is possible that for
some rows aT
iofA,aT
iw<c i. This motivates the need
for a constrained linear regression, that is, minimize the ex-
pression in Equation 16 subject to the constraints Aw≥C.
In other words, we are interested in solving the following
quadratic program:
min1
2wTATAw−wTATC
s.t. Aw ≥C(17)
Upon solving the quadratic program, we are able to compute
an upper bound that is consistent with the current set of
concrete program states. The techniques described above
are also useful for eﬃciently generating a free invariant for
a loop.
4.2 The Validate Phase
After a candidate bound for every loop in the program
has been obtained, TpT asks an oﬀ-the-shelf safety checker
to validate these bounds. To reduce the burden of invariant
inference on the safety checker, TpT also provides it with
free invariants which are computed by the infer phase. It is
important to note that the free invariants only serve as hints
to the safety checker. If a free invariant is invalid, then the
safety checker ignores it. In Section 6, we show empirical
data that establishes the usefulness of free invariants ob-
tained via linear regression of test data. If a loop bound is
invalid, then the safety checker returns a counterexample or
a test that demonstrates the violation of the assertion. This
set of tests (denoted by ∆ in Figure 6) is used to generate
more concrete states and this ensures better loop bounds in
the next iteration of TpT.
4.3 Corrective Measures
There can be several reasons for the failure of bound gen-
eration (line 11 in Figure 6). The ﬁrst reason is that the
bound obtained for a loop cannot be expressed as a linearexpression with integer coeﬃcients. We describe a simple
rounding strategy to handle this issue. If a variable has
value between N−0.1 and N+0.1 (where Nis an integer),
then we round it to N. If a variable still does not have an
integral coeﬃcient, then we check if it is constrained by the
program to be positive or negative. If yes, then we round it
“soundly”: ceiling for positive input variables and ﬂoor for
negative input variables. This is sound because increasing
the coeﬃcient of positive variables can only make the bound
looser, and similarly for the negative variables. Hence the
rounded bounds can be imprecise, but they are consistent
with the data and are suﬃcient to prove termination. In
our experiments, out of all the benchmarks TpT succeeds
on, rounding was performed only in four cases. For the rest,
the output obtained by solving the quadratic program of
Equation 17 was already integral.
If rounding fails, then the reason might be that the loop
does not have a single bound. The loop might show diﬀerent
behaviors for diﬀerent inputs, and hence a single bound is
perhaps not possible for this mix of two or more behaviors.
Therefore, there is a need to partition the input values to
the loop such that for each region in the partition, the tests
in that region have the same bound. Once a correct parti-
tioning has been obtained, linear regression can be used to
obtain the bounds for each individual partition. We consider
two simple schemes for partitioning the data:
1.Partition according to the predicates syntactically oc-
curring in the program. For instance, if the guard for
al o o pi s p∨q, then we can partition the input values
based on whether they satisfy the predicate p,q,o r
both. [10,11].
2.Partition according to the path executed in running
the test. There are existing techniques that are based
on control ﬂow reﬁnement [17,34] to do this systemat-
ically. In [34], if there is an “if” condition in the loop
that shows “phases” (it has the property that once the
condition becomes false, it remains false until the pro-
gram exits the loop) then the loop is rewritten into a
sequence of two loops: the ﬁrst containing the “then”
branch and the second containing the “else” branch.
Using information from tests, it is easy to detect if a
condition is showing phases.
If the above heuristics fail, that is, either there is no obvious
partitioning by predicates, or branches showing phases, then
TpT fails. If even after partitioning, we obtain coeﬃcients
for which the above rounding process fails, then we declare
failure of TpT. These heuristics for partitioning are basi-
cally trying to handle disjunctive bounds. How to split the
proof burdens for termination is a well known open prob-
lem [4]. Our technique is good at obtaining linear or non-
linear bounds when they exist. Handling disjunctive bounds
systematically is left for future work. The failure to infer the
correct partition is the primary reason why this technique
can fail. In our benchmarks, for two benchmarks we per-
formed predicate based splitting, and for one benchmark we
needed path based splitting. We illustrate partitioning by
predicates with the help of the example program shown in
Figure 7. We can partition the tests into three regions, each
deﬁned by the predicates a<M ∧b<N ,a<M ∧b≥N,
a≥M∧b<N . By applying the infer phase to the tests1a = i ; b = j ; c = 0 ;
2 while (i<M|| j<N){
3i = i + 1 ;
4j = j + 1 ;
5c = c + 1 ;
6 }
Figure 7: Program that requires partitioning.
1u = x ; v = y ; w = z ; c = 0 ;
2 while (x>=y ) {
3c = c + 1 ;
4 if(z>0){
5z = z −1;
6x = x + z ;
7 }else
8y = y + 1 ;
9 }
Figure 8: Example program that requires a non-
linear loop bound.
based on each of these regions separately, we obtain:
a<M ∧b<N ⇒c≤M+N−a−b
a<M ∧b≥N⇒c≤M−a
a≥M∧b<N ⇒c≤N−b(18)
The safety checker is able to prove the disjunctive loop bound
in Equation 18. Using clustering algorithms [27] in machine
learning for inferring disjunctive loop bounds systematically
is left for future work.
5. NON-LINEAR BOUNDS
Since the TpT algorithm is driven by tests, it is able to
seamlessly handle non-linearities. We illustrate this using
the example program in Figure 8.
Letdbe the degree of the polynomial τrepresenting the
loop bound. Assume that dis bounded above by 2 for this
example. As before, just as in the linear case, we create the
data matrices AandC:
•The matrix Ais such that the ithrow of Acorresponds
to the ithconcrete program state. Each column of A
corresponds to a monomial of degree at most two over
the variables u,vandw(where u,vandware ghost
variables recording the initial values of the program
variables x,yandzrespectively). Therefore, Ahas
10 columns, one for each of the monomials 1, u,v,
w,uu,vv,ww,uv,uwandvw. For instance, when
the program is tested on the input x=y=z=1 ,i t
generates a row of Awith ten ones.
•Theithrow of the matrix Cis the number of iterations
for the ithexecution of Lk.
By way of random testing, where the inputs x,yandzto
the program are in the range [ −4,4], and only test inputs
that execute the loop at least once are selected, we obtain
288 tests (essentially, this is a form of rejection sampling [33]
to select tests). Thus Ais a 288 ×10 matrix, and Cis a
288×1 matrix. Solving the quadratic program as deﬁned
by Equation 17, we obtain the solution:
wT=[ 1.9,1,−1,0.95,0,0,0.24,0,0,0] (19)This gives us a loop bound τ(u, w)=2 + u−v+w+w2=⇒
c≤2+u−v+w+w2after applying rounding (see Section 4.3
for a description of rounding).
Next, using the data from the logﬁle, we compute the
free invariant c≤y+w−v−z(see Section 4). This free
invariant together with the assertion encoding the candidate
loop bound is fed to a safety checker, which is able to prove
the bound and therefore termination of this program.
6. EXPERIMENTAL EVALUATION
We have evaluated the TpT algorithm on various bench-
marks for termination from [4, 7] as well as some Windows
device drivers. All experiments were performed on a 2.67GHz
Intel Xeon processor system with 8 GB RAM running Win-
dows 7 and MATLAB R2012a. The infer phase of TpT,i n
particular, Equation 11 is implemented using just one line
of MATLAB code:
quadprog (AT∗A,−AT∗C,−A,−C)
where A,Care the data matrices for a loop.
Micro-Benchmarks.
These benchmarks are shown in the ﬁrst column of Ta-
ble 1, and are categorized as follows:
1.Benchmarks preﬁxed by Oct are from the Octanal
distribution. These include programs such as heapsort
and bubblesort.
2.Benchmarks preﬁxed by Driver are code fragments
from Windows device drivers. These benchmarks have
been hand-translated to remove pointer aliasing.
3.Benchmarks preﬁxed by Poly are from the PolyRank
distribution. These benchmarks are tricky programs,
such as McCarthy’s 91 function, with non-trivial ter-
mination arguments.
Device Drivers.
We also evaluated TpT on Windows Device Drivers to
demonstrate its ability to analyze and scale to real world
applications. These drivers are part of the SDV-RP toolkit
(available at http://research.microsoft.com/slam ). The
statistics for these drivers are shown in columns 2 and 3 of
Table 3. The column LOCis the number of lines of code, and
the column #Loops is the number of loops that are reachable
from the harness to these drivers. We performed a simple
static analysis to determine this loop reachability informa-
tion.
Evaluation.
The second column of Table 1 shows the total time spent
byTpT in its infer phase. The third column shows the total
time taken by the validate phase of TpT. The fourth col-
umn shows the total time (in seconds) taken by TpT.W e
observe that a signiﬁcant fraction of the total analysis time
is spent in the validate phase. For the micro-benchmarks,
the data or tests were generated naively; each input vari-
able was allowed to take values from −NtoN, where N
was between 5 and 20. Therefore, if a program has two
input variables, we generated O(N2) tests. If the bench-
mark program had nondeterministic branches, then we ranName Infer time (sec) Validate time (sec) Total time (sec) Result
Oct1 0.004 0.98 0.98 ￿
Oct2 0.007 1.00 1.01 ￿
Oct3 0.081 0.98 1.06 ￿
Oct4 0.004 0.95 0.95 ￿
Oct5 0.002 0.92 0.92 ￿
Oct6 0.002 0.95 0.95 ￿
Driver1 0.007 1.91 1.92 ￿
Driver2 0.003 2.67 2.67 ×
Driver3 0.001 2.26 2.26 ×
Driver4 0.001 2.20 2.20 ￿
Driver5 0.0003 0.94 0.94 ￿
Driver6 0.004 1.02 1.02 ￿
Driver7 0.006 1.01 1.02 ￿
Driver8 0.006 1.00 1.01 ￿
Driver9 0.001 0.94 0.94 ×
Driver10 0.18 14.69 14.87 ￿
Poly1 0.24 10.11 10.35 ￿
Poly2 0.017 0.95 0.97 ￿
Poly3 0.035 1.33 1.37 ￿
Poly4 FAIL NA 0.096 FAIL
Poly6 0.011 3.57 3.58 ￿
Poly7 FAIL NA 0.011 FAIL
Poly8 FAIL NA 0.011 FAIL
Poly9 0.019 3.36 3.38 ￿
Poly10 FAIL NA 0.00 FAIL
Poly11 0.28 1.47 1.75 ￿
Poly12 FAIL NA 0.016 FAIL
Table 1: Name is the name of the benchmark; Infer time is the time taken by the infer phase of TpT in seconds.
Validate time is the time in seconds taken by the validate phase of TpT to verify the candidate loop bounds.
The fourth column shows the total time taken by TpT. The last column indicates the result of the analysis –
whether TpT proved termination ( ￿), found a termination bug ( ×), or failed (FAIL).
Group Total TpT O[4] P[4] PR[4] T[4] LR[7] LTA [26] LF [26] CTA [26]
Oct 6 6 6 6 2 4 6 6 5 4
Driver 10 10 10 10 1 9 10 10 5 8
Poly 11 6 0 2 11 3 2 2 0 0
All 27 22 16 18 14 16 18 18 10 12
Table 2: Group is the benchmark group; the last row represents the sum of results over each of the three
groups; Total is the number of benchmarks in the corresponding group; TpT is the number of benchmarks in
each group on which TpT successfully completes its analysis; Ois an Octagon based termination analysis [4];
Pis a polyhedra based termination analysis [4]; PRis a script on top of [6]; TisTerminator [9];LRisLinear-
RankTerm [7], an abstract-interpretation over an abstract domain which represents ranking functions; LTA
is algorithmic-learning-based termination analysis [26]; LFisLoopFrog [39], a summary-based termination
analysis; CTAis a compositional termination analysis [25].
it three times for each input value: one with nondetermin-
ism replaced by true, one with nondeterminism replaced by
false, and one with nondeterminism replaced by rand ()%2.
While it is possible to generate tests more intelligently, us-
ing inputs from a very small bounding box demonstrates the
generality of our technique by not tying it to any particu-
lar test generation technique. On measuring the sensitivity
to test data, we found that at most 300 randomly selected
states, from the test data, were suﬃcient to obtain a sound
bound for all our benchmarks.
For the micro-benchmarks, we used [36] for validation:
it can handle non-linearities, consume candidate invariants,
and requires tests. Unfortunately, on veriﬁcation failure, [36]
might not produce a reachable counterexample. Static anal-
ysis tools such as Yogi [16] do ﬁnd reachable counterex-
amples but cannot handle non-linearities. For the micro-
benchmarks, we run an increasing number of naively gener-
ated tests until [36] validates the inferred bounds.
The ﬁfth column shows the results reported by TpT.A￿shows that TpT was able to prove the termination of
all loops in the benchmark program. A ×shows that TpT
found a true non-termination bug. For such programs, TpT
terminates with a suspect trace – it is important to note that
TpT does not report a certiﬁcate of non-termination. How-
ever, our technique can be combined with non-termination
provers in the spirit of [22] to derive a certiﬁcate of non-
termination.
For all the benchmarks on which the infer phase succeeds
in computing a bound, TpT is able to prove termination.
For these cases, the free invariant obtained by linear regres-
sion was an actual invariant. However, the free invariant
had to be strengthened by the validate phase to obtain an
inductive invariant.
TpT required rounding for Oct3 ,Driver10 ,Poly3 , and
Poly6 and used the simple strategy described in Section 4.3.
For the remaining benchmarks, the quadratic programming
solver gave exact integral bounds. One major reason for
why numerical techniques are not common in veriﬁcation isName LOC #Loops Infer Validate TpT
time (sec) time (sec) time (sec)
kbfiltr 0.9K 2 0.001 8.8 8.8
diskperf 2.3K 4 0.001 41.8 41.8
fakemodem 3.1K 3 0.001 2841.7 2841.7
serenum 5.3K 17 0.04 2081.3 2081.3
flpydisk 6K 24 0.04 305.4 305.4
kbdclass 6.5K 16 0.05 1822.3 1822.4
Table 3: Performance of TpT on Windows drivers.
because of the diﬃculty in obtaining integral results. In the
case of linear regression for inference of loop bounds , this
concern is dispelled empirically. Rounding is usually not
needed, and even when it is needed, it is quite simple. For
the benchmarks Driver10 andPoly1 ,TpT requires predi-
cate based partitioning, and for the benchmark Poly11 ,TpT
uses path based partitioning. It is interesting to note that
Poly1 can also be handled by path based partitioning.
TpT fails on the benchmarks Poly4 ,Poly7 ,Poly8 , and
Poly12 . On preliminary examination, it seems like these
benchmarks require more sophisticated partitioning of data.
Development of learning algorithms for identifying these par-
titions is ongoing work. For instance, Poly4 requires the
data to be partitioned according to whether an input is pos-
itive or negative. TpTfails on Poly10 as this benchmark has
many assume statements and therefore it is hard to gener-
ate data by running the program and simultaneously satisfy
all assume statements. Symbolic execution techniques are
required for generating data for such benchmarks.
In terms of performance, the time taken by TpT is com-
parable with previous work. An exact comparison with the
times reported by previous approaches is not meaningful (as
we are running on newer hardware). However, we reproduce
the number of benchmarks on which previous techniques
are successful in Table 2 from their respective papers. From
Table 2, it is important to note that TpT is able to suc-
cessfully prove 15% more benchmarks in this suite than any
previously known technique. One of the reasons for this is
that regression is able to quickly guess sound bounds and
invariants using a reasonable amount of data, as is evident
from the times taken by the infer step. Moreover, unlike
existing techniques, since the infer phase of TpT is driven
by tests, it does not get confused by program text.
Finally, the results of TpT on Windows device drivers is
reported in Table 3. We used an existing test suite that was
available for these drivers (obtained by running the Yogi
tool [3,16]). The validate phase was implemented using the
Yogi tool which is routinely used to check safety properties
of Windows device drivers. As seen from the table, TpT is
able to successfully prove termination for all these drivers.
In contrast, Terminator [9] is unable to complete on the
serenum andflpydisk device drivers (it runs out of memory
when the memory limit is set to 1.8 GB). It is also interesting
to note that the infer phase of TpT is very eﬃcient and
almost all the time taken by TpT is spent in validating the
loop bounds. We believe that the infer phase of TpT which
is driven by data from tests is almost independent of the size
or complexity of the program.
7. RELATED WORK
Our work falls into the category of using machine learning
for proving program properties [30]. There is a large body
of work on termination and bounds analysis. We draw acomparison with techniques that are most closely related to
TpT.
Regression has also been used to determine the execution
time of programs [23], for empirical computational com-
plexity [14], and proﬁling [40]. These approaches have no
soundness guarantees. We have shown that regression can
be used to not only obtain sound bounds, suﬃcient for prov-
ing termination, but also for discovering invariants required
for proving the bounds. In contrast to these approaches,
we use a constrained variant of regression that is eﬃciently
solvable by quadratic programming.
There is a lot of work that addresses the problem of mining
useful information from tests [12, 24]. Deriving invariants
from tests for the purpose of proving safety properties has
been pioneered by the Daikon approach [13]. In contrast,
TpT is a novel testing based approach for proving program
termination. In safety checking, a candidate invariant is
refuted by a counter-example state which does not satisfy
the candidate [35–37]. Interestingly, for TpT the counter-
example state is not very relevant, since termination is not
a safety property. What is relevant for TpT is the number
of times a loop body iterates for a given counter-example.
Podelski and Rybalchenko [31] describe a complete pro-
cedure for proving termination for a restricted class of pro-
grams. Cousot [10], Gulwani et al. [19], and Bradley et al. [5]
compute ranking functions by using a template and solving
constraints encoding the program. TpT, on the other hand,
operates on data generated from tests, and the constraints
which verify that a given bound is an actual bound in the
validate phase are much simpler to solve than the constraints
used to synthesize ranking functions.
Bradley et al. [6] developed termination techniques based
on the lexicographic polyranking principle. These techniques
can prove termination of all the tricky loops in the Poly
benchmarks described in Section 6. These techniques were
originally developed for transition systems, and therefore
they ﬁnd it hard to deal with complex control ﬂow. In con-
trast, the infer phase of TpT does not even look at the
program and in the validate phase, the safety checker just
encodes control ﬂow as a constraint which is subsequently
handed oﬀ to an SMT solver. Since TpT does not rely on
predicate abstraction for inferring termination arguments, it
is also able to outperform techniques based on algorithmic
learning [26].
Techniques for handling termination of non-linear pro-
grams are based on a restricted program syntax because they
want their termination argument to be sound by construc-
tion. For instance, Babic et al. [1] can prove the termination
of non-linear programs with a restricted syntax by ﬁnding
“regions of guaranteed divergence”. Due to their restricted
syntax, they cannot prove the termination of the program in
Figure 8. In contrast, TpT does not require its infer phase
to be sound. This allows us to use predictive machine learn-
ing algorithms which work well in practice for the synthesis
of bounds. TpT recovers soundness via the validate phase.
Gulavani et al. [15] adopt a similar approach and try to ﬁnd
a bound for an instrumented loop counter by abstract inter-
pretation. Using their ideas, we can extend our technique to
infer loop bound expressions which can contain logarithms,
exponentials, and square roots. The idea is to just add a
column to the data matrix for every feature that can occur
in the bound and provide enough axioms to the checker to
reason about the features.Proofs using transition invariants [25, 32] require a well
chosen partitioning. Obtaining this partitioning is a well
known hard problem and several heuristics exist. Termina-
tor [9] is based on transition invariants and performs parti-
tioning iteratively. It will be useful to see if abstraction re-
ﬁnement techniques like those employed by Terminator can
help us obtain a good partitioning. [4, 7, 39] are abstract
interpretation based approaches for termination. These ap-
proaches failwhen non-linear computations are involved.
We note that [4] leaves handling disjunctions as an open
problem and [7] handles disjunctions by enumerating all
paths in a loop. TpT requires partitioning when no bounds
exist. In most loops occurring in practice (as attested by
our experiments), the loops do have linear or polynomial
bounds.
Together with proving termination, it seems important to
produce certiﬁcates of non-termination for potentially non-
terminating programs. We are exploring whether our tech-
nique can be combined with [20] in the spirit of [22].
Our technique is related to bounds analyses of Gulwani et
al. [17,18]. These approaches ﬁnd it diﬃcult to handle non-
linearities. As a consequence, they instrument the program
with multiple counters with the hope that all counters will
have linear bounds. In contrast, we can obtain non-linear
bounds. It is important to note that Gulwani et al. can ﬁnd
more precise bounds than TpT as their bounds can contain
richer operators like max. For the program in Figure 1, Gul-
wani et al. can compute the bound max(a, b). On the other
hand, TpT infers a looser bound a+b−2. Since our goal
is to obtain bounds for the purpose of proving termination,
these loose bounds suﬃce. That said, since we are using
linear regression, our bounds are not very loose. But since
they are restricted to linear or polynomial expressions, they
are not as tight.
When the number of iterations of a loop is a determin-
istic function of the input, then [38] can use dynamic in-
formation and polynomial interpolation to compute a loop
bound which is subsequently validated using a proof assis-
tant. However, many of our examples have internal non-
determinism and therefore an interpolating polynomial does
not exist (while a loop bound still exists).
8. CONCLUSION
In this paper, we have presented a novel algorithm TpT
for proving termination of programs using information de-
rived from tests. Programs usually have test suites asso-
ciated with them, and we are able to learn loop bounds
automatically from these test suites using a modiﬁcation of
linear regression. We have also shown how to extend linear
regression so as to infer polynomial loop bounds.
Our empirical results show that TpT signiﬁcantly im-
proves the state-of-the-art in termination analysis – on micro
benchmarks, TpT is able to prove termination on 15% more
benchmarks than any previously known technique. Our re-
sults over Windows device drivers demonstrates TpT’s abil-
ity to analyze and scale to real world applications.
There are number of interesting directions for future work:
Automatic partitioning: As seen in Section 6, TpT fails
to prove termination on four benchmarks all of which re-
quire more sophisticated partitioning of data. It would be
interesting to see if clustering algorithms in machine learn-
ing can be combined with regression to infer disjunctive loop
bounds systematically.Other instantiations of TpT:It would also be interesting
to extend TpTfor proving liveness properties as well as total
correctness of programs. We believe that these would require
a tighter integration of TpT with a safety checker.
9. ACKNOWLEDGEMENTS
We thank Saurabh Gupta, Bharath Hariharan, Andreas
Podelski and Sriram Rajamani for many insightful com-
ments and suggestions.
10. REFERENCES
[1]D. Babic, A. J. Hu, Z. Rakamaric, and B. Cook.
Proving termination by divergence. In Software
Engineering and Formal Methods (SEFM) , pages
93–102, 2007.
[2]M. Barnett, B.-Y. E. Chang, R. DeLine, B. Jacobs,
and K. R. M. Leino. Boogie: A modular reusable
veriﬁer for object-oriented programs. In Formal
Methods for Components and Objects (FMCO) , pages
364–387, 2005.
[3]N. E. Beckman, A. V. Nori, S. K. Rajamani, and R. J.
Simmons. Proofs from tests. In International
Symposium on Software Testing and Analysis
(ISSTA) , pages 3–14, 2008.
[4]J. Berdine, A. Chawdhary, B. Cook, D. Distefano, and
P. W. O’Hearn. Variance analyses from invariance
analyses. In Principles of Programming Languages
(POPL) , pages 211–224, 2007.
[5]A. R. Bradley, Z. Manna, and H. B. Sipma. Linear
ranking with reachability. In Computer Aided
Veriﬁcation (CAV) ,p a g e s4 9 1 – 5 0 4 ,2 0 0 5 .
[6]A. R. Bradley, Z. Manna, and H. B. Sipma. The
polyranking principle. In International Colloquium on
Automata, Logic and Programming (ICALP) , pages
1349–1361, 2005.
[7]A. Chawdhary, B. Cook, S. Gulwani, M. Sagiv, and
H. Yang. Ranking abstractions. In European
Symposium on Programming (ESOP) , pages 148–162,
2008.
[8]E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and
H. Veith. Counterexample-guided abstraction
reﬁnement. In Computer Aided Veriﬁcation (CAV) ,
pages 154–169, 2000.
[9]B. Cook, A. Podelski, and A. Rybalchenko.
Termination proofs for systems code. In Programming
Language Design and Implementation (PLDI) , pages
415–426, 2006.
[10]P. Cousot. Proving program invariance and
termination by parametric abstraction, Lagrangian
relaxation and semideﬁnite programming. In
Veriﬁcation, Model Checking and Abstract
Interpretation (VMCAI) ,p a g e s1 – 2 4 ,2 0 0 5 .
[11]P. Cousot and R. Cousot. Systematic design of
program analysis frameworks. In Principles of
Programming Languages (POPL) , pages 269–282,
1979.
[12]V. Dallmeier, N. Knopp, C. Mallon, G. Fraser,
S. Hack, and A. Zeller. Automatically generating test
cases for speciﬁcation mining. IEEE Transactions on
Software Engineering ,3 8 ( 2 ) : 2 4 3 – 2 5 7 ,2 0 1 2 .
[13]M. D. Ernst, J. H. Perkins, P. J. Guo, S. McCamant,
C. Pacheco, M. S. Tschantz, and C. Xiao. The Daikonsystem for dynamic detection of likely invariants.
Science of Computer Programming ,6 9 ( 1 - 3 ) : 3 5 – 4 5 ,
2007.
[14]S. Goldsmith, A. Aiken, and D. S. Wilkerson.
Measuring empirical computational complexity. In
Foundations of Software Engineering (FSE) , pages
395–404, 2007.
[15]B. S. Gulavani and S. Gulwani. A numerical abstract
domain based on expression abstraction and max
operator with application in timing analysis. In
Computer Aided Veriﬁcation (CAV) , pages 370–384,
2008.
[16]B. S. Gulavani, T. A. Henzinger, Y. Kannan, A. V.
Nori, and S. K. Rajamani. Synergy: a new algorithm
for property checking. In Foundations of Software
Engineering (FSE) , pages 117–127, 2006.
[17]S. Gulwani, S. Jain, and E. Koskinen. Control-ﬂow
reﬁnement and progress invariants for bound analysis.
InProgramming Languages Design and
Implementation (PLDI) , pages 375–385, 2009.
[18]S. Gulwani, K. K. Mehra, and T. M. Chilimbi. Speed:
precise and eﬃcient static estimation of program
computational complexity. In Principles of
Programming Languages (POPL) , pages 127–139,
2009.
[19]S. Gulwani, S. Srivastava, and R. Venkatesan.
Program analysis as constraint solving. In
Programming Language Design and Implementation
(PLDI) , pages 281–292, 2008.
[20]A. Gupta, T. A. Henzinger, R. Majumdar,
A. Rybalchenko, and R.-G. Xu. Proving
non-termination. In Principles of Programming
Languages (POPL) , pages 147–158, 2008.
[21]A. Gupta, R. Majumdar, and A. Rybalchenko. From
tests to proofs. In Tools and Algorithms for the
Construction and Analysis of Systems (TACAS) ,
pages 262–276, 2009.
[22]W. R. Harris, A. Lal, A. V. Nori, and S. K. Rajamani.
Alternation for termination. In Static Analysis
Symposium (SAS) , pages 304–319, 2010.
[23]L. Huang, J. Jia, B. Yu, B.-G. Chun, P. Maniatis, and
M. Naik. Predicting execution time of computer
programs using sparse polynomial regression. In
Neural Information Processing Systems (NIPS) , pages
883–891, 2010.
[24]A. Komuravelli, C. S. Pasareanu, and E. M. Clarke.
Learning probabilistic systems from tree samples. In
Logic in Computer Science (LICS) , pages 441–450,
2012.
[25]D. Kroening, N. Sharygina, A. Tsitovich, and C. M.
Wintersteiger. Termination analysis with
compositional transition invariants. In Computer
Aided Veriﬁcation (CAV) ,p a g e s8 9 – 1 0 3 ,2 0 1 0 .[26]W. Lee, B.-Y. Wang, and K. Yi. Termination analysis
with algorithmic learning. In Computer Aided
Veriﬁcation (CAV) ,p a g e s8 8 – 1 0 4 ,2 0 1 2 .
[27]T. M. Mitchell. Machine learning . McGraw-Hill, 1997.
[28]T. Nguyen, D. Kapur, W. Weimer, and S. Forrest.
Using dynamic analysis to discover polynomial and
array invariants. In International Conference on
Software Engineering (ICSE) ,2 0 1 2 .
[29]C. H. Papadimitriou and K. Steiglitz. Combinatorial
optimization: algorithms and complexity .
Prentice-Hall, Inc., 1982.
[30]C. S. Pasareanu and M. G. Bobaru. Learning
techniques for software veriﬁcation and validation. In
International Symposium on Leaveraging Applications
of Formal Methods, Veriﬁcation and Validation
(ISoLA) , pages 505–507, 2012.
[31]A. Podelski and A. Rybalchenko. A complete method
for the synthesis of linear ranking functions. In
Veriﬁcation, Model Checking and Abstract
Interpretation (VMCAI) ,p a g e s2 3 9 – 2 5 1 ,2 0 0 4 .
[32]A. Podelski and A. Rybalchenko. Transition
invariants. In Logic in Computer Science (LICS) ,
pages 32–41, 2004.
[33]C. P. Robert and G. Casella. Monte Carlo Statistical
Methods (Springer Texts in Statistics) .
Springer-Verlag New York, Inc., 2005.
[34]R. Sharma, I. Dillig, T. Dillig, and A. Aiken.
Simplifying loop invariant generation using splitter
predicates. In Computer Aided Veriﬁcation (CAV) ,
pages 703–719, 2011.
[35]R. Sharma, S. Gupta, B. Hariharan, A. Aiken,
P. Liang, and A. V. Nori. A data driven approach for
algebraic loop invariants. In European Symposium on
Programming (ESOP) , pages 574–592, 2013.
[36]R. Sharma, S. Gupta, B. Hariharan, A. Aiken, and
A. V. Nori. Program veriﬁcation as learning geometric
concepts. In Static Analysis Symposium (SAS) ,2 0 1 3 .
[37]R. Sharma, A. Nori, and A. Aiken. Interpolants as
classiﬁers. In Computer Aided Veriﬁcation (CAV) ,
pages 71–87, 2012.
[38]O. Shkaravska, R. Kersten, and M. C. J. D. van
Eekelen. Test-based inference of polynomial
loop-bound functions. In Principles and Practice of
Programming in Java (PPPJ) , pages 99–108, 2010.
[39]A. Tsitovich, N. Sharygina, C. M. Wintersteiger, and
D. Kroening. Loop summarization and termination
analysis. In Tools and Algorithms for the Construction
and Analysis of Systems (TACAS) , pages 81–95, 2011.
[40]D. Zaparanuks and M. Hauswirth. Algorithmic
proﬁling. In Programming Language Design and
Implementation (PLDI) , pages 67–76, 2012.