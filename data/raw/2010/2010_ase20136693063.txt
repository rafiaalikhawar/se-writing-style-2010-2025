Proving MCAPI Executions Are Correct using SMT
Yu Huang, Eric Mercer, and Jay McCarthy
Department of Computer Science
Brigham Young University
Provo, UT, 84602, USA
Email:fyuHuang,egm,jayg@byu.edu
Abstract â€”Asynchronous message passing is an important
paradigm in writing applications for embedded heterogeneous
multicore systems. The Multicore Association (MCA), an industry
consortium promoting multicore technology, is working to stan-
dardize message passing into a single API, MCAPI, for bare metal
implementation and portability across platforms. Correctness
in such an API is difï¬cult to reason about manually, and
testing against reference solutions is equally difï¬cult as reference
solutions implement an unknown set of allowed behaviors, and
programmers have no way to directly control API internals to
expose or reproduce errors. This paper provides a way to encode
an MCAPI execution as a Satisï¬ability Modulo Theories (SMT)
problem, which if satisï¬able, yields a feasible execution schedule
on the same trace, such that it resolves non-determinism in
the MCAPI runtime in a way that it now fails user provided
assertions. The paper proves the problem is NP-complete. The
encoding is useful for test, debug, and veriï¬cation of MCAPI
program execution. The novelty in the encoding is the direct use
of match pairs (potential send and receive couplings). Match-
pair encoding for MCAPI executions, when compared to other
encoding strategies, is simpler to reason about, results in signif-
icantly fewer terms in the SMT problem, and captures feasible
behaviors that are ignored in previously published techniques.
Further, to our knowledge, this is the ï¬rst SMT encoding that is
able to run in inï¬nite-buffer semantics, meaning the runtime has
unlimited internal buffering as opposed to no internal buffering.
Results demonstrate that the SMT encoding, restricted to zero-
buffer semantics, uses fewer clauses when compared to another
zero-buffer technique, and it runs faster and uses less memory.
As a result the encoding scales well for programs with high levels
of non-determinism in how sends and receives may potentially
match.
Index Terms â€”Abstraction, Reï¬nement, SMT, Message Passing
I. I NTRODUCTION
Embedded devices ï¬ll all sorts of crucial roles in our lives.
They exist as medical devices, as network infrastructure, and
they control our automobiles. Embedded devices continue
to become more powerful as computing hardware becomes
smaller and more modular. It is now becoming commonplace
to ï¬nd multiple processing units inside a single device. The
Multicore Association (MCA) is an industry group that has
formed to deï¬ne speciï¬cations for low-level communication,
resource management, and task management for embedded
heterogeneous multicore devices [14].
One speciï¬cation that the MCA has released is the Mul-
ticore Association Communications API (MCAPI) [15]. The
speciï¬cation deï¬nes types and functions for simple message
passing operations between different computing entities withina device. Messages can be passed across persistent channels
that force an ordering of the messages, or they can be passed
to speciï¬c endpoints within the system. The speciï¬cation
places few ordering constraints on messages passed from one
endpoint to another. This freedom introduces the possibility of
a race between multiple messages to common endpoints thus
giving rise to non-deterministic behavior in the runtime [19].
If an application has non-determinism, it is not possible to test
and debug such an application without a way to directly (or
indirectly) control the MCAPI runtime.
There are two ways to implement the MCAPI semantics:
inï¬nite-buffer semantics (the message is copied into a run-
time buffer on the API call) and zero-buffer semantics (the
message has no buffering) [26]. An inï¬nite-buffer semantics
provides more non-deterministic behaviors in matching send
and receives because the runtime can arbitrarily delay a send
to create interesting (and unexpected) send reorderings. The
zero-buffer semantics follow intuitive message orderings as a
send and receive essentially rendezvous.
Sharma et al. propose a method to indirectly control the
MCAPI runtime to verify MCAPI programs under zero-buffer
semantics [21]. As the work does not address inï¬nite-buffer
semantics, it is somewhat limited in its application. The work
does provide a dynamic partial order reduction for the model
checker, but such a reduction is not sufï¬cient to control
state space explosion in the presence of even moderate non-
determinism between message sends and receives. A key
insight from the approach is its direct use of match pairsâ€“
couplings for potential sends and receives.
Wang et al. propose an alternative method for resolving non-
determinism for program veriï¬cation using symbolic methods
in the context of shared memory systems [28]. The work
observes a program trace, builds a partial order from that trace
called a concurrent trace program (CTP), and then creates
an SMT problem from the CTP that if satisï¬ed indicates a
property violation.
Elwakil et al. extend the work of Wang et al. to message
passing and claim the encoding supports both inï¬nite and zero
buffer semantics. A careful analysis of the encoding, however,
shows it to not work under inï¬nite-buffer semantics and to
miss behaviors under zero-buffer semantics [7]. Interestingly,
the encoding assumes the user provides a precise set of match
pairs as input with the program trace, and it then uses those
match pairs in a non-obvious way to constrain the happens-
before relation in the encoding. The work does not discuss978-1-4799-0215-6/13/$31.00 c2013 IEEE ASE 2013, Palo Alto, USA26
Task 0 Task 1 Task 2
00 initialize(NODE_0,&v,&s);
01 e0=create_endpoint(PORT_0,&s);
02 msg_recv_i(e0,A,sizeof(A),&h1,&s);
03 wait(&h1,&size,&s,MCAPI_INF);
04 a=atoi(A);
05 msg_recv_i(e0,B,sizeof(B),&h2,&s);
06 wait(&h2,&size,&s,MCAPI_INF);
07 b=atoi(B);
08 if(b > 0);
09 assert(a == 4);
0a finalize(&s);10 initialize(NODE_1,&v,&s);
11 e1=create_endpoint(PORT_1,&s);
12 e0=get_endpoint(NODE_0,PORT_0,&s);
13 msg_recv_i(e1,C,sizeof(C),&h3,&s);
14 wait(&h3,&size,&s,MCAPI_INF);
15 msg_send_i(e1,e0,"1",2,N,&h4,&s);
16 wait(&h4,&size,&s,MCAPI_INF);
17 finalize(&s);20 initialize(NODE_2,&v,&s);
21 e2=create_endpoint(PORT_2,&s);
22 e0=get_endpoint(NODE_0,PORT_0,&s);
23 e1=get_endpoint(NODE_1,PORT_1,&s);
24 msg_send_i(e2,e0,"4",2,N,&h5,&s);
25 wait(&h5,&size,&s,MCAPI_INF);
26 msg_send_i(e2,e1,"Go",3,N,&h6,&s);
27 wait(&h6,&size,&s,MCAPI_INF);
28 finalize(&s);
Fig. 1. An MCAPI concurrent program execution
how to generate the match pairs, which is a non-trivial input
to manually generate for large or complex program traces. An
early proof claims that the problem of ï¬nding a precise set of
match pairs given a program trace is NP-complete [20].
This paper presents a proof that resolving non-determinism
in message passing programs in a way that meets all assertions
is NP-complete. The paper then presents an SMT encoding
for MCAPI program executions that works for both zero and
inï¬nite buffer semantics. The encoding does require an input
set of match pairs as in prior work, but unlike prior work,
the match-set can be over-approximated and the encoding is
still sound and complete. The encoding requires fewer terms
to capture all possible program behavior when compared to
other proposed methods making it more efï¬cient in the SMT
solver. To address the problem of generating match pairs, an
algorithm to generate the over-approximated set is given. To
summarize, the main contributions in this paper are
1) a proof that the problem of matching sends to receives
in a way that meets assertions is NP-complete;
2) a correct and efï¬cient SMT encoding of an MCAPI
program execution that detects all program errors under
zero or inï¬nite buffer semantics given the input set of
potential match pairs contains at least the precise set of
match pairs; and
3) anO(N2)algorithm to generate an over-approximation
of possible match pairs, where Nis the size of the
execution trace in lines of code.
Organization : Section 2 gives an example. Section 3 shows
the NP-completeness reduction. Section 4 gives the encoding.
Section 5 shows how to generate match-pairs. Section 6
presents the results. Section 7 discusses related work. And
Section 8 is conclusions and future work.
II. E XAMPLE
It is a challenge to explain intended behavior in simple sce-
narios consisting of a handful of calls when dealing with con-
currency. Consider the MCAPI program execution in Figure 1
that includes three tasks that use send ( mcapi_msg_sen
d_i) and receive ( mcapi_msg_recv_i ) calls to communi-
cate with each other. Line numbers appear in the ï¬rst columnfor each task with the ï¬rst digit being the task ID. The
declarations of the local variables are omitted for space.
Picking up the scenario just after the endpoints are deï¬ned,
lines 02and05receive two messages on the endpoint e0
in variables AandBwhich are converted to integer values
and stored in variables aandbon lines 04and07; task 1
receives one message on endpoint e1in variable Con line
13and then sends the message â€œ1â€ on line 15toe0; and
ï¬nally, task 2 sends messages â€œ4â€ andâ€œGoâ€ on lines 24and
26to endpoints e0ande1respectively. The additional code
(lines 08-09) asserts properties of the values in aandb. The
mcapi_wait calls block until the associated send or receive
buffer is able to be used. Given the scenario, a developer might
ask the question: â€œWhat are the possible values of aandb
after the scenario completes?â€
The intuitive trace is shown in Figure 2 using a shorthand
notation for the MCAPI commands: send (denoted as S),
receive (denoted as R), or wait (denoted as W). The shorthand
notation further preserves the thread ID and line number as
follows: for each command Oi;j(k;&h),O2fS;RgorW(&h),
irepresents the task ID, jrepresents the source line number,
krepresents the destination endpoint, and hrepresents the
command handler. A speciï¬c destination task ID is in the
notation when a trace is fully resolved, otherwise â€œ*â€ indicates
that a receive has yet to be matched to a send. The lines in the
trace indicate the context switch where a new task executes.
24S2;4(0;&h5)
25W(&h5)
02R0;2(2;&h1)
03W(&h1)
26S2;6(1;&h6)
27W(&h6)
04a=atoi (A);
13R1;3(2;&h3)
14W(&h3)
15S1;5(0;&h4)
16W(&h4)
05R0;5(1;&h2)
06W(&h2)
07b=atoi (B);
08assume (b>0);
09assert (a== 4);
Fig. 2. A feasible execution traces of the MCAPI program execution in
Figure 12724S2;4(0;&h5)
25W(&h5)
26S2;6(1;&h6)
27W(&h6)
13R1;3(2;&h3)
14W(&h3)
15S1;5(0;&h4)
16W(&h4)
02R0;2(1;&h1)
03W(&h1)
04a=atoi (A);
05R0;5(2;&h2)
06W(&h2)
07b=atoi (B);
08assume (b>0);
09assert (a== 4);
Fig. 3. A second feasible execution traces of the MCAPI program in Figure 1
From the trace, variable ashould contain 4and variable b
should contain 1since task 2 must ï¬rst send message â€œ4â€ to
e0before it can send message â€œGoâ€ toe1; consequently, task
1 is then able to send message â€œ1â€ toe0. The assume notation
asserts the control ï¬‚ow taken by the program execution. In this
example, the program takes the true branch of the condition
on line 08. At the end of execution the assertion on line 09
holds and no error is found.
There is another feasible trace shown in Figure 3 which
is reachable under the inï¬nite-buffer semantics. In this trace,
the variable acontains 1instead of 4, since the message â€œ1â€
is sent to e0after sending the message â€œGoâ€ toe1as it is
possible for the send on line 24to be buffered in transit. The
MCAPI speciï¬cation indicates that the wait on line 25returns
once the buffer is available. That only means the message
is somewhere in the runtime and not that the message is
delivered. As such, it is possible for the message to be buffered
in transit allowing the send on line 15to arrive at e0ï¬rst and
be received in variable â€œaâ€. Such a scenario is a program
execution that results in an assertion failure at line 09.
From the discussion above, it is important to consider non-
determinism in the MCAPI runtime when testing or debugging
an MCAPI program execution. The next section presents a
proof that the problem of matching sends to receives in
a way that meets all assertions is NP-complete. The proof
justiï¬es the encoding and SMT solver. Following the proof,
the algorithm to generate the encoding is presented. It takes an
MCAPI program execution with a set of possible send-receive
match pairs and generates an SMT problem that if satisï¬ed
proves that non-determinism can be resolved in a way that
violates a user provided assertion (the assertions are negated
in the encoding) and if unsatisï¬able proves the trace correct
(meaning the user assertions hold on the given execution under
all possible runtime behaviors). The encoding can be solved
by an SMT solver such as Yices [5] or Z3 [17].
III. NP C OMPLETENESS PROOF
The complexity proof is inspired by the NP-completeness
proof for memory coherence and consistency by Cantin et al.
that uses a similar reduction from SAT only in the context of
shared memory [3]. The complexity proof is on a new decision
problem: Verifying Assertions in Message Passing (V AMP).Deï¬nition 1. Verifying Assertions in Message Passing .
INSTANCE: A set of constants D, a set of variables X, and
a ï¬nite setHof task histories consisting of send, receive,
and assert operations over XandD.
QUESTION: Is there a feasible schedule Sfor the operations
ofHthat satisfy all the assertions?
The V AMP problem is NP-complete. The proof is a reduc-
tion from SAT. Given an instance Qof SAT consisting of a
set of variables Uand set of clauses CoverU, an instance V
of V AMP is constructed such that Vhas a feasible schedule S
that meets all the assertions if and only if there is a satisfying
truth assignment for Q. Feasible in this context means the
schedule is allowed by the MCAPI semantics.
The reduction is illustrated in Figure 4. The ï¬gure elides
the explicit calls to wait which directly follow each send and
receive operation, and it elides the subscript notation as it is
redundant in the ï¬gure. The ï¬gure also adds the value sent
and the variable that receives the value to the notation as that
information is pertinent to the reduction.
The reduction relies on non-determinism in the message
passing to decide the value of each variable in U. The taskshd0
andhd1repeatedly send the constant value d0(false valuation)
ord1(true valuation) to task hC. The key intuition is that these
tasks are synchronized with hCso they essentially wait to send
the value until asked.
The taskhCsequentially requests and receives d0andd1
values for each variable in the SAT instance Q. It does not
request values for a new variable until the current variable is
resolved. As the values come from two separate tasks upon
request, the messages race in the runtime and may arrive in
either order at hC. As a result, the value in each variable is
non-deterministically d0ord1.
After the value of each variable uiis resolved, the hCtask
asserts the truth of each clause in the problem instance. As the
clauses are conjunctive, the assertions are sequentially evalu-
ated. If a satisfying assignment exists for Q, then a feasible
schedule exists that resolves the values of each variable in
such a way that every assert holds.
Lemma 1. Sis a feasible schedule for Hthat satisï¬es all
assertions if and only if Qis satisï¬able.
Proof. Feasible schedule for V implies Q is satisï¬able :
proof by contradiction. Assume that Qis unsatisï¬able even
though there is a feasible schedule SforVthat meets all the
assertions. The reduction in Figure 4 considers all truth values
of the variables in Q, over every combination, by virtue of
the non-determinism, and then asserts the truth of each of the
clauses inQ. The complete set of possibilities is realized by
sending in parallel from hd0andhd1the two truth valuations
for a given variable to hC. As these messages may be received
in any order, each variable may assume either truth value.
Further, each variable resolved is an independent choice so
all combinations of variable valuations must be considered.
This fact is a contradiction to the assumption of Qbeing
unsatisï¬able as the same truth values that meet the assertions28SAT: Ufu0;u1;:::;umg
Cfc0;c1;:::;cng
Qfc0^c1^:::^cng
V AMPI: Hfhd0;hd1;hCg
Xfu0;:::;um;g0;g1g
Dfd0;d1g
hd0hd1hC
R(g0;)R(g1;)S(d0;hd0)
S(d0;hC)S(d1;hC)S(d0;hd1)
R(u0;)
R(u0;)
R(g0;)R(g1;)S(d0;hd0)
S(d0;hC)S(d1;hC)S(d0;hd1)
R(u1;)
R(u1;)
:::::::::
assert (c0)
assert (c1)
:::
Fig. 4. General SAT to V AMPI reduction
would be a satisfying assignment in Q.
Q is satisï¬able implies feasible schedule for V : the proof is
symmetric to the previous case and proceeds in a like manner.
Theorem 1 (NP-complete) .VAMP is NP-complete.
Proof. Membership in NP : a certiï¬cate is a schedule match-
ing send and receives in each of the histories. The schedule is
linearly scanned with the histories and checked that it does not
violate MCAPI semantics. Our extended version constructs an
operational model of MCAPI semantics that does just such a
check given a schedule [10]. The complexity is linear in the
size of the schedule.
NP-hard : polynomial reduction from SAT. The correctness
of the reduction is established by Lemma 1. The remainder
of the proof is the complexity of the reduction. There are two
tasks to send values d0andd1upon request. For each variable
ui2U, each of these tasks, d0andd1, needs two operations:
one to synchronize with hCand another to send the value:
O(22jUj). The taskhCmust request values from hd0and
hd1and then receive both those values; it must do this for each
variable:O(22jUj). Once all the values are collected, it
must them assert each clause: O(jCj). As every term is linear,
the reduction is linear.
IV. SMT E NCODING
The new SMT encoding is based on (1) a trace of events
during an execution of an MCAPI program including control-
ï¬‚ow assumptions and property assertions, such as Figure 2;
and (2) a set of possible match pairs. A match pair is the
coupling of a receive to a particular send. In the running
example, the set admits, for example, that R0;2can be matched
with either S1;5orS2;4. This direct use of match pairs, ratherthan a state-based or indirect use of match pairs in an order-
based encoding, [7] and [6], is novel.
The purpose of the SMT encoding is to force the SMT
solver to resolve the match pairs for the system in such a way
that the ï¬nal values of program variables meet the assumptions
on control ï¬‚ow but violate some assertion. In essence, the SMT
solver completes a partial order on operations into a total order
that determines the ï¬nal match pair relationships.
A. Deï¬nitions
The encoding needs to express the partial order imposed by
the MCAPI semantics as SMT constraints. The partial order
is based on a Happens-Before relation over operations such as
send, receive, wait, or assert:
Deï¬nition 2 (Happens-Before) .The Happens-Before (HB)
relation, denoted as HB, is a partial order over operations.
Given two operations, AandB, ifAmust complete before
Bin a valid program execution, then AHBBwill be an
SMT constraint.
The relation is derived from the program source and poten-
tial match pairs. In order to specify the constraints from the
program source, each program operation is mapped to a set of
variables that can be manipulated by the SMT solver.
Deï¬nition 3 (Wait) .The occurrence of a wait operation, W,
is captured by a single variable, order W, that constrains when
the wait occurs.
It is not enough to represent all events as simple numbers
that will be ordered in this way. Such an encoding would not
allow the solver to discover what values would ï¬‚ow across
communication primitives. Instead, some events in the trace
are modeled as a set of SMT variables that record the pertinent
information about the event. For example,
Deï¬nition 4 (Send) .A send operation S, is a four-tuple of
variables:
1)MS, the order of the matching receive event;
2)order S, the order of the send;
3)eS, the endpoint; and,
4)value S, the transmitted value.
The endpoints do not change and the transmitted values
are constants in an SMT encoding mainly because this static
topology has already been evaluated in an existing execution
trace once the trace was obtained. The most complex oper-
ation in MCAPI is a receive. Since receives are inherently
asynchronous, it is not possible to represent them atomically.
Instead, we need to associate each receive with a wait that
marks where in the program the receive operation is guaran-
teed to be complete. The MCAPI runtime semantics allow a
single wait to witness the completion of many receives due to
the message non-overtaking property . A wait that witnesses the
completion of one or more receives is the nearest-enclosing
wait.
Deï¬nition 5 (Nearest-Enclosing Wait) .A wait that witnesses
the completion of a receive by indicating that the message is29Task 0 Task 1
R0;1(;&h1) S1;1(0;&h3)
R0;2(;&h2) W(&h3)
W(&h2) S1;2(0;&h4)
W(&h1) W(&h4)
Fig. 5. Nearest-enclosing Wait example
delivered and that all the previous receives in the same task
issued earlier are complete as well.
Figure 5 shows that the wait W(&h2)witnesses the comple-
tion of the receive R0;1andR0;2in task 0. Thus, W(&h2)is
their nearest-enclosing wait.
The encoding requires that every receive operation have a
nearest-enclosing wait as it makes match pair decisions at
the wait operation. The requirement is not a limitation of the
encoding, as accessing a buffer from a receive that does not
have a nearest-enclosing wait is an error. Rather, the wait is a
convenience in the encoding to mark where a receive actually
takes place. The same requirement can be made for sends
for correctness but is not required for the encoding as send
buffering is handled differently than receive buffering. The
encoding effectively ignores wait operations for sends as will
be seen.
Deï¬nition 6 (Receive) .A receive operation Ris modeled by
a ï¬ve-tuple of variables:
1)MR, the order of the matching send event;
2)order R, the order of the receive;
3)eR, the endpoint;
4)value R, the received value; and,
5)nwR, the order of the nearest enclosing wait.
B. Assumptions, Assertions, and match pairs
The deï¬nitions so far merely establish the pertinent infor-
mation about each event in the trace as SMT variables. It is
necessary to now express constraints on those variables.
The most trivial kind of constraints are those for control-
ï¬‚ow assumptions.
Deï¬nition 7 (Assumption) .Every assumption Ais added as
an SMT assertion.
It may seem strange to turn assumptions into assertions ,
but from a constraint perspective, the assumption that we
have already observed some property (during control-ï¬‚ow) is
equivalent to instructing the SMT solver to treat it as inviolate
truth, or an assertion.
The next level of constraint complexity comes from property
assertions. These correspond to the invariants of the program.
The goal is to discover if they can be violated, so we instruct
the SMT solver to seek for a way to satisfy their negation
given all the other constraints.
Deï¬nition 8 (Property Assertion) .For every property asser-
tionP,:Pis added as an SMT assertion.Finally, we must express the relation in a given match pair
as a set of SMT constraints. Informally, a match pair equates
the shared components of a send and receive and constrains the
send to occur before the nearest-enclosing wait of the receive.
Formally:
Deï¬nition 9 (Match Pair) .A match pair,hR;Si, for a receive
Rand a send Scorresponds to the constraints:
1)MR=order S
2)MS=order R
3)eR=eS
4)value R=value Sand
5)order SHBnwR
The encoding is given a set of potential match pairs over all
the sends and receives in the program trace. The constraints
from these match pairs are not simply joined in a conjunctions.
If we were to do that, then we would be constraining the
system such that a single receive must be paired with all
possible sends in a feasible execution rather than a single send.
Therefore, we combine all the constraints for a given receive
with all possible sends as speciï¬ed by the input match pairs
into a single disjunction:
Deï¬nition 10 (Receive Matches) .For each receive R, ifhR;S0i
throughhR;Sniare match pairs, thenWn
ihR;Siiis used as an
SMT constraint.
This encoding of the input ensures that the SMT solver can
only use compatible send/receive pairs and ensures that sends
happen before nearest-enclosing waits on receives.
C. Program Order Constraints
The encoding thus far is missing additional constraints on
theHappens-Before relation stemming from program order.
These constraints are added in four steps: we must ensure
that sends to common endpoints occur in program order in a
single task (step 1); similarly for receives (step 2); receives
occur before their nearest-enclosing wait (step 3); and, that
sends are received in the order they are sent (step 4).
Step 1: For each task, if there are sequential send
operations, say SandS0, from that task to a common endpoint,
eS=eS0, then those sends must follow program order: order S
HBorder S0.
Step 2: For each task, if there are sequential receive
operations, say RandR0, in that task on a common endpoint,
eR=eR0, then those receives must follow program order:
order RHBorder R0.
Step 3: For every receive Rand its nearest enclosing wait
W,order RHBorder W.
Step 4: For any pair of sends Sand S0on common
endpoints,eS=eS0, such that order SHBorder S0, then those
sends must be received in the same order: MSHBMS0.
For example, consider two tasks where task 0 sends two
messages to task 1 as shown in Figure 6. The MSvariables
from the sends will be assigned to the orders for R1;1andR1;2
by the match pairs selected by the SMT solver. The constraints
added in this step force the send to be received in program30Task 0 Task 1
S0;1(1;&h1) R1;1(;&h3)
S0;2(1;&h2) R1;2(;&h4)
W(&h1) W(&h3)
W(&h2) W(&h4)
Fig. 6. Send Ordering Example
...
01order R0;2HBorder W(&h1)
02order R0;5HBorder W(&h2)
03order R0;2HBorder R0;5
04order R1;3HBorder W(&h3)
05 (> b 0)
06 (not (= a 4))
07hR0;2,S2;4i_hR0;2,S1;5i
08hR0;5,S2;4i_hR0;5,S1;5i
09hR1;3,S2;7i
Fig. 7. SMT Encoding
order using the HBrelation which for this example yields
MS0;1HBMS0;2.
D. Zero Buffer Semantics
The constraints presented so far correspond to an inï¬nite-
buffer semantics, because we do not constrain how many
messages may be in transit at once. We can add additional, or-
thogonal, constraints to further restrict behavior and enforce a
zero-buffer semantics. There are two kinds of such constraints.
First, for each task, if there are two sends SandS0such that
order SHBorder S0, and SandS0can both match a receive
R, then we add the following constraint to the encoding:
order WHBorder S0where Wis the nearest-enclosing wait that
witnesses the completion of Rin execution.
The second constraint relies on a dependence relation be-
tween two match pairs.
Deï¬nition 11. To match pairs are dependent, denoted as hR;Si
*hR0;S0i, if and only if
1) the nearest-enclosing wait WofR0issues before Son an
identical endpoint; or
2)9hR00S00isuch thathR;Si*hR00;S00i^hR00;S00i*hR0;S0i.
With the dependence relation, the second set of constraints
for the zero-buffer semantics is given as: for each pair of sends
SandS0that can both match a receive R, if there is a send
S00issued after the issuing of S0by an identical endpoint,
and a receive R0such thathR;Si*hR0;S00i, then we add
the following constraint to the encoding: order WHBorder S
where Wis the nearest-enclosing wait that witnesses the
completion of R.
E. Example
Figure 7 shows the encoding of Figure 1 as an SMT prob-
lem. We elide the basic deï¬nition of the variables discussedin Section IV-A. Lines 05through 09give the assumptions,
assertions, and match pairs. The ï¬rst four lines reï¬‚ect the pro-
gram order constraints: receives happen before corresponding
wait operations and receives from a common endpoint follow
program order. There are no constraints between sends because
there are no sequential sends from a common endpoint to a
common endpoint. To encode the zero-buffer semantics, the
constraint order W(&h1)HBorder S1;5would need to be added
to force the receive to complete before another send is issued.
F . Correctness
Before we can state our correctness theorem, we must
deï¬ne a few terms. We deï¬ne our encoder as a function from
programs and match pair sets to SMT problems:
Deï¬nition 12 (Encoder) .For all programs, p, and match pair
setsm, letSMT (p;m )be our encoding as an SMT problem.
We assume that an SMT solver can be represented as
a function that takes a problem and returns a satisfying
assignment of variables or an unsatisï¬able ï¬‚ag:
Deï¬nition 13 (SMT Solver) .For all SMT problems, s, let
SOL (s)be in+UNSAT , whereis a satisfying assignment
of variables to values.
We assume that from a satisfying assignment to one of our
SMT problems, we can derive an execution trace by observing
the values given to each of the order evariables. In other
words, we can view the SMT solver as returning traces and
not assignments.
We assume a semantics for traces that gives their behavior
as either having an assertion violation or being correct:1
Deï¬nition 14 (Semantics) .For all programs, p, and traces t,
SEM (p;t)is either BAD orOK.
Given this framework, our SMT encoding technique is
sound if
Theorem 2 (Soundness) .For all programs, p, and match pair
sets,m,SOL (SMT (p;m )) =t)SEM (p;t) =BAD .
Our soundness proof relies on the following lemma:
Lemma 2. Any match pairhR;Siused in a satisfying assign-
ment of an SMT encoding is a valid match pair and reï¬‚ects
an actual possible MCAPI program execution.
Proof. We prove this by contradiction. First, assume that hR;Si
is an invalid match pair (i.e. one that is not valid in an actual
MCAPI execution). Second, assume that the SMT solver ï¬nds
a satisfying assignment.
SincehR;Siis not a valid match pair, match RandSrequires
program order, message non-overtaking, or no-multiple match
to be violated. In other words, the Happens-Before constraints
encoded in the SMT problem are not satisï¬ed.
This is a contradiction: either the SMT solver would not
return an assignment or the match pair was actually valid.
1In fact, our extended technical report [10] gives such a semantics.31The correctness of our technique relies on completeness:
Theorem 3 (Completeness) .For all programs, p, and traces,
t,SEM (p;t) =BAD)9m:SOL (SMT (p;m )) =t.
We prove completeness in our extended version [10] by
designing our semantics, SEM , such that it simulates the
solving of the SMT problem during its operation to ensure
that the two make identical conclusions.
However, these theorems obscure an important problem:
how do we know which match pair set to use? Soundness
assumes we have one, while completeness merely asserts
that one exists. Although Section V discusses our generation
algorithm, we prove here an additional theorem that asserts
that any conservative over-approximation of match pair sets is
safe.
Theorem 4 (Approximation) .Give two match pair sets mand
m0,mm0)SOL (SMT (p;m ))vSOL (SMT (p;m0)),
where UNSATv.
Informally, this is true because larger match pair sets only
allow more behavior, which means that the SMT solver has
more freedom to ï¬nd violations, but that all prior violations are
still present. However, because of soundness, it is not possible
that using a larger match pair set will discover false violations.
The formal proof, in our extended version [10], relies on a
match set combination operator that we prove distributes over
an essential part of the semantics.
V. G ENERATING MATCH PAIRS
The exact set of match pairs can be generated by simulating
the program trace and using a depth-ï¬rst search to enumerate
non-determinism arising from concurrent sends and receives.
Such an effort, however, solves the entire problem at once
because if you simulate the program trace exploring all non-
determinism, then you may as well verify all runtime choices
for property violations at the same time.
In this section, we present an algorithm that does not require
an exhaustive enumeration of runtime behavior in simulation.
Our algorithm over-approximates the match pairs such that
match pairs that can exist in the runtime are all included and
some bogus match pairs that cannot exist in the runtime may
or may not be included. This algorithm does well in restricting
the size of bogus match pairs where each one is a non-
deterministic choice that costs an SMT solver more runtime
and system memory. Generating a precise set of match-pairs
is NP-complete [20].
The algorithm generates the over-approximated match pair
set by matching each pair of the send and receive commands
at common endpoints and then pruning obvious matches that
cannot exist in any runtime implementation of the speciï¬ca-
tion.
Figure 8 presents the major steps of the algorithm. The
algorithm proceeds by ï¬rst linearly traversing each task of
the program storing each receive and send command into two
distinct structured lists. The receive list, list r, is structured// initialization
input an MCAPI program
initialize list_r
initialize list_s
// check each receive and send with the same endpoint
for r in list_r
for s in list_s
let dest = destination endpoint(s)
let src = source endpoint(s)
// check matching criteria for r and s
if
1. endpoint(r) = dest
2. index(r) >= index(s)
3. index(r) =< (index(s)
+ count(sends(dest=dest))
- count(sends(src=src, dest=dest)))
then
add pair (r, s) to match_set
else
continue
end if
end for
end for
output match_set;
Fig. 8. Pseudocode for generating over-approximated match pairs
Task 0 Task 1 Task 2
R0;1(;&h1)S1;1(0;&h5)S2;1(0;&h8)
W(&h1) W(&h5) W(&h8)
R0;2(;&h2)R1;2(;&h6)
W(&h2) W(&h6)
S0;3(1;&h3)S1;3(0;&h7)
W(&h3) W(&h7)
R0;4(;&h4)
W(&h4)
Fig. 9. Another MCAPI concurrent program
as in (1) and the send list, list s, is structured as in (2).
(e0!((0;R0;1);(1;R0;2); : : :))
(e1!((0;R1;1);(1;R1;2); : : :))
: : :
(en!((0;Rn;1);(1;Rn;2); : : :))(1)
The list list_r groups receives by the issuing endpoint. The
integer ï¬eld merely records the order in which the receives are
issued and increases by one on each receive. Similarly, the list
list_s groups sends ï¬rst by the destination endpoint and
then by the source endpoint. Like list_r , an index increases
by one to track the issue order. As the input is a program
execution trace, any sends or receives in loops already have
unique identiï¬ers.
\dest" \src" \ src"
(e0!((e1!((0;S1;1);(1;S1;2); : : :);(e2!(: : :);
: : :))))
(e1!((e0!((0;S0;1);(1;S0;2); : : :);(e2!(: : :);
: : :))))
: : :
(en!((e0!((0;S0;3);(1;S0;4); : : :);(e1!(: : :);
: : :))))(2)
Consider the program in Figure 9. The lists list_r and
list_s for the program are
(0!((0;R0;1);(1;R0;2);(2;R0;4)))
(1!((0;R1;2)))(3)32(0!((1!((0;S1;1);(1;S1;3));(2!((0;S2;1))))))
(1!((0!((0;S0;3)))))(4)
The sends S1;1,S1;3, and S2;1have task 0 as an identical
destination endpoint. The send S0;3has task 1 as the desti-
nation endpoint. The list list_s in (4) reï¬‚ects this partition.
Receive R0;1is the ï¬rst receive operation in endpoint 0. This
fact is again reï¬‚ected in list_r in (3).
The algorithm traverses the two lists in a nested loop to
generate match pairs between send and receive commands.
The function index(r) takes the endpoint of the receive and
returns the issue order of that receive in the list_r structure.
Similarly, the function index(s) takes the destination and
source endpoints in the send and returns the issue order of
that send in the list_s structure. These indexes help track
message non-overtaking.
The criteria to generate a match pair ï¬rst requires the
send and receive to be compatible (check 1), consistent with
message non-overtaking (check 2), and that message non-
overtaking does not preclude the match (check 3). A match is
precluded by message non-overtaking when a receive cannot
possibly match a send because by the time the program
issues the receive, the send must have already been matched
somewhere else. The function count gives the number of
sends to a speciï¬c destination or the number of sends to a
speciï¬c source and destination. As long as a receive is issued
early enough to still match the send given the message non-
overtaking rule, then the match is possible.
In our concrete example, R0;1is matched with S1;1orS2;1,
but it cannot be matched with S1;3since the second rule is
not satisï¬ed such that the order of R0;1is less than the order
ofS1;3(i.e., S1;3would have to overtake S1;1to satisfy the
rule). The match between R0;4andS1;1is also precluded by
check 3 as S1;1must have already matched an earlier receive
by message non-overtaking.
The generated set of match pairs for our example in Figure 9
is over-approximated by the algorithm because it includes
pairs that cannot exist in any feasible execution. For example,
the match pair (S2;1R0;4)is not feasible because it is not
possible to order S1;3before R0;2since R1;2can only match
with S0;3that must occur after R0;2. Fortunately, a satisfying
solution is only possible using feasible match pairs. Non-
feasible match pairs merely result in extra clauses in the
encoding and potentially slow down the SMT solver.
The complexity of the algorithm is quadratic. Traversing
the tasks to initialize the lists is O(N), whereNis the total
lines of code of the program. Traversing the list of receives
and the list of sends takes O(mn)to complete, where mis the
total number of sends and nis the total number of receives. As
m+nN, the algorithm takes O(N+mn)O(N+N2)
O(N2)to complete.
VI. E XPERIMENTS AND RESULTS
To assess the new encoding in this paper, three experiments
with results are presented: a comparison to prior SMT en-
codings on a zero-buffer semantics, a scalability study on the
effects of non-determinism in the execution time on inï¬nitebuffer semantics, and an evaluation on typical benchmark
programs again with inï¬nite buffer semantics. All of the
experiments use the Z3 SMT solver ([17]) and are measured
on a 2.40 GHz Intel Quad Core processor with 8 GB memory
running Windows 7.
The initial program trace for the experiments is generated
using the MCA provided reference solution with ï¬xed input. In
other words, the only non-determinism in the programs is that
allowed by the MCAPI speciï¬cation. As such, the experiments
only consider one path of control ï¬‚ow through the program.
Complete coverage of the program for veriï¬cation purposes
would need to generate input to exercise different control ï¬‚ow
paths. Where appropriate, the time to generate the match pair
sets from the input trace is reported separately.
A. Comparison to Prior SMT Encoding
To our best knowledge, the current most effective SMT
encoding for veriï¬cation of message passing program traces
is the order-based encoding that describes the happens-before
relation directly in the encoding and is only functional for
zero-buffer semantics in its current form [7]. The order-based
encoding is more complex than the encoding in this paper
and generates more clauses for the SMT solver. Although
the tool to generate the encoding is not publicly available,
the authors of the order-based encoding graciously encoded
several contrived benchmarks used for correctness testing.
These benchmarks are best understood as toyexamples that
plumb the MCAPI semantics to clarify intuition on expected
behavior.
The zero-buffer encoding in this paper is compared directly
to the order-based encoding on the contrived benchmarks.
The order-based encoding yields incorrect answers for several
programs. Where the order-based encoding returns correct
answers, the new encoding, on average, requires 70% fewer
clauses, uses half the memory as reported by the SMT solver,
and runs eight times faster. The dramatic improvement of the
new encoding over the order-based encoding is a direct result
of the match pairs that simplify the happens-before constraints
and avoids redundant constraints in the transitive closure of the
happens-before relation.
B. Scalability Study
The intent of the scalability study is to understand how
performance is affected by the number of messages in the
program trace and the level of non-determinism in choosing
match pairs where multiple sends are able to match to multiple
receives. The programs for this study consist of a simple
pattern of a single thread to receive messages and Nthreads
to send messages. The single thread sequentially receives N
messages containing integer values and then asserts that every
message did not receive a speciï¬c value. In other words, a
violation is one where each message has a speciï¬c value.
The remaining Nthreads send a message, each containing
a different unique integer value, to the single thread that
receives. These programs represent the worst-case scenario for
non-determinism in a message passing program as any send is33TABLE I
SCALING AS A FUNCTION OF NON -DETERMINISM
Test Programs Performance
N Feasible Sets Time (hh:mm:ss) Memory(MB)
30 30!(3E32) 00:00:36 20.11
40 40!(8E47) 00:03:22 47.12
50 50!(3E64) 00:16:11 102.65
60 60!(8E81) 00:47:29 189.53
70 70!(1E100) 02:00:30 364.25
able to match with any receive in the runtime, and the assertion
is only violated when each send is paired with a speciï¬c
receive. The SMT solver must search through the multitude of
match pairs, NN, to ï¬nd the single precise subset of match
pairs that triggers the violation. In this program structure, there
areN!feasible ways to match Nsends toNreceives.
The study takes an initial program of N= 30 , so 31 threads,
and variesNto see how the SMT solver scales. A small Nis
an easy program while a large Nis a hard program. Table I
shows how the new encoding scales with hardness. The ï¬rst
column is the number of messages, or N, and the second
column is the number of feasible match pair subsets that
correctly match every receive to a unique send. As expected,
running time and memory consumption increase non-linearly
with hardness.
The case where N= 70 represents having 70 concurrent
messages in ï¬‚ight from 70 different threads of execution. Such
a scenario is not entirely uncommon in a high performance
computing application, and it appears the new encoding is
able to reasonably scale to such a level of concurrency. The
result provides a bound on expected cost for analysis given
the message passing behavior in a program. It is expected
that the analysis of any program with fewer than 70!possible
choices of feasible match pair resolutions will complete in
a reasonable amount of time. Regardless, such a high-level
concurrency seems unlikely in the embedded space to which
MCAPI is targeted.
C. Typical Benchmark Programs
The results in the prior section suggest that the number
of messages is not the deciding factor in hardness for the
new encoding; rather, hardness is measured by the number
of feasible match pair sets. This section further explores the
observation to show that some programs are easy, even if
there are many messages, while other programs are hard, even
though there are only a few messages.
The goal of these experiments is to measure the new
encoding on several benchmark programs. MCAPI is a new
interface, and to date, the authors are not aware of publicly
available programs written against the interface aside from the
few toy programs that come with the library distribution. As
such, the benchmarks in the experiments come from a variety
of sources.
LEis the leader election problem and is common to
benchmarking veriï¬cation algorithms.
Router is an algorithm to update routing tables. Each
router node is in a ring and communicates only withTABLE II
PERFORMANCE ON SELECTED BENCHMARKS
Test Programs Performance
Name # Mesg Feasible Sets EG(s) MG(s) Time (hh:mm:ss) Memory(MB)
LE 620 1 1.49 0.051 <00:00:01 33.41
Router 2006E2 0.417 0.032 00:00:02 15.03
MultiM 1001E40 0.632 0.436 00:16:40 135.19
Pktuse 5121E81 10.190 9.088 02:06:09 1539.90
immediate neighbors to update the tables. The program
ends when all the routing tables are updated.
MultiM is an extension to a program in the MCAPI
library distribution and is similar to the program in Fig-
ure 9. The extension adds extra iterations to the original
program execution to generate longer execution trace.
Pktuse is a benchmark from the MPI test suite [18]. The
program creates 5 tasksâ€”each of which randomly sends
several messages to the other tasks.
The benchmark programs are intended to cover a spectrum
of program properties. As before, the primary measure of
hardness in the programs in not the number of messages but
rather the size of the match pair set and the number of feasible
subsets. The LEprogram is the easiest program in the suite.
Although it sends 620 messages, there is only a single feasible
match pair set. The programs Router ,MultiM , and Pktuse
respectively increase in hardness, which again is not related
to the total number of messages but rather the total number
of feasible match-sets that must be considered. For example,
even though Router has 200 messages, it is an easier problem
thatMultiM that has 100 messages. The Pktuse program does
have the most number of messages, 512, and in this case, the
largest number of feasible match pair sets.
Table II shows the results for the benchmark suite. Other
than the metrics used in Table I, the time of generating the
encoding and the match pairs is included in the third and fourth
columns respectively. Note that the time shown in the third
column includes the time in the fourth column. As before,
the running time tracks hardness and not the total number
of messages. The table also shows the cost of match pair
generation as it dominates the encoding time for the Pktuse
program (an item for future work).
The benchmark suite demonstrates that a message passing
program may have a large degree of non-determinism in
the runtime that is prohibitive to veriï¬cation approaches that
directly enumerate non-determinism such as a model checker.
The SMT encoding, however, pushes the problem to the
SMT solver by generating the possible match pairs and then
relying on advances in SMT technology to resolve the non-
determinism in a way that violates the assertion. Of course,
the SMT problem itself is NP-complete, so performance is
only reasonable for small problem instances. The benchmark
suite suggests that problem instances with astonishingly large
numbers of feasible match pair sets are able to complete
in a reasonable amount of time using the new encoding in
this paper; though, the time to generate the match pairs may
quickly become prohibitive.34VII. R ELATED WORK
Morse et al. provided a formal modeling paradigm that is
callable from the C language for the MCAPI interface [16].
This model correctly captures the behavior of the interface
and can be applied to model checking C programs that use
the API. The work is a direct application of model checking
and directly enumerates the non-determinism in the runtime to
construct an exhaustive proof. The SMT encoding in this paper
pushes that complexity to the SMT solver and leverages recent
advances in SMT technology to ï¬nd a satisfying assignment.
Sharma et al. present an dynamic model checker for MCAPI
programs built on top of the MCA provided MCAPI runtime
[21]. MCC systematically enumerates all non-determinism in
the MCAPI runtime under zero-buffer semantics. It employs
a novel dynamic partial order reduction to avoid enumerating
redundant message orders. This work claims SMT technology
is more efï¬cient in practice in resolving non-determinism in
a away to violate correctness properties.
Wang et al. present an SMT encoding for shared memory
semantics for a given input trace from a multi-threaded pro-
gram [28]. As mentioned previously, the program is partitioned
into several concurrent trace programs, and the encoding for
each program is veriï¬ed using SMT technology. Elwakil et al.
extend the encoding to message passing programs using the
MCAPI semantics [6], [7]. The comparison to the encoding
in this work is already discussed previously.
An important body of work is being pursued for MPI
program veriï¬cation [25], [24], [23], [22], [27], [26], [8].
Highlights include an extension to the SPIN model checker
for MPI programs, symbolic execution tools for MPI pro-
grams including new approaches to computing loop invariants,
and various dynamic veriï¬cation tools for MPI programs.
Although MPI is more expressive than MCAPI, the correctness
properties in MCAPI are similar to those in MPI. More
importantly, the encoding in this work should be applicable
to MPI programs that do not include collective operations. An
important aspect of future work is to extend the encoding to
collectives.
There is a rich body of literature for SMT/SAT based
Bounded Model Checking. Burckhardt et al. exhaustively
check all executions of a test program by translating the
program implementation into SAT formulas [2]. The approach
relies on counter-examples from the solvers the reï¬ne the
encoding. The SMT encoding in this work is able to directly
resolve the match-pair set over-approximation directly without
needing to check a counter-example.
Dubrovin et al. give a method to translate an asynchronous
system into a transition formula over three partial order seman-
tics [4]. The encoding adds constraints to compress the search
space and decrease the bound on the program unwinding. The
encoding in this paper operates on a program execution and
does not need to resolve a bound.
Kahlon et al. presented a partial order reduction, MPOR ,
that operates in the bounded model checking space [11]. It
guarantees that exactly one execution is calculated per eachMazurkiewicz trace to reduce the search space. It would be
interesting to see if MPOR is able to extend to message passing
semantics. Other work in bounded model checking explores
heap-manipulating programs and challenges in sequential sys-
tems code [13], [12].
The application of static analysis is another interesting
thread of research to test or debug message passing programs
with some work in the MPI domain [29], [1], [9]. The work
is important as it lays the foundation for reï¬ning match-pair
sets to only include those that cannot be statically pruned.
VIII. C ONCLUSIONS AND FUTURE WORK
This paper presents a proof that the problem of resolving
non-determinism in message passing in a way that meets
asserts is NP-complete. The paper then presents an SMT en-
coding of an MCAPI program execution that uses match pairs
directly rather than the state-based or order-based encoding
in the prior work. The encoding is generated from a given
execution trace and a set of potential match pairs that can be
over-approximated. The encoding takes extra care in forming
the SMT problem to preclude bogus match pairs in any over-
approximation of the match pair input set. Critically, the
encoding is the ï¬rst to correctly capture the non-deterministic
behaviors of an MCAPI program execution under inï¬nite-
buffer semantics.
This paper further deï¬nes an algorithm with O(N2)time
complexity to over-approximate the true set of match pairs,
whereNis the total number of code lines of the program.
A comparison to prior work, [7], for a set of â€œtoyâ€ examples
under zero-buffer semanics shows the new encoding capable
and efï¬cient in capturing correct behaviors of an MCAPI pro-
gram execution. Experiments further show that the encoding
scales to programs with signiï¬cant levels of non-determinism
in how sends match to receives.
The results show that a large match-pair set does affect the
runtime performance of the encoding in the SMT problem
even if the encoding is sound under an over-approximation.
Future work explores new methods for generating a much
more precise set of match pairs. The encoding is dependent on
an input execution trace of the program. Future work explores
integrating the encoding into a model checker. The model
checker generates a program trace that is encoded and veriï¬ed.
The result is then used to inform the model checker as to where
it needs to backtrack to generate a new execution trace. The
goal is to use the trace veriï¬cation to construct a better partial
order reduction in the model checker.
Finally, given the importance of high performance com-
puting, future work looks to extend the encoding to account
for MPI collective operations. This direction is motivated by
the results where the encoding seems to scale to signiï¬cant
levels of concurrency. It should be possible to express MPI
collectives as additional constraints in the encoding and apply
the technique to MPI programs directly.35REFERENCES
[1] Bronevetsky, G.: Communication-sensitive static dataï¬‚ow for parallel
message passing applications. In: CGO. IEEE Computer Society (2009)
[2] Burckhardt, S., Alur, R., Martin, M.M.K.: Checkfence: Checking con-
sistency of concurrent data types on relaxed memory models. In: ACM
SIGPLAN PLDI. San Diego, California, USA (June 10â€“13, 2007)
[3] Cantin, J.F., Lipasti, M.H., Smith, J.E.: The complexity
of verifying memory coherence and consistency. IEEE
Trans. Parallel Distrib. Syst. 16(7), 663â€“671 (Jul 2005),
http://dx.doi.org/10.1109/TPDS.2005.86
[4] Dubrovin, J., Junttila, T., Heljanko, K.: Exploiting step semantics for
efï¬cient bounded model checking of asynchronous systems. In: Science
of Computer Programming. pp. 77(10â€“11):1095â€“1121 (2012)
[5] Dutertre, B., de Moura Leonardo: A fast linear-arithmetic solver for
DPLL(T). In: CA V . vol. 4144 of LNCS, pp. 81â€“94. Springer-Verlag
(2006)
[6] Elwakil, M., Yang, Z.: CRI: Symbolic debugger for MCAPI applications.
In: Automated Technology for Veriï¬cation and Analysis (2010)
[7] Elwakil, M., Yang, Z.: Debugging support tool for mcapi applications.
In: PADTAD â€™10: Proceedings of the 8th Workshop on Parallel and
Distributed Systems (2010)
[8] Flanagan, C., Godefroid, P.: Dynamic partial-order reduction for model-
ing checking software. In: POPL. pp. 110â€“121. ACM Press, New York,
NY , USA (2005)
[9] Gray, I., Audsley, N.: Targeting complex embedded architectures by
combining the multicore communications API (MCAPI) with compile-
time virtualisation. In: LCTES. ACM, Chicago, Illinois, USA (2011)
[10] Huang, Y ., Mercer, E., McCarthy, J.: Proving
MCAPI executions are correct using SMT (extended),
http://students.cs.byu.edu/ Ëœyhuang2/downloads
/paper.pdf
[11] Kahlon, V ., Wang, C., Gupta, A.: Monotonic partial order reduction: An
optimal symbolic partial order reduction technique. In: ACM CA V . pp.
398â€“413. Springer, Berlin/Heidelberg, Grenoble, France (June 26â€“July
02, 2009)
[12] Lahiri, S.: SMT-based modular analysis of sequential systems code. In:
CA V . Springer-Verlag (2011)
[13] Lahiri, S., Qadeer, S.: Back to the future revisiting precise program veri-
ï¬cation using SMT solvers. In: POPL. ACM, San Francisco, California,
USA (2008)
[14] MCA: The multicore association, http://www.multicore-
association.org
[15] MCA: The multicore association resource management API,
http://www.multicore-association.org/workgroup
/mcapi.php[16] Morse, E., Vrvilo, N., Mercer, E., McCarthy, J.: Modeling asynchronous
message passing for C program. In: Veriï¬cation, Model Checking, and
Abstract Interpretation. vol. 7148 of LNCS, pp. 332â€“347. Springer-
Verlag (2012)
[17] de Moura, L., Bj rner, N.: Z3: An efï¬cient SMT solver. In: TACAS.
vol. 4963, pp. 337â€“340. Springer, Heidelberg (2008)
[18] MPPTest: MPPTest benchmark, http://www.mcs.anl.gov
/research/projects/mpi/mpptest/
[19] Netzer, R., Brennan, T., Damodaran-Kamal, S.: Debugging race condi-
tions in message-passing programs. In: ACM SIGMETRICS Symposium
on Parallel and Distributed Tools. pp. 31â€“40. Philadelphia, PA, USA
(1996)
[20] Sharma, S.: Private conversation on active research.
[21] Sharma, S., Gopalakrishanan, G., Mercer, E., Holt, J.: MCC - a runtime
veriï¬cation tool for MCAPI user applications. In: FMCAD (2009)
[22] Siegel, S.F.: Verifying parallel programs with MPI-Spin. In: Cappello,
F., H Â´erault, T., Dongarra, J. (eds.) Recent Advances in Parallel Virtual
Machine and Message Passing Interface, 14th European PVM/MPI
Userâ€™s Group Meeting, Paris, France, September 30 - October 3, 2007,
Proceedings. Lecture Notes in Computer Science, vol. 4757, pp. 13â€“14.
Springer (2007)
[23] Siegel, S.F., Gopalakrishnan, G.: Formal analysis of message passing. In:
Jhala, R., Schmidt, D. (eds.) Veriï¬cation, Model Checking, and Abstract
Interpretation: 12th International Conference, VMCAI 2011, Austin, TX,
January 23â€“25, 2011, Proceedings. Lecture Notes in Computer Science,
vol. 6538, pp. 2â€“18 (2011)
[24] Siegel, S.F., Zirkel, T.K.: Automatic formal veriï¬cation of MPI-based
parallel programs. In: Cascaval, C., Yew, P.C. (eds.) Proceedings of the
16th ACM SIGPLAN Annual Symposium on Principles and Practices
of Parallel Programming (PPoPP â€™11). pp. 309â€“310. ACM (2011)
[25] Siegel, S.F., Zirkel, T.K.: Loop invariant symbolic execution for parallel
program. In: Kuncak, V ., Rybalchenko, A. (eds.) Veriï¬cation, Model
Checking, and Abstract Interpretation: 13th International Conference,
VMCAI 2012. Lecture Notes in Computer Science, vol. 7148, pp. 412â€“
427. Springer (2012)
[26] Vakkalanka, S., V o, A., Gopalakrishnan, G., Kirby, R.: Reduced execu-
tion semantics of MPI: From theory to pratice. In: FM. pp. 724â€“740
(2009)
[27] V o, A., Vakkalanka, S.S., Gopalakrishnan, G.: Isp tool update: Scalable
MPI veriï¬cation. In: M Â¨uller, M.S., Resch, M.M., Schulz, A., Nagel,
W.E. (eds.) Parallel Tools Workshop. pp. 175â€“184. Springer (2009)
[28] Wang, C., Chaudhuri, S., Gupta, A., Yang, Y .: Symbolic pruning of
concurrent program executions. In: ESEC/FSE. pp. 23â€“32. ACM, New
York, NY , USA (2009)
[29] Zhang, Y ., Evelyn, D.: Barrier matching for programs with textually
unaligned barriers. In: PPoPP. pp. 194â€“204. ACM, San Jose, California,
USA (2007)36