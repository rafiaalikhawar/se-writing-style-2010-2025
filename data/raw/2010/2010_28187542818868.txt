Camouﬂage: Automated Anonymization of Field Data∗
James Clause
Department of Computer
and Information Sciences
University of Delaware
clause@udel.eduAlessandro Orso
College of Computing
Georgia Institute of Technology
orso@cc.gatech.edu
ABSTRACT
Privacy and security concerns have adversely aﬀected the
usefulness of many types of techniques that leverage infor-
mation gathered from deployed applications. To address this
issue, we present an approach for automatically anonymizing
failure-inducing inputs that builds on a previously developed
technique. Given an input Ithat causes a failure f, our ap-
proach generates an anonymized input I/primethat is diﬀerent
fromIbut still causes f.I/primecan thus be sent to developers to
enable them to debug fwithout having to know I. We im-
plemented our approach in a prototype tool, camouflage ,
and performed an extensive empirical evaluation where we
applied camouflage to a large set of failure-inducing inputs
for several real applications. The results of the evaluation are
promising, as they show that camouflage is both practical
and eﬀective at generating anonymized inputs; for the inputs
that we considered, IandI/primeshared no sensitive information.
The results also show that our approach can outperform the
general technique it extends.
Categories and Subject Descriptors: D.2.5 [Software
Engineering]: Testing and Debugging; K.4.1 [Public Policy
Issues]: Privacy
General Terms: Experimentation, Security
Keywords: Input anonymization, symbolic execution
1. INTRODUCTION
Investigating techniques that capture data from deployed
applications to support in-house software engineering tasks
is an increasingly active and successful area of research ( e.g.,
[10, 11, 13, 17, 20, 21, 23]). However, privacy and security
concerns have prevented widespread adoption of many of
these techniques and, because they rely on user participation,
have ultimately limited their usefulness. Many of the earlier
proposed techniques attempt to sidestep these concerns by
collecting only limited amounts of information ( e.g., stack
traces and register dumps [2,4] or sampled branch proﬁles [20,
∗This work was supported in part by NSF awards CCF-
0725202 and CCF-0916605 to Georgia Tech.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’11, May 21–28, 2011, Waikiki, Honolulu, HI, USA
Copyright 2011 ACM 978-1-4503-0445-0/11/05 ...$10.00.21]) and providing a privacy policy that speciﬁes how the
information will be used ( e.g., [1,6]). Because the types of
information collected by these techniques are unlikely to be
sensitive, users are more likely to allow the techniques to be
used. Moreover, because only a small amount of information
is collected, it is feasible for users to manually inspect and
anonymize such information before it is sent to developers.
Unfortunately, recent research has shown that the eﬀec-
tiveness of these techniques increases when they can lever-
age large amounts of detailed information ( e.g., complete
execution recordings [3, 11] or path proﬁles [10, 18]). Since
more detailed information is bound to contain sensitive data,
users will most likely be unwilling to let developers collect
such information. In addition, collecting large amounts of
information would make it infeasible for users to anonymize
the collected information by hand. To address this prob-
lem, some of these techniques suggest using an input min-
imization approach ( e.g., [5, 29]) to reduce the number of
failure-inducing inputs and, hopefully, eliminate some sensi-
tive information. Input-minimization techniques, however,
were not designed to speciﬁcally reduce sensitive inputs, so
they can only eliminate sensitive data by chance. In or-
der for techniques that leverage captured ﬁeld information
to become widely adopted and achieve their full potential,
new approaches for addressing privacy and security concerns
must be developed.
One promising technique for addressing privacy concerns is
the one proposed by Castro and colleagues [9], which works
in conjunction with an execution record/replay technique
(e.g., [3,11]). Given an execution recording that contains a
captured failure-inducing input I=/angbracketlefti1,i2,...in/angbracketrightand termi-
nates with a failure f, the technique replays the execution
recording and leverages dynamic symbolic execution to au-
tomatically produce I/prime, an anonymized version of Ithat still
causesf.
In this paper, we extend the work presented in [9] in sev-
eral ways. From a conceptual standpoint, we present an
improved approach that incorporates two novel techniques
that we developed: path condition relaxation andbreakable
input conditions . Intuitively, these techniques increase the
strength of the general approach by decreasing the amount
of information that is revealed about the original inputs. By
doing so, they make it more diﬃcult to reconstruct all, or
even part, of the original input, which helps to ensure users’
privacy. From a practical standpoint, we present a more
thorough evaluation of the approach that considers a larger
number of faults and considerably more failure-inducing in-
puts than the empirical study in [9].
1Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’11, May 21–28, 2011, Waikiki, Honolulu, HI, USA
Copyright 2011 ACM 978-1-4503-0445-0/11/05 ...$10.00
21
To perform our evaluation, we implemented our approach
in a prototype tool, camouflage , that we used to anonymize
170 inputs that cause failures in several real applications. In
this evaluation, we investigated a set of research questions
that are concerned with the feasibility, strength, and eﬀec-
tiveness of the approach. The results of the evaluation show
that: (1) the approach is feasible in that, for each input that
we considered, camouflage generated, in a matter of min-
utes, an anonymized version of the input that reproduced
the original failure; (2) the percentage of information re-
vealed by the anonymized inputs ranged from ≈60% (in the
worst case) to≈2%(in the best case); (3) even in the worst
case, the anonymized inputs were unlikely to reveal sensitive
information and could have been safely sent to developers;
and (4) our two techniques, path condition relaxation and
breakable input conditions, are eﬀective—for the cases con-
sidered, they reduced the amount of information revealed
by the approach by more than 30% on average, without sig-
niﬁcantly increasing the amount of time needed to generate
anonymized inputs. Although still preliminary, these results
are promising and show that the approach can be both eﬃ-
cient and eﬀective at anonymizing inputs that cause failures
in real applications and can improve on the state of the art.
The contributions of this paper are:
•An automated approach for input anonymization that
extends the state of the art through two novel tech-
niques: path condition relaxation and breakable input
conditions.
•A prototype tool that implements our approach for
Java applications.
•An extensive empirical study that demonstrates (1)
the feasibility and eﬀectiveness of our approach and (2)
the beneﬁts provided by path condition relaxation and
breakable input conditions.
The remainder of this paper is organized as follows: Sec-
tion 2 presents a motivating example for our work. Section 3
provides background information on dynamic symbolic ex-
ecution. Section 4 describes the details of our technique.
Section 5 presents our prototype implementation and our
empirical evaluation. Finally, Sections 6 and 7 discuss re-
lated work and present our conclusions and future work.
2. MOTIVATING EXAMPLE
In this section, we provide an example that will be used
in the remainder of the paper to illustrate our technique.
Figure 1 shows the code for the example, which is an ex-
cerpt from a credit card processing utility that accepts Visa,
American Express, and Discover credit cards. The program
reads, from the command line, the credit card number to be
processed and passes it to isValidCardNumber , which checks
whether the provided number is valid using the Luhn for-
mula (a simple checksumming algorithm). If the credit card
number is valid, the program invokes processCard , which
determines the type of the credit card number ( i.e., Visa,
American Express, or Discover) by checking the number’s
preﬁx and processes the card accordingly.
Function processCard contains a fault that can cause the
credit card processing utility to incorrectly handle certain
credit card numbers. On October 1, 2006, Discover’s pre-
ﬁx was changed from “650” to “65.” Because line 20 of
processCard was not updated to reﬂect this change, validDiscover card numbers that start with “65[1–9]”, such as
6521 2556 8414 3585 , are not correctly processed and would
cause an UnknownCardType exception to be thrown.
Although this program and fault are relatively simple to
understand, failures caused by this fault are good examples
of the type of scenario that the technique targets, for two
reasons. First, such failures directly involve sensitive infor-
mation (credit card numbers, in this case), which means
that users would likely be unwilling to provide developers
with the speciﬁc input that triggered the fault. Second, it
would be diﬃcult for commonly used approaches to provide
an anonymized version of the input that still triggers the
fault. In particular, input-minimization techniques would be
likely to fail. Minimization techniques that attempt to ﬁnd
a subset of the inputs that causes the same failure, such as
ddmin [29], will be unsuccessful because a valid credit card
number must have 16 digits, so no minimization would be
possible. Minimization techniques that perform alphabet
normalization by substituting some portions of the input
with a “don’t care” value ( e.g., tmin [5]) would also likely
fail, as most inputs generated in this manner will not satisfy
the Luhn formula. Even constructing anonymized inputs
by hand would be quite challenging, due to the diﬃculty of
generating inputs that pass the Luhn check.
3. DYNAMIC SYMBOLIC EXECUTION
In this section we brieﬂy provide necessary background
information on dynamic symbolic execution. At a high level,
dynamic symbolic execution techniques ( e.g., [8,15,24]) exe-
cute a program using symbolic inputs so that, at each point
in the computation, the state is expressed as a function of the
input, and the conditions on the input for reaching the cur-
rent location lare expressed as a conjunction of constraints
called a path condition .
Symbolic execution techniques generate path conditions
by ﬁrst associating a symbolic variable vkwith every element
of an input. For the example in Figure 1, for instance, each
character of the command line argument would be associated
with a unique symbolic variable: the ﬁrst character would be
associated with v0, the second character would be associated
withv1, and so on. Then as the program executes, program
statements are interpreted, and their eﬀect determines (1)
the symbolic state of the program, expressed in terms of
the symbolic variables, and (2) the current path condition.
As an example of a symbolic state, consider two subsequent
instructions S1:x=i+ (j−5) and S2:y=x∗2 whereiis
associated with a symbolic expression eandjis associated
with symbolic variable v1; the value of yin the symbolic
state afterS2’s execution would be the symbolic expression
“(e+ (v1−5))∗2”.
Path conditions are constructed incrementally, by append-
ing a new constraint to the current path condition every time
a predicate that depends on the symbolic state is executed
(i.e.,every time a predicate involves one or more values that
have an associated symbolic expression). The constraint en-
codes the condition on the symbolic variables under which
the predicate evaluates in the same way as the concrete ex-
ecution. To illustrate, consider the code in Figure 1, and
assume that the code is run with command line argument
6521 2556 8414 3585 . When line 24is ﬁrst executed, cis
associated with symbolic variable v15, has the concrete value
/prime5/prime, and is compared with character/prime0/prime. In this case, the
predicate evaluates to true because/prime5/prime≥/prime0/prime, so the con-
222   boolean isValidCardNumber(String ccn) { 1.  if(ccn.length() != 16) return false;  2.  int sum = 0; 3.  boolean alternate = false; 4.  int i = ccn.length() - 1; 5.  for (; i >= 0; i--) { 6.    int n = mapChar(ccn.charAt(i)); 7.    if (alternate) { 8.      n *= 2; 9.      if (n > 9) n = (n % 10) + 1;10.    }11.    sum += n;12.    alternate = !alternate;13.  }14.  return (sum % 10) == 0;   }   void processCard(String ccn) {15.  if(ccn.startsWith("4"))16.    //process Visa17.  else if(ccn.charAt(0) == '3' && (ccn.charAt(1) == '4' ||18.                                   ccn.chatAt(1) == '7'))19.    //process American Express20.  else if(ccn.startsWith("650"))21.    //process Discover22.  else23.    throw new UnknownCardType(ccn);   }   int mapChar(char c) {24.  return (c >= '0' && c <= '9') ? c-'0' : c-'A'+10;   }   void main(String[] args) {25.  if(isValidCardNumber(args[0]))26.    processCard(args[0]);   }Figure 1: Code excerpt for our motivating example.
straint “v15≥/prime0/prime” is appended to the path condition. Had
the predicate evaluated to false , the constraint “ v15</prime0/prime”
would have been appended instead. Figure 2 shows the com-
plete path condition generated for this example program and
input (including constraints due to library code).
4. AUTOMATED ANONYMIZATION
Before discussing the details of our approach, we use Fig-
ure 4 to illustrate, intuitively, the approach’s goal and the
context in which it operates. Given a program Pwith input
domainID, a failuref, and an input I∈IDthat causes
f, there is typically a subset of the input domain, If⊆ID,
such that every input in Ifcausesf.
In general, identifying Ifis not possible due to computabil-
ity issues. However, under the assumptions that we discuss
in Section 4.3, it is possible to identify a subset of If, such
that every input in this subset follows the same path as I
and causes f.
The approach proposed by Castro and colleagues [9] ( ba-
sic approach , hereafter) computes this subset using dynamic
symbolic execution. Given a speciﬁc input I, dynamic sym-
bolic execution is used to identify a subdomain of IDwhose
elements are inputs that cause the program to follow the
same path as I. More precisely, dynamic symbolic execution
is performed along the speciﬁc path of execution pcaused
byI; when failure foccurs at location l, the computed path
condition,φ, identiﬁes this target subdomain—the set of
all inputs, including I, that cause pto be executed and f
to occur at l. We call this set Iφ. (Note that, in general,
the fact that an input satisﬁes φdoes not necessarily imply
that such input will follow the same path as Ior, if it does,
causef. However, this tends to be the case in most practical
situations, as we discuss in detail in Section 4.3.) After com-
putingφ, an anonymized input I/primeis generated by leveraging
   boolean isValidCardNumber(String ccn) { 1.  if(ccn.length() != 16) return false;  2.  int sum = 0; 3.  boolean alternate = false; 4.  int i = ccn.length() - 1; 5.  for (; i >= 0; i--) { 6.    int n = mapChar(ccn.charAt(i)); 7.    if (alternate) { 8.      n *= 2; 9.      if (n > 9) n = (n % 10) + 1;10.    }11.    sum += n;12.    alternate = !alternate;13.  }14.  return (sum % 10) == 0;   }   void processCard(String ccn) {15.  if(ccn.startsWith("4"))16.    //process Visa17.  else if(ccn.startsWith("34") 18.          || ccn.startsWith("37"))19.    //process American Express20.  else if(ccn.startsWith("650"))21.    //process Discover22.  else23.    throw new UnknownCardType(ccn);   }   int mapChar(char c) {24.  return (c >= '0' && c <= '9') ? c-'0' : c-'A'+10;   }   void main(String[] args) {25.  if(isValidCardNumber(args[0]))26.    processCard(args[0]);   }Constraints from mapCharv0 ≥ '0' ∧ v0 ≤ '9' ∧... v15 ≥ '0' ∧ v15 ≤ '9'Constraints from processCardv0 ≠ '4' ∧v0 ≠ '3' ∧ v0 = '6' ∧ v1 = '5' ∧ v2 ≠ '0'Constraints from isValidCardNumber((v0 - '0') * 2) > 9 ∧ ((v2 - '0') * 2) ≤ 9 ∧((v4 - '0') * 2) ≤ 9 ∧ ((v6 - '0') * 2) > 9 ∧((v8 - '0') * 2) > 9 ∧ ((v10 - '0') * 2) ≤ 9 ∧((v12 - '0') * 2) ≤ 9 ∧ ((v14 - '0') * 2) > 9 ∧((((((v0 - '0') * 2) % 10) + 1) + ((v1 - '0') + (((v2 - '0') * 2) + ((v3 - '0') + (((v4 - '0') * 2) + ((v5 - '0') + (((((v6 - '0') * 2) % 10) + 1) + ((v7 - '0') + (((((v8 - '0') * 2) % 10) + 1) + ((v9 - '0') + (((v10 - '0') * 2) + ((v11 - '0') + (((v12 - '0') * 2) + ((v13 - '0') + (((((v14 - '0') * 2) % 10) + 1) + (v15 - '0')))))))))))))))) % 10) = 0Path condition:
Breakable input constraintsv0 ≠ '6' ∧ v1 ≠ '5' ∧ v2 ≠ '1' ∧ v3 ≠ '0' ∧ v4 ≠ '2' ∧v5 ≠ '5' ∧ v6 ≠ '5' ∧ v7 ≠ '6' ∧ v8 ≠ '8' ∧ v9 ≠ '4' ∧v10 ≠ '1' ∧ v11 ≠ '8' ∧ v12 ≠ '3' ∧ v13 ≠ '5' ∧ v14 ≠ '8' ∧ v15 ≠ '5'Original input:  6510 2556 8418 3585
6510 4546 3868 7524Basic approach:5189 7167 5228 9754Our improved approach:v0 ≠ '4' ∧(v0 ≠ '3' ∨ (v1 ≠ '4' ∧ v1 ≠ '7')) ∧(v0 ≠ '6' ∨ v1 ≠ '5' ∨ v2 ≠ '0')Anonymized input:6510 4546 3868 7524
Constraints from processCard (relaxed)v0 ≠ '4' ∧(v0 ≠ '3' ∨ (v1 ≠ '4' ∧ v1 ≠ '7')) ∧(v0 ≠ '6' ∨ v1 ≠ '5' ∨ v2 ≠ '0')Constraints from mapChar and isValidCardNumbersame as Figure 2Path condition:
Original input:  6510 2556 8418 3585Anonymized input:5189 7167 5228 9754Figure 2: Path condition for the code in Figure 1
and input 6510 2556 8414 3585 .
Anonymized input:6510 4546 3868 7524
Figure 3: Anonymized input generated by the basic
approach for the path condition in Figure 2.
a constraint solver to identify a satisfying assignment for φ.
For our motivating example, a possible assignment generated
by this approach is shown in Figure 3.
The strength of this approach ( i.e.,how well it prevents
information about Ifrom being revealed) depends on several
related aspects. First , the solution identiﬁed by the solver,
I/prime, should be independent from I(i.e., it should not be
possible to algorithmically recover IfromI/prime).Second ,Iφ
must be large enough to make an enumeration of the domain
impractical in a reasonable amount of time. (Because φcan
be derived from I/prime, just as it is derived from I, a suﬃciently
small domain allows for easily recovering I, which defeats the
purpose of the technique.) And third, the inputs in I/primeshould
be as diﬀerent as possible from their corresponding inputs
inI. Although there are cases where only a single value can
satisfy some constraints in φ(e.g.,in our example, v0must be
equal to/prime6/prime), in general, trying to prevent I/primefrom duplicating
Ireduces the likelihood that sensitive information can be
identiﬁed simply by examining I/prime.
We expect the ﬁrst aspect not to be a problem; most
constraint solvers utilize some randomness in their search
heuristics, so the selection of I/primecan be safely considered
pseudo-random. To address the second and third aspects,
and thus improve the strength of the approach, we extend
the basic approach by means of two novel techniques: path
condition relaxation and breakable input conditions. Path
condition relaxation addresses the second aspect—the size
ofIφ. It consists of a set of optimizations that specialize the
constraint generation part of dynamic symbolic execution
to increase the size of Iφ. Intuitively, the technique relaxes
overly restrictive constraints, thus strengthening the overall
approach by allowing for a larger number of solutions. Break-
able input conditions address the third aspect by forcing the
constraint solver to chose, whenever possible, values for I/prime
that are diﬀerent from the corresponding values in I.
In the rest of this section, we discuss in detail path condi-
tion relaxation, breakable input conditions, and the assump-
tions that underlie the overall approach.
323●˒ID: Input domain: Inputs that cause f: Inputs that satisfy  the path condition  derived from II': sanitizedinputI: sensitive inputIΦIfFigure 4: Intuitive view of a program domain.
4.1 Path Condition Relaxation
As we mentioned in the previous section, path condition
relaxation consists of several optimizations that modify the
way path conditions are generated, so as to increase the
number of solutions for the computed conditions. In the
following, we describe the four cases that our technique op-
timizes. Note that, because these optimization are designed
for our speciﬁc goal of ﬁnding inputs that cause a known
path to be executed, we believe that they are unlikely to
beneﬁt other dynamic symbolic execution techniques ( e.g.,
[8,15,24]) in any signiﬁcant way.
Array inequality. Typically, a comparison between two
arrays is performed by iterating over the arrays and perform-
ing a pairwise comparison between corresponding elements.
In traditional symbolic execution, the result of each compar-
ison would be recorded as a constraint in the path condition.
Therefore, only inputs that cause every comparison to eval-
uate the same way as the observed execution would satisfy
the path condition. For example, assume that a= [1,2,3],
b= [1,2,4],a’s elements are associated with symbolic ex-
pressionse1,e2, ande3, andb’s elements are associated with
symbolic expressions e4,e5, ande6. Checking the equality
of these arrays would add the constraints “ e1=e4”, “e2=e5”
and “e3/negationslash=e6” to the path condition.
The key intuition behind our optimization of array com-
parisons is that such comparisons are essentially atomic oper-
ations. Therefore, when arrays are not equal, path condition
relaxation can replace the constraints that encode the indi-
vidual comparisons with a constraint that simply requires
that at least one comparison evaluates to false (i.e., at
least one element is diﬀerent). For the previous example,
the constraint “ e1/negationslash=e4∨e2/negationslash=e5∨e3/negationslash=e6” would be added.
All variable assignments that satisfy the original constraints
also satisfy the relaxed one, but the latter is also satisﬁed by
many other assignments ( e.g.,a= [2,2,3],b= [1,2,4]).
Multi-clause conditionals. In many languages, commonly
used Boolean operators such as “and” and “or” are evaluated
with short-circuit or minimal evaluation semantics; only the
minimal amount of evaluation is done to determine the value
of the expression. For example, consider the conditional
“if(a1>5/bardbla2>5)”, wherea1anda2are associated with
symbolic expressions e1ande2, respectively. If a1’s value is
6, then “a2>5” will not be evaluated, as the outcome of the
condition is known after the evaluation of “ a1>5”. Because
the rest of the conditional is not evaluated, the path condi-
tion will only include the constraint “ e1>5”. Like for array
inequalities, such path conditions exclude a large number of
assignments that would cause the conditional to evaluate to
the same value ( e.g.,a= 0,b= 6).To generate relaxed path conditions for multi-clause con-
ditionals, our technique generates constraints that encode
all clauses in the conditional, not just those evaluated at
runtime. For example, if the aforementioned conditional
“if(a1>5/bardbla2>5)” were to evaluate to true, the con-
straint “e1>5∨e2>5” would be generated. Conjunctive
clauses and conditionals comprised of more than two clauses
are handled in a similar manner.
Switch statements. Switch statements are similar to multi-
clause conditionals in that multiple values can cause the
switch to jump to the same target ( i.e.,for case statements
that immediately fall through to their successor). In these
cases, a traditional technique would build a constraint of
the form “e/negationslash=c1∧···∧ /negationslash=cm−1∧e=cm”, whereeis
the symbolic expression associated with the value compared
by the switch statement, cmis the value in the ﬁrst case
statement that matches e, andc1,...,cm−1are the val-
ues of the cases that precede cmin the switch statement.
Conversely, the technique would generate the constraint
“e/negationslash=c1∧···∧e/negationslash=cm−1∧(e=cm∨···∨e=cn)”, where
cm,...,cnare the values of the cases that branch to the
same target as cm. In this way, the technique allows more
possible values of eto be considered.
Array reads. When symbolically executing array accesses,
concretization1is often performed. For example, assume that
a= [2,0,1]and thatxhas the value “0” and is associated
with symbolic expression ewhen statement “ if(a[x]>0)” is
executed. In the common case of a solver that cannot han-
dle symbolic array indices, ewould be concretized to “ 0”. In
these cases, concretizing may be unnecessarily restrictive, as
multiple values in an array could satisfy the same condition.
In our example, for instance, the values “2” at index 0 and
“1” at index 2 would both cause the conditional to evaluate
totrue, which means that ecan be equal to either “0” or
“2”. To generate these extended path conditions, our tech-
nique uses an approach similar in nature to the one proposed
by Elkarablieh and colleagues [14]. Essentially, a snapshot
of the contents of the array is encoded in the path condi-
tion as a sequence of ternary-expressions. Considering again
our example, the technique would generate the constraints
“((e== 0) ? 2 : ( e== 1) ? 0 : 1) >0∧e≥0∧e <3”.
These constraints ensure that the value of eis within the
bounds ofa, yet allow it to be any value that satisﬁes the
conditional.
To illustrate, Figure 5 shows how the above optimizations
would relax the constraints generated for our motivating
example. Although in this case the narrow constraints on
the ﬁrst two digits of the input nullify the eﬀects of relaxation,
in general such relaxation can result in the expansion of the
set of possible solutions, as shown empirically in Section 5.6.
4.2 Breakable Input Conditions
The use of a constraint solver to compute I/primeby solving
the path condition for a failing execution guarantees that I/prime
can reproduce the failure considered. However, because the
solver’s only goal is to ﬁnd a satisfying assignment, it may
1Concretization [15,24] is a technique used in dynamic sym-
bolic execution to handle constraints that the decision pro-
cedure in the constraint solver does not support. It works by
replacing symbolic expression in the problematic constraints
with their corresponding concrete values, so that the con-
straints become decidable.
424Breakable input conditionsv0 ≠ '6' ∧ v1 ≠ '5' ∧ v2 ≠ '1' ∧ v3 ≠ '0' ∧ v4 ≠ '2' ∧v5 ≠ '5' ∧ v6 ≠ '5' ∧ v7 ≠ '6' ∧ v8 ≠ '8' ∧ v9 ≠ '4' ∧v10 ≠ '1' ∧ v11 ≠ '8' ∧ v12 ≠ '3' ∧ v13 ≠ '5' ∧ v14 ≠ '8' ∧ v15 ≠ '5'Constraints from processCard (relaxed)v0 ≠ '4' ∧(v0 ≠ '3' ∨ (v1 ≠ '4' ∧ v1 ≠ '7')) ∧v0 = '6' ∧ v1 = '5' ∧ v2 ≠ '0')Constraints from mapChar and isValidCardNumbersame as Figure 2Path condition:
Original input:  6510 2556 8418 3585Anonymized input:6538 7578 2506 9852Figure 5: Path condition and anonymized input gen-
erated by our approach for the example in Figure 1
and input 6510 2556 8414 3585 .
coincidentally choose values that are in I, even when other
choices are possible, thus unnecessarily revealing information
about the original input. This is especially true when the do-
main of some of parts of the input is small. In our example,
for instance, there are only ten possible values for each digit,
and the domain is further reduced by the constraints on the
inputs. It is not surprising that, in a similar situation, an
anonymized credit card number could share many digits with
the original number. The anonymized input shown in Fig-
ure 3, where the unchanged values are underlined, illustrates
an instance of this problem, which we have also observed in
practice in our empirical evaluation (see Section 5.6).
To address this issue, we add to the path condition break-
able input conditions —constraints that explicitly prevent the
constraint solver from choosing values from I. More precisely,
for each symbolic variable, our technique adds a new con-
straint that speciﬁes that the symbolic variable should not
be equal to the original value of its corresponding input. For
our running example, the breakable input conditions for the
given input are shown in Figure 5.
When the conjunction of a path condition and the corre-
sponding breakable input conditions is satisﬁable, and the
solver is able to ﬁnd a solution for the resulting set of con-
straints,I/primeis guaranteed to be diﬀerent from I. In situations
where an element must have a speciﬁc value in order to cause
the failure, however, the breakable input conditions make the
path condition unsatisﬁable. This is the case for our example,
where the ﬁrst two digits of the input must be “65”, and the
other digits must pass the Luhn checksumming algorithm.
For this reason, our technique encodes each breakable input
condition as a discardable constraint, that is, a constraint
that the solver can ignore in order to ﬁnd a solution for an
otherwise unsatisﬁable set of constraints. Because the solver
would still try to ignore as few discardable constraints as
possible, encoding breakable input conditions as discardable
constraints forces the solver to choose I/primesuch that it is as
diﬀerent as possible from I. Figure 5 shows an example of
an anonymized input computed using breakable input con-
ditions, where only three values are shared with the original
input.
4.3 Assumptions
Our technique is based on two main assumptions on failure
f: (1)fis observable and can be encoded in the form of an
assertion, and (2) any input that satisﬁes path condition φnot only follows the same path as the original failure-inducing
inputI, but also results in the same failure f.
The ﬁrst assumption is common to all debugging-related
techniques and holds in most, if not all, cases. The sec-
ond assumption requires that the necessary conditions for
fare encoded in φ. The only cases in which this assump-
tion does not hold are non-determinism and implicit checks.
If the program being considered is non-deterministic, the
technique may not be able to generate anonymized inputs
that reproduce the failure because it cannot guarantee that
events such as thread switches always occur in the same or-
der. This problem is also common to all debugging-related
techniques and can be addressed by leveraging record/replay
infrastructure that supports deterministic replay ( e.g., [3]).
Implicit checks are checks that are performed by an en-
tity that is external to the application and, thus, are not
observable by the symbolic execution. A typical example of
implicit checks is the set of checks performed by the under-
lying runtime system, such as checks that may result in a
division-by-zero or out-of-memory error.
Because these checks are not performed by the applica-
tion, they would not be included as constraints in the path
conditionφ, and an input that satisﬁes φmay fail to repro-
ducef. Although this issue exists, we believe it is of limited
relevance in most cases, for two reasons. First, although
(some types of) implicit checks occur frequently, the major-
ity of them are likely to be irrelevant because, as conﬁrmed
by our evaluation, they constrain variables that are not di-
rectly or indirectly related to the failure. Therefore, in the
worst case, the technique could simply ignore cases for which
the anonymized input cannot reproduce fand focus on the
remaining failures. Second, we can automatically account
for implicit checks that occur within the runtime system by
making them explicit. To account for division-by-zero errors,
for instance, the technique could easily preprocess the code
and add an explicit check of the denominator’s value every
time a division is encountered.
5. EVALUATION
To evaluate our technique, we implemented it in a proto-
type tool, called camouflage , and investigated the follow-
ing research questions:
RQ1: Feasibility—Can the approach generate, in a reason-
able amount of time, anonymized inputs that reproduce
the original failure?
RQ2: Strength—How much information about the original
failure-inducing inputs is revealed by the approach?
RQ3: Eﬀectiveness—Are the anonymized inputs generated
by our approach safe to send to developers?
RQ4: Improvement—Does the use of path condition relax-
ation and breakable input conditions provide any ben-
eﬁts over the basic approach?
Note that RQ2 provides an objective assessment of the tech-
nique; it does not make any assumptions about whether
the revealed information is actually sensitive. Conversely,
RQ3 does take into account whether the information that is
revealed is indeed sensitive.
The remainder of this section discusses camouflage , our
subjects, and our experimental protocol and results.
5255.1 Prototype Tool
Ourcamouflage tool is a prototype implementation of
the technique for applications written in the Java language.
It consists of two separate components: the constraint gen-
erator and the input anonymizer. (The record/replay is
assumed to be an external component.) The current imple-
mentation of the constraint generator is an extension to Java
PathFinder (JPF), an explicit state software model checker
for Java software ( http://javapathfinder.sourceforge.net/ ).
To assign symbolic variables to an application’s inputs, we
use JPF’s method interception capabilities to wrap all native
methods in the java.io package. Because, ultimately, all
ﬁle and network inputs are read by these methods, camou-
flage can easily associate a symbolic variable with every
input read from these sources. To handle other sources of
input, we also wrap the main method (to handle command
line arguments) and the appropriate methods for reading
environment variables and system properties. By default,
camouflage assumes that all inputs are sensitive. How-
ever, it also allows users to specify that inputs read from
speciﬁc sources should not be associated with a symbolic
variable. This feature is useful, for example, in cases where
it is known that inputs read from certain ﬁles or network
streams are not sensitive and do not need to be anonymized.
To implement our specialized path condition generation
(see Section 4.1), we use JPF’s bytecode overloading facilities
to replace each Java bytecode with a modiﬁed version that
replicates the instruction’s original semantics while also per-
forming the necessary steps for generating path conditions.
Finally, to identify when failures occur, we use JPF’s VMLis-
tener interface to intercept uncaught exceptions and failed
assertions. When the execution reaches the point of failure,
and the failure occurs, the constraint generator writes the
recorded path condition and the breakable input conditions
to disk.
The input anonymizer is implemented as a set of Ruby
scripts and works as follows. First, it transforms the con-
straints produced by the constraint generator into a format
understood by the constraint solver. Then, it invokes the
constraint solver to ﬁnd a solution for the constraints. Fi-
nally, it transforms the solution provided by the constraint
solver into a concrete input that can be sent to develop-
ers. As our constraint solver, we choose YICES [12] because,
among the constraint solvers that we know, it is the only one
that supports both discardable constraints (see Section 4.2)
and bit vector operations. Using bit vectors for symbolic
variables allows our implementation to handle bit shifts and
masks, which are commonly used in the Java libraries. How-
ever, using bit vectors does have one drawback: currently, no
constraint solver, including YICES, supports ﬂoating point
arithmetic on bit vectors. This means that, currently, cam-
ouflage does not support symbolic ﬂoats or doubles.
5.2 Subjects
The goal of the technique is to generate anonymized in-
puts that cause the same failures as the original input while
revealing as little information as possible. To suitably eval-
uate the technique with respect to this goal, we selected
applications with known faults that process information
that can be considered private or sensitive: NanoXML (16
faults), which is available from SIR (Software-artifact In-
frastructure Repository, http://sir.unl.edu/ ); a Java version
ofprinttokens (2 faults), whose original C implementa-tion is also available from SIR; the address book compo-
nent of the Columba email client version 1.4 (1 fault) ( http:
//www.columbamail.org ); and version 1.0 of htmlparser (1 fault)
(http://htmlparser.sourceforge.net ). For each fault, we selected
multiple failure-inducing inputs. For NanoXML and printto-
kens, we used the inputs provided with the two applications.
ForColumba andhtmlparser , we constructed representative
inputs by hand. In total, we used 170 failure-inducing inputs
that range in size from several hundred bytes to over ﬁve
megabytes.
5.3 RQ1: Feasibility
The primary goal of our ﬁrst research question is to assess
whether the amount of time needed to generate anonymized
inputs is reasonable and whether the anonymized inputs
reproduce the original failure. To generate the data necessary
for investigating these questions, we proceeded as follows:
for each failure-inducing input, we used camouflage to
run the application and generate an anonymized version of
such input. In addition, we recorded two measurements: (1)
the amount of time needed by camouflage to generate the
path condition and (2) the amount of time needed by the
constraint solver to solve the generated path condition.
The top-half of Figure 6 presents a bar chart that shows,
for each fault, the average amount of time camouflage
needed to generate path conditions. The bottom-half of the
ﬁgure shows the average amount of time needed by the con-
straint solver to solve the generated path conditions. As
the ﬁgure shows, the amount of time needed to generate
path conditions ranges from an average of 162 seconds (for
printtokens ) to an average of 533 seconds (for htmlparser ).
The amount of time needed to solve the path conditions
ranges from an average of 0.1 seconds (for printtokens ) to
an average of 15.7 seconds (for Columba ). Overall, for all
of the failure-inducing inputs that we considered, camou-
flage was able to generate an anonymized version in less
than 10 minutes. Because camouflage is designed to run
oﬀ-line, during idle periods when free cycles are available
(e.g., overnight), the approach is clearly practical. Users will
only experience the overhead caused by the record/replay
technique used, which have been shown to be in the single
digits for modern approaches [3,11].
To determine whether the anonymized inputs reproduce
the original failures, we executed our subject applications
with such inputs and manually inspected the outcomes. We
found that all 170 anonymized inputs produced by camou-
flage successfully reproduced the original failure.
5.4 RQ2: Strength
To assess the strength of camouflage ’s anonymization,
we used two metrics: bits of information revealed and residue.
The ﬁrst metric, bits of information revealed , is a standard
entropy measure that has been used in related work [9,27].
Intuitively, it measures how much information is revealed
by the technique by calculating how many inputs satisfy
the path condition ( i.e., the number of inputs in Iφ). In
general, an anonymized input reveals/summationtext
i∈I/prime|log2(xi)|bits
of information about I, wherexiis the number of solutions
to the constraints involving idivided by the size of i’s input
domain. For example, assume that i/prime
0is an 8-bit character
(i.e., its input domain contains 256 values) and that 5 of
the 256 possible values satisfy the constraints on i/prime
0. In
this case,i/prime
0reveals approximately 5.76of the 8total bits
626columbaprinttokens1printtokens2nanoxmlv01s01nanoxmlv01s03nanoxmlv01s05nanoxmlv01s06nanoxmlv02s02nanoxmlv02s03nanoxmlv02s04nanoxmlv02s05nanoxmlv02s06nanoxmlv02s07nanoxmlv03s04nanoxmlv03s09nanoxmlv03s10nanoxmlv05s03nanoxmlv05s05nanoxmlv0509htmlparserexecutiontime (s)fault runtime solvetimev01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s05v01s06v01s06v01s06v01s06v01s06v01s06v01s06v01s06v01s06v01s06v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s03v02s03v02s04v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s07v02s07v02s07v02s07v02s07v03s04v03s09v03s10v03s10v03s10v03s10v03s10v03s10v03s10v03s10v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s05v05s093.850.3943.850.3673.80.3803.850.4383.750.3963.810.3543.810.3923.80.3883.810.0003.850.0003.80.4043.810.3953.840.0003.850.4163.810.0003.80.0003.750.0003.850.3713.80.4233.850.4483.810.4163.850.4013.850.4113.810.4243.810.4383.760.3883.770.4363.80.4643.850.4163.820.0003.750.4413.810.4313.90.0003.860.0003.460.4633.410.4603.450.4883.450.4363.40.0003.470.4923.450.4763.470.5003.470.4883.450.4783.450.0003.550.0003.450.0003.40.4973.440.4863.260.4773.80.0003.650.4803.650.4363.710.5063.760.4743.750.4913.70.4653.760.0003.750.4313.80.46940.4253.660.4833.50.4553.50.4973.50.4483.460.4923.80.4653.80.4843.810.4763.80.5003.850.5003.80.5283.850.4883.80.5003.850.0003.880.5323.450.5243.350.0003.510.5423.550.5103.510.4913.50.5093.550.5143.550.4523.510.4403.490.4903.560.4893.550.5003.550.5203.50.4403.60.5163.510.5133.50.4643.50.4523.910.5923.650.3563.470.5053.570.4643.350.5683.530.4523.460.4963.450.4383.80.4393.760.4663.80.4393.80.4833.810.0003.820.4283.850.4393.860.0003.80.4173.90.3703.950.3963.510.4283.460.3833.50.4413.30.3793.50.3513.90.4493.530.3823.50.3603.350.4023.550.3853.410.4313.490.4534.020.3673.650.4374.050.3763.950.3864.050.4564.060.4224.10.3714.10.4354.060.4524.010.3874.060.4104.110.4864.060.4154.050.4394.170.4214.150.36440.4854.150.45840.3874.050.4484.050.4404.050.3884.060.4444.050.4114.050.4054.060.4604.010.3764.050.4284.050.48140.3594.110.4074.060.4774.110.4114.050.4444.050.5274.050.3794.050.4333.370.4593.30.438fault runtimeconstraintRuntimeaddressbookhtmlparsertokens1tokens2v01s01v01s03v01s05v01s06v02s02v02s03v02s04v02s05v02s06v02s07v03s04v03s09v03s10v05s03v05s05v05s095.42015.700325.208.8909.100533.402.7000.100162.002.7000.100162.003.8170.301229.043.4510.351207.083.2600.477195.603.7330.375223.983.7410.455224.483.4000.262204.003.5100.542210.603.5290.487211.723.6990.408221.973.5440.405212.643.5000.351210.003.9000.449234.003.5630.402213.754.0600.425243.583.3700.459202.203.3000.438198.00
0150300450600198202244214234210213222212211204224224196207229162162533325
00.20.40.60.810.440.460.420.400.450.350.410.410.490.540.260.450.380.480.350.300.100.109.1015.70constraint solver time (s)fault runtime solvetimev01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s01v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s03v01s05v01s06v01s06v01s06v01s06v01s06v01s06v01s06v01s06v01s06v01s06v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s02v02s03v02s03v02s04v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s05v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s06v02s07v02s07v02s07v02s07v02s07v03s04v03s09v03s10v03s10v03s10v03s10v03s10v03s10v03s10v03s10v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s03v05s05v05s093.850.3943.850.3673.80.3803.850.4383.750.3963.810.3543.810.3923.80.3883.810.0003.850.0003.80.4043.810.3953.840.0003.850.4163.810.0003.80.0003.750.0003.850.3713.80.4233.850.4483.810.4163.850.4013.850.4113.810.4243.810.4383.760.3883.770.4363.80.4643.850.4163.820.0003.750.4413.810.4313.90.0003.860.0003.460.4633.410.4603.450.4883.450.4363.40.0003.470.4923.450.4763.470.5003.470.4883.450.4783.450.0003.550.0003.450.0003.40.4973.440.4863.260.4773.80.0003.650.4803.650.4363.710.5063.760.4743.750.4913.70.4653.760.0003.750.4313.80.46940.4253.660.4833.50.4553.50.4973.50.4483.460.4923.80.4653.80.4843.810.4763.80.5003.850.5003.80.5283.850.4883.80.5003.850.0003.880.5323.450.5243.350.0003.510.5423.550.5103.510.4913.50.5093.550.5143.550.4523.510.4403.490.4903.560.4893.550.5003.550.5203.50.4403.60.5163.510.5133.50.4643.50.4523.910.5923.650.3563.470.5053.570.4643.350.5683.530.4523.460.4963.450.4383.80.4393.760.4663.80.4393.80.4833.810.0003.820.4283.850.4393.860.0003.80.4173.90.3703.950.3963.510.4283.460.3833.50.4413.30.3793.50.3513.90.4493.530.3823.50.3603.350.4023.550.3853.410.4313.490.4534.020.3673.650.4374.050.3763.950.3864.050.4564.060.4224.10.3714.10.4354.060.4524.010.3874.060.4104.110.4864.060.4154.050.4394.170.4214.150.36440.4854.150.45840.3874.050.4484.050.4404.050.3884.060.4444.050.4114.050.4054.060.4604.010.3764.050.4284.050.48140.3594.110.4074.060.4774.110.4114.050.4444.050.5274.050.3794.050.4333.370.4593.30.438fault runtimeconstraintRuntimeaddressbookhtmlparsertokens1tokens2v01s01v01s03v01s05v01s06v02s02v02s03v02s04v02s05v02s06v02s07v03s04v03s09v03s10v05s03v05s05v05s095.42015.700325.208.8909.100533.402.7000.100162.002.7000.100162.003.8170.301229.043.4510.351207.083.2600.477195.603.7330.375223.983.7410.455224.483.4000.262204.003.5100.542210.603.5290.487211.723.6990.408221.973.5440.405212.643.5000.351210.003.9000.449234.003.5630.402213.754.0600.425243.583.3700.459202.203.3000.438198.00
0150300450600198202244214234210213222212211204224224196207229162162533325
00.20.40.60.810.440.460.420.400.450.350.410.410.490.540.260.450.380.480.350.300.100.109.1015.70Figure 6: Bar charts showing, for each fault, the average amount of time needed to (1) execute the subject and
generate the corresponding path condition (top) and (2) ﬁnd a solution using the constraint solver (bottom).
columbaprinttokens1printtokens2nanoxmlv01s01
nanoxmlv03s10nanoxmlv05s03nanoxmlv05s05nanoxmlv0509htmlparser% residue% bitsrevealed
nanoxmlv01s03nanoxmlv01s05nanoxmlv01s06nanoxmlv02s02nanoxmlv02s03nanoxmlv02s04nanoxmlv02s05nanoxmlv02s06nanoxmlv02s07nanoxmlv03s04nanoxmlv03s09addressbookhtmlparserprinttokens1printtokens2v01s01v01s03v01s05v01s06v02s02v02s03v02s04v02s05v02s06v02s07v03s04v03s09v03s10v05s03v05s05v05s09020406080100addressbookhtmlparserprinttokens1printtokens2v01s01v01s03v01s05v01s06v02s02v02s03v02s04v02s05v02s06v02s07v03s04v03s09v03s10v05s03v05s05v05s09020406080100
Figure 7: Box plots showing, for each fault, the bits of information revealed as a percentage of the total
number of bits in the input (top) and the percentage of residue (bottom) that remains after anonymization.
of information about i0. Because computing xiexactly is
diﬃcult and expensive when constraints involve multiple
input elements, we chose to use an algorithm by Martin that
quickly provides an accurate over-approximation for xi[22].
The bits-of-information-revealed metric provides a good
starting point for assessing the strength of the anonymization.
However, its results can be misleading. For example, it
is possible to decrease the amount of bits revealed while
large portions of the input remain unchanged. To illustrate
this situation, consider a program that reads 10 characters
as input. Assume that the constraints on each of the last
5 characters have 10 possible solutions, while the ﬁrst 5
characters must remain the same. If the number of possible
solutions for the second 5 characters is increased from 10 to
200, the amount of information revealed decreases from 63.3
bits to 41.7 bits. This decrease correctly indicates that it is
now more diﬃcult to recover the original input, but it fails
to indicate that half of the input is unchanged, a fact that
may be important, especially if the ﬁrst half of the input is
more sensitive than the second half.
Our second metric, residue , addresses this shortcoming.
Residue is essentially the percentage of bits that remain un-
changed after anonymization. For the example mentioned
in the previous paragraph, the percentage of residue would
not change if the number of possible solutions for the sec-
ond 5 characters increased from 10 to 200, thus indicating
that anonymization may not have been as eﬀective as the
bits of information revealed metric would suggest. By usingboth metrics, we can assess the strength of the anonymiza-
tion performed by camouflage from multiple perspectives
and better judge how much information about the failure-
inducing inputs is revealed by their anonymized versions.
Figure 7 presents two box-and-whisker plots that show, for
each fault and failure-inducing input, the bits of information
revealed by the anonymized input as a percentage of the
total number of bits in the failure-inducing input (top) and
the percentage of residue in the anonymized input (bottom).
For the subjects we considered, the average percentage of
bits of information revealed ranges from 2.3%to76.5%, with
an average of 30 .6%, and the average percentage of residue
ranges from 1 .5% to 65%, with an average of 30%.
Although these results show that, under some circum-
stances, camouflage cannot generate fully anonymized in-
puts, they are also encouraging; the majority of anonymized
inputs produced by camouflage reveal only a limited amount
of information. (Moreover, as the results discussed in the
next section show, the information revealed is unlikely to
be sensitive.) These results also suggest that the strength
of the anonymization performed by camouflage depends
not only on the subject application, but also on the speciﬁc
input considered and can vary widely even among diﬀerent
inputs that trigger the same fault.
5.5 RQ3: Effectiveness
The results of RQ2’s investigation provide an objective
measure of the anonymization performed by camouflage .
727<!DOCTYPE Foo [   <!ELEMENT Foo (ns:Bar)>   <!ATTLIST Foo       xmlns CDATA #FIXED 'http://nanoxml.n3.net/bar'       a     CDATA #REQUIRED>   <!ELEMENT ns:Bar (Blah)>   <!ATTLIST_ns:Bar       xmlns:ns CDATA #FIXED 'http://nanoxml.n3.net/bar'>   <!ELEMENT Blah EMPTY>   <!ATTLIST_Blah       x    CDATA #REQUIRED       ns:x CDATA #REQUIRED>]><!-- comment --><Foo a='test' b='test1' c='test2'>vaz   <ns:Bar>       <Blah x="1" ns:x="2"/>   </ns:Bar></Foo>(a) Failure-inducing input for NanoXML .
...Wayne|Bartley|Bartley|Wayne|wbartly@acp.com||Ronald|Kahle|Kahle|Ron|ron.kahle@kahle.com||Wilma|Lavelle|Lavelle|Wilma||lavelle678@aol.com|Jesse|Hammonds|Hammonds|Jesse||hamj34@comcast.com|Amy|Uhl|Uhl|Amy|uhla@corp1|com|uhla@gmail.com|Hazel|Miracle|Miracle|Hazel|hazel.miracle@corp2.com||Roxanne|Nealy|Nealy|Roxie||roxie.nearly@gmail.com|Heather|Kane|Kane|Heather|kaneh@corp2.com||Rosa|Stovall|Stovall|Rosa||sstoval@aol.com|Peter|Hyden|Hyden|Pete||peteh1989@velocity.net|Jeffrey|Wesson|Wesson|Jeff|jwesson@corp4.com||Virginia|Mendoza|Mendoza|Ginny|gmendoza@corp4.com||Richard|Robledo|Robledo|Ralph|ralphrobledo@corp1.com||Edward|Blanding|Blanding|Ed||eblanding@gmail.com|Sean|Pulliam|Pulliam|Sean|spulliam@corp2.com||Steven|Kocher|Kocher|Steve|kocher@kocher.com||Tony|Whitlock|Whitlock|Tony||tw14567@aol.com|Frank|Earl|Earl|Frankie|||Shelly|Riojas|Riojas|Shelly|srojas@corp6.com||...(b) Failure-inducing input for Columba .
<?xml version="1.0" encoding="UTF-8" ?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><title>james clause @ gatech | home</title><style type="text/css" media="screen" title=""><!--/*--><![CDATA[<!--*/  body {    margin: 0px;.../*]]>*/--></style></head><body>  ...</body>(c) Failure-inducing input for htmlparser .
Figure 8: Example failure-inducing inputs.
However, without considering whether the revealed infor-
mation is actually sensitive, it is diﬃcult to accurately as-
sess if anonymized inputs can safely be sent to developers.
Performing such an assessment is the goal of the study ad-
dressing RQ3. In this study, we conducted an in-depth,
qualitative assessment of all the anonymized inputs gener-
ated by camouflage that takes into account whether the
revealed information is sensitive. To make this determina-
tion, we manually inspected each failure-inducing input and
its anonymized version. (As the discussion of the speciﬁc
anonymization cases in the rest of this section will show, for
the subjects we considered the distinction between sensitive
and not sensitive inputs was fairly clear-cut.) For all 170
anonymized inputs, we found that they did not reveal any
information that we believe to be sensitive. In the rest of
this section, we provide a detailed description of our anal-
ysis for three anonymized inputs: one for NanoXML , one for
the address book component of Columba , and one for html-
parser . We chose to present these inputs because, among
the failure-inducing inputs for each application, they have
the highest percentage of bits of information revealed and
residue. Consequently, they are the most likely to actually
reveal sensitive information.
Figures 8a, 8b, and 8c show representations of the portions
of the original inputs that can and cannot be changed ( i.e.,
residue) for the inputs we are presenting. (We shortened the
inputs to make them ﬁt.) In these ﬁgures, portions of the
inputs that cannot be changed are underlined.
NanoXML. The input for NanoXML shown in Figure 8a
is an XML ﬁle available from the SIR repository. The fault
triggered by this input causes NanoXML to incorrectly han-
dle closing tags. As the ﬁgure shows, the portions of this
ﬁle that cannot be changed do not contain any sensitive
information. The literals “DOCTYPE”, “ATTLIST”, and
“FIXED” are keywords of the language used to specify doc-
ument type deﬁnitions, and NanoXML speciﬁcally checks for
their presence. Similarly, the angle brackets, exclamation
points, hyphens, double quotation marks, backslashes, equals
signs, and white spaces (represented by “ ”) that cannot be
changed are necessary because they deﬁne the structure of
the XML document. Conversely, portions of the input that
are likely to contain sensitive information, such as XML tag
names, attribute values, and tag bodies, can all be changed
without preventing the modiﬁed input from reproducing the
failure. Therefore, although a relatively large percentage ofthe ﬁle cannot be changed ( ≈65%), we can consider the
input to be anonymized because it contains, to the best of
our knowledge, no real sensitive information.
Columba. The input for Columba shown in Figure 8b is
a pipe(“|”)-separated-value ﬁle of contact information. The
entries in each row are a contact’s ﬁrst name, last name,
sort key, nickname, email address, work phone, and home
phone (albeit none of the entries shown actually has a phone
number). This ﬁle triggers a fault in a section of Columba
that handles the email portion of each row. Columba assumes
that each contact has an email address. If this assumption
is violated, as it is by the second-to-last row in the part of
the input shown in Figure 8b, an exception is thrown. The
results of anonymizing this input are similar to the results of
anonymizing the input for NanoXML ; the structural elements
of the ﬁle ( i.e., the commas that separate the individual
ﬁelds) cannot be changed, but the non-structural elements
(i.e.,each contact’s ﬁrst name, last name, and so on) can all
be changed. Consequently, also in this case, we can conclude
that the input produced by camouflage is anonymized ( i.e.,
contains no sensitive information) and can be safely sent to
developers.
HtmlParser. The input for htmlparser shown in Fig-
ure 8c is an HTML ﬁle taken from the website of one of
the authors. The fault that this input triggers is in the
tag-processing portion of htmlparser , which scans for pairs
of angle brackets and backslashes. This version of html-
parser incorrectly handles several angle brackets around the
CDATA portion of the ﬁle, which causes a mismatch between
opening and closing brackets and leads, ultimately, to an ex-
ception being thrown. For this input, the only parts that
cannot be changed are the angle brackets and backslashes,
which are explicitly matched by the tag parser. Again, the
portions of the input that are most likely to be sensitive—the
contents of the web page and the style sheet—have all been
changed.
Overall conclusions. For the three failure-inducing in-
puts that we presented above, and the additional 167 in-
puts that we considered in our evaluation, camouflage
was always able to anonymize the inputs by removing all
of the portions of the inputs that we considered to be sen-
sitive. These results are encouraging because they provide
initial, yet strong evidence that camouflage can generate
anonymized failure-inducing inputs that could be safely sent
to developers.
828columbaprinttokens1printtokens2nanoxmlv01s01nanoxmlv01s03nanoxmlv01s05nanoxmlv01s06nanoxmlv02s02nanoxmlv02s03nanoxmlv02s04nanoxmlv02s05nanoxmlv02s06nanoxmlv02s07nanoxmlv03s04nanoxmlv03s09nanoxmlv03s10nanoxmlv05s03nanoxmlv05s05nanoxmlv0509htmlparserbits_basebits_path% Bits of Informationresidue_baseresidue_pathResidueaddressbookhtmlparserprinttokens1printtokens2v01s01v01s03v01s05v01s06v02s02v02s03v02s04v02s05v02s06v02s07v03s04v03s09v03s10v05s03v05s05v05s090.000.005.00%0.000.003.00%8.052.0374.78%7.373.5451.97%0.000.003.58%1.451.452.25%0.000.001.56%2.382.380.60%54.3938.1129.93%56.7138.6531.85%38.0015.6458.84%48.7212.2074.96%3.172.5419.87%3.803.1616.84%71.5751.2728.36%69.0346.5632.55%59.9540.7132.09%62.2337.0440.48%8.077.0213.01%8.797.9110.01%1.611.2919.88%30.976.7778.14%18.5916.928.98%31.5015.9449.40%54.1836.9631.78%56.2833.7640.01%68.1328.1258.73%65.9426.6759.55%8.776.7523.03%29.804.6484.43%88.7275.8114.55%81.2559.8726.31%32.5319.1241.22%40.4317.4056.96%51.8932.1837.98%56.6137.8233.19%0.630.6315.47%3.163.168.50%0.000.009.65%2.092.093.60%
0%25%50%75%100%4%9%33%57%26%84%60%40%49%78%10%40%33%17%75%32%1%2%52%3% 10%15%38%41%15%23%59%32%9%20%13%32%28%20%59%30%2%4%75%5%% Bits of InformationResidueImprovementFigure 9: Improvement provided by our approach in terms of bits of information revealed and residue.
5.6 RQ4: Improvement
RQ4 investigates the beneﬁts provided by path condi-
tion relaxation and breakable input conditions. Ideally, we
would have liked to answer RQ4 by comparing camouflage
against Castro and colleagues’ implementation. Unfortu-
nately, their implementation (1) targets x86 binaries and (2)
is not publicly available. We therefore performed a proxy
study in which we compared camouflage with a Java im-
plementation of Castro and colleagues’ technique that we
developed using JPF’s symbolic execution engine. Speciﬁ-
cally, we compared, for the two tools, the time needed to
generate anonymized inputs, the percentage of bits of infor-
mation revealed by such anonymized inputs, and the per-
centage of residue between the original and the anonymized
inputs. (These measures are the same ones that we used in
Sections 5.3 and 5.4.)
Figure 9 shows the average improvement achieved by cam-
ouflage over our implementation of Castro and colleagues’
technique, in terms of percentage of bits of information re-
vealed and percentage of residue. As the ﬁgure shows, for
all of the 20 faults considered, camouflage provides better
results. On average, the anonymized inputs generated us-
ingcamouflage revealed 30% less bits of information and
contained 40% less residue. Moreover, the use of path con-
dition relaxation and breakable input constraints increased
only marginally the time needed to generate anonymized
inputs. With the caveat of a potential implementation bias,
these results provide evidence that the use of path condi-
tion relaxation and breakable input constraints can substan-
tially improve the basic technique and the overall input-
anonymization process.
5.7 Threats to Validity
Because we used a limited number of subjects and faults,
and the majority of the considered faults are within one
subject, our results may not generalize. However, both the
subjects and the faults we considered are real, and it is rea-
sonable to assume that inputs to these applications may con-
tain sensitive data. Therefore, we believe that these results,
albeit preliminary, are promising and motivate further re-
search. An additional threat is that we determined whether
the information remaining after anonymization is sensitive,
which may introduce bias. Although a human study could
have eliminated this threat, we do not think that the eﬀort
involved in such a study is justiﬁed at this stage of the re-
search. Moreover, as we mentioned earlier and showed in
Section 5.5, for the cases considered the distinction between
sensitive and non-sensitive data was fairly clear-cut.
6. RELATED WORK
The technique most closely related to our approach is that
by Castro and colleagues [9], which we extended through thenovel concepts of path condition relaxation and breakable
input conditions. In addition, we perform a more extensive
and thorough evaluation on a wider range of inputs and dif-
ferent application types. Finally, our evaluation shows that,
for the cases considered, our extensions can considerably
improve the eﬀectiveness of input anonymization.
Broadwell and colleagues’ Scrash tool uses a form of se-
cure information ﬂow (or dynamic tainting) to identify where
sensitive information is stored inside a crash dump [7]. Dur-
ing an execution, an initial set of data is marked as sensitive.
As the execution progresses, any data that is derived from
this initial set is also marked as sensitive. If a crash occurs,
any data that is marked as sensitive is excluded from the
crash dump that is sent to developers. The main practical
limitation of this approach is the diﬃculty in identifying
the initial set of sensitive data—it is unreasonable to expect
users to perform this step, and relying on the application’s
developers is equivalent to trusting them with access to the
sensitive data. Furthermore, unlike our technique, Scrash
does not attempt to anonymize sensitive data, but simply
avoids sending it to the developers, which can result in a
loss of potentially useful information. In addition, their tech-
nique is performed on-line and, unlike our technique, may
subject users to high runtime overheads.
Wang and colleagues propose an approach, Panalyst [27],
that aims to reconstruct failure-inducing inputs on devel-
opers’ machines by using a combination of dynamic taint
analysis, symbolic execution, and collection of answers to
questions sent to a client running on the user’s machine.
Answers provided by the client determine which direction
the symbolic execution takes when encountering branches
that depend on sensitive information and what values are
read or written by memory accesses through sensitive point-
ers. The client will answer all questions that do not involve
sensitive information, but will only disclose up to a prede-
termined amount of sensitive information. Besides involving
a considerable amount of infrastructure, the main practical
limitation of this technique is, like for Scrash , the diﬃculty
in identifying which information is sensitive.
In addition to these closely related techniques, there is
also a large body of work concerned with anonymizing data
sets before they are released to the public ( e.g., [25,28,30]).
These approaches aim to maintain statistical properties of
the data ( e.g., the age distribution across a population) while
preventing users of the data from uniquely identifying a spe-
ciﬁc record ( e.g., the age of a speciﬁc individual). Typically,
this is accomplished by merging data ( e.g., grouping ages
0–18) or by adding random noise to the data. Because the
conditions for reproducing a failure are typically very speciﬁc,
these approaches are not suitable for our scenario.
White-box dynamic test generation and fuzzing techniques
(e.g., [8, 15, 24, 26]) are also tangentially related to our ap-
929proach. Instead of solving path conditions to obtain a new
set of inputs to reach a known failure, they iteratively gen-
erate and solve new path constraints to explore as many
execution paths as possible.
7. CONCLUSIONS AND FUTURE WORK
In this paper, we presented an approach for automati-
cally anonymizing failure-inducing inputs. Our approach ex-
tends a previously presented technique [9] through the novel
concepts of path condition relaxation and breakable input
conditions. We also presented camouflage , a prototype
implementation of the approach for Java programs, and an
empirical evaluation of camouflage on 170 failure-inducing
inputs for several real applications. The results of the eval-
uation show that the approach is feasible, eﬀective, and
improves on the state of the art. For each failure-inducing
input that we considered, camouflage was able to generate
an anonymized version that reproduced the original failure
in less than 10 minutes. Moreover, manual investigation of
the anonymized inputs showed that they did not reveal any
potentially sensitive information contained in the original
inputs, and could therefore be safely sent to developers.
In future work, we will investigate additional metrics for
quantifying the strength of the anonymization. Bits of in-
formation revealed and residue constitute a useful starting
point, but they fail to account for all aspects of privacy loss.
Most importantly, they do not consider the relative sensi-
tivity of diﬀerent parts of the inputs. We also believe that
typical users would ﬁnd these metrics diﬃcult to use, as they
provide no indication of what is an acceptable percentage of
bits of information revealed or residue. As our evaluation
shows, even when an anonymized input reveals a relatively
large amount of information, it may still be safe to collect.
We will also investigate how input minimization techniques
can be used, together with our technique, to improve the
anonymization process.
8. REFERENCES
[1] Privacy Statement for the Microsoft Error Reporting
Service, 2011. http://oca.microsoft.com/en/dcp20.asp .
[2] Technical Note TN2123: CrashReporter, 2011.
http://developer.apple.com/technotes/tn2004/tn2123.html .
[3] The Amazing VM Record/Replay Feature in VMware
Workstation 6, 2011. http:
//blogs.vmware.com/sherrod/2007/04/the_amazing_vm_.html .
[4] Windows Error Reporting: Getting Started, 2011.
http://www.microsoft.com/whdc/maintain/StartWER.mspx .
[5] tmin: Fuzzing Test Case Optimizer, 2011.
http://code.google.com/p/tmin/ .
[6] Apple Customer Privacy Policy, 2011.
http://www.apple.com/legal/privacy/ .
[7] P. Broadwell, M. Harren, and N. Sastry. Scrash: A system
for Generating Secure Crash Information. In Proceedings of
the 12th Conference on USENIX Security Symposium ,
pages 19–19, 2003.
[8] C. Cadar, D. Dunbar, and D. R. Engler. Klee: Unassisted
and automatic generation of high-coverage tests for complex
systems programs. In Proceedings of the 8th USENIX
Symposium on Operating Systems Design and
Implementation , pages 209–224, 2008.
[9] M. Castro, M. Costa, and J.-P. Martin. Better Bug
Reporting with Better Privacy. In Proceedings of the 13th
International Conference on Architectural Support for
Programming Languages and Operating Systems , pages
319–328, 2008.[10] T. Chilimbi, B. Liblit, K. Mehra, A. Nori, and K. Vaswani.
Holmes : Eﬀective Statistical Debugging via Eﬃcient Path
Proﬁling. In Proceedings of the 31st International
Conference on Software Engineering , pages 34–44, 2009.
[11] J. Clause and A. Orso. A Technique for Enabling and
Supporting Debugging of Field Failures. In Proceedings of
the 29th International Conference on Software Engineering ,
pages 261–270, 2007.
[12] B. Dutertre and L. de Moura. The YICES SMT Solver.
http://yices.csl.sri.com/tool-paper.pdf .
[13] S. Elbaum and M. Diep. Proﬁling Deployed Software:
Assessing Strategies and Testing Opportunities. IEEE
Transactions on Software Engineering , 31(4):312–327, 2005.
[14] B. Elkarablieh, P. Godefroid, and M. Y. Levin. Precise
pointer reasoning for dynamic test generation. In
Proceedings of the 18th International Symposium on
Software Testing and Analysis , pages 129–140, 2009.
[15] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed
Automated Random Testing. In Proceedings of the 2005
Conference on Programming Language Design and
Implementation , pages 213–223, 2005.
[16] P. Godefroid, M. Y. Levin, and D. A. Molnar. Automated
Whitebox Fuzz Testing. In Proceedings of the Network and
Distributed System Security Symposium , 2008.
[17] D. M. Hilbert and D. F. Redmiles. Extracting Usability
Information from User Interface Events. ACM Computing
Surveys , 32(4):384–421, Dec 2000.
[18] L. Jiang and Z. Su. Context-aware Statistical Debugging:
From Bug Predictors to Faulty Control Flow Paths. In
Proceedings of the 22nd IEEE/ACM International
Conference on Automated Software Engineering , pages
184–193, 2007.
[19] J. C. King. Symbolic execution and program testing.
Communications of the ACM , 19(7):385–394, 1976.
[20] B. Liblit. Cooperative Bug Isolation . PhD thesis, University
of California, Berkeley, 2004.
[21] B. Liblit, M. Naik, A. X. Zheng, A. Aiken, and M. I. Jordan.
Scalable Statistical Bug Isolation. In Proceedings of the
2005 Conference on Programming Language Design and
Implementation , pages 15–26, 2005.
[22] J.-P. Martin. Upper and lower bounds on the number of
solutions. Technical Report MSR-TR-2007-164, Microsoft
Research, 2007.
[23] C. Pavlopoulou and M. Young. Residual Test Coverage
Monitoring. In Proceedings of the 21st International
Conference on Software Engineering , pages 277–284, 1999.
[24] K. Sen, D. Marinov, and G. Agha. CUTE: A Concolic Unit
Testing Engine for C. In Proceedings of the 10th European
Software Engineering Conference / 13th International
Symposium on Foundations of Software Engineering , pages
263–272, 2005.
[25] V. S. Verykios, E. Bertino, I. N. Fovino, L. P. Provenza,
Y. Saygin, and Y. Theodoridis. State-of-the-art in Privacy
Preserving Data Mining. ACM SIGMOD Record ,
33(1):50–57, 2004.
[26] W. Visser, C. S. Pˇ asˇ areanu, and S. Khurshid. Test Input
Generation with Java PathFinder. SIGSOFT Software
Engineering Notes , 29(4):97–107, 2004.
[27] R. Wang, X. Wang, and Z. Li. Panalyst: Privacy-aware
Remote Error Analysis on Commodity Software. In
Proceedings of the 17th USENIX Security Symposium ,
pages 291–306, 2008.
[28] Z. Yang, S. Zhong, and R. N. Wright. Privacy-Preserving
Queries on Encrypted Data , volume 4189 of Lecture Notes
in Computer Science , pages 479–495. 2006.
[29] A. Zeller and R. Hildebrandt. Simplifying and isolating
failure-inducing input. IEEE Transactions on Software
Engineering , 28(2):183–200, 2002.
[30] S. Zhong, Z. Yang, and R. N. Wright. Privacy-Enhancing
K-Anonymization of Customer Data. In Proceedings of the
24th Symposium on Principles of Database Systems , pages
139–147, 2005.
1030