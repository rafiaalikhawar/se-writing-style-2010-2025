Predicting Null-Pointer Dereferences in Concurrent Programs
Azadeh FarzanyP. MadhusudanzNiloofar RazaviyFrancesco Sorrentinoz
Abstract
We propose null-pointer dereferences as a target for Ô¨Ånding bugs in
concurrent programs using testing. A null-pointer dereference pre-
diction engine observes an execution of a concurrent program un-
der test and predicts alternate interleavings that are likely to cause
null-pointer dereferences. Though accurate scalable prediction is
intractable, we provide a carefully chosen novel set of techniques
to achieve reasonably accurate and scalable prediction. We use an
abstraction to the shared-communication level, take advantage of
a static lock-set based pruning, and Ô¨Ånally, employ precise and re-
laxed constraint solving techniques that use an SMT solver to pre-
dict schedules. We realize our techniques in a tool, ExceptioNULL,
and evaluate it over 13 benchmark programs and Ô¨Ånd scores of null-
pointer dereferences by using only a single test run as the prediction
seed for each benchmark.
Categories and Subject Descriptors D.2.4 [ Software Engineer-
ing]: Software/Program VeriÔ¨Åcation; D.2.5 [ Software Engineer-
ing]: Testing and Debugging
Keywords Testing, Concurrency, SMT, Null-pointers, Data-Races
1. Introduction
Errors in concurrent programs often occur under subtle interleaving
patterns that the programmer had not foreseen. There are too many
interleavings to explore, even on a single test input for a concurrent
program, making concurrency testing a hard problem. With the rise
of multicore hardware platforms, Ô¨Ånding solutions to this problem
is very important as testing is still the most effective way of Ô¨Ånding
bugs today. Current testing technologies such as stress testing have
proved largely inadequate in exposing such subtle interleavings.
Prediction-based testing has emerged as a promising approach
to testing concurrent programs. It involves taking one arbitrary con-
current execution of the program under test, and from that predict
alternate interleavings that are more likely to contain bugs (inter-
leavings that lead to data-races, interleavings that violate atomicity,
etc.). Prediction replaces systematic search with a search for inter-
leavings that are close to observed executions only, and hence is
more tractable, and at the same time explores interesting interleav-
ings that are likely to lead to errors [9, 10, 26, 27, 31].
In this paper, we explore a new target for predictive testing
of concurrent programs that is fundamentally very different from
data-races or atomicity errors: we propose to target executions
This work was funded partly by the NSERC Discovery Grant at University
of Toronto and by the Illinois-Intel Parallelism Center at the University of
Illinois at Urbana-Champaign and by NSF Career Award #0747041.
yUniversity of Toronto.
zUniversity of Illinois.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior speciÔ¨Åc permission and/or a fee.
SIGSOFT‚Äô12/FSE-20, November 11‚Äì16, 2012, Cary, North Carolina, USA.
Copyright c2012 ACM 978-1-4503-1614-9/12/11. . . $10.00that lead to null-pointer dereferences . Given an arbitrary execution
of a concurrent program under test, we investigate fundamental
techniques to accurately and scalably predict executions that are
likely to lead to null-pointer dereferences.
Null-pointer dereferences can occur in a thread when deref-
erencing local variables. Consequently, an accurate prediction of
null-pointer dereferences requires, by deÔ¨Ånition, handling local
variables and the computation of threads. This is in sharp contrast to
errors like data-races and atomicity violations, which depend only
onaccesses to shared variables .
The prediction algorithm aims to Ô¨Ånd some interleaving of the
events in the observed run that will result in a null-pointer derefer-
ence. The naive approach to this problem is to reduce it to a con-
straint satisfaction problem; the set of constraints capture the se-
mantics of local computations as well as the interaction of threads
using reads and writes, concurrency control like locks, etc. A con-
straint solver could then solve these constraints and hence synthe-
size an interleaving that causes a null-pointer dereference to occur
(this is similar to logic-based bounded model-checking for concur-
rent programs [24, 25]). However, this simply does not scale in
realistic dynamic testing setting where the number of events that
model reads/writes and computation can span millions of events.
Consequently, accurate null-pointer dereference prediction seems
intractable.
The main goal of this paper is to achieve useful and scalable
prediction for Ô¨Ånding runs that cause null-pointer dereferences.
We propose a combination of four carefully chosen techniques to
achieve this:
1. Approximation: An approximation of the prediction problem
that ignores local computation entirely, and recasts the prob-
lem involving only the events that observe shared reads, writes,
and concurrency control events (which we call the shared com-
munication level) to achieve scalability. The prediction at the
shared communication level can be more efÔ¨Åciently solved, us-
ing a combination of a lock-set based static analysis that iden-
tiÔ¨Åes null read-write pairs and a constraint satisfaction problem
to predict executions that force these null reads. Predicted runs
in this model will be feasible but may not actually cause a null-
pointer dereference, though they are likely to do so.
2. Static Pruning: An aggressive pruning of executions using
static analysis based on vector-clocks that identiÔ¨Åes a small
segment of the observed run on which the the prediction ef-
fort can be focused. This greatly improves the scalability of
using sophisticated logic solvers. Pruning of executions does
not affect feasibility of the runs, but may reduce the number of
runs predicted. However, we show that in practice no additional
errors were found without pruning.
3. Relaxed prediction: A formulation of the prediction at the
shared communication level that allows some leeway so that
the prediction algorithm can predict runs with mild deviations
from the observed run which could be interesting runs; this
makes the class of predicted runs larger at the expense of pos-
sibly making them infeasible , though in practice we found the
majority of the predicted runs to be feasible.4. Re-execution: The runs predicted using the techniques may be
infeasible, or may be feasible and yet not cause any null-pointer
dereference. We mitigate this by a re-execution engine that ex-
ecutes predicted schedules accurately to check if a null-pointer
dereference actually occurs. Errors reported hence are always
real (i.e., they cause an uncaught exception or result in failing
the test harness), and hence we incur no false positives.
We explain these techniques below, and motivate their choice and
their impact.
Approximation to the shared communication level: Though
null-pointer dereferences could occur on local variables and shared
variables (unlike data-races and atomicity, which are deÔ¨Åned only
at the level of shared variables), a prediction that takes into account
local variables and local computation simply does not scale (we
have tried many experiments on such a model that validate this
claim). We propose an approximation to null-pointer dereference
prediction that works at the shared communication level. Consider
a threadTthat in some interleaving reads a shared variable xand
subsequently does some computation locally using its value, and
consider the task of predicting whether this could result in a null-
pointer dereference. Our approximation of the prediction problem
at the shared communication level asks for a run that forces the
threadTto read a value of null. Note that this approximation is
neither sound nor complete‚Äî thread Tmay read null forxbut
may not dereference the pointer (e.g., it could check if xis null),
and there may be runs where the value read is not nulland yet the
local computation causes a null pointer dereference. However, such
an approximation is absolutely necessary to scale to large runs, as
it is imperative that local computation is not modeled. As our ex-
periments demonstrate, this approximation does not inhibit us from
Ô¨Ånding interesting executions with null-pointer dereferences.
The above approximation poses the problem as a prediction
problem at the shared communication level, which is a well-studied
problem. In particular, there is a known maximal causal model that
allows prediction at this level [23] and is the most precise predic-
tion one can achieve at the shared communication level. Moreover,
this prediction can be achieved using automatic constraint solvers
that solve a constraint that demands a sequentially-consistent in-
terleaving that respects the semantics of read/write of shared vari-
ables and the concurrency control mechanisms (locks, barriers,
threads-creation, etc.). Maximal causality prediction using con-
straint solvers has been done in the past for data-races, atomicity,
etc. (as they are properties already deÔ¨Åned at the shared communi-
cation level) [22] and we utilize a similar technique with additional
optimizations to approximately predict null-pointer dereferences.
Static pruning of executions: Prediction at the shared communi-
cation level, though more scalable than when modeling local com-
putation, still has scalability issues in practice, as there can be in
the order of hundreds of thousands of events involving shared vari-
ables. We propose pruning the execution using a simple scalable
lock-set and vector-clock based analysis that determines a large
preÔ¨Åx of the observed run that can be cut out soundly . The predic-
tion algorithm hence is only applied to the remnant segment, which
is smaller by an order of magnitude. If the prediction of the smaller
segment succeeds, we are guaranteed that there is a way to stitch
back the removed preÔ¨Åx to predict a full execution. Furthermore,
the relaxed prediction technique (discussed below) being only ap-
plied to the smaller segment, introduces inaccuracies solely within
that segment.
Relaxed prediction: The above two techniques of approximate
prediction at the shared communication level and static pruning ad-
dress scalability issues, and ensure that predicted runs are always
feasible. However, they do not always work well in practice be-cause sometimes no solution to the constraints exist. Demanding
that the predicted run be absolutely guaranteed to be feasible (us-
ing the maximal causal model) seems too stringent a requirement,
as it rules out runs that even mildly deviate from the requirements.
For instance, if there is a read of ywith value 23in the original run,
the predicted run is required to make the same read-event read the
value 23, while in reality reading a different value, say 27, may not
cause the program to completely deviate from the current path.
We propose a novel relaxed prediction algorithm that models the
constraints to allow bounded wiggle-room . We propose to explore,
for an increasing threshold k, whether there is a predictable run
that violates at most kconstraints that specify the values of shared
reads. According to our experiments, even setting kto a small
number (e.g., 5) is often sufÔ¨Åcient to predict runs causing null-
pointer dereferences. These predicted runs are not guaranteed to be
feasible, but we show empirically that most of them actually are.
This technique, as well as the approximation to the shared com-
munication level, causes unsoundness (predicted runs may be feasi-
ble or not cause a null-pointer dereference), which is handled by us-
ing an accurate re-execution tool that checks whether the predicted
runs are indeed feasible and cause a null-pointer dereference.
The main technical contributions of this paper is the mechanism
of targeting null-pointer dereference prediction using the approxi-
mation to the shared-communication level, the static pruning for
scalability, and the prediction by relaxing constraints so as to make
the prediction useful.
Evaluation: The Ô¨Ånal contribution of this paper is a full-Ô¨Çedged
implementation realizing the new prediction-based testing tool that
targets null-pointer dereferences, called E XCEPTIO NULL . E X-
CEPTIO NULL monitors and reschedules interleavings for Java
programs using Java bytecode rewriting (building over the P ENE-
LOPE [27] infrastructure), and implements the identiÔ¨Åcation of
null-WR pairs, the pruning, and the logic-based procedures for
both precise and relaxed prediction, using the SMT solver Z3 from
Microsoft Research [11]. We show that E XCEPTIO NULL is ef-
fective in predicting a large number of feasible runs in a suite of
concurrent benchmarks. Evaluated over a suite of 13 benchmarks,
we show the discovery of a slew of about 40 null-pointer derefer-
ence errors just be predicting from single test executions, and with
no false positives. We know of no current technique that can Ô¨Ånd
anywhere close to these many null-pointer dereferences on these
benchmarks. We believe that the techniques proposed here hence
make a signiÔ¨Åcant leap forward in testing concurrent programs.
We also study some of the effects of techniques we have in-
troduced, and estimate the inaccuracies caused and the scalability
gained. We show that the pruning technique provides signiÔ¨Åcant
scalability beneÔ¨Åts, while at the same time does not prohibit the
prediction from Ô¨Ånding any of the errors. We also show experimen-
tally that the relaxation technique allows us to predict many more
runs than the maximal causal model that result in errors (14 of the
41 errors were found due to relaxation).
We also show the efÔ¨Åcacy of the relaxation technique by adapt-
ing our relaxed prediction to Ô¨Ånd data-races . Note that data-races
are already deÔ¨Åned at the shared communication level, and hence
the approximation technique is not relevant. However, even in this
setting, the static pruning allows us to scale more and the relaxation
technique allows us to predict a lot more runs that have data-races
than the strict prediction on the maximal causal model can (the lat-
ter is the current state-of-the-art in predicting data-races). Our tool
discovers 60 data-races over our benchmarks of which 17 are found
using relaxed prediction, showing that relaxed prediction is a very
effective for other types of errors as well.
Related Work: The closest work related to ours in the realm
of logic-based methods are those that stem from bounded model-checking for Ô¨Ånding executions of bounded length in concurrent
programs that have bugs. Typically, a program‚Äôs loops are unrolled
a few times to get a bounded program, and using a logical encoding
of the runs in this bounded program, a constraint solver is used to
check if there is an error. We refer the reader to the papers from
the NEC Labs group [24, 25] ([24] gives a clean encoding) as
well as work from Microsoft Research [2, 12, 16, 21], where the
programs are converted Ô¨Årst to a sequential program from which
bounded run constraints are generated. The crucial difference in our
work is that we use logic in the testing setting to predict alternate
interleavings. Another closely related work is C ONMEM[35] (see
also [34]), where the authors target a variety of memory errors in
testing concurrent programs, including null-pointer dereferences,
but the prediction algorithms are much weaker and quite inaccurate
compared to our robust prediction techniques. Furthermore, there is
no accurate rescheduling engine which leads the tool to have many
false positives.
There are two promising approaches that have emerged in test-
ing concurrent programs: selective interleavings andprediction-
based testing (and combinations of these). The selective interleav-
ing approach is to focus in testing a small but carefully chosen
subset of interleavings. There are several tools and techniques that
follow this philosophy: for instance, the CHESS tool from Mi-
crosoft [18] tests all interleavings that use a bounded number pre-
emptions (unforced context-switches), pursuing the belief that most
errors can be made to manifest this way. Several tools concentrate
on testing atomicity violating patterns (for varying notions of what
atomicity means), with the philosophy that they are much more
likely to contain bugs [17, 19, 20, 33]. However, systematically
testing even smaller classes of interleavings is often impossible in
practice, as there are often too many of them.
There are several work on prediction-based testing that do not
use logical methods. These algorithms may focus on predicting
runs violating atomicity or containing data-races : those by Sor-
rentino et al. [13, 27], those by Wang and Stoller [31, 32], and
[14] by Huang and Zhang. A more liberal notion of generalized
dynamic analysis of a single run has also been studied in a series
of papers by Chen et al. [9, 10]. JP REDICTOR [10] offers a predic-
tive runtime analysis that uses sliced causality [9] to exclude the
irrelevant causal dependencies from an observed run and then ex-
haustively investigates all of the interleavings consistent with the
sliced causality to detect potential errors. The main drawback of
non-logical prediction approaches is that the predicted runs may
not be feasible. In fact, they ignore data which makes them less ef-
fective in Ô¨Ånding bugs that are data-dependent such as null-pointer
dereferences.
Logic-based prediction approaches, target precise prediction.
Given an execution of the program, several work [29, 30] model the
whole computation (local as well as global) logically to guarantee
feasibility. The research presented in the above related work has too
big an overhead to scale to large executions. Maximal Causality
Model (MCM) [23], on the other hand, allows prediction at the
level of shared communication and is the most precise prediction
one can achieve at this level. MCM has been used by Said et al. [22]
for Ô¨Ånding data-race witnesses. We also use this model to predict
runs leading to null-pointer dereferences.
2. Motivating Example
Consider a code extract from the Pool 1.2 library [5] in the
Apache Commons collection, presented in Figure 1. The object
pool ‚Äôs state, open orclosed , is tested outside the synchronized
block in method returnObject , by checking whether the Ô¨Çag
variable isClosed is true. If so, then some local computation
occurs, followed by a synchronized block that dereferences the
shared object pool . A second method close closes the pool and
setsisClosed to true to signal that the pool has been closed.An error in this code (and such errors are very typical) stems
from the fact that the check of isClosed in the method return-
Object is not within the synchronized block; hence, if a thread
executes the check at line `, and then a concurrent thread executes
the method close() before the synchronized block begins, then
the access to the pool object at line `0will raise an uncaught null-
pointer dereference exception .
In a dynamic testing setting, consider the scenario where we
observe an execution with two threads, where Texecutes the
method returnObject Ô¨Årst, and then, T0executes the method
close afterTÔ¨Ånishes executing returnObject . There is no
null-pointer dereference in . Our goal is to predict an alternate
scheduling of events of that causes a null-pointer dereference.
Our prediction for null-pointer dereferences works as follows.
In the run, a read of the shared variable pool at`0occurs inT
and the read value is not null. Also, a write to pool occurs inT0
at`00which writes the value null . We ask whether there exists an
alternative run 0in which, the read at `0(inT) can read the value
null written by the write at location `00(inT0) (as illustrated by
the arrow in Figure 1).
Our prediction algorithm observes the shared events (such as
shared reads/writes) but suppresses the semantics of local compu-
tations entirely and does not even observe them; they have been
replaced by ‚Äú...‚Äù in the Ô¨Ågure as they play no role in our analysis.
Prediction of runs that force the read at `0to read the null
value written at `00must meet several requirements. Even if the
predicted run respects the synchronization semantics for locks,
thread creation, etc., the run may diverge from the observed run
due to reading a different set of values for shared variables which
will result in a different local computation path (e.g. the condition
check at`will stop the computation of the function right away if
the value of isClosed is true). Therefore, we also demand that
all other shared variable reads read the same value as they did in the
original observed run, in order to guarantee that unobserved local
computations will unfold in the same way as they did in the original
run. This ensures the feasibility of the predicted runs.
Relaxed prediction: The requirement for all shared variable reads
to read the same values, however, can be too strict in some cases.
For instance, in our example, the variable modCount is a global
counter keeping track of the number of modiÔ¨Åcations made to the
pool data structure, and does not play any role in the local control
Ô¨Çow reaching the point of null-pointer dereference at `00. In the real
execution leading to this null-pointer dereference, which is the one
where block b1(fromT) is executed Ô¨Årst, followed by b3(fromT0)
and thenb2(fromT), the read of modCount will read a different
value than the corresponding value read in . However, this does
not affect the feasibility of the run (in contrast to the value read for
isClosed , which plays an important role in reaching the null-
pointer dereference).
Our relaxed prediction model gives a slack threshold k, allowing
predicted runs to have at most kreads that do not have to read the
same values as in . By increasing the threshold kiteratively, our
technique will Ô¨Ånd an execution that violates the read condition on
modCount , but yet Ô¨Ånds a feasible run that causes the null-pointer
dereference in this example.
3. Preliminaries
Here, we present an overall overview of our prediction-based ap-
proach and set up a formal notation to describe the predicted runs.
3.1 Overview of proposed approach
Given a concurrent program Pand an input I, we perform the
following steps:
Monitoring: We execute Pon the input Iand observe an
arbitrarily interleaved run .publicvoidclose(){Synchronized(this){...modCount=......pool=null;isClosed=true;}}
publicvoidreturnObject(Objectobj){...if(isClosed)thrownewPoolClosedEx();...Synchronized(this){numActive--;......=modCount;...pool.push(obj);}}
/lscript:
/lscript/prime:
/lscript/prime/prime:
T/prime:
T:
Canthenullvaluebeobservedhere?
b1
b2
b3Figure 1. Code snippet of the buggy implementation of Pool.
Run Prediction: We analyze the run to Ô¨Ånd a set of pair of
events= (e;f)insuch that: (i) eis a write to shared
variablexthat writes a null value, (ii)fis a read from the
same shared variable xthat reads a non-null value in another
thread, and (iii) static analysis on the run determines that there
is a runbofP, obtained from reshufÔ¨Çing of events in , that
respects locks and in which freads the null value written by e.
We call such pair of events = (e;f)anull-WR pair. For each
null-WR pair, we logically encode the set of runs and use SMT
solvers to predict concrete runs bthat force null-reads.
Rescheduling: For each bgenerated by the run prediction
phase, we re-execute the program, on the same input I, forcing
it to follow b. If it succeeds, then the null value read at f
may later result in an error, such as a null-pointer dereference
exception ; we report all such conÔ¨Årmed errors.
We now set up the formal notation to describe the run prediction
phase. In particular, the prediction algorithm will ignore computa-
tion of threads, and interleave at the level of blocks of local com-
putations that happen between two reads/writes to global variables.
3.2 Modeling program runs, suppressing local computation
We model the runs of a concurrent program as a word where
each letter describes the action done by a thread in the system.
The word will capture the essentials of the run‚Äî shared variable
accesses, synchronizations, thread-creating events, etc. However,
we will suppress the local computation of each thread, i.e. actions
a thread does by manipulating local variables, etc. that are not (yet)
visible to other threads, and model the local computation as a single
event lc. (In the formal treatment, we will ignore other concurrency
constructs such as barriers, etc.; these can be accommodated easily
into our framework.)
We Ô¨Åx an inÔ¨Ånite countable set of thread identiÔ¨Åers T=fT1;T2;::g
and deÔ¨Åne an inÔ¨Ånite countable set of shared variable names SV
that the threads manipulate. Without loss of generality, we assume
that each thread Tihas a single local variable lvithat reÔ¨Çects its
entire local state. Let V=SVS
iflvigrepresent the set of all vari-
ables. Let Val(x)represent the set of possible values that variable
x2SVcan get, and deÔ¨Åne Init(x)as the initial value of x. We
also Ô¨Åx a countable inÔ¨Ånite set of locks L.
The actions that a thread Tican perform on a set of shared
variablesSVand global locks Lis deÔ¨Åned as:
Ti=fTi:readx;val; Ti:writex;valjx2SV;val2Val(x)g
[fTi:lcg[fTi:acquire (l); Ti:release (l)jl2Lg
[fTi:tcTjjTj2Tg
ActionsTi:readx;val andTi:writex;val correspond to the thread
Tireading the value valfrom and writing the value valto the
shared variable x, respectively. Action Ti:lccorresponds to a local
computation of thread Tithat accesses and changes the local state
lvi. ActionTi:acquire (l)represents acquiring the lock land theactionTi:release (l)represents releasing of the lock l, by thread
Ti. Finally, the action Ti:tcTjdenotes the thread Ticreating the
threadTj.
We deÔ¨Åne  =S
Ti2TTias the set of actions of all threads.
A wordwin, in order to represent a run, must satisfy several
obvious syntactic restrictions, which are deÔ¨Åned below.
Lock-validity, Data-validity, and Creation-validity: There are
certain semantic restrictions that a run must follow. In particular, it
should respect the semantics of locks and semantics of reads, i.e.
whenever a read of a value from a variable occurs, the last write
to the same variable must have written the same value, and the
semantics of thread creation. These are captured by the following
deÔ¨Ånitions (jAdenotes the word projected to the letters in A).
DEFINITION 3.1 (Lock-validity). A run2islock-valid if
it respects the semantics of the locking mechanism. Formally, let
l=fTi:acquire (l);Ti:release (l)jTi2Tgdenote the set of
locking actions on lock l. Thenis lock-valid if for every l2L,
jlis a preÔ¨Åx ofhS
Ti2T(Ti:acquire (l)Ti:release (l))i
DEFINITION 3.2 (Data-validity). A run2over a set of
threadsT, shared variables SV, and locksL, isdata-valid if it
respects the read-write constraints. Formally, for each nsuch that
[n] =Ti:readx;val, one of the following holds:
(i) The last write action to xwrites the value val. I.e. there is a
m<n such that[m] =Tj:writex;valand there is no m<k<n
such that[k] =Tq:writex;val‚Äôfor anyval0and any thread Tq, or
(ii) there is no write action to variable xbefore the read, and
valis the initial value of x. I.e. there is no m < n such that
[m] =Tj:writex;val‚Äô(for anyval0and any thread Tj), and
val=Init(x).
DEFINITION 3.3 (Creation-validity). A run2over a set of
threadsTiscreation-valid if every thread is created at most once
and its events happen after this creation, i.e., for every Ti2T,
there is at most one occurrence of the form Tj:tcTiinw, and, if
there is such an occurrence, then all occurrences of letters of Ti
happen after this occurrence.
Program Order: Let=a1:::anbe a run of a program P. The
occurrence of actions in runs are referred to as events in this paper.
Formally, the set of events of the run is E=fe1;:::;eng, and
there is a labeling function that maps every event to an action,
given by(eu) =au.
While the run deÔ¨Ånes a total order on the set of events in it
(E;), there is an induced total order between the events of each
thread. We formally deÔ¨Åne this as vifor each thread Ti, as follows:
for anyes;et2E, ifasandatbelong to thread Tiandstthen
esviet. The partial order that is the union of all the program
orders isv=[Ti2Tvi.
The Maximal Causal Model for prediction: Given a run 
corresponding to an actual execution of a program P, we would
like our prediction algorithms to synthesize new runs that interleave
the events of to cause reading of null values. However, we want
to predict accurately ; in other words we want the predicted runs to
be feasible in the actual program.
We now give a sufÔ¨Åcient condition for a partial run predicted
from an observed run to be always feasible. This model of pre-
diction was deÔ¨Åned by S ¬∏erb Àòanut ¬∏Àòa et al., and is called the maximal
causal model [23]; it is in fact the most liberal prediction model
that ensures that the predicted runs are always feasible in the pro-
gram that work purely dynamically (i.e. no other information about
the program is known other than the fact that it executed this set
of observable events, which in turn do not observe computation).We generalize the model slightly by taking into account thread cre-
ation.
DEFINITION 3.4 (Maximal causal model of prediction [23]). Let
be a run over a set of threads T, shared variables SV, and locks
L. A run0isprecisely predictable fromif (i) for each Ti2T,
0jTiis a preÔ¨Åx of jTi, (ii)0is lock-valid, (iii) data-valid, and
(iv) creation-valid. Let PrPred ()denote the set of all runs that
are precisely predictable from the run .
The Ô¨Årst condition above ensures that the events of Tiexecuted
in0is a preÔ¨Åx of the events of Tiexecuted in. This property is
crucial as it ensures that the local state of Tican evolve correctly.
Note that we are forcing the thread Tito read the same values
of global variables as it did in the original run. Along with data-
validity, this ensures that the thread Tireads precisely the same
global variable values and updates the local state in the same way
as in the original run. Lock-validity and creation-validity are, of
course, required for feasibility. We will refer to runs predicted
according to the maximal causal model (i.e. runs in PrPred ())
as the precisely predicted runs from .
The following soundness of the prediction that assures all pre-
dicted runs are feasible, follows:
THEOREM 3.5 ([23]). LetPbe a program and be a run cor-
responding to an execution of P. Then every precisely predictable
run02PrPred ()is feasible in P.
The above theorem is independent from the class of programs.
We will assume however that the program is locally determinis-
tic (non-determinism caused by threads interleaving is, of course,
allowed). The above theorem, in fact, even holds when local com-
putations of Parenon-deterministic ; i.e. the predicted runs will
still be feasible in the program P. However, in order to be able to
execute the predicted runs, we need to assume determinism of lo-
cal actions. In this case, we can schedule the run 0precisely and
examine the outcomes of the tests on these runs.
3.3 The prediction problem for null-reads
We are now ready to formally deÔ¨Åne the precise prediction problem
for forcing null-reads.
DEFINITION 3.6 (Precisely predictable null-reads). Letbe a
run of a program P. We say that 0is a precisely predictable
run that forces null-reads if there is a thread Tiand a variable x
such that the following are satisÔ¨Åed: (i) 0=00:fwherefis of
the formTi:readx;null, (ii)00is a precisely predictable run from 
using the maximal causal model, and (iii) there is some val 6=null
such that (00ji):Ti:readx;valis a preÔ¨Åx of ji.
Intuitively, the above says that the run 0must be a precisely
predictable run from followed by a read of null by a thread Ti
on variablex, and further, in the observed run , threadTimust be
executing a non-null read of variable xafter executing its events in
00. The above captures the fact that we want a precisely predictable
run followed by a single null-read that corresponded to a non-
null read in the original observed run. Note that 0itself is not in
PrPred (), but is always feasible in the program P, and results
in a null-read by thread Tion variablexthat had not happened in
the original run.
The precisely predictable runs that force null-reads are hence
excellent candidates to re-execute and test; if the local computation
after the read does not check the null-ness of xbefore dereferencing
a Ô¨Åeld ofx, then this will result in an exception or error.
4. Identifying null-WR pairs using lock-sets
The Ô¨Årst phase of our prediction is to identify null-WR pairs=
(e;f)whereeis a write of null to a variable and fis a read ofthe same variable, but where the read in the original run reads a
non-null value. Moreover, we would like to identify pairs that are
feasible at least according to the hard constraints of thread-creation
and locking in the program. For instance, if a thread writes to a
shared variable xand reads from it in the same lock-protected
region of code, then clearly the read cannot match a write protected
by the same lock in another thread. Similarly, if a thread initializes
a variablexto a non-null and then creates another thread that reads
x, clearly the read cannot read an uninitialized x. We use a lock-set
based static analysis of the run (without using a constraint solver) to
Ô¨Ålter out such impossible read-write pairs. The ones that remain are
then subject to a more intensive analysis using a constraint solver.
Using a static analysis on the observed run , we Ô¨Årst collect all
null-WR pairs= (e;f). Then, we prune away null-WR pairs for
which there is no lock-valid run in which fis reading the null value
written bye. Then, for each null-WR pair= (e;f)left, we use
our precise logical prediction algorithm to obtain a lock-valid, data-
valid and creation-valid run in which fis reading the null value
written bye. However, instead of using run for the purposes of the
prediction, we slice a relevant segment of it, and use the segment
instead. The reason for this is twofold: (1) these run segments are
often orders of magnitude smaller than the complete run, and this
increases the scalability of our technique and (2) when a precisely
predictable run does not exist, we use a more relaxed version of
the constraints to generate a new run, limiting the improvisation to
a smaller part of run increases our chances of obtaining a feasible
execution. We formally deÔ¨Åne this relevant run segment and how it
is computed in Section 7.
In this static analysis, the idea is to check if the null-WR pair=
(e;f)can be realized in a run that respects lock-validity and
creation-validity constraints only (and not data-validity). Creation
validity is captured by computing a vector clock associated with
each event, where the vector clock captures only the hard causality
constraints of thread creation. If foccurs before eaccording to this
relation, then clearly it cannot occur after eand the pair is infeasi-
ble. Lock-validity is captured by reducing the problem of realizing
the pair (e;f)topairwise reachability under nested locking [15],
which is then solved by computing lock-sets and acquisition his-
tories for each event. We describe only the lock-validity checking
below. Similar techniques have been exploited for Ô¨Ånding atomicity
violations in the tool P ENELOPE [27].
Checking lock-valid reachability Consider a null-WR pair=
(e;f)and a runin whichf(a read in thread Tj) occurs Ô¨Årst, and
later the write event eis performed by Ti.
Let us assume that e00is the next write event (to the same
variable accessed in eandf) inTiaftere. If there exists a lock-
valid run0(obtained by permuting the events in ) in which
freads the null value provided by e, then in0,fshould be
scheduled after e, but before e00; iffis scheduled also after e00,
then the write in e00overwrites the null value written by ebefore
it reachesf. This means that there should exist an event e0of
threadTi, occurring between events eande00, that is executed right
before (or after f) in0; in other words, e0andfare co-reachable.
e
e/prime/prime
f
Ti
Tj
.
.
.
.
.
.
.
.
.
.
.
e/prime
.
.
.
AH1
AH2
LS2
LS1
}
{
LS1‚à©LS2=‚àÖ
AH1compatiblewithAH2
{
:writeX,null
:readX,¬¨null
:writeX,‚Ä¢
.
We use a sim-
ple technique [15] to
check if there is an
evente0inTibe-
tweeneande00such
thate0andfare co-
reachable in a lock-
valid run. The co-
reachability check is
done by examining
the lock-sets and ac- ‚åòPO^CV^DV^LVPO=(Vni=1POi)^CinitCinit=Vni=1(tseinit<t sei,1)POi=Vmi 1j=1(tsei,j<t sei,(j+1))DV=VxVval2Val(x)Vr2Rx,val‚á£Ww02Wx,valCoupledr,w0‚åòCoupledr,w=(tsw<t sr)^^e002Wx {w}((tse00<t sw)_(tsr<t se00))LV=LV1^LV2LV1=^i6=j2{1,..,n}^lockl^[eac,erel]2Li,l[e0ac,e0rel]2Lj,l‚á£tserel<tse0ac_tse0rel<tseac‚åòLV2=^i6=j2{1,..,n}^lockl^eac2NoReli,l[e0ac,e0rel]2Lj,l‚á£tse0rel<tseac‚åòFigure 2. Constraints capturing the maximal causal model.
quisition histories at e0andf: the lock-sets at e0andfmust be
disjoint and the acquisition histories at e0andfmust be compati-
ble.
Note that the above condition is necessary for the existence of
the lock-valid run 0, but not sufÔ¨Åcient ; hence Ô¨Åltering out pairs that
do not meet this condition is sound.
5. Precise prediction by logical constraint solving
We now describe how we solve the problem of precisely predicting
a run that realizes a null-WR pair= (e;f). This problem is to
predict whether there is an alternate schedule in the maximal causal
model that forces the read at fto read the null value written by e.
We solve this using a logic constraint solver (an SMT solver); the
logic of the constraints is in a fragment that is efÔ¨Åciently decidable.
Prediction according to the maximal causal model is basically
an encoding of the creation-validity, data-validity, and lock-validity
constraints using logic, where quantiÔ¨Åcation is removed by expand-
ing over the Ô¨Ånite set of events under consideration. Modeling this
using constraint solvers has been done before ([22]) in the context
of Ô¨Ånding data races. We reformulate this encoding brieÔ¨Çy here for
several reasons. First, this makes the exposition self-contained, and
there are a few adaptations to the null-read problem that need ex-
planation. Second, we perform a wide set of carefully chosen op-
timizations on this encoding, whose description needs this exposi-
tion. And Ô¨Ånally, the relaxation technique, which is one of the main
contributions of this paper, is best explained by referring directly to
the constraints.
Capturing the maximal causal model using logic
Given a run, we Ô¨Årst encode the constraints on all runs predicted
from it using the maximal causal model, independent of the spec-
iÔ¨Åcation that we want runs that match a given null-WR pair . A
predicted run can be seen as a total ordering of the set of events E
of the run. We use an integer variable tseto encode the times-
tamp of evente2Ewheneoccurs in the predicted run. Using
these timestamps, we logically model the constraints required for
precisely predictable runs (see DeÔ¨Ånition 3.4), namely that the run
respect the program order of , that it be lock-valid, data-valid, and
creation-valid.
Figure 2 illustrates the various constraints. The constraints are
a conjunction of program order constraints (PO), creation-validity
constraints (CV), data-validity constraints (DV), and lock-validity
constraints (LV).The program order constraint (PO) captures the condition that
the predicted run respect the program order of the original observed
run. Suppose that the given run consists ofnthreads, and
letjTi=ei;1,ei;2, ...,ei;m ibe the sequence of events in 
that relates to thread Ti. Then the constraint POidemands that
the time-stamps of the predicted run obey the order of events in
threadTi, andPO demands that all threads meet their program
order. We also consider an initial event einitwhich corresponds
to the initialization of variables. This event should happen before
any thread starts the execution in any feasible permutation, and is
encoded as the constraint Cinit.
Turning to creation-validity, suppose that etc(i)is the event that
creates thread Ti. Then the constraint CV demands that the Ô¨Årst
event ofTican only happen after etc(i). Combined with program
order constraint, this means that all events before the creation of Ti
in the thread that created Timust also occur before the Ô¨Årst event
ofTi.
The data-validity constraints DV (see DeÔ¨Ånition 3.3) capture
the fact that reads must be coupled with appropriate writes; more
precisely, that every read of a value from a variable must have a
write before it writing that value to that variable, and moreover,
there is no other intermediate write to that variable. Let Rx;val
represent the set of all read events that read value valfrom variable
xin,Wxrepresent the set of all write events to variable x, and
Wx;val represent the set of all write events that speciÔ¨Åcally write
valuevalto variablex. For each read event r=readx;val and
write eventw2Wx;val , the formula Coupledr;wrepresents the
requirement that wis the most recent write to variable xbeforer
and henceris coupled with w. The constraint DV demands that all
reads be coupled with writes that write the same value as the read
reads.
Lock-validity is captured by the formula LV. We assume that
each lock acquire event acof locklin the run is matched by
precisely one lock release event relof locklin the same thread,
unless the lock is not released by the thread in the run. We call
the set of events in thread Tibetweenacandrela lock block
corresponding to lock lrepresented by [ac;rel ]. LetLi;lbe the set
of lock blocks in thread Tiregarding lock l. ThenLV1asserts that
no two threads can be simultaneously inside a pair of lock blocks
[eac;erel]and[e0
ac;e0
rel]corresponding to the same lock l. Turning
to locks that never get released, the constraint LV2handles asserts
that the acquire of lock lby a thread that never releases it must
always occur after the releases of lock lin every other thread. In
this formula, NoReli;lstands for lock acquire events in Tiwith no
corresponding later lock release event.
Optimizations
The constraints, when written out as above, can be large. We do
several optimization to control the formula bloat (while preserving
the same logical constraint).
The data-validity constraint above is expensive to express, as it
is, in the worst case, cubic in the maximum number of accesses
to any variable. There are several optimizations that reduce the
number of constraints in the encoding. Suppose that r=readx;val
is performed by thread Ti.
Each write event w0toxthat occurs after rinTi, i.e.rviw0,
can be excluded in the constraints related to coupling rwith a
write in constraint DV above.
Suppose that wis the most recent write to xbeforerinTi.
Then, each write event w0beforewinTi, (i.e.w0viw), can
be excluded in the constraints related to coupling rwith a write
in constraint DV above.
Whenris being coupled with w2Wx;val in threadTj, each
write eventw0beforewinTj, i.e.w0vjw, can be excluded as
candidates for e00in the formula Coupledr;w.Suppose that ris being coupled with w2Wx;val in thread
Tjandw0is the next write event to xafterwin threadTj.
Then each write event w00afterw0inTj, i.e.w0vjw00, can be
excluded as candidates for e00in the formula Coupledr;w.
Eventrcan be coupled with einitonly when there is no other
write event to xbeforerinTi, i.e.@w:(wvir^w2Wx).
Furthermore, it is enough to check that the Ô¨Årst write event to x
in each thread (if it exists) is performed after r.
The lock-validity formula above, which is quadratic in the num-
ber of lock blocks, is quite expensive in practice. We can optimize
the constraints. If a read event rin threadTican be coupled with
only onewrite eventwwhich is in thread Tjthen in all precisely
predictable runs, wshould happen before r. Therefore, the lock
blocks according to lock lthat are inTjbeforewand the lock
blocks according to lock lthat are inTiafterrare already ordered.
Hence, there is no need to consider constraints preventing Tiand
Tjto be simultaneously in such lock blocks. In practice, this greatly
reduces the number of constraints. Furthermore, when considering
lock acquire events with no corresponding release events in LV2
above, it is sufÔ¨Åcient to only consider the lastcorresponding lock
blocks in each thread and exclude the earlier ones from the con-
straint.
Predicting runs for a null-WR pair
We adapt the above constraints for predicting in the maximal causal
model to predict whether a null-WR pair= (e;f)is realizable.
Suppose that and= (e;f)are a run and a null-WR pair passed
to the prediction phase, respectively. Notice that in the original run
freads a non-null value while we will force it to read null in the
predicted run by coupling it with write event e. Indeed, this is the
whole point of predicting runs‚Äî we would like to diverge from the
original run at fby forcingfto read a null value. Note that once
freads a different value, we no longer have any predictive power
on what the program will do (as we do not examine the code of the
program but only its runs). Consequently, we cannot predict any
events causally later than f.
The prediction problem is hence formulated as follows:
Given a run, and a null-WR pair = (e;f)in, algorithmi-
cally Ô¨Ånd a precisely predictable run from that forces null-reads
according to ; i.e.fis the last event and reads the null value
written bye.
The prediction problem is to Ô¨Ånd precisely predicted runs that
executeefollowed by f, while avoiding any other write to the
corresponding variable between eandf. The constraints that force
the readfbe coupled with the write eisNC =Coupledf;e.
Furthermore, recall that the feasibility of the run that we are
predicting needs to be ensured only up to the readf. Consequently,
we drop from the data-validity formula that the value read at f(in
the original run) match the last write (it should instead match eas
above).
A further complication is scheduling events that happen after
ein the same thread. Note that some of these events may need
to occur in order to satisfy the requirements of events before f
(for instance a read before fmay require a write after eto occur).
However, we may not want to predict some events after e, as we are
really only concerned with foccurring after e. Our strategy here is
to let the solver Ô¨Ågure out the precise set of events to schedule after
e(and before the next write to the same variable as eis writing to)
in the same thread.
For events after einTi, we enforce lock-validity and data-
validity constraints only if they are scheduled beforef. More pre-
cisely, we replace_w0Coupledri;w0in the formula DV to(tsr<
tsf)_w0Coupledri;w0). Similarly, we drop the lock constraints
on events occurring after f(this relaxation is more involved but
straightforward).In summary, we have reduced the problem of predicting a run
according to the maximal causal model that causes the null write-
read pair to be realizable to a satisÔ¨Åability of a formula  in logic.
The constraints generated fall within the class of quantiÔ¨Åer-free
difference logic constraints which SMT solvers efÔ¨Åciently solve in
practice.
6. Relaxed prediction
The encoding proposed in the previous section is sound, in the
sense that it guarantees feasibility of the predicted runs. However,
as demonstrated by the example in Section 2, sound prediction
under the maximal causal model can be too restrictive and result
in predicting no runs. Slightly diverging from the original can
sometimes lead to prediction of runs that are feasible in the original
program.
We hence have a tension between two choices‚Äî we would like
to maintain the same values read for as many shared variable reads
as possible to increase the probability of getting a feasible run, but
at the same time allow a few reads to read different values to make
it possible to predict some runs. Our proposal, which is one of the
main contributions of this paper, is an iterative algorithm for Ô¨Ånding
theminimum number of reads that can be exempt from data-validity
constraints that will allow the prediction algorithm to Ô¨Ånd at least
one run. We deÔ¨Åne a suitable relaxed logical constraint system to
predict such a run. Our experiments show that exempting a few
reads from data-validity constraints greatly improves the Ô¨Çexibility
of the constraints and increases the possibility of predicting a run,
and at the same time, the predicted runs are often feasible.
The iterative algorithm works as follows. Let‚Äôs assume there
arenshared variable reads that are required to be coupled with
speciÔ¨Åc write by the full set of data-validity constraints. The data-
validity constraints are expressed so that we speciÔ¨Åcally ask for n
shared reads to be coupled correctly. If we fail to Ô¨Ånd a solution
satisfying constraints for all nreads, then we repeatedly decrement
n, and attempt to Ô¨Ånd a solution that couples n 1reads in the next
round, and so on. The procedure stops whenever a run (solution) is
found. The change required in the encoding to make this possible
is described below.
For every read event ri2R, we introduce a new Boolean
variable,bi, that is true if the data-validity constraint for riis
satisÔ¨Åed, and false otherwise. In addition, we consider an integer
variablebIntiwhich is initially 0, and set to 1only whenbi
is true. This is done through a set of constraints, one for each
ri2R:[(bi!bInti= 1)^(:bi!bInti= 0)] . Also,
for eachri2R, we change the sub-term _w0Coupledri;w0to
(tsr< tsf))(bi) _w0Coupledri;w0)inDV, forcing the
data-validity constraint for read rito hold when biis true. Note
that with these changes, we require a different theory, that is Linear
Arithmetic in the SMT solver to solve the constraints, compared
to the Difference Logic which was used for our original set of
constraints.
Initially, we set a threshold to bejRj, the number of all read
events. In each iteration, we assert the constraintP
1ijRjbInti=
, which speciÔ¨Åes the number ( ) of data-validity constraints that
should hold in that iteration. If no run can be predicted with the
current threshold (i.e. the constraint solver reports unsatisÔ¨Åa-
bility), then is decremented in each iteration, until the formula
is satisÔ¨Åable. This way, when a satisfying assignment is found, it
is guaranteed to have the maximum number of reads that respect
data-validity possible for predictable run.
Note that once  <jRj, the predicted run is not theoretically
guaranteed to be a feasible run. However, in practice, when is
close tojRjand a run is predicted, this run is usually feasible in the
program.Instrumenter
Observed
JavaClasses
JVM
Bug
Runs
Passedthe
Extractor
Schedule
Instrumenter
Instrumented
classes
null-WRpair
ConstraintGenerator
Z3
Constraints
Run
Extractor
Run
NoSolution
Segment
Generator
Instrumented
classes
JVM
PreÔ¨Åx
null-WR
pair
Segment
Monitor
Monitor
Scheduler
RunPredictor
Run
Predicted
TestHarnessFigure 3. EXCEPTIO NULL.
7. Pruning executions for scalability
Identifying null-WR pairs using the lock-set based analysis and
then subjecting them to constraint checking is a precise method to
force null reads. However, in our experiments, we discovered that
the constraint solving approach does not scale well when runs get
larger. In this section, we propose a pruning technique for the runs
that removes a large preÔ¨Åx of them while maintaining the property
that any run predicted from the sufÔ¨Åx will still be feasible. While
this limits the number of predictable runs in theory, we show that in
practice, it does not prevent us from Ô¨Ånding errors (in particular, no
error was missed due to pruning in our experiments). Furthermore,
we show that in practice pruning improves the scalability of our
technique, in some cases by an order of magnitude.
Consider an execution and a null-WR pair= (e;f). The
idea behind pruning is to Ô¨Årst construct the causal partial order
of events of , and then remove two sets of events from it. The
Ô¨Årst set consists of events that are causally after eandf(except
for some events, as described in detail below). The second set
is a causally preÔ¨Åx-closed set of events (a conÔ¨Åguration) that are
causally before eandf, and where all the locks are free at the
end of execution of this conÔ¨Åguration. The intuition behind this is
that such a conÔ¨Åguration can be replayed in the newly predicted
execution precisely in the same way as it occurred in the original
run, and then stitched to a run predicted from the sufÔ¨Åx, since the
sufÔ¨Åx will start executing in a state where no locks are held.
In order to precisely deÔ¨Åne this run segment, we deÔ¨Åne a notion
of partial order on the set of events Ethat captures the causal
order. LetDdenote the dependency relation between actions that
relates two actions of the same thread, reads and writes on the
same variable by different threads, and lock acquisition and release
actions of the same lock in different threads. We deÔ¨Åne the partial
orderEEon the set of program events as the least partial
order relation that satisÔ¨Åes the condition that (ei;ej)2whenever
ai=[i],aj=[j],ij, and (a;a0)2Dwhereaiandajare
actions performed by events eiandej, respectively.
Let us deÔ¨Åne as the smallest subset of events of that
satisÔ¨Åes the following properties: (1) contains events eandf,
(2) for any event e0in, all events e00e0are in, and
(3) for every event corresponding to a lock acquire in, its
corresponding release event is also in .
The intuition is that events that are not in are not relevant for
the scheduling of the null-WR pair ; they are either far enough in the
future, or are not dependent on any of the events in . The Ô¨Ågure
below presents a run of a program with 4 threads that is projected
into individual threads. Here, ebelongs to thread T1andfbelongs
to threadT2. The cut labeled marks the boundary after which
all events are not causally before eandf, and hence, need not be
considered for the generation of the new run.
Next, we identify a causally preÔ¨Åx-closed set of events before e
andfto remove. For the null-WR pair, deÔ¨Åneas the largestsubset of events of that has the following properties: (1) it does
not containeorf, (2) for any event e0in, all eventse00e0
are in, and (3) for any event e0inTisuch thate0is the last
event ofTiin(with respect tovi), the lockset associated to e0
inTiis empty. In the above Ô¨Ågure, the curve labeled marks the
boundary of , and eventsT1;:::;T 4have empty lock-sets.
T1
T2
T3
T4
f
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
e
œÅŒ±
œÉŒ±
t1
t2
t3
t4
ŒªŒ±
The run segment
relevant to a null-
WR pairis then
deÔ¨Åned as the set of
events in=n
scheduled according to
the total order in ().
One can use a simple
worklist algorithm to
compute both and
, and consequently
. This run segment is passed to the run prediction phase, in the
place of the whole run .
8. Implementation
We have implemented our approach in a tool named E XCEP -
TIONULL . Figure 3 demonstrates the architecture of E XCEP -
TIONULL . It consists of three main components: a monitor, a run
predictor, and a scheduler. The monitor and scheduler are built on
top of the P ENELOPE tool framework, with considerable enhance-
ments and optimizations, including the extension of the monitoring
to observe values of shared variables at reads and writes. In the fol-
lowing, we will explain each of these components in more details.
Monitor: The monitor component has an instrumenter which uses
the Bytecode Engineering Library (BCEL) [4] to (automatically)
instrument every class Ô¨Åle in bytecode so that a callto an event
recorder is made after each relevant action is performed. These
relevant actions include Ô¨Åeld and array accesses, acquisition and
releases of locks, thread creations and thread joins, etc., but ex-
clude accesses to local variables. The instrumented classes are then
used in the Java Virtual Machine (JVM) to execute the program
and get an observed run. For the purpose of generating the data-
validity constraints, the values read/written by shared variable ac-
cesses are also recorded. For variables with primitive types (e.g.
Boolean, integer, double, etc), we just use the values read/written.
Objects and arrays are treated differently; the object hash code (by
System.identityHashCode() ) is used as the value every
time an object or an array is accessed.
Run Predictor: The run predictor consists of several components:
null-WR pair extractor, segment generator, constraint generator,
Z3 SMT solver, and run extractor. The null-WR pair extractor
generates a set of null-WR pairs from the observed run by the
static lock analysis described in Section 4. The segment generator
component, for each null-WR pair= (e;f), isolates a part of 0.1 1 10 100 1000 10000
RayTracer Pool 1.2 Pool 1.3 Pool 1.5 SBuckerMap Vector Stack HashSet StringBuffer FtpServer Hedc WeblechTime (Seconds)Prediction Time (w/o Pruning)
Prediction Time (w Pruning)Figure 4. Prediction times with/without pruning in log scale.
runthat is relevant toas described in Section 7 and passes it
to the constraint generator. Given a null-WR pair and the relevant
segment, the constraint generator produces a set of constraints,
based on the algorithm presented in Section 5, and passes it to the
Z3. Any model found by Z3 corresponds to a concurrent schedule.
The run extractor component generates a run based on the model
returned by Z3. When Z3 cannot Ô¨Ånd a solution, the constraint
generator iteratively weakens the constraints (see Section 6) and
calls Z3 until a solution is found.
Scheduler: The scheduler is implemented using BCEL [4] as well;
we instrument the scheduling algorithm into the Java classes using
bytecode transformations, so that the program interacts with the
scheduler when it is executing the same set of events that were
monitored. The scheduler, at each point, looks at the predicted run,
and directs the appropriate thread to perform a sequence of nsteps.
The threads wait for a signal from the scheduler to proceed, and
only then do they execute the number of (observable) events they
are instructed to execute. Afterwards, the threads communicate
back to the scheduler, relinquishing the processor, and await further
instructions. The communication between the scheduler and the
threads is implemented using wait-notify synchronization which
allows us to have a Ô¨Ånely orchestrated scheduling process.
Data-Race Prediction: Our proposed monitoring, logic-based
precise and relaxed prediction on statically pruned runs, and the
rescheduling is a general framework and can be adapted to errors
other than null-pointer dereferences as well. In order to study the
effects of relaxed prediction and static pruning, we implemented
a data-race prediction unit as well to our tool, as data-races are a
more well studied class of errors for which precise prediction has
been studied. Due to lack of space, we do not discuss the details of
the data race detection unit here.
9. Evaluation
We subjected E XCEPTIO NULL to a benchmark suite of 13 con-
current programs, against several test cases and input parameters.
Experiments were performed on an Apple MacBook with 2 Ghz
Intel Core 2 Duo processors and 2GB of memory, running OS X
10.4.11 and Sun‚Äôs Java HotSpot 32-bit Client VM 1.5.0.
Benchmarks. The benchmarks are all concurrent Java programs
that use synchronized blocks and methods as means of syn-
chronization. They include RayTracer from the Java Grande
multi-threaded benchmarks [3], elevator from ETH [28], Vector ,
Stack ,HashSet andStringBuffer from Java libraries,
Pool (three different releases) and StaticBucketMap from
the Apache Commons Project [5], Apache FtpServer from
[7],Hedc from [6], and Weblech from [8]. elevator simulates
multiple lifts in a building; RayTracer renders a frame of an ar-
rangement of spheres from a given view point; Pool is an object
pooling API in the Apache Commons suite; StaticBucketMap
is a thread-safe implementation of the Java Map Interface; Apache
FtpServer is a FTP server by Apache; and Vector ,Stack ,HashSet andStringBuffer are Java libraries that respec-
tively implement the concurrent vector, the concurrent stack, the
HashSet and the StringBuffer data structures. Hedc is a Web
crawler application and Weblech is a websites download tool.
Experimental Results. Table 1 illustrates the experimental re-
sults for null-pointer dereference prediction ; information is pro-
vided about all the three phases of monitoring, run prediction, and
scheduling.
In the monitoring phase, the number of threads, shared vari-
ables, locks, the number of potential interleaving points (i.e. num-
ber of global events), and the time taken for monitoring are re-
ported. For the prediction phase, we report the number of null-
WRpairs in the observed run, the number of precisely predicted
runs, and the additional number of predicted runs after relaxing the
data-validity constraints (when there is no precisely predicted run
for a null read-write pair). In the scheduling phase, we report the
total number of schedulable predictions among the predicted ones.
Finally, we report the average time for prediction and rescheduling
of each run, the total time taken to complete the tests (for on all
phases on all predicted executions), and also the number of errors
found using the precise and relaxed predicted runs.
Errors Found. In almost all the cases, the errors manifested in
the form of raised exceptions during the execution. In Weblech ,
in addition to a null-pointer dereference, an unwanted behavior
occurred (the user is asked to push a stop button even after the
website is downloaded completely, resulting in non-termination!).
RayTracer has a built-in validation test which was failed in some
of the predicted runs. For some of the test cases of Vector and
Stack the output produced was not the one expected. We report
the errors found in two categories; those that were found through
the precise prediction algorithm, and those that were found after
weakening data-validity constraints (relaxation).
The effect of pruning: Figure 4 illustrates the substantial impact
of our pruning algorithm in reducing prediction time. We present
prediction times with and without using the pruning algorithm.
Note that the histogram is on a logarithmic scale. For example,
in the case of Weblech , the prediction algorithm is about 16
times faster with pruning. Furthermore, all errors found without the
pruning were found on the pruned runs, showing that the pruning
did not affect the quality of error-Ô¨Ånding on our benchmarks.
Data Race Detection. Table 2 presents the results of data-race
prediction on our benchmarks using the same observed runs as in
the null-reads prediction. For each benchmark we report the total
number of data-races found; these are all distinct races identiÔ¨Åed
by the code location of the racy access. We also report the number
of distinct variables involved in data-races. For brevity, information
about different test cases is aggregated for each benchmark (see [1]
for more details).
Observations: EXCEPTIO NULL performs remarkably well, pre-
dicting a large number of feasible program runs on which there are
null-pointer dereferences and data-races. In total, it Ô¨Ånds about 40
executions with null-pointer dereferences and 60 races, which to
our knowledge, is the most successful attempt at Ô¨Ånding errors on
Application
Elevator
RayTracer
Pool 1.2
Pool 1.3
Pool 1.5
SBucketMap
Vector
Stack
HashSet
StringBuffer
FtpServer
Hedc
WeblechTotal
Num. of Data-Races
(by precise prediction)-35-81116-855 43
Additional Data-Races
(by relaxation)-30-20113-304 17
Number of Distinct
Involved Variables-13-41223-743 31
Table 2. Experimental Results for data race prediction.Monitoring Prediction Scheduling
Application
(LOC)
Input
Base
Num. of Threads
Num. of
Shared Variables
Num. of Locks
Num. of Potential
Interleaving Points
Time to Monitor
Num. of null-WR
Pairs
Num. of Precisely
Predicted Runs
Additional Predicted
Runs by Relaxation
Num. of
Schedulable
Predictions
Average Time per
Predicted Run
Total Time
Null Pointer
Deref. by Precise
Prediction
Additional
Null-Pointer
Deref. by
Relaxation
Elevator
(566)Data 7.3s 3 116 814K 7.4s 0 - - - - 7.9s 0 0
Data2 7.3s 5 168 830K 7.4s 0 - - - - 8.9s 0 0
Data3 19.2s 5 723 50150K 19.0s 0 - - - - 58.5s 0 0
RayTracer
(1.5K)A-10 5.0s 10 106 10 648 5.0s 9 9 - 9 5.6s 50.5s 10
A-20 3.6s 20 196 20 1.7K 4.4s 19 19 - 19 6.7s 2m15s 10
B-10 42.4s 10 106 10 648 42.5s 9 9 - 9 42.7s 6m24s 10
Pool 1.2
(5.8K)PT1 <1s 4 28 1 98<1s 3 2 1 3<1s 1.6s 2 0
PT2 <1s 4 29 1 267<1s 3 0 0 - - 8.8s 0 0
PT3 <1s 4 20 3 180<1s 26 0 23 16 1.2s 27.0s 0 3
PT4 <1s 4 24 3 360<1s 32 2 21 15 2.5s 57.8s 0 1
Pool 1.3
(7K)PT1 <1s 4 30 1 100<1s 3 0 3 3<1s 2.6s 0 0
PT2 <1s 4 31 1 271<1s 3 0 0 - - 9.8s 0 0
PT3 <1s 4 20 3 204<1s 35 0 30 19 1.4s 42.9s 0 0
PT4 <1s 4 23 3 422<1s 62 1 48 29 2.2s 1m49s 0 1
Pool 1.5
(7.2K)PT1 <1s 4 33 2 124<1s 2 0 1 1 1.5s 1.5s 0 0
PT2 <1s 4 34 2 306<1s 5 0 1 0 10.5s 10.5s 0 0
PT3 <1s 4 15 2 108<1s 3 0 0 - - 4.1s 0 0
PT4 <1s 4 18 2 242<1s 18 1 7 8 3.4s 27.4s 0 1
SBucketMap
(750)SMT <1s 4 123 19 892<1s 2 2 - 2<1s 1.3s 1 0
Vector
(1.3K)VT1 <1s 4 44 2 370<1s 21 11 10 21<1s 14.3s 2 0
VT2 <1s 4 34 2 536<1s 31 21 10 31 1.1s 33.0s 1 0
VT3 <1s 4 34 2 443<1s 32 22 10 32<1s 22.1s 1 0
VT4 <1s 4 29 2 517<1s 30 0 30 30 2s 59.4s 0 1
VT5 <1s 4 29 2 505<1s 85 1 84 82 2s 2m57s 0 1
Stack
(1.4K)ST1 <1s 4 29 2 205<1s 11 6 5 11<1s 5.5s 2 0
ST2 <1s 4 24 2 251<1s 16 11 5 15<1s 10.9s 1 0
ST3 <1s 4 24 2 248<1s 17 12 5 17<1s 10.3s 1 0
ST4 <1s 4 29 2 515<1s 30 0 30 30 1.8s 53.2s 0 1
ST5 <1s 4 29 2 509<1s 85 1 84 83 2.0s 2m51s 0 1
HashSet
(1.3K)HT1 <1s 4 76 1 432<1s 7 7 - 7<1s 3.2s 1 0
HT2 <1s 4 54 1 295<1s 0 - - - - <1s 0 0
StringBuffer
(1.4K)SBT <1s 3 16 3 80<1s 2 2 - 2<1s 1.3s 1+0
Apache
FtpServer
(22K)LGN 1m2s 4 112 4 582 60s 116 78 32 65 1m13s 2h14m46s 9 3
Hedc
(30K)Std 1.7s 7 110 6 602 1.74s 18 9 1 10 11.7s 1m57s 1 0
Weblech
v.0.0.3
(35K)Std 4.9s 3 153 31.6K 4.92s 55 10 29 30 16.26s 10m34s 1 1@
Total Number of Errors 27 14
Table 1. Experimental results for predicting null-reads. Errors tagged withrepresent test harness failures. Errors tagged with+represent
array-out-of-bound exceptions. Errors tagged with@represent unexpected behaviors. All other errors are null-pointer dereference exceptions.
these benchmarks in the literature. Furthermore, all the errors are
completely reproducible deterministically using the scheduler.
We count exceptions raised in different parts of the code as
separate errors. More precisely, each error reported in Table 1
consists of a unique read-write pair in the code that were forced to
perform a null-read and that resulted in an error. For example, the
12 exceptions in FtpServer are raised in 7 different functions
and at different locations inside the functions, and involve null-
pointer dereferences on 5 different variables.
The prediction algorithm works extremely well‚Äî while there
were several runs that were predicted in the precise model, the re-laxed prediction gives a lot more predictions, and a large fraction of
these were schedulable. The time taken for prediction and schedul-
ing are very reasonable for the kind of targeted analysis that we
perform, despite the use of fairly sophisticated static analysis and
logic-solvers.
The number of data-races found using relaxed prediction fur-
ther shows the efÔ¨Åcacy of relaxed prediction. A further 17 data-
races were found using relaxed prediction, showing that predicting
beyond the maximal causal model can be effective even in Ô¨Ånding
errors other than null-pointer dereferences.References
[1]http://www.cs.uiuc.edu/ sorrent1/penelope
/exceptionull .
[2]http://research.microsoft.com/en-us/projects
/poirot .
[3]http://www.javagrande.org/ .
[4]http://jakarta.apache.org/bcel .
[5]http://commons.apache.org .
[6]http://www.hedc.ethz.ch .
[7]http://mina.apache.org/ftpserver .
[8]http://weblech.sourceforge.net .
[9] F. Chen and G. Ros ¬∏u. Parametric and sliced causality. In CAV, pages
240‚Äì253, 2007.
[10] F. Chen, T.F. Serbanuta, and G. Ros ¬∏u. JPredictor: a predictive runtime
analysis tool for java. In ICSE , pages 221‚Äì230, 2008.
[11] L. de Moura and N. Bj√∏rner. Z3: An efÔ¨Åcient smt solver. In TACAS ,
pages 337‚Äì340, 2008.
[12] M. Emmi, S. Qadeer, and Z. Rakamaric. Delay-bounded scheduling.
InPOPL , pages 411‚Äì422, 2011.
[13] A. Farzan, P. Madhusudan, and F. Sorrentino. Meta-analysis for
atomicity violations under nested locking. In CAV, pages 248‚Äì262,
2009.
[14] J. Huang and C. Zhang. Persuasive prediction of concurrency access
anomalies. In ISSTA , pages 144‚Äì154, 2011.
[15] V . Kahlon, F. Ivancic, and A. Gupta. Reasoning about threads com-
municating via locks. In CAV, pages 505‚Äì518, 2005.
[16] S.K. Lahiri, S. Qadeer, and Z. Rakamari ¬¥c. Static and precise detection
of concurrency errors in systems code using smt solvers. In CAV, pages
509‚Äì524, 2009.
[17] Zhifeng Lai, S.C. Cheung, and W.K. Chan. Detecting atomic-set se-
rializability violations in multithreaded programs through active ran-
domized testing. In ICSE , pages 235‚Äì244, 2010.
[18] M. Musuvathi and S. Qadeer. Iterative context bounding for systematic
testing of multithreaded programs. In PLDI , pages 446‚Äì455, 2007.
[19] C-S Park and K. Sen. Randomized active atomicity violation detection
in concurrent programs. In FSE, pages 135‚Äì145, 2008.
[20] S. Park, S. Lu, and Y . Zhou. CTrigger: exposing atomicity violation
bugs from their hiding places. In ASPLOS , pages 25‚Äì36, 2009.
[21] Z. Rakamari ¬¥c. STORM: static unit checking of concurrent programs.
InICSE , pages 519‚Äì520, 2010.
[22] M. Said, C. Wang, Z. Yang, and K. Sakallah. Generating data race
witnesses by an smt-based analysis. In Proceedings of the Third
international conference on NASA Formal methods , NFM‚Äô11, pages
313‚Äì327, Berlin, Heidelberg, 2011. Springer-Verlag.
[23] T.F. S ¬∏erb Àòanut ¬∏Àòa, F. Chen, and G. Ros ¬∏u. Maximal causal models for se-
quentially consistent systems. Technical report, University of Illinois
at Urbana-Champaign, October 2011.
[24] N. Sinha and C. Wang. Staged concurrent program analysis. In FSE,
pages 47‚Äì56, 2010.
[25] N. Sinha and C. Wang. On interference abstractions. In POPL , pages
423‚Äì434, 2011.
[26] Y . Smaragdakis, J. Evans, C. Sadowski, J. Yi, and C. Flanagan. Sound
predictive race detection in polynomial time. In POPL , pages 387‚Äì
400, 2012.
[27] F. Sorrentino, A. Farzan, and P. Madhusudan. PENELOPE: weaving
threads to expose atomicity violations. In FSE, pages 37‚Äì46, 2010.
[28] C. von Praun and T. R. Gross. Object race detection. SIGPLAN Not. ,
36(11):70‚Äì82, 2001.
[29] C. Wang, S. Kundu, M. Ganai, and A. Gupta. Symbolic predictive
analysis for concurrent programs. In Proceedings of the 2nd World
Congress on Formal Methods , FM ‚Äô09, pages 256‚Äì272, Berlin, Hei-
delberg, 2009. Springer-Verlag.[30] C. Wang, R. Limaye, M. Ganai, and A. Gupta. Trace-based symbolic
analysis for atomicity violations. In TACAS , pages 328‚Äì342, 2010.
[31] L. Wang and S. D. Stoller. Accurate and efÔ¨Åcient runtime detection of
atomicity errors in concurrent programs. In PPoPP , pages 137‚Äì146,
2006.
[32] L. Wang and S. D. Stoller. Runtime analysis of atomicity for multi-
threaded programs. IEEE Transactions on Software Engineering ,
32:93‚Äì110, 2006.
[33] J. Yi, C. Sadowski, and C. Flanagan. SideTrack: generalizing dynamic
atomicity analysis. In PADTAD , pages 1‚Äì10, 2009.
[34] W. Zhang, J.Lim, R. Olichandran, J. Scherpelz, G. Jin, S. Lu, and T. W.
Reps. Conseq: detecting concurrency bugs through sequential errors.
InASPLOS , pages 251‚Äì264, 2011.
[35] W. Zhang, C. Sun, and S. Lu. Conmem: detecting severe concurrency
bugs through an effect-oriented approach. In ASPLOS , pages 179‚Äì192,
2010.