Don‚Äôt Touch My Code!
Examining the Effects of Ownership on Software Quality
Christian Bird
Microsoft Research
cbird@microsoft.comNachiappan Nagappan
Microsoft Research
nachin@microsoft.comBrendan Murphy
Microsoft Research
bmurphy@microsoft.com
Harald Gall
University of Zurich
gall@iÔ¨Å.uzh.chPremkumar Devanbu
University of California, Davis
ptdevanbu@ucdavis.edu
ABSTRACT
Ownership is a key aspect of large-scale software develop-
ment. We examine the relationship between dierent own-
ership measures and software failures in two large software
projects: Windows Vista and Windows 7. We nd that
in all cases, measures of ownership such as the number of
low-expertise developers, and the proportion of ownership
for the top owner have a relationship with both pre-release
faults and post-release failures. We also empirically iden-
tify reasons that low-expertise developers make changes to
components and show that the removal of low-expertise con-
tributions dramatically decreases the performance of contri-
bution based defect prediction. Finally we provide recom-
mendations for source code change policies and utilization
of resources such as code inspections based on our results.
Categories and Subject Descriptors
D.2.8 [ Software Engineering ]: Metrics| Process metrics
General Terms
Measurement, Management, Human Factors
Keywords
Empirical Software Engineering, Ownership, Expertise, Qual-
ity
1. INTRODUCTION
Many recent studies [6, 9, 26, 29] have shown that hu-
man factors play a signicant role in the quality of software
components. Ownership is a general term used to describe
whether one person has responsibility for a software com-
ponent, or if there is no one clearly responsible developer.
Within Microsoft, we have found that when more people
work on a binary, it has more failures [5, 26]. However, to
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ESEC/FSE‚Äô11, September 5‚Äì9, 2011, Szeged, Hungary.
Copyright 2011 ACM 978-1-4503-0443-6/11/09 ...$10.00.our knowledge, the eect of ownership has not been stud-
ied in depth in commercial contexts. Based on our observa-
tions and discussions with project managers, we suspect that
when there is no clear point of contact and the contributions
to a software component are spread across many developers,
there is an increased chance of communication breakdowns,
misaligned goals, inconsistent interfaces and semantics, all
leading to lower quality.
Interestingly, unlike some aspects of software which are
known to be related to defects such as dependency com-
plexity, or size, ownership is something that can be delib-
erately changed by modifying processes and policies. Thus,
the answer to the question: \How much does ownership af-
fect quality?" is important as it is actionable . Managers and
team leads can make better decisions about how to govern
a project by knowing the answer. If ownership has a big
eect, then policies to enforce strong code ownership can be
put into place; managers can also watch out for code which
is contributed by developers who have inadequate relevant
prior experience. If ownership has little eect, then the nor-
mal bottlenecks associated with having one person in charge
of each component can be removed, and available talent re-
assigned at will.
We have observed that many industrial projects encour-
age high levels of code ownership. In this paper, we examine
ownership and software quality. We make the following con-
tributions in this paper:
1. We dene and validate measures of ownership that are
related to software quality.
2. We present an in depth quantitative study of the eect
of these measures of ownership on pre-release and post-
release defects for multiple large software projects.
3. We identify reasons that components have many low-
expertise developers contributing to them.
4. We propose recommendations for dealing with the ef-
fects of low ownership.
2. THEORY & RELATED WORK
A number of prior studies have examined the eect of
developer contribution behavior on software quality.
Rahman & Devanbu [30] examined the eects of owner-
ship & experience on quality in several open-source projects,
using a ne-grained approach based on x-inducing frag-
ments of code, and report ndings similar to those of ourpaper. However, they operationalize ownership dierently,
and ownership policies and practices in OSS and commercial
software are quite dierent. Thus the similarity of eect is
striking. Furthermore, Rahman & Devanbu do not study the
relationship of minor contribution on software dependencies;
nor do they consider social network measures.
Weyuker et al. [35], examined the eect of including team
size in prediction models. They use a count of the develop-
ers that worked on each component, but do not examine the
proportion of work, which we account for. They found a neg-
ligible increase in failure prediction accuracy when adding
team size to their models. We dier in that we examine
theproportion of contributions made by each developer to
a component. Further, we are not interested in prediction,
but rather determining if there is a statistically signicant
relationship between ownership and failures.
Similarly, Meneely and Williams examined the relation-
ship of the number of developers working on parts of the
Linux kernel with security vulnerabilities [19]. They found
that when more than nine developers contribute to a source
le, it is sixteen times more likely to include a security vul-
nerability.
New methods such as Extreme Programming (XP) [4] pro-
fess collective code ownership but there has been little em-
pirical evidence or backing of this data on reasonably ma-
ture/complex or large systems. Our study is the rst to em-
pirically quantify the eect code owners (and low-expertise
contributors) have on the overall code quality.
Domain, application, and even component-specic knowl-
edge are important aids for helping developers to maintin
high quality software. Boh et al. found that project specic
expertise has a much larger impact on the time required to
perform development tasks than high levels of diverse expe-
rience in unrelated projects [7]. In a qualitative study of 17
commercial software projects, Curtis et al. [10] found that
\the thin spread of application domain knowledge" was one
of the top three salient problems. They also found that one
common trait among engineers categorized as \exceptional"
was that they had deep domain knowledge, and understood
how the system design would generate the system behavior
customers expected, even under exceptional circumstances.
Such knowledge is not easily obtained. One systems engi-
neer explained, \Someone had to spend a hundred million to
put that knowledge in my head. It didn't come free."
The question naturally arises, how can we determine who
has such domain knowledge? Fortunately, there is a wealth
of literature that uses the prior development activity on a
component as a proxy for expertise and knowledge with re-
spect to the component. As examples Expertise Browser
from Mockus et al. [22] and Expertise Recommender from
McDonald and Ackerman [18] both use measures of the
amount of work that a developer has performed on a soft-
ware component to recommend component experts. Fritz
et al. found that the ability of a developer to answer ques-
tions about a piece of code in a system was strongly deter-
mined by whether the developer had authored some of the
code, and how much time was spent authoring it [15].
Mockus and Weiss used properties of an individual change
to predict the probability of that change causing a fail-
ure [23]. They found that changes made by developers that
were more experienced with a piece of code were less likely to
induce failure. Three of their fourteen measures capture theexperience of a developer history (by counting prior changes)
and they were signicant in prediction.
In a study of oshoring and succession in software devel-
opment [21], Mockus evaluated a number of succession mea-
sures with the goal of being able to automatically identify
mentors for developers working on a per-component basis.
A succession measure based on ownership was able to accu-
rately pinpoint the most likely method and was used in a
large scale study evaluating the factors aecting productiv-
ity in project succession and oshoring.
Research in other domains, such as manufacturing, has
found that when a worker performs a task repeatedly, the
labor requirements to complete subsequent work in the same
task decreases and the quality increases [11]. Software de-
velopment diers from these domains in that workers do not
perform the exact same task repeatedly. Rather, software
development represents a form of constant problem solving
in which tasks are rarely exactly the same, but may be sim-
ilar. Nonetheless, developers gain project and component
specic knowledge as they repeatedly perform tasks on the
same systems [32]. Banker et al. found that increased ex-
perience increases a developer's knowledge of the architec-
tural domain of the system [1]. Repeatedly using a particu-
lar API, or working on a particular system creates episodic
knowledge . Robillard indicates that the lack of such knowl-
edge negatively aects the quality of software [31]. Indeed,
Basili and Caldiera present an approach for improving qual-
ity in software development through learning and experience
by establishing \experience factories" [2]. They claim that
by reusing knowledge, products, and experience, companies
can maintain high quality levels because developers do not
need to constantly acquire new knowledge and expertise as
they work on dierent projects. Drawing on these ideas,
we develop ownership measures which consider the number
of times that a developer works on a particular component,
with the idea that each exposure is a learning experience
and increases the developer's knowledge and abilities.
there is a knowledge-sharing factor at play as well. The
set of developers that contribute to a component implicitly
form a team that has shared knowledge regarding the seman-
tics and design of the component. Coordination is a known
problem in software development [16]. In fact, another of
the top three problems identied in Curtis' study [10] was
\communication and coordination breakdowns." Working
in such a group always creates a need for sharing and in-
tegrating knowledge across all members [8]. Cataldo et al.
showed that communication breakdowns delay tasks [9]. If
a member of this team devotes little attention to the team
and/or the component, they may not acquire the knowledge
required to make changes to the component without error.
We attempt to operationalize these team members in this
paper and examine their eect on quality.
If ownership of a particular component in a system (whether
it be a le, class, module, plugin, or subsystem) is a valid
proxy for expertise, then what is the eect of having most
changes made by those with little expertise? Is it better
to have one clear owner of a software component? We op-
erationalize ownership in two key ways here and formally
dene our measures in section 3. One measure of ownership
is how much of the development activity for a component
comes from one developer. If one developer makes 80% of
the changes to a component, then we say that the compo-
nent has high ownership. The other way that we measure!"#$%&%'()*%+'",-+("./)‚Ä¢ !"#$%&'$#(%")*($%)0)1)2"+%$)#%+($"34(%$)(%).)#%25%+-+()"&).)#%+($"34(%$)67%&-)%6+-$&7"5)"&).()%$)3-/%6)89:));7"&)(7$-&7%/,)6.&)#7%&-+)3.&-,)%+)-<.2"+.("%+)%'),"&($"34("%+&)%')%6+-$&7"5=)34().)+423-$)%')(7$-&7%/,)>./4-&)$.+?"+?)'$%2)@9)(%)AB9).//)C"-/,"+?)&"2"/.$)$-&4/(&:)‚Ä¢ !+,$%& '$#(%")*($%)0)1)2.D%$)#%+($"34(%$)(%).)#%25%+-+()"&).)#%+($"34(%$)67%&-)%6+-$&7"5)"&).3%>-)89:)E"(7)(7-&-)(-$2&),-'"+-,)6-)+%6)"+($%,4#-)%4$)2-($"#&).+,),"&#4&&)(7-)"+(4"("%+)3-7"+,)(7-2:)))‚Ä¢ F423-$)%')!"+%$)*%+($"34(%$&)G!-./0H)‚Ä¢ F423-$)%')!.D%$)*%+($"34(%$&)G!12/0H)‚Ä¢ ;%(./)F423-$)%')*%+($"34(%$&)G3/314H)‚Ä¢ I$%5%$("%+)%')J6+-$&7"5)'%$)(7-)#%+($"34(%$)(7.()2.K-&)(7-)2%&()#%22"(&)G/5.6078-9H)
)!"#$%&'(')'*%+,-'./',%.,.%0".1'./'2.33"04'0.'+5.2.3,6788'59'7&:&8.,&%4'7$%"1#';"40+'7&:&8.,3&10'2928&6'L"?4$-) A) &7%6&) (7-) 5$%5%$("%+) %') #%22"(&) '%$) -.#7) %') (7-) ,->-/%5-$&) (7.() #%+($"34(-,) (%)abocomp.dll "+)E"+,%6&)M"&(.=)"+),-#$-.&"+?)%$,-$:));7"&)/"3$.$C)7.,).)(%(./)%')NAO)#%22"(&)2.,-),4$"+?) (7-) ,->-/%52-+() #C#/-:) ) ;7-) (%5) #%+($"34("+?) -+?"+--$) 2.,-) PQN) #%22"(&=) $%4?7/C) RA9:) )L">-)-+?"+--$&)2.,-).()/-.&()89)%')(7-)#%22"(&)G.()/-.&()RS)#%22"(&H:));6-/>-)-+?"+--$&)2.,-)/-&&)(7.+)89)%')(7-)#%22"(&)G/-&&)(7.+)RS)#%22"(&H:))L"+.//C=)(7-$-)6-$-).)(%(./)%')&->-+(--+)-+?"+--$&)(7.()2.,-)#%22"(&)(%)(7-)3"+.$C:));74&=)%4$)2-($"#&)'%$).3%#%25:,//).$-T)<&0%"2';+8$&'!UFJV)8)!1WJV)A@)
Figure 1: Graph of the proportion of commits to abocamp.dll by developers during the Vista development cycle, showing the
four measures of ownership used in this paper.
ownership is by determining how many low-expertise de-
velopers are working on a component. If many developers
are all making few changes to a component, then there are
many non-experts working on the component and we label
the component as having low ownership.
We expect that having one clear \owner" for a compo-
nent will lead to fewer failures and that when many non-
experts are making changes, indicating that ownership is
spread across many contributors, the component will have
more failures.
3. TERMINOLOGY AND METRICS
We adopt Basili's goal question metric approach [3] to
frame our study of ownership. Our goal is to understand
the relationship between ownership and software quality. We
also hope to gain an understanding of how this relationship
varies with the development process in use. Achievement of
this goal can lead to more informed development decisions
or possibly process policy changes resulting in software with
fewer defects.
In order to reach this goal, we ask a number of specic
questions:
1. Are higher levels of ownership associated with less de-
fects?
2. Is there a negative eect when a software entity is de-
veloped by many people with low ownership?
3. Are these eects related to the development process
used?
In order to answer these questions, we propose a number of
ownership metrics and use them to evaluate our hypotheses
of ownership. We begin by dening some important terms
and metrics used throughout the rest of this paper:
Software Component { This is a unit of develop-
ment that has some core functionality. Defects canbe traced back to a specic component and software
changes from developers can also be traced to a compo-
nent. In Windows, a component is a compiled binary.
Contributor { A contributor to a software com-
ponent is someone who has made commits/software
changes to the component.
Proportion of Ownership { The proportion of own-
ership (or simply ownership) of a contributor for a
particular component is the ratio of number of com-
mits that the contributor has made relative to the to-
tal number of commits for that component. Thus, if
Cindy has made 20 commits to ie9.dll and there are
a total of 100 commits to ie9.dll then Cindy has an
ownership of 20%.
Minor Contributor { A developer who has made
changes to a component, but whose ownership is below
5% is considered a minor contributor to that compo-
nent. This threshold was chosen based on examination
of distributions of ownership1. We refer to a commit
from a minor contributor as a minor contribution.
Major Contributor { A developer who has made
changes to a component and whose ownership is at or
above 5% is a major contributor to the component and
a commit from such a developer is a major contribu-
tion.
Note that we examine the number of changes to a compo-
nent made by a developer rather than the actual number of
lines modied. Within Windows, each change corresponds
to one x or enhancement and individual changes are quite
small, usually on the order of tens of lines. We use number
of changes because each change represents an \exposure" of
the developer to the code and because the previous measure
1A sensitivity analysis with threshold values ranging from
2% to 10% yielded similar results.3
Ownership of A.dll by Developers(a) A.dll
3
Ownership of B.dll by Developers (b) B.dll
Figure 2: Ownership graphs for two binaries in Windows
of experience used by Mockus and Weiss also used the num-
ber of changes. However, prior literature [14] has shown high
correlation (above 0.9) between number of changes and num-
ber of lines contributed and we have found similar results in
Windows, indicating that our results would not change sig-
nicantly. With these terms dened, we now introduce our
metrics.
Minor { number of minor contributors
Major { number of major contributors
Total { total number of contributors
Ownership { proportion of ownership for the contrib-
utor with the highest proportion of ownership
Figure 1 shows the proportion of commits for each of the
developers that contributed to abocomp.dll in Windows, in
decreasing order. This library had a total of 918 commits
made during the development cycle. The top contributing
engineer made 379 commits, roughly 41%. Five engineers
made at least 5% of the commits (at least 46 commits).
Twelve engineers made less than 5% of the commits (less
than 46 commits). Finally, there were a total of seventeen
engineers that made commits to the binary. Thus, our met-
rics for abocomp.dll are:
Metric Value
Minor 12
Major 5
Total 17
Ownership 0.41
4. HYPOTHESES
We begin with the observation that a developer with lower
expertise is more likely to introduce bugs into the code. A
developer who has made a small proportion of the commits
to a binary likely has less expertise and is more likely to
make an error. We expect that as the number of develop-
ers working on a component increases, the component may
become \fragmented" and the diculty of vetting and coor-
dinating all these minor contributions becomes an obstacle
to good quality. Thus if Minor is high, quality suers.Hypothesis 1 - Software components with many minor con-
tributors will have more failures than software components
that have fewer.
We also look at the proportion of ownership for the highest
contributing developer for each component ( Ownership ). If
Ownership is high, that indicates that there is one devel-
oper who \owns" the component and has a high level of ex-
pertise. This person can also act as a single point of contact
for others who need to use the component, need changes to
it, or just have questions about it. We theorize that when
such a person exists, the software quality is higher resulting
in fewer failures.
Hypothesis 2 - Software components with a high level of
ownership will have fewer failures than components with
lower top ownership levels.
If the number of minor contributors negatively aects soft-
ware quality, the next question to ask is, \Why do some
binaries have so many minor contributors?" We have ob-
served both at Microsoft and also within OSS projects such
as Python and Postgres, that during the process of mainte-
nance, feature addition, or bug xing, owners of one compo-
nent often need to modify other components that the rst
relies on or is relied upon by. As a simple example, a devel-
oper tasked with xing media playback in Internet Explorer
may need to make changes to the media playback interface li-
brary even though the developer is not the designated owner
and has limited experience with this component. This leads
to our hypothesis.
Hypothesis 3 - Minor contributors to components will be
Major contributors to other components that are related
through dependency relationships
Finally, if low-expertise contributions do have a large im-
pact on software quality, then we expect that defect predic-
tion techniques will be aected by their inclusion or removal.
We therefore replicate prior defect prediction techniques and
compare results when using all data, data derived only from
changes by minor contributors and, and data derived only
from changes to major contributors. We expect that when
data from minor contributors is removed, the quality of the
defect prediction will suer.Windows Vista Windows 7
Category MetricPre-release Post-release Pre-release Post-release
Failures Failures Failures Failures
Ownership
MetricsTotal 0.84 0.70 0.92 0.24
Minor 0.86 0.70 0.93 0.25
Major 0.26 0.29 -0.40 -0.14
Ownership -0.49 -0.49 -0.29 -0.02
\Classic"
MetricsSize 0.75 0.69 0.70 0.26
Churn 0.72 0.69 0.71 0.26
Complexity 0.70 0.53 0.56 0.37
Table 1: Bivariate Spearman correlation of ownership and code metrics with pre- and post-release failures in Windows Vista
and Windows 7. All correlations are statistically signicant except for that of Ownership and post-release failures in Windows
7.
Hypothesis 4 - Removal of minor contribution information
from defect prediction techniques will decrease performance
dramatically.
5. DATA COLLECTION AND ANALYSIS
This data presents an opportunity to investigate hypothe-
ses regarding code ownership. In this study, we examine
Windows Vista and Windows 7.
Windows Vista and Windows 7 is developed entirely by
Microsoft, who have processes and policies that favor strong
code ownership. Windows Vista and 7 were developed by
2,000+ software developers and is composed of thousands
of individual executable les ( .exe), shared libraries ( .dll),
and drivers ( .sys), which we collectively refer to as binaries .
We track the development history from the release of Win-
dows Server 2003 to the release of Windows 7 and include
pre-release defects as well as post-release failures in Vista
and 7 as software quality indicators.
We require several types of data. The most important
data are the commit histories and software failures. Soft-
ware repositories record the contents of every change made
to a piece of software, along with the change author, the
time of change, and an associated log message that may be
indicative of the type of change (e.g. introducing a feature,
or xing a bug). We collected the number of changes made
by each developer to each source le and used a mapping of
source les to binaries in order to determine the number of
changes made by each developer to each binary. Although
the source code management system uses branches heavily,
we only recorded changes from developers that were edits to
the source code. Branching operations (e.g. branching and
merging) were not counted as changes.
We also gathered both pre-release and post-release soft-
ware failures for all three projects. We gathered the failures
recorded prior to release and in the rst six months after re-
lease. Because of the information contained in the failures,
we can automatically trace them back to the binaries that
caused them, but cannot reliably trace them to the source
les that caused the failures. We only count failures that
the development team deemed important enough to x.
Finally, we gathered source code metrics including vari-
ous size, complexity, and churn metrics. This information
is gathered from both the source code repositories and the
build process.5.1 Analysis Techniques
We use a number of methods to examine the relationship
between ownership and software quality.
We began with a correlation analysis of both pre- and
post-release failures with each of the ownership metrics as
well as a number of other metrics such as test coverage, com-
plexity, size, dependencies, and churn (shown in Table 1).
The results indicated that pre- and post-release defects in
had strong relationships with Minor ,Total , and Owner-
ship. In fact, Minor had a higher correlation with both pre-
and post-release defects in Vista and pre-release defects in
Windows 7 than any other metric that Microsoft collects! .
Post-release failures for Windows 7 present a diculty for
analysis as at the time of this analysis many binaries had no
post-release failures reported. Thus the correlation values
between metrics and and post-release failures are noticeably
lower than the other failure categories (although all except
the correlation with Ownership are still statistically signif-
icant).
However, we also observed some relationship between code
attributes and ownership metrics. For example, Figure 2
shows data for two anonymized binaries in Windows with
vastly dierent ownership proles. Unsurprisingly, the bi-
nary depicted in Figure 2-b ( B.dll ) has more failures than
the binary in Figure 2-a ( A.dll ), eight times as many pre-
release failures and twice as many post-release failures. How-
ever, B.dll is also a larger binary and experienced far more
churn during the development cycle. Thus it is not clear
whether the increase in failures is attributable to more mi-
nor contributors or other measures such as size, complexity,
and churn, which are known to be related to defects [25,28]
and are likely related to the number of minor contributors.
Prior research has shown that when characteristics such as
size are not considered, they may aect the validity of other
software metrics [13].
To overcome this problem, we used multiple linear regres-
sion. Linear regression, is primarily used in two dierent
ways. First, it can be used to make predictions about an
outcome based on prior data (for instance predicting how
many failures a software component may have based on char-
acteristics of the components). We stress that while our re-
gression analysis does use failures as the dependent variable
in our models, the purpose of this paper is notto predict
failures.
Second, linear regression enables us to examine the eectWindows Vista Windows 7
Model Pre-release Post-release Pre-release Post-release
Failures Failures Failures Failures
Base (code metrics) 26% 29% 24% 18%
Base + Total 40%(+14%) 35%(+6%) 68%(+35%) 21%(+3%)
Base + Minor 46%(+20%) 41%(+12%) 70%(+46%) 21%(+3%)
Base + Minor +Major 48%(+2%) 43%(+2%) 71%(+1%) 22% (+1%)
Base + Minor +Major +Ownership 50%(+2%) 44%(+1%) 72%(+1%) 22% (+0%)
Table 2: Variance in failures for the base model which includes standard metrics of complexity, size, and churn, as well as the
models with Minor andOwnership added. An asteriskdenotes that a model showed statistically signicant improvement
when the additional variable was added.
of one or more variables on an outcome when controlling for
other variables. We use it for this purpose in an eort to
examine the relationship of our ownership measures when
controlling for source code characteristics such as size, com-
plexity, and churn .
A linear regression model for failures indicates which vari-
ables have an eect on failures, how large the eect is, in
what direction (i.e. if failures go up when a metric goes
up or when it goes down), and how much of the variance
in the number of failures is explained by the metrics. We
compare the amount of variance in failures explained by a
model that includes the ownership metrics to a model that
does not include them. There are many measures of churn,
complexity, and size. However, to avoid multi-collinearity
and over-tting, we include only one of each measure in the
model; We choose the measure which results in the best
base model. This gives an indication of how much own-
ership actually aects software failures. We examined the
improvement in amount of variance in failures explained by
the metrics (commonly referred to as the adjusted R2) and
examine improved goodness of t using F-tests to determine
if the addition of an ownership metric improves the model
by a statistically signicant degree [12].
Linear regression models can be reliably interpreted if cer-
tain assumptions hold. Two key assumptions are that the
residuals are normally distributed, and not correlated with
any of the independent variables. In our analysis, we found
that the distribution of failures was almost always heavily
right skewed, which led to a similar skew in the residuals.
When we transformed the dependent variable to be the log
of the number of failures, the skew diminished, and the resid-
uals t the normality assumption. This data transformation
was applied to all dependent variables except for post-release
failures in Vista, where linear regression assumptions were
met by the raw data.
6. RESULTS
We now present the results of our analysis of Windows
Vista and Windows 7. Table 2 illustrates the results of
our analysis. We denote with an asterisk, cases where a
goodness-of-t F-test indicated that the addition of a vari-
able improved the model by a statistically signicant degree.
The value in parentheses indicates the percent increase in
variance explained over the model without the added vari-
able. For example, in Table 2 the Base+ Minor +Major
model in Vista explains 48% of the variance in pre-release
failures which is 2% more than the Base+ Minor modelwhich explains 46%. the Base+ Minor model explains 20%
more of the variance in pre-release failures than the Base
model. Adding an independent variable to a model can never
decrease the variance explained, so we use the adjusted R2
measure which penalizes models that have additional vari-
ables.
We built ve statistical models of failures for pre- and
post-release defects in Windows Vista and Windows 7 (sum-
marized in Table 2). The rst model contains only the clas-
sical source code metrics: size, complexity, and churn. We
refer to this as the base model. This model showed that
churn, size, and complexity all have a statistically signi-
cant eect on both pre and post-release failures. In addi-
tion, these metrics are able to explain 26% of the variance
in pre-release failures and 29% of the variance in post-release
failures in Vista and 24% and 28% in Windows 7.
In the second model, we added Total to the classic vari-
ables. This examines the eect of team size on defects and
does not include any measures of the proportion of contribu-
tions made by individual members. All models exhibitted a
statistically signicant improvement in variance explained.
Next, we added Minor to the set of predictor variables
in the base model. This was done to determine if the total
number of developers has a dierent eect on quality than
the number of minor contributors. The statistics showed
thatMinor is positively related to both pre and post-release
failures to a statistically signicant degree. The addition of
Minor increased the proportion of variance in pre-release
failures to 46% and post-release failures to 41%. The gains
shown by Minor were stronger than those shown by Total
for both types of failures to a statistically signicant degree,
in all cases except for post-release failures in Windows 7,
indicating that Minor has a larger eect on failures.
The addition of Major andOwnership showed smaller
gains, but were often still statistically signicant. We found
similar results regardless of the order that these variables
were added to the models. Ownership was found to have
a negative relationship with failures to a statistically signi-
cant degree and Major had a positive relationship, but was
much smaller than Minor .Minor still showed more of an
eect than Ownership andMajor even when it was added
last (not shown). The nal models account for up to 72% of
variance in failures. In all cases, ownership had a stronger
relationship with pre-release failures than post-release fail-
ures and the models in general were less explanatory. This
may indicate that there are already measures being taken
(e.g. increased testing, more stringent quality controls, etc.)between implementation completion and release to counter-
act the eects of poor ownership.
For all metrics that measure ownership levels there is a
clear trend of having a statistically signicant relationship
to failures in Windows. In all cases, Major andOwnership
show less of an eect than Minor orTotal , indicating that
the number of higher-expertise contributors has marginal
eect on quality, although the results are still statistically
signicant.
The results of our analysis of ownership in both releases
of Windows can be interpreted as follows:
1.The number of minor contributors has a strong posi-
tive relationship with both pre- and post-release failures
even when controlling for metrics such as size, churn,
and complexity.
2.Higher levels of ownership for the top contributor to
a component results in fewer failures when controlling
for the same metrics, but the eect is smaller than the
number of minor contributors.
3.Ownership has a stronger relationship with pre-release
failures than post-release failures.
4.Measures of ownership and standard code measures show
a much smaller relationship to post-release failures in
Windows 7.
7. EFFECTS OF MINOR CONTRIBUTORS
One of the key ndings in our analysis was that the num-
ber of minor contributors has a strong relationship with fail-
ures in both releases of Windows. Since Microsoft has the
capability to make changes to practices based on these nd-
ings, we were eager to gain a deeper understanding of this
phenomenon. To this end, we performed two more detailed
analyses in order to examine the minor contributors further.
First, we observed that almost all developers were ma-
jor contributors to some binaries and minor contributors to
others; very few developers never played a major contrib-
utor role. This led us to investigate the obvious question:
Given a particular developer, is there a relationship between
a component to which she is a major contributor, and one
to which she is a minor contributor?
Second, we adapted a fault prediction study carried out
by Pinzger et al. [29] and examined the eect of modifying
the study in ways related to ownership.
7.1 Dependency Analysis
The majority of developers that contributed to Windows
acted as major contributors to some binaries and minor con-
tributors to others. There were very few developers who are
only minor contributors. This fact is an indication of strong
code ownership, as it shows that nearly everyone has a main
responsibility for at least one binary.
Discussions with engineers at Microsoft indicated that of-
ten an engineer who was the owner of one binary would
make changes to another binary whose services he or she
used, often in the process of addressing reported bugs. In
our context this would show up as one engineer who was
a major contributor to some binary, A, and a minor con-
tributor to some binary, B, with a dependency relationship
between AandB. We call this a Major-Minor-Dependency
relationship, which is illustrated in Figure 3.
Major-Minor-Dependency Relationship
Dependency
Major Contributor
Minor Contributor
Foo.exe
Bar.dll2Add graph rewiring slide around. ont op..add some thought bubbles to the developer‚ÄúI need to use this...‚Äù‚ÄúI need to make a change to that... which is used by this...‚ÄùFigure 3: Illustration of the major-minor-dependency rela-
tionship commonly observed in Vista
Cataldo et al. found that making changes to a depending
component without coordinating with the other stakehold-
ers (in our case, the owner) of the component increases the
likelihood of faults [9]. We have no record of the communi-
cation between developers of Windows. However, the fact
that a minor contributor has, by denition, made few if any
prior contributions to a component suggests that their par-
ticipation in the component's implicit team is likely minimal,
increasing the risk of a introducing a bug.
But does this actually happen? Is a developer D, work-
ing on binary Foo:exe , statistically more likely to be a mi-
nor contributor to a binary Bar:dll , just because Foo:exe
depends on Bar:dll ? If so, how many of the minor con-
tributors to components can this phenomenon account for?
If the majority of minor contributors are a result of com-
ponent owners making changes do depending or dependent
components to accomplish their own tasks such as resolving
failures, then deliberate steps could be taken to avoid this
type of risky behavior.
To investigate this further, we employed a static analy-
sis tool, MaX [33], to detect dependency relationships be-
tween binaries. MaX uses debugging information les that
are generated during compilation to identify these relation-
ships, which include method calls, read and writes to the
registry, IPC, COM calls, and use of types. We were unable
to obtain the required debugging information les for Win-
dows 7 and thus limit our analysis here to Vista. Using this
tool, we constructed a dependency graph that includes all
of the binaries in Windows Vista.
The next step is to determine whether the major-minor-
dependency phenomenon occurs statistically more often than
would be expected by chance. But what exactly does \by
chance" mean? We model \chance" by generating a large,
plausible, random sample of contributions; we can then com-
pare the observed frequency of major-minor-dependency with
the frequency in the generated sample. Our plausible ran-
dom model is that each developer chooses their contribu-
tions at random, while preserving their rate of minor and
major contributions. In other words, a developer is just as
hardworking, but her choice of where to contribute is not
inuenced by dependencies in the code. Using this model,
we generate a large sample of simulated contribution graphs.D
Bob
CAmyminorminor(a) before
D
Bob
CAmyminorminor (b) after
Figure 4: An illustration of graph rewiring. Rewiring pre-
serves the number of minor and major edges per developer
and per binary, but randomizes the organization of the con-
tribution network.
This gives us a basis for comparison to evaluate observed,
real-world contribution behavior is inuenced by dependen-
cies between modules.
This \bootstrapping" approach comes from the statisti-
cal theory of random graphs [20, 24, 27]. A phenomenon is
judged statistically signicant if the actual, observed phe-
nomenon occurs rarely in the generated sample graphs. Fol-
lowing previous techniques [24,27], we use a graph-rewiring
method to bootstrap our random ensemble, based on the ob-
served frequency of commits from individuals. In each gen-
erated random sample, each developer makes the same num-
ber of major and minor contributions as in the observed real
sample, but the contributions are chosen at random from the
given set of components. We check to see how often a \ma-
jorly contributed component" for a developer has an actual
dependency on a \minorly contributed component" for the
same developer in these generated random samples. If the
frequency of major-minor-dependency relationships that oc-
cur in the ensemble of simulated samples diers signicantly
from that of the observed real sample, then we can conclude
that the phenomenon most likely represents some real, in-
tended behavior, and not simply a chance occurrence.
Graph rewiring is performed as follows in our context.
For the sake of convenience we refer to an edge connecting a
binary to one of its major contributors as a major edge and
an edge connecting a binary to one if its minor contributors
as aminor edge . Two edges that are either both major edges
or both minor edges are selected at random and endpoints
of both are switched as shown in Figure 4. Thus, after the
switch, the number of major and major contributions for
each developer node and each component node remains the
same.
After performing E2rewirings where Eis the number
of contribution edges in the graph, a suciently random
graph is obtained. We created 10,000 such random contri-
bution graphs and compared the frequency of major-minor-
dependency relationships to the frequency in the observed,
actual contribution graph. We found that in the observed
Vista contribution graph, 52% of the binaries had minor
contributors who were major contributors to other binaries
that the original had a dependency with. In contrast, this
relationship only existed for an average of 24% of the bina-
ries in the random networks with the same minor and major
contribution degree distributions. The maximum value forthe normally distributed frequency of this phenomenon out
of all 10,000 graphs was 32% of the time, indicating that
52% is denitely a statistically signicant dierence, and
the phenomenon that we are observing does not occur by
chance.
In Vista, one common reason that a developer is a minor
contributor to a binary is that he/she is a major contributor
to a depending binary. This allows for processes to be put
into place to recognize and either minimize or aid minor
contributions.
7.2 Effects on Network Metrics
In 2007, Pinzger et al. reported a method to nd fault
prone binaries in Windows Vista based on contribution net-
works [29]. A contribution network is composed of binaries
and the developers that contributed to those binaries. Thus,
a node representing a developer is connected to all binaries
the developer has contributed to and a node representing a
binary is connected to all developers that contributed to it.
Figure 5 shows an example of a contribution network with
boxes representing binaries and circles representing develop-
ers. Major contribution edges are solid and minor contribu-
tion edges are dashed.
The eld of social network analysis has developed a num-
ber of metrics that measure various attributes of nodes in a
network. For instance, the degree of a node is the number
of direct connections that it has and can be indicative of
how important the node is within the local network. Other
metrics measure how much information can ow through a
node, the average distance from a node to all other nodes,
how much \power" a node exerts over its neighbors, etc. An
in-depth discussion of these metrics can be found in Wasser-
man and Faust [34]. Pinzger et al. found that these mea-
sures had a strong relationship with post-release failures in
Windows Vista and in a prior study [6] we found that these
measures were able to predict failures in Eclipse accurately
as well.
Specically, Pinzger et al. built a predictor for fault prone
binaries using this method, it identied 90% of the fault
prone binaries in Vista (recall) and 85% of the binaries that
it classied as fault prone actually were (precision). This
was a dramatic increase over the predictive power of prior
methods that used source code metrics.
We adapted that study, and examined the eect of remov-
ing minor and major contributor edges. In Figure 5, such
minor edges are indicated by the dashed lines. The topolog-
ical eect of removing minor edges, as shown in Figure 5, is
that many pairs of binaries that had short connecting paths
through minor contributors are disconnected. Our ndings
focused on two key aspects of the results. First, we exam-
ined the correlation between social network measures and
post-release failures in the complete network and the net-
work with minor edges removed. Second, we measured the
change in the ability of a predictor to identify fault prone
binaries when removing major or minor contribution edges.
Table 3 shows the strength of relationship of six network
measures with pre- and post-release failures. These particu-
lar metrics are chosen because they had the highest correla-
tion with failures among those collected. Columns labelled
with Minor shows the correlations of SNA metrics calculated
on networks that contain only minor contribution edges and
those labelled with Major shows correlations from networks
of major contribution edges. For all metrics except for nodeWindows Vista Windows 7
Pre-release Post-release Pre-release Post-release
SNA Metric Minor Major Minor Major Minor Major Minor Major
Degree Centrality 0.861 0.909 0.668 0.599 0.931 0.797 0.269 0.319
Closeness Centrality 0.624 -0.098 0.602 0.107 0.737 0.167 0.130 0.013
Reachability 0.647 -0.091 0.618 0.119 0.747 0.176 0.135 0.018
Betweenness Centrality 0.703 0.146 0.601 0.132 0.748 0.285 0.289 0.154
Hierarchy 0.420 -0.273 0.176 -0.244 0.298 -0.302 0.136 -0.055
Eective Size 0.775 0.311 0.649 0.286 0.884 0.391 0.223 0.196
Table 3: Correlation of Social Network Analysis metrics on the contribution network with pre- and post-release failures.
Columns labeled \Minor" are correlations of failures with metrics computed on networks composed only of minor contribution
edges. Columns labeled "Major" are from networks made up of major contribution edges. For the majaority of metrics,
removing the minor edges drops the correlations considerably. For some metrics, the direction of correlation actually changes
for \Major".
B
D
C
Bob
Sara
Fu
Amy
Ram
A
Figure 5: An example contribution network. Boxes rep-
resent binaries and circles represent developers who con-
tributed to them. A dashed line between a binary and de-
veloper indicates a minor contributor relationship.
degree, the networks that consider major contributions have
dramatically lower correlations. In fact, for the case of Hi-
erarchy, the sign of the correlation is negative, indicating
that higher value of hierarchy in the major contribution net-
works were associated with fewer failures. These ndings
clearly indicate that the edges from minor contributors em-
body much of the important structure of the contributions
graph. So much so that their removal results in a decrease
in the discriminatory power of these metrics.
We also built a predictor from these measures for identi-
fying fault prone binaries in Windows Vista and Windows 7
using the same approach as Pinzger et al. [29]. They trained
a logistic regression model on a randomly chosen two thirds
of the binaries in the contribution network and then eval-
uated the model based on its results when classifying the
remaining third.
This process was repeated fty times, each with a dierent
random split of the data and the measures of performance,
precision, recall, and F-score | standard measures of infor-
mation retrieval [17] | were averaged across all runs.
Their original model based on the complete network iden-
tied 90% of the fault prone binaries and 85% of its fault
prone predictions were correct (their evaluation was based
on a prior Windows release). When the predictor was trainedusing the same methods on the network with minor con-
tributors removed, it identied only 58% of the fault prone
binaries and around 44% of its fault prone predictions were
correct. In Pinzger's formulation of the prediction approach,
random guessing would result in 50% for both measures.
Thus a predictor based on network measures for a network
containing major contributor only does marginally better
than one that chose binaries purely at random. Table 4
shows the performance when a predictor is trained on the
complete network as well as the networks with minor con-
tributions removed and major contributions removed.
We also show results for pre-release failures in Vista as
well as pre- and post-release failures for Windows 7. In all
cases, models built on minor contributions performed better
than those based on major contributions to a statistically
signicant degree. In the case of Vista post-release failures,
minor contribution prediciton models perform better than
models based on the entire network, and models based on
the entire network were never statistically better than those
based on minor contributions
We therefore conclude the minor contribution edges pro-
vide the \signal" used by defect predictors that are based on
the contribution network. Without them, the ability to pre-
dict failure prone components is greatly diminished, further
supporting our hypothesis that they are strongly related to
software quality.
8. DISCUSSION
Our ndings are valuable in a number of ways. We have
shown that for both versions of Windows, ownership does in-
deed have a relationship with code quality. This observation
is an actionable result, as this is an aspect of software devel-
opment that can be controlled and monitored to some degree
by management decisions on development process and poli-
cies. In all projects, the addition of Minor improved the
regression models for both pre- and post-release failures to
a statistically signicant degree. After controlling for known
software quality factors, binaries with more minor contribu-
tors had more pre- and post-release failures in both versions
of Windows. Thus hypothesis 1 is empirically supported in
both projects .
The analysis of Ownership is a little bit dierent. In this
case, we saw a small, but still statistically signicant eect
in pre- and post-release failures for Vista and pre-releaseWindows Vista Windows 7
Pre-release Post-release Pre-release Post-release
SNA Metric All Minor Major All Minor Major All Minor Major All Minor Major
Precision 90% 87% 83% 75% 84% 44% 89% 88% 80% 12% 11% 8%
Recall 91% 93% 91% 82% 88% 58% 92% 93% 87% 66% 75% 61%
F-Score 91% 89% 87% 78% 86% 50% 90% 90% 84% 21% 20% 14%
Table 4: Performance of network based failure predictors for pre- and post-release failures for Vista and Windows 7
failures for Windows 7. Part of this may be attributable to
a moderate relationship between the Minor andOwner-
ship, but although Ownership was signicant in all models
when removing Minor , the eect was smaller. Nonetheless,
in all cases, higher values for Ownership was associated
with lower numbers of failures. We therefore conclude that
hypothesis 2 is supported in the case of Windows Vista and
in pre-release data for Windows 7 .
The results of empirical software engineering studies do
not always generalize to settings where a dierent process
is used. The process that is used may dictate the eect of
other factors on software quality as well. Therefore, when
determining the applicability of a research result to a soft-
ware project, the context of the study must be taken in
account. Microsoft employs strong ownership practices and
our results are much more likely to hold in other indus-
trial settings where similar policies are in place. Examining
the eect of ownership in contexts where ownership is not
stressed as highly, such as in many open source software
(OSS) projects, is an area of continued study as we attempt
to understand the interaction between ownership, quality,
and varying software processes.
For contexts in which strong ownership ispracticed or
where empirical studies are consistent with our own nd-
ings, we make the following recommendations regarding the
development process based on our ndings:
1.Changes made by minor contributors should be reviewed
with more scrutiny. Changes made by minor con-
tributors should be exposed to greater scrutiny than
changes made by developers who are experienced with
the source for a particular binary. When possible, ma-
jor contributors should perform these code inspections.
If a major contributor cannot perform all inspections,
he or she should focus on inspecting changes by minor
contributors.
2.Potential minor contributors should communicate de-
sired changes to developers experienced with the respec-
tive binary. Often minor contributors to one binary
are major contributors to a depending binary. Rather
than making a desired change directly, these develop-
ers should contact a major contributor and commu-
nicate the desired change so that it can be made by
someone who has higher levels of expertise.
3.Components with low ownership should be given pri-
ority by QA resources. Metrics such as Minor and
Ownership should be used in conjunction with source
code based metrics to identify those binaries with a
high potential for having many post-release failures.
When faced with limited resources for quality-control
eorts, these binaries should have priority.It may not always be possible to follow these recommen-
dations (for instance, in cases where too many potential con-
tributors need changes to a component for one developer to
handle), however they should be followed as much as pos-
sible within reason. These recommendations are currently
being evaluated at Microsoft. We plan to investigate the re-
lationship of the ownership measures used in this paper with
software quality in other projects at Microsoft that dier in
size and process domain (e.g. projects utilizing agile). Fur-
ther, we plan to observe the results of projects that follow
these recommendations.
9. CONCLUSION
We have examined the relationship between ownership
and software quality in two large software development projects.
We found that high levels of ownership, specically opera-
tionalized as high values of Ownership andMajor , and
low values of Minor , are associated with less defects.
An investigation into the eects of minor and major con-
tributions on network based defect prediction found that
removing minor contribution edges severely impaired pre-
dictive power. We also found that when a component has
a minor contributor, the same developer is a major contrib-
utor to a dependent component approximately half of the
time, uncovering at least one signicant reason for high lev-
els of minor contributions. Changes to policies regarding
tasks that would lead to this behavior, such as defect reso-
lution and feature implementation, should be implemented
and evaluated.
For organizations where ownership has a strong relation-
ship with defects, we have presented recommendations which
are currently being evaluated at Microsoft. As our measures
of ownership are cheap and lightweight, we encourage other
researchers and practitioners to perform and report their
ndings of similar analyses so that we can build a body of
knowledge regarding ownership and quality in various do-
mains and contexts.
10. REFERENCES
[1] R. Banker, G. Davis, and S. Slaughter. Software
development practices, software complexity, and
software maintenance performance: A eld study.
Management Science , 44(4):433{450, 1998.
[2] V. Basili and G. Caldiera. Improve Soft-ware Quality
by Reusing Knowledge and Experience. Sloan
Management Review , 37:55{55, 1995.
[3] V. Basili, G. Caldiera, and H. Rombach. The Goal
Question Metric Approach. Encyclopedia of Software
Engineering , 1:528{532, 1994.
[4] K. Beck and C. Andres. Extreme ProgrammingExplained: Embrace Change . Addison-Wesley Reading,
MA, 2005.
[5] C. Bird, N. Nagappan, P. Devanbu, H. Gall, and
B. Murphy. Does distributed development aect
software quality? an empirical case study of windows
vista. In Proc. of the International Conference on
Software Engineering , 2009.
[6] C. Bird, N. Nagappan, P. Devanbu, H. Gall, and
B. Murphy. Putting it All Together: Using
Socio-Technical Networks to Predict Failures. In
Proceedings of the 17th International Symposium on
Software Reliability Engineering . IEEE Computer
Society, 2009.
[7] W. Boh, S. Slaughter, and J. Espinosa. Learning from
experience in software development: A multilevel
analysis. Management Science , 53(8):1315{1331, 2007.
[8] F. Brooks. The Mythical Man-Month: Essays on
Software Engineering, 20th Anniversary Edition .
Addison-Wesley, 1995.
[9] M. Cataldo, P. Wagstrom, J. Herbsleb, and K. Carley.
Identication of coordination requirements:
implications for the Design of collaboration and
awareness tools. Proceedings of the 2006 20th
anniversary conference on Computer supported
cooperative work , pages 353{362, 2006.
[10] B. Curtis, H. Krasner, and N. Iscoe. A eld study of
the software design process for large systems.
Communication of the ACM , 31(11):1268{1287, 1988.
[11] E. Darr, L. Argote, and D. Epple. The acquisition,
transfer, and depreciation of knowledge in service
organizations: Productivity in franchises. Management
Science , 41(11):1750{1762, 1995.
[12] S. Dowdy, S. Wearden, and D. Chilko. Statistics for
research . John Wiley & Sons, third edition, 2004.
[13] K. El Emam, S. Benlarbi, N. Goel, and S. N. Rai. The
confounding eect of class size on the validity of
object-oriented metrics. IEEE Transactions of
Software Engineering , 27(7):630{650, 2001.
[14] S. Elbaum and J. Munson. Code churn: A measure for
estimating the impact of code change. In Proceedings
of the International Conference on Software
Maintenance , 1998.
[15] T. Fritz, G. Murphy, and E. Hill. Does a programmer's
activity indicate knowledge of code? In Proc. of the
ACM SIGSOFT symposium on The foundations of
software engineering , page 350. ACM, 2007.
[16] R. Kraut and L. Streeter. Coordination in software
development. Communications of the ACM ,
38(3):69{81, 1995.
[17] F. W. Lancaster. Information Retrieval Systems:
Characteristics, Testing, and Evaluation . Wiley, 2nd
edition, 1979.
[18] D. W. McDonald and M. S. Ackerman. Expertise
recommender: a exible recommendation system and
architecture. In Proc. of the ACM conference on
Computer supported cooperative work , 2000.
[19] A. Meneely and L. A. Williams. Secure open source
collaboration: an empirical study of linus' law. In
Proceedings of the ACM Conference on Computer and
Communications Security , 2009.[20] R. Milo, N. Kashtan, S. Itzkovitz, M. E. J. Newman,
and U. Alon. On the uniform generation of random
graphs with prescribed degree sequences. Arxiv
preprint cond-mat/0312028 , 2003.
[21] A. Mockus. Succession: Measuring transfer of code
and developer productivity. In Proceedings of the 31st
International Conference on Software Engineering ,
2009.
[22] A. Mockus and J. D. Herbsleb. Expertise browser: a
quantitative approach to identifying expertise. In
Proc. of the 24th International Conference on
Software Engineering , 2002.
[23] A. Mockus and D. Weiss. Predicting risk of software
changes. Bell Labs Technical Journal , 5(2):169{180,
2000.
[24] M. Molloy and B. Reed. A critical point for random
graphs with a given degree sequence. Random Struct.
Algorithms , 6(2-3):161{179, 1995.
[25] N. Nagappan and T. Ball. Use of relative code churn
measures to predict system defect density. Proceedings
of the 27th International Conference on Software
Engineering , pages 284{292, May 2005.
[26] N. Nagappan, B. Murphy, and V. Basili. The inuence
of organizational structure on software quality: an
empirical case study. In Proc. of the 30th international
conference on Software engineering , 2008.
[27] M. E. J. Newman, S. H. Strogatz, and D. J. Watts.
Random graphs with arbitrary degree distributions
and their applications. Phys. Rev. E , 64(2):026118, Jul
2001.
[28] T. Ostrand, E. Weyuker, and R. Bell. Where the bugs
are. In Proceedings of the ACM SIGSOFT
international symposium on Software testing and
analysis , 2004.
[29] M. Pinzger, N. Nagappan, and B. Murphy. Can
developer-module networks predict failures? In
Proceedings of the 16th ACM SIGSOFT International
Symposium on Foundations of software engineering ,
2008.
[30] F. Rahman and P. Devanbu. Ownership, Experience
and Defects: a ne-grained study of Authorship. In
Proceedings ICSE 2011, To appear , 2011.
[31] P. Robillard. The role of knowledge in software
development. Communications of the ACM , 42(1):92,
1999.
[32] M. Sacks. On-the-Job Learning in the Software
Industry. Corporate Culture and the Acquisition of
Knowledge. Quorum Books, 88 Post Road West,
Westport, CT 06881., 1994.
[33] A. Srivastava, J. Thiagarajan, and C. Schertz.
Ecient Integration Testing using Dependency
Analysis. Technical Report MSR-TR-2005-94,
Microsoft Research, 2005.
[34] S. Wasserman and K. Faust. Social network analysis:
Methods and applications . Cambridge University
Press, 1994.
[35] E. J. Weyuker, T. J. Ostrand, and R. M. Bell. Do too
many cooks spoil the broth? using the number of
developers to enhance defect prediction models.
Empirical Softw. Engg. , 13(5):539{559, 2008.