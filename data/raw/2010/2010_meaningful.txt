Specifying and Detecting Meaningful Changes
in Programs
Yijun Yu⇤, Thein Than Tun⇤, and Bashar Nuseibeh⇤†
⇤The Open University, Milton Keynes, UK
†Lero, Irish Software Engineering Research Centre, Limerick, Ireland
Abstract —Software developers are often interested in partic-
ular changes in programs that are relevant to their current
tasks: not all changes to evolving software are equally important.
However, most existing differencing tools, such as diff , notify
developers of more changes than they wish to see. In this
paper, we propose a technique to specify and automatically
detect only those changes in programs deemed meaningful, or
relevant, to a particular development task. Using four elementary
annotations on the grammar of any programming language,
namely Ignore ,Order ,Prefer andScope , developers can specify,
with limited effort, the type of change they wish to detect.
Our algorithms use these annotations to transform the input
programs into a normalised form, and to remove clones across
different normalised programs in order to detect non-trivial and
relevant differences. We evaluate our tool on a benchmark of
programs to demonstrate its improved precision compared to
other differencing approaches.
I. I NTRODUCTION
Nothing endures but change.
Heraclitus (c.535 BC—475 BC)
This philosophy is true in many software development
projects. However, not all changes are equally relevant to
developers engaged in different development tasks. For exam-
ple, changing the indentation of statements in a Java program
does not necessarily alter its execution semantics. Nonethe-
less, most revision control systems, typically using text-based
differencing tools such as the diff utility in Unix [1], do not
discard changes to the indentation of such programs. Although
indentation is not meaningful to the execution semantics of
Java programs, it can be very important for the execution of
Python programs. Furthermore, for those who are concerned
with pretty-prints of Java programs, indentation is important.
Another example is API evolution [2]: users of object-oriented
programming libraries are encouraged to use the API instead
of its implementation, to adhere to the information hiding
principle [3]. As a result, some developers may wish to
identify only those changes made to the API, whilst others
may want to determine changes in the API implementation
only.
A change considered meaningful for one purpose may be
irrelevant for another. For a given purpose, how can one
specify the types of changes that are relevant to a speciﬁc
development task? How can such a speciﬁcation be used for
automatic detection?
Most change detection tools are effective either at reporting
all changes through general purpose differencing algorithmson programs represented as line-separated text and structured
models [1], [4], [5] or at ﬁnding out certain or all changes that
are speciﬁc to one particular language such as UML class dia-
grams [6], dependency graphs [7], or Verilog speciﬁcations [8].
Few techniques aim to provide a generic solution that can also
be customised to the speciﬁc language and the speciﬁc needs
of the developers.
In this paper, we propose a new way to specify meaningful
changes as the composition of elementary changes that are
deﬁned on a normalising transformation of source programs.
Two programs that are not different due to orderings, abstrac-
tions and preferences are normalised into the same program,
using three basic normalising transformations Order ,Ignore
andPrefer respectively. We show that such normalisations can
be speciﬁed as simple annotations on the original “production
rules” [9], while speciﬁc needs of further normalisation can
be accommodated by user-deﬁned functions. Each type of
elementary normalisation corresponds to an elementary type
of transformation to a term in the production rules of the
source language. Once such annotations are speciﬁed, a fully
automated meta-transformation can turn them into a composed
transformation that operates directly on the source programs,
separating meaningful changes from the irrelevant ones.
The meta-transformation is written as a generic modiﬁcation
to the meta-grammar of the TXLtransformation system [10],
that is, the grammar of all TXL grammars. Therefore, it is
applicable to any source language speciﬁable by TXL, which
currently supports several general-purpose programming lan-
guages such as C, Java, C#, and Python as well as several
modelling languages such as XML, XMI, GXL. An evaluation
of our Meaningful Change Tool (hereafter mct) on the CVS
repositories of two medium-sized software projects and one
small hardware project shows that (i) few annotations are
needed to specify typical meaningful changes, such as changes
made to the API, and (ii) the tool is scalable.
The remainder of the paper is organised as follows: Sec-
tion II introduces a running example illustrating the need
for detecting meaningful change. Section III explains our
approach to generate from meta-grammar speciﬁcations those
normalisation transformations needed to detect meaningful
changes. Section IV presents the results of a number of
experiments in using the tool, and compares the performance
with existing differencing tools. Section V compares existing
approaches with ours, highlighting some of our limitations.
Section VI concludes the paper.Fig. 1. The differences found by EMFCompare on the two EMF models
II. A M OTIVATING EXAMPLE
The essence of meaningful change can be illustrated using
a simple Java program in Listing 1. After some changes, the
execution semantics in Listing 2 remain the same. The Unix
diff utility [1] reports these changes, ignoring white spaces,
as one deletion and one modiﬁcation shown in Listing 3. A
more advanced algorithm ldiff [4] reports these changes,
again ignoring white spaces, as two insertions, one deletion
and two modiﬁcations shown in Listing 4.
Listing 1. cat -n HelloWorld.java
1public class HelloWorld
2{
3static private String hello ="Hello ";
4private static String world ="world ";
5static public void main (String args []) {
6 System .out.println (hello +","+world +"!");
7}
8}
Listing 2. cat -n HelloWorld-2.java
1public class HelloWorld
2{
3private static String world ="world ";
4
5static private String hello ="Hello ";
6public static void main (String args []) {
7 System .out.println (hello +","
8+ world +"!");
9}
10 }
Listing 3. diff -w HelloWorld.java HelloWorld-2.java
1 3d2
2<static private String hello ="Hello ";
3 5,6c4,8
4<static public void main (String args []) {
5< System .out.println (hello +","+world +"!") ;
6 ---
7>
8>static private String hello ="Hello ";
9>public static void main (String args []) {
10> System .out.println (hello +","
11> +world +"!") ;
Listing 4. ldiff.pl -w -o diff HelloWorld.java
HelloWorld-2.java
1 3,3d2
2<static private String hello ="Hello ";
3 4a4,5
4>
5>static private String hello ="Hello ";
6 5,5c6,6
7<static public void main (String args []) {
8 ---
9>public static void main (String args []) {10 6,6c7,7
11< System .out.println (hello +","+world +"!") ;
12 ---
13> System .out.println (hello +","
14 6a8,8
15> +world +"!") ;
The EMFCompare tool (http://eclipse.org/emf/compare)
is applied to the corresponding EMF models of the
two Java examples parsed by the JaMoPP Java parser
(http://www.jamopp.org), reporting three changes: one con-
cerns the renamed compilation units, one concerns the class
HelloWorld for “the order of the reference members”, and
the ﬁnal one concerns the method main for “the order of
reference annotationsAndModiﬁers values”.
If only the differences in the execution semantics are mean-
ingful to a programmer, none of the changes identiﬁed in this
example are relevant: just as adding a newline or some white
spaces would not change the syntax of the program, swapping
the keywords public andstatic in the declaration of the
main method makes no semantic difference.
III. T HEMCTSYSTEM
Our approach to ﬁnding meaningful change between two
versions of a program has two steps shown in Figure 2:
•Step 1. Speciﬁcation : A developer speciﬁes annotations
onto the grammar terms of programs, see dotted arrows
in Figure 2;
•Step 2. Detection : The mct tool generates a reﬁned
parsing grammar and two sets of transformations, nor-
malisations and clone-removals, from the speciﬁcation in
Step 1 and applies these transformations to a pair of two
source programs, reporting any meaningful change to the
developer. See solid arrows in Figure 2.
In a typical work ﬂow the speciﬁcation step is done
manually by the developer, whilst the detection step is done
automatically by the mctsystem to ﬁnd meaningful changes
of programs in revisions stored in the repository.
Bootstrap
(TXL)Developer
Grammar
Parser
(TXL)Programs:
v1, v2...(CVS)
Normalisations
(TXL)Clone Removals
(TXL)Meaningful Changes:
v1-v2, v2-v3, ...
ReﬁnedgrammarIgnore
Order
PreferScopeAnnotations: Ignore,
Order, Prefer, Scope
1
2.1 2.2 2.3
Fig. 2. Specifying and detecting meaningful changes using mctTABLE I
BASIC ANNOTATIONS TO THE TERMS IN A TXL GRAMMAR
Transformation Application scope TXL annotations
Example
Ignore Repeat/List ( ⇤), Optional ( |) [. . . ignored when F]
[repeat member declaration ignored when Private ]
Order Repeat/List ( ⇤) [. . . ordered by F]
[member declaration ordered by Ascending ]
Prefer Alternative ( |) [. . . preferred with C ]
[method body preferred with ’; ]
Scope Any non-terminal term [. . . scoped ]
[class body declaration scoped ]
Fig. 3. The outline view of the Eclipse IDE helps programmers to
select meaningful information interactively while reviewing a Java class.
Typically, they care about the ordering (e.g., the “a-z” button), and may
ignore certain details (e.g., the“hide ﬁelds”, “hide non-public members”,
“hide static members” buttons), and express a preference (e.g., “Java” or “
Debug” perspective). Other ﬁltering options can be expressed by user-deﬁned
dialogues.
A. Specifying Meaningful Changes
We ﬁrst deﬁne a few requirements for specifying meaningful
changes through the concept of normalisation transformations.
Deﬁnition 1: Equivalence classes by normalisation .A
program Pis said to be meaningfully equivalent to program
P0if and only if (P0=P)_(N(P0)= N(P))where N(P)
is the normalisation transformation of P. In other words, P0
introduces no meaningful changes to P. Typically N(P)is a
many-to-one transformation.
The exact meaning for ‘meaningful equivalent’ in the Def-
inition 1 is intentionally left open to the user who deﬁnes the
normalisation function appropriate to the tasks at hand.
This deﬁnition only provides the general criteria for deter-
mining whether a transformation is a suitable normalisation
once it is clear what is meaningfully equivalent to the users:
any trivial or irrelevant changes should be normalised to
the same program. After the normalisation transformation is
deﬁned, the detection of the meaningful changes becomes a
comparison of two normalised programs.
According to Deﬁnition 1, however, a normalisation trans-
formation can be a recursive function that does not terminate
when applied. For example, adding white spaces can be
regarded as a normalisation transformation but it would lead to
inﬁnite results when the transformation is applied recursively.
Therefore, a useful normalisation transformation needs to be
terminable so that no further transformation is necessary when
a ﬁxed point is reached.
Deﬁnition 2: Fixed points of terminable normalisation.
A ﬁxed point of normalisation Nis a program Psuchthat N(P)= N0(P)= P. A normalisation transforma-
tion terminates upon its ﬁxed point. The normalisation is
terminable if any input program Pcan converge to a ﬁxed
point: Ni+1(P)= Ni(P),where i 0is a ﬁnite number.
Every ﬁxed point in FP(N)is the representative element for
a class of meaningfully equivalent programs according to the
normalisation N.
By this deﬁnition, the identity transformation is trivially ter-
minable. There are non-trivial terminable normalisations. For
example, ordering the modiﬁers (i.e., “private”, “static”) of
all class members is a terminable transformation, because the
number of inverse order of the modiﬁers is ﬁnite, so is the
number of class members.
The following property guarantees that a composition of
any two terminable normalisation transformations is still ter-
minable, for a subset of ﬁxed points.
Property 1: Composability of terminable normalisations
If two normalisations N1and N2are terminable accord-
ing to Deﬁnitions 1 and 2, then the functional composition
(N1 N2)(P)= N2(N1(P)) = Pis also a terminable
normalisation, and FP(N1 N2)✓FP(N1)\FP(N2).
For example, ignoring the method bodies in all classes is
a terminable normalisation composable with reordering the
method modiﬁers. A program with method bodies ignored
may not have the modiﬁers sorted, and vice versa. Only
fewer programs with both the method bodies ignored and
the modiﬁers ordered are the ﬁxed points that terminate the
composed normalisation transformation. In general, the more
normalisation transformations are composed, the fewer ﬁxed
points can be distinguished.
In order to support most programming languages, at the
level of the meta-grammar we aim to generate normalisation
transformations by composing three elementary terminable
normalisations derived from the production rules of grammars:
Ignore ,Order and Prefer . For every term of a production
rule, one can check whether any one of these basic types
of terminable normalisations is applicable to provide what
programmers like to compare. For example, traditionally, Java
programmers get help from an IDE such as Eclipse to obtain
meaningful information in an “outline” view, as shown in
Figure 3. The abstraction presented in the outline view can
be further customised by clicking at the right buttons by the
programmer. Our elementary normalisation operations already
cover all the most commonly used meaningful selection but-
tons of the Eclipse IDE.
Deﬁnition 3: Elementary normalisations: Ignore ,Order
andPrefer .Let a production rule be N (...T i[?|⇤]...)|...
where Nis a non-terminal, and Tiis the i-th term (which
could be either terminal or non-terminal), and optionally the
rule could contain more than one alternative sequence pattern.
Every optional (denoted by ‘?’) term can be ignored if, with
or without the value, it makes no difference to the developer;
elements of a repeated (denoted by ‘*’) term can be ordered
if the ordering of the values is not important to the developer;
and the whole element Nmatches a mandatory alternative
can be preferred to another alternative (denoted by ‘ |’ ), if thedifference between these two alternatives are not signiﬁcant to
the developer.
Table I gives an example of each of these elementary trans-
formations: by ignoring the members when they are private;
by sorting the member declarations in ascending order; and
by preferring the semicolon over the detailed method bodies.
These elementary normalisations can be used to preserve
the conformance to the syntax of the source programming
language, if one does not apply Ignore to mandatory terms.
Since different programming languages have different seman-
tics, users may wish to preserve the semantics by avoiding
certain normalisations. For example, one would not reorder
the statements in normalisation to avoid breaking the execu-
tion semantics of Java. Whether these syntax or semantics-
preserving transformations are desirable really depends on the
developer’s task.
Property 2: Syntax conformance. The normalised pro-
grams generated by the three elementary transformations in
Table I are valid programs in the source programming lan-
guage.
Of course, syntax conformance of the normalised programs
is not an issue when the purpose of checking meaningful
changes is not to obtain a compilable program. One may
choose to deﬁne the target grammar to be incompatible with
the source language. The elementary normalisations can also
be further customised. The unconditional ignored rule for
an optional term ‘?’ can be associated with a conditional
check: in the API extraction example, one would remove
a declaration if and only if it does not have ‘public’ or
‘protected’ modiﬁers. Similarly, the ordered rule for repeating
terms ‘*’ can be customised to ascending or descending orders,
and the ordering criteria can be associated with certain foreign
keys.
B. Detecting Meaningful Changes
After each program revision is normalised, the next task is to
detect the non-trivial changes. A simple method is to apply an
existing diff algorithm on the normalised results. However,
this may not detect the exact and subtle differences smaller
than one line of code. The method we adopted is to apply
clone detection [11] in order to take advantage of knowing the
meaningful structures independent of the line boundaries. As
long as the normalised entities are the same, a clone detector
could locate them. On the other hand, if the two entities are
similar but not exactly the same, a meaningful context of
the difference may need to be shown. After removing the
clones across a pair of programs, their differences become
evident. Note that we do not check intra-program clones as our
purpose is not to detect clones, but only to reuse existing clone
detection techniques for the sake of differencing. In principle
any parametrised AST-based clone detector could be used for
this purpose. To illustrate this in this paper, we use the simplest
exact clone detection.
Not all language constructs at all levels of granularity should
be considered as clones either. For example, index variables
of a for-loop are not apparently so meaningful to detect as aclone because it makes little sense to scope the comparison
at this level of abstraction. To be able to specify the scope
of language construct that needs to be considered as clones
to remove, another kind of annotation is introduced to non-
terminals.
Property 3: Scoping the clone detection. Any optional or
repeat term in the production rule can be marked as a possible
scope for clone detection such that removing the inter-program
clones at this level does not change the conformance of the
source programming language. Instances of any mandatory
term in the grammar can be marked as possible clones if
required, whilst the target programming language may violate
the syntax rules of the source programming language.
The last row of Table I summarises the scoping annotation
for clone removals.
C. Running Example: Specifying Normalisations for the Java
API
To illustrate the features of our method, we use the ex-
ample of the Java 5 grammar provided by the TXL web-
site (http://txl.ca), containing 970 lines of code. TXL is a
functional programming language in which a transformation
is deﬁned by either a non-recursive function or a recursive
rule [10]. Instead of using pseudo code to illustrate the
algorithms, in this paper, some of the exact declarative rules
are used in order that the work can be easily reproduced.
Listing 5. cat -n java.annotated.grm
1include "java .grm"
2annotate package_declaration [ opt package_header scoped ]
3annotate package_declaration [ repeat import_declaration
ignored ]
4annotate package_declaration [ repeat type_declaration
scoped ordered ]
5annotate class_or_interface_body [ repeat
class_body_declaration scoped ordered ignored when
Private]
6annotate method_declaration [ repeat modifier ordered by
Descending]
7annotate method_declaration [method_body preferred with
’;]
8%...
9function Private A [class_body_declaration]
10 match [class_or_interface_body] B [
class_or_interface_body]
11 construct M [modifier *] _ [ˆ A]
12 construct PublicModifiers [modifier *] ’public ’
protected
13 where not M [contains each PublicModifiers]
14end function
15rule Descending B [modifier]
16match [modifier] A [modifier]
17construct SA [stringlit] _ [quote A]
18construct SB [stringlit] _ [quote B]
19where SA [< SB]
20end rule
Line 1 includes the original Java 5 grammar. The
annotate rules in Table I are used or composed in some of
the term extensions. Here we explain the rationale behind these
extensions. The annotations “ scoped ” are appended to the
terms such as “package header” (Line 2), “type declaration”
(Line 4), “class body declaration” (Line 5). These instruct a
clone detector to compare these three types of entities for
possible clones. Although the technique is similar to general-
purpose clone detection, the purpose of the cross-programclone-removal is exactly the opposite: those non-clones are
the differences to be detected.
However, the ordering of elements or appearance of ig-
norable details can get in the way of meaningful change
detections. Therefore several normalisation transformations
are required to be applied before the change detection step.
Since one does not care about whether a modiﬁer is before
another one or not (e.g., ’private static’ is the same as ’static
private’), the ordering of the elements in the array of repeat
modifier is unimportant to the Java semantics. However, the
default behaviour of a TXL parser preserves the ordering of
the modiﬁers in the parsing tree as they occur in the source
program. To specify the “Order” normalisation, one only needs
to insert ordered at the end of the [repeat modifier]
term.
Furthermore, if one would like to normalise the elements
in descending order, a user-deﬁned rule Descending (Lines
15-20) is added in Listing 5. This is just to illustrate how easy
it is to customise the comparison function, in case one would
like to deﬁne a different key or ordering for the structure to
be normalised. For the sake of identifying meaningful changes
in this particular case, ordering these members in ascending
order is the same as ordering them in descending order.
The Ignore annotations ( ignored ), on the other
hand, will replace the optional or repeated terms with
[empty] . The terms import_declaration at
Line 3 and class_body_declaration at Line 5,
are examples. In particular, the Ignore annotation to
class_body_declaration is conditional, it uses a
user-deﬁned function from Lines 9-14 to check when the
term has not used the public orprotected modiﬁers. As
a result, it will achieve the effect of extracting API methods
from all members.
Without specifying such user-deﬁned functions, the default
behaviour of Ignore extension would simply ignore the term,
just as what the annotated term [import_declaration
ignored] does. Since such terms are unconditionally ig-
nored, it is unnecessary to compose them with the Scope
annotation as other siblings do. As a result, this will ignore
the import statements in the API regardless, so any difference
in such statements will not be considered as meaningful.
Finally, the Prefer annotations ( preferred ) are appended
to the terms that have more than one alternative expansion.
The user is free to choose a sequence of literals to make a
constant instance of the terms in any one of its alternative
production rules. For example, when the method_body at
Line 7 is annotated by preferred ’; , this will lead to a
transformation to turn any block into a semicolon.
D. Brief Implementation of the mct
The Meaningful Change Detection tool, mct, is imple-
mented completely as a TXL program. The ﬁrst part of the
implementation is an extension to the TXL’s meta-grammar
(given in the ﬁle txl.grm ). Listing 6 shows the extension to
the existing typeSpec rule and the addition of four anno-
tation rules orderedBy ,ignoredWhen ,preferred andscoped , corresponding respectively to the three elementary
normalisations and the scoping rules.
Listing 6. cat -n norm.grm
1include "txl.grm"
2%The extension ofthe Txl grammar
3keys
4 ... ’ scoped ’ordered ’by’ignored ’when ’preferred ’
with ’annotate
5end keys
6define typeSpec
7 ... [ opt scoped ][opt orderedBy] [ opt ignoredWhen] [ opt
preferredWith]
8end define
9define scoped ’scoped end define
10define orderedBy ’ ordered [opt byFunction] end define
11define byFunction ’ by[id] end define
12define ignoredWhen ’ ignored [opt whenFunction] end define
13define whenFunction ’ when [id] end define
14define preferred ’preferred ’with [literal+] end define
15redefine statement ... | [MCT_annotate] end define
16define MCT_annotate ’ annotate [id] ’[ [typeSpec] ’] [NL]
end define
The second part of the implementation is a speciﬁcation of
the normalisation transformations.
For brevity, we only discuss the extension for the Order
transformation, shown in Listing 7. The transformation gener-
ates the rules for eliminating ordered annotations so that it
is recognisable by TXL at runtime, and for producing the rules
for ordering the parsed terms. Lines 44-64 specify how to gen-
erate the transformation rules denoted by the variable Rules
on the ﬂy by checking every defineStatement in the TXL
grammar such as those in Listings 5. For each occurrence of
[repeat X ordered by F] , the transformation in Lines
9-31 is invoked to generate a rule such as those instantiated in
Lines 22-27. These rules have unique names constructed from
the names of the defineStatement and the term X. By
the end of the main transformation, the rule in Lines 2-8 are
applied to eliminate the Order annotations from the extended
grammar.
Listing 7. cat -n norm.Txl
1include "norm .grm"
2rule typeSpec_eliminateOrderedBy
3replace *[typeSpec] T [typeSpec]
4deconstruct TM[ opt typeModifier] I [typeid] R [ opt
typeRepeater] O [orderedBy]
5deconstruct O’ordered B[opt byField]
6construct T1 [typeSpec] M I R
7byT1
8end rule
9function typeSpec_repeat_byField DS [redefineStatement] T
[typeSpec]
10import Rules [statement *]
11import RuleIDs [id *]
12replace [statement *] _ [statement *]
13deconstruct DS ’ redefine TID [typeid] TYPE [
literalOrType *] REST [barLiteralsAndTypes *]’end ’
define
14deconstruct T’repeat I [typeid] R [ opt typeRepeater] O
[opt orderedBy]
15deconstruct O’ordered B[opt byField]
16deconstruct B’byF [id]
17construct StrID [id] _ [quote TID]
18deconstruct I TypeID [id]
19construct ID [id] ’normalise_list
20construct ruleID [id] ID [_ StrID] [_ TypeID]
21construct S [statement *]
22 ’ rule ruleID
23 ’ replace ’[ ’ repeat I ’]
24 ’N1 ’[ I ’] ’N2 ’[ I ’] ’Rest ’[ ’ repeat I ’]
25 ’ where ’N1 ’[ F ’N2 ’]
26 ’ by’N2 ’N1 ’Rest27 ’ end ’rule
28export Rules Rules [. S]
29export RuleIDs RuleIDs [. ruleID]
30byS
31end function
32function DS_replace DS [redefineStatement]
33replace [statement *] S0 [statement *]
34construct T [typeSpec *] _ [ˆ DS]
35construct S2 [statement *] _ [typeSpec_repeat_byField DS
each T]
36construct S [statement *] S0 [. S1] [. S2] [. S3]
37byS
38end function
39function id_to_type ID [id]
40replace [literalOrExpression *] L [literalOrExpression *]
41construct T [literalOrExpression *] ’[ ID ’]
42byL [. T]
43end function
44function main
45replace [program] P [program]
46export Rules [statement *]_
47export RuleIDs [id *]_
48construct DS [defineStatement *] _ [ˆ P]
49construct S [statement *] _ [DS_replace each DS]
50import Rules
51import RuleIDs
52deconstruct P S0 [statement *]
53construct ID [id *] RuleIDs [print]
54construct PL [literalOrExpression *] ’Prg
55construct PL2 [literalOrExpression *] _ [id_to_type each
RuleIDs]
56construct L [literalOrExpression *] _ [. PL] [. PL2]
57construct REPLACE [replacement] L
58construct MAIN [statement]
59 ’ function ’main ’ replace ’[ ’program ’]
60 ’Prg ’[ ’program ’] ’ byREPLACE
61 ’ end ’function
62construct P1 [program] S0 [. Rules] [. MAIN ]
63byP1 [typeSpec_eliminateOrderedBy]
64end function
E. Generated Normalisation Transformation
The above generic implementation is done on the meta-
grammar of TXL. When it is applied to a concrete TXL
grammar, such as the one speciﬁed in Listing 5, a concrete
normalisation transformation is produced in the original syntax
of TXL, as shown in Listing 8. Lines 2-9 are generated from
the[repeat modifier ordered by Descending]
annotations from the Line 6 of Listing 5, using the user-deﬁned
comparison function Descending , which was listed in Lines
15-20 in Listing 5.
Listing 8. cat -n java.Txl
1include "java .grm"
2rule normalise_list_method_declaration_modifier
3 replace [repeat modifier]
4 N1 [modifier] N2 [modifier] Rest [ repeat
modifier]
5 where
6 N1 [Descending N2]
7 by
8 N2 N1 Rest
9end rule
10function main
11 replace [program]
12 Prg [ program ]
13 by
14 Prg [ normalise_list_method_declaration_modifier
]
15end function
F . The Normalised Programs and Relevant Changes
We have implemented the processor of all the four types
of elementary annotations using TXL, which generates a
few transformation rules per annotated term. Applying thecomposed normalisation transformation to the two Java pro-
grams in Listings 1 and 2 produces the normalised results
that are identical, as shown in Listing 9. Both hello and
world members are removed because they are not public nor
protected members of the class. The main method has the
modiﬁers ordered in ascending order as public static ,
whilst its method body is replaced by the preferred sim-
pliﬁcation semicolon alternative. To display the differences
of two compared programs, a generated transformation is
applied to remove all inter-program cloned instances of the
annotated terms. This transformation only applies to those
“scoped” annotated terms, because one usually would not
remove duplication of low-level term such as identiﬁers.
Listing 9. mct HelloWorld.java HelloWorld-2.java
1public class HelloWorld {
2
3 public static void main (String args []);
4}
5public class HelloWorld {
6
7 public static void main (String args []);
8}
As a result, there is no longer anything left, leaving the output
empty as shown in Listing 10.
Listing 10. mct -diff HelloWorld.java HelloWorld-2.java
IV . E XPERIMENTAL RESULTS
Themcttool has been applied to three benchmark evolving
programs in the public domain: (i) GMF is a model-driven
code generator for Eclipse Graph Editors, (ii) JHotDraw is a
GUI framework for technical and structured Graphics, and (iii)
OpenCores Uart16650 is a speciﬁcation of FIFO queue for
hardware, which was used for the study of Verilog Diff [8].
A. Specifying Meaningful Changes on Java and Verilog
The meaningful changes we want to detect are differences
in the APIs of these programs in different programming
languages. Table II lists the sizes of the meta-grammar
(txl.grm ), Java 5 grammar ( java5.Txl ) and the Verilog
grammars ( v.Txl ). The ‘+’ sign before the numbers is used
for counting those incremental grammars that include the orig-
inal one. The mcttool is implemented as mct.Txl , which
consists of 28 additional rules that transform the 7 extended
terms. The Java API normalisation tool is implemented by
redeﬁning terms using 22 (3 Scope, 14 Order, 3 Ignore and 2
Prefer) annotations, and 1 user-deﬁned rule in additional to the
original grammar. As a result, 47 new transformation rules are
generated, which also deﬁne 6 new reﬁned terms. The Verilog
annotations include 1 Scope, 1 Order and 1 Ignore, which
generates 7 additional transformation rules.
On a server running RedHat Enterprise Linux 5.0, with a
3.16 GHz Intel Xeon X5464 CPU, 6MB cache, 24GB memory,
the automated generation of these normalisation rules takes no
more than 0.07 seconds. The programming language grammars
in TXL (L) and the generated normalisation transformation
rules in TXL (M) were then used in the remaining experiments.Fig. 4. Contrast the effectiveness of change detection at the ﬁle level as the
percentage of reduced changed ﬁles
TABLE II
SIZE OF THE FULLY EXTENDED GRAMMARS AND TIME TO GENERATE THE
NORMALISATION RULES
Grammar Description LOC Terms Rules
txl.grm meta-grammar 408 58 1
mct.Txl Implementation 1081(+673) 65(+7) 29(+28)
java5.Txl (L) Java 5 grammar 976 168 1
java.norm annotation 1108(+132) 189(+21) 2(+1)
java.Txl (M) result 1837(+729) 194(+5) 45(+43)
v.Txl (L) Verilog grammar 233 37 1
verilog2.norm annotation 254(+21) 41(+4) 1(+0)
verilog2.Txl (M) result 469(+215) 46(+5) 8(+7)
TABLE III
CHANGE OF SOURCE PROGRAMS WITH COMMENTS /WHITE SPACES (J),
W/OW H I T ES P A C E S /COMMENTS (L) OR AFTER NORMALISATIONS (M)
Program File LOC(J) LOC(L) LOC(M)
 =diff Commit  LOC(J)  LOC(L)  LOC(M)
uart16650 12 51,601 28,805 417
(mct) 8 19 19 19
(diff) 128 1,864 879 29
(ldiff) 71 1, 552 694 29
jhotdraw 1,012 316,248 212,145 41,614
(mct) 724 2,506 2,506 2,506
(diff) 1,582 29,088 21,479 3,472
(ldiff) 1,264 28,882 28,699 3,284
gmf 5,263 8,944,841 4,288,931 453,181
(mct) 4,810 31,797 31,797 31,797
(diff) 17,522 437,860 274,835 44,516
(ldiff) 14,046 440,160 278,190 37,838
B. Detecting Meaningful Changes on Three Projects
We accessed the history of gmfandjhotdraw by analysing
all commits from their public CVS repositories; whilst we
were using the same set of selected revisions of Uart16650
provided by Duley et al [8]. Let ‘J’ stand for the original
code, ‘L’ stand for the comment-less code and ‘M’ stand for
the normalised code. The Java parsers obtained from the TXL
website are already designed to remove all the comments and
white spaces in the Java programs. Thus it is perhaps better
to compare the normalised results (M) with the unparsed ones
(L) rather than with the original code (J).Table III lists the size metrics of these programs. The metric
‘LOC’ is the number of accumulated lines of code of all the
revisions; ‘  LOC’ is the number of accumulated lines of
changes detected by the diff /ldiff utilities.
All the size metrics show that UArt16650 <<JHotDraw
<< GMF, roughly by a magnitude of 10. The GMF CVS
repository of accumulated lines of code has close to 9 million
lines of code. Taking out white spaces/comments does help
reduce the size by almost half, indicating that the three open-
source programs were all well-commented. The performance
TABLE IV
COMPARING FILE -LEVEL CHANGES
Program Pairs diff txl+diff mct
Uart16650 71 62(-12.7%) 53(-25.4%) 8(-88.7%)
jHotDraw 1,302 1,264( -2.9%) 1,107(-15.0%) 724(-44.4%)
GMF 14,046 11,196(-20.3%) 9,767(-30.5%) 4,810(-65.8%)
ofldiff in terms of detecting ﬁle-level changes is the same
as that of diff . However, ldiff generally reduces the
amount of information presented to developers when changes
did occur.
The absolute size of the normalised code LOC(M) is almost
10 times smaller than LOC(L), and the change  LOC(M)
is also much smaller than the counterparts. As a result, in
all the three examples, fewer ﬁle-level changes are found by
diff /ldiff . Table IV highlights the ratio of reduction of
the ﬁle-level changes after diff ,txl+diff andmctare
applied, where mcthas the most effective result. The ratios
are compared in Figure 4.
The time, in seconds, it took for the experiment is shown in
Table V. “T(X)” is the time it took to generate the programs,
and to measure the differences using diff orldiff between
pairs of consequent revisions. For the original (X=J) program,
no computation is needed for the diff /ldiff measurements
in generating the program. The generation of the pretty printed
(X=L) is done by the default TXL parser, and generation of
the normalised (X=M) programs is done by the mctgenerated
transformations.
Amongst the three evolving programs, diff is the
fastest, on average only as little as (0.2 + 18.5 + 105.7)
/(128+1582+17522)=124.4/19232 <0.007 seconds per re-
vision pair; whilst using txl then ldiff is the slowest,
on average 44255.4/19232=2.30 seconds per revision. On
average, the normalisations and clone removals in one step
mcttakes about 24077.5/19232=1.25 seconds per revision.
Finally, Table VI lists the time performance relative to the
input size, in seconds per million lines of code. The columns
are ordered by the last row, from the slowest on the left to the
fastest on the right. We only compare the scalability of ﬁve
conﬁgurations for detecting changes, using a combination of
4 tools, diff ,ldiff ,txlandmct. Figure 5 plots the data
in this table.
C. Threats to Validity
Although some of our experiments were large scale, we
should not over-generalise our ﬁndings. The GMF projectTABLE V
ABSOLUTE TIME PERFORMANCE IN SECONDS
Program Tool txl mct
Commits T(J) T(L) T(M)
uart16650 codegen 0.0 1.7 2.8
128 diff 0.2 0.2
ldiff 18.5 18.0
jhotdraw codegen 0.0 16.5 120.4
1,582 diff 18.7 24.1
ldiff 633.5 866.7
gmf codegen 0.0 845.2 23,954.3
17,522 diff 105.5 193.5
ldiff 42,740.0 18,525.0
TABLE VI
SCALABILITY :TIME RELATIVE TO THE INPUT SIZE (SEC/MLOC)
txl mct txl
LOC(J) +ldiff ldiff +diff diff
51,601 391.5 358.5 54.3 36.8 3.9
316,248 2055.3 2003.2 380.7 128.4 59.1
8,944,841 4872.7 4778.2 2678.0 116.1 11.8
is model-driven, and an unknown portion of CVS commits
attributes to the code generations, thus it is less relevant
to the API-evolution compared to those manual changes in
the JHotDraw project. In these experiments, however, we did
not separate generated code from the CVS repository. The
Verilog normalisation applies fewer annotated transformations
than that of the Java API, which could explain why the
average time/MLOC performance of Verilog is better than
JHotdraw. The performance of ldiff in terms of ﬁle level
change detection is not better than that of diff , however,
the quality of diff-chunks in ldiff may be ﬁner than that
ofdiff . Therefore we included experiments of both to
indicate how mct compares with the scalable ldiff tool.
To avoid any skewing of the running environment, we took
the timing measurement 5 times and the minimal elapsed
time. However, a different hardware conﬁguration may lead to
slightly different measurements. Finally, we did not compare
the interactive supervised diff results as some of the related
0.0#1000.0#2000.0#3000.0#4000.0#5000.0#6000.0#
Uart16650#jHotDraw#GMF#txl+ldiﬀ(L)#ldiﬀ(J)#mct#txl+diﬀ(L)#diﬀ(J)#Fig. 5. Contrast the scalability of the experimented command line tools
work does because such supervisions require a large amount
of time on the code base, and truthful interpretation from thedevelopers that is intrusive to the development projects. As
a trade-off, our command line tool mctcould substitute the
underlying diff algorithms for the interactive use cases.
V. R ELATED WORK
General problem. Brunet et at [12] deﬁne the challenges of
model managements in terms of merge, match, diff, split and
slice operations and the properties that should be preserved by
those operations. Their operations and properties are indepen-
dent of models and modelling languages. Our normalisation
steps are similar to slice operations because they are a series
of transformations performed from model to model based on
slicing criteria. And the clone removal step is similar to the
diffoperation that transforms two models to a set of changes.
Model matching and merging [13] are also related to our
work in the sense that they merge the detected changes. Our
emphasis is on ensuring the transformed programs (or models)
remain valid according to the original language syntax so
that it is easier to compare the differences with the original
programs.
Structural diff. Xing and Stroulia [6] propose an approach
to recover UML design models (such as class diagrams)
from Java code, then compare their structural changes. The
approach is speciﬁc to UML, which uses similarity metrics for
names and structures to determine the types of changes made.
Schmidt and Gloetzner [14] describe an approach that inte-
grates the SiDiff tool to detect semantic changes on diagram
structures. It then visualises the changes on UML diagrams
and SimuLink models. These diagrams, in principle, can be
speciﬁed in domain speciﬁc languages such as UMLasSketch1.
Thus it is possible to apply our tool to detect changes on the
textual models. The main difference with our work is that our
approach allows the tool user to specify selective changes to
be detected.
Apiwattanapong et al [15] present a graph-based algorithm
for differencing API of Java programs. Since their approach
and the tool JDiff is geared towards Java, there is explicit
support of Java-speciﬁc features, such as the exception hierar-
chies. Their tool is therefore not as language-independent as
ours. In addition, we can also specify the meaningful changes
to extract UML models and to isolate user-speciﬁed “generated
NOT” elements from model-driven software development with
only a few additional semantic rules in TXL. These are beyond
the scope of JDiff .
Beyer et al [16] present an efﬁcient relational calculator
crocopat that can perform diff calculation on two sets
of tuples very efﬁciently, and thus has been widely used
invisualisation reverse engineered facts such as call graphs
or inheritance/aggregation relationships. However, crocopat
treats all differences in sets rather than ordered lists. Therefore
it is not suitable for checking the differences among ordered
structures such as statements or parameter lists.
Fluri et al [17] describe an approach to ﬁnd differences
on abstract syntax trees. The criterion for measuring the
1http://martinfowler. com/bliki/UmlAsSketch.htmlsize of differences is the length of minimal number of edit-
ing operations such as insert, delete, move, update , as well
as refactoring-based operations such as condition expression
change, method renaming, parameter delete, ordering change,
type change, statement insertion, parent changes, etc. Most
of their basic editing operations can be expressed using a
composition of the four basic annotations rules used in this
paper. On the other hand, the refactoring changes on semantic
behaviour preserving require more advanced transformations
that depends much on the speciﬁc Java semantics. Our design
considers that speciﬁcity with the generalisable principle so
that a substantially different programming language such as
Verilog can also be supported. In principle, refactoring type of
transformations can be supported by specifying those changes
as user-deﬁned equivalence functions.
Semantic diff. Several differencing tools work at the seman-
tic level which may be complementary to ours. Jackson and
Ladd [7] use dependency between input and output variables
of a procedure as a way to detect certain changes. The
dependency is represented as a graph and any difference in
two graphs is taken as a change to the semantics of the
procedure. There are, of course, changes that affect other kinds
of semantics but not the dependency graph, such as changes
in constants. Working at the level of program grammar, our
tool presents all the choices for the user to decide whether a
change in constant should be ignored or not.
Kawaguchi et al [18] present a static semantic diff tool
called SymDiff , which uses the notion of partial/conditional
equivalence where two versions of a program are equivalent
for a subset of inputs. The tool can infer certain conditions
of equivalence, and therefore behavioural differences can be
lazily computed. Our tool does not work at the level of
program semantics.
Duley et al [8] present VDiff for differencing non-
sequential, “position independent” Verilog programs. Their
algorithm extracts the abstract syntax trees of the programs,
and matches the sub-trees in the AST’s whilst traversing
them top-down. Furthermore, Boolean expressions are checked
using a SAT solver and the results of differencing are presented
as Verilog-speciﬁc change types. In this work, we used their
datasets to demonstrate that our work can be applied to this
language too. Although we do not classify the changes into 25
types as they did, we can also classify the changes according
to annotated terms.
Applications. Wenzel et al [19] present a view that the
evolution history of models can be traced into modelling ele-
ments and visualise the change metrics. When large amounts
of data are being processed, again it is important to be able to
extract the relevant information to compare with each other.
Our work has shown that it is not only possible to trace the
history of evolution, but also possible to specify such views
based on the relevance to programming tasks. On the other
hand, adding some visualisation capability to our command-
line tools should be possible, especially since we have obtained
the exact structures in the comparisons.
Dagenais and Robillard [20] present a promising way to
use change detection for recommendation systems, especiallyfor the framework evolution. Recently, Kawrykow and Ro-
billard [21] demonstrate the DiffCat tool to classify both
CVS and SVN change sets of Java programs for non-essential
changes such that those induced by cosmetic refactoring
operations can be ignored. DiffCat aims to classify the
changes as input data that might be non-essential for auto-
mated techniques, instead of deﬁning for Java programmers
which changes are essential or meaningful. On the other hand,
our approach can be used to deﬁne a suitable normalisation
for each of these classiﬁed change types. For example, a
local variable renaming could be normalised by renaming any
local variable to the surrounding context of its declaration.
Therefore it is possible to combine the two approaches further
for classifying the different types of meaningful changes.
Kim and Notkin [22] present the LSdiff tool to automat-
ically identify structural changes. Similar to us, there are no
predeﬁned change types in LSdiff , though the abstraction
ofLSdiff is at the level of code element and structural
dependencies. While both LSdiff andmctshare a common
goal of helping programmers to understand changes at a high
level, instead of focusing on identifying and summarizing
systematic structural differences, right now our tool focuses
on programmer-provided annotations on the production rules
to ﬁlter out meaningless changes.
Godfrey and Zou [23] introduce the notion of “origin
analysis” for detecting structural changes made to program
entities, in order to ﬁnd out reasons for merging and splitting
of code. With more precise changes identiﬁed on the structure,
it is possible to increase the chance of identifying such origins.
Refactoring transformations improve program structures
without introducing behavioural changes (see Mens and
Tourw ´e [24]). The four basic annotations may already express
simple forms of refactorings that “normalise” the structures in
order to remove irrelevant changes when evolving programs
are compared. To detect an advanced refactoring, especially
those happened to the API’s (see Dig et al[2]), a user-
deﬁned function works on a term of appropriate scope (e.g.,
class declaration, or method body), depending on the nature
of the refactoring.
Implementation. Although our implementation is based
onTXL [10], the implementation of the concepts could be
replaced using other generic transformation systems/ language
engineering tools such as GrammarWare [25].
VI. C ONCLUSIONS AND FUTURE WORK
In this paper, we have presented a declarative approach
to specify changes in programs that are relevant to different
programming tasks. In particular, we have demonstrated its
use in extracting the changes at the API levels for evolv-
ing Java programs and hardware speciﬁcations. We have
shown that four elementary annotations can account for all
light-weight syntactical normalisations by default, and can
be customised for more advanced semantic changes through
user-deﬁned functions. Our declarative speciﬁcation approach
already works on several programming and domain-speciﬁclanguages. Our automated tool has been implemented on top
of a generic transformation system, TXL, and the results
of detecting relevant differences in the three programs were
evaluated and compared to other diff utilities such as line-
based diff , showing more precise detection and acceptable
scalability and time performance. The tool and results can
be downloaded from http://sead1.open.ac.uk/mct. The tool
currently supports a substantial list of programming languages
inherited from http://txl.ca, as well as several requirements
modelling languages including i* [26], Problem Frames [27]
and argumentation [28], [29].
Our implementation of the clone removal is currently lim-
ited to exact clones. We are planning to integrate a near-
miss clones detector such as NiCAD by Roy and Cordy [11]
to ignore more structural changes. Recently, Kim et al [30]
proposed the MeCC tool to detect semantic clones (i.e. Types
3/4 according to Roy et al [11]) by statically analysing the
equivalent classes of memory footprints upon the exit of every
C/C++ procedure. Their approach adopts a speciﬁc technique
to guarantee a ﬁxed point can be reached by the normalisations
implicitly deﬁned by the checked equivalence classes. Without
an explicit user-deﬁned function, our approach cannot be
applied to these cases. Therefore, we plan to specify such
normalisations explicitly.
Recent work on requirements monitoring [31], [32] in-
dicates that it is important to detect meaningful changes
at run-time. In a generic graph-based approach, high-level
meaningful changes are expressed declaratively as change
patterns [33]. We are investigating how to extend our meta-
annotation approach to generate such change patterns for
detecting dynamic meaningful changes at the runtime.
ACKNOWLEDGEMENT
The work is partly supported by the EU FP7 Security
Engineering of Lifelong Evolvable Systems (SecureChange)
project, the Microsoft Software Engineering Innovative Foun-
dation (SEIF 2011) award, and the SFI CSET2 programme at
Lero. The authors would like to thank Charles B. Haley and
Michael A. Jackson for useful discussions.
REFERENCES
[1]D. MacKenzie, P. Eggert, and R. Stallman, Comparing and Merging
Files with GNU diff and patch . Network Theory, Ltd, December 2002.
[2]D. Dig and R. E. Johnson, “How do APIs evolve? a story of refactoring,”
Journal of Software Maintenance , vol. 18, no. 2, pp. 83–107, 2006.
[3]D. L. Parnas, “On the criteria to be used in decomposing systems into
modules,” Commun. ACM , vol. 15, pp. 1053–1058, December 1972.
[4]G. Canfora, L. Cerulo, and M. Di Penta, “Tracking your changes:
A language-independent approach,” IEEE Softw. , vol. 26, pp. 50–57,
January 2009.
[5]F. Heidenreich, J. Johannes, M. Seifert, and C. Wende, “Closing the
gap between modelling and Java,” in 2nd International Conference on
Software Language Engineering , 2009, pp. 374–383.
[6]Z. Xing and E. Stroulia, “UMLDiff: an algorithm for object-oriented
design differencing,” in 20th IEEE/ACM Conference on Automated
Software Engineering , 2005, pp. 54–65.
[7]D. Jackson and D. A. Ladd, “Semantic diff: A tool for summarizing
the effects of modiﬁcations,” in International Conference on Software
Maintenance . IEEE Computer Society, 1994, pp. 243–252.
[8]A. Duley, C. Spandikow, and M. Kim, “A program differencing al-
gorithm for Verilog HDL,” in IEEE/ACM international conference on
Automated Software Engineering , 2010, pp. 477–486.[9]A. V . Aho, R. Sethi, and J. D. Ullman, Compilers: principles, techniques,
and tools . Boston, MA, USA: Addison-Wesley Longman Publishing
Co., Inc., 1986.
[10] J. Cordy, “The TXL source transformation language,” Science of Com-
puter Programming , vol. 61, no. 3, pp. 190–210, 2006.
[11] C. K. Roy and J. R. Cordy, “NICAD: Accurate detection of near-miss
intentional clones using ﬂexible pretty-printing and code normalization,”
inInternational Conference on Program Comprehension . IEEE Com-
puter Society, 2008, pp. 172–181.
[12] G. Brunet, M. Chechik, S. Easterbrook, S. Nejati, N. Niu, and M. Sa-
betzadeh, “A manifesto for model merging,” in International Workshop
on Global Integrated Model Management . ACM, 2006, pp. 5–12.
[13] S. Nejati, M. Sabetzadeh, M. Chechik, S. Easterbrook, and P. Zave,
“Matching and merging of statecharts speciﬁcations,” in International
Conference on Software Engineering . IEEE Computer Society, 2007,
pp. 54–64.
[14] M. Schmidt and T. Gloetzner, “Constructing difference tools for models
using the SiDiff framework,” in 30th International Conference on
Software Engineering . ACM, 2008, pp. 947–948.
[15] T. Apiwattanapong, A. Orso, and M. J. Harrold, “A differencing
algorithm for object-oriented programs,” in 19th IEEE international
conference on Automated Software Engineering . IEEE Computer
Society, 2004, pp. 2–13.
[16] D. Beyer, A. Noack, and C. Lewerentz, “Efﬁcient relational calculation
for software analysis,” IEEE Trans. Software Eng. , vol. 31, no. 2, pp.
137–149, 2005.
[17] B. Fluri, M. Wuersch, M. PInzger, and H. Gall, “Change distilling:tree
differencing for ﬁne-grained source code change extraction,” IEEE
Transactions on Software Engineering , vol. 33, pp. 725–743, 2007.
[18] M. Kawaguchi, S. K. Lahiri, and H. Rebelo, “Conditional equivalence,”
Microsoft, Tech. Rep. MSR-TR-2010-119, October 2010.
[19] S. Wenzel and U. Kelter, “Analyzing model evolution,” in 30th Interna-
tional Conference on Software Engineering . ACM, 2008, pp. 831–834.
[20] B. Dagenais and M. P. Robillard, “Recommending adaptive changes
for framework evolution,” in 30th International Conference on Software
Engineering . ACM, 2008, pp. 481–490.
[21] D. Kawrykow and M. P. Robillard, “Non-essential changes in version
histories.” in 31st International Conference on Software Engineering .
ACM, 2011, pp. 351–360.
[22] M. Kim and D. Notkin, “Discovering and representing systematic code
changes,” in 29th International Conference on Software Engineering .
ACM, 2009, pp. 309 –319.
[23] M. W. Godfrey and L. Zou, “Using origin analysis to detect merging
and splitting of source code entities,” IEEE Trans. Softw. Eng. , vol. 31,
pp. 166–181, February 2005.
[24] T. Mens and T. Tourw ´e, “A survey of software refactoring,” IEEE Trans.
Softw. Eng. , vol. 30, pp. 126–139, February 2004.
[25] P. Klint, R. L ¨ammel, and C. Verhoef, “Toward an engineering discipline
for grammarware,” ACM Trans. Softw. Eng. Methodol. , vol. 14, pp. 331–
380, July 2005.
[26] E. S. K. Yu, “Towards modeling and reasoning support for early-phase
requirements engineering,” in International Conference on Requirements
Engineering . IEEE Computer Society, 1997, pp. 226–235.
[27] M. Jackson, Problem frames: analysing and structuring software devel-
opment problems . Addison-Wesley, 2001.
[28] C. B. Haley, R. C. Laney, J. D. Moffett, and B. Nuseibeh, “Security
requirements engineering: A framework for representation and analysis,”
IEEE Trans. Software Eng. , vol. 34, no. 1, pp. 133–153, 2008.
[29] Y . Yu, T. T. Tun, A. Tedeschi, V . Nunes Leal Franqueira, and B. Nu-
seibeh, “OpenArgue: Supporting argumentation to evolve secure soft-
ware systems,” in 19th IEEE International Requirements Engineering
Conference . IEEE Computer Society, August 2011.
[30] H. Kim, Y . Jung, S. Kim, and K. Yi, “MeCC: memory comparison-
based clone detector,” in 33rd International Conference on Software
Engineering . ACM, 2011, pp. 301–310.
[31] M. Salifu, Y . Yu, and B. Nuseibeh, “Specifying monitoring and switch-
ing problems in context,” in 15th IEEE International Requirements
Engineering Conference , 2007, pp. 211–220.
[32] Y . Wang, S. A. McIlraith, Y . Yu, and J. Mylopoulos, “Monitoring and
diagnosing software requirements,” Autom. Softw. Eng. , vol. 16, no. 1,
pp. 3–35, 2009.
[33] G. Bergmann, I. R ´ath, G. Varr ´o, and D. Varr ´o, “Change-driven model
transformations. change (in) the rule to rule the change.” Software and
Systems Modeling , pp. 1–31, 2011.