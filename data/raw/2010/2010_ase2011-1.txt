An Optimal Strategy for Algorithmic Debugging
David Insa and Josep Silva
Departamento de Sistemas Inform ¬¥aticos y Computaci ¬¥on
Universidad Polit ¬¥ecnica de Valencia
E-46022 Valencia, Spain.
fdinsa,jsilvag@dsic.upv.es
Abstract ‚ÄîAlgorithmic debugging is a technique that uses an
internal data structure to represent computations and ask about
their correctness. The strategy used to explore this data structure
is essential for the performance of the technique. The most
efÔ¨Åcient strategy in practice is Divide and Query that, until
now, has been considered optimal in the worst case. In this
paper we Ô¨Årst show that the original algorithm is inaccurate
and moreover, in some situations it is unable to Ô¨Ånd all possible
solutions, thus it is incomplete. Then, we present a new version
of the algorithm that solves these problems. Moreover, we
introduce a counterexample showing that Divide and Query is not
optimal, and we propose the Ô¨Årst optimal strategy for algorithmic
debugging with respect to the number of questions asked by the
debugger.
Index Terms ‚ÄîAlgorithmic Debugging, Divide and Query
I. I NTRODUCTION
Algorithmic debugging [15], [18] is based on the answers
of the programmer to a series of questions generated auto-
matically by the algorithmic debugger. In each question the
debugger provides the programmer with the input and output
of a (sub)computation (e.g., a function activation) and the
programmer states their correctness. This information is used
by the debugger to discard correct parts of the code and guide
the search for the bug until a buggy portion of code is isolated.
Example 1.1: Consider the following simple (and buggy)
Haskell program:
main = mix [1, 3] [2, 4]
insert e [] = [e]
insert e (x:xs)
| e <= x = e : x : xs
| otherwise = x : insert e xs
mix [] ys = ys
mix (x:xs) ys = insert x (mix xs xs)
An algorithmic debugging session for this program is the
following ( YES andNOanswers are provided by the program-
mer):
Starting Debugging Session...
(1) mix [3] [3] = [3]? NO
(2) mix [] [] = []? YES
(3) insert 3 [] = [3]? YES
Bug found in rule:
mix (x:xs) ys = insert x (mix xs xs)
The debugger points out the part of the code that contains the
bug. In this case mix xs xs should be mix xs ys . Note that,to debug the program, the programmer only has to answer
questions. It is not even necessary to see the code.
Algorithmic debuggers often produce a data structure called
theexecution tree (ET) [13] that represents a program execu-
tion. For instance, the ET of the program in Example 1.1 is
depicted in Figure I.
Fig. 1. ET of the program in Example 1.1
The nodes of the ET contain questions, and the strategy used
to decide what nodes of the ET should be asked is crucial for
the performance of the technique [16].
The algorithmic debugging strategy that presents the best
performance in practice is Divide and Query (D&Q) [15],
[7]. In fact, from a theoretical point of view, this strategy has
been thought optimal in the worst case for almost 30 years,
and it has been implemented in almost all current algorithmic
debuggers (see, e.g., [5], [6], [8], [14]). In this paper we show
that current algorithms for D&Q are suboptimal. We show the
problems of D&Q and solve them in a new improved algorithm
that is proven optimal. Moreover, the original strategy was
only deÔ¨Åned for ETs where all the nodes have an individual
weight of 1. In contrast, we allow our algorithms to work
with different individual weights that can be integer, but
also decimal. An individual weight of zero means that this
node cannot contain the bug. A positive individual weight
approximates the probability of being buggy. The higher the
individual weight, the higher the probability. This generaliza-
tion strongly inÔ¨Çuences the technique and allows us to assign
different probabilities of being buggy to different parts of the
program. For instance, a recursive function with higher-order
calls should be assigned a higher individual weight than a
function implementing a simple base case [16]. The weight
of the nodes can also be reassigned dynamically during the
debugging session in order to take into account the oracle‚Äôs
answers [6].We show that the original algorithms are inefÔ¨Åcient with
ETs where nodes can have different individual weights in the
domain of the positive real numbers (including zero) and we
redeÔ¨Åne the technique for these generalized ETs.
The rest of the paper has been organized as follows. In
Section II we recall the algorithmic debugging technique and
formalize the strategy D&Q. Then, we show with counterex-
amples that D&Q is suboptimal and incomplete. In Section III
we introduce an improved version of D&Q. In Section IV we
deÔ¨Åne a new strategy for algorithmic debugging that is optimal
in all cases. The correctness of the algorithms presented is
proven in Section V. Finally, Section VI concludes.
II. A LGORITHMIC DEBUGGING
In this section we recall the algorithmic debugging tech-
nique and formalize the strategy D&Q [15]. We start with the
deÔ¨Ånition of marked execution tree , that is an ET where some
nodes could have been removed because they were marked
as correct (i.e., answered YES), some nodes could have been
marked as wrong (i.e., answered NO) and the correctness of
the other nodes is undeÔ¨Åned.
DeÔ¨Ånition 2.1 (Marked Execution Tree): Amarked execu-
tion tree (MET) is a tree T= (N;E;M )whereNare the
nodes,ENNare the edges, and M:N!Vis a
marking total function that assigns to all the nodes in Na
value in the domain V=fWrong;Undenedg.
Initially, all nodes in the MET are marked as Undened .
But with every answer of the user, a new MET is produced.
Concretely, given a MET T= (N;E;M )and a noden2N,
the answer of the user to the question in nproduces a new
MET such that: (i) if the answer is YES, then this node and
its subtree is removed from the MET. (ii) If the answer is
NO, then, all the nodes in the MET are removed except this
node and its descendants.1Therefore, note that the only node
that can be marked as Wrong is the root. Moreover, the rest
of nodes can only be marked as Undened because when
the answer is YES, the associated subtree is deleted from the
MET.
Therefore, the size of the MET is gradually reduced with the
answers. If we delete all nodes in the MET then the debugger
concludes that no bug has been found. If, contrarily, we Ô¨Ånish
with a MET composed of a single node marked as wrong,
this node is called the buggy node and it is pointed to as
being responsible for the bug of the program.
All this process is deÔ¨Åned in Algorithm 1 where function
selectNode selects a node in the MET to be asked to the user
with function askNode . Therefore, selectNode is the central
point of this paper. In the rest of this section, we assume that
selectNode implements D&Q. In the following we use Eto
refer to the reÔ¨Çexive and transitive closure of EandE+for
the transitive closure.
1It is also possible to accept I don‚Äôt know as an answer of the user. In this
case, the debugger simply selects another node [8]. For simplicity, we assume
here that the user only answers YES or NO.Algorithm 1 General algorithm for algorithmic debugging
Input: A MET T= (N; E; M )
Output: A buggy node or?if no buggy node is detected
Preconditions:8n2N,M(n) =Undened
Initialization: buggyNode =?
begin
(1)do
(2) node = selectNode( T)
(3) answer = askNode(node)
(4) if(answer = NO)
(5) thenM(node) = Wrong
(6) buggyNode = node
(7) N=fn2Nj(node!n)2Eg
(8) elseN=Nnfn2Nj(node!n)2Eg
(9)while (9n2N; M (n) =Undened )
(10) return buggyNode
end
A. Divide and Query
D&Q assumes that the individual weight of a node is
always 1. Therefore, given a MET T= (N;E;M ), the
weight of the subtree rooted at node n2N,wn, is deÔ¨Åned
recursively as its number of descendants including itself (i.e.,
1 +Pfwn0j(n!n0)2Eg).
D&Q tries to simulate a dichotomic search by selecting the
node that better divides the MET into two subMETs with a
weight as similar as possible. Therefore, given a MET with n
nodes, D&Q searches for the node whose weight is closer to
n
2[7].
B. Limitations of D&Q
In this section we show that D&Q is suboptimal when the
MET does not contain a wrong node (i.e., all nodes are marked
as undeÔ¨Åned).2The intuition beyond this limitation is that the
objective of D&Q is to divide the tree by two, but the real
objective should be to reduce the number of questions to be
asked to the programmer. For instance, consider the MET in
Figure 2 (left) where each node is labeled with its weight and
the black node is marked as wrong, thus D&Q would select the
gray node. The objective of D&Q is to divide the 8 nodes into
two groups of 4. Nevertheless, the real motivation of dividing
the tree should be to divide the tree into two parts that would
produce the same number of remaining questions (in this case
3).
The problem comes from the fact that D&Q does not
take into account the marking of wrong nodes. For instance,
observe the two METs in Figure 2 (center) where the black
node is marked as wrong. In both cases D&Q would behave
exactly in the same way, because it completely ignores the
marking of the root. Nevertheless, it is evident that we do not
need to ask again for a node that is already marked as wrong
to determine whether it is buggy. However, D&Q counts the
2Modern debuggers [8] allow the programmer to debug the MET while it
is being generated. Thus the root node of the subtree being debugged is not
necessarily marked as Wrong .nodes marked as wrong as part of their own weight, and this
is a source of inefÔ¨Åciency.
Fig. 2. Behavior of Divide and Query
In the METs of Figure 2 (center) we have two METs. In
the one at the right nodes with weight 1 and 2 are optimal, but
in the one at the left, only the node with weight 2 is optimal.
In both METs D&Q would select either the node with weight
1 or the node with weight 2 (both are equally close to3
2).
However, we show in Figure 2 (right) that selecting node 1
is suboptimal, and the strategy should always select node 2.
Considering that the gray node is the Ô¨Årst node selected by the
strategy, then the number at the side of a node represents the
number of questions needed to Ô¨Ånd the bug if the buggy node
is this node. The number at the top of the Ô¨Ågure represents the
number of questions needed to determine that there is not a
bug. Clearly, as an average, it is better to select Ô¨Årst the node
with weight 2 because we would perform less questions (8
4
vs.9
4considering all four possible cases).
Therefore, D&Q returns a set of nodes that contains the
best node, but it is not able to determine which of them is the
best node, thus being suboptimal when it is not selected. In
addition, the METs in Figure 3 show that D&Q is incomplete.
Observe that the METs have 4 nodes, thus D&Q would always
select the node with weight 2. However, the node with weight
3 is equally optimal (both need12
5questions as an average to
Ô¨Ånd the bug) but it will be never selected by D&Q because
its weight is farther from the half of the tree4
2.
Another limitation of D&Q is that it was designed to work
with METs where all the nodes have the same individual
weight, and moreover, this weight is assumed to be 1. If we
work with METs where nodes can have different individual
weights and these weights can be any value greater or equal
to zero, then D&Q is suboptimal as it is demonstrated by
the MET in Figure 4. In this MET, D&Q would select node
n1because its weight is closer to21
2than any other node.
Fig. 3. Incompleteness of Divide and Query
Fig. 4. MET with decimal individual weights
However, node n2is the node that better divides the tree in
two parts with similar probabilities of containing the bug.
In summary, (1) D&Q is suboptimal when the MET is
free of wrong nodes, (2) D&Q is correct when the MET
contains wrong nodes and all the nodes of the MET have
the same weight, but (3) D&Q is suboptimal when the MET
contains wrong nodes and the nodes of the MET have different
individual weights.
III. O PTIMAL D&Q
In this section we introduce a new version of D&Q that
divides the MET into two parts with the same probability of
containing the bug (instead of two parts with the same weight).
We introduce a new algorithm that is correct and complete
even if the MET contains nodes with different individual
weights that can be any decimal number greater than 0. For
this, we deÔ¨Åne the search area of a MET as the set of
undeÔ¨Åned nodes.
DeÔ¨Ånition 3.1 (Search area): LetT= (N;E;M )be a
MET. The search area ofT,Sea(T), is deÔ¨Åned asfn2Nj
M(n) =Undenedg.
While D&Q uses the whole T, we only use Sea(T), because
answering all nodes in Sea(T)guarantees that we can discover
all buggy nodes [9]. Moreover, in the following we refer to the
individual weight of a node nwithwin; and we refer to the
weight of a (sub)tree rooted at nwithwnthat is recursively
deÔ¨Åned as:
wn=Pfwn0j(n!n0)2EgifM(n)6=Undened
win+Pfwn0j(n!n0)2Eg otherwise
Note that, contrarily to standard D&Q, the deÔ¨Ånition of
wnexcludes those nodes that are not in the search area (i.e.,
the root node when it is wrong). Note also that winallows
us to assign any individual weight to the nodes. This is a
generalization of D&Q where it is assumed that all nodes have
the same individual weight and it is always 1.
For the sake of clarity, given a node n2Sea(T), we
distinguish between three subareas of Sea(T)induced by n:
(1)nitself, whose individual weight is win; (2) descendants
ofn(Down (n)), whose weight is
dn=Pfwin0jn02Sea(T)^(n!n0)2E+g
and (3) the rest of nodes ( Up(n)), whose weight is
un=Pfwin0jn02Sea(T)^(n!n0)62Eg
Example 3.2: Consider the MET in Figure 5. Assuming that
the rootnis marked as wrong and all nodes have an individual
weight of 1, then Sea(T)contains all nodes except n,un0= 3Fig. 5. Functions Up and Down
(total weight of the gray nodes), and dn0= 3 (total weight of
the white nodes).
Clearly, for any MET whose root is nand a node n0,
M(n0) =Undened , we have that:
wn=un0+dn0+win0 (Equation 1)
wn0=dn0+win0 (Equation 2)
Intuitively, given a node n, what we want to divide by half
is the area formed by un+dn. That is,nwill not be part
ofSea(T)after it has been answered, thus the objective is
to makeunequal todn. This is another important difference
with traditional D&Q: winshould not be considered when
dividing the MET. We use the notation n1n2to express
thatn1divides Sea(T)better than n2(i.e.,jdn1 un1j<
jdn2 un2j). And we use n1n2to express that n1andn2
equally divide Sea(T). If we Ô¨Ånd a node nsuch thatun=dn
thennproduces an optimal division, and should be selected
by the strategy.
In the rest of this section we present an algorithm for
optimal D&Q (i.e., that optimally divides the MET by half).
In particular, given a MET, Algorithm 2 efÔ¨Åciently determines
the best node to divide Sea(T)by half (in the following the
optimal node ). In order to Ô¨Ånd this node, the algorithm does
not need to compare all nodes in the MET. It follows a path
of nodes from the root to the optimal node which is closer to
the root producing a minimum set of comparisons.
Algorithm 2 Optimal D&Q ‚ÄîSelectNode in Algorithm 1‚Äî
Input: A MET T= (N; E; M )whose root is n2Nand8n02
N; wi n00
Output: A node nOptimal2N
Preconditions:9n02N,M(n0) =Undened
begin
(1) Candidate = n
(2)do
(3) Best = Candidate
(4) Children =fmj(Best!m)2Eg
(5) if(Children =;)then return Best
(6) Candidate = n0j8n00withn0; n002Children, wn0wn00
(7)while (wCandidate wiCandidate
2>wn
2)
(8) Candidate = n0j8n00withn0; n002Children,
wn0 win0
2wn00 win00
2(9)if(M(Best) =Wrong )then return Candidate
(10) if(wnwBest+wCandidate wiBest
2 wiCandidate
2)
then return Best
(11) else return Candidate
endExample 3.3: Consider the MET in Figure 6 where 8n2
N;win= 1 andM(n) =Undened .
Fig. 6. DeÔ¨Åning a path in a MET to Ô¨Ånd the optimal node
Observe that Algorithm 2 traverses the MET top-down from
the root selecting at each level the heaviest node until we Ô¨Ånd
a node whose weight minus its individual weight divided by
two is smaller or equal than the half of the MET (wn
2), thus,
deÔ¨Åning a path in the MET that is colored in gray. Finally, the
algorithm selects n1.
One important idea of the algorithm is the identiÔ¨Åcation of
a path from the root to the buggy node. In particular, when
we use Algorithm 2 and compare two nodes n1;n2in a MET
whose root is n, we Ô¨Ånd Ô¨Åve possible cases (see Figure 7) to
deÔ¨Åne this path:
Case 1:dn1>un1^dn2un2^n1,n2are brothers
Case 2:dn1un1^dn2un2^n1,n2are brothers
Case 3:dn1>un1^dn2>un2^(n1!n2)2E
Case 4:dn1>un1^dn2un2^(n1!n2)2E
Case 5:dn1un1^dn2un2^(n1!n2)2E
Case 1 Case 2 Case 3 Case 4 Case 5
Fig. 7. Determining the best node in a MET (Ô¨Åve possible cases)
In cases 1 and 5 n1is better (i.e., n1n2orn1n2); in
case 3n2is better; and in cases 2 and 4 the best node must be
determined comparing them. Observe that these results allow
the algorithm to determine the path to the optimal node that is
closer to the root. For instance, in Example 3.3 case 1 is used
to select a child, e.g., node n1instead of node n4. Case 3 is
used to go down and select node n1instead of node n. Case 2
is used to select node n2instead of node n3(this is done with
line (8) of the algorithm). Case 5 is used to stop going down
at noden2because it is better than all its descendants. And
it is also used to determine that nodes n3andn4are better
than all their descendants. Finally, case 4 is used to select the
optimal node, n1instead ofn2(this is done with line (10) of
the algorithm). Note that D&Q could have selected node n2
that is equally close to9
2than noden1; but it is suboptimal
becauseun1= 3 anddn1= 5 whereasun2= 6 anddn2= 2.The correctness of Algorithm 2 is stated by the following
theorem.
Theorem 3.4 (Correctness): LetT= (N;E;M )be a MET
where8n2N;win0, then the execution of Algorithm 2
withTas input always terminates producing as output a node
n2Sea(T)such that @n02Sea(T)jn0n.
Algorithm 2 always returns a single optimal node. However,
a small modiÔ¨Åcation can make the algorithm to return all
optimal nodes, thus being complete: changing line (8) to
collect all candidates instead of one, and updating accordingly
the output lines to return a set. Moreover, line (10) should be
split to distinguish between the cases ‚Äò >‚Äô (returningfBestg)
and ‚Äò =‚Äô (returning candidates[fBestg).
IV. D IVIDE BY QUERIES
An strategy should be consider optimal with respect to the
number of questions generated if and only if the average
number of questions asked with any MET is minimum. Note
that we can compute this average by assuming that the bug can
be in any node of the MET, and thus computing the number
of questions asked for each node using Algorithm 1. In this
section we call optimal node to the Ô¨Årst node asked by an
optimal strategy (instead of the node that better divides the
MET by the half).
DeÔ¨Ånition 4.1 (Optimal strategy): Letbe an algorithmic
debugging strategy. Given a MET T= (N;E;M ), lets
nthe
sequence of questions made by Algorithm 1 with strategy 
and considering that the only buggy node in Tisn2N. Let
t=P
ni2Njs
nij. We say that is optimal if and only if for any
MET @0: t>t0.
In this section we show that any version of D&Q is and
will be suboptimal. The reason is that D&Q tries to prune
the biggest possible subtree, but it ignores the structure of
the MET. In practice, pruning complex subtrees that are more
difÔ¨Åcult to explore is very important, but this is ignored by
D&Q. This means that our version of D&Q (Algorithm 2)
is optimal in the sense that it optimally divides the MET
by the half. But it is not an optimal strategy because in
total (considering all questions needed to Ô¨Ånd the bug) it can
perform more questions than necessary.
Because we compute the cost of a strategy based on the
number of questions asked, we need a formal deÔ¨Ånition for
sequence of questions.
DeÔ¨Ånition 4.2 (Sequence of questions): Given a MET T=
(N;E;M )and two nodes n1;n22N, asequence of questions
ofn1with respect to n2,sq(n1;n2), is formed by all nodes
asked by Algorithm 1 when the Ô¨Årst node selected by function
selectNode (T)isn2and the only buggy node in Tisn1.
This means that the sequence of questions is completely
dependent on the used strategy. For instance, using standard
D&Q with the MET in Figure 2 (left) and assuming that all
nodes are marked as undeÔ¨Åned:
sq(n; n 3) = [n3; n1; n2; n7; n]sq(n3; n) = [n; n 3; n4; n5; n6]
sq(n; n) = [n; n 3; n1; n2; n7]sq(n3; n3) = [n3; n4; n5; n6]
We now show a counterexample where D&Q cannot Ô¨Ånd an
optimal node.
Fig. 8. MET where D&Q cannot Ô¨Ånd an optimal node
Example 4.3: Consider the MET in Figure 8 (left) where
the number at the right of the node represents jsq(n;n0)jbeing
nthe node itself and n0the gray node. D&Q would select node
n1because its weight is closer to114
2= 57 . However,n2is
the only optimal node, and it produces less questions than n1
even though its weight is far from 57.
In the MET at the left we start asking node n1. If the bug is
located in the subtree of node n1, because it is a deep subtree,
we would ask an average of log257 = 5;83questions to each
node ( +1because we have initially asked node n1). If the
bug were not in this subtree, then after asking node n1we
would explore the subtree of node n2. If the bug is located in
this subtree we must ask all nodes until we Ô¨Ånd the bug, and
all these nodes have to consider the question already asked to
noden1; in total we ask (P51
i=3i) + 51 = 1374 questions. If
the bug were not located in the right brach, there only remain
the 7 top nodes in the left branch (including the root). There
we ask an average of log27 = 2;8questions to each node
(+2because we already asked nodes n1andn2). In total we
ask576;83 + 1374 + 74;8 = 1796;91questions, and an
average of1796;91
114= 15;76questions.
If, contrarily, we start asking node n2(see the MET at the
right) and the bug is located in this subtree, we ask (P50
i=2i)+
50 = 1324 questions. If the bug is located in the other branch,
after asking node n2we still have 64 nodes in depth; therefore,
with log264 = 6 questions ( +1because we have initially
asked noden2) we will Ô¨Ånd the bug. In total, we ask 1324 +
647 = 1772 questions, and an average of1772
114= 15;54
questions.
Example 4.3 showed that D&Q is not an optimal strategy.
The question now is whether an optimal strategy exists: is the
problem decidable?
Theorem 4.4 (Decidability): Given a MET, Ô¨Ånding all op-
timal nodes is a decidable problem.
Proof: We show that at least one Ô¨Ånite method exists to
Ô¨Ånd all optimal nodes. Firstly, we know that the size of the
MET is Ô¨Ånite because the question in the root can only be
completed if the execution terminated, and hence the number
of subcomputations‚Äîand nodes‚Äîis Ô¨Ånite [8]. Because the
tree is Ô¨Ånite, we know (according to Algorithm 1) that any
sequence of questions asked by the debugger (no matter the
strategy used) is also Ô¨Ånite because at most all nodes of
the tree are asked once. Therefore, the number of possiblesequences is also Ô¨Ånite. This guarantees that we can compute
all possible sequences and select the best sequences according
to the equation in DeÔ¨Ånition 4.1. The optimal nodes will be
the Ô¨Årst of the selected sequences.
Even though the method described in the proof of Theo-
rem 4.4 is effective, it is too expensive because it needs to
compute all possible sequences of questions. In the rest of
this section we present a more efÔ¨Åcient method to compute
all optimal nodes.
We now present a method to select the best sequences of
questions (sqn) for the nodes in a MET. For the sake of clarity,
in the following when we talk about the sequence of questions
of a node, we assume that this node is wrong and that the
sequence contains a set of nodes that after they have been
asked, they allow us to know whether the node is buggy or
not.
In order to formalize the method described in the proof of
Theorem 4.4 we Ô¨Årst deÔ¨Åne the notion of valid sequence of
questions.
DeÔ¨Ånition 4.5 (Valid sequences of questions of a node):
LetT= (N;E;M )be a MET whose root is n2N. A
sequence of questions sqn= [n1;:::;nm]fornis valid if:
1)8ni;nj2sqn;1i<jm;(ni!nj)62E
2)Nnfnjj(ni!nj)2E^ni2sqng=fng
We denote with SQnthe set of valid sequences of questions
ofn.
Intuitively, the valid sequences of questions of a root node
nare all those sequences formed with non-repeated nodes
that (1) a node in the sequence cannot be descendant of a
previous node in the sequence, and (2) after having pruned all
the subtrees whose roots are the nodes of the sequence, node
nhas not descendants.
The next example shows that if we label each node of a
MET with a valid sequence of questions, then it is possible
to know how many questions do we need to ask to Ô¨Ånd the
buggy node.
Example 4.6: Consider the next tree:
Here, nodes are labeled with their weight (inside) their
identiÔ¨Åer (top left), an optimal sequence of questions for this
node (top right), jsq(n;n 1)jwherenis the node (bottom
right), and the sum of jsq(n0;n)jfor all node n0of the subtree
of this node ( n) (bottom left).
There exist many valid sequences for node n1, (e.g.
[n2;n7;n10],[n2;n10;n7],[n3;n2;n7;n10], etc.). If we con-
sider the sequence of the Ô¨Ågure ( [n2;n7;n10]) and taking intoaccount that we start asking in the root node3, then we can
easily determine the number of questions needed to Ô¨Ånd the
bug in any node n. We refer to this number with qn. For
instance, we need 4 questions to Ô¨Ånd the bug in node n1
([n1;n2;n7;n10]). Similarly, qn4= 4 ([n1;n2;n3;n4]) and
qn7= 5 ([n1;n2;n7;n8;n9]). Observe that when we reach
noden7and mark it as wrong we continue the sequence of
questions of this node ( [n8;n9]).
Once we have computed qfor all descendants of node n,
we can also compute the n‚Äôs number at bottom left (referred to
asQn) by adding all qs. In the Ô¨Ågure, we see that Qn1= 46 ,
Qn2= 19 and (trivially) the leafs only need one question (the
node itself).
Therefore, to Ô¨Ånd the optimal nodes, we only have to:
(i) Compute Qnfor all nodes in the MET, (ii) add to the
MET a Ô¨Åctitious root node, (iii) compute all valid sequences
of the root node, (iv) compute the cost associated to each
sequence (with Algorithm 3), and (v) select the Ô¨Årst node of
the sequences with the minimum cost.
Essentially, Algorithm 3 is used to compute Qnof a given
node. For this, it compositionally computes the number of
questions that should be asked to each node. This is done by
taking into account the individual weight of each node that,
as with Algorithm 2, can be any number greater than or equal
to 0.
Example 4.7: Consider the following tree at the left with
depth 4, where we want to compute the cost Qn1associated
to the sequence [n3;n6;n2].
Function ComputeQ takes the Ô¨Årst element of the sequence
(n3) and computes the number of questions to be done if the
bug is located in its subtree. This is Qn3= 8. Therefore, no
matter where the bug is, we have to ask one extra question for
each node (the one in the root n1). Thus we have a total of
8+3=11 questions. If the bug is not located in the subtree of
n3, then we should continue asking questions of the sequence
having pruned this subtree. Therefore, we should prune this
tree and recalculate Qfor the ancestors of node n3. This is
done with function AdjustIntermediateNodes producing the
tree with a depth of 2 in the middle of the Ô¨Ågure above. In
this new tree, Qn2has been recomputed and its value is 1.
Then, we proceed with the next question in the sequence
(n6). Now we have Qn6=4 questions. But now we have to
take into account two extra questions (one for n1and one
3Note that this does not mean that valid sequences must necessarily start
asking the root node. Given any MET we can add a new Ô¨Åctitious parent of
the root and compute the optimal sequence of questions associated to this
new node.forn3) for each node in the subtree of n6: 2*2=4 questions.
Hence we have a total of (8+3)+(4+4)=19 questions. If the
bug is not located in the subtree of node n6we prune it
producing the tree at the right of the Ô¨Ågure and we ask the
next question in the sequence: n2. If the bug is n2, then
we have to ask one question ( n2) plus the extra questions
done before ( n1,n3andn6). Thus we have a total of
(8+3)+(4+4)+(1+3)=23 questions. Finally, if the bug is located
in the root, we have to ask 4 questions: the root node itself
and all questions in the sequence. Thus, the Ô¨Ånal value of Qn1
is (8+3)+(4+4)+(1+3)+(4)=27.
The previous example illustrates the work done by Algo-
rithm 3 to compute Q. It basically computes and sums the
number of questions asked for each node. For this, it has to
take into account the sequence of questions in order to decide
how many questions are cumulated when a new subtree is
explored.
Algorithm 3 uses function computeSQ (T;n)to compute
all possible valid sequences of questions associated to node n.
Therefore, because this function returns all possible sequences
for the node, then the strategy is optimal. However, note that
this function could be restricted to behave as other strategies of
the literature. For instance, we could adapt it to work as the
strategy Top-Down [1] if we restrict the sequences returned
to those where all elements in the sequence are children of
n. This is equivalent to adding the following restriction to
DeÔ¨Ånition 4.5:
3)8n02sqn;(n!n0)2E
V. P ROOFS OF TECHNICAL RESULTS
We Ô¨Årst deÔ¨Åne a MET where individual weights can be
decimal numbers:
DeÔ¨Ånition 5.1 (Variable MET): Avariable MET T=
(N;E;M )is a MET, where8n2N;win0.
Theorem 3.4 states the correctness of Algorithm 2. For the
proof of this theorem we deÔ¨Åne Ô¨Årst some auxiliary lemmas.
The following lemma ensures that wn1 win1
2>wn
2used in
the condition of the loop implies dn1>un1.
Lemma 5.2: Given a variable MET T= (N;E;M )whose
root isn2Nand a node n12Sea(T),dn1> un1if and
only ifwn1 win1
2>wn
2.
Proof: We prove that wn1 win1
2>wn
2impliesdn1>
un1and vice versa.
wn1 win1
2>wn
22wn1 win1> wn
We replace wn1using Equation 2:
2(dn1+win1) win1> wn
2dn1+win1> wn
dn1> wn dn1 win1
We replace wn dn1 win1using Equation 1:
dn1> un1
The following lemma ensures that given two nodes n1and
n2wherednunin both nodes and n1!n2thenn2
n1_n2n1(Case 3 ).Algorithm 3 ComputeQn
Input: A MET T= (N; E; M )and a node n2N
Output: Qn
(1)(sqn; Qn) =ComputeOptimalSequence (T; n)
(2)return Qn
function ComputeOptimalSequence (T; n)
begin
(3)SQn=computeSQ (T; n)
(4)sqOptimal =sqn2SQnj@sq0
n2SQn:
ComputeQ (T; n; sq n)>ComputeQ (T; n; sq0
n)
(5)QOptimal =ComputeQ (T; n; sqOptimal )
(6)return (sqOptimal; QOptimal )
end
function ComputeQ (T; n; sq n)
begin
(7)questions = 0
(8)indexNode = 0
(9)accumNodes = 1
(10)while (fn0j(n!n0)2Eg6=fng)
(11) node =sqn[indexNode ]
(12) indexNode =indexNode + 1
(13) questions =questions + (Qnode +accumNodeswnode)
(14) accumNodes =accumNodes + 1
(15) T=AdjustIntermediateNodes (T; n; node )
end while
(16)questions =questions + (accumNodeswin)
(17)return questions
end
function AdjustIntermediateNodes (T; n; n0)
begin
(18)O=fn002Nj(n0!n00)2Eg
(19)N=NnO
(20)n0=n00j(n00!n0)2E
(21)while (n06=n)
(22) (; Qn0) =ComputeOptimalSequence (T; n0)
(23) wn0=wn0 jOj
(24) n0=n00j(n00!n0)2E
end while
(25)return T
end
Lemma 5.3: Given a variable MET T= (N;E;M )and
given two nodes n1;n22Sea(T), with (n1!n2)2E, if
dn2un2thenn2n1_n2n1.
Proof: We prove thatjdn2 un2jjdn1 un1jholds.
First, we know that dn1=dn2+win2+incandun1=
un2 win1 incwithinc0, whereincrepresents the
weight of the possible brothers of n2.
jdn2 un2jjdn1 un1j
As we know that dnunin both nodes:
dn2 un2dn1 un1
We replace dn1andun1:
dn2 un2(dn2+win2+inc) (un2 win1 inc)
dn2 un2dn2 un2+win1+win2+ 2inc
0win1+win2+ 2inc
Hence, because win1,win2,inc0thenjdn2 un2j 
jdn1 un1jis satisÔ¨Åed and thus n2n1_n2n1.
The following lemma ensures that given two nodes n1and
n2wherednunin both nodes and n1!n2thenn1
n2_n1n2(Case 5 ).
Lemma 5.4: Given a variable MET T= (N;E;M )and
given two nodes n1;n22Sea(T), with (n1!n2)2E, if
dn1un1thenn1n2_n1n2.Proof: We prove thatjdn1 un1jjdn2 un2jholds.
First, we know that dn2=dn1 win2 incandun2=
un1+win1+incwithinc0, whereincrepresents the
weight of the possible brothers of n2.
jdn1 un1jjdn2 un2j
As we know that undnin both nodes:
un1 dn1un2 dn2
We replace dn2andun2:
un1 dn1(un1+win1+inc) (dn1 win2 inc)
un1 dn1un1 dn1+win1+win2+ 2inc
0win1+win2+ 2inc
Hence, because win1,win2,inc0thenjdn1 un1j 
jdn2 un2jis satisÔ¨Åed and thus n1n2_n1n2.
The following lemma ensures that given two brother nodes
n1andn2, ifdn1un1thendn2un2.
Lemma 5.5: Given a variable MET T= (N;E;M )whose
root isn2N, and given three nodes n12Nandn2;n32
Sea(T), with (n!n1)2E,(n1!n2);(n1!n3)2E,
ifdn2un2thendn3un3.
Proof: We prove it by contradiction assuming that dn3>
un3whendn2un2and they are brothers. First, we know
that asn2andn3are brothers then un2wn3andun3
wn2. Therefore, if dn3> un3thendn2un2wn3
dn3> un3wn2dn2that implies dn2> dn2that is a
contradiction itself.
If two nodes n1andn2are brothers and dn1un1then
n1n2_n1n2(Case 1 ). The following lemma proves
this property.
Lemma 5.6: Given a variable MET T= (N;E;M )whose
root isn2N, and given three nodes n12Nandn2;n32
Sea(T), with (n!n1)2E,(n1!n2);(n1!n3)2E,
ifdn2un2thenn2n3_n2n3.
Proof: We prove thatjdn2 un2jjdn3 un3jholds.
First, asn2andn3are brothers we know that wndn2+
dn3+win2+win3, thenwn=dn2+dn3+win2+win3+inc
withinc0.
jdn2 un2jjdn3 un3j
Asdn2un2by Lemma 5.5 we know that un3dn3:
dn2 un2un3 dn3
We replace un2andun3using Equation 1:
dn2 (wn dn2 win2)(wn dn3 win3) dn3
 wn+ 2dn2+win2wn 2dn3 win3
 2wn 2dn2 2dn3 win2 win3
2wn2dn2+ 2dn3+win2+win3
wndn2+dn3+win2
2+win3
2We replace wn:
dn2+dn3+win2+win3+incdn2+dn3+win2
2+win3
2
win2+win3+incwin2
2+win3
2win2
2+win3
2+inc0
Hence, because win2,win3,inc0thenjdn2 un2j 
jdn3 un3jis satisÔ¨Åed and thus n2n3_n2n3.
The following lemma ensures that given two brother nodes
n1andn2, ifwn1wn2anddn1un1thendn2un2.
Lemma 5.7: Given a variable MET T= (N;E;M )whose
root isn2N, and given three nodes n12Nandn2;n32
Sea(T), with (n!n1)2E,(n1!n2);(n1!n3)2E,
ifwn2wn3anddn2un2thendn3un3.
Proof: We prove it by contradiction assuming that dn3>
un3whenwn2wn3anddn2un2and they are brothers.
First, we know that as n2andn3are brothers then un2wn3andun3wn2. Therefore, if dn3> un3thendn3>
un3wn2wn3dn3that implies dn3> dn3that is a
contradiction itself.
If two nodes n1andn2are brothers and un1dn1^
un2dn2then, ifwn1 win1
2wn2 win2
2is satisÔ¨Åed then
n1n2_n1n2(Case 2 ). The following lemma proves
this property.
Lemma 5.8: Given a variable MET T= (N;E;M )whose
root isn2N, and given three nodes n12Nandn2;n32
Sea(T), with (n!n1)2E,(n1!n2);(n1!n3)2E,
andun2dn2andun3dn3,n2n3_n2n3if and
only ifwn2 win2
2wn3 win3
2.
Proof: First, ifjdn2 un2jjdn3 un3jthenn2
n3_n2n3. Thus it is enough to prove that wn2 win2
2
wn3 win3
2impliesjdn2 un2jjdn3 un3jand vice versa
whenundnin both nodes and they are brothers.
wn2 win2
2wn3 win3
22wn2 win22wn3 win3
We replace wn2andwn3using Equation 2:
2(dn2+win2) win22(dn3+win3) win3
2dn2+win22dn3+win3
We add wn:
 wn+ 2dn2+win2 wn+ 2dn3+win3
wn 2dn2 win2wn 2dn3 win3
We replace wnusing Equation 1:
(dn2+un2+win2) 2dn2 win2
(dn3+un3+win3) 2dn3 win3
 dn2+un2 dn3+un3
un2 dn2un3 dn3
Asundnin both nodes:
jun2 dn2jjun3 dn3j
jdn2 un2jjdn3 un3j
If two nodes n1andn2are brothers and dn1un1and
n2!+n3then, ifn1n2thenn1n3_n1n3. The
following lemma proves this property.
Lemma 5.9: Given a variable MET T= (N;E;M )whose
root isn2N, and given four nodes n12Nandn2;n3;n42
Sea(T), with (n!n1)2E,(n1!n2);(n1!n3)2E,
(n3!n4)2E+, ifdn2un2andn2n3thenn2
n4_n2n4.
Proof: This can be trivially proved having into account
thatdn3un3whendn2un2by Lemma 5.5 and then by
Lemma 5.4 we know that n3n4_n3n4and asn2n3
thenn2n4_n2n4.
If two nodes n1andn2are brothers and dn1un1^dn2
un2andn2!+n3then, ifn1n2thenn1n3_n1n3.
The following lemma proves this property.
Lemma 5.10: Given a variable MET T= (N;E;M )whose
root isn2N, and given four nodes n12Nandn2;n3;n42
Sea(T), with (n!n1)2E,(n1!n2);(n1!n3)2E,
(n3!n4)2E+, ifdn2un2anddn3un3andn2n3
thenn2n4_n2n4.
Proof: This can be trivially proved having into account
thatdn3un3and then by Lemma 5.4 we know that n3
n4_n3n4and asn2n3thenn2n4_n2n4.
If two nodes n1andn2are brothers and n1n2and
n2!+n3thenn1n3. The following lemma proves this
property.Lemma 5.11: Given a variable MET T= (N;E;M )whose
root isn2N, and given four nodes n12Nandn2;n3;n42
Sea(T), with (n!n1)2E,(n1!n2);(n1!n3)2E,
(n3!n4)2E+, ifn2n3thenn2n4.
Proof: We show that if n2n3thendn3< un3. We
prove it by contradiction assuming that dn3un3whenn2
n3. First, asn2andn3are brothers we know that wndn2+
dn3+win2+win3, thenwn=dn2+dn3+win2+win3+inc
withinc0. Therefore, ifjdn2 un2j<jdn3 un3jthen
n2n3. Thus it is enough to prove that jdn2 un2j<
jdn3 un3jis not satisÔ¨Åed when dn3un3andn2andn3
are brothers.
jdn2 un2j<jdn3 un3j
Asdn3un3by Lemma 5.5 we know that un2dn2:
un2 dn2< dn3 un3
We replace un2andun3using Equation 1:
(wn dn2 win2) dn2< dn3 (wn dn3 win3)
wn 2dn2 win2<2dn3 wn+win3
2wn<2dn2+ 2dn3+win2+win3
wn< dn2+dn3+win2
2+win3
2We replace wn:
dn2+dn3+win2+win3+inc < d n2+dn3+win2
2+win3
2
win2+win3+inc <win2
2+win3
2win2
2+win3
2+inc < 0
But, this is a contradiction with win2;win3;inc0. Hence,
dn3<un3.
Now we show that, if n2n3thenn2n4. We prove
it by contradiction assuming that n4n2_n4n2when
n2n3. First, we know that dn3<un3. Therefore we know
thatdn4=dn3 win4 decandun4=un3+win3+dec
withdec0, wheredecrepresents the weight of the possible
brothers ofn4.
jdn3 un3j>jdn2 un2jjdn4 un4j
We replace dn4andun4:
jdn3 un3j>jdn2 un2j
jdn2 un2jj(dn3 win4 dec) (un3+win3+dec)j
jdn2 un2jjdn3 win4 dec un3 win3 decj
jdn2 un2jjdn3 un3 win3 win4 2decj
Note thatdn3 un3must be positive, thus dn3> un3. But
this is a contradiction with dn3<un3.
The following lemma ensures that given two nodes n1and
n2wheredn1un1anddn2un2andn1!n2then
ifwnwn1+wn2 win1
2 win2
2is satisÔ¨Åed then n1
n2_n1n2(Case 4 ).
Lemma 5.12: Given a variable MET T= (N;E;M )and
given two nodes n1;n22Sea(T), with (n1!n2)2E, and
dn1un1, anddn2un2,n1n2_n1n2if and only
ifwnwn1+wn2 win1
2 win2
2.
Proof: First, ifjdn1 un1jjdn2 un2jthenn1n2
orn1n2. Thus it is enough to prove that wnwn1+
wn2 win1
2 win2
2impliesjdn1 un1jjdn2 un2jand
vice versa when dn1un1anddn2un2.wnwn1+wn2 win1
2 win2
2We replace wn1; wn2using Equation 2:
wn(dn1+win1) + (dn2+win2) win1
2 win2
2
wndn1+dn2+win1
2+win2
22wn2dn1+ 2dn2+win1+win2
 2wn 2dn1 2dn2 win1 win2
 wn+ 2dn1+win1wn 2dn2 win2
We replace wnusing Equation 1:
 (dn1+un1+win1) + 2dn1+win1
(dn2+un2+win2) 2dn2 win2
 dn1 un1 win1+ 2dn1+win1
dn2+un2+win2 2dn2 win2
 un1+dn1 dn2+un2
dn1 un1un2 dn2
Asdn1un1anddn2un2:
jdn1 un1jjun2 dn2j
jdn1 un1jjdn2 un2j
Finally, we prove the correctness of Algorithm 2.
Theorem 3.4. LetT= (N;E;M )be a variable MET, then
the execution of Algorithm 2 with Tas input always terminates
producing as output a node n2Sea(T)such that @n02
Sea(T)jn0n.
Proof: The Ô¨Åniteness of the algorithm is proved thanks
to the following invariant: each iteration processes one single
node, and the same node is never processed again. Therefore,
becauseNis Ô¨Ånite, the loop will terminate.
The correctness can be proved showing that after any
number of iterations the algorithm always Ô¨Ånishes with an
optimal node. We prove it by induction on the number of
iterations performed.
(Induction Hypothesis) Afteriiterations, the algorithm
has a candidate node Best2Sea(T)such that8n02
Sea(T);(Best!n0)62E;Bestn0_Bestn0.
(Inductive Case) We prove that the iteration i+ 1 of the
algorithm will select a new candidate node Candidate such
thatCandidateBest_CandidateBest , or it will
terminate selecting an optimal node.
Firstly, when the condition in Line (5) is satisÔ¨Åed Best and
Candidate are the same node (say n0). According to the
induction hypothesis, this node is better or equal than any
other of the nodes in the set fn002Sea(T)j(n0!n00)62Eg.
Therefore, because n0has no children, then it is an optimal
node; and it is returned in Line (5). Otherwise, if the condition
in Line (5) is not satisÔ¨Åed, Line (7) in the algorithm ensures
thatwBest wiBest
2>wn
2beingnthe root ofTbecause in
the iteration ithe loop did not terminate or because Best
is the root (observe that an exception can happen when
all nodes have an individual weight of 0. But in this case
all nodes are optimal, and thus the node returned by the
algorithm is optimal). Then we know that dBest> uBest by
Lemma 5.2. Moreover, according to Lines (4) and (6), we
know thatCandidate is the heaviest child of Best . We have
two possibilities:
dCandidate > u Candidate : In this case the loop does not terminate
and8n02Sea(T);(Candidate!n0)62E;Candidate
n0_Candidaten0. Firstly, by Lemma 5.3 we know that
CandidateBest_CandidateBest , and thus, by the
induction hypothesis we know that 8n02Sea(T);(Best!
n0)62E;Candidaten0_Candidaten0. By Lemma 5.6
we know that Candidaten0_Candidaten0being n0a
brother of Candidate . Moreover, by Lemma 5.9 and 5.11 wecan ensure that Candidaten0_Candidaten0being n0
a descendant of a candidate ‚Äôs brother.
dCandidateuCandidate : In this case the loop terminates (Line
(7)) and we know by Lemma 5.7 that dn0un0being n0any
brother of Candidate . In Line (8) according to Lemma 5.8 we
select the Candidate such that Candidaten0_Candidate
n0being n0a brother of Candidate . Moreover, by Lemma 5.10
and 5.11 we can ensure that Candidaten0_Candidate
n0being n0a descendant of a candidate ‚Äôs brother. Then
equation (wnwBest+wCandidate wiBest
2 wiCandidate
2)
is applied in Line (10) to select an optimal node. Lemma 5.12
ensure that the node selected is an optimal node because,
according to Lemma 5.4, for all descendant n0ofCandidate ,
Candidaten0_Candidaten0.
VI. C ONCLUSION
During three decades, Divide & Query has been the
more efÔ¨Åcient algorithmic debugging strategy. On the practi-
cal side, all current algorithmic debuggers implement D&Q
[2], [4], [6], [8], [10], [11], [12], [13], [14], and experi-
ments [3], [17] (see also http://users.dsic.upv.es/ jsilva/DDJ/
#Experiments) demonstrate that it performs on average 2-36%
less questions than other strategies. On the theoretical side,
because D&Q intends a dichotomic search, it has been thought
optimal with respect to the number of questions performed,
and thus research on algorithmic debugging strategies has
focused on other aspects such as reducing the complexity of
questions.
In this work we show that in some situations current
algorithms for D&Q are incomplete and inefÔ¨Åcient because
they are not able to Ô¨Ånd all optimal nodes, and sometimes
they return nodes that are not optimal. We have identiÔ¨Åed the
sources of inefÔ¨Åciency and provided examples that show both
the incompleteness and incorrectness of the technique.
A relevant contribution of this work is a new algorithm for
D&Q that optimally divides the ET even in the case where
all nodes of the ET can have different individual weights
inR+[f0g. The algorithm has been proved terminating
and correct. And a slightly modiÔ¨Åed version of the algorithm
has been provided that returns all optimal solutions, thus
being complete. We have implemented the technique and
experiments show that it is more efÔ¨Åcient than all previous
algorithms.
Other important contributions are the proof that D&Q is not
optimal in the worst case as supposed, and the deÔ¨Ånition of
the Ô¨Årst optimal strategy for algorithmic debugging.
The implementation‚Äîincluding the source code‚Äîand the
experiments are publicly available at: http://users.dsic.upv.es/
jsilva/DDJ.ACKNOWLEDGEMENTS
This work has been partially supported by the Spanish
Ministerio de Ciencia e Innovaci ¬¥onunder grant TIN2008-
06622-C03-02 and by the Generalitat Valenciana under grant
PROMETEO/2011/052.
REFERENCES
[1] E. Av-Ron. Top-Down Diagnosis of Prolog Programs . PhD thesis,
Weizmanm Institute, 1984.
[2] B. Bra el and F. Huch. The Kiel Curry system KiCS. In Proc of 17th
International Conference on Applications of Declarative Programming
and Knowledge Management (INAP 2007) and 21st Workshop on
(Constraint) Logic Programming (WLP 2007) , pages 215‚Äì223. Technical
Report 434, University of W ¬®urzburg, 2007.
[3] R. Caballero. A Declarative Debugger of Incorrect Answers for Con-
straint Functional-Logic Programs. In Proc. of the 2005 ACM SIGPLAN
Workshop on Curry and Functional Logic Programming (WCFLP‚Äô05) ,
pages 8‚Äì13, New York, USA, 2005. ACM Press.
[4] R. Caballero. Algorithmic Debugging of Java Programs. In Proc. of the
2006 Workshop on Functional Logic Programming (WFLP‚Äô06) , pages
63‚Äì76. Electronic Notes in Theoretical Computer Science, 2006.
[5] R. Caballero, N. Mart ¬¥ƒ±-Oliet, A. Riesco, and A. Verdejo. A Declarative
Debugger for Maude Functional Modules. Electronic Notes in Theoret-
ical Computer Science , 238:63‚Äì81, June 2009.
[6] T. Davie and O. Chitil. Hat-delta: One Right Does Make a Wrong.
InSeventh Symposium on Trends in Functional Programming, TFP 06 ,
April 2006.
[7] V . Hirunkitti and C. J. Hogger. A Generalised Query Minimisation for
Program Debugging. In Proc. of International Workshop of Automated
and Algorithmic Debugging (AADEBUG‚Äô93) , pages 153‚Äì170. Springer
LNCS 749, 1993.
[8] D. Insa and J. Silva. An Algorithmic Debugger for Java. In Proc. of the
26th IEEE International Conference on Software Maintenance , 0:1‚Äì6,
2010.
[9] J. W. Lloyd. Declarative Error Diagnosis. New Gen. Comput. , 5(2):133‚Äì
154, 1987.
[10] W. Lux. M ¬®unster Curry User‚Äôs Guide (release 0.9.10 of may 10, 2006).
Available at: http://danae.uni-muenster.de/ lux/curry/user.pdf, 2006.
[11] I. MacLarty. Practical Declarative Debugging of Mercury Programs .
PhD thesis, Department of Computer Science and Software Engineering,
The University of Melbourne, 2005.
[12] L. Naish, P. W. Dart, and J. Zobel. The NU-Prolog Debugging
Environment. In A. Porto, editor, Proceedings of the Sixth International
Conference on Logic Programming , pages 521‚Äì536, Lisboa, Portugal,
June 1989.
[13] H. Nilsson. Declarative Debugging for Lazy Functional Languages .
PhD thesis, Link ¬®oping, Sweden, May 1998.
[14] B. Pope. A Declarative Debugger for Haskell . PhD thesis, The
University of Melbourne, Australia, 2006.
[15] E. Shapiro. Algorithmic Program Debugging . MIT Press, 1982.
[16] J. Silva. A Comparative Study of Algorithmic Debugging Strategies. In
Proc. of the International Symposium on Logic-based Program Synthesis
and Transformation (LOPSTR‚Äô06) , pages 143‚Äì159. Springer LNCS
4407, 2007.
[17] J. Silva. An Empirical Evaluation of Algorithmic Debugging Strategies.
Technical Report DSIC-II/10/09, UPV , 2009. Available from URL: http:
//www.dsic.upv.es/ jsilva/research.htm#techs.
[18] J. Silva. A Survey on Algorithmic Debugging Strategies. Advances in
Engineering Software , 42(11):976‚Äì991, 2011.