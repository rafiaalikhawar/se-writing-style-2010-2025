Automated Reliability Estimation over PartialSystematic ExplorationsEsteban Pavese Víctor BrabermanUniversidad de Buenos Aires{epavese,vbraber}@dc.uba.arSebastián UchitelUniversidad de Buenos Aires andImperial College Londonsuchitel@dc.uba.arAbstract—Model-based reliability estimation of software sys-tems can provide useful insights early in the development process.However, computational complexity of estimating reliability met-rics such as mean time to ﬁrst failure (MTTF) can be prohibitiveboth in time, space and precision. In this paper we present analternative to exhaustive model exploration–as in probabilisticmodel checking–and partial random exploration–as in statisticalmodel checking. Our hypothesis is that a (carefully crafted)partial systematic exploration of a system model can providebetter bounds for reliability metrics at lower computation cost.We present a novel automated technique for reliability estimationthat combines simulation, invariant inference and probabilisticmodel checking. Simulation produces a probabilistically relevantset of traces from which a state invariant is inferred. Theinvariant characterises a partial model which is then exhaustivelyexplored using probabilistic model checking. We report onexperiments that suggest that reliability estimation using thistechnique can be more effective than (full model) probabilisticand statistical model checking for system models with rarefailures.I. INTRODUCTIONModel-based automated veriﬁcation for assessing reliabilityof software systems aims to provide insights early in the devel-opment process that can reduce signiﬁcantly both developmentcosts, and costs associated with deploying unreliable software.However, traditional reliability metrics such as mean time toﬁrst failure (MTTF) require models that support describingprobabilistic, non-deterministic and timed behaviour; modelsfor which estimating such metrics can be prohibitive in time,space and/or precision.Model checking is emerging as an effective software ver-iﬁcation method. In particular, in the context of reliability,quantitative guarantees (on MTTF and other measures) can becomputed for complex models using the techniques developedin the area known as probabilistic model checking [1], [2].These techniques input probabilistic models (such as MarkovChains and Markov Decision Processes) and can assess quan-titative properties through exhaustive exploration of the modelstate space and subsequent numerical analysis.Applicability of probabilistic model checking for reliabilityassessment of complex models is threatened by the size ofthe model. Although state space reduction techniques exist,they may still fail to prevent state explosion on complexenough models. Further, even if the entire state space can beexplored, its size typically impedes exact numerical calculation(e.g. Gaussian elimination) of reliability metrics, so iterativemethods (such as Jacobi or Gauss-Seidel) that approximatemetrics must be used. However, these methods do not haveconvergence guarantees, and when they do converge theymay do so (intractably) slowly. The latter can be a problemfor reliability metrics of models with unlikely failures (e.g.probability of failure in a ﬁxed period below10−5), and canlead to iterations being cut short far from the actual value ofthe metric being estimated.In summary, although probabilistic model checking mayseem to promise exact calculation of quantitative reliabilityproperties, state space explosion and numerical methods can becomputationally prohibitive or result in poor approximations.Despite these limitations, probabilistic model checking canprovide bounds with 100% conﬁdence for reliability metricseven though the distance of these bounds to the real valuecannot be known.Numerical analysis and, to some extent, state explosion canbe avoided using statistical techniques. These apply statisticalinference over a ﬁnite set of sample executions extracted fromthe model. Variations of these approaches are usually referredto as Monte Carlo estimations. When using these techniquesto estimate metrics such as MTTF, the population meanXisapproximated through an estimator such as the sample meanX[3]. Of course, such estimation is subject to statistical errorand thus it is crucial to understand how far and how likely theestimator deviates from the actual mean.The deviations from the actual value that result from thespeciﬁc samples used is usually conveyed in terms of statisticalerrors and conﬁdence intervals. Bounds for statistical error andconﬁdence intervals can be computed based on the number ofsamples being analysed. Although signiﬁcant progress for fastgeneration of random walks over models has been made, sam-ple generation can be very costly timewise even for analyseswith modest guarantee requirements due to the sheer numberof samples required. For Monte Carlo reliability estimations,the length of samples can be particularly problematic, sincesampled executions must reach a failure in order to allowcomputing an estimator. This may make sample generationfor high-reliability systems intractable.In summary, statistical techniques can provide approxima-tions with measurable conﬁdence intervals and error bounds.However, in the presence of large models with rare failures,the number and length of samples may make such techniquesintractable or lose guarantees over results.978-1-4673-3076-3/13/$31.00 c2013 IEEE ICSE 2013, San Francisco, CA, USA602
In this paper we present an alternative to exhaustive modelexploration –as in probabilistic model checking– and partialrandom exploration –as in statistical model checking– whichmay counter some of the limitations of existing model-basedreliability veriﬁcation techniques. Our hypothesis, inspiredon the Pareto principle, is that a (carefully crafted) partialsystematic exploration of system models can provide goodbounds on reliability metrics with lower computation cost.More speciﬁcally, probabilistic model checking of a submodelof the system can bound the value of reliability metrics for thecomplete model in a cost effective manner. Furthermore, it canproduce better approximations, given equal time and memorybudgets, than probabilistic and statistical model checking.We hypothesise that there is a gain to be had by identi-fying a small probabilistically signiﬁcant portion of the statespace, considering all other states as failures and performingprobabilistic model checking on the resulting submodel. Theintuition is that, in contrast to full-model probabilistic modelchecking, performing a probabilistic check on a portion ofthe full model allows for faster iterations of the numericalanalysis methods. Consequently, more iterations can be per-formed within the same time budget and, for slowly convergingmodels, a better approximation may be achieved.More speciﬁcally, in this paper we present a novel auto-mated technique for MTTF estimation that combines simula-tion, invariant inference and probabilistic model checking. Weuse simulation to produce a set of traces that represent likelybehaviour of the full model. These traces are used to inferinvariants of the state space explored during the simulation.A submodel containing all states that satisfy the invariant isconstructed and its MTTF is computed using a probabilisticmodel checker.The technique we propose obtains lower bounds to realMTTFs with 100% conﬁdence (as full-model probabilisticmodel checking and in contrast to statistical model checking).Preliminary evidence shows that the lower bounds achieved(for a ﬁxed budget of time and memory) are higher thanthose obtained by full model probabilistic and stochasticmodel checking for models with rare failures. Furthermore,automated invariant generation seems to perform reasonablywell against domain-expert provided invariants.The remainder of the paper is organized as follows. Insection II we provide background. In Section III we describeour approach to the MTTF estimation. Section IV providescase studies illustrating the approach and comparing resultsto existing techniques. In Section V we present a discussionof our results and of related work. Finally we offer ourconclusions and discuss future work in Section VI.II. BACKGROUNDMean time to ﬁrst failure[3] is a widely accepted metric forsoftware reliability. The metric represents the time a client canexpect to operate a software system until it experiences its ﬁrstfailure. In order to calculate such a measure, practitioners basetheir efforts on afailure model[3], which describes conditionsunder which the component is known to fail. Most often, theseconditions are probabilistic in nature. This failure behaviouris usually modelled with a Markov chain.Deﬁnition 2.1 (Discrete Time Markov Chain):ADiscreteTime Markov Chain(DTMC) [4] is deﬁned by a tuple/angbracketleftS, s0, A, R/angbracketrightwhereS⊆V→Cis a ﬁnite set of states,deﬁned by mapping a ﬁnite set of variablesVto values ona ﬁnite subset ofZ,C.s0∈Sis the initial state.Ais aﬁnite set of action labels.R⊆S×(A∪{τ})×D(S)is thetransition relation where the transition target is deﬁned by adistribution on target states.Ris such that∀si∈S,∃!a∈(A∪{τ}),∃!µ∈D(S)such that(si,a ,µ)∈R. That is, thechoice of transition distributions is deterministic.Complex DTMCs can be built compositionally using paral-lel composition [4] to model components that run asynchro-nously but synchronise on shared actions.In order to assert intended properties of DTMC modelsseveral modal logics have been proposed. pCTL [5], a prob-abilistic extension of CTL, is widely used to describe modelproperties. pCTL formulae differ from CTL in that, insteadof predicating about properties that may hold globally or forsome execution paths, they aim at quantifying the probabilityof witnessing traces that satisfy a given property.Deﬁnition 2.2 (Traces and Probabilities):Given a DTMCM=/angbracketleftS, s0, A, R/angbracketright, anexecution traceonMis a nonemptyand possibly inﬁnite sequenceπ=s0p0−→s1p1−→s2..., suchthat for alli,si∈Sand there exists a unique(si,a ,µ)∈Rsuch thatµ(si+1)=pi>0. The probability induced bya ﬁnite pathπis given byPr(π,M)=/producttext0≤i≤length(π)pi,wherelength(π)is the number of transitions inπ. We notethe existence of a ﬁnite execution traceπfroms0tosnbys0π−→sn. We will denote the inﬁnite set of all possible tracesthroughMasΠ(M).Reward structures are used to convey some sense of valueto DTMC traces. For example, a transition reward structurethat assigns a value of 1 to each transition is a standard wayof deﬁning overall time steps cost for the traces of a DTMC.Deﬁnition 2.3 (Reward Structures):Given a DTMCM=/angbracketleftS, s0, A, R/angbracketright,atransition reward structureis a functionρ:S×A×S→R≥0.Given a traceπof a DTMCM, and a reward structureρoverM, thepath-rewardofπis the sum of the reward ofeach of its transitions. We will abuse notation and noteρ(π)to note the path-reward ofπbased on reward structureρ.We will noteΠSend(M)(whereSendis a set of states) torefer to the possibly inﬁnite set of all execution traces ofM,but where they have been pruned so that the last state of eachtrace is one of those inSend, and no other state inSendexistsin the trace before the end. Note thatΠSend(M)may containtraces of inﬁnite length (i.e., those that never reach a state inSendand therefore have not been pruned).Deﬁnition 2.4 (Mean time to ﬁrst failure):LetM=/angbracketleftS,s0, A, R/angbracketrightbe a DTMC,Sevent⊆Sbe a set of states fromMrepresenting failure states, andρa reward structure overMmodelling time passage on transitions. Let time to ﬁrstfailureTFbe a random variable onR≥0∪{+∞}such that theprobability of the time to failure being equal toxis deﬁned as603Pr(TF=x)=/summationtextπ∈ΠSend(M),ρ(π)=xPr(π,M). Themeantime to ﬁrst failure (MTTF)for failuresSeventinM, notedT(Sevent,M)is given by themathematical expectationof therandom variableTF.It is generally accepted to employexecution timerather thancalendar timefor MTTF estimations [3]. While calendar timemeasures real time in terms of hours, weeks, etc., executiontime is the time actually spent executing the software. Thisdistinction is important for reactive systems which may havelong idle times.III. APPROACHThis section formally deﬁnes an approach to computingbounds to MTTF of software models. The approach is basedon calculating MTTF for a partial systematic exploration of themodel’s state space. We ﬁrst deﬁne what is meant by a partialexploration and show that MTTF computed over these partialexplorations are guaranteed bounds to the MTTF of the entiresystem model. We then show how some partial explorationscan be speciﬁed declaratively through invariant properties thatdrive the exploration. Finally, we show how these invariant-driven partial explorations can be obtained automatically fromany given model, without need for human intervention.A. Partial ExplorationsWe refer to a partial exploration of a system model as asubmodel. Intuitively, a submodel of a DTMCMis a modelthat retains a subset of the states and transitions ofM–including and reachable from the initial state – and in whichall other states inMhave been abstracted away into a newλtrap state. Formally, a DTMC submodel is deﬁned as follows,wheresupp(µ)denotes thesupport setof the distributionµ,that is, the set of valuesxifor whichµ(xi)>0:Deﬁnition 3.1 (Submodels):Given a DTMCM=/angbracketleftS, s0,A, R/angbracketright,asubmodelofMis a DTMCM/prime=/angbracketleftS/prime∪{λ},s0, A, R/prime/angbracketrightsuch thatS/prime⊆S,s0∈S/prime, andR/prime⊆(S/prime∪{λ})×(A∪{τ})×D(S/prime∪{λ})is such that for alla∈A1) for each(λ,a ,µR/prime)∈R/prime, it must be the case thatsupp(µR/prime)={λ}anda=τ;2) for alls∈S/prime, for alla∈A∪{τ}, it must be that∃µR/prime∈D(S/prime∪{λ})such that(s, a, µR/prime)∈R/prime⇐⇒∃µR∈D(S∪{λ})such that(s, a, µR)∈R;3) for alls1,s2∈S/primesuch thats1/negationslash=λ, and for alla∈A∪{τ}it must be that∃µR/prime∈D(S/prime∪{λ})such that(s1,a ,µR/prime)∈R/prime∧s2∈supp(µR/prime)⇒∃µR∈D(S∪{λ})such that(s1,a ,µR)∈R∧µR(s2)=µR/prime(s2);4) for alls1∈S/primesuch thats1/negationslash=λ, and for alla∈A∪{τ}it must be that∃µR/prime∈D(S/prime∪{λ})such that(s1,a ,µR/prime)∈R/prime⇒∃µR∈D(S∪{λ})such that(s1,a ,µR)∈R·µR/prime(λ)=1−/summationtexts2∈supp(µR/prime)\{λ}µR(s2).Submodels are key to our approach since they conserva-tively approximate MTTF. That is, the MTTF of a modelMis always greater or equal to the MTTF of its submodels.Theorem 3.1 (Submodels bound MTTF):LetMandM/primebetwo DTMCs with state spacesSandS/primeand such thatM/primeis!"!#!$!%!&!'!(!)!*"+&'"+'"+&"+"'"+"'"+"'"+,$+""+"'"+,'"+'"+'
"+"'"+#'"+'$+""+%"+&'
"+#'$+"!$%!$$!$"!$&!,$+""+$'"+("+&$+"$+""+('Fig. 1. Example partial exploration of a state spacea submodel ofM. IfSf⊆Sare all the failure states inMthenT((Sf∩S/prime)∪{λ},M/prime)≤T(Sf,M).Proof:Note that, for every trace in the complete model, iteither exists completely in the submodel, or the submodel con-tains only a preﬁx that is extended by theλstate. Since rewardstructures are based on transitions, every trace in the full modelaccruesat leastas much reward to the failure state (possibly∞) as the corresponding trace (or preﬁx) in the submodel.Hence these preﬁxes contribute toT((Sf∩S/prime)∪{λ},M/prime)atmost what their extensions inMcontribute toT(Sf,M)The above result entails that if computing MTTF of a systemmodel is intractable, it can be conservatively approximated onany of its submodels.B. Automatic Submodel GenerationAlthough any submodel will provide a lower bound forMTTF, the key to a tractable reliability estimation technique isto identify a submodel for which its MTTF can be computedwithin a reasonable time budget, and for which the resultingbound is a reasonable approximation to the MTTF of the fullmodel. Of course, and independently of the fact that the MTTFfor the full model is unknown, this is a problem for whichcoming up with an exact solution (i.e. the “best” submodel)is intractable [6]. In this section we discuss a heuristic forautomatically constructing submodels that can provide betterbounds for reliability at lower computation cost than fullmodel checking and Monte Carlo approaches.Our approach adopts a heuristic based on the reasoningthat the submodel construction strategy should aim to identifya portion of the model that is probabilistically dense, thatis, a small submodel for which the probability of reachingtheλtrap state in a ﬁxed time is low. Such models willcontain probabilistically likely loops that delay the tracesfrom reaching the submodel boundary, hence contributing toa higher reliability bound.The problem of ﬁnding a probabilistically dense submodelis NP-hard. Our alternative approach attempts to approximatesuch a submodel through bounded simulation. Hence, wesimulate several traces over the full model. The resulting set ofﬁnite traces, if sufﬁciently large and consisting of sufﬁcientlylong traces, is likely to cover a good part of a probabilisticallydense submodel. These traces form the basis for building604our submodels. The smallest submodel that includes the setof states and transitions covered by the simulated tracescan be constructed easily by simply adding any non-visitedtransitions between any two visited states, abstracting all non-visited states into theλtrap state. Figure 1 shows sucha construction, where solid lines are transitions covered bythe simulated traces, and dotted lines are transitions in themodel that were not covered. States outside the boundaryhave not been covered, and would be abstracted away inthe submodel. However, such submodels are likely to haverelatively short traces that escape the submodel (see paths0,s2,s10,...in the ﬁgure). These short traces contributea relatively high probability of escaping the submodel (theshorter the preﬁx, the larger the probability of the set ofextended traces), reducing the submodel’s MTTF. Note thats10falls back within the boundary tos6with high probabilityand including it would increase the submodel’s MTTF. This isconsistent with our experimentation in [7] where we observedthat submodels generated with a breadth ﬁrst search strategytend to approximate reliability measures better.In our approach, rather than adopting a syntactic notion ofbreadth ﬁrst traversal for extending the submodel determinedby a simulation of the full model, we take a more semanticapproach based on the attributes of states visited during thesimulation. We compute state invariants based on the statesvisited during the simulation and then add to the submodelany states and transitions that satisfy the invariant. In this way,we expect to add behaviour that, although different to whatwas simulated, represents variations in terms of symmetries,race conditions, and independent events [8], and contributessigniﬁcantly to the probabilistic weight of the submodel.We now formally deﬁne our submodel construction method.We start with the notion of invariant of a set of traces.Deﬁnition 3.2 (Invariant):Given a DTMCM=/angbracketleftS, s0,A, R/angbracketright, and a set of ﬁnite execution tracesTobtained fromsaid model, aninvariantofMthroughTis a state predicateψon the variables ofMsuch that for every executiontracet=s0p0−→s1p1−→s2... sn∈T, it holds that∀0≤i≤n, si|=ψ.An invariant then induces a unique submodel as follows:Deﬁnition 3.3 (Invariant-driven submodels):LetM=/angbracketleftS,s0, A, R/angbracketrightbe a DTMC andψan invariant; aninvariant-driven submodelinduced byψis a submodelM/prime=/angbracketleftS/prime∪{λ},s0,A/prime,R/prime/angbracketrightofMsuch thata)each states/prime∈S/primeis suchthats/prime|=ψ;b)for eachs/prime1∈S/prime,s/prime1/negationslash=s0,s0π−→s/prime1; andﬁnallyc)for all statess/prime2∈S\S/primesuch that there exists/prime1∈S,(s/prime1,a ,µR)∈RwithµR(s/prime2)>0, it is the case thatM,s/prime2|/negationslash=ψ. In other words, if a states/prime2not in the submodel isdirectly reachable from a states/prime1in the submodel, it must bethe case thats/prime2violatesψ. The submodel is thus maximallyconnected from the initial state through the invariantψ.Our approach aims at automatically obtaining invariants. Tothis end, we produce probabilistically driven walks over thefull system model, recording the states (i.e. variable valua-tions) traversed. We use Daikon [9], an invariant inferenceengine, to obtain predicates that hold over all traversed states.IV. VALIDATIONIn this section we set out to answer three questions in orderto validate our approach.Q1: can our approach, when compared to model checkingover full explorations, produce higher bounds, in less time, forMTTF of system models with rare failures?Q2: can our approach, when compared to Monte Carloapproaches, produce higher bounds, in less time, for MTTFof system models with rare failures?Q3: how do the MTTF for submodels compare when thesesubmodels are generated from automatically inferred invariantsas in our approach against manually generated ones?Q1andQ2aim at comparing our proposal with establishedapproaches to reliability estimation, to evaluate if our approachcan complement existing techniques.Q3aims at assessing theadded value of automatic techniques for obtaining submodels.A. MethodologyFor each case study taken from the literature, we builtDTMC system models to describe behaviour, modelled failuresas state formulae, and deﬁned an appropriate reward structure.We used the same input for all MTTF estimation techniques.We ran our approach for all case studies for several automat-ically generated invariants varying the number and length oftraces used for invariant inference. We used Daikon v4.6.4[9]conﬁgured to produce invariants that are conjunctions of termsof the formx∼y, wherexandyare either variables inthe model, or integer constants, and∼∈{<,≤,=,≥>}. Theinvariants we obtained were used to automatically build anobserverO, a DTMC that monitors the validity of the invari-ant. This observer, when composed with the system modelM, synchronises with all actions and forces transitioning intotheλtrap state whenever the destination state of the intendedtransition would result in an invariant violation.ForQ1we used a modiﬁed version of PRISM v4.0.3 [10] toperform probabilistic model checking to estimate MTTF bothfor the full state space and for its invariant-driven submodels.Modiﬁcations allow for batch trace generation (used for in-variant inference) and time and memory-use tracking (used forgenerating intermediate MTTF results and for timing out whentime budget is up). Intermediate MTTF results were generatedfor visualising convergence rates. PRISM was deployed on an8x Core Intel Xeon CPU @1.60 GHz with 8GB RAM.PRISM provides different numerical methods for rewardcalculation. We compared computation of MTTF of the fulland partial explorations for the Jacobi, Gauss-Seidel andPower methods, as well as several optimisations over theJacobi and Gauss-Seidel methods. Due to space limitations, weonly report on results obtained with the backwards variation ofthe Gauss-Seidel method (BGS), which proved to be the mosteffective method for full model probabilistic model checkingin terms of bounds obtained for time budget.PRISM runs were considered complete when any of the fol-lowing criteria held: eithera)theabsolutedifference betweenresults of successive iterations of the numerical method wasless than 0.01 (relative differences are not adequate because of605slow convergence, which causes iterative methods to cut tooearly). Alternatively,b)running time reached 24 hours; orc)memory was exhausted. Note that the time measured includesonly the execution of the numerical methods. This allows forconvergence analysis and favours full-model exploration asthe time spent on construction of the model state space isnot considered (we comment on execution time for submodelgeneration later in the Experimental Results subsection).ForQ2Monte Carlo simulations were generated usingthe same version of PRISM and the same hardware asQ1.However, note that while our approach produces lower boundsto MTTF with 100% conﬁdence but for which precision(percentual difference between the estimation and the actualvalue) is unbounded, Monte Carlo produces estimations withvarying degrees of conﬁdence but for which precision can bebounded. Consequently, we performed statistical model checksfor a range of conﬁdence and precision values.For Monte Carlo approaches to be successful, all randomlygenerated traces must eventually fail, and enough traces mustbe generated in order to guarantee estimations with a ﬁxedprecision and conﬁdence. Setting a trace length horizon forthe simulator to ensure all traces fail is typically done basedon an estimation of the MTTF. We used the MTTF estimationsobtained inQ1to set this horizon for each case study.In addition to comparing probabilistic model checking ofsubmodels against Monte Carlo simulations of the completemodel, we compared probabilistic model checking againstMonte Carlo simulations over the same submodels.Finally,Q3uses the same setup and MTTF estimationapproach based on automatically inferred invariants as inQ1.Manually produced invariants for submodel generation wereput forth before any of the experiments were performed.Hence the manually proposed invariants were not tainted byknowledge gained from the automatic approach. The mainheuristic for coming up with the invariants was the use ofof necessary (and more likely) conditions for failures.B. Case StudiesTandem Queueing Network:The ﬁrst case study is a tandemqueueing network, based on [11]. Queueing systems have beenextensively studied in queueing theory, and analytical solutionsfor some variants exist. In the case of this model, generalqueueing models do not apply. Generating an ad-hoc analyticalformulation would require extensive expertise and time.The system consists of two process queuesCandMofgiven capacities. Clients queue processes for execution in theﬁrst queue while it is not full. The queue may either route aprocess to the second queue after a probabilistically chosentime elapses, or it might choose to deal with the requestitself. The behaviour of this ﬁrst queue is governed by twodifferentphases; the difference between the phases is givenby the probability with which it will choose to route to thesecond queue or deal with requests. The second can serviceits requests after a probabilistically chosen time elapses. Afailure is observed when both queues are full. The capacityof the queues is ﬁxed at 1200 each. Clients are less inclined(i.e., they take more time in average) to enqueue processes asthe free capacity of the queues decreases.The reliability metric to be estimated is the mean operationaltime until the ﬁrst failure. Consequently, the reward structureρassigns the value1to every timing transition. The state pred-icate that captures failure iscliC= 1200∧cliM= 1200andcomputing the metric amounts to calculating the expectationof the accumulated reward before reaching a state satisfyingthe state predicate.Bounded Retransmission Protocol:The second casestudy [12] models a robust communication protocols thatattempts to ensure delivery of data, the bounded retransmissionprotocol (BRP) [13].BRP is a variant of the alternating bit protocol, which allowsfor a bounded number of retransmissions of a given chunk (i.e.,a part of a ﬁle). The protocol consists of a sender, a receiver,and two lossy channels, used for data and acknowledgementsrespectively. The sender transmits a ﬁle composed of a numberof chunks, by way offrames. Each frame contains the chunkitself and three bits. The ﬁrst bit indicates whether the chunk isthe ﬁrst one; the second one if it is the last chunk; and the thirdbit is the alternating one, used for avoiding data duplication.The sender waits for acknowledgement of each frame sent.The sender may timeout if either the frame or the corre-sponding acknowledgement are dropped. When this happens,the sender resends the frame and does so repeatedly up to aspeciﬁed retry limit. If the limit is reached and the transmissionis terminated, the sender may be able to establish that theﬁle was not sent (if some chunks were left unsent) or itmay not know the outcome (if the last frame was sent butno acknowledgement was received). In any case, the sendermay send a new ﬁle, resetting the retry count. A maximum of256 retransmissions are attempted per ﬁle before the sendergives up and aborts transmission of the ﬁle. Once a ﬁle issent successfully or its transmission fails, the system waits foranother ﬁle to be sent.Protocol clients send ﬁles one at a time. Each of these ﬁles isof a different size (in number of chunks). The size is selectedprobabilistically for each ﬁle, between just a few and 1500chunks. Exceedingly large or small ﬁles are modelled to beless likely to be sent than those of average size.We wish to estimate the mean time to the ﬁrst failure, wherefailure is deﬁned as the sender failing to send a completeﬁle (incomplete) or not being able to establish if a ﬁle wassent successfully (unknown). Consequently, the state predicatedescribing failures isincomplete∨unknown. The deﬁnitionof time for this case study aims at establishing how many datapackets can be expected to be sent successfully before failure.C. Experimental ResultsWe now present some of the experimental results obtainedfor the three research questions presented above. The modelsused and complete experimental results can be found athttp://lafhis.dc.uba.ar/~epavese/ICSE13.Question 1:When comparing probabilistic model checkingof both full and partial models we are interested in considering606 0 5000 10000 15000 20000 25000 30000 35000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 1 10 100 1000 10000 100000 1e+06 1e+07 1e+08Estimated MTTF(operational time)Tandem Queue MTTF estimation
Submodel size(states)Verification time(seconds)Estimated MTTF(operational time)
Fig. 2. Results of analysis of Tandem Queue for different sized submodels,Backwards Gauss-Seidel method.
 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 0 5000 10000 15000 20000 25000 30000 35000Submodel size(states)Tandem Queue submodel sizes
Sample size(number of traces)Trace lengthSubmodel size(states)
 0 5000 10000 15000 20000 25000 30000 35000
Fig. 3. Tandem Queue submodels sizes for different sample size and tracelength parameters.TABLE ISELECTION OFTANDEMQUEUE SUBMODEL SIZES AND INV ARIANTS FORDIFFERENT PARAMETER CONFIGURATIONS.Traces Length StatesInvariant10000114cliC=cliM∧cliC≤0∧state≤2∧cliC≤state1000050112690cliC≤73∧cliM≤15∧state≤950001000 14134cliC≤69∧cliM≤18∧state≤910000 1000 16086cliC≤83∧cliM≤17∧state≤950002000 23388cliC≤100∧cliM≤21∧state≤910000 2000 22486cliC≤92∧cliM≤22∧state≤950003000 20932cliC≤98∧cliM≤19∧state≤910000 3000 25228cliC≤108∧cliM≤21∧state≤950004000 24538cliC≤105∧cliM≤21∧state≤910000 4000 24882cliC≤94∧cliM≤24∧state≤950005000 26424cliC≤104∧cliM≤23∧state≤910000 5000 23686cliC≤97∧cliM≤22∧state≤950006000 26182cliC≤99∧cliM≤24∧state≤910000 6000 31902cliC≤121∧cliM≤24∧state≤950007000 29926cliC≤123∧cliM≤22∧state≤910000 7000 30674cliC≤121∧cliM≤23∧state≤950008000 23910cliC≤107∧cliM≤20∧state≤910000 8000 29424cliC≤116∧cliM≤23∧state≤950009000 29924cliC≤118∧cliM≤23∧state≤910000 9000 29926cliC≤123∧cliM≤22∧state≤95000 10000 27174cliC≤107∧cliM≤23∧state≤910000 10000 27460cliC≤100∧cliM≤25∧state≤9the impact between the inferred invariant, the resulting sub-model’s size and the value of the MTTF estimation obtainedfrom it. We are also interested in gaining insight on combi-nations of trace length and number that are likely to yield thebest overall result.For the Tandem Queue case study the estimated MTTFcalculated in 24 hours over the full model was4.20×105.The full model comprises∼1.5×107states. Regardingcomputations over submodels, we report on MTTF estimation(Figure 2), submodel sizes (Figure 3) and invariants obtained(Table I) for various settings of numbers and lengths of traces.Note that we report here on a subset of the values obtained,however non-reported data is in-line with the trends shown.The ﬁrst ﬁgure shows, for different automatically generatedsized submodels, the estimated MTTF (over a logarithmicscale) along with how much time it took for the calculation toﬁnish. Executions that ﬁnished before the 24 hour timeout areﬂattened on the MTTF axis at the time the result was reached.It is noteworthy that none of the automatically obtainedsubmodels is larger than35000states, comprising roughly0.25%of the states of the complete model. Despite havingexplored only such a small percentage of the full model,the obtained lower bound for MTTF is quite large in somecases, possibly sufﬁcient to argue for high system reliability– MTTF isat leastin the order of1.0×107. Although verysmall submodels do not provide good bounds, larger submodelMTTF estimations increase dramatically, quickly rising to the7×107maximum MTTF witnessed, which is a full two ordersof magnitude beyond the estimation for the full model.An important question is if good submodels can be ob-tained in a consistent fashion regarding trace quantity andlength parameters of the simulation phase. Figure 3 showsthat such submodels are easily attainable for this example.Experiments with trace length below3000do not consistentlyproduce rich enough models that yield good MTTF estimates.Unsurprisingly, small sample sets are also inconsistent in theirresults. However, once the sample set size parameter is set toat least6000samples, the submodels produced consistentlyyield large MTTF estimates. In summary, for this case studya minimum of6000samples of traces at least4000steps longare necessary for consistent results. Furthermore, increasingthese parameters does not yield clear advantage in terms ofthe ﬁnal MTTF estimation. Both ﬁgures also show that resultsbecome more stable as these parameters are increased.State space size alone is not the only important factorwhen evaluating the effectiveness of the approach. For agiven size, many submodel of that size exist, and not allof them may be effective. Preliminary work [7] has shownthat submodels obtained through depth ﬁrst search (DFS)explorations yield very poor results. Although breadth ﬁrstsearch (BFS) obtains higher MTTF lower bounds than DFSwhen used as a submodel generator, it performs poorly againstour approach, as the state space that it explores is not asrelevant. For example, our approach using10000traces10000states long (one of the best performers) obtains a27460state sized submodel, which is characterised by the invariantcliC≤100∧cliM≤25∧state≤9. Consider a similarlysized BFS generated submodel of28000states. The TandemQueue model allows four different actions (push, fwd, svc1,svc2). Conservatively assuming at most two actions enabledat each state, an equal sized BFS submodel would explore atmost⌈log2(27460)⌉= 15levels deep. Such a submodel wouldonly allow for very limited behaviour. If each transition levelgenerated a new state, queues of no more than 15 elementscould be generated by such a submodel. Of course, it is notalways the case that a new state is generated. In fact, a BFSexploration that allows for 50 elements per queue results ina32000state submodel. The MTTF obtained through such asubmodel is∼70000, very far from the results we obtain.Regarding potential overhead of trace generation and invari-ant inference, memory consumption is negligible with respect607 0 100000 200000 300000 400000 500000 600000 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 1 10 100 1000 10000 100000 1e+06 1e+07 1e+08Estimated MTTF(packages sent)BRP MTTF estimation
Submodel size(states)Verification time(seconds)Estimated MTTF(packages sent)
Fig. 4. Results of analysis of BRP for different sized submodels, BackwardsGauss-Seidel method.
 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 0 100000 200000 300000 400000 500000 600000Submodel size(states)Tandem Queue submodel sizes
Sample size(number of traces)Trace lengthSubmodel size(states)
 0 100000 200000 300000 400000 500000 600000
Fig. 5. BRP submodels sizes for different sample size and trace lengthparameters.to representing the state space of the full model, as only onerelatively short trace needs to be kept in memory at a time.Timewise, analysis of10000traces of length10000took lessthan an hour. Accounting for this hour in the veriﬁcation timebudget, the submodel that yielded the highest MTTF lowerbound would have achieved a result of∼6×107in 23 hours.Although not intended to be shown to developers, we reporton some of the automatically inferred invariants in Table I.The discovered invariants deal with bounding the size of bothqueues, while the variablestateencodes whether the queuesare full or not, and the phase the system is in at the time. It isnoteworthy that although it is intuitive that an invariant shouldbound the queue sizes, it is unlikely that a human would comeup with the particular bounding values used.For the BRP case study similar results were obtained andare shown in Figures 4 and 5, and Table II.In contrast to the prior case study, we were unable to obtainthe MTTF for the full model due to state explosion thatexhausted available memory. However, observations prior torunning out of memory showed that the full model containsat least30million states, which means that the submodelsanalysed represent at most2%of the size of the full model,still a very low percentage. Furthermore, the highest MTTFbounds were obtained for submodels starting from400000states (less than1.33%of the full model) yielding an MTTF inthe order of2.5×107. This result is most signiﬁcant, becauseof the impossibility of estimating MTTF for the full model.Note that around the400000and500000states mark, thereare both estimations that provide very good bounds and thosethat yield not so useful ones. Interestingly, those that do notperform well arise from submodels obtained through invariantsinferred from sets of traces shorter than7000states long,while sets of longer traces perform very well. This showsthat appropriate trace length is critical to the ﬁnal MTTFestimation. As before, a similarly sized submodel obtainedthrough BFS does not provide such higher MTTF lowerbounds. One of our best performers, at10000traces10000states long, produces a submodel392786states in size which(with eight BRP actions and conservatively assuming threeenabled at any time) results in a BFS submodel of depth⌈log3(392786)⌉= 12, which models very few frames beingsent. In fact, a BFS-like submodel that allows only for5framesto be sent per ﬁle comprises∼400000states and yields anMTTF of only40.Figure 5 depicts information related to the possibility ofobtaining useful submodels. It can be seen that it is quiteeasy to obtain such submodels, without many restrictions onexperiment conﬁguration. In fact, the conﬁgurations for thiscase study behave much more steadily than with that of theTandem Queue. Sets of4000traces of at least7000states seemto be enough for obtaining good estimates. Further increasesof these parameters yield larger and slightly better-performingmodels, and this increase is much smoother (hence predictable)than is the case for the Tandem Queue submodels.As in the other case study, trace generation and invariantinference incurs an overhead. In this case, since the model ismore complex, this analysis can take up to 2 additional hours.Reducing the veriﬁcation time by these 2 hours, the estimatedMTTF would have been still large, about2×107. Recall thatthis overhead was not included in measured time to allowgraphs to show convergence speed of numerical analysis.As before, we show for reference some of the inferredinvariants. The variablesfileSize,iandnrtrdescribe thesize of the ﬁle being sent, how many frames have been sentfor that ﬁle, and the number of retries attempted, respectively.Other variables such assab,rab,bsandfsencode the bitalternation in the protocol. The invariants obtained establishrelationships between variables that seem unrelated, makingthem quite unintuitive even for a domain expert.What both case studies and experiments indicate is that,through careful partial exploration of the model, we can obtainuseful bounds for MTTF estimation with very low percentages(<1.5%) of actual state space exploration. Further, submodelsthat yield these results also converge very quickly (muchbefore the 24 hour timeout) to good MTTF results. Whilethe estimation does constantly improve during the rest ofthe 24 hours, it does so at a slower pace. This is goodnews, as even with the trace analysis overhead, good MTTFresults can still be attained under the same time budget. Fromthese results it follows that, for these case studies, effort intoestimating MTTF through automatically obtained submodelsthrough model invariants of the full model pays off.It must be noted that it is possible that theactualMTTFis much larger than any of those obtained. Of course, weare always limited by the fact that the actual MTTF cannotbe calculated, neither with partial nor full models. It can be608TABLE IISELECTION OFBRPSUBMODEL SIZES AND INVARIANTS FOR DIFFERENT PARAMETER CONFIGURATIONS.Traces Length StatesInvariant10000135srep=nrtr∧srep=fileSize∧srep=r∧srep=rrep∧srep=k∧srep=l∧bs=s_ab∧bs=fs∧bs=ls∧bs=fr∧bs=lr∧bs=br∧bs=r_ab∧bs=recv∧s≤7∧srep≤0∧i≤1∧s≥srep∧s≥i∧srep≤i1000050166282s≤7∧srep≤3∧nrtr≤2∧fileSize≤1500∧i≤84∧r≤4∧rrep≤3∧k≤2∧l≤2∧s≥k∧s≥l∧srep≤fileSize∧srep≤i∧srep≤r∧srep≤rrep∧nrtr≤fileSize∧nrtr≤i∧fileSize≥r∧fileSize≥rrep∧fileSize≥k∧fileSize≥l∧r≥l 10000 5000 333099s≤7∧srep≤3∧nrtr≤2∧fileSize≤1500∧i≤833∧r≤4∧rrep≤3∧k≤2∧l≤2∧s≥k∧s≥l∧srep≤fileSize∧srep≤i∧srep≤r∧srep≤rrep∧nrtr≤fileSize∧fileSize≥r∧fileSize≥rrep∧fileSize≥k∧fileSize≥l∧r≥l 10000 10000 392786s≤7∧srep≤3∧nrtr≤2∧fileSize≤1500∧i≤1500∧r≤4∧rrep≤3∧k≤2∧l≤2∧s≥k∧s≥l∧srep≤fileSize∧srep≤i∧srep≤r∧srep≤rrep∧nrtr≤fileSize∧nrtr≤i∧fileSize≥r∧fileSize≥rrep∧fileSize≥k∧fileSize≥l∧r≥largued, though, that it is often the case that the exact MTTFvalue is not needed as such; rather, satisfying a minimumdegree of reliability is a sufﬁcient guarantee. Hence, methodswhich provide higher lower bounds faster are useful.Question 2:Experimentation to answer this question is notstraightforward due to the problem of generating sufﬁcientfailing simulations to ensure given precision and conﬁdenceparameters. We ﬁrst aimed at performing a straightforwardstatistical analysis of the model. A ﬁrst experiment wasdesigned requiring a result precision of99%. As is standardfor statistical analyses, we also required a95%conﬁdence.A straightforward calculation of the necessary sample sizebased on the Chernoff bound [14] determines that a totalof∼60000samples are necessary, which does not seemexcessive. However recall that each sample must eventuallyfail. For systems with rare failures, this means that samplesmay be extremely long. Through trial and error, and based onthe bounds obtained inQ1, we tried to determine the minimumlength for samples to consistently reach failure states. For theTandem Queue full model, even samples as long as4×108do not consistently fail. Considering that generating a sampleof such length takes 15 minutes, generation of the full60000traces required leads to a 2 year period for sample generation.A similar situation is found upon analysis of the BRP model.Relaxing the precision requirement to95%reduces thesample generation cost to 1 month. Further relaxation to90%still requires a week of execution. In fact, if we were to set a24 hour budget for sample generation, the precision obtainedwould be70%. That is, the MTTF estimate would be up to±30%away from the true MTTF value with a95%guarantee.Note that this is a very conservative estimate as it is unlikelythat all traces of length4×108generated in the 24 hourperiod will consistency reach failure states, and possibly muchlengthier traces will be needed.To overcome this limitation of standard Monte Carlo veriﬁ-cation, we tried a variation of Wald’s sequential testing [15].This procedure generates samples while at the same time itdetermines whether more samples are necessary or not. As aresult of this online estimation, it might require less samplesthan those mandated by the Chernoff bound, although itcannot be stated beforehand how many samples will be neededexactly. This optimization does not eliminate the need forsamples to reach property-determining states, so sample lengthremains a problem. We attempted to perform this analysistruncating generated samples at length4×108and treatingthem asfailingsamples once they reached this threshold. Thisis a similar strategy as the one used in our approach (anythingbeyond the submodel is a failure). However, this procedureyielded no results after 24 hours of execution, indicating thatthe sequential testing still needed more evidence.Furthering this strategy of over-approximation of failuresin Monte Carlo veriﬁcation, we generated samples over thesubmodels with highest MTTF obtained inQ1rather thanthe full model. However, the problem of producing samplesthat consistently fail persisted, failing to provide an MTTFin the budgeted time. These results suggest that Monte Carloapproaches may be unsuitable to answer reliability questionsin systems with high MTTF (i.e., rare failures).Question 3:In this section, we compare the results obtainedwhile answeringQ1with the results a practitioner might obtainby specifying invariants herself, based on her knowledge ofthe model. Prior to experimenting on automatically generatedinvariants, we analysed the models and came up with at leastone invariant for each one. These invariants were selectedbased on our understanding that their negation is a necessarycondition for failure.For the Tandem Queue case study, we established theinvariant to be that the total number of enqueued processesglobally in both queues is less thanc, and ran experiments fordifferent values ofcranging up to the total capacity of thequeueing system (2×C). A failure entails that the invariantdoes not hold forc<2×C, and that forc=2×Cthe resultinginvariant-driven submodel is exactly the whole model. In ourexperiments we found that there where multiplecvalues forwhich the invariant resulted in a signiﬁcantly higher MTTFthan the MTTF estimated for the full model. In Table III resultsare presented for various invariant-driven submodel parametervalues together with estimated MTTF and computation timeusing the BGS method.From the table it follows that the best MTTF is obtainedfor the submodel which considers up to 120 processes queued(MTTF>5.5∗107).In the case of the Bounded Retransmission Protocol casestudy, a parametric invariant chosen was that the number ofretries performed while transmitting a single ﬁle was lessthanmaxretries. We ran experiments for different values ofmaxretriesranging up to the true maximum number of retries(256). A failure entails that the invariant does not hold formaxretries<256. Forretries=maxretriesthe resultinginvariant-driven submodel is the whole model.Again, we show a selection of submodels, ranging from thevery small upwards to almost the complete model. Results forthese experiments are depicted in Table III.Estimation results are even more signiﬁcant than for theprevious case study considering that analysis of the full modelwith 256 retries was not possible within the memory budget.609TABLE IIIEXPERIMENTAL RESULTS FOR TANDEM QUEUE(2×1200PROCESSES)ANDBRP (256RETRIES)MEAN TIMES TO FIRST FAILURE TIMES.cSizeBGSMTTFTime202398 st0.83·10368.75 s6560 tr408778 st1.12·10482.72 s24280 tr6019158 st1.25·105276.69 s53200 tr8033538 st1.36·10664.06 m93320 tr10051918 st1.49·10717.93 h144640 tr12074298 st5.50·107TO207160 tr140100678 st4.63·107TO280880 tr160131058 st3.17·107TO365800 tr180165438 st2.31·107TO461920 tr200203818 st1.66·107TO569240 tr9004067118 st8.41·105TO11381440 tr160011219198 st4.20·105TO31407194 tr240014362898 st4.20·105TO40213194 trretries SizeBGSMTTF Time1366915 st1.50·10621.06 h489574 tr2480460 st1.69·107TO646758 tr5821095 st1.08·107TO1118310 tr101388820 st6.29·106TO1904230 tr505930620 st1.39·106TO8191590 tr15017285120 st4.86·105TO23909990 tr25028639620 st2.73·105TO39628390 tr256N/A stN/AOOMN/A trHowever, the trend indicates that augmenting the number ofretries considered does not yield better MTTF and in fact, avery low number of retries gives a much higher MTTF.It is interesting to note that for relatively small submod-els (e.g.c= 80on the Tandem Queue case study, andmaxretries<2for BRP) the estimated MTTF is much higherthan the MTTF computed over the complete model.Still, while the manual invariant approach did provide usefulbounds, it turns out that the best MTTF values generatedby the automatic approach obtains slightly higher boundsfor the same time budget. For the Tandem Queue study, thebest automatically estimated MTTF is of∼7×107against∼5.5×107. For the BRP case study the best automaticestimation is∼2.5×107versus∼1.69×107when manualintervention is applied.V. DISCUSSION ANDRELATEDWORKWe have presented a fully automated technique for MTTFestimation of system models. Experimental results have shownthat this approach may provide more useful MTTF estimationsthan both standard probabilistic model checking and MonteCarlo veriﬁcation. However, two parameters exist that need tobe set for the approach to work–the size of the simulationset and the length of the simulated traces. Good news isthat our experimentation has shown that, at least for theexamples studied, very good results can be obtained throughrelatively small set of short traces. Although the elaborationof guidelines on how to set the number and length of tracesis beyond the scope of this paper, results show that theremay be a broad combination of parameter values for whichhigh MTTF results are obtained in reasonable time. Further,overshooting these parameters does not have an dramaticimpact in the resulting submodel size. It is important to notethat exploration of an appropriate parameter space can be doneconcurrently, taking as the ﬁnal MTTF estimation the highestof the bounds obtained. Full model probabilistic checkingcannot exploit concurrent computation in such a way. MonteCarlo veriﬁcation can be applied concurrently, however webelieve that the signiﬁcant time cost for sample generationwould not be outweighed by concurrent execution; furtherexperimentation is needed to address this point.As was previously mentioned, most probabilistic modelcheckers [16], [10], [17], [18] provide functionality that mayeither reduce the time required to obtain results, or reduce thememory footprint required for veriﬁcation, such as symmetryreductions [19],lumping[20] and several numerical methods.All these optimizations are orthogonal to the model check-ing procedure itself. Our work relies on probabilistic modelchecking and the experiments were run on PRISM, whichimplements some of these optimizations.Monte Carlo veriﬁcation of models where the requiredsize or veriﬁcation time have determined exhaustive modelchecking to be intractable, statistical simulation has proven tobe an effective technique. As was mentioned in section IV,an important issue with simulation approaches is that theytend to work well mostly in the case that the speciﬁedproperties are bounded in time, i.e. when these propertiescan be written in the formψU≤Tρfor a ﬁxedT. This isso because estimation of the random variableXφby meansof a sample of tracesσirequires that the question of whetherM,σi|=φor not be answered in a deﬁnite way for eachtraceσiin the sample set. If the formulaφis temporallybounded, then termination is guaranteed when evaluating itstruth for the traces, but for temporally unbounded formulaesuch termination is threatened.In such cases, generating traces with acceptable lengthbounds that answer the property deﬁnitively can be veryunlikely. To address this problembiased sampling[21], [22],[23], [24] has been studied. However, bias to sampling must bedone manually resulting in an impact on the analysis resultsthat cannot be quantiﬁed in general. The result obtained byour approach is guaranteed to be a true bound to MTTF.Recent work by Younes et. al. [25] proposes two novelMonte Carlo approaches that do not rely on biased sampling.However, one of them may require an inordinate numberof samples to produce results; while the other relies onreachability analysis, which requires the full model to beconstructed, relinquishing one of the key advantages of MonteCarlo model checking over probabilistic model checkingIt should also be noted that Monte Carlo approaches aretypically inadequate for models that exhibit non-determinism.A workaround is to transform non-determinism into a proba-bilistic choice, introducing bias. We believe that our proposedapproach can be straightforwardly adapted to be applied tonon-deterministic DTMCs. This remains future work.The analysis of system behaviour that exhibitsrareyet rele-vant (e.g. failures) events is the subject of focused study withinthe simulation community as well. A technique that is usuallyused in conjunction with stochastic processes that have rareevents is that ofimportance sampling[26]. Roughly speaking,the idea of importance sampling is to replace the originalprocess’s distribution for another more likely to generatethe (originally) rare event during the sample generation. Thedistribution replacement is chosen so that results from analyses610for the new distribution can be translated back to results validfor the original distribution. Although a promising approach,ﬁnding suitable replacement distributions is a complex and ad-hoc task for which further research and expertise is necessary.Another promising simulation technique that also focuseson rare-events is that ofsample splitting, most notably theRESTART implementation [27] which, roughly, rather thanstarting each simulation from the initial state, it does so froma statesvisited in a previous simulation and from whichreaching a rare-event is more likely. The likelihood of reachingstatesfrom the initial state is taken into account for producingthe ﬁnal analysis results. Key to the application of thesetechniques is making appropriate decisions on where to restartsimulations; these decisions demand deep understanding ofboth the model and the underlying splitting technique.Finally, common to both the Monte Carlo approach andthe simulation techniques discussed is the fact that they areinherently statistical results. As such, there is always a nonzeroprobability that the results obtained are completely off themark. Further reducing this error probability may requireexcessive amount of additional traces to be sampled in orderto obtain the guarantee. Our technique, though conservative inthe bounds it obtains, is deﬁnitive in its answers.VI. CONCLUSIONS ANDFURTHERWORKIn this paper we have proposed an approach to reliability es-timation of system models. The approach is a novel combina-tion of simulation, invariant inference and probabilistic modelchecking. We report on experiments that suggest that reliabilityestimation using this technique can be more effective than (fullmodel) probabilistic and statistical model checking for systemmodels with rare failures.We believe the notion of reliability analysis over partialyet systematic explorations offers an alternative to, and hencecomplements, exhaustive model exploration–as in probabilisticmodel checking–and partial random exploration–as in statisti-cal model checking.We believe the experimental results presented in this paperare promising. However further experimentation is due. Inaddition, this work opens up two fronts that need to befurthered to develop more effective reliability estimation ap-proaches. One front is generalising the approach to supportestimation of other properties related to stochastic behaviour.In addition, the generalisation of the kinds of models for whichthis technique can be applied is also of interest (e.g. MarkovDecision Processes, that extend Discrete Time Markov Chainsby introducing nondeterminism).Additionally, another area that calls for future work is betterunderstanding the relationship between the simulated set oftraces (both its size as the trace length) and the submodels thatresult from them. This understanding should lead to heuristicsfor setting appropriate values to these parameters.ACKNOWLEDGEMENTSThis work was partially supported by grants PICT 2272,PIP 0955, UBACYT W0813, ERC StG PBM-FIMBSE andMEALS 295261.REFERENCES[1] M. Vardi, “Automatic veriﬁcation of probabilistic concurrent ﬁnite stateprograms,” inSFCS 1985. IEEE, Oct. 1985, pp. 327–338.[2] A. Bianco and L. De Alfaro, “Model checking of probabilistic andnondeterministic systems,” inFoundations of Software Technology andTheoretical Computer Science. Springer, 1995, pp. 499–513.[3] M. R. Lyu,Handbook of software reliability engineering. Hightstown,NJ, USA: McGraw-Hill, Inc., 1996.[4] R. Segala, “Modelling and veriﬁcation of randomized distributed realtime systems,” Ph.D. dissertation, Massachusetts Institute of Technology,1995.[5] A. Aziz, V. Singhal, F. Balarin, R. Brayton, and A. Sangiovanni-Vincentelli, “It Usually Works: The Temporal Logic of StochasticSystems,”Lecture Notes in Computer Science, pp. 155–155, 1995.[6] L. Jamieson and B. Dean, “Weighted alliances in graphs,”CongressusNumerantium, vol. 187, p. 76, 2007.[7] E. Pavese, V. Braberman, and S. Uchitel, “My model checker died!: howwell did it do?” inQUOVADIS/ICSE’10. ACM, 2010, pp. 33–40.[8] C. Baier and J. Katoen,Principles of model checking. MIT press, 2008.[9] M. D. Ernst, J. H. Perkins, P. J. Guo, S. McCamant, C. Pacheco, M. S.Tschantz, and C. Xiao, “The Daikon system for dynamic detection oflikely invariants,”Sci. Comput. Program., vol. 69, no. 1-3, pp. 35–45,Dec. 2007.[10] A. Hinton, M. Kwiatkowska, G. Norman, and D. Parker, “PRISM: Atool for automatic veriﬁcation of probabilistic systems,” inTACAS’06Proceedings, vol. 3920. Springer, 2006, pp. 441–444.[11] H. Hermanns, J. Meyer-Kayser, and M. Siegle, “Multi terminal binarydecision diagrams to represent and analyse continuous time Markovchains,” inProc. NSMC’99. Prensas Universitarias de Zaragoza, 1999,pp. 188–207.[12] P. D’Argenio, B. Jeannet, H. Jensen, and K. Larsen, “Reachabil-ity analysis of probabilistic systems by successive reﬁnements,” inPAPM/PROBMIV, ser. LNCS, vol. 2165. Springer, 2001, pp. 39–56.[13] L. Helmink, M. Sellink, and F. Vaandrager, “Proof-checking a data linkprotocol,” inProc. International Workshop on Types for Proofs andPrograms (TYPES’93), ser. LNCS, vol. 806. Springer, 1994.[14] H. Chernoff, “A measure of asymptotic efﬁciency for tests of a hypothe-sis based on the sum of observations,”Annals of Mathematical Statistics,vol. 23, no. 4, pp. 493–507, 1952.[15] V. Nimal, “Statistical approaches for probabilistic model checking,”M.Sc. Dissertation, Oxford University Computing Laboratory, 2010.[16] J. Katoen, M. Khattri, and I. Zapreevt, “A Markov reward modelchecker,” inQEST’05. IEEE, 2005, pp. 243–244.[17] K. Sen, M. Viswanathan, and G. Agha, “VESTA: A statistical model-checker and analyzer for probabilistic systems,” inQEST’05. IEEE,2005, pp. 251–252.[18] H. Younes, “Ymer: A statistical model checker,” inComputer AidedVeriﬁcation. Springer, 2005, pp. 171–179.[19] M. Kwiatkowska, G. Norman, and D. Parker, “Symmetry reductionfor probabilistic model checking,” inComputer Aided Veriﬁcation.Springer, 2006, pp. 234–248.[20] T. Dean and R. Givan, “Model minimization in Markov decisionprocesses,” inProceedings of the National Conference on ArtiﬁcialIntelligence, 1997, pp. 106–111.[21] K. Sen, M. Viswanathan, and G. Agha, “On statistical model checkingof stochastic systems,” inProc. CAV’05. Springer, 2005, pp. 266–280.[22] D. Rabih and N. Pekergin, “Statistical model checking using perfectsimulation,” inProc. ATVA’09. Springer-Verlag, 2009, pp. 120–134.[23] R. Lassaigne and S. Peyronnet, “Probabilistic veriﬁcation and approxi-mation,”ENTCS, vol. 143, pp. 101–114, 2006.[24] S. Basu, A. Ghosh, and R. He, “Approximate model checking of PCTLinvolving unbounded path properties,”ICFEM’09, pp. 326–346, 2009.[25] H. Younes, E. Clarke, and P. Zuliani, “Statistical veriﬁcation of proba-bilistic properties with unbounded until,”Formal Methods: Foundationsand Applications, pp. 144–160, 2011.[26] R. Rubinstein and D. Kroese,Simulation and the Monte Carlo method(Series in Probability and Statistics). Wiley, 2008, vol. 707.[27] M. Villén-Altamirano and J. Villén-Altamirano, “RESTART: a straight-forward method for fast simulation of rare events,” inProc. WSC’94,San Diego, USA, 1994, pp. 282–289.611