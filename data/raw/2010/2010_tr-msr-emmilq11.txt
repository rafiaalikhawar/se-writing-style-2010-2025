Asynchronous Programs with Prioritized Task-Buffers
Michael Emmi
LIAFA, Universit√© Paris Diderot
Paris, France
mje@liafa.jussieu.frAkash Lal
Microsoft Research
Bangalore, India
akashl@microsoft.comShaz Qadeer
Microsoft Research
Redmond, WA, USA
qadeer@microsoft.com
January 1, 2012
Technical Report
MSR-TR-2012-1
Formal programming models are designed to identify and isolate key features in programs. For example, pushdown systems are a
natural (and popular) model for sequential recursive programs that isolate the call-return semantics of procedure calls. Isolating features
allows an analysis to focus on the key challenges. For concurrent programs, the model of multithreading can sometimes be too general.
Consequently, previous work [ 26] has proposed a model of asynchronous programming where tasks (unit of computation) can be
posted to a task buffer and are then executed in a nondeterministically chosen, but serial, order from the buffer.
Guided by real-world applications of asynchronous programming, we propose a new model that enriches the asynchronous
programming model by adding two new features: multiple task-buffers and multiple task-priority levels. In our model, tasks can reside
in multiple buffers and are served in priority order. Our model allows non-serial execution: tasks with higher priority can preempt tasks
with a lower priority, and tasks obtained from different buffers can freely interleave with each other. Modeling these features allows
analysis algorithms to detect otherwise uncaught programming errors in asynchronous programs due to inter-buffer interleaving and
task-interruption, while correctly ignoring false errors due to infeasible out-of-priority-order executions.
We also give an algorithm for analyzing this new model. Given bounds K1;K22Nthat restrict inter-buffer task interleaving and
intra-buffer task reordering, we give a code-to-code translation from programs in our model to sequential programs, which can then be
analyzed by off-the-shelf sequential-program analysis tools. For any given parameter values, the sequential program encodes a subset
of possible program behaviors, and in the limit as both parameters approach inÔ¨Ånity, the sequential program encodes all behaviors. We
demonstrate the viability of our technique by experimenting with a prototype implementation. It is competitive with state-of-the-art
veriÔ¨Åcation tools for concurrent programs. Our prototype is able to correctly identify programming errors in simpliÔ¨Åed asynchronous
Windows device driver code, while ignoring infeasible executions.
Microsoft Research
Microsoft Corporation
One Microsoft Way
Redmond, WA 98052
http://www.research.microsoft.com1. Introduction
Users of interactive computer systems expect little or no latency in
an application‚Äôs ability to react to their actions. For instance, when
interacting with a graphical user interface (GUI), one expects an
instant reaction for each mouse click and key stroke, despite the long
running computation the application may be performing. Similarly,
one expects a web server to reply to each HTTP request immediately,
despite the thousands of concurrent requests the server may be
handling. To ensure such low-latency behavior, the modern operating
systems on which these applications run provide mechanisms to
break and parallelize applications‚Äô sequential control Ô¨Çow. Hardware
events initiate software handlers which interrupt the currently-
executing process, e.g., ensuring each keystroke is communicated to
the application immediately. In multi-processing systems, logically
disjoint tasks are executed in parallel, e.g., to divide the processing
of distinct HTTP connections across several cores or processors.
Traditionally such reactive software systems have been de-
signed as shared-memory multi-process or multi-threaded programs.
Whether executing on a single or across multiple processors, a
collection of software threads‚Äîeach essentially behaving as recur-
sive sequential programs‚Äîexecute concurrently, interleaving their
read and write accesses to shared memory. Though simple to state,
such a concurrent programming model is complex due to the many
possible intricate interactions between threads. Such complexity
is troublesome for the designer who must predict and prevent un-
desirable thread interleavings by adding synchronization such as
atomic locking instructions. This job is particularly difÔ¨Åcult given
that over-synchronizing, e.g., by protecting all transactions by a
single global lock, hampers reactivity and destroys opportunities for
parallelization. Furthermore, the non-deterministic nature of such
interleaving semantics is the root cause of Heisenbugs , i.e., pro-
gramming errors that manifest themselves rarely, and are often very
difÔ¨Åcult to reproduce and repair.
In reaction to the difÔ¨Åculty of multi-threaded programming,
reactive software systems designed according to the asynchronous
programming model [ 9,11,26] have gained much traction. An
asynchronous program divides cumulative program behavior into
short-running tasks. Each task behaves essentially as a recursive
sequential program, which in addition to accessing a memory shared
by all tasks can post new tasks to task-buffers for later execution.
Tasks from each buffer execute serially, one after the other: when
one task completes, another task is taken from the buffer and run to
completion. To program a reactive system the designer simply must
ensure that no single task executes for too long to prevent other,
possibly more urgent, tasks from executing. Figure 1 illustrates the
general architecture of asynchronous programs.
Due to the relative simplicity, asynchronous programming is be-
coming a particularly appealing way to implement reactive systems.
Asynchronous programming has seen widespread adoption in recent
years by desktop applications, servers, and embedded systems alike.
The Javascript engines of modern web browsers [ 10], Grand Central
Dispatch in MacOS and iOS [ 2], Linux‚Äôs work-queues [ 27], asyn-
chrony in .NET [ 20], and deferred procedure calls in the Windows
kernel [ 21] are all based on asynchronous programming. Even in the
single-processing setting (i.e., without any parallelism) asynchrony
frameworks such as Node.js [ 6] are becoming widely used to design
extremely scalable (web) servers.
Despite the relative simplicity of asynchronous programming,
concurrent programming errors are still possible. Since program-
mers are often required to restructure long-running tasks tinto a
sequence of short-running tasks t1;:::;t i, other tasks executing be-
tween sometjandtj+1may interfere with t‚Äôs intended atomic com-
putation. Furthermore, tasks executing across several task-buffers
(e.g., on a multi-core processor) are not guaranteed to execute seri-
ally, and may interleave their accesses to shared memory. Formal
Figure 1. A general architecture of asynchronous programs with
Ntask buffers. Tasks from the same buffer execute serially, but
concurrently with tasks of other buffers.
reasoning about concurrent program behavior is thus still crucial to
prevent costly programming errors.
In order to analyse asynchronous programs, we propose a formal
model to capture concurrency in real-world asynchronous systems.
In our model, each task has an associated priority level , and tasks
execute from and post to multiple task-buffers. Tasks from each
buffer execute serially, one after the other, posting new tasks to the
same buffer from which they were taken, but tasks of distinct buffers
may interleave. (Initially, each task-buffer contains at least one
initial task.) When one task completes, a highest-priority pending
task is taken from its buffer and begins executing. At any moment
when a task t1posts a higher-priority task t2,t1is suspended to
executet2. When there are no more remaining tasks with higher
priority,t1resumes execution. The number of priority levels and
task-buffers are both Ô¨Ånite and statically determined. Furthermore,
tasks taken from one task-buffer may not post tasks to another; the
only inter-buffer communication occurs though shared-memory.
Our model extends previous formal model of asynchronous
programs proposed by Sen and Viswanathan [26] to more-accurately
capture the concurrency in real-world asynchronous programs [ 2,
20,21,27]. Without accounting for priorities, the previous model
permits priority-order breaking executions which can never arise in
the actual system being modeled. By considering a single task-buffer,
the previous model excludes inter-buffer task interleavings which
can arise in actual systems. In the context of formal veriÔ¨Åcation,
the former leads to falsely detected errors, while the latter leads to
uncaught errors.
We also give an algorithm for analyzing programs that follow our
model. The state-reachability problem for Ô¨Ånite-data programs with
a single task-buffer and single priority level is decidable [ 9,26]. It
remains decidable in the presence of multiple levels, though highly
complex [ 3]. Extending orthogonally to multiple interleaving task-
buffers renders the problem undecidable: recursive multi-threaded
programs are easily captured. Nevertheless, we believe the multiple
task-buffer asynchronous model is important enough to be distin-
guished from the multi-threaded model for two reasons. First, encod-
ing an asynchronous program with multiple prioritized task-buffers
as a multi-threaded program requires adding additional state and syn-
chronization to ensure (a) same-buffer tasks do not interleave, and
(b) only highest-priority tasks from each buffer may execute. Encod-
ing these constraints with general-purpose synchronization mecha-
nisms disregards the more declarative program structure, and leads
to inefÔ¨Åcient program exploration (as shown by our experiments).
Second, by leveraging the intensional structure of concurrency in
the actual program, we can derive useful heuristics for prioritized
program exploration. For example, following the premise of context-
bounding [ 22,24], we beneÔ¨Åt by exploring program executions with
relatively few alternations between task-buffers, or relatively few
intra-buffer task reorderings (without directly restricting the number
of tasks executed).
1In the spirit of exploiting the structure of asynchronous programs,
we develop a parameterized program analysis by reduction to
sequential program analysis. The analysis parameters K1andK2
restrict the amount of interleaving between tasks of different buffers
(K1) and reordering between tasks of the same buffer ( K2); as
we increase K1(resp.,K2) our analysis explores more and more
inter-buffer task interleavings (resp., intra-buffer task reoderings);
in the limit as both K1andK2approach inÔ¨Ånity, our encoding
encodes all valid executions. For any given parameter values,
we succinctly encode a limited set of asynchronous executions
as executions of a non-deterministic sequential program with a
polynomial number (in K1andK2)of additional copies of shared
variables. Our encoding is compositional in the spirit of existing
sequential program reductions [ 4,7,13,17], in that each task-
buffer‚Äôs execution is explored in isolation from other task-buffers,
and the task-buffers themselves are not explicitly represented. Such
compositionality sidesteps the combinatorial explosion that would
arise by keeping the local-state of other buffers‚Äô tasks, and by
explicitly representing the contents of even a single task-buffer.
Our reduction happens in two steps. First, in Section 4, we reduce
asynchronous programs with multiple task-buffers to asynchronous
programs with a single task-buffer, while preserving task priorities.
We accomplish this by a code-to-code translation that introduces K1
copies of shared variables. Each copy stores the value at which a task
resumes after being preempted by other buffers‚Äô tasks; these values
are initially guessed, and later validated. Interleavings with other
task-buffers are thus simulated locally by moving to the next shared
variable copy. In the second step (Section 5), we reduce single-buffer
asynchronous programs with task priorities to sequential programs.
We again accomplish this by a code-to-code translation, though in
this translation we also introduce copies of shared variables for each
priority level. Since our translation targets a sequential program
without explicitly representing the task-buffer, each asynchronous
task post is roughly translated as a synchronous procedure call. As
posts to lower-priority tasks are not allowed to execute immediately,
we use the extra shared variable copies to summarize their execution,
postponing their effects until later.
This paper makes the following contributions:
Motivated by our investigation into the concurrency arising in
real-world desktop, server, and embedded asynchronous soft-
ware (Section 2), we introduce a model of asynchronous pro-
grams with multiple task-buffers and task priorities (Section 3)
that can naturally express the concurrency in these applications.
We propose an incremental parameterized analysis technique for
asynchronous programs by a two-step reduction to sequential
programs (Sections 4 and 5).
We demonstrate that our analysis is relatively easy to implement
and efÔ¨Åcient in practice. We have written a prototype imple-
mentation for bounded veriÔ¨Åcation of asynchronous C programs
(Section 6). Our tool is able to discover errors in our case stud-
ies, without imprecisely reporting false errors which would be
detected by analyses based on existing asynchrony models.
By translating asynchronous programs to sequential programs, we
allow the many existing sequential-program analysis tools to be
lifted for (underapproximate) analysis of asynchronous programs.
Moreover, our translation is agnostic to datatypes present in the
program, and is thus able to target analyses that support arbitrary
data-domains, e.g., Boolean programs, programs with integers, or
lists, etc.
2. Asynchronous Programming in Practice
In order to build practical veriÔ¨Åcation and debugging tools, we
desire to formally specify the program behaviors that occur in re-active software systems. To better understand why existing formal
programming models are inadequate, we examine two real-world
applications: hardware-software interaction in the Windows operat-
ing system, and asynchronous multi-processing in the Apache web
server.
2.1 Hardware-Software Interaction in the Windows Kernel
The primary mechanism for ensuring high-performance hardware
interaction in the Windows kernel is priority interrupt levels . In the
following discourse, we focus on three levels in decreasing priority
order‚Äî DEVICE_LEVEL1, DISPATCH_LEVEL , and PASSIVE_LEVEL .
At the DEVICE_LEVEL run the software ‚Äúinterrupt service rou-
tines‚Äù (ISRs). A Boolean-valued ‚Äúinterrupt line‚Äù connecting the
device to a processor core triggers a Ô¨Åxed ISR: when a core‚Äôs
interrupt line is raised, and an ISR is not currently running, the
currently-running code is interrupted to execute the ISR. Since
DEVICE_LEVEL routines prevent any other code, including the
scheduler, from executing, DEVICE_LEVEL routines should execute
in a very short period of time, delegating remaining computation to
an asynchronous ‚Äúdeferred procedure call‚Äù (DPC). The Windows
kernel maintains a queue of pending DPCs and periodic invoca-
tions of the Windows scheduler, and executes each one-by-one at
DISPATCH_LEVEL until completion, until the queue is empty. Nor-
mal applications run at PASSIVE_LEVEL , and thus, only execute
when the DPC queue is empty. Like DEVICE_LEVEL code, DPCs
should not sleep or block waiting for I/O; instead they should either
continue to defer future work by queueing another DPC, or delegate
the work to a PASSIVE_LEVEL thread. Although DPCs are guaran-
teed not to interleave with other DPCs nor application threads on
the same core, DPCs may execute concurrently with ISRs, DPCs,
the Windows scheduler, and threads, of other cores.
Besides bringing reactivity, the priority-level scheme pro-
vides synchronization for devices‚Äô shared data. Since code above
PASSIVE_LEVEL executes atomically without preemption by
same- or lower-level code, raising from PASSIVE_LEVEL to
DISPATCH_LEVEL synchronizes device accesses on a single-core.
Our model can precisely capture these aspects of Windows
by assigning each task one of the three priority levels, and by
dividing code from separate cores into separate task-buffers. In
order to capture arbitrary interleaved interaction between hardware
and software, we can designate a separate task-buffer for a single
spinning hardware-simulating task. Note that ignoring priorities
can result in false data-race errors on device-data protected with
level-based synchronization, and ignoring multiple buffers will miss
real errors due to interleaving across separate cores (or with the
hardware).
2.2 Multi-Processing in Apache via Grand Central Dispatch
In a recently-released software patch, the once multi-threaded
Apache web server has been redesigned as an asynchronous pro-
gram using the libdispatch concurrency framework [ 1]. In the
updated architecture, the application begins by creating a number
of concurrently-executing connection-listener objects, each main-
taining a separate queue of incoming connection requests. Each
listener handles connection requests by creating a new connection
object, which besides storing all data relevant to a given client con-
nection, maintains a queue of tasks pertaining to the connection.
Client activity on the low-level network socket triggers additional
connection-processing tasks to be placed on the queue. Tasks spurred
by periodic timers and server replies are also placed on the queue.
Importantly, the tasks manipulating the data of any given connection
are placed in the same task-queue, although the connection-listening
1DEVICE_LEVEL is really a family of levels to which each device maps.
Here we consider a generic device mapped to a single level.
2tasks responsible for initializing new connection data are distributed
across several queues.
The underlying concurrency manager, called Grand Central
Dispatch (GCD), is responsible for executing tasks from the various
queues. GCD ensures that each task from a queue executes only
after the previous task has completed.2Concerning Apache, this
ensures that at most one task per connection executes at any moment,
and allows several tasks from distinct connections and connection
listeners to execute concurrently.
For any Ô¨Ånite number of connections and listeners, our pro-
gramming model accurately captures the possible executions, by
associating a task-buffer to each connection and connection listener.
Existing formal models do not sufÔ¨Åce. Single-buffer asynchronous
programs could not capture potentially unsafe interleaving between
connections and between connection-listeners; without adding extra
synchronization, multi-threading allow tasks of the same connection
to erroneously interleave their shared-memory accesses.
2.3 Abstraction of Task-Buffer Order
These systems Ô¨Åt well into our programing model with one caveat‚Äî
we abstract the FiFo-ordered queues by unordered buffers. We
believe this is justiÔ¨Åed for two reasons. First, algorithmic formal
reasoning about processes accessing unbounded ordered queues
remains a difÔ¨Åcult problem.3Second, our understanding of these
particular systems leads us to believe that while the FiFo semantics
is important to ensures fairness and reactivity, key safety properties
may not rely on the order. Of course, this is not a technical
limitation‚Äîone can encode the FiFo order using shared-memory
synchronization if required (but at the cost of introducing signiÔ¨Åcant
complexity).
3. Asynchronous Programs
We consider a programming model in which computations are
divided into tasks . Each task has a Ô¨Åxed priority-level and a task-
buffer associated with it, and behaves essentially as a recursive
sequential program. Besides accessing a global memory shared
by all other tasks, each task can post additional tasks to its task-
buffer for later execution. Same-level tasks from each buffer execute
serially, one after the other, yet are interrupted by higher-level tasks,
and executed in parallel with tasks from distinct buffers. We call
a task-buffer without a currently-executing task idle, the yet-to-be
executed tasks of a buffer pending , the tasks who have Ô¨Ånished
execution completed , and the task chosen to execute when another
completes dispatched . Initially each task-buffer is idle and contains
at least one pending task. When a buffer is idle or a task completes,
a highest-priority pending task is dispatched. At any moment when
a taskt1posts a higher-priority task t2,t1is suspended to execute
t2‚Äîwe sayt1isinterrupted byt2; as soon as all higher-priority
tasks of the same buffer have completed, t1resumes execution.
The resulting model generalizes the classical model of asyn-
chronous programs [ 26] by adding priority-levels [ 3] and multiple
task-buffers. Here, only highest-priority tasks may be dispatched,
and tasks from different task buffers execute in parallel. Though we
prefer to keep the concept of task-buffer disconnected from physical
entities such as processes, threads, processors, cores, etc., Section 2
describes particular mappings to task-buffers from such entities in
real-world asynchronous systems.
We adopt an interleaving semantics for our model: at any point
in time only tasks from a single task-buffer may execute, but a
(buffer) preemption can transfer control to a task from another buffer.
2Strictly speaking, GCD schedules at most wtasks from each queue, where
wis a user-speciÔ¨Åed per-queue parameter, usually set to 1.
3State-reachability for even a single Ô¨Ånite-state process accessing an un-
bounded queue is undecidable [5].P::= v ar g:T( pro cp ( v ar l:T )s)
s::=s ;sj skipjx :=ej assumee
j ife thens elsesj whilee dos
j callx :=p ej returne
j p ostm p ej yieldj zield
x::= gj l
Figure 2. The grammar of asynchronous programs P. HereT
is an unspeciÔ¨Åed type, p2Procs ranges over procedure names,
e2Exprs over expressions, and m2Mover priority levels.
We explicitly mark opportunities for such control transfers with
a special program statement called zield . Additionally, to further
extend the applicability of our model we introduce a similar control-
transfer called a (task) preemption that suspends execution of the
current task and transfers control to another same-level task of
the same buffer. We mark opportunities for these transfers with a
special program statement called yield . Having explicit instructions
for such control transfer allows for great Ô¨Çexibility in model. We
write atomic methods (e.g., synchronization operations) simply by
omitting yield s and zield s for the duration of the atomic section.
We model DISPATCH_LEVEL deferred procedure calls in Windows
(see Section 2) by omitting yield s (but not zield s). Moreover, we
model multithreaded programs by inserting yield s before every
statement that accesses shared memory.4
3.1 Program Syntax
LetProcs be a set of procedure names, Vals a set of values, Exprs a
set of expressions, and N;M2N, resp., the number of task-buffers
and priority-levels. For N2Nwe denote the setf0;:::;N 1g
simply byN. The grammar of Figure 2 describes our language of
asynchronous programs (with prioritized task-buffers) . We inten-
tionally leave the syntax of expressions eunspeciÔ¨Åed, though we do
insist Vals contains true andfalse , and Exprs contains Vals and the
(nullary) choice operator ?.
Amulti-buffer (resp., single-buffer )program is a program with
(resp., without) zield statements. A program in which the Ô¨Årst state-
ment of each posted procedure5is while? do yield is called re-
orderable , a program in which the yield statement does (resp., does
not) occur otherwise (including transitively called procedures) is
called preemptive (resp., non-preemptive ), and a program without
yield or zield statements is called scheduler-dependent . Intuitively,
a scheduler-dependent program is deterministic modulo nondeter-
minism in the sequential statements (e.g., arising by using the ?
operator in if- then - else statements), and modulo the possibly
nondeterministic choices made at task-dispatch points; in a reoder-
able program, any dispatched task can immediate re-become pend-
ing. A sequential program is one without p ost , yield , and zield
statements.
Each program Pdeclares a single shared type- Tglobal variable
g, and a sequence of procedures named p1:::pi2Procs, eachp
having single type- Tparameter land a top-level statement denoted
sp. The set of program statements sis denoted Stmts . Furthermore
each program PdeclaresNparameter-less initial procedures named
main(0), main(1), . . . , main(N 1), which are never posted nor
called; we will assume an initial frame of main(n)is initially
pending for each task-buffer n2N. Intuitively, a p ostm p e
statement is an asynchronous call to a procedure pwith argument
eto be executed at priority level m. The yield statement transfers
control to a same-priority level pending task of the same task-buffer,
4Here we assume memory accesses are sequentially consistent [18].
5We assume each procedure can be either posted or called, but not both.
3g;`;v2Vals
e2Exprs
s2Stmts
p2Procsf2Framesdef=ValsStmtsM
t2Tasksdef=Frames
a2N!Tasks
b2N!M[Tasks ]
c2Congsdef=ValsN(N!Tasks )(N!M[Tasks ])
Figure 3. The semantic domains of the meta-variablesused in the
transition relation of Figure 4.
and the zield statement transfers control to a task from another task-
buffer. The assumeestatement proceeds only when eevaluates
to true ; we will use this statement to block undesired executions in
subsequent reductions to sequential programs.
The programming language we consider is simple, yet very
expressive, since the syntax of expressions is left free, and we lose
no generality by considering only single global and local variables.
Appendix A lists several syntactic extensions, which easily reduce to
the syntax of our grammar, and which we use in the source-to-source
translations of the subsequent sections. Additionally, hardware
interrupts and lock-based synchronization can be encoded using
global shared memory; see Sections 3.3 and 3.4.
3.2 Program Semantics
A(procedure-stack) frame f=h`;s;miis a current valuation
`2Vals to the procedure-local variable l, along with a statement
sto be executed, and a priority level m2M. (Heresdescribes
the entire body of a procedure pthat remains to be executed, and
is initially set to p‚Äôs top-level statement sp.) The set of frames is
denoted Framesdef=ValsStmtsM. A sequence t=f1:::fi
of frames is called a task (f1is the top-most frame), and the set
of tasks is denoted Tasks . The level (resp., base level ) of a task
t, denoted by level(t)(resp., base(t)), is the level of t‚Äôs topmost
(resp., bottommost) frame, and  1whent=".
Since we consider a cooperative multitasking model, where
control transfers between buffers and between tasks of the same
buffer are explicit, our operational model need only consider a single
currently executing task of a single buffer at any moment. When
higher-level tasks of the same buffer interrupt a lower-level task,
our model simply adds the higher-level task‚Äôs frame to the top of
the current procedure stack. We thus represent each task-buffer
n2Nby a currently-executing active task a(n)2Tasks , along
with a multiset b(n)2M[Tasks ]of pending tasks, and we deÔ¨Åne a
conÔ¨Åguration c=hg;n;a;bias a valuation g2Vals of the global
variable g, along with a currently active task-buffer n2N, an active
taska:N!Tasks per buffer, and a multiset of pending tasks
b:N!M[Tasks ]per buffer. Figure 3 summarizes the various
semantic domains and meta-variable naming conventions.
We deÔ¨Åne top:M[Tasks ]!Mas the maximum level for
which there is a pending task in the given buffer:
top()def= max(f0g[f level(t) :t2g);
and we let top(hg;n;a;bi)def=top(b(n))be the maximum such
level for the currently active buffer. Similarly, we deÔ¨Åne the
level of a conÔ¨Åguration as the level of the currently active buffer:
level(hg;n;a;bi)def=level(a(n)).
The singleton pending-tasks map (n7!t)mapsntoftg, and
n02Nnfngto;, and the union b1[b2of pending-tasks maps
is deÔ¨Åned by the multiset union of each mapping: (b1[b2)(n)def=
b1(n)[b2(n)forn2N. Similarly, the active-task map a0=
a(n7!t)extendsaby setting the currently active task of buffer n
tot:a0(n) =t, anda0(n0) =a(n0)for alln02Nnfng.For expressions without program variables, we assume the
existence of an evaluation function JKe:Exprs!}(Vals)such
that J?Ke=Vals. For convenience, when c=hg;n;a;biand
a(n) =ft=h`;s;mit, we deÔ¨Åne
e(c)def=e(g;ft)def=e(g;f)def=e(g;`)def=Je[g= g;`= l]Ke
to evaluate the expression ein a conÔ¨Åguration c(alternatively, in a
global valuation gand taskft) by substituting the current values
for variables gand l. As these are the only program variables,
the substituted expression e[g= g;:::]has no free variables. For
expressionseover only the task-local variable lwe writee(ft)def=
Je[`= l]Ke. Additionally we deÔ¨Åne
c( g g0)def=
g0;n;a;b
global assignment
c( l `0)def=
g;n;a 
n7!f0t
;b
local assignment
cf0def=hg;n;a (n7!f0ft);bi frame push/pop
wheref0=h`0;s;miupdates the local valuation of frame f, and
f0is an arbitrary frame.
To reduce clutter and highlight the meaningful components
of rules in the operational program semantics, we introduce a
notion of context. A statement context Sis a term derived from
the grammar S::= jS;s, wheres2Stmts . We write
S[s]for the statement obtained by substituting a statement s
for the unique occurrence of inS. Atask-statement context
T=h`;S;mitis a task whose top-most frame‚Äôs statement is
replaced with a statement context, and we write T[s]to denote
the taskh`;S[s];mit. Finally, a conÔ¨Åguration-statement context
C=hg;n;a (n7!T);biis a conÔ¨Åguration whose currently active
task is replaced with a task-statement context, and we write C[s]
to denote the conÔ¨Åguration hg;n;a (n7!T[s]);bi. Intuitively, a
context Ô¨Ålled with s, e.g.,C[s], indicates that sis the next state-
ment to execute in a given conÔ¨Åguration, task, or statement se-
quence. We abbreviate e(T[skip]),e(g;T[skip]), ande(C[skip])
by, resp.,e(T),e(g;T), ande(C)for arbitrary expressions e.
As an example, the ASSUME rule of Figure 4 takes a conÔ¨Ågu-
rationC[assumee] =hg;n;a (n7!h`;assumee ;s;mit);bi
in which true2e(C) =e(g;`)and transitions to the conÔ¨Åguration
C[skip] =hg;n;a (n7!h`;skip ;s;mit);bi; as only the current
statement is updated, the description C[assumee]!PC[skip]
completely and concisely describes the conÔ¨Åguration change.
Figure 4 deÔ¨Ånes the transition relation !of asynchronous
programs as a set of operational steps on conÔ¨Ågurations. The
transitions for the sequential statements are mostly standard. The
ASSUME rule restricts the set of valid executions: a step is only
allowed when the predicated expression eevaluates to true . (This
statement‚Äîusually conÔ¨Åned to intermediate languages‚Äîis crucial
for our reductions between program models in the subsequent
sections.)
More interesting are the transitions for the asynchronous con-
structs (i.e., p ost , yield , and zield ). The POSTrule creates a new
frame to execute given procedure pwith argument eat levelm0, and
places the new frame in the pending-tasks of the currently active
task-buffern. When a (single-frame) task fcompletes its execution,
theRESUME rule discards fto continue the execution of the task
tbelowfon the procedure stack. The YIELD rule allows a task to
relinquish control to another pending task at the same level. The
ZIELD rule simply updates the currently active task-buffer from n
to somen02N. The DISPATCH rule schedules a highest-level task
t1when the currently executing task t2has a lower level.
Anexecution of a program P(fromc0tocj)is a conÔ¨Åguration
sequencec0c1:::cjsuch thatci!Pci+1for0i < j . A
conÔ¨Åguration c=hg;n0;a;biof a program Pisg0-initial when
g=g0,n0= 0, and for alln2N,
a(n) =" andb(n) =f
`;s main(n);0
g
4SKIP
C[skip ;s]  !
PC[s]ASSUME
true2e(C)
C[assumee]  !
PC[skip]
ASSIGN
v2e(C)
C[x :=e]  !
PC[skip] (x v)IF-THEN
true2e(C)
C[ifethens1elses2]  !
PC[s1]IF-ELSE
false2e(C)
C[ifethens1elses2]  !
PC[s2]
LOOP-DO
true2e(C)
C[whileedos]  !
PC[s;whileedos]LOOP-END
false2e(C)
C[whileedos]  !
PC[skip]
CALL
v2e(C)m=level(C)
C[callx :=pe]  !
PC[x :=?]hv;sp;miRETURN
g2 g(C)v2e(g;`)m=level(C)
C[x :=?]h`;S[returne];mi  !
PC[x :=v]RESUME
m> level(c)
ch`;S[returne];mi  !
Pc
POST
`2e(g;T)f=h`;sp;mib0=b[(n7!f)
hg;n;a (n7!T[postmpe ]);bi  !
P
g;n;a (n7!T[skip]);b0DISPATCH
level(t1)top(b(n))>level(t2)
hg;n;a (n7!t2);b[(n7!t1)i  !
Phg;n;a (n7!t1t2);bi
YIELD
level(T1) =base(T1)>level(t2)b0=b[(n7!T1[skip])
hg;n;a (n7!T1[yield ]t2);bi  !
P
g;n;a (n7!t2);b0ZIELD
n22N
hg;n1;a(n17!T[zield ]);bi  !
Phg;n2;a(n17!T[skip]);bi
Figure 4. The transition relation for the asynchronous programs; each rule, besides DISPATCH , is implicitly guarded by level(c)top(c),
wherecis the conÔ¨Åguration on the left-hand side of the transition.
for some/any6`2Vals. A conÔ¨Ågurationhg;n;a;biisgf-Ô¨Ånal
wheng=gf. A pairhg0;gfiis areachability fact of Pwhen there
exists an execution of Pfrom somec0to somecfsuch thatc0is
g0-initial andcfisgf-Ô¨Ånal.
Problem 1 (State-Reachability) .The state-reachability problem
is to determine, given a pair hg0;gfiand a program P, whether
hg0;gfiis a reachability fact of P:
Since preemption (i.e., arbitrary use of the yield statement)
and multiple task-buffers can both be used to simulate arbitrary
multi-threaded programs, the presence of either feature makes state-
reachability undecidable.
Theorem 1. The state-reachability problem is undecidable for Ô¨Ånite-
data asynchronous programs with either preemptive tasks, or with
multiple task-buffers.
For single-buffer programs without arbitrary preemption between
tasks, Atig et al. [3]have shown decidability by reduction to
reachability in a decidable class of Petri nets with inhibitor arcs.
Theorem 2. The state-reachability problem is decidable for Ô¨Ånite-
data single-buffer programs without preemption.
Though Atig et al. [3]‚Äôs reduction does show decidability, it
does not lead to a practical program analysis algorithm since the
only known algorithms for checking reachability in Petri nets have
extremely high complexity‚Äîthey are non-primitive recursive [ 8].
In the following sections we design an approximating algorithm for
the general case, encompassing both cases of Theorem 1 and 2, by
reduction to sequential program analysis. Though approximation
is necessary in the undecidable case with preemption or multiple
buffers, approximation also allows us practical analysis algorithms
in the decidable yet complex case with prioritized buffers. Note
that though these decidability results only apply to Ô¨Ånite-data
programs, our sequential reduction applies equally well to programs
with inÔ¨Ånite data, and does not approximate individual program
states; e.g., given a program using unbounded integer variables, our
6Since main (n)takes no arguments, the initial local valuation is irrelevant.translation encodes a subset of all possible concurrent behaviors,
without abstracting in any given state the integer variable valuations.
3.3 Modeling Hardware Interrupts
Although our model only allows tasks to post other tasks to their
own buffers, inter-buffer task-posting can be modeled using shared
memory. For instance, consider modeling hardware interrupts in
operating systems kernels like Windows and Linux. Each processor
core has a Ô¨Åxed number of Boolean-valued interrupt lines which
once raised by hardware devices, trigger software routines to inter-
rupt the currently-running application or kernel task (see Section 2.1
for more details).
To model hardware interrupts we add an additional highest
priority-level M, and an array v ar IRQ[N ]:Bto the global
program state‚Äîhere we suppose each core corresponds to a task-
buffer, and we handle only a single interrupt line per core; the
generalization to multiple lines per core is straightforward. For each
coren2N, we designate a Ô¨Åxed procedure pro c ih(n) ()sto
be the interrupt handler for the core. Raising an interrupt on core
n2Nis as simple as setting IRQ[n ] := true . An interrupt is
caught and processed on core nby inserting the following code
before each global-variable access and p ost , yield , or zield
statement
if IRQ[n ] then
IRQ[n ] := false;
p ostM ih(n) ()
Posting to level Mensures that no matter which level the current
task is running at, the interrupt handler will interrupt it.
3.4 Modeling Synchronization
As the execution of tasks across multiple task-buffers may interleave,
in general programs need a way to ensure atomicity of data accesses.
Implementing atomic locking instructions is not difÔ¨Åcult because
we have assumed tasks are only preempted by other buffer‚Äôs tasks
at designated zield points, or by same-buffer tasks at designated
yield points. A lock can thus be implemented by adding an
additional global variable v ar lock: B; acquiring the lock is
achieved by the statement
5while lock = true do
yield ; // only for preemptive programs
zield ;
lock := true
and releasing the lock is as simple as setting lock := false .
Note that the exit from the while loop and the assignment
lock := true are guaranteed to happen atomically, since there are
no interfering yield or zield statements. Once the lock is held by
one task, any other acquiring tasks must wait until it is released.
4. Reduction to Single-Buffer Programs
As a Ô¨Årst step in our scheme to reduce the state-reachability prob-
lem of asynchronous programs to state-reachability in sequential
programs, we translate multiple-buffer programs to single-buffer
programs, while preserving task priorities. As the state-reachability
problem for single-buffer Ô¨Ånite-data asynchronous programs with
task priorities is decidable [ 3] for non-preemptive programs7, while
our multi-buffer variation is not, our translation necessarily repre-
sents an approximation of the original problem. Though our trans-
lation encodes various inter-buffer interleavings, it cannot encode
every inter-buffer interleaving. In order to control and reÔ¨Åne the
amount of considered interleavings, and thus the degree of approxi-
mation, our translation takes a bounding parameter K. Following
the approach of the original multi-threaded sequentializations [ 17],
for a given bounding parameter K, we explore only K-round round-
robin executions in buffer-index order; i.e., in each round, tasks
from buffer 0execute until a (perhaps not the Ô¨Årst) zield statement,
at which point tasks from buffer 1execute to some zield statement,
and so on. At the zield statement where a task from buffer N 1
gives up control, the second round begins, resuming the suspended
task of buffer 0. Note that the bounding permits arbitrarily long
executions within a buffer.
Example 1 (Restricted Inter-Buffer Interleaving) .The following
asynchronous program with 2task buffers and a single priority
demonstrates how K-round exploration restricts program behaviors.
v ar b:B
v ar r:N
pro c main (0) ()
b := true;
r := 1;
p ost 0 p;
return
pro c main (1) ()
p ost 0 q
returnpro c p ()
zield ;
assume !b;
b := true;
r := r + 1;
p ost 0 p ();
return
pro c q ()
zield ;
b := false;
p ost 0 q ();
return
In the round-robin order, execution begins with main(0)of the Ô¨Årst
task-buffer, which sets the variable bto true , sets rto 1, and posts
a single task p. Each ptask blocks unless bis set to false , in which
case bis set to true , rincremented, and pre-posted. When the
zield statement is encountered, control may be transferred to the
second task buffer, which begins in main(1)by posting q. Each
instance of qsets bto false , and re-posts q.
In a single-round execution, i.e., K= 1, the only reachable
value of ris 1. In order to increment r, a qtask of the second
buffer, which sets bto false , must be executed before p‚Äôs assume
statement. In general, incrementing rKtimes requires Krounds of
7Note that the programs Atig et al. [3]consider are non-preemptive; what
they refer to as ‚Äúpreemption‚Äù we refer to as ‚Äúinterruption.‚Äù// translation
// of var g: T
v ar G[K ]:T
v ar k:K
// translation of g
G[k]
// translation
// of zield
k := in (k,K -1)// translation
// of post m p e
p ost (m +1)p e
// translation of
// proc main (i) ()s
pro c main' (i) ()s
pro c main (0) ()
for n = 0 toN 1 do
k := 0;
p ost 1 main' ( n) ()
Figure 5. The multi-to-single buffer code translation ( (P) )K
Mof a
multi-buffer asynchronous program Pparameterized by K2N.
The resulting single-buffer program encodes only round-robin task-
buffer executions of Krounds.
execution, each in which a qtask from the second buffer proceeds a
ptask of the Ô¨Årst. Since only one such alternation can happen per
round,Krounds are required to make Kalternations.
As in Lal and Reps [17]‚Äôs original multi-threaded sequentializa-
tion, our code translation ( () )K
Mof Figure 5 stores a copy of the
global valuation reached in each round. Initially, the global valua-
tions for the second round and beyond are set non-deterministically.
Then, for each task buffer n, we execute all tasks from nacross all
rounds before moving on to the next buffer and resetting the round
to0. At non-deterministically chosen zield statements, any task
may cease accessing the ithglobal valuation copy and begin using
the(i+ 1)stcopy; this simulates the progression of buffer nfrom
roundito round (i+ 1) . After each buffer has completed executing
all of its tasks, we can determine whether the initially guessed global
valuations were valid by ensuring the initial valuation from each
roundi>0matches the valuation reached in round (i 1). This va-
lidity relation is captured formally by a predicate SK
Mrelating initial
and Ô¨Ånal global valuations: a ‚Äúsequentialized‚Äù execution of ( (P) )K
Mfromg0togfrepresents a valid K-round round-robin execution
of the original program Ponly whenSK
M(g0;gf), in which case
a mappingfK
Mtranslates the reachability pair hg0;gfito a valid
reachability pair fK
M(g0;gf)inP. Note that our simulation requires
only a single task-buffer since we execute all tasks of each buffer
to completion before moving on to the next. To ensure all tasks of
each buffer complete before coming back to main ‚Äôs loop, we shift
all priority levels up by one.
Formally, our K-round multi-to-single buffer translation
K
M=D
( () )K
M;SK
M;fK
ME
is the code transformation ( () )K
Mlisted in Figure 5, along with a
validity predicate SK
M:Vals2!B, indicating when an execution
of( (P) )K
Mcorresponds to a valid execution of P, and a function
fK
M:Vals2!Vals2, mapping reachability pairs of ( (P) )K
Mto
reachability pairs of P:
SK
M(g0;gf)def= G[1..K -1](g0) = G[0..K -2](gf),
fK
M(g0;gf)def=h G[0](g0); G[K -1](gf)i.
Given this correspondence, we reduce state-reachability of K-round
multi-buffer round-robin executions of Pto state-reachability of
( (P) )K
M; this reduction thus under-approximates P‚Äôs behavior.
Theorem 3 (Soundness) .For all programs P, ifhg0;gfiis a
reachability fact of ( (P) )K
MandSM(g0;gf)holds, thenfM(g0;gf)
is a reachability fact of P.
6Since every multi-buffer execution can be expressed in a Ô¨Ånite
number of rounds of a round-robin execution, our reduction com-
pletely captures all executions in the limit as Kapproaches inÔ¨Ånity.
Theorem 4 (Completeness) .For all reachability facts hg0;gfiof a
programPthere existsK2Nand a reachability fact
g0
0;g0
fof
( (P) )K
Msuch thathg0;gfi=fM(g0
0;g0
f)andSM(g0
0;g0
f).
4.1 Translation Composition
Crucial to our staged-translation approach is the fact that a sequence
of translations can be composed. The ordered composition of the
translations 1=
( () )1;S1;f1and2=
( () )2;S2;f2is
deÔ¨Åned by the translation 21=
( () );S;f
such that
( () ) = ( () )2( () )1,
S=S2^(S1f2), and
f=f1f2.
When both 1and2are sound and complete in the sense of
Theorems 3 and 4, then 21is also sound and complete.
5. Reduction to Sequential Programs
In the second step of our reduction scheme, we translate single-
buffer asynchronous programs with task priorities to sequential
programs. Though the state-reachability problem is decidable for
Ô¨Ånite-data single-buffer programs without preemption [ 3], allowing
arbitrary inter-task preemption does make the state-reachability prob-
lem undecidable, due to unbridled interleaving between concurrently
executing tasks of the same level; indeed recursive multi-threaded
programs are easily encoded when use of the yield statement is unre-
stricted. Furthermore, even in the decidable case of non-preemptive
programs, the complexity of state-reachability is very high: due to
the arbitrary dispatch order of same-level tasks (and perhaps further
complicated by interruptions from higher-level tasks), the problem
is at least as hard as reachability in Petri nets [ 3]‚Äîa problem for
which the only known algorithms are non-primitive recursive [8].
Thus, as in Section 4, our translation to sequential programs is
again obliged (in the presence of preemption), or at least better off
(even without preemption), to represent only an approximation of
the original state-reachability problem. Our translation encodes only
a subset of the possible task interleavings and dispatch orderings. As
before, we introduce a bounding parameter Kwith which to restrict
the amount of interleavings expressed; with increasing values of K
we capture more and more interleaving and task dispatching orders,
and in the limit encode all possible executions.
To simplify our translation, we again divide our work in half.
In Section 5.1, we propose a translation to remove yields from a
given program with task priorities. In Section 5.2, we then translate
a yield-free single-buffer asynchronous program with task priorities
to a sequential program. The Ô¨Årst ‚Äúyield-elimination‚Äù step is crucial
to our translation; it deals with both task reorderings (where any
of the pending tasks at the same level can be dispatched) and task
preemption. Our second step then simulates only a Ô¨Åxed schedule
of task dispatching, following the approach of delay-bounded
scheduling [ 7]. To ensure our translation encodes all possible task
dispatch schedules in the limit as the bounding parameter approaches
inÔ¨Ånity, we assume programs are reorderable, i.e., by requiring that
the Ô¨Årst statement of each task is while? do yield . (Note that
this does not make a program preemptive; recall the deÔ¨Ånitions of
Section 3.1.)
5.1 Eliminating Preemption and Reordering
Again following the vectorization approach pioneered by Lal and
Reps [17], we proceed by restricting the set of interleaved executions// translation of
// call x :=p e
call (x ,k) :=
p (e ,cur_lvl,k)
// translation
// of return e
return (e ,k)
// translation
// of var g: T
v ar G[K ]:T
v ar R[M ]:K
// translation
// of yield
k := in (k..K -1)
// translation of g
G[k]// translation of
// proc p (var l: T )s
pro c p ( v ar l:T , cur_lvl: M ,
k:K )s
// translation of post m p e
2 assert m cur_lvl+1;
ifm = cur_lvl+1 then
4 let saved_G = G in
let G? in
6 G := G?;
G[0] := saved_G[k];
8 R[cur_lvl] := k;
p ost m p (e ,m ,0);
10 assume G?[1.. K -1] = G[0.. K -2];
saved_G[k] := G[ K -1];
12 G := saved_G;
else if m = cur_lvl then
14 p ost m p (e ,m ,k)
else p ost m p (e ,m ,R[m ])
Figure 6. The yield-eliminating translation ( (P) )K
Yof a single-
buffer multi-level program P, parameterized by K2N.
between tasks of any given level to those according to a round-
robin schedule; for a given bounding parameter K, we will explore
executions in which each task can be preempted by or reordered
with other same-level tasks across Krounds.
To accomplish this, our code translation ( () )K
Yof Figure 6 stores
a copy G[k ]of the global valuation reached in each round k, for just
one level at a time, and each task stores a current-round counter k.
Initially execution begins with a task at level 0accessing the 0thcopy
of the global valuation; the other copies of the global valuation are
set non-deterministically. At any point upon encountering a yield
statement, the currently executing task can increment his round
counter to any value k < K , and begin accessing the kthcopy of
the global valuation. Such an increment propels the current task
to roundk, simulating a preemption by or reordering with other
tasks from his level. When a task in round kposts a same-level
task, the posted task is constrained to execute in or after round k.
The possibility of inter-level posts makes our reduction signiÔ¨Åcantly
more intricate than previous sequentializations [7, 17].
Posts to higher-level tasks interrupt execution of the currently
executing task. When such a post happens, we save the global-
valuation vector for the current level (Line 4), and allocate a new
global-valuation vector for the target level whose Ô¨Årst element
is initialized with the current global valuation reached by the
posting task (Lines 5‚Äì7); the other values are again guessed non-
deterministically. When control returns to the posting task, we
must ensure the guessed global valuations at the beginning of each
round of the target level have been reached by previous rounds
(Line 10); when this is the case we have simulated some round-robin
execution of the target level‚Äôs tasks. As long as those guesses can be
validated, we restore the previously-saved global-valuation vector
for the posting task‚Äôs level, update the current-round‚Äôs valuation with
the Ô¨Ånal valuation reached in the posted task‚Äôs level, and continue
executing the posting task (Lines 11‚Äì12).
Though posting a lower-priority-level task is handled almost
identically to posting a same-level task, there is one important
difference: the round of the posted task t2must not occur before the
round of an interrupted task t1of the same priority level waiting
below on the task stack; otherwise causality is broken, since t2
would execute before t1in the simulated execution, though t2‚Äôs
existence may rely on t1‚Äôs execution. To prevent such anomalies, we
store in R[m ]the current round kof each priority level mbelow
7the currently executing task, and constrain tasks posted to level m
to execute no sooner than round k. To simplify our translation, we
assume priority-level mtasks post only tasks of priority at most
m+ 1; posts to higher levels can be encoded by a chain of posts.
We deÔ¨Åne formally the K-round yield-eliminating translation
K
Y=D
( () )K
Y;SK
Y;fK
YE
as the code transformation ( () )K
Ylisted in Figure 6, along with a
validity predicate SK
Yand reachability-fact map fK
Y:
SK
Y(g0;gf)def= G[1..K -1](g0) = G[0..K -2](gf),
fK
Y(g0;gf)def=h G[0](g0); G[K -1](gf)i.
Given this correspondence, we reduce state-reachability of K-round
round-robin intra-level executions of Pto state-reachability of
( (P) )K
Y; we thus under-approximate the behavior of Pby restricting
the set of interleavings/reorderings between same-level tasks.
Theorem 5 (Soundness) .For all programs P, ifhg0;gfiis a
reachability fact of ( (P) )K
YandSK
Y(g0;gf), thenfK
Y(g0;gf)is
a reachability fact of P.
Since every execution with yields can be expressed by allocating
some Ô¨Ånite number of rounds to each execution sequence of same-
level tasks, our reduction completely captures all executions in the
limit asKapproaches inÔ¨Ånity.
Theorem 6 (Completeness) .For all reachability facts hg0;gfiof a
programPthere existsK2Nand a reachability fact
g0
0;g0
fof
( (P) )K
Ysuch thathg0;gfi=fK
Y(g0
0;g0
f)andSK
Y(g0
0;g0
f).
5.2 Sequentializing Asynchronous Programs with Priorities
By removing all yield statements in the previous step, our Ô¨Ånal
translation need only give a translation for scheduler-dependent
single-buffer asynchronous programs with priorities. Our reduction
expresses all executions according to a particular total order on task-
dispatching. Though not strictly important for the soundness nor
completeness of our encoding, the determined task-dispatch order
roughly corresponds to Emmi et al. [7]‚Äôs deterministic depth-Ô¨Årst
schedule, except here we are faced with the added complexity of
multiple priority levels.
Example 2 (Restricted Intra-Buffer Reordering) .The following
reorderable single-buffer asynchronous program demonstrates how
ourK-bounded exploration restricts program behaviors. Execution
begins with main , which sets the variable bto true , sets rto 1, and
posts a sequence of ptasks followed by a sequence of qtasks. Each
ptask blocks unless bis set to false , in which case bis set to true
and rincremented. Each qtask sets bto false .
v ar b:B
v ar r:N
pro c main ()
b := true;
r := 1;
while ? do
p ost 0 p ();
while ? do
p ost 0 q ();
returnpro c p ()
while ? do yield ;
assume !b;
b := true;
r := r + 1;
return
pro c q ()
while ? do yield ;
b := false;
return
WhenK= 1, we explore only executions according to a deter-
ministic schedule of task dispatching; speciÔ¨Åcally, according to the
depth-Ô¨Årst scheduler [ 7]. For this program, that means all posted p
tasks must run before any qtask, in which case the only reachable
value of ris 1. WhenK > 1, we introduce task reordering by// translation of
// call x :=p e
call x :=
p (e ,cur_lvl)
// translation
// of var g: T
v ar done: B
v ar g:T
v ar G[M ]
// translation of
// proc main () s
pro c main ()
done := false;
s ;
done := true
// translation of g
g// translation of
// proc p (var l: T )s
pro c p ( v ar l:T , cur_lvl: M )s
// translation of post m p e
2 assert m cur_lvl+1;
ifm = cur_lvl+1 then
4 let g? = ? in
G[m ] := g?;
6 call p (e ,m );
assume g = g?;
8 g := G[ m ];
else //m cur_lvl
10 let saved_G = G[ m +1..cur_lvl] in
let saved_g = g in
12 let g? = ? in
g := G[ m ];
14 G[m ] := g?;
call p (e ,m );
16 assume g = g?;
G[m +1..cur_lvl] := saved_G;
18 g := saved_g;
Figure 7. The sequential translation ( (P) )Pof a yield-free single-
buffer asynchronous program Pwith task priorities.
allowing each task to advance among the Krounds at yield points.
In this way,K+ 1rounds sufÔ¨Åces to capture Kalternations from q
to ptasks, allowing the value of rto be incremented Ktimes.
In the case of a single priority level, our asynchronous-to-
sequential code translation ( () )Pof Figure 7 is identical to the
no-delay depth-Ô¨Årst scheduling sequentialization [ 7]. Each p ost
statement is roughly translated to a call statement. Since each
posted tasktmust execute after the completion of the currently
executing task, at the point where tis called, the current valuation
of the global variable gdoes not generally correspond to t‚Äôs initial
global valuation. The sequentialization thus introduces an auxiliary
variable G, which holds at any point the global valuation encountered
by the next-to-be-posted task. Initially, G‚Äôs value is guessed, and
later veriÔ¨Åed to be the value reached by the initial task. Each time a
new tasktis posted, Gis updated with a guess of the value reached
bytandtbegins with the previous value stored in G(Lines 12‚Äì
14), and when tcompletes, we verify that the guessed value indeed
matches the value reached by t(Line 16). The simulated execution
corresponds to a depth-Ô¨Årst traversal of the tree of tasks connected
by the task-posting relation, in which each task executes atomically,
to completion.
The presence of multiple priority levels makes our translation
signiÔ¨Åcantly more intricate. First, instead of a single auxiliary
variable Gstoring the next-to-be-posted task‚Äôs valuation, we must
track that valuation per priority level , due to the additional task
ordering constraints. Second, when a call to a higher-level posted
task returns, we must update the global valuation of the currently-
executing task to that reached by the higher-priority tasks (Line 8),
rather than restoring previous global valuation (as in Line 18); this
captures interruption. Third, calls to lower-level m1taskst1must
not overwrite the values stored in Gfor levels between m1and the
current level m3>m 1, e.g., by posting additional tasks t2to level
m2betweenm1andm3. Doing so would simulate executions in
whicht2executes before other same-level tasks t0
2not yet posted
by levelm3; this would be a breach in causality, since t0
2must in
reality execute before t1, and thus before t2. Our translation prevents
such inconsistent behavior by saving the Gvalues for levels between
m1andm3(Line 10), and restoring them upon return from calls
corresponding to lower-level posts (Line 17). Finally, since even the
8value encountered by the Ô¨Årst-posted task is originally guessed, a
simulated execution can only be considered valid when the main task
completes and can validate the initial guess; we add the additional
variable done to indicate whether the main task has completed. To
simplify our translation, we assume priority-level mtasks post only
tasks of priority at most m+1; posts to higher levels can be encoded
by a chain of posts.
Formally, our prioritized asynchronous to sequential translation
P=
( () )P;SP;fP
is the code transformation ( () )Plisted in Figure 7, along with the
validity predicate SPand reachability-fact map fPdeÔ¨Åned as
SP(g0;gf)def= done(gf) =true^ G[0](g0) = g(gf), and
fP(g0;gf)def=h g(g0); G[0](gf)i.
Given this correspondence, we reduce state-reachability of a single-
buffer scheduler-dependent asynchronous program with priorities
Pto state-reachability of the sequential program ( (P) )P.
Theorem 7 (Soundness) .For all programs P, ifhg0;gfiis a
reachability fact of ( (P) )PandSP(g0;gf), thenfP(g0;gf)is a
reachability fact of P.
Note that we cannot state a completeness result for this Ô¨Ånal
translation step, since the translation only encodes a deterministic
schedule of task dispatching. However, when combined with the pre-
viousK-bounded yield-eliminating translation, and the assumption
that the original program is reorderable, we do obtain completeness
in the limit as Kapproaches inÔ¨Ånity.
Theorem 8 (Completeness) .For all reachability facts hg0;gfiof
a reoderable single-buffer asynchronous program Pthere exists
K2Nand a reachability fact
g00
0;g00
fof( (( (P) )K
Y) )P, and
g0
0;g0
f
such that
g0
0;g0
f
=fP(g00
0;g00
f),hg0;gfi=fK
Y(g0
0;g0
f),
SP(g00
0;g00
f), andSK
Y(g0
0;g0
f).
Finally, by choosing K1;K22N, composing our translations
K1
MK2
YP
and gathering the results of Theorems 3‚Äì8, we have a sound
algorithm for state-reachability of asynchronous programs with
multiple prioritized task-buffers and arbitrary preemption, which is
complete in the limit as both K1andK2approach inÔ¨Ånity.
6. Implementation and Experience
We have implemented our sequentialization technique in a tool
called ASYNC CHECKER . It takes a concurrent program with asser-
tions as input, written in the C programming language extended with
thepost primitive for spawning threads. This primitive allows us to
easily model concurrency provided by, for example, the pthread
library, or the Win32 API. The user is also given control on where
to insert yields and zields; the default choice being that they are
inserted before every access to a shared variable. ASYNC CHECKER
also takes two integers as input, which denote the zield budget (i.e.,
the bound used in Section 4) and the yield budget (i.e., the bound
used in Section 5). It uses these budgets to sequentialize the program
and then look for assertion violations within those budgets. When it
Ô¨Ånds an assertion violation, it displays the interleaved error trace.
ASYNC CHECKER has the unique capability of targetting one kind
of bugs over another by changing the budgets: a high zield bound
targets bugs that require inter-buffer interleavings, and a high yield
bound targets bugs that require inter-task reorderings or preemp-
tions. ASYNC CHECKER uses CORRAL [15], an SMT-based model
checker, as the sequential veriÔ¨Åer. Appendix B details how we deal
with assertions and error-trace generation in our sequentializations.
We now give evidence that even though ASYNC CHECKER usesName Outcome POIROT (sec) ASYNC CHECKER (sec)
driver1 Correct 8:66 10:63
driver2 Buggy 4:42 3:44
driver3 Buggy 7:48 9:14
driver4 Correct 13:26 9:61
driver5 Buggy 6:1 5:2
driver6 Correct 37:57 77:1
driver7 Correct 44:43 86:56
driver8 Buggy 24:33 29:1
driver9 Buggy 31:5 33:9
driver10 Correct 23:64 25:4
Figure 8. Results on P OIROT regressions.
an elaborate sequentialization, it is still a practical tool capable of
Ô¨Ånding real bugs using three different experiments.
First Experiment. Our Ô¨Årst experiment is to compare ASYNC -
CHECKER against other more mature tools on Ô¨Ånding bugs in multi-
threaded programs (with a single task-buffer and no priorities). This
is to show: (1)Although ASYNC CHECKER is a prototype imple-
mentation, it already competes well with existing tools on real pro-
grams; (2)one does not pay the cost of using multiple task-buffers
or priorities unless the program uses these features. We compare
ASYNC CHECKER against POIROT [23], which is also based on a se-
quentialization technique [ 16,17] that requires a thread round-robin
bound, similar in spirit to ASYNC CHECKER ‚Äôs yield budget. POIROT
also uses C ORRAL as the underlying sequential checker.
For benchmarks, we used POIROT ‚Äôs regression suite that consists
of real device drivers. Some drivers have seeded bugs. The sizes
of the drivers ranged from 500to700lines of source code, with
three threads that exercise different routines exposed by the driver.
The results are shown in Fig. 8. We ran ASYNC CHECKER with
a zield budget of 1and a yield budget equal to the round-bound
used by POIROT . In each case, the outcome of POIROT andASYNC -
CHECKER (buggy or correct) was the same. ASYNC CHECKER per-
formed reasonably well in comparison to P OIROT .
For programs with multiple task-buffers or prioritized tasks,
there is no tool (other than ASYNC CHECKER ) for analyzing them,
to the best of our knowledge. However, there is still an alternative
to using ASYNC CHECKER : one can encode the task-buffers and
priority levels using shared memory and synchronization and then
usePOIROT on the resulting multithreaded program. We also imple-
mented this approach (lets call it SYNCE). It introduces shared state
that counts the number of tasks in each buffer and at each priority
level. Next, it inserts assume statements to prevent a task from
running if the buffer size at a higher priority level is non-empty.8
Second Experiment. Consider the single-buffer program shown in
Fig. 9. (We assume that there are implicit yields and zields between
every two instructions.) The program has a single assertion in bar
that checks the value of xagainst a parameter N. For any positive
value of N, there is an execution that violates the assertion. Moreover,
that execution necessarily has to alternate between priorities 0and
1for a total of Ntimes. We ran both ASYNC CHECKER andSYNCE
on this program with different values of N. In each case, we report
the time taken by the tools to Ô¨Ånd the assertion violation under the
best possible budget values.
The table in Fig. 9 shows the poor scalability of SYNCE. The
reason is that ASYNC CHECKER can Ô¨Ånd the bug using a yield budget
of1, but POIROT (running underneath SYNCE) requires a context-
switch bound proportional to Nbecause of SYNCE‚Äôs encoding of
priorities. The increase in this bound causes exponential slowdown.
8Appendix C outlines this approach in detail using a code-to-code
transformation.
9v ar x:N
v ar cont: B
pro c bar()
v ar t := x
x := t + 1
assert (x != N)
if (? ) then
cont := truepro c main()
x := 0; cont := true;
call foo();
pro c foo()
if (cont and ? ) then
cont := false
p ost 1 bar()
p ost 0 foo()
N 1 2 3 4
SYNCE 1.5 2.1 13.6 384.2
ASYNC CHECKER 1.2 1.2 1.25 1.34
Figure 9. A single-buffer example and the running times (in sec-
onds) of S YNCE and A SYNC CHECKER .
v ar x := 0
pro c main2()
v ar j := 0
while (? ) do
assume (x = 2 ? j + 1)
p ost 1 bar()
j := j + 1
assert(x != 2 ? N)pro c main1() {
v ar i := 0;
while (? ) do
assume (x = 2 ? i)
p ost 1 bar()
i := i + 1
pro c bar()
v ar t := x; x := t + 1;
N 1 2 3 4
SYNCE 1.6 5.1 168.9 >500
ASYNC CHECKER 1.1 1.7 7.23 256.6
Figure 10. A multi-buffer example and the running times (in
seconds) of S YNCE and A SYNC CHECKER .
The next example, shown in Fig. 10 has two task buffers with
initial tasks main1 and main2 , respectively. Again, there are implicit
yields and zields between every two instructions, except in barthat
is supposed to execute yield free. This program requires switching
between buffers each time the shared variable is incremented. Note
that intra-buffer yielding is not necessary for this example‚Äîan
observation that ASYNC CHECKER can exploit by setting the yield
budget to 1and only increasing the zield budget to Ô¨Ånd the bug. The
results show that even though ASYNC CHECKER has an exponential
dependence on the zield budget, it scales much better than SYNCE.
This experiment shows that an encoding of priorities and multi-
ple buffers using shared memory may not Ô¨Åt well with the analyses
that follows. This motivates our Ô¨Årst-class treatment of such features
in A SYNC CHECKER .
Third Experiment. Inspired by typical hardware-software interaction
in Windows [ 19], we hand-coded a small C program ( 117 lines
of code) that has two task-buffers (one for the hardware and
one for the software) and three priority levels ( DEVICE_LEVEL ,
DISPATCH_LEVEL and PASSIVE_LEVEL ). Tasks running at level
above PASSIVE_LEVEL do not yield. The driver, running on the
software buffer signals the hardware to read data from a device.
When the hardware Ô¨Ånishes reading data, it raises an interrupt line
(a shared variable). When tasks in the software buffer see that the
interrupt line has been raised, they post the interrupt handler (ISR) at
DEVICE_LEVEL (and immediately interrupt themselves). Two read
requests from the driver can cause two hardware interrupts to Ô¨Åre,
but, because the ISR runs at an elevated level, it cannot interleavewith other instances of the ISR task. We seeded a bug in this program
where some read request gets dropped without being processed by
the driver.
This example is to show why one needs our model. (1)Inter-
buffer interleaving is necessary to model the hardware-software
interaction (namely, the interrupt mechanism), and (2)priorities are
necessary as well: POIROT , which does not understand priorities,
gets distracted and reports a data race in the ISR, which is incorrect.
ASYNC CHECKER , on the other hand, takes 440seconds to Ô¨Ånd the
seeded bug (and is incapable of reporting the erroneous data race
reported by P OIROT ). SYNCE takes too long to Ô¨Ånish.
7. Related Work
Our model of asynchronous programs with prioritized task-buffers
is inspired by and extends the classical single-buffer asynchronous
programming model [ 9,11,26], and that with task-priorities con-
sidered once before [ 3]. Though Atig et al. [3]showed decidability
of state-reachability in the asynchronous programming model with
priorities, their decision procedure relies on reachability in Petri
nets, for which the only known algorithms are extremely complex‚Äî
they are non-primitive recursive. We build on this body of work by
(1) adding multiple task-buffers, (2) demonstrating real-world exam-
ples which rely on task priorities and/or multiple task-buffers, and
(3) giving a relatively practical parameterized under-approximating
algorithm for state reachability, which incrementally explore more
and more program behaviors as the parameter value increases, by
reduction to state-reachability in sequential programs.
Our work closely follows the line of research on compositional
reductions from concurrent to sequential programs. The initial so-
called ‚Äúsequentialization‚Äù [ 25] explored multi-threaded programs
up to one context-switch between threads, and was later expanded
to handle a parameterized amount of context-switches between a
statically-determined set of threads executing in round-robin or-
der [ 17]. La Torre et al. [13] later provided an alternate encoding
better suited toward model-checking the resulting sequential pro-
gram, and eventually extended the approach to handle programs
parameterized by an unbounded number of statically-determined
threads [ 14]. Shortly after, Emmi et al. [7]further extended these re-
sults to handle an unbounded amount of dynamically-created tasks,
which besides applying to multi-threaded programs, naturally han-
dles asynchronous event-driven programs [ 9,11,26]. Bouajjani et al.
[4]pushed these results even further to a sequentialization which
attempts to explore as many behaviors as possible within a given
analysis budget. Though the latter two of these sequentializations
are applicable to asynchronous programs dynamically creating an
unbounded number of tasks, they do not account for task priorities,
nor multiple task buffers. Though Kidd et al. [12] have demonstrated
a priority-aware sequentialization, their reduction assumes a Ô¨Åxed
number of statically-determined tasks, and does not account for
multiple task buffers.
8. Conclusion
We have introduced a formal model of asynchronous programs
with multiple prioritized task-buffers, which closely captures the
concurrency present in many real-world asynchronous systems.
Though program analysis in our model is complex, we propose
an incremental approximate analysis algorithm by reduction to
sequential program analysis. The parameters K1;K22Nto
our sequential reduction restrict, resp., the amount of inter-buffer
interleaving and intra-buffer task orderings explored; in the limit as
K1andK2approach inÔ¨Ånity, our reduction explores all program
behaviors. We demonstrate that this reduction is relatively easy
to implement, and by using off-the-shelf sequential analysis tools
is able to discover concurrency errors, without reporting spurious
10errors due to modeling imprecision, in asynchronous device driver
code in the Windows kernel.
References
[1]Apple Computer Inc. Apache GCD multi-processing module. http:
//libdispatch.macosforge.org/trac/wiki/apache .
[2]Apple Computer Inc. Grand central dispatch (GCD) reference. http:
//developer.apple.com/library/mac/#documentation/
Performance/Reference/GCD_libdispatch_Ref/Reference/
reference.html .
[3]M. F. Atig, A. Bouajjani, and T. Touili. Analyzing asynchronous
programs with preemption. In FSTTCS ‚Äô08: Proc. IARCS Annual
Conference on Foundations of Software Technology and Theoretical
Computer Science , volume 2 of LIPIcs , pages 37‚Äì48. Schloss Dagstuhl
- Leibniz-Zentrum fuer Informatik, 2008.
[4]A. Bouajjani, M. Emmi, and G. Parlato. On sequentializing concurrent
programs. In SAS ‚Äô11: Proc. 18th International Symposium on Static
Analysis , volume 6887 of LNCS , pages 129‚Äì145. Springer, 2011.
[5]D. Brand and P. ZaÔ¨Åropulo. On communicating Ô¨Ånite-state machines.
J. ACM , 30(2):323‚Äì342, 1983.
[6]R. Dahl. Node.js: Evented I/O for V8 JavaScript. http://nodejs.
org/ .
[7]M. Emmi, S. Qadeer, and Z. Rakamari ¬¥c. Delay-bounded scheduling.
InPOPL ‚Äô11: Proc. 38th ACM SIGPLAN-SIGACT Symposium on
Principles of Programming Languages , pages 411‚Äì422. ACM, 2011.
[8]J. Esparza. Decidability and complexity of Petri net problems - an
introduction. In Petri Nets: Proc. Dagstuhl Lectures on Petri Nets I:
Basic Models, Advances in Petri Nets , volume 1491 of LNCS , pages
374‚Äì428. Springer, 1998.
[9]P. Ganty and R. Majumdar. Algorithmic veriÔ¨Åcation of asynchronous
programs. CoRR , abs/1011.0551, 2010. http://arxiv.org/abs/
1011.0551 .
[10] I. Hickson. HTML5: A vocabulary and associated APIs for HTML and
XHTML. http://dev.w3.org/html5/spec/Overview.html .
[11] R. Jhala and R. Majumdar. Interprocedural analysis of asynchronous
programs. In POPL ‚Äô07: Proc. 34th ACM SIGPLAN-SIGACT Sympo-
sium on Principles of Programming Languages , pages 339‚Äì350. ACM,
2007.
[12] N. Kidd, S. Jagannathan, and J. Vitek. One stack to run them all:
Reducing concurrent analysis to sequential analysis under priority
scheduling. In SPIN ‚Äô10: Proc. 17th International Workshop on Model
Checking Software , volume 6349 of LNCS , pages 245‚Äì261. Springer,
2010.
[13] S. La Torre, P. Madhusudan, and G. Parlato. Reducing context-bounded
concurrent reachability to sequential reachability. In CAV ‚Äô09: Proc.
21st International Conference on Computer Aided VeriÔ¨Åcation , volume
5643 of LNCS , pages 477‚Äì492. Springer, 2009.
[14] S. La Torre, P. Madhusudan, and G. Parlato. Model-checking parame-
terized concurrent programs using linear interfaces. In CAV ‚Äô10: Proc.
22nd International Conference on Computer Aided VeriÔ¨Åcation , volume
6174 of LNCS , pages 629‚Äì644. Springer, 2010.
[15] S. Lahiri, A. Lal, and S. Qadeer. Corral: A whole program analyzer for
boogie. In BOOGIE Workshop , 2011.
[16] S. K. Lahiri, S. Qadeer, and Z. Rakamari ¬¥c. Static and precise detection
of concurrency errors in systems code using SMT solvers. In CAV ‚Äô09:
Proc. 21st International Conference on Computer Aided VeriÔ¨Åcation ,
volume 5643 of LNCS , pages 509‚Äì524. Springer, 2009.
[17] A. Lal and T. W. Reps. Reducing concurrent analysis under a context
bound to sequential analysis. Formal Methods in System Design , 35(1):
73‚Äì97, 2009.
[18] L. Lamport. Proving the correctness of multiprocess programs. IEEE
Trans. Software Eng. , 3(2):125‚Äì143, 1977.
[19] J. Li, F. Xie, T. Ball, V . Levin, and C. McGarvey. An automata-theoretic
approach to hardware/software co-veriÔ¨Åcation. In FASE , pages 248‚Äì
262, 2010.[20] Microsoft Inc. Parallel programming in the .NET framework. http:
//msdn.microsoft.com/en- us/library/dd460693.aspx .
[21] Microsoft Inc. Windows kernel-mode driver architecture.
http://msdn.microsoft.com/en- us/library/windows/
hardware/ff557560(v=VS.85).aspx .
[22] M. Musuvathi and S. Qadeer. Iterative context bounding for systematic
testing of multithreaded programs. In PLDI ‚Äô07: Proc. ACM SIGPLAN
Conference on Programming Language Design and Implementation ,
pages 446‚Äì455. ACM, 2007.
[23] Poirot: The Concurrency Sleuth. http://research.microsoft.
com/en- us/projects/poirot/ .
[24] S. Qadeer and J. Rehof. Context-bounded model checking of concurrent
software. In TACAS ‚Äô05: Proc. 11th International Conference on Tools
and Algorithms for the Construction and Analysis of Systems , volume
3440 of LNCS , pages 93‚Äì107. Springer, 2005.
[25] S. Qadeer and D. Wu. KISS: Keep it simple and sequential. In PLDI
‚Äô04: Proc. ACM SIGPLAN Conference on Programming Language
Design and Implementation , pages 14‚Äì24. ACM, 2004.
[26] K. Sen and M. Viswanathan. Model checking multithreaded programs
with asynchronous atomic methods. In CAV ‚Äô06: Proc. 18th Interna-
tional Conference on Computer Aided VeriÔ¨Åcation , volume 4144 of
LNCS , pages 300‚Äì314. Springer, 2006.
[27] M. Wilcox. I‚Äôll do it later: Softirqs, tasklets, bottom halves, task queues,
work queues and timers. In LCA ‚Äô03: Proc. 4th Linux Conference
Australia , 2003.
A. Syntactic Sugar
The following syntactic extensions are reducible to the original
program syntax of Section 3. Here we freely assume the existence of
various type- and expression-constructors. This does not present a
problem since our program semantics does not restrict the language
of types nor expressions.
Multiple types. Multiple type labels T1;:::;T jcan be encoded by
systematically replacing each Tiwith the sum-type T=Pj
i=1Ti.
This allows local and global variables with distinct types.
Multiple variables. Additional variables x1 :T1 , ..., x j :Tj
can be encoded with a single record-typed variable x:T, whereT
is the record type
{ f1 :T1 , ..., f j :Tj }
and all occurrences of xiare replaced by x.fi. When combined with
the extension allowing multiple types, this allows each procedure to
declare any number and type of local variable parameters, distinct
from the number and type of global variables.
Local variable declarations. Additional (non-parameter) local
variable declarations v ar l':Tto a procedure pcan be encoded
by adding l'to the list of parameters, and systematically adding an
initialization expression (e.g., the choice expression ?, or false )
to the corresponding position in the list of arguments at each call
site ofpto ensure that l'begins correctly (un)initialized.
Unused values. Call assignments call x :=p e, where xis not
subsequently used, can be written as call _ :=p e, where _:T
is an additional unread local variable, or simpler yet as callp e.
Let bindings. Let bindings of the form let x:T =e incan be
encoded by declaring xas a local variable v ar x:Timmediately
followed by an assignment x :=e. This construct is used to
explicate that the value of xremains constant once initialized. The
binding let x:T inis encoded by the binding let x:T =?
inwhere?is the choice expression.
11Tuples. Assignments (x1 , ..., x j ) :=eto a tuple of vari-
ables x1. . . xjare encoded by the sequence
let r: { f 1 :T1 , ..., f j :Tj } =e in
x1 := r.f 1 ; ...; x j := r.f j
where ris a fresh variable. A tuple expression (x1 , ..., x j )
occurring in a statement sis encoded as
let r: { f 1 :T1 , ..., f j :Tj } = { f 1 = x1 , ...,
fj = xj } in
s[ r= (x1 , ..., x j )]
where ris a fresh variable, and s[e1=e2]replaces all occurrences of
e2inswithe1. When a tuple-element xion the left-hand side of
an assignment is unneeded (e.g., from the return value of a call),
we may replace the occurrence of xiwith the _variable‚Äîsee the
‚Äúunused values‚Äù desugaring.
Arrays. Finite arrays with jelements of type Tcan be encoded
as records of type { f1 :T , ..., f j : T } , where f1. . . fjare
fresh names. Occurrences of terms a[i] are replaced by a.fi,
and array-expressions [e1 , ...,ej ]are replaced by record-
expressions { f1 =e1 , ..., f j =ej }.
B. Asserts and Error Traces
Assertions. The program transformations presented in this paper
preserve reachability facts, which talk about starting and end state of
a program execution. In order to check for assertions in the program,
we Ô¨Årst map them to reachability facts as follows: when an asserted
condition is violated, the program is intrumented to raise a Ô¨Çag and
throw an exception. The exception has the effect of aborting the
current as well as all pending tasks. If we see that the exception
Ô¨Çag been raised in the end state of an execution, then we know
that an assertion must have been violated in that execution. Thus,
our implementation asserts that the exception Ô¨Çag is not set in the
sequential program produced by our technique.
Error Traces. When the sequential veriÔ¨Åer Ô¨Ånds a bug in the
sequential program produced by our technique, we still need to map
the bug back to an execution of the original concurrent program.
We follow a general approach to solve this problem, which is easily
adaptable to other sequentializations as well. First, we introduce a
primitive in our model called print that takes a single variable as
argument. We assume that when the sequential veriÔ¨Åer Ô¨Ånds an error
trace (in the sequential program), and it passes through some print
statements, then it prints the values of their arguments in the order
they appear on the trace.
Next, we introduce an extra integer variable called traceCnt in
the original program that is initialized to 0. Finally, at the beginning
of each task and after every yield ,zield andpost statement, we
insert the code ‚Äú loc := traceCnt; print (loc) ; traceCnt++ ‚Äù,
where loc is a fresh local variable. Because the print statement
only operates on local state, it will be left untouched by our
sequentialization. When the sequential veriÔ¨Åer reports an error
trace, one simply has to follow the sequence of printed values to
reconstruct the interleaving in the error trace.
C. Encoding buffers and priorities using shared
memory
This section describes one approach for encoding a multi-buffer
and multi-priority program as a single-buffer and single-priority
program using shared-memory and synchronization. The encoding
is a code-to-code translation, shown in Figure 11. The translation
assumes that at any point in the program‚Äôs execution, the following
is known about the currently executing task: curr_level is its
priority level; curr_buff is the buffer it came from, curr_tid isits task identiÔ¨Åer. (We assume that each task is associated with a
unique task identiÔ¨Åer, which is distinct from 0.)
The translation introduces three extra shared variables with
the following intention: BufferSize[b][l] records the num-
ber of pending tasks in buffer number bat priority level l;
Interrupted[b][l] records the identiÔ¨Åer of the task of level
land buffer bthat last got interrupted by a higher priority task (if
any); Switched[b] records the identiÔ¨Åer of the task of buffer b
that last got preempted by another buffer (if any). The assume
statements introduced by the translation are the ones that rule out
infeasible executions. The other assignments do the appropriate
book-keeping for the extra variables introduced.
12Additional declarations
v ar BufferSize: NN!N
v ar Interrupted: NN!N
v ar Switched: N!N
Additional initialization
forall b,l. BufferSize[b][l] := 0
forall b,l. Interrupted[b][l] := 0
forall b. Switched[b] := 0
Statement/Expr Translation
yieldyield ;
assume (forall l > curr_level. BufferSize[curr_buff][l] == 0);
assume (Interrupted[curr_buff][curr_level] == 0);
assume (Switched[curr_buff] == 0);
zieldSwitched[curr_buff] := curr_tid;
yield ;
Swicthed[curr_buff] := 0;
return from a taskBufferSize[curr_buff][curr_level] --;
return ;
p ostm p eifm > curr_level then
BufferSize[curr_buff][m]++;
Interrupted[curr_buff][curr_level] := curr_tid;
p ostp e
yield ;
assume (forall l > curr_level. BufferSize[curr_buff][l] == 0);
Interrupted[curr_buff][curr_level] := 0;
else
BufferSize[curr_buff][m] ++;
p ostp e
Figure 11. Semantics-preserving encoding of multi-buffer and multi-priority programs to ones with a single buffer and a single priority.
13