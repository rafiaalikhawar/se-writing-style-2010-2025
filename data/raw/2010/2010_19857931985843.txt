Aspect Recommendation for Evolving Software
Tung Thanh Nguyen, Hung Viet Nguyen, Hoan Anh Nguyen, Tien N. Nguyen
Electrical and Computer Engineering Department
Iowa State University
{tung,hungnv,hoan,tien}@iastate.edu
ABSTRACT
Cross-cutting concerns are unavoidable and create diﬃcul-
ties in the development and maintenance of large-scale sys-
tems. In this paper, we present a novel approach that iden-
tiﬁes certain groups of code units that potentially share
some cross-cutting concerns and recommends them for cre-
ating and updating aspects. Those code units, called con-
cern peers , are detected based on their similar interactions
(similar calling relations in similar contexts, either internally
or externally). The recommendation is applicable to both
the aspectization of non-aspect-oriented programs (i.e. for
aspect creation), and the evolution of aspect-oriented pro-
grams (i.e. for aspect updating). The empirical evaluation
on several real-world software systems shows that our ap-
proach is scalable and provides useful recommendations.
Categories and Subject Descriptors
D.2.7 [ Software Engineering ]: Distribution, Maintenance,
and Enhancement
General Terms
Algorithms, Design, Reliability, Management
Keywords
Cross-cutting Concern, Aspect Mining, Concern Peer
1. INTRODUCTION
Generally, a large software system can be modularized in
only a main design, i.e. dominant decomposition, at a time.
Thus, some functionality, originally existing or being added
as the system evolves, may not align well with that modu-
larization and needs to be scattered across many modules.
Such functionality is called a “cross-cutting concern” [22].
Figure 1 illustrates two functions deposit and withdraw of
an online banking system that provides the accesses to its
users’ bank accounts. To maintain the database integrity in
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’11, May 21–28, 2011, Waikiki, Honolulu, HI, USA
Copyright 2011 ACM 978-1-4503-0445-0/11/05 ...$10.00.public class BankAccount {
Database db;
public void deposit( double value) {
db.lock();
ResultSet r = db.execute(...);
db.unlock(); }
public void withdraw( double value) {
db.lock();
ResultSet r = db.execute(...);
db.unlock(); }
Figure 1: Locking as a Cross-Cutting Concern
concurrent accesses, a locking mechanism with two functions
lockand unlock is used. Method calls to these two functions
are added into the code of the database accessing functions,
creating a database locking cross-cutting concern.
For clariﬁcation, the code units sharing a cross-cutting
concern, e.g. the methods deposit and withdraw , are called
concern containers . The code fragments realizing a cross-
cutting concern, e.g. two added function calls to lockand
unlock in those methods, are called concern implementors .
Cross-cutting concerns create problems for software devel-
opment and maintenance [14]. For example, when a cross-
cutting concern is added or modiﬁed, all scattered code units
relevant to the concern must be detected and updated con-
sistently. Fortunately, aspect-oriented programming (AOP)
provides a solution for such problems. With AOP, the con-
cern implementors of a cross-cutting concern can be factored
out into an aspect and woven back to the corresponding
concern containers at suitable time. For example, a lock-
ing aspect would be deﬁned such that two function calls to
lock/unlock would be executed before/after the statements
performing the database accesses in two methods deposit and
withdraw . In AOP terminology, the code containing the calls
tolockand unlock is called advices . The concern containers
such as deposit and withdraw , after aspectization (i.e. factor-
ing out concern implementors), are called shadows .
However, as software evolves, the maintenance problems
with cross-cutting concerns still exist, even in the aspectized
programs or the programs developed with AOP from the be-
ginning. For example, in the above online banking system,
assume that after aspectization, a new function transfer is
added and also has locking, i.e., it is a locking concern con-
tainer. If developers do not know about the existence of the
deﬁned locking aspect or its relation to the new function
transfer , they might not add transfer as a relevant shadow,
thus, might miss locking in transfer , or create a redundant
locking cross-cutting concern for that function.Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ICSE ’11, May 21–28, 2011, Waikiki, Honolulu, HI, USA
Copyright 2011 ACM 978-1-4503-0445-0/11/05 ...$10.00
361
Recognizing that aspectization is an evolutionary process,
in this paper, we address the problem with a new direc-
tion: investigating the concern containers in both Aspect-
Oriented (AO) and non-AO evolving programs. Our ap-
proach aims at recommending relevant and useful groups of
concern containers for both tasks: creating corresponding
aspects and updating them as software evolves. Since it is
unrealistic to identify all possible cross-cutting concerns in a
system, we emphasize on the concern containers that share
some common characteristics.
Based on the research philosophy that similar code would
have similar properties , we develop our approach with the
assumption that “methods having similar interactions in a
system (i.e. call or are called by similar methods in simi-
lar contexts) tend to share some cross-cutting concern(s)”.
We call such methods as concern peers , to emphasize their
similarity and their correlation with cross-cutting concerns.
The similarity of two interactions is deﬁned based on the
similarity of their callees (or callers) and contexts. Two
methods having suﬃciently similar interactions are consid-
ered as concern peers of each other, i.e. a pair of con-
cern peers. After all pairs of concern peers are detected
and grouped, each group is ranked based on the number of
the relevant interactions of all of its members, which repre-
sents the scatteredness of those members in the code. The
ranked groups are then recommended for AOP. The recom-
mendation is useful in two cases: 1) [aspect mining] when
the code is not yet aspectized, XScan recommends the top-
ranked groups as concern containers of some cross-cutting
concerns, and 2) [aspect updating] when new code is added
into an evolving AO system or an aspectized one, XScan
updates concern peers’s groups, recommends newly added
concern containers as potential shadows to existing aspects,
or other concern containers into potential new aspects.
We developed several techniques to identify, rank, and
recommend concern peers for both aspect creation in aspec-
tization and aspect updating in AOP during software evo-
lution. Those techniques are realized in a prototype tool,
XScan . We conducted an empirical experiment to evaluate
the scalability, correctness and usefulness of our approach.
The results show that, XScan can recommend concern con-
tainers for actual concerns/aspects in the large-scale subject
systems, both AO and non-AO, with coverage and precision
up to 100% and f-score mostly in the range of 97-99%.
The key contributions of this paper include
1. New concepts, formulations, and algorithms to identify,
rank, and recommend concern peers as concern containers.
An aspect updating algorithm is presented. The recommen-
dation is useful for both AO and non-AO evolving programs;
2. A scalable and accurate prototype tool for automated
aspect mining and updating that relies on concern peers;
3. An empirical evaluation on several real-world systems,
showing the scalability, correctness, and usefulness of XScan.
Section 2 describes some observations from the real-world
systems on the existence of concern peers and the evolu-
tionary nature of the aspects. Sections 3 and 4 present our
approach. Evaluation is in Section 5. Related work is in
Section 6. Conclusions appear last.
2. MOTIVATING EXAMPLES
This section discusses some motivating examples on the
similarity of interactions in the concern containers/shadows,
and the evolutionary nature of the aspects. We examinedpublic class SendToBackCommand extends AbstractCommand {
public void execute() {
super .execute();
setUndoActivity(createUndoActivity());
getUndoActivity().setAﬀectedFigures(view().selectionZOrdered());
FigureEnumeration fe = getUndoActivity().getAﬀectedFigures();
while (fe.hasNextFigure())
view().drawing().sendToBack(fe.nextFigure());...
public class BringToFrontCommand extends AbstractCommand {
public void execute() {
super .execute();
setUndoActivity(createUndoActivity());
getUndoActivity().setAﬀectedFigures(view().selection());
FigureEnumeration fe = getUndoActivity().getAﬀectedFigures();
while (fe.hasNextFigure())
view().drawing().bringToFront(fe.nextFigure());...
Figure 2: Similar Interactions in JHotDraw
three open-source systems. Two systems are JHotDraw and
AJHotDraw. JHotDraw is an API framework for graphic
editing, which has been frequently used as a testbed for
aspect-mining research [13, 27]. AJHotDraw [14] is an
aspectized version of JHotDraw, developed by Delft Uni-
versity. The third system is HealthWatcher, a health care
management system. Unlike AJHotDraw, which is aspec-
tized from a non-AO system, HealthWatcher is initially de-
veloped with AOP paradigm and has a consistent evolution.
We analyzed all implemented aspects in AJHotDraw and
HealthWatcher, and all cross-cutting concerns in JHotDraw
reported in previous research [13, 14, 27]. We used AJDT [2]
and PointcutDoctor [25], which provide Eclipse-based tool
support for AspectJ and pointcut/shadow analysis, to parse
AJHotDraw and HealthWatcher code, and then collected
their aspects and corresponding shadows. For JHotDraw,
we utilized its public documentation, and examined the pre-
viously reported cross-cutting concerns and their respective
concern containers [13, 27]. For each concern container and
shadow, we analyzed its interactions via calling relations
with the help of Eclipse and a control ﬂow graph tool.
2.1 Analysis of Concern Containers
Example 1 . JHotDraw has a cross-cutting concern Undo ,
associating a group of nine concern containers, each of which
is a method named execute of nine diﬀerent classes inherited
from class Command . Figure 2 shows two of them: Send-
ToBackCommand.execute() and BringToFrontCommand.execute() .
As shown, two execute() methods call other similar methods
in similar orders. Their classes inherit from the same parent
class, thus they override the same parent method. This is
an example of concern containers having similar internal in-
teractions , i.e. they call similar methods in similar contexts
within their implementation code. We could see that the
two methods in fact also have similar functionality : chang-
ing the order of a ﬁgure in a collection of ﬁgures on which
the current view object is processing.
Example 2 . HealthWatcher (HW) v10 has an aspect, named
HWManagedSynchronization , with a group of three shadows in-
sert(...) from three classes EmployeeRecord ,SymptomRecord ,
and DiseaseRecord . That aspect“synchronizes the methods of
employee, symptom, and disease type records using concur-
rency managers”. Figure 3 shows how they are used/called
in the system. Interestingly, they are called by 3 similar362public class HealthWatcherFacade implements IFacade {
public void insert(Employee employee) throws
ObjectAlreadyInsertedException, ObjectNotValidException {
employeeRecord.insert(employee);
}
public void insert(Symptom symptom) throws InsertEntryException,
ObjectAlreadyInsertedException, ObjectNotValidException {
symptomRecord.insert(symptom);
}
public void insert(DiseaseType diseaseType) throws InsertEntryException,
ObjectAlreadyInsertedException, ObjectNotValidException {
diseaseRecord.insert(diseaseType);
}
Figure 3: Similar Interactions in HealthWatcher
public class CommandMenu extends JMenu implements ActionListener,
CommandListener {
public void actionPerformed(ActionEvent e) {...
Command cmd = (Command) hm.get(item);
if(cmd != null) cmd.execute(); //proxy call to any Command+.execute
Figure 4: Proxy External Interactions in JHotDraw
methods, and are called only at that location in the entire
source code. This is due to the fact that, their client class
HealthWatcherFacade , is designed with Facade design pattern
to work as a common hub to provide accessibility to other
functionality of the system. This is an example of concern
containers/shadows having similar external interactions , i.e.
they are called in similar methods with similar contexts in
their client code. As seen, those three classes have simi-
lar roles in the system (e.g. providing insertion function-
ality to process three types of information that the system
manages: Employee ,Symptom , and DiseaseType ). Many simi-
lar cases were found in which the shadows are not similar,
however, they have similar external interactions. This is
reasonable because after common parts are factored out, al-
though the shadows might not be similar anymore, they are
externally used in a similar manner.
Example 3 . The execute methods in Example 1 are not
called directly in JHotDraw, i.e. they do not have explicit
external interactions. They are called via their ancestor
method Command.execute . Figure 4 shows how they are called
inCommandMenu class, which provides menu functionality.
Since a method invocation to the ancestor method Comm-
nad.execute at run-time could be a call to any overriding
method of execute , we call this interaction a proxy (exter-
nal) interaction of such methods. Since the contexts and
the callers are the same, we also consider such methods hav-
ing similar external interactions in this case, although they
are called via their proxy (i.e. an ancestor method).
Discussion . The concern containers/shadows in all three
examples share the common characteristics that they have
similar interactions , in terms of calling relations. Such sim-
ilarity could be seen in their implementation code and/or in
their client code. Such similarity might come from the fact
that in a system, there tends to exist multiple objects hav-
ingsimilar roles , i.e. providing similar behavior/function-
ality and/or being similarly processed . Because functional-
ity and processing in object-oriented programs are mainly
expressed via objects and interactions between them, such
objects will have similar interactions. Thus, we hypothesize
that the methods of objects with similar interactions wouldoften share one or more cross-cutting concerns . We use the
term concern peers to denote such methods.
Analyzing all aspects in AJHotDraw and HealthWatcher,
we found that this phenomenon is rather prevalent. In
AJHotDraw, 128 out of 143 shadows exhibit the similar-
ity in internal and/or external interactions. Those shadows
belong to 13 (out of total 15) existing aspects in the whole
system. The corresponding numbers in HealthWatcher are
138 out of 147 shadows and 14 out of 23 aspects. Each of
the remaining 9 aspects advises for a single shadow.
The examples and our observations also suggest that con-
cern peers tend to have similar names, similar implementa-
tion code, or similar inheritance. This is due to the follow-
ing reasons. As a convention in object-oriented program-
ming, the objects with similar functions will often be ab-
stracted into a parent class, the speciﬁc behaviors are im-
plemented in the children classes. Sometimes, the meth-
ods/classes might not be similarly implemented, but they
implement the same interface , i.e., promise the similar func-
tions. The other objects could interact in the same way with
the objects in such classes via their promised methods. The
classes/methods having similar functions and/or being re-
lated via inheritance/interface will often be named similarly
by the developers to help themselves in better understand-
ing the roles of such classes/methods. In other cases, to
implement the methods/classes having similar functional-
ity, developers tend to copy-and-paste the implementation
code, thus creating similar code fragments. Therefore, class-
es/methods having similar interactions, tend to have similar
implementation code , or have similar names , or inherit/im-
plement from the same ancestor class/interface .
2.2 Analysis of Aspect Evolution
We analyzed the version history of HealthWatcher, an AO
program, to observe how its aspects and corresponding shad-
ows evolve. Here are some interesting examples.
Example 4 . From v2 to v3, four new aspects are cre-
ated to “implement the state transitions for the state de-
sign pattern”. One aspect, ComplaintStateAspect , is created
for four existing shadows *Complaint. <init>. Each of three
others is created for an existing method ( *Complaint. <init>)
and a newly added method ( *ComplaintState.setStatus ).
Example 5 . From v8 to v9, six existing aspects are updated
to include totally 20 new shadows. We observed that, such
updating is due to the addition of new functionality. For
example, the system manages two new types of information,
symptoms and diseases , thus, the aspect ManagedSynchroniza-
tion(described in Example 2) is updated to advise two new
shadows SymptomRecord.insert and DiseaseRecord.insert .
Examples 4 and 5 show that when an AO program evolves,
new aspects might be created for new concerns, or existing
aspects might be updated to advise newly added shadows
that share corresponding concerns with existing shadows.
2.3 Implications
The aforementioned observations imply the necessity of
tool support for developers not only in identifying/mining
the cross-cutting concerns while aspectizing non-AO pro-
grams, but also in creating and updating the aspects while
developing and maintaining evolving AO programs. The ex-
amples in Section 2.1 suggest that cross-cutting concerns
might occur at code units having similar interactions in363terms of method calls, in both non-AO and AO programs.
Therefore, the desired recommendation tool could be based
on concern peers. That is, one could identify concern peers
based on the similarity of their interactions and recommend
them as the candidates of concern containers to support cre-
ating and updating corresponding aspects. The next sec-
tions present our approach to build such a tool.
3. FORMULATION
In object-oriented programming (OOP), a software sys-
tem is modeled via objects and interactions between them.
Generally, the objects are abstracted into classes, their be-
haviors are implemented as methods, and the interactions
between objects are expressed as calls/invocations between
such methods. The interactions of an object otoward other
objects are expressed in the implementation code of its meth-
ods which invoke the methods of other objects. Let us call
them internal interactions . In contrast, the interactions of
other objects toward oare expressed in its client code within
other methods in which the methods of oare called by those
of other objects. Let us call them external interactions . In
either case, the interactions of the objects could be realized
via method invocations and ﬁeld accesses. Since ocould
change its states in the execution of any method, the calls
before and after the call to a method o.x() are also impor-
tant. We call them the context of the call to o.x().
In this paper, a contextual calling relation is deﬁned as a
4-tuple (x,y,A,B ) in whichxis the caller method, yis the
callee, and the contexts AandBare the sets of dependent
methods that xcalls after and before calling y, respectively.
We consider zis a dependent method call of yif they share
both control and data dependencies . For example, in Fig-
ure 1, there is a contextual calling relation in which caller
x=BankAccount.deposit , calleey=Database.execute , and con-
text information A={Database.unlock},B={Database.lock}.
Definition 1 (Interaction). Given a contextual call-
ing relation (x,y,A,B ):
1)p= (y,A,B )is an internal interaction of x;
2)q= (x,A,B )is an external interaction of y;
3)q= (x,A,B )is a proxy (external) interaction of y1if
y1overrides or implements y.
Item 3) in Deﬁnition 1 is meant to address dynamic dis-
patching in object-oriented programming. That is, if y1over-
rides or implements y, a method call to ymight actually be
a call toy1at run-time. Thus, an external interaction of y
should be a proxy external interaction of y1.
In Figure 1, p=(Database.execute ,{Database.unlock},{Database.-
lock}) is an internal interaction of BankAccount.deposit while
q=(BankAccount.deposit ,{Database.unlock},{Database.lock}) is an
external interaction of Database.execute . If MyDatabase is a
class inheriting from Database and has its method execute
overriding Database.execute , thenqis a proxy external inter-
action of MyDatabase.execute .
Definition 2 (Interaction Sets). Each method xhas
three sets of interactions: internal interactions I(x), exter-
nal interactions E(x), and proxy external interactions P(x).
Such sets could be empty.
Internal interactions of a method xare expressed within
the body of x. External and proxy interactions of xare often
expressed in the bodies of others. For example, in Figure 1,BankAccount.deposit has 3 internal interactions corresponding
toDatabase.lock ,Database.unlock , and Database.execute . Each
of those methods has 2 external interactions corresponding
todeposit and withdraw .MyDatabase.execute has 2 proxy ex-
ternal interactions because it overrides Database.execute .
The following deﬁnes the interaction equivalence relation
that we call (concern) peer relation for methods, and the in-
teraction similarity measures for any two methods, two sets
of methods, two interactions, or two sets of interactions. For
simplicity, peer-relation is denoted by ≡and all similarity
measures are denoted by sim. The parameters will distin-
guish diﬀerent types of sim.
Definition 3 (Concern Peer Methods and Groups).
Two methods are peers of each other if their interaction sim-
ilarity, measured by the corresponding function sim, is suﬃ-
ciently large, i.e. exceeds a pre-deﬁned threshold. A group of
methods is a peer group if each method is a peer to at least
one other method in that group.
Deﬁnition 3 could be written as: sim(x,y)≥σ⇒x≡y
in whichσis a chosen threshold. We consider peer rela-
tions to be reﬂexive (i.e. a method is a peer of itself) and
symmetric (i.e. if xis a peer of y, thenyis also a peer of
x). However, peer relation is not transitive, i.e. if xandy
are peers, and yandzare also peers, xandzmight not be
peers because they might have many diﬀerent interactions
(although some interactions of xorzare similar to some
interactions of y). Function simis deﬁned as follows:
Definition 4 (Interaction Similarity). Interaction
similarity of two methods xandy, denoted by sim(x,y), is
a weighted sum of the similarity values of their internal, ex-
ternal, and proxy interaction sets.
This deﬁnition could formally be written as sim(x,y)
=αsim (I(x),I(y)) +βsim (E(x),E(y)) +γsim (P(x),P(y))
α+β+γ
withα,β,γ are chosen weighting parameters for diﬀerent
types of interactions. If any interaction set is empty, the
corresponding similarity is undeﬁned, thus the correspond-
ing weighting parameter and simwill be disregarded in that
equation, both in the numerator and denominator. Function
simfor the similarity of such interaction sets is deﬁned as:
Definition 5 (Similarity of Two Sets). Similarity
between two sets of methods (or interactions) PandQ, de-
noted assim(P,Q), is the ratio between the size of their
common part and the minimum of their sizes. That is,
sim(P,Q) =|P⊗Q|
min(|P|,|Q|)
We use the minimum of their sizes to emphasize more
on the shared part P⊗Qof two sets. For example, if Q
containsP, we could consider them to be equivalent in the
interactions of P(sinceQmight have some interactions that
are irrelevant to the shared concern of two corresponding
methods). If one or two sets are empty, the minimum size
is zero and the similarity is undeﬁned. In such cases, we
disregard them in the equation.
One would expect the common part P⊗Qto be their
ordinary intersection set P∩Q. However, such a set takes3641function DetectPeerMethod( P)
2C.add(MethodsHaveSimilarCode( P))//add peer candidates with
3C.add(MethodsHaveSimilarName( P))//similar code, name,
4C.add(RelativeMethods( P))//and inheritance
5 repeat
6 (x,y)=C.next() //repeatedly process candidates
7 ifsim(x,y)≥σ//similar enough
8C.remove( (x,y))//remove from candidates
9L.add((x,y))//add as peers
10X=ClassOf(x),Y=ClassOf(y))//check enclosing classes
11C.add(MethodsHaveSimilarName( X,Y ))//more candidates
12 foreach (u,v)∈C: recalculate sim(u,v)//update similarity
13 until nonew peer pairs isdetected
14G= RankGroup( L)
15returnG
Figure 5: Concern Peer Detection
into account only the same/identical methods or interactions
between two sets. To further consider the peer methods and
interactions , i.e. the methods and interactions having peer
relations, we deﬁne the shared part P⊗Qas follows:
Definition 6 (Peer intersection). Peer-intersection
between two sets of methods/interactions PandQ, denoted
byP⊗Q, is the largest set of matching pairs having peer
relations in those two sets.
Deﬁnition 6 could be written as: P⊗Q={(x,y)|x∈
P∧y∈Q∧x≡y}such that∀(x,y),(x/prime,y/prime)∈P⊗Q:x=
x/prime⇔y=y/primeand|P⊗Q|→max. IfPandQare two sets
of methods, we use the peer relation ≡in Deﬁnition 3. If P
andQare two sets of interactions, the peer relation of two
interactions is deﬁned as the following:
Definition 7 (Peer interactions). Two interactions
p= (x,A,B )andp/prime= (x/prime,A/prime,B/prime)are peer-interactions, de-
noted asp≡p/prime, ifxandx/primeare peers of each other, and the
(peer-)similarity degree of AandA/prime, and that of BandB/prime
are suﬃciently large, i.e. exceed a pre-deﬁned threshold.
Deﬁnition 7 could be written as: ( x≡x/prime)∧(sim(A,A/prime)≥
δ)∧(sim(B,B/prime)≥δ)⇒(x,A,B )≡(x/prime,A/prime,B/prime). If one or
more sets are empty, they and their corresponding condi-
tion(s) will be disregarded. For example, if Ais empty, the
conditionsim(A,A/prime)≥δwill be disregarded, i.e. it will not
be included in the evaluation of the expression.
4. ALGORITHMIC SOLUTION
In this section, we describe 2 algorithms in XScan to 1)
detect peer methods, group them, and rank the groups; and
2) recommend peer groups for aspect creation and update.
4.1 Concern Peer Detection and Grouping
4.1.1 Algorithm Design Strategy
To identify all possible pairs of peer methods, one could
use pairwise comparison between all methods using Deﬁ-
nitions 3 and 4 (Section 3). However, such pairwise com-
parison might be impossible because in a large system, the
number of methods might be huge (e.g. ten of thousands),
making pairwise comparison too expensive. More seriously,
there is a possibility that the computation of peer methods
would result in an inﬁnite loop due to the recursive nature of
peer similarity measure. For example, assume that we havetwo call relations“ xcallsy”and“x/primecallsy/prime”. When calculat-
ing interaction similarity of xandx/prime, we might need to check
whetheryandy/primeare peers (to ﬁnd the peer-interactions as
in Deﬁnition 7) since yandy/primebelong to internal interactions
ofxandx/prime, respectively. Then, to check the peer relation of
yandy/prime, we need to calculate the similarity of their external
interactions (as in Deﬁnitions 3 and 4), thus might need to
check the peer-relation of xandx/prime(xandx/primealso belong to
an external interaction of yandy/prime, respectively).
To avoid that, an approximate algorithm is developed for
the identiﬁcation of peer methods with the following ideas:
1. Instead of pairwise comparison for all methods, XScan
uses some heuristics to ﬁnd the pairs of methods that po-
tentially have peer-relations. Each pair is called a candidate .
Two methods will be considered as a peer candidate if they
satisfy at least one of the following conditions:
a) they have some similar portions of code in their body
(such portions of code might be the implementation of a
cross-cutting concern and/or contain many similar internal
interactions of such two methods);
b) they override or implement the same ancestor method
(thus, they promise the same role or have similar function-
ality, and they might be called via that common ancestor
method, i.e. having similar proxy external interactions);
c) they have similar names (developers often have a nam-
ing scheme to memorize the functionality or roles of the enti-
ties, thus, similar names could suggest similar concerns [27]).
2. Instead of calculating similarity measure recursively,
XScan iteratively identiﬁes peer pairs, and calculates the
interaction similarity of candidates using only the already-
identiﬁed peers. When any candidates are identiﬁed as peer
methods, they will be used to update the interaction simi-
larity of the remaining candidates.
3. After all possible pairs of peer methods are detected, we
could form a graph in which nodes represent peer methods
and edges represent peer relations. Each connected compo-
nent of that graph could be reported as a peer group.
4.1.2 Detailed Algorithm
Figure 5 shows the algorithm to detect peer pairs and peer
groups in a program P. The algorithm maintains two lists
LandC, in which each item of Lis a pair of identiﬁed
peer methods while each item of Cis a pair of methods as a
peer candidate under processing. The algorithm iteratively
adds and updates the members of LandC. Then, the peer
pairs inGwill be used to form the graph representing peer
relations and its connected components will be reported as
peer groups. The algorithm has three key phases:
1. Scan for candidates . XScan scans and adds all pairs of
methods with similar portions of code to the candidate list C
(line 2, function MethodsHaveSimilarCode ). It also adds into C
the methods with similar names in the system (line 3, func-
tion MethodsHaveSimilarName ) and the methods that override
or implement the same ancestor method (line 4, function
RelativeMethods ).
In function MethodsHaveSimilarCode , XScan uses Clever,
our clone detection tool to detect similar portions of code in
a program [16]. Clever represents a code fragment as a sub-
tree in an abstract syntax tree (AST), extracts structural
features from the nodes, paths, and labels in the subtree,
and computes the characteristic vector for the subtree with
the occurrence-counts of such features [16]. Similarity be-
tween code fragments is measured based on the distance of365such vectors. To ﬁnd similar vectors, Clever hashes the vec-
tors into buckets using locality-sensitive hashing [1], which
ensures that similar vectors will have high probability to be
hashed into the same bucket, and dissimilar ones have low
probability to be so. Pairwise comparison is applied only on
individual buckets to ﬁnd similar vectors.
In function MethodsHaveSimilarName , XScan compares the
methods to ﬁnd the ones with similar names. First, each
name is separated into words. For example, doGet is sepa-
rated into doand get. Then, the similarity of two names S
andS/prime, as two sequences of words, are calculated via their
longest common subsequence So:sim(S,S/prime) =|So|
avg(|S|,|S/prime|).
To avoid pairwise comparison on all methods, XScan indexes
the method names based on their words and compares only
the method names having at least one common word. For
example, doGet will be put into two buckets for the names
having the words doand get. Thus, doGet and doPost will
be put in the same bucket for the word doand compared
for name similarity. In future work, MethodsHaveSimilarName
could utilize other lexical analysis techniques [24].
2. Scan for peers . Peer candidates (as pairs of meth-
ods) inCare stored as a descending sorted queue based on
their current interaction similarity. Such interaction similar-
ity is calculated via function simin Deﬁnition 4 using only
the already-identiﬁed peers in L. If two candidate methods
have interaction similarity larger than the chosen threshold
(line 7), XScan will remove them from Cand add them to
the list of already identiﬁed peer pairs L(lines 8-9). Then,
it uses such newly identiﬁed peers to detect more candidates
with similar names in the two enclosing classes (lines 10-11)
and to re-compute the interaction similarity of the remain-
ing candidates (line 12). This evaluation process repeats
until no more peers is identiﬁed.
3. Detect and rank peer groups . All detected peer pairs
inLare used to form a graph representing peer relations in
which each node is a peer method, and each edge represents a
peer pair in L. Then, XScan traverses the graph and reports
its connected components as peer groups (lines 14-15).
Since a system might have a large number of peer groups,
to improve the quality of recommendation, XScan uses a
ranking scheme to determine the groups that potentially
share cross-cutting concerns. Intuitively, cross-cutting con-
cern code tends to be scattered in the code base. Thus, if
some methods are called in many places, they are likely to
correlate to some cross-cutting concerns. In other words,
the more external (including proxy external) interactions
a group of peer methods has, the more likely those meth-
ods are concern containers/implementors. Thus, each peer
groupX∈Gis ranked by the total number of external/proxy
interactions of all members of X. This rank value for a group
Ais formally deﬁned as R(X) =/summationtext
x∈X(|E(x)|+|P(x)|).
4.2 Aspect Recommendation
After detection and ranking, the ranked groups are ready
for recommendation. XScan uses two diﬀerent recommen-
dation mechanisms for the two following usage cases.
4.2.1 Aspectization of a non-AO program
When a non-AO program Pis provided, ﬁrst XScan uses
Eclipse to parse it and extract internal, external, and proxy
interaction sets for each method. To distinguish cross-cutting
concerns from common API functions, XScan disregards the1function RecommendUpdate( P1,A1,P2,A2)
2M= DetectChange( P1,P2)//map and ﬁnd changed methods
3N= MatchAspect( A1,A2,M)//map and ﬁnd changed aspects
4G2= DetectPeerMethod( P2);
5 foreach shadow group SinA2//match peer groups to
6X= Match(S,G2)// shadow groups and recommend
7 ifX\S/negationslash=∅Recommend( X\S,N,M)//relevant methods
8 foreach unmatched peer group YinG2//recommend for
9 recommendYfor new aspects //creating new aspects
Figure 6: Aspect Update Recommendation
standard libraries (e.g. JDK). It also ﬁlters the getters, set-
ters, and utility methods, which have “get”, “set”, and “util”
patterns in their names, or are provided by the users. Note
that the calls to those methods are still used in the compu-
tation of interactions for other methods, but such methods
are not reported as concern containers. Then, it detects and
ranks peer groups in Pusing the algorithm in Section 4.1.
Finally, it reports the ranked groups to users for considering
as concern containers, i.e. recommends for aspect creation.
To help users recognize the shared concerns, XScan pro-
vides the common callers/callees of the methods in each rec-
ommended peer group. It also reports those callers/callees
if they are peers of each other. Such callers/callees provide
the interaction contexts of peer methods for developers to
create an aspect. For example, in Figure 2, for the peer
group related to Undo, XScan reports that they all have a
common interaction method createUndoActivity , even though
those createUndoActivity methods belong to diﬀerent classes.
4.2.2 Aspect Update for an AO program
When an AO program P1is changed into P2, XScan an-
alyzes those two versions to provide two types of updating
recommendations: 1) recommend to create new aspects for
newly detected concern groups, and 2) recommend to add
potentially missing shadows of existing aspects. Let us de-
note the set of aspects in P1byA1and that in P2byA2.
The aspect updating algorithm has four phases (Figure 6):
1. Detect changed and unchanged methods between
P1andP2. First, XScan detects from two versions P1
andP2the sets of unchanged, modiﬁed, deleted, and added
methods. To achieve that, XScan utilizes OAT [17], our
prior origin analysis tool to map the classes and methods
betweenP1andP2via an approximate tree edit algorithm.
2. Detect newly added and existing aspects be-
tweenA1andA2. XScan does this detection on the sets
of aspects between two versions using name mapping. That
is, aspects having the same names are mapped and consid-
ered as existing, while unmapped aspects are considered as
added/deleted. The newly added and existing aspects de-
tected inA2will be used in the update recommendation.
3. Redetect and rank peer groups in P2. SinceP2is
an AO program, XScan uses AJDT and PointcutDoctor to
parse it, and statically adds the method calls in each ad-
vice into the sets of interactions of the respective shadow
methods. This pre-processing step helps in determining the
existence of the cross-cutting concerns which have been fac-
tored out from the concern containers using AOP. Thus, the
collected sets of internal, external, and proxy external inter-
actions of each method of P2might have some method calls
chosen from its advices. Other steps for detecting, group-366System LOC Methods TtotalTcloneTpeer
JHotDraw-60b1 72K 5,259 62s 30s 11s
JEdit-4.3.1 175K 7,414 84s 45s 1s
Columba-1.4 183K 9,293 132s 101s 2s
JFreeChart-1.0.13 217K 8,462 96s 68s 9s
Tomcat-6.0.26 324K 15,804 64s 32s 5s
Jarp-1.0.1 19K 1,335 20s 19s <1s
HealthWatcher 8-10K 551-820 11s 10s <1s
Table 1: XScan Running Time
ing, and ranking peer groups in P2are as similar as those
for non-AO programs (described in Section 4.1).
4. Recommend detected peer groups . XScan matches
each shadow group Sof an aspect in P2(collected in phase
2) to a peer group Xdetected in phase 3. Sis matched to X
if the matching ratio|X∩S|
avg(|X|,|S|)between them is maximal.
Then, XScan recommends relevant peer methods in X\S
as new members of S. IfScorresponds to a newly added
aspect, all methods in X\Sare relevant for the recommen-
dation. Otherwise, only newly added or modiﬁed methods
are considered. Since a method that is more similar to the
shadows in Sis more likely to be its new member, each
recommended peer method xis ranked based on its total
interaction similarity to all methods in S, i.e. its rank is
calculated as R(x) =/summationtext
y∈Ssim(x,y).
After this step, for all detected peer groups having changed
methods that are not mapped to any shadow group, XScan
ranks and recommends them for creating newaspects as the
recommendation for the aspectization process discussed in
Section 4.2.1.
5. EMPIRICAL EVALUATION
This section discusses the empirical evaluation of XScan
on real-world subject systems. All experiments were carried
out on a Windows Vista computer with CPU Intel Core
2 Duo T6500 2.10 GHz and 4GB RAM. We set weighting
parameters for internal, external, and proxy interactions in
Deﬁnition 4 at: α=β= 0.3,γ= 0.4. A little higher weight
for proxy interaction γis used to detect better the cross-
cutting concerns relevant to the methods that interact with
one another via proxy calls. Two thresholds for similarity
of peer methods and contexts in Deﬁnitions 3 and 7 are set
loosely atσ=δ= 0.5 because for aspect recommendation,
more reported concern-related entities are desirable.
5.1 Scalability
In this experiment, we evaluate the scalability of our ap-
proach, measured via the running time of XScan. Sixteen
subject systems were used in the experiment (including ten
versions of HealthWatcher and six other systems - see Ta-
ble 1), with their sizes ranging from 10 to 324 KLOCs, and
their numbers of methods ranging from 1K to 16K. For each
system, we measured the total processing time Ttotal, which
includes the time for code parsing by Eclipse and AspectJ,
detecting code clones Tclone, and detecting and recommend-
ing peer groups Tpeer.
The result shows that XScan is highly scalable. It pro-
cesses most systems in less than 2 minutes. Most processing
time is spent on parsing and detecting clones. Time for
detecting/recommending concern peers is reasonably small.
That shows the eﬀectiveness of our algorithm design.XScan CBFA
Concern Rank Cov. Prec. Fscore Cov. Prec. Fscore
Undo 1 93% 90% 91% 86% 100% 92%
Iterator 2 89% 100% 94% 100% 100% 100%
Persistence 4 93% 100% 96% 100% 80% 89%
Observer 5 100% 97% 98% 80% 86% 83%
Visitor 23 100% 100% 100% 100% 86% 92%
Table 2: Accuracy on JHotDraw’s Popular Concerns
5.2 Accuracy in Aspect Mining
As in previous aspect mining approaches [13, 27], we mea-
sure the correctness of XScan in aspect creation in the aspec-
tization process via precision and coverage on each (cross-
cutting) concern . Precision is deﬁned as the ratio of actual
concern containers in the total recommended ones for that
concern. Coverage is deﬁned as the proportion of correctly
recommended concern containers over the total number of
actual concern containers for that concern. The computa-
tion of coverage is based on individual concern, rather than
on all concerns in a system (such as in recall), because it is
impractical to have an oracle on all possible concerns, espe-
cially in large systems [27]. Note that recall is the ratio of
correctly detected concerns over the total possible concerns.
In aspect recommendation, high coverage would be more
favorable. If a recommended concern container is wrong,
developers could remove it using domain knowledge. In con-
trast, if the tool misses true concern containers, they might
have to manually search through the codebase for such con-
cern containers. Certainly, the tool needs a high level of pre-
cision to reduce annoying recommendations. Thus, we also
useFscore , a measurement that represents a harmonic av-
erage of coverage and precision: Fscore = 2/(1/coverage +
1/precision ). Higher Fscore signiﬁes better accuracy.
5.2.1 Results on Popular Concerns in JHotDraw
First, we evaluated the correctness of XScan on several
widely analyzed and reported cross-cutting concerns in prior
aspect mining research for the subject systems [11, 13, 27].
Table 2 shows the correctness of XScan on ﬁve well-analyzed
cross-cutting concerns in JHotDraw [13, 27]. As shown, XS-
can can achieve a very high level of accuracy with Fscore in
the range of 91%-100%. In 3 out of 5 concerns, XScan has
signiﬁcantly higher Fscore than Cluster-based Fan-In Anal-
ysis approach (CBFA) [27], which was shown to outperform
other state-of-the-art aspect mining approaches [11, 13].
Column Rank shows the ranks of peer groups recommended
for the corresponding concerns. As seen, our ranking mech-
anism of XScan is quite good, because the peer groups rec-
ommended for those concerns have very high ranks. Visitor
is lowly ranked because its member methods are not called
as scattered in the code as the others. For this case, fan-in
and CBFA approaches also cannot rank this concern high,
because the total number of fan-ins (i.e. the total number
of calls to all members in that concern) is small.
5.2.2 Results on Top-10 Concern Groups
To further evaluate XScan, we analyzed the top-10 groups
recommended for JHotDraw. We collected the methods be-
longing to each individual concern in JHotDraw via ana-
lyzing the corresponding aspects realized in AJHotDraw.
Table 3 shows the result for the top ten concern groups.
As seen, XScan also achieves a high level of accuracy (with367XScan CBFA
Concern Cov. Prec. Fscore Cov.
Undo 93% 90% 91% 86%
Iterator 89% 100% 94% 100%
MouseHandler 94% 94% 94% 87%
Persistence 93% 100% 96% 100%
Observer 100% 97% 98% 80%
ConsistentBehavior [new] 100% 100% 100%
FigureSelectionObserver [new] 100% 41% 58%
Draw 100% 88% 94% 92%
HandleInvoke [new] 100% 100% 100%
ManageHandles 100% 100% 100% 75%
Table 3: Top-10 Concern Groups in JHotDraw
System Cov. Prec. Fscore
JEdit 97% 98% 97%
JHotDraw 96% 90% 93%
Columba 96% 98% 97%
JFreeChart 97% 98% 97%
Tomcat 99% 97% 98%
Jarp 99% 100% 99%
Table 4: Accuracy on Top-10 Concern Groups
Fscore mostly above 90%). Since CBFA’s precision is not
available from [27], we compare XScan and CBFA via cov-
erage. XScan has higher coverage than CBFA in 5 out of 7
concerns reported by both tools.
We also evaluated top-100 groups recommended for ﬁve
other subject systems (Table 4). Because some systems have
not been previously studied, we examined the code and rel-
evant documentation to gain the knowledge about them for
the manual analysis of cross-cutting concerns. We used the
same criteria as Zhang et al. [27] to identify concern con-
tainers/implementors. That is, for each recommended peer
group, we collected the methods supporting the same/sim-
ilar purpose or functionality, and ﬁnd in the whole system
other methods with the same purpose/functionality.
Table 5 shows top-10 result for TomCat with Fscore mostly
in the range of 98%-100%. Due to the space limit, we could
not show the result for all systems. Thus, we summarize the
average coverage and precision on each of other systems in
Table 4, which are calculated for all top-10 concerns, rather
than for individual concerns. As shown, for top 10 recom-
mended groups, XScan has very high accuracy, with Fscore
mostly in the range of 97%-99%.
5.2.3 Interesting Cases
Manually examining the reports, we found several inter-
esting cases. Firstly, in JHotDraw, XScan identiﬁed three
new concerns that are not reported by existing approaches:
1)ConsistentBehavior (a concern to activate/deactivate the
drawing views), 2) FigureSelectionObserver (a concern to ob-
serve the selection of ﬁgures), and 3) Handle Invoke (a concern
to invoke actions when the handle of a ﬁgure is selected).
Secondly, XScan is able to detect concern containers that
CBFA can not. For example, in JHotDraw, XScan is able
to detect the methods addand remove belonging to the same
concern FigureSelectionObserver due to their interaction sim-
ilarity. Because CBFA is based on the similarity of fan-ins
and names to cluster candidate concern containers, it could
not group the methods having very dissimilar names (e.g.
add,remove ) into the same concern.Concern Cov. Prec. Fscore
LifeCycle.stop 100% 100% 100%
LifeCycle.start 100% 100% 100%
Valve.invoke 100% 100% 100%
Task.execute 100% 94% 97%
Persistence 94% 100% 97%
LifeCycleListener 100% 100% 100%
MembershipListener 100% 100% 100%
ChannelInterceptor 100% 75% 86%
sendError 98% 100% 99%
JkHandler.invoke 97% 100% 98%
Table 5: Top-10 Concern Groups in TomCat
Version Aspects Added Updated
(1) (2) (3) (1) (2) (3)
v1-v2 11-13 2 4
v2-v3 13-17 4
v3-v4 17-20 3
v7-v8 20-22 2
v8-v9 22-22 7
v9-v10 22-23 1 1
Table 6: Aspect Evolution on HealthWatcher
Thirdly, XScan is also able to distinguish methods hav-
ing the same names and fan-ins, yet belonging to diﬀerent
concerns. For example, in TomCat, based on the interac-
tion similarity, XScan can distinguish two separate groups
of callback methods Valve+.invoke and JkHandler+.invoke into
two concerns. Another example is in Columba in which the
callback methods for diﬀerent Button objects in diﬀerent con-
cerns/purposes must have the same name of actionPerformed
(the callback mechanism requires so). In these cases, CBFA
would incorrectly group all of such methods into a concern
because they have the same name.
5.3 Accuracy in Aspect Updating
5.3.1 Manual Analysis of Aspect Evolution
We manually analyzed existing aspects and the corre-
sponding shadows of HealthWatcher (HW) with 10 versions,
and considered them as the oracle for the evaluation on as-
pect updating. As seen in Table 6, we found two kinds of
changes to aspects from one version to the next version: new
aspects are added , or currently existing aspects are updated
(either by the changes in its advice code, or the changes in
the set of its shadows). In both cases, the aﬀected shadows
might have (1) newly added code only, (2) existing code only,
or (3) both added and existing code. For example, from v1
to v2, HW has two added aspects for newly added code,
while four other aspects are updated for existing shadows.
5.3.2 Results on Update Recommendation
We ran XScan on 10 consecutive versions of HealthWatcher
to evaluate its update recommendation. For each version, if
applicable, XScan recommended two types of action: updat-
ing an existing aspect (U) with new shadows, and/or adding
a new aspect (A). Recommendation for the type U is given
as ranked lists of relevant methods, thus, a method is consid-
ered as correctly recommended ifit was added at the version
of recommendation or at a later version . Evaluation criteria
for the type A are the same as in a non-AO program.
Table 7 shows the result. For a created aspect (Type A),
column Shdrepresents the number of its actual shadows, and368Aspect Change T Shd Rec Cov.
HWClientDistribution v1-v2 U 19 22 100%
HWDistributionExc... v1-v2 U 4 4 100%
HWPersistenceExc... v1-v2 U 4 4 100%
HWTransactionExc... v1-v2 U 4 4 100%
ServletCommanding v1-v2 A 2 2 100%
ComplaintStateAspect v2-v3 A 5 3 60%
HWManagedSynchronization v8-v9 U 3 11 100%
HWClientDistribution v8-v9 U 8 14 100%
HWUpdateObserverExc... v8-v9 U 2 2 100%
UpdateStateObserver v8-v9 U 2 3 100%
ObserverProtocol v8-v9 U 5 29 100%
HWDataCollection v8-v9 U 1 1 100%
HWTransactionManagement v8-v9 U 9 9 100%
HWTimestamp v9-v10 U 1 7 100%
Table 7: Accuracy on Update Recommendation
column Recis the number of recommended peer methods for
that aspect. For an updated aspect (Type U), column Shd
is the number of actual updated shadows from the previ-
ous version, and column Recis the number of top-ranked
peer methods in the recommended list corresponding to the
maximum coverage for that aspect. For example, in the ﬁrst
row, aspect HWClientDistribution was actually updated to ad-
vise additional 19 shadows, which all belong to the top 22
peer methods in the ranked list recommended by XScan.
That is, the coverage is 100% with only 3 incorrect ones.
As shown, XScan always achieves 100% coverage for all
updated aspects with a reasonable cutpoint for top ranking.
Thus, in most cases, the number of methods that need to be
examined to get all actual shadows is acceptable. The worst
case is for aspect ObserverProtocol : one needs to examine up
to 29 methods for 5 actual shadows. Some aspects in Table 6
are not recommended because they contain single shadows.
5.3.3 Interesting Cases
There are some cases in which XScan correctly recom-
mends the shadows before they are actually added into the
corresponding aspects. For example, aspect HWTimestamp
was created at v1 and advised two methods insert and up-
date of class ComplaintRepositoryRDB . The method search of
this class also existed at v1. However, it was not added
as a shadow of HWTimestamp until v10. XScan detects the
peer relation of methods insert ,update , and search right at v1.
Thus, XScan could provide an early and useful update, and
help to avoid missing shadows.
In some other cases, XScan did not need to provide recom-
mendation for creating aspects because those aspects advise
only unchanged shadows, which have been recommended at
a prior version. For example, aspect ComplaintStateAspect is
created at v3 (see Example 4) but three of its ﬁve shadows
have been reported as a peer group since v1. Similarly, at v4,
three aspects HWUpdateObserverExceptionHandler ,UpdateSta-
teObserver , and ObserverProtocol are created to advise a group
of three methods. However, those three methods belong to
a peer group which has been recommended at v2. Moreover,
at v8, two aspects HW*Distribution were refactored: two new
aspects RMI* were added as their children aspects, and one
pointcut was moved from the parent aspect to the children
ones. Via AJDT/PointcutDoctor, XScan ﬁnds no changes
in the corresponding shadows, thus, provides no suggestion.
Those cases show that, in practice, XScan could provideearly and useful recommendations for creating new aspects,
thus, help avoid missing implementations of concerns.
There are two cases that XScan missed providing recom-
mendation for creating new aspects. At v2, aspect Exception-
HandlingPrecedence is created to “guarantee that Exception
Handling happens around the Command pattern”. XScan
was able to detect two smaller concern groups for Exception-
Handler and Command , however, found no matched peer group
forExceptionHandlingPrecedence since it is related to methods
in two groups with interaction similarity less than the chosen
threshold. Similarly, at v3, three new aspects are created,
each for a pair of methods (see Example 4). The interaction
similarity between each pair is also not suﬃciently large.
Our aspect updating technique is evaluated in one sub-
ject system. Thus, this threat to validity could aﬀect its
generalization. We plan to evaluate it in other AO systems.
6. RELATED WORK
Aspect Mining. Several approaches have been proposed
for mining cross-cutting concerns. Closely related work to
XScan is fan-in analysis [13]. Its underlying philosophy is
that a method that is called many times is likely to be a
cross-cutting concern. However, fan-in analysis provides
only sets of methods with high fan-ins. Sometimes, those
methods might be unrelated. XScan focuses on internal/ex-
ternal interactions including method calls and their contexts,
and groups related methods by their similar interactions.
Other related work is Cluster-based fan-in (CBFA) anal-
ysis [27], which combines fan-in approach with name-based
clustering to group methods with similar names into a con-
cern. As shown in Section 5, name-based clustering would
miss the methods that share the same cross-cutting concern
but have very dissimilar names. CBFA would incorrectly
group unrelated methods with the same required name, for
example, in the callback functions in graphical user inter-
face libraries (e.g. actionPerformed ). CBFA counts only the
number of fan-ins. XScan looks into interaction similarity
with contextual information as well, thus, overcomes those
problems. More importantly, fan-in and CBFA approaches
do not support aspect updating. Those approaches do not
focus on similar interactions of concern containers. For the
shadows of an aspect (e.g. after advice code is factored out
of a concern container), XScan still can recognize (at least)
the external interactions among shadows, thus, can use in-
teraction similarity for aspect updating.
Clone detection is also used as a technique to determine
similar code that could be factored out into aspects. Bruntink
et al. [4] conﬁrm that crosscutting functionality is often im-
plemented by similar code fragments. Shepherd et al. [21]
use both Program Dependence Graph-based and AST-based
clone detection for aspect mining. XScan focuses not only on
internal interactions as in those approaches, but also on ex-
ternal interactions . As shown earlier, several concern peers
interact similarly with other parts of the system, despite the
diﬀerences in their internal code.
Other aspect mining methods utilize lexical andtext-based
analysis [9, 24]. Those methods face the same problem as
the name-based method in CBFA because they lack the deep
analysis on program semantics such as interaction analy-
sis in XScan. Speciﬁcally, Tourwe and Mens [24] use for-
mal concept analysis and similar identiﬁer analysis to mine
structurally related classes/methods in an aspect. Aspect
Browser [9] identiﬁes concerns with lexical pattern match-369ing for querying the code. Aspect Mining Tool [10] com-
bines textual approach with structural search for type us-
ages. PRISM [26] supports mining of activity-oriented as-
pects by lexical and type-based patterns. Action-oriented
relations between identiﬁers are captured with queries over
a program model in [20]. The idea of concern peers is in-
spired from code peers for preventing recurring bugs [15].
FEAT [19], a feature exploration and analysis tool, starts
with a concern seed and allows developers to query several
relations among classes/methods. Relevant entities form a
concern graph. Concern graphs do not take into account
peer interactions among methods as in XScan. As shown
earlier, several methods in the same aspect contain the calls
topeermethods, but not exactly to the same methods.
Other aspect mining approaches rely on mining version
repositories. Breu and Zimmermann [7] introduce an aspect
mining approach by analyzing how fan-ins change over time.
Via mining version history, Adams et al. [3] analyze how
code changes together to identify cross-cutting concerns.
Some aspect mining approaches are dynamic [6, 12] or
hybrid [5]. Krinke [12] uses CFGs to ﬁnd recurring execution
patterns. DynAMiT [6] analyzes execution traces to ﬁnd
patterns of calls. Dynamo [23] utilizes concept analysis to
ﬁnd relations between traces and executed code units.
Concern Management. There exist several approaches
on aspect tracking and management. Dagenais et al. [8]
propose an approach to trace concerns in evolving software
via inferring structural patterns . In contrast, XScan main-
tains the concern peer relations among code units and uses
them to suggest the update for aspects as software changes.
An empirical study on tracing concerns was reported in [18].
7. CONCLUSIONS
This paper investigates the common characteristics of cross-
cutting concerns, and ﬁnds that most of the concern contain-
ers are concern peers, i.e. methods having similar roles with
similar interactions to others in a system. We developed
several techniques to identify, rank, and recommend con-
cern peers as concern containers, both in the aspectization
process with aspect mining support and in the evolution of
AO programs with aspect updating support. Our evaluation
showed that our approach achieves high level of accuracy in
recommendation of both aspect creating and updating.
Acknowledgment. This project is funded by NSF CCF-
1018600 award. It was also funded in part by Vietnam Ed-
ucation Foundation for the ﬁrst and second authors.
8. REFERENCES
[1] A. Andoni and P. Indyk. E2LSH 0.1 User Manual.
http://web.mit.edu/andoni/www/LSH/manual.pdf.
[2] AspectJ Development Tools. www.eclipse.org/ajdt/.
[3] B. Adams, Z. M. Jiang, and A. E. Hassan. Identifying
crosscutting concerns using historical code changes. In
ICSE 2010 , pages 305–314. ACM Press, 2010.
[4] M. Bruntink, A. van Deursen, T. Tourwe, and R. van
Engelen. An evaluation of clone detection techniques
for identifying crosscutting concerns. In ICSM’04 .
[5] S. Breu. Extending dynamic aspect mining with static
information. In SCAM’05 , pp. 57–65. IEEE CS, 2005.
[6] S. Breu and J. Krinke. Aspect mining using event
traces. In ASE’04 , pages 310–315. IEEE CS, 2004.[7] S. Breu and T. Zimmermann. Mining aspects from
version history. In ASE’06 , pp. 221–230. IEEE, 2006.
[8] B. Dagenais, S. Breu, F. W. Warr, and M. P.
Robillard. Inferring structural patterns for concern
traceability in evolving software. In ASE’07 , pages
254–263. ACM Press, 2007.
[9] W. G. Griswold, J.J. Yuan, and Y. Kato. Exploiting
the map metaphor in a tool for software evolution. In
ICSE’01 , pages 265–274. IEEE CS, 2001.
[10] J. Hannemann and G. Kiczales. Overcoming the
prevalent decomposition of legacy code. In Workshop
on Advanced Separation of Concerns , 2001.
[11] T. Ishio, H. Date, T. Miyake, K. Inoue. Mining coding
patterns to detect crosscutting concerns in Java
programs. In WCRE’08 , pp. 123–132. IEEE CS, 2008.
[12] J. Krinke. Mining control ﬂow graphs for crosscutting
concerns. In WCRE’06 , pp. 334–342. IEEE CS, 2006.
[13] M. Marin, A. van Deursen, and L. Moonen.
Identifying crosscutting concerns using fan-in analysis.
ACM Transactions on Software Engineering and
Methodology , 17(1):1–37, 2007.
[14] M. Marin, L. Moonen, and A. van Deursen. An
integrated crosscutting concern migration strategy and
its application to JHotDraw. In SCAM’07 . IEEE CS.
[15] T.T. Nguyen, H.A. Nguyen, N. H. Pham, J. M.
Al-Kofahi, and T. N. Nguyen. Recurring bug ﬁxes in
object-oriented programs. In ICSE’10 . ACM, 2010.
[16] T.T. Nguyen, H.A. Nguyen, N. H. Pham, J. M.
Al-Kofahi, and T. N. Nguyen. Clone-aware
conﬁguration management. In ASE’09 . ACM, 2009.
[17] H.A. Nguyen, T.T. Nguyen, G. Wilson, Jr., A.
Nguyen, M. Kim, T. N. Nguyen. A Graph-based
approach to API usage adaptation. In OOPSLA’10 .
[18] M. P. Robillard. Tracking concerns in evolving source
code: An empirical study. In ICSM’06 . IEEE, 2006.
[19] M. P. Robillard and G. C. Murphy. Concern graphs:
ﬁnding and describing concerns using structural
program dependencies. In ICSE’02 . ACM Press, 2002.
[20] D. Shepherd, Z. Fry, E. Hill, L. Pollock,
K. Vijay-Shanker. Using natural language program
analysis to locate and understand action-oriented
concerns. In AOSD’07 , pp. 212–224. ACM Press, 2007.
[21] D. Shepherd, E. Gibson, and L. Pollock. Design and
evaluation of an automated aspect mining tool.
Software Engineering Research and Practice , 2004.
[22] P. Tarr, H. Ossher, W. Harrison, and S.M. Sutton, Jr.
N degrees of separation: multi-dimensional separation
of concerns. ICSE ’99 , pp. 107–119. ACM Press, 1999.
[23] P. Tonella and M. Ceccato. Aspect mining through
the formal concept analysis of execution traces. In
WCRE’04 , pages 112–121. IEEE CS, 2004.
[24] T. Tourwe and K. Mens. Mining aspectual views using
formal concept analysis. In SCAM’04 . IEEE CS, 2004.
[25] L. Ye and K. De Volder. Tool support for
understanding and diagnosing pointcut expressions. In
AOSD’08 , pages 144-155. ACM Press, 2008.
[26] C. Zhang and H.-A. Jacobsen. PRISM is research in
aspect mining. In OOPSLA’04 . ACM Press, 2004.
[27] D. Zhang, Y. Guo, and X. Chen. Automated aspect
recommendation through clustering-based fan-in
analysis. In ASE’08 , pages 278–287. IEEE CS, 2008.370