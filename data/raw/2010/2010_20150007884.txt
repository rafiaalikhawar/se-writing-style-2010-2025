Statistical Symbolic Execution with Informed Sampling
Antonio Filieri
University of Stuttgart
Stuttgart, GermanyCorina S. P ÀòasÀòareanu
Carnegie Mellon Silicon Valley,
NASA Ames
Moffet Field, CA, USAWillem Visser and
Jaco Geldenhuys
Stellenbosch University
Stellenbosch, South Africa
ABSTRACT
Symbolic execution techniques have been proposed recently for the
probabilistic analysis of programs. These techniques seek to quan-
tify the likelihood of reaching program events of interest, e.g., as-
sert violations. They have many promising applications but have
scalability issues due to high computational demand. To address
this challenge, we propose a statistical symbolic execution tech-
nique that performs Monte Carlo sampling of the symbolic program
paths and uses the obtained information for Bayesian estimation
and hypothesis testing with respect to the probability of reaching
the target events. To speed up the convergence of the statistical
analysis, we propose Informed Sampling, an iterative symbolic ex-
ecution that Ô¨Årst explores the paths that have high statistical signif-
icance, prunes them from the state space and guides the execution
towards less likely paths. The technique combines Bayesian esti-
mation with a partial exact analysis for the pruned paths leading to
provably improved convergence of the statistical analysis.
We have implemented statistical symbolic execution with in-
formed sampling in the Symbolic PathFinder tool. We show exper-
imentally that the informed sampling obtains more precise results
and converges faster than a purely statistical analysis and may also
be more efÔ¨Åcient than an exact symbolic analysis. When the latter
does not terminate symbolic execution with informed sampling can
give meaningful results under the same time and memory limits.
Categories and Subject Descriptors
D.2.4 [ Software Engineering ]: Software/Program VeriÔ¨Åcation‚Äî
Model checking, Reliability, Statistical methods
1. INTRODUCTION
Several techniques have been proposed recently for the proba-
bilistic analysis of programs [ 2,9,10]. These techniques have
multiple applications, ranging from program understanding and de-
bugging to computing reliability of software operating in uncertain
environments.
For example, in previous work [ 9,10], we described a bounded
symbolic execution of a program that uses a quantiÔ¨Åcation proce-
dure over the collected symbolic constraints to compute the counts
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.of the inputs that follow the explored program paths. These counts
are then used to compute the probability of executing different
paths through the program (or of violating program assertions), un-
der given probabilistic usage proÔ¨Åles. While promising, these exact
techniques have scalability issues due to the large number of sym-
bolic paths to be explored.
To address this problem we describe a statistical symbolic ex-
ecution technique that uses randomized sampling of the symbolic
paths. For deciding termination of sampling we investigate two dif-
ferent criteria: Bayesian estimation and hypothesis testing [ 11,23].
The Ô¨Årst is used to estimate the probability of executing designated
program paths while the latter is used to test a given hypothesis
about such probability. Unlike in a typical statistical setting where
one samples randomly across a concrete input domain, our samples
are done in the context of symbolic execution, according to condi-
tional probabilities computed at each branching point in the pro-
gram. This approach is similar to statistical model checking [ 33,
35], with the difference that we work with code not with models
and we sample symbolic paths, where the probabilistic information
is computed based on the collected symbolic constraints.
When using Bayesian estimation, the randomized sampling ter-
minates when pre-speciÔ¨Åed conÔ¨Ådence and error bounds (accuracy)
have been achieved. The answer to the analysis problem is not
guaranteed to be correct, but the probability of a wrong answer can
be made arbitrarily small [ 35]. However, in practice, the conver-
gence to an answer might be very slow. Hypothesis testing can be
faster [ 35], but both techniques may require a very large number of
sample paths to achieve the desired statistical conÔ¨Ådence.
To speed up both methods, we propose Informed Sampling (IS),
an iterative technique combining statistical methods with partial ex-
act analysis. At each iteration, IS randomly samples a set of exe-
cution paths and performs a statistical analysis of the sample. The
probability of sampling each path is proportional to the number of
input points following it under the speciÔ¨Åed usage proÔ¨Åle so not
to bias the sample. If the statistical method converged, its result
is returned. Otherwise the already sampled paths are pruned out
from the execution tree and analyzed exactly. The next iteration
will then focus on the analysis of only the remaining part of the
execution tree, increasing also the chances of selecting low proba-
bility paths that might have not been sampled (and pruned) during
the previous iterations.
For pruning the sampling space we propose an efÔ¨Åcient proce-
dure that leverages the counts of the inputs associated with each ex-
plored symbolic path and subtracts them from the counts of all the
preÔ¨Åxes along the path. The intuition is that, at the end of each iter-
ation, the counts should keep track of the number of inputs that still
need to be explored (sampled) for the execution to follow that path.
The counts keep decreasing with each iteration and if a counter be-comes 0 it means that the sub-tree rooted at that node has been fully
explored and can be safely pruned from the search space.
For estimating the probability results we propose a combination
of exact analysis (for the paths that are pruned in previous itera-
tions) and Bayesian statistical analysis (for the paths sampled in
the current iteration over the pruned state space). The analysis ter-
minates when the pre-speciÔ¨Åed conÔ¨Ådence and error bounds have
been achieved (for Bayesian estimation) or when the hypothesis is
conÔ¨Årmed (for hypothesis testing). The analysis may also terminate
when all the paths have been explored, in which case the results will
be the same as for the exact analysis. IS converges faster and re-
quires fewer samples than the purely random sampling techniques,
since the set of samples is different with each iteration and each
pruned path set is analyzed exactly (with conÔ¨Ådence 1). Further-
more, the probability of Ô¨Ånding the target program events increases
with each iteration.
The main focus of this work is on computing non-functional
properties of programs, such as the probability of successful ter-
mination (or conversely the probability of failure) under a given
usage proÔ¨Åle [ 9]. However, statistical symbolic execution with IS
can also be used for improving ‚Äúclassical‚Äù (non-probabilistic) sym-
bolic execution, in the sense that, if symbolic execution runs out
of resources (time, memory) the statistical techniques can be used
to provide useful information with statistical guarantees. Note also
that the statistical techniques provide an ‚Äúany time‚Äù approach to
software analysis: the longer they run, the better the results.
We make the following contributions:
statistical symbolic execution with two stopping criteria
(Bayesian estimation and hypothesis testing) and implemen-
tation within the Symbolic PathFinder tool [ 22];
IS that converges faster than Monte Carlo sampling;
an efÔ¨Åcient procedure for pruning the state space for incre-
mental symbolic execution;
combined statistical and exact information for (1) Bayesian
estimation and (2) hypothesis testing;
experimental evidence showing the improvement of IS over
state-of-the-art statistical approaches.
2. BACKGROUND
2.1 Symbolic Execution
Symbolic execution is an extension of normal execution in which
the semantics of the basic operators of a language is extended to
accept symbolic inputs and to produce symbolic formulas as out-
put [15]. The behavior of a program Pis determined by the values
of its inputs and can be described by means of a symbolic execu-
tion tree where tree nodes are program states and tree edges are
the program transitions as determined by the symbolic execution
of program instructions.
The state sof a program is deÔ¨Åned by the tuple (IP;V;PC)where
IPrepresents the next instruction to be executed, Vis a mapping
from each program variable vto its symbolic value (i.e., a sym-
bolic expression in terms of the symbolic inputs), and PCis apath
condition .PCis a conjunction of constraints over the symbolic
inputs that characterizes exactly those inputs that follow the path
from the program‚Äôs initial state to state s.
The current state sand the next instruction IPdeÔ¨Åne the set of
transitions from s. Without going into the details of every Java
instruction, we informally deÔ¨Åne these transitions depending on the
type of instruction pointed to by IP.Assignment . The execution of an assignment to variable v2V
leads to a new state where IPis incremented to point to the next
instruction and Vis updated to map vto its new symbolic value.
PCdoes not change.
Branch . The execution of an if-then-else instruction on condi-
tioncintroduces two new transitions. The Ô¨Årst leads to the state s1
where IP1points to the Ô¨Årst instruction of the then block and the
path condition is updated to PC1=PC^c. The second leads to a
state s2where IP2points to the Ô¨Årst instruction of the elseblock and
the path condition is updated to PC2=PC^:c. If the path con-
dition associated with a branch is not satisÔ¨Åable, the new transition
and state are not added to the symbolic execution tree.
Loop . Awhile loop is unrolled until its condition evaluates to
false or a pre-speciÔ¨Åed exploration depth limit is reached. Analo-
gous transformations are applied to other loop constructs.
The initial state of a program is s0= (IP0;V0;PC0), where IP0
points to the Ô¨Årst instruction of the main method, V0maps the argu-
ments of main (if any) to fresh symbolic values, and PC0=true. A
program may also have one or more terminal states that represent
conditions such as the successful termination of the program or an
uncaught exception that aborts the program execution abruptly.
Although our approach can be customized for any symbolic ex-
ecution system, we focus on Symbolic PathFinder (SPF) [ 22] that
works at the Java bytecode level.
2.2 Probability Theory
The possible outcomes of an experiment are called elementary
events . For example, the rolling of a 6-sided die may produce the
elementary events 1, 2, 3, 4, 5, and 6. Elementary events have to be
atomic , i.e., the occurrence of one of them excludes the occurrence
of any other. The set of all elementary events is called a sample
space . In this paper, we consider only Ô¨Ånite and countable sam-
ple spaces, meaning that the underlying set of elementary events is
countable and Ô¨Ånite.
DEFINITION 1 (P ROBABILITY DISTRIBUTION ).Let‚Ñ¶be
the sample space of an experiment. A probability distribution on
‚Ñ¶is any function Pr :P(‚Ñ¶)![0;1]Rthat satisÔ¨Åes the follow-
ing conditions (probability axioms):
Pr(fxg)0for every elementary event x
Pr(‚Ñ¶) =1
Pr(A[B) =Pr(A) +Pr(B)for all events A ;B with A\B=/ 0
The pair (‚Ñ¶;Pr)constitutes a probability space .
DEFINITION 2 (C ONDITIONAL PROBABILITY ).Let (‚Ñ¶;Pr)
be a probability space. Let A and B be events (A;B‚Ñ¶), and
let Pr (B)Ã∏=0. The conditional probability of the event A given that
the event B occurs, is:
Pr(AjB) =Pr(A\B)
Pr(B)
Pr(AjB)is also referred to as the probability of Agiven B.
DEFINITION 3 (L AW OF TOTAL PROBABILITY ).Let(‚Ñ¶;Pr)
be a probability space and fBn:n=1;2;3;:::gbe a Ô¨Ånite partition
of‚Ñ¶. Then, for any event A:
Pr(A) =√•
nPr(AjBi)Pr(Bi)
The law of total probability can also be stated for conditional
probabilities:
Pr(AjX) =√•
nPr(AjX\Bi)Pr(BijX)
where Biare deÔ¨Åned as in DeÔ¨Ånition 3andXdoes not invalidate
the assumptions of DeÔ¨Ånition 2.2.3 Probabilistic Analysis
We follow previous work [ 9] where we deÔ¨Åned a symbolic exe-
cution framework for computing the probability of successful ter-
mination (and alternatively the probability of failure) for a Java
software component placed in a stochastic environment. A failure
can be any reachable error, such as a failed assertion or an uncaught
exception. For simplicity, we assume the satisfaction of target pro-
gram properties to be characterized by the occurrence of a target
event, but our work generalizes to bounded LTL properties [ 35].
To deal with loops, we run SPF using bounded symbolic exe-
cution, i.e., a bound is set for the exploration depths. The result
of symbolic execution is then a Ô¨Ånite set of paths, each with a path
condition. Some of these paths lead to failure, some of them to suc-
cess (termination without failure) and some of them lead to neither
success nor failure (they were interrupted because of the bounded
exploration) ‚Äì the latter are called grey paths.
The path conditions produced by SPF consequently form three
sets: PCs=fPCs
1;PCs
2;:::; PCsmg,PCf=fPCf
1;PCf
2;:::; PCf
pg
andPCg=fPCg
1;PCg
2;:::; PCg
qg, according to whether they lead
to success, failure, or were truncated. Note that the path conditions
are disjoint and cover the whole input domain. In other words, the
three sets form a complete partition of the input domain [ 15,22].
Not all input values are equally likely, and we employ a usage
proÔ¨Åle to characterize the interaction of the software and the envi-
ronment. It maps each valid combination of inputs to the probabil-
ity with which it may occur. In [ 9] we provide an extensive treat-
ment of usage proÔ¨Åles and how they are used for the probabilistic
computations. For simplicity, and without loss of generality, we
will assume here that the usage proÔ¨Åle is embedded in the code.
This can be done with every usage proÔ¨Åle where the probabilities
piare described by arbitrary precision, rational numbers. More
general usage proÔ¨Åles, such as Markov Chains, can be embedded
as well; they are analyzed in a bounded way.
Given the output of SPF, and assuming the constraints from the
usage proÔ¨Åle have been embedded in the code, the probability of
success is deÔ¨Åned as the probability of executing program Pwith
an input satisfying any of the successful path conditions (recall the
path conditions are disjoint):
Prs(P) =√•
iPr(PCs
i) (1)
The failure probability Prf(P)and ‚Äúgrey‚Äù probability Prg(P)have
analogous deÔ¨Ånitions; it is straightforward to prove that Prs(P) +
Prf(P) +Prg(P) =1.Prg(P)can be used to quantify the impact
of the execution bound on the quality of the analysis (1  Prg(P)).
In this paper we focus on sequential programs with integer in-
puts. In other work we provide treatment of multi-threading [ 18],
input data structures [ 9], and Ô¨Çoating-point inputs [ 2] (see Sec-
tion7).
2.3.1 QuantiÔ¨Åcation Procedure
We compute the probabilities of path conditions using a quantiÔ¨Å-
cation procedure (e.g., [ 6,9,10]) for the path conditions. We use
LattE [ 6] to count models for linear integer constraints but our work
generalizes straightforwardly to other tools such as QCoral [ 2] (for
arbitrary Ô¨Çoating point constraints) and Korat [ 3] (for heap data
structures; see [ 9] for details).
Given a Ô¨Ånite integer domain D, model counting allows us to
compute the number of elements of Dthat satisfy a given constraint
c; we denote this number by ‚ôØ(c)(a Ô¨Ånite non-negative integer). By
deÔ¨Ånition [ 20],Pr(c)is‚ôØ(c)=‚ôØ(D)(where ‚ôØ(D)is the size of the
domain implicitly assumed to be greater than zero).
The success probability (or failure or grey probability) can thens0:true [109]
s1:x50[50106] s2:x>50[950106]
s3:xÃ∏=500^x>50[949106] s4:x=500^x>50[106]
Figure 1: Partial symbolic execution tree of the example.
be computed using model counting as follows.
Prs(P) =√•
iPr(PCs
i) =√•i‚ôØ(PCs
i)
‚ôØ(D)(2)
3. EXAMPLE
In this section we illustrate the proposed techniques with a sim-
ple example. Consider the code in Listing 1. Assume the goal is to
estimate the success probability of the method test, i.e., the proba-
bility of not reaching line 6, where an exception would be raised.
Assume the input variables x,y, and zrange over the integer do-
main [1::1000 ]. The size of the input domain is 103103103=109
points. In practice the domains can be much larger. Note that the
size of the domain does not affect the complexity of the counting
procedure, which only depends on the number of input variables
and the number of constraints [ 6,28].
Listing 1: Illustrative example
1void test( int x,int y,int z) {
2 if(x<=50) {
3 // Do some work
4 }else {
5 if(x==500 && y==500 && z==500){
6 assert false ;
7 }
8 // Do more work
9 }
10}
Assuming a uniform usage proÔ¨Åle, the probability of hitting the
failure ( assert false ) is 10 9, since there is only one point in the
input domain that can lead to failure.
To illustrate how sampling works, consider Figure 1, where a
part of the symbolic execution tree of Listing 1is reported. For
each branching point (represented as a node) we show both the path
condition and the corresponding counter in square brackets. These
counters are initially computed by LattE as the paths are explored,
and stored for re-use. The Ô¨Årst time a branch is encountered, the
counters are used to compute the probability of each alternative,
and a randomized choice is made accordingly (see Section 4). For
example, the probability of moving from s2tos3is 949 =950; the
number of points satisfying PCats3is 949106while the number
of those satisfying PCats4is 106, which together sum up to the
number of points in PCat the parent state s2. In our approach, a
second simulation run would reuse this computation, making re-
peated sampling efÔ¨Åcient.
Statistical symbolic execution with IS starts the Ô¨Årst iteration by
performing a small number of samples, as dictated by the proba-
bilities of the branching conditions. Assume for simplicity that at
the end of the Ô¨Årst iteration, only the path s0!s2!s3has been
taken (perhaps multiple times); this is reasonable since the tran-
sitions along this path have signiÔ¨Åcantly higher probabilities than
their peers. The counter for the Ô¨Ånal PCalong this path is 949 106.
This number is then subtracted from all the counters upward alongs0:true [51106]
s1:x50[50106] s2:x>50[106]
s3:xÃ∏=500^x>50[0] s4:x=500^x>50[106]
Figure 2: Symbolic execution tree: counters updated after one iter-
ation
s0:true [106]
s1:x50[0] s2:x>50[106]
s3:xÃ∏=500^x>50[0] s4:x=500^x>50[106]
Figure 3: Symbolic execution tree: counters updated after two iter-
ations; only one path left to explore.
the path, yielding the updated counters in Figure 2. A new iteration
begins, where the sampling is now guided by the updated values of
thePCcounters. Note that in this iteration, the transition from s2to
s3can never be taken, since its counter is 0. At the same time no-
tice that the probability of following the path leading to the subtree
containing the error (rooted at s4) has increased from 1 =103in the
Ô¨Årst iteration to 1 =51 in the second iteration.
Assuming the more likely path s0!s1is sampled in the second
iteration, the counters are updated according to the numbers shown
in Figure 3. In this last iteration, the only remaining path s0!
s2!s4is taken, leading to the exploration of the subtree containing
the assert violation. Monte Carlo sampling without pruning would
miss the path leading to the violation, unless an infeasibly large
number of samples were taken. For example, after 20000 samples
the error is still undetected.
After each iteration we also combine the information obtained
from an exact analysis of pruned paths and a Bayesian inference
over sampled paths (over the pruned state space) to determine if
enough evidence was collected about the probabilities of the events
of interest. For simplicity we omit the details for this example but
we will describe this at length later in the paper.
4. STATISTICAL SYMBOLIC EXECU-
TION
We Ô¨Årst describe Statistical Symbolic Execution, which com-
putes an approximate solution to the probability of success (or fail-
ure) of a program, based on sampling carefully chosen program
paths. Informed Sampling will be described in the next section.
The basic idea is to address the probability computation as a sta-
tistical inference problem. First, a randomized sampling procedure
generates a Ô¨Ånite number of simulation runs and classiÔ¨Åes each of
them as either satisfying or violating a given property œï(e.g., an
assertion in the code). Second, suitable statistical methods are ap-
plied to either estimate the probability of œïfrom an analysis of the
samples or to test a hypothesis about this probability.
Similar techniques have already been explored in the literature
on statistical model checking [ 33,35], which typically phrase thestatistical inference problem in the context of formal veriÔ¨Åcation of
probabilistic models, i.e., transition systems annotated with proba-
bilities such as Markov Chains or Markov Decision Processes.
We describe here how we adapted Bayesian statistical tech-
niques [ 35] in the context of symbolic execution of Java programs,
where no model is assumed and the probabilistic information is
derived via model counting over the symbolic constraints (in com-
bination with the usage proÔ¨Åle).
4.1 Monte Carlo Sampling of Symbolic Paths
Typically, a Monte Carlo method deÔ¨Ånes the solution of the prob-
lem as the parameter of a hypothetical population, and then gener-
ates a random set of samples from which statistical estimates of this
parameter can be obtained [ 12,24].
In the context of symbolic execution, we deÔ¨Åne a sample as the
simulation of one symbolic path. Whenever a branch is encoun-
tered during such simulation, the decision to proceed along either
of the alternative branches has to be taken according to the proba-
bility of satisfying the corresponding branch conditions under the
current usage proÔ¨Åle.
Every time a condition is encountered, the simulation has to de-
cide whether to follow the true or the false branch. In particular let
PCbranch be the path condition at the current state, and let cbe the
branching condition at that state. The path condition after taking
the ‚Äúthen‚Äù branch is PCthen=c^PCbranch while the path condition
after taking the ‚Äúelse‚Äù branch is PCelse=:c^PCbranch .
Similar to [ 10] we associate to each of PCbranch ,PCthen, and
PCelsea counter of the number of points in the input domain satis-
fying the path condition, identiÔ¨Åed by C(PCbranch ),C(PCthen)and
C(PCelse), respectively. The Ô¨Årst time a path condition PCis en-
countered, its counter is initialized through model counting to the
number of points of the input domain that satisÔ¨Åes PC:Ci=‚ôØ(PC).
After its initialization, the value of each counter is stored and reused
through the simulation process.
We can compute the branch probabilities as follows:
pthen=‚ôØ(c^PCbranch )
‚ôØ(PCbranch )=C(PCthen)
C(PCbranch )
pelse=‚ôØ(:c^PCbranch )
‚ôØ(PCbranch )=C(PCthen)
C(PCbranch )(3)
From Equation ( 3) it is straightforward to note that ‚ôØ(PCthen) +
‚ôØ(PCelse) =‚ôØ(PCbranch )andpthen+pelse=1 .
The decision whether to take the then or the elsebranch can now
be taken randomly according to their respective probabilities pthen
andpelse. It remains to show that making the sampling choices
locally at each branch is equivalent to making the choices over the
complete PC, i.e., we do not introduce any statistical bias. This is
implied by the following result:
THEOREM 1.For a path with PC =c1^c2^:::^cnand the
branching conditions encountered in the given order, the path prob-
ability given by Pr(PC) is equal to the product of the conditional
probabilities at each branch given by Pr (c1jtrue)Pr(c2jc1)
Pr(c3jc2^c1):::Pr(cnjcn 1^:::^c1).
PROOF .From Section 2.3.1 we have that Pr(PC) =‚ôØ(PC)
‚ôØ(D)where
D is the complete Ô¨Ånite domain and from Equation 3we can rewrite
the product of conditional probabilities as
‚ôØ(c1)
‚ôØ(D)‚ôØ(c1^c2)
‚ôØ(c1)‚ôØ(c1^c2^c3)
‚ôØ(c1^c2):::‚ôØ(c1^:::^cn)
‚ôØ(c1^:::^cn 1)
which is equal to‚ôØ(c1^:::^cn)
‚ôØ(D)=Pr(PC).4.2 Bayesian Inference and Stopping Criteria
The samples generated by the Monte Carlo simulation described
in the previous section need to be analyzed to estimate the prob-
ability mof the program to satisfy a given property œï. Bayesian
statistical techniques exploit Bayes‚Äô theorem to update the prior
information on the probability mafter every observed sample. The
prior is a probability distribution that summarizes all the available
information (including its lack) gathered through sampling [ 7,17].
As explained in [ 35], a prior for mcan be formalized via the Beta
distribution B(a;b)(see details in [ 11,23,35]). By setting aand
bit is possible to specify the initial assumption about mas follows.
Assume the software engineer has an initial guess Àúmabout m, for
example based on the analysis of previous versions of the software
or on the quality of third-party components involved. One way of
encoding such knowledge as a prior distribution is:
{
a=ÀúmNp
b= (1 Àúm)Np(4)
where Np1 represents the ‚Äútrust‚Äù on Àúmas if it was observed on Np
samples. If no initial information is available, a ‚Äúnon-informative‚Äù
prior can be used, such as B(1=2;1=2)[23]. The meaning is that
we give the same chance (1 =2) to both possible outcomes, and we
give small trust to it. We treat grey paths either optimistically or
pessimistically , meaning that they are considered as either success
or failure, as desired by the user.
When new samples are gathered, they are used to update the
prior, leading to the construction of the posterior distribution. In
particular, if nsamples have been collected with nsof them satisfy-
ingœï, the parameters a‚Ä≤andb‚Ä≤of the posterior distribution will be
computed as:
{
a‚Ä≤=a+ns
b‚Ä≤=b+n ns(5)
This information can then be used for statistical estimation or
hypothesis testing as explained below.
4.2.1 Bayesian Estimation
We use Bayesian estimation [ 11,23] to compute a value that is
close to mwith high probability. More precisely, we compute an
estimate ÀÜmBsuch that:
Pr(ÀÜmB emÀÜmB+e)d (6)
where e>0 is the accuracy and 0 <d<1 is the conÔ¨Ådence ; the
accuracy determines how close the estimate has to be to the real
unknown mand the conÔ¨Ådence expresses how much this result can
be trusted [ 35].
Recalling that the posterior has a Beta distribution, with param-
etersa‚Ä≤andb‚Ä≤, Equation ( 6) can be restated as:
FB(a‚Ä≤;b‚Ä≤)(ÀÜmB+e) FB(a‚Ä≤;b‚Ä≤)(ÀÜmB e)d (7)
where FB(a‚Ä≤;b‚Ä≤)()is the cumulative distribution function of the
posterior distribution, i.e., it computes the probability for a random
variable distributed according to the posterior to assume a value
less than or equal to the argument [ 20].
From the correctness of Bayesian estimation [ 11,23] (i.e., it al-
ways converges to the real value of mafter enough samples are col-
lected), Equation ( 7) can be used as a sequential stopping criterion
to decide how many samples are needed to achieve the accuracy
and conÔ¨Ådence goals.
If the estimation converges with the prescribed accuracy and
conÔ¨Ådence, the estimate ÀÜmBis deÔ¨Åned as the expected value of theposterior distribution:
ÀÜmB=a‚Ä≤
a‚Ä≤+b‚Ä≤(8)
An estimate on the number of samples that is required to achieve
the accuracy and conÔ¨Ådence goals is discussed in [ 35]. In general,
this number is highly sensitive to the accuracy parameter, while in-
creasing the prescribed conÔ¨Ådence has a lower impact on the num-
ber of samples.
4.2.2 Bayesian Hypothesis Testing
We use hypothesis testing as an alternative stopping criterion for
termination. Hypothesis Testing [ 20,23] is a statistical method for
deciding, with enough conÔ¨Ådence, whether the unknown probabil-
itymis greater than a given threshold q(H0:mq). Alternatively,
we may want to evaluate the complementary hypothesis H1:m<q.
Similar to estimation, hypothesis testing starts from prior knowl-
edge and updates it with the information obtained through sam-
pling until enough evidence is provided in support of either H0or
H1. The procedure aims at estimating the odds for hypothesis H0
versus H1, which can be computed as follows [ 35]:
Pr(H0jS)
Pr(H1jS)=Pr(SjH0)
Pr(SjH1)Pr(H0)
Pr(H1)(9)
where Sis the set of samples collected, and Pr(H0)andPr(H1)
are the probability of the hypothesis to be true given the prior
knowledge, respectively; Pr(H0) =1 FB(a;b)(q)andPr(H1) =
1 Pr(H0).
The ratio Pr(SjH0)=Pr(SjH1)is called a Bayes factor and can
be used as a measure of relative conÔ¨Ådence in H0versus H1[23,
35], i.e., it quantiÔ¨Åes how many times H0is more likely to be true
than H1given the evidence collected through sampling. The val-
uesPr(H0jS)andPr(H1jS)represent the probability of the two
hypotheses to be true after samples Shave been collected. Since
all the information gathered from the samples is embedded in the
posterior distribution, the latter is used to compute Pr(H0jS) =
1 FB(a‚Ä≤;b‚Ä≤)(q)andPr(H1jS) =1 Pr(H0jS). Thus, the Bayes
factor Bcorresponding to the posterior odds for hypothesis H0can
be computed from Equation ( 9) after some algebraic simpliÔ¨Åcations
as:
B=Pr(SjH0)
Pr(SjH1)=Pr(H1)
Pr(H0)(1
FB(a‚Ä≤;b‚Ä≤)(q) 1)
(10)
If no preference among the two hypotheses is provided by the prior,
e.g., when a non-informative prior is used, the initial value of the
ratio Pr(H1)=Pr(H0)is 1.
Equation ( 10) can be used to deÔ¨Åne a sequential stopping crite-
rion. In particular, sampling can stop when the odds in favor of
one of the hypotheses (the Bayes factor B) is greater than a given
threshold T, i.e., when a relative conÔ¨Ådence of at least Tis obtained
from data to support one of the hypotheses. A precise quantiÔ¨Åca-
tion of the number of samples needed to achieve convergence for
Bayesian hypothesis testing is discussed in [ 31,35]. In general, hy-
pothesis testing is faster than estimation, although its performance
degrades when qis close to the (unknown) probability m[31].
5. INFORMED SAMPLING
A weakness of statistical analysis is the large number of paths
that may need to be explored and the slow convergence to a re-
sult, within the desired conÔ¨Ådence. To address this problem, we
introduce here Informed Sampling (IS), an iterative technique that
combines Monte Carlo sampling with pruning of already exploredAlgorithm 1: Statistical Symbolic Execution with Informed
Sampling
1exploredD 0;
2successD 0;
3repeat
4 numSamples 0;
5 numSuccess 0;
6 successPCs fg ;
7 exploredPCs fg ;
8 repeat
9 p MonteCarloSample();
10 letPCbe the path condition of path p;
11 numSamples numSamples +1;
12 exploredPCs exploredPCs[fPCg;
13 ifpj=œïthen
14 numSuccess numSuccess +1;
15 successPCs successPCs[fPCg;
16 end
17 updatePrior();
18 until StopCombinedEst ()_numSamplesNI;
19 exploredD exploredD +‚ôØ(exploredPCs );
20 successD successD +‚ôØ(successPCs );
21 ifStopCombinedEst ()then
22 return ;
23 end
24 pruneOutPaths( exploredPCs );
25until exploredD =domainSize ;
26return ;
paths. Furthermore, to obtain a precise estimation of the proba-
bility of satisfying property œï, IS combines information from two
sources: the Ô¨Årst is based on the exact probabilistic analysis (de-
scribed in Section 2) for the pruned paths and the second is based
on Bayesian inference (as described in Section 4.2) for the sampled
paths. We describe IS in more detail below.
5.1 Algorithm
Symbolic execution with Informed Sampling is described at a
high level by Algorithm 1. Assume for simplicity that we are in-
terested in the success probability of the program with respect to a
property œï(the algorithm can also be applied to failure probabil-
ity with only minor modiÔ¨Åcations). NIis a pre-speciÔ¨Åed number
of samples per iteration. Assume also that we treat the grey paths
optimistically.
The algorithm works through a number of iterations (lines 3‚Äì25).
At each iteration, IS Ô¨Årst tries to tackle the veriÔ¨Åcation problem
through Bayesian inference. For this task, it takes a pre-speciÔ¨Åed
number of Monte Carlo samples (lines 8‚Äì18) as dictated by the
conditional probabilities computed from the code. At each itera-
tion, the algorithm keeps track of the following values:
numSamples counts the number of sampled paths
numSuccess counts the number of sampled paths that lead to
success
exploredPCs stores the PCs of explored paths
successPCs stores the PCs of explored paths that lead to suc-
cess
The algorithm also computes exploredD andsuccessD which
keep count of total explored inputs and explored inputs that lead
to success. These values are computed using model counting (lines
19‚Äì20) and are used in the combined estimators as described below.
As before we use as stopping criteria for sampling eitherBayesian estimation or Hypothesis testing (high-level procedure
StopCombinedEst() in lines 18 and 21). However for IS we use
combined estimators that enhance the Bayesian inference with pre-
cise information obtained from symbolic paths. If the (combined)
Bayesian estimator converges to the desired conÔ¨Ådence or if the
(combined) estimated probability satisÔ¨Åes the hypothesis, this re-
sult is reported and the analysis stops. The iterative process can
also terminate when the whole domain was analyzed (line 25).
After each iteration the symbolic paths explored so far are pruned
out of the execution tree (line 24) and analyzed using the exact
method (Section 2); the results are used to build the combined es-
timator. This improves the efÔ¨Åciency of the inference procedure
because it accounts for all the information obtainable from the path
conditions of explored paths. Indeed, each sampled path has a
path condition which is used in the exact analysis to quantify how
many input values from the domain will follow the execution along
that path. For example, referring to Figure 1, the symbolic path
s0!s2!s3accounts for more concrete program paths than the
path s0!s1; however this information is ignored by the purely
statistical inference, which treats symbolic paths as concrete paths.
Pruning using Counters.
Recall that for each path condition PCwe maintain a counter
C(PC)to count the number of solutions. Initially these counters
are computed using off-the-shelf quantiÔ¨Åcation procedures such as
LattE. At each iteration, IS performs sampling, as guided by the PC
counters (see Section 4.1). For each sampled (non-duplicate) path,
with Ô¨Ånal PCcounter n, IS updates all the counters for the preÔ¨Åxes
ofPCalong the path (to the root of the symbolic execution tree)
by subtracting n, and a new iteration starts (with the updated coun-
ters). Thus, for each pruned PConly a small number of arithmetic
operations is required, with no signiÔ¨Åcant impact on the overall
computation time.
At the end of each iteration, the counters keep track of the num-
ber of inputs that need to be sampled to follow that path. If a
counter becomes 0 it means that the sub-tree rooted at that node
has been fully explored, and it does not need to be sampled again.
Therefore we can safely prune it from the search space. If the
counter of the root node becomes 0 the analysis stops, because the
whole domain was analyzed exactly.
After each pruning, exact information is obtained for a fraction
of the input domain. This fraction needs no longer to be considered
for statistical inference, allowing the latter to focus on the remain-
ing part of the domain. Furthermore, the overall conÔ¨Ådence in the
result grows, since there is no uncertainty about the fraction of the
domain analyzed exactly.
Estimation with IS.
The combined estimator, denoted here as ÀÜm, is deÔ¨Åned through
the mixture of an exact estimator, denoted mE, and a Bayesian es-
timator, denoted ÀÜmB.Erefers to the inputs that follow the paths
explored in previous iterations of IS (and can therefore be analyzed
Exactly), while Brefers to the inputs that have not been explored
yet (and therefore can only be used in Bayesian estimation). A hat
(‚ÄúÀÜ‚Äù) denotes an approximate value.
For the input points that have already been explored, we can
compute the exact probability mE. Recall that successD denotes
the number of input points corresponding to the pruned successful
paths and exploredD is the total number of points corresponding to
pruned paths. Then:
mE=successD
exploredD(11)and or the rest of the input domain we have at each iteration just
the Bayesian estimator:
ÀÜmB=numSuccess +a
numSamples +a+b(12)
where for both aandbwe use 1 =2 as default. By the law of total
probability (DeÔ¨Ånition 3) we can combine the exact and Bayesian
estimators:
ÀÜm= (1 fE)ÀÜmB+fEmE (13)
where fEis the fraction of the domain that has been pruned out
up to the previous iteration, i.e., exploredD =‚ôØ(D). The number of
samples to take at each iteration is decided according to a sequen-
tial stopping criteria, and it is bounded by the maximum value NI
provided by the user.
Hypothesis Testing with IS.
For hypothesis testing recall that we base the decision on the
posterior odds of the hypothesis H0:Pr(Pj=œï)qversus H1:
Pr(Pj=œï)<q. For IS we compute the posterior odds based on a
combined estimator similar to the one described in Equation ( 13):
ÀÜmH0= (1 fE)ÀÜmH0
B+fEmH0
E(14)
where ÀÜmH0
Bis the Bayesian posterior estimator deÔ¨Åned in Sec-
tion 4.2.2 for the probability Pr(H0jS).Sis the set of samples
taken during the current iteration (i.e., 1  FB(a‚Ä≤;b‚Ä≤)(q), where
a‚Ä≤=a+numSuccess andb‚Ä≤=b+numSamples numSuccess are
the parameters of the posterior Beta distribution of the Bayesian es-
timator). mH0
Eis equal to 1 if the result mEof the partial exact anal-
ysis is greater than or equal to q, and equal to 0 otherwise; fEis the
fraction of the domain that has been pruned out up to the previous
iteration, as described in the previous section.
Early Termination.
We further enhance the IS procedure to check for additional suf-
Ô¨Åcient termination conditions determined by the partial exact anal-
ysis of pruned paths. Indeed, the actual value of mis by deÔ¨Ånition
in the interval:
successD
‚ôØ(D)m1 failD
‚ôØ(D)(15)
where failD =exploredD successD .
We use these lower and upper bounds to test against the hy-
pothesis and decide early termination of the IS procedure. Indeed,
ifsuccessD =‚ôØ(D)qthe hypothesis is necessarily true; while if
1 failD =‚ôØ(D)<qthe hypothesis is necessarily false. In both
cases we stop the iterative process and return the result to the user.
This check is performed in StopCombinedEst() .
5.2 Discussion
Combined Estimators are Unbiased and Consistent.
The construction of the combined estimator of Equation ( 13) is
an application of stratiÔ¨Åed sampling, where the population (the in-
put domain) is partitioned into disjoint subsets to be analyzed inde-
pendently; the local results are then linearly composed, assigning
each one a weight proportional to the size of the corresponding sub-
set [5]. An estimator obtained through stratiÔ¨Åed sampling is unbi-
ased (i.e., its expected value converges to the measure it estimates)
and consistent (i.e., its variance converges to 0 when the number of
samples goes to ¬•) if the local estimators used for each subset of
the partition are unbiased and consistent [ 5].For the portion of the domain analyzed exhaustively, mEis by
deÔ¨Ånition the actual measure it estimates. Thus it is trivially un-
biased and consistent (indeed the variance of a number is always
zero). For the portion of the domain subject to statistical estima-
tion, we adopt the standard Bayesian estimator for the parameter of
a Bernoulli distribution. Proofs that it is unbiased and consistent
can be found, for example, in [ 11,23,35]. Thus, the combined
estimator is in turn unbiased and consistent.
Termination.
If IS explores the whole domain, that is exploredD =‚ôØ(D), the
process terminates with the same results as for the exact analy-
sis. Since at each iteration the number of samples to collect for
Bayesian inference is greater than zero, IS is guaranteed to termi-
nate, in the worst case, when the whole domain has been analyzed
exactly. (Note that we assumed the domain is Ô¨Ånite.)
Faster Convergence for Bayesian Estimation.
A beneÔ¨Åt of mixing the Bayesian estimator ÀÜmBwithmEis a faster
convergence to the criterion of Equation ( 6). Indeed, if an input
falls in the portion of the domain analyzed exactly, our estimate is
perfectly accurate (with conÔ¨Ådence 1) by deÔ¨Ånition. Otherwise it
will provide conÔ¨Ådence ÀÜd:
ÀÜd= (1 fE)dB+fE (16)
Thus, to meet the prescribed conÔ¨Ådence das a whole, the Bayesian
estimator is required to just satisfy the relaxed conÔ¨Ådence dB.
dBd fE
1 fE(17)
During the Ô¨Årst iteration, when fE=0,dBneeds to satisfy the
original convergence criterion of Bayesian estimation (i.e., the pre-
scribed d). However, with each iteration, fEincreases, thus relax-
ing the constraint on dB.
Faster Convergence for Hypothesis Testing.
As for Bayesian hypothesis testing, the process terminates as
soon as the odds in favor of H0overcome those in favor of H1
by a factor Tdecided by the user. To understand the beneÔ¨Åt
in terms of the convergence rate provided by the IS estimator of
Equation ( 14), we need to consider the ratio of the posterior odds
Pr(H0jS)=Pr(H1jS). IfH0is actually true, Pr(H0jS)will converge
to 1 (and consequently Pr(H1jS)to 0) the more samples are col-
lected. The other way around, if H0is false Pr(H0jS)will con-
verge to 0 (and Pr(H1jS)to 1). The convergence of the estimator
ÀÜmH0can be evaluated again considering fE. Since after each iter-
ation fEgrows, the room for the uncertainty derived from the use
of Bayesian estimation is always bounded by a decreasing factor
1 fE. The more execution paths are pruned out and analyzed ex-
actly, the more such uncertainty is reduced, usually speeding up the
convergence of the combined estimator.
Detecting Errors with Random Exploration.
The iterative pruning of the input domain increases the chances
of random exploration to detect errors. To show this, let us consider
an error path with path condition PCR. Let Birepresent the set of
the paths targeted by random sampling during iteration i, and let
Bi+1represent the set of paths targeted by sampling during iteration
i+1. If the error path is not detected at iteration i, we will show
that the probability of catching PCRis higher at iteration i+1.
Let us assume, for simplicity, that only one path is sampled per
iteration (the worst case for our proof). The probability of samplingPCRat iteration iisPr(PCRjBi). If it is sampled, then the error has
been detected. Otherwise a sampled path with condition PCiis
removed from Bi. Since Bi+1=Bi PCiit follows that at iteration
i+1, the probability Pr(PCRjBi+1)of catching PCRis higher than
in the previous iteration:
Pr(PCRjBi) =Pr(PCRjPCi)Pr(PCi) +Pr(PCRjBi+1)Pr(Bi+1)(18)
Note that Pr(PCRjPCi) =0 because we assumed that the sampled
path with PCiwas not the error path with PCR, it follows that:
Pr(PCRjBi+1) =Pr(PCRjBi)
Pr(Bi+1)(19)
Again, assuming that PCRhas not been detected yet, necessarily
Bi+1Ã∏=/ 0 and thus Pr(Bi+1)>0 . The example in Section 3illus-
trates this phenomenon: the error is very hard to detect with purely
random exploration but it can be easily detected with IS.
Number of Samples; Incremental Symbolic Execution.
The maximum number of samples to take in each iteration of IS
allows us to select different operation modes for the algorithm. If
a very large number of samples are allowed during each iteration,
IS reduces to Bayesian inference as described in Section 4.2. On
the other hand, if NI=1 the impact of the Bayesian estimation
becomes negligible, since it will almost surely not converge after a
single sample, making IS perform an incremental exact analysis by
selecting, pruning, and analyzing one symbolic path per iteration.
Thus IS can be used to improve on ‚Äúclassical‚Äù symbolic execu-
tion by providing for a new kind of incremental analysis where the
next path to be analyzed is selected according to the Monte Carlo
Sampling described in Section 4.1. In this way IS will likely cover
the most probable paths Ô¨Årst, computing also the fraction of the
domain these paths cover. This results in an ‚Äúany time‚Äù approach
where it is possible to interrupt the execution when enough of the
input domain has been covered, even if the analysis cannot be ex-
haustively completed within a reasonable time.
Values of NIbetween the two extremes trade off the effort
Bayesian estimation is allowed to take to converge during a single
iteration with the number of iterations required to converge. Choos-
ing a good value for NIdepends on the speciÔ¨Åc problem. We will
discuss its choice for several applications in Section 6. Another op-
tion is to ‚Äúadapt‚Äù the value of NIwith the number of iterations, e.g.,
by starting small to quickly prune out paths with high likelihood of
execution and gradually increasing the value of NIto stress-test the
parts of the state space that have a small likelihood of execution.
False Positives or Negatives.
Statistical hypothesis testing, being a randomized procedure op-
erating on a limited number of samples, may produce false neg-
atives or positives, i.e., it may reject a hypothesis that is actually
true and vice versa. This problem can occur especially when the
analyzed programs are very large and the probability of success or
failure is close to the extremes (0 or 1) [ 34]. In the next section we
show an instance of the problem. For Bayesian hypothesis testing,
it has been proved that the probability of obtaining spurious results
is bounded by 1 =T[35], where Tis the threshold set by the user
(see Section 4.2.2 ).
For IS, pruning reduces the possibility of spurious results since
it limits the possibility of wrong conclusions to the fraction of the
domain analyzed with the Bayesian estimator (1  fE). Also note
that the sufÔ¨Åcient conditions that we added to IS, for early termi-
nation with hypothesis testing, do not suffer from incorrect results
because they rely on exact methods. Thus they improve the qualityof the overall approach since if IS terminates due to the sufÔ¨Åcient
conditions, its results are always correct.
6. EXPERIENCE
We implemented the statistical symbolic execution techniques
described in this paper in the context of SPF [ 22], an open-source
toolset. We plan to make our tool available for download. Sampling
is parallelized using a map-reduce algorithm. Path counters are
shared and reused in subsequent sampling phases.
In this section we compare IS with both an exhaustive analysis
and a purely statistical approach. We report on the analysis of the
following software artifacts:
OAE: the Onboard Abort Executive (OAE) [ 21] software compo-
nent manages the Crew Exploration Vehicle‚Äôs ascent abort handling
developed at NASA. OAE has 1400 LOC, 36 input variables rang-
ing over large domains, and fairly complicated logic encoding the
Ô¨Çight rules (a path condition can have approx. 60 constraints). We
are interested in the probability of the OAE not raising a mission
abort command.
MER : models a component of the Ô¨Çight software for JPL‚Äôs Mars
Exploration Rovers (MER) [ 1]; it consists of a resource arbiter and
two user components competing for Ô¨Åve resources. MER has 4697
LOC (including the Polyglot framework). The software has an er-
ror (see [ 1]) and is driven by input test sequences. We analyze two
versions: MER (small) for sequence length 8 and MER (large) for
sequence length 20; the latter cannot be analyzed fully with sym-
bolic execution because of the huge number of execution paths.
Sorting : an implementation of Insertion sort. We calculate the
probability of sorting an array of size nin exactly n(n 1)=2 com-
parisons, i.e., the worst case. A large number of paths need to be
analyzed ( n!), but only 1 path leads to the worst case. Despite being
a simple algorithm, this example is very challenging for statistical
techniques due to the low probability of hitting any failure. We
analyze a version for n=7.
Windy : a standard example in the reinforcement learning com-
munity that involves a robot moving in a grid from a start to a goal
state. A crosswind can blow the robot off course and an added
weight to the robot counter-balances that. We analyze two versions:
Windy (small) has a 54 grid and solutions limited to 5 moves, and
Windy (large) has a 94 grid and 12 moves. The latter cannot be
analyzed exhaustively with symbolic execution because of the very
large number of paths the robot may follow. We consider reaching
the goal state in the speciÔ¨Åed number of moves as a success.
OAE was analyzed on a Red Hat Linux 64bit machine with 4Gb
of memory and a 2.8GHz Intel i7 CPU. The other software was an-
alyzed on an Ubuntu Server 12.04.4 LTS 64bit with 16Gb of mem-
ory and a 3.10GHz quad-core Intel Xeon CPU E31220.
Estimation. Table 1shows some of our results for the proba-
bility estimation problem. danderepresent the target conÔ¨Ådence
and accuracy, NIis the number of samples per iterations, Iteris the
number of iterations completed during analysis, Estimate is the re-
sult computed, and Time is time consumption in milliseconds. For
all the examples in this table we assume a uniform usage proÔ¨Åle for
the inputs and we treat grey paths optimistically.
d=1 denotes that IS has been used for incremental exact anal-
ysis (thus computing the actual success probability without uncer-
tainty), while NI=100000 means that the analysis was purely sta-
tistical (no IS). There are several observations to make about these
numbers:
For OAE, eandNIdo not seem to play a role in the number of
iterations required, or the time consumption. This is because af-
ter the Ô¨Årst iteration, even with 100 samples, more than 99 :8% of
the domain is pruned out, and IS achieves the required conÔ¨ÅdenceTable 1: Estimation results (* means non-convergence, ** means
exhaustive analysis)
OAEd e NI Iter Estimate Time
1  1 3754 0.999999981808025 629;818
0.99 10 2100 2 0.9998659113123208 42;110
0.99 10 21000 1 0.9998659113123208 40;326
0.99 10 3100 2 0.9998659113123208 42;223
0.99 10 31000 2 0.9998659113123208 540;678
0.99 10 3100000  0.9995836802664446 317;074
0.99 10 5100000  0.999990000199996* 31;654;165MER (small)d e NI Iter Estimate Time
1 - 1 122 .75 100;420
0.99 10 3100 9 0.75** 168;414
0.99 10 31000 9 0.7499661471528664 210;635
0.975 10 5100 9 0.7499263416861861 167;695
0.975 10 51000 9 0.7499828915718787 211;332
0.99 10 5100 9 0.7499254209572634 166;871
0.99 10 51000 9 0.7499686952166291 210;464
0.99 10 3100000  0.749705005899882* 25;784;373
0.99 10 5100000  0.7510049799004019* 25;803;456Sortingd e NI Iter Estimate Time
1  1 5040 0.999988 946;681
0.99 10 3100 68 0.9999069235294118 1;943;537
0.99 10 31000 18 0.9999636105960265 1;823;969
0.99 10 5100 69 0.9999527117647059 2;689;889
0.99 10 51000 18 0.9999856615894039 2;195;849
0.99 10 3100000 - 0.9995836802664446 307;192
0.99 10 5100000 - 0.999990000199996* 9;113;719Windy (small)d e NI Iter Estimate Time
1  1 614 0.004073625 70;554
0.99 10 3100 16 0.004164252291666667 7;348
0.99 10 31000 11 0.004073625 8;275
0.99 10 5100 17 0.004100003958333333 123;204
0.99 10 51000 11 0.004073625** 148;843
0.99 10 3100000  0.00438745663560302 1;859;271
0.99 10 5100000  0.004309913801723965* 6;319;183
quickly. Indeed, OAE has a few ‚Äúsuccess behavior‚Äù paths account-
ing for most of the executions, while the abort paths share a small
probability of being taken under the uniform proÔ¨Åle (we will later
report on a different mission proÔ¨Åle). Thanks to Monte Carlo sam-
pling, the former are very likely to be sampled, and then pruned,
Ô¨Årst. IS is dramatically faster than the purely statistical approach,
and its estimate is also closer to the true value.
MER (small) has several execution paths occurring for roughly
the same number of inputs. IS needs more iterations to prune
them out and achieve the high accuracy and conÔ¨Ådence goals (un-
like in the OAE case). However, due to the small number of paths
(122), after 9 iterations at least 99% of the domain is covered,
pushing the convergence of the IS estimator, which outperforms
the Bayesian estimator. Notice also that the latter does not reach
the required conÔ¨Ådence for such high accuracy: after 100000 sam-
ples it reaches a conÔ¨Ådence of only :5346 and :0058, for eequal
to 10 3and 10 5, respectively.
For Sorting, only NIsigniÔ¨Åcantly inÔ¨Çuences the number of iter-
ations. This reÔ¨Çects the fact that ‚Äì initially ‚Äì the 5040 paths are
equally likely, and so we expect the impact of pruning in IS to
be small. This scenario is particularly suitable to Bayesian esti-
mation, which converges for e=10 3after about 2500 samples.
Since we limited NIto smaller values, IS was not able to achieve
convergence by its statistical component until pruning covered
a large portion of the domain. When the accuracy is raised to
e=10 5, the Bayesian estimator is not able to converge within
100000 samples (Ô¨Ånal conÔ¨Ådence 0:864), while for IS increas-
ing the accuracy does not require higher overhead, allowing it
to converge faster than Bayesian. For this problem, a higher NI
would be a reasonable choice, especially for low accuracy.
Windy is similar to Sorting, since there are many paths, all withcomparable probability, and only a few of them are classiÔ¨Åed
as success. However, while for Sorting the Bayesian estimator
quickly converged for accuracy 10 3without observing any fail-
ure, in this case the probability of success is high enough to allow
sampling both types of path. This increases the variance of the
sample, slowing down the statistical estimator. On the other hand,
for IS, thanks to pruning, as soon as the few success paths are col-
lected they are pruned out, reducing the variance of the samples
of subsequent iterations and speeding up convergence.
In summary, IS is particularly effective for problems where a
subset of the execution paths accounts for a large portion of the
inputs. In this case, such paths are likely to be pruned out af-
ter a few iterations increasing the conÔ¨Ådence on the partial result.
Also, IS outperforms statistical methods when high accuracy is
required. Finally, if an exact analysis is required for a problem
that would require too much memory to be analyzed with previous
approaches [ 9], IS can analyze them incrementally, producing in-
termediate results with quantiÔ¨Åed conÔ¨Ådence after each iteration,
though usually taking longer time.
Hypothesis testing. The results for hypothesis testing are shown
in Table 2.qandTrepresent the hypothesis ( H0:Pr(Pj=œï)q)
and the conÔ¨Ådence threshold to accept or reject H0, and Result is
the result computed (whether or not the hypothesis holds), while
the meanings of the other columns are the same as before. Once
again, we assume a uniform usage proÔ¨Åle.
Table 2: Hypothesis testing results (* denotes convergence for suf-
Ô¨Åcient exact conditions, ** denotes a false positive/negative)
OAEq T NI Iter Result Time
0.999 105100 2 true 40;150
0.999 1051000 1 true 35;458
0.9999 105100 2 true 40;495
0.9999 1051000 2 true 168;000
0.999 105100000  true 36;295
0.9999 105100000  true 362;125MER (small)q T NI Iter Result Time
0.74999 105100 4 true* 143;775
0.74999 1051000 2 true* 541;618
0.9 105100 1 false* 34;822
0.9 1051000 1 false 80;266
0.74999 105100000    25;763;139
0.9 105100000  false 79;229Sortingq T NI Iter Result Time
0.999978 105100 47 true 1;567;080
0.999978 1051000 6 true 1;291;770
0.999999999 105100 61 false 1;931;810
0.999999999 1051000 7 false 1;567;732
0.9999978 105100000    9;372;129
0.999999999 105100000  false 1;536;449Windy (small)q T NI Iter Result Time
0.003073625 105100 1 false** 11;120
0.003073625 1051000 1 true 110;437
0.004083625 105100 1 false 10;961
0.004083625 1051000 3 false* 210;286
0.003073625 105100000  true 627;864
0.004083625 105100000    6;257;120
Our choices of qare values close to the actual success proba-
bilities, obtained by estimation and as given in Table 1. As ex-
pected [ 35], hypothesis testing is usually faster than estimation.
However, when qis very close to the actual probability of success,
Bayesian methods fail to converge within a reasonable amount of
time (results marked with  ). IS responds to this situation by re-
quiring more iterations (more rounds of sampling/pruning). Com-
pare, for example, the cases with q=:9 and q=:74999 for MER
(small). IS generally performs better than a pure Bayesian testing
(and for some smaller cases the sampling procedure covered, by
chance, the full domain after a just few iterations, producing an ex-act result). Interestingly, in the Ô¨Årst experiment reported for Windy
(small) with NI=100 we obtained a false negative result. In this
case the Bayesian component of IS converged to a false decision af-
ter the 100 samples produced, by chance, 100 failures. Increasing
the number of samples NIwas enough to avoid this error.
Table 3: Hypothesis testing results where ‚Äúclassical‚Äù symbolic ex-
ecution runs out of memory (* denotes convergence for sufÔ¨Åcient
exact conditions)
MER (large)q T N I Iter Result Time
0.2 105100 1 true 55;004
0.2 1051000 1 true 287;829
0.35 105100 15 false* 913;109
0.35 1051000 1 true 287;372Windy (large)q T N I Iter Result Time
10 1105100 1 false 30;000
10 11051000 1 false 61;968
10 3105100 174 true 6;836;523
10 31051000 7 true 804;979
10 5105100 5 true 146;986
10 51051000 1 true 82;998
Intractable ‚Äúclassic‚Äù symbolic execution. Table 3shows the
results for a second set of experiments where we ran the techniques
on the larger examples for which ‚Äúclassical‚Äù symbolic execution is
intractable. We show results for the most efÔ¨Åcient technique from
the smaller cases, i.e., IS for hypothesis testing. There, IS was
able to converge to a decision within a reasonable amount of time.
Nevertheless, the large number of execution paths of these cases
led for MER (Large) with qclose to the actual success probability
to a false positive result for q=:35 and NI=1000; we know it is
a false positive because with NI=100 we obtained termination for
a sufÔ¨Åcient condition check. As already discussed, a false positive
result is possible for statistical testing. IS can mitigate this issue
by leveraging its exact analysis component, as for the case of NI=
100, although, in some cases, even 100 could be enough to make
the Bayesian component of IS converge to the wrong conclusion,
and an even smaller value for NImight be required.
Usage proÔ¨Åles. We brieÔ¨Çy mention the impact of the usage
proÔ¨Åles on the probability of satisfying a target property. We an-
alyzed OAE with a different usage proÔ¨Åle, where one input vari-
able ( thrust ) has a Gaussian (normal) distribution. The Gaussian
distribution was approximated by discretizing the domain of thrust
of into 5 segments, which led to 5 usage scenarios with different
probabilities [ 9].
Under this usage proÔ¨Åle, the density of inputs following the ‚Äúnor-
mal behavior‚Äù paths is reduced, requiring more rounds of prun-
ing for IS estimation to converge, even accuracy as low as 10 1.
This results in longer computation time, though still within reason-
able ranges. For example, IS with Bayesian estimation for conÔ¨Å-
dence 0.975 took approx. 50 ;000 ms in 5 iterations (with 100 or
1000 samples per iteration) while for conÔ¨Ådence 0.99 it took ap-
prox. 167 ;000 ms in 6 iterations.
The source code for all the examples (except OAE) and more
experimental data are available from [ 8].
7. RELATED WORK
Our work is related to statistical model checking (SMC) [ 32],
also formulated as a statistical hypothesis testing problem veri-
Ô¨Åed through Wald‚Äôs sequential probability ratio test (SPRT) [ 29].
SPRT does not Ô¨Åx the required number of samples a priori but
uses a sequential approach to decide after each sample whether
to stop or continue. A different hypothesis testing criterion has
been proposed in [ 26], where the size of the sample set is auto-matically increased until it allows for satisfying the convergence
criteria. In [ 13], SMC has been formulated as an estimation prob-
lem, with the number of samples Ô¨Åxed a priori by means of the
Chernoff and Hoeffding bound [ 14]. Other approaches for decid-
ing the number of samples have been discussed in [ 26,34]. Some
of these approaches have been implemented in well-known proba-
bilistic model checkers [ 16,30].
In our work we combined Bayesian inference techniques with
exact analysis through the IS technique, which is shown to provide
better performance than the pure Bayesian analysis.
A recent approach related to ours [ 19] provides automated re-
liability estimation over partial systematic explorations applied to
models. The approach Ô¨Årst performs sampling over the model and
then applies invariant inference over the samples. The inferred in-
variant characterizes a partial model which is then exhaustively ex-
plored using (exact) probabilistic model checking, obtaining better
results than (full model) probabilistic and statistical model check-
ing for system models.
The techniques we propose are different. Indeed we focus on the
use of symbolic execution to analyze software from its source code,
while [ 19] focuses on Markov chain models analyzed through prob-
abilistic model checking. The samples in [ 19] are used to produce
an approximate simpliÔ¨Åed model to be analyzed, while instead we
use an iterative process that prunes the execution tree and guides
the sampling towards low-probability paths.
We proposed several techniques for the probabilistic analysis of
programs [ 2,9,10]. The approaches in [ 9,10] can only perform ex-
act analysis that requires all paths to be evaluated. The work in [ 2]
addresses the approximate analysis of non-linear constraints; we
can apply the techniques described here also in that domain, using
the quantiÔ¨Åcation procedure from [ 2] instead of model counting.
Another approximate analysis for programs is proposed in [ 25];
that also uses sampling of symbolic paths (but no incremental or
informed sampling as we do here) and gives bounds on the prob-
ability of events of interest in a program. In more recent work
we study statistical techniques that target speciÔ¨Åcally programs that
have nondeterminism (for example due to concurrency) [ 18]. The
work also uses hypothesis testing (a simpler form than here) but its
main focus is on deriving optimal schedulers, with the best tech-
nique using reinforcement learning for the most promising sched-
uler moves.
Our work shares similar goals with guided testing techniques,
which provide heuristics to guide the exploration of a program to-
wards ‚Äúinteresting‚Äù paths (to increase coverage or to uncover er-
rors), e.g., [ 4,27] and many other works. However such techniques
do not provide statistical guarantees as we do here.
8. CONCLUSIONS
We described statistical symbolic execution, for the analysis of
software implementations. The technique uses a randomized sam-
pling of symbolic paths with Bayesian estimation and hypothesis
testing. We also proposed Informed Sampling, an iterative ap-
proach that Ô¨Årst explores the paths with high statistical signiÔ¨Åcance,
prunes them from the state space and then keeps guiding the exe-
cution along less likely paths. Informed sampling combines sta-
tistical information from sampling with exact analysis for pruned
paths leading to provably improved convergence of the statistical
analysis. The techniques have been implemented in the context of
Symbolic PathFinder and have been shown to be effective for the
analysis of Java programs. In the future we plan to perform further
evaluations and to investigate applications in statistical information
Ô¨Çow analysis. We also plan an in-depth study on probability com-
putations for programs with structured inputs.9. REFERENCES
[1]D. Balasubramanian, C. S. Psreanu, G. Karsai, and M. R.
Lowry. Polyglot: Systematic analysis for multiple Statechart
formalisms. In TACAS , LNCS #7795, pages 523‚Äì529, Mar.
2013.
[2]M. Borges, A. Filieri, M. d‚ÄôAmorim, C. S. P ÀòasÀòareanu, and
W. Visser. Compositional solution space quantiÔ¨Åcation for
probabilistic software analysis. In PLDI , 2014 ‚Äì to appear.
[3]C. Boyapati, S. Khurshid, and D. Marinov. Korat: automated
testing based on Java predicates. SIGSOFT Software
Engineering Notes , 27(4):123‚Äì133, July 2002.
[4]J. Burnim and K. Sen. Heuristics for scalable dynamic test
generation. In ASE, pages 443‚Äì446, Sept. 2008.
[5]R. Chambers and R. Clark. An Introduction to Model-Based
Survey Sampling with Applications . Oxford Statistical
Science Series. OUP Oxford, 2012.
[6]J. A. De Loera, R. Hemmecke, J. Tauzer, and R. Yoshida.
Effective lattice point counting in rational convex polytopes.
Journal of Symbolic Computation , 38(4):1273‚Äì1302, Oct.
2004.
[7]A. Filieri, C. Ghezzi, and G. Tamburrelli. A formal approach
to adaptive software: continuous assurance of non-functional
requirements. Formal Aspects of Computing , 24(2):163‚Äì186,
Mar. 2012.
[8]A. Filieri, C. S. P ÀòasÀòareanu, and W. Visser. Statistical analyzer
for SPF. http://www.iste.uni-stuttgart.de/
rss/people/filieri/2014-fse-jpf .
[9]A. Filieri, C. S. P ÀòasÀòareanu, and W. Visser. Reliability analysis
in Symbolic PathFinder. In ICSE , pages 622‚Äì631, July 2013.
[10] J. Geldenhuys, M. B. Dwyer, and W. Visser. Probabilistic
symbolic execution. In ISSTA , pages 166‚Äì176, July 2012.
[11] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin.
Bayesian data analysis . CRC press, 2003.
[12] J. H. Halton. A retrospective and prospective survey of the
Monte Carlo method. Siam review , 12(1):1‚Äì63, Jan. 1970.
[13] T. Herault, R. Lassaigne, F. Magniette, and S. Peyronnet.
Approximate probabilistic model checking. In VMCAI ,
LNCS #2937, pages 73‚Äì84, Jan. 2004.
[14] W. Hoeffding. Probability inequalities for sums of bounded
random variables. Journal of the American Statistical
Association , 58(301):13‚Äì30, Mar. 1963.
[15] J. C. King. Symbolic execution and program testing.
Commun. ACM , 19(7):385‚Äì394, July 1976.
[16] M. Kwiatkowska, G. Norman, and D. Parker. PRISM 4.0:
VeriÔ¨Åcation of probabilistic real-time systems. In CAV,
LNCS #6806, pages 585‚Äì591, July 2011.
[17] D. V . Lindley. The present position in Bayesian statistics.
Statistical Science , 5(1):44‚Äì89, Mar. 1990.
[18] K. Luckow, C. S. P ÀòasÀòareanu, M. Dwyer, A. Filieri, and
W. Visser. Probabilistic symbolic execution for
nondeterministic programs. In CAV, 2014 ‚Äì submitted.
[19] E. Pavese, V . A. Braberman, and S. Uchitel. Automated
reliability estimation over partial systematic explorations. In
ICSE , pages 602‚Äì611, July 2013.
[20] W. R. Pestman. Mathematical Statistics . De Gruyter
Textbook. De Gruyter, 2009.
[21] C. S. P ÀòasÀòareanu, P. C. Mehlitz, D. H. Bushnell,
K. Gundy-Burlet, M. R. Lowry, S. Person, and M. Pape.
Combining unit-level symbolic execution and system-level
concrete execution for testing NASA software. In ISSTA ,
pages 15‚Äì26, July 2008.[22] C. S. P ÀòasÀòareanu, W. Visser, D. H. Bushnell, J. Geldenhuys,
P. C. Mehlitz, and N. Rungta. Symbolic PathFinder:
integrating symbolic execution with model checking for Java
bytecode analysis. Automated Software Engineering ,
20(3):391‚Äì425, Sept. 2013.
[23] C. Robert. The Bayesian choice: from decision-theoretic
foundations to computational implementation .
Springer-Verlag, 2007.
[24] C. Robert and G. Casella. Monte Carlo Statistical Methods .
Springer Texts in Statistics. Springer-Verlag, 2010.
[25] S. Sankaranarayanan, A. Chakarov, and S. Gulwani. Static
analysis for probabilistic programs: inferring whole program
properties from Ô¨Ånitely many paths. In PLDI , pages
447‚Äì458, June 2013.
[26] K. Sen, M. Viswanathan, and G. Agha. On statistical model
checking of stochastic systems. In CAV, LNCS #3576, pages
266‚Äì280, July 2005.
[27] K. Taneja, T. Xie, N. Tillmann, and J. de Halleux. eXpress:
guided path exploration for efÔ¨Åcient regression test
generation. In ISSTA , pages 1‚Äì11, July 2011.
[28] UC Davis, Mathematics. LattE.
|http://www.math.ucdavis.edu/ latte|.
[29] A. Wald. Sequential tests of statistical hypotheses. The
Annals of Mathematical Statistics , 16(2):117‚Äì186, June
1945.
[30] H. L. S. Younes. Ymer: A statistical model checker. In CAV,
LNCS #3576, pages 429‚Äì433, July 2005.
[31] H. L. S. Younes, M. Kwiatkowska, G. Norman, and
D. Parker. Numerical vs. statistical probabilistic model
checking. International Journal on Software Tools for
Technology Transfer , 8(3):216‚Äì228, June 2006.
[32] H. L. S. Younes and D. J. Musliner. Probabilistic plan
veriÔ¨Åcation through acceptance sampling. In AIPS-02
Workshop on Planning via Model Checking , pages 81‚Äì88,
Apr. 2002.
[33] H. L. S. Younes and R. G. Simmons. Probabilistic
veriÔ¨Åcation of discrete event systems using acceptance
sampling. In CAV, LNCS #2404, pages 223‚Äì235, July 2002.
[34] P. Zuliani, C. Baier, and E. M. Clarke. Rare-event
veriÔ¨Åcation for stochastic hybrid systems. In HSCC , pages
217‚Äì226, Apr. 2012.
[35] P. Zuliani, A. Platzer, and E. M. Clarke. Bayesian statistical
model checking with application to StateÔ¨Çow/Simulink
veriÔ¨Åcation. Formal Methods in System Design ,
43(2):338‚Äì367, Oct. 2013.