Green Streams for Data-Intensive Software
Thomas W. Bartenstein and Yu David Liu
SUNY Binghamton
Binghamton, NY13902, USA
ftbarten1, davidLg@binghamton.edu
Abstract ‚ÄîThis paper introduces G REEN STREAMS , a novel
solution to address a critical but often overlooked property
of data-intensive software: energy efÔ¨Åciency. G REEN STREAMS
is built around two key insights into data-intensive software.
First, energy consumption of data-intensive software is strongly
correlated to data volume and data processing, both of which
are naturally abstracted in the stream programming paradigm;
Second, energy efÔ¨Åciency can be improved if the data processing
components of a stream program coordinate in a ‚Äúbalanced‚Äù
way, much like an assembly line that runs most efÔ¨Åciently when
participating workers coordinate their pace. G REEN STREAMS
adopts a standard stream programming model, and applies
Dynamic Voltage and Frequency Scaling (DVFS) to coordinate
the pace of data processing among components, ultimately
achieving energy efÔ¨Åciency without degrading performance in a
parallel processing environment. At the core of G REEN STREAMS
is a novel constraint-based inference to abstract the intrinsic
relationships of data Ô¨Çow rates inside a stream program, which
uses linear programming to minimize the frequencies ‚Äì hence
the energy consumption ‚Äì for processing components while still
maintaining the maximum output data Ô¨Çow rate. The core
algorithm of G REEN STREAMS is formalized, and its optimality
is established. The effectiveness of G REEN STREAMS is evaluated
on top of the StreamIt framework, and preliminary results show
the approach can save CPU energy by an average of 28% with
a 7% performance improvement.
I. I NTRODUCTION
From megabyte-scale Youtube Apps on smart phones, to
gigabyte-scale NetÔ¨Çix applications on laptops, and to terabyte-
scale NASA scientiÔ¨Åc computations on servers [1], data-
intensive software is quickly becoming the new norm of
modern computing. Software engineering for ‚ÄúBig Data‚Äù is
an active area of research, with innovations addressing diverse
goals, such as architectural soundness [2], [3], programma-
bility [4], [5], performance [6], [7], and seamless database
integration [8], [9].
A critical goal that has received less attention than it
deserves is the energy efÔ¨Åciency of data-intensive software.
According to US Environment Protection Agency (EPA), data
centers in 2007 were responsible for up to 1.5% of the total
US electricity consumption [10], and recent reports show the
percentage has increased to 1.7-2.2% in 2011 [11]. In the
consumer sphere, battery-powered hand held devices such as
smart phones and tablets are experiencing explosive growth
in popularity. On both high-end and low-end platforms, data-
intensive software is widely used: data center applications are
predominately data-intensive in nature; smart phone Apps re-
lated to video, music, and maps are among the most commonly
used. In recent years, a number of software-centric solutionshave been proposed to address energy efÔ¨Åciency, through
design patterns [12], [13], programming language designs [14],
[15], [16] and compiler and runtime optimizations [17], [18],
[19], but none has focused on data-intensive software. This is
unfortunate because the root cause of energy consumption for
data-intensive software is often a combination of high-volume
data processing and complex data Ô¨Çows, distinctive traits not
sufÔ¨Åciently addressed by solutions built around control-Ô¨Çow-
centric models.
In this paper, we propose G REEN STREAMS , a novel energy-
efÔ¨Åcient solution that addresses data-intensive software. At its
essence, G REEN STREAMS is an energy-efÔ¨Åcient ‚Äútwist‚Äù to
standard stream programming models [4], [20], [21]. Stream
programming is a general-purpose paradigm where software is
composed as a stream graph , where nodes of the graph are data
processing components called Ô¨Ålters , and edges of the graphs
are data Ô¨Çows called streams . Compared with control-Ô¨Çow-
centric models ( e.g.Java and C), the streaming model exposes
data processing and data Ô¨Çow at the forefront of programming.
Its friendliness to parallelism ‚Äì crucial in the multi-core era
‚Äì has been well articulated. G REEN STREAMS elucidates yet
another beneÔ¨Åcial trait of the stream paradigm ‚Äì its friendliness
for improving energy efÔ¨Åciency ‚Äì crucial in the ‚ÄúBig Data‚Äù era.
The energy efÔ¨Åciency solution of G REEN STREAMS is based
on a key insight into stream programming: a stream graph,
like a manufacturing assembly line, can be operated with
more efÔ¨Åciency if the rates of streams can be coordinated,
so that, one Ô¨Ålter may output a data item to a stream ‚Äújust-
in-time‚Äù for consumption by the next Ô¨Ålter on the receiving
end of the stream. G REEN STREAMS optimizes the trade-
offs between performance and energy consumption through
judicious adjustment of the stream rates, a goal achieved by
a novel combination of static inference and dynamic scaling
of CPU frequencies through Dynamic V oltage and Frequency
Scaling (DVFS). Concretely, this paper makes the following
technical contributions:
a novel constraint-based rate inference algorithm to
statically compute the intrinsic relationships among data
streams and coordinate them in an energy-efÔ¨Åcient fash-
ion;
the use of linear programming to compute the minimal
frequencies necessary to execute individual Ô¨Ålters while
at the same time maintaining the maximum output rate
of the whole application;
a formal account of the G REEN STREAMS core, and more
importantly, a formal analysis of the optimality of allFig. 1. Stream Composition: (a) Sequence (b) Split/Join (c) Loop
frequency selections, which intuitively translates to the
analytical optimality of energy reduction;
a prototype implementation that involves DVFS instru-
mentations on top of a parallel stream processing infras-
tructure;
an evaluation that demonstrates the effectiveness of our
approach in saving energy without degrading perfor-
mance.
Broadly, G REEN STREAMS explores the unbeaten path of
constructing energy-efÔ¨Åcient software where innovations on
programming models, program analyses, and runtime systems
converge. To the best of our knowledge, this uniÔ¨Åed software-
centered approach is unique in addressing energy efÔ¨Åciency of
data-intensive software.
II. B ACKGROUND
A. Stream Programming Model
The stream paradigm organizes software into basic units of
Ô¨Årst-in-Ô¨Årst-out (FIFO) data streams Ô¨Çowing through stream
Ô¨Ålters. A data stream is simply a list of data objects of Ô¨Åxed
size. A stream Ô¨Ålter is a unit of software which consumes
data from a single input data stream, and produces data on a
single output data stream. The description of the details of a
stream Ô¨Ålter is implementation dependent, but can be viewed
abstractly like a function, with internal computation. Stream
Ô¨Ålters pop a Ô¨Åxed number of data items from their input stream
when that data is available, process the input data, and push a
Ô¨Åxed number of derived data items onto their output stream.
A stream program is represented as a stream graph, which
can be decomposed as sub-graphs, which ultimately decom-
poses to simple Ô¨Ålters. There are three common forms of
composition, as represented in Figure 1. The simplest is
sequential composition, in which the output stream of one
sub-graph feeds the input stream of the second sub-graph
(Figure 1(a)). The split/join composition (Figure 1(b)) Ô¨Årst
‚Äúsplits‚Äù a single input stream to two or more streams, each of
Fig. 2. An Example Stream Graph (BeamFormer)
which will be fed to different sub-graphs. The output streams
of these sub-graphs will be ‚Äújoined‚Äù together into a single
output stream. A third, less commonly used composition style
is a loop conÔ¨Åguration (Figure 1(c)). Here, the output of the
‚Äùbody‚Äù sub-graph is split into an output stream and a feedback
stream. The feedback stream feeds a ‚Äùloop‚Äù sub-graph, whose
output is joined to the input stream, and the result feeds the
body sub-graph. For instance, the full stream graph for the
BeamFormer benchmark [22] is graphically represented in
Figure 2. In this Ô¨Ågure, each colored oval represents a stream
Ô¨Ålter, and sub-graphs are surrounded by rectangles.
It is well known that a major beneÔ¨Åt of stream programming
is its natural support for parallelism. For instance, two Ô¨Ålters
with different functionalities can be deployed as different
threads running on different CPU cores, achieving task par-
allelism, whereas two instances of the same Ô¨Ålter code can
take different data and run in parallel as well, achieving data
parallelism. Logically speaking, every Ô¨Ålter ‚Äì such as every
oval box in Figure 2 ‚Äì can be mapped to a separate thread and
run in parallel. In real-world stream programming systems,
optimizations exist to map muliple logical Ô¨Ålters into one
thread [4].
B. The Stream Paradigm: Expressiveness and Applicability
Popular terms such as ‚Äúvideo streaming‚Äù are both a boon
and a burden to the stream paradigm. It vividly demonstrates
what onestreaming application looks like, but at the same time
may lead to misconceptions about the generality of stream
programming. Is the stream paradigm a general-purpose soft-
ware development paradigm? We answer this question in two
dimensions.
From the perspective of language expressiveness, the stream
model is a variant of the data-Ô¨Çow programming model
[23]. The namesake difference between control-Ô¨Çow and data-
Ô¨Çow programming highlights the individual strengths of each
model, but in terms of language expressiveness, the two
models are on par: commonly used control Ô¨Çows are eithersupported or encodable in the dataÔ¨Çow model, and data-Ô¨Çow
analysis is a standard semantic analysis for the control Ô¨Çow
model [24]. Most of the recently developed stream languages
are extensions from Java/C-like languages [4], [20], [21], a
hybrid of both paradigms. Below the surface, the most non-
trivial semantic difference between the two models is the data-
Ô¨Çow model generally assumes a non-shared memory model
between Ô¨Ålters: different Ô¨Ålters only access the same mem-
ory through explicit input/output stream connections. With a
growing awareness off the vulnerabilities of shared-memory
models ( e.g.race conditions and atomicity violations), non-
shared memory models are becoming more popular in new
languages such as Scala [25] and Go [26]. The combination
of non-shared memory models and the explicit identiÔ¨Åcation
of parallelism in stream languages make them naturally con-
ducive to constructing highly effective parallel software.
From the perspective of applicability, any software where
the program can be decomposed as a graph of data Ô¨Çows
will naturally Ô¨Åt into a stream programming paradigm. In
modeling, this application style is among the most classic
software architectures [27], and resonates in current research
on software processes and work Ô¨Çows. In programming, the
stream paradigm is known to be relevant to Graphical User
Interface (GUI) programming (‚ÄúGUI events as streams‚Äù [28]),
sensor network programming (‚Äúsensing data as streams‚Äù [29]),
database programming (‚Äúquery results as streams‚Äù [30]), and
robotics programming (‚Äúsignals as streams‚Äù [31]).
C. Dynamic Voltage and Frequency Scaling (DVFS)
DVFS [32] is a common CPU feature where the opera-
tional frequency and the supply voltage of the CPU can be
dynamically adjusted. Virtually all CPUs being used today ‚Äì
from ARM Cortex on Droid smartphones, Intel Core 2 on
laptops and desktops, to high-end clusters in data centers ‚Äì
support DVFS. It the era of multi-core CPUs, the frequencies
of individual cores can often be adjusted separately, a feature
known as multiple frequency domain support. For instance,
the AMD Zambezi family, a family of 8, 6, or 4-core CPUs
shipped in 2011, supports this feature.
DVFS is often used as an effective power management
strategy in VLSI and architecture research. In addition to small
portions related to static leakage, the vast majority of a CPU‚Äôs
power consumption Presults from its dynamic operation,
which can be (roughly) computed as P=CV2F,
whereVis the voltage, Fis the frequency, and Cis the
capacitance. The energy consumption Eis an accumulation
of power consumption over time, roughly E=Ptwhere
tis the operating time. Due to the innate nature of CPU
VLSI design, voltage and frequency are often scaled together.
In a multi-core context, it has been known that power has
a somewhat cubic relation to DVFS scaling [33]. Scaling
down the CPU frequency is thus effective in saving power .
Saving energy however is slightly more complex, because a
reduction of frequency may increase the execution time, t.
DVFS-based energy management thus often deals with the
trade-off between energy consumption and performance.A::=hS;Pi stream application
P::=PP0stream graph
jPkhnsa;nsb;nja;njbiP0
jPhnj;nfi;nfo;nsiP0
jFh`;ni;noi
F Ô¨Ålter
S::=hd;rti stream
`2 LAB Ô¨Ålter label
d2 INTEGER data element
n2 NAT natural number
rt2 FLOAT rate
Fig. 3. Stream Programming Core Abstract Syntax
III. T HEGREEN STREAMS ALGORITHM
This section describes the algorithm used to statically de-
termine an optimal DVFS setting for multiple cores executing
a parallelized stream process.
A. Abstract Syntax
We formalize a small core of stream programming, whose
abstract syntax is represented in Figure 3. A stream applica-
tion,A, is represented as a tuple, hS;Pi, whereSis the input
stream, and Pis a stream graph. Each stream is represented
by tuplehd;rti, whereddeÔ¨Ånes a sequence of data dand
rtrepresents data rate ,i.e.the frequency the elements in
dbecome available. For convenience, we only formalize the
case where stream data are integers. A stream graph is either
a Ô¨Ålter (Fh`;ni;noi), or composed of two stream graphs P
andP0, via either sequential composition PP0, or split-
join composition Pkhnsa;nsb;nja;njbiP0, or loop composition
Phnj;nfi;nfo;nsiP0.
A Ô¨ÅlterFh`;ni;noiis the basic building block of a stream
application. Each Ô¨Ålter pops (consumes) nidata elements from
its input stream, and pushes (produces) nodata elements on
its output stream. To keep this presentation simple, we are
abstract about the internal implementation of Ô¨Ålters, but a Ô¨Ålter
is most easily pictured as a function taking niinput elements
as parameters, and returning nooutput elements as the return
value. Each Ô¨Ålter is explicitly labeled ( `). For a stream graph,
P, the set of all Ô¨Ålter labels appearing in Pis computed
by convenience function filters (P), whose deÔ¨Ånition is
obvious. Operationally, hS;Fh`;ni;noiifeeds elements in dto
Ô¨ÅlterFin a FIFO fashion at the rate of rt, whereS=hd;rti.
An output stream ‚Äì the result of applying Foverd‚Äì is
implicit.
Stream application hS;PP0ican be viewed as having S
as the input stream of P, whose output stream is then fed to
P0as input. Application hS;Pkhnsa;nsb;nja;njbiP0iÔ¨Årst splits
the data elements in stream Sinto two streams in a round-
robin fashion, following the distribution factor hnsa;nsbi: thecomputation waits until nsa+nsbdata elements are available
on its input stream, S, and then writes the Ô¨Årst nsaof these
data elements to the input stream of P, and thensbdata
elements to the input stream of P0. This process then repeats.
For instance, given S=h[1;2;3;:::; ];rtifor some rt, and
nsa= 2,nsb= 3, the data elements fed to the input of P
are[1;2;6;7;11;12;:::], and those fed to the input of P0are
[3;4;5;8;9;10;:::]. The second part of the parallel operation
is to join the data elements output from PandP0into a
single stream, again, in a round-robin fashion, following the
aggregation factor hnja;njbi. The process waits until there
are at least njadata items available on the output of P, and
at leastnjbdata items available as the output of P0. When
both conditions are met, njadata items from Pandnjbdata
items fromP0are transferred to the output of the composed
stream.
The meaning ofhS;Phnj;nfi;nfo;nsiP0iis to Ô¨Årst join
Sand the output stream of P0(i.e.the output stream of
the feedback loop) following the aggregation factor hnj;nfoi,
then feed the joined stream as the input stream of P, and
Ô¨Ånally divide the output stream of Pinto two following the
distribution factor hnfi;nsi, one of which becomes the Ô¨Ånal
output stream, while the other of which is the input stream
ofP0. Note that there are some restrictions on the values of
nfiandnfoin order to ensure that a feedback loop stream
graph can achieve a steady-state schedule [22], a topic out of
the scope of this paper.
r::= rvj`jrIjrO rate variable
 ::= constraint set
 linear constraint over r
rv rate variable name
Fig. 4. Inference Elements
B. Constraint-Based Rate Inference
We deÔ¨Åne a novel constraint-based algorithm to infer the
intrinsic rate dependencies of different elements of a stream
program. The inference algorithm represents the data stream
rates as rate variables , deÔ¨Åned in Figure 4.
A rate variable, r, is the abstract representation of a stream
rate, used to constrain and reason about stream rates statically.
The most basic form of a rate variable is rv, simply a name that
the inference algorithm can internally generate, where every
fresh generation speciÔ¨Åes the creation of a distinct rate variable
with a distinct name. The second form of a rate variable is
a Ô¨Ålter label `. When a Ô¨Ålter label appears in a constraint, it
doubles as a rate variable that abstractly represents the natural
rate of a Ô¨Ålter. The natural rate is the intrinsic rate at which a
Ô¨Ålter can process a single set of data, i.e.the inverse of time
required to take nidata items from the input stream, process
it through the Ô¨Ålter, and put nodata items onto the output
stream. When a Ô¨Ålter executes at its natural rate, the rate at
which items are consumed from the input stream is `ni,and the rate at which items are added to the output stream is
`no. For convenience, we further provide two pre-deÔ¨Åned
rate variables, rIandrOto represents the input rate and output
rate of the entire stream graph, respectively.
The core inference rules for rate constraints are deÔ¨Åned in
Figure 5. Function RC(r;P;r0)collects the constraints for
stream graph Pwhen its input stream rate and output stream
rate are represented by randr0respectively. Each rule is
deÔ¨Åned over a particular syntactical construct, and represents
a principle of G REEN STREAMS that we now elaborate.
a) Principle of Natural Bound: Clearly, the output rate of
a Ô¨Ålter is dependent on the input rate to that Ô¨Ålter. It might be
tempting to consider a Ô¨Ålter as a pipeline whose output stream
rate can be inÔ¨Ånite given an inÔ¨Ånite input stream rate. This
naive view ignores the execution model of a stream program:
a Ô¨Ålter cannot start processing a second set of input data items
until it has Ô¨Ånished with the Ô¨Årst. Therefore, even if data items
arrive at the input to a Ô¨Ålter very fast, the Ô¨Ålter cannot execute
faster than its natural rate. Thus, the maximum output rate of
a Ô¨Ålter is not only constrained by the rate of the input stream
(r0rno
niin(R-Filter )), but also the natural rate of the
Ô¨Ålter itself ( r0`noin the same rule).
b) Principle of Sequential Balance: Given a stream
graph involving sequential composition P1P2, it would be a
waste of energy if P1can output data items at the rate of 100
items a second whereas P2can only take in data items at the
rate of 10 items a second. It would also be a waste of energy
ifP2can only output 10 items a second, and P1could take in
data items at the rate of 100 items a second. In both cases, the
party with a faster rate has no positive impact on the overall
output rate of the stream graph ‚Äì the ultimate ‚Äúthroughput‚Äù that
matters. G REEN STREAMS balances the output of P1with the
input ofP2. Observe that in (R-Seq ),rvis used both as the
output rate of P1‚Äì as inRC(r;P1;rv)‚Äì and the input rate
ofP2‚Äì as inRC(rv;P2;r0).
c) Principle of Join Balance: Given a split-join com-
position of two streams PAandPB, in the form of
PAkhnsa;nsb;nja;njbiPB, let us Ô¨Årst assume nja= 1 and
njb= 1. It would be a waste of energy if the output rate
ofPAwere vastly greater than that of PB, because in this
case, the two streams are ‚Äújoined‚Äù together by taking items
from the two streams in a round-robin fashion, 1 from PA
and 1 from PB, and thePAbranch would have to wait for
thePBbranch. More generally in (R-Par ), we use rv0
aand
rv0
bto represent the output rates of PAandPBrespectively,
where the balanced execution would conform to the constraint
rv0
a
nja=rv0
b
njb. The rest of the generated constraints of the same
rule describes the intrinsic dependencies of rates. Here rvaand
rvbare the input rates of PAandPBrespectively. The Ô¨Årst two
constraints denote how the rates of the two are ‚Äúsplit‚Äù from
the input rate of the whole stream graph, whereas the last
constraint describes how the output rate of the whole stream
graph is combined.
Notice that the (R-Loop )rule is simply a variation of the
(R-Par )rule because a loop composition can be viewed as a
‚Äúreversed‚Äù split-join conÔ¨Åguration. In this case, rvbis the rate(R-Filter ) RC(r;Fh`;ni;noi;r0)def=fr0rno
ni;r0`nog
(R-Seq ) RC(r;P1P2;r0)def=RC(r;P1;rv)[RC(rv;P2;r0)
if rvfresh
(R-Par )RC(r;PAkhnsa;nsb;nja;njbiPB;r0)def=RC(rva;PA;rv0
a)[RC(rvb;PB;rv0
b)[8
>>><
>>>:rva=rnsa
nsa+nsb
rvb=rnsb
nsa+nsb
rv0
a
nja=rv0
b
njb
rv0
a+rv0
b=rO9
>>>=
>>>;
if rva;rvb;rv0
a;rv0
bfresh
(R-Loop )RC(r;PBhnj;nfi;nfo;nsiPF;r0)def=RC(rvb;PB;rv0
b)[RC(rvf;PF;rv0
f)[8
>>><
>>>:r
nj=rv0
f
nfo
rvb=rI+rv0
f
r0=rv0
bns
nfi+ns
rvf=rv0
bnfi
nfi+ns9
>>>=
>>>;
if rvb;rvf;rv0
b;rv0
ffresh
Fig. 5. Constraint-Based Rate Inference
for the joined stream combining the input stream of the graph
and the output stream of the feedback loop, and rv0
bis the rate
of the stream to be split into the output stream of the graph
and the input stream of the feedback loop.
Since any stream graph is inductively deÔ¨Åned over the 3
forms of compositions of Ô¨Ålters, the inductive deÔ¨Ånition in
Figure 5 is sufÔ¨Åcient to compute constraints over arbitrary
stream graphs.
C. Relating Frequency and Natural Rate
Our ultimate goal is to select appropriate frequencies for
individual Ô¨Ålters, a task that we will tackle in Sec. III-D.
First, we must elucidate how frequencies are related to our
rate inference.
Let us abstractly represent the supported frequencies of a
CPU core as a total order h FREQ ;<i, where each element
freq2 FREQ in the concrete scenario would be an available
frequency supported by the CPU (in Hertz). For simplicity,
we only consider homogeneous architectures where all cores
support the same number of available frequencies for DVFS.
We use max( FREQ )to compute the upper bound of FREQ .
We further deÔ¨Åne a mapping function  : LAB FREQ!
FLOAT that, given a Ô¨Ålter label `2 LAB, and a frequency
freq2 FREQ ,(`;freq)computes the natural rate for Ô¨Ålter
labeled`under operating frequency freq. Intuitively, records
how fast a data item can be output by Ô¨Ålter `when the Ô¨Ålter
is running on a CPU core of a particular frequency.
We rely on proÔ¨Åling to compute . Concretely, we proÔ¨Åle
a Ô¨Ålter to determine the natural rate of that Ô¨Ålter at the max-
imum CPU frequency, and assume an inversely proportional
relationship between frequency and elapsed time of the Ô¨Ålter.
This relationship can be deÔ¨Åned with the equation:
(`;freq) = (`;max( FREQ ))freq
max( FREQ )
We elaborate on this implementation detail in Section IV-C.D. Linear Programming for Optimal Frequency Selection
From an abstract perspective, G REEN STREAMS follows
two steps to select frequencies for speciÔ¨Åc Ô¨Ålters. First, we
assume every Ô¨Ålter runs at the highest CPU frequency, and
compute the maximum possible output rate of the whole
stream graph. This is described as Algorithm 1 below. Second,
we compute the lowest possible frequency at which individual
Ô¨Ålters can execute, assuming we must maintain the maximum
possible rate computed in the Ô¨Årst step. This is conducted
by Algorithm 2 below. The central idea here is both steps
can be achieved by performing linear programming over the
constraints we inferred earlier (Section III-B).
Before we explain the details, let us Ô¨Årst introduce some
notation related to linear programming. Notation min
obf
represents an instance of linear programming to minimize
an objective function obf over constraints . It computes
a mapping whose domain coincides with the rate variables
that appear in obf, and whose range is the Ô¨Çoating point
numbers for rates ( rt). In other words, all rate variables
in all constraints are now ‚Äúsolved‚Äù, including the subset of
variables we care about. For example, a typical result looks
like[r17!3:3;r27!4:0], meaningr1should be of rate 3.3
andr2should be of rate 4.0 if we wanted to achieve the
minimality of obf. Objective function obftakes the form of
a linear expression. For convenience, we use symbol to
represent the AST expansion of addition, i.e.M
rv2frv1;rv2grvis
equivalent to objective function ‚Äú rv1+rv2.‚Äù The meaning of
notation max
obf is identical to min
obf except that we
are maximizing the objective function.
Next let us deÔ¨Åne the constraints of a stream graph assuming
that all Ô¨Ålters are executing at the maximum frequency possi-
ble. In other words, each Ô¨Ålter can operate at its highest natural
rate. The deÔ¨Ånition is a simple substitution of all rate variables
that represent Ô¨Ålter natural rates with a concrete rate whenthe maximum frequency is used. Notation frt=rgmeans
substitute every occurrence of rinwithrt.
DeÔ¨Ånition 1 (Global Constraints with Maxed-Out Fil-
ters): Given a stream graph P,mofCons (P)is deÔ¨Åned
asRC(rI;P;r O)f(`1;freq)=`1g:::f(`n;freq)=`ng, where
filters (P) = [`1;:::;` n]andfreq=max( FREQ ).
With this, the maximum output rate of a stream graph P
is an instance of linear programming of maximizing rOover
global constraints with maxed-out Ô¨Ålters:
Algorithm 1 (Max Output Rate): Given a stream graph P,
maxOut (P)denotes the maximum output rate with unbounded
input rate. It is deÔ¨Åned as rt, where max
mofcons (P)rO= [rO7!
rt].
Note that we do not bound the input rate of the stream graph
here. This is not necessary because, intuitively, the natural
rate of individual Ô¨Ålters ‚Äì and the constraints associated with
them ‚Äì will limit the output rate of the whole stream graph.
Hence, linear programming cannot yield unbounded results.
Obviously, for users of G REEN STREAMS who would like to
artiÔ¨Åcially bound the input rate of the stream graph, a variant
algorithm can be provided as follows:
DeÔ¨Ånition 2 (Max Output Rate with bounded Input Rate):
Given a stream graph Pand a pre-deÔ¨Åned input rate
rt0,maxOutB (P;rt0)denotes the maximum output rate
with bounded input rate rt0. It is deÔ¨Åned as rt, where
max
mofcons (P)frt0=rIgrO= [rO7!rt].
Finally, given that we know the maximum output rate, the
issue of reducing individual frequencies of Ô¨Ålter executions ‚Äì
and hence energy consumption ‚Äì is a matter of minimizing
the natural rate of individual Ô¨Ålters:
Algorithm 2 (Minimal Frequency): Given a stream graph P,
the minimal frequency required for Ô¨Ålter `without affecting
the overall output rate, denoted as minFreq (P;`), is deÔ¨Åned
as the least value freq in FREQ such that (`;freq)rtand
 =RC(rI;P;r O)fmaxOut (P)=rOg, and min
`= [`7!
rt].
E. Global Optimality and Algorithm Optimization
Algorithm 2 leaves two issues to be resolved. First, it only
says how to Ô¨Ånd the minimal frequency for a particular
Ô¨Ålter. Does this localized optimality ‚Äì seemingly greedy to
the particular Ô¨Ålter being subjected to linear programming ‚Äì
also lead to global optimality? Second, the algorithm requires
linear programming to be used for every Ô¨Ålter in the stream
graph, which is not an efÔ¨Åcient solution.
The following theorem addresses the Ô¨Årst issue with Al-
gorithm 2 above, namely, Algorithm 2 is a globally optimal
algorithm.
Theorem 1 (Natural Rate Independence for Fixed Output):
Given a stream graph Pand a pre-determined output rate
rt, then if frt1=`1ghas solutions, and frt2=`2ghas
solutions, then frt1=`1gfrt2=`2ghas solutions, where
`1;`22filters (P), and  =RC(rI;P;r O)frt=rOg.
This important theorem states the independence of satis-
Ô¨Åability of Ô¨Ålter natural rates given a Ô¨Åxed output rate ofthe stream graph. Here represents the necessary constraints
to allow the stream graph to maintain an output rate rt,
and`1and`2are two Ô¨Ålter natural rate variables ( `1;`22
filters (P)). The fact that frt1=`1ghas solutions implies
that by setting the natural rate of the Ô¨Ålter represented by `1
tort1, the output rate of the stream graph is maintained.
Similarly, the fact that frt2=`2ghas solutions means that
by setting the natural rate of the Ô¨Ålter represented by `2tort2,
the output rate of the stream graph is maintained as well. The
theorem thus tells us that the settings of `1and`2‚Äì hence
the minimal frequency selections of the two ‚Äì do not interfere
with each other, and by setting `1tort1and setting `2to
rt2at the same time, the stream graph can still maintain it
output rate rt.
Finally, the independence of natural rate variables intuitively
tells us that minimizing the natural rates of Ô¨Ålters one by one
is no better than minimizing the sum of all of them together.
This leads to an optimized algorithm where one instance of
linear programming can compute all minimal natural rates of
all Ô¨Ålters, and hence compute all minimal frequencies:
Theorem 2 (Linear Programming Compositionality): Given
a stream graph Pand some pre-deÔ¨Åned rate constant rt, and
 =RC(rI;P;r O)frt=rOg,min
`i= [`i7!rti]for
each`i2filters (P)andmin
M
`i2filters (P)`i= [`17!
rt0
1;:::;` n7!rt0
n], then rt1=rt0
1,:::, and rtn=rt0
n.
IV. E XPERIMENTAL RESULTS
A. Implementation
We implemented G REEN STREAMS as an extension to
StreamIt1(version 2.1.1), a sophisticated stream programming
infrastructure. There were several signiÔ¨Åcant modiÔ¨Åcations to
StreamIt required in order to implement G REEN STREAMS ,
including the following:
The inclusion of run-time monitors for proÔ¨Åling natural
rate (Section III-C).
The ability to perform and manipulate DVFS for StreamIt
applications. To demonstrate the effectiveness of our
approach in context, support was added to select one of
four different DVFS conÔ¨Ågurations:
‚ÄìA G REEN STREAMS conÔ¨Åguration, which sets DVFS
frequencies based on the results of our static analysis.
‚ÄìA ‚Äùfast‚Äù conÔ¨Åguration in which all DVFS frequencies
are forced to the highest possible frequency. This
conÔ¨Åguration is likely to deliver the fastest possible
performance, but also consume the most energy.
‚ÄìAn ‚Äùon-demand‚Äù conÔ¨Åguration in which all DVFS
frequencies are managed by the standard ‚Äùon-
demand‚Äù governor in Linux. The on-demand gov-
ernor modulates DVFS frequency based on demand.
Cores with a high work-load are run at a high DVFS
frequency to improve performance. Cores with a
low workload are run at a low DVFS frequency to
1http://groups.csail.mit.edu/cag/streamit/save energy. The on-demand DVFS conÔ¨Åguration is
the conÔ¨Åguration most often used in DVFS-capable
microprocessors, and is considered the default con-
Ô¨Åguration.
‚ÄìA ‚Äùslow‚Äù conÔ¨Åguration in which all DVFS frequen-
cies are forced to the lowest possible frequency.
This conÔ¨Åguration is likely to deliver the slowest
performance.
The implementation of the Ô¨Ålter frequency selection al-
gorithm (Section III-D).
The ability to assign a Ô¨Ålter to a core, and set DVFS for
that core at run time.
The StreamIt compiler is equipped with an optimization
performed during an intermediate pass called partitioning .
Partitioning transforms and load-balances the source-program
stream graph into a stream graph that contains a small number
of relatively independent Ô¨Ålters that can be mapped to inde-
pendent cores in a multi-core architecture. The load balancing
optimizations of StreamIt partitioning enable high parallel ef-
Ô¨Åciency on multi-core hardware. The G REEN STREAMS algo-
rithm is implemented over the post-partitioning stream graph.
B. Experimental Environment
All experiments were performed on an AMD FX-8510
(Bulldozer) microprocessor running Debian Linux Version
6.0.5. The processor was conÔ¨Ågured as an 8-core multi-
processor with the Turbo-boost feature disabled. All normal
operating system tasks were executing in the background, but
all experiments were performed with no other load on the
system.
Our experiments consisted of running Ô¨Åve StreamIt bench-
marks in each of the four DVFS conÔ¨Ågurations Ô¨Åve times,
while measuring the system current draw using a current meter
on the CPU power cable of the microprocessor. Since the CPU
is supplied at a constant voltage of 12V , the power is directly
proportional to the measured current, and the energy consists
of the power consumed over time. We used a Fluke¬©i30
AC/DC Current Clamp which accurately measures current
with a resolution of 1mA using Hall Effect technology. Current
measurements were taken every 1/100th of a second, and
stored on an independent system. These measurements were
then post-processed to isolate each trial run, where a trial run
consists of a single execution of a benchmark program in a
single DVFS conÔ¨Åguration. Five trials were collected for each
benchmark in each DVFS conÔ¨Åguration to avoid intermittent
errors or current draw based on external factors such as cache
latencies. We automated the testing of a single benchmark
by creating a loop that cycled through each DVFS state with
a three second sleep between each trial, and then executing
that loop Ô¨Åve times. This ensured that there were no latencies
between DVFS states.
The benchmark programs we tested were a subset of bench-
marks developed for the StreamIt compiler [22]. The Ô¨Åve
benchmark programs we selected were as follows.
Beamformer - An implementation of standard beam-
forming or spatial Ô¨Åltering. This is a signal processing
Fig. 6. Error between Computed Natural Rate and ProÔ¨Åled Natural Rate
technique that combines signals in such a way as to
achieve constructive interference or destructive interfer-
ence, depending on the spatial relationship of the signals.
Beamforming is used in several applications, including
seismology, radio astronomy, etc.
BitonicSort - An implementation of Batcher‚Äôs bitonic sort
network for sorting power-of-2 sized key sets.
DCT - An implementation of a two-dimensional 8x8
inverse Discrete Cosine Transfer, which transforms a 16x
16 signal from frequency domain to signal domain. DCT
is used in both JPEG and MPEG-2 coding.
DES - An implementation of a Data Encryption Standard
block cipher. This implementation uses 4 stages of pro-
cessing rather than the 16 required by the US government
DES standard.
V ocoder - An implementation of a the speech Ô¨Ålter
analysis portion of a source-Ô¨Ålter model. The analysis
includes Fourier analysis, a low-pass Ô¨Ålter, a bank of
band-pass Ô¨Ålters, and a pitch detector.
C. Experimental Results
In Section III-C, we introduced a formula to calculate
natural rate with the assumption that the relationship between
DVFS frequency and the elapsed time of a speciÔ¨Åc Ô¨Ålter is
inversely proportional: G REEN STREAMS proÔ¨Åles the active
elapsed time using the maximum CPU frequency, but assumes
that the active elapsed time for lower frequencies can be
estimated proportionally. In order to validate this assumption,
we proÔ¨Åled each of the Ô¨Ålters in the Ô¨Åve benchmarks at all
valid DVFS frequencies: 3.6Ghz, 3.3Ghz, 2.7Ghz, 2.1Ghz,
and 1.4Ghz, monitoring the active elapsed time. We compared
our estimated elapsed time with the monitored elapsed time.
The graph in Figure 6 shows the percentage of error (Z axis)
resulting from this assumption. Filters are on the X axis, and
frequencies on the Y axis. While there are some Ô¨Ålters at some
frequencies that show signiÔ¨Åcant error, the average error is
well below 10%.TABLE I
DVFS F REQUENCIES ASSIGNED TO BENCHMARK FILTERS
Frequency in Ghz
Benchmark 3.6 3.3 2.7 2.1 1.4
BeamFormer 4 1 2 1
BItonicSort 2 2 1 3
DCT 2 6
DES 2 3 3
V ocoder 1 4 3
The G REEN STREAMS compiler was run against the Ô¨Åve
benchmarks described above, each of which contains 8 Ô¨Ålters
that can be independently scheduled as threads after StreamIt
partitioning (see Section IV-A). The G REEN STREAMS al-
gorithm determines the optimum frequency for each of the
8 Ô¨Ålters. Table I shows the DVFS frequencies computed
according to our algorithm, and the number of Ô¨Ålters for each
benchmark assigned to each frequency.
Our 8-core CPU has 4 independently adjustable frequency
domains, i.e.every pair of cores need to share a single
frequency. Due to this hardware constraint, G REEN STREAMS
needs to map the 8 Ô¨Ålters (threads) to 4 DVFS frequency
domains. In doing so, one Ô¨Ålter in each benchmark (except
DCT) was forced to a higher frequency than the one computed
by our algorithm. We then collected current measurements for
all benchmarks in all DVFS conÔ¨Ågurations.
The Ô¨Årst observation is that the results show a remarkable
consistency. The results from the 20 trials of the BeamFormer
benchmark appear in Figure 7, grouped by different DVFS
conÔ¨Ågurations. Observe that the instantaneous current Ô¨Çuctua-
tions (which, given constant voltage, is proportional to power
consumption) over time are very similar for different trials
of the same DVFS conÔ¨Ågurations. Other benchmarks showed
similar consistency. This consistency reinforces the concept
that our experimental environment produced reliable results.
Given this consistency, we are able to consolidate results from
different trials of the same DVFS conÔ¨Åguration and the same
benchmark by taking the average current at each time.
The consolidated graph for the BeamFormer benchmark is
in Figure 8. Following our discussion earlier, the instantaneous
current readings (Y axis) are proportional to the instantaneous
power consumption because the CPU has a constant voltage
of 12V . The Ô¨Ågure demonstrates the effect of running all
cores at their top speed (the purple line), which consumes
high power but Ô¨Ånishes the fastest, versus running all cores
at their lowest speed (the blue line), which incurs the lowest
power consumption but takes signiÔ¨Åcantly longer to complete.
The G REEN STREAMS line (green) shows performance that
almost matches the fast line, but with signiÔ¨Åcantly less power
consumption. The only surprising data in this graph is the
on-demand line (in red). The on-demand DVFS conÔ¨Åguration
consumes more power than the fast state, but performs slightly
slower. We speculate this is because the on-demand DVFS
governor spends extra energy to switch DVFS frequencies,
Fig. 7. BeamFormer Trial Consistency (X unit: 0.01 second; Y unit: 1mA)
Fig. 8. BeamFormer Execution over Different DVFS ConÔ¨Ågurations (X unit:
0.01 second; Y unit: 1mA)
and the somewhat erratic resource demand of the BeamFormer
benchmark may cause the on-demand governor to switch too
frequently.
Figure 9 contains the DVFS conÔ¨Åguration comparison for
the other four benchmarks. In this Ô¨Ågure, the DCT benchmark
is the most interesting graph. The G REEN STREAMS DVFS
conÔ¨Åguration not only requires less power than either the
fast state or the on-demand state, but also Ô¨Ånishes signiÔ¨Å-
cantly sooner than either the fast or the on-demand DVFS
conÔ¨Åguration. The DES graph is also interesting because it
demonstrates the static nature of G REEN STREAMS . In the
DES case, the on-demand DVFS conÔ¨Åguration is better at
handling an application for which the resource requirements
change over time.
The energy consumption of each benchmark/DVFS con-
Ô¨Åguration is proportional to the area under each curve in
Figure 8 and Figure 9. Since the CPU is supplied at aFig. 9. Other Benchmarks over Different DVFS ConÔ¨Ågurations (X unit: 0.01
second; Y unit: 1mA)
constant voltage of 12V , the power is directly proportional to
the measured current, and the energy consists of the power
consumed over time. Our data collection method enabled
simple energy consumption calculations, based on summing
the current measurements for the entire time span of a given
trial. Since current measurements were taken every 1/100th of
a second, we can compute the ‚Äúinstantaneous energy consump-
tion‚Äù for that measurement by multiplying the measurement
value, 1/100 sec, and 12 V . The total energy consumed by
the CPU for that trial is the sum of all instantaneous energy
consumption values.
Fig. 10. Energy and Performance
Figure 10 and Tables II and III present the results of
average performance and CPU energy consumption for all Ô¨Åve
benchmarks. In three of the Ô¨Åve benchmarks (Beamformer,
DCT, and V ocoder), the energy consumption with G REEN
STREAMS was less than the on-demand energy consumption,
and in all benchmarks except V ocoder, the performance ofTABLE II
ENERGY CONSUMPTION PER BENCHMARK
BenchMark Slow OnDem GreenStr Fast
BeamFormer 25.79 37.22 25.16 32.13
BitonicSort 10.02 13.62 14.76 13.94
DCT 192.74 199.59 124.82 199.76
DES 14.19 10.82 17.83 15.05
V ocoder 49.71 61.40 46.88 82.82
TABLE III
TIMECONSUMPTION PER BENCHMARK
Benchmark Slow OnDem GreenStr Fast
BeamFormer 6.88 3.64 3.29 3.23
BitonicSort 2.90 1.71 2.03 1.64
DCT 59.12 28.31 21.32 27.93
DES 4.61 1.72 2.35 2.00
V ocoder 13.45 6.30 11.23 8.63
GREEN STREAMS was comparable or better than all other
DVFS states. Clearly, the DCT benchmark, which was the
most computation-intensive and had the most stable resource
requirements, was the best demonstration of the advantages of
GREEN STREAMS .
V. R ELATED WORK
A number of energy management strategies have been
proposed for stream applications, primarily from the systems
community. Benoit et. al. [34] considers a subset of stream
programs that can be modeled as serial-parallel workÔ¨Çows,
and studies the problem of mapping such workÔ¨Çows to CMPs
to minimize energy. Eprof [35] designs an energy-efÔ¨Åcient
scheduling algorithm for stream applications, with a non-
DVFS based solution. Rangasamy et. al. [36] used stream
programs as the context to evaluate the effectiveness of three
DVFS schemes: one based on a Petri net performance model,
one based on proÔ¨Åling, and one based on hardware. None of
these efforts reduce the problem to a program analysis over
stream programs as we do, nor do they perform constraint-
based inference over stream rates.
DVFS as an implementation strategy has been used in
compiler and run-time optimizations. Hsu et. al. [18] deÔ¨Ånes
a compiler optimization algorithm where memory-intensive
regions of the program control Ô¨Çow are identiÔ¨Åed, and a CPU‚Äôs
frequency is scaled down in these regions to reduce energy
consumption. Xie et. al. [17] evaluates the limitations and
opportunities of DVFS in a control-Ô¨Çow-centric setting. An
operating system solution [19] is proposed to reduce energy
efÔ¨Åciency by scheduling Ô¨Åxed-deadline tasks judiciously.
Several energy-aware programming models have been pro-
posed as extensions to Java-like languages. Green [14] de-
Ô¨Ånes a framework where programmers can customize quality
of service (QoS) to balance the trade-off QoS and energy
consumption. EnerJ [15] allows data to be approximated,
and applies hardware techniques to approximate data to saveenergy. Energy Types [16] deÔ¨Ånes a type system to reason
about program energy-phase behaviors and energy states. Both
EnerJ and Energy Types use DVFS as an implementation
strategy; they are otherwise unrelated to our approach. Clause
et. al. [12] explores the impact of different design patterns on
energy consumption. The impact of different synchronization
patterns on energy consumption was also explored [13].
Related work on stream programming and its applications
was summarized in Sec. II-B.
VI. C ONCLUSION
GREEN STREAMS provides a practical and effective solution
to save energy for data-intensive software. The stream pro-
gramming paradigm not only provides appropriate language
abstractions for developing data-intensive software, but also
offers the ideal structure and predictability for effective energy
management.
In the future, we plan to extend G REEN STREAMS to
support dynamic adaptability. Instead of relying on off-line
proÔ¨Åling and static inference, frequency selections can be
adaptive to the Ô¨Çuctuations of the run-time and changing
resource requirements.
ACKNOWLEDGMENTS
We thank Tyler Stachecki for helping us set up the experi-
ment environment. We thank Michael Gordon, Bill Thies, and
anonymous reviewers for their useful suggestions. This work
is supported by NSF CAREER Award CCF-1054515 and a
Google Faculty Award.
REFERENCES
[1] J. J. Tran, L. Cinquini, C. A. Mattmann, P. A. Zimdars, D. T. Cuddy,
K. S. Leung, O.-I. Kwoun, D. Crichton, and D. Freeborn, ‚ÄúEvaluating
cloud computing in the NASA DESDynI ground data system,‚Äù in
Proceedings of the 2nd International Workshop on Software Engineering
for Cloud Computing , ser. SECLOUD ‚Äô11, 2011, pp. 36‚Äì42.
[2] C. A. Mattmann, D. J. Crichton, N. Medvidovic, and S. Hughes, ‚ÄúA
software architecture-based framework for highly distributed and data
intensive scientiÔ¨Åc applications,‚Äù in ICSE ‚Äô06 , 2006, pp. 721‚Äì730.
[3] R. Mahjourian, ‚ÄúAn architectural style for data-driven systems,‚Äù in
Proceedings of the 10th international conference on Software Reuse:
High ConÔ¨Ådence Software Reuse in Large Systems , ser. ICSR ‚Äô08, 2008,
pp. 14‚Äì25.
[4] W. Thies, M. Karczmarek, and S. P. Amarasinghe, ‚ÄúStreamIt: A language
for streaming applications,‚Äù in Proceedings of the 11th International
Conference on Compiler Construction , 2002, pp. 179‚Äì196.
[5] K. Fisher and R. Gruber, ‚ÄúPADS: a domain-speciÔ¨Åc language for
processing ad hoc data,‚Äù in PLDI ‚Äô05 , 2005, pp. 295‚Äì304.
[6] J. Dean and S. Ghemawat, ‚ÄúMapReduce: SimpliÔ¨Åed data processing on
large clusters,‚Äù in OSDI‚Äô04 , 2004.
[7] Nvidia, ‚ÄúCompute uniÔ¨Åed device architecture programming guide,‚Äù
NVIDIA: Santa Clara, CA , 2007.
[8] G. Wassermann, C. Gould, Z. Su, and P. Devanbu, ‚ÄúStatic checking of
dynamically generated queries in database applications,‚Äù ACM Trans.
Softw. Eng. Methodol. , vol. 16, no. 4, Sep. 2007.
[9] W. R. Cook and S. Rai, ‚ÄúSafe query objects: statically typed objects as
remotely executable queries,‚Äù in ICSE , 2005, pp. 97‚Äì106.
[10] E. S. P. U.S. Environmental Protection Agency, ‚ÄúReport to congress on
server and data center energy efÔ¨Åciency public law 109-431,‚Äù 2007.
[11] J. Koomey, ‚ÄúGrowth in data center electricity use 2005 to 2010,‚Äù August
2011.
[12] J. Clause, C. Sahin, F. Cayci, I. L. M. Gutierrez, F. Kiamilev, L. Pol-
lock, and K. Winbladh, ‚ÄúInitial explorations on design pattern energy
usage,‚Äù in Proceedings of Workshop on Green and Sustainable Software
(GREENS‚Äô12) , 2012.[13] Y . D. Liu, ‚ÄúEnergy-efÔ¨Åcient synchronization through program pat-
terns,‚Äù in Proceedings of Workshop on Green and Sustainable Software
(GREENS‚Äô12) , 2012.
[14] W. Baek and T. M. Chilimbi, ‚ÄúGreen: a framework for supporting
energy-conscious programming using controlled approximation,‚Äù in
PLDI ‚Äô10 , 2010, pp. 198‚Äì209.
[15] A. Sampson, W. Dietl, E. Fortuna, D. Gnanapragasam, L. Ceze, and
D. Grossman, ‚ÄúEnerJ: Approximate data types for safe and general low-
power computation,‚Äù in PLDI‚Äô11 , Jun. 2011.
[16] M. Cohen, H. S. Zhu, S. E. Emgin, and Y . D. Liu, ‚ÄúEnergy types,‚Äù in
OOPSLA ‚Äô12 , October 2012.
[17] F. Xie, M. Martonosi, and S. Malik, ‚ÄúCompile-time dynamic voltage
scaling settings: opportunities and limits,‚Äù in PLDI ‚Äô03 , 2003, pp. 49‚Äì
62.
[18] C.-H. Hsu and U. Kremer, ‚ÄúThe design, implementation, and evaluation
of a compiler algorithm for CPU energy reduction,‚Äù in PLDI ‚Äô03 , 2003,
pp. 38‚Äì48.
[19] M. Weiser, B. Welch, A. Demers, and S. Shenker, ‚ÄúScheduling for
reduced CPU energy,‚Äù in OSDI ‚Äô94 . Berkeley, CA, USA: USENIX
Association, 1994, p. 2.
[20] J. H. Spring, J. Privat, R. Guerraoui, and J. Vitek, ‚ÄúStreamÔ¨Çex: high-
throughput stream programming in java,‚Äù in OOPSLA ‚Äô07 , 2007, pp.
211‚Äì228.
[21] J. Zhou and B. Demsky, ‚ÄúBamboo: a data-centric, object-oriented
approach to many-core software,‚Äù in PLDI‚Äô10 . ACM, 2010, pp. 388‚Äì
399.
[22] M. I. Gordon, ‚ÄúCompiler techniques for scalable performance of stream
programs on multicore architectures,‚Äù Ph.D. dissertation, Massachusetts
Institute of Technology, Cambridge, MA, May 2010.
[23] W. M. Johnston, J. R. P. Hanna, and R. J. Millar, ‚ÄúAdvances in dataÔ¨Çow
programming languages,‚Äù ACM Comput. Surv. , vol. 36, pp. 1‚Äì34, March
2004.
[24] T. Reps, S. Horwitz, and M. Sagiv, ‚ÄúPrecise interprocedural dataÔ¨Çow
analysis via graph reachability,‚Äù in POPL ‚Äô95 , 1995, pp. 49‚Äì61.
[25] P. Haller and M. Odersky, ‚ÄúScala Actors: Unifying thread-based and
event-based programming,‚Äù Theor. Comput. Sci. , vol. 410, no. 2-3, pp.
202‚Äì220, Feb. 2009.
[26] Google, ‚ÄúThe Go language, http://golang.org/.‚Äù
[27] M. Shaw and D. Garlan, Software architecture: perspectives on an
emerging discipline . Upper Saddle River, NJ, USA: Prentice-Hall, Inc.,
1996.
[28] L. A. Meyerovich, A. Guha, J. Baskin, G. H. Cooper, M. Greenberg,
A. BromÔ¨Åeld, and S. Krishnamurthi, ‚ÄúFlapjax: a programming language
for Ajax applications,‚Äù in OOPSLA ‚Äô09 , 2009, pp. 1‚Äì20.
[29] A. Manjhi, S. Nath, and P. B. Gibbons, ‚ÄúTributaries and deltas: efÔ¨Åcient
and robust aggregation in sensor network streams,‚Äù in SIGMOD ‚Äô05 ,
2005, pp. 287‚Äì298.
[30] S. Madden, M. Shah, J. M. Hellerstein, and V . Raman, ‚ÄúContinuously
adaptive continuous queries over streams,‚Äù in SIGMOD ‚Äô02 , 2002, pp.
49‚Äì60.
[31] Z. Wan and P. Hudak, ‚ÄúFunctional reactive programming from Ô¨Årst
principles,‚Äù in PLDI ‚Äô00 , 2000, pp. 242‚Äì252.
[32] T. Pering, T. Burd, and R. Brodersen, ‚ÄúThe simulation and evaluation
of dynamic voltage scaling algorithms,‚Äù in Proceedings of the 1998 in-
ternational symposium on Low power electronics and design (ISLPED) ,
1998, pp. 76‚Äì81.
[33] C. Isci, A. Buyuktosunoglu, C.-Y . Cher, P. Bose, and M. Martonosi,
‚ÄúAn analysis of efÔ¨Åcient multi-core global power management policies:
Maximizing performance for a given power budget,‚Äù in IEEE/ACM
International Symposium on Microarchitecture (MICRO) , 2006, pp. 347‚Äì
358.
[34] A. Benoit, P. Renaud-Goud, Y . Robert, and R. Melhem, ‚ÄúEnergy-aware
mappings of series-parallel workÔ¨Çows onto chip multiprocessors,‚Äù in
2011 International Conference on Parallel Processing (ICPP) , 2011,
pp. 472 ‚Äì481.
[35] Y . Yetim, S. Malik, and M. Martonosi, ‚ÄúEPROF: An energy/perfor-
mance/reliability optimization framework for streaming applications,‚Äù in
Design Automation Conference (ASP-DAC), 2012 17th Asia and South
PaciÔ¨Åc , 2012, pp. 769 ‚Äì774.
[36] A. Rangasamy and Y . N. Srikant, ‚ÄúEvaluation of dynamic voltage and
frequency scaling for stream programs,‚Äù in Proceedings of the 8th ACM
International Conference on Computing Frontiers (CF) , 2011, pp. 40:1‚Äì
40:10.