Broken Sets in Software Repository Evolution
J´erˆome V ouillon
CNRS, PPS UMR 7126,
Univ Paris Diderot, Sorbonne Paris Cit ´e
jerome.vouillon@pps.jussieu.frRoberto Di Cosmo
Univ Paris Diderot, Sorbonne Paris Cit ´e
PPS, UMR 7126, CNRS, F-75205
roberto@dicosmo.org
Abstract —Modern software systems are built by composing
components drawn from large repositories , whose size and
complexity increase at a fast pace. Software systems built with
components from a release of a repository should be seamlessly
upgradeable using components from the next release. Unfortu-
nately, users are often confronted with sets of components that
were installed together, but cannot be upgraded together to the
latest version from the new repository. Identifying these broken
setscan be of great help for a quality assurance team, that could
examine and ﬁx these issues well before they reach the end user.
Building on previous work on component co-installability,
we show that it is possible to ﬁnd these broken sets for any
two releases of a component repository, computing extremely
efﬁciently a concise representation of these upgrade issues,
together with informative graphical explanations.
A tool implementing the algorithm presented in this paper is
available as free software, and is able to process the evolution
between two major releases of the Debian GNU/Linux distri-
bution in just a few seconds. These results make it possible to
integrate seamlessly this analysis in a repository development
process.
I. I NTRODUCTION
Component-based software architectures, maintained in a
distributed fashion and evolving at a very quick pace are
nowadays commonplace, in particular in the world of free and
open source software (FOSS). Components are usually made
available via a repository , and are equipped with metadata,
such as dependencies andconﬂicts , that specify concisely the
contexts in which a component can or cannot be installed.
A typical example taken from the Debian GNU/Linux
distribution, is shown in Figure I, where we can see that
the logical language used for expressing dependencies and
conﬂicts is quite powerful, as it allows conjunctions (symbol
‘,’), disjunctions (symbol ‘ |’) and version constraints.
Maintaining and evolving component repositories is an
important task and requires an extensive quality assurance
process: besides traditional issues concerning the bugs in the
code inside each component, the quality of a large component
repository rests also on how well components can be combined
with each other, a property known as co-installability [24].
Similarly to what happens with the source code of a single
component, which is passed through regression tests to ensure
that one did not re-introduce issues that were ﬁxed before [18],
we are naturally led to check whether there is any set of
Work performed at the IRILL centre for Free Software Research and
Innovation (http://www.irill.org).1 Package: tesseract-ocr
2Source: tesseract (2.04-2.1)
3 Version: 2.04-2.1+b1
4 Depends: libc6 (>= 2.2.5), libgcc1 (>= 1:4.1.1),
5libjpeg8 (>= 8c), libstdc++6 (>= 4.1.1),
6libtiff4, zlib1g (>= 1:1.1.4),
7tesseract-ocr-eng | tesseract-ocr-language
8
9 Package: tesseract-ocr-eng
10Source: tesseract-eng
11 Version: 3.02-2
12 C o n f l i c t s : tesseract-ocr (<< 3.02-2)
Fig. 1. Inter-package relationships of tesseract-ocr , an optical character
recognition engine, and tesseract-ocr-eng , the english language pack,
as found on 20 February 2012, in the testing suite of the Debian GNU/Linux
distribution.
components which were co-installable in the old repository,
but become non co-installable in the new release.
Sets of components with this property, which we call
broken sets , are particularly damaging in the evolution of a
repository: their existence means that there may be perfectly
functional deployments based on the old repository that will
be disrupted as soon as one tries to upgrade their components
to the version in the new repository. The conﬁguration in
Example I is a real world example of such a broken set: the
tesseract optical character recognition program, which
is split in several related packages1, was perfectly functional
before February 20th2012, but on that day, the introduction of
the updated english language pack tesseract-ocr-eng
made the installation of this program temporarily impossible
for the English language.
Broken sets need to be identiﬁed early in the evolution
process, and ﬁxed well before the release of the new
repository, but ﬁnding broken sets in repositories whose size
is in the tens of thousands of components is a daunting task:
there may be exponentially many broken sets, and listing
them all would be both computationally unfeasible and of no
use for a quality assurance team, which would be ﬂooded
under the error reports.
In this paper, we describe a highly efﬁcient algorithm that
solves the problem by ﬁnding a very small subset of the broken
sets, which subsume all the others, and is close to minimal , in
a sense that will be made precise later on.
1Essentially, tesseract-ocr for the core engine, and
tesseract-ocr- lang for all supported language langWe have developed a tool that implements this algorithm
and ﬁnds such minimal problematic conﬁgurations on real
component repositories in a few seconds; it also provides very
concise explanations that allow to identify the origin of the
problem. We found several such issues in the evolution of the
Debian distribution using the tool.
The paper is organised as follows: Section II brieﬂy recalls
the basic notions about packages and dependencies, and the
formally certiﬁed semantic preserving repository transforma-
tions developed in [24] which our work builds upon, and
then presents the key ideas of our approach. Section III
presents some of the results obtained by our tool on real-world
GNU/Linux distributions. The technical development follows:
Section IV provides a precise formalisation of all the transfor-
mations and simpliﬁcations that can be performed to reduce
dramatically the search space for explanations; Section V
describes in detail an algorithm that uses these results and
builds a set of broken sets that cover all upgrade issues, and we
show in Section VI how we provide minimal explanations that
contain all the relevant information for understanding the cause
of these broken sets. We discuss related work in Section VII
and Section VIII concludes.
II. O VERALL APPROACH
While the concrete details may vary from one technology
to the other, the core metadata found in component based
systems always allows to express a few fundamental prop-
erties: a component, called package in the following, may
depend on a combination of components, expressed as a
conjunction of disjunctions of components, and a component
may conﬂict with a combination of components, expressed
as a conjunction. Extra properties like versioned constraints
(e.g.libc6 (>= 2.2.5) in Figure I) can be preprocessed
out [14], so we focus on a core dependency system containing
a binary symmetric conﬂict relation, and a dependency func-
tionD(π) ={{π1
1,...,π1
n1},...,{πk
1,...,πk
nk}}that is satisﬁed
when for each iat least one of the πi
jis installed. We follow
the notations of earlier works [14], [24], that we brieﬂy recall.
A. Repositories
Arepository is a tuple R= (P,D,C)wherePis a
ﬁnite set of packages ,D:P→ P(P(P))is the dependency
function (we write P(X)for the set of subsets of X), and
C, a symmetric irreﬂexive relation over P, is the conﬂict
relation . One can represent a repository with a concise
graphical notation, like in Figure 2a, where cis in conﬂict
withbandf, whilearequiresfand either borc, ande
requiresfandg, anddrequirese. We call dependency a set
of packages dincluded in D(π)for some package π∈P.
Aninstallation Iof a repository (P,D,C)is a subset of P.
An installation Iishealthy when the following holds:
•abundance : every package has what it needs. Formally,
for every package π∈I, and for every dependency
d∈D(π), we have d∩I/\e}atio\slash=∅.
•peace : no two packages conﬂict, that is, C∩(I×I) =∅.
A package πisinstallable in a repository if it is included in a
healthy installation Iof this repository. A set of packages Πareco-installable in a repository Rif they are all included in
some healthy installation Iof the repository.
B. Repository Transformations
To identify co-installability issues in a single repository,
[24] introduced a set of repository transformations that al-
low to extract from a large repository a much smaller
co-installability kernel which is equivalent as far as co-
installability is concerned. The gain allowed by these transfor-
mations is impressive: starting from a Ubuntu repository con-
taining 7277 packages, 31069 dependencies and 82 conﬂicts,
one goes down to a kernel containing only 100 elements, with
29 dependencies and 60 conﬂicts (similar gains are obtained
on Debian or Mandriva repositories). A description of these
transformations can be found in section 2 of [24], where they
are also shown correct (the proofs are certiﬁed in Coq [20]):
for completeness we recall here the main steps involved.
1) Flattening Dependencies: The ﬁrst transformation re-
places the dependency function Dof a repository R=
(P,D,C)with a special ﬂattened form/hatwideDwith two key
properties: ﬁrst, by applying a sort of transitive closure to D,
itdirectly describes all dependencies of each package, so if
/hatwideD(π) ={{π1
1,...,πk1
1},...{π1
n,...,πknn}},then the packages
πj
iare all the packages relevant for installing package π,
and only them. On the example repository of Figure 2a, this
amounts to adding a dependency from dtof, and one from
dtog(Figure 2b). Second, since we are only interested
in co-installability, we can prune the expanded dependency
function by removing any dependency containing a package
with no conﬂicts. On the example repository of Figure 2a,
this pruning phase removes the dependencies from dtoe,
fromdtogand from etog, leading to the repository of
Figure 2c. Finally, to render the repository more homogeneous
/hatwideDadds a self dependency to each package with conﬂicts,
leading to Figure 2d. Packages d,eandfnow have the same
dependencies, which reﬂects the intuition that they behave the
same way as far as co-installability is concerned.
These three operations (transitive closure, pruning, and addi-
tion of self conﬂicts) leave co-installability invariant (Theorem
6 in [24]). They are performed in a single pass, and can be
formally deﬁned as follows; given a repository (P,D,C), the
ﬂattened dependency function /hatwideDis the smallest function (with
respect to point-wise inclusion) such that:
REFL
(π,π′)∈C
{π} ∈/hatwideD(π)TRANS
{π1,...,π n} ∈D(π)
d1∈/hatwideD(π1)... d n∈/hatwideD(πn)/uniondisplay
1≤i≤ndi∈/hatwideD(π)
The presentation of ﬂattening through these inductive rules is
particularly useful, as it is possible to see, by following the
derivation tree, how the original dependencies are composed
together into the ﬁnal ﬂattened form.
2) Removing Irrelevant Dependencies And Redundant Con-
ﬂicts: As a second phase, [24] identiﬁes several classes of
dependencies that are irrelevant as far as co-installability isa
b ce
f∨
#d
#g
(a) Original repositorya
b ce
f∨
#d
#g
(b) Transitivitya
b cd
f∨
#e
#g
(c) Pruning
a
b cd
f∨
#e
#f g b c
(d) Self dependency additiona
b cd
f#e
#f g b c
(e) Simpliﬁcationb c a,d,e,f# #g b c a,d,e,f
(f) Quotient
Fig. 2. Transformations of a repository (added dependencies are in bold, dotted ones are removed in the next phase)
a
b c∨
(a) The dependency {b,c}is
implied by {b}a b
c d##
(b) Redundant conﬂict between
aandb
Fig. 3. Implied dependency, redundant conﬂict
concerned, and can thus be removed. In this work, we only
use two such simpliﬁcations.
The ﬁrst simpliﬁcation is called canonisation in [24], as it
corresponds to putting dependencies in a canonical minimal
form, by removing any dependency dthat is implied by
another dependency d′of the same package (that is, d′⊆d).
An example can be seen in Figure 3a, where the dependency
ofaonborcis implied by the dependency of aonb.
The second simpliﬁcation is the removal of irrelevant
dependencies , with have no impact on co-installability. In
particular, a dependency disclearly irrelevant if it contains a
packageπthat has conﬂicts only with packages belonging to
d. In Figure 2d, the dotted disjunctive dependency is clearly
irrelevant and can be removed, by Theorems 8 and 11 of [24],
leading to the repository in Figure 2e.
It is also possible to remove conﬂicts which are implied by
other conﬂicts, like the one between aandbin Figure 3b.
3) Quotienting Equivalent Packages: It is evident looking
at Figure 2e, that packages a,d,eandfare, as far as
co-installability is concerned, really equivalent , because they
share the very same set of dependencies. This happens quite
often in real repositories, so quotienting the ﬁnal repository
can greatly reduce its size, as can be seen in Figure 2f.
These transformations have been proven correct in [24] in a
modular way, so we can now safely cherry pick those of them
which are relevant for us.
C. Repository Evolution and Upgrades
This work is no longer concerned with a single repository
R: we want to compare co-installable sets of packages in aab
c
R'R
de
#
∨
Fig. 4. Repository evolution.
current repository R= (P,D,C)with those of a previous
stateR′= (P′,D′,C′)of the repository, that evolved into R.
One example of such evolution is shown in Figure 4,
where one can see that in the process, we may ﬁnd: removed
packages, in P′\P(liked);upgraded packages, in P∩P′
(likea,b,c );new packages, in P\P′(likee).
We assume that packages keep the same name across repos-
itory evolution: this allows to immediately relate packages
between the two repositories with no extra notational burden,
and corresponds to a best practice in GNU/Linux distributions,
where repository maintainers keep a dummy package with the
old package name and a dependence on the new package name
when a change of name is needed; similarly, we assume that
package upgrades are one-to-one operations.
A healthy installation I′of repository R′can be success-
fully upgraded if one can ﬁnd an healthy installation Iof
repository Rsuch that I′∩P⊆I: this models closely the
common practice of allowing to install extra packages during
an upgrade, and accepting to uninstall old packages that have
been removed in the new repository.
D. Finding Upgrade Issues: the Key Insights
In a perfect world, it would be possible to successfully
upgrade any healthy installation, but in practice, this is not
the case, as Example I shows. To improve this situation, we
need to ﬁnd a way of identifying all potential upgrade failures
by looking only at the old and new repositories.
Of course, if an installation I′cannot be upgraded, it must
contain a set of packages that were co-installable in the oldp0 q0#p1p2p3q1q2q3
Fig. 5. Many minimal broken sets, one minimal explanation
repository R′= (P′,D′,C′), and are no longer co-installable
in the new repository R= (P,D,C): we call such sets
broken sets . andI′∩Pis a broken set.
1) Finding broken sets is not easy: Listing all broken sets
would require to enumerate all co-installable sets of the old
repository R′to see whether their image in the new repository
becomes non co-installable. Unfortunately, this might lead to
testing all the 2nsubsets of a repository of size n: withnin
the range of thousands to tens of thousands2, this approach is
unfeasible.
A dual approach would be to reuse the highly efﬁcient
coinst tool from [24] to ﬁnd all minimal non co-installable
subsets of the new repository R, and check whether they
were installable in the old repository R′. Unfortunately, this
would also be unsatisfactory: on one side, the number of
minimal non co-installable subsets in Rcan be huge, and
one would need to test them all, even if the changes made
fromR′toRhave no impact on them; on the other side,
the efﬁciency of coinst relies on computing equivalence
classes of co-installable packages, but these classes may be
completely disrupted by an evolution of a repository.
2) Our Solution: Fortunately, it is possible to avoid listing
all broken sets, by looking for a special collection of broken
sets that has the property that any installation that cannot be
upgraded contains at least one element of this collection; we
call any such collection a cover .
To efﬁciently build such a cover, we needed to combine
several key ideas. We illustrate them here on small examples
of repository evolutions, that are represented graphically by
indicating the newly added packages, dependencies or conﬂicts
by dashed lines or borders.
Using explanations to choose relevant broken sets. We
remark that broken sets are closed by superset: if Πcannot be
upgraded, then all Π′⊇Πfail as well. So, we might want to
only consider broken sets of minimal size. But the fact that
a broken set has minimal size does not mean that it must be
included in a cover, as we can see in the repository shown in
Figure 5. Here we have three packages depending on p0and
three packages depending on q0: adding the conﬂict between
p0andq0in the new repository prevents the upgrade of any
installation containing simultaneously one of the piand one
of theqipackages. In this case, all the sets {pi,qj}built
by taking one package on the left and one on the right are
2The current Debian testing distribution is approaching 30.000 packages,
and the basic collection of Eclipse plugins contains over 5.000 elements.a
b c
d# #
(a) conjunctiona
b c
d∨
# #
(b) disjunction
Fig. 6. Multiple explanations
a
b c#
Fig. 7. Broken sets: minimal size vs. minimal explanation
broken sets of minimal size, but one of these broken sets,
namely{p0,q0}, is much better than the others: indeed, any
installation containing one of the {pi,qj}necessarily contains
also{p0,q0}, which is sufﬁcient, alone, to provide a cover.
To capture the reason why {p0,q0}is better than the other
sets, we call explanation of a broken set Πin a repository
R= (P,D,C)any subrepository (as formally deﬁned in
Section IV-A) of Rin which Πis still a broken set, and
then we give our preference to the broken sets with minimal
explanations. In Figure 5, {p0,q0}is the broken set with the
minimal explanation: all other pairs have an explanation that
contains it.
There can be several minimal explanations associated with
a broken set: for instance, in the repository Rof Figure 6a,
the broken set {a,d}has one minimal explanation that is R
restricted to packages {a,b,d}, and another minimal expla-
nation that is Rrestricted to packages {a,c,d}. In this case,
it is easy to see that any installation containing {a,d}must
also contain either {b,d}or{c,d}. This means that we have
the choice, when building a cover, to replace {a,d}by either
one of the two other broken sets, and we prefer {b,d}or
{c,d}, because they have smaller explanations than {a,d}.
The repository Rof Figure 6b illustrates a dual situation: here
the broken set {a,d}has a unique minimal explanation, the
full repository. But we prefer to add to a cover the two broken
sets{b,d}and{c,d}, instead of {a,d}, because they both
have smaller explanations than the broken set {a,d}.
Unfortunately, it is not always possible to minimise simul-
taneously the cardinality of a broken set and the size of its
explanation, as can be seen in the repository of Figure 7;
here we have the choice between taking as best broken set
either{a}, which has as explanation all the repository, or
the set{a,b}, which is bigger, but has a smaller explanation
consisting of the repository without the dependency from ato
b. Our algorithm combines the two minimisation techniques
by ﬁrst enumerating all possible minimal explanations of a
given shape, and then taking minimal broken sets for each of
them.
Focusing on explanations containing only new conﬂictsor new dependencies. The second insight is that if it is
impossible to upgrade an installation, the cause must lie with
thechanges made to the repository, so we should start our
search from the differences between the old and the new
repository. Indeed, a fundamental result proven in this work is
that when searching for broken sets to add to a cover, we
can restrict our attention to explanations that have as root
cause only new conﬂicts andnew dependencies . This allows
to reduce dramatically the search space, by only enumerating
explanations involving new conﬂicts and new dependencies.
Building explanations by combining ﬂattened dependen-
cies. The ﬁnal ingredient of our approach is the reuse of
several transformations from [24] that leave co-installability
invariant, which we recalled in subsection II-B. After these
transformations, the new repository is put in a simpliﬁed,
ﬂattened form, that allows to enumerate explanations by just
combining together the ﬂattened dependencies, joining them
when they share conﬂicts.
Combining these three key ideas, we could devise an
algorithm that is complete and extremely efﬁcient in practice,
ﬁnding covers that contain very small broken sets, and
providing minimal explanations for each broken set.
3) Visualising upgrade issues: To visualise in a compelling
way the upgrade issues, we ﬁrst draw a graph of the broken
sets in the cover, as can be seen in Figure 9: this allows a
repository maintainer to quickly identify the new incompati-
bilities, and select the ones he wants to focus on.
Then, for each broken set in the cover, we draw a graph,
called full explanation , that conveys concisely all the informa-
tion necessary to understand why it was co-installable in the
original repository, and is no longer co-installable in the new
one. In this graph, dependencies and conﬂicts are drawn with
different styles: solid lines indicate an object present in both
the old and new repositories, dashed lines indicate an object
present only in the new repository, and dotted lines indicate
an object present only in the old one.
Two examples of full explanations are given in Figure 10,
which can be read as follows. In Figure 10a, we see that
tdbsodbc is no longer co-installable with libiodbc2
because the new version of package tdbsodbc is in conﬂict
with both versions, old and new, of libiodbc2 . In Fig-
ure 10b, we see that speechd-el is no longer co-installable
withemacs23-nox because all versions of emacs23 con-
ﬂict with all versions of emacs23-nox , and both versions
ofspeechd-el depend on any version of emacs23 , or on
the old version of eieio .
III. E XPERIMENTAL RESULTS
An OCaml program implementing the algorithm described
in this paper is available, together with a few sample outputs,
from http://coinst.irill.org/upgrades.
We have run it on several instances of repository evolutions
of the Debian GNU/Linux distributions that correspond to the
two main use cases of the tool. Analysing major upgrades
requires comparing one version of a distribution to the next;we tested two such cases by comparing two successive releases
of Debian (oldstable and stable), and the last Debian stable
release (February 2011) versus the 13 February 2012 snapshot
of the testing release (i386 architecture). Identifying recently
introduced issues requires comparing versions of a distribution
during the development phase; we tested several instances of
this scenario by comparing various pairs of testing snapshots
monthly from October 2011 to February 2012.
A summary of the result is shown in the table below; the
running time has been measured on a machine using an Intel
Core i7-870 at 2.93GHz.
Distributions Running time Broken sets
oldstable – stable 7.4s 202
stable – testing 14.9s 346
2012-01-20 – 2012-01-20 6.2s 64
In ﬁgure 9, one can see the full set of upgrade issues
between the stable version of Debian and the snapshot of the
testing version, which ﬁts on a single A4 page. On this graph,
an edge connecting two packages stands for a broken pair
of packages. A larger broken set is represented by a circle
connected to the packages it contains. One can see that, with
only two exceptions, the broken sets that compose the cover
contain just two packages.
Looking at some of the transitions, we could ﬁnd several
real upgrade issues in the evolution of the Debian repositories;
many of them are due to incomplete migrations of related
packages, like in the case of the tesseract example shown
in the introduction, but there are more damaging ones, like
the transition from gnat-4.4 tognat-4.6 where some
packages changed to depend from the old version to the new
one starting in December 2011, while most packages are still
depending on the old one in February 2012.
IV. F ORMAL DEVELOPMENT
We now turn to the formal development of our approach,
and present the fundamental theoretical results of our work,
which allow to ﬁnd a cover containing a limited number
of small broken sets, and to provide concise and readable
explanations for each of them.
A. Finding Broken Sets
As highlighted in the previous section, in order to ﬁnd a
cover of broken sets for a repository R, we focus on explana-
tions , which are particular subrepositories ofR′consisting of
dependencies and conﬂicts that may prevent the installation of
a set of packages that were previously co-installable.
Formally, a repository R= (P1,D1,C1)is asubrepository
of another repository (P2,D2,C2), written R⊆R′, when
P1⊆P2,∀π∈P1,D1(π)⊆D2(π),C1⊆C2.
Our algorithm enumerates such explanations, striving to satisfy
two conﬂicting objectives: on one side, we want to ﬁnd enough
explanations to get a cover, but on the other side we want to
keep the number of explanations small enough to keep the
problem tractable and the report readable.1) Reduced Repositories: We start by putting the two initial
repositories in a reduced form by applying, in this order, the
following co-installability invariant transformations from [24]:
1) perform ﬂattening (see Theorem 6 of [24]);
2) remove redundant conﬂicts (see Lemma 14 of [24]);
3) remove remaining irrelevant dependencies (see Theorem
8 and 9, and Lemma 13 of [24]);
4) canonise dependencies (see Theorem 2 of [24]).
We write (P,/tildewideD,/tildewideC)for the reduced repository computed
from a repository (P,D,C). Compared to [24], we do not
remove an irrelevant dependency dof a package πif we can
ﬁndd′∈/tildewideD(π0)andd0∈D(π0)such that π∈d0and
d⊆d′, so as to validate the crucial lemma 4 below. All
clearly irrelevant dependencies and in practice almost all other
irrelevant dependencies can still be removed.
2) Weak Co-Installability: An important feature of reduced
repositories is that one does not need to consider dependencies
recursively to check co-installability. Instead, we can adopt a
two-level view of repositories: given a set of packages at the
upper level, they are (weakly) co-installable if one can ﬁnd a
set of packages at the lower level (called features ) that satisﬁes
their dependencies and that do not conﬂict with one another.
Aconﬁguration is a pair(I,F)of a setIof packages and a
setFof features; we say that it is healthy when the following
conditions hold:
•abundance : every package has the features it needs. For-
mally, for every package π∈I, and for every dependency
d∈D(π), we have d∩F/\e}atio\slash=∅.
•peace : no two features conﬂict, that is, C∩(F×F) =∅.
The following key theorem is a direct consequence of our
previous work [24], as its proof is just a composition of
the theorems corresponding to each of the transformations
performed to obtain a reduced repository:
Theorem 1: A set of packages is co-installable in an initial
repository if and only if it is weakly co-installable in the
corresponding reduced repository.
3) Minimal Explanations: Given a set of packages Πnot
weakly co-installable in a reduced repository (P,/tildewideD,/tildewideC), we
callexplanation ofΠany subrepository of (P,/tildewideD,/tildewideC)in which
Πis not weakly co-installable. Explanations correspond to the
so-called unsatisﬁable cores of SAT problems [7]. There may
be several explanations for a set of packages Π. Considering
only the minimal ones, with respect to the subrepository rela-
tion, is sufﬁcient. They have a very speciﬁc shape, illustrated
in Figure 8, as shown by the following theorem.
Theorem 2: A minimal explanation (PΠ,DΠ,CΠ)of a bro-
ken setΠhas the following properties:
•the set of dependencies and conﬂicts is connected
•only packages in Πhave dependencies: if π/\e}atio\slash∈Π, then
DΠ(π) =∅
•all packages in a dependency have a conﬂict: ∀π∈
P,∀d∈DΠ(π),∀π′∈d,∃π′′∈P,(π′,π′′)∈CΠ;
•packages in conﬂict belong to a dependency: ∀(π′,π′′)∈
CΠ,∃d∈DΠ(π),π′∈d;Π
∨
# #
Fig. 8. Typical shape of a minimal explanation
•if the set Πis minimal and π∈Π, thenDΠ(π)/\e}atio\slash=∅.
B. Focusing on Interesting Explanations
We can take advantage of the similarities between the old
and new repositories to only consider some of the minimal ex-
planations above, built using only a subset of the dependencies
and conﬂicts of the new reduced repository.
First of all, the packages in a broken set, by deﬁnition,
are present in both repositories, so new packages have no
dependencies in a minimal explanation. In the following
subsections we show that we can restrict our attention to
minimal explanations containing only a very restricted form
of dependencies; this characterisation is essential to prune the
search space when we enumerate minimal explanations. For
the sake of clarity, we ﬁrst explain some of the pruning we
could perform if we were working on the initial repositories,
before turning to the case of reduced repositories.
1) Interesting Explanations in Non Reduced Repositories:
We consider an old repository (P′,D′,C′)and a new repos-
itory(P,D,C). We call new dependency a dependency d∈
D(π)of some package π∈P∩P′, such that there is no
dependency d′∈D′(π)such that d′⊆d. An explanation
for a non co-installable set of packages is a subrepository
in which these packages are still not co-installable. The
following lemma shows that if we were to enumerate minimal
explanations in the initial repositories, it would be sufﬁcient to
consider explanations in which the root dependencies are all
new. The proof of the lemma relies on iteratively removing
root dependencies that are not new in the explanations. We
writeR\{π/mapsto→d}for the repository Rwhere the dependency
dof package πhas been removed.
Theorem 3: There exists a cover Ccontaining only broken
setsΠhaving an explanation (PΠ,DΠ,CΠ)such that all
dependencies in DΠ(π)forπ∈Πare new dependencies.
Proof: We show that by starting with any cover Cand
iteratively applying a suitable transformation, we eventually
reach a cover that satisﬁes the above property.
Consider a cover Ccontaining a broken set Π, with explana-
tionRΠ= (PΠ,DΠ,CΠ). Suppose that there exists a package
π∈Πand a dependency d∈DΠ(π)which is not new. Then,
we claim that the set
C1=C \{Π}∪{Π∪{π1}broken|π1∈d∩P′}
is also a cover, and that the subrepository RΠ\{π/mapsto→d}is an
explanation for all broken sets Π∪{π1}. LetI′be an healthy
installation of R′that cannot be successfully upgraded. We
need to prove that it includes a broken set in C1. AsCis
a cover, there exists a broken set Π1inCthat is containedinI′. IfΠ1/\e}atio\slash= Π , thenΠ1∈ C1and we are done. We now
consider the case where Π⊆I′. Asdis not new, there exists
d′∈D′(π)such that d′⊆d. AsI′is an healthy installation
ofR′that contains package π, by abundance, there exists a
packageπ′∈d′∩I′. Note that π′∈d∩P′. Thus the set
Π∪ {π′}, included in I′was co-installable, and therefore is
included in C1, as wanted, provided it is not co-installable in
R. Suppose this were not the case. Then, it would also be
co-installable in the subrepository RΠ\ {π/mapsto→d}. But then,
it is easy to see that Πwould be co-installable in RΠ, which
contradicts our hypotheses. Hence, the set is not co-installable,
which complete this part of the proof.
To prove termination, we keep track of an explanation for
each of the broken sets in the cover, that is, we consider sets
formed of pairs (Π,RΠ)composed of a broken set and the
corresponding explanation such that the collection of broken
setsΠis a cover. Then, the operation above consists in
removing pairs from the set, adding new pairs with strictly
smaller explanations. Clearly, this process terminates. At this
point, the operation cannot be applied anymore, which means
that we have a cover that proves the lemma.
2) Taking Advantage of Reduced Repositories: We now
turn to reduced repositories, and establish a similar result,
but with the important difference that we do not need all
the new dependencies: we show that it is enough to consider
those dependencies which are both new w.r.t. the reduced
repositories, and whose derivation tree has at the root a
dependency which is new in the non reduced repository. We
call such dependencies fully new .
To the new repository (P,D,C), we associate the ﬂattened
repository (P,/hatwideD,C). Each dependency din/hatwideD(π)can be seen
as a composition of dependencies: in the derivation below, dis
the composition of dependency d0from the initial repository
and dependencies difrom the ﬂattened repository.
d0={π1,...,π n} ∈D(π)...
d1∈/hatwideD(π1)......
dn∈/hatwideD(πn)
d=/uniondisplay
1≤i≤ndi∈/hatwideD(π)
A crucial lemma shows that a similar property holds for
dependencies in the reduced repository (P,/tildewideD,/tildewideC). We call
lean derivation tree a derivation tree of d∈/hatwideD(π)such that, for
any conclusion d′∈/hatwideD(π′)of a subderivation of this tree, we
haved′∈/tildewideD(π′)as well. With such a tree, we can decompose
a dependency in /tildewideDwhile remaining in /tildewideD.
Lemma 4: All dependencies in /tildewideD(π)for allπ∈Phave a
lean derivation tree.
Proof: We show that, given a dependency d∈/tildewideD(π)
and any derivation tree of d∈/hatwideD(π), we can ﬁnd a lean
derivation tree. The proof is by induction on the cardinality of
the dependency d, then by induction on the size of the initial
derivation tree.
The base case, where the tree is just composed of rule REFL,
is immediate. Otherwise, the tree starts by an application of
rule TRANS to some dependency d0∈D(π)and subtrees with
conclusions di∈/hatwideD(πi)forπi∈d0. We are going to showthat for each πi∈d0, we can ﬁnd a lean derivation tree with
conclusion d′
i∈/hatwideD(πi)for some dependency d′
i⊆di. Then, by
applying rule TRANS ond0and these trees, we get a derivation
tree for a dependency/uniontext
id′
i∈/hatwideD(πi). Due to canonisation, as/uniontext
id′
i⊆/uniontext
idi=d, we must have/uniontext
id′
i=d, and thus we
have a lean derivation for d.
We now prove the existence of suitable dependencies d′
i.
A dependency in /hatwideD(πi)but not in /tildewideD(πi)is either irrelevant
or implied by another dependency in /tildewideD(πi). Sincedi⊆d
and the dependency dis still in /tildewideD(π), the dependency di
has not been removed due to irrelevancy either. Therefore, by
deﬁnition of canonisation, we can ﬁnd d′
i∈/tildewideD(πi)such that
d′
i⊆di. Ifdi=d′
i, we ﬁnd a lean derivation tree by applying
the induction hypothesis of the inner induction. Otherwise, the
cardinality of d′
iis strictly smaller than the cardinality of d.
Hence, we can apply the induction hypothesis of the outer
induction to get the lean derivation tree.
Theorem 5: There exists a cover Ccontaining only broken
setsΠwith an explanation (PΠ,DΠ,CΠ)such that all depen-
dencies in DΠ(π)forπ∈Πare either self-dependencies or
fully new dependencies.
Proof: Starting from the cover composed of all possible
broken sets, we can associate to each of these sets an expla-
nation, and to each dependency in this explanation, we can
associate a lean derivation tree by Lemma 4.
Adapting the proof of Lemma 3, if one of these derivation
trees start by a rule TRANS involving a dependency which is
not new in the non ﬂattened repository, we can build a new
cover by removing the corresponding broken set and adding
other broken sets with the explanation where the tree has been
replaced by all immediate subtrees above the rule TRANS . We
are replacing subtrees by strictly smaller subtrees. Hence, the
process eventually terminates, yielding a cover for which no
associated derivation trees start with a dependency which is
not new in the non ﬂattened repository.
After this ﬁrst transformation, we mimic again the argument
of the proof of Lemma 3 to remove all ﬂattened dependencies
dthat are not new; after each removal, it may be necessary
to add some self-dependencies, which are important for weak
co-installability.
3) Pruning Conﬂicts and Self Dependencies: We can fur-
ther restrict the search space when enumerating minimal
explanations as follows.
If a minimal explanation contains a conﬂict and self-depen-
dencies for the two packages in conﬂict, then it is reduced
to this conﬂict and these dependencies. Besides, this conﬂict
must be a new conﬂict , that is, a pair of packages πandπ′,
both inP∩P′such that (π,π′)∈C\C′.
Otherwise, the minimal explanation is composed of fully
new dependencies, of conﬂicts that connect a new dependency
to either another fully new dependency or a package in P∩P′,
and of the self dependencies for such packages.
So we can ﬁrst inspect all new conﬂicts, to capture the
ﬁrst kind of explanations, and then drop all conﬂicts and self
dependencies that do not correspond to the conﬁguration of
the second kind before continuing to enumerate explanations.C. Simplifying covers
A cover containing only broken sets with minimal explana-
tions may be further simpliﬁed, using a notion of implication
that generalises to sets of packages the strong dependencies
introduced in [1].
We say that a set of packages S1implies a set of packages
S2, written S1⇒S2, ifS1is installable and every healthy
installation containing S1also contains S2.
If in a cover C={Π1,...Πn}there is some broken set Πi
that implies another broken set Πjin the old repository, then
C \{Πi}is still a cover, and we can safely drop Πi.
Computing implications may be expensive, though, so we
only implement an approximation of this simpliﬁcation step
in our algorithm, that turns out to provide a good compromise
in practice, and is based on the following notions.
We say that a broken set Π1implies pointwise another
broken set Π2if for every package π2∈Π2there exists a
package π1∈Π1such that {π1}implies{π2}in the old
repository. We approximate the implication between packages
by following only conjunctive dependencies: this can be done
with the following rules.
CONJ-REFL
π⇒πCONJ-TRANS
{π1,...,π n} ∈D(π)
π1⇒π′... π n⇒π′
π⇒π′
V. P UTTING IT ALL TOGETHER :THE ALGORITHM
The algorithm takes as input the old repository (P′,D′,C′)
and the new repository (P,D,C). It starts by comput-
ing the corresponding reduced repositories (P′,/tildewiderD′,/tildewiderC′)and
(P,/tildewideD,/tildewideC), as described in Section IV-A1), and initialises a
SAT solver with their encodings, as described in [14]: since
our solver allows to check co-installability without rebuilding
the encodings, such checks are blazingly fast and can be
performed at little cost in the rest of the process.
We then progressively build a cover in two phases, corre-
sponding to the observations of Section IV-B3.
Broken sets corresponding to new conﬂicts. We ﬁrst ﬁnd
the pairs of packages (π1,π2)∈/tildewideC\/tildewiderC′which are broken sets.
For each of these pairs, we add to the cover a broken set of
minimal cardinality contained in it.
Other Broken Sets. We ﬁrst compute a subrepository
(P,D1,C1)of(P,/tildewideD,/tildewideC)that contains all relevant minimal
explanations, by removing from (P,/tildewideD,/tildewideC)the conﬂicts and
dependencies that may be dropped according to Section IV-B3.
For this, we start by computing the fully new dependencies
(Section IV-B2), and the subset C1⊆/tildewideCof conﬂicts that
involve at least a package in a new dependency, and whose
other package is either in P∩P′or belongs to a new
dependency as well. We then remove fully new dependencies
that are irrelevant with respect to C1and ﬁnally add self-
dependencies on packages in P∩P′with a conﬂict. This
gives us the repository (P,D1,C1).
To ﬁnd the explanations we are interested in, we enumerate
all dependency functions D2pointwise included in D1suchthat all dependencies in D2are connected through conﬂicts in
C1, using a backtracking algorithm.
In order not to consider all permutations of dependencies,
we keep track of two sets of dependencies when building ex-
planations: the positive set of dependencies that are part of the
explanation; a negative set of dependencies that are not going
to be part of any further explanation. When backtracking, we
add the dependency to the negative set, as all explanations
it may be involved into have already been considered. The
process starts with the two sets being empty. We add a ﬁrst
dependency to the positive set, then repeatedly add dependen-
cies connected to other dependencies in the positive sets. All
possible combinations are considered through backtracking.
At each step, the set of all packages {π|D2(π)/\e}atio\slash=∅}
included in the positive set is a candidate broken set . Each
time a minimum broken set is built, it is added to the cover.
Final simpliﬁcation. Finally, we identify all broken sets Π
that can be shown to imply pointwise another broken set
following only conjunctive dependencies, and remove them
to obtain the ﬁnal cover (Section IV-C).
VI. E XPLAINING BROKEN SETS
As said in Section II-D3, we associate to each broken set Π
a graph called full explanation, which is computed as follows.
We run a SAT solver on the unsatisﬁable problem obtained by
encoding the new repository and asserting the packages in Π,
and then extract an unsatisﬁable core [7].
Since in our encoding each Boolean clause of the SAT
problem corresponds exactly to one dependency or conﬂict,
the unsatisﬁable core can be immediately turned into an
explanation. Then, we annotate appropriately each dependency
and conﬂict in this explanation: a dependency can be present
in both the old and the new repository, or just in one of them;
the possible targets of a dependency might satisfy it in the old
repository, the new one, or both; similarly, a conﬂict might be
between all possible versions of a pair of packages, between
one version of a package and any version of the other, or
between two precise versions of the packages. As explained
in Section II-D3, different line styles distinguish these cases.
VII. R ELATED WORKS
Ensuring the correct behaviour of components when com-
posed into an assembly is a fundamental concern for mod-
ern software architectures, and has been extensively studied;
dynamic aspects of the components are considered to ensure
certain properties of their composition [13], [21], to automati-
cally detect behavioural incompatibilities from the component
source code [15], or to deploy and upgrade such systems [4],
[9]. Research on static inter-module dependencies is also
largely performed at the level of the component source code,
with dependencies automatically extracted from huge sets of
source code, and then used to predict failures [8], [16], [17],
[26], or to guide automated testing [25]; some work, like [19],
manually analyse the architectural dependencies to improve
the modularisation of the software architecture, on problemspython-envisageplugins
mayavi2
python-enable python-traitsbackendqt (x 2)
magit (x 45) liboss-salsa-asound2
xul-ext-adblock-plussoftware-properties-kdemdbtools-dev (x 4)
libqt4-phononkredentials (x 7)
kid3-qt
libdap-dev
libcurl4-openssl-devliboauth-dev
heimdal-dev
grass-devlibgdal1-dev
code-saturne-includelibhdf4-devlibdnet-devbinutils-gold
lazarus (x 7)fpc
libjpeg62-dev
libhdf5-lam-1.8.4 (x 2)
cdoparaview (x 3)
gnudatalanguagelibhdf5-serial-1.8.4libopal-deviceape-browser (x 4)
libgdchart-gd2-xpm-dev (x 22)libkio5 (x 2)
libcurl4-gnutls-dev
libiodbc2-dev (x 3)fp-units-multimedia
libgcal-dev
libmagplus3 (x 4)libxqilla-dev libxerces-c2-dev libmedc-dev
libsc-dev (x 2)libcups2-dev (x 2)gnome-core-devel (x 5) libgl1-mesa-swx11
gnome-desktop-environment (x 5) libgpod4-nogtk
filelight-l10n kde-l10n-cavalencia (x 51)mingw32-ocaml (x 2) mingw32-binutilsphp-apc php5-xcache
speechd-el emacs23-lucid (x 2)
capplets-data gnome-utils (x 2)cyrus-dev-2.2 (x 5)
sa-learn-cyrus
harden-servers
cyrus-doc-2.2 (x 4) kolab-cyrus-commoncyrus-imapd-2.2
bindfs (x 15) loop-aes-utils
smcroute pimdgnome-core gpe-login (x 3)
libamrita2-ruby1.8 (x 2) libamrita-ruby1.8bcfg2-server fam (x 2)libqwt5-qt4-dev libqwt-devgnome-api-docs libclutter-gtk-0.10-doc
zabbix-server-pgsql (x 2) zabbix-proxy-mysql (x 2)
texmacs-common texmacs-extra-fontsw3c-dtd-xhtml w3c-markup-validatorlibgdb-dev (x 2) gdb-minimal
kbd gcpeggkcc heimdal-clients
libodbc-ruby1.9.1 (x 7) libodbc-ruby-dococtave3.2-headers (x 2) libreiser4-dev
libcdb-dev libowfat-dev policycoreutils mcstranspacemaker (x 2) cluster-agents
linkchecker python-dnspythonocsinventory-reportslibapache2-mod-php5filter (x 3)
libgd2-noxpm
libcgi-application-extra-plugin-bundle-perl (x 3)
libgd-gd2-noxpm-perl
libgnuift0-dev (x 2) graphicsmagick-libmagick-dev-compatgnat-4.4 ahven-dbg (x 2)
fso-gpsd kde-window-manager
obexd-server gnome-session
libdb4.8-dev libdb-devldtp python-pyatspi
Fig. 9. Problematic upgrades in Debian, i386, Stable vs. Testing (13 February 2012)
tdsodbc libiodbc2
(a)emacs23-nox emacs23
speechd-el
eieio∨
(b)
Fig. 10. Actual broken sets and their full explanationssmall enough (some 20 components) to avoid the need for
automation.
Our work is part of a recent research area that focuses
on the properties of large component repositories that can be
established automatically without looking at the source code of
the components, and without testing them: it is only assumed
that each component carries with itself a small amount of
metadata describing what the component provides and what
it requires to be deployed and run. In most frameworks,
determining whether a single component can be installed at all
is an NP-Complete problem [2], albeit the concrete instances
arising in real-world systems, like GNU/Linux distributions,
Eclipse plugins or OSGI component repositories, turn out to
be tractable [14], [23], [6], [5], [22], [11], [12].
For the maintenance of component repositories, though,
more sophisticated analyses are required. This includes iden-
tifying for each component the other components that it
absolutely needs [1], those that it can never be installed
with [10], and what component upgrades are more likely to
impact a repository [3].
An important advance in this area was made in [24],
that shows how to efﬁciently extract from any component
repository a much smaller co-installability kernel that allows to
identify directly the sets of components that cannot be installed
together. This makes it possible for a quality assurance team to
quickly ﬁnd component incompatibilities in a given repository .
The present work is a signiﬁcant step forward in this
direction, as it provides for the ﬁrst time a means to identify
how coinstallability evolves from one version of the repository
to another, and provides simple and effective explanations for
quality assurance teams that want to understand why some
components that were coinstallable become all of a sudden
incompatible. While the examples in this paper all come from
the world of GNU/Linux distributions, the algorithm presented
can be applied directly to other frameworks, like Eclipse
plugins or OSGI component repositories.
VIII. C ONCLUSION
We have shown that it is possible to determine how co-
installable sets of packages change across repository evolu-
tions and developed an algorithm that computes efﬁciently
a concise representation of the upgrade issues introduced by
such changes. We have also shown how to present concisely all
the information relevant for understanding the origin and the
importance of an upgrade issue with an informative graphical
explanation. A tool implementing the algorithm presented in
this paper is available as free software, and is able to process
the evolution between two major releases of the Debian
GNU/Linux distribution, and compute all the explanations, in
just a few seconds. These results make it possible to integrate
seamlessly this analysis in a repository development process.
Acknowledgments: the authors would like to thank Mehdi
Dogguy, Ralf Treinen and Stefano Zacchiroli for interesting
discussions on the Debian repository evolution process.
Code and data availability: the tool, together with a few
sample outputs, can be found at http://coinst.irill.org/upgradesREFERENCES
[1] P. Abate, J. Boender, R. Di Cosmo, and S. Zacchiroli. Strong depen-
dencies between software components. In ESEM , pages 89–99. IEEE
Press, Oct. 2009.
[2] P. Abate, R. Di Cosmo, R. Treinen, and S. Zacchiroli. Dependency solv-
ing: a separate concern in component evolution management. Journal
of System and Software Science , 85(10):2228 – 2240, 2012.
[3] P. Abate, R. Di Cosmo, R. Treinen, and S. Zacchiroli. Learning from
the Future of Component Repositories. In CBSE-2012 , Bertinoro, Italie,
June 2012. ACM.
[4] S. Ajmani, B. Liskov, and L. Shrira. Modular software upgrades for
distributed systems. In ECOOP , pages 452–476, 2006.
[5] J. Argelich, D. Le Berre, I. Lynce, J. Marques-Silva, and P. Rapicault.
Solving Linux upgradeability problems using boolean optimization. In
LoCoCo , volume 29 of EPTCS , pages 11–22, 2010.
[6] D. L. Berre and A. Parrain. On sat technologies for dependency
management and beyond. In SPLC (2) , pages 197–200, 2008.
[7] R. Bruni. Approximating minimal unsatisﬁable subformulae by means
of adaptive core search. Discrete Appl. Math. , 130(2):85–100, Aug.
2003.
[8] H. Cleve and A. Zeller. Locating causes of program failures. In ICSE ,
pages 342–351, 2005.
[9] O. Crameri, N. Knezevic, D. Kostic, R. Bianchini, and W. Zwaenepoel.
Staged deployment in mirage, an integrated software upgrade testing
and distribution system. SIGOPS Oper. Syst. Rev. , 41(6):221–236, Oct.
2007.
[10] R. Di Cosmo and J. Boender. Using strong conﬂicts to detect quality
issues in component-based complex systems. In ISEC , pages 163–172,
New York, NY , USA, 2010. ACM.
[11] R. Di Cosmo, O. Lhomme, and C. Michel. Aligning component
upgrades. In C. Drescher, I. Lynce, and R. Treinen, editors, LoCoCo ,
volume 65 of EPTCS , pages 1–11, 2011.
[12] M. Gebser, R. Kaminski, and T. Schaub. aspcud: A linux package
conﬁguration tool based on answer set programming. In LoCoCo ,
volume 65 of EPTCS , pages 12–25, 2011.
[13] P. Inverardi, A. L. Wolf, and D. Yankelevich. Static checking of
system behaviors using derived component assumptions. ACM TOSEM ,
9(3):239–272, 2000.
[14] F. Mancinelli, J. Boender, R. Di Cosmo, J. V ouillon, B. Durak, X. Leroy,
and R. Treinen. Managing the complexity of large free and open source
package-based software distributions. In ASE, pages 199–208, 2006.
[15] S. McCamant and M. D. Ernst. Early identiﬁcation of incompatibilities
in multi-component upgrades. In ECOOP , pages 440–464, 2004.
[16] N. Nagappan and T. Ball. Using software dependencies and churn
metrics to predict ﬁeld failures: An empirical case study. In ESEM ,
pages 364–373, 2007.
[17] S. Neuhaus, T. Zimmermann, C. Holler, and A. Zeller. Predicting
vulnerable software components. In ACM CCS , pages 529–540, 2007.
[18] A. Orso, M. J. Harrold, D. Rosenblum, G. Rothermel, H. Do, and M. L.
Soffa. Using component metacontent to support the regression testing
of component-based software. In ICSM pages 716–, Washington, DC,
USA, 2001. IEEE Computer Society.
[19] H. Pei-Breivold, I. Crnkovic, R. Land, and S. Larsson. Using dependency
model to support software architecture evolution. In Evol, September
2008.
[20] The Coq Development Team. The Coq Proof Assistant Reference
Manual – Version V8.2 , 2008.
[21] M. Tivoli and P. Inverardi. Failure-free coordinators synthesis for
component-based architectures. Sci. Comput. Program. , 71(3):181–212,
2008.
[22] P. Trezentos, I. Lynce, and A. L. Oliveira. Apt-pbo: solving the software
dependency problem using pseudo-boolean optimization. In ASE, pages
427–436, 2010.
[23] C. Tucker, D. Shuffelton, R. Jhala, and S. Lerner. Opium: Optimal
package install/uninstall manager. In ICSE , pages 178–188, 2007.
[24] J. V ouillon and R. Di Cosmo. On software component co-installability.
InSIGSOFT FSE , pages 256–266, 2011.
[25] I.-C. Yoon, A. Sussman, A. Memon, and A. Porter. Direct-dependency-
based software compatibility testing. In Proceedings of ASE ’07 , pages
409–412, New York, NY , USA, 2007. ACM.
[26] T. Zimmermann and N. Nagappan. Predicting defects using network
analysis on dependency graphs. In ICSE’08 , pages 531–540. ACM,
2008.