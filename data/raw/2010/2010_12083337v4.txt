What Good Are Strong SpeciÔ¨Åcations?
Nadia PolikarpovaCarlo A. FuriaYu PeiYi WeiBertrand Meyer;y
Chair of Software Engineering, ETH Zurich, SwitzerlandyITMO National Research University, St. Petersburg, Russia
Ô¨Årstname.lastname@inf.ethz.ch
Abstract ‚ÄîExperience with lightweight formal methods sug-
gests that programmers are willing to write speciÔ¨Åcation if it
brings tangible beneÔ¨Åts to their usual development activities.
This paper considers stronger speciÔ¨Åcations and studies whether
they can be deployed as an incremental practice that brings
additional beneÔ¨Åts without being unacceptably expensive. We
introduce a methodology that extends Design by Contract to
write strong speciÔ¨Åcations of functional properties in the form of
preconditions, postconditions, and invariants. The methodology
aims at being palatable to developers who are not Ô¨Çuent in formal
techniques but are comfortable with writing simple speciÔ¨Åcations.
We evaluate the cost and the beneÔ¨Åts of using strong speciÔ¨Åcations
by applying the methodology to testing data structure implemen-
tations written in Eiffel and C#. In our extensive experiments,
testing against strong speciÔ¨Åcations detects twice as many bugs
as standard contracts, with a reasonable overhead in terms of
annotation burden and run-time performance while testing. In
the wide spectrum of formal techniques for software quality,
testing against strong speciÔ¨Åcations lies in a ‚Äúsweet spot‚Äù with a
favorable beneÔ¨Åt to effort ratio.
I. I NTRODUCTION
Many years of progress in the theory and practice of formal
methods notwithstanding, writing software speciÔ¨Åcations1still
seems to be ‚Äúdisliked by almost everyone‚Äù [1]. In many cases,
this disliking is a consequence of a high cost/beneÔ¨Åt ratio‚Äî
perceived or real‚Äîof writing and maintaining accurate spec-
iÔ¨Åcations on top of the code. After all, developers will write
speciÔ¨Åcations as long as they are simple, have a straightfor-
ward connection with the implementation, and help them write
and debug code better and faster. One example is Design by
Contract [2], [3] where simple executable speciÔ¨Åcations, writ-
ten in the same syntax as programming language expressions,
support design, incremental development, and testing and
debugging. Another one is test-driven development [4], where
rigorously deÔ¨Åned test cases play the role of speciÔ¨Åcations
in deÔ¨Åning correct and incorrect behavior. Experiences with
these techniques show that providing lightweight speciÔ¨Åcations
is an accepted practice when it brings tangible beneÔ¨Åts and
integrates well with the overall development process.
But what about strong speciÔ¨Åcations, which attempt to cap-
ture the entire (functional) behavior of the software? Should
we dismiss them on the grounds that the effort required to
write them is not justiÔ¨Åed against the beneÔ¨Åts they bring in
the majority of mundane software projects? This paper studies
the impact of deploying strong behavioral speciÔ¨Åcations, in
the form of contracts (pre- and postconditions and class
invariants), for detecting errors in software using automatic
testing.
1In this paper, we target formal speciÔ¨Åcations of functional properties.Using strong contracts involves costs and possible beneÔ¨Åts.
Among the former we have the programming effort necessary
to write such strong speciÔ¨Åcations and the runtime overhead
of checking them during execution. The beneÔ¨Åts may include
Ô¨Ånding more errors, Ô¨Ånding more subtle errors, Ô¨Ånding errors
more quickly, and exposing errors in ways that are easier
to understand and correct. Our contributions address the
cost factors‚Äîby measuring and trying to mitigate them‚Äîand
assess the beneÔ¨Åts:
Sect. III presents a methodology to write strong
speciÔ¨Åcations‚Äîextending our previous work [5]‚Äîthat
does not require Ô¨Çuency in formal techniques because it
is an extension of such traditional practices as Design by
Contract. This is instrumental in reducing the program-
ming effort associated with strong speciÔ¨Åcations.
The methodology comes with tool support and speciÔ¨Åca-
tion libraries, so that strong speciÔ¨Åcations are usable with
standard debugging and testing tools.
Sect. IV and V describe an extensive empirical study that
evaluates the use of strong contracts for real software
and measures their costs and beneÔ¨Åts in terms of defect
detection.
The bulk of our empirical study targets EiffelBase, a library
of generic containers and data structures (such as lists, tables,
and trees), which has been in use in the Eiffel community
for more than 20 years. The production version of EiffelBase
includes simple contracts, a form of partial speciÔ¨Åcation, that
are nonetheless quite effective at Ô¨Ånding implementation bugs
automatically using contract-based random testing [6], where
executable contracts serve as oracles and enable a push-button
testing process. In the present paper, we augment the simple
contracts that come with EiffelBase using the methodology
discussed in Sect. III. The result is EiffelBase+: a version of
EiffelBase with identical implementation but strong (mostly
complete) speciÔ¨Åcations.
In an extensive set of experiments, we compare the effec-
tiveness of random testing on EiffelBase and EiffelBase+, with
the goal of assessing whether the additional effort invested
into the strong contracts pays off in terms of quantity and
complexity of the bugs found. Our experiments show that
these measures dramatically increase when deploying strong
speciÔ¨Åcations: random testing found twice as many bugs in
EiffelBase+, and the simple contracts of EiffelBase would
have uncovered none of the new bugs. The overhead size
of speciÔ¨Åcations, in contrast, remains moderate, with the
speciÔ¨Åcation-to-code ratio going from 0.2 to 0.46.arXiv:1208.3337v4  [cs.SE]  22 Feb 2013merge right (other :LINKED LIST [G])
require
notafter
other6=Void
other6=Current
ensure
count =oldcount +oldother .count
index =oldindex
end
TABLE I
STANDARD SPECIFICATION OF ROUTINE merge right INLINKED LIST .
Our approach to writing strong speciÔ¨Åcations that are ef-
fective for testing is not limited to Eiffel programs. In a
companion set of experiments, we applied the same technique
to writing strong speciÔ¨Åcations for the DSA C# library [7] and
tested the result using Pex [8]; in this case too we discovered
new bugs with reasonable additional effort.
II. S TRONG SPECIFICATIONS : ANEXAMPLE
The following example illustrates and justiÔ¨Åes the use of strong
speciÔ¨Åcations. Consider the EiffelBase class LINKED LIST‚Äî
Eiffel‚Äôs standard implementation of linked lists. Like many
containers in EiffelBase, LINKED LIST includes an internal
cursor to iterate over elements of the list. The query2index
gives the cursor‚Äôs position, which can be on any element of the
list in positions 1 through count, or take the special boundary
values 0 (‚Äú before ‚Äù the list) and count + 1(‚Äúafter‚Äù the list). The
attribute count denotes the number of elements in the list.
Tab. I shows the EiffelBase speciÔ¨Åcation of LINKED LIST‚Äôs
routine (method) merge right. The routine inserts another list
other passed as argument into the current list (denoted Current in
Eiffel, corresponding to thisin Java and C#) immediately after
the cursor position. For example, if Current stores the sequence
of elements bartwith cursor positioned on the ‚Äú r‚Äù (index = 3)
and other stores one,merge right changes Current tobaronet.
The precondition ( require ) speciÔ¨Åes that the routine cannot be
called when the cursor is after: there is no valid position to the
right of it. It also demands that other be non- Void (nullin Java
and C#) and not aliased with the Current list: otherwise, merg-
ing is not well deÔ¨Åned. The postcondition ( ensure ) describes
some expected effects of executing merge right: the Current list
will contain as many elements as it contained before the call to
merge right (denoted by oldcount) plus the number of elements
of the other list; and the cursor‚Äôs position index will not change.
The contracts in Tab. I are a good example of the kind of
speciÔ¨Åcation that Eiffel programmers normally write [9]: it is
correct and nontrivial, and it can help detect errors in the im-
plementation, such as performing partial merges or incorrectly
leaving the cursor at a different position. Unfortunately the
speciÔ¨Åcation is also incomplete, because it does not precisely
describe the expected state of the list after merging. In fact,
the current implementation of merge rightcontains an error that
is undetectable against the speciÔ¨Åcation of Tab. I. The error
2Aquery is an attribute or a function [2].merge right (other :LINKED LIST [G])
require
   As in Tab. I
modify sequence
ensure
sequence =old(sequence .front (index ) +
other .sequence +sequence .tail(index + 1))
end
TABLE II
MODEL -BASED SPECIFICATION OF ROUTINE merge right INLINKED LIST .
occurs in the special case of calling merge right with cursor
before the list ( index = 0): the implementation will insert other
at the second rather than at the Ô¨Årst position. For example,
merging foldand unwhen the cursor is before yields funold
instead of the correct unfold.
Sect. III presents a methodology to write, with moderate ef-
fort, strong speciÔ¨Åcations that extend and, whenever possible,
complete this kind of partial speciÔ¨Åcation. Tab. II shows the
strong speciÔ¨Åcation obtained by applying the methodology to
merge right, the way it appears in EiffelBase+. As is common
in most Eiffel projects, the programmer who wrote merge right
did a good job with the precondition, which is sufÔ¨Åciently
detailed and need not be strengthened. The postcondition,
however, turns into a single assertion that deÔ¨Ånes the sequence
of elements stored in the list after calling merge right as the
concatenation (operator +) of three segments: Current ‚Äôs original
sequence up until position index (written sequence .front (index )),
followed by other‚Äôs element sequence, followed by the original
sequence from position index + 1(written sequence .tail(index + 1)).
This postcondition relies on an abstract model of the linked
list in the form of a mathematical sequence of elements,
which was already implicitly present above, in the informal
description of the semantics of merge right. Models blend well
with Eiffel‚Äôs standard speciÔ¨Åcation constructs to help formalize
programmers‚Äô intuitive understanding of data structures se-
mantics. Using the strong postcondition in Tab. II, completely
automatic testing with the AutoTest tool [6] detected the error
that occurs in merge right when the cursor is before .
The postcondition in Tab. II describes how the sequence
changes, but it does not say what does not change . Including
the assertion index =oldindex from the original postcondition is
not sufÔ¨Åcient, as it only mentions one piece of state that does
not change. Instead we include the assertion modify sequence ,
which means that merge right may only modify the sequence
of elements in the Current list and nothing else . Together pre-,
postcondition, and modify clause give a complete speciÔ¨Åcation
ofmerge rightbehavior, against which we can automatically test
any implementation for correctness.
III. H OW TO WRITE STRONG SPECIFICATIONS
Writing good speciÔ¨Åcation is hard; at least this is the common
belief. Experience with Design by Contract suggests that
programmers can competently write simple speciÔ¨Åcations if
they can be expressed using familiar syntax. See for examplethe speciÔ¨Åcation in Tab. I, which refers to regular class queries
such as count and index, also used in the implementation.
Without further guidance and language support, however,
programmers tend to write only partial speciÔ¨Åcations, because
expressing complex properties is cumbersome. This section
describes model-based contracts (MBC): a methodology to
write strong speciÔ¨Åcations that structures and extends tradi-
tional Design by Contract. MBC includes simple guidelines
to deÔ¨Åne the abstract model of a class (Sect. III-A), and to
write pre- and postconditions of routines (Sect. III-B and III-C)
and other, more advanced, speciÔ¨Åcation elements (Sect. III-D
and III-E).
The MBC approach supports writing strong speciÔ¨Åcations in
a number of ways: models facilitate choosing the right level
of abstraction and expressing complex behavioral properties
concisely, while the structured discipline for writing postcon-
ditions and invariants, together with the notion of complete-
ness (Sect. III-D), provides precise guidelines as to which
properties are worth documenting in a contract, and when a
contract is strong enough. While fostering rigor and accuracy
in speciÔ¨Åcations, MBC is still palatable to practitioners be-
cause its notation is part of the programming language. When
developing speciÔ¨Åcations for testing, as opposed to formal
veriÔ¨Åcation, MBC can be exploited incrementally : developers
may skip writing the most advanced speciÔ¨Åcation elements (for
example, complex class invariants) while still getting strong
speciÔ¨Åcations that are useful to detect subtle errors.
The following subsections present MBC using examples
from EiffelBase. The few additional constructs introduced
by MBC are highlighted in a different color and underlined
in the examples (e.g., modify ). The current presentation of
MBC derives from previous work of ours [5], which focused
on using strong speciÔ¨Åcations when designing new software.
In this paper we adapt the principles introduced in [5] to
the goal of supplying existing software with Ô¨Çexible strong
speciÔ¨Åcations for runtime checking and automatic testing (see
Sect. III-F). We also extend the speciÔ¨Åcation methodology with
new construct that handle framing (Sect. III-D) and complex
class invariants (Sect. III-E).
A. Abstract Class Models
Writing strong speciÔ¨Åcations becomes simpler if we can
readily express the abstract state space of classes and how
it changes. Therefore, the Ô¨Årst step in specifying a class with
MBC is deÔ¨Åning a model for the class: a set of mathematical
elements that capture the abstract state space.
Syntactically, the annotation model (see Tab. III) declares
the abstract model of a class as a list of attributes or functions
called model queries ; each element listed after model is either
a query of basic type (Boolean, integer, or object reference)
already used in the implementation, or a speciÔ¨Åcation query ,
meaning a query introduced solely to deÔ¨Åne the model. As part
of our work on MBC, we developed the Mathematical Model
Library (MML), a collection of immutable Eiffel classes that
represent mathematical concepts useful for speciÔ¨Åcation: sets,
bags, sequences, maps, and relations. SpeciÔ¨Åcation queriesclass LINKED LIST [G]
model sequence ,index
sequence :MML SEQUENCE [G]
status speciÔ¨Åcation
   SpeciÔ¨Åcation query: sequence of elements in the list.
index :INTEGER
   Internal cursor position.
off:BOOLEAN
   Is the cursor not on a list element?
ensure
Result =notsequence .domain .has(index )
end
invariant
   Model constraint
0index and indexsequence .count + 1
   Attribute deÔ¨Ånition
count =sequence .count
   Linking invariant
bag=sequence .tobag
   Internal representation constraint
notsequence .isempty implies last cell.item =sequence .last
end
TABLE III
EXCERPT OF LINKED LIST ‚ÄôSMBC SPECIFICATION IN EIFFEL BASE+.
make use of MML classes to represent complex components
of class models. For example, LINKED LIST‚Äôs model in Tab. III
has two components: a speciÔ¨Åcation function sequence with
return type MML SEQUENCE that gives the abstract sequence
of elements stored in the list, and the ordinary class attribute
index of integer type.
Class models should be expressive enough to formalize the
class behavior as seen at the API level, without exposing
implementation-speciÔ¨Åc details. For example, the same ab-
stract model‚Äîa sequence of elements‚Äîis suitable for all three
implementations of lists in EiffelBase: singly-linked, doubly-
linked and array-based, as the particular representation does
not inÔ¨Çuence the functional properties of public routines. In
practice, it is usually easy to devise a model for a data struc-
ture using MML abstractions. Even for classes representing
complex real-world concepts, such as an ATM or a Ô¨Çight
scheduler, MML remains applicable if used incrementally to
deÔ¨Åne partial yet useful behavioral properties.
B. Preconditions
Theprecondition of a routine deÔ¨Ånes when a call to the routine
is valid. In practice preconditions appear to be the most widely
and accurately used form of contract [9]. Therefore, MBC does
not introduce special guidelines for writing preconditions.
C. Postconditions
Thepostcondition of a routine rdescribes the intended effects
of executing ron the object state; it is a relation between the
state just before (denoted using the keyword old) and the state
just after executing r.MBC postconditions express the intended effect of execut-
ing a routine on the model , that is in terms of the model
queries. Procedure merge right in Tab. II, for example, declares
its effect on the model query sequence of the current object. For
functions , the postcondition also mentions the returned object
(and its model queries) using the keyword Result . For example,
function offin Tab. III deÔ¨Ånes Result in terms of sequence and
index.
D. Framing SpeciÔ¨Åcation
An accurate routine speciÔ¨Åcation should limit the effects of
the routine execution to a certain part of the program state.
Such speciÔ¨Åcation elements are called framing speciÔ¨Åcations .
Eiffel offers no dedicated language support for writing
framing speciÔ¨Åcations. In principle this support is not strictly
necessary, because one can express the unchanged elements
in postconditions with expressions such as index =oldindex in
Tab. I. In practice, however, this is cumbersome because
any given routine usually affects only a handful of program
elements; hence explicitly specifying all that does not change
is verbose and tedious. In fact, Eiffel practitioners rarely write
framing speciÔ¨Åcations in this form.
In MBC, the keyword modify introduces a routine‚Äôs framing
speciÔ¨Åcation: a list of all model queries whose value is allowed
to change after executing the routine. For example, routine
merge right in Tab. II may only change sequence , but not index
and not any component of the other list‚Äôs model.
The modify clause mechanism is taken from other speciÔ¨Å-
cation notations and methodologies (e.g., Spec# [10]) usually
targeted to formal correctness proofs. It is only with a speci-
Ô¨Åcation technique based on models, however, that it becomes
practical for real classes and standard programming practices.
Writing modify clauses in terms of attributes would violate
information hiding and be of limited usefulness to the client,
while listing arbitrary public queries is too tedious: since the
values of several regular queries are often related (for example,
the value of offmay change when index changes; see Tab. III),
modify clauses should include all related queries, possibly also
queries with arguments and on other objects. Model queries
are instead normally only a small number, they are orthogonal,
and only depend on the state of the Current object. Hence
specifying which model queries change is not onerous; the
values of all other queries are automatically deÔ¨Åned in terms
of them.
This approach to framing also supports a simple deÔ¨Ånition
of speciÔ¨Åcation completeness: a routine postcondition and
framing speciÔ¨Åcation are complete if the relation between the
model‚Äôs pre- and poststate is a function .3Completeness is not
an imperative in the MBC methodology: programmers can still
approach writing postconditions and framing incrementally. It
should rather be viewed as a safeguard against accidentally
missing an important property.
3Such notion of completeness is of course relative to the model.E. Class Invariants
The class invariant speciÔ¨Åes global properties of valid in-
stances of a class, which every operation must preserve. Since
the semantics of class invariants can be subtle MBC intro-
duces additional dedicated constructs for complex invariant
properties. We borrow some ideas from the existing techniques
developed for formal correctness proofs (e.g., [10], among
many); unlike these sophisticated techniques, MBC‚Äôs solution
for class invariants does not target comprehensiveness, but is
easy to deploy and sufÔ¨Åcient in practice for Ô¨Ånding errors by
testing and avoiding spurious invariant violations.
Class invariant types. Like postconditions, class invariants
in MBC use models to describe which object states are valid
and which are not. For example, the Ô¨Årst invariant clause in
Tab. III constrains the values of the model queries sequence
and index, stating that index must never take values outside the
interval [0::sequence .count + 1].
Additionally, class invariants in MBC have three more spe-
ciÔ¨Åc usages: deÔ¨Ånitions of public attributes, linking invariants
and internal representation constraints. Public attributes, from
the class interface standpoint, are indistinguishable from public
functions, and thus their values should be deÔ¨Åned in terms of
model queries. An example of such attribute deÔ¨Ånition is the
second invariant clause in Tab. III, which explains the attribute
count is terms of the model query sequence .
Parent classes may use simpler abstract models than their
children. LINKED LIST, for instance, inherits from a generic
CONTAINER class whose model is a bag (multiset) rather than
a sequence, because the order of its elements is immaterial.
To reuse the speciÔ¨Åcation of the parent stated in terms of
a different model, we introduce class invariants that deÔ¨Åne
the parent‚Äôs model queries in terms of the child‚Äôs model; we
call them linking invariants . For example, the third invariant
clause in Tab. III says that the parent‚Äôs model query bag
contains the same elements as sequence , disregarding the order
(sequence .tobag).
Finally, internal representation constraints introduce speci-
Ô¨Åcations that relate the values of model queries to the private
attributes of the class. For example, the last invariant clause
in Tab. III says that the private attribute last cellstores the
same value as sequence ‚Äôs last element (whenever the sequence
is not empty). Unlike other MBC speciÔ¨Åcations, invariants
of this type do not describe the public interface of the
class and usually cannot be made complete without revealing
unnecessary implementation details in the model. However,
even in this limited form, they turned out to be very effective
at revealing errors that corrupt object‚Äôs internal representation
(see Sect. V-A).
Class invariant semantics. Eiffel checks class invariants
at the beginning and at the end of every qualiÔ¨Åed4call
on an object of the class. This rule prevents checking the
invariant whenever routines of a class call one another within
the boundaries of a single object, in order to accomplish a
common task, as the object will normally be inconsistent
4A call t.risqualiÔ¨Åed when the target tis an object other than Current .(‚Äúopen‚Äù) until all operations are completed. When circular
dependencies between objects arise, this semantics may lead
to spurious invariant violations: this is the dependent delegate
problem [11].
Consider an example derived from real code in EiffelBase:
a binary tree data structure, where each node has a link to its
parent and leftand right children. The Current node is executing
one of its routines and is temporarily in a state that violates
the invariant; to restore it, it makes a qualiÔ¨Åed call on, say, its
right child. The object right, however, does not know that its
parent is in the middle of executing a call; if right calls back
toCurrent , then, it detects an invariant violation even if right‚Äôs
call does not rely on the invariant.
MBC deploys a runtime semantics where these spurious in-
variant violations do not occur. Objects are implicitly equipped
with a Boolean attribute isopenthat is set to true at the entrance
of every public routine call on the object and restored to its
previous value when the routine terminates; class invariants
are checked only if isopen is false. This automatically solves
the dependent delegate problem in the presence of callbacks:
when right calls back to Current , the latter is open, and hence
its invariant is not checked.
This ‚Äúimplicit opening‚Äù mechanism is not sufÔ¨Åcient to
avoid spurious invariant violations when an object‚Äôs invariant
depends on the state of other objects. Consider again binary
trees; an invariant states that the Current node is its parent‚Äôs
left or right child:
parent6=Void implies (parent .left=Current or parent .right =
Current )
Routine prune leftremoves Current ‚Äôs left child as follows:
oldleft:=left
left:=Void
ifoldleft6=Void then oldleft.setparent (Void )end
When oldleft.setparent (Void )is called to remove the back-link
from Current ‚Äôs child, oldleft‚Äôs class invariant is violated: its
parent‚Äôs leftis already set to Void and oldleftis not open; in
fact, the very reason for calling setparent is to remove this
inconsistency. MBC provides the keyword depend to declare
that an invariant clause depends on the state of an attribute,
and hence it should be checked only if the object attached to
attribute is closed. Annotating the invariant in the example
with depend parent removes the spurious invariant violation
(oldleft.parent isCurrent , which is open).
In the few cases when Ô¨Åne-grained control over the opening
of objects is necessary, MBC provides the open clause for
routines, which explicitly opens the objects attached to some of
the routine‚Äôs arguments when the routine begins execution and
restores them when the routine terminates (as we discussed,
the target is always opened implicitly). Consider a variant of
the binary tree example where nodes have an attribute isroot
that should be true when their parent node is Void:
parent =Void implies isroot =True
In this variant, prune takes an argument of class NODE that is
supposed to be its left or right child and removes it as follows:prune (n:NODE )
do
ifleft=nthen
left.setparent (Void ) ;left.setroot (True ) ;left:=Void
end
ifright =nthen : : :end
end
When prune‚Äôs call to left.setparent returns, the invariant about
parent and isrootis violated ( left.parent =Voidbut left.isrootis still
false). Annotating prune with open nsuspends checking of n‚Äôs
invariant until prune terminates, thus removing the spurious
invariant violation.
As we discuss in Sect. IV, in EiffelBase+ we had to deploy
explicit depend and open annotations only in a very few cases,
limited to doubly-linked list nodes, and binary and n-ary trees.
F . Runtime Support for Strong SpeciÔ¨Åcations
Model-based postconditions and invariants can be checked at
runtime and used in testing out of the box: with the same
tools and user experience as standard Eiffel contracts. Model
queries introduced for speciÔ¨Åcation purposes are implemented
as regular functions that compute the abstract model value
from the concrete object state, and thus do not require explicit
initialization or updates. The speciÔ¨Åcation classes we provide
in MML are also regular Eiffel classes, implemented in a
functional style. Even though this approach to implementation
of model queries and model classes potentially incurs a high
runtime overhead, the experiment results in Sect. V conÔ¨Årm
that using MBC for contract-based testing is feasible.
Newly introduced speciÔ¨Åcation constructs, such as modify ,
depend and open, do not have any effect in the standard
Eiffel semantics: they are speciÔ¨Åed using notemeta-annotations
(similar to Javadoc or C#‚Äôs meta-data). We have developed a
simple tool that rewrites these annotations into plain Eiffel; for
example, modify clauses become explicit postconditions such
asitem =olditem. The MBC methodology is conservative, in
that the class semantics is still sound if we ignore the spe-
cial annotations; ignoring modify clauses, for instance, yields
weaker, yet correct, postconditions.
IV. U SING STRONG SPECIFICATIONS : EXPERIMENTS
We performed an extensive experimental evaluation to assess
the beneÔ¨Åts of using strong speciÔ¨Åcations for Ô¨Ånding errors in
software.
A. Research Questions
The overall goal of this evaluation is assessing and comparing
the advantages and the cost of deploying strong speciÔ¨Åcations
in the form of model-based contracts (MBC, described in
Sect. III) when applied to automatic contract-based testing of
real software.
This materializes into the following research questions:
1) Are strong speciÔ¨Åcations effective for Ô¨Ånding faults in
software?
2) Do strong speciÔ¨Åcations Ô¨Ånd subtle and complex faults?
3) Do strong speciÔ¨Åcations Ô¨Ånd faults in little testing time?4) What is the performance overhead of checking strong
speciÔ¨Åcations at runtime?
5) What is the development effort required to provide
strong speciÔ¨Åcations for existing software?
To answer these questions, we conducted two sets of experi-
ments, targeting software written in Eiffel (Sect. IV-B) and C#
(Sect. IV-C). In both cases, we selected an open-source library,
speciÔ¨Åed it following the MBC methodology, and extensively
tested it with a standard automatic testing tool. The rest of this
section discusses the experiments; Sect. V presents the results.
B. Eiffel Experiments
The main experiments target EiffelBase (rev. 506)‚ÄîEiffel‚Äôs
standard base library‚Äîfrom which we selected 21 classes
of varying size and complexity. Using the facilities of the
EiffelStudio IDE, we built the Ô¨Çatversion of each class, which
is a self-contained implementation including all inherited
members explicitly in the class text. This simpliÔ¨Åed the task of
writing speciÔ¨Åcations without being distracted by EiffelBase‚Äôs
deep multiple inheritance hierarchy. For each of the 21 classes
in their Ô¨Çat version, Tab. IV lists the size (in LOC) and
the number of public routines (PR), possibly also including
helper classes directly used in the class implementation. Since
different classes may share some parent or helper classes, the
totals at the bottom of the table are in general less than the
sum of the elements in each column.
Like most Eiffel software, EiffelBase comes with partial
speciÔ¨Åcation in the form of contracts: the 21 classes include
561 precondition clauses, 985 postcondition clauses, and 250
class invariant clauses. In EiffelBase+ we completely replaced
EiffelBase‚Äôs original postconditions and class invariants with
model-based annotations, but we kept EiffelBase‚Äôs precondi-
tions (with a few exceptions discussed below)5. EiffelBase+‚Äôs
strong speciÔ¨Åcation includes 589 precondition clauses, 1066
postcondition clauses and 164 class invariant clauses (21%
model constraints, 23% attribute deÔ¨Ånitions, 10% linking
invariants, 46% internal representation constraints), as well as
278 modify , 4 depend and 7 open clauses. Tab. IV shows the
size (in LOC and PR) of EiffelBase+, which also includes
model deÔ¨Ånitions and implementations of the model queries
necessary to write MBC.
Preconditions. In all but two EiffelBase+ classes we kept
the same preconditions as in EiffelBase. Within the speciÔ¨Åc
setup of our experiments, where we compare traditional con-
tracts and strong contracts, it is important to have the same
preconditions in the two artifacts under comparison. Precondi-
tions deÔ¨Åne the valid calling contexts of routines (in particular,
contract-based testing tools use them to select valid test cases).
Changing preconditions would change the semantics of classes
in a way similar to changing implementation: strengthening
a precondition may reduce the number of faults detectable
for the routine, since it would move obligations from the
routine to its clients; weakening a precondition may increase
5All the code developed as part of the study, as well as descriptions of
found faults are publicly available online [12].the number of faults, since it would impose a heavier burden
on its implementation. We treat preconditions as developers‚Äô
design decisions, which we normally take at face value. This
policy makes the experiments with EiffelBase and EiffelBase+
fully comparable.
The only exception occurred with four routines of class
BINARY TREE and eight routines of class TWO WAY TREE that
insert new nodes into a tree. In these twelve cases, we strength-
ened the preconditions to disallow creating cycles among
nodes in the tree. Without the strengthening, tree instances can
be driven into inconsistent states with cycles where the whole
speciÔ¨Åcation of trees would be inapplicable. These changes in
preconditions are conservative: the EiffelBase+ experiments
using these stronger preconditions miss a few faults that are
detected in EiffelBase, because the new preconditions rule out
some previously valid failing test cases. Since these changes
affect only a small fraction of all the experiments, the results
with EiffelBase and EiffelBase+ remain comparable.
SpeciÔ¨Åcation correctness. To write correct strong contracts
with MBC, we analyzed the original implementation, con-
tracts, and comments in EiffelBase, and relied on our informal
knowledge of the semantics of data structures and their imple-
mentation. To increase our conÔ¨Ådence in the correctness of the
new speciÔ¨Åcation, we ran a series of short preliminary testing
sessions with the goal of detecting inconsistencies and inaccu-
racies. All our changes were conservative, in that whenever a
new contract forbade a behavior that was not clearly forbidden
by the comments, standard contracts, or informal knowledge,
we weakened the speciÔ¨Åcation to allow the behavior. In all,
we reached a high conÔ¨Ådence that EiffelBase+‚Äôs speciÔ¨Åcation
is correct and strong enough. The results of the main testing
sessions (Sect. V) corroborate this informal assessment.
Testing experiments. We ran a large number of random
testing sessions with the AutoTest framework [6] on a com-
puting cluster of the Swiss National Supercomputing Centre,
conÔ¨Ågured to allocate a standard 1.6 GHz core and 4 GB
memory to each parallel AutoTest session. The experiments
totalled 1680 hours of testing time that generated nearly 87
millions of test cases; the TC columns in Tab. IV list the
million of test cases drawn when testing each class in Eiffel-
Base and in EiffelBase+. The testing of every class was split
into 30 sessions of 80 minutes, each with a new seed for the
random number generator, such that corresponding sessions in
EiffelBase and EiffelBase+ use the same seeds. This thorough
testing protocol guaranteed statistically signiÔ¨Åcant results [13].
C. C# Experiment
A smaller set of experiments targets 9 classes from DSA
(v. 0.6)‚Äîan open-source data structure and algorithm library
written in C# [7]. Support for contracts in C# appeared
only recently, through the Code Contracts framework [14];
therefore, most C# projects (including DSA) do not have
any formal speciÔ¨Åcation. This was a chance to extend the
validation of the MBC methodology to other languages and to
projects without pre-existing speciÔ¨Åcation.TABLE IV
EIFFEL CLASSES UNDER TEST AND RESULTS .
EIFFEL BASE EIFFEL BASE+
CLASS LOC PR TC S PEC INC REAL NEW LOC PR TC I NC REAL NEW
ARRAY 831 53 2.8 2 0 2 1 986 59 1.2 0 3 2
ARRAYED LIST 1840 86 3.5 0 0 0 0 2037 92 1.7 0 1 1
ARRAYED QUEUE 537 32 1.8 0 0 2 0 648 37 3.8 0 2 0
ARRAYED SET 1960 49 5.8 3 1 8 0 2053 58 5.4 0 16 8
BINARY TREE 1122 64 1.0 2 5 6 0 1366 70 1.1 0 16 10
BOUNDED QUEUE 558 32 1.4 0 0 2 0 659 37 3.8 0 2 0
HASH TABLE 1345 51 0.9 1 0 1 0 1626 63 0.9 0 2 1
HASH TABLE ITERATOR 217 15 0.4 0 0 0 0 248 15 0.5 0 0 0
INDEXABLE ITERATOR 186 14 1.0 2 0 0 0 228 15 2.7 0 0 0
INTEGER INTERVAL 519 42 4.3 1 1 0 0 637 45 0.9 0 3 3
LINKED LIST 1759 69 2.0 0 0 2 0 1942 77 2.5 0 5 3
LINKED LIST ITERATOR 311 15 0.7 0 0 0 0 357 16 0.7 0 0 0
LINKED SET 2128 83 5.4 5 2 7 0 2410 94 4.8 0 24 17
LINKED SET ITERATOR 311 15 0.7 0 0 0 0 357 16 0.7 0 0 0
LINKED STACK 1077 27 1.0 0 0 3 1 1078 32 3.2 0 6 4
TWO WAY LIST 2007 71 0.8 0 0 3 0 2184 79 2.2 0 6 3
TWO WAY LIST ITERATOR 412 15 0.7 0 0 0 0 462 16 0.7 0 0 0
TWO WAY SORTED SET 2706 91 5.3 5 2 9 0 2983 102 4.8 1 34 25
TWO WAY SORTED SET ITERATOR 412 15 0.7 0 0 0 0 462 16 0.7 0 0 0
TWO WAY TREE 2548 90 1.4 4 4 22 5 2865 101 1.3 0 29 12
TWO WAY TREE ITERATOR 412 15 0.7 0 0 0 0 462 16 0.7 0 0 0
Total 17841 1033 42.5 15 12 48 7 19400 1164 44.4 1 103 62
LOC: Lines of code, PR: Public routines, TC: Test cases drawn (million)
SPEC: SpeciÔ¨Åcation errors found, I NC: Inconsistency errors found, R EAL: Real faults found, N EW: Faults found only in this experiment
TABLE V
C# CLASSES UNDER TEST AND RESULTS .
DSA DSA+ TESTING
CLASS LOC PR LOC PR T F
AvlTree 345 6 391 7 23 1
BinarySearchTree 205 5 213 5 21 1
CommonBinaryTree 419 13 536 18 83 0
Deque 201 14 231 15 145 0
DoublyLinkedList 408 17 458 19 171 3
Heap 371 11 390 12 61 1
OrderedSet 136 9 158 11 10 0
PriorityQueue 186 13 216 14 65 0
SinglyLinkedList 439 20 492 22 148 3
Total 3043 133 3486 149 727 9
LOC: Lines of code, PR: Public routines
T: Testing time (minutes), F: Faults found
We instructed one of our bachelor‚Äôs students to follow
the methodology of Sect. III and create DSA+: a variant
of DSA with the same implementation but equipped with
strong model-based contracts. DSA+‚Äôs speciÔ¨Åcation includes
6 precondition clauses, 143 postcondition clauses and 23 class
invariant clauses. For each of the 9 classes, Tab. V shows the
size (in LOC and PR) of both DSA and DSA+, inclusive of
all speciÔ¨Åcation elements and model query implementations.
As in Tab. IV, the count also includes (possibly shared) helper
classes. Flattening was not necessary in this case because the
inheritance hierarchy is shallow.
SpeciÔ¨Åcation correctness. We manually inspected the
DSA+ speciÔ¨Åcation written by our student, and assessed its
quality to be comparable to that of EiffelBase+ in terms of
correctness and completeness. Since DSA was not designed
with contracts in mind, it makes recurrent usage of defensive
programming, throwing exceptions to signal invalid arguments.The experiment setup is consistent with this programming
style: we do not consider such exceptions to be faults.
Testing experiments. We performed automatic testing with
the Pex concolic testing framework [8] running on a Windows
box equipped with a 2.16 GHz Intel Core2 processor and 3 GB
of memory. The experiments ran for about 12 hours; column
T in Tab. V reports the breakdown per class in minutes. The
testing time is different from class to class because Pex testing
sessions by default are limited by coverage criteria rather than
duration. We only tested DSA+ since DSA has no formal
speciÔ¨Åcation elements usable as automated testing oracles.
The C# experiment is less extensive than the Eiffel exper-
iment and intended as a control mechanism to identify any
potential dependency of the results on the Eiffel language,
libraries (EiffelBase) or tools.
V. U SING STRONG SPECIFICATIONS : RESULTS
This section discusses the result of the experiments, focusing
on the larger EiffelBase experiments, with V-A through V-E
targeting the research questions 1‚Äì5 of Sect. IV-A. Then, V-F
brieÔ¨Çy discusses the experiments with C#, and V-G presents
possible threats to validity of the results.
A. Faults Found
AutoTest found 75 faults in EiffelBase and 104 in EiffelBase+;
these are unique , that is they identify distinct and independent
errors. We classiÔ¨Åed them in three categories.
SpeciÔ¨Åcation faults correspond to violations of wrong con-
tracts (meaning that in our judgement they specify the ex-
pected behavior of the program incorrectly). We found 15
speciÔ¨Åcation faults in EiffelBase (column S PEC in Tab. IV)
and none in EiffelBase+, which increased our conÔ¨Ådencethat the preliminary testing sessions mentioned in Sect. IV-B
were sufÔ¨Åcient to achieve correct speciÔ¨Åcations. We consider
speciÔ¨Åcation faults spurious in our study, because we are not
comparing the correctness of the speciÔ¨Åcation in EiffelBase
and EiffelBase+ but rather their effectiveness at Ô¨Ånding real
errors in the implementation.
Inconsistency faults correspond to failures triggered by calls
on objects in inconsistent states, which are not captured by a
partial class invariant. For example, LINKED SETmay be driven
into a state where the container stores duplicate elements;
calling remove (x)in such a state triggers a failure (only one
occurrence of xis removed), but remove is not to blame for
it, since it is due to previous erroneous behavior that went
undetected. While inconsistency faults are genuine errors, we
classify them separately because understanding and locating
the ultimate source of an inconsistency is normally harder.
Additionally, a single inconsistency fault often results in many
failing test cases (potentially in all routines of the class that
rely on the broken invariant), requiring additional effort from
the developer when analyzing the testing results.
We found 12 inconsistency faults in EiffelBase and 1 in
EiffelBase+ (columns I NCin Tab. IV); the ultimate source of
the latter fault is a class invariant not including all internal
representation constraints (see Sect. III-E), which would have
required exposing implementation details in the model. The
other inconsistency faults of EiffelBase are not detected in
EiffelBase+, because, due to stronger class invariants, their
real source is detected instead. In the LINKED SETexample
above, instead of the inconsistency fault in remove , MBC report
a fault in routine replace , which does not check if the new value
is already present in the set, thereby introducing duplicates.
The results in this category indicate that strong speciÔ¨Åcations
report faults in a way that is easier to understand and debug.
All other errors are real faults which correspond to genuine
errors directly traceable to the code. We found 48 real faults in
EiffelBase and 103 in EiffelBase+ (columns R EAL in Tab. IV);
41 of them are found in both sets of experiments, 7 only in
EiffelBase, and 62 only in EiffelBase+. We submitted bug
reports for all the 110 faults found in our experiments. The
Eiffel Software developers in charge conÔ¨Årmed 107 (97%) of
them as real bugs to be Ô¨Åxed. This is evidence that we are
dealing with genuine faults in our evaluation. The remaining
three faults not taken on by the developers also arguably
highlight real problems in the implementation, but they are
probably not so likely to occur during ‚Äúnormal‚Äù runs. The rest
of the discussion focuses on real faults unless stated otherwise.
Only seven faults are found in EiffelBase but not in
EiffelBase+ (columns N EWin Tab. IV). Four of them are
prevented by the strengthened preconditions in the tree classes
(Sect. IV-B); two are shadowed by new failures occurring
earlier; and one disappears with MBC due to an unintentional
side-effect of a model query that amends an invariant violation.
None of these faults found only in EiffelBase show inherent
deÔ¨Åciencies of strong speciÔ¨Åcations or of the MBC method.
In contrast, the 62 faults found only in EiffelBase+ are
undetectable in EiffelBase.
40 50 60 70 80 90
Total number of faults found40 50 60 70 80 90 40 50 60 70 80 90EiffelBase EiffelBase+Fig. 1. Unique real faults found in all classes over 80-minute testing sessions.
Except for the two ITERATOR classes (no faults in both
cases) and the two QUEUE classes (the same two faults in
both cases), the number of faults found is consistently higher
in EiffelBase+ in each class . As evident from the boxplot in
Fig. 1, the difference is highly signiÔ¨Åcant: the Mann-Whitney
Utest gives U= 0 (testing EiffelBase+ outperforms testing
EiffelBase in allsessions), and p= 210 11overall and
p2:110 11for every class (except the ITERATOR s and
QUEUE s). The difference remains highly statistically signiÔ¨Åcant
even if we aggregate the experiments in sessions of different
length.
Testing with strong speciÔ¨Åcations detected 55 more
(twice as many) unique real faults than testing with
standard, partial contracts. 62 (56%) of the faults are
detected only with strong speciÔ¨Åcations.
B. Fault Complexity
Although it is to some extent subjective whether a fault is
‚Äúdeep‚Äù or ‚Äúsubtle‚Äù, faults violating postconditions or class
invariants are arguably more complex because so are the
violated properties. While there is no signiÔ¨Åcant difference in
the percentage of class invariant violations between EiffelBase
and EiffelBase+ (33% in both cases), postconditions trigger
42% of violations in EiffelBase+ but only 11% in EiffelBase:
the Wilcoxon signed-rank test among all classes gives W= 0
andp= 610 3both for postconditions alone and for
postconditions and class invariants counted together, which
demonstrates that strong speciÔ¨Åcations systematically detect
more complex errors. 76% of faults in EiffelBase+ are detected
thanks to postconditions or invariants‚Äîa direct consequence
of the effectiveness of the MBC methodology for writing them.
One example of a fault detected by a model-based postcon-
dition was already discussed in Sect. II. Here we give two
other examples to demonstrate that they are indeed subtle yet
understandable:
Routine ARRAY .force (v,i)inserts value vat position iinto
an array, extending its bounds if needed. All elements
in between the old bound and iare supposed to be
initialized with default values, however force contains an
off-by-one error, and in a particular scenario fails to
initialize one element. This is missed by the original
postcondition item(i)=v, which only takes care of the newly
inserted element, but detected by the complete model-
based postcondition, which, following the methodology,
speciÔ¨Åes array elements at all positions.0 20 40 60 800 20 40 60 80
Time (min)Unique faults found
‚óè
‚óèEiffelBase
EiffelBase+Fig. 2. Median number of faults, aggregated from all classes, in time. Dotted
lines show minimum and maximum for each case.
Both ARRAYED SETand LINKED SETinherit most of their
implementation from the corresponding list classes, in-
cluding the implementation of isequal: the object equality
function. As a result, two sets with the same elements in
a different order are considered different. The original
postcondition only states that equal sets must have the
same size and that equality is symmetric, which does not
capture the speciÔ¨Åcs of set equality.
It is revealing that 11 faults in EiffelBase+ are detected due
to violations of contracts generated automatically by our tool
that processes MBC annotations (Sect. III-F) such as modify
and depend . These faults are practically out of the scope of
regular contracts, as specifying the corresponding properties
explicitly is extremely onerous.
Throughout the whole experiment we encountered one
violation of an invariant that could be later restored before
the enclosing public routine call terminates. Strictly speaking,
such violation is spurious, and to eliminate it we would
have to extend the notation for open clauses, in order to
support opening arbitrary expressions rather than just routine
arguments. However in reality this particular invariant was
notrestored, so the violation pointed to a real fault. This
example suggests that if an object is too ‚Äúfar away‚Äù in the
object structure from the call target to be mentioned in the
open ordepend clause, it is likely that a developer forgets to
restore its invariant anyway, because the object is not in the
area of immediate interest for the routine.
C. Usage of Testing Time
Fig. 2 plots the number of faults detected in EiffelBase and
EiffelBase+ over a median 80-minute session; it is clearTABLE VI
SPECIFICATION OVERHEAD
#TOKENS EIFFEL BASE EIFFEL BASE+ O VERHEAD
Preconditions 1514 1696 1.12
Postconditions 5410 11837 2.19
Invariants 1508 1587 1.05
MBC annotations 1893
Model queries 2268
Total 8432 19281 2.29
Spec/code 0.20 0.46
that the behavior with strong speciÔ¨Åcations dominates over
standard contracts after only a few minutes. Dominance is
observed consistently in all classes (with the usual exception of
ITERATOR s and QUEUE s): a median session with strong contracts
Ô¨Ånds more faults than a median session with standard contracts
after a time between two seconds and Ô¨Åve minutes depending
on the class under test; after a time between 13 seconds and 20
minutes, testing with strong contracts Ô¨Ånds more faults than
testing with standard contracts will Ô¨Ånd in the whole session.
Testing with standard contracts also seems to exhaust earlier
its fault-Ô¨Ånding potential: given any time from 20 minutes on,
there are more EiffelBase sessions than EiffelBase+ sessions
that have found all the faults they ever will by this time. This
may indicate that standard contracts are good to Ô¨Ånd ‚Äúquick
to detect‚Äù faults, but they also soon run out of steam.
We considered other differences between experiments with
EiffelBase and with EiffelBase+ in the usage of testing time:
repeatability of testing session history, and the presence of rare
faults triggered only in a small number of cases. Our exper-
iments with strong speciÔ¨Åcations are slightly less repeatable
and include a few more rare faults, but the differences with
standard contracts are not statistically signiÔ¨Åcant.
D. Runtime Performance Overhead
Runtime checking of strong speciÔ¨Åcations based on models
often requires traversing the whole data structure to construct
an object of a model class, whenever a contract element is
exercised. As a rule, this demands more computational re-
sources than executing the simple checks involved in standard
contracts. To measure the runtime overhead of checking MBC
speciÔ¨Åcations in automated testing, we compared the number
of test cases generated by AutoTest in the same amount of
time when testing EiffelBase and EiffelBase+. Contrary to
our expectations, the overhead is small in many cases and not
signiÔ¨Åcant overall (see column TC of Tab. IV). A possible
interpretation of this data is that the overhead of strong
speciÔ¨Åcations grows as larger data structures are instantiated;
because random testing most of the time only exercises small
data structures, this overhead does not show.
We did not Ô¨Ånd a signiÔ¨Åcant correlation between the vari-
ation of overhead for different classes and any source code
metrics we considered. On the other hand, some AutoTest
heuristics that decide to discard previously created objects are
activated more often for classes where strong speciÔ¨Åcations
are faster to check.E. SpeciÔ¨Åcation Writing Overhead
Applying MBC to create EiffelBase+ required roughly one
person-month, plus one person-week of preliminary testing
for Ô¨Åne-tuning the speciÔ¨Åcation, which puts the overall ratio
beneÔ¨Åt/effort at about four defects detected per person-day.
Tab. VI measures the amount of work produced in this time:
for each speciÔ¨Åcation item, including preconditions, postcon-
ditions, class invariants, MBC annotations such as modify ,
and model query implementations, we compare the number
oftokens in EiffelBase+ against those in EiffelBase (when
applicable) and give the O VERHEAD of strong speciÔ¨Åcations
as the ratio of the two values. The last line also shows the
overall speciÔ¨Åcation to code ratios.
ReÔ¨Çecting the importance MBC gives to strong postcondi-
tions and the more restricted role of class invariants, 67% of all
new speciÔ¨Åcation in EiffelBase+ are postconditions, whereas
only 9% are class invariants. MBC-speciÔ¨Åc annotations are
11%, mostly modify clauses that are however straightforward
to write and dispense for more intricate explicit framing
speciÔ¨Åcations. Model query implementations account for the
remaining 13%.
These numbers suggest that the speciÔ¨Åcation overhead of
MBC is moderate and abundantly paid off by the advantages
in terms of errors found and quality of documentation. The
speciÔ¨Åcation to code ratio also compares favorably to other ap-
proaches to improving software quality. Detailed quantitative
data about industrial experiences with test-driven development
is scarce, but few references indicate [4], [15], [16] that it is
common to have between 0.4 and 1.0 lines of tests per line of
application code for projects of size comparable to EiffelBase.
Correctness proofs are normally much more demanding, as
they require between 1.5 and 9 speciÔ¨Åcation elements per
implementation element [17], [18], [19].
F . C# Experiments
Pex found 9 unique faults in DSA+ violating the model-
based speciÔ¨Åcation (column F in Tab. V). Unfortunately, we
could not get an evaluation of these faults by the original
code developers. We have conÔ¨Ådence, however, that the faults
uncover some obvious errors and, even in the most benign
interpretation, some instances of bad object-oriented design.
The fault rates (faults per line of executable code) are com-
parable in the Eiffel and C# experiments, being respectively
610 3and310 3. The fault complexity is also qualitatively
similar for the two languages. The testing time (column T
in Tab. V) is instead incomparable, as Pex and AutoTest
implement very different testing algorithms.
Applying MBC to create DSA+ required roughly 50 person-
hours, plus another 8 person-hours used by the student to
learn the MBC methodology on small examples. The spec-
iÔ¨Åcation/code ratio is perceptibly higher in DSA+ compared
to EiffelBase+ (0.9); this is largely due to the verbose syntax
of Code Contracts which are a library, as opposed to Eiffel‚Äôs
native language support for contracts.G. Threats to Validity
Threats to internal validity of our Ô¨Åndings come from the usage
of randomized testing tools, whose behavior may change in
different sessions. We designed the experimental protocol [13]
to reduce this threat to a minimum: we ran a large number
of repeated experiments and we performed suitable non-
parametric statistical tests of signiÔ¨Åcance for all differences
we observed.
Threats to external validity refer to the generalizability of
our Ô¨Åndings. While MBC leads to very good results in our
experiments, applying it to programs in application domain
other than data structures might be more difÔ¨Åcult or require
an extension of the technique. Our results remain signiÔ¨Åcant,
however, if compared to the state of the art in deploying
strong speciÔ¨Åcations. The generalizability to other languages
and analysis tools is partially addressed by our experiments
targeting two languages (Eiffel and C#) and two automatic
testing technologies (random and concolic). Future work will
experiment with even more approaches and notations.
VI. R ELATED WORK
This section discusses the most signiÔ¨Åcant related work in
three areas: using formal speciÔ¨Åcations for testing; using
inferred speciÔ¨Åcations to improve testing; and model-based
speciÔ¨Åcation methods.
Formal speciÔ¨Åcations for testing. The idea of using formal
speciÔ¨Åcations for testing has a history that stretches back
more than three decades; see [20] for a comprehensive survey.
Various proposals targeted different speciÔ¨Åcation formalisms
including algebraic datatypes [21], [22], logic-based nota-
tions [23], UML Statecharts [24] and other state machines, and
contracts and similar forms of embedded assertions [25], [26],
[27], [6]. In these applications, formal speciÔ¨Åcations provide
reliable‚Äîoften automated‚Äîtesting oracles [28] and can also
guide test planning and test case generation.
This extensive experience is evidence that formal speci-
Ô¨Åcations can improve the testing process. From a software
engineering viewpoint, however, an outstanding open issue
is Ô¨Ånding optimal trade-offs between the effort required to
provide formal speciÔ¨Åcations and the improvements (in ef-
Ô¨Åciency and effectiveness) they bring to the testing of real
software. The evidence‚Äîempirical [29] or anecdotal [1]‚Äî
is scarce in this area: most successful experiences do not
explicitly take into account the effort required to produce
reliable speciÔ¨Åcations against the beneÔ¨Åts gained for testing
(e.g., [30]); or they only target partial speciÔ¨Åcations, which
have the advantage of being easy to write (e.g., [27], [6]).
In contrast, this paper targeted the high-hanging fruit of
deploying strong speciÔ¨Åcations, explicitly addressing the dif-
Ô¨Åculties of writing and using such speciÔ¨Åcations for existing
software. Our results that strong speciÔ¨Åcations reveal complex
(design) errors corroborate Hoare‚Äôs view that the real value
of tests is that ‚Äúthey detect inadequacy in the [development]
methods‚Äù [31].
Inferred speciÔ¨Åcations for testing. When speciÔ¨Åcations can
be inferred automatically from the code, the deployment effortis negligible compared to the beneÔ¨Åts they bring. Therefore,
a number of recent works (e.g., [32], [33], [34], [35]) devel-
oped sophisticated techniques for inferring speciÔ¨Åcations from
program executions with the intent of using them to improve
testing. The experiments reported in these papers show that
inferred speciÔ¨Åcations can boost automated testing [36]; on
the other hand, even the most accurate inferred speciÔ¨Åcations
only express the code from a different angle, and hence cannot
take the developer‚Äôs intent fully into account and are nec-
essarily limited to detecting certain types of inconsistencies.
Combining inferred and manually written speciÔ¨Åcations is an
interesting endeavor that belongs to future work (see [9], [37]
for some preliminary studies).
Model-based speciÔ¨Åcation methods. The methodology
described in Sect. III extends our previous work [5] with
the speciÔ¨Åc goal of developing executable speciÔ¨Åcations for
automated testing. The same goal has also motivated the
techniques to improve the runtime checking of strong spec-
iÔ¨Åcations described in Sect. III-F. The related work section
of [5] compares the foundations of our model-based method
against other similar approaches such as JML [38].
VII. C ONCLUSIONS AND FUTURE WORK
This paper presents a methodology to write strong speciÔ¨Å-
cations that extends the traditional Design by Contract, and
applied it to specifying data structure classes in Eiffel and C#.
We carried out an extensive empirical evaluation to determine
the beneÔ¨Åts of using such strong speciÔ¨Åcations in testing with
automatic tools. We found twice as many bugs in the software
with strong speciÔ¨Åcations as in the same software speciÔ¨Åed
with standard partial contracts. We also demonstrated that the
effort required to write the strong speciÔ¨Åcations was moderate
thanks to the methodology that is practical and palatable to
professionals not Ô¨Çuent in formal techniques.
The beneÔ¨Åts brought by strong speciÔ¨Åcations are not limited
to Ô¨Ånding errors through testing. While the present paper
focused on adding strong speciÔ¨Åcations to existing code a pos-
teriori, our related work [5] shows that model-based contracts
help achieve consistent designs and higher-quality code by
construction.
Asfuture work , we plan to extend the MBC methodology
and supporting tools to work on more complicated application
domains with a higher degree of automation, and to support
other software analysis techniques such as correctness proofs
and static analysis. We will also expand the experimental
evaluation to more projects and programming languages.
Acknowledgements. Thanks to Rosemary Monahan and
Scott West for comments on a draft of this paper; and to
Tobias Kiefer for carrying out the C# experiments. This work
was partially supported by the Swiss SNF under projects
FullContracts (200021-137931) and ASII (200021-134976);
we also acknowledge the support of the Swiss National
Supercomputing Centre for the testing experiments.
REFERENCES
[1] D. L. Parnas, ‚ÄúPrecise documentation: The key to better software,‚Äù in
The Future of Software Engineering . Springer, 2011, pp. 125‚Äì148.[2] B. Meyer, Object Oriented Software Construction . Prentice Hall, 1997.
[3] P. Chalin, ‚ÄúAre practitioners writing contracts?‚Äù in The RODIN Book ,
ser. LNCS, vol. 4157, 2006, p. 100.
[4] K. Beck, Test-Driven Development . Addison-Wesley, 2002.
[5] N. Polikarpova, C. A. Furia, and B. Meyer, ‚ÄúSpecifying reusable
components,‚Äù in VSTTE , ser. LNCS, vol. 6217, 2010, pp. 127‚Äì141.
[6] B. Meyer, A. Fiva, I. Ciupa, A. Leitner, Y . Wei, and E. Stapf, ‚ÄúPrograms
that test themselves,‚Äù IEEE Computer , vol. 42, no. 9, pp. 46‚Äì55, 2009.
[7] http://dsa.codeplex.com/.
[8] N. Tillmann and J. de Halleux, ‚ÄúPex‚Äìwhite box test generation for
.NET,‚Äù in TAP, 2008, pp. 134‚Äì153.
[9] N. Polikarpova, I. Ciupa, and B. Meyer, ‚ÄúA comparative study of
programmer-written and automatically inferred contracts,‚Äù in ISSTA ,
2009, pp. 93‚Äì104.
[10] M. Barnett, K. R. M. Leino, and W. Schulte, ‚ÄúThe spec# programming
system: an overview,‚Äù in CASSIS . Berlin, Heidelberg: Springer-Verlag,
2005, pp. 49‚Äì69.
[11] B. Meyer, ‚ÄúThe dependent delegate dilemma,‚Äù in Engineering Theories
of Software Intensive Systems . Springer, 2005.
[12] http://se.inf.ethz.ch/people/polikarpova/mbctesting.
[13] A. Arcuri and L. Briand, ‚ÄúA practical guide for using statistical tests to
assess randomized algorithms in software engineering,‚Äù in ICSE . ACM,
2011, pp. 1‚Äì10.
[14] http://research.microsoft.com/en-us/projects/contracts/.
[15] N. Nagappan, E. M. Maximilien, T. Bhat, and L. Williams, ‚ÄúRealizing
quality improvement through test driven development: results and ex-
periences of four industrial teams,‚Äù ESE, vol. 13, no. 3, pp. 289‚Äì302,
2008.
[16] E. M. Maximilien and L. Williams, ‚ÄúAssessing test-driven development
at IBM,‚Äù in ICSE , 2003, pp. 564‚Äì569.
[17] V . Klebanov et al. , ‚ÄúThe 1st veriÔ¨Åed software competition,‚Äù in FM, ser.
LNCS, vol. 6664, 2011, extended version at www.vscomp.org.
[18] F. Dupressoir, A. D. Gordon, J. J ¬®urjens, and D. A. Naumann, ‚ÄúGuiding
a general-purpose C veriÔ¨Åer to prove cryptographic protocols,‚Äù in IEEE
Computer Security Foundations Symposium , 2011.
[19] J.-C. Filli ÀÜatre, ‚ÄúVerifying two lines of C with Why3: an exercise in
program veriÔ¨Åcation,‚Äù in VSTTE , ser. LNCS, 2012, pp. 83‚Äì97.
[20] R. M. Hierons et al. , ‚ÄúUsing formal speciÔ¨Åcations to support testing,‚Äù
ACM Comput. Surv. , vol. 41, no. 2, 2009.
[21] J. D. Gannon, P. R. McMullin, and R. G. Hamlet, ‚ÄúData-abstraction
implementation, speciÔ¨Åcation, and testing,‚Äù ACM Trans. Program. Lang.
Syst., vol. 3, no. 3, pp. 211‚Äì223, 1981.
[22] J. Chang and D. J. Richardson, ‚ÄúStructural speciÔ¨Åcation-based testing:
Automated support and experimental evaluation,‚Äù in ESEC/FSE , 1999,
pp. 285‚Äì302.
[23] P. Stocks and D. A. Carrington, ‚ÄúTest templates: A speciÔ¨Åcation-based
testing framework,‚Äù in ICSE , 1993, pp. 405‚Äì414.
[24] A. J. Offutt and A. Abdurazik, ‚ÄúGenerating tests from UML speciÔ¨Åca-
tions,‚Äù in UML , 1999, pp. 416‚Äì429.
[25] D. Marinov and S. Khurshid, ‚ÄúTestEra: A novel framework for auto-
mated testing of Java programs,‚Äù in ASE, 2001, p. 22.
[26] Y . Cheon and G. T. Leavens, ‚ÄúA simple and practical approach to unit
testing: The JML and JUnit way,‚Äù in ECOOP , 2002, pp. 231‚Äì255.
[27] C. Boyapati, S. Khurshid, and D. Marinov, ‚ÄúKorat: automated testing
based on Java predicates,‚Äù in ISSTA , 2002, pp. 123‚Äì133.
[28] M. Staats, M. W. Whalen, and M. P. E. Heimdahl, ‚ÄúPrograms, tests, and
oracles,‚Äù in ICSE , 2011, pp. 391‚Äì400.
[29] M. M. M ¬®uller, R. Typke, and O. Hagner, ‚ÄúTwo controlled experiments
concerning the usefulness of assertions as a means for programming,‚Äù
inICSM , 2002, pp. 84‚Äì92.
[30] L. du Bousquet, Y . Ledru, O. Maury, C. Oriat, and J.-L. Lanet, ‚ÄúReusing
a JML speciÔ¨Åcation dedicated to veriÔ¨Åcation for testing, and vice-versa:
Case studies,‚Äù J. Autom. Reasoning , vol. 45, no. 4, pp. 415‚Äì435, 2010.
[31] C. A. R. Hoare, ‚ÄúHow did software get so reliable without proof?‚Äù in
FME , 1996, pp. 1‚Äì17.
[32] C. Pacheco and M. D. Ernst, ‚ÄúEclat: Automatic generation and classiÔ¨Å-
cation of test inputs,‚Äù in ECOOP , 2005, pp. 504‚Äì527.
[33] T. Xie and D. Notkin, ‚ÄúTool-assisted unit-test generation and selection
based on operational abstractions,‚Äù Autom. Softw. Eng. , vol. 13, no. 3,
pp. 345‚Äì371, 2006.
[34] A. Zeller, ‚ÄúMining speciÔ¨Åcations: A roadmap,‚Äù in The Future of Software
Engineering . Springer, 2010, pp. 173‚Äì182.[35] Y . Wei, H. Roth, C. A. Furia, Y . Pei, A. Horton, M. Steindorfer,
M. Nordio, and B. Meyer, ‚ÄúStateful testing: Finding more errors in code
and contracts,‚Äù in ASE, 2011, pp. 440‚Äì443.
[36] M. d‚ÄôAmorim, C. Pacheco, T. Xie, D. Marinov, and M. D. Ernst,
‚ÄúAn empirical comparison of automated generation and classiÔ¨Åcation
techniques for object-oriented unit testing,‚Äù in ASE, 2006, pp. 59‚Äì68.
[37] Y . Wei, C. A. Furia, N. Kazmin, and B. Meyer, ‚ÄúInferring better
contracts,‚Äù in ICSE , 2011, pp. 191‚Äì200.
[38] G. T. Leavens, Y . Cheon, C. Clifton, C. Ruby, and D. R. Cok, ‚ÄúHow
the design of JML accommodates both runtime assertion checking and
formal veriÔ¨Åcation,‚Äù Sci. Com. Prg. , vol. 55, no. 1-3, pp. 185‚Äì208, 2005.