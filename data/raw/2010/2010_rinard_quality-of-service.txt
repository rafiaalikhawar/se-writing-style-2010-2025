MIT Open Access Articles
Quality of service profiling
The MIT Faculty has made this article openly available. Please share
how this access benefits you. Your story matters.
Citation: Misailovic, Sasa et al. "Quality of service profiling." in Proceedings of the 32nd ACM/
IEEE International Conference on Software Engineering, ICSE ‚Äô10, May 2-8 2010, Cape Town, 
South Africa, ACM (2010).
As Published: http://dx.doi.org/10.1145/1806799.1806808
Publisher: Association for Computing Machinery
Persistent URL: http://hdl.handle.net/1721.1/72415
Version: Author's final manuscript: final author's manuscript post peer review, without 
publisher's formatting or copy editing
Terms of use: Creative Commons Attribution-Noncommercial-Share Alike 3.0
Quality of Service ProÔ¨Åling
Sasa Misailovic
MIT CSAIL
misailo@csail.mit.eduStelios Sidiroglou
MIT CSAIL
stelios@csail.mit.eduHenry Hoffmann
MIT CSAIL
hank@csail.mit.edu
Martin Rinard
MIT CSAIL
rinard@csail.mit.edu
ABSTRACT
Many computations exhibit a trade o between execution
time and quality of service. A video encoder, for example,
can often encode frames more quickly if it is given the free-
dom to produce slightly lower quality video. A developer
attempting to optimize such computations must navigate a
complex trade-o space to nd optimizations that appropri-
ately balance quality of service and performance.
We present a new quality of service proler that is de-
signed to help developers identify promising optimization
opportunities in such computations. In contrast to stan-
dard prolers, which simply identify time-consuming parts
of the computation, a quality of service proler is designed
to identify subcomputations that can be replaced with new
(and potentially less accurate) subcomputations that deliver
signicantly increased performance in return for acceptably
small quality of service losses.
Our quality of service proler uses loop perforation (which
transforms loops to perform fewer iterations than the orig-
inal loop) to obtain implementations that occupy dierent
points in the performance/quality of service trade-o space.
The rationale is that optimizable computations often con-
tain loops that perform extra iterations, and that removing
iterations, then observing the resulting eect on the quality
of service, is an eective way to identify such optimizable
subcomputations. Our experimental results from applying
our implemented quality of service proler to a challenging
set of benchmark applications show that it can enable devel-
opers to identify promising optimization opportunities and
deliver successful optimizations that substantially increase
the performance with only small quality of service losses.
Categories and Subject Descriptors
D.2.8 [ Software Engineering ]: Metrics { performance
General Terms
Performance, Experimentation, Measurement
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ICSE ‚Äô10, May 2-8 2010, Cape Town, South Africa
Copyright 2010 ACM 978-1-60558-719-6/10/05 ...$10.00.Keywords
Proling, Loop Perforation, Quality of Service
1. INTRODUCTION
Performance optimization has been an important soft-
ware engineering activity for decades. The standard ap-
proach typically involves the use of prolers (for example,
gprof [13]), to obtain insight into where the program spends
its time. Armed with this insight, developers can then focus
their optimization eorts on the parts of the program that
oer the most potential for execution time reductions.
In recent years a new dimension in performance optimiza-
tion has emerged | many modern computations (such as
information retrieval computations and computations that
manipulate sensory data such as video, images, and audio)
exhibit a trade o between execution time and quality of ser-
vice. Lossy video encoders, for example, can often produce
encoded video frames faster if the constraints on the quality
of the encoded video are relaxed [16]. Developers of such
computations must navigate a more complex optimization
space. Instead of simply focusing on replacing inecient
subcomputations with more ecient subcomputations that
produce the same result, they must instead consider (a po-
tentially much broader range of) subcomputations that 1)
increase performance, 2) may produce a dierent result, but
3) still maintain acceptable quality of service.
For such developers, existing prolers address only one
side (the performance side) of the trade o. They provide
no insight into the quality of service implications of mod-
ifying computationally expensive subcomputations. To ef-
fectively develop computations with an appropriate trade o
between performance and quality of service, developers need
new prolers that can provide insight into both sides of the
trade o.
1.1 Quality of Service ProÔ¨Åling
The goal of quality of service proling is to provide in-
formation that can help developers identify forgiving sub-
computations | i.e., subcomputations that can be replaced
with dierent (and potentially less accurate) subcomputa-
tions that deliver increased performance in return for ac-
ceptable quality of service losses. Note that a necessary
prerequisite for quality of service proling is the availabil-
ity of multiple implementations (with dierent performance
and quality of service characteristics) of the same subcom-
putation.
We present a technique, loop perforation , and an associ-
ated proler that is designed to give developers insight intothe performance versus quality of service trade-o space of
a given application. Loop perforation automatically gener-
ates multiple implementations (with dierent performance
and quality of service characteristics) of a given subcompu-
tation. The proling tool leverages the availability of these
multiple implementations to explore a range of implementa-
tion strategies and generate tables that summarize the re-
sults of this exploration. The goal is to help developers focus
their optimization eorts on subcomputations that do not
just consume a signicant amount of the computation time
but also oer demonstrated potential for signicant perfor-
mance increases in combination with acceptable quality of
service losses.
1.1.1 Loop Perforation
Given a loop, loop perforation transforms the loop so that
it performs fewer iterations (for example, the perforated
loop may simply execute every other iteration of the original
loop). Because the perforated loop executes fewer iterations,
it typically performs less computational work, which may in
turn improve the overall performance of the computation.
However, the perforated loop may also produce a dierent
result than the original loop, which may, in turn, reduce the
computation's quality of service. An appropriate analysis
of the eect of loop perforation can therefore help the de-
veloper identify subcomputations that can be replaced with
less computationally expensive (and potentially less accu-
rate) subcomputations while still preserving an acceptable
quality of service.
The rationale behind the use of loop perforation to iden-
tify promising optimization opportunities is that many suc-
cessful optimizations target partially redundant subcompu-
tations. Because this partial redundancy often manifests
itself as extra loop iterations, one way to nd such subcom-
putations is to nd loops that the proler can perforate with
only small quality of service losses. Our experimental results
(see Sections 4 and 5) support this rationale | many of the
optimization opportunities available in our set of benchmark
applications correspond to partially redundant subcomputa-
tions realized as loops in heuristic searches of complex search
spaces. Our results indicate that quality of service proling
with loop perforation is an eective way to uncover these
promising optimization targets.
1.1.2 Quality of Service Metrics and Requirements
To quantify the quality of service eects, the proler works
with a developer-provided quality of service metric. This
metric takes an output from the original application, a cor-
responding output from perforated application run on the
same input, and returns a non-negative number that mea-
sures how much the output from the perforated application
diers from the output from the original application. Zero
indicates no dierence, with larger numbers indicating corre-
spondingly larger dierences. One typical quality of service
metric uses the scaled dierence of selected output elds.
Another uses the scaled dierence of output quality metrics
such as peak signal to noise ratio.
A quality of service requirement is simply a bound on the
quality of service metric. For example, if a 10% dierence
from the output of the original program is acceptable, the
appropriate quality of service requirement for a scaled dif-
ference metric is 0 :1.1.1.3 Individual Loop ProÔ¨Åling
The proler starts by characterizing the impact of per-
forating individual loops on the performance and quality of
service. For each loop in the program that consumes a signif-
icant amount of the processing time, it generates a version of
the program that perforates the loop. It then runs this per-
forated version, recording the resulting execution time and
quality of service metric. It is possible for the perforation
to cause the program to crash or generate clearly unaccept-
able output. In this case the proler identies the loop as a
critical loop . Loops that are not critical are perforatable .
The developer can use the individual loop proling results
(as presented in the generated proling tables, see Section 4)
to obtain insight into potentially fruitful parts of the pro-
gram to explore for optimizations. The proling tables can
also identify parts of the program that show little potential
as optimization targets.
1.1.4 Combined Loop ProÔ¨Åling
The proler next explores potential interactions between
perforated loops. Given a quality of service requirement,
the proler searches the loop perforation space to nd the
point that maximizes performance while satisfying the qual-
ity of service requirement. The current algorithm uses a
cost/benet analysis of the performance and quality of ser-
vice trade o to order the loops. It then successively and
cumulatively perforates loops in this order, discarding perfo-
rations that exceed the quality of service requirement. The
result is a set of loops that, when perforated together, deliver
the required quality of service.
The developer can use the combined loop proling re-
sults (as presented in the generated tables, see Section 4)
to better understand how the interactions (both positive
and negative) between dierent perforated loops aect the
performance and quality of service. Positive interactions
can identify opportunities to optimize multiple subcompu-
tations with more performance and less quality of service loss
than the individual loop perforation results might indicate.
Conversely, negative interactions may identify subcompu-
tations that cannot be optimized simultaneously without
larger than expected quality of service losses.
1.2 Results and Scope
We have applied our techniques to a set of applications
from the PARSEC benchmark suite [9]. This benchmark
suite is designed to contain applications representative of
modern workloads for the emerging class of multicore com-
puting systems. Our results show that, in general, loop per-
foration can increase the performance of these applications
on a single benchmark input by a factor of between two or
three (the perforated applications run between two and three
times faster than the original applications) while incurring
quality of service losses of less than 10%. Our results also
indicate that developers can use the proling results to de-
velop new, alternative subcomputations that deliver signi-
cantly increased performance with acceptably small quality
of service losses.
Separation of Optimization Targets: Our results show
that quality of service proling produces a clear separation of
optimization targets. Some perforated loops deliver signi-
cant performance improvements with little quality of service
loss. The subcomputations in which these loops appear are
good optimization targets | at least one optimization at-tempt (loop perforation) succeeded, and the application has
demonstrated that it can successfully tolerate the pertur-
bations associated with this optimization attempt. Other,
potentially more targeted, optimization attempts may there-
fore also succeed.
Other perforated loops, on the other hand, either fail to
improve the performance or produce large quality of service
losses. These loops are much less compelling optimization
targets because the rst optimization attempt failed, indi-
cating that the application may be unable to tolerate per-
turbations associated with other optimization attempts.
Application Properties: Guided by the proling results,
we analyzed the relevant subcomputations to understand
how loop perforation was able to obtain such signicant per-
formance improvements with such small quality of service
losses. In general, we found that the successfully perforated
loops typically perform (at least partially) redundant sub-
computations in heuristic searches over a complicated search
space. For ve out of seven of our applications, the results
show that it is possible to obtain a signicantly more ecient
search algorithm that nds a result that is close in quality to
the result that the original search algorithm nds. This anal-
ysis clearly indicates that, for our set of benchmark applica-
tions, loops that perform partially redundant computations
in heuristic search algorithms are an appropriate optimiza-
tion target (and an optimization target that our proler can
enable developers to quickly and easily nd).
Manual Optimization Results: We also used the pro-
ling results to identify optimization opportunities in two
PARSEC applications (x264, a video encoder, and body-
track, a computer vision application). Guided by the pro-
ling results, we manually developed alternate implemen-
tations of the identied subcomputations. These alternate
implementations deliver signicantly increased performance
with small quality of service losses.
Scope: We note that our overall approach is appropriate
for computations with a range of acceptable outputs. Com-
putations (such as compilers or databases) with hard logical
correctness requirements and long dependence chains that
run through the entire computation may not be appropriate
targets for optimizations that may change the output that
the program produces.
1.3 Contributions
This paper makes the following contributions:
Quality of Service Proling: It introduces the con-
cept of using a quality of service proler to help the de-
veloper obtain insight into the performance and quality
of service implications of optimizing dierent subcom-
putations.
Loop Perforation: Any quality of service proler
needs a mechanism to obtain alternative subcomputa-
tions with a range of performance and quality of service
characteristics. This paper identies loop perforation
as an eective mechanism for automatically obtaining
alternative subcomputations for this purpose.
Rationale: It explains why loop perforation is an ef-
fective mechanism for identifying promising optimiza-
tion opportunities. Many optimizable subcomputa-
tions manifest themselves as loops that perform extra
iterations. Eliminating loop iterations, in combination
with measuring quality of service eects, is an eective
way to nd such subcomputations.Experimental Results: It presents experimental re-
sults that characterize the eectiveness of quality of
service proling. These results use a set of benchmark
applications chosen to represent modern workloads for
emerging multicore computing platforms.
{ Loop Perforation Results: It presents indi-
vidual and cumulative loop perforation tables for
our benchmark applications. The information in
these tables provides a good separation between
optimization targets, enabling developers to iden-
tify and focus on promising targets while placing
a lower priority on less promising targets.
{ Manual Optimization Results: It presents re-
sults that illustrate how we were able to use the
proling results in two manual optimization ef-
forts. These eorts produced optimized versions
of two benchmarks. These versions combine sig-
nicantly improved performance with small qual-
ity of service losses.
Unsound Program Transformations: Over the
last several years the eld has developed a range of
unsound program transformations (which may change
the semantics of the original program in principled
ways) [23, 8, 20, 10, 11, 18, 17, 14]. This paper presents
yet another useful application of an unsound transfor-
mation (loop perforation), further demonstrating the
advantages of this approach.
2. LOOP PERFORATION
We implemented the loop perforation transformation as
an LLVM compiler pass [15]. Our evaluation focuses on ap-
plications written in C and C++, but because the perforator
operates at the level of the LLVM bitcode, it can perforate
applications written in any language (or combination of lan-
guages) for which an LLVM front end exists.
The perforator works with any loop that the existing LLVM
loop canonicalization passes, loopsimplify and indvars , can
convert into the following form:
for (i = 0; i < b; i++) { ... }
In this form, there is an induction variable (in the code
above, i) initialized to 0and incremented by 1on every itera-
tion, with the loop terminating when the induction variable
iexceeds the bound (in the code above, b). The class of
loops that LLVM can convert into this form includes, for
example, forloops that initialize an induction variable to
an arbitrary initial value, increment or decrement the in-
duction variable by an arbitrary constant value on each it-
eration, and terminate when the induction variable exceeds
an arbitrary bound.
The perforation rate (r) determines the percentage of it-
erations that the perforated loop skips | the loop perfora-
tion transformation takes ras a parameter and transforms
the loop to skip iterations at that rate. Modulo perforation
transforms the loop to perform every nth iteration (here the
perforation rate is r=n-1=n):
for (i = 0; i < b; i += n) { ... }
Our implemented perforator can also apply truncation
perforation (which skips a contiguous sequence of iterations
at either the beginning or the end of the loop) or random per-
foration (which randomly skips loop iterations). The loopperforator takes as input a specication of which loops to
perforate, what kind of perforation to apply (modulo, trun-
cation, or random), and the perforation rate r. It produces
as output the corresponding perforated program. All of the
experimental results in this paper use modulo perforation
with an nof 2 and a perforation rate of1
2(i.e., the perfo-
rated loop skips half the iterations of the original loop).
3. QUALITY OF SERVICE METRIC
In general, it is possible to use any quality of service met-
ric that, given two outputs (typically one from the original
application and another from the perforated application),
produces a measure of the dierence between the outputs.
The quality of service metric for our benchmark applica-
tions all use a program output abstraction to obtain numbers
from the output to compare. These abstractions typically
select important output components or compute a measure
(such as peak signal to noise ratio) of the quality of the
output. The quality of service metric simply computes the
relative scaled dierence between the produced numbers.
Specically, we assume the output abstraction produces a
sequence of numbers o1; : : : ; o m. Given numbers o1; : : : ; o m
from an unmodied execution and numbers ^ o1; : : : ; ^omfrom
a perforated execution, the following quantity d, which we
call the distortion [21], measures the accuracy of the output
from the perforated execution:
d=1
mmX
i=1oi ^oi
oi
The closer the distortion dis to zero, the less the perfo-
rated execution distorts the output. By default the dis-
tortion equation weighs each component equally, but it is
possible to modify the equation to weigh some components
more heavily than others.
The distortion measures the absolute error that loop per-
foration (or, for that matter, any other transformation) in-
duces. It is also sometimes useful to consider whether there
is any systematic direction to the error. We use the bias[21]
metric to measure any such systematic bias. If there is a
systematic bias, it may be possible to compensate for the
bias to obtain a more accurate result.
4. PROFILING RESULTS
To evaluate the eectiveness of our approach, we apply
quality of service proling to seven benchmarks chosen from
the PARSEC benchmark suite [9]. Unless otherwise noted,
the input for the proling runs is the simlarge input provided
as part of the benchmark suite.
x264. This media application performs H.264 encod-
ing on a video stream. The quality of service met-
ric includes the mean distortion of the peak signal-to-
noise ratio (PSNR) (as measured by the H.264 refer-
ence decoder) and the bitrate of the encoded video. We
ran this application on the tractor input from xiph.org
(available at http://media.xiph.org/video/derf/ ).
streamcluster. This data mining application solves
the online clustering problem. The quality of service
metric uses the BCubed (B3) clustering quality metric
[4]. This clustering metric calculates the homogene-
ity and completeness of the clustering generated by
the application, based on external class labels for data
points. The value of the metric ranges from 0 (badclustering) to 1 (excellent clustering). The quality of
service metric itself is calculated as the dierence be-
tween the clustering quality of the perforated and orig-
inal application. It is possible for the perforated pro-
gram to perform better than the unmodied version,
in which case the quality of service metric is zero.
For this application, the simlarge input contains a uni-
formly distributed set of points with no clusters. This
input is therefore not representative of production data.
We instead ran streamcluster on the covtype input
from the UCI machine learning repository [2].
swaptions. This nancial analysis application uses
Monte-Carlo simulation to solve a partial dierential
equation and price a portfolio of swaptions. The qual-
ity of service metric uses the scaled dierence of the
swaption prices from the original and perforated appli-
cations. With the simlarge input from the PARSEC
benchmark suite, all swaptions have the same value.
To obtain a more realistic computation, we changed
the input to vary the interest rates of the swaptions.
canneal. This engineering application uses simulated
annealing to minimize the routing cost of microchip
design. The quality of service metric is the scaled dif-
ference between the routing costs from the perforated
and original versions.
blackscholes. This nancial analysis application solves
a partial dierential equation to compute the price of
a portfolio of European options. The quality of service
metric is the scaled dierence of the option prices.
bodytrack. This computer vision application uses
an annealed particle lter to track the movement of a
human through a scene. The quality of service met-
ric uses the relative mean squared error of the series
of vectors that the perforated application produces to
represent the changing congurations of the tracked
body (as compared with the corresponding series of
vectors from the original application). The metric di-
vides the relative mean squared errors by the magni-
tudes of the corresponding vectors from the original
application, then computes the mean error for all vec-
tors as the nal quality of service metric. The simlarge
input from the PARSEC benchmark suite has only four
frames. We therefore used the rst sixty frames from
the PARSEC native input. These sixty frames contain
the four frames from the simlarge input.
ferret. This search application performs content-based
similarity search on an image database. It returns a
list of images present in the database whose content
is similar to an input image. The quality of service
metric is based on the intersection of the sets returned
by the original and perforated versions. Specically,
the quality of service metric is 1 minus the number of
images in the intersection divided by the number of
images returned by the original version.
In addition to these benchmarks, the PARSEC benchmark
suite contains the following benchmarks: facesim, dedup,
uidanimate, freqmine, and vips. We do not include fre-
qmine and vips because these benchmarks do not success-
fully compile with the LLVM compiler. We do not include
dedup and uidanimate because these applications produce
complex binary output les. Because we were unable to de-
cipher the meaning of these les given the time available to
us for this purpose, we were unable to develop meaningfulquality of service metrics. We do not include facesim be-
cause it does not produce any output at all (except timing
information).
4.1 Single Loop ProÔ¨Åling Results
Table 1 presents the results of the single loop proling
runs. The rows of the table are grouped by application.
Each row of the table presents the results of the proling
run for a single perforated loop. The rows are sorted ac-
cording to the number of instructions executed in the loop
in the original unperforated application.1Our proling runs
perforated all loops that account for at least 1% of the ex-
ecuted instructions. For space reasons, we present at most
the top eight loops for each application in Table 1.
First Column (Function): The rst column contains the
name of the function that contains the loop, optionally aug-
mented with additional information to identify the specic
loop within the function. Many functions contain a single
loop nest with an outer and inner nested loop; the loops in
such functions are distinguished with the outer and inner
labels. Other functions contain multiple loops; the loops
in such functions are distinguished by presenting the line
number of the loop in the le containing the function.
Second Column (Instruction %): The second column
presents the percentage of the (dynamically executed) in-
structions in the loop for the proling run. Note that be-
cause of both interprocedural and intraprocedural loop nest-
ing, instructions may be counted in the execution of multiple
loops. The percentages may therefore sum to over 100%.
Third Column (Quality of Service): The third column
presents the quality of service metric for the run. Recall
that a quality of service metric of zero indicates no quality
of service loss. A quality of service metric of 0.5 typically
indicates a 50% dierence in the output of the perforated
application as compared with the output of the original ap-
plication. A dash (-) indicates that the perforated execution
either crashed or produced a clearly unacceptable output.
Fourth Column (Speedup): The fourth and nal col-
umn presents the speedup of the perforated application |
i.e., the execution time of the perforated application divided
by the execution time of the original application. Numbers
greater than 1 indicate that the perforated application runs
faster than the original; numbers less than 1 indicate that
the perforated application runs slower than the original.
Interpreting the Results: Good candidate subcomputa-
tions for manual optimization contain loops with the follow-
ing three properties: 1) the application spends a signicant
amount of time in the loop, 2) perforating the loop signif-
icantly increases the performance, and 3) perforating the
loop causes small quality of service losses. The developer
can easily identify such loops by scanning the data in Ta-
ble 1. For example (and as discussed further in Section 5),
the pixel_satd_wxh loops in x264 are promising candidates
for optimization because they have all three properties. The
success of the loop perforation optimization provides evi-
dence that the computation is amenable to optimization and
that other optimization attempts may also succeed.
1Our technique is designed to work with any execution time
proler. Our proling runs use an execution time proler
that counts the number of times each basic block executes.
This execution time proler uses an LLVM compiler pass to
augment the program with the instrumentation required to
count basic block executions.Perhaps more importantly, the developer can easily reject
otherwise promising candidates that fail to satisfy one of the
properties. For example, the pixel_sub_wxh2018 , outer loop
in x264 would be a reasonable candidate for optimization
except for the large quality of service loss that the applica-
tion suers when the loop is perforated. In comparison with
a standard proler, which only provides information about
where the application spends its execution time, the addi-
tional information present in a quality of service prole can
help the developer focus on promising optimization oppor-
tunities with demonstrated potential while placing a lower
priority on opportunities with more potential obstacles.
4.2 Multiple Loop ProÔ¨Åling Results
Table 2 presents the proling results for the multiple loop
proling runs. The quality of service requirement for each
application is set to 0.10 (which corresponds to a 10% dier-
ence between the outputs from the original and perforated
applications). The rows are grouped by application, with
each row presenting the proling results from augmenting
the existing set of perforated loops with the next loop. The
rst column (function) identies the loop added to set of
perforated loops from the preceding rows. The next two
columns repeat the proling results for that loop from the
single loop proling runs as presented in Table 1. The -
nal two columns present the quality of service metric and
speedup from the corresponding cumulative proling run.
This run perforates all loops from all rows up to and includ-
ing the current row.
Interpreting the Results: The multiple loop proling re-
sults identify a group of loops that have demonstrated po-
tential when optimized together. The lack of negative inter-
actions between the perforated loops in the group indicates
that other optimization attempts that target all of the cor-
responding computations as a group may also succeed.
4.3 Individual Application Results
Proling Results for x264: The single loop proling re-
sults for x264 (Table 1) indicate that the the top two loops in
the table (the outer and inner loops from pixel_satd_wxh ) are
promising optimization candidates | these loops account
for a signicant percentage of the executed instructions and
perforation delivers a signicant performance improvement
with more than acceptable quality of service loss. Guided
by these proling results, we were able to develop an op-
timized implementation of the corresponding functionality
with even more performance and less quality of service loss
than the perforated version (see Section 5).
The proling results also identify subcomputations that
are poor optimization candidates. Perforating the loops in
pixel_sub_wxh2018 , for example, produces a large quality of
service loss for relatively little performance improvement.
Perforating the loop in x264_mb_analyse_inter_p8x8 (as well
as several other loops) causes x264 to crash.
The cumulative proling results in Table 2 highlight these
distinctions. The nal perforated collection of loops contains
all of the promising optimization candidates from Table 1
and none of the poor optimization candidates. The cumula-
tive proling results also include loops that were not in the
top 8 loops from Table 2. Because perforating these loops
adds relatively little performance but also relatively little
quality of service loss, they made it into the cumulative set
of perforated loops.x264
Function Instruction % Quality of Service Speedup
pixel satd wxh, outer 41.70% 0.0365 1.459
pixel satd wxh, inner 40.90% 0.0466 1.452
rene subpel 40.90% 0.0005 1.098
pixel subwxh2018, outer 20.50% { {
x264 mbanalyse inter p8x8 20.10% { {
pixel subwxh2018, inner 16.20% 0.2787 1.210
pixel avg, outer 12.90% 0.0158 1.396
x264 mbanalyse inter p8x16, outer 12.30% { {
streamcluster
Function Instruction % Quality of Service Speedup
pFL, inner 99.10% 0.0065 1.137
pgain 95.30% 0.2989 0.865
dist 92.00% 0.5865 1.249
swaptions (with bias correction)
Function Instruction % Quality of Service Speedup
worker 100.00% 1.0000 1.976
HJM Swaption Blocking, outer 100.00% 0.0285 1.979
HJM SimPath Forward Blocking, L.74 45.80% 1.5329 1.146
HJM SimPath Forward Blocking, L.75 45.80% 1.5365 1.167
HJM SimPath Forward Blocking, L.77 43.70% 1.5365 0.982
HJM SimPath Forward Blocking, L.80 31.00% 0.3317 1.011
HJM SimPath Forward Blocking, L.41 15.10% 0.0490 1.008
HJM SimPath Forward Blocking, L.42 15.00% 1.9680 1.005
canneal
Function Instruction % Quality of Service Speedup
annealer thread::run 68.40% 0.0014 0.992
netlist elem::swap cost, L.80 26.20% 0.0048 0.981
netlist elem::swap cost, L.89 26.20% { {
netlist::netlist 25.30% 0.0000 0.989
MTRand::reload, L.307 2.79% 0.0414 1.079
netlist elem::routing cost given loc, L.56 1.84% 0.2000 1.002
netlist elem::routing cost given loc, L.62 1.79% { {
MTRand::reload, L.309 1.42% 0.0254 1.079
blackscholes
Function Instruction % Quality of Service Speedup
main, outer 98.70% 0.0000 1.960
main, inner 98.70% 0.4810 1.885
bodytrack
Function Instruction % Quality of Service Speedup
mainPthreads 99.40% 1.00000 1.992
ParticleFilter::Update 74.70% 0.00050 1.542
ImageMeasurements::ImageErrorInside, outer 36.00% 0.00038 1.201
ImageMeasurements::ImageErrorInside, inner 35.90% 0.00028 1.165
ImageMeasurements::InsideError, outer 28.10% 0.00036 1.121
ImageMeasurements::ImageErrorEdge, outer 27.30% 0.00062 1.112
ImageMeasurements::ImageErrorEdge, inner 27.30% 0.00146 1.033
ImageMeasurements::InsideError, inner 24.00% 0.00023 1.134
ferret
Function Instruction % Quality of Service Speedup
rawquery, L.168 62.30% { {
emd, L.134 37.60% 0.0020 1.020
LSH query, L.569 27.70% 0.4270 1.60
LHS query bootstrap, L.243 27.10% { {
LHS query bootstrap, L.247 26.80% 0.2523 1.162
emd, L.418 19.10% 0.8391 6.663
emd, L.419 18.70% { {
LSH query bootstrap, L.254 15.30% { {
Table 1: Single loop proling results. For Quality of Service, smaller is better. For Speedup, larger is better.x264
Individual Cumulative
Function Quality of Service Speedup Quality of Service Speedup
pixel satd wxh, outer 0.0365 1.459 0.0365 1.459
pixel satd wxh, inner 0.0466 1.452 0.0967 1.672
rene subpel 0.0005 1.098 0.0983 1.789
pixel sad8x8, outer 0.0001 1.067 0.0996 1.929
pixel sad8x8, inner 0.0003 1.060 0.0994 1.986
x264 mesearch ref 0.0021 1.014 0.0951 2.058
streamcluster
Individual Cumulative
Function Quality of Service Speedup Quality of Service Speedup
pFL, inner 0.0065 1.137 0.0065 1.137
swaptions (with bias correction)
Individual Cumulative
Function Quality of Service Speedup Quality of Service Speedup
HJM Swaption Blocking, outer 0.0285 1.979 0.0285 1.979
HJM Swaption Blocking, middle 0.0111 1.015 0.0245 2.044
HJM Swaption Blocking, inner 0.0131 1.009 0.0255 2.068
HJM SimPath Forward Blocking, L.41 0.0490 1.008 0.0799 2.117
canneal
Individual Cumulative
Function Quality of Service Speedup Quality of Service Speedup
MTRand::reload, L.307 0.0254 1.079 0.0254 1.079
blackscholes
Individual Cumulative
Function Quality of Service Speedup Quality of Service Speedup
main, outer 0.0000 1.960 0.0000 1.960
bodytrack
Individual Cumulative
Function Quality of Service Speedup Quality of Service Speedup
ParticleFilter::Update 0.00050 1.542 0.00050 1.542
ImageMeasurements::ImageErrorInside, outer 0.00038 1.201 0.00032 1.809
ImageMeasurements::ImageErrorInside, inner 0.00028 1.165 0.00040 1.960
TrackingModel::GetObservation 0.00371 1.200 0.00309 2.282
ImageMeasurements::InsideError, inner 0.00023 1.134 0.00573 2.376
ImageMeasurements::InsideError, outer 0.00036 1.121 0.00684 2.420
ImageMeasurements::ImageErrorEdge, inner 0.00146 1.033 0.00684 2.627
ImageMeasurements::EdgeError, L.71 0.00099 1.049 0.00500 2.742
ImageMeasurements::EdgeError, L.64 0.00056 1.042 0.00564 2.827
ImageMeasurements::ImageErrorEdge, outer 0.00062 1.112 0.01260 2.984
ferret
Individual Cumulative
Function Quality of Service Speedup Quality of Service Speedup
emd, L.134 0.0020 1.020 0.0020 1.020
LSH query bootstrap, L.257 0.0066 1.021 0.0066 1.021
Table 2: Multiple loop proling results using 0.1 quality of service bound. For Quality of Service, smaller is
better. For Speedup, larger is better.
An analysis of x264 shows that the vast majority of suc-
cessfully perforated loops perform computations that are
part of motion estimation [12]. Motion estimation performs
a heuristic search for similar regions of dierent frames.
The proling results indicate that perforation somewhat de-
grades the quality of this heuristic search, but by no means
disables it. Indeed, eliminating motion estimation entirely
makes the encoder run more than six times faster than the
original version but, unfortunately, increases the size of the
encoded video le by more than a factor of three. The cu-mulatively perforated version, on the other hand, runs more
than a factor of two faster than the original program, but
increases the size of the encoded video le by less than 18%
(which indicates that motion estimation is still working well
even after perforation). This result (which is directly re-
ected in the proling tables) shows that there is a signi-
cant amount of redundancy in the motion estimation com-
putation, which makes this computation a promising target
for optimizations that trade small quality of service losses
in return for substantial performance increases.Proling Results for streamcluster: Perforating the
loop in pgain actually decreases the performance. Upon ex-
amination, the reason for this performance decrease becomes
clear | this loop is embedded in a larger computation that
executes until it satises its own internally calculated result
quality metric. Perforating this loop causes the computation
to take longer to converge, which decreases the performance.
Perforating the inner loop in pFL, on the other hand, does
produce a performance improvement. This loop controls
the number of centers considered when generating a new
clustering. Perforation causes the computation to relax the
constraint on the actual number of centers. In practice this
modication increases performance but in this case does not
harm quality of service | there is enough redundancy in
the default set of potential new centers that discarding other
new centers does not harm the overall quality of service.
The loop in distcomputes the Euclidean distance between
two points. Perforating this loop causes the computation
to compute the distance in a projected space with half the
dimensions of the original space, which in turn causes a sig-
nicant drop in the quality of service.
Proling Results for swaptions: The single loop pro-
ling results for swaptions indicate that there is only one
promising optimization candidate: the outer loop in the
function HJM_Swaption_Blocking . Further examination re-
veals that perforating this loop reduces the number of Monte-
Carlo trials. The result is a signicant performance increase
in combination with a reduction in the swaption prices pro-
portional to the percentage of dropped trials. The bias cor-
rection mechanism (see Section 3) corrects this reduction
and signicantly decreases the drop in quality of service.
Perforating the other loops either crashes the application
or produces an unacceptable quality of service loss. The
cumulative proling results reect this fact by including
HJM_Swaption_Blocking from the single loop proling runs
plus several other loops that give a minor performance in-
crease while preserving acceptable quality of service.
Proling Results for canneal: The proling results for
canneal identify no promising optimization candidates |
perforating the loops typically provides little quality of ser-
vice loss, but also little or no performance gain.
Proling Results for blackscholes: The proling results
for blackscholes indicate that there are only two loops of
interest. Perforating the rst loop (the outer loop in main)
produces a signicant speedup with no quality of service loss
whatsoever. Further investigation reveals that this loop was
apparently added to articially increase the computational
load to make the benchmark run longer. While this loop
is therefore not interesting in a production context, these
proling results show that our technique is able to identify
completely redundant computation. Perforating the other
loop (in main,inner ) produces unacceptable quality of service
loss coupled with signicant performance improvement.
Proling Results for bodytrack: The proling results
for bodytrack indicate that almost all of the loops are promis-
ing optimization candidates. Only one of the loops (the top
loop, mainPthreads ) has substantial quality of service loss
when perforated. The others all have very small quality of
service losses. And indeed, the cumulative proling results
show that it is possible to perforate all of these loops (and
more, the cumulative proling results in Table 2 present only
the rst eight perforated loops) while keeping the quality of
service losses within more than acceptable bounds.We attribute this almost uniformly good quality of ser-
vice even after perforation to two sources of redundancy
in the computation. First, bodytrack uses a Monte Carlo
approach to sample points in the captured images. It sub-
sequently processes these points to recognize important im-
age features such as illumination gradients. Sampling fewer
points may reduce the accuracy of the subsequent image
processing computation, but will not cause the computation
to fail or otherwise dramatically alter its behavior. Second,
bodytrack does not simply perform one sampling phase. It
instead performs a sequence of sampling phases, with the
results of one sampling phase used to drive the selection of
points during the next sampling phase. Once again, per-
forming fewer sampling phases may reduce the accuracy of
the overall computation, but will not cause the computation
to fail or dramatically alter its behavior.
Optimizations that target such sources of redundancy can
often deliver signicant performance gains without corre-
sponding reductions in the quality of service. This applica-
tion shows how quality of service proling can help the de-
veloper identify such sources of redundancy. See Section 5
for a discussion of how we used quality of service proling
to develop a manually optimized version of this application.
Proling Results for ferret: For each query image, fer-
ret performs two processing phases. In the rst phase ferret
divides the image into segments. In the second phase fer-
ret uses the image segments to nd similar images in its
database. Our proling results show that the most time
consuming loops are found in the database query phase. For
most of these loops, perforation produces unacceptable out-
put. For two loops the output distortion is acceptable, but
perforation does not signicantly improve the performance.
5. CASE STUDIES
We next present two case studies that illustrate how we
used the proling information to guide application optimiza-
tion while preserving acceptable quality of service.
x264: The top two perforated loops in the x264 prole (see
Tables 1 and 2) both occur in the pixel_satd_wxh() function.
The proling results indicate that perforating these loops
delivers a signicant performance improvement with accept-
able quality of service loss, which makes the pixel_satd_wxh()
subcomputation a promising candidate for optimization.
A manual examination of the pixel_satd_wxh() function
indicates that it implements part of the temporal redun-
dancy computation in x264, which nds similar regions of
dierent frames for motion estimation [12]. The function
pixel_satd_wxh() takes the dierence of two regions of pix-
els, performs several Hadamard transforms on 4 4 subre-
gions, then computes the sum of the absolute values of the
transform coecients (a Hadamard transform is a frequency
transform which has properties similar to the Discrete Co-
sine Transform).
One obvious alternative to the Hadamard-based approach
is to eliminate the Hadamard transforms and simply return
the sum of absolute dierences between the pixel regions
without computing the transform. Replacing the original
pixel_satd_wxh() function with this simpler implementation
delivers a speedup of 1 :47 with a quality of service loss of
0.8%. This loss is due to a 1.4 % increase in the size of the en-
coded video and a .1 dB loss in PSNR. As Table 2 indicates,
the automatically perforated version of pixel_satd_wxh() de-
livers speedup of 1.67 with a quality of service loss of 9.67%| a larger performance improvement than the manually op-
timized version, but also a larger quality of service loss.
Our next optimization subsamples the sum of absolute
dierences computation by discarding every other value in
each row of the subregion. This optimization produces a
speedup of 1 :68 and a quality of service loss of 0.4 %. This
loss results from a 0.3 dB loss in PSNR with the size of the
encoded video remaining the same. Note that this PSNR
loss remains well below the accepted 0.5 dB perceptability
threshold. These results show that, guided by the proling
information, we were able to identify and develop an op-
timized alternative to an important x264 subcomputation
while preserving acceptable quality of service.
bodytrack: Bodytrack processes video streams from four
coordinated cameras to identify and track major body com-
ponents (torso, head, arms, and legs) of a subject moving
through the eld of view (see Figure 1). It uses a particle-
based Monte-Carlo technique | it randomly samples a col-
lection of pixels (each sampled pixel corresponds to a par-
ticle), then processes the samples to identify visual features
(such as sharp illumination gradients) and map the visual
features to body components. The application itself per-
forms an annealing computation with several phases, or lay-
ers, of samples. Each layer uses the image processing results
from the previous layer to guide the selection of the particles
during its sampling process.
The top loop in the individual loop prole table is the
mainPthreads loop. But the results show that perforating
this loop causes an unacceptable quality of service loss. We
therefore focus our optimization eorts on the next loop
in the prole ( ParticleFilter::Update ), which can be per-
forated with signicant performance improvement and very
little quality of service loss. This loop performs the core of
bodytrack's computation in which it randomly samples and
processes particles (using the annealed particle lter algo-
rithm) to perform edge and foreground silhouette detection.
The loop itself iterates through the annealing layers per-
forming directed particle ltering at each layer.
Guided by the proling results, we developed an optimiza-
tion that reduces the number of particles sampled at each
layer. Specically, the optimization reduces the number of
sampled particles from 4000 to 2000. This optimization pro-
duces a speedup of 1.86 with a quality of service loss of
0.01% | a larger performance increase than the automati-
cally perforated version of this loop with a smaller quality of
service loss. Figure 2 presents the output of this optimized
version. This gure shows that this optimized version of
bodytrack successfully identies all of the major body com-
ponents (with the exception of one forearm). Each gure
presents four frames, one from each of the cameras.
6. RELATED WORK
Performance Proling. Proling a system to under-
stand where it spends its time is an essential component
of modern software engineering. Standard prolers simply
identify the amount of time spent in each subcomputation
[1, 3, 5, 13, 19, 26]. A quality of service proler, in contrast,
adds the extra dimension of providing developers with infor-
mation about the quality of service implications of changing
the implementation of specic subcomputations. This ad-
ditional information can enhance developer productivity by
enabling the developer to focus on promising subcomputa-
tions that loop perforation has already shown can be opti-mized with acceptable quality of service losses while avoiding
less promising subcomputations for which one optimization
attempt has already failed.
Automatic Generation and Management of Perfor-
mance versus Quality of Service Trade Os. We
have also used loop perforation to automatically enhance
applications with the ability to execute at a variety of dif-
ferent points in the underlying performance versus quality
of service trade-o space [14]. We have demonstrated how
an application can use this capability to automatically in-
crease its performance or (in combination with an appro-
priate monitoring and control system) dynamically vary its
perforation policy to adapt to clock frequency changes, core
failures, load uctuations, and other disruptive events in the
computing substrate [14].
Rinard has developed techniques for automatically de-
riving empirical probabilistic quality of service and timing
models that characterize the trade-o space generated by
discarding tasks [21, 22]. Loop perforation operates on ap-
plications written in standard languages without the need
for the developer to identify task boundaries.
An alternate approach to managing performance/quality
of service trade os enables developers to provide alternate
implementations for dierent pieces of functionality, with
the system choosing implementations that are appropriate
for a given operating context [6, 7]. Loop perforation, in
contrast, automatically identies appropriately optimizable
subcomputations.
Unsound Program Transformations. We note that
loop perforation is an instance of an emerging class of un-
sound program transformations. In contrast to traditional
sound transformations (which operate under the restrictive
constraint of preserving the semantics of the original pro-
gram), unsound transformations have the freedom to change
the behavior of the program in principled ways. Unsound
transformations have been shown to enable applications to
productively survive memory errors [23, 8, 24], code injec-
tion attacks [23, 20, 25, 24], data structure corruption er-
rors [10, 11], memory leaks [18], and innite loops [18]. They
have also been shown to be eective for automatically im-
proving application performance [21, 22, 14] and paralleliz-
ing sequential programs [17]. The success of loop perforation
in enabling quality of service proling provides even more ev-
idence for the value of this class of program transformations.
7. CONCLUSION
To eectively optimize computations with complex per-
formance/quality of service trade os, developers need tools
that can help them locate promising optimization opportuni-
ties. Our quality of service proler uses loop perforation to
identify promising subcomputations. Developers can then
leverage the generated proling tables to focus their opti-
mization eorts on optimization targets that have already
demonstrated the potential for signicant performance im-
provements with acceptably small quality of service losses.
Experimental results from our set of benchmark applica-
tions show that our quality of service proler can eectively
separate promising optimization opportunities from oppor-
tunities with less promise. And our case studies provide con-
crete examples that illustrate how developers can use the
proling information to guide successful eorts to develop
new, alternate, and eectively optimized implementations
of important subcomputations.Figure 1: bodytrack reference output.
 Figure 2: bodytrack output after manual optimization.
8. ACKNOWLEDGEMENTS
This research was supported in part by the National Sci-
ence Foundation under Grant Nos. CNS-0509415, CCF-
0811397 and IIS-0835652, DARPA under Grant No. FA8750-
06-2-0189 and Massachusetts Institute of Technology. We
would like to thank Derek Rayside for his input on earlier
drafts of this work.
9. REFERENCES
[1] prof. Digital Unix man page.
[2] UCI Machine Learning Repository.
http://archive.ics.uci.edu/ml/ .
[3] VTune Performance Analyser, Intel Corp.
[4] E. Amigo, J. Gonzalo, and J. Artiles. A comparison of
extrinsic clustering evaluation metrics based on formal
constraints. In Information Retrieval Journal .
Springer Netherlands, July 2008.
[5] J. Anderson, L. Berc, J. Dean, S. Ghemawat,
M. Henzinger, S. Leung, R. Sites, M. Vandevoorde,
C. Waldspurger, and W. Weihl. Continuous proling:
where have all the cycles gone? ACM Transactions on
Computer Systems , 15(4):357{390, 1997.
[6] J. Ansel, C. Chan, Y. Wong, M. Olszewski, Q. Zhao,
A. Edelman, and S. Amarasinghe. PetaBricks: a
language and compiler for algorithmic choice. In
PLDI '09 .
[7] W. Baek and T. Chilimbi. Green: A system for
supporting energy-conscious programming using
principled approximation. Technical Report
TR-2009-089, Microsoft Research, Aug. 2009.
[8] E. Berger and B. Zorn. DieHard: probabilistic memory
safety for unsafe languages. In PLDI , June 2006.
[9] C. Bienia, S. Kumar, J. P. Singh, and K. Li. The
PARSEC benchmark suite: Characterization and
architectural implications. In PACT '08 .
[10] B. Demsky, M. Ernst, P. Guo, S. McCamant,
J. Perkins, and M. Rinard. Inference and enforcement
of data structure consistency specications. In
ISSTA '06 .
[11] B. Demsky and M. Rinard. Data structure repair
using goal-directed reasoning. In ICSE '05 , 2005.
[12] B. Furht, J. Greenberg, and R. Westwater. Motion
Estimation Algorithms for Video Compression . Kluwer
Academic Publishers, Norwell, MA, USA, 1996.[13] S. Graham, P. Kessler, and M. Mckusick. Gprof: A
call graph execution proler. In SCC '82 .
[14] H. Homann, S. Misailovic, S. Sidiroglou, A. Agarwal,
and M. Rinard. Using Code Perforation to Improve
Performance, Reduce Energy Consumption, and
Respond to Failures . Technical Report
MIT-CSAIL-TR-2009-042, MIT, Sept. 2009.
[15] C. Lattner and V. Adve. LLVM: A Compilation
Framework for Lifelong Program Analysis &
Transformation. In CGO'04 .
[16] D. Le Gall. MPEG: A video compression standard for
multimedia applications. CACM , Apr. 1991.
[17] S. Misailovic, D. Kim, and M. Rinard. Automatic
Parallelization with Automatic Accuracy Bounds.
Technical Report MIT-CSAIL-TR-2010-007, 2010.
[18] H. Nguyen and M. Rinard. Detecting and eliminating
memory leaks using cyclic memory allocation. In
ISMM '07 .
[19] G. Pennington and R. Watson. jProf { a JVMPI based
proler, 2000.
[20] J. Perkins, S. Kim, S. Larsen, S. Amarasinghe,
J. Bachrach, M. Carbin, C. Pacheco, F. Sherwood,
S. Sidiroglou, G. Sullivan, , W. Wong, Y. Zibin,
M. Ernst, and M. Rinard. Automatically patching
errors in deployed software. In SOSP '09 .
[21] M. Rinard. Probabilistic accuracy bounds for
fault-tolerant computations that discard tasks. In
ICS '06 .
[22] M. Rinard. Using early phase termination to eliminate
load imbalancess at barrier synchronization points. In
OOPSLA '07 .
[23] M. Rinard, C. Cadar, D. Dumitran, D. M. Roy,
T. Leu, and J. William S. Beebee. Enhancing Server
Availability and Security Through Failure-Oblivious
Computing. In OSDI '04 .
[24] S. Sidiroglou, O. Laadan, C. Perez, N. Viennot,
J. Nieh, and A. D. Keromytis. Assure: automatic
software self-healing using rescue points. In
ASPLOS '09 .
[25] S. Sidiroglou, M. E. Locasto, S. W. Boyd, and A. D.
Keromytis. Building a reactive immune system for
software services. In USENIX '05 .
[26] D. Viswanathan and S. Liang. Java virtual machine
proler interface. IBM Systems Journal , 39(1), 2000.