Regression Tests to Expose Change Interaction Errors
Marcel BÃ¶hme Bruno C.d.S. Oliveira Abhik Roychoudhury
National University of Singapore
{marcel, oliveira, abhik}@comp.nus.edu.sg
ABSTRACT
Changes often introduce program errors, and hence recent
software testing literature has focused on generating tests
which stress changes. In this paper, we argue that changes
cannot be treated as isolated program artifacts which are
stressed via testing. Instead, it is the complex dependency
across multiple changes which introduce subtle errors. Fur-
thermore, the complex dependence structures, that need to
be exercised to expose such errors, ensure that they remain
undiscovered even in well tested and deployed software. We
motivate our work based on a well tested and stable project
- GNU Coreutils - where we found that one third of the re-
gressions take more than two (2) years to be xed, and that
two thirds of such long-standing regressions are introduced
due to change interactions for the utilities we investigated.
To combat change interaction errors , we rst dene a no-
tion of change interaction where several program changes
are found to aect the result of a program statement via
program dependencies. Based on this notion, we propose a
change sequence graph (CSG) to summarize the control-ow
and dependencies across changes. The CSG is then used
as a guide during program path exploration via symbolic
execution - thereby eciently producing test cases which
witness change interaction errors. Our experimental infra-
structure was deployed on various utilities of GNU Coreutils,
which have been distributed with Linux for almost twenty
years. Apart from nding ve (5) previously unknown er-
rors in the utilities, we found that only one in ve generated
test cases exercises a sequence that is critical to exposing a
change-interaction error, while being an order of magnitude
more likely to expose an error. On the other hand, stressing
changes in isolation only exposed half of the change interac-
tion errors. These results demonstrate the importance and
diculty of change dependence-aware regression testing.
Categories and Subject Descriptors: D.2.5 [Software
Engineering]: Testing and Debugging
General Terms: Theory, Algorithms, Experimentation
Keywords: Test Generation, Graph-based Search
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proï¬t or commercial advantage and that copies
bear this notice and the full citation on the ï¬rst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciï¬c
permission and/or a fee.
ESEC/FSE â€™13, August 18-26, 2013, Saint Petersburg, Russia
Copyright 13 ACM 978-1-4503-2237-9/13/08 ...$15.00.1. INTRODUCTION
Changes even to well-tested software projects can intro-
duce subtle bugs of varying severity that may be exposed
only years later. Such change-based errors in deployed soft-
ware come in two forms. First of all, bug xes may intro-
duce new bugs. For instance, Gu et al. [7] mention that
feature additions or bug xes, introduce new bugs in 9% of
cases. Secondly, a subtle or poorly understood \interaction"
among various changes may introduce hard-to-nd errors in
well-tested code, which then get deployed. In this paper,
we focus on test generation to expose such subtle change
interaction errors (CIEs).
Subtle change interaction errors can be found in many
well-tested and deployed software projects. In our study on
GNU Coreutils , we found that every fth bug x actually
patches regressions introduced in an earlier commit. About
one third of these regressions take more than two (2) years
to nd and x1, despite the tool set being rather well tested.
Note that21% of the total commits update the comprehen-
sive test suite, while only 30% actually update the utilities
(the remaining 49% are related to maintenance, like docu-
mentation, the build process, or ambiguous error messages).
Thus, it is surprising that on utilities with such well-updated
test-suites, errors due to change interaction will remain for
two years. In fact, the GNU Coreutils have been dispatched
with almost every Linux distribution for the last 20 years!!
This led us to think that change interaction errors, which
stress subtle dependencies across changes, may be hard-to-
nd due to most regression testing methods being focused
on some form of coverage .
At this point, we step back and review the recent re-
gression testing research which focus on program changes.
A recent work [17] presents criteria and experiments for
the interaction among program changes but does not sug-
gest any method for integrating them into regression test-
ing. Among the works achieving change-aware test genera-
tion, some study only independent program changes [1, 13].
Several of the testing methods attempt to achieve either
a structural coverage of changed statements or some other
structural coverage (such as branch outcome coverage) in
the modied program (e.g., see [22]). Since coverage-based
methods may not stress the semantic eect of the changes,
attempts have been made to take a powerful symbolic execu-
tion based path exploration engine, and adapt it to the pres-
ence of program changes. Since symbolic execution captures
the semantic eect of program changes, the hope is that
the semantic eect of a change can be propagated through
1In our experience, most bugs are xed days after the report.Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proï¬t or commercial advantage and that copies bear this notice and the full citation
on the ï¬rst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciï¬c permission and/or a
fee. Request permissions from Permissions@acm.org.
ESEC/FSEâ€™13 , August 18â€“26, 2013, Saint Petersburg, Russia
Copyright 2013 ACM 978-1-4503-2237-9/13/08...$15.00
http://dx.doi.org/10.1145/2491411.2491430
309such methods. On the other hand, since a full-edged sym-
bolic execution based path exploration can be exceedingly
slow, these methods employ various pruning strategies to
cull away program paths which cannot reach or propagate
changes (e.g., see [18]). Other authors suggest to statically
compute the program slices for every change and dynami-
cally employ symbolic execution upon these slices to exercise
all paths that are aected by a changed statement (e.g., see
[12]). However, in all of these works, the set of changes in
a program is treated in an aggregate fashion. The ows/de-
pendencies across changes are not systematically explored/-
exploited for generating test cases.
In this paper, we present a test generation method to sys-
tematically explore and expose subtle errors arising due to
the \interaction" among program changes. Since any such
change interaction leading to errors is inherently dynamic,
we rst statically approximate the relationships among the
changes. Our approximation is called change sequence graph
(CSG) which captures (i) the control-ow across the changed
statements and (ii) the control-ow to control locations at
which multiple changes may interact, leading to unexpected
semantic eects. These interaction locations are computed
based on the program dependencies across multiple changed
statements. The CSG is then used as a denitive guide to
nd out the sequence of control locations that need to be vis-
ited for exposing potential change interaction errors. These
control locations are visited systematically by programming
a graph-based search strategy on top of the directed sym-
bolic execution engine, Otter [9].
Experimental results from our approach on Coreutils
show the prevalence of change interaction errors among re-
gression bugs. We note that the GNU Coreutils tool-set is
a collection of Linux utilities which have been widely tested.
In particular, every fth commit to the repository updates
a comprehensive test suite that exists for more than twenty
years, and the tool set was further tested by the authors
ofklee [3] and test-zesti [10] (reporting 3 and 2 errors,
respectively). Despite such extensive testing, we found and
reported ve veried, previously unknown regression errors,
apart from many known errors. Among other notable nd-
ings, we noticed that two in three dierential errors can be
classied as change interaction errors. We also found that
only half of the CIEs were exposed by a testing algorithm
that target changes in isolation, but does not account for
their interaction. This clearly demonstrates the importance
of change interaction-aware regression testing.
In summary, the contributions of this paper are:
Change Interaction Errors: We identify and for-
malize change interaction errors: errors that happen
in evolving software, which arise due to the combined
semantic impact of multiple changes. We argue for
the importance of this class of errors with a study of
regression on GNU coreutils over a period of 5 years.
Detection Method for CIEs based on CSGs:
We propose a datastructure called a change sequence
graph to capture potential sequences of changed state-
ments and interaction locations in an execution of a
program. Using CSGs we show a detection method
which stresses sequences in the graph to expose CIEs.
Implementation and Empirical Evaluation: Our
CIEs detection method has been implemented and an
empirical evaluation using that implementation was
conducted to evaluate its eectiveness.2. REGRESSION IN GNU COREUTILS
To study software regression, we looked at the repository
ofGNU Coreutils , which has been actively developed and
maintained for more than twenty years. Our results show
that within the last ve years every fth bug x actually
patches regressions introduced earlier and that 30% of such
regressions take more than 2 years to be xed.
2.1 Statistics of Regression
It is possible to access the history of every change com-
mited to the source code repository of GNU Coreutils since
Oct'922. Usually, these commits are accompanied by a com-
mit message that describes the relevance and intention of
the change. The commits to the repository of GNU Core-
utils are categorized as changes to particular tools, or as
build,tests,maint [enance], amongst others. The developers
adopted this commit message labeling about ve years ago.
This allows us to distinguish code-changing commits3from
maintenance commits. Parsing the commit messages for
keywords, such as \bug", \x", or \regression", we were able
to approximate how many of the code-changing commits are
bug xes and feature additions. If the commit message con-
tained \introduced" or \regression", we could derive whether
a bug x was actually patching regressions introduced ear-
lier. Often, a regression-xing commit would reference the
regression-introducing commit. Thus, we can measure the
time in-between. Note that this process may yield false neg-
atives. While we manually validated the reported ones, we
may miss some real regressions. As the commits have been
nicely categorized in the last ve years, we looked at those
between Jan'08 and Feb'13. However, regression-xing com-
mits can reference regression-introducing commits that were
submitted much earlier. Given the X- and the (logarithmic)
Y-axis in Figure 1, the graph shows that X percent of the
regression-introducing commits 1) require more than Y days
to be found and xed (solid line), and 2) contain more than
Y Changed Lines of Code (CLoC; dashed line).
Figure 1: Regression Statistics - GNU Coreutils
Results. About 30% of the 2.6k commits in the recent
5 years are code changes - feature additions and bug xes
in roughly equal shares. Interestingly, every fth bug x
actually patches regressions introduced in an earlier com-
mit. The following observations are further corroborated by
package maintainer, P adraig Brady, via email-exchange:
2http://git.savannah.gnu.org/cgit/coreutils.git
3Code-changing commits are labeled by the changed tool.310O.i 30% of the regressions introduced in earlier commits
take more than 2 years to nd and x despite a com-
prehensive and well-maintained test suite ( 21% of the
total commits update the test suite)
O.ii 45% of the regressions are introduced when more than
35 LoC are changed (while only about 25% of the code-
changing commits modify 35 LoC or more).
This led us to suspect that the changed behaviour intro-
duced by the syntactic changes to the tools is not properly
tested. In particular, we consider the subtle interplay of
many code changes as reasons for regressions to be exposed
so late. We call this type of errors change interaction errors .
Indeed, as discussed in Section 7, we nd that 66% of the
errors introduced in earlier commits can only be exposed by
input exercising certain critical sequences of changed state-
ments. It turns out that only one in ve tests inputs exercise
a critical sequence, while such test cases are 15 times more
likely to expose an error. In the remainder of this section,
we have a closer look at one of the regression errors.
2.2 Buffer Overï¬‚ow in cut
During our investigations, we found and reported a buer
overow in the tool cutofGNU Coreutils which was intro-
duced as a regression error in commit ec48bead and man-
ifests as SEG FAULT for the failing test input.4Buer
overows can be exploited maliciously to gain root access
to aected computers [4]. This issue is particularly criti-
cal for systems that are dispatched with almost every Linux
distribution, such as GNU Coreutils , which contains well-
known command-line tools, such as cp,mv,rm,echo, and
cut. Fortunately, in the ve years preceeding this paper
the package maintainer of GNU Coreutils had to x only
10 SEG FAULTs.5However, a surprising 6 out of 10 are
regression errors introduced in earlier commits .
2.2.1 The Anatomy of a Regression
In simple terms, the tool cuttakes a set of number ranges,
a le, and an optional output-delimiter as input and prints
the content of every line in the specied le within the spec-
ied ranges, optionally separated by the specied output-
delimiter. For instance, the command in Figure 2, uses\hello
world"as input to the cututility - which prints the range be-
tween the 2nd and 3rd character, and from the 7th character
onwards, both ranges separated by \ ," (comma).
$ echo "hello world" | cut -output-del=, -b2-3,7-
el,world
Figure 2: Linux Terminal - the output of cut
Problem .If there are no nite ranges (e.g., 7-), then too
much memory is unnecessarily allocated.
Specically, if max_range_endpoint is set in line 504 of Fig-
ure 3 or earlier, then the array printable_field is allocated
max_range_endpoint of memory (line 509). If output_deli-
miter_specified , then printable_field is unnecessarily
(but successfully) accessed at eol_range_start in line 266.
Note, if eol_range_start>max_range_endpoint , then max-
_range_endpoint is set to eol_range_start in line 504.
4Report and x avail. at http://debbugs.gnu.org/13627 .
5Again, we analysed commit messages in the repository.
Due to false negatives the actual number may be greater.Intended Change .Memory allocation only if necessary.
Specically, only if max_range_endpoint is set, allocate the
array printable_field with max_range_endpoint of mem-
ory. Only if output_delimiter_specified andmax_range-
_endpoint is set, then the array printable_field shall be
accessible in line 534.
265 :bool is_printable_field (size_t i)
266 : return printable_field[i];
.. :
503--:if (max_range_endpoint < eol_range_start)
504--:max_range_endpoint = eol_range_start
.. :
508++:if (max_range_endpoint)
509 :printable_field = malloc(max_range_endpoint+1)
.. :
531 :if (output_delimiter_specified
532 : && !complement
533 : && eol_range_start
534++: && max_range_endpoint
: && ! is_printable_field (eol_range_start))
535 :mark_range_start (eol_range_start)
Figure 3: SEG FAULT introduced in cut
Actual Changes .The developer applies three code changes.
Every change is essential to x the memory leak.
Specically, the developer C.1) adds that printable_field
is allocated only if max_range_endpoint is set (line 508),
C.2) adds that printable_field is accessed only if max-
_range_endpoint is set (line 534), and C.3) removes that
max_range_endpoint is set to eol_range_start ifeol_ran-
ge_start > max_range_endpoint (lines 503-504). Note, all
changes are essential to x the memory leak. For instance,
without change C.3, the variable guarding the memory al-
location is always set, rendering the additional checks of
changes C.1and C.2redundant.
Regression Error .If nite ranges are specied, then un-
allocated memory can be accessed, yielding a SEG FAULT.
Specically, if 1) max_range_endpoint is set, 2) max_range-
_endpoint < eol_range_start , and 3) output_delimiter-
_specified is set, then the array printable_field is ac-
cessed out-of-bounds at eol_range_start in line 266.
2.2.2 Combined Semantic Impact of Changes
The observation of the regression error depends on the
execution of both changes, C.1and C.2. They have a com-
bined \semantic impact" on the same program location -
the memory access. Specically, the allocation of memory
forprintable_field in line 509 depends on the code added
with change C.1. The access of memory in printable_field
in line 266 depends on the code added with change C.2.
Because the success of accessing an array also depends on
the memory allocation for this array, both changes have a
combined impact at the memory access location. So, the
memory access at line 266 is called interaction location of
C.1and C.2. The sequences in which the changes can be
executed are depicted in Figure 4.6Note, C.3is not part of
the presented graphs since a deletion does not manifest in
the changed version P0.
6For brevity, we removed sequences that contain a change
but no memory allocation or access.311Root 
Memory 
Allocation C.1
Memory 
Access C.2 OutFigure 4: Input can exercise these change sequences.
It is insucient to test both changes in isolation. The
regression error is only observable for (some) input that ex-
ercises both changes - the sequence following the solid lines
in Figure 4. The buer overow is not observable for in-
put exercising only change C.1but not C.2and neither for
input exercising only change C.2but not C.1- sequences
exercising one of the dashed lines in Figure 4. Hence, we
call this regression a change interaction error .
3. ERRORS IN SOFTWARE EVOLUTION
This section formally describes classes of errors that can
occur during software evolution. In particular, we are inter-
ested in a class of errors, arising from the interaction of mul-
tiple changes, that we call change interaction errors (CIE).
To establish the context of CIEs, we also dene a useful
generalization of regression errors, which we call dierential
errors .
3.1 Preliminaries
For the denitions in this section, we will assume two
successive versions of a program, PandP0, and an oracle S.
The oracle Sspecies the intended behavior for PandP0.
As such, it is expected that for all input iexecuted on P0,
the output is observationally equivalent7to executing ion
the oracle S. Note that we abstract over what the oracle S
is: it could be a specication, the ultimate nal version of a
program, a validating test suite, or some other artifact that
could be used to validate expected behaviour. Using earlier
version P, the changed version P0and intended behavior S
ofPandP0, we can more formally dene what we mean by
aregression error .
Denition 1 ( Regression Error )
A regression error is observed on input iif and only if
P(i)6P0(i)andP(i)S(i).
In other words, a regression error happens when for some
input ithe earlier version, P, works as expected but the new
version, P0, does not work anymore. Note that this deni-
tion does not prevent P0from exposing the correct behaviour
for some other input, which fails in Pw.r.t. S. Therefore,
our denition of regression error captures the common sit-
uation in which the initial version Pmay have some errors
that are intended to be xed in P0, but while P0is xed for
some inputs, it starts behaving incorrectly for some other in-
puts. An intended software quality improvement turns into
a possible detoriation of the software quality.
7Two programs PandP0are observationally equivalent for
an input i,P(i)P0(i), if the relevant program output
produced by executing ionPandP0is the same.3.2 Differential Errors
In the context of software evolution we often nd the need
for a notion more general than that of a regression error . We
call this notion dierential error .
Denition 2 ( Dierential Error )
A dierential error is observed on input iif and only if
P(i)6P0(i)andP0(i)6S(i).
In other words, a dierential error happens when, for some
input i, the changed version P0works dierently from both,
the earlier version Pand the intended behavior S. There are
two interesting situations. The situation in which the earlier
version P(i) worked as expected ( P(i)S(i)) is just equiva-
lent to the denition of regression error. On the other hand,
the situation in which the earlier version P(i) did not work
as expected either ( P(i)6S(i)) cannot be called regression
error. So we call it dierential error. This captures a situa-
tion, e.g., of an incomplete x. The developer intends to x
the behaviour of P, when test cases iandjfailed on Pw.r.t.
S. But while imay now pass in the xed version P0andj
produces dierent output, jmay still fail on P0w.r.t. S{
the x was incomplete. In practice, it is helpful to charac-
terize situations in which several intermediate \xes" are im-
plemented until an ultimate version meets the expectations.
3.3 Change Interaction Errors
A change interaction error is a special kind of dieren-
tial error. Informally, a change interaction error happens
when multiple changes are introduced in a program, and
those multiple changes interact in unexpected ways. More
formally we can dene this class of errors as follows.
Denition 3 ( Change interaction error (CIE) )
A change interaction error occurs if there exists a sequence
~Cconsisting of at least two changed statements, such that:
1) there exists an input ithat exercises all changed state-
ments in ~Cin order and P(i)6P0(i)^S(i)6P0(i); and
2) for every input jthat skips the execution of at least
one changed statement in ~C, we have that S(j)P0(j).
We call the sequence ~Cacritical sequence of the CIE because
it corresponds to a sequence of changed statements that
needs to be exercised in the given order to expose the dif-
ferential error. Intuitively, if every input exercising smaller
sequences than ~Cdoes not expose an error but some input
exercising ~Cin order exposes a dierential error, then this
error is due to the interaction among the statements c2~C.
3.4 Running Example
For illustration purposes, we use the two concrete program
versions PandP0in Figure 5 to explain salient concepts in
the remainder of this work. The two programs are simplied
extracts of two versions of the Linux core utility cut- the
behavior of which is explained in Section 2.2.1. The code is
related to the parsing of the user-provided number ranges for
the tool. As long as *fspoints to a character of the string, it
tests whether the character is a digit (line 1), a dash (line 6)
or the end of the line (line 9). If the character is a digit, then
the number is read into value v. In the changed version a
boolean lhsis set to true (lines 4-5). If the character is a
dash, the variable init is computed using v(lines 7-8). If
the end of the line is reached, the bug is observable if init
is 0 (line 10).312P P0
1
2while(true){
3if(isDigit(*fs)){
4 v = rdDigit(*fs );
5
6} else if(*fs == '-'){
7 c = v;
8 init = (c)? v : 1;
9} else if (*fs == EOL){
10 assert(init != 0);
11 break;
12}
13fs++;
14}1bool lhs = false;
2while(true){
3if(isDigit(*fs)){
4 v = rdDigit(*fs);
5 lhs = true;
6} else if (*fs == '-'){
7 c = lhs;
8 init = (c)? v : 1; //IL
9} else if (*fs == EOL){
10 assert(init != 0);
11 break;
12}
13fs++;
14}
Figure 5: Core Utility cut.v1 changed to cut.v2
The changed statements are highlighted in grey. There are
three changed statements in the changed version, which can
be identied using the corresponding line numbers: f1;5;7g.
We should point out that our notion of change is syntactic,
purely textual and corresponds to code changes that mani-
fest in the changed version (P0), such as added or modied
statements. In other words, changed statements can be de-
termined using textual dierencing tools, like diff. The use
ofdiff has the advantage that it works for any two pro-
grams, although it can be quite imprecise. There are other,
more precise ways to deal with changes, but these typically
assume some form of alignment between the two program
versions [1, 13]. Unfortunately, these alignment assump-
tions do not always hold for the real programs that we are
interested in. For this reason we chose the less precise, but
unrestricted approach using diff.
Change Interaction Error. In the program P0in Fig-
ure 5 a CIE happens when the input string is \0-". In this
case the following sequence of changed statements is exe-
cuted:h1;5;7i. Before entering the loop, line 1 is executed.
Since the rst character is `0', the rst iteration of the loop
meets the condition at line 3 and the changed statement in
line 5 is executed. At this point the variable vis set to 0 and
the variable lhsis set to true. In the second iteration of
the loop the condition at line 6 is met and the change in line
7 is executed. Since lhsis true, init is set to 0 (as vis 0).
In contrast, for the same input, program Psets the variable
init to 1. Consequently, in the last iteration of the loop,
the assertion in line 10 is violated for P0, but not for P.
Note that only a specic sequence of changes (as well as
a specic input) triggers this error. The interaction of the
changed statements in lines 5 and 7 at the statement in
line 8 causes this error. The combined semantic impact of
both changes lead to the dierential evaluation of the condi-
tional expression (c)?v:1 in both versions, PandP0. Other
change sequences, such as h1;7;7i,h1;7;5i,h1;7;7;5i, will
not expose the error.
4. CHANGE SEQUENCE GRAPH
To support detection of change interaction errors (CIE)
we propose a statically computed structure which we call
change sequence graph (CSG). A change sequence graph
approximates the computation of potential CIEs by using
control-ow information to derive sequences in which the
changed statements can potentially be exercised and depen-
dence information to derive locations at which the changes
can potentially interact.
8
717
51
132
3 6 9
4
810
112 1113
4 3
5 6
8 10CFG PDG CSG 
1
5 7
11 9Figure 6: PDG, CFG, and CSG for P0in Figure 5.
4.1 Potential Interaction
To aid detecting CIEs, we can approximate all poten-
tial sequences of changed statements in a program using
control-ow information from a control-ow graph (CFG).
Essentially, a potential sequence of changed statements cor-
responds to a path in the CFG that contains changed state-
ments. Having information about every potential sequences
of changed statements is helpful because all critical sequences
will be included in those sequences. In other words, this in-
formation will allow us to build a detection method for CIEs
that searches potential critical sequences and exposes CIEs.
We are particularly interested in change sequences where
the changed statements interact. That is, each executed
changed statement has some impact on the output, and not
executing one of those statements can lead to a dierent
output. It is in this class of sequences where we can nd
change interaction errors. To detect such sequences, one
useful denition is that of a potential interaction location of
a sequence of changed statements.
Denition 4 ( Potential Interaction Location )
A statement sis a potential interaction location of a set
of changed statements C, ifs(statically) data- or control-
depends on every c2C.
Information about potential interaction points can be com-
puted using the program dependency graph (PDG). Essen-
tially, we utilize the backward slice of the statement sto
compute the set of changed statements that can have a se-
mantic impact on s. If the set contains more than one dif-
ferent changed statement, then sis a potential interaction
location of those statements. Note that an interaction loca-
tion can coincide with a changed statement.
In Figure 6, the graphs on the left and in the middle de-
pict the PDG and the CFG for our running example, re-
spectively. The statement at line 8 is a potential interaction
location of the changed statements in lines 5 and 7, since
it transitively depends on both the changed statements. As
such, both changes can have a combined semantic impact on
this control-location, eectively causing the regression error.
The notion of potential interaction location allows us to
dene an approximation of change interaction .
Denition 5 ( Potential Change Interaction )
A set of changed statements ~Cis potentially interacting
if there are potential interaction locations for ~C.
If there is no interaction location for two changed state-
ments, since there is no information-ow, they are guaran-
teed not to interact and can be tested in isolation.313Algorithm 1 Change Sequence Graph Construction
Require: Programs PandP0
1: let CCode diff(P; P0)
2: let CFG markedCFG (P0; CCode)
3: let PDG markedPDG (P0; CCode)
4: let CSG markedNodesOf (CFG )
5:for all Change c2CFG do
6: traverseChange (c,c)
7:end for
8:
9:function traverseChange (curr,c)
10: for each node that directly follows curr inCFG do
11: ifnode is change or output then
12: add edge from ctonode inCSG
13: else
14: let CI dependsOnChanges (node,PDG )
15: ifjCIj>1then
16: add node toCSG
17: for each c2CIdo
18: add edge from ctonode inCSG
19: end for
20: traverseChange (node,node)
21: else
22: traverseChange (node,c)
23: end if
24: end if
25: end for
26:end function
Ensure: Change sequence graph CSG .
The information about all potential sequences of changed
statements and potential interaction points can be synthe-
sized in a change sequence graph (CSG). Thus a CSG repre-
sented a subset of program paths in a program where change
interaction errors may exist. Other program paths, which
are not represented in the CSG, cannot have change inter-
action errors as they do not contain change sequences.
4.2 Computing the Change Sequence Graph
The CSG can be computed using the CFG and the PDG
for the changed program P0. Algorithm 1 shows the detailed
construction of the CSG. The inputs of the algorithm are two
programs PandP0and the output is the change sequence
graph CSG . The rst step is to compute the changed state-
ments between PandP0(line 1). As discussed in Section 3,
this can be done using the diff tool. The next step is to
compute the annotated versions of the CFG and PDG of P0
(lines 2 3). Both, the CFG and PDG are annotated with in-
formation about the changed statements. Initially the CSG
contains no edges, only nodes. These nodes are the changed
statements and output nodes that are recovered from the
CFG using the procedure markedNodesOf (line 4). The -
nal step of the algorithm is to iterate through all the changed
statements in the CFG and, for each change, use the aux-
iliary function traverseChange to add the relevant edges
and interaction locations to the CSG (lines 5  7).
The recursive function traverseChange takes two argu-
ments curr andc. The rst argument represents the cur-
rent node in the CFG. The second argument represents the
changed statement that edges may have to connect to. For
each node in the CFG, which directly follows from the cur-
rent node, we have three possibilities for the node:Change or output node (lines 11 12): If we reach
some other change node, this indicates that there may be a
control-ow from the change cto this change. Thus, we add
a corresponding edge to the CSG to indicate such potential
ow. Similarly, if we reach an output node, we should add
an edge between change cand that node to indicate the
potential control-ow.
Interaction location (lines 14 20): If the node is an
interaction location, it is added to the CSG and connected.
Specically, the function dependsOnChanges (node,PDG )
computes the changed statements that can have a semantic
input on node using the PDG . If there is more than one
change having a semantic impact on node, then node is an
interaction location and is added to the CSG connected to
the changes it depends on. Conceptually, every interaction
location can be regarded as a new change. To trace the
semantic impact of the interaction location, we keep recur-
sively traversing the CFG by invoking traverseChange
with both arguments set to node. Naively, the function
dependsOnChanges can return all changed statements in
the static backward slice of node. For optimization purposes,
the function may choose a node to be an interaction location
only if node is an \important" interaction location in some
respect. For instance, given an interaction location ifor
change sequence ~Cand a statement sthat directly depends
oni| while sis now also considered an interaction location
of~C, it may not be an important one. Alternatively, the in-
teraction locations could be computed by taking the static
forward slice for every changed statement and marking their
intersection as an interaction location.
Neither of above (line 22): Any other CFG node should
be ignored in the CSG. This is achieved by calling traverse-
Change with node as rst argument. This sets curr, repre-
senting the node in the CFG that is currently traversed, to
node and implies that node will not appear in the CSG.
5. SEARCH-BASED INPUT GENERATION
To expose change interaction errors, and dierential errors
in general, test cases are generated. The exploration tech-
nique uses the Change Sequence Graph as a guide to exer-
cises the structure of inter-dependencies across the changed
statements. We employ symbolic execution along these de-
pendencies.
The search-based input generation is depicted in Algo-
rithm 2. The algorithm takes two program versions, Pand
P0, and the CSG (cf. Alg. 1) as input and computes a set of
dierence-revealing test cases T. We adopted the directed
symbolic execution algorithm as discussed by Ma et al. [9].
However, instead of searching for input that exercises any
target in a specied (at) set of targets, we extended the al-
gorithm to search a specied directed graph of targets (i.e.,
theCSG ). The search algorithm is presented independent
of the search strategy.
Algorithm 2 is initialized in the rst ve lines. It starts
with an empty test suite Tand the rst set of changed state-
ments in the CSG (those without incoming edges). These
are added as targets for the symbolic state symbState which
is created in lines 2-4. A symbolic state is essentially an in-
termediate state of symbolic execution and has three main
properties - (i) a statement next which is to be executed
next, (ii) a partial path condition pc, that is satised by
every input exercising the same program path until s, and
(iii) a set of targets .314Algorithm 2 Search-Based Input Generation
Require: Programs PandP0; Directed Graph CSG
1: let T ;
2: let symbState:targets  CSG:startNodes
3: let symbState:pc true
4: let symbState:next P0:firstStmt
5: let states fsymbStateg
6:while states6=;^: isTimeout ()do
7: let bestState chooseBestState (states )
8: let s symbExec next(bestState; P0)
9: ifisBranch (s)then
10: let stateT bestState:pc^s:branchCond
11: let stateF bestState:pc^:s:branchCond
12: remove bestState from states
13: add stateT andstateF tostates
14: else if s2bestState:targets then
15: ifsis an output then
16: let t smtsolve (bestState:pc )
17: ifP(t)6=P0(t)then
18: add ttoT
19: end if
20: remove bestState from states
21: else
22: bestState:targets  next targets of sinCSG
23: end if
24: end if
25:end while
Ensure: Dierence-revealing test cases T.
The symbolic execution of a symbolic state can be resumed
at any time and pauses if a branch or a target is reached. The
rst symbolic state symbState is created with pc=true,
statement next is set program start, and the targets are
assigned to the rst set of changed statements in line 4. In
the following line 5, it is added to the empty list of symbolic
states .
distance
public class HelloWorld { 
   public static void main(String [] args) { 
       String a = "e"; 
        String b = "l"; 
        String c = "w"; 
        String d = "o"; 
        String e = "H"; 
        String f = "r"; 
        String g = "d"; 
        String final1 = e + a + b + b + d; 
        String final2 = c + d + f + b + g; 
        String low = final1.tolowerCase(); 
        System.out.println(low + " " + final2); 
      }
 }CSG P' 
bestState 
s
Figure 7: The bestState is chosen with the shortest
distance in the source code of P0from sto the target
(left). Once a target is reached, the symbolic state
moves to the target's children in the CSG (right).
The search commences in line 6. As long as the list of
states is non-empty and no timeout occurs, the search works
as follows. From the list of states thebestState is chosen
according to a given search strategy, which is implemented
inchooseBestState . For instance, as depicted in Figure 7,
every symbolic state is assigned a measure of distance to its
targets, ranked according to this measure, and chosen if ithas the shortest distance. We further prioritize states with
a greater proportion of targets that are yet unreached by
other symbolic states. In line 8, the bestState resumes the
symbolic execution of P0until s, the next statement to be
executed, becomes either a branch or one of the targets to
be reached. If sis a branch (lines 9-12), then two states
are created | one following the true-branch and the other
following the false -branch. The path conditions and the list
ofstates are updated accordingly. If sis atarget (lines 13-
23), then we further distinguish whether or not sis an output
statement. If sis an output statement, then we solve the
path condition using a Satisability Modulo Theory solver
to derive a concrete program input t(line 15). This input
is executed on both versions to validate whether texposes a
behavioral dierence. If so, tis added to the set of dierence-
revealing test cases T. Since bestState reached the output, it
requires no further symbolic execution and can be removed
from the list of states (line 19). Otherwise, if sis a target of
bestState and not an output statement (line 21), then we set
as new targets ofbestState the nodes following the outgoing
edges of the reached node in the CSG . The right-hand side
of Figure 7 shows the bestState searching for two CSG nodes
(in grey). If bestState nds the node on the left, the next
target of bestState becomes that bottom left node.
6. EMPIRICAL EV ALUATION
6.1 Implementation and Setup
We have implemented Algorithm 2 into the directed sym-
bolic execution tool, Otter [9]. The user provides two ver-
sions of a C program compiled into the C Intermediate Lan-
guage (CIL) and a text le with a representation of the CSG.
Otter provides a wide choice of search strategies which im-
plement the function chooseBestState in Algorithm 2. For
our experiments we used one of the most ecient8strate-
gies. The best symbolic state is chosen based on the short-
est distance to the targets computed in the interprocedural
control-ow graph. Occasionally, the next state is chosen
randomly. We extended the search strategy by prioritizing
states with a greater proportion of yet unreached targets.
Instead of searching for a global set of targets, our imple-
mentation extends a symbolic state to have its own set of
targets. Once a target is reached, the children of the reached
target become the new targets for this state. The execution
of a symbolic state terminates only if the output has been
reached and thus no more further targets are to be reached.
We then compute a concrete input satisfying the path con-
dition of a state that reached an output node. This input is
executed on both program versions. The information from
the standard unix pipes stdout and stderr describes the
program output. If the output diers in more than the pro-
gram name, the test case and its diering output is reported.
If the user optionally provides a \golden version", our imple-
mentation can classify the observed dierential output fur-
ther as \dierential error" (i.e., regression/incomplete x) or
\progression".
We executed our implementation on a desktop computer
with an Intel RCoreTM2 Quad CPU at 2.83GHz and 4GB of
main memory to generate test cases within the time frame
of 5 minutes. The same sequence of changed statements can
be exercised by multiple generated test cases.
8RoundRobin(RandomPath,InterSDSE-efficient) .3156.2 Subjects
We chose the subjects according to the following criteria:
Known Regressions. For every regression, we know i) the
earlier version, ii) the regression-introducing version,
iii) the bug report(s), and iv) the regressing-xing ver-
sion(s). The analysis of known regressions increases
the credibility of the subjects and reduces the scope of
non-maintenance commits which we need to inspect.
Multiple Changes. In this study, we are not interested in
the semantic impact of single changed statements but
the interplay of multiple changed statements. There-
fore, we consider only regressions involving multiple
changed statements.
Deterministic Behavior. The execution of the same in-
put on the same program always yields the same out-
put. Determinism is a prerequesite for every testing
technique and as such also for symbolic execution.
Version Pair Fixed in Commit Bug Report [5] @
Revision Date http://lists.gnu.org/
seq.v0!seq.v1 seq.v2 09.07.2007 2007-07/msg00055.html
16.06.05!01.07.06 seq.v3 14.02.2009 2009-02/msg00139.html
seq.v3 14.02.2009 2009-02/msg00139.html
seq.v1!seq.v2 seq.v4 24.11.2012 2012-11/msg00145.html
01.07.06!09.07.07 seq.v5 10.01.2013 2013-01/msg00054.html
cut.v0!cut.v1 cut.v4 07.02.2011 2011-02/msg00036.html
02.06.04!04.12.04 cut.v6 24.11.2012 2012-11/msg00151.html
cut.v1!cut.v2 cut.v3 22.05.2007 2007-05/msg00195.html
04.12.04!22.05.07 cut.v5 18.11.2012 2012-11/msg00114.html
cut.v6!cut.v7cut.v8 05.02.2013 2013-02/msg00011.html24.11.12!06.12.12
expr.v0!expr.v1expr.v2 26.05.2005 2005-05/msg00189.html16.11.04!14.01.05
Table 1: Six version pairs introducing eleven errors.
We study six version pairs that together introduced 11
dierential errors, ve of which are found and reported by
our method (in bold font). Table 1 shows the considered
Version Pairs the latter version of which introduces er-
rors that are Fixed in the a subsequent revision. The xes
are presented with Commit Date and Bug Report . The bug
being xed with cut.v4 is further discussed by Marinescu
and Cadar [10] and together with cut.v8 only observable as
buer overow. We inserted an assertion that states that
an array shall never be accessed out of bounds. The tools
cut,seq, and expr consist of about 900, 500, and 900 Lines
of Code (LoC), respectively. However, these tools utilize
monolithic, shared libraries, prompting colleagues to quote
between 2k to 3k eective LoC for the smallest tools [3] up to
20k instructions for the largest tool [10] in GNU Coreutils .
6.3 Research Questions
During the empirical evaluation of the change interaction
guided regression test generation technique, we want to an-
swer the following research questions.
RQ.1 Severity. How many dierential errors can be clas-
sied as change interaction errors? What is the prob-
ability to exercise a sequence exposing a change inter-
action error compared to other sequences?
RQ.2 Ecacy. How many dierential errors are exposed
by a test generation technique that exercises changes
in isolation as compared to one that considers their
inter-dependencies and change interactions?7. RESULTS AND ANALYSIS
7.1 Result Presentation
Table 2 shows the errors introduced when changing the
given versions, whether these are change interaction errors
and the test cases generated by our CSG-guided test gen-
eration technique. The rst two columns show the errors
introduced by the changes of the Version Pairs that are
Fixed in the versions given in the second column. For in-
stance, when seq.v1 was changed to seq.v2 , errors are intro-
duced that are xed in versions seq.v3 ,seq.v4 , and seq.v5 .
Errors xed in revisions highlighted in bold face were pre-
viously unknown and subsequently reported by us. The fol-
lowing four columns show the results for the generation of
test cases exercising the Change Sequence Graph , while the
latter three columns show the results for a test generation
technique that considers sucient to exercise every changed
statement, eectively treating Changes in Isolation . Both
groups of columns have a similar format. Column #Tests
depicts the number of test cases generated. Column #Diff
depicts the number of test cases revealing a dierence when
executed on both versions. Some of the semantic dier-
ences are expected (progression). Column #Error depicts
the number of test cases exposing the given error. As per
Denition 3, a dierential error, that is exposed only by in-
put exercising a sequence of changed statements but not by
input \skipping" statements in that sequence, is classied as
change interaction error (Col. CIE).
Version Pairs Sequence %Test %Error
seq.v0!seq.v1non-critical 19.02% 0.00%
critical 80.98% 1.39%
seq.v1!seq.v2non-critical 99.50% 0.30%
critical 0.50% 100.00%
cut.v0!cut.v1non-critical 96.83% 4.09%
critical 3.17% 100.00%
cut.v1!cut.v2non-critical 87.40% 11.71%
critical 12.60% 33.33%
cut.v6!cut.v7non-critical 95.68% 0.00%
critical 4.32% 28.57%
expr.v0!expr.v1non-critical 71.43% 0.00%
critical 28.57% 16.67%
Table 3: %Test of generated tests exercise a (non-)
critical sequence. %Error of generated tests, that
exercise a (non-) critical sequence, expose an error.
Table 3 shows the percentage of tests exercising critical se-
quences versus the percentage of tests exercising non-critical
sequences. One test case exercises exactly one sequence. A
critical sequence is a sequence of changed statements that
is relevant to expose a change interaction error. The rst
column depicts the Version pairs considered, followed by
whether the results refer to critical ornon-critical se-
quences. The latter two columns are explained by example
of the last row: \On average, one quarter of the generated
test cases for the version pair expr.v0 andexpr.v1 exercise a
critical sequence. From those, every sixth exposes an error".
To generate the test suites that stress changes in isola-
tion (see RQ.2), we generated test cases that cover every
changed statement that is also exercised by the approach
presented in this paper. We set as targets the output and
such statements that have the greatest depth in the chain
of control-dependencies. In other words, instead of a graph
of targets, we provided a set of targets. Otherwise, we em-
ployed the same tool, search strategy, and time frame.316RQ1: Change Sequence Graph RQ2: Changes in Isolation
Version Pair Fixed in CIE #Tests #Di #Error #Tests #Di #Error
seq.v0!seq.v1seq.v2 x 163 43 6 205 65 0
seq.v3 x 163 43 5 205 65 0
seq.v1!seq.v2seq.v3 - 200 26 2 200 21 17
seq.v4 - 200 26 3 200 21 0
seq.v5 x 200 26 1 200 21 0
cut.v0!cut.v1cut.v4 - 379 42 30 471 42 30
cut.v6 x 379 42 12 471 42 12
cut.v1!cut.v2cut.v3 - 254 228 162 453 201 58
cut.v5 x 254 228 26 453 201 5
cut.v6!cut.v7 cut.v8 x 324 4 4 342 6 6
expr.v0!expr.v1 expr.v2 x 42 2 2 82 2 2
Average (per version pair) 7/11 227 57.5 46.3 292.2 55.8 21.7
Table 2: Errors introduced, xed in later versions, are witnessed by test cases generated within 5 minutes.
RQ.1 Change Interaction Errors
Two third of the analyzed dierential errors are change in-
teraction errors. Only one in ve test cases exercise a crit-
ical sequence, being 15 times more likely to expose an error.
Using our implementation, we have found and reported
four of the seven listed change interaction errors and one
more dierential error, that were previously unknown. On
average, 227 test cases were generated that exercise a change
sequence (see Table 2). Every fourth test case propagates
the combined semantic eect of the exercised changed state-
ments to the output and thus makes a dierence observable.
While many of these expose expected behavioral changes,
every fth test case exposes a dierential error.
Change interaction errors are subtle . On average, only
21.7% of the generated test cases exercise a critical sequence
(see Table 3). On the other hand, the malicious eect of a
critical change sequence is much greater than that of a non-
critical sequence. Only 3.2% of the test cases exercising a
non-critical sequence expose an error versus 50% exercising
a critical sequence. Test cases exercising a critical sequence
are 15.6 times more likely to expose an error than test cases
exercising a non-critical sequence. That suggests that the
changes in these critical sequences are interacting in a neg-
ative and unintended manner.
RQ.2 Comparison to Changes in Isolation
Only 57% of the change interaction errors are exposed by
test cases generated to stress changes in isolation .
To compare, we generated a test suite that covers every
changed statement which is also covered by the test suite
generated using a change sequence graph. On average, 292
test cases were generated that exercise a change sequence
(cf. Table 2). Every fth test case propagates the combined
semantic eect of the exercised changed statements to the
output and thus makes a dierence observable. Many of
these expose expected behavioral changes, every 15th test
case exposes a dierential error { signicantly less than our
CSG-based test generation approach. Within ve minutes,
using our CSG-based approach every error is witnessed by 25
test cases on average. In contrast, using the other approach
that considers changes in isolation only seven of the eleven
errors are witnessed by, on average, 18 test cases each. In
particular, only 57% of the change interaction errors are
exposed by test cases generated to stress changes in isolation
as compared to 100% by our technique.8. THREATS TO V ALIDITY
The main threat to external validity is the generalization
of the results. During our study of GNU Coreutils we en-
countered several regression errors that can only be observed
when certain environmental conditions are satised. One ex-
ample is an error that was reported to occur specically on
a Solaris 32-bit machine and could not be reproduced on
other machines. Depending on the program environment,
the same test case may or may not expose an error. In
fact, the package co-maintainer of GNU Coreutils , P adraig
Brady, noted in an email correspondence that it may be
unclear even for the experienced developer, exactly how to
write the test cases in the presence of such non-determinism.
He suggested to introduce an explicit interface for le op-
erations. This suggests a lack of modelling the environ-
ment [14], or concurrency [20] during the testing process.
As discussed in Section 6.2, our experimental subjects and
regression errors are chosen so that the observability of an
error does not depend on the program environment but on
source code properties. The conclusions should be viewed
in the same context.
The main threats to internal validity are T.1) the search
strategy that was utilized and T.2) the practical absence
of assertions that mark an error within symbolic execution.
T.1) The experimental results depend on the utilized search
strategy. A less ecient search strategy may have exposed
less dierential errors within the same amount of time. How-
ever, the utilized search strategy does not prioritze critical
over non-critical sequences. Thus, it does not aect the main
conclusion of RQ.1 . We utilized the same search strategy for
the experiments that compares to testing changes in isola-
tion. Thus, it does not aect the main conclusion of RQ.2 .
T.2) Symbolic execution requires highlighting of error states,
for instance, by assertions. In Section 2 and Table 1, we list
the versions cut.v4 and cut.v8 as bug xes for regressions
introduced in an earlier version of cut. The regressions are
observable as buer overows. However, without the explicit
assertion stating that an array should never be accessed at
an index greater than its size, the symbolic index for this
array may often concretize as small number, such as 1 or
0, but never as a number that has more than the nine dig-
its necessary to witness these particular overows. While
ourimplementation is able to nd error-exposing test cases
in the presence of such assertions, it is unable to nd error-
exposing test cases in their absence for such buer-overows.3179. RELATED WORK
Test Suite Augmentation aims at generating new test
cases that stress the changed behaviour in a program. Typ-
ically, this is done by exploiting knowledge about changes
and using symbolic execution techniques - which are also
key ideas in our approach. However, the main novelty of our
work is the consideration of the inter-dependencies among
multiple changes during test generation. Our technique ef-
fectively exercises sequences of changed statements and po-
tential interaction locations. Existing techniques either dis-
cuss the semantic impact of single changes only [1, 13], or
do not systematically consider the interaction and inter-
dependencies among multiple code changes [15, 18].
Test Suite Augmentation techniques can be distinguished
insemantic approaches [2, 11], that are based on the pro-
gram summaries of both versions to compute the semantic
changes, and syntactic approaches , that are directed by the
syntactic changes to exercise paths that may expose seman-
tic changes. The syntactic techniques can be further distin-
guished into those seeking to re-establish code coverage of a
test suite after the program is changed [22], those following
the Reach-Infect-Propagate9approach [1, 15, 13], and those
exercising every program path aected by a change [18, 12].
Techniques, such as eXpress [18] or DiSE [12], that exer-
cise every program path aected by changed statements, are
ner-grained and less scalable than our approach. The focus
on aected code regions makes these techniques more e-
cient than full path exploration approaches, like DART [6],
since less paths are to be explored. However, these tech-
niques may still exercise many dierent paths within the
same sequence of changed statements; paths that may or
may not contain interaction locations; paths that may all
expose the same error. More systematically, our CSG di-
rected TSA approach targets sequences and interaction lo-
cations of changed statements instead of all aected paths .
In practice, this means that once a dierence revealing test
case is found for a sequence, unexplored aected paths that
can still realize this sequence do not no have to be explored
further.
TSA techniques based on Reach-Infect-Propagate (RIP)
[15, 13, 16] follow a motivation similar to our work: Instead
of exploring every path aected by changes, the RIP ap-
proaches deem it sucient to nd one path that executes
a change, infects the program state, and propagates to the
output. However, existing techniques consider the semantic
eects of the changes in isolation. For the subjects in our
experiments, a technique based on this consideration could
expose only half of the change interaction errors. In the
presence of multiple changes, the approach of Santelices et
al. [15] requires a change-free path from the change to the
program start - eectively a change in isolation.
Coverage-based TSA techniques seek to re-establish code
coverage when the program is changed [22, 21]. However, to
expose change-interaction errors and understand the com-
bined semantic impact of multiple changes, it is insucient
to merely exercise every change, as discussed earlier.
Semantic TSA techniques [2, 11] require the computation
of a dierential semantic program summary for both versions
to determine the semantic changes. While this approach is
sound and very precise, it may be less scalable.
9Reach a change, infect the program state, and propagate
the infection to the output [19].Change Interaction. Santelices et al. [17] propose a
formal denition of change interaction: two changes c1and
c2interact in an execution if removing one of the changes
alters the semantic eect of the other change on that execu-
tion. This notion of change interaction is too precise. For
our practical purposes, detecting such changes interactions
cannot be done in an ecient manner. Essentially, given a
test case tand code changes Cthat are applied to program
Pyielding P0, there are 2jCjprogram congurations to be
analyzed, each with only a subset of Capplied to P. Our
denition of potential change interaction approximates the
above denition and can be computed more eciently. A set
of changed statements Cpotentially interacts if there exists
a statement that syntactically depends on every c2C.
Reachability. In order to explore change sequences our
approach builds and extends previous work that deals with
reaching statements in a program. However, these tools seek
to reach a single statement [13, 23], a set of statements [9], or
a sequence of statements [8] instead of a graph. To overcome
this problem we have modied the Otter tool [9] to take a
graph of statements as input and target multiple statements
along this graph structure at once.
10. CONCLUSION
When a program evolves due to feature additions, bug
xes, or other code quality improvements, the source code of
the program is changed. Especially, when multiple develop-
ers change the code base at dierent places, comprehending
the semantic impact of such code changes and potential in-
teractions is dicult. Consequently, errors that result from a
poor understanding of the inter-dependencies across changes
are often introduced in the code base.
In this paper, we have argued for the importance and sub-
tleness of such change interaction errors, which are perva-
sive even in well-tested and widely used software. Since
existing regression test generation techniques do not ade-
quately stress code where change interaction may occur,
we have proposed a new regression test generation tech-
nique that addresses these limitations. Our recipe for ex-
posing change-interaction errors employs a judicious mix of
ows, dependencies and semantic eects across changes. In
other words, to witness a change interaction error { multi-
ple changes should be executed (ow information), multi-
ple changes should aect a potential interaction location via
data- and control dependencies (dependence information),
and the semantic eect of a change should not get masked.
In our approach, the control ow between changes is cap-
tured in the Change Sequence Graph, dependencies across
changes are witnessed in potential interaction locations, and
we attempt to exercise these dependencies and propagate
their semantic eects via symbolic execution on the changed
program. Our experiments on GNU Coreutils demonstrate
the eectiveness of this approach in hunting down hard-to-
nd change-interaction errors even in well-tested software.
11. ACKNOWLEDGMENTS
We are grateful for the engaging discussions with the pack-
age maintainers of the GNU Coreutils , Jim Meyering and
P adraig Brady. Both shared their valueable insights in the
testing of a real, widely distributed project that is being
successfully maintained for over 20 years. This work was
partially supported by Singapore's Ministry of Education
research grant MOE2010-T2-2-073.31812. REFERENCES
[1] T. Apiwattanapong, R. Santelices, P. K. Chittimalli,
A. Orso, and M. J. Harrold. Matrix:
Maintenance-oriented testing requirements identier
and examiner. In Proceedings of the Testing: Academic
& Industrial Conference on Practice And Research
Techniques , TAIC-PART '06, 2006.
[2] M. B ohme, B. C. Oliveira, and A. Roychoudhury.
Partition-based regression verication. In Proceedings
of the 2013 International Conference on Software
Engineering , ICSE 2013, pages 301{310, 2013.
[3] C. Cadar, D. Dunbar, and D. Engler. Klee: unassisted
and automatic generation of high-coverage tests for
complex systems programs. In Proceedings of the 8th
USENIX conference on Operating systems design and
implementation , OSDI'08, pages 209{224, Berkeley,
CA, USA, 2008. USENIX Association.
[4] C. Cowan, C. Pu, D. Maier, H. Hintony, J. Walpole,
P. Bakke, S. Beattie, A. Grier, P. Wagle, and
Q. Zhang. Stackguard: automatic adaptive detection
and prevention of buer-overow attacks. In
Proceedings of the 7th conference on USENIX Security
Symposium - Volume 7 , SSYM'98, pages 5{5,
Berkeley, CA, USA, 1998. USENIX Association.
[5] GNU Coreutils - bug reports. http://lists.gnu.org/
archive/html/bug-coreutils/ , Accessed: July 2013.
[6] P. Godefroid, N. Klarlund, and K. Sen. Dart: directed
automated random testing. In Proceedings of the 2005
ACM SIGPLAN conference on Programming language
design and implementation , PLDI '05, 2005.
[7] Z. Gu, E. T. Barr, D. J. Hamilton, and Z. Su. Has the
bug really been xed? In Proceedings of the 32nd
ACM/IEEE International Conference on Software
Engineering - Volume 1 , ICSE '10, pages 55{64, New
York, NY, USA, 2010. ACM.
[8] W. Jin and A. Orso. Bugredux: reproducing eld
failures for in-house debugging. In Proceedings of the
2012 International Conference on Software
Engineering , ICSE 2012, 2012.
[9] K.-K. Ma, K. Y. Phang, J. S. Foster, and M. Hicks.
Directed symbolic execution. In Proceedings of the
18th International Conference on Static Analysis ,
SAS'11, 2011.
[10] P. D. Marinescu and C. Cadar. make test-zesti: a
symbolic execution solution for improving regression
testing. In Proceedings of the 2012 International
Conference on Software Engineering , ICSE 2012, pages
716{726, Piscataway, NJ, USA, 2012. IEEE Press.
[11] S. Person, M. B. Dwyer, S. Elbaum, and C. S.
P as areanu. Dierential symbolic execution. In
Proceedings of the 16th ACM SIGSOFT International
Symposium on Foundations of software engineering ,
SIGSOFT '08/FSE-16, pages 226{237, New York, NY,
USA, 2008. ACM.
[12] S. Person, G. Yang, N. Rungta, and S. Khurshid.Directed incremental symbolic execution. In
Proceedings of the 32nd ACM SIGPLAN conference
on Programming language design and implementation ,
PLDI '11, 2011.
[13] D. Qi, A. Roychoudhury, and Z. Liang. Test
generation to expose changes in evolving programs. In
Proceedings of the IEEE/ACM international
conference on Automated software engineering , ASE
'10, 2010.
[14] D. Qi, W. N. Sumner, F. Qin, M. Zheng, X. Zhang,
and A. Roychoudhury. Modeling software execution
environment. Reverse Engineering, Working
Conference on , 0:415{424, 2012.
[15] R. Santelices, P. K. Chittimalli, T. Apiwattanapong,
A. Orso, and M. J. Harrold. Test-suite augmentation
for evolving software. In Proceedings of the 2008 23rd
IEEE/ACM International Conference on Automated
Software Engineering , ASE '08, 2008.
[16] R. Santelices and M. J. Harrold. Applying aggressive
propagation-based strategies for testing changes. In
Proceedings of the 2011 Fourth IEEE International
Conference on Software Testing, Verication and
Validation , ICST '11, pages 11{20, Washington, DC,
USA, 2011. IEEE Computer Society.
[17] R. Santelices, M. J. Harrold, and A. Orso. Precisely
detecting runtime change interactions for evolving
software. In Proceedings of the 2010 Third
International Conference on Software Testing,
Verication and Validation , ICST '10, 2010.
[18] K. Taneja, T. Xie, N. Tillmann, and J. de Halleux.
express: guided path exploration for ecient
regression test generation. In Proceedings of the 2011
International Symposium on Software Testing and
Analysis , ISSTA '11, 2011.
[19] J. M. Voas. Pie: A dynamic failure-based technique.
IEEE Trans. Softw. Eng. , 18(8):717{727, Aug. 1992.
[20] C. Wang, M. Said, and A. Gupta. Coverage guided
systematic concurrency testing. In Proceedings of the
33rd International Conference on Software
Engineering , ICSE '11, pages 221{230, New York, NY,
USA, 2011. ACM.
[21] Z. Xu. Directed test suite augmentation. In
Proceedings of the 33rd International Conference on
Software Engineering , ICSE '11, pages 1110{1113,
New York, NY, USA, 2011. ACM.
[22] Z. Xu, Y. Kim, M. Kim, G. Rothermel, and M. B.
Cohen. Directed test suite augmentation: techniques
and tradeos. In Proceedings of the eighteenth ACM
SIGSOFT international symposium on Foundations of
software engineering , FSE '10, pages 257{266, New
York, NY, USA, 2010. ACM.
[23] C. Zamr and G. Candea. Execution synthesis: a
technique for automated software debugging. In
Proceedings of the 5th European conference on
Computer systems , EuroSys '10, 2010.319