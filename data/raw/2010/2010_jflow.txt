JFlow: Practical Refactorings for Flow-based
Parallelism
Nicholas Chen, Ralph E. Johnson
Department of Computer Science
University of Illinois at Urbana-Champaign
fnchen, rjohnsong@illinois.edu
Abstract ‚ÄîEmerging applications in the domains of recognition,
mining and synthesis (RMS); image and video processing; data
warehousing; and automatic Ô¨Ånancial trading admit a particular
style of parallelism termed Ô¨Çow-based parallelism . To help devel-
opers exploit Ô¨Çow-based parallelism, popular parallel libraries
such as Groovy‚Äôs GPars, Intel‚Äôs TBB Flow Graph and Microsoft‚Äôs
TPL DataÔ¨Çow have begun introducing many new and useful
constructs. However, to reap the beneÔ¨Åts of such constructs,
developers must Ô¨Årst use them. This involves refactoring their
existing sequential code to incorporate these constructs ‚Äì a
manual process that overwhelms even experts. To alleviate this
burden, we introduce a set of novel analyses and transformations
targeting Ô¨Çow-based parallelism. We implemented these ideas
in JFlow, an interactive refactoring tool integrated into the
Eclipse IDE. We used JFlow to parallelize seven applications: four
from a previously known benchmark and three from a suite of
large open source projects. Our evaluation on these applications
demonstrates that JFlow, with some minimal interaction from
the developer, can successfully parallelize applications from the
aforementioned domains with good performance (offering up to
3.45x speedup on a 4-core machine) and is fast enough to be
used interactively as part of a developer‚Äôs workÔ¨Çow.
I. I NTRODUCTION
The term ‚ÄúÔ¨Çow-based parallelism‚Äù is coined after Morri-
son‚Äôs Flow-Based Programming: A New Approach to Appli-
cation Development [1]. Flow-based parallelism is a parallel
programming paradigm that partitions an expensive computa-
tion into a directed graph, i.e., a computation Ô¨Çow graph. Each
node in the graph embodies part of the original computation
and the edges between nodes represent dependencies. Data
Ô¨Çow between nodes . Nodes perform their computation when all
their data dependencies are available. Parallelism is achieved
when nodes can operate concurrently. Examples of Ô¨Çow-
based parallelism include pipeline parallelism, event-based
coordination and the wavefront pattern [2], [3]. The structure
of the graph is usually simple, e.g., in the case of pipeline
parallelism but could also be more complex, e.g., in the case
of wavefront computations.
Flow-based parallelism offers many advantages. It is well-
suited for parallelizing emerging applications in the domains
of recognition, mining and synthesis (RMS); image and video
processing; data warehousing; and automatic Ô¨Ånancial trading
(Section IV). Using Ô¨Çow-based parallelism not only improves
the performance of such applications but also their modular-
ity. By partitioning the computation into nodes of a graph
that communicate via explicit parameters, we can reduce thecoupling between different parts of the software, making it
easier to maintain and evolve each part independently.
A compelling way to leverage Ô¨Çow-based parallelism is
to refactor existing sequential code to use the constructs of
a parallel library such as Groovy‚Äôs GPars [4], Intel‚Äôs TBB
Flow Graph [5] or Microsoft‚Äôs TPL DataÔ¨Çow [6]. Our prior
work examined the constructs in an older version of Intel‚Äôs
TBB and found them expressive enough to address many
of the common idioms found in applications [7]. We found
using such constructs to be more advantageous compared to
direct parallelizing with low-level threads. Firstly, programs
written using parallel constructs were more succinct and easier
to evolve because the library provides useful constructs for
adding/removing nodes or edges to a computation graph. Sec-
ondly, in some cases, code parallelized using library constructs
were faster than code parallelized directly with low-level
threads because the library has better support for managing
and coordinating threads through a thread pool.
To refactor their code to use such constructs, developers
face two overwhelming tasks: analysis andtransformation of
their sequential code. First, a developer has to partition the
original sequential code into a computation Ô¨Çow graph with
nodes and edges. She must scrutinize each node to ensure that
no data races exist. Given a large and unfamiliar code base,
this is hard even for experts. Second, once she is convinced
that there are no data races, she still has to meticulously write
repetitive, boilerplate code to create the nodes and link the
edges between nodes. Given a large computation graph, there
could be many nodes and edges, and manually writing code
to describe them is tedious. How can we assist developers in
analyzing and transforming their sequential programs?
Parallelizing compilers attempt to relieve the burden of
analyzing and transforming the code in an entirely automated
manner, without involving the developer. While appealing,
even the most advanced static analysis in the compiler are
frequently confounded by common programming idioms that
abound in typical object-oriented programs, forcing the com-
piler to be overly pessimistic and precluding many paralleliza-
tion opportunities. Kim et al. [8] tested two commercial C/C++
compilers on the OmpSCR benchmarks [9] and found that,
at best, the compilers could only automatically parallelize 4
out of 13 loops although loop parallelism had been studied
since the Ô¨Årst parallelizing compilers [10]. They attributed
the reasons for failure to pointer based accesses, complexcontrol Ô¨Çow and insufÔ¨Åcient cost-beneÔ¨Åt analysis. Even state
of the art static analysis for object-oriented program [11]‚Äì
[13] have trouble reasoning about many best practice idioms.
For instance, in the applications we evaluated, we found that
the use of static factory methods, logging constructs and, in
general, the use of fairly standard library APIs confuse the
static analysis and force it to be safe but overly conservative.
Common techniques for increasing the precision of static
analysis (at the expense of memory and running time) e.g.,
increasing kfor k-object sensitivity [14] or nfor call-string-
sensitivity [15], do not help.
While it is difÔ¨Åcult for static analysis to reason about such
idioms, it is easier for a human. Thus, we propose a practical
approach that combines static analysis with human interaction.
Our approach actively engages the developer, i.e., the domain
expert in the parallelization process. We adapt ideas from
human automation and divide the tasks between developer
and tool such that each performs what each excels at [16].
The developer performs the high-level reasoning task that tools
have problems with ‚Äî identifying which parts of the original
computation to partition ‚Äî whereas the tool handles the low-
level analysis task that developers Ô¨Ånd tedious ‚Äî analyzing if
the partitions have data races and generating the parallel code.
This combination is effective. It enables us to parallelize many
more applications than would have been possible through static
analysis alone.
We implemented this interactive approach in our tool, JFlow.
JFlow statically analyzes the code and reports back to the
developer. As a tool, JFlow has high utility and is useful
in many scenarios. When the analyses are successful, the
tool performs the transformation, generating source code that
targets the constructs of a parallel library. Even when the
analyses fail, the tool is useful ‚Äî it pinpoints and reports the
problems. This allows the developer to either Ô¨Åx the problems
and retry, or proceed with the transformation directly if she
deems the reported problems innocuous (e.g., as determined by
her suite of test cases). JFlow can even be used exploratorily:
if the developer wishes to inspect for data races, she could
use the tool to analyze the code, view the results and forego
the transformation step. She could even use JFlow as a code
generator, ignoring all analysis results and merely using it to
generate code that she will later tweak by hand. Our tool
operates at the source code level. Thus, all issues reported
can be easily inspected and understood by the developer. Ad-
ditionally, the transformations can be inspected and tweaked
by the developer, as desired.
Our contributions are twofold. First, we introduce our analy-
ses and transformations that speciÔ¨Åcally target Ô¨Çow-based par-
allelism. In this paper, we target the most common Ô¨Çow-based
parallelism, i.e., pipeline parallelism, that we have observed in
our suite of applications. The heart of our analyses is a novel
approach for detecting inter andintra node data-races. Our ap-
proach combines k-object sensitivity with ownership transfer
inference ‚Äî an approach that works particularly well for Ô¨Çow-
based parallelism with their regular Ô¨Çows of coarse-grained
data (see Section III). Our transformations generate human-readable source code to describe the computation Ô¨Çow graph.
The ideas behind our analyses and transformations are general
and can be adapted for different languages and frameworks.
Second, we incorporated our analyses and transformations into
our interactive tool, JFlow. JFlow works with Java applications
and targets the constructs from Groovy‚Äôs GPars parallel library.
We evaluated JFlow on seven applications from different
emerging domains. We report the parallel speedups and discuss
the user interactions necessary for each application.
The source code for JFlow and the applications that we
evaluated are available at http://vazexqi.github.io/JFlow/.
II. M OTIVATING EXAMPLE
Consider LIRe (16K SLOC), an open source Java content-
based image retrieval (CBIR) library [17]. LIRe takes a query
image, extracts features from it and, based on those features,
retrieves similar images from a database of candidate images.
Typical features that are extracted using computer vision
techniques include color histograms, shapes and textures.
In LIRe, the main bottlenecks to performance are the
indexing and retrieval stages. This example focuses on the
indexing stage. In the indexing stage, a set of images is
analyzed to build the database of candidate images. During
the analysis, features are extracted from the images and stored
in the database. Because there isn‚Äôt a single feature that works
across all images, multiple features are usually extracted and
stored in the database. The bottleneck in the indexing stage
comes from the number of features extracted and the number
of images that need to be analyzed (typically in the hundreds
of thousands for a decent size database).
Figure 1 shows the indexing loop for LIRe with four feature
extractors. Consider a developer who decides to parallelize
this loop using Ô¨Çow-based parallelism. She decides to partition
each feature extractor into its own node. The Ô¨Çow graph for
such a partition, i.e., a pipeline, is shown on the right hand side
of the Ô¨Ågure. How could she make use of JFlow to parallelize
her code? Three steps: annotate, extract nodes and invert loop.
First, she would need to annotate her desired partitioning;
we use simple comments for now. While there have been prior
work [18], [19] on using the program dependence graph [20]
to perform automatic partition, our own experience shows that
it does not work as well for the kinds of modern object-
oriented programs that we are interested in. Complex heap data
dependencies in the program dependence graph lead to very
Ô¨Åne-grained partitions that have high communication costs
when parallelized. We found it more effective to rely on the
developer to provide a suitable partition as a starting point, as
done by Thies et al. [21] and Jenista et al. [22].
After annotating her code, the developer invokes JFlow.
JFlow currently supports two refactorings. The ideas for both
refactorings, E XTRACT NODE and I NVERT LOOP, were con-
ceived based on our past experiences parallelizing applications
using parallel library constructs [7].
The Ô¨Årst refactoring that JFlow performs is E XTRACT
NODES . This refactoring attempts to create nodes from the
developer‚Äôs annotations and links each node with other nodesNode1Node2Node3Node41classBundle {2BufferedImage bufferedImage;3Document docColor, docJPEG, docTamura;4String imagePath;5}67finalDataflowQueue<Bundle> channel0=newDataflowQueue<Bundle>();8finalDataflowQueue<Bundle> channel1=newDataflowQueue<Bundle>();9...10for(String imagePath : FileUtils.getAllImages(newFile(IMAGES_DIRECTORY))) {11Bundle b=newBundle();12b.imagePath= imagePath;13channel0.bind(b);14...15newDataflowMessagingRunnable() {16@Override17protected voiddoRun(Object... args) {18Bundle b= ((Bundle)args[0]);19BufferedImage bufferedImage= b.bufferedImage;20String imagePath= b.imagePath;21Document docTamura= b.docTamura;22Document docColor= autoColorCorrelogramExtractor.createDocument(docTamura, bufferedImage, imagePath);23b.docColor= docColor;24channel3.bind(b);25}26}.call(channel2.getVal());27...28}Fig. 2. The closure representingNode2and the channels connecting it.1for(String imagePath : FileUtils.getAllImages(newFile(IMAGES_DIRECTORY))) {23// Begin Node14BufferedImage bufferedImage= ImageIO.read(newFileInputStream(imagePath));5Document docJPEG= JPEGExtractor.createDocument(bufferedImage, imagePath);6// End Node178// Begin Node29Document docTamura= tamuraExtractor.createDocument(docJPEG, bufferedImage, imagePath);10// End Node21112// Begin Node313Document docColor= autoColorCorrelogramExtractor.createDocument(docTamura, bufferedImage, imagePath);14// End Node31516// Begin Node417Document docFCTH= FCTHExtractor.createDocument(docColor, bufferedImage, imagePath);18indexWriter.addDocument(docFCTH);19// End Node420}Fig. 3. Inverting the loop so that each node can operate in parallel.VII. CONCLUSIONACKNOWLEDGMENTThe authors would like to thank Stas Negara, MohsenVakilian, Gopal Santhanaraman and Fredrik Kjolstad for theirthoughtful comments and feedback on the ideas and the imple-mentation. Nicholas Chen was supported by US Departmentof Energy Grant No. DOE DE-FG02-06ER25752 and the RayOzzie Fellowship.REFERENCES[1]J. P. Morrison,Flow-Based Programming: A New Approach to Appli-cation Development, 2nd ed. CreateSpace, 2010.[2]T. G. Mattson, B. A. Sanders, and B. L. Massingill,Patterns for ParallelProgramming. Addison-Wesley Professional, 2004.[3]E.-G. Kim and M. Snir, ‚ÄúResources on Parallel Patterns,‚Äùhttp://www.cs.uiuc.edu/homes/snir/PPP/, 2011.[4]‚ÄúGPars (Groovy Parallel Systems),‚Äùhttp://gpars.codehaus.org/.[5]Intel Corporation, ‚ÄúIntel Threading Building Blocks,‚Äùhttp://www.threadingbuildingblocks.org/.[6]‚ÄúTPL DataÔ¨Çow,‚Äùhttp://msdn.microsoft.com/en-us/devlabs/gg585582.[7]E. Reed, N. Chen, and R. Johnson, ‚ÄúExpressing Pipeline ParallelismUsing TBB Constructs: A Case Study on What Works and WhatDoesn‚Äôt,‚Äù inWorkshop on Transitioning to Multicore, 2011.[8]M. Kim, H. Kim, and C.-K. Luk, ‚ÄúProspector: A Dynamic Data-Dependence ProÔ¨Åler To Help Parallel Programming,‚Äù in2nd USENIXWorkshop on Hot Topics in Parallelism (HotPar; 10), 2010. [Online].Available:http://www.cc.gatech.edu/‚á†minjang/hotpar10.pdf[9]A. J. Dorta, C. Rodriguez, F. d. Sande, and A. Gonzalez-Escribano,‚ÄúThe OpenMP Source Code Repository,‚Äù inProceedings of the 13thEuromicro Conference on Parallel, Distributed and Network-BasedProcessing. Washington, DC, USA: IEEE Computer Society, 2005,pp. 244‚Äì250. [Online]. Available:http://portal.acm.org/citation.cfm?id=1042445.1043616[10]M. Wolfe,High Performance Compilers for Parallel Computing.Addison-Wesley, 1996.[11]M. Sridharan, S. Chandra, J. Dolby, S. J. Fink, and E. Yahav,Alias Analysis for Object-Oriented Programs. Springer BerlinHeidelberg, 2013, vol. 7850, pp. 196‚Äì232. [Online]. Available:Fig. 1. The indexing loop for LIRe with the different nodes annotated.
through their data dependencies. In its analysis step, it stati-
cally checks for inter -node data races (i.e., data races between
nodes) and warns the developer of any. In its transformation
step, it creates the nodes and the edges between them using
the underlying library constructs.
The underlying construct to represent a node is a closure .
The body of the closure contains the annotated statements
for each node. Closures as a built-in language construct are
supported in C++11 and C#. In the current version of Java,
closures are expressed using anonymous inner classes. The
underlying construct to represent an edge is a channel . A
channel is a strongly-typed queue data structure. All three
parallel libraries, i.e., GPars, TBB and TPL DataÔ¨Çow, follow
this same scheme of using closures and channels. Thus, our
approach is very applicable to all three and we can easily target
the constructs in each of them.
Figure 2 shows the generated code for Node2 after the
EXTRACT NODES refactoring. Node2 is expressed as a
DataflowMessagingRunnable anonymous inner class
(lines 15 ‚Äì 26). It consumes values from channel2 (line 26)
and produces values into channel3 (line 24). The values
inchannel2 are provided by Node1 . The channels are
expressed as a DataflowQueue . Typically, each data depen-
dency is communicated via one dedicated channel. However,
this leads to a proliferation of channels ‚Äî making the code
hard to read ‚Äî and also comes with an associated performance
cost ‚Äî additional bookkeeping for each channel. We address
both these issues by bundling data dependencies together when
possible (lines 1 ‚Äì 5).
Observe that there is a non-trivial amount of boilerplate code
that needs to be written. Imagine how tedious it would be for a
developer to do this by hand. While some amount of verbosity
stems from the lack of a direct syntax for closures in Java,
the rest are actually required as part of using the underlying
parallel library. Note that the generated code is notparallel yet.
EXTRACT NODES is an intermediate refactoring step. We offer
the developer the opportunity to explore the code and makesimple tweaks as desired. For instance, perhaps she would like
to make use of other refactorings such as R ENAME VARIABLE
to rename the generic channels names from channel0 to
something more intention-revealing.
The second refactoring that JFlow supports
is I NVERT LOOP. I NVERT LOOP locates all the
DataflowMessagingRunnable objects in the loop
and moves them into a computation Ô¨Çow graph. Intuitively,
it inverts the nodes in the loop into a new construct, a
FlowGraph object, allowing the nodes to run in parallel.
Internally, a FlowGraph object maintains its own thread
pool and coordinates the execution of node.
Figure 3 shows the code after the I NVERT LOOP refactoring.
Line 1 creates a new FlowGraph object, fGraph . Lines
3 ‚Äì 14 register the DataflowMessagingRunnable for
Node2 with the FlowGraph object.
For each node, JFlow checks if it is possible to run the
node in a data parallel manner without any intra -node data
races (i.e., data races within nodes). If so, it informs the
user of this possibility. The user then needs to decide if
this is suitable for her particular application. Operating in
a data parallel manner improves throughput but does not
preserve the ordering of processed items. For instance, in
the LIRe example, the images will arrive out-of-order if they
are processed in a data parallel manner.1Allowing this is a
decision that the developer needs to make. It is impossible
to statically infer this from the sequential code alone. The
sequential code is over-constrained and always imposes an
ordering even when one is not necessary [23]. If we strictly
enforce the sequential ordering, we miss many parallelization
opportunities.
In the LIRe example, JFlow informs the user that Node1 ,
Node2 andNode3 can operate in a data parallel manner.
1TBB supports in-order processing by tagging items. Each item is tagged
with its arrival order. The receiving node keeps track of the order and buffers
items until it receives an item with the right order. This is convenient but
incurs some overhead.Node2Node2Node2Node2Node2Node2Node2Node2Node21classBundle {2BufferedImage bufferedImage;3Document docColor, docJPEG, docTamura;4String imagePath;5}67finalDataflowQueue<Bundle> channel0=newDataflowQueue<Bundle>();8finalDataflowQueue<Bundle> channel1=newDataflowQueue<Bundle>();9...10for(String imagePath : FileUtils.getAllImages(newFile(IMAGES_DIRECTORY))) {11Bundle b=newBundle();12b.imagePath= imagePath;13channel0.bind(b);14...15newDataflowMessagingRunnable() {16@Override17protected voiddoRun(Object... args) {18Bundle b= ((Bundle)args[0]);19BufferedImage bufferedImage= b.bufferedImage;20String imagePath= b.imagePath;21Document docTamura= b.docTamura;22Document docColor= autoColorCorrelogramExtractor.createDocument(docTamura, bufferedImage, imagePath);23b.docColor= docColor;24channel3.bind(b);25}26}.call(channel2.getVal());27...28}Fig. 4. Inverting the loop so that each node can operate in parallel. Additionally,Node1,Node2andNode3can operate in a data parallel manner.1FlowGraph fGraph=newFlowGraph();2...3fGraph.operator(Arrays.asList(channel1), Arrays.asList(channel2), 4,newDataflowMessagingRunnable() {4@Override5protected voiddoRun(Object... args) {6Bundle b= ((Bundle)args[0]);7BufferedImage bufferedImage= b.bufferedImage;8Document docJPEG= b.docJPEG;9String imagePath= b.imagePath;10Document docTamura= tamuraExtractor.createDocument(docJPEG, bufferedImage, imagePath);11b.docTamura= docTamura;12bindOutput(b);13}14});15...16for(String imagePath : FileUtils.getAllImages(newFile(IMAGES_DIRECTORY))) {17Bundle b=newBundle();18b.imagePath= imagePath;19channel0.bind(b);20}21fGraph.waitForAll();// Wait for all computation in the FlowGraph to complete and then continue executionFig. 5. Inverting the loop so that each node can operate in parallel. Additionally,Node1,Node2andNode3can operate in a data parallel manner.
ColorCorrelogramTamuraJPEGFCTHDatabaseColorCorrelogramTamuraJPEGFCTHDatabaset1t2t3t4t5t6TimeImages
IMG
IMG
IMGFig. 6. The LIRe pipeline executing through time.using a different color to represent which image each node isoperating on at each time instance.Figure7presents an overview of the analysis. We detaileach stage below. Earlier stages are less expensive to run; weuse their results to determine if we need to run the later, more
Check control dependenciesCompute data dependenciesCompute heap mod/refCheck node interferenceReport warnings PerformTransformation AnnotatenodesFig. 7. Overview of the analysis workÔ¨Çow for the EXTRACTNODESrefactoring.expensive stages or to abort the analysis.The developer annotates the original program and partitionsthe statements into nodes,N. Each node,n2Ncontains anon-empty set of statements,S.1) Check Control Dependencies:Nodes in a pipeline canhave both control and data dependencies. We handle controlFig. 2. The closure representing Node2 and the channels connecting it.
Node2Node4Node2Node2Node2Node2Node2Node2Node3Node2Node2Node2Node11classBundle {2BufferedImage bufferedImage;3Document docColor, docJPEG, docTamura;4String imagePath;5}67finalDataflowQueue<Bundle> channel0=newDataflowQueue<Bundle>();8finalDataflowQueue<Bundle> channel1=newDataflowQueue<Bundle>();9...10for(String imagePath : FileUtils.getAllImages(newFile(IMAGES_DIRECTORY))) {11Bundle b=newBundle();12b.imagePath= imagePath;13channel0.bind(b);14...15newDataflowMessagingRunnable() {16@Override17protected voiddoRun(Object... args) {18Bundle b= ((Bundle)args[0]);19BufferedImage bufferedImage= b.bufferedImage;20String imagePath= b.imagePath;21Document docTamura= b.docTamura;22Document docColor= autoColorCorrelogramExtractor.createDocument(docTamura, bufferedImage, imagePath);23b.docColor= docColor;24channel3.bind(b);25}26}.call(channel2.getVal());27...28}Fig. 4. Inverting the loop so that each node can operate in parallel. Additionally,Node1,Node2andNode3can operate in a data parallel manner.1FlowGraph fGraph=newFlowGraph();2...3fGraph.operator(Arrays.asList(channel1), Arrays.asList(channel2), 4,newDataflowMessagingRunnable() {4@Override5protected voiddoRun(Object... args) {6Bundle b= ((Bundle)args[0]);7BufferedImage bufferedImage= b.bufferedImage;8Document docJPEG= b.docJPEG;9String imagePath= b.imagePath;10Document docTamura= tamuraExtractor.createDocument(docJPEG, bufferedImage, imagePath);11b.docTamura= docTamura;12bindOutput(b);13}14});15...16for(String imagePath : FileUtils.getAllImages(newFile(IMAGES_DIRECTORY))) {17Bundle b=newBundle();18b.imagePath= imagePath;19channel0.bind(b);20}21fGraph.waitForAll();// Wait for all computation in the FlowGraph to complete and then continue executionFig. 5. Inverting the loop so that each node can operate in parallel. Additionally,Node1,Node2andNode3can operate in a data parallel manner.
ColorCorrelogramTamuraJPEGFCTHDatabaseColorCorrelogramTamuraJPEGFCTHDatabaset1t2t3t4t5t6TimeImages
IMG
IMG
IMGFig. 6. The LIRe pipeline executing through time.using a different color to represent which image each node isoperating on at each time instance.Figure7presents an overview of the analysis. We detaileach stage below. Earlier stages are less expensive to run; weuse their results to determine if we need to run the later, more
Check control dependenciesCompute data dependenciesCompute heap mod/refCheck node interferenceReport warnings PerformTransformation AnnotatenodesFig. 7. Overview of the analysis workÔ¨Çow for the EXTRACTNODESrefactoring.expensive stages or to abort the analysis.The developer annotates the original program and partitionsthe statements into nodes,N. Each node,n2Ncontains anon-empty set of statements,S.1) Check Control Dependencies:Nodes in a pipeline canhave both control and data dependencies. We handle control
Fig. 3. Inverting the loop so that each node can operate in parallel. Additionally, Node1 ,Node2 andNode3 can operate in a data parallel manner.
She decides that it is permissible for items to be processed
out-of-order. The third parameter to operator on line 3,
represents the degree of parallelism to use. By default, JFlow
uses the number of cores on the machine. The user can tune
this by hand using an external proÔ¨Åler, or an auto-tuning
technique [24].
The original loop serves as a generator that will provide
the initial data to Node1 . In the Ô¨Ågure, the for loop will
generate theimagePath variable that is used in the Ô¨Årst
and subsequent nodes. After the FlowGraph object Ô¨Ånishes
its execution, it resumes serial execution with the rest of the
code (Line 21).
III. A NALYSES AND TRANSFORMATIONS
This section details the analyses we perform to determine if
the E XTRACT NODES and I NVERT LOOP refactorings can be
performed safely. The analyses use the WALA [25] library foranalyzing Java source code. Both refactorings are integrated
into the Eclipse IDE.
A. Extract Nodes
The analysis for the E XTRACT NODES refactoring checks if
the annotated nodes can be safely partitioned into a pipeline,
i.e., no abnormal control Ô¨Çow, no loop-carried dependencies
and no inter-node data races. Figure 4 presents an overview
of the analysis. We detail each stage below. Earlier stages are
less expensive to run; we use their results to determine if we
need to run the later, more expensive stages or to abort the
analysis.
The developer annotates the original program and partitions
the statements in the original loop into Nnodes. The origi-
nal loop iterates over all the elements to be processed and
generates the data for the Ô¨Årst node in the pipeline.Check control dependenciesCompute data dependenciesCompute side eÔ¨ÄectsCheck inter-node data racesReport warnings PerformTransformation AnnotatenodesFig. 4. Overview of the analysis workÔ¨Çow for the E XTRACT NODES
refactoring.
1) Check Control Dependencies: Nodes in a pipeline can
have both control and data dependencies. We handle control
dependencies implicitly by constraining each node to have a
single exit. The Ô¨Årst stage of our analysis builds a control Ô¨Çow
graph for the program and checks that each node obeys this
single exit constraint. One consequence of this is that a node
should not throw an exception that it does not catch. If a node
violates this constraint, we inform the developer and abort the
rest of the analysis.
2) Compute Data Dependencies: The second stage of the
analysis computes the data dependencies between nodes and
determines how to route the values of variables between nodes.
For instance, in Figure 1, Node2 consumes the values of vari-
ables docJPEG ,bufferedImage andimagePath from
Node1 ; in turn, it produces the value of variable docTamura
forNode3 .
To compute the data dependencies between nodes, we Ô¨Årst
build a data dependence graph for the method that contains
the annotated nodes.2LetVbe the set of variables and Sbe
the set of statements in the program. A data dependence graph
contains vertices that represent program statements and edges
that represent data dependencies between statements. A data
dependence exists between statements s1;s22Sifs1deÔ¨Ånes
a variablev2Vands2usesv, and there is no intervening
deÔ¨Ånition of valong the execution path from s1tos2. Let all
data dependencies in the program be represented as tuples of
the formhs1;v;s2i2DSVS, wheres1deÔ¨Ånes the
variablevthats2uses.
Each node, n2Nhas a set of input and output data
dependencies. Denote the statements in node nby the set
Sn. DeÔ¨Åne the set of input dependencies for a node as
IN(n) =fhs1;v;s2i2Djs1=2Sn^s22Sng. Intuitively,
IN(n)denote the data dependencies coming into the current
node from outside, which is why we ignore statements internal
to a node (the s1=2Snclause). Similarly, deÔ¨Åne the set
of output dependencies as OUT (n) =fhs1;v;s2i 2Dj
s12Sn^s2=2Sng. Intuitively, OUT (n)denote the data
dependencies going out of the current node, again ignoring
statements internal to a node.
Finally, deÔ¨Åne the function ContainingNode :S!N[
fgeneratorgthat maps statements to nodes. Recall that the
original loop serves as a generator that provides the necessary
initialization data that are notproduced by any of the nodes,
2We leverage WALA‚Äôs use of static single assignment (SSA) form as
its intermediate representation. SSA offers the same information as a data
dependence graph but in a more compact representation.
Stmt2Stmt3Stmt1Stmt4Node2var1var3var2Node3Node1IN(Node2)=hStmt1,va r1, Stmt2iOUT(Node2)=hStmt3,va r3, Stmt4iContainingNode(Stmt1)=Node1D=hStmt1,va r1, Stmt2i,hStmt2,va r2, Stmt3i,hStmt3,va r3, Stmt4iContainingNode(Stmt3)=Node2ContainingNode(Stmt4)=Node3ContainingNode(Stmt2)=Node2Fig. 5. Keeping track of dependencies between nodes.
e.g., loop variables and instance Ô¨Åelds. Using the functions
IN(n),OUT (n)andContainingNode (s), we determine
how to route variables between nodes. Figure 5 illustrates these
functions for a simple example.
In the LIRe example, one of the elements of IN(Node 2)is
hS#5;docJPEG;S#9i, where S#X represents the statement
at line X in Figure 1. ContainingNode (S#5) =Node 1so
we know that docJPEG comes from Node1 .
If we discover a loop-carried dependency during the pro-
cess of building the data dependence graph, we inform the
developer and abort the rest of the analysis. A loop-carried
dependency essentially serializes the execution since it needs
to wait for the previous iteration to complete before continu-
ing.
3) Compute side effects: This stage of the analysis com-
putes the possible side effects to the heap for each statement.
The results of this stage are used in the Ô¨Ånal stage of our
analysis to determine if two nodes might have a data race. We
distinguish read andwrite effects to objects on the heap.There
is a data race between two nodes if their contained statements
may access the same object and at least one of those accesses
is a write.
Computing the side effects requires both call-graph and
pointer analysis. Call-graph analysis attempts to approximate
the calling relations between methods in a program. Pointer
analysis is a compile-time analysis that attempts to determine
the set of objects pointed to by a reference variable of a
reference object Ô¨Åeld. The results of both analyses allow us to
track read and write accesses to the heap across method calls.
Call-graph and pointer analysis are highly interdependent; we
rely on WALA‚Äôs on-the-Ô¨Çy call-graph construction that builds
the call-graph and performs pointer analysis simultaneously,
yielding better precision [26].
Our call-graph analysis employs k-object sensitivity , a no-
tion of context sensitivity proposed by Milanova et al. [14] and
recently shown by Naik et al. [12] to be effective for detecting
data races in object-oriented programs. Object-sensitivity uses
thereceiver object at an instance method invocation (the
implicit this parameter for object-oriented programs), to
distinguish different calling contexts. Static methods that lack
a receiver object have an empty context . K-object sensitivity
keeps track of a sequence of, at most, k, object allocation sites
representing the receiver object, i.e., objects are named by the
sequenceo1;o2;:::;o k. In general, the larger the value of k,
the more precise the results, albeit at the expense of scalability.
We usek= 2 in our analysis.Our pointer analysis is a context sensitive, Ô¨Çow insensitive,
Ô¨Åeld sensitive and subset-based analysis [11]. Abstract objects
are distinguished based on their allocation sites in a particular
context, i.e., k-object sensitivity, in our case. This allows us
to treat context and objects uniformly, as done in Naik et
al. [12]. This uniformity plays a key role in the Ô¨Ånal stage
of our analysis.
Our side effects analysis is based on an existing interpro-
cedural mod-ref analysis [27]. We compute the effects on
instance Ô¨Åelds, static Ô¨Åelds and array elements. We use the
result from our pointer analysis to determine what objects
they can point to. For arrays, our analysis is index-insensitive,
i.e., it does not distinguish between individual elements of
the array. More precisely, we keep track of the effects of the
following heap-accessing statements, where x,yandiare
local variables:
Instance Fields y=x:f(resp.x:f=y) that read (resp.
write) instance Ô¨Åeld f of the set of objects that xcan
point to.
Static Field y=C:s (resp.C:s=y) that read (resp.
write) to the static Ô¨Åeld sof classC.
Arraysy=x[i](resp.x[i] =y) that read (resp. write)
an element of the set of arrays that xcan point to.
DeÔ¨ÅneStatementRef (s;c)(resp.StatementMod (s;c))
as the set of heap objects that statement sin context
cof the enclosing method can read (resp. write). DeÔ¨Åne
MethodRef (c;m)(resp.MethodMod (c;m)) as the set of
heap objects that can be read (resp. written) in context c
of method m. Intuitively, MethodRef andMethodMod
summarize all the heap accesses for a particular method,
including its callees (as determined by the call-graph analysis)
transitively. Figure 6 shows the algorithm for computing the
side effects for each node in our pipeline. On line 8, we consult
the call-graph to determine the possible target methods for
the invocation statement in the current context. We apply the
algorithm to each node in our pipeline and collect its read
effects in nodeRef and write effects in nodeMod. For brevity,
we writeSet 1 Set 1[Set 2asSet 1[=Set 2.
B. Check Inter-node Data Races
The Ô¨Ånal stage of the analysis makes use of information
from the previous stages to check for data race between nodes.
Our analysis checks for data races between pairs of nodes.
Considering pairs of nodes at a time simpliÔ¨Åes the analysis
and also makes it easier to pinpoint and report the possible
data races to the developer in an understandable way.
Letf(ni;nj)jni;nj2N^i6=jgrepresent pairs of nodes
in the pipeline. From the previous stage of the analysis, we
computed both nodeRef and nodeMod for each node. Figure 7
presents our algorithm for computing possible data races.
Becauseniandnjcan operate in parallel, there is a possible
data race if nireads from orwrites to a memory location
thatn2also writes to. Line 1 of Figure 7 computes the set
of objects that could have a data race. The algorithm then
examines each object and prints specialize warning messages
based on the type of the object and the pairs of nodes involved.Input: callgraph, currentContext, statementsInNode
Output: nodeRef, nodeMod
1:nodeRef ;
2:nodeMod ;
3:for all Statement s : statementsInNode do
4: ifisHeapAccessingStmt(s) then
5: nodeRef[=StatementRef(s, currentContext)
6: nodeMod[=StatementMod(s, currentContext)
7: else if isMethodInvocationStmt(s) then
8: methods possibleInvocations(callgraph, s, current-
Context)
9: for allhc;mi: methods do
10: nodeRef[=MethodRef(c,m)
11: nodeMod[=MethodMod(c,m)
12: end for
13: else
14:fStatement has no effect on heap g
15: end if
16:end for
Fig. 6. Algorithm to compute the side effects for each node.
Input:nodeRef ni;nodeMod ni;nodeMod nj
1:conÔ¨ÇictingHeapObjects  (nodeRef ni[nodeMod ni)\
nodeMod nj
2:for all Object o : conÔ¨ÇictingHeapObjects do
3: ifisStaticField(o) then
4: warningMessageForStaticField(o, ni,nj)
5: else if isInstanceField(o) then
6: warningMessageForInstanceField(o, ni,nj)
7: else
8: warningMessageForArray(o, ni,nj)
9: end if
10:end for
Fig. 7. Basic algorithm to compute the possible data races between pairs of
nodes.
ColorCorrelogramTamuraJPEGFCTHDatabaseColorCorrelogramTamuraJPEGFCTHDatabaset1t2t3t4t5t6TimeImages
IMG
IMG
IMG
Fig. 8. The LIRe pipeline executing through time.
While the basic algorithm shown in Figure 7 works (it is
sound), it is too conservative. For instance, in Figure 1, it will
warn that the object pointed to by the variable docJPEG could
be involved in a data race since it is being accessed (and at
least one access is a write) in both Node1 andNode2 . The
basic algorithm fails to take advantage of a useful property of
Ô¨Çow-based parallelism: ownership transfer .
Figure 8 shows the pipeline execution of LIRe. At each time
slice, t, at most nnodes can execute in parallel, where n is thenumber of annotated nodes in the pipeline. Each node operates
on a different image. We illustrate this by using a different
color to represent which image each node is operating on at
each time slice. A common pattern we have observed is that
each stage receives an object, operates on it, generates new
objects and passes them on to the next stage. This is a form
of ownership transfer [28]. A node transfers ownership of the
object it was operating on to the next node in the pipeline.
Input:nodeRef ni;nodeMod ni;nodeMod nj
1:conÔ¨ÇictingHeapObjects  (nodeRef ni[nodeMod ni)\
nodeMod nj
2:for all Object o : conÔ¨ÇictingHeapObjects do
3: ifisStaticField(o) then
4: warningMessageForStaticField(o, ni,nj)
5: else if isTransferred(o, ni,nj)then
6:fNo data race since object ownership is transferred g
7: else if isInstanceField(o) then
8: warningMessageForInstanceField(o, ni,nj)
9: else
10: warningMessageForArray(o, ni,nj)
11: end if
12:end for
Fig. 9. Algorithm that incorporates ownership transfer to compute the possible
data races between pairs of nodes.
Figure 9 shows the new algorithm that incorporates own-
ership transfer. The main changes are on lines 5 ‚Äì 6. Notice
that ownership transfer only affects non-static objects. Static
objects are essentially global variables and we cannot transfer
their ownership since all nodes operate on the same static
object. On the other hand, it is possible to transfer ownership
of instance objects and arrays.
To determine if an object can be transferred between nodes,
we use the results of the data dependence and pointer analysis
from previous stages. To be able to transfer an object, a node
must Ô¨Årst own it. There are two ways that a node becomes the
owner. First, a previous node could have transferred ownership
to it. Second, and the most common case, is that the node
created the object. For instance, from Section III-A2, we
computed that the variable docJPEG is passed from Node1
toNode2 . The object pointed to by docJPEG was indeed
created in Node2 . Thus, it can transfer the ownership to
Node3 . Using this object as the root, we then calculate all
other objects that could also be transferred. Figure 10 shows
the procedure isTransferred , which determines if object o
is transferred from node nito nodenj.
The key idea of isTransferred is to take advantage of
the way that objects are labeled using a k-object sensitive
pointer analysis. Objects are labeled through a sequence of
their allocation sites, i.e., o1;o2;:::;o k. We can use this label
to determine if an object is rooted at one of the objects that
was transferred. If so, then by transitivity, it is also transferred.
We make use of this fact on line 5 of Figure 10.
An important assumption of our algorithm is that the
developer starts with a purely sequential version of the appli-Input: dataDependenceAnalysis, pointerAnalysis, o,ni,nj
Output: true if the object ois transferred, false otherwise
1:var fhs1;v;s2i jContainingNode (s1) =ni^
ContainingNode (s2) =njg
2:objects fpointsTo (v)jh;v;i2varg
3:root frjr2objects^isOwner (r;ni)g
4:o1;o2;:::;o k= label(o)
5:return true if9r2root that is part of the label( o)
Fig. 10. Procedure isTransferred(o, ni,nj)
Compute data dependenciesCompute side eÔ¨ÄectsCheck intra-node data racesReport warnings PerformTransformation 
Fig. 11. Overview of the analysis workÔ¨Çow for the I NVERT LOOP refactoring.
cation that she wishes to parallelize. If her application already
incorporates some form of parallelism (through threads), then
we would need to also perform a thread escape analysis to
ensure that the objects in one node are not leaked to other
threads.
If these four analyses succeed, then then E XTRACT NODES
goes ahead and performs the transformations shown in Sec-
tion II. If not, it presents the warnings to the developer. The
developer can then review the warnings and act accordingly.
C. Invert Loop
The analysis for the I NVERT LOOP refactoring checks if any
of the extracted nodes from the E XTRACT NODE refactoring
can be run in a data parallel manner. While the analysis
for E XTRACT NODES checks for inter -node parallelism, this
analysis checks for intra -node parallelism. Figure 11 presents
an overview of the analysis. The Ô¨Årst and second stages follow
the same principles as the previous analysis; we discuss only
the third stage ‚Äî computing possible data races.
Input:nodeMod n
1:for all Object o :nodeMod ndo
2: ifisStaticField(o) then
3: warningMessageForStaticField(o, n)
4: else if isOwner(o, n)_isTransferred(o, n, predeces-
sor(n)) then
5:fNo data race on this object g
6: else if isInstanceField(o) then
7: warningMessageForInstanceField(o, n)
8: else
9: warningMessageForArray(o, n)
10: end if
11:end for
Fig. 12. Algorithm to determine if a node can run in a data-parallel manner.Figure 12 shows the algorithm for computing possible data
races when a node is run in a data-parallel manner. It checks all
possible write effects to the heap from the selected node. Any
write access to a static Ô¨Åeld will cause a data race when the
node operates in parallel. However, write accesses to instance
Ô¨Åelds and arrays are safe as long as the node only writes to
heap locations that it owns or has been transferred to it from
a predecessor node. Intuitively, a node can run in parallel if it
operates only on fresh objects.
If the analyses for I NVERT LOOP succeeds, JFlow informs
the developer of the possibility of running a node in a data-
parallel manner. Recall that running a node in this manner
causes its processed objects to arrive out-of-order to the next
node. Thus, the developer needs to use her domain knowledge
to decide if this is permissible for her application.
IV. E VALUATION
We have implemented JFlow and evaluated it on a 2.33 GHz
4-core Core 2 Quad processor with 4 GB of memory. When
invoked interactively as an Eclipse plug-in, JFlow takes less
than 30 seconds to perform the analysis and transformations.
We think this is reasonable for an interactive tool. The bulk of
this time was spent in initializing the call graph and pointer
analysis.
After performing the transformations, we used Oracle‚Äôs Java
HotSpot 64-Bit Server JVM to measure the execution times.
We set the min and max heap space for the JVM to 512M.
We average the running times over 6 runs. The source code
for both the serial and parallel versions of the benchmarks are
available at http://vazexqi.github.io/JFlow/.
Table I shows the results. The SLOC Parallel column
gives an estimate of the transformation effort required to use
GPars parallel library constructs. The actual parallelization
effort, if done manually, is much higher since the developer
has to also spend time analyzing and scrutinizing the code for
data races. The performance numbers show that applications
parallelize using Ô¨Çow-based parallelism through the constructs
of a parallel library can perform reasonably well. We now
discuss the necessary inspections and changes (if any) involved
with parallelizing these applications using JFlow.
The Ô¨Årst four benchmarks are taken directly from OoO-
Java [22], which is most similar to our work. OoOJava
solves the complexity of parallelizing modern object-oriented
applications through a combined static and dynamic approach
with a custom runtime (see Section V). JFlow, on the other
hand, solves the problem by involving developer in the
parallelization process. The partitioning annotations for each
program follow the task annotations from OoOJava. We use
these benchmarks to validate the effectiveness of our approach
in analyzing and transforming sequential code to parallel code.
Note that we do not directly compare execution times as the
runtime of OoOJava is sufÔ¨Åciently different from the approach
that we are taking.
After the initial annotation for the nodes, JFlow was able to
parallelize KMeans successfully without any user intervention.
For MolDyn, it reported one spurious data race that involvedarray accesses because our analysis is index-insensitive for
array accesses. For Monte Carlo, it reported spurious data
races on twostatements that access the Ô¨Åle system. Java‚Äôs File
API is very complex and uses a lot of programming idioms (in
particular, the Decorator design pattern for wrapping different
input streams) that confuses static analysis. OoOJava does not
use Java‚Äôs File API; it translates Java into C and, thus, is spared
from the complexity of analyzing Java‚Äôs API. Finally, for
RayTracer, we reported spurious data races stemming from one
statement. This single statement made use of multiple objects
allocated using static factory methods. Recall that for our k-
object sensitive analysis, static methods are all lumped under
one context, , which reduces the precision of the analysis.
However, because all the spurious data races only involved a
single statement and were of a particular type of problem, it
was easy for a developer to inspect these by hand and proceed
with the transformation.
The next three applications are what we term real ap-
plications; they are about an order of magnitude larger in
terms of lines of code. We chose these applications because
they are similar to the applications parallelized using pipeline
parallelism from the PARSEC benchmark (written in C++
instead of Java) [29]. PARSEC comprises a representative set
of emerging applications and we are interested to see how well
JFlow can handle them. We used the parallel versions of the
PARSEC benchmarks to guide our partitioning annotations.
Duke is a data-deduplication engine. Our benchmark pro-
cessed a 700MB Ô¨Åle looking for pairs of duplicates and links
them together. Duke has a parallel version with threads. We
followed the same parallelization scheme and achieve similar
speedups as its threaded version, i.e., 1.49x. This shows that
JFlow is able to handle how a developer might parallelize it by
hand. In fact, it detected two data races that was present in the
original parallelization by the author (writes to two separate
counters without proper synchronization). The speedup is low
because Duke is primarily I/O bound rather than CPU bound.
Jbzip2 is a bzip2 compression/decompression library. Our
benchmark decompressed and compressed 1000 Ô¨Åles; this
represents a typical workÔ¨Çow where one would decompress
a Ô¨Åle to manipulate it and then compress it again. As with
MolDyn, the main challenge here was the spurious data races
reported from statements that used Java‚Äôs File API. However,
we could isolate these data races to particular statements that
used the File API and it was easy for a developer to manually
inspect by hand and proceed. Below are two lines (out of six)
that were involved in compressing the contents of a Ô¨Åle. The
main source of confusion in static analysis was the wrapping
of each stream (a key characteristic of the Decorator design
pattern). While it is hard for static analysis, any developer can
quickly inspect these lines and conclude that the streams all
operate on different Ô¨Åles and, thus, cannot have a data race.
1OutputStream compressedStream= new BufferedOutputStream(
2new FileOutputStream(tempFile));
3BZip2OutputStream bzip2OStream= new BZip2OutputStream(
4compressedStream);
Section II described LIRe in detail. Here we focus onTABLE I
SPEEDUPS ON BENCHMARKS
Application Domain SLOC Sequential SLOC Parallel Sequential (ms) Parallel (ms) Speedup
KMeans Mining & Synthesis 504 +73 12980 4356 2.98x
Monte Carlo Financial Trading 991 +45 14906 5294 2.82x
MolDyn Molecular Dynamics 653 +56 23694 7029 3.37x
RayTracer Image processing 828 +55 17704 5127 3.45x
Duke Data warehousing 11464 +55 9502 6384 1.49x
Jbzip2 Data warehousing 3238 +38 17785 7011 2.54x
LIRe Image processing 15476 +76 49226 15446 3.19x
the challenges to parallelization. The original version of
LIRe used reÔ¨Çection to instantiate its classes based on class
names. For instance, to instantiate some of its feature extrac-
tors, it used the Class.forName(x).newInstance()
construct. This form of dynamic class creation, which is
common in dependency-injection frameworks, poses great
difÔ¨Åculties for static analysis [11], [30]. We manually trans-
formed the code so that it instantiates the class directly
via a new statement to the speciÔ¨Åc class. Like most mod-
ern applications, LIRe makes use of the highly reÔ¨Çective
java.util.logging API for error reporting. SpeciÔ¨Åcally
it used the log4j API; we treated such calls as being thread
safe and ignored data races through those calls.
Both Duke and LIRe use the Lucene search engine library
for its indexing and querying. By default, JFlow does not
analyze the source code for external libraries such as Lucene.
We justify this decision in favor of scalability and under-
standability. First, external libraries are huge; moreover, many
projects make use of more than one external library. Analyzing
these libraries will increase the analysis time signiÔ¨Åcantly.
Second, even if we do analyze external libraries, data races
reported that involve the internal structure will be hard to
understand by a developer who is merely using it as a black-
boxlibrary. Her efforts would be better rewarded from reading
the APIs and documentation for those external libraries with
regards to their thread safety. When we ignore calls to external
libraries, we issue a warning to the developer so that she knows
that some of the information might be missing. If she chooses,
she can instruct JFlow to analyze these libraries, albeit at the
expense of time and memory.
TABLE II
INSPECTIONS AND CHANGES NEEDED FROM THE DEVELOPER
Application Inspections & changes
Kmeans None
Monte Carlo Inspect two statements using File API
MolDyn Inspect one statement accessing arrays
RayTracer Inspect one statement using objects created through static
factory methods
Duke Inspect two statements accessing Lucene API
Jbzip2 Inspect six statements using File API
LireConvert reÔ¨Çective construction to use new
Ignore data races from logging constructs
Inspect four statements accessing Lucene APITable II summarizes the inspections and changes necessary
from the developer. We believe that the effort required from the
developer is minimal. If a developer were to do this entirely
manually, it would have required more effort to analyze and
transform. The feedback from JFlow pinpoints the potential
problems and guides her parallelization efforts. We sampled
seven applications from different domains and we believe that
the inspections and changes required are typical of modern
applications. A common pattern we observed is that most
of the applications manipulate data through File APIs; future
work could focus on providing more precise analysis for such
operations.
V. R ELATED WORK
The ideas behind Ô¨Çow-based parallelism are not new. The
earliest inÔ¨Çuences come from the dataÔ¨Çow programming com-
munity. Johnston et al. provide a detailed history of the
evolution of the hardware and software for dataÔ¨Çow pro-
gramming in [31]. Similar to Ô¨Çow-based programming, a
program in the dataÔ¨Çow execution model is represented by
a directed graph; the nodes of the graph represent operations
and the edges between nodes represent data dependencies [32].
DataÔ¨Çow programming typically relies on dedicated dataÔ¨Çow
languages. Lucid [33] and Id [34] are examples of early
dataÔ¨Çow languages while LabView [35] and Prograph [36] are
examples of current dataÔ¨Çow languages that are in use. Most
dataÔ¨Çow languages tend to be restrictive, favoring functional
styles without side effects [37]. These restrictions allow for
easier reasoning of the system but also require that existing
programs be rewritten to conform to those restrictions. Our
approach with JFlow does not mandate a functional style
of programming. Our approach is more practical and allows
existing programs with side-effects to take advantage of Ô¨Çow-
based parallelism as long as the side-effects are well isolated.
Morrison‚Äôs original work on Ô¨Çow-based applications fo-
cused mostly on the architecture and design of systems using
Ô¨Çow-based programming, i.e., decomposing a system into
black boxes that communicate via message passing [1]. While
he did acknowledge that Ô¨Çow-based programming lends itself
well to parallelism, his implementation [38] focused mostly on
modularity and not on parallel performance. This differs from
streaming languages such as Brook [39], StreamIt [40] and
StreamC/KernelC [41], where performance was the primary
focus. By building upon well-designed parallel libraries, ourwork attempts to bring both performance and modularity to a
parallelized application.
To infer the side effects of statements, we relied on a mod-
ref analysis. An alternative approach is to rely on types and
effects systems [42]‚Äì[44]. While types and effects systems
can be more precise, an inherent difÔ¨Åculty is that they require
extensive annotations from the developer. Work has been done
to alleviate this by inferring some of these annotations [45]‚Äì
[47]. Another limitation of such type systems is that they
usually require custom language syntax. This makes them
challenging to adopt into existing programs written in legacy
programming languages. In this regard, approaches based on
pluggable type systems are attractive because they allow a type
system to be seamlessly added to an existing programming
language [48].
We rely on static analysis to determine if an application can
be parallelized safely. As demonstrated in Section IV, static
analysis tends to be conservative. Realizing the limitations of
static analysis, some researchers have proposed a dynamic ap-
proach to program analysis through proÔ¨Åling at runtime. These
approaches rely on the developer to provide a representative
test program for the data dependence analyses to work. A
faulty test program could easily jeopardize the entire analysis
and transformation process.
Though unsound, dynamic approaches can be quite ef-
fective. Thies et al. [21] Ô¨Årst proposed an annotation-based
method for automatically detecting and parallelizing pipeline
parallelism in C programs. Rul et al. [49] and Tournavitis
et al. [50] improved on their work and automatically detect
and parallelize pipeline parallelism in applications without any
annotations. Unfortunately, this approach is not always ideal
for every workÔ¨Çow. Running, collecting and analyzing the data
is slow and consumes a lot of memory and storage. Work by
Kim et al. attempt to alleviate this overhead by parallelizing
and compressing the data collection process [51].
Static and dynamic analysis need not be mutually exclusive.
The OoOJava project combines both [22]. It uses disjoint
reachability analysis to statically analyze the code. When the
analysis cannot safely prove that threads operate on disjoint
objects, it inserts a run-time check. During run time, it
compares the addresses of both objects to determine if they
are indeed disjoint. Such an approach requires the use of a
specialized runtime and might not be feasible for all scenarios.
In its current implementation, OoOJava sidesteps some of the
complexities of analyzing the internal Java libraries (e.g. Java
File API) by translating programs into C and using simpler
library calls.
The idea of interactive tools for parallelization has been
explored in various forms. Two notable tools are SUIF Ex-
plorer [52] and Parascope Editor [53], which focus on transfor-
mations for loop parallelism for scientiÔ¨Åc applications written
in Fortran. Both tools allow the developer to examine the
outcomes of the analysis of the compiler in a rich environment
that includes various visualizations for program dependencies.
Both tools utilized deep interprocedural analyses, which are
inherently conservative, and sought developer input to helpreÔ¨Åne the outcomes of the analyses.
More recently, Dig et al. demonstrated that a transformation-
based approach for introducing concurrency and parallelism
into sequential code via library constructs is practical. Their
initial work focused on providing support for three kinds
of transformations: (i) convert int toAtomicInteger ,
(ii) convert HashMap toConcurrentHashMap and (iii)
convert recursion to ForkJoinTask [54]. Dig et al. then
created R ELOOPER , a tool for for converting array operations
to use data parallelism through the new ParallelArray
construct in Java [55]. Kjolstad et al. continued work in this
area by introducing transformations to convert mutable classes
into immutable classes, i.e., value objects [56].
VI. C ONCLUSIONS AND FUTURE WORK
Modern applications are complex. They tend to use many
different programming idioms and many library APIs. Relying
solely on fully automated parallelizing compilers is likely to
fail and yield unsatisfactory results. On the other hand, the
interactive approach taken by JFlow is both effective and
practical. By leveraging a fast analysis, it tightens the feedback
loop, allowing developers to invoke the tool, act on the
feedback and repeat the process until they have successfully
parallelized their application. While static analysis is con-
stantly improving to account for more programming idioms,
it can never handle allof them ‚Äî nor should it. Incorporating
the developer as part of a tool‚Äôs workÔ¨Çow complements static
analysis and is a practical approach that yields great beneÔ¨Åts.
This paper adopts the interactive approach for refactoring
sequential programs to use pipeline parallelism, the most
common form of Ô¨Çow-based parallelism that we have ob-
served. However, this only scratches the surface of Ô¨Çow-based
parallelism. Many more styles of Ô¨Çow-based parallelism exist
and it would be helpful to equip developers with tools to
handle them. Future work in this area falls into two key
themes: decomposition andre-composition .
Decomposition focuses on helping the developer partition-
ing the original sequential program into nodes of a computa-
tion Ô¨Çow graph. Currently we rely on the developer to annotate
the nodes in a pipeline. This works well for a pipeline with
its linear structure. However, many more complex structures
exist and work remains to determine how to handle them.
Re-composition, on the other hand, focuses on helping the
developer transform the partitioned program to run in parallel.
This involves composing the most appropriate parallel library
constructs to use and tuning them not only for performance
but also for extensibility.
ACKNOWLEDGMENT
The authors would like to thank Stas Negara, Mohsen
Vakilian, Gopal Santhanaraman and Fredrik Kjolstad for their
thoughtful comments and feedback on the ideas and the imple-
mentation. Nicholas Chen was supported by US Department
of Energy Grant No. DOE DE-FG02-06ER25752 and the Ray
Ozzie Fellowship.REFERENCES
[1] J. P. Morrison, Flow-Based Programming: A New Approach to Appli-
cation Development , 2nd ed. CreateSpace, 2010.
[2] T. G. Mattson, B. A. Sanders, and B. L. Massingill, Patterns for Parallel
Programming . Addison-Wesley Professional, 2004.
[3] E.-G. Kim and M. Snir, ‚ÄúResources on Parallel Patterns,‚Äù http://www.
cs.uiuc.edu/homes/snir/PPP/, 2011.
[4] ‚ÄúGPars (Groovy Parallel Systems),‚Äù http://gpars.codehaus.org/.
[5] Intel Corporation, ‚ÄúIntel Threading Building Blocks,‚Äù http://www.
threadingbuildingblocks.org/.
[6] ‚ÄúTPL DataÔ¨Çow,‚Äù http://msdn.microsoft.com/en-us/devlabs/gg585582.
[7] E. Reed, N. Chen, and R. Johnson, ‚ÄúExpressing Pipeline Parallelism
Using TBB Constructs: A Case Study on What Works and What
Doesn‚Äôt,‚Äù in TMC , 2011.
[8] M. Kim, H. Kim, and C.-K. Luk, ‚ÄúProspector: A Dynamic Data-
Dependence ProÔ¨Åler To Help Parallel Programming,‚Äù in HotPar , 2010.
[9] A. J. Dorta, C. Rodriguez, F. d. Sande, and A. Gonzalez-Escribano,
‚ÄúThe OpenMP Source Code Repository,‚Äù in Proceedings of the 13th
Euromicro Conference on Parallel, Distributed and Network-Based
Processing , 2005, pp. 244‚Äì250.
[10] M. Wolfe, High Performance Compilers for Parallel Computing .
Addison-Wesley, 1996.
[11] M. Sridharan, S. Chandra, J. Dolby, S. J. Fink, and E. Yahav, Alias
Analysis for Object-Oriented Programs . Springer Berlin Heidelberg,
2013, vol. 7850, pp. 196‚Äì232.
[12] M. Naik, A. Aiken, and J. Whaley, ‚ÄúEffective Static Race Detection for
Java,‚Äù in PLDI ‚Äô06 .
[13] R. Vall ¬¥ee-Rai, P. Co, E. Gagnon, L. Hendren, P. Lam, and V . Sundaresan,
‚ÄúSoot - a Java bytecode optimization framework,‚Äù in Proceedings of the
1999 conference of the Centre for Advanced Studies on Collaborative
research , ser. CASCON ‚Äô99. IBM Press, 1999, pp. 13‚Äì.
[14] A. Milanova, A. Rountev, and B. G. Ryder, ‚ÄúParameterized object
sensitivity for points-to analysis for java,‚Äù ACM Trans. Softw. Eng.
Methodol. , vol. 14, pp. 1‚Äì41, January 2005.
[15] M. Sharir and A. Pnueli, Two approaches to interprocedural data Ô¨Çow
analysis . Englewood Cliffs, NJ: Prentice-Hall, 1981, ch. 7, pp. 189‚Äì
234.
[16] T. B. Sheridan, ‚ÄúFunction allocation: algorithm, alchemy or apostasy?‚Äù
Int. J. Hum.-Comput. Stud. , vol. 52, pp. 203‚Äì216, February 2000.
[17] M. Lux and S. A. ChatzichristoÔ¨Ås, ‚ÄúLire: Lucene Image retrieval - An
Extensible Java CBIR library,‚Äù in MM ‚Äô08 .
[18] H. Vandierendonck, S. Rul, and K. De Bosschere, ‚ÄúThe Paralax Infras-
tructure: Automatic Parallelization with a Helping Hand,‚Äù in PACT ‚Äô10 .
[19] V . Sarkar, ‚ÄúAutomatic partitioning of a program dependence graph into
parallel tasks,‚Äù IBM J. Res. Dev. , vol. 35, no. 5-6, pp. 779‚Äì804, Sep.
1991.
[20] J. Ferrante, K. J. Ottenstein, and J. D. Warren, ‚ÄúThe program dependence
graph and its use in optimization,‚Äù ACM Trans. Program. Lang. Syst. ,
vol. 9, pp. 319‚Äì349, July 1987.
[21] W. Thies, V . Chandrasekhar, and S. Amarasinghe, ‚ÄúA Practical Approach
to Exploiting Coarse-Grained Pipeline Parallelism in C Programs,‚Äù in
MICRO ‚Äô07 .
[22] J. C. Jenista, Y . h. Eom, and B. C. Demsky, ‚ÄúOoOJava: Software Out-
of-order Execution,‚Äù in PPoPP ‚Äô11 .
[23] K. Knobe, ‚ÄúEase of use with concurrent collections (CnC),‚Äù in HotPar
‚Äô09, Berkeley, CA, USA, 2009.
[24] M. A. Suleman, M. K. Qureshi, Khubaib, and Y . N. Patt, ‚ÄúFeedback-
Directed Pipeline Parallelism,‚Äù in PACT ‚Äô10 , 2010.
[25] ‚ÄúT.J. Watson Libraries for Analysis (WALA),‚Äù http://wala.sf.net.
[26] D. Grove and C. Chambers, ‚ÄúA Framework for Call Graph Construction
Algorithms,‚Äù ACM Trans. Program. Lang. Syst. , vol. 23, pp. 685‚Äì746,
November 2001.
[27] B. G. Ryder, W. A. Landi, P. A. Stocks, S. Zhang, and R. Altucher,
‚ÄúA Schema for Interprocedural ModiÔ¨Åcation Side-Effect Analysis With
Pointer Aliasing,‚Äù ACM Trans. Program. Lang. Syst. , vol. 23, no. 2, pp.
105‚Äì186, Mar. 2001.
[28] S. Negara, R. K. Karmani, and G. Agha, ‚ÄúInferring Ownership Transfer
for EfÔ¨Åcient Message Passing,‚Äù in PPoPP ‚Äô11 . [Online]. Available:
http://doi.acm.org/10.1145/1941553.1941566
[29] C. Bienia, ‚ÄúBenchmarking modern multiprocessors,‚Äù Ph.D. dissertation,
Princeton University, January 2011.[30] E. Bodden, A. Sewe, J. Sinschek, H. Oueslati, and M. Mezini, ‚ÄúTaming
ReÔ¨Çection: Aiding Static Analysis in the Presence of ReÔ¨Çection and
Custom Class Loaders,‚Äù in ICSE ‚Äô11 .
[31] W. M. Johnston, J. R. P. Hanna, and R. J. Millar, ‚ÄúAdvances in DataÔ¨Çow
Programming Languages,‚Äù ACM Comput. Surv. , vol. 36, pp. 1‚Äì34, March
2004.
[32] A. Davis and R. Keller, ‚ÄúData Flow Program Graphs,‚Äù Computer , vol. 15,
no. 2, pp. 26 ‚Äì 41, feb 1982.
[33] W. W. Wadge and E. A. Ashcroft, LUCID, The DataÔ¨Çow Programming
Language . San Diego, CA, USA: Academic Press Professional, Inc.,
1985.
[34] Arvind, K. P. Gostelow, and W. Plouffe, ‚ÄúAn Asynchronous Program-
ming Language and Computing Machine,‚Äù University of California
Irvine, Tech. Rep., 1978.
[35] National Instruments, ‚ÄúWhat is NI Labview?‚Äù http://www.ni.com/
labview/whatis/.
[36] S. Matwin and T. Pietrzykowski, ‚ÄúPROGRAPH: A preliminary report,‚Äù
Computer Languages , vol. 10, no. 2, pp. 91 ‚Äì 126, 1985.
[37] W. Ackerman, ‚ÄúData Flow Languages,‚Äù Computer , vol. 15, no. 2, pp.
15 ‚Äì 25, feb 1982.
[38] J. P. Morrison, ‚ÄúJava Flow-Based Programming,‚Äù http://sourceforge.net/
projects/Ô¨Çow-based-pgmg.
[39] I. Buck, T. Foley, D. Horn, J. Sugerman, K. Fatahalian, M. Houston,
and P. Hanrahan, ‚ÄúBrook for GPUs: Stream Computing on Graphics
Hardware,‚Äù in SIGGRAPH ‚Äô04 .
[40] W. Thies, M. Karczmarek, and S. P. Amarasinghe, ‚ÄúStreamIt: A Lan-
guage for Streaming Applications,‚Äù in CC ‚Äô02 .
[41] U. J. Kapasi, S. Rixner, W. J. Dally, B. Khailany, J. H. Ahn, P. Mattson,
and J. D. Owens, ‚ÄúProgrammable stream processors,‚Äù Computer , vol. 36,
pp. 54‚Äì62, August 2003.
[42] R. L. Bocchino, Jr., V . S. Adve, D. Dig, S. V . Adve, S. Heumann,
R. Komuravelli, J. Overbey, P. Simmons, H. Sung, and M. Vakilian, ‚ÄúA
Type and Effect System for Deterministic Parallel Java,‚Äù in OOPSLA
‚Äô09.
[43] K. R. M. Leino, A. Poetzsch-Heffter, and Y . Zhou, ‚ÄúUsing Data Groups
to Specify and Check Side Effects,‚Äù in PLDI ‚Äô02 .
[44] J. M. Lucassen and D. K. Gifford, ‚ÄúPolymorphic Effect Systems,‚Äù in
POPL ‚Äô88 , New York, NY , USA.
[45] N. Kellenberger, ‚ÄúStatic Universe Type Inference,‚Äù Master‚Äôs thesis, ETH
Zurich, 2005.
[46] M. Niklaus, ‚ÄúStatic universe type inference using a SAT-solver,‚Äù Master‚Äôs
thesis, ETH Zurich, 2006.
[47] M. Vakilian, D. Dig, R. Bocchino, J. Overbey, V . Adve, and R. Johnson,
‚ÄúInferring Method Effect Summaries for Nested Heap Regions,‚Äù in ASE
‚Äô09, Washington, DC, USA.
[48] W. Dietl, S. Dietzel, M. D. Ernst, K. Mus ¬∏lu, and T. W. Schiller, ‚ÄúBuilding
and Using Pluggable Type-Checkers,‚Äù in ICSE ‚Äô11 , New York, NY , USA.
[49] S. Rul, H. Vandierendonck, and K. De Bosschere, ‚ÄúA ProÔ¨Åle-Based
Tool for Finding Pipeline Parallelism in Sequential Programs,‚Äù Parallel
Comput. , vol. 36, pp. 531‚Äì551, September 2010.
[50] G. Tournavitis and B. Franke, ‚ÄúSemi-Automatic Extraction and Exploita-
tion of Hierarchical Pipeline Parallelism using ProÔ¨Åling Information,‚Äù in
PACT ‚Äô10 , New York, NY , USA.
[51] M. Kim, H. Kim, and C.-K. Luk, ‚ÄúSD3: A Scalable Approach to
Dynamic Data-Dependence ProÔ¨Åling,‚Äù in Proceedings of the 2010 43rd
Annual IEEE/ACM International Symposium on Microarchitecture , ser.
MICRO ‚Äô43. Washington, DC, USA: IEEE Computer Society, 2010,
pp. 535‚Äì546.
[52] S.-W. Liao, A. Diwan, R. P. Bosch, Jr., A. Ghuloum, and M. S. Lam,
‚ÄúSUIF Explorer: An Interactive and Interprocedural Parallelizer,‚Äù in
Proceedings of the seventh ACM SIGPLAN symposium on Principles
and practice of parallel programming , ser. PPoPP ‚Äô99. New York, NY ,
USA: ACM, 1999, pp. 37‚Äì48.
[53] K. Kennedy, K. S. McKinley, and C. W. Tseng, ‚ÄúInteractive Parallel
Programming using the ParaScope Editor,‚Äù IEEE Trans. Parallel Distrib.
Syst., vol. 2, pp. 329‚Äì341, July 1991.
[54] D. Dig, J. Marrero, and M. D. Ernst, ‚ÄúConcurrencer: A Tool for
RetroÔ¨Åtting Concurrency into Sequential Java Applications via Concur-
rent Libraries,‚Äù in ICSE ‚Äô09 (Companion) .
[55] D. Dig, M. Tarce, C. Radoi, M. Minea, and R. Johnson, ‚ÄúRelooper:
Refactoring for Loop Parallelism in Java,‚Äù in OOPSLA ‚Äô09 (Companion) ,
New York, NY , USA.
[56] F. Kjolstad, D. Dig, G. Acevedo, and M. Snir, ‚ÄúTransformation for Class
Immutability,‚Äù in ICSE ‚Äô11 , New York, NY , USA.