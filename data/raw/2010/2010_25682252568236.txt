CARE: Cache Guided Deterministic Replay for
Concurrent Java Programs
Y anyan Jiang, Tianxiao Gu, Chang Xu, Xiaoxing Ma, Jian Lu
State Key Lab for Novel Software Technology, Nanjing University, 210023, Nanjing, China
Department of Computer Science and Technology, Nanjing University, 210023, Nanjing, China
jiangyy@outlook.com, tianxiaogu@gmail.com, {changxu,xxm,lj}@nju.edu.cn
ABSTRACT
Deterministic replay tools help programmers debug concurrent pro-
grams. However, for long-running programs, a replay tool may
generate huge log of shared memory access dependences. In this
paper, we present CARE , an application-level deterministic record
and replay technique to reduce the log size. The key idea of CARE
is logging read-write dependences only at per-thread value predic-
tion cache misses. This strategy records only a subset of all exact
read-write dependences, and reduces synchronizations protecting
memory reads in the instrumented code. Realizing that such record
strategy provides only value-deterministic replay, CARE also adopts
variable grouping and action prioritization heuristics to synthesize
sequentially consistent executions at replay in linear time. We
implemented CARE in Java and experimentally evaluated it with
recognized benchmarks. Results showed that CARE successfully
resolved all missing read-write dependences, producing sequentially
consistent replay for all benchmarks. CARE exhibited 1.7–40
(median 3.4) smaller runtime overhead, and 1.1–309 (median
7.0) smaller log size against state-of-the-art technique LEAP .
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging— Debug-
ging aids
General Terms
Algorithms, Performance, Reliability, Theory
Keywords
Replay, Debugging, Cache, Concurrency
1. INTRODUCTION
Concurrent programs are error-prone but difﬁcult to debug. In
order to alleviate such debug difﬁculties, it would be better to have
cyclic debugging techniques such as breakpoint and time-traveling
Corresponding authors.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee.
ICSE ’14, May 31 – June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05 ...$15.00.debugging. However, this is a nontrivial task requiring cost-effective
execution record for deterministic replay [23, 24, 32]. By faithfully
reproducing the progress of the recorded execution, deterministic
replay tools help programmers better pinpoint the root causes of
such concurrency bugs.
The major challenge of replaying a concurrent program execu-
tion comes from its non-determinism, which is naturally associated
with concurrency. On a uniprocessor machine, providing all exter-
nal inputs and thread-scheduling data of an execution necessarily
eliminates all of its non-determinism [12]. However, such infor-
mation is still insufﬁcient for replaying a concurrent execution on
a multiprocessor machine, due to non-deterministic outcomes of
parallel shared memory accesses. According to the methodology
of tackling shared memory non-determinism, existing multiproces-
sor deterministic replay work can be roughly classiﬁed into two
categories: search-based [3, 19, 29, 33, 36] and order-based [9,
13, 18, 35, 37]. Search-based techniques emphasize reduced record
cost, thereby their recorded information is typically incomplete for
a faithful replay. To construct a valid execution for debugging,
search-based techniques usually use the best-effort exhaustive state
space search. On the other hand, order-based techniques record
dependences among all key events (e.g., variable-read/write and
object-lock/unlock events) at runtime. Such dependence informa-
tion is usually sufﬁcient for a faithful replay, but may at the same
time incur intolerably large record cost, e.g., huge log.
State-of-the-art order-based deterministic replay techniques have
reported encouraging results in reproducing concurrent program
executions. However, their record cost is still unsatisfactory. For
example, Stride [37] generates over 30MB/s (2.5TB/day) of log in
its evaluation. For programs that contain mass of shared memory
accesses, order-based replay technique can easily generate hundreds
of megabytes of log per second, and nobody in practice can afford
such performance degradation that may last unpredictably long.
In this paper, we present an order-based deterministic replay
technique that is capable of reducing the record cost, speciﬁcally,
reducing the log size. This is achieved by a trade-off in the replay
guarantee: our approach in theory gives only value-deterministic
replay. Fortunately, we carefully design our algorithms such that
they produce sequentially consistent replay executions for almost all
programs in practice (actually all evaluated benchmarks), making it
practically useful for debugging.
Our key insight lies in the fact that a dominant percentage of
memory accesses exhibit thread locality , i.e., for a speciﬁc vari-
able, its successive accesses can very likely be performed by a
single thread1. Combining successive local memory accesses into
a single log entry can greatly compact the log [8, 37]. To identify
1In our evaluated benchmarks, 77% to 96% of shared variable
accesses exhibit such thread locality.Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ICSE’14 , May 31 – June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05...$15.00
http://dx.doi.org/10.1145/2568225.2568236
457
local memory accesses, we innovatively use light-weight software
value prediction cache to optimistically overestimate such locality
property (i.e., identifying a superset of all such memory accesses
with an ideal cache). Such overestimation reduces the log size, but
also makes replay difﬁcult because some critical shared memory
access dependences might be lost. Therefore, we also propose two
heuristics that can resolve such missing dependences.
Such an idea leads to our cache guided deterministic replay ap-
proach, CARE . Being a typical order-based technique, CARE logs
a fraction of actual precedence orders between reads and their as-
sociated writes (i.e., read-write dependences). CARE assigns each
thread with a value prediction cache that keeps buffered variable
values. Each time a read action is executed, the buffered value is
compared with the one actually read. Only when a distinct compar-
ison result occurs (i.e., cache miss), the corresponding read-write
dependence is logged. Note that this is only a sufﬁcient but not nec-
essary condition indicating that a thread is reading a value written
by another thread. Therefore, CARE logs only a subset of all exact
read-write dependences. Another beneﬁt of this treatment is that
in case of cache hit, CARE does not need to keep the read action
synchronized, further reducing the runtime overhead.
To understand how cache can reduce the log size, consider an
example that thread T1initializes a large data structure consisting
of many variables. Thread T2then copies all these variables into
T2’s thread-local storage. Now all order-based deterministic replay
techniques including CARE keep read-write dependence for each of
these variables. Suppose that later T1once again writes to this data
structure, but overwrites most of the variables with their original
values. After that, all these variables are read by T2a second time.
This time, however, in contrast to state-of-the-art techniques like
LEAP [18] and Stride [37] that keep exact dependences for all of
these variables, CARE only keeps those dependences for variables
being overwritten with different values, reducing the log size.
However, CARE ’s capability of reducing log size is at the cost of
providing only value-deterministic guarantee at replay. Though each
thread’s local behavior can be faithfully reproduced, the global order
of replayed actions might not be sequentially consistent, causing
trouble for the debugging procedure. Fortunately, we propose two
heuristics to mitigate such worst-case possibility: one is grouping
variable sequence numbers into coarse-granularity atomic counters
at record, and the other is prioritizing candidate actions at replay.
With these two heuristics, we resolved all lost read-write depen-
dences in our evaluation.
We implemented CARE as a prototype tool in Java2and evaluated
it on a set of benchmark programs. CARE realized cost-effective
record and replay for Java programs by reducing runtime overhead
and log size. Our experiments showed promising results that CARE
reduced 2.6of runtime overhead and 4.9 of log size compared
with state-of-the-art deterministic replay work LEAP [18] on the
Dacapo benchmark suite, and up to 40 runtime overhead reduction
and 300log size reduction on the scientiﬁc benchmarks. For
another state-of-the-art replay work Stride [37], CARE also reduced
record cost and realized 4 –20log size reduction relatively on
some scientiﬁc benchmarks. In summary, we make the following
contributions in this paper:
1.We propose using value prediction cache to reduce the record
cost in deterministic replay of concurrent programs. This
strategy yields a new trade-off between the record cost and
the replay ﬁdelity.
2The idea of CARE is general and extensible to other programming
languages.2.We present two heuristics for synthesizing sequentially con-
sistent execution at replay, realizing that our approach ensures
only value-deterministic guarantee.
3.We implemented our CARE approach and evaluated it exper-
imentally with real-world benchmarks.
The rest of this paper is organized as follows. Section 2 overviews
CARE . Section 3 presents CARE algorithms for deterministic
record and replay. Section 4 elaborates on some important issues
including CARE ’s cache organization, replay guarantee, and heuris-
tics for resolving unordered actions. Section 5 discusses CARE
implementation and evaluation, which are followed by related work
in Section 6, and ﬁnally Section 7 concludes this paper.
2. CARE OVERVIEW
Deterministic replay tools give developers the ability to time-
traveling a past execution via logged information at runtime. In
this paper, we focus on order-based deterministic replay for failure
diagnosis, i.e., to reproduce execution states by topologically sorting
partially-ordered actions observed at runtime.
To deterministically replay a concurrent Java program on a mul-
tiprocessor machine, we need happens-before orders about shared
memory accesses, lock acquisitions/releases and thread synchro-
nizations. As studied before [25], the latter two kinds of orders
are relatively fewer and can be easily captured. However, shared
memory accesses can be many, and a faithful replay requires pre-
serving the relative order of any two conﬂicting variable accesses in
the observed and replayed executions. Existing order-based work
[9, 13, 18, 35] keeps version numbers of shared variables to iden-
tify such causal relationships. However, simultaneous accesses to
the same version number can occur on a multiprocessor machine.
Thus these accesses have to be synchronized explicitly by additional
locks or implicitly by atomic operations, which can introduce large
runtime overhead at record. Stride [37] addresses this issue by
recording inexact version numbers without synchronization and in-
ferring equivalent read-write dependences later at replay, but value
ﬁngerprints of variable reads have to be logged. On the contrary,
ourCARE takes a fundamentally different approach.
The ﬁrst innovation of CARE is using cache to automatically
identify the dependences between shared memory accesses. CARE
assigns each thread with a software cache storing buffered variable
values, which is updated each time this thread accesses a shared
variable (either read or write). The cache is queried each time
immediately after a thread reads a shared variable. Cache miss
occurs if the read value differs from the one buffered in the cache,
andCARE logs a read-write dependence corresponding to this
variable access. Let us assume that the cache has an inﬁnite capacity
and never discards any buffered value. If a program is sequential
(i.e., single-threaded), no cache miss would ever occur, and hence no
log is kept. Otherwise, cache miss always indicates that a read value
is written by another thread: cache misses successfully identify the
read-write dependences. Note that the converse does not necessarily
hold as cache hit might occur at reading an inter-thread value, as
illustrated in (8)-(9) of Figure 13.
When cache miss occurs, one needs to log exact read-write de-
pendence of memory accesses. However, exact dependences can
be hard to determine because other writes to the same variable may
have already occurred in a short earlier period. To ensure exact
3In this paper, we use the visual convention that actions from the
same thread are grouped vertically by program order. We use R(x) ,
W(x) ,ACQ(x) ,REL(x) to denote read, write, lock acquisition and
release on x, respectively. Solid lines are CARE ’s recorded happens-
before dependences, while dashed lines are actual read-write depen-
dences omitted by CARE .458R(x)=1ACQ(y)REL(y)ACQ(y)REL(y)
W(x)=2Thread 1 Thread 2W(x)=1W(x)=2
W(x)=1R(x)=1(1)
(3)
(4)
(5)
(8)
(10)(2)
(6)
(7)
(9)Figure 1: Illustration of missing dependences
R(x)=1ACQ(x)W(x)=1REL(x)missed
dependenceACQ(x)W(x)=2REL(x)ACQ(x)R(x)=2REL(x)logged
dependencecache query (miss)
cached=0, read=1
value discardThread 1 Thread 2R(x)=0
first read attempt
no synchronization
second read
with synchronizationmissed
dependence
write occurred
before refetching
Figure 2: Illustration of refetching
dependences to be logged, CARE would perform the same read
actions again (i.e., refetching) with synchronization to identify exact
writers corresponding to these read actions, as illustrated in Figure 2.
This trick favors programs that are dominated by the thread-local
accesses because cache-hit queries incur only tiny overhead and
require no synchronization.
The second innovation of CARE lies in its trade-off between log
size and replayed trace ﬁdelity guarantee. Recall that cache miss is
only a sufﬁcient but not necessary indicator of an exact read-write
dependence. As such, not every linear extension of recorded partial
orders is necessarily a valid execution. Figure 1 gives such an ex-
ample. At record, CARE omits the dashed dependences because
of cache hit at (9), hence possibly creating linear extension (1)-(2)-
(3)-(4)-(5)-(6)-(7)-(8)-(10)-(9) at replay. Such a linear extension is
invalid because placing (9) after (10) violates the requisite of sequen-
tial consistency. Actually, the CARE approach weakens the replay
guarantee to be value-deterministic as the trade-off for reduced log
size. At replay, CARE simulates the behavior of every thread’scache to reproduce its exact local behavior. These algorithms are
formalized later in Section 3 and discussed in Section 4.
Realizing this drawback, the third innovation of CARE is two
powerful heuristics to increase the chance of producing valid ex-
ecution at replay for debugging. Both heuristics are based on the
observation that such limitation is caused by missed read-write de-
pendences. The ﬁrst heuristic tries to guide the replay scheduler to
stop before an unordered read action as early as possible, so that
a thread can immediately continue once its target value is written
by another thread. The second heuristic is adding extra ordering
information to reduce non-determinism by grouping variables into
bundles and recording ordering information at a granularity of bun-
dle. Also intuitively, the situation shown in Figure 1 rarely occurs
in the execution of real-world programs. For all evaluated bench-
marks, CARE successfully resolved all missed dependences and
obtained valid executions at replay. Besides, CARE also achieved a
signiﬁcant reduction of log size up to 300%, as compared with the
state-of-the-art replay work LEAP [18].
3. CARE ALGORITHMS
In this section, we formalize the CARE instrumentation for col-
lecting happens-before dependences at runtime, and the algorithm
synthesizing a value-deterministic execution. We currently focus
on the general description of algorithms explaining the principle
ofCARE . More speciﬁc issues such as cache organization, formal
proof of replay guarantee and heuristics for execution synthesis are
discussed in Section 4.
3.1 Notations
Our execution model is similar to the Java memory model [27].
The basic building block of an execution is an action . For action a
of kind kperformed by thread taccessing variable or monitor object
vwhose unique identiﬁer is u, we denote it by a tuple ht;k;v;uiwith
the following conventions: (1) We only consider kto be read, write,
lock acquisition or lock release, and assume that there is neither
dynamic thread creation nor nested lock for brevity4. (2) A runtime
variable vis uniquely identiﬁed by an object reference and a ﬁeld
name. A monitor object vis uniquely identiﬁed by its reference. We
call both of them variables for short. (3) We use a:t,a:k,a:vand
a:uto denote the thread identiﬁer, action type, runtime variable and
unique identiﬁer of action a, respectively. (4) The shared memory is
denoted by heap , which is a mapping from variables to their values.
The mapping can be altered by write actions at runtime.
We assume that any execution of a Java program conforms the
sequential consistency memory model5. Formally, we denote a
Java program execution Eby a 6-tuplehP;A;V;po!;sw!;sc!i.Pis the
program. Note that we assume all threads to be statically created
and their identiﬁers can be uniquely determined by P.Ais the set of
all actions executed in E.Vis the value function indicating the value
read or written by a variable access action. For any lock acquisition
or release action a, we deﬁne V(a)=?.po!denotes the program
order of all actions in A.sw!is the partial order indicating the actual
ordering of lock acquisitions and releases happened in E. Every pair
of lock actions performed on the same monitor variable is ordered
insw!.sc!is a total order on Ato deﬁne a sequentially consistent
execution. We assume that any actual execution Eproduced by Java
runtime is valid, i.e., Emeets the following constraints:
4For thread fork/join and wait/notify actions in actual executions,
we technically treat them as special kinds of lock acquisitions and
releases and create corresponding dependences.
5Actually, CARE instrumentation enforces the sequential consis-
tency memory model.459Algorithm 1: Instrumentation for d heap (v)generating r=
ht;read;v;ui
1d heap (v);
2ifcache t(v),dthen
3 synchronized v
4 d heap (v);
5H H[ (last(v);r);
6G G[f rg;
7 last(v) r;
8 cache t(v) d;
1.sw!conforms the lock semantic, i.e., for any two paired lock
acquisition and release actions on the same monitor variable
v, say, (acq 1;rel1)and(acq 2;rel2), either rel1sw!acq 2or
rel2sw!acq 1holds.
2.sc!conforms the program order and lock order, i.e.,sw!sc!
andpo!sc!hold.
3.sc!is sequentially consistent, i.e., for every read action r2A,
there is a unique write action w2Asuch that wsc!r^ w:v=
r:v^ V(r)=V(w), and there is no wsc!w0sc!rfor any
write action w0.
3.2 CARE Record
At record, CARE instruments a given program’s bytecode at
class-loading time to collect dependences of its actions. During
the program’s execution, log hG;H;Piis collected for later deter-
ministic replay6.G  Ais the set of all read actions that have
ever encountered cache miss in the execution, H AAis the
inter-thread causal dependences, and P AAis the program
order.
In order to collect such ordering information, CARE maintains
several data structures at runtime: (1) Each thread tis associated
with a value prediction cache cache tkeeping buffered values of
variables. Formally, cache tis a mapping from variables to their
values. Initially, cache t(v)=?for all v, and cache t(v)can be reset
to?before any cache update for arbitrary v. The cache resides in
each thread’s local storage and is invisible to other threads. Caches
of different threads are allowed to have inconsistent values for a
variable. (2) Each variable vis assigned with last(v)denoting the
unique identiﬁer of the last thread that performs an action on v.
For every Java virtual machine instruction that can generate a
non-deterministic action, CARE instruments it to collect depen-
dences. For instructions in thread tgenerating heap read action
d heap (v), heap write action heap (v) dand lock acquisition
action acquire (v), their instrumentations are shown in Algorithms 1–
3, respectively. In each algorithm, the underlined action is the one
being instrumented. These algorithms are explained in detail below.
In Algorithm 1, for each instruction generating read action ht;read,
v;ui,CARE ﬁrst reads the value dfrom heap (Line 1). Then
the buffered value cache t(v)in thread tis fetched from t’s value
prediction cache for a comparison with d. Ifcache t(v)=d,CARE
optimistically assumes that there is no write action on vsince the last
update of cache t(v)int, and hence no log other than the program
order is kept. Otherwise, we have cache t(v),d, indicating that
the read value dmust be written by another thread. At this time,
6The claim that CARE keeps log ofhG;H;Piis for brevity of
presenting our algorithms and proofs. As shown in Section 5.1,
we store such logs compactly in each thread’s local storage in the
implementation of CARE .Algorithm 2: Instrumentation for heap (v) dgenerating w=
ht;write ;v;ui
1synchronized v
2 heap (v) d;
3 iflast(v):t,tthen
4H H[ (last(v);w);
5 last(v) w;
6cache t(v) d;
Algorithm 3: Instrumentation for acquire (v)generating `=
ht;acquire ;v;ui
1acquire (v);
2iflast(v):t,tthen
3H H[ (last(v); `);
4 last(v) `;
however, it is already too late to exactly determine which write
action is responsible for writing this value, because other threads
might write to vduring this short period. Instead of recording an
inexact dependence and value ﬁngerprint for replay-time inference
asStride [37] did, CARE logs exact read-write dependence by
redoing the read action again with the lock of vheld (Line 4). Since
in Algorithm 2, all writes to variable vare synchronized on the
monitor variable v, the second read is serialized with any write to v,
and hence its depending write action can be correctly identiﬁed and
logged inH(Line 5). Finally in Line 7–8, last(v)andcache t(v)are
correspondingly updated.
In Algorithm 2, for each instruction generating write action
ht;write ;v;ui,CARE wraps it with a synchronization block on the
monitor variable v. Log is kept only if last(v)does not happen in
thread t, because successive writes in the same thread can be inferred
by program orderP.last(v)andcache t(v)are subsequently updated
as in the instrumentation of read actions.
In Algorithm 3, for each instruction generating lock acquisition
actionht;acquire ;v;ui,CARE maintains last(v)keeping the latest
acquisition action that has successfully entered the monitor. Each
time right after vis acquired, CARE checks whether the last acqui-
sition of vis previously performed by another thread. If so, this
inter-thread dependence is kept in H.
In summary, the CARE record algorithm logs the write total order,
synchronization order and read-write dependences at the cache miss.
We discuss several remaining issues below.
First, the record algorithm does not require a speciﬁc cache orga-
nization. Using an inﬁnite cache that never discards any buffered
value is both impractical and unnecessary. Note that using a ﬁnite
cache does not affect the correctness of the replay algorithm: reduc-
ing the cache size only makes cache miss more frequent, incurring
extra synchronizations and more detailed log. We further discuss
cache organization related issues later in Section 4.1.
Second, the CARE instrumentation keeps actual orders that hap-
pen in a recorded execution. Assume that the actual execution is
E=hP;A;V;po!;sw!;sc!i. In the CARE implementation, we use
the thread identiﬁer and the sequence number in each thread to
uniquely identify an action, thuspo!=Pis conﬁrmed. Also since
every logged action is correctly synchronized if necessary, Hmust
conform the actual execution. Particularly, we havesw!H and
Hsc!guaranteed. Letrec!be all the information of HandP, i.e.,460Algorithm 4: CARE replay
1S A;T ?;
2while S,?do
3 ﬁnda2Ssuch that @a02Sanda0rec!a;
4 execute thread a:tfor one action, obtaining action a0;
5M M[ (a;a0);
6 S Snfag;T T[fag;
7 switch a.kdo
8 case read ( d heap (a0:v))
9 ifa<Gthen
10 d cache t(a0:v);
11 else
12 cache t(a0:v) d;
13 case write ( heap (a0:v) d)
14 cache t(a0:v) d;
rec!=tr(H[P ). Since bothPsc!andHsc!hold, it is clear
thatrec!sc!is a valid partial order on A.
3.3 CARE Replay
TheCARE replayer is a scheduler that controls a program’s
execution. The replay algorithm suspends a thread when it is about
to execute an instruction that can generate an action. When all
threads are suspended, the scheduler decides which thread to resume
according torec!. The algorithm also generates a mapping M.M
maps actions in a recorded execution to the ones in its corresponding
replayed execution. Mis only used for proving properties of CARE ,
and hence is not kept in the actual implementation. We formalize
the replay algorithm in Algorithm 4.
To better illustrate the intuition behind Algorithm 4, we consider
a special case that every read action rsatisﬁes r2G. In this case,
all reads trigger cache miss and every read on twill be ordered with
every write on tinrec!. Existing work [14] has shown that any linear
extension ofrec!is a valid, failure-reproductive and sequentially
consistent execution. Then for this case, Line 7–14 in the algorithm
would be totally redundant.
For those r<G, no ordering information about rother than its
predecessor and successor in thread r:tis kept. There can be inter-
leaving read action r<Gand write action waccessing the same
variable r:v=w:vsuch that neither rrec!wnorwrec!rholds. These
unordered actions make obtaining a sequentially consistent linear ex-
tension ofrec!difﬁcult. Nevertheless, CARE is still able to faithfully
restore such read values by simulating the cache behavior at replay.
Note that Line 6 in Algorithm 1 is guarded by the path condition
of v<cache t_cache t(v),d. Therefore, r<Gis sufﬁcient for
conducting cache t(v)=d. For a thread’s every read action r, mak-
ingV(r)=cache t(v)at replay essentially reproduces that thread’s
execution path. Therefore, CARE simulates the cache behavior, and
replaces the return value of every r<Gto be cache t(v).
Observing that V(r)forr<Gonly depends on r:t’s thread-local
state: either an earlier read action in G, or a write action. Ordering
information for such an action is faithfully kept inrec!. Executing
the program by the order ofrec!yields the identical cache state in
the recorded and replayed executions, and hence CARE is able to
provide value-deterministic replay.
However, this replay technique alters the semantic of the program
being executed at replay: in a valid Java implementation, any sharedmemory read should always be fetched from the heap rather than
from a thread-local cache. Although the replayed execution’s thread-
local behavior is identical with the one recorded, the total order of
these actions might not satisfy the sequential consistency criteria,
causing trouble in ﬁguring out how failures happened and what is
the root cause.
In practice, however, this issue is not that serious. With an efﬁ-
cient heuristic of variable grouping at nearly zero cost, the amount
of unordered actions in the log of CARE can be largely reduced.
We also propose another heuristic to increase the probability of syn-
thesizing a valid execution even if unordered actions exist. These
two heuristics are to be discussed in the next section. Actually,
this is exactly the key insight of the trade-off in CARE : to have
an acceptable relaxation of the replay ﬁdelity guarantee for much
lessened read synchronization, reduced log size, linear replay time,
as well as synthesizing sequentially consistent executions for all
evaluated benchmarks.
4. DISCUSSIONS
Last section gives the algorithms of CARE . We still have some re-
maining issues with CARE algorithms. First, we have not discussed
how the cache organization may impact the performance of logging.
Second, CARE keeps log for a read action only if cache miss is
encountered. This, however, is insufﬁcient for easily restoring a
sequentially consistent execution at replay. In this section, we dis-
cuss issues about CARE’s cache organization, value-deterministic
replay guarantee, sequentially consistent execution synthesis, and
performance characteristics.
4.1 Cache Organization
Cache organization may impact CARE ’s runtime overhead be-
cause every shared memory access is associated with at least one
cache query or update operation. Using a simple cache can reduce
such overhead, however, on the other hand, can incur a higher cache
miss rate. Frequent cache misses would lead to redundant read
synchronizations as well as redundant logs, which are undesirable.
Therefore, cache organization is a trade-off issue.
At one end, cache can be of no use at all: every read action triggers
a cache miss. In this case, every shared variable keeps an individual
log of all actions accessing it. This becomes exactly the algorithm
described in [18]. At another end, we can also use an ideal cache
of inﬁnite capacity that never discards any buffered value. Read
synchronizations and log size can be reduced to minimal in this
setting. However, operations on such a cache is considerably slower
than those on simple ones. The most serious issue of such a cache or-
ganization strategy is that it virtually disables the garbage collection
mechanism, which can quickly drain all memory available for long-
running programs. Therefore, we need to set up a cache organization
that satisﬁes: (1) queries and updates are efﬁcient, (2) memory con-
sumption is moderate, and (3) its cache hit rate is comparable to
that of an inﬁnite cache. At a ﬁrst glance, these requirements are
conﬂicting. Fortunately for most real-word programs, memory ac-
cesses exhibit very strong locality. A moderate-sized cache readily
brings satisfactory performance. We study cache organization and
its impact on CARE performance later in the evaluation.
4.2 Value-deterministic Replay Guarantee
As mentioned in Section 3.3, there can be read action rand
write action won the same variable that are not ordered inrec!. Re-
solving these unordered actions to obtain a sequentially consistent
execution would be very costly. Instead of determining all exact
read-write dependences, the CARE replay algorithm simulates the461cache behavior and overrides the read values from heap by values
buffered in cache at replay. To prove that such strategy provides
value-deterministic executions, we ﬁrst introduce several notations
and deﬁnitions. As deﬁned in Section 3.1, an execution is deﬁned by
a program, the actions performed, a value function, a program order,
a lock order and a total order of actions. Let a recorded execution be
E=hP;A;V;po!;sw!;sc!iwhich is sequentially consistent. CARE re-
play algorithm creates another execution E0=hP;A0;V0;po0
!;sw0
!;sc0
!i,
but not necessarily sequentially consistent. For two actions a2E
anda02E0, we deﬁne aa0indicating their equivalence by
(a:t=a0:t)^(a:k=a0:k)^(a:v=a0:v)^ V(a)=V0(a0):
For actions a;b2E, we deﬁne akbindicating that aandbare
interleaving in the logged partial orderrec!by
: arec!b^: brec!a:
For read action r2A, we deﬁne its interleaving write set W(r)by
n
w2A w:k=write^ w:v=r:v^ rkwo
:
Value-deterministic replay guarantee is reﬂected by reproducing
each thread’s local behavior in E0. In Algorithm 4, we have already
created mappingM, which associates the actions in Eto those in
E0. The replay guarantee is characterized by the following theorem:
THEOREM 1.(1) For all actions a2A,aM (a). (2) For all
pairs of actions a;b2A,apo!bif and only ifM(a)po0
!M (b). (3)
sw0
!satisﬁes the lock semantics.
PROOF .(Sketch) Prove by induction. Assume that each time at
the beginning of an iteration in Algorithm 4, (1) through (3) holds
concerning actions in T. Speciﬁcally, for all action a2T,aM (a),
program orderpo!onTis reﬂected inpo0
!, and all lock actions in T
do not violate the lock semantics.
The inductive hypothesis trivially holds before the ﬁrst iteration
because T=?.
Each time during an iteration, an action a2Sis chosen, and
the thread with identiﬁer a:tis executed for one action a0=M(a).
Hence a:t=a0:t. The one-one correspondence between threads
ensures that program orderpo!is reﬂected inpo0
!. Also note that the
state of a thread (i.e., stack, registers, thread-local storages, etc.)
is deterministic if values of read actions previously performed by
the thread are known. According to our inductive hypothesis that
for all read actions r2T,V(r)=V(M(r)), we have a:k=a0:k
anda:v=a0:v. We enumerate the action type a:kto show that the
inductive hypothesis still holds after this iteration.
Case 1: ais a lock acquisition or release action. This would
never violate the lock semantics becausesw!rec!and Line 3 in
Algorithm 4 ensures that for any actions pandqthatprec!q, we
haveM(p)rec!M (q).
Case 2: ais a write. V(a)must be equal to V0(a0)according to
the inductive hypothesis that each thread’s local state is identical in
the recorded and replayed executions.
Case 3: ais a read and a2G. Since all writes on a:vare serialized
by lock of a:v, the interleaving write set W(a)=?. Let the latest
write to a:vbefore ainrec!bew,M(w)must also be the latest
write to a:vinE0. According to the inductive hypothesis, V0(a0)=
V(M(w))=V(w). By the sequentially consistency assumption of E,
we have V(w)=V(a)and hence V(a)=V0(a0).
Case 4: ais a read and a <G. According to Line 2 of Algorithm 1,
We know that cache t(a:v)=V(a). Since a cached value dependsonly on the cache’s associated thread state, the inductive hypothesis
tells that we can easily construct the value of cache t(a:v)to be V(a),
and this value is overridden as V0(a0)=V(a).
All possible conﬁgurations are enumerated and we thus conclude
thataa0always holds at the end of each iteration. The algorithm
terminates when S=?andT=A. At this time, T=Aindicates
that our theorem is proved.
The theorem above tells that CARE is able to correctly reproduce
all read and write actions, their values and their program order in E.
Observable failures such as wrong outputs, assertion violations and
uncaught exceptions are guaranteed to be triggered in E0. Still, this
is not sufﬁcient for cyclic debugging. Value-deterministic replay
can be achieved by logging every read value of the failed thread and
feeding them in the replay. However, this gives not enough informa-
tion about how the failure has happened, especially in the case that
the failure is triggered by a sophisticated thread interleaving.
4.3 Synthesizing Sequentially Consistent Exe-
cutions
It is interesting that CARE records dependences of actions, but
only gives value-deterministic replay, while traditional order-based
approaches [13, 18] give provable replay guarantee. Intuitively,
CARE captures most of “critical” dependences for synthesizing a
sequentially consistent execution. An example is replaying data-
race-free programs. As shown in [24], for such programs, any
linear extension ofsw!is sequentially consistent. Sincesw!H ,
CARE restores sequentially consistent executions for such programs.
Another example is programs that for every variable, all write values
to it are distinct. Cache miss now becomes a sufﬁcient and necessary
condition indicating that a value being read is certainly from another
thread. For such programs, the log collected by CARE contains all
exact read-write dependences. Results in [14] suggest that CARE
would always restore sequentially consistent executions for such
programs.
The intuition above suggests that CARE would mostly replay
a sequentially consistent execution. Observing that read-write de-
pendences are hard to determine only when a speciﬁc value is back
and forth written to the same variable together with writes writing
other values in between, at the same time being fetched by a racing
memory read (as shown in Figure 1). One can reasonably expect that
such hard-to-determine memory accesses are very rare in practice
because breaking any part of this condition can make CARE easily
synthesize a sequentially consistent execution. This motivates us to
formulate an enhanced replay guarantee statement:
THEOREM 2.CARE can determine orders of interleaving read
and write actions to obtain sequentially consistent executions in
replay if for any read action r2A, either of the following two
conditions holds:
(1)8w2W(r),V(w),V(r);
(2)8w1;w22W(r),V(w1)=V(w2)=V(r).
PROOF . (Sketch) Since write total order of each variable is con-
tained inrec!, we can always ﬁnd the latest write action w`writing
variable r:vsuch that w`rec!r.
In Case (1), we manually add rrec!wfor all w2W(r). This
extra dependence conformssc!because for any w2W(r),wsc!r
would never be the case, otherwise there must be w02W(r)such
thatV(w0)=V(r)according to sequential consistency ofsc!. This
contradicts our assumption that V(w0),V(r).
In Case (2), if V(w`)=V(r),rnever violates the sequential
consistency assumption in any linear extension ofrec!. In case that462V(w`),V(r), there must exist a write action that writes V(r)be-
tween w`andrinsc!and such an action must be in W(r). Let the ear-
liest write in W(r)bewe,wesc!rmust be the case because w`sc!r.
Therefore we manually add werec!r. Since all writes in W(r)have
the same value written, the ordering issue is resolved.
The above analysis inspires us to use a heuristic rule giving those
reads r<Ghigher priority so that they can be executed early at
replay: if a pair of interleaving read and write action could both
be executed at a time, one should try to schedule the read action
ﬁrst because executing the write action might prevent the read from
returning the desired value. Therefore to synthesize a sequentially
consistent execution, CARE tries to schedule read actions interleav-
ing with other write actions as early as possible. Only in case that
the desired value of a read action is inconsistent with the one in the
heap, CARE suspends the reading thread and registers a listener on
the desired value. Immediately after the desired value is written by
another thread, the reading thread is resumed.
Another heuristic used in CARE is based on the observation that
interleaving read and write actions can be reduced by recording
more artiﬁcial dependences inrec!. This leads to a straightforward
strategy that randomly groups variables together into bundles, and
collects dependence log at a granularity of bundle. In the actual
implementation of CARE , the precedence order is represented by
sequence numbers, and variable grouping is equivalent to binding
several separate sequence numbers into a single atomic counter. In
this setting, the heuristic neither increases the log size nor combines
ﬁne-granularity locks into coarse ones.
We evaluate the usefulness of the two heuristics in Section 5.
The results show that CARE ’s practical replay guarantee is quite
satisfactory that it successfully produced sequentially consistent
executions for all of our benchmarks, including those who contain
extensive benign data races.
4.4 Performance
CARE is efﬁcient both at record and at replay. At record, a vast
majority of read actions incur little overhead as they require CARE
to perform only thread-local cache queries without synchronization.
Besides, only a small portion of all inter-thread dependences have
to be logged. Now we present a theorem and a series of facts to
explain the intuition why CARE is able to generate small log size
with low runtime overhead.
THEOREM 3.Suppose that the cache capacity is inﬁnite. If a
variable is accessed by only one thread during a time period, at
most one memory access log entry for this variable is kept.
PROOF .(Sketch) Suppose that variable vdoes not escape the
thread scope during the time period. The ﬁrst access to vmight gen-
erate a log entry because last(v)may possibly not refer to the current
thread, and cache t(v)is immediately updated. Since cache t(v)and
last(v)are not altered by other threads, none of subsequent memory
accesses needs any log.
There are also intuitive facts below explaining why CARE achieves
both log size and runtime efﬁciency. Their impacts are presented in
the following section of evaluation.
1.Memory accesses exhibit both temporal and spatial locality.
Cache precisely identiﬁes successive memory accesses hap-
pening in the same thread, reducing both the log size and
runtime overhead.
2.A write action causes at most T 1cache misses, assuming
that there are Tthreads in a program’s execution. However
in practice, such kind of “broadcasting” is quite rare: mostdata are shared among only two threads. Together with the
phenomenon of memory access locality, cache would be very
efﬁcient in reducing synchronization needed for read actions.
3.TheCARE algorithms are orthogonal to many of existing
widely-used optimization techniques such as static analysis
(e.g., escape analysis and race-free analysis), lock grouping,
etc. These techniques can be applied for further reducing the
runtime overhead and log size.
4.CARE records dependences of actions by logging sequence
numbers. These numbers typically follow speciﬁc patterns,
leading to a low-entropy log. If a log is needed to be archived,
one can further reduce the log size by compressing it with a
standard tool (e.g., gzip).
Finally, note that ﬁnding a linear extension of a partial order
can easily be done in linear time. When cache size is ﬁxed, any
operation performed on it takes only O(1)time. Moreover, the ﬁrst
heuristic requires only value-listener registration which can also be
implemented by hashing in O(1)time. It is thus straightforward that
the time complexity of CARE replay algorithm is linear of the trace
size.
5. EVALUATION
In this section, we present our CARE implementation and evalu-
ate it with real-world benchmark programs.
5.1 Implementation
We implemented CARE on the basis of our DPAC tool [21],
which is an encapsulation of JVM Tool Interface [2] and ASM byte-
code transformation libraries [1]. CARE instruments Java bytecode
at class loading to collect log at record and to insert breakpoints at
replay.
According to Section 3, CARE virtually logshG;H;Piby main-
taining each variable’s access sequence numbers. An action aof
sequence number smeans that it is the s-th action performed on
variable a:v. We store such sequence numbers compactly in each
thread’s local storage: each time when thread tis about to log a
dependence on variable v,v’s sequence number is increased and
logged in t’s local log. Non-conﬂicting actions are logged in paral-
lel. Each thread’s log is a list of tuples hc;si. Each tuple denotes
a logged action of sequence number s, with cunlogged actions
skipped before. Our variable grouping heuristic combines many sep-
arate sequence numbers into a single atomic counter. Since updates
to sequence numbers are synchronized by CARE ’s instrumentation,
our atomic counters can guarantee to restore actual orders for these
separate variables.
At replay, the instrumented program generates a breakpoint each
time before an action is actually executed. Breakpoint suspends
the current thread. According to Algorithm 4, when all threads are
suspended, our scheduler selects an eligible thread to execute for
one action. If multiple threads are eligible, the heuristic of action
prioritization favors such a thread whose next action ris read and
cache r:t(r:v)is identical to the value of r:vin the heap.
We also implemented state-of-the-art deterministic replay work
LEAP [18] on the same base as our CARE for comparison. We make
sure that the low-level implementation and optimization settings are
both identical for comparison fairness. For Stride [37], we did not
implement it for comparison because it contains many optimizations
yielding very impressive evaluation results, but not available for us.
We tried an alternative way by making LEAP as the normalized
line to connect the evaluation results of CARE andStride , in the
sense that LEAP andStride are from the same authors and they
have made careful comparisons between them in [37].463Table 1: Comparison of CARE andLEAP under benchmark programs
BenchmarkCARE LEAP [18]
Overhead ()Log Size (/s) Unordered (#) Resolved (?) Overhead ()Log Size (/s)
Avrora 1.52 2.18MB 23K Y 9.48 24.3MB
Batik 1.49 1.51KB 0 Y 3.77 2.32KB
H2 18.5 24.2MB 0 Y 62.8 27.4MB
Lusearch 3.41 6.53MB 0 Y 9.01 46.0MB
Sunﬂow 64.9 886MB 0 Y 389 6029MB
Tomcat 4.76 7.80MB 15 Y 11.9 23.5MB
Xalan 7.18 13.6MB 0 Y 12.2 143MB
Tsp 2.79 1.84MB 0 Y 111 570MB
Moldyn 11.9 24.1MB 0 Y 50.5 303MB
5.2 Evaluation Results
5.2.1 Experimental Settings
Our experiments were conducted on a Dell PowerEdge server
running Linux Kernel 3.2 with dual 6-core Intel Xeon E5645 pro-
cessors and 48GB memory. We disabled the Turbo Boost and
the Hyper-threading technologies to alleviate unpredictable perfor-
mance thrashing.
Following existing replay work [18, 37], we chose a wide range
of benchmarks from Dacapo suite, including concurrent programs
on network simulation ( Avrora ), vector imaging ( Batik ), database
transactions ( H2), text search ( Lusearch ), graphics rendering ( Sun-
ﬂow), web server ( Tomcat ) and document processing ( Xalan ). We
also chose two scientiﬁc benchmarks used in [37]7:Tsp solving the
travelling salesperson problem and Moldyn simulating molecular
dynamics. We used available default settings for all benchmarks in
our experiments.
In the following, we ﬁrst validate CARE ’s main claims that it
can reduce the record-time overhead and log size, at the same time
synthesized valid executions at replay. We then study speciﬁc details
ofCARE :
1.How does cache organization impact CARE ’s runtime over-
head and log size?
2.How does variable-grouping heuristic impact CARE ’s run-
time overhead?
5.2.2 Runtime Overhead and Log Size Reduction
Our evaluation results of CARE andLEAP are presented in
Table 1. Columns 2 and 6 present the runtime overhead of CARE
andLEAP , and Columns 3 and 7 present their log size. All runtime
overhead and log size data are normalized based on the running
time of non-instrumented executions (i.e., normalized log size per
second is the total log size divided by the execution time of a non-
instrumented execution). Columns 4 and 5 present evaluation results
of our heuristics for synthesizing sequentially consistent executions.
The amount of unordered conﬂicting memory access pairs in the log
is shown in Column 4, while results in Column 5 indicate whether
CARE successfully resolved these ordering issues for synthesizing
sequentially consistent executions (Y denotes “successful resolve”).
Regarding the record cost for the Dacapo suite benchmarks,
CARE exhibited on average 2.6 and 4.9reduction on runtime
overhead and log size, respectively over LEAP . For scientiﬁc bench-
mark Tsp,CARE was even 40faster and incurred 300 smaller
7Derby ,SpecJBB andICE evaluated in [37] were not included in
our evaluation because they are neither available to us nor contain
available default settings.Table 2: Comparison of CARE andStride with normalized
values
BenchmarkCARE Stride [37]
Overhead Log Size Overhead Log Size
Avrora 16.0% 8.97% 54.0% 36.4%
Batik 39.5% 65.1% 50.0% 34.9%
H2 29.5% 88.3% 29.8% 23.9%
Lusearch 37.9% 14.2% 34.7% 30.0%
Sunﬂow 16.7% 14.7% 38.5% 9.17%
Tomcat 40.0% 33.2% 64.3% 34.6%
Xalan 59.2% 9.52% 19.0% 23.1%
Tsp 2.51% 0.32% 9.36% 7.18%
Moldyn 23.8% 7.94% 1.32% 0.71%
log. This is because threads in Tsp frequently read from shared
memory without any lock protection. LEAP had to serialize all
these accesses, while our CARE did not have to because cache hit is
almost always the case. Similar situation occurred to Moldyn , and
CARE also outperformed LEAP .
We also observed that CARE ’s heuristics worked well in syn-
thesizing sequentially consistent executions because the evaluated
benchmarks are almost correctly synchronized, and there were not
many actions left unordered.
As mentioned earlier, we indirectly compare our CARE with
Stride [37] based on LEAP [18] by aligning two LEAP imple-
mentations’ data. We had to do so as two LEAP implementations
performed quite differently for different benchmarks for unknown
reasons. For benchmark Avrora ,Lusearch andXalan , ourLEAP
implementation incurred much smaller runtime overhead than re-
ported in [37]. On the contrary, for Tomcat ,H2andSunﬂow ,
LEAP ’s log size reported in [37] was much smaller than ours. We
conjecture that this is due to the optimizations used in [37], which
can beneﬁt some programs but may harm the others. After LEAP
data alignment ( LEAP data are all normalized to 1), we obtain re-
sults in Table 2. According to absolute comparisons (in Table 1
and in [37]) and relative comparisons (in Table 2), we can safely
conclude that the current CARE andStride implementations have
comparable record costs. For some benchmarks, CARE outper-
formed Stride but for some other benchmarks, Stride beat our
CARE . Nevertheless, we note that Stride has done extensive engi-
neering optimizations like escape analysis (introduced by one whole
page in [37]) to additionally reduce runtime overhead and log size.
Therefore, we believe that our CARE still has the potential to be
further improved by additional engineering efforts.46432 64 128 256 512 1024 16384345
Number of Cache SetsRuntime Overhead ( )2-way
4-way
8-way
16-way
(a)Study of runtime overhead against cache organization32 64 128 256 512 1024 16384051015
Number of Cache SetsLog Size (MB/s)2-way
4-way
8-way
16-way
(b)Study of log size against cache organization1 2 4 8 160:90:9511:051:1
Number of Group(s)Normalized Runtime Overhead ( )Avrora
Tomcat
Tsp
Moldyn
(c)Study of runtime overhead against variable grouping
Figure 3: Impacts of Cache Organization and Variable Grouping
5.2.3 Impact of Cache Organization
To study the impact of cache organization, we studied software-
implemented k-way set associative cache with nsets (from 2 sets
to 16 sets) using the widely-used LRU strategy for replacement.
We conducted the study on the Tsp benchmark because it contains
frequent racing memory reads, realizing that cache hit can largely
affect the performance of such benchmarks. Figures 3(a) and 3(b)
show the study results. We observe that increasing cache size can
greatly reduce the runtime overhead and log size when the cache
size is small (e.g., less than 512 sets). When the cache is larger than
a moderate size (e.g., 1024 sets), the improvement becomes less
signiﬁcant and such a moderate size can be easily deployed on a
commodity computer. Studies of other benchmarks also give similar
results, and we therefore omit their details. From these results, we
conclude that using a moderate-sized cache is already sufﬁcient for
reducing the record cost in CARE .
5.2.4 Impact of Variable Grouping
As mentioned earlier, our variable-grouping heuristic succeeded
in synthesizing sequentially consistent executions, but one may
wonder its accompanied cost. According to [37], a Global approach
that serializes all write actions can outperform LEAP and even has
comparable performance with Stride in many evaluated benchmarks.
This result gives a clue in concluding that our heuristic could be
efﬁcient in practice, because even the most aggressive variable
grouping strategy that groups all variables into a single bundle still
allows write actions to different variables to be executed in parallel,
which is much more efﬁcient than Global .
We study the impact of variable grouping in Figure 3(c) and
observe from it that the cost of variable grouping is almost negligible
for our four benchmarks, as compared to the setting of no variable
grouping. This is mainly because CARE generates log only at
cache miss. In a commodity processor, executing millions of atomic
operations only requires milliseconds of time, and its out-of-order
execution mechanism does not even suspend a thread if it just waits
for an atomic operation to complete. Therefore, we can safely use
the most aggressive variable grouping strategy, i.e, grouping all
sequence numbers into a single atomic counter, to achieve a higher
probability of reproducing sequentially consistent executions. In
fact, we use such a strategy to produce data in Table 1.
6. RELATED WORK
Deterministic replay tools can either be implemented purely at
an application level, within a virtual machine monitor, or evenwith assistance of customized hardware [4, 5, 9, 16]. CARE is an
application-level and software-only work, but adopts experiences
from approaches of other categories.
In a uni-processor system, deterministically replaying an execu-
tion is readily solved because logging thread preemptions and ex-
ternal inputs essentially eliminates non-determinism for replay [10,
12]. However, in a multi-processor setting, racing memory accesses
make deterministic replay much more challenging: diverse execu-
tion paths emerge from interleaving data races. According to the
fundamental approach of taming non-deterministic racy memory
accesses, existing pieces of work can be roughly categorized into
search-based ones and order-based ones.
Search-based work [3, 19, 29, 33, 36] takes a different fundamen-
tal approach than CARE does, which logs only selective information
at runtime and synthesizes a valid execution later at replay. Logging
strategies for search-based work can be very optimistic such that
runtime overhead and log size can be largely reduced. Aggressive
log reduction, on the other hand, makes ﬁnding a valid execution
computationally intractable. Search-based work typically only gives
best-effort replay guarantee, or the success of replay depends on
powerful state space exploration engine such as an SMT solver.
In contrast, order-based work8[9, 13, 18, 35, 37] carefully keeps
the actual happens-before order of executed actions, obtaining a
partial order over these actions. Failure reproduction is generally
achieved by executing a program in guidance of the topologically
sorted order of the logged actions of this program. To distinguish the
precedence of variable accesses, order-based work has to instrument
a program with extra synchronizations serializing racing memory
accesses. CARE also belongs to this category.
Despite the fact that all order-based work shares a similar idea of
enforcing CREW semantics and recording memory access orders,
there are still subtle trade-offs for reducing runtime overhead, log
size and replay cost. To the best of our knowledge, CARE is the
ﬁrst order-based deterministic replay technique striking the balance
that both runtime overhead and log size are reduced, replay is done
at linear time, and replay ﬁdelity is only slightly weakened.
In order-based deterministic replay, logs for successive thread-
local memory accesses can be combined into a single entry, thus
reducing the log size. Such thread locality can be detected by a
value prediction cache, as used in iDNA [8] and Stride [37]. CARE
further observed the cache’s ability of ﬁnding inexact causal depen-
8Stride [37] considers itself search-based, but we classify it as
order-based because it records inexact read-write dependences and
perform replay by topologically sorting the recorded actions.465dences between memory accesses. Compared with LEAP [18], its
core algorithm can be considered as a special case of CARE that trig-
gers cache miss at every memory read. The technique of refetching
read value at cache miss in CARE is similar with the one presented
inReEmu [9].ReEmu uses atomic counters and memory fences to
guard shared memory reads, which incur implicit synchronizations.
In contrast, CARE ’s cache requires no extra inter-processor syn-
chronization at cache hit. In reducing synchronizations, one piece
of ingenious work is Stride which eliminates all read synchroniza-
tions by logging inexact version numbers, and ensures strong replay
guarantee. Stride tackles the problem of runtime overhead, but not
log size. Inference of exact read-write dependences requires log-
ging value ﬁngerprint for every read, and this substantially increases
the log size and suffers from hash collisions. CARE logs no such
value and hence does not have such issues. Also note that extra
synchronization of CARE is within a small constant factor than that
inStride in practice, because CARE needs synchronized read only
when cache miss is encountered.
All these order-based deterministic replay techniques have attrac-
tive replay guarantee, but with less satisfactory record-time overhead.
To reduce this overhead, static determinism analysis, transitive re-
duction and domain-speciﬁc optimizations are proposed:
1.Examining non-racing memory accesses unnecessarily slows
down the instrumented execution. Runtime overhead can be
greatly reduced if these accesses on these variables are not in-
strumented, and this is typically achieved by a static program
analysis [18, 37]. CARE is orthogonal to these deterministic
analyses such as escape analysis and lock-set analysis. In
extreme end of determinism analysis, Chimera [25] statically
converts racy programs to equivalent race-free ones by adding
extra synchronizations. Compared with Chimera ,CARE
tries to make racing reads as parallel as possible. For pro-
grams with intensive intended racing reads of shared variables,
CARE would have less runtime overhead.
2.The key idea of order-based deterministic replay is logging
causal dependences between read and write actions. However,
logging all of them is of course not a minimal setting. The
problem of transitive reduction is addressed in [20, 26, 28,
34]. Actually, the cache in CARE also does an approximate
transitive reduction with very low runtime overhead, remov-
ing some redundant logs. We can adopt existing transitive
reduction techniques for even smaller logs.
3.For speciﬁc application domains, performance of determin-
istic replay can be further tuned. For example, replaying
Android applications with GUI interactions is studied in [15].
Debugging non-determinism caused by external inputs in li-
braries is discussed in [6]. They are out of our scope and thus
not discussed further.
To replay concurrent executions, one can also adopt deterministic
execution [11] that ensures a determinsitic execution environment.
However, for general applications running on generic operating
systems, eliminating all non-determinism is essentially too costly in
the absence of customized hardware’s assistance [7, 17].
Finally, deterministic replay technology is the cornerstone of
numerous testing and debugging tools for concurrent programs.
Examples include cyclic debugging [23], data race detection [30,
31], deadlock prediction [22], to name but a few. We believe that
improvements in deterministic replay can considerably beneﬁt these
kinds of work.
7. CONCLUSION
In this paper we present CARE , a cache guided deterministic
replay technique. By utilizing cache miss as the indicator of record-ing necessary memory access orders, CARE reduces a majority of
additional synchronizations for read actions, runtime overhead and
log size compared with conventional techniques, while still offering
reasonable replay guarantee for debugging. Our experimental results
show that CARE ’s generated log can be several orders of magnitude
smaller than state-of-the-art order-based replay techniques.
To the best of our knowledge, our work is the ﬁrst one trying to
trade slightly weakened replay guarantee for much reduced record
cost in deterministic replay. We also note that this trade-off, though
might potentially create invalid traces at replay, works ﬁne in prac-
tice with the aids of our two replay heuristics. Hence it would be
interesting to see whether it is possible to further extend this central
trade-off idea in CARE to more practical systems (e.g., systems
with relaxed memory models).
8. ACKNOWLEDGMENTS
This work was supported in part by National High-tech R&D
863 Program (2013AA01A213) and National Natural Science Foun-
dation (61100038, 91318301, 61321491, 61361120097) of China.
Chang Xu was also partially supported by Program for New Century
Excellent Talents in University, China (NCET-10-0486).
9. REFERENCES
[1]ASM toolkit for bytecode manipulation. http://asm.ow2.
org/ .
[2]JVM tool interface. http://docs.oracle.com/
javase/7/docs/platform/jvmti/jvmti.html .
[3]G. Altekar and I. Stoica. ODR: output-deterministic replay
for multicore debugging. In Proceedings of the ACM SIGOPS
22nd symposium on Operating systems principles , SOSP, pp.
193–206, 2009.
[4]D. F. Bacon and S. C. Goldstein. Hardware-assisted replay
of multiprocessor programs. In Proceedings of the 1991
ACM/ONR workshop on Parallel and distributed debugging ,
PADD, pp. 194–206, 1991.
[5]A. Basu, J. Bobba, and M. D. Hill. Karma: Scalable deter-
ministic record-replay. In Proceedings of the international
conference on Supercomputing , ICS, pp. 359–368, 2011.
[6]J. Bell, N. Sarda, and G. Kaiser. Chronicler: Lightweight
recording to reproduce ﬁeld failures. In Proceedings of the
2013 International Conference on Software Engineering ,
ICSE, pp. 362–371, 2013.
[7]T. Bergan, O. Anderson, J. Devietti, L. Ceze, and D. Grossman.
CoreDet: a compiler and runtime system for deterministic mul-
tithreaded execution. In Proceedings of the ﬁfteenth edition of
ASPLOS on Architectural support for programming languages
and operating systems , ASPLOS, pp. 53–64, 2010.
[8]S. Bhansali, W.-K. Chen, S. de Jong, A. Edwards, R. Mur-
ray, M. Drini ´c, D. Miho ˇcka, and J. Chau. Framework for
instruction-level tracing and analysis of program executions.
InProceedings of the 2nd international conference on Virtual
execution environments , VEE, pp. 154–163, 2006.
[9]Y . Chen and H. Chen. Scalable deterministic replay in a par-
allel full-system emulator. In Proceedings of the 18th ACM
SIGPLAN symposium on Principles and practice of parallel
programming , PPoPP, pp. 207–218, 2013.
[10] A. Cheung, A. Solar-Lezama, and S. Madden. Partial replay
of long-running applications. In Proceedings of the 19th ACM
SIGSOFT symposium and the 13th European conference on
Foundations of software engineering , ESEC/FSE, pp. 135–145,
2011.466[11] J. Devietti, B. Lucia, L. Ceze, and M. Oskin. DMP: deter-
ministic shared memory multiprocessing. In Proceedings of
the 14th international conference on Architectural support for
programming languages and operating systems , ASPLOS, pp.
85–96, 2009.
[12] G. W. Dunlap, S. T. King, S. Cinar, M. A. Basrai, and P. M.
Chen. ReVirt: enabling intrusion analysis through virtual-
machine logging and replay. In Proceedings of the 5th sympo-
sium on Operating systems design and implementation , OSDI,
pp. 211–224, 2002.
[13] G. W. Dunlap, D. G. Lucchetti, M. A. Fetterman, and P. M.
Chen. Execution replay of multiprocessor virtual machines. In
Proceedings of the fourth ACM SIGPLAN/SIGOPS interna-
tional conference on Virtual execution environments , VEE, pp.
121–130, 2008.
[14] P. B. Gibbons and E. Korach. Testing shared memories. SIAM
J. Comput. , 26(4):1208–1244, Aug. 1997.
[15] L. Gomez, I. Neamtiu, T. Azim, and T. Millstein. RERAN:
Timing- and touch-sensitive record and replay for android. In
Proceedings of the 2013 International Conference on Software
Engineering , ICSE, pp. 72–81, 2013.
[16] N. Honarmand, N. Dautenhahn, J. Torrellas, S. T. King,
G. Pokam, and C. Pereira. Cyrus: Unintrusive application-
level record-replay for replay parallelism. In Proceedings of
the eighteenth international conference on Architectural sup-
port for programming languages and operating systems , ASP-
LOS, pp. 193–206, 2013.
[17] D. Hower, P. Dudnik, M. Hill, and D. Wood. Calvin: De-
terministic or not? Free will to choose. In 2011 IEEE 17th
International Symposium on High Performance Computer Ar-
chitecture , HPCA, pp. 333–334, 2011.
[18] J. Huang, P. Liu, and C. Zhang. LEAP: Lightweight determin-
istic multi-processor replay of concurrent Java programs. In
Proceedings of the eighteenth ACM SIGSOFT international
symposium on Foundations of software engineering , FSE, pp.
207–216, 2010.
[19] J. Huang, C. Zhang, and J. Dolby. CLAP: Recording local
executions to reproduce concurrency failures. In Proceedings
of the 34th ACM SIGPLAN conference on Programming lan-
guage design and implementation , PLDI, pp. 141–152, 2013.
[20] N. Jalbert and K. Sen. A trace simpliﬁcation technique for
effective debugging of concurrent programs. In Proceedings
of the eighteenth ACM SIGSOFT international symposium on
Foundations of software engineering , FSE, pp. 57–66, 2010.
[21] Y . Jiang, C. Xu, and X. Ma. DPAC: An infrastructure for
dynamic program analysis of concurrency Java programs. In
Proceedings of the 2013 Middleware Doctoral Symposium ,
2013.
[22] P. Joshi, C.-S. Park, K. Sen, and M. Naik. A randomized dy-
namic program analysis technique for detecting real deadlocks.
InProceedings of the 2009 ACM SIGPLAN conference on
Programming language design and implementation , PLDI, pp.
110–120, 2009.
[23] S. T. King, G. W. Dunlap, and P. M. Chen. Debugging operat-
ing systems with time-traveling virtual machines. In Proceed-
ings of the annual conference on USENIX Annual Technical
Conference , ATEC, 2005.[24] T. LeBlanc and J. Mellor-Crummey. Debugging parallel pro-
grams with instant replay. Computers, IEEE Transactions on ,
C-36(4):471–482, 1987.
[25] D. Lee, P. M. Chen, J. Flinn, and S. Narayanasamy. Chimera:
Hybrid program analysis for determinism. In Proceedings of
the 33rd ACM SIGPLAN conference on Programming Lan-
guage Design and Implementation , PLDI, pp. 463–474, 2012.
[26] K. H. Lee, Y . Zheng, N. Sumner, and X. Zhang. Toward gener-
ating reducible replay logs. In Proceedings of the 32nd ACM
SIGPLAN conference on Programming language design and
implementation , PLDI, pp. 246–257, 2011.
[27] J. Manson, W. Pugh, and S. V . Adve. The Java memory model.
InProceedings of the 32nd ACM SIGPLAN-SIGACT sympo-
sium on Principles of programming languages , POPL, pp.
378–391, 2005.
[28] R. H. B. Netzer. Optimal tracing and replay for debugging
shared-memory parallel programs. In Proceedings of the 1993
ACM/ONR workshop on Parallel and distributed debugging ,
PADD, pp. 1–11, 1993.
[29] S. Park, Y . Zhou, W. Xiong, Z. Yin, R. Kaushik, K. H. Lee,
and S. Lu. PRES: probabilistic replay with execution sketching
on multiprocessors. In Proceedings of the ACM SIGOPS 22nd
symposium on Operating systems principles , SOSP, pp. 177–
192, 2009.
[30] K. Sen. Race directed random testing of concurrent programs.
InProceedings of the 2008 ACM SIGPLAN conference on
Programming language design and implementation , PLDI, pp.
11–21, 2008.
[31] Y . Smaragdakis, J. Evans, C. Sadowski, J. Yi, and C. Flana-
gan. Sound predictive race detection in polynomial time. In
Proceedings of the 39th annual ACM SIGPLAN-SIGACT sym-
posium on Principles of programming languages , POPL, pp.
387–400, 2012.
[32] J. Tucek, S. Lu, C. Huang, S. Xanthos, and Y . Zhou. Triage: Di-
agnosing production run failures at the user’s site. In Proceed-
ings of twenty-ﬁrst ACM SIGOPS symposium on Operating
systems principles , SOSP, pp. 131–144, 2007.
[33] D. Weeratunge, X. Zhang, and S. Jagannathan. Analyzing
multicore dumps to facilitate concurrency bug reproduction.
InProceedings of the ﬁfteenth edition of ASPLOS on Archi-
tectural support for programming languages and operating
systems , ASPLOS, pp. 155–166, 2010.
[34] M. Xu, M. D. Hill, and R. Bodik. A regulated transitive reduc-
tion (RTR) for longer memory race recording. In Proceedings
of the 12th international conference on Architectural support
for programming languages and operating systems , ASPLOS,
pp. 49–60, 2006.
[35] Z. Yang, M. Yang, L. Xu, H. Chen, and B. Zang. ORDER:
Object centric deterministic replay for java. In Proceedings
of the 2011 USENIX conference on USENIX annual technical
conference , ATEC, pp. 30–43, 2011.
[36] C. Zamﬁr and G. Candea. Execution synthesis: A technique
for automated software debugging. In Proceedings of the 5th
European conference on Computer systems , EuroSys, pp. 321–
334, 2010.
[37] J. Zhou, X. Xiao, and C. Zhang. Stride: Search-based deter-
ministic replay in polynomial time via bounded linkage. In
Proceedings of the 2012 International Conference on Software
Engineering , ICSE, pp. 892–902, 2012.467