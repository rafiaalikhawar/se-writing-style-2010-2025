Practical Static Analysis of JavaScript Applications
in the Presence of Frameworks and Libraries
Magnus Madsen
Aarhus University, DenmarkBenjamin Livshits
Microsoft Research, USAMichael Fanning
Microsoft Corporation, USA
ABSTRACT
JavaScript is a language that is widely-used for both web-
based and standalone applications such as those in the Win-
dows 8 operating system. Analysis of JavaScript has long
been known to be challenging due to the language's dynamic
nature. On top of that, most JavaScript applications rely on
large and complex libraries and frameworks, often written
in a combination of JavaScript and native code such as C
and C++. Stubs have been commonly employed as a par-
tial specication mechanism to address the library problem;
alas, they are tedious and error-prone.
However, the manner in which library code is used within
applications often sheds light on what library APIs return
or pass into callbacks declared within the application. In
this paper, we propose a technique which combines pointer
analysis with a novel use analysis to handle many challenges
posed by large JavaScript libraries. Our techniques have
been implemented and empirically validated on a set of 25
Windows 8 JavaScript applications, averaging 1,587 lines
of code, together with about 30,000 lines of library code,
demonstrating a combination of scalability and precision.
Categories and Subject Descriptors
F.3.2 [ Semantics of Programming Languages ] Program
analysis
General Terms
Algorithms, Languages
Keywords
Points-to analysis, use analysis, JavaScript, libraries
1. INTRODUCTION
While JavaScript is increasingly used for both web and
server-side programming, it is a challenging language for
static analysis due to its highly dynamic nature. Recently
much attention has been directed at handling the peculiar
features of JavaScript in pointer analysis [13, 14, 7], data
ow analysis [18, 17], and type systems [29, 28].
The majority of work thus far has largely ignored the fact
that JavaScript programs usually execute in a rich execution
environment. Indeed, Web applications run in a browser-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ESEC/FSE ‚Äô13, August 18‚Äì26, 2013, Saint Petersburg, Russia
Copyright 13 ACM 978-1-4503-2237-9/13/08 ...$5.00.based environment interacting with the page through the
extensive HTML DOM API or sophisticated libraries such
as jQuery. Similarly, node:jsapplications run inside an ap-
plication server. Finally, JavaScript applications in the Win-
dows 8 OS, which are targets of the analysis in this paper,
call into the underlying OS through the Windows 8 runtime.
In-depth static analysis of these application hinges on our
understanding of libraries and frameworks.
Unfortunately, environment libraries such as the HTML
DOM and the Windows 8 runtime lack a full JavaScript
implementation, relying on underlying C or C++, which
is outside of what a JavaScript static analyzers can reason
about. Popular libraries, such as jQuery, have a JavaScript
implementation, but are hard to reason about due to their
heavy use of reective JavaScript features, such as eval,
computed properties, runtime addition of elds, etc. The
standard solution to overcome these problems is to write
partial JavaScript implementations (also known as stubs )
to partially model library API functionality. Unfortunately,
writing stubs is tedious, time-consuming, and error-prone.
Use analysis: The key technical insight that motivates this
paper is that observing uses of library functionality within
application code can shed much light on the structure and
functionality of (unavailable) library code. By way of anal-
ogy, observing the eect on surrounding planets and stars
can provide a way to estimate the mass of an (invisible) black
hole. This paper describes how to overcome the challenges
described above using an inference approach that combines
pointer analysis and use analysis to recover necessary infor-
mation about the structure of objects returned from libraries
and passed into callbacks declared within the application.
Example 1 We open with an example illustrating several of
the challenges posed by libraries, and how our technique can
overcome these challenges. The code below is representative
of much DOM-manipulating code that we see in JavaScript
applications.
var canvas = document . querySelector ("# leftcol . logo ");
var context = canvas . getContext ("2d");
context . fillRect (20 , 20, c. width / 2, c. height / 2);
context . strokeRect (0, 0, c.width , c. height );
In this example, the call to querySelector retrieves
a<canvas> element represented at runtime by an
HTMLCanvasElement object; the context variable points to
aCanvasRenderingContext2D object at runtime. context
is then used for drawing both a lled and stroked rectangle
on the canvas . Since these objects and functions are imple-
mented as part of the browser API and HTML DOM, no
JavaScript implementation that accurately represents themPermission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ESEC/FSE‚Äô13 , August 18‚Äì26, 2013, Saint Petersburg, Russia
Copyright 2013 ACM 978-1-4503-2237-9/13/08...$15.00
http://dx.doi.org/10.1145/2491411.2491417
499
is readily available. Furthermore, note that the return value
of the querySelector call depends on the CSS expression
provided as a string parameter, which is dicult to reason
about without an accurate model of the underlying HTML
page. There are two common approaches for attempting to
analyze this code statically:
model querySelector as (unsoundly) returning a refer-
ence to HTMLElement :prototype . This approach suers
from a simple problem: HTMLElement :prototype does not
dene getContext , so this call will still be unresolved.
This is the approach used for auto-completion suggestions
in the Eclipse IDE.
model querySelector as returning any HTML element
within the underlying page. While this approach correctly
includes the canvas element, it suers from returning ele-
ments on which getContext is undened. While previous
work [17] has focused on tracking elements based on their
ids and types, extending this to tracking CSS selector ex-
pressions is non-trivial.
Neither solution is really acceptable. In contrast, our
analysis will use pointer information to resolve the call
todocument :querySelector and then apply use analysis
to discover that the returned object must have at least
three properties: getContext ,width , and height , assum-
ing the program runs correctly. Looking through the static
heap approximation, only the HTMLCanvasElement has all
three properties. Assuming we have the whole program
available for analysis, this must be the object returned by
querySelector . From here on, pointer analysis can resolve
the remaining calls to fillRect and strokeRect .2
1.1 Applications of the Analysis
The idea of combining pointer analysis and use analysis
turns out to be powerful and useful in a variety of settings:
Call graph discovery: Knowledge about the call graph
is useful for a range of analysis tools. Unlike C or Java, in
JavaScript call graphs are surprisingly dicult to construct.
Reasons for this include reection, passing anonymous func-
tion closures around the program, and lack of static typing,
combined with an ad-hoc namespace creation discipline.
API surface discovery: Knowing the portion of an im-
portant library such as WinRT utilized by an application is
useful for determining the application's attack perimeter. In
aggregate, running this analysis against many applications
can provide general API use statistics for a library helpful for
maintaining it (e.g., by identifying APIs that are commonly
used and which may therefore be undesirable to deprecate).
Capability analysis The Windows 8 application model
involves a manifest that requires capabilities such as
camera access orgps location access to be statically de-
clared. However, in practice, because developers tend to
over-provision capabilities in the manifest [15], static analy-
sis is a useful tool for inferring capabilities that are actually
needed [10].
Automatic stub creation Our analysis technique can cre-
ate stubs from scratch or identify gaps in a given stub collec-
tion. When aggregated across a range of application, over
time this leads to an enhanced library of stubs useful for
analysis and documentation.
Auto-complete Auto-complete or code completion has tra-
ditionally been a challenge for JavaScript. Our analysismakes signicant strides in the direction of better auto-
complete, without resorting to code execution.
Throughout this paper, our emphasis is on providing a
practically useful analysis, favoring practical utility even if
it occasionally means sacricing soundness. We further ex-
plain the soundness trade-os in Section 2.5.
Contributions: We make the following contributions:
We propose a strategy for analyzing JavaScript code
in the presence of large complex libraries, often imple-
mented in other languages. As a key technical contri-
bution, our analysis combines pointer analysis with a
novel use analysis that captures how objects returned
by and passed into libraries are used within application
code, without analyzing library code.
Our analysis is declarative, expressed as a collection of
Datalog inference rules, allowing for easy maintenance,
porting, and modication.
Our techniques in this paper include partial andfullit-
erative analysis, the former depending on the existence
of stubs, the latter analyzing the application without
any stubs or library specications.
Our analysis is useful for a variety of applications. Use
analysis improves points-to results, thereby improving
call graph resolution and enabling other important ap-
plications such as inferring structured object types, in-
teractive auto-completion, and API use discovery.
We experimentally evaluate our techniques based on
a suite of 25 Windows 8 JavaScript applications,
averaging 1,587 line of code, in combination with
about 30,000 lines of partial stubs. When using our
analysis for call graph resolution, a highly non-trivial
task for JavaScript, the median percentage of resolved
calls sites increases from 71.5% to 81.5% with partial
inference.
Our analysis is immediately eective in two practical
settings. First, our analysis nds about twice as many
WinRT API calls compared to a na ve pattern-based
analysis. Second, in our auto-completion case study we
out-perform four major widely-used JavaScript IDEs
in terms of the quality of auto-complete suggestions.
2. ANALYSIS CHALLENGES
Before we proceed further, we summarize the challenges
faced by any static analysis tool when trying to analyze
JavaScript applications that depend on libraries.
2.1 Whole Program Analysis
Whole program analysis in JavaScript has long been
known to be problematic [14, 7]. Indeed, libraries such as
the Browser API, the HTML DOM, node:jsand the Win-
dows 8 API are all implemented in native languages such
as C and C++; these implementations are therefore often
simply unavailable to static analysis. Since no JavaScript
implementation exists, static analysis tool authors are often
forced to create stubs. This, however, brings in the issues
of stub completeness as well as development costs. Finally,
JavaScript code frequently uses dynamic code loading, re-
quiring static analysis at runtime [14], further complicating
whole-program analysis.5002.2 Underlying Libraries & Frameworks
While analyzing code that relies on rich libraries has
been recognized as a challenge for languages such as Java,
JavaScript presents a set of unique issues.
Complexity: Even if the application code is well-behaved
and amenable to analysis, complex JavaScript applications
frequently use libraries such as jQuery and Prototype. While
these are implemented in JavaScript, they present their own
challenges because of extensive use of reection such as eval
or computed property names. Recent work has made some
progress towards understanding and handling eval [25, 16],
but these approaches are still fairly limited and do not fully
handle all the challenges inherent to large applications.
Scale of libraries: Underlying libraries and frameworks
are often very large. In the case of Windows 8 applications,
they are around 30,000 lines of code, compared to 1,587
for applications on average. Requiring them to be analyzed
every time an application is subjected to analysis results in
excessively long running times for the static analyzer.
2.3 Tracking Interprocedural Flow
Points-to analysis eectively embeds an analysis of inter-
procedural data ow to model how data is copied across the
program. However, properly modeling interprocedural data
ow is a formidable task.
Containers: The use of arrays, lists, maps, and other
complex data structures frequently leads to conated data
ow in static analysis; an example of this is when anal-
ysis is not able to statically dierentiate distinct indices
of an array. This problem is exacerbated in JavaScript
because of excessive use of the DOM, which can be ad-
dressed both directly and through tree pointer traver-
sal. For instance document :body is a direct lookup,
whereas document :getElementsByName ("body" )[0] is an in-
direct lookup. Such indirect lookups present special chal-
lenges for static analyses because they require explicit track-
ing of the association between lookup keys and their values.
This problem quickly becomes unmanageable when CSS se-
lector expressions are considered (e.g., the jQuery $()se-
lector function), as this would require the static analysis to
reason about the tree structure of the page.
Reective calls: Another typical challenge of analyzing
JavaScript code stems from reective calls into application
code being \invisible" [21]. As a result, callbacks within the
application invoked reectively will have no actuals linked
to their formal parameters, leading to variables within these
callback functions having empty points-to sets.
2.4 Informal Analysis Assumptions
Here we informally state some analysis assumptions. Our
analysis relies on property names to resolve values being
either a) returned by library functions or b) passed as argu-
ments to event handlers. Thus, for our analysis to operate
properly, it is important that property names are static. In
other words, we require that objects being passed to and
from the library exhibit class-like behavior:
Properties are not dynamically added or removed after
the object has been fully initialized.
The presence of a property does not rely on program
control-ow, e.g. the program should not conditionally
add one property in a then branch, while adding a dier-
ent property in an else branch.
Win8 Application
DOM
(45k objects)Builtin
(1k objects)WinJS
(1k objects) WinRT
(13k objects)Figure 1: Structure of a Windows 8 JavaScript app.
Name Lines Functions Alloc. sites Fields
Builtin 225 161 1,039 190
DOM 21,881 12,696 44,947 1,326
WinJS 404 346 1,114 445
Windows 8 API 7,213 2,970 13,989 3,834
Total 29,723 16,173 61,089 5,795
Figure 2: Approximate stub sizes for common libraries.
Libraries should not overwrite properties of application
objects or copy properties from one application object to
another. However, the library is allowed to augment the
global object with additional properties.
Property names should not be computed dynamically (i.e.
one should not use o["p" + "q"] instead of o:pq).
2.5 Soundness
While soundness is a highly attractive goal for static anal-
ysis, it is not one we are pursuing in this paper, opting
for practical utility on a range of applications that do not
necessarily require soundness. JavaScript is a complex lan-
guage with a number of dynamic features that are dicult
or impossible to handle fully statically [25, 16] and hard-to-
understand semantic features [23, 9]. The reader is further
referred to the soundiness eort [20].
We have considered several options before making the de-
cision to forgo conservative analysis. One approach is den-
ing language subsets to capture when analysis results are
sound. While this is a well-known strategy, we believe that
following this path leads to unsatisfactory results.
First, language restrictions are too strict for real pro-
grams: dealing with dicult-to-analyze JavaScript language
constructs such as with and eval and intricacies of the
execution environment such as the Function object, etc.
While language restrictions have been used in the past [13],
these limitations generally only apply to small programs
(i.e. Google Widgets, which are mostly under 100 lines of
code). When one is faced with bodies of code consisting of
thousands of lines and containing complex libraries such as
jQuery, most language restrictions are immediately violated.
Second, soundness assumptions are too dicult to under-
stand and verify statically. For example, in Ali et al. [1]
merely explaining the soundness assumptions requires three
pages of text. It is not clear how to statically check these as-
sumptions, either, not to mention doing so eciently, bring-
ing the practical utility of such an approach into question.
3. OVERVIEW
The composition of a Windows 8 (or Win8) JavaScript ap-
plication is illustrated in Figure 1. These are frequently com-
plex applications that are not built in isolation: in addition
to resources such as images and HTML, Win8 applications
depend on a range of JavaScript libraries for communicat-
ing with the DOM, both using the built-in JavaScript DOM
API and rich libraries such as jQuery and WinJS (an appli-501cation framework and collection of supporting APIs used for
Windows 8 HTML development), as well as the underlying
Windows runtime. To provide a sense of scale, information
about commonly used stub collections is shown in Figure 2.
3.1 Analysis Overview
The intuition for the work in this paper is that despite
having incomplete information about this extensive library
functionality, we can still discern much from observing how
developers use library code. For example, if there is a call
whose base is a variable obtained from a library, the variable
must refer to a function for the call to succeed. Similarly,
if there is a load whose base is a variable returned from a
library call, the variable must refer to an object that has
that property for the load to succeed.
Example 2 A summary of the connection between the
concrete pointer analysis and use analysis described in
this paper is graphically illustrated in Figure 3. In this
example, function process invokes functions mute and
playSound , depending on which button has been pressed.
Both callees accept variable a, an alias of a library-dened
Windows :Media :Audio , as a parameter. The arrows in the
gure represent the ow of constraints.
Points-to analysis (downward arrows) ows facts from ac-
tuals to formals | functions receive information about the
arguments passed into them, while the use analysis (upward
arrows) works in the opposite direction, owing demands on
the shape of objects passed from formals to actuals.
Specically, the points-to analysis ows variable a, dened
inprocess , to formals xandy. Within functions playSound
andmute we discover that these formal arguments must have
functions Volume and Mute dened on them, which ows
back to the library object that variable amust point to. So,
its shape must contain functions Volume and Mute.2
Use analysis: The notion of use analysis above leads us to
an inference technique, which comes in two avors: partial
and full.
Partial inference assumes that stubs for libraries are avail-
able. Stubs are not required to be complete implemen-
tations, instead, function bodies are frequently completely
omitted, leading to missing data ow. What is required is
that all objects, functions and properties (JavaScript term
forelds ) exposed by the library are described in the stub.
Partial inference solves the problem of missing ow between
library and application code by linking together objects of
matching shapes, a process we call unication (Section 4.3).
Full inference is similar to partial inference, but goes further
in that it does not depend on the existence of any stubs. In-
stead it attempts to infer library APIs based on uses found in
the application. Paradoxically, full inference is often faster
than partial inference, as it does not need to analyze large
collections of stubs, which is also wasteful, as a typical ap-
plication only requires a small portion of them.
In the rest of this section, we will build up the intuition
for the analysis we formulate. Precise analysis details are
found in Section 4 and the companion technical report [22].
Library stubs: Stubs are commonly used for static analysis
in a variety of languages, starting from libc stubs for C
programs, to complex and numerous stubs for JavaScript
built-ins and DOM functionality.
Example 3 Here is an example of stubs from the WinRT
function playSound(x){
  x.Volume(30);
  ...
}function process(button){
  var a = Windows.Media.Audio;
  if(button == ‚ÄòMute‚Äô)
    mute(a);
  if(button == ‚ÄòPlay‚Äô)
    playSound(a);
  ...a flows to parameter x
function mute(y){
  y.Mute();
}$AudioPrototype$ = 
 { 
   Volume = function(){},
   Mute = function(){}
}
a flows to parameter y
Constraint ‚Äúx has 
function Volume‚Äù 
propagates to aConstraint ‚Äúy has 
function Mute‚Äù 
propagates to aFigure 3: Points-to owing facts downwards and use
analysis owing data upwards.
library. Note that stub functions are empty.
Windows . Storage . Stream . FileOutputStream =
function () {};
Windows . Storage . Stream . FileOutputStream . prototype =
{
writeAsync = function () {},
flushAsync = function () {},
close = function () {}
}
This stub models the structure of the FileOuputStream ob-
ject and its prototype object. It does not, however, capture
the fact that writeAsync and flushAsync functions return
anAsyncResults object. Use analysis can, however, dis-
cover this if we consider the following code:
var s = Windows . Storage . Stream ;
var fs = new s. FileOutputStream (...)
fs. writeAsync (...) . then ( function () {
...
});
We can observe from this that fs:writeAsync should re-
turn an object whose then is a function. These facts al-
low us to unify the return result of writeAsync with the
Promise JProto Kobject, the prototype of the Promise ob-
ject declared in the WinJS library. 2
3.2 Symbolic Locations and UniÔ¨Åcation
Abstract locations are typically used in program analyses
such as a points-to analysis to approximate objects allocated
in the program at runtime. We employ the allocation site
abstraction as an approximation of runtime object allocation
(denoted by domain Hin our analysis formulation). In this
paper we consider the partial and full inference scenarios.
It is useful to distinguish between abstract locations in
the heap within the application (denoted as HA) and those
within libraries (denoted as HL). Additionally, we main-
tain a set of symbolic locations HS; these are necessary for
reasoning about results returned by library calls. In gen-
eral, both library and application abstract locations may be
returned from such a call.
It is instructive to consider the connections between the
variable Vand heap Hdomains. Figure 4a shows a connec-
tion between variables and the heap H=HA[HS[HLin
the context of partial inference. Figure 4b shows a similar
connection between variables and the heap H=HA[HS
in the context of full inference, which lacks HL. Vari-
ables within the Vdomain have points-to links to heap ele-
ments in H;Helements are connected with points-to links
that have property names. Since at runtime actual objects502Heap for partialHL HS HA                 Variable domain
f
g
Heap for full HS HA                Variable domain
f
gFigure 4: Partial (a, above) and full (b, below) heaps.
are either allocated within the application ( HA) or library
code ( HL), we need to unify symbolic locations HSwith
those in HAandHL.
3.3 Inference Algorithm
Because of missing interprocedural ow, a fundamen-
tal problem with building a practical and usable points-to
analysis is that sometimes variables do not have any ab-
stract locations that they may point to. Of course, with
the exception of dead code or variables that only point to
null/undefined , this is a static analysis artifact. In the
presence of libraries, several distinct scenarios lead to
dead returns : when a library function stub lacks a re-
turn value;
dead arguments : when a callback within the applica-
tion is passed into a library and the library stub fails to
properly invoke the callback;
dead loads : when the base object reference (receiver)
has no points-to targets.
Strategy: Our overall strategy is to create symbolic loca-
tions for all the scenarios above. We implement an iterative
algorithm. At each iteration, we run a points-to analysis
pass and then proceed to collect dead arguments, returns,
and loads, introducing symbol locations for each. We then
perform a unication step, where symbolic locations are uni-
ed with abstract locations. A detailed description of this
process is given in Section 4.
Iterative solution: An iterative process is required be-
cause we may discover new points-to targets in the process
of unication. As the points-to relation grows, additional
dead arguments, returns, or loads are generally discovered,
requiring further iterations. Iteration is terminated when we
can no longer nd dead arguments, dead returns, or dead
loads, and no more unication is possible. Note that the
only algorithmic change for full analysis is the need to create
symbolic locations for dead loads. We evaluate the iterative
behavior experimentally in Section 5.
Unication strategies: Unication is the process of link-
ing or matching symbolic locations with matching abstractNewObj (v1:V; h:H; v 2:V) object instantiation
Assign (v1:V; v 2:V) variable assignment
Load (v1:V; v 2:V; p:P) property load
Store (v1:V; p:P; v 2:V) property store
FormalArg (f:H; z :Z; v:V) formal argument
FormalRet (f:H; v :V) formal return
ActualArg (c:C; z:Z; v:V) actual argument
ActualRet (c:C; v:V) actual return
CallGraph (c:C; f :H) indicates that fmay be in-
voked by a call site c
PointsTo (v:V; h:H) indicates that vmay point
toh
HeapPtsTo (h1:H; p :P; h 2:H) indicates that h1'spprop-
erty may point to h2
Prototype (h1:H; h 2:H) indicates that h1may have
h2in its internal prototype
chain
Figure 5: Datalog relations used for program represen-
tation and pointer analysis.
AppAlloc (h : H),
AppVar (v:V)represents that the allocation site or
variable originates from the applica-
tion and not the library
SpecialProperty (p :
P)properties with special semantics
or common properties, such as
prototype orlength
PrototypeObj (h:H) indicates that the object is used as a
prototype object
Figure 6: Additional Datalog facts for use analysis.
locations. In Section 4.3, we explore three strategies: unify
based on matching of a single property, all properties, and
prototype-based unication.
4. TECHNIQUES
We base our technique on pointer analysis and use analy-
sis. The pointer-analysis is a relatively straightforward ow-
and context-insensitive subset-based analysis described in
Guarnieri et al. [13]. The analysis is eld-sensitive, meaning
that it distinguishes properties of dierent abstract objects.
The call-graph is constructed on-the-y because JavaScript
has higher-order functions, and so the points-to and call
graph relations are mutually dependent. The use analysis
is based on unication of symbolic and abstract locations
based on property names.
4.1 Pointer Analysis
The input program is represented as a set of facts in re-
lations of xed arity and type summarized in Figure 5 and
described below. Relations use the following domains : heap-
allocated objects and functions H, program variables V, call
sitesC, properties P, and integers Z.
The pointer analysis implementation is formulated declar-
atively using Datalog, as has been done in range of prior
projects such as Whaley et al. for Java [30] and Gatekeeper
for JavaScript [13]. The JavaScript application is rst nor-
malized and then converted into a set of facts. These are
combined with Datalog analysis rules resolved using the
Microsoft Z3 xpoint solver [8]. This is a relatively stan-
dard formulation; more information about individual facts
is given in the companion technical report [22]. Rules for
the Andersen-style inclusion-based [2] points-to analysis are
shown in Figure 7a.50310:4PointsTo (v; h) : { NewObj (v; h; _):
PointsTo (v1; h) : { Assign (v1; v2);PointsTo (v2; h):
PointsTo (v2; h2) : { Load (v2; v1; p);PointsTo (v1; h1);HeapPtsTo (h1; p; h 2):
HeapPtsTo (h1; p; h 2) : { Store (v1; p; v 2);PointsTo (v1; h2);PointsTo (v2; h2):
HeapPtsTo (h1; p; h 3) : { Prototype (h1; h2);HeapPtsTo (h2; p; h 3):
Prototype (h1; h2) : { NewObj (_; h1; v);PointsTo (v; f);HeapPtsTo (f;"prototype" ; h3):
CallGraph (c; f) : { ActualArg (c;0; v);PointsTo (v; f):
Assign (v1; v2) : { CallGraph (c; f);FormalArg (f; i; v 1);ActualArg (c; i; v 2); z > 0:
Assign (v2; v1) : { CallGraph (c; f);FormalRet (f; v1);ActualRet (c; v2):
(a) Inference rules for an inclusion-based points-to analysis expressed in Datalog.
ResolvedVariable (v) : { PointsTo (v;_):
PrototypeObj (h) : { Prototype (_; h):
DeadArgument (f; i) : { FormalArg (f; i; v );:ResolvedVariable (v);AppAlloc (f); i > 1:
DeadReturn (c; v2) : { ActualArg (c;0; v1);PointsTo (v1; f);ActualRet (c; v2);
:ResolvedVariable (v2);:AppAlloc (f):
DeadLoad (h; p) : { Load (v1; v2; p);PointsTo (v2; h);:HasProperty (h; p);AppVar (v1);AppVar (v2):
DeadLoad (h2; p) : { Load (v1; v2; p);PointsTo (v2; h1);Prototype (h1; h2);
:HasProperty (h2; p);Symbolic (h2);AppVar (v1);AppVar (v2):
DeadLoadDynamic (v1; h) : { LoadDynamic (v1; v2);PointsTo (v2; h);:ResolvedVariable (v1);
AppVar (v1);AppVar (v2):
DeadPrototype (h1) : { NewObj (_; h; v );PointsTo (v; f);Symbolic (f);:HasSymbolicPrototype (h):
CandidateObject (h1; h2) : { DeadLoad (h1; p);HasProperty (h2; p);Symbolic (h1);:Symbolic (h2);
:HasDynamicProps (h1);:HasDynamicProps (h2);:SpecialProperty (p):
CandidateProto (h1; h2) : { DeadLoad (h1; p);HasProperty (h2; p);Symbolic (h1);:Symbolic (h2);
:HasDynamicProps (h1);:HasDynamicProps (h2);PrototypeObj (h2):
NoLocalMatch (h1; h2) : { Prototype (h2; h3);
8p:DeadLoad (h1; p))HasProperty (h2; p);8p:DeadLoad (h1; p))HasProperty (h3; p);
CandidateProto (h1; h2);CandidateProto (h1; h3); h26=h3:
UnifyProto (h1; h2) : { :NoLocalMatch (h1; h2);CandidateProto (h1; h2);
8p:DeadLoad (h1; p))HasProperty (h2; p):
FoundPrototypeMatch (h) : { UnifyProto (h;):
UnifyObject (h1; h2) : { CandidateObject (h1; h2);:FoundPrototypeMatch (h1);
8p:DeadLoad (h1; p))HasProperty (h2; p):
(b) Use analysis inference.
Figure 7: Inference rules for both points-to and use analysis.
4.2 Extending with Partial Inference
We now describe how the basic pointer analysis can be ex-
tended with use analysis in the form of partial inference . In
partial inference we assume the existence of stubs that de-
scribe all objects, functions and properties. Function imple-
mentations, as stated before, may be omitted. The purpose
of partial inference is to recover missing ow due to missing
implementations. Flow may be missing in three dierent
places: arguments, return values, and loads.
DeadLoad (h:H; p :P) where his an abstract location
andpis a property name. Records that property pis ac-
cessed from h, but hlacks a pproperty. We capture this
with the rule:
DeadLoad (h; p) : { Load (v1; v2; p);
PointsTo (v2; h);
:HasProperty (h; p);
AppVar (v1);AppVar (v2):
Here the PointsTo (v2; h) constraint ensures that the base
object is resolved. The two AppVar constraints ensure that
the load actually occurs in the application code and not the
library code.
DeadArgument (f:H; i:Z) where fis a function and iis
an argument index. Records that the i'th argument has novalue. We capture this with the rule:
DeadArgument (f; i) : { FormalArg (f; i; v );
:ResolvedVariable (v);
AppAlloc (f); i > 1:
Here the AppAlloc constraint ensures that the argument
occurs in a function within the application code, and not in
the library code; argument counting starts at 1.
DeadReturn (c:C; v:V) where cis a call site and vis the
result value. Records that the return value for call site chas
no value.
DeadReturn (c; v2) : { ActualArg (i;0; v1);
PointsTo (v1; f);
ActualRet (i; v2);
:ResolvedVariable (v2);
:AppAlloc (f):
Here the PointsTo (v1; f) constraint ensures that the call
site has call targets. The :AppAlloc (f) constraint ensures
that the function called is not an application function, but
either (a) a library function or (b) a symbolic location.
We use these relations to introduce symbolic locations into
PointsTo ,HeapPtsTo , and Prototype as shown in Fig-
ure 8. In particular for every dead load, dead argument and
dead return we introduce a fresh symbolic location. We re-
strict the introduction of dead loads by requiring that the504Inference (constraints; facts; isFull )
1relations =Solve-Constraints (constraints; facts )
2repeat
3 newFacts =Make-Symbols (relations; isFull )
4 facts =facts[newFacts
5 relations =Solve-Constraints (constraints; facts )
6until newFacts ==;
Make-Symbols (relations; isFull )
1facts =;
2for(h; p)2relations: DeadLoad :HP
3 if:Symbolic (h) or isFull
4 facts [=newHeapPtsTo (h; p; newH)
5for(f; i)2relations: DeadArgument :HZ
6 v=FormalArg [f; i]
7 facts [=newPointsTo (v;newH)
8for(c; v)2relations: DeadReturn :CV
9 facts [=newPointsTo (v;newH)
10 / /Unication:
11forh2relations: DeadPrototype :H
12 facts [=newPrototype (h;newH)
13for(h1; h2)2relations: UnifyProto :HH
14 facts [=newPrototype (h1; h2)
15for(h1; h2)2relations: UnifyObject :HH
16 for(h3; p; h 1)2relations: HeapPtsTo :HPH
17 facts [=newHeapPtsTo (h3; p; h 2)
18return facts
Figure 8: Iterative inference algorithms.
base object is not a symbolic object, unless we are operating
in full inference mode. This means that every load must be
unied with an abstract object, before we consider further
unication for properties on that object. In full inference
we have to drop this restriction, because not all objects are
known to the analysis.
4.3 UniÔ¨Åcation
Unication is the process of linking or matching symbolic
locations swith matching abstract locations l. The simplest
form of unication is to do no unication at all. In this case
no actual ow is recovered in the application. Below we
explore unication strategies based on property names.
9shared properties: The obvious choice here is to link ob-
jects which share at least one property. Unfortunately, with
this strategy, most objects quickly become linked. Espe-
cially problematic are properties with common names, such
aslength ortoString , as all objects have these properties.
8shared properties: We can improve upon this strategy
by requiring that the linked object must have allproper-
ties of the symbolic object. This drastically cuts down the
amount of unication, but because the shape of sis an over-
approximation, requiring all properties to be present may
link to too few objects, introducing unsoundness. It can also
introduce imprecision: if we have swith function trim() , we
will unify sto all string constants in the program. The fol-
lowing rule
CandidateObject (h1; h2) : { DeadLoad (h1; p);
HasProperty (h2; p);
Symbolic (h1);
:Symbolic (h2);
:HasDynamicProps (h1);
:HasDynamicProps (h2);
:SpecialProperty (p):expresses which symbolic and abstract locations h1andh2
arecandidates for unication. First, we require that the
symbolic and abstract location share at least one property.
Second, we require that neither the symbolic nor the ab-
stract object have dynamic properties. Third, we disallow
commonly-used properties, such as prototype and length ,
as evidence for unication. The relation below captures
when two locations h1andh2are unied:
UnifyObject (h1; h2) : { CandidateObject (h1; h2);
8p:DeadLoad (h1; p))
HasProperty (h2; p):
This states that h1andh2must be candidates for unication
and that if a property pis accessed from h1then that prop-
erty must be present on h2. Ifh1andh2are unied then
theHeapPtsTo relation is extended such that any place
where h1may occur h2may now also occur.
Prototype-based unication: Instead of attempting to
unify with all possible abstract locations l, an often better
strategy is to only unify with those that serve as prototype
objects. Such objects are used in a two-step unication pro-
cedure: rst, we see if all properties of a symbolic object can
be satised by a prototype object, if so we unify them and
stop the procedure. If not, we consider all non-prototype
objects. We take the prototype hierarchy into consideration
by unifying with the most precise prototype object. Our
TR discusses the issue of selecting the most precise object
in the prototype hierarchy [22].
4.4 Extending with Full Inference
As shown in the pseudo-code in Figure 8, we can extend
the analysis to support full inference with a simple change.
Recall, in full inference we do not assume the existence of
any stubs, and the application is analyzed completely by
itself. We implement this by dropping the restriction that
symbolic locations are only introduced for non-symbolic lo-
cations. Instead we will allow a property of a symbolic lo-
cation to point to another symbolic location. Introducing
these symbolic locations will resolve a load, and in doing so
potentially resolve the base of another load. This in turn
may cause another dead load to appear for that base ob-
ject. In this way the algorithm can be viewed as a frontier
expansion along the known base objects. At each iteration
the frontier is expanded by one level. This process cannot
go on forever, as there is only a xed number of loads, and
thereby dead loads, and at each iteration at least one dead
load is resolved.
5. EXPERIMENTAL EV ALUATION
5.1 Experimental Setup
We have implemented both the partial and fullinference
techniques described in this paper. Our tool is split into a
front-end written in C# and a back-end which uses analysis
rules encoded in Datalog, as shown in Section 4. The front-
end parses JavaScript application les and library stubs and
generates input facts from them. The back-end iteratively
executes the Z3 Datalog engine [8] to solve these constraints
and generate new symbolic facts, as detailed in Section 4. All
times are reported for a Windows 7 machine with a Xeon 64-
bit 4-core CPU at 3.07 GHz with 6 GB of RAM.
We evaluate our tool on a set of 25 JavaScript applications
obtained from the Windows 8 application store. To provide505Alloc. Call
Lines Functions sites sites Properties Variables
245 11 128 113 231 470
345 74 606 345 298 1,749
402 27 236 137 298 769
434 51 282 194 336 1,007
488 53 369 216 303 1,102
627 59 341 239 353 1,230
647 36 634 175 477 1,333
711 315 1,806 827 670 5,038
735 66 457 242 363 1,567
807 70 467 287 354 1,600
827 33 357 149 315 1,370
843 63 532 268 390 1,704
1,010 138 945 614 451 3,223
1,079 84 989 722 396 2,873
1,088 64 716 266 446 2,394
1,106 119 793 424 413 2,482
1,856 137 991 563 490 3,347
2,141 209 2,238 1,354 428 6,839
2,351 192 1,537 801 525 4,412
2,524 228 1,712 1,203 552 5,321
3,159 161 2,335 799 641 7,326
3,189 244 2,333 939 534 6,297
3,243 108 1,654 740 515 4,517
3,638 305 2,529 1,153 537 7,139
6,169 506 3,682 2,994 725 12,667
1,587 134 1,147 631 442 3,511
Figure 9: Benchmarks, sorted by lines of code.
a sense of scale, Figure 9 shows line numbers and sizes of
the abstract domains for these applications. It is important
to note the disparity in application size compared to library
stub size presented in Figure 2. In fact, the average applica-
tion has 1,587 lines of code compared to almost 30,000 lines
of library stubs, with similar discrepancies in terms of the
number of allocation sites, variables, etc. Partial analysis
takes these sizable stubs into account.
5.2 Call Graph Resolution
We start by examining call graph resolution. As a baseline
measurement we use the standard pointer analysis provided
with stubs without use analysis. Figure 10 shows a his-
togram of resolved call sites for baseline and partial inference
across our 25 applications. We see that the resolution for
baseline is often poor, with many applications having less
than 70% of call sites resolved. For partial inference, the
situation is much improved with most applications having
01234567
0-50% 50-60% 60-70% 70-80% 80-90% 90-100%number of applications  
baseline  
024681012
0-50% 50-60% 60-70% 70-80% 80-90% 90-100%number of applications  
partial inference  
Figure 10: Percentage of resolved call sites for baseline
(points-to without stubs) and partial inference.
020406080
020406080100120140
Partial
Full
Points-to
Na√ØveFigure 11: Resolving WinRT API calls.
over 70% call sites resolved. This conclusively demonstrates
that the unication approach is eective in recovering pre-
viously missing ow. Full inference, as expected, has 100%
of call sites resolved. Note that the leftmost two bars for
partial inference are outliers, corresponding to a single ap-
plication each.
5.3 Case Study: WinRT API Resolution
We have applied analysis techniques described in this pa-
per to the task of resolving calls to WinRT API in Win-
dows 8 JavaScript applications. WinRT functions serve as
an interface to system calls within the Windows 8 OS. Con-
sequently, this is a key analysis to perform, as it can be
used to compute an application's actual (as compared to
declared) capabilities. This information can identify appli-
cations that are over-privileged and which might therefore
be vulnerable to injection attacks or otherwise provide a ba-
sis for authoring malware. The analysis can also be used for
triaging applications for further validation and testing.
Figures in the text show aggregate statistics across all
benchmarks, whereas Figure 11 represents the results of our
analysis across 15 applications, those that are largest in our
set. To provide a point of comparison, we implemented a
navegrep-like analysis by means of a JavaScript language
parser which attempts to detect API use merely by extract-
ing fully-qualied identier names used for method calls,
property loads, etc.
Technique APIs used
nave analysis 684
points-to 800
points-to + partial 1,304
points-to + full 1,320As expected,
we observe
that the na ve
analysis is very
incomplete in
terms of identi-
fying WinRT usage. The base points-to analysis provides
a noticeable improvement in results but is still very in-
complete as compared to the full and partial techniques.
Partial and full analysis are generally comparable in terms
of recall, with the following dierences:
Allanalysis approaches are superior to na ve analysis.
The number of API uses found by partial and full is
roughly comparable.
Results appearing only in full analysis often indicate miss-
ing information in the stubs.
Partial analysis is eective at generating good results
given fairly minimal observed in-application use when cou-
pled with accurate stubs.
As observed previously, common property names lead to
analysis imprecision for partial analysis.
We highlight several examples that come from further ex-
amining analysis results. Observing the following call5060.05.010.015.020.0
245
345
402
434
488
627
647
711
735
807
827
843
1,010
1,079
1,088
1,106
1,856
2,141
2,351
2,524
3,159
3,189
3,243
3,638
6,169seconds  
benchmarks (lines of code)  Partial
FullFigure 13: Running times, in seconds. Gray is partial
inference. Black is full inference. Sorted by lines of code.
driveUtil . uploadFilesAsync ( server . imagesFolderId ).
then ( function ( results ) {...} ))
leads the analysis to correctly map then to the
WinJS :Promise :prototype :then function. A load like:
var json = Windows . Storage . ApplicationData . current .
localSettings . values [key ];
correctly resolves localSettings to an instance of
Windows :Storage :ApplicationDataContainer . Partial
analysis is able to match results without many observed uses.
For instance, the call x.getFolderAsync(‚Äòbackgrounds‚Äô)
is correctly resolved to getFolderAsync on object
Windows :Storage :StorageFolder :prototype .
5.4 Case Study: Auto-Complete
We show how our technique improves auto-completion
by comparing it to four popular JavaScript IDEs: Eclipse
Indigo SR2 for JavaScript developers, IntelliJ IDEA 11,
Visual Studio 2010, and Visual Studio 2012. Figure 12
shows ve small JavaScript programs designed to demon-
strate the power of our analysis. The symbol \ " indicates
the placement of the cursor when the user asks for auto-
completion suggestions. For each IDE, we show whether it
gives the correct suggestion ( X) and how many suggestions
it presents (#); these tests have been designed to have a
single correct completion.
We illustrate the benets of both partial and full infer-
ence by considering two scenarios. For snippets 1{3, stubs
for the HTML DOM and Browser APIs are available, so
we use partial inference. For Windows 8 application snip-
pets 4{5, no stubs are available, so we use full inference. For
all snippets, our technique is able to nd the right suggestion
without giving any spurious suggestions. We further believe
our analysis to be incrementalizable, because of its iterative
nature, allowing for fast, incremental auto-complete sugges-
tion updates.
5.5 Analysis Running Time
Figure 13 shows the running times for partial and full in-
ference. Both full and partial analysis running times are
quite modest, with full usually nishing under 2{3 seconds
on large applications. This is largely due to the fast Z3 Data-
log engine. As detailed in our technical report, full inference
requires approximately two to three times as many iterations
as partial inference. This happens because the full inference
algorithm has to discover the namespaces starting from the
global object, whereas for partial inference namespaces are
known from the stubs. Despite the extra iterations, full in-ference is approximately two to four times faster than partial
inference.
5.6 Examining Result Precision & Soundness
App
OK
Incomplete
Unsound
Unknown
Stubs
Total
app1 16 1 2 0 1 20
app2 11 5 1 0 3 20
app3 12 5 0 0 3 20
app4 13 4 1 0 2 20
app5 13 4 0 1 2 20
app6 15 2 0 0 3 20
app7 20 0 0 0 0 20
app8 12 5 0 1 2 20
app9 12 5 0 0 3 20
app10 11 4 0 3 2 20
Total 135 35 4 5 21 200We have manually in-
spected 20 call sites | twelve
resolved, ve polymorphic and
three unresolved | in 10 ran-
domly picked benchmark apps
to estimate the precision and
unsoundness of our analysis; this
process took about two hours.
Figure to the right provides
results of our examination. Here
OK is the number of call sites
which are both sound and com-
plete (i.e. their approximated
call targets match the actual
call targets), Incomplete is the
number of call sites which are sound, but have some
spurious targets (i.e. imprecision is present), Unsound is
the number of call sites for which some call targets are
missing (i.e. the set of targets is too small ),Unknown is the
number of call sites for which we were unable to determine
whether it was sound or complete due to code complexity,
Stubs is the number of call sites which were unresolved due
to missing or faulty stubs.
Out of the 200 inspected call sites, we nd 4 sites, which
were unsoundly resolved, i.e. true call targets were missing.
Of these, three were caused by JSON data being parsed and
the fourth was caused by a type coercion, which is not han-
dled by our implementation. Here is an example unsound-
ness related to JSON:
JSON . parse ( str ).x. split ("~")
Remember that use analysis has no knowledge of the struc-
ture of JSON data. Thus, in the above code, use analysis
can see that the returned object should have property x,
however it cannot nd any objects (application or library)
with this property; thus it cannot unify the return value.
Furthermore, we found that for 35 call sites the analysis
had some form of imprecision (i.e. more call targets than
could actually be executed at runtime). We found two rea-
sons for this: (1) property names may be shared between dif-
ferent objects, and thus if use analysis discovers a property
read like x:slice (and has no further information about x)
it (soundly) concludes that xcould be an array or a string as
both has the x:slice function. We observed similar behavior
foraddEventListener ,querySelector , and appendChild ,
all frequently occurring names in HTML DOM; (2) we
found several errors in existing stubs, for instance double-
declarations like:
WinJS .UI. ListView = function () {};
WinJS .UI. ListView = {};
As an example of imprecision, consider the code below:
var encodedName = url. slice (url. lastIndexOf ('/')+1)
Here urlis an argument passed into a callback. In this
case, use analysis knows that urlmust have property slice ,
however both arrays and strings have this property, so use
analysis infers that urlcould be either an array or a string.
In reality, urlis a string.507Eclipse IntelliJ VS 2010 VS 2012
Category Code X #X #X # X #
Partial inference
1DOM Loopvar c =document :getElementById ("canvas" );
var ctx =c:getContext ("2d");
var h =c:height ;
var w =c:w7 0X 35 7 26 X 1
2Callbackvar p =ffirstName :"John" ;lastName :"Doe"g;
function compare (p1;p2)f
var c =p1:firstName <p2:firstName ;
if(c! = 0)return c ;
return p1 :last
g7 0X 9 7 7X?k
3Local Storagevar p1 =ffirstName : "John";lastName : "Doe"g;
localStorage :putItem ("person ";p1);
var p2 =localStorage :getItem ("person ");
document :writeln ("Mr:" +p2:lastName +
";" +p2:f);7 0X 50+ 7 7 7 7
Full inference
4NamespaceWinJS :Namespace :define ("Game:Audio ";
play :function ()fg;volume :function ()fg
);
Game:Audio :volume (50);
Game:Audio :p7 0X 50+ 7 1X?k
5Pathsvar d =new Windows :UI:Popups :MessageDialog ();
var m =new Windows :UI:7 0 7 250+ 7 7X?k
Figure 12: Auto-complete comparison. ?means that inference uses all identiers in the program. \ " marks the auto-
complete point, the point where the developer presses Ctrl+Space or a similar key stroke to trigger auto-completion.
6. RELATED WORK
Pointer analysis and call graph construction: Declar-
ative points-to analysis explored in this paper has long been
subject of research [30, 19, 5]. In this paper our focus is
on call graph inference through points-to, which generally
leads to more accurate results, compared to more traditional
type-based techniques [12, 11, 24]. Ali et al. [1] examine the
problem of application-only call graph construction for the
Java language. Their work relies on the separate compila-
tion assumption which allows them to reason soundly about
application code without analyzing library code, except for
inspecting library types. While the spirit of their work is
similar to ours, the separate compilation assumption does
not apply to JavaScript, resulting in substantial dierences
between our techniques.
Static analysis of JavaScript: A project by Chugh et al.
focuses on staged analysis of JavaScript and nding infor-
mation ow violations in client-side code [7]. Chugh et al.
focus on information ow properties such as reading docu-
ment cookies and URL redirects. A valuable feature of that
work is its support for dynamically loaded and generated
JavaScript in the context of what is generally thought of
as whole-program analysis. The Gatekeeper project [13, 14]
proposes a points-to analysis together with a range of queries
for security and reliability as well as support for incremental
code loading. Sridharan et al. [27] presents a technique for
tracking correlations between dynamically computed prop-
erty names in JavaScript programs. Their technique allows
them to reason precisely about properties that are copied
from one object to another as is often the case in libraries
such as jQuery. Their technique only applies to libraries
written in JavaScript, so stubs for the DOM and Windows
APIs are still needed. Schafer et al. study the issue of
auto-completion for JavaScript in much more detail than we
do in Section 5 and propose a solution to JavaScript auto-
completion within IDEs using a combination of static and
runtime techniques [26].
Type systems for JavaScript: Researchers have noticed
that a more useful type system in JavaScript could preventerrors or safety violations. Since JavaScript does not have
a rich type system to begin with, the work here is devising
a correct type system for JavaScript and then building on
the proposed type system. Soft typing [6] might be one of
the more logical rst steps in a type system for JavaScript.
Much like dynamic rewriters insert code that must be exe-
cuted to ensure safety, soft typing must insert runtime checks
to ensure type safety. Several project focus on type sys-
tems for JavaScript [4, 3, 28]. These projects focus on a
subset of JavaScript and provide sound type systems and
semantics for their restricted subsets. As far as we can tell,
none of these approaches have been applied to large bodies
of code. In contrast, we use pointer analysis for reasoning
about (large) JavaScript programs. The Type Analysis for
JavaScript (TAJS) project [18] implements a data ow anal-
ysis that is object-sensitive and uses the recency abstraction.
The authors extend the analysis with a model of the HTML
DOM and browser APIs, including a complete model of the
HTML elements and event handlers [17].
7. CONCLUSIONS
This paper presents an approach that combines traditional
pointer analysis and a novel use analysis to analyze large
and complex JavaScript applications. We experimentally
evaluate our techniques based on a suite of 25 Windows 8
JavaScript applications, averaging 1,587 lines of code, in
combination with about 30,000 lines of stubs each. The
median percentage of resolved calls sites goes from 71.5%
to 81.5% with partial inference, to 100% with full infer-
ence. Full analysis generally completes in less than 4 sec-
onds and partial in less than 10 seconds. We demonstrated
that our analysis is immediately eective in two practical
settings in the context of analyzing Windows 8 applica-
tions: both full and partial nd about twice as many WinRT
API calls compared to a na ve pattern-based analysis; in
our auto-completion case study we out-perform four major
widely-used JavaScript IDEs in terms of the quality of auto-
complete suggestions.5088. REFERENCES
[1] K. Ali and O. Lhotak. Application-only call graph
construction. In Proceedings of the European
Conference on Object-Oriented Programming , 2012.
[2] L. O. Andersen. Program analysis and specialization
for the C programming language. Technical report,
University of Copenhagen, 1994.
[3] C. Anderson and P. Giannini. Type checking for
JavaScript. In In WOOD S04, volume WOOD of
ENTCS. Elsevier, 2004. http://www.binarylord.com/
work/js0wood.pdf , 2004.
[4] C. Anderson, P. Giannini, and S. Drossopoulou.
Towards type inference for JavaScript. In In
Proceedings of the European Conference on
Object-Oriented Programming , pages 429{452, July
2005.
[5] M. Bravenboer and Y. Smaragdakis. Strictly
declarative specication of sophisticated points-to
analyses. In OOPSLA , pages 243{262, 2009.
[6] R. Cartwright and M. Fagan. Soft typing. SIGPLAN
Notices , 39(4):412{428, 2004.
[7] R. Chugh, J. A. Meister, R. Jhala, and S. Lerner.
Staged information ow for JavaScript. In PLDI , June
2009.
[8] L. M. de Moura and N. Bjrner. Z3: An ecient SMT
solver. In TACAS , pages 337{340, 2008.
[9] P. Gardner, S. Maeis, and G. D. Smith. Towards a
program logic for JavaScript. In POPL , 2012.
[10] M. Grace, Y. Zhou, Z. Wang, and X. Jiang.
Systematic detection of capability leaks in stock
Android smartphones. In NDSS , 2012.
[11] D. Grove and C. Chambers. A framework for call
graph construction algorithms. Transactions of
Programming Language Systems , 23(6), 2001.
[12] D. Grove, G. DeFouw, J. Dean, and C. Chambers.
Call graph construction in object-oriented languages.
InOOPSLA , pages 108{124, Oct. 1997.
[13] S. Guarnieri and B. Livshits. Gatekeeper: Mostly
static enforcement of security and reliability policies
for JavaScript code. In Proceedings of the Usenix
Security Symposium , Aug. 2009.
[14] S. Guarnieri and B. Livshits. Gulfstream: Incremental
static analysis for streaming JavaScript applications.
InProceedings of the USENIX Conference on Web
Application Development , June 2010.
[15] A. Guha, M. Fredrikson, B. Livshits, and N. Swamy.
Veried security for browser extensions. In IEEESymposium on Security and Privacy , May 2011.
[16] S. H. Jensen, P. A. Jonsson, and A. Mller.
Remedying the eval that men do. In ISSTA , July 2012.
[17] S. H. Jensen, M. Madsen, and A. Mller. Modeling the
HTML DOM and browser API in static analysis of
JavaScript web applications. In FSE, 2011.
[18] S. H. Jensen, A. Mller, and P. Thiemann. Type
analysis for JavaScript. In Proceedings of the
International Static Analysis Symposium , volume
5673, August 2009.
[19] B. Livshits and M. S. Lam. Finding security errors in
Java programs with static analysis. In Proceedings of
the Usenix Security Symposium , Aug. 2005.
[20] B. Livshits, M. Sridharan, Y. Smaragdakis, and
O. Lhotak. In defense of unsoundness.
http://soundiness.org , 2013.
[21] B. Livshits, J. Whaley, and M. S. Lam. Reection
analysis for java. In LNCS 3780 , Nov. 2005.
[22] M. Madsen, B. Livshits, and M. Fanning. Practical
static analysis of JavaScript applications in the
presence of frameworks and libraries. Technical Report
MSR-TR-2012-66, Microsoft Research, 2012.
[23] S. Maeis, J. Mitchell, and A. Taly. An operational
semantics for JavaScript. 2008.
[24] A. Milanova, A. Rountev, and B. G. Ryder. Precise
and ecient call graph construction for programs with
function pointers. Journal of Automated Software
Engineering , 2004.
[25] G. Richards, C. Hammer, B. Burg, and J. Vitek. The
eval that men do { a large-scale study of the use of
eval in JavaScript applications. In ECOOP , pages
52{78, 2011.
[26] M. Schaefer, M. Sridharan, J. Dolby, , and F. Tip.
Eective smart completion for JavaScript. Technical
Report RC25359, IBM Research, Mar. 2013.
[27] M. Sridharan, J. Dolby, S. Chandra, M. Schaefer, and
F. Tip. Correlation tracking for points-to analysis of
JavaScript. In ECOOP , 2012.
[28] P. Thiemann. Towards a type system for analyzing
JavaScript programs. European Symposium On
Programming , 2005.
[29] P. Thiemann. A type safe DOM API. In DBPL , pages
169{183, 2005.
[30] J. Whaley, D. Avots, M. Carbin, and M. S. Lam.
Using Datalog and binary decision diagrams for
program analysis. In APLAS , Nov. 2005.509