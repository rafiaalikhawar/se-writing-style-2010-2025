How DoFixesBecome Bugs?
A ComprehensiveCharacteristicStudyonIncorrectFixesin Commercialand
Open SourceOperatingSystems
Zuoning Yin ‡,Ding Yuan ‡,Yuanyuan Zhou †, Shankar Pasupathy∗,Lakshmi Bairavasundaram∗
‡Department ofComputer Science,Univ. ofIllinois atUrbana -Champaign, Urbana,IL 61801, USA
{zyin2, dyuan3}@cs.uiuc.edu
†Department of Computer Science andEngineering, Univ. ofCa lifornia, San Diego, LaJolla ,CA92093, USA
yyzhou@cs.ucsd.edu
∗NetApp Inc.,Sunnyvale, CA94089, USA
{pshankar, lakshmib}@netapp.com
ABSTRACT
Software bugs aﬀect system reliability. When a bug is ex-
posed in the ﬁeld, developers need to ﬁx them. Unfor-
tunately, the bug-ﬁxing process can also introduce errors,
which leads to buggy patches that further aggravate the
damage to end users and erode software vendors’ reputa-
tion.
This paper presents a comprehensive characteristic study
on incorrect bug-ﬁxes from large operating system code base s
including Linux, OpenSolaris, FreeBSD and also a mature
commercial OS developed and evolved over the last 12years,
investigating not only the mistake patterns during bug-ﬁxi ng
but also the possible human reasons in the development pro-
cess when these incorrect bug-ﬁxes were introduced. Our
major ﬁndings include: (1) at least 14.8% ∼24.4% of sam-
pled ﬁxes for post-release bugs1in these large OSes are
incorrect and have made impacts to end users. (2) Among
several common bug types, concurrency bugs are the most
diﬃcult to ﬁx correctly: 39% of concurrency bug ﬁxes are
incorrect. (3) Developers and reviewers for incorrect ﬁxes
usually do not have enough knowledge about the involved
code. For example, 27% of the incorrect ﬁxes are made by
developers who have never touched the source code ﬁles as-
sociated with the ﬁx. Our results provide useful guidelines
to design new tools and also to improve the development
process. Based on our ﬁndings, the commercial software
vendor whose OS code we evaluated is building a tool to
improve the bug ﬁxing and code reviewing process.
Categories and Subject Descriptors: D.2.0 [Software
Engineering]: General
General Terms: Reliability
1These only include those ﬁxes for bugs discovered after
software releases.
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and thefull citation on the ﬁrstpage. Tocop y otherwise, to
republish, topostonserversortoredistribute tolists,re quires priorspeciﬁc
permission and/or afee.
ESEC/FSE’11, September 5–9, 2011, Szeged, Hungary.
Copyright 2011 ACM 978-1-4503-0443-6/11/09 ...$10.00.Keywords: Incorrect ﬁxes, software bugs, bug ﬁxing, hu-
man factor, testing
1. INTRODUCTION
1.1 Motivation
As a man-made artifact, software suﬀers from various er-
rors, referred to as software bugs, which cause crashes, han gs
or incorrect results and signiﬁcantly threaten not only the
reliability but also the security of computer systems. Bugs
are detected either during testing before release or in the
ﬁeld by customers post-release. Once a bug is discovered,
developers usually need to ﬁx it. In particular, for bugs
that have direct, severe impact on customers, vendors usu-
ally make releasing timely patches the highest priority in
order to minimize the amount of system down time.
Unfortunately, ﬁxes to bugs are not bullet proof since they
are also written by human. Some ﬁxes either do not ﬁx the
problem completely or even introduce new problems. For ex-
ample, in April 2010, McAfee released a patch which incor-
rectly identiﬁed a critical Windows system ﬁle as a virus [8] .
As a result, after applying this patch, thousands of systems
refused to boot properly, had lost their network connection s,
or both. In 2005, Trend Micro also released a buggy patch
which introduced severe performance degradation [22]. The
company received over 370,000 calls from customers about
this issue and eventually spent more than $8 million to com-
pensate customers. The above two incidents are not the
only cases in recent history. As a matter of fact, there were
many other similar events [2, 15, 4] in the past which put
the names of big companies such as Microsoft, Apple and
Intel under spotlight.
We had also conducted a study on every security patch
released by Microsoft in its security bulletin [1] since Jan -
uary 2000 to April 2010. Surprisingly, out of the total 720
released security patches, 72 of them were buggy when they
were ﬁrst released. These patches were expected to ﬁx some
severe problems. Once released, they were usually applied
to millions of users automatically. Therefore, they would
have enormous impacts and damages to end users as well as
software vendors’ reputation.
Mistakes in bug ﬁxes may be caused by many possible
reasons. First, bug ﬁxing is usually under very tight time
schedule, typically with deadlines in days or even hours,char buf[256] ;
  …... (52 lines omitted)
sprintf( buf,   "You have an existing file %s.\
n", …)
sprintf( buf,   "You have an existing file 
%s",  Do you want to rename the existing 
keytab (a very long message ? )\n", …)kerberos.c (FreeBSD) First fix Second fix 
char buf[256] ;
char buf[400] ;
  …... (52 lines omitted)
sprintf( buf,    "You have an existing file 
snprinf(buf, sizeof(buf),  "You have an …
%s",  Do you want to rename the existing 
keytab (a very long message ? )\n", …)
Figure 1: An incorrect ﬁx example from FreeBSD. A
part of the ﬁrst ﬁx appended a console message with
some additional information, unfortunately introducing
a buﬀer overﬂow (The added lines are in bold while the
deleted lines are crossed out).
deﬁnitely not weeks. Such time pressure can cause ﬁxers2
to have much less time to think cautiously, especially about
the potential side-eﬀects and the interaction with the rest
of the system. Similarly, such time pressure prevents teste rs
from conducting thorough regression tests before releasin g
the ﬁx. Figure 1 shows a real world example from FreeBSD,
the original bug ﬁx appended a log message with additional
information. Unfortunately, the ﬁxer did not pay attention
to the buﬀer length deﬁned 52 lines upwards in the same ﬁle
and introduced a buﬀer overﬂow.
SOCK_LOCK(so);
if (INP_CHECK_SOCKAF(so, PF_INET)) {
      if (so->so_pcb  == NULL)    return;
          …... 
}
SOCK_UNLOCK(so);audit_arg.c (FreeBSD) First fix Second fix 
SOCK_LOCK(so)
if (INP_CHECK_SOCKAF(so, PF_INET)) {
      if (so->so_pcb == NULL){
         SOCK_UNLOCK(so);  return;
       }     
        …... 
}
SOCK_UNLOCK(so)
Figure 2: An incorrect ﬁx example from FreeBSD. The
ﬁrst ﬁx tried to ﬁx a data race bug by adding locks,
which then introduced a deadlock as it forgot to release
the lock via SOCK_UNLOCK before return .
Second, bug ﬁxing usually has a narrow focus (e.g., remov-
ing the bug) comparing to general development. As such,
the ﬁxer regards ﬁxing the target bug as the sole objective
and accomplishment to be evaluated by his/her manager.
Therefore, he/she would pay much more attention to the
bug itself than the correctness of the rest of the system.
Similarly, such narrowly focused mindset may also be true
for the testers: Tester may just focus on if the bug symptom
observed previously is gone, but forget to test some other
aspects, in particular how the ﬁx interacts with other parts
and whether it introduces new problems. As shown in Fig-
ure 2, the ﬁxer just focused on removing the data race bug by
adding locks. While the data race bug was removed, the ﬁx
unfortunately introduced a new bug: a deadlock. This dead-
lock was obviously not discovered during regression testin g.
Third, the two factors above can be further magniﬁed if
ﬁxers or reviewers are not familiar with the related code.
While an ideal ﬁxer could be someone with the most knowl-
edge about the related code, in reality it may not always
be the case. Sometimes, it may be diﬃcult to know who is
the best person to do the ﬁx. Even if such person is known,
he/she may be busy with other tasks or has moved to other
projects, and is therefore unavailable to perform the ﬁx.
Sometimes, it is due to the development and maintenance
process. Some software projects have separate teams for
2we will refer the developer who ﬁxes the bug as the “ﬁxer”
in the rest of the paper.developing and maintaining software. All these real world
situations can lead to the case that the ﬁxer does not have
enough knowledge about the code he/she is ﬁxing, and con-
sequently increases the chance of an incorrect ﬁx. This
might help explaining the incorrect ﬁx shown in Figure 3
from the commercial OS we evaluated. When we measure
the ﬁxer’s knowledge based on how many lines he had con-
tributed to the ﬁle involved in the patch, we found that he
had never touched this ﬁle in the past, indicating that he
may not have suﬃcient relevant knowledge to ﬁx the bug
correctly.
if (correct_sum()) 
if (correct_sum() &&  blk->count()) 
         blk_clear_flag(blk, F_BLK_VALID);rescan.c (a commercial OS) First fix Second fix 
if (correct_sum() &&  blk->count()) 
if (correct_sum() && blk->count() 
&&!blk_scan_exist(blk,BLKS_CALC)) 
        blk_clear_flag(blk, F_BLK_VALID);
Figure 3: An incorrect ﬁx that hadn’t ﬁxed the problem
completely. This example is from the large commercial OS
we evaluated. The ﬁrst ﬁx tried to address a semantic
bug by modifying the ifcondition. Unfortunately, the
revised condition was still not restrictive enough.
Regardless what is the reason for introducing these errors
during bug ﬁxing and why they were not caught before re-
lease, their common existences and severe impacts on users
and vendors have raised some serious concerns about the
bug ﬁxing process. In order to come up with better process
and more eﬀective tools to address this problem, we need to
ﬁrst thoroughly understand the characteristics of incorre ct
ﬁxes, including:
•How signiﬁcant is the problem of incorrect ﬁxes? More
speciﬁcally, what percentages of bug ﬁxes are incorrect?
How severe are the problems caused by incorrect ﬁxes?
•What types of bugs are diﬃcult to ﬁx correctly? Are some
types of bugs just more diﬃcult to ﬁx correctly so that ﬁx-
ers, testers and code reviewers for these types of bug ﬁxes
should pay more attention and eﬀort to avoid mistakes?
•What are the common mistakes made in bug ﬁxes? Are
there any patterns among incorrect bug ﬁxes? If there are
some common patterns, such knowledge would help alert-
ing developers to pay special attention to certain aspects
during bug ﬁxing. Additionally, it may also inspire new
tools to catch certain incorrect ﬁxes automatically.
•What aspects in the development process are correlated to
the correctness of bug ﬁxing? For example, does ﬁxers
and reviewers’ relevant knowledge have a high correlation
to incorrect ﬁxes?
A few recent studies had been conducted on certain as-
pects of incorrect ﬁxes [6, 36, 33, 13]. For example, Śliwers ki
et al. [36] proposed an eﬀective way to automatically locate
ﬁx-inducing changes and studied the incorrect ﬁx ratios in
Eclipse and Mozilla. They found developers are easier to
make mistakes during bug ﬁxing on Friday. Purushothaman
et al. [33] studied the incorrect ﬁx ratio in a switching system
from Lucent, but their focus was on the impact of one-line
changes. Gu et al. [13] studied the incorrect ﬁx ratio in three
Apache projects, but they focused on providing a new patch
validation tool.
While these studies have revealed some interesting ﬁnd-
ings, most of them focused more on incorrect ﬁx ratios and
studied only open source code bases, providing one of the
ﬁrst steps toward understanding incorrect bug ﬁxes. ThisImportance of Incorrect Fixes Implications
(1) At least 14.8% ∼24.4% of examined ﬁxes for post-release
bugs are incorrect. 43% of the examined incorrect ﬁxes can
cause crashes, hangs, data corruptions or security problem s.Although the ratio of incorrect ﬁxes is not very high, the imp act
of the incorrect ﬁxes indicate that the problem of incorrect ﬁxes
is signiﬁcant and worth special attention.
(2) Among common types of bugs and based on our samples,
ﬁxes on concurrency bugs (39% of them) are most error-prone,
followed by semantic bugs (17%) and then memory bugs (14%).Developers and testers should be more cautious when ﬁxing
concurrency bugs.
Incorrect ﬁxes to Concurrency bugs Implications
(3) Fixes on data race bugs can easily introduce new deadlock
bugs or do not completely ﬁx the problem.The synchronization code added for ﬁxing data races need to
be examined in more detail to avoid new deadlock. Knowing
all the access locations to the shared objects is the key to ﬁx
data race completely.
(4) Fixes to deadlock bugs might reveal bugs which were hidde n
by the previous deadlock.Fixers need to further examine the path after deadlock in cas e
there are some bugs hidden due to the existence of the deadloc k.
Incorrect ﬁxes to Memory bugs Implications
(5) Fixing buﬀer overﬂows by statically increasing the buﬀe r
size is still vulnerable to future overﬂows. Fixing buﬀer ov er-
ﬂows by dynamically allocating memory could introduce null
pointer dereference bugs if the allocated memory is used wit h-
out check.It is better to use safe string functions (e.g., snprintf ) or bound
checking to ﬁx buﬀer overﬂow. Fixers need to be aware of the
potential memory leaks and the failure of allocation when ﬁx ing
buﬀer overﬂows by dynamically allocating memory.
(6) Fixing memory leaks can introduce dangling pointer bugs
when freeing the memory without nullifying the pointer, and
memory corruption when freeing something that should not be
freed, or do not solve the problem completely when forgettin g
to free the members of a structure.It is good to nullify the pointer after freeing the memory. It is
also important to clearly understand what and when should be
freed to avoid overreaction. Fixers should remember to free the
structure members when freeing a complex structure to avoid
an incomplete ﬁx.
Human reasons to incorrect ﬁxes Implications
(7) Comparing to correct ﬁxes, the developers who introduce d
incorrect ﬁxes have less knowledge (or familiarity) with th e
relevant code. 27% of the incorrect ﬁxes are even made by
ﬁxers who previously had never touched the ﬁles involved in
the ﬁx.Code knowledge has inﬂuence on the correctness of bug ﬁxes.
It is dangerous to let developers who are not familiar with th e
relevant code to make the ﬁx.
(8) Interestingly, in most of the cases, the developers who a re
most familiar (5 ∼6 times of the actual ﬁxers) with the relevant
code of these incorrect ﬁxes are still working on the project ,
but unfortunately were not selected to do the ﬁxes.Having a right software maintenance process and selecting t he
right person to ﬁx a bug is important.
(9) The code reviewers for incorrect ﬁxes also have very poor
relevant knowledge.It is also important to select a developer who is familiar wit h
the relevant code as the code-reviewer.
Table 1: Our major ﬁndings of real world incorrect bug ﬁx characteris tics and their implications. Please take our
methodology and potential threats to validity into conside ration when you interpret and draw any conclusions.
paper goes much beyond prior work, studying both com-
mercial and open source, large operating system projects,
and investigating not only incorrect ﬁx percentages, but al so
other characteristics such as mistake patterns during bug
ﬁxing, types of bugs that are diﬃcult to ﬁx correctly, as
well as the potential reasons in the development process for
introducing incorrect bug ﬁxes.
1.2 Our Contribution
To the best of our knowledge, this paper presents one
of the most comprehensive characteristic studies on incor-
rect ﬁxes from large OSes including a mature commercial
OS developed and evolved over the last 12 years and three
open-source OSes (FreeBSD, OpenSolaris and Linux), ex-
ploring not only the mistake patterns but also the possible
human reasons in the development process when these in-
correct ﬁxes were introduced. More speciﬁcally, from these
four OS code bases, we carefully examined each of the 970
randomly selected ﬁxes for post-release bugs and identiﬁed
the incorrect ﬁxes. To gain a deeper understanding of what
types of bugs are more diﬃcult to ﬁx correctly as well as
the common mistakes made during ﬁxing those bugs, we
further sampled another set of 320 ﬁxes on certain impor-
tant types of bugs. The details of our methodology and
potential threats to validity are described in Section 2.
Our major ﬁndings are summarized in Table 1. These
ﬁndings provide useful guidelines for patch testing and val i-dations as well as bug triage process. For example, motivated
from our ﬁndings, the large software vendor whose OS code
was evaluated in our study is building a tool to improve its
bug ﬁxing and code review process.
While we believe that the systems and ﬁxes we examined
well represent the characteristics in large operating syst ems,
we do not intend to draw any general conclusions about all
the applications. In particular, we should note that all of t he
characteristics and ﬁndings in this study are associated wi th
the types of the systems and the programming languages
they use. Therefore, our results should be taken with the
speciﬁc system types and our methodology in mind.
Paper outline: In Section 2, we discuss the methodology
used in our study and threats to validity. Section 2. After
that we present our detailed results on the incorrect ﬁx rati o
in Section 3. Then we further study which types of bugs are
more diﬃcult to ﬁx and what common mistakes could be
made in Section 4. After that we study the human factors
which could lead to incorrect ﬁxes in Section 5. Section 6 is
the related work and we conclude in Section 7.
2. METHODOLOGY
In this section, we ﬁrst discuss the software projects used
in our study (Section 2.1), the techniques to ﬁnd incorrect
ﬁxes (Section 2.2), how we select bug samples (Section 2.3)
and how we study the inﬂuence of human factors on bugﬁxing(Section 2.4). At the end, we talk about the threats
to the validity of our study (Section 2.5).
2.1 Software projects under study
App LoC Open src?
The commercial OS conﬁdential N
FreeBSD 9.97M Y
Linux 10.94M Y
OpenSolaris 12.99M Y
Table 2: The four OSes that our study uses.
Table 2 lists the four code bases we studied, including a
commercial, closed-source OS from a large software vendor3
and three open-source OSes (FreeBSD, Linux and OpenSo-
laris). We chose to study OS code because they are large,
complex and their reliability is critically important. Add i-
tionally, as OS code is developed by many programmers,
contains lots of components, uses a variety of data struc-
tures and algorithms, it could provide us a broad base to
understand incorrect ﬁx examples.
The four OSes have diﬀerent architectures. The commer-
cial OS is especially designed for high-reliability system s
with many enterprise customers like big ﬁnancial compa-
nies and government agencies. It has evolved for almost
12 years. The other three open-source OSes have diﬀer-
ent origins. FreeBSD originates from academia (Berkeley
Unix). OpenSolaris originates from a commercial OS (So-
laris). Linux completely originates from the open-source
community. We think the variety in data sources would
help us ﬁnd general software laws or interesting speciﬁciti es.
These OSes usually have multiple branches (series) in their
OS families. We focus on those branches which are both sta-
ble and widely deployed. For the commercial OS, we chose
the branch which is most widely deployed. For FreeBSD,
we chose FreeBSD 7 series. For Linux, we chose Linux 2.6
series. For Opensolaris, it has a diﬀerent release model so
we just studied the releases since its 2008.5 version.
In order to further preserve the privacy and reputation for
the software vendor, we anonymized the results in Section 3,
4 and 5. The four code bases will be just referred as A, B,
C and D with the mapping information hidden. We know
that such anonymization may prevent us from making some
interesting comparison between open source and commercial
code bases, but fortunately we can still make many other
ﬁndings like the ones summarized in Introduction.
2.2 Finding incorrect ﬁxes
The deﬁnition of incorrect ﬁx: A bug ﬁx fxis deﬁned
as an incorrect ﬁx if there is another following bug ﬁx fy
that ﬁxes either a new problem introduced by fx, or the
original problem that was not completely ﬁxed by fx.
Note that we consider only ﬁxes to bugs, not any gen-
eral or non-essential changes [16] (e.g., feature addition or
renaming). This is identiﬁed by checking whether a ﬁx is
associated with a bug report. This screening criteria is im-
portant to the ﬁdelity of our study since bug reports often
contain rich information which is important for us to under-
stand the ﬁx. It is hard to obtain a complete picture from
the bug ﬁx itself alone.
Unfortunately, the link between ﬁxes and bug reports is
not always systematically maintained [5]. For the commer-
cial OS and OpenSolaris, the SCM (software conﬁguration
3Due to conﬁdentiality agreement, we can neither mention
the company’s name nor the LoC of its OS.management) systems record the link between every bug re-
port and every change. However, for FreeBSD and Linux,
such links are only documented voluntarily by developers
in an unstructured way. To identify such links, we use a
method similar to the methods used in [11, 36, 40]. The
main idea is to leverage the verbal information in the bug
reports or change logs to reconstruct the links. For example ,
developers may write “ the bug is ﬁxed by change 0a134fad ”
in a bug report. Then we can link the bug to the change
0a134fad.
After the above process, we will have a set of bug ﬁxes
linked with bug reports. We then randomly select a tar-
get number of bug ﬁxes and then semi-automatically check
whether each one is an incorrect ﬁx or not. We call the pro-
cess semi-automatic because we use a two-step process: ﬁrst
step automatically selects potential incorrect ﬁx candida tes,
while the second step manually veriﬁes each candidate.
Two techniques are used in the ﬁrst step to automatically
identify potential incorrect ﬁx candidates. First, we look at
thesource code overlap between changes. This technique is
similar to the methods used in [36, 33]. If there is source
code overlap between two changes, then the latter change
may be made to correct the previous change. More specif-
ically, if a latter change fyoverwrites or deletes the code
written in the previous change fxorfyjust adds code in
the proximity (+/-25 lines) of fx, we regard fxas an in-
correct ﬁx candidate for manual examination. The second
technique is to search for speciﬁc keywords in the bug report
and change log of each ﬁx that may suggest an incorrect ﬁx.
For example, if we ﬁnd “ this patch ﬁxed a regression intro-
duced by the ﬁx in Bug 12476 ” in the bug report linked with
fy, we regard the ﬁx in “Bug 12476” as an incorrect ﬁx can-
didate. In general, we ﬁnd the ﬁrst technique to be more
comprehensive.
Please note that the ﬁrst step is only identifying candi-
dates. We still need to manually examine each candidate,
which is the unique challenge in our study. We examined all
the relevant code related to each ﬁx. We also examined the
bug reports and change logs to get proof from developer’s
explanation. For some ﬁxes, we even discussed with devel-
opers of these systems to ensure the correct understanding
on them. Then based on all the evidences we got, we ﬁnally
decide whether a ﬁx is incorrect or not.
Also note that the ﬁrst step may prune a few incorrect
ﬁxes out, especially those incorrect ﬁxes whose next ﬁxes
in a completely diﬀerent location without any overlap at all
(i.e. beyond the +/-25 lines proximity). But we expect such
incorrect ﬁxes are very rare as two subsequent ﬁxes to the
same problem usually has good locality in terms of code
changes. And we did try to relax the proximity requirement
to be “within” the same ﬁle but did not ﬁnd more incorrect
ﬁxes.
2.3 The target bugs to study
In this study we used two sets of bug ﬁxes with diﬀerent
focuses.
Sample set 1: To get this sample set, we ﬁrst randomly
sampled a total of 2,000 bug ﬁxes (500 from each OS) that
are associated with bug reports. From these 2,000 bug ﬁxes,
we further select only those ﬁxes to post-release bugs (970
in total). Selecting such post-release bug ﬁxes allows us
to focus on ﬁxes to bugs that made high impacts to both
customers and vendors. Post-release bugs are selected afte rthe random sampling instead of before the sampling because
the manual eﬀort in verifying all bug ﬁxes would be too huge.
We then use the process described in the previous subsection
to identify and study incorrect ﬁxes.
Sample set 2: This sample set is used to further zoom in
certain bug types observed in sample set 1 whose ﬁxes are
most error-prone. Speciﬁcally, we chose to study the ﬁxes to
memory leak, buﬀer overﬂow, data race and deadlock bugs.
However, it is diﬃcult to reuse the bugs in sample set 1 ,
since there are not statistically suﬃcient number of bug ﬁxe s
for these types of bugs. Therefore, we deliberately sampled
more bug ﬁxes focusing on these four types. Speciﬁcally, we
used all the related keywords to search for the bug ﬁxes of
a speciﬁc type. Keyword search is enough to get these bug
ﬁxes since there are only limited ways to name them. Then
we randomly selected 20 from each type for each code base.
In total, we sampled 320 ﬁxes which provide us a richer
base-set to study the incorrect ﬁxed patterns. This set is
only used in Section 4.
2.4 Measuring codeknowledge
To understand why a programmer cannot ﬁx a bug cor-
rectly, we also dive deeper into his/her knowledge about the
relevant code. In this study, we measure code knowledge by
checking the cumulative “authorship” of each line of code at
a particular version, which can be systematically measured .
From SCM, we obtain the authorship of each line for a ﬁle at
a given version by using commands such as “svn annotate”.
Assume a developer d, a ﬁle F, a function fand a version v,
we calculate code knowledge at two levels of granularity:
K_File d,F,v=The LoC written by dforFatv
The total LoC in Fatv
K_Func d,f,F,v =The LoC written by dforfinFatv
The total LoC in the fatv
We use percentage as the unit of K_File andK_Func .
For example, “ K_File d,F,v=75%” means 75% of code lines
inFat version vare written by d.dmay write these code
lines in any version that is not later than v. Both ﬁxers’ and
reviewers’ knowledge are measured in our study in this way.
2.5 Threats to validity
Real world empirical studies are all subject to validity
problems, so is our study. Potential threats to the validity of
our study are the representativeness of the selected softwa re
projects, the representativeness of the incorrect ﬁx sampl es,
our classiﬁcation process and evaluation methodology.
Representativeness of software: Both commercial and
open-source software are covered in this study, so we believ e
that we have a good coverage for at least OS code. We do not
intend to draw any general conclusions in all software, but
some of the ﬁndings such as ﬁxers and reviewers’ knowledge
would also apply to other applications.
Representativeness of bug ﬁx samples: We studied
only those bug ﬁxes that could be linked to a bug report.
The set of ﬁxes that cannot be linked were not covered, and
some of our ﬁndings might not hold in them [5]. Fortunately,
the results from the commercial OS and OpenSolaris are
immune to this threat since every bug ﬁx is linked to a bug
report. Since the results from FreeBSD and Linux show a
similar trend as the commercial OS and OpenSolaris, which
may ease the concern on this threat for this problem.
As discussed earlier, there is also a potential problem inour automatic ﬁltering process, i.e., we can potentially ﬁl -
ter out an incorrect ﬁx if its subsequent ﬁx does not have
any proximity in code location. Fortunately our exercises o f
relaxing the proximity constraint did not discover any more
incorrect ﬁxes, which indicates that the amount of missed
incorrect ﬁxes should be very low.
Threats of manual classiﬁcation: Our study involves
manual classiﬁcation on bug reports and ﬁxes which cannot
be replaced by automatic techniques. Therefore, subjectiv -
ity is inevitable. However, we tried our best to minimize
such subjectivity by using double veriﬁcation. Also the au-
thors have previous experience in studying bugs and familia r
with OSes [19, 42, 38, 21]. For every incorrect ﬁx candidate,
we examined all the information sources we could have, in-
cluding source code, bug reports, change logs, etc. Besides ,
for some ﬁxes we also discussed with developers of these
systems to ensure the correct understanding on them. Since
we manually examined each incorrect ﬁx candidate and clas-
sify it as incorrect only if we have concrete evidence, we are
conﬁdent that the number of false positives should be very
low.
Limitation in measuring the knowledge: The way we
measure code knowledge is relatively simple since we only
want to check the ﬁxers and reviewers’ knowledge in a coarse-
grain, qualitative way. A more sophisticated knowledge
model might provide us more accurate results in Section 5,
which remains as our future study.
3. ISINCORRECTFIXREALLYASIGNIF-
ICANTPROBLEM?
The ratio of incorrect ﬁxes among all bug ﬁxes and the
impact of bugs introduced by incorrect ﬁxes are important
for us to accurately understand whether incorrect bug ﬁx
is a signiﬁcant problem. As described in Section 2, we ﬁrst
randomly sampled 2,000 bug ﬁxes from the four OSes (500
from each OS), among them 970 are ﬁxes to post-release
bugs.
App# of post-release # of incorrectRatiobug ﬁxes ﬁxes
A 189 39 20.6%±3.0%
B 309 46 14.8%±2.9%
C 267 41 15.3%±2.6%
D 205 50 24.4%±3.7%
Table 3: The ratio of incorrect ﬁxes on sampled post-
release bugs in the four OSes. A 95% conﬁdence interval
is used.
Table 3 shows the ratio of incorrect ﬁxes based on our sam-
ples is 14.8% ∼24.4% among the four OSes. As discussed in
Section 2.5, this is only a lower-bound estimation. Conside r-
ing that the ﬁxes on post-release bugs would be applied by a
lot of customers and users, even this ratio can still have sig -
niﬁcant impact. Since regression testing had already been
applied before releasing the ﬁxes, it also indicates genera l
testing techniques may need to be tailored to be more eﬀec-
tive in capturing the errors in patches.
We further studied the impact of the bugs introduced by
the examined incorrect ﬁxes. We judge the impact based
on the symptoms described in the bug reports. We found
14.0% of them introduced crash, 8.4% caused system to
hang, 15.4% led to data corruption or data loss, 5.6% caused
security problem, 7.0% degraded the performance, and 45.1%
introduced incorrect functionality. Some bugs introducedare actually more severe than the original bugs. Moreover,
for some bugs, they could even be incorrectly ﬁxed for sev-
eral times.
Finding: At least 14.8% ∼24.4% of the sampled bug ﬁxes
are incorrect. Moreover, 43% of the incorrect ﬁxes resulted
in severe bugs that caused crash, hang, data corruption or
security problems.
Implication: Incorrect ﬁx is indeed a signiﬁcant problem
that requires special attentions from software vendors.
4. INCORRECTFIX PATTERNS
Though bug ﬁx patterns had already been studied in [17,
31], few had studied the patterns of incorrect ﬁxes before.
In this section, we ﬁrst study which types of bugs are more
likely to introduce incorrect ﬁxes. Then we probe deeper
into each of these bug types and try to understand their
incorrect ﬁx patterns via case studies. Finally, we discuss
how we can leverage those patterns to detect incorrect ﬁxes
in the testing process.
4.1 Which types of bugs are more difﬁcult to
ﬁx correctly?
We classiﬁed all the 970 sampled ﬁxes into three categories
based on the bugs they ﬁx: memory bug, concurrency bug
or semantic bug. Semantic bugs are those bugs that cannot
be classiﬁed as memory or concurrency bug and are usually
application speciﬁc problems. This classiﬁcation is adopt ed
from previous literature [19].
App Concurrency Memory Semantic
A 4/13 (31%) 3/17 (18%) 32/159 (20%)
B 9/21 (43%) 5/44 (13%) 32/244 (13%)
C 7/19 (37%) 6/43 (14%) 28/205 (14%)
D 10/23 (44%) 5/30 (17%) 35/152 (23%)
Overall 30/76 (39%) 19/134 (14%) 127/760 (17%)
Table 4: The number of incorrect ﬁxes among all the
sampled ﬁxes and the incorrect ﬁx ratio for the three
categories of bugs in the four OSes.
Table 4 shows the ratio of incorrect ﬁxes to each type
of bug. Based on our samples, concurrency bugs have the
largest incorrect ﬁx ratio (39% overall), indicating concu r-
rency bugs are the hardest to ﬁx. Semantic bugs and mem-
ory bugs have similar ratio, 17% and 14%, respectively.
We focus on studying concurrency bugs and memory bugs,
while only providing some high level discussion on semantic
bugs (Section 4.2.5). This is because semantic bugs have
very diverse root causes so that it is diﬃcult to observe gen-
eral patterns from their ﬁxes and the mistakes in the ﬁxes.
Bug types and their percentages
data race 33% deadlock 29%
buﬀer overﬂow 8% memory leak 6%
uninitialized read 4% null pointer deref 4%
Table 5: The most observed bug types among all the
concurrency bugs and memory bugs being ﬁxed incor-
rectly. Only top six are shown.
To select the important types of bugs for a detailed study,
we further dive into all the concurrency bugs and memory
bugs being ﬁxed incorrectly to see which sub-types are most
observed. The result is shown in Table 5. Among all the
bug types, data race (33%), deadlock (29%), buﬀer overﬂow
(8%) and memory leak (6%) are the top four types of themost observed concurrency bugs and memory bugs which
were ﬁxed incorrectly. Therefore, we just focused on the
characteristics of bug ﬁxes to these four types of bugs.
AppBug types
race deadlock buf overﬂow mem leak
A 9/20 (45%) 5/20 (25%) 2/20 (10%) 1/20 (5%)
B 11/20 (55%) 6/20 (30%) 1/20 (5%) 3/20(15%)
C 11/20 (55%) 8/20 (40%) 3/20 (15%) 0/20 (0%)
D 8/20 (40%) 9/20 (45%) 1/20 (5%) 4/20 (20%)
All 39/80 (49%) 28/80 (35%) 7/80 (9%) 8/80 (10%)
Table 6: The number of incorrect ﬁxes among the all the
ﬁxes and the incorrect ﬁx ratio for the four important
types of bugs from sample set 2 .
Table 6 further shows the ratio of incorrect ﬁxes for these
four types of bugs. The result is from 320 ﬁxes only to these
bug types ( sample set 2 mentioned in Section 2.3), where
for each type we randomly sampled 20 ﬁxes from each code
base. We use this data set instead of the one used above be-
cause among the original 970 ﬁxes ( sample set 1 mentioned
in Section 2.3), there are not statistically suﬃcient numbe r
of bug ﬁxes for these four types of bugs. sample set 2 pro-
vides us a richer base-set of incorrect ﬁxes to conduct our
case studies in Section 4.2. As indicated in Table 6, ﬁxes to
data race and deadlock are most error-prone, with an incor-
rect ﬁx ratio of 49% and 35% respectively, which is generally
4x∼6x of buﬀer overﬂow and memory leak.
Finding: Based on our samples, concurrency bugs are
the most diﬃcult (39%) to ﬁx right. Among concurrency
and memory bugs which were ﬁxed incorrectly, the four
most observed bug types are: data race, deadlock, buﬀer
overﬂow and memory leak.
Implication: Developers and testers should be more
cautious when ﬁxing concurrency bugs. The allocation of
ﬁxing and testing resources could consider the types of
bugs to be ﬁxed.
4.2 Mistakes inbug ﬁxing
After understanding which types of bugs are more diﬃ-
cult to ﬁx right, it would be interesting to understand the
common mistakes (patterns) when ﬁxing a particular type
of bugs and the consequence introduced by those incorrect
ﬁxes. In this Section, we use the incorrect ﬁx examples got
from sample set 2 . Generally, we ﬁnd there are two types of
incorrect ﬁxes: incomplete ﬁxes andintroducing new prob-
lems, while each type of bug also has its own incorrect ﬁx
patterns. We also discuss techniques to detect or reveal
these mistakes: either extending current techniques or sug -
gesting new approaches.
4.2.1 Fixingdataraces
The most common practice for ﬁxing data race is to add
synchronization primitives (e.g., locks) to create mutual ex-
clusion on shared resources. However, delivering a correct
ﬁx requires deep reasoning on all the side-eﬀects of the newl y
added synchronization, which is often error-prone.
Speciﬁcally, adding locks might introduce deadlock. This
incorrect ﬁx pattern is observed in all the four code bases
we evaluated and in 16.4% (6 out of 39) of the incorrect
ﬁxes to data race bugs. Figure 4 shows one of the exam-
ples. In the ﬁrst ﬁx, a lock scwas added to avoid a race.
However, the function bus_teardown_intr is not supposedFXP_LOCK(sc);
ether_ifdetach(&sc->arpcom.ac_if);
….. 
bus_teardown_intr(sc->dev, ...);
FXP_UNLOCK(sc);if_fx.c (FreeBSD) First fix Second fix 
FXP_LOCK(sc);
ether_ifdetach(&sc->arpcom.ac_if);
….. 
FXP_UNLOCK(sc);
bus_teardown_intr(sc->dev, ...);
Figure 4: Incorrect ﬁx to a data race introduced a dead-
lock. The function bus_teardown_intr cannot be called
with lock held, otherwise deadlock will be introduced.
to be called inside the critical section, otherwise it can le ad
to deadlock. Unfortunately, developers were not aware of
this rule and made the incorrect ﬁx. To ﬁx this deadlock,
bus_teardown_intr was moved out of the critical section.
Figure 2 (in Section 1) is another example of this pattern
that ﬁxing data race introduces deadlock. The ﬁxer for-
got to release the lock via SOCK_UNLOCK before a return
statement therefore a deadlock happened.
Implications: When adding synchronization primitives,
ﬁxers need to make sure the newly added primitives (e.g.,
lock) will not introduce deadlocks with the existing synchr o-
nization code. This can be checked by extending deadlock
detectors to only focus on the synchronization primitives
newly added. Besides, lock and unlocks should be added
in pairs along all the execution paths in the newly formed
atomic region. This can be checked automatically by extend-
ing some existing path-sensitive bug detection tools such a s
RacerX [9] or PR-Miner [20] to only scan the code regions
touched by the ﬁx.
spin_lock_irqsave(&hcall_lock,flag);
plpar_hcall9(…);  
spin_unlock_irqrestore(&hcall_lock, flag);
…... 
plpar_hcall9_norets(…);
 hcp_if.c (Linux) First fix Second fix 
spin_lock_irqsave(&hcall_lock,flag);
plpar_hcall9(…);  
spin_unlock_irqrestore(&hcall_lock, flag);
…... 
spin_lock_irqsave(&hcall_lock,flag );
plpar_hcall9_norets(…);  
spin_unlock_irqrestore(&hcall_lock, flag);
Figure 5: Fix to a data race was not complete.
The ﬁrst ﬁx only added locks to protect function
plpar_hcall9 , while forgot to protect plpar_hcall9_noret
(which contains the access to the same shared objects in
plpar_hcall9 ).
Fixing data races could be incomplete such that not all the
data races are ﬁxed. This incorrect ﬁx pattern is observed in
three of the code bases we evaluated and in 10.2% (4 out of
39) of the incorrect ﬁxes to data race bugs. For example, as
shown in Figure 5, when adding locks, the developer forgets
to lock all the places she should lock.
Implications: For a complete ﬁx to data race, it is im-
portant to know all the accesses to the shared objects which
could race with each others. We can design checkers to de-
tect where the same shared objects are protected by lock in
some paths but unprotected in some others [10], and make
these checkers focus only on checking the patched code.
4.2.2 Fixingdeadlocks
To ﬁx a deadlock, developers may either reverse the order
of locks, or even drop some locks. However, these means
need to be applied with caution.
Speciﬁcally, ﬁxing deadlocks could still lead to deadlock
bugs. This incorrect ﬁx pattern is observed in three of the
code bases we evaluated and in 14.3% (4 out of 28) of the
incorrect ﬁxes to deadlocks. Figure 6 shows such an exam-
ple. The root cause of this incorrect ﬁx is similar to the onedown_write(&(bonding));
If(...){
     rtnl_lock();
     If(atomic_read(...)>cnt){
          rtnl_unlock();
          goto out:
      }
     bond_destroy(bond);
    rtnl_unlock();
    goto out:
}
... 
out:
up_write(&(bonding));First fix Second fix 
If(...){
   rtnl_lock();
   down_write(&(bonding));
   If(atomic_read(...)>cnt) 
             goto out:
    }
   bond_destroy(bond);
   up_write(&(bonding));
   rtnl_unlock();
   goto out:
}
... 
out:bond_sysfs.c (Linux)
If(...){
   rtnl_lock();
   down_write(&(bonding));
   If(atomic_read(...)>cnt) 
             goto out_unlock:
   }
   bond_destroy(bond);
   goto out_unlock:
}
... 
out_unlock:
up_write(&(bonding));
rtnl_unlock();
out:Original bug 
Figure 6: Incorrect ﬁx to a deadlock introduced a new
deadlock. The ﬁrst ﬁx reversed the order of locks to pre-
vent deadlock, but forgot to release locks before taking
agoto path.
rw_enter(iss->iss_lockp);
mutex_enter(stmf_lock);
for (i = 0; i < nentries; i++) 
{...}
mutex_exit(stmf_lock);
rw_exit(iss->iss_lockp);
... 
for (i = 0; i < nentries; i++) 
{...}First fix Second fix 
mutex_enter(stmf_lock);
rw_enter(iss->iss_lockp);
for (i = 0; i < nentries; i++) 
{...}
rw_exit(iss->iss_lockp);
mutex_exit(stmf_lock);
... 
for (i = 0; i < nentries; i++) 
{...}stmf.c (OpenSolaris)
mutex_enter(stmf_lock);
rw_enter(iss->iss_lockp);
for (i = 0; i < nentries; i++) 
{...}
... 
for (i = 0; i < nentries; i++) 
{...}
rw_exit(iss->iss_lockp);
mutex_exit(stmf_lock);Original bug 
Figure 7: A ﬁx to a deadlock exposed a hidden data
race bug.
in Figure 2. Therefore we can again extend some current
path-sensitive bug detection tools to spot the deadlock.
Additionally, ﬁxing deadlock may reveal some other bugs
that were originally hidden by the deadlock, especially dat a
race bugs. This incorrect ﬁx pattern is observed in two of
the code bases we evaluated and in 7.1% (2 out of 28) of
the incorrect ﬁxes to deadlocks. Though we only spotted
2 such cases, we think this is still an interesting pattern.
Figure 7 shows one of the examples. There are two bugs
in the original code: a deadlock caused by the wrong order
of the two locks, and a data race caused by an unprotected
shared variable in the second forloop. However, the data
race is hidden by the existence of the deadlock since the
execution would not even reach the second forloop due to
the deadlock. The ﬁrst ﬁx resolved the deadlock. However,
it also enables the execution to proceed so that the data race
is much easier to manifest.
Implications: The hang introduced by deadlock bugs
might prevent some execution paths from being exercised
thoroughly, which could make some bugs hidden in those
paths diﬃcult to manifest. After removing deadlock bugs,
ﬁxers should further test those execution paths.
4.2.3 Fixingbuffer overﬂow
We also found some interesting incorrect ﬁxes examples
for memory bugs. However, since the total numbers of in-
correct ﬁxes to buﬀer overﬂows and memory leaks in sample
set2 is not statistically large enough (7 and 8 respectively),
we do not claim those examples are frequently observed in-
correct ﬁx patterns. However, we assume these examples
could be common for the incorrect ﬁxes to buﬀer overﬂows
and memory leaks (shown in Section 4.2.4) if we can further
enlarge our sample set.
Common techniques to ﬁx buﬀer overﬂow include: a) re-
strict the length of the data which will be stored into buﬀer
by using safe string functions (e.g., snprintf ) or do boundchecking b) increase the buﬀer size statically from stack c)
allocate larger buﬀer dynamically from heap to replace a
stack buﬀer.
Based on our observation, technique a) is usually safe and
seldom introduces any further incorrect ﬁxes since it eradi -
cates the chance of a buﬀer overﬂow in the future.
Implications: The good practice to ﬁx buﬀer overﬂow is
to use safe string functions or do bound check when possible.
vm_offset_t avail[10]; 
vm_offset_t avail[20];
for (indx = 0;  avail[indx + 1] != 0; indx += 2) 
            size1 = avail[indx + 1] - avail[indx];machdep.c (FreeBSD) First fix Second fix 
vm_offset_t avail[20]; 
vm_offset_t avail[100];
for (indx = 0; avail[indx + 1] != 0; indx += 2) 
            size1 = avail[indx + 1] - avail[indx];
Figure 8: Incorrect ﬁx to a buﬀer overﬂow by increasing
static buﬀer size. The ﬁrst ﬁx enlarged the buﬀer size to
20, but the size was still not big enough. Under certain
input, avail was still overﬂown.
Technique b) is potentially problematic if the developer
cannot anticipate the input size accurately. The buﬀer size
after increasing may still be not enough for an untested in-
put in the future. As shown in Figure 8, the ﬁrst ﬁx was
incomplete. After it increased the size of avail to 20, avail
was still overﬂown later. Actually even the second ﬁx might
still be ﬂawed. Since the developer does not add a bound
check, a future input beyond the size 100 could still overﬂow
avail .
Implications: Increasing the static buﬀer size can be dan-
gerous if the input size cannot be accurately estimated.
char tempMail[24];
char *tempMail;
len = strlen(tmpdir);
tempMail = (char *) malloc (len+…);
strcpy(tempMail, tmpdir);temp.c (FreeBSD) First fix Second fix 
char *tempMail;
len = strlen(tmpdir);
if((tempMail = malloc(len + …)) == NULL)
                 panic("Out of memory");
strcpy(tempMail, tmpdir); 
Figure 9: Incorrect ﬁx to a buﬀer overﬂow by allocating
heap memory. The ﬁrst ﬁx allocated heap memory to
replace stack buﬀer, but the return value of malloc was
unchecked.
For technique c), developers need to be aware of the rules
to use memory allocation functions. The memory allocated
needs to be freed after use, otherwise it may introduce a
memory leak. Besides, developers need to consider to do
error handling if memory allocation fails. As shown in Fig-
ure 9, the ﬁxer did ﬁx the buﬀer overﬂow, but introduced a
potential invalid memory access.
Implications: When allocating memory dynamically to
ﬁx buﬀer overﬂow, developers also need to follow the safety
rules of using memory allocation functions.
4.2.4 Fixingmemoryleak
Once a memory leak is detected, writing ﬁxes may be
straightforward, but mistakes can still be made.
Speciﬁcally, ﬁxing memory leak can introduce dangling
pointer or null pointer dereference if the pointer would sti ll
be accessed after the free. Figure 10 shows an example where
a dangling pointer bug was introduced.
Implications: It is a good practice to nullify the pointer
after freeing it, which can avoid dangling pointer bugs.
Developer may also not be aware of the condition to free
an object. They should only free an object when it is no
longer used. If they overreact, they could mistakenly free
an object still in use under certain conditions. Figure 11
shows such an example which led to data corruption.void blk_online_work(online_t *p) { 
    …...     
    kmem_free(p);    
    return;
}
void blk_scan(){
   blk_online_work(info);
   find_blk_by_id(info, WIT_FS)
}toc.c (a commercial OS) First fix Second fix 
void blk_online_work(online_t *p) { 
    …...     
    kmem_free(p); 
    p = null  
    return;
}
void blk_scan(){
   blk_online_work(info);
   find_blk_by_id(info, WIT_FS)
}
Figure 10: Incorrect ﬁx to memory leak introduced a
dangling pointer. The pointer pwas later used in func-
tion ﬁnd_blk_by_id with null pointer check. However,
the ﬁrst ﬁx simply freed pwithout nullifying it.
…... 
acm_free(M_USM,case_username);auth.c (a commercial OS) First fix Second fix 
if (IS_DEFAULT(get_choices())) {
     acm_free(M_USM,case_username);
}
Figure 11: Incorrect ﬁx to a memory leak introduced
data corruption. The ﬁrst ﬁx freed the data indexed
bycase_username unconditionally. However, the data
should be freed only under certain conditions.
Implications: Before ﬁxing memory leak, developers should
make sure when and what should be freed.
if (lseek(cat->fd, nextSet, 0) == -1) {
     …... 
     free(cat->set);
}msgcat.c (FreeBSD) First fix Second fix 
if (lseek(cat->fd, nextSet, 0) == -1) {
     …... 
     if (!cat->set->tag)   free(cat->set->data);
     free(cat->set);    
}
Figure 12: Incomplete ﬁx to a memory leak. The ﬁrst
ﬁx only freed cat->set but forgot to free its member data .
Besides, ﬁxing memory leak can be incomplete. For some
complex data structures, ﬁxers may forget to free all their
members. Figure 12 shows such an example.
Implications: For complex data structures, ﬁxers should
remember to free all their members.
4.2.5 Fixingsemanticbugs
Semantic bugs have very diverse root causes, so the ways
to ﬁx them are also diversiﬁed. However, we still observed
one common incorrect ﬁx pattern for semantic bugs: con-
ditions (e.g., ifcondition) are diﬃcult to ﬁx correctly. As
shown in Figure 3 in Section 1, the ﬁrst ﬁx to the ifcondi-
tion was still not restrictive enough. Though this pattern i s
frequently observed, it is not easy to leverage current tech -
niques to detect them. We think ﬁxing semantic bugs cor-
rectly may require more application speciﬁc knowledge from
ﬁxers.
4.2.6 Generalapproachesto detectincorrectﬁxes
Understanding the impact of the change: A funda-
mental reason for developers to make mistakes during bug
ﬁxing is that they do not know all the potential impacts of
the newly ﬁxed code. For example, in Figure 4, the ﬁxer
was not aware that the newly added lock scwould dead-
lock with the function bus_teardown_intr . If all such po-
tential “inﬂuenced code” (either through control- or data-
dependency) is clearly presented to developers, they may
have better chances to detect the errors. We envision com-
piler techniques such as program slicing [41, 12, 14, 43] can
be extended to analyze such information, using the depen-
dencies to the patch as the slicing criterion.AppActual ﬁxer for Actual ﬁxer for Potential
incorrect ﬁxes correct ﬁxes optimal ﬁxer
K_File K_Func K_File K_Func K_File K_Func
A 13.2% ( 0.022 )18.1% ( 0.046 )18.3% ( 0.019 )20.5% ( 0.012 )65.0% ( 0.043 )75.1% ( 0.031 )
B 9.5% ( 0.013 ) 11.5% ( 0.023 )15.4% ( 0.016 )27.9% ( 0.031 )39.7% ( 0.024 )51.4% ( 0.022 )
C 12.8% ( 0.024 )16.1% ( 0.037 )17.2% ( 0.021 )18.4% ( 0.023 )69.8% ( 0.031 )78.1% ( 0.026 )
D 7.9% ( 0.017 ) 12.5% ( 0.035 )15.5% ( 0.024 )16.4% ( 0.021 )78.0% ( 0.023 )78.4% ( 0.039 )
AVG 10.9% 14.6% 16.6% 20.8% 63.1% 70.8%
Table 7: The ﬁxers’ average code knowledge on the buggy ﬁles/functio ns. The variance of the code knowledge is
shown in the parentheses. Code knowledge is shown in the form of percentage (e.g., 13.2% means a knowledge value
of 0.132). “Potential optimal ﬁxer” is the developer with th e most knowledge on the buggy ﬁles/functions but might
not be always assigned the bug ﬁxing task.
Apply checkers incrementally As discussed before, it is
possible for some existing bug detection tools (checkers) [ 20,
9, 10] to detect some types of incorrect ﬁxes. However, ap-
plying these tools directly on the full code base after the ﬁx is
not practical: it may take a very long time for them to scan
the entire code base, which may be redundant with the orig-
inal testing steps, or not always necessary. Also it may pro-
duce too many false positives. Instead, developers may want
to check the code inﬂuenced by the patch ﬁrst. One obser-
vation is that sometimes, just checking within the function
boundary is enough to detect problems in the patch. For
example, in Figure 2 (Section 1), a path-sensitive checker
that simply checks the rule “lock is always paired with an
unlock” can easily detect the missed SOCK_UNLOCK by
only scanning the function that the patch modiﬁed.
Dealing with incomplete ﬁxes Some incomplete ﬁxes
are introduced by the fact that ﬁxers may forget to ﬁx all
the buggy regions with the same root cause. This types of
incomplete ﬁxes can be mitigated by using technique [30, 28]
which searches for other places that have the same patterns
or usage scenarios in entire code. For example, in Figure 5,
the ﬁrst ﬁx that suggested certain shared objects need to
be protected. Then developers can try to ﬁnd the other
places where those objects are accessed without protection .
However, this technique is less eﬀective when a consistent
pattern is diﬃcult to learn. Moreover, those incomplete ﬁxe s
related to conditions (Figure 3 in Section 1) cannot be solve d
by this technique.
5. LACK OFKNOWLEDGE
Multiple factors can inﬂuence developers to make an in-
correct ﬁx. In this section, we focus on programmers’ code
knowledge. Intuitively, if a ﬁle or a function is mostly writ -
ten by a developer, the developer may have higher chance
to give a correct ﬁx to a bug rooted in that ﬁle or function.
We ﬁrst measured the K_File andK_Func (deﬁned in
Section 2.4) for the ﬁxers who made the incorrect ﬁxes. The
incorrect ﬁxes are from sample set 1 . The results are shown
in Table 7. We found that in general these ﬁxers who made
the incorrect ﬁxes were not knowledgeable about the buggy
ﬁles/functions. Speciﬁcally, they had only contributed on
average 10.9% to the ﬁles and 14.6% to the functions in-
volved in the patch before they made the incorrect ﬁx. In
comparison, Table 7 also shows the ﬁxers’ knowledge in cor-
rectﬁxes. The correct ﬁxes are from the complement of the
incorrect ﬁx set (Table 3). We found those ﬁxers who made
the correct ﬁxes had contributed on average 16.6% to the
ﬁles and 20.8% to the functions. In other words, the knowl-
edge of the ﬁxers who made the correct ﬁxes is 1.5 times of
that of the ﬁxers who made the incorrect ﬁx based on ourcode knowledge metrics, indicating source code knowledge
could be a factor to incorrect ﬁxes.
But can we really ﬁnd a developer who is more knowl-
edgeable than the actual ﬁxer of the incorrect ﬁx? Table 7
also answered this question: surprisingly, by selecting th e
most knowledgeable developer who is still active in the de-
velopment when the bugs need to be ﬁxed as the ﬁxer, the
K_File andK_Func can reach as high as 63.1% and 70.8%
respectively, which is 5 ∼6 times of the knowledge of the
actual ﬁxers in incorrect ﬁxes. Additionally, by selecting
the two of the most knowledgeable developers as review-
ers (two is the average number of reviewers in the OSes
we studied), the K_File andK_Func can reach 68.2%
and 78.8% respectively, which is 6 ∼7 times of the knowl-
edge of the actual reviewers on each incorrect ﬁx. Note that
these “potential optimal ﬁxers” are still reachable when th e
bugs were opened, which suggests that the current bug ﬁxing
and reviewing process is not always assigning the problem
to the developers who could be most “knowledgeable” with
the bug.
0.00%10.00%20.00%30.00%40.00%50.00%60.00%
K = 0% 0< K <= 1% 1% < K <= 5% 5% < K <= 50% K > 50% K_File 
K_Func 
Different levels of knowledge (K)% of incorrect fixes
Figure 13: The distribution of incorrect ﬁxes in diﬀerent
knowledge scales.
Figure 13 further studies why the K_File andK_Func
in incorrect ﬁxes are low by probing deeper into the distri-
bution of incorrect ﬁxes in diﬀerent knowledge scales. We
found the low K_File andK_Func are caused by a large
portion of incorrect ﬁxes that were made by ﬁxers with zero
prior knowledge to the buggy ﬁles/functions. As shown in
Figure 13, 27.2% of the ﬁxers had not contributed any lines
to the ﬁle ( K_File= 0% ) they were about to ﬁx. It is even
worse at the function level. 51.4% of ﬁxers had not con-
tributed any lines of code to the function they were about
to ﬁx. These “ ﬁrst touches ” could be dangerous since the
developer could have little knowledge about the particular
part of code when they are doing the ﬁx.
Besides studying the eﬀect of code knowledge in terms of
K_File andK_Func , we further study the code knowledge
in terms of whether the ﬁxer actually ﬁxed the lines of code
previously written by him. The intuition behind this is that
even though a ﬁxer had written small amount of code (i.e.,
small K_File/K _func ), as long as the ﬁxer was modifying
the code regions that he had written, he might be still con-
sidered as the knowledgeable person for the ﬁx. Speciﬁcally ,
for each ﬁx, if any code line modiﬁed by the ﬁx was alsopreviously written by the same ﬁxer, we count this ﬁxer is
ﬁxing his own code. The result is shown in Table 8.
App for incorrect ﬁxes for correct ﬁxes
A 7.7% 26.2%
B 16.4% 44.8%
C 18.2% 25.9%
D 8.0% 24.1%
AVG 12.6% 30.3%
Table 8: The percentage of ﬁxes that ﬁxer is ﬁxing his
own code. For example, the number 7.7% in the ﬁrst cell
means: among all the incorrect ﬁxes from OS A, 7.7% of
them were actually ﬁxed by developers who were ﬁxing
their own code.
Table 8 shows large diﬀerence between correct ﬁxes and
incorrect ﬁxes. The ratio of the ﬁxers who ﬁxed their own
code for correct ﬁxes is 2.5 times of the ratio for incorrect
ﬁxes (30.3% v.s. 12.6%). This suggests fewer ﬁxers (in term
of ratio) are ﬁxing their own code for incorrect ﬁxes than for
correct ﬁxes, which further suggests that ﬁxing code writte n
by others might be prone to incorrect ﬁxes.
Based on our study in code knowledge, a software vendor
is building a tool to ﬁnd knowledgeable ﬁxers and reviewers.
Sometimes when the bug report just arrives it may be un-
clear which ﬁles/functions contain the bug. In these cases
the knowledge is more useful to assign reviewers who are
knowledgeable to the ﬁles/functions involved in the ﬁx afte r
the ﬁx is made. This knowledge can also be used in prior-
itizing patch testing eﬀorts to pay more attentions to the
patches ﬁxed by less-knowledgeable ﬁxers.
Finding: The ﬁxers’ knowledge on the buggy ﬁles/func-
tions in correct ﬁxes is 1.5 times of the ﬁxers’ knowledge
in incorrect ﬁxes. Fewer ﬁxers (in term of ratio) are ﬁxing
their own code for incorrect ﬁxes than for correct ﬁxes.
Moreover, nearly 27% of the incorrect ﬁxes are made by
developers who have not contributed a single line to the
entire ﬁle they are about to ﬁx. The potential “Optimal”
developer who is most familiar with the buggy code has
5∼6 times knowledge of that of the actual ﬁxer in incorrect
ﬁxes.
Implication: It might be beneﬁcial to assign the bugs
to developers with more knowledge during the bug-triage
process. The knowledge can also be considered as a factor
in prioritizing the testing eﬀorts on patches.
6. RELATED WORK
Studying incorrect ﬁxes As brieﬂy discussed in Introduc-
tion, several previous studies [6, 36, 33, 13] had also studi ed
incorrect ﬁxes. Our work is complementary in several ways:
(1) we focus on large OS code, while previous studies focused
on certain types of applications. (2)We study both commer-
cial and open source code bases, while previous work studied
only either open source or commericial. (3) Previous stud-
ies more focused on measuring incorrect ﬁx ratios, while we
went much beyond and also studied what types of bug ﬁxes
are more error-prone, the common mistake patterns, as well
as the possible human reason in the development process for
introducing incorrect ﬁxes.
Śliwerski et al. [36] proposed an eﬀective way to auto-
matically locate ﬁx-inducing changes by linking a version
archive to a bug database. They studied the incorrect ﬁxratio in Eclipse and Mozilla and also found developers are
easier to make incorrect changes on Friday. Purushothaman
et al. [33] studied the incorrect ﬁx ratio in a switching sys-
tem from Lucent, but their focus was the impact of one-line
changes. Gu et al. [13] studied the incorrect ﬁx ratio in three
Apache projects, but they focused on providing a tool to val-
idate the patch. Baker et al. [6] visualized the incorrect ﬁx
ratio for a switch system in AT&T.
Human factors The inﬂuence of code knowledge on gen-
eral code changes had been explored in [34, 26]. Mockus
et al. [26] found that changes made by more experienced
developers were less likely to induce failures. Rahman et
al.[34] found ﬁle owner with higher knowledge is less as-
sociated with ﬁx-inducing code. Our study focused on bug
ﬁxes and measured the knowledge of the ﬁxers who made the
incorrect ﬁxes in commercial and widely used open source
OSes. We found 27% of the incorrect ﬁxes are made by
ﬁxers with zero knowledge, suggesting there might be some
ﬂaws in the overall bug assignment process. Some work [3,
24] also studied human factors for designing recommenda-
tion systems. Anvik et al. [3] suggested to assign ﬁxer based
on bug history. McDonald et al. [24] suggested to ﬁnd the
person who last modiﬁed the code. We proposed to assign
ﬁxer/reviewer based on code knowledge deﬁned at line level.
Besides, other aspects of human factors had also been stud-
ied. Meneely et al. [25] found that independent developer
groups were more likely to introduce a vulnerability. Bird
et al. [7] found that a binary might be more buggy if more
developers are working on it. Nagappan et al. [27] studied
the organizational structure and used it to build model to
predict the failure proneness in Windows Vista.
Taming incorrect ﬁxes There are diﬀerent ways to solve
the problem of incorrect ﬁxes including predicting or isola t-
ing buggy changes [37, 18, 23, 44], patch validation [13, 39] ,
automatic patching [32] and regression testing [35, 29]. Śl iw-
erski et al. built a plug-in for Eclipse which shows the risk of
changing a particular code location based on previous revi-
sion information. Kim et al. [18] also leveraged the historical
source repository data to train models for predicting the co r-
rectness of a future change. McCamant et al. [23] compared
operational abstractions generated from the old component
and the new component to predict the safety of a component
upgrade. Zeller et al. [44] proposed automated delta debug-
ging to locate the bug introducing changes. ClearView [32]
automatically generates patches without human interven-
tion, which can reduce the chance of incorrect ﬁxes. Besides ,
regression testing [35, 29] is also a common practise to ensu re
patches don’t break the previously working functionalitie s.
Our study discovered some incorrect ﬁx patterns which are
helpful for detecting/exposing/avoiding incorrect ﬁxes. We
studied what mistakes programmers should be aware of dur-
ing bug ﬁxing, which are also useful to design new detection
tools to detect errors in ﬁxes. Besides, we also proposed a
bug assignment process based on code knowledge, which is
being implemented by a large software vendor.
7. CONCLUSION ANDFUTURE WORK
This paper presents one of the most comprehensive char-
acteristic studies on incorrect bug-ﬁxes from large operat -
ing system code bases, including a commercial OS project.
We ﬁrst studied the ratio and impact of incorrect ﬁxes, and
found incorrect ﬁx is a signiﬁcant problem that requires spe -cial attention. We also studied the common patterns of mis-
takes made in incorrect ﬁxes that can be used to alert the
programmers as well as to design detection tools to catch
incorrect ﬁxes. We ﬁnally studied the code knowledge of
developers and found 27% of incorrect ﬁxes are made by de-
velopers who have not contributed a single line to the entire
ﬁle they are about to ﬁx. A tool based on our ﬁndings to
assign the most-knowledgeable developer to ﬁx/review the
bug is being built into the bug assignment process of a large
software vendor.
Though we had already done some preliminary study on
the the ﬁxes to semantics bugs, there are still some inter-
esting questions waiting to be answered considering their
diversity. Therefore, we plan to have a more comprehensive
study on the ﬁxes to semantics bugs in the future. Besides,
we also plan to extend the characteristic study to non-OS
applications, such as server applications and client appli ca-
tions. Another possible direction we want to proceed is to
build some checkers to detect incorrect ﬁxes based on the
patterns we learned.
8. REFERENCES
[1] Microsoft security bulletin. http:
//www.microsoft.com/technet/security/current.aspx .
[2] After buggy patch, criminals exploit Windows ﬂaw.
http://www.infoworld.com/d/security-central/
after-buggy-patch-criminals-exploit-windows-flaw-84 8.
[3] J. Anvik, L. Hiew, and G. C. Murphy. Who should ﬁx this
bug? In ICSE’06 .
[4] Apple updates leopard again.
http://voices.washingtonpost.com/fasterforward/2008 /
02/apple_updates_leopardagain.html .
[5] A. Bachmann, C. Bird, F. Rahman, P. Devanbu, and
A. Bernstein. The missing links: Bugs and bug-ﬁx commits.
InFSE’10 .
[6] M. J. Baker and S. G. Eick. Visualizing software systems.
InICSE’94 .
[7] C. Bird, N. Nagappan, P. Devanbu, H. Gall, and
B. Murphy. Does distributed development aﬀect software
quality? An empirical case study of Windows Vista. In
ICSE’09 .
[8] Buggy McAfee update whacks Windows XP PCs.
http://news.cnet.com/8301-1009_3-20003074-83.html .
[9] D. Engler and K. Ashcraft. RacerX: eﬀective, static
detection of race conditions and deadlocks. In SOSP’03 .
[10] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf.
Bugs as deviant behavior: a general approach to inferring
errors in systems code. In SOSP’01 .
[11] M. Fischer, M. Pinzger, and H. Gall. Populating a releas e
history database from version control and bug tracking
systems. In ICSM’03 .
[12] K. B. Gallagher and J. R. Lyle. Using program slicing in
software maintenance. IEEE Transactions on Software
Engineering , 17(8):751–761, 1991.
[13] Z. Gu, E. T.Barr, D. J.Hamilton, and Z. Su. Has the bug
really been ﬁxed? In ICSE’10 .
[14] M. Harman, D. Binkley, and S. Danicic. Amorphous
program slicing. Journal of Systems and Software ,
68(1):45–64, October 2003.
[15] Intel reissues buggy patch. http://www.pcworld.com/
businesscenter/article/126918/rss.html .
[16] D. Kawrykow and M. P. Robillard. Non-essential changes
in version histories. In ICSE’11 , May 2011.
[17] S. Kim, K. Pan, and J. E. James Whitehead. Memories of
bug ﬁxes. In FSE’06 , November 2006.
[18] S. Kim, E. J. Whitehead, Jr., and Y. Zhang. ClassifyingSoftware Changes: Clean or Buggy? IEEE Trans. Software
Engineering , 34(2):181–196, March 2008.
[19] Z. Li, L. Tan, X. Wang, S. Lu, Y. Zhou, and C. Zhai. Have
things changed now? An empirical study of bug
characteristics in modern open source software. In ASID’06 .
[20] Z. Li and Y. Zhou. PR-Miner: Automatically extracting
implicit programming rules and detecting violations in
large software code. In FSE’05 .
[21] S. Lu, S. Park, E. Seo, and Y. Zhou. Learning from
mistakes – a comprehensive study on real world
concurrency bug characteristics. In ASPLOS , March 2008.
[22] McAfee to reimburse customers for bad patch. http://www.
computerworlduk.com/technology/security-products/
prevention/news/index.cfm?newsId=20005 .
[23] S. McCamant and M. D. Ernst. Predicting problems caused
by component upgrades. In FSE’03 .
[24] D. W. McDonald and M. S. Ackerman. Expertise
recommender: a ﬂexible recommendation system and
architecture. In CSCW’00 .
[25] A. Meneely and L. Williams. Secure open source
collaboration: An empirical study of linus’s law. In CCS’09 .
[26] A. Mockus and D. M. Weiss. Predicting risk of software
changes. Bell Labs Technical Journal , 5:169–180, 2000.
[27] N. Nagappan, B. Murphy, and V. R. Basili. The inﬂuence
of organizational structure on software quality. In ICSE’08 .
[28] T. T. Nguyen, H. A. Nguyen, N. H. Pham, J. Al-Kofahi,
and T. N. Nguyen. Recurring bug ﬁxes in object-oriented
programs. In ICSE’10 , May 2010.
[29] A. Orso, N. Shi, and M. J. Harrold. Scaling regression
testing to large software systems. In FSE’04 .
[30] Y. Padioleau, J. Lawall, R. R. Hansen, and G. Muller.
Documenting and automating collateral evolutions in linux
device drivers. In Eurosys’08 .
[31] K. Pan, S. Kim, and J. E. James Whitehead. Toward an
understanding of bug ﬁx patterns. Empirical Software
Engineering , 14(3):286–315, November 2009.
[32] J. H. Perkins, S. Kim, S. Larseng, S. Amarasinghe,
J. Bachrach, M. Carbin, C. Pachecod, F. Sherwood,
S. Sidiroglou, G. Sullivan, W.-F. Wong, Y. Zibin, M. D.
Ernst, and M. Rinard. Automatically patching errors in
deployed software. In SOSP’09 , October 2009.
[33] R. Purushothaman and D. E. Perry. Towards
understanding the rhetoric of small changes. In MSR’04 .
[34] F. Rahman and P. Devanbu. Ownership and experience in
ﬁx-inducing code. In UC Davis Department of Computer
Science, Technical Report CSE-2010-4 , 2010.
[35] G. Rothermel, R. H. Untch, C. Chu, and M. J. Harrold.
Prioritizing test cases for regression testing. IEEE
Transactions on Software Engineering , 27:929–948, 2001.
[36] J. Śliwerski, T. Zimmermann, and A. Zeller. When do
changes induce ﬁxes? In MSR’05 .
[37] J. Śliwerski, T. Zimmermann, and A. Zeller. Hatari:
Raising risk awareness (research demonstration). In
FSE’05 , September 2005.
[38] L. Tan, D. Yuan, and Y. Zhou. /* icomment: Bugs or bad
comments? */. In SOSP , October 2007.
[39] J. Tucek, W. Xiong, and Y. Zhou. Eﬃcient online
validationwith delta execution. In ASPLOS’09 .
[40] D. Čubranić and G. C. Murphy. Hipikat: Recommending
pertinent software development artifacts. In ICSE’03 .
[41] M. Weiser. Program slicing. In ICSE’83 .
[42] Z. Yin, M. Caesar, and Y. Zhou. Towards understanding
bugs in open source router software. ACM SIGCOMM
Computer Communication Review , 40(3):34–40, July 2010.
[43] D. Yuan, H. Mai, W. Xiong, L. Tan, Y. Zhou, and
S. Pasupathy. Sherlog: error diagnosis by connecting clues
from run-time logs. In ASPLOS’10 .
[44] A. Zeller. Yesterday, my program worked. today, it does
not. why? In FSE’99 .