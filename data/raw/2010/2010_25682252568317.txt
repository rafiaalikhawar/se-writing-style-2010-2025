Mining Fine-Grained Code Changes to Detect Unknown
Change Patterns
Stas Negara
University of Illinois
Urbana, IL, USA
snegara2@illinois.eduMihai Codoban
Oregon State University
Corvallis, OR, USA
codobanm@eecs.oregonstate.eduDanny Dig
Oregon State University
Corvallis, OR, USA
digd@eecs.oregonstate.edu
Ralph E. Johnson
University of Illinois
Urbana, IL, USA
rjohnson@illinois.edu
ABSTRACT
Identifying repetitive code changes benets developers, tool
builders, and researchers. Tool builders can automate the
popular code changes, thus improving the productivity of de-
velopers. Researchers can better understand the practice of
code evolution, advancing existing code assistance tools and
beneting developers even further. Unfortunately, existing
research either predominantly uses coarse-grained Version
Control System (VCS) snapshots as the primary source of
code evolution data or considers only a small subset of pro-
gram transformations of a single kind | refactorings.
We present the rst approach that identies previously
unknown frequent code change patterns from a ne-grained
sequence of code changes. Our novel algorithm eectively
handles challenges that distinguish continuous code change
pattern mining from the existing data mining techniques.
We evaluated our algorithm on 1,520 hours of code devel-
opment collected from 23 developers, and showed that it is
eective, useful, and scales to large amounts of data. We
analyzed some of the mined code change patterns and dis-
covered ten popular kinds of high-level program transfor-
mations. More than half of our 420 survey participants ac-
knowledged that eight out of ten transformations are rele-
vant to their programming activities.
Categories and Subject Descriptors: D.2.7 [Software
Engineering]: Distribution, Maintenance, and Enhancement
General Terms: Algorithms, Experimentation
Keywords: Program Transformation, Code Changes, Data
Mining
1. INTRODUCTION
Many code changes are repetitive by nature [14, 17, 25],
thus forming code change patterns . Frequent pattern min-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proÔ¨Åt or commercial advantage and that copies
bear this notice and the full citation on the Ô¨Årst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc
permission and/or a fee.
ICSE ‚Äô14, May 31 ‚Äì June 7, 2014, Hyderabad, India
Copyright 14 ACM 978-1-4503-2756-5/14/05 ...$15.00.ing [12] is successfully applied in a broad range of domains.
For example, Amazon.com recommends related products ba-
sed on\customers who bought this also bought that". Netix
recommends new movies based on \customers who watched
this also watched that". Similar frequent pattern mining has
revolutionized other services such as iTunes, GoodReads, so-
cial platforms, etc. More recently, data mining techniques
became popular in the domain of genetics [27, 29, 31]. In
particular, these techniques are employed to identify similar
sequences of genes, which is a common task in DNA stud-
ies. We conjecture that mining frequent code changes can
be similarly transformative for software development.
Identifying frequent code change patterns benets Inte-
grated Development Environment (IDE) designers, code evo-
lution researchers, and developers. IDE designers can build
tools that automate execution of frequent code changes,
recommend code changes, or oer intelligent code comple-
tion [3, 24, 26], thus improving the productivity of develop-
ers. Researchers would better understand the practice of
code evolution and also would be able to focus their atten-
tion on the most popular development scenarios. Library
developers can notice and x the common mistakes in the
library API usage.
Existing research [3{5,15,19,21,30,32,35,36,39] predomi-
nantly detects frequent code change patterns either analyz-
ing the static source code of a single version of an applica-
tion or comparing the application's Version Control System
(VCS) snapshots. In our previous study [23], we showed that
data stored in VCS is imprecise ,incomplete , and makes it
impossible to perform analysis that involves the time dimen-
sion inside a single VCS snapshot. Recent research [9, 11]
considered more precise data captured directly from IDE,
but their code change identication techniques were limited
in two ways: (i) they were looking for a single kind of code
change patterns | refactorings, (ii) they considered only a
small subset of previously known kinds of refactorings.
In this paper, we employed data mining techniques to de-
tect previously unknown frequent code change patterns from
ane-grained sequence of code changes. Our mining al-
gorithm does not use any predened templates to look for
patterns, and thus, all patterns it detects are previously un-
known. We recorded the code changes as soon as they were
produced by developers. Consequently, our algorithm's in-
put sequence is the most ne-grained and precise represen-
tation of code evolution.Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ICSE‚Äô14 , May 31 ‚Äì June 7, 2014, Hyderabad, India
Copyright 2014 ACM 978-1-4503-2756-5/14/05...$15.00
http://dx.doi.org/10.1145/2568225.2568317
803
There are unique challenges posed by our problem domain
of program transformations, which render previous o-the-
shelf data mining techniques [12] inapplicable. First, for
program transformations, we need to mine a continuous se-
quence of code changes that are ordered by their timestamps,
without any previous knowledge of where the boundaries be-
tween patterns of transformations are. In contrast, standard
data mining techniques operate on a database of transac-
tions with well known boundaries. Second, unlike the stan-
dard frequent itemset mining [1,13,37,38], when mining fre-
quent code change patterns, a high-level program transfor-
mation corresponding to a given pattern may contain sev-
eral instances of the same kind of code change. For example,
Rename Local Variable refactoring involves the same change
for all references of the renamed variable. Consequently, in
our mining problem, a transaction may contain multiple in-
stances of the same item kind, thus forming itembags rather
than itemsets.
In this paper, we present our novel frequent code change
patterns mining algorithm that eectively handles both chal-
lenges specic to our mining problem. We applied our algo-
rithm on a large corpus of real world data that we collected
during our previous user study [23], in which we accumu-
lated 1,520 hours of code development from 23 developers
working in their natural settings. Our evaluation shows that
our algorithm is eective, useful, and scales well for large
amounts of data. In particular, our algorithm mined more
than half a million of item instances in less than six hours.
We analyzed some of the frequent code change patterns de-
tected by our algorithm and identied ten kinds of popular
high-level program transformations. On average, 32% of the
pattern occurrences reported by the algorithm led to high-
level program transformation discoveries.
To assess the popularity of the identied high-level pro-
gram transformations, we conducted a survey study with
420 participants. More than half of our survey participants
found eight out of ten kinds of program transformations
relevant to their programming activities. Moreover, most
participants regularly perform six transformation kinds and
would like to get automated support for ve transforma-
tion kinds. These results conrm that our mining algorithm
helps identify useful and popular program transformations.
This paper makes the following contributions:
Algorithm: We designed a novel algorithm that eec-
tively addresses the challenges of frequent code change
patterns mining.
Implementation: We implemented our algorithm as
part of CodingTracker .CodingTracker is open sour-
ce and is available at
http://codingtracker.web.engr.illinois.edu.
Evaluation: We evaluated our algorithm on 1,520
hours of real world code development data and showed
that it is eective, useful, and scalable.
Results: We analyzed some of the mined code change
patterns and identied ten kinds of popular high-level
program transformations.
2. MOTIVATING EXAMPLE
Figure 1 shows a code editing example in which a de-
veloper repeatedly applies a high-level program transforma-
tion. In this and all subsequent examples of program trans-
formations, we represent the changed parts of code as un-
derlined text. Figure 1 shows that the developer edits two
double getDistance(Point p1, Point p2) {
  ...
}
float computeDirection(Point o, Point p) {
  ...
}Before
After
double computeDistance(Point p1, Point p2) {
  if (p1.equals(p2)) return 0;
  ...
}
double computeDirection(Point o, Point p) {
  if (o.equals(p)) return 0;
  ...
}Figure 1: An example of a repeated high-level pro-
gram transformation. Changed code is underlined.
methods, getDistance and computeDirection . Method get-
Distance computes distance between two points, p1and p2.
Method computeDirection computes a direction angle from
some origin point oto a given point p. In this code editing
example, the developer rst renames getDistance tocompute-
Distance to better reect its meaning. Then, the developer
decides to increase accuracy of direction angle computation
and changes accordingly the return type of computeDirection
method from float todouble . Finally, the developer im-
proves the performance of both methods | if the method's
arguments are equal, the method returns 0without perform-
ing any additional computations. We call this high-level
program transformation Return If Arguments Are Equal.
Table 1 shows code changes of the code editing scenario
in Figure 1. The rst column presents the relative order of
the changes. Note, however, that the ordering of changes is
partial. For example, according to the code editing scenario
in Figure 1, change 2 happened after change 1. At the same
time, the relative order of changes 3 { 9 is undened. The
second and the third columns correspondingly show the kind
of the Abstract Syntax Tree (AST) node operation and the
aected AST node's type. The next column presents the
content of the aected AST node (or the content's change
forchange operations). We explain the content of the last
column in the following section.
Given a sequence of code changes like the one in Table 1,
we would like to identify repetitive code change patterns that
correspond to some high-level program transformations. For
example, we would like to detect that code changes 3 { 9 and
10 { 16 represent the same code change pattern | the pat-
tern of high-level program transformation Return If Argu-
ments Are Equal. To achieve this goal, we use data mining
techniques. In the following section, we discuss how our
approach diers from the canonical data mining problem.
3. BACKGROUND
Denition 1 (Code Change): A code change is a pair
(<operation kind>, <AST node type>) .
We ignore the contents of the aected AST nodes to avoid
making our code changes too specic. Too specic represen-
tation hinders detecting similar changes, e.g., changes 9 and
16 in Table 1 would be dierent, if we considered the aected
nodes' contents.
Denition 2 (Code Change Pattern): A code change pat-
tern is an unordered bagof code changes.804Table 1: Code changes of the code editing scenario in Figure 1.
Order index Operation AST node type AST node content change Item
1 change SimpleName getDistance!computeDistance a
2 change PrimitiveType float!double b
3 add SimpleName p1 c
4 add SimpleName equals c
5 add SimpleName p2 c
6 add MethodInvocation p1.equals(p2) d
7 add NumberLiteral 0 e
8 add ReturnStatement return 0 f
9 add IfStatement if (p1.equals(p2)) return 0 g
10 add SimpleName o c
11 add SimpleName equals c
12 add SimpleName p c
13 add MethodInvocation o.equals(p) d
14 add NumberLiteral 0 e
15 add ReturnStatement return 0 f
16 add IfStatement if (o.equals(p)) return 0 g
Note that a code change pattern is a bag rather than a set,
since the same code change might occur several times in a
pattern, e.g., (add, SimpleName) occurs three times in the
pattern of transformation Return If Arguments Are Equal.
In data mining terminology, an item corresponds to our
code change and an itembag corresponds to our code change
pattern. For brevity, items are usually represented as char-
acters. The last column of Table 1 shows the items corre-
sponding to every distinct code change. For example, item c
corresponds to code change (add, SimpleName) , while item
d| to code change (add, MethodInvocation) .
The number of repetitions of a pattern (itembag) is called
frequency . For example, the frequency of a pattern con-
taining only item cis 6. Note, however, that our goal is
to detect full code change patterns rather than their parts
(i.e., we would like to detect a pattern with code changes 3
{ 9 rather than 3 { 7 or 5 { 8, or any other subset of code
changes). Therefore, we mine closed itembags, i.e., item-
bags that are not part of a bigger itembag with the same
frequency. In other words, a closed itembag represents the
maximal size code change pattern for a given frequency.
To discuss how our problem of mining frequent code chan-
ge patterns diers from the canonical one, we rst present
several denitions from the data mining domain.
Denition 3 (Transaction): A transaction is a tuple
< tid; X > , where tidis a unique transaction identier and
Xis a set of items.
Denition 4 (Transaction Database): A transaction data-
baseDis a set of transactions.
The canonical problem of mining frequent itemsets from a
given transaction database Dconsists in nding all itemsets,
whose frequency is not lower than a user-specied minimum
frequency threshold. Thus, the o-the-shelf data mining al-
gorithms are designed to mine itemsets rather than item-
bags. Also, they assume that transactions are disjoint.
For code change mining, a transaction is a window in
which an algorithm looks for a pattern. The size of the win-
dow determines the maximum size of a pattern that a mining
algorithm can detect. To mine the actual code changes, we
use a time window, while for presentation purposes, we de-
ne the size of a window as the number of code changes.
For example, let's consider that our window is of size eight.
Then, according to Table 1, we have two disjoint windows
a  b  c  c  c  d  e  f  g  c  c  c  d  e  f  g1   2    3    4   5    6   7    8   9   10  11 12  13 14  15 16
Transaction 1
Transaction 2
Transaction 3Figure 2: The overlapping transactions of size eight
for the sequence of code changes from Table 1.
(transactions), the rst spans code changes 1 { 8, and the
second | changes 9 { 16. As a result, the pattern with
code changes 3 { 9 crosses the boundary between windows.
Consequently, an o-the-shelf mining algorithm would not
be able to correctly detect the whole pattern. To avoid this
problem, we designed a mining algorithm that uses overlap-
ping windows (transactions).
Figure 2 shows overlapping transactions of size eight for
the sequence of code changes from Table 1. The number
above each item reects the order index of the corresponding
code change. We use these numbers as IDs that help dis-
tinguish separate occurrences of the same item in the same
transaction. For example, three occurrences of item cin the
rst transaction have IDs 3, 4, and 5.
Note, however, that just overlapping transactions of size
eight is insucient to detect code change patterns of size
eight. In particular, Figure 2 shows that the pattern with
code changes 3 { 9 still crosses the boundary between trans-
actions. Consequently, the size of a transaction should be
larger than the maximum-size pattern we are looking for.
In the following section, we present the high-level overview
of our mining algorithm and discuss handling of overlapping
transactions and itembags in more detail.
4. OVERVIEW OF OUR ALGORITHM
Denition 5 (Vertical Data Format): The vertical data
format represents a transaction database as a set of tuples
< item; tidset > , where tidset is a set of identiers of trans-
actions that contain the corresponding item .
Table 2 shows the transaction database in the vertical data
format for the items from Table 1 according to transactions
in Figure 2. Note that to present the basic idea of the verti-805Table 2: The items from Table 1 in the vertical data
format according to transactions in Figure 2.
Item Tidset
af1g
bf1g
cf1;2;3g
df1;2;3g
ef1;2;3g
ff1;2;3g
gf2;3g
cal data format mining algorithm, we rst disregard the fact
that items in Table 1 form itembags rather than itemsets and
are shared between overlapping transactions.
To accommodate such properties of code change pattern
mining as overlapping transactions and itembags, it is cru-
cial to access the transaction identiers directly while com-
puting new itemsets. The vertical data format grants such
access to a mining algorithm. Therefore, our approach is
inspired by several ideas from CHARM [38], an advanced al-
gorithm for mining data in the vertical data format, which
introduces the notion of itemset-tidset tree (IT-tree), em-
ploys several optimizations, and searches for closed itemsets,
thus considerably reducing the size of the mining result. In
particular, our algorithm extends the notion of IT-tree and
adapts several optimization insights of CHARM. We rst in-
troduce the basic idea of mining data in the vertical data for-
mat and present the CHARM's denition of IT-tree. Then,
we discuss how our approach builds upon CHARM to handle
overlapping transactions and itembags.
Denition 6 ( n-itemset): An n-itemset is an itemset that
contains nitems.
Denition 7 (Support of an Itemset): In a given trans-
action database D, the support of an itemset X, which we
denote as sup(X), is the number of transactions in Dthat
contain X. That is, sup(X) =jt(X)j.
Eclat [37] is the rst algorithm for mining data in the ver-
tical data format without candidate generation. The basic
idea of the algorithm is to compute ( n+ 1)-itemsets from n-
itemsets by intersecting their tidsets. The algorithm starts
with frequent 1-itemsets and nishes when no more frequent
itemsets can be found. For example, let's consider two 1-
itemsets,fagandfbg, from Table 2 (note that for any item
xthere is a corresponding 1-itemset fxg). The algorithm
computes the tidset of a 2-itemset fa; bgby intersecting the
tidsets offagandfbg:t(fa; bg) =t(fag)\t(fbg) =f1g. The
support of the itemset fa; bgis 1:sup(fa; bg) =jt(fa; bg)j=
1. If the minimum frequency threshold is greater than 1,
then itemsetfa; bgis discarded. Otherwise, it is added to
the results and considered for computing 3-itemsets.
The nodes in an IT-tree are pairs itemset :tidset . The
root of the tree represents an empty itemset, and thus, its
tidset is T, the set of all tids. The immediate children of the
root node are 1-itemsets that are computed by scanning the
transaction database. The immediate children of a non-root
node are computed by intersecting this node's tidset with
the tidsets of the not yet considered 1-itemsets, traversing
them from left to right. If the resulting tidset's size falls
below the minimum frequency threshold, the new node is
not added to the IT-tree. The IT-tree is completed when no
more nodes can be added to it. Figure 3 shows the partially
completed rst three levels of the IT-tree for the transaction
database from Table 2. The rst level of the tree consistsof the 1-itemsets from the database that are paired with
their tids, e.g.,fag:f1g,fbg:f1g,fcg:f1;2;3g, etc. The
following levels are computed according to the procedure
described above. For example, node fa; bg:f1gis the result
of combination of nodes fag:f1gandfbg:f1g.
Handling overlapping transactions and itembags.
We mine frequent code change patterns from an ordered se-
quence of code changes (note that code changes are naturally
ordered according to when they happened, i.e., according to
their timestamps). To populate our transaction database,
we divide this continuous sequence into individual transac-
tions. Our code editing example in Section 2 shows that
making transactions disjoint and sizing them according to
the maximum length of a pattern, max length , does not ac-
count for patterns that cross the boundary of two transac-
tions. Therefore, we use overlapping transactions whose size
is 2max length . The size of the overlap between two neigh-
boring transactions is max length . As a result, our mining
algorithm nds all patterns whose length does not exceed
max length and some patterns whose length lies in between
max length and 2max length . Note that as an alternative
to overlapping transactions of size 2 max length , we could
employ a sliding window of transactions of size max length .
However, this approach would not simplify the algorithm
and would lead to a signicant increase in the number of
transactions, thus undermining the algorithm's scalability.
Figure 2 shows overlapping transactions of size eight for
the sequence of code changes from Table 1. Such choice of
transactions ensures that the algorithm detects all patterns
whose length does not exceed four. To detect the pattern
with code changes 3 { 9, which is of size seven, the size of
the transactions should be at least 14. We specify the size
of a transaction as the number of code changes (i.e., items)
for presentation purposes only, while for the actual mining,
we set max length to ve minutes, and thus, transactions
contained various numbers of items.
An important observation is that although code changes
form an ordered sequence, a code change pattern is un-
ordered because the corresponding high-level program trans-
formation may be performed in dierent orders. For ex-
ample, a developer who performs a Rename Local Variable
refactoring might rst change the variable's declaration and
then its references or vice versa, or even intersperse chang-
ing the declaration and the references. Thus, the order of a
transaction's items does not matter.
Another observation is that a high-level program trans-
formation may contain several instances of the same kind of
code change. For example, Rename Local Variable refac-
toring involves the same change for all references to the
renamed variable. Section 2 presents an example of an-
other high-level program transformation, Return If Argu-
ments Are Equal, that also contains multiple instances of the
same kind of code change, (add, SimpleName) . These ex-
amples show that for mining code change patterns, a trans-
action's items form a bag rather than a set. In particular,
the rst transaction in Figure 2 contains three items c.
The major dierence between our frequent code change
pattern mining algorithm and the existing approaches to
mining frequent itemsets is that our algorithm handles over-
lapping transactions and itembags rather than itemsets. To
distinguish dierent occurrences of an item in the same tran-
saction as well as the overlapped parts of two transactions,
our algorithm assigns a unique ID to each item's occur-806{} : {1, 2, 3}
{a} : {1} {b} : {1} {c} : {1, 2, 3} {d} : {1, 2, 3}
{a, b} : {1}{a, c} : {1}{a, d} : {1}{b, c} : {1}{b, d} : {1}
{a, b, c} : {1}{c, d} : {1, 2, 3} ...
...... ...
{a, b, d} : {1}......Figure 3: The partially completed rst three levels of the IT-tree for the transaction database from Table 2.
rence. The rst line in Figure 2 shows the IDs assigned
to the underlying items' occurrences. For example, the rst
transaction contains occurrences of item cwith IDsf3;4;5g,
the second transaction | f5;10;11;12g, and the third |
f10;11;12g. Although our algorithm handles itembags, we
use the notion of itemsets throughout our presentation, since
the fact that our itemsets are actually itembags is accounted
for by explicitly tracking each item's occurrences.
Tracking an item's occurrences. In order to track
items' occurrences, a node in our itemset-tidset tree (IT-
tree) is dened as follows:
[item 1; item 2; :::; item n] :
[tid1: [[occurrences 1];[occurrences 2]; :::;[occurrences n]];
tid2: [[occurrences 1];[occurrences 2]; :::;[occurrences n]];
:::;
tidm: [[occurrences 1];[occurrences 2]; :::;[occurrences n]]]
We use square brackets to denote ordered sets. The order
of items in an itemset does not matter for a pattern, but
it helps our algorithm to track occurrences of every item in
each transaction that contains this itemset. Thus, we repre-
sent an n-itemset as an ordered set of items [ item 1; item 2; :::;
item n]. For a given itemset, a node in an IT-tree contains an
ordered set of tids of transactions that contain this itemset.
Ordering of transactions enables our algorithm to eectively
handle overlapping parts of the neighboring transactions.
For each transaction, the IT-tree node also tracks all oc-
currences for every item in the given itemset (in the above
representation, [ occurrences i] are all occurrences of item i
in a particular transaction). Our algorithm also orders an
item's occurrences to ensure the optimal result of our item-
set frequency computation technique that we discuss below.
Similarly to CHARM [38], we compute our IT-tree by
traversing the 1-itemsets from left to right and intersect-
ing the tidset of a particular itemset with the tidsets of the
not yet considered 1-itemsets to generate new IT-tree nodes.
The major dierence from the CHARM's approach is that
our algorithm tracks items' occurrences, and thus, whenever
a new item is added to an itemset, the item's occurrences
are appended to the set of occurrences of every transaction
in the corresponding IT-tree node. Table 3 shows several
examples of itemsets and their corresponding IT-tree nodes
for the sequence of code changes from Figure 2. The third
row presents the IT-tree node for itemset fcg. The node con-
sists of the itemset itself, [ c], followed by tids of transactions
that this itemset appears in | 1 ;2;3. For each transac-
tion, the node tracks all occurrences of item c: transaction
1 contains occurrences 3 ;4;5, transaction 2 | 5 ;10;11;12,
and transaction 3 | 10 ;11;12. Note that storing an item's
occurrences in every IT-tree node that contains this item isTable 3: Examples of itemsets and their correspond-
ing IT-tree nodes for code changes from Figure 2.
Itemset IT-tree node
fag [a] : [1 : [[1]]]
fbg [b] : [1 : [[2]]]
fcg[c] : [1 : [[3 ;4;5]];2 : [[5 ;10;11;12]];3 : [[10 ;11;12]]]
fa; cg [a; c] : [1 : [[1] ;[3;4;5]]]
not only redundant, but also prohibitively expensive. In-
stead, our algorithm stores occurrences of individual items
and then just refers these occurrences from the containing
IT-tree nodes. We inline the referred occurrences for pre-
sentation purposes only.
Computing the frequency of an itemset. Due to
overlapping transactions and multiple occurrences of an item
in the same transaction, our algorithm cannot compute the
frequency of an itemset as the number of transactions that
contain this itemset (as it is done in the existing frequent
itemset mining techniques). Instead, we devised our own
frequency computation technique that accounts for the par-
ticularities of our mining problem. In a given transaction k:
tidk: [[occurrences 1];[occurrences 2]; :::;[occurrences n]]
the frequency of the corresponding itemset is:
fk= min
i=1::nj[occurrences i]j (1)
That is, fkis the number of occurrences of an itemset's
item that appears the least number of times. The overall
frequency of an itemset contained in mtransactions is:
F=mX
k=1fk (2)
If an item occurrence is shared between two neighbor-
ing transactions, kandl, the algorithm should count this
occurrence only once, either as part of fkor as part of
fl. In an ordered set of transactions, two transactions,
kandl, are neighboring if and only if jk lj= 1 and
jtidk tidlj= 1. That is, the neighboring transactions
follow each other both in the ordered set and in the orig-
inal sequence of code changes. For example, in Figure 2
transactions of the ordered set [1 ;2] are neighboring, while
transactions of the ordered set [1 ;3] are not neighboring.
Let's denote [ occurrencesk
i] the ordered set of occurrences
ofitem iin a transaction k. Let's denote ojan occurrence
owith the index jin the ordered set of occurrences. To
compute the frequency of an n-itemset that is contained in m
transactions, our algorithm visits each pair of transactions k
andk+ 1, where 1k < m . First, our algorithm computes
fkusing formula (1). Then, if transactions kandk+ 1807are neighboring, our algorithm visits every occurrence oj2
[occurrencesk
i], where 1in. Ifo2[occurrencesk+1
i],
then our algorithm checks whether the shared occurrence o
should be removed from the transaction kork+1. If jfk,
then ois removed from the transaction k+ 1. Otherwise,
it is removed from the transaction k. Note that removing
shared occurrences never aects the initially computed fk).
Finally, our algorithm computes the overall frequency using
formula (2).
For the best performance of our algorithm, we order an
item's occurrences such that those that happened earlier in
time appear earlier in the ordered set. Since occurrences' IDs
are generated incrementally (see Figure 2), such ordering is
easily achieved by sorting occurrences in ascending order of
their IDs. Consequently, the occurrences that are shared be-
tween transactions kandk+1 are placed at the end of the or-
dered set of all occurrences for the transaction k. Hence, our
algorithm computes the maximal possible frequency for the
transaction kemploying the shared occurrences only when
needed, while the unused part of them is attributed to the
subsequent transaction k+1, thus maximizing its frequency
too. Going through each pair of transactions kandk+ 1,
1k < m , our algorithm propagates this maximization,
thus computing the optimal overall frequency F.
More details about our mining algorithm, including opti-
mizations to handle large amounts of data, computation of
closed itemsets, and establishing the frequency thresholds
can be found in our technical report [22].
5. EVALUATION
In our evaluation, we would like to answer these questions:
Q1(scalability): Is our algorithm scalable to handle
large amounts of data?
Q2(eectiveness): Does our algorithm mine code chan-
ge patterns that simplify identication of high-level
program transformations?
Q3(usefulness): Are there useful high-level program
transformations among the mined code change pat-
terns?
To answer these questions, we applied our frequent code
change pattern mining algorithm on a large corpus of real
world data. In the following, we rst describe how we col-
lected the data and performed the evaluation of the algo-
rithm. Then, we present our results.
5.1 Experimental Setup
To evaluate our mining algorithm, we rst applied it on
the previously collected code development data. We ana-
lyzed the mining results and identied ten kinds of high-
level program transformations. Then, we performed a sur-
vey study to assess the popularity of the identied transfor-
mation kinds.
5.1.1 Mining Code Changes
We applied our algorithm on the data collected during our
previous user study [23], which involved 23 participants: ten
professional programmers who worked on dierent projects
in domains such as marketing, banking, business process
management, and database management; and 13 Computer
Science graduate students and senior undergraduate summer
interns who worked on a variety of research projects from
six research labs at the University of Illinois at U-C.According to the responses of our participants, 1, 4, 11,
and 6 of them had 1 { 2, 2 { 5, 5 { 10, and more than 10
years of programming experience, respectively. In the course
of our study, we collected code evolution data for 1,520 hours
of code development with a mean distribution of 66 hours
per developer and a standard deviation of 52.
The participants of our study installed the CodingTracker
plug-in in their Eclipse IDEs. Throughout the study, Cod-
ingTracker recorded the detailed code evolution data rang-
ing from individual code edits up to the high-level events
like automated refactoring invocations. CodingTracker up-
loaded the collected data to our centralized repository using
the existing infrastructure [33].
We rst applied our AST node operations inference al-
gorithm [23] on the collected raw data to represent code
changes as add,delete , and update operations on the un-
derlying AST. Next, we represented distinct kinds of code
changes as combinations of the operation and the type of
the aected AST node. For example, (add, IfStatement) ,
(delete, IfStatement) , and (add, InfixExpression) are
three dierent kinds of code changes. The instances of code
change kinds serve as input to our frequent code change pat-
tern mining algorithm. That is, in our mining algorithm, a
code change kind is an item and an instance of a code change
kind is an item's occurrence .
For each mined code change pattern, our algorithm re-
ports all occurrences of the pattern in the input sequence of
code changes. We use CodingTracker 's replayer to man-
ually investigate these occurrences. We replay the code
changes of a particular occurrence to detect the correspond-
ing high-level program transformation.
Since the mining result is huge, we order the mined pat-
terns along three dimensions: by frequency of the pattern
(F), by size of the pattern ( S), and by FS. Then, we
output the top 1,000 patterns for each dimension and inves-
tigate them starting from the top of the list.
We noticed that some items (i.e., atomic AST node op-
erations like (add, IfStatement) ) are much more frequent
than the others. Thus, using xed threshold values to an-
alyze our data is not practical. If these values are too low,
our algorithm's scalability would degrade, while the output
would become disproportionately big. On the other hand,
too high values would hinder the mining of patterns that
involve less frequent items. Therefore, we divided the input
items into three groups, applying dierent threshold values
to each. Table 4 shows all three groups as well as the corre-
sponding thresholds and the mining time. The absolute fre-
quency threshold ensures that the frequency of a code change
pattern does not fall below a particular absolute value. The
dynamic threshold represents a pattern's frequency multi-
plied by its size, thus ensuring that the longer a pattern is,
the less frequent it can be in order to pass the threshold.
More details can be found in our technical report [22]. We
performed all mining on a quad-core i7 2GHz machine with
8GB of RAM.
We observed that some AST node operations are too fre-
quent to be considered at all. For example, adding and
deleting SimpleName accompanies any code change that de-
clares or references a program entity. Consequently, mining
items that represent such AST node operations would only
add noise to the detected code change patterns. Therefore,
before applying our algorithm, we ltered out the noisy item
kinds, thus reducing the number of item kinds from 162 to808Table 4: Grouping of item kinds by their frequency.
Column NK shows the number of item kinds in each
group. Columns AFT and DT show the values of the
absolute frequency and dynamic thresholds.
Frequency, FNK AFT DT Mining time
10;000F 23 30 10,000 15 minutes
300F < 10;000 81 30 300 5.2 hours
5F < 300 32 5 5 7.7 seconds
138. According to Table 9, the total number of the consid-
ered item kinds is 136, which means that two item kinds
were too infrequent to be part of any group.
5.1.2 Survey Study
To assess the popularity of the identied transformations,
we conducted a survey study with 420 participants. To re-
cruit our participants, we promoted the survey on Twitter
and Google+ feeds that are mainly read by developers. We
also released our survey on checkbox.io, a platform for soft-
ware engineering empirical research.
For each transformation, our survey contains three ques-
tions | the rst and the third are multiple-choice, while the
second is Likert scale:
Do you nd this kind of change interesting, relevant, or
applicable to your programming activities?
How often have you manually performed this kind of
change?
Would you like your IDE to provide automated support
for this change?
Tables 5, 6, 7, and 8 show that the majority of the devel-
opers who participated in our survey study are from indus-
try, have more than ve years of programming experience,
and often employ refactoring and code completion features
of their IDEs. The column IDK abbreviates the \I do not
know" answer of our participants.
Table 5: Programming experience in years (%).
0 - 2 2 - 5 5 - 10 10 - 15 15 - 20 more than 20
2.87 21.05 31.34 25.60 7.18 11.96
Table 6: Software project type (%).
Open Source Personal/Class Proprietary Research
7.18 10.77 76.32 5.74
5.2 Results
Table 9 summarizes performance statistics of our experi-
ment. Our algorithm mined more than half a million item
occurrences in less than six hours, and thus, the answer
to the rst question is that our mining algorithm is
suciently scalable to handle large amounts of data
with the appropriate threshold values .
The frequent patterns mined by our algorithm helped us
identify ten new kinds of program transformations. Note
that among the mined patterns we encountered those that
pointed to dierent kinds of refactorings (mostly Field Re-
name, Method Rename, and Change Method Signature),
but we disregarded them in this evaluation, since our goal
was to focus on new transformation kinds. The second au-
thor randomly picked 34 pattern occurrences among the top
mined patterns ordered by frequency, size, and frequency
multiplied by size. Out of 34 investigated occurrences, 11
were fruitful , i.e., the second author could describe them asTable 7: Usage of IDE refactoring features (%).
IDK Never Very rarely Sometimes Often
0.24 4.55 8.37 31.10 55.74
Table 8: Usage of IDE code completion features (%).
IDK Never Very rarely Sometimes Often
0.48 2.63 3.35 10.29 83.25
Table 9: Performance statistics of our experiment.
ItemTransactionsItem Total
kinds occurrences mining time
136 7,927 549,184 5.5 hours
high-level program transformations. Thus, 32% of investi-
gated pattern occurrences were fruitful. Therefore, our an-
swer to the second question is that our algorithm is
eective | it mines patterns that often lead to dis-
covery of new high-level program transformations .
Note that the number of fruitful pattern occurrences is a
lower bound. Although the second author could not give
meaning to 68% of investigated occurrences, some of them
might be considered high-level program transformations by
a developer more familiar with the underlying code.
Table 10 shows the identied kinds of program transfor-
mations grouped according to their scope. The last two
columns of the table show the number of pattern occur-
rences that we investigated and the number of pattern oc-
currences that led to the discovery of the corresponding pro-
gram transformations. In the following, we present the dis-
covered transformation kinds in more detail.
Table 10: Identied kinds of program transforma-
tions. Column I shows the number of the inves-
tigated pattern occurrences. Column F shows the
number of pattern occurrences that were fruitful.
Scope Identied program transformation IF
Statement Convert Element to Collection 52
Loop Add a Loop Collector 31
MethodAdd Null Check for a Parameter 51
Wrap Code with Timer 21
ClassAdd a New Enum Element 21
Change and Propagate Field Type 31
Change Field to ThreadLocal 21
Copy Field Initializer 21
Create and Initialize a New Field 41
Move Interface Implementation to Inner Class 61
Convert Element to Collection. This is a statement-
level transformation in which a developer converts a eld,
parameter, or a local variable of a certain type into a collec-
tion (e.g., list, set, array, etc.) of that type. All references
to the element need to be updated accordingly.
Before After
void start(Car car){
car.start();
}void start( List<Car> cars){
for(Car car : cars)
car.start();
}
Add a Loop Collector. This is a transformation in
which a developer introduces a new variable that collects or
aggregates the data processed in a loop.809Before After
for (Task t : tasks){
t.execute();
}Set<TaskResult> results = new HashSet<>();
for (Task t : tasks){
t.execute();
results.add(t.getResult());
}
Wrap Code with Timer. A developer applies this
transformation to compute the execution time of a code
fragment, e.g., a loop. The developer surrounds the code
with variables that hold the time before and after the code's
execution and outputs the time dierence.
Before After
for(i = 0; i < 1000; i++)
if (isPrime(i)) println(i);long start = System.currentTimeinMillis();
for(i = 0; i < 1000; i++)
if (isPrime(i)) println(i);
long end = System.currentTimeinMillis();
long totalTime = end ‚Äì start;
Add Null Check for a Parameter. This is a transfor-
mation in which a developer adds null precondition checks
to all methods of a class that receive a particular parame-
ter such that the methods' bodies are not executed if the
parameter is null.
Before After
void addPerson(Person p){
‚Ä¶
registry.add(p);
‚Ä¶
}
Record retrieveRecordsFor(Person p){
‚Ä¶ 
registry.retrieveRecords(p);
‚Ä¶ 
}void addPerson(Person p){
if (p == null) return;
‚Ä¶
registry.add(p);
‚Ä¶
}
Record retrieveRecordsFor(Person p){
if (p == null) return null;
‚Ä¶ 
registry.retrieveRecords(p);
‚Ä¶ 
}
Add a New Enum Element. Adding a new element to
enum triggers a ripple of changes such as adding new switch
cases, if-then-else chains, and dealing with any duplicated
code that uses the updated enum.
Before After
enum EventType {START, STOP};
switch (e) {
  case START: ...
  case STOP: ...
}
if (e.isStart()) { ... }
if (e.isStop()) { ... }
EventDescriptor createDescriptor() {
  EventDescriptor ed = new EventDescriptor();
  ed.add(EvenType.START);
  ed.add(EvenType.STOP);
  return ed;
}enum EventType {START, STOP , PAUSE};
switch (e) {
  case START: ...
  case STOP: ...
  case PAUSE: ...
}
if (e.isStart()) { ... }
if (e.isStop()) { ... }
if (e.isPause()) { ... }
EventDescriptor createDescriptor() {
  EventDescriptor ed = new EventDescriptor();
  ed.add(EvenType.START);
  ed.add(EvenType.STOP);
  ed.add(EvenType.PAUSE);
  return ed;
}
Change and Propagate Field Type. This is a trans-
formation in which a developer changes the type of a eld.
As a result, the developer also has to update the type of some
local variables as well as the return type of some methods.
Before After
int mileage;
int getCurrentMileage(){
return mileage;
}
void updateMileage(int newMiles){
mileage += newMiles;
}long mileage;
long getCurrentMileage(){
return mileage;
}
void updateMileage( long newMiles){
mileage += newMiles;
}
Change Field to ThreadLocal. To improve thread
safety of an application, a developer may decide to convert
some elds to ThreadLocal . Besides changing the type and
the initialization of the converted eld, the developer also
has to modify all eld's accesses such that they use get()
and set() ofThreadLocal .
Before After
Cache c = new Cache();
void putInfo(String key, String value){
c.add(key, value);
}ThreadLocal< Cache> c = new ThreadLocal<>(){
protected Cache initialValue() {
return new Cache();
}
}
void putInfo(String key, String value){
c.get().add(key, value);
}
Copy Field Initializer. This is a transformation in
which a developer copies the same initializer to several elds.
Before After
class Cars {
   List<Car> compacts;
   List<Car> sedans;
   ...
}class Cars {
   List<Car> compacts = new ArrayList<>() ;
   List<Car> sedans = new ArrayList<>() ;
   ...
}
Create and Initialize a New Field. When a developer
adds a new eld, it has to be properly initialized alongside
the already present elds in constructors and other initial-
ization places (e.g., static initialization blocks).
Before After
class Car {
   private List<Valve> valves;
   public Car() {
      valves = new ArrayList<>();
      ...
   }
   ...
}class Car {
   private List<Valve> valves;
   private List<Wheel> wheels;
   public Car() {
      valves = new ArrayList<>();
      wheels = new ArrayList<>();
      ...
   }
   ...
}
Move Interface Implementation to Inner Class. In
this transformation, a developer moves the implementation
of an interface from a class to its newly created inner class.
Before After
class FolderNode implements SelectionListener{
   public void selected() {
      ...
   }
   ...
}class FolderNode {
   class SelectionBehaviour 
implements SelectionListener{
      public void selected() {
         ...
      }
   }
   ...
}
The mined code change patterns helped us identify ten
kinds of interesting program transformations whose scopes
range from individual statements to whole classes. Thus,
our answer to the third question is that our algo-
rithm is useful .
5.2.1 Survey Study Results
Table 11 ranks ten transformation kinds identied by our
mining algorithm according to the percentage of our survey
participants who reported them as relevant. More than half
of our participants recognized eight out of ten transforma-
tions as relevant to their programming activities.
Table 12 shows that more than 50% of developers who
completed our survey regularly (columns Sometimes and
Often ) applied six out of ten transformation kinds.
Table 13 shows that more than 50% of our survey study
participants would like to see ve out of ten transformation
kinds automated in their IDEs. Similarly to the existing au-
tomated refactorings, our automated transformations would
be interactive: the developer will guide the automated ex-
ecution of a transformation and provide the required input
values, e.g., specifying functionality of a new case statement
introduced by Add a New Enum Element transformation.810Table 11: Ranking of transformation kinds accord-
ing to the percentage of our survey participants who
reported them as interesting, relevant, or applicable
to their programming activities.
Change Field Type 93.15
Create and Initialize a New Field 86.68
Add Precondition Checks for a Parameter 76.64
Add a New Enum Element 75.91
Wrap Code with Timer 60.77
Add a Loop Collector 60.49
Copy Field Initializer 56.97
Convert Element to Collection 55.23
Move Interface Implementation to Inner Class 38.40
Change Field to ThreadLocal 28.15
Table 12: The fraction of our survey study par-
ticipants who applied the identied transformation
kinds with dierent frequency (%).
IDK Never Very rarely Sometimes Often
Create and Initialize... 0.49 2.93 10.76 30.07 55.75
Change Field Type 0.00 1.23 12.07 37.19 49.51
Add Precondition ... 0.49 4.90 22.30 25.98 46.32
Add a New Enum ... 1.23 6.63 31.94 34.89 25.31
Copy Field Initializer 1.00 12.75 35.25 30.75 20.25
Add a Loop Collector 1.49 10.95 33.83 34.83 18.91
Wrap Code with ... 0.49 10.95 41.36 28.95 18.25
Convert Element ... 0.98 9.80 52.94 27.45 8.82
Move Interface Impl... 2.01 34.92 37.19 19.35 6.53
Change Field to Thr... 1.75 40.15 44.39 11.22 2.49
6. THREATS TO VALIDITY
In our experiment, we used the output of the AST node
operations inference algorithm [23] to prepare the input to
our frequent code change pattern mining algorithm. Con-
sequently, imprecisions in the inferred AST node operations
could negatively aect our mining results. Note, however,
that our approach to mining frequent code change patterns
is independent of the way its input is produced.
We investigated the mined patterns manually, and thus,
might have missed some of their corresponding high-level
program transformations. Also, we investigated only a frac-
tion of the mining results. However, our experiment did not
aim at discovering all program transformations performed
by our participants. Instead, our goal was to show that
our algorithm mines patterns that eectively point to high-
level program transformations, and we believe that discov-
ering several such transformations in a reasonable amount
of time (identifying and documenting these transformations
took just a couple of days) supports this claim.
In our study, we collected code evolution data from devel-
opers who use Eclipse for Java programming. Consequently,
the identied high-level program transformations might not
be generalizable to other programming environments and
languages. Nevertheless, our approach to identifying such
transformations is orthogonal to the way developers make
their code changes.
Our dataset is not publicly available due the nondisclosure
agreement with our participants.
7. RELATED WORK
7.1 Mining Frequent Itemsets
The major challenge in mining frequent itemsets is to de-
velop scalable algorithms that can eectively handle largeTable 13: Survey study participants' preference for
automated IDE support (%).
Change Field Type 86.42
Create and Initialize a New Field 74.33
Add a New Enum Element 60.20
Add Precondition Checks for a Parameter 60.10
Wrap Code with Timer 57.32
Copy Field Initializer 44.22
Convert Element to Collection 43.52
Add a Loop Collector 42.12
Move Interface Implementation to Inner Class 33.42
Change Field to ThreadLocal 24.69
transaction databases. One of the fundamental distinctions
between dierent approaches to mining frequent itemsets is
whether mining is performed with or without candidate gen-
eration. Agrawal et al. [1] observed that an n-itemset is fre-
quent only if all its subsets are also frequent. Their mining
algorithm, Apriori, leverages this property by using frequent
n-itemsets to generate ( n+ 1)-itemset candidates. Apriori
checks the newly generated candidates against the transac-
tion database to establish those of them that are frequent.
The algorithm starts with detecting frequent 1-itemsets di-
rectly from the transaction database and proceeds iteratively
until no more frequent itemsets can be found.
Mining with candidate generation has two major draw-
backs: a) it generates redundant itemsets that are found to
be infrequent; b) it repeatedly scans the transaction databa-
se while progressing through the iterations. Mining without
candidate generation addresses both these limitations. Such
mining can be broadly divided into mining using horizon-
tal data format and mining using vertical data format . The
horizontal data format represents a transaction database as
a set of tuples < TransactionID; itemset > . Han et al. [13]
suggested to mine frequent itemsets without candidate gen-
eration using horizontal data format. Their frequent-pattern
growth (FP-growth) algorithm rst scans the database to
detect frequent 1-itemsets. The algorithm uses these 1-
itemsets to construct FP-tree, an extended prex-tree struc-
ture. Then, the algorithm expands the initial FP-tree by
growing pattern fragments in a recursive fashion.
Zaki [37] proposed a dierent approach to mining fre-
quent itemsets without candidate generation. His algorithm,
Eclat, explores the vertical data format, which explicitly
stores transactions' identiers (tidsets) for every itemset (li-
ke in Table 2). Eclat computes ( n+ 1)-itemsets from n-
itemsets by intersecting their tidsets. The algorithm collects
the initial set of frequent 1-itemset by scanning the trans-
action database. Our technical report [22] compares the
horizontal vs. vertical data formats and the corresponding
algorithms in more detail.
Subsequently, Zaki [38] developed CHARM, a more ad-
vanced algorithm for mining data in the vertical data for-
mat. The algorithm is based on the same idea of intersecting
itemsets' tidsets to produce new itemsets, but it species
the search problem using the notion of itemset-tidset tree
(IT-tree). Also, CHARM introduces several optimizations,
including the search for closed itemsets.
All the approaches above operate on a database with dis-
joint transactions, each containing a set of items. On the
contrary, our frequent code change pattern mining algorithm
handles overlapping transactions and itembags rather than
itemsets, which are the two major challenges specic to fre-811quent code change pattern mining from continuous sequence
of code changes.
7.2 Mining Source Code
Source code mining research has a long history. Here, we
present several representative examples.
Michail [21] applied data mining techniques to detect how
a library is reused in dierent applications. The mined li-
brary reuse patterns, represented as association rules, facil-
itate the reuse of the library components by developers.
Li et al. [19] employed frequent itemset mining to extract
programming rules from the source code of an application.
They also showed that source code fragments that violate
the extracted rules are likely to be buggy.
Holmes et al. [15] matched the structural context of the
edited source code against a code repository to present a
developer with the examples demonstrating the relevant API
usage. Similarly, Bruch et al. [3] proposed to improve the
IDE's code completion systems by making them learn from
code repositories.
Andersen et al. [2] inferred code changes from several ex-
amples of code before and after editing. The inferred trans-
formations are context-sensitive and thus, could be applied
to matching code contexts.
Hovemeyer et al. [16] developed FindBugs, a tool that
detects a variety of bug patterns in an application by stati-
cally matching bug pattern descriptions against the under-
lying source code. Lin et al. [20] proposed an approach to
search for a specic kind of bug patterns | violations of
check-then-act idioms.
All these approaches mine the application's source code,
while our algorithm mines ne-grained code changes.
Another direction of research is mining source code change
patterns from the Version Control System (VCS) history of
an application. Ying et al. [35] and Zimmermann et al. [39]
apply data mining techniques on the application's revision
history to detect software artifacts (e.g., methods, classes,
etc.) that are usually changed together. The mined associa-
tion rules predict what other source code locations a devel-
oper needs to consider while performing a particular change.
Uddin et al. [32] proposed to mine VCS histories of client
applications to study how their use of APIs evolves over
time, which is helpful both to developers and users of the
libraries' APIs. Canfora et al. [4,5] and Thummalapenta et
al. [30] used VCS snapshots to study and track the evolution
of dierent software entities such as source lines, bugs, and
clones. More recently, Nguyen et al. [25] extracted method-
level code changes from revision histories of Java projects
and studied their within-project and cross-project repeti-
tiveness. In the domain of software testing, Zaidman et
al. [36] mined software repositories to explore how produc-
tion and test code co-evolve.
Mining VCS snapshots of an application is exposed to the
limited nature of VCS data. In our previous study [23],
we showed that data stored in VCS is imprecise ,incomplete ,
and makes it impossible to perform analysis that involves the
time dimension inside a single VCS snapshot. Also, similarly
to other source code mining techniques, these approaches
mine static source code, while our algorithm mines dynamic
code changes.
7.3 Automated Inference of Refactorings
Early work by Demeyer et al. [7] inferred refactorings by
comparing two dierent versions of source code using heuris-tics based only on low-level software metrics | method size,
class size, and inheritance levels. Kim et al. [18] used a func-
tion similarity algorithm to detect methods that have been
renamed. More recent refactoring inference approaches de-
tect refactorings depending on how well they match a set
ofcharacteristic properties that are constructed from the
dierences between two consecutive versions of an applica-
tion. Dig et al. [8] employed references of program entities
like instantiation, method calls, and type imports as its set
of characteristic properties. Weigerber and Diehl [34] used
characteristic properties based on names, signature analysis,
and clone detection. Prete et al. [28] developed Ref-Finder,
a tool that can infer the widest variety of refactorings to date
| up to 63 of the 72 refactorings cataloged by Fowler [10].
Their set of characteristic properties involved accesses, calls,
inherited elds, etc.
All these approaches infer refactorings from VCS snap-
shots, and thus, suer from the limitations of VCS data.
Also, they mine static source code and consider refactorings
only.
Recently, Ge et al. [11] and Foster et al. [9] proposed tools
that continuously monitor code changes to detect and com-
plete manual refactorings in real-time . Although this di-
rection of research is very promising, the proposed tools are
limited to a single kind of program transformations | refac-
torings, and detect a small subset of already known refactor-
ings. On the contrary, our algorithm is not restricted to any
specic kind of program transformations and is designed to
detect previously unknown code change patterns.
Wit et al. [6] performed live monitoring of the clipboard to
detect clones. Their tool tracked the detected clones, oer-
ing several resolution strategies whenever the clones were
edited inconsistently. Our approach of detecting similar
changes to dierent parts of the code is complementary to
detecting dierent changes to the similar parts of the code.
8. CONCLUSIONS
Although mining frequent code change patterns has a long
research history, we are the rst to present an algorithm that
mines previously unknown patterns from a ne-grained se-
quence of code changes. Our algorithm eectively handles
overlapping transactions that contain multiple instances of
the same item kind | the major challenge that distinguishes
our approach from the existing frequent itemset mining tech-
niques.
To evaluate our algorithm, we used 1,520 hours of real
world code changes that we collected from 23 developers.
Our experiment showed that our mining algorithm is scal-
able, eective, and useful. Analyzing some of the mining
results, we identied ten popular kinds of high-level pro-
gram transformations. To assess the popularity of the iden-
tied transformations, we conducted a survey study with
420 participants. More than half of the survey participants
recognized the relevance of eight out of ten transformation
kinds in their daily development activities.
Acknowledgments. We would like to thank Jiawei Han
for his guidance in the eld of data mining. We also thank
Darko Marinov and students in the Software Engineering
seminar at UIUC and the Software Evolution group at OSU
for insightful comments on earlier drafts of this paper. This
work was partially supported by the National Science Foun-
dation grants number CCF-1117960 and CCF-1213091.8129. REFERENCES
[1] R. Agrawal and R. Srikant. Fast algorithms for mining
association rules. In VLDB , 1994.
[2] J. Andersen, A. C. Nguyen, D. Lo, J. L. Lawall, and
S.-C. Khoo. Semantic patch inference. In ASE, 2012.
[3] M. Bruch, M. Monperrus, and M. Mezini. Learning
from examples to improve code completion systems. In
FSE, 2009.
[4] G. Canfora, M. Ceccarelli, L. Cerulo, and M. D.
Penta. How long does a bug survive? an empirical
study. In WCRE , 2011.
[5] G. Canfora, L. Cerulo, and M. D. Penta. Tracking
your changes: A language-independent approach. In
IEEE Software , 2009.
[6] M. de Wit, A. Zaidman, and A. van Deursen.
Managing code clones using dynamic change tracking
and resolution. In ICSM , 2009.
[7] S. Demeyer, S. Ducasse, and O. Nierstrasz. Finding
refactorings via change metrics. In OOPSLA , 2000.
[8] D. Dig, C. Comertoglu, D. Marinov, and R. E.
Johnson. Automated detection of refactorings in
evolving components. In ECOOP , 2006.
[9] S. Foster, W. G. Griswold, and S. Lerner.
WitchDoctor: IDE Support for Real-Time
Auto-Completion of Refactorings. In ICSE , 2012.
[10] M. Fowler. Refactoring: Improving the Design of
Existing Code . Addison-Wesley Longman Publishing
Co., Inc., 1999.
[11] X. Ge, Q. L. DuBose, and E. Murphy-Hill. Reconciling
manual and automatic refactoring. In ICSE , 2012.
[12] J. Han, H. Cheng, D. Xin, and X. Yan. Frequent
pattern mining: current status and future directions.
Data Min. Knowl. Discov. , 15, 2007.
[13] J. Han, J. Pei, and Y. Yin. Mining frequent patterns
without candidate generation. In SIGMOD , 2000.
[14] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and
P. Devanbu. On the naturalness of software. In ICSE ,
2012.
[15] R. Holmes, R. J. Walker, and G. C. Murphy.
Approximate structural context matching: An
approach to recommend relevant examples. IEEE
Trans. Softw. Eng. , 32, 2006.
[16] D. Hovemeyer and W. Pugh. Finding bugs is easy. In
OOPSLA , 2004.
[17] L. Jiang and Z. Su. Automatic mining of functionally
equivalent code fragments via random testing. In
ISSTA , 2009.
[18] S. Kim, K. Pan, and J. W. Jr. When functions change
their names: Automatic detection of origin
relationships. In WCRE , 2005.
[19] Z. Li and Y. Zhou. Pr-miner: automatically extracting
implicit programming rules and detecting violations in
large software code. In FSE, 2005.
[20] Y. Lin and D. Dig. Check-then-act misuse of java
concurrent collections. In ICST , 2013.
[21] A. Michail. Data mining library reuse patterns in
user-selected applications. In ASE, 1999.[22] S. Negara, M. Codoban, D. Dig, and R. E. Johnson.
Mining continuous code changes to detect frequent
program transformations. Technical Report
http://hdl.handle.net/2142/43889, University of
Illinois at Urbana-Champaign, 2013.
[23] S. Negara, M. Vakilian, N. Chen, R. E. Johnson, and
D. Dig. Is it dangerous to use version control histories
to study source code evolution? In ECOOP , 2012.
[24] A. T. Nguyen, T. T. Nguyen, H. A. Nguyen,
A. Tamrawi, H. V. Nguyen, J. Al-Kofahi, and T. N.
Nguyen. Graph-based pattern-oriented,
context-sensitive source code completion. In ICSE ,
2012.
[25] H. A. Nguyen, A. T. Nguyen, T. T. Nguyen, T. N.
Nguyen, and H. Rajan. A study of repetitiveness of
code changes in software evolution. In To appear in
ASE, 2013.
[26] C. Omar, Y. Yoon, T. D. LaToza, and B. A. Myers.
Active code completion. In ICSE , 2012.
[27] H. T. T. Petteri Sevon and P. Onkamo. Gene mapping
by pattern discovery. In Data Mining in
Bioinformatics , 2005.
[28] K. Prete, N. Rachatasumrit, N. Sudan, and M. Kim.
Template-based reconstruction of complex
refactorings. In ICSM , 2010.
[29] P. Sevon, H. Toivonen, and V. Ollikainen. TreeDT:
Tree pattern mining for gene mapping. IEEE/ACM
Trans. Comput. Biol. Bioinformatics , 3, 2006.
[30] S. Thummalapenta, L. Cerulo, L. Aversano, and
M. D. Penta. An empirical study on the maintenance
of source code clones. In Empirical Software
Engineering , 2010.
[31] H. Toivonen, P. Onkamo, P. Hintsanen, E. Terzi, and
P. Sevon. Data mining for gene mapping. In Next
Generation of Data Mining Applications , 2005.
[32] G. Uddin, B. Dagenais, and M. P. Robillard.
Analyzing temporal api usage patterns. In ASE, 2011.
[33] M. Vakilian, N. Chen, S. Negara, B. A. Rajkumar,
B. P. Bailey, and R. E. Johnson. Use, disuse, and
misuse of automated refactorings. In ICSE , 2012.
[34] P. Weigerber and S. Diehl. Identifying refactorings
from source-code changes. In ASE, 2006.
[35] A. T. Ying, G. C. Murphy, R. Ng, and M. C.
Chu-Carroll. Predicting source code changes by mining
change history. IEEE Trans. Softw. Eng. , 30, 2004.
[36] A. Zaidman, B. V. Rompaey, S. Demeyer, and A. van
Deursen. Mining software repositories to study
co-evolution of production & test code. In ICST , 2008.
[37] M. J. Zaki. Scalable algorithms for association mining.
IEEE Transactions on Knowledge and Data
Engineering , 2000.
[38] M. J. Zaki and C.-J. Hsiao. CHARM: An ecient
algorithm for closed itemset mining. In SDM , 2002.
[39] T. Zimmermann, P. Weissgerber, S. Diehl, and
A. Zeller. Mining version histories to guide software
changes. IEEE Transactions on Software Engineering ,
31, 2005.813