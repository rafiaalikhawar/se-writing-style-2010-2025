DroidMate-2: A Platform for Android Test Generation
Nataniel P. Borges Jr.∗
Saarland University
Saarbrücken, Germany
nataniel.borges@cispa.saarlandJenny Hotzkow
Saarland University
Saarbrücken, Germany
jenny.hotzkow@cispa.saarlandAndreas Zeller
Saarland University
Saarbrücken, Germany
zeller@cs.uni-saarland.de
ABSTRACT
Androidapplications(app s)representaneverincreasingportionof
the software market. Automated test input generators are the state
of the art for testing and security analysis.
WeintroduceDroidMate-2(DM -2),aplatformtoeasilyassist
both developers and researchers to customize, develop and test
new test generators. DM -2 can be used without app instrumen-
tation or operating system modifications, as a test generator onreal devices and emulators for app testing or regression testing.
Additionally, it provides sensitive resource monitoring or blocking
capabilities through a lightweight app instrumentation, out-of-the-
box statement coverage measurement through a fully-fledged app
instrumentationandnativeexperimentreproducibility.Inourex-
perimentswecomparedDM -2againstDroidBot,astate-of-the-art
test generator by measuring statement coverage. Our results show
that DM-2 reached 96% of its peak coverage in less than 2/3 of the
timeneededbyDroidBot,allowingforbetterandmoreefficient
tests. On short runs (5 minutes) DM -2 outperformed DroidBot by
7%while in longer runs (1 hour) this difference increases to 8%.
ACM DL Artifact: https://www.doi.org/10.1145/3264864. For the
details see:
https://github.com/uds-se/droidmate/wiki/ASE-2018:-Data
CCS CONCEPTS
•Software and its engineering →Software testing and de-
bugging;Dynamic analysis ;•Human-centered computing →
Graphical user interfaces; Smartphones;
KEYWORDS
dynamic analysis, test generation, Android
ACM Reference Format:
NatanielP.BorgesJr.,JennyHotzkow,andAndreasZeller.2018.DroidMate-
2:APlatformforAndroidTestGeneration.In Proceedingsofthe201833rd
ACM/IEEEInternationalConferenceonAutomatedSoftwareEngineering(ASE
’18), September 3–7, 2018, Montpellier, France. ACM, New York, NY, USA,
4pages.https://doi.org/10.1145/3238147.3240479
∗Authors in alphabetical order.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.32404791 INTRODUCTION
The Android mobile application market is highly volatile and com-
petitivewithmillionsofapplications(apps )onGooglePlayStore.
The quality of an app is vital to stay competitive in such a market
and testing is a core technique for quality control.
Since manual app testing is expensive and laborious, several
tools for automated test generation [ 10] have been developed. Au-
tomatedtestingis,however,aconstantlyevolvingsubject,astesting
techniques improve, so increases the app’s complexity. This results
in a never ending demand for more advanced testing techniques
to cover app behavior as effective and efficient as possible. Quality
control mostly implies defect-free apps and test generators mainly
focus on functionality testing. As the recent Facebook incident [ 5]
shows, this is no longer sufficient. As security and privacy become
moreprominent,securityanalysisshouldbepartofthetestingand
development cycle.
InthisworkwepresentDM -2,anextendedandimprovedver-
sion of the original DroidMate project. While DroidMate was a
test input generator with API monitoring capabilities, DM -2 offers
easytousemechanicstoimplementsystematictestingstrategieson
top of a ready to use selection of strategies such as random, fitness
based or playback of recorded executions. DM -2 is still usable out-
of-the-boxasarandomtestinputgenerator ,however, besidesmajor
performance improvements, its improved design gives developers
and researchers means to easily implement and combine their own
customstrategieswhileabstractingallAndroidspecifics,suchas
appsetupordevicecommunication,away.Eachstrategyisauto-
matically selected according to freely configurable conditions, e.g.,
the condition if there is a permission request, accept it can be easily
expressedasbooleancheckofthecurrentlyvisibleelementsforthe
permissionrequestidentifier.Allthesetestgenerationalgorithms
canbenefitfrommonitoring,mockingorblockingofsensitivere-
sourcesduringanalysisaswellofanewdynamicallygeneratedand
extensible app model, which allows for context aware exploration
strategies. DM -2 runs on stock Android versions between 6 (API
23) and 8 (API 26), on physical devices and emulators without any
need of device rooting or operating system (OS) modification. It
providesout-of-the-boxtestreproducibility,aswellasstatement
coverage analysis via app instrumentation.
2 TOOL DESIGN
Thearchitectureof DM -2consistsofthreemajorcomponents,as
illustrated by the dashed frames in Figure 1.
Exploration Engine – running on the host PC – creates the UI
statemodel(onthefly)anddeterminesinteractionswiththeapp
under test based on a configurable set of exploration strategies;
Monitoring Proxy – running on the device – is responsible for
intercepting API calls between the app and the Android OS to log,
block or mock the responses of these API calls;
916
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Nataniel P. Borges Jr., Jenny Hotzkow, and Andreas Zeller
Figure 1: DM-2’s conceptual architecture, highlighting
places where the developer can add custom implementa-tions (light gray), as well as components from the originalDroidMate extended by DM-2 (dashed).
Automation Engine
– consisting of a PC interface and a device
componentwhichcommunicateviaTCP–toexecutetheactions
asdeterminedbythe ExplorationEngine onthedevice.Therebythe
device itself is controlled via Android’s native UiAutomator.
2.1 Exploration Engine
Originally, the test generation of DroidMate utilized an explo-
ration loop to determine after each executed device action what
interactions should be issued next. DM -2 extends this mechanism
with a pool of exploration strategies andselectorswhich determine
the next interaction, based on the current state of the App Model
(seeSection 2.1.3). Each selectorprogrammatically specifies, based
on the current and previous model states, if it is able to process the
current state and, if so, which specific strategy should be activated.
To cope with cases where multiple conditions are fulfilled at the
sametime,auniquepriorityvaluehastobespecifiedforeachse-
lector.Foranyiterationintheexplorationloop,theselectorwith
thehighestprioritywhichcanprocessthecurrentstateischosen
and its strategy is used to compute the next device interaction.
After each device action DM -2 fetches the current device screen
(window dump) and a screenshot, alongside potential logcat ex-
ceptions. With this information the new app state is derived as
described in App Model . Additionally, all registered model features
arenotifiedaboutthisstatetransition.Thesemodelfeaturespro-
videtheinterfacetoallowformodelextensionslikeablacklistof
all UI elements which let the app crash or the exploration stagnate.
The new state is then used in the next iteration of the explo-
ration loop as current state of the app. This loop continues until
any strategy triggers a terminate action.
2.1.1 Strategy Selectors. DM-2supportsthedefinitionofcriteria
to determine the best strategy for different situations, e.g., when a
permissionisrequestedortheexplorationgetsstuck.Thesecriteria
are referred to as selectors.
Formally, a selector is defined as a pair/parenleftBig
p,f(c)→s/parenrightBig
wherepis
itspriorityand f(c)isamappingfunction ffromamodelcontext c
(e.g.,thecurrentstateortheactiontrace)toanexplorationstrategy
s.DM-2calculatesiftheselectioncriteriaisfulfilled f(c)andchoses
themostsignificantsuccessfulselector.Thatis,theonewithhighest
prioritywhichreturnedastrategy stobeusedtoderivethenext
device interaction.DM-2providesasetofselectorstoactivatethedefaultstrategies
described in Section 2.1.2. The set of selectors to be used can be
configuredviacommandlineorwithinaconfigurationfile.Custom
selectors can be implemented or existing selectors can be modified
(e.g to change priorities) and passed to DM-2’s initialization.
2.1.2 Strategies. Aninteractionwithanappcanbesimple,suchas
click on coordinates (x,y), or complex, such as close the app, enable
thedevice wi-fi,bluetooth andrestartthe appfrom itsinitialscreen.
Such complex interactions are abstracted as exploration actions.A n
exploration action determines which specific sequence of device
actionsshould be performed by the automation engine. A strat-
egy decides, based on the current state of the app model, which
exploration action(s) should be issued next.
DM-2 is shipped with a set of strategies, e.g., it is able to ran-
domly explore an arbitrary app without any need of additional
meta information, labeling or manual user interaction. In addition
torandomexploration,DM -2offersthefollowingdefaultstrategies
Reset(re-)enables wi-fi,triggersthehome buttonandstarts the
app from its main activity.Terminate closes the app and finishes the exploration.
Backpresses the back button of the device.
BiasedRandom
randomlyselectsaUIelementfromthecurrent
screen, among those which have been least explored, and clicks or
long clicks it.
In particular, we count how often any UI element was clicked in
the context of a specific state and how often over all states. The
leastinteractedUIelementiscomputedbydeterminingtheinter-
actable elementswhich wereleast interactedin thecontext ofthe
current state and filtering these by the smallest overall interaction
number.IfthiscomputationresultsinmorethanoneUIelement,
the target is chosen randomly among them. Apps which belong
totheapplicationpackagearepreferredtoguidetheexploration
rather to app internal features.
Random randomly clicks on the coordinate of any UI element on
the screen, similar to Monkey [1].
Fitness Proportionate uses a statically mined interaction model
to predict the probability of each UI element having an event, then
use these probabilities as bias for a random selection.
PlayBack selects the next valid interaction from a previously
recorded model trace and replays it.
2.1.3 App Model. The appmodel constructed duringexploration
consists of the UI states– featuring a set of UI elements. Some
of these UI elements are interactable, meaning the user can, for
example, tick, click or long-click them. This interaction (transition )
mayleadintoanotherstate.WhileAndroidsallowsthedeveloper
tospecifya resource id foranyUIelement,itisoptionalandseldom
used. Thus, we uniquely identify a UI element by computing its id
wIdin the form of a UUID(from the Java default library) based on
the concatenation of its display and description text, if available,or on its image bytes, cut from a screenshot, if not. In additionto the unique ID, we compute a
propIdwhich represents the UI
element configuration by converting all state-related properties
such as position, checked, enabled, click-able etc. to a string and
computing its UUID.
917
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. DroidMate-2: A Platform for Android Test Generation ASE ’18, September 3–7, 2018, Montpellier, France
Weaimtoidentifyconceptuallyidenticalstates,i.e.,slightdiffer-
encesintherenderinglikethehighlightingofpreviouslyinteracted
elementsshouldnotbeinterpretedasadifferentstate.Moreover,
wedisregardUIelementswhichdonotbelongtotheapp,thatis,
possessadifferentpackagename;aswellasnon-interactableand
simply structuring elements as non-essential for the conceptual
identityoftheUIstate.However,wewouldstillliketobeableto
distinguish if, for example, a check-box in the same conceptual
state was ticked or not. With this goal, we specify the identityidof a state by a tuple
stateId =(uniqueId ,configId ). Where the
uniqueId is computed as the union of the wIdof all UI elements
belongingtotheappwhichareeitherinteractableorleafsinthe
elementhierarchy(non-leafelementsareusedforlayoutandvisualrepresentationpurposes)andthe configIdistheunionofthe
propId
of all currently visible UI elements.
Thismetricforuniqueidsallowsustoefficientlyre-identifycon-
ceptuallyidenticalUIstatesaswell asUIelementswhichreoccur
withindifferentUIstates(likemenuorhelpbuttons),independently
oftheirpositionorlayout.Themetricfor configIdallowstoiden-
tify which configurations were explored for each UI state. Both
functionalities are essential for advanced exploration strategies.
2.2 Automation Engine
TheAutomation Engine abstracts and manages all communication
between the exploration and app using a synchronous protocolbased on actionsandresponses. Strategies send one action at a
timetothe AutomationEngine (PCside),whichforwardsittoits
on-device instance and halts the exploration while this action is
processed.
The on-device Automation Engine converts actions into automa-
tion commands or API calls. Before issuing a response to the ex-ploration, the on-device Automation Engine must wait until the
appstabilizes,thatis,untilitfinishesperformingthepreviousac-
tion and has at least one element from the app to interact with.
This synchronizationis anatural bottleneckof most Androidtest
generatorswhichallowforstate-awareUIactions.Itis,however,
necessary to correctly emulate a user’s behavior, who would have
to wait until a new screen is loaded to continue the exploration.
Thetimetoexecuteanactionvariesaccordingtothefunctional-
itybeingperformed–tickingacheckboxisfasterthanclickinga
loginbutton–aswellasexternalfactors,suchasnetw orkspeed
and server availability. The Automation Engine copes with varying
load times as follows: first, it waits for the device to be idle, that is,
ready to receive and handle commands again. It then waits until
atleastoneUIelementcanbeinteractedwith.ItdiscardsanyUI
elementsdisplayedonlyduringthistransitionperiod,e.g.,progress
bars, as they do not provide any explorable behavior.
Oncetheappstabilizes,theon-device AutomationEngine issuesa
responsecontainingthestructural(screendump)andvisual(screen-
shot) state of the device to its PC counterpart, which forwards it to
theExploration Engine for processing.
2.3 Monitoring Proxy
TheMonitoringProxy isapayloaddeployedtothedeviceinorderto
workasaproxybetweentheappandOS.Itmonitorsaconfigurable
listofprivacy-sensitiveresourcesandinterceptsAPIinvocations
without changing the app code. This functionality is only available
Figure2:AveragecoverageovertimebetweenDM-2,Droid-Bot and Monkey for the test dataset.
on physical devices or emulators with ARM processor architecture.
In order to use it, the app has to be instrumented to activate this
payloadbeforestartingtheapp.DM -2offersthisinstrumentation
functionalitythroughits inlinemechanism,whichinsertsanacti-
vationcalltothepayloadintheentrypointoftheapp,keepingthe
remainder of the app unaltered.
WhileoriginallydevelopedforAPImonitoring,the Monitoring
ProxyallowscustomcodetobetriggeredforeachAPI,aswellasto
individuallydefinesecuritypoliciessuchasmockingorblocking
API access. When active, Monitoring Proxy ’s standard mocking
behavioris toreturna defaultvalueforprimitive typeAPIs,such
as 0 for integers and empty string for strings. When blocking, it by
default raises a security exception.
3 EMPIRICAL EVALUATION
WeconductedasetofexperimentstoevaluateDM -2’sefficiency
and effectiveness. In particular we aim to answer the followingresearch question: Does DM
-2 reach a coverage peak faster than
current tools?
We compared DM -2 against DroidBot, which presents similar
functionality and has been shown to outperform most current test
generators [ 2] and Monkey, the standard test generator from An-
droid. As an evaluation metric we used statement coverage, which
has been extensively used to determine the effectiveness of testing
toolsandisregardedasagoodpredictorforfaultdetection[ 6].We
evaluated all tools on 11 different apps, randomly chosen from [ 3].
Each app exploration was executed for 1 hour on a real Google
Nexus 5X device, with 10 runs per app to mitigate noise.
OurresultsinFigure 2showthatconcretestrategiesaresuperior
topurerandomeventsforthetestedappset.EventhoughMonkeyimplementsmoreinputtypes(e.g.,swipeandzoom)thantheothertools it has the worst overall coverage. This is in particular true for
apps which have ‘deeper functionality‘, meaning the user has to
navigatethroughafewscreensuntilcertainfeaturesareaccessible.
DroidBot and DM -2, both, try to systematically explore differ-
ent UI elements. DroidBot applies a depth-first strategy, mean-
while DM -2 usesBiasedRandom. This fact together with the better
performanceof DM -2(2sinstead of3-4s peraction) leadto faster
and more efficient explorations. On average, DM -2 achieved 8%
bettercoveragethanDroidBotafter1hour,witha 7%difference
in 5 minute runs. In addition, this chart shows that DM -2 achieved
96% of its maximum coverage in approximately 15 minutes, whileDroidBot reached the same ration in approximately 24 minutes.
4 USAGE SCENARIOS
WeenvisionDM -2asatoolbeneficialtobothresearchandindustry
due to its modular architecture and out-of-the-box functionality.
Below we describe a few scenarios where DM-2 can be applied.
918
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Nataniel P. Borges Jr., Jenny Hotzkow, and Andreas Zeller
RecordandReplaySystemTests. Duringthetestexecution,DM -2
records each action performed, UI element seen and state reached,
italsoprovidesout-of-the-boxstatementcoveragemeasurement.
AninitialDM -2run–orasetofrunswithdifferentconfigurations–
canbeexecutedtotestasystem.Duringthereleaseofanewversion
oftheappthesetestscanbereplayedandthefollowingevaluations
performed: (1)does the functionality tested on the previous app
version still work the same? (2)Are there any previously tested code
segments which are no longer tested?
Sensitive Resource Impact Analysis. DM-2 can be used to analyze
theimpactofaccessrestrictiontosensitiveresources.WhileDroid-
Mate was capable of monitoring API access it did not provide any
means torestrict – orimpersonate –them. By combining DM -2’s
APIrestrictingcapabilitieswithitsrecordandreplayfeatureand
code coverage metric, it is possible to measure the impact when
restricting access to a sensitive resource.
AppBehaviorAnalysis. DM-2createsanappmodelduringexplo-
ration, which can be used to generate new test inputs. This model
can be easily extended with custom features, like tracking APIs
triggered after clicking UI elements with certain text labels.
Previousresearch[ 7]demonstratedthatsuchinformationcan
beusedtoidentifyanomalousbehaviorswithinappcategories.Ourmodelallowssuchstudiestobeperformedwithcontext-awareness
(current and previous app states) and on finer granularity level.
NewTestGenerationStrategies. DM-2’sarchitectureoffersma-
jor assistance for the development of new Android test generation
algorithms.DM -2canbeusedtoabstractalllow-levelAndroidcom-
municationandtocreatetestsfromamodelrepresentationofthe
app,mitigatingthedevelopmentefforts.Inaddition,DM -2provides
natively experiment reproducibility (through record and replay) as
well as coverage metrics for comparison between techniques.
5 RELATED WORK
Automated Test Input Generation in mobile apps is a frequent re-
searchtopic.Threemajorapproachesareusedforinputgenerators,
namely:random,model-based, and systematic.
Random testing tools create sequences of events to explore apps.
Representatives are Monkey [ 1] – the lightweight test generator
shippedwithAndroid,aswellasDroidMate[ 8].DM-2supports
the same feature, while providing more functionality.
Model-based inputgeneratorsusea–previouslydefinedoron
theflygenerated–modeltoproduceinputs.ForexampleDroid-
Bot[9]employsdifferentmethodstodynamicallyconstructand
consumeappmodels.DM -2’sofferssimilarfeatures.Adeveloper
can easily implement custom strategies which use the on the fly
constructed model. DroidBot’s methods to quantify test effective-
ness are orthogonal to our approach and may be integrated in the
future.SwiftHand [4] uses statically generated models to guide test
generation.DM -2providesout-of-the-boxa FitnessProportionate
strategywhichconsumesastaticmodelfortestgeneration.This
mechanism can be applied to arbitrary input models.
Systematic testing approaches systematically test an app with a
specific goal. EvoDroid [11] andSapienz[12] attempt to improve
test coverage, while IntelliDroid [13] attempt to trigger specific
behaviors.WithDM-2’sextensiveappmodelitisstraightforwardto support all these approaches or to try out other new strategies.Besidestheperformancebenefitsaspresentedin Section3,DM -2
offersadditionalfeatureslikereproducibility(playbackstrategy),
an extensible architecture and a more powerful app model.
6 CONCLUSION
WepresentDM -2,aplatform forAndroidtestgeneration,which
canbeusedonallstockAndroidversions6to8.1.WhileDM -2can
beusedoutoftheboxforrandomtesting,withAPImonitoringand
privilege restriction, or for recording and replaying system tests,
its major advantage is the easement for development, combination,
extension and comparison of different test generation strategies.
DM-2simplifiestheworkfordevelopersbyabstractingalldevice
related issues and providing a dynamically constructed app model,
whichcanbeusedtoverifytestcriteriaorforstrategydevelopment.
OurevaluationshowedthatDM -2isablenotonlytoachieveabetter
coveragethanbothastate-of-the-artandAndroid’sstandardtest
generators, butthat it isalso able toreach itspeak coverageearlier,
allowing for faster more efficient testing.
ACKNOWLEDGMENT
This work was funded partially by a German Research Foundation
(DFG) grant (D514111409), the DFG project (SFB 1223, Project A3)
and partially by European Research Council grant (G514111401).
REFERENCES
[1]Android. 2017. UI/Application Exerciser Monkey. (2017). https://developer.
android.com/studio/test/monkey.html
[2]Lingfeng Bao, Tien-Duy B Le, and David Lo. 2018. Mining sandboxes: Are
we there yet?. In 2018 IEEE 25th International Conference on Software Analysis,
Evolution and Reengineering (SANER). IEEE, 445–455.
[3]NatanielBorgesJr.,MariaGómez,andAndreasZeller.2018. GuidingAppTesting
With Mined Interaction Models. In Mobile Software Engineering and Systems
(MOBILESoft’18), 2018 IEEE/ACM International Conference on. IEEE.
[4]Wontae Choi, George Necula, and Koushik Sen. 2013. Guided GUI Testing of
Android Apps with Minimal Restart and Approximate Learning. In OOPSLA ’13
Proceedings of the 2013 ACM SIGPLAN international conference on Object oriented
programming systems languages & applications. 1–30.
[5]Facebook. 2017. Cracking Down on Platform Abuse. (2017). https://newsroom.
fb.com/news/2018/03/cracking-down-on-platform-abuse/
[6]RahulGopinath,CarlosJensen,andAlexGroce.2014. Codecoverageforsuite
evaluationbydevelopers.In Proceedingsofthe36thInternationalConferenceon
Software Engineering. ACM, 72–82.
[7]Alessandra Gorla, Ilaria Tavecchia, Florian Gross, and Andreas Zeller. 2014.
Checking app behavior against app descriptions. In Proceedings of the 36th Inter-
national Conference on Software Engineering. ACM, 1025–1035.
[8]KonradJamrozikandPhilippVonStyp-rekowskyAndreas.2016. MiningSand-
boxes.ICSE,2016IEEE/ACM38thInternationalConferenceonSoftwareEngineering
(2016).
[9]Yuanchun Li, Ziyue Yang, Yao Guo, and Xiangqun Chen. 2017. DroidBot : A
LightweightUI-GuidedTestInputGeneratorforAndroid. 2017IEEE/ACM39th
IEEE International Conference on Software Engineering (2017).
[10]MarioLinares-Vásquez,KevinMoran,andDenysPoshyvanyk.2017. Continuous,
evolutionaryandlarge-scale:Anewperspectiveforautomatedmobileapptesting.
InSoftwareMaintenanceandEvolution(ICSME),2017IEEEInternationalConference
on. IEEE, 399–410.
[11]RiyadhMahmood,NarimanMirzaei,andSamMalek.2014. EvoDroid:segmented
evolutionarytestingofAndroidapps.In Proceedingsofthe22ndACMSIGSOFT
InternationalSymposiumonFoundationsofSoftwareEngineering–FSE’14.599–
609.
[12]KeMao,MarkHarman,andYueJia.2016. Sapienz:Multi-objectiveAutomated
Testing for Android Applications. In Proceedings of the 25th International Sympo-
siumonSoftwareTestingandAnalysis (ISSTA2016) .ACM,NewYork,NY,USA,
94–105.
[13]Michelle Y Wong and David Lie. 2016. IntelliDroid: A Targeted Input Generator
fortheDynamicAnalysisofAndroidMalware.In ProceedingsoftheNetworkand
Distributed System Security Symposium (NDSS). 21–24.
919
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. 