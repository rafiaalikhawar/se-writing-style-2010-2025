Improving Model-Based Test Generation by
Model Decomposition
Paolo Arcaini
Charles University in Prague
Faculty of Mathematics and
Physics, Czech Republic
arcaini@d3s.mff.cuni.czAngelo Gargantini
Dipartimento di Ingegneria
Universit√† degli Studi di
Bergamo, Italy
angelo.gargantini@unibg.itElvinia Riccobene
Dipartimento di Informatica
Universit√† degli Studi di
Milano, Italy
elvinia.riccobene@unimi.it
ABSTRACT
One of the well-known techniques for model-based test gen-
eration exploits the capability of model checkers to return
counterexamples upon property violations. However, this
approach is not always optimal in practice due to the re-
quired time and memory, or even not feasible due to the state
explosion problem of model checking. A way to mitigate
these limitations consists in decomposing a system model
into suitable subsystem models separately analyzable. In
this paper, we show a technique to decompose a system
model into subsystems by exploiting the model variables
dependency, and then we propose a test generation approach
which builds tests for the single subsystems and combines
them later in order to obtain tests for the system as a whole.
Such approach mitigates the exponential increase of the test
generation time and memory consumption, and, compared
with the same model-based test generation technique applied
to the whole system, shows to be more ecient. We prove
that, although not complete, the approach is sound.
Categories and Subject Descriptors
D.2.5 [ Software Engineering ]: Testing and Debugging;
D.2.4 [ Software Engineering ]: Software/Program Veri-
cation| formal methods, model checking
General Terms
Verication
Keywords
Test case generation, model-based testing, state explosion
problem, abstraction
The work was partially supported by Charles University
research funds PRVOUK.1. INTRODUCTION
Model-based test generation by model checking is a well-
known technique that allows automatic generation of test
cases from models by exploiting the capability of model
checkers to return counterexamples [18]. Model checkers are
tools that explore the reachable state space of a model and
return a counterexample if a property of interest is violated
in some state. In the context of model-based testing, once
the testing requirements (or testing goals ) are represented
by suitable temporal logic predicates, called test predicates ,
tests are generated by forcing the model checker to build
counterexamples upon violation of test predicates negation.
Although completely automatic, this technique suers from
the\state explosion problem", i.e., the size of the system state
space grows exponentially with the number of variables and
the size of their domains, and it could become intractable.
Finding a test in an enormous state space is still a challenge.
Much of the research in model checking over the past 30
years has involved developing techniques for dealing with
this problem in the context of property verication [14];
however, several of these abstraction techniques (like coun-
terexample guided abstraction [13]) are not suitable for test
generation [31]. Indeed, they can guarantee validity of a
property in the original model if the property is veried in
the abstract model, but they may not guarantee to nd the
right counterexample if the property is false. Other classical
abstractions (like slicing [33] or reduction techniques like
nite focus [2] that soundly reduces a state machine) trans-
form the original specication to a smaller one for which it
may be easier to nd the desired tests; however, they may
miss parts of the system specication that are necessary for
building the tests.
Our goal was to investigate a possible solution in the
context of those abstraction techniques for test generation
that, following the \divide and conquer" principle, are based
on system [4, 5] or property [26] decomposition. Since model
checkers suer exponentially from the size of the system,
decomposition brings an exponential gain and allows to test
large systems.
In this paper we present a technique for system decomposi-
tion and a test generation approach where tests for the whole
system are built as combination of tests generated for the
subsystems. The idea was inspired from our previous work
in [8], although the techniques we propose here for model
decomposition and test building are dierent. A comparison
is discussed in Sect. 6.
We here assume that models from which test cases shall be
derived are given as transition system formal specications.Our approach is based on the following intuitions. Given a
system model, a variable dependency graph can be dened on
the base of variable updates given by the model assignments.
Dependency induces an equivalence relation on the set of
model variables and, therefore, variables can be partitioned
into equivalence classes representing the strongly connected
components of the variables dependency graph. According
to the variables decomposition in strongly connected compo-
nents, the transition system can be decomposed in a set of
subsystems that are linked each other by exposing the same
dependency relation of the corresponding strongly connected
components they are built on. For each transition subsys-
tem, the model-based testing approach by model checking
can be used to automatically generate tests, and, at least in
principle, it should be more ecient than the same technique
applied to the global system. The question is how to exploit
the test generation approach applied at subsystem level to
build a test for the system as a whole.
For the way most coverage criteria for transition systems
are dened, given a test predicate tpproduced from these
criteria, there exists at least a subsystem containing all the
variables of tp. The test generation for tpstarts generating
a test over this subsystem. This test is then extended by
providing suitable test predicates to the other subsystems
in order to build (by merging the test generated for the
subsystems) a test for the whole system covering the original
testing goal.
We here describe how decomposing a transition system
into linked subsystems by exploiting the model variables
dependency. We then give the algorithm to automatically
generate a test covering a given test goal for the global
system by merging tests obtained for the subsystems by
proving them with suitable testing goals.
We prove that the generation technique is sound, even if
not complete. We discuss how to rene the technique to
increase its applicability, even if completeness of the rened
technique is still dicult to achieve.
Results of the technique application on a certain number
of case studies are presented, and these results are compared
with those obtained by applying the same technique without
system decomposition. Experiments show that a signicant
benet is obtained in terms of time and memory.
Note that our approach can be adapted to most state-based
methods, as SCR [18], RSMLe[21], ASMs [19], Event-B [1],
SPIN/Promela [25], NuSMV [12], etc., since they can be
mapped to the formal notation used here.
The paper is organized as follows. Sect. 2 provides some
basic denitions of transition systems and briey recalls the
model-based test case generation by model checking. Sect. 3
introduces all necessary concepts and denitions regarding
dependency of model variables, variable dependency graph,
and system decomposition into dependent subsystems. The
algorithm for test generation is presented in Sect. 4, where
also soundness and completeness of the technique are dis-
cussed. Experimental results about applicability and gain
achieved in test generation are presented in Sect. 5. Sect. 6
reviews related literature, and Sect. 7 concludes the paper.
2. BASIC DEFINITIONS
We assume that systems are modeled in terms of transition
systems. Therefore, we here provide some basic denitions
adapted from [30]. We also briey recall the approach of
automatic test generation from models by model checking,and we introduce coverage criteria suitable for transition
systems.
2.1 Transition System SpeciÔ¨Åcations
Denition 1. (Transition system ) A transition system
Mis a tuplexA;P; ywhere
Ais a rst order structure representing the instanta-
neous conguration of the system. Ahas a rst order
signatureGincluding a nite set of variables Vtv1;
v2;:::;vnu, a domainDvifor each variable vi, relations
and functions, and an interpretation function. The sys-
tem state is uniquely determined by the values of the
variables.
Pis a program consisting of a sequence of next assign-
ment sv1
1:e1;:::;v1
n:en, beingV1tv1
1;:::; v1
nu
the variables in the next state. Each eiis a term over
G, possibly containing variables of VandV1.
 tv1e0
1;:::; vne0
nuis the set of initial
assignment s, wheree0
ican contain only variables of V.
Termseiande0
iin next and initial assignments may contain
conditional expressions. We assume that Gmay contain a
predened function randompDq, randomly returning a value
taken from domain D.
Denition 2. (Computational step ) Executing the pro-
gramPin a statesconsists in evaluating terms e1;:::;enin
sand assigning the computed values to variables v1;:::;vn
obtaining the next state s1.
Note that, because of variables dependencies, a set of
assignments cannot be evaluated in any order. For instance
the assignments x1:y1andy1:xcan be evaluated only
in one order. We suppose that Pandare well-dened and
thus there always exists an order that permits to evaluate all
the assigned terms (i.e., there are no combinatorial loops [9],
that is cycles of dependencies not broken by delays). For
example, program Ptx1:y1;y1:x1uis not well-dened
since it contains a combinatorial loop among variables tx;yu.
Denition 3. (System execution ) An execution of a
transition system is a nite or innite sequence of states
s0,s1,:::,snsuch that the initial state s0is obtained by
evaluating the assignments in and each state si 1is ob-
tained by executing the program Pat statesi.
Note that transition systems allow modeling nondetermin-
istic systems. Because of the function random , executing P
twice from the same state smay lead to two dierent next
states.
Example 1. Consider a locker whose one-digit combination
is 4. If the locker digit is correct, the locker becomes un locked ,
and then the handle can be OPEN ed. Once the digit has
been set to 4, it cannot be changed. The locker is modeled
by the transition system MxA;P; yshown in Code 1.
Remark 1. Well known state-based formal approaches as
SCR [18], RSMLe[21], ASMs [19], Event-B [1], SPIN/-
Promela [25], and NuSMV [12] can be represented as transi-
tion systems. In some cases, the mapping is straightforward,
while other approaches could require suitable conversions.signatureA:
Vthandle;locked;digitu
DhandletOPEN;CLOSEDu,Dlockedboolean ,
Ddigitt0; :::; 9u
programP:
handle1:iflocked then CLOSED else randompDhandleq
locked1:digit14
digit1:iflocked then randompDdigitqelse digit
initial state :
handleCLOSED
lockedtrue
digit0
Code 1: Transition system example { Locker
NuSMV specications, for example, can be easily mapped to
transition systems, since in NuSMV the initialization and the
update of a variable vhave the same form of initial and next
assignments of transition systems (i.e., ve0andv1:e).
ASM specications, instead, require a certain transformation.
An ASM model can be viewed (in its simplest form) as a set
of transition rules of the form ifguard then Updates endif
where Updates is a set of updates of locations of the model
signature; in order to describe an ASM as a transition system,
we should collect, for each location l, all its updates and build
a next assignment l1:elwhereelis a term containing con-
ditional expressions built from the conditions that guard the
updates of lin the ASM model. In SCR, each table can be
easily represented as a conditional assignment. SCR events
that are used as terms can be translated by using the primed
values of variables. For instance, the event @T(x) , which
means that xbecomes true, is equivalent to x1^ x. Similar
transformations can be devised for the other formalisms.
2.2 Model-Based Testing by Model Checking
In model-based testing [24, 32], the specication describ-
ing the expected behavior of the system is used for testing
purposes.
Denition 4. (Test ) A testis a nite system execution
(as dened in Def. 3).
Tests are usually generated for covering some desired sys-
tem behaviors, called testing goals , formally represented by
test predicates.
Denition 5. (Test predicate ) Atest predicate is a for-
mula over the model, and determines if a particular testing
goal is reached.
The generation of testing goals is usually driven by some
coverage criteria.
Denition 6. (Coverage criterion ) Acoverage criterion
Cis a function that, given a formal specication, produces
a set of test predicates. A test suite TSsatises a coverage
criterionCif each test predicate generated with Cis satised
in at least one state of a test sequence in TS.
Ascoverage criteria for transition systems we can identify:
value coverage (i.e., each value of each variable is covered)
and guard coverage criteria [3] as decision coverage (i.e.,each decision in Pand in  is covered both to true and to
false), condition coverage (i.e, each atomic condition in P
and in  is covered both to true and to false), and Modied
Condition/Decision Coverage ( MCDC ) [10], requiring that
every atomic condition in a decision (found in Por in ) is
shown to independently aect the nal value of the decision.
Example 2. The value coverage criterion applied to the
transition system shown in Ex. 1 produces the following test
predicates: FphandleOPENq;FphandleCLOSEDq;
Fplockedq;Fp lockedq;Fpdigit0q; :::; Fpdigit9q.
Test generation by model checking. A classical technique
for model-based test generation exploits the capability of
model checkers to produce counterexamples [17, 18]. Given
a test predicate tp, the trap property  tpis veried. If
the model checker proves that the trap property is false ( tp
isfeasible ), then the returned counterexample shows how
to cover tp. We call the counterexample witness , and we
translate it to a test. If the model checker explores the
whole state space without nding any violation of the trap
property, then the test predicate is said unfeasible and it is
ignored. In the worst case, the model checker terminates
without exploring the whole state space and without nding
a violation of the trap property (i.e., without producing
any counterexample), usually because of the state explosion
problem. In this case, the user does not know if either the
trap property is true (i.e., the test is unfeasible) or it is
false (i.e., there exists a sequence that reaches the goal), and
the problem of nding a suitable test for that case remains
unsolved.
3. SYSTEM DECOMPOSITION
Variables of a transition system Mcan be analyzed in
order to discover their dependencies and detect the way the
systemMcan be modularized in subsystems. We here rst
introduce the concepts of variables dependency, dependency
graph, and set of strongly connected variables. Then we
explain how to decompose a transition system.
Denition 7. (Variable dependency ) Given two vari-
ablesvi;vjPVof a transition system, we say that vidirectly
depends on vjifvj(primed or not primed) occurs in eior in
e0
i.
We denote by DirDeppvqthe set of variables which v
directly depends on.
Denition 8. (Dependency graph ) We call dependency
graph of a transition system Mthe directed graph DG
xV;Ey, whereVis the set of variables of Mandpv;wqPE
ivdirectly depends on w, i.e.,wPDirDeppvq.
We say that vdepends on wif there exists a path from
vtowinDG. The dependency is the transitive closure
of the direct dependency. Note that the dependency graph
can contain cycles, even when a program is well-dened, i.e.,
it does not contain combinatorial loops. For instance, in a
correct program that exchanges two variables xandyby the
assignments x1:yandy1:x, the two variables are both
dependent on the other.handleSCV 1
locked digitSCV 2
Figure 1: Variables dependency graph
Denition 9. (Strongly connected variables set ) Given
a dependency graph DG xV;Eyof a transition system
M, each strongly connected component of DGidenties a
strongly connected variables set (SCV).
Any two variables in one SCV depend one on the other.
Intuitively, they constitute a group of interdependent quan-
tities. Furthermore, some variables in an SCV may also
directly depend on some variables of other SCVs.
Denition 10. (SCV inputs ) Given an SCV C, we iden-
tify with INpCq¬î
vPCDirDeppvqzCtheinputs ofC.
INpCqrepresents the inputs ofCsince it identies the
direct dependencies (not in C) of the variables of C.
Example 3. Fig. 1 shows the dependency graph and the
two SCVs of the transition system introduced in Ex. 1. Vari-
able handle directly depends on locked and depends on digit.
On the base of the decomposition of system variables in
strongly connected variables sets, we show how to decompose
the transition system.
Decomposition technique. Given a transition system M
xA;P; yand its dependency graph DG, we can build a
subsystemMixAi;Pi;iyofMfor each SCV CiofDG,
where
Aiis the structure obtained from Aby reducing the
set of variables VtoViCiYINpCiq;
Picontains the next assignments of Pfor the variables
inCi; moreover, for each variable vPINpCiq,Picon-
tains the next assignment of vinPonly if DirDeppvq
H, otherwise it contains v1:randompDvq;
icontains the initial assignments in for the vari-
ables inCi; moreover, for each variable vPINpCiq,
icontains the initial assignment of vinonly if
DirDeppvqH , otherwise it contains vrandompDvq.
EachMiis a well-formed transition system by construction:
next and initial assignments in Piandiare well-dened
and only contain variables of Vi.
We now establish some dependency relations among sub-
systems. These denitions will be used in the next section
for test building.
Denition 11. (Linking variables ) Given two subsys-
temsMiandMj, we call linking variables the set of direct
dependencies of variables in Cifrom variables in Cj, i.e.,
LpMi;MjqINpCiqXCj.
Denition 12. (Subsystems dependency ) A subsystem
Midirectly depends on another subsystem MjifLpMi;
MjqH . We denote by DirDeppMiqthe set of subsystems
ofMwhichMidirectly depends on.V1"
handle;
locked*M1
V2"
locked;
digit*M2
locked
Figure 2: Subsystems dependency graph
The subsystem dependency relation induces an acyclic
dependency graph among subsystems.
Example 4. Let us consider the transition system intro-
duced in Ex. 1. The subsystems obtained through decompo-
sition areM1xA1;P1;1y:
signatureA1:
V1thandle;lockedu
programP1:
handle1:iflocked then CLOSED else randompDhandleq
locked1:randompDlockedq
initial state 1:
handleCLOSED
lockedtrue
andM2xA2;P2;2y:
signatureA2:
V2tlocked;digitu
programP2:
locked1:digit14
digit1:iflocked then randompDdigitqelse digit
initial state 2:
lockedtrue
digit0
The linking variables are LpM1;M2qt lockedu. The subsys-
tem dependency graph is depicted in Fig. 2.
Remark 2. For the way Miis built from M, its behav-
ior subsumes the behavior of Mrestricted to variables Vi.
However,Mimay expose further computations that do not
correspond to any computation of M, since some of the input
variables of MiinINpCiqare randomly initialized or up-
dated and, therefore, they could assume values or sequences
of values not allowed in M.
We now provide some denitions to trace back computa-
tions ofMfrom computations of its subsystems.
Denition 13. (State projection ) Given a state sof a
transition system and a set of variables Ltv1;:::;vku, we
denote byLpsqthe list of values of the variables Lins, i.e.,
Lpsqtvv1ws;:::;vvkwsu.
Denition 14. (Sequence projection ) Given a sequence
s0;:::;snof a transition system and a set of variables L,
the projection of with respect to Lis dened as Lpq
Lps0q;:::;Lpsnq.
Denition 15. (Allowed sequence ) A sequence isal-
lowed if there exists an execution 1ofMsuch thatvarpqp1q
, being varpqthe variables occurring in .Intuitively, a sequence of states is allowed when it is a
projection of a valid execution of the entire system M. An
allowed sequence may not contain the values for every
variable inM, but still, all the variables in correctly behave.
Letbe an execution of a subsystem MiofM. When is
an allowed sequence?
Theorem 1.IfDirDeppMiqH , thenis allowed.
Proof. If a subsystem Mihas no dependencies, its vari-
ables setVicorresponds to Ci(i.e., INpCiqH ); therefore,
since the initial and next assignments of variables in Ciare
the same of M, all the sequences of Miare allowed.
Theorem 2.IfDirDeppMiq  H andINpCiqpqis al-
lowed, then is allowed.
Proof. IfMihas some dependencies, then INpCiqH .
The behavior of the variables in INpCiqcorresponds to the
correct behavior as in Mby hypothesis. Since the other
variables in Ciare computed as in M, the sequence is a
projection with respect to the variables Viof a valid execution
ofM.
Intuitively, an execution of a subsystem Miis allowed if
eitherMihas no dependencies, i.e., it is a leaf in the graph,
or its inputs represent an allowed behavior, i.e., they force
Mito behave as M.
4. TEST GENERATION BY SYSTEM DE-
COMPOSITION
We have seen how, exploiting variables decomposition,
a transition system can be decomposed in a set of linked
subsystems. We show now how to apply the model-based
test generation approach by model checking to the single
subsystems and how to merge the subsystems tests in order
to obtain a test for the global system.
Our technique works on test predicates of a particular class
of coverage criteria, called robust , dened as follows.
Denition 16. (Robust criterion ) A coverage criterion
Cisrobust to decomposition i, for each test predicate tp
produced by CoverM, it exists at least one subsystem Mi
ofMsuch that varptpq¬ÑVi.Miis said compatible with tp.
Most of the classical coverage criteria for transition systems,
including all those introduced in Sect. 2.2, are robust. From
now on, we assume that the test predicates are derived from
robust criteria. In case of fragile criteria, techniques for
merging subsystems can be applied, but this is left as future
work.
Given a test predicate tpthat we like to cover for M, we
can use as starting point of our test generation technique the
subsystemMicontaining all the variables of tp.Miand its
dependencies are sucient to generate a test able to cover tp
(if it exists). If there exists more than one Mi, we choose the
subsystem having fewer (direct and indirect) dependencies.
4.1 Test Generation Algorithm
Our test generation algorithm requires that the subgraph
consisting of Miand its dependencies is a tree whose root
isMi. This requirement guarantees that each subsystem
provides input values at most to only another subsystem. If
the graph were not a tree, a subsystem may be required toInjection Pressure
WaterPressure
(a) Original graph
Injection,Pressure
WaterPressure
(b) Merging upwardsInjection
Pressure,WaterPressure
(c) Merging downwards
Figure 3: Transforming a graph into a tree with
Injection as root
œÅi‚Üê getWitness(tp)
foreach Mj in DirDep(Mi)inputSeq‚ÜêgetInputSeq(œÅi, Mi, Mj)
reqInputsTp‚ÜêbuildTestPredicate(inputSeq)
œÅj ‚ÜêgenerateTest(Mj, reqInputsTp)
œÅi‚Üêmerge(œÅi, œÅj) return test œÅigenerateTest( Mi tp)
generateTestPart for Mj
finish?
truetruetruefalse
Figure 4: Control ow of the test generation algo-
rithm
provide dierent values to dierent subsystems at the same
time, so complicating our test generation approach.
If the subgraph does not have a tree-structure, we keep
on merging adjacent subsystems (among those reachable
fromMi) untilMibecomes the root of a tree. Note that
transforming a graph into a tree having Mias root can be
performed in dierent ways. Fig. 3 shows two possible ways
of obtaining the tree: merging the nodes upwards towards the
desired root (as in Fig. 3b), or merging the nodes downwards
away from the desired root (as in Fig. 3c). In the experiments
executed for this paper, we have adopted the latter approach.
However, as future work we plan to avoid the transformation
to a tree and to generate tests directly from the original
dependency graph of subsystems.
The test generation for a test predicate tpis briey visually
represented in Fig. 4. It consists in a recursive function
generateTest that takes in input a subsystem MiofM
and a test predicate tpwhichMis compatible with. The
function generateTest returns as test an allowed sequence
for covering tpover the composition of Miand its (direct
and indirect) dependent subsystems. The main steps of the
function are the following.
1.It ndsi, a witness for tpinMiby using a model
checker.Algorithm 1 Test generation algorithm generateTest for
a subsystem Miand its test predicates tp
Require: A subsystem Mi
Require: A test predicate tpforMi
Ensure: A complete test for Miand its dependencies
1:i√êgetWitnessptp;Miq
2:ifiUNFEASIBLE then
3: return UNFEASIBLE
4:end if
5:forMjPDirDeppMiqdo
6: inputSeq√êgetInputSeqpi;Mi;Mjq
7: reqInputsTp√êbuildTestPredicate pinputSeqq
8:j√êgenerateTest pMj;reqInputsTpq
9: ifjUNFEASIBLE_jUNKNOWN then
10: return UNKNOWN
11: end if
12:i√êmergepi;jq
13:end for
14:returni
2.For each dependency Mj, it generates a partial test
jby recursively calling itself. The test jof the
subsystemMjrepresents the input sequence ( inputSeq )
to be given to Mito exhibit the behavior shown by i.
3.It nally merges the obtained tests with iin order to
nd the nal test.
The translation of the input sequence ( inputSeq ) to a tem-
poral logic predicate to be used as test predicate is performed
by the function buildTestPredicate .
The algorithm is precisely described in Alg. 1 and explained
in the following. The algorithm traverses the dependency
tree in pre-order . As rst step, the generateTest function
computes, by means of function getWitness , the testi
si
0;:::;si
nto cover the test predicate tpoverMi(line 1). If the
test is not unfeasible, it computes all the direct dependencies
ofMi(line 5), and for each Mjof them:
It extracts from the test ithe input sequence inputSeq
for the linking variables LLpMi;Mjqtv1;:::;vku
(see Def. 14) using function getInputSeq (line 6):
inputSeqLpiqrti0
1;:::;i0
ku;:::;tin
1;:::;in
kus(1)
Applying function buildTestPredicate to the input
sequence inputSeq (line 7), it computes the test predi-
cate reqInputsTp forMj, dened as LTL property as
follows:
reqInputsTpin0^Xpin1^Xp:::Xpinnq:::qq(2)
being int¬ôk
h1vhit
h(t0;:::;n), and Xthe
next temporal connective. Note that reqInputsTp is the
LTL characterization of the input sequence inputSeq .
The test predicate has that particular form to obtain a
sequencej(in the next step of the algorithm), such
thatLpiqLpjqwithLLpMi;Mjq.
It recursively visits subsystem Mj(calling function
generateTest ), using reqInputsTp as test predicate
(line 8); as a result (if any), it gets the test j
sj
0;:::;sj
nforMjand its dependencies; note that jisguaranteed to be as long as iby the test predicate
construction.
If the returned test jis neither unfeasible nor unknown,
the testiismerged withjthrough function merge ,
obtaining the sequence s0;:::;sn(line 12) where sh
si
hYsj
h(h0;:::;n ), otherwise the test is unknown.
We call this technique StrongTP . Another version of the
technique will be described in the next section, where the
test predicate construction and the merging of the tests are
modied.
Example 5. Let us consider the transition system intro-
duced in Ex. 1, whose decomposition is shown in Ex. 4, and
the test predicate FphandleOPENq. The test predicate
is covered in M1by the test
1handle :s1
0hkkkkkikkkkkj
CLOSEDs1
1hkkkkkikkkkkj
CLOSEDs1
2hkkkikkkj
OPEN
locked : true false false(3)
The input sequence is tlockedtrueu;tlockedfalseu;
tlockedfalseu. The corresponding test predicate for M2
is:
locked^Xp locked^Xp lockedqq (4)
The test predicate is feasible in M2and covered by the test
2locked :s2
0hk kik kj
trues2
1hk kik kj
falses2
2hk kik kj
false
digit : 0 4 4(5)
The test1Y2for the global system is as follows
handle :s0hkkkkkikkkkkj
CLOSEDs1hkkkkkikkkkkj
CLOSEDs2hkkkikkkj
OPEN
locked : true false false
digit : 0 4 4
Soundness and Completeness
A technique is sound if each produced test is an allowed
sequence (see Def. 15).
Theorem 3.The StrongTP technique is sound .
Proof. Alg. 1 recursively visits all the (direct and indi-
rect) dependencies of subsystem Miand builds a test se-
quence for each subsystem. By Thm. 1, all the sequences
produced (at line 1) for the subsystem with no dependencies
are allowed: these subsystems are leaves of the dependency
graph (the recursive visit stops when a leaf is reached). If the
leaves are reached, all the sequences built (at line 1) for their
ancestors are allowed by Thm. 2 and the construction of the
test predicate at line 7 of the algorithm. The merging of the
sequences at line 12 produces an allowed sequence because
the common variables between subsystems are guaranteed
to be equal.
To prove completeness of the technique, we should prove
that each test predicate that can be covered on the global
system is also covered by the technique.
Theorem 4.The StrongTP technique is not complete.
Proof. As counterexample, consider a variation of the
Ex. 1 in Code 1 where the next assignment of variable locked
is modied as locked1:digit4(i.e., the locker becomes
unlocked only after the digit is observed to be 4), and still
consider FphandleOPENqas test predicate to cover.In order to cover some test predicates that are not cov-
ered by the StrongTP technique, in the following section we
slightly modify the technique, using a dierent (and less bind-
ing) version of the test predicate reqInputsTp in Formula 2
and a dierent way of merging sequences at line 12 of the
algorithm.
4.2 WeakTP Technique
Technique StrongTP requires that sequences built over the
single machines have the same length (by the test predicate
construction) and, therefore, that a given submachine Mi
receives, from its dependencies, the inputs it needs exactly
when it requires them. However, it may be that the dependent
subsystems may not be able to provide the required inputs
exactly when requested, but with some delay (some states
later). We modify technique StrongTP with technique Weak-
TP, in which dependent subsystems of Mican produce tests
jlonger than the test iproduced over Mi, and testiis
extended to match the length of tests j.
In this technique, the test predicate built with function
buildTestPredicate (from the input sequence in Formula 1)
at line 7 of Alg. 1 is dened as LTL formula as follows:
in0SXUpin1SXU:::pinn1SXU innq:::q
being int¬ôk
h1vhit
h(t0;:::;n), and SXU is a
new temporal operator dened as follows: ASXUB
A^XpAUBqwhere Uis the until temporal connective.
ASXUBmeans that Ais continuously true for at least one
state untilBbecomes true.
The testjsj
0;:::;sj
m, computed at line 8 of Alg. 1 with
the recursive call of function generateTest for covering the
test predicate (if feasible), is at least as long as i(i.e.,m¬•
n).jcan be split in n 1 sub-sequences j
0;:::;j
nhaving
the same values for the linking variables in LpMi;Mjq 
tv1;:::;vku, i.e.,
jj
0hkkkkkkikkkkkkj
sj
0;:::;sj
r11
in0;j
1hkkkkkkkikkkkkkkj
sj
r1;:::;sj
r21
in1;:::;j
nhkkkkkikkkkkj
sj
rn;:::;sj
m
inn
where, in all the states of each j
t,intholds, and 0¬†r1¬†
r2¬†:::¬†rn¬§m.
At line 12 of Alg. 1, sequences iandjmust be merged
with function merge . Sequences can be merged only if some
particular states of iarestutter prone .
Denition 17. Given a transition system MxA;P; y,
we call a state sstutter prone if, by executing Pfroms, we
can obtain s.
For each subsequence j
tlonger than one state (i.e., |j
t|¬°1),
statesi
tof sequence imust be stutter prone. If this condition
is not satised, the algorithm returns UNKNOWN . Otherwise,
sequencesiandjcan be merged as follows:
0hkkkkkkikkkkkkj
s0;:::;sr11;1hkkkkkkkikkkkkkkj
sr1;:::;sr21;:::;nhkkkkkikkkkkj
srn;:::;sm
j
0si
0 hkkkkkkkkkkkkkkikkkkkkkkkkkkkkj
sj
0Ysi
0;:::;sj
r11Ysi
0;:::;j
nsi
n hkkkkkkkkkkkkkikkkkkkkkkkkkkj
sj
rnYsi
n;:::;sj
mYsi
n(6)
wheretj
tsi
t(t0;:::;n), i.e., for each shof each
t,shsj
hYsi
t. Note that we can merge a state si
tofi
with all the states of j
tinj, sincesi
tis stutter prone and,
therefore, can be duplicated as many times as necessary.signatureA:
Vthandle;locked;digit;cmdu
...DcmdtUP;DOWN;NONEu
programP: ...
cmd1:randompDcmdq
digit1:ifcmdUPthenpdigit 1qmod 10
elseif cmdDOWN thenpdigit 9qmod 10
initial state : ...
cmdrandompDcmdq
Code 2: Modied running example
Example 6. The proof of Thm. 4 shows a test predicate
for the global system that cannot be covered with technique
StrongTP (since that technique requires locked to become
false after one step); the same test predicate, instead, can
be covered with technique WeakTP. Using the WeakTP
technique, the test predicate built for M2, starting from the
input sequence of the test for M1(see Formula 3), is
locked SXUp locked SXU lockedq
The test predicate is feasible in M2and the obtained test is
2locked :2
0hkkkkkkkikkkkkkkj
true true2
1hk kik kj
false2
2hk kik kj
false
digit : 0 4 4 4
Note that variable locked remains true in the rst two states
and becomes false only in the third state. Therefore, we
require state s1
0of sequence 1(see Formula 3) to be stutter
prone; since this is the case, the technique is applicable.
The test1Y2for the complete system is
handle :2
0s1
0 hkkkkkkkkkkkkkkikkkkkkkkkkkkkkj
CLOSED CLOSED2
1s1
1hkkkkikkkkj
CLOSED2
2s1
2hkkikkj
OPEN
locked : true true false false
digit : 0 4 4 4
Soundness and Completeness
Theorem 5.The WeakTP technique is sound.
Proof. If the technique returns a test, it means that in
sequenceisi
0;:::;si
nall the states required to be stutter
prone are so. Therefore, ican be extended to a sequence
1
isi1
0;:::; si1
m(by duplicating the states required to be
stutter prone) such that, for all the couples psi1
h;sj
hq, the
values of linking variables LpMi;Mjqare the same: this is
what we actually do in Formula 6. Then, the proof of Thm. 3
already proves that the composition of two sequences 1
iand
jof equal length and with the same values for variables in
LpMi;Mjqis correct.
Theorem 6.The WeakTP technique is not complete.
Proof. As counterexample, consider the modication,
shown in Code 2, of the transition system described in Ex. 1:
a random variable cmd over domain DcmdtUP;DOWN;
NONEuis introduced to model the transformation of the
variable digit that can be increased/decreased of only one
unit at a time. FphandleOPENqis still the test predicate
to cover. The subsystems are as shown in Fig. 5.V1="
handle;
locked*M1
V2="
locked;
digit*M2
lockedV3="
digit;
cmd*M3
digit V4=
tcmduM4
cmd
Figure 5: Modied running example { Dependency
graph
5. EXPERIMENTS
The proposed technique is in principle more ecient than
the model checking approach applied directly to the global
system, but it requires several assumptions, like that the
system is actually decomposed by using dependency among
variables, which may not hold in practice and the actual
advantages must be experimentally checked. We present
here a series of experiments to validate our approach.
We have performed a set of experiments using a represen-
tative example of NuSMV specications. NuSMV [12] is a
well-known tool that performs symbolic model checking. It
allows the representation of synchronous and asynchronous
nite state systems, and supports model checking of temporal
properties. A NuSMV specication describes the behavior of
a Finite State Machine (FSM) in terms of a \possible next
state" relation between states that are determined by the
values of variables. Its language can be easily mapped to the
formalism presented in Sect. 2.1. Furthermore, specications
written in ASM, Statecharts, Event-B, SCR, RSMLe, and
many other notations have been translated in NuSMV in
several previous works [16, 6, 11]. For these reasons, we
chose NuSMV for evaluating our approach.
We have gathered 119 NuSMV specications including
examples from the NuSMV site and models we have used
in the past for testing a static analysis tool [7]. Then we
have flattened all the models in order to eliminate modules
and parameters. We have reused the parser we have built
for NuSeen1, an eclipe-based framework for NuSMV. To
analyze the dependencies, build the dependency graph, and
compute the strongly connected variables sets, we have used
a feature recently introduced in NuSeen. Fig. 6a shows the
sizes of the considered specications in terms on number of
BDD variables (for 115 models, because 4 models having
more than 300 BDD variables are not included in the gure):
the majority of models have less than 100 BDD variables,
but there are still models with more than 100 variables.
Our technique, however, works considering the specication
variables; therefore, in Fig. 6b we report the distribution of
variables in the considered models (for 113 models, because
6 models having more than 200 variables are not included
in the gure): the distribution slightly corresponds to the
distribution of BDD variables.
We present here some research questions that guided our
experiments.
How many systems are decomposable by dependency?
We have applied the decomposition technique presented in
Sect. 3 to all the models. Fig. 6c reports the number of
variables for subsystem on average over all the models. Most
of the models (109/119) have on average less than 4 variables
for subsystem. The ideal situation of each subsystem having
only one variable occurs for 33 models which originally have,
on average, 18.12 variables. Only 5 models were completely
1http://nuseen.sourceforge.net/not decomposable by our technique. On average, every sub-
system has 1/39th of the variables of the entire system. The
data shows that dependencies among variables can eciently
guide system decomposition.
How many dependency subgraphs are trees?
One major assumption of the algorithm presented in Sect. 4.1
is that the subgraph including the subsystem Miand all its
dependencies is a tree. We found that this is true in 52%
of all the subsystems we have examined. In all the other
cases, the subgraph must be transformed in a tree by merging
nodes, as explained in Sect. 4.1. The transformation may
increase the complexity of the SCVs and jeopardize the
advantages of the decomposition: the worst situation would
be when all the subsystems except Miare merged together,
causing a decomposition of the system only in half. We have
implemented a simple algorithm that merges SCVs until no
more undirected cycles are found and the subgraph becomes
a tree. We have then measured the number of vertexes
and the average of number of variables in each subsystem.
We have found that on average the number of variables for
subsystem raises from 4.36 to 7.63, while the number of
subsystems decreases from 19 to 11. So, the decomposition
is less ecient, but it is still able to reduce the system size
by a factor around 10 even for the 48% of the cases in which
the dependency subgraph is not already a tree (i.e., from an
average of 102 variables in the global system to an average
of 7.63 variables per subsystem).
Does test generation actually beneÔ¨Åt from system de-
composition?
We experimented whether the technique presented in Sect. 4
is really useful for test generation. We took three NuSMV
specications: BombRel , the bomb-release component of the
ight-control software of an attack aircraft [23], SIS, a sim-
plied specication of the control software for the safety
injection component of a nuclear power plant [22], and Lock
a simple digital lock that requires the insertion of the right
sequence of numbers on dierent keypads in order to un-
lock [28]. Fig. 7 shows the dependency graphs of the three
case studies.
For each specication, we made two versions (v1 and v2)
by increasing the size of the variables domains. For instance,
inSISthe domain of the variable WaterPressure is from 0
to 5000 in version v1, and from 0 to 9000 in version v2. For
BombRel , we choose two dierent test predicates. The rst
one simply requires to observe BombRelease set to on, while
the second one also requires that MissDistance is at least
10; the second test predicate has been built in a way that
technique StrongTP is not able to nd a test, but technique
WeakTP is.
Table 1 reports the memory required and time took by the
classical generation over the complete systems (column Com-
plete) and by the proposed generation over the decomposed
subsystems (column Decomposition ). For each considered
test predicate, we have used the StrongTP technique when
possible, otherwise we have used the WeakTP technique (this
has always been applicable since all the states required to
be stutter prone were so). The gain diers in the dierent
specications: this is due both to the considered test predi-
cate and to the degree of decomposition of the system (the
more the variables are distributed among the subsystems, the
better it is). Using the proposed technique greatly diminishes(a) # BBD variables
 (b) # variables
 (c) # variables for subsystem (avg)
Figure 6: Data about the models used in the experiments
(a) BombRel
 (b) SIS
 (c) Lock
Figure 7: Dependency graphs for the case studies
the required memory and time (column ) in all the cases,
except in one case in which the use of memory is increased
probably due to the higher complexity of the test predicate
containing the SXU operator.
Note that our technique might not be able to cover a test
predicate that is feasible: this may weaken the fault detection
with respect to the model checking approach applied directly
to the global system (that, however, might also not be able
to cover the test predicate for the state explosion problem).
Nonetheless, whenever our technique is complete, the fault
detection and the coverage provided by the test cases are
the same as those obtained by using the model checking
approach on the global system.
6. RELATED WORK
Since our approach is based on model checking, one may im-
mediately think of reusing abstraction techniques introduced
for formal verication. For this reason, we initially compare
our work to the research done in the area of abstractions for
property verication.
The cone of inuence (COI) technique [15] reduces the
size of the transition graph by removing from the model the
variables that do not inuence the variables in the property
one wants to check. In [29], COI is used to reduce the
state space of fFSM models, a variant of Harel's Statecharts;
models that could not be veried before, have been veried
successfully after its application. COI works well also for
test generation, but only if the variables in the property
to be veried have few dependencies. For subsystems deep
inside the dependency graph, COI is unable to reduce the
specication. Actually, our technique subsumes COI, since
we also remove variables that are not necessary for covering
a test predicate.
The data abstraction technique [15], instead, consists in
creating a mapping between the data values and a small
set of abstract data values; the mapping, extended to states
and transitions, usually reduces the state space, but it may
not preserve properties. In [13], a technique called CEGARis presented, to iteratively rene an abstract model. The
technique assures that, if a property is true in the abstract
model, so it is in the initial model; if it is false in the abstract
model, instead, the spurious counterexample may be the
result of some behavior in the abstract model not present in
the original model. The counterexample itself is used to rene
the abstraction so that the wrong behavior is eliminated.
CEGAR is not suitable for testing: indeed, the returned
counterexample usually does not contain all the variables
since the abstraction removes specication parts, and it may
be spurious.
A technique for sequential modular decomposition for prop-
erty verication of complex programs is presented in [27].
The approach consists in partitioning the program into se-
quentially composed subprograms (instead of the typical
solution of partitioning the design into units running in par-
allel). Based on this partition, the authors present a model
checking algorithm for software that arrives at its conclusion
by examining each subprogram in separation. They identify
ending states in the component where the computation is con-
tinued in another component and some information passed to
the next subprogram. The algorithm then tries to formally
prove the property in each component nding the necessary
assumptions about the initial (entering) states of the compo-
nent. The algorithm proceeds backwards until it nds that
the property is true in every sub-component starting from
any initial state of the system. Since the goal is formal veri-
cation, the algorithm must check that the property holds
inanystate, while in our approach disproving a property is
not enough since we want to nd a counterexample, i.e., a
path leading to interesting states in which a suitable prop-
erty is false. Moreover, we decompose the entire system in
subsystems that run in parallel and not sequentially.
There exist few abstraction techniques that are suitable
for test generation. Reduction techniques like nite focus [2]
soundly reduce the original specication to a smaller one for
which it may be easier to nd the desired tests. Finite focus
maps variables with large or unbounded domains to a xed
subset of possible values. In this case the number of variablesTable 1: Memory consumption (BDD size) and time (seconds)
Specication Test predicate Complete Decomposition 
mem. time Technique mem. time mem. time
(max) (sum)
BombRel v1 BombRelease = on 363016 5.8 StrongTP 195885 4.04 -46% -30%
BombRelease = on & MissDistance ¬•10 473027 9.0 WeakTP 333677 4.32 -29% -52%
BombRel v2 BombRelease = on 970498 47.4 StrongTP 646327 39.1 -33% -17%
BombRelease = on & MissDistance ¬•10 924291 69.1 WeakTP 1058389 40.2 +14% -41%
SISv1 SafetyInjection = on 547238 6.32 WeakTP 238705 5.68 -56% -10%
SISv2 SafetyInjection = on 788361 19.5 WeakTP 437094 18.4 -44% -5%
Lock v1 unlock 409813 0.27 WeakTP 1676 0.04 -99% -86%
Lock v2 unlock 547238 6.32 WeakTP 1676 0.08 -98% -98%
to be considered is not reduced but their domains are. In
order to avoid unsound counterexamples, some constraints
must be added and there is not guarantee that the speci-
cation is actually simpler than the original one. Moreover,
how to reduce domain sets may be a dicult task and no
algorithm is given for that. Finite focus could be used also in
conjunction with our approach when generating the tests for
a single subsystem. In general, our technique is compatible
with all the reduction abstractions.
An approach performing test generation by decomposing
sequential programs , called SMART, is presented in [20].
It proposes a sequential decomposition technique: given a
program calling several functions inside it, these called func-
tions are tested in isolation and complete tests are composed
only at the end. The main dierence with our approach
is that tests for sub-functions are not real tests but they
are expressed as summaries using input preconditions and
output postconditions, and then re-used when testing higher-
level functions. The main advantage is that SMART is both
sound and complete compared to monolithic test generation,
while our approaches are only sound. A disadvantage is that
SMART must maintain the summaries and it can solve them
only at the end. Sometimes constraints on some inputs can
not be expressed (for instance a hash function) and some-
times all the collected constraints are very hard to solve,
leaving some issues still open.
The approach we presented in [8] shares with this work
the idea of exploiting system decomposition to tackle the
limitation of model-based test generation by model checking.
It presents a technique to build test for Decomposable by
Dependency Asynchronous Parallel (DDAP) systems, which
are systems composed of several subsystems running in par-
allel and connected together in a way that the inputs of
one subsystem are provided by another subsystem. Apart
sharing the philosophical idea of tacking a problem by de-
composing it into smaller problems, the approaches dier
(1) on the way a system is decomposed, (2) on the class of
obtained dependent subsystems (that in [8] are interleaving
subsystems, while here we have parallel subsystems), and
(3) on the way a test for the whole system is built on the
base of the tests for the subsystems (concatenation of tests
in [8], merging of tests here).
In [4], we proposed a test generation technique for sequen-
tial net s of Abstract State Machines (ASMs), which represent
systems constituted by a set of ASMs such that only oneASM is active at a time. Given a net of ASMs, a test suite
for every ASM in the net is built, and then the tests are
combined in order to obtain a test suite for the entire system.
The technique has been later extended in [5] for handling
the passing of information between subsystems. Apart the
dierent notation, the main dierence with this work is that
in [4, 5] we suppose to already have the decomposed sub-
systems, whereas here we propose a way to decompose the
global system. Moreover, in [4, 5] the subsystems run in
sequence, while here they run in parallel.
7. CONCLUSIONS
We have proposed a test generation approach by model
checking that decomposes systems into dependent subsys-
tems on the base of the system variables dependency. Such
dependent subsystems coming from the system decomposi-
tion can be viewed as systems linked each other { on the
base of the variables dependency { in a way that (part of)
the inputs of one subsystem are provided by another sub-
system. Therefore, a test of the global system can be built
by suitably merging tests of the single subsystems. Such
approach permits to mitigate the state explosion problem of
model checking since the time and the memory required to
build a test for each subsystem is considerably less than the
time and the memory required when considering the system
globally. The method has been proved to be sound but not
complete, and its eciency w.r.t. the same model-based
testing approach without system decomposition has been
shown by a number of experiments on NuSMV models.
Currently, we automatically build the dependency graphs,
but not the subsystems and the test predicates. As future
work, we plan to completely automatize our approach and
to consider test predicates possibly involving more than one
subsystem. This will allow us to perform a larger evaluation
on more models across a variety of sizes. Moreover, we plan
to better investigate which is the best solution for merging
the subsystems when their dependency graph is not a tree.
8. REFERENCES
[1] J. Abrial. Modeling in Event-B - System and Software
Engineering . Cambridge University Press, 2010.
[2] P. Ammann and P. Black. Abstracting formal
specications to generate software tests via model
checking. In Digital Avionics Systems Conference, 1999.Proceedings. 18th , volume 2, pages 10.A.6{1{10.A.6{10
vol.2, 1999.
[3] P. Ammann and J. Outt. Introduction to Software
Testing . Cambridge University Press, New York, NY,
USA, 1 edition, 2008.
[4] P. Arcaini, F. Bolis, and A. Gargantini. Test
Generation for Sequential Nets of Abstract State
Machines. In J. Derrick, J. Fitzgerald, S. Gnesi,
S. Khurshid, M. Leuschel, S. Reeves, and E. Riccobene,
editors, Proceedings of the Third International
Conference on Abstract State Machines, Alloy, B,
VDM, and Z (ABZ 2012), Pisa, Italy, June 18-21,
2012, volume 7316 of Lecture Notes in Computer
Science , pages 36{50. Springer, 2012.
[5] P. Arcaini and A. Gargantini. Test generation for
sequential nets of Abstract State Machines with
information passing. Science of Computer
Programming , 94, Part 2(0):93 { 108, 2014.
[6] P. Arcaini, A. Gargantini, and E. Riccobene.
AsmetaSMV: a way to link high-level ASM models to
low-level NuSMV specications. In Proceedings of the
2nd International Conference on Abstract State
Machines, Alloy, B and Z (ABZ 2010) , volume 5977 of
Lecture Notes in Computer Science , pages 61{74.
Springer, 2010.
[7] P. Arcaini, A. Gargantini, and E. Riccobene. A model
advisor for NuSMV specications. Innovations in
Systems and Software Engineering , 7(2):97{107, 2011.
[8] P. Arcaini, A. Gargantini, and E. Riccobene. An
abstraction technique for testing decomposable systems
by model checking. In M. Seidl and N. Tillmann,
editors, Tests and Proofs , volume 8570 of Lecture Notes
in Computer Science , pages 36{52. Springer
International Publishing, 2014.
[9] R. Cavada, A. Cimatti, C. A. Jochim, G. Keighren,
E. Olivetti, M. Pistore, M. Roveri, and A. Tchaltsev.
NuSMV 2.5 User Manual. http://nusmv.fbk.eu/ ,
2010.
[10] J. J. Chilenski and S. P. Miller. Applicability of
modied condition/decision coverage to software
testing. Software Engineering Journal , 9(5):193{200,
1994.
[11] Y. Choi and M. P. E. Heimdahl. Model checking
RSML-e requirements. In 7th IEEE International
Symposium on High-Assurance Systems Engineering
(HASE 2002), 23-25 October 2002, Tokyo, Japan ,
pages 109{118. IEEE Computer Society, 2002.
[12] A. Cimatti, E. M. Clarke, E. Giunchiglia,
F. Giunchiglia, M. Pistore, M. Roveri, R. Sebastiani,
and A. Tacchella. NuSMV Version 2: An OpenSource
Tool for Symbolic Model Checking. In Proceedings
International Conference on Computer-Aided
Verication (CAV 2002) , volume 2404 of Lecture Notes
in Computer Science . Springer, July 2002.
[13] E. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith.
Counterexample-guided abstraction renement for
symbolic model checking. J. ACM , 50:752{794, 2003.
[14] E. Clarke, W. Klieber, M. Novacek, and P. Zuliani.
Model checking and the state explosion problem. In
B. Meyer and M. Nordio, editors, Tools for Practical
Software Verication , volume 7682 of Lecture Notes inComputer Science , pages 1{30. Springer Berlin
Heidelberg, 2012.
[15] E. M. Clarke, O. Grumberg, and D. A. Peled. Model
Checking . MIT Press, 1999.
[16] E. M. Clarke and W. Heinle. Modular Translation of
Statecharts to SMV. Technical report, Carnegie Mellon
University, 2000.
[17] G. Fraser and A. Gargantini. An evaluation of model
checkers for specication based test case generation. In
ICST 2009, 1-4 April 2009, Denver, Colorado, USA ,
pages 41{50. IEEE Computer Society, 2009.
[18]A. Gargantini and C. Heitmeyer. Using model checking
to generate tests from requirements specications. In
Proceedings of ESEC/FSE'99 , volume 1687 of Lecture
Notes in Computer Science , pages 146{162, London,
UK, 1999. Springer Berlin Heidelberg.
[19] A. Gargantini and E. Riccobene. ASM-Based Testing:
Coverage Criteria and Automatic Test Sequence.
Journal of Universal Computer Science ,
7(11):1050{1067, 2001.
[20] P. Godefroid. Compositional dynamic test generation.
InProceedings of the 34th annual ACM
SIGPLAN-SIGACT symposium on Principles of
programming languages , POPL '07, pages 47{54, New
York, NY, USA, 2007. ACM.
[21] M. P. E. Heimdahl, S. Rayadurgam, and W. Visser.
Specication Centered Testing. In Proceedings of the
Second International Workshop on Automated Program
Analysis, Testing and Verication (ICSE 2001) , 2001.
[22] C. Heitmeyer, R. Jeords, and B. Labaw. Automated
consistency checking of requirements specications.
ACM Transactions on Software Engineering and
Methodology , 5(3):231{261, July 1996.
[23] K. L. Heninger, J. Kallander, D. L. Parnas, and J. E.
Shore. Software requirements for the A-7E aircraft.
NRL Memorandum Report 3876, United States Naval
Research Laboratory, Washington DC, Nov. 1978.
[24] R. Hierons and J. Derrick. Editorial: special issue on
specication-based testing. Software Testing,
Verication and Reliability , 10(4):201{202, 2000.
[25] G. J. Holzmann. The SPIN Model Checker - primer
and reference manual . Addison-Wesley, 2004.
[26] H.-M. Koo and P. Mishra. Functional test generation
using design and property decomposition techniques.
ACM Trans. Embed. Comput. Syst. , 8(4):32:1{32:33,
July 2009.
[27] K. Laster and O. Grumberg. Modular model checking
of software. In B. Steen, editor, Tools and Algorithms
for the Construction and Analysis of Systems , volume
1384 of Lecture Notes in Computer Science , pages
20{35. Springer, 1998.
[28] E. F. Moore. Gedanken experiments on sequential
machines. In Automata Studies , pages 129{153,
Princeton, 1956.
[29] S. Park and G. Kwon. Avoidance of State Explosion
Using Dependency Analysis in Model Checking Control
Flow Model. In ICCSA 2006 , volume 3984 of Lecture
Notes in Computer Science , pages 905{911. Springer,
2006.
[30] D. Peled. Software Reliability Methods . Texts in
Computer Science. Springer, 2001.[31] W. Prenninger and A. Pretschner. Abstractions for
Model-Based Testing. Electron. Notes Theor. Comput.
Sci., 116:59{71, Jan. 2005.
[32] M. Utting and B. Legeard. Practical Model-Based
Testing: A Tools Approach . Morgan-Kaufmann, 2006.[33]B. Xu, J. Qian, X. Zhang, Z. Wu, and L. Chen. A brief
survey of program slicing. SIGSOFT Softw. Eng. Notes ,
30(2):1{36, Mar. 2005.