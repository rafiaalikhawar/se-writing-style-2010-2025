AssertionGuidedSymbolicExecution 
ofMultithreadedPrograms 
ShengjianGuo 
VirginiaTech 
Blacksburg,VA,USA MarkusKusano 
VirginiaTech 
Blacksburg,VA,USA ChaoWang 
VirginiaTech 
Blacksburg,VA,USA 
ZijiangYang 
WesternMichiganUniversity 
Kalamazoo,MI,USA AartiGupta 
PrincetonUniversity 
Princeton,NJ,USA 
ABSTRACT 
Symbolic execution is a powerful technique for systematic t esting 
ofsequentialandmultithreadedprograms. However,itsapp lication 
islimitedbythehighcostofcoveringallfeasibleintra-th readpaths 
and inter-threadinterleavings. Wepropose a new assertion guided 
pruningframeworkthatidentiﬁesexecutionsguaranteedno ttolead 
toanerror andremoves them duringsymbolic execution. Bysu m- 
marizing the reasons why previously explored executions ca nnot
reachanerrorandusingtheinformationtopruneredundante xecu- 
tionsinthefuture,wecansoundlyreducethesearchspace. W ealso 
usestaticconcurrentprogramslicingandheuristicminimi zationof 
symbolic constraints tofurtherreduce thecomputational o verhead.
We have implemented our method in the Cloud9 symbolic execu- 
tion tool and evaluated it on a large set of multithreaded C/C ++ 
programs. Our experiments show that the new method can reduc e
theoverallcomputationalcostsigniﬁcantly.
CategoriesandSubjectDescriptors 
F.3.1 [ LogicsandMeaningsofPrograms ]: Specifying and Veri- 
fying and Reasoning about Programs; D.2.4 [ SoftwareEngineer-
ing ]: Software/ProgramVeriﬁcation 
Keywords 
Symbolic execution, test generation, concurrency, partia l order re- 
duction,weakestprecondition 
1. INTRODUCTION 
The past decade has seen exciting developments on symbolic 
execution of both sequential [19, 42, 48, 8] and concurrent p ro- 
grams [41, 38, 14, 5]. However, existing methods are still li mited 
in their capability of mitigating the state space explosion . That is,
thenumberofpathsineachthreadmaybeexponential tothenu m- 
ber of branch conditions, and the number of thread interleav ings 
maybeexponential tothenumber ofconcurrent operations. M any 
techniques have been proposed to address this problem, incl uding 
theuseoffunctionsummaries[18],interpolation[34,23,6 1],static 
Permission to make digital or hard copies of all or part of thi s work for 
personalorclassroomuseisgrantedwithoutfeeprovidedth atcopiesarenot
madeordistributed forproﬁtorcommercial advantage andth atcopiesbear 
thisnoticeandthefullcitationontheﬁrstpage. Copyright sforcomponents 
ofthisworkownedbyothersthanACMmustbehonored. Abstrac tingwith 
creditispermitted. Tocopyotherwise,orrepublish,topos tonserversorto 
redistribute tolists,requirespriorspeciﬁcpermissiona nd/orafee. Request
permissionsfrompermissions@acm.org.
ESEC-FSE’15, August31–September 4,Bergamo,Italy.
Copyright 2015ACMX-XXXXX-XX-X/XX/XX...$15.00.Summary Executions Computing Pruning 
no no 
yes yes Symbolic 
Execution 
(in,sch ′) ( in ′,sch )(in,sch )
Flipb-PP? End Flipi-PP? Initial
Slicing Static 
TestInput
Figure1:Ourassertionguidedpruningframework.
analysis [7], and coverage metrics [14]. In this paper, we pr opose 
a new and complementary method, which is designed speciﬁcal ly 
forpruningredundantexecutionsinmultithreadedprogram swhere 
thepropertiesunderveriﬁcationareexpressedasassertio ns.
Our assertion guided symbolicexecutionframeworkfocuses on 
identifyingandeliminatingexecutionsthatareguarantee dtobere- 
dundant for checking assertions. Assertions can be used to m odel
awidevarietyofinterestingproperties, rangingfromlogi candnu- 
merical errors, to memory safety and concurrency errors, an d has 
beenthefocusofmanysoftwareveriﬁcationprojects. Whens eman- 
tic errors of the program are modeled as simple code reachabi lity,
i.e., the reachability of a bad state guarded by the assertio n condi- 
tion, we can concentrate on exploring potentially failure- inducing 
executions as opposed to all feasible executions of the prog ram.
Thisisparticularlyattractiveinthepresence of concurrency , since 
it becomes possible to uniformly handle the exploration of b oth 
intra-thread execution paths and inter-thread interleavi ngs leading 
toasimplebutmorepowerfulanalysisalgorithm.
The overall ﬂow of our new method is illustrated in Figure 1:
the shaded block represents our addition and the remainder i llus- 
trates the classic symbolic execution procedure for multit hreaded 
programs[41]. Speciﬁcally,givenaprogram Pandsomesymbolic 
input variables, the procedure explores the feasible execu tions of 
theprogramsystematically,e.g.,inadepth-ﬁrstsearchor der.
Starting with an initial test (in ,sch )consisting of inputs and 
threadschedule,themethodﬁrstproducesaconcreteexecut ionfol- 
lowed by a symbolic execution. Then, it tries to generate a ne w
testbyﬂippingapriordecisionateitheraninterleavingpi votpoint
(i-PP)oralocalbranchpivotpoint(b-PP).Thenewtestisde noted 
by either (in ,sch ′)or (in ′,sch ), depending on whether changes 
are made to the thread schedule ( sch ′) or data input ( in ′), respec- 
tively. Theiterativeprocedure terminateswhennonew test canbe 
generated. Stateexplosionoccursbecauseithastoexplore thecom- 
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ESEC/FSE’15 , August 30 – September 4, 2015, Bergamo, Italy
c2015 ACM. 978-1-4503-3675-8/15/08...$15.00
http://dx.doi.org/10.1145/2786805.2786841
854bined space of inputs and thread schedules where each indivi dual
executionmaybeunique,i.e.,itleadstoadifferentprogra mstate.
We extend the baseline algorithm by adding a constraint-bas ed 
pruningblockshowninFigure1,whichcentersaroundtheide aof 
summarizing the reasons whythe bad state is unreachable via pre- 
viously explored executions, and leveraging such informat ion to 
avoid similarly futile executions. Speciﬁcally, at each gl obal con- 
trollocation n,weuseapredicatesummary(PS)constrainttocap- 
turethe weakestpreconditions [13]oftheassertionconditionalong 
allexploredexecutions startingfrom n. Therefore, PS [n]captures 
the reason why prior executions are not able to violate the as ser- 
tion. Whenever symbolic state nis reached again through another 
executionpath,wecheckifthenew pathcondition issubsumedby 
PS [n]. If so, we can safely backtrack from nsince extending the 
executionbeyond nwouldneverleadtoabadstate.
Our method for pruning redundant executions can be viewed as
a wayof systematicallyexploring anabstract searchspace d eﬁned 
by a set of predicates [4] which, in this case, are extracted f rom 
the assertion. Although the concrete search space may be arb itrar- 
ily large, the abstract search space can be signiﬁcantly sma ller. In 
this sense, our method is similar to predicate abstraction [21] in 
model checking except that the latter requires constructin ga pri- 
ori a ﬁnite-statemodel from the actual software code whereas ou r
method directly works on the software code while leveraging the 
predicatestoeliminateredundantexecutions.
Our method complements partial order reduction (POR) tech-
niques in that it relies on property-speciﬁc information to reduce 
thestatespace. But,PORtechniques typicallydonot target partic- 
ularstates. Wewillshowthroughexperimentsthatournewme thod 
canindeedeliminateadifferentclassofredundantexecuti onsfrom 
those eliminated by state-of-the-art POR techniques, such as dy- 
namicpartialorderreduction(DPOR)[16]. Towardthisend, since 
DPORisanelegantbutdelicatealgorithm thatcaneasilybem ade 
unsound without taking great care in the implementation [59 ], a 
maintechnicalchallengeinourworkistomakesureournewpr un- 
ingmethoddoesnotinterferewithDPORormakeitlesseffect ive.
OurmethoddiffersfrompriorworksbyWachteretal.[51],an d
Chu andJaffar [9], whichextended the frameworkof lazyabst rac- 
tion with interpolants [34] to multithreaded programs. One main 
differenceisthatourcomputationofpredicatesummariesi ssignif- 
icantlymoregeneralthanexistingmethods,especiallyatt hethread 
interleaving pivot points, where we merge summaries from mu lti- 
ple execution paths to form a combined summary. Another main
difference is in the integration of property speciﬁc prunin g with 
partialorderreduction. Bothexistingmethodsimplemente davari- 
ant of thesymbolic partialorder reduction algorithmby Kah lonet
al.[26]whereasweintegrateourpredicatesummary-basedp runing 
methodwiththemorescalableDPORalgorithm.
Wehaveimplementedourmethodin Cloud9 [11],astate-of-the- 
artsymbolicexecutiontoolformultithreadedC/C++progra ms. We 
have implemented an inter-procedural static program slici ng algo- 
rithm[22],executed priortosymbolicexecution, tofurthe rreduce 
the search space. We have also implemented heuristic based m in- 
imizations of predicate summary constraints during symbol ic ex- 
ecution to reduce the computational overhead. In both cases , the 
maintechnicalchallengeistoensuretheoverallalgorithm remains 
sound in the presence of such optimizations. We have conduct ed 
experimentsonasetofstandardmultithreadedC/C++applic ations.
Our results show that the new method can reduce the number of 
exploredexecutionsaswellastheoverallruntimesigniﬁca ntly.
Tosumup,thispapermakesthefollowingcontributions:
•We propose anassertion guided symbolic execution method 
for eliminating redundant executions in multithreaded pro -
gramstoreducetheoverallcomputationalcost.•Weimplementourmethodinastate-of-the-artsymbolicexe-
cutiontool whileensuring itdoes not interferewiththe pop -
ularDPORalgorithmormakeitlesseffective.
•We demonstrate through experiments that our new method 
can indeed achieve a signiﬁcant performance improvement
onpublicbenchmarks.
The remainder of this paper is organized as follows. First, w e
illustrate our new method through examples in Section 2, the n es- 
tablishthe notationand review the baseline symbolic execu tion al- 
gorithm inSection 3. We present our method for summarizing e x- 
plored executions in Section 4 and pruning redundant execut ions 
inSection5. We present optimization techniques inSection 6and 
experimental results in Section 7. We review related work in Sec- 
tion8andﬁnallygiveourconclusionsinSection9.
2. MOTIVATINGEXAMPLES 
In this section, we illustrate the high-level ideas in our me thod 
using examples. Consider the example inFigure 2, whichhas t wo 
threads T1and T2, a global variable x, and two local variables a
and b. The initialvalue of xis a symbolic input which can be any 
integer value. We want to check if the assertion fails and, if so,
computeafailure-inducingtestinput.
x = symbolic(V); 
if(x>10) return; 
----[T1]-----------------------------[T2]---- 
x = 10; a = x; 
x = 20; b = x; 
--------------------------------------------- 
assert( a<=b ) 
(x≤10) 
a=x;
a=x;n1
n2
n4
n7n5n3
n6
n8
n9a=x;
x= 20 ;x= 10 ;
x= 10 ;
x= 20 ;b=x;b=x;b=x;x= 10 ;
x= 20 ;
run#1 run#2 
run#3 run#4 
run#6 
(a≤b)
Run1:if(x<=10)x=10;x=20;a=x;b=x; leadsto (a=20,b=20) .
Run2:if(x<=10)x=10;a=x;x=20;b=x; leadsto (a=10,b=20) .
Run3:if(x<=10)x=10;a=x;b=x;x=20; leadsto (a=10,b=10) .
Run4:if(x<=10)a=x;x=10;x=20;b=x; leadsto (a=V ,b=20) .
Run5:if(x<=10)a=x;x=10;b=x;x=20; leadsto (a=V ,b=10) .
Run6:if(x<=10)a=x;b=x;x=10;x=20; leadsto (a=V ,b=V ) .
a=x; n1
n2
n4n3
n6b=x;x= 10 ;
x= 20 ;
n5
n7 n7 n7 n8 n8x= 10 ;
n8x= 10 ;
n5
a=x;a=x;
b=x;b=x;x= 20 ;
b=x; b=x;x= 20 ;(x≤10) 
x= 20 ;b=x;
x= 20 ;x= 20 ;
n9
(a≤b)n9 n9 n9 n9 n9
(a≤b) ( a≤b) ( a≤b) ( a≤b) ( a≤b)
Figure2:Ourmethodhastoexploreonefullrunandfourpar-
tialruns,asopposedtoallsixrunsbyexistingmethods.
855Theprogramhassixdistinctexecutions,eachleadingtoadi ffer- 
ent ﬁnal state deﬁned by the values of aand b. According to the 
theory of partial order reduction [16], they belong to six di fferent
equivalence classes [32], as each has a different ﬁnal state . How- 
ever, exploring all six executions is not necessary for the p urpose 
ofcheckingtheassertion,sincesomeoftheseexecutions sh arethe 
samereasonwhytheycannotreachthebadstate. Ournewmetho d
can reduce the exploration from six executions to one full ex ecu- 
tion together with four partial executions, as illustrated by the red 
dottedlinesinFigure2.
Our method ﬁrst extracts a set of predicates by computing the
weakestpreconditionsoftheassertionconditionalongthe explored 
executions. Thesepredicatesarethencombinedatthemerge points 
(inthegraph) toformasuccinct summarythatcaptures there ason 
whythebadstatehasnotbeenreachedviaexecutionsstartin gfrom 
these merge points. During subsequent symbolic execution i tera- 
tions,ourmethodneedstoexploreonlythoseexecutions tha thave 
not be covered by these predicates, thereby leading to a soun d re- 
ductionofthesearchspace.
Now,weexplainhowourmethodworksonthisexample:
•Run 1 is the ﬁrst and only execution fully explored, which 
goes through nodes n1,n2,n4,n7in the graph in Figure 2 
beforeexecuting b=x;if(a<=b) .Sinceitdoesnotviolation 
theassertion,wesummarizethereasonat n9and n7,respec- 
tively,asfollows: PS [n9] = ( a≤b)and PS [n7] = ( a≤x).
That is, as long as (a≤x)holds at node n7, it would be 
impossiblefortheexecutiontoreachthebadstate.
•Run 2 goes through n1,n2,n5before reaching n7, where 
its path condition is pcon [n7] = ( V≤10) and symbolic 
memoryis M=(a=10,x=20) . Since pcon [n7]→PS [n7]
under M, meaning the set of reachable states falls inside 
PS [n7],continuingtheexecutionfrom n7wouldnotleadtoa 
badstate. Therefore,weskiptheremainderofthisexecutio n.
•Run 3 goes through nodes n1,n2,n5,n8before reaching 
n9, where its path condition again falls within PS [n9]. We 
skiptheremainderofthisexecutionandupdatethesummary 
atn8and n5as follows: PS [n8] = ( a≤b)and PS [n5] = 
wp [n7]∧wp [n8] = ( a≤20) ∧(a≤x). By conjoining 
theweakestpreconditionsalongbothinterleavings n5→n7
and n5→n8, we capture the summary common to both 
interleavings.
•Run 4 goes through nodes n1,n3before reaching n5, with 
thenewpathcondition pcon [n5] = ( V≤10) andsymbolic 
memory M=(a=V,x=10) . Since pcon [n5]→PS [n5]un- 
der M,weskiptheremainderofthisexecution,whichwould 
haveledtoRun4andRun5ifitisallowedtocontinue.
•Run 6 goes through nodes n1,n3,n6before reaching n8,
wherethenewpathconditionfallswithin PS [n8]. Therefore,
weskiptheremainderofthisexecution.
•Atthismoment,ourmethodhascompletedtheexploration.
Note that we conjoin weakest preconditions from different inter- 
leavings at i-PP nodes such as n5, butunion them from different
thread-localpathsatb-PPnodes(seeSection4.) Alsonotet hatthe 
amount of reduction achieved by our method depends on the pro -
gramstructureaswellasthelocationoftheassertion. Fore xample,
if we change if(x>10) to if(x>11) , our method would have to 
exploreRun5insteadofskippingitbecause pcon [n5] = ( V≤11) 
wouldnolongerbesubsumedby PS [n5] = ( V≤10) .
This example demonstrates that our method differs from par-
tial order reduction techniques such as DPOR [16] which coul d
not prune away any of the six interleavings. Furthermore, ou r
method also differs from the stateful state space explorati on tech- 
niques commonly used in model checking, which record the for -
ward reachable states explicitly during exploration to pre vent vis- x = y = z = 1; 
---[T1]--------------[T2]--- 
a = x; x = 10; 
---------------------------- 
assert(a>0) 
---[T1]-------------[T3]---- 
b = y; y = 10; 
---------------------------- 
assert(b>0) 
---[T1]-------------[T4]---- 
c = z; z = 10; 
---------------------------- 
assert(c>0) x=y=z= 1;
(b > 0) (a > 0) 
(c > 0) 
*Run1:a=x;x=10;if(a>0);b=y;y=10;if(b>0);c=z;z=10;if(c>0) .
*Run2:a=x;x=10;if(a>0);b=y;y=10;if(b>0);z=10;c=z;if(c>0) .
Run3:a=x;x=10;if(a>0);y=10;b=y;if(b>0);c=z;z=10;if(c>0) .
*Run4:a=x;x=10;if(a>0);y=10;b=y;if(b>0);z=10;c=z;if(c>0) .
*Run5:x=10;a=x;if(a>0);b=y;y=10;if(b>0);c=z;z=10;if(c>0) .
Run6:x=10;a=x;if(a>0);b=y;y=10;if(b>0);z=10;c=z;if(c>0) .
Run7:x=10;a=x;if(a>0);y=10;b=y;if(b>0);c=z;z=10;if(c>0) .
Run8:x=10;a=x;if(a>0);y=10;b=y;if(b>0);z=10;c=z;if(c>0) .
Figure3: Ourmethod canreducethenumberof executions 
from 2kdownto (k+1) .
iting them again. Such methods would not be effective for the ex- 
ample in Figure 2 either because each of the six executions le ads 
to a distinct state. In contrast, our new method can achieve a sig- 
niﬁcant reduction due to its use of property speciﬁc informa tion 
as guidance. In this sense, our new method is a property directed 
reduction,whereasthePORtechniquesare property agnostic .
However, it can be tricky to combine our pruning method with 
thestate-of-the-artDPORalgorithm. Themainadvantageof DPOR 
overstaticPORliesinitsdynamicupdateofbacktracksets, which 
uses runtime information to compute the dependency relatio n be- 
tween shared accesses. Without taking any additional measu re,
pruning redundant executions may interfere with the dynami c up- 
date of backtrack sets in DPOR. Consider run 4 in Figure 2 as an
example. If the execution is allowed tocomplete, when b=x is ex- 
ecuted, thread T2will be added to the backtrack set of node n3.
However,ifrun4isterminatedpre-maturelyatnode n5duetoour 
predicate summary-based pruning, thread T2would not be added 
to the backtrack set of node n3since b=x has been skipped. As 
a result, the DPOR algorithm would not explore run 6. Therefo re,
integrating DPOR with property speciﬁc pruning is a challen ging 
task. WepresentoursolutiontothisprobleminSection5.2.
Ourcomputation ofpredicate summaries atthe threadinterl eav- 
ing merge point n5in Figure 2 shows that it is different from the 
prior work by Wachter et al. [51], and Chu and Jaffar [9]. Spec iﬁ- 
cally, we combine the summaries from all outgoing edges by co n- 
joining them, whereas existing methods do not merge interpo lants 
at these i-PP nodes. Furthermore, these existing methods im ple- 
mented symbolic POR whereas our method is integrated with th e
morescalableDPOR.
Now, we use the example in Figure 3 to demonstrate that our 
new method has the potential to achieve an exponential reduc tion.
Inthiscontrivedexample,theinterleavingofinstruction s in {a=x, 
x=10} is completely independent from {b=y, y=10} and {c=z, 
z=10} . Exploring all feasible executions results in 23runs, each 
of whichleads toadifferent ﬁnal state. However, based onth e ab- 
stract searchspace induced by the assertions, our new metho d can 
reduce the exploration of eight runs down to one full run toge ther 
with three partial runs, as marked by the ‘*’ symbol in Figure 3.
To further generalize the example, a program with kindependent
code segments would have 2kdistinct interleavings, which can be 
reducedbyourmethodto (k+1) executions.
8563. PRELIMINARIES 
We establish the notation and review the baseline symbolic e xe- 
cutionalgorithmformultithreadedprogramsinthissectio n.
3.1 MultithreadedPrograms 
For ease of presentation, we consider a simple imperative la n- 
guage with integer variables, assignments, and if-else sta tements 
only. We elide the details for handling of complex language f ea- 
tures such as pointers, recursion, and system calls in symbo lic ex- 
ecution since these are orthogonal issues addressed previo usly by 
many symbolic execution tools [8, 11]. A multithreaded prog ram 
Pconsists of a set of threads {T1...T m}, where each thread, Ti,
is a sequential program. Threads share a set of global variables.
Eachthreadalsohasasetof local variables.
Letst be an instruction in a thread with the thread index tid .
Letevent e=/an}bracketle{ttid,l,st,l ′/an}bracketri}htbe an execution instance of st , where 
land l′are locations in the thread before and after executing the 
instance of st . If the same instruction is executed more thanonce,
e.g.,whenitisinalooporarecursivefunctioncall,wemake copies 
of l,st,l ′to make them unique for each event. Conceptually, this 
correspondstounrollingloopsandrecursivecalls. A globalcontrol 
state of the multithreaded program is a tuple s=/an}bracketle{tl1,...,l m/an}bracketri}ht,
where each liis a location in Ti. We regard a global control state 
as an abstract state implicitly containing all concrete states that
have the same thread locations but potentially different va lues of 
thelocalandglobalvariables.
Withoutlossofgenerality,weassumethateveryassertiono fthe 
form assert(c) is transformed to if(!c)abort . We use a spe- 
cial eventabortto denote faulty program termination and haltto 
denote normalprogramtermination. Let vldenote alocalvariable,
vgdenote a global variable, cond ldenote a local condition, and 
exp ldenoteanlocalexpression. Inadditionto abortand halt,each 
instruction st inaneventmayhaveoneofthefollowingtypes:
•α-operation,whichisalocalassignment vl:= exp l;
•β-operation,whichisalocalbranch assume (cond l);
•γ-operation,whichisaglobaloperationdeﬁnedasfollows:
–γ-Iisaglobalwrite vg:= exp lorread vl:= vg;
–γ-IIisathreadsynchronizationoperations.
For each if(c)-else statement, we use assume (c)to denote 
the execution of then-branch, and assume( ¬c)to denote the exe- 
cution of else-branch. Without loss of generality, we assum e that
all if-else conditions use only local variables or local cop ies of 
global variables [17]. For thread synchronizations, we foc us on 
mutexlocks andconditionvariablessincetheyarefrequent lyused 
in mainstream multithreaded programming environments suc h as 
C,C++,andJava. Speciﬁcally,we consider thefollowingtyp es of 
γ-II operations: thread creation, thread join, lock, unlock , signal,
and wait. If other thread synchronizations or blocking oper ations 
areusedtheycanbemodeledsimilarlyas γ-IIevents.
Duringtheprogramexecution, γ-operationsarethreadinterleav- 
ing points whereas β-operations are thread-local branching points.
Both contribute to the path/interleaving explosion. In con trast,α-
operations arelocalandthusinvisibletootherthreads;th eydonot
contributedirectlytothepath/interleavingexplosion.
Aconcrete execution of the multithreaded program is charac- 
terized by π= ( in ,sch ), where in is the data input and sch 
is the thread schedule corresponding to the total order of ev ents 
e1...e n. The corresponding symbolic execution is denoted by 
(∗,sch ), where the ∗indicates the data input is kept symbolic and 
thus maytake anyvalue. Eachexecution ofthe program Pcanbe 
representedbyaﬁniteword {α,β,γ }∗{halt,abort}. Iftheexecu- 
tion ends with haltit is a normal execution. If the execution ends 
with abortitisa faulty execution.a1: a=x++; 
a2: if(a==0) A1;
else A1;
a3: a=y++; 
a4: if(a==0) A2;
else A2;
a5:
--- [T1] --- b1: b=x++; 
b2: if(b==0) B1;
else B1;
b3: b=y++; 
b4: if(b==0) B2;
else B2;
b5:
--- [T2] --- 
{a3,b 4}
{a3,b 5}{a1,b 1}
{a3,b 1}
{a5,b 1}{a1,b 3}
{a3,b 3}{a1,b 5}
{a5,b 3}
{a5,b 5}A1 A2B1A1
B1
B1B1
B2B1
B1B1
A1
A1A1
A2
A2
A2A2A1{a2,b 1}
{a4,b 1}
B1
B2
run-ii run-i run-iiiA2{a5,b 2}
{a5,b 4}B1
B1{a1,b 2}
{a1,b 4}
{a2,b 5}
{a4,b 5}{a3,b 2}
{a4,b 3}
Figure4: Atwo-threadedprogramanditsgeneralizedinter-
leavinggraph(GIG).Blackedgesrepresenteventsfromthre ad 
T1andblueedgesrepresenteventsfromthread T2.
3.2 GeneralizedInterleavingGraph(GIG)
The set of all possible executions of a multithreaded progra m
canbe captured bya generalized interleaving graph (GIG) ,where 
nodesareglobalcontrolstatesandedgesareevents. Theroo tnode 
correspondstotheinitialstate. Leafnodescorrespondton ormalor 
faultyendsoftheexecution. Eachinternalnodemayhave:
•oneoutgoingedgecorrespondingtoan α-operation;
•twooutgoingedgescorrespondingtoa β-operation;or 
•koutgoing edges where k≥2is the number of enabled 
γ-operationsfromdifferentthreads.
Wecallanodewithmorethanoneoutgoingedgea pivot point .
•If the pivot point corresponds to β-operations we call it a 
branching pivot point ( b-PP ).
•If the pivot point corresponds to γ-operations we call it a 
thread interleaving pivot point ( i-PP ).
Figure4showsaprogramanditsGIG.Forsimplicity,weassum e
a=x++ isatomic. Therootnode (a1,b 1)correspondstothestarting 
points of the two threads. The terminal node (a5,b 5)corresponds 
totheendofthetwothreads. Nodessuchas (a1,b 1)arei-PPnodes,
where we can execute either thread 1 which leads to (a2,b 1), or 
thread2whichleadsto (a1,b 2). Incontrast,nodessuchas (a2,b 1)
are b-PP nodes, where we can take either the assume( a= 0 )
branch, leading to the code segment A1, or the assume( a/negationslash= 0 )
branch,leadingtothecodesegment A1.
NotethattheGIGdoes nothaveloop-back edges since theGIG 
paths represent unrolled executions. Furthermore, pointe rs, alias- 
ing,andfunctioncallshavebeenresolvedaswellduringexe cution.
However, a GIG may have branches, which makes it signiﬁcantl y
857differentfromthetypicalthreadinterleavinggraphusedi nthepar- 
tialorderreductionliterature.
Asistypicalinsymbolicexecutionalgorithms,wefocusono nly 
a ﬁnite set of executions and assume that each execution has a ﬁ- 
nite length. Typically, the user of a symbolic execution too l needs 
to construct a proper testing environment that satisﬁes the above 
assumption. In KLEE [8] and Cloud9 [11], for example, the user 
mayachievethisbyboundingthesizeofthesymbolicinputth ereby 
restrictingtheexecutiontoaﬁxednumberofpathsofﬁnitel engths.
3.3 SymbolicExecution 
We present the baseline symbolic execution procedure for mu l- 
tithreaded programs inAlgorithm 1 followingSenet al. [41] . The 
recursive procedure E XPLORE isinvoked withthesymbolic initial
state s0. Insidetheprocedure,wedifferentiateamongthreescenar -
ios based on whether s, the current state, is an i-PP node, a b-PP 
node,oranon-branchingnode.
If sisan i-PP nodewheremultiple γ-operationsareenabled,we 
recursively explore the next γevent from each thread. If sis a 
b-PP node where multiple sequential branches are feasible, we re -
cursively explore each branch. If sis a non-branching node, we 
explore the unique next event. The current execution ends if s
is a leaf node (normal_end_state, faulty_end_state) or an i nfeasi- 
ble_state, at whichpoint we returnfrom E XPLORE (s)by popping 
thestate sfromthestack S.
Algorithm1 BaselineSymbolicExecution.
Initially: Stack S={s0};runE XPLORE (s0)withthesymbolicinitialstate s0.
1:EXPLORE (s)
2:S.push( s);
3:if(sisani-PPnode) 
4:while (∃t∈(s.enabled \s.done ))
5: s′←NEXT STATE (s, t );
6: EXPLORE (s′);
7: s.done ←s.done ∪{ t};
8:elseif(sisab-PPnode){ 
9:while (∃t∈(s.branch \s.done ))
10: s′←NEXT STATE (s, t );
11: EXPLORE (s′);
12: s.done ←s.done ∪{ t};
13:elseif(sisaninternalnode) 
14: t←s.next ;
15: s′←NEXT STATE (s, t );
16: EXPLORE (s′);
17: S.pop();
18:NEXT STATE (s, t )
19:lets=/a\}bracketle{tpcon ,M,enabled,branch,done /a\}bracketri}ht;
20:if(tis halt)
21: s′←normal_end_state;
22:elseif(tis abort)
23: s′←faulty_end_state;
24:elseif(tis assume (c))
25:if(s.pcon isunsatisﬁableunder M)
26: s′←infeasible_state;
27:else 
28: s′←/a\}bracketle{tpcon ∧c, M/a\}bracketri}ht;
29:elseif(tisassignment v:= exp )
30: s′←/a\}bracketle{tpcon ,M[exp/v ]/a\}bracketri}ht;
31:return s′;
Eachstate s∈Sisatuple /an}bracketle{tpcon ,M,enabled ,branch ,done /an}bracketri}ht,
where pcon isthe pathconditionfortheexecutiontoreach sfrom 
s0,Mis the symbolic memory map, s. enabled is the set of γ-
eventswhen sisani-PPnode, s. branch isthesetof β-eventswhen 
sis a b-PP node, and s. done is the set of αor βevents already 
explored from sby the recursive procedure. Initially, s0is set to 
/an}bracketle{ttrue ,Minit /an}bracketri}ht,where true meansthestateisalwaysreachableand 
Minit represents theinitialcontentofthememory. Theexecution
ofeachinstruction tiscarriedoutbyN EXT STATE (s,t )asfollows:
•If tis halt,theexecutionendsnormally.•If tis abort,and s. pcon issatisﬁableunderthecurrentmem- 
orymap s. M,wehavefoundanerror.
•If tis v:=exp , we need to update the current memory map 
Mbychangingthecontentof vto exp .
•If tis assume(c) ,wechangethepathconditionto( pcon ∧c).
Ateachpivotpoint(i-PPorb-PP),wetrytoﬂipadecisionmad e
previously to compute a new execution. Let (in ,sch )denote the 
current execution. By ﬂipping the decision made previously at an 
i-PPnode,wecomputeanewexecution (in ,sch ′),where sch ′isa 
permutationoftheoriginalthreadschedule. Incontrast,b yﬂipping 
the decision made previously at a b-PP node, we compute a new 
execution (in ′,sch ), where in ′is a new data input. Note that in 
both cases, the newly computed execution will be the same as t he 
original execution up to the ﬂipped pivot point. After the ﬂi pping,
therestoftheexecutionwillbeafreerun.
Asanexample, consider theGIGinFigure 4,where thecurrent
execution is represented by the dotted line run-i . Flipping at the 
b-PPnode (a4,b 3)wouldleadtothe newexecutionlabeled run-ii ,
whereas ﬂipping at the i-PP node (a3,b 3)would lead to the new 
execution run-iii .
4. SUMMARIZINGTHEEXPLOREDEXE-
CUTIONS 
We ﬁrst present our method for symbolically summarizing the
reason why explored executions cannot reach the bad state. I nthe 
nextsection,wewillleveragetheinformationtopruneaway redun- 
dantexecutions.
Our method for summarizing the explored executions is based
on the weakest precondition computation [13]. We different iate 
the following two scenarios, depending on whether the execu tion 
encounterstheassertstatementornot.
•For each execution that encounters assert (c)and satisﬁes 
thecondition c,wecomputetheweakestpreconditionofthe 
predicate calongthisexecution.
•For each execution that does not encounter the assert state-
mentatall,wecomputetheweakestpreconditionofthepred-
icate true alongthisexecution.
SincetheweakestpreconditionisaformofCraig’sinterpol ant[34],
itprovidesasuccinctexplanationastowhytheexploredexe cution 
cannotreachthebadstateguardedby ¬c.
DEFINITION 1.The weakest precondition of the predicate φ
withrespect toasequence ofinstructions is deﬁned as follo ws: 
•For t:v:= exp ,WP (t,φ ) = φ[exp /v ];
•For t: assume( c),WP (t,φ ) = φ∧c; and 
•For sequence t1;t2,WP (t1;t2,φ ) = WP (t1,WP (t2,φ )) .
Intheabovedeﬁnition, φ[exp /v ]denotesthesubstitutionofvari- 
able vin φwith exp . Asanexample,considertheexecutionpathin 
the following table, which consists of three branch conditi ons and 
threeassignments. Column1showsthecontrollocationsalo ngthe 
current path. Column 2 shows the sequence of instructions ex e- 
cuted. Column3showstheweakest preconditions computedba ck- 
wardlystartingat l6. Column4shows the rulesappliedduringthe 
computation.
Loc. Instruction WP Computed RuleApplied 
l0if (a≤0) ( a≤0) ∧(b≤0) ∧(c≤0) wp ∧c
l1res := res + 1 ( b≤0) ∧(c≤0) wp [exp/v ]
l2if (b≤0) ( b≤0) ∧(c≤0) wp ∧c
l3res := res + 2 ( c≤0) wp [exp/v ]
l4if (c≤0) ( c≤0) wp ∧c
l5res := res + 3 true wp [exp/v ]
l6 true terminal 
8584.1 PredicateSummariesatb-PPNodes 
Assumethatthebaselinesymbolicexecutionproceduretrav erses 
the GIG in a depth-ﬁrst search (DFS) order, meaning that it ba ck- 
tracks s, a branching pivot point (b-PP), only after exploring both 
outgoing edges sassume (c)−→s′and sassume (¬c)−→s′′ . This also in- 
cludestheentireexecutiontreesstartingfromthesetwoed ges. Let
wp [s′]and wp [s′′ ]be the weakest preconditions computed from 
thetwooutgoingexecutions,respectively.
Followingtheclassicdeﬁnitionofweakestprecondition[1 3],we 
computethemattheb-PPnode sasfollows:
wp [s] := ( c∧wp [s′]) ∨(¬c∧wp [s′′ ]) .
Then,weuse wp [s]computedfromtheseoutgoingedgestoupdate 
theglobalpredicatesummary.
The predicate summary, PS [s], deﬁned for each global control
state s,istheunionofallweakestpreconditionsalongtheoutgoin g
edges. Recall that each node smay be visited by E XPLORE mul- 
tiple times,presumably from different execution paths (fr om s0to 
s). Therefore,wemaintainaglobalmap PS andupdate eachpred- 
icate summary entry PS [s]incrementally. Initially PS [s] = false 
foreveryGIGnode s. Then, wemergethenewlycomputed wp [s]
to PS [s]everytimeE XPLORE backtracksfrom s.
Thedetailedmethodforupdatingthepredicatesummaryishi gh- 
lighted in blue in Algorithm 2, which follows the overall ﬂow of 
Algorithm1,exceptforthefollowingtwoadditions:
•Wecompute wp [s]beforetheprocedurebacktracksfromstate 
s. Atthismoment, wp [s]captures thesetof allexploredex- 
ecutionsfrom sasacontinuationofthecurrentexecution.
•Weupdate thesummaryasfollows: PS [s] = PS [s]∨wp [s].
Here,PS [s]capturesthesetofexecutiontreesasacontinua- 
tionofallexploredexecutionsfrom s0to s,including wp [s],
whichrepresentsthenewlyexploredexecutiontree.
4.2 PredicateSummariesati-PPNodes 
Incontrasttothestraightforwardcomputationofweakestp recon- 
ditionatthesequentialmergepoint,thesituationatthein terleaving 
merge point is trickier. Infact, tothe best of our knowledge , there 
does not exista deﬁnitionof weakest preconditioninthelit erature 
forthreadinterleavingpoints.
A naive extension of Dijkstra’s original deﬁnition would be in- 
efﬁcient since it leads to the explicit enumeration of all po ssible 
interleavings. For example, assume that an i-PPnode has two out- 
goingedges sγ1−→s′and sγ2−→s′′ ,onemayattempttodeﬁnethe 
weakestpreconditionatnode sasfollows:
/parenleftbig
(γ1<hb γ2)∧wp [s′]/parenrightbig
∨/parenleftbig
(γ2<hb γ1)∧wp [s′′ ]/parenrightbig
,
where (γ1<hb γ2)means that we choose to execute γ1before 
γ2,(γ2<hb γ1)means that we choose to execute γ2before γ1,
and wp [s′]and wp [s′′ ]aretheweakestpreconditionsalongthetwo 
interleavings,respectively.
Although the above deﬁnition serves the purpose of summariz -
ing the weakest preconditions along all explored execution s from 
s, it has a drawback: the size of wp [s]computed in this way can 
quickly explode when there are a large number of threads. Rec all
thatinamultithreadedprogramthenumberofoutgoingedges atan 
i-PPnodeequalsthenumberofenabledthreadsandthenumber of 
interleavingsof kconcurrentthreadscanbe k!intheworstcase.
However, for the purpose of pruning redundant executions, t he 
weakest precondition computation does not have to be precis e to 
beeffective. Tomitigatetheaforementionedinterleaving explosion problem,weresorttothefollowingdeﬁnition,whichcanbev iewed 
asanunder-approximationofthenaivedeﬁnition:
wp [s] := /logicalanddisplay
1≤i≤kwp [sk],
whereeach wp [si]istheweakestpreconditioncomputedalongone 
of the koutgoing edges of the form sγi−→si, such that 1≤i≤
k. Consider Figure 2 as an example. We compute the weakest
preconditionatnode n5byconjoiningweakestpreconditionsatthe 
two successor nodes n7and n8. That is, wp [n5] = wp [n7]∧
wp [n8] = ( a≤20) ∧(a≤x).
Algorithm2 AssertionGuidedSymbolicExecution.
Initially: summary PS [n] = false for all node n; stack S={s0}; run E X-
PLORE (s0)withinitialstate s0.
1:EXPLORE (s)
2:S.push( s);
3:if(sisani-PPnode) 
4: wp [s]:= true ;
5:while (∃t∈(s.enabled \s.done ))
6: s′←NEXT STATE (s, t );
7: EXPLORE (s′);
8: wp [s]←wp [s]∧COMPUTE WP ( s,t,s ′);
9: s.done ←s.done ∪{ t};
10:elseif(sisab-PPnode) 
11: wp [s]:= false ;
12:while (∃t∈(s.branch \s.done ))
13: s′←NEXT STATE (s, t );
14: EXPLORE (s′);
15: wp [s]←wp [s]∨COMPUTE WP ( s,t,s ′);
16: s.done ←s.done ∪{ t};
17:elseif(sisaninternalnode) 
18: t←s.next ;
19: s′←NEXT STATE (s, t );
20: EXPLORE (s′);
21: wp [s]←COMPUTE WP ( s,t,s ′);
22:else //endstate 
23: wp [s]←true ;
24: PS [s]:= PS [s]∨wp [s];
25: S.pop();
26:COMPUTE WP( s, t,s ′)
27:if(tis assume (c))
28:return (wp [s′]∧c);
29:elseif(tisassignment v:= exp )
30:return substitute( wp [s′],v,exp );
31:else 
32:return wp [s′];
33:NEXT STATE (s, t )
34:letsbetuple /a\}bracketle{tpcon ,M,enabled,branch,done /a\}bracketri}ht;
35:if(tis halt)
36: s′←normal_end_state;
37:elseif(tis abort)
38: s′←faulty_end_state;
39:elseif(tis assume (c))
40:if(s.pcon isunsatisﬁableunder M)
41: s′←infeasible_state;
42:elseif(pcon →PS [s])
43: s′←early_termination_state;
44:else 
45: s′←/a\}bracketle{tpcon ∧c, M/a\}bracketri}ht;
46:elseif(tisassignment v:= exp )
47: s′←/a\}bracketle{tpcon ,M[exp /v]/a\}bracketri}ht;
48:return s′;
Forpruningredundant executions,conjoiningweakestprec ondi- 
tions from different interleavings at i-PP nodes is a sound a pprox- 
imation. Although it may not capture all the explored execut ions 
and thus fail to prune certain redundant executions, all the pruned 
executionsareguaranteedtoberedundant.
5. PRUNINGREDUNDANTEXECUTIONS 
We present our method for leveraging the predicate summarie s
topruneawayredundant executionsinthissection.
8595.1 AssertionGuidedPruning 
Todecideifwecanskipexecutionsstartingfromaglobalcon trol
state s, where shas been visited by E XPLORE through some exe- 
cutions from s0to sbut isreachedagainthrough anew execution,
we check whether the current path condition s. pcon is subsumed 
by PS [s]underthecurrentmemorymap s. M. Intuitively,thepath 
condition s. pcon represents the set of states reachable along the 
currentexecutionfrom s0to s,whereas PS [s]representsthesetof 
statesfromwhichitisimpossibletoreachthebadstate.
Withinthe N EXT STATE procedureinAlgorithm2,wecheckfor 
thepruningconditionasfollow:
•If s. pcon →PS [s]holds under s. M, extending the current
executionbeyond swouldnotleadtoabadstate. Therefore,
we backtrack immediately by setting s′as an early termina- 
tionstate .
•Otherwise,there may existanextensionofthecurrentexecu- 
tionbeyond storeachthebadstate. Inthiscase,weneedto 
continuetheforwardsymbolicexecutionasusual.
The validity of s.pcon →PS [s]can be decided by checking the 
satisﬁability of (s.pcon ∧ ¬ PS [s]) using an SMT solver. That is,
s.pcon →PS [s]holdsifandonlyif (s.pcon ∧¬ PS [s]) isunsatis- 
ﬁable.
Our new pruning method is complementary to partial order re-
duction techniques. POR is a generic reduction that relies s olely 
on commutativity between concurrent operations. Therefor e, two 
executions are considered equivalent as long as they result in the 
same program state. Our new method, in contrast, uses assert ions 
to guide the pruning. Therefore, even executions that resul t indif- 
ferentprogramstatesmaystillberegardedasequivalent.
Consider the GIGinFigure4, whichhas54feasible execution s.
To make the presentation simple, we have assumed that x++ is 
atomicinthisexample. However,notethat a1:a= x++ and b1:b= 
x++ donotcommute,becausefromastatewhere x=0,forinstance,
executing a1;b1 leadsto a=0,b=1,x=2,butexecuting b1;a1 leads 
to a=1,b=0,x=2. AsshowninTable1,withoutapplyinganyreduc- 
tion technique, the program has a total of 54 distinct runs. P artial
order reduction (POR) alone can reduce the 54 runs down to 34 
runs. Ournewpredicatesummary-basedpruningmethodalone can 
reduce the54runsdowntothe18runs. Finally,applyingboth our 
methodandPORcanreducethe54runsdownto13runs.
Table1:ApplyingvariousreductiontechniquestoFigure4.
ReductionTechnique NumberofPaths 
None 54 
Partialorderreduction(POR) 34 
Ourpredicatesummary-basedpruningmethod 18 
BothPORandournewpruningmethod 13 
5.2 InteractionwithDPOR 
However,thereisacaveatincombiningourpredicatesummar y- 
based pruning method with dynamic partial order reduction [ 16],
because DPOR is a delicate algorithm that relies on the dynam ic 
computation of the backtrack sets . Without taking precautions,
naivelypruningawayredundantexecutions,eveniftheydon otlead 
tothebadstate,maydepriveDPORtheopportunitytoproperl yup- 
dateitsbacktracksets,therebyleadingtounsoundreducti on.
AswehaveshowninSection2,whenthecurrentexecutionisru n
4 in Figure 2, by the time node n5is reached DPOR has not had 
theopportunitytoupdateitsbacktracksetat n3. Ideally,thread T2
should be put into the backtrack set of n3, that is, after E XPLORE 
backtracksto n3,itshouldproceedtoexplorerun6.However, since n5.pcon →PS [n5]along run 4, our pruning 
methodwouldforce E XPLORE tobacktrackfrom n5,therebyskip- 
pingtheremainderofrun4andrun5. Here,thetechnicalchal lenge 
is how to properly update the backtrack set at node n3before E X-
PLORE backtracks from n5.
Fortunately,similarproblemswereencounteredduringthe devel- 
opment ofstatefulDPORalgorithms[59]. Inthiswork,wefol low 
the solution by Yang et al. [59]. We maintain two global table s,
RVar [s]and WVar [s], for each global control state s. The RVar 
tablestoresthesetofglobalvariablesthathavebeenreadb ysome 
threadduringpreviouslyexploredexecutions startingfro ms. Sim- 
ilarly, the WVar table stores the set of global variables that have 
been written to by some thread during previously explored ex ecu- 
tionsstartingfrom s. Thesetwotablesareupdatedatthesametime 
theglobal PS tableisupdated.
FortheexampleinFigure2,afterexploringrun1,run2,andr un 
3, we would have WVar [n5] = {(x,T 1)}representing that x=20 
has previously been executed by thread T1at some point after n5.
Similarly, we have RVar [n5] = {(x,T 2)}representing that b=x 
haspreviouslybeenexecutedbythread T2atsomepointafter n5.
Whenever E XPLORE decides to skip the execution tree from a 
node s, we can leverage the information stored in WVar [s]and 
RVar [s]to properly update the backtrack sets for DPOR. For ex- 
ample,theoriginal DPORalgorithmwaitsuntilassignment b=x is 
executedbythread T2before itcanupdate the backtracksetof n3.
Now, using the entry (x,T 2)∈RVar [n5], it can put thread T2
intothebacktracksetof n3,asif b=x has beenexecutedbythread 
T2atsomepointafter n5.
The correctness of this solution follows Yang et al. [59] in t he 
contextofstatefulDPOR,whichensurethatDPORremainssou nd 
inthepresence ofassertionguided pruning. Formore inform ation 
onthedynamicupdateofbacktracksets,pleaserefertotheo riginal
descriptionofDPOR[16].
5.3 ProofofCorrectness 
Now,westateandprovethecorrectnessofouroverallalgori thm.
LetSE orig bethebaselinesymbolicexecutionproceduredescribed 
in Algorithm 1, and SE new be our new symbolic execution proce- 
dure withpredicate summary-based pruning, asdescribed in Algo- 
rithm 2. We say that SE new is a sound reduction of SE orig if it
alwaysreachesthesamesetoferrorstatesas SE orig .
THEOREM 1.Givenaprogram Pandanerrorlocation E. Our 
new symbolic execution procedure SE new reaches Eif and only if 
the original symbolic executionprocedure SE orig reaches E.
Proof: We divide the proof into two steps. First, we prove tha t
if SE new reaches E, then SE orig also reaches E. This is straight- 
forward because SE new explores a subset of the execution paths 
exploredby SE orig ,asshownbyacomparisonofthetwoversions 
of N EXT STATE inAlgorithms1and2.
Second, weprove that if SE orig reaches E,then SE new reaches 
E. Wedothisbycontradiction. Assume SE orig canreach Ealong 
πbutSE new cannot. Since Lines 42–43 in Algorithm 2 are the 
onlyplaceswhere SE new canskipapath,theremustexistanevent
/an}bracketle{ts,t,s ′/an}bracketri}htin πsuchthat s. pcon →PS [s]holdsunder s. M.
•Sincepath πisfeasible, thesubpath of πfrom s′to Emust
alsobe feasible. Toskip πin SE new ,thesubpath musthave 
been explored and then summarized in PS [s′], presumably 
when SE new ﬁrstexploredthesubpath.
•Butif PS [s′]alreadyincludes this common subpath from s′
to E,bydeﬁnition, SE new musthavereachedtheerrorblock 
E. This contradicts our assumption that the new symbolic 
executionprocedure SE new cannotreachtheerrorblock E.
Therefore,ourassumptionisincorrect. Thetheoremholds.
8606. OPTIMIZATIONS 
In our new method, the size of the summary table as well as 
the size of the logical constraint ineachentrymaybecome an per- 
formance bottleneck. Since large logic formulas are expens ive to 
compute and store, we would like toreduce the associated com pu- 
tational cost without affecting soundness of the overall pr ocedure.
Towardthisend,weproposetwooptimizations.
6.1 LeveragingStaticProgramSlicing 
Ourﬁrstoptimizationistocombineourassertionguidedpru ning 
withstaticprogram slicing toachieveamoresigniﬁcantstatespace 
reduction. Givenanassertionstatement st ,wedeﬁnethe slice of st 
asthesetofallstatementsintheprogramthatmayaffectthe result
of st . The slice is computed based on two dependency relations:
the control dependency relation and the data dependency rel ation.
Intuitively, a statement st ′is a control dependency of a statement
st if the execution of st ′determines whether st can be executed.
Whereasastatement st ′′ isadatadependencyof st iftheexecution 
of st ′′ mayaffectthedatausedin st .
1if (p) 
2y = v; 
3z = w *5; 
4if (q) 
5x = z *2; 
6assert(x); 
Figure5:Exampleforstatic 
programslicing.Slice 
AB
assert(c) s0
Figure6:UsingTypeAand 
Bnodesoutsidetheslice.
Consider the example in Figure 5. The write to xat Line 5 has 
acontrol dependency at Line 4, and a data dependency at Line 3.
The slice ofLine5isdeﬁnedasthetransitiveclosureofitscontrol
and data dependencies, which consists of Lines 3–5. In contr ast,
the branching statement at Line 1 and the write to yat Line 2 are 
irrelevant since their execution will not affect the value written to 
xat Line5nor thereachabilityof Line5. Therefore, forcheck ing 
the assertionatLine6,whichisrelatedtothe value of xatLine5,
wecansimplyignoreLines1–2. Inotherwords,thesliceofLi ne5 
(and Line 6) deﬁnes a sub-program producing anequivalent re sult
asthefullprogramasfarasassertioncheckingisconcerned .
Weimplementedtheinter-proceduralslicingmethodofHorw itz 
et al. [22, 39] together withan Andersen [3] style ﬂow-insen sitive 
alias analysis to compute the program slice statically. We i mple- 
mented the method in LLVM using the Datalog engine inside the
Z3 SMT solver [12]. The overall method is ﬂow-insensitive, a nd 
safe for handling multithreaded program with sequentially consis- 
tentmemory. Duetothelackofspace,wedonotgooverthedeta ils 
here. Readerscanreferto[27,22,15,3]formoredetails.
We combine static program slicing with symbolic execution a s
follows. First,wecomputethestaticprogramslicepriorto thestart
of symbolic execution. Then, inside the symbolic execution pro- 
cedure as described in Algorithm 2, for each to-be-executed b-PP 
or i-PPnode s, we check ifthe corresponding branch condition or 
global operation belongs to the static slice of the assertio n state- 
ment. Ifthe answerisno, wehandle apivot point s(whichcanbe 
an i-PP or a b-PP) in one of the following ways depending on the
nodetypeasillustratedinFigure6.
•TypeA:If sisnotonanypathfrom s0totheassertionstate- 
ment, we treat each outgoing edge from sas if it is halt. In 
other words, we stop the current execution and backtrack from simmediately. Note that backtracking will automati- 
callytriggerthecomputationofweakestprecondition.
•TypeB:If sis on some GIG path from s0to the assertion 
statement,wecannotsimplytreat sastheendoftheprogram 
since outgoing paths from smay still lead to the assertion 
failure. As shown inFigure 6, we have tosymbolically exe- 
cuteatleastoneoftheoutgoingedgesfromtheTypeBnode,
whileskippingtheotheroutgoingedges.
The correctness of this approach directly follows from the d ef- 
inition of slicing. For both Type A and Type B nodes outside 
the program slice, which outgoing edge to execute does not affect
the reachability of the bad state. Due to the relative efﬁcie ncy of 
static slicing, the overhead of computing the slice is small com- 
pared to the subsequent symbolic execution. However, we wil l
showthroughexperimentsthat,byleveragingstaticslicin g,wecan 
signiﬁcantly decrease of the number of executions to be expl ored,
thusdecreasingthecomplexityoftheoverallanalysis.
6.2 ApproximatingtheSummaryConstraints 
Following Theorem 1, we can prove that in general, any kind 
ofunderapproximation of PS [s]maybeusedinAlgorithm 2tore- 
place PS [s],whilemaintainingthesoundnessofourpruningmethod.
Our optimization is to heuristically reduce the computatio nal cost
associatedwithpredicatesummaries. Towardthisend,wepr opose 
thefollowingtwounderapproximations.
First,weuseaglobalhashtablewithaﬁxednumber Nofentries 
tolimitthestoragecostfor PS ;thatis,twoglobalcontrollocations 
sand s′maybehashed tothesame entry. Whenever thishappens,
instead of storing both ina linked list, we drop one of them. T hat
is, when key (s) = key (s′), we heuristically remove one entry,
effectivelysettingthecorresponding predicatesummary false .
Second, we use a ﬁxed threshold to bound the size of each in- 
dividual logical constraint for PS [s]. In other words, when the 
predicate summary becomes too large, we will stop adding new
weakest-preconditions to it, thereby dropping all subsequ ently ex- 
ploredsubpaths. Thatis,
if(size (PS [s])<bnd) PS [s]:= PS [s]∨wp [s].
Thisisagainanunderapproximation of PS [s].
A main advantage of this on-demand constraint minimization
framework is that it allows various forms of underapproxima tions 
to be plugged into it without affecting the soundness proof o f the 
overallalgorithm. Withunderapproximations,itispossib lethatwe 
maynolongerbeabletopruneawayallredundantexecutions, how- 
ever, we can guarantee that all pruned executions are truly r edun- 
dant. Inparticular,thebaselinesymbolic executioninAlg orithm1 
(no pruning) can be viewed as an extreme form of underapproxi -
mation, where PS [s]is underapproximated to false for all global
controllocations.
7. EXPERIMENTS 
Wehaveimplementedourmethodin Cloud9 [11],whichinturn 
builds upon the LLVM compiler [2] and the KLEE symbolic vir- 
tual machine [8]. Note that KLEE does not by itself support mu l- 
tithreading, and although Cloud9 has extended KLEE to support
a limited number of POSIX thread routines, it does not attemp t
to cover all feasible thread interleavings. Indeed, Cloud9 allows 
for context switches only before certain POSIX thread synch ro- 
nizations butnotbefore sharedvariablereads/writes. Fur thermore,
Cloud9 doesnot support partialorderreduction. Instead, itforks a
newexecutioneverytimeaPOSIXsynchronizationisencount ered,
whichcancausethenumberofexecutionstoexplode quickly.
We have extended Cloud9 to implement the baseline symbolic 
executioninAlgorithm1,whichsystematicallyexploresbo thintra- 
thread paths and thread interleavings. Then, we implemente d the 
861DPOR algorithm [16]. Based on these extensions, we have impl e- 
mented our new assertion guided pruning (Algorithm 2) with t he 
optimizationspresentedinSection6.
Table2:Summaryofourexperimentalresults.
Cloud9 +DPOR +DPOR+AG 
Name LOC Threads Runs Time(s) Runs Time(s) Runs Time(s) 
ﬁbbenchfalse1 44 2 924 61.4 48 2.0 15 1.8 
ﬁbbenchfalse2 44 2 −>1800 628 36.2 34 3.9 
ﬁbbenchfalse3 44 2 −>1800 8704 503.8 378 13.7 
indexertrue 85 2 −>1800 81 2.8 24 6.0 
lazy01false 51 3 11 0.5 3 0.3 3 1.1 
reorder2false1a 85 2 7 0.3 3 0.3 3 1.2 
reorder2false1b 85 3 91 1.4 26 0.6 9 1.2 
reorder2false1c 85 4 2421 89.1 205 3.2 39 1.6 
reorder2false2a 85 2 23 0.6 14 0.5 14 1.5 
reorder2false2b 85 3 479 8.9 233 5.0 64 2.2 
sigmafalse1 49 2 12 0.4 6 0.3 2 1.2 
sigmafalse2 49 3 180 3.2 50 1.0 2 1.2 
sigmafalse3 49 4 4830 222.4 862 18.6 2 1.2 
singletonfalse 57 4 60 1.1 24 0.6 19 1.1 
stackfalse 120 2 527 8.6 236 3.9 49 2.8 
stateful01true 55 2 6 0.4 6 0.4 5 1.2 
twostage3false 129 3 4862 302.1 88 1.1 34 2.2 
dekkertrue 55 2 −>1800 280 3.6 6 1.5 
petersontrue1 43 2 −>1800 1052 22.7 64 2.7 
petersontrue2 43 2 −>1800 2566 86.6 85 8.1 
readwritelktrue1 52 2 24 0.6 4 0.3 4 1.1 
readwritelktrue2 52 4 −>1800 −>1800 436 14.9 
timevarmutextrue 55 2 41 0.8 4 0.3 2 1.0 
szymanskitrue 55 2 −>1800 −>1800 6 1.8 
unveriftrue 40 2 −>1800 221 2.9 27 1.7 
bluetoothbad 88 2 −>1800 1789 25.1 95 4.0 
art-example 71 2 450 11.5 146 3.1 9 1.5 
fsbenchbad 86 8 −>1800 256 9.2 9 20.9 
tickettrue 76 2 1062 19.6 274 4.8 44 1.9 
accountbad 60 3 8 0.4 8 0.4 8 1.0 
circularbufbad1 109 2 118 1.7 118 1.9 58 3.8 
circularbufbad2 109 2 358 5.5 358 5.5 132 6.4 
readreadwrite 50 3 96 1.4 19 0.5 3 1.1 
queuefalse 167 2 252 3.9 252 3.8 26 3.9 
nbds-slU1a 1942 2 −>1800 133 8.9 5 7.8 
nbds-slU1b 1942 2 −>1800 −>1800 76 16.2 
nbds-slU1c 1942 2 −>1800 −>1800 202 35.2 
nbds-slU2a 1942 2 −>1800 241 25.3 29 12.8 
nbds-slU2b 1942 2 −>1800 −>1800 118 24.5 
nbds-slU2c 1942 2 −>1800 −>1800 717 164.8 
nbds-skiplist 1994 3 −>1800 −>1800 1 25.1 
nbds-hashw1a 2322 2 −>1800 1339 167.4 123 177.8 
nbds-hashw1b 2322 2 −>1800 6501 1568.9 675 222.8 
nbds-hashw1c 2322 2 −>1800 −>1800 2399 476.9 
nbds-hashw2a 2234 2 −>1800 5852 674.1 369 155.3 
nbds-hashw2b 2234 2 −>1800 −>1800 1735 257.4 
nbds-hashw2c 2234 2 −>1800 −>1800 4017 528.4 
nbds-hash 2375 2 −>1800 −>1800 2283 333.8 
nbds-list 1887 3 −>1800 10274 1130.7 1 5.9 
nedmalloc 6303 4 −>1800 −>1800 1 12.0 
Average 986.9 518.5 51.6 
Wehaveconductedexperimentsontwosetsofbenchmarks. The
ﬁrst set consists of multithreaded C programs from the 2014 S oft- 
ware Veriﬁcation Competition (SV-COMP) benchmark [47] and
programs from [14, 29]. The second set consists of two real mu l- 
tithreaded applications: nbds [35], a collection of lock-free data 
structures, and nedmalloc [36], a thread-safe malloc implementa- 
tion. Eachoftheseprogramshasbetween40to6,500linesofc ode,
withacombinedtotalof40,291linesofcode. Eachbenchmark pro- 
gram is ﬁrst transformed into LLVM bitcode using Clang/LLVM ,
beforegiventothesymbolicexecutiontoolwithasetofuser anno- 
tatedvariablesassymbolicinput.
Table 2 summarizes the results of our experimental evaluati on.
Columns 1–3 show the name, lines of code, and the number of 10 010 110 210 310 010 110 210 3
RunsCloud9 Runs+DPOR+AG 
10 010 110 210 310 010 110 210 3
Time(s)Cloud9 Time(s)+DPOR+AG 
Figure7:ScatterplotscomparingourmethodwithCloud9.
threads for each program. Columns 4–9compare the performan ce 
ofthreedifferentmethods intermsofthenumber ofexplored runs 
andthetotalruntimeinseconds. Cloud9 denotesthebaselinesym- 
bolicexecutionalgorithminAlgorithm1,+DPORdenotesthe base- 
linealgorithmwithdynamicpartialorderreduction,and+D POR+ 
AG denotes our new method, which augments the baseline algo-
rithm with DPOR and assertion guided pruning. The runtime of
+DPOR+ AG includes the timeto compute the slice. For alltest s,
weusedamaximumtimeof30minutes.
In the remainder of this section, we analyze the experimenta l
resultsinmoredetails,toanswerthefollowingresearchqu estions:
1. Howeffectiveisourproposedpruningtechnique? Isitmor e
effectivethanDPORalone? 
2. How scalable is our technique? Is it practical in handling
realisticC/C++programs? 
First, we show the comparison of Cloud9 and +DPOR + AG in 
two scatter plots in Figure 7, where the x-axis in each scatter plot
represents the number of runs (or time) of the baseline algor ithm 
(Cloud9), and the y-axis represents the number of runs (or time) 
ofour method(+DPOR+AG).Eachbenchmark program isrepre- 
sented by a dot in the scatter plots; dots below the diagonal l ines 
are winning cases for our method. The results show that our ne w
method can signiﬁcantly reduce the number of runs explored b y
symbolic execution as wellas the overall execution time. In many 
cases, the baseline algorithm timedout after 30 minutes whi le our 
newmethodﬁnishedinafewseconds.
Next,weshowthecomparisonof+DPORand+DPOR+AGin 
the scatter plots in Figure 8. Our goal is to quantify how much
of the performance improvement comes from our new assertion
guided pruning as opposed to DPOR. Again, dots below the di- 
agonal lines are winning cases for our method (+DPOR + AG) 
overDPOR.Formostofthebenchmarkprograms,ournewmethod
demonstrated a signiﬁcant performance improvement over DP OR.
But for some benchmark programs, +DPOR + AG was slightly 
slowerthan+DPORdespitethatitexecutedthesame,orasmal ler,
number of runs. This is due to the additional overhead of run-
ning the supplementary static slicing algorithm, as well as predi- 
cate summary-based pruning, whichdidnot provide sufﬁcien t per- 
formanceboosttooffsettheiroverhead.
However, it is worth noting that, where our combined optimiz a- 
tionofslicingandpruningisabletobringaperformance imp rove- 
ment,itoftenleadstoadrasticreductionintheexecutiont imecom- 
pared to DPOR alone. For example, in nedmalloc (Table 2), our 
newmethodwasabletoidentifythatthepropertydoesnotdep end 
onanysharedvariables. Insuchcases,itcansafelyskipexp loring 
theentireinterleavedstatespaceandﬁnishinjustonerun.
We also evaluated the growth trends of the three methods when
thecomplexityofthebenchmarkprogramincrease. Figure9s hows 
theresultsofcomparingthethreemethodsonaparameterize dpro- 
gram named reorder2false . In these two ﬁgures, the x-axis repre- 
86210 010 110 210 310 010 110 210 3
Runs+DPOR Runs+DPOR+AG 
10 010 110 210 310 010 110 210 3
Time(s)+DPOR Time(s)+DPOR+AG 
Figure8:ScatterplotscomparingourmethodwithDPOR.
2 4 6 10 210 4
NumberofThreads Runs Cloud9 
+DPOR 
+DPOR+AG 
2 4 6 10 010 2
NumberofThreads Time(s) Cloud9 
+DPOR 
+DPOR+AG 
Figure9:Parameterizedresultsfor reorder2false experiment.
sents the number of threads created in the parameterized pro gram,
and the y-axis represents, inlogarithmicscale, the number ofruns 
explored and the execution time in seconds. As shown by these
two ﬁgures, the computational overhead of all three methods in- 
creases as the complexity of the program increases. However , our 
new method increases at a signiﬁcantly reduced rate compare d to 
thetwoexistingmethods.
8. RELATEDWORK 
As we have mentioned earlier, for sequential programs, ther e is 
a large body of work on mitigatingpath explosion in symbolic ex- 
ecutionusingfunctionsummaries[18],may-mustabstracti on[20],
demand-driven reﬁnement [31], state matching [50], state m erg- 
ing[30],andstructuralcoverage[37]. McMillanproposed lazy ab- 
straction withinterpolants[33,34],whichhasbeenshowntobeef- 
fectiveinmodelcheckingsequentialsoftware[6]. Jaffare tal.[10] 
useda similarmethodinthecontext ofconstraint programmi ng to 
computeresource-constrainedshortestpathsandworst-ca seexecu- 
tion time. However, a direct extension of such methods to mul ti- 
threadedprogramswouldbeinefﬁcientsincetheyleadtothe naive 
explorationofallthreadinterleavings.
Wachteretal.[51]extendedMcMillan’slazyabstractionwi thin- 
terpolants [34]tomultithreadedprograms whilecombining itwith 
a symbolic implementation of the monotonic partial order re duc- 
tion algorithm [26, 58]. The idea is to apply interpolant-ba sed 
reduction to each interleaved execution while applying sym bolic 
PORtoreducethenumberofinterleavings. ChuandJaffar[9] pro- 
posedasimilarmethod,wheretheyimprovedthesymbolicPOR by 
considering not only the standardindependence relationbu t alsoa 
new semi-commutativity relation. However, these existing meth- 
ods[51,9]differfromourmethodsigniﬁcantly.
First,wemergepredicatesummariesatinterleavingpivotp oints 
whereas the existing methods [51, 9] do not. Second, we lever -
age static program slicing and heuristic minimization of su mmary 
constraints during symbolic execution tofurther reduce th e search 
space. Finally,ourpruningmethodisdesignedtoworkseaml essly 
with the more scalable DPOR algorithm [16] whereas the exist -
ing methods implemented symbolic POR. Neither of these prev i- ous methods demonstratedhandlingC/C++code withmorethan a
thousandlinesofcodeasinourwork.
Kusano and Wang [29] introduced a notion of predicate depen-
dence in the context of dynamic partial order reduction. Wan g et
al. [57, 52] proposed similar property-driven pruning meth ods for 
dynamic model checking. However, all these prior methods we re 
gearedtowardstatelessmodel checking, whichcanbe viewed asa 
formofsystematictestingwithﬁxeddatainput,asopposedt osym- 
bolic data inputs. Furthermore, these methods relied on con trol
and data dependency relations as opposed to symbolic constr aints 
generated from weakest precondition computation, and ther efore 
were unable to merge non-failing executions reaching diffe rent ﬁ- 
nalstates. Inthissense,ournewmethodisamoregeneraland more 
accurate version of the prior works. Furthermore, it is orth ogonal
and complementary to the symmetry-reduction method propos ed 
byYangetal.[60].
Our sound method for pruning executions differs signiﬁcant ly 
from various heuristic reduction techniques inconcurrenc y testing 
thatdonotguaranteethesoundness. Forexample,Farzaneta l.[14] 
and Razavi et al. [38] proposed heuristic methods for quickl y ex- 
ploringcertainsubsetsofthreadinterleavingscenariosi nsymbolic 
executionof concurrent programs. Thistype ofselectivein terleav- 
ing exploration techniques were also used by Wang et al. [56] to 
quickly cover certain pairs of dependent operations captur ed by a 
historyawarepredecessorset. Furtheralongthisline,the rearepre- 
dictivebugdetectionmethodsbasedontheuseofSMTsolvers [54,
28,55,45,46,24,25,40,44,43,53],whichdifferfromourme thod 
in that they explore only the thread interleavings under ﬁxe d pro- 
graminputs.
TheGREENtoolbyVisseretal.[49]providesawrapperaround
constraint satisﬁability solvers to check if the results ar e already 
available from prior invocations, and reuse the results if a vailable.
Assuch,theycanachievesigniﬁcantreuseamongmultipleca llsto 
the same solvers during the symbolic execution of different paths.
GREEN achieves this by distilling constraints into their es sential
parts and then representing them in a canonical form. The reu se 
achievedbyGREENisatamuchlowerlevel,andthereforeisco m- 
plementarytoournewpruningmethod.
Finally,weassume sequentialconsistency, althoughourme thod 
canbeintegratedwithdynamicpartialorderreductionmeth odsfor 
relaxedmemorymodels[62,1];weleavethisforfuturework.
9. CONCLUSIONS 
We have presented a predicate summary-based pruning method
for improving symbolic execution of multithreaded program . Our 
methodisdesignedtoworkwiththepopularDPORalgorithm,a nd 
has the potential of achieving exponential reduction. We ha ve im- 
plementedthemethodin Cloud9 anddemonstrateditseffectiveness 
throughexperiments onmultithreadedC/C++benchmarks. Fo rfu- 
ture work, we plan to conduct more experiments to identify th e
sweetspots inusingheuristicminimizationsofsummaryconstraints 
to exploit the trade-off between increasing the pruning pow er and 
decreasingthecomputationaloverhead.
10. ACKNOWLEDGMENTS 
This work was primarily supported by the NSF under grants 
CCF-1149454, CCF-1405697, and CCF-1500024. Partial suppo rt
was provided by the ONR under grant N00014-13-1-0527. Any 
opinions, ﬁndings, and conclusions expressed in this mater ial are 
those of the authors anddo not necessarilyreﬂect theviews o f the 
fundingagencies.
86311. REFERENCES 
[1] P.A.Abdulla,S.Aronis,M.F.Atig,B.Jonsson,
C.Leonardsson, andK.F.Sagonas.Statelessmodel
checkingforTSOandPSO.In International Conference on 
Tools and Algorithmsfor Construction and Analysis of 
Systems ,pages353–367, 2015.
[2] V.Adve,C.Lattner,M.Brukman,A.Shukla,andB.Gaeke.
LLVM:Alow-levelvirtualinstructionsetarchitecture.In
ACM/IEEEinternational symposium onMicroarchitecture ,
SanDiego,California,Dec2003.
[3] L.O.Andersen.Programanalysisandspecializationfor the 
cprogramminglanguage. Technicalreport,Universityof 
Copenhagen, 1994.
[4] T.Ball.Atheoryofpredicate-completetestcoverage an d
generation.In Formal Methods for Components and Objects,
ThirdInternational Symposium, Leiden,The Netherlands ,
pages1–22,2004.
[5] T.Bergan,D.Grossman,andL.Ceze.Symbolicexecutiono f
multithreadedprogramsfromarbitraryprogramcontexts.I n
ACMSIGPLANConference onObject Oriented 
Programming, Systems, Languages, and Applications ,pages 
491–506,2014.
[6] D.BeyerandP.Wendler.Algorithmsforsoftwaremodel
checking: Predicateabstractionvs.impact.In International 
Conference onFormal Methods inComputer-Aided Design ,
pages106–113, 2012.
[7] P.Boonstoppel,C.Cadar,andD.R.Engler.RWset:
Attackingpathexplosioninconstraint-basedtestgenerat ion.
In International Conference on Tools and Algorithmsfor 
Construction andAnalysis of Systems ,pages351–366, 2008.
[8] C.Cadar,D.Dunbar,andD.R.Engler.KLEE:Unassisted 
andautomaticgenerationofhigh-coverage testsforcomple x
systemsprograms.In USENIXSymposium onOperating 
Systems Designand Implementation ,pages209–224, 2008.
[9] D.ChuandJ.Jaffar.Aframeworktosynergizepartialord er 
reductionwithstateinterpolation.In International Haifa 
VeriﬁcationConference ,pages171–187, 2014.
[10] D.-H.ChuandJ.Jaffar.Acompletemethodforsymmetry 
reductioninsafetyveriﬁcation.In International Conference 
on Computer AidedVeriﬁcation ,pages616–633, 2012.
[11] L.Ciortea,C.Zamﬁr,S.Bucur,V.Chipounov, and 
G.Candea.Cloud9: asoftwaretestingservice. Operating 
Systems Review ,43(4):5–10, 2009.
[12] L.M.deMouraandN.Bjørner.Z3: AnefﬁcientSMTsolver.
In International Conference on Tools and Algorithmsfor 
Construction andAnalysis of Systems ,pages337–340, 2008.
[13] E.Dijkstra. A Disciplineof Programming .PrenticeHall,NJ,
1976.
[14] A.Farzan,A.Holzer,N.Razavi,andH.Veith.Con2colic
testing.In ACMSIGSOFTSymposium on Foundations of 
Software Engineering ,pages37–47, 2013.
[15] J.Ferrante,K.J.Ottenstein,andJ.D.Warren.Theprog ram 
dependence graphanditsuseinoptimization. ACM Trans. 
Program. Lang. Syst. ,9(3):319–349, July1987.
[16] C.FlanaganandP.Godefroid.Dynamicpartial-order 
reductionformodelcheckingsoftware.In ACM 
SIGACT-SIGPLANSymposium on Principlesof 
Programming Languages ,pages110–121, 2005.
[17] P.Godefroid. Partial-Order Methods for the Veriﬁcationof 
Concurrent Systems - AnApproach tothe State-Explosion 
Problem .Springer,1996.[18] P.Godefroid.Compositionaldynamictestgeneration. In 
ACM SIGACT-SIGPLANSymposium on Principles of 
ProgrammingLanguages , pages47–54,2007.
[19] P.Godefroid,N.Klarlund,andK.Sen.DART:directed 
automatedrandomtesting.In Programming Language 
Design andImplementation ,pages213–223,June2005.
[20] P.Godefroid,A.V.Nori,S.K.Rajamani,andS.Tetali.
Compositionalmay-mustprogramanalysis: unleashingthe 
powerofalternation.In ACMSIGACT-SIGPLANSymposium 
onPrinciples of Programming Languages , pages43–56,
2010.
[21] S.GrafandH.Saïdi.Constructionofabstractstategra phs 
withPVS.In International Conference onComputer Aided 
Veriﬁcation ,pages72–83.Springer,1997.LNCS1254.
[22] S.Horwitz,T.W.Reps,andD.Binkley.Interprocedural
slicingusingdependence graphs.In ACM SIGPLAN 
Conference onProgramming Language Designand 
Implementation ,pages35–46,1988.
[23] J.Jaffar,V.Murali,andJ.A.Navas.Boostingconcolic
testingviainterpolation.In ACMSIGSOFT Symposium on 
Foundations of Software Engineering ,pages48–58,2013.
[24] V.KahlonandC.Wang.UniversalCausalityGraphs: A 
precisehappens-before modelfordetectingbugsin 
concurrentprograms.In International Conference on 
Computer AidedVeriﬁcation ,pages434–449, 2010.
[25] V.KahlonandC.Wang.Lockremovalforconcurrent trace
programs.In International Conference onComputer Aided 
Veriﬁcation ,pages227–242, 2012.
[26] V.Kahlon,C.Wang,andA.Gupta.Monotonicpartialorde r
reduction: Anoptimalsymbolicpartialorderreduction 
technique.In International Conference on Computer Aided 
Veriﬁcation ,pages398–413, 2009.
[27] K.KennedyandJ.R.Allen. OptimizingCompilers for 
Modern Architectures: ADependence-based Approach .
MorganKaufmannPublishersInc.,SanFrancisco,CA,USA,
2002.
[28] S.Kundu,M.K.Ganai,andC.Wang.CONTESSA:
Concurrencytestingaugmentedwithsymbolicanalysis.In 
International Conference onComputer AidedVeriﬁcation ,
pages127–131, 2010.
[29] M.KusanoandC.Wang.Assertionguidedabstraction: a 
cooperativeoptimizationfordynamicpartialorderreduct ion.
In IEEE/ACMInternational Conference OnAutomated 
Software Engineering ,pages175–186, 2014.
[30] V.Kuznetsov,J.Kinder,S.Bucur,andG.Candea.Efﬁcie nt
statemerginginsymbolicexecution.In ACMSIGPLAN 
Conference onProgramming Language Designand 
Implementation ,pages193–204, 2012.
[31] R.MajumdarandK.Sen.Hybridconcolictesting.In 
International Conference onSoftware Engineering ,pages 
416–426, 2007.
[32] A.W.Mazurkiewicz.Tracetheory.In Advances inPetriNets ,
pages279–324. Springer,1986.
[33] K.L.McMillan.Lazyabstractionwithinterpolants.In
International Conference onComputer AidedVeriﬁcation ,
pages123–136. Springer,2006.LNCS4144.
[34] K.L.McMillan.Lazyannotationforprogramtestingand
veriﬁcation.In International Conference onComputer Aided 
Veriﬁcation ,pages104–118, 2010.
[35] Non-blockingdatastructures.URL:
https://code.google.com/p/nbds/.
[36] nedproductions: nedmallocURL:
http://www.nedprod.com/programs/portable/nedmalloc/ .
864[37] R.Pandita,T.Xie,N.Tillmann,andJ.deHalleux.Guide d
testgenerationforcoverage criteria.In IEEEInternational 
Conference onSoftware Maintenance , pages1–10,2010.
[38] N.Razavi,F.Ivancic,V.Kahlon,andA.Gupta.Concurre nt
testgenerationusingconcolicmulti-traceanalysis.In Asian 
Symposium on ProgrammingLanguages andSystems ,pages 
239–255, 2012.
[39] T.Reps,S.Horwitz,andM.Sagiv.Preciseinterprocedu ral
dataﬂowanalysisviagraphreachability.In ACM 
SIGACT-SIGPLANSymposium on Principlesof 
Programming Languages ,pages49–61,NewYork,NY,
USA,1995.ACM.
[40] M.Said,C.Wang,Z.Yang,andK.Sakallah.Generatingda ta 
racewitnessesbyanSMT-basedanalysis.In NASAFormal 
Methods ,pages313–327,2011.
[41] K.Sen. Scalable AutomatedMethods for Dynamic Program 
Analysis .PhDthesis,UIUC,2006.
[42] K.Sen,D.Marinov,andG.Agha.CUTE:aconcolicunit
testingengineforC.In ACMSIGSOFTSymposium on 
Foundations of Software Engineering ,pages263–272, 2005.
[43] A.Sinha,S.Malik,C.Wang,andA.Gupta.Predicting 
serializabilityviolations: SMT-basedsearchvs.
DPOR-basedsearch.In HaifaVeriﬁcationConference ,pages 
95–114, 2011.
[44] A.Sinha,S.Malik,C.Wang,andA.Gupta.Predictive 
analysisfordetectingserializabilityviolationsthroug htrace 
segmentation.In ACM-IEEEInternational Conference on 
Formal Methods andModels for System Design ,pages 
99–108, 2011.
[45] N.SinhaandC.Wang.Stagedconcurrentprogramanalysi s.
In ACMSIGSOFT Symposium onFoundations ofSoftware 
Engineering ,pages47–56, 2010.
[46] N.SinhaandC.Wang.Oninterferenceabstractions.In ACM 
SIGACT-SIGPLANSymposium on Principlesof 
Programming Languages ,pages423–434, 2011.
[47] SV-COMP.2014softwareveriﬁcationcompetition.URL:
http://sv-comp.sosy-lab.org/2014/, 2014.
[48] N.TillmannandJ.deHalleux.PEX–whiteboxtest
generationfor.NET.In International Conference onTests 
and Proofs ,pages134–153, 2008.
[49] W.Visser,J.Geldenhuys,andM.B.Dwyer.Green: reduci ng,
reusingandrecyclingconstraintsinprogramanalysis.In 
ACMSIGSOFTSymposium on Foundations of Software 
Engineering ,page58,2012.
[50] W.Visser,C.S.Pasareanu,andR.Pelánek.Testinput
generationforjavacontainersusingstatematching.In 
International Symposium onSoftware Testingand Analysis ,
pages37–48,2006.[51] B.Wachter,D.Kroening,andJ.Ouaknine.Verifying 
multi-threadedsoftwarewithImpact.In International 
Conference onFormal Methods inComputer-AidedDesign ,
pages210–217, 2013.
[52] C.Wang,S.Chaudhuri,A.Gupta,andY.Yang.Symbolic 
pruningofconcurrentprogramexecutions.In ACM 
SIGSOFTSymposium on Foundations of Software 
Engineering ,pages23–32,2009.
[53] C.WangandM.Ganai.Predictingconcurrencyfailuresi n
generalizedtracesofx86executables.In International 
Conference onRuntime Veriﬁcation ,pages4–18,Sept.2011.
[54] C.Wang,S.Kundu,M.Ganai,andA.Gupta.Symbolic 
predictiveanalysisforconcurrentprograms.In International 
Symposium onFormal Methods ,pages256–272, 2009.
[55] C.Wang,R.Limaye,M.Ganai,andA.Gupta.Trace-based 
symbolicanalysisforatomicityviolations.In International 
Conference onTools and Algorithms for Construction and 
Analysis of Systems ,pages328–342, 2010.
[56] C.Wang,M.Said,andA.Gupta.Coverageguided 
systematicconcurrencytesting.In International Conference 
onSoftware Engineering ,pages221–230,2011.
[57] C.Wang,Y.Yang,A.Gupta,andG.Gopalakrishnan.
Dynamicmodelcheckingwithpropertydrivenpruningto 
detectraceconditions.In International Symposium on 
AutomatedTechnology for Veriﬁcationand Analysis ,pages 
126–140, 2008.
[58] C.Wang,Z.Yang,V.Kahlon,andA.Gupta.Peepholeparti al
orderreduction.In International Conference on Toolsand 
Algorithms for Construction and Analysis ofSystems ,pages 
382–396, 2008.
[59] Y.Yang,X.Chen,G.Gopalakrishnan,andR.Kirby.Efﬁci ent
statefuldynamicpartialorderreduction.In SPINWorkshop 
onModel CheckingSoftware ,pages288–305, 2008.
[60] Y.Yang,X.Chen,G.Gopalakrishnan, andC.Wang.
Automaticdiscoveryoftransitionsymmetryinmultithread ed 
programsusingdynamicanalysis.In International SPIN 
workshop on Model Checking Software ,pages279–295,
2009.
[61] Q.Yi,Z.Yang,S.Guo,C.Wang,J.Liu,andC.Zhao.
Postconditionedsymbolicexecution.In IEEEInternational 
Conference onSoftware Testing, Veriﬁcationand Validatio n,
pages1–10,2015.
[62] N.Zhang,M.Kusano,andC.Wang.Dynamicpartialorder 
reductionforrelaxedmemorymodels.In ACMSIGPLAN 
Conference onProgramming Language Designand 
Implementation ,pages250–259, 2015.
865