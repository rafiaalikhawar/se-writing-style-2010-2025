Parsimony: An IDE for Example-Guided Synthesis
of Lexers and Parsers
Alan Leung, Sorin Lerner
University of California, San Diego, USA
{aleung, lerner}@cs.ucsd.edu
Abstract ‚ÄîWe present Parsimony, a programming-by-example
development environment for synthesizing lexers and parsers
by example. Parsimony provides a graphical interface in which
the user presents examples simply by selecting and labeling
sample text in a text editor. An underlying synthesis engine
then constructs syntactic rules to solve the system of constraints
induced by the supplied examples. Parsimony is more expressive
and usable than prior programming-by-example systems for
parsers in several ways: Parsimony can (1) synthesize lexer
rules in addition to productions, (2) solve for much larger
constraint systems over multiple examples, rather than handling
examples one-at-a-time, and (3) infer much more complex sets of
productions, such as entire algebraic expression grammars, by
detecting instances of well-known grammar design patterns. The
results of a controlled user study across 18 participants show
that users are able to perform lexing and parsing tasks faster
and with fewer mistakes when using Parsimony as compared to
a traditional parsing workÔ¨Çow.
Index Terms ‚ÄîLexer, parser, program synthesis, programming-
by-example.
I. I NTRODUCTION
Despite over four decades of research on parsing, building
parsers remains a difÔ¨Åcult task. Widely used parser genera-
tors such as Bison demand detailed understanding of their
underlying algorithms for effective use. More modern tools
such as ANTLR [ 1] and Packrat parsers [ 2] are arguably more
user friendly, but even still have their own subtle gotchas,
such as restrictions against preÔ¨Åx matches or left recursion [ 3].
Even generalized parsers [ 4], which allow speciÔ¨Åcation of any
context-free grammar, present subtle difÔ¨Åculties as they allow
speciÔ¨Åcation of ambiguous grammars.
Programming-by-example (PBE) is a programming paradigm
that improves user-friendliness by allowing users to construct
programs by supplying examples demonstrating the result of
an intended computation, rather than writing code manually. In
this paper we present Parsimony, a novel application of PBE
for constructing parsers: the user selects text in a Ô¨Åle the user
wishes to parse, then supplies a label for that selection. Under
the hood, Parsimony infers productions to parse those selections.
As the user provides more examples in this way, Parsimony
successively constructs a more complete implementation.
As will be discussed in detail in related work, compared to
Parsify, our prior work on PBE for parsers [ 5], Parsimony is
more expressive, more usable, and has been evaluated more
extensively ‚Äì in particular, through an end-user study. The
key to Parsimony‚Äôs expressiveness and usability lies in several
novel technical contributions, which we now discuss.Lexer by Example: Parsimony provides new facilities for
synthesizing lexer deÔ¨Ånitions from example tokens. Our key
insight is to exploit a large corpus of useful, curated regular
expressions (regexes) that already exist: the lexers for existing
programming languages. We frame the task of synthesizing
lexers as queries to a data structure called an R-DAG built
from this corpus. In contrast to previous approaches [ 6], our
approach guarantees that any synthesized rule will be realistic
rather than synthetic, in the sense that it is known to be useful
in the context of a real-world language implementation.
Insensitivity to Order: To make Parsimony insensitive to
the order in which the user presents examples, we develop a
fresh perspective on a classical parsing algorithm Ô¨Årst described
over 50 years ago, the Cocke-Younger-Kasami (CYK) parsing
algorithm [ 7]. We propose a a novel graph data structure built
from CYK tables called the CYK automaton that efÔ¨Åciently
tracks a large set of candidate productions, rather than just one.
Crucially, because the number of candidates can explode with
the length of the example, CYK automata efÔ¨Åciently encode
an exponential number of candidates with space only quadratic
in the length of the example. We then frame synthesis as
graph transformations on automata in which candidates are
only removed from consideration when no longer applicable,
thus avoiding premature loss of candidates.
Principled Generalization: To allow Parsimony to gener-
alize from examples, we make the key insight that many impor-
tant design patterns can be encoded by specially constructed
CYK automata. Detecting an instance of a design pattern then
reduces to a standard graph intersection between two CYK
automata: one representing the pattern and one representing the
example. We demonstrate the generality of this approach by
implementing the repetition patterns from Parsify along with
new patterns (such as inÔ¨Åx algebraic expressions), simply by
deÔ¨Åning an automaton for each pattern, along with a schema
for the productions to generate based on that pattern.
Finally, we perform a thorough evaluation of Parsimony‚Äôs
effectiveness via a controlled study in which 18 programmers
previously unfamiliar with Parsimony performed a series of
tasks using experimental and control variants of Parsimony.
Our results show that Parsimony improves user outcomes as
measured by both time to completion and number of mistakes.
In summary, we make the following contributions:
(1)A novel data structure, the R-DAG, for synthesizing lexer
rules by example (Section III).
978-1-5386-2684-9/17/$31.00 c2017 IEEEASE 2017, Urbana-Champaign, IL, USA
Technical Research815
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. Fig. 1. The Parsimony user interface.
(2)Another novel data structure, the CYK automaton, and
corresponding algorithms for synthesizing productions by
example (Section IV).
(3)An extensible framework for generalizing from examples
of common parser design patterns (Section IV).
(4)The results of a controlled user study demonstrating the
effectiveness of our approach (Section V).
II. O VERVIEW
Parsimony‚Äôs user interface is shown in Figure 1. Its basic
functionality includes standard features ubiquitous amongst
integrated development environments: (1) a customizable
workspace consisting of resizable panes and tabs, (2) a Ô¨Åle
browser for managing project contents, and (3) text editors for
viewing and editing Ô¨Åles. Parsimony also borrows graphical
features from Parsify, such as tree visualizations and coloring
of text Ô¨Åles based on grammar changes. Unique to Parsimony,
however, are two tabs for the lexer and parser synthesis engines:
(1)The Token Labels Tab allows the user to synthesize lexer
rules from example tokens.
(2)The Solver Tab provides rich functionality for synthesizing
and previewing grammar productions derived from strings
labeled with syntactic categories (i.e., nonterminals).
In the remainder of this section, we illustrate the Parsimony
workÔ¨Çow and its salient features by walking through a series
of scenarios demonstrating how we might employ Parsimony
to develop the lexer and parser for a toy language called Fuyu.
A sample Fuyu program, 1.fuyu , is shown below.
def a = 2; def alpha = a;
def gamma1 = (a+-88)^(a*0.3);
def Delta-2 = [1e12, 6.022e+23, 12.2E-10];
Keywords: We start by synthesizing a lexer rule for the
defkeyword via following three steps: (1) click the Token
Labels Tab to activate it, (2) select the substring " def" in
1.fuyu , then (3) add it as an example token by clicking the
blue plus sign that appears.
The Token Labels Tab then
updates its contents, as shown
at right. In particular, the left-
hand drop-down shows the list
of examples added (only one
so far), and the right-hand side
shows a candidate rule that Parsimony has inferred from that
example: DEF = def . This rule meets our requirements, so we
add it to our lexer deÔ¨Ånition by clicking the button labeled
Add to token deÔ¨Ånitions .
Parsimony immediately recompiles
the lexer and colors 1.fuyu in
response. The coloring, shown at
right, tells us two important facts.
First, the colored box surrounding " def"
tells us that " def" matches the lexer
rule we just deÔ¨Åned, as indicated by
the Legend. Just like a chart legend,
the Legend gives the correspondence
between colors and names. Second, the red error box tells
us that no lexer rule yet matches the character " a". Intuitively,
the error box‚Äôs location tells us how far into the Ô¨Åle the lexer
was able to construct the token stream. To Ô¨Åx this error, we
will need to deÔ¨Åne a rule for identiÔ¨Åers like " a".
IdentiÔ¨Åers: TheDEF rule we have just deÔ¨Åned is the
simplest sort of rule ‚Äì it matches exactly the string " def", which
is easy enough to write without synthesizing it. IdentiÔ¨Åers,
however, are a more challenging sort of token. Suppose our
language speciÔ¨Åcation dictates that identiÔ¨Åers consist only of
alphanumerics and hyphens; additionally, the Ô¨Årst character
must be alphabetical. We want Parsimony to automatically
synthesize a lexer rule that meets that speciÔ¨Åcation. We start
by adding the example identiÔ¨Åer " a" to the Token Labels Tab.
Based on this single example, Parsimony infers the candidate
ruleALC = a , which is disappointingly speciÔ¨Åc because one
example is not enough for Parsimony to make a good inference.
To ask Parsimony to infer a rule from a group of examples ,
rather than just one, we drag and drop multiple samples into
their own folder. Shown below is a folder labeled IDENT into
which we have added the four identiÔ¨Åers from 1.fuyu ; the
right-hand side of the Ô¨Ågure shows that Parsimony has inferred
two different candidates from the examples in that folder.
To gain more intuition, we click the Example Strings buttons
to ask Parsimony to show us examples of strings matched by
each rule. Parsimony then updates the view with the strings
shown in gray. It is clear from them that the Ô¨Årst rule permits
underscores, which violates our speciÔ¨Åcation. The second rule,
however, seems correct by inspection of the example strings
and the rule‚Äôs deÔ¨Ånition, so we accept the inference. As before,
Parsimony recompiles the lexer and colors 1.fuyu .
At this point, based on the coloring we can proceed as
before: synthesize a new rule for the next failing token, which
happens to be the " =" token. Since the basic scenario is the
same as for keywords, let us assume for the sake of exposition
that lexer rules for the remaining basic symbols (e.g., +,-,*,{},
etc.) have been deÔ¨Åned in the remainder of this section.
816
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. Numeric Literals: Numeric literals in Fuyu take the form
of integers or Ô¨Çoating point numbers speciÔ¨Åed in decimal or
scientiÔ¨Åc notation. The desired lexer should assign such literals
the token name NUMBER . The six numeric literals from 1.fuyu
are 2, -88, 0.3, 1e12, 6.022e+23, and 12.2E-10.
Numeric literals are the most complex lexical forms in Fuyu.
It would likely take a seasoned veteran of lexical analysis to
correctly implement its regex on the Ô¨Årst try:
\-?(0|[1-9][0-9]*)(\.[0-9]+)?([Ee][+\-]?(0|[1-9][0-9]*))?
Parsimony synthesizes this regex from just those six examples.
In fact, it is the only candidate Parsimony shows the user
because there exists no other expression of equivalent or better
quality in its corpus of training data. Parsimony uses a notion
of quality based on how speciÔ¨Åcally the candidate matches
the examples: for instance, the pattern .*also matches the
examples, but it is much more general and thus inferior ‚Äì we
deÔ¨Åne this notion of quality formally in Section III. After
accepting the inference, our lexer is complete. 1.fuyu , with
all tokens properly colored, is shown below.
With lexer in hand, we proceed to the parser. In this section,
we successively augment fuyu.g with productions for the
various syntactic constructs of Fuyu.
Simple Assignments: We start the process by posing an
example of an assignment statement. We do this by 1) selecting
"def a = 2; ", 2) typing " assign " into the text box that appears,
then 3) clicking the Solve button. The Solver Tab responds
by presenting the following stylized candidate production that
Parsimony has synthesized from the example:
The production is close to correct, but it has the token NUMBER
hardcoded in the fourth position, which precludes other kinds of
non-numeric expressions. To Ô¨Åx this, suppose we pose another
example: " def alpha = a; ". The Solver Tab now responds
with a pair of candidates:
At this point, it should be clear that Parsimony needs to be
taught that NUMBER andIDENT are instances of a common
syntactic category (nonterminal) representing expressions: expr .
To do this, we pose to the Solver
both "2" and "a" as examples of
expr . The result is a set of three
candidates, shown at right. The
Ô¨Årst two candidates match our expectation: to parse NUMBER
andIDENT tokens as expressions, add the two productions
expr!NUMBER andexpr!IDENT . The third candidate has
a special form. It indicates that the we can choose between
two options for the second position: either IDENT orexpr.
Parsimony gives us this option because it has determined that
either choice is consistent with the examples we have provided.
To help us make a decision, Parsi-
mony shows us parse tree visualizations
corresponding to each option, shown at
right. In particular, if we choose expr,
we will get the top parse tree. If we
chooseIDENT , we will get the bottom
parse tree. Suppose that according to our
speciÔ¨Åcation, only variable names (i.e.,
IDENT tokens), can appear on the left-
hand side of an assignment. To achieve
this, we choose the IDENT option before accepting the solution.
All our interactions with the Solver thus far have the net effect
of augmenting fuyu.g with the three productions expr!
NUMBER ,expr!IDENT , andexpr!DEF IDENT EQ expr SEMI .
Parsimony automatically recompiles the parser, then colors
1.fuyu accordingly: the result is shown below. Note that the
Ô¨Årst two assignments are now surrounded by colored boxes
corresponding to the nonterminal assign .
Algebraic Expressions: From the appearance of line 2,
we know that our parser cannot yet handle the right-hand
side of the assignment to gamma1 , so we pose a new expr
example: " (a+-88)ÀÜ(a*0.3) ". Because algebraic expressions
are ubiquitous in programming languages, Parsimony contains
a powerful heuristic mechanism for detecting such syntac-
tic constructs. Based on this heuristic, Parsimony presents
the user with a graphical wizard that asks 1) if this is
indeed an algebraic expression, 2) for each operator ( +,*,ÀÜ )
whether that operator is left- or right-associative, and 3) what
should be the order of precedence for those operators. Based
on the answers to these questions, Parsimony constructs
an idiomatic subgrammar for parsing expressions of this
kind. Suppose we answer using the standard mathemati-
cal order of operations. The synthesized subgrammar then
comprises four productions with associativity annotations:
expr!expr + expr {left} ,expr!expr * expr {left} ,
expr!expr ÀÜ expr {right} , andexpr!( expr ) . Addi-
tionally, Parsimony synthesizes the following precedence anno-
tation:priorities { expr !expr ÀÜ expr > expr !expr
* expr ; expr !* expr > expr !expr + expr ; } . Un-
der the hood, these annotations compile to disambiguating
Ô¨Ålters [8], [9] that enforce a policy in the parser such that
parse trees obey the speciÔ¨Åed associativity and precedence
hierarchy. Parsimony recolors 1.fuyu in accordance with this
new set of inferences:
Array Literals: The last syntax left to handle is the
array literal, shown on line 3. We pose " [1e12, 6.022e+23,
12.2E-10] " as an example of an array . Parsimony contains
a built-in heuristic to detect delimited repetitions, another
ubiquitous language design pattern. Based on this heuristic,
817
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. Parsimony presents a graphical wizard conÔ¨Årming whether
1) each element of the list is a NUMBER orexpr , 2) the separator
between elements is a comma, and 3) the list is surrounded
by a pair of square brackets. After conÔ¨Årming, Parsimony
synthesizes an idiomatic subgrammar for delimited lists of
exprs:array![ -array-inner ] ,-array-inner!expr,
-array-inner!expr COMMA -array-inner .
The new coloring shows
that the array literal
parses correctly. However,
the parent assignment is still not surrounded by a box for
assign : we haven‚Äôt told Parsimony that an array literal is also
a form of expr .
The Ô¨Åx is simple: we pose " [1e12, 6.022e+23,
12.2E-10] " as an example of an expr , then accept
the inference expr!array , shown at right.
Fuyu Program: Finally, we deÔ¨Åne a start symbol for the
parser. We simply pose the entirety of 1.fuyu as an example of
aprogram . Parsimony detects that this is yet another example
of a ubiquitous pattern ‚Äì this time, an undelimited list of
assign instances. When we conÔ¨Årm this inference, Parsimony
generates two productions: program!assign andprogram!
assign program . Our parser is now complete.
III. L EXER SYNTHESIS
In this section we formalize Parsimony‚Äôs algorithm for
synthesizing lexers. The core of our approach is the R-DAG, a
novel data structure for representing sets of regexes.
We Ô¨Årst deÔ¨Åne the R-DAG*, the precursor to an R-DAG. An
R-DAG* is a poset (R;<)such that
(1)Ris a set of regexes,
(2)<(RR)is the language containment relation over R
such that8r1;r22R:L(r1)L(r2),(r1;r2)2<,
(3)Rcontains a designated regex >Dsuch thatL(>D)is
the set of all strings, and
(4)8r1;r22R:L(r1) =L(r2))r1=r2.
An R-DAG* can be viewed equivalently as a directed acyclic
graph such that Ris its vertex set and <is its edge set. For
ease of exposition we will view R-DAG*s as graphs or posets
interchangably as is convenient in the sequel.
We now deÔ¨Åne the R-DAG via reduction from an R-DAG*.
LetD= (R;<)be an R-DAG*. We deÔ¨Åne its corresponding
R-DAGD= (R;<)to be the transitive reduction of D. That
is,Dis the graph with the same vertex set RasD, but with
edge set <, the unique minimum size relation whose transitive
closure is <.
From a practical perspective, we can view an R-DAG as
a database of regexes such that the language containment
relationship between regexes is stored explicitly in the form of
graph edges. In our implementation, this database contains ~3K
regexes scraped from open source lexer implementations [ 10].
We exploit this structure via a specially designed graph query
to answer the question ‚ÄúWhat is the most speciÔ¨Åc set of regexes
that match strings s1,s2, ...?" In this instance, ‚Äúmost speciÔ¨Åc"
informally means that there exists no other regex (in the
database) with smaller language that could also match thosestrings. We additionally would like this set to be the largest
set with this property, so we know we are not missing out. The
remainder of this section discusses the query algorithm.
A. Regular Expression Inference via R-DAG Queries
We now deÔ¨Åne the HORIZON query on R-DAGs: the purpose
of this query is to discover the largest , yet most speciÔ¨Åc set of
regexes that match a set of example strings.
We start with some intuition. Suppose we have an R-DAG
D= (R;<)and a string s. First, we wish to Ô¨Ånd a set of
regexesHRsuch that every regex in Hmatchess. Second,
we requireHto be succinct: no two regexes in Hshould be
related by <. Third, we require Hto be as large as possible
without compromising quality: adding any regex would violate
succinctness, and replacing any regex would make it worse
(i.e., closer to>D). These three conditions are captured by the
notions of consistency ,succinctness , and maximality , which
we now deÔ¨Åne formally.
LetSbe a set of strings and let D= (R;<).His consistent
withSiff8r2H;s2S:s2L(r).His succinct with respect
toDiff8r;r02 H:r6<r0.His maximal with respect
to(D;S)iff no regex r2Rexists such that: (1) r =2H ,
(2)8s2S:s2L(r), and (3)8r02H:(r<r0_r06<r).
His a horizon of (D;S)iffHis consistent with S, succinct
with respect toD, and maximal with respect to (D;S).
We now deÔ¨Åne the query HORIZON (D;S), which computes
the horizon of (D;S):
1function HORIZON (D;S)
2W f>Dg;H ;
3whilejWj>0
4 letr=removeAny (W)
5 letRp=fr02predecessors (D;r)j8s2S:s2L(r0)g
6 ifRp>0
7W (W r)[Rp
8 elseW W  r;H H[frg
9returnH
Intuitively, HORIZON maintains a worklist Wof vertices to
inspect. The worklist initially contains only >D, the topmost
regex that matches any string, and is thus guaranteed to be
reachable from any other vertex of D. In each iteration, we
remove a regex rfrom the worklist and compute the set
of predecessors of rthat match all strings in S. If such
predecessors are found, we then add them to the worklist and
proceed to the next iteration. However, if no such predecessor
exists, then we have gone as far down the graph as possible (i.e.,
we have found the most speciÔ¨Åc regex), so we add the current
vertex to output set H. We continue this process until the
worklist is exhausted. At completion, His a set of regexes that
is consistent with S, succinct with respect to D, and maximal
with respect to (D;S). In other words, it is the horizon of
(D;S). Because each constituent regex is known to match every
string inS, it is a candidate for the body of a lexer rule for
S. BecauseHis succinct with respect to Dand maximal with
respect to (D;S), we know there are no ‚Äúbetter" candidates
that we have missed.
818
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. IV. P ARSER SYNTHESIS
In this section we formalize Parsimony‚Äôs algorithms for
synthesizing parsers. We begin with a preliminary overview of
context-free grammars and parsers.
A. Preliminaries
Acontext-free grammar is a tupleG= (N;;P;S ), where
Nis a set of nonterminals, is a set of terminals, Sis a
designated start nonterminal, and P(NV)is a set of
productions where Vis the setN[called the vocabulary
ofG. For convenience, productions (A;)2Pare written
equivalently as A!.
String Indexing: String indices begin at 0. We write [i]
to mean the symbol at index iof string. By[i:::]we denote
the sufÔ¨Åx of starting at index i, and by[i:::j]we denote the
substring of starting at index iwith lengthj i. We writejj
to denote the length of , and we write for concatenation
ofand.
Derivations: We sayderivesin a single step, written
), ifPcontains a production A!such that=A
and=. Equivalently,)is the single-step derivation
relation such that (;)2) iffderivesin a single step.
Let)be the transitive closure of ). We sayderives
iff), and a derivation offromis a sequence
):::)that witnesses ). Asentential form is a
string2Vsuch thatS), asentence is a sentential
form containing only terminals, and L(G), the language of G,
is the set of all its sentences.
CYK Algorithm: The Cocke-Younger-Kasami (CYK)
parsing algorithm [ 7] is a classical dynamic programming
algorithm for computing whether a string is derivable via
a grammar G. For our purposes, the crucial feature of the
algorithm is that it constructs a 2D table M, called a CYK
table, that records for every substring 0ofthe set of
nonterminals that derive 0:A2Mi;l()A)[i:::i+l].
For a description of the algorithm itself, we refer the reader
to Grune and Jacobs [ 11]. In the remainder of this paper, we
assume without deÔ¨Ånition that we have a function CYK(G;)
that returns a CYK table given a grammar Gand string.
B. Parser Synthesis Constraint Systems
We now make precise the parser synthesis problem by fram-
ing it as constraint satisfaction. A parser synthesis constraint
system is a tuple C= (G;F;L)where
(1)Gis a grammar,
(2)F=ff1;f2;:::;fkgis a set of strings called Ô¨Åles with
unique labels f1;f2;:::;f kcalled Ô¨Åle names , and
(3)Lis a set of parse constraints of formhA;i;lifdenoting
a lengthlselection starting at index iinto Ô¨Ålef2F
labeled with nonterminal A.
Let the notation G]Pmean the grammar Gaugmented
with additional productions P. A solution to constraint system
Cis a set of productions Pthat satisÔ¨Åes the formula:
8hA;i;lif2L:M=CYK
G]P;f
[i:::i+l]
^A2Mi;lIfPsatisÔ¨Åes the above formula, we say PsatisÔ¨Åes C.
Intuitively, then, the parser synthesis problem is the task of
Ô¨ÅndingP, a set of productions that allow us to derive every
constrained substring encoded by L.
C. A Data Structure for Large Sets of Candidate Productions
In this section we describe the CYK automaton , a data
structure for efÔ¨Åciently representing large sets of candidate
productions. This data structure is a central component of
Parsimony‚Äôs parser synthesis engine.
Intuition: Intuitively, a CYK table is simply a static record
of the nonterminals that derive each piece of a string being
parsed. For example, M2;5is the set of nonterminals that derive
the substring [2:::7]. However, this is only one interpretation
of the table. An alternate perspective is that the table contains
predictions about the set of productions that we might add to
our grammar to grow the language. Consider, for instance, that
we have the string aband grammar with productions A!a
andB!b. We would then have CYK table Msuch that
M0;1=fAg,M1;1=fBg, andM0;2=;. Suppose that we
wish forabto also belong to the language we are designing.
What production should we add to make it so? The CYK table
has almost all the information we need to answer that question.
We could combine one element of M0;1with one element
ofM1;1to create the production body AB. If we add the
productionS!AB, we will have augmented the language to
include exactly the string ab. Note, however, that there are other
productions we could have added instead: S!aB,S!Ab,
orS!ab. Even in this trivial case, we see that there can be
many such candidate productions. A CYK automaton is a data
structure for making explicit what the candidates are and for
providing efÔ¨Åcient queries to compute those candidates.
DeÔ¨Ånition: A CYK automaton is a directed graph Y=
(I;E;i s;If;U;)whereIZis a set of vertices, EII
is a set of edges, is2Iis a designated start vertex, IfIis
a designated set of Ô¨Ånal vertices, Uis a set of symbols, and 
is a map from edges in Eto sets of symbols in U. We use the
notation [e7!X]for the mapx:ifx=ethenXelse(x).
Given a grammar Gand string, we construct a CYK
automaton via algorithm BUILD -CYK-AUTOMATON below.
1function BUILD -CYK-AUTOMATON (G;;i s;if)
2let(N;;;) =G
3letM=CYK(G;)
4(I;E; ) (f0ijjg;;;x:;)
5foriin
is;if
6E E[f(i;i+ 1)g
7 [(i;i+ 1)7!f[i]g]
8foriin
is;if
9 forlin
1;if i
10 ifMi;l6=;
11E E[f(i;i+l)g
12  [(i;i+l)7!(i;i+l)[Mi;l]
13return (I;E;i s;fifg;N[;)
Intuitively, each vertex of a CYK automaton corresponds
to a position between tokens (e.g., 1 indicates the position
between the 0thand 1sttoken). An edge between vertices j
andkcorresponds to the CYK table entry Mj;k j: that is, the
set of nonterminals of Gthat derive the substring [j:::k]. This
819
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. set is recorded via map entry (j;k). Additionally, for every
singleton edge (j;j+ 1) (i.e., those that correspond to length
1 substrings), we also add to the terminal [j]occurring at
that position. By construction, any path between vertex 0and
vertexjjcorresponds to a set of candidate production bodies
that derive, as will be illustrated in the following section.
D. Parser Synthesis via CYK Automata
In this section, we progress through several descriptions of
successively more sophisticated mechanisms for solving parser
synthesis constraint systems via CYK automata, building from
simple cases up to more complex cases. We motivate each
augmentation with an example demonstrating the limitation it
overcomes. At the end of this section, we will have arrived at
the full algorithm used by Parsimony, dubbed PARSYNTH .
Case 1 ‚Äì One Parse Constraint :We Ô¨Årst consider synthesis
constraint systems with only one parse constraint. Let us revisit
the example from Section IV-C , in which we have the string ab,
a partially implemented grammar G1with productions A!a
andB!b, but wish for abto derive from a new nonterminal
Sthat has yet to be implemented. As we saw in Section II,
to do this using Parsimony we simply highlight the text ab,
type the label Sinto the Solver text box, then run the Solver.
Under the hood, this sequence of user operations constructs
the following parser synthesis constraint system:
C1= (G1;F1;L1);F1=fabf1g;L1=fhS;0;2if1g
To solve this constraint system, our strategy will be to construct
a CYK automaton for the parse constraint in L1, then generate
productions corresponding to the shortest path through the au-
tomaton. SpeciÔ¨Åcally, we construct the automaton for constraint
hS;0;2if1with parameters =ab;is= 0;If=f2g:
0 1 {A, a}{B,b}2 
The shortest (and only) path is 0;1;2. Taking the n-ary
Cartesian product of edge attributes along the path, we
havefA;agfB;bg=f(A;B);(A;b);(a;B);(a;b)g. Each
constituent tuple, when read from left to right, is the body
of a production for Sthat derives ab. That is, any such
production is a solution to C1. To succinctly represent the
space of choices, Parsimony uses a graphical representation
called a candidate matrix , an example of which is shown below.
S	 ¬†a	 ¬†b	 ¬†A	 ¬†B	 ¬†
The semantics of a candidate matrix is straight-
forward: the kthcolumn of the matrix shows
all the symbols that may possibly occur at
positionkin the corresponding production body. The user must
enable exactly one such symbol per column. The sequence
of enabled symbols, when read from left to right, gives us
the corresponding production. A candidate matrix succinctly
visualizes a potentially large set of productions that grows
exponentially in the number of columns: a candidate matrix
withkcolumns and nsymbols per column encodes nk
productions. We denote by XJN1N2:::NkKthe candidate
matrix with kcolumns such that Njis the set of symbols
in columnj, andXis the left-hand side symbol.Each production encoded by a candidate matrix Mis called a
valuation ofM. To construct candidate matrices, we deÔ¨Åne the
following constructor function 	X
, which given a path through
a CYK automaton, constructs the corresponding candidate
matrix: 	X
(i0;:::;i n) =XJ(i0;i1):::(in 1;in)K.
Case 2 ‚Äì Non-Overlapping Parse Constraints :We now
consider systems of multiple parse constraints. As a Ô¨Årst step,
we consider the simplest case in which no two parse constraints
overlap (i.e., they reference disjoint substrings).
To handle this in the straightforward way, we could construct
one candidate matrix per parse constraint. Suppose we have
the following constraint system C2, which models a grammar
where identiÔ¨Åers idand numbers 1are forms of expressions
E, and the user has selected and labeled two substrings " id=
id" and "id= 1" with the nonterminal S(statements). The
synthesis task is to infer one or more productions for S.
G2= (fE;Sg;fid;1;=g;fE!id;E!1g;S)
C2= (G2;F2;L2)F2=fid=idf1;id= 1f2g
L2=fhS;0;3if1;hS;0;3if2g
The computed solution is the set of two candidate matrices
fM1;M2gwhere M1=SJfE;idgf=gfE;idgKandM2=
SJfE;idgf=gfE;1gK. In this situation, Parsimony would
display both candidate matrices in the Solver Tab and allow
the user to interact with each. There are two problems in
this scenario: (a) Since the user provided parse constraints for
only one kind of syntactic construct (namely, statements S),
it may be confusing for the user to see two distinct candidate
matrices when only one was expected, and (b) it may lead the
user to accept a solution of two productions (one for M1and
one for M2), which is subpar because the more economical
solution to C2consists of only a single production: namely
S!id=E. Clearly, our algorithm needs to be improved
to handle such cases and avoid computing more candidate
matrices than necessary.
Case 3 ‚Äì Non-Overlapping Parse Constraints with Sharing :
As we have just seen, M1andM2are redundant ‚Äì we need
only one of the two since both share the desired valuation
S!id=E. To eliminate such redundancies, our strategy is
to Ô¨Ånd a way to partition the constraints L2into disjoint sets,
called classes, such that the constraints in each class can be
satisÔ¨Åed by the same productions. By producing as few classes
as we can, then computing only a single candidate matrix for
each such class, we seek to produce an economical solution.
To do this we will Ô¨Årst need to deÔ¨Åne an operation for the
intersection of two CYK automata.
Intersection: LetY= (I;E;i s;If;U;)andY0=
(I0;E0;i0
s;I0
f;U0;0). The intersection of YandY0, written
Ye\Y0, is deÔ¨Åned as follows:
Ye\Y0= (II0;E\;(is;i0
s);IfI0
f;U\U0;\)
\= 
(x;x0);(y;y0)
: 
(x;y)
\0 
(x0;y0)
E=n 
(x;x0);(y;y0)
j(x;y)2E^(x0;y0)2E0o
E\=
e2Ej\(e)6=;	
We say that CYK automata YandY0are compatible, written
COMPATIBLE (Y;Y0), if and only if the intersection Ye\Y0
820
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. 1function PARTITION (Y)
2letays=f((A1;Y1);(A2;Y2))j((A1;Y1);(A2;Y2))2Y2^
3 A1=A2^COMPATIBLE (Y1;Y2)g
4if(ays6=;)
5 let(ay1;ay2) =Ô¨Årst(sortDescBy (SCORE Y;ays))
6 let((A1;Y1);(A2;Y2)) = (ay1;ay2)
7 letY12=Y1e\Y2
8 return PARTITION (Y fay1;ay2g[f (A1;Y12)g)
9else return Y
10function SCORE Y((A1;Y1);(A2;Y2))
11if(A16=A2)return 0
12returnX
(A3;Y3)2Ys.t.A3=A1SCORE -ONE-TRIPLET (Y1;Y2;Y3)
13function SCORE -ONE-TRIPLET (Y1;Y2;Y3)
14if(COMPATIBLE (Y1;Y3)^COMPATIBLE (Y2;Y3)^
15 COMPATIBLE (Y1e\Y2;Y3))return 1
16else return 0
Fig. 2. Algorithm PARTITION .Yis a set of pairs (A;Y)whereYis a CYK
automaton and Ais its corresponding nonterminal.
contains a path from the start vertex (is;i0
s)to a Ô¨Ånal vertex
inIfI0
f.
Intersection of CYK automata is similar to the standard prod-
uct construction for intersection of Ô¨Ånite automata; however,
we additionally intersect edge attributes such that each resulting
edge attribute is the set of symbols shared by both originating
edges. With this construction, any path through the intersection
Ye\Y0corresponds to a common set of candidates shared by
bothYandY0. If:COMPATIBLE (Y;Y0), then there exists no
such shared candidate.
Partitioning: Our partitioning algorithm is shown in
Figure 2. We describe the algorithm informally here. We Ô¨Årst
compute for each parse constraint a tuple (A;Y)whereAis
the nonterminal of the constraint, and Yis the CYK automaton
constructed from that constraint. This set of tuples, denoted
Y, serves as the input to PARTITION . We then iteratively
intersect automata until no more intersection is possible. In
each iteration, we greedily intersect only the highest scoring
pair of automata, where our scoring function SCORE Ygives
preference to the pair that is maximally compatible with all
the other automata. The idea is to intersect those pairs whose
intersection has the most opportunity to intersect again in a
future iteration. At termination, the output of PARTITION should
be a set Y0such thatY0jYj, and each constituent tuple
(A0;Y0)2Y0contains a CYK automaton Y0that is possibly
the intersection of multiple automata from the original input
Y. Most importantly, any path in Y0from start to Ô¨Ånal vertex
gives us a solution to all the parse constraints that gave rise
toY0. In other words, each element of Y0corresponds to the
class of parse constraints that it solves .
For illustration, consider the constraint system C2from Case
2. The CYK automata before and after partitioning are shown
below, where Y1andY2correspond to the two constraints in
L2, andY12is the intersection of Y1andY2due to partitioning.
0 1 3 2 {=}{E,id}{E,id}{E,1}0 1 3 2 {=}{E,id}1,1 3,3 2,2 {=}{E,id}{E}0,0 Y1,Y2Y12By incorporating partitioning, the computed solution becomes
the single candidate matrix M3=SJfE;idgf=gfEgK. There
are two key features of this solution to note. First, there is only
one candidate matrix, not two. Second, the last column of M3
contains only E, notidor 1, because idand 1 were excluded
from edge ((2;2);(3;3))inY12during intersection. The two
possible valuations of M3areS!E=EandS!id=E.
In fact, these are the only possibilities: there exists no other
single production that would also satisfy C2. In this sense, this
computed solution is as good as possible.
Case 4 ‚Äì Overlapping Parse Constraints :A complication
occurs when constraints can overlap. Suppose we have the
following constraint system C4, which represents a situation in
which we have the same grammar G2as before, but the user
has created overlapping parse constraints like so:
id=id+idSE .
C4= (G2;F4;L4)
F4=fid=id+idf1gL4=fhS;0;5if1;hE;2;3if1g
The user‚Äôs intention is to specify that the enclosing con-
text id=id+id is an example of a statement S, and that
nested within it id+id is an example of an expression E.
Unfortunately, our algorithm sketched so far ignores this
nested relationship, and would compute the solution fM4;M5g
where M4=SJfE;idgf=gfE;idgf+gfE;idgKandM5=
EJfE;idgf+gfE;idgK. To see the problem, examine the
CYK automaton for M4(ignore the dotted edge for now):
0 1 5 2 {=}{E,id}3 4 {E,id}{E,id}{+}{E}
The subpath 2,3,4,5 corresponds to the substring id+id that the
user has constrained with nonterminal E, but the automaton
ignores that constraint and faithfully retains the underlying
CYK table information for edges (2;3),(3;4), and (4;5). Thus,
the synthesized candidate matrix M4is overly speciÔ¨Åc and
contains columns corresponding to those edges.
Our strategy is to replace such subpaths with summary
edges that summarize the effect of nested constraints. For
example, we replace the subpath 2,3,4,5 with a single edge
(2;5)whose edge attribute fEgreferences the nonterminal
of the nested constraint. The dotted edge (2;5)is such a
summary edge. After this transformation, the revised candidate
matrix M0
4=SJfE;idgf=gfEgKcorrectly encodes only
those productions where the right hand side of the assignment
statementSmust be an expression E. The candidate matrix M5
remains untouched. Together, M0
4andM5represent a solution
of two interrelated productions (one for Eand one for Sthat
referencesE). For example, one possible valuation for M0
4and
M5isS!id=EandE!E+E.
The algorithm for inserting summary edges is shown
in Figure 3. The function APPLY -NESTING takes as input
constraint system Cand returns a set Ywith summary edges
inserted.
821
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. 1function APPLY -NESTING (C)
2let(G;ffjgn
j=0;L) =C
3Y ;
4forL=hA;i;lifk2L
5 letL0=fL02LjLcontainsL0g
6Y BUILD -CYK-AUTOMATON (G;fk;i;i+l)
7 forL02L0
8Y SUMMARIZE (Y;L0)
9Y Y[(A;Y)
10return Y
Fig. 3. Algorithm APPLY -NESTING .SUMMARIZE takes an automaton and parse
constraint and returns the automaton with constrained paths replaced by a
summary edge.
Case 5 ‚Äì Constrained Patterns :Consider the constraint
system C5, which models the scenario in which the user has
selected and labeled the string [1,id,1] with the nonterminal
A(arrays).
G5= (fEg;f[;];,;1;idg;fE!1;E!idg;E)
C5= (G5;F5;L5)F5=f[1,id,1]f1gL5=fhA;0;7if1g
Plausibly, the user‚Äôs intention is that the constrained substring
is an example of literal array syntax permitting repetition of
the elements within square brackets. However, our algorithm
sketched so far has no special handling of such patterns. It
simply infers that the literal array must contain exactly 3
elements: M6=AJf[gfE;1gf,gfE;idgf,gfE;1gf]gK.
Our strategy for handling this case is two-fold. First, we
detect instances of common grammar design patterns using the
machinery for intersection of CYK automata. Second, for each
pattern we predeÔ¨Åne carefully crafted schema for productions;
the schema contain holes to be instantiated with symbols that
have been resolved during pattern detection.
Pattern Detection: SupposeY6is the CYK automaton
shown below from which we computed M6.
0 1 2 3 4 {[}{]}{,}{E,1}5 6 {,}7 {E,1}{E,id}
We wish to detect whether Y6represents an enclosed, delimited
repetition: that is, the repetition of two or more instances of a
symbol, each separated by a delimiter symbol, and surrounded
by a matching pair of enclosing symbols. Our key insight is
that it is possible to precisely specify such a pattern with a
specially constructed CYK automaton Y
edlist:
0 1 5 2 3 4 NdelimNelemNopenNcloseNelemNelem
whereNopen;Nclose;Nelem;Ndelim are sets of opening enclosers,
closing enclosers, element symbols, and delimiter symbols,
respectively. We set NopenandNcloseto statically predeÔ¨Åned
values for common encloser terminals ([],(),{} ), while we
setNelemandNdelim to be the vocabulary and terminals of
the current grammar, respectively. Then, to detect whether
Y6matches the pattern, we simply intersect Y6andY
edlist. If
COMPATIBLE (Y6;Y
edlist), then we have detected a match.
The intersection Y6e\Y
edlist is shown below, where edges
corresponding to array elements ( Nelem) are bold, and edgescorresponding to delimiters ( Ndelim) are dashed.
0,0 1,1 2,2 3,3 4,2 {[}{]}{,}{E,1}5,3 6,4 {,}7,5 {E,1}{E,id}
The set intersection of all dashed edge attributes is f,gand
gives us the set of possible delimiters N\
delim. Analogously, the
set intersection of all bolded edge attributes is fEgand gives
us the set of possible elements N\
elem. Finally, the Ô¨Årst and
last edge attributes are f[gandf]g, which give us the sets of
possible open and closing enclosers N\
openandN\
close.
Schema Instantiation: The last step is to instantiate
productions. Parsimony contains the following predeÔ¨Åned
schema, named P
edlist, for enclosed, delimited lists, where
each hole (subscripted ) is a placeholder to be instantiated by
a nonterminal or terminal, and Afreshis a fresh nonterminal.
P
edlist=lhs! openAfreshclose
Afresh! elem; A fresh! elemdelimAfresh
The valid instantiations for each placeholder are restricted to
the symbols (edge attributes) captured during intersection:
open2N\
openclose2N\
closeelem2N\
elemdelim2N\
delim
Additionally,lhsis a special placeholder instantiated
withA, the nonterminal from the originating parse
constrainthA;0;7if1. Fully instantiated, our solution is
A![Afresh];Afresh!E;A fresh!E,Afresh	
.
As already discussed in Section II, Parsimony‚Äôs interface
for pattern detection and schema instantiation comes in the
form of a wizard in the Solver Tab ‚Äì the user can graphically
select instantiations for each hole, or reject the inference
altogether if the detected pattern is spurious. Parsimony also
implements pattern detection and schema instantiation for inÔ¨Åx
algebraic expressions, undelimited lists, and unenclosed lists.
In each case, we simply deÔ¨Åne a CYK automaton paired with a
corresponding production schema. Their speciÔ¨Åcation is similar
in principle to that already shown, so we omit their details here.
We encapsulate pattern detection and schema instantiation in
procedure HEURISTIC (Y), which returns a tuple (P;L)where
Pis a set of instantiated production schemas (i.e., a set of
productions) and Lis the set of originating parse constraints.
The Algorithm PARSYNTH
1function PARSYNTH (C= (G;F;L))
2G0 G;L0 L;eM ; ;change? true
3while change?
4 change? false
5Y PARTITION (APPLY -NESTING ((G0;F;L0)))
6 let(P;L00) = HEURISTIC (Y)
7 ifP6=;
8G0 G0]P;L0 L0 L00;change? true
9foriin[0;1]
10Y PARTITION (APPLY -NESTING ((G0e]eM;F;L0)));eM ;
11 for(A;Y = (;;is;fifg;;))2Y
12eM eM[	A
(SHORTEST -PATH(Y;is;if))
13return (G0;eM)
Lines 3-8 repeatedly attempt to match patterns, accumulating all
instantiated schema until no more matches are found. Lines 11-
12 accumulate candidate matrices from any parse constraints
not handled by the Ô¨Årst loop. We perform two passes of the
822
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. loop such that solutions computed in the second pass take
advantage of those produced by the Ô¨Årst. In particular, the
operationG0e]eMon line 10 inserts into G0productions of the
formX!(A1j:::jAm):::(Z1j:::jZn)for each candidate matrix
XJfA1;:::;A mg;:::;fZ1;:::;Z ngKineM. To see why this is
valuable, recall Section II, in which we synthesized the fol-
lowing candidate matrices: expr JfIDENTgK,expr JfNUMBERgK,
andassign JfDEFgfexpr;IDENTgfEQgfexprgfSEMIgK. The
underlined nonterminal expr is computed in the second pass
by making use of the candidate production expr!IDENT ,
which was computed in the Ô¨Årst pass.
V. E VALUATION
To evaluate the effectiveness of Parsimony, we conducted a
user study in which 18 subjects without previous experience
using Parsimony were asked to complete a series of tasks
using one of two interfaces: either Parsimony with all its
features enabled, or a stripped-down version with no synthesis
or visualization features at all. We test the following hypotheses:
(1)Hypothesis 1. Parsimony helps users construct parsers
more quickly than with a traditional parsing workÔ¨Çow.
(2)Hypothesis 2. Parsimony leads users to make fewer
mistakes than with a traditional parsing workÔ¨Çow.
We targeted our user study at programmers who had some
familiarity with parsing, but who were not experts as determined
by self-rating. Our sample pool consisted of 18 Computer
Science students who were split by random assignment into
control and experimental groups. The interface seen by the
experimental group contained all features described in this
paper. The interface seen by the control group retained only a
workspace with Ô¨Åle browser and text editors, but no synthesis
or visualization features ‚Äì the interface modeled a traditional
parsing workÔ¨Çow in which the user employs a text editor and
relies on command-line compiler feedback.
Both groups Ô¨Årst read a brief introduction, then followed
a tutorial introducing them to the features of their interface.
Subjects then had two hours to complete 9 tasks asking them
to implement lexers and parsers for two toy languages, Fuyu
and Hachiya, designed speciÔ¨Åcally for the experiment. We
chose synthetic languages to prevent bias that might stem from
users‚Äô prior familiarity with existing languages ‚Äì although
synthetic, these languages contain syntactic constructs that
occur commonly in real languages, such as literal primitives
and data structures, loops, branches, and various statements.
Due to lack of space, we provide reference deÔ¨Ånitions online
athttps://github.com/parsimony-ide/ase2017-extra .
The Ô¨Årst seven tasks asked subjects to implement the lexer
and parser for the Fuyu language. Each task asked the subject
to implement one syntactic construct in isolation (e.g., numeric
literal or expression) ‚Äì in each case, the subject was given a Ô¨Åle
with positive examples of that construct. The Ô¨Ånal two tasks
asked subjects to write a parser for Hachiya given a sample
source Ô¨Åle and informal language speciÔ¨Åcation ‚Äì subjects were
free to implement syntactic constructs in any order they wished.
To Ô¨Ånish any task, subjects ran a test suite (provided by us) tocheck their solution. Subjects were not allowed to skip tasks
or to proceed without passing all tests.
Hypothesis 1 :We Ô¨Ånd that Parsimony signiÔ¨Åcantly improves
users‚Äô speed at constructing parsers. We focus on two measures
of time-based performance: average completion time per task,
and total progress made. We discuss total progress Ô¨Årst. Figure 4
(left) shows the number of subjects completing each of tasks
1-9. In the time alotted, Ô¨Åve experimental subjects progressed
through all 9 tasks, but only two control subjects completed all
tasks. The dropoff in the control group begins at task 4, which
was one of the more complex tasks, as it involved construction
of a grammar for algebraic expressions built from variables
and literals. By contrast, the dropoff in the experimental group
begins much later at task 7.
Figure 4 (center) shows average completion time for each
task. We average across only subjects who successfully
completed that task. The Ô¨Ågure shows that Parsimony either
matches or improves performance in the three most difÔ¨Åcult
tasks for the Fuyu language: 2, 4, and 5. Task 2 required
constructing a lexer rule for numeric literals (recall Section II).
Task 4, as already mentioned, covered algebraic expressions.
Task 5 required writing productions for literal arrays. In all three
cases, control subjects took approximately twice as long. We
do note, however, that our results appear to show no signiÔ¨Åcant
speed advantage in tasks 8 and 9 ‚Äì the averages for those
tasks are biased toward the control group as they contain only
a high-performing minority of the control group, compared
against a larger subset of experimental group.
Hypothesis 2 :We Ô¨Ånd that Parsimony signiÔ¨Åcantly reduces
the number of mistakes made. We measure two kinds of
mistakes: compile errors (when the user speciÔ¨Åes a bad rule
that causes a compile failure); and reasoning errors (when the
user speciÔ¨Åes a rule that is later deleted or modiÔ¨Åed).
Compile Errors: Figure 4 (right) shows the per-user
average number of compile errors. In lexer tasks (1-3), the
experimental group signiÔ¨Åcantly outperformed the control
group, as evidenced by the Ô¨Årst three columns of the Ô¨Ågure.
The experimental group also signiÔ¨Åcantly outperformed the
control group in parsing tasks (4-9). To more Ô¨Ånely distinguish
the contributing factors for this trend, we classify parser
compile errors into two kinds: syntax and semantic errors.
Syntax errors are self-explanatory. Semantic errors occur when
the compiler fails a semantic check: (a) the user speciÔ¨Åes a
production that references an undeÔ¨Åned symbol or introduces
a non-productive cycle (i.e., groups of productions that permit
inÔ¨Ånite derivation), or (b) the user speciÔ¨Åes disambiguating
Ô¨Ålters that are inconsistent with one another (e.g., the same
production is both left and right associative). Control users
averaged 8.3 syntax errors and 7.7 semantic errors, while
experimental users averaged 2.4 and 4.4, respectively, a
signiÔ¨Åcant reduction in both categories. This indicates that
Parsimony helps users not only avoid simple errors, such
as typos, but also helps them reason about the relationships
between productions to avoid conceptual mistakes.
Reasoning Errors: To measure reasoning errors in lexing
tasks, we recorded every lexer rule written by the user. We call
823
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. 0	 ¬†2	 ¬†4	 ¬†6	 ¬†8	 ¬†10	 ¬†
1	 ¬†2	 ¬†3	 ¬†4	 ¬†5	 ¬†6	 ¬†7	 ¬†8	 ¬†9	 ¬†#	 ¬†Completed	 ¬†Control	 ¬†Experimental	 ¬†
0	 ¬†10	 ¬†20	 ¬†30	 ¬†40	 ¬†50	 ¬†
1	 ¬†2	 ¬†3	 ¬†4	 ¬†5	 ¬†6	 ¬†7	 ¬†8	 ¬†9	 ¬†Minutes	 ¬†Control	 ¬†Experimental	 ¬†
0	 ¬†2	 ¬†4	 ¬†6	 ¬†8	 ¬†10	 ¬†
1	 ¬†2	 ¬†3	 ¬†4	 ¬†5	 ¬†6	 ¬†7	 ¬†8	 ¬†9	 ¬†Errors	 ¬†Control	 ¬†Experimental	 ¬†Fig. 4. (left) # subjects completing each task. (center) Mean time per task. (right) Mean compile errors per task. Error bars show standard error. X-axes show
tasks numbered sequentially in time.
this the cumulative lexer rule set Clex. We also recorded the set
of rules appearing in the subject‚Äôs Ô¨Ånal answer. We call this the
Ô¨Ånal lexer rule set Flex. The ratiojClexj=jFlexjapproximates the
amount of churn : how much the subject edited their result in
response to errors in reasoning. The experimental and control
groups saw an average churn ratio of 1.2 and 3.1, respectively.
In other words, the control group kept only 32% of rules and
threw away more than two-thirds of attempted rules, while the
experimental group kept nearly 81% of attempts.
We also measured the analogous churn ratio in parsing tasks.
In the experimental condition, the average churn ratio was
1.31, which tells us that subjects kept a large majority (76%)
of attempted productions in their Ô¨Ånal answer. The churn ratio
of the control group was signiÔ¨Åcantly higher at 1.99: nearly
half of all productions they wrote were eventually discarded.
Survey :Subjects were given exit surveys to rate their
experience. The averaged survey responses are summarized
below. Each response is on a 1-5 scale, where 5 is best. E and
C refer to experimental and control responses, respectively.
Question E Question E C
1 Coloring 4.78 7 Overall 4.78 4.00
2 Parse Tree Viz. 4.67 8 Easier to Use 4.56 4.00
3 Token Labels Tab 4.56 9 Recommend to Others 4.78 4.00
4 Solver Tab 4.78
5 Sequence Pattern 4.56
6 Expr. Pattern 4.67
Questions 1-6 asked users to rate each listed experimental
feature of Parsimony individually. Only the experimental group
saw these questions. The last three questions were given to
both groups. In order, these questions asked (7) if the tool was
useful overall, (8) if the tool was easier to use than software
they had previously used to construct parsers, and (9) if they
would recommend the tool to others. Answers to questions
1-6 were uniformly positive, indicating agreement that every
feature of Parsimony was valuable. Responses to questions 7-9
show that subjects in the experimental group favored Parsimony
more than those of the control group, across all three metrics.
In summary, the experimental group not only performed better,
but also indicated a higher degree of satisfaction.
Threats to Validity :Subjects were UCSD CS students and
thus may not be representative of programmers in general.
Because the study employed toy languages, subjects‚Äô perfor-
mance may not be indicative of performance on real-world
parsing tasks; to control for this, we designed the languages
to model the syntax of real languages. Our experiments were
single-blind, so there is a risk that subjects were inÔ¨Çuenced byinteraction with the proctor. To minimize this risk, users were
given written, rather than oral instructions for each task.
VI. R ELATED WORK
Parsimony is more expressive and usable than our previous
system, Parsify [ 5], in three ways: (1) Parsimony can synthesize
lexers, which Parsify cannot; (2) by making use of CYK
automata to keep track of many candidate productions simulta-
neously, Parsimony is far less sensitive to the order in which
examples are provided; and (3) whereas Parsify had ad-hoc
support for a single kind of generalization, namely repetition,
Parsimony has a more principled approach to generalization
‚Äì extensible encoding via CYK automata. Finally, whereas
Parsify had not been evaluated on end users, we perform a
thorough evaluation of Parsimony with end users and report
detailed statistics on the beneÔ¨Åts of using Parsimony.
The class of algorithms for program synthesis via input/out-
put examples is broadly termed programming-by-example
(PBE) [ 12], [13], [14], [15]. Examples include synthesis of
string transformations [ 16], [17], [18], spreadsheet manip-
ulations [ 19], [20], number transformations [ 21], and data
extraction from unstructured or semi-structured inputs [22].
We mention four program synthesis systems with a visual
component similar to ours. The LAPIS [ 23] and SMARTe-
dit [ 24] systems support repetitive edits by example, but
export no underlying hierarchy. The iXj [ 25] system supports
systematic edits to Java code, but only from single examples.
The STEPS [ 26] system supports region highlighting and
labeling like Parsimony, but toward the narrower aim of
generating text transforms like those performed by short shell
scripts. We distinguish our work from these prior systems by
our broader scope: parsers for context-free languages.
Research on grammatical inference [27], [28] focuses on
the theory of inferring structure from text. We contrast our
work by our practical focus: constructing syntax speciÔ¨Åcations
that not only parse the given text, but that also give rise to
meaningful parse trees comprehensible to a software engineer.
VII. C ONCLUSION
We have presented Parsimony, an IDE for synthesizing lexers
and parsers by example. Parsimony makes use of two novel
graph data structures, the R-DAG and CYK automaton, for
efÔ¨Åciently inferring lexical rules and grammar productions,
respectively. Through a controlled study, we have demonstrated
Parsimony‚Äôs effectiveness at helping users complete parsing
and lexing tasks more quickly and with fewer errors.
824
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1]T. Parr and K. Fisher, ‚ÄúLL(*): The foundation of the ANTLR parser
generator,‚Äù in Proceedings of the 32nd ACM SIGPLAN Conference on
Programming Language Design and Implementation , ser. PLDI ‚Äô11. New
York, NY , USA: ACM, 2011, pp. 425‚Äì436.
[2]B. Ford, ‚ÄúPackrat parsing:: Simple, powerful, lazy, linear time, functional
pearl,‚Äù in Proceedings of the Seventh ACM SIGPLAN International
Conference on Functional Programming , ser. ICFP ‚Äô02. New York, NY ,
USA: ACM, 2002, pp. 36‚Äì47.
[3]T. Parr, S. Harwell, and K. Fisher, ‚ÄúAdaptive LL(*) parsing: The power
of dynamic analysis,‚Äù in Proceedings of the 2014 ACM International
Conference on Object Oriented Programming Systems Languages &
Applications , ser. OOPSLA ‚Äô14. New York, NY , USA: ACM, 2014, pp.
579‚Äì598.
[4]E. Scott and A. Johnstone, ‚ÄúGLL parsing,‚Äù Electronic Notes in Theoretical
Computer Science , vol. 253, no. 7, pp. 177 ‚Äì 189, 2010, proceedings of
the Ninth Workshop on Language Descriptions Tools and Applications
(LDTA 2009).
[5]A. Leung, J. Sarracino, and S. Lerner, ‚ÄúInteractive parser synthesis by
example,‚Äù in Proceedings of the 36th ACM SIGPLAN Conference on
Programming Language Design and Implementation , ser. PLDI ‚Äô15. New
York, NY , USA: ACM, 2015, pp. 565‚Äì574.
[6]D. Angluin, ‚ÄúLearning regular sets from queries and counterexamples,‚Äù
Information and Computation , vol. 75, no. 2, pp. 87 ‚Äì 106, 1987.
[7]D. H. Younger, ‚ÄúRecognition and parsing of context-free languages in
timen3,‚ÄùInformation and Control , vol. 10, no. 2, pp. 189‚Äì208, 1967.
[8] P. Klint and E. Visser, ‚ÄúUsing Ô¨Ålters for the disambiguation of context-
free grammars,‚Äù in Proc. ASMICS Workshop on Parsing Theory , 1994,
pp. 1‚Äì20.
[9]M. Thorup, ‚ÄúDisambiguating grammars by exclusion of sub-parse trees,‚Äù
Acta Informatica , vol. 33, no. 5, pp. 511‚Äì522, 1996.
[10] grammars v4, https://github.com/antlr/grammars-v4, 2016.
[11] D. Grune and C. J. H. Jacobs, Parsing Techniques: A Practical Guide .
Upper Saddle River, NJ, USA: Ellis Horwood, 1990.
[12] A. Cypher, Ed., Watch What I Do ‚Äì Programming by Demonstration .
Cambridge, MA, USA: MIT Press, 1993.
[13] S. Gulwani, ‚ÄúSynthesis from examples: Interaction models and algo-
rithms,‚Äù in Symbolic and Numeric Algorithms for ScientiÔ¨Åc Computing
(SYNASC), 2012 14th International Symposium on , Sept 2012, pp. 8‚Äì14.
[14] H. Lieberman, Your Wish is My Command: Programming by Example .
San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2001.
[15] O. Polozov and S. Gulwani, ‚ÄúFlashMeta: A framework for inductive
program synthesis,‚Äù in Proceedings of the 2015 ACM SIGPLAN Interna-
tional Conference on Object-Oriented Programming, Systems, Languages,
and Applications , ser. OOPSLA 2015. New York, NY , USA: ACM,
2015, pp. 107‚Äì126.
[16] A. Arasu, S. Chaudhuri, and R. Kaushik, ‚ÄúLearning string transformations
from examples,‚Äù Proceedings of the VLDB Endowment , vol. 2, no. 1, pp.
514‚Äì525, Aug. 2009.[17] S. Gulwani, ‚ÄúAutomating string processing in spreadsheets using input-
output examples,‚Äù in Proceedings of the 38th Annual ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages , ser. POPL
‚Äô11. New York, NY , USA: ACM, 2011, pp. 317‚Äì330.
[18] A. K. Menon, O. Tamuz, S. Gulwani, B. Lampson, and A. T. Kalai,
‚ÄúA machine learning framework for programming by example,‚Äù in
Proceedings of the 30th International Conference on International
Conference on Machine Learning - Volume 28 , ser. ICML‚Äô13. JMLR.org,
2013, pp. 187‚Äì195.
[19] D. W. Barowy, S. Gulwani, T. Hart, and B. Zorn, ‚ÄúFlashrelate: Extracting
relational data from semi-structured spreadsheets using examples,‚Äù in
Proceedings of the 36th ACM SIGPLAN Conference on Programming
Language Design and Implementation , ser. PLDI ‚Äô15. New York, NY ,
USA: ACM, 2015, pp. 218‚Äì228.
[20] W. R. Harris and S. Gulwani, ‚ÄúSpreadsheet table transformations from
examples,‚Äù in Proceedings of the 32nd ACM SIGPLAN Conference on
Programming Language Design and Implementation , ser. PLDI ‚Äô11. New
York, NY , USA: ACM, 2011, pp. 317‚Äì328.
[21] R. Singh and S. Gulwani, ‚ÄúSynthesizing number transformations from
input-output examples,‚Äù in Proceedings of the 24th International Confer-
ence on Computer Aided VeriÔ¨Åcation , ser. CA V‚Äô12. Berlin, Heidelberg:
Springer-Verlag, 2012, pp. 634‚Äì651.
[22] V . Le and S. Gulwani, ‚ÄúFlashExtract: A framework for data extraction
by examples,‚Äù in Proceedings of the 35th ACM SIGPLAN Conference
on Programming Language Design and Implementation , ser. PLDI ‚Äô14.
New York, NY , USA: ACM, 2014, pp. 542‚Äì553.
[23] R. C. Miller and B. A. Myers, ‚ÄúLightweight structured text processing,‚Äù
inProceedings of the Annual Conference on USENIX Annual Technical
Conference , ser. ATEC ‚Äô99. Berkeley, CA, USA: USENIX Association,
1999, pp. 10‚Äì10.
[24] T. Lau, S. A. Wolfman, P. Domingos, and D. S. Weld, ‚ÄúProgramming
by demonstration using version space algebra,‚Äù Mach. Learn. , vol. 53,
no. 1-2, pp. 111‚Äì156, Oct. 2003.
[25] M. Boshernitsan, S. L. Graham, and M. A. Hearst, ‚ÄúAligning develop-
ment tools with the way programmers think about code changes,‚Äù in
Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems , ser. CHI ‚Äô07. New York, NY , USA: ACM, 2007, pp. 567‚Äì576.
[26] K. Yessenov, S. Tulsiani, A. Menon, R. C. Miller, S. Gulwani, B. Lamp-
son, and A. Kalai, ‚ÄúA colorful approach to text processing by example,‚Äù
inProceedings of the 26th Annual ACM Symposium on User Interface
Software and Technology , ser. UIST ‚Äô13. New York, NY , USA: ACM,
2013, pp. 495‚Äì504.
[27] C. de la Higuera, ‚ÄúA bibliographical study of grammatical inference,‚Äù
Pattern Recogn. , vol. 38, no. 9, pp. 1332‚Äì1348, Sep. 2005.
[28] E. Vidal, ‚ÄúGrammatical inference: An introductory survey,‚Äù in Grammat-
ical Inference and Applications , ser. Lecture Notes in Computer Science,
R. Carrasco and J. Oncina, Eds. Springer Berlin Heidelberg, 1994, vol.
862, pp. 1‚Äì4.
825
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:03 UTC from IEEE Xplore.  Restrictions apply. 