CRADLE: Cr oss-Backend Va lidation to D etect and
Localize Bugs in De ep Learning Libraries
Hung Viet Pham, Thibaud Lutellier
University of Waterloo, Canada
{hvpham, tlutelli }@uwaterloo.caWeizhen Qi
USTC, China
zkdqwz@mail.ustc.edu.cnLin Tan
Purdue University, USA
lintan@purdue.edu
Abstract â€”Deep learning (DL) systems are widely used in do-
mains including aircraft collision avoidance systems, Alzheimerâ€™s
disease diagnosis, and autonomous driving cars. Despite the
requirement for high reliability, DL systems are difï¬cult to test.
Existing DL testing work focuses on testing the DL models, not
the implementations (e.g., DL software libraries) of the models.
One key challenge of testing DL libraries is the difï¬culty of
knowing the expected output of DL libraries given an input
instance. Fortunately, there are multiple implementations of the
same DL algorithms in different DL libraries.
Thus, we propose CRADLE, a new approach that focuses on
ï¬nding and localizing bugs in DL software libraries. CRADLE (1)
performs cross-implementation inconsistency checking to detect
bugs in DL libraries, and (2) leverages anomaly propagation
tracking and analysis to localize faulty functions in DL libraries
that cause the bugs. We evaluate CRADLE on three libraries
(TensorFlow, CNTK, and Theano), 11 datasets (including Ima-
geNet, MNIST, and KGS Go game), and 30 pre-trained models.
CRADLE detects 12 bugs and 104 unique inconsistencies, and
highlights functions relevant to the causes of inconsistencies for
all 104 unique inconsistencies.
Index T erms â€”deep learning software testing; cross-
implementation testing; bugs detection; software testing;
I. I NTRODUCTION
Deep learning (DL) is widely used in many domains, includ-
ing aircraft collision avoidance systems [1], Alzheimerâ€™s dis-
ease diagnosis [2], autonomous driving cars [3], and romance
storytelling [4], [5]. Bugs in such systems can cause disastrous
consequences, e.g., a software bug in Uberâ€™s self-driving car
DL system has resulted in the death of a pedestrian [6].
Users of DL systems have a diverse range of background,
including people with little technical backgrounds, e.g., singer-
s/songwriters have used DL to compose music [7]. The per-
vasive use of DL systems requires them to be highly reliable.
Unfortunately, DL algorithms are complex to understand
and use. Average users do not know all the details of DL
algorithms. High-level DL Application Programming Inter-
faces (APIs) have been developed to enable users to build DL
systems without knowledge of the inner working of neural
networks. These high-level APIs rely on lower-level libraries
that implement DL algorithms.
Figure 1 presents the structure of typical DL libraries.
Developers write code using high-level library APIs (e.g.,
Keras [8] API). These APIs invoke low-level libraries that
implement speciï¬c DL algorithms. Low-level libraries suchEÄ‹Ä‚ÄˆË‡Ä¡Ã¬Å¸Ã¬Ä¡
[Ä‹Ã¡ÅÃ†ÅÄ‹Ã¬Å–
EÃ†ÅÃ¨Å¹Ã†ÅÃ¬[Ä®Å¹Ë‡Ä¡Ã¬Å¸Ã¬Ä¡
[Ä‹Ã¡ÅÃ†ÅÄ‹Ã¬Å–Â˜Ã¬Ä¨Å–Ä®Å>Ä¡Ä®Å¹ Â˜ÄˆÃ¬Ã†Ä¨Ä®  bÂ˜Y
 Â‡Â ?Â‡ÂYÃ¬ÅÃ†Å–ÂÅ–Ã¬ÅÃ¢Ä®Ã¨Ã¬
HÄ¨ÅÃ¬ÅÄÃ†Ã¢Ã¬
Ã†Ã¢ÄÃ¬Ä¨Ã¨
Fig. 1: Overview of DL libraries.
as TensorFlow (Google) [9], Theano [10], and CNTK (Mi-
crosoft) [11], implement the same algorithms, e.g., convolu-
tional neural network (CNN) and recurrent neural network
(RNN). Low-level libraries use different input formats and
provide different APIs, while a high-level library allows users
to seamlessly switch among different low-level libraries. The
components that invoke low-level libraries are referred to as
the interfaces between the high-level libraries and the low-
level libraries. Each interface and low-level library, referred to
as a backend , provides an implementation of DL algorithms.
The backend trains and tests DL models. A DL model contains
a DL network and parameters (also known as weights ).
Keras [8] is the most popular high-level library for deep
learning [12]. Keras has been used to implement neural
networks in critical domains, including aircraft collision avoid-
ance systems [1], inï¬‚ammatory bowel disease diagnosis [13],
chemical reaction predictions [14], medical imaging [15], [16],
air quality control [17] and computer network security [18].
The backends and the high-level libraries contain bugs,
which are particularly challenging to ï¬nd and ï¬x [19], [20].
One key challenge is that it is difï¬cult for developers to
know the expected output given an input instance. DL back-
ends implement DL models that use complex networks and
mathematical formula. Thus, it is hard for humans to produce
the expected output of a DL backend given an arbitrary
input instance, if possible at all. For example, given an input
image of digit â€˜1â€™ ( ground truth â€˜1â€™), and a digit classiï¬cation
model, the expected output of that model on that image is not
necessarily â€˜1â€™, as it is common for a model to misclassify
due to its limitations (100% classiï¬cation accuracy is rarely
achieved). Existing DL testing work [19], [21]â€“[25] focuses
on generating input instances that make the ground truth and
the model output disagree so that DL users and builders can
improve the model.
10272019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 Â©2019 IEEE
DOI 10.1109/ICSE.2019.00107
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. (a) Input image â€œPetri dishâ€ (b) Top-5 InceptionResNetV2
- return (x-mean)/(C.sqrt (var)+epsilon) *gamma+beta
+ return (x-mean)/ C.sqrt (var +epsilon )*gamma+beta
(c) Bug ï¬x in batch_normalization in the CNTK backend.
Fig. 2: A bug found by CRADLE in the CNTK backend, which
has been ï¬xed after we reported it.
Models must be implemented by backend libraries. If the
backend libraries fail to faithfully implement a model (e.g.,
due to a bug in the backend), the output from the backend
can be wrong even if the model is correct, and vice versa.
An incorrectly-implemented DL backend may cause the afore-
mentioned digit classiï¬cation model to output â€˜9â€™ for the same
image of â€™1â€™, even if the expected output of the DL model is
â€˜7â€™. Alternatively, the DL backend may output â€˜1â€™ accidentally
matching the ground truth. The wrong outputs could mislead
DL users and builders in their debugging and ï¬xing process.
The output masks the implementation bug, which makes it
challenging to be detected.
There has been little attention to testing the correctness of
the modelsâ€™ implementation . Instead many techniques [19],
[21]â€“[25] test the correctness of the models , which assume that
the backend implementation is correct. Both the model and the
backend implementation need to be correct for DL algorithms
to produce a correct output. The critically important task of
testing DL backend implementation is challenging since the
expected output of the backend is hard to obtain as explained.
The multiple implementations (i.e., the DL backends) of
the same functionality (i.e., the same DL algorithm) provide
us a unique opportunity to detect inconsistencies among these
implementations to ï¬nd bugs in DL backend libraries. For
example, if the same CNN modelâ€”which is the same CNN
network with identical weightsâ€”behaves differently when
running on the two CNN implementations (e.g., TensorFlow
and CNTK), one of the CNN implementations is likely to be
incorrect, without knowing the expected output.
Figure 2 shows a bug that causes two backends to be
inconsistent. The input image (Figure 2a) is manually labeled
as a petri dish (the ground truth) in ImageNet (a popular
dataset of manually labeled images) [26]. Figure 2b shows the
classiï¬cation results of this image by the pre-trained model,
InceptionResNetV2 [27], on Keras 2.2.0 with TensorFlow and
CNTK backends respectively. While the model with Tensor-
Flow backend classiï¬es the image as a petri dish correctly
as its ï¬rst choice, the same model with CNTK classiï¬es the
image as an analog clock, with petri dish not in the top-5.Once an inconsistency is detected, a big challenge is to
identify the faulty functions among many functions in the
DL backend libraries. For example, one run that exposes the
inconsistency bug in Figure 2 contains 781 invocations of
backend functions. Following the complex invocation path of
the InceptionResNetV2 model, it is difï¬cult for developers to
tease out that the batch_normalization function is faulty.
To automatically detect and localize such inconsistencies
across DL backends, we propose and implement a novel
approachâ€” CRADLE . Given a DL model and its input data,
CRADLE (1) uses two distance metrics to compare the out-
put of a model on different backends to detect inconsistent
output, and (2) identiï¬es the location of the inconsistency by
tracking the anomaly propagation through the execution graph.
By identifying the spike in the magnitude of the difference
between two backends, CRADLE points out the inconsistent
functions in the backend that introduces the inconsistency,
which should be very useful for developers to debug and
understand the bug.
Including the example in Figure 2, CRADLE identiï¬es
580 images (out of a 5,000 random sample from ImageNet)
that trigger inconsistent classiï¬cations for InceptionResNetV2
model. CRADLE then successfully localizes the faulty func-
tion ( bath_normalization ). After we reported this bug in
the interface, developers have ï¬xed the bug since Keras 2.2.1.
Figure 2c shows the ï¬x. The batch normalization formula
was implemented incorrectly in CNTK backendâ€™s function
batch_normalization : it should take the square root of
(var + epsilon) instead of the square root of var .
To evaluate the effectiveness of CRADLE, we answer the
following research questions:
RQ1: Can CRADLE detect bugs and inconsistencies in deep
learning backends?
RQ2: Can CRADLE localize the source of inconsistencies?
RQ3: What is CRADLEâ€™s detection and localization time?
In this paper, we make the following contributions:
â€¢A new approach to testing DL software by cross-checking
multiple implementations of the same model to detect in-
consistencies and bugs;
â€¢The ï¬rst approach to localizing the faulty function of
a cross-model inconsistency, using anomaly propagation
tracking and analysis; and
â€¢An evaluation of the testing and localization technique on
30 DL models, 11 datasets (including ImageNet, MNIST,
Udacity challenge 2, and KGS Go game), and 15 Keras
versions (including the latest version).
Our results show that CRADLE detects 12 bugs (9 have
been ï¬xed by developers) in DL software that cause incon-
sistencies for 28 out of 30 models, 3 of which are previously
unknown bugs, 2 of which have already been conï¬rmed by
developers (RQ1). CRADLE highlights functions relevant to
the causes of inconsistencies for all 104 unique inconsistencies
(RQ2). CRADLEâ€™s median end-to-end running time is less
than 5 minutes, suggesting that CRADLE is practical (RQ3).
1028
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. [Ä®Ã¢Ã†Ä¡Ä‹ÆˆÃ†ÅÄ‹Ä®Ä¨ÅÄˆÃ†Å–Ã¬
&Ã¬ÅÃ¬Ã¢ÅÄ‹Ä®Ä¨ÅÄˆÃ†Å–Ã¬hÅ£ÅÅÅ£ÅÃ¬Å¾ÅÅÃ†Ã¢ÅÄ®Å
 ÅÃ†Å–ÄˆÃ¬Å–Å£Ä‚Å–
Ä®Ä¨ÅÄˆÃ†Å–Ã¬ÅaÄ®Ã¨Ã¬Ä¡Ä®Å£ÅÅÅ£ÅÃ†Ã¢ÄÃ¬Ä¨Ã¨ÅÃ†Ä‹ÅÅ–
HÄ¨Ã¢Ä®Ä¨Å–Ä‹Å–ÅÃ¬Ä¨Å
Ä§Ä®Ã¨Ã¬Ä¡Å–Â˜ÅÃ†Ä‹Ä¨Ã¬Ã¨Ä§Ä®Ã¨Ã¬Ä¡Å–
Â²Ã†Ä¡Ä‹Ã¨Ã†ÅÄ‹Ä®Ä¨Ã¨Ã†ÅÃ†
EÄ‹Ã¨Ã¨Ã¬Ä¨Å–ÅÃ†ÅÃ¬Å–
Ã¬Å¾ÅÅÃ†Ã¢ÅÄ®ÅEÄ‹Ã¨Ã¨Ã¬Ä¨Å–ÅÃ†ÅÃ¬Å–
HÄ¨Ã¢Ä®Ä¨Å–Ä‹Å–ÅÃ¬Ä¨Ã¢Å¿
Ä¡Ä®Ã¢Ã†Ä¡Ä‹ÆˆÃ¬Å[Ä®Ã¢Ã†Ä¡Ä‹ÆˆÃ†ÅÄ‹Ä®Ä¨
Ä§Ã†ÅÅ–
hÅ£ÅÅÅ£Å
Ã¢Ä®Ä§ÅÃ†ÅÃ†ÅÄ®Å
Fig. 3: Overview of CRADLE. Red boxes indicate CRADLE outputs.
II. B ACKGROUND
AD L network is a structure (i.e., a graph) that contains
nodes or layers that are stacked to perform a speciï¬c task (e.g.,
regression or classiï¬cation). Each layer represents a speciï¬c
low-level transformation (e.g., convolution, pooling, etc.) of
the input data with speciï¬c parameters (e.g., weights ).
Each layer maps to a function invocation that converts
weight and the input data to output. While multiple layers
in a network can have the same type, the operation performed
is generally different because the parameters of these layers
are different. This is analogous to, in a traditional program,
the same methods/functions, deï¬ned in one speciï¬c place in
the source code, are called many times with different input
parameters. Similarly, in a DL network, the same layer type
can be called several times (i.e., in multiple layers) with
different input parameters (i.e., weights). Fed with one input
instance, a model maps to an execution graph of those low-
level functions (i.e., layers).
As a DL network generally consists of more than two layers,
there are many intermediate layers. Each intermediate layer
produces an internal state that is fed to the next layers. We call
such states hidden states because they are internal, to which
normal users have no access.
To obtain the correct weights for each layer, the network
needs to be trained on a training set . We call this phase the
training phase. Once the training phase is over, the weights
(or parameters) of each layer are ï¬xed and do not change, and
the model can be used in the inference phase. A validation set
is a set of input, different from the training set, that is used to
tune a model. In this work, we use it as input to the models
because we know the ground-truth labels of such input.
Apre-trained model is a network that had been trained
(and saved) in prior work. Its network structure and weights
are ï¬xed and do not change. In the context of this paper, a
trained model also refers to a pre-trained model. While the
training phase is often non-deterministic (e.g., the weights of
the network can be initialized randomly), a pre-trained model
is expected to behave deterministically in the inference phase
because the weights of each layer do not change.
III. A PPROACH
In this section, we describe how CRADLE detects and
localizes inconsistencies among multiple backends. Recall that
a backend consists of low-level libraries and the interface to
high-level libraries (e.g., Keras). For example, the TensorFlowbackend contains the TensorFlow library, the interface between
Keras and TensorFlow, and the GPU computation library
Nvidia CUDA invoked by TensorFlow.
A. Overview and Challenges
Figure 3 shows the two phases of CRADLE: the detection
phase and the localization phase. The detection phase takes
pre-trained DL models and their corresponding validation data
as input. We focus only on the inference stage because of the
non-deterministic nature of DL training.
CRADLE runs a pre-trained model using multiple DL back-
ends. Speciï¬cally, the Output extractor feeds the validation
set to the trained model as input and extracts the sets of
output from the model on multiple backends. In general, we
represent the output as a matrix of numbers. If a DL backend
crashes during this extraction stage, the failure is recorded and
later reviewed and reported. Otherwise, the Output comparator
performs pairwise comparisons of the output for each model
evaluated on different backends to detect inconsistencies.
Once an inconsistency is detected, CRADLE performs the
localization phase. Speciï¬cally, the Hidden states extractor
records hidden states of each inconsistent model on different
backends. These hidden states are fed to the Inconsistency
localizer , which produces localization maps where signiï¬cant
spikes in deviations propagating between hidden states on
different backends are highlighted, indicating faulty locations.
To detect and localize cross-backend inconsistencies and
bugs effectively, we need to address two main challenges:
1. How to determine if a modelâ€™s outputs with two
backends are inconsistent? Since different backends optimize
the computational process differently, the results of the same
calculation are almost always slightly different [28]. A naive
approach that expects the output to be identical will detect
inconsistencies for practically all models on all backends,
which will not be useful for identifying bugs in DL systems.
As shown by our experiment, Theano and CNTK backends
always output slightly different values (the differences vary
from 10âˆ’5to less than 10âˆ’10).
It is difï¬cult to know how big of a difference indicates a
bug-revealing inconsistency, due to the diversity of models,
DL tasks, and datasets. It is not possible to have a single
threshold to distinguish between bug-revealing inconsistencies
and uninteresting inconsistencies for all models and datasets.
For example, LeNet1, a model performing a simple image
classiï¬cation task has an average top-1 conï¬dence level of
1029
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. 95%. This means that for this model, a small variation (e.g.,
a change in conï¬dence level from 95% to 80%) is unlikely
to make the label change. On the other hand, Betago is a
model performing a complex task (i.e., playing Go). For this
model, the average top-1 conï¬dence level is only 60%. In
this case, the same output variation (from 60% to 45%) might
change the predicted label. Therefore, different models need
different thresholds. Determining the correct threshold is a
challenging problem as it depends on many parameters (e.g.,
dataset, model structure, training, etc.).
To address this challenge of identifying bug-revealing incon-
sistencies without the need for complex hard-coded heuristics,
we use two distance metrics (refer to later sections for details)
that emphasize the deviation between the output of both
backends and the ground truth. These metrics effectively
differentiate bug-revealing inconsistent runs from consistent
runs and uninteresting inconsistent runs.
For these metrics, we compare the differences of outputs
against the ground-truth instead of comparing individual out-
puts directly to the expected output. Recall that it is difï¬cult
to obtain the expected output as explained in the Introduction.
We cannot directly compare the output of one backend to
the ground truth to detect bugs because when one backend
produces a wrong label it does not necessarily indicate a bug
in the backend, as it is common for DL models to produce
incorrect labels for some inputs (e.g., due to the limitation of
the algorithm/model, not a bug in the implementation).
2. How to precisely localize the source of an inconsistency?
After an inconsistency is detected, the internal source of
the inconsistency is often challenging to localize, due to the
complexity of DL backends. For example, one run that exposes
the inconsistency bug in Figure 2 contains 781 invocations
of backend functions that have complex mathematical con-
nections. We propose a novel localization and visualization
method that localizes faulty functions in the backend library
which introduces inconsistencies by analyzing internal input
and output of these backend functions and localizing the error
spikes that propagate through the execution graph.
B. Detection Phase
In the detection phase, CRADLE identiï¬es pairs of back-
ends that are inconsistent for a speciï¬c model.
Output extractor takes as input a pre-trained model and
its corresponding validation instances. It loads the provided
weights (no training required) and performs classiï¬cation or
regression tasks using the loaded models. It produces the
model output using all backends under test for each input
instance. For example, comparing 5,000 validation instances
and one associated model on 3 different backends will generate
15,000 output vectors. During this phase, CRADLE detects
crashes on speciï¬c backends and we report them to developers.
Output comparator loads previously stored output matrices
and performs pair-wise comparisons for each given validation
instance to detect inconsistencies. These pair-wise compar-
isons are between a speciï¬c pair of backends using a particularmodel, its associated validation data, and a particular Keras
version. The Output comparator then groups inconsistencies
into unique inconsistencies. We use two metrics to compare a
pair of backendsâ€”the Class-based distance for classiï¬cation
and the MAD-based distance for regression.
A straightforward metric to use is top-k accuracy on the
entire validation set. Top-k accuracy calculates the portion of
correct instancesâ€”an instanceâ€™s ground-truth label is within
the top-k predicted labelsâ€”among the total number of in-
stances classiï¬ed. Top-k accuracy could fail to identify certain
inconsistencies. For example, the Dog species classiï¬cation
model, affected by the presented Batch Normalization bug,
induces inconsistency between Tensorï¬‚ow and CNTK. How-
ever, when ran on those backends, the model has identical
top-1 (29.9%) and top-5 (64.4%) accuracies.
To overcome this problem, we calculate the portion of
inconsistent input instances over the validation set. Because of
the way inconsistent input instances are detected, we will not
aggregate inconsistencies in the same way as top-k accuracy
metric. In the following sections, we introduce Class-based
and MAD-based distances as the ways to measure the severity
of inconsistent instances. Once we have the severities of all
validation instances between a pair of backends, we can apply
two thresholds to see if that pair of backends is inconsistent.
Class-based distance is speciï¬c to classiï¬cation models. It
calculates the distance between two classiï¬cations based on
the relative distances of the ground-truth label ranks in the
output matrices. Here, we leverage the mapping between the
syntax of the model output (the output vector) and its semantic
meaning (the classiï¬cation). Without this mapping, it would
be difï¬cult to come up with a universal metric and threshold
that could work across different model conï¬gurations (e.g.,
the output vector size of a classiï¬er can vary from 1000 for
ImageNet models to 1 for binary classiï¬ers).
A classiï¬cation model with Nclasses outputs a vector of
sizeNcontaining conï¬dence level picorresponding to class
Ci, where 0<iâ‰¤N. Conï¬dence level pishows how
conï¬dent the model is in predicting class Cias the correct
label for that input instance. Given an output vector of a
classiï¬cation model as Yand the ground-truth label Cof the
input, we calculate the score of classiï¬cation ÏƒC,Y as:
ÏƒC,Y=/braceleftBigg
2kâˆ’rank C,Y ifrank C,Yâ‰¤k
0 otherwise(1)
rank C,Y is the rank of the ground-truth label Cin the
classiï¬cation Y. For example rank C,Y=1 ifCis predicted
as top-1 in classiï¬cation Y. The score ÏƒC,Y emphasizes on
classiï¬cations that predict ground-truth label with higher rank.
We consider rank C,Y out of top-k not interesting.
Given the conï¬dence level output of the same model
on a different backend as Y/prime, the Class-based distance
DCLASS C,Y,Y/primeis calculated as the absolute difference be-
tween two scores ÏƒC,Y andÏƒC,Y/prime:
DCLASS C,Y,Y/prime=|ÏƒC,Yâˆ’ÏƒC,Y/prime| (2)
1030
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. TABLE I: Example of inconsistencies found using the Class-
based metric. TF is TensorFlow and CN is CNTK.
Inconsistency pattern
Id Keras Backends Model 16 15-8 7-4 3-2 1 0
1 2.2.2 TF-CN Xception 10 202 147 100 85 4456
2 2.2.2 TF-CN NASNetLarge 5 132 86 77 65 4635
3 2.2.1 TF-CN Xception 10 202 147 100 85 4456
4 2.2.1 TF-CN NASNetLarge 5 132 86 77 65 4635
We deï¬ne our Class-based metric based on the top-k rank-
ings with k=5 . For example, in Figure 2, Ïƒpetridish,Y TF=
25âˆ’1=16as the rank of petri dish label by the TensorFlow
backendrank petridish,Y TFis 1. Similarly, Ïƒpetridish,Y CN=0
because petri dish is not in CNTKâ€™s top-5 for that image.
Then the Class-based distance D CLASS petridish,Y TF,YCN is
16. If another backend generates the ground-truth label in rank
3, then its Ïƒpetridish,Y is 4, and D CLASS petridish,Y TF,Yis
12. The maximum value of D CLASS C,Y,Y/primeis 16, and the
minimum is 0 with k=5 .
Mean absolute deviation (MAD)-based distance is a metric
that could be used for both classiï¬cation and regression mod-
els. However, the main purpose of the MAD-based distance
is detecting inconsistencies in regression models where our
Class-based distance would not work.
Given two predicted vectors YandY/primeof sizeNfor a
pair of backends using a model and an input instance, we
ï¬rst calculate the Mean Absolute Distance (MAD), Î´Y,O and
Î´Y/prime,O, between the two output vectors and the ground-truth
vectorO.Î´Y,O is calculated as followed:
Î´Y,O=1
N/summationdisplay N
i=1|Yiâˆ’Oi| (3)
The MAD-based distance D MAD O,Y,Y/primeis calculated as:
DMAD O,Y,Y/prime=|Î´Y,Oâˆ’Î´Y/prime,O|
Î´Y,O+Î´Y/prime,O(4)
MAD is used here (instead of the more common Euclidean
distance) because it does not inï¬‚ate due to outliers.
For example, Dave-2 [29] is a model that outputs the
steering angle (measured in radian) of a car given a dashboard
camera image as input. For a given input image I, the recorded
(ground-truth) steering angle is O=0.0. Using the same
image as input, Dave-2 outputs Y=0.4andY/prime=âˆ’0.1using
two different backends. We have Î´Y,O=|0.4âˆ’0.0|=0.4
andÎ´Y,O =|âˆ’0.1âˆ’0.0|=0.1. We can then calculate
DMAD O,Y,Y/primeas|0.4âˆ’0.1|/(0.4+0.1) = 0.6. MAD-based
metric produces values between 0 and 1.
Before we can use this metric with classiï¬cation models, we
ï¬rst need to convert the ground-truth labels to one-hot vectors.
In multi-class classiï¬cation, a one-hot vector is a vector of all
zero except the value at the ground-truth label index is 1. This
vector indicates a perfect classiï¬cation with 100% conï¬dence
in the ground-truth label.
Identifying Inconsistencies: Given a model (and its valida-
tion set), two backends, and one version of Keras, we consider
this pair of backends inconsistent if at least p%of validation
input instances cause the distance between those two sets of
output to be larger than a given threshold T(TCdenotes thethreshold for the Class-based metric and TMfor MAD-based
metric). We call such input instances inconsistency-triggering .
For Class-based metric with k=5 , using threshold TC=
16is the most strict. This means that an input instance is
considered inconsistency-triggering if one backend ranks the
ground-truth label top-1, while the other ranks it outside of the
top-5. Using threshold TC=1 means that an input instance is
inconsistency-triggering if there is any difference in the top-5
labels of the two backends and the ground-truth label is in the
top-5 of at least one backend (e.g., if one backend ranks the
ground truth label in the top-5, while the other backend ranks
it outside of the top-5). In Figure 2, the petri dish image is an
inconsistency-triggering input instance.
Similarly, for MAD-based metric, using TM=1 is the most
strict. For example, with the Dave-2 model, an input image is
inconsistency-triggering withTM=1 if it causes one backend
to predict an angle matching the recorded angle exactly, while
causing the other to predict a different angle. On the other
hand, using TM=0 means that we consider any input image
inconsistency-triggering.
The stricter the thresholds are the fewer inconsistencies are
detected, however, the detected inconsistencies will be more
severe (higher TCorTMmeans each inconsistency-triggering
instance is more severe, while higher pmeans more output
instances are inconsistent). If covering all inconsistencies is
the priority, lower and more relaxed thresholds should be used
(e.g., the recommended thresholds in Section IV). However,
if ï¬nding severe bugs that signiï¬cantly affect modelsâ€™ accu-
racies is the priority, then stricter settings would ensure that
those severe bugs will be found and ï¬xed quicker with less
inspection effort.
Identifying Unique Inconsistencies: Table I shows four ex-
amples of inconsistencies. These inconsistencies are identiï¬ed
using the Class-based metric. Column â€˜7â€“4â€™ is the number
of validation input instances that cause the two backends to
have Class-based distances of 7, 6, 5, or 4. Inconsistency in
row one (inconsistency 1) indicates that the model Xception is
inconsistent between TensorFlow and CNTK (Keras 2.2.2) on
its associated ImageNet validation set where 10 input instances
trigger a Class-based distance of 16, 202 instances trigger
distances in the range of 15â€“8, etc.
The same inconsistencies may exist in different Keras
versions (different interface versions in the backend). To
avoid ï¬nding duplicate inconsistencies, the output comparator
also automatically groups certain inconsistencies together into
unique inconsistencies based on inconsistency patterns.
Aninconsistency pattern is the distribution of the distances
over the entire validation data. It expresses the characteristics
of the inconsistencies. Table I shows two unique inconsistency
patterns: pattern 1 (for inconsistencies 1 and 3) and pattern 2
(for inconsistencies 2 and 4).
Since the range of MAD-based metric is between 0 and 1,
we choose 5 equal sized bins between 0 and 1 to calculate
the inconsistency patterns. Similar to Class-based metric, the
number in bin 0.6-0.8 is the number of input instances that
1031
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. trigger the MAD-based distance 0.6â‰¤DMAD<0.8for
each pairwise comparison.
C. Localization Phase:
Given each unique inconsistency, the Hidden states ex-
tractor and the Inconsistency localizer produce a localization
map. A localization map is an execution deviation graph of
two implementations (backends), which highlights inconsistent
executions (hidden states) of a function (layer type), pointing
to potential faulty functions in one of the backends.
Recall that an execution of a model produces one execution
graph (Section II). Each execution graph contains connected
layers, where the output of one layer is the input of subsequent
layers. Given a model and an input instance, there is one
execution graph for each implementation of libraries. An
execution deviation graph is a graph that represents the differ-
ences between two execution graphs of the same model. Since
both execution graphs are from executions of the same model,
they have the same structure i.e., the network structure. Thus,
the execution deviation graph also has that same structure
but contains the deviation between each pair of layer type
executions. We describe the deviation calculation below.
For each unique inconsistency, we only perform localization
on the most inconsistent input instance. The most inconsis-
tent input instance triggers the largest Class-based distance
(classiï¬cation tasks) or MAD-based distance (regression tasks)
between the output of two backends.
Hidden states extractor produces execution graphs in a
similar way to the Output extractor described previously. Both
execute the model on validation input instances to extract
output. However, the latter also retrieves the intermediate
function output (hidden state) of each hidden layer (internal
execution) in the model. Hidden states are presented as vectors
of ï¬‚oating point numbers.
Inconsistency localizer produces a localization map for each
unique inconsistency by ï¬rst extracting the execution deviation
graphs. It does this by calculating the mean absolute deviation
(MAD) between each pair of corresponding hidden state
from two executions of the same layer type on two different
backends. It is important not to confuse the usages of MAD
here to the MAD-based metrics mentioned previously. Here,
MAD is used to calculate the distances between corresponding
intermediate outputs of hidden layers to represent the internal
deviations of two execution graphs. Given the intermediate
statesSLandS/primeLof layerLexecuted on two backends, the
deviation is calculated using Equation 3 as Î´SL,S/primeL.
Due to the sequential nature of a model, a noticeable MAD
deviation at a particular layer does not indicate inconsistency
at that layer as deviation can propagate through the execution
graph and get ampliï¬ed along the way. Ideally, we want to
localize the source of the inconsistency. To do this, the Incon-
sistency localizer calculates the rate of change in deviation
between consecutive function executions. Finally, it generates
the localization maps by highlighting functions in the execu-
tion deviation graph that have inconsistent executions.To calculate the rate of change, we ï¬rst need to calculate
the MAD deviation for all executions (layers output) in the
setpre(L)asÎ´Sl,S/primelwithlâˆˆpre(L)(pre(L)is the set of in-
bound layers which hidden states are the input to layer L). We
calculate the representative deviation of inbound executions,
Î´pre, simply as the maximum deviation:
Î´pre=m a x
lâˆˆpre(L)(Î´Sl,S/primel) (5)
The rate of change in deviations at layer Lis:
RL=Î´SL,S/primeLâˆ’Î´pre
Î´pre+/epsilon1(6)
We use a smoothing constant /epsilon1=1 0âˆ’7to prevent RL=âˆ
in the case where Î´pre=0 (e.g.,Lis the ï¬rst layer).
We callRLthe inconsistency introduction rate of a layer
L, i.e., how much diversion layer L(executions of a pair
of function implementations) introduces due to inconsistent
implementations. RLvalues of all layers provide an overall
picture of how the inconsistency is introduced through the
model so that we can localize the function that is the source of
the inconsistency. To generate the localization map, we overlay
the MAD and RLvalues for each layer on the model structure
graph (e.g., maps in Figure 4). A node, representing a layer L,
shows the layer type (i.e., low-level transformation function),
the MAD value Î´, and the inconsistency introduction rate RL.
We select the third quantile of RLdistribution of all nodes in
each map as the highlighting threshold. We highlight a node
red if its RLis higher than this threshold.
IV . D A TASETS AND EXPERIMENTAL SETTINGS
Trained Models and Datasets: To evaluate CRADLE, we
collect 11 public datasets and 30 DL models that are pre-
trained from these datasets. Table II lists the datasets.
We collected the models by looking for pre-trained models
compatible with Keras from prior work and GitHub. To avoid
low-quality models (e.g., class projects and simple demos),
we only examine repositories with at least two stars. Overall,
we collected 13 ImageNet [26] models (Xception, VGG16-19,
ResNet50, InceptionV3, InceptionResNetV2, MobileNetV1-
V2, DenseNet121-169-201, NASNetLarge-Mobile [8]), 3 self-
driving models used in previous work (DaveOrig-Norminit-
Dropout [19], [29]), 3 MNIST models (LeNet1-4-5 [30]), and
various models trained for other tasks (Thai number detector
â€“ ThaiMnist [31], Go game player â€“ Betago [32], anime
faces recognition â€“ AnimeFaces [33], cat and dog classiï¬ers â€“
CatDog(Basic, Augmented) [34], [35], dog species classiï¬er â€“
Dog [36], gender detection â€“ Gender [37], Pokemon classiï¬er
â€“ Pokedex [38], and GTSRB trafï¬c sign recognition â€“ Trafï¬c-
Signs(1, 2, 3) [39]â€“[41]). We use provided validation dataset
for each model to run our experiment. For ImageNet, we use
a random sample of 5,000 images from over 80,000 provided
cropped validation images.
Experimental settings: We run CRADLE on 15 versions
of Keras (2.0.5â€“2.2.2). For the low-level libraries, we use
the latest versions of CNTK (2.5.1), Theano (1.0.1), and
1032
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. %DWFK1RUP
áƒ¥áƒ¥ 
5 &RQY'
áƒ¥ 
5 $FWLYDWLRQ
áƒ¥
5 
&RQY'
áƒ¥ 
5 *OR$YJ3RRO
áƒ¥ 
5 
OD\HUV
RPLWWHG$FWLYDWLRQ
áƒ¥ 
5 'HQVH
áƒ¥ 
5 
7HQVRU)ORZ MHDQ
&17.PDLOEDJ
,QSXW MHDQ&RQY'
áƒ¥ 
5 
%DWFK1RUP
áƒ¥ 
5 
Fig. 4: Batch normalization bugâ€™s localization map for InceptionResNetV2 between TensorFlow and CNTK with Keras 2.2.0.
TABLE II: Number of inconsistencies found by CRADLE.
The numbers outside and (inside) brackets are the unique and(total) number of inconsistencies respectively. TF is Tensor-Flow, TH is Theano, and CN is CNTK.
Dataset Instances# of Inconsistencies
TH-TF TF-CN CN-TH
ImageNet 5,000 10(34) 21(54) 18(46)
Driving 5,614 3(9) 3(12)
MNIST 10,000 3(9) 3(12)
Thai MNIST 1,665 1(3) 1(4)
KGS Go game 12,288 2(14) 3(12) 3(15)
Anime Faces 14,490 1(5) 1(6)
Dogs VS Cats 832 2(6) 2(8)
Dog species 835 3(8) 3(9)
Faces 466 2(14) 3(8) 6(15)
Pokedex 1,300 1(14) 1(3) 2(15)
GTSRB sign 12,630 2(14) 2(5) 2(7)
Total18(95) 42(117) 44(149)
104(361)
TensorFlow (1.7.0). For regression models, i.e., Dave variants,
we only use the MAD-based metric because the Class-basedmetric does not apply. For the classiï¬cation models, we useboth Class and MAD-based metrics. Some models are notsupported with older versions of Keras and result in crashes.Since the crash is the expected behavior, we do not consider
them as bugs and exclude those runs from our experiment.
We vary the thresholds (T
C,TM, andp) and found the
optimal setting (covering the most inconsistency without false
positives and false negatives) for Class-based metric are TC=
8andp=0 % and for MAD-based metric are TM=0.2and
p=0 % . We use cross-validation with 80-20% of models to
conï¬rm that the thresholds consistently perform across all 5folds. These are the thresholds we use in RQ1 and RQ2.
Hardware and Infrastructure: We utilize multiple Anaconda
environments to switch between multiple versions of Keras
and different backends. We run all experiments on an Intel
Xeon E5-2695 machine with 128 GB of RAM and two NvidiaTitan XP GPUs. For the performance analysis, we run theoutput extraction step utilizing a single GPU.
V. R
ESULTS
A. RQ1: Can CRADLE detect bugs and inconsistencies indeep learning backends?
CRADLE detects 12 bugs in DL software for 28 out of
30 models that cause 104 unique inconsistencies. The 12
bugs (9 have been ï¬xed) consist of 7 inconsistency bugs (3previously unknown, 2 out of 3 have already been conï¬rmedby developers, e.g., the bug in Figure 2 has been ï¬xed by de-
velopers after we reported it), and 5 crash bugs that crash either
Keras or one of the backend libraries. None of the 12 bugsTensorFlow: groom
Theano: Indian elephant
TensorFlow: banana
CNTK: tennis ball
TensorFlow: hen
CNTK: Arabian camel
Fig. 5: Inconsistency-triggering inputs for the pooling bug (leftcolumn), the padding bug (middle column), and the batchnormalization bug (right column). Correct backends are bold.
is detected by the test cases that come with Keras (including
the interface), which does simple unit and integration testing.The results demonstrate that cross-backend inconsistencies are
frequent and CRADLE is effective in detecting them.
Our approach does not report false inconsistencies as it is
a dynamic approach: for each inconsistency, we have inputs
that trigger two backends to disagree. Theoretically speaking,some true inconsistencies may indicate a false bug, as ourapproach may identify uninteresting inconsistencies (e.g., nat-ural computation difference explained in Section III-A). In ourexperiment, all 12 bugs are real (i.e., no false bugs detected).
Inconsistencies and inconsistency-triggering input: Using
the Class-based metric on classiï¬cation tasks and the MAD-
based metric on regression tasks, CRADLE detected a totalof 361 inconsistencies. Based on the inconsistency patterns,
CRADLE automatically groups the inconsistencies into 104
unique inconsistencies (Section III-B).
Table II shows the number of inconsistencies found by
CRADLE for each dataset and pair of backends. For example,CRADLE detects â€˜21(54)â€™ inconsistencies between the twobackends TensorFlow and CNTK triggered by 13 ImageNetmodels. Here â€˜21(54)â€™ indicates that CRADLE detects 54inconsistencies which map to 21 unique inconsistencies cor-responding to 21 unique inconsistency patterns. Table I showstwo of such patterns (the ï¬rst and second rows).
On average, these inconsistencies are triggered by 21.9%
of input instances in a dataset (22.2% for classiï¬cation tasksand 13.9% for regression tasks). Figure 5 provides examples
of inconsistency-triggering inputs. The image of a groom was
identiï¬ed correctly by TensorFlow but incorrectly as an Indianelephant by the faulty Theano. In some extreme cases, thefaulty TensorFlow backend accidentally labels an image of
bananas â€œcorrectlyâ€ while CNTK identiï¬es it as tennis balls.
Inconsistency bugs: We use CRADLE to localize the source
function of all 104 detected unique inconsistencies (detailed
1033
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. TABLE III: Bugs found by CRADLE. â€˜# Inc. bugsâ€™ indicates the number of inconsistency bugs per root inconsistency.
Root inconsistency Localized layers (functions) Affected backends # Affected models # Inc. bugs
Batch normalization BatchNomalization CNTK 11 2
Padding scheme Conv2D, DepthwiseConv2D, SeparatableConv2D TensorFlow, Theano 15 2
Pooling scheme AveragePooling2D Theano 3 1
Parameter organization Trainable convolution CNTK, Theano 18 2
localization results are in Section V-B). We ï¬nd that they
are caused by 7 bugs in the backend libraries (Table III).
Some bugs have the same root inconsistency because they are
either different bugs in the same function or affect several
backends which required multiple ï¬xes to multiple backends.
For example, in addition to the batch normalization bug
we presented earlier, we found another bug in the batch
normalization function affecting an older version of Keras.
We manually check the fault localization maps for each
cluster of inconsistencies and conï¬rm whether it indicates
a bug. If we ï¬nd a corresponding bug ï¬xing commit in a
more recent version, we consider the bug has been ï¬xed by
developers. If not, we consider it previously unknown. Once
two authors agree that it is a bug, we report it to developers.
If the same invocation of functions is identiï¬ed for multiple
bugs that are triggered by the same model in the same pair
of backends across successive Keras versions (which affect
the interface code between Keras and low-level libraries),
we consider them one unique bug. However, if the bugs
are in nonconsecutive versions, and the inconsistency pattern
changes for some versions of Keras, this indicates that the
issue was partially ï¬xed (or a new bug introduced) in some
Keras versions, then we consider them different bugs (e.g., the
new inconsistency is likely to be a regression bug).
In addition to the batch normalization bug in Figure 2, we
detail two additional conï¬rmed bugs that CRADLE found.
Padding scheme bugs: Padding artiï¬cially increases the
size of an input image so that a kernel function can be
applied to all the pixels of the original image and produces
an output of the same shape as the input. The SAME padding
scheme behaves inconsistently across backends when applied
on different combination of odd or even sizes of input and
kernel. This creates a shift in the input that propagates through
the model and caused the model to sometimes completely miss
some of the shapes it was trained to recognize. Eventually,
it results in inconsistencies between Theano or TensorFlow
(depends on the different combination of input and kernel
sizes) and the other two backends. The middle column of
Figure 5 shows an example of input images revealing this
bug. Although it has not been ï¬xed yet in the interface
source code, this bug has been conï¬rmed to be a signiï¬cant
problem because various models (i.e., ResNet50, MobileNet,
NASNetsLarge-Mobile, and MobileNetV2) have been updated
by their developers to include workarounds that makes their
models consistent across backends.
Pooling scheme bug: This bug in Theano backend causes
Gender, InceptionResNetV2, and InceptionV3 models to mis-
behave. In Keras 2.1.4 and earlier, the 2D pooling layer
in Theano interface determined the average pooling scheme
based on the padding scheme. If the padding is SAME ,i t- if padding == â€™sameâ€™:
- th_avg_pool_mode = â€™average_inc_padâ€™
- elif padding == â€™validâ€™:
- th_avg_pool_mode = â€™average_exc_padâ€™
...
- mode=th_avg_pool_mode)
+ mode=â€™average_exc_padâ€™)
Fig. 6: Pooling scheme bug ï¬x in pool2d in Theano backend.
used the pooling average_inc_pad scheme which includes
padding in the average calculation. However, if there is no
padding, then they use the average_exc_pad scheme. This
creates inconsistencies for models that use the AveragePooling
layer with SAME padding. Figure 6 presents the ï¬x where
average_exc_pad is used regardless of the padding scheme.
Crashes bugs: Excluding crashes caused by unsupported
models, we encounter 86 crashes out of 1173 possible runs.
We identiï¬ed 3 Keras bugs (happened with all backends)
and 2 speciï¬c backend bugs. In total, 4 of the crash bugs
have already been ï¬xed and a workaround has been added to
the crashing model to address the last issue. They are often
caused by incorrect objectâ€™s shape (e.g., incorrect weight or
convolution kernel shapes).
Comparison between Class-based metric and top-k accu-
racy: One alternative to our Class-based metric is top-k accu-
racy. To measure its effectiveness in detecting inconsistencies,
we integrate it into CRADLE by calculating the top-k accuracy
differences between pairs of backends. A pair is considered
inconsistent if the accuracy difference is larger than a threshold
TAC. We vary k(1 to 5) and accuracy threshold TAC(between
0% and 50%).
UsingTAC=0 % andk=1 , the accuracy metric detects
the most number of inconsistencies (305) but still misses 35
inconsistencies found by our Class-based metric. These are 35
valuable test cases that developers could use to test, localize,
and ï¬x detected bugs. In addition, our Class-based metric
enables the generation of inconsistency patterns which help
remove duplicates to reduce 340 detected inconsistencies to
98 unique inconsistencies. This reduction is not possible with
top-k accuracy. The results show that our Class-based metric
is more effective than top-k accuracy.
MAD-based metric usage for classiï¬cation models: To
demonstrate the usefulness of our Class-based metric, we
compare the ability of both metrics in detecting unique in-
consistencies for classiï¬cation models.
Using the MAD-based metric for classiï¬cation tasks, CRA-
DLE can only ï¬nd 10 unique inconsistencies, 4 of which are
inconsistent in conï¬dent level but do not trigger inconsistent
classiï¬cations. On the other hand, with the Class-based met-
rics, CRADLE correctly identiï¬es 98 unique inconsistencies
in classiï¬cation models, including all inconsistencies correctly
1034
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. found using the MAD-based metric. These results show that
Class-based metric help CRADLE ï¬nd more inconsistencieswith no false positive.
B. RQ2: Can CRADLE localize the source of inconsistencies?
For each of the 104 unique inconsistencies, CRADLE
generates a localization map for the most inconsistent input
instance (Section III-C). By focusing on the ï¬rst localizedinconsistent execution and executions with high inconsistencyintroduction rates in each map, we manually cluster the 104unique inconsistencies into 7 bugs. CRADLEâ€™s localizationmaps enable us to do this clustering. This manual processtakes 1â€“2 hours per bug. A technique to automatically clusterunique inconsistencies based on the ï¬rst localized functionexecutions or similarity between localization maps remains asfuture work.
Overall, CRADLE highlights executions that are relevant
to the causes of inconsistencies for all 104 unique incon-sistencies. For 4 of the bugs, the ï¬rst localized inconsistentexecutions are exactly the executions of faulty functions thatwere ï¬xed by developers. This suggests that the localizationtechnique is effective in pinpointing the faulty functions, whichshould help developers to understand and ï¬x the bugs. Forexample, the reduction is 13 to 1 in one case, meaning thatthe developers only need to examine one function instead of13 functions with complicated formula and interactions tounderstand and ï¬x the bug. When we consider all (insteadof only the ï¬rst) localized inconsistent executions, the faultymethods are invoked in one of the localized inconsistentexecutions for 5 of the bugs. For the ï¬fth bug, this represents areduction of 22â€“44% for the number of functions to examine.For the remaining 2 bugs, the localized inconsistent executionsare related to the bug ï¬xes. In fact, the localized executionshelped us tremendously in understanding the bugs so that wewere able to write good bug reports.
Figure 4 shows a part of a localization map for the batch
normalization bug (for the unique inconsistency involvingInceptionResNetV2, TensorFlow and CNTK backends, andKeras 2.2.0). The input image shown is the most inconsistentinput instance for this unique inconsistency. The Dense boxshows the output: â€œjeanâ€ from TensorFlow, and â€œmailbagâ€from CNTK, while the ground truth is â€œjeanâ€. The mapincludes 781 invocations of backend functions, for presentationpurposes, 772 of which are omitted. Each box represents aninvocation of a neural network function, the arrows indicate theï¬‚ow of data. Function names are indicated in each box, whileÎ´is the MAD distance between the hidden states (deï¬ned
in Equation 3), and Ris the inconsistency introduction rate
(deï¬ned in Equation 6). In this example, executions of function
batch_normalization are localized as faulty (shown in
red). The white boxes indicate executions with low or negativeR(i.e., they are unlikely the source of inconsistency). This
map correctly highlights the earliest invocation of the function
batch_normalization as the source of inconsistency. We
examine localization maps for the other affected models (e.g.,InceptionV3, DenseNets (121, 169, 201)) and notice that they&RQY'
áƒ¥áƒ¥
5 0D[3RRO
áƒ¥
5 &RQY'
áƒ¥
5 
$YJ3RRO
áƒ¥ 
5 
OD\HUVRPLWWHGOD\HUVRPLWWHG
&RQY'
áƒ¥
5 %DWFK1RUP
áƒ¥
5 
Fig. 7: Pooling scheme bugâ€™s localization map for modelInceptionV3 between TensorFlow and Theano with Keras2.1.4 on the â€œgroomâ€ input image in Figure 5.
all point to the
batch_normalization function. We reported
this bug to developers and it has been ï¬xed in Keras 2.2.1.
Figure 7 shows a section of the localization map highlight-
ing the faulty executions for pooling scheme bug with model
InceptionV3 between TensorFlow and Theano on Keras 2.1.4.The ï¬rst highlighted execution indicate correctly the source ofthis unique inconsistency as the function
average_pooling .
We look at the source code of average_pooling which
points to the faulty pool2d function in the Theano backend.
Figure 6 shows the ï¬x (for Keras 2.1.5) in the Theano backendsource code where the average pooling scheme is set to
average_exc_pad regardless of the padding scheme.
C. RQ3: What is CRADLEâ€™s detection and localization time?
We measure the execution time of CRADLE on the latest
version of Keras (2.2.2) using all 30 models. Overall, CRA-DLEâ€™s detection and localization time is quite reasonable witha typical end-to-end execution time lower than 5 minutes.
The running times of Output extractor and Hidden states
extractor are dominantly the model execution times, which
depends on the model complexity, validation dataset size, andperformance of the backend. The extractor is slow in rarecases, e.g., nearly 10 hours with the large NASNetLarge modelcontaining over 1,000 layers. However, the typical runningtime is within minutes with the median of less than 2 minutes.
The Output comparator and Inconsistency localizer are
much faster with the median running time of less than 20seconds and the maximum of less than 5 minutes. The runningtime is independent of the backend implementation; it dependson the dataset size and the model complexity respectively.
VI. L
IMITA TIONS AND THREA TS TO VALIDITY
Since we focus on detecting bug-revealing inconsistencies,
CRADLE may miss inconsistencies that cause internal errorsbut not failures (i.e., incorrect external behaviors). This is ourdesign choice to avoid detecting too many false alarms.
We assume that the same algorithms are implemented with
similar speciï¬cations in all backends due to the interchange-ability of DL backends. In theory, it is possible for ourtechnique to ï¬nd false positive inconsistencies because of thisassumption. However, our results show that the inconsistenciesfound by our approach indicate real bugs because 11 of themhave already been conï¬rmed or ï¬xed by developers.
1035
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. Our approach might not be generalizable to other models
or DL libraries. To mitigate this threat, we use 30 models
extracted from different GitHub projects and evaluate our
approach on Keras, the most popular high-level DL library
[12], and three popular backends. Our approach of detecting
and localizing inconsistencies should be applicable to other
models and libraries with little work.
It is possible that some complex DL systems contain non-
deterministic layers so that given the same input the output
might be slightly different. To mitigate this issue, we make
sure none of the layers contains intentional sources of ran-
domness and we apply two metrics that are designed to be
robust even in the existence of small inconsistencies.
Our approach uses pre-trained models, which is our design
choice in believing that those pre-trained models that are used
by real users are likely to cause bugs that developers care.
Alternatively, we can use dummy models or mutated models
to test backends in order to ï¬nd more bugs, which remains as
future work.
VII. R ELA TED WORK
To the best our knowledge, we are the ï¬rst to detect and
localize inconsistencies between DL backends.
Testing machine learning (ML) libraries: Recently, au-
tomatic testing of ML libraries becomes active [42]â€“[44].
Srisakaokul et al. [43] detect inconsistencies between multi-
ple implementations of common ML algorithms (i.e., kNN
or Naive Bayes (NB)). This approach uses majority votes
to estimate the expected output. However, it requires many
implementations of the same algorithm (19 kNNs and 7 NBs
used) with the assumption that most of them are correctly
implemented. In contrast, CRADLE performs pairwise com-
parisons, which as shown by our experiments, detects incon-
sistencies without knowing the expected output and works
with a minimum of two implementations. Another major
difference is that Srisakaokul et al. deï¬ne deviation based on
the inconsistency of top-1 classiï¬cations without comparing
them to the ground truth. CRADLE, on the other hand,
deï¬ne inconsistency as deviations in predicted ranks of the
ground-truth label because we want to focus on inconsistent
implementations that affect the performance of DL models
on real world validation dataset. Dwarakanath et al. [42] test
ML libraries by applying transformations on the training and
testing data to detect inconsistencies. However, they were only
able to identify artiï¬cially injected bugs. Dutta et al. [44] used
fuzzing to test probabilistic programming systems. None of
these techniques performs localization.
Benchmarking DL Libraries: Liu et al. [20] observe that
the same DL algorithm with identical conï¬gurations, such
as training set and learning rate, produces different execution
time and accuracy when trained with different low-level DL
libraries. However, this work aims to benchmark DL libraries,
not to detect or localize inconsistency bugs, as it does not
compare the exact same model on different backends. Since
each model is re-trained on each backend and the trainingprocess contains non-determinism (e.g., the seed for the op-
timization function), small accuracy differences are expected.
DL libraries have been compared in the literature [45]â€“[49].
However, the prior work focuses on performance comparison
only and does not detect or localize non-performance bugs in
DL libraries.
Adversarial Testing of DL Models: Much recent work
focuses on testing DL models [19], [21]â€“[25], [50]â€“[55].
Many techniques generate adversarial examples [21]â€“[25].
Some work [50]â€“[52] veriï¬es DL software. DeepXplore [19]
introduces neuron coverage to measure testing coverage in
CNN models. These approaches are orthogonal to our work
as they test the correctness of DL models, while we test
the correctness of the implementations of models in the DL
software libraries.
Differential Testing and Inconsistency Detection: Differen-
tial testing [56] consists of testing whether different compilers
produce the same results. Much work uses differential testing
to ï¬nd bugs in compilers by comparing the output of multiple
compilers [57]â€“[59] or different compiler optimization lev-
els [57], [60]. Inconsistency detection has been used in other
domains such as cross-platform [61], [62], web browsers [63]â€“
[66] or document readers [67]. Our work is a new application
of differential testing and inconsistency detection for DL
software, which has its unique challenges such as identifying
bug-triggering inconsistencies (Section III-A). In addition, we
localize the inconsistencies to the faulty functions.
Debugging and Fault Localization: We are not aware of prior
work that localizes inconsistency bugs in DL libraries, despite
the large volume of debugging and fault localization work for
general software bugs [68]â€“[75]. While these approaches could
be used to debug DL networks, applying such techniques to
localize faulty functions in DL networks may have unique
challenges such as scalability, which remains as future work.
VIII. C ONCLUSION
We propose CRADLE, a new approach to ï¬nd and localize
bugs in the implementations of DL models by cross-checking
multiple backends. We evaluate CRADLE on three backends
and 30 pre-trained models and ï¬nd 12 bugs and 104 unique
inconsistencies in the backends for 28 models. This paper
calls for attention for testing DL implementations not just
DL models. In the future, we plan to design approaches to
identify bugs even if they do not cause observable differences
in backends. It is also conceivable to expand the set of trained
models with mutants for CRADLE to ï¬nd more bugs.
ACKNOWLEDGMENT
The authors thank Carmen Kwan for her contribution in
collecting evaluation models from GitHub, Yitong Li for the
reproduction and validation of experimental results, and the
anonymous reviewers for their invaluable feedback. This work
has been partially supported by the Natural Sciences and
Engineering Research Council of Canada.
1036
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] K. D. Julian, J. Lopez, J. S. Brush, M. P . Owen, and M. J.
Kochenderfer, â€œPolicy Compression for Aircraft Collision Avoidance
Systems,â€ in Digital Avionics Systems Conference (DASC), 2016
IEEE/AIAA 35th . IEEE, 2016, pp. 1â€“10.
[2] S. Liu, S. Liu, W. Cai, S. Pujol, R. Kikinis, and D. Feng, â€œEarly
Diagnosis of Alzheimerâ€™s Disease with Deep Learning,â€ in Biomedical
Imaging (ISBI), 2014 IEEE 11th International Symposium on . IEEE,
2014, pp. 1015â€“1018.
[3] C. Chen, A. Seff, A. Kornhauser, and J. Xiao, â€œDeepdriving: Learning
Affordance for Direct Perception in Autonomous Driving,â€ in
Proceedings of the IEEE International Conference on Computer
Vision , 2015, pp. 2722â€“2730.
[4] R. Kiros, Y . Zhu, R. Salakhutdinov, R. S. Zemel, A. Torralba,
R. Urtasun, and S. Fidler, â€œSkip-Thought V ectors,â€ arXiv preprint
arXiv:1506.06726 , 2015.
[5] J. R. Kiros, â€œRecurrent Neural Network that Generates Little Stories
About Images,â€ https://github.com/ryankiros/neural-storyteller, 2018.
[6] A. Efrati, â€œUber Finds Deadly Accident Likely Caused by Software
Set to Ignore Objects on Road,â€ The information , 2018.
[7] â€œTaryn Southernâ€™s new album is produced entirely by AI,â€
https://www.digitaltrends.com/music/
artiï¬cial-intelligence-taryn-southern-album-interview/, 2018.
[8] F. Chollet et al. , â€œKeras,â€ https://keras.io, 2015.
[9] M. Abadi, P . Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard et al. , â€œTensorFlow: a System for
Large-Scale Machine Learning.â€ in OSDI , vol. 16, 2016, pp. 265â€“283.
[10] J. Bergstra, F. Bastien, O. Breuleux, P . Lamblin, R. Pascanu,
O. Delalleau, G. Desjardins, D. Warde-Farley, I. Goodfellow,
A. Bergeron et al. , â€œTheano: Deep learning on GPUs with Python,â€ in
NIPS 2011, BigLearning Workshop, Granada, Spain , vol. 3. Citeseer,
2011, pp. 1â€“48.
[11] F. Seide and A. Agarwal, â€œCNTK: Microsoftâ€™s Open-Source
Deep-Learning Toolkit,â€ in Proceedings of the 22nd ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining .
ACM, 2016, pp. 2135â€“2135.
[12] â€œThe Data Incubator,â€ https://github.com/thedataincubator/
data-science-blogs/blob/master/output/DL libraries ï¬nal Rankings.csv,
2018.
[13] D. Fioravanti, Y . Giarratano, V . Maggio, C. Agostinelli, M. Chierici,
G. Jurman, and C. Furlanello, â€œPhylogenetic Convolutional Neural
Networks in Metagenomics,â€ BMC bioinformatics , vol. 19, no. 2,
p. 49, 2018.
[14] S. Kwon and S. Y oon, â€œDeepCCI: End-to-End Deep Learning for
Chemical-Chemical Interaction Prediction,â€ in Proceedings of the 8th
ACM International Conference on Bioinformatics, Computational
Biology, and Health Informatics . ACM, 2017, pp. 203â€“212.
[15] K. Chang, N. Balachandar, C. Lam, D. Yi, J. Brown, A. Beers,
B. Rosen, D. L. Rubin, and J. Kalpathy-Cramer, â€œDistributed Deep
Learning Networks Among Institutions for Medical Imaging,â€ Journal
of the American Medical Informatics Association , 2018.
[16] K.-H. Thung, P .-T. Yap, and D. Shen, â€œMulti-Stage Diagnosis of
Alzheimerâ€™s Disease with Incomplete Multimodal Data via Multi-Task
Deep Learning,â€ in Deep Learning in Medical Image Analysis and
Multimodal Learning for Clinical Decision Support . Springer, 2017,
pp. 160â€“168.
[17] B. S. Freeman, G. Taylor, B. Gharabaghi, and J. Th Â´e, â€œForecasting Air
Quality Time Series Using Deep Learning,â€ Journal of the Air &
Waste Management Association , pp. 1â€“21, 2018.
[18] N. N. Diep, â€œIntrusion Detection Using Deep Neural Network,â€
Southeast Asian Journal of Sciences , vol. 5, no. 2, pp. 111â€“125, 2017.
[19] K. Pei, Y . Cao, J. Yang, and S. Jana, â€œDeepxplore: Automated
Whitebox Testing of Deep Learning Systems,â€ in Proceedings of the
26th Symposium on Operating Systems Principles . ACM, 2017, pp.
1â€“18.
[20] L. Liu, Y . Wu, W. Wei, W. Cao, S. Sahin, and Q. Zhang,
â€œBenchmarking Deep Learning Frameworks: Design Considerations,
Metrics and Beyond,â€ in 2018 IEEE 38th International Conference on
Distributed Computing Systems (ICDCS) . IEEE, 2018.
[21] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan,
I. Goodfellow, and R. Fergus, â€œIntriguing Properties of Neural
Networks,â€ arXiv preprint arXiv:1312.6199 , 2013.[22] A. Nguyen, J. Y osinski, and J. Clune, â€œDeep Neural Networks are
Easily Fooled: High Conï¬dence Predictions for Unrecognizable
Images,â€ in Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition , 2015, pp. 427â€“436.
[23] A. Kurakin, I. Goodfellow, and S. Bengio, â€œAdversarial Examples in
the Physical World,â€ arXiv preprint arXiv:1607.02533 , 2016.
[24] N. Papernot, P . McDaniel, A. Swami, and R. Harang, â€œCrafting
Adversarial Input Sequences for Recurrent Neural Networks,â€ in
Military Communications Conference, MILCOM 2016-2016 IEEE .
IEEE, 2016, pp. 49â€“54.
[25] N. Narodytska and S. P . Kasiviswanathan, â€œSimple Black-Box
Adversarial Attacks on Deep Neural Networks,â€ in CVPR Workshops ,
2017, pp. 1310â€“1318.
[26] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,
Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and
L. Fei-Fei, â€œImageNet Large Scale Visual Recognition Challenge,â€
International Journal of Computer Vision (IJCV) , vol. 115, no. 3, pp.
211â€“252, 2015.
[27] C. Szegedy, S. Ioffe, and V . V anhoucke, â€œInception-v4,
Inception-ResNet and the Impact of Residual Connections on
Learning,â€ in AAAI Conference on Artiï¬cial Intelligence , 02 2016.
[28] D. Goldberg, â€œWhat every computer scientist should know about
ï¬‚oating-point arithmetic,â€ ACM Comput. Surv. , vol. 23, no. 1, pp.
5â€“48, Mar. 1991. [Online]. Available:
http://doi.acm.org/10.1145/103162.103163
[29] Z. Chen and X. Huang, â€œEnd-to-End Learning for Lane Keeping of
Self-Driving Cars,â€ in 2017 IEEE Intelligent V ehicles Symposium (IV) ,
June 2017, pp. 1856â€“1860.
[30] Y . Lecun, L. Bottou, Y . Bengio, and P . Haffner, â€œGradient-Based
Learning Applied to Document Recognition,â€ Proceedings of the
IEEE , vol. 86, no. 11, pp. 2278â€“2324, Nov 1998.
[31] â€œThai Handwriting Number,â€
https://kittinan.github.io/thai-handwriting-number/, 2018.
[32] â€œBetaGo: AlphaGo for the Masses,â€
https://github.com/maxpumperla/deep learning and the game ofgo,
2018.
[33] â€œAnime Face Dataset,â€
http://www.nurs.or.jp/ âˆ¼nagadomi/animeface-character-dataset, 2018.
[34] â€œCat vs. Dog Models,â€ https://github.com/rajshah4/image keras, 2017.
[35] â€œDog Model,â€ https://github.com/humayun/dl-dataday-workshop, 2018.
[36] â€œModel Weights File of Dog Project,â€
https://github.com/humayun/dl-dataday-workshop/blob/master/code/
dog project/saved models/weights.best.from scratch.hdf5, 2018.
[37] â€œGender Model,â€ https://github.com/oarriaga/face classiï¬cation/, 2018.
[38] â€œPokedex,â€
https://github.com/Robert-Alonso/Keras-React-Native-Pokedex, 2018.
[39] â€œTrafï¬cSigns1 Model,â€
https://github.com/jaeoh2/CoreML-Trafï¬c-Sign-Classiï¬er, 2018.
[40] â€œTrafï¬cSigns2 Model,â€
https://github.com/inspire-group/advml-trafï¬c-sign, 2018.
[41] â€œTrafï¬cSigns3 Model,â€ https://github.com/MidnightPolaris/gtsdb cnn,
2018.
[42] A. Dwarakanath, M. Ahuja, S. Sikand, R. M. Rao, R. P . J. C. Bose,
N. Dubash, and S. Podder, â€œIdentifying implementation bugs in
machine learning based image classiï¬ers using metamorphic testing,â€
inProceedings of the 27th ACM SIGSOFT International Symposium
on Software Testing and Analysis , ser. ISSTA 2018. New Y ork, NY ,
USA: ACM, 2018, pp. 118â€“128.
[43] S. Srisakaokul, Z. Wu, A. Astorga, O. Alebiosu, and T. Xie,
â€œMultiple-implementation testing of supervised learning software,â€ in
Proc. AAAI-18 Workshop on Engineering Dependable and Secure
Machine Learning Systems (EDSMLS) , 2018.
[44] S. Dutta, O. Legunsen, Z. Huang, and S. Misailovic, â€œTesting
probabilistic programming systems,â€ in Proceedings of the 2018 ACM
Joint Meeting on European Software Engineering Conference and
Symposium on the F oundations of Software Engineering,
ESEC/SIGSOFT FSE 2018, 2018 , 2018, pp. 574â€“586.
[45] C. Coleman, D. Narayanan, D. Kang, T. Zhao, J. Zhang, L. Nardi,
P . Bailis, K. Olukotun, C. R Â´e, and M. Zaharia, â€œDAWNBench: An
End-to-End Deep Learning Benchmark and Competition,â€ Training ,
vol. 100, no. 101, p. 102, 2017.
[46] S. Shi, Q. Wang, P . Xu, and X. Chu, â€œBenchmarking State-of-the-Art
Deep Learning Software Tools,â€ in 2016 7th International Conference
on Cloud Computing and Big Data (CCBD) , Nov 2016, pp. 99â€“104.
1037
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. [47] S. Dutta, B. Manideep, S. Rai, and V . Vijayarajan, â€œA Comparative
Study of Deep Learning Models for Medical Image Classiï¬cation,â€ in
IOP Conference Series: Materials Science and Engineering , vol. 263,
no. 4. IOP Publishing, 2017, p. 042097.
[48] S. Shams, R. Platania, K. Lee, and S.-J. Park, â€œEvaluation of Deep
Learning Frameworks Over Different HPC Architectures,â€ in
Distributed Computing Systems (ICDCS), 2017 IEEE 37th
International Conference on . IEEE, 2017, pp. 1389â€“1396.
[49] A. Shatnawi, G. Al-Bdour, R. Al-Qurran, and M. Al-Ayyoub, â€œA
Comparative Study of Open Source Deep Learning Frameworks,â€ in
Information and Communication Systems (ICICS), 2018 9th
International Conference on . IEEE, 2018, pp. 72â€“77.
[50] M. Wicker, X. Huang, and M. Kwiatkowska, â€œFeature-Guided
Black-Box Safety Testing of Deep Neural Networks,â€ in International
Conference on Tools and Algorithms for the Construction and Analysis
of Systems . Springer, 2018, pp. 408â€“426.
[51] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer,
â€œReluplex: An Efï¬cient SMT Solver for V erifying Deep Neural
Networks,â€ in International Conference on Computer Aided
V eriï¬cation . Springer, 2017, pp. 97â€“117.
[52] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu, â€œSafety
V eriï¬cation of Deep Neural Networks,â€ in International Conference on
Computer Aided V eriï¬cation . Springer, 2017, pp. 3â€“29.
[53] Y . Tian, K. Pei, S. Jana, and B. Ray, â€œDeepTest: Automated Testing of
Deep-neural-network-driven Autonomous Cars,â€ in Proceedings of the
40th International Conference on Software Engineering , ser. ICSE â€™18.
New Y ork, NY , USA: ACM, 2018, pp. 303â€“314. [Online]. Available:
http://doi.acm.org/10.1145/3180155.3180220
[54] L. Ma, F. Juefei-Xu, F. Zhang, J. Sun, M. Xue, B. Li, C. Chen, T. Su,
L. Li, Y . Liu, J. Zhao, and Y . Wang, â€œDeepgauge: Multi-granularity
testing criteria for deep learning systems,â€ in Proceedings of the 33rd
ACM/IEEE International Conference on Automated Software
Engineering , ser. ASE 2018. New Y ork, NY , USA: ACM, 2018, pp.
120â€“131. [Online]. Available:
http://doi.acm.org/10.1145/3238147.3238202
[55] T. Gehr, M. Mirman, D. Drachsler-Cohen, P . Tsankov, S. Chaudhuri,
and M. V echev, â€œAI 2: Safety and Robustness Certiï¬cation of Neural
Networks with Abstract Interpretation,â€ in Security and Privacy (SP),
2018 IEEE Symposium on , 2018.
[56] W. M. McKeeman, â€œDifferential Testing for Software,â€ Digital
Technical Journal , vol. 10, no. 1, pp. 100â€“107, 1998.
[57] X. Yang, Y . Chen, E. Eide, and J. Regehr, â€œFinding and Understanding
Bugs in C Compilers,â€ in ACM SIGPLAN Notices , vol. 46, no. 6.
ACM, 2011, pp. 283â€“294.
[58] T. Y oshikawa, K. Shimura, and T. Ozawa, â€œRandom Program
Generator for Java JIT Compiler Test System,â€ in Quality Software,
2003. Proceedings. Third International Conference on . IEEE, 2003,
pp. 20â€“23.
[59] F. Sheridan, â€œPractical Testing of a C99 Compiler Using Output
Comparison,â€ Software: Practice and Experience , vol. 37, no. 14, pp.
1475â€“1488, 2007.
[60] V . Le, M. Afshari, and Z. Su, â€œCompiler V alidation via Equivalence
Modulo Inputs,â€ in ACM SIGPLAN Notices , vol. 49, no. 6. ACM,
2014, pp. 216â€“226.
[61] M. Fazzini and A. Orso, â€œAutomated Cross-platform Inconsistency
Detection for Mobile Apps,â€ in Proceedings of the 32Nd IEEE/ACM
International Conference on Automated Software Engineering , ser.ASE 2017. Piscataway, NJ, USA: IEEE Press, 2017, pp. 308â€“318.
[Online]. Available: http://dl.acm.org/citation.cfm?id=3155562.3155604
[62] M. E. Joorabchi, M. Ali, and A. Mesbah, â€œDetecting Inconsistencies in
Multi-platform Mobile Apps,â€ in 2015 IEEE 26th International
Symposium on Software Reliability Engineering (ISSRE) , Nov 2015,
pp. 450â€“460.
[63] S. Roy Choudhary, H. V ersee, and A. Orso, â€œWEBDIFF: Automated
Identiï¬cation of Cross-browser Issues in Web Applications,â€ in
Proceedings of the 2010 IEEE International Conference on Software
Maintenance , ser. ICSM â€™10. Washington, DC, USA: IEEE Computer
Society, 2010, pp. 1â€“10. [Online]. Available:
http://dx.doi.org/10.1109/ICSM.2010.5609723
[64] S. R. Choudhary, â€œDetecting Cross-browser Issues in Web
Applications,â€ in Proceedings of the 33rd International Conference on
Software Engineering , ser. ICSE â€™11. New Y ork, NY , USA: ACM,
2011, pp. 1146â€“1148. [Online]. Available:
http://doi.acm.org/10.1145/1985793.1986024
[65] S. Roy Choudhary, M. R. Prasad, and A. Orso, â€œCrossCheck:
Combining Crawling and Differencing to Better Detect Cross-browser
Incompatibilities in Web Applications,â€ in Proceedings - IEEE 5th
International Conference on Software Testing, V eriï¬cation and
V alidation, ICST 2012 , 04 2012, pp. 171â€“180.
[66] S. Roy Choudhary, M. R. Prasad, and A. Orso, â€œX-PERT: a Web
Application Testing Tool for Cross-Browser Inconsistency Detection,â€
inProceedings of the 2014 International Symposium on Software
Testing and Analysis . ACM, 2014, pp. 417â€“420.
[67] T. Kuchta, T. Lutellier, E. Wong, L. Tan, and C. Cadar, â€œOn the
Correctness of Electronic Documents: Studying, Finding, and
Localizing Inconsistency Bugs in PDF Readers and Files,â€ Empirical
Software Engineering , pp. 1â€“34, 2018.
[68] S. Pearson, J. Campos, R. Just, G. Fraser, R. Abreu, M. D. Ernst,
D. Pang, and B. Keller, â€œEvaluating and Improving Fault
Localization,â€ in Proceedings of the 39th International Conference on
Software Engineering . IEEE Press, 2017, pp. 609â€“620.
[69] J. A. Jones and M. J. Harrold, â€œEmpirical Evaluation of the Tarantula
Automatic Fault-Localization Technique,â€ in Proceedings of the 20th
IEEE/ACM international Conference on Automated software
engineering . ACM, 2005, pp. 273â€“282.
[70] L. Naish, H. J. Lee, and K. Ramamohanarao, â€œA Model for
Spectra-based Software Diagnosis,â€ ACM Transactions on software
engineering and methodology (TOSEM) , vol. 20, no. 3, p. 11, 2011.
[71] S. Moon, Y . Kim, M. Kim, and S. Y oo, â€œAsk the Mutants: Mutating
Faulty Programs for Fault Localization,â€ in 2014 IEEE Seventh
International Conference on Software Testing, V eriï¬cation and
V alidation (ICST) . IEEE, 2014, pp. 153â€“162.
[72] M. Papadakis and Y . Le Traon, â€œMetallaxis-FL: Mutation-based Fault
Localization,â€ Software Testing, V eriï¬cation and Reliability , vol. 25,
no. 5-7, pp. 605â€“628, 2015.
[73] A. Zeller and R. Hildebrandt, â€œSimplifying and Isolating
Failure-Inducing Input,â€ IEEE Transactions on Software Engineering ,
vol. 28, no. 2, pp. 183â€“200, 2002.
[74] G. Misherghi and Z. Su, â€œHDD: Hierarchical Delta Debugging,â€ in
Proceedings of the 28th international conference on Software
engineering . ACM, 2006, pp. 142â€“151.
[75] R. Hodov Â´an and Â´A. Kiss, â€œModernizing Hierarchical Delta
Debugging,â€ in Proceedings of the 7th International Workshop on
Automating Test Case Design, Selection, and Evaluation . ACM,
2016, pp. 31â€“37.
1038
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:53 UTC from IEEE Xplore.  Restrictions apply. 