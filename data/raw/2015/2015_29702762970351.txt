Optimizing Customized Program Coverage
Peter Ohmann
ohmann@cs.wisc.eduDavid Bingham Brown
bingham@cs.wisc.edu
Naveen Neelakandan
neelakandan@cs.wisc.eduJeff Linderoth
linderoth@wisc.eduBen Liblit
liblit@cs.wisc.edu
University of Wisconsin‚ÄìMadison
Madison, WI, USA
ABSTRACT
Program coverage is used across many stages of software develop-
ment. While common during testing, program coverage has also
found use outside the test lab, in production software. However,
production software has stricter requirements on run-time overheads,
and may limit possible program instrumentation. Thus, optimizing
the placement of probes to gather program coverage is important.
We introduce and study the problem of customized program cov-
erage optimization. We generalize previous work that optimizes for
complete coverage instrumentation with a system that adapts opti-
mization to customizable program coverage requirements. SpeciÔ¨Å-
cally, our system allows a user to specify desired coverage locations
and to limit legal instrumentation locations. We prove that the prob-
lem of determining optimal coverage probes is NP-hard, and we
present a solution based on mixed integer linear programming. Due
to the computational complexity of the problem, we also provide
two practical approximation approaches. We evaluate the e ective-
ness of our approximations across a diverse set of benchmarks, and
show that our techniques can substantially reduce instrumentation
while allowing the user immense freedom in deÔ¨Åning coverage re-
quirements. When na√Øve instrumentation is dense or expensive, our
optimizations succeed in lowering execution time overheads.
CCS Concepts
¬àSoftware and its engineering !Software testing and debug-
ging; Software post-development issues; Software performance;
¬àMathematics of computing !Integer programming;
Keywords
Debugging, mixed integer linear optimization, program coverage
1. INTRODUCTION
Program coverage data identiÔ¨Åes which program features exe-
cuted during one or more runs of a program. Program coverage
is commonly used as a quality metric for test suites; developers
wish to ensure that a test suite exercises an adequate portion of their
code-base. However, developers also use program coverage in othercontexts, such as postmortem program analysis [ 28,29] and fault lo-
calization [ 22,36]. Many granularities of coverage are possible. For
example, statement coverage identiÔ¨Åes the set of statements that exe-
cuted during a run. Coarser granularities, such as function coverage,
gather coverage data for a smaller set of program points, providing
less detailed information, but with lower run-time overhead. Finer
granularities, such as path coverage, make the opposite trade: higher
run-time overhead for more detailed execution information. This
paper targets uses of program coverage in low-overhead monitoring
of deployed applications. SpeciÔ¨Åcally, we optimize instrumenta-
tion for binarized control-Ô¨Çow coverage metrics (i.e., coverage data
marks each program location as ‚Äúcovered‚Äù or ‚Äúuncovered,‚Äù rather
than counting the number of occurrences). We focus on statement
and edge coverage, which prior work has shown to be useful in
postmortem debugging [ 29] and amenable to residual monitoring
[32,34]. That is, we reduce the instrumentation required to track
which program points were covered for a particular execution 1.
In many scenarios, one may not require‚Äîor cannot a ord to
gather‚Äîfull coverage information for a program run. This is espe-
cially true after deployment: deployed software is already partially
tested, and only tolerates small run-time overheads. Sparse tracing
also means sending less data back to developers in Ô¨Åeld reports.
Further, developers often do not require full information from these
reports. For example, developers may focus on code features (e.g.,
call sites [ 28,29]) likely to be useful for debugging or program
analysis. Alternately, they may desire coverage only for newly
added code, or code not adequately tested before release [ 32,34].
Conversely, security-sensitive code, tightly optimized code, or code
with strict real-time requirements may be o -limits for monitoring.
Optimization for gathering program coverage is well-studied (see
Section 5). Agrawal [ 1] and Tikir and Hollingsworth [ 37] optimize
probe placement for binarized statement coverage. Unfortunately,
Agrawal‚Äôs approach is not applicable for incomplete executions,
such as those that terminate unexpectedly due to a fatal signal.
Support for aborted runs is important if post-deployment failure data
is to include coverage information [ 29]. However, low-cost coverage
tracing is especially important in these deployed scenarios, as only
small amounts of run-time overhead are tolerable. Further, neither
Agrawal nor Tikir and Hollingsworth optimizes for incomplete or
constrained coverage requirements. Deployed software calls for
customized coverage information: coverage at a subset of program
locations, such as those not exercised by a test suite [ 34] or those
containing features interesting for debugging [28, 29].
In this paper we present three approaches that select a smaller
set of coverage probes given instrumentation restrictions and a set
of program points of interest. We prove that the resulting problem
1Source code is available as part of the CSI instrumentation frame-
work at http: //pages.cs.wisc.edu /~liblit /ase-2016-b /code/.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ASE‚Äô16 , September 3‚Äì7, 2016, Singapore, Singapore
c2016 ACM. 978-1-4503-3845-5/16/09...$15.00
http://dx.doi.org/10.1145/2970276.2970351
27
is NP-hard, so the existence of a fast algorithm for computing the
optimal set of probes is unlikely. Our Ô¨Årst approach constructs a
mixed integer linear program (MILP) whose solution identiÔ¨Åes the
optimal probe set; however, solving this MILP to optimality requires
prohibitive analysis time during instrumentation. We therefore o er
two approximation approaches. The Ô¨Årst approximation is very
inexpensive to compute, but provides no optimality guarantees;
the second Ô¨Ånds a locally optimal approximation. The primary
contributions of this work are as follows:
We deÔ¨Åne the Customized Coverage Probing Problem and
formalize the notion of a coverage set for customized coverage
criteria. We argue the problem‚Äôs signiÔ¨Åcance and applicability
to common problems in monitoring deployed applications.
We prove that the Customized Coverage Probing Problem is
NP-hard via a reduction from work by Maheshwari [23].
We present three approaches to tackle this problem: an opti-
mal solution implemented as a MILP, and two approximations
with varying degrees of optimality and computation cost.
We perform an extensive evaluation of our approaches. In
agreement with prior work on full-coverage optimization
[1,27,37], we Ô¨Ånd that even coarse approximations can stati-
cally eliminate much instrumentation. When na√Øve instrumen-
tation imposes large overhead, our optimizations signiÔ¨Åcantly
reduce both compilation and run-time costs.
This paper is organized as follows. Section 2 formally deÔ¨Ånes the
Customized Coverage Probing Problem, and argues for its applica-
bility to common problems using program coverage for deployed
applications. Section 3 describes our three approaches, which we
then evaluate in Section 4. Section 5 positions our work in the
context of prior research. Section 6 concludes.
2. CUSTOMIZED COVERAGE
Our goal is to determine an optimal instrumentation plan to gather
customized, binarized program coverage information. More con-
cretely, we are given a single procedure‚Äôs control-Ô¨Çow graph (CFG),
G; some subset of the vertices in Gfor which the developer desires
information, D; and another subset of the vertices in GdeÔ¨Åning
legal observation points, I. The problem is to determine the cheapest
set of probes to insert into locations from Isuch that, for any given
path pthrough G, the set of probes encountered along pis sucient
to determine which vertices from Dwere traversed along p.
2.1 Input
The input to the problem is as follows:
G=(V;E), a directed graph with vertices Vand edges E
e2V, a unique source (or entry) vertex with in-degree 0
IV, a subset of vertices that may be probed (instrumented)
ci, the cost of probing vertex i2I, where8i2I;ci>0
DV, a set of ‚Äúdesired‚Äù vertices that must be ‚Äúcovered‚Äù
XV, a set of possible termination points
2.2 Problem DeÔ¨Ånition
DeÔ¨Ånition 1 Forv1;v22V,v1!v2denotes the set of all paths
from v1tov2inG. Ifv1=v2, then the trivial path (crossing no
edges) is included in this set.
DeÔ¨Ånition 2 V(p)denotes the set of all vertices encountered along
path p, including the start and end vertices of p. Ifpis the trivial
path from vertex v(crossing no edges), then V(p)is the singleton
setfvg.e
1
2
3
4 5
6
7
(a) Original control-Ô¨Çow graphe
q
1
2
3
4 5
6
7
(b) Multiple function executions
Figure 1: Example control-Ô¨Çow graph with transformation for
multiple function executions
DeÔ¨Ånition 3 A set of vertices SIis called a coverage set ofD
if8x2Xand8p1;p22e!x,V(p1)\S=V(p2)\S=)
V(p1)\D=V(p2)\D. That is, two executions ending at the same
termination point x2Xthat encounter the same Svertices must
encounter the same Dvertices as well. Contrapositively, paths that
encounter di erent Dvertices must be distinguishable by encoun-
tering di erent S vertices as well.
Problem Statement:
TheCustomized Coverage Probing Problem is to Ô¨Ånd a cover-
age set SofDsuch thatP
s2Scsis minimal.
2.3 Discussion
We desire the lowest-cost coverage set of D. Put another way, the
goal is to Ô¨Ånd the cheapest set of probe vertices ( SI) such that
the resulting observations ( V(p1)\SandV(p2)\S) are su cient
to derive desired coverage information ( V(p1)\DandV(p2)\D)
for all executions, whether terminating normally or abnormally
(8x2X). IfDI, then a coverage set of Dexists, since we can set
S=D. However, the existence of some Sthat satisÔ¨Åes DeÔ¨Ånition 3
does not imply that DI. That is, we may be able to infer coverage
information for d2Dwithout probing ddirectly.
The cost of probing each vertex ( ci) is input to the problem.
To minimize the expected run-time cost of instrumentation, these
values should represent the expected execution frequency of each
i2I, which could be derived from static heuristics [ 38] or proÔ¨Åle
data [ 5,18]. However, other cost functions can minimize the static
number of probes inserted, or prioritize instrumentation locations
based on real-time requirements or security concerns. (See Section 4
for computation of these values in our evaluation.)
2.4 Encoding SpeciÔ¨Åc Problems
We now describe how to encode speciÔ¨Åc realistic requirements as
instances of our problem. Figure 1a shows an example CFG with
entry vertex e. Using this graph as G=(V;E), one can obtain full
local statement coverage data with I=D=Vnfeg. Assuming
the program could crash at any statement, we can also let X=V.
We thus obtain full coverage data for any local execution (i.e., if
coverage information is stored in the program stack [ 29]), and for
functions known to execute exactly once (e.g., the main function).
To handle multiple executions of the instrumented function, one
performs a simple graph modiÔ¨Åcation: add a new vertex qrepre-
28e   xd
:::
Y1: all paths not crossing fdg:::
Y2: all paths not crossing fdgp: some path not crossing (SnY)[fdgpd: some path
not crossingSnYpd: some pathnot crossing
SnY
Figure 2: Pictorial representation of an ambiguous triangle
senting any execution from the rest of the program, as shown in
Fig. 1b. For full statement coverage, we then let I=D=Vnfe;qg.
Usually, we say that q2X, indicating that execution may terminate
outside the current function. If we can statically determine that the
program cannot crash in the function (or we only need coverage data
for complete executions), we can set X=fqg. For edge coverage
instead of vertex coverage, we split each edge in the CFG. Let V0
be the set of new vertices added on these split edges. Full edge
coverage is then encoded by I=D=V0.
In some contexts, one need only gather coverage information for
a speciÔ¨Åc set of statements or edges. For example, prior work in
debugging and program slicing focuses on call statements [ 28,29].
In this case, Dis the set of basic blocks containing call statements.
Other work gathers residual coverage information for deployed
applications based on statements or branches not covered during
in-house testing [ 32,34]. Here, Dis the set of non-covered blocks
(or edges, using the edge-splitting method described above). Beyond
well-studied cases, many others are possible. One might reduce run-
time cost by removing some portion of the ‚Äúhottest‚Äù blocks from I
as identiÔ¨Åed by standard proÔ¨Åling. With previous post-deployment
failure analysis data, one might set Dto program locations whose
execution status was unknown in the failing execution. After a
product release, developers could isolate new failures by setting D
to recently changed code. Alternately, one might exclude security-
sensitive code or code with real-time requirements from I.
2.5 Proof of NP-Hardness
To show that the Customized Coverage Probing Problem is NP-
hard, we show that a known NP-complete problem reduces to our
problem in polynomial time. Maheshwari [ 23] proves that determin-
ing the optimal placement for traversal markers in acyclic CFGs is
NP-complete. SpeciÔ¨Åcally, given an acyclic CFG, G=(V;E), one
can enumerate the set of source‚Äìsink paths through G,P(G); then,
for all p2P(G), deÔ¨Åne E(p)as the set of edges along p. Mahesh-
wari proves that determining the minimum-size set of edge traversal
markers, ME, such that each p2P(G)traverses a unique set
of traversal markers, is an NP-complete problem. Formally, the
problem is to Ô¨Ånd MEsuch that for all distinct p1;p22P(G),
M\E(p1),M\E(p2); and for all M0such thatjM0j<jMj, there
exist distinct p1;p22P(G)such that M0\E(p1)=M0\E(p2).
Note that traversal markers and coverage probes yield precisely
the same information for acyclic graphs: no edge may occur more
than once in any path (because there are no cycles), and the order
of any pair of edges is Ô¨Åxed if both may occur along the same
path (because there would otherwise be a path containing a cycle).
Thus, while Maheshwari‚Äôs original intent was to prove that minimal
probing to distinguish all paths in an acyclic CFG is NP-complete,
the same proof also shows that minimizing the number of edge
probes to obtain full edge coverage information is NP-complete.
Transforming a Traversal Marker Placement Problem into a Cus-
tomized Coverage Probing Problem is straightforward. Given a CFGG=(V;E), we split each edge to instrument for edge coverage as in
Section 2.4. Then, an optimal solution to the Customized Coverage
Probing Problem with input
I=D=V0nV c i=1 for all i2I
is also an optimal traversal marker placement. The transformation
is polynomial, as splitting each edge is simply an O(E)operation.
Therefore, the Customized Coverage Probing Problem is NP-hard.
3. APPROACH
This section describes our solution to the Customized Coverage
Probing Problem, and two approximations. First, in Section 3.1, we
give a characterization of a coverage set that can be checked in poly-
nomial time. Using this new characterization, Section 3.2 outlines
a MILP to identify the optimal coverage set. Section 3.3 describes
a dominance-based approximation; however, this approximation
provides no optimality guarantees. We build on this approach in
Section 3.4 to formulate a second approximation that Ô¨Ånds a locally
minimal coverage set. Finally, Section 3.5 touches on recovery of
full coverage information from optimized instrumentation.
3.1 Checking SufÔ¨Åciency of Coverage Sets
As a Ô¨Årst step, we must devise a su ciency check for a candidate
coverage set SI. That is, we would like a simpliÔ¨Åed condition
(relative to DeÔ¨Ånition 3) in order to check whether any given set S
is a coverage set of D. Recall that Dis the set of desired vertices,
and that Sis a coverage set of Dif and only if coverage information
forSunambiguously allows one to determine coverage information
forDon any execution path. DeÔ¨Ånition 3 is given with respect
to all paths through Gending at some x2X; for any graph with
loops, there may be inÔ¨Ånitely many such paths. Intuitively, however,
many of these paths are redundant with respect to S‚Äôs coverage
set status. We formalize this intuition by narrowing our search to
Ô¨Ånding ‚Äúambiguous triangles‚Äù in which some d2Dmay or may
not occur between observation vertices and. The condition is
represented pictorially in Fig. 2. As input, we have all items from
Section 2.1 and some SI, a candidate coverage set for D.
In Fig. 2, wavy lines represent paths crossing 0 or more edges.
The core of this approach lies in Ô¨Ånding an ambiguous triangle
composed of paths pd,p, and pd. Such a triangle represents
an ambiguous region of execution (between observation points) that
demonstrates that Salone is not su cient to determine if dexecuted.
Conversely, Sis a coverage set of DifSallows no ambiguous
triangles in G. An ambiguous triangle is a triple (;; d)such that:
is either the entry vertex or an observation point from S,
is either from Sor a possible termination location, and
d2D, and dmay or may not occur on paths !that
contain no other new observations.
29To deÔ¨Åne new observations above, we must deÔ¨Åne sets Y1,Y2, and
Y. The set Y1contains all d-free paths from the entry vertex to .
The set Y2contains all d-free paths from to a possible termination
location. (If d2X, then dis excluded as a possible Ô¨Ånal location,
since ending at dimplies the observation, and hence execution, of
d.) The set Ycontains all vertices along paths in Y1[Y2. These
vertices may occur before or after !paths, and, hence, any
vertices in Y\Sprovide no new information along !paths. If
Y1=;, then ddominateson all paths through G; hence,will
not provide a useful witness, as doccurs on allpaths through .
Conversely, if Y2=;, then dpost-dominates with respect to all
termination points; hence, will not provide a useful witness, as d
will occur on allpaths through . Note that we can form paths p1
andp2from DeÔ¨Ånition 3 by conjoining appropriate paths from Y1
andY2to the two paths through the ambiguous triangle.
To formalize the above, we require one new deÔ¨Ånition:
DeÔ¨Ånition 4 (Connected Excluding) For	Vandv1;v22V,
letv1<	   !v2denote the set of paths from v1tov2thatdo not cross
any edges with a source or target vertex  2	.
This deÔ¨Ånition includes trivial paths. That is, for v2V,v<	   !v
is nonempty for any 	V, even if v2	. Then, for all (;; d)
triples where
2S[feg2S[X d2DnS
we deÔ¨Åne the following sets:
Y1=e<fdg    ! Pd=<SnY     ! d
Y2=[
x2Xnfdg<fdg    ! x P=<(SnY)[fdg             ! 
Y=[
2Y1[Y2V() Pd=d<SnY     !
Then, set Sis a coverage set of Dif and only if:
Y1=;_Y2=;_ Pd=;_ P=;_ Pd=;
for all (;; d)triples deÔ¨Åned above. Note that these Ô¨Åve disjuncts
correspond precisely to the Ô¨Åve necessary parts of the ambiguous
triangle pictured in Fig. 2, and those necessary to form paths p1and
p2from DeÔ¨Ånition 3. Thus, if all Ô¨Åve of these subpaths exist for any
(;; d)triple, then Sis not a coverage set of D.
As an example, consider the CFG in Fig. 1a, and the input
conÔ¨Åguration X=f6gand D=f5g. Candidate coverage set
S=f1;2;3;4;6;7gis not su cient to cover D, because the paths
1=he;1;2;3;4;6;2;3;4;6iand2=he;1;2;3;4;6;2;3;5;6icon-
tain the same set of Svertices (f1;2;3;4;6g) but2contains 52D
while1does not. Note the key di erence highlighted in bold : the
instrumentation cannot distinguish a h3;4;6iloop iteration from a
h3;5;6iiteration. In terms of an ambiguous triangle, we have
=3 Y=f1;2;3;4;6g
=6 h3;5i2Pd
Y1.vertices =f1;2;3;4;6g h 3;4;6i2P
Y2.vertices =f2;3;4;6g h 5;6i2Pd
Again, we see the exact same ambiguity. Because of observations
on prior and /or future loop iterations ( Y1andY2), the execution of
vertex 4 does not preclude the execution of vertex 5, and we have
an ambiguous triangle formed from subpaths h3;4;6iandh3;5;6i.
Consider a few special cases. If SD, then Sis always a
coverage set of D, as no possible vertex for dexists (i.e., DnS=;).This aligns with Section 2.3‚Äôs claim that if DI(the instrumentable
set), then Iitself is a coverage set of D. IfS=;, then Sis a coverage
set of Di8d2D,doccurs on either all or no paths from the entry
to any termination point. In this case, =e,2X, and Y\S=;.
Thus, by the deÔ¨Ånition of pd,p, and pd,Sis not a coverage
set of Difdmay or may not occur on paths from eto2X.
All of our approaches assume that Iis a coverage set of D. In prac-
tice, one might consider cases where this is untrue (and ask for maxi-
malcoverage given a limited Iset). Fortunately, because each d2D
is independent, we can Ô¨Ånd the maximal D0DthatIcan possibly
cover by letting D0=fd2Dsuch that Iis a coverage set of fdgg.
3.2 Optimal MILP Formulation
As shown in Section 2.5, obtaining an optimal solution to the
Customized Coverage Probing Problem is NP-hard. Using the char-
acterization in Section 3.1, we are able to construct a 0‚Äì1 mixed
integer linear optimization problem (MILP) whose solution iden-
tiÔ¨Åes the optimal coverage set. Due to space limitations and the
intractability of obtaining an optimal solution (see Section 4), we
give only an overview of the formulation; the complete MILP model
can be found in our companion technical report [31].
To begin, we can deÔ¨Åne all possible ambiguous triangles for all
possible sets SIas the set of triples of vertices T=f(;; d)2
(I[feg)(I[X)Dg. Then, for each (;; d)2T we deÔ¨Åne
the additional set of vertices
Yd=[
x2X;2(e<fdg    !)[(<fdg    ! x)V():
For each (;; d)triple, the set Ydcorresponds exactly to the Y
set from Section 3.1. That is, it contains all vertices along d-free
paths from eto(Y1) orto some termination point ( Y2). We can
compute this set by checking basic graph connectivity. These sets
are provided as input to the MILP model.
The goal is to Ô¨Ånd S, a minimal-cost coverage set of D. We Ô¨Årst
introduce the binary selection variables
zi=1 ii2S
to represent the selected coverage set. Next, we use Ô¨Åve sets of
binary variables, one for each path set in the coverage set characteri-
zation from Section 3.1, to force the associated set to be empty:
sd=1 will imply that e<fdg    !=;
td=1 will imply that <fdg    ! x=;8x2Xnfdg
ud=1 will imply that <SnYd        ! d=;
vd=1 will imply that <(SnYd)[fdg
              ! =;
wd=1 will imply that d<SnYd        !=;
The model is constructed as a network Ô¨Çow problem. Each of the
above variables is accompanied by a set of constraints that force the
non-existence of the respective path by constraining the dual Ô¨Çow
equations induced by the program‚Äôs control-Ô¨Çow graph and basic
linear programming duality theory (Farkas‚Äô Lemma) [11].
Recall from Section 3.1 that Sis a coverage set of Dif and only if
at least one of these Ô¨Åve sets of paths is empty for all (;; d)2T.
These paths are only relevant when zd=0, because instrumented
vertices are always observed. To force this condition, we thus
introduce the constraint:
sd+td+ud+vd+wd(1 zd)8(;; d)2T
30e
1
2
3 7
4 5 6
Figure 3: Dominator tree for Fig. 1a
global :willInst , the set of vertices that will be probed
global :willCover , the set of vertices for which coverage information
will be available
input :G=(V , E) , a single-function control-Ô¨Çow graph
input :e2V, the entry vertex
input :IV, vertices that may be probed
input :c:V7!R+, costs for vertices
input :DV, vertices with desired coverage
input :XV, possible ending vertices
output :willInstI, a coverage set of D
T=dominator tree for G, with entry vertex e;
ord_T =any bottom-up ordering of T.vertices;
willInst =;;
willCover =;;
canCover =;;
needInst =;;
foreach vinord_T do
coveredChildren =T.children_of( v)\willCover ;
if:exitWithout( v, coveredChildren, X )then
willCover[=fvg;
canCover[=fvg;
else
canCoverChildren =T.children_of( v)\canCover ;
vNeedInst =exitWithout( v, canCoverChildren, X );
ifv2I_:vNeedInst then canCover[=fvg;
ifvNeedInst then needInst[=fvg;
ifv2Dthen
ifv<canCover then return FAIL ;
else cover( v, canCover, needInst, T, X, c ) ;
return willInst ;
Figure 4: Dominator-based approximation
In the end, our objective is to minimize cost
X
i2Vcizi
subject to the above forcing constraint on program paths, and the
relevant constraints for each of the Ô¨Åve classes of paths.
This approach is guaranteed to provide a provably optimal cover-
age set, but unfortunately is too slow in practice. In fact, we were
only able to evaluate the fully optimal approach on our smallest test
subjects (see Section 4). There are a number of reasons for this. The
formulation requires pre-computation of the sets Yd, which is
quartic in the number of vertices in G. Further, even with powerful
commercial software, solving a large-scale MILP still relies on enu-
merating an often large branch-and-bound search tree. Fortunately,
safe and fast approximations of the optimal result are possible.
3.3 An Inexpensive Approximation
Several prior approaches optimize coverage probes by using the
dominance relation among basic blocks [ 1,37]. A basic block vFunction exitWithout( v, children, X )
input :v, the vertex possibly covered
input :children , a subset of v‚Äôs immediate-dominator children that
may provide coverage information for v
input :X, possible ending vertices
return9xsuch that x2Xandvdoes not dominate xand
v<children       ! x,;;
Figure 5: Test for an exit bypassing dominator children
dominates a basic block wif and only if e<fvg    ! w=;. Immediate
dominance relations for any single-entry directed graph form a tree,
and algorithms for computing dominators are well-known [ 3,20].
Figure 3 shows the dominator tree for the example from Fig. 1a.
In this section, we develop an inexpensive approximation algo-
rithm based on dominator information, rather than the su ciency
condition from Section 3.1. Our approach performs a bottom-up
traversal of the dominator tree, ‚Äúcovering‚Äù a block‚Äôs subtrees only
as necessitated by the desired set, D. This approach is inspired by
Agrawal [ 1] and Tikir and Hollingsworth [ 37], but supports cus-
tomized coverage. Most accurately, our approach generalizes these
prior approaches, which could be considered special cases of our
algorithm for only complete executions [ 1] and full coverage [ 1,37].
A vertex, v, can be ‚Äúcovered‚Äù (i.e., guaranteed accurate cover-
age information for any execution) in two possible ways. First,
vitself may be instrumented, so that its coverage is observed di-
rectly. Second, we might instrument an appropriate subset of v‚Äôs
dominator-tree descendants such that all executions through vmust
execute at least one vertex in the descendant set. Clearly, for this
approximation, we must instrument all leaves of the tree. Internal
block vmust be instrumented only if v‚Äôs dominator-tree children
cannot cover v. In our case, vis instrumented if a path exists in G
from vto some x2Xthat bypasses all of v‚Äôs covered children in the
dominator tree (and such that vdoes not dominate x). By the deÔ¨Åni-
tion of dominance, any time a descendant of vexecutes (including a
crashing execution), it implies the execution of v. Intuitively, if the
program can halt after executing vwithout an observation implying
v‚Äôs execution, then v‚Äôs coverage data is unknown on some execution.
For example, consider vertex 3 in Fig. 3, and a crash x=7 (i.e.,
the program halts in block 7). Then the subset of dominator children
f4;5gis sucient to cover 3: in Fig. 1, all paths from 3 to 7 must
pass through some element of f4;5g. Likewise,f6gwould also cover
3: any CFG path from 3 to 7 must pass through 6. Of course, both
alternatives assume that Iincludes the necessary instrumentation
points. If Idisallows bothf4;5gandf6gas instrumentation plans,
then 3 can only be covered by direct instrumentation of 3 itself.
Figure 4 details our algorithm. The global set willInst builds up
the Ô¨Ånal result: the set of basic blocks to be probed for coverage.
The global set willCover tracks which blocks will be guaranteed to
have accurate coverage information available. Hence, as vertices are
added to willInst ,willCover is updated to reÔ¨Çect the newly covered
nodes. The overall goal is to make DwillCover . First, we
compute T, the dominator tree of G, and any bottom-up ordering
ofT‚Äôs vertices, ord_T . Then, we iterate over each vertex in ord_T ,
adding those vertices from Ithat require instrumentation to the set
willInst . During this iteration, we discover which vertices can only
be covered via direct instrumentation (stored in set needInst ), and
which could possibly be covered either via direct instrumentation or
via their dominator descendants (stored in set canCover ).
In the loop, we Ô¨Årst Ô¨Ånd v‚Äôs dominator children that are already
covered ( coveredChildren ). If these vertices are already su cient
to cover v(no path exists from vto an exit or crash bypassing
31Procedure cover( v, canCover, needInst, T, X, c )
input :v2canCover , the vertex to cover
input :canCover , a pre-computed set of vertices that could be
covered
input :needInst , a pre-computed set of vertices whose coverage
information can only be determined by direct probing
input :T, the dominator tree for the function containing v
input :X, possible ending vertices
input :c, costs for vertices
ifv2needInst then
willInst[=fvg;
else
canCoverChildren =T.children_of( v)\canCover ;
assert:exitWithout( v, canCoverChildren, X );
removableChildren =canCoverChildren nwillCover ;
foreach winremovableChildren ordered by cdo
ifexitWithout( v, canCoverChildren nfwg, X)then
cover( w, canCover, needInst, T, X, c );
else
canCoverChildren n=fwg;
willCover[=fvg;
Figure 6: Cover a dominator tree vertex
the covered children, as deÔ¨Åned in function exitWithout() from
Fig. 5), then vis added to willCover andcanCover . Otherwise, we
gather all of v‚Äôs dominator children that possibly could be covered
(canCoverChildren ). Because we process Tbottom-up, canCover
already contains all of v‚Äôs dominator children that could possibly
be covered. If canCoverChildren is insu cient to cover v, then vis
added to needInst . Ifvcan be covered by its dominator children or
can be directly instrumented, vis added to canCover . At this point,
ifv2D, we want to Ô¨Ånd a cheap coverage set for v. However, note
that this approximation assumes that a vertex can only be covered
by its dominator descendants, which is not always true. If we desire
coverage for vbutv<canCover , then the algorithm fails to Ô¨Ånd a
coverage set for D. This situation is rare in practice, and another
approach (see Section 3.4) could reduce the size of Iin this case. If
v2canCover , we Ô¨Ånd a coverage set for vvia a call to cover().
Procedure cover() in Fig. 6 walks back down the dominator tree
in order to cheaply cover vertex v. First, if vcannot be covered
by its dominator children (i.e., v2needInst ), then we instrument
vto obtain its coverage data. Otherwise, we iterate over all of v‚Äôs
dominator children that can be covered, sorted by cost to try to avoid
instrumenting the costliest vertices. For each child w, ifwis already
covered, we skip it. Otherwise, if wis necessary to cover v(as
determined by the call to exitWithout()), we must recursively cover
w. After the completion of cover(), vis covered either via direct
instrumentation, or via calls to cover() on its descendants. Thus,
we pass each vertex as argument vto cover() at most once, since
vis added to willCover at the conclusion of cover(), and will be
excluded from removableChildren in future calls.
Our approach is most similar to that of Tikir and Hollingsworth
[37], who instrument a basic block, v, whenever vis either a leaf
vertex in the dominator tree, or has an outgoing edge (in G) to a
block that vdoes not dominate. This is equivalent to our approach in
the un-customized special case of I=D=X=V, since any such
outgoing edge from vtargets a possible halting location. However,
our approach handles the full range of input from Section 2, allowing
us to optimize coverage with far more degrees of Ô¨Çexibility. We
look for paths to any non-dominated termination point (Fig. 5), and
only cover vertices where necessitated by D(Fig. 6).input :IV, vertices that may be probed
input :c:V7!R+, costs for vertices
input :DV, vertices with desired coverage
output :SI, a locally optimal coverage set of D
assert Iis a coverage set of D;
S=copy( I);
tryRemove =sortIbyc;
foreach iintryRemove do
ifSnfigis a coverage set of D then
Sn=fig;
return S;
Figure 7: Locally optimal approximation
3.4 Locally Optimal Approximation
The approach in Section 3.3 is computationally inexpensive: it
calls cover() on each block at most once, and, therefore traverses
each dominator tree vertex at most twice. However, it provides
no guarantees on the optimality of the obtained willInst set. In
fact, as noted in Section 3.3, it is possible that the dominator-based
approximation will be unable to Ô¨Ånd any coverage set SI, even if
at least one such set exists. This is the ‚Äú return FAIL‚Äù case in Fig. 4.
We can compute a locally optimal coverage set in polynomial time
by iteratively testing smaller-and-smaller candidate coverage sets
via the conditions in Section 3.1. By these conditions, a candidate
coverage set Scan clearly be checked in polynomial time. For each
(;; d)triple arising from our current choice of S, we:
1.compute Y, which requires two depth-Ô¨Årst or breadth-Ô¨Årst
search passes (one to gather all possible vertices along paths
e<fdg    !, and one to gather vertices along paths <fdg    ! x);
2. check for the existence of any path <SnY     ! d;
3. check for the existence of any path <(SnY)[fdg             ! ; and
4. check for the existence of any path d<SnY     !.
Each of the three connected-excluding tests again requires a single
depth-Ô¨Årst or breadth-Ô¨Årst search. If, for any (;; d)triple, each
of the collected vertex sets from Item 1 are non-empty and a path
exists for all Items 2 to 4, then Sisnota coverage set of D.
A coverage set Sis locally minimal with respect to Dwhen S
is a coverage set of D, and8S0S,S0is not a coverage set of D.
Figure 7 gives the direct approach. We begin with S=I(a coverage
set of Dby assumption), and iteratively attempt to remove each
element of S. Removing vertices from Scan never cause Sto cover
more vertices. Thus, if Sis a coverage set of D, then8S"S,S"is
also a coverage set of D. Contrapositively, if Sisnota coverage set
ofD, then8S#S,S#is not a coverage set of Deither.
This approach has polynomial time complexity, but performs
redundant computation, and is too ine cient for practical use. We
improve performance using a number of optimizations and heuristics.
We begin by reducing our initial Iset by a call to our dominator-
based approximation (Fig. 4). If this approximation returns FAIL,
then Icannot be proven a coverage set of Dusing only dominance
relations, and we begin with the full user-speciÔ¨Åed Iset. As Fig. 7
shows, we heuristically attempt to Ô¨Årst remove the costliest vertices
from S. We pre-compute V(Y1)for each (;d)pair, and V(Y2)for
each (;d)pair, as these sets are not dependent on the choice of S.
We also perform substantial pruning of possible (;; d)triples. For
example, as Fig. 2 illustrates, all possible vertices must precede d,
32Table 1: Evaluated applications, ordered by size. Compilation times are scaled relative to 1 for standard Clang with no instrumenta-
tion. ‚Äú‚Äì‚Äù marks compilations that did not complete within 3 hours.
Relative Compilation Time
Basic Block Coverage Call Coverage
Application Description Versions Mean LOC None Dominators Local None Dominators Local
tcas Siemens 1 173 1 :3 1:3 1 :3 1:3 1:3 1 :3
schedule2 Siemens 1 373 1 :4 1:4 2 :0 1:3 1:3 1 :3
schedule Siemens 1 413 1 :4 1:4 5 :1 1:3 1:3 1 :5
replace Siemens 1 563 1 :4 1:4 43 :2 1:3 1:3 1 :3
tot_info Siemens 1 564 1 :3 1:3 14 :2 1:3 1:3 1 :4
print_tokens2 Siemens 1 568 1 :3 1:3 5 :4 1:3 1:3 1 :3
print_tokens Siemens 1 727 1 :4 1:4 360 :6 1:3 1:3 1 :7
ccrypt Linux utility 1 5 ;280 1:5 1:5 5 :1 1:4 1:4 1 :6
gzip Linux utility 5 8 ;114 1:7 1:6 3;157:8 1:4 1:4 64 :7
space ADL interpreter 1 9 ;563 1:6 1:6 24 :8 1:5 1:5 1 :6
exif Linux utility 1 10 ;611 1:5 1:5 22 :2 1:5 1:4 12 :3
bc Linux utility 1 14 ;292 1:6 1:6 365 :5 1:5 1:5 18 :7
sed Linux utility 7 14 ;314 2:0 1:8 ‚Äì 1 :5 1:5 3;744:4
Ô¨Çex Linux utility 5 14 ;946 2:1 1:8 ‚Äì 1 :6 1:6 ‚Äì
grep Linux utility 5 15 ;460 1:9 1:7 ‚Äì 1 :4 1:4 12 :1
bash Linux shell 6 80 ;443 1:5 1:5 ‚Äì 1 :5 1:5 ‚Äì
gcc C compiler 1 222 ;196 1:8 1:7 ‚Äì 1 :5 1:5 ‚Äì
and allmust follow d. Finally, we Ô¨Ånd that, in practice, ambiguous
triangles tend to exist in close proximity to the un-covered d2D.
In other words, the length of paths in <SnY     ! d,<(SnY)[fdg             ! ,
andd<SnY     !tends to be short. Thus, we prioritize testing and
vertices crossing the fewest edges from d.
Overall, though, our approach does not fundamentally di er from
Fig. 7. We are actively searching for optimizations and heuristics
that increase performance, particularly for large, complex CFGs.
Recall that the approach is approximate; any solution Scontains no
unnecessary blocks to cover D, but other less-costly instrumentation
plans may exist. Thus, as stated, in the context of our MILP from
Section 3.2, this approach results in a locally optimal solution.
3.5 Recovering Coverage Data
Extracting desired coverage data from gathered probes can be
somewhat complex in cases of aggressive probe optimization. For
most prior work in coverage optimization [ 1,37], full coverage
data can be derived using nothing more than gathered coverage
data and a function‚Äôs dominator /post-dominator trees. However,
our approaches (except for that in Section 3.3) use more complex
reasoning. Fortunately, our prior research [ 30] recovers complete
coverage information based on incomplete data. The data we collect
here can be fed directly into our existing recovery algorithms with
no changes to the latter whatsoever.
4. EV ALUATION
We evaluated our techniques across a wide variety of C bench-
marks. Our evaluations assess the e ciency of our instrumentation
(as compile-time overhead to optimize coverage probes) and gener-
ated probing schemes (as probe counts and run-time overhead).
4.1 Experimental Design
We implemented the techniques described in Section 3 for C /C++
programs. We extended our existing instrumenting compiler csi-cc
[29] built with Clang /LLVM 3.5 [ 19]. csi-cc already has support formaintaining in-memory coverage data post-crash. We use LLVM‚Äôs
built-in BlockFrequency analyses to determine costs ( cifor each
i2I) as input to our approach. This statically approximates the
execution frequency of each block, but is realistic since even a
run-time proÔ¨Åle approximates post-deployment behavior. We ran
two sets of experiments. First, we optimized for full statement
coverage: I=D=V. Second, we optimized to gather coverage at
call sites: I=D=fbasic blocks containing at least one call site g.
Call-site coverage is an example of customized coverage that cannot
be optimized by any prior approach. Note the slight di erence from
call-site coverage as described in Section 2.4, where we propose
allowing instrumentation anywhere (i.e., I=V). In practice, we
have found that LLVM‚Äôs static cost model is not always a good
representation of run-time costs, which means that our approaches
may be driven to choose more expensive instrumentation plans. By
setting I=D, we ensure that our optimizations can only remove
probes; they cannot, for example, cover basic block bby inserting
new probes into b‚Äôs dominator descendants (present in Ibut absent
from D) to assure coverage of b. Note that inaccurate cost data
is a threat to run-time e ciency, but never to correctness. That is,
our approaches can never select a result Sthat is not a coverage set
ofD, even if Sresults in suboptimal run-time performance. In all
cases, we optimize coverage assuming programs may crash at any
statement: X=V. We ran all experiments on a quad-core Intel Core
i5-3450 CPU clocked at 3:10 GHz with 32 GB of RAM and running
Red Hat Enterprise Linux 6.7.
Table 1 provides details for our subject programs. We obtained
most of these applications from the Software-artifact Infrastructure
Repository [ 12,35]. The exceptions are bc, ccrypt, exif, and gcc:
these are real-world programs. We ran experiments over the non-
faulty builds of most applications; gcc and exif used builds with
a known fault. Some of the applications had multiple versions as
indicated by the ‚ÄúVersions‚Äù column of Table 1.
Note that we exclude fully optimal coverage results from all
experiments. Our implementation of the MILP formulation from
Section 3.2 either exceeds our compilation time limit (3 hours) or
runs out of memory for all but a selection of the small Siemens
33siemens
ccrypt
gzip
space
exif
bc
sed
Ô¨Çex
grep
bash
gcc0%20%40%60%80%100%
190
834
2;433
2;485
1;921
2;791
3;594
6;778
3;534
19;605
56;914120
485
1;381
1;484
1;250
1;662
2;291
3;568
2;036
12;201
37;16188
343
1;013
1;120
1;011
1;352percent of unoptimized probe count
(a) Static probe counts for full basic block coverage
siemens
ccrypt
gzip
space
exif
bc
sed
Ô¨Çex
grep
bash
gcc0%20%40%60%80%100%
32
240
556
686
893
787
796
1;609
618
6;556
15;29530
212
471
497
774
719
735
1;272
561
5;716
13;67521
129
316
298
711
599
519
377percent of unoptimized probe count
(b) Static probe counts for call-site coverage
No Optimization Dominator Approximation Locally Optimal
Figure 8: Coverage probe counts. All bars are scaled to 100% for no optimization to show how much relative reduction the lo-
cally optimal and dominator-based approximations achieve. Numbers within each bar are mean counts without scaling. For ex-
ample, at the left edge of Fig. 8a, the Siemens benchmarks average 190 probes with no optimization , but just 120 probes with the
dominator-based approximation : 70 probes have been optimized away. In relative terms, these Siemens benchmarks have just 63%
as many probes with dominator-based optimization as they do with no optimization .
benchmarks. Our locally optimal implementation from Section 3.4
compiles 12 of our 17 benchmarks for full statement coverage, and
14 benchmarks for call-site coverage, within the time limit.
4.2 Optimization and Compile Time
For each version of each application, we Ô¨Årst measured the wall-
clock time to perform each of our optimization approaches and
instrument the program. These results are shown in Table 1, rel-
ative to a base build with ‚Äú clang -O3 ‚Äù: a value of 1.0 indicates
no compilation-time overhead. We built each application version
at least three times, and divided by base compilation time. We
then took the geometric mean to aggregate across all versions (to
avoid over-representing speciÔ¨Åc versions). The ‚ÄúNone‚Äù columns
indicate compilation overhead for instrumenting all i2Ifor the
selected option. The ‚ÄúDominators‚Äù columns show overhead for
the dominator-based approximation from Section 3.3. The ‚ÄúLocal‚Äù
columns show overhead to obtain a locally minimal solution. In
all cases, we instrumented functions to gather local coverage data
(see Section 2.4), storing coverage data within the program stack at
run time. Storing coverage data in-memory results in substantially
smaller absolute overheads, and is common in practice [4, 29].
The results are grouped into statement coverage results (gathered
as basic block coverage) and call-site coverage results. Without op-
timization, there is a cost of 1 :3‚Äì2:1to compile benchmarks for
coverage. However, the dominator-based optimization is extremely
inexpensive, often saving time over full instrumentation. We believe
that the extra cost results from generating and inserting the required
probing code. The overhead of locally minimal optimization varies
greatly between benchmarks. We Ô¨Ånd that large, complex func-
tions take a disproportionately long time to optimize. For example,
gzip‚Äôs base compile time averages under 2 seconds, but computing
a locally optimal solution requires over 1.5 hours, dominated by 3functions that consume over 90% of the total time. As we discuss in
Section 3.4, the approach has polynomial time complexity; however,
the description in Section 3.1 indicates that, in the worst case, we
must consider all possible (;; d)triples in order to prove that a
particular SIis a coverage set of our desired set D.
Restricting the set of desired blocks, D, reduces the number of
(;; d)triples considered by our locally optimal approach, and
should reduce optimization time. Our call-site coverage compilation
results conÔ¨Årm this; we Ô¨Ånd substantially smaller compile-time
overheads when compiling for coverage only at call sites. For
example, while gzip‚Äôs compile time increases from 1.5 seconds
to just over 2 minutes, this is far below the 3;000increase we
see for optimizing full statement coverage. These improvements
allow us to compute locally optimal solutions for two additional
benchmarks (grep and sed). However, 3 benchmarks still do not
complete compilation, and sed exhibits a 3;744slowdown; thus,
scalability remains a concern for our locally optimal formulation.
4.3 Static Probe Counts
We also gathered the total number of probes inserted by each
approach, to examine the static reduction in probe insertions for
our optimizations. We again took the mean of probe counts for
dierent versions of each application. We also aggregated results for
all Siemens applications to simplify presentation. Probe reductions
are very similar across all Siemens benchmarks of non-trivial size.
Figure 8a shows results for full statement coverage. As noted in
Section 3.3, since I=D=X=Vfor full statement coverage, our
dominator-based approximation is equivalent to the optimizations
of Tikir and Hollingsworth [ 37] in this speciÔ¨Åc scenario. Stacked
bars indicate the percentage of the unoptimized probes still included
after the speciÔ¨Åed optimization. Hence, for example, bc with the
dominator-based approximation reduces the probe count by approx-
34siemens
ccrypt
gzip
space
exif
bc
sed
Ô¨Çex
grep
gcc0%20%40%60%80%100%percent of unoptimized probe count
(a) Dynamic probe executions for full basic block coverage
siemens
ccrypt
gzip
space
exif
bc
sed
Ô¨Çex
grep
bash
gcc0%20%40%60%80%100%percent of unoptimized probe count
(b) Dynamic probe executions for call-site coverage
No Optimization Dominator Approximation Locally Optimal
Figure 9: Dynamic probe executions. All bars are scaled to 100% for no optimization to show how much relative reduction the locally
optimal and dominator-based approximations achieve. Mean counts without scaling are omitted due to space limitations.
imately 40% relative to unoptimized instrumentation. The locally
optimal approach further reduces the probe count, cutting the remain-
ing probes to just below half of the original set. Those applications
that cannot be compiled within our time limit exclude locally opti-
mal results in the Ô¨Ågure. Overall, probe reductions are substantial.
Our dominator-based approximation is inexpensive, but still reduces
probe counts by over 40% on average. The locally optimal approach
is substantially more expensive (as seen in Table 1), but further
reduces necessary instrumentation to just 44% of unoptimized in-
strumentation for completed benchmarks, on average.
The main thrust of our approaches, however, comes in their ability
to optimize instrumentation based on customized coverage require-
ments. Figure 8b presents results for call-site coverage. Note that
prior work cannot optimize coverage probes in this scenario. Here,
the unoptimized instrumentation set is much more selective. Reduc-
tions are smaller across all benchmarks, but, for most applications,
we still see substantially less instrumentation. The dominator-based
approximation reduces probe counts by up to 28% (space), and
averages a 15% reduction across all benchmarks. The beneÔ¨Åts of
the locally optimal approach are very pronounced. For those appli-
cations that completed local optimization, we see an average further
reduction of 30% from the dominator-based approximation, with
total reductions as high as 57% (space, relative to unoptimized).
4.4 Dynamic Probe Counts
With the completed builds, we then gathered the total number
of probe executions at run time to assess the dynamic impact of
optimizations. We ran each application through its corresponding
test suite. We gathered the count for each trial, and computed the
percentage reduction for each level of optimization. We took the
arithmetic mean to aggregate across each complete test suite, and ag-
gregated the resulting values across all versions of each application
(to avoid over-representing speciÔ¨Åc versions or long-running test
cases). We again aggregated results for the Siemens applications,
which exhibit similar run-time performance.Figure 9a shows dynamic probe execution reductions for full state-
ment coverage. We excluded one test case for gzip that exceeds our
1-hour timeout for extracting probe counts. We omit bash results,
as bash‚Äôs test suite is highly sensitive to our probe counting infras-
tructure with dense statement coverage. Stacked bars are scaled to
the number of executed probes for the unoptimized variant. Again,
I=D=X=V, and our dominator-based approximation is equiv-
alent to Tikir and Hollingsworth [ 37]. For all of the applications,
even this approximation results in a substantial drop in overheads;
in fact, all applications lose at least 60% of their probe executions,
while simultaneously shrinking compile time per Table 1. ccrypt
sees the largest reduction, executing just 39% of the unoptimized
probe count. Although expensive to compute, overhead reductions
from further reducing probes via the locally optimal formulation
are sometimes substantial. For example, after the dominator-based
approximation reduces gzip‚Äôs probe executions by 43%, our locally
optimal approach removes more probes, reducing probe executions
to just 37% relative to uninstrumented code; ccrypt is reduced to
just 24% of the unoptimized count. Of course, as mentioned earlier,
this run-time performance may come at a cost: gzip‚Äôs compile time
increases from seconds to hours when moving to a locally optimal
solution. Overall, the performance of the dominator-based approxi-
mation is quite impressive. Our locally optimal approach presents a
signiÔ¨Åcant trade-o : it does often remove signiÔ¨Åcantly more probes
(see Fig. 8a), but at a very high compilation cost (see Table 1).
Figure 9b presents call-site coverage results. We exclude 10 (out
of 1061) bash test cases due to time-out. Here, unoptimized probe ex-
ecutions are much smaller, and reductions from the dominator-based
approximation are less pronounced. Nevertheless, some applications
see signiÔ¨Åcant beneÔ¨Åt. For example, exif and space both execute
just 70% of the unoptimized probe counts. Our locally optimal
approach, however, is very impressive. While some applications see
less beneÔ¨Åt (e.g., gzip), many applications see enormous reductions.
For example, bc and ccrypt both reduce probe executions by 40%
beyond the reductions of the dominator-based approximation.
35We also assessed the statistical signiÔ¨Åcance of the results from
Fig. 9. We conducted a Wilcoxon signed-rank test between test
cases with each level of optimization. For all results, we Ô¨Ånd suf-
Ô¨Åcient evidence ( p<0:01) to reject the null hypothesis that our
optimizations have no e ect on dynamic probe executions.
4.5 Running Time
The results from Figure 9 do not depend on probe costs, but
real impacts on running time depend on the cost to execute each
probe. We measured execution times of each program‚Äôs test suite,
measuring overheads relative to ‚Äú clang -O3 ‚Äù as a baseline. We
used inline, in-memory probes, which impose far smaller overheads
than would be seen if data were occasionally Ô¨Çushed to disk or
if probes required function calls to record data. Even so, we ob-
serve signiÔ¨Åcant reductions, particularly with statement coverage.
Mean overhead for the non-trivial benchmarks shrinks from 7.2%
to 3.6% using the dominator-based approximation. Although ex-
pensive to compute, the locally optimal formulation can provide
substantial additional beneÔ¨Åt. For example, the dominator-based
approximation reduces gzip‚Äôs overhead from 11.6% to 5.7%; our
locally optimal formulation reduces this further to just 3.4% relative
to uninstrumented code. For call-site coverage, our optimizations
did not measurably reduce running time. This is surprising, given
the reductions shown in Fig. 9b. However, our in-memory binary
probes are already quite fast, and the majority of our test cases do
not run long enough to exhibit large overheads. If probes were more
costly, we would expect much more pronounced results. Further, the
larger numbers of probes used for statement coverage show a corre-
spondingly larger optimization beneÔ¨Åt. We again used a Wilcoxon
test, and found our statement coverage reductions to be statistically
signiÔ¨Åcant ( p<0:01 for each non-zero overhead reduction).
Overall, our results show we can signiÔ¨Åcantly reduce the static and
dynamic cost of customized coverage instrumentation. We specif-
ically evaluate customized coverage of call sites, where required
coverage information is already substantially reduced. Even so, our
techniques reduce static probe counts by as much as 57% (space
in Fig. 8b), and dynamic probe executions by up to 55% (ccrypt
in Fig. 9b). Even when the absolute numbers are not large, these
reductions should not be discounted: these may be very important
in systems with real-time requirements or for deployed software.
5. RELATED WORK
Closely related work optimizes placement of binarized coverage
probes. Agrawal [ 1] optimizes probes by forming ‚Äúsuperblocks‚Äù
from sets of basic blocks based on dominance and post-dominance
relations. Later, Agrawal [ 2] extends this work to interprocedural
dominance relations; Li et al. [ 21] and Xu et al. [ 39] extend these
optimizations beyond superblocks. Tikir and Hollingsworth [ 37]
also optimize coverage probe placement via dominators, but use a
faster, simpler approach (and no post-dominance information) for
online instrumentation. Our approximation in Section 3.3 is inspired
by many of these prior approaches. However, because we support
multiple crash points (via input parameter X), we cannot directly
take advantage of post-dominator information as in Agrawal. Fur-
ther, because we allow customization of desired and instrumentable
locations, we develop a generalization of these existing approaches,
facilitating many coverage optimization scenarios that are not sup-
ported by any prior work. Particularly for local coverage data (i.e.,
without the transformation from Fig. 1b), our approaches can opti-
mize instrumentation more aggressively than any prior approach.
Binarized coverage only needs to observe each probed location
one time: once a coverage value becomes true, it stays true. Building
on this insight, prior work optimizes coverage gathering via dynamicinsertion and deletion of probes [ 10,16,26,27,33,37]. These
techniques are complimentary to our own: we optimize where to
insert probes, while such techniques address how andwhen to insert
probes. Many commercial tools gather program coverage over test
suites (e.g., [ 4,9,14,15]). These tools gather complete program
coverage, whereas our work allows a developer to focus tracing to
reduce overheads and /or limit possible instrumentation.
Prior work has optimized instrumentation to gather frequency
counts of statements or edges, often to identify program ‚Äúhot spots.‚Äù
Knuth and Stevenson [ 18] optimize frequency counter placement for
program statements, and Knuth [ 17] optimizes instrumentation for
edge counts. Ball and Larus [ 5] formalize these classic approaches,
and generalize the counting problems for vertices and edges. While
these classic approaches run in polynomial time, their solutions
cannot be used for binarized instrumentation: they rely on Kircho ‚Äôs
current law, which does not hold of binarized indicators. Further,
many use cases that we consider would not make use of the more
detailed count information. Coverage data can obviously be derived
from count data, but the cost of gathering counts is higher than
the cost of gathering coverage. In contexts where counts are not
required, binarized coverage has a number of advantages: (1) each
probe is less expensive to execute, (2) each probe requires only
one bit of storage rather than a larger, overÔ¨Çow-vulnerable integer,
(3) instrumentation is easily made thread-safe on all architectures,
and (4) probes can be removed after they are Ô¨Årst triggered.
Pavlopoulou and Young [ 34] monitor residual coverage of code
missed during testing. The GAMMA project [ 8,32] adapts post-
deployment instrumentation for data collection aggregated across
large user communities; each individual entity only traces a subset of
desired data. Our optimizations are directly applicable here, further
reducing required coverage probes for each deployed instance.
Prior work optimizes the set of test cases required to achieve
a speciÔ¨Åc coverage criterion [ 1,7,24,40]. Early approaches to
test suite minimization have much in common with approaches
to minimizing coverage probes: for example, all can make use of
dominance information for implied coverage. However, our problem
is dierent in that desired coverage information must be guaranteed
foranyrun, rather than attained from a minimal setof runs.
Other work has developed the idea of relative coverage in the
context of web services [ 6,13,25]. Our work can also facilitate
customizing coverage metrics to context-dependent targets, but deals
with optimizing coverage probe placement rather than how to gather
and present this data to users of a web service.
6. CONCLUSION
Binarized program coverage information is used in a wide variety
of scenarios, from the testing lab to post-deployment monitoring.
Dierent situations yield very di erent requirements for coverage,
as well as di erent run-time overhead restrictions. We present a
system that allows users to specify customized coverage criteria:
desired coverage locations, as well as the set of locations that are
valid for instrumentation. While we show that the Customized
Coverage Probing Problem is NP-hard, we also develop inexpensive
approximations, and show that even coarse approximations can lead
to signiÔ¨Åcant reductions in instrumentation cost.
7. ACKNOWLEDGMENTS
This research was supported in part by DARPA MUSE award
FA8750-14-2-0270 and NSF grants CCF-0953478, CCF-1217582,
CCF-1318489, and CCF-1420866. Opinions, Ô¨Åndings, conclusions,
or recommendations expressed herein are those of the authors and
do not necessarily reÔ¨Çect the views of the sponsoring agencies.
368. REFERENCES
[1]H. Agrawal. Dominators, super blocks, and program coverage.
InProceedings of the 21st ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages , POPL
‚Äô94, pages 25‚Äì34, New York, NY , USA, 1994. ACM. URL
http://doi.acm.org /10.1145 /174675.175935.
[2]H. Agrawal. E cient coverage testing using global dominator
graphs. In W. G. Griswold and S. Horwitz, editors,
Proceedings of the SIGPLAN /SIGSOFT Workshop on Program
Analysis For Software Tools and Engineering, PASTE ‚Äô99,
Toulouse, France, September 6, 1999 , pages 11‚Äì20. ACM,
1999. URL http: //doi.acm.org /10.1145 /316158.316166.
[3]A. V . Aho, R. Sethi, and J. D. Ullman. Compilers: Principles,
Techniques, and Tools . Addison-Wesley, 1986.
[4] Atlassian. Clover, Jan. 2016. URL
https: //www.atlassian.com /software /clover.
[5] T. Ball and J. R. Larus. Optimally proÔ¨Åling and tracing
programs. ACM Trans. Program. Lang. Syst. , 16(4):
1319‚Äì1360, 1994. URL
http://doi.acm.org /10.1145 /183432.183527.
[6] C. Bartolini, A. Bertolino, S. G. Elbaum, and E. Marchetti.
Whitening SOA testing. In H. van Vliet and V . Issarny,
editors, Proceedings of the 7th joint meeting of the European
Software Engineering Conference and the ACM SIGSOFT
International Symposium on Foundations of Software
Engineering, 2009, Amsterdam, The Netherlands, August
24-28, 2009 , pages 161‚Äì170. ACM, 2009. URL
http://doi.acm.org /10.1145 /1595696.1595721.
[7] A. Bertolino. Unconstrained edges and their application to
branch analysis and testing of programs. Journal of Systems
and Software , 20(2):125‚Äì133, 1993. URL
http://dx.doi.org /10.1016 /0164-1212(93)90004-H.
[8]J. Bowring, A. Orso, and M. J. Harrold. Monitoring deployed
software using software tomography. In Proceedings of the
2002 ACM SIGPLAN-SIGSOFT workshop on Program
analysis for software tools and engineering , PASTE ‚Äô02,
pages 2‚Äì9, New York, NY , USA, 2002. ACM. URL
http://doi.acm.org /10.1145 /586094.586099.
[9] Bullseye Testing Technology. BullseyeCoverage, Jan. 2016.
URL http: //www.bullseye.com /productInfo.html.
[10] K. Chilakamarri and S. G. Elbaum. Leveraging disposable
instrumentation to reduce coverage collection overhead. Softw.
Test., Verif. Reliab. , 16(4):267‚Äì288, 2006. URL
http://dx.doi.org /10.1002 /stvr.347.
[11] G. Dantzig. Linear Programming and Extensions . Princeton
University Press, Princeton, NJ, 1963.
[12] H. Do, S. G. Elbaum, and G. Rothermel. Supporting
controlled experimentation with testing techniques: An
infrastructure and its potential impact. Empirical Software
Engineering , 10(4):405‚Äì435, 2005. URL
http://dx.doi.org /10.1007 /s10664-005-3861-2.
[13] M. M. Eler, A. Bertolino, and P. C. Masiero. More testable
service compositions by test metadata. In J. Z. Gao, X. Lu,
M. Younas, and H. Zhu, editors, IEEE 6th International
Symposium on Service Oriented System Engineering, SOSE
2011, Irvine, CA, USA, December 12-14, 2011 , pages
204‚Äì213. IEEE Computer Society, 2011. URL
http://dx.doi.org /10.1109 /SOSE.2011.6139109.
[14] Free Software Foundation. Gcov: a test coverage program,
Jan. 2016. URL
https: //gcc.gnu.org /onlinedocs /gcc/Gcov.html.[15] IBM Rational. PureCoverage, 2003. URL ftp: //ftp.software.
ibm.com /software /rational /docs/v2003 /purecov /index.htm.
[16] B. Kasikci, T. Ball, G. Candea, J. Erickson, and M. Musuvathi.
Ecient tracing of cold code via bias-free sampling. In
G. Gibson and N. Zeldovich, editors, 2014 USENIX Annual
Technical Conference, USENIX ATC ‚Äô14, Philadelphia, PA,
USA, June 19-20, 2014. , pages 243‚Äì254. USENIX
Association, 2014. URL https: //www.usenix.org /conference /
atc14 /technical-sessions /presentation /kasikci.
[17] D. E. Knuth. The Art of Computer Programming, Volume I:
Fundamental Algorithms . Addison-Wesley, 1968.
[18] D. E. Knuth and F. R. Stevenson. Optimal measurement
points for program frequency counts. BIT Numerical
Mathematics , 13(3):313‚Äì322, 1973.
[19] C. Lattner and V . Adve. LLVM: A compilation framework for
lifelong program analysis & transformation. In Proceedings
of the 2004 International Symposium on Code Generation and
Optimization (CGO‚Äô04) , Palo Alto, California, Mar. 2004.
[20] T. Lengauer and R. E. Tarjan. A fast algorithm for Ô¨Ånding
dominators in a Ô¨Çowgraph. ACM Trans. Program. Lang. Syst. ,
1(1):121‚Äì141, 1979. URL
http://doi.acm.org /10.1145 /357062.357071.
[21] J. J. Li, D. M. Weiss, and H. Yee. An automatically-generated
run-time instrumenter to reduce coverage testing overhead. In
Proceedings of the 3rd International Workshop on Automation
of Software Test, AST 2008, Leipzig, Germany, May 11-11,
2008. , pages 49‚Äì56. ACM, 2008. URL
http://dx.doi.org /10.1145 /1370042.1370054.
[22] B. Liblit. The Cooperative Bug Isolation Project, Jan. 2014.
URL http: //research.cs.wisc.edu /cbi/.
[23] S. N. Maheshwari. Traversal marker placement problems are
NP-complete. Technical Report CU-CS-092-76, University of
Colorado, Boulder, July 1976.
[24] M. Marr√© and A. Bertolino. Using spanning sets for coverage
testing. IEEE Trans. Software Eng. , 29(11):974‚Äì984, 2003.
URL http: //dx.doi.org /10.1109 /TSE.2003.1245299.
[25] B. Miranda and A. Bertolino. Social coverage for customized
test adequacy and selection criteria. In H. Zhu, J. Gao,
S. Sinha, and L. Zhang, editors, 9th International Workshop
on Automation of Software Test, AST 2014, Hyderabad, India,
May 31 - June 1, 2014 , pages 22‚Äì28. ACM, 2014. URL
http://doi.acm.org /10.1145 /2593501.2593505.
[26] J. Misurda, J. A. Clause, J. L. Reed, B. R. Childers, and M. L.
Soa. Demand-driven structural testing with dynamic
instrumentation. In G. Roman, W. G. Griswold, and
B. Nuseibeh, editors, 27th International Conference on
Software Engineering (ICSE 2005), 15-21 May 2005, St.
Louis, Missouri, USA , pages 156‚Äì165. ACM, 2005. URL
http://doi.acm.org /10.1145 /1062455.1062496.
[27] J. Misurda, B. R. Childers, and M. L. So a. Jazz2: a Ô¨Çexible
and extensible framework for structural testing in a Java VM.
In C. W. Probst and C. Wimmer, editors, Proceedings of the
9th International Conference on Principles and Practice of
Programming in Java, PPPJ 2011, Kongens Lyngby,
Denmark, August 24-26, 2011 , pages 81‚Äì90. ACM, 2011.
URL http: //doi.acm.org /10.1145 /2093157.2093169.
[28] A. Nishimatsu, M. Jihira, S. Kusumoto, and K. Inoue.
Call-mark slicing: an e cient and economical way of
reducing slice. In Proceedings of the 21st international
conference on Software engineering , ICSE ‚Äô99, pages
422‚Äì431, New York, NY , USA, 1999. ACM. URL
http://doi.acm.org /10.1145 /302405.302674.
37[29] P. Ohmann and B. Liblit. Lightweight control-Ô¨Çow
instrumentation and postmortem analysis in support of
debugging. In 28th International Conference on Automated
Software Engineering (ASE 2013) , Palo Alto, California, Nov.
2013. IEEE and ACM.
[30] P. Ohmann, D. B. Brown, B. Liblit, and T. W. Reps.
Recovering execution data from incomplete observations. In
H. Xu and W. Binder, editors, Proceedings of the 13th
International Workshop on Dynamic Analysis, WODA 2015,
Pittsburgh, PA, USA, October 26, 2015 , pages 19‚Äì24. ACM,
2015. URL http: //doi.acm.org /10.1145 /2823363.2823368.
[31] P. Ohmann, D. B. Brown, N. Neelakandan, J. Linderoth, and
B. Liblit. Encoding optimal customized coverage
instrumentation. Technical Report 1836, Department of
Computer Sciences, University of Wisconsin‚ÄìMadison, Aug.
2016.
[32] A. Orso, D. Liang, M. J. Harrold, and R. Lipton. Gamma
system: continuous evolution of software after deployment. In
Proceedings of the 2002 ACM SIGSOFT international
symposium on Software testing and analysis , ISSTA ‚Äô02,
pages 65‚Äì69, New York, NY , USA, 2002. ACM. URL
http://doi.acm.org /10.1145 /566172.566182.
[33] T. Pankumhang and M. Rutherford. Iterative instrumentation
for code coverage in time-sensitive systems. In 8th IEEE
International Conference on Software Testing, VeriÔ¨Åcation
and Validation, ICST 2015, Graz, Austria, April 13-17, 2015 ,
pages 1‚Äì10. IEEE, 2015. URL
http://dx.doi.org /10.1109 /ICST.2015.7102594.
[34] C. Pavlopoulou and M. Young. Residual test coverage
monitoring. In B. W. Boehm, D. Garlan, and J. Kramer,
editors, Proceedings of the 1999 International Conference on
Software Engineering, ICSE‚Äô 99, Los Angeles, CA, USA, May16-22, 1999. , pages 277‚Äì284. ACM, 1999. URL
http://portal.acm.org /citation.cfm?id =302405.302637.
[35] G. Rothermel, S. Elbaum, A. Kinneer, and H. Do.
Software‚Äìartifact infrastructure repository, Sept. 2006. URL
http://sir.unl.edu /portal /.
[36] R. A. Santelices, J. A. Jones, Y . Yu, and M. J. Harrold.
Lightweight fault-localization using multiple coverage types.
In31st International Conference on Software Engineering,
ICSE 2009, May 16-24, 2009, Vancouver, Canada,
Proceedings , pages 56‚Äì66. IEEE, 2009. URL
http://dx.doi.org /10.1109 /ICSE.2009.5070508.
[37] M. M. Tikir and J. K. Hollingsworth. E cient instrumentation
for code coverage testing. In ISSTA , pages 86‚Äì96, 2002. URL
http://doi.acm.org /10.1145 /566172.566186.
[38] Y . Wu and J. R. Larus. Static branch frequency and program
proÔ¨Åle analysis. In H. Mulder and M. K. Farrens, editors,
Proceedings of the 27th Annual International Symposium on
Microarchitecture, San Jose, California, USA, November 30 -
December 2, 1994 , pages 1‚Äì11. ACM /IEEE, 1994. URL
http://dx.doi.org /10.1109 /MICRO.1994.717399.
[39] X. Xu, Y . Chen, W. E. Wong, and D. Guo. Vnm: A novel
method to reduce the overhead of program instrumentation. In
Proceedings of the 2009 WRI World Congress on Software
Engineering - Volume 04 , WCSE ‚Äô09, pages 256‚Äì260,
Washington, DC, USA, 2009. IEEE Computer Society. URL
http://dx.doi.org /10.1109 /WCSE.2009.315.
[40] S. Yoo and M. Harman. Regression testing minimization,
selection and prioritization: a survey. Softw. Test., Verif.
Reliab. , 22(2):67‚Äì120, 2012. URL
http://dx.doi.org /10.1002 /stv.430.
38