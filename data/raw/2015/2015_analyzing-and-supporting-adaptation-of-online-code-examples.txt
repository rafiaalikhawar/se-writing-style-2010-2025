Analyzing and Supporting Adaptation of Online
Code Examples
Tianyi Zhang‚Ä†Di Yang¬ßCrista Lopes¬ßMiryung Kim‚Ä†
‚Ä†University of California, Los Angeles
¬ßUniversity of California, Irvine
{tianyi.zhang, miryung}@cs.ucla.edu {diy4, lopes}@uci.edu
Abstract ‚ÄîDevelopers often resort to online Q&A forums such
as Stack OverÔ¨Çow (SO) for Ô¨Ålling their programming needs.
Although code examples on those forums are good starting points,
they are often incomplete and inadequate for developers‚Äô local
program contexts; adaptation of those examples is necessary tointegrate them to production code. As a consequence, the process
of adapting online code examples is done over and over again, by
multiple developers independently. Our work extensively studiesthese adaptations and variations, serving as the basis for a tool
that helps integrate these online code examples in a target context
in an interactive manner.
We perform a large-scale empirical study about the nature
and extent of adaptations and variations of SO snippets. We
construct a comprehensive dataset linking SO posts to GitHub
counterparts based on clone detection, time stamp analysis,and explicit URL references. We then qualitatively inspect 400
SO examples and their GitHub counterparts and develop a
taxonomy of 24 adaptation types. Using this taxonomy, we
build an automated adaptation analysis technique on top of
GumTree to classify the entire dataset into these types. We builda Chrome extension called E
XAMPLE STACK that automatically
lifts an adaptation-aware template from each SO example andits GitHub counterparts to identify hot spots where most changeshappen. A user study with sixteen programmers shows that seeing
the commonalities and variations in similar GitHub counterparts
increases their conÔ¨Ådence about the given SO example, and helpsthem grasp a more comprehensive view about how to reuse the
example differently and avoid common pitfalls.
Index T erms‚Äîonline code examples, code adaptation
I. I NTRODUCTION
Nowadays, a common way of quickly accomplishing pro-
gramming tasks is to search and reuse code examples in
online Q&A forums such as Stack OverÔ¨Çow (SO) [1]‚Äì[3]. Acase study at Google shows that developers issue an averageof twelve code search queries per weekday [4]. As of July2018, Stack OverÔ¨Çow has accumulated 26M answers to 16Mprogramming questions. Copying code examples from StackOverÔ¨Çow is common [5] and adapting them to Ô¨Åt a targetprogram is recognized as a top barrier when reusing code fromStack OverÔ¨Çow [6]. SO examples are created for illustrationpurposes, which can serve as a good starting point. However,these examples may be insufÔ¨Åcient to be ported to a productionenvironment, as previous studies Ô¨Ånd that SO examples maysuffer from API usage violations [7], insecure coding prac-tices [8], unchecked obsolete usage [9], and incomplete code
* Both the Ô¨Årst author and the second author contributed signiÔ¨Åcantly and
this research is led by UCLA.fragments [10]. Hence, developers may have to manually adaptcode examples when importing them into their own projects.
Our goal is to investigate the common adaptation types
and their frequencies in online code examples, such as thosefound in Stack OverÔ¨Çow, which are used by a large numberof software developers around the world. To study how theyare adopted and adapted in real projects, we contrast themagainst similar code fragments in GitHub projects. The insightsgained from this study could inform the design of tools forhelping developers adapt code snippets they Ô¨Ånd in Q&Asites. In this paper, we describe one such tool we developed,
E
XAMPLE STACK , which works as a Chrome extension.
In broad strokes, the design and main results of our study
are as follows. We link SO examples to GitHub counter-parts using multiple complementary Ô¨Ålters. First, we quality-control GitHub data by removing forked projects and selectingprojects with at least Ô¨Åve stars. Second, we perform clonedetection [11] between 312K SO posts and 51K non-forkedGitHub projects to ensure that SO examples are similar toGitHub counterparts. Third, we perform timestamp analysisto ensure that GitHub counterparts are created later than theSO examples. Fourth, we look for explicit URL referencesfrom GitHub counterparts to SO examples by matching the
post ID. As the result, we construct a comprehensive dataset
ofvariations and adaptations.
When we use all four Ô¨Ålters above, we Ô¨Ånd only 629 SO
examples with GitHub counterparts. Recent studies Ô¨Ånd thatvery few developers explicitly attribute to the original SO postwhen reusing code from Stack OverÔ¨Çow [5, 6, 12]. Therefore,
we use this resulting set of 629 SO examples as an under-
approximation of SO code reuse and call it an adaptations
dataset. If we apply only the Ô¨Årst three Ô¨Ålters above, we Ô¨Ånd
14,124 SO examples with GitHub counterparts that representpotential code reuse from SO to GitHub. While this set does
not necessarily imply any causality or intentional code reuse,it still demonstrates the kinds of common variations between
SO examples and their GitHub counterparts, which developersmight want to consider during code reuse. Therefore, weconsider this second dataset as an over-approximation of SO
code reuse, and call it simply a variations dataset.
We randomly select 200 clone pairs from each dataset
and manually examine the program differences between SOexamples and their GitHub counterparts. Based on the manualinspection insights, we construct an adaptation taxonomy with
3162019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ¬©2019 IEEE
DOI 10.1109/ICSE.2019.00046
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. 6 high-level categories and 24 specialized types. We then de-
velop an automated adaptation analysis technique built on top
of GumTree [13] to categorize syntactic program differences
into different adaptation types. The precision and recall of
this technique are 98% and 96% respectively. This technique
allows us to quantify the extent of common adaptations and
variations in each dataset. The analysis shows that both the
adaptations and variations between SO examples and their
GitHub counterparts are prevalent and non-trivial. It also
highlights several adaptation types such as type conversion,
handling potential exceptions, and adding ifchecks, which
are frequently performed yet not automated by existing code
integration techniques [14, 15].
Building on this adaptation analysis technique, we develop
a Chrome extension called E XAMPLE STACK to guide devel-
opers in adapting and customizing online code examples to
their own contexts. For a given SO example, E XAMPLE STACK
shows a list of similar code snippets in GitHub and also lifts an
adaptation-aware template from those snippets by identifying
common, unchanged code, and also the hot spots where most
changes happen. Developers can interact and customize these
lifted templates by selecting desired options to Ô¨Åll in the hot
spots. We conduct a user study with sixteen developers to
investigate whether E XAMPLE STACK inspires them with new
adaptations that they may otherwise ignore during code reuse.
Our key Ô¨Ånding is that participants using E XAMPLE STACK
focus more on adaptations about code safety (e.g., adding an
if check) and logic customization, while participants without
EXAMPLE STACK make more shallow adaptations such as
variable renaming. In the post survey, participants Ô¨Ånd E XAM -
PLE STACK help them easily reach consensus on how to reuse
a code example, by seeing the commonalities and variations
between the example and its GitHub counterparts. Participants
also feel more conÔ¨Ådent after seeing how other GitHub de-
velopers use similar code in different contexts, which one
participant describes as ‚Äú asynchronous pair programming .‚Äù
In summary, this work makes the following contributions:
‚Ä¢It makes publicly available a comprehensive dataset of
adaptations and variations between SO and GitHub.1
The adaptation dataset includes 629 groups of GitHub
counterparts with explicit references to SO posts, and the
variation dataset includes 14,124 groups. These datasets
are created with care using multiple complementary
methods for quality control‚Äîclone detection, time stamp
analysis, and explicit references.
‚Ä¢It puts forward an adaptation taxonomy of online code
examples and an automated technique for classifying
adaptations. This taxonomy is sufÔ¨Åciently different from
other change type taxonomies from refactoring [16] and
software evolution [17, 18], and it captures the particular
kinds of adaptations done over online code examples.
‚Ä¢It provides browser-based tool support, called E XAM -
PLE STACK that displays the commonalities and variations
1Our dataset and tool are available at https://github.com/tianyi-zhang/
ExampleStack-ICSE-Artifactbetween a SO example and its GitHub counterparts
along with their adaptation types and frequencies. Par-
ticipants Ô¨Ånd that seeing GitHub counterparts increases
their conÔ¨Ådence of reusing a SO example and helps them
understand different reuse scenarios and corner cases.
The rest of the paper is organized as follows. Section II de-
scribes the data collection pipeline and compares the character-
istics of the two datasets. Section III describes the adaptation
taxonomy development and an automated adaptation analysis
technique. Section IV describes the quantitative analysis of
adaptations and variations. Section V explains the design and
implementation of E XAMPLE STACK . Section VI describes a
user study that evaluates the usefulness of E XAMPLE STACK .
Section VII discusses threats to validity. Section VIII discusses
related work, and Section IX concludes the paper.
II. L INKING STACK OVERFLOW TO GITHUB
This section describes the data collection pipeline. Due to
the large portion of unattributed SO examples in GitHub [5,
6, 12], it is challenging to construct a complete set of reused
code from SO to GitHub. To overcome this limitation, we
apply four quality-control Ô¨Ålters to underapproximate and
overapproximate code examples reused from SO to GitHub,
resulting in two complementary datasets.
GitHub project selection and deduplication. Since GitHub
has many toy projects that do not adequately reÔ¨Çect software
engineering practices [19], we only consider GitHub projects
that have at least Ô¨Åve stars. To account for internal duplication
in GitHub [20], we choose non-fork projects only and further
remove duplicated GitHub Ô¨Åles using the same Ô¨Åle hashing
method as in [20], since such Ô¨Åle duplication may skew our
analysis. As a result, we download 50,826 non-forked Java
repositories with at least Ô¨Åve stars from GitTorrent [21]. After
deduplication, 5,825,727 distinct Java Ô¨Åles remain.
Detecting GitHub candidates for SO snippets. From the SO
dump taken in October 2016 [22], we extract 312,219 answer
posts that have java orandroid tags and also contain code
snippets in the <code> markdown. We consider code snippets
in answer posts only, since snippets in question posts are
rarely used as examples. Then we use a token-based clone
detector, SourcererCC (SCC) [11] to Ô¨Ånd similar code between
5.8M distinct Java Ô¨Åles and 312K SO posts. We choose SCC
because it has high precision and recall and also scales to a
large code corpus. Since SO snippets are often free-standing
statements [23, 24], we parse and tokenize them using a
customized Java parser [25]. Prior work Ô¨Ånds that larger SO
snippets have more meaningful clones in GitHub [26]. Hence,
we choose to study SO examples with no less than 50 tokens,
not including code comments, Java keywords, and delimiters.
We set the similarity threshold to 70% since it yields the best
precision and recall on multiple clone benchmarks [11]. We
cannot set it to 100% since SCC will then only retain exact
copies and exclude those adapted code. We run SCC on a
server machine with 116 cores and 256G RAM. It takes 24
hours to complete, resulting in 21,207 SO methods that have
one or more similar code fragments (i.e., clones) in GitHub.
317
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. Num of GitHub ClonesPercentage of SO examples
0 5 10 15 200 2 04 06 08 0 1 0 0adaptation
variation
(a) Examples with different numbers of clonesCode Size (LOC)Percentage of SO examples
0 50 100 15002468 1 0adaptation
variation
(b) Examples with different code sizesVote Score (i.e., u pvotes minus downvotes )Percentage of SO examples
0 100 200 300 4000 1 02 03 04 05 06 0adaptation
variation
(c) Examples with different vote scores
Fig. 1: Comparison between SO examples in the adaptation dataset and the variation dataset
Timestamp analysis. If the GitHub clone of a SO example
is created before the SO post, we consider it unlikely to be
reused from SO and remove it from our dataset. To identify the
creation date of a GitHub clone, we write a script to retrieve
the Git commit history of the Ô¨Åle and match the clone snippet
against each Ô¨Åle revision. We use the timestamp of the earliest
matched Ô¨Åle revision as the creation time of a GitHub clone.
As a result, 7,083 SO examples (33%) are excluded since all
their GitHub clones are committed before the SO posts.
Scanning explicitly attributed SO examples. Despite the large
portion of unattributed SO examples, it is certainly possible to
scan GitHub clones for explicit references such as SO links
in code comments to conÔ¨Årm whether a clone is copied from
SO. If the SO link in a GitHub clone points to a question post
instead of an answer post, we check whether the corresponding
SO example is from any of its answer posts by matching the
post ID. We Ô¨Ånd 629 explicitly referenced SO examples.
Overapproximating and underapproximating reused code.
We use the set of 629 explicitly attributed SO examples as an
underapproximation of reused code from SO to GitHub, which
we call an adaptation dataset. We consider the 14,124 SO
examples after timestamp analysis as an overapproximation
of potentially reused code, which we call a variation dataset.
Figure 1 compares the characteristics of these two datasets of
SO examples in terms of the number of GitHub clones, code
size, and vote score (i.e., upvotes minus downvotes). Since
developers do not often attribute SO code examples, explicitly
referenced SO examples have a median of one GitHub clone
only, while SO examples have a median of two clones in
the variation dataset. Both sets of SO examples have similar
length, 26 vs. 25 lines of code in median. However, SO
examples from the adaptation dataset have signiÔ¨Åcantly more
upvotes than the variation dataset: 16 vs. 1 in median. In
the following sections, we inspect, analyze, and quantify the
adaptations and variations evidenced by both datasets.
III. A DAPTA TION TYPE ANALYSIS
A. Manual Inspection
To get insights into adaptations and variations of SO ex-
amples, we randomly sample SO examples and their GitHubcounterparts from each dataset and inspect their program
differences using GumTree [13]. Below, we use ‚Äúadaptations‚Äù
to refer both adaptations and variations for simplicity.
The Ô¨Årst and the last authors jointly labeled these SO
examples with adaptation descriptions and grouped the edits
with similar descriptions to identify common adaptation types.
We initially inspected 90 samples from each dataset and had
already observed convergent adaptation types. We continued
to inspect more and stopped after inspecting 200 samples from
each dataset, since the list of adaptation types was converging.
This is a typical procedure in qualitative analysis [27]. The
two authors then discussed with the other authors to reÔ¨Åne the
adaptation types. Finally, we built a taxonomy of 24 adaptation
types in 6 high-level categories, as shown in Table I.
Code Hardening. This category includes four adaptation types
that strengthen SO examples in a target project. Insert a
conditional adds an ifstatement that checks for corner cases
or protects code from invalid input data such as null or
an out-of-bound index. Insert a Ô¨Ånal modiÔ¨Åer enforces that
a variable is only initialized once and the assigned value or
reference is never changed, which is generally recommended
for clear design and better performance due to static inlining.
Handle a new exception improves the reliability of a code
example by handling any missing exceptions, since exception
handling is often omitted in examples in SO [7]. Clean up
unmanaged resources helps release unneeded resources such
as Ô¨Åle streams and web sockets to avoid resource leaks [28].
Resolve Compilation Errors. SO examples are often in-
complete with undeÔ¨Åned variables and method calls [24, 29].
Declare an undeclared variable inserts a statement to declare
an unknown variable. Specify a target of method invocation re-
solves an undeÔ¨Åned method call by specifying the receiver ob-
ject of that call. In an example about getting CPU usage [30],
one comment complains the example does not compile due
to an unknown method call, getOperatingSystemMXBean .
Another suggests to preface the method call with an instance,
ManagementFactory , which is also evidenced by its GitHub
counterpart [31]. Sometimes, statements that use undeÔ¨Åned
variables and method calls are simply deleted.
Exception Handling. This category represents changes of
318
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. TABLE I: Common adaptation types, categorization, and implementation
Category Adaptation Type Rule
Code HardeningAdd a conditional Insert( t1,t2,i)‚àßNodeT ype(t1, IfStatement)
Insert a Ô¨Ånal modiÔ¨Åer Insert( t1,t2,i)‚àßNodeT ype(t1, ModiÔ¨Åer) ‚àßNodeV alue( t1, Ô¨Ånal)
Handle a new exception type Exception(e, GH)‚àß¬¨ Exception(e, SO)
Clean up unmanaged resources (e.g. close a stream) (LocalCall(m, GH)‚à®InstanceCall(m, GH)) ‚àß¬¨ LocalCall(m, SO) ‚àß¬¨ InstanceCall(m, SO) ‚àßisCleanMethod(m)
Resolv e Compilation
ErrorsDeclare an undeclared variable Insert( t1,t2,i)‚àßNodeT ype(t1, V ariableDeclaration) ‚àßNodeV alue( t1,v )‚àßUse(v, SO) ‚àß¬¨ Def(v, SO)
Specify a target of method invocation InstanceCall(m, GH)‚àßLocalCall(m, SO)
Remo ve undeclared variables or local method calls (Use(v , SO)‚àß¬¨ Def(v, SO) ‚àß¬¨ Use(v, GH)) ‚à®(LocalCall(m, SO) ‚àß¬¨ LocalCall(m, GH) ‚àß¬¨ InstanceCall(m, GH))
Exception HandlingInsert/delete a try-catch block (Insert( t1,t2,i)‚à®Delete( t1))‚àßNodeT ype(t1, TryStatement)
Insert/delete a thrown exception in a method headerChanged( t1)‚àßNodeT ype(t1, Type)‚àßParent( t2,t1)‚àßNodeType( t2, MethodDeclaration) ‚àßNodeV alue( t1,t )‚àß
isExceptionType(t)
Update the exception typeUpdate( t1,t2)‚àßNodeT ype(t1, SimpleType) ‚àßNodeType( t2, SimpleType) ‚àßNodeV alue( t1,v1)‚àß
isExceptionType( v1)‚àßNodeV alue( t2,v2)‚àßisExceptionType( v2)
Change statements in a catch block Changed( t1)‚àßAncestor( t2,t1)‚àßNodeT ype(t2, CatchClause)
Change statements in a Ô¨Ånally block Changed( t1)‚àßAncestor( t2,t1)‚àßNodeT ype(t2, FinallyBlock)
Logic CustomizationChange a method call Changed( t1)‚àßAncestor( t2,t1)‚àßNodeT ype(t2, MethodInvocation)
Update a constant value Update( t1,t2)‚àßNodeT ype(t1, Literal) ‚àßNodeType( t2, Literal)
Change a conditional expressionChanged( t1)‚àßAncestor( t2,t1)‚àß
(NodeT ype(t2, IfCondition) ‚à®NodeType( t2, LoopCondition) ‚à®NodeType( t2, SwitchCase))
Change the type of a variable Update( t1,t2)‚àßNodeT ype(t1, Type)‚àßNodeType( t2, Type)
RefactoringRename a variable/Ô¨Åeld/method Update( t1,t2)‚àßNodeT ype(t1, Name)
Replace hardcoded constant values with variables Delete( t1)‚àßNodeT ype(t1, Literal) ‚àßInsert( t1,t2,i)‚àßNodeType( t1, Name)‚àßMatch( t1,t2)
Inline a Ô¨Åeld Delete( t1)‚àßNodeT ype(t1, Name)‚àßInsert( t1,t2,i)‚àßNodeType( t1, Literal) ‚àßMatch( t1,t2)
MiscellaneousChange access modiÔ¨Åers Changed( t1)‚àßNodeT ype(t1, ModiÔ¨Åer) ‚àßNodeV alue( t1,v )‚àßv‚àà{ private, public, protected, static }
Change a log/print statement Changed( t1)‚àßNodeT ype(t1, MethodInvocation) ‚àßNodeV alue( t1,m )‚àßisLogMethod(m)
Style reformatting (i.e., inserting/deleting curly braces) Changed( t1)‚àßNodeT ype(t1, Block)‚àßParent( t2,t1)‚àß¬¨ Changed( t2)‚àßChild( t3,t1)‚àß¬¨ Changed( t3)
Change Java annotations Changed( t1)‚àßNodeT ype(t1, Annotation)
Change code comments Changed( t1)‚àßNodeT ype(t1, Comment)
GumT ree Edit Operation Syntactic Predicate Semantic Predicate
Insert( t1,t2,i)inserts a new tree node t1as the i-th
child of t2in the AST of a GitHub snippet.NodeT ype(t1,X)checks if the node type of t1isX.Exception( e,P)checks ifeis an exception caught in a catch
clause or thrown in a method header in program P.
NodeV alue( t1,v)checks if the corresponding source code
of node t1isv.LocalCall( m,P)checks ifmis a local method call in program P.
Delete( t)remo ves the tree node tfrom the AST of a
SO example.Match( t1,t2)checks ift1andt2are matched based on
surrounding nodes regardless of node types.InstanceCall( m,P)checks ifmis an instance call in program P.
Parent( t1,t2)checks if t1is the parent of t2in the AST. Def(v,P)checks if variable vis deÔ¨Åned in program P.
Update( t1,t2)updates the tree node t1i naS O
example with t2in the GitHub counterpart.Ancestor( t1,t2)checks ift1is the ancestor of t2in the AST. Use(v,P)checks if variable vis used in program P.
Child( t1,t2)checks ift1is the child of t2. IsExceptionT ype(X)checks if Xcontains ‚ÄúException‚Äù.
Move(t1,t2,i)moves an existing node t1in the
AST of a SO example as the i-th child of t2in
the GitHub counterpart.Changed( t1)isa shorthand for Insert( t1,t2,i)‚à®Delete( t1)
‚à®Update( t1,t2)‚à®Move( t1,t2), which checks any
edit operation on t1.IsLogMethod( X)checks ifXis one of the predeÔ¨Åned log methods,
e.g., log, println, error, etc.
IsCleanMethod( X)checks ifXis one of the predeÔ¨Åned resource
clean-up methods, e.g., close, recycle, dispose, etc.
the exception handling logic in catch/finally blocks and
throws clauses. One common change is to customize the
actions in a catch block, e.g., printing a short error mes-
sage instead of the entire stack trace. Some developers han-
dle exceptions locally rather than throwing them in method
headers. For example, while the SO example [32] throws
a generic Exception in the addLibraryPath method, its
GitHub clone [33] enumerates all possible exceptions such as
SecurityException andIllegalArgumentException in
atry-catch block. By contrast, propagating the exceptions
to upstream by adding throws in the method header is
another way to handle the exceptions.
Logic Customization. Customizing the functionality of a code
example to Ô¨Åt a target project is a common and broad category.
We categorize logic changes to four basic types. Change a
method call includes any edits in a method call, e.g., adding
or removing a method call, changing its arguments or receiver,
etc. Update a constant value changes a constant value such as
the thread sleep time to another value. Change a conditional
expression includes any edits on the condition expression ofanifstatement, a loop ,o ra switch case .
Update a type name replaces a variable type or a method
return type with another type. For example, String and
StringBuffer appear in multiple SO examples, and a faster
type, StringBuilder , is used in their GitHub clones instead.
Such type replacement often involves extra changes such as
updating method calls to Ô¨Åt the replaced type or adding method
calls to convert one type to another. For example, instead of
returning InetAddress in a SO example [34], its GitHub
clone [35] returns String and thus converts the IP address
object to its string format using a new Formatter API.
Refactoring. 31% of inspected GitHub counterparts use a
method or variable name different from the SO example.
Instead of slider in a SO example [36], timeSlider is used
in one GitHub counterpart [37] and volumnSlider is used
in another counterpart [38]. Because SO examples often use
hardcoded constant values for illustration purposes, GitHub
counterparts may use variables instead of hardcoded constants.
However, sometimes, a GitHub counterpart such as [39] does
the opposite by inlining the values of two constant Ô¨Åelds,
319
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. Num of AST editsPercentage of SO examples
0 50 100 1500 5 10 15 20 25 30adaptation
variation
(a) Distribution of AST edits20 40 60 80 1000 50 100 150 200
Code Size (LOC)Number of AST edits (median)adaptation
variation
(b) Code size vs. AST edits0 100 200 300 4000 2 04 06 08 0 1 0 0
Vote Score (i.e., u pvotes minus downvotes )Number of AST edits (median)adaptation
variation
(c) V ote score vs. AST edits
Fig. 2: Code size (LOC) and vote scores on the number of AST edits in a SO example
BUFFER SIZE andKB, since these Ô¨Åelds do not appear along
with the copied method, downloadWithHttpClient [40].
Miscellaneous. Adaptation types in this category do not have
a signiÔ¨Åcant impact on the reliability and functionality of
a SO example. However, several interesting cases are still
worth noting. In 91 inspected examples, GitHub counterparts
include comments to explain the reused code. Sometimes,
annotations such as @NotNull or@DroidSafe appear in
GitHub counterparts to document the constraints of code.
B. Automated Adaptation Categorization
Based on the manual inspection, we build a rule-based
classiÔ¨Åcation technique that automatically categorizes AST
edit operations generated by GumTree to different adaptation
types. GumTree supports four edit operations‚Äî insert ,delete ,
update , and move , described in Column GumT ree Edit
Operation in Table I. Given a set of AST edits, our technique
leverages both syntactic and semantic rules to categorize the
edits to 24 adaptation types. Column Rule in Table I describes
the implementation logic of categorizing each adaptation type.
Syntactic-based Rules. 16 adaptation types are detected based
on syntactic information, e.g., edit operation types, AST node
types and values, etc. Column Syntactic Predicate deÔ¨Ånes
such syntactic information, which is obtained using the built-in
functions provided by GumTree. For example, the rule insert
a Ô¨Ånal modiÔ¨Åer checks for an edit operation that inserts a
Modifier node whose value is final in a GitHub clone.
Semantic-based Rules. 8 adaptation types require leverag-
ing semantic information to be detected (Column Seman-
tic Predicate ). For example, the rule declare an unde-
clared variable checks for an edit operation that inserts a
VariableDeclaration node in the GitHub counterpart and
the variable name is used but not deÔ¨Åned in the SO exam-
ple. Our technique traverses ASTs to gather such semantic
information. For example, our AST visitor keeps track of all
declared variables when visiting a VariableDeclaration
AST node, and all used variables when visiting a Name node.
C. Accuracy of Adaptation Categorization
We randomly sampled another 100 SO examples and their
GitHub clones to evaluate our automated categorization tech-nique. To reduce bias, the second author who was not involved
in the previous manual inspection labeled the adaptation
types in this validation set. The ground truth contains 449
manually labeled adaptation types in 100 examples. Overall,
our technique infers 440 adaptation types with 98% precision
and 96% recall. In 80% of SO examples, our technique infers
all adaptation types correctly. In another 20% of SO examples,
it infers some but not all expected adaptation types.
Our technique infers incorrect or missing adaptation types
for two main reasons. First, our technique only considers
24 common adaptation types in Table I but does not handle
infrequent ones such as refactoring using lambda expressions
and rewriting ++i toi++ . Second, GumTree may generate
sub-optimal edit scripts with unnecessary edit operations in
about 5% of Ô¨Åle pairs, according to [13]. In such cases, our
technique may mistakenly report incorrect adaptation types.
IV . E MPIRICAL STUDY
A. How many edits are potentially required to adapt a SO
example?
We apply the adaptation categorization technique to quantify
the extent of adaptions and variations in the two datasets. We
measure AST edits between a SO example and its GitHub
counterpart. If a SO code example has multiple GitHub
counterparts, we use the average number. Overall, 13,595 SO
examples (96%) in the variation dataset include a median of
39 AST edits (mean 47). 556 SO examples (88%) in the
adaptation dataset include a median of 23 AST edits (mean
33). Figure 2a compares the distribution of AST edits in
these two datasets. In both datasets, most SO examples have
variations from their counterparts, indicating that integrating
them to production code may require some type of adaptations.
Figure 2b shows the median number of AST edits in SO
examples with different lines of code. We perform a non-
parametric local regression [41] on the example size and the
number of AST edits. As shown by the two lines in Figure 2b,
there is a strong positive correlation between the number of
AST edits and the SO example size in both datasets‚Äîlong SO
examples have more adaptations than short examples.
320
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. %##+#+(**$,,%,&+%,&$*)$&%$&$&)'+'%$+&&&$(%$($+'(#*$$'$
# (# $## $(# %## %(# &## &(# '##



 










 

	









 !


!	
 

"
 !


"
 








 






	

















		
	






		

(a) Adaptations: 629 explicitly attributed SO examples
($#('''$%)&&&*,))'%)$+&&&'*&$#$,&*(,&'))#**$($$*'*'$*$+))$#$*$&#%%$+*%,*,,#,$#)'&&)%%%&&&%#'*')
# %### '### )### +### $#### $%### $'###



 










 

	









 !


!	
 

"
 !


"
 








 






	




















		






	



(b) V ariations: 14,124 potentially reused SO examples
Fig. 3: Frequencies of categorized adaptation types in two datasets
Stack OverÔ¨Çow users can vote a post to indicate the appli-
cability and usefulness of the post. Therefore, votes are often
considered as the main quality metric of SO examples [42].
Figure 2c shows the median number of AST edits in SO
examples with different vote scores. Although the adaptation
dataset has signiÔ¨Åcantly higher votes than the variation dataset
(Figure 1c), there is no strong positive or negative correlation
between the AST edit and the vote score in both sets. This
implies that highly voted SO examples do not necessarily
require fewer adaptations than those with low vote scores.
B. What are common adaptation and variation types?
Figure 3 compares the frequencies of the 24 categorized
adaptation types (Column Adaptation T ype in Table I) for the
adaptation and variation datasets. If a SO code example has
multiple GitHub counterparts, we only consider the distinct
types among all GitHub counterparts to avoid the inÔ¨Çation
caused by repetitive variations among different counterparts.
The frequency distribution is consistent in most adaptation
types between the two datasets, indicating that variation
patterns resemble adaptation patterns . Participants in the user
study (Section VI) also appreciate being able to see variations
in similar GitHub code, since ‚Äúit highlights the best practices
followed by the community and prioritizes the changes that I
should make Ô¨Årst,‚Äù as P5 explained.
In both datasets, the most frequent adaptation type is change
a method call in the logic customization category. Other logic
customization types also occur frequently. This is because
SO examples are often designed for illustration purposes with
contrived usage scenarios and input data, and thus require fur-
ther logic customization. Rename is the second most common
adaptation type. It is frequently performed to make variable
and method names more readable for the speciÔ¨Åc context
of a GitHub counterpart. 35% and 14% of SO examples in
the variation dataset and the adaptation dataset respectively
include undeÔ¨Åned variables or local method calls, leading to
compilation errors. The majority of these compilation errors(60% and 61% respectively) could be resolved by simply
removing the statements using these undeÔ¨Åned variables or
method calls. 34% and 22% of SO examples in the two
datasets respectively include new conditionals (e.g., an if
check) to handle corner cases or reject invalid input data.
To understand whether the same type of adaptations appears
repetitively on the same SO example, we count the number
of adaptation types shared by different GitHub counterparts.
Multiple clones of the same SO example share at least one
same adaptation type in the 70% of the adaptation dataset and
74% of the variation dataset. In other words, the same type of
adaptations is recurring among different GitHub counterparts .
V. T OOL SUPPORT AND IMPLEMENTA TION
Based on insights of the adaptation analysis, we build
a Chrome extension called E XAMPLE STACK that visualizes
similar GitHub code fragments alongside a SO code example
and allows a user to explore variations of the SO example in
an adaptation-aware code template.
A.EXAMPLE STACK Tool Features
Suppose Alice is new to Android and she wants to read
some json data from the asset folder of her Android applica-
tion. Alice Ô¨Ånds a SO code example [43] that reads geometric
data from a speciÔ¨Åc Ô¨Åle, locations.json (xin Figure 4).
EXAMPLE STACK helps Alice by detecting other similar snip-
pets in real-world Android projects and by visualizing the hot
spots where adaptations and variations occur.
Browse GitHub counterparts with differences. Given the
SO example, E XAMPLE STACK displays Ô¨Åve similar GitHub
snippets and highlights their variations to the SO example ( z
in Figure 4). It also surfaces the GitHub link and reputation
metrics of the GitHub repository, including the number of
stars, contributors, and watches ( {in Figure 4). By default,
it ranks GitHub counterparts by the number of stars.
View hot spots with code options. EXAMPLE STACK lifts
a code template to illuminate unchanged code parts, while
abstracting modiÔ¨Åed code as hot spots to be Ô¨Ålled in ( yin
321
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply.  A Stack Over Ô¨Çow code example of interest
 Adaptation-aware code template
 A list of similar GitHub snippets
 GitHub snippet link & metrics Undo the previous selection Copy the template
 Colors of di Ô¨Äerent 
adaptation categories
Fig. 4: In the lifted template, common unchanged code is retained, while adapted regions are abstracted with hot spots .
Figure 4). The lifted template provides a bird‚Äôs-eye view and
serves as a navigation model to explore a variety of code
options used to customize the code example. In Figure 5,
Alice can click on each hot spot and view the code options
along with their frequencies in a drop-down menu. Code
options are highlighted in six distinct colors according to their
underlying adaptation intent ( ~in Figure 4). For example, the
second drop-down menu in Figure 5 indicates that two GitHub
snippets replace locations.json tolanguages.json to
read the language asset resources for supporting multiple
languages. This variation is represented as update a constant
value in the logic customization category.
Drop-down menu 1
Drop-down menu 2
Code option Frequency
Drop-down menu 3
Fig. 5: Alice can click on a hot spot and view potential code
options colored based on their underlying adaptation type.
Fill in hot spots with auto-selection. Instead of hard-
coding the asset Ô¨Åle name, Alice wants to make her pro-
gram more general‚Äîbeing able to read asset Ô¨Åles with any
given Ô¨Åle name. Therefore, Alice selects the code option,
jsonFileName , in the second drop-down menu in Figure 5,
which generalizes the hardcoded Ô¨Åle name to a variable.
EXAMPLE STACK automatically selects another code option,
String jsonFileName , in the Ô¨Årst drop-down menu in
Figure 5, since this code option declares the jsonFileNamevariable as the method parameter. This auto-selection feature
is enabled by def-use analysis, which correlates code options
based on the deÔ¨Ånitions and uses of variables (Section V-B).
By automatically relating code options in a template, Alice
does not have to manually click through multiple drop-down
menus to Ô¨Ågure out how to avoid compilation errors. Fig-
ure 6 shows the customized template based on the selected
jsonFileName option. The list of GitHub counterparts and
the frequencies of other code options are also updated accord-
ingly based on user selection. Alice can undo the previous
selection ( |in Figure 4) or copy the customized template to
her clipboard ( }in Figure 4).
User-selected adaptationAuto-selected adaptation
Updated list of similar GitHub snippets
Fig. 6: E XAMPLE STACK automatically updates the code tem-
plate based on user selection.
B. Template Construction
Diff generating and pruning. To lift an adaptation-aware
code template of a SO code example, E XAMPLE STACK Ô¨Årst
computes the AST differences between the SO example and
each GitHub clone using GumTree. E XAMPLE STACK prunes
322
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. the edit operations by Ô¨Åltering out inner operations that modify
the children of other modiÔ¨Åed nodes. For example, if an insert
operation inserts an AST node whose parent is also inserted by
another insert, the Ô¨Årst inner insert will be removed, since its
edit is entailed by the second outer insert. Given the resulting
tree edits, E XAMPLE STACK keeps track of the change regions
in the SO example and how each region is changed.
Diff grouping. EXAMPLE STACK groups change regions to
decide where to place hot spots in a SO example and what code
options to display in a hot spot. If two change regions are the
same, they are grouped together. If two change regions overlap,
EXAMPLE STACK merges the overlapping change locations
into a bigger region enclosing both and groups them together.
For example, consider a diff that changes a= b toa= b+c ,
and another diff that completely changes a=b too.foo() .
Simply abstracting the changed code in these two diffs without
any alignment will overlay two hot spots in the template,
a= b and the smaller diff is shadowed by the bigger diff
in visualization. E XAMPLE STACK avoids this conÔ¨Çict by re-
calibrating the Ô¨Årst change region from a= b toa=b .
Option generating and highlighting. For each group of
change regions, E XAMPLE STACK replaces the corresponding
location in the SO example with a hot spot and attaches a
drop-down menu. E XAMPLE STACK displays both the original
content in the SO example and contents of the matched GitHub
snippet regions as options in each drop-down menu. E XAM -
PLE STACK then uses the adaptation categorization technique
to detect the underlying adaptation types of code options. We
use six distinct background colors to illuminate the categories
in Table I, which makes it easier for developers to recognize
different intent. The color scheme is generated using Color-
Brewer [44] to ensure the primary visual differences between
different categories in the template.
EXAMPLE STACK successfully lifts code templates in all
14,124 SO examples. On average, a lifted template has 81
lines of code (median 41) with 13 hot spots (median 12) to
Ô¨Åll in. On average, 4 code options (median 2) is displayed in
the drop-down menu of each hot spot.
VI. U SER STUDY
We conducted a within-subjects user study with sixteen Java
programmers to evaluate the usefulness of E XAMPLE STACK .
We emailed students in a graduate-level Software Engineering
class and research labs in the CS department at UCLA. We
did a background survey and excluded volunteers with no Java
experience, since our study tasks required users to read code
examples in Java. Fourteen participants were graduate students
and two were undergraduate students. Eleven participants had
two to Ô¨Åve years of Java experience, while the other Ô¨Åve were
novice programmers with one-year Java experience, showing a
good mix of different levels of Java programming experience.
In each study session, we Ô¨Årst gave a Ô¨Åfteen-minute tutorial
of our tool. Participants then did two code reuse tasks with
and without E XAMPLE STACK . When not using our tool (i.e.,
the control condition), participants were allowed to search
online for other code examples, which is commonly done inreal-world programming workÔ¨Çow [3]. To mitigate learning
effects, the order of assigned conditions and tasks were coun-
terbalanced across participants through random assignment. In
each task, we asked participants to mark which parts of a SO
code example they would like to change and explain how they
would change. We did not require participants to fully integrate
a code example to a target program or make it compile,
since our goal was to investigate whether E XAMPLE STACK
could inspire developers with new adaptations that they may
otherwise ignore, rather than automated code integration. Each
task was stopped after Ô¨Åfteen minutes. At the end, we did a
post survey to solicit feedback.
Table II describes the four code reuse tasks and also the
user study results. Column Assignment in each condition
shows the participant ID and the task order. ‚ÄúP5-A ‚Äù means
the task was done by the Ô¨Åfth participant as her Ô¨Årst task.
Column Adaptation shows the number of different types
of adaptations each participant made. Overall, participants
using E XAMPLE STACK made three times more code hardening
adaptations (15 vs. 5) and twice more logic customization
adaptations (43 vs. 20), considering more edge cases and dif-
ferent usage scenarios. For instance, in Task III, all users in the
experimental group added a null check for the input byte array
after seeing other GitHub examples, while only one user in the
control group did so. P14 wrote, ‚Äú I would have completely
forgotten about the null check without seeing it in a couple
of examples. ‚Äù On average, participants using E XAMPLE STACK
made more adaptations (8.0 vs. 5.5) in more diverse categories
(2.8 vs. 2.2). Wilcoxon signed-rank tests indicate that the
mean differences in adaptation numbers and categories are
both statistically signiÔ¨Åcant (p=0.042 and p=0.009). We do
not argue that making more adaptations are always better.
Instead, we want to emphasize that, by seeing commonalities
and variations in similar GitHub code, participants focus more
on code safety and logic customization, instead of making
shallow adaptations such as variable renaming only. The
average task completion time is 725 seconds (SD=186) and
770 seconds (SD=185) with and without E XAMPLE STACK .
We do not claim E XAMPLE STACK saves code reuse time,
since it is designed as an informative tool when developers
browse online code examples, rather than providing direct
code integration support in an IDE. Figure 7 shows the code
templates generated by E XAMPLE STACK , not including the
one in Task II due to its length (79 lines).
How do you like or dislike viewing similar GitHub code
alongside a SO example? In the post survey, all participants
found it very useful to see similar GitHub code for three main
reasons. First, viewing the commonality among similar code
examples helped users quickly understand the essence of a
code example. P6 described this as ‚Äú the fast path to reach
consensus on a particular operation. ‚Äù Second, the GitHub
variants reminded users of some points they may otherwise
miss. Third, participants felt more conÔ¨Ådent of a SO example
after seeing how similar code was used in GitHub repositories.
P9 stated that, ‚Äú [it is] reassuring to know that the same code is
used in production systems and to know the common pitfalls. ‚Äù
323
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. TABLE II: Code reuse tasks and user study results
ID Desir ed Function & SO Example LOC Clone#Contr ol Experiment
Assignment Adaptation Time(s) Assignment Adaptation Time(s)
Task ICalculate the geographic distance
between two GPS coordinates [45]12 2P5-A refactor(5), logic(1) 458 P2-A harden(1), logic(1), misc(2) 870
P7-A refactor(1), logic(2), misc(1) 900 P3-B refactor(6), logic(4), misc(3) 900
P12-B refactor(2), harden(1) 900 P10-B refactor(5), logic(2), misc(1) 366
P16-B refactor(7) 727 P15-A refactor(10), logic(14), misc(3) 842
Task IIget the relative path between
two Ô¨Åles [46]74 2P3-A refactor(5), logic(1), exception(2), misc(3) 900 P1-B refactor(3), harden(1), logic(2) 640
P8-A harden(1) 900 P6-A harden(4), logic(3) 900
P11-B none 621 P9-A harden(4), logic(2) 900
P15-Brefactor(13), harden(1), logic(5),
exception(1), misc(1)863 P13-Brefactor(3), logic(2), exception(1),
misc(1)900
Task IIIencode a byte array to a
hexadecimal string [47]12 17P1-A refactor(5), harden(1) 652 P4-A refactor(5), harden(1), misc(1) 667
P6-B refactor(1), misc(1) 900 P8-B refactor(2), harden(1), misc(2) 548
P9-B harden(1), logic(1) 635 P12-A refactor(3), harden(2), misc(1) 748
P13-A refactor(3), misc(1) 900 P14-B refactor(3), harden(1), misc(1) 700
Task IVadd animation to an Android
view [48]29 4P2-B refactor(3), logic(1) 441 P5-B refactor(1), logic(3) 478
P4-B refactor(1), compile(1), misc(1) 900 P7-B refactor(2), compile(3), logic(3) 887
P10-A refactor(3), logic(5) 900 P11-A refactor(1), logic(3) 617
P14-A refactor(2), logic(4) 862 P16-A refactor(6), logic(4), misc(1) 773
How do you like or dislike interacting with a code
template? Participants liked the code template, since it showed
the essence of a code example and made it easier to see subtle
changes, especially in lengthy code examples. Participants also
found displaying the frequency count of different adaptations
very useful. P5 explained, ‚Äú it highlights the best practices
followed by the community and also prioritizes the changes
that I should make Ô¨Årst. ‚Äù However, we also observed that,
when there were only a few GitHub counterparts, some
participants inspected individual GitHub counterparts directly
rather than interacting with the code template.
How do you like or dislike color-coding different adapta-
tion types? Though the majority of participants conÔ¨Årmed the
usefulness of this feature, six participants felt confused or dis-
tracted by the color scheme, since it was difÔ¨Åcult to remember
these colors during navigation. Three of them considered some
adaptations (e.g., renaming) trivial and suggested to allow
users to hide adaptations of no interest to avoid distraction.
When would you use EXAMPLE STACK ?Six participants
would like to use E XAMPLE STACK when learning APIs, since
it provided multiple GitHub code fragments that use the
same API in different contexts with critical safety checks and
exception handling. Five participants mentioned that E XAM -
PLE STACK would be most useful for a lengthy example. P4
wrote, ‚Äú the tool is very useful when the code is longer and hard
to spot what to change at a glance. ‚Äù Two participants wanted
to use E XAMPLE STACK to identify missing points and assess
different solutions, when writing a large-scale robust project.
In addition, P15 and P16 suggested to display similar
code based on semantic similarity rather than just syntactic
similarity, in order to Ô¨Ånd alternative implementations and
potential optimization opportunities. P13 suggested to add
indicators about whether a SO example is compilable or not.
VII. T HREA TS TO VALIDITY
In terms of internal validity , our variation dataset may
include coincidental clones, since GitHub developers may
write code with similar functionality as a SO example. Tomitigate this issue, we compare their timestamps and remove
those GitHub clones that are created before the correspond-
ing SO examples. We further create an adaptation set with
explicitly attributed SO examples and compare the analysis
results of both datasets for cross-validation. Figure 3 shows
that the distribution of common adaptation patterns is similar
between these two datasets. It would be valuable and useful
to guide code adaptation by identifying the commonalities and
variations between similar code, even for clones coming from
independent but similar implementations.
In terms of external validity , when identifying common
adaptation types, we follow the standard qualitative analysis
procedure [27] to continuously inspect more samples till the
insights are converging. However, we may still miss some
adaptation types due to the small sample size. To mitigate this
issue, the second author who was not involved in the manual
inspection further manually labeled 100 more samples to
validate the adaptation taxonomy (Section III-C). In addition,
user study participants may not be representative of real Stack
OverÔ¨Çow users. To mitigate this issue, we recruit both novice
and experienced developers who use Stack OverÔ¨Çow on a
regular basis. To generalize our Ô¨Åndings to industrial settings,
further studies with professional developers are needed.
In terms of construct validity , in the user study, we only
measure whether E XAMPLE STACK inspires participants to
identify and describe adaptation opportunities. We do not ask
participants to fully integrate a SO example to a target program
nor make it compile. Therefore, our Ô¨Ånding does not imply
time reduction in code integration.
VIII. R ELA TED WORK
Quality assessment of SO examples. Our work is inspired
by previous studies that Ô¨Ånd SO examples are incomplete
and inadequate [7]‚Äì[9, 12, 23, 24, 29]. Subramanian and
Holmes Ô¨Ånd that the majority of SO snippets are free standing
statements with no class or method headers [23]. Zhou et
al. Ô¨Ånd that 86 of 200 accepted SO posts use deprecated APIs
but only 3 of them are reported by other programmers [9].
324
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. (a) Compute distance between two coordinates [45]
 (b) Encode byte array to a hex string [47]
 (c) Add animation to an Android view [48]
Fig. 7: E XAMPLE STACK code template examples
Fischer et al. Ô¨Ånd that 29% of security-related code in SO
is insecure and could potentially be copied to one millionAndroid apps [8]. Zhang et al. contrast SO examples with API
usage patterns mined from GitHub and detect potential API
misuse in 31% of SO posts [7]. These Ô¨Åndings motivate ourinvestigation of adaptations and variations of SO examples.
Stack OverÔ¨Çow usage and attribution. Our work is motivated
by the Ô¨Ånding that developers often resort to online Q&A
forums such as Stack OverÔ¨Çow [3]‚Äì[6]. Despite the wide usageof SO, most developers are not aware of the SO licensingterms nor attribute to the code reused from SO [5, 6, 12]. Only1.8% of GitHub repositories containing code from SO followthe licensing policy properly [5]. Almost one half developersadmit copying code from SO without attribution and two thirdsare not aware of the SO licensing implications. Based on theseÔ¨Åndings, we carefully construct a comprehensive dataset ofreused code, including both explicitly attributed SO examples
and potentially reused ones using clone detection, timestamp
analysis, and URL references. Origin analysis can also beapplied to match SO snippets with GitHub Ô¨Åles [49]‚Äì[52].
SO snippet retrieval and code integration. Previous support
for reusing code from SO mostly focuses on helping develop-
ers locate relevant posts or snippets from the IDE [15, 53]‚Äì[55]. For example, Prompter retrieves related SO discussionsbased on the program context in Eclipse. SnipMatch sup-ports light-weight code integration by renaming variables ina SO snippet based on corresponding variables in a targetprogram [15]. Code correspondence techniques [14, 56] match
code elements (e.g., variables, methods) to decide which code
to copy, rename, or delete during copying and pasting. Ourwork differs by focusing on analysis of common adaptationsand variations of SO examples.
Change types and taxonomy. There is a large body of litera-
ture for source code changes during software evolution [57]‚Äì
[59]. Fluri et al. present a Ô¨Åne-grained taxonomy of codechanges such as changing the return type and renaming aÔ¨Åeld, based on differences in abstract syntax trees [18]. Kim
et al. analyze changes on ‚Äúmicro patterns‚Äù [60] in Java using
software evolution data [17]. These studies investigate generalchange types in software evolution, while we quantify commonadaptation and variation types using SO and GitHub code.
Program differencing and change template. Diff tools com-
pute program differences between two programs [13, 61]‚Äì
[64]. However, they do not support analysis of one examplewith respect to multiple counterparts simultaneously. Lin et
al. align multiple programs and visualize their variations [65].However, they do not lift a code template to summarize thecommonalities and variations between similar code. Several
techniques construct code templates for the purpose of code
search [66] or code transformation [67]. Glassman et al. de-sign an interactive visualization called E
XAMPLORE to help
developers comprehend hundreds of similar but different APIusages in GitHub [68]. Given an API method of interest,
E
XAMPLORE instantiates a pre-deÔ¨Åned API usage skeleton
and Ô¨Ålls in details such as various guard conditions andsucceeding API calls. E
XAMPLE STACK is not limited to API
usage and does not require a pre-deÔ¨Åned skeleton.
IX. C ONCLUSION
This paper provides a comprehensive analysis of common
adaptation and variation patterns of online code examples byboth overapproximating and underapproximating reused codefrom Stack OverÔ¨Çow to GitHub. Our quantitative analysis
shows that the same type of adaptations and variations appears
repetitively among different GitHub clones of the same SO
example, and variation patterns resemble adaptation patterns.
This implies that different GitHub developers may applysimilar adaptations to the same example over and over againindependently. This further motivates the design of E
XAM -
PLE STACK , a Chrome extension that guides developers in
adapting online code examples by unveiling the commonalitiesand variations of similar past adaptations. A user study withsixteen developers demonstrates that E
XAMPLE STACK helps
developers focus more on code safety and logic customizationduring code reuse, resulting in more complete and robust code.
Currently, E
XAMPLE STACK only visualizes potential adap-
tations of a SO example within a web browser. As future work,we plan to build an Eclipse plugin that enables semi-automatedintegration of online code examples. It would be worthwhileto investigate how such a tool Ô¨Åts developer workÔ¨Çow and to
compare it with other code integration techniques [14, 15].
A
CKNOWLEDGMENT
Thanks to anonymous participants for the user study and
anonymous reviewers for their valuable feedback. This work is
supported by NSF grants CCF-1764077, CCF-1527923, CCF-1460325, CCF-1723773, ONR grant N00014-18-1-2037, IntelCAPA grant, and DARPA MUSE program.
325
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] M. Umarji, S. E. Sim, and C. Lopes, ‚ÄúArchetypal internet-scale source
code searching,‚Äù in IFIP International Conference on Open Source
Systems . Springer, 2008, pp. 257‚Äì263.
[2] R. E. Gallardo-V alencia and S. Elliott Sim, ‚ÄúInternet-scale code
search,‚Äù in Proceedings of the 2009 ICSE Workshop on Search-Driven
Development-Users, Infrastructure, Tools and Evaluation . IEEE Com-
puter Society, 2009, pp. 49‚Äì52.
[3] J. Brandt, P . J. Guo, J. Lewenstein, M. Dontcheva, and S. R. Klemmer,
‚ÄúTwo studies of opportunistic programming: interleaving web foraging,
learning, and writing code,‚Äù in Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems . ACM, 2009, pp. 1589‚Äì1598.
[4] C. Sadowski, K. T. Stolee, and S. Elbaum, ‚ÄúHow developers search for
code: a case study,‚Äù in Proceedings of the 2015 10th Joint Meeting on
Foundations of Software Engineering . ACM, 2015, pp. 191‚Äì201.
[5] S. Baltes and S. Diehl, ‚ÄúUsage and attribution of stack overÔ¨Çow code
snippets in github projects,‚Äù arXiv preprint arXiv:1802.02938 , 2018.
[6] Y . Wu, S. Wang, C.-P . Bezemer, and K. Inoue, ‚ÄúHow do developers uti-
lize source code from stack overÔ¨Çow?‚Äù Empirical Software Engineering ,
pp. 1‚Äì37, 2018.
[7] T. Zhang, G. Upadhyaya, A. Reinhardt, H. Rajan, and M. Kim, ‚ÄúAre
code examples on an online q&a forum reliable?: a study of api misuse
on stack overÔ¨Çow,‚Äù in Proceedings of the 40th International Conference
on Software Engineering . ACM, 2018, pp. 886‚Äì896.
[8] F. Fischer, K. B ¬®ottinger, H. Xiao, C. Stransky, Y . Acar, M. Backes, and
S. Fahl, ‚ÄúStack overÔ¨Çow considered harmful? the impact of copy&paste
on android application security,‚Äù in Security and Privacy (SP), 2017
IEEE Symposium on . IEEE, 2017, pp. 121‚Äì136.
[9] J. Zhou and R. J. Walker, ‚ÄúApi deprecation: a retrospective analysis and
detection method for code examples on the web,‚Äù in Proceedings of the
2016 24th ACM SIGSOFT International Symposium on Foundations of
Software Engineering . ACM, 2016, pp. 266‚Äì277.
[10] C. Treude and M. P . Robillard, ‚ÄúUnderstanding stack overÔ¨Çow code
fragments,‚Äù in Proceedings of the 33rd International Conference on
Software Maintenance and Evolution . IEEE, 2017.
[11] H. Sajnani, V . Saini, J. Svajlenko, C. K. Roy, and C. V . Lopes,
‚ÄúSourcerercc: Scaling code clone detection to big-code,‚Äù in Software
Engineering (ICSE), 2016 IEEE/ACM 38th International Conference on .
IEEE, 2016, pp. 1157‚Äì1168.
[12] L. An, O. Mlouki, F. Khomh, and G. Antoniol, ‚ÄúStack overÔ¨Çow: a code
laundering platform?‚Äù in Software Analysis, Evolution and Reengineer-
ing (SANER), 2017 IEEE 24th International Conference on . IEEE,
2017, pp. 283‚Äì293.
[13] J.-R. Falleri, F. Morandat, X. Blanc, M. Martinez, and M. Monperrus,
‚ÄúFine-grained and accurate source code differencing,‚Äù in Proceedings
of the 29th ACM/IEEE international conference on Automated software
engineering . ACM, 2014, pp. 313‚Äì324.
[14] R. Cottrell, R. J. Walker, and J. Denzinger, ‚ÄúSemi-automating small-
scale source code reuse via structural correspondence,‚Äù in Proceedings
of the 16th ACM SIGSOFT International Symposium on Foundations of
software engineering . ACM, 2008, pp. 214‚Äì225.
[15] D. Wightman, Z. Ye, J. Brandt, and R. V ertegaal, ‚ÄúSnipmatch: Using
source code context to enhance snippet retrieval and parameterization,‚Äù
inProceedings of the 25th annual ACM symposium on User interface
software and technology . ACM, 2012, pp. 219‚Äì228.
[16] M. Fowler, Refactoring: Improving the Design of Existing Code .
Addison-Wesley Professional, 2000.
[17] S. Kim, K. Pan, and E. J. Whitehead Jr, ‚ÄúMicro pattern evolution,‚Äù in
Proceedings of the 2006 international workshop on Mining software
repositories . ACM, 2006, pp. 40‚Äì46.
[18] B. Fluri and H. C. Gall, ‚ÄúClassifying change types for qualifying change
couplings,‚Äù in ICPC ‚Äô06: Proceedings of the 14th IEEE International
Conference on Program Comprehension . Washington, DC, USA: IEEE
Computer Society, 2006, pp. 35‚Äì45.
[19] E. Kalliamvakou, G. Gousios, K. Blincoe, L. Singer, D. M. German, and
D. Damian, ‚ÄúThe promises and perils of mining github,‚Äù in Proceedings
of the 11th working conference on mining software repositories . ACM,
2014, pp. 92‚Äì101.
[20] C. V . Lopes, P . Maj, P . Martins, V . Saini, D. Yang, J. Zitny, H. Sajnani,
and J. Vitek, ‚ÄúD ¬¥ej`avu: a map of code duplicates on github,‚Äù Proceedings
of the ACM on Programming Languages , vol. 1, p. 28, 2017.[21] G. Gousios and D. Spinellis, ‚ÄúGhtorrent: Github‚Äôs data from a Ô¨Årehose,‚Äù
inMining software repositories (msr), 2012 9th ieee working conference
on. IEEE, 2012, pp. 12‚Äì21.
[22] Stack OverÔ¨Çow data dump , 2016, https://archive.org/details/
stackexchange, accessed on Oct 17, 2016.
[23] S. Subramanian and R. Holmes, ‚ÄúMaking sense of online code snippets,‚Äù
inProceedings of the 10th Working Conference on Mining Software
Repositories . IEEE Press, 2013, pp. 85‚Äì88.
[24] D. Yang, A. Hussain, and C. V . Lopes, ‚ÄúFrom query to usable code: an
analysis of stack overÔ¨Çow code snippets,‚Äù in Proceedings of the 13th
International Workshop on Mining Software Repositories . ACM, 2016,
pp. 391‚Äì402.
[25] S. Subramanian, L. Inozemtseva, and R. Holmes, ‚ÄúLive api documenta-
tion,‚Äù in Proceedings of the 36th International Conference on Software
Engineering . ACM, 2014, pp. 643‚Äì652.
[26] D. Yang, P . Martins, V . Saini, and C. Lopes, ‚ÄúStack overÔ¨Çow in github:
any snippets there?‚Äù in 2017 IEEE/ACM 14th International Conference
on Mining Software Repositories (MSR) . IEEE, 2017, pp. 280‚Äì290.
[27] B. L. Berg, H. Lune, and H. Lune, Qualitative Research Methods for
the Social Sciences . Pearson Boston, MA, 2004, vol. 5.
[28] E. Torlak and S. Chandra, ‚ÄúEffective interprocedural resource leak detec-
tion,‚Äù in Proceedings of the 32nd ACM/IEEE International Conference
on Software Engineering-V olume 1 . ACM, 2010, pp. 535‚Äì544.
[29] B. Dagenais and M. P . Robillard, ‚ÄúRecovering traceability links between
an api and its learning resources,‚Äù in 2012 34th International Conference
on Software Engineering (ICSE) . IEEE, 2012, pp. 47‚Äì57.
[30] Get OS-level system information , 2008, https://stackoverÔ¨Çow.com/
questions/61727.
[31] A GitHub clone that gets the CPU usage , 2014, https:
//github.com/jomis/nomads/blob/master/nomads-framework/src/main/
java/at/ac/tuwien/dsg/utilities/PerformanceMonitor.java \#L44-L63.
[32] Adding new paths for native libraries at runtime in Java , 2013, https:
//stackoverÔ¨Çow.com/questions/15409446.
[33] A GitHub clone that adds new paths for native libraries at runtime
in Java , 2014, https://github.com/armint/Ô¨Åresight-java/blob/master/
src/main/java/org/Ô¨Årepick/Ô¨Åresight/utils/SharedLibLoader.java \#L131-
L153.
[34] How to get IP address of the device from code? , 2012, https://
stackoverÔ¨Çow.com/questions/7899226.
[35] A GitHub clone about how to get IP address from an Android de-
vice. , 2014, https://github.com/kalpeshp0310/GoogleNews/blob/master/
app/src/main/java/com/kalpesh/googlenews/utils/Utils.java \#L24-L39.
[36] JSlider question: Position after leftclick , 2009, https://stackoverÔ¨Çow.
com/questions/518672.
[37] A GitHub clone about JSlide , 2014, https://github.com/changkon/
Pluripartite/tree/master/src/se206/a03/MediaPanel.java \#L329-L339.
[38] Another GitHub clone about JSlide , 2014, https://github.com/changkon/
Pluripartite/tree/master/src/se206/a03/MediaPanel.java \#L343-L353.
[39] A GitHub clone that downloads videos from YouTube , 2014,
https://github.com/instance01/Y outubeDownloaderScript/blob/master/
IY outubeDownloader.java \#L148-L193.
[40] Youtube data API : Get access to media stream and play (JAVA) , 2011,
https://stackoverÔ¨Çow.com/questions/4834369.
[41] W. M. Shyu, E. Grosse, and W. S. Cleveland, ‚ÄúLocal regression models,‚Äù
inStatistical models in S . Routledge, 2017, pp. 309‚Äì376.
[42] S. M. Nasehi, J. Sillito, F. Maurer, and C. Burns, ‚ÄúWhat makes a good
code example?: A study of programming q&a in stackoverÔ¨Çow,‚Äù in Soft-
ware Maintenance (ICSM), 2012 28th IEEE International Conference
on. IEEE, 2012, pp. 25‚Äì34.
[43] Add Lat and Long to ArrayList , 2016, https://stackoverÔ¨Çow.com/
questions/37273871.
[44] ColorBrewer: Color Advice for Maps , 2018, http://colorbrewer2.org.
[45] Calculate distance in meters when you know longitude and latitude in
java , 2017, https://stackoverÔ¨Çow.com/questions/837957.
[46] Construct a relative path in Java from two absolute paths , 2015, https:
//stackoverÔ¨Çow.com/questions/3054692.
[47] How to use SHA-256 with Android , 2014, https://stackoverÔ¨Çow.com/
questions/25803281.
[48] How can I add animations to existing UI components? , 2015, https:
//stackoverÔ¨Çow.com/questions/33464536.
[49] Q. Tu and M. W. Godfrey, ‚ÄúAn integrated approach for studying
architectural evolution,‚Äù in Program Comprehension, 2002. Proceedings.
10th International Workshop on . IEEE, 2002, pp. 127‚Äì136.
326
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. [50] M. Godfrey and Q. Tu, ‚ÄúTracking structural evolution using origin
analysis,‚Äù in Proceedings of the international workshop on Principles
of software evolution . ACM, 2002, pp. 117‚Äì119.
[51] L. Zou and M. W. Godfrey, ‚ÄúDetecting merging and splitting using origin
analysis,‚Äù in null. IEEE, 2003, p. 146.
[52] M. W. Godfrey and L. Zou, ‚ÄúUsing origin analysis to detect merging
and splitting of source code entities,‚Äù IEEE Transactions on Software
Engineering , vol. 31, no. 2, pp. 166‚Äì181, 2005.
[53] A. Bacchelli, L. Ponzanelli, and M. Lanza, ‚ÄúHarnessing stack overÔ¨Çow
for the ide,‚Äù in Proceedings of the Third International Workshop on
Recommendation Systems for Software Engineering . IEEE Press, 2012,
pp. 26‚Äì30.
[54] L. Ponzanelli, A. Bacchelli, and M. Lanza, ‚ÄúSeahawk: Stack overÔ¨Çow
in the ide,‚Äù in Proceedings of the 2013 International Conference on
Software Engineering . IEEE Press, 2013, pp. 1295‚Äì1298.
[55] L. Ponzanelli, G. Bavota, M. Di Penta, R. Oliveto, and M. Lanza,
‚ÄúMining stackoverÔ¨Çow to turn the ide into a self-conÔ¨Ådent programming
prompter,‚Äù in Proceedings of the 11th Working Conference on Mining
Software Repositories . ACM, 2014, pp. 102‚Äì111.
[56] R. Holmes and R. J. Walker, ‚ÄúSupporting the investigation and planning
of pragmatic reuse tasks,‚Äù in Proceedings of the 29th international
conference on Software Engineering . IEEE Computer Society, 2007,
pp. 447‚Äì457.
[57] S. Kim, K. Pan, and E. E. J. Whitehead, Jr., ‚ÄúMemories of bug Ô¨Åxes,‚Äù
inProceedings of the 14th ACM SIGSOFT International Symposium
on Foundations of Software Engineering , ser. SIGSOFT ‚Äô06/FSE-14.
New Y ork, NY , USA: ACM, 2006, pp. 35‚Äì45. [Online]. Available:
http://doi.acm.org/10.1145/1181775.1181781
[58] M. Fischer, J. Oberleitner, J. Ratzinger, and H. Gall, ‚ÄúMining evolution
data of a product family,‚Äù in MSR ‚Äô05: Proceedings of the 2005
International Workshop on Mining Software Repositories . New Y ork,
NY , USA: ACM, 2005, pp. 1‚Äì5.
[59] D. Dig and R. Johnson, ‚ÄúHow do APIs evolve? a story of refactoring,‚Äù
Journal of software maintenance and evolution: Research and Practice ,
vol. 18, no. 2, pp. 83‚Äì107, 2006.
[60] J. Y . Gil and I. Maman, ‚ÄúMicro patterns in java code,‚Äù ACM SIGPLAN
Notices , vol. 40, no. 10, pp. 97‚Äì116, 2005.
[61] W. Miller and E. W. Myers, ‚ÄúA Ô¨Åle comparison program,‚Äù Software:
Practice and Experience , vol. 15, no. 11, pp. 1025‚Äì1040, 1985.
[62] W. Yang, ‚ÄúIdentifying syntactic differences between two programs,‚Äù
Software ‚Äì Practice & Experience , vol. 21, no. 7, pp. 739‚Äì755, 1991.
[Online]. Available: citeseer.ist.psu.edu/yang91identifying.html
[63] S. S. Chawathe, A. Rajaraman, H. Garcia-Molina, and J. Widom,
‚ÄúChange detection in hierarchically structured information,‚Äù in SIGMOD
‚Äô96: Proceedings of the 1996 ACM SIGMOD International Conference
on Management of Data . New Y ork, NY , USA: ACM, 1996, pp. 493‚Äì
504.
[64] B. Fluri, M. Wuersch, M. PInzger, and H. Gall, ‚ÄúChange distilling:
Tree differencing for Ô¨Åne-grained source code change extraction,‚Äù IEEE
Transactions on software engineering , vol. 33, no. 11, 2007.
[65] Y . Lin, Z. Xing, Y . Xue, Y . Liu, X. Peng, J. Sun, and W. Zhao, ‚ÄúDetecting
differences across multiple instances of code clones.‚Äù in ICSE , 2014, pp.
164‚Äì174.
[66] T. Zhang, M. Song, J. Pinedo, and M. Kim, ‚ÄúInteractive code review
for systematic changes,‚Äù in Proceedings of the 37th International Con-
ference on Software Engineering-V olume 1 . IEEE Press, 2015, pp.
111‚Äì122.
[67] N. Meng, M. Kim, and K. S. McKinley, ‚ÄúLase: locating and applying
systematic edits by learning from examples,‚Äù in Proceedings of the 2013
International Conference on Software Engineering . IEEE Press, 2013,
pp. 502‚Äì511.
[68] E. L. Glassman, T. Zhang, B. Hartmann, and M. Kim, ‚ÄúVisualizing api
usage examples at scale,‚Äù in Proceedings of the 2018 CHI Conference
on Human Factors in Computing Systems . ACM, 2018, p. 580.
327
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:42 UTC from IEEE Xplore.  Restrictions apply. 