A User-Guided Approach to Program Analysis
Ravi Mangal, Xin Zhang, Aditya V. Noriy, Mayur Naik
Georgia Institute of Technology, USAyMicrosoft Research, UK
{ravi.mangal, xin.zhang, naik}@gatech.edu adityan@microsoft.com
ABSTRACT
Program analysis tools often produce undesirable output
due to various approximations. We present an approach
and a system Eugene that allows user feedback to guide
such approximations towards producing the desired output.
We formulate the problem of user-guided program analy-
sis in terms of solving a combination of hard rules and soft
rules: hard rules capture soundness while soft rules capture
degrees of approximations and preferences of users. Our
technique solves the rules using an o-the-shelf solver in a
manner that is sound (satises all hard rules), optimal (max-
imally satises soft rules), and scales to real-world analy-
ses and programs. We evaluate Eugene on two dierent
analyses with labeled output on a suite of seven Java pro-
grams of size 131{198 KLOC. We also report upon a user
study involving nine users who employ Eugene to guide an
information-ow analysis on three Java micro-benchmarks.
In our experiments, Eugene signicantly reduces misclassi-
ed reports upon providing limited amounts of feedback.
Categories and Subject Descriptors
D.2.4 [ Software Engineering ]: Software/Program Veri-
cation
Keywords
User feedback, program analysis, report classication
1. INTRODUCTION
Program analysis tools often make approximations. These
approximations are a necessary evil as the program analysis
problem is undecidable in general. There are also several
specic factors that drive various assumptions and approx-
imations: program behaviors that the analysis intends to
check may be impossible to dene precisely (e.g., what con-
stitutes a security vulnerability), computing exact answers
may be prohibitively costly (e.g., worst-case exponential inthe size of the analyzed program), parts of the analyzed pro-
gram may be missing or opaque to the analysis (e.g., if the
program is a library), and so on. As a result, program analy-
sis tools often produce false positives (or false bugs) and false
negatives (or missed bugs), which are absolutely undesirable
to users. Users today, however, lack the means to guide such
tools towards what they believe to be \interesting" analysis
results, and away from \uninteresting" ones.
This paper presents a new approach to user-guided pro-
gram analysis . It shifts decisions about the kind and degree
of approximations to apply in an analysis from the analysis
writer to the analysis user . The user conveys such decisions
in a natural fashion, by giving feedback about which analysis
results she likes or dislikes, and re-running the analysis.
Our approach is a radical departure from existing ap-
proaches, allowing users to control both the precision and
scalability of the analysis. It oers a dierent, and poten-
tially more useful, notion of precision|one from the stand-
point of the analysis user instead of the analysis writer. It
also allows the user to control scalability, as the user's feed-
back enables tailoring the analysis to the precision needs of
the analysis user instead of catering to the broader precision
objectives of the analysis writer.
Our approach and tool called Eugene satises three use-
ful goals: (i) expressiveness : it is applicable to a variety of
analyses, (ii) automation : it does not require unreasonable
eort by analysis writers or analysis users, and (iii) precision
and scalability : it reports interesting analysis results from a
user's perspective and it handles real-world programs. Eu-
gene achieves each of these goals as described next.
Expressiveness. An analysis in Eugene is expressed as
logic inference rules with optional weights ( x3). In the ab-
sence of weights, rules become \hard rules", and the analysis
reduces to a conventional one where a solution that satises
all hard rules is desired. Weighted rules, on the other hand,
constitute\soft rules"that generalize a conventional analysis
in two ways: they enable to express dierent degrees of ap-
proximation, and they enable to incorporate feedback from
the analysis user that may be at odds with the assumptions
of the analysis writer. The desired solution of the resulting
analysis is one that satises all hard rules and maximizes the
weight of satised soft rules. Such a solution amounts to re-
specting all indisputable conditions of the analysis writer,
while maximizing precision preferences of the analysis user.
Automation. Eugene takes as input analysis rules from
the analysis writer, and automatically learns their weights
using an oine learning algorithm (x4.2). Eugene also
requires analysis users to specify which analysis results they
like or dislike, and automatically generalizes this feedback
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ESEC/FSE‚Äô15 , August 30 ‚Äì September 4, 2015, Bergamo, Italy
ACM. 978-1-4503-3675-8/15/08...$15.00
http://dx.doi.org/10.1145/2786805.2786851
4621package org. apache . ftpserver ;
2public class RequestHandler {
3 Socket m_controlSocket ;
4 FtpRequestImpl m_request ;
5 FtpWriter m_writer ;
6 BufferedReader m_reader ;
7 boolean m_isConnectionClosed ;
8 public FtpRequest getRequest () {
9 return m_request ;
10 }
11 public void close () {
12 synchronized (this ) {
13 i f( m_isConnectionClosed )
14 return ;
15 m_isConnectionClosed = true ;
16 }
17 m_request . clear ();
18 m_request = null ;
19 m_writer . close ();
20 m_writer = null ;
21 m_reader . close ();
22 m_reader = null ;
23 m_controlSocket . close ();
24 m_controlSocket = null ;
25 }
26 }
Figure 1: Java code snippet of Apache FTP server.
using an online inference algorithm (x4.1). The analysis
rules (hard and soft) together with the feedback from the
user (modeled as soft rules) forms a probabilistic constraint
system that Eugene solves eciently, as described next.
Precision andScalability. Eugene maintains precision
by ensuring integrity and optimality in solving the rules
without sacricing scalability. Integrity (i.e., satisfying hard
rules) amounts to respecting indisputable conditions of the
analysis. Optimality (i.e., maximally satisfying soft rules)
amounts to generalizing user feedback eectively. Together
these aspects ensure precision. Satisfying all hard rules and
maximizing the weight of satised soft rules corresponds to
the well-known MaxSAT problem [35]. Eugene leverages
o-the-shelf solvers to solve MaxSAT instances in a manner
that is integral, optimal, and scalable.
We demonstrate the precision and scalability of Eugene
on two analyses, namely, datarace detection, and monomor-
phic call site inference, applied to a suite of seven Java pro-
grams of size 131{198 KLOC. We also report upon a user
study involving nine users who employ Eugene to guide an
information-ow analysis on three Java micro-benchmarks.
In these experiments, Eugene signicantly reduces misclas-
sied reports upon providing limited amounts of feedback.
In summary, our work makes the following contributions:
1. We present a new approach to user-guided program anal-
ysis that shifts decisions about approximations in an anal-
ysis from the analysis writer to the analysis users, allow-
ing users to tailor its precision and cost to their needs.
2. We formulate our approach in terms of solving a combina-
tion of hard rules and soft rules, which enables leveraging
o-the-shelf solvers for weight learning and inference that
scale without sacricing integrity or optimality.
3. We show the eectiveness of our approach on diverse anal-
yses applied to a suite of real-world programs. The ap-
proach signicantly reduces the number of misclassied
reports by using only a modest amount of user feedback.
2. MOTIV ATING EXAMPLE
We illustrate our approach using the example of apply-
ing the static race detection tool Chord [30] to a real-world
multi-threaded Java program, Apache FTP server [1].Analysis Relations:
next(p1;p2) (program point p1is immediate successor
of program point p2)
parallel (p1;p2) (dierent threads may reach program
points p1and p2in parallel)
mayAlias (p1;p2) (instructions at program points p1and p2
may access the same memory location, and
constitute a possible datarace)
guarded (p1;p2) (at least one common lock guards program
points p1and p2)
race(p1;p2) (datarace may occur between dierent
threads while executing the instructions at
program points p1and p2)
Analysis Rules:
parallel (p1;p2)^next(p3;p1)) parallel (p3;p2) (1)
parallel (p1;p2)) parallel (p2;p1) (2)0
@parallel (p1;p2)^
mayAlias (p1;p2)^
:guarded (p1;p2)1
A) race(p1;p2) (3)
Figure 2: Simplied race detection analysis.
Figure 1 shows a code fragment from the program. The
RequestHandler class is used to handle client connections
and an object of this class is created for every incoming
connection to the server. The close () method is used to
clean up and close an open client connection, while the
getRequest () method is used to access the mrequest eld.
Both these methods can be invoked from various compo-
nents of the program (not shown), and thus can be simulta-
neously executed by multiple threads in parallel on the same
RequestHandler object. To ensure that this parallel execu-
tion does not result in any dataraces, the close () method
uses a boolean ag misConnectionClosed . If this ag is
set, all calls to close () return without any further updates.
If the ag is not set, then it is rst updated to true, followed
by execution of the clean-up code (lines 17{24). To avoid
dataraces on the ag itself, it is read and updated while hold-
ing a lock on the RequestHandler object (lines 12{16). All
the subsequent code in close () is free from dataraces since
only the rst call to close () executes this section. How-
ever, note that an actual datarace still exists between the
two accesses to eld mrequest on line 9 and line 18.
We motivate our approach by contrasting the goals and
capabilities of a writer of an analysis , such as the race detec-
tion analysis in Chord, with those of a user of the analysis ,
such as a developer of the Apache FTP server.
The role of the analysis writer. The designer or writer
of a static analysis tool, say Alice, strives to develop an anal-
ysis that is precise yet scales to real-world programs, and is
widely applicable to a large variety of programs. In the case
of Chord, this translates into a race detection analysis that is
context-sensitive but path-insensitive. This is a common de-
sign choice for balancing precision and scalability of static
analyses. The analysis in Chord is expressed using Data-
log, a declarative logic programming language, and Figure 2
shows a simplied subset of the logical inference rules used
by Chord. The actual analysis implementation uses a larger
set of more elaborate rules but the rules shown here suce
for the discussion. These rules are used to produce output
relations from input relations, where the input relations ex-
press known program facts and output relations express the
analysis outcome. These rules express the idioms that the
463E1: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler. m_isConnectionClosedorg.apache.ftpserver.RequestHandler: 13org.apache.ftpserver.RequestHandler: 15Eliminated RacesR1: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_requestorg.apache.ftpserver.RequestHandler: 9org.apache.ftpserver.RequestHandler: 18R2: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_requestorg.apache.ftpserver.RequestHandler: 17org.apache.ftpserver.RequestHandler: 18R3: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_writerorg.apache.ftpserver.RequestHandler: 19org.apache.ftpserver.RequestHandler: 20R4: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_readerorg.apache.ftpserver.RequestHandler: 21org.apache.ftpserver.RequestHandler: 22R5: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_controlSocketorg.apache.ftpserver.RequestHandler: 23org.apache.ftpserver.RequestHandler: 24
Detected Races
(a) Before feedback.
R1: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_requestorg.apache.ftpserver.RequestHandler: 9org.apache.ftpserver.RequestHandler: 18
Detected Races
E2: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_requestorg.apache.ftpserver.RequestHandler: 17org.apache.ftpserver.RequestHandler: 18E3: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_writerorg.apache.ftpserver.RequestHandler: 19org.apache.ftpserver.RequestHandler: 20E4: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_readerorg.apache.ftpserver.RequestHandler: 21org.apache.ftpserver.RequestHandler: 22E5: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler.m_controlSocketorg.apache.ftpserver.RequestHandler: 23org.apache.ftpserver.RequestHandler: 24E1: Race on Ô¨Åeld org.apache.ftpserver.RequestHandler. m_isConnectionClosedorg.apache.ftpserver.RequestHandler: 13org.apache.ftpserver.RequestHandler: 15Eliminated Races (b) After feedback.
Figure 3: Race reports produced for Apache FTP server. Each report species the eld involved in the race,
and line numbers of the program points with the racing accesses. The user feedback is to \dislike" report R2.
analysis writer Alice deems to be the most important for cap-
turing dataraces in Java programs. For example, Rule (1) in
Figure 2 conveys that if a pair of program points ( p1;p2) can
execute in parallel, and if program point p3is an immedi-
ate successor of p1, then (p3;p2) are also likely to happen in
parallel. Rule (2) conveys that the parallel relation is sym-
metric. Via Rule (3), Alice expresses the idiom that only
program points not guarded by a common lock can be po-
tentially racing. In particular, if program points ( p1;p2) can
happen in parallel, can access the same memory location,
and are not guarded by any common lock, then there is a
potential datarace between p1andp2.
The role of the analysis user. The user of a static
analysis tool, say Bob, ideally wants the tool to produce
exact (i.e., sound and complete) results on his program.
This allows him to spend his time on xing the bugs in
the program instead of classifying the reports generated by
the tool as spurious or real. In our example, suppose that
Bob runs Chord on the Apache FTP server program in Fig-
ure 1. Based on the rules in Figure 2, Chord produces
the list of datarace reports shown in Figure 3(a). Reports
R1{R5 are identied as potential dataraces in the program,
whereas for report E1, Chord detects that the accesses to
misConnectionClosed on lines 13 and 15 are guarded by
a common lock, and therefore do not constitute a datarace.
Typically, the analysis user Bob is well-acquainted with the
program being analyzed, but not with the details of under-
lying analysis itself. In this case, given his familiarity with
the program, it is relatively easy for Bob to conclude that
the code from line 17{24 in the body of the close () method
can never be executed by multiple threads in parallel, and
thus reports R2{R5 are spurious.
The mismatch between analysis writers and users.
The design decisions of the analysis writer Alice have a di-
rect impact on the precision and scalability of the analysis.
The datarace analysis in Chord is imprecise for various the-
oretical and usability reasons.
First, the analysis must scale to large programs. For
this reason, it is designed to be path-insensitive and over-approximates the possible thread interleavings. To eliminate
spurious reports R2{R5, the analysis would need to only
consider feasible thread interleavings by accurately track-
ing control-ow dependencies across threads. However, such
precise analyses do not scale to programs of the size of
Apache FTP server, which comprises 130 KLOC.
Scalability concerns aside, relations such as mayAlias are
necessarily inexact as the corresponding property is undecid-
able for Java programs. Chord over-approximates this prop-
erty by using a context-sensitive but ow-insensitive pointer
analysis, resulting in spurious pairs ( p1;p2) in this relation,
which in turn are reported as spurious dataraces.
Third, the analysis writer may lack sucient information
to design a precise analysis, because the program behav-
iors that the analysis intends to check may be vague or am-
biguous. For example, in the case of datarace analysis, real
dataraces can be benign in that they do not aect the pro-
gram's correctness [32]. Classifying such reports typically
requires knowledge about the program being analyzed.
Fourth, the program specication can be incomplete. For
instance, the race in report R1 above could be harmful
but impossible to trigger due to timing reasons extrinsic to
Apache FTP server, such as the hardware environment.
In short, while the analysis writer Alice can inuence the
design of the analysis, she cannot foresee every usage sce-
nario or program-specic tweaks that might improve the
analysis. Conversely, analysis user Bob is acquainted with
the program under analysis, and can classify the analysis re-
ports as spurious or real. But he lacks the tools or expertise
to suppress the spurious bugs by modifying the underlying
analysis based on his intuition and program knowledge.
Closing the gap between analysis writers and users.
Our user-guided approach aims to empower the analysis user
Bob to adjust the underlying analysis as per his demands
without involving the analysis writer Alice. Our system,
Eugene , achieves this by automatically incorporating user
feedback into the analysis. The user provides feedback in
a natural fashion, by \liking" or \disliking" a subset of the
analysis reports, and re-running the analysis. For example,
464(relation)r2R (argument) a2A=V[C
(constant) c2C (fact)t2T=RA
(variable)v2V (ground fact) g2G=RC
(valuation) 2V!C (weight)w2R+ = (0;1]
(hard rules) H::=fh1;:::;hng; h ::=Vn
i=1ti)Wm
i=1t0
i
(soft rules) S::=fs1;:::;sng; s ::= (h;w)
(probabilistic analysis) C::= (H;S)
(analysis input, output) P;QG
Figure 4: Syntax of a probabilistic analysis.
when presented with the datarace reports in Figure 3(a),
Bob might start inspecting from the rst report. This re-
port is valid and Bob might choose to either like or ignore
this report. Liking a report conveys that Bob accepts the
reported bug as a real one and would like the analysis to
generate more similar reports, thereby reinforcing the be-
havior of the underlying analysis that led to the generation
of this report. However, suppose that Bob ignores the rst
report, but indicates that he dislikes the second report by
clicking on the corresponding icon. Re-running Chord after
providing this feedback produces the reports shown in Fig-
ure 3(b). While the true report R1 is generated in this run as
well, all the remaining spurious reports are eliminated. This
highlights a key strength of our approach: Eugene not only
incorporates user feedback, but it also generalizes the feed-
back to other similar results of the analysis. Reports R2{R5
are correlated and are spurious for the same root cause: the
code from line 17{24 in the body of the close () method
can never be executed by multiple threads in parallel. Bob's
feedback on report R2 conveys to the underlying analysis
that lines 17 and 18 cannot execute in parallel. Eugene is
able to generalize this feedback automatically and conclude
that none of the lines from 17{24 can execute in parallel.
In the following section, we describe the underlying details
ofEugene that allow it to incorporate user feedback and
generalize it automatically to other reports.
3. ANALYSIS SPECIFICATION
Eugene uses a constraint-based approach wherein anal-
yses are written in a declarative constraint language. Con-
straint languages have been widely adopted to specify a
broad range of analyses. The declarative nature of such
languages allows analysis writers to focus on the high-level
analysis logic while delegating low-level implementation de-
tails to o-the-shelf constraint solvers. In particular, Dat-
alog, a logic programming language, is widely used in such
approaches. Datalog has been shown to suce for express-
ing a variety of analyses, including pointer and call-graph
analyses [7,40,41,44], concurrency analyses [30,31], security
analyses [11,27], and reection analysis [25].
Existing constraint-based approaches allow specifying only
hard rules where an acceptable solution is one that satises
all the rules. However, this is insucient for incorporating
feedback from the analysis user that may be at odds with the
assumptions of the analysis writer. To enable the exibil-
ity of having conicting constraints, it is necessary to allow
soft rules that an acceptable solution can violate. Our user-
guided approach is based on such a constraint language that
extends Datalog rules with weights. We refer to analyses
specied in this extended language as probabilistic analyses .
Probabilistic analysis syntax. Aprobabilistic analysis
C, dened in Figure 4, consists of a set of hard rules Hand
a set of soft rules S. A hard rule h2His an inference(ground clause) ::=Wn
i=1:gi_Wm
i=1g0
i
(hard clauses) ::=Vn
i=1i
(soft clauses)  ::=Vn
i=1(i;wi)
MaxSAT (;Vn
i=1(i;wi)) =
8
<
:unsat if@Q:Qj=
Qsuch that
Qj=and
n
i=1fwijQj=igis maximized
otherwise
Qj=Vn
i=1i i8i:Qj=i
Qj=Wn
i=1:gi_Wm
i=1g0
ii9i:gi=2Qor9i:g0
i2Q
(a) Syntax and semantics of a MaxSAT formula.
J(H;S)K= ( JHK;JSK)
Jfh1;:::;hngK=Vn
i=1JhiK
Jfs1;:::;sngK=Vn
i=1JsiK
JhK=V
JhK
J(h;w)K=V
(JhK;w)
JVn
i=1ti)Wm
i=1t0
iK= (Wn
i=1:JtiK_Wm
i=1Jt0
iK)
Jr(a1;:::;an)K=r(Ja1K;:::; JanK)
JvK=(v)
JcK=c
(b) Compiling a probabilistic analysis to MaxSAT.
Figure 5: Semantics of a probabilistic analysis.
ruleA)B, whereAis a conjunction of facts and Bis a
disjunction of facts. An analysis facttcomprises a relation
name and a tuple of arguments, which include variables and
constants; a fact is a ground fact gwhen all arguments are
constants. Our setting subsumes logical analyses written in
Datalog, where all rules are Horn rules, i.e., rules with at
most one disjunct on the right hand side ( jBj= 1).
A soft rules2Sis a hard rule along with a positive weight
w. A weight has a natural probabilistic interpretation, where
the condence associated with a soft rule increases with the
weight. For the precise semantics of weights, the reader is
referred to [10]. In the absence of soft rules, the analysis
reduces to a logical analysis consisting of only hard rules.
The analysis input (a program P) and the analysis output
(a resultQ) are represented as sets of ground facts.
Probabilistic analysis semantics. We dene the se-
mantics of a probabilistic analysis in terms of an optimiza-
tion extension of the Boolean satisability (SAT) problem,
called the weighted partial maximum satisability (MaxSAT)
problem [35], shown as procedure MaxSAT in Figure 5(a). This
procedure takes as input a MaxSAT formula comprising a
set of hard clauses and a set of soft clauses  . These are
counterparts of hard rules and soft rules in a probabilistic
analysis. The key dierence is that all facts in each (hard or
soft) MaxSAT clause are grounded, whereas analysis rules
can contain ungrounded facts. The MaxSAT procedure views
each unique ground fact in the input MaxSAT formula as
a separate Boolean variable. The procedure returns either:
(1)unsat , if no assignment of truth values to the Boolean
variables satises the set of hard clauses , or (2) a solution
Q, denoting the assignment \ g:(g2Q) ?true:false", i.e., it
sets variables corresponding to ground facts contained in Q
to true, and the rest to false. The solution Qnot only sat-
ises all hard clauses in but it also maximizes the sum of
the weights of satised soft clauses in  . Note that Qis not
necessarily unique; two solutions Q1andQ2areequivalent
ifWeight (Q1; ) =Weight (Q2; ).
The compilation of a probabilistic analysis to a MaxSAT
formula is shown in Figure 5(b). The compilation proce-
465Input facts:
next(18;17) mayAlias (18;17) guarded (13;13)
next(19;18) mayAlias (20;19) guarded (15;15)
next(20;19) mayAlias (22;21) guarded (15;13):::
MaxSAT formula:
w1: (:parallel (17;17)_:next(18;17)_parallel (18;17))^
(:parallel (18;17)_parallel (17;18)) ^
w1: (:parallel (17;18)_:next(18;17)_parallel (18;18))^
w1: (:parallel (18;18)_:next(19;18)_parallel (19;18))^
(:parallel (19;18)_parallel (18;19)) ^
w1: (:parallel (18;19)_:next(19;18)_parallel (19;19))^
w1: (:parallel (19;19)_:next(20;19)_parallel (20;19))^
:parallel (18;17)_ : mayAlias (18;17)_
guarded (18;17)_ race(18;17)
^

:parallel (20;19)_ : mayAlias (20;19)_
guarded (20;19)_ race(20;19)
^
w2::race(18;17) ^:::
Output facts (before feedback):
parallel (18;9)parallel (20;19)race(18;9)race(20;19):::
parallel (18;17)parallel (22;21)race(18;17)race(22;21)
Output facts (after feedback):
parallel (18;9)race(18;9):::
Figure 6: Probabilistic analysis example.
dure grounds each analysis rule into a set of correspond-
ing MaxSAT clauses. In particular, the conversion JhK=V
JhKgrounds analysis rule hby enumerating all possible
groundings of variables to constants, producing a MaxSAT
clause for each unique valuation to the variables in h.
There are a number of solvers [8,14,26,33,34,37] that e-
ciently compile a probabilistic analysis down into a MaxSAT
formula, and solve the corresponding formula to produce the
desired output that satises all the hard rules and maximizes
the weight of the satised soft rules. Eugene treats the un-
derlying solver as a black-box, and can use any of these
solvers to solve the constraints of a probabilistic analysis.
Example. Equipped with the concept of probabilistic
analysis, we can now describe how Eugene works on the
race detection example from x2. Figure 6 shows a subset
of the input and output facts as well as a snippet of the
MaxSAT formula constructed for the example. The input
facts are derived from the analyzed program (Apache FTP
server) and comprise the next,mayAlias , and guarded rela-
tions. In all these relations, the domain of program points is
represented by the corresponding line number in the code.
Note that all the analysis rules expressed in Figure 2 are hard
rules since existing tools like Chord do not accept soft rules.
However, we assume that when this analysis is fed to Eu-
gene , rule (1) is specied to be soft by analysis writer Alice,
which captures the fact that the parallel relation is impre-
cise.Eugene automatically learns the weight of this rule to
bew1from training data (see x4.2 for details). Given these
input facts and rules, the MaxSAT problem to be solved is
generated by grounding the analysis rules, and a snippet of
the constructed MaxSAT formula is shown in Figure 6. Ig-
noring the clause enclosed in the box, solving this MaxSAT
formula (without the boxed clause) yields output facts, a
subset of which is shown under \Output facts (before feed-
back)" in Figure 6. The output includes multiple spurious
races like race(18;17),race(20;19), and race(22;21).
As described inx2, when analysis user Bob provides feed-
back that race(18;17) is spurious, Eugene suppresses all
spurious races while retaining the real race race(18;9).Eu-
gene achieves this by incorporating the user feedback itselfas a soft rule, represented by the boxed clause :race(18;17)
in Figure 6. The weight for such user feedback is also learned
during the training phase. Assuming the weight w2of the
feedback clause is higher than the weight w1of rule (1)|a
reasonable choice that emphasizes Bob's preferences over Al-
ice's assumptions|the MaxSAT semantics ensures that the
solver prefers violating rule (1) over violating the feedback
clause. When the MaxSAT formula (with the boxed clause)
in Figure 6 is then fed to the solver, the output solution
violates the clause w1: (:parallel (17;17)_:next(18;17)_
parallel (18;17)) and does not produce facts parallel (18;17)
and race(18;17) in the output. Further, all the facts that
are dependent on parallel (18;17) are not produced either.1
This implies that facts like parallel (19;18), parallel (20;19),
parallel (22;21) are not produced, and therefore race(20;19)
andrace(22;21) are also suppressed. Thus, Eugene is able
to generalize based on user feedback. The degree of gener-
alization depends on the quality of the weights assigned or
learned for the soft rules.
4. THE Eugene SYSTEM
This section describes our system Eugene for user-guided
program analysis. Its workow, shown in Figure 7, com-
prises an online inference stage and an oine learning stage.
In the online stage, Eugene takes the probabilistic analy-
sis specication together with a program Pthat an analysis
user Bob wishes to analyze. The inference engine, described
inx4.1, uses these inputs to produce the analysis output Q.
Further, the online stage allows Bob to provide feedback on
the produced output Q. In particular, Bob can indicate the
output queries he likes ( QL) or dislikes ( QD), and invoke the
inference engine with QLandQDas additional inputs. The
inference engine incorporates Bob's feedback as additional
soft rules in the probabilistic analysis specication used for
producing the new result Q. This interaction continues until
Bob is satised with the analysis output.
The accuracy of the produced results in the online stage is
sensitive to the weights assigned to the soft rules. Manually
assigning weights is not only inecient, but in most cases
it is also infeasible since weight assignment needs analysis
of data. Therefore, Eugene provides an oine stage that
automatically learns the weights of soft rules in the proba-
bilistic analysis specication. In the oine stage, Eugene
takes a logical analysis specication from analysis writer Al-
ice and training data in the form of a set of input programs
and desired analysis output on these programs. These inputs
are fed to the learning engine described in x4.2. The logi-
cal analysis specication includes hard rules as well as rules
marked as soft whose weights need to be learnt. The learn-
ing engine infers these weights to produce the probabilistic
analysis specication. The learning engine ensures that the
learnt weights maximize the likelihood of the training data
with respect to the probabilistic analysis specication.
4.1 Online Component of Eugene : Inference
Algorithm 1 describes the online component Inference of
Eugene .Inference takes as input, a probabilistic analysis
(H;S) (with learnt weights), and the program Pto be ana-
lyzed. First, in line 6, the algorithm augments the hard and
soft rules (H;S) of the analysis with the inputs P,QL,QDto
1This is due to implicit soft rules that negate each output
relation, such as w0::parallel (p1;p2) wherew0< w 1, in
order to obtain the least solution.
466P: Program to be analyzedProbabilistic analysis speciÔ¨ÅcationInferenceEngineLearningEngineLogical analysis speciÔ¨Åcation
AnalysiswriterAliceAnalysisuserBobOFFLINEONLINEQL, QD: Parts of output that user likes vs. dislikesQ: Output of analysis on program P(P‚Äô, Q‚Äô): Desired analysisoutput on training programFigure 7: Workow of the Eugene system for user-guided program analysis.
Algorithm 1 Inference : Online component of Eugene .
1:PARAM (wl;wd): Weights of liked and disliked queries.
2:INPUTC= (H;S): Probabilistic analysis.
3:INPUTP: Program to analyze.
4:OUTPUT Q: Final output of user-guided analysis.
5:QL:=;;QD:=;
6:H0:=H[P
7:repeat
8:S0:=S[f(g;wl)jg2QLg[f (:g;wd)jg2QDg
9:Q:=solve (H0;S0)
10:QL:=PositiveUserFeedback (Q)
11:QD:=NegativeUserFeedback (Q)
12:untilQL[QD=;
the analysis, to obtain an extended set of rules ( H0;S0) (lines
6 and 8). Notice that the user feedback QL(liked queries)
andQD(disliked queries) are incorporated as soft rules in
the extended rule set. Each liked query feedback is assigned
the xed weight wl, while each disliked query feedback is
assigned weight wd(line 8). Weights wlandwdare learnt
in the oine stage and fed as parameters to Algorithm 1.
Instead of using xed weights for the user feedback, two
other options are: (a) treating user feedback as hard rules,
and (b) allowing a dierent weight for each query feedback.
Option (a) does not account for users being wrong, leaving
no room for the inference engine to ignore the feedback if
necessary. Option (b) is too ne-grained, requiring learning
separate weights for each query. We therefore take a middle
ground between these two extremes.
Next, in line 9, the algorithm invokes a weighted con-
straints solver [26] with the extended set of rules. Note that
Eugene treats the solver as a black-box and any suitable
solver suces. The solver produces a solution Qthat satis-
es all the hard rules in the extended set, while maximizing
the weight of satised soft rules. The solution Qis then
presented to Bob who can give his feedback by liking or dis-
liking the queries (lines 10{11). The sets of liked and disliked
queries,QLandQD, are used to further augment the hard
and soft rules ( H;S) of the analysis. This loop (lines 7{12)
continues until no further feedback is provided by Bob.
4.2 OfÔ¨Çine Component of Eugene : Learning
Algorithm 2 describes the oine component Learning of
Eugene . It is an adaptation of [38] to our application.
Learning takes a probabilistic analysis C= (H;S) with arbi-
trary weights, a set of programs Pand the desired analysis
outputQas input, and outputs a probabilistic analysis C0
with learnt weights. Without loss of generality, we assume
thatPis encoded as a set of hard clauses and is part of H.
As a rst step, in line 5, Learning assigns initial weights
to all the soft rules. The initial weight of a rule h2SisAlgorithm 2 Learning : Oine component of Eugene .
1:PARAM: rate of change of weight of soft rules.
2:INPUTC= (H;S): Initial probabilistic analysis.
3:INPUTQ: Desired analysis output.
4:OUTPUT C0: Probabilistic analysis with learnt weights.
5:S0:=f(h;w0)j9w: (h;w)2Sandw0=log(n1=n2)g
6:wheren1=jGroundings (h;Q)j,n2=jViolations (h;Q)j.
7:repeat
8:C0:= (H;S0)
9:Q0:=Inference (C0;;)
10:S:=S0
11:S0:=f(h;w0)j9w: (h;w)2Sand
12: w0=w+(n1 n2)g
13: wheren1=jViolations (h;Q0)j,n2=jViolations (h;Q)j.
14:untilS0=S
15: Violations (h;Q) =fJhKjQ6j=JhKg
16: Groundings (h;Q) =fJhKjQj=JhKg
computed as a log of the ratio of the number of groundings
ofhsatised by the desired output Qto the number of
violations of hbyQ(lines 5{6). In other words, the initial
weight captures the log odds of a rule being true in the
training data. Note that, in the case Violations (h;Q) = 0,
it is substituted by a suitably small value [38].
Next, in line 9, the probabilistic analysis C0(dened in line
8) with the initialized weights is fed to the Inference proce-
dure described in Algorithm 1. This produces a solution Q0
that is integral and optimal for the probabilistic analysis C0.
The solution Q0is then used to update the weights of the
soft rules. The weights are updated according to the formu-
lae in lines 10-13. The basic intuition for these update rules
is as follows: weights learnt by the learning algorithm must
be such that the output solution of the Inference algorithm
for the training program is as close to the desired output Q
as possible. Towards that end, if the current output Q0pro-
duces more violations for a rule than the desired output, it
implies that the rule needs to be strengthened and its weight
should be increased. On the other hand, if the current out-
putQ0produces fewer violations for a rule then Q, the rule
needs to be weakened and its weight should be reduced. The
formula in the algorithm has exactly the same eect as de-
scribed here. Moreover, the rate of change of weights can be
controlled by an input parameter . The learning process
continues iteratively until the learnt weights do not change.
In practice, the learning process can be terminated after a
xed number of iterations, or when the dierence in weights
between successive iterations does not change signicantly.
5. EMPIRICAL EV ALUATION
We implemented Eugene atop Chord [29], an extensible
program analysis framework for Java bytecode that supports
467writing analyses in Datalog. In our evaluation, we investi-
gate the following research questions:
RQ1: Does using Eugene improve analysis precision for
practical analyses applied to real-world programs? How
much feedback is needed for the same, and how does the
amount of provided feedback aect the precision?
RQ2: Does Eugene scale to large programs? Does the
amount of feedback inuence the scalability?
RQ3: How feasible is it for users to inspect analysis out-
put and provide useful feedback to Eugene ?
5.1 Experimental Setup
We performed two dierent studies with Eugene : a con-
trol study and a user study.
First, to evaluate the precision and scalability of Eugene ,
we performed a control study using two realistic analyses ex-
pressed in Datalog applied to seven Java benchmark pro-
grams. The goal of this study is to thoroughly investigate
the performance of Eugene in realistic scenarios and with
varying amounts of feedback. To practically enable the eval-
uation of Eugene over a large number of a data-points in the
(benchmark;analysis; #feedback ) space, this study uses a
more precise analysis, instead of a human user, as an oracle
for generating the feedback to be provided. This study helps
us evaluate RQ1 andRQ2 .
Second, to evaluate the practical usability of Eugene when
human analysis users are in the loop, we conducted a user
study with nine users who employed Eugene to guide an
information-ow analysis on three benchmark programs. In
contrast to the rst study, the human users provide the feed-
back in this case. This study helps us evaluate RQ3 .
All experiments were run using Oracle HotSpot JVM 1.6.0
on a Linux server with 64GB RAM and 3.0GHz processors.
Clients. Our two analyses in the rst study (Table 1) are
datarace detection ( datarace ) and monomorphic call site in-
ference ( polysite ), while we use an information-ow ( infoow )
analysis for the user study. Each of these analyses is sound,
and composed of other analyses written in Datalog. For
example, datarace includes a thread-escape analysis and a
may-happen-in-parallel analysis, while polysite and infoow
include a pointer analysis and a call-graph analysis. The
pointer analysis used here is a ow/context-insensitive, eld-
sensitive, Andersen-style analysis using allocation site heap
abstraction [20]. The datarace analysis is from [30], while the
polysite analysis has been used in previous works [22,42,45]
to evaluate pointer analyses. The infoow analysis only
tracks explicit information ow similar to the analysis de-
scribed in [23]. For scalability reasons, all these analyses
are context-, object-, and ow-insensitive, which is the main
source of false positives reported by them.
Benchmarks. The benchmarks for the rst study (up-
per seven rows of Table 2) are 131{198 KLOC in size, and
include programs from the DaCapo suite [5] ( antlr ,avrora ,
luindex ,lusearch ) and from past works that address our two
analysis problems.
The benchmarks for the user study (bottom three rows
of Table 2) are 0.6{4.2 KLOC in size, and are drawn from
Securibench Micro [3], a micro-benchmark suite designed to
exercise dierent parts of a static information-ow analyzer.
Methodology. We describe the methodology for the of-
ine (learning) and online (inference) stages of Eugene .
Oine stage. We rst converted the above three logical
analyses into probabilistic analyses using the oine train-Table 1: Statistics of our probabilistic analyses.
rules input relations output relations
datarace 30 18 18
polysite 76 50 42
infoow 76 52 42
ing stage of Eugene . To avoid selection bias, we used a
set of small benchmarks for training instead of those in Ta-
ble 2. Specically, we used elevator and tsp(100 KLOC
each) from [2]. While the training benchmarks are smaller
and fewer than the testing benchmarks, they are sizable,
realistic, and disjoint from those in the evaluation, demon-
strating the practicality of our training component. Besides
the sample programs, the training component of Eugene
also requires the expected output of the analyses on these
sample programs. Since the main source of false positives in
our analyses is the lack of context- and object-sensitivity, we
used context- and object-sensitive versions of these analyses
as oracles for generating the expected output. Specically,
we usedk-object-sensitive versions [28] with cloning depth
k=4. Note that these oracle analyses used for generating the
training data comprise their own approximations (for exam-
ple, ow-insensitivity), and thus do not produce the absolute
ground truth. Using better training data would only imply
that the weights learnt by Eugene are more reective of the
ground truth, leading to more precise results.
Online stage. We describe the methodology for the on-
line stage separately for the control study and the user study.
Control study methodology. To perform the control
study, we started by running the inference stage of Eugene
on our probabilistic analyses ( datarace andpolysite ) with no
feedback to generate the initial set of reports for each bench-
mark. Next, we simulated the process of providing feedback
by: (i) randomly choosing a subset of the initial set of re-
ports, (ii) classifying each of the reports in the chosen subset
as spurious or real, and (iii) re-running the inference stage
ofEugene on the probabilistic analyses with the labeled
reports in the chosen subset as feedback. To classify the
reports as spurious or real, we used the results of k-object-
sensitive versions of our client analyses as ground truth. In
other words, if a report contained in the chosen subset is also
generated by the precise version of the analysis, it is clas-
sied as a real report, otherwise it is labeled as a spurious
report. For each ( benchmark;analysis ) pair, we generated
random subsets that contain 5%, 10%, 15%, and 20% of the
initial reports. This allows us to study the eect of varying
amounts of feedback on Eugene 's performance. Addition-
ally,Eugene can be sensitive to not just the amount of feed-
back, but also to the actual reports chosen for feedback. To
discount this eect, for a given ( benchmark;analysis ) pair,
and a given feedback subset size, we ran Eugene thrice us-
ing dierent random subsets of the given size in each run.
Randomly choosing feedback ensures that we conservatively
estimate the performance of Eugene . Finally, we evalu-
ated the quality of the inference by comparing the output of
Eugene with the output generated by the k-object-sensitive
versions of our analyses with k=4.
User study methodology. For the user study, we en-
gaged nine users, all graduate students in computer science,
to run Eugene oninfoow analysis. Each user was assigned
two benchmarks from the set of fsecbench1 ,secbench2 ,
secbench3g, such that each of these benchmarks was as-
signed to six users in total. The users interacted with Eugene
by rst running it without any feedback so as to produce
468Table 2: Benchmark statistics. Columns \total" and \app" are with and without JDK library code.
brief description # classes # methods bytecode (KB) source (KLOC)
app total app total app total app total
antlr parser/translator generator 111 350 1,150 2,370 128 186 29 131
avrora microcontroller simulator/analyzer 1,158 1,544 4,234 6,247 222 325 64 193
ftp Apache FTP server 93 414 471 2,206 29 118 13 130
hedc web crawler from ETH 44 353 230 2,134 16 140 6 153
luindex document indexing and search tool 206 619 1,390 3,732 102 235 39 190
lusearch text indexing and search tool 219 640 1,399 3,923 94 250 40 198
weblech website download/mirror tool 11 576 78 3,326 6 208 12 194
secbench1 securibench micro 1 4 5 10 13 0.3 0.3 0.08 0.6
secbench2 securibench micro 2 3 4 9 12 0.2 0.2 0.07 0.6
secbench3 securibench micro 3 2 17 4 46 0.3 1.25 0.06 4.2
0 338 324 111 1824 79 0
0%20%40%60%80%100%false reports
eliminated
0
antlr700
avrora119
ftp153
hedc2597
luindex183
lusearch10
weblech0%
20%
40%
60%
80%
100%true reports
retained√Ébaseline
false
reports
√Ébaseline
true
reports
Figure 8: Results of Eugene ondatarace analysis.
the initial set of reports. The users then analyzed these pro-
duced reports, and were asked to provide any eight reports
with their corresponding label (spurious or real) as feedback.
Also, for each benchmark, we recorded the time spent by
each user in analyzing the reports and generating the feed-
back. Next, Eugene was run with the provided feedback,
and the produced output was compared with manually gen-
erated ground truth for each of the benchmarks.
We next describe the results of evaluating Eugene 's pre-
cision ( RQ1 ), scalability ( RQ2 ), and usability ( RQ3 ).
5.2 Precision of Eugene
The analysis results of our control study under varying
amounts of feedback are shown in Figures 8 and 9. In these
gures, \baseline false reports" and \baseline true reports"
are the number of false and true reports produced when
Eugene is run without any feedback. The light colored bars
above and below the x-axis indicate the % of false reports
eliminated and the % of true reports retained, respectively,
when the % of feedback indicated by the corresponding dark
colored bars is provided. For each benchmark, the feedback
percentages increase from left to right, i.e., 5% to 20%. Ide-
ally, we want all the false reports to be eliminated and all
the true reports to be retained, which would be indicated by
the light color bars extending to 100% on both sides.
Even without any feedback, our probabilistic analyses are
already fairly precise and sophisticated, and eliminate all
except the non-trivial false reports. Despite this, Eugene
helps eliminate a signicant number of such hard-to-refute
reports. On average 70% of the false reports are eliminated
across all our experiments with 20% feedback. Likewise im-
portantly, on average 98% of the true reports are retained
when 20% feedback is provided. Also, note that with 5%
feedback the percentage of false reports eliminated falls to
44% on average, while that of true reports retained is 94%.
A ner-grained look at the results for individual benchmarks
and analyses reveals that in many cases, increasing feedback
only leads to modest gains.
5 75 7 6 67 29 2
0%20%40%60%80%100%false reports
eliminated
138
antlr119
avrora64
ftp41
hedc71
luindex293
lusearch29
weblech0%
20%
40%
60%
80%
100%true reports
retained√Ébaseline
false
reports
√Ébaseline
true
reportsFigure 9: Results of Eugene onpolysite analysis.
338 1824
0%20%40%60%80%100%false reports
eliminated
2 9 3 17 4 26 8 37 8 46
700
avrora2597
luindex0%
20%
40%
60%
80%
100%true reports
retained2 13 6 26 11 39 12 49 17 62√Ébaseline
false
reports
√Ébaseline
true
reports
Figure 10: Results of Eugene ondatarace analysis
with feedback (0.5%,1%,1.5%,2%,2.5%).
We next discuss the precision of Eugene for each of our
probabilistic analyses. For datarace , with 20% feedback, an
average of 89% of the false reports are eliminated while an
average of 98% of the true reports are retained. Further,
with 5% feedback the averages are 66% for false reports elim-
inated and 97% for true reports retained. Although the pre-
cision of Eugene increases with more feedback in this case,
the gains are relatively modest. Note that given the large
number of initial reports generated for luindex and avrora
(4421 and 1038 respectively), it is somewhat impractical to
expect analysis users to provide up to 20% feedback. Conse-
quently, we re-run Eugene for these benchmarks with 0.5%,
1%, 1.5%, 2% and 2.5% feedback. The results are shown in
Figure 10. Interestingly, we observe that for luindex , with
only 2% feedback on the false reports and 1.9% feedback on
true reports, Eugene eliminates 62% of false reports and
retains 89% of the true reports. Similarly for avrora , with
only 2.3% feedback on the false reports and 1.8% feedback on
true reports, Eugene eliminates 76% of false reports and re-
tains 96% of the true reports. These numbers indicate that,
for the datarace client, Eugene is able to generalize even
with a very limited amount of user feedback.
For polysite , with 20% feedback, an average of 57% of
the false reports are eliminated and 99% of the true reports
are retained, while with 5% feedback, 29% of the false re-
ports are eliminated and 92% of the true reports are re-
469antlr
avrora
ftp
hedc
luindex
lusearch
weblech05101520Running time (minutes)datarace
analysisfeedback
5%
10%
15%
20%
antlr
avrora
ftp
hedc
luindex
lusearch
weblech020406080100120140Running time (minutes)polysite
analysisfeedback
5%
10%
15%
20%Figure 11: Running time of Eugene .
tained. There are two important things to notice here.
First, the number of eliminated false reports does not al-
ways grow monotonically with more feedback. The reason
is that Eugene is sensitive to the reports chosen for feed-
back, but in each run, we randomly choose the reports to
provide feedback on. Though the precision numbers here are
averaged over three runs for a given feedback amount, the
randomness in choosing feedback still seeps into our results.
Second, Eugene tends to do a better job at generalizing the
feedback for the larger benchmarks compared to the smaller
ones. We suspect the primary reason for this is the fact that
smaller benchmarks tend to have a higher percentage of bugs
with unique root causes, and thereby a smaller number of
bugs are attributable to each unique cause. Consequently,
the scope for generalization of the user feedback is reduced.
Answer to RQ1 :Eugene signicantly reduces false re-
ports with only modest feedback, while retaining the vast
majority of true reports. Though increasing feedback leads
to more precise results in general, for many cases, the gain
in precision due to additional feedback is modest.
5.3 Scalability of Eugene
The performance of Eugene for our control study, in
terms of the inference engine running time, is shown in Fig-
ure 11. For each ( benchmark;analysis; #feedback ) con-
guration, the running time shown is an average over the
three runs of the corresponding conguration. We observe
two major trends from this gure. First, as expected, the
running time is dependent on the size of the benchmark and
the complexity of the analysis. For both the analyses in the
control study, Eugene takes the longest time for avrora ,
our largest benchmark. Also, for each of our benchmarks,
thedatarace analysis, with fewer rules, needs shorter time.
Recollect that Eugene uses an o-the-shelf solver for solv-
ing the constraints of probabilistic analysis, and thus the
performance of the inference engine largely depends on the
performance of the underlying solver. The running time of
all such solvers depends on the number of ground clauses
that are generated, and this number in turn depends on the
size of the input program and complexity of the analysis.
Second, the amount of feedback does not signicant af-
fect running time. Incorporating the feedback only requires
adding the liked/disliked queries as soft rules, and thus does
not signicantly alter the underlying set of constraints.
Finally, the fact that Eugene spends up to 120 minutes
(polysite analysis on avrora with 15% feedback) might seemdisconcerting. But note that this represents the time spent
by the system rather than the user, in computing the new
results after incorporating the user feedback. Since Eugene
uses the underlying solver as a black-box, any improvement
in solver technology directly translates into improved perfor-
mance of Eugene . Given the variety of solvers that already
exist [8,14,26,33,34,37], and the ongoing active research in
this area, we expect the running times to improve further.
Answer to RQ2 :Eugene eectively scales to large pro-
grams up to a few hundred KLOC, and its scalability will
only improve with advances in underlying solver technol-
ogy. Additionally, the amount of feedback has no signi-
cant eect on the scalability of Eugene .
5.4 Usability of Eugene
In this section, we evaluate the results of our user study
conducted using Eugene . The usage model for Eugene
assumes that analysis users are familiar with the kind of
reports produced by the analysis as well as with the pro-
gram under analysis. To ensure familiarity with reports pro-
duced by infoow analysis, we informed all our users about
the expected outcomes of a precise infoow analysis in gen-
eral. However, familiarity with the program under analysis
is harder to achieve and typically requires the user to have
spent time developing or xing the program. To address this
issue, we choose relatively smaller benchmarks in our study
that users can understand without too much eort or exper-
tise. The users in this study were not informed about the
internal working of either Eugene or the infoow analysis.
The two main questions that we evaluate here are: (i)
the ease with which users are able to analyze the reported
results and provide feedback, and (ii) the quality of the user
feedback. To answer the rst question, we record the time
spent by each user in analyzing the infoow reports and
providing the feedback for each benchmark. Recall that we
ask each user to provide eight reports as feedback, labeled
either spurious or real. Figure 12 shows the time spent by
each user on analyzing the reports and providing feedback.
We observe that the average time spent by the users is only 8
minutes on secbench1 , 11.5 minutes on secbench2 , and 5.5
minutes on secbench3 . These numbers show that the users
are able to inspect the analysis output and provide feedback
toEugene with relative ease on these benchmarks.
To evaluate the quality of the user provided feedback, we
consider the precision of Eugene when it is run on the prob-
abilistic version of infoow analysis with the feedback. Fig-
ure 13 shows the false bugs eliminated and the true bugs
retained by Eugene for each user and benchmark. This g-
ure is similar in format to Figures 8 and 9. However, for each
benchmark, instead of dierent bars representing a dierent
amount of feedback, the dierent bars here represent dier-
ent users, with feedback amount xed at eight reports. The
varying behavior of Eugene on these benchmarks highlights
the strengths and limits of our approach.
Forsecbench1 , an average of 78% of the false reports are
eliminated and 62.5% of the true reports are retained. The
important thing to note here is that the number of true
reports retained is sensitive to the user feedback. With the
right feedback, all the true reports are retained (5thbar).
However, in the case where the user only chooses to provide
one true feedback report (4thbar), Eugene fails to retain
most of the true reports.
470secbench1
secbench2
secbench30510152025User inspection time
 (minutes)Figure 12: Time spent by each user in inspecting
reports of infoow analysis and providing feedback.
20 21 8
0%20%40%60%80%100%false reports
eliminated
4
secbench19
secbench216
secbench30%
20%
40%
60%
80%
100%true reports
retained√Ébaseline
false
reports
√Ébaseline
true
reports
Figure 13: Results of Eugene oninfoow analysis
with real user feedback. Each bar maps to a user.
For secbench2 , an average of 79% of the false reports
are eliminated and 100% of the true reports are retained.
The reason Eugene does well here is that secbench2 has
multiple large clusters of reports with the same root cause.
User feedback on any report in such clusters generalizes to
other reports in the cluster. This highlights the fact that
Eugene tends to produce more precise results when there
are larger clusters of reports with the same root cause.
Forsecbench3 , an average of 46% of the false reports are
eliminated while 82% of the true reports are retained. First,
notice that this benchmark produces only eight false reports.
We traced the relatively poor performance of Eugene in
generalizing the feedback on false reports to limiting the
analysis user's interaction with the system to liking or dis-
liking the results. This does not suce for secbench3 be-
cause, to eectively suppress the false reports in this case,
the user must add new analysis rules. We intend to explore
this richer interaction model in future work.
Finally, we observed that for all the benchmarks in this
study, the labels provided by the users to the feedback re-
ports matched with the ground truth. While this is not un-
expected, it is important to note that Eugene is robust even
under incorrectly labeled feedback, and can produce precise
answers if a majority of the feedback is correctly labeled.
Answer to RQ3 : It is feasible for users to inspect analysis
output and provide feedback to Eugene since they only
needed an average of 8 minutes for this activity in our user
study. Further, in general, Eugene produce precise results
with this user feedback, leading to the conclusion that it is
not unreasonable to expect useful feedback from users.
5.5 Limitations of Eugene
Eugene requires analyses to be specied using the Datalog-
based language described in x3. Additionally, the program
to be analyzed itself has to be encoded as a set of ground
facts. This choice is motivated by the fact that a growing
number of program analysis tools including bddbddb [43],
Chord [29], Doop [39], LLVM [36], Soot [21], and Z3 [12]
support specifying analyses and programs in Datalog.The oine (learning) component of Eugene requires the
analysis designer to specify which analysis rules must be
soft. Existing analyses employ various approximations such
as path-, ow-, and context-insensitivity; in our experience,
rules encoding such approximations are good candidates for
soft rules. Further, the learning component requires suitable
training data in the form of desired analysis output. We
expect such training data to be either annotated by the user,
or generated by running a precise but unscalable version
of the same analysis on small sample programs. Learning
using partial or noisy training data is an interesting future
direction that we plan to explore.
6. RELATED WORK
Our work is related to existing work on classifying error
reports and other applications of probabilistic reasoning.
Dillig et al. [9] propose a user-guided approach to clas-
sify reports of analyses as errors or non-errors. They use
abductive inference to compute small, relevant queries to
pose to a user that capture exactly the information needed
to discharge or validate an error. Their approach does not
incorporate user feedback into the analysis specication and
generalize it to other reports. Blackshear and Lahiri [6] pro-
pose a post-processing framework to prioritize alarms pro-
duced by a static verier based on semantic reasoning of
the program. Statistical error ranking techniques [13,15,16]
employ statistical methods and heuristics to rank errors re-
ported by an underlying static analysis. Non-statistical clus-
tering techniques correlate error reports based on a root-
cause analysis [18, 19]. Our technique, on the other hand,
makes the underlying analysis itself probabilistic.
Recent years have seen many of applications of proba-
bilistic reasoning to analysis problems. In particular, spec-
ication inference techniques based on probabilistic infer-
ence [4, 17, 24] can be formulated as probabilistic analyses
(as dened inx3). It would be interesting to explore the
possibility of solving these specication inference formula-
tions using the algorithms proposed in this paper. Another
connection between user-guided program analysis and spec-
ication inference is that user feedback can be looked upon
as an iterative method by means of which the analysis user
communicates a specication to the program analysis tool.
Finally, the inferred specications can themselves be em-
ployed as soft rules in our system.
7. CONCLUSION
We presented a user-guided approach to program analysis
that shifts decisions about the kind and degree of approxi-
mations to apply in analyses from analysis writers to anal-
ysis users. Our approach enables users to interact with the
analysis by providing feedback on a portion of the results
produced by the analysis, and automatically uses the feed-
back to guide the analysis approximations to the user's pref-
erences. We implemented our approach in a system Eugene
and evaluated it on real users, analyses, and programs. We
showed that Eugene greatly reduces misclassied reports
even with limited amounts of user feedback.
Acknowledgements. We thank the referees for useful
feedback. This work was supported by DARPA under agree-
ments #FA8750-12-2-0020 and #FA8750-15-2-0009, and by
NSF award #1253867. The U.S. Government is authorized
to reproduce and distribute reprints for Governmental pur-
poses notwithstanding any copyright thereon.
4718. REFERENCES
[1] Apache FTP Server.
http://mina.apache.org/ftpserver-project/ .
[2] PJBench. https://code.google.com/p/pjbench/ .
[3] Securibench Micro. http://suif.stanford.edu/
~livshits/work/securibench-micro/index.html .
[4] N. Beckman and A. Nori. Probabilistic, modular and
scalable inference of typestate specications. In PLDI ,
2011.
[5] S. M. Blackburn, R. Garner, C. Homan, A. M. Khan,
K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg,
D. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking,
M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar,
D. Stefanovi c, T. VanDrunen, D. von Dincklage, and
B. Wiedermann. The DaCapo benchmarks: Java
benchmarking development and analysis. In OOPSLA ,
2006.
[6] S. Blackshear and S. Lahiri. Almost-correct
specications: A modular semantic framework for
assigning condence to warnings. In PLDI , 2013.
[7] M. Bravenboer and Y. Smaragdakis. Strictly
declarative specication of sophisticated points-to
analyses. In OOPSLA , 2009.
[8] A. Chaganty, A. Lal, A. Nori, and S. Rajamani.
Combining relational learning with SMT solvers using
CEGAR. In CAV , 2013.
[9] I. Dillig, T. Dillig, and A. Aiken. Automated error
diagnosis using abductive inference. In PLDI , 2012.
[10] P. Domingos and D. Lowd. Markov Logic: An
Interface Layer for Articial Intelligence . Synthesis
Lectures on Articial Intelligence and Machine
Learning. Morgan & Claypool Publishers, 2009.
[11] S. Guarnieri and B. Livshits. Gatekeeper: Mostly
static enforcement of security and reliability policies
for JavaScript code. In USENIX Security Symposium ,
2009.
[12] K. Hoder, N. Bjrner, and L. M. de Moura. Z- an
ecient engine for xed points with constraints. In
CAV , 2011.
[13] Y. Jung, J. Kim, J. Shin, and K. Yi. Taming false
alarms from a domain-unaware C analyzer by a
bayesian statistical post analysis. In SAS, 2005.
[14] S. Kok, M. Sumner, M. Richardson, P. Singla,
H. Poon, D. Lowd, and P. Domingos. The alchemy
system for statistical relational AI. Technical report,
Department of Computer Science and Engineering,
University of Washington, Seattle, WA, 2007.
[15] T. Kremenek, K. Ashcraft, J. Yang, and D. Engler.
Correlation exploitation in error ranking. In FSE,
2004.
[16] T. Kremenek and D. Engler. Z-ranking: Using
statistical analysis to counter the impact of static
analysis approximations. In SAS, 2003.
[17] T. Kremenek, P. Twohey, G. Back, A. Ng, and
D. Engler. From uncertainty to belief: Inferring the
specication within. In OSDI , 2006.
[18] W. Le and M. L. Soa. Path-based fault correlations.
InFSE, 2010.
[19] W. Lee, W. Lee, and K. Yi. Sound non-statistical
clustering of static analysis alarms. In VMCAI , 2012.[20] O. Lhot ak. Spark: A exible points-to analysis
framework for Java. Master's thesis, McGill
University, 2002.
[21] O. Lhot ak and L. Hendren. Jedd: a BDD-based
relational extension of Java. In PLDI , 2004.
[22] O. Lhot ak and L. Hendren. Context-sensitive points-to
analysis: is it worth it? In CC, 2006.
[23] B. Livshits and M. Lam. Finding security
vulnerabilities in Java applications with static
analysis. In USENIX Security Symposium , 2005.
[24] B. Livshits, A. Nori, S. Rajamani, and A. Banerjee.
Merlin: specication inference for explicit information
ow problems. In PLDI , 2009.
[25] B. Livshits, J. Whaley, and M. S. Lam. Reection
analysis for Java. In APLAS , 2005.
[26] R. Mangal, X. Zhang, M. Naik, and A. Nori. Solving
weighted constraints with applications to program
analysis. http://hdl.handle.net/1853/53191 , 2015.
[27] M. Martin, B. Livshits, and M. Lam. Finding
application errors and security aws using PQL: a
program query language. In OOPSLA , 2005.
[28] A. Milanova, A. Rountev, and B. G. Ryder.
Parameterized object sensitivity for points-to analysis
for Java. ACM TOSEM , 14(1), 2005.
[29] M. Naik. Chord: A program analysis platform for
Java. http://jchord.googlecode.com/ .
[30] M. Naik, A. Aiken, and J. Whaley. Eective static
race detection for Java. In PLDI , 2006.
[31] M. Naik, C.-S. Park, K. Sen, and D. Gay. Eective
static deadlock detection. In ICSE , 2009.
[32] S. Narayanasamy, Z. Wang, J. Tigani, A. Edwards,
and B. Calder. Automatically classifying benign and
harmful data races using replay analysis. In PLDI ,
2007.
[33] F. Niu, C. R e, A. Doan, and J. W. Shavlik. Tuy:
Scaling up statistical inference in markov logic
networks using an RDBMS. In VLDB , 2011.
[34] J. Noessner, M. Niepert, and H. Stuckenschmidt.
RockIt: Exploiting parallelism and symmetry for
MAP inference in statistical relational models. In
AAAI , 2013.
[35] C. H. Papadimitriou. Computational complexity .
Addison-Wesley, 1994.
[36] E. I. Psallida. Relational representation of the LLVM
intermediate language. B.S. Thesis, University of
Athens, Jan. 2014.
[37] S. Riedel. Improving the accuracy and eciency of
MAP inference for Markov Logic. In UAI, 2008.
[38] P. Singla and P. Domingos. Discriminative training of
markov logic networks. In AAAI , 2005.
[39] Y. Smaragdakis and M. Bravenboer. Using Datalog
for fast and easy program analysis. In Datalog 2.0
Workshop , 2010.
[40] Y. Smaragdakis, M. Bravenboer, and O. Lhot ak. Pick
your contexts well: Understanding object-sensitivity.
InPOPL , 2013.
[41] Y. Smaragdakis, G. Kastrinis, and G. Balatsouras.
Introspective analysis: context-sensitivity, across the
board. In PLDI , 2014.
472[42] M. Sridharan and R. Bod k. Renement-based
context-sensitive points-to analysis for Java. In PLDI ,
2006.
[43] J. Whaley, D. Avots, M. Carbin, and M. Lam. Using
Datalog with binary decision diagrams for program
analysis. In APLAS , 2005.[44] J. Whaley and M. Lam. Cloning-based
context-sensitive pointer alias analysis using binary
decision diagrams. In PLDI , 2004.
[45] X. Zhang, R. Mangal, R. Grigore, M. Naik, and
H. Yang. On abstraction renement for program
analyses in Datalog. In PLDI , 2014.
473