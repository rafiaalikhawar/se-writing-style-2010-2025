Search-Based Energy Testing of Android
Reyhaneh Jabbarvand, Jun-Wei Lin, and Sam Malek
School of Information and Computer Sciences
University of California, Irvine, USA
fjabbarvr,junwel1,malek g@uci.edu
Abstract —The utility of a smartphone is limited by its battery
capacity and the ability of its hardware and software to efﬁciently
use the device’s battery. To properly characterize the energy
consumption of an app and identify energy defects, it is critical
that apps are properly tested, i.e., analyzed dynamically to assess
the app’s energy properties. However, currently there is a lack
of testing tools for evaluating the energy properties of apps.
We present C OBWEB , a search-based energy testing technique
for Android. By leveraging a set of novel models, representing
both the functional behavior of an app as well as the contextual
conditions affecting the app’s energy behavior, C OBWEB gen-
erates a test suite that can effectively ﬁnd energy defects. Our
experimental results using real-world apps demonstrate not only
its ability to effectively and efﬁciently test energy behavior of
apps, but also its superiority over prior techniques by ﬁnding a
wider and more diverse set of energy defects.
Index Terms —Software Testing; Energy Testing, Android
I. I NTRODUCTION
Improper usage of energy consuming hardware elements,
such as GPS, WiFi, radio, Bluetooth, and display, can drasti-
cally discharge the battery of a mobile device. Recent studies
have shown energy to be a major concern for both users [1]
and developers [2]. In spite of that, many mobile apps are
abound with energy defects. This can be attributed to the
lack of tools and methodologies for energy testing [2]. Recent
advancements in mobile app testing have mostly focused on
testing functional correctness of programs, which may not be
suitable for revealing energy defects [3]. There is, thus, an
increasing demand for solutions to assist developers in testing
energy behavior of apps prior to their release.
The ﬁrst step toward energy testing is to understand the
properties of tests that are effective in revealing energy de-
fects in order to automatically generate such tests. Recently,
Jabbarvand et al. [3] proposed a technique based on mutation
testing to identify the properties of proper tests for energy
testing. They showed that to kill the energy mutants, tests
need to be executed under a variety of contextual settings.
Based on the results of their study, we have identiﬁed three
contextual factors that are correlated to energy defects and
should be considered in energy-driven testing: (1) Lifecycle
Context : A subset of energy defects, e.g., wakelocks and
resource leaks, manifest themselves under speciﬁc sequences
of lifecycle callbacks; (2) Hardware State Context : Some
energy defects happen under peculiar hardware states, e.g.,
poor network signal, no network connection, or low battery;
and (3) Interacting Environment Context : Certain energy
defects manifest themselves under speciﬁc interactions with
the environment—consisting of user, backend server, other
apps, and connected devices such as smartwatches.None of the prior automated Android testing techniques
properly consider these contextual factors in test genera-
tion [4], [3], thereby are not able to effectively test the
energy behavior of apps. That is, majority of the state-of-
the-art Android testing tools [5], [6], [7], [8], [9], [10], [11],
[12], [13], [14], [15] are aimed for GUI testing, which only
considers the inputs directly generated by user, e.g., clicking
on a button. Even among the techniques that go beyond GUI
testing [16], [17], there is no systematic approach for altering
the lifecycle of components and state of hardware elements to
properly evaluate the energy behavior of apps.
In this paper, we present C OBWEB , an energy testing
technique for Android apps. C OBWEB uses an evolutionary
search strategy with an energy-aware genetic makeup for test
generation. By leveraging a set of novel models, representing
lifecycle of components and states of hardware elements on
the phone, C OBWEB is able to generate tests that execute the
energy-greedy parts of the code under a variety of contextual
conditions. Extensive evaluation of C OBWEB using real-world
Android apps with conﬁrmed energy defects demonstrates
not only its ability to effectively and efﬁciently test energy
behavior of apps, but also its superiority over prior techniques
by ﬁnding a wider and more diverse set of energy defects.
The remainder of this paper is organized as follows. Sec-
tion II introduces an illustrative example that is used to
describe our research. Section III provides an overview of our
approach, while Sections IV-V describe the details. Section VI
presents the evaluation results. The paper concludes with a
discussion of the related research and avenues of future work.
II. I LLUSTRATIVE EXAMPLE
As an illustrative example, we use an Android app called
MyTracker [18]. In this section, we describe two main func-
tionalities of MyTracker, two tests to exercise these functional-
ities, and two energy defects in this app that cannot be caught
by tests that do not take execution context into account.
App: As shown in Figure 1, MyTracker allows users to search
for the map of different locations using either the internet
or GPS, download them, and navigate through each speciﬁc
downloaded map. This app consists of seven components, i.e.,
four Activities and three Services . MyTracker provides two
functionalities: tracking/navigation and search/download map.
When a user clicks on the Download Maps button, the app
navigates to MapSearchActivity , where the user can search
for maps using the Internet or GPS. If the user decides to
search using the Internet, she needs to provide the name of the
city, e.g., Ottawa, and then click on the Find by Internet
button. Otherwise, she can just click on the Find by GPS
button. Depending on the selected search option, the app starts
11192019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ©2019 IEEE
DOI 10.1109/ICSE.2019.00115
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. Fig. 1: MyTracker Android Application
InternetService orGPSService in the background, which
searches for the map on a speciﬁc server. Upon ﬁnding a
match with the name provided by user or location coordinates,
DownloadService downloads the map, resulting in the list
of maps displayed on MainActivity to be updated.
For tracking, once the user clicks on one of the downloaded
maps in MainActivity , e.g. the map of Montreal shown in
Figure 1, the app navigates to LocationActivity . In this
activity, the user can see the map of Montreal and provide a
source and destination address to start the navigation. By click-
ing on the Start button, the app starts TrackingActivity
and registers a location listener, which updates the GUI of
TrackingActivity upon movement.
Tests: Android tests can be represented as a sequence of
events, where each event is an input to the app and can be
triggered by the user or system. We formally deﬁne each test
tin test suite T, ashc1he1; : : : ; e p1i; : : : ; c mhe1; : : : ; e pmii,
where ciindicates the ithcomponent covered during the
execution of t. The execution of each component ci, which
could be Activity, Service, or Broadcast Receiver, by test tis
represented as an event sequence, where each event is denoted
ase. We consider two types of events: (1) input events that
take inputs using speciﬁc APIs, e.g., ﬁlling a text box, and (2)
callback events that are invocation of Android callbacks, e.g.,
click on a button or transition to a lifecycle state. Figure 2
shows representation of two tests according to this formalism
that target the two functionalities of MyTracker app. We use
these tests throughout the paper for illustrating our approach.
Energy Defects: MyTracker suffers from two energy defects:
1)Fail to check connectivity energy defect [3] occurs when
an app fails to check for connectivity before performing a
network operation. MyTracker unnecessarily searches for a
network signal when there is no network connection available,
which is a power draining operation. To ﬁnd this energy
defect, MyTracker should be tested both when there is a
network connection available and not. The test corresponding
Fig. 2: Event sequences for testing the tracking/navigation and
search/download functionalities of MyTracker
Fig. 3: COBWEB Framework
to Sequence 1 in Figure 2 does not enable or disable network
connectivity, therefore, cannot detect this defect.
2) MyTracker starts listening to location updates in
TrackingActivity by registering a location listener for
GPS. As long as TrackingActivity is visible to the user
and GUI is rendered based on location updates, MyTracker
can keep the GPS active. However, when user puts the app
in the Paused state, i.e., MyTracker is sent to background, it
does not unregister the location listener, thereby, unnecessarily
updates a GUI that is not visible to the user [19], [20]. To ﬁnd
this energy defect, a test needs to put TrackingActivity
into paused state for some time to assess utilization of GPS
hardware in this state. Clearly, the test corresponding to
Sequence 2 in Figure 2 does not have this property.
III. A PPROACH OVERVIEW
Since the domain of events and inputs for android apps is
quite large, C OBWEB follows a search-based testing technique
for input generation. Every search-based testing technique has
three facets: (1) search space , which is a set of possible
solutions, (2) meta-heuristics to guide the search through the
search space, and (3) evaluation metrics to measure the quality
of potential solutions.
COBWEB identiﬁes the search space as a set of event
sequences, i.e., system tests. To guide the search through the
search space, our approach utilizes an evolutionary algorithm
to globally search for an optimal solution. Similar to other
search-based techniques, C OBWEB relies on the abstract rep-
resentation of the program, i.e., models, to generate event
sequences and compute the ﬁtness function as an evaluation
metric. However, a key novelty of C OBWEB is that unlike
prior search-based testing techniques, it also utilizes several
other contextual models, representing the state of hardware
and environment, in the search process.
Figure 3 provides an overview of C OBWEB , consisting of
two major components: (1) Model Extractor component that
derives the required models for test generation; and (2) Test
Generator component that utilizes an evolutionary search-
based technique to create system tests. C OBWEB ’s ﬁtness
function rewards the tests based on two criteria: (1) how close
they are to covering energy-greedy APIs in the application
logic, and (2) how well they contribute to exercising different
contextual factors.
IV. M ODEL EXTRACTOR
COBWEB uses four types of models: Component Transition
Graph (CTG) ,Call Graph (CG) ,Lifecycle State Machine
(LSM) , and Hardware State Machine (HSM) . Figure 4 shows
1120
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. a subset of these models for MyTracker app. At the highest-
level is the CTG model, which represents the components
comprising the app as nodes and the Intents as transitions
among the nodes. Intents are Android events (messages) that
result in the execution ﬂow to move from one component to a
different component. Each node of the CTG in turn contains
one CG—representing the internal behavior of the correspond-
ing software component, one LSM—representing the possible
lifecycle states of the corresponding software component, and
zero or more HSM—each of which represents the states of an
energy-greedy hardware element utilized during the execution
of the corresponding software component. LSM and HSM
models are generic and app/device independent, constructed
manually by the authors, while CTG and CG models are app-
speciﬁc and automatically extracted through static analysis of
an app’s bytecode. We describe each model and how it is
obtained in the remainder of this section.
A. Component Transition Graph (CTG)
COBWEB utilizes CTG to ensure generation of valid and
useful event sequences. Events can be categorized into (1)
input events that take inputs to the app using speciﬁc APIs,
e.g., EditText.getText() that reads a string provided by
user for a text box, and (2) callback events that invoke Android
callbacks, e.g., onLocationChanged() , which is invoked
when the physical location of the device changes.
COBWEB uses CTG model of the app under test to gen-
erate the proper order of event calls. Finding the proper
order of event call invocations is particularly a challenge
in Android due to usage of callbacks, each considered
a possible entry point for an application. For example,
onLocationChanged() callback is an entry point for My-
Tracker app. The call graph obtained from running the
state-of-the-art static analysis tools, such as Soot [27],
does not model any particular order for the execution of
entry points. That is, using such call graphs to gener-
ate event sequences, onLocationChanged() can appear
before the onCreate() ofTrackingActivity or even
onCreate() ofMainActivity . However, proper invoca-
tion of onLocationChanged() is after the execution of
onCreate() ofTrackingActivity , as shown in Sequence
2 of Figure 2.
Furthermore, to properly test the energy behavior of My-
Tracker with respect to its tracking functionality, C OBWEB
needs to mock the location, such that Android platform
invokes onLocationChanged() callback. The tricky part of
generating such tests is that onLocationChanged() callback
should only be invoked if the app has already registered
a location listener to receive location updates, which hap-
pens in the onCreate() method of TrackingActivity
component. In other words, mocking the location should
be performed after TrackingActivity starts. Otherwise,
mocking has no effect and will not result in the invocation
ofonLocationChanged() callback. Generating valid and
useful events entails not only an inter-procedural analysis—
to ﬁnd the proper component for callback invocation—but
also requires considering the speciﬁc types of dependencies
among events. To overcome these challenges, CTG considers
ﬁvetypes of transitions:
Fig. 4: CTG model for MyTracker. Gray boxes show the detailed
CG, LSM, and HSM of DownloadService and TrackingActivity
components. Components marked with an asterisk contain energy-
greedy API invocations
1-Call transition : These intra-component transitions are
inferred from the basic call graph generated for the app under
test using Soot [27].
2-Intent transition : These transitions are inter-component,
which result in transferring the control from one component
to another component. A method or callback inside one
component that starts another component is connected to the
lifecycle entry point of that component using this kind of
transition. C OBWEB uses IC3 [28] to infer Intent transitions.
3-GUI transition : These intra-component transitions indicate
the order of execution between GUI widgets. For example, the
Start button in the LocationActivity of MyTracker should
be clicked after user provides source and destination addresses
in the From and Totext boxes. C OBWEB builds on top of
TrimDroid [11] to infer such transitions.
4-Registration transition : This type of transition consists
of two sub-categories: broadcast receiver registration and
event listener registration . A broadcast receiver receives an
intent for which it has registered for via the onReceive()
callback method. While static broadcast receivers—those iden-
tiﬁed in the manifest ﬁle—are registered when the app
launches, dynamic broadcast receivers are registered using
registerReceiver() API. Broadcast registration transition,
which could be inter- or intra-component, connects a CG
node that registers a broadcast receiver to its corresponding
onReceive() callback, which is also a CG node.
An event listener is an interface that contains one or
more callbacks. Listener callbacks are called by the Android
framework when the event that the listener has been registered
1121
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. for is triggered either by user or environment. For example,
onLocationChanged() is called upon any change in the
location of the device, if the app has previously registered a
location listener. Listener registration transition, which could
also be inter- or intra-component, connects a CG node that
registers a listener to its corresponding callbacks, which is
also a CG node. The listener callbacks have no order among
themselves.
COBWEB ’s approach for identifying registration transition
works as follows. For a given registered callback, C OBWEB
performs an inter-procedural, ﬂow-sensitive static program
analysis to ﬁnd the registrar —the entity that registers the
broadcast receiver or listener of that callback. It then assigns
a transition from the registrar to the registered callback node
in CG. For broadcast registration, the registered callback is
onReceive() —either deﬁned inside an inner-class broadcast
receiver or a broadcast receiver component, and registrar is
callback or method that invokes the registerReceiver()
API. For listener transition, C OBWEB takes a list of listener
callbacks available in Android API1to identify registered
callbacks. The listener registrar is a callback or method that
registers a listener with the given callback implemented. Flow-
sensitivity is required for this analysis, as a broadcast re-
ceiver may subscribe to receive multiple Intents, and multiple
listeners of the same kind might be registered for an app.
For example, an app may register two location listeners, one
listening to GPS location updates, and another one tracking
location updates via network.
5-Lifecycle transition : These intra-component transitions are
between starting lifecycle callback nodes of a component,
e.g., onCreate() for Activities or onStartCommand() for
Services, and every non-lifecycle node with no incoming edge
inside the component. That is, every callback or method inside
a component with no incoming edge can be called after the
component is started. C OBWEB resolves lifecycle transitions
after all other transitions are identiﬁed. It ignores all other
lifecycle callbacks that do not instantiate/start a component,
e.g.,onPause() oronDestroy() , since these other lifecycle
callbacks are considered using the LSM model, discussed next.
B. Lifecycle State Machine (LSM)
Wakelocks and other resources, such as GPS, are commonly
acquired and released in lifecycle event handlers [29]. Thereby,
proper implementation of lifecycle callbacks is important, as
developers need to ensure apps are not unnecessarily con-
suming power due to changes in the lifecycle state. To that
end, we represent possible transitions among lifecycle states
of an Android component type as a ﬁnite state machine, called
Lifecycle State Machine (LSM).
Since the lifecycle callbacks are handled by the Android
framework itself, we can deﬁne an LSM for each Android
component type, regardless of which callbacks are actually
implemented by instances of that component. Such a represen-
tation also ensures thorough testing of an app, as developers
may have failed to implement important lifecycle callbacks,
where resources should be managed properly.
1Derivation of this list is discussed in Section IV-CWe derived three types of LSM models, one for each of the
Android components types (Activities, Services, and Broadcast
Receivers), based on the lifecycle callbacks identiﬁed for them
in the Android documentation. Figure 4 shows LSMs of the
Activity and Service components for TrackingActivity and
InternetService , respectively. For example, the Activity
LSM demonstrates four different lifecycle states for an Activ-
ity component. The Activity LSM indicates how the execution
of lifecycle callbacks results in transitions to different states.
C. Hardware State Machine (HSM)
Developers should adjust the functionality of apps according
to the states of hardware elements. For instance, per Android
developer guidelines [19], a location listener should be unreg-
istered when user is stationary, or the frequency of location
update should be lowered when user is walking rather than
driving. To take such factors into account, we need to look
for changes in the hardware states from the inputs generated
by the environment (e.g., change in the strength of network
signal), or the user, directly or indirectly (e.g., user can turn
on/off location directly from setting, or she can trigger changes
in the state of GPS by changing her location).
Identifying different states of hardware elements for energy
testing is crucial, since apps consume different amounts of
energy in different states [30]. We followed a systematic
approach to derive generic and reusable models for each
hardware element on a mobile device, called Hardware State
Machine (HSM).
Android provides libraries to access and utilize hardware
elements. These libraries provide APIs and constant values,
i.e., ﬁelds, which can be used to inquire about possible states of
hardware elements. Developers can use the APIs implemented
by such libraries to monitor the state of hardware elements
(e.g., using LocationManager to track user location changes
and ConnectivityManager to query about the state of
network connections) or manipulate the states (e.g., hold a
lock on the CPU using PowerManager.Wakelock APIs to
prevent the phone from going to sleep). Documentation of
these APIs is a rich source for identifying different hardware
states.
Similarly, constant values introduced in such libraries
can be used to identify hardware states, as they usu-
ally are either representative of different states of hard-
ware elements, or the action ﬁeld of broadcast Intents
that show a change in the state of hardware. For ex-
ample, WIFI_MODE_FULL ,WIFI_MODE_FULL_HIGH_PERF ,
andWIFI_MODE_SCAN_ONLY are constants associated with
WiFiManager library, indicating that WiFi hardware can
operate in different modes, each consuming battery of the
device differently.
To ﬁnd a thorough list of such libraries, we started by
automatically crawling Android API reference [31] using
Crawler4J [32] to search for classes, where description of
their public methods or ﬁelds contained at least two of the
following keywords: location, lock, gps, network, connect,
radio, cellular, bluetooth, display, sensor, cpu, battery, power,
consume, drain, charge, discharge, monitor, hardware, state,
and telephone. We crawled 6;279pages in total and collected
1;971 libraries after keyword ﬁltering. We further processed
1122
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. Fig. 5: Genetic representation of tests
the documentation of those libraries to ﬁnd all the possible
states of hardware elements as follows:
1. APIs : To automatically collect a set of APIs that monitor
state of the hardware elements, we searched for event listeners
and callbacks in the public methods of the 1;971 collected
libraries, as they monitor the changes in the state of hardware
elements. From a total of 38;626 APIs in these classes,
we searched for APIs that have the keyword listener in
their signature—for event listener APIs—and APIs that start
with on—for callbacks. This yielded 441listeners and 2;968
callbacks. To collect APIs that manipulate state of hardware,
we searched for methods that have derivation of the following
keywords in their description: scan, access, acquire, release,
state, register, disable, enable, connect, and disconnect. In the
end, we collected a total of 104 APIs correlated to different
states of various hardware elements.
2. Fields : We automatically searched for the constant values
identiﬁed for the collected libraries, whose description con-
tained one of the keywords we used for initial ﬁltering. This
search left us with 225constant values.
Once the states of each hardware element were identiﬁed
using the aforementioned approach, we constructed seven
HSMs for major hardware elements on mobile phones. These
HSMs correspond to battery, Bluetooth, CPU, display, GPS,
radio, and sensors, e.g., accelerometer and gyroscope.
HSM is a ﬁnite state machine that represents different
states of a hardware element. Figure 4 shows HSM models
derived for Network and Location hardware elements (in
the details of InternetService andTrackingActivity
components). For Network HSM for example, from 46APIs
and12ﬁelds of two libraries— ConnectivityManager and
WiFiManager —along with their nested classes, we identiﬁed
9states for Network, namely Disconnected ,Connected (with
poor or full signal strength), Utilized (under poor or full
signal strength), Scanning , and Locked (full, multi-cast, and
high performance).2Edges between different states of the
hardware can be traversed by calling one of the Android APIs
inside the app or triggering events outside of it.3Hence, it
is crucial to have a generic HSM for each hardware without
considering just the source code of the app. For example,
an application can start scanning for available WiFi networks
using startScan() API, or the state of hardware can be
changed to scanning by manipulating the platform. We have
made the HSM models of other hardware elements publicly
available [33].
2For a better illustration, different locked states are merged in the HSM
3Labels of edges are not shown here for sake of simplicityAlgorithm 1: Evolutionary Energy Test Generation
Input: Appapp; Set of LSM s;Set of HSM s;List of
energy-greedy APIs HW; threshold; breedSize
Output: Test suite TE
1CTG; CG staticAnalysis (app )
2model mergeModels (CTG; CG; HSM; LSM )
3P randomPopulation (app )
4while improvement in ﬁtness (TR; model )threshold do
5 Poffspring select (P; breedSize )
6 Poffspring converge (model; P offspring )
7 Poffspring diverge (model; HW; P offspring )
8 TRtmp generate (Poffspring )
9 fitness (TRtmp; model )
10 P merge (P; Poffspring )
11 TR TR[TRtmp
12TE minimize (TR)
V. T ESTGENERATOR
Our objective is to generate tests that (1) cover energy-
greedy APIs, and (2) execute them under different contex-
tual conditions. In this section, we describe the evolutionary
search-based test generation algorithm utilized in C OBWEB
that aims to satisfy this objective.
A. Genetic Algorithm
COBWEB identiﬁes the search space for energy testing
problem as a set of system tests. Figure 5 illustrates the genetic
representation of a test suite generated by C OBWEB . Overall,
COBWEB generates a set of system tests that corresponds to a
population of chromosomes in the evolutionary algorithm. At
a ﬁner granularity, each chromosome consists of genes , which
are the main Android components of an app, and each gene
contains multiple sub-genes , which are either input events or
callback events (recall Section II).
Algorithm 1 presents the evolutionary approach of C OBWEB
for test generation. It takes the app along with LSM and
HSM models as inputs and generates a set of Espresso [26]
tests— TE. The algorithm starts by constructing the CTG and
CG models through static analysis of the app (Line 1) and
integrating those with LSM and HSM models to arrive at the
ﬁnalmodel of the app under test (Line 2). Next, it randomly
generates the initial population P, which is later evolved
using evolutionary search operators through multiple iterations
(Lines 5-7). Once the new generation is available, C OBWEB
generates Robolectric tests for each chromosome (Line 8),
executes them on JVM, and calculates their corresponding
ﬁtness (Line 9). At the end of iteration, C OBWEB adds newly
generated tests to the test suite and starts a new iteration. This
process continues until the termination condition is met: if the
improvement in the average ﬁtness of generated tests in two
consecutive iterations is less than a conﬁgurable threshold ,
the algorithm terminates (Line 4). Afterwards, Algorithm 1
minimizes the generated Robolectric test suite and transforms
them to Espresso tests for execution on a mobile device (Line
12), such that energy measurements can be collected.
For input ﬁelds, C OBWEB follows an approach similar to
Sapienz [12] and extracts statically-deﬁned values from the
source code and layout ﬁles. Additionally, developers can
provide a list of inputs, e.g., list of cities for MyTracker.
Alternatively, the input values can be provided to C OBWEB
1123
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. Fig. 6: Intuition behind convergence and divergence operators
through symbolic execution of the app, using one of the many
tools available for this purpose (e.g., [34], [35], [36], [37]).
B. Genetic Operators
We now provide a more detailed explanation of the three
genetic operators in Algorithm 1.
1) Selection Operator: COBWEB implements a ﬁtness pro-
portionate selection strategy, a.k.a., roulette wheel selection,
for breeding the next generation. That is, the likelihood of
selecting a chromosome is proportional to its ﬁtness value.
The intuition behind this selection strategy is that tests that are
closer to covering energy-greedy APIs or exercise them under
previously unexplored contexts—thus having a higher ﬁtness
value—should have a higher chance of selection. C OBWEB
sorts chromosomes based on their ﬁtness value and selects a
subset of them, denoted as Poffspring , for inclusion in the next
generation. The size of selected chromosomes is determined
bybreedSize variable that is an input to the algorithm. If
F(i)is the ﬁtness value for a chromosome iin the current
population with size n, the probability of this chromosome to
be selected for breeding is computed as follows:
p(i) =F(i)
nP
j=1F(j)(1)
2) Convergence Operator: The goal of convergence opera-
tor is to pull the population towards local optima, i.e., generate
new chromosomes that largely inherit the genetic makeup
of their parents. The convergence operator only changes the
execution context of tests. That is, from the parents identiﬁed
by the selection operator, Poffspring , it chooses those that
have reached energy-greedy APIs, then uses LSM and HSM
models or mocking to create a new context for those tests. The
intuition behind this operator is shown in Figure 6. LSM and
HSM models have ﬁnite states, thereby their search space—
identiﬁed by dashed circle in Figure 6—is relatively small
compared to the typical search space associated with the
functional behavior of a program, represented by CTG and CG
models. Convergence operator, denoted by the orange arrow in
Figure 6, promotes exploration of the search space within close
proximity of parent chromosomes, thereby aids the algorithm
to converge to local optima.
For each chromosome in Poffspring , COBWEB randomly
selects a gene to modify its context by inserting proper events
in the chromosome event sequence. To avoid bloated popula-
tions, C OBWEB applies convergence operator if the gene has
events associated with lifecycle callbacks or hardware-related
APIs. C OBWEB uses two types of convergence operator:
lifecycle context operator andhardware context operator .
Lifecycle context operator : To show the necessity of life-
cycle context and usage of LSM for test generation, consider
the second energy defect for MyTracker app described in
Fig. 7: Evolved event sequences from illustrative example
Section II. Recall that to effectively detect this bug, a test needs
to put the TrackingActivity into the paused state to assess
utilization of GPS hardware in this state. To generate such test,
lifecycle context operator determines current lifecycle state of
the chromosome that utilizes GPS in one of its genes, and
inserts the proper lifecycle callback event based on the next
possible state determined from LSM.
Consider Sequence 2 of Figure 2 to see how lifecycle
context operator works. The onLocationChanged event in
TrackingActivity gene indicates access to GPS hardware.
COBWEB realizes the lifecycle state of TrackingActivity
isRunning based on the last lifecycle callback in the event
sequence. The next eligible state for TrackingActivity is
Paused based on LSM, which can be reached by execut-
ingonPause() lifecycle callback. Additionally, since proper
execution of a test requires the component to be in the
Running state, C OBWEB needs to include a callback to restore
the component to the running state to avoid generation of
invalid tests. Thereby, C OBWEB generates a new chromosome
corresponding to Sequence 2 of Figure 7. The input argument
ofonPause indicates that during the execution of this test,
TrackingActivity remains in the paused state for 10sec-
onds.
Hardware context operator : Many energy defects manifest
themselves under speciﬁc hardware settings [3], making it
important to test an app under different hardware states. Recall
“fail to check for connectivity” energy defect in MyTracker
described in Section II. To ﬁnd this energy defect, MyTracker
should be tested both when there is a network connection avail-
able and not. For each chromosome in Poffspring , hardware
context operator ﬁnds a gene that utilizes hardware, if any,
determines the next hardware state based on the last explored
state in HSM, and inserts a speciﬁc hardware state sub-gene
right before the sub-gene that is a callback or contains APIs
that utilize a hardware element.
For example, consider a chromosome represented by Se-
quence 1 in Figure 2. The startDownload sub-gene inside
theDownloadService gene makes an app connect to a
server and download the map of Ottawa. If no prior hardware
context operator is applied on DownloadService , the state of
network would be Disconnected based on the Network HSM
presented in Figure 4. Hence, C OBWEB randomly chooses
to transfer the state to either Scanning ,Utilized Poor , or
Utilized Full . Supposing the next state is chosen to be Utilized
Full, COBWEB changes this event sequence to Sequence 1 in
Figure 7. Unlike lifecycle context operator, there is no need
to restore the state of hardware. That is, if a test crashes by
changing the hardware state, developer has failed to properly
handle that situation.
3) Divergence Operator: In contrast to convergence opera-
tor, the goal of divergence operator is to bring the population
1124
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. out of local optima to discover potentially better solutions,
i.e., ﬁnd solutions that cover new energy-greedy APIs not
previously covered by tests in the current population. The
intuition behind this operator is shown in Figure 6. Unlike
convergence operators that perform a neighborhood search,
divergence operator, denoted by the dashed green arrow, causes
exploration of the whole new areas of the search space.
The goal of this operator is to explore new paths, speciﬁcally
paths that cover energy-greedy APIs. To that end, it combines
two operations, namely breakup andreconcile to breed a new
chromosome. For each chromosome in Poffspring , breakup
operation breaks it into two set of genes, passes the ﬁrst set to
reconcile operation, and discards the seconds set. Note that the
breakup point is selected randomly and could also be the end
of the chromosome, i.e., the ﬁrst set is the entire chromosome
and the second set is empty. At the next step, reconcile
operation creates a new individual from the broken chromo-
some. Starting from the last gene of the broken chromosome,
reconcile operation uses the CTG and CG models to generate
a sequence of events that cover a path toward their leaf nodes.
The operator selects a path based on a priority value. Given
the following path, hCihe1; : : : ; e pii; : : : ; C mhe1; : : : ; e pmii,
its priority value is calculated as follows:
PRi;m=mX
j=iAPI j API j=lX
k=0wk (2)
where API jis a weighted sum of the number of energy-
greedy APIs, l, that might be invoked during the execution
of event sequences in component Cj. COBWEB takes a list
of38;626 energy-greedy APIs from our empirical study
described in Section IV-C, and counts the number of their
invocations for each component using a conventional use-
def static analysis. Since energy-greediness of APIs vary,
COBWEB employs a weighted sum. To obtain the weight of
each energy-greedy API, C OBWEB relies on a prior study [38]
that has ranked energy-greedy APIs based on their energy-
greediness to compute wkin Equation 2.
Reconcile operation may need to change the sub-genes
of the last gene in the broken chromosome to reduce
the likelihood of generating invalid tests. For example,
consider Sequence 1 in Figure 2, where breakup operation
divides it into hMainActivity ,MapSearchActivity i
and hInternetService ,DownloadService i
sequences of components. Referring to the CTG of
MyTracker shown in Figure 4, reconcile chooses
hGPSService ,DownloadService ito create a new
chromosomehMainActivity ,MapSearchActivity ,
GPSService ,DownloadService i. Without changing
the event sequences of MapSearchActivity , the test
corresponding to this new chromosome would fail, as
clicking on the “Find by Internet” button does not instantiate
GPSService . Thereby, C OBWEB changes the genetic makeup
ofMapSearchActivity and generates a new chromosome
corresponding to Sequence 3 shown in Figure 7.
C. Fitness Evaluation
The ﬁtness function rewards tests based on two criteria: ( C1)
how close they are to covering energy-greedy APIs; and ( C2)how well they contribute to exercising different contextual
factors. The ﬁrst criterion is measured using CTG and CG,
while the second criterion is measured using LSM and HSM.
COBWEB calculates the ﬁtness value in two steps. First, it
computes the ﬁtness of tiwith respect to each energy-greedy
APIj. Then, it averages those values to compute a single
ﬁtness value for test. For each test ti, COBWEB computes the
ﬁtness value as follows:
F(i) =1
nnX
j=1fi(j) (3)
where nis the number of energy-greedy APIs on the path of
tito a leaf in CTG and fi(j)is the ﬁtness value of tiwith
respect to energy-greedy API j, calculated as follows:
fi(j) =8
<
:1
3[c1i(j) +c2i(j)]APIjis on the path to a leaf
0 otherwise(4)
Here, c1i(j)determines the ﬁtness of tiwith respect to
ﬁtness criteria C1. It computes how close test tiis to cover
energy-greedy API j. It is calculated asx
y, where xis the
number of edges in CG to the node that contains API j,
starting from the last node covered by ti, and yis the total
number of edges from root to the node that contains API j.
The intuition behind this formulation is that, a test may not
cover energy-greedy APIs in the early iterations. However, if
it comes close to covering energy-greedy APIs, it is likely to
be able to eventually cover those APIs in future iterations.
Thereby, tests that exercise paths that contain more energy-
greedy APIs or get close to covering such APIs should have a
higher priority to evolve. If a test covers API j,c1i(j)attains
a value of 1.
c2i(j)corresponds to ﬁtness criterion C2and determines
how well tiexercises lifecycle and hardware state contexts:
c2i(j) =bc1i(j)c[li(j) +hi(j)] (5)
Here, li(j)andhi(j)are indicators of how well tiexercises
the lifecycles of a software component and different states
of a hardware element that implements API j, respectively.
COBWEB computes li(j)andhi(j)values as follows:1 if the test achieve prime path coverage
z
qotherwise(6)
where zis the length of path covered in LSM/HSM, and
qis the length of the longest prime path for LSM/HSM.
This formulation enables tests that exercise more states in
LSM/HSM models to have a higher ﬁtness value. Since
execution context matters only if an API is covered by a test,
Equation 5 has a coefﬁcient bc1i(j)c, such that it is 0, when ti
has not reached API j, and 1, otherwise. Unless c1i(j)equals
to1, the value ofbc1i(j)c, hence c2i(j), is0and the execution
context does not matter in calculation of ﬁtness. Finally, note
that coefﬁcient1=3in Formula 4 is to ensure that the ﬁtness
value is between 0and1.
D. Test-Suite Minimization
To minimize the size of test suite, C OBWEB removes
tests that are subset of others, as they are unlikely to ﬁnd
new defects. C OBWEB uses Lowest Common Ancestor (LCA)
algorithm to ﬁnd tests corresponding to overlapping paths in
1125
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. the graph and removes the shortest tests from TR. For two
testst1=hC1;; Cmiandt2=hC1;; Cni, if the LCA
between CmandCnis either of these nodes, these tests are
likely to be overlapping. The algorithm then checks the events
inside overlapping components and if they are the same, it
removes the shorter test and keeps the longer one. In addition,
COBWEB removes tests that fail to cover any energy-greedy
APIs, as such tests are unlikely to have a signiﬁcant impact
on energy. Finally, the reduced test suite is transformed to
Espresso tests, which can be executed on a mobile device.
VI. E VALUATION
We investigate the following ﬁve research questions in the
evaluation of C OBWEB :
RQ1. API and execution context coverage : How well do the
generated tests cover energy-greedy APIs and exercise
different lifecycle and hardware state contexts?
RQ2. Effectiveness : How effective are the generated tests in
revealing energy defects in real-world Android apps?
RQ3. Necessity of the models : To what extent does using the
LSM and HMS models and considering the execution
context aid C OBWEB to ﬁnd energy defects?
RQ4. Energy defects coverage : What types of energy defects
can be detected by C OBWEB and not other energy
analysis tools?
RQ5. Performance : How long does it take to generate tests
using C OBWEB ?
A. Experimental Setup
Alternative Approaches : For a thorough evaluation of
COBWEB , we compare it with other testing tools as well
as a variety of other energy analysis approaches targeting
Android. We compare C OBWEB against Monkey [39], since
(1) it is arguably the most widely used automated testing tool
for Android, and (2) in practice, it has shown to outperform
other academic test generation tools [4]. We also compare
against the most recent publicly available Android testing tool,
Stoat [13], shown to be superior to prior testing tools. Stoat
uses a combination of model-based stochastic exploration of
a GUI model of an app and randomly injected system-level
events to maximize code coverage.
Subject Apps : To evaluate effectiveness of C OBWEB , we
needed Android apps with real energy defects. To eliminate
any bias toward selection of subject apps in favor of C OBWEB ,
we looked at the dataset of 8related approaches presented
in Table II and used two criteria in selecting apps. First, the
energy defects identiﬁed by the approach should be conﬁrmed
by the developers of studied subject apps through a commit
in the repository. Second, information about the faulty version
of an app or pointers to a commit ﬁxing the issue should be
publicly available. These criteria are required to ensure the
defects reported by those tools are in fact reproducible in our
experimental setup and do not impose a threat to the validity
of our results. From the total of 2;035apps studied in related
approaches, only 25matched our inclusion criteria. From those
apps, we were able to reproduce the faults in 18of them,
mostly because a subset of faults in those apps related to older
versions of Android and could not be reproduced in Android
6.0 that we used in our evaluation. Out of these 18apps,we removed 3, since Soot was not able to generate complete
call graphs for them. Table I shows information about our 15
subjects with real energy defects.
Fault Reproduction : To ensure the energy issues are re-
producible, we executed each defective subject app under the
documented use-case known to exhibit the defect. We proﬁled
the state of hardware elements during and after execution of
the app using Trepn [40]. Trepn is a proﬁling tool developed
byQualcomm that collects the exact power consumption data
from sensors embedded in the chipset. If the proﬁled data
indicated over-utilization of a hardware element during the
execution of use-case, we marked the energy defect to be
reproducible. For example, if the energy defect to reproduce
is categorized as a location defect , we monitored the state of
GPS to see if the GPS hardware is released after the execution.
B. RQ1: API and Execution Context Coverage
The objective of C OBWEB is to maximize the coverage
of energy-greedy APIs under various execution contexts. To
evaluate the extent to which C OBWEB achieves this goal,
we measured API, LSM, and HSM coverage of test suites
produced for our subjects. Similarly, we calculated these met-
rics for Monkey and Stoat as an alternative testing approach.
We collected coverage information of the subjects using
EMMA [41] during test execution. We ran Stoat for 3hours,
similar to the conﬁguration used by its authors [13]. Monkey
is shown to converge very close to its highest coverage at
around 10minutes [4]. However, we ran it for 1hour to
ensure sufﬁcient testing budget. During 1hour, it generates
over100;000events per subject, which is signiﬁcantly higher
than the 7;630 events generated on average by C OBWEB in
our experiments. Table I illustrates the result of this experiment
under Coverage column. We observe that:
COBWEB achieves a higher API coverage compared to
alternative approaches. COBWEB achieves 79% API cover-
age on average, ranging from 33% to96% with the median
of89%. In contrast, Monkey and Stoat are able to cover on
average 42% and46% of energy-greedy APIs.
COBWEB is more effective in exercising different ex-
ecution contexts compared to Monkey. While C OBWEB
achieves an average of 85% in covering prime paths of LSMs,
ranging from 53% to100% with the median of 96%, Monkey
and Stoat are able to cover only 27% and40% LSM prime
paths on average. Alternative approaches perform worse in
terms of HSM coverage, failing to cover even a single HSM
prime path. This is due to the fact that neither Monkey nor
Stoat are capable of effectively manipulating hardware and
systematically create system events during testing.
C. RQ2: Effectiveness
We investigated the ability of C OBWEB , Monkey, and Stoat
for ﬁnding the energy defects in the subject apps. To that
end, we executed the generated tests on a Google Nexus 6
device, running Android version 6.0. During the execution
of each test, Trepn was running in the background to proﬁle
the states of hardware elements during and after execution
of each test. We used the results of fault reproduction (recall
Section VI-A) as our oracle. Similar to prior work [3], if the
energy traces obtained during the fault reproduction and test
1126
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. TABLE I: Subject apps and coverage information for C OBWEB and alternative approaches.
Apps VersionCoverage
# Tests Energy-Greedy APIs LSM HSM Detection
O (events) LH O M S O M S O M S OLH M S
a2dp.V ol8624c4f 2234 (15796) 35049 22435 86% 36% 23% 96% 22% 36% 86% 0% 0% Y Y Y N N
b9a5768 1681 (18383) 27111 17398 87% 33% 23% 96% 22% 36% 76% 0% 0% N N N N N
8231d4d 1612 (22824) 27036 17674 90% 35% 26% 96% 22% 36% 78% 0% 0% Y Y Y N Y*
4767d64 1836 (20849) 29195 18775 88% 36% 23% 96% 22% 36% 76% 0% 0% Y Y N N N*
GTalkdce8b85 586 (2507) 47669 62759 94% 49% 49% 53% 14% 25% 56% 0% 0% Y Y N N N
c0f8fa2 531 (4836) 45406 59611 94% 51% 49% 53% 14% 25% 51% 0% 0% Y Y Y N Y*
5ce2d94 466 (3558) 44748 59323 94% 49% 49% 53% 14% 25% 53% 0% 0% Y N N N N
Openbmap56c3a67 751 (2328) 4933 2786 90% 46% 62% 80% 28% 38% 77% 0% 0% Y Y N N N
14d166f 746 (2984) 5343 3060 89% 45% 62% 80% 28% 38% 83% 0% 0% Y N Y N* N*
f72421f 754 (2980) 5410 3153 96% 46% 62% 80% 28% 38% 78% 0% 0% Y Y N N N
OpenCamera 1.0 606 (3916) 72241 54296 33% 49% 54% 100% 26% 66% 66% 0% 0% Y Y Y Y* Y*
Senoriume153fdf 96 (288) 354 1127 63% 37% 56% 100% 30% 51% 86% 0% 0% Y N Y N N
94c9a8d 99 (336) 394 1145 63% 36% 56% 100% 30% 51% 96% 0% 0% Y N Y N N
94c9a8d 105 (337) 428 1360 63% 37% 57% 100% 30% 51% 85% 0% 0% Y N Y N* N
Ushahidi 4f20612 3519 (12523) 4865 5032 79% 46% 39% 86% 59% 41% 59% 0% 0% Y Y Y Y* Y*
O: Original C OBWEB ,L: C OBWEB without LSM, H: C OBWEB without HSM, M: Monkey, S: Stoat
execution matched, we determined that the test suite was able
to detect the corresponding fault. Column Detection in Table I
demonstrates the result of this study. These results show that:
Random GUI exploration and random system event
injection proves to be highly ineffective. Monkey and Stoat
were able to detect only 2and4energy defects, respectively.
The root cause of this weakness comes from their inability to
cover energy-greedy APIs under different execution contexts.
In fact, Monkey and Stoat were able to cover the code related
to4and5energy defects, respectively—those marked with
asterisk under Detection column. Even when covered by these
tools, manifestation of those defects requires the apps to
be executed under speciﬁc component lifecycle or hardware
states.
COBWEB is effective for detecting energy defects. From
the total of 15veriﬁed energy defects, C OBWEB was able to
detect 14, where 10of them could be detected by exercising
different component lifecycle states and 4of them could be
revealed under speciﬁc hardware states. C OBWEB was not
able to ﬁnd 1energy defect in a2dp.Vol . Further investiga-
tion showed that manifestation of this energy defect requires
complex interactions with the app. In fact, a2dp.Vol requires
a user to connect a Bluetooth device to her phone, change her
location, save her location in a database, and disconnect the
Bluetooth device from her phone. C OBWEB generated a test
for each of these use-cases, but not a single test to reproduce
the whole scenario, as they cover different branches of CTG.
D. RQ3: Necessity of the Models
To evaluate necessity and usefulness of LSM and HSM
models, we ﬁrst compared the size of test suites originally
generated by C OBWEB that considers these models with that
generated by a modiﬁed version of Algorithm 1 that exhaus-
tively injects lifecycle or hardware related events into event
sequences, i.e., changed the convergence operator. In addition,
we compared the ability of test suites originally generated
by C OBWEB in ﬁnding energy defects with that generated
without using the models, i.e., we removed the consideration
of execution context from the test generation process. From
the results presented in Table I, we can observe that:
Contextual models make energy testing scalable. Without
a model, each component of app should be exhaustively
tested under all possible lifecycle/hardware states. ColumnsLandHunder #Tests show the size of test suites generate
by exhaustively injecting lifecycle/hardware related events to
explore all possible states. We can see that by using LSM and
HSM models, C OBWEB is able to generate test suites that are
27and28times smaller, respectively.
Execution context is crucial for detecting energy defects.
ColumnsLandHunder Detection illustrate the number
of faults that can be detected by test suites not using either
LSM or HSM models. Test suites generated without using
LSM and HSM models can only detect 9energy defects,
thereby are inferior to those generated by C OBWEB in terms
of their ability to ﬁnd energy defects. These results conﬁrm
our intuition about the importance of considering contextual
conditions for energy testing.
E. RQ4: Energy Defects Coverage
We evaluated C OBWEB ’s ability to ﬁnd different types of
energy defect by comparing it with the state-of-the-art energy
analysis approaches. To that end, we used a recently published
energy defect model for Android [3], consisting of 28energy
defect types, categorized into seven groups, namely bluetooth,
display, location, network, recurring callback, sensor, and
wakelock. For approaches that are either not publicly available
or do not work on newer versions of Android, we rely on
the corresponding paper, i.e., description of the approach and
limitations stated in the paper, to determine if it is able
to detect each type of defect. Table II shows how these
approaches differ in terms of their ability to ﬁnd various types
of energy defect.
We can see that COBWEB is able to detect a wider
range of energy defects compared to prior techniques .
Furthermore, it appears that dynamic analysis solutions, such
as C OBWEB and [46], are able to detect a wider variety of
energy defects compared to static analysis solutions.
F . RQ5: Performance
To answer this research question, we evaluated the time
required for C OBWEB to extract models as well as the time
required for test generation and test minimization. To evaluate
test generation time, we measured time from when the algo-
rithm starts generating initial population to when it terminates
the loop in Algorithm 1 at Line 11. We ran the experiments
on a laptop with 2.2 GHz Intel Core i7 processor and 16 GB
1127
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. TABLE II: Comparing ability of energy analysis tools to ﬁnd different types of energy defects.
Defect Model C OBWEB [42] [43] [29] [44] [45] [20] [46] [47]
Analysis Type - Hybrid Static Hybrid Static Static Static Dynamic Dynamic Static
Lifecycle Context - Y N N Y N Y Y N N
Hardware Context - Y N N N N N N N N
Bluetooth 3 3 0 0 0 0 0 0 2 0
Display 4 3 0 0 0 0 1 0 1 1
Location 4 2 0 1 0 1 0 1 1 0
Network 6 5 0 1 0 1 0 0 1 0
Recurring Callback 5 3 1 0 0 0 0 0 2 0
Sensor 2 2 0 1 0 1 0 1 2 0
Wakelock 4 4 0 2 2 2 0 2 3 0
Total 28 22 1 5 2 5 1 4 12 1
Fig. 8: Performance characteristics of C OBWEB
DDR3 RAM. Figure 8 shows the performance characteristics
of C OBWEB for each subject app (results are averaged over
various faulty versions of apps presented in Table I). From this
data, we can see that C OBWEB takes 23seconds on average
to extract models, 8minutes for test generation and execution
(including calculation of ﬁtness value), and 57seconds for
test-suite minimization. These results corroborate scalability of
COBWEB for test generation, making it a reasonably efﬁcient
testing tool for detecting energy issues.
VII. R ELATED WORK
We provide an overview of the related research on mobile
testing and green software engineering.
Mobile Testing : Test input generation techniques for Android
apps mainly focus on either fuzzing to generate Intents or
exercising an Android app through its GUI [4]. Several
approaches generate Intents with null payloads or by ran-
domly generating payloads for Intents [48], [49], [50], [51].
Dynodroid [16] and Monkey [39] generate test inputs using
random input values. Several techniques [52], [53], [54], [55],
[56], [13], [14], [15] rely on a model of the GUI, usually
constructed dynamically and non-systematically, leading to
unexplored program states. POLARIZ [57] uses information
from crowd-based testing to enhance mobile test generation.
Another set of techniques employ systematic exploration of
an app in the construction of test cases: EvoDroid [10] and
Sapienz [12] employ an evolutionary algorithm; ACTEve [34],
JPF-Android [35], Collider [36], and SIG-Droid [37] utilize
symbolic execution. Another group of techniques focus on
testing for speciﬁc defects [58], [59], [17].
None of the aforementioned solutions can be used to prop-
erly test the energy behavior of Android apps, as they lack the
ability to generate tests meant to exercise contextual factors.
Green Software Engineering : In recent years, several auto-
mated approaches for analysis [60], [47], [20], [38], [61], [62],
[63], [64], [42], testing [46], [65], [3], [66], re-factoring [67],
[68], and repair [69], [45] of mobile apps have been proposed
to help developers produce more energy efﬁcient apps.
The closest approaches to C OBWEB are that of Banerjee et
al. [46], GreenDroid [20], and EnergyPatch [43]. Banerjee etal. [46] present a search-based proﬁling strategy with the goal
of identifying energy defects in an app. They construct a graph
representing an app’s GUI events, extract the event traces using
the (incomplete) generated graph, and explore event traces that
may possibly reach energy hotspots, while proﬁling energy
consumption of the device. The proﬁling process always starts
from the root activity of an app, making it infeasible to
test particular sequences of the app’s lifecycle. Finally, the
usage of a power measurement hardware makes their approach
device dependent and impractical. EnergyPatch [43] ﬁxes the
scalability issue of the prior work [46] by using abstract
interpretation-based program analysis to detect resource leaks
instead of power trace oracle. Similar to the prior work, they
rely on a dynamically constructed model for GUI events to
guide the search for ﬁnding paths leading to a resource leak.
GreenDroid uses only bounded symbolic execution for ﬁnding
event sequences that lead to resource leaks.
None of these techniques consider system inputs that are
independent of GUI, nor do they incorporate lifecycle and
hardware contextual factors in the generation of tests. They
also do not generate reproducible tests. More importantly, they
generate tests speciﬁcally targeted for resource leaks, failing
to detect wide range of other energy defects shown in Table II.
VIII. C ONCLUSION AND FUTURE WORK
Energy efﬁciency is an important quality attribute for mobile
apps. Naturally, prior to releasing apps, developers need to test
them for energy defects. Yet, there is a lack of practical tools
and techniques for energy testing. In this paper, we presented
COBWEB , a search-based energy testing framework for An-
droid. The approach employs a set of novel models to take
execution context into account, i.e., lifecycle and hardware
state context, in the generation of tests that can effectively
ﬁnd energy defects. Additionally, C OBWEB implements novel
genetic operators tailored to the generation of energy tests. Our
experience with C OBWEB on Android apps with real energy
defects corroborate its ability to effectively generate useful
tests to ﬁnd energy defects in a scalable fashion.
Currently, we are considering several directions for future
work. First, test generation is not complete without accounting
for the test oracle. We are planning to explore automated
methods of generating energy test oracles in future. We also
plan to extend the approach for multi-objective test genera-
tion, making C OBWEB a more general Android testing tool.
COBWEB and research artifacts are available publicly [33].
IX. A CKNOWLEDGMENT
This work was supported in part by awards CCF-1252644,
CNS-1629771, CCF-1618132, CNS-1823262 from the Na-
tional Science Foundation, and a Google PhD Fellowship.
1128
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1]C. Wilke, S. Richly, S. Gotz, C. Piechnick, and U. Aßmann, “Energy
consumption and efﬁciency in mobile applications: A user feedback
study,” in The Internation Conf. on Green Computing and Communi-
cations .
[2]I. Manotas, C. Bird, R. Zhang, D. Shepherd, C. Jaspan, C. Sadowski,
L. Pollock, and J. Clause, “An empirical study of practitioners’ per-
spectives on green software engineering,” in Proceedings of the 38th
International Conference on Software Engineering . ACM, 2016, pp.
237–248.
[3]R. Jabbarvand and S. Malek, “ droid: an energy-aware mutation testing
framework for android,” in Proceedings of the 2017 11th Joint Meeting
on Foundations of Software Engineering . ACM, 2017, pp. 208–219.
[4]S. R. Choudhary, A. Gorla, and A. Orso, “Automated test input
generation for android: Are we there yet?(e),” in Automated Software
Engineering (ASE), 2015 30th IEEE/ACM International Conference on .
IEEE, 2015, pp. 429–440.
[5]D. Amalﬁtano, A. R. Fasolino, P. Tramontana, S. De Carmine, and
A. M. Memon, “Using gui ripping for automated testing of android
applications,” in Proceedings of the 27th IEEE/ACM International
Conference on Automated Software Engineering . ACM, 2012, pp. 258–
261.
[6]T. Azim and I. Neamtiu, “Targeted and depth-ﬁrst exploration for
systematic testing of android apps,” in Acm Sigplan Notices , vol. 48,
no. 10. ACM, 2013, pp. 641–660.
[7]W. Choi, G. Necula, and K. Sen, “Guided gui testing of android apps
with minimal restart and approximate learning,” in Acm Sigplan Notices ,
vol. 48, no. 10. ACM, 2013, pp. 623–640.
[8]W. Yang, M. R. Prasad, and T. Xie, “A grey-box approach for automated
gui-model generation of mobile applications,” in International Confer-
ence on Fundamental Approaches to Software Engineering . Springer,
2013, pp. 250–265.
[9]S. Hao, B. Liu, S. Nath, W. G. Halfond, and R. Govindan, “Puma:
programmable ui-automation for large-scale dynamic analysis of mobile
apps,” in Proceedings of the 12th annual international conference on
Mobile systems, applications, and services . ACM, 2014, pp. 204–217.
[10]R. Mahmood, N. Mirzaei, and S. Malek, “Evodroid: Segmented evo-
lutionary testing of android apps,” in Proceedings of the 22nd ACM
SIGSOFT International Symposium on Foundations of Software Engi-
neering . ACM, 2014, pp. 599–609.
[11]N. Mirzaei, J. Garcia, H. Bagheri, A. Sadeghi, and S. Malek, “Reducing
combinatorics in gui testing of android applications,” in Software En-
gineering (ICSE), 2016 IEEE/ACM 38th International Conference on .
IEEE, 2016, pp. 559–570.
[12]K. Mao, M. Harman, and Y . Jia, “Sapienz: Multi-objective automated
testing for android applications,” in Proceedings of the 25th International
Symposium on Software Testing and Analysis . ACM, 2016, pp. 94–105.
[13]T. Su, G. Meng, Y . Chen, K. Wu, W. Yang, Y . Yao, G. Pu, Y . Liu, and
Z. Su, “Guided, stochastic model-based gui testing of android apps,” in
Proceedings of the 2017 11th Joint Meeting on Foundations of Software
Engineering . ACM, 2017, pp. 245–256.
[14]C. Zhang, H. Cheng, E. Tang, X. Chen, L. Bu, and X. Li, “Sketch-
guided gui test generation for mobile applications,” in Proceedings of
the 32nd IEEE/ACM International Conference on Automated Software
Engineering . IEEE Press, 2017, pp. 38–43.
[15]W. Song, X. Qian, and J. Huang, “Ehbdroid: beyond gui testing for
android applications,” in Proceedings of the 32nd IEEE/ACM Interna-
tional Conference on Automated Software Engineering . IEEE Press,
2017, pp. 27–37.
[16]A. Machiry, R. Tahiliani, and M. Naik, “Dynodroid: An input generation
system for android apps,” in Proceedings of the 2013 9th Joint Meeting
on Foundations of Software Engineering . ACM, 2013, pp. 224–234.
[17]L. L. Zhang, C.-J. M. Liang, Y . Liu, and E. Chen, “Systematically
testing background services of mobile apps,” in Automated Software
Engineering (ASE), 2017 32nd IEEE/ACM International Conference on .
IEEE, 2017, pp. 4–15.
[18]“MyTracker Android App,” 2017. [Online]. Available: https://github.
com/ReyhanJB/MyTracker
[19]“Location manager strategies,” 2017. [Online]. Available: https:
//developer.android.com/guide/topics/location/strategies.html
[20]Y . Liu, C. Xu, S.-C. Cheung, and J. L ¨u, “Greendroid: Automated
diagnosis of energy inefﬁciency for smartphone applications,” IEEE
Transactions on Software Engineering , vol. 40, no. 9, pp. 911–940, 2014.[21]M. Harman and P. McMinn, “A theoretical and empirical study of search-
based testing: Local, global, and hybrid search,” IEEE Transactions on
Software Engineering , vol. 36, no. 2, pp. 226–247, 2010.
[22]M. Harman, P. McMinn, J. T. De Souza, and S. Yoo, “Search based
software engineering: Techniques, taxonomy, tutorial,” in Empirical
software engineering and veriﬁcation . Springer, 2012, pp. 1–59.
[23]E. Cantu-Paz and D. E. Goldberg, “Efﬁcient parallel genetic algorithms:
theory and practice,” Computer methods in applied mechanics and
engineering , vol. 186, no. 2-4, pp. 221–238, 2000.
[24]F. Asadi, G. Antoniol, and Y .-G. Gueheneuc, “Concept location with
genetic algorithms: A comparison of four distributed architectures,” in
Search Based Software Engineering (SSBSE), 2010 Second International
Symposium on . IEEE, 2010, pp. 153–162.
[25]“Robolectric,” 2017. [Online]. Available: http://robolectric.org/
[26]“Android testing support library : Espresso,” 2017. [Online]. Available:
https://google.github.io/android-testing-support-library/docs/espresso/
[27]R. Vall ´ee-Rai, P. Co, E. Gagnon, L. Hendren, P. Lam, and V . Sundaresan,
“Soot-a java bytecode optimization framework,” in Proceedings of the
1999 conference of the Centre for Advanced Studies on Collaborative
research . IBM Press, 1999, p. 13.
[28]D. Octeau, D. Luchaup, M. Dering, S. Jha, and P. McDaniel, “Composite
constant propagation: Application to android inter-component commu-
nication analysis,” in Proceedings of the 37th International Conference
on Software Engineering-Volume 1 . IEEE Press, 2015, pp. 77–88.
[29]Y . Liu, C. Xu, S.-C. Cheung, and V . Terragni, “Understanding and
detecting wake lock misuses for android applications,” pp. 396–409,
2016.
[30]A. Pathak, Y . C. Hu, and M. Zhang, “Where is the energy spent inside
my app?: ﬁne grained energy accounting on smartphones with eprof,” in
Proceedings of the 7th ACM european conference on Computer Systems .
ACM, 2012, pp. 29–42.
[31]“Android api reference,” 2017. [Online]. Available: https://developer.
android.com/reference/packages.html
[32]“crawler4j,” 2017. [Online]. Available: https://github.com/yasserg/
crawler4j
[33]“Cobweb website,” 2018. [Online]. Available: https://sites.google.com/
view/icse-cobweb
[34]S. Anand, M. Naik, M. J. Harrold, and H. Yang, “Automated concolic
testing of smartphone apps,” in Proceedings of the ACM SIGSOFT 20th
International Symposium on the Foundations of Software Engineering ,
ser. FSE ’12. New York, NY , USA: ACM, 2012, pp. 59:1–59:11.
[Online]. Available: http://doi.acm.org/10.1145/2393596.2393666
[35]H. van der Merwe, B. van der Merwe, and W. Visser, “Execution
and property speciﬁcations for jpf-android,” SIGSOFT Softw. Eng.
Notes , vol. 39, no. 1, pp. 1–5, Feb. 2014. [Online]. Available:
http://doi.acm.org/10.1145/2557833.2560576
[36]C. S. Jensen, M. R. Prasad, and A. Møller, “Automated testing
with targeted event sequence generation,” in Proceedings of the 2013
International Symposium on Software Testing and Analysis , ser. ISSTA
2013. New York, NY , USA: ACM, 2013, pp. 67–77. [Online].
Available: http://doi.acm.org/10.1145/2483760.2483777
[37]N. Mirzaei, H. Bagheri, R. Mahmood, and S. Malek, “Sig-droid:
Automated system input generation for android applications,” in Soft-
ware Reliability Engineering (ISSRE), 2015 IEEE 26th International
Symposium on . IEEE, 2015, pp. 461–471.
[38]M. Linares-V ´asquez, G. Bavota, C. Bernal-C ´ardenas, R. Oliveto,
M. Di Penta, and D. Poshyvanyk, “Mining energy-greedy api usage
patterns in android apps: an empirical study,” in Proceedings of the 11th
Working Conference on Mining Software Repositories . ACM, 2014, pp.
2–11.
[39]“UI/Application Excersizer Monkey,” 2017. [Online]. Available:
http://developer.android.com/tools/help/monkey.html
[40]L. Ben-Zur, “Using Trepn Proﬁler for Power-
Efﬁcient Apps,” https://developer.qualcomm.com/
blog/developer-tool-spotlight-using-trepn-proﬁler-power-efﬁcient-apps,
2017.
[41]“EMMA: a free Java code coverage tool,” http://emma.sourceforge.net.
[42]Y . Lyu, D. Li, and W. G. Halfond, “Remove rats from your code:
automated optimization of resource inefﬁcient database writes for mobile
applications,” in Proceedings of the 27th ACM SIGSOFT International
Symposium on Software Testing and Analysis . ACM, 2018, pp. 310–
321.
1129
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. [43]A. Banerjee, L. K. Chong, C. Ballabriga, and A. Roychoudhury, “En-
ergypatch: Repairing resource leaks to improve energy-efﬁciency of
android apps,” IEEE Transactions on Software Engineering , vol. 44,
no. 5, pp. 470–490, 2018.
[44]T. Wu, J. Liu, Z. Xu, C. Guo, Y . Zhang, J. Yan, and J. Zhang, “Light-
weight, inter-procedural and callback-aware resource leak detection for
android apps.” IEEE Trans. Software Eng. , vol. 42, no. 11, pp. 1054–
1076, 2016.
[45]M. Linares-V ´asquez, G. Bavota, C. E. B. C ´ardenas, R. Oliveto,
M. Di Penta, and D. Poshyvanyk, “Optimizing energy consumption of
guis in android apps: a multi-objective approach,” in Proceedings of
the 2015 10th Joint Meeting on Foundations of Software Engineering .
ACM, 2015, pp. 143–154.
[46]A. Banerjee, L. K. Chong, S. Chattopadhyay, and A. Roychoudhury,
“Detecting energy bugs and hotspots in mobile apps,” in Proceedings of
the 22nd ACM SIGSOFT International Symposium on Foundations of
Software Engineering . ACM, 2014, pp. 588–598.
[47]D. Li, A. H. Tran, and W. G. Halfond, “Making web applications
more energy efﬁcient for oled smartphones,” in Proceedings of the 36th
International Conference on Software Engineering . ACM, 2014, pp.
527–538.
[48]H. Ye, S. Cheng, L. Zhang, and F. Jiang, “DroidFuzzer: Fuzzing the
Android Apps with Intent-Filter Tag,” in Proceedings of International
Conference on Advances in Mobile Computing & Multimedia , ser.
MoMM ’13. New York, NY , USA: ACM, 2013, pp. 68:68–68:74.
[Online]. Available: http://doi.acm.org/10.1145/2536853.2536881
[49]K. Yang, J. Zhuge, Y . Wang, L. Zhou, and H. Duan,
“IntentFuzzer: Detecting Capability Leaks of Android Applications,”
inProceedings of the 9th ACM Symposium on Information,
Computer and Communications Security , ser. ASIA CCS ’14. New
York, NY , USA: ACM, 2014, pp. 531–536. [Online]. Available:
http://doi.acm.org/10.1145/2590296.2590316
[50]R. Sasnauskas and J. Regehr, “Intent Fuzzer: Crafting Intents of
Death,” in Proceedings of the 2014 Joint International Workshop on
Dynamic Analysis (WODA) and Software and System Performance
Testing, Debugging, and Analytics (PERTEA) , ser. WODA+PERTEA
2014. New York, NY , USA: ACM, 2014, pp. 1–5. [Online]. Available:
http://doi.acm.org/10.1145/2632168.2632169
[51]A. Maji, F. Arshad, S. Bagchi, and J. Rellermeyer, “An empirical study
of the robustness of Inter-component Communication in Android,” in
2012 42nd Annual IEEE/IFIP International Conference on Dependable
Systems and Networks (DSN) , Jun. 2012, pp. 1–12.
[52]D. Amalﬁtano, A. R. Fasolino, P. Tramontana, S. De Carmine, and
A. M. Memon, “Using gui ripping for automated testing of android
applications,” in Proceedings of the 27th IEEE/ACM International
Conference on Automated Software Engineering , ser. ASE 2012. New
York, NY , USA: ACM, 2012, pp. 258–261. [Online]. Available:
http://doi.acm.org/10.1145/2351676.2351717
[53]D. Amalﬁtano, A. Fasolino, P. Tramontana, B. Ta, and A. Memon,
“Mobiguitar: Automated model-based testing of mobile apps,” Software,
IEEE , vol. 32, no. 5, pp. 53–59, Sept 2015.
[54]W. Yang, M. Prasad, and T. Xie, “A grey-box approach for automated
gui-model generation of mobile applications,” in Fundamental
Approaches to Software Engineering , ser. Lecture Notes in Computer
Science, V . Cortellessa and D. Varr ´o, Eds. Springer Berlin
Heidelberg, 2013, vol. 7793, pp. 250–265. [Online]. Available:
http://dx.doi.org/10.1007/978-3-642-37057-1 19[55]T. Azim and I. Neamtiu, “Targeted and depth-ﬁrst exploration for
systematic testing of android apps,” SIGPLAN Not. , vol. 48, no. 10, pp.
641–660, Oct. 2013. [Online]. Available: http://doi.acm.org/10.1145/
2544173.2509549
[56]S. Hao, B. Liu, S. Nath, W. G. Halfond, and R. Govindan, “Puma:
Programmable ui-automation for large-scale dynamic analysis of mobile
apps,” in Proceedings of the 12th Annual International Conference
on Mobile Systems, Applications, and Services , ser. MobiSys ’14.
New York, NY , USA: ACM, 2014, pp. 204–217. [Online]. Available:
http://doi.acm.org/10.1145/2594368.2594390
[57]K. Mao, M. Harman, and Y . Jia, “Crowd intelligence enhances auto-
mated mobile testing,” in Automated Software Engineering (ASE), 2017
32nd IEEE/ACM International Conference on . IEEE, 2017, pp. 16–26.
[58]R. Hay, O. Tripp, and M. Pistoia, “Dynamic detection of inter-
application communication vulnerabilities in android,” in Proceedings
of the 2015 International Symposium on Software Testing and Analysis ,
ser. ISSTA 2015. New York, NY , USA: ACM, 2015, pp. 118–128.
[Online]. Available: http://doi.acm.org/10.1145/2771783.2771800
[59]A. Sadeghi, R. Jabbarvand, and S. Malek, “Patdroid: permission-aware
gui testing of android,” in Proceedings of the 2017 11th Joint Meeting
on Foundations of Software Engineering . ACM, 2017, pp. 220–232.
[60]C. Guo, J. Zhang, J. Yan, Z. Zhang, and Y . Zhang, “Characterizing and
detecting resource leaks in android applications,” in Automated Software
Engineering (ASE), 2013 IEEE/ACM 28th International Conference on .
IEEE, 2013, pp. 389–398.
[61]A. Gupta, T. Zimmermann, C. Bird, N. Nagappan, T. Bhat, and S. Em-
ran, “Mining energy traces to aid in software development: An empirical
case study,” in Proceedings of the 8th ACM/IEEE International Sympo-
sium on Empirical Software Engineering and Measurement . ACM,
2014, p. 40.
[62]R. Jabbarvand, A. Sadeghi, J. Garcia, S. Malek, and P. Ammann,
“Ecodroid: An approach for energy-based ranking of android apps,”
inProceedings of the Fourth International Workshop on Green and
Sustainable Software . IEEE Press, 2015, pp. 8–14.
[63]H. Wu, S. Yang, and A. Rountev, “Static detection of energy defect pat-
terns in android applications,” in Proceedings of the 25th International
Conference on Compiler Construction . ACM, 2016, pp. 185–195.
[64]S. Chowdhury, S. Di Nardo, A. Hindle, and Z. M. J. Jiang, “An
exploratory study on assessing the energy impact of logging on android
applications,” Empirical Software Engineering , vol. 23, no. 3, pp. 1422–
1456, 2018.
[65]R. Jabbarvand, A. Sadeghi, H. Bagheri, and S. Malek, “Energy-aware
test-suite minimization for android apps,” in Proceedings of the 25th
International Symposium on Software Testing and Analysis . ACM,
2016, pp. 425–436.
[66]H. Wu, Y . Wang, and A. Rountev, “S entinel: generating gui tests for
android sensor leaks,” in Proceedings of the 13th International Workshop
on Automation of Software Test . ACM, 2018, pp. 27–33.
[67]I. Manotas, L. Pollock, and J. Clause, “Seeds: a software engineer’s
energy-optimization decision support framework,” in Proceedings of the
36th International Conference on Software Engineering . ACM, 2014,
pp. 503–514.
[68]A. Banerjee and A. Roychoudhury, “Automated re-factoring of android
apps to enhance energy-efﬁciency,” 2016.
[69]D. Li, Y . Lyu, J. Gui, and W. G. Halfond, “Automated energy optimiza-
tion of http requests for mobile applications,” in Proceedings of the 38th
International Conference on Software Engineering . ACM, 2016, pp.
249–260.
1130
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:40:54 UTC from IEEE Xplore.  Restrictions apply. 