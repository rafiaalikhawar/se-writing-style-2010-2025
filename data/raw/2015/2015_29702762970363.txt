Mining Revision Histories to Detect Cross-Language
Clones without Intermediates
Xiao Cheng1, Zhiming Peng2, Lingxiao Jiang2, Hao Zhong1, Haibo Yu3, Jianjun Zhao4
1Department of Computer Science and Engineering, Shanghai Jiao Tong University, China
2School of Information Systems, Singapore Management University, Singapore
3School of Software, Shanghai Jiao Tong University, China
4Department of Advanced Information Technology, Kyushu University, Japan
fx.cheng, zhonghao, haibo yug@sjtu.edu.cn,fzmpeng, lxjiangg@smu.edu.sg, zhao@ait.kyushu-u.ac.jp
ABSTRACT
To attract more users on dierent platforms, many projects
release their versions in multiple programming languages
(e.g., Java and C#). They typically have many code snip-
pets that implement similar functionalities, i.e., cross-language
clones. Programmers often need to track and modify cross-
language clones consistently to maintain similar functional-
ities across dierent language implementations. In litera-
ture, researchers have proposed approaches to detect cross-
language clones, mostly for languages that share a common
intermediate language (such as the .NET language family)
so that techniques for detecting single-language clones can
be applied. As a result, those approaches cannot detect
cross-language clones for many projects that are not imple-
mented in a .NET language. To overcome the limitation,
in this paper, we propose a novel approach, CLCMiner ,
that detects cross-language clones automatically without the
need of an intermediate language. Our approach mines such
clones from revision histories, which reect how program-
mers maintain cross-language clones in practice. We have
implemented a prototype tool for our approach and con-
ducted an evaluation on ve open source projects that have
versions in Java and C#. The results show that CLCMiner
achieves high accuracy and point to promising future work.
CCS Concepts
Software and its engineering !Software libraries and
repositories; Software maintenance tools;
Keywords
cross-language clone, di, revision history
1. INTRODUCTION
Due to various considerations, many projects are imple-
mented in dierent programming languages. For example,
ANTLR [1] releases its versions in Java, C#, JavaScript and
Python. As another example, Lucene [2] release its versions
in Java and C#. When maintaining such projects, if a codesnippet is modied, programmers often copy their modi-
cations to proper locations in other language versions, and
conduct further editions, according to the syntactic and se-
mantic requirements of the target programming language.
As a result, released versions can have similar code snippet
in dierent programming languages. In literature, Kraft et
al.[15] call such code snippets as cross-language code clones .
Cross-language clones can be inevitable and benecent for
a project [13], even though sometimes code clones may be
harmful and could be removed [6]. It also becomes neces-
sary for programmers to locate and maintain cross-language
clones. For example, after a developer D1 develops a cross-
language project, another developer D2, who is not familiar
with the source code, joins the project. If D2 modies a code
snippet in a programming language, all the clone instances
of the code snippet in another language may require similar
modications. In particular, when a bug is reported in a
programming language, D2 often needs to check versions in
other languages. It can be tedious for D2 to locate the clones
manually. An automated cross-language clone detection tool
can be useful for D2 and reduce overlooks.
Researchers [9, 12, 10, 11] have proposed various detec-
tion approaches for code clones in one programming lan-
guage. Recently, researchers [15, 3] start to detect cross-
language code clones for the .NET language family. How-
ever, their approaches are limited to the languages that share
a common intermediate language, while many projects are
implemented in other programming languages that cannot
be addressed by existing approaches. Without a common in-
termediate language, it becomes more challenging to detect
cross-language clones. In this paper, we need to overcome
the following challenges to detect such clones:
Challenge 1. Existing approaches [15, 3] can detect
cross-language clones for the .NET language family, which
is built on the Microsoft intermediate language. These ap-
proaches assume that dierent programming languages share
a common intermediate language. As a result, it is feasible
to reduce source code to the intermediate language and to
detect clones based on such intermediates. However, most
languages do not have such a common intermediate lan-
guage, which makes the task challenging.
Challenge 2. Dierent programming languages have dif-
ferent grammars and APIs. As a result, even if code snippets
in dierent programming languages implements the same
functionality, their structures (even their lines of code) can
be dierent. It becomes more challenge to determine cross-
language clones than clones in a single language.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ASE‚Äô16 , September 3‚Äì7, 2016, Singapore, Singapore
c2016 ACM. 978-1-4503-3845-5/16/09...$15.00
http://dx.doi.org/10.1145/2970276.2970363
696
1@@ -129,11 +129,11 @@ public class MachineProbe {2if(!t.isEpsilon() && !t.label.getSet().and(label).isNil()&&next.contains(t.target)) {3if (p.associatedASTNode != null) {4-antlr.Token oldtoken = p.associatedASTNode.token;5+Token oldtoken = p.associatedASTNode.token;6CommonToken token = new CommonToken(oldtoken.getType(), oldtoken.getText());7token.setLine(oldtoken.getLine());8-token.setColumn(oldtoken.getColumn());9+token.setCharPositionInLine(oldtoken.getCharPositionInLine());10tokens.add(token);11break nfaConfigLoop; // found path, move to next12// NFAState set13‚Ä¶‚Ä¶(a) MachineProbe.java
1@@ -143,11 +148,11 @@ namespaceAntlr3.Analysis2{3ITokenoldtoken= p.associatedASTNode.Token;4CommonTokentoken= newCommonToken(oldtoken.Type, oldtoken.Text);5-token.Line= (oldtoken.Line);6-token.CharPositionInLine= (oldtoken.CharPositionInLine);7+token.Line= oldtoken.Line;8+token.CharPositionInLine= oldtoken.CharPositionInLine;9tokens.Add(token);10-gotoendNfaConfigLoop; // foundpath, moveto next11-// NFAStateset12+// foundpath, moveto nextNFAStateset13+gotoendNfaConfigLoop;14}15‚Ä¶‚Ä¶ (b) MachineProbe.cs
Figure 1: A Pair of Matched Dis
In this paper, we propose a new approach, CLCMiner ,
which detects cross-language clones without intermediate
languages. Our approach is based on comparing revision
histories that are recorded in repository logs. Here, Di is
a change-log tool that is widely used in Version Control Sys-
tems (VCS) such as Git, SVN, and Mercurial. In this paper,
we also call its generated delta as a di. Each didescribes
changes of a code fragment in the source code.
The rationale for our approach is that, in multi-language
projects, versions in dierent languages can have similar dis
since dierent versions should have similar functionalities
and developers may change all versions in similar ways (i.e.,
dis) to perform similar tasks. Based on this insight, our
approach detects cross-language clones through comparing
the similarity among pieces of dis in dierent programming
languages and aligning each diwith the most similar one,
which is called di matching. Meanwhile, as a di con-
tains both its changed lines of code and surrounding code
lines, it becomes easier to determine the granularity of cross-
language clones based on dis.
This paper makes the following contributions:
To the best of our knowledge, we proposed the rst
approach that detects cross-language clones for pro-
gramming languages that do not have an intermediate
language. Our approach is based on comparing change
histories, and thus reduces cross-language clone detec-
tion into a dimatching problem.
We conducted an evaluation on ve open source projects
that release versions in Java and C#. Our results show
that our approach achieves an average precision of 87%
and recall of 93%.
2. RUNNING EXAMPLE
Figure 1 shows an example of two matched dis in Java
and C# code fragments. We use the example to illustrate
the problem and how our approach works. The dion the
left records two lines of changes in an if-block in Java class
MachineProbe , while the one on the right records four lines
of changes in a block in C# class MachineProbe .
The matched dipair indicates a cross-language clone,
which has similar functionality. Both of the code fragments
intend to set the elds ( i.e.,line and charPositionIn-
Line) of the object token . The Java code achieves this
through method invocations ( i.e.,setLine() and setChar-
PositionInLine() ), while the C# code achieves this through
assigning them directly. In addition, the Java jumps out of
theif-block through a break statement, while the C# code
uses a goto statement. Our approach extracts all the dis
from the project (in both Java and C#), and matches each
diin Java code to a diin C# code according to the class
Log Parsing
Matching Normalizing
Ranking & ReportingGit Logs
Author Commit IDCommit
DateFile Name
Token Stream
ClonesDiffs
Matched DiffsCommit MessageProcessingEntity
Figure 2: Approach Overview
name ( e.g., MachineProbe ) and the text similarity ( e.g., the
identier names and the words). Thus, our approach is able
to detect the cross-language clone in Figure 1. The detailed
algorithm to match the dis will be presented in Section 3.
3. APPROACH AND IMPLEMENTATION
3.1 Overview
The same functionality implemented in dierent languages
may diverge in the syntax, but the functionality in one lan-
guage ( e.g, Java) can be used as a reference for implemen-
tation in another language ( e.g., C#). As a result, similar
variable or method names can be used in such cases. To
detect cross-language clones, CLCMiner adapts natural lan-
guage processing (NLP) techniques to calculate the similar-
ity among pieces of dis in dierent programming languages
and selects the most similar one for each dias a pair of
matched dis. Each pair of matched dis refers to a pair of
potential clones. Base on the most similar one, we expect
that other similar ones can be further detected by single-
language clone detection tools. Therefore, CLCMiner so far
does not report the second most similar or other similar ones
for each di. Finally, CLCMiner ranks the matched pairs of
dis according to their disimilarity and reports top ones
as potential cross-language clones.
Figure 2 shows an overview of CLCMiner . Each blue rect-
angle represents a processing step, and each red rounded
rectangle represents an entity. The input of CLCMiner is
git logs, and its output is a ranked list of detected potential
cross-language clones. The approach has four main steps:
1.Log Parsing. This step extracts dis and their at-
tributes from revision logs.
2.Normalizing. This step normalizes dis and pre-
pares for the comparison in the next step.
3.Di Matching. This step matches dis in dierent
languages by comparing their similarity values. For
each di, its matched one is the most similar one.
4.Ranking & Reporting. This step ranks matched
dis according to their similarity and reports cross-
language clones.
697Table 1: Attributes of Example Dis
FN MachineProbe.java MachineProbe.cs
CID 7288ec550b52a1b969ce6f1db62377241c36ed66 e589c63956a9e06aec08b146c2871211c13b1d56
CA Sharwell Sharwell
CD Mon Mar 28 15:33:44 2011 -0800 Tue May 3 20:16:15 2011 -0800
CMConvert all Tool grammars to ANTLR v3. The only remaining dependency on v2 is the
StringTemplate 3.2's use of the v2 runtime(C# 3) Code cleanup
TSif t is epsilon t label get set and label is nil next contains t target if p associated ast
node null antlr token oldtoken p associated ast node token token oldtoken p associated
ast node token common token token new common token oldtoken get type oldtoken get
text token set line oldtoken get line token set column oldtoken get column token set char
position in line oldtoken get char position in line tokens add token break nfa cong loopi token oldtoken p associated ast node token common token token new
common token oldtoken type oldtoken text token line oldtoken line token
char position in line oldtoken char position in line token line oldtoken line
token char position in line oldtoken char position in line tokens add token
goto end nfa cong loop goto end nfa cong loop
3.2 Log Parsing
In a Version Control System (VCS), repository logs record
code evolution histories. For example, the structure of git
logs is organized as follows: a git log consists of several com-
mits; each commit is related to one or more les; each le is
related to one or more dis; each direcords one or more
change hunks that occur in a code fragment [5].
Log parsing is a preparation step that extracts useful in-
formation from repository logs. CLCMiner parses a log into
a list of dis, and attaches each diwith a set of attributes ,
including Commit Date (CD), Commit Author (CA), Com-
mit ID (CID), File Name (FN), and Commit Message (CM).
For example, Table 1 lists the attributes of the dis in Fig-
ure 1. Some attributes ( e.g.,FN) are useful for matching
dis, and others ( e.g.,CID) help to uniquely locate the code.
3.3 Normalizing
Normalizing is to remove uninteresting contents from the
dis and transform the rest contents into normalized com-
parison units. CLCMiner uses the token streams of the dis
as the comparison unit, and normalizes them as follows:
1.Removing Comments. To relieve the impact of
comments in natural language, CLCMiner removes the
comments from the dirstly.
2.Lexing. CLCMiner employs a lexer to lex the code in
thediwithout comments into a token stream.
3.Removing Punctuations. Punctuations and num-
bers are removed from the token stream, as they often
do not indicate signicant semantics.
4.Post Processing. Camel case tokens are split by
the uppercase letters and tokens with underscores are
split by the underscores. After that, all tokens are
transformed to lowercases. This step paves dierence
between programming styles.
In Table 1, Column \TS" lists the two normalized token
streams of the dis in the running example.
3.4 Diff Matching
Di matching is the process to align a diin a language
(e.g., Java) to the di in the other language ( e.g., C#),
according to their similarity. Bag of Words (BOW) [8] rep-
resents a piece of text as a bag (multiset) of its words, dis-
regarding grammar and the ordering of words. CLCMiner
adopts BOW to build a characteristic vector, each dimension
of which represents the number of times that a word appears
in the token stream of a di, to calculate the similarity be-
tween two dis. Table 2 shows the characteristic vectors
for the token streams in Table 1. Column \Token" lists the
words appearing in the token streams. Columns \Java" and
\C#" list the numbers of times that each word occurs in the
di ofMachineProbe.java and MachineProbe.cs respec-
tively. Column \Dierence" lists the absolute value of the
dierence between the numbers of occurrence. For example,Table 2: Characteristic Vectors
Token Java C# Dierence
#add 1 1 0
#and 1 0 1
#antlr 1 0 1
#associated 3 1 2
#ast 3 1 2
#break 1 0 1
: : : : : : : : : : : :
#token 11 10 1
#tokens 1 1 0
#type 1 1 0
Total 80 59 61
token \break" appears in the diof Java code once but does
not appear in the C# code, and the dierence is 1 ( j1 0j).
We use the distance between two vectors to measure the
similarity of two dis. For two vectors, Vi(vi1; vi2; : : : ; v in)
andVj(vj1; vj2; : : : ; v jn), their distance is dened as:
Distance (Vi; Vj) =Pn
k=1jvik vjkjPn
k=1(vik+vjk)
In the example, the distance is 61 =(80+59) = 0 :4388. The
smaller the distance is, the more similar two dis appear.
Algorithm 1 shows the details for matching dis. It takes
as input two lists of dis, each of which represents changes of
the code fragments in a programming language. The output
is a list of matched dipairs, each of which is from dierent
input lists. CLCMiner compares the sizes of the two di
lists and sets the small one and the large one as source and
target respectively (Lines 1{2). The dis, whose le names
are the same, are called neighbors of each other. For each
diinsource (ds),CLCMiner searches target for its near-
est neighbors by comparing the distances from dsto all of
itsneighbors intarget (Lines 3{18). The shortest distance
indicates the nearest one. As long as there exists a neighbor
intarget fords,dscan be matched; otherwise, it cannot.
CLCMiner only matches a dito its nearest neighbor to
report clone pairs , instead of reporting all its top-k nearest
neighbors to form clone groups . This takes into considera-
tion that, with the nearest neighbor, the other top-k nearest
neighbors and even clones in les with dierent names can be
detected by a single-language clone detector to build more
comprehensive clone groups. Section 5 discusses more about
this setting for future work.
3.5 Ranking and Reporting
Each pair of matched dis is called clone candidates. We
rank all such pairs according to their distances. The pairs
whose didistances are lower than 0.5 are to be reported
as code clones because it is empirically determined ( cf.Sec-
tion 4) that such short distance pairs of dis are highly likely
to be cross-language clones.
4. EVALUATION
We implemented CLCMiner , and conducted evaluations
to answer the following research questions:
698Algorithm 1: Di Matching
Input :List dList jdList cs
Output :List dPair
1source =minimumList (dList j; dList cs);
2target =maximunList (dList j; dList cs);
3foreach ds2source do
4 distance 1;
5 foreach dt2target do
6 ifdt:fileName ():equals (ds:fileName ())then
7 ifDistance (ds; dt) == distance then
8 pairs:add (ds; dt);
9 end
10 ifDistance (ds; dt)< distance then
11 pairs:clean ();
12 pairs:add (ds; dt);
13 distance Distance (ds; dt);
14 end
15 end
16 end
17 dPair:addAll (pairs );
18end
19return dPair ;
RQ 1. What is the clone ratio distribution with re-
spect to the didistances?
RQ 2. What is the accuracy of CLCMiner ?
RQ 3. What is the impact of the other attributes on
cross-language clones?
4.1 Setup
In our evaluation, we use ve open source projects imple-
mented in both Java and C#, i.e., ANTLR3, FpML, Log4j
(Log4net), Spring, Lucene. Table 3 shows the projects and
lists LOCs, log sizes, numbers of commits and dis.
We apply our approach to each project to obtain the
ranked list of cross-language clone pairs as the report. Col-
umn \#Matched Di Pairs" in Table 3 lists the number of
matched dipairs according to the le name and disim-
ilarity. Due to the large number of clone candidates and
limited manpower, we randomly sampled, in a uniform way,
a small percentage of the clone candidates in the reported
ranked lists and manually labelled whether they were actual
clones. As listed in Table 3, for ANTLR3, FpML, Log4j
(Log4net), and Spring, we sampled over 6% of all the re-
ported clone candidates in each project; for Lucene, we sam-
pled about 2%. Two co-authors manually labelled whether
they were actual clones separately based on the clone def-
inition of Bellon [4] and the functionality equivalence. If
there exists a dierence between the labels given by the
two co-authors, it will be labelled and decided by a third
co-author. We calculated the clone ratio and its distribu-
tion w.r.t. the distances, where the clone ratio is dened as
CR=#clones
#candidates100%.
4.2 Result
4.2.1 RQs 1 & 2. Distribution and Accuracy
Figure 3 shows the clone ratio distribution and the accu-
mulated clone ratio, w.r.t. ,didistances. The clone ratio
distribution in Figure 3(a) indicates: 1) almost all the can-
didates whose didistances are lower than 0.3 are clones;
2) almost none of the candidates whose didistances are
larger than 0.7 is clone; 3) when distances increase from 0.3
to 0.5, the clone ratio decreases gradually; 4) when distances
increase from 0.5 to 0.7, the clone ratio decreases greatly.
The accumulated clone ratio in Figure 3(b) also decreases
with the increasing of the didistance. When the didis-Table 3: Characteristics of Subject Projects
Projects #LOCLogs#Commit #Dis#Matched#Samples(MB) Di Pairs
ANTLR3Java 49,617 32 572 2,8397,117 710C# 97,304 31 648 18,962
FpMLJava 17,810 244 329 2,7363,993 259C# 16,548 227 183 2,206
Log4j 30,287 46 2,644 19,1722,599 166Log4net 30,885 36 925 7,391
SpringJava 551,475 335 11,971 162,7396,080 400C# 224,807 316 1,747 20,160
LuceneJava 867,110 821 24,988 286,62859,377 908C# 434,577 883 1,320 43,073
tance is lower than 0.5, the clone ratio decreases slowly and
when the di distance is larger than 0.5, the clone ratio
decreases greatly.
Based on the above observation, it is reasonable to set
0.5 as the proper threshold distance. If the didistance is
lower than 0.5, its related clone candidate is considered as
a clone; if the didistance is larger than 0.5, its related
clone candidate is not considered as a clone. In other words,
we only report as clones the pairs of code fragments in the
ranked list whose didistance is lower than 0.5.
We use precision and recall to evaluate the accuracy of
CLCMiner . In this way, for ANTLR3, FpML, Log4j (Log4net),
Spring and Lucene, w.r.t. the manually labelled clone sam-
ples, the report precisions are 86%, 90%, 71%, 68% and 90%
respectively and the average precision is about 87%. For the
clone candidates in the ve projects whose didistance is
between 0.5 and 1, the clone ratios are 3%, 8%, 2%, 5%, and
2% respectively. Since it is impossible to know how many
actual cross-language clones in the projects, we calculate the
recall based on the number of the missed clones whose dis-
tance is larger than 0.5. In this way, the recalls of the ve
projects are 90%, 97%, 71%, 69% and 98% respectively and
the average recall is about 93%.
4.2.2 RQ3. Impact of More Attributes of Diffs
For matching dis, BOW is not the only choice. We iden-
tify the following attributes that may be used to improve the
eectiveness of matching cross-language clones in future.
Author. As a developer may have a programming style
that may persist even across dierent languages, we hypoth-
esize that a pair of dis from dierent language versions of a
project may be more likely to be clones if they are authored
by the same developer. To investigate the hypothesis, we
look into the labels for the clone reports sampled in the way
mentioned in Section 4.1. Among these ve projects, all
sampled pairs of dis in Spring and Log4j (Log4net) were
committed by dierent persons; about only 0.5% of the di
pairs in Lucene were committed by the same developer, and
about only 1% in FpML were committed by the same de-
veloper. ANTLR3 has a more pronounced dierence: about
74% of dipairs were made by dierent authors. So for
each pair of dis in the sampled reports, we have a variable
indicating whether it is clones and another variable indicat-
ing whether it is made by the same author. A simple t-test
showed that dipairs made by the same author are statis-
tically more likely to be clones than those made by dierent
authors, but the correlation between the two variables is
very weak (Pearson's correlation coecient is about 0.08).
Commit Time. As the functionalities in dierent lan-
guage versions of a project are likely to remain consistent,
changes in one language version may induce similar changes
in another within a short period of time. Similarly, we in-
vestigate whether the commit time dierence between the
69900.10.20.30.40.50.60.70.80.91Clone Ratio
Diff DistanceAntlr3 FpML Log4j(Log4net) Lucene Spring(a) Clone Distribution
00.10.20.30.40.50.60.70.80.91
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Clone Ratio
Diff Distance
Antlr3 FpML Log4j(Log4net) Lucene Spring
(b) Accumulated Clone Distribution
Figure 3: Clone Ratio Distribution
two dis in a reported pair is correlated with whether the
pair is a clone with t-test and Pearson's correlation. We no-
ticed that ve projects exhibit dierent correlations between
commit time dierences and clones. In FpML and Spring,
thedipairs with shorter time dierences are statistically
more likely to be clones, but the correlation coecients be-
tween these the two variables are very weak (-0.19 and -0.11).
In Log4j (Log4Net), the eect is reversed: the di pairs
with longer time dierences are statistically more likely to
be clones, although the correlation is still weak (0.33). In
ANTLR3 and Lucene, whether dipairs are clones statis-
tically has no eect on their time dierences.
Commit Message. As a commit message often summa-
rizes the changes in the commit, a dipair may be more
likely to be clones if they share similar commit messages. So
we also investigate whether the distance between the com-
mit messages of a dipair is correlated with whether the
pair is a clone. We calculate the distance between commit
messages via the same technique we used for code (Section
3.4), and we check the relationship with t-test and Pearson's
correlation. We found mixed results too as many commit
messages are empty or very brief and non-informative: in
FpML, ANTLR3, and Spring, clone pairs have statistically
shorter commit message distance, while in Log4j (Log4net)
and Lucene, clone pairs have statistically longer distance,
and the correlation coecients are all weak.
As a summary , there is no clear deciding attribute for
dipairs to be clones, besides the code itself. It could be
a combined eect of various attributes, even some contexts
beyond dis. In our future work, we plan to investigate
whether the combination of more attributes, together with
additional ones discussed in Section 5, can be used to im-
prove cross-language clone detection.
5. DISCUSSION AND FUTURE WORK
Using comments in code. In di normalization (Sec-
tion 3.3), code comments were removed as we hypothesizedthat comments in natural language may be too high-level
and appear similar even for non-clones and thus are not
accurate enough for clone detection. However, during the
manual labelling of the sampled dipair reports, we no-
ticed that many clone pairs either contain quite dierent
comments for dierent parts of the two code fragments in the
pair or contain almost exactly the same comments (which
may indicate an actual copying-pasting operation). In our
future work, we plan to more systematically investigate how
comments in code are related with clones.
Relaxing le names. Di matching (Section 3.4) used
a requirement that potentially matched dis should be from
les of the same name, and thus all code in every reported
clone pair has the same le name. However, cross-language
clones can appear in les with dierent names, especially
if they are from dierent projects. The requirement was
added to reduce the pair-wise matching time for projects
involving too many commits; it is a trade-o between e-
ciency and recall. In the future work, we will optimize our
matching algorithm and analyze how the le names impact
cross-language clones that may be from dierent projects.
Detecting clone groups and change propagation.
CLCMiner matches a di in one language to its nearest
neighbors in another language only, as we focus on the fea-
sibility of using dis for detecting cross-language clones. We
can change the setting to return all the neighbors of a di
whose distance is within a small threshold, which can en-
able us to detect cross-language clone groups, in addition to
pairs. Also, by linking clone groups based on clone transi-
tivity within a threshold and complemented with a single-
language detector, we will be able to study how changes
are propagated even through dierent languages, extending
similar studies within the same language [20].
Detecting clones beyond revision histories. Based
on revision histories, CLCMiner is limited to detect cross-
language clones that have been changed in the past in the
same project. For clones that are never changed, we can
explore more language attributes that can identify clone re-
lations ( e.g., using deep learning to build vector represen-
tation of programs [18]) across languages. This limitation
can also be compensated by a single-language detector that
can detect cross-project and same-language clones based on
certain clone transitivity across projects and languages.
Crossing more languages. Increasing demands for cross-
platform mobile applications ( e.g., iOS and Android) raise
the need for quick development that can reuse code across
more diverse kinds of languages ( e.g., Objective-C, Swift,
and Java). In our future work, we plan to adapt CLCMiner
to more languages and explore more attributes that can
identify co-change relations and be used to detect clones
and facilitate code reuse across dierent languages.
Handling false positives. Although CLCMiner reports
high precisions, there is still space for improvement. We in-
vestigated the false positives and found various characteris-
tics causing \accidental similarity" among dis: 1) a short
method is dened in one dibut invoked in the other di;
2) the dis contain code that handles exceptions or errors;
3) the dis contain a large number of same string constants
used dierently; 4) the dis contain a number of dierent
numeric values which were excluded by our normalizing step;
5) the dis contain code that uses the same set of library
functions ( e.g., File I/O, HttpHeaders) in dierent ways. In
future work, we will rene CLCMiner to handle such cases.
700Comparing with token-based clone detection. Some
token-based clone detection techniques [19], can run in plain
text mode to detect some cross-language clones. For ex-
ample, CCFinder lexes each line of source les into token
sequence and utilizes sux-tree-based substring matching
algorithm to search for similar subsequences. Dierent from
CCFinder ,CLCMiner splits each camel case identier ( e.g.,
the variable name) and utilizes the statistical method to cal-
culate the distance between dis and search for similar dis.
We will compare CLCMiner with CCFinder in future work.
6. RELATED WORK
Cross-language clone detection. The number of var-
ious software systems implemented in multiple languages is
increasing considerably [14], but cross-language clone detec-
tion is limited. Kraft et al. [15] conduct the rst study on
code clones that span over multiple languages. They imple-
mented a tool called C2D2 based on the CodeDOM library
in the Microsoft .NET framework, which uses NRefactory
Library to generate the Unied CodeDOM graph for both
C# and VB.NET. Al-omari et al. [3] present a clone detec-
tion approach for the .NET language family too, based on
the Common Intermediate Language (CIL). It can detect
cross-language clone pairs in C#, J#, and VB.NET. Com-
pared with these work, our approach focuses on detecting
cross-language clone detection on dierent platforms with-
out common intermediate languages.
Data mining in VCS. There are considerable studies
of data mining in Version Control Systems (VCS). Zimmer-
mann et al. [21] apply data mining on version histories to
recommend related syntactic changes. G^ rba et al. [7] apply
concept analysis on VCS to identify groups of co-changes.
McIntosh, et al. [16] mine source and test code for accom-
panying build changes. Meng et al. [17] mine revision histo-
ries to identify updated API interfaces. We mine VCS for a
dierent purpose, i.e., detecting cross-language clones.
7. CONCLUSION
This paper proposes a novel approach, CLCMiner , that
detects cross-language clones without common intermediate
languages. Our key idea is to utilize disimilarity. We have
implemented and evaluated its prototype on ve open source
projects. The results show that CLCMiner can detect many
cross-language code clones with a high precision of 87% and
recall of 93% on average ( w.r.t. distance threshold 0.5).
To improve CLCMiner in our future work, we plan to
rene the handling of false positives, detect more cross-
language clones not captured in revision histories by incor-
porating in single-language clone detectors, and detect more
clone groups across more languages ( e.g., Objective-C, Swift,
and Java) as described in Section 5.
8. ACKNOWLEDGMENTS
This work is sponsored by the 973 Program in China (No.
2015CB352203), the National Nature Science Foundation of
China (No. 61572312, No. 61572313, and No. 61272102)
and the grant of Science and Technology Commission of
Shanghai Municipality (No. 15DZ1100305). This work is
performed during Xiao Cheng's visit to Singapore Manage-
ment University (SMU) and partially supported by SMU.
Also, we thank all anonymous reviewers for their feedbacks.9. REFERENCES
[1] Antlr. http://www.antlr.org.
[2] Lucene. http://lucene.apache.org.
[3] F. Al-Omari, I. Keivanloo, C. K. Roy, and J. Rilling.
Detecting clones across microsoft .net programming
languages. In Proc. WCRE , pages 405{414, 2012.
[4] S. Bellon, R. Koschke, G. Antoniol, J. Krinke, and
E. Merlo. Comparison and evaluation of clone
detection tools. TSE, 33(9):577{591, 2007.
[5] C. Bird, P. C. Rigby, E. T. Barr, D. J. Hamilton,
D. M. Germ an, and P. T. Devanbu. The promises and
perils of mining git. In MSR , pages 1{10, 2009.
[6] R. Fanta and V. Rajlich. Removing clones from the
code. J. of Software Maintenance , 11(4):223{243, 1999.
[7] T. G^ rba, S. Ducasse, A. Kuhn, R. Marinescu, and
D. Ratiu. Using concept analysis to detect co-change
patterns. In Proc. ESEC/FSE , pages 83{89, 2007.
[8] Z. S. Harris. Distributional structure. Word ,
10(2-3):146{162, 1954.
[9] L. Jiang, G. Misherghi, Z. Su, and S. Glondu.
DECKARD: scalable and accurate tree-based
detection of code clones. In ICSE , pages 96{105, 2007.
[10] L. Jiang and Z. Su. Automatic mining of functionally
equivalent code fragments via random testing. In Proc.
ISSTA , pages 81{92, 2009.
[11] E. J urgens, F. Deissenboeck, and B. Hummel.
Clonedetective - A workbench for clone detection
research. In Proc. ICSE , pages 603{606, 2009.
[12] T. Kamiya, S. Kusumoto, and K. Inoue. CCFinder: A
multilinguistic token-based code clone detection
system for large scale source code. IEEE Transaction
on Software Engineering , 28(7):654{670, 2002.
[13] C. J. Kapser and M. W. Godfrey. \cloning considered
harmful" considered harmful: Patterns of cloning in
software. ESME , 13(6):645{692, Dec 2008.
[14] K. Kontogiannis, P. K. Linos, and K. Wong.
Comprehension and maintenance of large-scale
multi-language software applications. In Proc. ICSM ,
pages 497{500, 2006.
[15] N. A. Kraft, B. W. Bonds, and R. K. Smith.
Cross-language clone detection. In Proc. SEKE , pages
54{59, 2008.
[16] S. McIntosh, B. Adams, M. Nagappan, and A. E.
Hassan. Mining co-change information to understand
when build changes are necessary. In Proc. ICSME ,
pages 241{250, 2014.
[17] S. Meng, X. Wang, L. Zhang, and H. Mei. A
history-based matching approach to identication of
framework evolution. In ICSE , pages 353{363, 2012.
[18] H. Peng, L. Mou, G. Li, Y. Liu, L. Zhang, and Z. Jin.
Building program vector representations for deep
learning. In Knowledge Science, Engineering and
Management (KSEM) , pages 547{553, 2015.
[19] C. K. Roy and J. R. Cordy. A survey on software
clone detection research. Queen's School of Computing
TR, 541(115):64{68, 2007.
[20] S. Wang, D. Lo, and L. Jiang. Understanding
widespread changes: A taxonomic study. In 17th
CSMR , pages 5{14, 2013.
[21] T. Zimmermann, P. Weigerber, S. Diehl, and
A. Zeller. Mining version histories to guide software
changes. In Proc. ICSE , pages 563{572, 2004.
701