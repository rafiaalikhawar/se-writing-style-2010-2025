Presence-Condition SimpliÔ¨Åcation in
Highly ConÔ¨Ågurable Systems
Alexander von Rhein, Alexander Grebhahn, Sven Apel, Norbert Siegmund, Dirk Beyer, and Thorsten Berger
University of Passau, GermanyUniversity of Waterloo, Canadac2015 IEEE. Personal use of this material is permitted. Permission from IEEE must
be obtained for all other uses, in any current or future media, including reprinting/republishing this material
for advertising or promotional purposes, creating new collective works, for resale or redistribution
to servers or lists, or reuse of any copyrighted component of this work in other works.
Abstract ‚ÄîFor the analysis of highly conÔ¨Ågurable systems, anal-
ysis approaches need to take the inherent variability of these sys-
tems into account. The notion of presence conditions is central to
such approaches. A presence condition speciÔ¨Åes a subset of system
conÔ¨Ågurations in which a certain artifact or a concern of interest
is present (e.g., a defect associated with this subset). In this paper,
we introduce and analyze the problem of presence-condition sim-
pliÔ¨Åcation . A key observation is that presence conditions often con-
tain redundant information, which can be safely removed in the
interest of simplicity and efÔ¨Åciency. We present a formalization
of the problem, discuss application scenarios, compare different
algorithms for solving the problem, and empirically evaluate the
algorithms by means of a set of substantial case studies.
I. I NTRODUCTION
Highly conÔ¨Ågurable systems have become more and more
complex in recent years [8, 37]. A conÔ¨Ågurable system provides
conÔ¨Åguration options (also known as features ) to tailor the
system according to a given set of requirements. A conÔ¨Ågura-
tion option typically represents a choice to include a certain
functionality in a system variant. As often not all combinations
of conÔ¨Åguration options are allowed or meaningful, additional
constraints are deÔ¨Åned between them, typically using a variabil-
ity model , such as a feature model [26] or decision model [41].
The constraints of the variability model are enforced globally,
that is, they must hold for all conÔ¨Ågurations.
Apresence condition is an expression over a set of conÔ¨Ågura-
tion options. The condition represents a subset of conÔ¨Ågurations
in which a certain implementation artifact, such as a code
fragment, is included in the corresponding system variants or in
which a certain behavior can be observed. For many application
scenarios, it is important that presence conditions are as simple
as possible. For example, if the presence condition identiÔ¨Åes
defective system variants, a developer needs to understand the
condition (i.e., which options need to be enabled or disabled)
to Ô¨Åx the defect [4]. In this paper, we focus on Boolean conÔ¨Åg-
uration options and Boolean presence-conditions, which is suf-
Ô¨Åcient to represent most presence conditions in practice [7, 8].
With presence conditions as a key concept, variability-aware
analyses emerged for type checking [3, 20, 27], static analy-
sis [32], model checking [12, 30], and variability-model anal-
ysis [5]. A variability-aware analysis analyzes a conÔ¨Ågurable
system as a whole, incorporating its variability model. Typically,
the analysis considers only valid combinations of options, and
it presents its Ô¨Åndings (e.g., a detected defect) annotated with
presence conditions. For example, a reported presence conditioncould identify all system variants containing a certain type error.
Even in small systems with few options, these conditions can
be very complex and difÔ¨Åcult to understand.
Consider the example of the tool SPL VERIFIER for
veriÔ¨Åcation of conÔ¨Ågurable systems [4], which reports the
following defect in the E-M AIL system‚Äîa benchmark for
interactions between options in conÔ¨Ågurable programs [23]:
1SpeciÔ¨Åcation 11 violated on condition
2encrypt && decrypt && keys &&
3((sign && verify && base && autoresponder) ||
4(!sign && !verify && base && autoresponder))
The defect in this example is caused by an interaction of only
two options, encrypt andautoresponder . All other parts of this
presence condition have been introduced by the global variabil-
ity model (e.g., encrypt requires keys). A desirable simpliÔ¨Åca-
tion of the presence condition is to identify encrypt andautore-
sponder as the sole cause of the defect and to ‚Äúhide‚Äù the parts in-
troduced by the variability model. Simplifying the condition and
identifying the responsible options help in Ô¨Åxing the defect [4].
A straightforward way to simplify a presence condition (or
make it more readable) is to Ô¨Ånd the smallest, but equivalent
expression. This problem is known as the minimum-equivalent-
expression problem [11, 24]. Although Ô¨Ånding a minimal
equivalent expression might reduce the size of the presence
condition, the minimal equivalent expression is still larger
than necessary. One reason for unnecessarily large expressions
is that variability-aware analyses typically consider only
conÔ¨Ågurations satisfying the variability model. Thus, the
variability model is an integral part of every reported presence
condition, even though the condition describes only a local
situation or fact. Since the variability model must be satisÔ¨Åed
globally, this information obfuscates the presence condition.
Our goal is to simplify a given presence condition such that
it becomes smaller and can be used instead of the original pres-
ence condition. In the example above, we want to remove the
constraints already enforced by the variability model from the
presence condition and show only the rest to the user. This rest
must be satisÔ¨Åed in addition to the variability model to reach the
situation of interest (e.g., it identiÔ¨Åes the source of the defect).
To this end, we introduce the presence-condition-
simpliÔ¨Åcation problem and present a formal deÔ¨Ånition of the
problem. We are interested in a function simp (p;m)such that
the expression p0=simp (p;m)is equivalent to the presence con-
dition punder all assignments that satisfy the context m:m)
(p0,p). In addition to this invariant, the size of p0should beas small as possible (we deÔ¨Åne a size measure in Section III-C ).
There are many other application scenarios of presence-
condition simpliÔ¨Åcation, including (1) the simpliÔ¨Åcation of
preprocessor directives in system software (#ifdef conditions
are simpliÔ¨Åed based on the conditions of surrounding #ifdef
conditions in the nesting hierarchy) and (2) the simpliÔ¨Åcation
of cross-tree constraints in variability models (information that
is already encoded in the feature/option hierarchy is removed
from the cross-tree constraints).
As a solution for presence-condition simpliÔ¨Åcation,
we identify and adopt three algorithms from the circuit-
optimization domain. To the best of our knowledge, the
algorithms have not yet been applied to the simpliÔ¨Åcation
of presence conditions. The Ô¨Årst algorithm, RESTRICT [14],
is based on binary decision diagrams (BDDs) [10]. The
second and third algorithms are solutions for two-level logic
minimization: the QUINE -MCCLUSKEY algorithm [22, 40]
and the E SPRESSO algorithm [9].
To compare the algorithms and to explore their feasibility
and effectiveness for presence-condition simpliÔ¨Åcation, we
conduct a series of experiments on three application scenarios
and 31 subject systems. We evaluate processing time and size
reduction of presence conditions for the three algorithms. Our
results show that presence-condition simpliÔ¨Åcation can achieve
substantial improvements in reasonable time for various
realistic application scenarios. For example, in an experiment
where we simpliÔ¨Åed analysis results (E1), one simpliÔ¨Åcation
algorithm ( simpBDD) reduced the size of presence conditions
by 61%, on average. Furthermore, we analyze how the
simpliÔ¨Åcation algorithms scale with the increasing complexity
of the input expressions.
In summary, we contribute:
A formalization of the presence-condition simpliÔ¨Åcation
problem in the context of highly conÔ¨Ågurable systems,
and a discussion of scenarios to which presence-condition
simpliÔ¨Åcation can be applied.
A discussion of three algorithms solving the problem:
RESTRICT , QUINE -MCCLUSKEY , and E SPRESSO .
An evaluation of the algorithms on three application
scenarios and 31 subject systems showing that
simpliÔ¨Åcation potential exists and the algorithms scale
in realistic scenarios.
One of the presented algorithms ( simpBDD) has been
integrated in the variability-aware analysis tool TYPECHEF,
resulting from our research. We provide a replication package
for our experiments and further detailed results on an
accompanying website: www.fosd.de/pcsimp/.
II. B ACKGROUND
To establish the terminology that we use throughout the paper,
we give an overview of conÔ¨Ågurable systems and (Boolean)
presence conditions. A conÔ¨Ågurable system provides a set of
conÔ¨Åguration options to be set by the user to derive a desired
system variant . In what follows, we use the E-M AILsystem of
Hall [23] as a running example. The E-M AILsystem simulates
a network of e-mail hosts between which e-mails are sent.1struct email {
2intid;char from; char to;char subject; char body;
3#if(deÔ¨Åned (encrypt) || deÔ¨Åned (decrypt))
4intisEncrypted; char encryptionKey;
5#endif
6};
7// incoming e-mails enter here
8void incoming ( struct client client, struct email msg) {
9#if(deÔ¨Åned (decrypt))
10 decrypt (client, msg); // decrypt encrypted incoming e-mails
11#endif
12#if(deÔ¨Åned (forward))
13 forward (client, msg); // forward incoming e-mails automatically
14#endif
15 ...// store e mail in a mailbox
16} ...
17#if(deÔ¨Åned (decrypt))
18// decrypt a given e-mail if the key of the sender is known
19void decrypt ( struct client client, struct email msg) { ... }
20#endif
Fig. 1: Excerpt of the conÔ¨Ågurable E- MAIL system
Figure 1 shows an excerpt of the system‚Äôs code with variability
expressed using #if preprocessor directives. In addition to the
basic functionality ( base), the E-M AIL system offers eight
conÔ¨Åguration options: keys enables support for private and
public keys, encrypt and decrypt implement encryption and
decryption, sign andverify implement signing of e-mails and
verifying of signatures, forward implements automatic e-mail
forwarding, autoresponder generates automatic response
e-mails, and addressbook provides contact management. A con-
Ô¨Åguration of a system is a total mapping from the conÔ¨Åguration
options to values. Here, we focus on Boolean conÔ¨Åguration
options (whose values can only be true orfalse ), because they
are an important backbone of conÔ¨Ågurations in practice [7];
non-Boolean conÔ¨Åguration options can be represented by
multiple Boolean variables, if the domain is discrete and small,
such as for enumerations. We represent a mapping from options
to choice values, such as base7!true;keys7!true;forward7!
true;encrypt7!false ; :::, with a Boolean expression such as
base^keys^forward^:encrypt^:::Typically, not all possible
mappings are valid in a conÔ¨Ågurable system; a variability
model deÔ¨Ånes the set of valid conÔ¨Ågurations. A possible
representation of a variability model is again a Boolean
expression, for example: base^(decrypt,encrypt )^(sign,
verify )^(encrypt)keys)^(sign)keys). All assignments
of conÔ¨Åguration options for which the variability model is
satisÔ¨Åed correspond to the set of valid conÔ¨Ågurations.
Apresence condition is a Boolean expression over the set of
conÔ¨Åguration options [16]. We use the term presence condition
in a broad sense, but it always is a Boolean expression denoting
the condition for presence of certain code or behavior in variants
of the conÔ¨Ågurable system. For example, a presence condition
can denote the condition for a defect in the system or for the
presence of a statically conditional piece of code in a variant.
Finally, given two Boolean expressions fandg, and the fact
that fimplies g, we refer to fas an implicant (also known
aspremise ) of g, and to gas an implicate (also known as
conclusion ) of f. Aprime implicant fofgis an implicant of gthat is minimal‚Äîthat is, the removal of any literal from fresults
in a non-implicant for g. For example, the expression g=(x^
y)_whas the implicants x^y,x^w, and more. The term x^yis
a prime implicant‚Äîthe removal of xoryleaves a non-implicant.
III. P RESENCE -CONDITION SIMPLIFICATION
We illustrate the problem of presence-condition
simpliÔ¨Åcation by means of three practical application
scenarios (Section III-B ), deÔ¨Åne invariants for a solution of
the problem formally (Section III-C ), and discuss algorithms
satisfying these invariants (Section III-D).
A. Problem Overview
Presence-condition simpliÔ¨Åcation aims at simplifying a
presence condition pwith respect to its context m. As an
approximate measure for ‚Äúsimpleness‚Äù of a Boolean expression,
we use the number of its literals, but other measures are
possible as well (see Section III-C , for further details). pand
mare given as Boolean expressions, and we require that pis
embedded in m, which means that pis evaluated only if mis
satisÔ¨Åed. A simpliÔ¨Åcation function ‚Äô simp ‚Äô receives two Boolean
expressions pandmand returns a Boolean expression.
B. Application Scenarios
Although the application domain is much broader, we are
particularly interested in presence-condition simpliÔ¨Åcation in
the context of developing and analyzing highly conÔ¨Ågurable
systems. Next, we illustrate three interesting scenarios.
Reporting Analysis Results: Variability-aware analyses
often report the condition under which certain events or
states occur as presence conditions. Recall our example of
SPL VERIFIER [4], which implements variability-aware model
checking of conÔ¨Ågurable systems. The tool prints the following
output after verifying Hall‚Äôs E-M AILsystem [4, 23]:1
1SpeciÔ¨Åcation 11 violated on condition
2encrypt && decrypt && keys &&
3((sign && verify && base && autoresponder) ||
4(!sign && !verify && base && autoresponder))
The E-M AILsystem can be conÔ¨Ågured with various options,
and some combinations of options can lead to violations of
certain speciÔ¨Åcations, as reported above by SPL VERIFIER .
Such violations indicate either an incomplete variability model,
which should be Ô¨Åxed to prevent defective conÔ¨Ågurations,
or a bug in the system. Since SPL VERIFIER veriÔ¨Åes only
conÔ¨Ågurations that satisfy the variability model, which is
standard in variability-aware analyses [47], the reported
presence conditions contain parts that are already implied by the
variability model. This mix of error condition with variability-
model constraints hinders understanding and pinning down
the source of an error. Even though the E-M AILsystem has
only nine conÔ¨Åguration options, the reported defect conditions
are often unnecessarily complicated. The defect conditions we
encountered for the E-M AILsystem have between 5 and 17
literals. By applying presence-condition simpliÔ¨Åcation to the
1The speciÔ¨Åcation states that e-mails must be decrypted before sending
an automatic response.32...
33obj $(LOCKDEP) \
34+= lockdep.o
35...
(a) Excerpt from
kernel/MakeÔ¨Åle826#if deÔ¨Åned (PROVE_LOCKING)
827...
1301#if deÔ¨Åned (TRACE_IRQFLAGS)
1302 &&deÔ¨Åned (PROVE_LOCKING)
1303...
1674#else
1675...
1688#endif
1689...
2146#endif
(b) Excerpt from kernel/lockdep.c
Fig. 2: Nested variability annotations with redundancy
defect presence condition shown above, we yield the following
result containing only 2 instead of 11 literals:
1SpeciÔ¨Åcation 11 violated on condition
2VariabilityModel && (encrypt && autoresponder)
SimpliÔ¨Åcation of Variability Annotations: Variability
annotations are directives in a system‚Äôs source code that
conditionally include or exclude parts of the code based
on the choice of conÔ¨Åguration options. For illustration, we
focus on two implementation mechanisms for variability
annotations: conditional inclusion of Ô¨Åles in build scripts
and #if preprocessor directives. Figure 2 shows an example
of both mechanisms used together, taken from the LINUX
kernel v3.4. Figure 2a shows an excerpt of the MakeÔ¨Åle in
thekernel directory. It states that the object Ô¨Åle of lockdep.c is
included if option LOCKDEP is enabled. Figure 2b shows an
excerpt of Ô¨Åle lockdep.c , which contains several #if directives.
Observe that, in the example, the innermost #if directive
(Figure 2b, Line 1301) is enclosed by two conditions: the #if
condition in Line 826 and the condition from the MakeÔ¨Åle . The
conjunction of both enclosing conditions is the context of the
condition in Line 1301: m=(LOCKDEP^PROVE_LOCKING )
and p= (TRACE_IRQFLAGS ^PROVE_LOCKING ). Using
presence-condition simpliÔ¨Åcation, we can remove the redundant
term PROVE_LOCKING from the condition of the inner
preprocessor directive without changing the behavior of any
variant of the LINUX kernel: simp (p;m)=TRACE_IRQFLAGS .
Admittedly, the expressions involved in this example are
relatively simple, so a developer might be aware of the
redundancy and leave it for documentation. Still, in more
complex cases, simpliÔ¨Åcation can be more effectful, especially
because it is also beneÔ¨Åcial for tools working on the code to
ease automatic reasoning.
Automatic code analysis of systems with #ifdef variability is
difÔ¨Åcult because the preprocessor directives can be interleaved
with normal Ccode in complicated ways. The tool TYPE-
CHEF [28] solves this problem by providing a variability-aware
parser for Ccode with #if directives. It is used by many research
projects [29, 32], which would beneÔ¨Åt from presence condition
simpliÔ¨Åcation. TYPECHEF resolves preprocessor directives
and macros, and it generates an abstract syntax tree (AST),
preserving the variability induced by #if directives. Technically,
nodes in the AST are annotated with the presence conditions
that correspond to the #if directives. Due to difÔ¨Åculties in thebasekeysencryptsignaddressbookautoresponderforwarddecryptverifyLegend:Optionalsign  ‚áî  verifyencrypt  ‚áî  decryptFig. 3: Feature model of the E-M AILsystem
parsing process (e.g., macro expansion) [28], these presence
conditions are often an overapproximation of the actual
presence conditions and contain redundancy. We can make the
AST generated by TYPECHEF more concise by simplifying
the presence conditions with their context (presence conditions
of ancestors in the AST conjoined with the presence condition
of the Ô¨Åle), which improves the performance of subsequent
analyses, such as type checking or data-Ô¨Çow analysis [32].
Variability-Model Generation: A variability model can be
expressed in different formats. In this paper, we use Boolean
expressions, but other scenarios require richer representations,
such as feature models by Kang et al. [26]; Figure 3 shows
a representation of the feature model of the E-Mail system
(Section II). Such a model contains a hierarchy that shows
dependencies between the conÔ¨Åguration options (child‚Äìparent
implication). For example, selecting option encrypt implies
selecting its parent keys. Constraints that cannot be encoded
in the hierarchy are written as separate cross-tree constraints .
For example, the dependencies from encrypt todecrypt and
vice versa are expressed as cross-tree constraints.
If a variability model is given as a Boolean expression
(for instance, when extracted from source code [42]), it is
sometimes desirable to transform it into a visual model for
presentation. There are a number of approaches (e.g., [42])
that synthesize a hierarchy (shown as tree in Figure 3) and
constraints between siblings in the hierarchy. All constraints
that cannot be encoded in the hierarchy or as sibling constraints
are added as cross-tree constraints.
If the cross-tree constraints are still complex, it is advisable
to simplify them using the hierarchy and the sibling constraints
as context. That is, the cross-tree constraints should not restate
the dependencies covered by the hierarchy or the sibling
constraints. Given the hierarchy constraints h, the sibling
constraints s, and the cross-tree constraints ctc, this can be
achieved with simp (ctc;h^s). The result of simpliÔ¨Åcation can
replace the original cross-tree constraints, because the context
of hierarchy and sibling constraints always hold.
C. Problem Formalization
Function simp (p;m)has two inputs: a presence condition p
and a context m. The goal is to represent the relevant
information in pas concise as possible. The input parameters
and the result of the simpliÔ¨Åcation are Boolean expressions.
Even though the problem and the described algorithms
(Section III-D) work on general Boolean expressions, we use
them only in the conÔ¨Ågurable-systems context.We assume that the context mis available and holds
signiÔ¨Åcant information on the situations in which pcan be
evaluated. If it is not available, or if it represents a tautology,
then we have to assume that all information in pis relevant to
identify the situation or fact that prepresents. In this case, the
only possibility to improve the presentation of pis to generate a
minimum equivalent expression forp[11, 24]. However, in the
scenarios that we focus on, usually a substantial, non-tautology
context is available (e.g., a global variability model).
Presence conditions are meant to be evaluated only if the
context mholds. The information encoded in a presence
condition pis essentially the set of implicates of p. Elements of
this set can be categorized as follows: An implicate of pis either
(1) also an implicate of mor (2) no implicate of m. Implicates
in group 1 are redundant and can be dropped. Some implicates
in group 2 are implied by elements of group 2 conjoined
with mand are therefore also redundant. If we can extract
the essential, non-redundant elements of group 2 and present
them as replacement for p, this would be sufÔ¨Åcient, because
the context mguarantees that the implicates in group 1 are
satisÔ¨Åed. Hence, we do not search for an equivalence-preserving
function, but we aim at removing implicates from pif they are
redundant with respect to mand if they increase the size of p.
Figure 4 illustrates the relationship between p,m, and
simp (p;m)in terms of the conÔ¨Åguration space of a
conÔ¨Ågurable system. The white rectangle mrepresents all
valid conÔ¨Ågurations. The rectangle prepresents the space of
conÔ¨Ågurations denoted by the presence condition. pencloses
only conÔ¨Ågurations that are in m. Also, pis (often) smaller
than mbecause it speciÔ¨Åces a certain local condition within
the global space of conÔ¨Ågurations. The rectangle simp (p;m)
represents the simpliÔ¨Åed presence condition. This rectangle
encloses all conÔ¨Ågurations of p, but also conÔ¨Ågurations from
out of m, if it helps to remove implicates from the expression
(i.e., if it reduces the size of p). The objective is that the area
of simp (p;m)represents a more concise expression than p.
Context m
Presence Condition p
SimpliÔ¨Åed Presence Condition simp (p;m)
Fig. 4: Illustration of presence-condition simpliÔ¨Åcation. Each point on
the plane represents a conÔ¨Åguration. The crosshatched area denotes the
overlapping of the area of p andsimp (p;m). The simpliÔ¨Åed presence
condition can include conÔ¨Ågurations not allowed by the context (e.g., the
variability model) if it helps reducing the size of the condition.2
Formally, the invariant for correctness of simp (p;m)is:
m)(simp (p;m),p) (1)
This invariant states that, in the context of m, the expressions p
and simp (p;m)are logically equivalent. Therefore, we can
use simp (p;m)as replacement for p, provided that mholds.
Equation 1 is a sufÔ¨Åcient condition for the correctness of
replacing all occurrences of pin the context mbysimp (p;m).
2A condition that includes more conÔ¨Ågurations can be smaller in size than
a condition with more implicates.In the simplest case, simp (p;m)=pwould be a valid solution.
However, our goal is to simplify p. So, we deÔ¨Åne an objective
function stating that simp (p;m)must be minimal according
to a given measure size:
8x: 
m)(x,p)
) 
size(simp (p;m))size(x)
(2)
DeÔ¨Åning a general measure for the size of Boolean
expressions is not reasonable as it depends on the application
scenario. In the application scenarios we are interested in (cf.
Section III-B ), conciseness of expressions is most important,
because they are usually presented to the user. In other cases,
expressions are used to generate hardware circuits, for which
other optimization goals are needed.
In practice, we have to compare formulas given in notations
with different constraints (e.g., CNF, DNF, or BDD) because
different simpliÔ¨Åcation algorithms (described in Section III-D )
have different input and output formats. To avoid bias of
different notations, we focus on the complexity of the encoded
formula. To this end, we convert all expressions to a canonical
normal form before comparison. As canonical form, we choose
a reduced if-then-else normal form (derived from BDDs) that
contains only^,_, and:as operators.
After the expressions are converted to the same notation,
there are several possible size measures for comparison. We
choose the number of occurrences of literals as size measure
because it represents the total expression length and is not
inÔ¨Çuenced, for instance, by lengths of variable names. So, for
the remaining sections, we deÔ¨Åne the measure size(y)as the
number of occurences of literals in the string representation
of an expression yin canonical form. For expression
y=(A^B)_(:A^C), size (y)=4 (B,C, and twice A).
We also evaluated the number of operators and the number
of nodes in a BDD representation as alternative size measures,
but observed no major deviations in our experiments (cf. Sec-
tion IV). In their work on the minimum-equivialent-expression
problem, Hemaspaandra and Schnoor [24] have also used the
number of occurrences of literals and the number of operators.
We decided against measures such as the depth of an AST of the
formula, because a CNF/DNF representation would always have
depth 2, which renders the measure useless for our purposes.
D. Implementation
We introduce four algorithms solving the presence-condition-
simpliÔ¨Åcation problem: BRUTE -FORCE (simpBF),RESTRICT
(simpBDD),ESPRESSO (simpE), and QUINE -MCCLUSKEY
(simpQC).simpBFÔ¨Ånds an optimal solution, but it iterates
over all possible solutions. The other three algorithms employ
heuristics to improve computational complexity while still
satisfying the invariant of Equation 1.
Naive Solution: The BRUTE -FORCE (simpBF) algorithm
enumerates all implicates of p. Technically, it uses the clauses
of the canonical conjunctive normal form (CCNF) of p. Then,
it builds the powerset of these clauses. For each element
of the powerset, the algorithm tests whether it satisÔ¨Åes
Equation 1 and therefore qualiÔ¨Åes as a solution. From all
possible solutions, the algorithm selects an optimal solution
according to the size measure.The CCNF has 2nclauses for nconÔ¨Åguration options. There-
fore, the size of the powerset of the set of clauses is 22n, and we
have to iterate through the entire set. Due to its computational
complexity, we cannot use simpBFin our experiments.3
BDD SimpliÔ¨Åcation: The second algorithm was Ô¨Årst
described by Coudert and Madre [14] in 1989 as the RESTRICT
algorithm ( simpBDD). The RESTRICT algorithm takes two
expressions pand mrepresented as BDDs and generates a
third BDD c=simpBDD(p;m)that satisÔ¨Åes the invariant of
Equation 1 [14]. The algorithm is intended to minimize the
number of nodes in the BDD representation of simpBDD(p;m).
This is in line with our optimization goal, but as the algorithm
uses heuristics, it does not always generate optimal results.
For further details, we refer to the original publication [14]
and to our supplementary website.
Like many other BDD operations, simpBDD is a polynomial-
time graph-manipulation algorithm (if caching is used). In
the worst case, the size of the graph may be exponential in
the number of the variables, which renders the algorithm also
exponential in the number of variables. However, in practice,
the worst case is unlikely, which is part of the reason for the
success of BDDs.
Two-Level Logic Minimization: The third solution is to
transform the problem of presence-condition simpliÔ¨Åcation
into a two-level-logic-minimization problem [15], which
can be solved with the QUINE -MCCLUSKY andESPRESSO
algorithms ( simpQCand simpE). The attribute ‚Äútwo-level‚Äù
arises from the fact that input expressions are expected in DNF,
and a DNF has two levels (the global level with _operations
and the clause level with ^operations). Two-level logic
minimization receives a Boolean expression fand a second
expression dc, which represents a don‚Äôt care set , called
DC set . The expressions divide the entire space of option
assignments into three partitions: (1) the set of assignments
for which f^:dcis satisÔ¨Åed, called the ON set , (2) the set of
assignments for which :f^:dcis satisÔ¨Åed, called the OFF
set, and (3) the DC set for which dcis satisÔ¨Åed. The result
of two-level logic minimization is a simpliÔ¨Åed version of f.
Mapped to our problem, expression frepresents the presence
condition p. DC describes variable assignments for which the re-
sultsimpE(p;m)need not be equivalent to p. In our case, these
are all variable assignments that are not valid in the context
(:m). That is, DC is the piece of information needed for mini-
mization. So, the setup fpanddc:msatisÔ¨Åes Equation 1.
Two-level logic minimization can be exact or heuristics-
based. An exact algorithm determines the minimal set of
prime implicants needed to represent fwithout respecting dc.
It can be solved with the QUINE -MCCLUSKY algorithm,
which is NP-complete. In a nutshell, the algorithm starts with
computing all prime implicants for the union of the ON and
DC sets. Finding the smallest set of these prime implicants
that still cover fis basically a set-covering problem, which
is also NP-complete. The algorithm uses reduction techniques
and a branch-and-bound strategy to solve this problem [15].
3Our implementation works for up to four conÔ¨Åguration options.For performance, several heuristics have been developed.
The most prominent heuristic-based algorithm is the ESPRESSO
algorithm [15], which utilizes a local search without generating
all prime implicants. It is composed of three main operations:
expand ,reduce , and irredundant . The operations expand
and reduce are applied to improve the current term during
optimization, and the operation irredundant is used to get
out of a local minimum. In our experiments, we evaluate the
ESPRESSO algorithm, denoted with simpE, and the QUINE -
MCCLUSKEY algorithm, denoted with simpQC. For further
details on the algorithms, we refer to an overview paper [15].
Input-Format Conversion: Different application scenarios
of presence-condition simpliÔ¨Åcation require different input
formats for the parameters pandm. So, the input expressions
need to be converted in formats suitable for the different
algorithms. This is mainly a technical issue that we describe
in the Appendix.
IV. E VALUATION
We evaluate the different algorithms for presence-condition
simpliÔ¨Åcation guided by two research questions:
RQ1 We expect that presence conditions with a known
context are often too complex and can be simpliÔ¨Åed. In
which application scenarios does this hold, and are the
resulting expressions substantially smaller?
RQ2 How does the processing time of the algorithms simpBDD,
simpE, and simpQCscale to complex simpliÔ¨Åcation tasks?
We evaluate these research questions on the application
scenarios described in Section III-B on, overall, 31 example
conÔ¨Ågurable systems. As a measure of simpliÔ¨Åcation (RQ1), we
compare the number of occurences of literals in the expression
before and after simpliÔ¨Åcation. To ensure a fair comparison,
we transform the results generated by the simpEandsimpQC
algorithms to BDDs after the algorithms have terminated. This
step ensures that the compared result strings are compact and
have the same variable order. We do not include the time needed
for this transformation. The processing time (RQ2) is measured
per simpliÔ¨Åcation task. To ensure fairness we did not call
simpBDDon in-memory BDDs, but wrote them to a Ô¨Åle, invoked
simpBDD in a new process, and measured the time for that
process to terminate. This time includes parsing the presence
condition and context, and writing the result expression.
In total, we designed Ô¨Åve experiments labelled E1 through E5.
To evaluate research question RQ1, we needed sets of Boolean
presence conditions and contexts from different application
scenarios and conÔ¨Ågurable systems. We obtained these sets from
different research projects and did one experiment per project.
E1 and E2 represent variations of the ‚ÄúReporting Analysis
Results‚Äù application scenario, E3 and E4 apply the ‚ÄúSimpliÔ¨Å-
cation of Variability Annotations‚Äù scenario to source code and
to the internal code representation in TYPECHEF, respectively.
To evaluate research question RQ2, we needed a setting
where we can Ô¨Çexibly control the size of the problem.
We chose to evaluate this question with the ‚ÄúVariability-
Model Generation‚Äù scenario and used a variability-model
generator [34] to create simpliÔ¨Åcation tasks. In the generator,TABLE I: S UBJECT SYSTEMS AND APPLICATION SCENARIOS
(MORE DETAILS ARE AVAILABLE ON THE SUPPLEMENTARY WEBSITE )
APACHE (E1) L INUX v2.6.33.3 (E3, E4) SPLOT models (E5)
E-MAIL (E1, E2) L INUX v3.4 (E3) SQL ITE(E1,E3)
ELEVATOR (E2) LLVM (E1) Z IPME(E1)
H264 (E1) PKJ AB(E1) 18 other
LINKED LIST(E1) SNW (E1) systems (E3)
we can increase the number of generated variables and therefore
generate harder problems. We used these generated tasks in E5
to evaluate the processing-time performance of the algorithms.
A. Subject Systems and Experiments
We use a diverse set of subject systems from various sources
to evaluate the different applications of presence-condition
simpliÔ¨Åcation. For each system, we ensured that a variability
model was available. Table I gives an overview of the systems
and in which experiments they are used. The experiments
E1‚ÄìE5 are described next.
ClassiÔ¨Åcation of Variants (E1): The Ô¨Årst application
scenario is based on an approach that estimates non-functional
properties (footprint, response time, etc.) of the variants
of a conÔ¨Ågurable system [44]. Experiments evaluating the
approach typically generated huge datasets. For E1, we use the
following systems from previous studies [43, 44, 45]: APACHE ,
E-MAIL ,H264, and LLVM (prediction of response time per
variant), and LINKED LIST,PKJ AB,SNW ,SQL ITE, and
ZIPME(prediction of binary footprint per variant). Presence
conditions in this scenario indentify system conÔ¨Ågurations for
which the prediction accuracy is low, possibly due to unknown
interactions among conÔ¨Åguration options. Presence-condition
simpliÔ¨Åcation is useful for pinpointing these to a smaller
number of options such that further investigation is possible.
We have presence conditions for seven different levels of
prediction accuracy and simplify all of them seperately using
the corresponding variability model as context.
Reporting Defect Locations (E2): For our second
experiment, we use data from a study evaluating the
performance of variability-aware model checking [4]. During
experiments, the authors found many defects in the subject
systems that occur only under certain presence conditions. We
use the E-MAIL andELEVATOR systems, which are standard
benchmarks for interaction detection [4, 13, 23]. Presence
conditions of defects and the variability model are given
as textual Boolean expressions. An example for the defect
location scenario is the output of the SPL VERIFIER tool given
in Section III-B . We simplify the defect presence conditions
and evaluate the performance of the simpliÔ¨Åcation algorithms.
Code-Annotation SimpliÔ¨Åcation (E3): To evaluate the
simpliÔ¨Åcation potential for code annotations, we use several
conÔ¨Ågurable software systems with #if directives and apply
simpliÔ¨Åcation to the #if conditions (see Section III-B ). For
our experiments (see Section IV-C ), we use 21 conÔ¨Ågurable
systems, including the L INUX kernel.
The context of #if conditions in these projects has two
components: the conditions of enclosing #if directives and the
condition under which the respective Ô¨Åle will be included inthe project, as described in Section III-B . In projects that use
KCONFIG , we used the tool KBUILD MINER [6, 7] to extract the
conditions under which source Ô¨Åles are used. For the others, we
assumed that each Ô¨Åle is used in all conÔ¨Ågurations. We extracted
#if conditions in source Ô¨Åles with the PREDATOR tool [46].
PREDATOR also provides the hierarchy of #if conditions,
such that we can generate for each #if condition a context
consisting of the conjunction of the enclosing #if conditions
and the Ô¨Åle condition. Given these pairs of #if conditions and
contexts, we apply the simpBDD,simpEandsimpQCalgorithms
and measure how often the conditions could be improved to
evaluate the potential for presence-condition simpliÔ¨Åcation. We
skip pairs for which #if conditions or contexts are tautologies
or contradictions because then simpliÔ¨Åcation is impossible.
AST-Annotation SimpliÔ¨Åcation (E4): In this experiment,
we analyze the variability-aware ASTs generated by TYPE-
CHEF [28]. Each generated AST node has a presence condition.
Due to difÔ¨Åculties in parsing C code with #if directives (e.g.,
undisciplined annotations and macro expansion), the resulting
presence conditions are often larger than the conditions written
in the source code [28]. For simpliÔ¨Åcation, we generated
a context for each presence condition pby building the
conjunction mof all presence conditions on the path from
pto the root node of the AST. Then, we applied simpliÔ¨Åcation
ofpin the context mand evaluated the reduction in the size of
the presence conditions. Again, we do not simplify if pormis
a tautology or a contradiction. Even though we optimize only
an internal representation here, it can affect processing time.
Furthermore, presence conditions are visible to users (1) as part
of reports, (2) as debugging info, and (3) if the AST is printed
again after some modiÔ¨Åcation (e.g., automatic code refactoring).
Cross-Tree-Constraint SimpliÔ¨Åcation (E5): To evaluate
the scalability potential of presence-condition simpliÔ¨Åcation,
we used the variability-model generator from the SPLOT
repository [34] for generating test variability models. Each
model comprises hierarchy, grouping, and cross-tree constraints
given in CNF. This is the same setup as in the Ô¨Ånal step of
the variability-model generation scenario (Section III-B).
As scaling factor, we used the number of conÔ¨Åguration
options of the generated models. We have generated sets
of 10 variability models with 20/30/40/50/60 conÔ¨Åguration
options (50 models in total). For each model, we simplify
the cross-tree constraints using the hierarchy and sibling
constraints as context. All constraints are given in CNF, so we
apply the FORCE algorithm [2] to optimize the BDD variable
ordering. The more compact representation is beneÔ¨Åcial for
simpBDD, but also for simpEand simpQC.
B. Experiment Setup
For our experiments, we use existing algorithm
implementations: simpBDD is available as function
net.sf.javabdd.BDD.simplify(BDD) in the JAVABDD library, simpE
is available in the ESPRESSO tool, and simpQCis also
implemented in ESPRESSO as a revised version of the original
QUINE -MCCLUSKEY algorithm. We provide links to the tools
on our supplementary website. We also tried to use SCHERZO ,a newer tool for two-level logic minimization, however, we
were not able to apply it to presence-condition simpliÔ¨Åcation
because of technical problems and missing documentation.
All experiments have been executed on an Intel Xeon
machine (8 cores with 2.93 GHz) with Ubuntu 12.04.
Regarding parallelization, we have not observed that more
than one core was used in the experiments. In all experiments,
simpliÔ¨Åcation has been executed in a JVM with 4 GB of
RAM. We set the timeout for the simpliÔ¨Åcation algorithms
in all experiments to 60 seconds (the usual response time was
much less). In the experiments E1‚ÄìE4, we encountered only
12 timeouts, (7 with simpEand 5 with simpQC). All timeouts
occured while simplifying presence conditions of the SQL ITE
system (E1). For code simpliÔ¨Åcation (E3), we used scripts to
call the external analysis tools (e.g., TYPECHEF). The tool
output was aggregated and later simpliÔ¨Åed.
During the experiments, we measured the processing
time of the algorithms and the number of literals in the
expressions before and after simpliÔ¨Åcation. We use the number
of occurences of literals as size measure (Section III-C ). We
also evaluated other measures (number of operands and node
count in the BDD), but they do not change the overall picture.
For each simpliÔ¨Åcation, we compare the size of the original
presence condition pand the simpliÔ¨Åed presence condition
simp (p;m). For these comparisons, we deÔ¨Åne the reduction
factor as size 
simp (p;m)
=size(p).
In some cases, the size of the supposedly simpliÔ¨Åed expres-
sion was larger than the size of the original expression. This can
happen because some of the algorithms rely on heuristics. Such
cases are easy to detect and we just use the original expression
instead of the generated expression. In such cases, we logged
that simpliÔ¨Åcation did not improve the expression size (the
reduction factor is 1). To provide a ground truth, we would
need to iterate over all solutions (i.e., apply the BRUTE -FORCE
algorithm). However, due to the complexity of the problem,
BRUTE -FORCE does not scale for any of our experiments.
C. Results
ClassiÔ¨Åcation of Variants (E1): Figure 5 shows the
reduction factors we observed for the classiÔ¨Åcation of variants
per subject system. A lower reduction factor indicates a better
simpliÔ¨Åcation result. Each boxplot covers all experiments per al-
gorithm and subject system. Figure 5 shows that (1) the number
of literals is generally much lower after simpliÔ¨Åcation and that
(2)simpBDD generates slightly better results, on average, than
simpEandsimpQC, as conÔ¨Årmed by paired Mann-Whitney tests
(p-values below 0:001for both tests). These results conÔ¨Årm
RQ1: For this application scenario and the considered systems,
there is signiÔ¨Åcant simpliÔ¨Åcation potential, and the algorithms
are able to simplify the presence conditions substantially.
Figure 6 shows the time needed for simpliÔ¨Åcation in a
quantile plot. For example, the point (150;110)in graph
simpEin the plot states that the 150-th fastest simpliÔ¨Åcation
with simpEtook 110 ms and there were 149 simpliÔ¨Åcation
tasks that took 110 ms or less with simpE. The plot shows how
the algorithms scale when tasks are harder to solve using theFig. 5: Reduction factors for the classiÔ¨Åcation of variants (E1)
Time for Simplification (ms)‚óè1 10 100 1 000
Presence Conditions (ordered by processing time)0 50 100 150 175‚óèsimpBDD
simpE
simpQC
Fig. 6: Time for simpliÔ¨Åcation in a quantile plot (E1); a point (x;y)in the
plot states that the x-th fastest simpliÔ¨Åcation with the respective algorithm
took ymilliseconds; the right-most xvalue indicates the number of solved
tasks; the yaxis has a logarithmic scale
TABLE II: R EDUCTION FACTORS FOR DEFECT LOCATION REPORTING (E2)
simpBDD simpE simpQC
ELEVATOR 0.39 0.37 0.37
E-M AIL 0.22 0.14 0.14
same simpliÔ¨Åcation tasks as in Figure 5; the time for simpQC
and simpEis negligible for easy tasks but increases with
harder tasks; simpBDD needs between 400 ms and500 ms in
most cases, however, it can solve more problems than simpQC
andsimpE. Note that in our setup simpBDD requires startup
time for the JVM, which dominates the processing time.
Reporting Defect Locations (E2): In E2, we consider veri-
Ô¨Åcation of E-M AILandELEVATOR [4] as application scenario.
Note that E-M AILandELEVATOR are the same systems as
in E1, but the considered presence conditions represent very
different facts: In E1, the presence conditions represent the
prediction accuracy of the non-functional property prediction
approach [43, 45]. In E2, the considered presence conditions
point to conÔ¨Ågurations in which speciÔ¨Åcations of the conÔ¨Åg-
urable systems are violated, as identiÔ¨Åed by SPL VERIFIER [4].
Table II shows the average reduction factor per case study
and algorithm. All three algorithms achieve signiÔ¨Åcant improve-
ments of the simpliÔ¨Åed expressions in terms of the reduction fac-
tors, providing further evidence for RQ1. Overall, the reduction
factors are very similar for all algorithms. The maximum time
measured for simpliÔ¨Åcation was 472 ms, which is negligible.
Code-Annotation SimpliÔ¨Åcation (E3): In E3, we evaluate
the potential for simpliÔ¨Åcation of #if conditions in source code.
0 100 200 300 400‚óè
‚óè
before after(a) Presence-condition size
0.0 0.2 0.4 0.6 0.8 1.0‚óè (b) Reduction factor
Fig. 7: Experiment results for the TYPECHEF AST simpliÔ¨Åcation on LINUX
(E4)
Overall, we found only few situations where our approach
could improve the presence conditions. For detailed results
of the experiment we refer to the supplementary website.
With all three algorithms and in all systems except gnuplot
(3.3%) and libxml2 (3.3%), we could improve only less
than 2% of the parsable, non-trivial presence conditions. If
we could not parse the conditions, this was usually due to
non-Boolean conÔ¨Åguration options. Most situations for which
we could improve the conditions are rather simple, similar
to the example shown in Figure 2.
The experiment E3 shows that our approach is feasible in
the application scenario, but there is only little potential for
simpliÔ¨Åcation in the considered systems. #if conditions in the
analyzed systems do not contain much redundancy, which
indicates a good code quality. So the expectation stated in RQ1
does not hold in this application scenario, for these systems.
AST-Annotation SimpliÔ¨Åcation (E4): To evaluate the
simpliÔ¨Åcation potential in ASTs as generated by TYPECHEF,
we modiÔ¨Åed TYPECHEF such that it applies simpliÔ¨Åcation
to all presence conditions generated as AST annotations. In
particular, we analyzed the AST conditions generated for
LINUX 2.6.33.3 (the actual subject of E4 is TYPECHEF, not
LINUX , so one version is sufÔ¨Åcient). Figure 7 shows the
results by means of violin plots. A violin plot contains a
boxplot and shows also the probability density of the data.
In total, we found 6 115 774 non-trivial presence conditions
inLINUX ‚Äôs AST. Figure 7a shows that most of these have
less than 100 literals. However, there is a substantial number
of presence conditions that have an extremely large number
of literals. After simpliÔ¨Åcation (shown data generated with
simpBDD), the conditions have less than 50 literals. Figure 7b
shows the reduction factors observed with simpBDD (the
results are similar for simpEandsimpQC). For most presence
conditions, we achieved extreme improvements, which leads us
to two conclusions conÔ¨Årming RQ1: (1) TYPECHEF introduces
many redundancies during parsing, because we did not observe
similar sizes for LINUX in E3, and (2) simpliÔ¨Åcation can
remove those redundancies from the AST.
Cross-Tree-Constraint SimpliÔ¨Åcation (E5): To evaluate
the scalability of simpBDD,simpE, and simpQC(RQ2), we ran
experiments with synthetic feature models of different sizes
(see scenario ‚ÄúCross-Tree-Constraint SimpliÔ¨Åcation‚Äù). Figure 8
shows the time needed for simpliÔ¨Åcation of the cross-tree
constraints in a quantile plot. It supports the general resultTime for Simplification (ms)‚óè1 10 100 1 000
Presence Conditions (ordered by processing time)0 10 20 30 40 50‚óèsimpBDD
simpE
simpQCFig. 8: Scalability of simpliÔ¨Åcation algorithms shown in a quantile plot (E5),
similar to the quantile plot in Figure 6
of E1: simpBDD has a higher processing time for simple tasks
(again, consider JVM startup time), but it can solve more tasks
and is faster than simpEandsimpQCwhen it comes to harder
tasks. simpQCperforms better than simpE, which was not to
be expected, because it is an earlier algorithm solving the
same problem. We were not able to run a complete evaluation
for larger problem sizes, because the computation of the
input Ô¨Åles for simpEandsimpQCis very expensive for harder
problems. When evaluating presence-condition simpliÔ¨Åcation
on 10 problem instances with 150 options, simpBDD still needs
only 9 ms, on average (when the BDD is already loaded in
memory). In summary, the answer to RQ2 is that simpBDD
has a high base processing-time ( 500 ms ) but scales better
than the other algorithms.
D. Threats to Validity
A threat to internal validity is that we have no exact
measure for the simplicity of Boolean expressions. This is
a problem that is not speciÔ¨Åc to our work; in general, it is
difÔ¨Åcult to deÔ¨Åne such a measure. We have tried a number of
different measures and observed similar results, so we expect
our observations to hold with other sensible measures. In
addition, we tried to use a ground truth for the minimal size
measure in our experiments. However, even small problems
require an infeasible amount of computations. Hence, we
focus on the comparison between the algorithms.
Another threat to internal validity is that we used existing
tools to compare the algorithms, so we rely on that the tools
actually implement the algorithms correctly. Still, we veriÔ¨Åed
that each simpliÔ¨Åcation result satisÔ¨Åes Equation 1.
A threat to the external validity‚Äîas always‚Äîis the selection
of subject systems and application scenarios. To mitigate
this threat, we selected a diverse set of application scenarios
and subject systems. Our assumption that simpliÔ¨Åcation can
signiÔ¨Åcantly improve presence-condition size holds in all these
scenarios (except for code-annotation simpliÔ¨Åcation).
A possible threat to the external validity is that we can only
handle Boolean options. However, it has been shown that the
majority of presence conditions in large conÔ¨Ågurable systems
(e.g., kernels of LINUX andFREEBSD ) can be expressed using
only propositional expressions [7], and that the large majority
of options in conÔ¨Ågurable systems software is Boolean [8].Even if parts of the context cannot be expressed with Boolean
options, a partial context can be used for simpliÔ¨Åcation.
Even though the majority of our subject systems and
application scenarios are real, our approach is certainly limited
with respect to very large presence conditions. We tried
larger problem instances in experiment E5. However, for
one variability model with 100 options, we had to generate
an input Ô¨Åle for simpEwith 637 GB , which is not feasible.
For very large presence conditions, the simpliÔ¨Åed presence
condition will probably still be quite large, so it is questionable
whether simpliÔ¨Åcation is even useful in such cases. We argue
that even if the result expression is still large, every bit of size
reduction helps if the result is used as input to an analysis
tool. If a user interprets the (still large) result, the user might
use tools such as dependency graphs. Such graphs are simpler
once redundant information is removed by simpliÔ¨Åcation.
V. R ELATED WORK
SimpliÔ¨Åcation of presence conditions in the context of
highly conÔ¨Ågurable systems has not been investigated before.
However, work on variability-model reasoning and the
extraction of presence conditions is related.
Variability-model reasoning aims at analyzing properties of
variability models (e.g., consistency) or of sets of models (e.g.,
relationships between models)‚Äîto assure correctness, and to
support evolution and conÔ¨Åguration of systems. A common
reasoning operation is to calculate differences between two
variability models. This problem is closely related to ours and
has been explored before [1, 17, 48]. In general, computing dif-
ferences (diffs) between two entities aandbinvolves two tasks:
stripping the information of afrom band vice versa. Thus, a
diff is a pair of sub-comparisons. The main difference to our
simpliÔ¨Åcation problem is that a diff has to be exact. That is, all
the information of bis removed from aandonly the remainder
is presented to the user. Therefore, applying model-differencing
methods on presence conditions has fewer means to inÔ¨Çuence
the size of the presence condition. Our problem formulation
gives us more leverage: Information that is contained in pand
mcan either remain in simp (p;m)or be removed. We use this
leverage to make simp (p;m)smaller and more readable.
Off-the-shelf reasoners, such as BDD libraries or SAT
solvers, are used for reasoning about Boolean expressions.
Scalability experiments [33, 35, 36] show that SAT solvers
are more scalable than BDDs for most analyses on feature
models. However, BDDs are efÔ¨Åcient for analyses that rely
on enumerating conÔ¨Ågurations; they are known to scale up to
models with 2000 features [35]. In our experiments, simpBDD
exhibited a better scalability than simpEandsimpQC, but for
smaller models and presence conditions, and for a very different
analysis, which has not been investigated before. Good news
is that the algorithms we tested scaled on generated models,
which are usually more complex and harder to reason about than
real-world models [39]. We are not aware of any SAT-based
algorithm applicable to our problem. However, investigating the
feasibility of using a SAT solver would be valuable future work.Various researchers have extracted and analyzed presence
conditions in the context of highly conÔ¨Ågurable systems.
Presence conditions have been extracted using static analysis
from build systems [6, 38], and using dynamic analysis by
compiling individual system variants [21]. All these pieces
of work show the importance of complex presence conditions
to realize the mapping between the variability model and
implementation. In fact, presence conditions in source code
and other artifacts are means to maintain the variability model
by establishing a balance between constraints residing in the
model and in other artifacts. Our experiments (E3) have shown
that the size of presence conditions in real systems is moderate,
suggesting that such systems are relatively well maintained.
In our search for simpliÔ¨Åcation algorithms, we have
also looked at several research areas related to BDDs and
two-level-logic minimization. In particular decomposable
negation normal forms [19, 25], semantic tableaux [18],
and minimization of propositional formulae [31] appeared
promising at Ô¨Årst sight, but in the end, we have not found
algorithms applicable to our problem.
VI. C ONCLUSION
We formally deÔ¨Åned the problem of presence-condition
simpliÔ¨Åcation : A presence condition pis simpliÔ¨Åed with
respect to its context m, in which the presence condition is
used. It is not necessary (and even obstructive) for pto include
information that is already guaranteed by m, which offers
simpliÔ¨Åcation potential. We provide solutions to this problem by
mapping presence-condition simpliÔ¨Åcation to related problems
developed in the 1980/90s for different purposes, namely
two-level logic minimization and the R ESTRICT algorithm.
We discussed a variety of application scenarios for
presence-condition simpliÔ¨Åcation in the area of development
and analysis of highly conÔ¨Ågurable systems. The application
scenarios include the simpliÔ¨Åcation of (1) presence conditions
representing defects found by variability-aware analysis tools,
(2) #if conditions in source code and in variability-aware
ASTs, and (3) cross-tree constraints in variability models.
In a series of experiments, we evaluated the different
algorithms concerning their effectiveness and processing time
as well as the different application scenarios concerning their
potential for simpliÔ¨Åcation. In our experiments, we found
substantial potential for simpliÔ¨Åcation of presence conditions
in many real use cases (e.g., performance prediction or defect
reporting), and the algorithms are suited well for simpliÔ¨Åcation.
This suggests that our approach may produce good results
in other contexts, too. Our experiments have shown that
reduction factors are usually better with simpBDD than with
simpQCorsimpE. Concerning scalability, we have shown that
simpBDD can handle larger problems than simpQCor simpE.
In future work, we plan to include presence-condition
simpliÔ¨Åcation in a variety of analysis tools for conÔ¨Ågurable
systems. Furthermore, our work can serve as a basis for
researchers to further investigate algorithms for presence-
condition simpliÔ¨Åcation.ACKNOWLEDGEMENTS
We thank Olivier Coudert for information on the relationship
of the RESTRICT algorithm to two-level logic minimization,
and Ilia Polian for suggesting two-level logic minimization as
a solution. This work has been supported by the DFG grants
AP 206/4, AP 206/6, and AP 206/7.
APPENDIX
TABLE III: E XAMPLE FOR A PRESENCE CONDITION GIVEN AS
CONFIGURATION TABLE .p1IS THE DNF EXPRESSION FOR r1. FOR BREVITY ,
WE OMIT CONJUNCTIONS (^)AND DENOTE NEGATIONS WITH OVERLINES .
o1 o2 o3 o4 r1 r2 p1= m=
0 0 1 0 X X (o1o2o3o4)
0 0 1 1 X X _(o1o2o3o4)
1 1 0 0 X X (o1o2o3o4)_(o1o2o3o4)
1 1 0 1 X X _(o1o2o3o4)
1 1 1 0 XX_(o1o2o3o4)_(o1o2o3o4)
1 1 1 1 XX_(o1o2o3o4)_(o1o2o3o4)
Input-Format Conversion: Different application scenarios
of presence-condition simpliÔ¨Åcation require different input
formats for the parameters pandm. Conversion between these
formats is a non-trivial technical issue.
The E-M AIL example of Figure 1 illustrates a simple
scenario: The presence condition is aggregated to a single
expression that covers multiple conÔ¨Ågurations. In other
scenarios, a presence condition is given as a table, in which a
row represents a conÔ¨Åguration and the corresponding analysis
result. In Table III, we illustrate this format by means of a
system with conÔ¨Åguration options o1,o2,o3, and o4and two
results r1andr2(e.g., for two different speciÔ¨Åcations). As an
example, assume that conÔ¨Ågurations of the system are tested,
and we mark failed conÔ¨Ågurations with X. ConÔ¨Ågurations
that are not valid with respect to the variability model are not
listed (e.g.,:o1^:o2^:o3^:o4).
We can build the expressions pand mby forming the
disjunction of the respective conÔ¨Ågurations in the table. For
example, to build p1(representing the failed conÔ¨Ågurations
inr1), we form the disjunction of all rows for which column
r1has an X. To build the variability model m, we form the
disjunction of all rows (shown in Table III).
To merge DNF clauses, if possible, we use BDDs, because
BDDs can automatically optimize the representation. Besides a
reduction in BDD size and an improvement for simpBDD, this
also beneÔ¨Åts simpQCandsimpE, because we build the input sets
forsimpQCandsimpEusing the reduced BDD. Each path from
the root node to the true terminal in the BDD translates to one
row in the input table for simpQCandsimpE. Often these paths
do not use all conÔ¨Åguration options (e.g., (o1o2)). In the input
ofsimpQCandsimpE, we would use ‚Äú-‚Äù as value for o3ando4
to indicate that this DNF clause does not depend on o3ando4.
This decreases the size of the ON and OFF sets to be considered
by two-level logic minimization. The DC set needs not be stated
explicitly, because it can be inferred as complement of ON-
and OFF-set. In CNF-based scenarios, we apply the FORCE
algorithm [2] to optimize the variable ordering in the BDD
and improve the input for simpBDD, simpQC, and simpE.REFERENCES
[1]M. Acher. Managing Multiple Feature Models: Foundations, Language
and Applications . PhD thesis, Universit√© Nice-Sophia Antipolis, 2011.
[2]F. Aloul, I. Markov, and K. Sakallah. FORCE: A Fast and Easy-to-
Implement Variable-Ordering Heuristic. In Proc. GLSVLSI , pages
116‚Äì119. ACM, 2003.
[3]S. Apel, C. K√§stner, A. Gr√∂√ülinger, and C. Lengauer. Type Safety
for Feature-Oriented Product Lines. Automated Software Engineering ,
17(3):251‚Äì300, 2010.
[4]S. Apel, A. von Rhein, P. Wendler, A. Gr√∂√ülinger, and D. Beyer.
Strategies for Product-Line VeriÔ¨Åcation: Case Studies and Experiments.
InProc. ICSE , pages 482‚Äì491. IEEE, 2013.
[5]D. Benavides, S. Segura, and A. Ruiz-Cort√©s. Automated Analysis
of Feature Models 20 Years Later: A Literature Review. Information
Systems , 35(6), 2010.
[6]T. Berger, S. She, K. Czarnecki, and A. W Àõ asowski. Feature-to-Code
Mapping in Two Large Product Lines. Technical report, Department
of Computer Science, University of Leipzig, 2010.
[7]T. Berger, S. She, R. Lotufo, K. Czarnecki, and A. W Àõ asowski.
Feature-to-Code Mapping in Two Large Product Lines. In Proc. SPLC ,
pages 498‚Äì499. ACM, 2010.
[8]T. Berger, S. She, R. Lotufo, A. W Àõ asowski, and K. Czarnecki. A Study
of Variability Models and Languages in the Systems Software Domain.
IEEE Transactions on Software Engineering , 39(12):1611‚Äì1640, 2013.
[9]R. Brayton, A. Sangiovanni-Vincentelli, C. McMullen, and G. Hachtel.
Logic Minimization Algorithms for VLSI Synthesis . Kluwer, 1984.
[10] R. Bryant. Symbolic Boolean Manipulation with Ordered Binary-
Decision Diagrams. ACM Computing Surveys , 24(3):293‚Äì318, 1992.
[11] D. Buchfuhrer and C. Umans. The Complexity of Boolean Formula
Minimization. Journal of Computer and System Sciences , 77(1):142‚Äì153,
2011.
[12] A. Classen, M. Cordy, P.-Y . Schobbens, P. Heymans, A. Legay, and
J.-F. Raskin. Featured Transition Systems: Foundations for Verifying
Variability-Intensive Systems and their Application to LTL Model Check-
ing.IEEE Transactions on Software Engineering , 39(8):1069‚Äì1089, 2013.
[13] A. Classen, P. Heymans, P.-Y . Schobbens, and A. Legay. Symbolic
Model Checking of Software Product Lines. In Proc. ICSE , pages
321‚Äì330. ACM, 2011.
[14] O. Coudert, C. Berthet, and J. Madre. VeriÔ¨Åcation of Synchronous
Sequential Machines Based on Symbolic Execution. In Proc. AVMFSS ,
pages 365‚Äì373. Springer, 1990.
[15] O. Coudert and T. Sasao. Two-level Logic Minimization. In Logic
Synthesis and VeriÔ¨Åcation , pages 1‚Äì27. Kluwer, 2002.
[16] K. Czarnecki and M. Antkiewicz. Mapping Features to Models: A
Template Approach Based on Superimposed Variants. In Proc. GPCE ,
pages 422‚Äì437. Springer, 2005.
[17] K. Czarnecki and A. W Àõ asowski. Feature Diagrams and Logics: There
and Back Again. In Proc. SPLC , pages 23‚Äì34. IEEE, 2007.
[18] M. D‚ÄôAgostino. Tableau Methods for Classical Propositional Logic. In
Handbook of Tableau Methods , pages 45‚Äì123. Springer, 1999.
[19] A. Darwiche and P. Marquis. A knowledge compilation map. ArtiÔ¨Åcial
Intelligence Research , 17:229‚Äì264, 2002.
[20] B. Delaware, W. Cook, and D. Batory. Fitting the Pieces Together: A
Machine-Checked Model of Safe Composition. In Proc. FSE , pages
243‚Äì252. ACM, 2009.
[21] C. Dietrich, R. Tartler, W. Schr√∂der-Preikschat, and D. Lohmann. A
Robust Approach for Variability Extraction from the Linux Build
System. In Proc. SPLC , pages 21‚Äì30. ACM, 2012.
[22] E. McCluskey. Minimization of Boolean functions. The Bell System
Technical Journal , 35(5):1417‚Äì1444, 1956.
[23] R. Hall. Fundamental Nonmodularity in Electronic Mail. Automated
Software Engineering , 12(1):41‚Äì79, 2005.
[24] E. Hemaspaandra and H. Schnoor. Minimization for Generalized
Boolean Formulas. In Proc. IJCAI , pages 566‚Äì571. AAAI, 2011.[25] J. Huang and A. Darwiche. On Compiling System Models for Faster and
More Scalable Diagnosis. In Proc. AAAI , pages 300‚Äì306. MIT, 2005.
[26] K. Kang, S. Cohen, J. Hess, W. Novak, and A. Peterson. Feature-
Oriented Domain Analysis (FODA) Feasibility Study. Technical Report
CMU/SEI-90-TR-21, SEI, 1990.
[27] C. K√§stner, S. Apel, T. Th√ºm, and G. Saake. Type Checking Annotation-
based Product Lines. ACM Transactions on Software Engineering and
Methodology , 21(3):14:1‚Äì14:39, 2012.
[28] C. K√§stner, P. Giarrusso, T. Rendel, S. Erdweg, K. Ostermann, and
T. Berger. Variability-aware Parsing in the Presence of Lexical Macros and
Conditional Compilation. In Proc. OOPSLA , pages 805‚Äì824. ACM, 2011.
[29] C. K√§stner, A. von Rhein, S. Erdweg, J. Pusch, S. Apel, T. Rendel,
and K. Ostermann. Toward Variability-Aware Testing. In Proc. FOSD ,
pages 1‚Äì8. ACM, 2012.
[30] K. Lauenroth, S. Toehning, and K. Pohl. Model Checking of Domain
Artifacts in Product Line Engineering. In Proc. ASE , pages 269‚Äì280.
IEEE, 2009.
[31] P. Liberatore. Redundancy in logic i: {CNF} propositional formulae.
ArtiÔ¨Åcial Intelligence , 163(2):203‚Äì232, 2005.
[32] J. Liebig, A. von Rhein, C. K√§stner, S. Apel, J. D√∂rre, and C. Lengauer.
Scalable Analysis of Variable Software. In Proc. ESEC/FSE , pages
81‚Äì91. ACM, 2013.
[33] M. Mendon√ßa. EfÔ¨Åcient Reasoning Techniques for Large Scale Feature
Models . PhD thesis, University of Waterloo, 2009.
[34] M. Mendon√ßa, M. Branco, and D. Cowan. S.P.L.O.T.: Software Product
Lines Online Tools. In Proc. OOPSLA , pages 761‚Äì762. ACM, 2009.
[35] M. Mendon√ßa, A. W Àõ asowski, and K. Czarnecki. SAT-based Analysis
of Feature Models is Easy. In Proc. SPLC , pages 231‚Äì240. SEI, 2009.
[36] M. Mendon√ßa, A. W Àõ asowski, K. Czarnecki, and D. Cowan. EfÔ¨Åcient
Compilation Techniques for Large Scale Feature Models. In Proc.
GPCE , pages 13‚Äì22. ACM, 2008.
[37] S. Nadi, T. Berger, C. K√§stner, and K. Czarnecki. Mining ConÔ¨Åguration
Constraints: Static Analyses and Empirical Results. In Proc. ICSE ,
pages 140‚Äì151. ACM, 2014.
[38] S. Nadi and R. Holt. The Linux Kernel: A Case Study of Build System
Variability. J Softw. , 2013.
[39] R. Pohl, V . Stricker, and K. Pohl. Measuring the Structural Complexity
of Feature Models. In Proc. ASE , pages 454‚Äì464. IEEE, 2013.
[40] W. Quine. The Problem of Simplifying Truth Functions . Mathematical
Association of America, 1952.
[41] K. Schmid, R. Rabiser, and P. Gr√ºnbacher. A Comparison of Decision
Modeling Approaches in Product Lines. In Proc. VaMoS , pages 119‚Äì126.
ACM, 2011.
[42] S. She, R. Lotufo, T. Berger, A. W Àõ asowski, and K. Czarnecki. Reverse
Engineering Feature Models. In Proc. ICSE , pages 461‚Äì470. IEEE, 2011.
[43] N. Siegmund, S. Kolesnikov, C. K√§stner, S. Apel, D. Batory,
M. Rosenm√ºller, and G. Saake. Predicting Performance via Automated
Feature-Interaction Detection. In Proc. ICSE , pages 167‚Äì177. IEEE, 2012.
[44] N. Siegmund, M. Rosenm√ºller, C. K√§stner, P. Giarrusso, S. Apel,
and S. Kolesnikov. Scalable Prediction of Non-functional Properties
in Software Product Lines: Footprint and Memory Consumption.
Information and Software Technology , 55(3):491‚Äì507, 2013.
[45] N. Siegmund, A. von Rhein, and S. Apel. Family-Based Performance
Measurement. In Proc. GPCE , pages 95‚Äì104. ACM, 2013.
[46] R. Tartler, C. Dietrich, J. Sincero, W. Schr√∂der-Preikschat, and
D. Lohmann. Static analysis of variability in system software: The
90,000 #ifdefs issue. In Proc. USENIX , pages 421‚Äì432. USENIX
Association, 2014.
[47] T. Th√ºm, S. Apel, C. K√§stner, I. Schaefer, and G. Saake. A ClassiÔ¨Åcation
and Survey of Analysis Strategies for Software Product Lines. ACM
Comput. Surv. , 47(1):6:1‚Äì6:45, 2014.
[48] T. Th√ºm, D. Batory, and C. K√§stner. Reasoning About Edits to Feature
Models. In Proc. ICSE , pages 254‚Äì264. IEEE, 2009.