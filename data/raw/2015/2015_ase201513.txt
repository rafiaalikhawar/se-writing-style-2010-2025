Evolutionary Robustness Testing of Data Processing
Systems using Models and Data Mutation
Daniel Di Nardo, Fabrizio Pastore, Andrea Arcuri, Lionel Briand
Interdisciplinary Centre for Security, Reliability and Trust (SnT Centre)
University of Luxembourg, Luxembourg
Email: {daniel.dinardo,fabrizio.pastore,andrea.arcuri,lionel.briand}@uni.lu
Abstract —System level testing of industrial data processing
software poses several challenges. Input data can be very large,
even in the order of gigabytes, and with complex constraints thatdeﬁne when an input is valid. Generating the right input data tostress the system for robustness properties (e.g. to test how faultydata is handled) is hence very complex, tedious and error pronewhen done manually. Unfortunately, this is the current practicein industry. In previous work, we deﬁned a methodology to modelthe structure and the constraints of input data by using UMLclass diagrams and OCL constraints. Tests were automaticallyderived to cover predeﬁned fault types in a fault model. Inthis paper, to obtain more effective system level test cases, wedeveloped a novel search-based test generation tool. Experimentson a real-world, large industrial data processing system showthat our automated approach can not only achieve better codecoverage, but also accomplishes this using signiﬁcantly smallertest suites.
I. I NTRODUCTION
Data processing software is an essential component of
systems that aggregate and analyse real-world data, thereby
enabling automated interaction between such systems and thereal world. Examples are search engines that return stockquotes [1] or personal information collected from the web [2],web applications that show real-time airplane positions [3],devices such as specialised eyeglasses that capture images andprovide contextual suggestions [4], and phones able to translatein real time the words of a road sign [5].
Robustness is “the degree to which a system or component
can function correctly in the presence of invalid inputs orstressful environmental conditions” [6]. Robustness testing ofdata processing software in the presence of invalid inputs is ofparticular importance because of the impact unexpected fail-ures may have. For example, data faults in the transmission ofan airplane position may crash airplane tracking applications,while malformed HTML pages may lead a web crawler toreport stock market collapses and cause panic to end users [7].
Robustness testing of data processing software is often
complicated by the complex structure of the input data. Awell known example is an HTML page that contains manyblocks, some of which are kept hidden or contain dynamicinformation. Similar complexity characterises other kinds ofprocessing systems; for example, the data acquisition (DAQ)systems developed by our industrial partner SES to pro-cess satellite transmissions [8]. When performing robustnesstesting, software engineers need to handcraft complex datastructures where valid and faulty values need to be insertedwhile taking care to preserve all the relationships among thedata ﬁelds. Handcrafting huge amounts of complex data isparticularly time consuming and error prone.In [8] we introduced a technique to test the capability of
data processing software to identify invalid test inputs thatmatch a given fault model. The technique uses a set of genericmutation operators to generate test inputs by sampling andmutating ﬁeld data. The technique ensures that each possiblefault instance characterised by a fault model is covered by thegenerated test cases.
In this paper, we tackle the more general problem of
generating minimal robustness test suites, with high faultrevealing power, for data processing systems. When dealingwith robustness testing, a single test generation criterion, forexample the coverage of the given fault model implementedin [8], is not enough. Multiple factors must be considered; forexample the presence of multiple data faults in the same input,the coverage of functional speciﬁcations in addition to faultmodels, and the generation of a minimal number of test cases.Satisfying multiple criteria when generating robustness testsuites may easily lead to combinatorial explosion and speciﬁctechniques able to deal with scalability issues are required.
When addressing complex problems where there is a large
space of candidate solutions, and one wants to choose asolution that maximises some chosen criteria, metaheuristicsare a plausible solution [9]. Metaheuristic algorithms, such asevolutionary algorithms, identify optimal solutions for a prob-lem by iteratively building candidate solutions and by testingthem to identify the one that best achieves the objectives. Ateach iteration, new candidate solutions are built by means ofa tweak operation that is applied on a copy of a candidatesolution. The tweak operation allows the algorithm to explorethe search space looking for an optimal solution.
Testing techniques based on metaheuristic search focus
mostly on unit testing [10], while techniques that tackle testingat the system level either address the problem of testing non-functional properties such as execution time [11], or deal withthe problem of testing systems where the costs of testing donot depend on complex input data structures, such as in thecase of embedded systems working with input signals [12].
In this paper, we propose a model-based evolutionary
algorithm that relies upon a data model and a set of data mu-tation operators to build system test suites for data processingsystems that optimises multiple objectives. The evolutionaryalgorithm uses data sampling and data mutation operatorsto generate new test inputs, and relies upon four differentmodel-based and code-based ﬁtness functions to evaluate howwell each test input contributes to a proper robustness testsuite. Model-based ﬁtness functions exploit the data modelto generate test cases that cover important aspects of thebehaviour of the system by ensuring the coverage of all the
2015 30th IEEE/ACM International Conference on Automated Software Engineering
978-1-5090-0025-8/15 $31.00 © 2015 IEEE
DOI 10.1109/ASE.2015.13126
/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23
/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/g31/;#23#23#23#23#23#23/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23/g33/;#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/g34/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g35/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g33/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/g33/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/g37/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g37/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g37/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/g37/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g37/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/g37/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23
/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g39/;#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g40/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23/g34/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/g41/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g33/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23
/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g42/g39/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g40/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g42/g39/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g40/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23#23#23/g32/;#23#23#23#23#23#23#23#23#23#23#23/g33/;#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g32
/g43
/g43/g44/g44/g45 /g43/g44/g44/g45/g43/g44/g44/g45
/;#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g43/g43
/g43/g43 /g43/g44/g44/g45/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23/;#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/g46/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23
/;#23/;#23#23/;#23#23#23/;#23#23#23#23/;#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23
/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g37/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g36/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23/g38/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23/;#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23#23/g43/g43/g43/g43 /g43/g44/g44/g45
Fig. 1. Simpliﬁed input data model for the SES running example. SA,
StreamAttributes; SC, StreamClass.
different types of test inputs processed by the system, the
presence of different types of data faults, and the possibleviolations of the constraints among test inputs. The code-based ﬁtness function has the goal of achieving the maximumstructural coverage of the system under test.
This paper contributes to the state of the art by:
• proposing an evolutionary algorithm to automate ro-
bustness testing of data processing systems;
• deﬁning four ﬁtness functions (model-based and code-based) that enable the effective generation of robust-ness test cases by means of evolutionary algorithms;
• performing an extensive study of the effect of ﬁt-ness functions and conﬁguration parameters on theeffectiveness of the approach using an industrial dataprocessing system as case study.
The paper proceeds as follows. Section II provides back-
ground information on the data modelling and mutation op-erators used by the algorithm. Section III presents a listof challenges that need to be addressed when building asearch algorithm for robustness testing. Section IV providesan overview of the evolutionary algorithm that we designedto generate robustness tests. Section V describes how datamutation is adopted to generate new test inputs during thesearch. Section VI presents the heuristic functions used toevaluate candidate solutions. Section VII describes the seedingstrategy integrated into the algorithm. Section VIII details howwe automate the execution and validation of the generatedtest suites. Section IX presents the empirical results obtained,whereas Section X discusses related work. Finally, Section XIconcludes the paper.
II. B
ACKGROUND ON DATA MODELLING
The evolutionary algorithm presented in this paper uses
data models to automatically generate test inputs. Such datamodels are designed according to the data modelling method-ology introduced in previous work [8], [13]. This sectionprovides an overview of the methodology.
The methodology presented in [8] uses UML class dia-
grams to capture the structure of inputs and outputs, relies uponObject Constraint Language (OCL) [14] expressions to deﬁnerelationships between the inputs and outputs, and uses UML1 context Vcdu inv:
2 let
3 frameCount : Integer = self.header.vcFrameCount,
4 vdcuIndex : Integer = self.virtualChannel.vcdu→indexOf( self ),5 previous : Vcdu = self.virtualChannel.vcdu→at( vcduInde x-1) ,
6 previousFrameCount : Integer = previous.header.vcFrameCount7 in
8 ifpreviousFrameCount <16777215
9 then frameCount <> previousFrameCount + 1
10 else previousFrameCount =16777215 and frameCount <> 0endif
11 implies
12 VcduEvents.allInstances()13 →exists(e |e.eventType = COUNTER
JUMP )
Fig. 2. Input/output constraint for the COUNTER JUMP error event.
stereotypes to capture a fault model driving the generation of
test cases.
To brieﬂy present the methodology, we show how it can
be applied to model the transmission data processed by SES-DAQ, a DAQ system developed by SES (see [15] for thecomplete speciﬁcations of the transmission data). SES-DAQprocesses bytestreams of transmitted satellite data. Developingsuch a model requires time and engineering effort but the costof modelling was considered acceptable by SES engineers [13].
Figure 1 shows how we model SES-DAQ input data ac-
cording to our methodology. The model captures the structureof a transmission: we use UML classes to represent elementsthat contain multiple ﬁelds, while we use UML attributesto model elements that cannot be further decomposed. Forexample, it shows that each transmission consists of a sequenceofVirtual Channel Data Units (VCDUs) . Each VCDU begins
with a Header, followed by a PacketZoneHeader and a Pack-
etZone that may contain a sequence of Packets (if the packet
zone is active). The VCDUs in a transmission may belong to
different virtual channels.
Associations are used to represent containment relation-
ships. In Figure 1 the classes that model the VCDU and itsHeader are connected by an association. We use generalisationsto indicate when a data ﬁeld can have multiple differentdeﬁnitions. For example, in the case of SES-DAQ the packetzones can be active (i.e. they transmit data) or idle (i.e. they donot transmit anything). The data model of SES-DAQ reﬂectsthis characteristic with generalisations for PacketZoneHeaderand PacketZone, both of which have idle and active subtypes.
We use class attributes to represent the transmitted binary
information (e.g. checksums, frame counters, or data). Forexample, attribute sequenceCount of class Packet is used to
store information about the packet order.
Constraints between inputs and outputs are represented
using OCL. These constraints are used as an oracle to validatethe execution of automatically generated test cases: a violatedconstraint indicates that the system under test does not producethe expected output. In the case of SES-DAQ, we use OCLconstraints to model the error messages expected in the pres-ence of speciﬁc faults in the input data. For example, Figure 2shows an OCL constraint that states that the frame count ofa VCDU should be greater by one than the frame count ofthe previous VCDU on the same virtual channel. Otherwise,an error event COUNTER
JUMP should exist in the system
output log ﬁle.
Stereotypes are used to capture the fault model of the
system, and are used to identify the ﬁelds that can be mutatedto generate new inputs. The stereotype InputData is used by the
software engineer to tag the classes that model input data, to
127contrast them with output data classes, which do not need to be
mutated. The two stereotypes Identiﬁer and Measure are used
to indicate the mutation operators to apply to class attributes.The stereotype Derived is used to tag class attributes that need
to be derived from other attributes after every mutation, inorder to prevent trivial inconsistencies (e.g. it is used to updatethe checksum ﬁeld when other ﬁelds are mutated).
The stereotypes StreamClass and StreamAttributes are used
to automate the loading of data from bytestreams but are outof the scope of this paper (see [8] for details).
III. C
HALLENGES FOR THE SEARCH -BASED GENERA TION
OFROBUSTNESS SYSTEM TESTS
Search algorithms are useful when addressing complex
problems where there is a large space of candidate solutions,and one wants to choose one that optimises some chosencriteria. A typical example in software engineering is test datageneration, in which a tester might want to ﬁnd test data thatmaximises code coverage or triggers new failures.
There are many different kinds of search algorithms, in-
cluding genetic algorithms, which have been widely appliedin many ﬁelds. Not all search algorithms perform well onall types of problems. Each problem can have special char-acteristics that are better exploited by some search algorithms,whereas others might struggle.
In this paper, we identify four main challenges that need to
be addressed when designing an algorithm for the automaticgeneration of a system test suite: (1) conﬁguring the algorithmto properly ﬁnd a tradeoff between exploration and exploitation
of the search landscape, (2) building a tweak operation, (3)
deﬁning effective ﬁtness functions for the problem under
investigation, and (4) integrating effective seeding techniques
(i.e. techniques that speed up search by exploiting knowledgeabout the input domain).
One of the main discerning characteristics among search
algorithms is the tradeoff they have between exploration and
exploitation of the search landscape. On one hand, some
algorithms (e.g. hill climbing) put more emphasis on theexploitation of the search landscape. This means that, givenan evaluated solution, they will only look at “close” solutionsto see if any small change could improve the chosen criterion.On the other hand, other algorithms put more emphasis onthe exploration of the search space. Typical examples arepopulation-based algorithms, in which a diverse set of solu-tions is maintained to consider different areas of the searchlandscape at the same time, in case one area turns out to featuremore ﬁtting solutions than the others.
In the context of robustness testing, exploration is very
important since it enables the construction of test suites witha high diversity of test cases. In the case of SES-DAQ,for example, one wants to generate test inputs that includeIdlePacketZones and test inputs that include ActivePacketZones
at the same time. However, exploitation leads to coveringinvalid inputs that include a speciﬁc set of data faults. Forexample, SES-DAQ might be able to properly process aninvalid input containing a packet that breaks the constraint inFigure 2, but it may crash in the presence of both a brokenconstraint and a duplicated packet. To satisfy this case, thealgorithm must be able to exploit the search space by bothbreaking the constraint of Figure 2 and by duplicating a packet.
Tweak operations play an important role in guiding the
search algorithm towards the exploitation of the search land-scape; they modify existing solutions to generate new can-didate solutions. When deﬁning tweak operations, the char-acteristics of the domain should be carefully considered. Forexample, when a solution is represented in a binary format,a tweak operation could just ﬂip one or more bits. However,ﬂipping bits on a complex data transmission ﬁle would likelyresult in meaningless or trivially wrong input data. Therefore,one would need to exploit the information in the data modelsto automatically derive better tweak operations, for exampleby applying model-based data mutation.
In the context of robustness system testing, one still wants
to generate faulty input data, but in a nontrivial way (e.g. byincluding multiple faults in a same test input). However, thereis a limit on the number of faults that can be included in asame input. Although having multiple mutations that affect asame test input might help stress the robustness of the system,a number of faults that is too high might lead to inputs that aretrivially recognised and discarded by the system under test.
Another very important aspect for the success of a search
algorithm is the deﬁnition of a ﬁtness function, used to evaluate
how close a solution is to optimising a chosen criterion. Sucha function is problem dependent, and effort must be madeto design a proper one. Ideally, one would like to exploit asmuch domain information as possible, but this might lead tocomputationally expensive ﬁtness functions. The more timeconsuming the ﬁtness function, the fewer solutions can beevaluated by a search algorithm in the same amount of time.In the case of model-based testing, this tradeoff can be verycritical, as ﬁtness functions calculated on models can bemuch quicker to compute than ones calculated from test caseexecutions (e.g. using structural coverage).
Finally, in the presence of complex search spaces, the
quick identiﬁcation of a proper solution is often aided bythe adoption of techniques that exploit knowledge about thesearch space to build solutions that improve the effectivenessof the search algorithm; these are known as seeding techniques.
Different seeding techniques have been adopted in the contextof software testing; for instance, a well known approach usedby techniques that generate inputs for unit testing is the reuseof constant values taken from the source code of the softwareunder test [16]. However, smart seeding at the system level isnot as simple as that, and poses new challenges.
IV . A
NEVOLUTIONARY ALGORITHM FOR ROBUSTNESS
TESTING
To address the problem of generating test cases to stress
the robustness of software at the system level, we propose anovel evolutionary algorithm based on an archive. Figure 3shows the algorithm.
In the context of this paper, a solution to the search problem
consists of a test suite that effectively tests the capability ofthe software to handle invalid data. A test suite is a collectionof test inputs (i.e. data ﬁles conforming to a data model) to beprocessed by the software under test. During the search, testinputs are generated, and those are then aggregated to form aﬁnal test suite to give as output to the user. In our context, thesolution to the search problem (i.e. the test suite) cannot berepresented using a ﬁxed size data structure because the sizeof the test suite (i.e. the number and size of the test cases itcontains) cannot be known a priori.
We did not directly use a traditional search algorithm
(e.g. a genetic algorithm or a hill climbing algorithm) due
128Require: fD , the ﬁeld data used to generate test inputs
Require: dM , the data model used to drive tweaking
Require: budget, the maximum proportion of the search space that needs to be visited
Require: pfield , probability of sampling a new individual from the ﬁeld data
Require: pmutation , probability of mutating an individual just after sampling it
Require: pseeding , probability of using seeding to sample from the ﬁeld data
Require: minSize, the minimum size of a test input
Require: maxSize , the maximum size of a test input
Require: maxMutations, the maximum number of mutations for a same test input
Ensure: archive, the archive containing the minimised robustness test suite
1:total=0
2: while total < budget do
3: if((archive.individualAvailable(maxMutations)= false)
4: OR(random ()<p field))then
5: ind=sampleNew (fD, dM, minSize, maxSize, p seeding)
6: ifrandom ()<p mutation then
7: mutate(ind)
8: end if
9: else
10: ind=archive.sampleACopy ()
11: mutate(dM, ind)
12: end if
13: if(improving (ind, archive) then
14: archive.add(ind)
15: forprev in archive do
16: ifsubsume (ind, prev )then
17: archive.remove(prev )
18: end if
19: end for
20: end if
21: total=total+ind.size
22: end while
Fig. 3. An Evolutionary Algorithm for Robustness Testing
to the special characteristics of the addressed problem. For
example, in system level testing, each test case execution canbe computationally very expensive. So, a traditional geneticalgorithm that works on a population would likely be toocomputationally expensive to use. Furthermore, special carewould be needed to design a crossover operator that generatesvalid offspring. On the other hand, hill climbing algorithms putemphasis on the exploitation of the search landscape; this isachieved by using a tweak operation that iteratively improvesa single solution. In our case, it is hard to envision a singletweak operation that works at the test suite level and allows forthe building of a minimised test suite that contains test inputswith high diversity.
Our customised evolutionary algorithm is based on the use
of an archive of test cases, initially empty. Archives have beenused in prior work related to multi-objective search algorithms(e.g. [17], [18]). The archive plays the important role ofguiding the algorithm towards the exploitation of the searchlandscape like hill climbing, while maintaining at the sametime some characteristics of population-based algorithms. Likehill climbing, the algorithm improves only a single test input ateach iteration, but uses the archive to keep a collection of thebest test inputs found so far (i.e. the test suite). Furthermore,our algorithm keeps solutions in the archive that are differentfrom each other to maximise exploration, like populationalgorithms. The size of the archive can vary during the searchand the test suite is minimised by keeping in the archive onlythe best individuals that contribute to overall ﬁtness of thewhole test suite (i.e. the archive). Finally, the individuals inthe archive are tweaked one at a time, thus exploiting thesearch landscape and creating new individuals that improvethe overall ﬁtness of the test suite.
Our novel algorithm addresses all the challenges presented
in Section III. The tradeoff between exploration and exploita-tion is controlled by conﬁguration parameters that regulate:(1) the probability of tweaking an individual from the archiveversus generating a completely new individual (parameterp
field in Figure 3), (2) the probability of working with correct
test inputs versus the use of test inputs that contain at leastone fault (parameter p
mutation in Figure 3), and (3) the
maximum number of data faults a test input may contain(parameter maxMutations in Figure 3). Tweaking operations
are implemented by means of mutation operators describedin [8], while speciﬁc ﬁtness functions have been developedand are described in Section VI. The probability of seeding iscontrolled by the parameter p
seeding (further details are given
in Section VII).
At the ﬁrst iteration, the archive is empty, and a new
random individual needs to be sampled. Generating new inputdata completely at random would result almost certainly intrivially wrong data. An alternative is to sample according tosome speciﬁc rules, if those can be deﬁned for the addressedproblem domain (e.g. a grammar in the testing of parsers).In our case, we used a different approach that relies on thesampling of ﬁeld data. In the case of industrial data processingsystems, we can have access to very large amounts of existingvalid ﬁeld data. If not already available, a large ﬁeld datapool can be constructed, and then used by the evolutionaryalgorithm to sample from.
New individuals are sampled from the available ﬁeld data
by means of the function sampleNew, which randomly selects
and returns a chunk of the available ﬁeld data (Line 5).The function sampleNew receives as input two integer values,
minSize and maxSize that indicate the minimum and maximum
size of the data chunk to be sampled. Since in general an inputfor a data processing system does not have a size that is ﬁxeda priori, we leave it to the software engineers to decide therange of the input size according to their domain knowledge;for example, in the case of SES we choose the values 1 and 500for the minimum and maximum values, respectively (wherethese values represent the number of VCDUs).
The evolutionary algorithm incrementally builds a test
suite by keeping only those individuals in the archive thatcontribute to improving the overall combined ﬁtness of allthe currently stored test cases, which will form the ﬁnal testsuite. The algorithm generates test inputs by applying thetechnique presented in [8], that is by sampling chunks of datafrom the ﬁeld data and by mutating these chunks to generatepossibly faulty inputs. Unlike [8], in this paper we considerthe possibility of applying multiple mutations to a same testinput. Each test input is thus represented in terms of the offsetfrom the beginning of the original ﬁeld data ﬁle, the length ofthe sample, and a list of the mutations that have been appliedto the sample.
The algorithm keeps exploring the search space until
a given stopping condition is reached (Line 2). Since ouralgorithm focuses on the generation of test inputs for dataprocessing systems, we express the stopping condition in termsof the amount of data processed to generate test cases, that isthe sum of the size of all the test inputs generated during thesearch. At each iteration, the algorithm increments the counterof the data processed (Line 21). In the speciﬁc case of SES, wemeasure the size of a single test input in terms of the numberof VCDUs that it contains, but different measurement units(meaningful for a given domain) may be used for differentsystems.
At each iteration, the algorithm works by tweaking an
individual (i.e. a test input). Each individual is created by
129sampling either the ﬁeld data or the archive; this choice is
driven by a probability value, the parameter pfield in Figure 3,
which indicates the probability of sampling a new individualfrom the ﬁeld data (see Lines 3 and 4).
If no individuals are available in the archive, the
algorithm samples the ﬁeld data (see the conditionarchive.individualAvailable() = false in Line 3). This happens
in two situations, when the archive is empty (i.e. on the ﬁrstsearch iteration) or when all the individuals in the archive havealready been mutated a maximum numbers of times. Softwareengineers can specify the maximum number of mutations thatcan be applied to the same test input. This is done to avoidtrivially invalid inputs. Although in principle a test input canbe mutated an inﬁnite number of times, the presence of toomany mutations (i.e. data faults) on the same test input, mighttransform the test input into a trivially invalid input that iseasily detected by the data processing system and does nothelp to extensively test its robustness.
Lines 6 to 8 show that the parameter p
mutation regulates
the probability of mutating an individual just after creating it,that is the probability of working with individuals that containat least one data mutation. Lines 10 and 11 show that everytime the algorithm samples a copy of an individual from thearchive it applies a mutation to it. This is done to create a copythat differs from the original one. This tweaking operation isfurther described in Section V.
Lines 13 and 14 show that an individual is added to the
archive only if it improves the overall ﬁtness of the archive.Similarly, the algorithm removes any individual already presentin the archive that is subsumed by the last one added (seeLines 15 to 17). Individuals that are subsumed by new onescan be safely removed from the archive because they do notcontribute to the overall ﬁtness of the archive. Section VIdescribes the assessment procedure adopted to measure howindividuals contribute to the ﬁtness of the archive.
V. T
WEAKING BY MEANS OF DATA MUTA TION
The search algorithm tweaks individuals by applying the
data mutation operators described in [8]. There are six mu-tation operators that can be applied to an individual: ClassInstance Duplication, Class Instance Removal, Class InstancesSwapping, Attribute Replacement with Random, AttributeReplacement using Boundary Condition, and Attribute BitFlipping. To apply a mutation operator to an individual, thealgorithm loads into memory the data chunk corresponding tothe test input as an instance of the data model.
According to [8], each mutation operator can be applied
only to a speciﬁc set of targets. This is done to avoid makingmutations that will result in the generation of trivial datafaults and to ensure conformance with a domain-speciﬁc faultmodel. Software engineers specify the targets of each mutationoperator by using appropriate stereotypes in the UML classdiagram (data model). These stereotypes indicate the elementsthat can be mutated and the operators that can be applied tothem. To mutate an individual, the algorithm randomly picks amutation operator, identiﬁes a possible target for the operatoron the current individual, and applies the operator on thetarget. For example, during the generation of test inputs forSES-DAQ, the algorithm may randomly choose the operatorAttribute Replacement with Random. It then selects one of theattributes that can be mutated according to that operator, forexample the attribute sequenceCount of class Packet . Finally,it identiﬁes a speciﬁc instance to mutate, which means that itchanges the value of the attribute sequenceCount of one of the
Packet instances contained in the current test input.
In case a selected operator cannot be applied on a given
individual, another operator is randomly selected; this canhappen, for example, if the algorithm selects the attributesequenceCount for replacement with random, but the current
test input contains only IdlePacketZones (which according to
Figure 1 does not contain any Packet instances).
VI. A
SSESSMENT PROCEDURE
We identify four objectives that should be fulﬁlled to
effectively stress the robustness of the software:
• O1: include input data that covers all the classes ofthe data-model;
• O2: include data faults such that all the possible faultsof the fault model have been covered;
• O3: cover all the clauses of the input/output con-straints;
• O4: maximise code coverage.
Each of the four objectives captures how well the test
inputs cover some speciﬁc targets, respectively, the classes ofthe data-model, the faults of the fault model, the clauses ofthe input/output constraints and the code instructions. Eachobjective deﬁnes a set of targets (e.g. instructions in code
coverage) that the algorithm aims to cover. A given objective isfully achieved by a test suite if each of its targets is covered byat least one test input of the test suite. A portion of the targetsfor SES-DAQ along with their coverage for three test inputs areshown in Table I (covered targets are marked with an X). Wedescribe below each objective, and how ﬁtness improvementsand subsumption can be deﬁned in terms of these objectives.
Objective O1 ensures that the test suite includes test inputs
that cover all the classes of the data model. Each class of thedata model is univocally represented by an objective target. Atest input covers a class if it contains at least one instance ofthe class. Table I shows that input I3covers, among others,
classes ActivePacketZone and IdlePacketZone; input I1covers
only class ActivePacketZone (there are no idle packets in I1).
Objective O2 ensures that an instance of each class and
attribute has been mutated at least once by each mutationoperator that can be applied to it (to generate test inputscovering all the faults of the fault model). Our algorithmgenerates faulty data (i.e. new test inputs) by applying mutationoperators on instantiated ﬁeld data objects. Since the attributesand classes of the data model can be mutated in differentways by applying different mutation operators, for each testinput we keep track of which mutation operator has beenapplied to a speciﬁc class/attribute. Table I, for example,shows that input I1 contains at least one instance of a VCDU
whose vcFrameCount has been mutated with the operator At-
tributeReplacementWithRandom, while input I3contains both a
VCDU with a deleted packet (operator ClassInstanceRemoval
is marked as being applied on an instance of class Packet )
and a VCDU whose versionNumber has been replaced with a
random value (see operator AttributeReplacementWithRandom
marked for the attribute versionNumber ).
Objective O3 ensures that every clause of the input/output
constraints has been exercised. Input/output constraints areexpressed in the form of implications. The left hand side ofthe implication captures the characteristics of the input under
130which a given output is expected. The right hand side captures
the characteristics of the expected output (see Figure 2).
To measure how well the test suite stresses the conditions
under which a given output is generated, it is enough to focuson the clauses contained on the left side of the implication (i.e.clauses deﬁned over the characteristics of the test input). Foreach clause, we aim to have at least one test input that causesthe clause to be true and another that causes the clause to befalse. Each clause is thus associated to two different targetsfor objective O3 that trace whether the clause is true/false atleast once in the input. Table I shows some targets derived forthe constraint in Figure 2. Table I shows that input I1 has atleast one VCDU whose frameCount does not correspond to
the previousFrameCounter plus one (this is the effect of the
mutation operator AttributeReplacementWithRandom applied
to the attribute vcFrameCount ). The same clause can be both
true and false within the same test input. This is the caseof input I1 that, in addition to a VCDU with the invalidframeCount, also includes VCDUs with a valid frameCount
(i.e. a frameCount equal to previousFrameCount plus one).
It is noteworthy that, by focusing on the input clauses,
we can measure objective O3 without the need to execute thesystem under test (i.e. without generating an output for a giventest input). This makes the search algorithm scale even whenthe execution of the test cases is particularly time consuming.
Objective O4 aims to maximise the structural coverage of
the source code. This is one of the means adopted by softwareengineers to ensure that all the implemented features havebeen tested at least once. Each instruction in the system is anobjective target. In our implementation, we measure coverageusing JaCoCo, a toolkit for measuring Java code coverage [19].
The main limitation of measuring the structural coverage of
system test cases is that it requires the execution of the systemunder test. This may slow down the overall search processconsiderably and prevent the generation of results in practicaltime. Furthermore, in certain contexts, for example systemsdeployed on dedicated hardware, structural coverage might notbe easily calculated in practice. For this reason, the empiricalstudy presented in Section IX aims also to determine to whichextent objective O4 is subsumed by other objectives.
Our algorithm works with objectives that are not conﬂicting
and aims to maximise the coverage of all targets. Therefore,the algorithm does not rely upon the computation of Paretofronts, a solution adopted by others (e.g. [20]).
Our algorithm adds to the archive only test inputs that
improve the overall ﬁtness (i.e. a test input must cover at leastone target not covered by the other inputs in the archive).Furthermore, the algorithm removes from the archive any test
inputs subsumed by new test inputs. A test input i
/primesubsumes
an input i/prime/primeif, and only if, i/primecovers all the targets covered
byi/prime/prime, and either i/primecovers at least one target not covered
byi/prime/primeor the size of i/primeis smaller. For example, given an
archive that contains inputs I1and I2, our algorithm creates
input I3by tweaking a copy of input I2(i.e. by deleting a
class instance). I3is added to the archive because it covers
target Packet::ClassInstanceRemoval (not covered by I1and
I2). Given that I3subsumes I2the algorithm will then remove
I2from the archive thus minimising its size.
VII. I NPUT SEEDING
To further improve search results, we developed a novel
model-driven seeding strategy that guides the search towardsthe identiﬁcation of a diverse and complex set of test inputs.
To stress diversity in the data, the algorithm aims to
generate test inputs that cover all the available data types (see
objective O1 described in Section VI). Given that some ofthese data types may occur rarely in the ﬁeld data, it might behighly improbable to cover these types by means of randomsampling. To guarantee the coverage of all the data types, itis enough to know the locations of the different data types.For example, within a ﬁeld data sample of SES-DAQ, we mayhave idle packets only in a very small number of the VCDUsof the bytestream. Having the location information makes iteasier for the search algorithm to load multiple data chunkscontaining idle packets; otherwise, the chance of loading idlepackets is low when only resorting to random sampling.
To stress complexity our algorithm looks for test inputs
that contain instances of two or more subclasses belongingto the same generalisation. In the case of SES-DAQ, thiscorresponds to the case of an input containing a transitionbetween two alternate data types (e.g. from idle to active packetzone). These complex inputs are interesting for robustnesstesting because one can assume that handling heterogeneousdata zones might be more prone to processing failures thanhomogeneous ones.
Our seeding strategy works by ﬁrst processing the ﬁeld
data to build a seeding pool that contains data chunks that are
useful to stress both diversity and complexity. To maximisediversity, we identify, for each class Sthat is a subclass of
a generalisation: (1) data chunks that contain at least one
instance of the subclass S, (2) data chunks that contain only
instances of the subclass S, i.e. data chunks that contain
instances of Sbut that do not contain instances of other
classes belonging to the same hierarchy of S. To maximise
complexity, we identify, for each pair of classes that belong to ageneralisation, data chunks that contain at least one instance ofeach class in the pair. In the case of SES-DAQ this ensures thatwe test scenarios where two different data types are processed
TABLE I. A SSESSMENT OF THREE INPUTS OF SES-DAQ
Objective TargetsTest Inputs
I1 I2 I3Objective O1Transmission X X X
Sync X X X
Header X X X
IdlePacketZoneHeader X X
ActivePacketZoneHeader X X X
IdlePacketZone X X
ActivePacketZone X X X
Packet X X X
...Objective O2Header.versionNumber::AttributeReplacementWithRandom X X
Header.vcFrameCount::AttributeReplacementWithRandom X
Packet::ClassInstanceRemoval X
Packet::ClassInstanceDuplication
Packet::ClassInstancesSwapping
...Objective O3True : previousFrameCount <16777215 X X X
True : frameCount <> previousFrameCount + 1 X
True : previousFrameCount = 16777215
True : frameCount <> 0 X X X
...
False : previousFrameCount <16777215
False : frameCount <> previousFrameCount + 1 X X X
False : previousFrameCount = 16777215 X X X
False : frameCount <> 0
...O4SesDaq.java:Line 10 X X X
SesDaq.java:Line 11 X
...
131TABLE II. L IST OF THE CHARACTERISTICS OF THE INPUT DA TA USED
TO DRIVE SEEDING FOR SES-DAQ
Only IdlePacketZoneHeader instances are included
At least one IdlePacketZoneHeader instance is included
Only ActivePacketZoneHeader instances are included
At least one ActivePacketZoneHeader instance is included
Only IdlePacketZone instances are included
At least one IdlePacketZone instance is included
Only ActivePacketZone instances are included
At least one ActivePacketZone instance is included
Both IdlePacketZone and ActivePacketZone are included
Both IdlePacketZoneHeader and ActivePacketZoneHeader are included
in sequence (e.g. idle and active packets). Table II shows a list
with the characteristics of the data chunks we identify for theSES-DAQ data model in Figure 1.
The seeding pool can be used when a new individual is
sampled. When seeding is enabled, the algorithm selects oneof the chunks in the seeding pool. In the case of SES-DAQ thisis done by ﬁrst selecting one on the ten characteristics listedin Table II, and then by loading a data chunk that presentssuch characteristics. Software engineers can tune the use ofseeding by means of a parameter for the search algorithm thatindicates the probability of applying seeding when sampling adata chunk from the ﬁeld data (p
seeding in Figure 3).
Higher values of pseeding guarantee that all the character-
istics are covered, at the expense of a free exploration of thesearch space (which may lead to the sampling of complex testinputs not identiﬁed by predeﬁned seeding characteristics).
VIII. T
ESTING AUTOMA TION
The evolutionary algorithm generates a minimised robust-
ness test suite that is kept in an archive. The test suiteconsists of a set of test inputs that can be executed against theDAQ system under test. The oracle relies on the model-basedautomated validation technique presented in [13] and [8].
After the execution of a test case, the oracle simply loads
the test input and the test output as an instance of the datamodel, and checks if the OCL constraints of the data modelare satisﬁed
1. Unsatisﬁed constraints indicate the presence of
a failure (i.e. unexpected or missing output) and are reportedto the software engineers. Similarly, crashing executions arereported.
IX. E
MPIRICAL EV ALUA TION
We performed an empirical evaluation in order to respond
to the following research questions:
• RQ1: How does the search algorithm compare with
random and state-of-the-art approaches?
• RQ2: How does ﬁtness based on code coverage affect
performance?
• RQ3: How does smart seeding affect performance?
• RQ4: What are the conﬁguration parameters that
affect performance?
• RQ5: What conﬁguration should be used in practice?
A. Subject of the Study
As subject of our study we considered the industrial SES-
DAQ system. SES-DAQ is a good example of a data processingsystem dealing with complex input and output data, written inJava (having 32170 bytecode instructions). The data modelof SES-DAQ includes 82 classes with 322 attributes and 56
1This is done by using the MDT/UML2 library, http://eclipse.org/modeling/associations. As an input for our approach, we considered alarge transmission ﬁle containing ﬁeld data provided by SES,the same adopted for the empirical evaluation in [8]. The sizeof the transmission ﬁle is about 2 gigabytes, containing 1million VCDUs belonging to four different virtual channels.
B. Experimental Settings
To answer our research questions, we carried out a series
of experiments. Since our search algorithm depends on several
parameters, we evaluated several possible conﬁgurations.
The minSize and maxSize parameters (i.e. the minimum and
the maximum size of a test input, measured in VCDUs) wereﬁxed to 1 and 500, respectively. We used three different valuesforp
field : 0.3, 0.5, and 0.8. For pmutation , we considered the
values: 0.0, 0.5, and 1.0. For maxMutations, we used: 1, 10,
and 100. For pseeding , we used two values, 0.0and0.5, which
means that in one case the seeding strategy was not used,while in the other case the seeding was applied with a 50%probability every time a new input was sampled.
In order to give the algorithm some degree of freedom
when exploring the search space, we do not consider the casein which inputs are selected exclusively according to the smartseeding strategy. Finally, we considered cases with and withoutthe code coverage ﬁtness function. This led to 3×3×3×2×2=
108 different conﬁgurations.
The search budget (in the case of SES-DAQ, the number
of VCDUs inspected when building new inputs during search)might vary from project to project. For this reason, we eval-uated each of the 108 conﬁgurations of the algorithm on ﬁvedifferent search budgets from 50,000 to250,000 VCDUs (in
steps of 50k ).250,000 VCDUs correspond to one fourth of
the transmission ﬁle used for building test inputs. This led to108×5 = 540 different conﬁgurations of the search algorithm.
Because search algorithms have a random component, to
take into account the effects of such randomness on the ﬁnalresults, each of the experiments was repeated ﬁve times with adifferent random seed. This led to a total of 540×5=2 ,700
runs of the algorithm. Because each run could take betweenten and thirty-ﬁve hours, we used a large cluster of computersto run these experiments [21].
C. Cost and Effectiveness Metrics
We want to assess and compare cost-effectiveness among
automatically generated test suites. Code coverage is used
as a measure of test effectiveness as it helps assess howcomplete the test suite is from a structural and functionalstandpoint. We measure the code coverage in terms of thenumber of bytecode instructions covered by the test suiteby using JaCoCo. Maximising code coverage within timeconstraints is often an objective among system testers. Evensmall improvements in coverage can help exercise importantcorner cases. For example, in our case study, additionallycovered instructions often turned out to be critical blocks ofcode including exception handling and critical scenarios. Wealso compare test suites with respect to their size because,given two test suites having identical coverage, one wouldprefer the smaller one, entailing a lower testing and debuggingcost. The size of a test suite is measured in terms of thenumber of test inputs in the test suite. Smaller test suites are ofpractical importance as, in many systems, system testing mustbe performed on actual deployment hardware or a dedicated,realistic testing platform, which requires some degree of tuning
132TABLE III. C OMPARISON BETWEEN THE BEST SEARCH ALGORITHM
CONFIGURA TION AND RANDOM SEARCH .( S EEDING DISABLED .C ODE
COVERAGE FITNESS ENABLED .)
Budget Conﬁguration Coverage # Tests
(Avg/Min/Max ) (Avg/Min/Max)50kBest: r=0.5,m=1,n=100 23424.4 / 23407 / 23448 28.4 /1 9/3 2
BO: r=0.5,m=1,n=100 23424.4 / 23407 / 23448 28.4 /1 9/3 2
Rand: r=1,m=1,n=1 23386.8 / 23341 / 23424 43.2 / 38 / 46100kBest: r=0.5,m=1,n=100 23487.8 / 23461 / 23577 31.6 /2 5/3 5
BO: r=0.5,m=1,n=100 23487.8 / 23461 / 23577 31.6 /2 5/3 5
Rand: r=1,m=1,n=1 23436.8 / 23428 / 23458 52.0 / 50 / 57150kBest: r=0.5,m=1,n=100 23502.0 / 23471 / 23577 34.0 /3 0/3 8
BO: r=0.5,m=1,n=100 23502.0 / 23471 / 23577 34.0 /3 0/3 8
Rand: r=1,m=1,n=1 23453.4 / 23438 / 23480 57.8 / 55 / 64200kBest: r=0.5,m=0.5,n=100 23519.6 / 23464 / 23618 34.6 /2 8/3 8
BO: r=0.5,m=1,n=100 23513.4 / 23476 / 23579 36.0 / 31 / 41
Rand: r=1,m=1,n=1 23465.8 / 23449 / 23490 60.2 / 57 / 66250kBest: r=0.5,m=1,n=10 23538.6 / 23463 / 23631 38.4 / 31 / 43
BO: r=0.5,m=1,n=100 23515.2 / 23480 / 23579 36.4 /3 3/4 0
Rand: r=1,m=1,n=1 23482.6 / 23452 / 23499 62.4 / 60 / 69
or simulation to run test cases. Access time to such platforms
can also be limited.
D. RQ1: How does the search algorithm compare with random
and state-of-the-art approaches?
The effectiveness of a search-based algorithm highly de-
pends on the nature of the problem to solve. For example, ifthe solution space of the problem is ﬂat, that is if the ﬁtnessfunction does not provide any gradient, then a search-basedalgorithm might perform even worse than a random approach.
RQ1 aims to evaluate the usefulness of the search-based
algorithm proposed in this paper by comparing it with arandom algorithm and with a simple model-based algorithm.
However, a direct comparison with a trivial random gener-
ation approach would not bring any useful result. For example,test inputs containing random data may be trivially invalid anduseless for extensively testing the system. For this reason, weuse as baseline for the comparison the random algorithm em-ployed in previous work [8]; the algorithm samples a portion ofthe ﬁeld transmission ﬁle, randomly selects a mutation operatorand applies it to one of the elements where it can be applied.
The algorithm employed in [8] does not support the gen-
eration of test inputs of variable size; furthermore, it does notminimise the generated test suite. To address these limitationsand perform a fairer comparison, we execute an improvedversion of the random algorithm employed in [8] by using oursearch algorithm with a speciﬁc conﬁguration: minSize and
maxSize are set to the same values as the search algorithm;
p
field =1 , to generate a new test input at each iteration
by sampling the ﬁeld data; and pmutation =1 ,t oa l w a y s
mutate the sampled test input like in [8]. The value chosenformaxMutations is irrelevant because we generate a new
test input at each iteration (because of p
field =1 ).
To compare with a simple model-based approach, we
consider the results achieved with the All Possible Targets
(APT) approach proposed in [8]. The APT mutation strategy
ensures that each class or attribute of the data model is mutatedat least once by each of the mutation operators that can beapplied to it.
Table III shows the comparison of the search algorithm
with random search. Columns Budget and Conﬁguration report
the search budget and the best conﬁgurations found, columnCoverage reports the average, minimum and maximum cov-
erage achieved by the test suite, and column # Tests reports
the average, minimum and maximum number of test inputs ineach test suite. For each search budget we identiﬁed the bestconﬁguration out of the 54 conﬁgurations of the search algo-rithm with seeding disabled (Best in Table III). Furthermore,
we identiﬁed the best conﬁguration on average over all thesearch budgets (BO in Table III). The comparison with BO is
fairer since the conﬁguration indicated as BO is not optimised
for a speciﬁc search budget, but is a stable, good overallconﬁguration. For each conﬁguration we report the probabilityof random sampling (r ), the probability of applying mutation
when sampling (m), and the maximum number of allowedmutations in a test (n). The best values for maximum coverageand minimum test suite size appear in bold. Our comparisondid not include conﬁgurations with seeding because it is anoptimisation of the search algorithm. The impact of seeding isaddressed in RQ3.
The search algorithm presented in this paper provides better
results than both the random approach and the APT algorithmpresented in [8]. APT achieves an average coverage of 23283instructions, which is less than the coverage obtained withthe search and random approaches (see Table III). This ismostly because APT focuses on the coverage of the modeland stops after sampling many fewer VCDUs (at most 20,000VCDUs in [8] while the lowest search budget is 50,000).In summary, the search algorithm presented in this papergenerates signiﬁcantly less test inputs while achieving bettercoverage. This mainly results from the adoption of ﬁtnessfunctions that help minimise the test suites by keeping onlyuseful test inputs in the archive.
Results also show that the search algorithm achieves better
coverage than the random approach. The difference in coverageranges between 37.6 and 56 instructions. Though the differencein coverage might not appear large, as discussed earlier, evensmall increases in coverage might exercise important cornercases. Once again, the search algorithm generates signiﬁcantlysmaller numbers of test inputs (e.g. 57.8 versus 34 on averagefor a 150k budget).
Our conclusions hold even considering the random vari-
ation across runs, which is small, as shown by the Min andMax values appearing in Table III.
E. RQ2: How does ﬁtness based on code coverage affect
performance?
To answer RQ2, Table IV shows, for each search budget,
the best conﬁgurations (Best ) with and without code coverage
ﬁtness (Code), with seeding enabled and disabled (Seeding).Furthermore, Table IV also reports the conﬁguration thatperforms better on average over all the search budgets ( BO
in Table IV).
Enabling code coverage ﬁtness results in higher coverage
but it comes, however, at the expense of a signiﬁcantly largertest suite. All conﬁgurations in Table IV with higher coverageenable coverage ﬁtness whereas all the ones with smallertest suites do not. For small search budgets, the differencein coverage when enabling coverage ﬁtness is small, thussuggesting that relying on model information is enough, notrequiring test execution for generating test cases.
F . RQ3: How does smart seeding affect performance?
Table IV shows that smart seeding has a positive effect on
cost-effectiveness when the search budget is above 150k. In
133TABLE IV . C OMPARISONS BETWEEN BEST SEARCH ALGORITHM
CONFIGURA TIONS BASED ON WHETHER CODE COVERAGE IS EMPLOYED IN
THE FITNESS EV ALUA TION (COLUMN ’CODE ’), AND ON WHETHER SMART
SEEDING IS ACTIV A TED (COLUMN ’SEEDING ’).
Budget Code Seeding Conﬁguration Coverage #Tests #Mut.50kFalse 0.0 Best: r=0.5,m=1,n=100 23361.4 17.0 4.8
True 0.0 Best: r=0.5,m=1,n=100 23424.4 28.4 3.6
False 0.5 Best: r=0.5,m=1,n=10 23417.2 21.0 4.0
True 0.5 Best: r=0.5,m=1,n=10 23428.4 34.2 3.2
True 0.5 BO: r=0.3,m=0,n=10 23401.8 27.0 4.3100kFalse 0.0 Best: r=0.3,m=1,n=10 23404.4 16.8 8.2
True 0.0 Best: r=0.5,m=1,n=100 23487.8 31.6 4.9
False 0.5 Best: r=0.5,m=1,n=10 23442.2 21.0 6.4
True 0.5 Best: r=0.3,m=0,n=10 23487.0 33.2 5.6
True 0.5 BO: r=0.3,m=0,n=10 23487.0 33.2 5.6150kFalse 0.0 Best: r=0.8,m=1,n=100 23418.4 28.2 4.0
True 0.0 Best: r=0.5,m=1,n=100 23502.0 34.0 6.0
False 0.5 Best: r=0.5,m=1,n=100 23447.4 23.4 7.5
True 0.5 Best: r=0.3,m=0,n=10 23528.2 35.6 6.5
True 0.5 BO: r=0.3,m=0,n=10 23528.2 35.6 6.5200kFalse 0.0 Best: r=0.8,m=1,n=100 23426.0 28.0 4.7
True 0.0 Best: r=0.5,m=0.5,n=100 23519.6 34.6 6.7
False 0.5 Best: r=0.5,m=1,n=100 23456.0 23.2 9.2
True 0.5 Best: r=0.3,m=0,n=10 23551.0 37.2 7.0
True 0.5 BO: r=0.3,m=0,n=10 23551.0 37.2 7.0250kFalse 0.0 Best: r=0.8,m=1,n=100 23433.2 28.6 5.4
True 0.0 Best: r=0.5,m=1,n=10 23538.6 38.4 7.1
False 0.5 Best: r=0.5,m=1,n=100 23461.8 23.6 10.3
True 0.5 Best: r=0.3,m=0,n=10 23554.4 37.2 7.4
True 0.5 BO: r=0.3,m=0,n=10 23554.4 37.2 7.4
these cases, smart seeding is always part of the conﬁgurations
that achieve the highest coverage or the lowest number of testcases.
G. RQ4: What are the conﬁguration parameters that affect
performance?
For each of the 108 conﬁgurations, we calculated their
average coverage over all the search budgets (thus considering25 test suites for each conﬁguration). We ranked these conﬁg-urations based on their average coverage (not reported in thepaper due to space constraints). A detailed analysis showedthat coverage ﬁtness was enabled in the top 15 conﬁgurations,and never by the worst 15, thus showing its importance toguide the search. The effect of seeding is however much lessvisible as it depends on other parameters.
Different parameters have different effects depending on
the selected search budget. For example, Table IV showsthat, for small search budgets (i.e. search budgets includingat most 100,000 VCDUs) search achieves better results whenmore focused on exploitation (i.e. having a low probabilityof random sampling, like 0.3 and 0.5). Table IV also showsthat with higher search budgets, in the absence of coverageﬁtness or seeding, putting more emphasis on the explorationof the search landscape (i.e. using a 0.8 probability of randomsampling) pays off. This result is expected since, with a highersearch budget, random sampling allows for the sampling ofmuch of the ﬁeld data transmission ﬁle, roughly one fourth.
Further, Table IV shows some interesting side effects.
For search budgets above or equal to 150,000, using eitherseeding or code coverage decreases the need to explore thesearch landscape (probability of random sampling decreasingfrom 0.8 to 0.5). If both are used, even less exploration isneeded (probability of random sampling equal to 0.3). Thisphenomenon can be easily explained for smart seeding, as itdoes provide more diverse and useful samples in the searchTABLE V . S TA TISTICAL COMPARISONS OF BEST OVERALL (BO)
CONFIGURA TION AGAINST BEST WITH NO SEEDING ,BEST WITH NO CODE
COVERAGE FITNESS FUNCTION ,AND RANDOM WITH CODE COVERAGE .
Budget Conﬁguration Coverage ˆA12 p-value50kBO 23401.8 - -
BO no seeding 23424.4 0.32 0.403
BO no code 23417.2 0.40 0.676Rand with code 23386.8 0.64 0.530100kBO 23487.0 - -
BO no seeding 23487.8 0.56 0.835BO no code 23442.2 0.92 0.037Rand with code 23436.8 0.96 0.022150kBO 23528.2 - -
BO no seeding 23502.0 0.68 0.403BO no code 23443.4 1.00 0.012Rand with code 23453.4 0.94 0.027200kBO 23551.0 - -
BO no seeding 23513.4 0.80 0.144BO no code 23448.6 1.00 0.012Rand with code 23465.8 1.00 0.012250kBO 23554.4 - -
BO no seeding 23515.2 0.80 0.144BO no code 23450.4 1.00 0.012Rand with code 23482.6 1.00 0.012
landscape. In the case of code coverage, this phenomenon
occurs because some rare inputs contribute to code coveragebut not to other search objectives. Enabling code coverageﬁtness prevents the algorithm from discarding rare inputs thatcontribute to code coverage once they are found. In the absenceof code coverage ﬁtness, such rare inputs can be easily missedif there is low variety in the test inputs stored in the archive.In the case of higher values of exploration, there is going to behigher variety in the archive, which increases the probabilityof having those rare inputs.
For completeness, Table IV reports also the average number
of mutations per test input (column #Mut.). Although the
presence of multiple mutations (i.e. data faults) in a sameinput may trigger hard-to-detect, complex failures, it couldalso complicate debugging. Table IV shows that on averagethe number of mutations is low compared to the maximumallowed (e.g. 5.4 versus 100 for a budget of 250k), thus makingeventual debugging operations easier
2.
H. RQ5: What conﬁguration should be used in practice?
The best overall conﬁguration (see Table IV) is using
pfield =0.3(small probability of sampling a new test data
at random instead of reusing the ones already in the archive),p
mutation =0 (do not mutate new inputs immediately when
sampled), and maxMutations =1 0 . Furthermore, it does use
seeding and the code coverage ﬁtness function.
For each search budget, we ran experiments only ﬁve times
per conﬁguration, due to the high time cost of running them.On one hand, this is useful to get a general picture of cost-effectiveness trends among different parameter conﬁgurations.On the other hand, it makes it harder to compare two speciﬁcconﬁgurations, as the randomness of the algorithm does in-troduce some degree of noise. Is the best found conﬁgurationreally better than the others? To address this issue, one couldrun more experiments just on a subset of conﬁgurations ofinterest. For example, in our case, we are interested in what is
2To further simplify debugging our implementation keeps track of the list of
mutations applied on each test input and a reference to the mutated element.
134the best overall conﬁguration, how it differs when seeding and
code coverage ﬁtness functions are or are not used, and howit compares with random search. However, even with just ﬁveruns, we obtained statistically signiﬁcant results regarding ourresearch questions, as reported in Table V.
Following the guidelines in [22], we used the Wilcoxon-
Mann-Whitney U-test to check statistical difference quantiﬁedby the V argha-Delaney standardised effect size. For largesearch budgets, code ﬁtness has the strongest effect (e.g. fora 250k budget, BO is statistically signiﬁcantly better than BO
no code, with an effect size of 1.00). Also for large budgets,random yields statistically and practically worse results thansearch (e.g. for a 250k budget, BO is statistically signiﬁcantly
better than Rand with code, with an effect size of 1.00). But
for low budgets, no statistically signiﬁcant results are visible,which can be explained by low statistical power resultingfrom lower effect size (less search) and a small number ofobservations.
X. R
ELA TED WORK
Related work dealing with the automatic generation of
faulty input data for system level testing focuses mostly onmodel-based and mutation testing approaches, while search-based approaches are still in their infancy.
Most model-based testing techniques target the generation
of valid data structures to be used in unit testing [23]–[25]that are typically much simpler than the input ﬁles needed fortesting data processing systems.
Existing model-based techniques like threat modelling
techniques and speciﬁcation mutation testing generate test
inputs that are less complex than those processed by dataprocessing systems. Threat modelling techniques use modelsthat capture the characteristics of typical invalid inputs thatshould be properly handled by the software under test. Modelslike attack trees [26], UML state machines [27], and transitionnets [28], are used to generate sequences of illegal actions,which are not relevant for testing data processing systemswhere the complexity of the testing process lies in the deﬁni-tion of the input data structures. Context free grammars insteadcan generate input data structures [29], [30] but do not allowfor the modelling of relationships among data ﬁelds.
Speciﬁcation-based mutation testing techniques use muta-
tion operators to seed faults into speciﬁcation models (e.g.a state machine) to generate speciﬁcation mutants [31]. Ap-proaches that generate mutated statecharts can only generateinputs that are sequences of system operations [32], whileapproaches that mutate class diagrams have only been used totest model transformation systems in which the state diagramitself is the input [33].
Data mutation approaches use mutation operators to gen-
erate new test inputs from existing ones [34]–[36]. Like ourprevious approach [8], the approaches based on data mutationfocus on a single objective (e.g. covering all the possible datafaults of a fault model) but do not allow for covering themultiple objectives needed to perform effective robustness test-ing. The answer to RQ1 in Section IX shows that the search-
based approach presented in this paper performs better thanapproaches that focus on the coverage of a single objective.
Most of the search-based testing techniques have primarily
focused on unit testing [37] or the testing of non-functionalproperties [11]. Work on search-based robustness testing per-formed at the system level focuses either on the identiﬁcationof performance issues [38], which are out of the scope of thispaper, or functional faults caused by complex sequences of testinputs [39], [40], or by input signals [41], [42].
Ali et al. [39] exploit the information encoded into UML
state machines and aspect-oriented modelling to generate testcases that stress the robustness of a software system by gener-ating complex invocations of function calls. Similarly, Fu andKone [40] use ﬁnite state machines to generate robustness testcases for protocol testing. In contrast with these techniques, wefocus on systems for which it is important to generate complexdata structures; thus, instead of using behavioural models suchas state machines, we rely upon exploit class diagrams.
In the context of embedded systems, metaheuristic search
is used for the generation of input signals satisfying somegiven properties such as requirements on signal shapes [41] ortemporal constraints [42]. Our work is complementary to theseapproaches since it addresses the problem of generating com-plex data structures by innovatively combining metaheuristicsearch and data mutation.
XI. C
ONCLUSION
Building a minimal robustness test suite for data processing
systems, with high fault revealing power, is complicated bymultiple factors: the complex structure of the test inputs thatpresent several constraints among their data ﬁelds, the needfor generating a set of inputs that covers both the functionalspeciﬁcations and the data faults captured by a given faultmodel, and the possibility to have multiple data faults in asame input.
We designed a novel evolutionary algorithm that addresses
these challenges by: generating complex test inputs by meansof data mutation, relying upon model-based and code-based ﬁt-ness functions, and identifying optimal test suites by managingthe tradeoff between the exploration and the exploitation of thesearch landscape thanks to a set of conﬁguration parameters.The ﬁtness functions capture aspects that are relevant forrobustness testing, that is how well each input covers thestructure of the input data, the fault model, the functionalspeciﬁcations, and the structure of the system.
Empirical results obtained by applying our search-based
testing approach to test an industrial data processing systemshow that it outperforms previous approaches based on faultcoverage and random generation: higher code coverage isachieved with smaller test suites.
Furthermore, we show that although a ﬁtness function that
includes code coverage is essential to maximise the coverageof the generated test suite, ﬁtness functions based on modelsalone can achieve good coverage results, while signiﬁcantlyreducing test suite size. This is of practical importance as testgeneration is much quicker and often more practical whenno test execution is required. Finally, we identiﬁed a bestconﬁguration for our search algorithm that returns better resultsregardless of the search budget; this conﬁguration facilitatesthe application of our approach and includes smart seeding,which turns out to be a key feature in improving search results.
A
CKNOWLEDGMENT
Supported by the Fonds National de la Recherche, Luxem-
bourg (FNR/P10/03 and FNR 4082113) and an SES grant. Theauthors would like to thank Raul Gnaga, Vincent Masquelier,and Tomislav Nakic-Alﬁrevic for their valuable feedback andassistance.
135REFERENCES
[1] Yahoo!, “Stock market search engine.” http://ﬁnance.yahoo.com/.
[2] Peopleﬁnders, “People search service.” http://www.peopleﬁnders.com.[3] FlightRadar24, “Flight tracking web service.”
http://www.ﬂightradar24.com.
[4] Google Inc., “Google glasses,” http://www.google.com/glass/start/.[5] http://questvisual.com/, “Wordlens camera translation application,”
http://mashable.com/2010/12/17/word-lens/.
[6] “Systems and software engineering – vocabulary,” ISO/IEC/IEEE
24765:2010(E), pp. 1–418, Dec 2010.
[7] The Register, “Dow Jones average collapses to 0.20.” http://www.
theregister.co.uk/2001/03/19/dow
jones average collapses/.
[8] D. Di Nardo, F. Pastore, and L. Briand, “Generating complex and faulty
test data through model-based mutation analysis,” in 8th International
Conference on Software Testing, V eriﬁcation and V alidation (ICST’15) .
IEEE Computer Society, 2015.
[9] S. Luke, Essentials of Metaheuristics, 2nd ed. Lulu, 2013, available
at http://cs.gmu.edu/∼sean/book/metaheuristics/.
[10] S. Ali, L. Briand, H. Hemmati, and R. Panesar-Walawege, “A systematic
review of the application and empirical investigation of search-based test
case generation,” Software Engineering, IEEE Transactions on, vol. 36,
no. 6, pp. 742–762, Nov 2010.
[11] W. Afzal, R. Torkar, and R. Feldt, “A systematic review of search-based
testing for non-functional system properties,” Information and Software
Technology, vol. 51, no. 6, pp. 957 – 976, 2009. [Online]. Available:http://www.sciencedirect.com/science/article/pii/S0950584908001833
[12] M. Iqbal, A. Arcuri, and L. Briand, “Environment modeling and
simulation for automated testing of soft real-time embedded software,”Software and Systems Modeling, vol. 14, no. 1, pp. 483–524, 2015.[Online]. Available: http://dx.doi.org/10.1007/s10270-013-0328-6
[13] D. Di Nardo, N. Alshahwan, L. Briand, E. Fourneret, T. Naki ´c-Alﬁrevi ´c,
and V . Masquelier, “Model based test validation and oracles for dataacquisition systems,” in Automated Software Engineering (ASE), 2013
IEEE/ACM 28th International Conference on , Nov 2013, pp. 540–550.
[14] The Object Management Group, “The object constraint language,”
http://www.omg.org/spec/OCL/.
[15] Council of the Consultative Committee for Space Data
Systems, “CCSDS 732.0-B-2 AOS space data link protocol,”http://public.ccsds.org/publications/archive/732x0b2c1.pdf, 2006.
[16] G. Fraser and A. Arcuri, “The seed is strong: Seeding strategies in
search-based software testing,” in Software Testing, V eriﬁcation and
V alidation (ICST), 2012 IEEE Fifth International Conference on, April2012, pp. 121–130.
[17] G. T. Parks and I. Miller, “Selective breeding in a multiobjective genetic
algorithm,” in Parallel Problem Solving From NaturePPSN V. Springer
Berlin Heidelberg, 1998.
[18] J. Knowles and D. Corne, “The pareto archived evolution strategy: A
new baseline algorithm for pareto,” in Proceedings of the 1999 Congress
on Evolutionary Computation-CEC99. IEEE Computer Society, 1999.
[19] Mountainminds, “JaCoCo library,” http://www.eclemma.org/jacoco/.
[20] E. Zitzler, M. Laumanns, and L. Thiele, “Spea2: Improving the strength
pareto evolutionary algorithm for multiobjective optimization.” in Pro-
ceedings of EUROGEN 2001 - Evolutionary Methods for Design,
Optimisation and Control with Applications to Industrial Problems,2001.
[21] S. V arrette, P . Bouvry, H. Cartiaux, and F. Georgatos, “Management of
an academic hpc cluster: The ul experience,” in Proc. of the 2014 Intl.
Conf. on High Performance Computing & Simulation (HPCS 2014).Bologna, Italy: IEEE, July 2014, pp. 959–967.
[22] A. Arcuri and L. Briand, “A hitchhiker’s guide to statistical tests for
assessing randomized algorithms in software engineering,” Software
Testing, V eriﬁcation and Reliability, vol. 24, no. 3, pp. 219–250, 2014.
[23] C. Boyapati, S. Khurshid, and D. Marinov, “Korat: Automated testing
based on Java predicates,” in Proceedings of the 2002 ACM SIGSOFT
International Symposium on Software Testing and Analysis, ser. ISSTA’02. New Y ork, NY , USA: ACM, 2002, pp. 123–133.
[24] V . Senni and F. Fioravanti, “Generation of test data structures using
constraint logic programming,” in Proceedings of the 6th InternationalConference on Tests and Proofs, ser. TAP’12. Berlin, Heidelberg:Springer-V erlag, 2012, pp. 115–131.
[25] S. Khurshid and D. Marinov, “TestEra: Speciﬁcation-based testing of
Java programs using SA T,” in Automated Software Engineering, vol. 11,
no. 4. Hingham, MA, USA: Kluwer Academic Publishers, 2004, pp.403–434.
[26] A. Morais, A. Cavalli, and E. Martins, “A model-based attack injection
approach for security validation,” in Proceedings of the 4th International
Conference on Security of Information and Networks, ser. SIN ’11.New Y ork, NY , USA: ACM, 2011, pp. 103–110.
[27] M. Hussein and M. Zulkernine, “UMLintr: A UML proﬁle
for specifying intrusions,” in Proceedings of the 13th Annual
IEEE International Symposium and Workshop on Engineering ofComputer Based Systems , ser. ECBS ’06. Washington, DC, USA:
IEEE Computer Society, 2006, pp. 279–288. [Online]. Available:http://dx.doi.org/10.1109/ECBS.2006.70
[28] D. Xu, M. Tu, M. Sanford, L. Thomas, D. Woodraska, and W. Xu,
“Automated security test generation with formal threat models,” IEEE
Transactions of Dependable and Secure Computing, vol. 9, no. 4, pp.526–539, Jul. 2012.
[29] D. Hoffman, H.-Y . Wang, M. Chang, and D. Ly-Gagnon, “Grammar
based testing of HTML injection vulnerabilities in RSS feeds,” inProceedings of the 2009 Testing: Academic and Industrial Conference -Practice and Research Techniques, ser. TAIC-PART ’09. Washington,DC, USA: IEEE Computer Society, 2009, pp. 105–110.
[30] S. Zelenov and S. Zelenova, “Automated generation of positive and
negative tests for parsers,” vol. 3997, pp. 187–202, 2006.
[31] Y . Jia and M. Harman, “An analysis and survey of the development of
mutation testing,” Software Engineering, IEEE Transactions on, vol. 37,
no. 5, pp. 649–678, Sept 2011.
[32] R. Schlick, W. Herzner, and E. J ¨obstl, “Fault-based generation of
test cases from UML-models: Approach and some experiences,” inProceedings of the 30th International Conference on Computer Safety,Reliability, and Security, ser. SAFECOMP’11. Berlin, Heidelberg:Springer-V erlag, 2011, pp. 270–283.
[33] J.-M. Mottu, B. Baudry, and Y . Le Traon, “Mutation analysis testing for
model transformations,” in Proceedings of the 2nd European Conference
on Model Driven Architecture: F oundations and Applications (ECMDA-F A’06). Berlin, Heidelberg: Springer-V erlag, 2006, pp. 376–390.
[34] L. Shan and H. Zhu, “Generating structurally complex test cases by
data mutation,” Comput. J., vol. 52, no. 5, pp. 571–588, Aug. 2009.
[Online]. Available: http://dx.doi.org/10.1093/comjnl/bxm043
[35] A. Bertolino, S. Daoudagh, F. Lonetti, E. Marchetti, F. Martinelli, and
P . Mori, “Testing of PolPA-based usage control systems,” Software
Quality Journal, vol. 22, no. 2, pp. 241–271, 2014.
[36] M. De Jonge and E. Visser, “Automated evaluation of syntax error
recovery,” in Proceedings of the 27th IEEE/ACM International Con-
ference on Automated Software Engineering, ser. ASE 2012. NewY ork, NY , USA: ACM, 2012, pp. 322–325.
[37] P . McMinn, “Search-based software test data generation: a survey,”
Software Testing, V eriﬁcation and Reliability, vol. 14, no. 2, pp.105–156, 2004. [Online]. Available: http://dx.doi.org/10.1002/stvr.294
[38] L. Briand, Y . Labiche, and M. Shousha, “Using genetic algorithms
for early schedulability analysis and stress testing in real-timesystems,” Genetic Programming and Evolvable Machines, vol. 7,
no. 2, pp. 145–170, 2006. [Online]. Available: http://dx.doi.org/10.1007/s10710-006-9003-9
[39] S. Ali, L. C. Briand, and H. Hemmati, “Modeling robustness behavior
using aspect-oriented modeling to support robustness testing of indus-trial systems,” Software and Systems Modeling, vol. 11, no. 4, pp. 633–
670, 2012.
[40] Y . Fu and O. Kone, “Security and robustness by protocol testing,”
Systems Journal, vol. 8, no. 3, pp. 699–707, 2014.
[41] A. Baresel, H. Pohlheim, and S. Sadeghipour, “Structural and functional
sequence test of dynamic and state-based software with evolutionaryalgorithms,” in Genetic and Evolutionary Computation ? GECCO
2003, ser. Lecture Notes in Computer Science. Springer BerlinHeidelberg, 2003, vol. 2724, pp. 2428–2441. [Online]. Available:http://dx.doi.org/10.1007/3-540-45110-2
147
136[42] B. Wilmes and A. Windisch, “Considering signal constraints in search-
based testing of continuous systems,” in Software Testing, V eriﬁcation,
and V alidation Workshops (ICSTW), 2010 Third International Confer-
ence on, April 2010, pp. 202–211.
137