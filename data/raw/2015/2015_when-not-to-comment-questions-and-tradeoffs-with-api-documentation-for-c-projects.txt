When Not to Comment
Questionsand Tradeoffs with API Documentation for C++ Projects
Andrew Head∗
UC Berkeley
andrewhead@berkeley.eduCaitlin Sadowski
Google, Inc.
supertri@google.comEmersonMurphy-Hill∗
NC State University
emerson@csc.ncsu.eduAndrea Knight
Google, Inc.
aknight@google.com
ABSTRACT
Without usable and accurate documentation of how to use an API,
developerscanfindthemselvesdeterredfromreusingrelevantcode.
InC++,oneplacedeveloperscanfinddocumentationisinaheader
file.Wheninformationismissing,theymaylookatthecorrespond-
ing implementation code. To understand what’s missing from C++
APIdocumentationandthefactorsinfluencingwhetheritwillbe
fixed, we conducted a mixed-methods study involving two experi-
encesamplingsurveyswithhundredsofdevelopersatthemoment
theyvisitedimplementationcode,interviewswith18ofthosede-
velopers, and interviews with 8 API maintainers. In many cases,
updating documentation may provide only limited value for devel-
opers, while requiring effort maintainers don’t want to invest. We
identify a set of questions maintainers and tool developers should
considerwhen improving API-level documentation.
ACM Reference Format:
AndrewHead,CaitlinSadowski,EmersonMurphy-Hill,andAndreaKnight.
2018. When Not to Comment. In Proceedings of ICSE ’18: 40th International
Conference on Software Engineering , Gothenburg, Sweden, May 27-June 3,
2018(ICSE’18), 11 pages.
https://doi.org/10.1145/3180155.3180176
1 INTRODUCTION
Seeking information is a substantial part of day-to-day program-
ming work. Both professional [ 32] and hobbyist [ 5] developers
frequently search for code examples. For routine coding, debug-
ging,andmaintenancetasks,developersspendalargeportionof
thetimenavigatingandsearchingexistingcode[ 14,25].Developers
report that understanding existing code is one of the most time-
consuming parts of software development, and that understanding
the rationale behind code is a serious challenge [16].
Developerssometimesfindthatmissingorinsufficientdocumen-
tation can block them from using an API [ 29,30,38]. At Google,
274 of 601 surveyed developers reported that they encountered
“Missing/poordocumentationforanAPI”theirprojectdepended
on in the last 6 months. In the words of one of the interviewees
in our study, missing information is a “standard fact of life.” While
the literature demonstrates documentation is often incorrect ormissing, it remains unclear what information is missing, what it
∗AuthorsdidthisresearchwhileanInternandVisitingScientistatGoogle,repectively.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5638-1/18/05.
https://doi.org/10.1145/3180155.3180176would take for maintainers to add or update this information, and
whetherimp roveddocumentationwouldhelpdevelopersintypical
situations where documentation is insufficient.
In this paper, we report the results of a mixed-methods study of
what developers are looking for when they leave an API specifica-
tion to look at implementation code, and maintainers’ perspectives
aboutupdatingdocumentationtoanswerthesedevelopers’ques-
tions. To make this study feasible, we focus on C++ APIs where
developerscouldeasilysearchboththeAPIspecificationandimple-
mentation code, a typical context for professional and open source
development. We instrumented Google’s internal code search tool
with an in-situ survey to find out what questions developers were
askingwhentheynavigatedfroma .h“header”filecontainingAPI
declarations,toacorresponding .cc“implementation”filecontain-
ing API definitions. We interviewed developers who made these
transitions.Withstoriesandquestionsfromthesedevelopers,we
interviewedmaintainersfortheseandotherAPIstoseewhether
they thought the questions represented missing documentation,
and whether they would update the documentation.
Concretely,thefindingsfromthisstudywereasfollows.First,
a minority (between around 5–25%) of visits to implementation
files were to learn about API usage. Some visits were for questions
that possibly should have been answered in the documentation
(inputvalues,returnvalues).Othervisitswereforquestionsthat
aren’toftenansweredinlow-leveldocumentation(hiddencontracts,
implementationdetails, sideeffects).
Second,respondentsfrequentlyreportedthatitwouldhavebeen
most convenient to find answers to these questions in header files,
insteadofimplementationcodeordocumentsonourMarkdown
server. This was the case even for some questions typically left out
of API-level documentation. However, developers we interviewed
sometimespreferredtofindanswersinimplementationcode,which
could be more accurate and quick enough to read.
Finally, maintainers were reluctant to answer searchers’ ques-
tions for several reasons, falling into themes of it not being the
right timeto document, and keeping explanations minimal.
Themaincontributionsofthispaperare:1)asetofquestionsthat
developersareseekingtoansweraboutC++APIswhenviewing
implementation files, and 2) trade-offs for maintainers to consider
when updating documentation to answer searchers’ questions. At
Google, developersand technical writersinvest effort inchoosing
and organizing content to document APIs and tools, and they need
to decide how to prioritize that effort. Software engineering re-
searchersaredevelopingtoolstomineAPIinformationandserveit
in helpful places (e.g., [ 24,37]). We believe our study helps inform
what information should be surfaced, and the software develop-
ment context that would determine the acceptance and value of
tools and strategies to improve API documentation.
"$.*&&&UI*OUFSOBUJPOBM$POGFSFODFPO4PGUXBSF&OHJOFF SJOH
This work is licensed under a Creative Commons
Attribution-NonCommercial-NoDerivs International 4.0 License.
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden Andrew Head, Caitlin Sadowski, Emerson Murphy-Hill, and Andrea Knight
2 RELATED WORK
2.1 How Developers Reference Documentation
Theliteraturesuggeststhatdevelopersfaceanumberofchallenges
whenlookingforinformationinAPIdocumentation.Frominter-
views with developers, Lethbridge et al. reported that documen-
tationcanbeout-of-date,poorlywritten,andsomesystemsmay
have too much of it [ 17]. In a survey of professional developers,
Robillard found that inadequate learning resources were a com-mon obstacle for learning about APIs [
29]. Robillard and DeLine
interviewed and surveyed developers about learning obstacles, rec-
ommendingthatcommonobstaclescouldbeavoidediftheintent
ofanAPIisdocumented,codeexamplescovernon-trivialusecases
andbestpractices,anddocumentationhelpsdevelopersfindAPI
elementsfortheirtasks,understandrelevantpartsofAPIs’internal
behavior, and avoids fragmentation [ 30]. In another survey, Uddin
and Robillard found that developers were more likely to report
incompleteness, ambiguity, and incorrectness of documentation as
“blockers” or “severe” issues than other documentation issues [ 38].
Priorstudiesindicatethattheperceivedandactualutilityofcom-
mentsvariesbased on where they appear and who is reading them.
Roehm et al. observed that most professional developers in theirstudy reported getting their main information from source code
andinlinecommentsratherthandocumentation,asdocumentation
could be sparse or inaccurate [ 31]. Salviulo et al. found that young
professionaldevelopers,comparedtostudentprogrammers,were
less likely to consult comments during in-lab code comprehension
tasks [33]. Borstler et al. showed that although source code with
“good” comments was reported as more readable, these comments
didn’t appear to impact actual comprehension [4].
Inrelationtothesepastfindingsaboutdocumentation,thisstudy
providesaperspectiveonwhatinformationmaybemissingfrom
low-levelAPIdocumentation,andanunderstandingofcostsand
benefits of improving missing documentation in header files.
2.2 Information Foraging in Code
Software engineering is an information intensive task, requiringdevelopers to gather information from peers, code, design docu-
mentation,andmore[ 16].Recently,informationforagingtheory
hasbeenusedtodescribehowsoftwaredeveloperssearchforin-
formation,andtradeoffsindesigningsoftwareengineeringtools
(see[11]foraprimer).Ininformationforaging,adevelopersearches
to satisfy a goal(e.g., a piece of code with desired functionality).
Theylocateinformation patchestoinspectforfeaturessatisfying
theirgoal,called prey.Developersmakechoicestomaximizethe
valueofinformationtheyfind,andminimizethecostofnavigation.
Tochoosewheretolook,developersestimatetheexpectedvalueof
information withina patch, andthe costof finding it.When there
is a mismatch between the expected and actual costs and values, a
developer could benefit from a better strategy or tools. For sometasks, foraging consistently delivers less value than expected: in
one study, as many as 50% of navigation choices yielded less value
than expected, and 40% cost more than expected [25].
Thesoftwareengineeringresearchcommunityhaselicitedmany
informationgoalsasconcretequestionsdevelopersaskastheywrite
and maintain code. Sillito et al. describe 44 such questions arising
duringsoftwarechangetasks,whichbelongedtofourcategories:finding initial focus points, building on these points, building amodel connecting found information, and integrating an under-
standingacrosssuchmodels[ 34].Sadowskietal.observeddevelop-
ers’ queries to a code search tool, grouping them into questions ofhow to do something, what code does, why it is behaving the way
it is, finding where something is, who did something, and when
theydidit[ 32].Duala-EkokoandRobillarddescribe20questions
developers askabout APIs, basedon talk-aloud dataof developers
performing in-lab coding tasks [10].
Developers adapt their foraging strategies to their goals. In one
study,developersinspectedcodemorewhencollectingdetailsabout
types,and searchedcode moretofindinitiallocationsrelevantto
theirdebuggingtask[ 26].Fromaforagingperspective,ourstudy
seekstocharacterizeaspecificforagingstrategy:lookingforAPI
usageinformationinimplementationcode.Wereportasetofinfor-
mationgoalsdevelopershavewhentheylookatimplementation
codeforanAPI,anddescribefactorsinfluencingthecostandvalue
of finding answers to API usage information in code vs. documen-
tation in a real-world software development setting.
2.3 Choosing What to Document
When considering how maintainers decide what to document, we
buildonpriorstudiesofwritingbothunofficialandofficialdocu-
mentation.Parninetal.interviewedprogrammingbloggers,finding
thattheyfacechallengeskeepingupwithcommunitycontributions
andpreparingexamples[ 23].DagenaisandRobillardspokewith
contributors to open source projects, finding that maintainers’ mo-
tivationtowriteandmaintaindocumentationcouldbelow,though
maintainers may update documentation in response to commu-
nity contributions [ 8]. Our study can be seen as providing context
about the choices maintainers make when writing and considering
making updates to low-level documentation.
MaalejandRobillarddescribedtwelvetypesofknowledgeinref-
erence documentation, including purpose and usage examples [ 18].
Padioleau et al. observed what code comments describe by classify-
inghundredsofcomments:52.6%wentbeyondexplainingthecode,
to describe types, relationships between code entities, aspects of
code evolution, synchronization, and more [ 22]. In relation to this
work, our study provides some examples of questions that were
not answered in API-level comments.
Recent research has proposed tools for automatically improv-
ing documentation. Such tools synthesize code examples [ 6,21],
generate method [ 19,35] and parameter descriptions [ 36], mine
API usage patterns (e.g., [ 20,40]), collect insightful sentences de-
scribingAPIs[ 37],andidentifyimprovabledocumentation[ 39,41].
Researchers have extended development environments to revealimportant usage information [
9] and integrate online documen-
tation [27] and web search history [ 12]. This study provides an
understanding of developer questions and perspectives on docu-
mentationthatwehopecanhelpmotivatethedesignofsuchtools.
3 METHODS
3.1 Overview of Mixed Methods
Weusedamixed-methodsapproachtounderstandwhatdevelopers
are looking for in implementation code and whether more infor-
mationshouldbeaddedtodocumentation.ThroughCodeSearch

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. 
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden Andrew Head, Caitlin Sadowski, Emerson Murphy-Hill, and Andrea Knight
#include  "display.h"  
int main(void) { 
  displayNumber( 1); 
}/**  * Display number to the  * console. Returns 0 if  * successful. No runtime  * guarantees.  */ int displayNumber( int number);
Client's codeHeader (in display.h ) Implementation (in display.cc )
int displayNumber( int number) { 
  if (number == -1) 
    throw "Invalid arguments!" ; 
  /* Some complex logic ... */  
  printf("%d\n", number); 
  return 0; 
}
The client can reference the header for API 
declarations and usage info....
Though the behavior of the API will be 
encoded in the implementation.
Figure2:Writingdocsin .handimplementationin .ccfiles.
For C++ APIs, the member declarations and actual implementation
are often split between two distinct files, as shown in this toy
example. Clients may have to reference both to understand both
an API’s intended usage andits actual behavior.
3.4 Searcher Interviews
We conducted interviews with 18 developers, whom we refer to
as“searchers”(S1...S18),tolearnwhatdeveloperslookforwhen
they leave header files to visit implementation files. We invited
subscribersofaninternalC++developersmailinglisttoagreeto
participate in a 15-minute interview if warranted based on log
analysis. 62 developers opted in.
Twice a day, we ran a script to identify developers in our opt-in
list who had made a transition from a .hfile to the corresponding
.ccfile.ToincreasethelikelihoodofrevealingmissingAPIusability
information,weonlyconsideredtransitionsfromfilesthathadvisits
from 10 or more distinct developers in the last six months.1We
then reached out to the developer to arrange an interview. Mostinterviews took place on the same day as the searcher had made
the transitionfrom the .hfile to the .ccfile.2
We held a semi-structured interviews with each developer (API
Searcher Questions in the online appendix [ 1]). One author con-
ductedallinterviews.First,weremindedthedeveloperwhat .hfile
they left to visit implementation code, and asked them to describe
what they were looking for in the .hfile, and why they visited
the.ccfile. Developers then described their process of looking
for information in the implementation code, including files they
visited, methods they inspected, and the answer they found.
Ifthedeveloperwaslookingforinformationina .ccfileforhow
to use an API, we asked them where it would be most convenient
to find this information. With any time remaining, we asked the
developeraboutoneoftwotopics.Thefirsttopicwastorecallrecentexperiencesofinformationmissingfrom
.hfiles,orofreadingwell-
maintained .hfiles. The second topic was having them describe
theirteam’sprocessfordecidinghowtodocumenttheircode,so
wecouldgathercontextabouthowAPIdocumentationwaswritten
and maintained at Google.
1With one exception: for one interview (S12), the header had no views in the past.
2Oneinterviewwasheld2daysafterthesearcherhadmadethetransitionfromheader
to implementation, and four were held 1 day after the transition.Survey N Questions
API
Usage
Survey1,147•Q1:Whatbestdescribestheinformation
you are looking for?
•Q2:Whatwouldbethemostconvenient
location for this information?
•Q3: What question are you trying to
answer about this API? e.g., how this
APIbehaveswhenpassingindatesthat
are in the past
•Q4: What “.cc” files are you looking at?
Implemented
Behavior
Survey778Q1 from “API Usage Survey” and:
•Why are you looking into how a behav-
iorwas implemented?
•Youselected“Noneoftheabove”.Please
describewhatyouaretryingtofindout
by looking at the implementation.
Table 1: Experience sampling surveys to collect developers’
questionsfor implementationcode. We ran two main surveys
to ask developers to describe the questions they had about code as
they left header files to inspect implementation files.
Theinterviewer didlive transcriptionwhile interviewingeach
participant. To validate these transcripts, we recorded audio for
all butthree participants.3For each of the interviews where audio
was recorded, the notes were replaced with a transcript of the full
session audio. We observed that the difference between the live
transcriptionand the audio was minimal.
Threatstovalidity: DeveloperswhooptedintotheSearcherIn-
terviewsmaynotberepresentativeof alldevelopers,atGoogleor
other institutions. Many interviewees had strong opinions, which
representedadiversityofviewpoints;there’sachancethatsome
perspectives on the experience of finding answers in code vs. docu-
mentationwerenotrepresentedinthissample.Furthermore,the
interviewswereaimedatfindinganti-patternsindocumentation;
therearemanybenefitsofgettinginformationfromdocumentation
that are not reported in our results.
3.5 Code Search Experience Sampling
We instrumented the web-based Code Search tool so that an ex-
perience sampling survey would pop-up whenever a developer
navigatedfroma .hfiletoa .ccfileinthesamedirectorywiththe
same name. Either one of our surveys appeared in the lower-right
corneroftheCodeSearchapp(Figure1),andcouldbeclosedifa
developer did not want to answer the questions.
Theaimofoursurveyswastounderstandwhatquestionsdevel-
opersaskwhentheyvisitimplementationcodetolearnaboutAPIs,
at the moment they left a header file. We launched two variants
of the same survey, each designed to collect information about
a different type of API question: the API Usage andImplemented
Behavior Surveys.Eachsurveyhadhundredsofrespondents.The
design of the two surveys is summarized in Table 1.
3Due to technical issues, audio for S1, S2, and S9 is missing.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. When Not to Comment ICSE’18, May 27-June3, 2018, Gothenburg, Sweden
TheAPIUsageSurvey wasdesignedtoelicitthetypesofques-
tions developers asked when visiting implementation code. We
asked developers to choose one of seven reasons that best matched
why they opened the implementation code. These reasons were
chosen based on prior work [10, 32] and the Searcher Interviews:
(1) Whatbest describes the information you are looking for?
•How to use this API (common cases)
•How to use this API (special cases)
•Who has been working on this code
•Where I can make a change to the code
•Performance/ non-functional API details
•How a behavior was implemented
•Noneof the above
If a respondent selected one of the first two answers, indicating
that they were interested in learning about how to use the API, we
asked themwhere itwould havebeen mostconvenient tofind an
answer to their question. Participants could choose from one of
three options—a .hfile, a .ccfile, and the project’s g3doc. We also
asked what question developers were trying to answer in this case.
(2)What would be the most convenient location for this infor-
mation?
(3)What question are you trying to answer about this API? e.g.
how this API behaves when passing in dates that are in the
past
(4) What .ccfile are you looking at?
The survey also asked respondents to enter the path of the ‘ .cc’
file, since the survey tool could not collect this information.
Wepilotedthesequestionswith246responses.Inthepilot,we
asked Q2 regardless of which options were selected for Q1. In addi-
tion,thepilotrunoftheAPISurveyincludedthequestion,“Where
would you expect to find this type of information?” with the same
options. However, we dropped this question since the responses
were essentially the same as answers to Q2. When piloting we
useddifferentwordingforQ3:“Whatinformationareyoutryingtogatherbyviewingthis‘
.cc’file?”,butreceivedtoomanyresponses
reporting “implementation details”.
TheAPIUsageSurvey wasdeployedoveraperiodof3workdays.
Afteradevelopercompletedthesurveyonce,itwouldnotbeshown
tothemagainuntilatleast5hourshadpassed.Thesurveyreceived
atotalof1,147responses(outofwhatweexpectwasabout8,000
total prompts). 60 respondents were looking for information about
APIusage.54ofthese60completedallfourquestionsinthesurvey;
all 54 were looking at different source code files.
TheImplemented Behavior Survey was designed to answer ques-
tions raised internally about what exactly respondents meant by
“How a behavior was implemented”, a response that a majority
of respondents selected in the API Usage Survey. Using the first
questionfromtheAPIUsageSurvey,wescreenedrespondentsto
just those asking a question about implemented behavior. Then we
asked two additional questions:
(2)Whyareyoulookingintohowabehaviorwasimplemented?
•Understandingunexpected code behavior
•Finding code or logic to reuse
•Planning a code refactoring
•Checkingspecific values (e.g. path name)
•Checkingstyle or best practices•None of the above
(3)(If “None of the above” selected). You selected “None of the
above”. Please describe what you are trying to find out by
looking at the implementation:
TheImplementedBehaviorSurvey wasdeployedoveraperiodof
2 workdays. After a developer completed the survey once, it wouldnot be shown to them again until at least 36 hours had passed. The
surveyreceived625responses.325respondentswerelookingfor
how a behavior was implemented.
Threatstovalidity: IntheAPIUsageSurvey,somerespondents
maynothavebeenlookingfor informationabouttheAPIdefined
in the .hfile, but rather to understand how to use an API called
fromtheimplementationcode.Thispossibilityismorelikelyfor
sometypes of API questions than others — for example, questions
about input types were likely about the API in the .h file. As
we discuss in the results, question order could have also biased the
responses so that we underestimate the percentage of questions
that are about API usage patterns in the API Usage Survey.
3.6 Maintainer Interviews
We interviewed the maintainers for a handful of internal APIs
(M1...M8)tounderstandthemaintainers’processandrationalefor
writingand updating API documentation.
M1–M5 were maintainers of header files participants in the
Searcher Interviews reported as missing API usage information. It
wasn’t always straightforward to find an active and relevant main-
tainer for a file. In two cases, the person we initially contacted was
arecentcontributortothefile,butmadeonlyahandfulofcontri-
butions, and the document’s original authors or main contributors
hadleft thecompany or were out of the office.
M6 and M7 contributed to files containing API functions that
Code Search users click extremely frequently. We interpreted a
large number of clicks on a function as an indication that some
information about the method was missing. Before contacting the
maintainers,weinspectedtheheadersandverifiedthatsomeim-
portant information was likely missing from the comments.
M8 was a maintainer of a widely-used internal API, updating
the documentation as part of an open sourcing effort.
One interviewer conducted all eight interviews (see "Questions:
API Maintainer" [ 1]). For M1–M5, we described questions that
searchershadabouttheAPI,askedwhetherthequestionwasan-
sweredintheheader,andifitwasnot,whetheritshouldbe,and
wheretheanswershouldappear.Wealsoaskediftheyweresur-
prisedthatadeveloperwasusingtheirAPIinthisway.Allmain-
tainers(M1–M8)wereaskedtodescribetheirprocessofdeciding
whatgoes intotheproject’sdocumentation. Theinterviewertook
notesduringeachinterviewandtranscribedtheaudiorecording
from each one. Interviews typically lasted 20–30 minutes.
Threatstovalidity: AswiththeSearcherInterviews,maintainers
who opted to answer questions about their process could have sys-
tematically stronger or different opinions about what belongs in
documentation than those who did not opt in; these results should
be seen as representing an important but perhaps not comprehen-
sive set of maintainer perspectives.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. 
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. When Notto Comment ICSE’18, May27-June 3, 2018, Gothenburg, Sweden
API Usage Question SampleResponses .h .cc g3doc N
Input Values“How a given argument behaves when it’s empty”
“What does the arguments mean exactly”“I’m trying to figure out how the flags are used”92 2
13
HowDoI...? “What method to use to convert the current timestamp into a string” 62 1 9
Return Values “What does the return value mean and how can this method fail” 71 0 8
Recommended Use“Sampleuse cases of this API”
“How to properly update deprecated functions to use this API”32 2 7
Hidden Contracts “IfI need to do a special tear-down in order not to leak memory” 31 2 6
ImplementationDetails “How this API passes data to TensorFlow session run calls in C” 32 0 5
Side Effects “What logs it writes or status messages it returns when it finishes reading the file” 21 0 3
ExtensionPoints “WhetherI should need to override this method in my subclass” 11 0 2
Verify Inconsistency“Why the service in the proto says one thing but the code does something else, and if
I can file a fix to correct that”01 0 1
Total 34 13 7 54
Table 2: Nine API usage questions developers asked when looking up implementation code, and where they wanted to find
theanswers. Foreachquestion,wereporthowmanyrespondenthadthatquestion( N),andhowmanythoughtitwouldbemostconvenient
to find an answer in a header file ( .h), implementation code ( .cc), or the projects g3doc ( g3doc). Respondents often reported it would be most
convenient to find answers in .hfiles, even for implementation-specific questions like those about hidden contracts and side effects.
run calls in C”), and side effects (“what logs it writes or status mes-
sagesitreturnswhenitfinishesreadingthefiles”).Respondentsstill
sometimes thought it would be most convenient to find answers to
such questions in headers.
4.2.3 Questions about How a Behavior Is Implemented. In the
Implemented Behavior Survey, when respondents were looking for
information about how a behavior was implemented, the majority
of respondents were “finding code or logic to reuse” (30.4%) or “un-
derstandingunexpectedcodebehavior”(31.7%).Whileitisexpected
thatdevelopersneedtoconsultimplementationcodewhenlooking
for code to reuse, perhaps some unexpected code behaviors should
have been documented in these headers.
4.3 Seeking Answers in Code vs.
Documentation
Survey respondents frequently reported it would be most conve-
nienttofindanswersquestionsaboutAPIusageinheaders.How-
ever, developers we interviewed in the Searcher Interviews indi-
cated they sometimes preferred to find answers in implementation
code, which could be more accurate and quick enough to read.
4.3.1 ConvenientLocationstoFindAnswers. IntheAPIUsage
Survey, 61.7% of the 60 respondents looking for API usage infor-
mation believed that the information they were looking for would
have been most convenient to find in a .h file. This included
66.7%ofrespondentslookingforinformationaboutcommonusage,
and 52.4% looking for information about special case usage. Of the
six interviewees in the Searcher Interviews looking for API usage
information,fourreportedthatitwouldhavebeenconvenienttofind that information in a header file. Survey respondents were
morelikelytowanttofindanswersin .hfilesforAPI-relatedques-
tionsthanotherquestions:whenpilotingtheAPIUsageSurveywe
asked all respondents (not just respondents looking for API usage
information)wheretheywantedtofindtheanswertotheirques-
tion. Only 14.2% of the 183 pilot respondents that weren’t looking
for API usage information thought the header file would be the
most convenient place to find the answer to their question.
However, header files weren’t always reported as the most con-
venientplacetofindanswersaboutAPIs.Foreachtypeofquestion,
at least one developer always thought it would be most convenienttofindananswerinimplementationcodeorg3doc.Theproportion
of respondents who preferred each location varied somewhat by
question(seetherightmostcolumnsofTable2).Forexample,inline
with our expectations that questions about discovering functional-
ityandrecommendedusagebelonginhigh-leveldocumentation,
g3doc was a preferred medium for some of these questions.
4.3.2 Rationale for Seeking Answers in Code vs. Documentation.
Thepotentialbenefitsdeveloperscouldhavereapedfromimproved
commentsvariedbasedonthecodethatthedeveloperwaslooking
at and the question they had. We distilled a set of themes from the
SearcherInterviewsdescribingwhysomedevelopersexpectedor
preferredtofindinformationaboutAPIsinimplementationcode
as compared with comments in a header file (Figure 4).
Correctness and Completeness. Because it is “what the computer
will execute” (S4), developers could count on source code as an
accurate representation of that code’s behavior. Some interviewees
distrusted code comments in general. In the words of S2, “to a first
orderapproximation,Ihavestoppedreadingcomments,because

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May27-June 3, 2018, Gothenburg, Sweden Andrew Head, Caitlin Sadowski, Emerson Murphy-Hill, and Andrea Knight
Pros for Referencing Code
•Sometimes quick to read 
•Always "accurate" 
•All accessible from Code Search 
•Oers implementation choices 
hidden by public API•Answers can be in a di erent )le 
than where you expect it 
•Sometimes complicated to 
comprehend 
•Generated code will be very 
dicult to understandCons for Referencing Code
Pros for Referencing Docs
•Typically of good enough quality 
for popular internal APIs 
•Handy for understanding 
recommended usageCons for Referencing Docs
•Can be inaccurate, 
untrustworthy, or missing 
•Fragmented, i.e. across .h )les, 
g3doc, external sites
Figure4:Whylookatimplementationcodevs.headercom-
ments?DevelopersintheSearcherInterviewsdescribedwhenthey
would look for answers to API usage questions in API documenta-
tion or implementation code.
thecommentsarejustlies.Myeyeshavejustlearnedtoskipthem.”
It was clearwhy some developers’ experiencescould lead them to
distrustdocumentation:oneoftherespondentstotheAPIUsage
Survey reported that they were visiting the implementation to
clarify an inconsistency between documentation and behavior.
However, incorrect or incomplete documentation wasn’t univer-
sal.Severalintervieweesmade adistinctionbetweenwidely-used
internalAPIs,andprojectswrittenbyteammatesandcollaborators:
“So there’s those sorts of [general utilities], and those tend to be
verywelldocumented.Andthenthere’stheteam-specificinternal
code, which is all very horribly documented. And it’s relatively
rare for me to find something where I don’t personally know the
person who wrote it but it’s also missing documentation”— S16
Distrustofdocumentationcouldleadtounnecessarysearches:
S6 visited the implementation to check for unexpected behavior
when “it was actually documented properly, but I didn’t believe it.”
Intendedvs.actualfunctionality. Sourcecodecanrevealundoc-
umentedbehaviorthatcanbeusefulforprototyping.S10studied
howcode“actuallyworks”whiledevelopinginitial“messycode”.
Oncetheyfiguredout“howtomakeitwork”,thentheytried“to
make it clean before I send it off for review” by adjusting the code
to respect how the API was documented to work.
Cost of finding information. Sometimes, a developer could get
ananswertoaquestionaboutanAPIprettyquicklybyjustread-
ing code. For S1 and S14, this only involved looking through a
fewdozenlinesofcodeoverafewmethods.Toolingalsoplaysa
role in reducing the cost of code navigation: with the Code Search
tool, much of the code is indexed in one place, with clickable cross-
references between types and functions. Because of this, it may be
morestraightforwardtonavigatecodethanlookingfordocumenta-
tion, which could be fragmented across multiple web locations and
breakone’s “flowofthought” (S4).However, sometimesitwasin-
feasibletogleanananswertoanAPIusagequestionfromthecode.
S9 and S11 searched through multiple functions in multiple files.
S9eventuallygaveupbecausethecodebecametoocomplicated.In
thesecases,awell-writtencommentintherightplacecouldhaveTheme Examples
Minimal
explanations• No need to explain readable signatures•
Readersmayhavesufficientprior knowledge
• Adding details could clutter the docs
Nottheright
time• Never maintained, won’t be maintained
• Concentrating on evolving or fixing the code•
Good enough documentation already exists
for similarexternal projects
Preservation• Should preserve existing comment style• Writing comments that are unlikely to rot
Table 3: Why (not) update documentation? Themes and sam-
ples of these themes of why and how maintainers might choose to
update the documentation for their APIs.
saved time. There are also some types of code, like generated code,
whichwill alwaysbe difficult to read (S5).
4.4 Factors Impacting Whether Maintainers
Will Update Comments
WhenpresentedwithquestionssearchersaskedabouttheirAPIs,
most maintainers weren’t surprised that searchers were asking
such questions. However, maintainers were sometimes reluctant
to updateAPI commentsto answerthese questions.Reluctance to
createandupdatedocumentationhasbeenobservedinthelitera-
ture[8].Theseinterviewsprovidecontextbehindwhyproposing
andincorporatingupdatestoAPI-levelcommentscouldbedifficult.
We developed three themes (Table 3) from analyzing Maintainer
interview transcripts, and also report on the factors influencing
past choicesto change and add to documentation.
4.4.1 Keeping Explanations Minimal. This fundamental tension
wasdescribedbyM1whotoldus,whenaskediftheyshouldadd
a comment to answer S9’s question, “How often do you want to
go into details, which can be easily too much?” M8 was just as
interestedinfindingoutiftheirAPIhad toomuchdocumentation
as whether the comments had the right content.
Maintainersassumedthatsometimes,APIclientscaninferusage
protocolfromanAPI’sdeclaration.M8describedhowthesemantics
of a function could be inferred for an API for formatting time:
“Sojustfromlookingatthat[signature]rightthere,Ibelievemost
callers would infer that it takes three arguments, a time and a
time zone, and it takes some format that tells it how to format
thetime, and it returns the value as a string.”—M 8
However, it is clear is that in practice not all methods in the
Googlecodebaseareself-explanatory.M8alsodescribedapopu-
larAPImethod,writtenasacomplextemplateinC++toreplace
dozens of other methods with related functionality but distinct sig-
natures. M8 stressed the importance of comments for this method,
suggesting thatit couldtake someonehalf anhour tounderstand
the code without documentation.
For one maintainer, explicit functionality marked the boundary
between what deserved to be described in comments and what

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. When Notto Comment ICSE’18, May27-June 3, 2018, Gothenburg, Sweden
didn’t. M2 quoted Knuth’s programming aphorism, “Premature op-
timizationistherootofallevil”[ 13],todescribehowadeveloper’s
main concern when using an API will be with writing code that
does the right thing, rather than non-functional aspects like per-
formancecharacteristics.Forsuchnon-functionalaspects,clients
shouldalreadyhavetherequisitebackgroundknowledgetosuccess-
fullyselectandusetheAPI.M2expectedclientsofaconcurrency
API to understand in what contexts they should use threads vs.
futures. M5 did not believe it was relevant to describe the runtime
of standard algorithms or data structures like maps.
Takentoanextreme,thecontentsofcommentscouldindicate
who shouldbe usingthe API.M2 worried thatif high-level guid-
ance like performance characteristics of threads and futures was
available,somedevelopersmightmisinterpretthisinformation,and
be compelled to use it incorrectly or not at all:
“It’sstillgoingtohavepeoplethatarenotexpertstryingtofol-
low and if you say something is slow, you’ll get people writing
alternativesfirstofall, ornotusingit,or, arbitrarilysaying,‘Oh
no, you shouldn’t use that’, just because they, if they’re not an
expert,alltheyknowiswhatthey’vereadinthatbriefcomment.”
—M 2
4.4.2 It’s Notthe RightTime toDocument. In acode basewith
millions of lines of code, developers may find APIs that were never
beintendedtobewidely used,andcontinuetouseusethemlong
aftertheauthorsofthatAPIhavemovedontootherprojects.Logis-
tically,thismadeitdifficultforustogetincontactwithmaintainers
of APIs mentioned in the Searcher Interviews. Contributions from
core contributors could be years old, and some contributors had
even moved on to other companies.
M3toldustheyweren’tsurprisedthatsearcherslikeS14were
findingandusinganAPItheyhadoncecontributedto.However,
the API wasn’t for use by other teams, and the team had moved on
to other projects. M3 had no intention, and believed no one else
had any intention, to further update the code or comments:
“It’s unlikely this will ever get changed again. They’re going to
deletetheunderlyingdataandthen,hopefullysomeonewillclean
up this utility, I guess, ostensibly it’s my team that’s responsible
for it, but...if you didn’t schedule this meeting I would have
forgottenthis fileexisted.”
—M 3
EvenforanAPIwithalotofdevelopmentattentionandanactive
clientele, maintainers could have good reason not to add or update
comments. When informed of a searcher’s question, M4 and M5
toldusthatitwasn’ttherighttimetodocument.Theirprojectwas
a re-implementation of a standard C++ library, with “quite a few
earlyadopters.”M4tolduscurrentdevelopmenteffortwasgoingto
gointoimprovingcompilererrormessagesandfixingperformance
bugs. Another complication was that, as a re-implementation of
an externally available library, documentation already existed—
however,thisdocumentationwasnotaccessiblewithinCodeSearch.
For M5, writing documentation in the header files would not only
be redundant, it could cause maintenance issues later on:
“...recapitulating the entire documentation for [our API] here is
just not a good choice. It duplicates a lot of things, it lets them
fall out of date weirdly... Also, [the online reference] is better
cross-linked than the documentation in the header.”
—M 54.4.3 PreferenceandPreservation. Mostsearchersandmaintain-
ersweinterviewedhadopinionsaboutwhat didbelongindocumen-
tation,atboththelevelofheadersandin-linecomments. Maintainers
andsearchersmentionedtheimportanceofdescribinghowafile
relatestootherfilesintheproject(S17),thestateoftheworldwhen
amethodiscalled(S8),executableexamples (M5,M8),implemen-
tation comments for future maintainers of an API (M5), explicit
linkstoexternaldocumentation(M5),semanticsofafunction(M8),
mainconceptsthatsomeoneshouldunderstandandknowtouse
the API (M8), “what” the code is doing and “why” at a statement
level (M6), and even a proof of correctness (M6). It is unsurprising
that not all of this information was available for all of the APIs we
saw duringthis study.
Choices to include or update documentation could also be based
on preserving existing style, and writing comments that can stand
thetestoftime.M6preservedthestyleandplacementofexisting
comments when makinga one-off contribution to a common C++
utility method. M6 also noted the brittleness of concrete perfor-
mance descriptions,describingone such inline comment:
“... ithadthesenumbers,likespecificnumbers,50%speedup,25x
speedup, things like that, which are, like, naturally out of date,
you know? They were for a machine in 2006 or something like
that, like, a particular machine. They’re surely not correct today,
you know what I mean?”
—M 6
To resist “rot”, M6 replaced this description with a proof that
would hold even as computing infrastructure changed.
4.4.4 Factors Influencing Changes to API Documentation. M2
aptly described the somewhat solitary nature by which comments
were often written and updated when they told us:
“... It was mostly just me, a little bit of feedback from code re-
viewers, when I was, you know, initially checking this in on what
needed to be documented and what didn’t.”
—M 2
While changes to documentation could be on the whole infre-
quent,maintainersmentionedseveralcasesinwhichtheymight
updatedocumentation.Themostobviouspathwasthroughroutine
development workflows, by getting feedback from code reviewers
(M8, S14), or cleaning up comments while refactoring or updating
existingcode(M6,M8,S19).Beyondtypicaldevelopmentprocess,
some maintainers also told us they had considered (though did not
alwaysaccept)suggestionsraisedthroughcompanyemailandchat
(M1, M7), and questions raised on mailing lists (M4) as potential
indicationsof usage that should be better explained.
5 DISCUSSION
In thisstudy, we foundthat a minority ofvisits to C++implemen-
tation code were for questions about API usage, some of which
areconventionallycoveredindocumentationandothersthatare
not.Surveyrespondentsreporteditwouldbemostconvenientto
find answers to many of these questions in header files, though
interviewees indicatedcode couldbeaccurate andquickenough to
readinmanycases.Maintainershadreasontobereticenttoupdate
documentation in response to some of these questions. What do
these results, as a whole, imply for maintainers and researchers?

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden Andrew Head, Caitlin Sadowski, Emerson Murphy-Hill, and Andrea Knight
5.1 Implications
5.1.1 Contributing to a Conceptual Framework of Documenta-
tion.Dagenais and Robillard describe documentation process as
comprising initial effort, incremental changes, and bursts, with de-
cisionpointsthroughout[ 8].ForoursampleofAPIs,incremental
changes and bursts were not frequent events. Among others fac-
tors,maintainers’attitudestowardupdatingdocumentationwere
impactedbyfactors includingwhethertheAPIothers wereusing
wassomethingtheyshouldbeusing,keepingexplanationsminimal
fortheintendedaudience,andtheavailabilityofdocumentationfor
comparable APIs. Our conversations with searchers also suggested
additionalfactors thatshould be considered:
Should you document for the unexpected client? What happens
whentheinternalutilityyouforgotaboutgetsinvokedbydevel-
opers across the ocean as an API? This was the case for one of the
maintainers we interviewed. At a company with globally visible
sourcecode,it’spossibleanyfilecouldbecomeatemplateorAPI
foranotherdeveloper’scode.Whoshouldbewatchingthatcode
and documentation when the team working on it moves on?
Whenisn’tcodeenoughtobeself-documenting? Sometimes,de-
velopers had no problem reading code, and in fact preferred it
for finding more accurate information. However, there are some
caseswhereself-documentationisn’tfeasible,likecodewithoverly
complex method signatures and generated code. Other details, like
recommended usage, just can’t be conveyed by source code.
Which “implementation details” belong in docs? While documen-
tationstandardslikeJavadocsuggestthatthebehavior(i.e.input
and output) of APIs functions should be documented, our study
showedthatdevelopershadquestionsaboutimplementationthat
didn’t get answered in the headers, including some questions that
would be most conveniently answered in headers. However, this
type of information appears infrequently in reference documen-
tation [18]. It’s clear that it’s not the best choice to break the ab-
stractionofanAPItodiscussinternalsthatareobviousfromthe
code—which ones should be documented?
5.1.2 ImplicationsforMaintainers. Oneactionableresultofthis
studyisconfirmingtheexistenceofunansweredAPIquestionsin
authentic programming settings beyond input-output specification
(e.g.,sideeffects).However,thisstudyquestionssomeassumptions
aboutwhatbelongsindocumentation.Theresultssuggestmain-
tainers can answer questions with discoverable, understandable
code instead of comments. If code is self-explanatory, it may be
sufficienttoanswersearchers’questions,especiallyifthesearchers
areexperiencedinnavigatingcodeforanswers.However,codeis
no substitute for high-level information or when it is very compli-
cated to read. Furthermore, many surveyed developers felt some
salientimplementationdetailsshouldbesurfacedinheaders.Up-
datestodocumentationshouldheedadiversityofuserquestions
and code-vs-documentation expectations we observed.
5.1.3 Implications for Tool-Builders. This study presents a di-
versity of questions whose answers could be surfaced, beyond just
function signatures, and even including implementation choices.
Tools for editing and navigating implementation code may benefit
from helping developers find answers to these uestions quickly.This study also shows the messiness of proposing updates to docu-
mentation. The ideal time to propose changes to documentation is
duringcodeauthoringandreview,possiblythroughasurrogatelike
a code reviewer. Documentation can get updated only infrequently
after it is initially written, as future updates may raise questions of
whether the informationadds clutter or redundancy.
5.2 Results in Context
Whilethisstudywasconductedatasoftwareengineeringcompany
withbillionsoflinesofcodeanddedicatedcodesearchtools,we
expect our observations apply elsewhere whenever:
Implementationcodeissearchable. AtGoogle,therearededicated
toolsto supportlooking upimplementation code.For APIswhere
source code is less accessible, developers probably won’t ask the
samequestionsofimplementationcode,orhavethesameprefer-
ences of where they find answers. Many professional and open
sourceprojectsrelyonbothamixoflocalAPIsforwhichsource
code is readily available, and external APIs for which it isn’t.
Developers search the source code. Perhaps because of mature
searchtools,Googledevelopersfrequentlysearchcodewhenasking
questions about code [ 32]. Developers’ willingness to reference
codelikelyvariesbycompanyorproject.However,wenotethat
professionaldevelopers’willingnesstoreadcodeovercomments
hasbeen observed in several other research settings [31, 33].
Implementation code and documentation are separated. For other
languages, code and documentation may not be in separate files
(e.g.,Javadoc).Whileonecouldn’treplicateourmethodologyfor
such languages, we expect there would be overlap in the questions
developersask.Specificinstancesofquestionsandfrequencymight
changefor otherlanguages: forexample, a Pythondeveloper may
ask questions about side effects, though likely not the question
about memory leaks one survey respondent reported.
Some APIsare unstable. ThisstudyconsidersAPIs from widely-
usedutilitiestoteam-specificlibrariesusedbyahandfulofdevelop-
ers. Developers likely rely more on documentation for stable APIs
where more effort has been put into documentation.
6 CONCLUSION
In this mixed-methods study, we collected a cross-section of de-
veloper questions about API usage, and API maintainers’ attitudes
about updating documentation in response to these questions. Re-
flectingontheresultingsetofquestionsaboutAPIs,andcontextual
factors that influenced maintainer attitudes on updating documen-
tation,ourobservationsprovideanewsetofquestionsmaintainers
and tool developers should consider in the pursuit of improving
low-level documentation for APIs.
ACKNOWLEDGMENTS
SpecialthankstomembersofGoogle’sEngineeringProductivityRe-
search (EPR) team for guidance, particularly Matthew Jorde, Ciera
Jaspan,andEdwardK.SmithandtoEdwardHuangforinterview
transcription.WealsothankdocumentationstakeholdersatGoogle
forprovidingideasandfeedbackaboutthiswork,particularlyGreg
Miller and Ríona MacNamara.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. When Not to Comment ICSE ’18, May27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1] Appendix to this paper. https://goo.gl/wMg3vY.
[2]How to Write Doc Comments for the Javadoc Tool. http://www.oracle.com/
technetwork/java/javase/documentation/index-137868.html. Accessed 12 Febru-
ary 2018.
[3] Stack Overflow. http://www.stackoverflow.com.[4]
JürgenBörstler andBarbara Paech.2016. TheRole ofMethod ChainsandCom-
ments in Software Readability and Comprehension—An Experiment. IEEE Trans-
actions on Software Engineering 42,9 (Sept. 2016), 886–898.
[5]JoelBrandt,PhilipJ.Guo,JoelLewenstein,MiraDontcheva,andScottR.Klemmer.
2009. TwoStudiesofOpportunisticProgramming:InterleavingWebForaging,
Learning, and Writing Code. In Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems . ACM, 1589–1598.
[6]RaymondP.L.BuseandWestleyWeimer.2012. SynthesizingAPIUsageExamples.
InProceedings of the 34th International Conference on Software Engineering . IEEE
Press, 782–792.
[7]Mihaly Csikszentmihalyi and Reed Larson. 2014. Validity and Reliability of the
Experience-SamplingMethod. In FlowandtheFoundationsofPositivePsychology .
Springer, 35–54.
[8]Barthélémy Dagenais and Martin P. Robillard. 2010. Creating and Evolving
DeveloperDocumentation:UnderstandingtheDecisionsofOpenSourceCon-
tributors.In ProceedingsoftheEighteenthACMSIGSOFTInternationalSymposium
on Foundations of Software Engineering . ACM, 127–136.
[9]Uri Dekel and James D. Herbsleb. 2009. Improving API Documentation Usability
withKnowledgePushing.In Proceedingsofthe31stInternationalConferenceon
Software Engineering . IEEE Press, 320–330.
[10]Ekwa Duala-Ekoko and Martin P. Robillard. 2012. Asking and Answering Ques-
tions about Unfamiliar APIs: An Exploratory Study. In Proceedings of the 34th
International Conference on Software Engineering . IEEE Press, 266–276.
[11]Scott D. Fleming, Chris Scaffidi, David Piorkowski, Margaret Burnett, RachelBellamy, Joseph Lawrance, and Irwin Kwan. 2013. An Information Foraging
Theory Perspective on Tools for Debugging, Refactoring, and Reuse Tasks. ACM
Transactions on Software Engineering and Methodology 22,2 (2013), 14:1–14:41.
[12]Björn Hartmann, Mark Dhillon, and Matthew K. Chan. 2011. HyperSource:
Bridging the Gap Between Source and Code-Related Web Sites. In Proceedings of
theSIGCHIConferenceonHumanFactorsinComputingSystems .ACM,2207–2210.
[13]DonaldE.Knuth.1974. StructuredProgrammingwithgotoStatements. Comput.
Surveys6, 4 (Dec. 1974), 261–301.
[14]Andrew J. Ko, Brad A. Myers, Michael J. Coblenz, and Htet Htet Aung. 2006.
An Exploratory Study of How Developers Seek, Relate, and Collect Relevant
Information during Software Maintenance Tasks. IEEE Transactions on Software
Engineering 32, 12 (Dec. 2006).
[15] John Lakos. 1996. Large-scale C++ Software Design . Addison-Wesley.
[16]Thomas D. LaToza, Gina Venolia, and Robert DeLine. 2006. Maintaining Mental
Models:AStudyofDeveloperWorkHabits.In Proceedingsofthe28thInternational
Conference on Software Engineering . ACM, 492–501.
[17]TimothyC.Lethbridge,JaniceSinger,andAndrewForward.2003. HowSoftware
Engineers Use Documentation: The State of the Practice. IEEE Software 20, 6
(Nov.–Dec. 2003), 35–39.
[18]Walid Maalej and Martin P. Robillard. 2013. Patterns of Knowledge in API
Reference Documentation. IEEE Transactions on Software Engineering 39, 9 (Sept.
2013), 1264–1282.
[19]PaulW.McBurneyandCollinMcMillan.2014. AutomaticDocumentationGener-
ationviaSourceCodeSummarizationofMethodContext.In Proceedingsofthe
22nd International Conference on Program Comprehension . ACM, 279–290.
[20]JoãoEduardoMontandon,HudsonBorges,DanielFelix,andMarcoTulioValente.
2013. DocumentingAPIswithExamples:LessonsLearnedwiththeAPIMiner
Platform. In 20th Working Conference on Reverse Engineering . IEEE, 401–408.
[21]Laura Moreno, Gabriele Bavota, Massimiliano Di Penta, Rocco Oliveto, and
AndrianMarcus.2015. HowCanIUseThisMethod?.In Proceedingsofthe37th
International Conference on Software Engineering . IEEE, 880–890.
[22]YoannPadioleau,LinTan,andYuanyuanZhou.2009. ListeningtoProgrammers—
Taxonomies and Characteristics of Comments in Operating System Code. In
Proceedings of the 31st International Conference on Software Engineering . IEEEPress, 331–341.
[23]Chris Parnin, Christoph Treude, and Margaret-Anne Storey. 2013. Blogging
DeveloperKnowledge:Motivations,Challenges,andFutureDirections.In Pro-
ceedingsofthe2013IEEE21stInternationalConferenceonProgramComprehension .
IEEE Press, 211–214.
[24]GayanePetrosyan,Martin P.Robillard, and Renato De Mori. 2015. Discovering
Information ExplainingAPI Types UsingTextClassification. In Proceedingsof
the 37th International Conference on Software Engineering . IEEE Press, 869–879.
[25]DavidPiorkowski,AustinZ.Henley,TahmidNabi,ScottD.Fleming,Christopher
Scaffidi, and Margaret Burnett. 2016. Foraging and Navigations, Fundamentally:
Developers’ Predictions ofValue and Cost. In Proceedings ofthe 2016 24th ACM
SIGSOFT International Symposium on Foundations of Software Engineering . ACM,
97–108.
[26]DavidJ.Piorkowski,ScottD.Fleming,IrwinKwan,MargaretM.Burnett,Chris
Scaffidi, Rachel K.E. Bellamy, and Joshua Jordahl. 2013. The Whats and Hows of
Programmers’ForagingDiets.In ProceedingsoftheSIGCHIConferenceonHuman
Factors in Computing Systems . ACM, 3063–3072.
[27]Luca Ponzanelli, Alberto Bacchelli, and Michele Lanza. 2013. Seahawk: Stack
OverflowintheIDE.In Proceedingsofthe35thInternationalConferenceonSoftware
Engineering . IEEE Press, 1295–1298.
[28]Rachel Potvin and Josh Levenberg. 2016. Why Google Stores Billions of Lines of
Code in a Single Repository. Commun.ACM 59, 7 (July 2016), 78–87.
[29]Martin P. Robillard. 2009. What Makes APIs Hard to Learn? Answers from
Developers. IEEE Software 26, 6 (Nov.–Dec. 2009), 27–34.
[30]Martin P. Robillard and Robert DeLine. 2011. A field study of API learning
obstacles. Empirical Software Engineering 16, 6 (Dec. 2011), 703–732.
[31]TobiasRoehm,RebeccaTiarks,RainerKoschke,andWalidMaalej.2012. How
DoProfessionalDevelopersComprehendSoftware?.In Proceedingsofthe34th
International Conference on Software Engineering . IEEE Press, 255–265.
[32]CaitlinSadowski,KathrynT.Stolee,andSebastianElbaum.2015.HowDevelopers
SearchforCode:ACaseStudy.In Proceedingsofthe201510thJointMeetingon
Foundations of Software Engineering . ACM, 191–201.
[33]Felice Salviulo and Giuseppe Scanniello. 2014. Dealing with Identifiers and
CommentsinSourceCodeComprehensionandMaintenance:Resultsfroman
Ethnographically-informedStudywithStudentsandProfessionals.In Proceedings
of the 18th International Conference on Evaluation and Assessment in Software
Engineering . ACM, 48:1–48:10.
[34]JonathanSillito,GailC.Murphy,andKrisDeVolder.2006. QuestionsProgram-
mers Ask During Software Evolution Tasks. In Proceedings of the 14th ACM
SIGSOFT International Symposium on Foundations of Software Engineering . ACM,
23–34.
[35]Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, and K. Vijay-
Shanker. 2010. Towards Automatically Generating Summary Comments for Java
Methods. In Proceedings of the IEEE/ACM International Conference on Automated
Software Engineering . ACM, 43–52.
[36]GiriprasadSridhara,LoriPollock,andK.Vijay-Shanker.2011. GeneratingParam-
eterCommentsandIntegratingwithMethodSummaries.In Proceedingsofthe
2011 IEEE 19th International Conference on Program Comprehension . IEEE, 71–80.
[37]ChristophTreudeandMartinP.Robillard.2016. AugmentingAPIDocumenta-
tionwithInsightsfromStackOverflow.In Proceedingsofthe38thInternational
Conference on Software Engineering . ACM, 392–403.
[38]GiasUddin andMartinP.Robillard. 2015. HowAPIDocumentation Fails. IEEE
Software32,4 (July–Aug. 2015), 68–75.
[39]Hao Zhong and Zhendong Su. 2013. Detecting API Documentation Errors. In
Proceedingsofthe2013ACMSIGPLANInternationalConferenceonObject-Oriented
Programming Systems Languages & Applications . ACM, 803–816.
[40]HaoZhong,TaoXie,LuZhang,JianPei,andHongMei.2009. MAPO:MiningandRecommendingAPIUsagePatterns.In ProceedingsoftheEuropeanConferenceon
Object-Oriented Programming . Springer, 318–343.
[41]YuZhou,RuihangGu,TaolueChen,ZhiqiuHuang,SebastianoPanichella,and
Harald Gall. 2017. Analyzing APIs Documentation and Code to Detect Directive
Defects.In Proceedingsofthe39thInternationalConferenceonSoftwareEngineering .
IEEE Press, 27–37.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:54:18 UTC from IEEE Xplore.  Restrictions apply. 