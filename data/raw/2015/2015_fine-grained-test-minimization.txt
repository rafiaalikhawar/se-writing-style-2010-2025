Fine-Grained Test Minimization
Arash Vahabzadeh
University of British Columbia
Vancouver, BC, Canada
arashvhb@ece.ubc.caAndrea Stocco
University of British Columbia
Vancouver, BC, Canada
astocco@ece.ubc.caAli Mesbah
University of British Columbia
Vancouver, BC, Canada
amesbah@ece.ubc.ca
ABSTRACT
As asoftware systemevolves, its testsuite canaccumulate redun-
dancies over time.Test minimization aimsat removing redundant
test cases. However, current techniques remove whole test cases
fromthetestsuiteusingtestadequacycriteria,suchascodecov-
erage. This has two limitations, namely (1) by removing a whole
test case the corresponding test assertions are also lost, which can
inhibit test suite effectiveness, (2) the issue of partly redundant
test cases, i.e., tests with redundant test statements, is ignored. We
proposeanovelapproachforfine-grainedtestcaseminimization.
Our analysis is based on the inference of a test suite model that
enables automated test reorganization within test cases. It enables
removingredundanciesattheteststatementlevel,whilepreserving
the coverage and test assertions of the test suite. We evaluated our
approach,implementedinatoolcalledTestler,onthetestsuitesof
15opensourceprojects.Ouranalysisshowsthatover4,639(24%)of
the tests in these test suites are partly redundant, with over 11,819
redundantteststatementsintotal.OurresultsshowthatTestler
removes43%oftheredundantteststatements,reducingthenumber
ofpartlyredundanttestsby52%.Asaresult,testsuiteexecution
timeis reducedby upto 37%(20%on average),while maintaining
theoriginalstatementcoverage,branchcoverage,testassertions,
and fault detection capability.
CCS CONCEPTS
•Software and its engineering →Software testing and de-
bugging;
KEYWORDS
test minimization, test reduction, test redundancy, test model
ACM Reference Format:
ArashVahabzadeh,AndreaStocco,andAliMesbah.2018.Fine-GrainedTest
Minimization.In Proceedingsof40thInternationalConferenceonSoftware
Engineering (ICSE ’18). ACM, New York, NY, USA, 12 pages. https://doi.org/
10.1145/3180155.3180203
1 INTRODUCTION
Testinghasbecomeawidespreadpracticetoensurethequalityand
correctnessofsoftwaresystems.Astheproductioncodeevolves,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
©2018 Copyright held by the owner/author(s). Publication rights licensed to the
Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.3180203newtestcasesareaddedandexistingonesaremodified.Overtime,
a test suite can accumulate redundant test cases [ 3,9,21], without
benefiting the overall test suite coverage or effectiveness.
Test suite minimization —also known as reduction— techniques
aimateliminatingredundanttestcasesfromtestsuitestoreduce
their maintenance and regression testing costs [ 35]. Existing re-
ductiontechniques,however,useadequacycriteria,suchascode
coverage, as a guideline to remove wholetest cases with redun-
dant coverage [ 48]. A potential drawback of such techniques is
the deletion of a test case having similar code coverage as other
test cases, but different test statements and assertions. This can
severelymodifytheintendedtestsuitebehaviour[ 35],becausehow
aproductionmethodiscalledandassertedinfluencestheoverall
test suite effectiveness [50] and fault finding capability [34, 44].
Toovercomethisissue,anapproachtargetingmorefine-grained
redundancies within test statements is needed. However, reorga-
nizing(or refactoring)test casesisa challengingtask.Developersusethe testsuite tocheck thatthe behaviour ofthe systemis pre-
served when production code is changed. In contrast, such a safety
net does not exist when a test suite needs to go through internal
changes.Moreover,itisnotstraightforwardtomanuallyre-order
complex test cases in a way that retains the semantics.
Inthis paper,we proposeanovel approachto fine-grained test
minimization,whilepreservingtheoriginalbehaviourofthetest
suite.Ourapproachanalysestestcasesatthe statementlevel and
infers a test model that captures the relationships between test
statements and test states. The test model allows fine-grained test
re-organizationaltaskssuchasidentifyingandremovingredundant
teststatements.Asopposedtoexistingtestreductiontechniques,
our fine-grained test minimization technique: (1) models the actualbehaviourofthetestsuitebycapturingtheproductionmethodcalls
togetherwiththeirinputs,insteadofsimplyrelyingoncodecov-
erage, (2) removes redundant test statements, instead of removing
whole test cases, and (3) preserves all test assertions in a test suite,
inadditiontomaintainingthecoverageandfaultfindingcapability.
Our work makes the following main contributions:
•A novel test minimization technique for eliminating fine-
grained redundancies in testcases that is safe and accurate.
•A test model capturing test statements and test states, along
with their relationships.
•An algorithm for identifying behaviour-preserving refactor-
ings in a test suite. It uses the test model to reorganize tests
in a way to minize redundant test statements.
•AnimplementationofourapproachinatoolcalledTestler,
which supports Java code and JUnit4 and is available [41].
•Anempiricalevaluationof Testlerperformedontestsuites
of 15 open source projects. Our results show, on average,a 43% decrease in the number of redundant statements, a
52%decreaseinthenumberofpartlyredundanttests,and
2102018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden A. Vahabzadeh et al.
1 @Test
2 public void testAdd() {
3 Complex x=new Complex(3.0, 4.0);
4 Complex y=new Complex(5.0, 6.0);
5 Complex z = x.add(y);
6 assertEquals(8.0, z.getReal(), 1.0e-5);
7 }
8 @Test
9 public void testSubtract() {
10 Complex x=new Complex(3.0, 4.0);
11 Complex y=new Complex(5.0, 6.0);
12 Complex z = x.subtract (y);
13 assertEquals(-2.0, z.getReal(), 1.0e-5);
14 }
15 @Test
16 public void testMultiply() {
17 Complex x=new Complex(3.0, 4.0);
18 Complex y=new Complex(5.0, 6.0);
19 Complex z = x.multiply (y);
20 assertEquals(-9.0, z.getReal(), 1.0e-5);
21 }
22 @Test
23 public void testDivide() {
24 Complex dividend =new Complex(3.0, 4.0);
25 Complex divisor =new Complex(5.0, 6.0);
26 Complex q = dividend.divide(divisor);
27 assertEquals(39.0 / 61.0, q.getReal(), 1.0e-5);
28 }
Figure 1: Four tests from Apache Commons Math. Fine-
grained redundancies are highlighted.
atestsuiteexecutiontimereductionbyupto37%(20%on
average).
2 A MODEL FOR ANALYZING TESTS
Ourtest suite model that enables our fine-grained test analysis is
defined as follows.
Definition 1 ( Test Suite Model ).A Test Suite Model is a
directedgraphdenotedbyatriple /angbracketleftr,V,E/angbracketrightwhereVisasetofvertices
representingteststates, Eisasetofdirectededgesrepresentingtest
statements and assertions, and rdenotes the root of the graph, which
is the initial empty state.
To explain our model, we use the ComplexTest class from the
ApacheCommonsMathproject[ 2],oneoftheexperimentalsub-
jects used in our evaluation. The test class, shown in Figure 1,
consistsoffourtestcaseswithredundantstatements(i.e.,theini-
tializationoftheobjects xand yoftheclass Complex,atLines3-4,
10-11,17-18,and24-25).Figure2showshowtheseredundantstate-
ments are removed by our approach.
Figure 3 illustrates the test suite model obtained for the class
ComplexTest . Rectanglesdenote test states (nodes),whereas round
boxes(theannotatededges)depictteststatements,anddashedlinesrepresentthecompatibilitybetweenateststateandateststatement
(explained in Section 2.4).
Next, we define the properties of our model, the notions of test
statement and test state, as well as their relationships in the model.
2.1 Model Properties
Thereareanumberofpropertiesthatourmodelneedstoexhibit.
First, the model should capture how the production code meth-ods are called by the test suite. This is important to preserve thebehaviour of the test suite after any refactoring activity. Second,
the model should capture dependencies at the test statement level1 @Test
2 public void testAdd_Subtract_Multiply_Divide() {
3 Complex x=new Complex(3.0, 4.0);
4 Complex y=new Complex(5.0, 6.0);
5 Complex z = x.add(y);
6 assertEquals(8.0, z.getReal(), 1.0e-5);
7 Complex z_subtract = x.subtract (y);
8 assertEquals(-2.0, z_subtract.getReal(), 1.0e-5);
9 Complex z_multiply = x.multiply (y);
10 assertEquals(-9.0, z_multiply.getReal(), 1.0e-5);
11 Complex q = x.divide(y);
12 assertEquals(39.0 / 61.0, q.getReal(), 1.0e-5);
13 }
Figure 2: Reorganized tests of Figure 1. The redundant teststatements are removed and four test cases are merged intoone.
tosupporttestreorganization.Sinceateststatementmighthave
dependencies on previous statements, it is important to know how
tosafelymoveteststatementswithinoramongtests.Finally,the
model should facilitate the discovery and removal of redundancies
in test cases.
2.2 Test Statements
We use test statements as the smallest unit of computation for the
test model. Using a more fine-grained unit, such as bytecode oper-
ation,wouldincreasethemodelsizeandtheanalysiscomplexity.
On the other hand, using a larger unit, such as blocks of state-
ments, would invalidate our ability to detect and reorganize partly
redundant testcases with common test statements. Therefore, we
considereachtestcaseasasequenceof teststatements (hereafter
referredtoas st).Forexample,eachlineofthetestcasesinFigure1
is ast. Assertions are also a particular type of st.
A unittest casetypically creates aset ofvariables (e.g., objects)
and assigns values to their (member) variables, then it calls the
production method under test using those variables as inputs, and
finally it asserts the value returned by the method. Our test model
needs to capture all these three entities, namely, variables and their
values,production method calls, and test assertions.
Definition 2 ( Variable Value ).The value of a variable x
(Val(x))is defined as:
Val(x)=⎧⎪⎪ ⎨
⎪⎪⎩primitive _value :Type(x)∈P
{(xi,Val(xi))|xi∈Fields(x)}:Type(x)/nelementP
Type(x)denotesthetypeofthevariable x,Pisthesetofallprim-
itivetypes,and Fields(x)denotesthesetofallmembervariablesof
theobject x.Ifthevariable xisaprimitivetype, Val(x)istheprimi-
tive value. Otherwise, if the variable xis an object, its value is a set
of(xi,Val(xi))pairswhere xiisthenameof ithmembervariablein
x;inJavathisincludes private,protected and publicmembervari-
ables of the object. For example, in Figure 1 the value of the object
xat Line 3 is Val(x)={(Complex .r,3.0),(Complex .i,4.0)}given
that the Complexclass has two member variables of type double
named rand i.
In order to preserve the test suite semantics, we analyze it to
captureitsexternallyobservablebehaviour.Werefertomethods
in the production code that are under test as production methods.
211
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Fine-Grained Test Minimization ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Complex : {(Complex.r, 3.0), (Complex.i, 4.0)}
Complex : {(Complex.r, 3.0), (Complex.i, 4.0)}
Complex : {(Complex.r, 5.0), (Complex.i, 6.0)}
Complex : {(Complex.r, 3.0), (Complex.i, 4.0)}Complex : {(Complex.r, 5.0), (Complex.i, 6.0)}
Complex : {(Complex.r, 8.0), (Complex.i, 10.0)}Complex : {(Complex.r, 3.0), (Complex.i, 4.0)}Complex : {(Complex.r, 5.0), (Complex.i, 6.0)}
Complex : {(Complex.r, -2.0), (Complex.i, -2.0)}Complex : {(Complex.r, 3.0), (Complex.i, 4.0)}Complex : {(Complex.r, 5.0), (Complex.i, 6.0)}
Complex : {(Complex.r, -9.0), (Complex.i, 38.0)}Complex : {(Complex.r, 3.0), (Complex.i, 4.0)}Complex : {(Complex.r, 5.0), (Complex.i, 6.0)}
Complex : {(Complex.r, 0.64), (Complex.i, 0.03)}S0
S3S4S5st
3st
10st
24
st
4st
11st
25st
17
st
18
st
5
st
27st
12st
19st
26
st
20st
13st
6S6S1
S2
Figure3:Extractedpartialmodelfortherunningexample.Nodes(rectangles)representteststatesanddirectededgesaretest
statements. Each edge is labelled with all the information about the test statement; here we use line numbers to simplify the
graph. Dashed lines represent state compatibility relations between test states and test statements.
The external behaviour of a test suite can be hence modelled by
capturingalltheproductionmethodscalledalongwiththeirinputs.
Definition 3 ( Production Method Calls (PMC) ).The
Production Method Calls of a test statement st (PMC(st))is a set
of(MethodName i,InputSet i)pairs,in which MethodName iisthe
qualified name of the called production method, and InputSet iis the
ordered setof ( Type(xj),Val(xj)) pairsfor eachinput variable xjof
themethodstartingwith thisobjectfornon-staticmemberfunctions.
Forexample,inFigure1,the PMCfortheteststatementatLine5
is{(Complex .add,[(Type(x),Val(x)),(Type(y),Val(y))])}since,as
part of the test statement execution, the method Complex.add is
called with the two inputs xand y. ThePMCof a test statement
that does not call any production methods is the empty set.
Further, our model needs to accommodate the ability of moving
test statements from a source position in one test case to a desti-
nation position in another test case. In order to preserve the test’s
behaviourandavoidundesirablesideeffects,weneedtokeeptrack
of the data and definition dependencies of the test statements [ 26].
Indeed,ifweknowwhichvariableshavebeenusedaspartofthe
executionof atest statement,we candetermine whetherit canbe
safely moved to another destination position in the test suite.
Concerning datadependency,wesavethevariablesthatareused
by the test statements and by the assertions, defined as follows.
Definition4( UsedVariablesofTestStatements(UVS) ).
The Used Variables of a test statement stj(UVS(stj)) is a set of
(Type(xi),Val(xi)) pairs where each variable xiis used in the execu-
tion ofstj.
For example, the UVS of the statement at Line 5 of Figure 1
contains{(Type(x),Value(x)),(Type(y),Value(y))}.
For assertions, we also need to keep track of the method calls
that create the value of the variables. Since assertions check theoutputofparticularproductionmethodcalls,weneedtocapture
thisinformationaspartofourtestmodel.Forexample,atLine6
of Figure 1, the assertion checks the output of the method add
with specific inputs. It is possible to retrieve the whole chain of
methodcallsthattheassertionevaluatesasfollowing:theassertion
checks the output of the addmethod, which uses the output of two
constructor calls of the Complexclass.
Definition5( UsedVariablesofAssertions(UVA) ).The
UsedVariables ofanassertion asrt,UV A(asrt),isasetof ( Type(xi),
Val(xi),Meth(xi))tupleswhereaspartoftheassertionexecutionthe
variablexiis used and Meth(xi)is thePMCof the test statement
that assigns the value of xi.
Forexample,inFigure1,theUVAatLine6is {(Type(z),Value(z),
Meth(z))}, whereMeth(z)={(Complex .add,[(Type(x),Val(x)),
(Type(y),Val(y))])}sincevariable zisbeingusedaspartoftheexe-
cutionoftheassertionanditsvalueiscreatedbythe addproduction
method call ( PMCof the test statement at Line 5).
In addition to data dependencies, a test statement can have def-
inition dependencies on previous test statements. For example, at
Line26ofFigure1,theteststatementdoesnotdependonthevalue
of the variable q. Thus, given that the datadependency of the test
statement is satisfied, it is possible to replace the variable qwith
any other variable of type Complex. In order to be executed, the
test statement needs three variables of the type Complexdefined in
thepreviousteststatements,inadditiontoitsdatadependencies.
The Defined Variables ( DV) set of a test statement captures this
definition dependency.
Definition 6 (Defined Variables (DV)). The Defined Vari-
ables of a test statement st,DV(st), is the set of the variable types
thatarereferencedin st,whichneedtobedefinedbeforetheexecution
ofst.
212
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden A. Vahabzadeh et al.
Note that for the defined variables, we abstract away the actual
values by focusing on the types.Consider Figure 1 again. TheDV
set at Line 26 is {Complex ,Complex ,Complex}since the variables
dividend,divisorand qneedtobepreviouslydefinedtosatisfythe
definition dependency of the statement.
2.3 Test States
Toperform dataanddefinition dependency analysis,wemaintain
atest stateat each test statement.
Definition 7 ( TestState ).A Test State encompasses informa-
tion pertaining to the defined variables, their values, and the PMC
thatcreatedthemataspecificteststatementinthetestcase.Formally,
the Test State ( Sj) is a set of (Type(xi),Val(xi),Meth(xi))tuples for
each variable xireferable from jth test statement in the test case.
In the Java programming language and JUnit testing frame-
work, the test state includes information about local variables,
static field of loaded classes, and member variables of the test
class. For example, in Figure 1, the test state before the execu-
tionofLine5is {(Type(x),Value(x),Meth(x)),(Type(y),Value(y),
Meth(y))},sincethetwovariables xandyarereferableatLine5.Fol-
lowingourmodel, Meth(x)={(Complex ,{(double ,3.0),(double ,4.0)})}
since xis created by the PMC Complex(i.e., the constructor) with
two input values 3 .0 and 4 .0 of type double.
2.4 Test State Compatibility
It is possible to move a test statement stto a destination position d
only if the test state at discompatible withst.
Definition 8 ( Compatible State ).A test state is compati-
ble with a test statement if it satisfies the test statement data anddefinition dependencies. In this case, the test statement can be exe-
cuted on the test state while preserving its behaviour. Formally, a test
state(Si)iscompatiblewithateststatement( stj)iffitsusedvariables
(UVS(stj))anddefinedvariables( DV(stj))aresubsetsoftheteststate
((UVS(stj)⊂Si)∧(DV(stj)⊂Def(Si))).Def(Si)denotesthesetof
defined variables in the test state Si.
The compatibility relation for assertions is defined similarly. In
Figure 3 dashed lines represent state compatibility relations be-
tweenteststatesandteststatements.Forexample,thestatement
of Line 12 ( st12) is compatible with the states S2,S3,S4,S5, andS6
sincethe readvariable setat Line12 {(Complex ,{(Complex .r,3.0),
(Complex .i,4.0)}),(Complex ,{(Complex .r,5.0),(Complex .i,6.0)})}
is a subset of these test states. Note that we have illustrated only a
subset of all compatibility relations to avoid a tangled graph.
With the notion of compatible states, we can determine possible
valid reorganizations of test statements in test cases. For example,
wecanrelocatetheteststatementofLine12( st12)inFigure3to
any location after the states S3,S4,S5,o rS6.
2.5 Equivalent and Redundant Test Statements
To detect redundancies in the test suite, we look at the external
behaviourofeachteststatementtoidentifythosethathaveidentical
behaviour.These equivalentteststatements areidenticalasfaras
testing the production code is concerned.Test Code Production Code
Run Instrumented 
Test CasesProduction 
Method 
Calls
Test 
StatesIdentify Deﬁned/Used 
Variables
Deﬁned/Used 
VariablesIdentify 
Compatible 
StatesCompatible 
StatesIdentify 
equivalent test 
statements
Equivalent 
Test 
Statements Create 
Test Suite 
Model
Test 
Suite 
Model
Reorganize Test 
CasesReorganized 
Test PathsCompose Minimized 
Test CaseMinimized 
Test SuiteCode Instrumentation
Test Suite
MinimizationInstrumentModel Generation
Traces
Test Code Production Code
Identif y Deﬁned /Used 
Variables
Deﬁned /Used 
VariablesCode Instrumentatio n
InstrumentRun Instrumented 
Test CasesProduction 
Method 
Calls
Test 
StatesIdentify 
Compatible
StatesCompatible 
StatesIdentify 
equivalent test 
statement s
Equivalent 
Test 
Statement s Create 
Test Suite 
Model
Test 
Suite 
ModelModel Generatio n
TracesT
Figure 4: Overview of our approach.
Definition9( Eqivalent Test Statements ).Equivalent
Test Statements are the sets of test statements that have the same set
of production method calls (PMC).
To preserve the coverage of the production code, we need to
execute(atleast)oneoftheteststatementsineachsetofequiva-
lentteststatements.Allremainingequivalentteststatementsare
redundant test statements and hence can be removed.
Forexample,concerningFigure1,thesetofequivalentteststate-
mentsis{{st3,st10,st17,st24},{st4,st11,st18,st25},{st5},{st6},{st12},
{st13},{st19},{st20},{st26},{st27}}. In this case, in order to main-
tain the coverage of the test, we only need to execute one of the
teststatementsfromtheset {st3,st10,st17,st24},onefromtheset
{st4,st11,st18,st25}, as well as the sets with only one member.
Definition10( Partly Redundant Tests ).Testcasesthat
haveoneormoreredundantteststatementsarecalledpartlyredun-
dant tests.
3 APPROACH
Wenowdescribeourapproachforcreatingthemodelofatestsuite
andreducingtheredundanciesgiventhemodel.Figure4depicts
our overall approach.
3.1 Code Instrumentation
Tocapturetheteststateateachteststatementlevel,westorethe
type and value of all referable variables through code instrumenta-
tion.Weprobelocalvariables,membervariablesofthetestclass,
andstaticfieldsofloadedclasses.Tocaptureproductionmethod
calls(PMCs),weinstrumenttheproductioncodetologtheentry
point,inputvalues(includingthe thisobjectfornon-staticmeth-
ods),andexitpointsofeachmethod.Tokeeptrackofproduction
methods that are called by each test statement, we produce a sepa-
rate call stack log for each test statement of every test case. These
call stacks allow us to obtain the PMC sets directly called from test
statements.
Used and Defined Variables. For each method invocation, we
assume that all the input variables and all of their properties are
usedas partof thetest statementexecution. Thisalso includes all
referablevariables,suchasstaticvariablesandmembervariables
213
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Fine-Grained Test Minimization ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
of an object that are part of a method invocation on the object. For
example, at Line 6 of Figure 1, we assume that all of the properties
of the variable z(i.e. z.rand z.i) will be used as part of the test
statement execution (even if z.iis not actually used). This is a
conservative assumption that prioritizes the precision of detecting
compatible states for test statements. In this case, our recall might
be adversely influenced since we might miss some compatibility
relations, but the precision is enforced because the relations we
detect are correct. To compute the definedvariables set (see Defini-
tion6),wecheckforthetypeofthevariablesthatarereferenced
in the test statement.
3.2 Model Generation
Equivalent Test Statements. After the instrumentation phase,
weexecutetheinstrumentedtestcasesagainsttheinstrumented
productioncode,andusethetracestocomputesetsofequivalent
test statements (i.e., having the same PMC).
Compatible States. To compute compatible states for a test state-
ments,wecheckthestatesinwhichthevariablesusedin shave
thesamevalues.We also makesurethattheteststatessatisfythe
definitiondependency(seeSection2.4).Forassertions,additionally,
we look for the PMCthat defined the most recent value for the
used variables. We require that the direct method calls and theirinputs that an assertion checks remain the same to preserve test
assertion coverage [37, 50].
With the information about equivalent test statements and com-
patiblestates, wecreatea graphrepresentingour testsuitemodel.
3.3 Test Suite Minimization
Weusetheinferredmodeltoidentifyandremoveredundanttest
statements. For example, by reorganizing the four test cases ofFigure 1, we create the minimized test case shown in Figure 2,
which has the same coverage and assertions, but with
six less
statements.
To maintain the test suite coverage, we basically need to call
each production method once. Each test case in our test modelis a path starting from the initial state. For example, in Figure 3,
the test testAddis the path /angbracketleftst3,st4,st5,st6/angbracketrightin which stiisith test
statement (i.e., edge). Thus, to maintain the test suite coverage,
we need to find a set of paths, starting from the initial state, that
visits at least one test statement from each set of equivalent test
statements. To find such paths, we propose a greedy algorithm.
Test Reorganization Algorithm. Algorithm 1 shows our test re-
organization algorithm. The intuition is to extend a path among
thecompatiblestatesofateststatementtocoverasmanyunique
teststatementsandassertionsaspossible.Todoso,wemaintain
asetofequivalentteststatementsandassertionsthatweneedto
cover ( uncoveredEqStmts ).
Starting from the initial state, we find the shortest path to the
nearest test statement that is still uncovered (Line 7). We repeat
thisprocedurefromthatnodeuntilpathextensioncoveringnew
equivalentteststatementsorassertionsisnolongerpossible(inner
loopLines12–20).Thiseventoccurswhenalltheequivalenttest
statementsandalltheassertionsinthemodelhavebeencovered.
Otherwise, if there exist equivalent test statements or assertions
which are still uncovered, we start from the initial state and repeatAlgorithm 1: Test Suite Reorganization
Input:uncoveredEqStmts : set of uncovered equivalent test statements
Input:G: the test suite model
Output:paths: set of paths that visits at least one test statement in each set of
equivalentteststatements,andallassertionswhileminimizingnumberoftest
statements visited
1Reorganize(uncoveredEqStmts, G)
2 begin
3paths←∅
4d o
5 first←G.get(init)
6 runningState ←∅
7 first,path←pathToNearestUncovered( G,first,uncoveredEqStmts,
runningState )
8 foreach sti∈pathdo
9 runningState ←apply( sti,runningState )
10 end
11 frontier←first
12 whilefrontier /nequalnulldo
13 frontier,newpath←pathToNearestUncovered( G,frontier,
uncoveredEqStmts, runningState )
14 foreach sti∈newpathdo
15 runningState ←apply( sti,runningState )
16 end
17 updateGraph( G,frontier,runningState )
18 markAsCovered(frontier, uncoveredEqStmts )
19 path.add(newpath )
20 end
21 paths.add(path )
22 while first/nequalnull
23 end
the procedure again (outer loop Lines 4–22). To find the shortest
path, we use a variant of the best-fit search algorithm that alsomaintains the running state [
36]. We track the test state at each
pointinthegraphbymaintainingarunningstate( runningState ).
Thisisessentiallytheteststatethatiscomputeddynamicallyateach
pointinthegraph.Weupdatetherunningstateateachiteration
of the algorithm (Line 9 and Line 15).
Eachteststatementoperatesonacompatibleteststateandtrans-
formstherunningstatetoanotherteststate.Let SiandSi+1bethe
teststatesbeforeandaftertheexecutionoftheteststatement sti.
The function apply(sti,Si)=Si+1applies the effect of executing
the test statement stion the test state Siand gives us the changed
test state Si+1. Thus, we know the test state beforeandafterthe
executionofeachteststatementintheoriginaltestexecution.This
enables us to compute the effects of running the test statement on
eachofitscompatiblestates.Basically,weneedtoupdatethevalue
of the used variables of the compatible test state to the values of
variablesin Si+1.Ifthestate Sjiscompatiblewiththeteststatement
sti, thenapply(sti,Sj)=updateValues (USV(sti),Si+1,Sj).W ea s -
sume that the test statement could potentially change all of itsusedvariables.Weupdatethegraph toincludeanynewcompat-ibility edge based on the computed running state (Line 17). To
this aim, we compare the UVSandDVof test statements with the
computed running state to identify the compatible test statements.
The algorithm returns a set of paths (each corresponding to a re-
organized/mergedtestcase)thatcovereachsetofequivalenttest
statements and all the assertions. For example, for the test suite
modelofFigure3,ouralgorithmreturnsthepath /angbracketleftst3,st4,st5,st6,
st12,st13,st19,st20,st26,st27/angbracketright,whichcorrespondstothemergedtest
case of Figure 2.
ComposingMinimizedTestCases. Algorithm1givesusasetof
pathsthatminimizesthenumberofteststatementsexecuted,while
214
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden A. Vahabzadeh et al.
Algorithm 2: Test Case Composition
Input:statementsPath : ordered list of statements in the composed test case
Output:statementsPath : renamed list of statements in the composed test case
1RenameStatements(statementsPath )
2 begin
3stateBiMap /angbracketleftvalue, Set/angbracketleftname, type /angbracketright/angbracketright← ∅
4 foreach stmt∈statementsPath do
5 mapPreq/angbracketleftname, value /angbracketright←getNameValuePreqVarsInStatement(stmt )
6 renameMap /angbracketleftoldName, newName /angbracketright←∅
7 castMap/angbracketleftvarName, oldType, newType /angbracketright←∅
8 foreach(varName, varValue) ∈mapPreq do
9 varNamesInState ←stateBiMap[varValue]
10 ifvarName /nequalvarNamesInState then
11 renameMap[varName] ←generateName(varNamesInState)
12 end
13 castMap←checkForTypes(stateBiMap, stmt)
14 end
15 leftHandSideVars /angbracketleftName/angbracketright←getVarsInLeftHandSide(stmt)
16 foreachvarName∈mapPreq do
17 varNameInState ←stateBiMap[varName]
18 ifvarNameInState /nequalnullthen
19 renameMap[varName] ←generateName(varName)
20 end
21 end
22 stmt←renameStatement(stmt, renameMap, castMap)
23 updateStateMap(stateBiMap, stmt)
24 end
25 end
preservingthetest suitecoverage.Despitethestate compatibility,
however,problemsmayarisewhenmovingteststatements,because
ofvariablenamingandcastissues.Forexample,in testDivide of
Figure 1, variables xand yhave names dividend and divisor,r e -
spectively. Therefore, to generate a compilable reorganized test
case,weneedtorenamethesevariables.Teststatementscanalso
definevariablesthathavepreviouslybeendefinedwiththesame
name. For example, in the reorganized test case, the variable zwas
already defined in three out of four test cases. Thus, we need to
rename such variable definitions to avoid name clashes. Further,
teststatementscanusemembervariablesandmemberfunctionsof
thesourcetestclass;thuswealsoneedtoincludethoseinthedesti-
nation test class (note that this is not needed when test statements
relocate within a test class). At last, due to the polymorphism in
object oriented programs, we might need to cast a variable to itssub or super class, if the static type of two variables having the
same value differ in the source and the destination state.
Algorithm 2 shows the pseudocode of the algorithm for com-
posing reorganized test paths. To maintain the state, we use a
bidirectional map from variable values to variable names and their
types. As we go through the test statements in the reorganized test
casepath,wecheck,foreachteststatement,ifwehavethevalue
for each variable in the test statement. If such a value exists, buthas a different name in the state, we rename the variable in the
test statement to the name of the variable in the state (Lines 8–15).
If the type of the variable is different, we cast the variable to thedestination type. If there are name duplicates, we rename them
(Lines16–22).Finally,weupdatethebidirectionalstatemapwith
the changed values from test statement execution (Line 23).
3.4 Preserving Test Suite Behaviour
Assumethatwereorganizeasetoftestcases xintothereorganized
set of test cases y, we show that ypreserves the fault revealing
behaviourof x.PMC(x)denotesthesetofproductionmethodcallsthatthesetoftestcases xcallwiththeirinputs.Since PMC(x)=
PMC(y), each production method mithat is called as part of the
executionof x,willbecalledwiththesameinputsin y.Hence,both
the coverage and the implicitoracles ofxare preserved. We also
retainthe explicitoracles ofx,becauseourapproachkeepsallthe
correspondingtestassertionsinthereorganizedtestcases.Assume
that inx, assertion asichecks the return value of the production
methodmiwith the input ini. Letasjbe the same assertion asi
thatisincludedin y.SinceUVA(asi)=UVA(asj),assertion asjwill
checkthereturnvalueof miwiththesameinput ini.Ifafault fin
miaffects the return value of mi(ini)and is detectable by asi,i ti s
also detectable by asj./square
3.5 Implementation
We implemented our approach in a tool called Testler, which
is publicly available [ 41]. The tool is written in Java. It supports
analyzing Java programs with JUnit4 tests. However, our overall
approachisgeneralandapplicabletootherprogramminglanguages
and testing frameworks. Testler takes as input the path to a Java
project.Itinstrumentsthetestandproductioncode,andrunsthe
instrumentedtestcodeagainsttheinstrumentedproductioncodeto
obtain traces. Then, Testler uses the traces to create a test model,
detects and reorganizes partly redundant test cases, and generates
a new minimized test suite.
4 EVALUATION
Toassessthereal-worldrelevanceandefficacyofourapproach,we
address the following research questions:
RQ1(prevalence): How prevalent are partly redundant tests in
practice?
RQ2(reduction): What is the redundancy reduction, in terms of
tests and test statements, achievable with Testler?
RQ3(execution time): What is the reduction in the execution
time of the test suites reorganized by Testler?
RQ4(code coverage and fault detection): DoesTestlerpreserve
the code coverage and fault detection of the test suite?
RQ5(performance): What is the runtime of Testler?
4.1 Subject Systems
Weinclude15subjectsystemsinourstudy.Ourselectioncriteria
forthesubjectsystemswasthattheyshouldusetheMavenbuild
system and to have executable JUnit4 test cases (as required by our
tool’s implementation), to be of various sizes in terms of lines of
code,andtospandifferentdomains.WeranTestlertoinferthe
testmodelsonthetestsuitesofthesubjectsystems.Forprojects
thatcomewithdifferentmodules,werepeatedtheanalysisonaper-
modulebasis.Table1providescharacteristicsofthesubjectsystems,
including their names, lines of Java production code counted using
cloc[8],linesoftestcode,numberoftestcases,aswellasnumber
and percentage of partly redundant tests.
4.2 Procedure and Results
Prevalence(RQ 1).Toassesstheprevalenceoffine-grainedredun-
dancies,wemeasuredthenumberoftestcasesthathaveatleastonecommonequivalentteststatementwithanothertestcase,whichwe
215
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Fine-Grained Test Minimization ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Table 1: Subject systems and their characteristics
Lines of Code (K) Test Cases
Prod. Test # Par. Redundant %
Collections 12 .32 0 .3 459 110 24
Math 45 .25 9 .1 3,990 1 ,354 34
Lang 26 .64 1 .6 2,344 604 26
Email 2 .73 .0 141 21 15
AssertJ 6 .42 4 .7 4,620 947 20
CheckStyle 16 .62 7 .0 1,865 164 9
PMD 42 .21 4 .3 465 192 41
LambdaJ 3 .64 .8 260 82 32
Java-library 24 .31 2 .2 611 86 14
JFreeChart 98 .51 7 .3 187 111 59
Accumulo 192 .91 3 .8 987 289 29
XmlSecurity 40 .03 2 .3 941 190 20
Crunch 24 .07 .2 452 78 17
Tika 60.51 7 .1 553 75 14
Log4J 46 .22 5 .0 1,475 336 23
Total/Average 642 .0 319 .6 19,350 4 ,639 24
callpartlyredundanttests .Todoso,weinferredthetestmodels
byrunningTestleronthetestsuitesofthesubjectsystems.For
each subject, we analyzed the inferred test suite model to identify
classes of equivalent test statements (see Section 2.5).
The fifth and sixth columns of Table 1 show the number and
percentage of partly redundant tests in the subject systems. Our
results show that 4,639 (24%) out of the total number of 19,350 test
cases in the test suites of our subject systems are partly redun-
dant.Redundanciesonindividualsubjectsystemsrangefrom9%
(CheckStyle) to 59% (JFreeChart).
Figure5showsboxplotsaboutthedistributionofredundanttest
statementsineachsubjectsystem.Weobservethatmostofthetests
of the studied subjects share between 1–7 common test statements.
This empirical data motivates further the need for an approach
capable of detecting fine-grained redundancies in tests.
Reduction (RQ 2).To assess the efficacy of our approach in reduc-
ing test statement redundancies, we ran Testler on the subject
systems.Testlerreorganizesredundanttestcasestoavoidrepeated
productionmethodcalls,thusreducingthenumberofredundant
teststatements.Thefirstmacro-columnofTable2(Redundancy)
presentsthenumberofpartlyredundant testcases beforerunning
Testler, the subset reducedby Testler, and the reduction per-
centage.Further,thetableshowsthenumberofpartlyredundant
test statements beforerunning Testler, the subset reducedby
Testler, and the achieved reduction percentage.
Onaverage,Testlerwasabletoremove43%oftheredundant
test statements, which also resulted in a reduction of 52% in the
number of test cases. Across all test suites, 4,639 partly-redundant
testcaseswerereorganizedinto2,236(4,639-2,403)tests,performed
byremoving5,041redundantteststatements.XmlSecurityisour
best case with 82% test reduction, obtained by discarding 98% re-
dundant test statements. The lowest reduction was obtained for
AssertJ (27%), by removing 40% redundant test statements. All test
cases that werereorganized passed successfully, withno errors or
failures. Our results confirm the design choice of our algorithm
Collections
Math
Lang
Email
AssertJ
CheckStyle
PMD
LambdaJ
JavaLibrary
JFreeChart
Accumulo
XmlSec
Crunch
Tika
Log4J2468101214
Figure 5: Distribution of redundant test statements per test
case in each subject system.
(see Section 3.1), which prioritizes the precision of redundancy de-
tectionoverthedetrimentoftherecall.WediscusswhyTestler
cannot eliminate all the partial redundancies in Section 5.
Execution time (RQ 3).To assess the effects of reducing redun-
dancy on test suite execution time, we measure the execution time
of the test suites beforeandafterthe reorganization by Testler.
To mitigate the variability effect of non-deterministic tests, we
performed the measurements 10 times and we report the averages.
Thesecondmacro-columnofTable2(ExecutionTime)showsthe
executiontimeof theoriginaltestsuite, theexecutiontimeofthe
reorganizedtestsuite,andthepercentageofreduction.Percentage-
wise, Testler was able to reduce test execution time across all
test suites by about 20%, with the lowest being Collections and
PMD(5%)andthehighestLambdaJ(37%).Forninesubjects(Collec-
tions,Lang,Email,AssertJ,CheckStyle,PMD,LambdaJ,Java-library,
JFreeChart),thetestsuitesraninlessthanoneminute.Theabsolute
executiontimereductionsforthose“fast”testsuitesrangebetween
0.211sofJFreeChart(-10%)and5.326sofCheckStyle(-20%).The
other six test suites (Math, Accumulo, XMLSecurity, Crunch, Tika,
Log4J)haveexecutionsthatrangebetween1.4and4.4minutes.For
those“slower”testsuites,theabsoluteexecutiontimereductions
range between 10.305 s of Math (-12%) and 63.644 s of Log4J (-24%).
Code Coverage and Fault Detection (RQ 4).We measured the
statement and branch coverage for each test suite before and after
reorganization, using EclEmma [10]. The third macro-column of
Table 2 (Code Coverage) shows these coverage numbers.
Tomeasurefaultdetectionrate,wemutatedeachsubjectsystem
using PIT[32]againstthetestsuitebeforeandafterourrefactoring.
Thefourthmacro-columnofTable2(FaultDetection)showsthe
mutation scores obtained. We also counted the number of testassertions in the original and the reorganized test suites, which
remained the same in all subject systems.
216
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden A. Vahabzadeh et al.
Table 2: Results
Redundancy Execution Time Code Coverage Fault Detection Analysis Time
Par. Red. Tests Red. Test Stmts Seconds % Stmt Branch Mut. Score CI/MG/TR (Tot)
Before (#)
Reduced (#)
Reduction (%)
Before (#)
Reduced (#)
Reduction (%)
Original
Reorganized
Reduction
Before (%)
Reduced (%)
Before (%)
Reduced (%)
Before (%)
Reduced (%)
Time (seconds)
Collections 110 52 47 210 165 79 17.359 16.440 5 84.784.7 72.372.3 40.0 40.0 71/70/183 (324)
Math 1,354 946 70 4,0521,623 40 83.109 72.804 12 92.792.7 85.785.7 79.0 79.0 101/401/1103 (1,605)Lang 604 335 55 1,533 563 37 11.053 10.376 6 92.992.9 57.557.5 66.0 66.0 38/43/372 (453)Email 21 10 48 38 12 32 7.143 5.933 17 54.654.6 50.950.9 48.0 48.0 10/12/3 (25)
AssertJ 947 253 27 516 207 40 3.389 2.794 18 95.695.6 92.292.2 63.0 63.0 244/37/383 (664)CheckStyle 164 77 47 258 122 47 26.361 21.035 20 95.495.4 96.896.8 17.0 17.0 172/625/216 (1,013)PMD 192 122 64 346 203 59 7.550 7.145 5 90.190.1 52.852.8 25.0 25.0 367/110/32 (508)LambdaJ 82 42 51 109 55 50 1.468 0.924 37 85.285.2 52.252.2 85.0 85.0 12/6/13 (31)
Java-library 86 37 43 338 71 21 2.062 1.851 10 96.096.0 60.760.7 54.0 54.0 58/97/215 (370)JFreeChart 111 56 50 1,657 374 23 2.752 2.485 10 95.595.5 47.647.6 24.0 24.0 45/52/205 (302)Accumulo 289 93 32 683 140 20 65.883 50.794 23 94.794.7 71.571.5 20.0 20.0 58/333/106 (497)XmlSecurity 190 156 82 1,1021,079 98 68.590 57.590 16 78.778.7 54.054.0 68.0 68.0 42/179/142 (363)Crunch 78 52 67 125 83 66 161.812137.657 15 94.594.5 74.474.4 31.0 31.0 27/123/20 (170)Tika 75 45 60 141 54 38 78.970 54.350 31 88.488.4 57.557.5 35.0 35.0 50/673/348 (1,071)
Log4J 336 127 38 711 290 41 261.987198.343 24 80.580.5 38.738.7 13.0 13.0 48/490/100 (638)
Total/Average4,6392,403 52 11,8195,041 43 799.488640.521 20 88.088.0 64.364.3 44.5 44.5 8,034/536
Overall,ourresultsshowthat(1)testassertionsremainintact,
(2) the statement and branch coverage are preserved, and (3) the
fault detection rate is unchanged, for all the subject systems.
Performance(RQ 5).ToassesstheperformanceofrunningTestler,
we measured the execution time on a macOS machine, equipped
witha 2.3GHz IntelCore i7and 16GB ofmemory. Table 2(Analy-
sis Time) shows the execution time in seconds, pertaining to the
three phases of our algorithm: code instrumentation (CI), model
generation(MG),andthetestsuitereorganization(TR),andtotal
(Tot).
In total, Testler took 8,034 seconds (2.2 hours) to analyze all
the 15 subjects test suites; 536 seconds (8.9 minutes) on average.
Email and Math were the extreme cases with 25 and 1,605 seconds,
respectively. This is not surprising as Testler found the least (21)
and the most (1,354) number of redundant test cases in Email and
Math, respectively. On average, code instrumentation (CI) required
approximately1.5minutes,themodelgeneration(MG)3.6minutes,
and the reorganization (TR) 3.8 minutes. Considering the analy-sis time in relation with the size of the test suites, Testler was
fastestonLambdaJ(0.12s/testcase)andslowestonTika(1.94s/test
case).Onaverage,acrossallsystems,theruntimeis0.42seconds
(8,034/19,350) for each test case to be analyzed, reorganized, and
recomposed.
5 DISCUSSION
In this section, we discuss some of our evaluation findings, tooldesign decisions and limitations, as well as threats to validity of
our study.Automation. Ourresultsconfirmthatovertime(1)testsuitestend
toaccumulateaconsiderablenumberofpartlyredundanttests,and
(2)fine-grainedredundanciesmaypertaintoteststatementsintests
acrossthewholetestsuite,and(3)ourtechniquecansafelyremove
nearlyhalfofthese redundanciesautomatically.Manuallyfinding
and reorganizing redundant tests to create a reduced test suite that
still preserves the coverage could be in fact quite challenging. Our
ownexperienceinreorganizingtests,whichwewererequiredto
dowhiledevisingTestler,corroboratesthedifficultyofthetask.
Forexample,forthe ComplexTest classofMath,whichiscomposed
of 139 tests, the authors spent approximately one hour to manu-
allydetecttheredundantstatementswithinthat singleclass,and
reorganize the tests in a way to retain the coverage; analyzing and
reorganizing the remaining 3,989 test classes would be practically
infeasible to perform manually.
Test Suite Evolution. As long as the SUT stays deterministic,
Testler preserves all the test states and assertions also during
softwareevolution,becausethemodeliscreatedandupdatedbased
ontheactualbehaviourofthetestsuite.Animportantfeatureof
Testleristhatthereducedtestsuitedoesnotneedtobeupdatedif
therearenochangesmadetothetests,aspartofacommit.Testler
savestheinferredtestmodelsothatthewholeanalysisdoesnot
needtoberepeatedeverytimeanewtestisaddedoranexistingoneischanged.Thismeansthatthetestmodelisonlypartiallyupdated
when the software evolves. Asdiscussed in our evaluations (RQ 5),
thetestanalysisprocesstooklessthanhalfasecondtocomplete
for each test case.
Readability. Weareawarethatmergingtestsmightaffecttheover-
all readability of the test suite. In our experiments (RQ 1), Testler
217
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Fine-Grained Test Minimization ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
mergedtestcaseshavingatleastonecommonequivalentteststate-
mentwithanothertestcase,becausewewereinterestedinassessing
the maximal capability of our technique at finding and eliminating
fine-grained redundancies (at the cost of producing larger merged
testclasses).Asfarasreadabilityisconcerned,inpracticethetester
cancustomizethegranularityoftheanalysistooptimizethebal-
ance between readability and redundancy reduction. That said, the
purposeofourworkisnottoreplacetheexistingtestsuite.Testler
keeps both the original and minimized versions of the test suite
andmaintainslinksbetweenthem.Thisenablestheusertotrace
back anyminimized testcase (or itsfailure) tothe test casein the
original test suite for better comprehension.
TestExecutionReductionandOverhead. Industrialprojectsof-
tengothroughnumerouschangesdaily,andthewholetestsuite
is executed after each change. For instance at Google, on a typical
workday,around 40,000changesarecommitted[ 33].Ourresults
showthatbyremovingfine-grainedredundancies,thetestexecu-
tiontimecanbeminimizedby20%onaverage,whichwasachieved
by removing around 12% of the initial 19,350 test cases in our eval-
uation.A20%reductionintestexecutiontimewouldadduptoa
substantialtestruntimereductionquickly.Inourevaluation,the20% reduction corresponds to about 11 seconds. Hypothetically
speaking,ifaminimizedtestsuiteisexecuted40,000timesaday,
this would save 122 hours per day. Thus, we believe the startupoverhead associated with our analysis can be amortized quickly
when considering high commit rates in practice.
AccuracyandEfficacy. OurevaluationresultsshowthatTestler
removed around half of redundant test statements automatically
and safely. All the test suites that were reorganized passed success-
fullyandthecoverageandfaultdetectionratesweremaintained.
Therefore, we believe Testler is accurate in its minimization task.
Regardingtheefficacyof Testler,weinvestigatedwhy allre-
dundant test statements were not reduced. We enumerate some of
themainreasonsnext,whichpertaintoboththeinherentnatureof
JUnittestsandsomeofourdesigndecisionsindevelopingTestler.
Our analysis does not have a fully sound handling of the following
features.
First,Testlercannotreorganizetestcasesthatterminateabruptly
as,forinstance,thosethat checkthatanexceptionisthrown(e.g.,
usingtheJUnitannotation @Test(expected=SomeException.class)) .
In our experiments, a similar behaviour was also simulated by
meansofthe returnand failstatements.Second,althoughtheuse
ofinheritanceintestcodeisdebatable[ 24],mostofoursubjectsys-
tems use inheritance in their test code. We chose not to reorganize
testcasesintestclassesthataresubclassedbyanothertestclass,
sinceinthiscasethesubclassmightoverridesomeofthetestcases
and render the reorganized test cases useless. Third, Testler does
not reorganize parameterized test cases, since in this case, the test
case will be run with different inputs and can only be merged with
another test case that has exactly the same inputs. Fourth, some
testsusecustomtestrunnerstoruntheirtestcases.Forexample,
inonecase,testcaseswouldberetriedseveraltimeswithacustom
runner until they would pass. In this scenario, we can only reorga-
nize test classes that have the same custom runner. Fifth, we chose
not to reorganize test statements inside conditionals such as ifs,
for-loops, and try-catch s. Sixth, since we do not store the variableidentityaspartofourteststate(Definition7),wedonotsupport
reorganizingtestcaseswith assertSame assertions.Finally,wedo
not reorganize flaky (non-deterministic) tests, multithreaded tests,
orteststhathaveread/writedependenciesonexternalresources
such as files or databases.
SideEffectsorTestDependencies. Inourevaluation,wedidnot
witness any issues with side effects of running tests or test depen-
dencies. By creating our test model from the dynamic execution
ofthetestcases,weconsiderpotentialsideeffectsanddependen-
cies of test statements and test states, using the state compatibility
notion, when reorganizing tests.
Applications. Testlercanbeusedbydeveloperstofindandmin-
imize redundant test statements. Our test suite model can also
be utilized for other test analysis activities, for instance, for testbug [
42] or test smell [ 43] detection. One of the tasks performed
duringtestrefactoringistoreorganizetestcasestoremoveeager
and lazy test smells [ 43]; in this case, our model can help with
the refactoring task, since it is not straightforward to manually
reorganizetestcasesinawaythatpreservesthebehaviourofthe
testsuite.Forinstance,ourtestmodelcanbeusedtoidentifysmall
test cases that have common test statements and merge them toremove lazy test smells. Our test model also facilitates going theother direction: it can be used to reorganize large test cases intosmaller ones, to remove the eager test smell, while keeping the
incurred redundancy at a minimum.
Although we evaluated Testler on desktop unit tests, we be-
lieve our technique can be even more effective in other domainsof testing, such as UI, mobile, or web, where the test execution
timemaybelonger.Forexample,testsdevelopedforthewebdo-
mainusingframeworkssuchasSeleniumhavegenerallyamuch
higherrunningcostthanunitteststhattestlow-levelJavamethods.
This is due to the overhead imposed by the interaction with the
GUI,thebrowserandthenetworklatency.Inthiscontext,weex-
pect Testler to be especially beneficial, because a minimized test
suitewouldcontainlesscallstothebrowser’sAPIsandserver-side
requests, resulting in a substantial decrease in test execution time.
Relation to Test Reduction Techniques. Traditional test suite
minimization seeks to eliminate redundant test cases in order toreduce the number of tests to run [
48]. Our technique seeks to
eliminate redundant statements in the whole test suite in order
toreducethenumberofteststatementstoexecute(asourresults
show,thisalsoresultsinareductionofthenumberoftestcases).
More importantly, a distinguishing characteristic of our work is
that we retain all the test assertions, which are known to be highly
correlated with test suite effectiveness [50].
RelationtoTestPrioritization/SelectionTechniques. Testpri-
oritizationseekstoordertestcasesinsuchawaythatearlyfault
detection is maximized, whereas test selection seeks to identify the
test cases that are relevant to the most recent changes [ 48]. Our
approachisorthogonaltothosetechniques,andcanbecombined
withthem.Minimizedtestcasescanstillbeprioritized.Ontheother
hand, test selection is change-driven. Although we do not target
software evolution in this paper, our technique can also be used to
applychange-relatedfine-grainedminimization.Also,asthetest
cases that we merge together have common test statements, it is
218
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden A. Vahabzadeh et al.
likelythat theytestthe samecomponent andthuscan beselected
together as part of a selection strategy.
Parallel/Virtualized Test Execution. A number of techniques
address the problem of long running test suites by running tests
in virtualized [ 4], or cloud-based parallel [ 14,25] environments.
Any of these techniques require complete test independency, a
requirement hard to meet in many real-world test suites including
those of our subject systems, which we ran sequentially. However,
such techniques can still be applied to test suites that Testler
minimizes.
ThreatstoValidity. Usingalimitednumberofsubjectsystemsin
our evaluation poses an external validity in terms of generalizabil-
ity of our results. We tried to mitigate this threat by choosing 15subject systems with various sizes, domains, and tests, although
weneedmoresubjectsystemstofullyaddressthegeneralization
threat. As reported in a recent empirical study of 20 large Java
systems[ 4],it isoftennotnecessary toresettheapplication prior
to test execution. Our results confirm this finding as we did not
witnessedanysideeffects.However,insometypesofapplicationsit
mightbenecessarytoresettheapplicationaftereachtestexecution
session.Withrespecttoreproducibilityofourresults,thesource
codeof Testlerandallsubjectsystemsareavailableonline[ 41],
making the evaluation repeatable and our results reproducible.
6 RELATED WORK
Thereisalargebodyofworkontestsuitereduction(minimization)
andtestselectiontechniques[ 5–7,19,20,22,23,29,30,34,39,40,
44,47,48], which have been proposed for removing redundant
test cases. These techniques use different coverage criteria, such as
statement or branch coverage to detect redundancies at the whole
testcaselevel.Althoughitispossibletousecoveragecriteriainour
approach, we chose to preserve the test suite behaviour and find
redundantpartsoftestcasesthatcallthesameproductionmethods
withexactlythesameinput.Asopposedtothesetechniquesthat
remove whole test cases, in this paper we tackle the problem of
partlyredundanttests,andwereorganizetestcasesbyremoving
only redundant test statements. This allows us to preserve the
original test suite’s coverage and retain all test assertions, without
affecting the fault finding capability.
Many techniques are proposed for regression test selection [ 11],
and use different levels of granularity for tracking dependencies,
suchasfiledependency[ 15]andclassdependency[ 31],todetect
affected test cases, as part of a change to production code. More
recently,techniqueshavebeenproposedthatcombinetestreduc-
tion, test selection, and test prioritization techniques [ 28,38,49].
However, none operates at the fine-grained test statement level.
Ourteststaterepresentationiscloselyrelatedtotheheaprep-
resentation used by Gyori et al. [18]. They store the portions of
the concrete heap accessible from static fields of test classes. Onthe other hand, in order to support test reorganization, we need
toincludelocalvariablesaswellasmembervariablesusedinthe
testclass.Ourstatealsoincludesinformationabouttheproduction
method calls that were responsible for the creation of a specific
value in the test state.
Some approaches entirely focus on reducing the test suite ex-
ecution time [ 4,16,27]. For instance, a recent work by Bell andKaiser[4] usesunit testvirtualization toreduce the timerequired
for the execution of a test suite, while leaving all the redundant
statements. Our work, on the contrary, focuses on identifying and
removing redundant test statements, which also results in test exe-
cution time reduction of the merged test suites. Moreover, in most
of our subjects, there are test dependencies and it is not always
possible to reset the system state prior to execution of tests.
Alipouretal. [1]presentanapproachthatreducesatestsuiteby
compromising a certain amount of coverage while preserving the
overallfault-findingability.Ourtechniquereducesthetestsuiteby
eliminatingredundantteststatementswhilepreservingboththe
original coverage and fault-finding ability.
Fangetal. [12]useassertionfingerprintstodetectsimilartest
casesthatcanberefactoredintoonesingletestcase.Theyperform
staticanalysisontestcodeand,byanalyzingthecontrolflowgraph,
theycomputebranchcount,mergecount,andexceptionalsuccessor
count for each assertion. Based on these attributes, they detect
refactoringcandidates. Ourapproach findsrefactoringcandidates
based on common redundant statements in test cases.
Guerraetal. [17]visuallyrepresenttestcaseswithagraphical
notationtohelpdeveloperswiththerefactoringactivity.Ourap-
proach makes sure that reorganizing test statements in the test
suite preserves its behaviour by closely examining the production
methods called from test cases.
Xuanetal. [45]splittestcasesintosmallerfragmentstoenhance
dynamic analysis, while Xuan and Monperrus [46] perform test
purification to improve fault localization. In these papers the goal
istoimprovedynamicanalysisbysplittingtestcasesintosmaller
units, whereas we aim at reducing redundancies in the test code
through test case reorganization.
FraserandWotawa [13]mergetestcasesgeneratedbyamodel
checkerbycomparingthestateoftheapplicationfordifferenttests
and merging only those for which a common prefix exists. Devaki
et al.[9] merge web applications GUI test cases to reduce test exe-
cution time. They define the state of the program as a combination
ofbrowser’sDOManddatabasestate.Theseapproachescanonly
interleavechunksofteststepsthatresultinthesamestate,whereas
ourapproachiscapableofreorganizingandinterleavingallvalid
refactorings among and across unit test cases.
7 CONCLUSIONS
In this paper, we proposed a test suite model that facilitates testcode analysis at the test statement level. We used the proposed
model to present an automated technique and tool, called Testler,
forminimizingfine-grainedstatement redundanciesintestcases,
while preserving the behaviour, coverage, test assertions, and fault
detection of the test suite. We empirically evaluated our technique
on 15 subject systems and overall, Testler was able to reduce the
numberofpartlyredundanttestcasesupto52%andtestexecutiontimebyupto37%,whilepreservingtheoriginaltestsuitecoverage
and production method call behaviour.
Forfuturework,weplantoinvestigatetheapplicationoffine-
grainedtestanalysisontestselectiontechniques.Wealsointend
to run Testler on more subject systems and extend the tool to
support web and mobile test suites.
219
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Fine-Grained Test Minimization ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]MohammadAminAlipour,AugustShi,RahulGopinath,DarkoMarinov,andAlex
Groce. 2016. Evaluating Non-adequate Test-case Reduction. In Proceedings of the
31st IEEE/ACM International Conference on Automated Software Engineering (ASE
2016).ACM,NewYork,NY,USA,16–26. https://doi.org/10.1145/2970276.2970361
[2]Apache Commons Math 2018. Lightweight, self-contained mathematics and sta-
tistics components. http://commons.apache.org/proper/commons-math. (2018).
[3]G. Bavota, A. Qusef, R. Oliveto, A. De Lucia, and D. Binkley. 2012. An empirical
analysis of the distribution of unit test smells and their impact on software
maintenance. In Proceedings of the 28th International Conference on Software
Maintenance (ICSM ’12). IEEE Press, Piscataway, NJ, 56–65.
[4]Jonathan Bell and Gail Kaiser. 2014. Unit Test Virtualization with VMVM. In
Proceedingsofthe36thInternationalConferenceonSoftwareEngineering (ICSE’14).
ACM, New York, NY, USA, 550–561. https://doi.org/10.1145/2568225.2568248
[5]J.Black,E.Melachrinoudis,andD.Kaeli.2004. Bi-criteriamodelsforall-usestest
suitereduction.In Proceedingsofthe26thInternationalConferenceonSoftware
Engineering (ICSE ’04). IEEE Computer Society, Washington, DC, USA, 106–115.
[6]T.Y. Chen and M.F. Lau. 1998. A new heuristic for test suite reduction. Infor-
mationandSoftwareTechnology 40,5(1998),347–354. https://doi.org/10.1016/
S0950-5849(98)00050-0
[7]T.Y. Chen and M.F. Lau. 1998. A simulation study on some heuristics for test
suite reduction. Information and Software Technology 40, 13 (1998), 777–787.
https://doi.org/10.1016/S0950-5849(98)00094-9
[8]Cloc 2018. Counts blank lines, comment lines, and physical lines of source code
in many programming languages. https://github.com/AlDanial/cloc. (2018).
[9]Pranavadatta Devaki, Suresh Thummalapenta, Nimit Singhania, and Saurabh
Sinha. 2013. Efficient and Flexible GUI Test Execution via Test Merging. In
Proceedings of the 2013 International Symposium on Software Testing and Analysis
(ISSTA’13).ACM,NewYork,NY,USA,34–44. https://doi.org/10.1145/2483760.
2483781
[10]EclEmma2018. JavaCodeCoverageforEclipse. http://www.eclemma.org.(2018).
[11]Emelie Engström, Per Runeson, and Mats Skoglund. 2010. A Systematic Review
onRegressionTestSelectionTechniques. InformationandSoftwareTechnology
52, 1 (Jan. 2010), 14–30. https://doi.org/10.1016/j.infsof.2009.07.001
[12]ZhengFelixFangandPatrickLam.2015. IdentifyingTestRefactoringCandidates
with Assertion Fingerprints. In Proceedings of the Principles and Practices of
ProgrammingonTheJavaPlatform (PPPJ’15).ACM,NewYork,NY,USA,125–
137. https://doi.org/10.1145/2807426.2807437
[13]GordonFraserandFranzWotawa.2007. RedundancyBasedTest-suiteReduction.
InProceedingsofthe10thInternationalConferenceonFundamentalApproaches
to Software Engineering (FASE ’07). Springer-Verlag, Berlin, Heidelberg, 291–305.
http://dl.acm.org/citation.cfm?id=1759394.1759425
[14]AlessioGambi,SebastianKappler,JohannesLampel,andAndreasZeller.2017.
CUT:AutomaticUnitTestingintheCloud.In Proceedingsofthe2017International
Symposium on Software Testing and Analysis (ISSTA ’17). ACM, New York, NY,
USA, 364–367. https://doi.org/10.1145/3092703.3098222
[15]MilosGligoric,LamyaaEloussi,andDarkoMarinov.2015. PracticalRegression
Test Selection with Dynamic File Dependencies. In Proceedings of the 2015 In-
ternationalSymposiumonSoftwareTestingandAnalysis (ISSTA’15).ACM,New
York, NY, USA, 211–222. https://doi.org/10.1145/2771783.2771784
[16]Alex Groce, Mohammed Amin Alipour, Chaoqiang Zhang, Yang Chen, and John
Regehr. 2014. Cause Reduction for Quick Testing. In Proceedings of the 7th
IEEE International Conference on Software Testing, Verification, and Validation
(ICST ’14). IEEE Computer Society, Washington, DC, USA, 243–252. https:
//doi.org/10.1109/ICST.2014.37
[17]Eduardo Martins Guerra and Clovis Torres Fernandes. 2007. Refactoring Test
CodeSafely.In ProceedingsoftheInternationalConferenceonSoftwareEngineering
Advances (ICSEA ’07). IEEE, Piscataway, NJ, 44–44.
[18]Alex Gyori, August Shi, Farah Hariri, and Darko Marinov. 2015. Reliable Testing:
DetectingState-pollutingTeststoPreventTestDependency.In Proceedingsofthe
2015 International Symposium on Software Testing and Analysis (ISSTA ’15). ACM,
New York, NY, USA, 223–233.
[19]Dan Hao, Lu Zhang, Xingxia Wu, Hong Mei, and Gregg Rothermel. 2012. On-
demand Test Suite Reduction. In Proceedings of the 34th International Conference
on Software Engineering (ICSE ’12). IEEE Press, Piscataway, NJ, USA, 738–748.
http://dl.acm.org/citation.cfm?id=2337223.2337310
[20]Mary Jean Harrold, Rajiv Gupta, and Mary Lou Soffa. 1993. A Methodology for
ControllingtheSizeofaTestSuite. ACMTransactionsonSoftwareEngineeringand
Methodologies 2, 3 (July 1993), 270–285. https://doi.org/10.1145/152388.152391
[21]BenediktHauptmann,ElmarJuergens,andVolkmarWoinke.2015. Generating
RefactoringProposalstoRemoveClonesfromAutomatedSystemTests.In Pro-
ceedings of the 23rd International Conference on Program Comprehension (ICPC
’15). IEEEPress, Piscataway, NJ,USA, 115–124. http://dl.acm.org/citation.cfm?
id=2820282.2820298
[22]DennisJeffreyandNeelamGupta.2007. ImprovingFaultDetectionCapabilityby
Selectively Retaining Test Cases During Test Suite Reduction. IEEE Trans. Softw.
Eng.33, 2 (Feb. 2007), 108–123. https://doi.org/10.1109/TSE.2007.18[23]James A. Jones and Mary Jean Harrold. 2001. Test-Suite Reduction and Priori-
tization for Modified Condition/Decision Coverage. In Proceedings of the IEEE
International Conference on Software Maintenance (ICSM ’01). IEEE Computer So-
ciety, Washington, DC, USA, 92–101. https://doi.org/10.1109/ICSM.2001.972715
[24]Petri Kainulainen. 2014. Three Reasons Why We Should Not Use InheritanceIn Our Tests. https://www.petrikainulainen.net/programming/unit-testing/
3-reasons-why-we-should-not-use-inheritance-in-our-tests. (2014).
[25]SebastianKappler.2016. FindingandBreaking TestDependencies toSpeedUp
TestExecution.In Proceedingsofthe24thACMSIGSOFTInternationalSymposium
on Foundations of Software Engineering (FSE ’16). ACM, New York, NY, USA,
1136–1138. https://doi.org/10.1145/2950290.2983974
[26]KenKennedyandJohnR.Allen.2002. OptimizingCompilersforModernArchi-
tectures:ADependence-basedApproach. MorganKaufmannPublishersInc.,San
Francisco, CA, USA.
[27]Shadi Abdul Khalek and Sarfraz Khurshid. 2011. Efficiently Running Test Suites
UsingAbstractUndoOperations.In Proceedingsofthe2011IEEE22NdInterna-
tional Symposium on Software Reliability Engineering (ISSRE ’11). IEEE Computer
Society, Washington, DC, USA, 110–119. https://doi.org/10.1109/ISSRE.2011.20
[28]Bogdan Korel, Luay Tahat, and Boris Vaysburg. 2002. Model based regression
test reduction using dependence analysis. In Proceedings of the International Con-
ference on Software Maintenance (ICSM ’02). IEEE Computer Society, Piscataway,
NJ, 214–223.
[29]MartinaMarréandAntoniaBertolino.2003. UsingSpanningSetsforCoverage
Testing.IEEETransactionsonSoftwareEngineering 29,11(Nov.2003),974–984.
https://doi.org/10.1109/TSE.2003.1245299
[30]ScottMcMasterandAtifMemon.2008. Call-StackCoverageforGUITestSuite
Reduction. IEEETransactionsonSoftwareEngineering 34,1(Jan.2008),99–115.
https://doi.org/10.1109/TSE.2007.70756
[31]Alessandro Orso, Nanjuan Shi, and Mary Jean Harrold. 2004. Scaling Regression
Testing to Large Software Systems. In Proceedings of the 12th ACM SIGSOFT
InternationalSymposiumonFoundationsofSoftwareEngineering(SIGSOFT’04/FSE
’12).ACM,NewYork,NY,USA,241–251. https://doi.org/10.1145/1029894.1029928
[32] PIT 2018. PIT Mutation Testing. http://pitest.org. (2018).
[33]Rachel Potvin and Josh Levenberg. 2016. Why Google Stores Billions of Lines
ofCodeinaSingleRepository. Commun.ACM 59,7(jun2016),78–87. https:
//doi.org/10.1145/2854146
[34]GreggRothermel,MaryJeanHarrold,JefferyOstrin,andChristieHong.1998. Anempiricalstudyoftheeffectsofminimizationonthefaultdetectioncapabilitiesoftestsuites.In ProceedingsoftheInternationalConferenceonSoftwareMaintenance
(ICSM ’98). IEEE Computer Society, Piscataway, NJ, 34–43. https://doi.org/10.
1109/ICSM.1998.738487
[35]Gregg Rothermel, Mary Jean Harrold, Jeffery Von Ronne, and Christie Hong.
2002. Empirical studies of test-suite reduction. Software Testing, Verification and
Reliability 12, 4 (2002), 219–249.
[36]StuartJ.RussellandPeterNorvig.2003. ArtificialIntelligence:AModernApproach
(2 ed.). Pearson Education.
[37]David Schuler and Andreas Zeller. 2011. Assessing Oracle Quality with Checked
Coverage. In Proceedings of the 4th IEEE International Conference on Software
Testing,VerificationandValidation(ICST’11).IEEEComputerSociety,Washington,
DC, USA, 90–99. https://doi.org/10.1109/ICST.2011.32
[38]August Shi, Tifany Yung, Alex Gyori, and Darko Marinov. 2015. Comparing and
CombiningTest-suiteReductionandRegressionTestSelection.In Proceedings
of the 10thJoint Meeting onFoundations of Software Engineering (ESEC/FSE’15).
ACM, New York, NY, USA, 237–247. https://doi.org/10.1145/2786805.2786878
[39]AdamM.Smith,JoshuaGeiger,GregoryM.Kapfhammer,andMaryLouSoffa.
2007. TestSuiteReductionandPrioritizationwithCallTrees.In Proceedingsofthe
22ndIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering (ASE
’07).ACM,NewYork,NY,USA,539–540. https://doi.org/10.1145/1321631.1321733
[40]Sriraman Tallam and Neelam Gupta. 2005. A Concept Analysis Inspired Greedy
Algorithm for Test Suite Minimization. In Proceedings of the 6th ACM SIGPLAN-
SIGSOFTWorkshoponProgramAnalysisforSoftwareToolsandEngineering(PASTE
’05). ACM, New York, NY, USA, 35–42. https://doi.org/10.1145/1108792.1108802
[41]Testler 2018. Refactoring Java test suites to eliminate fine-grained redundancies.
https://github.com/saltlab/Testler. (2018).
[42]ArashVahabzadeh,AminMilaniFard,andAliMesbah.2015. AnEmpiricalStudy
ofBugsinTestCode.In ProceedingsoftheInternationalConferenceonSoftware
Maintenance and Evolution (ICSME ’15). IEEE Computer Society, Piscataway, NJ,
101–110.
[43]A. van Deursen, L. Moonen, A. van den Bergh, and G. Kok. 2002. Refactoring
Test Code. In Extreme Programming Perspectives. Addison-Wesley, 141–152.
http://www.cwi.nl/~arie/papers/xp2001.pdf
[44]W.EricWong,JosephR.Horgan,SaulLondon,andAdityaP.Mathur.1995. Effect
ofTestSetMinimizationonFaultDetectionEffectiveness.In Proceedingsofthe
17thInternationalConferenceonSoftwareEngineering (ICSE’95).ACM,NewYork,
NY, USA, 41–50. https://doi.org/10.1145/225014.225018
[45]JifengXuan,BenoitCornu,MatiasMartinez,BenoitBaudry,LionelSeinturier,
and Martin Monperrus. 2016. B-Refactoring: Automatic test code refactoring to
improvedynamicanalysis. InformationandSoftwareTechnology 76(2016),65–
80. https://doi.org/10.1016/j.infsof.2016.04.016
220
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden A. Vahabzadeh et al.
[46]Jifeng Xuan and Martin Monperrus. 2014. Test Case Purification for Improving
Fault Localization. In Proceedings of the 22nd ACM SIGSOFT International Sympo-
siumonFoundationsofSoftwareEngineering (FSE’14).ACM,NewYork,NY,USA,
52–63. https://doi.org/10.1145/2635868.2635906
[47]Xue ying Ma, Zhen feng He, Bin kui Sheng, and Cheng qing Ye. 2005. A ge-
neticalgorithmfortest-suitereduction.In ProceedingsoftheIEEEInternational
Conference on Systems, Man and Cybernetics (SMC ’05). IEEE, Piscataway, NJ,
133–139.
[48]ShinYooandMarkHarman.2012. RegressionTestingMinimization,Selection
andPrioritization:ASurvey. SoftwareTesting,VerificationandReliability 22,2(March 2012), 67–120. http://dx.doi.org/10.1002/stv.430
[49]LingmingZhang,DarkoMarinov,andSarfrazKhurshid.2013. FasterMutation
TestingInspiredby TestPrioritizationandReduction. In Proceedingsof the2013
InternationalSymposiumonSoftwareTestingandAnalysis (ISSTA’13).ACM,New
York, NY, USA, 235–245. https://doi.org/10.1145/2483760.2483782
[50]Yucheng Zhang and Ali Mesbah. 2015. Assertions Are Strongly Correlated with
TestSuiteEffectiveness.In Proceedingsofthe10thJointMeetingonFoundations
of Software Engineering (ESEC/FSE ’15). ACM, New York, NY, USA, 214–224.
https://doi.org/10.1145/2786805.2786858
221
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. 