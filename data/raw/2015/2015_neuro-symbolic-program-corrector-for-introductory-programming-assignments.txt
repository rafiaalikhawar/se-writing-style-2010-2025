Neuro-Symbolic Program Corrector for Introductory
Programming Assignments
Sahil Bhatia
Netaji Subhas Institute of Technology
Delhi, India
sahilbhatia.nsit@gmail.comPushmeet Kohli
Google Deepmind
London, UK
pushmeet@google.comRishabh Singh
Microsoft Research
Redmond, USA
risin@microsoft.com
ABSTRACT
Automaticcorrectionofprogramsisachallengingproblemwithnu-
merous real world applications in security, verification, and educa-
tion.Oneapplicationthatisbecomingincreasinglyimportantisthe
correctionofstudentsubmissionsinonlinecoursesforproviding
feedback.MostexistingprogramrepairtechniquesanalyzeAbstract
Syntax Trees (ASTs) of programs, which are unfortunately unavail-
ableforprogramswithsyntaxerrors.Inthispaper,weproposea
novel Neuro-symbolic approach that combines neural networks
with constraint-based reasoning. Specifically, our method first uses
aRecurrentNeuralNetwork(RNN)toperformsyntaxrepairsfor
thebuggyprograms;subsequently,theresultingsyntactically-fixed
programs are repaired using constraint-based techniques to ensure
functionalcorrectness.TheRNNsaretrainedusingacorpusofsyn-
tacticallycorrectsubmissionsforagivenprogrammingassignment,
andarethenqueriedtofixsyntaxerrorsinanincorrectprogram-
mingsubmissionby replacingorinsertingthepredicted tokensat
the error location. We evaluate our technique on a dataset com-
prising of over 14,500 student submissions with syntax errors. Our
method is able to repair syntax errors in 60% (8689) of submissions,
and finds functionally correct repairs for 23.8% (3455) submissions.
CCS CONCEPTS
•Computing methodologies →Neural networks ;•Software
andits engineering →Functionality ;Search-based software engi-
neering;
KEYWORDS
NeuralProgramCorrection,AutomatedFeedbackGeneration,Neu-
ral guided search
ACM Reference Format:
Sahil Bhatia, Pushmeet Kohli, and Rishabh Singh. 2018. Neuro-Symbolic
Program Corrector for Introductory Programming Assignments. In ICSE
’18: ICSE ’18: 40th International Conference on Software Engineering , May
27-June 3, 2018, Gothenburg, Sweden. ACM,NewYork,NY,USA,11pages.
https://doi.org/10.1145/3180155.3180219
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.31802191 INTRODUCTION
Theincreasingimportanceofcomputinghasresultedinadramatic
growthinthenumberofstudentsinterestedinlearningprogram-
ming. Initiatives such as edX and Coursera attempt to meet this
demand by providing Massive Open Online Courses (MOOCs) that
areeasilyaccessibletostudentsworldwide.WhileMOOCshavenu-
merousbenefits,theireffectivenessoverthetraditionalclassroom
setting is limited by the challenge of providing quality feedback to
studentsontheirsubmissionstoopen-responseprogrammingas-
signments. We present a learning based technique to automatically
generate corrections for student submissions that in turn can be
used to generate feedback.
Most existing systems for automated feedback generation are
based on the functional correctness and style characteristics of
student programs. For instance, the AutoProf [ 27] system uses
constraint-basedsynthesistofindtheminimumnumberofchanges
toanincorrectstudentsubmissionthatwouldtransformittobe-
come functionally equivalent to a reference teacher implementa-
tion. Incontrast, theCodewebs system[ 17] adoptsa searchbased
approach where feedback generated by teachers on a handful ofsubmissions is propagated to provide feedback on thousands of
submissionsbyqueryingthedatasetusingcodephrases.Codewebs
allows querying the dataset of student submissions using "codephrases", which are subgraphs of AST in the form of subtrees,subforests, and contexts. These systems assume the availability
ofprogramASTs,whichunfortunatelydonotexistforprograms
with syntax errors. As an example, almost 20% of submissions in a
datasetweobtainedfromanintroductoryPythoncourseonedX
hadsyntaxerrors.Inthispaper,weproposeanovelNeuro-symbolic
programcorrectionapproachthatovercomesthisproblembyus-
ing a hybrid approach that combines deep neural networks with
constraint-based reasoning. While the neural networks are able to
correctsyntacticproblemswithstudentsubmissions,theconstraint-
based synthesis techniques allow for finding semantic corrections.
Aparticularlyinterestingaspectenabledbyourhybridapproachis
thatofgeneratingthecorrectusageofinfrequentvariablenames
in a student program.
Therearetwokeystepsinourapproach.Foragivenprogram-
ming problem, we first use the set of student submissions without
syntaxerrorstolearnamodeloftokensequences,whichisthenused to hypothesize possible fixes to syntax errors in a student
submission.Oursystemenumeratesoverthesetofpossiblemod-
ifications to the incorrect program in an ordered fashion to com-
pute the syntax error fixes. We use a Recurrent Neural Network
(RNN) [25] to learn the token sequence model that can learn large
contextual dependencies between tokens. In the second step, we
use constraint-based program synthesis (the Sketch solver [ 28])
602018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Sahil Bhatia, Pushmeet Kohli, and Rishabh Singh
to find minimal changes to the student program such that it be-
comes functionally equivalent to a reference implementation. Note
that the small size of student programs in this domain of intro-
ductoryprogramming(around10-20LOC)allowsforperforming
sophisticated search-based correction techniques.
Our approach is inspired from the recent pioneering work on
learningprobabilisticmodelsofsourcecodefromalargerepository
ofcodeformanydifferentapplications[ 1–4,13,19,24].Hindleet
al.[13]learnann-gramlanguagemodeltocapturetherepetitive-
nesspresentinacodecorporaandshowthatn-grammodelsare
effectiveatcapturingthelocalregularities.Theyusedthismodel
for suggesting next tokens that was already quite effective as com-
paredtothetype-basedstate-of-the-artIDEsuggestions.Nguyen
et al. [19] enhanced this model for code auto-completion to also
include semantic knowledgeabout the tokens (such as types)and
the scope and dependencies amongst the tokens to consider global
relationshipsamongstthem.TheNaturalizeframework[ 3]learns
an n-gram language model for learning coding conventions and
suggestingchangestoincreasethestylisticconsistencyofthecode.
More recently, some other probabilistic models such as conditional
randomfieldsandlogbilinearcontextmodelshavebeendeveloped
for suggesting names for variables, methods, and classes [ 4,24].
We also learn a language model to encode the set of valid token
sequences,butourapproachdiffersfrompreviousapproachesin
four key ways: i) our application of using a language model learnt
from syntactically correct programs to fix syntax errors is novel,
ii) since we cannot obtain the AST of the programs with syntaxerrors, many of these techniques that use the AST information
forlearningthe languagemodelarenotapplicable, iii)welearna
recurrent neural network (RNN) that can capture more complex
dependenciesbetweentokensthanthen-gramorlogbilinearneural
networks,andfinallyiv)insteadoflearningonelanguagemodel
for the complete code corpus, we learn individual RNN models for
different programming assignments so that we can generate more
precise repairs for different problems.
We evaluate our system on student solutions obtained from 9
programming problems taken from the Intro to Programming class
(6.00x) offered on edX. We consider 74818 student submissions
in total, out of which 14526 (19.4%)submissions have syntax er-
rors. Our technique can find repairs for fixing syntax errors for
59.8%(8689/14526)ofthesesubmissionsandfindssemanticrepairs
for23.8%(3455)ofthesubmissions.Tosummarize,thepapermakes
the following key contributions:
•Weformalizetheproblemofsyntaxcorrectionsinprograms
as a token sequence prediction problem using the recurrent
neural networks (RNN).
•We present the SynFixalgorithm that uses the predicted
token sequences for finding syntax repairs using a searchprocedure. The algorithm then uses constraint-based syn-
thesis to find minimal repairs for semantic correctness.
•We evaluate the effectiveness of our system on more than
14,500 student submissions.
2 MOTIVATING EXAMPLES
Inthissection,wepresentasampleofdifferenttypesofcorrections
oursystemisabletogenerateasshowninFigure2.Theexampleprograms,showninFigure2,comefromthestudentsubmissions
fordifferentproblemstakenfromtheIntroductiontoPythonPro-
gramming MOOC (6.00x) on edX.
Our syntax correction algorithm considers two types of parsing
errors in Python programs: i) syntax errors, and ii) indentation er-
rors.ItusestheoffsetinformationprovidedbythePythoncompilertolocatethepotentialerrorlocations,andthenusestheprogramto-kensfromthebeginningofthefunctiontotheerrorlocationasthe
prefixtokensequencetoquerytheRNNmodeltopredictthecor-
recting token sequences. The algorithm enumerates subsequences
ofpredictedsequenceinarankedordertogenerateproposalsfor
insertion or replacements at the error location. However, there are
manycases suchas theones shownin Figure2(c)where thecom-
piler is not able to accurately locate the exact offset location for
the syntax error. In such cases, our algorithm ignores the tokens
present in the error line and considers the prefix ending at the
previous line. Using the prefix token sequence, the algorithm uses
aneuralnetworktoperformthepredictionofnext ktokensthat
are most likely to follow the prefix sequence, which are then either
inserted at the error location or are used to replace the original
token sequence.
A sample of repairs generated by our algorithm (emphasized in
red)basedoninsertingthepredictedtokensattheoffsetlocation
isshowninFigure2(a).Thekindsoferrorsinthisclasstypically
include inserting unbalanced parenthesis, completing partial ex-
pressions(suchas exp-toexp-1),addingsyntactictokenssuchas
:afterifandelse, etc. Some example syntax errors that require
replacing the original tokens in the incorrect program with the
predictedtokensareshowninFigure2(b).Theseerrorstypically
includereplacinganincorrectoperatorwithanotheroperator(suchasreplacing =with*,=incomparisonswith ==),deletingadditional
mismatched parenthesis etc.
Since the compiler might not always accurately identify the
error location, oursystem predicts the complete replacementline
forsuchcasesasshowninFigure2(c).Theseerrorstypicallyinclude
wrongspellingofkeywords(e.g. retruninsteadof return),wrong
expression for the return statement etc. For fixing such syntax
errors,ouralgorithmgeneratestheprefixtokensequencethatendsatthelasttokenofthelineprevioustotheerrorline.Itthenqueries
the model to predict a token sequence that ends at a new line, and
replacestheerrorlinecompletelywiththepredictedline.Asample
of indentation errors is shown in Figure 2(d) and submissions that
requiremultiplefixesareshowninFigure2(e).Afterfixingasyntax
error, the algorithm iteratively calls itself to fix other errors.
Thefixestosyntaxerrorsinthecodemayormaynotcorrespond
to the correct semantic fix, i.e. the fixed program may not compute
the desired result. An end-to-end example of semantic repair is
shown in Figure 1. Since the Python compiler does not predict the
correct location for syntax error for this case, the RNN model uses
the previous line method to insert a new line while a%t != 0 or b%t
!=0as the suggested fix. This results in fixing the syntax error, but
introduces an unknown variable t. In the second phase, our system
usesanerrormodelconsistingofasetofrewriterulestomodify
different program expressions, and then uses the Sketch solver to
efficientlysearchoverthislargespacetocomputeminimalmodi-
fications toprogram such thatit becomes functionallyequivalent
withrespecttoateacher’simplementation.Forthisexample,we
61
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. Neuro-Symbolic Program Corrector for Introductory Programming Assignments ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
defgcdIter(a,b):
m=min(a,b)
whilea%m!=0:
orb%m!=0:
m = m + 1
returnmdefgcdIter(a,b):
m=min(a,b)
whilea%t!=0
orb%t!=0:
m = m + 1
returnm
def gcdIter (a,b): 
 m = min({a|m|b},{b|m|a}) 
 while {a|m|b}%{t|a|m|b}!= 0 
     or {b|m|a}%{t|a|b|m}!= 0: 
  m = {m|a|b} {+|-} 1 
  return mdef gcdIter (a,b): 
  m=min(a,b) 
  while a% m!=0                     or b%m!=0: 
    m = m - 1 
  return  m
Sketch
Figure 1: An end-to-end correction example: the RNN model first fixes the syntax error by replacing line 3 but introduces
an unknown variable t. The second phase applies an error model to introduce various replacement choices and uses Sketchto find minimal repair for the input program to be functionally correct. An expression of the form {a|b|c}denotes a choice
expression, where the Sketch compiler can choose any expression amongst them. The first option in the choice expression
denotes the default expression with cost 0, while all other options result in a cost of 1.
defgcdRecur(a, b):
ifb= =0 :
return a
x,y=max(a,b), min(a,b)
return gcdRecur(x
−y,y)defrecPower(b, e):
ife< =0 :
return 1
return b∗recPower(b, e −1)
(a) SyntaxError - Insert Token
defisWordGuessed(sWord, lGuess):
result=True
forsinsWord:
if!not(sinlGuess):
result=False
return resultdefrP(b, e):
t=b
if(e==0):
return t
else:
t∗=b
return t+rP(b,e −=11))
(b) SyntaxError - Replace Token
defrecPower(b, e):
fe= =1 :
i fe= =1 :
return b
return b∗recPower(b, e −1)defrecPower(b, e):
ife= =1 :
return b
ife>1 :
return e -= 1
returnb*r ec P o w e r (b ,e-1)
(c) SyntaxError - Previous Line Insert
defrecPower(b, e):
ife= =0 :
return 1
return 1
return b∗recPower(b,e −1)defrecPower(b, e):
x=b
while(e > 0):
x∗=b
-= 1
e- =1
return b
(d) Indentation Error - Insert Token
defrecPower(b, e):
ife= =1 :
return e
return b + recPower(b, e −-1)defgcdIter(a, b):
mi=min(a,b)
while a%mi!=0 :orb%mi!=0 :
mi−=1
return mi
(e) Multiple Errors - Combination of Insert, Replace, Previous Line
Figure2:AsampleofexamplesyntaxfixesgeneratedbytheRNNmodelforthestudentsubmissionswithsyntaxerrors.The
fix suggestions are emphasized in red font, whereas the expressions removed are emphasized in blue with a frame box.
useasimpleerrormodelforbrevitythatcanreplaceavariablein
assignments and conditionals with any other variable, and replace
an operator with +or-. Sketch is then able to identify the correct
semantic fix that replaces twithmiand changes +to-in line 4.3 NEURO-SYMBOLIC REPAIR ALGORITHM
AnoverviewoftheworkflowofoursystemisshowninFigure3.
Foragivenprogrammingproblem,wefirstusethesetofallsyn-
tactically correct submissions to learn a generative token sequence
62
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Sahil Bhatia, Pushmeet Kohli, and Rishabh Singh
SynFix
Syntactically Correct 
Student Submissions
Student Submission 
with Syntax ErrorsCorrected
ProgramLearnt Model
SketchError Model
Figure 3: An overview of the system workflow.
modelusinganRNN[ 30].Thesequencemodelsareproblem-specific
and we learn different models for different problems. We then use
theSynFixalgorithmtofindsmallsyntacticcorrectionstoastudent
submission by modifying the submission with the token sequences
predicted by the learnt model. Finally, we use the Sketch [ 28] syn-
thesis system to find minimal modifications (defined by rewrite
rules) to the syntactically-repaired program such that the program
becomes functionally correct with respect to a reference imple-
mentation. We now briefly describe the three key phases in our
workflow:i)thetrainingphase,andii)the SynFixalgorithm,and
iii) Sketch-based synthesis.
3.1 RNN-based Language Model
TheRecurrentNeuralNetwork(RNN)isageneralizationoffeedfor-
wardnetworksthatcanencodesequencesofvariablelengthand
RNNs have been shown to be effective in many domains such as
machinetranslation[ 31]andspeec hrecognition[ 7].Wefirstuse
the syntactically correct student submissions to obtain the set of
all valid token sequences and then use a threshold frequency value
to decide whether to relabel a token to a general IDENTtoken for
handlingrarelyusedtokens(suchasinfrequentvariable/method
names). A token is encoded into a fixed-length one-hot vector,
wherethesizeofthevectorisequaltothesizeofthetrainingvo-
cabulary. In the training phase, we provide the token sequences to
theinputlayeroftheRNNandtheinputtokensequenceshiftedleft
by1asthetargettokensequencetotheoutputlayerasshownin
Figure4(a).Afterlearningthenetworkfromthesetofsyntactically
correct token sequences, we use the model to predict next token
sequencesgivenaprefixofthetokensequencetotheinputlayer
asshowninFigure4(b).Thefirstoutputtokenispredictedatthe
output layer using the input prefix sequence. For predicting thenext output token, the predicted token is used as the next input
token in the input layer as shown in the figure.
We first present a brief overview of the computational model
of a simple RNN with a single hidden layer. Consider an input
sequence oflength Land anRNN with Inumber of inputs,a single
hidden layer with Hnumber of hidden units, and koutput units.
Letxt∈RIdenote the input at time step t(encoded as a vector),
ht∈RHdenotethehiddenstateattimestept, W∈RH×Idenote
the weight matrix corresponding to the weights on connections
frominputlayertohiddenlayer, V∈RH×Hbetheweightmatrix
from hidden to hidden layer (recursive), and U∈RI×Hbe the
weightmatrixfromhiddentotheoutputlayer.Thecomputationmodel of the RNN can be defined as following:
ht=f(W∗xt+V∗ht−1);ot=softmax(U∗st)
The hidden state htat time step tis computed by applying a
non-linearfunction f(e.g.tanhorsigmoid)toaweightedsumof
the input vector xtand the previous hidden state vector ht−1. The
output vector otis computed by applying the softmaxfunction to
theweightedstatevectorvalueobtained stobtainedbyanaffine
transformation U∗ht. The hidden units take the weighted sum
as input and map it to a value in the set (-1,1) using the sigmoid
functiontomodelnon-linearactivationrelationships.TheRNNs
can be trained using backpropagation through time (BPTT) [ 32]t o
calculatethegradientandadjusttheweightsgivenasetofinput
and output sequences.
3.2 The SYNFIX Algorithm
Wefirstpresentthe SynFixOne algorithmthatfixesthefirstsyntax
errorinthestudentsubmission(ifpossible),andthenpresentthe
SynFix algorithm to fix multiple syntax errors.
Fixing one syntax error: TheSynFixOne algorithm, shown
in Algorithm. 1, takes as input a program P(with syntax errors)
and a token sequence model M, and returns a program P/primewith
its first syntax error on the error location fixed (if possible) or ϕ
denoting that the syntax error can not be fixed. The algorithm first
uses a parser to obtain the type of error errand the token location
locwhere the first syntax error occurs, and computes a prefix of
the token sequence /tildewideTprefcorresponding to the token sequence
startingfromthe beginning oftheprogramuntiltheerrortokenlocationloc. We use the notation
a[i..j]to denote a subsequence
ofasequence astartingatindex i(inclusive)andendingatindex
j(exclusive).Thealgorithmthenqueriesthemodel Mtopredict
the token sequence /tildewideTkof a constant length kthat is most likely to
follow the prefix token sequence.
Afterobtainingthetokensequence /tildewideTk,thealgorithmsearches
over token sequences /tildewideTk[1..i]of increasing lengths (1 ≤i≤k)
until either inserting or replacing the token sequence /tildewideTk[1..i]at
theerrorlocationresultsinaprogram P/primewithnosyntaxerrorat
the error location. If the algorithm cannot find a token sequencethat can fix the syntax error at loc, the algorithm then creates
another prefix
/tildewideTprev
prefof the original token sequence such that it
ignoresallprevioustokensinthesamelineasthatoftheerrortoken
location.Itthenpredictsanothertokensequence /tildewideTprev
kusingthe
modelforthenewtokensequenceprefix,andselectsasubsequence
/tildewideTprev
k[1..m]that ends at a new line token. Finally, the algorithm
checksifreplacingthelinecontainingtheerrorlocationwiththe
predictedtokensequenceresultsinfixingthesyntaxerror.Ifyes,
it returns the fixed program P/prime.
Example :ConsiderthePythonprogramshowninFigure5(a).
The Python parser returns a syntax error in line 2 with the error
offset corresponding to the location of the =token. The SynFix
algorithm first constructs a prefix of the token sequence consist-
ing of tokens from the start of the program to the error loca-
tion such that /tildewideTpref=[’def’,’recPower’ ,’(’,’b’,’,’,’e’,’)’,’:’,’\r\n’,
’\t’,’if’,’e’]. It then queries the learnt model to predict the most
likelytokensequencethatfollowstheinputprefixsequence.Letus
assumekis 3 and the model returns the predicted token sequence
63
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. Neuro-Symbolic Program Corrector for Introductory Programming Assignments ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
if exp == 1 :exp == 1 :
\r\n\r\n \t
Input LayerHidden LayerOutput Layer
\
 if exp ==1 :\r\n \t
Input TokensPredicted Tokens
(a) Training Phase (b) Prediction Phase
Figure4:ThemodelingofoursyntaxrepairproblemusinganRNNwith1hiddenlayer.(a)Weprovideinputandoutputtoken
sequences in the training phase to learn the weight matrices. (b) In the prediction phase, we provide a token sequence to the
input layer of the RNN and generate the output token sequences using the learnt model.
Algorithm 1 SynFixOne
Input:buggy program P, token sequence model M
(err,loc):=Parse(P);/tildewideT:=Tokenize( P)
/tildewideTpref:=/tildewideT[1..loc];/tildewideTk:=Predict(M ,/tildewideTpref)
fori∈range(1,k)do
P/prime
ins:=Insert(P,loc,/tildewideTk[1..i])
ifFixed(P/prime
ins,loc)returnP/prime
ins
P/prime
repl:=Replace(P,loc,/tildewideTk[1..i])
ifFixed(P/prime
repl,loc)returnP/prime
repl
end for
/tildewideTprev
pref:=/tildewideT[1..lprev(loc)];/tildewideTprev
k:=Predict(M ,/tildewideTprevpref)
P/primeprev:=ReplaceLine( P,line(loc),/tildewideTprev
k[1..m])
ifFixed(P/primeprev,,loc)returnP/primeprev else return ϕAlgorithm 2 SynFix
Input:buggy program P, sequence model M, max
fixesf
fori∈range(1,f+1)do
P/prime:=SynFixOne( P,M)
ifP/prime==ϕreturnϕ
ifParse(P/prime)=ϕreturnP/prime
elseP:=P/prime
end for
returnϕ
/tildewideTk=[’==’,’0’,’:’].Thealgorithmfirsttriestousethesmallerpre-
fixes of the predicted token sequence (in this case ’==’)t os e ei f
the syntax error can be fixed. It first tries to insert the predicted
token sequence ’==’in the original program but that results in the
expression ife===0:,whichstillresultsinanerror.Itthentries
to replace the original token sequence with the predicted token
sequence, which results in the expression i fe= =0 : that passes the
parser check, and returns the fixed program.
Fixing multiplesyntax errors: TheSynFixalgorithm shown
in Algorithm. 2 takes as input the buggy student submission P, the
tokensequencemodel M,andaparameter fdenotingthemaxi-
mum number of syntax corrections considered by the algorithm,
and returns either the fixed program P/primeobtained using fewer than
fnumber ofcorrectionsor ϕotherwise.The algorithmiteratively
callstheSynFixOne (amaximumof ftimes)tofixonesyntaxerror
inPat a time. Some example programs requiring multiple fixes are
shown in Figure 2(e).3.3 Constraint-based Semantic Repair
Afterobtainingasyntacticallycorrectprogramusingthe SynFix
algorithm, our system uses a technique similar to that of Auto-
Prof to findminimal transformations to thestudent program such
that it becomes functionally equivalent with respect to a refer-ence implementation. The class of transformations are definedusing a generic error model comprising of five different typesof transformations
R(rewrite rules): 1) Comparison operators:
cop→{<|≤|>|≥|!=|==}(i.e. a comparison operator
can be modified to any of the operators in the right hand set), 2)
Arithmeticoperators: aop→{+|−|∗|/|%},3)Variablereplacement:
v→?von RHS of assignments and expressions, where ? vdenotes
the set of all variables live at the program location, 4) off-by-one
errors:a→{a+1,a−1,0,1},and5)Constantmodification: n→??,
where??denotes any integer constant value. For example, the first
rewrite rule states that any comparison operator in the student
program can be potentially rewritten to any of the operator in the
set{<|≤|>|≥|!=|==}. Since this results in a huge search
spaceofprogrammodification,weuseaconstraint-basedsynthesis
64
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Sahil Bhatia, Pushmeet Kohli, and Rishabh Singh
solverSketchtosolveforminimalnumberofmodificationssuch
that the student program becomes functionally correct as follows.
∃P/prime∀in:P/prime=Rewrite(P,R)∧PT(in)=P/prime(in)∧min(Cost( P,P/prime))
(1)
The above constraint requires Sketch to find a program P/primein
the space of programs obtained from the rewrite rules Rsuch
thatP/primeis functionally equivalent with respect to the reference
implementation PTandP/primerequiresminimalnumberofapplications
of the rewrite rules. More details about how Sketch solves the
above constraint using the Cegis algorithm can be found in [28].
Consider the program shown in Figure 5(b), which requires 4
corrections.Theprogramusesanundefinedvariable tandusesthe
wrongcomparisonexpressions a%t != 1insteadof a%mi != 0 .Given
thisprogram,Sketchusesthegenericerrormodeltoidentifythe
correct loop comparison expression a%mi != 0 or b%mi != 0, which
results in a functionally correct program.
4 EVALUATION
We evaluate our system on 74 ,818 Python submissions obtained
fromtheIntrotoProgramminginPythoncourse(6.00x)ontheedX
MOOC platform. Our benchmark set consists of student submis-
sionsfor9programmingproblems,whichasksstudentstowriteiterative or recursive functions over integer, string, and list data
types.Thenumberofsubmissionsforeachprobleminourevalu-
ationsetisshowninTable1andasignificantfractionofstudent
submissions have syntax errors (19 .41%). Using the evaluation, we
aimtoanswerthefollowingresearchquestions:1)Howwellour
algorithm is able to repair syntax and semantic errors?, 2) What
algorithmicchoicesarechoseninthe SynFixalgorithmforfixing
the errors?, 3) How do problem-specific models compare with gen-
eral models?, and finally 4) How does the RNN language model
compares with an n-gram baseline model.
4.1 Benchmarks
Our benchmark set consists of student submissions for 9 program-
mingproblems recurPower, iterPower, oddTuples, evalPoly, com-
pDeriv,gcdRecur, hangman1, hangman2,and gcdItertakenfrom
theedXcourse.Theseproblemsaskstudentstowriteiterativeor
recursive functions over integer, string, and list data types, and
requires students to use different language constructs such as con-
ditionals,nested loops,functions,list comprehensionsetcto solve
the problems. The recurPower problem asks students to write a
recursivefunctionthattakesasinputanumber baseandaninteger
exp,andcomputesthevalue baseexp.TheiterPower problemhas
the same functional specification as the recurPower problem but
asks studentsto writean itervative solutioninstead ofa recursive
solution. The oddTuples problem asks students to write a function
that takes as input a tuple land returns another tuple that consists
of every other element of l. TheevalPolyproblem asks students to
writeafunctiontocomputethevalueofapolynomialonagiven
point, where the coefficients of the polynomial are represented us-
ing a list of doubles. Finally, the compDeriv problem asks students
to write a function to return a polynomial (represented as a list)
thatcorrespondstothederivativeofagivenpolynomial.Thedistri-butionofthelinesofcode(LOC)fordifferentbenchmarkproblemsis shown inFigure 6.The overallmean is7.13 LOCwith astandard
deviation of 3.52.
The number of student submissions for each problem in our
evaluationsetisshowninTable1.Intotalourevaluationsetconsists
of 74,818 student submissions. The number of submissions for the
evalPoly andcompDeriv problems are relatively fewer than the
numberofsubmissionsfortheotherproblems.Thisisbecausethese
problems were still in the submission stage at the time the data
snapshotwasobtainedfromtheedXplatform.Butthisalsogives
us an opportunity to evaluate how well our technique performs
when we have thousands of correct attempts in the training phase
ascomparedtoonlyafewhundredattempts.Anotherinteresting
facttoobservefromthetableisthatasignificantfractionofstudent
submissions have syntax errors (19 .41%).
TrainingPhase: Thetokensequencemodelforagivenproblem
is learnt over all the problem submissions without syntax errors.
Thesubmissionsarefirsttokenizedintoasetofsequenceoftokens(withtokensoccurringbelowathresholdrenamedas ident),which
are then fed into the RNN. We used a learning rate of 0 .002, a
sequence length of 10, and a batch size of 50. We use the batchgradient descent method with rmsprop (decay rate 0.97) to learn
theweights,wherethegradientswereclippedatathresholdof1.
WeuseRNNwithLSTMcellsconsistingof2hiddenlayerseachwith
128 hidden units and train the model for 50 epochs. We also varied
thenumberofhiddenlayers(1/2),thehiddenunits(128/256),and
the type of RNN cells (RNN/LSTM), but did not observe significant
changes in correction accuracy.
4.2 Number of Corrected Submissions
TheoverallresultsofoursystemisshowninTable1.The SynFix
algorithmisabletogeneraterepairstofixthesyntaxerrorsin8689
(59.8%)programs. Amongst these repaired programs, 2051 (14.12%)
of the programs are also semantically correct – i.e. the repaired
programsexhibitthedesiredfunctionalbehavior.UsingtheSketch
systemwithagenericerrormodel,oursystemisabletogenerate
semantically correct repairs for 3455 (23.78%)of the submissions.
The average time taken by the SynFixto repair syntax errors is
1.15sand by Sketch to generate semantic repair is 2 .7s.
We observe that even with relatively fewer number of total
attempts for the evalPoly andcompDeriv problems, the system
isabletorepairasignificantnumberofsyntaxerrors(50 .3%and
55.73% respectively). The average number of tokens per problem is
331,458, whereas the average vocabulary size for training RNNs
is only 626. This implies that there are a large number of common
identifiernamessharedacrosslargenumberofstudentsubmissions.
Fortheresultsshowninthetable,weuseavocabularythreshold
value oft=4. Additionally, a large fraction of syntax errors can
befixedusingonly1repair(6966),buttherearestillasignificant
number of submissions (1723) that are repaired by considering
additional changes.
Anotherinterestingobservationisthatthedifferencebetween
vocabulary size (number of unique tokens) and the training vocab-
ulary obtained after removing tokens below the threshold is not
verylarge–implyingthattherearemanypopularidentifiernames
thataresharedacrosssubmissionsthatthelanguagemodelcanuse
for prediction. Finally, the number of semantic corrections is the
65
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. Neuro-Symbolic Program Corrector for Introductory Programming Assignments ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
defrecPower(b, e):
ife=0 :
return 1;
else:
return b∗recPower(b,e −1)defgcdIter(a, b):
mi=min(a,b)
while a%t!=1 orb%t!=1:
mi−=1
return mi
(a) (b)
Figure 5: (a) A submission with syntax error in line 2 (= instead of ==), (b) A syntactically correct but semantically incorrect
program generated by SynFix algorithm.
Problem Total Syntax Errors Total Training Syntax Semantic RNN + Sketch
Attempts (Percentage) Tokens Vocab Fixed Fixed Semantic Fix
recurPower 10247 2071 (20.21%) 3389858 117 1309 (63.21%) 663 (32.01%) 955 (46.11%)
iterPower 11855 2661 (22.45%) 3558849 526 1864 (70.05%) 401 (15.07%) 667 (25.07%)
oddTuples 29120 4905(16.84%) 1167877 1053 2976 (60.67%) 165 (3.37%) 654 (13.34%)
evalPoly 1148 324 (28.22%) 55370 276 163 (50.31%) 39 (12.04%) 67 (20.68%)
compDeriv 528 323 (61.18%) 18557 150 180 (55.73%) 54 (16.72%) 84 (26.00%)
gcdRecur 7751 1421(18.33%) 275476 274 829 (58.34%) 426 (29.98%) 484 (34.06%)
hangman1 2040 192(9.41%) 106970 398 79 (41.14%) 14 (7.29%) 36 (18.75%)
hangman2 1604 101(6.29%) 108662 546 53 (52.48%) 8 (7.92%) 23 (22.77%)
gcdIter 10525 2528(24.01%) 552405 741 1236 (48.89%) 281(11.15%) 485 (19.18%)
Total 74818 14526(19.4%) 2983124 453 8689(59.8%) 2051(14.1%) 3455(23.8%)
Table 1: The overall results of the SynFix algorithm on 9 benchmark problems.
ProblemIncorrectSyntactically Fixed Num. of Fixes
Offset Offset-1PrevLine f=1f=2Attempts Insert Replace Insert Replace
recurPower 2071 55 55 574 832 1128 1022 287
iterPower 2661 15 14 746 964 1488 1559 305
oddTuples 4905 198 192 1279 1765 2106 2311 665
evalPoly 324 8 6 49 48 147 135 28
compDeriv 323 2 2 53 80 147 129 51
gcdIter 2528 34 44 637 640 927 1013 223
hangman1 192 1 7 24 43 64 6514
hangman2 101 2 3 23 18 44 47 6
gcdRecur 1421 20 19 332 620 732 685144
Total 14526 335 342 3717 5010 6783 69661723
Table 2: The detailed breakdown of the algorithmic choices taken by SynFix.
Figure6:Thedistributionoflinesofcode(LOC)fordifferent
benchmark problems.highest for recursive problems as compared to other problems that
ask for imperative solutions.
Adetailedbreakdownofthechoicestakenbythe SynFixalgo-
rithm is shown in Table 2. The table reports the number of cases
forwhichthesyntaxerrorswerefixedbythepredictedtokense-
quences using different algorithmic choices: i) Offset:the prefix
token sequence is constructed from the start of the program to the
error token reported by the parser, ii) Offset-1: the prefix token
sequence is constructed upto one token before the error token,
iii)PrevLine : the prefix token sequence is constructed upto the
previouslineandtheerrorlineisreplacedbythepredictedtoken
sequence,(iv) Insert:thepredictedtokensequenceisinsertedat
the Offset location, and (v) Replace: the original tokens starting at
66
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Sahil Bhatia, Pushmeet Kohli, and Rishabh Singh
010203040506070
recurPower iterPower oddTuples evalPoly com pDeriv gcdRecur hangman1 hangman2 gcditerPercentage of Submissions FixedProblem-specific vs General Models
Specific
 General
Figure 7: The performance of problem-specific models vs
general models trained on all the problems.
the Offset location are replaced by the predicted token sequence.
The table also reports the number of repairs that require 1 and 2
changes. We can observe that there is no one single choice that
worksbetterthaneveryotherchoice.Thismotivatestheneedofthe
SynFixalgorithm that tries all of the different algorithmic choices
in the order of first finding an insertion or a replacement fix us-ing the predicted token sequences of increasing length and thenusing the Previous Line method. We use this ranking order over
thechoicestopreferrepairsthatresultinsmallerchangestothe
original program.
First,wecanobservethatgeneratingtheprefixtokensequences
for querying the language model that end at one token earlier than
the error token ( Offset-1) performs significantly better than using
prefixsequencesthatendattheerrortoken( Offset).Second,the
PrevLine choiceperformsthebestcomparedtootherchoices.The
reason for this is that the algorithm has more freedom to make
largerchangestotheoriginalprogrambycompletelyreplacingthe
error line,but it may sometimesalso lead toundesirable semantic
changes. The Previous line changes are explored only after trying
out the Insertion/Replace choices in the SynFixalgorithm. The
replacement of original tokens with the predicted token sequences
performsalittlebetterthantheinsertionchoice.Finally,weobserve
that there are many student submissions that are fixed uniquely
by each one of the 5 choices, and the algorithm therefore needs to
consider all of the choices.
We also report the number of submissions that need 1 and 2
changes. A large fraction of submissions can be fixed using only 1
repair(6966),buttherearestillasignificantnumberofsubmissions
(1723) that are repaired by considering additional changes. We
observeasmallinsignificantincreaseinthenumberofadditional
repaired programs when considering f>2 number of changes.
4.3 General vs Problem Specific Models
Wenowpresentanexperimenttoevaluatewhetherweneedtotrain
separate token sequence models per problem or one global general
modelcanperformequallywell.Forevaluatingthisquestion,we
perform two sets of experiments. For the first experiment, we train
a general model using the set of all correct submissions for all the
benchmark problems, and compare its performance with that of
problem-specificmodelsthataretrainedindividuallyonlyonthe
correctsolutionsforagivenproblem.Forthesecondexperiment,wetrainamodelonlyonthecorrectsubmissionsforaparticularbench-markproblem(recurPower)tocorrecttheremainingproblems,andcompare its performance with the problem-specific models. Thesecond experiment is performed to evaluate how well the tokenmodels learnt from one problem (with a large number of diverse
solutions)generalizetootherproblems.Thecomparisonsareper-
formedbased onthe numberof submissionsthat aresyntactically
fixed with one ( f=1) fix.
TheresultsforthefirstexperimentareshowninFigure7.Overall,
the general model performs comparable to the problem-specificmodels. In total, the general model fixes syntax errors for 6833
studentsubmissionscomparedto6966fixedbytheproblem-specific
models. Moreover, for two problems, gcdRecur andgcdIter, the
general model performs a little better than the problem-specific
models.Thisresultshowsthatitmightnotbenecessarytomaintain
and train separate models per problem, and a global general model
trained on all the problems together can work almost as well in
most of the cases.
For investigating how well the token sequence models learnt
fromoneproblem generalizetoanotherproblem,we performthe
secondexperiment.WetraintheRNNmodelonthesyntactically
correctsubmissions forthe recurPower problem anduseit toper-
form corrections on submissions to other problems. The results for
this experiment are shown in Figure 8(a). We can observe that the
problem-specificmodelconsistentlyfixesmorenumberofsyntax
errors as compared to the recurPower language model. In total, the
recurPower model fixes 5217 submissions whereas the problem-
specific models repair about 14% more number of submissions
(5944).Inaddition,wealsoempiricallyobservethatthefixesgen-
erated by problem-specific models resulted in significantly higher
semantically correct fixes in comparison to the fixes generated by
therecurPower model.ThisresultshowsthatfortheRNNmodelto
perform well on a larger number of submissions to a new problem,
itneedstobetrainedonatleastsomecorrectprogramsfromthe
new problem.
4.4 Comparison with N-gram Baseline
WecomparetheeffectivenessofusinganRNNmodeltolearntoken
sequences over using an N-gram language model with N=5. The
5-gram model first queries the model with a prefix of 4 tokens and
returns the next token if one exists. Otherwise, it falls back to 3size token sequence and so on until it finds one in the frequency
dictionary.Weperformthestandardadd-1smoothingon5-gram
models. The results are shown in Figure 8(b). The RNN modelsignificantly outperforms the N-gram model consistently across
allproblems.TheN-grammodelintotalcanfixsyntaxerrorsfor
4016 problems (27.65%), whereas the RNN language model can fix
errorsfor8689problems(59.81%).TheRNNlanguagemodelisable
to capture and generalize long term dependencies between tokens
as compared to a small context learnt by the N-gram model.
5 RELATED WORK
In this section, we describe several related work on learning lan-guagemodelsforBigCode,automatedcodegradingapproaches,
and machine learning based grading techniques for other domains.
Neural Networks for syntax correction: DeepFix[ 12]uses
anattention-basedseq2seqmodelforlearningatokenmodelfroma
synthetic set of buggy programs. The learnt model in DeepFix first
67
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. Neuro-Symbolic Program Corrector for Introductory Programming Assignments ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
010203040506070
iterPower oddTuples evalPoly compDeriv gcdRecur hangman1 hangman2 gcditerPercentage of Submissions FixedrecurPower Model vs Problem-Specific Models
Problem-specific
 RecurPower
01020304050607080
recurPower iterPower oddTuples evalPoly com pDeriv gcdRecur hangman1 hangman2 gcditerPercentage of Submissions FixedRNN vs N-gram baseline
RNN
 N-gram
(a) (b)
Figure8:(a)Theperformanceofproblem-specificvsmodeltrainedonrecurPower.(b)ComparisonoftheperformanceofRNN
token sequence model vs a 5-gram baseline.
predictsthebuggylineintheprogramandreplacesthecomplete
line with the statement predicted by the model. Sk_p [ 22] uses a
skip-gramneuralnetworkmodeltopredictaprogramstatement
usingthelinesbeforeandaftertheerroneousline.Itenumerates
over all lines in the program and their potential replacements until
findingoneprogramthatiscorrect.Unlikethesetechniquesthat
always replace the complete statement (line) in a student program,
our system uses an iterative algorithm that is able to generate
fine-grainedtoken-levelfixestogeneratesmallrepairs,whichare
morelikelytocorrespondtostudent’sintent.Moreover,oursystem
uses constraint-based synthesis to perform semantic repairs and
complementthesyntacticrepairsfoundbytheRNNtokenmodel.
Finally, the model in DeepFix is trained on a synthetic dataset
obtainedbymutatingcorrectstudentsubmissionsusinganerror
model, whereas our token sequence model is trained directly on
the correct submissions. The synthetic dataset generation not only
requiresknowingsomeerrormodelupfront,butalsotheconsidered
error model might not correspond to the distribution of real-world
student errors.
Language Models for Big Code: Our work is inspired from
the work on capturing naturalness (in terms of syntactic patterns)
ofcodeinlargerepositories[ 1,3,4,13,19,24].Unlikethesetech-
niques that analyze large code repositories, our system analyzes
student submissions that are typically much smaller and therefore
also more amenable to more expensive analyses such as enumera-
tive and constraint-based synthesis for program correction. Hindle
et al. [13] use an n-gram model to capture the regularity of local
project-specific contexts in software and use it for next token sug-
gestions. Nguyen et al. [ 19] extended this model to also include
semantic token annotations that describe the token type and theirsemantic role. Allamanis et al. [
1] showed that the n-gram models
can significantly increase their predictive capabilities when learnt
on alarge corpus containing350 millionlines of code.Natural-
ize [3] is a language-independent framework that uses the n-gram
languagemodeltolearnthecodingconventionfromaprojectcode-baseandsuggestsrevisionssuchasidentifiernamesandformatting
conventions to improve stylistic consistency. Allamaniset al. [ 4]
recently presented a technique for suggesting method and class
namesfromitsbodyandmethodsrespectivelyusinganeuralprob-
abilistic language model. JSNice [ 24] uses structured predictionwithCRFsforpredictingidentifiernamesandtypeannotationof
variables in JavaScript programs.
Ourtechniqueisinspiredfromthesepreviousworks,butuses
problem-specific RNN language models to compute fixes to syntaxerrors in student submissions. Campbell et al. [
6] presented a tech-
nique to use unnaturalness of code with syntax errors to locate the
actual source of errors. Ray et al. [ 23] recently showed that even
syntacticallycorrectbuggycodearetypicallyunnatural,whichcan
then be used to assist bug repair methods. Our system currently
usesthePythoncompilertolocateerrorlocations,butthesetech-
niquescanbeusedtocomplementandenhanceourtechniqueto
increase the robustness of locating errors in submissions.
Code Grading andFeedback: The problem of providing feed-
backonprogrammingassignmentshasseenalotofrecentinterest.
These approaches can be categorized into two broad categories
– peer-grading [ 14,15] and automated grading techniques [ 8,17,
26,27,29]. A recently proposed approach uses neural networks
to simultaneously embed both the precondition and postcondition
spacesofasetofprogramsintoafeaturespace,whereprograms
are considered as linear maps on this space. The elements of the
embedding matrix of a program are then used as code features for
automatically propagating instructor feedback at scale [ 21]. How-
ever,thesetechniquesrelyontheabilitytogeneratetheprogram
AST and cannot repair programs with syntax errors.
Machine learning for Grading in Other domains: There
have been similar automated grading systems developed for do-mains other than programming such as Mathematics [
16] and
shortanswerquestions[ 5].TheMathematicalLanguageProcessing
(MLP) [16] framework leverages solutions from large number of
learners to evaluate correctness of student solutions to open re-
sponse Mathematical questions. It first converts an open response
toasetofnumericalfeatures,whicharethenusedforclustering
to uncover structures of correct, partially-correct, and incorrect
solutions.Ateacherassignsagrade/feedbacktoonesolutionina
cluster,whichisthenpropagatedtoallsolutionsinthecluster.Basu
etal.[5]presentanapproachtotrainasimilaritymetricbetween
shortanswer responsesto UnitedStatesCitizenship Exam,which
is then used to group the responses into clusters and subclusters
for powergrading. The main difference between our technique and
these techniques is that we use RNNs to learn a language model
68
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Sahil Bhatia, Pushmeet Kohli, and Rishabh Singh
fortokensequencesunlikemachinelearningbasedclusteringap-
proachesusedbythesetechniques.Moreover,wefocusongiving
feedback on syntax errors whereas these techniques focus on se-
mantic correctness of the student solutions.
Automated Program Repair: The research in automated pro-
gram repair focuses on automatically modifying incorrect pro-
gramssuchthatthemodifiedprogrammeetssomedesiredspeci-
fication[11].GenProg[ 10]usesanextendedformofgeneticpro-
gramming to search for a source-level patch by evolving a pro-gram variant to fix some defects in the original buggy program
whilemaintainingfunctionalitywithrespecttoasetoftestcases.
SemFix[18]usesacombinationofsymbolicexecution,constraint
solving,andprogramsynthesistoautomaticallyderiverepairex-
pressions for a buggy program given a set of testcases. It first uses
statisticalfaultlocalizationtechniquestolocatetheerrorlocation
and then uses layered component based synthesis techniques to
generaterepairexpressionsofvaryingcomplexity.Qlose[ 8]also
usesprogramsynthesistechniquestoperformautomatedrepairby
optimizing a multi-objective constraint of minimizing both syntac-
ticandsemanticdistancesbetweentheoriginalbuggyprogramand
the fixed program. These systems focus on fixing semantic bugsin programs by encoding and analyzing program ASTs, whereas
oursystemfocusesonrepairingprogramswithsyntaxerrorsfor
which program ASTs can not be obtained.
Neural Program Synthesis: There are some recent neural ar-
chitectures developed for program synthesis that learn to search
over a discrete space of programs [ 9,20]. Unlike learning to search
over programs from scratch, we instead search over minimal modi-
fications to student programs and use the prefix context in student
submissions to guide the search more efficiently. We believe our
techniqueoflearningsequencemodelsovercorpusofrealprograms
can complement program synthesis techniques as well.
6 LIMITATIONS AND FUTURE WORK
Our systemcurrently only usesthe prefixtoken sequence forpre-
dicting the potential token sequences for syntax repair. For the
programshown inFigure 9,the SynFixalgorithmsuggests thefix
corresponding to the expression exp==0. If the algorithm also took
into account the token sequences following the error location such
asreturn base, then it could have predicted a better fix correspond-
ing to the token sequence exp == 1, and could have produced a
semanticallycorrectprogram.OursystemcurrentlyusesSketchto
perform such semantic edits, but in future we would like to extend
the RNNs to also encode the suffix sequences to potentially gener-
ate more semantic repairs. Another limitation of our system is that
wecurrentlydependonthePythoninterpretertoprovidetheerror
locationforsyntaxerrors,whichissufficientformostbutnotall
cases.Infuture,wewouldliketotrainaseparateneuralmodelthatalso learnsto predict sucherror locationsin an end-to-endmanner.
There is another interesting research question on how to best
translate the generated repairs into good pedagogical feedback.
Somesyntaxerrorsaresimplytypossuchasmismatchedparenthe-
sis/operators,forwhichthefeedbackgeneratedbyourtechnique
shouldbesufficient.ButtherearesyntaxerrorsthatpointtodeeperdefrecurPower( base, exp):
ifexp < 0:
return 1
ifexp = 0:
return base
return base∗recurPower( base, exp −1)
Figure 9: The SynFix algorithm suggests the fix e x p= =0us-
ing the prefix sequence.
misconceptionsinthestudent’smind.Someexamplesofsucher-
rorsincludeassigningtoreturnkeyworde.g. return=exp,perform-
inganassignmentinsideaparametervalueofafunctioncalle.g.
recurPower(base,exp-=1),etc.Weplantobuildasystemontopof
our technique that can first distinguish small errors from deeper
misconceptionerrors,andthentranslatethesuggestedrepairfix
accordinglysothatstudentscanlearnthehigh-levelconceptsfor
correctly understanding the language syntax.
7 THREATS TO VALIDITY
A threat to internal validity is that the syntax error repairs gen-
eratedbythe SynFixalgorithmmightnotbenaturalordesirable,
since the algorithm selects any repair that passes the compiler
check.Tomitigatethisissue,weperformtwosteps.First,weuse
the Sketch solver to compute semantic repairs that reduces thepotential chances to computing an undesirable syntax repair as
itwilllikelyprecludethecorrespondingsemanticrepair.Second,
we also randomly sampled 200 syntactically-fixed programs for
2 assignments, and manually checked that 74% of the fixed pro-grams corresponded to desirable syntax repairs. Another threatto internal validity is that we did not comprehensively evaluate
alldifferentneuralnetworkconfigurationsandparametervalues
due to compute resource constraint. However, we sampled someconfigurations from the space using a limited parameter sweep.
A threat to external validity of our results is that we have only
evaluatedourframeworkonsmallPythonprogramsobtainedfrom
anintroductorycourse,whichmightnotberepresentativeofother
programming courses taught in different languages.
8 CONCLUSION
We presented a technique to combine RNNs with constraint-based
synthesis to repair programs with syntax errors. For a program-
mingassignment,ourtechniquefirstusesthesetofallsyntactically
correct student submissions to train an RNN for learning the token
sequence model, and then usesthe trained model to predict token
sequencesforfindingsyntaxrepairsforstudentsubmissions.Itthen
uses constraint-based synthesis techniques to find minimal seman-
ticrepairsbasedonasetofrewriterules.Weshowtheeffectiveness
of our systemon a large set ofstudent submissions obtained from
edX. We believe that this combination of RNNs with constraint-
basedsynthesiscanprovideabasisforprovidingeffectivefeedback
on student programs with syntax errors.
69
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. Neuro-Symbolic Program Corrector for Introductory Programming Assignments ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]MiltiadisAllamanisandCharlesA.Sutton. Miningsourcecoderepositoriesat
massive scale using language modeling. In MSR, pages 207–216, 2013.
[2]Miltiadis Allamanis and Charles A. Sutton. Mining idioms from source code. In
FSE, pages 472–483, 2014.
[3]MiltiadisAllamanis,EarlT.Barr,ChristianBird,andCharlesA.Sutton. Learning
natural coding conventions. In FSE, pages 281–293, 2014.
[4]MiltiadisAllamanis,EarlT.Barr,ChristianBird,andCharlesA.Sutton.Suggesting
accurate method and class names. In FSE, pages 38–49, 2015.
[5] Sumit Basu, Chuck Jacobs, and Lucy Vanderwende. Powergrading: a clustering
approachtoamplifyhumaneffortforshortanswergrading. TACL,1:391–402,
2013.
[6]Joshua Charles Campbell, Abram Hindle, and José Nelson Amaral. Syntax errors
just aren’t natural: Improving error reporting with language models. In MSR
2014, pages 252–261, 2014.
[7]JanKChorowski,DzmitryBahdanau,DmitriySerdyuk,KyunghyunCho,and
YoshuaBengio. Attention-basedmodels forspeechr ecognition. In Advances in
Neural Information Processing Systems, pages 577–585, 2015.
[8]Loris D’Antoni, Roopsha Samanta, and Rishabh Singh. Qlose: Program repair
with quantitative objectives. In CAV, pages 383–401, 2016.
[9]JacobDevlin,JonathanUesato,SuryaBhupatiraju,RishabhSingh,Abdel-rahman
Mohamed,andPushmeetKohli. Robustfill:Neuralprogramlearningundernoisy
I/O. In ICML, pages 990–998, 2017.
[10]C. Le Goues, T. Nguyen, S. Forrest, and W. Weimer. Genprog: A generic method
for automatic software repair. IEEE Transactions on Software Engineering, 38(1):
54–72, 2012.
[11]Claire Goues, Stephanie Forrest, and Westley Weimer. Current challenges in
automaticsoftwarerepair. Software Quality Journal,21(3):421–443,September
2013.
[12]RahulGupta,SohamPal,AdityaKanade,andShirishShevade. Deepfix:Fixing
common c language errors by deep learning. In AAAI, 2017.
[13]AbramHindle,EarlT.Barr,ZhendongSu,MarkGabel,andPremkumarT.De-
vanbu. On the naturalness of software. In ICSE, pages 837–847, 2012.
[14]ChinmayKulkarni,MichaelS.Bernstein,andScottR.Klemmer. Peerstudio:Rapid
peer feedback emphasizes revision and improves performance. In Learning @
Scale,, pages 75–84, 2015.
[15]Chinmay Eishan Kulkarni, Pang Wei Wei, Huy Le, Daniel Jin hao Chia, Kathryn
Papadopoulos, Justin Cheng, Daphne Koller, and Scott R. Klemmer. Peer and self
assessment in massive online classes. ACM Trans. Comput.-Hum. Interact., 20(6):
33, 2013.
[16]Andrew S. Lan, Divyanshu Vats, Andrew E. Waters, and Richard G. Baraniuk.
Mathematicallanguageprocessing:Automaticgradingandfeedbackforopen
response mathematical questions. In Learning@Scale, pages 167–176, 2015.
[17]Andy Nguyen, Christopher Piech, Jonathan Huang, and Leonidas J. Guibas.Codewebs: scalable homework search for massive open online programming
courses. In WWW, pages 491–502, 2014.
[18]Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra. Semfix: program repair via semantic analysis. In ICSE, pages 772–781,
2013.
[19]TungThanhNguyen,AnhTuanNguyen,HoanAnhNguyen,andTienN.Nguyen.
A statistical semantic language model for source code. In Proceedings of the 2013
9th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2013, 2013.
[20]Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong
Zhou, and Pushmeet Kohli. Neuro-symbolic program synthesis. In ICLR, 2017.
[21]Chris Piech, Jonathan Huang, Andy Nguyen, Mike Phulsuksombati, MehranSahami, and Leonidas J. Guibas. Learning program embeddings to propagate
feedback on student code. In ICML, pages 1093–1102, 2015.
[22]Yewen Pu, Karthik Narasimhan, Armando Solar-Lezama, and Regina Barzilay.
sk_p: a neural program corrector for moocs. CoRR, abs/1607.02902, 2016.
[23]Baishakhi Ray, Vincent Hellendoorn, Saheel Godhane, Zhaopeng Tu, Alberto
Bacchelli, and Premkumar Devanbu. On the naturalness of buggy code. In ICSE,
pages 428–439, 2016.
[24]Veselin Raychev, Martin T. Vechev, and Andreas Krause. Predicting program
properties from "big code". In POPL, pages 111–124, 2015.
[25]D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Parallel distributed processing:
Explorationsinthemicrostructureofcognition,vol.1. chapterLearningInternal
Representations by Error Propagation, pages 318–362. MIT Press, 1986.
[26]GursimranSingh,ShashankSrikant,andVarunAggarwal. Questionindependentgradingusingmachinelearning:Thecaseofcomputerprogramgrading. In KDD,
pages 263–272, 2016.
[27]RishabhSingh,SumitGulwani,andArmandoSolar-Lezama. Automatedfeedback
generationforintroductoryprogrammingassignments. In PLDI,pages15–26,
2013.
[28]Armando Solar-Lezama, Liviu Tancau, Rastislav Bodík, Sanjit A. Seshia, and
Vijay A. Saraswat. Combinatorial sketching for finite programs. In ASPLOS,
pages 404–415, 2006.[29]ShashankSrikantandVarunAggarwal. Asystemtogradecomputerprogram-
ming skills using machine learning. In KDD, pages 1887–1896, 2014.
[30]Ilya Sutskever, James Martens, and Geoffrey E Hinton. Generating text with
recurrent neural networks. In ICML, pages 1017–1024, 2011.
[31]IlyaSutskever,OriolVinyals,andQuocVLe. Sequencetosequencelearningwith
neural networks. In Advances in neural information processing systems, pages
3104–3112, 2014.
[32]P. J. Werbos. Backpropagation through time: what it does and how to do it.
Proceedings of the IEEE, 78(10):1550–1560, Oct 1990.
70
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:49:35 UTC from IEEE Xplore.  Restrictions apply. 