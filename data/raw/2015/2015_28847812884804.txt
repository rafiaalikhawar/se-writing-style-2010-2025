Automatically Learning Semantic Features for Defect
Prediction
Song Wang,Taiyue Liu and Lin Tan
Electrical and Computer Engineering, University of Waterloo, Canada
{song.wang, t67liu, lintan}@uwaterloo.ca
ABSTRACT
Software defect prediction, which predicts defective code re-
gions, can help developers nd bugs and prioritize their test-
ing eorts. To build accurate prediction models, previous
studies focus on manually designing features that encode the
characteristics of programs and exploring dierent machine
learning algorithms. Existing traditional features often fail
to capture the semantic dierences of programs, and such a
capability is needed for building accurate prediction models.
To bridge the gap between programs' semantics and
defect prediction features, this paper proposes to leverage a
powerful representation-learning algorithm, deep learning,
to learn semantic representation of programs automatically
from source code. Specically, we leverage Deep Belief
Network (DBN) to automatically learn semantic features
from token vectors extracted from programs' Abstract
Syntax Trees (ASTs).
Our evaluation on ten open source projects shows that
our automatically learned semantic features signicantly im-
prove both within-project defect prediction (WPDP) and
cross-project defect prediction (CPDP) compared to tradi-
tional features. Our semantic features improve WPDP on
average by 14.7% in precision, 11.5% in recall, and 14.2%
in F1. For CPDP, our semantic features based approach
outperforms the state-of-the-art technique TCA+ with tra-
ditional features by 8.9% in F1.
1. INTRODUCTION
Software defect prediction techniques [12,18,20,23,27,32,
38, 40, 52, 62, 70] have been proposed to detect defects and
reduce software development costs. Defect prediction tech-
niques build models from software data, and use the mod-
els to predict whether new instances of code regions, e.g.,
les, changes, and methods, contain defects. Eorts of pre-
vious studies towards building accurate prediction models
fall into two main directions: one is manually designing new
features or new combinations of features to represent de-
fects more eectively; the other is using new and improved
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ‚Äô16, May 14-22, 2016, Austin, TX, USA
c2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI:http://dx.doi.org/10.1145/2884781.2884804machine learning algorithms. Researchers have manually
designed many features to distinguish defective les from
non-defective les, e.g., Halstead features [10] based on op-
erator and operand counts, McCabe features [31] based on
dependencies, CK features [5] based on function and in-
heritance counts, etc., MOOD features [11] based on poly-
morphism factor, coupling factor, etc., code change features
[18] include number of lines of code added, removed, etc.,
and other object-oriented features [7]. Meanwhile, many
machine learning algorithms have been adopted for soft-
ware defect prediction, including Support Vector Machine
(SVM), Naive Bayes (NB), Decision Tree (DT), Neural Net-
work (NN), and Dictionary Learning [20].
Programs have well-dened syntax , which can be repre-
sented by Abstract Syntax Trees (ASTs) [15] and have been
successfully used to capture programming patterns [44, 46].
In addition, programs have semantics , which is hidden
deeply in source code [65]. It has been shown that pro-
grams' semantic information is useful for tasks such as
code completion and bug detection [15, 28, 44, 46, 60]. Such
semantic information should also be useful for character-
izing defects for improving defect prediction. Specically,
in order to make accurate predictions, the features need to
be discriminative: capable of distinguishing one instance of
code region from another.
However, existing traditional features cannot distinguish
code regions of dierent semantics. Program les with
dierent semantics can have traditional features with the
same values. For example, Figure 1 shows two Java les,
File1.java and File2.java , both of which contain an if
statement, a forstatement, and two function calls. Using
traditional features to represent these two les, their feature
vectors are identical, because these two les have the same
source code characteristics in terms of lines of code, function
calls, raw programming tokens, etc. However, the semantic
information is dierent. Features that can distinguish such
semantic dierences should enable the building of more
accurate prediction models.
To bridge the gap between programs' semantic informa-
tion and features used for defect prediction, this paper pro-
poses to leverage a powerful representation-learning algo-
rithm, namely deep learning [17], to learn semantic represen-
tation of programs automatically and use the representation
to improve defect prediction. Specically, we use Deep Belief
Network (DBN) [16] to automatically learn features from to-
ken vectors extracted from programs' ASTs, and then utilize
these features to train a defect prediction model.
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   297
1 int i = 9;
2 if (i == 9) {
3 foo ();
4 for (i = 0; i < 10;
i++) {
5 bar ();
6 }
7 }
File1.java1 int i = 9;
2 foo ();
3 for (i = 0; i < 10; i
++) {
4 if (i == 9) {
5 bar ();
6 }
7 }
File2.java
Figure 1: A Motivating Example
DBN is a generative graphical model, which learns a rep-
resentation that can reconstruct training data with a high
probability. It automatically learns high-level representa-
tion of data by constructing a deep architecture [2]. We have
seen successful applications of DBN in many elds, including
speech recognition [37], image classication [6, 25], natural
language understanding [35,55], and semantic search [54].
To use a DBN to learn features from code snippets, we
convert the code snippets into vectors of tokens with struc-
tural and contextual information preserved, and use these
vectors as input to the DBN. For the two code snippets in
Figure 1, the input vectors will be [..., if, foo, for,
bar, ...] and [..., foo, for, if, bar, ...] respec-
tively. Since the vectors of these two les are dierent,
DBN will automatically learn features to distinguish these
two code snippets (details are in Figure 3 and Section 3.3).
This paper makes the following contributions:
We propose to leverage a powerful representation-
learning algorithm, namely deep learning, to learn
semantic features from token vectors extracted from
programs' ASTs automatically.
We leverage the semantic features learned automati-
cally by DBN to improve both within-project defect
prediction (WPDP) and cross-project defect predic-
tion (CPDP).
Our evaluation results on ten open source Java projects
show that the automatically generated semantic fea-
tures improve both WPDP and CPDP. For WPDP, our
semantic features achieve an average improvement of
precision by 14.7%, recall by 11.5%, and F1 by 14.2%
compared to traditional features. For CPDP, our se-
mantic feature based approach outperforms the state-
of-the-art technique TCA+ [42] built on traditional
features by 8.9% in F1.
The rest of this paper is summarized as follows. Section 2
provides backgrounds on defect prediction and DBN. Sec-
tion 3 describes our proposed approach to learn semantic
features from source code automatically, and leverage these
learned features to predict defects. Section 4 shows the ex-
perimental setup. Section 5 evaluates the performance of
learned semantic features. Section 6 and Section 7 present
threats to our work and related work respectively. We con-
clude this paper in Section 8.
2. BACKGROUND
This section provides the backgrounds of le-level defect
prediction and deep belief network.
Figure 2: Defect Prediction Process
2.1 Defect Prediction
Figure 2 presents a typical le-level defect prediction pro-
cess that is adopted by existing studies [20,27,34,41,42,51,
64]. The rst step is to label data as buggy or clean based
on post-release defects for each le. A le is buggy if the le
contains bugs. Otherwise, the le is clean . The second step
is to collect corresponding traditional features of these les.
Instances with features and labels are used to train machine
learning classiers. Finally, trained models are used to pre-
dict new instances as buggy or clean.
We refer to the set of instances used for building models as
thetraining set, whereas the set of instances used to evaluate
the trained models as the test set. As shown in Figure 2,
when performing within-project defect prediction (following
existing work [41], we call this WPDP), the training and test
sets are from the same project A. When performing cross-
project defect prediction (following existing work [41] we call
this CPDP), prediction models are trained by training set
from a project A (source), and test set is from a dierent
project B (target).
In this study, we examine the performance of learned se-
mantic features on both WPDP and CPDP.
2.2 Deep Belief Network
A Deep Belief Network is a generative graphical model
that uses a multi-level neural network to learn a representa-
tion from training data that could reconstruct the semantic
and content of input data with a high probability [2]. DBN
contains one input layer and several hidden layers , and the
top layer is the output layer that used as features to repre-
sent input data as shown in Figure 3. Each layer consists of
several stochastic nodes. The number of hidden layers and
the number of nodes in each layer vary depending on users'
demand. In this study, the size of learned semantic features
is the number of nodes in the top layer. The idea of DBN
is to enable the network to reconstruct the input data using
generated features by adjusting weights between nodes in
dierent layers.
DBN models the joint distribution between input layer
and the hidden layers as follows:
P(x;h1;:::;hl) =P(xjh1)(lY
k=1P(hkjhk+1)) (1)
wherexis the data vector from input layer, lis the number
of hidden layers, and hkis the data vector of kthlayer (1
kl).P(hkjhk+1) is a conditional distribution for the
adjacentkandk+ 1 layer.
298To calculate P(hkjhk+1), each pair of two adjacent layers
in DBN are trained as a Restricted Boltzmann Machines
(RBM) [2]. A RBM is a two-layer, undirected, bipartite
graphical model where the rst layer consists of observed
data variables, referred to as visible nodes , and the second
layer consists of latent variables, referred to as hidden nodes .
P(hkjhk+1) can be eciently calculated as:
P(hkjhk+1) =nkY
j=1P(hk
jjhk+1) (2)
P(hk
j= 1jhk+1) =sigm (bk
j+nk+1X
a=1Wk
ajhk+1
a) (3)
wherenkis the number of node in layer k,sigm (c) =1
1+e c,
bis a bias matrix, bk
jis the bias for node jof layerk, and
Wkis the weight matrix between layer kandk+ 1.
DBN automatically learns Wandbmatrices using an
iteration process. Wandbare updated via log-likelihood
stochastic gradient descent:
Wij(t+ 1) =Wij(t) +@log(P(vjh))
@W ij(4)
bo
k(t+ 1) =bo
k(t) +@log(P(vjh))
@bo
k(5)
wheretis thetthiteration,is the learning rate, P(vjh)
is the probability of the visible layer of a RBM given the
hidden layer, iandjare two nodes in dierent layers of the
RBM,Wijis the weight between the two nodes, and bo
kis
the bias on the node oin layerk.
To train the network, one rst initializes all Wmatrices
between two layers via RBM and sets the biases bto0. They
can be well-tuned with respect to a specic criterion, e.g.,
the number of training iterations, error rate between recon-
structed input data and original input data. In this study,
we use the number of training iterations as the criterion for
tuningWandb. The well-tuned Wandbare used to set
up a DBN for generating semantic features for both training
and test data. Also, we discuss how these parameters aect
the performance of learned semantic features in Section 4.4.
3. APPROACH
In this work, we use DBN to generate semantic features
automatically from source code and leverage these features
to improve defect prediction. Figure 4 illustrates the work-
ow of our approach according to the motivating example in
Figure 1. Our approach takes tokens from the source code
of the training and test sets as input, and generates seman-
tic features from them, which are then used to build and
evaluate the models for predicting defects. Specically, our
approach rst extracts a vector of tokens from the source
code of each le in both the training and test sets. Since
DBN requires input data in the form of integer vectors, we
build a mapping between integers and tokens and convert
the token vectors to integer vectors. To generate semantic
features, we rst use the integer vectors of the training set
to build a DBN. Then, we use the DBN to automatically
generate semantic features from the integer vectors of the
Figure 3: Deep belief network architecture and input in-
stances of File1.java and File2.java. Although the token
sets of these two les are identical, the dierent structural
and contextual information between tokens enables DBN to
generate dierent features to distinguish these two les.
training and test sets. Finally, based on the generated se-
mantic features, we build defect prediction models from the
training set, and evaluate their performance on the test set.
Our approach consists of four major steps: 1) parsing
source code into tokens, 2) mapping tokens to integer iden-
tiers, which are the expected inputs of DBN, 3) leveraging
DBN to automatically generate semantic features, and 4)
building defect prediction models and predicting defects us-
ing the learned semantic features of the training data and
the test data.
3.1 Parsing Source Code
For our study, we need to extract syntactic information
from source code for DBN to learn semantic features. We
utilize Java Abstract Syntax Tree (AST) to extract syn-
tactic information from source code. Three types of AST
nodes are extracted as tokens: 1) nodes of method invoca-
tions and class instance creations, e.g., in Figure 3, method
foo() and bar() are recorded as their method names, 2)
declaration nodes, i.e., method declarations, type declara-
tions, and enum declarations, and 3) control-ow nodes such
aswhile statements, catch clauses, ifstatements, throw
statements, etc. Control-ow nodes are recorded as their
statement types, e.g., an ifstatement is simply recorded as
if. In summary, for each le, we obtain a vector of tokens
of the three categories.
We exclude AST nodes that are not one of these three
categories, such as assignment and intrinsic type declara-
tion, because they are often method-specic or class-specic,
which may not be generalizable to the whole project. Adding
them may dilute the importance of other nodes.
Since the names of methods, classes, and types are typi-
cally project-specic, methods of an identical name in dif-
ferent projects are either rare or of dierent functionalities.
Thus, for cross-project defect prediction, we extract all three
categories of AST nodes, but for the AST nodes in cate-
gories 1) and 2), instead of using their names, we use their
AST node types such as method declarations and method
invocations . Take project xerces as an example. As an
XML parser, it consists of many methods named getXXX and
299Figure 4: Overview of our proposed DBN-based feature generation and defect prediction
setXXX , where XXXrefers to XML-specic keywords includ-
ingcharset ,type, and href. Each of these methods con-
tains only one method invocation statement, which is in form
of either getAttribute(XXX) orsetAttribute(XXX) . Meth-
odsgetXXX and setXXX do not exist in other projects, while
getAttribute(XXX) and setAttribute(XXX) have dierent
meanings in other projects, so using their names getAt-
tribute(XXX) orsetAttribute(XXX) is not helpful. But it
is useful to know that there exist method declaration nodes,
and only one method invocation node is under each of these
method declaration nodes, since it might be unlikely for a
method with only one method invocation inside to be buggy.
In this case, compared with using the method names, using
the AST node types method declaration and method in-
vocation is more useful since they can still provide partial
semantic information.
3.2 Handling Noise and Mapping Tokens
3.2.1 Handling Noise
Defect data are often noisy and suer from the mislabeling
problem. Studies have shown that such noises could signi-
cantly erode the performance of defect prediction [14,22,58].
To prune noisy data, Kim et al. proposed an eective mis-
labeling data detection approach named Closest List Noise
Identication (CLNI) [22]. It identies the k-nearest neigh-
bors for each instance and examines the labels of its neigh-
bors. If a certain number of neighbors have opposite labels,
the examined instance will be agged as noise. However,
such approach cannot be directly applied to our data be-
cause their approach is based on the Euclidean Distance of
traditional numerical features. Since our features are seman-
tic tokens. The dierence between the values of two features
only indicates that these two features are of dierent tokens.
To detect and eliminate mislabeling data, and help DBN
learn common knowledge between the semantic information
of buggy and clean les, we adopt the edit distance similarity
computation algorithm [43] to dene the distances between
instances. The edit distances are sensitive to both the tokens
and order among the tokens. Given two token sequences A
andB, the edit distance d(A;B ) is the minimum-weight
series of edit operations that transform AtoB. The smaller
d(A;B ) is, the more similar AandBare.
Based on edit distance similarity, we deploy CLNI to elimi-
nate data with potential incorrect labels. In this study, since
our purpose is not to nd the best training or test set, we do
not spend too much eort on well tuning the parameters of
CLNI. We use the recommended parameters and nd themwork well. In our benchmark experiments with traditional
features, we also perform CLNI to remove the incorrectly
labeled data.
Additionally, we lter out infrequent AST nodes, which
might be designed for a specic le and be hardly generalized
to other les. For a project, if the total number of occur-
rences of a token is less than three, we lter the token out.
We encode only the tokens that occur three or more times,
which is a common practice in the NLP research eld [30].
3.2.2 Mapping Tokens
DBN takes only numerical vectors as inputs, and the
lengths of the input vectors must be the same. To use DBN
to generate semantic features by using DBN, we rst build
a mapping between integers and tokens, and encode token
vectors to integer vectors. Each token has a unique integer
identier while dierent method names and class names will
be treated as dierent tokens. Since our integer vectors may
have dierent lengths, we append 0 to the integer vectors
to make all the lengths consistent and equal to the length
of the longest vector. Adding zeros does not aect the
results, and it is simply a representation transformation to
make the vectors acceptable by DBN. Taking code snippets
in Figure 3 as an example, if we consider only \File1" and
\File2", the token vectors for \File1" and \File2" would be
mapped to [1, 2, 3, 4] and [2, 3, 1, 4] respectively. Through
this encoding process, method invocation information and
inter-class information are represented as integer vectors. In
addition, some program structure information is preserved
since the order of tokens remains unchanged.
3.3 Training DBN and Generating Features
3.3.1 Training DBN
To generate semantic features for distinguishing buggy
and clean les, we need to rst train DBN by using the
training data. As discussed in Section 2, to train an eective
DBN for learning semantic features, we need to tune three
parameters, which are: 1) the number of hidden layers , 2)
the number of nodes in each hidden layer , and 3) the number
of training iterations . Existing work that leveraged DBN to
generate features for NLP [55] and image recognition [6,25]
reported that the performance of DBN-generated features is
sensitive to these parameters. We show how we tune these
parameters in Section 4.4.
To simplify our model, we set the number of nodes to
be the same in each layer. Through these hidden layers
and nodes, DBN obtains characteristics that are dicult
300to be observed but are capable of capturing semantic dier-
ences. For each node, DBN learns probabilities of traversing
from this node to the nodes of its top level. Through back-
propagation validation, DBN reconstructs the input data us-
ing generated features by adjusting weights between nodes
in dierent layers.
DBN requires the values of input data ranging from 0 to 1,
while data in our input vectors can have any integer values
due to our mapping approach. To satisfy the input range re-
quirement, we normalize the values in the data vectors of the
training and test sets by using min-max normalization [66].
In our mapping process, integer values for dierent tokens
are just identiers. One token with a mapping value of 1 and
one token with a mapping value of 2 only means these two
nodes are dierent and independent. Thus, the normalized
values can still be used as token identiers since the same
identiers still keep the same normalized values.
3.3.2 Generating Features
After we train a DBN, both the weights wand the biases b
(details are in Section 2) are xed. We input the normalized
integer vectors of the training data and the test data into
the DBN respectively, and then obtain semantic features for
the training and test data from the output layer of the DBN.
3.4 Building Models and Performing Defect
Prediction
After we obtain the generated semantic features for each
le in both the training data and the test data, we build
and train defect prediction models by following the standard
defect prediction process described in Section 2, and then we
use the test data to evaluate the performance of the built
defect prediction models.
4. EXPERIMENTAL SETUP
We conduct several experiments to study the performance
of the proposed semantic features and compare them with
existing traditional features. We run experiments on a
2.5GHz i5-3210M machine with 4GB RAM.
4.1 Evaluation Metrics
To measure defect prediction results, we use three metrics:
Precision ,Recall , andF1. These three metrics are widely
adopted to evaluate defect prediction techniques [20,33,34,
42,70]. Here is a brief introduction:
Precision =true positive
true positive +false positive(6)
Recall =true positive
true positive +false negative(7)
F1 =2PrecisionRecall
Precision +Recall(8)
Precision and recall are composed of three numbers in terms
oftrue positive ,false positive , and false negative. True posi-
tive is the number of predicted defective les that are truly
defective, while false positive is the number of predicted de-
fective les that are actually not defective. False negative
records the number of predicted non-defective les that are
actually defective. A higher precision makes the manual in-
spection on a certain amount of predicted defective les nd
more defects, while an increase in recall can reveal moredefects given a project. F1 takes consideration of both pre-
cision and recall.
4.2 Evaluated Projects and Data Sets
To facilitate the replication and verication of our exper-
iments, we use publicly available data from the PROMISE
data repository. We select all Java open source projects
from PROMISE1whose version numbers are provided. We
need the version numbers of each project because we need
to extract token vectors from ASTs of source code to feed
our DBN-based feature generation approach. In total, 10
Java projects are collected. Table 1 shows the versions, the
average number of les, and the average buggy rate of each
project. The numbers of les of the projects range from
150 to 1,046, and the buggy rates of the projects have a
minimum value of 13.4% and a maximum value of 49.7%.
4.3 Two Baselines of Traditional Features
To evaluate the performance of semantic features in defect
prediction, we compare semantic features with traditional
features. Our rst baseline of traditional features consists
of 20 traditional features, including lines of code, operand
and operator counts, number of methods in a class, the po-
sition of a class in inheritance tree, and McCabe complexity
measures, etc. The 20 traditional features are available for
PROMISE data, and the work from He et al. [13] contains
the full list of the 20 features, which are well described in
their Table II. These features and data have been widely
used in previous work [20, 33, 34, 42, 70]. We choose the
widely used PROMISE data so that we can directly com-
pare our work with previous studies. Note that, for a fair
comparison, we also perform the noise removal approach de-
scribed in Section 3.2.1 on the PROMISE data.
The traditional features from PROMISE do not contain
AST nodes, which were used by our DBN models. For a fair
comparison, our second baseline of traditional features is
the AST nodes that were given to our DBN models, i.e., the
AST nodes in all les after xing noise (Section 3.2.1). Each
instance is represented as a vector of term frequencies of the
AST nodes.
4.4 Parameter Settings for Training a DBN
Model
Many DBN applications [6,25,37] report that an eective
DBN needs well-tuned parameters, i.e., 1) the number of hid-
den layers , 2)the number of nodes in each hidden layer , and
3)the number of iterations . In this study, since we leverage
DBN to generate semantic features, we need to consider the
impact of the three parameters. We tune the three parame-
ters by conducting experiments with dierent values of the
parameters on ant(1.5, 1.6), camel (1.2, 1.4), jEdit (4.0,
4.1), lucene (2.0, 2.2), and poi(1.5, 2.5) respectively. Each
experiment has specic values of the three parameters and
runs on the ve projects individually. Given an experiment,
for each project, we use the older version of this project to
train a DBN with respect to the specic values of the three
parameters. Then, we use the trained DBN to generate se-
mantic features for both the older and newer versions. After
that, we use the older version to build a defect prediction
model and apply it to the newer version. Lastly, we evaluate
the specic values of the parameters by the average F1 score
of the ve projects in defect prediction.
1http://openscience.us/repo/defect
301Table 1: Evaluated projects
Project Description Releases Avg Files Avg Buggy Rate (%)
ant Java based build tool 1.5,1.6,1.7 488 13.4
camel Enterprise integration framework 1.2,1.4,1.6 1,046 18.7
jEdit Text editor designed for programmers 3.2,4.0,4.1 645 19.2
log4j Logging library for Java 1.0,1.1 150 49.7
lucene Text search engine library 2.0,2.2,2.4 402 35.8
xalan A library for transforming XML les 2.4,2.5 992 29.6
xerces XML parser 1.2,1.3 549 15.7
ivy Dependency management library 1.4,2.0 311 20.0
synapse Data transport adapters 1.0,1.1,1.2 220 22.7
poi Java library to access Microsoft format les 1.5,2.5,3.0 416 40.7
Figure 5: Defect prediction performance with dierent pa-
rameters
4.4.1 Setting the number of hidden layers and the
number of nodes in each layer
Since the number of hidden layers and the number of
nodes in each hidden layer interact with each other, we tune
these two parameters together. For the number of hidden
layers, we experiment with 11 discrete values include 2, 3,
5, 10, 20, 50, 100, 200, 500, 800, and 1,000. For the number
of nodes in each hidden layer, we experiment with eight
discrete values include 20, 50, 100, 200, 300, 500, 800, and
1,000. When we evaluate these two parameters, we set the
number of iterations to 50 and keep it constant.
Figure 5 illustrates the average F1 scores for tuning the
number of hidden layers and the number of nodes in each
hidden layer together. When the number of nodes in each
layer is xed, with increasing number of hidden layers, all
the average F1 scores are convex curves. Most curves peak
at the point where the number of hidden layers is equal to 10.
If the number of hidden layers remains unchanged, the best
F1 score happens when the number of nodes in each layer
is 100 (the top line in Figure 5). As a result, we choose the
number of hidden layers as 10 and the number of nodes in
each hidden layer as 100. Thus, the number of DBN-based
features for each project is 100.
4.4.2 Setting the number of iterations
The number of iterations is another important parameter
for building an eective DBN. During the training process,
DBN adjusts weights to narrow down error rate between
reconstructed input data and original input data in each it-
eration. In general, the bigger the number of iterations, the
Figure 6: Average error rate and time cost for dierent
numbers of iterations
lower the error rate. However, there is a trade-o between
the number of iterations and the time cost. To balance the
number of iterations and the time cost, we choose the same
ve projects to conduct experiments with ten discrete val-
ues for the number of iterations. The values range from 1 to
10,000. We use error rate to evaluate this parameter. Fig-
ure 6 demonstrates that, as the number of iterations increas-
ing, the error rate decreases slowly with the corresponding
time cost increases exponentially. In this study, we set the
number of iterations to 200, with which the average error
rate is about 0.098 and the time cost is about 15 seconds.
4.5 Within-Project Defect Prediction
To examine the performance of our semantic features in
within-project defect prediction, we build defect prediction
models using three machine learning classiers, including
ADTree, Naive Bayes, and Logistic Regression, which have
been adopted in previous work [20,33,34,42,70]. To obtain
the training and test data, we use two consecutive versions
of each project listed in Table 1. We use the source code
of an older version to train DBN and generate the training
data. Then we use the trained DBN to generate features for
a newer version, which are the test data. We compare our
semantic features with the traditional features as described
in Section 4.3. For a fair comparison, we use the same
classiers on these traditional features.
Defect data are often imbalanced [57], which might aect
the accuracy of defect prediction. Table 1 shows that most
of our examined projects have buggy rates less than 50%
and so are imbalanced. To obtain optimal defect prediction
302models, we perform the re-sampling technique used in exist-
ing work [57], i.e., SMOTE, on our training data for both
semantic features and traditional features.
4.6 Cross-Project Defect Prediction
Due to the lack of defect data, it is often dicult to build
accurate prediction models for new projects. To overcome
this problem, cross-project defect prediction techniques
train prediction models by using data from mature projects
or called source projects , and use the trained models to
predict defects for new projects or called target projects .
However, since the features of source projects and target
projects often have dierent distributions, making an
accurate and precise cross-project defect prediction is still
challenging [41].
We believe that our proposed semantic features can cap-
ture the common characteristics of defects, which implies
that the semantic features trained from a project can be
used to predict a dierent project, and so applicable in
cross-project defect prediction. To measure the performance
of the semantic features in cross-project defect prediction,
we propose a technique called DBN C ross-Project Defect
Prediction ( DBN-CP ). Given a source project and a target
project, DBN-CP rst trains a DBN by using the source
project and generates semantic features for both the two
projects. Then, DBN-CP trains an ADTree based defect
prediction model using data from the source project, and
then use the built model to perform defect prediction on
the target project. We choose TCA+ [42] as our baseline.
To compare with TCA+, we randomly pick 1 or 2 versions
from each project, in total we have 11 target projects, and
for each target project, we randomly select 2 source projects
that are dierent from the target projects. Thus, 22 test
pairs are collected.
The reason why we compare with TCA+ is that TCA+
is the state-of-the-art technique that reports the best per-
formance in cross-project defect prediction. Since TCA+
is not publicly available, we have reimplemented our own
version of it. In our reproduction, we follow the processes
described in [42], we rst implement all their proposed ve
normalization methods and assign them with the same con-
ditions as given in TCA+ paper. We then perform Trans-
fer Component Analysis [49] on source projects and target
projects together, and map them onto the same subspace
while minimizing data dierence and maximizing data vari-
ance. Finally, we use the source projects and target projects
with the new features to build and evaluate ADTree-based
prediction models.
5. RESULTS
This section presents our experimental results. We focus
on the performance of our proposed semantic features and
answer the following research questions (RQ):
RQ1: Do semantic features outperform traditional
features for within-project defect prediction?
To answer this question, we use dierent features to build
within-project defect prediction models to compare the im-
pact of three sets of features: semantic features that are au-
tomatically learned by DBN, PROMISE features, and AST
features. The latter two are the two baselines of traditional
features. We conduct 16 sets of within-project defect pre-
diction experiments, each of which uses two versions of theTable 2: Comparison between semantic features and two
baselines of traditional features (PROMISE features and
AST features) using ADTree. Tr denotes the training set
version and T denotes the test set version. P, R, and F1
denote precision, recall, and F1 score respectively and are
measured in percentage. The best F1 scores are highlighted
in bold.
Pro
jectV
ersions S
emantic PR
OMISE A
ST
(
Tr->T) P
R F1 P
R F1 P
R F1
a
nt1
.5->1.6 8
8.0 95.1 91.4 4
4.8 51.1 47.7 4
0.5 51.4 45.3
1
.6->1.7 9
8.8 90.1 94.2 4
1.8 77.1 54.2 4
1.2 54.7 47.0
c
amel1
.2->1.4 9
6.0 66.4 78.5 2
4.8 75.2 37.3 3
2.3 55.6 40.2
1
.4->1.6 2
6.3 64.9 37.4 2
8.3 63.7 39.1 2
9.7 51.5 38.3
jEd
it3
.2->4.0 4
6.7 74.7 57.4 4
4.7 73.3 55.6 4
5.8 47.4 46.6
4
.0->4.1 5
4.4 70.9 61.5 4
6.1 67.1 54.6 5
0.4 40.4 44.8
lo
g4j 1
.0->1.1 6
7.5 73.0 70.1 4
9.1 73.0 58.7 5
5.4 38.6 45.5
lu
cene2
.0->2.2 7
5.9 56.9 65.1 7
3.3 38.2 50.2 6
9.5 37.4 48.4
2
.2->2.4 6
6.5 92.1 77.3 7
0.9 52.7 60.5 6
5.9 53.1 58.8
xa
lan 2
.4->2.5 6
5.0 54.8 59.5 6
4.7 43.2 51.8 6
0.1 43.5 50.5
xe
rces 1
.2->1.3 4
0.3 42.0 41.1 1
6.0 46.4 23.8 2
5.5 22.0 23.6
iv
y 1
.4->2.0 2
1.7 90.0 35.0 2
2.6 60.0 32.9 3
1.6 28.6 30.0
sy
napse1
.0->1.1 4
6.0 66.7 54.4 4
5.5 50.0 47.6 5
1.5 45.7 48.4
1
.1->1.2 5
7.3 59.3 58.3 5
1.1 55.8 53.3 5
0.7 40.5 49.0
p
oi1
.5->2.5 7
6.1 55.2 64.0 7
3.7 44.8 55.8 7
0.0 31.6 43.5
2
.5->3.0 8
1.6 79.0 80.3 7
5.0 75.8 75.4 7
2.1 46.3 55.6
A
verage 6
3.0 70.7 64.1 4
8.3 59.2 49.9 4
9.5 43.0 44.7
same project (listed in Table 1). The older version is used
to train prediction models, and the newer version is used as
the test set to evaluate the trained models.
Table 2 shows the precision, recall, and F1 of the within-
project defect prediction experiments. The highest F1 of the
three sets of features are shown in bold. For example, by
using ant 1.6 as the training set, and ant 1.7 as the test
set, the F1 of using semantic features is 94.2%, while the
F1 is only 54.2% with the rst baseline of traditional fea-
tures (from PROMISE), and the F1 is 47.0% with the sec-
ond baseline of traditional features (based on AST nodes).
For this comparison, the only dierence is the three sets
of features, meaning that the same classication algorithm,
namely ADTree, the same parameters and the same training
and test sets are used.
On average, semantic features achieve a F1 of 64.1%, while
the PROMISE features achieve a F1 of 49.9%, and the AST
features achieve a F1 of 44.7%. The results demonstrate
that by using the semantic features automatically learned
by DBN instead of the PROMISE features, we can improve
the defect prediction F1 by 14.2% on average on 16 data
sets. The average improvement in the precision and recall is
14.7% and 11.5% respectively.
Since the DBN algorithm has randomness, the generated
features vary between dierent runs. Therefore, we run our
DBN-based feature generation approach ve times for each
experiment. Among the runs, the dierence in the generated
features is at the level of 1.0 e-20, which is too small to
propagate to precision, recall, and F1. In other words, the
precision, recall, and F1 of all ve runs are identical.
The proposed DBN-based approach is eective in auto-
matically learning semantic features, which improves the
performance of within-project defect prediction.
RQ1a: Do semantic features outperform tradi-
tional features with other classication algorithms?
We use semantic features and PROMISE features separately
to build defect prediction models by using two alternative
303Table 3: Comparison of F1 scores between semantic features
and PROMISE features using Naive Bayes and Logistic Re-
gression. Tr denotes the training set version and T denotes
the test set version. F1 scores are measured in percentage.
The best F1 scores are highlighted in bold.
Pro
jectV
ersion N
aive Bayes Lo
gistic Regression
(
Tr->T) S
emantic PR
OMISE S
emantic PR
OMISE
a
nt1
.5->1.6 6
3.0 5
6.0 9
1.6 5
0.6
1
.6->1.7 9
6.1 5
2.2 9
2.5 5
4.3
c
amel1
.2->1.4 4
5.9 3
0.7 5
9.8 3
6.3
1
.4->1.6 4
8.1 2
6.5 3
4.2 3
4.6
jEd
it3
.2->4.0 5
8.3 4
8.6 5
5.2 5
4.5
4
.0->4.1 6
0.9 5
4.8 6
2.3 5
6.4
l
og4j 1
.0->1.1 7
2.5 6
8.9 6
8.2 5
3.5
l
ucene2
.0->2.2 6
3.2 5
0.0 6
3.0 5
9.8
2
.2->2.4 7
3.8 3
7.8 6
2.9 6
9.4
xa
lan 2
.4->2.5 4
5.2 3
9.8 5
6.5 5
4.0
xe
rces 1
.2->1.3 3
8.0 3
3.3 4
7.5 2
6.6
i
vy 1
.4->2.0 3
4.4 3
8.9 3
4.8 2
4.0
sy
napse1
.0->1.1 4
7.9 5
0.8 4
2.3 3
1.6
1
.1->1.2 5
7.9 5
6.5 5
4.1 5
3.3
p
oi1
.5->2.5 7
7.0 3
2.3 6
6.4 5
0.3
2
.5->3.0 7
7.7 4
6.2 7
8.3 7
4.5
A
verage 6
0.0 4
5.2 5
9.7 4
9.0
classication algorithms|Naive Bayes and Logistic Regres-
sion. We conduct 16 sets of within-project defect prediction,
where the training sets and the test sets are exactly same
as those in RQ1. Table 3 shows the F1 scores of running
Naive Bayes and Logistic Regression on semantic features
and PROMISE features. We compare the performance of
semantic features and PROMISE features under dierent
classication algorithms. The better F1 scores are in
bold. Take antas an example, when the model is built
on Naive Bayes, by choosing version 1.5as the training
set and 1.6as the test set, semantic features produce a
F1 of 63.0%, which is 7.0% higher than using PROMISE
features. For the same example with Logistic Regression
as the classication algorithm, semantic features achieve a
F1 of 91.6%, while using PROMISE features produces a F1
of 50.6% only. Among the experiments with either Naive
Bayes or Logistic Regression as the classication algorithm,
semantic features outperform PROMISE features in 14 out
of the 16 times. On average, Naive Bayes based defect
prediction model with semantic features achieves a F1 of
60.0%, which is a 14.8% improvement over Naive Bayes
with PROMISE features. Similarly, the average F1 of using
semantic features with Logistic Regression is 59.7%, which
is a 10.7% improvement over Logistic Regression with
PROMISE features.
The semantic features automatically learned from DBN
improve within-project defect prediction and the im-
provement is not tied to a particular classication al-
gorithm.
RQ2: Do semantic features outperform traditional
features for cross-project defect prediction?
In order to answer this question, we compare our pro-
posed cross-project defect prediction technique DBN-CP
with TCA+ [42]. DBN-CP runs on the semantic features
that are automatically generated by DBN, while TCA+
uses PROMISE features. For a fair comparison, we also
provide a benchmark of within-project defect prediction.
We conduct 22 sets of cross-project defect prediction exper-
iments. Each experiment takes two versions separately fromTable 4: F1 scores of cross-project defect prediction. F1
scores are measured in percentage. The best F1 scores be-
tween DBN-CP and TCA+ are highlighted in bold.
S
ource T
argetCro
ss-Project Wi
thin-Project
DBN
-CP TC
A+ S
emantic Features
a
nt1.6 c
amel1.4 3
1.6 2
9.27
8.5jEd
it4.1 c
amel1.4 6
9.3 3
3.0
c
amel1.4 a
nt1.6 9
7.9 6
1.69
1.4p
oi3.0 a
nt1.6 4
7.8 5
9.8
c
amel1.4 jEd
it4.1 6
1.5 5
3.76
1.5lo
g4j1.1 jEd
it4.1 5
0.3 4
1.9
jEd
it4.1 l
og4j1.1 6
4.5 5
7.47
0.1lu
cene2.2 l
og4j1.1 6
1.8 5
7.1
lu
cene2.2 xa
lan2.5 5
5.0 5
3.05
9.5xe
rces1.3 xa
lan2.5 5
7.2 5
8.1
xa
lan2.5 l
ucene2.2 5
9.4 5
6.16
5.1lo
g4j1.1 l
ucene2.2 6
9.2 5
2.4
xa
lan2.5 xe
rces1.3 3
8.6 3
9.44
1.1iv
y2.0 xe
rces1.3 4
2.6 3
9.8
xe
rces1.3 i
vy2.0 4
5.3 4
0.93
5.0sy
napse1.2 i
vy2.0 8
2.4 3
8.3
iv
y1.4 sy
napse1.1 4
8.9 3
4.85
4.4p
oi2.5 sy
napse1.1 4
2.5 3
7.6
iv
y2.0 sy
napse1.2 4
3.3 5
7.05
8.3p
oi3.0 sy
napse1.2 5
1.4 5
4.2
sy
napse1.2 p
oi3.0 6
6.1 6
5.18
0.3a
nt1.6 p
oi3.0 6
1.9 3
4.3
A
verage 5
6.8 4
7.9 6
3.2
two dierent projects, while one is as the training set and
the other one is as the test set. Dierent from DBN-CP and
TCA+, the benchmark of within-project defect prediction
uses the data from an older version of the target project as
the training set.
Table 4 contains the F1 scores of DBN-CP, TCA+, and
the benchmark within-project defect prediction. The better
F1 scores between DBN-CP and TCA+ are in bold. Take an
example of the experiment where the source project (train-
ing set) is from camel 1.4 and the target project (test set)
is from ant 1.6 . Running DBN-CP with camel 1.4 as the
training set and ant 1.6 as the test set produces a F1 of
97.9%, while running TCA+ on the same sets produces a
F1 of 61.6%. The within-project defect prediction for this
experiment uses semantic features with ant 1.5 as the train-
ing set and ant 1.6 as the test set, which are the same sets
with the experiment that uses ant 1.6 as the test set in Ta-
ble 2. In this experiment, running DBN-CP achieves a F1
score of 97.9%, which is even higher than the F1 score of
within-project defect prediction with a value of 91.4%.
From the point of average F1, DBN-CP achieves 56.8%,
which is 8.9% higher than the 47.9% of TCA+. Compared
with within-project defect prediction, DBN-CP makes
progress for cross-project defect prediction by reducing the
gap to only 6.4%.
Ou
r proposed DBN-CP improves the performance of
cross-project defect prediction. The semantic features
learned by DBN are eective and able to capture the
common characteristics of defects across projects.
R
Q3: What is the time and space cost of the pro-
posed DBN-based feature generation process?
While we conduct the 16 sets of within-project defect pre-
diction experiments for RQ1, we keep track of the time cost
and memory space cost for our proposed DBN-based fea-
ture generation process (refer to Section 3.3), in which DBN
304Table 5: Time and space cost of generating semantic features
(s: second)
ProjectGenerating Features
Time (s) Memory (MB)
ant 15.5 2.8
camel 32.0 5.5
jEdit 18.1 3.3
log4j 10.1 2.2
lucene 11.1 2.4
xalan 29.6 6.2
xerces 13.9 5.8
ivy 8.0 2.2
synapse 8.5 1.9
poi 11.9 4.4
generates semantic features automatically by using noise-
handled data. For the other processes, including parsing
source code, handling noise, mapping tokens, building mod-
els, and predicting defects, they are all common procedures,
so we do not analyze their costs.
Table 5 shows the time cost and the memory space cost
for generating semantic features. Give an example of ant,
Table 2 shows that anthas two sets of within-project defect
prediction experiments, which are ant 1.5 ->1.6 and ant
1.6->1.7 . On average, it takes the two experiments 15.5
seconds and 2.8MB memory for DBN to generate semantic
features for both the training data and the test data.
Among all the projects, the time cost of automatically
generating semantic features varies from 8.0 seconds ( ivy)
to 32.0 seconds (camel ). As for the memory space cost, it
takes less than 6.5MB for all the examined projects.
U
sing our proposed DBN-based approach to automati-
cally learn semantic features is applicable in practice.
6.
THREATS TO VALIDITY
Implementation of TCA+.
For the comparative analysis, we compare our proposed
CPDP approach with TCA+ [42], which is the state-of-the-
art CPDP technique. Since the original implementation is
not released, we have reimplemented our own version of
TCA+. Although we strictly followed the procedures de-
scribed in their work, our new implementation may not re-
ect all the implementation details of the original TCA+.
We test our implementation using data provided by their
work, since our implementation could generate the same re-
sults, we are condent that our implementation reects the
original TCA+.
In this work we did not evaluate our DBN-based fea-
ture generation approach on projects used for evaluating
TCA+ [42]. There are two reasons. First, our DBN-based
feature generation approach to within-project defect pre-
diction works on data of two dierent versions from the
same project, while datasets used in [42] only provided one
version of defect data for each of their eight projects, which
are unsuitable for evaluating our approach to within-project
defect prediction. Second, some of their examined projects
are C/C++ projects. The current implementation of our
DBN-based feature generation approach focuses on Java
projects, and all of the ten evaluated projects in this workare Java projects. Despite the threats, our comparison
should be fair, since we apply TCA+ and our approach on
the same projects, which are publicly available data from
PROMISE and are biased toward neither TCA+ nor our
approach.
Project selection.
The examined projects in this work have a large variance
in average buggy rates. We have tried our best to make our
dataset general and representative. However, it is still pos-
sible that these ten projects are not generalizable enough to
represent all software projects. Given projects that are not
included in the ten projects, our proposed approach might
generate better or worse results. Our proposed semantic fea-
tures generation approach is only evaluated on open source
Java projects. Its performance on closed source software and
projects written in other languages is unknown.
7. RELATED WORK
7.1 Software Defect Prediction
There are many software defect prediction tech-
niques [12, 18, 20, 23, 27, 32, 38, 40, 47, 52, 62, 70]. Most
defect prediction techniques leverage features that are
manually extracted from labeled historical defect data to
train machine learning based classiers [34]. Commonly
used features can be divided into static code features
and process features [33]. Code features include Halstead
features [10], McCabe features [31], CK features [5], and
MOOD features [11], which are widely examined and used
for defect prediction. Recently, process features have been
proposed and used for defect prediction. Moser et al. [38]
used the number of revisions, authors, past xes, and
ages of les as features to predict defects. Nagappan et
al. [40] proposed code churn features, and shown that these
features were eective for defect prediction. Hassan et
al. [12] used entropy of change features to predict defects.
Lee et al. [27] proposed 56 micro interaction metrics to
improve defect prediction. Other process features, including
developer individual characteristics [18, 48] and collabora-
tion between developers [27, 34, 51, 64], were also useful for
defect prediction.
Based on these features, many machine learning models
are built for two dierent defect prediction tasks|within-
project defect prediction and cross-project defect prediction.
7.1.1 Within-Project Defect Prediction
Within-project defect prediction (WPDP) uses training
data and test data that are from the same project. Many
machine learning algorithms have been adopted for WPDP,
including Support Vector Machine (SVM) [8], Bayesian
Belief Network [1], Naive Bayes (NB) [59], Decision Tree
(DT) [9,21,62], and Dictionary Learning [20].
Elish et al. [8] evaluated the capability of SVM in predict-
ing defect-prone software modules, and they compared SVM
against eight statistical and machine learning models on four
NASA datasets. Amasaki et al. [1] proposed an approach to
predict the nal quality of a software product by using the
Bayesian Belief Network. Tao et al. [59] proposed a Naive
Bayes based defect prediction model, they evaluated the pro-
posed approach on 11 datasets from the PROMISE defect
data repository. Wang et al. [62] and Khoshgoftaar et al. [21]
examined the performance of Tree-based machine learning
305algorithms on defect prediction, their results suggested that
Tree-based algorithms could help defect prediction. Jing et
al. [20] introduced the dictionary learning technique to de-
fect prediction. They proposed a cost-sensitive dictionary
learning based approach to improve defect prediction.
7.1.2 Cross-Project Defect Prediction
Due to the lack of data, it is often dicult to build accu-
rate models for new projects. To address this issue, cross-
project defect prediction (CPDP) models are trained by us-
ing data from other projects. Watanabe et al. [63] proposed
an approach for CPDP by transforming the target dataset
to the source dataset by using the average feature values.
Turhan et al. [61] proposed to use a nearest-neighbor lter
to improve CPDP. Nam et al. [42] proposed TCA+, which
adopted a state-of-the-art technique called Transfer Compo-
nent Analysis (TCA) and optimized TCA's normalization
process to improve CPDP. They evaluated TCA+ on eight
open-source projects, results shown TCA+ signicantly im-
proved CPDP. Nam et al. [41] and Jing et al. [19] used dier-
ent approaches to address the heterogeneous data problem
in cross-project defect prediction.
The main dierences between our approach and existing
approaches for within-project defect prediction and cross-
project defect prediction are as follows. First, existing ap-
proaches to defect prediction are based on manually encoded
traditional features which are not sensitive to programs' se-
mantic information, while our approach automatically learns
semantic features using DBN and uses these features to per-
form defect prediction tasks. Second, since our approach re-
quires only the source code of the training and test projects,
it is suitable for both within-project defect prediction and
cross-project defect prediction.
7.2 Deep Learning and Semantic Feature
Generation in Software Engineering
Recently, deep learning algorithms have been adopted to
improve research tasks in software engineering. Yang et
al. [68] proposed an approach that leveraged deep learning
to generate features from existing features and then used
these new features to predict whether a commit is buggy or
not. This work was motivated by the weaknesses of logistic
regression (LR) that LR can not combine features to gener-
ate new features. They used DBN to generate features from
14 traditional change level features: the number of mod-
ied subsystems, modied directories, modied les, code
added, code deleted, line of code before/after the change,
les before/after the change, and several developer experi-
ence related features [68].
Our work diers from the above study mainly in three
aspects. First, we use DBN to learn semantic features di-
rectly from source code, while features generated from their
approach are relations among existing features. Since the ex-
isting features used cannot distinguish many semantic code
dierences, the combination of these features would still fail
to distinguish the semantic dierences. For example, if two
changes add the same line at dierent locations in the same
le, the traditional features used cannot distinguish the two
changes. Thus, the generated new features, which are com-
binations of the traditional features, would also fail to dis-
tinguish the two changes. Second, we evaluate the eective-
ness of our generated features using dierent classiers and
for both within-project and cross-project defect prediction,while they use LR only for within-project defect prediction.
Third, we focus on le level defect prediction, while they
work on change level defect prediction.
Other studies leverage deep learning to address other
problems in software engineering. Lam et al. [26] combined
deep learning algorithms and information retrieval tech-
niques to improve fault localization. Raychev et al. [53]
reduced the code completion problem to a natural language
processing problem and used deep learning to predict the
probabilities of next tokens. White et al. [65] leveraged deep
learning to model program languages for code suggestion.
Similarly, Mou et al. [39] used deep learning to model
programs and showed that deep learning can capture
programs' structural information. In addition, deep learn-
ing has also been used for malware classication [50, 69],
acoustic recognition [24,36,37], etc.
Many studies used topic model [3] to extract semantic
features for dierent tasks in software engineering [4, 29,
45, 47, 56, 67]. Nguyen et al. [47] leveraged topic model to
generate features from source code for within-project defect
prediction. However, their topic model handled each source
le as one unordered token sequence. Thus, its generated
features cannot capture structural information in a source
le. Chen et al. [4] used topic model to generate features
for source les to help explain their defect-proneness. Liu
et al. [29] proposed to use topic model to generate features
from comments and identiers in source code. Then they
further used these features to model class cohesion.
In this work, we leverage DBN to automatically learn se-
mantic features from token vectors extracted from programs'
ASTs for both WPDP and CPDP.
8. CONCLUSIONS AND FUTURE WORK
This paper proposes to leverage a representation-learning
algorithm, deep learning, to learn semantic representation
directly from source code for defect prediction. Specically,
we deploy Deep Belief Network to learn semantic features
from token vectors extracted from programs' ASTs automat-
ically, and leverage the learned semantic features to build
machine learning models for predicting defects.
Our evaluation on ten open source projects shows that
the automatically learned semantic features could signi-
cantly improve both within-project and cross-project defect
prediction compared to traditional features. Our semantic
features improve the within-project defect prediction on av-
erage by 14.7% in precision, 11.5% in recall, and 14.2% in
F1 comparing with traditional features. For cross-project
defect prediction, our semantic features based approach im-
proves the state-of-the-art technique TCA+ built on tradi-
tional features by 8.9% in F1.
In the future, we would like to extend our automatically
semantic feature generation approach to C/C++ projects
for defect prediction. In addition, it would be promising
to leverage our approach to automatically generate features
for predicting defects at other levels, such as change level,
module level, and package level.
ACKNOWLEDGMENTS
The authors thank the anonymous reviewers for their feed-
back which helped improve this paper. This work has been
partially supported by the Natural Sciences and Engineering
Research Council of Canada.
3069. REFERENCES
[1] S. Amasaki, Y. Takagi, O. Mizuno, and T. Kikuno. A
Bayesian Belief Network for Assessing the Likelihood
of Fault Content. In ISSRE'03 , pages 215{226.
[2] Y. Bengio. Learning Deep Architectures for AI.
Foundations and Trends in Machine Learning ,
2(1):1{127, 2009.
[3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent
dirichlet allocation. the Journal of machine Learning
research , 3:993{1022, 2003.
[4] T.-H. Chen, S. W. Thomas, M. Nagappan, and A. E.
Hassan. Explaining software defects using topic
models. In MSR'12 , pages 189{198.
[5] S. R. Chidamber and C. F. Kemerer. A Metrics Suite
for Object Oriented Design. TSE'94 , 20(6):476{493.
[6] D. Ciresan, U. Meier, and J. Schmidhuber.
Multi-column deep neural networks for image
classication. In CVPR'12 , pages 3642{3649.
[7] F. B. e Abreu and R. Carapu ca. Candidate metrics for
object-oriented software within a taxonomy
framework. JSS'94 , 26(1):87{96.
[8] K. O. Elish and M. O. Elish. Predicting defect-prone
software modules using support vector machines.
JSS'08 , 81(5):649{660.
[9] N. Gayatri, S. Nickolas, A. Reddy, S. Reddy, and
A. Nickolas. Feature selection using decision tree
induction in class level metrics dataset for software
defect predictions. In WCECS'10 , pages 124{129.
[10] M. H. Halstead. Elements of Software Science
(Operating and programming systems series) . Elsevier
Science Inc., 1977.
[11] R. Harrison, S. J. Counsell, and R. V. Nithi. An
evaluation of the mood set of object-oriented software
metrics. TSE'98 , 24(6):491{496.
[12] A. E. Hassan. Predicting faults using the complexity
of code changes. In ICSE'09 , pages 78{88.
[13] Z. He, F. Peters, T. Menzies, and Y. Yang. Learning
from open-source projects: An empirical study on
defect prediction. In ESEM'13 , pages 45{54.
[14] K. Herzig, S. Just, and A. Zeller. It's not a bug, it's a
feature: how misclassication impacts bug prediction.
InICSE'13 , pages 392{401.
[15] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and
P. Devanbu. On the naturalness of software. In
ICSE'12 , pages 837{847.
[16] G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast
learning algorithm for deep belief nets. Neural
computation'06 , 18(7):1527{1554.
[17] G. E. Hinton and R. R. Salakhutdinov. Reducing the
dimensionality of data with neural networks.
Science'06, 313(5786):504{507.
[18] T. Jiang, L. Tan, and S. Kim. Personalized defect
prediction. In ASE'13 , pages 279{289.
[19] X. Jing, F. Wu, X. Dong, F. Qi, and B. Xu.
Heterogeneous cross-company defect prediction by
unied metric representation and cca-based transfer
learning. In FSE'15 , pages 496{507.
[20] X.-Y. Jing, S. Ying, Z.-W. Zhang, S.-S. Wu, and
J. Liu. Dictionary learning based software defect
prediction. In ICSE'14 , pages 414{423.
[21] T. Khoshgoftaar and N. Seliya. Tree-based software
quality estimation models for fault prediction. In
Software Metrics'02 , pages 203{214.[22] S. Kim, H. Zhang, R. Wu, and L. Gong. Dealing with
noise in defect prediction. In ICSE'11 , pages 481{490.
[23] S. Kim, T. Zimmermann, E. J. Whitehead Jr, and
A. Zeller. Predicting faults from cached history. In
ICSE'07 , pages 489{498.
[24] S. Kombrink, T. Mikolov, M. Kara at, and L. Burget.
Recurrent neural network based language modeling in
meeting recognition. In INTERSPEECH'11 , pages
2877{2880.
[25] A. Krizhevsky, I. Sutskever, and G. E. Hinton.
Imagenet classication with deep convolutional neural
networks. In Advances in neural information
processing systems'12 , pages 1097{1105.
[26] A. Lam, A. Nguyen, H. Nguyen, and T. Nguyen.
Combining deep learning with information retrieval to
localize buggy les for bug reports. In ASE'15 , pages
476{481.
[27] T. Lee, J. Nam, D. Han, S. Kim, and H. P. In. Micro
interaction metrics for defect prediction. In FSE'11 ,
pages 311{321.
[28] Z. Li and Y. Zhou. Pr-miner: automatically extracting
implicit programming rules and detecting violations in
large software code. In FSE'05 , pages 306{315.
[29] Y. Liu, D. Poshyvanyk, R. Ferenc, T. Gyim othy, and
N. Chrisochoides. Modeling class cohesion as mixtures
of latent topics. In ICSM'09 , pages 233{242.
[30] C. D. Manning and H. Sch utze. Foundations of
statistical natural language processing . MIT press,
1999.
[31] T. J. McCabe. A complexity measure. TSE'76 ,
(4):308{320.
[32] A. Meneely, L. Williams, W. Snipes, and J. Osborne.
Predicting failures with developer networks and social
network analysis. In FSE'08 , pages 13{23.
[33] T. Menzies, J. Greenwald, and A. Frank. Data mining
static code attributes to learn defect predictors.
TSE'07 , 33(1):2{13.
[34] T. Menzies, Z. Milton, B. Turhan, B. Cukic, Y. Jiang,
and A. Bener. Defect prediction from static code
features: current results, limitations, new approaches.
ASE'10 , 17(4):375{407.
[35] A. Mnih and G. E. Hinton. A scalable hierarchical
distributed language model. In Advances in neural
information processing systems'09 , pages 1081{1088.
[36] A. Mohamed, D. Yu, and L. Deng. Investigation of
full-sequence training of deep belief networks for
speech recognition. In INTERSPEECH'10 , pages
2846{2849.
[37] A.-r. Mohamed, G. E. Dahl, and G. Hinton. Acoustic
modeling using deep belief networks. Audio, Speech,
and Language Processing, IEEE Transactions on ,
20(1):14{22, 2012.
[38] R. Moser, W. Pedrycz, and G. Succi. A comparative
analysis of the eciency of change metrics and static
code attributes for defect prediction. In ICSE'08 ,
pages 181{190.
[39] L. Mou, G. Li, Z. Jin, L. Zhang, and T. Wang.
TBCNN: A tree-based convolutional neural network
for programming language processing. arXiv preprint
arXiv:1409.5718 , 2014.
307[40] N. Nagappan and T. Ball. Using software dependencies
and churn metrics to predict eld failures: An
empirical case study. In ESEM'07 , pages 364{373.
[41] J. Nam and S. Kim. Heterogeneous defect prediction.
InFSE'15 , pages 508{519.
[42] J. Nam, S. J. Pan, and S. Kim. Transfer defect
learning. In ICSE'13 , pages 382{391.
[43] G. Navarro. A guided tour to approximate string
matching. ACM Comput. Surv. , 33(1), 2001.
[44] A. T. Nguyen and T. N. Nguyen. Graph-based
statistical language model for code. In ICSE'15 , pages
858{868.
[45] A. T. Nguyen, T. T. Nguyen, T. N. Nguyen, D. Lo,
and C. Sun. Duplicate bug report detection with a
combination of information retrieval and topic
modeling. In ASE'12 , pages 70{79.
[46] T. T. Nguyen, H. A. Nguyen, N. H. Pham, J. M.
Al-Kofahi, and T. N. Nguyen. Graph-based mining of
multiple object usage patterns. In FSE'09 , pages
383{392.
[47] T. T. Nguyen, T. N. Nguyen, and T. M. Phuong.
Topic-based defect prediction. In ICSE'11 , pages
932{935.
[48] T. J. Ostrand, E. J. Weyuker, and R. M. Bell.
Programmer-based fault prediction. In PROMISE'10,
pages 19:1{19:10.
[49] S. J. Pan, I. Tsang, J. Kwok, and Q. Yang. Domain
adaptation via transfer component analysis. Neural
Networks, IEEE Transactions on , pages 199{210,
2011.
[50] R. Pascanu, J. W. Stokes, H. Sanossian, M. Marinescu,
and A. Thomas. Malware classication with recurrent
networks. In ICASSP'15 , pages 1916{1920.
[51] M. Pinzger, N. Nagappan, and B. Murphy. Can
developer-module networks predict failures? In
FSE'08 , pages 2{12.
[52] F. Rahman and P. Devanbu. How, and why, process
metrics are better. In ICSE'13 , pages 432{441.
[53] V. Raychev, M. Vechev, and E. Yahav. Code
completion with statistical language models. In
PLDI'14 , pages 419{428.
[54] R. Salakhutdinov and G. Hinton. Semantic hashing.
RBM'07 , 500(3):500.
[55] R. Sarikaya, G. E. Hinton, and A. Deoras. Application
of deep belief networks for natural language
understanding. Audio, Speech, and Language
Processing, IEEE/ACM Transactions on ,
22(4):778{784, 2014.[56] A. Tamrawi, T. T. Nguyen, J. M. Al-Kofahi, and
T. N. Nguyen. Fuzzy set and cache-based approach for
bug triaging. In FSE'11 , pages 365{375.
[57] M. Tan, L. Tan, S. Dara, and C. Mayeux. Online
defect prediction for imbalanced data. In ICSE'15 ,
pages 99{108.
[58] C. Tantithamthavorn, S. McIntosh, A. E. Hassan,
A. Ihara, and K. ichi Matsumoto. The impact of
mislabelling on the performance and interpretation of
defect prediction models. In ICSE'15 , pages 812{823.
[59] W. Tao and L. Wei-hua. Naive bayes software defect
prediction model. In CiSE'10 , pages 1{4.
[60] Z. Tu, Z. Su, and P. Devanbu. On the localness of
software. In FSE'14 , pages 269{280.
[61] B. Turhan, T. Menzies, A. B. Bener, and
J. Di Stefano. On the relative value of cross-company
and within-company data for defect prediction.
Empirical Softw. Engg. , 14(5):540{578, 2009.
[62] J. Wang, B. Shen, and Y. Chen. Compressed c4. 5
models for software defect prediction. In QSIC'12 ,
pages 13{16.
[63] S. Watanabe, H. Kaiya, and K. Kaijiri. Adapting a
fault prediction model to allow inter languagereuse. In
Proceedings of the 4th International Workshop on
Predictor Models in Software Engineering, pages
19{24, 2008.
[64] E. J. Weyuker, T. J. Ostrand, and R. M. Bell. Using
developer information as a factor for fault prediction.
InPROMISE'07, pages 8{8.
[65] M. White, C. Vendome, M. Linares-V asquez, and
D. Poshyvanyk. Toward deep learning software
repositories. In MSR'15 , pages 334{345.
[66] I. H. Witten and E. Frank. Data Mining: Practical
machine learning tools and techniques . Morgan
Kaufmann, 2005.
[67] X. Xie, W. Zhang, Y. Yang, and Q. Wang. Dretom:
Developer recommendation based on topic models for
bug resolution. In PROMISE'12, pages 19{28.
[68] X. Yang, D. Lo, X. xia, Y. Zhang, and J. Sun. Deep
learning for just-in-time defect prediction. In QRS'15 ,
pages 17{26.
[69] Z. Yuan, Y. Lu, Z. Wang, and Y. Xue. Droid-sec:
Deep learning in android malware detection. In
SIGCOMM'14 , pages 371{372.
[70] T. Zimmermann, R. Premraj, and A. Zeller.
Predicting defects for eclipse. In PROMISE'07, pages
9{9.
308