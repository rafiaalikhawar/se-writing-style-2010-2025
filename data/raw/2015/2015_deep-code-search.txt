Deep Code Search
Xiaodong Gu1, Hongyu Zhang2, and Sunghun Kim1,3
1The Hong Kong University of Science and Technology, Hong Kong
guxiaodong1987@126.com,hunkim@cse.ust.hk
2The University of Newcastle, Callaghan, Australia
hongyu.zhang@newcastle.edu.au
3Clova AI Research, NAVER
ABSTRACT
Toimplementaprogramfunctionality,developerscanreusepre-
viouslywrittencodesnippetsbysearchingthroughalarge-scale
codebase.Overtheyears,manycodesearchtoolshavebeenpro-
posedtohelpdevelopers.Theexistingapproachesoftentreatsource
code as textual documents and utilize information retrieval models
to retrieve relevant code snippets that match a given query. These
approaches mainly rely on the textual similarity between source
code and natural language query. They lack a deep understanding
of the semantics of queries and source code.
Inthispaper,weproposeanoveldeepneuralnetworknamed
CODEnn (Code-Description Embedding Neural Network). Instead
of matching text similarity, CODEnn jointly embeds code snippets
and natural language descriptions into a high-dimensional vec-
tor space, in such a way that code snippet and its correspondingdescription have similar vectors. Using the unified vector repre-sentation, code snippets related to a natural language query can
be retrieved according to their vectors. Semantically related words
can also be recognized and irrelevant/noisy keywords in queries
can be handled.
As a proof-of-concept application, we implement a code search
toolnamedDeepCSusingtheproposedCODEnnmodel.Weem-
pirically evaluate DeepCS on a large scale codebase collected from
GitHub.Theexperimentalresultsshowthatourapproachcanef-
fectively retrieve relevant code snippets and outperforms previous
techniques.
CCS CONCEPTS
•Software and its engineering →Reusability;
KEYWORDS
code search, deep learning, joint embedding
ACM Reference Format:
Xiaodong Gu1, Hongyu Zhang2, and Sunghun Kim1,3. 2018. Deep Code
Search. In ICSE ’18: ICSE ’18: 40th International Conference on Software
Engineering , May 27-June 3, 2018, Gothenburg, Sweden. ACM, New York,
NY, USA, 12 pages. https://doi.org/10.1145/3180155.3180167
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
©2018 Copyright held by the owner/author(s). Publication rights licensed to the
Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.31801671 INTRODUCTION
Code search is a very common activity in software development
practices[ 57,68].Toimplementacertainfunctionality,forexample,
toparse XMLfiles, developersusually searchand reusepreviously
written code by performing free-text queries over a large-scale
codebase.
Many code search approaches have been proposed [ 13,15,29,
31,32,35,44,45,47,62], most of them being based on information
retrieval(IR)techniques.Forexample,Linsteadetal.[ 43]proposed
Sourcerer,aninformationretrievalbasedcodesearchtoolthatcom-
bines the textual content of a program with structural information.
McMillanetal.[ 47]proposedPortfolio,whichreturnsachainof
functions through keyword matching and PageRank. Lu et al. [ 44]
expanded a query with synonyms obtained from WordNet and
then performed keyword matching of method signatures. Lv etal. [
45] proposed CodeHow, which combines text similarity and
API matching through an extended Boolean model.
AfundamentalproblemoftheIR-basedcodesearchisthemis-
match between the high-level intent reflected in the natural lan-
guagequeriesandlow-levelimplementationdetailsinthesource
code [12,46]. Source code and natural language queries are hetero-
geneous.Theymaynotsharecommonlexicaltokens,synonyms,orlanguagestructures.Instead,theymayonlybesemanticallyrelated.
Forexample,arelevantsnippetforthequery“ readanobjectfrom
an xml” could be as follows:
public static < S > S deserialize (Class c, File xml) {
try{
JAXBContext context =JAXBContext .newInstance(c);
Unmarshaller unmarshaller =context.createUnmarshaller();
S deserialized =(S) unmarshaller .unmarshal(xml);
returndeserialized;
} catch(JAXBException ex) {
log.error("Error-deserializing-object-from-XML" ,ex);
return null ;
}
}
Existing approaches may not be able to return this code snippet
as it does not contain keywords such as readandobjector their
synonymssuchas loadandinstance.Therefore,aneffectivecode
searchenginerequiresahigher-levelsemanticmappingbetween
code and natural language queries. Furthermore, the existing ap-
proacheshavedifficultiesinqueryunderstanding[ 27,29,45].They
cannoteffectivelyhandleirrelevant/noisykeywordsinqueries[ 27].
Therefore, an effective code search engine should also be able to
understandthesemanticmeaningsofnaturallanguagequeriesand
source code in order to improve the accuracy of code search.
Inourpreviouswork,weintroducedtheDeepAPIframework[ 27],
which is a deep learning based method that learns the semantics of
queries and the corresponding API sequences. However, searching
sourcecodeismuchmoredifficultthangeneratingAPIs,because
9332018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Xiaodong Gu, Hongyu Zhang, and Sunghun Kim
thesemanticsofcodesnippetsarerelatednotonlytotheAPIse-
quencesbutalsotoothersourcecodeaspectssuchastokensand
methodnames.Forexample,DeepAPIcouldreturnthesameAPI
ImageIO.write for the query save image as png andsave image as
jpg.Nevertheless,theactualcodesnippetsforansweringthetwo
queries are different in terms of source code tokens. Therefore, the
code search problem requires models that can exploit more aspects
of the source code.
Inthispaper,weproposeanoveldeepneuralnetworknamedCO-
DEnn(Code-DescriptionEmbeddingNeuralNetwork).Tobridge
thelexicalgapbetweenqueriesandsource code,CODEnnjointly
embeds code snippets and natural language descriptions into a
high-dimensional vector space, in such a way that code snippetand its corresponding description have similar vectors. With the
unifiedvectorrepresentation,codesnippetssemanticallyrelated
to a natural language query can be retrieved according to their
vectors. Semantically related words can also be recognized and
irrelevant/noisy keywords in queries can be handled.
Using CODEnn, weimplement a code search tool,DeepCS as a
proof of concept. DeepCS trains the CODEnn model on a corpus of
18.2millionJavacodesnippets(intheformofcommentedmethods)
from GitHub. Then, it reads code snippets from a codebase and
embedsthemintovectorsusingthetrainedCODEnnmodel.Finally,
whenauserqueryarrives,DeepCSfindscodesnippetsthathave
the nearest vectors to the query vector and return them.
Toevaluatetheeffectivenessof DeepCS,weperformcodesearch
on a search codebase using 50 real-world queries obtained from
StackOverflow.OurresultsshowthatDeepCSreturnsmorerele-
vantcodesnippetsthanthetworelatedapproaches,thatis,Code-
How [45] and a conventional Lucene-based code search tool [ 5].
On average, the first relevant code snippet returned by DeepCSis ranked 3.5, while the first relevant results returned by Code-How [
45] and Lucene [ 43] are ranked 5.5 and 6.0, respectively.
For 76% of the queries, the relevant code snippets can be found
within the top 5 returned results. The evaluation results confirm
the effectiveness of DeepCS.
Toourknowledge,wearethefirsttoproposedeeplearningbased
code search. The main contributions of our work are as follows:
•Weproposeanoveldeepneuralnetwork,CODEnn,tolearnaunifiedvectorrepresentationofbothsourcecodeandnatural
language queries.
•We develop DeepCS, a tool that utilizes CODEnn to retrieve
relevant code snippets for given natural language queries.
•WeempiricallyevaluateDeepCSusingalargescalecodebase.
Therestofthispaperisorganizedasfollows.Section2describes
the background of the deep learning based embedding models.Section 3 describes the proposed deep neural network for codesearch. Section 4 describes the detailed design of our approach.Section 5 presents the evaluation results. Section 6 discusses our
work, followed by Section 7 that presents the related work. We
conclude the paper in Section 8.
2 BACKGROUND
Ourworkadoptsrecentadvancedtechniquesfromdeeplearning
and natural language processing [ 10,17,70]. In this section, we
discuss the background of these techniques.Hidden LayerOutput Layer
Input Layer
htht-1
wt
(a)RNN StructureEmbedding
h1 h2 h3
parse xml filew1 w2 w3
(b)RNN for sentence embedding
Figure 1: Illustration of the RNN Sentence Embedding
2.1 Embedding Techniques
Embedding(alsoknownasdistributedrepresentation[ 50,72])is
a techniquefor learningvector representationsof entitiessuch as
words, sentences and images in such a way that similar entities
have vectors close to each other [48, 50].
Atypicalembeddingtechniqueiswordembedding,whichrepre-
sents words as fixed-length vectors so that similar words are close
toeachotherinthevectorspace[ 48,50].Forexample,supposethe
wordexecuteisrepresentedas[0.12,-0.32,0.01]andtheword run
isrepresentedas[0.12,-0.31,0.02].Fromtheirvectors,wecanes-
timate their distance and identify their semantic relation. Wordembedding is usually realized using a model such as CBOW and
Skip-Gram[ 48].Thesemodelsbuildaneuralnetworkthatcaptures
the relations between a word and its contextual words. The vector
representationsofwords,asparametersofthenetwork,aretrained
with a text corpus [50].
Likewise,asentence(i.e.,asequenceofwords)canalsobeem-
bedded as a vector [ 59]. A simple way of sentence embedding is,
for example, to view it as a bag of words and add up all its word
vectors [39].
2.2 RNN for Sequence Embedding
Wenowintroduceawidely-useddeepneuralnetwork,theRecur-
rent Neural Networks (RNN) [ 49,59] for the embedding of sequen-
tial data such as natural language sentences. The Recurrent Neural
Network is a class of neural networks where hidden layers arerecurrently used for computation. This creates an internal stateof the network to record dynamic temporal behavior. Figure 1a
shows the basic structure of an RNN. The neural network includes
three layers, an input layer which maps each input to a vector, a
recurrenthiddenlayer whichrecurrentlycomputesand updatesa
hiddenstateafterreadingeachinput,andanoutputlayerwhich
utilizesthehiddenstateforspecifictasks.Unliketraditionalfeed-
forward neural networks, RNNs can embed sequential inputs such
as sentences using their internal memory [25].
Consider a natural language sentence with a sequence of T
wordss=w1, ...,wT, RNN embeds it through the following com-
putations:it readswordsin thesentence oneby one, andupdates a
hiddenstateateachtimestep.Eachword wtisfirstmappedtoa
d-dimensionalvector wt∈Rdbyaone-hotrepresentation[ 72]or
word embedding [ 50]. Then, the hidden state (values in the hidden
layer)htisupdatedattime tbyconsideringtheinputword wtand
the preceding hidden state ht−1:
ht=tanh(W[ht−1;wt]),∀t=1,2, ... ,T (1)
934
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. Deep Code Search ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
3475
1520
8324
h0h1h2h3max pooling 
with 1h4 
window size7
5
8
Figure 2: Illustration of max pooling
where [a;b]∈R2drepresents the concatenation of two vectors, W∈
R2d×dis the matrix of trainable parameters in the RNN, while
tanhis a non-linearity activation function of the RNN. Finally,
the embedding vector of the sentence is summarized from the
hiddenstates h1, ...,hT.Atypicalwayistoselectthelasthidden
statehTastheembeddingvector.Theembeddingvectorcanalsobe
summarizedusingothercomputationssuchasthemaxpooling[ 36]:
s=maxpooling([ h1, ... ,hT]) (2)
Maxpooling is an operation that selects the maximum value in
each fixed-size region over a matrix. Figure 2 shows an example
ofmaxpoolingoverasequenceofhiddenvectors h1, ...,hT.Each
columnrepresentsahiddenvector.Thewindowsizeofeachregion
is set to 1 ×Tin this example. The result is a fixed-length vector
whose elements are the maximum values of each row. Maxpooling
cancapturethemostimportantfeature(onewiththehighestvalue)
for each region and can transform sentences of variable lengths
into a fixed-length vector.
Figure1bshowsanexampleofhowRNNembedsasentence(e.g.,
parse xml file ) into a vector. To facilitate understanding, we expand
therecurrenthiddenlayerforeachtimestep.TheRNNreadswordsin the sentence one by one, and records a hidden state at each time
step. When it reads the first word parse, it maps the word into a
vectorw1andcomputesthecurrenthiddenstate h1usingw1.Then,
itreadsthesecondword xml,embedsitinto w2,andupdatesthe
hidden state h1toh2usingw2. The procedure continuesuntil the
RNNreceivesthelastword fileandgetsthefinalstate h3.Thefinal
stateh3can be used as the embedding cof the whole sentence.
The embedding of the sentence, i.e., the sentence vector, can
be used for specific applications. For example, one can build a
languagemodelconditioningonthesentencevectorformachine
translation [ 17]. One can also embed two sentences (a question
sentence and an answer sentence) and compare their vectors for
answer selection [21, 71].
2.3 Joint Embedding of Heterogeneous Data
Suppose there are two heterogeneous data sets XandY. We want
to learn a correlation between them, namely,
f:X→Y (3)
For example, suppose Xis a set of images and Yis a set of natural
languagesentences, fcanbethecorrelationbetweentheimages
andthesentences(i.e.,imagecaptioning).Sincethetwodatasourcesareheterogeneous,itisdifficulttodiscoverthecorrelation
fdirectly.
Thus, we need a bridge to connect these two levels of information.
Joint Embedding, also known as multi-modal embedding [ 78], is
atechniquetojointlyembed/correlateheterogeneousdataintoa
unified vector space so that semantically similar concepts acrossthe two modalities occupy nearby regions of the space [
33]. The
joint embedding of XandYcan be formulated as:
Xϕ− →VX→J(VX,VY)←VYψ←−Y (4)“read a text file 
line by line”
“read an object 
from an xml file”
Description(Query)
Embedding
Code
Embeddingpublic voidreadText(String file) {
BufferedReader br = newBufferedReader(
newFileInputStream(file));
String line = null;
while((line = br.readLine())!= null) {
System.out.println(line);
}
br.close();
}
public <S> S deserialize(Class c,File xml) {
JAXBContext context 
= JAXBContext.newInstance(c);
Unmarshaller unmarshaller
= context.createUnmarshaller();
S deserialized
=(S)unmarshaller.unmarshal(xml);
returndeserialized;
}
Figure3: Anexampleshowingtheideaofjointembeddingforcode
and queries. The yellow points represent query vectors while the
blue points represent code vectors.
whereϕ:X→Rdis an embedding function to map Xinto a d-
dimensional vector space V;ψ:Y→Rdis an embedding function
tomapYintothesamevectorspace V;J(·,·)isasimilaritymea-
sure(e.g.,cosine)toscorethematchingdegreesof VXandVYin
order to learn the mapping functions. Through joint embedding,
heterogeneous data can be easily correlated through their vectors.
Joint embedding has been used in many tasks [ 22,74,78]. For
example,in computervision, Karpathyand Li[ 33]use aConvolu-
tional Neural Network (CNN) [ 22], a deep neural network as the
ϕand an RNN as the ψ, to jointly embed both image and text into
the same vector space for labeling images [33].
3 A DEEP NEURAL NETWORK FOR CODE
SEARCH
Inspired by existing joint embedding techniques [ 21,22,33,78],
weproposeanoveldeepneuralnetworknamedCODEnn(Code-
Description Embedding Neural Network) for the code search prob-
lem. Figure 3 illustrates the key idea. Natural language queries and
code snippets are heterogeneous and cannot be easily matched ac-
cording to their lexical tokens. To bridge the gap, CODEnn jointly
embeds code snippets and natural language descriptions into a
unified vector space so that a query and the corresponding code
snippets are embedded into nearby vectors and can be matched by
measuring vector similarities.
3.1 Architecture
AsintroducedinSection2.3,ajointembeddingmodelrequiresthree
components: the embedding functions ϕ:X→Rdandψ:Y→Rd,
as well as the similarity measure J(·,·). CODEnn realizes these
components with deep neural networks.
Figure 4 shows the overall architecture of CODEnn. The neu-
ral network consists of three modules, each corresponding to a
component of joint embedding:
•a code embedding network (CoNN) to embed source code
into vectors.
•a description embedding network (DeNN) to embed natural
language descriptions into vectors.
•a similarity module that measures the degree of similarity
between code and descriptions.
The following subsections describe the detailed design of these
modules.
3.1.1 Code Embedding Network. The code embedding network
embedssourcecodeintovectors.Sourcecodeisnotsimplyplain
text. It contains multiple aspects of information such as tokens,
controlflowsandAPIs[ 46].Inourmodel,weconsiderthreeaspects
935
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Xiaodong Gu, Hongyu Zhang, and Sunghun Kim
Code Embedding 
Network (CoNN)Description Embedding 
Network(DeNN)
Code Description
Code Vector Description Vector
Cosine 
Similarity
(a)Overall ArchitectureCode Description
RNNRNNRNNmax pooling
read a text
RNN
fileRNN
RNNmax pooling
MLP
text reader
RNN
RNN
RNNmax pooling
Scanner.new Scanner.next Scanner.closemax pooling
str buff close
MLPFusion
MLP
method name [M] API sequence [A] Tokens [Ȟ]code vector [ ⃗ࢉ] description vector [ ࢊ]
࢓࢚⃗ࢇ
[D]Cosine 
Similarity
(b)Detailed Structure
Figure 4: The structure of the Code-Description Embedding Neural Network
ofsourcecode:themethodname,theAPIinvocationsequence,and
the tokens contained in the source code. They are commonly used
in existing code search approaches [ 19,27,41,44,45]. For each
codesnippet(atthemethodlevel),weextractthesethreeaspects
of information. Each is embedded individually and then combined
into a single vector representing the entire code.
Consider an input code snippet C=[M,A,Γ], where M=w1,...,
wNMisthe methodnamerepresented asasequence of NMcamel
split tokens [ 1];A=a1, ...,aNAis the API sequence with NAcon-
secutive API method invocations, and Γ={τ1, ...,τNΓ} is the set of
tokensinthesnippet.Theneuralnetworkembedsthethreeaspects
asfollows:forthemethodname M,itembedsthesequenceofcamel
split tokens using an RNN with maxpooling:
ht=tanh(WM[ht−1;wt]),∀t=1,2, ... ,NM
m=maxpooling([ h1, ... ,hNM])(5)
wherewt∈Rdis the embedding vector of token wt,[a;b]∈R2drep-
resentstheconcatenationoftwovectors, WM∈R2d×disthematrix
of trainable parameters in the RNN, tanhis the activation function
of theRNN. Amethod name isthus embedded asa d-dimensional
vectorm.
Likewise, the API sequence Ais embedded into a vector ausing
an RNN with maxpooling:
ht=tanh(WA[ht−1;at]),∀t=1,2, ... ,NA
a=maxpooling([ h1, ... ,hNA])(6)
whereat∈Rdis the embedding vector of API at,WAis the matrix
of trainable parameters in the RNN.
For the tokens Γ, as they have no strict order in the source code,
theyaresimplyembeddedviaamultilayerperceptron(MLP),i.e.,
the conventional fully connected layer [52]:
hi=tanh(WΓτi),∀i=1,2, ... ,NΓ (7)
whereτi∈Rdrepresents the embedded representation of the to-
kenτi,WΓis the matrix of trainable parameters in the MLP,
hi,i=1, ...,NΓare the embedding vectors of all individual tokens.
The individual vectors are also summarized to a single vector tvia
maxpooling:
t=maxpooling([ h1, ... ,hNΓ]) (8)
Finally,thevectorsofthethreeaspectsarefusedintoonevector
through a fully connected layer:c=tanh(WC[m;a;t]) (9)
where [a;b;c] represents the concatenation of three vectors, WCis
the matrix of trainable parameters in the MLP. The output vector c
represents the final embedding of the code snippet.
3.1.2 DescriptionEmbeddingNetwork. Thedescriptionembed-
dingnetwork(DeNN)embedsnaturallanguagedescriptionsinto
vectors. Consider a description D=w1, ...,wNDcomprising a se-
quenceof NDwords.DeNNembedsitintoavector dusinganRNN
with maxpooling:
ht=tanh(WD[ht−1;wt]),∀t=1,2, ... ,ND
d=maxpooling([ h1, ... ,hND])(10)
wherewt∈Rdrepresents the embedded representation of the de-
scriptionword wt,WDisthematrixoftrainableparametersinthe
RNN,ht,t=1, ...NDare the hidden states of the RNN.
3.1.3 SimilarityModule. Wehavedescribedthetransformations
that map the code and description into vectors (i.e., the candd).
Since we want the vectors of code and description to be jointly
embedded, we measure the similarity between the two vectors.
We use the cosine similarity for the measurement, which is
defined as:cos(c,d)=cTd
/bardblc/bardbl/bardbld/bardbl(11)
wherecanddare the vectors of code and a description respec-
tively. The higher the similarity, the more related the code is to the
description.
Overall,CODEnntakesa /angbracketleftcode,description /angbracketrightpairasinputand
predicts their cosine similarity cos( c,d).
3.2 Model Training
NowwepresenthowtotraintheCODEnnmodeltoembedboth
code and descriptions into a unified vector space. The high-level
goalofthejointembeddingis:ifacodesnippetandadescription
have similar semantics, their embedded vectors should be close to
eachother.Inotherwords,givenanarbitrarycodesnippet Cand
anarbitrarydescription D,wewantittopredictahighsimilarity
ifDis a correct description of C, and a little similarity otherwise.
At training time, we construct each training instance as a triple
/angbracketleftC,D+,D-/angbracketright: for each code snippet Cthere is a positive description
936
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. Deep Code Search ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Code VectorsRecommen ded 
Code
Search 
Codebase
Nearest
Vectors 
SelectionQuery
Query Vectorembedding0101010
Commented 
Code Snippets
Training
Instances
TrainingOffline Training 
code snippets 
(Java methods)
Offline Embeddingaspect 
extraction
aspect 
extraction
CODEnn
Model
natural 
language 
descriptions
)
ction
 code snippets 
(Java methods)
Figure 5: The overall workflow of DeepCS
D+(acorrect descriptionof C) aswellas anegative description(an
incorrectdescriptionof C)D-randomlychosenfromthepoolofall
D+’s.When trainedonthe setof /angbracketleftC,D+,D-/angbracketrighttriples,the CODEnn
predicts the cosine similarities of both /angbracketleftC,D+/angbracketrightand/angbracketleftC,D-/angbracketrightpairs
and minimizes the ranking loss [18, 22]:
L(θ)=/summationdisplay.1
<C,D+,D->∈Pmax(0,ϵ−cos(c,d+)+cos(c,d-))(12)
whereθdenotes the model parameters, Pdenotes the training
dataset,ϵis a constant margin. c,d+andd-are the embedded
vectors of C,D+andD-, respectively. A small, fixed ϵvalue of
0.05 is used in all the experiments. Intuitively, the ranking loss
encourages the cosine similarity between a code snippet and its
correct description to go up, and the cosine similarities between a
code snippet and incorrect descriptions to go down.
4 DEEPCS: DEEP LEARNING BASED CODE
SEARCH
In this section, we describe DeepCS, a code search tool based on
the proposed CODEnn model. DeepCS recommends top K most
relevant code snippets for a given natural language query. Figure 5
showstheoverallarchitecture.Itincludesthreemainphases:offline
training, offline code embedding, and online code search.
We begin by collecting a large-scale corpus of code snippets,
i.e., Java methods with corresponding descriptions. We extract sub-
elements (including method names, tokens, and API sequences)
fromthemethods.Then,weusethecorpustotraintheCODEnn
model(theofflinetrainingphase).Foragivencodebasefromwhich
users would like to search for code snippets, DeepCS extracts code
elementsforeachJavamethodinthesearchcodebase,andcomputesacodevectorusingtheCoNNmoduleofthetrainedCODEnnmodel
(theofflineembeddingphase).Finally,whenauserqueryarrives,
DeepCSfirstcomputesthevectorrepresentationofthequeryusing
the DeNN module of the CODEnn model, and then returns codesnippets whose vectors are close to the query vector (the online
code search phase).
In theory, our approach could search for source code written in
anyprogramminglanguages.Inthispaper,welimitourscopeto
the Java code. The following sections describe the detailed steps of
our approach.
4.1 Collecting Training Corpus
AsdescribedinSection3,theCODEnnmodelrequiresalarge-scale
training corpus that contains code elements and the correspond-ing descriptions, i.e., the
/angbracketleftmethod name, API sequence, tokens,description /angbracketrighttuples.Figure6 showsanexcerptofthe trainingcor-
pus.
We buildthe trainingtuples usingJava methodsthat havedoc-
umentationcomments1fromopen-sourceprojectsonGitHub[ 3].
Foreach Javamethod,weuse themethoddeclarationas thecode
elementandthe firstsentenceofitsdocumentation commentasits
natural language description. According to the Javadoc guidance2,
thefirstsentenceisusuallyasummaryofamethod.Topreparethedata,wedownloadJavaprojectsfromGitHubcreatedfromAugust,
2008 to June, 2016. To remove toy or experimental programs, we
excludeanyprojectswithoutastar.WeselectonlytheJavamethods
that have documentation comments from the downloaded projects.
Finally, we obtain a corpus comprising 18,233,872 commented Java
methods.
Havingcollectedthecorpusofcommentedcodesnippets,weex-
tract the/angbracketleftmethod name, API sequence, tokens, description /angbracketrighttuples
as follows:Method Name Extraction:
ForeachJavamethod,weextractits
name and parse the name into a sequence of tokens accordingto camel case [
1]. For example, the method name listFileswill be
parsed into the tokens listandfiles.
APISequenceExtraction: WeextractanAPIsequencefromeach
Java method using the same procedures as described in Deep-
API [27] – parsing the AST using the Eclipse JDT compiler [ 2]
and traversing the AST. The API sequences are produced as fol-
lows [27]:
•For each constructor invocation new C(), we produce C.new
and append it to the API sequence.
•For each method call o.m()whereois an instance of class C,
we produce C.mand append it to the API sequence.
•For a method call passed as a parameter, we append themethod before the calling method. For example,
o1.m1(o2
.m2(),o3.m3()), we produce a sequence C2.m2-C3.m3-C1.m1,
whereCiis the class of the instance oi.
•For a sequence of statements s1;s2;...;sN, we extract the API
sequence aifromeachstatement si,concatenatethemtothe
API sequence a1-a2-...-aN.
•For conditional statements such as if( s1){s2;}else{s3;}, we cre-
ateasequencefromallpossiblebranches,thatis, a1-a2-a3,
whereaiistheAPIsequenceextractedfromthestatement si.
•For loop statements such as while( s1){s2;}, we produce a
sequence a1-a2,wherea1anda2areAPIsequencesextracted
from the statement s1ands2, respectively.
Token Extraction: To collect tokens from a Java method, we tok-
enizethemethodbody,spliteachtokenaccordingtocamelcase[ 1],
andremovetheduplicatedtokens.Wealsoremovestopwords(suchastheandin)andJavakeywordsastheyfrequentlyoccurinsource
code and are not discriminative.Description Extraction:
To extract the documentation comment,
weusetheEclipseJDTcompiler[ 2]toparsetheASTfromaJava
method and extract the JavaDoc Comment from the AST.
1A documentation comment in JAVA starts with slash-asterisk-asterisk (/ ∗∗) and ends
with asterisk-slash ( ∗/)
2http://www.oracle.com/technetwork/articles/java/index-137868.html
937
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Xiaodong Gu, Hongyu Zhang, and Sunghun Kim
Method Name API Sequence Tokens Description (English)
1file reader InputStream.read →OutputStream.write input, output, stream, write copy a file from an inputstream
2open URL.new →URL.openConnection url, open, conn open a url
3test exists File.new→File.exists file, create, exists test file exists
⋮⋮ ⋮ ⋮ ⋮
Figure 6: An excerpt of training tuples
/**
* Converts a Date into a Calendar. 
* @param date the date to convert to a Calendar
* @return the created Calendar* @throws NullPointerException if null is passed in
* @since 3.0
*/
public static Calendar toCalendar (finalDate date) {
finalCalendar c =Calendar .getInstance();
c.setTime(date);
returnc;
}
Method Name: to calendar
API sequence: Calendar.getInstance Calendar.setTime
Tokens: calendar, get, instance, set, time, date
Description:  converts a date into a calendar.
Figure 7: An example of extracting code elements from a Java
method DateUtils.toCalendar3
Figure7showsanexampleofcodeelementsanddocumentation
commentsextractedfromaJavamethod DateUtils .toCalendar3in
theApache commons-lang library.
4.2 Training CODEnn Model
We use the large-scale corpus described in the previous section
to train the CODEnn model, following the method described in
Section 3.2.
ThedetailedimplementationoftheCODEnnmodelisasfollows:
weusethebi-directionalLSTM[ 70],astate-of-the-artsubclassof
RNN for the RNN implementation. All LSTMs have 200 hidden
unitsineachdirection.Wesetthedimensionofwordembedding
to100.TheCODEnnhastwotypesofMLPs,theembeddingMLP
forembeddingindividualtokensandthefusionMLPtocombine
the embeddings of different aspects. We set the number of hidden
units as 100 for the embedding MLP and 400 for the fusion MLP.
The CODEnn model is trained via the mini-batch Adam algo-
rithm[37,40].Wesetthebatchsize(i.e.,thenumberofinstances
per batch) as 128. For training the neural networks, we limit the
size of the vocabulary to 10,000 words that are most frequently
used in the training dataset.
We build our model on Keras [ 4] and Theano [ 6], two open-
source deep learning frameworks. We train our models on a server
withoneNvidiaK40GPU.Thetraininglasts ∼50hourswith500
epochs.
4.3 Searching Code Snippets
Givenauser’sfree-textquery,DeepCSreturnstherelevantcode
snippets through the trained CODEnn model. It first computes the
codevectorforeachcodesnippet(i.e.,aJavamethod)inthesearch
codebase.Then,itselectsandreturnsthecodesnippetsthathave
the top K nearest vectors to the query vector.
Morespecially,beforeasearchstarts,DeepCSembedsallcode
snippets in the codebase into vectors using the CoNN module of
3https://github.com/apache/commons-lang/blob/master/src/main/java/org/apache/
commons/lang3/time/DateUtils.javaCODEnn in an off-line manner. During the on-line search, when
adeveloperentersanatural languagequery,DeepCSfirstembeds
the query into a vector using the DeNN module of CODEnn. Then,
it estimates the cosine similarities between the query vector and
all code vectors using Equation 11. Finally, the top K code snippets
whose vectors are most similar to the query vector are returned as
the search results. Kis set to 10 in our experiments.
5 EVALUATION
In this section, we evaluate DeepCS through experiments. We also
compare DeepCS with the related code search approaches.
5.1 Experimental Setup
5.1.1 SearchCodebase. TobetterevaluateDeepCS,ourexper-
iments are performed over a search codebase, which is different
fromthetrainingcorpus.Codesnippetsthatmatchauserqueryareretrievedfromthesearchcodebase.Inpractice,thesearchcodebase
could be an organization’s local codebase or any codebase created
from open source projects.
Toconstructthesearchcodebase,wechoosetheJavaprojects
thathaveatleast20starsinGitHub.Differentfromthetrainingcor-pus,theyareconsideredinisolationandcontainallcode(including
thosedonothaveJavadoccomments).Thereare9,950projectsin
total.Weselectall16,262,602methodsfromtheseprojects.Foreach
Javamethod,weextracta /angbracketleftmethodname,APIsequence,tokens /angbracketright
triple to generate its code vector.
5.1.2 QuerySubjects. Toselectcodesearchqueriesfortheeval-
uation, we adopt a systematic procedure used in [ 41]4. We build
abenchmarkofqueriesfromthetop50votedJavaprogramming
questionsinStackOverflow.Toachieveso,webrowsethelistof
Java-taggedquestionsinStackOverflowandsortthemaccordingto
thevotesthateachonereceives5.Wemanuallycheckthesortedlist
sequentially,andaddquestionsthatsatisfythefollowingconditions
to the benchmark:
(1) The question is a concrete Java programming task. We exclude
questionsaboutproblems,knowledge,configurations,experience
andquestionswhosedescriptionsarevagueandabstract.Forex-
ample,Failed to load the JNI Library, What is the difference between
StringBuilderandStringBuffer?,and WhydoesJavahavetransient
fields?. (2) The accepted answer to the question contains a Javacode snippet. (3) The question is not a duplicate of the previous
questions. We filter out questions that are tagged as “duplicated”.
The full list of the 50 selected queries can be found in Table 1.
For each query, two developers manually inspect the top 10 results
returnedbyDeepCSandlabeltheirrelevancetothequery.Then
theydiscusstheinconsistentlabelsandrelabelthem.Theprocedure
repeats until a consensus is reached.
4http://taoxie.cs.illinois.edu/racs/subjects.html
5http://stackoverflow.com/questions/tagged/java?sort=votes&pagesize=15
938
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. Deep Code Search ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
5.1.3 Performance Measure. We use four common metrics to
measuretheeffectivenessofcodesearch,namely,FRank,Success-
Rate@k, Precision@k, and Mean Reciprocal Rank (MRR). They
arewidelyusedmetricsininformationretrievalandcodesearch
literature [41, 45, 62, 79].
TheFRank(alsoknownas besthitrank [41])istherankofthe
first hit result in the result list [ 62]. It is important as users scan
the results from top to bottom. A smaller FRank implies lowerinspection effort for finding the desired result. We use FRank to
assess the effectiveness of a single code search query.
TheSuccessRate@k (alsoknownas successpercentageatk [41])
measuresthepercentageofqueriesforwhichmorethanonecorrect
result could exist in the top kranked results [ 35,41,79]. In our
evaluations it is calculated as follows:
SuccessRate@k =1
|Q|Q/summationdisplay.1
q=1δ(FRankq≤k) (13)
whereQis a set of queries, δ(·)is a function which returns 1 if the
input is true and 0 otherwise. SuccessRate@k is important because
abettercodesearchengineshouldallowdeveloperstodiscoverthe
neededcodebyinspectingfewerreturnedresults.Thehigherthe
metric value, the better the code search performance.
ThePrecision@k [45,57]measuresthepercentageofrelevantre-
sultsinthetop kreturnedresultsforeachquery.Inourevaluations
it is calculated as follows:
Precision@k =#relevant results in the top k results
k(14)
Precision@k isimportantbecausedevelopersofteninspectmultiple
resultsof differentusages tolearn from[62]. Abetter codesearch
engineshouldallowdeveloperstoinspectlessnoisyresults.The
higherthemetricvalues,thebetterthecodesearchperformance.
We evaluate SuccessRate@k andPrecision@k whenk’s value is 1, 5,
and 10. These values reflect the typical sizes of results that users
would inspect [41].
TheMRR[ 45,79]istheaverageofthereciprocalranksofresults
ofa setofqueries Q.The reciprocalrankofa queryisthe inverse
oftherankofthefirsthitresult[ 26].MRRiscalculatedasfollows:
MRR=1
|Q||Q|/summationdisplay.1
q=11
FRankq(15)
The higher the MRR value, the better the code search performance.
5.1.4 Comparison Methods. We compare the effectiveness of
ourapproachwithCodeHow[ 45]andaconventionalLucene-based
code search tool [5].
CodeHowisastate-of-the-artcodesearchengineproposedre-
cently. It is an information retrieval based code search tool that
incorporates an extended Boolean model and API matching. It first
retrieves relevant APIs to a query by matching the query with
theAPIdocumentation.Then,itsearchescodebyconsideringbothplaincodeandtherelatedAPIs.LikeDeepCS,CodeHowalsoconsid-
ers multiple aspects of source code such as method name and APIs.
ItcombinesmultipleaspectsusinganExtendedBooleanModel[ 45].
The facts that CodeHow also considers APIs and is also built for
large-scale code search make it an ideal baseline for our experi-
ments.
Lucene is a popular, conventional text search engine behind
many existing code search tools such as Sourcerer [ 43]. Sourcerer
combines Lucene with code properties such as FQN (full qualifiedTable 1: Benchmark Queries and Evaluation Results (NF: Not
Found within the top 10 returned results LC:Lucene CH:CodeHow
DCS:DeepCS)
No.Question
IDQueryFRank
LCCHDCS
1309424 convert an inputstream to a string 211
2157944 create arraylist from array NFNF2
31066589 iterate through a hashmap NF41
4363681 generating random integers in a specific range NF62
55585779 converting string to int in java NF101
61005073 initialization of an array in one line NF41
71128723 how can I test if an array contains a certain value 661
8604424 lookup enum by string value 1NF10
9886955 breaking out of nested loops in java NFNFNF
101200621 how to declare an array NFNF4
1141107 how to generate a random alpha-numeric string NF11
12409784 what is the simplest way to print a java array 6NF1
13109383 sort a map by values NF13
14295579 fastestwaytodetermineifaninteger’ssquarerootisaninteger NFNFNF
1580476 how can I concatenate two arrays in java NF11
16326369 how do I create a java string from the contents of a file 8NF5
171149703 how can I convert a stack trace to a string 312
18513832 how do I compare strings in java 131
193481828 how to split a string in java 111
202885173 how to create a file and write to a file in java 21NF
21507602 how can I initialise a static map 712
22223918 iterating through a collection, avoiding concurrentmodifica-
tionexception when removing in loop332
23415953 how can I generate an md5 hash 136
241069066 get current stack trace in java 311
252784514 sort arraylist of custom objects by property 111
26153724 how to round a number to n decimal places in java 114
27473282 how can I pad an integers with zeros on the left NF31
28529085 how to create a generic array in java NFNF3
294716503 reading a plain text file in java 4NF7
301104975 a for loop to iterate over enum in java NFNFNF
313076078 check if at least two out of three booleans are true NFNFNF
324105331 how do I convert from int to string 21NF
338172420 how to convert a char to a string in java 5103
341816673 how do I check if a file exists in java 121
354216745 java string to date conversion 6NF1
361264709 convert inputstream to byte array in java 751
371102891 how to check if a string is numeric in java 1NF2
38869033 how do I copy an object in java 211
39180158 how do I time a method’s execution in java NFNF2
405868369 how to read a large text file line by line using java 111
41858572 how to make a new list in java 211
421625234 how to append text to an existing file in java 311
432201925 converting iso 8601-compliant string to date 311
44122105 what is the best way to filter a java collection NF92
455455794 removing whitespace from strings in java NF31
46225337 how do I split a string with any whitespace chars as delimiters 112
4752353 in java, what is the best way to determine the size of an object NFNFNF
48160970 how do I invoke a java method when given the method name
as a string312
49207947 how do I get a platform dependent new line character 1NF10
501026723 how to convert a map to list in java 6NF1
name) of entities and code popularity to retrieve the code snippets.
In our implementation of the Lucene-based code search tool, we
considertheheuristicofFQN.Wedidnotincludethecodepopular-
ityheuristic(computedusingPageRank)asitdoesnotsignificantly
improve the code search performance [43].
We use the same experimental setting for CodeHow and the
Lucene-based tool as used for evaluating DeepCS.
5.2 Results
Table 1 shows the evaluation results of DeepCS and related ap-
proachesforeachqueryinthebenchmark.Thecolumn QuestionID
shows the original ID of the question in Stack Overflow where the
querycomesfrom.Thecolumn FRankshowstheFRankresultof
eachapproach.Thesymbol‘NF’standsfor NotFound whichmeans
thatnorelevantresulthasbeenreturnedwithinthetop Kresults
(K=10).
TheresultsshowthatDeepCSproducesgenerallymorerelevant
results than Lucene and CodeHow. Figure 8a shows the statistical
939
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Xiaodong Gu, Hongyu Zhang, and Sunghun Kim
Table 2: Overall Accuracy of DeepCS and the Related Approaches
Tool R@1R@5R@10P@1P@5P@10MRR
Lucene 0.240.480.620.240.240.260.35
CodeHow 0.380.580.660.380.290.280.45
DeepCS 0.460.760.860.460.500.490.60
summary of FRank for the three approaches. The symbol ‘ +’ in-
dicates the average FRank value achieved by each approach. We
conservatively treatthe FRank as11 for queries thatfail to obtain
relevant results within the top 10 returned results. We observe that
DeepCSachievesmorerelevantresultswithanaverageFRankof
3.5,whichissmallerthantheaverageFRankachievedbyCodeHow
(5.5)andLucene(6.0).TheFRankvaluesof DeepCSconcentrateon
the range from 1 to 4, while CodeHow and Lucene produce larger
variance and many less relevant results. Figure 8b, 8c and 8d show
the statistics of Precision@k for the three approaches when kis
1,5and10,respectively.WeobservethatDeepCSachievesbetter
overall precision values than CodeHow and the Lucene-based tool.
Totestthestatisticalsignificance,weapplytheWilcoxonsigned-
rank test (p <0.05) for the comparison of FRank and Precision@k
betweenDeepCSandthetworelatedapproachesforallthequeries.
We conservatively treat the FRank as 11 for queries that fail to
obtain relevant results within the top 10 returned results. The p-
values for the comparisons of DeepCS with Lucene and CodeHow
are all less than 0.05, indicating the statistical significance of the
improvement of DeepCS over the related approaches.
Table2 shows the overall performanceof thethree approaches,
measuredin termsof SuccessRate@k,Precision@k andMRR. The
columnsR@1,R@5andR@10show the results of SuccessRate@k
whenkis 1, 5 and 10, respectively. The columns P@1,P@5and
P@10show the results of the average Precision@k over all queries
whenkis 1, 5 and 10, respectively. The column MRRshows the
MRRvaluesofthethreeapproaches.TheresultsshowthatDeepCS
returns more relevant code snippets than CodeHow and Lucene.
For example, the R@5value is0.76, whichmeans that for76% of
the queries, the relevant code snippets can be found within thetop5returnresults.The P@5valueis0.5,whichmeansthat50%
ofthetop5resultsaredeemedaccurate.FortheSuccessRate@k,
the improvements to CodeHow are 21%, 31% and 30%, respectively.
For the Precision@k, the improvements to CodeHow are 21%, 72%
and 75%, respectively. For the MRR, the improvement to CodeHow
is 33%. Overall, our approach improves the accuracy of related
techniques on all metrics.
5.3 Examples of Code Search Results
We now provide concrete examples of code search results that
demonstrate the advantages of DeepCS.
Figure9aand9bshowtheresultsfortwoqueries: queueanevent
to be run on the thread andrun an event on a thread queue. The
two queries have the same set of keywords with different wordsequences. The keyword queuein the two queries have different
meanings and it could be difficult for an IR-based approach to
distinguish.Still,DeepCScanunderstandthemeaningofthetwo
queriesand returnrelevant snippets.Apparently,DeepCShas the
ability to recognize query semantics.
TheabilityofqueryunderstandingenablesDeepCStoperform
a more robust code search. Its search results are less affected by● ● ● ● ● ● ● ● ●
02468 1 0 1 2LuceneCodeHowDeepC6
+++
(a)FRank● ● ● ● ● ● ● ● ● ● ● ●
0 2 04 06 08 0 1 0 0LuceneCodeHowDeepC6
+++
(b)Precision@1
0 2 04 06 08 0 1 0 0LuceneCodeHowDeepC6
+++
(c)Precision@50 2 04 06 08 0 1 0 0LuceneCodeHowDeepC6
+++
(d)Precision@10
Figure8: ThestatisticalcomparisonofFRankandPrecison@kfor
three code search approaches
irrelevantornoisykeywords.Forexample,thequery getthecontent
of an input stream as a string using a specified character encodingcontains 9 keywords. CodeHow returns many snippets that arerelated to less relevant keywords such as specifiedandcharacter.
DeepCS,ontheotherhand,cansuccessfullyidentifytheimportance
ofdifferentkeywordsandunderstandthekeypointofthequery
(Figure 10).
Anotheradvantageof DeepCSrelatestoassociativesearch.That
is, it not onlyseeks snippets with matched keywords but alsorec-
ommendsthosewithoutmatchedkeywordsbutaresemantically
related. This is important because it significantly increases the
search scope especially when the codebase is small. Besides, devel-
opers need snippets of multiple usages [ 62]. The associative search
provides more options of code snippets for developers to learn
from.Figure11ashowsthefirstresultofthequery readanobject
from an xml file. As discussed in Section 1, traditional IR-based
approachesmayonlymatchsnippetsthatcontainkeywordssuch
asxml,objectandread.However,asshowninthefigure,DeepCS
successfullyrecognizesthequerysemanticandreturnsresultsof
xml deserialize, even the keywords do not exist in the result. Bycontrast, CodeHow only returns snippets containing read,object
andxml, narrowing down the search scope. The example indicates
thatDeepCSsearchescodebyunderstandingthesemanticsinstead
of just matching keywords. Similarly, the query initialization of an
arraylist in one line in Table 1 returns snippets containing “new
ArrayList /angbracketleft/angbracketright” although the snippet does not include the keyword
initialization. Figure 11b shows another example of the associative
search. When searching play a song. DeepCS not only returns snip-
pets with matching keywords but also recommends results with
semantically related words such as audioandvoice.
6 DISCUSSIONS
6.1 Why does DeepCS Work?
Wehaveidentifiedthreeadvantagesof DeepCSthatmayexplain
its effectiveness in code search:
940
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. Deep Code Search ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
public boolean enqueue(EventHandler handler, Event event) {
synchronized(monitor) {
••••••
handlers[tail] =handler;
events[tail] =event;
tail++;
if(handlers .length<=tail)
tail =0;
monitor.notify();
}
return true ;
}
(a)The third result of the query “queue an event to be run on the
thread”
public void run() {
while(!stop) {
DynamicModelEvent evt; 
while((evt=eventQueue .poll()) !=null) {
for(DynamicModelListener l :listeners .toArray(
newDynamicModelListener[ 0])) 
l.dynamicModelChanged(evt);
}
••••••
}
}
(b)The first result of the query “run an event on the thread queue”
Figure 9: Examples showing the query understanding
public static String toStringWithEncoding (
InputStream inputStream, String encoding) {
if(inputStream ==null)
throw new IllegalArgumen tException (
"inputStream-should-not-be-null" );
char[] buffer =new char [BUFFER_SIZE ];
StringBuffer stringBuffer =newStringBuffer();
BufferedReader bufferedReader =newBufferedReader(
newInputStreamReader(inputStream, encoding), BUFFER_SIZE );
intcharacter =-1;
••••••
returnstringBuffer .toString();
}
Figure 10: An example showing the search robustness – The first
result of the query “get the content of an input stream as a string
using a specified character encoding”
public static < S > S deserialize (Class c, File xml) {
try{
JAXBContext context =JAXBContext .newInstance(c);
Unmarshaller unmarshaller =context.createUnmarshaller();
S deserialized =(S) unmarshaller .unmarshal(xml);
returndeserialized;
} catch(JAXBException ex) {
log.error("Error-deserializing-object-from-XML" ,ex);
return null ;
}
}
(a)The first result of the query “read an object from an xml file”
public void playVoice (intclearedLines) throwsException {
intaudiosAvailable =audioLibrary .get(clearedLines) .size();
intaudioIndex =rand.nextInt(audiosAvailable); 
audioLibrary .get(clearedLines) .get(audioIndex) .play();
} 
(b)The second result of the query “play a song”
Figure 11: Examples showing the associative search
A unified representation of heterogeneous data Source code
and natural language queries are heterogeneous. By jointly embed-
ding source code and natural language query into the same vector
representation, their similarities can be measured more accurately.
Betterqueryunderstandingthroughdeeplearning Unliketra-
ditional techniques, DeepCS learns queries and source coderepre-
sentationswithdeeplearning.Characteristicsofqueries,suchaspublic static byte [] generateRandom256 () {
byte[] randomSeed1 =ByteUtils .longToBytes(System .nanoTime());
byte[] randomSeed2 =(newSecureRandom()) .generateSeed( KEY_SIZE_BYTES );
byte[] bh1 =ByteUtils .concatenate(randomSe ed1, randomSeed2);
Thread.sleep(100L);
byte[] randomSeed3 =UUID.randomUUID() .toString() .getBytes();
byte[] randomSeed4 =ByteUtils .longToBytes(System .nanoTime());
byte[] bh2 =ByteUtils .concatenate(rando mSeed3, randomSeed4);
returnsimpleHash256(ByteUtils .concatenate(bh1, bh2));
}
Figure 12: An example showing the inaccurate results – The first
result of the query “generate md5”
semanticallyrelatedwordsandwordorders,areconsideredinthese
models[27].Therefore,itcanrecognizethesemanticsofqueryand
codebetter.Forexample,itcandistinguishthequery queueanevent
to be run on the thread from the query run an event on the event
queue.
Clusteringsnippetsbynaturallanguagesemantics Anadvan-
tage of our approach is that it embeds semantically similar code
snippets into vectors that are close to each other. Semanticallysimilar code snippets are grouped according to their semantics.
Therefore, in addition to the exact matching snippets, DeepCS also
recommends the semantically related ones.
6.2 Limitation of DeepCS
Despitetheadvantagessuchasassociativesearch,DeepCScould
still return inaccurate results. It sometimes ranks partially relevant
resultshigherthantheexactmatchingones.Figure12showsthe
result forthe query generate md5 . Theexactly matchingresultis
ranked 7 in the result list, while partially related results such as
generate checksum are recommended before the exact results. This
is because DeepCS ranks results by just considering their semantic
vectors. In future work, more code features (such as programming
context)[ 58]couldbeconsideredinourmodeltofurtheradjustthe
results.
6.3 Threats to Validity
OurgoalistoimprovetheperformanceofcodesearchoverGitHub,
thusbothtrainingandsearchareperformedoverGitHubcorpus.
There is a threat of overlap between the training and search code-
bases. To mitigate this threat, in our experiments, the training and
search codebasesare constructedto be significantlydifferent. The
training codebase only contains code that has corresponding de-
scriptions, while the search codebase is considered in isolation and
containsallcode(includingthosedonothavedescriptions).Webe-lievethethreatofoverfittingforthisoverlapisnotsignificantasour
training codebase considers a vast majority of code in Github. The
most important goal of our experiments is to evaluate DeepCS in a
real-worldcodesearch scenario.Forthat,weused50real queries
collected from Stack Overflow to test the effectiveness of DeepCS.
These queries are not descriptions/comments of Java methods and
are not used for training.
Inourexperiments,therelevancyofreturnedresultsweremanu-
ally graded and could suffer from subjectivity bias. To mitigate thisthreat,(i)themanualanalysiswasperformedindependentlybytwo
developers and (ii) the developers performed an open discussionto resolve conflict grades for the 50 questions. In the future, we
willfurthermitigatethisthreatbyinvitingmoredevelopersforthe
grading.
941
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Xiaodong Gu, Hongyu Zhang, and Sunghun Kim
In the grading of relevancy, we consider only the top 10 results.
QueriesthatfailareidenticallyassignedwithanFRankof11and
could be biased from the real relevancy of code snippets. However,
we believe that the setting is reasonable. In real-world code search,
developers usually inspect the top K results and ignore the remain-
ing. That means it does not make much difference if a code snippet
appears at rank 11 or 20 if K is 10.
Likerelatedwork(e.g.,[ 14,41]),weevaluateDeepCSwithpopu-
lar Stack Overflow questions. SO questions may not be representa-
tive to all possible queries for code search engines. To mitigate this
threat, (i) DeepCS is not trained on SO questions but on large scale
Githubcorpus.(ii)Weselectthemostfrequentlyaskedquestions
whichmightbealsocommonlyaskedbydevelopersinothersearch
engines. In the future, we will extend the scale and scope of test
queries.
7 RELATED WORK
7.1 Code Search
In code search, a line of work has investigated marrying state-
of-the-art information retrieval and natural language processing
techniques[ 13–15,32,35,41,45–47,61,81,82].Muchoftheexisting
workfocusesonqueryexpansionandreformulation[ 29,31,44].For
example,Hilletal.[ 30]reformulatedquerieswithnaturallanguage
phrasal representations of method signatures. Haiduc et al. [ 29]
proposed to reformulate queries based on machine learning. Their
method trains a machine learning model that automatically recom-
mendsareformulationstrategybasedonthequeryproperties.Luetal. [
44] proposed to extend a query with synonyms generated from
WordNet. There is also much work that takes into account code
characteristics.Forexample,McMillanetal.[ 47]proposedPortfolio,
acodesearchenginethatcombineskeywordmatchingwithPageR-anktoreturnachainoffunctions.Lvetal.[
45]proposedCodeHow,
a code search tool that incorporates an extended Boolean model
andAPImatching.Ponzanellietal.[ 61]proposedanapproachthat
automatically retrievespertinent discussions fromStack Overflow
givenacontextintheIDE.RecentlyLietal.[ 41]proposedRACS,a
code search framework forJavaScript that considers relationships
(e.g., sequencing, condition, and callback relationships) among the
invoked API methods.
As described in Section 6, DeepCS differs from existing code
searchtechniquesinthatitdoesnotrelyoninformationretrieval
techniques.Itmeasuresthesimilaritybetweencodesnippetsand
userqueriesthroughjointembeddinganddeeplearning.Thus,it
can better understand code and query semantics.
As the keyword based approaches are inefficient on recognizing
semantics, researchers have drawn increasing attention on seman-
ticsbasedcodesearch[ 34,65,69].Forexample,Reiss[ 65]proposed
the semantics-based code search, which uses user specifications to
characterizetherequirementandusestransformationstoadaptthe
searchingresults.However,Reiss’sapproachdifferssignificantly
fromDeepCS.Itdoesnotconsiderthesemanticsofnaturallanguage
queries. Furthermore, it requires users to provide not only natu-
rallanguagequeriesbutalsootherspecificationssuchasmethod
declarations and test cases.
Besides code search, there have been many other information
retrievaltasksinsoftwareengineering[ 8,9,16,23,24,29,51,55,63,67] such as bug localization [ 66,73,80], feature localization [ 19],
traceability links recovery [ 20] and community Question Answer-
ing [11]. Ye et al. [ 80] proposed to embed words into vector rep-
resentations to bridge the lexical gap between source code and
natural language for SE-related text retrieval tasks. Different from
DeepCS, the vector representations learned by their method are at
thelevelofindividualwordsandtokensinsteadofthewholequery
sentences. Their method is based on a bag-of-words assumption,
and word sequences are not considered.
7.2 Deep Learning for Source Code
Recently, researchers have investigated possible applications of
deeplearningtechniquestosourcecode[ 7,38,53,56,60,64,75,76].
Atypicaluseofdeeplearningiscodegeneration[ 42,54].Forexam-
ple,Mouetal.[ 54]proposedtogeneratecodefromnaturallanguage
user intentions using an RNN Encoder-Decoder model. Their re-
sultsshowthefeasibilityofapplyingdeeplearningtechniquesto
codegenerationfromahighlyhomogeneousdataset(simplepro-
gramming assignments). Gu et al. [ 27] applies deep learning for
APIlearning,thatis,generatingAPIusagesequencesforagiven
naturallanguagequery.Theyalsoapplydeeplearningtomigrate
APIsbetweendifferentprogramminglanguages[ 28].Deeplearning
isalsoappliedtocodecompletion[ 64,77].Forexample,Whiteet
al.[77]appliedtheRNNlanguagemodeltosourcecodefilesand
showed its effectiveness in predicting software tokens. Recently,
White et al. [ 76] also applied deep learning to code clone detection.
Their framework for automatically links patterns mined at the lex-
ical level with patterns mined at the syntactic level. In our work,
we explore the application of deep learning to code search.
8 CONCLUSION
In this paper, we propose a novel deep neural network named CO-
DEnnforcodesearch.Insteadofmatchingtextsimilarity,CODEnn
learns a unified vector representation of both source code and nat-
ural language queries so that code snippets semantically related
toaquerycanberetrievedaccordingtotheirvectors.Asaproof-
of-conceptapplication,weimplementacodesearchtoolDeepCS
basedontheproposedCODEnnmodel6.Ourexperimentalstudy
hasshownthattheproposedapproachiseffectiveandoutperforms
the related approaches.
In the future, we will investigate more aspects of source code
suchascontrolstructurestobetterrepresenthigh-levelsemanticsofsourcecode.Thedeepneuralnetworkwedesignedmayalsobenefit
other software engineering problems such as bug localization.
9 ACKNOWLEDGMENT
TheauthorswouldliketothankDongmeiZhangatMicrosoftRe-
searchAsiaforhersupportforthisprojectandinsightfulcomments
on the paper.
REFERENCES
[1] Camel case, https://en.wikipedia.org/wiki/camelcase.
[2] Eclipse JDT. http://www.eclipse.org/jdt/.[3] Github. https://github.com.[4] Keras. https://keras.io/.
[5] Lucene. https://lucene.apache.org/.
6Oursourcecodeanddataareavailableat:https://github.com/guxd/deep-code-search
942
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. Deep Code Search ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
[6] Theano, http://deeplearning.net/software/theano/.
[7]M. Allamanis, H. Peng, and C. Sutton. A convolutional attention network for
extremesummarizationofsourcecode. In InternationalConferenceonMachine
Learning (ICML), 2016.
[8]J. Anvik and G. C. Murphy. Reducing the effort of bug report triage: Recom-
menders for development-oriented decisions. ACM Transactions on Software
Engineering and Methodology (TOSEM), 20(3):10, 2011.
[9]A. Bacchelli, M. Lanza, and R. Robbes. Linking e-mails and source code arti-
facts. InProceedings ofthe 32nd ACM/IEEE InternationalConference on Software
Engineering-Volume 1, pages 375–384. ACM, 2010.
[10]D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly
learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.
[11]O. Barzilay, C. Treude, and A. Zagalsky. Facilitating crowd sourced software
engineering via stack overflow. In Finding Source Code on the Web for Remix and
Reuse, pages 289–308. Springer, 2013.
[12]T. J. Biggerstaff, B. G. Mitbander, and D. E. Webster. Program understanding and
the concept assignment problem. Communications of the ACM, 37(5):72–82, 1994.
[13]J. Brandt, M. Dontcheva, M. Weskamp, and S. R. Klemmer. Example-centricprogramming: integrating web search into the development environment. InProceedingsoftheSIGCHIConferenceonHumanFactorsinComputingSystems ,
pages 513–522. ACM, 2010.
[14]B.A.CampbellandC.Treude. NLP2Code:Codesnippetcontentassistvianatural
language tasks. arXiv preprint arXiv:1701.05648, 2017.
[15]W.-K.Chan, H.Cheng, andD.Lo. Searching connected APIsubgraph viatext
phrases. In Proceedings ofthe ACMSIGSOFT 20thInternational Symposiumon the
Foundations of Software Engineering, page 10. ACM, 2012.
[16]O.ChaparroandA.Marcus. Onthereductionofverbosequeriesintextretrieval
based software maintenance. In Proceedings of the 38th International Conference
on Software Engineering Companion, pages 716–718. ACM, 2016.
[17]K. Cho, B. Van Merriënboer, Ç. Gülçehre, D. Bahdanau, F. Bougares, H. Schwenk,
and Y. Bengio. Learning phrase representations using RNN encoder–decoder for
statisticalmachinetranslation. In Proceedingsofthe2014ConferenceonEmpirical
Methods in Natural Language Processing (EMNLP) , pages 1724–1734, Doha, Qatar,
Oct. 2014. Association for Computational Linguistics.
[18]R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa.
Natural language processing (almost) from scratch. Journal of Machine Learning
Research, 12(Aug):2493–2537, 2011.
[19]C.S.Corley,K.Damevski,andN.A.Kraft. Exploringtheuseofdeeplearning
forfeaturelocation. In SoftwareMaintenanceand Evolution(ICSME),2015IEEE
International Conference on, pages 556–560. IEEE, 2015.
[20]B. Dagenais and M. P. Robillard. Recovering traceability links between an api
and its learning resources. In 2012 34th International Conference on Software
Engineering (ICSE), pages 47–57. IEEE, 2012.
[21]M. Feng, B. Xiang, M. R. Glass, L. Wang, and B. Zhou. Applying deep learning toanswerselection:Astudyandanopentask. In 2015IEEEWorkshoponAutomatic
SpeechRecognition and Understanding (ASRU) , pages 813–820. IEEE, 2015.
[22]A.Frome,G.S.Corrado,J.Shlens,S.Bengio,J.Dean,T.Mikolov,etal. DeViSE:
A deep visual-semantic embedding model. In Advances in neural information
processing systems, pages 2121–2129, 2013.
[23]X. Ge, D. C. Shepherd, K. Damevski, and E. Murphy-Hill. Design and evaluation
of a multi-recommendation system for local code search. Journal of Visual
Languages & Computing, 2016.
[24]G.Gousios,M.Pinzger,andA.v.Deursen. Anexploratorystudyofthepull-based
software development model. In Proceedings of the 36th International Conference
on Software Engineering, pages 345–355. ACM, 2014.
[25]A. Graves, M. Liwicki, S. Fernández, R. Bertolami, H. Bunke, and J. Schmidhuber.
Anovel connectionistsystemfor unconstrainedhandwriting recognition. IEEE
transactions on pattern analysis and machine intelligence, 31(5):855–868, 2009.
[26]M. Grechanik, C. Fu, Q. Xie, C. McMillan, D. Poshyvanyk, and C. Cumby. A
searchengineforfindinghighlyrelevantapplications. In 2010ACM/IEEE32nd
International Conference on Software Engineering, volume 1, pages 475–484. IEEE,
2010.
[27]X. Gu, H. Zhang, D. Zhang, and S. Kim. Deep API learning. In Proceedings of
the ACMSIGSOFT20th InternationalSymposium on theFoundations ofSoftware
Engineering (FSE’16), 2016.
[28]X.Gu,H.Zhang,D.Zhang,andS.Kim. DeepAM:MigrateAPIswithmulti-modal
sequencetosequencelearning. In ProceedingsoftheTwenty-SixthInternational
Joint Conferences on Artifical Intelligence (IJCAI’17), 2017.
[29]S. Haiduc, G. Bavota, A. Marcus, R. Oliveto, A. De Lucia, and T. Menzies. Au-
tomatic query reformulations for text retrieval in software engineering. In
Proceedingsofthe2013InternationalConferenceonSoftwareEngineering,pages
842–851. IEEE Press, 2013.
[30]E. Hill, L. Pollock, and K. Vijay-Shanker. Improving source code search with nat-
urallanguagephrasalrepresentationsofmethodsignatures. In Proceedingsofthe
2011 26th IEEE/ACM International Conference on Automated Software Engineering,
pages 524–527. IEEE Computer Society, 2011.
[31]E. Hill, M. Roldan-Vega, J. A. Fails, and G. Mallet. NL-based query refinement
andcontextualizedcodesearchresults:Auserstudy. In SoftwareMaintenance,ReengineeringandReverseEngineering(CSMR-WCRE),2014SoftwareEvolution
Week-IEEE Conference on, pages 34–43. IEEE, 2014.
[32]R. Holmes, R. Cottrell, R. J. Walker, and J. Denzinger. The end-to-end use of
source code examples: An exploratory study. In Software Maintenance, 2009.
ICSM 2009. IEEE International Conference on, pages 555–558. IEEE, 2009.
[33]A. Karpathy and L. Fei-Fei. Deep visual-semantic alignments for generating
imagedescriptions. In ProceedingsoftheIEEEConferenceonComputerVisionand
Pattern Recognition, pages 3128–3137, 2015.
[34]Y. Ke, K. T. Stolee, C. Le Goues, and Y. Brun. Repairing programs with semantic
code search(T). In Automated SoftwareEngineering (ASE), 201530th IEEE/ACM
International Conference on, pages 295–306. IEEE, 2015.
[35]I.Keivanloo,J.Rilling,andY.Zou.Spottingworkingcodeexamples.In Proceedings
ofthe36thInternationalConferenceonSoftwareEngineering ,pages664–675.ACM,
2014.
[36]Y.Kim. Convolutionalneuralnetworksforsentenceclassification. arXivpreprint
arXiv:1408.5882, 2014.
[37]D.KingmaandJ.Ba. Adam:Amethodforstochasticoptimization. arXivpreprint
arXiv:1412.6980, 2014.
[38]A. N. Lam, A. T. Nguyen, H. A. Nguyen, and T. N. Nguyen. Combining deep
learning with information retrieval to localize buggy files for bug reports (n).InAutomated Software Engineering (ASE), 2015 30th IEEE/ACM International
Conference on, pages 476–481. IEEE, 2015.
[39]Q.LeandT.Mikolov. Distributedrepresentationsofsentencesanddocuments.
InProceedingsofthe31stInternationalConferenceonMachineLearning(ICML-14),
pages 1188–1196, 2014.
[40]M. Li, T. Zhang, Y. Chen, and A. J. Smola. Efficient mini-batch training for
stochastic optimization. In Proceedings of the 20th ACM SIGKDD international
conference on Knowledge discovery and data mining, pages 661–670. ACM, 2014.
[41]X. Li, Z. Wang, Q. Wang, S. Yan, T. Xie, and H. Mei. Relationship-aware codesearch for JavaScript frameworks. In Proceedings of the ACM SIGSOFT 24th
International Symposium on the Foundations of Software Engineering. ACM, 2016.
[42]W. Ling, E. Grefenstette, K. M. Hermann, T. Kocisky, A. Senior, F. Wang, andP. Blunsom. Latent predictor networks for code generation. arXiv preprint
arXiv:1603.06744, 2016.
[43]E. Linstead, S. Bajracharya, T. Ngo, P. Rigor, C. Lopes, and P. Baldi. Sourcerer:mining and searching internet-scale software repositories. Data Mining and
Knowledge Discovery, 18:300–336, 2009.
[44]M. Lu, X. Sun, S. Wang, D. Lo, and Y. Duan. Query expansion via wordnet foreffective code search. In 2015 IEEE 22nd International Conference on Software
Analysis, Evolution, and Reengineering (SANER), pages 545–549. IEEE, 2015.
[45]F.Lv,H.Zhang,J.Lou,S.Wang,D.Zhang,andJ.Zhao. CodeHow:Effectivecode
search based on API understanding and extended boolean model. In Proceedings
ofthe30thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering
(ASE 2015). IEEE, 2015.
[46]C.McMillan,M.Grechanik,D.Poshyvanyk,C.Fu,andQ.Xie. Exemplar:Asourcecodesearchengineforfindinghighlyrelevantapplications. IEEETransactionson
Software Engineering, 38(5):1069–1087, 2012.
[47]C. McMillan, M. Grechanik, D. Poshyvanyk, Q. Xie, and C. Fu. Portfolio: find-ingrelevantfunctionsandtheirusage. In Proceedingsofthe33rdInternational
Conference on Software Engineering (ICSE’11), pages 111–120. IEEE, 2011.
[48]T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimation of word
representations in vector space. arXiv preprint arXiv:1301.3781, 2013.
[49]T. Mikolov, M. Karafiát, L. Burget, J. Cernock `y, and S. Khudanpur. Recurrent
neural network based language model. In INTERSPEECH 2010, 11th Annual
Conference of the International Speech Communication Association, Makuhari,
Chiba, Japan, September 26-30, 2010, pages 1045–1048, 2010.
[50]T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed rep-resentations of words and phrases and their compositionality. In Advances in
neural information processing systems, pages 3111–3119, 2013.
[51]I. J. Mojica, B. Adams, M. Nagappan, S. Dienst, T. Berger, and A. E. Hassan. A
large scale empirical study on software reuse in mobile apps. IEEE Software,
31(2):78–86, 2014.
[52]D. J. Montana and L. Davis. Training feedforward neural networks using genetic
algorithms. In IJCAI, volume 89, pages 762–767, 1989.
[53]L. Mou, G. Li, L. Zhang, T. Wang, and Z. Jin. Convolutional neural networks
over tree structures for programming language processing. In Proceedings of the
ThirtiethAAAIConferenceonArtificialIntelligence,AAAI’16,pages1287–1293.
AAAI Press, 2016.
[54]L.Mou,R.Men,G.Li,L.Zhang,andZ.Jin. Onend-to-endprogramgeneration
from user intention by deep neural networks. arXiv, 2015.
[55]A.Nederlof,A.Mesbah,andA.v.Deursen. Softwareengineeringfortheweb:
the state of the practice. In Companion Proceedings of the 36th International
Conference on Software Engineering, pages 4–13. ACM, 2014.
[56]T. D. Nguyen, A. T. Nguyen, H. D. Phan, and T. N. Nguyen. Exploring api
embeddingforapiusagesandapplications. In Proceedingsofthe39thInternational
Conference on Software Engineering, pages 438–449. IEEE Press, 2017.
[57]L. Nie, H. Jiang, Z. Ren, Z. Sun, and X. Li. Query expansion based on crowd
knowledgeforcodesearch. IEEETransactionsonServicesComputing,9(5):771–783,
943
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Xiaodong Gu, Hongyu Zhang, and Sunghun Kim
2016.
[58]H.Niu,I.Keivanloo,andY.Zou. Learningtorankcodeexamplesforcodesearch
engines.Empirical Software Engineering, pages 1–33, 2016.
[59]H.Palangi,L.Deng,Y.Shen,J.Gao,X.He,J.Chen,X.Song,andR.K.Ward. Deep
sentenceembeddingusingthelongshorttermmemorynetwork:Analysisand
application to information retrieval. CoRR, abs/1502.06922, 2015.
[60]H. Peng, L. Mou, G. Li, Y. Liu, L. Zhang, and Z. Jin. Building program vector rep-
resentations for deep learning. In Proceedings of the 8th International Conference
onKnowledgeScience,EngineeringandManagement-Volume9403,KSEM2015,
pages 547–553, New York, NY, USA, 2015. Springer-Verlag New York, Inc.
[61]L.Ponzanelli,G.Bavota,M.DiPenta,R.Oliveto,andM.Lanza. Miningstackover-
flow to turn the ide into a self-confident programming prompter. In Proceedings
ofthe11thWorkingConferenceonMiningSoftwareRepositories,pages102–111.
ACM, 2014.
[62]M.Raghothaman,Y.Wei,andY.Hamadi. SWIM:synthesizingwhatImean:code
searchandidiomaticsnippetsynthesis. In Proceedingsofthe38thInternational
Conference on Software Engineering, pages 357–367. ACM, 2016.
[63]M.RahimiandJ.Cleland-Huang. Patternsofco-evolutionbetweenrequirements
and source code. In 2015 IEEE Fifth International Workshop on Requirements
Patterns (RePa), pages 25–31. IEEE, 2015.
[64]V. Raychev, M. Vechev, and E. Yahav. Code completion with statistical language
models. In In Proceedings of the 35th ACM SIGPLAN Conference on Programming
Language Design and Implementation. ACM, 2014.
[65]S. P. Reiss. Semantics-based code search. In Proceedings of the 31st International
ConferenceonSoftwareEngineering,pages243–253.IEEEComputerSociety,2009.
[66]M. Renieres and S. P. Reiss. Fault localization with nearest neighbor queries.
InAutomated Software Engineering, 2003. Proceedings. 18th IEEE International
Conference on, pages 30–39, Oct 2003.
[67]P. C. Rigby and M. P. Robillard. Discovering essential code elements in informal
documentation. In Proceedingsofthe2013InternationalConferenceonSoftware
Engineering, pages 832–841. IEEE Press, 2013.
[68]J. Singer, T. Lethbridge, N. Vinson, and N. Anquetil. An examination of software
engineering work practices. In CASCON First Decade High Impact Papers, pages
174–188. IBM Corp., 2010.
[69] K. T. Stolee, S. Elbaum,and D. Dobos. Solving the search forsource code. ACM
Transactions on Software Engineering and Methodology (TOSEM), 23(3):26, 2014.
[70]I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural
networks. In Advancesinneuralinformationprocessingsystems,pages3104–3112,
2014.[71]M. Tan, B. Xiang,and B. Zhou. Lstm-based deep learning modelsfor non-factoid
answer selection. arXiv preprint arXiv:1511.04108, 2015.
[72]J. Turian, L. Ratinov, and Y. Bengio. Word representations: a simple and general
methodforsemi-supervisedlearning. In Proceedingsofthe48thannualmeeting
of the association for computational linguistics, pages 384–394. Association for
Computational Linguistics, 2010.
[73]Y.Uneno,O.Mizuno,andE.-H.Choi. Usingadistributedrepresentationofwords
in localizing relevant files for bug reports. In Software Quality, Reliability and
Security (QRS), 2016 IEEE International Conference on, pages 183–190. IEEE, 2016.
[74]J.Weston,S.Bengio,andN.Usunier. Wsabie:scalinguptolargevocabularyimage
annotation. In Proceedings of the Twenty-Second international joint conference on
Artificial Intelligence-Volume Volume Three, pages 2764–2770. AAAI Press, 2011.
[75]M. White, M. Tufano, M. Martinez,M. Monperrus, and D. Poshyvanyk. Sorting
and transforming program repair ingredients via deep learning code similarities.
arXiv preprint arXiv:1707.04742, 2017.
[76]M. White, M. Tufano, C. Vendome, and D. Poshyvanyk. Deep learning code frag-
mentsforcodeclonedetection. In Proceedingsofthe31thIEEE/ACMInternational
Conference on Automated Software Engineering (ASE 2016), 2016.
[77]M.White,C.Vendome,M.Linares-Vásquez,andD.Poshyvanyk. Towarddeep
learning software repositories. In Mining Software Repositories (MSR), 2015
IEEE/ACM 12th Working Conference on, pages 334–345. IEEE, 2015.
[78]R. Xu, C. Xiong, W. Chen, and J. J. Corso. Jointly modeling deep video andcompositional text to bridge vision and language in a unified framework. In
AAAI, pages 2346–2352. Citeseer, 2015.
[79]X. Ye, R. Bunescu, and C. Liu. Learning to rank relevant files for bug reports
using domain knowledge. In Proceedings of the 22nd ACM SIGSOFT International
Symposium on Foundations of Software Engineering, pages 689–699. ACM, 2014.
[80]X.Ye,H.Shen,X.Ma,R.Bunescu,andC.Liu. Fromwordembeddingstodocu-
ment similarities for improved information retrieval in software engineering. In
Proceedingsofthe38thInternationalConferenceonSoftwareEngineering,pages
404–415. ACM, 2016.
[81]H. Zhang, A. Jain, G. Khandelwal, C. Kaushik, S. Ge, and W. Hu. Bing developer
assistant:Improving developerproductivitybyrecommending samplecode. In
Proceedingsofthe201624thACMSIGSOFTInternationalSymposiumonFounda-
tions of Software Engineering, FSE 2016, pages 956–961. ACM, 2016.
[82]J.ZhouandR.J.Walker. APIDeprecation:Aretrospectiveanalysisanddetection
method for codeexamples on the web. In Proceedings of theACM SIGSOFT 20th
International Symposium on the Foundations of Software Engineering (FSE’16).
ACM, 2016.
944
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:38:44 UTC from IEEE Xplore.  Restrictions apply. 