Impact of Developer Turnover on Quality
in Open-Source Software
Matthieu Foucault
U. of Bordeaux, LaBRI, France
mfoucaul@labri.frMarc Palyart
UBC, Canada
mpalyart@cs.ubc.caXavier Blanc
U. of Bordeaux, LaBRI, France
xblanc@labri.fr
Gail C. Murphy
UBC, Canada
murphy@cs.ubc.caJean-R√©my Falleri
U. of Bordeaux, LaBRI, France
falleri@labri.fr
ABSTRACT
Turnover is the phenomenon of continuous inux and retreat
of human resources in a team. Despite being well-studied in
many settings, turnover has not been characterized for open-
source software projects. We study the source code repos-
itories of ve open-source projects to characterize patterns
of turnover and to determine the eects of turnover on soft-
ware quality. We dene the base concepts of both external
and internal turnover, which are the mobility of develop-
ers in and out of a project, and the mobility of developers
inside a project, respectively. We provide a qualitative anal-
ysis of turnover patterns. We also found, in a quantitative
analysis, that the activity of external newcomers negatively
impact software quality.
Categories and Subject Descriptors
D.2 [Software ]: Software Engineering; D.2.8 [ Software
Engineering ]: Metrics| process metrics
Keywords
Mining software repositories, qualitative analysis, software
metrics
1. INTRODUCTION
Throughout the evolution of a project, the team con-
tributing to it evolves, with collaborators joining, leaving,
or changing their role in the project. This phenomenon of
continuous inux and retreat of human resources is called
turnover . Turnover has been studied in managerial science
and human-computer interaction research, with several the-
ories regarding its impact. The most common theory holds
that turnover has a negative impact on performance and on
the quality of the work, due to a loss of experience [22].
Other theories suggest that turnover has (1) a positive im-
pact since the most dissatised members leave the team, andthat only the most motivated ones stay in it [27], (2) helps
renew experience and knowledge on the team [40], and (3)
increases social interactions [10].
In the software development context, developer turnover
has been analyzed by Mockus [30] on one industrial project.
He found that developers leaving the project had a negative
impact on quality but that new members had no eect on
it. Our work extends these ndings made on an industrial
software project by looking at ve large open-source soft-
ware projects. These projects are interesting to study given
their extensive use and low barriers to entry and exit for
collaborators [15].
To study turnover in open-source, we introduce activity
metrics that measure external and internal turnover. By
splitting a software project into dierent modules, we are
able to measure not only the arrivals and departures of de-
velopers from the project (i.e. external turnover), but also
the movement of developers within the project (i.e. internal
turnover).
Based on the concepts we dene in this paper, we quantify
the level of turnover, both external and internal, in open-
source software projects. We quantify turnover by measur-
ing the amount of changes performed in the source code by
newcomers or leavers, instead of measuring the actual num-
ber of developers joining or leaving, as there is a great dis-
parity between developers in open-source projects. We then
perform an empirical study on 5 large open-source projects
(Angular.JS, Ansible, Jenkins, JQuery and Rails) to pro-
vide insights on the relationship among developer turnover
and software quality, where quality was measured based on
the density of bug-xing commits. The extraction process
for bug-xing commits is performed manually, to reduce the
risk of errors produced by automatic approaches [5, 7, 21],
thus limiting the number of projects that can be considered
in this paper.
We provide the following contributions, for the ve open-
source projects mentioned above:
We provide a curated set of bugs.
We provide metrics to measure turnover.
We show the importance of the turnover phenomenon
in open-source projects.
We observe several trends of internal and external turn-
over.
We show that there is a relationship between turnover
and quality of software modules.
This paper is structured as follows: Section 2 presents the
theory and related work. Turnover metrics are dened in
This is the author‚Äôs version of the work. It is posted here for your personal use. Not for
redistribution. The deÔ¨Ånitive version was published in the following publication:
ESEC/FSE‚Äô15 , August 30 ‚Äì September 4, 2015, Bergamo, Italy
c2015 ACM. 978-1-4503-3675-8/15/08...
http://dx.doi.org/10.1145/2786805.2786870
829Section 3. Our research questions are detailed in Section 4
and the methodology we used to build our dataset in Sec-
tion 5. Our results are then presented in Section 6. Section 7
presents an overview of the main threats to the validity of
these results, and nally, Section 8 concludes and presents
trails for future work. We produced a replication package
which allows to reproduce and extend the results presented
in this study. This package, which has been successfully
evaluated by the Replication Packages Evaluation Commit-
tee and found to meet expectations, is presented Section 10.
2. THEORY & RELATED WORK
As the literature contains dierent and sometimes contra-
dictory opinions on turnover, we rst describe all its possible
interpretations. We then present existing work on turnover
in collaborative communities and nally research specic to
software development.
2.1 Turnover Perception
Member turnover, initially dened as the rate at which in-
dividuals leave a project, can be extended to all the changes
made to the development team of a project. These modi-
cations of the team can be either external, (i.e., a member
leaves or joins the team) or internal (i.e., a member changes
her role in the team). Distinct theories regarding the impact
of turnover, whether it is external or internal, suggest that
it has both positive and negative aspects on a team.
2.1.1 External Turnover
The most common vision holds that external turnover neg-
atively impacts employee performance [22, 43]. Departures
lead to a loss of experience and knowledge, but also disrupt
the social network and environment of those who remain [4,
11]. Moreover, it induces devoting resources and time to
recruit and train new employees.
A second vision considers turnover as a good opportunity
for organizations, as leavers are those most dissatised with
the current organization, and those who remain enjoy better
conditions and performance [27].
A last perspective sees moderate levels of turnover as
the best organizational performance [3]. When there is no
turnover, experience and knowledge are not renewed, and
become obsolete and parochial [40]. Introduction of new
people is a solution to overcome this situation, as their vi-
sion is less established and less redundant with respect to
the knowledge possessed by the current team.
2.1.2 Internal Turnover
Internal turnover was dened in traditional organizations
as the number of employees who changed function within
an organization [20]. Motivations behind such actions are
opportunities for career moves to increase income and au-
tonomy as well as getting new responsibilities and express-
ing new skills [41]. Kanter et al. pointed out that members
had lower aspirations and involvements in their work when
mobility was blocked [26]. Thus, internal mobility is com-
monly supported to maintain members commitment to the
organization.
2.2 Turnover in Collaborative Platforms
Turnover has been studied in online communities and col-
laborative platforms where participants are free to enter
or leave at any moment without any cost. In the EnglishWikipedia, high turnover is even the norm with sixty per-
cent of editors contributing only for a single day [32]. Rans-
botham et al. suggested that collaboration success can be
reached thanks to moderate levels of turnover [36], provided
that the level of novel knowledge exceeds the loss of existing
knowledge held by departing people. Similarly, Dabbish et
al. discovered that membership turnover might bring fresh
levels of activity and liveliness in a community which leads
to increased participation [10]. Inversely, Qin et al. observed
that departures of WikiProjects contributors has a negative
eect on the community and causes social capital losses [35].
2.3 Turnover in Software Development
Developer turnover in open-source software projects was
studied mainly to understand developers motivations to con-
tribute. Yu et al. suggested that personal expectation plays
a role in project retention, and that turnover is partially ex-
plained by dissatisfaction [45]. Hynninen et al. conducted
a survey with developers and suggested that their depar-
tures from a project can be a manifestation of low orga-
nizational commitment [23]. A study from Schilling et al.
unveiled that the level of development experience and knowl-
edge is strongly associated with retention [38]. According
to Sharma et al., past activity, age and size of a project
as well as developer tenures are important predictors of
turnover [39]. These observations are consistent with other
classical theoretical models related to job satisfaction [44].
Measures of knowledge loss were suggested by Izquierdo-
Cortazar et al [24]. These measures include the evolution of
orphan lines of code lastly edited by a developer who left the
team. They showed that while in some projects, developers
devote eorts to maintain code introduced by former devel-
opers, in others, they seek to eliminate such code. Robles
et al. designed a methodology to compute generations of
joining and leaving developers [37]. Finally, Fronza et al.
propose a wordle to visualize the level of cooperation of a
team and mitigate the knowledge loss due to turnover [17].
Hall et al. conducted a survey with practitioners to unveil
that turnover may be related to project success, but however
did not dene turnover metrics computable by analyzing
the history of the project [19]. Mockus found that while
departures of members impact the software quality because
of the loss of knowledge and experience, newcomers are not
responsible for an increase of defects, possibly because they
are not assigned to important changes [30]. Mockus also
found a relationship between turnover and productivity in
commercial projects [29].
Mens et al. explored developer turnover in the Gnome
ecosystem with concepts and metrics similar as the ones we
use in this paper [28]. They looked at developer turnover
at a coarser grain: in their study, internal turnover refers to
the mobility of developers between projects of the Gnome
ecosystem, while external turnover in their case was associ-
ated to developers entering or leaving the Gnome ecosystem.
Our study diers from theirs as it we look at a ner gran-
ularity: we measure mobility of developer between modules
of a project, and in and out of a project. In their study they
sought for possible patterns of developer turnover, with the
conclusion that this is a highly project-specic phenomenon.
They did not, seek for a relationship between turnover and
code quality.
830Alice Bob Jane Alan
m1 m1
m2 m2
P2 P1S0 S-2 S-1Figure 1: Example of ctive software project con-
taining two modules.
3. TURNOVER METRICS
A software project can have many kinds of turnover. To be
able to study dierent aspects of turnover, we introduce ve
metrics that can be computed from the source code history
of a software project.
3.1 Setup and Requirements
In order to compute turnover metrics, we need to dene
the periods over which turnover will be computed, as well
as how contributors are identied.
3.1.1 Period Selection
We compute developer turnover by comparing the contrib-
utors of software modules in two consecutive time periods:
P1andP2. These two periods are therefore delimited by
three snapshots of the project history: S0,S 1andS 2
such that P1is delimited by S 2andS 1and that P2is
delimited by S 1andS0(see Figure 1).
In practice, S0is the snapshot for which we want to com-
pute turnover metrics. The selection of the two other snap-
shots can be based on dierent approaches. One could con-
sider either the prior releases of the software, snapshots such
that periods P1andP2have the same duration, or snapshots
such that periods P1andP2have the same overall activity
in the repository. We study in Section 5 the impact of these
choices on turnover computation.
3.1.2 Software Modules and Contributors
Developer turnover is relative to the software project's
structure. A developer who has only worked on a few mod-
ules in the system that suddenly contributes to more, should
be considered as new, or inexperienced, as she moves to new
parts of the code base.
We therefore consider that a software project is composed
of a nite set Mof software modules developed by a nite
set of developers who submit their code modications by
sending commits to a shared code repository. Each module is
dened by a nite set of source code les. When a developer
modies one of the les of a software module by committing
her work, she is contributing to that module. A developer
contributes to the software project as soon as she contributes
once to any module of the software.
To illustrate all our denitions, we rely on the ctitious
software depicted in Figure 1, which is composed of two
modules developed over two periods P1andP2. A total
of four developers participated to this software between the
S 2andS0snapshots.
Given a module m,Dm;P is the set of developers who
made at least one contribution to mduring the period P.We obtain with our example Dm2;P1=fBob, Janegand
Dm2;P2=fBob, Alang.
Dtis the set of developers who made at least one contribu-
tion to the software during the period t, i.e. DP=MS
mDm;P.
From our example, we have DP1=fAlice, Bob, Janegand
DP2=fBob, Jane, Alang.
3.2 Turnover Actors and Metrics
We now provide formal denitions for the sets of develop-
ers involved in turnover, and the metrics associated to them.
We consider two kinds of developer turnover: external and
internal turnover. The developers involved in each kind of
turnover are considered to be either newcomers or leavers.
Finally, we dene stayers, i.e. the developers contributing
to both studied periods.
We consider as newcomers the developers who joined the
team of a module in the period P2, whereas leavers are the
developers who left the team of a module within the period
P1. This dierence between the periods is due to the fact
that the intent of our metrics is to evaluate the impact of
turnover on the quality of the software at the S0snapshot.
Thus, newcomers of the P2period may inuence its quality
as their rst contributions on a module were between S 1
andS0, and leavers of the P1period may inuence its qual-
ity as the loss of knowledge their departure induce will be
perceptible after they left, i.e., after the S 1snapshot.
3.2.1 External Turnover
External turnover refers to the movement of developer in
and out of a project.
External newcomers of a module mare the developers
who contributed to the module between S 1andS0, but
did not contribute to any module of the project between
S 2andS 1(i.e., during the P1period). The set of external
newcomers is noted ENm;P 1;P2and is computed as follows:
ENm;P 1;P2=Dm;P 2 DP1
In Figure 1, we observe that Alan is a newcomer in m2,
and that he did not work on any module during P1. He
is therefore an external newcomer, and thus ENm2;P1;P2=
fAlang.
External leavers of a module mrefer to developers who
worked on the module during P1but did not contribute to
the project at all in P2. The set of external leavers is noted
ELm;P 1;P2and is computed as follows:
ELm;P 1;P2=Dm;P 1 DP2
We observe that only Alice contributed to m1 during P1
but was inactive on the project in P2. Consequently,
ELm1;P1;P2=fAliceg.
3.2.2 Internal Turnover
Internal turnover refers to movements of developers inside
a project. Even though some developers contribute to a
project in both periods P1andP2, they may not work on
the same modules in the two periods.
Internal newcomers are the developers who contributed
tominP2, but not in P1. However, they contributed to
at least one other module than min this period. They are
noted INm;P 1;P2and are computed as follows:
INm;P 1;P2= (Dm;P 2 Dm;P 1)\DP1
831Following the previous illustrations, we obtain here
INm1;P1;P2=fJanegandINm2;P1;P2=;.
Internal leavers refer to developers who ceased to con-
tribute to a module mbut are still active in the project.
This set is noted ILm;P 1;P2and is computed as follows:
ILm;P 1;P2= (Dm;P 1 Dm;P 2)\DP2
We observe that only Jane modied m1 during P2but
not in P1, while working on m2 during P1. Consequently,
ILm2;P1;P2=fJaneg.
3.2.3 Stayers
Finally, stayers are the developers who contributed to a
module min both P1andP2. We dene the set of stayers
for a given module as:
Stm;P 1;P2=Dm;P 1\Dm;P 2
3.2.4 Metric DeÔ¨Ånitions
The intention of our metrics is to quantify the impact
that the dierent turnover actors may have on a module's
quality at the snapshot S0of the project. Due to the large
inequalities in the involvement of developers in open-source
projects, we cannot quantify turnover by counting the num-
ber (or ratio) of developer in each of the categories dened
above. Filtering the developers by considering only core or
paid contributors is not a viable alternative either. Indeed,
peripheral developers as a group still produce a signicant
amount of contributions, and ignoring these contributions
may signicantly impact our measurements. Therefore, to
measure the impact that each category of turnover actors
have on the source code, we use the activity of developers,
i.e., the amount of source code they produce.
For a given module m, developer dand period t, we dene
Am;d;t as the activity of the developer, which we measure us-
ing the code churn, i.e. the number of lines of code added or
deleted by can be measured with the number of le modi-
cations she performed on the module, or the code churn (i.e.,
the total number of lines added or deleted) of such modica-
tions. In this paper we only present results obtained using
the code churn as an activity measure. However, results ob-
tained with the number of modications are similar, and are
available online (see Section 9).
The ve metrics we dene are the internal and external
leavers activity (ILA and ELA, resp.), the internal and exter-
nal newcomers ratio (INA and ENA, resp.), and the stayers
activity (SA):
ILA m;P 1;P2=X
d2ILm;P 1;P2Am;d;P 1
ELA m;P 1;P2=X
d2ELm;P 1;P2Am;d;P 1
INA m;P 1;P2=X
d2INm;P 1;P2Am;d;P 2
ENA m;P 1;P2=X
d2ENm;P 1;P2Am;d;P 2;
StAm;P 1;P2=X
d2Stm;P 1;P2avg(Am;d;P 1; Am;d;P 2)
4. RESEARCH QUESTIONS
To the best of our knowledge we found no previous study
that looked at trends of developer turnover in open-sourcesoftware projects. Hence the rst objective of our study is to
seek for such trends, starting with a global view of turnover
at the project level, and then focusing on developer turnover
on module thanks to the metrics previously dened.
More formally, we seek to answer the following two re-
search questions:
RQ1 Using the concepts of external newcomers and leavers
at the project level, is turnover an important phe-
nomenon (in terms of number of developers involved)
in open-source software projects?
RQ2 Looking deeply into the project at the module level,
is there any patterns regarding the contributions of
persistent, internal and external developers?
By answering the aforementioned research questions, we
provide an overview of developer turnover both at the project
and at the module levels. We then go further by exploring
the relationship between developer turnover at the module
level and software quality, which we measure based on bug-
x information.
We then answer the following research question:
RQ3 Using the turnover metrics at the module level, is
there any relationship with the quality of the software
modules?
5. DATASET CONSTRUCTION
Although many automatic techniques are often used to
build large datasets, they are all imprecise to a certain ex-
tent. Instead of having a dataset with dozens of project
containing approximate measures, we chose to focus on the
reliability of the information extracted from the dataset. In
particular, to answer our research questions, our dataset
must meet several requirements:
The author of each contribution must be clearly iden-
tied.
The source code of the project must be organized into
modules.
A measure of quality must be available for each mod-
ule.
Each of these criteria is addressed in current research, and
software engineering researchers are still developing tech-
niques to extract reliable information from software reposi-
tories, as we detail below.
5.1 Authors IdentiÔ¨Åcation
Centralized VCS.
The rst issue regarding the identication of authors is
related to the version control system (VCS) used by the
project. In centralized VCSs such as Subversion, a developer
must enter her credentials to commit her code to the central
repository. Given the large number of contributors to open-
source projects, assigning credentials to each of them would
be unwieldy, and contributions are therefore submitted via
patches, and applied by core developers who have credentials
for the repository.
This issue is xed by the use of decentralized VCSs such
as Git, which are able to distinguish the original author
of a commit and the developer who added it to the main
repository (i.e., the committer) [6]. However, automatically
selecting a large number of Git repositories (from hosting
832platforms such as GitHub) would not be a suitable process
in our case as a non negligible amount of large Git repos-
itories are simply mirrors of Subversion repositories. Well
known examples of such repositories include the gcccom-
piler project, or most of the projects hosted by the Apache
Software Foundation (eg. the httpd server). Moreover, even
if a project currently uses Git as a VCS, it may not have been
so for all its development history. It is not uncommon for
a project, especially older projects, to migrate its code base
from one VCS to another throughout its history. This is the
case of two projects selected in our dataset, Rails and Jenk-
ins, which originally used Subversion and then migrated to
Git. We manually searched commit messages for contents
such as \Patch sent by Alice" to determine if at one point
these projects were still using Subversion or if they did mi-
grate to Git, and only include the history subsequent to this
migration in our analyses.
Identity Merging.
Even when the identity of each contribution's author is
reliable, it is possible that a single developer has several
identities in the VCS, because of typos, changes in the con-
guration of the Git client, or a change of email address
for instance. This issue is addressed by identity merging,
for which Goeminne and Mens address a comprehensive re-
view [18]. Following their recommendations, we use a semi-
automatic process which is based on their simple algorithm
which has a very high recall. To counter the low precision of
the algorithm, we manually review the results of the identity
merge algorithm and remove false positive merges.
5.2 Quality Measurement
Our study aims to evaluate the quality of project' modules
for a given snapshot. In most software engineering studies
the quality of software projects is assessed by looking at the
number of bugs xed by the developers.
Bug Fix IdentiÔ¨Åcation.
In order to measure the amount of these bugs, the state-
of-the-art technique used in studies mining software reposi-
tories consists in parsing the commit messages, looking for
the identier of a bug stored in the project's bugtracker
(e.g., "Bug #42") [46]. However, recent work raised concerns
regarding the precision and recall of this automatic process,
due to the misclassication of issues in the bugtrackers, or
imprecision of algorithms linking bugs to source code [21, 5,
7].
Some approaches remove these concerns by only consid-
ering information stored in the VCS, and assume that the
number of bug-xing commits is a fair representation of the
actual number of bugs within a software module. Unfortu-
nately, to the best of our knowledge, no automatic approach
has a satisfactory precision to produce reliable statistics. For
instance, among the best automatic approaches, the ones
developed by Tian et al. [42] and Mockus et al. [31] have a
precision of only 53% and 61%, respectively, in the evaluated
benchmarks, which in our case would have unpredictable ef-
fect on the number of bug-xing commits identied, and
would be a non-negligible bias to our study.
As we did not nd a suitable automatic approach we chose
to manually analyze commits to constitute our dataset to
the detriment of the number of projects that we were ableto include in it. Our manual approach therefore aims to
identify commits that are true bugxes.
Maintenance Branches.
To have measures which are representative of the quality
of the code at a given snapshot or release, we need to iso-
late post-release bugxes from development bugxes. Post-
release bugxes for a snapshot S0are commits that x a bug
which was in the project's code at the snapshot S0, while
development bugxes performed after the snapshot S0may
have been introduced between the snapshot S0and the time
of the bugx. If the development history of a project is linear
(i.e. if all the commits are performed on a single branch),
isolating one category of commits from the other may be
cumbersome and imprecise. Therefore, another constraint is
added to the projects to include in our dataset: the release
S0must have a dedicated maintenance branch, sometimes
called long time support (or LTS) branch, where the only
commits performed in it aim to improve the code quality
of the release S0. These maintenance branches dier from
development branches. They usually do not contain new
features. The operations performed in such branches are
mainly bug-xing, documentation, optimizations, or com-
patibility updates related to third party dependencies (e.g.,
the 2:3:xmaintenance branch of Rails contains updates re-
lated to new versions of the Ruby programming language).
Moreover, we restrict our search to maintenance branches
where no commit was performed for the past six months,
in order to have branches where most of the bugs were had
time to get xed.
Bug Fix ClassiÔ¨Åcation.
Our denition of a bug-xing commit includes any se-
mantic changes to the source code which xes an unwanted
behavior. The type of bugs considered includes any arith-
metic or logic bug (e.g., division by zero, innite loops, etc.),
resource bugs (e.g., null pointer exceptions, buer overows,
etc.), multi-threading issues such as deadlocks or race con-
ditions, interfacing bugs (e.g., wrong usage of a particular
API, incorrect protocol implementation or assumptions of a
particular platform, etc), security vulnerabilities, as well as
misunderstood requirements and design aws.
We identied bug-xing commits manually, discarding com-
mits where new features are implemented. We choose to
ignore commits where performance optimizations are per-
formed, as we consider performance issues as a dierent as-
pect of code quality. Moreover, we also ignore commits that
resolve compatibility issues due to the evolution of a third-
party dependency, as these bugxes are not due to the lack
of quality of the changed code, but to the modication of
an external requirement. Finally, it occurs that bug-xing
commits are lated discarded by the developers due to a re-
gression introduced by the bugx. In such cases, the devel-
opers perform a \revert" operation of such commits, and we
ignore both the \revert" and the \reverted" commits.
We consider that bug-xing commits are atomic, in the
way that we do not consider the possibility that a bug-xing
commit may in fact include two bug-xes. Moreover, if a
bug-xing commits aects two modules, the number of bug-
xing commits will be incremented in both modules.
8335.3 Code Modularization
In this study, we use metrics that target software modules.
Breaking a software system into modules is known to be a
hard task that requires some subjective choices [33]. We
consider two heuristics for determining software modules,
such as its organization within les and directories or the
co-change activity. We present here the dierent sets of
modules based on these heuristics.
5.3.1 Using the Directory Structure
The rst modularization approach we consider is based
on the directory structure of the system, in which software
modules are dened to be either a le or a directory, with
the possibility to include or not its subdirectories. We chose
not to simply extract a modularization based on the direc-
tory structure, instead we manually inspected the directory
structure of each project to select a suitable level of granu-
larity so that a module includes similar features, based on
le and directories names, and on the information found in
projects conguration les. To overcome the bias of having
a single judge for the module decomposition, we asked three
members of our research group (three PhD students in soft-
ware engineering) to provide, for each of the ve projects
in the corpus, a list of software modules. The three judges
then met to merge their results. They agreed on the gran-
ularity of most of the modules of projects such as JQuery,
Angular.JS and Ansible, while agreement on Jenkins and
Rails was initially reached by only two judges, the third
one having chosen a coarser granularity. As the decisions
made by the judges may be dierent than the developers
of the projects, we tried to contact their core developers to
conrm our decompositions, using the ocial mailing lists
and/or IRC channels of each project. Unfortunately, we did
not obtained any answers.
5.3.2 Using the Co-change Activity
The second modularization technique we use considers
that source code les that are changed together (i.e. in the
same commit) belong to the same module, regardless of the
directory structure of the project. We use an automated
process that consists in building the co-change graph of the
project, which is a weighted, undirected graph where each
vertex is a source code le of the project, and the weight
of an edge is equal to the number on commits where both
les were modied together. To determine the modules, we
used two algorithms aiming at building communities in a
graph [9, 34]. Both algorithms produced a relatively low
number of modules (less than ten) in the projects developed
in Javascript (Angular.JS and JQuery), which is due to the
fact that Javascript projects tend to have fewer, larger les
compared to projects in languages such as Java. Therefore,
these decomposition allow to produce statistical results on
only three projects. As the results obtained with this mod-
ularization algorithms are similar to the ones obtained with
the manual decomposition based on directories structure,
they are not presented in this paper. However, they are
available in our additional results online (see Section 9).
5.4 Periods Selection
The computation of turnover metrics for a snapshot S0
relies on the choice of two periods P1andP2(Figure 1).
To choose a suitable size for the periods P1andP2, we
measured the impact of these periods on the sets of turnoveractors (i.e. internal and external leavers and newcomers).
The length of the periods P1andP2may impact the result-
ing sets of actors, especially if the periods are too short, in
which case we may consider as newcomers or leavers devel-
opers who stopped contributing to the project for a period of
time before re-starting. To assess the impact of this choice
we have tested four congurations for the lengths of the pe-
riods: one release-based conguration where S0,S 1and
S 2are three following releases of the project, and three
time-based congurations where P1andP2both last for 1,
3 and 6 months.
UsingjP1j=jP2jmay limit our vision in the past. This
may for example result in considering some developers as
newcomers because they were inactive for sometime, but the
length of P1is not sucient to see their previous contribu-
tions. On the other hand, if we looked at the whole history
of the project to check whether developers are newcomers or
leavers, we may consider as stayers developers who did not
contribute to the project for several years. To quantify the
impact of the length of P1andP2, we compute two versions
of each turnover set:
A version with limited visibility , wherejP1j=jP2j.
A version with full visibility , where:
{S 2= is the beginning of the Git repository when
computing the sets of newcomers.
{S0is the most recent release available in the project
when computing the sets of leavers.
To decide which period size is suitable for our analyses,
we chose to measure the similarity between sets of turnover
actors computed with limited and full visibility, using the
Sorensen-Dice quotient of similarity, which is equal to 1
when two sets are identical, and 0 when they are disjoint [12].
The selected period size is the rst period size where the me-
dian Dice coecient is, for all projects and actors sets, above
a threshold of 0 :75.
The distributions of Dice coecients obtained for each
project are available online (See Section 9). For each period
sizejPj, project and category of turnover actors (e.g., exter-
nal newcomers), we have a distribution of Dice coecient,
as we computed one Dice coecient for each module. These
distribution show that, with a period of one month, several
sets of developers have large dierences between limited and
full visibility, the worst case being with Angular.JS where
sets of external newcomers computed with limited visibility
have no intersection with sets computed with full visibility.
WithjPj= 3 months, the distributions are closer to a dice
coecient of 1, but there are still cases where the median
Dice coecient is below the threshold of 0 :75, especially with
internal turnover. With jPj= 6 months, most of the sets
of turnover actors are identical whether we use limited or
full visibility. Only few modules have a dice coecient of
zero, and the median Dice coecient for all projects and
categories of turnover actors is above the threshold of 0 :75
The release period conguration is not stable as the length
of time between two releases depends on the roadmap of the
project and on the features that are developed.
Therefore, we chose to use the 6 months period for the
remainder of our analysis: all the results presented in this
paper consider that jP1j=jP2j= 6 months.
5.5 Resulting Dataset
Our dataset, listed in Table 1 includes ve projects, writ-
ten in four dierent programming languages. The selected
834Table 1: The projects included in our dataset.
Project Language Release #Bugxes LoC #Modules
(S0)
Angular.JS JavaScript 1.0.0 147 11,041 26
Ansible Python 1.5.0 62 50,553 29
Jenkins Java 1.509 74 79,774 60
JQuery Javascript 1.8.0 46 5,306 23
Rails Ruby 2.3.2 390 33,919 46
releases are minor releases (i.e., no breaking changes have
been performed in the selected development period) in An-
sible, JQuery, and Rails. They are major release in An-
gular.JS and Jenkins. The selected releases are, with the
exception of the one in Ansible, considered to be long term
supported (LTS) releases. For these LTS releases, bug-xing
commits are backported from the main development branch
even after subsequent releases are available. In Ansible, al-
though the maintenance of the 1.5.x releases stopped a cou-
ple of week before the availability of the 1.6.0 release, it was
performed simultaneously with the development of the 1.6.0
release. This dataset is available online (see Section 9) and
can be reused for future studies.
6. RESULTS
6.1 Turnover at the Project Level ( RQ1)
In order to characterize developer turnover at the project
level we look at the number of external newcomers, external
leavers and stayers during the life of each project.
Developers Volatility.
Since we dened jP1j=jP2j= 6 months we compute the
dierent sets of actors by starting with S0= 12 months after
the earliest version of the project when we know that Git
was used as a VCS, and move S0toward the end of the
project by steps of two weeks. The resulting numbers are
presented in Figure 2.
We can observe two types of phases during the life of a
project. The rst phase that we call the \enthusiastic" phase
can only be seen in Angular.JS and Ansible since we are
missing the beginning of the other projects as we excluded
from the study the period when they were using SVN. Dur-
ing the \enthusiastic" phase (2011-2014 for Angular.JS and
2013-06/2014 for Ansible) the number of newcomers is con-
stantly superior to the number of leavers. At some point
projects switch to the second phase that we call the \al-
ternating" phase where either the number of newcomers or
leavers is higher than the other one.
In all projects, the number of newcomers and leavers is
quite high. Throughout the histories of these projects, at
least 80% of developers are either newcomers or leavers.
Overall this conrms that turnover in open-source software
projects is an important phenomenon.
Stayers Conversion and Motivations.
The number of stayers increase mainly during the \enthu-
siastic" phase and stay fairly stable during the \alternating"
phase. To further understand the evolution of the popula-
tion of stayers we use the notion of conversion rate that is
usually found in marketing. In our case the conversion raterepresents the proportion of newcomers that the project was
able to keep long enough so they could become stayers. It
is equal to the number of developers who were at least once
stayer divided by the number of developers in the whole
history of the project we look at. The conversion rates for
each project are between 8% (Ansible) and 19% (Jenkins
and JQuery). Even if it is not in the same proportion for
each project we observed that only a low ratio of newcomers
become stayers.
To better understand what make developers stay in their
project we looked at the top 10 stayers of each projects:
developers who were in the stayers set the highest number
of times over the project history. We searched their Github
and LinkedIn proles as well as their personal web pages to
understand their motivation. We found four categories:
Developers who are paid by the company that devel-
ops the project. For example 7 out of the top 10 stay-
ers of Angular.JS work at Google which maintains the
framework.
Developers who are paid by a company that use the
project for their business. It is the case 6 times in the
top 10 stayers of Ansible.
Developers who are consultants on the technology de-
veloped within the project. For example 5 out of the
top 10 stayers of Rails are consultants.
Developers who contribute on their spare time without
direct or indirect nancial interest. Out of the 50 top
stayers we looked at only 2 t that category.
In conjunction to these categories developers were some-
times also the initial creators of the project (6 developers
out of 50).
6.2 Patterns of Contributions ( RQ2)
The visualizations in Figure 3 represents the turnover met-
rics1computed withjP1j=jP2j= 6 months and where the
S0snapshots are the releases mentioned in Table 1 (these
releases are also indicated in Figure 2 via vertical lines). We
use these visualizations to observe the dierent patterns of
contributions.
In Angular.JS, most of the activity is due to stayer or ex-
ternal leavers. The high amount of external leavers activity
is in fact due to the contributions of a single developer, a
major contributor who was inactive in the six months prior
to the release of Angular.JS 1 :0:0.
In Ansible, all categories of developers have similar lev-
els of activity, and all contributed to a wide range of mod-
ules. This diers from other projects, especially for exter-
nal newcomers: all but one module has external newcomers,
and these developers often have an important activity. We
looked more closely at the module where external newcom-
ers were the most active, which is the module containing
\cloud" plugins for Ansible. Among the newcomers making
the most contributions, one was hired at Ansible, Inc., and
two worked at Rackspace, a managed cloud computing com-
pany, and developed an Ansible plugin for the Rackspace
cloud storage. These developers were most probably paid
to do their contributions, which explains this high level of
activity, not present with most of the newcomers.
The last three projects, Jenkins, JQuery and Rails, ex-
hibit the same patterns. In these three projects, internal
newcomers are active in most of the modules, while exter-
1Figure 3 also contains information related to bugxes,
which are discussed in the next research question.
8352011 2012 2013 2014 20150 100 300 500 700Angular.JS
2014 20150 100 300 500 700Ansible
2012 2013 2014 20150 20 40 60 80 120Jenkins
2011 2012 2013 20140 20 40 60 80JQuery
2009 2011 2013 20150 200 400 600 800RailsFigure 2: Evolution of developer turnover. The plain blue line (on top) represents the total number of
developers, the plain purple line (on the bottom) the number of stayers, the green dotted line the number of
external newcomers and the red dashed line the number of external leavers.
Total A
INA
ENA
ILA
ELA
StA
BugFixesAngular.JS
Total A
INA
ENA
ILA
ELA
StA
BugFixesAnsible
Total A
INA
ENA
ILA
ELA
StA
BugFixesJenkins
Total A
INA
ENA
ILA
ELA
StA
BugFixesJQuery
Total A
INA
ENA
ILA
ELA
StA
BugFixesRails
Figure 3: Visualization of developers activity and the quantity of bugxes for each module. Each horizontal
line of blocks represents a module. The darker the color, the higher the metric value.
nal newcomers and leavers are more focused, and do not
contribute to more than half of the modules.
Overall there is no module that was changed exclusively
by external newcomers. In all the projects of our corpus,
the external newcomers always contributed to modules with
either internal internal or permanent developers.
6.3 Developer Turnover and Software Mod-
ule Quality ( RQ3)
To answer our third research question, related to the rela-
tionship between module turnover and software quality, we
use the bug-related information extracted from our dataset
(same conguration as RQ2 for P1andP2). We perform
Spearman correlation tests between each turnover metric
and our quality metric. The quality metric we use is the
density of bugxes per module (i.e., the number of commits
that xed bugs divided by the size of the module). These
bugxes are extracted from the maintenance branch asso-
ciated to S0, meaning that there is a high probability that
they indeed x defects that occur in S0.Table 2 presents the results of these correlation tests for
each project and metric. Correlation coecients vary from
 1 to 1, which corresponds to a perfect negative and positive
correlation, respectively. Also, a correlation coecient of 0
reveals an absence of correlation. We used bootstrap with
theBCa statistic to compute 95% condence intervals of the
correlation coecients [13, 14]. If both ends of a condence
interval are either positive or negative (results highlighted in
bold), this means that there is a strong probability that there
is a positive or negative correlation, respectively, between
the turnover metric and the density of bug-xing commits.
To have a deeper understanding of the observed corre-
lations, Figure 3 presents a graphical visualization of the
turnover metrics and the number of bugxes. In that Fig-
ure, each project is presented by a matrix where each column
represents a metric, and each line represents a component
of the project. The cell of the matrix then represents the
value of the corresponding metrics and darker colors repre-
sent higher values.
836Table 2: Spearman correlation coecients between turnover metrics and the density of bug-xing commits
per module. Condence intervals are computed using bootstrap.
Project INA ILA ENA ELA StA Overall Activity
Angular.JS [-0.41 , 0.37] [-0.36 , 0.25] [0.12 , 0.69] [-0.56 , 0.16] [0.23 , 0.83] [-0.16 , 0.7]
Ansible [-0.27 , 0.73] [-0.31 , 0.65] [-0.21 , 0.68] [-0.3 , 0.7] [-0.15 , 0.76] [-0.27 , 0.75]
Jenkins [-0.3 , 0.28] [-0.18 , 0.42] [0.3 , 0.75] [-0.05 , 0.51] [0.05 , 0.63] [-0.01 , 0.6]
JQuery [-0.1 , 0.69] [0.13 , 0.81] [-0.02 , 0.73] [-0.4 , 0.44] [0.09 , 0.84] [0.14 , 0.8]
Rails [-0.01 , 0.52] [-0.24 , 0.3] [0.09 , 0.57] [-0.23 , 0.3] [0.14 , 0.58] [0.03 , 0.51]
The most important information in the results presented
in Table 2 is that there is a positive correlation between the
External Newcomer Activity and the density of bugxes.
Almost all of the projects exhibit a quite strong correlation.
Only Ansible exhibits a weak correlation but, looking at
Figure 3, this is certainly due to the fact that external new-
comers contributed to almost all of the components, even to
the ones that were not the target of bugxes. This is consis-
tent with the theories exposed in Section 2, which suggest
that external turnover has a negative eect on the quality
of a team's work. External Leavers Activity on the other
hand do not show any statistically signicant correlation
with bugx density in Table 2, and the two columns seem
completely independent in Figure 3.
Although Table 2 shows three statistically signicant cor-
relations between the Internal Leaver and Newcomer Activ-
ity and bugxes, their interpretation when looking at Fig-
ure 3 is unclear. As discussed with the previous research
question, internal newcomers contribute to the majority of
the modules, even the ones without any bugx.
Finally, as expected, there is a correlation between the
activity of persistent developers and the density of bugxes.
This then raises the question of the relative importance of
the turnover metrics regarding the software quality, and es-
pecially for the External Newcomer Activity (ENA) metrics,
as there is no correlation of the internal turnover metrics.
To measure how important is ENA we therefore built mul-
tiple linear regression models including other metrics, such
as the size of modules or the number of developers who con-
tributed to it. Unfortunately, it did not produce exploitable
results, due to the low R-squared of the resulting models,
and multicollinearity issues exposed by high variance ina-
tion factors of the predictors. We therefore cannot provide
sound answer to that point.
7. THREATS TO V ALIDITY
The validity of the results presented above is exposed to
several threats that we present here.
7.1 External Validity
The generalization of the results is our rst concern. On
one hand, we selected projects that use dierent program-
ming languages and that have hundreds of developers. On
the other hand, the study was performed on only ve projects
that were manually selected. To overcome this threat, fur-
ther studies have to be performed, to conrm and improve
the ndings presented in this paper. A barrier to achieve
these studies is to build curated datasets, following the re-
quirements presented in Section 5.7.2 Internal Validity
Our metrics assume that the only way developers con-
tribute to a project is by modifying its source code. This is
an approximation, as developers can modify other les such
as build and documentation les. A project is not conned
to its version control system: other types of repositories,
such as bug-tracking system or mailing lists, might reveal
that some developers considered as newcomers or leavers
might be in fact persistent contributors of the project. Turnover
metrics based on multiple kinds of repositories are left for
future work.
It should be noted that our results should not be inter-
preted as if external leavers and newcomers developers in-
troduced more bugs than internal. We do not provide or
have any information on who introduce bugs because there
is, to the best of our knowledge, no reliable algorithm that
can identify the author of a bug.
We did not nd a reliable way to identify developers with
push rights to the repositories. Hence, we could not deter-
mine the impact of this feature on the dierent patterns of
turnover. However it should be noted that the projects in
our dataset mainly follow a pull-request workow (a popular
approach on Github). With this workow, even if a devel-
oper has push rights she will create a pull-request in the
project when making a contribution to benet from the re-
view mechanism. Thus, except for the developers in charge
of merging the pull-requests the other core members do not
need to have push rights.
7.3 Construct Validity
In addition, we identify several threats to construct va-
lidity from the previous study. On GitHub, developers can
submit pull requests, so that the project leaders, who have
write permission on the repository, can add their contribu-
tions to the project. As the identity of the initial author
is maintained through the pulloperation, she is identiable
even though she does not have access to the main reposi-
tory. However, as shown in [25] it may happen that a de-
veloper discussed with a pull request author to agree on its
acceptance. Even though this developer spent time to x or
improve the pull request content, all the credits will go to
the pull request author. This may also introduce a bias in
the results.
Identifying software modules in a project is not a straight-
forward task and might be subject to interpretation. Since
we could not get the conrmation from the dierent devel-
opment teams some modules in our decomposition might
be split or merged in comparison to what the development
teams would have dened.
Related to the same threat the quality of the software
architecture can have an impact on the metrics. Retention
837could appear higher in well modularized systems than poorly
designed systems where one x might require changes to
many modules. The fact that the results produced with the
decomposition based on co-change activity overlaps strongly
with the manual decomposition based on directories shows
that the impact is negligible for this dataset.
We deliberatively did not rely on the information pro-
vided by bugtrackers, as several studies showed that their
use can introduce an important bias [21]. The drawback
of our technique is that the number of bug-xing commits
may not reveal the actual number of bugs that appeared
in the software modules. There may exists bugs that are
tedious to x and remain to be resolved. In addition, the
manual analysis has some limits due to the subjective eval-
uation to decide whether or not a commit is a bug-xing
commit. We only went through a maintenance branch to
collect such commits for each project, although it poten-
tially exists bug-xing commits from the main development
branch that have not been backported to the maintenance
branch. Finally some bug-xing commits may x bugs that
were not introduced in the current release but in one of the
older releases.
8. CONCLUSION AND FUTURE WORK
In this paper, we propose and investigate metrics to mea-
sure turnover in open-source software projects. Our met-
rics measure how the structure of a group of developers is
changing, both internally and externally, for a given period
of a software project. We used these metrics on ve open-
source projects with two objectives: to observe the turnover
phenomenon, and to evaluate its relationship with software
quality.
We observed that the ve open-source projects in our cor-
pus, chosen because of their popularity and success, have a
high turnover. This observation disagrees with the conclu-
sions of Hall et al. that recommend to control turnover to
improve the success of industrial projects [19]. Our results
then suggest that turnover and success may have a dierent
relationship in open-source projects.
Looking at the module level, we show some very inter-
esting turnover patterns. These patterns reveal that the
projects of our corpus act dierently regarding turnover.
For instance, in some projects modules receive contributions
only by internal developers with no contribution from stay-
ers. These patterns also show that in all projects external
newcomers always work with either permanent or internal
developers, who hopefully supervise them. Such an observa-
tion opens the room for rules or guidelines that will dene
how newcomers should be supervised, and how they should
contribute to modules of a project [8].
We also found that external turnover has a negative im-
pact on the quality of the modules. This result is consistent
with theories that suggest that external turnover has a nega-
tive eect on the quality of a team's work. However, it diers
from the ones of Mockus [30], as in our case newcomers have
a relationship with quality and leavers do not have such re-
lationship, while it was the opposite in Mockus' study. On
the other hand, internal turnover has almost no eect. Our
observations therefore do not conrm the theories that sug-
gest that internal turnover is benecial. These ndings can
be reused by researchers when using software metrics based
on the activity of developers on the source code: as the ac-
tivity of external newcomers has a stronger relationship withquality than the activity of other categories of developers,
this may be the only activity worth considering.
Finally, our study and ndings lead the way for many
kinds of future work:
Our ndings are based on observations made on software
modules, with manual observation of patterns and using
correlation between the density of bug-xing commits and
the activity of the dierent categories of turnover actors.
As there are no related work that performed such obser-
vations on open-source projects, our study needs to be
replicated on more projects, which is facilitated by our
replication package (Section 10).
The main limitation of our metrics is the fact that they
require a selection of periods. In particular, we shown
that the length of the chosen periods has a major impact
on the measures, and we therefore provide some insights
showing that a time period is adequate in the case of open-
source project, with good results with 6 months periods.
We then plan to overcome this limitation by developing
continuous metrics for turnover, where the discretization
of the history is not necessary.
Our results regarding turnover patterns suggest that the
observed patterns are impacted by the motivation of de-
velopers, which mainly depends on the fact that they are
paid or not. This hypothesis can be evaluated only if it is
possible to distinguish paid contributors from volunteers.
We then plan to identify the employee of the developers,
and then to analyze its relationship with turnover metrics.
Independently of whether developers are paid or volun-
teers, they may be core member of the projects, and thus
have a higher retention level than other developers, as
well as a higher level of activity in the project. Identify-
ing core members of a project may help us understanding
the impact of developer turnover on software quality.
9. AUXILIARY MATERIAL
Due to the space constraint of this paper, part of our
results are available online [2]. This page includes results
regarding the period selection, as well as more detailed ver-
sions of Figure 2 and Figure 3.
10. REPLICATION PACKAGE
The dataset built using the methodology presented in Sec-
tion 5, the code necessary to extract the metrics, as well as
additional results are available online, in a replication pack-
age that has been successfully evaluated by the Replication
Packages Evaluation Committee and found to meet expec-
tations [2]. We describe here the technical aspects of this
package, the data produced by the executed software and
the installation process of the replication package.
10.1 The Diggit Tool
The software of our replication package relies on the Diggit
tool, which supports analysis of Git repositories and which
helps manage the analysis process [1]. Diggit manages a set
of Git repositories. On each repository, Diggit applies sev-
eral user specied analyses . When all user-specied analy-
ses have been applied, Diggit applies global analyses (called
joins in the tool) that use the results of all the previously ap-
plied analyses to produce nal results. Diggit is used within
adiggit folder , which contains various conguration les, in-
cluding the list of Git repositories to clone and analyse, the
838list of analyses and joins to perform, and additional infor-
mation that may be used by analyses. This tool is developed
in Ruby by two of the authors of this paper; we used version
2.0.2.
10.2 Package Installation and Usage
The replication package is distributed as a VirtualBox vir-
tual machine image. This image is based on a minimal ver-
sion of a Linux Ubuntu on which only the requirements to
replicate the study were installed. The list of commands re-
quired to install our replication package from a fresh install
of a minimal Ubuntu is also available online.
The package consists of a set of diggit analyses, that are all
loaded in a diggit folder in the VM image (this folder can also
be generated with a script). The rst step of the replication
is to clone the ve Git repositories to be analyzed using the
dgit clone command. Then, the dgit analyses perform
command allows to run, for each of the cloned repositories,
the following analyses:
Extraction of the number of lines of code of each le at
release S0, which is used to compute bug-xing com-
mits density.
Computation of the number of lines of code and the
number of bug-xing commits of each module (the list
of modules is stored in a conguration le).
Computation of the activity of each developer on each
module.
Computation of the activity of developers at the project
level.
The data produced for each repository is then aggregated
by a global analysis that uses the R programming language
and produces all the results presented in this paper and in
the additional results available online.
10.3 Replication Data
Our replication package also provides data that can be
reused for future studies. It includes the information de-
scribed in Section 5 which is given as input to the analy-
ses described above, and activity information, which can be
reused to compute other metrics than developer turnover
(such as code ownership for instance [16]).
For each repository, the data provided as input of the
analyses is the following:
The author renaming information.
The lists of modules extracted with the dierent mod-
ularization techniques.
The commit id of the S0release.
The commit ids of the bug-xing commits performed
inS0release's maintenance branch.
This data is stored in a single JSON le and thus can be
easily reused.
Besides the nal results provided by the global analysis
that are presented in this paper, each analysis produces in-
termediary results that are stored in a MongoDB database.
The data stored in this database consist in a monthly mea-
sure of activity (code churn) for each developer and module,
and each month prior to the S0release up to the start of the
Git history of the repository.
11. REFERENCES
[1] The diggit git repository analysis tool.
https://github.com/jrfaller/diggit . Accessed:
2015-07-15.[2] Replication package - impact of developer turnover on
quality in open-source software.
http://se.labri.fr/a/FSE15-foucault . Accessed:
2015-07-15.
[3] M. A. Abelson and B. D. Baysinger. Optimal and
dysfunctional turnover: Toward an organizational level
model. Academy of Management Review ,
9(2):331{341, Apr. 1984.
[4] L. Argote and D. Epple. Learning curves in
manufacturing. Science , 247(4945):920{924, Feb. 1990.
[5] C. Bird, A. Bachmann, E. Aune, J. Duy,
A. Bernstein, V. Filkov, and P. Devanbu. Fair and
balanced?: Bias in bug-x datasets. In 7th joint
meeting of the European Software Engineering
Conference and the ACM SIGSOFT symposium on
The Foundations of Software Engineering
(ESEC/FSE) , page 121{130, 2009.
[6] C. Bird, P. Rigby, E. Barr, D. Hamilton, D. German,
and P. Devanbu. The promises and perils of mining
git. In 6th IEEE International Working Conference on
Mining Software Repositories, 2009. MSR '09 , pages 1
{10, May 2009.
[7] T. F. Bissyand e, F. Thung, S. Wang, D. Lo, L. Jiang,
and L. R eveill ere. Empirical evaluation of bug linking.
InProceedings of the 17th European Conference on
Software Maintenance and Reengineering (CSMR
2013) , pages 1{10, Mar. 2013.
[8] G. Canfora, M. Di Penta, R. Oliveto, and
S. Panichella. Who is going to mentor newcomers in
open source projects? In Proceedings of the ACM
SIGSOFT 20th International Symposium on the
Foundations of Software Engineering , page 44, 2012.
[9] A. Clauset, M. E. Newman, and C. Moore. Finding
community structure in very large networks. Physical
review E , 70(6):066111, 2004.
[10] L. Dabbish, R. Farzan, R. Kraut, and T. Postmes.
Fresh faces in the crowd: Turnover, identity, and
commitment in online groups. In Proceedings of the
ACM 2012 Conference on Computer Supported
Cooperative Work , CSCW '12, page 245{248. ACM,
2012.
[11] G. G. Dess and J. D. Shaw. Voluntary turnover, social
capital, and organizational performance. Academy of
Management Review , 26(3):446{456, July 2001.
[12] L. R. Dice. Measures of the amount of ecologic
association between species. Ecology , 26(3):297, July
1945.
[13] B. Efron. Bootstrap methods: another look at the
jackknife. The Annals of Statistics , page 1{26, 1979.
[14] B. Efron. Better bootstrap condence intervals.
Journal of the American Statistical Association ,
82(397):171{185, 1987.
[15] K. Fogel. Producing Open Source Software: How to
Run a Successful Free Software Project . O'Reilly
Media, rst edition, Feb. 2013.
http://www.producingoss.com/.
[16] M. Foucault, J.-R. Falleri, and X. Blanc. Code
ownership in open-source software. In Proceedings of
the 18th International Conference on Evaluation and
Assessment in Software Engineering , EASE '14, page
39:1{39:9. ACM, 2014.
839[17] I. Fronza, A. Janes, A. Sillitti, G. Succi, and
S. Trebeschi. Cooperation wordle using pre-attentive
processing techniques. In 2013 6th International
Workshop on Cooperative and Human Aspects of
Software Engineering (CHASE) , pages 57{64, May
2013.
[18] M. Goeminne and T. Mens. A comparison of identity
merge algorithms for software repositories. Science of
Computer Programming , 78(8):971{986, 2013.
[19] T. Hall, S. Beecham, J. Verner, and D. Wilson. The
impact of sta turnover on software projects: The
importance of understanding what makes software
practitioners tick. In Proceedings of the 2008 ACM
SIGMIS CPR Conference on Computer Personnel
Doctoral Consortium and Research , SIGMIS CPR '08,
page 30{39. ACM, 2008.
[20] D. S. Hamermesh, W. H. J. Hassink, and J. C. v.
Ours. Job turnover and labor turnover: A taxonomy of
employment dynamics. Open Access publications from
Tilburg University 12-86873, Tilburg University, 1996.
[21] K. Herzig, S. Just, and A. Zeller. It's not a bug, it's a
feature: How misclassication impacts bug prediction.
InProceedings of the 2013 International Conference
on Software Engineering , page 392{401, 2013.
[22] M. A. Huselid. The impact of human resource
management practices on turnover, productivity, and
corporate nancial performance. Academy of
Management Journal , 38(3):635{672, June 1995.
[23] P. Hynninen, A. Piri, and T. Niinimaki. O-site
commitment and voluntary turnover in GSD projects.
In2010 5th IEEE International Conference on Global
Software Engineering (ICGSE) , pages 145{154, Aug.
2010.
[24] D. Izquierdo-Cortazar. Relationship between
orphaning and productivity in evolution and GIMP.
2008.
[25] E. Kalliamvakou, G. Gousios, K. Blincoe, L. Singer,
D. M. German, and D. Damian. The promises and
perils of mining GitHub. In Proceedings of the 11th
Working Conference on Mining Software Repositories ,
page 92{101. ACM, 2014.
[26] R. M. Kanter. The impact of hierarchical structures
on the work behavior of women and men. Social
Problems , 23(4):415{430, Apr. 1976.
[27] D. Krackhardt and L. W. Porter. When friends leave:
A structural analysis of the relationship between
turnover and stayers' attitudes. Administrative Science
Quarterly , 30(2):242{61, Jan. 1985.
[28] T. Mens, M. Claes, P. Grosjean, and A. Serebrenik.
Studying evolving software ecosystems based on
ecological models. In Evolving Software Systems , pages
297{326. Springer Berlin Heidelberg, Jan. 2014.
[29] A. Mockus. Succession: Measuring transfer of code
and developer productivity. In Proceedings of the 31st
International Conference on Software Engineering ,
ICSE '09, page 67{77. IEEE Computer Society, 2009.
[30] A. Mockus. Organizational volatility and its eects on
software defects. In Proceedings of the Eighteenth
ACM SIGSOFT International Symposium on
Foundations of Software Engineering , FSE '10, page
117{126. ACM, 2010.[31] A. Mockus and L. G. Votta. Identifying reasons for
software changes using historic databases. In
Proceedings of the International Conference on
Software Maintenance (ICSM'00) , ICSM '00, page
120{. IEEE Computer Society, 2000.
[32] K. Panciera, A. Halfaker, and L. Terveen. Wikipedians
are born, not made: A study of power editors on
wikipedia. In Proceedings of the ACM 2009
International Conference on Supporting Group Work ,
GROUP '09, page 51{60. ACM, 2009.
[33] D. L. Parnas. On the criteria to be used in
decomposing systems into modules. Communications
of the ACM , 15(12):1053{1058, 1972.
[34] P. Pons and M. Latapy. Computing communities in
large networks using random walks. In Computer and
Information Sciences - ISCIS 2005 , number 3733 in
Lecture Notes in Computer Science, pages 284{293.
Springer Berlin Heidelberg, 2005.
[35] X. Qin, M. Salter-Townshend, and P. Cunningham.
Exploring the relationship between membership
turnover and productivity in online communities.
2014.
[36] S. Ransbotham and G. C. Kane. Online communities:
Explaining rises and falls from grace in wikipedia. MIS
Q., 35(3):613{628, Sept. 2011.
[37] G. Robles and J. M. Gonzalez-Barahona. Contributor
turnover in libre software projects. In Open Source
Systems , number 203 in IFIP International Federation
for Information Processing, pages 273{286. Springer
US, Jan. 2006.
[38] A. Schilling, S. Laumer, and T. Weitzel. Who will
remain? an evaluation of actual person-job and
person-team t to predict developer retention in
FLOSS projects. In 2012 45th Hawaii International
Conference on System Science (HICSS) , pages
3446{3455, Jan. 2012.
[39] P. N. Sharma, J. Hulland, and S. Daniel. Examining
turnover in open source software projects using
logistic hierarchical linear modeling approach. In Open
Source Systems: Long-Term Sustainability , number
378 in IFIP Advances in Information and
Communication Technology, pages 331{337. Springer
Berlin Heidelberg, Jan. 2012.
[40] J. D. Shaw, N. Gupta, and J. E. Delery. Alternative
conceptualizations of the relationship between
voluntary turnover and organizational performance.
Academy of Management Journal , 48(1):50{68, Feb.
2005.
[41] J. D. Thompson. Organizations in action: Social
science bases of administrative theory. SSRN Scholarly
Paper ID 1496215, Social Science Research Network,
1967.
[42] Y. Tian, J. Lawall, and D. Lo. Identifying linux bug
xing patches. In Software Engineering (ICSE), 2012
34th International Conference on , page 386{396, 2012.
[43] Z. Ton and R. S. Huckman. Managing the impact of
employee turnover on performance: The role of
process conformance. Jan. 2008.
[44] S. G. Westlund and J. C. Hannon. Retaining talent:
Assessing job satisfaction facets most signicantly
related to software developer turnover intentions.
840Journal of Information Technology Management ,
19(4):1{15, 2008.
[45] Y. Yu, A. Benlian, and T. Hess. An empirical study of
volunteer members' perceived turnover in open source
software projects. In 2012 45th Hawaii International
Conference on System Science (HICSS) , pages
3396{3405, Jan. 2012.[46] T. Zimmermann, R. Premraj, and A. Zeller.
Predicting defects for eclipse. In International
Workshop on Predictor Models in Software
Engineering, 2007. PROMISE'07: ICSE Workshops
2007, page 9, May 2007.
841