Automatically Finding Bugs in a Commercial Cyber-Physical
System Development Tool Chain With SLforge
Shafiul Azam Chowdhury
Computer Science & Eng. Dept.
University of Texas at Arlington
Arlington, TX, USASoumik Mohian
Computer Science & Eng. Dept.
University of Texas at Arlington
Arlington, TX, USASidharth Mehra
Computer Science & Eng. Dept.
University of Texas at Arlington
Arlington, TX, USA
Siddhant Gawsane
Computer Science & Eng. Dept.
University of Texas at Arlington
Arlington, TX, USATaylor T. Johnson
EECS Department
Vanderbilt University
Nashville, TN, USAChristoph Csallner
Computer Science & Eng. Dept.
University of Texas at Arlington
Arlington, TX, USA
ABSTRACT
Cyber-physicalsystem(CPS)developmenttoolchainsarewidely
used in the design, simulation, and verification of CPS data-flow
models.CommercialCPStoolchainssuchasMathWorks’Simulink
generateartifactssuchascodebinariesthatarewidelydeployedin
embeddedsystems.Hardeningsuchtoolchainsbytestingiscru-
cial since formally verifying them is currently infeasible. Existing
differential testing frameworks such as CyFuzz can not generate
models richinlanguage features,partly becausethese toolchains
do not leverage the available informal Simulink specifications. Fur-
thermore, no study of existing Simulink models is available, which
could guide CyFuzz to generate realistic models.
To address these shortcomings, we created the first large col-
lectionofpublicSimulinkmodelsandusedthecollectedmodels’
properties to guide random model generation. To further guide
modelgenerationwesystematicallycollectedsemi-formalSimulink
specifications. In our experiments on several hundred models, the
resultingSLforgegeneratorwasmoreeffectiveandefficientthan
the state-of-the-art tool CyFuzz. SLforge also found 8 new con-
firmed bugs in Simulink.
CCS CONCEPTS
•Softwareanditsengineering →Model-drivensoftwareen-
gineering ;Software testing and debugging ;
KEYWORDS
Cyber-physical systems, differential testing, tool chain bugs
ACM Reference Format:
ShafiulAzamChowdhury,SoumikMohian,SidharthMehra,SiddhantGawsane,
TaylorT.Johnson,andChristophCsallner.2018.AutomaticallyFindingBugs
in a Commercial Cyber-Physical System Development Tool Chain WithSLforge. In ICSE ’18: ICSE ’18: 40th International Conference on Software
Engineering , May 27-June 3, 2018, Gothenburg, Sweden. ACM, New York,
NY, USA, 12 pages. https://doi.org/10.1145/3180155.3180231
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.
For all other uses, contact the owner/author(s).
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5638-1/18/05.
https://doi.org/10.1145/3180155.31802311 INTRODUCTION
Cyber-physicalsystemdevelopersrelyheavilyoncomplexdevel-
opment environments or tool chains, which they use to design
graphical models(i.e.,block-diagrams )ofcyber-physicalsystems.
Such models enable engineers to do rapid prototyping of theirsystems through simulation and code generation [
23]. Since au-
tomatically generated native code from these data-flow models
areoftendeployedinsafety-criticalenvironments,itiscrucialto
eliminate bugs from cyber-physical system tool chains [7, 40].
Ideally, one should formally verify such tool chains, since a tool
chain bug may compromise the fidelity of simulation results or
introducesubtlebugsingeneratedcode[ 8].However,acommer-
cialcyber-physicalsystem (CPS)developmenttoolchainconsists
of millions of lines of code, so formal verification does not (yet)
scaletosuchtoolchains.WhilecompilersandotherCPStoolchain
components remain mostly unverified, we continue to observe fre-
quent safety recalls in various industries [ 1,55,56]. The recalls are
attributed to hidden bugs in the deployed CPS artifacts themselves,
in spite of spending significant efforts in their design validation
and verification [5, 57].
Testing,ontheotherhand,isaprovenapproachtoeffectively
discover defects in complex software tool chains [ 34]. Especially
randomized differential testing has recently found over a thousand
bugs in popular production-grade compilers (e.g., GCC and LLVM)
thatarepartofCPSdevelopmenttoolchains[ 17,25,30,45,58].The
technique eliminates the need of a test-oracle and can hammer the
system under test in the absence of a complete formal specification
of the system under test—a phenomenon we commonly observe in
commercialCPStoolchaintesting[ 6,24,50].Differentialtesting
seemssuitableforblack-boxtestingoftheentireCPStoolchain,and
itsmostsusceptibleparts(e.g.,codegenerators)inparticular[ 43,50].
CyFuzzisthefirst(andonly)knownrandomizeddifferentialtesting
tool for CPS data-flow languages [11].
While CyFuzz initiated the work for testing CPS tool chains,
moreworkisnecessarytoevaluatethescheme’scapabilities,e.g.,
forfindingbugsinSimulinkthatdeveloperscareabout.Forinstance,
a random model generator should generate tests with properties
similartothemodelspeopletypicallyuse,sincetheyaremorelikely
togetfixedbythesystemundertest(SUT)developers.Whilelarge
repositoriesofpubliclyavailableprogramsofvariousprocedural
andobject-orientedprogramminglanguagesexist[ 12,22,59],we
9812018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Chowdhury, Mohian, Mehra, Gawsane, Johnson, Csallner
are not aware of such a collection of CPS models. The existing CPS
studiesrelyonahandfulofpublic[ 41]orproprietary[ 47]Simulink
models.
Among other shortcomings, the models CyFuzz generates are
small and lack many syntactic constructs. Recent studies identified
expressive test-input generation as a success-factor for compiler
validation([ 30,58]).Perhapsduetoitsinabilitytogeneratelarge
tests with rich language features, CyFuzz has not found previously
unknown bugs. Furthermore, CyFuzz essentially generates invalid
models and iteratively fixes them until the SUT can compile and
simulate them without error or exception. However, this heuristic
approachrequiredseveraltime-consumingiterationsanddidnot
use Simulink specifications, which are available publicly in natural
language.
Toaddresstheseshortcomings,wehaveconductedthefirststudy
ofalargenumberofpublicSimulinkmodels.Thesizeofmanyof
these models is larger than the average size of models used in
industry.Fromthecollectedmodelsweobtainpropertiesthatare
usefulfortargetingarandomSimulinkmodelgenerator.Ourmodel
collection is publicly available and may eliminate the nontrivial
overhead of artifact-collection in future studies.
Next,extendingCyFuzz,wepresentSLforge,atoolforautomat-
icallygeneratingmodelswithadvancedSimulinklanguagefeatures.
The goal is that the SLforge-generated models are similar to the
collectedpublicmodels.ImprovingonCyFuzz’sundirectedrandom
model generation approach, SLforge can generate models more ef-
ficiently, by consulting available (informal) Simulink specifications.
Finally,weprovidethefirstapproachto Equivalentmoduloinput
(EMI) testing in CPS development tool testing [ 30]. SLforge creates
EMIvariantsfromtherandommodelsitgeneratesandusestheminthedifferentialtestingsetup.Duringanapproximatelyfivemonths
long testing time, we found and reported 12 bugs overall, Math-
Worksconfirmed10ofthem,ofwhich8werepreviouslyunknown.
To summarize, the paper makes the following major contributions.
•To better target a random CPS model generator, we con-
ductthefirstlarge-scalestudyofpubliclyavailableSimulinkmodels.Asignificantportionofthesemodelsareofsizeand
complexity that are comparable to models used in industry.
•We identify problems in the existing CPS random model
generatorCyFuzzanddesignsolutionsthatdirectlyledto
the discovery of new bugs in the Simulink tool chain.
•Finally, by comparing it with CyFuzz, we evaluate SLforge’s
efficiency and bug-finding capability.
2 BACKGROUND
ThissectionprovidesnecessarybackgroundinformationonCPS
dataflowmodels,themajorcommercialCPStool-chainSimulink,
the state-of-the-art differential CPS tool-chain testing tool CyFuzz,
and EMI-based differential testing.
2.1 CPS Data-flow Models And Simulink
Whilein-depthdescriptionsareavailableelsewhere[ 54],thefollow-
ingarethekeyconcepts.InaCPSdevelopmenttool(e.g.,Simulink),
a user designs a CPS as a set of dataflow models. A model contains
blocks.Ablockacceptsdatathroughits inputports ,typicallyper-
forms on the data someoperation, and may pass output through
Figure 1: Example hierarchical CPS model: Rounded rec-
tangle = model; shaded = block; oval = I/O; solid ar-row = dataflow; dashed arrow = hierarchy.
itsoutput ports to other blocks, along connection lines. Simulink
specifies which port (of a block) supports which data-types .
Inaconnection,wenametheblocksendingoutput sourceandthe
blockreceivingdataa target.Outputportsarenumberedstarting
with1.Inputportnumberingstartswith0,where0denotesaspecial
port(e.g.,the Actionportofthe IfActionblock).Inadditiontosuch
explicitconnections,using FromandGotoblocks,onecandefine
implicit (hidden) connections [40, 44].
Commercial CPS tool chains offer many librariesof built-in
blocks.BesidescreatingaCPSfrombuilt-inblocks,onecanadd cus-
tomblocks anddefinetheirfunctionalityviacustom“native”code
(e.g., in Matlab or C, using Simulink’s S-function feature). Most
blocks have user-configurable parameters .
More formally, block b∈Band connection c∈Cmay be part of
modelm∈M.Thenaflat(non-hierarchical)modelisatuple /angbracketleftB,C/angbracketright
wherem.Bandm.Cdenote the model’s blocks and connections.
Eachconnectionisatuple /angbracketleftbs,ps,bt,pt/angbracketrightofsourceblock bs,source
output port ps, target block bt, and target input port pt. While a
Simulinkconnectionmayhavemultipletargets,webreaksucha
multi-target connection into multiple (single-target) connection
tuples, without losing expressiveness.
Forhierarchicalmodelswelistamodel miathierarchylevel i
withitsndirectchildmodelsas mi[mi+1
k,...,mi+1
k+n−1].TheFigure1
examplem1
1[m2
2,m2
3]hasm1
1asitstop-levelmodel.m2
2andm2
3are
m1
1’schildmodelsathierarchylevel2.Thedashedarrowstarting
atb2indicatesthatinthe m1
1modelb2isaplaceholder forthem2
2
model. Block b1sends data to m2
2, whereb6receives it. Block b8
sends data back to b4inm1
1.
Example placeholders are the subsystem andmodel reference
blocks.Achildmodel m’ssemanticsareinfluencedby m’shierarchy-
typepropertyTh,whichdependson m’sconfiguration,thepresence
of specific blocks in m, and onm’s placeholder block-type.
AfterdesigningamodelinSimulink,userstypically compileand
simulateit. In simulation, Simulink numerically solves the model’s
mathematical relationships established by the blocks and their con-
nections and calculates various non-dead (§4.3) block’s outputs
according to user-requested sample-times and inferred context-dependent time steps , using built-in solvers[
33]. Simulink offers
differentsimulation modes . While in Normalmode Simulink “only”
simulates blocks,it alsoemits some code for blocksin Accelerator
mode, and a standalone executable in Rapid Accelerator mode.
Aninputport pofblockbisDirectFeed-through ifb’soutputde-
pendsonvaluesreceivedfrom p.Theparenttochildmodelrelation
982
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. Automatically Finding CPS Tool Chain Bugs With SLforge ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
is acyclic. But within a model Simulink permits feedback loops (cir-
cular data flow). During compilation Simulink may reject a model
ifitfailstonumericallysolvefeedbackloops(aka algebraicloops ).
Simulink also supports explicit control-flow, e.g., via Ifblocks. An
If(“driver”) block connects to two If Actionsubsystem blocks, one
for each branch, via the If Actionblock’sActionport.
2.2 Testing Simulink With CyFuzz
CyFuzzisthefirstknowndifferentialtestingframeworkforCPS
tool chains [ 11]. The framework has five phases. The first three
phases create a random model and the last two phases use the
model to automatically test a SUT.
Specifically, startingfrom an emptymodel, (1)the SelectBlocks
phasechoosesrandomblocksandplacestheminthemodel.(2)The
ConnectPorts phaseconnectstheblocks’portsarbitrarily,yieldinga
modeltheSUTmayreject,e.g.,duetoatypeerror.Forexample,an
output port’s data type may be incompatible with the data type of
the input port it connects to. (3) CyFuzz iteratively fixes such bugs
in theFix Errors phase, by responding to the SUT’s error messages
with corresponding repair actions. This “feedback-driven model
generation” approach, despite being an imperfect heuristic, can fix
many such model errors.
Once the SUT can compile a randomly generated model, (4) Cy-
Fuzz’sLogSignals phasesimulatesthemodelundervaryingSUT
options. The key idea of differential testing is that each such simu-
lation isexpectedto producethe sameresults. Thisphase records
the output data (aka signals) of each block at various time-steps.
CyFuzzusesdifferentSimulinksimulationmodes,partlytoexercise
various code generators in the tool chain. Finally, in addition to
SUT crashes, (5) the Compare phase looks for signals that differ
between two simulation setups, which also indicate a bug.
CyFuzzcategorizesitsgeneratedmodelsintothreegroups:(1) Suc-
cess:modelswithoutanycompile-timeandruntimeerrors,(2) Error:
models with such errors, and (3) Timed-out : models whose simula-
tiondidnotcompletewithinaconfiguredtime-outvalue.Although
CyFuzz pioneered the differential testing of Simulink using ran-
domlygeneratedmodels,itdidnotfindnewbugs,perhapssince
thegeneratedmodelsaresmallandsimple(usingonlyfourbuilt-in
libraries and lacking advanced modeling features). Also, CyFuzz
doesnotuseSimulinkspecificationsandsolelyreliesoniterative
model correction.
2.3 EMI-based Compiler Testing
Equivalentmoduloinput(EMI) testingisarecentadvancementin
differentialtestingofcompilersforprocedurallanguages[ 30].Com-
plementing plain differential testing, EMI found over one hundred
bugs in GCC and LLVM [ 8]. The idea is to systematically mutate a
sourceprogramaslongasitssemanticsremainequivalentunder
the given input data. Engineering basic mutators is relatively easy
andtheoverallschemecaneffectivelyfindbugs,whencombined
withapowerfulrandomgeneratorthatcancreateexpressivetest
inputs (e.g., Csmith [58]).
In its original implementation, EMI mainly leverages Csmith,
whichgeneratesrandomCprogramsthatdonottakeuserinputs.
A given compiler in a given configuration can then be expected to
produce programs that yield the same result on all EMI-mutants ofa given source program. The initial implementation proved very
effective and found 147 bugs in production-grade C compilers such
as GCC and LLVM.
3 PUBLIC SIMULINK MODEL COLLECTION
To understand the properties of CPS data-flow models designed by
both researchers and engineers, we conducted the first large study
ofSimulinkmodels.ThelargestearlierSimulinkmodelcollection
we are aware of contains some 100k blocks [ 16]. However, these
modelsarecompany-internalandthusnotavailableforthird-party
studies. In contrast, our collection consists of some 145k blocks,
which are all publicly available (some require a standard Simulink
license as they are shipped with Simulink).
For context, earlier work reports that at Delphi, a large indus-
trialSimulinkuser,anaverageSimulinkmodelconsistsofseveral
hundredblocks[ 32].Ofthemodelswecollected,35consistofmore
than 1,000 blocks, which is larger than an average model at Delphi.
3.1 Model Collection and Classification
Forthisstudy,weusedtheSimulinkconfigurationourorganization
has licensed, which includes the base Simulink tool chain and a
largesetoflibraries.ThisconfigurationincludesthelatestSimulink
version;theprojectwebpageliststhedetailedconfiguration[ 10].
However,withthisconfiguration,wecoulddirectlycompileonly
justoverhalfofthecollectedmodels,astheremainingonesrequired
additional libraries that were not part of our configuration [10].
3.1.1 Tutorial. This group consists of official Simulink tutorial
models from MathWorks1. We manually reviewed the models and
theirdescriptionsintheAutomotive,Aerospace,IndustrialAutoma-
tion,GeneralApplications,andModelingFeaturescategoriesand
excluded what we considered toy examples. We also included here
the Simulink-provided domain-specific library we had access to,
i.e., Aerospace. An example model from this group is NASA HL-20
(1,665blocks),whichmodels“theairframeofaNASAHL-20lifting
body, a low-cost complement to the Space Shuttle orbiter” [53].
3.1.2 Simple and Advanced. Wecollectedmodelsfrombothma-
jor open source project hosting services for Simulink, GitHub and
MatlabCentral.(1)WeusedtheGitHubsearchpageforkeyword
search (“Simulink”) and file extension search (Simulink extensions
.mdland.slx).(2)OnMatlabCentral2wefilteredresultsby“con-
tent type: model”and considered only thoserepositories with the
highest average ratings (27 projects) or “most downloads” count in
the last 30 days (27 projects).
To distinguish toy examples from more realistic models, we
labeledtheGitHubprojectsnouserhasforkedormarkedafavorite
asSimpleandtherestasAdvanced.FortheMatlabCentralprojects,
we manually explored their descriptions and labeled those that
demonstrate some blocks’ features or are academic assignments as
Simple and the rest as Advanced.
Asanexample,amodelfromthe Grid-ConnectedPVArray project
is“adetailedmodelofa100-kWarrayconnectedtoa25-kVgridvia
1https://www.mathworks.com/help/simulink/examples.html
2https://www.mathworks.com/matlabcentral/fileexchange
983
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Chowdhury, Mohian, Mehra, Gawsane, Johnson, Csallner
Table 1: Overview of collected public models: Total num-
ber of models (M); models we could readily compile with-out extra effort (C); hierarchical models (H); total numberof blocks and connections.
Group M C H Blocks Connect.
t Tutorial 41 40 40 10,926 11,541
s Simple 156 99 136 7,187 7,121
a Advanced 167 66 165 118,632 116,608
o Other 28 14 21 8,317 9,577
Total 391 219 362 145,062 144,847
aDC-DCboostconverter”createdbyaseniorengineeratHydro-
Quebec Research Institute (IREQ) [ 42]. It has 1,320 blocks. We clas-
sified it as Advanced.
3.1.3 Other. Thisgroupconsistsofmodelsweobtainedfrom
academic papers (5 models), the academic research of colleagues
(7 models), and Google searches (16 models). An example is the
Benchmarks for Model Transformations and Conformance Checking
releasedbyengineersatToyotaTechnicalCenterCalifornia[ 27].It
has 208 blocks.
3.2 Model Metrics
In this study, we focus on those model properties that are relevant
for constraining a random model generator to models that are
representativeofrealisticCPSmodels.OurMatlab-basedtoolwe
usedtocollectthefollowingmetricsisfreelyavailableontheproject
site [10]. The collected metricvalues are shown as box-plots with
min-max whiskers.
3.2.1 Number of Blocks and Connections. Blocks and connec-
tions are the main elements of Simulink models and are counted
widely[32,39].Wehaveincludedthecontentsofmaskedblocks[ 54]
in the parent model’s count. Next, we count the total number of
blocks and connections at a particular hierarchy level up to hierar-
chy level 7.
Ourconnection-countmetricdoesnotincludehiddenconnec-
tions. For connections with multiple target ports, we count the
connections’ target ports. Perhaps not surprisingly, Simple models
aresmaller(andAdvancedmodelsarelarger)thanmodelsofthe
other groups (Figures 2a and 2b), since we manually reviewed and
classified them in this class.
3.2.2 Hierarchy Depth. Since industrial modelsare frequently
organized as a hierarchy, we measured how deep these hierarchies
are.Wetreatedboth subsystems andmodelreference blocksasadding
ahierarchylevel.Mostofthecollectedmodelsareindeedhierar-
chical(i.e.,362/391models).Butthemedianmaximumhierarchy
depth did not extend five across all model groups.
Moresurprisingwerethedistributionofblocksandconnections
across hierarchy levels (Figures 3a and 3b). These numbers were
rathersimilaracrosshierarchylevels.Overall,thenumberofblocks
and connections in each hierarchy level were small, as denoted by
the small median value.ts a o100101102103104Blocks
(a)ts a o100101102103104Connections
(b)ts a o24681012Hierarchy depth
(c)ts a o100105Simulation duration (sec)
(d)
Figure 2: Collected public models: Total blocks (a), connec-
tions (b), maximum hierarchy depth (c), and requested sim-
ulation duration (d).
3.2.3 Library Participation. This metric identifies the library
each model block comes from. For example, do models mostly
consist of built-in blocks or do they instead contain mostly custom
blocks? If we cannot resolve a block’s library (i.e., due to Matlab
API limitations), we record the block’s library as other.
Figure 4 suggests that only a small portion of the blocks are
custom (“User_Defin”). Across all four groups, Ports & Subsystems
andMathOperations werethetwolibrariesusedmostfrequently.
SLforgethussupportstheselibraries(amongothers,see§4.1.1),and
automatic custom block generation. We also noted a high contribu-
tion from the Signal Routing library using FromandGotoblocks,
which enables establishing hidden data-flow relationship (§2.1).
3.2.4 Requested Simulation Duration. This metric captures the
total simulation time requested by a given model (not the actual
CPU time spent in simulating it). Most of the models (except those
fromtheOthergroup)usedthedefaultsimulationdurationvalue
of 10 seconds (Figure 2d). Consequently, we ran simulations using
this default value in ourexperiments, and have not experimented
with other possible values yet.
4 SLFORGE
To address the shortcomings in the state-of-the-art differential
testingframeworkforCPStoolchains,thissectiondescribesthe
designofSLforge.Figure5givesanoverviewoftheSLforge’sseven
main phases.
4.1 Gathering Semi-Formal Specifications
CyFuzz heavily relies on its Fix Errors phase to repeatedly com-pile and simulate a model and iteratively repair errors based onthe content of Simulink-provided error messages. Instead of thistime-consuming iterative process, SLforge aims at generating a
validmodelinthefirstplace,ifgiventhelanguagespecifications.
Ofcourse,thechallenge(whichmotivatedCyFuzz’siterativepro-
cess)isthatthereexistsnocomplete,uptodate,formalSimulink
specification.
4.1.1 Design Choice. Simulink specifications are available as
informalandsemi-formaldescriptionsofSimulinkbehavior,mainly
984
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. Automatically Finding CPS Tool Chain Bugs With SLforge ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
1234567100102Blocks
(a)
1234567100102Connections
(b)
Figure 3: Collected public models: Blocks (a) and connec-
tions (b) by hierarchy-level, grouped by model group (t, s,a, and o).
fromthevariousSimulinkwebsites.Fromourexperimentswith
CyFuzz, we hypothesized that many of the iterations in the FixErrors phasearedue to block data-type inconsistency and fixing
algebraic loops. Besides, in our CyFuzz experiment (§5.1) the most
frequenterrorwasblock sampletime inconsistency.Wecollected
specificationstobothaddresstheseissuesandtoenablecreating
largehierarchicalmodels(asSimulinkuserspreferthismodeling
choice).
Sofar,wehavecollecteddata-typesupportandblock-parameter
specifications for all built-in libraries. Other language specifica-
tions (§4.2) are often block and library specific. Since collecting
theentireSimulinklanguagespecificationwouldbeoverwhelming,
we collected specifications for blocks from the most-used libraries.
Concretely, SLforge supports blocks from Math Operations ,Ports
andSubsystems ,Discrete,Continuous ,LogicandBitOperations ,Sinks
andSourceslibraries. This list also covers the CyFuzz-supported
libraries and thus helps ease evaluating SLforge.
4.1.2 Collection Process. Usinglittleengineeringeffort,SLforge’s
regular expression based parser parsed block data-type and param-
eterspecificationsforallbuilt-inblocks.However,duetothelim-
itation of the parser and Simulink’s free-form specification style,
SLforge can only collect parts of some specification. E.g., for three
different ports of the Variable Time Delay ,Discrete Filter andDe-
layblocks, the Direct Feed-through property (§2.1) is described
as“Yes,ofthetimedelay(second)input”,“Onlywhentheleading
numeratorcoefficientdoesnotequalzero”and“Yes,whenyouclear
Prevent direct feedthrough” respectively [54].4.2 Use of Semi-Formal Specifications
Since complete and updated formal specifications for Simulink are
not publicly available, existing work relies on a subset of Simulink
operationalspecifications,whicharemanuallycraftedandpossibly
outdated[ 6,24].Unliketheseapproaches,weexploredcollecting
specifications directly from official Simulink documentations auto-
matically,usingeasy-to-engineerparsers.Suchparserscanauto-
matically update the collected specifications when new versions of
theSUTarereleased,giventhestructureofthespecificationsgo
underminorornochange.Fromourexperiencewithrecentver-
sionsofSimulinkspecifications(R2015a-R2017a),thespecifications
SLforge collects indeed had minor structural changes.
Although SLforge parses specifications automatically and stores
them using internal data-structure, for the aid of discussion, we
introduceafewnotionsinthissection.Extendingthenotationof
§2.1,function Tbreturnsablock’sSimulink block-type .Forexample,
foreachSimulink Ifblock,TbreturnsIf.Next,the validpredicate
indicatesiftheSimulinktypecheckerandruntimesystemaccept
a given model as legitimate, i.e., when there are no compile or
run-time exceptions. Now we can express (part of) the Simulink
specificationasaformulaorspecification rule.Givensucharule
δ∈Δ,wedenotewith m/satisfiesδthatmodel msatisfies(i.e.,complies
with)therule.Weobservethatavalidmodelsatisfiesall(collected)
specification rules ( ∀δ∈Δ:valid(m)→m/satisfiesδ).
4.2.1 Select Blocks Phase. To support built-in libraries, SLforge
uses specifications in this phase. Specifically, SLforge-generated
models satisfy the following rules by construction. For example,
using usual set cardinality notation, Eq. (1)ensures that for each If
block,themodelhastwo IfActionsubsystemblocks(oneeachfor
theifandelsebranch).
2∗|{b1∈m.B:Tb(b1)=If}|
=|{b2∈m.B:Tb(b2)=IfA ction }|(1)
ByparsingSimulinkdocumentation,SLforgeobtainsaset Sof
blocks from the SinksandSourcelibraries that are only valid in the
top-level model, as enforced by Eq. (2). Similarly, Eq. (3)restricts
using illegitimate blocks in non-top-level models, depending onthe hierarchy-type property of the model (§2.1), using predicate
supports. The predicate holds only when model mi’s hierarchy-
type (first argument) allows block binmi, based on b’s block-type
(second argument).
∀b∈mi.B:(i>1)→(Tb(b)/nelementS) (2)
∀b∈mi.B:(i>1)→supports(Th(mi),Tb(b)) (3)
∀b∈m.B:((Th(m)∈W)∧stime(b)=stime(driver(m)))
∨(Th(m)/nelementW∧st(Tb(b),b)) (4)
Eq.(4)configureseachblock’ssampletimeproperty stime.When
used in hierarchical model mof aW-listed hierarchy-type, block
b’ssampletimeshouldmatchthesampletimeofthemodel’sdriver
(§2.1).Inallothercases,weusepredicate st,whichholdsonlywhen
the sample time property of block bis properly configured accord-
ing to its block-type. To enforce such rules, SLforge propagates
information from parent to child models.
985
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Chowdhury, Mohian, Mehra, Gawsane, Johnson, Csallner
Additio Continu Discont Discret Lo gicAn Looku pT MathO pe Others Ports_S Si gnalA Si gnalR Sinks Sources User_De020406080100 Blocks (%)
Figure 4: Collected public models: Distribution of blocks across libraries (shortened to the first 7 letters), each from left to
right: Tutorial, Simple, Advanced, and Other.
Figure5:OverviewofSLforge’smainphases.Forspace,wemergedCyFuzz’slasttwophasesintothesingle Comparison phase.
4.2.2 Pre-connection and Connect Ports Phases. While CyFuzz
uses a random search to connect unconnected ports and relies
onlaterphasestorecoverfromillegalconnections,SLforgeadds
connections correctly by construction, by satisfying the following
rules.
∀c∈m.C:(Tb(c.bt)=IfA ction)∧(c.pt=0)→(Tb(c.bs)=If)
(5)
∀c∈m.C:(Tb(c.bs)=If)→(Tb(c.bt)=IfA ction)∧(c.pt=0)
∧|{c2∈m.C:c2.bs=c.bs∧c2.ps=c.ps}|=1
(6)
Eq.(5)and Eq.(6)together specify the control-flow from an If
block to its If Actionblocks. Specifically, each Ifblock output port
is connected to a single (Eq. (6)) If ActionblockActionport.
4.2.3 Analyze Model Phase. Onthecurrentmodelstate,SLforge
now removes algebraic loops and assigns data-types. Instead of
querying a disjoint-set data structure every time SLforge connects
twoblockstodetectwhetherconnectingthemwillcreateacycle,
we detect them later in this phase using a single graph traversal re-
move_algebraic_loops (Listing1)oneachofthechildmodelsandon
the top-level model. In contrast, CyFuzz relies on Simulink built-in
functionstofixalgebraicloops;SLforgediscoveredapreviouslyun-
known Simulink bug in these features (§5.3.1). Specifically, SLforge
identifies back-edges andinterruptsthem with Delayblocks[13].
Since this process changes m, SLforge ensures that the model re-
mains valid. For example, to ensure that the model satisfies the
rulesinEq. (5)andEq.(6),insteadofplacinga Delayblockbetween
anIfand anIf Actionblock, Listing 1 places it before the Ifblock.
Listing 1: Removing possible algebraic loops from a model.
color(b) denotes a block’s visit-status via do_dfs method:
white=unvisited; gray and black: visited.
method remove_algebraic_loops ( m):F= new set /∗ stores problematic blocks ∗/
for each block b∈m.B: set WHITE as color(b)
for each block b∈m.B:
ifcolor(b)= WHITE: do_dfs( m,b,F)
for each block binF:
s:= get aﬀected source block for b
get and remove aﬀected connection between sandb
d/prime:= add new Delay block in m
connect from stod/primeand from d/primetob
method do_dfs( m,b,F):
set GRAY as color(b)
for each connection c∈m.Cwherec.bs=b:
ifcolor(c.bt)= WHITE: do_dfs( m,c.bt,F)
else ifcolor(c.bt)= GRAY:
ifc.pt=0: addbinFelse: add c.btinF
set BLACK as color(b)
After removing possible algebraic loops, SLforge propagates
data-typeinformation,toeliminatedata-typemismatches.While
CyFuzzcompiledamodelwithSimulinkrepeatedlyintheFixEr-
rorsphasetoidentifydata-typeinconsistenciesbetweenconnected
blocks,SLforgefixessucherrorsinlineartimeusingasinglegraph
traversal.
Specifically, SLforge places every block whose output data-type
isinitiallyknown(Non-DirectFeed-throughandblocksfrom Source
library)inasetandstartingfromthem,runsadepth-firstsearch
onthegraph-representationofthemodel.Data-typeinformationis
then propagated to other blocks along the connections from blocks
with known output data types, using forward propagation. E.g.,
considerconnection c∈m.Candsaywearecurrentlyvisitingblock
c.bsinthedepth-firstsearch.Ifthedata-typeat c.psisnotsupported
986
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. Automatically Finding CPS Tool Chain Bugs With SLforge ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
byc.ptasperspecification,weadda Data-typeConversion block
between the ports.
4.3 EMI-testing
AsrecentworksuggeststhatEMI-testingispromisingforcompiler
testing[30],weexploredthisdirectionforSimulink.EMI-testing
forSimulinkcouldtakemanyforms.Forexample,onecouldextend
amodelwithblocksandconnectionsthatremaindeadunderthe
existinginputs.Asanotherexample,onecouldstaticallyremove
some of the dead blocks.
In this work we infer an EMI-variant from a given randomly
generated model, by removing all blocks that are dead. We ap-
proximatethesetofdeadblocksstatically,usingSimulink’s block
reduction feature [54]. This approach differs from the original EMI
implementation([ 30])inthesensethatwecollectthedead-blockin-
formationstatically,while[ 30]dynamicallycollectedcodecoverage
information.Wechosethestaticapproachasitrequiredminimal
engineering effort.
Inourexperiments,wenotedthatCyFuzzconnectsalloutput
portstocertain Sinkblocks.Thegoalwastoguaranteeallblocks’
participationduringsimulation,whichallowedtouseSimulink’s
Signal Logging feature to record every block’s outputs. Conse-
quently, CyFuzz-generated models do not have many staticallydead blocks. To let EMI-testing remove larger parts of the gener-
ated model, SLforge leaves random output ports unconnected.
4.4 Classification of Bugs
SLforge automatically detects Simulink crash or unresponsiveness
(which we categorize as Hang/Crash Error ) and only reports if it is
reproducibleusingthe samemodel.Besidescrash,wediscussthe
types of bugs in following two directions:
4.4.1 Compile Time vs. Runtime. SLforge discovers some bugs
during(orbefore)compilingthemodel;wecategorizetheseas Com-
pile Time bugs. In the event of compilation error, SLforge reports a
bugiftheerrorisnotexpected.Forexample,SLforgeexpectsno
data-typeinconsistencyerrorwhengeneratingtype-safemodels.
SLforgedetectssomespecification-mismatchbugsevenbeforecom-
piling, since we call various Simulink APIs to construct a model
before compiling it. During this process, SLforge reports a bug
when Simulink prevents it from setting a valid block parameter
(according to the specification). Lastly, SLforge detects bugs when
simulating the model — which we categorize as Runtimebugs.
4.4.2 Essential Feature. Herewediscussbugsbasedonthe es-
sentialgenerator/differentialtestingfeaturethathelpeddiscovering
them. We attribute Hierarchy to a bug if SLforge can reproduce the
bugonlybycreatinghierarchicalmodels.Next,intuitively,SLforge
attributes Specification toabugwhenitidentifiesSimulinkspecifica-
tionmismatches.Finally,likeCyFuzz,SLforgeidentifies Comparison
bugsbysimulatingamodelvaryingSUToptions(§2.2).Asaspe-
cial case,SLforge attributes EMIto abug if someEMI-variant ofa
successfullysimulatedmodeldoesnotcompile,orresultsincom-
parison error when after-simulation signal data of the EMI-variant
is compared with the original model or with other EMI-variants.0 500 100005001000Runtime (se c
(a)0 500 100001020Num. Iter
(b)
Figure 6: Runtime on valid models by model size given in
blocks: (a) Average runtime of model generation; (b) Av-erage number of required iterative fixes. Solid = SLforge;dashed = SLforge without specification usage and analyses;dotted = CyFuzz.
5 EVALUATION
In this section we pose and explore the following relevant research
questions.
RQ1Can SLforge generate models systematically and effi-
ciently in contrast to CyFuzz?
RQ2Can SLforge generate feature-rich, hierarchical models
in contrast to CyFuzz?
RQ3Can SLforge effectively test Simulink to find bugs in the
popular development tool chain?
Toanswertheseresearchquestions,weimplementedSLforgeon
topoftheopen-sourceCyFuzzimplementation.Intheevaluation,
weranSLforgeon64-bitUbuntu16.04virtualmachines(VM),of
4 GB RAM and 4 processor cores each. We have used two identical
host machines (Intel i74790 CPU (8 cores) at 3.60 GHz; 32 GB RAM
each). When measuring runtime and other performance metrics
(RQ1), we ran SLforge on each of the otherwise idle host machines
(one VM per host). To find bugs (RQ3) we ran up to five VMs on
each of these two hosts.
5.1 SLforge Generates Models More
Systematically and Efficiently (RQ1)
TocompareSLforge’snewphaseswithCyFuzzintermsofefficiency
andbug-findingcapabilities,weconductedthreeexperiments,each
generating 160 models. To compare with CyFuzz, the experiments
usedblocksfromfouroftheCyFuzz-supportedlibraries(i.e. Sources,
Sinks,Discrete, andConstant). In the first two experiments we used
SLforge:(1)enablingspecificationusageandanalysesin Exp.S+and
(2) disabling them in Exp.S-, and (3) in the third experiment Exp.CF
we used CyFuzz. Across these three experiments we kept the other
generatorconfigurationparametersconstant.Astime-outwechose
1,200 seconds.
We compared the average time taken to generate a valid model
(i.e.,fromSelectBlockstoFixErrors,inclusively).Wealsomeasured
thenumberofiterativemodel-correctionsteps( Num.Iter. )intheFix
Errorsphase.HoweverthismetricwasnotavailableinExp.CF.In
eachoftheseexperimentswestartedwithgenerating100blocks(on
average)permodel,andgraduallyincreasedtheaveragenumberof
blocks(by100ineachstep,using20modelsineachstep),upto800blocks/modelonaverage.Toapproximatethebug-findingcapability
of these three setups, we counted the total number of unique bugs
987
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Chowdhury, Mohian, Mehra, Gawsane, Johnson, Csallner
found in each of these experiments. Data in Both SLforge versions
had a lower average runtime than CyFuzz (Figure 6a).
As the number of blocks increases, Exp.S- needs more time than
Exp.S+togenerateSuccessmodels.WhenweconfiguredCyFuzzto
generatemodelshaving700(ormore)blocksonaverage,itfailed
to generate any valid models.
Similarly, SLforge needs fewer iterations in the Fix Errors phase
(Figure6b)inExp.S+.Moreover,thisvalueremainsalmostconstant
inExp.S+.However,perhapsnotsurprisingly,thenumberincreases
with the number of blocks in Exp.S-. This result indicates that
SLforge generates models more systematically as it reduces the
dynamic error-correction steps significantly.
Next,weexaminehowthechangesinSLforgeaffectthetool’s
bug-finding capability. The total number of unique bugs found
in Exp.S+, Exp.S- and Exp.CF are 4, 1, and 0, respectively. Exp.S+
foundthesamebugdiscoveredinExp.S-,andfound3morebugs.
Whileinvestigating,weobservedthathavingspecificationsenabled
SLforgefindingthosebugs,sincewithoutthespecifications,SLforge
could not determine whether it should report a bug given an error
message returned by Simulink. As an example, consider compiling
amodelwithSimulink whichresultsinadata-typeinconsistency
errorbetweentwoblocksinthemodel.Leveragingthedata-type
support specificationsof the two blocks,SLforge can report abug
whenitdoesnotexpectanydata-typeinconsistencybetweenthe
blocks.
Finally, a crucial step to efficiently generate large hierarchical
modelsistoeliminatethealgebraicloopsfromthem.SimulinkalsorejectssimulatingsomemodelsinAcceleratormodeinthepresence
ofalgebraicloops,whichpreventsdifferentialtestingusingthose
model. As discussed before, CyFuzz depends on Simulink’s buggy
APIstoremovesuchloops,whereasSLforgeeliminatestheloops
in the Analyze Model phase.
5.2 SLforge Generates Large, Feature-rich
Models (RQ2)
InthisexperimentwecomparevariouspropertiesoftheSLforge-
generated models to the models used in our study of public models
(excluding the Simple models), and to CyFuzz-generated models.
First, to compare SLforge with CyFuzz, we configured SLforge
and CyFuzz to generate models with hierarchy depth 7, as this
value is slightly larger than the median values for all model classes.
Fortime-outparameterwechose800secondsandgenerated100
models using each of the tools. CyFuzz’s Success (of generating
validmodels)ratedroppedto2%.WehypothesizethatCyFuzzisnot
capable ofgenerating suchlarge hierarchicalmodels andreduced
the maximum hierarchy depth to 3. After generating 100 models inthis configuration, CyFuzz achieved a 12% Success rate. In contrast,
SLforge achieved a 90% success-rate with 7 depth.
Inthisexperiment,SLforgegeneratedmodelswithanaverage
of 2,152 blocks (median: 1,776), an average of 2,544 connections
(median: 2,107), and an average hierarchy depth of 7 (median: 7).
Both the averageand median values of these propertiesare larger
than(butstillwithinthesameorderofmagnitudeas)thevalueswe
observed in the collected public models. SLforge-generated models
are in this sense similar to the collected public models.
Figure7:BugTSC-02472993:The Modelblock(top)refersto
thechildmodel(bottom).Simulinkfailstohandleratetran-sition automatically, leading to a runtime failure.
Figure 8: Bug TSC-02386732: While specified to only acceptdoubleinputs, Simulink does not raise a type error for this
PID Controller (2DOF) accepting a uint16.
Figure 9: Bug TSC-02614088: In spite of supporting double
data-type in its dport, block VID issued a data-type consis-
tency as it prefers integer type.
5.3 SLforge Found New Bugs in Simulink (RQ3)
To answer RQ3, SLforge continuously generated models and tested
Simulink for approximately five months. Throughout the exper-
iments, configuration options for SLforge varied and became ap-
plicableonceweimplementedaparticularfeature.Inallofthese
experimentsweusedtheNormalandAcceleratorsimulationmodes
in the comparison framework.
We have reported almost all of the SLforge-suspected bugs to
MathWorksexcepttwocaseswherewehadassociatedthebugtoan
implementation error. For eachof the reported cases,MathWorks
hasindicatedifitconsidersthecaseabug.Forthisworkwemarkareportasa falsepositive ifMathWorksconsidersthecaseanon-bug.
Our rate of false-positive is low: 2/12 reports.
Table 2summarizesall thebugs wehave reported.MathWorks
hasconfirmed10ofourreportedissuesasuniquebugs,ofwhich
8 are new bugs. Following are details of a representative subset
of the confirmed bugs, including SLforge-generated models we
manuallyreducedtofitthespaceandaidbug-reporting.Automated
test-case reduction ispart offuture work.These modelsare freely
available [10].
5.3.1 Hang/Crash Error bug. When generating large hierarchi-
calmodels,wenoticedthatMatlab’s getAlgebraicLoops APIhangs
and makes the entire tool chain unresponsive (TSC-02513701).
988
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. Automatically Finding CPS Tool Chain Bugs With SLforge ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Table 2: SLforge-discovered issues and confirmed Simulink bugs: TSC=Technical Support Case number from MathWorks;
St=statusofbugreport( NB=newbug, KB=knownbug, FP=falsepositive); P=discoverypoint( C=CompileTime, R=Run-
time);F=bugtypebasedonEssentialFeature( A=Hang/CrashError, S=Specification, C=Comparison, H=Hierarchy, E=EMI,
? = not further investigated); Ver= Latest Simulink version affected.
TSC Summary St P F Ver
02382544 Simulink Block parameter specification mismatch ( Constant) NB C S 2015a
02382873 Internal rule cannot choose data-type ( Add) FP C ? 2015a
02386732 Data-type support specification mismatch ( PID Controller (2DOF) ) NB C S 2015a
02472993 Automated rate transition failure (First-order hold ) NB R S, H 2017a
02476742 Block-reduction optimization does not work (Accelerator mode) NB R E, H 2017a02513701 Simulink hangs for large models with hierarchy NB C A, H 2015a02515280 Inconsistent result and ambiguous specification ( SubSystemCount metric); NB C S, H 2017a
02539150 Ambiguous results (selecting connection with multiple destinations) NB C S 2017a
02565622 Limited support in Accelerator mode ( First-order hold ) KB R C, H 2015a
02568029 timerdoes not execute callback as expected FP R ? 2015a
02614088 Undocumented specification ( Variable Integer Delay ) KB C S 2017a
02705290 Incorrect data-type inheritance (multiple blocks) NB C S 2017a
Figure 10: Bug TSC-02515280: For the child model (topright) Simulink’s Verification and Validation toolbox API
calculatesinconsistent SubSystemCount values.MathWorks
ruledtheAPIspecificationambiguous,asitdidnotproperlydefine the API’s scope.
Figure11:IssueTSC-02382873:Whenusingthe internalrule
to detect the Addblock’s output data-type, the rule fails to
chooseacorrectdata-typeforthesecondinputport(e.g. dou-
ble) and throws a compilation error.
5.3.2 Specification bug. After incorporating Simulink specifica-
tions into variousSLforge phases, SLforgestartedto identify bugs
causedbyspecificationviolation.Forexample,bugTSC-02472993
of Figure 7 manifests when Simulink fails to handle blocks oper-
ating at different sample times, leading to runtime failure whichis not expected as per specification. The bug only occurs for theFirst-Order Hold block and when SLforge generates hierarchical
models. As another example, Figure 8 depictsSimulink’s PID Con-
troller(2DOF) blockacceptingdataoftypeunsignedint,whereas
Figure 12: EMI bug TSC-02476742: The Top Model ’s (in bot-
tom right corner) Modelblock is a placeholder for the child
model (top and left), where all blocks except bl11andbl12
are dead.
the specification states that the block only accepts data of type
double (TSC-02386732).
In another case we noted that in spite of supporting type dou-
blein portd, blockVariable Integer Delay (blockVIDin Figure 9)
resulted intype-mismatcherror.After reportingthe issue,Math-
Works suggested that the port “prefers” integer types and thus
issuedatypemismatcherrorwhenitwasgivenadoubletype.This
specification is not publicly available. Lastly, the Figure 10 issue
(TSC-02515280) MathWorks classified as expected behavior, where
Simulink’scountofthenumberof Subsystems didnotmatchour
count. However, part of Simulink’s results are inconsistent and
the specification has been found ambiguous, resulting in a new
confirmed bug.
5.3.3 Comparison bug. In issue TSC-02565622, one Simulink
instancecould simulatethe SLforge-generatedhierarchicalmodel
in Normal mode but returned an error in Accelerator mode, due
to inconsistent block sample rates. MathWorks confirmed this as a
known issue that does not have a public bug report.
5.3.4 EMI bug. Figure12illustratesSimulinkbugTSC-02476742.
Notice how only block bl11 is connected to an Outport block bl12,
henceallremainingchildblocksaredeadandcanberemovedin
EMI-testing. While EMI-testing in Normal mode removed all dead
989
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Chowdhury, Mohian, Mehra, Gawsane, Johnson, Csallner
childnodes,EMI-testinginAcceleratormodefailedtodoso,which
MathWorks classified as a Simulink bug.
6 DISCUSSION
Thispaperperformedthefirstlarge-scalestudyonpubliclyavail-
able Simulink models, to collect and observe various properties
fromthem,whichcanbeutilizedtogeneraterandommodelsand
serve as a collection of curated artifacts. However, some of the
models are quite simple. We endeavored to classify such modelsin the Simple category manually, however, our approach may be
imperfect and may suffer from human error. Opportunistically, we
found complex and large models in our study and consequently,our collection of artifacts should be suitable for other empirical
studies.
7 RELATED WORK
Empirical studies of widely used programs date back at least to
the 1970s [ 29] and have gained increasing interest due to the wide
availabilityofopensourceprograms[ 52].Forexample,earlierwork
computed properties from Java programs [ 12,22,59] and used the
properties to guide a random Java program generator [26].
Temperoetal.presentedthe qualitascorpus —acuratedcollection
of Java programs [ 52]. Although similar work has been performed
in other domains [ 9,35,51], we are not aware of related work in
the CPS domain, which differs significantly from procedural or
object-oriented languages.
Recent studies introduced measures for Simulink model mod-
ularity [15] and complexity [ 39], but only evaluated them on a
limitednumberofmodels.Incontrastwecreatedalargercollection
of391Simulinkmodels.Similarto[ 52],ourmodelcollectionmay
serve as a corpus for Simulink-model based empirical studies.
Recentworkhasfoundmanycompilerbugsusingdifferential
testing. To generate programs that are syntactically correct, many
ofthetestgeneratorsharnessthelanguage’scontext-freegrammar
andapre-determinedprobabilitytablefromwhichthegenerator
chooses grammar elements [ 17,25]. To generate programs that are
also well-typed, McKeeman imposes the type information directly
onto thestochastic grammar the generator uses [34].
Csmith, on the other hand, uses various analysis and runtime
checks to generate programs with no undefined behavior [ 58].
Other techniques generate well-typed programs using knowledge
of the type-system of the underlying language (e.g., JCrasher for
Java [14]) and using constraint-logic programming (such as the
Rust typechecker fuzzer [17]).
Whereasearlierapproachestargetcompilersoftextuallanguages
(includingprocedural,object-oriented,andfunctionalones),theydo
not address the challenges inherent in testing CPS tool chains [ 11].
CyFuzz pioneered differential testing of CPS tool chains, but the
prototypeforSimulinkwasineffectiveinfindingnewbugs.This
work addresses CyFuzz’s limitations by incorporating informal
Simulink specifications in the random model generation process
andgeneratinglargermodelswithrichlanguagefeatures,which
led to finding new bugs.
Recent work complements randomized differential testing via
EMI-testing. For example, Le et al. hammer C language compil-
ers[30].WeharnessthetechniquetocreateEMI-variantsofSimulinkmodels for the first time. Other work discusses the effectiveness
ofrandomizeddifferentialtestingandEMIforOpenCLcompilers
and performs a comprehensiveempirical compilertesting evalua-
tion [8, 31].
Amongotherworks,Nguyenetal.presentaruntimeverification
framework for CPS model analysis tools leveraging random hybrid
automatageneration[ 37,38].Incontrast,ourgeneratordoesnot
rely on model transformations [ 4], which may limit the efficiency
ofexistingwork[ 38].OthertestingschemestargetpartsoftheCPS
toolchainutilizinggraphgrammars[ 49,50].However,complete
and updated formal specifications for most commercial CPS devel-
opmenttoolsareunavailableandsuchwhite-boxtestinginparts
was found undesirable [46].
Sampath et al. discuss testing CPS model-processing tools using
semantic Stateflow meta-models [ 46]. Unfortunately, the approach
does not scale and updated specifications are unavailable, due to
therapidreleasecyclesofcommercialCPStools[ 17,49].Fehéret
al. model the data-type inferencing logic of Simulink blocks for
reasoningandexperimentalpurposes[ 19].Whiletheseworksfocus
onasmallpartoftheentireCPStoolchain,wedifferentially-test
the entire CPS tool chain harnessing the available informal (but
updated) specifications.
SLforge is loosely related to test case generators for existing
Simulinkmodels[ 7,18,20,21,33,36,48]andverificationandformal
analysis of CPS models [ 2,3,28,32,47,60]. But they do not aim at
finding bugs in the Simulink tool chain.
8 CONCLUSIONS
This paper described the first large collection of public Simulink
models and used the collected models’ properties to guide random
model generation. To further guide model generation we systemat-
ically collected semi-formal Simulink specifications. In our experi-
mentsonseveralhundredmodels,theresultingrandomSimulink
model generator SLforge was more effective and efficient than the
state-of-the-arttoolCyFuzz.SLforgealsofound8newconfirmed
bugs in Simulink.
ACKNOWLEDGMENTS
Thematerialpresentedinthispaperisbaseduponworksupported
by the National Science Foundation (NSF) under grant numbers
CNS 1464311, CNS 1713253, EPCN 1509804, SHF 1527398, and SHF
1736323, the Air Force Research Laboratory (AFRL) through the
AFRL’s Visiting Faculty Research Program (VFRP) under contract
number FA8750-13-2-0115, as well as contract numbers FA8750-
15-1-0105, and FA8650-12-3-7255 via subcontract number WBSC
7255SOIVU0001,andtheAirForceOfficeofScientificResearch
(AFOSR) through AFOSR’s Summer Faculty Fellowship Program
(SFFP) under contract number FA9550-15-F-0001, as well as under
contractnumbersFA9550-15-1-0258andFA9550-16-1-0246.TheU.S.
governmentis authorizedtoreproduce anddistribute reprintsfor
Governmentalpurposesnotwithstandinganycopyrightnotation
thereon. Any opinions, findings, and conclusions or recommenda-
tions expressed in this publication are those of the authors and do
not necessarily reflect the views of AFRL, AFOSR, or NSF.
990
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. Automatically Finding CPS Tool Chain Bugs With SLforge ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]H. Alemzadeh, R. K. Iyer, Z. Kalbarczyk, and J. Raman. 2013. Analysis of Safety-
Critical Computer Failures in Medical Devices. IEEE Security Privacy 11, 4 (July
2013), 14–26. https://doi.org/10.1109/MSP.2013.49
[2]RajeevAlur.2011.Formalverificationofhybridsystems.In Proc.11thInternational
ConferenceonEmbeddedSoftware,(EMSOFT)2011 .ACM,273–278. https://doi.
org/10.1145/2038642.2038685
[3]Rajeev Alur, Aditya Kanade, S. Ramesh, and K. C. Shashidhar. 2008. Symbolicanalysis for improving simulation coverage of Simulink/Stateflow models. In
Proc. 8th ACM & IEEE International Conference on Embedded Software (EMSOFT) .
ACM, 89–98. https://doi.org/10.1145/1450058.1450071
[4]StanleyBak,SergiyBogomolov,andTaylorT.Johnson.2015. HYST:ASource
TransformationandTranslationToolforHybridAutomatonModels.In Proc.18th
International Conference on Hybrid Systems: Computation and Control (HSCC) .
ACM, 128–133.
[5]BorisBeizer.1990. Softwaretestingtechniques (seconded.). VanNostrandRein-
hold.
[6]Olivier Bouissou and Alexandre Chapoutot. 2012. An Operational Semantics for
Simulink’s Simulation Engine. In Proc. 13th ACM SIGPLAN/SIGBED International
Conference on Languages, Compilers, Tools and Theory for Embedded Systems
(LCTES). ACM, 129–138. https://doi.org/10.1145/2248418.2248437
[7]Angelo Brillout, Nannan He, Michele Mazzucchi, Daniel Kroening, Mitra Puran-
dare, Philipp Rümmer, and Georg Weissenbacher. 2009. Mutation-Based Test
Case Generation for Simulink Models. In 8th International Symposium on Formal
Methods for Components and Objects (FMCO) . Springer, 208–227.
[8]Junjie Chen, Wenxiang Hu, Dan Hao, Yingfei Xiong,Hongyu Zhang, Lu Zhang,
andBingXie.2016. AnEmpiricalComparisonofCompilerTestingTechniques.In
Proc.38thInternationalConferenceonSoftwareEngineering(ICSE) .ACM,180–190.
[9]R.J.ChevanceandT.Heidet.1978. StaticProfileandDynamicBehaviorofCobol
Programs. SIGPLAN Not. 13, 4 (April 1978), 44–57.
[10]ShafiulAzamChowdhury.2018. ProjectHomepage. https://github.com/verivital/
slsf_randgen/wiki. (2018). Accessed Feb 2018.
[11]Shafiul Azam Chowdhury, Taylor T. Johnson, and Christoph Csallner. 2016.
CyFuzz:Adifferentialtestingframeworkforcyber-physicalsystemsdevelopmentenvironments.In Proc.6thWorkshoponDesign,ModelingandEvaluationofCyber
PhysicalSystems(CyPhy) .Springer. https://doi.org/10.1007/978-3-319-51738-4_4
[12]Christian S. Collberg, Ginger Myles, and Michael Stepp. 2007. An empirical
study of Java bytecode programs. Softw., Pract. Exper. 37, 6 (2007), 581–641.
https://doi.org/10.1002/spe.776
[13]T.H. Cormen, C.E. Leiserson, R.L. Rivest, and C. Stein. 2001. Introduction To
Algorithms . MIT Press.
[14]Christoph Csallner and Yannis Smaragdakis. 2004. JCrasher: An automaticrobustness tester for Java. Software—Practice & Experience 34, 11 (Sept. 2004),
1025–1050. https://doi.org/10.1002/spe.602
[15]Yanja Dajsuren, Mark G.J. van den Brand, Alexander Serebrenik, and Serguei
Roubtsov. 2013. Simulink Models Are Also Software: Modularity Assessment. In
Proc. 9th International ACM SIGSOFT Conference on Quality of Software Architec-
tures (QoSA) . ACM, 99–106.
[16]Florian Deissenboeck, Benjamin Hummel, Elmar Juergens, Michael Pfaehler,and Bernhard Schaetz. 2010. Model Clone Detection in Practice. In Proc. 4th
International Workshop on Software Clones (IWSC) . ACM, 57–64.
[17]Kyle Dewey, Jared Roesch, and Ben Hardekopf. 2015. Fuzzing the Rust Type-
checkerUsingCLP.In Proc.30thIEEE/ACMInternationalConferenceonAutomated
Software Engineering (ASE) . IEEE, 482–493. https://doi.org/10.1109/ASE.2015.65
[18]V. D’Silva, D. Kroening, and G. Weissenbacher. 2008. A Survey of Automated
Techniques for Formal Software Verification. IEEE Transactions on Computer-
Aided Design of Integrated Circuits and Systems 27, 7 (July 2008), 1165–1178.
https://doi.org/10.1109/TCAD.2008.923410
[19]P. Fehér, T. Mészáros, L. Lengyel, and P. J. Mosterman. 2013. Data Type Prop-agation in Simulink Models with Graph Transformation. In Proc. 3rd Eastern
European Regional Conference on the Engineering of Computer Based Systems .
127–137. https://doi.org/10.1109/ECBS-EERC.2013.24
[20]K. Ghani, J. A. Clark, and Y. Zhan. 2009. Comparing algorithms for search-
based test data generation of Matlab Simulink models. In Proc. IEEE Congress on
Evolutionary Computation . 2940–2947.
[21]Antoine Girard, A. Agung Julius, and George J. Pappas. 2008. Approximate
Simulation Relations for Hybrid Systems. Discrete Event Dynamic Systems 18, 2
(2008), 163–179. https://doi.org/10.1007/s10626-007-0029-9
[22]Mark Grechanik, Collin McMillan, Luca DeFerrari, Marco Comi, Stefano Crespi,
Denys Poshyvanyk, Chen Fu, Qing Xie, and Carlo Ghezzi. 2010. An Empiri-
calInvestigationintoaLarge-scaleJavaOpenSourceCodeRepository.In Proc.
ACM/IEEE International Symposium on Empirical Software Engineering and Mea-
surement (ESEM) . ACM, 11:1–11:10.
[23]C. Guger, A. Schlogl, C. Neuper, D. Walterspacher, T. Strein, and G. Pfurtscheller.
2001. RapidprototypingofanEEG-basedbrain-computerinterface(BCI). IEEE
Transactions on Neural Systems and Rehabilitation Engineering 9, 1 (March 2001),
49–58.[24]GrégoireHamonandJohnRushby.2007. AnoperationalsemanticsforStateflow.
InternationalJournalonSoftwareToolsforTechnologyTransfer 9,5(2007),447–456.
https://doi.org/10.1007/s10009-007-0049-7
[25]Christian Holler, Kim Herzig, and Andreas Zeller. 2012. Fuzzing with Code
Fragments. In Proc. 21th USENIX Security Symposium . USENIX Association, 445–
458. https://www.usenix.org/conference/usenixsecurity12/technical-sessions/
presentation/holler
[26]IshtiaqueHussain,ChristophCsallner,MarkGrechanik,QingXie,SangminPark,
Kunal Taneja, and B.M. Mainul Hossain. 2016. RUGRAT: Evaluating program
analysisandtestingtoolsandcompilerswithlargegeneratedrandombenchmark
applications. Software—Practice & Experience 46, 3 (March 2016), 405–431.
[27]Xiaoqing Jin, Jyotirmoy V. Deshmukh, James Kapinski, Koichi Ueda, and Ken
Butts.2017. BenchmarksforModelTransformationsandConformanceChecking.
https://cps-vo.org/node/12108. (2017). Accessed Feb 2018.
[28]AdityaKanade,RajeevAlur,FranjoIvancic,S.Ramesh,SriramSankaranarayanan,
and K. C. Shashidhar. 2009. Generating and Analyzing Symbolic Tracesof Simulink/Stateflow Models. In Proc. 21st International Conference on Com-
puter Aided Verification (CAV) . Springer, 430–445. https://doi.org/10.1007/
978-3-642-02658-4_33
[29]DonaldE.Knuth.1971. AnEmpiricalStudyofFORTRANPrograms. Softw.,Pract.
Exper.1, 2 (1971), 105–133.
[30]Vu Le, Mehrdad Afshari, and Zhendong Su. 2014. Compiler validation via equiv-
alencemoduloinputs.In Proc.ACMSIGPLANConferenceonProgrammingLan-
guage Design and Implementation (PLDI) . ACM, 216–226.
[31]ChristopherLidbury,AndreiLascu,NathanChong,andAlastairF.Donaldson.
2015. Many-coreCompilerFuzzing.In Proc.36thACMSIGPLANConferenceon
Programming Language Design and Implementation (PLDI) . ACM, 65–76.
[32]B.Liu,Lucia,S.Nejati,andL.C.Briand.2017. Improvingfaultlocalizationfor
Simulink models using search-based testing and prediction models. In Proc. 24th
IEEE International Conference on Software Analysis, Evolution and Reengineering
(SANER). 359–370.
[33]Reza Matinnejad, Shiva Nejati, Lionel C. Briand, and Thomas Bruckmann. 2016.
SimCoTest: A test suite generation tool for Simulink/Stateflow controllers. In
Proc.38thInternationalConferenceonSoftwareEngineering,(ICSE) .ACM,585–588.
https://doi.org/10.1145/2889160.2889162
[34]William M. McKeeman. 1998. Differential Testing for Software. Digital Technical
Journal10, 1 (1998), 100–107. http://www.hpl.hp.com/hpjournal/dtj/vol10num1/
vol10num1art9.pdf
[35]Barton P. Miller, Louis Fredriksen, and Bryan So. 1990. An Empirical Studyof the Reliability of Unix Utilities. Commun. ACM 33, 12 (Dec. 1990), 32–44.
https://doi.org/10.1145/96267.96279
[36]M. Mohaqeqi and M. R. Mousavi. 2016. Sound Test-Suites for Cyber-Physical
Systems. In 10th International Symposium on Theoretical Aspects of Software
Engineering (TASE) . 42–48. https://doi.org/10.1109/TASE.2016.33
[37]Luan Viet Nguyen, Khaza Hoque, Stanley Bak, Steven Drager, and Taylor T.
Johnson. 2018. Cyber-Physical Specification Mismatches. ACM Transactions on
Cyber-PhysicalSystems(<ahref="http://www.acm.org/TCPS/">TCPS</a>) (2018).
[38]LuanVietNguyen,ChristianSchilling,SergiyBogomolov,andTaylorT.Johnson.
2015. Runtime Verification of Model-based Development Environments. In Proc.
15th International Conference on Runtime Verification (RV) .
[39]MartaOlszewska,YanjaDajsuren,HaraldAltinger,AlexanderSerebrenik,Ma-
rinaA.Waldén,andMarkG.J.vandenBrand.2016. Tailoringcomplexitymetrics
for Simulink models. In Proc. 10th European Conference on Software Architecture
Workshops . 5. http://dl.acm.org/citation.cfm?id=3004853
[40]Vera Pantelic, Steven Postma, Mark Lawford, Monika Jaskolka, Bennett Macken-
zie, Alexandre Korobkine, Marc Bender, Jeff Ong, Gordon Marks, and Alan
Wassyng. 2017. Software engineering practices and Simulink: bridging the
gap.International Journal on Software Tools for Technology Transfer (2017), 1–23.
https://doi.org/10.1007/s10009-017-0450-9
[41]N.H.Pham,H.A.Nguyen,T.T.Nguyen,J.M.Al-Kofahi,andT.N.Nguyen.2009.
Complete and accurate clone detection in graph-based models. In Proc. 31st IEEE
International Conference on Software Engineering (ICSE) . 276–286.
[42]Pierre Giroux. 2018. Grid-Connected PV Array - File Exchange -Matlab Central. http://www.mathworks.com/matlabcentral/fileexchange/
34752-grid-connected-pv-array. (Feb. 2018). Accessed Feb 2018.
[43]A.C.Rajeev,PrahladavaradanSampath,K.C.Shashidhar,andS.Ramesh.2010.
CoGenTe:Atoolforcodegeneratortesting.In Proc.25thIEEE/ACMInternational
Conference on Automated Software Engineering (ASE) . ACM, 349–350. https:
//doi.org/10.1145/1858996.1859070
[44]Steven Rasmussen, Jason Mitchell, Chris Schulz, Corey Schumacher, and Phillip
Chandler. [n.d.]. A multiple UAV simulation forresearchers. In AIAA Modeling
and Simulation Technologies Conference and Exhibit . 5684.
[45]Jesse Ruderman. 2007. Introducing jsfunfuzz. https://www.squarefree.com/2007/
08/02/introducing-jsfunfuzz/. (2007). Accessed Feb 2018.
[46]PrahladavaradanSampath,A.C.Rajeev,S.Ramesh,andK.C.Shashidhar.2007.
Testing Model-ProcessingTools for Embedded Systems.In Proc. 13th IEEEReal-
Time and Embedded Technology and Applications Symposium . IEEE, 203–214.
https://doi.org/10.1109/RTAS.2007.39
991
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Chowdhury, Mohian, Mehra, Gawsane, Johnson, Csallner
[47]S.Sims,R.Cleaveland,K.Butts,andS.Ranville.2001. Automatedvalidationof
software models. In Proc. 16th Annual International Conference on Automated
Software Engineering (ASE) . 91–96. https://doi.org/10.1109/ASE.2001.989794
[48]A. Sridhar, D. Srinivasulu, and D. P. Mohapatra. 2013. Model-based test-casegeneration for Simulink/Stateflow using dependency graph approach. In Proc.
3rd IEEE International Advance Computing Conference (IACC) . 1414–1419. https:
//doi.org/10.1109/IAdCC.2013.6514434
[49]IngoStürmerandMirkoConrad.2003. Testsuitedesignforcodegenerationtools.
InProc.18thIEEEInternationalConferenceonAutomatedSoftwareEngineering
(ASE). 286–290. https://doi.org/10.1109/ASE.2003.1240322
[50]IngoStürmer,MirkoConrad,HeikoDörr,andPeterPepper.2007. SystematicTest-
ing of Model-Based Code Generators. IEEE Transactions on Software Engineering
(TSE)33, 9 (Sept. 2007), 622–634. https://doi.org/10.1109/TSE.2007.70708
[51]Giancarlo Succi, Witold Pedrycz, Snezana Djokic, Paolo Zuliani, and BarbaraRusso. 2005. An Empirical Exploration of the Distributions of the Chidamber
andKemererObject-OrientedMetricsSuite. EmpiricalSoftwareEngineering 10,1
(2005), 81–104.
[52]E.Tempero,C.Anslow,J.Dietrich,T.Han,J.Li,M.Lumpe,H.Melton,andJ.Noble.
2010. The Qualitas Corpus: A Curated Collection of Java Code for Empirical
Studies. In 2010 Asia Pacific Software Engineering Conference . 336–345.
[53]The MathWorks Inc. 2018. NASA HL-20 Lifting Body Airframe
- Matlab & Simulink. https://www.mathworks.com/help/aeroblks/
nasa-hl-20-lifting-body-airframe.html. (2018). Accessed Feb 2018.[54]TheMathWorksInc.2018. SimulinkDocumentation. http://www.mathworks.
com/help/simulink/. (2018). Accessed Feb 2018.
[55]U.S. Consumer Product Safety Commission (CPSC). 2010. Recall 11-702:Fire Alarm Control Panels Recalled by Fire-Lite Alarms Due to Alert Fail-
ure. http://www.cpsc.gov/en/Recalls/2011/Fire-Alarm-Control-Panels-Recalled-
by-Fire-Lite-Alarms-Due-to-Alert-Failure. (Oct. 2010). Accessed Feb 2018.
[56]U.S.NationalHighwayTrafficSafetyAdministration(NHTSA).2014.DefectInfor-
mation Report 14V-053. http://www-odi.nhtsa.dot.gov/acms/cs/jaxrs/download/
doc/UCM450071/RCDNN-14V053-0945.pdf. (Feb. 2014).
[57]U.S. National Institute of Standards and Technology (NIST). 2002. The economic
impacts of inadequate infrastructure for software testing: Planning report 02-3.
(May 2002).
[58]Xuejun Yang, Yang Chen, Eric Eide, and John Regehr. 2011. Finding andunderstanding bugs in C compilers. In Proc. 32nd ACM SIGPLAN Conference
on Programming Language Design and Implementation (PLDI) . ACM, 283–294.
https://doi.org/10.1145/1993498.1993532
[59]HongyuZhangandHeeBengKuanTan.2007. AnEmpiricalStudyofClassSizesforLargeJavaSystems.In Proc.14thAsia-PacificSoftwareEngineeringConference
(APSEC). 230–237.
[60]Liang Zou, Naijun Zhan, Shuling Wang, and Martin Fränzle. 2015. Formal Verifi-
cation of Simulink/Stateflow Diagrams. In Proc. 13th International Symposium
on Automated Technology for Verification and Analysis (ATVA) , Bernd Finkbeiner,
Geguang Pu, and Lijun Zhang (Eds.). Springer, 464–481.
992
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:56:19 UTC from IEEE Xplore.  Restrictions apply. 