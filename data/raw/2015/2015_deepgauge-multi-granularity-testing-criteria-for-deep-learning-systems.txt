DeepGauge: Multi-Granularity Testing Criteria for Deep
Learning Systems
Lei Ma1,3∗, Felix Juefei-Xu2, Fuyuan Zhang3, Jiyuan Sun4, Minhui Xue3,B oL i5
Chunyang Chen6, Ting Su3,L iL i6, Yang Liu3, Jianjun Zhao4, and Yadong Wang1
1HarbinInstituteofTechnology,China2CarnegieMellonUniversity,USA3NanyangTechnologicalUniversity,Singapore
4Kyushu University, Japan5University of Illinois at Urbana–Champaign, USA6Monash University, Australia
ABSTRACT
Deeplearning(DL)definesanewdata-drivenprogrammingpara-
digmthatconstructstheinternalsystemlogicofacraftedneuron
networkthroughasetoftrainingdata.Wehaveseenwideadop-
tionofDLinmanysafety-criticalscenarios.However,aplethora
ofstudieshaveshownthatthestate-of-the-artDLsystemssuffer
fromvariousvulnerabilitieswhichcanleadtosevereconsequences
when applied to real-world applications. Currently, the testing ad-
equacy of a DL system is usually measured by the accuracy of
test data. Considering the limitation of accessible high quality test
data,goodaccuracyperformanceontestdatacanhardlyprovide
confidencetothetestingadequacyandgeneralityofDLsystems.
Unlike traditional software systems that have clear and control-
lable logic and functionality, the lack of interpretability in a DL
system makes system analysis and defect detection difficult, which
couldpotentiallyhinderitsreal-worlddeployment.Inthispaper,
wepropose DeepGauge,asetofmulti-granularitytestingcriteria
for DL systems, which aims at rendering a multi-faceted portrayal
of the testbed. The in-depth evaluation of our proposed testing
criteriaisdemonstratedontwowell-knowndatasets,fiveDLsys-
tems,andwithfourstate-of-the-artadversarialattacktechniques
against DL.The potential usefulness of DeepGauge sheds lighton
the construction of more generic and robust DL systems.
CCS CONCEPTS
•Software and its engineering →Software testing and de-
bugging;•Theory of computation →Adversarial learning ;
KEYWORDS
Deep learning, Software testing, Deep neural networks, Testing
criteria
ACM Reference Format:
LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,Chun-
yang Chen, Ting Su, Li Li, Yang Liu, Jianjun Zhao, and Yadong Wang. 2018.
DeepGauge : Multi-Granularity Testing Criteria for Deep Learning Systems.
∗Lei Ma is the corresponding author. Email: malei@hit.edu.cn.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3238202InProceedings of the 2018 33rd ACM/IEEE International Conference on Au-
tomated Software Engineering (ASE ’18), September 3–7, 2018, Montpellier,
France.ACM,NewYork,NY,USA, 12pages.https://doi.org/10.1145/3238147.
3238202
1 INTRODUCTION
Deeplearning(DL)systemshavegainedgreatpopularityinvarious
applications, e.g.,speechprocessing [ 26], medical diagnostics [ 12],
image processing [ 11], and robotics [ 58]. A deep neural network
(DNN), as a type of deep learning systems, is the key driving force
behind recent success. However, DNN-based software systems,
such as autonomous driving, often exhibit erroneous behaviors
that lead to fatal consequences. For example, several accidents [ 21]
havebeenreportedduetoautonomousvehicle’sfailuretohandle
unexpected/corner-case driving conditions.
One of the trending research areas is to investigate the cause of
vulnerabilityinDLsystemsbymeansofgeneratingadversarialtest
examplesforimage-andvideo-basedDLsystems.Suchcarefully
learned pixel-level perturbations, imperceptible to human eyes,
can cause the DL-based classification system to output completely
wrongdecisionswithhighconfidence[ 20].Eversincetheinception
of adversarial attacks on the DL systems, more and more research
hasbeendedicatedtobuildingupstrongattackers[ 6,25,55,60].As
a consequence, betterdefense mechanisms in DL systemsagainst
adversarialattacksareindireneed.Varioustechniquestonullify
adversarialattacksandtotrainamorerobustDLsystemareemerg-
inginrecentstudies[ 18,23,41,43,45,51,56].Together,research
inbothrealmsformsavirtuouscircleandblazesatrailforbetter
understandingofhowtobuildmoregenericandrobustDLsystems.
However,whatisstilllackingisasystematicwayofgaugingthe
testingadequacyofgivenDLsystems.Currentstudiesfocusonly
on pursuing high accuracy of DL systems as a testing criterion, for
which we show several caveats as follows. First, measuring the
software quality from DL output alone is superficial in the sense
thatfundamentalunderstandingoftheDLinternalneuronactivitiesand network behaviors is not touched upon. We agree that it could
be an indicator of DL system quality and generality, but it is far
fromcomplete,andoftentimesunreliable. Second,acriterionsolely
basedonDLoutputwillrelyheavilyonhowrepresentativethetest
dataare.Havingachievedhigh-performanceDLoutputdoesnot
necessarily mean that the system is utmost generic, and achieving
low-performancedoesnotindicatetheoppositeeither.ADLmodelcanbeimmunetomanyknowntypesofadversarialattacks,butmayfailfromunseenattacks.Thisisbecausesuchacriterionbasedonly
on DL outputs is far from being comprehensive, and it leaves high
risks for currently cocooned DL systems to be deployed in the real-
world environment where newly evolved adversarial attacks are
120
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Ma, Xu, Zhang, Sun, Xue, Li, Chen, Su, Li, Liu, Zhao, and Wang
inescapable. Third,anyDLsystemthatpassessystematictesting
should be able to withstand all types of adversarial attacks to some
extent. Such generality upon various attacks is of vital importance
for DL systems to be deployed. But apparently this is not the case,
unless we stick to a set of more comprehensive gauging criteria.
We understand that even the most comprehensive gauging criteria
wouldnotbeabletoentirelyeliminaterisksfromadversarialattacks.
Nevertheless,byenforcingasuitablesetoftestingcriteria,wehope
thataDLsystemcouldbebettertestedtofacilitatetheconstruction
of a more generic and robust deep learning system.
Towardsaddressingtheaforementionedlimitations, asetoftest-
ing criteria is needed, as opposed to the sole criterion based onDL decision output. In addition to being scalable, the proposed
criteriawillhavetomonitorandgaugetheneuronactivitiesand
intrinsicnetwork connectivityat variousgranularitylevels, sothat
a multi-faceted in-depth portrayal of the DL system and testing
quality measures become desirable.
In this work, we are probing this problem from a software engi-
neeringandsoftwaretestingperspective.Atahighlevel,erroneous
behaviorsappearedinDNNsareanalogoustologicbugsintradi-
tional software. However, these two types of software are funda-
mentally different in their designs. Traditional software represents
itslogicascontrolflowscraftedbyhumanknowledge,whileaDNN
characterizes its behaviors by the weights of neuron edges and the
nonlinear activation functions (determined by the training data).
Therefore,detectingerroneousbehaviorsinDNNsisdifferentfrom
detectingthoseintraditionalsoftwareinnature,whichnecessitates
novel test generation approaches.
To achieve this goal, the very first step is to precisely define
a set of suitable coverage criteria, which can guide test design
and evaluate test quality.Despite a number of criteria existingfor
traditional software, e.g., statement, branch, data-flow coverage,
they completely lose effect in testing DNNs. To the best of our
knowledge,thedesignoftestingcoveragecriteriaforDNNsisstillattheearlystage[
38,47].Withoutacomprehensivesetofcriteria,(1)
designing tests to cover different learned logics and rules of DNNs
isdifficulttoachieve.Consequently,erroneousbehaviorsmaybe
missed;(2)evaluatingtestqualityisbiased,andtheconfidenceof
obtained testing results may be overestimated. In this paper, we
proposeDeepGauge —asetoftestingcriteriabasedonmulti-level
and-granularitycoveragefortestingDNNsandmeasurethetesting
quality. Our contributions are summarized as follows:
•Our proposed criteria facilitate the understanding of DNNs as
well as the test data quality from different levels and angles.
Ingeneral,wefinddefectscouldpotentiallydistributeonboth
major function regions as well as the corner-case regions of
DNNs. Given a set of inputs, our criteria could measure to what
extentitcoversthemainfunctionalityandthecornercasesofthe
neurons,whereDLdefectscouldincur.Ourevaluationresults
revealthattheexistingtestdataofagivenDLingeneralskew
more towards testing the major function region, with relatively
few cases covering the corner-case region.
•In line with existing test data of DNNs, we evaluate the use-
fulnessofourcoveragecriteriaasindicatorstoquantifydefect
detection ability of test data on DNNs, through generating newadversarial test data using 4 well-known adversarial data gener-
ation algorithms (i.e., Fast Gradient Sign Method (FGSM) [ 20],
Basic Iterative Method (BIM) [ 31], Jacobian-based Saliency Map
Attack (JSMA) [ 37] and Carlini/Wagner attack (CW) [ 8]). The
extensive evaluation shows that our criteria can effectively cap-
turethedifferencebetweentheoriginaltestdataandadversarial
examples, where DNNs could and could not correctly recognize,
respectively,demonstratingthatahighercoverageofourcriteriapotentiallyindicatesahigherchancetodetecttheDNN’sdefects.
•The various criteria proposed behave differently on DNNs w.r.t.
networkcomplexityanddatasetunderanalysis.Altogether,thesecriteriacanpotentiallyhelpusgaininsightsoftestingDNNs.Byprovidingtheseinsights,wehopethatbothsoftwareengineering
andmachinelearningcommunitiescanbenefitfromapplying
new criteria for gauging the testing quality of the DNNs to gain
confidence towards constructinggeneric androbust DLsystems.
To the best of our knowledge, this is among the earliest studies
to propose multi-granularity testing criteria for DL systems, which
are mirrored by the test coverage in traditional software testing.
2 PRELIMINARIES
In this section, we first introduce traditional software and then
deeplearningsystemsofwhichthearchitecturalfeaturesappearing
to be a step above current traditional software. We will see thatDL fundamentally changes the software development paradigm.
Precisely,wetrytoanalogizethattheprogramminglanguagelogic
execution to traditional software is what the connectivity strength
(weights) to a DNN. As we will see below, we are attempting to
connectthesetwocounterpartsaswellasdiscussingthedifferences.
2.1 Coverage Criteria in Traditional Software
Testing
Weregardtraditionalsoftwareasanyprogramwritteninhigh-level
programminglanguages(e.g., C/C++,Java,Python).Specially,each
statement in traditional program performs some certain operation
that eithertransforms theoutputs fromthe previousstatement to
the next one or changes the program states (e.g., assign new values
tovariables). Softwaredefects (bugs)canbeintroducedbydevelopers
due to incorrect implementation, which may cause unexpected
outputs or even fail-stop errors (e.g., program crashes).
To detect defects, software testing is one of the most widely
adoptedsoftwarevalidationtechniquesinsoftwareindustry—Given
asetoftestdata,itfeedsthesetestdataasinputstoprogramand
validates the correctness of the program’s run-time behavior by
comparingtheactualoutputswithexpectedones(testoracles);and
measurestestadequacybyusing coveragecriteria,theimportant,
practical measures to quantify the degree to which the software is
tested [36]. The program with higher test coverage often suggests
that it has a lower chance of containing defects. Many software
testingstandardsrequireasoftwareproducttobethoroughlytested
withhightestcoveragebeforeshipment,whichisusedasanindica-
tor and confidence of the software quality. On some safety critical
systems, the requirement of some form of test coverage is even
100%. For example, ECSS-E-ST-40C [ 15] standards demand 100%
statementcoverageofthesoftwareundertestfortwocriticallevels.
121
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. DeepGauge : Multi-Granularity Testing Criteria for Deep Learning Systems ASE ’18, September 3–7, 2018, Montpellier, France
For traditional software, a number of coverage criteria have
alreadybeendefinedatdifferentlevels,toanalyzethesoftwarerun-
timebehaviorfromdifferentperspectives, i.e.,codelevel(e.g.,state-
ment,branch,data-flowcoverageandmutationtesting[ 27,46,62])
ormodel-level(e.g.,stateandtransitioncoverage[ 2,14])tocater
for different testing methods and granularities. Some commonly
used test coverage criteria are listed as follows:
•Statementcoveragemeasureswhethereachinstructionhasbeen
executed, and branch coverage focuses on whether each branch
of control structure (e.g., in iforswitch-case statements) has
been covered, both of which are control-flow-based criteria.
•Data-flow coverage [ 46] enforces the coverageof each variable
definition and its uses to detect data-flow anomalies.
•Model-basedcoveragecriteria[ 3,52]aimtocovermoreprogram
behaviors via abstracted behavior models. Other comprehensive
variants of test coverage could be referred to [2].
However, none of these criteria can be directly applied to test
DNNs due to its unique architecture, as explained below.
2.2 Deep Neural Network Architecture
Inourpaper,weregardaDLsystemasanysoftwaresystemthat
includes one or more DNNs.1Unlike traditional software, pro-
grammedwithdeterministicalgorithmsbydevelopers,DNNsare
programmedbythetrainingdata,selectedfeatures,andnetwork
structures (e.g., number of layers). Specially, a DNN consists ofmultiple interconnected neurons organized on layers: the input
layer, the outputlayer, and one or multiple hiddenlayers. Each
neuronisacomputingunitthatcomputesitsoutputbyapplyingan
activationfunction toitsinput.InclassicDNNs,eachneuronisfully-
connected with all neurons on the next layer, and each edge has a
weight, which indicates the strength of the connections betweenneurons. Overall, a DNN could be considered as a function that
transformsagiveninputtotheoutput,andthisfunctionisdecided
by the aggregated effects from its computation units (i.e., neurons),
each of which contributes to the whole computation procedure.
Figure1(a)shows an example of a three-layer DNN.
Toaccomplishatask(e.g.,predictionontheautonomousvehi-
cles’steeringanglebymonitoredimages),DNNsaretrainedand
programmedthroughalargesetoflabelledtrainingdata.However,
similartotraditionalsoftware,DNNsmayalsocontaindefects(e.g.,
givewrongsteeringangles)duetoincorrect,incompletetraining
data, or even the wrongly stipulated run-time programming (i.e.,
training)procedure.Forexample,humananalystmayincludeer-
roneous and noisy data when collecting training data. In such a
case, a given input data might be wrongly handled (e.g., classi-fied, predicted), causing losses and even severe tragedies, if theflawed DNNs are deployed to safety-critical systems ( e.g., the re-
cent Tesla autonomous driving accident
2). For the complex and
high-dimensional real-world inputs, it is almost impossible for hu-
man toensure all possible,even corner-case dataare included. To
systematicallytestanduncoverhiddendefectsofDNNs,itiscrucial
1In particular, a DL system may either be entirely composed of DNNs, or have DNNs as its core
with extra software encapsulation. In this paper, we mostly focus on DNNs since it is the core of
a DL system, and our methods could be extended to support general DL systems. Although the
trainingprogramofthecurrentstate-of-the-artDNNsarestillwrittenastraditionalsoftware,the
obtained DNN from the training program is fundamentally different in how the logic is encoded.
2http://www.bbc.com/news/world-us-canada-43604440
Layer 1
(Input Layer)Layer 2
(Hidden Layer)Layer 3
(Output Layer)
n1
n2
n3n4
n5
n6
n7n8
n9
(a)
All Behaviors
Main Behaviors
(k-multisection Coverage)Corner-case
 Behaviors
(Boundary Coverage)
Erroneous 
Behaviors
(b)
Figure1: (a)AnexampleofafullyconnectedDNN. (b)Behav-
iorsofDNNsandrelationsbetweendefinedcoveragecriteria
(the red points denote erroneous behaviors therein).
todefineasetofsuitablecoveragecriteriaforevaluatingthetest
adequacyaswellasgaugingtheinternalcoveredstatesofDNNs
to gain confidence on the testing results of DNNs.
3 COVERAGE CRITERIA FOR TESTING DL
SYSTEMS
Fortraditionalsoftwaretesting,developersdesignandseekasetof
representativetestdatafromthewholelargeinputspace,hoping
thattheselectedtestdatacoulddetectthesoftwaredefectsunder
limited computational resources.3
Testingcoveragecriteriaisproposedtoshatterandapproximate
the software internal states. It partitions the input space and es-
tablishes the relation of an input subspace and an approximatedsoftware internal state. In this way, compared with the test datafrom a single input subspace, the same number of test data fromdifferent input sub-spaces would have a higher chance to covermore diverse software states, resulting in a higher possibility to
detectmorediversesoftwaredefects.Overthepastdecades,asetof
well-designedcoveragecriteria[ 2](e.g.,statementcoverage,branch
coverage)havedemonstratedtheirpracticalvalue andarewidely
adopted in software industry to systematically guide the testing
processtounveilthesoftwaredefectsatdifferentlevels, e.g.,(1)Unit
level:testingsmallsnippetsoffunctions.(2) Integrationlevel :testing
multiplesub-modulesorfunctionstochecktheirinteractions.(3)
System level : testing the software system as a whole.
Thecurrentstate-of-the-practiceDNNtesting,however,isstillat
itsearlystageandmainlyreliesonthepredictionaccuracy(similar
to black-box system level testing that only observes inputs andits corresponding outputs), lacking systematic testing coverage
criteria for defect detection. Furthermore, traditional software and
DNNs have obvious differences, so existing coverage criteria for
traditional software could not be directly applied to DNNs.
In this section, we design a set of DNN testing coverage criteria
frommultiplelevels,aimingtogaugethetestingadequacyofDNNs
and facilitate the detection of those erroneous behaviors from mul-
tipleportrayals.Tobeusefultowardsindustrylevelapplications,
webelievethatthetestcriteriashouldbesimple,scalableaswell
general enough to be applied to a large range of DNNs without
confining onspecific DNN structureor activation functions.Con-
ceptually, similar to traditional software, the behaviors of DNNs
canbedividedintotwocategories, i.e.,majorfunctionbehaviors
3Theinputspaceofasoftwarecouldbesolargethatitisoftenimpossibletoenumerateandtestall
the possibilities given limited computation resource.
122
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Ma, Xu, Zhang, Sun, Xue, Li, Chen, Su, Li, Liu, Zhao, and Wang
andcorner-casebehaviors,bothofwhichmaycontainerroneous
behaviors(seeFigure 1(b)andourevaluationresultsinSection 4).
Wehavetakenthesefactorsintoconsiderationduringthedesign
of coverage criteria.
LetN={n1,n2,...}be a set of neurons of a DNN. Let T=
{x1,x2,...}be aset oftestinputs. We use ϕ(x,n)todenote afunc-
tionthatreturnstheoutputofaneuron n∈Nunderagiventest
inputx∈T.4Let the DNN have llayers and Lidenote the set of
neurons on the i-th layer (1 ≤i≤l).
3.1 Neuron-Level Coverage Criteria
At the neuron-level, we use the output values of neuron ndeter-
mined from the training to characterize its behaviors. Since the
internal logic of a DNN is mostly programmed by training data,
intuitively,thefunctionality( i.e.,neuronoutput)foreachneuronof
aDNNshouldfollowsomestatisticaldistributionthatislargelyde-
termined by the training data. The output distribution of a neuron
obtained from training data analysis would allow to approximately
characterizethemajorfunctionregionswhoseoutputvaluesare
oftentriggeredbyinputdatawithasimilarstatisticaldistributionto
the training data, and the corner cases whose output values rarely
occur.However,forapractical-sizedDNN,obtaininganaccurate
outputdistributionfor each neuronwouldbecomputationallyin-
tensive. With the similar spirit while being scalable, we leverage
the neuron output value boundaries obtained from training data to
approximate the major function region and corner-case region.
Specially, for a neuron n, lethighnandlownbe its upper and
lower boundary output values, respectively, on the value range of
itsactivationfunction,where highnandlownarederivedfromthe
training dataset analysis. We refer to [ lown,highn] as the major
function region of a neuron n.
Definition 3.1. For a test input x∈T, we say that a DNN is
locatedinits majorfunctionregion givenxiff∀n∈N:ϕ(x,n)∈
[lown, highn].
Toexhaustivelycoverthemajorfunctionregions,wepartition
[lown,highn]intoksections,andrequireeachofthemtobecov-
eredbythetestinputs.Wenamethiscoverageas k-multisection
neuron coverage.
(i)k-multisection Neuron Coverage . Given a neuron n, thek-
multisection neuron coverage measures how thoroughly the given
set of test inputs Tcovers the range [ lown,highn]. To quantify
this, we divide the range [ lown,highn] intokequal sections ( i.e.,
k-multisections), for k>0. We write Sn
ito denote the set of values
in thei-th section for 1 ≤i≤k.
Ifϕ(x,n)∈Sn
i, we say the i-th section is covered by the test
inputx.Therefore, foragiven setof testinputs Tandthe neuron
n, itsk-multisection neuron coverage is defined as the ratio of the
number of sections covered by Tand the total number of sections,
i.e.,kin our definition. We define the k-multisection coverage of a
neuronnas:
|{Sn
i|∃x∈T:ϕ(x,n)∈Sn
i}|
k.
4Thispaperfocusesonfeedforwardneuralnetworks.Forrecurrentneuralnetworks(RNNs),wecan
unrollacertaindepthoflayersofanRNNandadapt ϕ(x,n)bysetting xtobeaninputsequence.We further define the k-multisection neuron coverage of a DNN as:
KMNCov( T,k)=/summationtext.1
n∈N|{Sn
i|∃x∈T:ϕ(x,n)∈Sn
i}|
k×|N|.
However, for a neuron n, there are also cases where ϕ(x,n)may
locate out of [ lown,highn],i.e.,ϕ(x,n) ∈ (−∞,lown)orϕ(x,n)∈
(highn,+∞).Wereferto (−∞,lown)∪(highn,+∞)asthecorner-
case region of a neuron n.
Definition 3.2. For a test input x∈T, we say that a DNN is
located in its corner-case region givenxiff∃n∈N:ϕ(x,n)∈
(−∞,lown)∪(highn,+∞).
Note that the profiled outputs of a neuron obtained from the
training data would not locate into the corner-case region.In other
words, if test inputs follow a similar statistical distribution with
the training data, a neuron output would rarely locate in corner-
case region as well. Nevertheless, it does not mean that testing the
corner cases of a neuron is not important because defects of DNNs
could also locate in the corner-case regions (see Section 4.3).
To cover these corner-case regions of DNNs, we define two
coveragecriteria, i.e.,neuronboundarycoverageandstrongneu-
ronactivationcoverage.Givenatestinput x,ifϕ(x,n)belongsto
(−∞,lown)or(highn,+∞), we say the corresponding corner-case
regioniscovered.Toquantifythis,wefirstdefinethenumberof
covered corner-case regions as follows:
UpperCornerNeuron ={n∈N|∃x∈T:ϕ(x,n)∈(highn,+∞)};
LowerCornerNeuron ={n∈N|∃x∈T:ϕ(x,n) ∈ (−∞,lown)}.
(ii) Neuron Boundary Coverage . Neuron boundary coverage
measureshowmanycorner-caseregions( w.r.t.bothoftheupper
boundary and the lower boundary values) have been covered by
thegiventestinputset T.Itisdefinedastheratioofthenumberof
coveredcornercasesandthetotalnumberofcornercases(2 ×|N|):
NBCov(T)=|UpperCornerNeuron |+|LowerCornerNeuron |
2×|N|.
SomerecentresearchonDNNsinterpretabilityempiricallyshows
thatthehyperactiveneuronsmightpotentiallydeliverusefullearn-
ing patterns within DNNs [ 30,61]. Based on this intuition, the
proposed coverage criteria in the rest of this section focus more on
the hyperactive neuron cases (e.g., top- kneuron coverage in the
next subsection). Similar to neuron boundary coverage, we further
define strong neuron activation coverage to measure the coverage
status of upper-corner cases.
(iii)StrongNeuronActivationCoverage .Strongneuronactiva-
tion coverage measures how many corner cases ( w.r.t.the upper
boundary value highn) have been covered by the given test inputs
T. It is defined as the ratio of the number of covered upper-corner
cases and the total number of corner cases ( |N|):
SNACov(T)=|UpperCornerNeuron |
|N|.
3.2 Layer-Level Coverage Criteria
Atlayer-level,weusethetophyperactiveneuronsandtheircombi-
nations (or the sequences) to characterize the behaviorsof a DNN.
Foragiventestinput xandneurons n1andn2onthesamelayer,
we sayn1is more active than n2givenxifϕ(x,n1)>ϕ(x,n2).
123
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. DeepGauge : Multi-Granularity Testing Criteria for Deep Learning Systems ASE ’18, September 3–7, 2018, Montpellier, France
For thei-th layer, we use topk(x,i)to denote the neurons that
have the largest koutputs on that layer given x. For example, in
Figure1(a), assume ϕ(x,n1)andϕ(x,n3)are larger than ϕ(x,n2),
the top-2 neurons on layer 1 are n1andn3(depicted in green).
(i)Top-kNeuronCoverage .Thetop- kneuroncoveragemeasures
howmanyneuronshaveoncebeenthemostactive kneuronson
each layer. It is defined as the ratio of the total number of top- k
neurons on each layer and the total number of neurons in a DNN:
TKNCov( T,k)=|/uniontext.1
x∈T(/uniontext.1
1≤i≤ltopk(x,i))|
|N|.
The neurons from the same layer of a DNN often play similar
roles and the top active neurons from different layers are impor-
tant indicators to characterize the major functionality of a DNN.Intuitively, to more thoroughly test a DNN, a test dataset should
uncover more top active neurons.
(ii)Top-kNeuronPatterns .Givenatestinput x,thesequenceof
thetop-kneuronsoneachlayeralsoformsapattern.InFigure 1(a),
assumetheneuronsingreenarethetop-2neuronsoneachlayer,
thepatterncanberepresentedas ({n1,n3},{n5,n6},{n8,n9}).More
formally, a pattern is an element of 2L1×2L2×···×2Ll, where
2Liisthesetofsubsetsoftheneuronson i-thlayer,for1 ≤i≤l.
Given the test input set T, the number of top- kneuron patterns for
Tis defined as:
TKNPat(T,k)=|{(topk(x,1),...,topk(x,l)) |x∈T}|.
Intuitively, the top- kneuron patterns denote different kinds of
activated scenarios from the top hyperactive neurons of each layer.
4 EXPERIMENTS
Weimplement DeepGauge onKeras2.1.3[ 10]withTensorFlow1.5.0
backend[ 1],andapplytheproposedtestingcriteriatoDNNsfor
evaluation in this section.
4.1 Evaluation Subjects
DatasetsandDNNModels. Weselecttwopopularpublicly-available
datasets,i.e., MNIST [ 32] and ImageNet [ 42] (see Table 1) for eval-
uation. MNIST is for handwritten digits recognition, containing
70,000 input data in total, of which 60,000 are training data and10,000 are test data. On MNIST, we use three pre-trained LeNet
family models (LeNet-1, LeNet-4, and LeNet-5) [32] for analysis.
To further demonstrate the usefulness of our criteria towards
largerscalereal-worldDLsystems,wealsoselectImageNet,alargesetofgeneralimagedataset( i.e.,ILSVRC-2012[
42])forclassification
containing more than 1.4 million training data and 50,000 test data
from 1,000 categories. The DNNs we used for ImageNet are pre-trained VGG-19 [
44] and ResNet-50 [ 24] models, both of which
are relatively large in size and obtain competitive records in the
ILSVRC competition [ 42], containing more than 16,000 and 94,000
neurons, and 25 and 176 layers, respectively. As a DNN testing
criteriontowardsfutureindustrylevelapplication,webelievethe
scalability up-to ImageNet-like or even larger data size and model
size is almost indispensable.
Adversarial Test Input Generation. Besidesusingoriginaltest
data accompanied in the corresponding dataset for coverage evalu-
ation,wefurtherexplorefourstate-of-the-artadversarialtestinput
generationtechniques(i.e.,FGSM[ 20],BIM[31],JSMA[ 37],andCW [8]) for comparative study. Each of the adversarial techniques
generatesteststodetectDNN’spotentialdefectsthroughtheminor
perturbations on a given input, described as follows:
•FGSM crafts adversarial examples usingloss function J(Θ,x,y)
with respect to the input feature vector, where Θdenotes the
modelparameters, xistheinput,and yistheoutputlabelof x,the
adversarialexampleisgeneratedas: x∗=x+ϵsign(∇xJ(Θ,x,y)).
•BIM applies adversarial noise ηmany times iteratively with a
smallparameter ϵ,ratherthanone ηwithoneϵatatime,which
gives a recursive formula: x∗
0=xandx∗
i=clipx,ϵ(x∗
i−1+
ϵsign(∇x∗
i−1J(Θ,x∗
i−1,y))), whereclipx,ϵ(·)denotes a clipping
of the values of the adversarial sample such that they are within
anϵ-neighborhood of the original input x.
•JSMA isproposed for targetedmisclassification. For aninput x
and a neural network F, the output of class jis denoted as Fj(x).
To achieve a target misclassification class t,Ft(x)is increased
while the probabilities Fj(x)of all other classes j/nequaltdecrease,
untilt=argmaxjFj(x).
•Carlini/Wagner (CW): Carlini and Wagner recently proposed
new optimization-based attack technique which is arguably the
most effective in terms of the adversarial success rates achieved
with minimal perturbation [ 8]. In principle, the CW attack is to
approximate the solution to the following optimization problem:
argmin
x∗λL(x,x∗)−J(Θ,x∗,y),
whereLisalossfunctiontomeasurethedistancebetweenthe
predictionandthegroundtruth,andtheconstant λistobalance
the two loss contributions. In this paper, we adopt the CW ∞,
where each pixel is allowed to be changed by up to a limit.
Figure2shows examples of the generated tests of the four ad-
versarialtechniquesonthesampleddatafromMNISTtestset.In
this example, we could see that compared with FGSM and BIM,
JSMA and CW perturb fewer pixels on the sampled test input. Fur-
thermore, given the same input data but different DNNs, the same
technique would often generate different adversarial test results.
For example, given the input image 7, JSMA generates different re-
sults on DNNs (i.e., LeNet-1, LeNet-4 and LeNet-5). In other words,
the studied adversarial techniques are often DNN dependent.
4.2 Evaluation Setup
MNIST.On MNIST dataset, each image is single-channel of size
28×28×1. Before the evaluation starts, we first obtain the DNN’s
neuron output statistical information through runtime profiling
eachofthestudiedDNNs(i.e.,LeNet-1,LeNet-4,andLeNet-5)using
the60,000trainingdata.Whentestingevaluationstarts,foreach
DNN under analysis, we run the 10,000 test data on the model
toobtainthecorrespondingcoverage.ForeachstudiedDNN,we
furthergenerateanotherfoursetsofadversarialtestdatawhichcan
exploredefectsofDL,5throughFGSM[ 20],BIM[31],JSMA[ 37],
and CW [ 8]. We show that DeepGauge is general and easy to be
testedonthestate-of-the-artadversarialtestgenerationtechniques.
Aftergeneratingthefouradversarialdatasets,weaggregateeach
ofthemwiththeoriginalMNISTtestdataset(withatotalsize20,000
foreach),whichenablesustoperformthecomparativestudyon
5Each generated adversarial dataset is of the same size as the original test set.
124
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Ma, Xu, Zhang, Sun, Xue, Li, Chen, Su, Li, Liu, Zhao, and Wang
Test org.FGSM BIM JSMA CW FGSM BIM JSMA CW FGSM BIM JSMA CW
LeNet-1 LeNet-4 LeNet-5
Figure 2: Examples of original sampled test data from MNIST in comparison to the ones generated by each adversarial tech-
nique on the corresponding studied DNN models.
Table 1: Breakdowns of datasets and DNN models.
DataSetDatasetDNN Model #Neuron #LayerTest Data Source
Description for Eval.
MNIST Digit recog.LeNet-1 52 7 Test org. &
LeNet-4 148 8FGSM/BIM/JSMA/CWLeNet-5 268 9
ImageNetGeneral image VGG-19 16,168 25 Test org. &
with 1000-classes ResNet-50 94,059 176 FGSM/BIM/CW
how the adversarial test data enhances the defect detection ability
fromourcoveragecriteriameasurement.Sincethestudiedadversar-ialtestgeneration techniquesaremodel dependent,theadversarial
datasets generated by the same adversarial techniques are actu-
ally different for each model, though the same number (i.e., five)
datasetsareusedtoevaluateoneachmodel.Foreachadversarial
technique, we actually use it to generate three adversarial datasets,
one for each of LeNet-1, LeNet-4, and LeNet-5, respectively.
The detailed parameter configurations for each criterion are
shown in Table 2, whereuandlare the output upper bound (max-
imal value) and lower bound (minimal value) obtained for each
neuronduringprofiling,respectively; σisthestandarddeviationof
theoutputsofaneuronduringprofiling.Althoughthedefinitionof
neuron boundary coverage and strong neuron activation coverage
arebasedon uandlalone(i.e.,neuronoutputUpperBound(UB)and
LowerBound (LB)), it would also be interesting to see what results
could be obtained if we further tighten corner-case regions (i.e.,increase upper bound and decrease lower bound). Therefore, be-sides setting UB and LB to
uandlas defined in Section 3.1,w e
also evaluate another two configurations by increasing UB (resp.
decreasingLB)by0 .5∗σandσforneuronboundarycoverageand
strongneuronactivationcoverage(seeTable 2).Intotal,wehave
3 (models) ×5 (datasets) ×14 (criterion settings) =210 evaluation
configurations for MNIST.ImageNet.
ImageNet(ILSVRC-2012)[ 42]ismorechallengingfor
evaluation due to its large data size (more than 1.4 million training
data) as well as large image size (224 ×224×3) for processing.
Moreover, the DNNs that achieve high accuracy are often com-
plex.ComparedwithLeNetfamilymodels,thestudiedVGG-19and
ResNet-50aremuchmorecomplexintermsofbothneuronsand
layers.Duetothecomputationalcomplexityofadversarialtestgen-erationonImageNetforanalysis,werandomlysampleimagesfromTable 2: The parameter configurations for evaluation.
DL Coverage Criteria Parameter Configuration
k-multisection Neuron Cov. (KMNC) k=1,000 k=10,000 N.A.
Neuron Boundary Cov. (NBC)LB=lLB=l−0.5∗σLB=l−σ
UB=uUB=u+0.5∗σUB=u+σ
Strong Neuron Activation Cov. (SNAC) UB=uUB=u+0.5∗σUB=u+σ
Top-kNeuron Cov. (TKNC) k=1 k=2 k=3
Top-kNeuron Patterns (TKNP) k=1 k=2 k=3
each of itslabeledcategories in the original ImageNettest dataset,
withatotalnumberof5,000imagesasthetestdataforourevalu-
ation.WealsotrytouseFGSM,BIM,JSMA,andCWtogenerate
adversarialtestsforeachofthestudiedDNNs.However,weareun-abletosetupJSMAtorunsuccessfullyoneitherofthetwoDNNs.
6
Overall, we have a total of 2 (models) ×4 (datasets) ×14 (criterion
settings) =112 experimental configurations for ImageNet.
To support such large scale evaluation, we run the experiments
onacomputercluster.EachclusternoderunsaGNU/Linuxsystem
withLinuxkernel3.10.0ona18-core2.3GHzXeon64-bitCPUwith
196 GB of RAM and also an NVIDIA Tesla M40 GPU with 24G.
4.3 Experimental Results
In our experiments, we have seen useful testing feedbacks frommultiple perspectives with each testing criterion, showing some
uniqueportrayaloftheruntimebehaviorofDNNs.Wefirstdescribe
some obtained results and then summarize our findings.7
4.3.1 MNIST and ImageNet. MNIST.As shown in Table 3, the
coverageofdifferentcriteriaobtainedbytheadversarialtechniques
generally increase compared with the original MNIST test dataset.
Forinstance,asforLeNet-4,theJSMAincreasesthecoverageofthe
originaltestsfrom 39.7%to52.3%by31.7%in 10 ,000-multisection
neuroncoverage,from9.1%to16.2%by78%inneuronboundary
coverage, from 13.5% to 27.7% by 105% in strong neuron activation
coverage,from62.2to66.2by6.6%intop-1neuroncoverage,and
from 787 to 1,395 by 77.3% in top-1 neuron patterns.
The increase of coverage infers that the adversarial test data
overallexplorenewDNNs’internalstates,someofwhicharenot
6ThiscouldbepotentiallycausedbythemassivedatasizeandthecomplexityofVGG-19andResNet-
50. The similar issue on JSMA was also reported in a previous work [57].
7Duetothepagelimit,weputmoredetailedexperimentalresultdiscussion,aswellasdataplotonthe paper’s accompanying website https://deepgauge.github.io/.
125
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. DeepGauge : Multi-Granularity Testing Criteria for Deep Learning Systems ASE ’18, September 3–7, 2018, Montpellier, France
Table 3: Coverage results of DeepGauge on MNIST, LetNet
models, and generated tests by adversarial techniques.
TestingDNN Eval. Config. Test org.Test org. Test org. Test org. Test org.
Criteria +FGSM +BIM +JSMA +CW
LN-1k=1,000 64.5 74.8 68.1 77.7 72.8
k=10,000 37.3 48.6 46.6 51.5 49.5
KMNCLN-4k=1,000 70.4 75.5 73.6 77.7 74.5
(%) k=10,000 39.7 49.7 50.2 52.3 50.1
LN-5k=1,000 68.5 72.0 71.5 73.8 71.2
k=10,000 37.2 46.0 47.6 48.8 46.8
LN-1LB=l,UB=u 43.3 47.1 49.0 46.2 44.2
l-0.5*σ,u+0.5*σ17.3 21.2 21.2 18.3 17.3
l-σ,u+σ 8.7 8.7 8.7 9.6 8.7
LN-4LB=l,UB=u 9.1 12.2 13.9 16.2 10.5
NBC l-0.5*σ,u+0.5*σ0.7 1.0 1.0 2.7 1.0
(%) l-σ,u+σ 0.3 0.3 0.3 1.0 0.3
LN-5LB=l,UB=u 8.6 10.5 11.6 13.4 9.1
l-0.5*σ,u+0.5*σ1.7 2.1 1.9 3.0 2.0
l-σ,u+σ 1.1 1.3 1.3 1.7 1.1
LN-1UB=u 38.5 42.3 46.2 42.3 40.4
UB=u+0.5*σ23.1 25.0 28.9 25.0 23.1
UB=u+σ 17.3 17.3 17.3 19.2 17.3
LN-4UB=u 13.5 16.2 18.9 27.7 13.5
SNAC UB=u+0.5*σ1.4 1.4 1.4 5.4 1.4
(%) UB= u+σ 0.7 0.7 0.7 2.0 0.7
LN-5UB=u 14.9 16.4 20.2 23.5 14.9
UB=u+0.5*σ3.4 4.1 3.7 6.0 3.4
UB=u+σ 2.2 2.6 2.6 3.4 2.2
LN-1k=1 61.5 61.5 61.5 63.5 61.5
k=2 86.5 88.5 88.5 88.5 86.5
k=3 92.3 92.3 92.3 92.3 92.3
LN-4k=1 62.2 63.5 64.9 66.2 64.9
TKNC k=2 79.1 79.7 80.4 81.8 80.4
(%) k=3 85.1 87.2 87.8 86.5 86.5
LN-5k=1 49.3 53.7 53.7 51.9 52.2
k=2 63.8 66.8 67.5 66.0 66.0
k=3 72.4 73.9 74.6 74.3 74.6
LN-1k=1 76 77 77 100 86
k=2 915 1,271 1,185 1,325 1,270
k=3 3,716 6,069 5,708 6,597 5,823
LN-4k=1 787 1,210 1,140 1,395 1,389
TKNP k=2 6,190 11,185 11,268 12,140 11,742
k=3 9,301 18,515 18,491 18,356 18,194
LN-5k=1 1,136 2,141 1,775 2,031 2,011
k=2 6,947 13,987 12,614 12,797 12,456
k=3 9,684 19,361 19,215 19,201 19,157
coveredbytheoriginaltests.Assuchadversarialtestdatareveal
defectsofstudiedLeNetmodels,itindicatesthatgeneratingtests
towards improving the coverage of the proposed criteria might po-
tentially trigger more states of a DNN, incurring higher chances of
defectdetection,whichisconsistentwiththeusageoftestcoverage
in traditional software testing.
ImageNet. The testing coverage (Table 4) on the ImageNet shares
some similarity with MNIST data while showing some differences.
VGG-19 and ResNet-50 models are much larger in size and com-
plexity, potentiallycausing the obtainedcoverage lower thanthat
ofLeNetinmanycases.Considerthe10 ,000-multisectionneuron
coverage,FGSMachieves48.6%onLeNet-1,butonly18.8%onVGG-
19. At first glance, it is tempting to draw the conclusion that a
DNNwithhighercomplexityintermsofnumberofneuronsand
layersismoredifficulttobecoveredbytests.Ourresultsshowthat
this might not be generally applicable. For example, the originaltests achieves 22.8% KMNC (
k=10,000) on ResNet-50, but only
obtains 13.5% on VGG-19, although ResNet-50 has a larger number
ofneuronsandlayers.ComparedwithMNIST,thegeneratedadver-
sarial tests on ImageNet incur even higher increase on the neuron
boundary coverage (NBC) and strong neuron activation coverage
(SNAC) (Table 4). For example, on ResNet50 under LB= land UB=u
configuration, BIM increases these two criteria by 280% (from 4.1%
to 11.5%) and 279% (from 4.7% to 13.1%), respectively.Table4:CoverageresultsonImageNet,VGG-19andResNet-
50, and generated tests by adversarial techniques.
TestingDNN Eval. Config. Test org.Test org. Test org. Test org.
Criteria +FGSM +BIM +CW
VGG-19k=1,000 32.2 36.9 38.0 35.7
KMNC k=10,000 13.5 18.8 19.1 18.5
(%)ResNet-50k=1,000 43.0 47.5 47.8 47.4
k=10,000 22.8 29.3 29.6 29.4
VGG-19LB=l,UB=u 2.8 8.7 7.4 2.9
l-0.5*σ,u+0.5*σ1.5 4.0 3.4 1.5
NBC l-σ,u+σ 1.1 3.2 2.5 1.1
(%)
ResNet-50LB=l,UB=u 4.1 6.9 11.5 4.7
l-0.5*σ,u+0.5*σ1.5 2.1 6.0 1.7
l-σ,u+σ 0.9 1.2 3.9 0.9
VGG-19UB=u 4.6 10.5 9.8 4.7
UB=u+0.5*σ3.0 8.0 6.8 3.1
SNAC UB=u+σ 2.1 6.3 5.1 2.2
(%)
ResNet-50UB=u 4.7 7.0 13.1 5.4
UB=u+0.5*σ2.1 2.8 8.3 2.4
UB=u+σ 1.3 1.8 6.1 1.4
VGG-19k=1 58.8 61.5 68.1 68.7
k=2 74.3 76.2 80.8 81.2
TKNC k=3 81.6 82.9 85.9 85.9
(%)
ResNet-50k=1 26.8 30.3 29.1 29.5k=2 36.0 38.6 38.3 38.3k=3 42.3 44.7 44.3 44.3
VGG-19k=1 4,999 8,265 9,989 9,816
k=2 4,999 9,581 9,998 9,816
TKNP k=3 4,999 9,921 9,998 9,816
ResNet-50k=1 4,999 9,998 9,998 9,948
k=2 4,999 9,998 9,998 9,948
k=3 4,999 9,998 9,998 9,948
The top-1 neuron coverage obtained by both MNIST and Ima-
geNet(seeTable 3(TKNC)andTable 4(TKNC))showthatmany
neurons of a DNN have been triggered into a top- k(i.e., 1, 2, and 3
inourevaluatedcases)hyperactivestates.Forexample,onVGG-19,
the sampled original tests of ImageNet achieve 58.8% top-1 neuron
coverage, and 81.6% top-3 neuron coverage. Although the top- k
coverage improvement is not that obvious compared with other
criteria, the adversarial data still trigger more neurons as top- k
activated neurons in many cases, which detects the hidden defects.
Fordifferenttestinputdatasets,itisoftenthecasethatonlya
fixed subset of neurons of each layer would function as top hyper-
activatedneurons.Thiswouldbeahintthatthetophyperactivated
neurons of each layer might describe the high-level major function
skeletonofaneuronnetwork.Incomparisonwiththetop- kneuron
patterns (see Table 3(TKNP) and Table 4(TKNP)),albeit most of
the top hyperactive neurons are relatively stable for each layer,
theircombinationstillcapturesthestructuraldifferenceofinput
data.8These two layer-level criteria altogether provide us with the
information on which neurons matter the most within each layer;
andthetop- kneuronpatternswouldmostlybeabletodifferentiate
theinputdatawhen kisproperlyselectedgivenatargetDNN.The
findings indicate that generating tests to cover more top- kneuron
patterns would have a higher chance to find defects of a DNN.
4.3.2 Findings and Remarks. Theoverallexperimentalresultsdemon-
strate the usefulness of our proposed testing criteria for DNNs and
arealsohelpfultoexplainthedifferenceofthestate-of-the-practice
adversarial techniques form multiple perspectives:
•The original test data of MNIST and ImageNet cover both the
DNNs major function region (see KMNC) as well as corner-case
region(seeNBCandSNAC)inTables 3and4.Thisalsohappens
8Our in-depth investigation on the generated top- kneuron patterns for ImageNet show that the
relatively large pattern coverage improvement (even for the top- 1case) is relevant to the large #
of neurons and layers in VGG-19 and ResNet-50.
126
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Ma, Xu, Zhang, Sun, Xue, Li, Chen, Su, Li, Liu, Zhao, and Wang
tothegeneratedadversarialdatasets,showingthatadefectof
DNNcanoccureitherinamajorfunctionregionoracorner-case
region, both of which should be extensively tested.
•Thetestdatageneratedbyfourstudiedadversarialtechniques
(combinedwithoriginaltestdata)generallyboostthecoverageof
ourcriteria.Sinceanadversarialtestdatacouldpotentiallyreveal
defectsofaDLsystem,itmeansthatboostingthecoverageofour
testing criteria could to some extent enhance the fault detection
ability, which is consistent with the practical purpose of testing
criteria widely adopted in traditional software testing. It alsoshows that our test criteria metrics could capture the DNNs’
internalbehavioraldifferenceofbenignandadversarialtestdata.
Wenotethatincreasingthetestcoveragedoesnotnecessarily
imply that new defects could be detected in traditional software
testing. The same conclusion applies to our coverage criteria for
DNNs as well, though better-defined coverage criteria would be
much more pronounced in finding defects.
•Test data (including the generated test data by adversarial) eval-
uated on both MNIST and ImageNet mostly obtain a higher
k-multisection neuron coverage than the neuron boundary cov-
erage and strong neuron activation coverage, revealing that the
testdatacovermoreofthemajorfunctionregionthanthecorner-caseregionofaDNN.ThedesignoffutureDLtestingtechniques
should also take account of covering corner-case regions.
•Formostoftheevaluatedconfigurations,wefindthatahigher
strong neuron activation coverage is more achieved than its
correspondingneuronboundarycoverage.ThismightbecausedbytheuniquecharacteristicsofthoseactivationfunctionsinourstudiedDNNs,whichmakesthelowerregion(smallvalue)more
difficult to be covered than the upper region of the statistical
profilingdistribution.9Thisobservationisconsistentwiththe
models we studied, asLeNet family, VGG-19, and ResNet-50 all
useReLUas activation functions, which could make the lower
regions of a neuron much smaller than the upper regions.10
Remark 1. In general, for neuron boundary coverage and
strong neuron activation coverage, the higher (resp. lower)
theneuron’s upper(resp. lower)bound,the lessincrementoncoverageweobserve;fortop-
kneuroncoverage,thelargerthe
valueofk,thelessincrementoncoverage;fortop- kneuron
patterns, the larger the value of k, the more increment on
patterns.
Remark 2. For neuron boundary coverage and strong neu-
ron activation coverage, the 4 adversarial techniques havesufficient diversity on the performance, which is similar to
traditionaltestgenerationwhichaimtocoverdifferentpoten-
tial defects. Specifically, we observe that the adversarial tests
generated by CW are harder to be distinguished by the testcoverage since the CW perturbation concentrates more onthe objects with smaller magnitude, which may trigger less
internal behavior changes of DNNs.
9LeNet-1istheonlyexceptionalcase,whichmightbecausedbytheover-simplicityofitsnetwork.
10In particular, ReLUfunction propagates the positive output of a neuron to the next layer while
blocking the negative output by setting it to zero, which stops influencing its following layers.Test orig. Test orig.+FGSM Test orig.+BIM Test orig.+JSMA Test orig.+CW
0.0%20.0%40.0%60.0%80.0%100.0%
LeNet-1 LeNet-4 LeNet-5
99.3%
 100%
 100%
 99.3%
 100%
 100%
 99.3%
 100%
 100%
 99.6%
 100%
 100%
 99.3%
 100%
 100%
(1) Threshold=00.0%18.0%36.0%54.0%72.0%90.0%
LeNet-1 LeNet-4 LeNet-5
85.5%
83.1%
78%
86.2%
81.8%
80.8%
86.2%
85.1%
80.8%
86.9%
85.8%
80.8%
85.1%
79.1%
73.1%
(2) Threshold=0.2
0.0%16.0%32.0%48.0%64.0%80.0%
LeNet-1 LeNet-4 LeNet-5
73.5%
68.2%
38.5%
73.9%
68.2%
38.5%
73.5%
68.2%
38.5%
73.9%
68.2%
38.5%
73.5%
68.2%
38.5%
(3) Threshold=0.50.0%14.0%28.0%42.0%56.0%70.0%
LeNet-1 LeNet-4 LeNet-5
65.7%
66.9%
38.5%
65.7%
 66.2%
38.5%
67.2%
 66.9%
38.5%
66%
 66.2%
38.5%
65.3%
66.2%
38.5%
(4) Threshold=0.75
Figure3:TheDeepXploreneuroncoverageresultsonMNIST
dataset under different threshold configurations.
4.4 Comparison with DeepXplore’s Neuron
Coverage (DNC)
Peietal.[38]proposeakindofneuronactivationcoverageasthe
measurementfortestingdatadiversityofaDNNandarguethatthe
higher the activation coverage, the more states of a DNN could be
explored,withahigherchancefordefectsdetection.Akeyparame-terofDNCisauser-specifiedthreshold,andifanoutputofaneuron
islargerthanthethreshold,theneuroniscountedascovered.To
demonstrate the difference between our set of criteria and DNC,
wesetuptheDNCevaluationwiththesamedataset,model,aswell
as adversarialdata generationsettings asdescribedin Section 4.1.
Forthethresholdparameter,wefirstsetthresholdstobe0and0.75,
as used in [ 38]; to make an even more comprehensive comparison,
we also use two other settings (i.e., 0.2 and 0.5). Figures 3and4
show that the results of DNC obtained on the original test dataset
and the dataset generated by adversarial techniques for MNISTand ImageNet are almost the same for all experimental settings,
indicating that DNC is unable to differentiate the original test data
fromadversariallygeneratedones,whichtriggerthecorrectand
incorrect behaviors ofa DNN, respectively.This meansthat DNC
could hardly capture the difference between original test data and
corresponding test data generated by adversarial techniques. How-
ever,todetectthedefectsofDNNsinamorefine-grainedlevel,itisnecessarythatthecoveragecriteriacapturesuchminordifferences,
where the defects (adversarially triggered states) also lie in.
Ourfurtherin-depthinvestigationonDNCrevealsthat,thiscov-
erage criterion imposes several limitations: (1) DNC uses the same
thresholdastheactivationevaluationforalltheneurons.However,
we find that the output statistical distribution of different neurons
are quite diverse. Given a test suite for analysis, the outputs of
someneuronsmayexhibitquiteasmallvariancewithalargemean
value,whileothersmighthavealargevariancewithalowmean
value. Therefore, using the same threshold for all neurons with-
outconsideringthedisparityinneuron’sfunctionaldistributions
would greatly diminish the accuracy. For example, given a neu-
ronwithverysmallmeanandstandarddeviation,evenaslightly
larger user-specified threshold would generally determine that this
neuron cannot be covered. (2) DNC normalizes the dynamic range
127
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. DeepGauge : Multi-Granularity Testing Criteria for Deep Learning Systems ASE ’18, September 3–7, 2018, Montpellier, France
0%20%40%60%80%100%
VGG19 ResNet50
99.99%
 99.92%
 99.99%
 99.92%
 99.99%
 99.92%
 99.99%
 99.92%
(1) Threshold=00%18%36%54%72%90%
VGG19 ResNet50
88.4%
69%
88.6%
69.4%
88.7%
68.9%
87.9%
68.5%
(2) Threshold=0.2Test orig. Test orig.+FGSM Test orig.+BIM Test orig.+CW
0%16%32%48%64%80%
VGG19 ResNet50
71%
57.2%
71.3%
57.2%
71.1%
57.2%
70.6%
57.2%
(3) Threshold=0.50%12%24%36%48%60%
VGG19 ResNet50
9.1%
56.7%
9.4%
56.7%
9.3%
56.7%
8.6%
56.5%
(4) Threshold=0.75
Figure 4: The DeepXplore neuron activation coverage results on ImageNet dataset for different threshold settings.
of neuron outputs according to maxandminoutput of neurons
on the corresponding layer for each input image under analysis.
This raises an issue that the same normalized activation value (e.g.,
0.3) means differently for different input data, as the maxandmin
outputofeachlayermightchangeforeachinput,whichrenders
thenotionof“largerthanagiventhreshold”inconsistentamong
different inputs.
Doingsowillalsoeliminatetherelativityinactivationmagnitude
among different inputs, which is a very important property to
support the findings of neuron activation coverage. We instead
specifytheupperandlowerboundsforeachneuronobtainedfrom
the analysis on the training dataset, as opposed to each individual
input. In other words, our method relies on the statistics of the
trainingsetwhichisusedtodeterminethemainfunctionalityof
the DNN system.
4.5 Threats to Validity and Discussion
The selection of evaluation subjects (i.e., dataset and DNN mod-
els) could be a threat to validity. We try to counter this by using
the commonly-studied MNIST dataset and the practical large-scale
dataset ImageNet; for each studied dataset, we use the well-known
pre-trained models of different sizes and complexity ranging from
52 neurons up to more than 90,000 neurons. Even though, someof our results might not generalize to other datasets and DNN
models. Another threat could be caused by the configurable hyper-
parametersinthecoveragecriteriadefinition.Asacountermeasure
whileconsideringthelimitedcomputationalresources,weevaluate
each criterion with different settings, and analyze the influence of
the parameters on criteria accuracy. Even though, it might still not
cover the best parameter use-cases. For example, our evaluation
studiedk=1,000 andk=10,000 fork-multisection neuron cover-
age.Weleavetheoptimizedhyper-parameterselectioninourfuture
work.Furtherthreatcouldbecausedbythequalityoftrainingdata
used for distribution (i.e., the interval range) analysis of neuron
output.Inthispaper,weconsiderpubliclyavailablewell-pretrained
DNN models accompanied by training data with good quality.
Foradversarialtestgeneration,weselectfourpopularstate-of-
the-practicetechniquestosimulatedefectsfromdifferentsources
andgranularity.Weeitherfollowtheauthors’suggestedsettingsor
usetheirdefaultsettings.Moreover,tomakecomprehensivecom-
parisonswithDeepXplore’sneuroncoverage(DNC),weevaluate
DNC with multiple threshold settings.5 RELATED WORK
In this section, we attempt to review the most relevant work in
three aspects: testing, verification, and security of DL systems.
5.1 Testing of DL Systems
Traditionalpracticesinmeasuringmachinelearningsystemsmainly
rely on probing their accuracy on test inputs which are randomly
drawn from manually labeled datasets and ad hocsimulations [ 54].
However,suchblack-boxtestingmethodologymaynotbeableto
find various kinds of corner-case behaviors that may induce un-expectederrors[
19].Wicker etal.[53]recentlyproposedaScale
InvariantFeature Transformfeature guidedblack-box testingand
showeditscompetitivenesswithCWandJSMAalongthisdirection.
Peietal.[38]proposedawhite-boxdifferentialtestingalgorithm
for systematically finding inputs that can trigger inconsistenciesbetween multiple DNNs. They introduced neuron coverage formeasuring how much of the internal logic of a DNN has been
tested.However, it still exhibits several caveats as discussed in Sec-
tion4.4.DeepTest[ 49]investigatesabasicsetofimagetransforma-
tions(e.g.,scaling,shearing,androtation)fromOpenCVandshows
thattheyareusefultodetectdefectsinDNN-drivenautonomous
cars.Alongthisdirection,DeepRoad[ 59]usesinputimagescene
transformation and shows its potentiality with two scenes (i.e.,
snowy and rainy) for autonomous driving testing. The scene trans-
formation is obtained through training a generative adversarial
network(GAN)withapairofcollectedtrainingdatathatcoverthe
statistical features of the two target scenes.
Comparedwithtraditionalsoftware,thedimensionandpotential
testingspaceofaDNNisoftenquitelarge.DeepCT[ 35]adaptsthe
concept of combinatorial testing, and proposes a set of coverage
basedontheneuroninputinteractionforeachlayerofDNNs,to
guide test generation towards achieving reasonable defect detec-tion ability with a relatively small number of tests. Inspired by
the MC/DC test criteria in traditional software [ 29], Sunet al.[47]
proposed a set of adapted MC/DC test criteria for DNNs, and show
thatgeneratingtestsguidedbytheproposedcriteriaonsmallscale
neuralnetworks(consistingof Denselayerswithnomorethan5
hidden layers and 400 neurons) exhibits higher defect detection
ability than random testing. However, whether MC/DC criteria
scaletoreal-world-sizedDLsystemsstillneedsfurtherinvestiga-
tion. Instead of observing the runtime internal behaviors of DNNs,
DeepMutation [ 34] proposes tomutate DNNs (i.e., injectingfaults
128
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Ma, Xu, Zhang, Sun, Xue, Li, Chen, Su, Li, Liu, Zhao, and Wang
eitherfromthesourcelevelormodellevel)toevaluatethetestdata
quality,whichcouldpotentiallybeusefulfortestdataprioritization
in respect of robustness on a given DNN.
Ourworkofproposingmulti-granularitytestingcoverageforDL
systems is mostly orthogonal to the existing work. Compared with
the extensive study on traditional software testing, testing DL is
still at an early stage. Most existing work on DL testing lacks somesuitablecriteriatounderstandandguidethetestgenerationprocess.
Since test generation guided by coverage criteria (e.g., statement
coverage, branch coverage) towards the exploration of diverse soft-
warestatesfordefectdetectionhasbecomethe defactostandard
in traditional software testing [ 5,16,17,33], the study to design
suitabletestingcriteriaforDLisdesperatelydemanding.Thispapermakesanearlyattempttowardsthisdirectionbyproposingasetof
testing criteria. Our criteria not only can differentiate state-of-the-
artadversarialtestgenerationtechniques,butalsopotentiallybe
useful for the measurement of test suite diversity by analyzing the
DNNs’internalstatesfrommultipleportrayals.Webelievethatour
proposed criteria set up an important cornerstone and bring a newopportunity to design more effective automated testing techniques
guided by testing criteria for DL systems.
5.2 Verification of DL Systems
Formalmethodscanprovideformalguaranteesaboutsafetyand
robustness of verified DL systems [ 22,28,39,40,50,53]. The main
concernofformalmethodsaretheirscalabilityforreal-world-sized
(e.g., 100 ,000 neurons or even more) DL systems.
Theearlyworkin[ 40]providedanabstraction-refinementap-
proach to checking safety properties of multi-layer perceptrons.
Theirapproachhasbeenappliedtoverifyanetworkwithonly6
neurons. DLV [53] can verify local robustness of DL systems w.r.t.
a set of user specified manipulations. Reluplex [ 28] is a sound and
completeSMT-basedapproachtoverifyingsafetyandrobustnessof
DL systems with ReLUactivation functions. The networks verified
by Reluplex in [ 28] have 8 layers and 300 ReLUnodes. DeepSafe
[22]usesReluplexasitsverificationengineandhasthesamescala-
bilityproblemasReluplex.AI2[50]isasoundanalyzerbasedon
abstract interpretation that can reason about safety and robustness
ofDLsystems.Ittradesprecisionforscalabilityandscalesbetter
thanReluplex.TheprecisionofAI2dependsonabstractdomains
used in the verification, and it might fail to prove a property when
itactuallyholds.VERIVIS[ 39]canverifysafetypropertiesofDL
systems when attackers are constrained to modify the inputs only
throughgiventransformationfunctions.However,real-worldtrans-
formations can be much more complex than the transformation
functions considered in the paper.
5.3 Attacks and Defenses of DL Systems
Aplethoraofresearchhasshownthatdeeplearningsystemscan
be fooled by applying carefully crafted adversarial perturbation
added to the original input [ 6–9,20,48,55,60], many of which are
basedongradientoroptimizationtechniques.However,itstilllacks
extensivestudyonhowtheseadversarialtechniquesdifferentiate
intermsofDNNs’internalstates.Inthisstudy,wemakeanearly
attempt towards such a direction based on our proposed criteria.With the rapid development of adversarial attack techniques,
extensivestudieshavebeenperformedtocircumventadversarial
attacks. Galloway et al.[18] recently observe that low-precision
DNNs exhibit improved robustness against some adversarial at-
tacks. This is primarily due to the stochastic quantization in neural
networkweights.Ensembleadversarialtraining[ 51],GANbased
approaches [ 43,45], random resizing and random padding [ 56],
gametheory[ 13],anddifferentiablecertificate[ 41]methodsareall
investigatedtodefendagainstadversarialexamples.Byapplying
image transformations, such as total variance minimization and
imagequilting,veryeffectivedefensescanbeachievedwhenthe
networkistrainedontheaforementionedtransformedimages[ 23].
Formoreextensivediscussiononcurrentstate-of-the-artdefense
techniques, we refer readers to [4].
Ourproposedtestingcriteriaenablethequantitativemeasure-
mentofdifferentadversarialattacktechniquesfromthesoftware
engineeringperspective.Thiscouldbepotentiallyhelpfulforun-
derstanding and interpreting DNNs’ behaviors, based on which
moreeffectiveDNNdefensetechniquecouldbedesigned.Infuture
work, it would be also interesting to examine how to integrate the
proposedtestingcriteriaintotheDLdevelopmentlifecycletowards
building high quality DL systems.
6 CONCLUSION AND FUTURE WORK
ThewideadoptionofDLsystems,especiallyinmanysafety-critical
areas, has posed a severe threat to its quality and generalization
property.Toeffectivelymeasurethetestingadequacyandlaydown
thefoundationtodesigneffectiveDLtestingtechniques,wepro-
pose a set of testing criteria for DNNs. Our experiments on two
well-known datasets, five DNNs with diverse complexity, and four
state-of-the-artadversarialtestingtechniquesshowthatthetests
generated by the adversarial techniques incur obvious increases
ofthecoverageintermsofthemetricsdefinedinthepaper.This
demonstrates that DeepGauge could be a useful indicator for evalu-
ating testing adequacy of DNNs.
To the best of our knowledge, our work is among the early
studiestoproposetestingcriteriaforDLsystems.Weexpectthat
the proposed testing criteriacould be particularly amenable to DL
testing in the wild. In the next step, we will continue to explorealternative testing criteria for DNNs, such as the combination ofboth hyperactive and hypoactive neurons. We also plan to studythe proposed testing criteria guided automated test generation
techniquesforDNNs.Wehopethatourstudynotonlyprovidesan
avenue to illuminate the nature and mechanism of DNNs, but also
lays the foundation towards understanding and building generic
and robust DL systems.
ACKNOWLEDGMENTS
This work was partially supported by National Key R&D Program
ofChina2017YFC1201200and2017YFC0907500,FundamentalRe-
search Fundsfor Central Universities ofChina AUGA5710000816,
JSPSKAKENHIGrant18H04097.Wegratefullyacknowledgethe
support ofNVIDIA AI Tech Center (NVAITC)to ourresearch. We
alsoappreciatetheanonymousreviewersfortheirinsightfuland
constructive comments.
129
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. DeepGauge : Multi-Granularity Testing Criteria for Deep Learning Systems ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1]MartinAbadi,PaulBarham,JianminChen,ZhifengChen,AndyDavis,Jeffrey
Dean,MatthieuDevin,SanjayGhemawat,GeoffreyIrving,MichaelIsard,Man-
junathKudlur,JoshLevenberg,RajatMonga,SherryMoore,DerekG.Murray,
Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan
Yu, and Xiaoqiang Zheng. 2016. TensorFlow: A System for Large-scale Ma-
chine Learning. In 12th USENIX Symposium on Operating Systems Design and
Implementation (OSDI 16). 265–283.
[2]Paul Ammann and Jeff Offutt. 2008. Introduction to Software Testing (1 ed.).
Cambridge University Press, New York, NY, USA.
[3]CyrilleArtho,QuentinGros,GuillaumeRousset,KazuakiBanzai,LeiMa,Takashi
Kitamura,MasamiHagiya,YoshinoriTanabe,andMitsuharuYamamoto.2017.
Model-BasedAPITestingofApacheZooKeeper.In 2017IEEEInt.Conf.onSoftware
Testing, Verification and Validation (ICST 2017). Tokyo, Japan, 288–298.
[4]Anish Athalye, Nicholas Carlini, and David Wagner. 2018. Obfuscated Gradients
GiveaFalseSenseofSecurity:CircumventingDefensestoAdversarialExamples.
InProceedings of the 35th International Conference on Machine Learning, ICML
2018.https://arxiv.org/abs/1802.00420
[5]Benoit Baudry and Martin Monperrus. 2015. The Multiple Facets of Software
Diversity: Recent Developments in Year 2000 and Beyond. ACM Computing
Surveys (CSUR) 48, 1 (2015), 16.
[6]Wieland Brendel, Jonas Rauber, and Matthias Bethge. 2018. Decision-Based Ad-
versarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models.
InICLR.
[7]NicholasCarliniandDavid Wagner.2017. AdversarialExamplesarenotEasily
Detected: Bypassing Ten Detection Methods. In Proceedings of the 10th ACM
Workshop on Artificial Intelligence and Security. ACM, 3–14.
[8]NicholasCarliniandDavidWagner.2017. TowardsEvaluatingtheRobustnessof
Neural Networks. In IEEE Symposium on Security and Privacy. 39–57.
[9]SenChen,MinhuiXue,LinglingFan,ShuangHao,LihuaXu,HaojinZhu,and
BoLi.2018. AutomatedPoisoningAttacksandDefensesinMalwareDetection
Systems: An Adversarial Machine Learning Approach. Computers & Security 73
(2018), 326–344.
[10] François Chollet et al. 2015. Keras. https://github.com/fchollet/keras.
[11]Dan Ciregan, Ueli Meier, and Jürgen Schmidhuber. 2012. Multi-column Deep
Neural Networks for Image Classification. In CVPR. 3642–3649.
[12]Dan Ciresan, Alessandro Giusti, Luca M Gambardella, and Jürgen Schmidhu-
ber. 2012. Deep Neural Networks Segment Neuronal Membranes in Electron
Microscopy Images. In NIPS. 2843–2851.
[13]Guneet S. Dhillon, Kamyar Azizzadenesheli, Jeremy D. Bernstein, Jean Kossaifi,
AranKhanna,ZacharyC.Lipton,andAnimashreeAnandkumar.2018. Stochastic
Activation Pruning for Robust Adversarial Defense. In ICLR.
[14]AriloC.DiasNeto,RajeshSubramanyan,MarlonVieira,andGuilhermeH.Travas-
sos.2007. ASurveyonModel-basedTestingApproaches:ASystematicReview.
InProc. 1st ACM Int’l Workshop on Empirical Assessment of Software Engineering
Languages and Technologies. 31–36.
[15] ECSS. 2009. Space engineering - Software.
[16]Robert Feldt, Richard Torkar, Tony Gorschek, and Wasif Afzal. 2008. Searching
for Cognitively Diverse Tests: Towards Universal Test Diversity Metrics. In Pro-
ceedings of the 2008 IEEE International Conference on Software Testing Verification
and Validation Workshop. IEEE, 178–186.
[17]Gordon Fraser and Andrea Arcuri. 2013. Whole Test Suite Generation. IEEE
Trans. Softw. Eng. 39, 2 (Feb. 2013), 276–291. https://doi.org/10.1109/TSE.2012.14
[18]Angus Galloway, Graham W. Taylor, and Medhat Moussa. 2018. Attacking
Binarized Neural Networks. In ICLR.
[19]IanGoodfellowandNicolasPapernot.2017. TheChallengeofVerificationand
Testing of Machine Learning.
[20]Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and
Harnessing Adversarial Examples. In ICLR.
[21]Google Accident. 2016. A Google Self-driving Car Caused a Crash
for the First Time. https://www.theverge.com/2016/2/29/11134344/
google-self-driving-car-crash-report
[22] Divya Gopinath,GuyKatz,CorinaS.Pasareanu,andClarkBarrett.2018. Deep-
Safe:AData-drivenApproachforCheckingAdversarialRobustnessinNeural
Networks. InternationalSymposiumonAutomatedTechnologyforVerificationand
Analysis (ATVA) (2018).
[23]Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van der Maaten. 2018.
Countering Adversarial Images using Input Transformations. In ICLR.[24]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual
Learning for Image Recognition. In CVPR. 770–778.
[25]Warren He, Bo Li, and Dawn Song. 2018. Decision Boundary Analysis of Adver-
sarial Examples. In ICLR.
[26]GeoffreyHinton,LiDeng,DongYu,GeorgeEDahl,Abdel-rahmanMohamed,
Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara NSainath, et al
.2012. Deep Neural Networks for Acoustic Modeling in Speech
Recognition: The Shared Views of Four Research Groups. IEEE Signal Processing
Magazine 29, 6 (2012), 82–97.
[27]Yue Jia and Mark Harman. 2011. An Analysis and Survey of the Development of
Mutation Testing. IEEE Trans. Softw. Eng. 37, 5 (Sept. 2011), 649–678.
[28]GuyKatz,ClarkW.Barrett,DavidL.Dill,KyleJulian,andMykelJ.Kochenderfer.
2017. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks.
International Conference on Computer Aided Verification (CAV) (2017).
[29]Hayhurst Kelly J., Veerhusen Dan S., Chilenski John J., and Rierson Leanna K.
2001.A Practical Tutorial on Modified Condition/Decision Coverage. Technical
Report.
[30]BeenKim,MartinWattenberg,JustinGilmer,CarrieCai,JamesWexler,Fernanda
Viegas, et al .2018. Interpretability beyond Feature Attribution: Quantitative
Testing with Concept Activation Vectors (TCAV). In International Conference on
Machine Learning. 2673–2682.
[31]Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2017. Adversarial Examples
in the Physical World. ICLR(2017).
[32]Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-
based Learning Applied to Document Recognition. Proc. IEEE 86, 11 (1998),
2278–2324.
[33]Lei Ma, Cyrille Artho, Cheng Zhang, Hiroyuki Sato, Johannes Gmeiner, andRudolf Ramler. 2015. GRT: Program-Analysis-Guided Random Testing (T). InProceedings of the 2015 30th IEEE/ACM International Conference on Automated
Software Engineering(ASE) (ASE’15). IEEEComputer Society,Washington, DC,
USA, 212–223. https://doi.org/10.1109/ASE.2015.49
[34]Lei Ma, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Fei Juefei-Xu, Chao
Xie, Li Li, Yang Liu, Jianjun Zhao, and Yadong Wang. 2018. DeepMutation:
MutationTestingofDeepLearningSystems. InternationalSymposiumonSoftware
Reliability Engineering (ISSRE) (2018).
[35] Lei Ma, Fuyuan Zhang, Minhui Xue, Bo Li, Yang Liu, Jianjun Zhao, and Yadong
Wang.2018. CombinatorialTestingforDeepLearningSystems. arXivpreprint
arXiv:1806.07723 (2018).
[36]Glenford J. Myers, Corey Sandler, and Tom Badgett. 2011. The Art of Software
Testing(3rd ed.). Wiley Publishing.
[37]NicolasPapernot,PatrickMcDaniel,SomeshJha,MattFredrikson,ZBerkayCelik,
and Ananthram Swami. 2016. The Limitations of Deep Learning in Adversarial
Settings.In SecurityandPrivacy(EuroS&P),2016IEEEEuropeanSymposiumon.
IEEE, 372–387.
[38]KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017. Deepxplore:Auto-
mated Whitebox Testing of Deep Learning Systems. In Proceedings of the 26th
Symposium on Operating Systems Principles. 1–18.
[39]KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017. TowardsPractical
Verification of Machine Learning: The Case of Computer Vision Systems. CoRR
abs/1712.01785 (2017). arXiv:1712.01785 http://arxiv.org/abs/1712.01785
[40]LucaPulinaandArmandoTacchella.2010. AnAbstraction-RefinementApproach
to Verification of Artificial Neural Networks. In International Conference on
Computer Aided Verification. Springer, 243–257.
[41]Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. 2018. Certified Defenses
against Adversarial Examples. In ICLR.
[42]OlgaRussakovsky,JiaDeng,HaoSu,JonathanKrause,SanjeevSatheesh,SeanMa,ZhihengHuang,AndrejKarpathy,AdityaKhosla,MichaelBernstein,AlexanderC.
Berg, andLi Fei-Fei.2015. ImageNet Large ScaleVisual RecognitionChallenge.
IJCV115, 3 (2015), 211–252.
[43]Pouya Samangouei, Maya Kabkab, and Rama Chellappa. 2018. Defense-GAN:
Protecting Classifiers Against Adversarial Attacks Using Generative Models. In
ICLR.
[44]KarenSimonyanandAndrewZisserman.2015. VeryDeepConvolutionalNet-
works for Large-scale Image Recognition. ICLR(2015).
[45]Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman.
2018. PixelDefend: Leveraging Generative Models to Understand and Defend
against Adversarial Examples. In ICLR.
[46]TingSu,KeWu,WeikaiMiao,GeguangPu,JifengHe,YutingChen,andZhendong
Su. 2017. A Survey on Data-Flow Testing. ACM Computing Surveys (CSUR) 50, 1,
Article 5 (March 2017), 35 pages.
130
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Ma, Xu, Zhang, Sun, Xue, Li, Chen, Su, Li, Liu, Zhao, and Wang
[47]Y. Sun, X. Huang, and D. Kroening. 2018. Testing Deep Neural Networks. ArXiv
e-prints(March 2018). arXiv:cs.LG/1803.04792
[48]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,
Ian Goodfellow, and Rob Fergus. 2014. Intriguing Properties of Neural Networks.
InICLR.
[49]YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018.DeepTest:Automated
Testing of Deep-Neural-Network-driven Autonomous Cars. In International Con-
ference on Software Engineering (ICSE). ACM.
[50]Dana Drachsler-Cohen Petar Tsankov Swarat Chaudhuri Martin Vechev Ti-
mon Gehr, Matthew Mirman. 2018. AI2: Safety and Robustness Certification of
NeuralNetworkswithAbstractInterpretation.In IEEESymposiumonSecurity
and Privacy (SP).
[51]Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh,
and Patrick McDaniel. 2018. Ensemble Adversarial Training: Attacks and De-
fenses. In ICLR.
[52]Mark Utting and Bruno Legeard. 2007. Practical Model-Based Testing: A Tools
Approach. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
[53]MatthewWicker,XiaoweiHuang,andMartaKwiatkowska.2018. Feature-Guided
Black-Box Safety Testing of Deep Neural Networks. International Conference
on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)
(2018).[54]IanHWitten,EibeFrank,MarkAHall,andChristopherJPal.2016. DataMining:
Practical Machine Learning Tools and Techniques. Morgan Kaufmann.
[55]ChaoweiXiao,Jun-YanZhu,BoLi,WarrenHe,MingyanLiu,andDawnSong.
2018. Spatially Transformed Adversarial Examples. In ICLR.
[56]Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille. 2018.
Mitigating Adversarial Effects through Randomization. In ICLR.
[57]Weilin Xu, David Evans, and Yanjun Qi. 2018. Feature Squeezing: Detecting
Adversarial Examples in Deep Neural Networks. In Network and Distributed
System Security Symposium (NDSS).
[58]Fangyi Zhang, Jürgen Leitner, Michael Milford, Ben Upcroft, and Peter Corke.
2015. TowardsVision-basedDeepReinforcementLearningforRoboticMotion
Control.arXiv:1511.03791 (2015).
[59]M.Zhang,Y.Zhang,L.Zhang,C.Liu,andS.Khurshid.2018. DeepRoad:GAN-
basedMetamorphicAutonomousDrivingSystemTesting. ArXive-prints (Feb.
2018). arXiv:cs.SE/1802.02295
[60]Zhengli Zhao, Dheeru Dua, and Sameer Singh. 2018. Generating Natural Adver-
sarial Examples. In ICLR.
[61]BoleiZhou,YiyouSun,DavidBau,andAntonioTorralba.2018. RevisitingtheIm-portanceofIndividualUnitsinCNNsviaAblation. arXivpreprintarXiv:1806.02891
(2018).
[62]Hong Zhu, Patrick A. V. Hall, and John H. R. May. 1997. Software Unit Test
Coverage and Adequacy. ACM Computing Survey 29, 4 (Dec. 1997), 366–427.
131
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. 