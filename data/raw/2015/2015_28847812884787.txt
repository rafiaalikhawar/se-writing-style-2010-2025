On The Limits of Mutation Reduction Strategies
Rahul Gopinath
Oregon State University
gopinath@eecs.orst.eduMohammad Amin Alipour
Oregon State University
alipour@eecs.orst.eduIftekhar Ahmed
Oregon State University
ahmedi@onid.orst.edu
Carlos Jensen
Oregon State University
cjensen@eecs.orst.eduAlex Groce
Oregon State University
agroce@gmail.com
ABSTRACT
Although mutation analysis is considered the best way to
evaluate the eﬀectiveness of a test suite, hefty computa-
tional cost often limits its use. To address this problem, var-
ious mutation reduction strategies have been proposed, allseeking to reduce the number of mutants while maintainingthe representativeness of an exhaustive mutation analysis.
While research has focused on the reduction achieved, the
eﬀectiveness of these strategies in selecting representativemutants, and the limits in doing so have not been investi-gated, either theoretically or empirically.
We investigate the practical limits to the eﬀectiveness of
mutation reduction strategies, and provide a simple theoret-ical framework for thinking about the absolute limits. Ourresults show that the limit in improvement of eﬀectivenessover random sampling for real-world open source programs
i sam e a no fo n l y1 3 .078%. Interestingly, there is no limit
to the improvement that can be made by addition of new
mutation operators.
Given that this is the maximum that can be achieved with
perfect advance knowledge of mutation kills, what can bepractically achieved may be much worse. We conclude thatmore eﬀort should be focused on enhancing mutations than
removing operators in the name of selective mutation for
questionable beneﬁt.
Categories and Subject Descriptors
D.2.5[Software Engineering ]: TestingandDebuggingTest-
ing Tools
Keywords
softwaretesting, statisticalanalysis, theoreticalanalysis, mu-tation analysis
1. INTRODUCTION
The quality of software is a pressing concern for the soft-
ware industry, and is usually determined by comprehensivetesting. However, tests are themselves programs, (usually)
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributedfor proﬁt or commercial advantage and that copies bear this notice and the full cita-tion on the ﬁrst page. Copyrights for components of this work owned by others thanACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-publish, to post on servers or to redistribute to lists, requires prior speciﬁc permissionand/or a fee. Request permissions from permissions@acm.org.
ICSE ’16, May 14-22, 2016, Austin, TX, USA
© 2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI: http://dx.doi.org/10.1145/2884781.2884787written by human beings, and their quality needs to be mon-
itored to ensure that they in fact are useful in ensuring soft-ware quality (e.g., it is important to determine if the tests
are also a quality software system).
Mutation analysis [11, 36] is currently the recommended
method [5] for evaluating the eﬃcacy of a test suite. It
involvessystematictransformationofaprogramthroughthe
introduction of small syntactical changes, each of which is
evaluated against the given test suite. A mutant that can
be distinguished from the original program by the test suiteis deemed to have been killedby the test suite, and the ratio
of all such mutants to the set of mutants identiﬁed by a test
suite is its mutation (kill) score, taken as an eﬀectiveness
measure of the test suite.
Mutation analysis has been validated many times in the
past. Andrews et al. [ 4,5], and more recently Just et al. [ 32],
found that faults generated through mutation analysis re-
semble real bugs, their ease of detection is similar to that
of real faults, and most importantly for us, a test suite’seﬀectiveness against mutants is similar to its eﬀectiveness
against real faults.
However, mutation analysis has failed to gain widespread
adoption in software engineering practice due to its substan-
tial computational requirements — the number of mutantsgenerated needs to be many times the number of programtokens in order to achieve exhaustive coverage of even ﬁrst
order mutants (involving one syntactic change at a time),
and each mutant needs to be evaluated by a potentially fulltest suite run. A number of strategies have been proposedto deal with the computational cost of mutation analysis.
Theseha v ebeenclassiﬁed[ 44]orthogonallyinto do faster, do
smarter,a n d do fewer approaches, correspondingtowhether
they improve the speed of execution of a single mutant, par-
allelize the evaluation of mutants, or reduce the number ofmutants evaluated.
A large number of do fewer strategies — mutation re-
duction methods that seek to intelligently choose a smaller,representative, set of mutants to evaluate — have been in-vestigated in the past. They are broadly divided into oper-
ator selection strategies, which seek to identify the smallest
subset of mutation operators that generate the most usefulmutants [ 43,46], and strata sampling [ 1,9] techniques, which
seek to identify groups of mutants that have high similar-ity between them to reduce the number of mutants while
maintaining representativeness and diversity [ 53,54]. Even
more complex methods using clustering [ 19,37], static anal-
ysis [28,34] and other intelligent techniques [ 48] are under
active research [ 20].
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   511
These eﬀorts raise an important question: What is the
actual eﬀectiveness of a perfect mutation reduction strategy
over the baseline – random sampling – given any arbitraryprogram?
We deﬁne the eﬃciency of a selection technique as the
amount of reduction achieved, and the eﬀectiveness as
the selection technique’s ability to choose a representativereduced set of mutants, that require as many test cases to
kill as the original set of mutants. The ratio of eﬀectiveness
of a technique to that of random sampling is taken as theutilityof the technique.
We approach these questions from two directions. First,
we consider a simple theoretical framework in which to eval-
uate the improvement in eﬀectiveness for the best muta-
tion reduction possible, using a few simplifying assump-
tions, and given oracular knowledge of mutation kills. Thishelps set the base-line. Second, we empirically evaluatethe best mutation reduction possible for a large number ofprojects, given post hoc (that is, oracular) detection knowl-edge. This gives us practical (and optimistic) limits given
common project characteristics.
Our contributions are as follows:
•We ﬁnd a theoretical upper limit for the eﬀectiveness
of mutation reduction strategies of 58.2% for a uni-form distribution of mutants — the distribution most
favorable for random sampling. We later show that for
real world programs, the impact of distribution is verysmall (4.467%) suggesting that uniform distribution isa reasonable approximation.
•Weﬁndanempiricalupperlimitforeﬀectivenessthroughtheevaluationofalargenumberofopensourceprojects,
which suggests a maximum practical utility of 13.078%
on average, and for 95% of projects, a maximum util-ity between 12.218% and 14.26% (one sample u-testp<0.001)
1.
•We show that even if we consider a set of mutants
that are distinguished by at least by one test (thus dis-
counting the impact of skew in redundant mutants) wecan expect a maximum utility of 17.545% on average,and for 95% of projects, a maximum utility between
16.912% and 18.876% (one sample u-test p<0.001).
What do our results mean for the future of mutation re-
duction strategies? Any advantage we gain over randomsampling is indeed an advantage, however small. However,
our understanding of mutant semiotics
2is as yet imperfect,
and insuﬃcient to infer whether the kind of selection em-ployed is advantageous. In fact, our current research [24]shows that current operator selection strategies seldom pro-
vide any advantage over random sampling, and even strata
sampling based on program elements never achieves morethan a 10% advantage over pure random sampling. Our re-sults suggest that the eﬀort spent towards improving mutant
selection mechanisms should be carefully weighed against
1We use the non-parametric Mann-Whitney u-testas it is
more robust to normality assumption, and to outliers. We
note that a t-testalso gives similar results.
2Here semiotics is the relation between a syntactic change
and its semantic impact.the potential maximum utility, and the risks associated with
actually making things worse through biased sampling.
Ourresearchisalsoanendorsementof theneed forfurther
research into new mutators. It suggests that addition of newmutators and then randomly sampling the same number ofmutantsasthatoftheoriginalset, isonlysubjecttoasimilarmaximumdisadvantage(
0.189× 100
1−0.189=23.268%upperlimitfor
95% projects), while having essentially no upper bound on
advantage due to increase in eﬀectiveness.
The asymmetry between improvement obtained by opera-
tor removal and operator addition is caused by the diﬀerence
in population from which the random comparison sample is
drawn. For operator selection, the perfect set remainingafter removal of operators is a subset of the original popu-
lation. Since the random sample is drawn from the originalpopulation, it can potentially contain a mutant from each
strata in the perfect set. For operator addition, the newperfect set is a superset of the original population, with asmany new strata as there are new mutants (no bounds onthe number of new strata). Since the random sample is con-
structed from the original population, it does not containthe newly added strata.
Our results suggest a higher payoﬀ in ﬁnding newer cate-
goriesof mutations, than in trying to reduce the mutation
operators already available.
In the interests of easy replication, our research is orga-
nized and reproducible using Knitr. The raw Knitrsource
of our paper along with the Rdata set required to build the
paper, and the instructions to do so, are available [ 23].
2. RELATED WORK
According to Mathur [ 39], the idea of mutation analysis
was ﬁrst proposed by Richard Lipton, and formalized by
DeMillo et al. [17 ] A practical implementation of mutation
analysis was done by Budd et al. [ 10] in 1980.
Mutationanalysissubsumesdiﬀerentcoveragemeasures[ 9,
40,45]; the faults produced are similar to real faults in terms
of the errors produced [15] and ease of detection [4 ,5]. Just
et al. [32] investigated the relation between mutation score
and test case eﬀectiveness using 357 real bugs, and foundthat the mutation score increased with eﬀectiveness for 75%
of cases, which was better than the 46% reported for struc-
tural coverage.
Performingamutationanalysisisusuallycostlyduetothe
large number of test runs required for a full analysis [31].
There are several approaches to reducing the cost of mu-tation analysis, categorized by Oﬀutt and Untch [44 ]a s :
dofewer,d osmarter, and do faster.T h edo fewer ap-
proaches include selective mutation and mutant sampling,while weak mutation, parallelization of mutation analysis,
and space/time trade-oﬀs are grouped under the umbrella
ofdo smarter .F i n a l l y , t h e do faster approaches include
mutant schema generation, code patching, and other meth-ods.
The idea of using only a subset of mutants was conceived
along with mutation analysis itself. Budd [ 9] and Acree [ 1]
showed that even 10% sampling approximates the full muta-tionscorewith99%accuracy. Thisideawasfurtherexploredby Mathur [ 38], Wong et al. [ 50,51], and Oﬀutt et al. [43 ]
using Mothra [16] for Fortran.
512A number of studies have looked at the relative merits of
operator selection and random sampling criteria. Wong et
al. [50] compared x% selection of each mutant type with op-erator selection using just two mutation operators and foundthat both achieved similar accuracy and reduction (80%).Mresa et al. [ 41] used the cost of detection as a means of
operator selection. They found that if a very high muta-
tion score (close to 100%) is required, x% selective mutation
is better than operator selection, and, conversely, for lowerscores, operator selection would be better if the cost of de-tecting mutants is considered.
Zhang et al. [ 54] compared operator-based mutant selec-
tion techniques to random sampling. They found that noneof the selection techniques were superior to random sam-pling. They also found that uniform sampling is more ef-
fective for larger programs compared to strata sampling on
operators
3, and the reverse is true for smaller programs. Re-
cently, Zhang et al. [ 53] conﬁrmed that sampling as few as
5% of mutants is suﬃcient for a very high correlation (99%)
withthefullmutationscore, withevenfewermutantshavinga good potential for retaining high accuracy. They inves-tigated eight sampling strategies on top of operator-basedmutant selection and found that sampling strategies basedon program components (methods in particular) performedbest.
Some studies have tried to ﬁnd a set of suﬃcient mutation
operators that reduce the cost of mutation but maintain
correlation with the full mutation score. Oﬀutt et al. [ 43]
suggested an n-selective approach with step-by-step removal
of operators that produce the most numerous mutations.Barbosa et al. [ 8] provided a set of guidelines for selecting
such mutation operators. Namin et al. [ 42,47]f o r m u l a t e d
the problem as a variable reduction problem, and found thatjust 28 out of 108 operators in Proteum were suﬃcient for
accurate results.
Using only the statement deletion operator was ﬁrst sug-
gested by Untch [ 49], who found that it had the highest cor-
relation ( R
2=0.97) with the full mutation score compared
to other operator selection methods, while generating the
smallest number of mutants. This was further reinforced byDeng et al. [18] who deﬁned deletion for diﬀerent languageelements, and found that an accuracy of 92% is achievedwhile reducing the number of mutants by 80%.
A similar mutation reduction strategy is to cluster similar
mutations together [20, 27], which has been attempted based
on domain analysis [ 28] and machine learning techniques
based on graphs [ 48].
In operator and mutant subsumption, operators or mu-
tants that do not signiﬁcantly diﬀer from others are elimi-nated. Kurtz et al. [35 ] found that a reduction of up to 24
times can be achieved using subsumption alone, even thoughthe result is based on an investigation of a single program,
cal. Research into subsumption of mutants also includes
Higher Order Mutants (HOM), whereby multiple mutationsare introduced into the same set of mutants, reducing thenumber of individual mutants by subsuming component mu-
tants. HOMs were investigated by Jia et al. [ 29,30], who
found that they can reduce the number of mutants by 50%.
Ammannetal.[3]observethatthesetofminimalmutants
corresponding to a minimal test suite has the same cardi-
3The authors choose a random operator, and then a mu-
tant of that operator. This is in eﬀect strata sampling on
operators given equal operator priority.nality as the test suite, and provides a simple algorithm
for ﬁnding both a minimal test suite and a correspondingminimal mutant set. Their work also suggests this minimalm u t a n ts e ta saw a yt oe v a l u a t et h eq u a l i t yo fam u t a t i o nreduction strategy. Finally, Ammann et al. also found thatthe particular strategies examined are rather poor when itcomes to selecting representative mutants. Our work is anextension of Ammann et al. [ 3] in that we provide a theo-
retical and empirical bound to the amount of improvementthat can be expected by anymutation reduction strategy.
In comparison with previous work [53, 54] our analysis
is backed by theory and compares random sampling to thelimit of selection . That is, the results from our study are ap-
plicable to techniques such as clustering using static analy-sis, and even improved strata sampling techniques. Further,we are the ﬁrst to evaluate the eﬀectiveness of non-adequate
test suites (Zhang et al. [ 53] evaluates only the predictive
power of non-adequate test suites, not eﬀectiveness). Fi-
nally, previous research [ 53,54] does not compare the eﬀec-
tiveness of the same number of mutants for sampling and
operator selection, but rather diﬀerent operator-selections
with samples of increasing size such as 5%, 10% etc. We be-
lieve that practitioners will be more interested in comparingthe eﬀectiveness achieved by the same numbers of mutants.
3. THEORETICAL ANALYSIS
The ideal outcome for a mutation reduction strategy is to
ﬁndtheminimumsetofmutantsthatcanrepresentthecom-plete set of mutants. A mutation reduction strategy accom-
plishes this by identifying redundant mutants and grouping
them together so that a single mutant is suﬃcient to rep-resent the entire group. The advantage of such a strategyover random sampling depends on two characteristics of the
mutant population. First, it depends on the number of re-dundant mutants in each group of such mutants. Random
sampling works best when these groups have equal numbersof mutants in them (uniform distribution), while any otherdistribution of mutants (skew) results in lower eﬀectiveness
ofrandomsampling. However, thisdistributionisdependent
on the program being evaluated. Since our goal is to ﬁndthe mean advantage for a perfect strategy for an arbitrary
program, we use the conservative distribution (uniform) ofmutants for our theoretical analysis (we show later that the
actual impact of this skew is less than 5% for real world
mutants).
The next consideration regards the minimum number of
mutants required to represent the entire population of mu-
tants. If a mutant can be distinguished from another in
terms of tests that detect it, then we consider both to bedistinguishable from each other in terms of faults they rep-
resent, and we pick a representative from each set of indis-tinguishable mutants. Note that, in the real world, the pop-
ulation of distinguishable mutants is often larger than the
minimum number of mutants required to select a minimum
test suite
4able to kill the entire mutant population. This is
4Aminimum testsuitewithrespecttoasetofmutantsisthe
smallest test suite that can kill all mutants in the set, and
aminimal test suite is a test suite from which no further
tests can be removed without decreaseing mutation score.Our approach tries to approximate the actual minimum test
suite using the greedyalgorithm that has an approximation
bound of k·ln(n) where kis the true minimum, and nis the
number of elements. Since we have a strong bound on the
513because while some mutants are distinguishable from others
in terms of tests that detect them, there may not be anytest that uniquely kills them
5. Since this is external to the
mutant population, and also because such a minimum setof mutants does not represent the original population fully(we can get away with a lower number only because the testsuiteisinadequate), weassumethatdistinguishablemutants
are uniquely identiﬁed by test cases. We note however, that
having inadequate test suites favors random sampling, and
hence lowers the advantage for a perfect mutation reduc-tion strategy, because random sampling can now miss themutant without penalty. We derive the limits of mutation
reduction for this system using the best strategy possible,g i v e no r a c u l a rk n o w l e d g eo fm u t a n tk i l l s .Impact of deviations of parameters:Skew:The presence of skew reduces the eﬀectiveness of ran-
dom sampling, and hence increases the utility of the perfectstrategy.Distinguishability: Any distinguishable mutant that is not
chosen by the strategy (due to not having a unique detectingtest case) decreases the eﬀectiveness of the selection strat-egy, decreasing its utility.
Before establishing a theoretical framework for utility of
mutation reduction strategies, we must establish some ter-minology for the original and reduced mutant sets and theirrelated test suites.
Terminology :L e t Mand M
strategydenote the original
set of mutants and the reduced set of mutants, respectively.
The mutants from Mkilled by a test suite Tare given by
kill(T,M) (We use Mkilledas an alias for kill(T,M)). Sim-
ilarly the tests in Tthat kill mutants in Mare given by
cover(T,M).
kill : T×M→M
cover : T×M→T
The test suite Tstrategycan kill all mutants in Mstrategy.
That is, kill(Tstrategy ,M strategy)=M strategy.I fi ti sm i n i -
mized with respect to the mutants of the strategy, we denote
it by Tmin
strategy.
Two mutants mand m/primeare distinguished if the tests that
kill them are diﬀerent: cover(T,{m})/negationslash=cover(T,{m/prime}).
We use Muniq
killedto denote the set of distinguished mutants
from the original set such that ∀m,m/prime∈Mcover(T,{m})/negationslash=
cover(T,{m/prime}).
Theutility(Ustrategy) of a strategy is improvement in ef-
fectiveness due to using that strategy compared to the base-
line (the baseline is random sampling of the same number6
of mutants). That is,
Ustrategy=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglekill(Tmin
strategy ,M)
kill(Tmin
random ,M)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle−1
approximation, and since the algorithm is robust in practice,
we use the minimal computed by the greedyalgorithm as a
proxy for the minimum test suite .
5Consider the mutant ×test matrix (1 implies the test kills
the mutant) {{1,1,0},{1,0,1},{0,1,1}}. While all the mu-
tants are distinguishable, just two test cases are suﬃcient tokill them all.
6For the rest of the paper, we require that eﬃciency of ran-
dom sampling is the same as that of the strategy it is com-pared to, i.e. |M
strategy|=|Mrandom|.Note that Tmin
strategyis minimized over the mutants selected
by the strategy, and it is then applied against the full set
of mutants (M )i nkill(Tmin
strategy ,M).
This follows the traditional evaluation of eﬀectiveness,
which goes as follows: start with the original set of mutants,
and choose a subset of mutants according to the strategy.Then select a minimized set of test cases that can kill allthe selected mutants. This minimized test suite is evaluated
against the full set of mutants. If the mutation score ob-
tained is greater than 99%, then the reduction is deemed tobe eﬀective. Note that we compare this score against thescore of a random set of mutants of the same size, in order
to handle the case where the full suite itself is not mutation
adequate (or even close to adequate). Our utility answersthe question: does this set of mutants better represent thetest adequacy criteria represented by the full set of mutantsthan a random sample of the same size, and if so, by how
much?
The strategy that can select the perfect set of represen-
tative mutants (the smallest set of mutants such that they
have the same minimum test suite as the full set) is called
theperfect strategy , with its utility denoted by U
perfect7.
We now show how to derive an expression for the max-
imum Uperfectfor the idealized system with the following
restrictions.
1. Weassumethatwehaveanequalnumberofredundant
mutants for each distinguished mutant.
From here on, we refer to a set of non-distinguished mu-
t a n t sa sastratum, and the entire population is referred to as
thestrata. Given any population of detected mutants, the
mutation reduction strategy should produce a set of mu-
tants such that if a test suite can kill all of the reduced
set, the same test suite can kill all of the original mutantset (remember that T
strategyk i l l sa l lm u t a n t si n Mstrategy).
Hence,
kill(Tperfect ,M)=kill(T,M)
The quality of the test suite thus selected is dependent onthe number of unique mutants that we are able to sample.
Since we have supposed a uniform distribution, say we have
xelements per stratum, and total nmutants. Our sample
size swould be p×kwhere kis the number of strata, p
is the number of samples from each stratum, and is a nat-ural number; i.e. the sample would contain elements fromeach stratum, and those would have equal representation.
Note that there will be at least one sample, and one strata:
i.e., s≥1. Since our strata are perfectly homogeneous by
construction, in practice p= 1 is suﬃcient for perfect rep-
resentation, and as we shall see below, ensures maximal ad-vantage over random sampling.
Next, we evaluate the number of diﬀerent (unique) strata
expected in a random sample of the same size s.
LetX
ibe a random variable deﬁned by:
Xi=/braceleftBigg
1i f s t r a t a iappears in the sample
0o t h e r w i s e .
LetXbe the number of unique strata in the sample, which
isgivenby: X=/summationtextk
i=1Xi, andtheexpectedvalueofX(con-
7Where unambiguous, we shorten the subscript such as p
forperfect,a n drforrandom.
514sidering that all mutants have equal chance to be sampled)
is given by:
E(X)=E(k/summationdisplay
i=1Xi)=k/summationdisplay
i=1E(Xi)=k×E(X1)
Next, consider the probability that the mutant 1 has beenselected, where the sample size was s=p×k:
P[X
i=1 ]=1 −/parenleftbiggk−1
k/parenrightbiggpk
The expectation of Xi:
E(X1)=1×P(Xi=1 )
Hence, the expected number of unique strata appearing ina random sample is:
k×E(X
1)=k−k×/parenleftbiggk−1
k/parenrightbiggpk
We already know that the number of uniquestrata appear-
ing in each strata-based sample is k(because it is perfect,
so each strata is unique). Hence, we compute the utility asthe diﬀerence divided by the baseline.
U
max=k−/parenleftBig
k−k×/parenleftbigk−1
k/parenrightbigpk/parenrightBig
k−k×/parenleftbigk−1
k/parenrightbigpk=1
(k
k−1)pk−1(1)
This converges to8
lim
k→∞1
(k
k−1)pk−1=1
ep−1(2)
and has a maximum value when p=1 .
Umax=1
e−1≈58.2% (3)
Note that this is the meanimprovement expected over ran-
domsamplingfor uniform distribution ofredundantmutants
in strata (and with oracular knowledge). That is, individ-ual samples could still be arbitrarily advantageous (after all,the perfect strata sample itself is one potential random sam-
ple), but on average this is the expected gain over random
samples.
How do we interpret this result? If you have a robust set
of test cases that is able to uniquely identify distinguishable
mutants, then given an arbitrary program, you can expect
a perfect strategy to have at least a mean 58 .2% advantage
over random sample of the same eﬃciency in terms of eﬀec-
tiveness. However, if the program produces redundant mu-
tants that are skewed, then the advantage of perfect strat-
egy with oracular knowledge will increase (depending on theamount of skew). Similarly, if the tests are not suﬃcient
to identify distinguishable mutants uniquely, we can expect
the advantage of the perfect strategy to decrease. Finally,strategies can rarely be expected to come close to perfectionin terms of classifying mutants in terms of their behavior
without post hoc knowledge of the kills. Hence the advan-tage held by such a strategy would be much much lower (or
it may not even have an advantage).
8W h i l ew ec a ne x p e c tk to be ﬁnite for mutation testing, we
are looking at the maximum possible value for this expres-
sion.Table 1: PIT Mutation Operators. The (*) operators were
added or extended by us.
IN Remove negative sign from numbers
RV Mutate return values
M Mutate arithmetic operators
VMC Remove void method calls
NC Negate conditional statementsCB Modify boundaries in logical conditions
I Modify increment and decrement statements
NMC Remove non-void method calls, returning default value
CC Replace constructor calls, returning null
IC Replace inline constants with default value
RI* Remove increment and decrement statements
EMV Replace member variable assignments with default value
ES Modify switch statements
RS* Replace switch labels with default (thus removing them)
RC* Replace boolean conditions with true
DC* Replace boolean conditions with false
●●
●●
●
●●●
●
●●
●●
●
●●
●●
●●
●●
●●●
●●
● ●●
●●
●●
●●●
● ●
255075
1,000 10,000 100,000
MutantsMutation Scorelog10(Tests)
●
●
●2.5
3.03.5Projects
Figure 1: Distribution of number of mutants and test
suites. It shows that we have a reasonable non-biased
sample with both large programs with high mutation
scores, and also small low scoring projects.
4. EMPIRICAL ANALYSIS
The above analysis provides a theoretical framework for
evaluating the advantage a sampling method can have over
random sampling, with a set of mutants and test suite con-
structed with simplifying assumptions. It also gives us anexpected limit for how good these techniques could get for
a uniform distribution of mutants. However, in practice, itis unlikely that real test suites and mutant sets meet our as-
sumptions. What advantage can we expect to gain with real
software systems, even if we allow our hypothetical methodto make use of prior knowledge of the results of mutationanalysis? To ﬁnd out, we examine a large set of real-worldprograms and their test suites.
Our selection of sample programs for this empirical study
of the limits of mutation reduction was driven by a few over-riding concerns. Our primary requirement was that our re-sults should be as representative as possible of real-worldprograms. Second, we strove for a statistically signiﬁcant
result, therefore reducing the number of variables present
in the experiments for reduction of variability due to theirpresence.
We chose a large random sample of Java projects from
Github [ 22]
9and the Apache Software Foundation [6] that
use the popular Maven [7] build system. From an initial
1,800projects, weeliminatedaggregateprojects, andprojects
without test suites, which left us with 796 projects. Out of
9Github allows us access only a subset of projects using their
search API. We believe this should not confound our results.
515nmc rv ic dc nc rc vmc cc emv m cb i ri rs es in
nmc
rv
ic
dc
nc
rc
vmc
cc
emv
m
cb
i
ri
rs
es
in1
0.030.13
0.11
0.05
0.09
0.21
0.04
0.1
0.22
0.23
0.14
0.32
0.26
0.15
0.360.06
1
0.13
0.11
0.05
0.09
0.21
0.04
0.1
0.22
0.23
0.14
0.32
0.26
0.15
0.360.050.03
1
0.11
0.05
0.09
0.21
0.04
0.1
0.22
0.23
0.14
0.32
0.26
0.15
0.360.060.03
0.13
1
0.05
0.09
0.21
0.04
0.1
0.23
0.23
0.14
0.33
0.27
0.15
0.430.060.03
0.13
0.11
1
0.09
0.21
0.04
0.1
0.22
0.23
0.14
0.32
0.26
0.15
0.360.060.03
0.13
0.11
0.05
1
0.21
0.04
0.1
0.22
0.23
0.14
0.32
0.26
0.15
0.360.05
0.03
0.13
0.11
0.05
0.09
1
0.04
0.1
0.22
0.22
0.14
0.32
0.27
0.15
0.360.06
0.03
0.13
0.11
0.05
0.09
0.21
1
0.09
0.23
0.22
0.14
0.32
0.25
0.15
0.360.06
0.03
0.13
0.11
0.05
0.09
0.21
0.04
1
0.22
0.22
0.13
0.31
0.27
0.15
0.360.05
0.03
0.1
0.1
0.05
0.09
0.24
0.04
0.11
1
0.23
0.13
0.31
0.27
0.16
0.360.050.03
0.11
0.09
0.05
0.08
0.2
0.04
0.09
0.22
1
0.14
0.32
0.26
0.14
0.360.05
0.03
0.11
0.09
0.04
0.07
0.21
0.04
0.1
0.2
0.18
1
0.32
0.26
0.14
0.380.05
0.03
0.11
0.09
0.04
0.07
0.21
0.04
0.09
0.2
0.18
0.13
1
0.26
0.14
0.380.05
0.04
0.11
0.09
0.04
0.07
0.2
0.04
0.08
0.19
0.17
0.13
0.28
1
0.15
0.340.05
0.04
0.11
0.09
0.04
0.07
0.2
0.04
0.08
0.19
0.17
0.13
0.28
0.26
1
0.340.040.03
0.12
0.15
0.05
0.07
0.25
0.04
0.07
0.13
0.24
0.15
0.23
0.14
0.1
1
Figure 2: Subsumption rate between operators. Note that
subsumption is not a symmetrical relation. No operators
come close to full subsumption. This suggests that none
of the operators studied are redundant .
these, 326 projects compiled (common reasons for failure in-
cluded unavailable dependencies, compilation errors due tosyntax, and bad conﬁgurations). Next, projects that did notpass their own test suites were eliminated since the analy-
sis requires a passing test suite. Tests that timed out forparticular mutants were assumed to have not detected the
mutant. The tests that completely failed to detect any ofthe mutants were eliminated as well, as these were redun-dant to our analysis. We also removed all projects with
trivial test suites, leaving only those that had at least 100
test cases. This left us with 39 projects. The projects are
g i v e ni nT a b l e 2.
We used PIT [ 13] for our analysis. PIT was extended to
provideoperatorsthatitwaslacking[ 2](acceptedintomain-
line). Wealsoensuredthattheﬁnaloperators(Table 1)w ere
not redundant. The redundancy matrix for the full operator
set is given in Figure 2.Am u t a n t m1is deemed to subsume
another, say m2if any tests that kills m1is guaranteed to
killm2. This is extended to mutation operators whereby the
fraction of mutants in o1killed by test cases that kills all
mutants in o2istakenasthe degreeofsubsumptionof o1by
o2. The matrix shows that the maximum subsumption was
just 43% — that is, none of the operators were redundant.For a detailed description of each mutation operator, pleaserefer to the PIT documentation [ 14]. To remove the eﬀects
of random noise, results for each criteria were averaged overten runs. The mutation scores along with the sizes of test
suites are given in Figure 1.
It is of course possible that our results may be biased
by the mutants that PIT produces, and it may be argued
that the tool we use produces too many redundant mutants,
and hence the results may not be applicable to a better tool
that reduces the redundancy of mutants. To account for thisargument, we run our experiment in two parts, with similarprocedures but with diﬀerent mutants. For the ﬁrst part, we
use the detected mutants from PIT as is, which provides uswith an upper bound that a practicing tester can expect toTable 2: The projects mutants and test suites
Pro je c t |M|Mkilled Muniq
killed |T|| Tmin|
events 1171 702 59 180 33.87
annotation-cli 992 589 110 109 38.97
mercurial-plugin 2069 401 102 138 61.77fongo 1461 1209 175 113 70.73
conﬁg-magic 1188 721 204 112 74.55
clazz 5242 1583 151 140 64.00
ognl 21852 12308 2990 114 85.43
java-api-wrapper 1715 1304 308 125 107.04
webbit 3780 1981 325 147 116.93
mgwt 12030 1065 168 101 90.65
csv 1831 1459 411 173 117.97
joda-money 2512 1272 236 173 128.48
mirror 1908 1440 532 301 201.21
jdbi 7754 4362 903 277 175.57
dbutils 2030 961 207 224 141.53
cli 2705 2330 788 365 186.24
commons-math1-l10n 6067 2980 219 119 109.02mp3agic 7344 4003 730 206 146.79
asterisk-java 15530 3206 451 214 196.32
pipes 3216 2176 338 138 120.00
hank 26622 7109 546 171 162.88
java-classmate 2566 2316 551 215 196.57
betwixt 7213 4271 1198 305 206.35
cli2 3759 3145 1066 494 303.86
jopt-simple 1818 1718 589 538 158.37
faunus 9801 4809 553 173 146.11
beanutils2 2071 1281 465 670 181.00
primitives 11553 4125 1365 803 486.71
sandbox-primitives 11553 4125 1365 803 488.56validator 5967 4070 759 383 264.35
xstream 18030 9163 1960 1010 488.25
commons-codec 9983 8252 1393 605 444.69
beanutils 12017 6823 1570 1143 556.67
conﬁguration 18198 13766 4522 1772 1058.36
collections 24681 8561 2091 2241 938.32
jfreechart 99657 32456 4686 2167 1696.86
commons-lang3 32323 26741 4479 2456 1998.11
commons-math1 122484 90681 17424 5881 4009.98
jodatime 32293 23796 6920 3973 2333.49
experience, now, using an industry-accepted tool. For thesecond part, we choose only distinguishable mutants [3] from
the original set of detected mutants. What this does is toreduce the number of samples from each stratum to 1, and
hence eliminate the skew in mutant population. Note that
this requires post-hoc knowledge of mutant kills (not justthat the mutants produce diﬀerent failures, but also thatavailable tests in the suite can distinguish between both),
and is the best one can do for the given projects to enhance
the utility of any strategy against random sampling. We
provide results for both the practical and more theoreticallyinteresting distinguishable sets of mutants. Additionally, incase adequacy has an impact, we chose the projects that had
plausible mutation-adequate test suites, and computed the
possible advantage separately.
4.1 Experiment
O u rt a s ki st oﬁ n dt h e Uperfectfor each project. The
requirements for a perfect strategy are simple:
1. The mutants should be representative of the full set.
That is,
kill(Tp,M)=kill(T,M)
2. The mutants thus selected should be non-redundant.
That is,
∀m∈Mpkill(Tp,M p\{m})⊂kill(Tp,M p)
516The minimal mutant set suggested by Ammann et al. [ 3]s a t -
isﬁes our requirements for a perfect strategy, since it is rep-
resentative — a test suite that can kill the minimal mutantscan kill the entire set of mutants — and it is non-redundantwith respect to the corresponding minimal test suite.
Ammann et al. [3] observed that the cardinality of a min-
imal mutant set is the same as the cardinality of the corre-
sponding minimal test suite. That is,
|M
min
perfect|=|MinT est (T,M)|=|Tmin
all|
Finding the true minimal test suite for a set of mutants is
NP-complete10. The best possible approximation algorithm
is Chvatal’s [ 12], using a greedy algorithm where each iter-
ation tries to choose a set that covers the largest number of
mutants. This is given in Algorithm 1. In the worst case,
i ft h en u m b e ro fm u t a n t si sn , and the smallest test suite
that can cover it is k, this algorithm will achieve a k·ln(n)
approximation. We note that this algorithm is robust inpractice, and usually gets results close to the actual mini-
mum k(see Figure 3). Further, Feige [21 ] showed that this is
the closest approximation ratio that an algorithm can reachf o rs e tc o v e rs ol o n ga sNP /negationslash=P
11.
Since it is an approximation, we average the greedily esti-
mated minimal test suite size over 100 runs. The variabilityi sg i v e ni nF i g u r e3, ordered by the size of minimal test suite.Note that there is very little variability, and the variabilitydecreases as the size of test suite increases. All we need now
is to ﬁnd the eﬀectiveness of random sampling for the same
number of mutants as produced by the perfectstrategy.
Algorithm 1 Finding the minimal test suite
function MinTest(T ests, Mutants)
T←T ests
M←kill(T,Mutants )
Tmin←∅
while T/negationslash=∅∨M/negationslash=∅do
t←random(max
t|kill({t},M)|)
T←T\{t}
M←kill(T,Mutants )
Tmin←Tmin∪{t}
end whilereturn T
min
end function
Next, we randomly sample |Mmin
perfect|mutants from the
original set Mrandom, obtain the minimal test suite of this
sample Tmin
random, and ﬁnd the mutants from the original set
that are killed by this test suite kill(Tmin
random ,M), which is
used to compute the utility of perfect strategy with respectto that particular random sample. The experiments were re-
10This is the Set Covering Problem [3] which is NP-
Complete [33].
11Weavoidedthe reverse greedy algorithm givenbyAmmann
et al. [3] for two reasons. First, while the approximation
ratioofthe greedyalgorithmisatmost k·ln(n)where kisthe
actual minimum, that of reverse greedy is much larger [26]
(if any). Secondly, the number of steps involved in reverse
greedyismuchlargerthanin greedywhenthesizeofminimal
set is very small compared to the full set. We also veriﬁedthat the minimum frequency o fk i l l so ft h es e to fm u t a n t sb y
the minimal test suite was 1. A larger minimum frequency
indicates that at least that many tests are redundant, whichis a rare but well-known problem with the greedyalgorithm.●● ● ●
●
●
●●
●
●● ●
●
● ● ●●
●●
● ●● ●
●●
●●
● ●●
● ●● ● ● ●
● ●●
● ● ●● ● ● ● ● ●
●●
●●
●● ●
● ● ●● ● ●
●●
● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●●
● ● ●●
●●
● ● ● ●● ●
●
●● ●
●●
●●
●●
●●●●
●
−4048
ProjectsMinTCMinTC Distribution
Figure 3: Variation of minimal test cases for each sample
as a percentage diﬀerence from the mean ordered by mean
minimal test suite size. There is very little variation, and
the variation decreases with test suite size.
●●●
●
●●
●●
●●●
●●
●● ●●
●●
●
●●
●●
●●
●●●
●
●●●
●●●●
●●
0.050.100.15
1000 2000 3000 40005000
Minimal test suite sizeutilityDetected mutants (log10)
●
●
●
●3.0
3.54.0
4.5
Figure 4: The ﬁgure plots utility (y-axis) against the
average minimal test suite size (log10). Bubble size
represents the magnitude of detected mutants (log10). The
ﬁgure suggests that there is no correlation between utility
and average minimal test suite size.
peated 100 times for each project, and averaged to compute
Uperfectfor the project under consideration.
5. RESULTS
5.1 All Mutants
Our results are given in Table 3. We found that the
largest utility achieved by the perfect strategy was 17.997%,
for project faunus, while the lowest utility was 1.153%, for
projectjoda-money. The mean utility of the perfect strat-
●●●
●
●●
●●
●●●
●●
●● ●●
●●
●
●●
●●
●●
●●●
●
●●●
●●●●
●●
0.050.100.15
25000 50000 75000
Number of detected mutantsutility Minimal test suite (log10)
●
●
●2.5
3.03.5
Figure 5: The ﬁgure plots utility (y-axis) against the
number of detected mutants. Bubble size represents the
magnitude of average minimal test suite size (log10). The
ﬁgure suggests that there is no correlation between utility
a n dn u m b e ro fd e t e c t e dm u t a n t s .
517Table 3: The maximum utility achievable by a perfect
strategy for each project
Pro je c t |kill(T,M)||kill(Tr,M)|Uperf
events 702 662.97 0.06
annotation-cli 589 529.51 0.11
mercurial-plugin 401 342.91 0.17
fongo 1209 1052.99 0.15
conﬁg-magic 721 640.91 0.13
clazz 1583 1402.39 0.13
ognl 12308 11426.09 0.08
java-api-wrapper 1304 1148.52 0.14
webbit 1981 1793.96 0.10
mgwt 1065 949.96 0.12
csv 1459 1282.93 0.14
joda-money 1272 1257.55 0.01
mirror 1440 1252.50 0.15
jdbi 4362 3914.73 0.11
dbutils 961 854.83 0.12
cli 2330 2069.84 0.13
commons-math1-l10n 2980 2527.66 0.18
mp3agic 4003 3620.41 0.11
asterisk-java 3206 2754.69 0.16
pipes 2176 1884.73 0.16
hank 7109 6200.08 0.15
java-classmate 2316 1969.76 0.18
betwixt 4271 3809.19 0.12
cli2 3145 2760.66 0.14
jopt-simple 1718 1546.21 0.11
faunus 4809 4078.22 0.18
beanutils2 1281 1141.73 0.12
primitives 4125 3565.83 0.16
sandbox-primitives 4125 3563.85 0.16
validator 4070 3616.71 0.13
xstream 9163 8307.12 0.10
commons-codec 8252 7455.50 0.11
beanutils 6823 6071.53 0.12
conﬁguration 13766 12359.89 0.11
collections 8561 7392.63 0.16
jfreechart 32456 28171.19 0.15
commons-lang3 26741 22742.46 0.18
commons-math1 90681 81898.25 0.11
jodatime 23796 20491.96 0.16Table 4: The maximum utility achievable by a perfect
strategy for each project using distinguishable mutants
Pro je c t |kill(T,M)||kill(Tr,M)|Uperf
events 59 49.15 0.20
annotation-cli 110 93.68 0.18
mercurial-plugin 102 80.95 0.26
fongo 175 145.13 0.21
conﬁg-magic 204 171.60 0.19
clazz 151 129.24 0.17
ognl 2990 2835.77 0.05
java-api-wrapper 308 259.87 0.19
webbit 325 280.89 0.16
mgwt 168 140.60 0.20
csv 411 349.30 0.18
joda-money 236 230.76 0.02
mirror 532 444.17 0.20
jdbi 903 783.99 0.15
dbutils 207 170.60 0.21
cli 788 688.05 0.15
commons-math1-l10n 219 177.86 0.23mp3agic 730 639.01 0.14
asterisk-java 451 372.25 0.21
pipes 338 288.41 0.17
hank 546 465.52 0.17
java-classmate 551 450.46 0.22
betwixt 1198 1055.30 0.14
cli2 1066 903.30 0.18
jopt-simple 589 514.36 0.15
faunus 553 467.03 0.18
beanutils2 465 392.30 0.19
primitives 1365 1155.09 0.18
sandbox-primitives 1365 1155.01 0.18
validator 759 647.36 0.17
xstream 1960 1691.84 0.16
commons-codec 1393 1192.29 0.17
beanutils 1570 1341.04 0.17
conﬁguration 4522 3934.21 0.15
collections 2091 1750.05 0.19
jfreechart 4686 3910.15 0.20
commons-lang3 4479 3663.98 0.22
commons-math1 17424 15139.90 0.15
jodatime 6920 5801.10 0.19
Table 5: The correlation of utility for all mutants, killed
mutants, mutation score, and minimal test suite size, based
on both full set of mutants, and also considering only
distinguished mutants
R2
all R2
distinguished
M-0.02 -0.03
Mkill-0.03 -0.01
Mkill/M-0.02 -0.00
Tmin-0.01 -0.02
egy was 13.078%. A one sample u-testsuggests that 95% of
projectshavemaximumutilitybetween12.218%and14.26%(p<0.001). The distribution of utility for each project is
captured in Figure 6. Projects are sorted by average mini-
mal test suite size.
One may wonder if the situation improves with either test
suite size or project size. We note that the utility U
phas low
correlation with total mutants, detected mutants (shown in
Figure5), mutationscore, andminimaltestsuitesize(shown
in Figure 4). The correlation factors are given in Table 5.
An analysis of variance (ANOVA) to determine signiﬁcant
variables aﬀecting Uperfectsuggests that the variability due
to project is a signiﬁcant factor (p<0 .001) and interactswith kill(Trandom ,M) strongly.
μ{Up}=project+kill(Tr,M)+project ×kill(Tr,M)
The variable projecthas a correlation of 0.682 with the
Uperfect, andthecombinedtermshaveacorrelationof0 .9995
with Uperfect.
5.2 Distinguishable Mutants
Our results are given in Table 4. We found that the
largest utility achieved by the perfect strategy was 26.159%,for project mercurial-plugin, while the lowest utility was
2.283%, for project joda-money.
The mean utility of the perfect strategy was 17.545%. A
one sample u-testshowed that 95% of projects have a max-
imum utility between 16.912% and 18.876% ( p<0.001).
The utility distribution for each project is captured in
Figure7. The projects are sorted by the average minimal
test suite size.
This situation does not change with either test suite or
project size.
The utility U
phas low correlation with total mutants, de-
tected mutants, mutation score, and minimal test suite size.
The correlation factors are given in Table 5.
An analysis of variance (ANOVA) to determine signiﬁcant
518●●●
●
●
●●●
●●●●
●●
●
●●●
●●●●●
●●●●
●●●
●●●
●●●
●●●
●
●
●
●●
●
0.00.10.20.3
ProjectsMaximum Utility"red"
redUtility Distribution of All Mutants
Figure 6: Using all mutants.●
●●
●
●●
● ● ●
●
●
●●●●
●●●
● ●
●●●
●●●●
● ● ● ●● ●●
●●●
●●●● ●
●
●
●
●●●●
●●
●●
●● ●●
●●●
●●
●
●●●
●●●●
●●
●●●
●
0.00.10.20.30.4
ProjectsMaximum Utility"red"
redUtility Distribution of Distinguished Mutants
Figure 7: Using distinguished mutants.
Distribution of mean utility using distinguished mutants across projects. The projects are ordered by the cardinality of
mean minimal test suite. The red line indicates the mean of all observations.
variables aﬀecting Uperfectfound that the variability due
to project is a signiﬁcant factor ( p<0 .001) and strongly
interacts with kill(Trandom ,M).
μ{Up}=project+kill(Tr,M)+project ×kill(Tr,M)
The variable projecthas a correlation of 0.734 with the
Uperfect, andthecombinedtermshaveacorrelationof0.9994
with Uperfect.
5.3 Adequate Mutants
Finally, one may ask if adequacy has an impact on the
eﬀectiveness of selection strategies. Following the industry
practice of deeming well-tested projects adequate after dis-
counting equivalent mutants [ 47,52–54], we chose large well
tested projects that had at least 10, 000 mutants and a mu-
tation score of at least 70% (in the range of similar stud-
ies above) which were deemed adequate. We evaluated theutility for conﬁguration, commons-lang3, commons-math1,
jodatime and found that they have a mean maximum utility
of 13.955%. These same projects have a distinguished meanmaximum utility of 17.893%. This suggests that adequacydoes not have a noticeable impact on the eﬀectiveness of
selection strategies.
6. DISCUSSION
Mutation analysis is an invaluable tool that is often diﬃ-
cult to use in practice due to hefty computational require-
ments. There is ongoing and active research to remedy
this situation using diﬀerent mutation reduction strategies.
Hence, it is important to understand the amount by whichone can hope to improve upon the simplest baseline strategyfor reduction — pure random sampling.
Our theoretical analysis of a simple idealized system ﬁnds
a mean improvement of 58.2% over random sampling for amutation reduction strategy with oracular knowledge of mu-tation kills given a uniform distribution of mutants. This
serves as an upper bound of what any known mutation re-duction strategy could be expected to achieve (under the
assumption that the mutant distribution is reasonably closeto uniform).
Ourempiricalanalysisusingalargenumberofopensource
projects reveals that the practical limit is much lower, how-
ever, on average only 13.078% for mutants produced by PIT.Even if we discount the eﬀects of skew, by using only distin-
guished mutants, the potential improvement is restricted to17.545% on average.
It is important to distinguish the diﬀerent questions that
the theory and empirical analysis tackle. The theoreticallimit shows the best that can be done by a perfect mutationstrategy given the worst distribution of mutants one mayencounter. On the other hand, the empirical analysis ﬁndsthe average utility of a perfect strategy without regard to
the distribution of mutants in diﬀerent programs. However,
given that the eﬀects of skew were found to be rather weak(only 4.467%) the theoretical bound is reasonable for the
empirical question too.
The empirical upper bounds on gain in utility are surpris-
ingly low, and call into question the eﬀort invested into im-
proving mutation reduction strategies. Of course, one canstill point out that random sampling is subject to the va-
garies of chance, as one can get arbitrarily good or bad
samples. However, our results suggest that the variance
of individual samples is rather low, and the situation im-proves quite a bit with larger projects — e.g. the varianceofcommons-math1 is just 0.397%. Hence the chances for
really bad samples are very low in the case of projects largeenough to really need mutant reduction, and drop quicklyas the number of test cases increases. One may wonder if
the adequacy of test suites has an impact, but our analysis
of projects with adequate test suites suggests that there isvery little diﬀerence due to adequacy ( U
perfect=13.955%).
In general, using accepted standard practices for statisticalsampling to produce reasonably-sized random mutant sam-ples should be practically eﬀective for avoiding unusually
bad results due to random chance. The added advantage
is that random sampling is easy to implement and incursnegligible overhead.
We note that our framework is applicable not only to se-
lective mutation, but also to mutation implementors looking
to add new mutators. Say a mutation implementor has a
perfect set of mutation operators such that their current set
of mutants does not have any redundant mutants (practi-
cally infeasible given our shallow understanding of mutant
semiotics). Even if we consider the addition of a new set of
random mutants that do notimprove the mutation set at
all, in that they are redundant with respect to the original
519set (rare in practice, given that we are introducing new mu-
tants), the maximum disadvantage thus caused is boundedbyourlimit(18.876%upperlimitfor95%ofprojects). How-ever, at least a few of the new mutants can be expected toimprove the representativeness of a mutation set comparedto the possible faults. Since we can’t bound the number ofdistinguishable mutants that may be introduced, there is no
upper bound for the maximum advantage gained by adding
new mutation operators. Adding new operators is especiallyattractive in light of recent results showing classes of real
faults that are not coupled to any of the operators currentlyin common use [ 32].
Our previous research [25] suggests that a constant num-
ber of mutants (a theoretical maximum of 9, 604, and 1,000
inpracticefor1%accuracy)issuﬃcientforcomputingmuta-
tion score with high accuracy irrespective of the total num-
ber of mutants. This suggests that sampling will lead to
neither loss of eﬀectiveness nor loss of accuracy, and henceaddition of new mutation operators (and sampling the re-quired number of mutants) is potentially a very fruitful en-
deavour.
7. THREATS TO V ALIDITY
While we have taken care to ensure that our results are
unbiased, and have tried to eliminate the eﬀects of randomnoise. Random noise can result from non-representative
choise of project, tool, or language, and can lead to skewedstrata and bias in empirical result. Our results are subjectto the following threats.
Threats due to approximation: We use the greedy algo-
rithm due to Chvatal [ 12] for approximating the minimum
test suite size. While this is guaranteed to be H(|M|)a p -
proximate, there is still some scope for error. We guard
against this error by taking the average of 100 runs for each
observation. Secondly, we used random samples to evaluate
the eﬀectiveness of random sampling. While we have used100 trials each for each observation, the possibility of biasdoes exist.
Threats due to sampling bias: To ensure representa-
tiveness of our samples, we opted to use search results from
the Github repository of Java projects that use the Maven
build system. We picked allprojects that we could retrieve
given the Github API, and selected from these only based on
constraints of building and testing. However, our sample of
programs could be biased by skew in the projects returned
by Github.
Bias due to tool used: For our study, we relied on PIT.
We have done our best to extend PIT to provide a reason-ably suﬃcient set of mutation operators, ensuring also thatthemutationoperatorsarenon-redundant. Further, wehavetried to minimize the impact of redundancy by consideringthe eﬀect of distinguished mutants. There is still a possi-
bility that the kind of mutants produced may be skewed,
which may impact our analysis. Hence, this study needs tobe repeated with mutants from diverse tools and projects infuture.
8. CONCLUSION
Our research suggests that blind random sampling of mu-
tants is highly eﬀective compared to the best achievableboundformutationreductionstrategies, usingperfectknowl-
edge of mutation analysis results, and there is surprisinglylittle room for improvement. Previous researchers showed
that there is very little advantage to currentoperator selec-
tion strategies compared to random sampling [ 53,54]. How-
ever, the experiment lacked direct comparison with random
sampling of the samenumber of mutants. Secondly it was
also shown that currentstrategies fare poorly [3] when com-
pared to the actual minimum mutant set, but lacked com-
parison to random sampling. Our contribution is to show
that there is a theoretical limit to the improvement that any
reduction strategy can have irrespective of the intelligence
of the strategy, and also a directempirical comparison of
eﬀectiveness of the best strategy possible with random sam-pling.
Our theoretical investigation suggests a mean advantage
of58 .2%foraperfectmutationreductionstrategywithorac-
ular knowledge of kills over random sampling given an arbi-trary program, under the assumption of no skew in redun-
dant mutants. Empirically, we ﬁnd a much lower advan-tage 13.078% for a perfect reduction strategy with oracular
knowledge. Even if we eliminate the eﬀects of skew in redun-dant mutant population by considering only distinguished
mutants, we ﬁnd that the advantage of a perfect mutation
reduction strategy is only 17.545% in comparison to randomsampling. The low impact of skew (4.467%) suggests that
our simplifying assumptions for theoretical analysis were not
very far oﬀ the mark. The disparity between the theoreticalprediction and empirical results is due to the inadequaciesof real world test suites, resulting in a much smaller mini-
mum mutant set than the distinguishable mutant set. We
note that mutation reduction strategies routinely claim highreduction factors, and one might expect a similar magnitude
of utility over random sampling, which fails to materialize
either in theory or practice.
Thesecondtakeawayfromourresearchisthataresearcher
or an implementor of mutation testing tools should consider
the value of implementing a mutation reduction strategy
carefully given the limited utility we observe. In fact, ourresearch [ 24] suggests that popular operator selection strate-
gies we examined have reduced utility compared to randomsampling, andevenstratasamplingtechniquesbasedonpro-
gram elements seldom exceed a 10% improvement. Given
that the variability due to projects is signiﬁcant, a testingpractitioner would also do well to consider whether the mu-
tation reduction strategy being used is suited for the partic-
ular system under test (perhaps based on historical data for
that project, or projects that are in some established sense
similar). Random sampling of mutants is not extremely farfrom an empirical upper bound on an ideal mutation reduc-
tion strategy, and has the advantage of having little room
for an unanticipated bias due to a“clever”selection method
that might not work well for a given project. The limit re-ported here is based on using full knowledge of the mutation
kill matrix, which is, to say the least, diﬃcult to attain in
practice.
Perhaps the most important takeaway from our research
is that it is possible to improve the eﬀectiveness of mutationanalysis, not by removing mutation operators, but ratherby further research into newer mutation operators (or new
categories of mutation operators such as domain speciﬁc op-
erators for concurrency or resource allocation). Our researchsuggests that the maximum reduction in utility due to ad-dition of newer operators is just 23.268%, while there is no
limit to the achievable improvement.
5209. REFERENCES
[1] A. T. Acree, Jr. On Mutation .P h Dt h e s i s ,G e o r g i a
Institute of Technology, Atlanta, GA, USA, 1980.
[2] P. Ammann. Transforming mutation testing from the
technology of the future into the technology of the
present. In International Conference on Software
Testing, Veriﬁcation and Validation Workshops.IEEE, 2015.
[3] P. Ammann, M. E. Delamaro, and J. Oﬀutt.
Establishing theoretical minimal sets of mutants. In
International Conference on Software Testing,
Veriﬁcation and Validation , pages 21–30, Washington,
DC, USA, 2014. IEEE Computer Society.
[4] J. H. Andrews, L. C. Briand, and Y. Labiche. Is
mutation an appropriate tool for testing experiments?InInternational Conference on Software Engineering ,
pages 402–411. IEEE, 2005.
[5] J. H. Andrews, L. C. Briand, Y. Labiche, and A. S.
Namin. Using mutation analysis for assessing and
comparing testing coverage criteria. IEEE
Transactions on Software Engineering , 32(8), 2006.
[6] Apache Software Foundation. Apache commons.
http://commons.apache.org/ .
[7] Apache Software Foundation. Apache maven project.
http://maven.apache.org .
[8] E. F. Barbosa, J. C. Maldonado, and A. M. R.
Vincenzi. Toward the determination of suﬃcientmutant operators for c. Software Testing, Veriﬁcation
and Reliability , 11(2):113–136, 2001.
[9] T. A. Budd. Mutation Analysis of Program Test Data.
PhD thesis, Yale University, New Haven, CT, USA,
1980.
[10] T. A. Budd, R. A. DeMillo, R. J. Lipton, and F. G.
Sayward. Theoretical and empirical studies on using
program mutation to test the functional correctness of
programs. In ACM SIGPLAN-SIGACT symposium on
Principles of programming languages, pages 220–233.ACM, 1980.
[11] T. A. Budd, R. J. Lipton, R. A. DeMillo, and F. G.
Sayward. Mutation analysis . Yale University,
Department of Computer Science, 1979.
[12] V. Chvatal. A greedy heuristic for the set-covering
problem. Mathematics of operations research ,
4(3):233–235, 1979.
[13] H. Coles. Pit mutation testing. http://pitest.org/ .
[14] H. Coles. Pit mutation testing: Mutators.
http://pitest.org/quickstart/mutators.
[15] M. Daran and P. Th´ evenod-Fosse. Software error
analysis: A real case study involving real faults andmutations. In ACM SIGSOFT International
Symposium on Software Testing and Analysis ,p a g e s
158–171. ACM, 1996.
[16] R. A. DeMillo, D. S. Guindi, W. McCracken,
A. Oﬀutt, and K. King. An extended overview of the
mothra software testing environment. In International
Conference on Software Testing, Veriﬁcation and
Validation Workshops, pages 142–151. IEEE, 1988.
[17] R. A. DeMillo, R. J. Lipton, and F. G. Sayward. Hints
on test data selection: Help for the practicingprogrammer. Computer, 11(4):34–41, 1978.
[18] L. Deng, J. Oﬀutt, and N. Li. Empirical evaluation of
the statement deletion mutation operator. In IEEE6th ICST, Luxembourg, 2013.
[19] A. Derezi´ nska. A quality estimation of mutation
clustering in c# programs. In New Results in
Dependability and Computer Systems, pages 119–129.Springer, 2013.
[20] A. Derezi´ n s k a .T o w a r dg e n e r a l i z a t i o no fm u t a n t
clustering results in mutation testing. In Soft
Computing in Computer and Information Science ,
pages
395–407. Springer, 2015.
[21] U. Feige. A threshold of ln n for approximating set
cover. pages 634–652, 1998.
[22] GitHub Inc. Software repository.
http://www.github.com.
[23] R. Gopinath. Replication: Limits of mutation
reduction strategies.http://eecs.osuosl.org/rahul/icse2016/.
[24] R. Gopinath, A. Alipour, I. Ahmed, C. Jensen, and
A. Groce. Do mutation reduction strategies matter?Technical report, Oregon State University, Aug 2015.
http://hdl.handle.net/1957/56917.
[25] R. Gopinath, A. Alipour, I. Ahmed, C. Jensen, and
A. Groce. How hard does mutation analysis have tobe, anyway? In International Symposium on Software
Reliability Engineering . IEEE, 2015.
[26]
A.(http://cstheory.stackexchange.com/users/37275/anonymous).What is the reverse of greedy algorithm for setcover?
Theoretical Computer Science Stack Exchange.
url:http://cstheory.stackexchange.com/q/33685(version: 2016-01-29).
[27] S. Hussain. Mutation clustering. Master’s thesis,
King’s College London, Strand, London, UK, 2008.
[28] C. Ji, Z. Chen, B. Xu, and Z. Zhao. A novel method of
mutation clustering based on domain analysis. In
SEKE, pages 422–425, 2009.
[29] Y. Jia and M. Harman. Constructing subtle faults
using higher order mutation testing. In IEEE
International Working Conference on Source Code
Analysis and Manipulation, pages 249–258. IEEE,
2008.
[30] Y. Jia and M. Harman. Higher Order Mutation
Testing. Information and Software Technology ,
51(10):1379–1393, Oct. 2009.
[31] Y. Jia and M. Harman. An analysis and survey of the
development of mutation testing. IEEE Transactions
on Software Engineering, 37(5):649–678, 2011.
[32] R. Just, D. Jalali, L. Inozemtseva, M. D. Ernst,
R. Holmes, and G. Fraser. Are mutants a valid
substitute for real faults in software testing? In ACM
SIGSOFT Symposium on The Foundations ofSoftware Engineering, pages 654–665, Hong Kong,China, 2014. ACM.
[33] R. M. Karp. Reducibility among combinatorial
problems . Springer, 1972.
[34] B. Kurtz, P. Ammann, and J. Oﬀutt. Static analysis
of mutant subsumption. In Software Testing,
Veriﬁcation and Validation Workshops (ICSTW),2015 IEEE Eighth International Conference on ,p a g e s
1–10, April 2015.
[35] R. Kurtz, P. Ammann, M. Delamaro, J. Oﬀutt, and
L. Deng. Mutant subsumption graphs. In Workshop
521on Mutation Analysis , 2014.
[36] R. J. Lipton. Fault diagnosis of computer programs.
Technical report, Carnegie Mellon Univ., 1971.
[37] Y.-S. Ma and S.-W. Kim. Mutation testing cost
reduction by clustering overlapped mutants. Journal
of Systems and Software , pages –, 2016.
[38] A. Mathur. Performance, eﬀectiveness, and reliability
issues in software testing. In Annual International
Computer Software and Applications Conference,
COMPSAC , pages 604–605, 1991.
[39] A. P. Mathur. Foundations of Software Testing .
Addison-Wesley, 2012.
[40] A. P. Mathur and W. E. Wong. An empirical
comparison of data ﬂow and mutation-based testadequacy criteria. Software Testing, Veriﬁcation and
Reliability, 4(1):9–31, 1994.
[41] E. S. Mresa and L. Bottaci. Eﬃciency of mutation
operators and selective mutation strategies: An
empirical study. Software Testing, Veriﬁcation and
Reliability, 9(4):205–232, 1999.
[42] A. S. Namin and J. H. Andrews. Finding suﬃcient
mutation operators via variable reduction. InWorkshop on Mutation Analysis, page 5, 2006.
[43] A. J. Oﬀutt, G. Rothermel, and C. Zapf. An
experimental evaluation of selective mutation. In
International Conference on Software Engineering ,
pages 100–107. IEEE Computer Society Press, 1993.
[44] A. J. Oﬀutt and R. H. Untch. Mutation 2000: Uniting
the orthogonal. In Mutation testing for the new
century, pages 34–44. Springer, 2001.
[45] A. J. Oﬀutt and J. M. Voas. Subsumption of condition
coverage techniques by mutation testing. Technicalreport, Technical Report ISSE-TR-96-01, Informationand Software Systems Engineering, George Mason
University, 1996.
[46] D. Schuler and A. Zeller. Javalanche: Eﬃcient
mutation testing for java. In ACM SIGSOFT
Symposium on The Foundations of Software
Engineering, pages 297–298, Aug. 2009.
[47] A. Siami Namin, J. H. Andrews, and D. J. Murdoch.
Suﬃcient mutation operators for measuring test
eﬀectiveness. In International Conference on Software
Engineering, pages 351–360. ACM, 2008.
[48] J. Strug and B. Strug. Machine learning approach in
mutation testing. In Testing Software and Systems ,
pages 200–214. Springer, 2012.
[49] R. H. Untch. On reduced neighborhood mutation
analysis using a single mutagenic operator. In Annual
Southeast Regional Conference, ACM-SE 47, pages71:1–71:4, New York, NY, USA, 2009. ACM.
[50] W. Wong and A. P. Mathur. Reducing the cost of
mutation testing: An empirical study. Journal of
Systems and Software , 31(3):185 – 196, 1995.
[51] W. E. Wong. On Mutation and Data Flow.P h D
thesis, Purdue University, West Lafayette, IN, USA,1993. UMI Order No. GAX94-20921.
[52] J. Zhang, M. Zhu, D. Hao, and L. Zhang. An
empirical study on the scalability of selective mutation
testing. In International Symposium on Software
Reliability Engineering . ACM, 2014.
[53] L. Zhang, M. Gligoric, D. Marinov, and S. Khurshid.Operator-based and random mutant selection: Better
together. In IEEE/ACM Automated Software
Engineering. ACM, 2013.
[54] L. Zhang, S.-S. Hou, J.-J. Hu, T. Xie, and H. Mei. Is
operator-based mutant selection superior to random
mutant selection? In International Conference on
Software Engineering, NY, USA, 2010. ACM.
522