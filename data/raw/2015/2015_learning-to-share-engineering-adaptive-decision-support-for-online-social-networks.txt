Learning to Share: Engineering Adaptive
Decision-Support for Online Social Networks
Yasmin Raﬁq∗, Luke Dickens†, Alessandra Russo∗, Arosha K. Bandara‡,M uY a n g/bardbl, Avelie Stuart§,
Mark Levine§, Gul Calikli∗∗, Blaine A. Price‡, and Bashar Nuseibeh‡¶
∗Imperial College London, UK: {y.raﬁq, a.russo}@imperial.ac.uk
†University College London, UK: {l.dickens}@ucl.ac.uk
‡The Open University, UK: {a.k.bandara, b.a.price, b.nuseibeh}@open.ac.uk
§University of Exeter, UK: {a.stuart, m.levine}@exeter.ac.uk
¶Lero, University of Limerick, Ireland, UK: {bashar.nuseibeh}@lero.ie
/bardblUniversity of Southampton, UK: {Mu.Yang}@soton.ac.uk
∗∗Chalmers & University of Gothenburg, Sweden: {gul.calikli}@gu.se
Abstract —Some online social networks (OSNs) allow users
to deﬁne friendship-groups as reusable shortcuts for sharing
information with multiple contacts. Posting exclusively to a
friendship-group gives some privacy control, while supporting
communication with (and within) this group. However , recipientsof such posts may want to reuse content for their own social
advantage, and can bypass existing controls by copy-pasting into
a new post; this cross-posting poses privacy risks.
This paper presents a learning to share approach that enables
the incorporation of more nuanced privacy controls into OSNs.
Speciﬁcally, we propose a reusable, adaptive software architecture
that uses rigorous runtime analysis to help OSN users to makeinformed decisions about suitable audiences for their posts. This
is achieved by supporting dynamic formation of recipient-groups
that beneﬁt social interactions while reducing privacy risks. Weexemplify the use of our approach in the context of Facebook.
I. I NTRODUCTION
Online Social networks (OSNs) are increasingly used to
maintain social ties with family members, friends, and col-
leagues, and build new social relationships (e.g., [1]–[3]).
However, these beneﬁts come with an increased risk of privacy
violation from oversharing or underusing privacy controls [4]–
[8]. Many OSN platforms currently support privacy manage-
ment through features such as static (user-deﬁned) friendship
groups as reusable shortcuts for sharing a single post with
multiple contacts. Users can select the group they deem
most appropriate when posting a message. In OSNs such as
Facebook, LinkedIn and Google+, users may perceive postingin closed group as a quick ﬁx to their privacy concerns, since
these OSNs can constrain the re-sharing to only those contactswho have received the original message. However, theseprivacy control mechanisms do not account for cross-posting,
i.e. when a contact copy-and-pastes the original message intoa new post, and sends it to contacts outside the original group,to either improve their own social capital or damage that ofthe original user [9]. We argue that privacy in OSNs cannotbe effectively delivered by inﬂexible and rarely-visited privacy
settings, instead contact lists should be formed dynamically per
post, such that unwanted cross-posting is minimized while the
user’s social beneﬁt is optimised.In this paper, we propose an adaptive privacy control
approach, called learning to share, that enables software
engineers/developers to incorporate adaptive privacy decisionsupport into OSN applications. Speciﬁcally, we propose asoftware architecture that supports continuous monitoring ofonline interactions between each user-contact pair in a user’ssocial network, to predict three categories of contacts: thosewho are most likely to pose a privacy breach (i.e. riskyfriends); those who are socially inactive but privacy aware(i.e., safe friends); and those who are both socially activeand privacy aware (i.e., super friends). The prediction isbased on an interaction model of sharing behaviours, which isupdated on-line in response to monitored behaviour and usedto evaluate social beneﬁt and privacy risk of sharing a post witheach potential recipient. The outcome of the classiﬁcation isused by the decision support component of the architecture todynamically form contacts lists per post, and allows the userto efﬁciently select the recipient group on a per post basis.
The underlying OSN infrastructure can take into account the
informed selection by the user and dynamically control whoshould be receiving which message when delivering the post.
Our proposed software architecture is not speciﬁc to a
particular OSN environment. Software engineers working ondeveloping and/or improving existing OSN applications withadaptive privacy decision mechanisms, can use our proposedarchitecture by deploying its automated learning and decisionsupport capabilities, and integrating an Abstract InteractionModel and a wrapper for monitoring the type of socialinteractions that are speciﬁc to the particular OSN application.
The rest of the paper is organized as follows. Section II
presents a motivating example within the context of Facebook.Section III describes our Learning to Share architecture.
Section IV exempliﬁes how OSN behaviours can be modelledas parametric Markov model, using the example of Facebook;introduces the related component for monitoring social net-work activities, and presents the online learning algorithmused to predict the model’s parameters. Section V describesthe computation of social beneﬁt and privacy risk used by the
978-1-5386-2684-9/17/$31.00 c/circlecopyrt2017 IEEEASE 2017, Urbana-Champaign, IL, USA
T echnical Research - New Ideas280
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:53:15 UTC from IEEE Xplore.  Restrictions apply. decision support component. Section VI discusses related work
and concludes the paper with a summary and future work.
II. M OTIV ATING EXAMPLE
Here, we illustrate the need for adaptive privacy control with
a motivating example based on Facebook use. Facebook user
Bob shares sensitive post A with his predeﬁned close friends
group, which does not include Ann – Bob’s work colleague but
not a close friend. As Ann is not a member of the close friends
group, Facebook does not allow her to see Bob’s post, andmembers of close
friends are unable to re-share the post with
her. Tom, a member of Bob’s close friends group, is also a
close friend of Ann, but is unaware of this privacy aspect ofFacebook’s group sharing. When Tom receives the post A, henaively decides to copy and paste the content into a new post,B, adding some content of his own, and shares B with a group
of contacts which includes Ann. Now Ann can see, via cross-
posting, what Bob shared in post A, but Facebook is unable
to detect this or notify Bob that his on-line close friend Tom
has violated his privacy, albeit unintentionally.
Bob’s Social NetworkBob
Close Friends Listshare post A
share post Asee post AAnn
Tom Sue Eve Ben Joe
Fig. 1: A scenario of privacy breach.
This shows that, while customised social network groups are
convenient for posting to multiple recipients and (in Facebook
at least) offering a form of privacy control, this static featurecan easily be bypassed, even fairly innocently. Good adaptive
privacy control would, instead, monitor Tom’s actions, detectthe similarity between posts A and B, and use this informationto learn that sending sensitive posts to Tom represents a
privacy risk, presenting this information to Bob the next timehe intends to share another sensitive post with close friends.
III. P
RIV ACY AWA R E SHARING ARCHITECTURE
Our proposed learning to share approach is implemented as
a reusable, adaptive software architecture as shown in Figure 2.
The architecture comprises two main modules: i) modelling
and monitoring (marked C2), and ii) adaptive decision support(marked C3). This design enables software engineers workingon OSN applications to deploy our architecture by reusingthe automated learning and decision support capabilities anddeveloping just two components: the abstract interaction model
for the speciﬁc OSN application and a wrapper, which enablesmonitoring of the application speciﬁc social network interac-
tions, and execution of sharing decisions.
The OSN wrapper implements the monitor functionality to
detect for each recipient of each post subsequent interactionsLearning Engine
Decision
Support
System{p1,p2,...,p n}
Learning To Share ComponentC1
Social Network Site
UserUser
updated
paramssocial
interactions
notiﬁcations
update d
paramssensitivity
labels
risk
attituderecommendationsDecision
Share info.
MonitorC2
Abstract
Interaction Model
p1
p3p2
p4
p5p6
p7
1.01.0C3update d
rulesInfo
Sensitivity
Store
Concrete
Interaction
Model
0.2
0.30.5
0.6
0.40.1
0.9
1.01.0Evaluation of
Reshare Risk
&
Social Beneﬁt
Fig. 2: Learning to share Architecture
between user and recipient, e.g., resulting likes and comments
on Facebook. Monitored events are used by the Learning En-
gine component, which updates the parameters of the associ-
ated instantiated interaction model, called Concrete Interaction
Models, essentially capturing the probability of each possiblesocial interaction at each post’s sensitivity level. The concreteinteraction model is then queried by the Decision Support
System (DSS) to assess sharing decisions. Speciﬁcally, the
DSS employs the concrete interaction model, a risk aversenessthreshold and a post’s sensitivity level to evaluate the re-sharerisk and social beneﬁt and to classify (at run-time) each ofuser’s contacts as super, safe orrisky. Sensitivity levels of
shared posts are deﬁned by the user and stored, together with
the post, to check for future re-shares of the post.
By providing just the wrapper and an abstract interaction
model, learning to share can be deployed for different OSNs
either as a fully integrated feature of an OSN’s infrastructure(i.e. total view mode), or as a plugin application of anexisting OSN infrastructure (i.e. partial view mode). In the
ﬁrst case, the adaptive privacy control beneﬁts from full accessto the OSN’s global network community and the monitoringof online social behaviour of all members in the network.Whereas, partial view mode only provides adaptive privacy
control and monitoring of users of the plugin application.
IV . M
ODELLING AND MONITORING RUNTIME ACTIVITY
This section describes the modelling module of our archi-
tecture as a parametric Markov model, illustrating it with an
example of an abstract interaction model for Facebook. It alsopresents our online learning method for updating the model’sparameters and a method for monitoring social interactionevents, used for computing the updates.
A. Quantitative V eriﬁcation of Markov Chains
Online social interactions can be modelled using parametric
Markov chains (PMC). These are deﬁned as follows:
Deﬁnition 4.1: A reward-annotated ﬁnite state discrete-
time parametric Markov chain (PMC),M, is the tuple
281
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:53:15 UTC from IEEE Xplore.  Restrictions apply. <S , s 0,V,P,ι,L> , withSa ﬁnite set of states and initial
states0∈S;Va set of real-valued parameters; Pa parametric
transition probability |S|×|S|-matrix whose elements are
functions of V; the reward function ι:S→R≥0assigning
a non-negative reward for each state, and labelling function
L:S→2APassigning a set of atomic propositions to
each state. The (i,j)th element of P,pij, is a function of
parameters V(writtenpij∈FV) and represents the probability
of transitioning from sitosj.pijtakes values strictly in [0,1]
and/summationtext
jpij=1 for alli.
Probabilistic model checker PRISM1[12] allows PMCs
to be expressed in a high-level language, and efﬁciently
evaluates queries expressed in a reward-augmented versionof probabilistic computational tree logic (PCTL) [13]. Weuse PRISM’s reward query operator R
=?[Φ] in conjunction
with the reachability reward property Φ=[ Fa], to evalute
the average reward accumulated along a path until a statesatisfying proposition a∈AP is reached (for PCTL semantics
see [14]). When queried with a PMC, PRISM’s reward queryoperator produces a symbolic expression, V∈F
V,o ft h e
associated reward property (a function of V). In what follows
we describe how we use this functionality to predict expectedsocial beneﬁt and privacy risk in the context of Facebook.
B. Modelling Sharing Behaviours
We describe here our PMC model for Facebook. It captures
the online social interactions between a user and contact, c,
following the user’s post. The ﬁrst model, M
1
c(see Fig. 3)
captures comments and likes from both contact cand the
user following some post. This behaviour is assumed to be
independent of a post’s sensitivity (as discussed later). States
inM1
care:s1,s2,s3ands4respectively representing likes
bycand user, and comments by cand user; initial state s0;
terminal state send; ands6(which simply improves readabil-
ity). Symbolic parameters in M1carep1,p2,p3,p4∈[0,1]and
r1,r2,r3,r4>0. Associated transition probabilities, rewards
and propositional labels are shown in the ﬁgure. For example,
ifM1
cis in state s0, thenp1is the probability that the next
reaction is a like by c, and given any of the four reactions, the
system returns to s0with certainty.
There are 5remaining models, M2
c,l(see Fig. 4), one per
sensitivity level l∈{0,1,2,3,4}, which capture the reshare
behaviour of the contact in response to a post at sensitivity l.
States in M2c,lare: initial state s0; terminal state send; ands5
representing a reshare by c.M2c,lhas two symbolic parameters
ql∈[0,1]andr5≥0. Again, transition probabilities, rewards
and labels are shown in the ﬁgure. In an example execution
ofM2
c,lfrom state s0,qlis the probability that a creshares,
and this can happen at most once.
We wish to estimate the social beneﬁt of all reactions which
follow the user sharing a post at sensitivity lwithc, and equate
this with the total reward accumluated over the lifetime of the
parallel execution of M1
candM2
c,l. This corresponds to the
sum of the expressions returned by PRISM when R=?[Fend]
1Similar model checkers include MRMC [10] and Ymer [11].is invoked on each model. These queries can be invoked once
at design time and respectively give:
V1
c=/summationtext4
i=1piri
(1−/summationtext4i=1pi)(1)
V2
c,l=qlr5 (2)
We discuss the use of these expressions in Section V-A.
s0s1
s2
{initial}
{comment u}{comment c}{like u}{like c}
p3p1
r3
r4r1
r21.0
p2 1.0
1.0s6
s4s3
1.0p4
1.01−(p1+p2+p3+p4)
send
{end}1.0M1
c
{again}
Fig. 3: PMC model of online social interactions between a Facebook
user and their post recipient c.
send
{end}1.0s0 s5
{initial} {reshare c}ql1−ql
1.0r5M2
c,l
Fig. 4: PMC model capturing the re-sharing behaviour of a recipient
cfor posts received with sensitivity level l.
C. Online Learning of Sharing Behaviour
PMC modelling and analysis, like that described above, is
conventionally used for ofﬂine analysis of system properties
[15], [16]. We instead apply these techniques at runtimeupdating our PMC parameters in light of observed interac-tions. We must, however, consider two complicating factors.First,c’s behaviour may change with time, and so we use a
variant of the adaptive Bayesian learning algorithm from [17].Secondly, we can never observe when the user-contact pairstop interacting on a given post. To address this, we accountfor unobserved transitions to terminal states, s
end, by noting
that each execution must eventually make this transition, andconstructing a synthetic observation to the end state for every
shared post with the same time-stamp as the original share.
Here, we describe how transition probabilities p
ijof a PMC
can be learned when the analysed system is operational, andits state transitions monitored (for Facebook these correspondto the monitored events, such as comments, likes, share and re-share). More formally, suppose that, we have observed K>0
transitions out of s
i∈Sand that the k-th such transition
1≤k≤K, is to state sjk∈S, we deﬁne
σk
ij=/braceleftBigg
1ifjk=j
0otherwise(3)
282
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:53:15 UTC from IEEE Xplore.  Restrictions apply. and estimate probability of a state transition from sitosjas
pK
ij=co
i
co
i+Kpo
ij+K
co
i+KfK
ij
gK
ij(4)
wherep0
ijis the prior for pKij,c0i>0quantiﬁes our conﬁdence,
f1
ij=σ1
ij,g1
ij=1, and for K>1,fK
ijandgK
ijare deﬁned
recursively as:
fK
ij=α−(tK−tK−1)fK−1
ij+σK
ij
gK
ij=α−(tK−tK−1)gK−1
ij+1
Here,tKrepresents the timestamp of the K-th observation,
andα≥1is an ageing parameter (see [17] for a full
description and proof). These probability estimates have two
key features: older observations are downweighted, allowingrapid adaptation to changes in p
ij; and the recursive form
means storage and computation complexity are both in O(1).
D. Interaction Monitoring
The Monitor component detects events that are being
tracked by our behavioural models (see Section IV-B), and,when detected, notiﬁes the Learning Engine so that appropriate
updates can be invoked (see Section IV-C). In order to detectcross-posting based on a post’s modality (e.g., text, image,audio or video), in the Monitor component, state-of-the-art
information retrieval techniques [18] can be implementedas a pluggable module to measure the similarity betweenposts sent to c, and posts csubsequently shares with others.
Posts that exceed some similarity threshold (e.g., [19]) canbe treated as cross-posts and the Learning Engine notiﬁed.
Such a task is becoming feasible recently with the advanceof high performance hardware and also information retrievaltechniques [19]–[25].
V. D
ECISION SUPPORT SYSTEM
In this section, we present the technical details of our
decison support system (DSS) that elicits and models thesharing preferences of the user, and informs the user ofany sharing decisions that represent signiﬁcant beneﬁts orexceed certain risk thresholds derived from these preferences.Section V-A and Section V-B formally deﬁne the social beneﬁt
and privacy risk models, and Section V-C describes how weinitialise the parameters associated with these models. Finally,in Section V-D we discuss the mechanisms for the user to
adjust the parameters of the privacy risk model, based oncontinual feedback about the working system from the user.
A. Social Beneﬁt
The DSS estimates the social-beneﬁt a user expects to gain
when sharing a post with contact, c, from the Concrete Inter-
action Models, described in Section IV-B. For our Facebook
example, this is captured by models M
1
candM2
c,l. These two
models attribute socially-beneﬁcial rewards to relevant social
events: reshares (of non-sensitive posts), comments and likesby contact c; and comments and likes in response by the user.
A user may value each event differently, but for simplicitywe assign a ﬁxed value to each event type. As discussed inSection IV, the expected social-beneﬁt for sharing a post withat sensitivity lwith contact c, is the expected total reward
accumulated over the lifetime of the parallel computation ofmodelsM
1
candM2
c,l, and is given by
Bc,l=V1
c+V2
c,l=/summationtext4
i=1piri
(1−/summationtext4i=1pi)+qlr5 (5)
For each potential sharing decision, the expected social beneﬁt,
Bc,l, is compared with a threshold, ¯B, set for the user.
If it exceeds that threshold, Bc,l>¯B, then the user is
notiﬁed by placing contact cin the super friends list. If a
different behavioural model were implemented, then the aboveexpression would need to be updated appropriately.
While a variety of choices could be made about rewards
in our Facebook model, we suggest the following simple,intuitive choice. Without loss of generality, a contact’s com-ment is given a unitary reward, i.e. r
3=1 . Other rewards
r1=1
2,r2=1
4,r4=1
2andr5=1 are based on a small
study where participants were given a questionnaire2about
expected levels of interaction following a Facebook post.
B. Privacy Risk
The DSS also estimates privacy risk – a numerical value of
undesirability related to risky decisions. By deﬁnition, sharing
any post at sensitivity l=0 carries no risk (reshares are
desired). Sharing at higher sensitivity l>0with a contact c
who has reshare probability qc,l, is considered a risky decision
with associated risk
Rc,l=blog2(qc,l)+a l (6)
where2alis the damage value associated with a privacy breach
(a known reshare) at sensitivity level l, andb>0 controls
how risk averse the user is (their risk posture). When the user
considers sharing a post of sensitivity lwithc, the associated
risk,Rc,l, is compared to the user’s risk-threshold, ¯R. The DSS
warns the user if Rc,l>¯Rby placing contact cinto the risky
list for that post. We deﬁne 5sensitivity levels l=0,1,2,3,4.
Forl>0,al=lmeaning a privacy breach at sensitivity lis
half as damaging as one at l/prime=l+1 (l=0 means no risk).
Risk posture, b, is set so Rc,lvalues, as closely as possible,
reﬂect a user’s preferences over risky decisions. Risk appetite,
¯R, represents the user’s maximum acceptable risk. These
parameters are given initial values based on user input (Section
V-C), then adjusted at runtime by the user (Section V-D).
C. Initialising Decision Support Parameters
As indicated, initial values for social beneﬁt threshold, ¯B,
risk-posture, b, and risk-threshold, ¯R, are elicited from users
via a short, non-technical questionnaire, where they consider
outcomes in three sharing scenarios2. However, as a user may
not feel able to respond to one or more questions, we providenull response options for each scenario, and generate defaultvalues based on previous responses.
2The questionnaire can be found at bit.ly/2x4Fqqs
283
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:53:15 UTC from IEEE Xplore.  Restrictions apply. The social-beneﬁt threshold, ¯Baims to identify contacts
who (on average) exceed a user’s expected level of social
engagement. We quantify this as the expected number of likes,
Nl, and comments, Nc, in response to a typical post from the
user to10recipients, and use this to predict the expected social
reward per person as:
¯B=0.1·(Nc+0.5Nl) (7)
The risk-posture, b, controls how the probability of a privacy
breach affects the associated risk. Values of 0<b<1model
risk-averseness, b=1 models risk-neutrality and b>1 models
risk-seeking behaviour.
We elicit, b, indirectly from the user in terms of what we
call the trade-probability, ˜q– the probability at which the user
would trade exposure to two simultaneous privacy breaches for
a guaranteed privacy breach, where all such privacy breachesare considered equally damaging. Risk posture is then calcu-lated as:
b=−1
log2(˜q)(8)
The risk-threshold, ¯R<0(in conjuction with b) controls
the regularity of warnings in the DSS. This value is again indi-
rectly elicited, this time via the sensitivity 1trigger probability,
¯q1– the lowest probability of reshare for which the user would
liked to be warned. The risk threshold is then calculated as:
¯R=a1+blog2(¯q1)=blog2(¯q1) (9)
Trigger probabilities at other sensitivity levels ( l>0) can
then be calculated as: ¯ql=2¯R−al
b.
D. Adjusting Decision Support Parameters
To provide additional user control over decision support,
and to allow for poorly initialised values to be corrected for,
we provide a mechanism to adjust risk-posture, b, and risk-
threshold, ¯R, based on repeated contemporaneous judgements
of the working system.
Adjusting ¯R:The lowest relevant sensitivity level, l=1,
has a maximum associated reshare risk of 0(see Equation (6)).
Therefore ¯Rmust be strictly negative, ¯R<0. Otherwise, the
user would never be warned at l=1. We therefore propose
multiplicative step adjustments to ¯Rwith a ﬁxed factor η>1
to lower ¯R, andη−1to raise it. More precisely, if the user
indicates that they have too many warnings, then we increase
the threshold with: ¯R←η−1¯R, which increases ¯qlfor all
l≥1. Conversely, if the user indicates they are getting too
few warnings then we reduce the threshold with: ¯R←η¯R.
Adjusting b:The risk-posture is also strictly positive, i.e.
b>0, so we again propose multiplicative changes by a new
step factor, ζ>1. In our system, an increased risk-posture
corresponds to a greater differentiation between sensitivitylevels and vice versa. Therefore, the user can increase differen-tiation between sensitivity levels with an incremental increasein risk-averseness, effected with: b←ζb. Similarly, a user
can decrease this differentiation by decreasing risk-averseness,
effected with: b←ζ
−1b. However, to ensure the baselinetrigger probability ¯q1remains unchanged, we also adjust
the privacy threshold. So an increase in risk-averseness isaccompanied by a reduction to the risk-threshold of: ¯R←ζ¯R.
Similarly, decrease in risk-averseness is accompanied by an
increase to the risk-threshold of: ¯R←ζ
−1¯R.
With these tools the user can incrementally shape the DSS
system to suit their privacy preferences.
VI. R ELATED WORK ,CONCLUSION AND FUTURE WORK
A considerable body of research has been devoted to address
the information sharing problem raised by the increasing num-ber of privacy incidents and regrets happening in OSNs [8],[26]–[34]. However, these approaches do not consider thesituation when users may have made poor sharing decisions inthe past. Whereas, Machine learning and statistical inferenceapproaches like [35]–[40] study information diffusion in OSNsin order to predict the temporal dynamics of the diffusionprocess. A very recent work [41] uses Inductive logic pro-gramming to build a formal model that learns users’ dynamicsocial identities at runtime in order to analyse group processesand intergroup relations in OSNs.
This paper presents a learning to share approach that
enables software engineers/developers to readily add adaptivedecision support to social network applications, such that theuser has ﬁne grained, informed control over their privacysettings. This allows users to maximise their social beneﬁt,
whilst controlling risk of privacy breaches to levels they ﬁnd
personally acceptable. We show how our approach can be usedin the context of Facebook as the selected OSN platform.However the approach is applicable to other OSNs such asLinkedIn and Google+. This approach could also be readily ex-tended to provide privacy control for a broader family of online
interactions, such as undesirable cross-posting behaviours in
social question answering services (e.g., StackOverﬂow) [42].
As for future work, we plan to conduct an online question-
naire in which users are asked to consider outcomes of their
online sharing, based on scenarios discussed in Section V-C.This will help us to initialise the parameters of the DSS withrealistic values. This will be followed by a user study to
help us evaluate the feasibility of our approach from users’
perspective within the context of Facebook. For this purpose,a Facebook plug-in has been implemented and we are at thestage of designing and conducting the user study. Finally wewill organise a workshop with OSN developers and present
our learning to share architecture, implemented as Facebook
plugin and the user study results. During this workshop we
will collect qualitative feedback from developers and elicit
their tendency towards integrating our approach as a privacymanagement for OSNs.
A
CKNOWLEDGMENT
We would like to thank EPSRC, SFI and the ERC for their
ﬁnancial support.
284
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:53:15 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] A. Lenhart et al., Social networking websites and teens: An overview.
Pew/Internet, 2007.
[2] C. Dwyer et al., “Trust and privacy concern within social networking
sites: A comparison of facebook and myspace,” AMCIS 2007 proceed-
ings, p. 339, 2007.
[3] K. Subrahmanyam et al., “Online and ofﬂine social networks: Use
of social networking sites by emerging adults,” Journal of applied
developmental psychology, vol. 29, no. 6, pp. 420–433, 2008.
[4] B. Debatin et al., “Facebook and online privacy: Attitudes, behaviors,
and unintended consequences,” Journal of Computer-Mediated Commu-
nication, 2009.
[5] A. Fitzpatrick, “Study says facebook privacy concerns are on the rise -
is it accurate?” Mashable, 4 May 2012, 2012.
[6] M. Johnson et al., “Facebook and privacy: it’s complicated,” in Proceed-
ings of the eighth symposium on usable privacy and security. ACM,
2012, p. 9.
[7] M. Madejski et al., “A study of privacy settings errors in an online social
network,” in Pervasive Computing and Communications Workshops
(PERCOM Workshops), 2012 IEEE International Conference on . IEEE,
2012, pp. 340–345.
[8] M. Yang et al., “Adaptive sharing for online social networks: A trade-off
between privacy risk and social beneﬁt,” in Proceedings of the 13th IEEE
International Conference on Trust, Security and Privacy in Computingand Communications, 2014, pp. 45–52.
[9] Z. Tufekci, “Can you see me now? audience and disclosure regulation in
online social network sites,” Bulletin of Science, Technology & Society,
vol. 28, no. 1, pp. 20–36, 2008.
[10] J.-P. Katoen et al., “A markov reward model checker,” in Quantitative
Evaluation of Systems, 2005. Second International Conference on the.
IEEE, 2005, pp. 243–244.
[11] H. L. Younes, “Ymer: A statistical model checker,” in International
Conference on Computer Aided V eriﬁcation. Springer, 2005, pp. 429–433.
[12] M. Kwiatkowska et al., “Prism 4.0: Veriﬁcation of probabilistic real-time
systems,” in International Conference on Computer Aided V eriﬁcation.
Springer, 2011, pp. 585–591.
[13] H. Hansson and B. Jonsson, “A logic for reasoning about time and
reliability,” F ormal aspects of computing, vol. 6, no. 5, pp. 512–535,
1994.
[14] F. Ciesinski et al., “On probabilistic computation tree logic,” in V alida-
tion of Stochastic Systems. Springer, 2004, pp. 147–188.
[15] C. Ghezzi and A. M. Shariﬂoo, “Model-based veriﬁcation of quantitative
non-functional properties for software product lines,” Information and
Software Technology, vol. 55, no. 3, pp. 508–524, 2013.
[16] T. Chen, M. Kwiatkowska, D. Parker, and A. Simaitis, “Verifying team
formation protocols with probabilistic model checking,” in International
Workshop on Computational Logic in Multi-Agent Systems. Springer,
2011, pp. 190–207.
[17] R. Calinescu et al., “Using observation ageing to improve markovian
model learning in qos engineering,” in Pr
 oceedings of the 2Nd
ACM/SPEC International Conference on Performance Engineering, ser.
ICPE ’11. New York, NY , USA: ACM, 2011, pp. 505–510. [Online].
Available: http://doi.acm.org/10.1145/1958746.1958823
[18] M. S. Lew et al., “Content-based multimedia information retrieval: State
of the art and challenges,” ACM Trans. Multimedia Comput. Commun.
Appl., vol. 2, no. 1, pp. 1–19, Feb. 2006.
[19] R. Baeza-Yates and B. Ribeiro-Neto, Modern information retrieval.
ACM Press Books, 1999.
[20] A. Huang, “Similarity measures for text document clustering,” 2008.
[21] J. Leskovec, A. Rajaraman, and J. D. Ullman, Mining of massive
datasets. Cambridge University Pess, 2014.[22] G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of
data with neural networks,” Science, vol. 313, no. 5786, pp. 504–507,
2006.
[23] V . Patraucean, A. Handa, and R. Cipolla, “Spatio-temporal video
autoencoder with differentiable memory,” CoRR, vol. abs/1511.06309,
2015. [Online]. Available: http://arxiv.org/abs/1511.06309
[24] G. Pass, R. Zabih, and J. Miller, “Comparing images using color
coherence vectors,” in Proceedings of the F ourth ACM International
Conference on Multimedia, 1996, pp. 65–73.
[25] A. McCallum, K. Nigam, and L. H. Ungar, “Efﬁcient clustering of
high-dimensional data sets with application to reference matching,” inProceedings of the Sixth ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, 2000.
[26] S. Wilson et al., “Privacy manipulation and acclimation in a location
sharing application,” in Proceedings of the 2013 ACM International Joint
Conference on Pervasive and Ubiquitous Computing , 2013, pp. 549–558.
[27] Y . Wang et al., “”I Regretted the Minute I Pressed Share”: A Qualitative
Study of Regrets on Facebook,” in Proceedings of the Seventh Sympo-
sium on Usable Privacy and Security, ser. SOUPS ’11. ACM, 2011,
pp. 10:1–10:16.
[28] T. Dinev et al., “An extended privacy calculus model for e-commerce
transactions,” Information System Research, vol. 17, no. 1, pp. 61–80,
2006.
[29] H. Krasnova et al., “Online social networks: Why we disclose,” Journal
of Information Technology, vol. 25, no. 2, pp. 109–125, 2010.
[30] H. Xu et al., “The role of push-pull technology in privacy calculus: The
case of location-based services,” Journal of Management Information
Systems, vol. 26, no. 3, pp. 135–174, 2009.
[31] H. Nissenbaum, “Privacy as Contextual Integrity,” Washington Law
Review, vol. 79, no. 1, 2004.
[32] A. Barth et al., “Privacy and contextual integrity: Framework and
applications,” in IEEE Symposium on Security and Privacy, 2006, pp.
184–198.
[33] Y . Krupa et al., “Handling privacy as contextual integrity in decentralized
virtual communities: The privacias framework,” Web Intelli. and Agent
Sys., vol. 10, no. 1, pp. 105–116, 2012.
[34] I. Bilogrevic et al., “Adaptive information-sharing for privacy-aware
mobile social networks,” in Proceedings of the 2013 ACM International
Joint Conference on Pervasive and Ubiquitous Computing , 2013, pp.
657–666.
[35]
J. Yang et al., “Modeling information diffusion in implicit networks,”
inProceedings of the 2010 IEEE International Conference on Data
Mining, 2010, pp. 599–608.
[36] J. Leskovec et al., “Meme-tracking and the dynamics of the news cycle,”
inProceedings of the 15th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, 2009, pp. 497–506.
[37] A. Guille et al., “A predictive model for the temporal dynamics of
information diffusion in online social networks,” in Proceedings of the
21st International Conference on World Wide Web, 2012, pp. 1145–1152.
[38] S. Huang et al., “Predicting aggregate social activities using continuous-
time stochastic process,” in Proceedings of the 21st ACM International
Conference on Information and Knowledge Management , 2012, pp. 982–
991.
[39] T. A. B. Snijders, “The statistical evaluation of social network dynam-
ics,” 2001.
[40] J. Li et al., “Social network user inﬂuence dynamics prediction,” in Web
Technologies and Applications, 2013, pp. 310–322.
[41] G. Calikli et al., “Privacy Dynamics: Learning Privacy Norms for Social
Software,” in International Symposium on Adaptive and Self-Managing
Systems, 2016.
[42] B. S. Butler and X. Wang, “The cross-purposes of cross-posting: Bound-
ary reshaping behavior in online discussion communities,” Information
Systems Research, vol. 23, no. 3-part-2, pp. 993–1010, 2012.
285
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:53:15 UTC from IEEE Xplore.  Restrictions apply. 