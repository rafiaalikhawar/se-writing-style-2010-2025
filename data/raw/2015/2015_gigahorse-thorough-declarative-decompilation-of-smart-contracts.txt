Gigahorse: Thorough, Declarative Decompilation of
Smart Contracts
Neville Grech
University of Athens
and University of Malta
Greece and Malta
me@nevillegrech.comLexi Brent
The University of Sydney
Australia
lexi.brent@sydney.edu.auBernhard Scholz
The University of Sydney
Australia
bernhard.scholz@sydney.edu.auYannis Smaragdakis
University of Athens
Greece
yannis@smaragd.org
Abstract —The rise of smart contracts—autonomous applica-
tions running on blockchains—has led to a growing number of
threats, necessitating sophisticated program analysis. However,smart contracts, which transact valuable tokens and cryptocur-rencies, are compiled to very low-level bytecode. This bytecode isthe ultimate semantics and means of enforcement of the contract.
We present the Gigahorse toolchain. At its core is a reverse
compiler (i.e., a decompiler) that decompiles smart contractsfrom Ethereum Virtual Machine (EVM) bytecode into a high-level 3-address code representation. The new intermediate rep-resentation of smart contracts makes implicit data- and control-ﬂow dependencies of the EVM bytecode explicit. Decompilationobviates the need for a contract’s source and allows the analysisof both new and deployed contracts.
Gigahorse advances the state of the art on several fronts.
It gives the highest analysis precision and completeness amongdecompilers for Ethereum smart contracts—e.g., Gigahorse candecompile over 99.98% of deployed contracts, compared to 88%for the recently-published Vandal decompiler and under 50%for the state-of-the-practice Porosity decompiler. Importantly,Gigahorse offers a full-featured toolchain for further analyses(and a “batteries included” approach, with multiple clientsalready implemented), together with the highest performanceand scalability. Key to these improvements is Gigahorse’s use ofa declarative, logic-based speciﬁcation, which allows high-levelinsights to inform low-level decompilation.
Index T erms—Ethereum, Blockchain, Decompilation, Program
Analysis, Security
I. I NTRODUCTION
Distributed blockchain platforms have captured the imagina-
tion of scientists and the public alike. Blockchain technology
offers decentralized consensus mechanisms for any transac-tions that, in the past, would have required a trusted central-ized authority. One of the most evident embodiments of thisvision is the development of smart contracts: Turing-complete
autonomous agents that run on distributed blockchains, suchas Ethereum or Cardano. A smart contract may, for instance,implement a lending policy, a charging scheme for digitalgoods, an auction, the full set of operations of a bank, andvirtually any other logic governing multi-party transactions.
Ethereum is the best-known, most popular blockchain plat-
form that supports full-featured smart contracts. (As of thiswriting, the Ethereum cryptocurrency market capitalizationis $13B.) Ethereum offers an excellent demonstration ofthe potential for smart contracts, as well as their technicalchallenges. Developers typically write smart contracts in ahigh-level language called Solidity, which is compiled intoimmutable low-level Ethereum VM (EVM) bytecode for theblockchain’s distributed virtual machine.
The open nature of smart contracts, as well as their role in
handling high-value currency, raise the need for thorough con-tract analysis and validation. This task is hindered, however, bythe low-level stack-based design of the EVM bytecode that hashardly any abstractions as found as in other languages, suchas Java’s virtual machine. For example, there is no notion offunctions or calls—a compiler that translates to EVM bytecodeneeds to invent its own conventions for implementing localcalls over the stack.
It is telling that recent research [1], [9], [22], [34] has
focused on decompiling smart contracts into a higher-levelrepresentation, before applying any further (usually security-oriented) analysis. Past decompilation efforts have been, atbest, incomplete. The best-known decompiler (largely deﬁningthe state-of-the-practice) is Porosity [33], which in our studyfails to yield results for 50% of deployed contracts of allsmart contracts on the block chain. Upcoming research toolsincluding the V andal decompiler [35] still fail to decompile asigniﬁcant portion of real contracts (around 12%) due to thecomplex task of converting EVM’s stack-based operations toa register-based intermediate representation.
Such difﬁculties are much more than technicalities of the
platform or idiosyncrasies of existing tools. Any current orfuture smart contract platform is likely to employ virtualmachines that are low-level. The designs of these virtualmachines are optimized for massively replicated execution ofsmart contracts. The bytecode effectively represents an as-sembly language designed for efﬁcient execution and compactprogram representation, since the bytecode must be stored onthe blockchain. Hence, the bytecode for smart contracts willnever be optimal for human readability or reverse compilation.
For effective decompilation, signiﬁcant program compre-
hension of the bytecode is necessary. A decompiler requiresdeep program understanding before it can reconstruct the
bytecode to a high-level representation. For instance, to recog-nize which low-level jumps correspond to high-level functioncalls, a decompiler must deduce possible addresses for jumpinstructions to be able to reconstruct the control-ﬂow of asmart contract. Such understanding is compounding: once callsare recognized as calls (and not just as a mere intra-proceduraljump), its decompilation precision can further improve, bypruning impossible targets.
11762019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ©2019 IEEE
DOI 10.1109/ICSE.2019.00120
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. In this paper, we introduce the Gigahorse toolchain for
analysis of Ethereum smart contracts. Gigahorse addresses the
above challenges, making the following contributions:
•It offers a highly-effective decompiler, yielding higher
precision and completeness than the state-of-the-art (e.g.,
decompiling virtually all existing contracts on the Ethereum
blockchain).
•Gigahorse anchors around it a full-featured tool suite,
offering libraries for building analyses, as well as ready-
made clients for existing analyses.
•The Gigahorse approach provides new decompilation in-
sights (possibly of value for many more platforms): As
higher level program features are discovered, they feed back
to lower level analyses. E.g., by discovering functions, stack
analyses are performed locally (more precisely), and the
effects of function calls on the stack are also summarized,
enabling both more precise and more scalable analysis.
•Gigahorse showcases an unconventional decompilation ap-
proach, which enables the above beneﬁts: the decompiler is
speciﬁed declaratively, using logic-based (Datalog) rules.
•Gigahorse is evaluated and its features illustrated on the
full set of smart contracts of the Ethereum blockchain.
Gigahorse is powering the ongoing free Contract Library
service ( https://contract-library.com ), which offers decom-
piled versions of all contracts on the Ethereum blockchain.
Contract Library is a valuable service for Ethereum security
analysts, and is currently receiving several tens of unique
visitors and over a thousand page views per day.
II. B ACKGROUND
We next present some background on the EVM bytecode
language and declarative static analysis.
A. Low-Level Bytecode in the Ethereum Blockchain
The EVM is a stack-based low-level intermediate represen-
tation (IR). In the bytecode form of a smart contract, symbolic
information has been replaced by numeric constants, functions
are fused together in a sea of instructions, and control-ﬂow is
obfuscated by jump addresses that are popped from the stack.
To highlight this issue, it is instructive to compare the EVM
bytecode language to the best-known bytecode: Java (JVM)
bytecode—a much higher-level IR. The differences include:
•Unlike JVM bytecode, EVM does not have the notion of
structs or objects, nor does it have a concept of methods.
•Java bytecode has a rich type system, EVM bytecode has
a single type: a 256bit word.
•In JVM bytecode, stack depth is ﬁxed under different
control-ﬂow paths: execution cannot reach the same pro-
gram point with different stack sizes. In the EVM byte-
code, no such execution constraints exist, which make the
identiﬁcation of standard control-ﬂow constructs very hard.
•All control-ﬂow edges (i.e., jumps) are to variables, not
constants. The destination of a jump is a value that is read
from the stack. Therefore, a value-ﬂow analysis is necessary
even to determine the connectivity of basic blocks. In
contrast, JVM bytecode has a clearly-deﬁned set of targets
for every jump, independent of value ﬂow.•JVM bytecode has deﬁned method invocation and return
instructions. In EVM bytecode, although calls to outside a
smart contract can be resolved, function calls inside a con-
tract are translated to just jumps (to variable destinations,
per the above point). All functions of a contract are fused
in one stream of instructions, with low-level jumps as the
means to transfer control.
To call an intra-contract function, the code pushes a return
address to the stack, pushes arguments, pushes the destina-
tion block’s identiﬁer (a hash), and performs a jump (which
pops the top stack element, to use it as a jump destination).
To return, the code pops the caller’s basic block identiﬁer
from the stack and jumps to it.
B. Declarative Program Analysis
Our work is based on declarative static program analysis,
applied to smart contract decompilation. Declarativeness refers
to implementing an analysis as a collection of logical rules
(i.e., simple implications) that lead to inferences, which in
turn trigger more rule inferences, up to the least ﬁxpoint. The
Datalog language is the most standard vehicle for declarative
analysis approaches, both low-level [4], [16], [19], [27], [29],
[36] and high-level [7], [11], [23], [24]. Additionally, Datalog-
style inference rules have been used in formal speciﬁcation
tasks, such as the ofﬁcial speciﬁcation of the Java VM veri-
ﬁer [17, p.170-320].
Datalog is less of a programming language and more of
a speciﬁcation language, since computation is based on two
constructs: logical implication rules, and recursion. A Datalog
rule “C( z,x)← A(x,y), B( y,z).” means that if A( x,y) and
B(y,z) are both true, for some values x,y,z , then C( z,x) can be
inferred. Syntactically, the left arrow symbol ( ←) is a logical
implication symbol and separates the inferred facts (i.e., the
head of the rule) from the previously established facts (i.e.,
the body of the rule).
Recursion is the standard vehicle for expressing computa-
tions in Datalog. Static analysis tasks are typically recursive,
with multiple sub-algorithms collaborating towards a joint goal
expressing the semantics of a program. The sub-algorithms
have no clear stepwise order, but instead, all refer to (yet-
incomplete) results of other sub-algorithm in a large recursive
deﬁnition. In this way, the sub-algorithms enhance each other’s
results, each beneﬁting the others.
The declarative nature of the Datalog language means that
any order of ﬁring of the rules, and any order of evaluation of
a rule’s body will yield the same ﬁnal result. To maintain
this property, the implication in Datalog has to be strictly
monotonic: each rule’s ﬁring can only introduce new facts
and not hinder any of the previous inferences.
Part of the appeal of the Datalog language is that it currently
enjoys several high-performance implementations including
Soufﬂ ´e [13]. Besides high-performance computation, state-of-
the-art Datalog engines offer extensions to the language ex-
pressiveness: one can relax pure declarativeness and introduce
ordering, as well as invent new values via constructor func-
tions. We will refer to such non-purely-declarative facilities
explicitly in our technical presentation.
1177
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. III. G IGAHORSE DECOMPILA TION SPECIFICA TION
In this section, we present the core building blocks of
the Gigahorse decompiler. We use Datalog as a speciﬁcation
language for the decompiler. The Datalog rules are simpliﬁed
but keep the essential complexity of their counterparts in
the actual Gigahorse implementation. We attempt to provide
as much technical detail as possible without sacriﬁcing the
readability and understandability of this paper. In this effort,
the exposition will be uneven: we give in-depth details in the
ﬁrst few sub-sections, and elide technical details in later parts
(of both Sections III and IV) when the reader will be able to
ﬁll the gaps.
A. Overview of Decompilation Steps
We next summarize the main decompilation actions per-
formed by the Gigahorse decompiler. For the sake of exposi-
tion, we describe a conceptual stepwise process, even though
the decompiler speciﬁcation is declarative and does not have
an explicit order of operations. Starting from the original
bytecode, the Gigahorse decompiler:
1) Finds basic block boundaries. The output to the next step
is the original bytecode , split by basic blocks.
2) Performs local analysis of stack effects of basic blocks.
The input of the next step attaches to the bytecode
relevant summaries of stack effects per block.
3) Performs whole-contract context- and ﬂow-sensitive
dataﬂow analysis with on-the-ﬂy control-ﬂow graph
(CFG ) construction. This information is used to produce
a 3-address IR, with global registers. We refer to this IR
asglobal 3-address IR .
4) Infers function boundaries heuristically (i.e., entry and
exit blocks, together with function calls) for public and
private functions. The function boundaries enable the
decompiler to transform the global CFG into local CFGs
and a call graph.
5) Infers function arguments and return arguments for all
functions, introduces fresh variables for these and per-
forms an intra-procedural ﬂow-sensitive analysis to infer
the ﬂow of these fresh variables. The output form is
afunctional 3-address IR , i.e., all variables are local
variables and are scoped. Data is passed around functions
through formal arguments, return arguments, or external
constructs like storage and memory.
All the above steps work in concert to derive a high-level
representation from the original bytecode. In this section, we
focus on steps 2 and 3, and assume that the input is already
parsed as statements in basic blocks (step 1). Section IV
focuses on steps 4 and 5.
The original bytecode and our two IRs (the global 3-address
IR and the functional 3-address IR) have common elements,
but also differ in important ways. Throughout the descriptions
of these, we will override certain concepts, such as statements
or variables. For instance, variables in the global 3-address
IR are global variables, whereas for the functional 3-address
IR they are all local. The distinction between these should be
clear from context.Sis a set of statement identiﬁers, S⊆Z
Cis a set of constants, C⊆Z
Vis a set of new variables
Bis a set of basic block identiﬁers
Iis a set of stack indices, from 0 to 1023
PUSH( s:S ,v a l: C) BINOP( s:S )
DUP( s:S ) POP( s:S )
JUMPDEST( s:S ) JUMPI( s:S )
NEXT (p r e v:S ,n e x t:S )
BLOCK (stmt : S, block : B )
BLOCK HEAD (block : B, stmt : S )
BLOCK TAIL(block : B, stmt : S )
PUSHES ANDPOPS (sOrB : S∪B, pushes : N, pops : N)
LOCAL DEFINES (stmt : S, var : V)
LOCAL STACK OUT(stmt : S, index : I, vOrI : V∪I)
LOCAL STACK IN(s t m t:S ,n:I , vOrI : V∪I)
VARIABLE VALUE (var : V , val : C)
NEWFRESH VAR(s t m t:S ,n: N)= variable : V
Fig. 1. Our domain, input relations representing the original bytecode, com-
puted relations and outputs. The input relations encode program instructions
and other environment information.
B. Input Language
Figure 1 describes the schema of the input and main inter-
mediate relations, together with the domains of the program
representation at this level of abstraction. Stack indices Iby
deﬁnition are between 0 and 1023, and we assume that all
arithmetic operations on Iare only deﬁned in that range (i.e.,
no overﬂow or underﬂows). Notice that the original bytecode
relations, such as PUSH or BINOP, make no references to
variables since the EVM is a stack-based machine. Relations
that capture instructions refer to a unique statement identiﬁer.
The PUSH instruction pushes a constant to the top of the
stack (which starts from 0). The BINOP operation denotes
any binary operation that takes the ﬁrst two operands from
the stack and returns a result into the stack. The speciﬁc form
of binary operations is elided for presentation reasons, but
examples include ADD, MUL, SHA, etc.
The JUMPDEST operation is a no-op, which only serves
to mark its statement identiﬁer as being a valid address to
jump to. The JUMPI instruction is a conditional jump, which
jumps to the address at the topmost element of the stack, if
the element of stack position 1 is not zero. The input relation
NEXT returns the next statement identiﬁer in program order
for a given statement identiﬁer. The relation B LOCK maps a
statement to its block, whereas B LOCK HEAD and B LOCK TAIL
indicate the head and tail statements of a block. Finally, input
relation P USHES ANDPOPS returns the maximum number of
stack elements that a statement or an entire block pushes and
pops. More precisely, for basic blocks this is a high-/low-
watermark computation: the maximum and negated minimum,
over all points in a block, of the balance of elements pushed
minus those popped at that program point.
C. Local Stack Analysis
The bottom part of Figure 1 shows the relations inferred
by step 2 of the decompilation: the local stack analysis. This
1178
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. step summarizes the effects on the stack, per basic block,
introduces the concept of variables (since none exist in the
input representation), as well as performs a ﬁrst value analysis,
computing a static abstraction of the contents of the execution
stack at every statement.
Relation L OCAL DEFINES connects a statement with a
freshly introduced variable, if the statement pushes new el-
ements on the stack. Relations L OCAL STACK INand L O-
CAL STACK OUT model the variables (or stack aliases) that
each stack position contains before and after executing each
statement, respectively. For instance, L OCAL STACK OUT(stmt,
index, v ) means that at statement stmt , stack position index
contains the same value as variable v(freshly-introduced
by some previous statement). The domain of these relations
includes both variables and stack aliases ( V∪I). A stack alias
(i.e., a stack index outside the range of values pushed by the
current basic block) refers to a value that existed in a given
stack position before the beginning of the basic block. This is
because each basic block is analyzed in isolation, and stack
values can also be passed from block to block. The earlier-
deﬁned input relation P USHES ANDPOPS gives the maximum
number of possible stack aliases.
Finally, relation V ARIABLE VALUE maps some of the vari-
ables to program constants. Any variable that is not present in
this relation is considered dynamically computed, and its value
is not modeled in this formalization (although we partially
model some dynamic operations in the full implementation).
The rules that describe the local stack analysis are shown in
Figure 2. The computation of L OCAL DEFINES introduces new
variables (one per statement that needs it) via a constructor
NEWFRESH VAR, also used in later sections. This constructor
function will typically be deﬁned to retain all information
passed to it:
NEWFRESH VAR(stmt, n )= pair(stmt, n) :V
The computation of relations L OCAL STACK INand L OCAL -
STACK OUTis more involved, and the relations are mutually
recursive. (As a convention, the rules use ∗as a wildcard, i.e.,
it denotes any element, which is ignored.) Both relations have
easy base cases: for L OCAL STACK OUT, if a statement assigns
a fresh variable, then stack position 0 holds the value of this
variable. For L OCAL STACK IN, if a statement is the ﬁrst in a
basic block, all stack positions that may be accessed contain
stack aliases (i.e., their contents are represented by just the
appropriate stack index and not by a fresh variable).
The recursive rules for L OCAL STACK OUT appeal to L O-
CAL STACK IN: At a DUP, the top of the stack after the
instruction has the same value as the top of the stack before
it. At all instructions, the unchanged contents of the stack
are propagated, at indexes adjusted based on the pushes and
pops performed by the instruction. Similarly, the recursive rule
for L OCAL STACK INmerely propagates all values from the
previous statement in the same basic block.
The above formulation illustrates well the declarative ap-
proach in the Gigahorse decompiler. Inspecting the rules and
their apparent simplicity, it is hard to even convince oneself
that they compute something useful. Yet they compactly cap-
ture the full ﬂow of constant values over the EVM execution
stack, at every stack position. Furthermore, the formulationNEWFRESH VAR(stmt, 0 )= v,
LOCAL DEFINES (stmt, v )←
PUSHES ANDPOPS (stmt, n, * ),n>0, !DUP( stmt ).
LOCAL STACK OUT(stmt, 0, var )←
LOCAL DEFINES (stmt, var ).
LOCAL STACK OUT(stmt, 0, vOrI )←
DUP( stmt ), L OCAL STACK IN(stmt, 0, vOrI ).
LOCAL STACK OUT(stmt, n + pushes - pops, vOrI )←
LOCAL STACK IN(stmt, n, vOrI ),
PUSHES ANDPOPS (stmt, pushes, pops ),n≥pops .
LOCAL STACK IN(stmt, i, i )←
BLOCK HEAD (block, stmt ),
PUSHES ANDPOPS (block, *, pops ),i<pops .
LOCAL STACK IN(stmt, n, var )←
LOCAL STACK OUT(prevStmt, n, var ),
NEXT (prevStmt, stmt ), !B LOCK HEAD (*, stmt ).
VARIABLE VALUE (var , val )←
PUSH( stmt, val ), L OCAL DEFINES (stmt, var ).
Fig. 2. Relations to perform local (within each basic block) analysis
carefully mixes the concept of freshly-introduced variables
with that of values at a stack position. The fresh variables both
are essential for decompiling into a 3-address representation
and serve as names to succinctly represent values.
D. Global Stack Analysis and CFG construction
Armed with a model of the contents for stack positions, the
decompiler can now compute the targets of jump instructions
(since these are values obtained from the stack). Global stack
analysis and control-ﬂow graph (CFG) construction is one
of the most computationally-heavy parts of the analysis. We
introduce additional relations in Figure 3 (top) and their
deﬁnition (bottom).
Relations B LOCK INand B LOCK OUTare global analogues
of L OCAL STACK INand L OCAL STACK OUT, and are com-
puted by transferring values between each other according to
the CFG deﬁned by G LOBAL CFG. Computing G LOBAL CFG
is the main part of this analysis step. A trivial CFG edge exists
(in inverse direction) between the ﬁrst statement of a basic
block (given by B LOCK HEAD ) and any of its predecessor
statements. More interestingly, a CFG edge exists between any
conditional jump instruction ( JUMPI) and any basic block
address (i.e., a constant value) held by the variable used to
denote the jump target in the program. This makes CFG con-
struction mutually recursive with the global ﬂow analysis, as is
typical with state-of-the-art frameworks for program analysis
of higher-order languages with virtual calls, such as Java [28].
The ﬁnal outputs of this analysis are embedded in relations
GLOBAL CFG and L OCAL USES. The latter relation represents
which variable ﬂows to which statement, in the same order as
in the original EVM stack. The relation effectively connects
the value ﬂow between basic blocks, by resolving stack aliases
1179
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. BLOCK IN(block : B, index : I, var : V )
BLOCK OUT(block : B, index : I, var : V )
JUMP TARGET (f r o m:B ,v a r:V ,t o:B )
GLOBAL CFG( f r o m:B ,t o:B )
LOCAL USES(stmt : S, position : N, var : V)
BLOCK IN(jumpee, index, var )←
BLOCK OUT(jumper , index, var ),
GLOBAL CFG( jumper , jumpee ).
BLOCK OUT(jumpee, index+pushes-pops, var )←
BLOCK IN(jumpee, index, var ),
PUSHES ANDPOPS (jumpee, pushes, pops ),index≥pops .
BLOCK OUT(block, index, var )←
GLOBAL CFG( *, block ), B LOCK TAIL(block, stmt ),
LOCAL STACK OUT(stmt, index, var ),var∈V.
GLOBAL CFG( jumper , ftBlock )←
GLOBAL CFG( *, jumper ), B LOCK (stmt, jumper ),
NEXT (stmt, ft ), B LOCK HEAD (ftBlock, ft ).
JUMP TARGET (jumper , var , jumpee ),
GLOBAL CFG( jumper , jumpee )←
BLOCK (stmt, jumper ), JUMPI( stmt ),
LOCAL USES(stmt, 0, var ),
VARIABLE VALUE (var , jumpdest ),
JUMPDEST( jumpdest ), B LOCK (jumpdest, jumpee ).
LOCAL USES(s, i, v )←
LOCAL STACK IN(s, i, v ),v∈V.
LOCAL USES(s, i, v )←
LOCAL STACK IN(s, i, j ),j∈I,
BLOCK (s, b), B LOCK IN(b, j, v ).
Fig. 3. Rules to describe the global stack analysis and on-the-ﬂy control-ﬂow
graph construction.
(i.e., stack positions set by predecessor basic blocks, as deﬁned
in Section III-C) when the interconnectivity of basic blocks is
determined. This again demonstrates well the compactness and
power of a declarative speciﬁcation.
After performing these analyses, we can now produce global
3-address code using the schema and rules listed in Figure 4.
This representation is adopted from the V andal [9], [35]
decompiler. The conversion to 3-address IR at this point is
straightforward. Syntax sugar and minor detail elision are em-
ployed for presentation purposes. Language syntax is quoted
using [and ]and implicitly unquoted for meta-variables. For
instance, s:[to:=BINOP( x, y)]indicates that statement sis
some binary operation on xandywith its result in to, where
x,y, and toare the meta-variables referring to the bytecode
variables. The distinction between variables in the analyzed
program and meta-variables in the analysis is clear from
context, therefore we simply refer to “variables”. We reuse the
instruction opcodes from the original bytecode whenever these
make sense. Instructions that do not deﬁne any new variables
or perform computation, such as DUP or JUMPDEST are not
present in this representation. From this point, unless otherwises:[to:=CONST( c)]←
PUSH( s, c), L OCAL DEFINES (s, to ).
s:[JUMPI( cond, label )]←
JUMPI( s),
LOCAL USES(s, 0, cond ), L OCAL USES(s, 1, label ).
s:[to:=BINOP( a, b )]←
BINOP( s), L OCAL DEFINES (s, to ),
LOCAL USES(s, 0, a ), L OCAL USES(s, 1, b ).
Fig. 4. The rules and relations that compute the global 3-address IR, an
important intermediate decompiler representation.
speciﬁed, whenever we refer to “statements”, or their identiﬁer
S, we will be referring to statements in the 3-address IR
representation.
IV . R ECONSTRUCTING SOURCE LEVEL FUNCTIONS
An essential element in the Gigahorse decompilation is the
inference of functions, which have been dissolved by the com-
pilation to EVM bytecode. We ﬁnd that this inference process
enters a virtuous circle with the CFG inference of the previous
section: CFG inference informs function reconstruction, and
functions inform an even more precise CFG inference.
A. Public Functions
The current EVM version does not have notions of functions
(call stacks will be introduced in a future version [30]).
However, all programming languages that compile down to
EVM support functions. The ABI (application binary inter-
face) for Solidity and the EVM introduces the notion of public
functions, so that external contracts or users can call public
functions by specifying the hash of the function signature. By
identifying the dispatching patterns that are introduced by the
Solidity compiler, the Gigahorse decompiler ﬁnds all public
function entries in the code. For instance, let us look at the
following simpliﬁed global 3-address IR:
// get hash supplied from caller
v12 = CALLDATALOAD v10
// check whether supplied hash matches
v1a = EQ v12 0x6fdde03
// conditionally jump to function 0x6fdde03
JUMPI 0x139 v1a
// nope, try this one instead
v25 = EQ v12 0x95ea7b3
// conditionally jump to function 0x95ea7b3
JUMPI 0x1b4 v25
We can see that there are two public functions, one with
the function descriptor of 0x6fdde03 that begins at address
0x139 , and one with the function descriptor 0x95ea7b3
that begins at address 0x1b4 . Since the ABI is standard, we
expect that all dispatching patterns by all compilers are catered
for. This matching is rather straightforward for any decompiler
to perform.
The only additional feature that Gigahorse adds is a pre-
sentational convenience: Gigahorse tries to match function
descriptors, such as 0x95ea7b3 , to the source-level function
signatures, such as approve(address,uint256) . This
is made possible by consulting an existing database [31]
1180
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. of public function signatures. This allows detecting source
signatures for over two-thirds of public functions in deployed
contracts.
B. Searching for Functions that Return
The challenge in reconstructing functions concerns private
functions, which have all but disappeared from the compiled
code. To detect private functions, Gigahorse employs complex
heuristics that require a full global dataﬂow information prop-
agation and the construction of CFGs. The ﬁrst heuristic is to
look for speciﬁc instances of passing addresses on the stack
inter-procedurally, when these addresses are subsequently used
for further jumps after running a function. For instance, let us
look at the following simpliﬁed global 3-address IR:
bar: ...
va = CONST <ret> // set return address
vb = CONST 0xFF // set data
vc = CONST <foo> // set function address
JUMPI vc 0x1 // jump to foo
ret: ...
foo: ...
JUMPI va 0x1 // jump to ’ret’
This program snippet ﬁrst passes the return address <ret>
before jumping to <foo> . At the end of <foo> , it jumps back
to the return address that was passed before. This function
search heuristic, therefore has to identify that (a) a basic block
(return) jumps to a valid non-locally-derived address, which
(b) originates at another block (the caller) that can reach the
return basic block. This heuristic is condensed in a relation,
which is further reﬁned into F NCALL RETby:
•Making sure that a basic block can only belong in a single
function. When a conﬂict arises, we deterministically pick
a function according to a total ordering of our choice.
•Making sure that a function can only be entered through a
function call.
C. Decomposing Functions Further
Detecting functions that return to their callers is not suf-
ﬁcient in the context of the EVM. Functions that terminate
(e.g., halt) are disproportionately common in smart contracts,
since smart contract computation is typically short. Therefore,
Gigahorse employs additional logic to detect functions that
do not return. The main idea is that a basic block is in an
independent function if it is reachable from two (or more)
previously-identiﬁed distinct functions. This is an intuitively
inevitable rule: if two functions both use the same code, this
code must also be factored into a reusable fragment, i.e., a
function. (Note that, unlike the technique of Section IV-B,
this approach only detects source-level functions that are called
more than once—functions that are called just once are inlined
with no loss of precision.)
In more detail, the detection logic identiﬁes basic blocks
reachable via paths that: (a) start from two or more function
entries (corresponding to previously-identiﬁed functions A
and B, for instance), where (b) each path remains within
its source function (A or B respectively). The process is
actually recursive—as more functions are discovered, more
opportunities arise for some basic block to be reachable frommore functions. Although the number of functions discovered
is monotonically growing, the logic is not monotonic at the
Datalog syntax level: in order to describe paths that occur
strictly within a single function, the logic needs to express that
“a path does not cross into a different function”, i.e., to use the
negation of the call-graph edges predicate, whose contents are
also growing in the same computation.1For this reason, we
use a ﬁxpoint loop external to the (monotonic) Datalog rules,
so that we are able to iteratively recompute relations at every
step, and each relation can refer to versions at the previous
iteration. (In the implementation, this is done via the standard
“components” facility of the Soufﬂ ´e Datalog engine [13] that
Gigahorse uses.)
The complete algorithm is shown in Figure 5. The in-
put relation, P UBLIC FUNCTION CALL is derived as described
in Section IV-A, while F NCALL RET is described in Sec-
tion IV-B. From these two relations we compute the inputs
our algorithm, i.e., C ALL GRAPH 0and F UNCTION ENTRY 0.
The algorithm then proceeds to discover new functions at
each iteration (F UNCTION ENTRY nand C ALL GRAPH n), and
each time recomputes paths reachable from the function entry
(REACH FROM n).
After computing a least ﬁxpoint on F UNCTION ENTRY , i.e.,
no more new functions are discovered, we can proceed to
compute local CFGs and call graphs. The call graphs are
computed by taking a union over all C ALL GRAPH n, i.e.,/uniontext
n∈NCALL GRAPH n, which we simply refer to as C ALL GRAPH
from this point onwards. We also assume the same for F UNC -
TION ENTRY . The local CFGs are then computed as follows:
LOCAL CFG( block : B, next : B )
LOCAL CFG( block, next )←
GLOBAL CFG( block, next ),
!FUNCTION ENTRY (next ),
!FNCALL RET(*, *, block, next ).
LOCAL CFG( block, next )←
GLOBAL CFG( block, func ),
FNCALL RET(block, func, *, next ).
That is, the function inference helps ﬁlter out previously-
inferred CFG edges, if these do not agree with the functional
abstraction. Such spurious edges arise due to inherent impre-
cision in any static analysis. In our rules, this imprecision
is mainly introduced at control-ﬂow join points, i.e., because
of multiple predecessors of a basic block getting their stack
contents mixed up, based on the logic of Figure 3.
D. Inferring Function Arguments and Local V ariables
Inferring function boundaries and local CFGs is very bene-
ﬁcial to client analyses. Not only are local CFGs more precise
(as discussed) but function-level reasoning enables summary-
based analyses (which are typically very scalable and highly
precise). In order to enable summary-based data-ﬂow analyses,
we need to have local variables, and minimize the number of
global variables.
1No real non-monotonicity exists: even though some path may later be
found to be invalid—by crossing into a different function—different paths
with the same overall property inevitably exist.
1181
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. PUBLIC FUNCTION CALL (caller : B, func : B )
FNCALL RET(caller : B, func : B, ret : B, rTarg : B )
RETURN BLOCK (r e t:B )
CALL GRAPH n:N(caller : B, func : B )
FUNCTION ENTRY n:N(func : B )
REACH FROM n:N(func : B, block: B )
RETURN BLOCK (ret),
FUNCTION ENTRY 0(func ),
CALL GRAPH 0(caller , func )←
FNCALL RET(caller , func, ret, * ).
FUNCTION ENTRY 0(func ),
CALL GRAPH 0(caller , func )←
PUBLIC FUNCTION CALL (caller , func ).
FUNCTION ENTRY 0(0x0).
i=1 .
DO{
REACH FROM i(block, block )←
FUNCTION ENTRY i−1(block )
REACH FROM i(func, next )←
REACH FROM i(func, block ),
GLOBAL CFG( block, next ),
!CALL GRAPH i−1(block, next ),
!RETURN BLOCK (block ).
CALL GRAPH i(prev, block ),
FUNCTION ENTRY i(block )←
REACH FROM i(f1, block ), R EACH FROM i(f2, block ),
GLOBAL CFG( prev, block ), !R ETURN BLOCK (prev ),
!REACH FROM i(f1, prev ), !R EACH FROM i(f2, prev ).
i=i+1 .
}UNTIL FIXPOINT (FUNCTION ENTRY )
Fig. 5. Heuristic for decomposing functions further.
Gigahorse infers the number of function arguments by
computing the number of caller-supplied elements that the
entire function pops from the stack throughout its execution.
Similarly, the number of function return arguments is inferred
by calculating the balance of extra (pushed and not popped)
elements pushed up to a call instruction. Unfortunately, the
EVM does not guarantee that the stack depth is statically
known at each program point (unlike, say, the Java VM). A
good practical solution to this is to infer all possible push and
pop balances along a function’s execution paths, up to a ﬁnite
upper bound, and take the minimum number of these at the
end of the returning basic block. This is a heuristic strategy,
whose effectiveness is validated experimentally.
After inferring the number of function arguments and return
values, Gigahorse proceeds to create fresh variables for them
using the NEWFRESH VAR constructor. This logic is elided
for space reasons.
The last analysis step is to infer (non-argument) local
variables and places where these variables ﬂow to. This is
a computation analogous to the introduction of variables,
before functions are detected, in Section III-D (predicateLOCAL USES in Figure 4). The main output of the analysis
is predicate F UNCTIONAL USES(s:S ,i:I ,v:V ), which, for
each statement, indicates which local variables are used and
in which order. Using this relation, we can produce the ﬁnal
functional 3-address IR, similar to the process described in
Figure 4. At this point, we can also introduce the additional
opcodes PRIV A TECALL and PRIV A TERETURN, which
substitute jump instructions that call functions or return from
a function.
V. I MPLEMENTA TION AND DISCUSSION
The speciﬁcation of the previous sections captures the
essence of the Gigahorse implementation. The actual Datalog
speciﬁcation of the decompiler has more technical details,
comprising several hundred logical rules (over 3K lines of
Datalog, using Soufﬂ ´e [13] as the dialect and execution
engine) and a small Python scaffolding (of around 1K lines)
borrowed from V andal [35]. Compared to the speciﬁcation, the
full implementation contains:
•handling of the full instruction set of the EVM, as opposed
to the minimal instruction set presented;
•several more decompilation heuristics, secondary but com-
plementary to the ones discussed in Sections III and IV.
•context sensitivity throughout the rules: concepts such as
CALL GRAPH have their elements qualiﬁed by a “context”,
which allows more precise static analysis. (We use a 1-call-
site context—a.k.a. 1-CFA—as the default.)
•a library facilitating further client analyses;
•example clients.
We next discuss some of the above in more detail.
A. Deployment
Gigahorse has been applied over the entire contents of the
Ethereum blockchain, with the results of decompilation offered
as the free Contract Library service ( https://contract-library.
com ). Contract Library has received very positive feedback
from the Ethereum community.
B. Output and Client Analyses
Gigahorse produces output both in structured form (i.e.,
tables, exported as CSV ﬁles) and in pretty-printed text. A
very simple contract, below, helps as illustration.
.
function _functionSelector() public {
v27 = (CallDataLoad(0x0) / 0x1000...);
if(0x5fdf05d7 == v27) two();
if(0x901717d1 == v27) one();
exit();
}
function two() public { f0x57(0x2); exit(); }
function one() public { f0x57(0x1); exit(); }
function f0x57(varg1) private {
STORAGE[0x0] = varg1; return ();
}
Gigahorse infers four functions in total, two of which are
public functions with a high-level function name. A private
function, f0x57 , is also inferred. All low-level jumps have
been transformed into high-level control-ﬂow and calls/returns.
Of the jump instructions in the original contract bytecode, only
the one corresponding to the return statement is polymorphic,
1182
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. since it can return to two callers. Gigahorse has no trouble
detecting this as a proper function with return, which enables
more precise data ﬂow. The other decompilers in our evalu-
ation set, Porosity, V andal and EthIR, fail to ﬁnd the private
function and call-return pattern.
Gigahorse has been designed as a framework for writing
security-related analyses on top of its high-level functional
3-address IR. In order to facilitate the development of these
client analyses, Gigahorse offers additional development tools.
For client analyses implemented in Datalog, we developed
a bulk analyzer that can be supplied with a user-deﬁned
pipeline of client analyses. These are compiled and executed
in parallel, in tandem with the decompilation. Client analyses
for Gigahorse can be written in any language by reading the
decompilation results from CSV ﬁles. In fact, one of our
client analyses is a high-level pretty-printer, which takes the
decompiler’s output and outputs high-level Solidity-like code,
including function signatures, control-ﬂow structures such as
if statements, some types and complex expressions. This is
a useful tool for the human inspection of smart contracts.
Additionally, Gigahorse offers a Datalog API for the decom-
pilation results together with libraries of analysis functions
tuned for the decompiler’s output. These libraries perform
data-ﬂow, dependency, and loop-semantic analysis. The data-
ﬂow analysis library is able to compute an intra-procedural
data-ﬂow analysis or summary-based inter-procedural data-
ﬂow analysis. The latter is enabled by the rich functional
decompilation described in the previous section. All anal-
yses are highly parametric. Users can instantiate multiple
versions, each deﬁning its own transfer functions, and can
also limit the scope of an analysis (e.g., analyze only loop-
induction variables within loops). The loop-semantic anal-
ysis identiﬁes loops and other control-ﬂow structures, their
exit conditions, induction variables, dominators, etc. Using
the provided libraries we have ported the recently-published
MadMax client analysis for gas-related vulnerabilities [9] to
the Gigahorse decompiler with similar results but with much
higher performance, and for over 99.9% of the deployed smart
contracts. The re-implementation of MadMax comprises just
250 lines of code, showcasing the power of the client analysis
infrastructure of Gigahorse.
C. Declarativeness and Monotonicity
The declarative nature of Gigahorse has been a signiﬁcant
facilitator of its decompilation effectiveness. (Speculatively,
this is an insight that may be also applicable in other de-
compilation domains, such as machine code decompilation.)
Logical rules allow for concise expression of decompilation
patterns and heuristics. Perhaps more importantly, separate
patterns can be speciﬁed completely independently, with no
ordering or other artiﬁcial dependency. Still, the independent
patterns can beneﬁt or complement each other. Dependencies
between decompilation patterns (e.g., that one needs to run
before another) are determined automatically by the execution
engine. Dependencies between decompilation patterns arise
naturally in the speciﬁcation we saw in earlier sections—e.g.,
the call-graph informs the ﬂow analysis and vice versa. We
also saw a representative example of complementary decom-pilation patterns in Section IV: one pattern detects functions by
tracking that they are called and return to their call site), while
another detects that a block must be in a separate function
because it is reachable by two existing ones. Neither pattern
is more complete or more precise than the other.
VI. E V ALUA TION
There are several research questions that our experiments
intend to answer:
RQ1: Scalability —is Gigahorse a scalable and efﬁcient de-
compiler, for all contracts in the wild?
RQ2: Completeness/Coverage —how well does the decom-
piled code cover the original code available in the wild?
RQ3: Precision —does the decompiled code precisely match
high-level semantics?
For most of these research questions, we will be com-
paring Gigahorse against Porosity (the best-known, state-of-
the-practice Ethereum decompiler at submission time) and
V andal [35] (a recent research tool, probably the closest
comparable in the literature). In Section VI-E we also perform
an experiment with less closely related tools.
Our experimental setup consists of all programs available on
the Ethereum blockchain as of April 2018. This makes up the
universe set of “contracts in the wild” of around 6.6 million
contracts deployed from 91.8K unique programs.
We ran all systems on an idle machine with an Intel Xeon
E5-2687W v4 3.00GHz and 512GB of RAM. To bound the
(long) time to run experiments, we set a cutoff of 120s
for decompilation. (As we show, decompilation time for
successfully-decompiled contracts is on average over 10 times
below this threshold, for all systems.) Any contracts that take
longer to decompile are considered to timeout. All experiments
were conducted in parallel. Our machine has 48 logical cores,
so we ran 45 processes in parallel. Note that the Gigahorse
decompiler can also be conﬁgured to parellelize decompilation
within a single contract, which is an option we did not enable
when analyzing multiple contracts in bulk.
We emphasize that our evaluation is quantitative, based on
several metrics, but we have conﬁrmed by manual inspection
of numerous contracts that the metrics reﬂect well the actual
quality of decompilation.
A. RQ1: Scalability
To answer this question we employ the following metrics:
Timeouts/fatal errors , i.e., proportion of contracts that were
not successfully decompiled due to timeouts or fatal errors.
Contracts with at least one function detected according to
the respective decompiler.
Time i.e., wall-clock time taken to decompile the average
contract, excluding contracts that time out.
Contract size in terms of the number of functions computed
by the Gigahorse decompiler.
The table below summarizes the ﬁrst three metrics. (We
use the convention that for metrics in italics lower is better,
otherwise higher is better.)
no timeout ≥1functions time
Gigahorse 99.98% 79.9% 0.7s
V andal 88.13% 63.7% 5.7s
Porosity 48.56% 17.4% 1.2s
1183
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. Fig. 6. Successful decompilation vs. unsuccessful decompilation against size
of contracts (number of functions).
Gigahorse is both very fast (over 4x faster than V andal,
for higher decompilation quality) and scalable to all contracts.
Both Porosity and V andal fail to decompile a signiﬁcantportion of the contracts. As can be seen, Porosity is bimodal:it is fast for the contracts it manages to decompile, or hits ascalability wall. Our setup, giving Porosity 100x the time ofits average successful decompilation (120s), still did not allowdecompilation of more than half of the contracts. The contractsthat are not decompiled correctly are larger in size, for bothPorosity and V andal—Figure 6 plots decompilation success vs.contract size in functions (as reported by Gigahorse, whosefunction inference is the most reliable).
Gigahorse also has the highest proportion of contracts with
at least a single function detected (apart from the dispatcherfunction). Having 0 functions is not necessarily proof ofincomplete decompilation, but it is a strong indicator, espe-cially when the numbers for Porosity and V andal diverge fromGigahorse, whose function inference is very reliable.
B. RQ2: Completeness
We employ the following metrics:
Unknown jump targets, i.e., proportion of jumps that do not
have a target for the non-fallthrough case.
Unreachable code, i.e., % of unreachable basic blocks.
Number of functions per contract, as indicated by the
respective decompiler.
The results of these metrics are shown in the following table.
unknown jump unreachable functions
targets code / contract
Gigahorse 0.00% 8.7% 21.0
V andal 0.81% 19.8% 12.2
Porosity N/A N/A 1.92
Note that the output of Porosity is not in a format that
enables the measurement of jump targets of unreachablecode, so we only measure functions. Gigahorse ﬁnds jumptargets for virtually all jump instructions, which translates intoless unreachable code than V andal. The number of functionsdetected (public or private) is also signiﬁcantly higher.
C. RQ3: Precision
To answer the question we employ the following metrics:Polymorphic jumps, i.e., proportion of jumps that resolve to
more than one target for non-fallthrough CFG edges.
Unstructured loops, i.e., proportion of loops with un-
usual control-ﬂow structure. This indicates imprecision in the
control-ﬂow graph.
Loops with an exit condition—the converse likely indicates
imprecision in the control-ﬂow graph.
Data ﬂows (values) per variable, in arithmetic or assign-
ments.
We only compare Gigahorse against V andal in this case, as
Porosity does not enable measurement of these metrics.
Poly. Unstr . Loops Data
jumps loops w/exit ﬂows
Gigahorse 2.58% 0.00% 96.6% 3.82
V andal 2.72% 11.7% 91.7% 8.20
Gigahorse fares better in all metrics. For instance, it com-
putes fewer polymorphic jumps (i.e., jumps with multiplepossible targets), primarily due to better context sensitivityduring the whole-contract analysis. The “data ﬂows” and“unstructured loops” metrics are most telling, and we discussthem next in the context of client analyses.
D. Discussion: Beneﬁts for client analyses
RQ3 shows that the number of values ﬂowing to variables
at arithmetic operations, is much lower for Gigahorse. This is
due to a variety of factors: summary-based analysis, contextsensitivity, and more precise CFGs. The data-ﬂow relation is aclient of the decompiler in its own right, but it is also useful forhigher-level clients, such as vulnerability detection analyses.
The detection of loops is also a client analysis offered by
the Gigahorse toolchain, where we can see that there are fewerunstructured loops detected in the inferred CFGs. Since thereare no high-level constructs in Solidity to write unstructuredloops, we expect that a good quality CFG has virtually nounstructured loops (which is the case in Gigahorse). Here,the context sensitivity and local CFGs offered by Gigahorsedirectly translate into a higher-quality client analysis.
We ported the recent MadMax gas-vulnerability detector [9]
(the main client of the V andal decompiler) to Gigahorse.Gigahorse analyzes virtually all contracts, rather than 92% inthe case of V andal. The performance of the client analysis alsobeneﬁts—the additional MadMax client analysis only costs0.15s of wall clock time per contract on average. The tablebelow summarizes the vulnerabilities ﬂagged by MadMax withdecompilation under V andal vs. under Gigahorse. (Neitherhigher nor lower numbers are better by default for this table.)
Unbounded Overﬂow Wallet
Iteration Loop Iter. Grieﬁng
Gigahorse 3.9% 1.8% 0.32%
V andal 4.1% 1.2% 0.12%
Although for liberal analyses (unbounded iteration) the
improved precision of Gigahorse yields lower numbers, formore exotic vulnerability patterns the improved completenessof Gigahorse (managing to analyze some-10% more contracts,among the largest available) yields more warnings.
E. Sensitivity Analysis
We next discuss varying several dimensions of our experi-
ments and how this affects the results.
1184
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. a) Different V andal settings: Published work on V an-
dal [9] claims a higher percentage of successfully decompiled
contracts: 91.8% vs. 88.1% in our experiments. The numbers
are close and the difference is due to slightly different settings.
To conﬁrm this, we also tried a different V andal setup, for
maximum decompilation ability, and got it to succeed in even
more contracts—94.7%—but at the expense of signiﬁcantly
worse precision than that of our experiments.
b) Other Research Decompilers: In addition to the pure
decompilers we compare against, several other recent research
tools perform some form of decompilation before further
analysis. We do not attempt a full comparison with such
tools, but performed a more limited experiment of their end-
to-end scalability and generality, in the same setup as for
RQ1. We consider EthIR [1], Mythril [22], and Rattle [34].
(Of these, EthIR is the closest to a pure decompiler.) EthIR
can handle 73% of the 91K unique contract programs, for an
average time of 11.9s per contract. Most of the failing contracts
produce an error-state exit. Our own inspection of the rule-
based representation output conﬁrms that EthIR only performs
simple local reasoning within each basic block. Mythril can
handle 40% of 91K unique contracts with an average time
of 19.1s per contract; exiting with an error state for 19% of
contracts. On the other hand Rattle can handle 69.7% of the
91K unique contracts with the same 120s timeout. It produced
non-timeout error-state exits on 24% of the contracts.
In recent months, the Eveem system [15] has emerged as
a decompiler for the Ethereum blockchain. Eveem offers a
convenient query language and high responsiveness, for a
positive user interaction experience. Eveem is based on a sym-
bolic execution engine, much like other smart contract tools—
e.g., EthIR. Compared to static analysis, a symbolic execution
approach lags in completeness: it may miss signiﬁcant parts of
the code, due to not ﬁnding symbolic inputs that can exercise
them. (At the same time, symbolic execution may yield higher
precision for the code it does decompile.) A recent anecdote
illustrates this lag. In Feb. 2019 electronic discussions (Secu-
rity Community Telegram group, Feb.10), the question “how
many deployed contracts call the 3 blockchain-precompiled
functions” was posed. Eveem produced an answer of 8,000
whereas Gigahorse returned over 40,000 contracts, showcasing
its much higher code coverage.
VII. R ELA TED WORK
Analysis and veriﬁcation for smart contracts has received
substantial attention recently due to the security issues inherent
in the high-risk paradigm of smart contract development.
a) Decompilers for smart contracts: V andal [9], [35] is
an open-source framework written in Python, and consists of
a decompiler, a blockchain scraper, and a set of extensible
vulnerability analyses written in Soufﬂ ´e [13] Datalog. We
have compared Gigahorse to V andal extensively in previ-
ous sections. Porosity [33] is a high-level decompiler from
EVM bytecode to Solidity-like source (similar to our pretty-
printer output) implemented in C++. The EthIR [1] frame-
work for high-level analysis of Ethereum bytecode based on
the trace-based Oyente tool [18]. Its decompilation output
introduces variables that are local to each basic block whichmakes the analysis trivial. Note that the EthIR framework
reconstructs some high-level control and data-ﬂow fragments
from Oyente traces. Fragments of the control-ﬂow graph that
are not covered by Oyente’s traces remain undiscovered by
EthIR. Mythril is a security analysis tool for Ethereum smart
contracts [22]. Mythril performs decompilation aided by a
symbolic execution engine (Laser-EVM). It produces traces
that are used to generate an intermediate representation and
it therefore suffers similar incompleteness issues as EthIR.
Similarly, Rattle [34] also constructs an IR in SSA form [6]
and performs program analysis on it.
b) Analysis frameworks for smart contracts: Previous
work on smart contract security analysis can be classiﬁed
according to its underlying techniques, including symbolic ex-
ecution, formal veriﬁcation, and abstract interpretation. Some
of the work does not necessarily need decompilation. Systems
including Oyente [18], MAIAN [25], GASPER [5] and Gross-
man et al.’s recent work [10] use a symbolic execution/trace
semantics approach. Thus, they analyze a single execution
trace only. The formal veriﬁcation tool by Bhargavan et al. [3]
detects vulnerabilities that include not checking the return
value of external address calls, and reentrancy using F*. Sim-
ilarly, the FSolidM framework [20] checks for reentrancy and
transaction ordering vulnerabilities. It can also detect coding
patterns such as time-constraint and authorization issues as
outlined in previous work [2]. The MAIAN framework [25]
ﬁnds contract vulnerabilities including locking of funds in-
deﬁnitely, leaking funds to arbitrary users, and killable smart
contracts. The ZEUS system [14] conducts policy checking for
a set of policies, including reentrancy, unchecked send, failed
send, integer overﬂow, transaction state dependence/order, and
block state dependence.
c) Decompilation for Java bytecode: There is a cornu-
copia of Java decompilers [8], [12], [21], [26], [32]. The
Krakatoa decompiler [26] uses a pipeline of transformations to
recover Java programs from Java bytecode. Gigahorse employs
similar techniques to convert stack-based operations to three-
address code via symbolic execution. In [8], Prolog is used to
specify a Java bytecode decompiler. An evaluation paper [12]
compared the performance of various Java decompilers.
VIII. C ONCLUSION
We presented Gigahorse, a toolchain for decompiling and
analyzing Ethereum smart contract binaries. Gigahorse lever-
ages declarative program analysis to produce a highly-effective
decompiler. The decompilation technology is unique due to the
feedback loops between different abstraction levels. We have
also shown that Datalog is very well suited for describing such
mechanisms succinctly and without sacriﬁcing performance.
Furthermore, the Gigahorse toolchain is built as a full-ﬂedged
framework containing highly-parametric program analysis li-
braries and security client analyses.
ACKNOWLEDGMENTS
This research was supported partially by the Australian Gov-
ernment through the Australian Research Council’s Discovery
Projects funding scheme (project ARC DP180104030).
1185
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] Elvira Albert, Pablo Gordillo, Benjamin Livshits, Albert Rubio, and Ilya
Sergey. Ethir: A framework for high-level analysis of ethereum bytecode.
InAutomated Technology for V eriﬁcation and Analysis (ATVA) . Springer,
2018.
[2] Massimo Bartoletti, Salvatore Carta, Tiziana Cimoli, and Roberto Saia.
Dissecting ponzi schemes on ethereum: identiﬁcation, analysis, and
impact, 2017.
[3] Karthikeyan Bhargavan, Antoine Delignat-Lavaud, C ´edric Fournet,
Anitha Gollamudi, Georges Gonthier, Nadim Kobeissi, Natalia Kulatova,
Aseem Rastogi, Thomas Sibut-Pinote, Nikhil Swamy, and Santiago
Zanella-B ´eguelin. Formal veriﬁcation of smart contracts: Short paper.
InProceedings of the 2016 ACM Workshop on Programming Languages
and Analysis for Security , PLAS ’16, pages 91–96, New Y ork, NY , USA,
2016. ACM.
[4] Martin Bravenboer and Yannis Smaragdakis. Strictly declarative speci-
ﬁcation of sophisticated points-to analyses. In submission to OOPSLA
’09: 24th annual ACM SIGPLAN conference on Object Oriented Pro-
gramming, Systems, Languages, and Applications , New Y ork, NY , USA,
2009. ACM.
[5] T. Chen, X. Li, X. Luo, and X. Zhang. Under-optimized smart contracts
devour your money. In 2017 IEEE 24th International Conference on
Software Analysis, Evolution and Reengineering (SANER) , pages 442–
446, Feb 2017.
[6] Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and
F. Kenneth Zadeck. Efﬁciently computing static single assignment form
and the control dependence graph. ACM Trans. Program. Lang. Syst. ,
13(4):451–490, October 1991.
[7] Michael Eichberg, Sven Kloppenburg, Karl Klose, and Mira Mezini.
Deﬁning and continuous checking of structural program dependencies.
InICSE ’08: Proceedings of the 30th International Conference on
Software Engineering , pages 391–400, New Y ork, NY , USA, 2008.
ACM.
[8] Miguel G ´omez-Zamalloa, Elvira Albert, and Germ ´an Puebla. Decom-
pilation of java bytecode to prolog by partial evaluation. Inf. Softw.
Technol. , 51(10):1409–1427, October 2009.
[9] Neville Grech, Michael Kong, Anton Jurisevic, Lexi Brent, Bernhard
Scholz, and Yannis Smaragdakis. Madmax: Surviving out-of-gas condi-
tions in ethereum smart contracts. Proc. ACM Programming Languages ,
2(OOPSLA):to appear, November 2018.
[10] Shelly Grossman, Ittai Abraham, Guy Golan-Gueta, Yan Michalevsky,
Noam Rinetzky, Mooly Sagiv, and Y oni Zohar. Online detection of
effectively callback free objects with applications to smart contracts.
Proc. ACM Programming Languages , 2(POPL):48:1–48:28, December
2017.
[11] Elnar Hajiyev, Mathieu V erbaere, and Oege de Moor. Codequest:
Scalable source code queries with Datalog. In ECOOP’06: Proceedings
of the 20th European Conference on Object-Oriented Programming ,
pages 2–27. Spinger, 2006.
[12] James Hamilton and Sebastian Danicic. An evaluation of current
java bytecode decompilers. In Proceedings of the 2009 Ninth IEEE
International Working Conference on Source Code Analysis and Ma-
nipulation , SCAM ’09, pages 129–136, Washington, DC, USA, 2009.
IEEE Computer Society.
[13] Herbert Jordan, Bernhard Scholz, and Pavle Suboti ´c. Soufﬂ ´e: On
synthesis of program analyzers. In Swarat Chaudhuri and Azadeh
Farzan, editors, Computer Aided V eriﬁcation , pages 422–430, Cham,
2016. Springer International Publishing.
[14] Sukrit Kalra, Seep Goel, Seep Goel, and Subodh Sharma. Zeus:
Analyzing safety of smart contracts, 2018.
[15] Tomasz Kolinko. Eveem/Panoramix – Showing Contract Sources since
2018, 2018. Accessed: 2019-02-15.
[16] Monica S. Lam, John Whaley, V . Benjamin Livshits, Michael C. Martin,
Dzintars Avots, Michael Carbin, and Christopher Unkel. Context-
sensitive program analysis as database queries. In Proc. of the 24th
Symp. on Principles of Database Systems , PODS ’05, pages 1–12, New
Y ork, NY , USA, 2005. ACM.
[17] Tim Lindholm, Frank Yellin, Gilad Bracha, and Alex Buckley. The
Java Virtual Machine Speciﬁcation, Java SE 8 Edition . Addison-Wesley
Professional, 1st edition, 2014.
[18] Loi Luu, Duc-Hiep Chu, Hrishi Olickel, Prateek Saxena, and Aquinas
Hobor. Making smart contracts smarter. In Proceedings of the 2016ACM SIGSAC Conference on Computer and Communications Security ,
CCS ’16, pages 254–269, New Y ork, NY , USA, 2016. ACM.
[19] Magnus Madsen, Benjamin Livshits, and Michael Fanning. Practical
static analysis of JavaScript applications in the presence of frameworks
and libraries. In Proceedings of the ACM SIGSOFT International
Symposium on the F oundations of Software Engineering , August 2013.
[20] Anastasia Mavridou and Aron Laszka. Designing secure ethereum smart
contracts: A ﬁnite state machine based approach, 2018.
[21] Jerome Miecznikowski and Laurie J. Hendren. Decompiling java
bytecode: Problems, traps and pitfalls. In Proceedings of the 11th
International Conference on Compiler Construction , CC ’02, pages 111–
127, London, UK, UK, 2002. Springer-V erlag.
[22] Bernhard Mueller. Smashing ethereum smart contracts for fun and real
proﬁt, 2018. The 9th annual HITB Security Conference.
[23] Mayur Naik, Alex Aiken, and John Whaley. Effective static race
detection for java. In Proc. of the 2006 ACM SIGPLAN Conf. on
Programming Language Design and Implementation , PLDI ’06, pages
308–319, New Y ork, NY , USA, 2006. ACM.
[24] Mayur Naik, Chang-Seo Park, Koushik Sen, and David Gay. Effective
static deadlock detection. In Proc. of the 31st International Conf. on
Software Engineering , ICSE ’09, pages 386–396, New Y ork, NY , USA,
2009. ACM.
[25] Ivica Nikolic, Aashish Kolluri, Ilya Sergey, Prateek Saxena, and Aquinas
Hobor. Finding the greedy, prodigal, and suicidal contracts at scale.
CoRR , abs/1802.06038, 2018.
[26] Todd A. Proebsting and Scott A. Watterson. Krakatoa: Decompilation
in Java (does bytecode reveal source?). In Proceedings of the 3rd
Conference on USENIX Conference on Object-Oriented Technologies
(COOTS) - V olume 3 , COOTS’97, pages 14–14, Berkeley, CA, USA,
1997. USENIX Association.
[27] Thomas Reps. Demand interprocedural program analysis using logic
databases. In R. Ramakrishnan, editor, Applications of Logic Databases ,
pages 163–196. Kluwer Academic Publishers, 1994.
[28] Yannis Smaragdakis and George Balatsouras. Pointer analysis. F ounda-
tions and Trends in Programming Languages , 2(1):1–69, 2015.
[29] Yannis Smaragdakis, George Kastrinis, and George Balatsouras. In-
trospective analysis: Context-sensitivity, across the board. In Proc. of
the 2014 ACM SIGPLAN Conf. on Programming Language Design and
Implementation , PLDI ’14, pages 485–495, New Y ork, NY , USA, 2014.
ACM.
[30] V arious. Eip 214 - new opcode staticcall. https://github.com/ethereum/
EIPs/blob/master/EIPS/eip-214.md. Accessed: 2018-08-15.
[31] V arious. Ethereum function signature database. https://www.4byte.
directory/. Accessed: 2018-08-15.
[32] V arious. JODE – Java Optimize and Decompile Environment, 2018.
Accessed: 2018-08-24.
[33] V arious. Porosity – a decompiler for EVM bytecode into readable
Solidity-syntax contracts, 2018. Accessed: 2018-08-24.
[34] V arious. Rattle – An EVM Binary Static Analysis Framework, 2018.
Accessed: 2018-08-24.
[35] V arious. V andal – A Static Analysis Framework for Ethereum Bytecode,
2018. Accessed: 2018-07-30.
[36] John Whaley, Dzintars Avots, Michael Carbin, and Monica S. Lam.
Using Datalog with binary decision diagrams for program analysis. In
Proc. of the 3rd Asian Symposium on Programming Languages and
Systems , pages 97–118, 2005.
1186
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. 