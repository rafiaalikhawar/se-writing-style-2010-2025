αDiff:Cross-VersionBinaryCodeSimilarityDetectionwithDNN
Bingchang Liu∗
liubingchang@iie.ac.cn
Institute of Information Engineering,
Chinese Academy of SciencesWei Huo∗†
huowei@iie.ac.cn
Institute of Information Engineering,
Chinese Academy of SciencesChao Zhang†
chaoz@tsinghua.edu.cn
Institute for Network Science and
Cyberspace, Tsinghua University
Wenchao Li∗
Institute of Information Engineering,
Chinese Academy of SciencesFeng Li∗
Institute of Information Engineering,
Chinese Academy of SciencesAihua Piao
Institute of Information Engineering,
Chinese Academy of Sciences
Wei Zou∗
zouwei@iie.ac.cn
Institute of Information Engineering,
Chinese Academy of Sciences
ABSTRACT
Binary code similarity detection (BCSD) has many applications,
including patch analysis, plagiarism detection, malware detection,
and vulnerability search etc. Existing solutions usually perform
comparisons over specific syntactic features extracted from binary
code, based on expert knowledge. They have either high perfor-
mance overheads or low detection accuracy. Moreover, few solu-tions are suitable for detecting similarities between cross-version
binaries, which may not only diverge in syntactic structures but
also diverge slightly in semantics.
In this paper, we propose a solution αDiff, employing three
semantic features, to address the cross-version BCSD challenge.It first extracts the intra-function feature of each binary function
usingadeepneuralnetwork(DNN).TheDNNworksdirectlyon
raw bytes of each function, rather than features (e.g., syntactic
structures)providedbyexperts. αDifffurtheranalyzesthefunction
callgraphofeachbinary,whicharerelativelystableincross-version
binaries, and extracts the inter-function and inter-module features.
Then, a distance is computed based on these three features and
used for BCSD. We have implemented a prototype of αDiff, and
evaluated it on a dataset with about 2.5 million samples. The result
shows that αDiff outperforms state-of-the-art static solutions by
over 10 percentages on average in different BCSD settings.
CCS CONCEPTS
•Securityandprivacy →Softwarereverseengineering ;•Com-
puting methodologies →Machine learning ;
∗Also with: School of Cyber Security, University of Chinese Academy of Sciences.
†corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3238199KEYWORDS
Code Similarity Detection, DNN
ACM Reference Format:
Bingchang Liu, Wei Huo, Chao Zhang, Wenchao Li, Feng Li, Aihua Piao,
and Wei Zou. 2018. αDiff: Cross-Version Binary Code Similarity Detec-
tion with DNN . In Proceedings of the 2018 33rd ACM/IEEE International
Conference on Automated Software Engineering (ASE ’18), September 3–7, 2018, Montpellier, France. ACM, New York, NY, USA, 12pages.https:
//doi.org/10.1145/3238147.3238199
1 INTRODUCTION
Given two binary functions, the problem of evaluating whether
theyaresimilariscalledbinarycodesimilaritydetection(BCSD).
It plays an important role in many applications, including code
plagiarismdetection[ 32,33,43]andmalwarefamilyandlineage
analysis [ 2,26,28]. It could also be used to analyze 1-day (i.e.,
patched) vulnerabilities [ 5], or summarize vulnerability patterns
[53], when applying BCSD on pre-patch and post-patch binaries.
Moreover,itcouldevenbeusedincross-architecturebugsearch-
ing[16,17,52],whenapplyingBCSDonaknownbugandtarget
applications.
However,BCSDfacesseveralchallenges.First,differentcompiler
optimizations yield cross-optimization binaries. Second, compilers
withdifferentalgorithms(e.g.,registerallocation)generate cross-
compilerbinaries.Third,thesourcecodecompiledondifferentplat-
forms (e.g., with different instruction sets) yields cross-architecture
binaries.Thesebinariesaresemantic-equivalent,buthavedifferent
syntactic structures. On the other hand, the source code itself may
evolveovertime(e.g.,beingpatched),yielding cross-version binaries.
Thesebinariesbynaturearesimilar,becausetheyhaveasameroot.
Buttheyhavedifferentsyntacticstructuresandslightlydifferent
semantics. Existing solutions could address these BCSD challenges
to some extent, but perform poorly in cross-version binaries.
State-of-the-artBCSD solutionsheavilyrely onaspecificsyn-
tactic feature of binary code, i.e., control flow graphs (CFGs) offunctions. The most widely used tool BinDiff [
55] utilizes graph-
isomorphism(GI)theory[ 14,18]tocomparefunctions’CFGs.How-
ever, GI algorithms are time consuming and lack polynomial time
667
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, W. Zou
solutions. Moreover, GI is vulnerable to (even minor) CFG changes,
andthushasalowaccuracy.BinHunt[ 19]andiBinHunt[ 34]e x-
tendGIwithsymbolicexecutionandtaintanalysistoaddressthese
challenges, but still have low accuracy and high overheads.
BinGo [6], Esh [12] and CABS [ 38] provide more resilience to
CFG changes, by computing the similarities of CFG fragments and
composingtheoverallCFGsimilarity.DiscovRE[ 16]providesbetter
performance, by employing a filter on CFGs to reduce the number
ofGIcomparisons.ItextractssomenumericfeaturesfromCFGs,
e.g.,countsofinstructionsorbasic blocks(BBs),andusethekNN
algorithm to pre-filter similar CFGs. Genius [ 17] extracts similar
numeric attributes from BBs, and use them to augment CFG nodes
and get Attributed CFGs (ACFGs), to support cross-architecture
BCSD.Gemini[ 52]usesanend-to-endneuralnetworktoembed
ACFGs, providing better performance and accuracy.
Thesesolutionsallrelyonthesyntacticfeature,i.e.,CFGs.These
featuresarederivedfromexpertknowledge,whichcouldintroducebiassometimes.Forexample,CFGscouldchangedramaticallyeven
if there is none or minor code changes, and cause noticeable devia-
tions in the BCSD results. The first research question addressed in
this paper is: RQ1: How to extract features from binary code with as
little human bias as possible?
Few solutions consider the semantics of the binary code, except
BinGo[6]andEsh[ 12].Thesetwousetheoremprovingtocheck
semanticequivalence ofCFGfragments,andthusarecomputation-
allyexpensive.Ontheotherhand,thesemanticsofcross-version
binariesmaychangeslightly,e.g.,duetopatching.So,strictseman-
ticequivalencecomparisonsarenotsuitableneither.Thesecond
research question addressed in this paper is: RQ2: How to efficiently
utilize semantic features to improve the accuracy of BCSD?
Cross-version BCSD is demanded for two decades, e.g., in patch
analysis [ 5] and knowledge transfer [ 50]. It is also one of the most
attractive functionalities provided by the popular tool BinDiff [ 55].
However,thisproblemisfarfrombeingsolved.Forexample,the
average accuracy of BinDiff is less than 0.5 when comparing core-
utils 5.0 with coreutils 8.29 that consist of hundreds of binaries.
But researchers have paid few attentions to this specific topic. The
thirdresearchquestionaddressedinthispaperis: RQ3:Howtobuild
a solution fit for cross-version BCSD?
Inthispaper,weproposeasolution αDifftoaddresstheafore-
mentioned questions. In short, it extracts proper semantic features
frombinaries,andusesthemtocomputesimilarityscorestoper-
form BCSD. To fit for cross-version BCSD, each binary function is
characterizedasthreesemanticfeatures,i.e.,thefunctioncode’s(i.e.,
intra-function) features, function invocation (i.e., inter-function)
features, and module interactions (i.e., inter-module) features.
First,tocharacterizeafunction’sintra-functionfeature,wedo
not use its CFG or other attributes derived from expert knowledge.
We notice that, the raw bytes contain all semantic information
ofthefunction,andneuralnetworks couldautomaticallyretrieve
unbiasedfeaturesfromthem.Thus,weproposeaneuralnetworktoextractfeaturesfromthefunction’srawbytes,inspiredbyprevious
works[
45].Morespecifically,werepresenttherawbytesasamatrix,
and use convolutional neural network (CNN) to convert it intoan embedding (i.e. a vector). Further, in order to ensure similar
functions’ embeddings are close to each other, we embed this CNNintoaSiamesenetwork,i.e.,apopularsolutionusedinfine-grained
visual similarity recognition [3, 4,44,47].
Second,wenoticethatsimilarfunctionshavesimilarcallgraphs
but not the opposite. So we analyze each function’s call graph
to extract its inter-function feature. Ideally, the whole call graph
shouldbeconsidered.Butinoursolution,weextractonlythein-
degreeandout-degreeofafunctionnodeinthecallgraphasthe
function’s feature, for performance reason.
Third,wealsonoticethatsimilarfunctionshavesimilarimported
functions (even in different architectures), but not the opposite. So
weanalyzeeachfunction’simportedfunctionsetanduseitasinter-
module feature. A specific algorithm (Section 3.4)i sp r o p o s e dt o
embed this set into a vector, to support distance computation.
So, given any two binary functions, we could extract their intra-
function, inter-function and inter-module features. Then, we could
compute their distances in terms of each feature respectively. Fi-
nally,wewillmergethesethreedistancestomeasuretheoverall
similarity of these two functions.
We have implemented a prototype of our solution αDiff, and
evaluated it on a custom dataset consisting of about 2.5 millions
pairs of cross-version functions, which are collected from public
repositories.Theresultsshowedthat, αDiffoutperformsBinDiffby
11percentageonaverage,upto52%forsomebinarypairs.With
only the intra-function feature, αDiff outperforms BinDiff by 6
percentage on average, up to 43% for some binary pairs.
More importantly, although our training data is composed of
cross-versionbinaries,ourmodelisalsogoodforcross-compiler
andcross-architecturebinarycodesimilaritydetection,aswellasin
a specific application, i.e., vulnerability search. The results showed
thatαDiff in general outperforms state-of-the-art solutions.
Overall, we made the following contributions:
(1)We proposed a neural network solution to extract intra-function semantic features from raw bytes of binary func-
tions,withoutinterferenceofexpertknowledge.Together
withtwootherproposedsemanticfeatures,i.e.,inter-function
and inter-module features, we built an end-to-end system
αDiff able to perform cross-version BCSD.
(2)We built a labelled dataset for deep learning, which con-
tains66,823pairsofbinariesandabout2.5millionpairsof
functions.Researcherscanfreelyusethisdataset1,todesign
other neural network models and solve other problems.
(3)We developed a prototype αDiff and evaluated it on this
dataset. The results showed that it outperforms state-of-the-
art solutions, in all of cross-compiler, cross-architecture and
cross-version BCSD settings.
2 PROBLEM DEFINITION
In this section, we will introduce the definition of the cross-
version BCSD (binary code similarity detection) problem.
2.1 Notation and Assumption
Weassumeallbinariesarecompiledfromsourcecodewrittenin
high-levellanguages,notassembledfromhand-writtenassembly
or generated by packers, which aim at obfuscating the binaries.
1https://twelveand0.github.io/AlphaDiff-ASE2018-Appendix
668
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. αDiff: Cross-Version Binary Code Similarity Detection with DNN ASE ’18, September 3–7, 2018, Montpellier, France
Tobepractical,wealsoassumethedebugsymbolsinbinariesare
stripped, which makes binary analysis more challenging.
A binary Biconsists of a set of functions fi1,fi2,...,fin. Binary
function identification, which is out of the scope of this paper,
couldbehandledwellbyexistingbinarydisassemblysolutions.We
herebyassumeeachbinary’sfunctionscouldbeidentifiedcorrectly,
i.e., all bytes of each function fijin a binary Bican be determined.
AcoretaskofBCSDistofindeachfunction’smatchingcounter-
part. Two binary functions are considered as matching, if they are
compiledfromfunctionswiththesamename(includingnamespace
and class etc.) and used in similar contexts. It is worth noting that,
identical functions (i.e., with same raw bytes) are matching, but
matching functions could be non-identical.
2.2 Cross-version BCSD Problem
Thecross-versionBCSDproblem focusesonanalyzingtwobina-
riesB1andB2compiled from a same source code project, which
could evolve over time. It is related to the following tasks:
(1)function matching: for each function f1iin a binary B1,i f
exist, find its match f2jin the other binary B2.
(2)similarityscore:foreachpairoffunctions f1iandf2j,com-
puteasemanticsimilarityscorerangingfrom0to1between
them, indicating how likely they are similar to each other.
(3)difference identification: for each matching pair of functions
f1iandf2j,identifytheexactdifferencesintheircodebytes,
if their similarity score is less than 1 (i.e., non-identical).
In this paper, we only focus on the first 2 tasks.
2.3 Variant BCSD Problems
Inthispaper,weaimtosolvethechallengesinthecross-version
BCSD problem, which is more challenging than other BCSD prob-
lems. As the evaluation results showed, our solution could be used
directlyforthefollowingvariantsettingsandreceivedgoodresults.
(1)Cross-optimizationBCSD:Itaimsatanalyzingtwobinaries
compiledfromasamecopyofcode,usingasamecompiler
but with different compilation optimizations.
(2)Cross-compiler BCSD: It aims at analyzing two binaries com-
piled from a same copy of code, using different compilers
(e.g., different vendors.).
(3)Cross-architecture BCSD: It aims at analyzing two binariescompiled from a same copy of code, targeting different ar-
chitectures (e.g., with different instruction sets).
2.4 Evaluation Metric
The goal of BCSD solutions is identifying matching functions
accurately.Wethusevaluatewhetherthematchingfunctionisin
the topKmatching candidates reported by a given BCSD, namely
Recall@K, similar to related works [29, 47],
Giventwobinaries B1=f11,f12,...,f1nandB2=f21,f22,...,f2m,
for simplicity, we assume they have Tpairs of matching functions,
i.e., (f11,f21), (f12,f22), ..., and ( f1T,f2T) respectively. The rest of
functions do not match.
For any function f1iinB1, the BCSD solution could sort func-
tions in the other binary B2, based on their similarities with f1i.
We denote the top K similar functions as topK(f1i), and denotehit@K(f1i)as whether f1i’s matching function exists in topK(f1i).
hit@K(f1i)=/braceleftBigg
1,f2i∈topK(f1i)andi≤T
0,otherwise(1)
The evaluation metric of BCSD is thus defined as follows.
Recall@K(B1,B2)=T/summationtext.1
i=1hit@K(f1i)
T(2)
3 APPROACH
In this section, we present the key idea of our solution to the
problem of cross-version binary code similarity detection.
3.1 Overview
Traditionalsolutionsbasedonsyntacticattributesareinadequate
for cross-version BCSD. The similarity of two cross-version binary
functions should be estimated by their semantics, i.e., their raw
bytes, their relationships with other functions defined in the same
binaries,andtheirrelationshipstoimportedfunctionsdefinedin
externalmodules.Forsimplicity,wenamethesefeaturesasintra-
function, inter-function and inter-module features respectively.
As shown in Figure 1, our solution αDiff first extracts these
featuresfromtwobinaryfunctions,thencalculatesthedistances
between each pair of features, and finally evaluates an overall simi-larityscorebasedonthesethreedistances.Thefinalscoreindicates
the similarity between the two functions.
Unlike traditional solutionswhich use CFG and othersyntactic
attributesasfeatures,weapplyadeepneuralnetworktodirectly
extract intra-function features from each function’s raw bytes. An
embedding is generated by this neural network, to represent the
binary function’s semantic feature.
Furthermore, we use the call graph (CG) to characterize the
inter-function semantic feature, and use the imported function
invocation relationship to characterize the inter-module semantic
feature.Thesetwofeaturescouldbeextractedfrombinarieswith
traditional lightweight program analysis.
3.2 Intra-function Semantic Feature
Inspired by previous binary analysis solutions [ 45], we also uti-
lize a neural network to extract intra-function semantic featuresfrom the raw bytes of binary functions. After many trials (e.g.,
Conv1D, LSTM and convolutional LSTM), we find out the convolu-
tional neural network (CNN) is the best fit.
In our solution, the CNN takes the raw bytes of a function Iq
as input, and maps it to an embedding f(Iq), i.e., a vector in a
d-dimensional Euclidean space Rd. Then we could calculate the
distance between any two functions using their embeddings.
Inordertodetectsimilarity,wehavetotrainthemodeltosatisfy
thefollowingrequirement. RQ:Thedistancebetween(embeddings
of) two similar functions should be small, while the distance between
(embeddings of) two dissimilar functions should be large.
Inspired by deep metric learning [ 3,44,47], we also embed two
identical CNNs into a Siamese architecture [ 4], to comply with
the requirement RQ and train the CNN’s parameters. Unlike the
recent work Gemini [ 52], which generates embeddings with DNN
669
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, W. Zou
Pre-processCNN tuned 
with Siameseraw bytes 
of input funcin/out degree 
in call graph
of input funcimported functions of 
input func and binaryfunc /
(bin1 ∩ bin2Euclid 
DistanceEuclid 
Distance
Binary 1
func1Binary 2
func2intra-func
distanceinter-func
distanceinter-mod
distanceintra-func
feature 1
intra-func
feature 2inter-func
feature 1
inter-func
feature 2inter-mod
feature 1
inter-mod
feature 2
Function Similarity Score
Figure 1: Overview of the cross-version binary code similarity detection solution αDiff.
based onsome engineered syntacticfeatures, our solutiondoes not
require expert knowledge and is suitable for cross-version BCSD.
3.2.1 EmbeddingFunctionswithCNN. Theconvolutionalneural
network (CNN) is a specific kind of neural network for processing
data that hasa known, grid-like topology[ 20,31]. It hasachieved
great success in many applications, e.g., AlexNet [30].
However, classical CNNs are specifically designed for image
classification, requiring inputs similar to RGB images, which have
atleast3channels.Thisisnotsuitableforourproblemscopeandour
input format. After many trials, we design a new CNN as follows.
Networkstructure. TheCNNthatweproposeconsistsof8convo-
lutional layers, 8 batch normalization layers, 4 max pooling layers
and2full-connectedlayers.Thewholemodelusesrectifiedlinear
units, i.e. ReLU [ 10], as the non-linear activation function. In total,
there are more than 1.6 million parameters in this network2.
Network I/O. This CNN takes a 100 ×100×1 tensor Tas input,
andoutputsa64-dimensionalvector(i.e.,embedding).Wefillthe
raw bytes of a function into Tbyte by byte. If the function has less
than 10,000 bytes, we will fill the tensor Twith zero byte paddings.
Otherwise, we will discard the redundant bytes of this function.
Itisworthnotingthat,fewfunctions(e.g.,lessthan0.01%inour
dataset)havemorethan10,000bytes.Moreover,iftwofunctions’
first 10,000 bytes are similar, they are likely similar too. So, it is
reasonable to simply discard redundant bytes of the function.
Data augmentation. In image classification applications, data
augmentationisapopularmeasuretoimprovedatasetsforCNN
training.Unlikeimagespixelsthataretoleranttominormodifica-
tions,functionbytesarevulnerabletochanges,sincetheywillalter
the function semantics. So during the training of our model, we do
not apply any data augmentation measures.
Overfitting issue. We also investigated the measures used in
AlexNet etc., i.e., layer stacking style and solutions, to avoid model
overfitting.Inparticular,weadopt batchnormalization [27]toad-
dress the overfitting issue.
3.2.2 LearningParametersUsingSiameseNetwork. Inordertotrain
theparametersofthisCNNembeddingnetwork,weusetheSiamese
architecture [ 4]. As shown in Figure 2, the Siamese architecture
uses two identical CNN embedding networks. Each CNN takes one
function as input, namely IqandIt, and outputs the corresponding
2Detailscouldbefoundat: https://twelveand0.github.io/AlphaDiff-ASE2018-AppendixLossCNN
CNNIq
θ
It
yf(Iq;θ)
f(It,;θ)L
Figure 2: Siamese network illustration.
embeddings, namely f(Iq;θ)andf(It;θ)respectively, where f
represents the network structure and θrepresents the network
parameters.
In addition to the input pair (Iq,It), the Siamese architecture
also accepts an indicator input y. This input yindicates whether
the two functions IqandItare similar or not. If they are similar,
y=1, otherwise y=0.
Thegoalofthetrainingistofindthebestparameter θ,tosatisfy
the aforementioned requirement RQ, i.e., the distance betweenfunctions
IqandItis small if they are similar otherwise large.
Formally,thedistanceoftwofunctions’intra-functionfeaturesis
defined as follows.
D1(Iq,It)=/bardblex/bardblexf(Iq;θ)−f(It;θ)/bardblex/bardblex (3)
To achieve this goal, we evaluate a contrastive loss function [22]
of this Siamese network as follows.
L(θ)=Averaдe
(Iq,It){y·D1(Iq,It)+
(1−y)·max(0 ,m−D1(Iq,It))}(4)
wheremisapre-definedhyper-parameter,i.e.,theminimalmargin
distance that dissimilar functions are expected to have.
We can infer that, if this loss function gets a minimal value,
D1(Iq,It)is close to 0 when y=1, andmax(0,m−D1(Iq,It))is
closeto0when y=0.Inotherwords,eachfunctionwillbecloseto
similar onesand farfrom dissimilar ones,in the embeddingspace.
So, the aforementioned requirement RQ is satisfied.
Theobjectiveofthetrainingthusbecomestofindtheparameter
θto minimize the Siamese network’s loss function, i.e.
arдmin
θL(θ) (5)
This objective function can be solved using Stochastic Gradient
Descent (SGD) with standard back propagation algorithms [ 31,41].
670
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. αDiff: Cross-Version Binary Code Similarity Detection with DNN ASE ’18, September 3–7, 2018, Montpellier, France
3.2.3 Negative Training Samples. It is crucial to build a set of posi-
tivesamples(i.e.,pairsofsimilarfunctions)andnegativesamples
(i.e., pairs of dissimilar functions), in order to get desirable conver-
gence in the aforementioned CNN and Siamese network.
We havecollected about2.5 million positivesamples frompub-
lic repositories. We thus need a way to either collect or generate
sufficientnegativesamplesfortraining.Similarto[ 37,44,47],we
also generate negative samples in each mini-batch during training,
based on the positive samples.
Morespecifically,foreachpositivesample (Iq,Ip)inamini-batch,
we will generate two semi-hard [44] negative samples, namely
(Iq,In1)and(Ip,In2).Takethefunction Iqasanexample,wewill
look for function Inthat satisfies the following equation3.
0<D1(Iq,In)<m (6)
Werandomlyselectonefunction In1thatsatisfiesthisconstraint
as the negative function. But we will skip the hardest negative
function(i.e. arдminD1(Iq,In)),becausesuchsamplescaneasily
lead the model to bad local minima during training.
In order to get sufficient different negative samples, we will
shuffle the mini-batch of positive samples in each epoch during
training.Morespecifically,ineachepoch,wefirstrandomlysort
the binary file pairs, then randomly sort the positive function pairs
betweeneachbinaryfilepair.Therandomlysortedpositivesamples
(function pairs) will then be divided into mini-batches, and new
negative samples could be generated from these new mini-batches.
3.3 Inter-function Semantic Feature
Functions do not work solely, i.e., they will call other functions
or be called by others. The interactive relationship with other func-
tions in the same binary (including themselves) is an important
semanticfeature,i.e.inter-functionfeature.Thisfeaturecanberep-
resentedasthefunctioncallgraph.Wenoticethatsimilarfunctions
have similar call graphs.
Ideally, the whole call graph should be considered. For example,
SMIT[26]usesthecallgraphmatchingtodetectsimilaritybetween
malwaresamples.AlthoughtheyproposeanefficientGraphEdit
Distance algorithm, the computation cost is still too high to deploy.
In our solution, we extract only the in-degree and out-degree of
a node (i.e., function) in the call graph as its inter-function feature.
More specifically, for each function Iq, we embed its inter-function
feature as a 2-dimensional vector as follows.
д(Iq)=(in(Iq),out(Iq)) (7)
wherein(Iq)andout(Iq)are the in-degree and out-degree of the
functionIqin the call graph respectively. Formally, the (Euclidean)
distance of two functions’ inter-function features is defined as:
D2(Iq,It)=/bardblex/bardblexд(Iq)−д(It)/bardblex/bardblex (8)
3.4 Inter-module Semantic Feature
A function Iqalso invokes a set of imported functions,denoted
asimp(Iq), which are defined in external modules (libraries). We
notice that similar functions invoke similar imported functions
butnottheopposite.Moreover,theset imp(Iq)isrelativelystable
evenifIqchangesacrossversions,duetothemodulardevelopment
3This is different from FaceNet [44] and VGGFace [37].process. As a result, the imported function set is also an important
semantic feature, i.e. inter-module feature.
For consistency, we also convert the inter-module feature, i.e.,
theimportedfunctionset,intoavectorfordistancecomputation.
Therefore, we use the following element-testing formula to embed
a set into the superset’s space.
h(set,superset)=<x1,x2,...,xN> (9)
whereNisthesizeofthesuperset,and xi=1ifthei-thelement
ofsupersetis inset; otherwise 0.
For two functions IqandIt, assuming their binaries are Bqand
Bt, we will get their imported function set imp(Bq)andimp(Bt)
too.Thenwetake imp(Bq)∩imp(Bt)asthesuperset,andusethe
aforementioned formula to encode each inter-module feature, then
compute their distance as follows.
D3(Iq,It)=/bardblh(imp(Iq),imp(Bq)∩imp(Bt))−
h(imp(It),imp(Bq)∩imp(Bt))/bardbl(10)
It is worth noting that, imp(Bq)is a superset of imp(Iq), and
imp(Bt)is a superset of imp(It). Moreover, although symbols (e.g.,
functionnames)maybestrippedfrombinaries,thenamesofim-
portedfunctionswillalwaysbekeptsothatthelinkercouldlink
modulestogether.Asaresult,itiseasytoextractthesetofimported
functions for a binary or a function.
3.5 Overall Similarity Computation
Given any two functions IqandIt, we could thus compute their
intra-functiondistance( D1),inter-functiondistance( D2)andinter-
moduledistance( D3),followingEquation 3,Equation 8andEqua-
tion10respectively.
As aforementioned, the imported function set of a function is
usually stable, so the inter-module distance D3 between similar
functions in general is small. Moreover, the intra-function distance
D1 between similar functions is also small, usually smaller than
theminimalmarginofdissimilarfunctions,i.e.,theparameter min
Equation 4.But,similarfunctionsincross-versionbinariescould
have different call graphs, especially different in-degree and out-
degree, resulting a relatively large inter-function distance D2.
So,weeventuallycomputeanoveralldistancetorepresentthe
overall similarity of these two functions as follows.
D(Iq,It)=D1(Iq,It)+(1−ξD2(Iq,It))+D3(Iq,It)(11)
whereξis a pre-defined hyper-parameter in the range (0,1), used
for suppressing the effect of D2.
For any function Iqin question, we will compute the overall dis-
tanceDwitheachtargetfunction,andthensortalltargetfunctions
bythedistance.Theclosesttargetfunctions(i.e., topKdefinedin
Section2.4) are more likely similar to Iq.
4 EVALUATION
4.1 Implementation
Wehaveimplementedaprototypeof αDiff.Itconsistsofthree
majorcomponents: preprocessor,featuregenerator ,andneuralnet-
workmodel.Thepreprocessorisimplementedasaplug-inofthe
binaryanalysistool IDA Pro6.8[ 24].Fromeachfunction inabi-
nary, three types of information are extracted, i.e. its raw bytes, its
671
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, W. Zou
Table 1: Sources of the dataset
data-src projects/ versioned cross-version cross-version
packages proj/pkg binary pairs function pairs
GitHub repo 31 9,419 8,510 166,541
Debian repo 895 1,842 58,313 2,323,252
TOTAL 926 11,261 66,823 2,489,793
for training - - 44,526 1,665,025
for validation - - 11,150 417,158
for testing - - 11,147 407,610
in/out-degreeinthecallgraphanditsimportedfunctionset.These
rawinformationarethenencodedintoembeddings,asdiscussedinSection3.Specifically,therawbytesareconvertedintoembeddings,
usingaspecialneuralnetwork.Thisnetworkmodelisimplemented
in TensorFlow-1.3 [1] and Keras-2.0 [8].
4.2 Evaluation Setup
Ourexperimentsareconductedonaserverequippedwithtwo
Intel Xeon E5-2650v4 CPUs (24 cores in total) running at 2.20 GHz,
128 GB memory, 12TB hard drives, and 4 NVIDIA Tesla P100 PCIE-
16GGPUcards.Duringbothtrainingandevaluation,only1GPU
card was used.
4.2.1 Dataset. A dataset is needed to train neural network model
andevaluateitseffectiveness.Wecollectedasetof2,489,793positivesamples(i.e.,pairsofmatchingfunctions)from66,823pairsof cross-
versionbinaries in x86 Linux platform. As shown in Table 1, the
dataset has two sources.
The first source is the GitHub repository, where we collected
sourcecodefrom31projectswith9,419releases.Eachreleaseisthen
compiled with the compiler GCC-5.4 with the default optimization
options.Weplacedeachproject’stwosuccessivereleasesofbinaries
into one pair, and got 8,510 pairs in total.
ThesecondsourceisDebianpackagerepository,wherewedi-
rectly collected binaries from .debpackages. We have collected
895packageswith1,842versions,fromtheUbuntu12.04,14.04and
16.04 platform. Each package may contain more than one binaries.
Wegroupedeachversionofbinarywithitsclosestversionasapair,
and got 58,313 pairs in total.
Foreachpairofcross-versionbinaries,wethenretrievedpairsof
matching functions, which have a same name but are not identical.
To increase the diversity, we also extracted some pairs of functions
that are identicalin cross-version binaries. Finally, intotal wehave
2,489,793 pairs of cross-version matching functions, from 66,823
pairsofcross-versionbinaries.Amongthem,about1.52percents
of pairs of cross-version functions are identical. It is worth noting
that, BinDiff reports that 29.4 percent of pairs are identical, due to
the inaccuracy introduced in its GI-based algorithm.
GroundTruth. Asaforementioned,togetthegroundtruthof
matching functions, we utilized function names and thus relied on
debug symbols optionally shipped with binaries. For binaries that
arecompiledfromGitHubcode,thecompilationoption -gisadded
when building. For binaries from Debina package repository, we
onlycollectedpackageswithsymbolicfiles(e.g.,.ddebpackages).
After collecting the ground truth, we stripped all debug symbolsfrom binaries, and evaluate our tool αDiff and other tools on the
stripped binaries only.
4.2.2 DatasetSplit. Similartootherworks,wealsosplitthedataset
into three disjoint subsets for training, validation and testing, in
order to evaluate the generalization capability of the trained modelonunseenbinaries.Roughly,wesetthenumberofpositivesamples
(i.e., pairs of matching functions) in these three subsets proportion
to 4:1:1. Moreover, we ensure that matching pairs from one pair of
binarieswillbeplacedinonesubset.Table 1showsthesizeofeach
subset at the bottom.
4.2.3 Neural Network Training. This dataset is used to train the
neural network model for intra-function feature extraction. In the
CNNmodel,weusetheRMSPropoptimizer[ 25],setthelearning
rate to 0.001, and set the forgetting factor to 0.9. In the Siamesenetwork (Eq.4), we set the margin
m, i.e., the minimal distance
betweendissimilarfunctions,to1.0.Furthermore,wesetthe ξin
theoverallsimilarityscoreformula(e.g.,Equation 11)to0.75.For
each mini-batch, 100 positive samples are selected and 200 semi-
hard negative samples are generated online. The Siamese network
is trained for 200 epochs (3.075 h/epoch), to tune the parameters in
the CNN embedding network.
4.3 Hyper-parameters in the Siamese Network
Inaddition,theDNNinvolvesseveralotherhyper-parameters
anddesigndecisions,e.g.,theshapeofinputtensor,theembedding
size, the negative sample mining method and the network archi-
tectureetc.Thechoicesoftheseparametersanddesigndecisions
could also affect the effectiveness of the model.
We have conducted a set of experiments to select proper param-
eters and design decisions. Due to the time and resource limitation,
we train each model setting with 25% samples of the training set
for 30 epochs. We evaluate each model’s performance on a subset
of the testing set, in which the number of positive samples of each
binary pair is no less than 100.
4.3.1 InputShapeandConvolutionalLayerType. Wehaveevalu-
atedtheperformanceofthenetworkindifferentinputshapeand
convolutional layer, as shown in Figure 3a. We can see that, the
model’sperformanceisaffectedbytheshapeofinputtensor.Be-sides, we also evaluate the performance of 1D-CNN and find it
doesn’t perform better than 2D-CNN with 100x100x1 input tensor.
Section5will discuss more about it.
4.3.2 Embedding Size. We have evaluated the performance of the
network in different embedding size, i.e., the dimension of theCNN’s output vector, as shown in Figure 3b. It shows that if the
embeddingsizeissetto64,themodelingeneralperformsbestand
get the highest average Recall@1 accuracy. Thus, in our model, we
set the embedding size to 64.
4.3.3 Hard Negative Sample Mining Method. We evaluate the per-
formanceofourhardnegativesamplesminingmethodandcompare
it with another two typical mining methods, i.e., FaceNet [ 44] and
VGGNet [ 37]. Further, we evaluate the performance of network
in different countof hard negative samplescorresponding to each
positive sample. In Figure 3c,FaceNet-3tuple means one semi-hard
negativesampleisminedbyFaceNetmethod[ 44]foreachpositive
672
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. αDiff: Cross-Version Binary Code Similarity Detection with DNN ASE ’18, September 3–7, 2018, Montpellier, France
0 5 10 15 20 25 30
epoch0.700.750.800.85Average Recall@1conv2d-100x100x1
conv2d-400x25x1
conv1d-10000x1
(a) Average Recall@1 in different input shape and convolutional
layer.0 5 10 15 20 25 30
epoch0.700.750.800.85Average Recall@164
128
256
512
1024
2048
(b) Average Recall@1 accuracy in different embedding sizes.
0 5 10 15 20 25 30
epoch0.600.650.700.750.800.850.90Average Recall@1®Diff-4tuple
®Diff2-4tuple
VGGNet-4tuple
FaceNet-4tuple
VGGNet-3tuple
FaceNet-3tuple
(c) Average Recall@1 in different negative sample mining methods.0 5 10 15 20 25 30
epoch0.600.650.700.750.800.85Average Recall@1Triplet_loss
Tetrad_loss
Siamese_3tuple
Siamese_4tuple
(d) Average Recall@1 in different network architecture.
Figure 3: Evaluation of hyper-parameters and design decisions.
Table 2: The recall accuracy of αDiff-1f and αDiff-3f on the
testing set of 9,308 pairs of binaries.
Whole set Big subset
αDiff-1fαDiff-3fαDiff-1fαDiff-3f
Avg. Recall@1 0.953 0.955 0.885 0.900
Avg. Recall@5 0.996 0.997 0.968 0.974
Avg. MRR 0.973 0.975 0.922 0.933
sample,while FaceNet-4tuple meanstwosemi-hardnegativesam-
ples,correspondingtotheleftandtherightofeachpositivesample
(i.e. a 2-tuple).
Besides, we have also tried a more gentle mining criterion4
as described by the line αDiff2-4tuple in Figure 3c. However, it
doesn’t performs better than ours. We can see that, our method
performs better than another two methods. And 4-tuple (tetrad)
mining method performs better than 3-tuple (triplet) mining.
4.3.4 Network Architecture. We have also evaluated the perfor-
mance of different network architectures, as shown in Figure 3d.
We evaluated the Triplet architecure of FaceNet [ 44] and Tetrad
architectureof[ 47].WealsoevaluatedSiamesearchitecturewith
triplet mining and tetrad mining method. We can see that, Siamese
architecture with tetrad mining method performs best.
4D1(Iq,Ip)<D1(Iq,In1)<m4.4 Accuracy in Cross-version BCSD
In this section, we evaluated the accuracy of αDiff, with only
theintra-functionfeatureenabled(denotedas αDiff-1f)andwith
allthree featuresenabled (denotedas αDiff-3for αDiff),using the
metricRecall@K . The task is essentially a ranking task and every
query has only one correct answer (matched function). So we thus
also evaluated the MRR (Mean Reciprocal Rank) [39].
4.4.1 Evaluation on Testing Set. We first evaluated αDiff-1f and
αDiff-3f on the testing dataset consisting of 9,308 pairs of cross-
version binaries, and calculated the metrics of Recall@1 and Re-
call@5 for each pair of binaries. In order to evaluate αDiff’s perfor-
manceonbigbinarypair(morefunctionpairs),wesplitthetesting
set into big subset and small subset. The big subset is consistedof 647 binary pairs and each binary pair contains more than 300
function pairs. Table 2shows the average recall and MRR results.
4.4.2 Evaluation on coreutils. We further evaluated the accuracy
ofαDiffonunseenbinaries,e.g., coreutils thatiscommonlyused
targetinotherBCSDsolutions[ 6,15,49].Wecollected7versions
ofcoreutils , including the latest version (i.e., v8.29 at the time of
writing), and got 604 pairs of cross-version binaries.
Table4shows the results of accuracy, when matching the old
version of coreutils to its latest version, compared with state-of-
the-art cross-version BCSD tool BinDiff.
First,BinDiffbecomeslessaccuratewhentheversiongapgets
larger. For example, the accuracy of matching v5.0 to v8.29 is only
0.486,lessthanhalfoftheaccuracyofmatchingv8.28tov8.29. αDiff
673
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, W. Zou
Table 3: Accuracy of αDiff and BinDiff in cross-compiler-vendor & cross-version BCSD.
vulnerability aliasbinaries BinDiff αDiff
pre post vul-func found? Recall@1 vul-func found in top-1? Recall@1 MRR
CVE-2014-0160 Heartbleed openssl-1.0.1f openssl-1.0.1g × 0.371√0.609 0.695
CVE-2014-6271 Shellshock bash-4.3 bash-4.3.30 × 0.485√0.559 0.577
CVE-2014-4877 wget-1.15 wget-1.16 × 0.555√0.691 0.664
CVE-2014-7169 Shellshock2 bash-4.3 bash-4.3.30 × 0.485 × 0.559 0.577
CVE-2014-9295 Clobberin Time ntpd-4.27p10 ntpd-4.28 × 0.434√0.422 0.364
CVE-2015-3456 Venom qemu-2.30 qemu-2.40 × 0.276 × 0.301 0.261
Table 4: Comparison between αDiff and BinDiff on unseen
binariesfrom coreutils.Eachversionofbinaryisevaluated
against its latest version, i.e., v8.29 released on 2017-12-31.
The average accuracy is shown here. @1 means Recall@1
and @5 means Recall@5.
Ver# Date BinDiffαDiff-1f αDiff-3f
@1 @5MRR @1 @5MRR
5.02003-04-02 0.486 0.649 0.756 0.708 0.738 0.821 0.782
6.32006-09-30 0.606 0.677 0.844 0.756 0.778 0.892 0.836
7.12009-02-21 0.618 0.743 0.870 0.809 0.804 0.896 0.853
8.102011-02-04 0.776 0.827 0.906 0.868 0.864 0.926 0.896
8.262016-11-30 0.992 0.958 0.987 0.972 0.977 0.999 0.987
8.282017-09-01 0.999 0.995 0.999 0.997 0.996 0.999 0.997basename
cat
chgrp
chmod
chown
chroot
cksum
comm
cp
csplit
cut
date
dd
df
dir
dircolors
dirname
du
echo
env
expand
expr
factor
false
fmt
fold
ginstall
head
hostid
id
join
kill
link
ln
logname
ls
md5sum
mkdir
mkfifo
mknod
mv
nice
nl
od
paste
pathchk
pinky
pr
printenv
printf
ptx
pwd
readlink
rm
rmdir
seq
sha1sum
shred
sleep
sort
split
stat
stty
sum
sync
tac
tail
tee
test
touch
tr
true
tsort
tty
uname
unexpand
uniq
unlink
uptime
users
vdir
wc
who
whoami
yes0.30.40.50.60.70.8Recall@1
αDiff-1f
αDiff-3f
BinDiff
Figure 4: Comparison of the exact matching accuracy (i.e.,
Recall@1)between αDiffandBindiff,whencomparingeach
binary in coreutils of version v5.0 to version v8.29.
has amuch better performancein detectsimilarities between ver-
sionsspanningalongtimeperiod.Forexample,asshowninFigure
4,αDiff outperforms BinDiff by more than 52% when comparing
some binaries from v5.0 to v8.29.
Second,αDiff-1f is also better than BinDiff when the version
gap is large. For example, it outperforms BinDiff by over 16% on
average, as shown in Figure 4. It shows that the sole intra-function
feature,whichisidentifiedbytheSiamesenetwork,isaverystrong
feature for cross-version BCSD.
Third, BinDiff performs slightly better than αDiff when the ver-
siongapissmall.Forexample,theRecall@1of αDiffis0.996,smaller
than the accuracy of BinDiff (i.e., 0.999), when comparing binaries
of version v8.28 to v8.29. However, the Recall@5 of αDiff is better
thanBinDiff,eveniftheversiongapissmall.Itshowsthat αDiff
could get better match in the top 5 candidates than BinDiff.4.5 Performance in Cross-compiler BCSD
Cross-compilerBCSDhasthreesub-types:cross-compiler-vendor,
cross-compiler-version and cross-optimization-level. Several ap-
proacheshavebeenproposedtosolveoneortwoofthem,however,
neither one can solve all of them well. Our solution αDiff employs
semantic features to solve BCSD, and brings a chance to solve
cross-compiler BCSD too.
4.5.1 Cross-compiler-vendor & Cross-compiler-version. Esh [12]i s
one of the representative solutions for this problem. However, it
is too slow, taking about 3 minutes to compare a pair of functions.
Butwehaveabunchofpairstoanalyze.Sohereweonlycompared
αDiff with the state-of-the-art industrial tool BinDiff, not Esh.
AsshowninTable 3,wecollectedsixprojectswithknownvul-
nerabilities, which are also evaluated in [ 12]. To construct cross-
compiler-vendorand cross-compiler-versionbinary pairs,we first
selected both vulnerable version and patched version for eachproject. Then we compiled the pre-patch version with gcc-4.6.3,
andcompiledthepost-patchversionwithclang-3.8.Toevaluatetheaccuracyofsimilaritydetection,wethendesignedtwoexperiments.
Wefirstqueriedthevulnerablefunction(s)inthepatchedbinary.
Ifthetoolreturnsthematchingvulnerablefunctionorputsitinthe
top-1 candidate, we mark a√otherwise ×in the table. The results
showed that, αDiff succeeded in four out of six cases, whereas
Bindiff failed in all cases.
Thenwecomputedtheoverallaccuracyoffunctionmatching,
i.e., Recall@1, between these two binaries. In all cases except CVE-
2014-9295, αDiffoutperformedBinDiffby10percentageonaverage.
4.5.2 Cross-compiler-vendor & Cross-optimization-level. BinGo [6]
is specialized on cross-compiler and cross-architecture BCSD prob-
lems.Here,wecompared αDiffwithBinGoandBinDiff,usingsame
experiment configurations as BinGo.
Morespecifically,wecompiledcoreutilsforx8632-bitandx86
64-bitarchitectures,usinggcc(v4.8.2)andclang(v3.0)withvarious
optimization levels (O0 toO3).
Tomakeahead-to-headcomparisonwithBinGo,wealsousethe
samemetricasBinGo.Morespecifically,itevaluatesthepercentage
of functions in the first binary, whose matching function in the
secondbinaryisrankedone(i.e.,bestmatch)bythetool.Wecan
infer that, this percentage is similar to Recall@1, except with a
different denominator in Equation 2.
We evaluated six settings and listed the results in Table 5.I nt h e
x86 architecture, we can see that αDiff outperforms BinGo in all
casesby20%onaverage,andoutperformsBinDiffinallcasesexcept
the two clang-O2 vs. clang-O3 settings. In the x64 architecture,
674
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. αDiff: Cross-Version Binary Code Similarity Detection with DNN ASE ’18, September 3–7, 2018, Montpellier, France
Table 5: Comparing percentage of matching functions
ranked#1bydifferenttools,i.e., αDiff,BinGoandBinDiff,in
cross-compiler-vendor & cross-optimization-level settings.
C is short for clang and G is short for gcc.
x86_64 x86
αDiffBinGoBinDiffαDiffBinGoBinDiff
C-O0 vs. G-O3 0.4030.2650.229 0.4620.3320.271
C-O0 vs. C-O3 0.4610.3050.285 0.4920.3720.315
C-O2 vs. C-O3 0.9600.5610.996 0.9690.5760.994
G-O0 vs. C-O3 0.4460.3070.199 0.4840.3330.258
G-O0 vs. G-O3 0.4280.2570.192 0.4410.3020.255
G-O2 vs. G-O3 0.5770.4700.780 0.7650.4800.757
C32-C64C32-G64C32-ARM C64-C32C64-G32C64-ARMG32-C64G32-G64G32-ARM G64-C32G64-G32G64-ARMARM-C32ARM-C64ARM-G32ARM-G640.00.10.20.30.40.50.6% of fucntions ranked #1BinGo
αDiff
Figure 5: Comparing αDiff with BinGo in cross-compiler-
vendorandcross-architecturesettings.C32isshortforclang
x86-32bit and G64 for gcc x86-64bit.
wecouldalsodrawsimilarresults.Ingeneral, αDiffoutperforms
BinGo and BinDiff in this setting of BCSD problems.
4.6 Performance in Cross-architecture BCSD
Since BinGo is also specialized on cross-architecture BCSD, we
still made a comparison with it here, using a same experiment
configuration. More specifically, we matched all functions in core-
utils binaries compiled for one architecture (i.e., x86 32-bit, x8664-bit and ARM) to namesakes in binaries compiled for anotherarchitecture. We also used the percentage of matching functions
ranked one as metric.
The evaluationresult is shown inFigure 5. For BinGo,we took
its best result (i.e., the one with selective inlining). The data in the
plot can be read in the same way as BinGo. For example, the bar
C32−G64 means that, when querying functions compiled using
clang for x86 architecture, around 42% of their matching functions
compiled using gcc for x64 architecture are ranked 1 by the tool
BinGo,while46%areranked1by αDiff.Overall, αDiffoutperforms
BinGo in all settings except G64−C32.
4.7 Application in Vulnerability Search
ManyBCSDsolutionsareproposedtosolvevulnerabilitysearch
problem.Herewealsoevaluatedtheperformanceof αDiffinvulner-
abilitysearch,inthecross-architecturesetting,asdonebyDiscovRE
[16], Multi-k-MH [38] and Genius [17].WefirstcompiledthevulnerableOpenSSLlibrary,whichhave
twovirtuallyidenticalvulnerabilities TLSandDTLS,onplatforms
ARM,MIPSandx86.Thenwequeriedonevulnerablefunctionin
one binary, and examined the ranks of the two matching functions
inanotherbinary,reportedbyeachtool.Theresultsarelistedin
Table6.
It shows that, when searching one function (e.g., TLS), αDiff
could always rank the two matching functions at place 1 and 2. In
general, it outperforms other tools. For example, when querying
the x86 TLS function in the MIPS binary, DiscovRE ranks the DTLS
function at place 4, while αDiff ranks it at place 2.
It shows that, the semantic feature automatically extracted by
neural network (used in αDiff) is effective, even better than the
CFGandotherattributes(usedinDiscovRE)providedbyhuman
experts.
Itisworthnotingthat,Gemini[ 52]alsousesanetworktosearch
bugs in cross-architecture. However, it uses features (e.g., CFG and
nodeattributes)providedbyhumanexpertstopre-processinput
binaries, which we believe would introduce bias. But we do not
have the benchmark they used to evaluate the effectiveness. So we
omit the comparison between αDiff and Gemini.
5 DISCUSSION
In our work, we use CNN to encode the raw bytes of a function
intoanembedding.Morespecifically,wetakeafunctionasa2Dgrid of bytes through 2-dimensional convolutional network (2D-CNN).2D-CNNisusuallyusedforimageprocessing,becauseanimage presents strong spatial locality on its the two dimensions
(i.e.widthandheight).Afunctionisdifferentfromthisandmore
similar to text, meaning 1D-CNN seems to be more appropriate. In
our evaluations, 1D-CNN performs not bad, however, 2D-CONV
with the specific configuration performs better.
We can’t explain the reason behind this and plan to explore
itbasedontheadvancesonneuralnetworkvisualization-related
researches[ 35,36]inthefuturework.Althoughwedon’tthinkwe
have found the best configuration for both 2D-CNN and 1D-CNN,
weshowthefeasibilityofextractingsimilarityfeaturesfromraw
bytes with 2D-CNN. Other researchers can also continue to find
better models and configurations with our dataset.
Although αDiff outperforms BinGo [ 6] in cross-architecture
evaluations, in fact, the inter-function feature and inter-module
featureplayimportantrolesinourevaluations.Inthefuture,we
plan to transfer our approach to the cross-architecture settings, i.e.
training a model with cross-architecture dataset.
6 RELATED WORK
In this section, we briefly survey closely related work.
6.1 Binary Code Similarity Analysis
Staitic Analysis. BinDiff[55],DiscovRE[ 16]andGenius[ 17]
are based on CFG/CG graph-isomorphism (GI) theory [ 14,18]. Dis-
covRE [16] identifies a set of lightweight numeric features and
builds a pre-filter based on the features to quickly identify a small
setofcandidatefunctions.Genius[ 17]encodestheCFGsintohigh-
level numeric vectors to achieve realtime vulnerability search in a
largesetoffirmwareimages.Theseapproachesdependongraph
675
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, W. Zou
Table 6: Accuracy of searching the two vulnerable functions of Heartbleed, namely ‘tls1_process_heartbeat’ (denoted as TLS)
and‘dtls1_process_heartbeat’(denotedasDTLS),inOpenSSLbinariescompiledforARM,MIPSandx86.Whensearchingone
function,bothtwoshouldappearinthetopcandidates,sincetheyarevirtuallyidentical.WhensearchingTLS(orDTLS),the
value in the cell means the ranks of the matching TLS;DTLS functions (or DTLS;TLS) reported by the tool.
Multi-MH [38] Multi-k-MH [38] DiscovRE [16] Genius [17] Centroid [7] αDiff
From→to TLS DTLS TLS DTLS TLS DTLS TLS DTLS TLS DTLS TLS DTLS
ARM→x86 1;2 1;2 1;2 1;2 1;2 1;2 * * * * 1;2 1;2
ARM→MIPS 1;2 1;2 1;2 1;2 1;2 1;2 * * * * 1;2 1;2
ARM→ReadyNAS [40] 1;2 1;2 1;2 1;2 1;2 1;2 * * * * 1;2 2;1
ARM→DD-WRT [13] 1;2 1;2 1;2 1;2 1;2 1;2 * * * * 1;2 1;2
MIPS→ARM 2;3 3;4 1;2 1;2 1;2 1;2 * * * * 2;1 2;1
MIPS→x86 1;4 1;3 1;2 1;3 1;2 1;2 * * * * 2;1 2;1
MIPS→ReadyNAS 2;4 6;16 1;2 1;4 1;2 1;2 1;2 1;2 88;190 678;988 2;1 1;2
MIPS→DD-WRT 1;2 1;2 1;2 1;2 1;2 1;2 1;2 1;2 46;100 87;99 1;2 2;1
x86→ARM 1;2 1;2 1;2 1;2 1;2 1;2 * * * * 2;1 2;1
x86→MIPS 1;7 11;21 1;2 1;6 1;4 1;3 * * * * 1;2 1;2
x86→ReadyNAS 1;2 1;2 1;2 1;2 1;2 1;2 1;2 1;2 145;238 333;127 2;1 2;1
x86→DD-WRT 70;78 1;2 5;33 1;2 1;2 1;2 1;2 1;2 97;255 102;89 1;2 1;2
matching, which has no known polynomial time algorithm, and
ignore the semantics of concrete assembly-level instructions.
InspiredbyDiscovREandGenius,Gemini[ 52]assumesafunc-
tioncanberepresentedasanACFG,aCFGwithnumericattributes.
It converts each ACFG to an embedding through Siamese architec-
ture and Structure2vec [ 11] network, which is similar with ours.
However, Gemini relies on hand-tuned features, such as CFG struc-
turesandnumericfeatures. αDiffextractstheintra-functionfeature
from the raw bytes of functions, without human interference.
BinHunt [ 19] and iBinHunt [ 34] extend GI with symbolic exe-
cution and taint analysis to find semantic differences. BinGo [ 6]
captures the complete function semantics by a selective inlining
techniqueandthenutilizeslengthvariantpartialtracestomodel
binary functions in a program structure agnostic fashion. Esh [ 12]
statisticallyreasonssimilarityoffunctionsbasedonsmallerfrag-
ments’semanticsimilaritiescomputedbyaprogramverifier.These
approaches are computationally expensive. For example, Esh takes
3 minutes on average to compare a pair of functions.
Dynamic Analysis. Under the assumption that similar code
hassimilarruntimebehaviors,BELX[ 15]executeseachfunction
for several calling contexts and collects runtime behaviors of func-
tionsunderacontrolledrandomizedenvironment.IMF-SIM[ 49]
introduces in-memory fuzzing to solve the coverage issue of dy-
namic approaches. These approaches rely on architecture-specific
tools to execute or emulate binaries, and are inconvenient to apply.
6.2 Deep Metric Learning
Bromley et al. [ 4] paves the way on deep metric learning and
trainedSiamesenetworksforsignatureverification.Chopraetal.
[9] presents a method for training a similarity metric from data
andappliedittofaceverification.Seanetal.[ 3]learnsfine-grained
visualsimilarity forproduct designwith deepconvolutionalneural
networkandsiamesenetwork.FaceNet[ 44]usesadeepconvolu-
tional network and triplet embedding [ 51] to learn unified embed-
ding on faces for face verification and identification. In contrast to
contrastive embedding [ 22] and triplet embedding [ 51], Song et al.[47]proposesanewdeepfeatureembeddingalgorithmbytaking
full advantage of the training batches.
6.3 Convolutional Neural Network
Convolutional networks are a specialized kind of neural net-
workforprocessingdata thathasaknownandgrid-liketopology
[20,31]. CNNs typically consist of multiple interleaved layers of
convolutions,non-linearactivations,localresponsenormalizations,
pooling layers and one or more full-connected layers. Since the
notablesuccessofAlexNet[ 30]inILSVRC2012[ 42],therehasbeen
an explosion of interest in CNNs and many successful variants,
suchasVGGNet[ 46],Inception-v3[ 48]andResNet[ 23],havebeen
presented. A full review of CNNs is beyond the scope of this paper
and more information can be found in [20, 21,54].
7 CONCLUSION
In this paper, we propose a DNN augmented solution αDiff to
solvethe cross-versionBCSDproblem. Itemploysthreesemantic
features, i.e., intra-function, inter-function and inter-module fea-
tures,whichareexactedfrombinarycodewithlightweightsolution.
Wehaveimplementedaprototypeof αDiff,andevaluateditona
datasetwithabout2.5 millionsamples.Theresultshowsthat αDiff
outperforms state-of-the-art static solutions by over 10 percent-
ages on average, in detecting similarities between cross-version,
cross-compiler and cross-architecture binaries.
ACKNOWLEDGMENTS
WewouldthankXiaoyuHe,JiaqiPengandShuaiWangfortheir
help in dataset preparing and paper comments. The work is sup-
ported by the Key Laboratory of Network Assessment Technology,
ChineseAcademyofSciencesandBeijingKeyLaboratoryofNet-
work Security and Protection Technology, as well as National Key
R&D Program of China under Grant No.: 2016QY071405, NSFC un-
der Grant No.: 61572481, 61602470, 61772308, 61472209, 61502536,
and U1736209. and Young Elite Scientists Sponsorship Program by
CAST (Grant No. 2016QNRC001).
676
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. αDiff: Cross-Version Binary Code Similarity Detection with DNN ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1]MartínAbadi,PaulBarham,JianminChen,ZhifengChen,AndyDavis,
Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving,
Michael Isard, et al .2016. TensorFlow: A System for Large-Scale
Machine Learning.. In OSDI, Vol. 16. 265–283.
[2]UlrichBayer,PaoloMilaniComparetti,ClemensHlauschek,Christo-
pherKruegel,andEnginKirda.2009. Scalable,Behavior-BasedMal-
ware Clustering.. In NDSS, Vol. 9. Citeseer, 8–11.
[3]SeanBellandKavitaBala.2015. Learningvisualsimilarityforproduct
design with convolutional neural networks. ACM Transactions on
Graphics (TOG) 34, 4 (2015), 98.
[4]Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Säckinger, and
RoopakShah.1994. Signatureverificationusinga"siamese"timedelay
neural network. In Advances in Neural Information Processing Systems.
737–744.
[5]David Brumley, Pongsin Poosankam, Dawn Song, and Jiang Zheng.
2008.Automaticpatch-basedexploitgenerationispossible:Techniques
andimplications.In SecurityandPrivacy,2008.SP2008.IEEESymposium
on. IEEE, 143–157.
[6]Mahinthan Chandramohan, Yinxing Xue, Zhengzi Xu, Yang Liu,Chia Yuan Cho, and Hee Beng Kuan Tan. 2016. Bingo: Cross-
architecture cross-os binary search. In Proceedings of the 2016 24th
ACM SIGSOFT International Symposium on Foundations of Software
Engineering. ACM, 678–689.
[7]Kai Chen, Peng Wang, Yeonjoon Lee, XiaoFeng Wang, Nan Zhang,
HeqingHuang,WeiZou,andPengLiu.2015. FindingUnknownMalice
in10Seconds:MassVettingforNewThreatsattheGoogle-PlayScale..
InUSENIX Security Symposium, Vol. 15.
[8]François Chollet et al .2015. Keras. Retrieved April 10, 2018 from
https://keras.io/
[9]SumitChopra,RaiaHadsell,andYannLeCun.2005. Learningasim-
ilarity metric discriminatively, with application to face verification.
InComputer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE
Computer Society Conference on, Vol. 1. IEEE, 539–546.
[10]George E Dahl, Tara N Sainath, and Geoffrey E Hinton. 2013. Improv-
ingdeepneuralnetworksforLVCSRusingrectifiedlinearunitsand
dropout.In Acoustics,Speec handSignalProcessing(ICASSP),2013IEEE
International Conference on. IEEE, 8609–8613.
[11]HanjunDai,BoDai,andLeSong.2016. Discriminativeembeddingsof
latent variable models for structured data. In International Conference
on Machine Learning. 2702–2711.
[12]YanivDavid,NimrodPartush,andEranYahav.2016. Statisticalsimi-
larity of binaries. ACM SIGPLAN Notices 51, 6 (2016), 266–280.
[13]DDWRT 2013. DD-WRT Firmware Image r21676. Retrieved April 26,
2018from ftp://ftp.dd-wrt.com/betas/2013/05-27-2013-r21676/senao-
eoc5610/linux.bin
[14]Thomas Dullien and Rolf Rolles. 2005. Graph-based comparison of
executable objects (english version). Sstic(2005), 1–13.
[15]Manuel Egele, Maverick Woo, Peter Chapman, and David Brumley.
2014. Blanket execution: Dynamic similarity testing for program
binaries and components. USENIX.
[16]Sebastian Eschweiler, Khaled Yakdan, and Elmar Gerhards-Padilla.
2016. discovRE: Efficient Cross-Architecture Identification of Bugs in
Binary Code.. In NDSS.
[17]Qian Feng, Rundong Zhou, Chengcheng Xu, Yao Cheng, Brian Testa,
and Heng Yin. 2016. Scalable graph-based bug search for firmware
images.In Proceedingsofthe2016ACMSIGSACConferenceonComputer
and Communications Security. ACM, 480–491.
[18]Halvar Flake. 2004. Structural comparison of executable objects. In
Proc. of the International GI Workshop on Detection of Intrusions and
Malware&VulnerabilityAssessment,numberP-46inLectureNotesin
Informatics. Citeseer, 161–174.[19]DebinGao,MichaelKReiter,andDawnSong.2008. Binhunt:Automat-icallyfindingsemanticdifferencesinbinaryprograms.In International
ConferenceonInformationandCommunicationsSecurity.Springer,238–
255.
[20]IanGoodfellow,YoshuaBengio, Aaron Courville,andYoshuaBengio.
2016.Deep learning. Vol. 1. MIT press Cambridge.
[21]IsmaHadjiandRichardPWildes.2018.WhatDoWeUnderstandAbout
Convolutional Networks? arXiv preprint arXiv:1803.08834 (2018).
[22]RaiaHadsell,SumitChopra,andYannLeCun.2006. Dimensionality
reductionbylearninganinvariantmapping.In Computervisionand
pattern recognition, 2006 IEEE computer society conference on, Vol. 2.
IEEE, 1735–1742.
[23]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep
residual learning for image recognition. In Proceedings of the IEEE
conference on computer vision and pattern recognition. 770–778.
[24]Hex-Rays.2015. IDAProDisassemblerandDebugger. RetrievedApril
10, 2018 from https://www.hex-rays.com/products/ida/index.shtml
[25]Geoffrey Hinton, Nitish Srivastava, and Kevin Swersky. 2012. Neural
NetworksforMachineLearning-Lecture6a-Overviewofmini-batch
gradient descent.
[26]XinHu,Tzi-ckerChiueh,andKangGShin.2009. Large-scalemalware
indexing using function-call graphs. In Proceedings of the 16th ACM
conference on Computer and communications security . ACM, 611–620.
[27]Sergey Ioffe and Christian Szegedy. 2015. Batch normalization: Ac-
celerating deep network training by reducing internal covariate shift.
arXiv preprint arXiv:1502.03167 (2015).
[28]JiyongJang,MaverickWoo,andDavidBrumley.2013. TowardsAu-
tomatic Software Lineage Inference.. In USENIX Security Symposium.
81–96.
[29]Herve Jegou, Matthijs Douze, and Cordelia Schmid. 2011. Product
quantization for nearest neighbor search. IEEE transactions on pattern
analysis and machine intelligence 33, 1 (2011), 117–128.
[30]AlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton.2012.Imagenet
classificationwithdeepconvolutionalneuralnetworks.In Advances
in neural information processing systems. 1097–1105.
[31]Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson,
Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. 1989.
Backpropagation applied to handwritten zip code recognition. Neural
computation 1, 4 (1989), 541–551.
[32]Lannan Luo, Jiang Ming, Dinghao Wu, Peng Liu, and Sencun Zhu.
2014. Semantics-based obfuscation-resilient binary code similarity
comparison with applications to software plagiarism detection. InProceedings of the 22nd ACM SIGSOFT International Symposium on
Foundations of Software Engineering. ACM, 389–400.
[33]Lannan Luo, Jiang Ming, Dinghao Wu, Peng Liu, and Sencun Zhu.
2017. Semantics-based obfuscation-resilient binary code similarity
comparisonwithapplicationstosoftwareandalgorithmplagiarism
detection. IEEE Transactions on Software Engineering 43, 12 (2017),
1157–1177.
[34]Jiang Ming, Meng Pan, and Debin Gao. 2012. iBinHunt: Binary hunt-
ing with inter-procedural control flow. In International Conference on
Information Security and Cryptology. Springer, 92–109.
[35]Anh Nguyen, Jason Yosinski, Yoshua Bengio, Alexey Dosovitskiy, and
JeffClune.2016.Plug&playgenerativenetworks:Conditionaliterative
generationofimagesinlatentspace. arXivpreprintarXiv:1612.00005
(2016).
[36]ChrisOlah,ArvindSatyanarayan,IanJohnson,ShanCarter,Ludwig
Schubert, Katherine Ye, and Alexander Mordvintsev. 2018. The Build-
ing Blocks of Interpretability. Distill3, 3 (2018), e10.
[37]OmkarMParkhi,AndreaVedaldi,AndrewZisserman,etal .2015. Deep
face recognition.. In BMVC, Vol. 1. 6.
677
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, W. Zou
[38]Jannik Pewny, Behrad Garmany, Robert Gawlik, Christian Rossow,
and Thorsten Holz. 2015. Cross-architecture bug search in binary
executables. In Security and Privacy (SP), 2015 IEEE Symposium on.
IEEE, 709–724.
[39]DragomirRRadev,HongQi,HarrisWu,andWeiguoFan.2002. Evalu-
ating web-based question answering systems. Ann Arbor 1001 (2002),
48109.
[40]ReadyNAS 2014. ReadyNAS Firmware Image v6.1.6. Retrieved
April 26, 2018 from http://www.downloads.netgear.com/files/GDC/
READYNAS-100/ReadyNASOS-6.1.6-arm.zip
[41]DavidERumelhart,GeoffreyEHinton,andRonaldJWilliams.1986.
Learningrepresentationsbyback-propagatingerrors. nature323,6088
(1986), 533.
[42]Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev
Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla,
Michael Bernstein, et al .2015. Imagenet large scale visual recogni-
tionchallenge. InternationalJournal ofComputer Vision 115,3 (2015),
211–252.
[43]Andreas Sæbjørnsen, Jeremiah Willcock, Thomas Panas, Daniel Quin-
lan, and Zhendong Su. 2009. Detecting code clones in binary exe-
cutables.In Proceedingsoftheeighteenthinternationalsymposiumon
Software testing and analysis. ACM, 117–128.
[44]Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015.Facenet: A unified embedding for face recognition and clustering.
InProceedings of the IEEE conference on computer vision and pattern
recognition. 815–823.
[45]Eui Chul Richard Shin, Dawn Song, and Reza Moazzezi. 2015. Rec-
ognizing Functions in Binaries with Neural Networks.. In USENIX
Security Symposium. 611–626.
[46]Karen Simonyan and Andrew Zisserman. 2014. Very deep convo-lutional networks for large-scale image recognition. arXiv preprint
arXiv:1409.1556 (2014).[47]Hyun Oh Song,YuXiang, Stefanie Jegelka, and SilvioSavarese. 2016.
Deep metric learning via lifted structured feature embedding. In Com-
puter Visionand Pattern Recognition(CVPR), 2016 IEEE Conferenceon.
IEEE, 4004–4012.
[48]ChristianSzegedy,VincentVanhoucke,SergeyIoffe,Jon Shlens,and
Zbigniew Wojna. 2016. Rethinking the inception architecture forcomputer vision. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition. 2818–2826.
[49]ShuaiWangandDinghaoWu.2017.In-memoryfuzzingforbinarycode
similarity analysis. In Proceedings of the 32nd IEEE/ACM International
Conference on Automated Software Engineering. IEEE Press, 319–330.
[50]ZhengWang,KenPierce,andScottMcFarling.2000. Bmat-abinary
matching tool for stale profile propagation. The Journal of Instruction-
Level Parallelism 2 (2000), 1–20.
[51]KilianQWeinberger,JohnBlitzer,andLawrenceKSaul.2006. Distance
metric learning for large margin nearest neighbor classification. In
Advances in neural information processing systems. 1473–1480.
[52]XiaojunXu,ChangLiu,QianFeng,HengYin,LeSong,andDawnSong.
2017. Neural Network-based Graph Embedding for Cross-PlatformBinary Code Similarity Detection. In Proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security. ACM,
363–376.
[53]Zhengzi Xu, Bihuan Chen, Mahinthan Chandramohan, Yang Liu, and
Fu Song. 2017. SPAIN: security patch analysis for binaries towards
understandingthepainandpills.In Proceedingsofthe39thInternational
Conference on Software Engineering. IEEE Press, 462–472.
[54]MatthewDZeilerandRobFergus.2014.Visualizingandunderstanding
convolutional networks. In European conference on computer vision.
Springer, 818–833.
[55]zynamics. [n. d.]. BinDiff. Retrieved April 09, 2018 from https:
//www.zynamics.com/bindiff.html
678
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. 