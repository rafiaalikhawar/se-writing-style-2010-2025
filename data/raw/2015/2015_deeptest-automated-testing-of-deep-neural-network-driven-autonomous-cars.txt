DeepTest: Automated Testing of
Deep-Neural-Network-driven Autonomous Cars
Yuchi Tian
University of Virginia
yuchi@virginia.eduKexin Pei
Columbia University
kpei@cs.columbia.edu
Suman Jana
Columbia University
suman@cs.columbia.eduBaishakhi Ray
University of Virginia
rayb@virginia.edu
ABSTRACT
Recent advances in Deep Neural Networks (DNNs) have led to the
developmentofDNN-drivenautonomouscarsthat,usingsensors
likecamera,LiDAR,etc.,candrivewithoutanyhumanintervention.
MostmajormanufacturersincludingTesla,GM,Ford,BMW,and
Waymo/Googleareworkingonbuildingandtestingdifferenttypes
ofautonomousvehicles.ThelawmakersofseveralUSstatesinclud-
ingCalifornia,Texas,andNewYorkhavepassednewlegislation
to fast-track the process of testing and deployment of autonomous
vehicles on their roads.
However, despite their spectacular progress, DNNs, just like
traditional software, often demonstrate incorrect or unexpected
corner-casebehaviorsthatcanleadtopotentiallyfatalcollisions.
Several such real-world accidents involving autonomous cars have
alreadyhappenedincludingonewhichresultedinafatality.Most
existing testing techniques for DNN-driven vehicles are heavily
dependent on the manual collection of test data under differentdriving conditions which become prohibitively expensive as the
number of test conditions increases.
In this paper, we design, implement, and evaluate DeepTest, a
systematic testing tool for automatically detecting erroneous be-haviors of DNN-driven vehicles that can potentially lead to fatal
crashes.First,ourtoolisdesignedtoautomaticallygeneratedtest
cases leveraging real-world changes in driving conditions like rain,
fog, lighting conditions, etc. DeepTest systematically explore differ-ent parts of the DNN logic by generating test inputs that maximize
the numbers of activated neurons. DeepTest found thousands oferroneous behaviors under different realistic driving conditions
(e.g.,blurring,rain,fog,etc.)manyofwhichleadtopotentiallyfatal
crashesinthreetop performingDNNsintheUdacityself-driving
car challenge.
CCS CONCEPTS
•Software and its engineering →Software testing and de-
bugging;•Securityand privacy →Softwareandapplicationse-
curity;•Computing methodologies →Neural networks ;
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.3180220KEYWORDS
deeplearning,testing,self-drivingcars,deepneuralnetworks,au-
tonomous vehicle, neuron coverage
ACM Reference Format:
Yuchi Tian, Kexin Pei, Suman Jana, and Baishakhi Ray. 2018. DeepTest:
Automated Testing of Deep-Neural-Network-driven Autonomous Cars. In
ICSE ’18: ICSE ’18: 40th International Conference on Software Engineering
, May 27-June 3, 2018, Gothenburg, Sweden. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3180155.3180220
1 INTRODUCTION
Significant progress in Machine Learning (ML) techniques like
Deep Neural Networks (DNNs) over the last decade has enabledthe development of safety-critical ML systems like autonomouscars.SeveralmajorcarmanufacturersincludingTesla,GM,Ford,
BMW, andWaymo/Googleare buildingand activelytesting these
cars. Recent results show that autonomous cars have become very
efficientinpracticeandalreadydrivenmillionsofmileswithoutanyhumanintervention[
21,36].TwentyUSstatesincludingCalifornia,
Texas, and New York have recently passed legislation to enable
testing and deployment of autonomous vehicles [18].
However, despitethetremendous progress,justlike traditional
software, DNN-based software, including the ones used for au-
tonomous driving, often demonstrate incorrect/unexpected corner-
casebehaviorsthatcanleadtodangerousconsequenceslikeafatal
collision. Several such real-world cases have already been reported
(see Table 1). As Table1 clearly shows, such crashes often happen
underrarepreviouslyunseencornercases.Forexample,thefatal
Teslacrashresultedfromafailuretodetectawhitetruckagainst
the bright sky. The existing mechanisms for detecting such erro-neous behaviors depend heavily on manual collection of labeled
testdataoradhoc,unguidedsimulation[ 11,20]andthereforemiss
numerouscornercases.Sincethesecarsadaptbehaviorbasedon
theirenvironmentasmeasuredbydifferentsensors(e.g.,camera,
Infraredobstacledetector,etc.),thespaceofpossibleinputsisex-
tremelylarge.Thus,unguidedsimulationsarehighlyunlikelyto
find many erroneous behaviors.
At a conceptual level, these erroneous corner-case behaviors
inDNN-basedsoftwareareanalogoustologicbugsintraditional
software. Similar to the bug detection and patching cycle in tra-
ditionalsoftwaredevelopment,theerroneousbehaviorsofDNNs,
once detected, can be fixed by adding the error-inducing inputs to
thetrainingdatasetandalsobypossiblychangingthemodelstruc-
ture/parameters.However, thisis achallengingproblem, asnoted
bylargesoftwarecompanieslikeGoogleandTeslathathavealready
deployed machine learning techniques in several production-scale
3032018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Tian et al.
Table 1: Examples of real-world accidents involving autonomous cars
Reported Date Cause Outcome Comments
Hyundai Competition [4] December, 2014 Rain fall Crashed while testing "The sensors failed to pick up street signs, lane markings, and even pedestrians
due to the angle of the car shifting in rain and the direction of the sun" [4]
Tesla autopilot mode [17] July, 2016 Image contrast Killed the driver "The camera failed to recognize the white truck against a bright sky" [23]
Google self-driving car [12] February, 2016 Failed to estimate speed Hita buswhileshifting
lane"The car assumed that the bus would yield when it attempted to merge back into
traffic" [12]
systemsincludingself-drivingcar ,speechrecognition,imagesearch,
etc. [22, 73].
Our experience with traditional software has shown that it is
hard to build robust safety-critical systems only using manual test
cases.Moreover,theinternalsoftraditionalsoftwareandnewDNN-
based software are fundamentally different. For example, unlike
traditionalsoftwarewheretheprogramlogicismanuallywritten
by the software developers, DNN-based software automatically
learnsitslogicfromalargeamountofdatawithminimalhuman
guidance.Inaddition,thelogicofatraditionalprogramisexpressed
in terms of control flow statements while DNNs use weights for
edgesbetweendifferentneuronsandnonlinearactivationfunctions
for similar purposes. Thesedifferences make automated testing of
DNN-based software challenging by presenting several interesting
and novel research problems.
First,traditionalsoftwaretestingtechniquesforsystematically
exploring different parts of the program logic by maximizing
branch/codecoverageisnotveryusefulforDNN-basedsoftware
as the logic is not encoded using control flow [ 70]. Next, DNNs are
fundamentallydifferentfromthemodels(e.g.,finitestatemachines)
usedformodelingandtestingtraditionalprograms.Unlikethetradi-tionalmodels,findinginputsthatwillresultinhighmodelcoverageinaDNNissignificantlymorechallengingduetothenon-linearity
of the functions modeled by DNNs. Moreover, the SatisfiabilityModulo Theory (SMT) solvers that have been quite successful atgenerating high-coverage test inputs for traditional software are
knowntohavetroublewithformulasinvolvingfloating-pointarith-
metic and highly nonlinear constraints, which are commonly used
in DNNs. In fact, several research projects have already attempted
to build custom tools for formally verifying safety properties of
DNNs.Unfortunately,noneof themscale wellto real-world-sized
DNNs[48,51,71].Finally,manuallycreatingspecificationsforcom-
plex DNN systems like autonomous cars is infeasible as the logic is
too complex to manually encode as it involves mimicking the logic
of a human driver.
In this paper, we address these issues and design a systematic
testing methodologyfor automaticallydetecting erroneous behav-iors of DNN-based software of self-driving cars. First, we leverage
thenotionofneuroncoverage(i.e.,thenumberofneuronsactivated
byasetoftestinputs)tosystematicallyexploredifferentpartsof
theDNNlogic.Weempiricallydemonstratethatchangesinneuron
coverage are statistically correlated with changes in the actions of
self-drivingcars (e.g.,steering angle).Therefore, neuroncoverage
canbeusedasaguidancemechanismforsystemicallyexploring
differenttypesofcarbehaviorsandidentifyerroneousbehaviors.
Next, we demonstrate that different image transformations thatmimicreal-worlddifferencesindrivingconditionslikechanging
contrast/brightness,rotationofthecameraresultinactivationof
differentsetsofneuronsintheself-drivingcarDNNs.Weshowthat
bycombiningtheseimagetransformations,theneuroncoverage
can be increased by 100% on average compared to the coverageachieved by manual test inputs. Finally, we use transformation-
specific metamorphic relations between multiple executions of the
tested DNN (e.g., a car should behave similarly under different
lighting conditions) toautomatically detect erroneous corner case
behaviors. We found thousands of erroneous behaviors across the
three top performing DNNs in the Udacity self-driving car chal-
lenge [15].
The key contributions of this paper are:
•Wepresentasystematictechniquetoautomaticallysynthesize
testcasesthatmaximizesneuroncoverageinsafety-criticalDNN-basedsystemslikeautonomouscars.Weempiricallydemonstrate
that changes in neuron coverage correlate with changes in an
autonomous car’s behavior.
•We demonstrate that different realistic image transformations
like changes in contrast, presence of fog, etc. can be used to gen-
erate synthetic tests that increase neuron coverage. We leverage
transformation-specificmetamorphicrelationstoautomatically
detect erroneous behaviors. Our experiments also show that the
syntheticimagescanbeusedforretrainingandmakingDNNs
more robust to different corner cases.
•We implement the proposed techniques in DeepTest, to the best
of our knowledge, the first systematic and automated testing
toolforDNN-drivenautonomousvehicles.WeuseDeepTesttosystematicallytestthreetopperformingDNNmodelsfromthe
Udacity driving challenge. DeepTest found thousands of erro-neous behaviors in these systems many of which can lead to
potentially fatal collisions as shown in Figure 1.
•We have made the erroneous behaviors detected by DeepTest
available at https://deeplearningtest.github.io/deepTest/. We also
plan to release the generated test images and the source of
DeepTest for public use.
1.1 original
 1.2 with added rain
Figure 1: A sample dangerous erroneous behavior found by
DeepTest in the Chauffeur DNN.
2 BACKGROUND
2.1 Deep Learning for Autonomous Driving
The key component of an autonomous vehicle is the percep-
tion module controlled by the underlying Deep Neural Network
(DNN) [14,19]. The DNN takes input from different sensors like
camera, light detection and ranging sensor (LiDAR), and IR (in-
frared) sensor that measure the environment and outputs the steer-
ing angle, braking, etc. necessary to maneuver the car safely under
304
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. DeepTest: Automated Testing of
Deep-Neural-Network-driven Autonomous Cars ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Figure 2: A simple autonomous car DNN that takes inputs from
camera, light detection and ranging sensor (LiDAR), and IR (in-
frared) sensor, and outputs steering angle, braking decision, andacceleration decision. The DNN shown here essentially models the
function σ(θ
(2)·σ(θ(1)·x))whereθs represent the weights of the
edges and σis the activation function. The details of the computa-
tions performed inside a single neuron are shown on the right.
current conditions as shown in Figure 2. In this paper, we focus on
the camera input and the steering angle output.
Atypicalfeed-forwardDNNiscomposedofmultipleprocessing
layersstackedtogethertoextractdifferentrepresentationsofthe
input [30]. Each layer of the DNN increasingly abstracts the input,
e.g.,fromrawpixelstosemanticconcepts.Forexample,thefirstfew
layersofanautonomouscarDNNextractlow-levelfeaturessuch
asedgesanddirections,whilethedeeperlayersidentifyobjectslike
stopsignsandothercars,andthefinallayeroutputsthesteering
decision (e.g., turning left or right).
EachlayerofaDNNconsistsofasequenceofindividualcom-
puting units called neurons. The neurons in different layers are
connectedwitheachotherthroughedges.Eachedgehasacorre-
sponding weight ( θs in Figure 2). Each neuron applies a nonlinear
activation function on its inputs and sends the output to the subse-
quentneuronsasshowninFigure2.Popularactivationfunctions
include ReLU (Rectified Linear Unit) [ 61], sigmoid [ 58], etc. The
edgeweightsofaDNNisinferredduringthetrainingprocessof
theDNNbasedonlabeledtrainingdata.MostexistingDNNsare
trained with gradient descent using backpropagation [ 72]. Once
trained, a DNN can be used for prediction without any further
changes to the weights. For example, an autonomous car DNN can
predict the steering angle based on input images.
Figure2illustratesabasicDNNintheperceptionmoduleofa
self-driving car. Essentially, the DNN is a sequence of linear trans-
formations( e.g.,dotproductbetweentheweightparameters θof
each edge and the output value of the source neuron of that edge)
and nonlinear activations (e.g., ReLU in each neuron). Recent re-
sults have demonstrated that a well-trained DNN fcan predict the
steeringanglewithanaccuracyclosetothatofahumandriver[ 31].
2.2 Different DNN Architectures
MostDNNsusedinautonomousvehiclescanbecategorizedinto
two types: (1) Feed-forward Convolutional Neural Network (CNN),
and (2) Recurrent neural network (RNN). The DNNs we tested (see
Section 4) include two CNNs and one RNN. We provide a brief
description of each architecture below and refer the interested
readers to [39] for more detailed descriptions.
3.1 A simplified CNN architecture
3.2 A simplified RNN architecture
Figure 3: (Upper row) A simplified CNN architecture with a con-
volution kernel shown on the top-left part of the input image. The
same filter (edges with same weights) is then moved across the en-
tire input space, and the dot products are computed between theedgeweightsandtheoutputsoftheconnectedneurons.(Lowerrow)
A simplified RNN architecture with loops in its hidden layers. The
unrolledversionontherightshowshowtheloopallowsasequenceofinputs(i.e. images)tobefedtotheRNNandthesteeringangleis
predicted based on all those images.
CNNarchitecture. ThemostsignificantdifferencebetweenaCNN
andafullyconnectedDNNisthepresenceofa convolutionlayer.
The neurons in a convolution layer are connected only to some
oftheneuronsinthenextlayerandmultipleconnectionsamong
differentneuronssharethesameweight.Thesetsofconnections
sharing the same weights are essentially a convolution kernel [ 50]
that applies the same convolution operation on the outputs of a set
ofneuronsinthepreviouslayer.Figure3(upperrow)illustratestheconvolutionoperationsforthreeconvolutionlayers.Thissimplified
architecture is similar to the ones used in practice [31].
Convolutionlayers havetwo majorbenefits.First, theygreatly
reduce the number of trainable weights by allowing sharing of
weights among multiple connections and thus significantly cut
down the training time. Second, the application of convolutionkernels is a natural fit for image recognition as it resembles the
human visual system which extracts a layer-wise representation of
visual input [50, 53].
RNN architecture. RNNs, unlike CNNs, allow loopsin the net-
work[49].Specifically,theoutputofeachlayerisnotonlyfedto
thefollowinglayerbutalsoflowbacktothepreviouslayer.Such
arrangement allows the prediction output for previous inputs (e.g.,
previousframesinavideosequence)tobealsoconsideredinpre-
dictingcurrentinput.Figure3(lowerrow)illustratesasimplified
version of the RNN architecture.
Similar to other types of DNNs, RNNs also leverage gradient
descent with back propagation for training. However, it is well
known that the gradient, when propagated through multiple loops
inanRNNs,mayvanishtozeroorexplodetoanextremelylarge
value [46] and therefore may lead to an inaccurate model. Long
305
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Tian et al.
short-term memory (LSTM) [47], a popular subgroup of RNNs, is
designedtosolvethisvanishing/explodinggradientproblem.We
encourage interested readers to refer to [47] for more details.
3 METHODOLOGY
To develop an automated testing methodology for DNN-driven
autonomous cars we must answer the following questions. (i) How
do we systematically explore the input-output spaces of an au-
tonomous car DNN? (ii) How can we synthesize realistic inputs to
automatesuchexploration?(iii)Howcanweoptimizetheexplo-
rationprocess?(iv)Howdoweautomaticallycreateatestoracle
that can detect erroneous behaviors without detailed manual speci-
fications?WebrieflydescribehowDeepTestaddresseseachofthese
questions below.
3.1 Systematic Testing with Neuron Coverage
Theinput-outputspace(i.e.,allpossiblecombinationsofinputsand
outputs)ofacomplexsystemlikeanautonomousvehicleistoolarge
for exhaustive exploration. Therefore, we must devise a systematic
wayofpartitioningthespaceintodifferentequivalenceclassesand
try to cover all equivalence classes by picking one sample from
each of them. In this paper, we leverage neuron coverage [ 70]a sa
mechanismforpartitioningtheinputspacebasedontheassumption
that all inputs that have similar neuron coverage are part of the
sameequivalenceclass(i.e.,thetargetDNNbehavessimilarlyfor
these inputs).
NeuroncoveragewasoriginallyproposedbyPei et al.forguided
differential testing of multiple similar DNNs [ 70]. It is defined as
theratioofuniqueneuronsthatgetactivatedforgiveninput(s)and
the total number of neurons in a DNN:
Neuron Coveraдe =|Activated Neurons |
|Total Neurons |(1)
Anindividualneuronisconsideredactivatediftheneuron’soutput
(scaled by the overall layer’s outputs) is larger than a DNN-wide
threshold. In this paper, we use 0 .2 as the neuron activation thresh-
old for all our experiments.
Similar to the code-coverage-guided testing tools for traditional
software, DeepTest tries to generate inputs that maximize neuron
coverage of the test DNN. As each neuron’s output affects the finaloutputofaDNN,maximizingneuroncoveragealsoincreasesoutput
diversity. We empirically demonstrate this effect in Section 5.
Peiet al.definedneuroncoverageonlyforCNNs[ 70].Wefurther
generalize the definition to include RNNs. Neurons, depending on
thetypeofthecorrespondinglayer,mayproducedifferenttypesof
outputvalues( i.e.singlevalueandmultiplevaluesorganizedina
multidimensional array). We describe how we handle such cases in
detail below.
Forallneuronsinfully-connectedlayers,wecandirectlycom-
pare their outputs against the neuron activation threshold as these
neuronsoutputasinglescalarvalue.Bycontrast,neuronsincon-
volutional layers output multidimensional feature maps as each
neuronoutputstheresultofapplyingaconvolutionalkernelacross
the input space [ 45]. For example, the first layer in Figure 3.1 il-
lustratestheapplicationofoneconvolutionalkernel(ofsize3 ×3)
totheentireimage(5 ×5)thatproducesafeaturemapofsize3 ×3
inthesucceedinglayer.Insuchcases,wecomputetheaverageof
the output feature map to convert the multidimensional output
ofaneuronintoascalarandcompareittotheneuronactivation
threshold.For RNN/LSTM with loops, the intermediate neurons are un-
rolled to produce a sequence of outputs (Figure 3.2). We treat each
neuronintheunrolledlayersasaseparateindividualneuronfor
the purpose of neuron coverage computation.
3.2 Increasing Coverage with Synthetic Images
Generatingarbitraryinputsthatmaximizeneuroncoveragemay
not be very useful if the inputs are not likely to appear in the real-
worldeveniftheseinputspotentiallydemonstratebuggybehaviors.
Therefore,DeepTestfocusesongeneratingrealisticsyntheticim-
agesbyapplyingimagetransformationsonseedimagesandmimic
different real-world phenomena like camera lens distortions, ob-
ject movements,different weatherconditions, etc.To this end,we
investigateninedifferentrealisticimagetransformations(chang-
ingbrightness,changingcontrast,translation,scaling,horizontal
shearing,rotation,blurring,fogeffect,andraineffect).Thesetrans-
formations can be classified into three groups: linear, affine, and
convolutional. Our experimental results, as described in Section 5,
demonstrate that all of these transformations increase neuron cov-
eragesignificantlyforallofthetestedDNNs.Below,wedescribe
the details of the transformations.
Adjusting brightness and contrast are both linear transforma-
tions.Thebrightnessofanimagedependsonhowlargethepixel
valuesareforthatimage.Animage’sbrightnesscanbeadjustedby
adding/subtractingaconstantparameter βtoeachpixel’scurrent
value. Contrast represents the difference in brightness between
different pixels in an image. One can adjust an image’s contrast by
multiplying each pixel’s value by a constant parameter α.
Table 2: Different affine transformation matrices
Affine Transform Example Transformation Matrix Parameters
Translation
/bracketleftbigg10tx
01ty/bracketrightbigg
tx: displacement along x axis
ty: displacement along y axis
Scale
/bracketleftbiggsx00
0sy0/bracketrightbigg
sx: scale factor along x axis
sy: scale factor along y axis
Shear
/bracketleftbigg1sx0
sy10/bracketrightbigg
sx: shear factor along x axis
sy: shear factor along y axis
Rotation
/bracketleftbiggcosq−sinq0
sinqcosq0/bracketrightbigg
q: the angle of rotation
Translation, scaling, horizontal shearing, and rotation are all
differenttypesofaffinetransformations.Anaffinetransformationisalinearmappingbetweentwoimagesthatpreservespoints,straight
lines, and planes [ 5]. Affine transforms are often used in image
processingtofixdistortionsresultingfromcameraanglevariations.
In this paper, we leverage affine transformations for the inversecase, i.e., to simulate different real-world camera perspectives or
movementsofobjectsandcheckhowrobusttheself-drivingDNNs
are to those changes.
An affine transformation is usually represented by a 2 ×3 trans-
formation matrix M[6]. One can apply an affine transformation
toa2Dimagematrix Ibysimplycomputingthedotproductof I
andM, the corresponding transformation matrix. We list the trans-
formation matrices for the four types of affine transformations
(translation,scale,shear,androtation)usedinthispaperinTable2.
Blurring andadding fog/raineffects are allconvolutional trans-
formations, i.e., they perform the convolution operation on the
inputpixelswithdifferenttransform-specifickernels.Aconvolu-
tionoperationadds(weightedbythekernel)eachpixeloftheinput
306
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. DeepTest: Automated Testing of
Deep-Neural-Network-driven Autonomous Cars ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
imagetoitslocalneighbors.Weusefourdifferenttypesofblurring
filters: averaging, Gaussian, median, and bilateral [ 3]. We compose
multiple filters provided by Adobe Photoshop on the input images
to simulate realistic fog and rain effects [1, 2].
3.3 Combining Transformations to Increase
Coverage
As the individual image transformations increase neuron coverage,
oneobvious questionis whethertheycan becombinedto further
increase the neuron coverage. Our results demonstrate that differ-
entimagetransformationstendtoactivatedifferentneurons,i.e.,
theycanbe stacked togethertofurtherincreaseneuron coverage.
However,thestatespaceofallpossiblecombinationsofdifferent
transformations is too large to explore exhaustively. We provide
a neuron-coverage-guided greedy search technique for efficiently
findingcombinationsofimagetransformationsthatresultinhigher
coverage (see Algorithm 1).
Algorithm 1: Greedy search for combining image tranforma-
tions to increase neuron coverage
Input : Transformations T, Seed images I
Output : Synthetically generated test images
Variable: S: stack for storing newly generated images
Tqueue: transformation queue
1
2Push all seed imgs ∈I to Stack S
3genTests = ϕ
4whileSis not empty do
5img = S.pop()
6Tqueue =ϕ
7numFailedTries = 0
8whilenumFailedTries ≤maxFailedTries do
9 ifTqueue is not empty then
10 T1 = Tqueue.dequeue()
11 else
12 Randomly pick transformation T1 from T
13 end
14 Randomly pick parameter P1 for T1
15 Randomly pick transformation T2 from T
16 Randomly pick parameter P2 for T2
17 newImage = ApplyTransforms(image, T1, P1, T2, P2)
18 ifcovInc(newimage) then
19 Tqueue.enqueue(T1)
20 Tqueue.enqueue(T2)
21 UpdateCoverage()
22 genTest = genTests ∪newimage S.push(newImage)
23 else
24 numFailedTries = numFailedTries + 1
25 end
26 end
27end
28return genTests
The algorithm takes a set of seed images I, a list of transfor-
mationsTandtheircorrespondingparametersasinput.Thekey
ideabehindthealgorithmistokeeptrackofthetransformations
thatsuccessfullyincreaseneuroncoverageforagivenimageand
prioritizethemwhilegeneratingmoresyntheticimagesfromthe
given image. This process is repeated in a depth-first manner to all
images.
3.4 Creating a Test Oracle with Metamorphic
Relations
OneofthemajorchallengesintestingacomplexDNN-basedsystem
likeanautonomousvehicleiscreatingthesystem’sspecifications
manually, againstwhich the system’sbehaviorcan bechecked. It
is challenging to create detailed specifications for such a system
as it essentially involves recreating the logic of a human driver. Toavoidthisissue,weleveragemetamorphicrelations[ 33]between
the car behaviors across different synthetic images. The key in-
sight is that even though it is hard to specify the correct behavior
ofaself-drivingcarforeverytransformedimage,onecandefine
relationshipsbetweenthecar’sbehaviorsacrosscertaintypesoftransformations. For example, the autonomous car’s steering an-
gleshouldnotchange significantlyforthesameimageunderany
lighting/weatherconditions,blurring,oranyaffinetransformations
withsmallparametervalues.Thus,ifaDNNmodelinfersasteering
angleθofor an input seed image Ioand a steering angle θtfor a
new syntheticimage It, whichis generatedby applyingthe trans-
formation tonIo,onemaydefineasimplemetamorphicrelation
whereθoandθtare identical.
However,thereisusuallynosinglecorrectsteeringanglefora
givenimage,i.e.,acarcansafelytoleratesmallvariations.Therefore,thereisatrade-offbetweendefiningthemetamorphicrelationsvery
tightly, like the one described above (may result in a large number
offalse positives)and makingthe relationsmore permissive(may
lead to many false negatives). In this paper, we strike a balance
betweenthesetwoextremesbyusingthemetamorphicrelations
defined below.
To minimize false positives, we relax our metamorphic relations
andallowvariationswithintheerrorrangesoftheoriginalinputim-ages.WeobservethatthesetofoutputspredictedbyaDNNmodel
for the original images, say { θo1,θo2,....,θon}, in practice, result in
a small but non-trivial number of errors w.r.t.their respective man-
ual labels ({ ˆθ1,ˆθ2,....,ˆθn}). Such errors are usually measured using
Mean Squared Error (MSE), where MSEoriд=1
n/summationtext.1n
i=1(ˆθi−θoi)2.
Leveraging this property, we redefine a new metamorphic relation
as:
(ˆθi−θti)2≤λMSEoriд (2)
Theaboveequationassumesthattheerrorsproducedbyamodel
for the transformed images as input should be within a range of
λtimes the MSE produced by the original image set. Here, λis a
configurable parameter that allows us to strike a balance between
the false positives and false negatives.
4 IMPLEMENTATION
AutonomousdrivingDNNs. Weevaluateourtechniquesonthree
DNN models that won top positions in the Udacity self-driving
challenge [ 15]: Rambo [ 13]( 2ndrank), Chauffeur [ 8]( 3rdrank),
andEpoch[ 10](6thrank).Wechoosethesethreemodelsastheir
implementationsarebasedontheKerasframework[ 34]thatour
current prototype of DeepTest supports. The details of the DNN
models and dataset are summarized in Table 3.
As shown in the right figure of Table 3, the steering angle is
definedastherotationdegreebetweentheheadingdirectionofthe
vehicle (thevertical line) and theheading directions of thesteering
wheel axles ( i.e., usually front wheels). The negative steering angle
indicatesturningleftwhilethepositivevaluesindicateturningleft.
Themaximumsteeringangleofacarvariesbasedonthehardware
of different cars. The Udacity self-driving challenge dataset used in
thispaperhasamaximumsteeringangleof+/-25degree[ 15].The
steering angle is then scaled by 1/25 so that the prediction should
fall between -1 and 1.
RambomodelconsistsofthreeCNNswhoseoutputsaremerged
using a final layer [ 13]. Two of the CNNs are inspired by NVIDIA’s
307
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Tian et al.
No. of Reported Our
Model Sub-Model Neurons MSE MSE
ChauffeurCNN 14270.06 0.06LSTM 513
RamboS1(CNN) 1625
0.06 0.05 S2(CNN) 3801
S3(CNN) 13473
Epoch CNN 2500 0.08 0.10
†dataset HMB_3.bag [16]
Table 3: (Left) Details of DNNs used to evaluate DeepTest.†(Right)
The outputs of the DNNs are the steering angles for a self-driving
car heading forward. The Udacity self-driving car has a maximum
steering angle of +/- 25 degree.
self-driving car architecture [ 31], and the third CNN is based on
comma.ai’s steering model [ 9]. As opposed to other models that
takeindividualimagesasinput,Rambotakesthedifferencesamong
three consecutive images as input. The model uses Keras [ 34] and
Theano [79] frameworks.
Chauffeur modelincludesoneCNNmodelforextractingfea-
tures from the image and one LSTM model for predicting steering
angle [8]. The input of the CNN model is an image while the input
oftheLSTMmodelistheconcatenationof100featuresextractedby
theCNNmodelfromprevious100consecutiveimages.Chauffeur
uses Keras [34] and Tensorflow [24] frameworks.
EpochmodelusesasingleCNN.Asthepre-trainedmodelfor
Epoch is not publicly available, we train the model using the in-
structions provided by the authors [ 10]. We used the CH2_002
dataset [16] from the Udacity self-driving Challenge for training
the epoch model. Epoch , similar to Chauffeur, uses Keras and
Tensorflow frameworks.
Image transformations. In the experiments for RQ2 and RQ3,
we leverage seven different types of simple image transformations:
translation,scaling,horizontalshearing,rotation, contrastadjust-
ment, brightness adjustment, and blurring. We use OpenCV to
implementthesetransformations[ 7].ForRQ2andRQ3described
inSection5,weuse10parametersforeachtransformationasshown
in Table 4.
Table4: TransformationsandparametersusedbyDeepTestforgen-
erating synthetic images.
Transformations Parameters Parameter ranges
Translation (tx,ty)(10,10)to(100,100)
step(10,10)
Scale (sx,sy)(1.5,1.5)to(6,6)
step(0.5,0.5)
Shear (sx,sy)(−1.0,0)to(−0.1,0)
step(0.1,0)
Rotation q(degree) 3to30with step3
Contrast α(gain) 1.2to3.0with step0.2
Brightness β(bias) 10to100with step10
Averaging kernel size 3×3,4×4,5×5,6×6
Gaussian kernel size 3×3,5×5,7×7,3×3
Blur Median aperture linear size 3, 5
Bilateral Filter diameter, sigmaColor, sigmaSpace 9, 75, 75
5 RESULTS
As DNN-based models are fundamentally different than traditional
software,first,wecheckwhetherneuroncoverageisagoodmetrictocapturefunctionaldiversityofDNNs.Inparticular,weinvestigate
whetherneuroncoveragechangeswithdifferentinput-outputpairs
of anautonomouscar. Anindividual neuron’soutput goesthroughasequenceoflinearandnonlinearoperationsbeforecontributing
tothefinaloutputsofaDNN.Therefore,itisnotveryclearhow
much (if at all) individual neuron’s activation will change the final
output. We address this in our first research question.
Table 5: Relation between neuron coverage and test output
Steering Steering
Model Sub-Model Angle Direction
Spearman Wilcoxon Effect size
Correlation Test (Cohen’s d)
Chauffeur Overall -0.10 (***) left (+ve) >right (-ve) (***) negligible
CNN 0.28 (***) left (+ve) <right (-ve) (***) negligible
LSTM -0.10 (***) left (+ve) >right (-ve) (***) negligible
Rambo Overall -0.11 (***) left (+ve) <right (-ve) (***) negligible
S1 -0.19 (***) left (+ve) <right (-ve) (***) large
S2 0.10 (***) not significant negligible
S3 -0.11 (***) not significant negligible
Epoch N/A 0.78 (***) left (+ve) <right (-ve) (***) small
*** indicates statistical significance with p-value <2.2∗10−16
RQ1.Do different input-output pairs result in different neuron
coverage?
For each input image we measure the neuron coverage (see
Equation 1 in Section 3.1) of the underlying models and the corre-
sponding output. As discussed in Section 4, corresponding to aninput image, each model outputs a steering direction (left (+ve) /right (-ve)) and a steering angle as shown in Table 3 (right). We
analyze the neuron coverage for both of these outputs separately.
Steering angle .Assteeringangleisacontinuousvariable,we
check Spearman rank correlation [ 76] between neuron coverage
andsteeringangle.Thisisanon-parametricmeasuretocompute
monotonic association between the two variables [ 44]. Correlation
withpositivestatisticalsignificancesuggeststhatthesteeringangle
increases with increasing neuron coverage and vice versa. Table 5
showsthatSpearmancorrelationsforallthemodelsarestatistically
significant—whileChauffeurandRambomodelsshowanoverall
negative association, Epoch model shows a strong positive correla-
tion.Thisresultindicatesthattheneuroncoveragechangeswith
the changes in output steering angles, i.e.different neurons get
activated for different outputs. Thus, in this setting, neuron cov-
erage can be a good approximation for estimating the diversity of
input-outputpairs.Moreover,ourfindingthatmonotoniccorrela-
tionsbetweenneuroncoverageandsteeringanglealsocorroborate
Goodfellow et al.’s hypothesis that, in practice, DNNs are often
highly linear [40].
Steering direction . To measure the association between neu-
roncoverageandsteeringdirection,wecheckwhetherthecover-
age varies between right and left steering direction. We use the
Wilcoxon nonparametric test as the steering direction can only
havetwovalues(leftandright).Ourresultsconfirmthatneuron
coverage varies with steering direction with statistical significance
(p<2.2∗10−16)forallthethreeoverallmodels.Interestingly,for
Rambo , only the Rambo-S1 sub-model shows statistically signif-icantcorrelationbutnotRambo-S2andRambo-S3.Theseresults
suggestthat,unlikesteeringangle,somesub-modelsaremorere-
sponsible than other for changing steering direction.
Overall, these results show that neuron coverage altogether
variessignificantlyfordifferentinput-outputpairs.Thus,aneuron-
coverage-directed(NDG)testingstrategycanhelpinfindingcorner
cases.
308
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. DeepTest: Automated Testing of
Deep-Neural-Network-driven Autonomous Cars ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
4.1 Difference in neuron coverage caused by different image transformations
 4.2 Average cumulative neuron coverage per input image
Figure 4: Different image transformations activate significantly different neurons. In the top figure the median Jaccard distances for
Chauffeur-CNN, Chauffeur-LSTM, Epoch, Rambo-S1, Rambo-S2, and Rambo-S3 models are 0.53, 0.002, 0.67, 0.12, 0.17, 0.30, and 0.65.
Result 1: Neuron coverage is correlated with input-output
diversity and can be used to systematic test generation.
Next, we investigate whether synthetic images generated by
applying different realistic image transformations (as described in
Table 2) on existing input images can activate different neurons.
Thus, we check:
RQ2.Dodifferentrealisticimagetransformationsactivatedif-
ferent neurons?
We randomly pick 1,000 input images from the test set and
transformeachofthembyusingsevendifferenttransformations:
blur,brightness,contrast,rotation,scale,shear,andtranslation.We
also vary the parameters of each transformation and generate a
total of 70,000 new synthetic images. We run all models with these
syntheticimagesasinputandrecordtheneuronsactivatedbyeach
input.
Wethencomparetheneuronsactivatedbydifferentsynthetic
images generated from the same image. Let us assume that two
transformations T1andT2, when applied to an original image I,
activatetwosetsofneurons N1andN1respectively.Wemeasure
thedissimilaritiesbetween N1andN2bymeasuringtheirJaccard
distance: 1 −|N1∩N2|
|N1∪N2|.
Figure4.1showstheresultforallpossiblepairoftransformations
(e.g.,blurvs.rotation,rotationvs.transformation, etc.)fordifferent
models.Theseresultsindicatethatforallmodels,exceptChauffeur-
LSTM , different transformations activate different neurons. As
discussedinSection2.1,LSTMisaparticulartypeofRNNarchitec-
turethatkeepsstatesfrompreviousinputsandhenceincreasing
the neuron coverage of LSTM models with single transformations
is much harder than other models. In this paper, we do not explore
this problem any further and leave it as an interesting future work.
Wefurthercheckhowmuchasingletransformationcontributes
inincreasingtheneuroncoverage w.r.t.allothertransformations
foragivenseedimage.Thus,ifanoriginalimage Iundergoesseven
discretetransformations: T1,T2,...T7,wecomputethetotalnumber
of neuronsactivated by T1,T1∪T2, ...,7/uniontext.1
i=1Ti. Figure4.2 showsthe
cumulative effect of all the transformations on average neuroncoverage per seed image. We see that the cumulative coverageincreases with increasing number of transformations for all themodels. In other words, all the transformations are contributing
towards the overall neuron coverage.
We also compute the percentage change in neuron coverage
per image transformation ( NT)w.r.t.to the corresponding seed
image (NO) as: (NT-NO)/NO. Figure 5 shows the result. For all
the studied models, the transformed images increase the neuron
coverage significantly—Wilcoxon nonparametric test confirms the
statisticalsignificance.Theseresultsalsoshowthatdifferentimage
transformations increase neuron coverage at different rates.
Result2: Differentimagetransformationstendtoactivate
different sets of neurons.
Next, we mutate the seed images with different combinations of
transformations (see Section 3). Since different imagetransforma-
tionsactivatedifferentsetofneurons,herewetrytoincreasethe
neuroncoveragebythesetransformedimageinputs.Tothisend,
we question:
RQ3.Canneuron coveragebefurtherincreased bycombining
different image transformations?
Weperformthisexperimentbymeasuringneuroncoveragein
two different settings: (i) applying a set of transformations and (ii)
combining transformations using coverage-guided search.
i)Cumulative Transformations. Since different seed images acti-
vate a different set of neurons (see RQ1), multiple seed images col-
lectively achieve higher neuron coverage than a single one. Hence,
we check whether the transformed images can still increase the
neuroncoveragecollectively w.r.t.thecumulativebaselinecoverage
ofa setofseed images.Inparticular, wegenerate atotalof 7,000images from 100 seed images by applying 7 transformations and
varying10parameterson100seedimages.Thisresultsinatotalof
7,000testimages.Wethencomparethecumulativeneuroncoverage
ofthesesyntheticimages w.r.t.thebaseline,whichusethesame100
seedimagesforfaircomparison.Table6showstheresult.Acrossall
the models (except Rambo-S3), the cumulative coverage increased
significantly. Since the Rambo-S3 baseline already achieved 97%coverage, the transformed images only increase the coverage by
(13,080−13,008)/13,008=0.55%.
ii)GuidedTransformations. Finally,wecheckwhetherwecanfur-
therincreasethecumulativeneuroncoveragebyusingthecoverage-
guided search technique described in Algorithm 1. We generate
254,221,and864imagesfrom100seedimagesforChauffeur-CNN,
309
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Tian et al.
Median Increase in Neuron Coverage
Transformation Chauffeur Epoch Rambo
(CNN,LSTM)( S1,S2,S3)
Scale (1.0,0.0) 39.0** (2.0*,5.0*,32.0)
(0.67%,0%) 93% (0.41%,1%,4%)
Brightness (100.0**,1.0) 113.0** (67.0**,104.0**,585.0*)
(67%,0.2%) 269% (14%,24%,66%)
Contrast (120.0**,1.0*) 75.0** (47.0**,100.0**,159.0)
(80%,0.2%) 179% (10%,23%,18%)
Blur (41.0**,0.0) 9.0* (18.0**,23.0**,269.5*)
(28%,0%) 21% (4%,5%,31%)
Rotation (199.0**,2.0*) 81.0** (70.0**,13.0**,786.5*)
(134%,0.39%) 193% (14%,3%,89%)
Translation (147.0**,1.0*) 65.0** (143.0**,167.0**,2315.5**)
(99%,0.2%) 155% (29%,38%,263%)
Shear (168.0**,1.0*) 167.0** (48.0**,132.0**,1472.0**)
(113%,0.2%) 398% (10%,30%,167%)
All numbers are statistically significant;
Numbers with * and ** have small and large Cohen’s D effect.
Figure 5: Neuron coverage per seed image for individual image
transformations w.r.t.baseline.
Table6: Neuroncoverageachievedbycumulativeandguidedtrans-
formations applied to 100 seed images.
Cumulative Guided % increase of guided w.r.t.
Model Baseline Transformation Generation Baseline Cumulative
Chauffeur-CNN 658 (46%) 1,065 (75%) 1,250 (88%) 90% 17%
Epoch 621 (25%) 1034 (41%) 1,266 (51%) 104% 22%
Rambo-S1 710 (44%) 929 (57%) 1,043 (64%) 47% 12%
Rambo-S2 1,146 (30%) 2,210 (58%) 2,676 (70%) 134% 21%
Rambo-S3 13,008 (97%) 13,080 (97%) 13,150 (98%) 1.1% 0.5%
Epoch,andRambomodelsrespectivelyandmeasuretheircollective
neuron coverage. As shown in Table 6, the guided transformations
collectivelyachieve88%,51%,64%,70%,and98%oftotalneurons
formodelsChauffeur-CNN,Epoch,Rambo-S1,Rambo-S2,and
Rambo-S3 respectively, thus increasing the coverage up to 17%
22%, 12%, 21%, and 0.5% w.r.t.the unguided approach. This method
alsosignificantlyachieveshigherneuroncoverage w.r.t.baseline
cumulative coverage.
Result3: Bysystematicallycombiningdifferentimagetrans-
formations,neuroncoveragecanbeimprovedbyaround100%
w.r.t. the coverage achieved by the original seed images.
Next we check whether the synthetic images can trigger any
erroneous behavior in the autonomous car DNNs and if we can
detectthosebehaviorsusingmetamorphicrelationsasdescribedin
Section 3.4. This leads to the following research question:RQ4.Canweautomaticallydetecterroneousbehaviorsusing
metamorphic relations?
Figure6: Deviationsfromthehumanlabelsforimagesthatviolate
themetamorphicrelation(seeEquation2)ishighercomparedtothe
deviationsfororiginalimages.Thus,thesesyntheticimageshavea
high chance to show erroneous behaviors.
Herewefocusonthetransformedimageswhoseoutputsviolate
the metamorphic relation defined in Equation 2. We call these
imagesIerrand their corresponding original images as Iorд.W e
comparethedeviationbetweentheoutputsof IerrandIorдw.r.t.the
corresponding human labels, as shown in Figure 6. The deviations
produced for Ierrare much larger than Iorд(also confirmed by
Wilcoxon test for statistical significance). In fact, mean squared
error (MSE) for Ierris 0.41, while the MSE of the corresponding
Iorдis 0.035. Such differences also exist for other synthetic images
that are generated by composite transformations including rain,
fog, and those generated during the coverage-guided search. Thus,
overallIerrhas a higher potential to show buggy behavior.
However, for certain transformations (e.g., rotation), not all vio-
lations of themetamorphic relations can be considered buggy as
thecorrectsteeringanglecanvarywidelybasedonthecontentsof
thetransformedimage.Forexample,whenanimageisrotatedbya
largeamount,say30degrees,itisnontrivialtoautomaticallydefine
itscorrectoutputbehaviorwithoutknowingitscontents.Toreduce
suchfalsepositives,weonlyreportbugsforthetransformations
(e.g.,smallrotations,rain,fog,etc.)wherethecorrectoutputshould
notdeviatemuchfromthelabelsofthecorrespondingseedimages.
Thus, we further use a filtration criteria as defined in Equation 3 to
identify such transformations by checking whether the MSE of the
synthetic images is close to that of the original images.
|MSE(trans ,param)−MSEorд|≤ϵ (3)
Thus, we only choose the transformations that obey Equation 3
for counting erroneous behaviors. Table 7 shows the number of
such erroneous cases by varying two thresholds: ϵandλ—a higher
value ofλand lower value of ϵmakes the system report fewer
bugs and vice versa. For example, with a λof 5 andϵof 0.03, we
report330violationsforsimpletransformations.Wedonotenforce
thefiltrationcriteriaforcompositetransformations.Rainandfog
effects should produce same outputs as original images. Also, in
guidedsearchsincemultipletransformationsproducethesynthe-
sized images, it is not possible to filter out a single transformation.
Thus, for rain, fog, and guided search, we report 4448, 741, and 821
erroneous behavior respectively for λ=5, across all three models.
310
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. DeepTest: Automated Testing of
Deep-Neural-Network-driven Autonomous Cars ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
original
 fog
 original
 rain
 original
 translation(40,40)
 original
 scale(2.5x)
original
 shear(0.1)
 original
 rotation(6 degree)
 original
 contrast(1.8)
 original
 brightness(50)
Figure 7: Sample images showing erroneous behaviors detected by DeepTest using synthetic images. For original images the arrows are
marked in blue, while for the synthetic images they are marked in red. More such samples can be viewed at https://deeplearningtest.github.
io/deepTest/.
Table 7: Number of erroneous behaviors reported by DeepTest
across all tested models at different thresholds
Simple Tranformation Composite Transformation
λ ϵ(see Eqn. 3) Fog Rain Guided
(see Eqn. 2) 0.01 0.02 0.03 0.04 0.05 Search
1 15666 18520 23391 24952 29649 9018 6133 1148
2 4066 5033 6778 7362 9259 6503 2650 1026
3 1396 1741 2414 2627 3376 5452 1483 930
4 501 642 965 1064 4884 4884 997 872
5 95 171 330 382 641 4448 741 820
6 49 85 185 210 359 4063 516 764
7 13 24 89 105 189 3732 287 721
8 3 5 34 45 103 3391 174 668
9 0 1 12 19 56 3070 111 637
10 0035 2 3 2801 63 597
Table 8: Number of unique erroneous behaviors reported by
DeepTest for different models with λ=5(see Eqn. 2)
Transformation Chauffeur Epoch Rambo
Simple Transformation
Blur 32 7 1 1
Brightness 97 32 15
Contrast 31 12 -
Rotation -1 3 -
Scale -1 0 -
Shear --2 3
Translation 21 35 -
Composite Transformation
Rain 650 64 27
Fog 201 135 4112
Guided 89 65 666
Table8furtherelaboratestheresultfordifferentmodelsfor λ=5
andϵ=0.03, as highlighted in Table 7. Interestingly, some models
aremorepronetoerroneousbehaviorsforsometransformations
thanothers.Forexample,Rambo produces23erroneouscasesfor
shear, while the other two models do not show any such cases.
Similarly, DeepTest finds 650 instances of erroneous behavior in
Chauffeur for rain but only 64 and 27 for Epoch and Rambo respec-tively.Intotal,DeepTestdetects6339erroneousbehaviorsacrossall
three models. Figure 7 further shows some of the erroneous behav-
iors that are detected by DeepTest under different transformations
that can lead to potentially fatal situations.
WealsomanuallycheckedthebugsreportedinTable8andreport
thefalsepositivesinFigure8.Italsoshowstwosyntheticimages
(the corresponding original images) where DeepTest incorrectly
reportserroneousbehaviorswhilethemodel’soutputisindeedsafe.
Although such manual investigation is, by definition, subjective
and approximate, all the authors have reviewed the images and
agreed on the false positives.Simple
Model Transformation Guided Rain Fog Total
Epoch 14 0 0 0 14
Chauffeur 5 3 12 6 26
Rambo 84 3 11 28 90
Total 27 46 23 34 130
original
 translation(50,50), epoch
 original
 shear(0.4), rambo
Figure 8: Sample false positives produced by DeepTest for λ=5,
ϵ=0.03
Result 4: With neuron coverage guided synthesized images,
DeepTestsuccessfullydetectsmorethan1,000erroneousbehavior
as predicted by the three models with low false positives.
RQ5.Can retrainingDNNs withsynthetic images improveac-
curacy?
Table9: ImprovementinMSEafterretrainingofEpochmodelwith
synthetic tests generated by DeepTest
Test set Original MSE Retrained MSE
original images 0.10 0.09
with fog 0.18 0.10
with rain 0.13 0.07
HerewecheckwhetherretrainingtheDNNswithsomeofthe
syntheticimagesgeneratedbyDeepTesthelpsinmakingtheDNNs
more robust.We used the images from HMB_3.bag [ 16] and cre-
ated their synthetic versions by adding the rain and fog effects. We
retrained the Epoch model with randomly sampled 66% of thesesynthetic inputs along with the original training data. We evalu-
atedboththeoriginalandtheretrainedmodelontherest34%of
the synthetic images and their original versions. In all cases, theaccuracy of the retrained model improved significantly over the
original model as shown in Table 9.
Result 5: Accuracy of a DNN can be improved up to 46% by
retrainingtheDNNwithsyntheticdatageneratedbyDeepTest.
311
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Tian et al.
6 THREATS TO VALIDITY
DeepTest generates realistic synthetic images by applying different
imagetransformationsontheseedimages.However,thesetrans-
formations are not designed to be exhaustive and therefore may
not cover all realistic cases.
While our transformations like rain and fog effects are designed
to be realistic, the generated pictures may not be exactly repro-
ducible in reality due to a large number of unpredictable factors,e.g., the position of the sun, the angle and size of the rain drops.
etc. However, as the image processing techniques become more
sophisticated, the generated pictures will get closer to reality.
AcompleteDNNmodelfordrivinganautonomousvehiclemust
alsohandlebrakingandaccelerationbesidesthesteeringangle.We
restricted ourselves to only test the accuracy of the steering angle
asourtestedmodelsdonotsupportbrakingandaccelerationyet.
However, our techniques should be readily applicable to testing
those outputs too assuming that the models support them.
7 RELATED WORK
Testing of driver assistance systems. Abdessalem et al. pro-
posed a technique for testing Advanced Driver Assistance Systems
(ADAS) in autonomous cars that show warnings to the drivers if it
detectspedestriansinpositionswithlowdrivervisibility[ 25].They
use multi-objective meta heuristic search algorithms to generate
tests that simultaneously focus on the most critical behaviors of
the system and the environment as decided by the domain experts
(e.g.,moving pedestrians in the dark).
Thekeydifferencesbetweenthisworkandoursarethreefold:
(i) We focus on testing the image recognition and steering logic
intheautonomouscarDNNswhiletheirtechniquetestedADAS
system’s warning logic based on preprocessed sensor inputs; (ii)
Their blackbox technique depends on manually selected critical
scenarioswhileourgray-boxtechniquelooksinsidetheDNNmodel
andsystematicallymaximizeneuroncoverage.Thetrade-offisthat
their technique can, in theory, work for arbitrary implementations
while our technique is tailored for DNNs; and (iii) We leverage
metamorphic relations for creating a test oracle while they depend
on manual specifications for detecting faulty behavior.
Testing and verification of machine learning. Traditional
practices in evaluating machine learning systems primarilymea-
sure their accuracy on randomly drawn test inputs from manually
labeleddatasetsandadhocsimulations[ 11,20,82].However,with-
out the knowledgeof the model’s internals, suchblackbox testing
paradigmsarenotabletofinddifferentcorner-casesthatmayin-
duce unexpected behaviors [26, 70].
Peiet al.[70] proposed DeepXplore, a whitebox differential test-
ing algorithm for systematically finding inputs that can trigger
inconsistencies between multiple DNNs. They introduced neuron
coverage as a systematic metric for measuring how much of the
internallogicofaDNNshavebeentested.Bycontrast,ourgrayboxmethodsuseneuroncoverageforguidedtestgenerationinasingle
DNN and leverage metamorphic relations to identify erroneous
behaviors without requiring multiple DNNs.
Anotherrecentlineofworkhasexploredthepossibilityofverify-
ing DNNs against different safety properties [ 48,51,71]. However,
none of these techniques can verify a rich set of properties for real-
world-sized DNNs. By contrast, our techniques can systematicallyteststate-of-the-artDNNsforsafety-criticalerroneousbehaviors
but do not provide any theoretical guarantees.
Adversarial machine learning. A large number of projects
successfully attacked machine learning models at test time by forc-
ingittomakeunexpectedmistakes.Morespecifically,theseattacks
focusonfindinginputsthat,whenchangedminimallyfromtheir
original versions, get classified differently by the machine learn-
ingclassifiers.Thesetypesofattacksareknowntoaffectabroad
spectrum of tasks such as image recognition [ 37,40,52,55,62,
63,65,66,78],facedetection/verification[ 75,81],malwaredetec-
tion [28,42,54,85], andtext analysis [ 59,67]. Severalprior works
haveexploreddefensesagainsttheseattackswithdifferenteffec-
tiveness [29, 32, 35, 38, 41, 43, 48, 57, 64, 68, 74, 77, 80, 84, 86].
Insummary,thislineofworktriestofindaparticularclassof
erroneousbehaviors,i.e.,forcingincorrectpredictionbyaddinga
minimumamountofnoisetoagiveninput.Bycontrast,wesystem-
atically test a given DNN by maximizing neuron coverage and find
a diverse set of corner-case behaviors. Moreover, we specifically
focus on finding realistic conditions that can occur in practice.
Test amplification. There is a large body of work on test case
generation and amplification techniques for traditional software
thatautomaticallygeneratetestcasesfromsomeseedinputsand
increase code coverage. Instead of summarizing them individually
here, we refer the interested readers to the surveys by Anand et
al. [27], McMinn et al. [ 56], and Pasareanu et al. [ 69]. Unlike these
approaches, DeepTest is designed to operate on DNNs.
Metamorphic testing. Metamorphic testing [ 33,87] is a way
of creating test oracles in settings where manual specifications
arenotavailable.Metamorphictestingidentifiesbuggybehavior
bydetectingviolationsofdomain-specificmetamorphicrelations
that are defined across outputs from multiple executions of the
test program with different inputs. For example, a sample meta-
morphic property for program padding two inputs aandbcan
bep(a,b)=p(a,0)+p(b,0). Metamorphic testing has been used
inthepastfortestingbothsupervisedandunsupervisedmachine
learningclassifiers[ 60,83].Bycontrast,wedefinenewmetamor-
phic relations in the domain of autonomous cars which, unlike the
classifierstestedbefore,produceacontinuoussteeringangle,i.e.,it
is a regression task.
8 CONCLUSION
Inthispaper,weproposedandevaluatedDeepTest,atoolforau-
tomatedtestingofDNN-drivenautonomouscars.DeepTestmaxi-
mizestheneuroncoverageofaDNNusingsynthetictestimages
generatedbyapplyingdifferentrealistictransformationsonaset
ofseedimages.Weusedomain-specificmetamorphicrelationsto
finderroneousbehaviorsoftheDNNwithoutdetailedspecification.DeepTestcanbeeasilyadaptedtotestotherDNN-basedsystemsby
customizingthetransformationsandmetamorphicrelations.We
believe DeepTest is an important first step towards building robust
DNN-based systems.
9 ACKNOWLEDGEMENTS
WewouldliketothankYoavHollanderandtheanonymousreview-
ers for their helpful feedback. This work was supported in part by
NSF grants CNS-16-18771, CNS-16-17670, and CNS-15-64055; ONR
grant N00014-17-1-2010; and a Google Faculty Fellowship.
312
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. DeepTest: Automated Testing of
Deep-Neural-Network-driven Autonomous Cars ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]2013. Add Dramatic Rain to a Photo in Photoshop. https://design.tutsplus.com/
tutorials/add-dramatic-rain-to-a-photo-in-photoshop--psd-29536. (2013).
[2]2013. How to create mist: Photoshop effects for atmospheric landscapes.
http://www.techradar.com/how-to/photography-video-capture/cameras/how-to-create-mist-photoshop-effects-for-atmospheric-landscapes-1320997.
(2013).
[3] 2014. The OpenCV Reference Manual (2.4.9.0 ed.).
[4]2014. This Is How Bad Self-Driving Cars Suck In The Rain. http://jalopnik.com/
this-is-how-bad-self-driving-cars-suck-in-the-rain-1666268433. (2014).
[5]2015. Affine Transformation. https://www.mathworks.com/discovery/
affine-transformation.html. (2015).
[6]2015. Affine Transformations. http://docs.opencv.org/3.1.0/d4/d61/tutorial_
warp_affine.html. (2015).
[7]2015. Open Source ComputerVision Library. https://github.com/itseez/opencv.
(2015).
[8]2016. Chauffeur model. https://github.com/udacity/self-driving-car/tree/master/
steering-models/community-models/chauffeur. (2016).
[9]2016. comma.ai’s steering model. https://github.com/commaai/research/blob/
master/train_steering_model.py. (2016).
[10]2016. Epoch model. https://github.com/udacity/self-driving-car/tree/master/
steering-models/community-models/cg23. (2016).
[11]2016. Google Auto Waymo Disengagement Report for Au-tonomous Driving. https://www.dmv.ca.gov/portal/wcm/connect/946b3502-c959-4e3b-b119-91319c27788f/GoogleAutoWaymo_disengage_
report_2016.pdf?MOD=AJPERES. (2016).
[12]2016. Google’s Self-Driving Car Caused Its First Crash. https://www.wired.com/
2016/02/googles-self-driving-car-may-caused-first-crash/. (2016).
[13]2016. Rambo model. https://github.com/udacity/self-driving-car/tree/master/
steering-models/community-models/rambo. (2016).
[14] 2016. Tesla Autopilot. https://www.tesla.com/autopilot. (2016).
[15]2016. Udacity self driving car challenge 2. https://github.com/udacity/
self-driving-car/tree/master/challenges/challenge-2. (2016).
[16]2016. Udacityselfdrivingcarchallenge2dataset. https://github.com/udacity/
self-driving-car/tree/master/datasets/CH2. (2016).
[17]2016. Who’sresponsiblewhenanautonomouscarcrashes? http://money.cnn.
com/2016/07/07/technology/tesla-liability-risk/index.html. (2016).
[18]2017. Autonomous Vehicles Enacted Legislation. http://www.ncsl.org/research/
transportation/autonomous-vehicles-self-driving-vehicles-enacted-legislation.
aspx. (2017).
[19] 2017. Baidu Apollo. https://github.com/ApolloAuto/apollo. (2017).
[20]2017. Inside Waymo’s Secret World for Training Self-DrivingCars. https://www.theatlantic.com/technology/archive/2017/08/
inside-waymos-secret-testing-and-simulation-facilities/537648/. (2017).
[21]2017. TheNumbersDon’tLie:Self-DrivingCarsAreGettingGood. https://www.
wired.com/2017/02/california-dmv-autonomous-car-disengagement. (2017).
[22]2017. Software 2.0. https://medium.com/@karpathy/software-2-0-a64152b37c35.
(2017).
[23]2017. Tesla’sSelf-DrivingSystemClearedinDeadlyCrash. https://www.nytimes.
com/2017/01/19/business/tesla-model-s-autopilot-fatal-crash.html. (2017).
[24]Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,Craig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al
.
2016. Tensorflow:Large-scalemachinelearningonheterogeneousdistributed
systems. arXiv preprint arXiv:1603.04467 (2016).
[25]RajaBenAbdessalem,ShivaNejati,LionelCBriand,andThomasStifter.2016.
Testing advanced driver assistance systems using multi-objective search and
neuralnetworks.In AutomatedSoftwareEngineering(ASE),201631stIEEE/ACM
International Conference on. IEEE, 63–74.
[26]an Goodfellow and Nicolas Papernot. 2017. The challenge of verification and
testingofmachinelearning. http://www.cleverhans.io/security/privacy/ml/2017/
06/14/verification.html. (2017).
[27]Saswat Anand, Edmund K Burke, Tsong Yueh Chen, John Clark, Myra B Cohen,
Wolfgang Grieskamp, Mark Harman, Mary Jean Harrold, Phil Mcminn, Antonia
Bertolino,etal .2013. Anorchestratedsurveyofmethodologiesforautomated
software test case generation. Journal of Systems and Software 86, 8 (2013),
1978–2001.
[28]HyrumAnderson.2017. EvadingNext-GenAVusingA.I. https://www.defcon.
org/html/defcon-25/dc-25-index.html. (2017).
[29]Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis,
Aditya Nori, and Antonio Criminisi. 2016. Measuring neural net robustness with
constraints. In Advances in Neural Information Processing Systems. 2613–2621.
[30]YoshuaBengio,PascalLamblin,DanPopovici,andHugoLarochelle.2007. Greedylayer-wisetrainingofdeepnetworks.In Advancesinneuralinformationprocessing
systems. 153–160.
[31]Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat
Flepp,PrasoonGoyal,LawrenceDJackel,MathewMonfort,UrsMuller,Jiakai
Zhang, et al .2016. End to end learning for self-driving cars. arXiv preprint
arXiv:1604.07316 (2016).
[32]Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness
of neural networks. In Security and Privacy (SP), 2017 IEEE Symposium on. IEEE,39–57.
[33]TsongYChen,ShingCCheung,andShiuMingYiu.1998. Metamorphictesting:a
newapproach forgeneratingnexttestcases. TechnicalReport.TechnicalReport
HKUST-CS98-01, Department of Computer Science, Hong Kong University of
Science and Technology, Hong Kong.
[34] François Chollet et al. 2015. Keras. https://github.com/fchollet/keras. (2015).[35]
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
Usunier. 2017. Parseval networks: Improving robustness to adversarial examples.
InInternational Conference on Machine Learning. 854–863.
[36]California DMV. 2016. Autonomous Vehicle Disengagement Reports.https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/disengagement_
report_2016. (2016).
[37]Ivan Evtimov, Kevin Eykholt, Earlence Fernandes, Tadayoshi Kohno, Bo Li, Atul
Prakash,AmirRahmati,andDawnSong.2017. RobustPhysical-WorldAttacks
on Machine Learning Models. arXiv preprint arXiv:1707.08945 (2017).
[38]Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and Andrew B Gardner. 2017.
DetectingAdversarialSamplesfromArtifacts. arXivpreprintarXiv:1703.00410
(2017).
[39]Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning.
http://www.deeplearningbook.org Book in preparation for MIT Press.
[40]Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explainingand harnessing adversarial examples. In International Conference on Learning
Representations (ICLR).
[41]Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes, andPatrick McDaniel. 2017. On the (statistical) detection of adversarial examples.
arXiv preprint arXiv:1702.06280 (2017).
[42]Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and
Patrick D. McDaniel. 2017. Adversarial PerturbationsAgainst DeepNeural Net-
worksforMalwareClassification.In Proceedingsofthe2017EuropeanSymposium
on Research in Computer Security.
[43]Shixiang Gu and Luca Rigazio. 2015. Towards deep neural network architec-tures robust to adversarial examples. In International Conference on Learning
Representations (ICLR).
[44]Jan Hauke and Tomasz Kossowski. 2011. Comparison of values of Pearson’sand Spearman’s correlation coefficients on the same sets of data. Quaestiones
geographicae 30, 2 (2011), 87.
[45]SamerHijazi,RishiKumar,andChrisRowen.2015. Usingconvolutionalneural
networks for image recognition. Technical Report. Tech. Rep., 2015.[Online].
Available: http://ip. cadence. com/uploads/901/cnn-wp-pdf.
[46]Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, Jürgen Schmidhuber, et al .2001.
Gradientflowinrecurrentnets:thedifficultyoflearninglong-termdependencies.
(2001).
[47]SeppHochreiterandJürgenSchmidhuber.1997. Longshort-termmemory. Neural
computation 9, 8 (1997), 1735–1780.
[48]Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. 2017. Safety
verification of deep neural networks. In International Conference on Computer
Aided Verification. Springer, 3–29.
[49]L. C. Jain and L. R. Medsker. 1999. Recurrent Neural Networks: Design and Appli-
cations(1st ed.). CRC Press, Inc., Boca Raton, FL, USA.
[50]AndrejKarpathy.[n.d.]. Convolutionalneuralnetworks. http://cs231n.github.
io/convolutional-networks/. ([n. d.]).
[51]GuyKatz,ClarkBarrett,DavidL.Dill,KyleJulian,andMykelJ.Kochenderfer.2017.
Reluplex: An Efficient SMTSolverfor VerifyingDeep Neural Networks. Springer
International Publishing, Cham, 97–117.
[52]JernejKos,IanFischer,andDawnSong.2017.Adversarialexamplesforgenerative
models.arXiv preprint arXiv:1702.06832 (2017).
[53]AlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton.2012. Imagenetclassifica-
tion with deep convolutional neural networks. In Advances in neural information
processing systems. 1097–1105.
[54]Pavel Laskovet al .2014. Practical evasion ofa learning-based classifier:A case
study. In Security and Privacy (SP), 2014 IEEE Symposium on. IEEE, 197–211.
[55]Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Xiaodong Song. 2017. Delving
into TransferableAdversarialExamples andBlack-boxAttacks. In International
Conference on Learning Representations (ICLR).
[56]PhilMcMinn.2004.Search-basedsoftwaretestdatageneration:asurvey. Software
testing, Verification and reliability 14, 2 (2004), 105–156.
[57]Jan Hendrik Metzen, Tim Genewein, Volker Fischer, and Bastian Bischoff. 2017.
On detecting adversarial perturbations. In International Conference on Learning
Representations (ICLR).
[58]Thomas M. Mitchell. 1997. Machine Learning (1 ed.). McGraw-Hill, Inc., New
York, NY, USA.
[59]Takeru Miyato, Andrew M Dai, and Ian Goodfellow. 2016. Adversarial Training
MethodsforSemi-SupervisedTextClassification.In ProceedingsoftheInterna-
tional Conference on Learning Representations (ICLR).
[60]ChristianMurphy,GailEKaiser,LifengHu,andLeonWu.2008. Propertiesof
Machine Learning Applications for Use in Metamorphic Testing.. In SEKE, Vol. 8.
867–872.
[61]Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve re-
strictedboltzmannmachines. In Proceedingsofthe 27thinternationalconference
313
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Tian et al.
on machine learning (ICML-10). 807–814.
[62]Nina Narodytska and Shiva Prasad Kasiviswanathan. 2016. Simple black-box
adversarialperturbationsfordeepnetworks.In WorkshoponAdversarialTraining,
NIPS 2016.
[63]AnhNguyen,JasonYosinski,andJeffClune.2015.Deepneuralnetworksareeasily
fooled: High confidence predictions for unrecognizable images. In Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition. 427–436.
[64]Nicolas Papernot and Patrick McDaniel. 2017. Extending Defensive Distillation.
arXiv preprint arXiv:1705.05264 (2017).
[65]Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay
Celik, and Ananthram Swami. 2017. Practical black-box attacks against machine
learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and
Communications Security. ACM, 506–519.
[66]NicolasPapernot,PatrickMcDaniel,SomeshJha,MattFredrikson,ZBerkayCelik,
and Ananthram Swami. 2016. The limitations of deep learning in adversarial
settings. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P) .
IEEE, 372–387.
[67]Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang.2016. Crafting adversarial input sequences for recurrent neural networks. In
Military Communications Conference, MILCOM 2016-2016 IEEE. IEEE, 49–54.
[68]Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami.
2016. Distillationasadefensetoadversarialperturbationsagainstdeepneural
networks. In Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 582–597.
[69]CorinaSPăsăreanuandWillemVisser.2009. Asurveyofnewtrendsinsymbolic
execution for software testing and analysis. International Journal on Software
Tools for Technology Transfer (STTT) 11, 4 (2009), 339–353.
[70]Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. 2017. DeepXplore:
Automated Whitebox Testing of Deep Learning Systems. arXiv preprint
arXiv:1705.06640 (2017).
[71]LucaPulinaandArmandoTacchella.2010.Anabstraction-refinementapproachto
verificationofartificialneuralnetworks.In ComputerAidedVerification.Springer,
243–257.
[72]DavidERumelhart,GeoffreyEHinton,andRonaldJWilliams.1988. Learning
representations by back-propagating errors. Cognitive modeling 5, 3 (1988), 1.
[73]D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar
Ebner,VinayChaudhary,andMichaelYoung.2014. MachineLearning:TheHigh
Interest Credit Card of Technical Debt.
[74]Uri Shaham, Yutaro Yamada, and Sahand Negahban. 2015. Understanding adver-
sarial training: Increasing local stability of neural nets through robust optimiza-
tion.arXiv preprint arXiv:1511.05432 (2015).[75]Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, and Michael K Reiter. 2016.
Accessorizetoacrime:Realandstealthyattacksonstate-of-the-artfacerecog-
nition. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 1528–1540.
[76]Charles Spearman. 1904. The proof and measurement of association between
two things. The American journal of psychology 15, 1 (1904), 72–101.
[77]JacobSteinhardt,PangWeiKoh,andPercyLiang.2017. CertifiedDefensesfor
Data Poisoning Attacks. arXiv preprint arXiv:1706.03691 (2017).
[78]C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R.
Fergus.2014.Intriguingpropertiesofneuralnetworks.In InternationalConference
on Learning Representations (ICLR).
[79]Theano Development Team. 2016. Theano: A Python framework for fast compu-
tation of mathematical expressions. arXiv e-prints abs/1605.02688 (May 2016).
http://arxiv.org/abs/1605.02688
[80]GangWang,TianyiWang,HaitaoZheng,andBenYZhao.2014. Manvs.Machine:PracticalAdversarialDetectionofMaliciousCrowdsourcingWorkers..In USENIX
Security Symposium. 239–254.
[81]Michael J Wilber, Vitaly Shmatikov, and Serge Belongie. 2016. Can we still avoid
automatic face detection?. In Applications of Computer Vision (WACV), 2016 IEEE
Winter Conference on. IEEE, 1–9.
[82]IanHWitten,EibeFrank,MarkAHall,andChristopherJPal.2016. DataMining:
Practical machine learning tools and techniques. Morgan Kaufmann.
[83]Xiaoyuan Xie, Joshua Ho, Christian Murphy, Gail Kaiser, Baowen Xu, and
Tsong Yueh Chen. 2009. Application of metamorphic testing to supervised
classifiers. In Quality Software, 2009. QSIC’09. 9th International Conference on.
IEEE, 135–144.
[84]Weilin Xu, David Evans, and Yanjun Qi. 2017. Feature Squeezing: Detecting
Adversarial Examples in Deep Neural Networks. arXiv preprint arXiv:1704.01155
(2017).
[85]Weilin Xu, Yanjun Qi, and David Evans. 2016. Automatically evading classifiers.
InProceedings of the 2016 Network and Distributed Systems Symposium.
[86]StephanZheng,YangSong,ThomasLeung,andIanGoodfellow.2016. Improving
therobustnessofdeepneuralnetworksviastabilitytraining.In Proceedingsof
the IEEE Conference on Computer Vision and Pattern Recognition. 4480–4488.
[87]Zhi Quan Zhou, DH Huang, TH Tse, Zongyuan Yang, Haitao Huang, and TY
Chen.2004. Metamorphictestinganditsapplications.In Proceedingsofthe8th
International Symposium on Future Software Technology (ISFST 2004). 346–351.
314
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:52:13 UTC from IEEE Xplore.  Restrictions apply. 