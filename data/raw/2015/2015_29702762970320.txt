Generating Test Cases to Expose Concurrency Bugs in Android Applications Hongyin Tang, Guoquan Wu*, Jun Wei, Hua Zhong State key Laboratory of Computer Sciences Institute of Software, Chinese Academy of Sciences, China {tanghongyin14, gqwu,wj, zhongh}@otcaix.iscas.ac.cn ABSTRACT Mobile systems usually support an event-based model of concurrent programming.  This model, although advantageous to maintain responsive user interfaces, may lead to subtle concurrency errors due to unforeseen threads interleaving coupled with non-deterministic reordering of asynchronous events. These bugs are very difficult to reproduce even by the same user action sequences that trigger them, due to the undetermined schedules of underlying events and threads. In this paper, we proposed RacerDroid, a novel technique that aims to expose concurrency bugs in android applications by actively controlling event schedule and thread interleaving, given the test cases that have potential data races. By exploring the state model of the application constructed dynamically, our technique starts first to generate a test case that has potential data races based on the results obtained from existing static or dynamic race detection technique. Then it reschedules test cases execution by actively controlling event dispatching and thread interleaving to determine whether such potential races really lead to thrown exceptions or assertion violations. Our preliminary experiments show that RacerDroid is effective, and it confirms real data races, while at the same time eliminates false warnings for Android apps found in the wild. Categories and Subject Descriptors D.2.5 [Software Engineering]: Testing and Debugging Keywords record/replay; data race; mobile application; android; testing. 1. INTRODUCTION Android devices currently lead the smartphone marketplace. As of May 2015, there are more than 1.5 million android apps available from Google Play Store. The widespread use of these devices poses great demands on the quality of the apps. However, as both android platforms and the accumulated developers are still immature compared to old areas of computing (e.g., desktop and server software), meeting these demands is still very challenging. A primary feature of mobile applications is their event-driven nature: the application must handle asynchronously generated events from a diverse set of sources including user interface, sensors, network and the framework, to maintain responsive user interfaces. Unfortunately, this asynchrony can cause harmful bugs due to data races that will potentially corrupt the overall application behavior or change the intended semantics of the application. Such concurrency bugs are often difficult to find and debug as they can only be manifested under very specific events scheduling and threads interleaving. To detect such harmful behaviors, researchers have recently devised program analyses aiming to automatically discover concurrency errors due to data races. For instance, CAFA [7] identifies user-after-free violations (a typical of kind of concurrency bug) based on the proposed causality model to infer happen-before relations between events. EventRacer for Android [9] (for brevity, we will refer it as “EventRacer” since the scope of this paper is Android apps) proposes a scalable race detection algorithm for android applications, which finds data races based on a precise happen-before model of android concurrency. DEvA [10] is static analysis technique to detect event anomaly (two or more events access the same memory location and at least one is write access) in event-based system. Asynchronizer [11], a refactoring tool that aims to extract long-running operations into AsyncTask, also provides a static race detector, which can identify the potential data races existed in AsyncTask. Despite recent advances, these techniques still often report many data races that are false warnings. For example, EventRacer [9], reports 21 data races for Flick-Uploader app, out of which only 2 are harmful. Moreover, being imprecise in nature, most of these tools require manual inspection to see if a race is real or not, which is difficult and time-consuming, especially for inexperienced developers. Nevertheless, these tools are very effective in finding data races because they can predict data races that could potentially happen during a real execution in case of static race detection, or they just need to see one real concurrent execution in case of dynamic race detection. In this paper, leveraging potential data races reported by existing static/dynamic race detection technique, we proposed RacerDroid, a new technique to assist developers to verify whether reported data races can really lead to concurrency errors by generating a test case and rescheduling test case execution under specific interleaving of the threads or the reordering of asynchronous events. Specifically, RacerDroid designs a lightweight scheduler by adapting existing Android testing framework, to actively control event schedule and thread interleaving to expose real race condition with high probability and confirm the concurrency bug by determining whether the detected races could cause a thrown exception or assertion violation. The technique works as follows: RacerDroid first uses an existing static or dynamic race detection technique, to compute a set of statement pairs that could potentially race in a concurrent execution. Then based on the constructed state model of the app, RacerDroid generates a test case automatically, which will 
* Corresponding Author 
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ASE’16 , September 3–7, 2016, Singapore, Singapore
c2016 ACM. 978-1-4503-3845-5/16/09...$15.00
http://dx.doi.org/10.1145/2970276.2970320
648
execute the statement pair that has potential data race. RacerDroid will replay the test case with a different schedule by interleaving threads or reordering events based on the proposed lightweight reschedule technique. Such alternative schedule can help RacerDroid to find whether a thrown exception or assertion violation can occur due to data race.  Generally, RacerDroid has the following useful features: l It exploits the results reported by existing static/dynamic race detection technique to generate a test case automatically that will contain potential data race based on the state model of the app constructed dynamically. l It designs a lightweight rescheduling technique which can actively control test case execution by adapting existing android testing framework. l Leveraging test oracles contained in the test cases, it can expose some semantic race errors, which will not crash the app but only violate the semantics of the application. 2. BACKGROUND ON ANDROID Android application organizes its logic into activities, each representing a single screen of UI. An activity contains widgets that users can interact with, which can be buttons, text boxes and number pickers, etc.  Similar to many typical GUI frameworks such as Swing and SWT, android applications are largely event-driven. Events in android include user actions, lifecycle events, sensor events, etc. For each kind of events, the framework provides corresponding callbacks and developers can implement their own callback to respond to these events. For example, onCreate() callback is invoked when an activity is created, onClick() callback of a button is executed when a button is clicked, and onLocationChanged() callback will be triggered when physical location changes. Android framework orchestrates app control flow by invoking user-provided callback in response to various user and system events. It uses a single thread model to process events by default. When an application is launched, the system will create a main thread (also called UI thread), which is charge of dispatching UI events to appropriate widgets or lifecycle events to activities.  However, if main thread executes CPU-intensive work or blocking I/O calls such as network access or database queries, the application will be blocked until the corresponding operation has finished. To avoid unresponsiveness and provide a good user experience, all potentially slow running operations in an Android application should run asynchronously. Android also supports multi-threads. In android, each thread may be associated with an event queue by attaching Looper object (which has a MessageQueue). Threads can communicate by posting events to each other’s event queues, and a thread can also post an event to its own queue. For each thread with a queue, it runs in a loop processing events from its event queue in the order of their arrival. When the queue is empty, the thread will block. Event handling is atomic, and no other message processing routine can be started until current one completes. Threads can also communicate with each other via shared memory, which is the same as in traditional Java programming. In android’s concurrency model, each application process has a main thread, and only the main thread can access GUI objects, to prevent nonresponsive threads from blocking UI. To update UI, non-main threads can send messages to UI thread. The main thread will attach a Looper object automatically when the app launches. We refer to any thread that has an attached Looper as looper thread. In addition to looper thread, android also supports two other kinds of threads: binder thread and background thread. The former is created as thread pools and mainly used for inter-process, while the latter are the result of a regular thread fork(). To ease the use of concurrency, Android provides additional constructs, such as Handler and AsyncTask class, to perform asynchronous processing. Handler class can be used to register to a thread and provides a simple channel to dispatch event to the main thread. AsyncTask is a high-level abstraction for encapsulating the creation of a background thread and the synchronization with the main thread. It also provides some callbacks, such as onPostExecute(), that will execute on the main thread when the task has finished.  3. APPROACH OVERVIEW The goal of our approach is to verify concurrency bugs from the potential data races identified by existing static or dynamic analysis technique, such as EventRacer [9], or DEvA [10]. We also assume these potential races are reported with the format <SharedVar, ACT1, task1, statement1, ACT2, task2, statement2>, which means that execution sequence of task1 in ACT1 and task2 in ACT2 is non-deterministic, both statement1 executed in task1 and statement2 executed in task2 have accessed shared variable SharedVar, and at least one is write access. Here, task1/task2 can be the callback function for asynchronous events, or the running method for the background thread. For the former, ACT1/ACT2 can be the components (e.g., activity, service) in android applications, and they usually refer to the same one if ACT1 and ACT2 are both activity. For the latter, ACT1/ACT2 is android component that creates the background thread. Statements statement1 and statement2 are also called as statement pair in the following. Fig.1 shows the overall process of our approach. Generally, it consists of two steps: test case generation and test case replay. The aim of first step is to generate a test case that contains potential data race, and the second step tries to confirm whether the data race can lead to thrown exception or assertion violation (hence, it is a concurrency bug) by rescheduling underlying events and threads during the test case replay. In the following, we elaborate these two steps. 
       Fig.1  Overall Framework of RacerDroid 3.1 Test cases generation GUI Exploration. Based on reported potential data races, RacerDroid first tries to find a path (user action sequence) that can trigger the execution of statement1 and statement2 leveraging the state space model of the app. One can construct this model based on dynamic analysis (such as the work [13][14]), or static analysis (such as the work [15][16]). RacerDroid chooses to build this model dynamically. Currently, we are developing a crawling tool, which aims to explore the application and construct the state space model of the app.  App.explorerpotential  data racesrescheduleassertion  violation/  exceptionInstrumentationinstrumented  app
test case
649Different from existing exploration techniques for android applications, we leverage existing test cases of the app to first construct the partial model of the app (which contains useful user input and test assertion information). Based on this partial model, crawler then continues to explore the remaining states of the app, which is similar to the work [12] done for the web application. Note that, besides the activity, the model will also contain information such as when service component is created (e.g., after user clicks ‘OK’ button). To support this, RacerDroid will instrument start/stop method of service component to notify the crawler when the service is started/stopped. The model also contains lots of useful information (e.g., each state contains the widgets available in current screen) that can direct test case generation. Furthermore, in the model, states (activities) may have some test oracles obtained from existing test cases, which can be used to detect whether the potential data race can leads to some semantic errors (that will not result in thrown exception, but change the intended semantics of the app). Test Case Generation. RacerDroid then generates a test case that executes statement1 and statement2 by dynamically exploring the application based on the constructed state space model. Before exploration, RacerDroid will instrument statement statement1 and statement2 firstly. When both statement1 and statement2 are executed, exploration will stop. For the race reported by the dynamic race detector, it is possible that statement1/statement2 is accessed in the framework (e.g., EventRacer [9] reports some such races). In this case, RacerDroid will instrument the statement located in the user code that invokes statement1 /statement2 by analyzing its call context if the report provides such information. Otherwise, RacerDroid will seek to determine whether the corresponding task is executed. To do this, RacerDroid will also instrument the callback of task1 and task2. Another function of instrumenting the callback is that RacerDroid needs to log the execution sequence of two tasks in this step, which will be alternated during the test case replay. Note that, RacerDroid avoids instrumenting the statement located in the framework, as we aim to make our technique easily run on any android devices. To find such user action sequence quickly, RaceDroid first computes a path from Main activity to target activity (which is or contains ACT1/ACT2) by querying the state model of the app. It then fires the actions along the path to arrive the state ACT1 and ACT2. After that, crawler systematically explores the widgets in current active activity, and fires various user actions on the widget to trigger statements that have potential data races.  During exploration, if one statement or both of them are triggered after firing a user action, RacerDroid will check whether test oracle (assertion) is violated in current state if it exists. It is possible that assertion is violated as the content of corresponding widget (specified in the assertion) changes (e.g., server updates the content frequently). In the case of violation, RacerDroid will update the assertion with new value obtained from the corresponding widget, which will then be added into the generated test cases. Explorer will also take a screenshot for current active activity, which can be compared with the corresponding one taken during the test case replay to assist developers to locate inconsistency between two activities quickly. After exploration completes, based on fired user actions, crawler will generate test cases expressed in Android Espresso [25] or Robotium [24] testing scripts automatically, which will be replayed in step 2. When explorer reaches the target activity, besides triggering the user action bound to the widget, it will also fire some actions that Android system provides to trigger some lifecycle events. For example, it can send ‘Back’ or ‘Rotate’ action to trigger pause/stop/destroy event, and send ‘lock, wakeup and swipe the screen to return to the app’ to trigger restart event (which also trigger pause/stop). For the lifecycle events create/pause/resume, they will be sequentially triggered when the explorer enters into the target activity. It is possible that existing static race detection technique will report some races if the callbacks of two different user actions both access the shared variable, RacerDroid does not consider it as a concurrency bug as the input (user action sequence) needs to change to generate the expected execution. For the same reason, RacerDroid also does not generate test case for the reported race, in which two tasks are both lifecycle events (e.g., onpause (), onresume()) of the same activity.  API Interception. During test case generation, the application may interact with the server, communicate with other app using intent, and invoke sensor services and random function. To assure input determinism during the test case replay and avoid false (assertion) violations, RacerDroid also instruments the app by intercepting various APIs of sensor services, network, intent and random function to cache the sensor data, network request/response, intent result and random number. These data will be directly sent back to the app when the test case is replayed.  3.2 Test Case Replay In this step, the test case generated from step 1 will be replayed with alternative schedule to expose concurrency bug and eliminate some false warning at the same time. RacerDroid leverages existing Android Testing Framework (e.g., Robotium [17], Espresso [18]) to execute test cases. To control event schedule and thread interleaving during test cases replay, RacerDroid modifies the testing framework to access the message queue of app’s UI thread. Therefore, it can monitor and control the event dispatching process (e.g., postpone one event until another event has been handled). To control the execution of background thread, RacerDriod instruments app by inserting synchronization primitives at the position where synchronization needs to be done. In the following, we describe how RacerDroid controls event schedule and thread interleaving to expose concurrency bugs.  1) If statement1 and statement2 are both invoked in the callback of task1 and task2 with the sequence <task1, task2> in the phase of test case generation, Racerdroid will alternate their execution by suspending task1 if it occurs before task2. After task2 is dispatched, RacerDroid will continue to dispatch task1 and the following events in the queue. Note that, it is possible that if task1 is not dispatched, task2  will not appear in the queue (which means task2 is registered during the execution of task1). In this case, task1 and task2 will have deterministic execution in this test case. However, it only means that statement1 and statement2 have no data race in the test case under consideration. To further verify this potential data race, RaceDroid can go back to step 1 and find another different user action sequence that callback task1 and task2 are invoked. If such path can be found, RacerDroid will go to step 2 to replay the new test case to try to expose the bug. If all the test cases found by RacerDroid cannot produce the alternate event schedule, RacerDroid concludes that this potential data races is a likely false positive. RaceDroid cannot provide a definitive verdict on whether the race is a false positive or not because there might exist some other execution in which the purported false positive proves to be a real race. 2) If statement1 is invoked from background thread and statement2 is invoked from event’s callback (vice versa), RacerDroid will instrument app by first inserting synchronization primitives for 
650statement1. During the replay, RacerDroid can alternate their execution by controlling event dispatching and thread execution. It’s also possible that background thread is started in the callback of statement2. In this case, reschedule will fail. However, as the background thread can interleave with the callback execution in android, RacerDroid can insert synchronization primitives for the statement2 in the callback of task2 to confirm whether it is really a concurrency bug. 3) If statement1 and statement2 are both invoked through background thread, RacerDroid just needs to instrument app to add synchronization primitives for two statements, and alternates the execution of two background threads during the replay to expose a concurrency bug. During the replay, if app crashes or a thrown exception is caught, a race bug can be verified. However, some race bugs will only change the intended semantics of the application. For example, in work [9], the authors conclude one such kind of data race caused by object reuse. To confirm these bugs, RacerDroid relies on the assertion existed in the test case, and if assertion is violated, a harmful race bug is detected. If no assertion exists, RacerDroid will compare two screenshots of the same activity captured during test case generation and test case replay by using image difference algorithm, such as Perceptual Image Differencing (PID) [27], a computer vision technique, to find visual difference. If no difference is found, RacerDroid can determine that the reported data race is harmless. Otherwise, it will provide the corresponding screenshots to developer and let the developer decide whether the race bug is harmful or not. 4. IMPLEMENTATION RacerDroid needs a model of the app to generate a test case that contains the potential data race. Currently, we are developing a crawling tool that aims to explore the app systematically to construct its state space model leveraging existing test cases. To facilitate developers to write test cases, we also developed an app based on accessibility API [26] that Android provides, which can record user actions when user interacts target application through this app. It also provides the function that allows user to insert assertion (e.g., text assertion) during the interaction with the app. To simulate ‘Back’/‘Rotate’/‘Lock, Wakeup and Swipe screen’ actions during the test case generation, RacerDroid relies on UIAutomator [28] to send corresponding commands, which will trigger stop/destroy/restart lifecycle events. To control event schedule, currently RacerDroid modifies the Android Espresso testing framework [18] to control event dispatching for the events placed in the queue. When the test case is running, espresso gets the event queue of the main thread using the java Reflect mechanism and then dispatch the events to their target handlers so that the events would not pass the loop() method of Looper object defined in the android framework. In this way, RacerDroid can postpone the dispatching of the event that it is interested in, and then resume the execution of this event after another event (in the reported race) has been handled. To control the thread interleaving in the app, RacerDroid uses semaphores to synchronize the execution between different threads (including UI thread and background thread).  Instrumentation also plays an important role in RacerDroid. It needs to instruments app to obtain the casual relation between the activities with the underlying services during the construction of the state model of the app. During the test case generation, app needs to be instrumented to capture various sensor inputs and network activity, which will be sent back during the test case replay. In addition, the semaphore that is used to schedule the threads interleaving also needs to be inserted. To implement the instrumentation, RaceDroid first disassembles dalvik bytecode to smali [19] code and then inserts the instrumentation code. At last, assemble the smali code back to the dalvik code and repackage it to the APK. RacerDroid will then run the instrumented app installed on the devices, and perform steps described in Section 3 to expose concurrency bugs.  5. CASE STUDIES As an instructive case study, we investigate a race bug in the MyTracks app, which is an application used to track the location of the user. This race bug is reported in work [7]. The example in Fig.2 shows the segment codes that are related to this race. In the activity MyTracks, when user presses the button to start a track recording, startRecording() callback will be invoked, which starts and binds TrackRecordingService service. As soon as the service is ready, an event would be sent to the queue of UI thread and onServiceConnected() callback will be executed when this event is dispatched, which calls startNewTrack() of TrackRecordingService through IPC mechanism. When user stops recording, stopRecording() callback will be invoked which stops and unbinds TrackRecordingService. This procedure will invoke onDestroy() asynchronously that set the “providerUtils” to null. In normal execution, onDestroy() will be invoked after startNewTrack(). However, there exists a situation that is contrary to the normal execution. Due to TrackRecordingService is started and stopped asynchronously, startNewTrack() may still not be executed while onDestroy() is performed, and an exception is thrown when startNewTrack() is invoked. This data race is expressed as <providerUtils, MyTracks, onServiceConnected(), “providerUtils.updateTrack(track)”, TrackRecordingService, onDestroy(), “providerUtils = null”> in RacerDroid. Here, onConnectedService() and onDestroy() are two asynchronous tasks located in MyTracks activity and TrackRecordingService service, respectively. When onConnectedService() is scheduled, it will execute statement “providerUtils.updateTrack(track)” and when onDestroy() callback of TrackRecordingService is scheduled, statement “providerUtils = null” will be executed. Obviously, a null pointer exception will be thrown if onDestroy() is executed before onConnectedService().  
       Fig.2  Code Segment of MyTracks 
651       Table 1.  Results of Case Study Subjects Components # of potential data races TP FP  TP (manual) FP (manual) ToDoWidget ColorCirle 1 0 1 0 1  ConnectBot HostEditorActivity 5 2 3 2 3 HostListActivity 4 2 2 2 2 PubkeyListActivity 4 0 4 0 4 TerminalManager 2 2 0 2 0 AnyMemo DownloaderAnyMemo 1 1 0 1 0 MyTack MyTracks/TrackRecordingService 1 1 0 1 0 OI File Manager FileListManager 1 1 0 1 0 As our test case generation tool is still developing, in order to confirm this potential data race, we first generate a test case manually that will trigger these two callbacks. Fig.3 shows the corresponding test case. It first presses menu button to show the options menu on the screen and starts recording by pressing the record button. Then the test case calls the options menu again and presses the button to stop recording. At last, it saves the recording. When this test case is executed without controlling schedule, onServiceConnected() will be invoked before onDestroy() with high probability. Therefore, no exception will be thrown. During the test case replay, when onServiceConnected() is monitored to be scheduled, RacerDroid will suspend its dispatch by removing it from the queue. After onDestroy() callback of service TrackRecordingService  is scheduled, RacerDroid will then resume the execution of onServiceConnected() task. In this way, this concurrency bug is guaranteed to produce.                                    Fig.3. Test case of MyTrack We also perform RacerDroid on several other open source applications to evaluate the feasibility of the technique. We select some race bugs reported from the existing works [9][10]. Then we generate a test case for each potential data race and run them by our scheduler. The result is shown in Table 1 (more details can be found in http://midori1.github.io/RacerDroid/). For each application, the table shows the number of potential data races that we selected. It also shows the components where these races are located. Each test case contains 2-4 user actions. TP shows number of harmful races that are confirmed by RacerDroid. FP shows the number of likely FP that cannot be confirmed by RacerDroid. We also manually check these potential races. The last two columns TP(manual) /FP(manual) show the number of real bugs/false warnings by manual analysis, respectively. As result shows, all the real races reported by RacerDroid are also confirmed by manual analysis, and the likely false warnings reported by RacerDroid are also true. Based on these initial case studies, we can conclude that RacerDroid is feasible and can assist developers to verify potential data races automatically. 6. RELATED WORK Numerous techniques and tools have been developed to support software testing and race detection of mobile apps, and we here discuss the most closely related work.  6.1 Data race detection and testing Many studies have been done in the literature to detect data races, either statically [3][4] or dynamically [5][6]. However, these techniques are mostly designed for thread-based programs, and usually work poorly for event-based programs.  Recently, some works start looking at race detection techniques for event-based programs, especially web applications and mobile applications. WebRacer [2] and EventRacer for Web App [1] are two recent studies focusing on detecting races in web applications.  A web application is typically executed in a single thread by the browser in an event-driven style. These works have shown that even if there is only one thread executing, races are still possible. To detect such type of races, happen-before relation (causality) for web application is redefined and lots of data races are found in many popular web sites. Targeting mobile applications, CAFA [7] focuses on detecting race errors that lead to user-after-free violation based on the casual order due to the event sequences. DroidRacer [8] is also a dynamic analysis technique for race detection in Android application based on a formal semantic model for Android concurrency. EventRacer [9] is a scalable race detection technique for android application, which proposed a fast algorithm to build and query happen-before graph. It also reports fewer false positives by using some domain-specific filters. DEvA [10] is a static analysis race detector for automatically detecting event anomalies in event-based systems (including mobile applications), which can handle the semantics of implicit invocation, ambiguous interface and implicit concurrency. Asynchronizer [11] is an automated refactoring tool which assists developers to extract long-running tasks into asynchronous task. It also provides a race detector specialized for AsyncTask, which can detect the potential data races in AsyncTask after refactoring. Recently, a couple of random testing techniques [21][22][23] for concurrent programs have been proposed, which systematic explores the alternate schedules of threads. One limitation of applying such technique to android applications is that test cases may contain lots of alternate schedules, and most of them have no data races. Exploring these schedules blindly will consume a lot of test resources. Our work is inspired by the RACEFUZZER [20], which aims to multi-thread applications, and use potential data race information obtained from existing dynamic analysis technique to control a random scheduler of threads, which can create real race condition with high probability. 6.2 GUI Model for Android RacerDroid depends on a state space model to generate a test case automatically. There are some related works that aim to explore the app systematically. A3E [13] is an automated GUI exploration tool for android applications, which can explore the app running on the actual devices. Specifically, it proposes a targeted exploration strategy, which supports fast, direct exploration activities based on a statically constructed high-level control flow graph. Swifthand [14] uses machining learning to learn a model of the app, uses the learned model to generate user actions that visit unexplored states of the app, and uses the execution of app to refine the model. A key feature of Swifthand is that it can avoid restarting the app.  
652The state model can also be built statically. For example, Yang et.al [15] build a GUI model of the android applications using context-sensitive static analysis of callback methods. In [16], they further proposed static window transition graph, a comprehensive model, which represents the possible GUI window sequence and their associated events and callbacks. 6.3 Record/Replay android application Our work is also related to record/replay technique [24][25] proposed for android application. RERAN [24] supports to record/replay sophisticated GUI gestures without requiring to access to app source code. VALERA [25] captures network activity, inter-app communication, sensor inputs by API interception, and event schedule by modifying Android framework to achieve high-accuracy replay. RacerDroid also uses API interception to capture network activity and various sensor inputs. The difference is that RacerDroid does not need to modify android framework, and it can reschedule the execution of user action sequence (test case) by just adapting existing android testing framework. 7. CONCLUSION AND FUTURE WORK In this paper we introduced a new technique for generating test cases to verify concurrency bugs reported in android applications re. In our initial case studies, the approach exposes 100% of the concurrency bugs from the given potential data races reported by existing static/dynamic race detector. Overall, these preliminary results are promising and indicate the feasibility our approach in being able to assist developers to automatically confirm the concurrency bugs. In the future work, we will first complete the implementation of our test case generation tool. We will also conduct more comprehensive studies to evaluate the effectiveness and efficiency of our approach.  8. ACKNOWLEDGEMENT This work is supported by National Natural Science Foundation of China under Grant No. 61472407, National Basic Research Program (973) of China under Grant No. 2015CB352201, and National Key Technology R&D Program under Grant No. 2015BAF05B01.  9. REFERENCES [1] V. Raychev, M. T. Vechev, and M. Sridharan. Effective race detection for event-driven programs. In OOPSLA, pages 151–166, 2013.  [2] B. Petrov, M. Vechev, M. Sridharan, and J. Dolby. Race detection for web applications. In PLDI ’12, pp.251-262.  [3] D. R. Engler and K. Ashcraft. RacerX: Effective, Static Detection of Race Conditions and Deadlocks. In SOSP, pages 237–252, 2003.  [4] J. W. Voung, R. Jhala, and S. Lerner. RELAY: Static Race Detection on Millions of Lines of Code. In ESEC/SIGSOFT FSE, pages 205–214, 2007.  [5] C. Flanagan and S. N. Freund. FastTrack: Efficient and Precise Dy- namic Race Detection. In PLDI, pages 121–133, 2009.  [6] R. H. B. Netzer. Optimal Tracing and Replay for Debugging Shared- Memory Parallel Programs. In Workshop on Parallel and Distributed Debugging, pages 1–11, 1993.  [7] C.-H. Hsiao, J. Yu, S. Narayanasamy, Z. Kong, C. L. Pereira, G. A. Pokam, P. M. Chen, and J. Flinn. Race detection for event-driven mobile applications. In PLDI ’14, pp.326-336. [8] P. Maiya, A. Kanade, and R. Majumdar. Race detection for android applications. In PLDI ’14, pp.316-325. [9] P. Bielik, V. Raychev, and M. T. Vechev. Scalable race detection for android applications. In OOPSLA, pages 332–348. ACM, 2015.   [10] G. Safi, A. Shahbazian, W.G. J. Halfond, and N. Medvidovic. Detecting event anomalies in event-based systems. In FSE 2015, pp.25-37. [11] Yu Lin, Cosmin Radoi, and Danny Dig. Retrofitting concurrency for Android applications through refactoring. In FSE 2014, pp.341-252. [12] A. M. Fard, M. Mirzaaghaei, and A. Mesbah. Leveraging existing tests in automated test generation for web applications. In ASE 2014, pages 67–78.   [13] W. Choi, G. Necula, and K. Sen. Guided gui testing of an- droid apps with minimal restart and approximate learning. In OOPSLA ’13, pp.623-640. [14] Tanzirul Azim and Iulian Neamtiu. Targeted and depth-first exploration for systematic testing of android apps. In OOPSLA ’13, pp.641-660. [15] Shengqian Yang, Dacong Yan, Haowei Wu, Yan Wang, and Atanas Rountev. Static control-flow analysis of user-driven callbacks in Android applications. In ICSE '15, pp.89-99. [16] Shengqian Yang, Hailong Zhang, Haowei Wu, et. al. Static Window Transition Graphs for Android. In ASE’15, pp.658-668. [17] Robtotium. Github. https://github.com/RobotiumTech /robotium [18] Espresso. https://google.github.io/android-testing-support-library/docs/espresso/ [19] Smali. Github. https://github.com/JesusFreke/smali [20] Koushik Sen. 2008. Race directed random testing of concurrent programs. In PLDI '08, pp.11-21. [21] O. Edelstein, E. Farchi, Y. Nir, G. Ratsaby, , and S. Ur. Multithreaded Java program test generation. IBM Systems Journal, 41(1): 111–125, 2002   [22] S. D. Stoller. Testing concurrent Java programs using randomized scheduling. In Workshop on Runtime Verification (RV’ 02), volume 70 of ENTCS, 2002   [23] K. Sen. Effective random testing of concurrent programs. In ASE’ 07, pp. 323-332. [24] Lorenzo Gomez, Iulian Neamtiu, Tanzirul Azim, and Todd Millstein. RERAN: timing- and touch-sensitive record and replay for Android. In ICSE '13, pp.72-81. [25] Hu, Yongjian, Tanzirul Azim, and Iulian Neamtiu. "Versatile yet lightweight record-and-replay for Android." In  OOPSLA’15, pp.349-366. [26] Android Accessibility. http://developer.android.com/guide/ topics/ui/accessibility/index.html [27] H. Yee, S. Pattanaik, and D. P. Greenberg. Spatiotemporal Sensitivity and Visual Attention for Efficient Rendering of Dynamic Environments. ACM Trans. Graph., 20(1), Jan. 2001.  [28] UI Automator. http://developer.android.com/tools/testing-support-library/index.html#UIAutomator. 
653