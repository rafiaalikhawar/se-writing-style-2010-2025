A Novel Neural Source Code Representation ased
on Abstract Syntax Tree
Jian Zhang†‡,X uW a n g†‡∗, Hongyu Zhang§, Hailong Sun†‡, Kaixuan Wang†‡and Xudong Liu†‡
†SKLSDE Lab, School of Computer Science and Engineering, Beihang University, Beijing, China
‡Beijing Advanced Innovation Center for Big Data and Brain Computing, Beijing, China
§The University of Newcastle, Australia
{zhangj, wangxu}@act.buaa.edu.cn, hongyu.zhang@newcastle.edu.au, {sunhl, wangkx, liuxd}@act.buaa.edu.cn
Abstract —Exploiting machine learning techniques for analyz-
ing programs has attracted much attention. One key problem
is how to represent code fragments well for follow-up analysis.Traditional information retrieval based methods often treatprograms as natural language texts, which could miss importantsemantic information of source code. Recently, state-of-the-artstudies demonstrate that abstract syntax tree (AST) based neuralmodels can better represent source code. However, the sizes ofASTs are usually large and the existing models are prone tothe long-term dependency problem. In this paper, we proposea novel AST-based Neural Network (ASTNN) for source coderepresentation. Unlike existing models that work on entire ASTs,ASTNN splits each large AST into a sequence of small statementtrees, and encodes the statement trees to vectors by capturingthe lexical and syntactical knowledge of statements. Based on thesequence of statement vectors, a bidirectional RNN model is usedto leverage the naturalness of statements and ﬁnally produce thevector representation of a code fragment. We have applied ourneural network based source code representation method to twocommon program comprehension tasks: source code classiﬁcationand code clone detection. Experimental results on the two tasksindicate that our model is superior to state-of-the-art approaches.
Keywords-Abstract Syntax Tree; source code representation;
neural network; code classiﬁcation; code clone detection
I. I NTRODUCTION
Many software engineering methods, such as source code
classiﬁcation [1], [2], code clone detection [3], [4], [5], [6],
defect prediction [7], [8] and code summarization [9], [10]have been proposed to improve software development andmaintenance. One main challenge that is common across allthese methods is how to represent source code, in orderto effectively capture syntactical and semantic informationembedded in the source code.
Traditional approaches such as Information Retrieval (IR)
usually treat code fragments as natural language texts andmodel them based on tokens. For example, programs arerepresented by token sequences or bag of tokens for code clonedetection [3], [4], bug localization[11], and code authorshipclassiﬁcation [1]. In addition, a number of researchers useLatent Semantic Indexing (LSI) [12] and Latent DirichletAllocation (LDA) [13] to analyze source code [14], [15], [16].However, according to [17], the common problem of theseapproaches is that they assume the underlying corpus (i.e.,
∗Corresponding author: Xu Wang, wangxu@act.buaa.edu.cn.the source code) is composed of natural language texts. Eventhough code fragments have something in common with plaintexts, they should not be simply dealt with text-based or token-based methods due to their richer and more explicit structuralinformation [2], [18].
Recent work [2], [5], [6] provides the strong evidence that
syntactic knowledge contributes more in modeling source codeand can obtain better representation than traditional token-based methods. These approaches combine Abstract SyntaxTree (AST) and Recursive Neural Network (RvNN) [5], Tree-based CNN [2] or Tree-LSTM [6] to capture both the lexical(i.e., the leaf nodes of ASTs such as identiﬁers) and syntactical(i.e., the non-leaf nodes of ASTs like the grammar constructWhileStatement ) information. Such AST-based neural models
are effective, yet they have two major limitations. First, similarto long texts in NLP, these tree-based neural models arealso vulnerable to the gradient vanishing problem that thegradient becomes vanishingly small during training, especiallywhen the tree is very large and deep [19], [20], [21]. Forexample, as our experiments show (Section V), the maximalnode number/depth of ASTs of common code fragments inC and Java are 7,027/76 and 15,217/192, respectively. Asa result, traversing and encoding entire ASTs in a bottom-up way [5], [6] or using the sliding window technique [2]may lose long-term context information [19], [22]; Second,these approaches either transform ASTs to or directly viewASTs as full binary trees for simpliﬁcation and efﬁciency,which destroys the original syntactic structure of source codeand even make ASTs much deeper. The transformed anddeeper ASTs further weaken the capability of neural modelsto capture more real and complex semantics [23].
In order to overcome the limitations of the above AST-
based neural networks, one solution is to introduce explicit(long-term) control ﬂow and data dependencies graphs andemploy a Graph Embedding technique [24] to represent sourcecode. For instance, one recent study considers the long-range dependencies induced by the same variable or functionin distant locations [25]. Another study directly constructscontrol ﬂow graphs (CFGs) of code fragments [26]. However,as depicted in the above work, precise and inter-proceduralprogram dependency graphs (PDGs) (i.e. control ﬂow and dataﬂow dependencies) [27] usually rely on compiled intermediaterepresentations or bytecodes [28], [29], and are not applicableB
7832019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ©2019 IEEE
DOI 10.1109/ICSE.2019.00086
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. 1. 
2. 
3. 
4. 
7. 5. 
6. 
8. 
9. 
10. 
11. 
12. 
15. 13. 
14. 
16. 
17. static public String readText( final String path) 
throws IOException { 
        final InputStream stream  
   = FileLocator.getAsStream( path); 
        final StringBuilder sb  
   = new StringBuilder(); 
        try (BufferedReader reader =  
   new BufferedReader(  
   new InputStreamReader( stream))){ 
           String line; 
           while ((line=reader.readLine())!= null)
           { 
              sb.append(line).append( "\n"); 
           } 
        } 
        return sb.toString();     
       }  
(a) Code fragment and statementsMethod
DeclarationModifier
…
bodypublic
static
LocalVariable
throws
LocalVariable
TryStatement
ReturnStatementType
...
Type
...
TryResource
block LocalVariable
WhileStatement...
...InputStream
StringBuilderreadText
(b) AST and statement treesMethodDeclaration 
LocalVariable 
LocalVariable 
TryStatement … 
LocalVariable … 
… 
… 
… 
ReturnStatement … WhileStatement … 
… 
(c) Statement naturalness
Fig. 1. An example of AST Statement nodes (marked in red)
to uncompilable and incomplete code fragments. Such a lim-
itation hinders the applications of the code representations in
many areas that involve arbitrary code fragments.
In this paper, we propose a novel approach for representing
code fragments that do not have to be compilable, called
AST-based Neural Network (ASTNN), which splits the large
AST of one code fragment into a set of small trees at
the statement level and performs tree-based neural embed-
dings on all statement trees. It produces statement vectors
which can represent the lexical and statement-level syntactical
knowledge. Here statements refer to the Statement AST
nodes deﬁned in program language speciﬁcation [30]. We
also treat MethodDeclaration as a special statement node. As
an example, Figure 1 shows a code fragment from an open
source project1. The code snippet between line 7 and line
15 contains a whole Try statement and the code snippet
between line 5 and line 6 includes only the LocalVariable
statement initializing variable sb. For each statement like the
Try statement that includes the header and other statements in
the body, we split the header of the statement and all included
statements. In this way, the large AST is decomposed to a
short sequence of small statement trees. We use Recurrent
Neural Network (RNN) [31] to encode statements and the
sequential dependency between the statements into a vector.
Such a vector captures the naturalness of source code [32],
[33] and can serve as a neural source code representation.
More speciﬁcally, ﬁrst, we build an AST from the code
fragment and split the whole AST to small statement trees (one
tree consisting of AST nodes of one statement and rooted at the
Statement node). For example, in Figure 1, the statement trees
are denoted by dashed lines and the corresponding statements
(or statement headers) in the original code fragment are also
marked by dashed lines. Second, we design a recursive encoder
on multi-way statement trees to capture the statement-level
lexical and syntactical information and then represent them in
statement vectors. Third, based on the sequence of statement
1https://github.com/apache/ctakes/blob/
9c552c5c4f92af00d9d008b8c7f9e9d326a2450a/ctakes-core/src/main/java/org/
apache/ctakes/core/resource/FileReadWriteUtil.java#L32vectors, we use bidirectional Gated Recurrent Unit (GRU)
[34], [35], one type of recurrent neural network, to leverage
the sequential naturalness of statements and ﬁnally obtain the
vector representation of an entire code fragment.
In summary, our proposed neural source code representation
aims to learn more syntactical and semantic information about
source code than the state-of-the-art AST-based neural models.
It is general-purpose and can be used in many program
comprehension related tasks such as source code classiﬁcation
and code clone detection. We have conducted experiments
on the two tasks on public benchmarks and compared with
state-of-the-art approaches. The experimental results show that
our model is more effective. For example, for source code
classiﬁcation, our approach improves the accuracy from 94%
to 98.2%. For clone detection, our approach improves the
results of F1 values from 82% to 93.8% and 59.4% to 95.5%
on two benchmark datasets, respectively.
Our main contributions are as follows:
•We propose a novel neural source code representation,
which can capture the lexical, statement-level syntactical
knowledge, and the naturalness of statements;
•We have applied our representation to two common
program comprehension tasks (code classiﬁcation and
clone detection). The experimental results show that our
approach can improve the state-of-the-art methods.
The remainder of this paper is structured as follows. Sec-
tion II introduces the background. Section III presents our
approach. Section IV describes the applications of our neural
source code representation. Section V provides our exper-
imental results. Related work and discussion about threats
to validity are presented in Section VI and Section VII,
respectively. Finally, Section VIII concludes our work.
II. B ACKGROUND
A. Abstract Syntax Tree
Abstract Syntax Tree (AST) is a kind of tree aimed at
representing the abstract syntactic structure of the source code
[36]. It has been widely used by programming language and
software engineering tools. As illustrated in Figure 1(b), nodes
784
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. of an AST are corresponding to constructs or symbols of the
source code. On the one hand, compared with plain source
code, ASTs are abstract and do not include all details such as
the punctuation and delimiters. On the other hand, ASTs can
be used to describe the lexical information and the syntactic
structure of source code, such as the method name readText
and the control ﬂow structure WhileStatement in Figure 1(b).
Some studies directly use ASTs in token-based methods
for source code search [37], program repair [38] and source
code differencing [39]. Due to the limitation of token-based
approaches [17], these methods can catch little syntactical
information of source code.
B. Tree-based Neural Networks
Recently Tree-based Neural Networks (TNNs) have been
proposed to accept ASTs as the input. Given a tree, TNNs
learn its vector representation by recursively computing node
embeddings in a bottom-up way. The most representative
tree-based models for ASTs are Recursive Neural Network
(RvNN), Tree-based CNN (TBCNN) and Tree-based Long
Short-Term Memory (Tree-LSTM).
1) Recursive Neural Network: RvNN was ﬁrst proposed for
the recursive structure in natural language and image parsing
[40]. Speciﬁcally, given a tree structure, suppose that one
parent node y1has two children nodes (c1,c2), wherec1and
c2are word embeddings or intermediate vector representations
of nodes. The vector of node y1is computed by:
p=f(W(1)[c1;c2]+b(1))
whereW(1)is a matrix of parameters, fis an element-wise
activation function, and b(1)is a bias term. To assess the
quality of this vector representation, a decoding layer is used
to reconstruct the children:
[c/prime
1;c/prime
2]=W(2)p+b(2)
Then the training loss is measured by E(θ)=||c1−c/prime
1||2
2+
||c2−c/prime
2||2
2. In this way, RvNN can recursively compute and
optimize parameters across the tree, and the ﬁnal vector of
the root node will represent the given tree. Based on RvNN, a
recursive autoencoder (RAE) is incorporated for automatically
encoding ASTs to detect code clones [5], where ASTs are
transformed to full binary trees due to the ﬁxed-size inputs
for simpliﬁcation.
2) Tree-based Convolutional Neural Network: TBCNN
performs convolution computation over tree structures for
supervised learning such as source code classiﬁcation [2].
Its core module is an AST-based convolutional layer, which
applies a set of ﬁxed-depth feature detectors by sliding over
entire ASTs. This procedure can be formulated by:
y=tanh(n/summationdisplay
i=1Wconv,i·xi+bconv)
wherex1,···,xnare the vectors of nodes within each sliding
window, Wconv,i are the parameter matrices and bconv is the
bias. TBCNN adopts a bottom-up encoding layer to integratesome global information for improving its localness. Although
nodes in the original AST may have more than two children,
TBCNN treats ASTs as continuous full binary trees because
of the ﬁxed size of convolution.
3) Tree-based Long Short-Term Memory: Tree-LSTM is a
generalization of LSTMs to model tree-structured topologies.
Different from standard LSTM, Child-Sum Tree-LSTM [41]
recursively combines current input with its children states
for state updating across the tree structure. CDLH [6] uses
Tree-LSTM to learn representations of code fragments for
clone detection where code fragments are parsed to ASTs.
To deal with the variable number of children nodes, ASTs
are transformed to full binary trees. After a bottom-up way
of computation, the root node vectors of ASTs are used to
represent the code fragments.
C. The limitations of the existing work
These three tree-based methods have two major limitations.
First, during gradient-based training of tree topologies, the gra-
dients are calculated via backpropagation over structures [41],
[23]. However, the structures of ASTs are usually large and
deep due to the complexity of programs, especially the nested
structures. Thus the bottom-up computations from the leaf
nodes to the root nodes may experience the gradient vanishing
problem and are difﬁcult to capture long-range dependencies
[19], [22], which will miss some of the semantics carried by
distant nodes from the root nodes such as identiﬁers in the leaf
nodes. Second, the existing tree-based methods view ASTs as
binary trees by moving three or more children nodes of a
parent node to new subtrees for simpliﬁcation, which changes
the original semantics of source code and makes the long-term
dependency problem more serious. For example, CDLH [6]
can only have the F1 value of 57% in one public benchmark
for clone detection, and the studies in NLP [23], [41], [21]
show that the tree size and depth do matter and have signiﬁcant
impact on the performance.
III. O URAPPROACH
We introduce our AST-based Neural Network (ASTNN) in
this section. The overall architecture of ASTNN is shown in
Figure 2. First, we parse a source code fragment into an AST,
and design a preorder traversal algorithm to split each AST
to a sequence of statement trees (ST-trees, which are trees
consisting of statement nodes as roots and corresponding AST
nodes of the statements), as illustrated in Figure 1. All ST-trees
are encoded by the Statement Encoder to vectors, denoted as
e1,···,et. We then use Bidirectional Gated Recurrent Unit
[35] (Bi-GRU), to model the naturalness of the statements.
The hidden states of Bi-GRU are sampled into a single vector
by pooling, which is the representation of the code fragment.
A. Splitting ASTs and Constructing ST-tree Sequences
At ﬁrst, source code fragments can be transformed to large
ASTs by existing syntax analysis tools. For each AST, we split
it by the granularity of statement and extract the sequence of
statement trees with a preorder traversal.
785
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. Statement Encoder ௛భ 
௛భ 
݁ଵ ݎ 
ܶܵ-݁݁ݎݐ ଵ ௛మ 
௛మ 
݁ଶ ௛య 
௛య 
݁ଷ ௛೟షమ 
௛೟షమ 
  ݁௧ିଶ ௛೟షభ 
௛೟షభ 
  ݁௧ିଵ ௛೟← 
௛೟→ 
݁௧ 
… … … ܶܵ-݁݁ݎݐ ଶ 
… … … ܶܵ-݁݁ݎݐ ଷ 
… … …   ܶܵ- ݁݁ݎݐ ௧ିଶ 
… … …   ܶܵ- ݁݁ݎݐ ௧ିଵ 
… … …   ܶܵ- ݁݁ݎݐ ௧ 
… … … ST-trees Encoding Layer Recurrent LayerRepresentation 
… … ℎଵ ℎଶ ℎଷ ℎ௧ିଶ ℎ௧ିଵ ℎ௧ Pooling Layer 
Fig. 2. The architecture of AST-based Neural Network
Formally, given an AST Tand a set of Statement AST
nodesS, each statement node s∈SinTcorresponds one
statement of source code. We treat MethodDeclaration as a
special Statement node, thus S=S∪{MethodDeclaration }.
For nested statements, as shown in Figure 1, we deﬁne the
set of separate nodes P={block,body }whereblock is
for splitting the header and body of nested statements such
asTry andWhile statements, and body for the method
declaration. All of the descendants of statement node s∈S
is denoted by D(s). For any d∈D(s), if there exists
one path from stodthrough one node p∈P, it means
that the node dis included by one statement in the body
of statement s. We call node done substatement node of
s. Then a statement tree (ST-tree) rooted by the statement
nodes∈Sis the tree consisting of node sand all of
its descendants excluding its substatement nodes in T.F o r
example, the ﬁrst ST-tree rooted by MethodDeclaration is
surrounded by dashed lines in Figure 1(b), which includes
the header part such as “static”, “public” and “readText” and
excludes the nodes of the two LocalVariable , oneTry and
oneReturn statement in the body. Since nodes of one ST-
tree may have three or more children nodes, we also call it
multi-way ST-tree for distinguishing it from a binary tree. In
this way, one large AST can be decomposed to a sequence of
non-overlapping and multi-way ST-trees.
The splitting of ASTs and the construction of ST-tree
sequences are straightforward by a traverser and a constructor.
The traverser visits each node through the ASTs in a depth-
ﬁrst walk in preorder and the constructor recursively creates
a ST-tree to sequentially add to the ST-tree sequences. Such a
practice guarantees that one new ST-tree are appended by the
order in the source code. In this way, we get the sequence of
ST-trees as the raw input of ASTNN.
Note that the selection of splitting granularity of ASTs
is not trivial. We choose the statement trees in this work
since statements are essential units for carrying source code
semantics. We also experimented with other granularities suchModifier readText Formal 
Parameter throws Method 
Declaration Pooling 
Reference 
Type body Statement Vector 
h1 h2 h3 hN hN-1 hN-2 h4 … 
Fig. 3. The statement encoder, where blue, orange and green circles represent
the initial embeddings, hidden states and statement vector, respectively.
as the node level of ASTs, the code blocks within brace
pairs, and the full ASTs. We will discuss these experiments
in Section V. If the size of selected granularity is too large
(e.g., the full AST), similar to the related work [5], [6], we
may also experience the gradient vanishing problem mentioned
in Section II. But if it is too small (e.g., the node level of
AST), the model will become a token-based RNN that may
capture less syntactical knowledge of statements than ours.
Our experimental results show that proposed statement-level
granularity is better since it has a good trade-off between the
size of ST-tree and the richness of syntactical information.
B. Encoding Statements on Multi-way ST-trees
1) Statement V ectors: Given the ST-trees, we design a
RvNN based statement encoder, which is used for learning
vector representations of statements.
Since there are a variety of special syntactic symbols in
ASTs, we obtain all the symbols by preorder traversal of
ASTs as the corpus for training. The word2vec [42] is used
to learn unsupervised vectors of the symbols, and the trained
embeddings of symbols are served as initial parameters in
the statement encoder. Because all the leaf nodes of ASTs
representing the lexical information such as identiﬁers are
also incorporated in the leaf nodes of ST-trees, our symbol
embeddings can capture the lexical knowledge well.
Taking the ﬁrst ST-tree rooted by the node of MethodDec-
laration in Figure 1 as an example, the encoder traverses the
ST-tree and recursively takes the symbol of current node as
new input to compute, together with the hidden states of its
children nodes. This is illustrated in Figure 3. We only show
the ﬁrst two levels here. In the ST-tree, the two children nodes
readText (i.e., the method name) and F ormalParameter (i.e.,
the grammar structure deﬁning parameters of the method) as
well as other siblings enrich the meaning of MethodDeclara-
tion. If we transform the ST-tree to one binary tree as described
in [5], [6], for example, moving the node of readText to one
child node or descendant of the F ormalParameter node, the
original semantics may be destroyed. Instead, we take original
multi-way ST-trees as input.
Speciﬁcally, given a ST-tree t, letndenote a non-leaf
node and Cdenote the number of its children nodes. At
786
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. the beginning, with the pre-trained embedding parameters
We∈R|V|×dwhereVis the vocabulary size and dis the
embedding dimension of symbols, the lexical vector of node
ncan be obtained by:
vn=We/latticetopxn (1)
wherexnis the one-hot representation of symbol nandvnis
the embedding. Next, the vector representation of node nis
computed by the following equation:
h=σ(Wn/latticetopvn+/summationdisplay
i∈[1,C]hi+bn) (2)
whereWn∈Rd×kis the weight matrix with encoding
dimension k,bnis a bias term, hiis the hidden state for each
childreni,his the updated hidden state, and σis the activation
function such as tanh or the identity function. We use the
identity function in this paper. Similarly, we can recursively
compute and optimize the vectors of all nodes in the ST-tree t.
In addition, in order to determine the most important features
of the node vectors, all nodes are pushed into a stack and
then sampled by the max pooling. That is, we get the ﬁnal
representation of the ST-tree and corresponding statement by
Equation 3, where Nis the number of nodes in the ST-tree.
et=[max(hi1),···,max(hik)],i=1,···,N (3)
These statement vectors can capture both lexical and
statement-level syntactical information of statements.
2) Batch Processing: For improving the training efﬁciency
on large datasets, it is necessary to design the batch processing
algorithm to encode multiple samples (i.e., code fragments)
simultaneously. However, generally batch processing on multi-
way ST-trees makes it difﬁcult since the number of children
nodes varies for the parent nodes in the same position of one
batch [2], [6]. For example, given two parent nodes ns1with
3 children nodes and ns2with 2 children nodes in Figure
4, directly calculating Equation 2 for the two parents in one
batch is impossible due to different Cvalues. To tackle this
problem, we design an algorithm that dynamically processes
batch samples in Algorithm 1.
Intuitively, although parent nodes have different number of
children nodes, the algorithm can dynamically detect and put
all possible children nodes with the same positions to groups,
and then speed up the calculations of Equations 2 of each
group in a batch way by leveraging matrix operations. In
algorithm 1, we batch Lsamples of ST-trees and then breadth-
ﬁrst traverse them starting from the root nodes (line 4). For
the current nodes nsin the same position of the batch, we
ﬁrstly calculate Equation 1 in batch (line 10), then detect and
group all their children nodes by the node positions (line 12-
16). As shown in Figure 4, we separate the children nodes to
three groups by their positions and record the groups in the
array lists CandCI. Based on these groups, we recursively
perform batch processing on all children nodes (line 17-21).
After getting the results of all children nodes, we compute
Equation 2 in batch (line 22), and push all node vectors ofAlgorithm 1 Dynamic batching algorithm of ST-trees
Input: The array of root nodes in batched ST-trees, B;
Output: The vectors of batched ST-trees, BV;
1:L←len(B);
2:BI←[1,···,L];//ST-tree indexes in the batch
3:S∈RN×L×k←φ;//record all node vectors
4:Call DynamicBatch( B,BI);
5:Perform pooling on Sby Eq. 3 to get BV∈RL×k;
6:returnBV;
7:function DYNAMIC BATCH (ns,ids)⊿The batched
current nodes nsand their indexes ids
8:l←len(ns);
9:BC∈Rl×d←0;//initialize the matrix
10: Calculate Eq. 1 in batch for nsand ﬁll into BC
according to ids;
11: Initialize two array list C,CI←φto record children
nodes and their batch indexes;
12: foreachnode∈nsdo
13: foreach children node child ofnode do
14: groupchild by its position, and record child
toCand its batch index to CI;
15: end for
16: end for
17: fori=0→len(C)−1do
18: ˜h∈Rl×k←0;
19: η←DynamicBatch( C[i],CI[i]);
20: ˜h←˜h+η;
21: end for
22: Calculate hby Eq. 2 in batch;
23:BZ∈RL×k←0;//for calculating BV
24: FillhintoBZ according to idsand addBZ toS;
25: returnh;
26:end function
  ݏ݊ ଵ 
ܿଵ ܿଶ ܿଷ  ݏ݊ ଶ 
ܿଵᇱ ܿଶᇱ 
ܿଵ ܿଵᇱ ܿଶ ܿଶᇱ ܿଷ ܥ 
ܫܥ 1, 2 1, 2 1 
Fig. 4. An example of dynamically batching children nodes
batched ST-trees to the stack S(line 24). Finally we can obtain
the vectors of ST-tree samples and corresponding statements
by pooling described in Equation 3 (line 5).
C. Representing the Sequence of Statements
Based on the sequences of ST-tree vectors, we exploit GRU
[34] to track the naturalness of statements. We also considered
the choice of using LSTM and the comparison between LSTM
and GRU will be discussed in our experiment.
Given one code fragment, suppose there are TST-
tree extracted from its AST and let Q∈RT×k=
[e1,···,et,···,eT],t∈[1,T]denote the vectors of encoded
787
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. ST-trees in the sequence. At time t, the transition equations
are as follows:
rt=σ(Wret+Urht−1+br)
zt=σ(Wzet+Uzht−1+bz)
˜ht=tanh(Whet+rt⊙(Uhht−1)+bh)
ht=( 1−zt)⊙ht−1+zt⊙˜ht(4)
wherertis the reset gate to control the inﬂuence of previous
state,ztis the update gate to combine past and new infor-
mation,˜htis the candidate state and used to make a linear
interpolation together with previous state ht−1to determine
the current state ht.Wr,Wz,Wh,Ur,Uz,Uh∈Rk×mare
weight matrices and br,bz,bhare bias terms. After iteratively
computing hidden states of all time steps, the sequential
naturalness of these statements can be obtained.
In order to further enhance the capability of the recurrent
layer for capturing the dependency information, we adopt
a bidirectional GRU [34], where the hidden states of both
directions are concatenated to form the new states as follows:
− →ht=−−−→GRU(et),t∈[1,T]
← −ht=←−−−GRU(et),t∈[T,1]
ht=[− →ht,← −ht],t∈[1,T](5)
Similar to the statement encoder, the most important fea-
tures of these states are then sampled by the max pooling
or average pooling. Considering the importance of different
statements are intuitively not equal, for example, API calls in
theMethodInvocation statements may contain more functional
information [43], thus we use max pooling for capturing
the most important semantics by default. The model ﬁnally
produces a vector r∈R2m, which is treated as the vector
representation of the code fragment.
IV . A PPLICATIONS OF THE PROPOSED MODEL
The proposed ASTNN model is general-purpose. It can be
trained for task-speciﬁc vector representations of source code
fragments to characterize different source code semantics for
many program comprehension tasks. In this work, we take two
common tasks including source code classiﬁcation and code
clone detection as examples to show the applications of the
proposed model.
Source code classiﬁcation . This task aims to classify code
fragments by their functionalities, which is useful for program
understanding and maintenance [2], [44], [45]. Given the code
fragment vector rand the number of categories M, we obtain
the logits by ˆx=Wor+bo, whereWo∈R2m×Mis the weight
matrix and bois the bias term. We deﬁne the loss function as
the widely used cross-entropy loss:
J(Θ,ˆx,y)=/summationdisplay/parenleftBigg
−logexp(ˆxy)/summationtext
jexp(ˆxj)/parenrightBigg
(6)
whereΘdenotes parameters of all the weight matrices in our
model and yis the true label.
Code clone detection . Detecting code clones is widely
studied in software engineering research [3], [4], [5], [6], [26],which is to detect whether two code fragments implement the
same functionality. Suppose there are code fragment vectors
r1andr2, and their distance is measured by r=|r1−r2|for
semantic relatedness [41]. Then we can treat the output ˆy=
sigmoid(ˆx)∈[0,1]as their similarity where ˆx=Wor+bo.
The loss function is deﬁned as binary cross-entropy:
J(Θ,ˆy,y)=/summationdisplay
(−(y·log(ˆy)+(1−y)·log(1−ˆy))) (7)
To train ASTNN models for the two tasks, the goal is to
minimize the loss. We use AdaMax [46] in this paper because
it is computationally efﬁcient.
After all the parameters are optimized, the trained models
are stored. For new code fragments, they should be pre-
processed into sequences of ST-trees and then fed into the
reloaded models for prediction. The output are probabilities
pfor different labels. For code classiﬁcation, since there are
multiple categories, the inferred value can be obtained by:
prediction =a r gm a x
i(pi),i=1,···,M (8)
While for clone detection, pis a single value in the range
[0,1], thus we get the prediction by:
prediction =/braceleftbiggTrue, p>δ
False, p ≤δ(9)
whereδis the threshold.
V. E XPERIMENTS
In this section, we evaluate the proposed source code
representation on two tasks of code classiﬁcation (Task 1) and
clone detection (Task 2), and compare it with several state-of-
the-art approaches.
A. Dataset Description
There are two public dataset benchmarks for code classiﬁca-
tion and clone detection. One dataset consists of simple C pro-
grams collected from the Online Judge (OJ) system and made
public by Mou et al. [2]2. The programs in OJ benchmark are
for 104 different programming problems. Programs have the
same functionality if they aim to solve the same problem.
The other dataset BigCloneBench (BCB) was provided by
Svajlenko et al. [47] for evaluating code clone detection tools.
BCB consists of known true and false positive clones from
a big data inter-project Java repository. As benchmarks, the
two datasets have been used by many researchers concerning
on code similarity [48], [49] and clone detection [5], [6]. The
basic statistics corresponding to our two tasks are summarized
in Table I.
B. Experiment Settings
We used the pycparser3and javalang tools4to obtain ASTs
for C and Java code, respectively. For both tasks, we trained
embeddings of symbols using word2vec [42] with Skip-gram
2https://sites.google.com/site/treebasedcnn/
3https://pypi.python.org/pypi/pycparser
4https://github.com/c2nes/javalang
788
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. TABLE I
THE STATISTICS OF DATASETS USED FOR OUR TWO TASKS
Code Classiﬁcation Clone Detection
Dataset OJ Dataset OJ BCB
#Programs 52,000 #Code fragments 7,500 59,688
#Classes 104 %True clone pairs 6.6% 95.7%
Max tokens 8,737 Max tokens 2,271 16,253
Avg. tokens 245 Avg. tokens 244 227
Max AST depth 76 Max AST depth 60 192
Avg. AST depth 13.3 Avg. AST depth 13.2 9.9
Max AST nodes 7,027 Max AST nodes 1,624 15,217
Avg. AST nodes 190 Avg. AST nodes 192 206
algorithm and set the embedding size to be 128. The hidden
dimension of ST-tree encoder and bidirectional GRU is 100.
We set the mini-batch size to 64 and a maximum of 15 and 5
epochs for the two tasks, respectively. The threshold is set to
0.5 for clone detection. For each dataset, we randomly divide it
into three parts, of which the proportions are 60%,20%,20%
for training, validation and testing. We use the optimizer
AdaMax [46] with learning rate 0.002 for training. All the
experiments are conducted on a server with 16 cores of
2.4GHz CPU and a Titan Xp GPU.
C. Evaluation on Two Tasks
1) Source Code Classiﬁcation: We conduct extensive ex-
periments on the OJ dataset. Apart from the state-of-the-art
model TBCNN [2], we also take into account of traditional
and other neural network based approaches including SVMs
with statistical features, TextCNN [50], LSTM [51], LSCNN
[52] and PDG-based Graph embedding approaches [25], [26]
as follows:
•SVMs . We use the linear SVMs with traditional IR
methods. TF-IDF, N-gram and LDA are used to extract
textual features. The corpus are tokens extracted from
the source code ﬁles. For N-gram, we set the number
of grams to 2 and the number of max features to 20
thousand. The number of topics for LDA is 300.
•TextCNN and LSTM . These two models are widely used
for sentence classiﬁcation in NLP. We adapt them for this
task with token sequences by treating code fragments as
plain texts. For TextCNN, the kernel size is set to 3 and
the number of ﬁlters is 100. For LSTM, The dimension
of hidden states is set to 100.
•LSCNN . Originally proposed for bug location [52],
LSCNN extracts program features with CNN for state-
ment embedding and uses LSTM for statement sequences.
•PDG based Graph Embedding . Most recently some
studies [25], [26] construct program graphs by consid-
ering control ﬂow and data ﬂow dependencies, and adopt
graph embedding techniques such as HOPE [24] and
Gated Graph Neural Network (GGNN) [53] for code
representation. Although original code fragments in the
OJ dataset is incomplete and uncompilable, they can be
manually complemented by adding standard C header
ﬁles and third-party libraries and we use an open-sourcetool Frama-C5to get their PDGs. Based on the PDGs,
we represents nodes of PDGs by the numerical ID of
statements in HOPE [26], and average the embeddings
of all tokens in each PDG node as its initial embedding
[25] in GGNN6. After graph embedding, we add a max
pooling layer on all nodes of PDGs to obtain the ﬁnal
code representation.
To evaluate the effectiveness of source code classiﬁcation, we
use the test accuracy metric, which computes the percentage
of correct classiﬁcations for the test set.
2) Code Clone Detection: There are generally four different
types of code clones [54]. Type-1 is identical code fragments
in addition to variations in comments and layout; Apart from
Type-1, Type-2 is identical code fragments except for different
identiﬁer names and literal values; Type-3 is syntactically
similar code snippets that differ at the statement level; Type-
4 is syntactically dissimilar code snippets that implement the
same functionality. For BCB, the similarity of clone pairs is
deﬁned as the average result of line-based and token-based
metrics [47]. The similarity of two fragments of Type-1 and
Type-2 is 1. Type-3 is further divided into Strongly Type-3
and Moderately Type-3, of which the similarities are in range
[0.7,1)and[0.5,0.7), respectively. The similarity of Type-4
is in range [0,0.5)and its clone pairs take up more than 98%
over all clone types. While in OJ, two programs for the same
problem form a clone pair of unknown type.
As Table I shows, similar to the previous work [6], we
choose 500 programs from each of the ﬁrst 15 programming
problems in OJ, namely OJClone. It will produce more than
28 million clone pairs which is extremely time-consuming for
comparison, thus we randomly select 50 thousand samples
instead. Likewise, we parsed nearly 6 million true clone pairs
and 260 thousand false clone pairs from BCB. We compare
our approach with existing state-of-the-art neural models for
clone detection including RAE [5] and CDLH [6]. For RAE,
the unsupervised vectors of programs are obtained by the
authors’ open-source tool7and we use them for supervised
training, namely RAE+ . Its conﬁgurations are set according
to their paper. CDLH is not made public by the authors, so we
directly cite their results from the paper since their experiments
share the same datasets with ours. Since other traditional
clone detection methods like DECKARD [55] and common
neural models such as doc2Vec8have been compared in RAE
and CDLH, we omit them in our experiment. Similar to the
experiments on code classiﬁcation, we also compare with the
two PDG-based Graph embedding approaches in OJClone.
However, BCB mainly contains incomplete and uncompilable
method-level code fragments, we fail to get their PDGs.
Since the code clone detection can be formulated as a
binary classiﬁcation problem (clone or not), we choose the
commonly-used Precision (P), Recall (R) and F1-measure (F1)
as evaluation metrics.
5https://frama-c.com/
6https://github.com/Microsoft/gated-graph-neural-network-samples
7https://github.com/micheletufano/AutoenCODE
8https://radimrehurek.com/gensim/models/doc2vec.html
789
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. TABLE II
COMPARED APPROACHES FOR CODE CLASSIFICATION
Groups Methods Test Accuracy(%)
SVMs SVM+TF-IDF 79.4
SVM+N-gram 84.7
SVM+LDA 47.9
Neural models TextCNN 88.7
LSTM 88.0
TBCNN 94.0
LSCNN 90.9
PDG+HOPE 4.2
PDG+GGNN 79.6
Our approach ASTNN 98.2
D. Research Questions and Results
Based on the evaluation on the two tasks, we aim to
investigate the following research questions:
RQ1: How does our approach perform in source code
classiﬁcation? In the task of code classiﬁcation, the samples
are strictly balanced among the 104 classes and our evaluation
metric is the test accuracy. Experimental results are provided
in Table II. The best results are shown in bold.
We can see that traditional methods such as SVMs perform
poorly in our experiment. These methods mainly rely on the
semantics of tokens or shallow semantics features of programs
to distinguish the code functionalities, but the tokens used in
OJ dataset are mostly arbitrary. For example, the names of
identiﬁers are usually a, i, j , etc. Thus most tokens contribute
little to recognize the functionalities.
For those neural models, the results of TextCNN and
LSTM are better than token-based methods above because
they can capture some local functional features. For example,
the semantics of a short scanf statement can be captured by
the sliding window of TextCNN or the memory cell unit in
LSTM. As a neural network based on entire ASTs, TBCNN
signiﬁcantly improves the accuracy since it uses the convo-
lution sliding window over ASTs to capture tree structural
features. LSCNN has a relatively competitive performance
among existing neural models. This can be inferred that
the sequential information of statements does contribute to
recognize the functionality, but the accuracy is still lower than
TBCNN because it cannot capture the rich structural seman-
tics. Graph-based approaches including HOPE and GGNN
on PDGs perform poorly among the above approaches. In
particular, PDG with HOPE gets an accuracy of only 4.2%,
because the nodes of PDGs are represented by their numerical
ID which miss lexical knowledge and only focuses on the
explicit dependency information in a high abstraction level
[26]. PDG with GGNN uses tokens for node embedding and
has an improvement, but still lacks the syntactical information.
Among all the approaches, our model achieves the best
accuracy. Speciﬁcally, our model improves TBCNN by 4.2%,
since our ASTNN model performs RvNN on much smaller
ST-trees than original ASTs. Unlike existing neural models,
our model does not use the sliding window and binary treeTABLE III
CODE CLONE DETECTION MODELS ON BCB
TypeRAE+ CDLH ASTNN
P R F1 P R F1 P R F1
BCB-T1 100 100 100 - - 100 100 100 100
BCB-T2 86.5 97.2 91.5 - - 100 100 100 100
BCB-ST3 79.9 72.2 75.9 - - 94 99.9 94.2 97.0
BCB-MT3 66.4 74.8 70.3 - - 88 99.5 91.7 95.5
BCB-T4 76.3 58.7 66.3 - - 81 99.8 88.3 93.7
BCB-ALL 76.4 59.1 66.6 92 74 82 99.8 88.4 93.8
TABLE IV
CODE CLONE DETECTION MODELS ON OJC LONE
Metric RAE+ CDLH PDG+HOPE PDG+GGNN ASTNN
P 52.5 47 76.2 77.3 98.9
R 68.3 73 7.0 43.6 92.7
F1 59.4 57 12.9 55.8 95.5
transformation. Instead, it captures knowledge about AST
statements and the sequential dependencies between state-
ments.
RQ2: How does our approach perform in code clone
detection? In this research question, we want to explore
whether our model is effective on the challenging problem of
code clone detection. We conduct experiments on the OJClone
and BCB datasets.
From OJClone, we sample 50 thousand clone pairs for
experiments. While from BCB, we ﬁrstly sample 20 thousand
false clone pairs as the negative samples. For Type-1 to
Strongly Type-3, we fetch all the true clone pairs belonging
to that type as positive samples since their numbers are less
than 20 thousand. For other types, we sample 20 thousand true
clone pairs. Then we turn them into ﬁve groups to detect each
type.
The detailed results are shown in Table III (BCB) and IV
(OJClone). In Table III, as mentioned before, we cite the
results of CDLH from [6]. Since there are no P and R values
reported for detailed clone types, we ﬁll them by “-” instead.
BCB-ST3 and BCB-MT3 represent Strongly Type-3 and Mod-
erately Type-3 in BCB, respectively, and so on. The BCB-
ALL is a weighted sum result according to the percentage
of various clone types [6]. In Table IV, we compare with two
more PDG-based Graph embedding methods PDG+HOPE and
PDG+GGNN as described before.
We ﬁrst discuss the performances of RAE+, CDLH, and our
ASTNN model on BCB. Obviously, all the three approaches
are quite effective in recognizing the similarities of two code
fragments in Type-1 and Type-2, since both code fragments
are almost the same excepting different identiﬁer names,
comments and so on. While for other types of BCB, RAE+
performs much worse than the other two approaches since it
has no mechanism on memorizing history information such as
LSTM or GRU in CDLH and ASTNN. Comparing CDLH with
our approach, we can see that ASTNN outperforms CDLH in
terms of F1-measure especially for Type-4. In BCB Type-4,
false clone pairs share syntactical similarity as well, which
790
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. TABLE V
COMPARISON BETWEEN THE PROPOSED MODEL AND ITS DESIGN
ALTERNATIVES
DescriptionCode Classiﬁcation Clone Detection
Accuracy F1( OJClone) F1(BCB)
AST-Full 96.2 87.7 85.7
AST-Block 97.3 92.9 90.2
AST-Node 96.7 92.1 87.4
Removing Pooling-I 98.1 95.2 93.1
Removing Pooling-II 96.0 94.0 90.0
LSTM instead of GRU 97.8 95.6 92.3
Long code fragments 95.7 92.9 93.5
ASTNN 98.2 95.5 93.8
is validated to be coincidental [47] and is challenging to be
distinguished. This indicates our ASTNN model can capture
more subtle syntactical difference and complex semantics than
CDLH by overcoming its limitations described in Section III
and capturing sequential naturalness of statements.
In OJClone, similar results can be observed by RAE+ and
our model. However, CDLH performs much worse than on
BCB. Unlike BCB, the variable names of programs in OJClone
are usually meaningless, thus CDLH may miss a lot of lexical
information and can only capture some syntactical informa-
tion. By contrast, our ASTNN model can further measure
the functional similarities by learning more local syntactical
knowledge and the global sequential naturalness among state-
ments. Similar to code classiﬁcation, we also compare with
PDG-based Graph embedding techniques HOPE and GGNN.
They achieve worse performance than our ASTNN model due
to the facts mentioned in the last research question.
RQ3: What are the effects of different design choices for
the proposed model? We conduct experiments to study how
different design choices affect the performance of the ASTNN
model on the two tasks. As shown in Table V, we consider
the following design choices:
Splitting granularities of ASTs . Given a large AST, there
are many ways to split it into different sequences of non-
overlapping small trees. The two extreme ways are treating
the original full AST as one special subtree (AST-Full), or
extracting all nodes of the AST as special “trees” (AST-
Node). Besides the statement level splitting, another possible
way (AST-Block) is to split the AST according to blocks
(compound statements that include multiple statements within
the same brace pairs). After splitting, the follow-up encoding
and bidirectional GRU processings are the same as those in
ASTNN. We can see that AST-Block and ASTNN outperform
both extreme splitting approaches of AST-Full and AST-Node.
Our ASTNN model achieves the best performance, as analyzed
in Section III, this is because it has a good trade-off between
the size of ST-tree and the richness of syntactical information.
Pooling . In our ASTNN model, we use the max pooling
on ST-trees in the statement encoder (Pooling-I) and the max
pooling layer on the statement sequences after the recur-
rent layer (Pooling-II) as described in Section III. We study
whether the two pooling components affect the performance or
not by removing them and directly using the last layer hiddenBatch Size 71.2  71.2  71.2  71.2  71.2  
0.010.020.030.040.050.060.070.080.0
4 8 16 32 64Time Cost (min/epoch) TWB PBR DBA
49.6 
45.4 45.1 44.9 44.8 
11.9 9.4 6.8 5.0 3.5 
Fig. 5. The time cost of different batching methods
states. From the table, we can see that the pooling on statement
sequences provides a comparatively signiﬁcant performance
boost, whereas pooling on ST-trees matters little. This shows
that different statements of the same code fragments actually
have different weights.
LSTM . In the recurrent layer of our proposed model, we
use GRU by default. If replacing GRU by LSTM, the results
indicate that overall LSTM has a slightly poor but comparative
performance with GRU. We prefer GRU in our ASTNN model
since it can achieve more efﬁcient training.
Long code fragments . Considering only long code frag-
ments which have more than 100 statements, the percentage
of long code fragments is 1.6% in OJ, and the percentage of
clone pairs which include at least one long code fragment is
4.1% in BCB. From the table, we can see that our ASTNN
model can also deal with long sequences of statements well
and the performance on long code fragments remains good.
RQ4: T o what extent does the proposed dynamic batching
algorithm contribute to the efﬁciency? As we described in
Section III, our statement encoder can accept batch samples
with arbitrary tree structures as inputs, thus can accelerate the
speed of training. However, it is still unknown how efﬁcient
this algorithm is. In order to test and verify its capability,
we train our model in three different ways: totally without
batching (TWB), batching only on the recurrent layer (PBR),
batching on the recurrent layer and the encoding layer by using
our dynamic batching algorithm in Algorithm 1 (DBA). In
detail, TWB means calculating one sample each time; PBR
accepts batch samples, but encodes only one ST-tree at each
time and performs batching on the recurrent layer by padding
sequences of ST-tree vectors; DBA encodes all batch samples
of ST-trees at once and then deals with ST-tree sequences as
PBR does. The experiment is conducted for Task 1 and the
time cost is the average running time of training and testing
for each epoch.
In the experiment, the batching has no effect on the perfor-
mance but changes the efﬁciency a lot. We ﬁnd that the average
time required by TWB is 71.2 minutes per epoch. From Figure
5 we can see that both PBR and DBA speed up the training
and testing process when compared with TWB. DBA shows
a signiﬁcant improvement over the others. Furthermore, DBA
791
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. runs 12+ times faster than PBR and 20+ times faster than TWB
when the batch size is 64. This conﬁrms that the proposed
batching algorithm makes our ASTNN model more efﬁcient.
VI. R ELATED WORK
A. Source Code Representation
How to effectively represent source code is a fundamental
problem for software engineering research.
Traditional IR and machine learning methods have been
widely used for textual token-based code representation. Pro-
grams are transformed to regularized token sequences for code
clone detection [3]. SourcererCC [4] has an improvement by
exploiting token ordering along with an optimized inverted-
index technique. Besides the lexical information, Deckard [55]
enriches programs with some syntax-structured information
for clone detection as well. Based on the statistical and
machine learning methods, the n-gram model [1] and SVM
[45] are used for classifying source code authorship and
domains. Maletic et al. [56] adopts LSI to identify semantic
similarities of code fragments, and the cohesion of classes in
software is evaluated by LDA [15].
Recently deep learning based approaches have attracted
much attention to learn distributed representation of source
code [57]. Raychev et al. [58] adopts RNN and n-gram model
for code completion. Allamanis et al. [59] uses a neural
context model to suggest method and class names. For defect
prediction, semantic features are extracted from source code by
a deep belief network [60]. DeepBugs [61] represents code via
word2vec for detecting name-based bugs. In order to capture
the syntactical information of ASTs, White et al. [5] exploits
a recursive auto-encoder over the ASTs with pre-trained token
embeddings. TBCNN [2] uses custom convolutional neural
network on ASTs to learn vector representations of code
snippets. CDLH [6] incorporates Tree-LSTM to represent
the functionality semantics of code fragments. Furthermore,
Allamanis et al. [25] performs Gated Graph Neural Networks
on program graphs which track the dependencies of the same
variables and functions to predict variable names and detect
variable misuses. DeepSim [62] encodes code control ﬂow
and data ﬂow into a semantic matrix for measuring code
functional similarity. Multiple different code representations
such as identiﬁers, CFGs and bytecodes can also be integrated
by the ensemble learning technique [26]. Compared with these
neural networks, our model focuses on improving existing
AST-based methods and can capture the lexical, statement-
level syntactical knowledge and the sequential naturalness of
statements.
B. Deep Learning in Software Engineering
In recent years, there are many emerging deep learning
applications in software engineering. DeepAPI [43] uses a
sequence-to-sequence neural network to learn representations
of natural language queries and predict relevant API se-
quences. Lam et al. [63] combines deep neural network with
IR technique to recommend potential buggy ﬁles. Xu et
al. [64] adopts word embeddings and convolutional neuralnetwork to predict the related questions in StackOverﬂow. The
neural machine translation is used to automatically generate
commit messages [10]. Guo et al. [65] proposes a RNN based
neural network to generate trace links. A joint embedding
model is used in code search to map source code and natural
language descriptions into a uniﬁed vector space for evaluating
semantics similarity [66]. The above related work mainly uses
neural network models to understand software-related natural
language texts for various tasks while we focus on the neural
representation of source code.
VII. T HREATS TO VALIDITY
There are three main threats to the validity. First, the OJ
dataset is not collected from the real production environment.
However, BigCloneBench includes code snippets of real-world
Java repositories from SourceForge [47], which reduces this
threat. The second threat is about the construction of OJClone.
As we described, programs under the same problem belong
to a clone pair. This leads to the uncertainty about whether
they are true clone pairs, although similar practice has been
done by previous work [6]. Nevertheless, BigCloneBench is
also used for validation where the code clones are inspected
manually. Therefore, we believe it is of little inﬂuence on ex-
perimental results. The last threat is that we cannot reproduce
the approach of CDLH due to some details missed in that
paper. Alternatively, we construct the same datasets described
in their paper to reduce this threat. We will make supplement
for comparison when the CDLH tool is available.
VIII. C ONCLUSION
In this work, we have presented an efﬁcient AST-based Neu-
ral Network (ASTNN) to learn vector representations of source
code fragments, which can capture the lexical, statement-
level syntactical knowledge and naturalness of statements.
The model decomposes large ASTs of code fragments into
sequences of small statement trees, obtains statement vectors
by recursively encoding multi-way statement trees, and ﬁnally
learns the vector representations of code fragments by leverag-
ing the naturalness of statements. We have evaluated ASTNN
on two common program comprehension tasks: source code
classiﬁcation and code clone detection. The experimental
results show that our model signiﬁcantly outperforms existing
approaches. Our code and experimental data are publicly
available at https://github.com/zhangj1994/astnn.
In the future, we will further evaluate the proposed model
on larger-scale datatsets in different programming languages
and for a variety of software engineering tasks. We will also
explore other neural models to capture more deep semantics
of source code.
ACKNOWLEDGMENT
This work was supported partly by National Key Research
and Development Program of China (No.2016YFB1000804),
partly by National Natural Science Foundation of China
(No.61702024, 61828201 and 61421003).
792
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] G. Frantzeskou, S. MacDonell, E. Stamatatos, and S. Gritzalis, “Exam-
ining the signiﬁcance of high-level programming features in source code
author classiﬁcation,” Journal of Systems and Software , vol. 81, no. 3,
pp. 447–460, 2008.
[2] L. Mou, G. Li, L. Zhang, T. Wang, and Z. Jin, “Convolutional neural
networks over tree structures for programming language processing,” in
AAAI , vol. 2, no. 3, 2016, p. 4.
[3] T. Kamiya, S. Kusumoto, and K. Inoue, “CCFinder: a multilinguistic
token-based code clone detection system for large scale source code,”
IEEE Transactions on Software Engineering , vol. 28, no. 7, pp. 654–670,
2002.
[4] H. Sajnani, V . Saini, J. Svajlenko, C. K. Roy, and C. V . Lopes,
“SourcererCC: Scaling code clone detection to big-code,” in Software
Engineering (ICSE), 2016 IEEE/ACM 38th International Conference on .
IEEE, 2016, pp. 1157–1168.
[5] M. White, M. Tufano, C. Vendome, and D. Poshyvanyk, “Deep learning
code fragments for code clone detection,” in Proceedings of the 31st
IEEE/ACM International Conference on Automated Software Engineer-
ing. ACM, 2016, pp. 87–98.
[6] H.-H. Wei and M. Li, “Supervised deep features for software functional
clone detection by exploiting lexical and syntactical information in
source code,” in Proceedings of the 26th International Joint Conference
on Artiﬁcial Intelligence . AAAI Press, 2017, pp. 3034–3040.
[7] M. DAmbros, M. Lanza, and R. Robbes, “Evaluating defect prediction
approaches: a benchmark and an extensive comparison,” Empirical
Software Engineering , vol. 17, no. 4-5, pp. 531–577, 2012.
[8] C. Tantithamthavorn, S. McIntosh, A. E. Hassan, and K. Matsumoto,
“An empirical comparison of model validation techniques for defect
prediction models,” IEEE Transactions on Software Engineering , vol. 43,
no. 1, pp. 1–18, 2017.
[9] S. Haiduc, J. Aponte, and A. Marcus, “Supporting program compre-
hension with source code summarization,” in Proceedings of the 32nd
ACM/IEEE International Conference on Software Engineering-V olume
2. ACM, 2010, pp. 223–226.
[10] S. Jiang, A. Armaly, and C. McMillan, “Automatically generating
commit messages from diffs using neural machine translation,” in Pro-
ceedings of the 32nd IEEE/ACM International Conference on Automated
Software Engineering . IEEE Press, 2017, pp. 135–146.
[11] J. Zhou, H. Zhang, and D. Lo, “Where should the bugs be ﬁxed?
more accurate information retrieval-based bug localization based on bug
reports,” in 2012 34th International Conference on Software Engineering
(ICSE) , June 2012, pp. 14–24.
[12] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and
R. Harshman, “Indexing by latent semantic analysis,” Journal of the
American society for information science , vol. 41, no. 6, p. 391, 1990.
[13] D. M. Blei, A. Y . Ng, and M. I. Jordan, “Latent dirichlet allocation,”
Journal of machine Learning research , vol. 3, no. Jan, pp. 993–1022,
2003.
[14] R. Tairas and J. Gray, “An information retrieval process to aid in the
analysis of code clones,” Empirical Software Engineering , vol. 14, no. 1,
pp. 33–56, 2009.
[15] Y . Liu, D. Poshyvanyk, R. Ferenc, T. Gyim ´othy, and N. Chrisochoides,
“Modeling class cohesion as mixtures of latent topics,” in Software
Maintenance, 2009. ICSM 2009. IEEE International Conference on .
IEEE, 2009, pp. 233–242.
[16] A. De Lucia, M. Di Penta, R. Oliveto, A. Panichella, and S. Panichella,
“Using IR methods for labeling source code artifacts: Is it worthwhile?”
inProgram Comprehension (ICPC), 2012 IEEE 20th International
Conference on . IEEE, 2012, pp. 193–202.
[17] A. Panichella, B. Dit, R. Oliveto, M. Di Penta, D. Poshynanyk, and
A. De Lucia, “How to effectively use topic models for software
engineering tasks? an approach based on genetic algorithms,” in Software
Engineering (ICSE), 2013 35th International Conference on . IEEE,
2013, pp. 522–531.
[18] J. F. Pane, B. A. Myers et al. , “Studying the language and structure in
non-programmers’ solutions to programming problems,” International
Journal of Human-Computer Studies , vol. 54, no. 2, pp. 237–264, 2001.
[19] Y . Bengio, P. Simard, and P. Frasconi, “Learning long-term dependencies
with gradient descent is difﬁcult,” IEEE transactions on neural networks ,
vol. 5, no. 2, pp. 157–166, 1994.
[20] S. Hochreiter, “The vanishing gradient problem during learning
recurrent neural nets and problem solutions,” Int. J. Uncertain.Fuzziness Knowl.-Based Syst. , vol. 6, no. 2, pp. 107–116, Apr. 1998.
[Online]. Available: http://dx.doi.org/10.1142/S0218488598000094
[21] P. Le and W. H. Zuidema, “Quantifying the vanishing gradient and long
distance dependency problem in recursive neural networks and recur-
sive LSTMs,” in Proceedings of the 1st Workshop on Representation
Learning for NLP , Berlin, Germany, 2016, p. 8793.
[22] S.-Y . Cho, Z. Chi, W.-C. Siu, and A. C. Tsoi, “An improved algorithm
for learning long-term dependency problems in adaptive processing of
data structures,” IEEE Transactions on Neural Networks , vol. 14, no. 4,
pp. 781–793, 2003.
[23] X. Zhu, P. Sobhani, and H. Guo, “Long short-term memory over
recursive structures,” in Proceedings of the 32Nd International
Conference on International Conference on Machine Learning -
V olume 37 , ser. ICML’15. JMLR.org, 2015, pp. 1604–1612. [Online].
Available: http://dl.acm.org/citation.cfm?id=3045118.3045289
[24] M. Ou, P. Cui, J. Pei, Z. Zhang, and W. Zhu, “Asymmetric transitivity
preserving graph embedding,” in Proceedings of the 22Nd ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining , ser. KDD ’16. New York, NY , USA: ACM, 2016, pp. 1105–
1114. [Online]. Available: http://doi.acm.org/10.1145/2939672.2939751
[25] M. Allamanis, M. Brockschmidt, and M. Khademi, “Learning
to represent programs with graphs,” in International Conference
on Learning Representations , 2018. [Online]. Available: https:
//openreview.net/forum?id=BJOFETxR-
[26] G. B. M. D. P. M. W. Michele Tufano, Cody Watson and D. Poshyvanyk,
“Deep learning similarities from different representations of source
code,” in 15th International Conference on Mining Software Reposi-
tories , 2018.
[27] J. Ferrante, K. J. Ottenstein, and J. D. Warren, “The program
dependence graph and its use in optimization,” ACM Trans. Program.
Lang. Syst. , vol. 9, no. 3, pp. 319–349, Jul. 1987. [Online]. Available:
http://doi.acm.org/10.1145/24039.24041
[28] E. M. Myers, “A precise inter-procedural data ﬂow algorithm,”
in Proceedings of the 8th ACM SIGPLAN-SIGACT Symposium
on Principles of Programming Languages , ser. POPL ’81. New
York, NY , USA: ACM, 1981, pp. 219–230. [Online]. Available:
http://doi.acm.org/10.1145/567532.567556
[29] “Llvms analysis and transform passes,” https://llvm.org/docs/Passes.
html, accessed August 3, 2018.
[30] J. Gosling, B. Joy, G. L. Steele, G. Bracha, and A. Buckley, The Java
Language Speciﬁcation, Java SE 8 Edition , 1st ed. Addison-Wesley
Professional, 2014.
[31] T. Mikolov, M. Karaﬁ ´at, L. Burget, J. ˇCernock `y, and S. Khudanpur,
“Recurrent neural network based language model,” in Eleventh Annual
Conference of the International Speech Communication Association ,
2010.
[32] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and P. Devanbu, “On the
naturalness of software,” in Software Engineering (ICSE), 2012 34th
International Conference on . IEEE, 2012, pp. 837–847.
[33] B. Ray, V . Hellendoorn, S. Godhane, Z. Tu, A. Bacchelli, and
P. Devanbu, “On the ”naturalness” of buggy code,” in Proceedings
of the 38th International Conference on Software Engineering , ser.
ICSE ’16. New York, NY , USA: ACM, 2016, pp. 428–439. [Online].
Available: http://doi.acm.org/10.1145/2884781.2884848
[34] D. Bahdanau, K. Cho, and Y . Bengio, “Neural machine translation by
jointly learning to align and translate,” arXiv preprint arXiv:1409.0473 ,
2014.
[35] D. Tang, B. Qin, and T. Liu, “Document modeling with gated recurrent
neural network for sentiment classiﬁcation,” in Proceedings of the 2015
conference on empirical methods in natural language processing , 2015,
pp. 1422–1432.
[36] I. D. Baxter, A. Yahin, L. Moura, M. Sant’Anna, and L. Bier, “Clone
detection using abstract syntax trees,” in Softwar e Maintenance, 1998.
Proceedings., International Conference on . IEEE, 1998, pp. 368–377.
[37] S. Paul and A. Prakash, “A framework for source code search using
program patterns,” IEEE Transactions on Software Engineering , vol. 20,
no. 6, pp. 463–475, 1994.
[38] W. Weimer, T. Nguyen, C. Le Goues, and S. Forrest, “Automatically
ﬁnding patches using genetic programming,” in Proceedings of the 31st
International Conference on Software Engineering . IEEE Computer
Society, 2009, pp. 364–374.
[39] J.-R. Falleri, F. Morandat, X. Blanc, M. Martinez, and M. Monperrus,
“Fine-grained and accurate source code differencing,” in Proceedings
of the 29th ACM/IEEE international conference on Automated software
engineering . ACM, 2014, pp. 313–324.
793
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. [40] R. Socher, C. C. Lin, C. Manning, and A. Y . Ng, “Parsing natural scenes
and natural language with recursive neural networks,” in Proceedings of
the 28th international conference on machine learning (ICML-11) , 2011,
pp. 129–136.
[41] K. S. Tai, R. Socher, and C. D. Manning, “Improved semantic rep-
resentations from tree-structured long short-term memory networks,”
inProceedings of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International Joint Conference
on Natural Language Processing (V olume 1: Long Papers) , vol. 1, 2015,
pp. 1556–1566.
[42] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their composi-
tionality,” in Advances in neural information processing systems , 2013,
pp. 3111–3119.
[43] X. Gu, H. Zhang, D. Zhang, and S. Kim, “Deep API learning,” in
Proceedings of the 2016 24th ACM SIGSOFT International Symposium
on F oundations of Software Engineering . ACM, 2016, pp. 631–642.
[44] S. Kawaguchi, P. K. Garg, M. Matsushita, and K. Inoue, “Mudablue: An
automatic categorization system for open source repositories,” Journal
of Systems and Software , vol. 79, no. 7, pp. 939–953, 2006.
[45] M. Linares-V ´asquez, C. McMillan, D. Poshyvanyk, and M. Grechanik,
“On using machine learning to automatically classify software applica-
tions into domain categories,” Empirical Software Engineering , vol. 19,
no. 3, pp. 582–618, 2014.
[46] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980 , 2014.
[47] J. Svajlenko, J. F. Islam, I. Keivanloo, C. K. Roy, and M. M. Mia,
“Towards a big data curated benchmark of inter-project code clones,” in
Software Maintenance and Evolution (ICSME), 2014 IEEE International
Conference on . IEEE, 2014, pp. 476–480.
[48] A. Charpentier, J.-R. Falleri, D. Lo, and L. R ´eveill `ere, “An empirical
assessment of bellon’s clone benchmark,” in Proceedings of the 19th
International Conference on Evaluation and Assessment in Software
Engineering . ACM, 2015, p. 20.
[49] P. Accioly, P. Borba, and G. Cavalcanti, “Understanding semi-structured
merge conﬂict characteristics in open-source java projects,” Empirical
Software Engineering , pp. 1–35, 2017.
[50] Y . Kim, “Convolutional neural networks for sentence classiﬁcation,” in
Proceedings of the 2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP) , 2014, pp. 1746–1751.
[51] W. Zaremba and I. Sutskever, “Learning to execute,” arXiv preprint
arXiv:1410.4615 , 2014.
[52] X. Huo and M. Li, “Enhancing the uniﬁed features to locate buggy ﬁles
by exploiting the sequential nature of source code,” in Proceedings of
the 26th International Joint Conference on Artiﬁcial Intelligence , ser.
IJCAI’17. AAAI Press, 2017, pp. 1909–1915. [Online]. Available:
http://dl.acm.org/citation.cfm?id=3172077.3172153
[53] Y . Li, D. Tarlow, M. Brockschmidt, and R. Zemel, “Gated graph
sequence neural networks,” arXiv preprint arXiv:1511.05493 , 2015.[54] C. K. Roy and J. R. Cordy, “A survey on software clone detection
research,” Queens School of Computing TR , vol. 541, no. 115, pp. 64–
68, 2007.
[55] L. Jiang, G. Misherghi, Z. Su, and S. Glondu, “DECKARD: Scalable
and accurate tree-based detection of code clones,” in Proceedings of the
29th International Conference on Software Engineering , ser. ICSE ’07.
Washington, DC, USA: IEEE Computer Society, 2007, pp. 96–105.
[Online]. Available: http://dx.doi.org/10.1109/ICSE.2007.30
[56] J. I. Maletic and A. Marcus, “Supporting program comprehension
using semantic and structural information,” in Proceedings of the 23rd
International Conference on Software Engineering . IEEE Computer
Society, 2001, pp. 103–112.
[57] M. Allamanis, E. T. Barr, P. Devanbu, and C. Sutton, “A survey
of machine learning for big code and naturalness,” arXiv preprint
arXiv:1709.06182 , 2017.
[58] V . Raychev, M. Vechev, and E. Yahav, “Code completion with statistical
language models,” in Acm Sigplan Notices ,vol. 49, no. 6. ACM, 2014,
pp. 419–428.
[59] M. Allamanis, E. T. Barr, C. Bird, and C. Sutton, “Suggesting accurate
method and class names,” in Proceedings of the 2015 10th Joint Meeting
on F oundations of Software Engineering . ACM, 2015, pp. 38–49.
[60] S. Wang, T. Liu, and L. Tan, “Automatically learning semantic features
for defect prediction,” in Proceedings of the 38th International Confer-
ence on Software Engineering . ACM, 2016, pp. 297–308.
[61] M. Pradel and K. Sen, “DeepBugs: A learning approach to
name-based bug detection,” Proc. ACM Program. Lang. , vol. 2,
no. OOPSLA, pp. 147:1–147:25, Oct. 2018. [Online]. Available:
http://doi.acm.org/10.1145/3276517
[62] G. Zhao and J. Huang, “DeepSim: Deep learning code functional
similarity,” in Proceedings of the 2018 26th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the
F oundations of Software Engineering , ser. ESEC/FSE 2018. New
York, NY , USA: ACM, 2018, pp. 141–151. [Online]. Available:
http://doi.acm.org/10.1145/3236024.3236068
[63] A. N. Lam, A. T. Nguyen, H. A. Nguyen, and T. N. Nguyen, “Combining
deep learning with information retrieval to localize buggy ﬁles for
bug reports (n),” in Automated Software Engineering (ASE), 2015 30th
IEEE/ACM International Conference on . IEEE, 2015, pp. 476–481.
[64] B. Xu, D. Ye, Z. Xing, X. Xia, G. Chen, and S. Li, “Predicting seman-
tically linkable knowledge in developer online forums via convolutional
neural network,” in Proceedings of the 31st IEEE/ACM International
Conference on Automated Software Engineering . ACM, 2016, pp. 51–
62.
[65] J. Guo, J. Cheng, and J. Cleland-Huang, “Semantically enhanced soft-
ware traceability using deep learning techniques,” in Proceedings of the
39th International Conference on Software Engineering . IEEE Press,
2017, pp. 3–14.
[66] X. Gu, H. Zhang, and S. Kim, “Deep code search,” in Proceedings of
the 2018 40th International Conference on Software Engineering (ICSE
2018) . ACM, 2018.
794
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. 