SEGATE : Unveiling Semantic Inconsistencies
between Code and SpeciÔ¨Åcation of String Inputs
Devika Sondhi
IIIT Delhi
New Delhi, India
devikas@iiitd.ac.inRahul Purandare
IIIT Delhi
New Delhi, India
purandare@iiitd.ac.in
Abstract ‚ÄîAutomated testing techniques are often assessed on
coverage based metrics. However, despite giving good coverage,
the test cases may miss the gap between functional speciÔ¨Åcationand the code implementation. This gap may be subtle in nature,arising due to the absence of logical checks, either in theimplementation or in the speciÔ¨Åcation, resulting in inconsistenciesin the input deÔ¨Ånition. The inconsistencies may be prevalentespecially for structured inputs, commonly speciÔ¨Åed using string-
based data types. Our study on defects reported over popular
libraries reveals that such gaps may not be limited to inputvalidation checks. We propose a test generation technique forstructured string inputs where we infer inconsistencies in inputdeÔ¨Ånition to expose semantic gaps in the method under test andthe method speciÔ¨Åcation. We assess this technique using our tool
S
EGATE , Semantic Gap Tester. S EGATE uses static analysis and
automaton modeling to infer the gap and generate test cases.
On our benchmark dataset, comprising of defects reported in 15popular open-source libraries, written in Java, S
EGATE was able
to generate tests to expose 80% of the defects.
Index T erms ‚Äîtesting, static analysis, string input generation,
regular expression, automaton modeling, data Ô¨Çow analysis
I. I NTRODUCTION
Oftentimes, a programmer may implement a functionality
that differs from speciÔ¨Åcations either in the documentationor in standard conventions followed for inputs, especially,
structured inputs such as a Ô¨Åle path or URL. These structured
inputs, despite being valid as per the speciÔ¨Åcation, may endup being handled incorrectly in the implementation if logicalchecks on the expected input are missing or weakly deÔ¨Ånedor if there are additional checks in the code that constrain the
input as compared to its speciÔ¨Åcation in the documentation.
Qualitative evaluation of test cases based on code- or path-coverage ([1], [2], [3], [4], [5]) may overlook such issues.
Consider the defect #1462
1in Google Guava library‚Äôs
getFileExtension method in Files class. According to the
speciÔ¨Åcation, as obtained from the javadoc, the method acceptsa string denoting a Ô¨Åle name and returns the Ô¨Åle extension
or an empty string if the Ô¨Åle has no extension. The faulty
implementation, shown in Listing 1, misses cases where a dot(‚Äò.‚Äô), the extension separator, may be present in the internalpath components of the Ô¨Åle name. For instance, the methodwith input C:\abc.def\testfile would incorrectly re-
turn the extension as def\testfile when it should return
1https://github.com/google/guava/issues/1462Listing 1: Defective implementation of getFileExtension.
1/ ** Returns the file extension for the given file name ,
2 or the empty string if the file has no e xtension .
3 T h e result does not include the ‚Äô. ‚Äô. **/
4 public static String getFileExtension ( String fileName )
5 { checkNotNull ( fileName ) ;6 int dotIndex = fileName . lastIndexOf ( ‚Äò. ‚Äô) ;7 return (dotIndex = = ‚àí1) ? "" : fileName . s ubstring (
dotIndex + 1) ; }
an empty string. The implementation returns the substring
following the last ‚Äò.‚Äô. However, the implementation misses thatthe Ô¨Åle separator (‚Äò\‚Äô in this case) may occur after the dot,which is valid for a Ô¨Åle path.
Appropriate constraints to extract a valid Ô¨Åle extension
are not explicitly provided either in the main code or as
assertions by the developer. As a result, passing the program-path constraints to a constraint solver or using a fuzz tester isunlikely to generate tests to reveal the described defect.
We know from the documentation that there is only a single
‚Äò.‚Äô as extension separator, while rest of the occurrences of
‚Äò.‚Äô act as non-separators. The implementation presumes all
occurrences of ‚Äò.‚Äô to act as separators. Our proposed techniqueleverages this gap by formulating two regular expressions fromthe documentation and the implementation, respectively, todenote the input structure treating separator ‚Äò.‚Äô as a differentcharacter altogether from the non-separator ‚Äò.‚Äô. Using this ap-
proach we generate the potentially defect exposing test strings
that denote the differences in the two regular expressions.
Our work focuses on test generation of structured and
semi-structured inputs commonly speciÔ¨Åed using string-baseddata types. The approach particularly targets cases of missinglogical checks in the implementation or missing details in the
speciÔ¨Åcations that are otherwise part of the implementation.
A solution to deal with such inconsistencies may be speciÔ¨Åcto the nature of input data type. The situation becomescomplicated with string inputs where the size of character-set (charset) may be large and the manipulation operationson strings may be diverse. These challenges make testing a
non-trivial task. While researchers have done substantial workon detecting input validation defects in a method ([6], [7],
[8], [9]), these techniques may not necessarily expose subtledefects in the method once the input passes all validationconstraint checks.
UI*&&&"$.*OUFSOBUJPOBM$POGFSFODFPO"VUPNBUFE4PGUXB SF&OHJOFFSJOH	"4&
¬•*&&&
%0*"4&
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. In this paper we make the following key contributions:
1) A test generation technique to expose defects arising
from string-based input inconsistencies between methodimplementation and speciÔ¨Åcation. These inconsistenciesmay be semantic or syntactic in nature.
2) Design and implementation of a prototype tool, S
EGATE ,
to assess the proposed technique on Java programs.
3) Exposing unreported defects in widely used libraries
using the proposed technique.
SEGATE ‚Äôs novelty is in its differential approach that is com-
bined with in-depth string analysis and prioritization heuristicsto improve the quality of test strings. The technique allows tar-geting tests beyond the coverage criteria and input validation.
Section II gives an overview of our technique.
II. O
VERVIEW
A. Motivating Example
Consider the defective implementation of getPrincipalsAnd-
Credentials method, from Apache Shiro library, in Listing
2. The method documentation describes the encoded input
as a Base64-encoded username:password value found in the
request‚Äôs authorization header. The method is expected to
return the username and password pair split over ‚Äò:‚Äô. RFC2617, referred to in the documentation, states that the user-name excludes ‚Äò:‚Äô character, but it is valid for a password tocontain a ‚Äò:‚Äô, even though there is only a single ‚Äò:‚Äô that acts
as a separator. The implementation misses the support for this
scenario, thus, depriving a user, having ‚Äò:‚Äô in the password,from connecting to a Shiro protected application. For instance,for a Base64-encoded input foo:this:bar , the method returns
password as this, at the second index of the returned String
array, instead of the expected this:bar . The implementation
has a single program path possible with the split function
indicating the possible presence of ‚Äò:‚Äô in the input. There isno additional check on single and multiple occurrences of ‚Äò:‚Äô,as both require a different way of handling. However, givena single constraint, it is not guaranteed for a constraint solveror a fuzzer to be able to generate concrete value containing
more than one ‚Äò:‚Äô. Thus, the defect, due to a missing constraint
check, may be left unexposed.
Our technique models the structures of the speciÔ¨Åed input
and the implementation-derived input as regular expressions(regexes), r
sandri, respectively. These regexes may accept
different languages. For the encoded input, rsis obtained by
annotation, derived from the grammar in RFC 26172, as below
^([a-zA-Z0-9\+/]+(:)[a-zA-Z0-9\+/:]+))$
SEGATE statically analyses the method to derive rias
^(([a-zA-Z0-9/:\+] *(:)[a-zA-Z0-9/:\+] *)+)$
As the colon (‚Äò:‚Äô) can act as a username-password separator
or a non-separator, S EGATE assigns a different character
representation in the regex as ( :nonspl ) for the occurrence of
colon as a non-separator in rs. We generalize this idea to all
characters that could play multiple roles in a string structure.
2https://tools.ietf.org/html/rfc2617#page-6Listing 2: Defective getPrincipalsAndCredentials method.
1/ ** Returns the username and password pair based on the
2 specified encoded String obtained from the re quest ‚Äô
3 s authorization header .4 Per R F C 2617, the de fault implementation first
5 Base64 decodes the st ring and then splits the
6 resulting decoded string into two based on the ":"
7 character8 @param s cheme the authcScheme found in the request
9 authzHeader . It is ignored by this implementation ,
1 0 but available to over riding im plementations should
1 1 they find it useful .12 @param encoded the Base64‚àíencoded username : password
1 3 value found after the sc heme in the header
14 @return the username ( index 0) / password ( index 1)1 5 pair obtained from the encoded header data .
16 **/
1 7 public String [] ge tPrincipalsAndCredentials ( String
scheme , String encoded) {
1 8 String decoded=Base64. decodeToString (encoded) ;
1 9 return decoded. s plit (":") ; }
The approach models rsandrias two separate Determin-
istic Finite Automata (DFA) to compute the differential DFA,
DŒî.DŒîrepresents the symmetric difference between sets of
strings accepted by rsandri.SEGATE applies prioritization
heuristics to generate a subset of test strings accepted by DŒî.
For the discussed example, S EGATE successfully generates test
strings with ‚Äò:‚Äô occurring in the password of the encoded input,as described in the reported defect, hence, exposing the defect.
B.S
EGATE Overview
We implement the proposed technique in a prototype tool,
SEGATE , Semantic Gap Tester. Figure 1 shows the two main
components of S EGATE , in grey boxes. Here is a Ô¨Çow of steps.
1) The Static Analyzer performs an inter-procedural
dataÔ¨Çow analysis to compute the regex, ri, denoting the
input string to the method, as inferred by analyzing theprogram. The analyzer also extracts special charactersfrom the program which are later used for test generation.
2)r
iis passed to the Test Generator, which also takes
a human annotated or system recommended regex, rs.
Here rsdenotes the set of input strings that are expected
to be accepted by the method, as inferred from the
documentation attached with the method being tested.
3)rsandriare modeled as DFA from which S EGATE com-
putes the symmetric difference between the two regexesto obtain a differential automaton, D
Œî.
4)DŒîis transformed into a graph. By performing a priority-
based traversal on the graph, a set of test strings aregenerated that would be accepted by D
Œî. These test
strings represent the inconsistencies over input constraints
in documentation and implementation.
We describe the components of S EGATE in the next section.
III. S EGATE ARCHITECTURE
A. Static Analyzer
We apply static dataÔ¨Çow analysis to derive the regex,
representing the structure of string input, from the source code.The Static Analyzer, built using Soot [10], performs forward-
Ô¨Çow, inter-procedural and context-sensitive string analysis.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. Test GeneratorStatic Analyzer
Source Code
and
DocumentationTest StringsRegex
Extractor Derived
Regex
Annotated /
Recommended
RegexSpecial
Character
Extractor
String Methods
Regex mappingDifferential
AutomatonAutomaton
TranformationPrioritized
Automaton
Traversal
Fig. 1: The architecture of S EGATE tool.
TABLE I: Flow functions used in String Analysis (SA).
V ector :{r|regex containing characters c ‚ààASCII charset } (1)
kill SA(stmt )=/braceleftBigg
‚àÖ stmt /‚ààtaintedStmt
all otherwise(2)
gen SA(stmt )=‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©‚àÖ stmt /‚ààtaintedStmt, stmt =T hrowStmt
concatenate (e,‚Äò&‚Äô,r)‚àÄe‚ààInSet (stmt ) stmt‚àà{IfStmt, LoopStmt, InvokeStmt, AssgnStmt with string
where r is regex obtained from RegMap‚àóoperation }and stmt ‚ààtaintedStmt/uniontext
using ‚Äò|‚Äô‚àÄe‚ààInSet (stmt ) ReturnStmt(3)
InSet (stmt )=/braceleftBigg
{.‚àó} at method entry/uniontext{OutSet (s/prime)|s/prime‚ààpred (stmt )}otherwise
(4)OutSet (stmt )=‚éß
‚é™‚é®
‚é™‚é©/uniontext
using ‚Äò|‚Äô‚àÄe‚ààInSet (stmt )at method exit
InSet (stmt )\kill SA(stmt )‚à™otherwise
gen SA(stmt )
(5)
‚àóRegMap contains mapping from method to the regex denoting the input structure derived from the implementation.
Algorithm 1: Derive Regular Expression.
Data: M // Method to test in 3-address Jimple code
Result: RegMap // regex mapping for all method inputs
1function Regex_Flow (M)
2 // Initialize: Load regex mappings for String API
3 RegMap := loadregexmapping()
4 CG := M.getinterproceduralCallGraph()
5 removeBackEdges(CG) // remove cycles from CG
6 methods := getmethods(CG) // Java lib. methods are ignored
7 reverseTopologicalSort(methods)
8 forall m in methods do
9 CFG := getUnitGraph(m) // control Ô¨Çow graph
10 forall stmt in CFG do
11 compute InSet[stmt], OutSet[stmt] // Func. 4,5
12 regex := OutSet[m.method_exit] // from Func. 5
13 RegMap.add(m,regex)
14 return RegMap
Algorithm 1 describes the derivation of regex from the
method. The analysis takes the method under test in the formof a 3-address code in Jimple format [11] and returns thestring representing the regex for each string input accepted
by the target method. The Regex_Flow function obtains the
call-graph to arrange methods in the reverse weak topologicalorder [12] (Algo. 1, line 4-7) to perform an inter-proceduralanalysis and compute the analysis summary.
Using the Ô¨Çow functions in Table I, the analyzer further
performs string analysis over statements of each method (Algo.1, line 8-12). In the rest of the paper, we refer to a string-based
parameter as input. The InSet vector at a method statementcontains the regex status of the input as derived from the
control Ô¨Çow paths reaching from all predecessors to thatstatement, denoted by pred(stmt) in function 4, condition 2
(func. 4, cond. 2). On processing the statement, the InSet
elements are updated (based on gen
SAand killSAfor the
statement type) to obtain the OutSet (func. 5). Note that the
presented string analysis is not a bit-vector analysis, and gen SA
and killSAdepend on the InSet .
The analysis uses taint propagation to extract statements
affected by the input and hence, contribute in generatingregex. At the method entry, we assume the input parameter astainted and add it to the inset. Further, using a may variant
of constant propagation, the local variables referring to aconstant string at an instance are replaced by their correspond-
ing possible constant values. Our implementation of constant
propagation also handles obtaining new string constants dueto statements involving string concatenation functions andexpressions. These constants are useful in building the regex.
1)Summary Computation :RegMap maintains mapping
(summary) from method to regex denoting the structure of theinput derived from the method implementation. RegMap is
updated with summaries as more methods are analyzed (Algo.
1, line 13). Initially, we maintain a manually obtained regexmapping for methods in Java‚Äôs String API. For instance, aregex for startsWith(str) method over alphanumeric charset is
((<str>)\w* ). The analyzer replaces <str> with all its pos-
sible values, obtained through constant propagation analysis,
described previously. We assume that the third party library

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. methods written in Java, dealing with string inputs, may at
some point invoke the methods from Java library‚Äôs String class.Hence, having these basic mappings would aid in buildingregex for string inputs of other methods. While obtaining thisinitial mapping, we ignored update-methods like ‚Äòconcat‚Äô andits variants. These methods make additions to the tainted stringwithout revealing any information about its original structure.
We stop exploring the depth of the call-graph at a method
invocation from the Java library. The analyzer fetches thecorresponding regex from RegMap for the invoked method.
2)Statement Analysis :For a method, the Regex_Flow
function generates regex by processing each taint-affected
statement ( taintedStmt ) according to its type, such as condi-
tionals, loop conditions, assignments, invocations and return.
For our analysis, we are only interested in a statement if
it contains at least one tainted use-value. For instance, in anassignment statement, having a tainted use-value indicates that
the variable being deÔ¨Åned on the l-value is directly or indi-
rectly affected by the input string and hence, would be usefulto infer the structure of the input. In statements containingmethod invocations, if the implicit parameter of the invokedmethod is tainted, we pass the tainted values and constant
arguments of the invoked method to obtain the corresponding
regex from the existing mapping (in RegMap ) of the invoked
method. This regex is then appropriately concatenated withthe existing regex in the inset according to the Ô¨Çow func. 3(cond. 2) to obtain the outset (func. 5, cond. 2). Consider
int dotIndex = Ô¨ÅleName.lastIndexOf(‚Äò. ‚Äô);
From this statement one can infer that Ô¨ÅleName may
contain the character ‚Äò.‚Äô, hence, deriving regex [a-zA-Z0-9_\-\.\\]*(\.)?[^\.]* for this statement.
A typical conditional statement has a boolean expression
which may be an (in-)equality check or a method invoca-
tion. We treat Switch-Case statement conditions and loops
conditions similar to If-Else statement. Conditionals involvingtainted values are relevant for our analysis to infer details aboutthe input. Similar to the assignment statements, we maintaina condition-to-regex mapping, in RegMap , to build on the
regex from the conditional statements. To reach a converging
Ô¨Åxed point while analyzing statements inside a loop body, the
derived regex from the loop body is not concatenated in theoutset elements if already done in the previous iteration.
Condition leading to a Throw statement that raises exception
may not be useful in learning about the input as it indicates a
case already handled for an invalid input. Hence, for everyThrow statement, the analyzer kills all elements (func. 2,
cond. 2) in the inset and generates nothing (func. 3, cond.1). However, the analyzer still captures the negated conditionthat takes the ‚Äòelse‚Äô path. The intuition is that the negatedcondition would deÔ¨Åne constraint on a ‚Äòvalid‚Äô input.
For a return statement, the regex derived along all paths
reaching it are concatenated using a ‚Äò|‚Äô indicating logicalor(func. 3, cond. 3). As all return statements lead to a
method exit, the regex coming from all return statements areconcatenated using a ‚Äò|‚Äô indicating logical or(func. 5, cond.
1). The Ô¨Ånal single regex thus obtained, represents the set ofstrings that the input would match. This regex is added to
RegMap corresponding to the method analyzed.
Statements of other types do not inÔ¨Çuence the regex and are
hence, ignored.
3)Handling multiple string inputs :If a method consists
of multiple string parameters (inputs), then for every input at a
time, we mark it as tainted and others as untainted to proceedcomputing its regex. This idea is similar to symbolic executiontreating one input as symbolic and others as concrete.
4)Collecting special characters :Any hard-coded charac-
ter or string occurring in a statement is recorded in a set ofspecial characters. This set is passed to the Test Generator.
Section III-B discusses the use of this set in detail.
B. Test Generator
The Test Generator aims to generate concrete test inputs
that are supported by exactly one of the two: the methodimplementation or the method speciÔ¨Åcation obtained from thedocumentation. The regex r
i, derived by the Static Analyzer, is
modeled into a Deterministic Finite Automaton (DFA), using
the dk.brics.automaton library [13]. From the speciÔ¨Åcations,we infer and annotate the regex, r
s, for the string input, which
is further modeled into another DFA.
1)Obtaining annotations from speciÔ¨Åcation :Similar to
past techniques that take assertions or contracts as inputs (such
as with Randoop [14]), S EGATE takes rsannotations from an
expert or as recommendation from our system. To obtain rs,
we follow a semi-automated approach using an annotation rec-ommender system. We build a repository of regex annotationsfor standard string structures to recommend annotations tofurther test other methods taking similar inputs. The repositorycontains a tag associated with every annotation, describingwhat the annotation denotes, such as ‚Äòjson string‚Äô, ‚Äòip address‚Äô,etc. To obtain recommendation for r
s, the system takes a query
description as input and computes a phrase similarity score
between the query and every tag in the repository, picking thetag with the highest score (ranging between 0 and 1), providedthe score exceeds the empirically determined threshold of 0.55.To compute the similarity score, we use a semantic similaritycomputation API ([15]). The regex corresponding to the picked
tag is recommended. If no appropriate tag exists, the user
provides an annotation, which is fed into the system, alongwith a provided tag, for future recommendations. Such anapproach thus reduces manual efforts and allows incorporatingdomain knowledge about the input structures, which could be
leveraged to test other methods.
2)Obtaining a differential DF A :The two DFAs, modeled
fromr
iandrs, are minimized using Hopcroft‚Äôs algorithm [16].
SEGATE computes a differential DFA, DŒî, accepting the set
of strings which is the symmetric difference represented by:
(rs‚à™ri)‚àí(rs‚à©ri) (6)
Using a DFA for string generation provides Ô¨Çexibility as well
as control to generate diverse strings by traversing differentpaths of the automaton. Automaton model could also be usedto generate strings by traversing selective paths.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. Algorithm 2: Derive DŒîandDt.
Data: Regex Strings ri,rs
Result: Transformed Automaton Dt
1function Transform_Automaton (ri,rs)
2 Automaton ai:=ri.toAutomaton()
3 Automaton as:=rs.toAutomaton()
4 Automaton DŒî:= Difference(Union( ai,as), Intersection( ai,as))
5 // Transformation
6 forall Transition StatePair (s1, s2) in DŒîdo
7 CharSet symbolset := partition((s1, s2).symbols, splchars)
8 forall sym in symbolset do
9 Node n := Node((s1, s2), sym)
10 ifs2 is acceptState then n.setAcceptNode;
11 ifs1 is initState then n.setInitNode;
12 ifs 1=s 2 then n.setSelfLoopNode(true);
13 forall adjacent Nodes n1, n2 do
14 Edge e := Edge(n1, n2) // where n1.secondState=n2.Ô¨ÅrstState
15 return Automaton(Set<Node>, ASCIICharSet, Set<Edge>,
Set<InitNode>, Set<AcceptNode>)
Need for differential automaton: The differential nature of
DŒîmakes the strings accepted by it as relevant test inputs.
We expect most ricomplying strings to comply with rs, and
vice versa. Hence, we use a differential approach to narrowdown to potentially defect-revealing strings.
3)DF A transformation for string generation :The ASCII
charset and the special characters obtained from the Static
Analyzer make up the alphabet for the DFA. However, D
Œî
may accept a large number of strings. To prepare test inputs,
the requirement is to obtain a smaller subset of strings acceptedbyD
Œî. Thus, the generator generates a subset of strings such
that every sequence of transitions from each start to acceptstate in D
Œîis traversed not more than once. To ensure that
every transition is visited once, we transform DŒîtoDt,
treating each transition as a Node and each pair of adjacent
transitions as an Edge . Figure 2 shows an example of a
snippet of DŒîbeing transformed to produce Dt. Algorithm 2
describes the derivation of DŒî(line 2-4) and its transformation
to DFA Dt(Q,Œ£,Œ¥,q0,F)(line 6-14), deÔ¨Åned as below:
‚Ä¢Q: Set of Ô¨Ånite Nodes formed where a pair of adjacent
States of DŒîform a Node, also called a State Pair Node
‚Ä¢Œ£: Alphabet containing the ASCII charset and the special
characters‚Äô set obtained from the Static Analyzer
‚Ä¢Œ¥: Set of transitions between all adjacent State Pair Nodes
with the transition function Q √óŒ£‚ÜíQ. For adjacent State
Pairs Nodes N1 and N2, N1.secondState = N2.Ô¨ÅrstState
‚Ä¢q0: Start Nodes which are the set of nodes with the Ô¨Årst
State as a start State of DŒî
‚Ä¢F: Subset of Q containing accept Nodes denoting strings
accepted by the regular language of expression 6. A Node
N is in accept state if N.secondState is an accept State.
4)T est string generation from Dt:To obtain the test
strings, we apply a variant of depth-Ô¨Årst search traversal(DFS_Visit function of Algorithm 3) over D
tto visit every
node, that represents a transition edge from DŒî. The number
of nodes in the automaton, despite minimization, ranged tolarge numbers, with maximum 6866 nodes for a method in ourdataset. Hence, while traversing D
t, we do not visit a node
more than once, hence ignoring the respective path (Algo.a
cdb
e
a,b
c,db,d
a,cb,c{s...}
d,e
 c
{s...}
{s...}
Fig. 2: Transformation from DŒîtoDt.
Algorithm 3: Generate Test Strings.
Data: Dt
Result: String[] testStrings
1function Generate_Teststring (Dt)
2 forall initState src in Dtdo
3 teststrings.add(DFS_Visit(src, visited:=[], Dt, str := "",
teststrings := []))
4 return teststrings
Data: srcNode, visitedNodes, Dt
Result: String[] testStr //list of test strings
5function DFS_Visit (src, visited[], Dt, str, testStr[])
6 visited.add(src)
7 ifsrc.isAcceptNode ‚àßstr not in testStr then testStr.add(str);
8 prioritize(src.neighbors)
9 forall neighbor of src do
10 ifneighbor not in visited then
11 // concatenate random char from the symbols of the Node
12 str := str.concat(neighbor.RandomSymbol())
13 ifneighbor .isAcceptNode then testStr.add(src);
14 DFS_Visit(neighbor, visited, Dt, str, testStr)
15 return testStr
3, line 10). This optimization allows the technique to scale
by avoiding path explosion and allows generating a smallerset of strings suitable for a test set. While traversing fromevery node, a symbol is randomly picked from the range
of symbols supported for the node and concatenated to thestring being derived (Algo. 3, line 12). On reaching an accept
state node, the resultant string is logged and the traversalcontinues deriving other test strings (Algo. 3, line 13-14).For the getPrincipalsAndCredentials method (section II-A),
the corresponding D
t, due to its differential nature, would
contain at least one path that accepts strings containing boththe colons (: and :
nonspl ) in the username:password encoding.
Advantage of Dtover DŒî:Note how the traversal over Dt
instead of DŒîguarantees visiting every vertex of the original
differential automaton DŒî. Referring to Figure 2, to explain
through an example, a traversal along the path a,b,d,e on
DŒîwould mark all the States (vertices) along the path as
visited. This eliminates the paths a,b,c,d,e anda,c,d,e
due to banddalready marked visited, leaving vertex c
unexplored. Transformation to Dt, as shown in the Ô¨Ågure,
deÔ¨Ånes distinct nodes for every transition and running a depth-
Ô¨Årst traversal on this automaton would allow exploring more
paths allowing every State (from DŒî) to be visited. Note how
the path a,c,d,e (ora,b,c,d,e ) could now be included
in the traversal, in addition to a,b,d,e .

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. TABLE II: List of some of the known defects from popular libraries used for evaluation.
BugId MethodName Library Defect Description
IO-499 FilenameUtils. directoryContains Apache Commons-IO Gives false positive when two directories have equal preÔ¨Åxes
IO-567 FilenameUtils.getExtension Apache Commons-IO Implementation misses accounting for existence of alternate
data stream in Ô¨Åle-path
http-392 UrlEncodedParser.parse google-http-java-client A parameter with ‚Äò=‚Äô in the value is misinterpreted
5)Separate representation for special characters :Recall
that the Static Analyzer derives special characters that arepassed to the Test Generator. These characters appear directlyin the implementation. Hence, they should be given moreimportance over other characters in the charset, while gener-
ating the test strings. In D
Œîthe transition symbols contain
a range of symbols merged into a single transition. Thesesymbols may include special characters, S
EGATE represents
each of which on a separate transition edge. To introducethese separate transitions the partition function (Algo. 2, line
7) performs splitting of the symbol range. For instance, a
transition with symbol range a-g , having das a special
character, would be split into three transitions with respectivesymbol ranges as a-c ,dand e-g . Analogous to splitting
the transition, D
twould introduce additional State Pair Node
with corresponding symbols set according to the separated
transition edge. On traversing Dt, these special character
edges are given higher priority over other edges (Algo. 3,line 8). Doing so provides the advantage of generating stringscontaining special characters.
Design decisions and trade-offs: The Static Analyzer as-
sumes that if a variable is tainted, then the constraints onit are relevant to infer r
iof the input that tainted it. For
instance, in Listing 2 from Section II, decoded is tainted by
the input encoded as the inter-procedural analysis results in
decodeToString invocation returning a tainted output. Hence,
the taint is propagated on to decoded . As a result, the
subsequent call on decoded.split(":") induces the constraint
of ":" being present in decoded as well as encoded . The
constraint on encoded is valid for the given example, as
inferred by studying the nature of manipulation on encoded
bydecodeToString . However, in general, this propagation of
constraint on the actual input may not always result in an
accurate inference. The analyzer could possibly relax theconstraint on the input into a ‚Äòpossible‚Äô occurrence instead of‚Äòstrict‚Äô occurrence. However, this relaxation would increase theexploration space of strings. Due to scalability consideration,the analyzer imposes strictness on such constraints.
Due to the size of the differential automaton being large,
capturing every transition edge would not scale. As a result,we applied the transformation to D
tto allow covering equal
or relatively more number of paths of string sequences thanthe number we could have covered on D
Œî. To generate a
reasonable number of test strings, we ignore paths on whichthe nodes have been visited before. While this allows theapproach to scale and results in a set of test strings representingthe gap, it comes with a trade-off on missing certain interestingTABLE III: Evaluation Data Description.
Data description Value
# Faulty methods analyzed 34
Code size (LOC) Mean: 495 Stdev.: 676.9
Range of code size (LOC) 14 - 2955Call-graph depth Mean: 31 Stdev.: 44.6Range of Call Graph size 1 - 176
TABLE IV: Performance of S EGATE in exposing defects.
Metric Value
# Known defects in dataset 34# New defects exposed using S
EGATE 6
# Known defects exposed by S EGATE 26
# Total defects exposed by S EGATE 32 (of 40)
# Test strings generated per run Mean: 1346 Stdev.: 2894
Range of # of test strings generated 2 - 12266Execution time(s) per run Mean: 8.23 Stdev:. 9.05Memory consumption(MB) per run Mean: 60.89 Stdev.: 15.58
paths from the perspective of producing defect revealing
strings. Improving on the traversal heuristics would be of our
interest.
IV . E XPERIMENTAL EV ALUATION
We evaluated S EGATE on its ability to expose defects in a
method or its speciÔ¨Åcation. We ran S EGATE : i) on methods
with known defects to verify if it generated test inputs to
expose the defects ii) on methods in popular libraries withthe objective to expose potential defects iii) to assess itsperformance relative to state-of-the-art techniques.
All evaluations were performed on a Windows 10 64-bit
system with Intel Core i7-5500U 2.40GHz processor with 8GB
RAM and maximum JVM heap-size of 4GB. S
EGATE has
been built over Eclipse Mars 4.5.2 IDE running with Java 1.8.The dataset and results are available at the project website.
3
A. V erifying against known defects
1)Methodology :We picked commonly used string struc-
tures, often used in research [17], to evaluate program methodstaking such structured input. These structures include Ô¨Ålepath, URL, JSON format, IP address, phone number, email
and credentials. To prepare a benchmark dataset with known
defects, we extracted top 30 starred Java projects on GitHub.Filtering on keyword search over these repositories on thestructure names mentioned, we obtained 14 projects that had at
3https://github.com/pag-iiitd/Segate

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. least one method taking at least one such structure as input. We
inspected the issue trackers of these 14 projects and extractedissues labeled as defect. We considered defects no older thanreported in the year 2012, to avoid the scenario where themethod of concern is obsolete. We further picked 1 moreproject which has been frequently referred to in some of these14 projects and followed the same Ô¨Åltering approach on it.This resulted in analyzing issues in 15 open-source projects.From the Ô¨Åltered issues, we shortlisted defects discussingmethods that take at least one parameter as a string-basedstructured input and discuss one or more of the followingcases: i) there is a difference in what the documentation orthe referenced speciÔ¨Åcations state and the code behavior; ii)there is a practical use-case that is not handled well by theimplementation. Some such defects are listed in Table II.
We obtained a dataset of 34 such defects in distinct methods,
across 15 libraries. Corresponding to every method were Java
documentation or external documentation, describing the input
structure. If our recommender system lacked a relevant regexannotation ( r
s), we assigned an annotator, a computer science
graduate having a development experience of 2 years inJava, with the task of deriving r
sfrom the documentation.
The annotator was provided with the documentation of thefaulty method and the method parameter for which we requireobtaining r
s. To avoid bias, the annotator was not informed
about the purpose of the study. One of the authors performedthe same task to validate the annotations derived. For 85%methods in our dataset, the documentation referred to external
sources, such as RFCs, that contained grammar deÔ¨Åning the
syntax of the string input. The annotators were required toderive r
sfrom the grammar. A manual annotation on an
average required 18 minutes. This exercise was required for
19 of the 34 methods. For the remaining 15 methods, basedon our domain knowledge, we felt that the recommendationforr
s, returned by our system, is Ô¨Åt for usage. To assess the
inter-rater agreement, the free-marginal kappa score [18] was
computed as 0.68, which is rated as ‚Äòfair to good‚Äô [19]. In 3of the 19 annotations, there was a minor disagreement amongannotators, which was resolved over discussion.
The Ô¨Ånal annotation, r
s, was then fed to S EGATE to generate
test strings complying with expression 6. These annotations
were added in the recommendation repository for future
query. As the repository expanded, we observed improvedrecommendations. This indicates the usefulness of manualintervention, in annotating, as the domain-knowledge gainedfrom experienced developers contribute to strengthening therecommendations.
We ran S
EGATE on the faulty methods in our dataset to
check if it generated test inputs to expose the defects. We
assess S EGATE on the number of defects exposed by its tests,
and its execution time and memory usage. Table III gives astatistical description of the nature of programs in our dataset.The description includes the range and the average size of
the code (LOC), over 34 faulty methods. The code size is a
count on the number of distinct statements (including inter-procedural method body), in Jimple representation, visited byListing 3: Snippet indirectly manipulating occurrence of ‚Äò,‚Äô.
1 while(index < json . length () )
2 { char current = json . charAt(index);
3 if ( current = = ‚Äô{‚Äô) inObject++;
4 if ( current = = ‚Äô}‚Äô) inObject ‚àí‚àí;
5 if ( current = = ‚Äô[ ‚Äô) inList++;
6 if ( current = = ‚Äô] ‚Äô) in List‚àí‚àí;
7 if ( current = = ‚Äô,‚Äô & & inOb ject = = 0 & & inList = = 0) {
8 list .add(build . toString () );9 build . setLength (0) ; }
1 0 else build . append ( current );
1 1 index++; }
the Static Analyzer. The call-graph depth refers to the depth
of method invocations involved in the method under analysis.
2)Results :SEGATE generated test strings exposing 26
of the 34 known defects. Table IV gives the details of theexecution time and memory consumption of S
EGATE , with
values averaged over 10 executions over every method. Overeach program, S
EGATE executed in a matter of a few seconds,
not exceeding 40 seconds, with the mean value of 8.2 seconds.Discounting the memory consumed by the garbage collector,
S
EGATE ‚Äôs memory consumption on execution ranged between
43 to 106 MB, as evaluated on every method in the dataset.
For the 8 defects missed by S EGATE , following are the key
observations to infer the reason for failure.
i.Indirect manipulation on position of characters in the
string : Consider the faulty method reported in the defect,
Spring-Boot-11992, which constrains the occurrence ofcomma (‚Äò,‚Äô) relative to ‚Äò[‚Äô, ‚Äò]‚Äô, ‚Äò{‚Äô and ‚Äò}‚Äô (statement 7 ofListing 3). This constraint is enforced by integral coun-ters. The Static Analyzer does not currently support mak-ing such precise inferences from numeric manipulation onstrings. The analyzer infers the occurrence of comma (‚Äò,‚Äô)anywhere in the string. Hence, S
EGATE misses exposing
the defect. However, the analyzer has basic support forinference of regex from character position. For instance,str .charAt(2)==‚Äò:‚Äô results in a regex indicating ‚Äò:‚Äô at third
position in str. Index-based manipulation on substrings is
handled based on certain templates to infer the positionas either at front, last or in between the string.
ii.Missing explicit checks from the speciÔ¨Åcation as well as
the implementation : The case reported in V ALIDATOR-
420 is about a validation method incorrectly accepting urlcontaining a space character. As both, the speciÔ¨Åcationand the implementation, do not have an explicit con-straint barring occurrence of a space in a url, S
EGATE
misses exposing the defect. As the charset of invalidcharacters may be huge, we do not currently consideroccurrence of a character, while modeling r
iandrs,i f
it does not explicitly appear in the implementation or
the speciÔ¨Åcation. We would be interested in obtaining
implicit characters that are common sources of errors,in the future. Nonetheless, adding the space (‚Äò ‚Äô) in thecharset of r
sallowed S EGATE to reveal the defect.
B. Exposing unreported defects
1)Methodology :With an objective to explore new defects,
we picked the Ô¨Årst 20 test strings generated (or all if # test

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. TABLE V: List of unknown defects from popular libraries exposed by S EGATE .
No. MethodName Library Defect Description
1. Files.getFileExtension Google Guava The method does not handle ADS Ô¨Åle paths supported in NTFS
2. InetAddresses.isInetAddress Google Guava Gives false positive for ipv6 address in certain cases of occurrence of 0s
such as in the last bit group for 804C:404C::0:CC:C0:00C0C
3. JsonParser.parse Spring-Boot Several validation checks missing in JsonParser- no check on closing ‚Äò}‚Äô
4. PhoneNumberUtil.parse libphonenumber SpeciÔ¨Åcations from the RFC reference in the documentation are loose as
compared to the stricter checks in the actual implementation
5. UriUtils.extractFileExtension Spring Validation check missing on the url path6. InetAddressValidator. isVa-
lidInet6AddressApache Validator Does not account for presence of scope id in the IP address
strings < 20) for each of the faulty methods obtained in Section
IV-A and passed them as inputs to the respective method.The obtained output for every input was logged. The potentialdefects may not necessarily lead to an exception throw; theprogram could silently give an unexpected output. Hence, we
manually studied the logged output to look out for unexpected
output, indicative of an exposed defect, based on the intendedbehavior speciÔ¨Åed in the documentation. Note that our workcontributes in generation of quality test inputs to help a testerprioritize the tests. We leave it to the tester to validate theprogram‚Äôs behavior on the test inputs and decide whether the
implementation or the documentation should be altered.
2)Results :By manual inspection, we could spot 4 new
defects in the methods in our dataset. On increasing the limit
to inspecting Ô¨Årst 150 test strings for each method, we explored
2 more new defects. Table V lists these new defects exposed by
S
EGATE . These defects varied in nature, discussed as follows
i.Missing validation checks leading to false positive output :
Third defect (Table V) is about missing validation checks
in code, accepting invalid JSON inputs without throwingan exception. Second and Ô¨Åfth defects have similar nature.
ii.Missing support for certain inputs in the implementation
when the documentations implicitly support them : First
and sixth defects in Table V fall in this category. In the
former, the Ô¨Åle path containing alternate data stream is a
feature of NTFS Ô¨Åle system, however, the implementationdoes not account for it while extracting the Ô¨Åle extension.
iii. Requiring changes in the documentation when the imple-
mentation has a stricter check while the documentation
is lenient on the structural or functional constraints : This
follows from the fourth defect (Table V) where the doc-umentation mentions supporting phone number formatas per RFC 3966. However, the grammar describing theformat in the RFC is relaxed as compared to the methodimplementation, which has stricter checks on the number
of digits appearing in the number.
We have reported these defects to the developers. One defect
had already been Ô¨Åxed before we reported, thus validating thedefect. We have so far received validation of four defects.
C. Comparative evaluation of S
EGATE
1)Undirected Fuzz T ester :To compare our technique
with black-box undirected fuzzing, we implemented such a
fuzzer using a semi-randomized string generation approach.To generate meaningful strings, the fuzzer derives automaton
from the annotated rsfor every method in our dataset and
generates test strings accepted by the automaton using depth-Ô¨Årst approach, traversing random paths. Usage of r
sin this
approach makes the fuzzer as purely speciÔ¨Åcation-based. Foreach method, the fuzzer generated same number of test stringsas generated by S
EGATE . Due to the randomized nature of the
undirected fuzzer we computed each result over 10 programexecutions. We considered defect detection as successful ifthe fault revealing string was generated in at least 5 of 10
executions.
Results :Table VI gives the comparative summary of
S
EGATE and the undirected fuzzer. Column ‚ÄòGen. ‚Äô denotes the
status of generation of defect-revealing string by the respective
technique. On a set of 40 defects, while S EGATE exposed 32
defects, the undirected fuzzer exposed 16 defects. Of these16 cases, for 2 cases the undirected fuzzer generated thefault revealing string for only 6 and 7 of the 10 executions,respectively, indicating unreliability of the technique. On the
other hand, S
EGATE uses a deterministic approach.
The undirected fuzzing technique missed the defect when
the defect-revealing input had one of the following properties.
i. The input does not comply with the speciÔ¨Åcations but it
is still accepted by the implementation due to missing orweak validation checks in the code.
For the above case, the defects could not be exposed by the
generated strings that already comply with the speciÔ¨Åcations.Thus, considering the implementation becomes necessary.
ii. We also observed defects in which the defect-revealing
string complied with the speciÔ¨Åcation but it was missedby black-box undirected fuzzing. This happens due to thelarge space of compliant strings, reducing the probabilityof generation of tests having the defect-revealing nature.
S
EGATE improves the probability of generation of tests
revealing unhandled boundary cases by eliminating trivialtests by using the differential approach (section III-B). Inour dataset, we did not Ô¨Ånd any defect exposed by the
undirected fuzzer which S
EGATE was unable to expose.
For a tester, it may be infeasible to evaluate a method on
a large test set. Hence, we picked the Ô¨Årst 20 test stringsgenerated by both the techniques to observe if the defect-
revealing strings appear in the set. Column Atin Table VI
denotes the position of occurrence of the defect-revealing

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. TABLE VI: Performance comparison of S EGATE with Undirected fuzzer and EvoSuite in generating fault exposing inputs.
No. BugId SEGATE Undirected Fuzzer EvoSuite
# Test Inputs Gen. At # Test Inputs Gen. At # Test Inputs Gen.
1. async-http-client-1071 7217 √ó - 7217 √ó - 45 /check
2. async-http-client-1110 3439 /check 1 3439 /check 1 156 /check
3. async-http-client-1455 2368 √ó - 2368 √ó - 156 √ó
4. GreenMail-213 1638 /check 2 1638 √ó - 7 √ó
5. Guava-1462 203 /check 12 203 /check 125 8 √ó
6. Guava-1557 1093 /check 1 1093 /check 8 10 √ó
7. Guava Files‚àó203 /check 2 203 /check 14 8 √ó
8. Guava InetAddresses‚àó1042 /check 119 1042 √ó - 10 √ó
9. http-392 91 /check 4 91 /check 3 17 √ó
10. IO-483 70 /check 1 70 √ó - 31 /check
11. IO-499 8 /check 2 8 √ó - 20 √ó
12. IO-545 243 /check 176 243 /check 244 27 /check
13. IO-552 133 /check 1 133 √ó - 30 /check
14. IO-559 95 /check 64 95 √ó - 39 √ó
15. IO-567 195 /check 9 195 /check 25 27 √ó
16. LANG-1374 3 /check 1 3 /check 1 1 √ó
17. LANG-1395 239 /check 1 239 /check 1 147 √ó
18. libphonenumber-1672 12266 √ó - 12266 √ó - 12 √ó
19. libphonenumber PhoneNumberUtil‚àó12266 /check 1 12266 √ó - 12 √ó
20. NET-582 202 /check 1 202 √ó - 10 /check
21. okhttp-2202 135 /check 1 135 √ó - 8 √ó
22. okhttp-2549 127 /check 8 127 √ó - 10 √ó
23. okhttp-2842 228 /check 8 228 √ó - 8 /check
24. okhttp-2939 9679 /check 181 10 √ó - 10 /check
25. SHIRO-375 95 /check 2 95 /check 23 24 √ó
26. Spring UriUtils‚àó36 /check 3 36 √ó - 18 √ó
27. Spring-15786 36 √ó - 36 √ó - 18 √ó
28. Spring-Boot-3273 56 /check 3 56 /check 44 25 √ó
29. Spring-Boot-6121 62 /check 13 62 /check 31 0‚àó‚àó√ó
30. Spring-Boot-12325 4451 /check 5 4451 /check 75 0‚àó‚àó√ó
31. Spring-Boot-12297 152 /check 1 152 √ó - 115 √ó
32. Spring-Boot-11992 152 √ó - 152 √ó - 130 √ó
33. Spring-Boot JsonParser‚àó152 /check 78 152 √ó - 130 /check
34. TEXT-118 2 /check 1 2 /check 1 10 /check
35. UrlBuilder-5 270 /check 1 270 /check 5 214 √ó
36. UrlBuilder-39 214 /check 7 214 √ó - 8 √ó
37. V ALIDATOR-411 180 √ó - 180 √ó - 11 √ó
38. V ALIDATOR-419 254 √ó - 254 √ó - 62 √ó
39. V ALIDATOR-420 180 √ó - 180 √ó - 11 √ó
40. V ALIDATOR InetAddressValidator‚àó254 /check 2 254 /check 23 62 √ó
# Faults Exposed 32 16 10
‚àóindicates new defect exposed by S EGATE‚àó‚àóindicates defective method was not covered by EvoSuite
string in the test set returned by the respective technique for a
method. The computed value has been averaged over positions
obtained from 10 executions for the undirected fuzzing.
Using S EGATE , for 27 of the 32 successfully exposed
defects, the defect-revealing string appeared in Ô¨Årst 20 tests.Further, for 25 of the 27 defects, the relevant test stringappeared in Ô¨Årst 10 tests. This observation is attributed tothe priority given to edges denoting special characters whiletraversing the differential automaton to generate test strings.
For 5 cases where the relevant string did not appear in top 20,
it was observed that leading strings contained other specialcharacters (other than those speciÔ¨Åc to the defect in question)with equal priority, thus, pushing the defect-revealing stringto lower position. Assigning priority among special characterscould be subjective to the nature of the defect, hence, we leavedeveloping heuristics for doing so for the future.
Using the undirected fuzzer, of the 16 successfully revealed
defects, for 8 cases the relevant test string appeared in the Ô¨Årst
20 tests, on an average. Further, for 7 of those 8 cases, thedefect-revealing test string appeared in Ô¨Årst 10 tests. For these7 cases, we observed the nature of the relevant test stringwhich in all the cases required occurrence of one or morespecial characters. The construct of the associated r
sallowed
occurrence of the special character(s) in high probability,resulting in a higher chance of defect-revealing string beinggenerated by undirected fuzzing. For instance, for a regex^[%/][0-9A-Fa-f]+$ there is a high chance of the percentage(‚Äò%‚Äô) appearing in a string generated by undirected fuzzing.
2)F eedback-directed Fuzz T ester :Randoop [14] generates
test-suites using a feedback-directed approach to iteratively

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. TABLE VII: ConÔ¨Åguration settings‚àóused in tools.
Tool Parameter Value
EvoSuite Dminimize false
JPFsymbolic.dp choco
symbolic.string_dp automata, satlistener gov.nasa.jpf.symbc.sequences.
SymbolicSequenceListener
‚àódefault values have been used for parameters other than those mentioned.
build an input. Randoop uses feedback, from the execution
of legal method sequences, to guide the search towards anew sequence resulting in new object states. We executedRandoop-4.1.0 ten times, using the default conÔ¨Åguration, on
every faulty method in our dataset. We have set the default
time-limit of 100 seconds on the execution of Randoop, whichis signiÔ¨Åcantly higher than S
EGATE ‚Äôs average execution time
of 8.2 seconds observed on the dataset. However, Randoop didnot reveal any defect in our dataset. On closely studying the
generated test-suites in ErrorTest and RegressionTest Ô¨Åles, we
observed that most of the generated test inputs were invalidstring-structures. To obtain meaningful tests, we passed a
speciÔ¨Åcation Ô¨Åle to Randoop, describing the pre-condition that
the input matches the corresponding r
s. However, Randoop
appears to check the pre-condition as a Ô¨Ålter after generatingthe tests, hence, not resulting in any useful test input.
3)Coverage-based testing :To assess coverage-based tech-
niques to test for semantic gaps, we executed Symbolic Path-
Finder (SPF) [20] and EvoSuite [21] on our dataset.
a)SPF :SPF uses the analysis engine of Java Path Finder
(JPF), which is a model checking tool for Java programs. SPFcombines path-coverage based symbolic execution technique
with model checking [22] and it is known to have symbolic
string support. We used SPF to verify the generation of teststrings exposing defects in the methods from our dataset. TableVII gives the details of JPF conÔ¨Åguration used in evaluation.
Result: For only one method SPF generated a defect-
exposing test string (BugId IO-552). Major reasons for missingthe rest of the defects are listed as follows.
i. Use of native method calls is not supported by JPF [23].
ii. The path constraints are loosely deÔ¨Åned in the method,
capturing a wide variety of strings. While the solverproduces a Ô¨Ånite set of strings for every path constraint,
it misses generating a string of defect-exposing nature.
iii. Explicit constraints are missing from the implementation
and hence, are not captured by the path traversal approachused by symbolic execution.
To handle the last two cases, S
EGATE leverages the
information-rich speciÔ¨Åcation in addition to the implementa-tion. This allows elimination of redundant tests satisÔ¨Åed byboth- the implementation and the speciÔ¨Åcation, to focus on
generating defect-revealing strings.
b)EvoSuite :EvoSuite generates test-suites using a
search-based approach which optimizes on coverage criterion.We executed EvoSuite-1.0.6, on every class containing theListing 4: Snippet with defect in a path.
1 Documentation : Takes input st ring str , denoting key:
value pairs separated by ‚Äô:‚Äô with key and value
containing alphanumeric characters
2 // Expected to return the substring prec eding ‚Äô: ‚Äô
3 if ( str . charAt( i ) = = ‚Äô: ‚Äô){
4 return str . substring (i+1); // returns substring
succeeding ‚Äô: ‚Äô }
defective methods from our dataset. While conÔ¨Åguring Evo-
Suite, we disabled the test-set minimizer (to prevent exclusion
of any code statement from analysis) and used the defaultcoverage criterion that includes combination of criteria suchas line coverage, branch coverage and method coverage. Dueto the randomized nature of EvoSuite, the readings have been
reported on 10 executions of EvoSuite for each defective
method. We considered a defect as revealed by EvoSuite ifat least one of the ten executions generated a defect revealingtest string.
Result: Of the 40 defects in our dataset, EvoSuite revealed
10 defects (Table VI), with mean coverage of 77.4% overthe 40 cases. Of these 10 defects, one defect (BugId async-http-client-1071) was not revealed by S
EGATE due to over-
approximation resulting from conÔ¨Çuence operation involvedin the dataÔ¨Çow analysis. Hence, the coverage based technique
was found to be more relevant to test for such a defect.
V. S
COPE AND LIMITATIONS
We scope our technique to explore defects arising from gap
in the input speciÔ¨Åcation and the input accepted by the imple-
mentation. There may be defects caused by input that complies
with the speciÔ¨Åcation and accepted by the implementation butmay be handled inappropriately in the implementation- such asperforming an incorrect operation at a path. Consider Listing4 that returns an incorrect sub-string. S
EGATE would derive
the same riandrsforstr,a s^ \ W+:\W+$ . Hence, targeting
the gap between the two would not generate the relevant input.
For such issues, path-coverage based techniques may generatedefect exposing input. Our technique can adapt to generatingpath-covering tests to expose such defects by conÔ¨Åguring r
s
to empty. For testers interested in the occurrence of particular
characters in the test strings, S EGATE also allows prioritization
of user-speciÔ¨Åed or source code derived special characters (‚Äò:‚Äôfrom Listing 4) while generating strings. As our technique
complements path-coverage techniques, we do not intend to
take into account path-coverage oriented defects where thereare no input inconsistencies with the documentation.
VI. R
ELATED WORK
There has been recent focus on defects arising from dif-
ference in the code and the associated documentation. Zhouet al. propose a technique to detect semantic defects in docu-
mentation using program comprehension and natural language
processing [24]. The technique scopes the nature of defects tochecks on range limitation and type restriction. It is based on
the assumption that the code is correct, which may not be thecase, as seen in the listed defects (Table II). S
EGATE attempts

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. to detect relatively broader variety of defects that could occur
either in the documentation or the code.
Tan et al. perform comment analysis to derive program
rules, scoped in the domain of locking protocols [25], [26].These rules are used to detect inconsistencies between com-ments and source code. @TCOMMENT [27] is another ap-proach for testing code-comment inconsistencies where theypropose simple heuristics to analyze free-form text in Javadoccomments related to method properties for null values andrelated exceptions in Java libraries.
Alkhalaf et al. present an input validation technique to check
input structure inferred from validation function against somegiven policies [9]. Similar to our technique, the technique usesdataÔ¨Çow analysis to infer the possible values of the stringin the form of a DFA. However, the approach uses intra-procedural analysis, unlike S
EGATE ‚Äôs inter-procedural analysis
that additionally exploits implicit assumptions in non-updatestring-manipulation functions. Alkhalaf et al. run the string
analysis over validation functions, hence limiting to exposing
input validation defects. SEMREP is a repair tool based on the
proposed technique [28]. By analyzing statements in the entirefunction, our technique goes a step ahead to expose deeperfunctionality Ô¨Çaws, in addition to input validation. While theapproach by Alkhalaf et al. checks compliance with certain
policies, we derive our own deviation policies through D
Œî.
Further, instead of assuming the speciÔ¨Åcation to be correct,we target inconsistencies between the speciÔ¨Åcation and theimplementation, which may result in Ô¨Åxing the speciÔ¨Åcation.
Shahbaz et al. propose to explore defects in routines due
to missing logical paths [29]. They use web search based
approach to gather valid tests and perform mutation overregexes, obtained from web searches, to generate invalid tests.Their approach relies on identiÔ¨Åer names to perform websearch upon to infer structured values. This may, however,not work for identiÔ¨Åers that heavily depend on the context
of occurrence. For instance, identiÔ¨Åer name pair may refer to
credential pairs, JSON key-value pairs or any other pair.
Kim et al. present a grammar-based fuzz testing, called
API-level Concolic Testing (ACT) [30]. To improve codecoverage of black-box testing, ACT derives a fuzzing grammar
from the implementation of the programs taking complex
structured input strings. Their approach, however, overlooksthe speciÔ¨Åcations. We follow a similar path-coverage basedapproach to derive the input structure from the implementa-tion, in the form of a regular expression. However, our focusis on generating test strings targeting missing logical paths,
for which considering the speciÔ¨Åcations becomes essential.
As string manipulation could be a source of vulnerabilities
in security critical programs ([31], [32], [33], [34]), string anal-ysis has been actively researched upon in the last two decades([35], [36]). Christensen et al. present a precise string analysis
which statically extracts Ô¨Çow graph from string operations in a
program to infer the structure of the derived string in the form
of a context free grammar [37]. The technique was shownto be effective in validating syntax of standard inputs likeSQL queries. However, to test a client program the approachis dependent on the existence of an input validator program,
which may not be present in all cases. A documentation ismore likely to be available instead. By generating the shortestpossible counter-example violating the speciÔ¨Åed grammar, thistechnique limits the revelation of several potential defects forwhich a well deÔ¨Åned string generation model may be required.
Several string constraint solvers have been proposed in the
past decade ([38], [39], [40], [41], [42], [43]), indicative of thewide usage and importance of string based structures in pro-grams and the need to verify such programs. However, stringanalysis based testing, using constraint solvers, focus purelyon the paths covered in a program and ignore the absence of
constraint checks in it. Our approach gives due consideration
to the documentation and other sources of input speciÔ¨Åcationsto verify the consistency with the implementation.
VII. C
ONCLUSION AND FUTURE WORK
We presented a test generation technique to expose defects
in a method occurring due to input inconsistencies in themethod documentation and the implementation. Focusing onstructured string inputs, we used static analysis to model
input as regex and comparing with the regex model derivedfrom documentation, we computed strings to expose the gap
between the two models. We evaluated our technique‚Äôs imple-mentation in our tool, S
EGATE , which exposed defects in pop-
ular libraries. To assess the effectiveness in exposing defects,
we compared S EGATE with some of the state-of-the-art test
generation tools. We showed that S EGATE outperformed the
other techniques on a dataset of 40 defects in library methods.
We plan to optimize the regex ( ri) generated by static
analysis, in addition to improving the precision of the StaticAnalyzer to support complex numeric manipulation on strings.
Other area of optimization is in reducing the test set bydiscarding highly similar strings. Determining the criteria ofsimilarity would be of our interest [44]. Incorporation of user-
deÔ¨Åned speciÔ¨Åcation constraints, when deÔ¨Åning the criteria of
similarity among inputs, could be one direction.
Further, a search-based approach to Ô¨Ånd behaviorally similar
regex [45] may be useful to fully automate regex repair or
recommendation. We would also be interested in integratingpast techniques proposed on comment analysis [46], [47] with
S
EGATE to assess their effectiveness in inferring the input
string‚Äôs properties in deriving rs.
ACKNOWLEDGEMENTS
We thank the anonymous reviewers and Prof. Myra Co-
hen for their valuable feedback on this work. This work issupported in part by the Department of Science and Technol-
ogy (DST) (India), Science and Engineering Research Board
(SERB), Confederation of Indian Industry (CII), MicrosoftResearch, and Infosys Centre for ArtiÔ¨Åcial Intelligence at IIITDelhi. We thank Dhriti Khanna, who performed the annotationexercise to derive r
s.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] M. B√∂hme, V .-T. Pham, and A. Roychoudhury, ‚ÄúCoverage-based grey-
box fuzzing as markov chain,‚Äù in Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security , ser. CCS ‚Äô16.
ACM, 2016, pp. 1032‚Äì1043.
[2] M.-T. Trinh, D.-H. Chu, and J. Jaffar, ‚ÄúS3: A symbolic string solver for
vulnerability detection in web applications,‚Äù in Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications Security ,
ser. CCS ‚Äô14, 2014, pp. 1232‚Äì1243.
[3] C. Cadar, V . Ganesh, P. M. Pawlowski, D. L. Dill, and D. R. Engler,
‚ÄúExe: Automatically generating inputs of death,‚Äù ACM Trans. Inf. Syst.
Secur . , vol. 12, no. 2, pp. 10:1‚Äì10:38, Dec. 2008.
[4] N. Li, T. Xie, N. Tillmann, J. d. Halleux, and W. Schulte, ‚ÄúReggae:
Automated test generation for programs using complex regular expres-sions,‚Äù in Proceedings of the 2009 IEEE/ACM International Conference
on Automated Software Engineering , ser. ASE ‚Äô09, 2009, pp. 515‚Äì519.
[5] Z. Xu, Y . Kim, M. Kim, G. Rothermel, and M. B. Cohen, ‚ÄúDirected
test suite augmentation: Techniques and tradeoffs,‚Äù in Proceedings of the
Eighteenth ACM SIGSOFT International Symposium on F oundations ofSoftware Engineering , ser. FSE ‚Äô10, 2010, pp. 257‚Äì266.
[6] H. Liu and H. B. K. Tan, ‚ÄúCovering code behavior on input validation in
functional testing,‚Äù Information and Software Technology , vol. 51, no. 2,
pp. 546‚Äì553, 2009.
[7] D. Yang, Y . Zhang, and Q. Liu, ‚ÄúBlendfuzz: A model-based framework
for fuzz testing programs with grammatical inputs,‚Äù in Trust, Security
and Privacy in Computing and Communications (TrustCom), 2012 IEEE11th International Conference on . IEEE, 2012, pp. 1070‚Äì1076.
[8] T. Scholte, W. Robertson, D. Balzarotti, and E. Kirda, ‚ÄúPreventing
input validation vulnerabilities in web applications through automatedtype analysis,‚Äù in Computer Software and Applications Conference
(COMPSAC), 2012 IEEE 36th Annual . IEEE, 2012, pp. 233‚Äì243.
[9] M. Alkhalaf, T. Bultan, and J. L. Gallegos, ‚ÄúVerifying client-side
input validation functions using string analysis,‚Äù in Proceedings of the
34th International Conference on Software Engineering , ser. ICSE ‚Äô12.
IEEE, 2012, pp. 947‚Äì957.
[10] P. Lam, E. Bodden, O. Lhot√°k, and L. Hendren, ‚ÄúThe soot framework
for java program analysis: a retrospective,‚Äù in Cetus Users and Compiler
Infastructure Workshop (CETUS 2011) , vol. 15, 2011, p. 35.
[11] A. Einarsson and J. D. Nielsen, ‚ÄúA survivor‚Äôs guide to java program
analysis with soot,‚Äù BRICS, Department of Computer Science, University
of Aarhus, Denmark , p. 17, 2008.
[12] F. Bourdoncle, ‚ÄúEfÔ¨Åcient chaotic iteration strategies with widenings,‚Äù
inF ormal Methods in Programming and their Applications . Springer,
1993, pp. 128‚Äì141.
[13] A. M√∏ller, ‚Äúdk. brics. automaton‚ÄìÔ¨Ånite-state automata and regular ex-
pressions for java, 2010,‚Äù 2014.
[14] C. Pacheco, S. K. Lahiri, M. D. Ernst, and T. Ball, ‚ÄúFeedback-directed
random test generation,‚Äù in Proceedings of the 29th International Con-
ference on Software Engineering , ser. ICSE ‚Äô07, 2007, pp. 75‚Äì84.
[15] T. F. J. M. Lushan Han, Abhay L Kashyap and J. Weese, ‚ÄúUmbc
ebiquity-core: Semantic textual similarity systems,‚Äù in Proceedings of
the Second Joint Conference on Lexical and Computational Semantics .
Association for Computational Linguistics, June 2013.
[16] J. Hopcroft, ‚ÄúAn n log n algorithm for minimizing states in a Ô¨Ånite
automaton,‚Äù in Theory of machines and computations . Elsevier, 1971,
pp. 189‚Äì196.
[17] M. Shahbaz, P. McMinn, and M. Stevenson, ‚ÄúAutomated discovery
of valid test strings from the web using dynamic regular expressionscollation and natural language processing,‚Äù in Quality Software (QSIC),
2012 12th International Conference on . IEEE, 2012, pp. 79‚Äì88.
[18] J. J. Randolph, ‚ÄúFree-marginal multirater kappa (multirater k [free]): An
alternative to Ô¨Çeiss‚Äô Ô¨Åxed-marginal multirater kappa.‚Äù Online submission ,
2005.
[19] http://justusrandolph.net/kappa/.
[20] C. S. P ÀòasÀòareanu, W. Visser, D. Bushnell, J. Geldenhuys, P. Mehlitz,
and N. Rungta, ‚ÄúSymbolic pathÔ¨Ånder: integrating symbolic executionwith model checking for java bytecode analysis,‚Äù Automated Software
Engineering , vol. 20, no. 3, pp. 391‚Äì425, 2013.
[21] G. Fraser and A. Arcuri, ‚ÄúEvosuite: Automatic test suite generation for
object-oriented software,‚Äù in Proceedings of the 19th ACM SIGSOFT
Symposium and the 13th European Conference on F oundations ofSoftware Engineering , ser. ESEC/FSE ‚Äô11, 2011, pp. 416‚Äì419.[22] W. Visser, C. S. P ÀáasÀáareanu, and S. Khurshid, ‚ÄúTest input generation with
java pathÔ¨Ånder,‚Äù SIGSOFT Softw. Eng. Notes , vol. 29, no. 4, pp. 97‚Äì107,
Jul. 2004.
[23] D. Bushnell, ‚ÄúJpf for beginners,‚Äù http://javapathÔ¨Ånder.sourceforge.net/
events/JPF-workshop-050108/tutorial.pdf, 2008, jPF Workshop 2008.
[24] Y . Zhou, R. Gu, T. Chen, Z. Huang, S. Panichella, and H. Gall,
‚ÄúAnalyzing apis documentation and code to detect directive defects,‚ÄùinProceedings of the 39th International Conference on Software Engi-
neering , ser. ICSE ‚Äô17. IEEE Press, 2017, pp. 27‚Äì37.
[25] L. Tan, Y . Zhou, and Y . Padioleau, ‚Äúacomment: mining annotations from
comments and code to detect interrupt related concurrency bugs,‚Äù in2011 33rd International Conference on Software Engineering (ICSE) ,
May 2011, pp. 11‚Äì20.
[26] L. Tan, D. Yuan, G. Krishna, and Y . Zhou, ‚Äú/*icomment: Bugs
or bad comments?*/,‚Äù in Proceedings of Twenty-Ô¨Årst ACM SIGOPS
Symposium on Operating Systems Principles , ser. SOSP ‚Äô07. New
York, NY , USA: ACM, 2007, pp. 145‚Äì158. [Online]. Available:http://doi.acm.org/10.1145/1294261.1294276
[27] S. H. Tan, D. Marinov, L. Tan, and G. T. Leavens, ‚Äú@tcomment: Testing
javadoc comments to detect comment-code inconsistencies,‚Äù in 2012
IEEE Fifth International Conference on Software Testing, V eriÔ¨Åcationand V alidation , April 2012, pp. 260‚Äì269.
[28] M. Alkhalaf, A. Aydin, and T. Bultan, ‚ÄúSemantic differential repair
for input validation and sanitization,‚Äù in Proceedings of the 2014
International Symposium on Software Testing and Analysis , ser. ISSTA
2014. ACM, 2014, pp. 225‚Äì236.
[29] M. Shahbaz, P. McMinn, and M. Stevenson, ‚ÄúAutomatic generation
of valid and invalid test data for string validation routines using web
searches and regular expressions,‚Äù Science of Computer Programming ,
vol. 97, pp. 405‚Äì425, 2015.
[30] S. Y . Kim, S. Cha, and D.-H. Bae, ‚ÄúAutomatic and lightweight grammar
generation for fuzz testing,‚Äù Computers & Security , vol. 36, pp. 1‚Äì11,
2013.
[31] T. Pietraszek and C. V . Berghe, ‚ÄúDefending against injection attacks
through context-sensitive string evaluation,‚Äù in Proceedings of the 8th
International Conference on Recent Advances in Intrusion Detection ,
ser. RAID‚Äô05. Springer, 2006, pp. 124‚Äì145.
[32] V . B. Livshits and M. S. Lam, ‚ÄúFinding security vulnerabilities in java
applications with static analysis,‚Äù in Proceedings of the 14th Conference
on USENIX Security Symposium - V olume 14 , ser. SSYM‚Äô05, 2005, pp.
18‚Äì18.
[33] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner, ‚ÄúDetecting format
string vulnerabilities with type qualiÔ¨Åers,‚Äù in Proceedings of the 10th
Conference on USENIX Security Symposium - V olume 10 , ser. SSYM‚Äô01,
2001.
[34] F. Yu, M. Alkhalaf, and T. Bultan, ‚ÄúStranger: An automata-based
string analysis tool for php,‚Äù in Proceedings of the 16th International
Conference on Tools and Algorithms for the Construction and Analysisof Systems , ser. TACAS‚Äô10. Springer, 2010, pp. 154‚Äì157.
[35] D. Shannon, S. Hajra, A. Lee, D. Zhan, and S. Khurshid, ‚ÄúAbstracting
symbolic execution with string analysis,‚Äù in Proceedings of the Testing:
Academic and Industrial Conference Practice and Research Techniques- MUTATION , ser. TAICPART-MUTATION ‚Äô07. IEEE, 2007, pp. 13‚Äì
22.
[36] P. Hooimeijer and M. Veanes, ‚ÄúAn evaluation of automata algorithms
for string analysis,‚Äù in Proceedings of the 12th International Confer-
ence on V eriÔ¨Åcation, Model Checking, and Abstract Interpretation , ser.
VMCAI‚Äô11. Springer, 2011, pp. 248‚Äì262.
[37] A. S. Christensen, A. M√∏ller, and M. I. Schwartzbach, ‚ÄúPrecise analysis
of string expressions,‚Äù in Proceedings of the 10th International Confer-
ence on Static Analysis , ser. SAS‚Äô03. Springer, 2003, pp. 1‚Äì18.
[38] A. Aydin, L. Bang, and T. Bultan, ‚ÄúAutomata-based model counting
for string constraints,‚Äù in International Conference on Computer Aided
V eriÔ¨Åcation . Springer, 2015, pp. 255‚Äì272.
[39] A. Kiezun, V . Ganesh, P. J. Guo, P. Hooimeijer, and M. D. Ernst,
‚ÄúHampi: A solver for string constraints,‚Äù in Proceedings of the Eigh-
teenth International Symposium on Software Testing and Analysis , ser.
ISSTA ‚Äô09. ACM, 2009, pp. 105‚Äì116.
[40] P. A. Abdulla, M. F. Atig, Y .-F. Chen, L. Hol√≠k, A. Rezine, P. R√ºmmer,
and J. Stenman, ‚ÄúString constraints for veriÔ¨Åcation,‚Äù in International
Conference on Computer Aided V eriÔ¨Åcation . Springer, 2014, pp. 150‚Äì
166.
[41] P. Hooimeijer and W. Weimer, ‚ÄúA decision procedure for subset con-
straints over regular languages,‚Äù SIGPLAN Not. , vol. 44, no. 6, pp. 188‚Äì
198, Jun. 2009.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. [42] T. Liang, A. Reynolds, N. Tsiskaridze, C. Tinelli, C. Barrett, and M. De-
ters, ‚ÄúAn efÔ¨Åcient smt solver for string constraints,‚Äù F orm. Methods Syst.
Des., vol. 48, no. 3, pp. 206‚Äì234, Jun. 2016.
[43] L. De Moura and N. Bj√∏rner, ‚ÄúZ3: An efÔ¨Åcient smt solver,‚Äù in Pro-
ceedings of the Theory and Practice of Software, 14th InternationalConference on Tools and Algorithms for the Construction and Analysisof Systems , ser. TACAS‚Äô08/ETAPS‚Äô08. Springer, 2008, pp. 337‚Äì340.
[44] T. Ringer, D. Grossman, D. Schwartz-Narbonne, and S. Tasiran, ‚ÄúA
solver-aided language for test input generation,‚Äù Proc. ACM Program.
Lang. , vol. 1, no. OOPSLA, pp. 91:1‚Äì91:24, Oct. 2017.
[45] C. Chapman and K. T. Stolee, ‚ÄúExploring regular expression usage and
context in python,‚Äù in Proceedings of the 25th International Symposium
on Software Testing and Analysis , ser. ISSTA 2016. ACM, 2016, pp.282‚Äì293.
[46] A. Blasi, A. GofÔ¨Å, K. Kuznetsov, A. Gorla, M. D. Ernst, M. Pezz√®,
and S. D. Castellanos, ‚ÄúTranslating code comments to procedurespeciÔ¨Åcations,‚Äù in Proceedings of the 27th ACM SIGSOFT International
Symposium on Software Testing and Analysis , ser. ISSTA 2018. New
York, NY , USA: ACM, 2018, pp. 242‚Äì253. [Online]. Available:http://doi.acm.org/10.1145/3213846.3213872
[47] E. Wong, L. Zhang, S. Wang, T. Liu, and L. Tan, ‚ÄúDase:
Document-assisted symbolic execution for improving automatedsoftware testing,‚Äù in Proceedings of the 37th International Conference
on Software Engineering - V olume 1 , ser. ICSE ‚Äô15. Piscataway,
NJ, USA: IEEE Press, 2015, pp. 620‚Äì631. [Online]. Available:http://dl.acm.org/citation.cfm?id=2818754.2818831

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:09:45 UTC from IEEE Xplore.  Restrictions apply. 