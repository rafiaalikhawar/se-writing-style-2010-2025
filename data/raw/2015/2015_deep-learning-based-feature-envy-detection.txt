Deep Learning Based Feature Envy Detection
Hui Liu∗
School of Computer Science and
Technology, Beijing Institute of
Technology
Beijing, China
Liuhui08@bit.edu.cnZhifeng Xu
School of Computer Science and
Technology, Beijing Institute of
Technology
Beijing, China
848602422@qq.comYanzhen Zou†
Key Laboratory of High Confidence
Software Technologies (Peking
University),Ministry of Education
Beijing, China
zouyz@pku.edu.cn
ABSTRACT
Software refactoring is widely employe d to improve software qual-
ity.Akeystepinsoftwarerefactoringistoidentifywhichpartof
thesoftwareshouldberefactored.Tofacilitatetheidentification,
a number of approaches have been proposed to identify certain
structures in the code (called code smells) that suggest the possi-
bility of refactoring. Most of such approaches rely on manually
designedheuristicstomapmanuallyselectedsourcecodemetrics
to predictions. However, it is challenging to manually select the
best features, especially textual features. It is also difficult to man-
ually construct the optimal heuristics. To this end, in this paper
we propose a deep learning based novel approach to detecting fea-
ture envy, one of the most common code smells. The key insight is
that deep neural networks and advanced deep learning techniques
couldautomaticallyselectfeatures(especiallytextualfeatures)of
source code for feature envy detection, and could automatically
build the complex mapping between such features and predictions.
Wealsoproposeanautomaticapproachtogeneratinglabeledtrain-
ing data for the neural network based classifier, which does not
requireanyhumanintervention.Evaluationresultsonopen-source
applicationssuggestthattheproposedapproachsignificantlyim-
proves the state-of-the-art in both detecting feature envy smells
and recommending destinations for identified smelly methods.
CCS CONCEPTS
•Softwareanditsengineering →Softwaremaintenancetools ;
Object oriented development;
KEYWORDS
Feature Envy, Deep Learning, Software Refactoring, Code Smells
ACM Reference Format:
Hui Liu, Zhifeng Xu, and Yanzhen Zou. 2018. Deep Learning Based Feature
Envy Detection. In Proceedings of the 2018 33rd ACM/IEEE International
∗corresponding author
†Also with School of Electronics Engineering and Computer Science, Peking
University.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3238166Conference on Automated Software Engineering (ASE ’18), September 3–7,
2018,Montpellier,France. ACM,NewYork,NY,USA, 12pages.https://doi.
org/10.1145/3238147.3238166
1 INTRODUCTION
Software refactoring is widely employed t o improve software qual-
ity by restructuring its internal structures whereas its external
behaviorsarekeptunchanged[ 37,42].MostofthemodernIDEs
provide tool support for software refactoring. For example, Eclipse
has a top-level menu specially designed for software refactoring.
Themenuprovidesentriestomostofthepopularsoftwarerefac-
torings investigated by the research community [20, 36,56].
A key step in softwarerefactoring is to identify where refactor-
ings should be applied [ 37]. To facilitate the identification, Beck
andFowler[ 19]proposetheconceptof codesmells thatare‘certain
structures in the code that suggest (sometimes they scream for) the
possibilityofrefactoring ’.Theyintroduce22typesofcodesmells,
includingthewell-known featureenvy andlargeclass.Theyalsoan-
alyze their features, as well as their impact and potential solutions
(refactorings).
However, it is tedious and time consuming to manually identify
codesmells,especiallywhensuchcodesmellsinvolvemorethan
one file or package [ 29,37]. Consequently, a large number of auto-
matic or semi-automatic approaches have been proposed to detect
differentkindsofcodesmells[ 37,47,63].Detailedliteraturereview
and analysis on code smell detection have been made by Zhang et
al.[63],Dallal[15],andmorerecentlybySharmaandSpinellis[ 53].
Most of the existing code smell detection approaches rely on
manually designed heuristics to map manually defined/selected
code metrics into binary predictions, i.e., smelly or non-smelly [ 15,
30,63]. However, i t is challenging to manually select the best
features, especially textual features. It is also difficult to manu-
allyconstructtheoptimalheuristics.Analysisresultsonsuchap-
proaches[ 15,40,63]alsosuggestthatdifferentpeoplemayselect
different metrics and different heuristics for the same code smells,
which results in low agreement between different detectors [ 35].
To avoid manually designed heuristics, statistical machine learn-
ing techniques, like SVM, Naive Bayes, and LDA, are employed to
buildthecomplexmappingbetweencodemetrics(aswellaslexical
similarity)andpredictions[ 11,17].However,empiricalstudies[ 41]
suggestthatsuchstatisticalmachinelearningbasedsmelldetection
approaches have critical limitations that deserve further research.
Tothisend,inthispaperweproposeadeeplearningbasedap-
proach to detecting feature envy, one of the most common code
smells. The key insight is that deep neural networks and advanced
deep learning techniques could automatically select useful features
385
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Hui Liu, Zhifeng Xu, and Yanzhen Zou
from source code (especially textual features) for code smell detec-
tion, and build the complex mapping between such features and
the labels (smelly or not). Deep neural networks and advanced
deep learning techniques have been proved to be good at selecting
usefulfeaturesandbuildingcomplexmappingfrominputtoout-
put automatically [ 60]. With significant advances in deep learning
techniques, they have been successfully used in different domains,
e.g., natural language processing (NLP) [ 44], video processing [ 49],
speech recognition [ 22], and software engineering [ 21]. That is the
reasonwhyweemploydeeplearningtechniquesinthispaperto
build a neural network based classifier that classifies methods in
subject applications into ‘smelly ’ and ‘non-smelly ’.
To train the neural network based classifier, we also propose an
automatic approach to generating labeled training data without
any human intervention. One of the biggest challenges for ma-
chinelearning(especiallydeeplearning)basedsmelldetectorsis
to collect a large number of labeled samples to train the classifiers
(detectors). To collect labeled training data, existing approaches
often rely heavily on manual checking of the initial detection re-
sults of similar smell detectors [ 11,40]. However, manual checking
is time consuming, which significantly limits the size of labeled
training data, and thus prevents machine learning techniques from
reaching their maximal potential. To this end, in this paper we
generatelabeledsamplesautomaticallybasedonopen-sourceap-
plications. We generate negative samples by extracting methods
(and their context) directly from high quality open-source appli-
cations, assuming that such methods are correctly placed in the
originalprograms.Togeneratepositivesamples,wemovemethods
randomlytootherclasseswhereitcouldbemovedbyrefactoring
tools. After the movement, such methods (together with their new
context)aretakenassmellymethods(with featureenvy ).Wecan
generate alarge number ofsuch labeled training databecause the
generation is fully automatic. The large data in turn serve as the
basis of machine learning based smell detection.
The evaluation of the proposed approach is composed of two
parts. In the first part, we evaluate it on 7 well-known open-source
applications with automatically injected feature envy smells. Eval-
uation results suggest that the proposed approach significantly
outperforms existing approaches. It improves F-measure by 34.32%.
In the second part, we evaluate it on 3 open-source applications
wherenosmellsareinjected.Evaluationresultsalsosuggestthat
the proposed approach significantly improves the state-of-the-art.
The paper makes the following contributions:
•A deep learning based approach to identifying feature envy.
To the best of our knowledge, we are the first to apply deep
learning techniques to feature envy detection.
•Anautomaticapproachtogeneratinglabeledtrainingdata
for feature envy detection.
•Evaluation of the proposed approach whose results suggest
that the proposed approach can significantly improve the
state-of-the-art.
Therestofthepaperisstructuredasfollows.Section 2introduces
related research. Section 3proposes the approach. Section 4and
Section5presenttheevaluationoftheproposedapproach.Section 6
discusses related issues. Section 7makes conclusions.2 RELATED WORK
2.1 Feature Envy
BeckandFowler[ 19]proposetheconceptof featureenvy toindicate
such methods that are ‘more interested in a class other than the one
it actually is in ’. To improve software quality and to easy software
maintenance, such misplaced methods should be moved to classes
(by move method refactoring) that they are really interested in.
A number of approaches have been proposed to identify fea-
ture envy or move method opportunities [ 13]. The first one was
proposed by Simon et al. in 2001 [ 54]. They define a distance to
measure how closely two entities are related:
distance(e1,e2)=1−|p(e1)∩p(e2)|
|p(e1)∪p(e2)|(1)
wheree1ande2are two software entities, and p(e)is the set of
properties that are possessed by e.I feis a method, p(e)includese
itself,allmethodsthataredirectlyinvokedby e,andallattributes
that are directly accessed by e.I feis an attribute, p(e)includese
itself,andallmethodsthatdirectlyaccess e.Baseonthedistance
metrics,Simonetal.drawentitiesonagraph,andthegeometric
distances between entities correspond to the distance calculated
by Formula 1. If a method is closer to entities of another class than
those of its enclosing class, it is associated with feature envy.
Sengetal.[ 52]proposeasearchbasedapproachtoidentifymove
method opportunities. They define a fitness function:
fitness(s)=n/summationdisplay.1
i=1wi∗Mi(s)−Minit i(s)
Mmax i(s)−Minit i(s)(2)
wheresis the application to be refactored, M(s)is a vector com-
posed of seven metrics: weighted method count, response for class,
information-flow-basedcoupling,tightclasscohesion,information-
flow-base-cohesion, lack of cohesion, and stability. Minit i(s)is the
initial value of the metrics, and Mmax i(s)is the maximal values
obtained by a calibration run optimizing each metric alone before-
hand.Theyemployasearchalgorithmtofindouttheoptimalclass
structure,aswellasasequenceofmovemethodrefactoringsthat
turn the current system into the optimal one. This approach is the
firstsearch-basedapproachtoidentifyingmovemethodrefactoring
opportunities.
TsantalisandChatzigeorgiou[ 57]proposeametricsbasedap-
proachtoidentifyfeatureenvyandmovemethodopportunities.For
each entity e(attribute or method), they collect a set of the entities
(notedas Se)thatitaccesses(ifitisamethod)oritisaccessedfrom
(if it is an attribute). They also define the distance between method
mand class C.I fmdoes not belong to C, the distance is computed
as follows:
distance(m,C)=1−Sm∩SC
Sm∪SC,where SC=/uniondisplay.1
ei∈C{ei}(3)
Otherwise, the distance is computed as follows:
distance(m,C)=1−Sm∩S/prime
C
Sm∪S/prime
C,where S/prime
C=SC\{m}(4)
Basedonthisdistancemetrics,theysuggesttomovemethod eto
classCtarдetif 1)Ctarдethas the shortest distance to eand 2) the
movement satisfies some preconditions that ensure the movement
will not change the external behaviors of the involved application.
386
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Deep Learning Based Feature Envy Detection ASE ’18, September 3–7, 2018, Montpellier, France
ThedistanceisdifferentfromthatdefinedbySimonetal.[ 54].The
lattermeasuresthedistancebetweentwomethods(orattributes)
whereas theformer measuresthe distancebetween a methodand
a class. This approach has been implemented by JDeodorant,a
well-known,powerful,andopen-sourcecodesmelldetectiontool.
JDeodorant isthemostcommonlyusedbenchmarkincodesmell
detection research community.
Sales et al.[ 51,55] propose a dependency based approach (called
JMove)toidentifyfeatureenvy.Theydefineametricstomeasure
the similarity of the dependencies established by a source method
withthedependenciesestablishedbythemethodsinpossibletarget
classes.Basedonthismetrics,theyrepresentthesimilaritybetween
methodmand class cas the average similarity between mand
methods in c. They suggest to move method mto classcifchas
the greatest similarity with m. Their evaluation results suggest
thatJMoveishighlyaccurateanditoutperformsthewell-known
JDeodorant in identifying feature envy.
Bavota et al. [ 13] exploit textual information in feature envy de-
tection.TheyrecommendmovemethodopportunitiesviaRelational
Topic Models (RTM), a statistical mode. This model is employed to
computetherelationshipamongmethodsaccordingtostructural
similarity between methods as well as textual information (e.g.,
identifier names and comments) extracted from the source code. It
isthe firstapproachtoidentify movemethodopportunitiesbased
on textual information besides source code structures. Palomba
et al. [48] also exploit textual information to detect code smells,
including feature envy. If a method is lexically more similar to an-
other class than its enclosing class, they suggest that the method is
associated with feature envy.
Palomba et al. [ 45] propose a change based approach to iden-
tifyfeatureenvy.Theyassumethatamethodaffectedbyfeature
envy changes more often with the envied class than with the class
whereitisdefined.Consequently,ifamethod misinvolvedincom-
mits with methods of another class ( Ctarдet) significantly more
often than methods of its enclosing class, they suggests to move
mtoCtarдet. They are the first to identify feature envy by mining
version histories of source code.
Liu et al. [ 31] propose a novel approach to recommend move
method opportunities based on conducted refactorings. Once a
methodmis moved from class Csourceto another class Ctarдet,
theapproachchecksothermethodswithin Csource,andsuggests
to move the method who has the greatest similarity and strongest
relationship with m. The rational is that similar and closely related
methodsshouldbemovedtogether.Theyarethefirsttoidentify
move method opportunities based on refactoring history.
The proposed approach differs from such approaches in that
it exploits deep learning techniques and generates training dataautomatically. The proposed approach is the first one to detect
feature envy with deep learning techniques.
2.2 Machine Learning Based Smell Detection
Withtheadvanceinmachinelearningtechniques,anumberofma-
chine learning based smell detection approaches are proposed [ 11].
Kreimer[ 28]proposesadecisiontreebasedapproachtoidentify
code smells, e.g, long method andlarge class. Vaucher et al. [ 26,
27,58] apply Bayesian beliefs networks to detect God class (Blob澷濣濦濤濩濧澻濙濢濙濦濕濨濝濣濢澔濣濚澔
濈濦濕濝濢濝濢濛澔澸濕濨濕濈濦濕濝濢濝濢濛澔濣濚澔
濨濜濙澔澷濠濕濧濧濝濚濝濙濦
澻濙濢濙濦濕濨濝濣濢澔濣濚澔
濈濙濧濨濝濢濛澔澸濕濨濕澸濙濨濙濗濨濝濣濢澔濣濚澔澺濙濕濨濩濦濙澔澹濢濪濭 濇濣濩濦濗濙澔
澷濣濘濙澷濠濕濧濧濝濚濝濙濦
Figure 1: Overview of the Proposed Approach
class).Maigaetal.[ 33,34]exploitSupportVectorMachine(SVM)
in detection of Blob class, and the same technology is employed
byAmorimetal.[ 10]todetect Blobclass, longparameterlist ,long
method, and feature envy. Fontana et al. [ 16–18] compare different
machine learning techniques (including J48, JRip, ERandom Forest,
Baive Bayes, SMO, and LibSVM) in predicting the severity of code
smells, e.g., God class, data class, long method, and feature envy.
Suchmachinelearningbasedapproacheshaveprovedtobeef-
fectiveandefficientalthoughsomeexperimentalevaluationalso
revealstheirsignificantlimitations[ 41].Theproposedapproachdif-
fersfromsuchapproachesintheflowingaspects.First,theproposed
approachexploitsdeeplearningwhereastheyexploittraditional
statisticalmachinelearningtechniques.Second,theproposedap-
proach generates training data automatically whereas they collect
training data manually with the help of smell detection tools.
3 APPROACH
In this section, we propose a deep learning based approach to
identify feature envy. An overview of the proposed approach is
presentedinSection 3.1,anddetailsarepresentedintherestofthis
section.
3.1 Overview
Fig.1presents the overview of the proposed approach. Based
on a large corpus of software applications, it generates a huge
number of training samples (i.e., methods with or without feature
envy). Such training samples are employed to train a neural net-
work based classifier whose output indicates whether the input
methodmfromclass ecenviesanotherclass tc.Atpredictionphase,
for a given method mwe select a set of potential target classes
tc={c1,c2...,ck}, and predict with the resulting neural network
whethermshouldbemovedtoanyofthem.Detailsoftheproposed
approach are presented in the following sections.
3.2 Input
To decide wether a given method mshould be moved from its
enclosing class ecto another class tc, we exploit both structural
information(codemetrics)andtextualinformation.Concerningthe
structural information, we reuse the distance metrics (as presented
inFormula 3andFormula 4)proposedbyTsantalisandChatzigeor-
giou [57]. We reuse such metrics because of the following reasons:
•First, they have been proved effective in feature envy detec-
tion [57].
•Second,theopen-sourceimplementationof JDeodorant makes
it easy to extract such metrics.
387
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Hui Liu, Zhifeng Xu, and Yanzhen Zou
澢澢澢
澢澢澢 濋澜濨澝澽濢濤濩濨 激濕濭濙濦 澼濝濘濘濙濢 激濕濭濙濦濃濩濨濤濩濨 激濕濭濙濦
濉澜濊澞濂澝
濊澔澛澜濂澞澥澝濋澜濨澡濟澝
濋澜濨澡濟澟澥澝
濋澜濨澟濟澝
澢澢澢 澢澢澢
澢澢澢濊澜濂澞濊澝澢澢澢
Figure 2: Model of Word2Vector
Besides the metrics, we also exploit textual information, includ-
ingthenameofthemethodtobeinvestigated,thenameofitsenclos-
ing class, and the name of its potential target class. The essence of
featureenvyisthat somemethods are misplaced.Ideally,a method
should be declared within the class whose role should have the
behavior of the method. We may identify whether a given method
should be declared within a given class by investigating the se-
mantical relationship between their identifiers because meaningful
identifierscanrevealtheroles/behaviorsoftherelatedentities[ 12].
As a conclusion, the input of the approach is a quintuple:
input=<name(m),name(ec),name(tc),
dist(m,ec),dist(m,tc)> (5)
wherename(e)is the identifier (method name or class name) of
software entity e.mis the method under investigation, ecis the
enclosingclassof m,andtcisthepotentialtargetclass. dist(m,c)
is the distance between method mand class ccomputed according
to Formula 3or Formula 4.
However, it is challenging to recover automatically the semanti-
cal relationship embedded in method names and class names. Lexi-
calsimilarityaloneisofteninsufficientinmeasuringthesemantical
relationshipbetweensoftwareentities.Forexample,lexicallydis-
similar software entities (e.g., CollectCandidates andRecommender-
System)couldbecloselyrelatedinsemantics.Consequently,tofully
exploitthesemanticsembeddedinnaturallanguages,weshould
employ some advanced technologies, e.g., deep learning, to extract
moreusefulfeaturesfromsuchtextualinput.Besidesthat,itisalso
challengingtoquantitativelyrelatetextualfeaturestonumerical
feature(codemetrics)withhandcraftedheuristics.Theproposed
approach handles these challenging issues in following sections.
3.3 Representation of Identifiers
To feed the identifiers described in nature languages into neu-
ral networks, we convert words in identifiers into fixed-length
numerical vectors. The conversion is accomplished by the well-
knownword2vector (continuousskipgram)proposedbyMikolov
et al. [38,39].Word2vector has been proved efficient for learning
high-qualitydistributedvectorrepresentationsthatcaptureprecise
syntactic and semantic word relationships [ 39].Word2vector is es-
sentiallyaneuralnetworkthatpredictsnearbywords,i.e.,words
before and after it (as shown in Fig 2). Once the network is trained,
澹濡濖濙濘濘濝濢濛
澺濠濕濨濨濙濢澷濂濂
濁濙濦濛濙澺濠濕濨濨濙濢澷濂濂
澸濙濢濧濙
濃濩濨濤濩濨
ݐݏ݅݀ሺ݉ǡܿ݁ሻ
ݐݏ݅݀ሺ݉ǡܿݐሻ݁݉ܽ݊ሺ݉ሻ
݁݉ܽ݊ሺܿ݁ሻ
݁݉ܽ݊ሺܿݐሻ
Figure 3: Neural Network based Classifier
we can exploit the hidden layer, a byproduct of the training, to
convert words into numerical vectors.
For a given identifier (method name or class name), we parti-
tion it into a sequence of words according to capital letters and
underscores, and convert each word into a fixed-length numerical
vector:
name(e)=<w1,w2,...,wk> (6)
=<V(w1),V(w2),...,V(wk)> (7)
name(e)istheidentiferofsoftwareentity e,and<w1,w2...,wk>
is a sequence of words. V(wi)converts word wiinto a fixed-length
(200 dimensions) numerical vector with word2vector.
Tofacilitatethedesignofneuralnetworks,welimitthelength
of word sequence for each identifier to five. Our analysis results
on open-source applications (as introduced in Table 1) suggest that
98.5%=(184,613/187,377)oftheinvolvedidentifierscontainnomore
than five words. If an identifier contains more than five words,
weextractthefirstfivewordsonly.Incontrast,ifitcontainsless
thanfivewords,weappendspecialcharacters(whosevectorsare
composed of zeros only) to the sequence.
3.4 Deep Neural Network based Classifier
The structure of the deep neural network based classifier is pre-
sentedinFig. 3andsourcecodeisavailableonline[ 61].Itsinput
is divided into two parts: textual input and numerical input. Thetextual input is a word sequence by concatenating the name ofthe method, the name of its enclosing class, and the name of the
potentialtargetclass.ItisfedintoanembeddinglayerthatconvertstextdescriptionintonumericalvectorsasintroducedinSection 3.3.
Such numerical vectorsare in turn fed into aConvolutional Neural
Network (CNN). In total we have tree CNN layers whose setting is
asfollows: filters=128,kernel size =1andactivation =tanh.
We exploit CNN because of the following reasons. First, signifi-
cantadvancesinCNNhavebeenachievedrecently,whichmakes
CNN effective in increasing the capacity and flexibility of machine
learning [ 62]. Powerful CNN layers may learn the deep semantical
relationship among the identifiers, and thus may reveal where the
methodshouldbeplaced.Second,CNNiswell-suitedforparallel
computation on modern powerful GPU, and thus can significantly
reducetrainingtime[ 50].TheoutputofCNNisforwardedtoa flat-
tenlayer [23] which turns its input into a one-dimensional vector.
388
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Deep Learning Based Feature Envy Detection ASE ’18, September 3–7, 2018, Montpellier, France
The numerical input, i.e., dist(m,ec)anddist(m,tc), is fed di-
rectly into another CNN whose output is forwarded to a flatten
layer. This CNN shares the same setting with the previous CNN
introduced in the preceding paragraph. Notable, we have exper-
imentally tried to replace this CNN with other types of neural
network layers (e.g., dense layer), but we fail to improve the per-formance with the replacement (for space limitation, details are
presentedat[ 32]).Thetextualinputandthenumericalinputare
finally merged by the mergelayer [25] which simply concatenates
alistofinputs(i.e.,theaforementionedtextualandnumericalin-
puts). The following denselayer (128 neurons) and outputlayer (2
neurons)mapthetextualinputandnumericalinputintoasingle
output(prediction)thatindicateswhether mshouldbemovedto
the target class tc. The model employs binary_crossentropy as the
loss function.
3.5 Generation of Training Data
Deep neural networks have a large number of parameters. Con-sequently, they often require a large number of training data toadjust such parameters. To train the deep neural network pro-
posed in Section 3.4, we generate training data as follows. First, we
downloadwell-knownandhighqualityopen-sourceapplications.
Second, for each method mfrom such applications, we generate
alabeledtrainingsampleasfollows.(1)Wetestwhether mcould
be moved to other classes with move method refactoring. The test
is accomplished with the APIs provided by Eclipse JDT. (2) Sup-pose that method
mcould be moved to a set of classes noted as
ptc={tc1,tc2,...,tck}.Ifptcisempty,i.e.,themethodcouldnot
be moved, we discard it and turn to the next method. Otherwise,
we turn to the next step to generate a labeled training item. (3) We
randomly (fifty-fifty chance) decide to generate a positive trainingitem (with feature envy) or a negative item (without feature envy).
(4)Wegenerateanegativeitemasfollows.First,werandomly se-
lectapotentialtargetclass tcifromptc.Second,wecomputethe
distancedist(m,ec)anddist(m,tci),whereecistheenclosingclass
ofm. Third, we create a negative item ( nдItem) and add it to the
training data set:
nдItem =<input,output> (8)
input=<name(m),name(ec),name(tci),
dist(m,ec),dist(m,tci)> (9)
output =0 (10)
(5) We generate a positive item as follows. First, we randomly
select a potential target class tcifromptc. Second, we move m
from its enclosing class ectotciby Eclipse APIs. Third, we cre-
ateapositiveitemwhoseinputis <name(m),name(tci),name(ec),
dist(m,tci),dist(m,ec)>andoutputis1.Notablythedistancesare
computed after the method is moved.
The generation is based on the assumption that all involved
methods are correctly placed in the original applications. Conse-quently, the original methods if not moved should be taken as
non-smelly(withoutfeatureenvy).Incontrast,iftheyaremoved
insomewaybymovemethodrefactorings,theyshouldbetaken
as smelly (with feature envy) after the movement. However, the
assumption may not hold in some cases, i.e., some methods in the
subject applications may have been placed improperly. As a result,thetrainingdatageneratedbasedonsuchmethodsmaybenoisy:
someofthemarelabeledincorrectly.Theimpactofsuchnoisydata
could be reduced in two ways. First, we only select high qualitysubject applications for data generation. Within such high qual-
ity applications, it is likely that most of the methods are placed
correctly.Asaresult,mostofthetrainingitemscouldbelabeled
correctly.Second,advancedneuralnetworkslikeCNNworkwell
even if the training data contain a few mislabeled items [14].
3.6 Feature Envy Detection
3.6.1 Binary Classification. Foragivenmethod mtobeinves-
tigated, we predictwhether it is smellyor non-smelly as follows.First, we collect all of its potential target classes (noted as
ptc=
{tc1,tc2,...,tck})withEclipseJDT.If ptcisempty,i.e.,themethod
couldnotbemoved, misnotsmelly.Otherwise,wegenerateatest-
ingitem(asshowninFormula 5)foreachofthepotentialclasses
(notedastci):inputi=<name(m),name(ec),name(tci),dist(m,ec),
dist(m,tci)>whereecistheenclosingclassofmethod m.W efeed
such items into the trained deep neural network. If all of such
items are predicted as negative (non-smelly), we say that the given
methodmisnotassociatedwithfeatureenvy.Otherwise,wesay
that it is smelly (associated with feature envy).
3.6.2 Recommendation of Refactoring Solutions. For methods
that are predicted as smelly (with feature envy), we should suggest
wheresuchmethodsshouldbemovedviamovemethodrefactor-
ings.Ifonlyone(notedas inputj)ofthetestingitemsgeneratedfor
mis predicted as positive, we suggest to move mto the target class
(tcj) that is associated with the positive testing item inputj.
If more than one testing items are predicted as positive, we
selecttheone(notedas inputi)withthegreatestoutput,andsug-
gest to move method mto classtcithat is associated with inputi.
Although the neural network proposed in Section 3.4is trained
as a binary classifier (aiming to minimize the likelihood of mis-classification instead of the mean squared error), the output of
the neural network is a decimal varying from zero to one. The
neuralnetworkinterpretsthepredictionaspositiveifandonlyif
the output is greater than 0.5 [ 24]. For the given input input=<
name(m),name(ec),name(tci),dist(m,ec),dist(m,tci)>,thegreater
the output is, the more likely that the mshould be moved to the
target class tci.
4 EVALUATION
In this section, we evaluate the proposed approach on seven open-
source applications with injected feature envy smells.
4.1 Research Questions
The evaluation investigates the following research questions:
•RQ1: Does the proposed approach outperform the state-of-
the-art approaches in identifying feature envy?
•RQ2:Istheproposedapproachaccurateinrecommending
destinations (target classes) for methods associated with
feature envy?
•RQ3: How efficient is the proposed approach? How long
does it take to train the neural network based classifier, and
how long does it take to make predictions?
389
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Hui Liu, Zhifeng Xu, and Yanzhen Zou
Research question RQ1investigates the performance (e.g., preci-
sionandrecall)oftheproposedapproachinidentifyingfeatureenvy
smellscomparedagainstthestate-of-the-artapproaches.Toanswer
this question, we compare the proposed approach against JDeodor-
ant[57] andJMove[55]. They are selected for comparison because
ofthefollowingreasons.First,theyrepresentthestate-of-the-art.
JDeodorant has been widely employed as a benchmark [ 13,31,55]
whereasJMoveis one of the latest advances in this area. Second,
theyarepubliclyavailable.Althoughsomerelatedapproacheshave
been reported recently, their implementations are not available,
which makes it difficult to compare the proposed approach against
such approaches.
Research question RQ2concerns how accurate the proposed
approach isin recommending where thesmelly methods should be
moved. The ultimate goal of code smell detection is not to find out
code smells, but to remove such smells by software refactoringsand thus to improve software quality. Consequently, it is critical
fortheproposedapproachtosuggestcorrectlytowhichclassesthe
misplaced methods should be moved.
Researchquestion Q3concernsthetimecomplexity ofthepro-
posed approach. Deep learning based approaches often take a long
timetotraindeepneuralnetworks.However,theyusuallyresponse
instantly for a given input once the neural networks are trained in
advance. Answering this question would reveal quantitatively the
training and predicting time of the proposed approach.
4.2 Subject Applications
We evaluate the proposed approach on seven open-source appli-
cations as introduced in Table 1. Although the proposed approach
is generic and should be able to work for different object-oriented
programming languages, its prototype implementation is confined
toJavaonly.Consequently,weselectJavaapplicationsonly.The
columns (from left to right) present the application name, version,
num of classes (NOC), number of methods (NOM), and lines of
source code (LOC), respectively.
JUnit[6] is a widely used testing framework. During the last 16
years,ithasreleasedmorethan40versions. PMD[8]isanextensible
cross-languagestaticcodeanalyzerthatiswidelyusedtofindcom-
monprogrammingflaws.Duringthelast14years,ithasevolved
extensivelyandreleasedmorethan100versions. JExcelAPI [4]is
anopen-sourceJavaAPIthatfacilitatesdeveloperstoread,writeor
modifyExcelspreadsheets dynamically. The evolution lasted more
than 7 years, and 75 versions have been released. Areca[1]i sa n
open-source application for file backup, supporting incremental
backuponlocaldrivesorFTPservers.Theevolutionlastedmore
than 8 years, and 90 versions have been released. Freeplane [2]i sa
free mind mapping and knowledge management software. During
thelast18years,ithasreleasedmorethan100versions. jEdit[3]
is a free text editor. During the last 18 years, it has released 143
versions. Weka[59]isaset ofwell-knownmachinelearningalgo-
rithms developed by the machine learning group at the University
ofWaikato.Theevolutionlastedmorethan18years,andmorethan
90 versions have been released.
These subject applications are selected because of the following
reasons.First,allofthemareopen-sourceapplicationswhosesource
code is publicly available. Selecting such open-source applicationsTable 1: Subject Applications
Applications Domain Version NOCNOM LOC
JUnit Unit Testing 4.10 12386611,734
PMD Static Code
Analysis5.2.0 2502,097 32,783
JExcelAPI Excel API 2.6.12 4243,118 90,555
Areca Document
Backup7.4.7 4735,055 88,126
Freeplane Knowledge
Manage-
ment1.3.12 7876,938124,937
jEdit Text Editor 4.5.0 5135,964185,571
Weka Machine
Learning3.9.0 134820,182 444,493
facilitates other researchers to repeat the evaluation. Second, all of
themarewell-known,popularandofhighquality.Allofthemhave
involved successfully for a long time (more than 7 years), which
usually depends on high quality of the maintained projects. We
also manually checked candidate projects to make sure that the
selectedprojectsareofhighquality.AsintroducedinSection 3.5,
the generation of training data is based on the assumption that
methodsin subjectapplicationsare correctlyplaced.Consequently,
selecting such high quality applications may reduce the likelihood
that methods in such applications are misplaced. Notable, the aver-
age LCM (Lack of Cohesion of Methods) of such projects is smaller
than 0.26, the average efferent coupling is smaller than 11, and the
averageafferentcouplingissmallerthan30.Allofthesetogether
may suggest that most methods have benn placed correctly. Third,
theseapplicationsweredevelopedbydifferentdevelopers,which
may reduce the bias introduced by specific developers.
4.3 Process
We carry out a k-fold (k= 7) cross-validation on the seven subject
applicationspresentedinTable 1.Oneachfold,asingleapplication
is used as the testing subject (noted as testingApp ) whereas the
othersareusedastrainingsubjects(notedas trainingApps ).Each
of the subject applications is used as the testing subject for once.
Each fold of the evaluation follows the following process:
(1)First, we generate a training data set traininдData based on
trainingApps as specified in Section 3.5.
(2)Second, we train the proposed approach with trainingData .
(3)Third, from the testing subject testingApp, we identify all
methods (noted as ms) that could be moved between classes
viaJDK’move method API.
(4)Fourth, from mswe randomly sample 23% of the methods,
and note them as ms1. The rest is noted as ms2, and thus we
havems=ms1/uniontext.1ms2.
(5)Fifth, for each method minms1, we randomly move it to
oneofitspotentialtargetclasses(i.e.,injectingsmellsinto
testingApp ).
390
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Deep Learning Based Feature Envy Detection ASE ’18, September 3–7, 2018, Montpellier, France
(6)Sixth, after the movement, we apply the proposed approach,
JDeodorant, and JMoveto the testing subject independently.
A predicted positive is a true positive if and only if the re-
ported method mhas been moved before (i.e., m∈ms1).
Methods may be unmovable because of differen reasons [ 43].
Forexample,movingoverridden/overridingmethodsoftenleadsto
syntaxerrors.Anotherexampleisthatmovingmethod mtoanother
class that is not related to its enclosing class in any way may break
thelinks(e.g.,methodinvocation)between mandmembersofits
enclosing class. Such unmovable methods could not serve as move
method opportunities. Smell detection tools can also exclude such
methods by static analysis or simply by existing JDT APIs. Con-
sequently,duringtheevaluationwedonotgeneratetestingitems
basedonsuchmethods.Instead,wegeneratetestingitemsbased
onmovablemethodsonly,althoughanalysisonthesubjectappli-
cations introduced in Table 1suggests that only 10%(=4,430/44,220)
of the methods could be moved.
WealsonoticethatexperimentalstudyconductedbyPalomba
et al. [46] suggest that around 2.3% of methods are associated with
feature envy and should be resolved by move method refactorings.
Consequently, from the movable methods, we randomly select 23%
of them to construct positive testing items. As a result, the smelly
methodsaccountforaround2.3%=10% ×23%ofallmethods(includ-
ingunmovableones),whichisconsistentwiththefindingreported
by Palomba et al. [46].
After the evaluation, we calculate the precision, recall, and F1of
the proposed approach (JDeodorant andJMoveas well) in identify-
ing feature envy smells as follows:
precision =truepositives
truepositives +falseneдatives(11)
recall=truepositives ÷|ms1| (12)
F1=2×precision ×recall
precision +recall(13)
Theaccuracyoftheapproachesinrecommendingdestinations
for smelly methods is computed as follows:
ac=correct recommendation for true positives
truepositives(14)
The recommended destination for method mis correct if and only
if it suggests to move mback to its enclosing class before it is
moved.Notably,recommendeddestinationsforfalsepositivesare
notcountedinwhilecomputingtheaccuracybecauseonlyifde-
velopers confirm that the detected method should be moved (i.e., it
is a true positive) they should consider the destination problem.
4.4 RQ1:Detection of Feature Envy
To answer research question RQ1we compare the proposed ap-
proach against JDeodorant andJMovein detecting feature envy
smells. Evaluation results are presented in Table 2. The first col-
umn presentsthe subjectapplications. Columns2-4 presents the
precision, recall, and F-measure of the proposed approach, respec-
tively.Theperformanceof JDeodorant andJMoveispresentedin
columns 5-7 and columns 8-10, respectively. The last row of the
tablepresentstheaverageperformanceoftheinvolvedapproaches.
From Table 2we make the following observations:•First,theproposedapproachsignificantlyoutperformsthe
state-of-the-art as F-measure is concerned. Its average F-
measureis52.98%whereastheaverageF-measureof JDeodor-
antandJMoveis 18.66% and 17.27%, respectively. Compared
toJDeodorant andJMove, the proposed approach improves
F-measure by 34.32% (=52.98%-18.66%) and 35.71% (=52.98%-
17.27%), respectively.
•Second, the proposed approach can identify most of the fea-
tureenvysmells.Itsaveragerecallisupto79.27%.Compared
toJDeodorant andJMove, it improves recall dramatically by
67.05% (=79.27%-12.22%) and 62.97% (=79.27%-16.3%), respec-
tively.
•Third, the precision (39.79%) of the proposed approach isslightly greater than that (39.51%) of JDeodorant, and it is
significantly greater than that (18.37%) of JMove.
We evaluate how the textualinput and code metrics contribute
tothe proposedmodelbyremovingthem respectively.Evaluation
resultssuggestthatremovingthetextualinputsignificantlyreduces
recall of the approach from 79.27% to 46.69%, and removing the
code metrics reduces precision significantly from 39.76% to 23.20%.
Weconcludefromtheseresultsintheprecedingparagraphsthat
theproposedapproachoutperformsthestate-of-the-artapproaches
significantly in detecting feature envy smells.
4.5 RQ2:Recommendation of Destinations
Methodsassociatedwithfeatureenvysmellsshouldberelocated.
However, before such methods could be relocated, we have tochoose their target classes (destinations). The accuracy of the in-
volvedapproachesinrecommendingthetargetclassesispresented
inTable3.Eachrowofthetablepresentstheiraccuracyonasubject
application except the last row that presents the average accuracy
on all subject applications.
From Table 3, we make the following observations:
•First,theproposedapproachisaccurateinrecommending
destinations for smelly methods. Its accuracy varies from
69.09%to80.52%.Onaverage,itsaccuracyisupto74.94%.Inotherwords,forthreeoutoffourtruepositives(i.e.,methods
that should be moved) the proposed approach can predict
correctly to which classes the methods should be moved.
•Second,theproposedapproachismoreaccuratethan JDeodor-
antandJMovein recommending destinations for smelly
methods.Comparedto JDeodorant andJMove,itimproves
theaccuracyby27.15%(=74.94%-47.79%)and46.54%(=74.94%-
28.4%), respectively.
We conclude from these results that the proposed approach is
accuratein recommendingdestinations forfeature envymethods,
and it improves the state-of-the-art significantly.
4.6 RQ3: Efficiency of the Proposed Approach
To investigate the efficiency (time complexity) of the neural net-
work based classifier, we record the time spent on training and
testingduringevaluation.Toimprovetheefficiencyoftraining,we
conductthetrainingonaworkstationwithGPUwhosesettingis
listed as follows: 64GB RAM, Intel Xeon CPU E5-2660 v4 2.00GHz,
NVIDIA Quadro M4000. In contrast, the testing is conducted on
apersonalcomputerwithoutGPU:16GBRAM,IntelCorei7-6700
391
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Hui Liu, Zhifeng Xu, and Yanzhen Zou
Table 2: Evaluation Results on Feature Envy Detection
ApplicationsProposed Approach JDeodorant JMove
precision recall F1precision recall F1precision recall F1
JUnit 40.59% 91.11% 56.16% 30.76% 14.82% 20% 22.72% 18.52% 20.41%
PMD 41.27% 68.42% 51.49% 15.79% 5.36% 8% 30% 26.79% 28.3%
JExcelAPI 31.9% 92.85% 47.49% 60% 10.7% 18.18% 27.27% 16.07% 20.22%
Areca 46.05% 72.16% 56.23% 32.14% 9.28% 14.4% 26.76% 39.18% 31.8%
Freeplane 38.09% 68.58% 48.97% 21.62% 8.94% 12.65% 24.83% 13.79% 17.73%
jEdit 42.63% 78.57% 55.28% 22.73% 4.55% 7.58% 17.43% 13.57% 15.26%
Weka 40.05% 86%54.65% 58.33% 17.5% 26.92% 11.22% 11.75% 11.48%
Average 39.79% 79.27% 52.98% 39.51% 12.22% 18.66% 18.37% 16.3% 17.27%
Table 3: Accuracy in Recommending Destinations
Applications Proposed Approach JDeodorant JMove
JUnit 70.73% 75% 60%
PMD 76.92% 33.33% 46.67%
JExcelAPI 61.54% 50% 44.44%
Areca 71.43% 55.55% 23.68%
Freeplane 73.74% 31.25% 27.78%
jEdit 69.09% 60% 26.31%
Weka 80.52% 48.57% 21.27%
Average 74.94% 47.79% 28.4%
CPU3.40GHz.Weconductthetestingonpersonalcomputerinstead
of more powerful workstation because detection of feature envy
(testing) is often conducted on personal computers by developers.
Evaluationresultssuggestthattheproposedapproachisefficient.
Onaverage,thetrainingcouldbedonewithin10minutes.Withthe
trainedclassifier,ittakes1.7-25.3minutes(9.43minutesonaverage)todetectfeatureenvysmellsforonesubjectapplication.Incontrast,
on average it takes Jdeodorant andJMove1 minute and 41 minutes
respectively.Furtheranalysisonthetestingtimesuggeststhatmost
(99%=9.35 minutes/9.43 minutes) of the testing time is spent on
information extraction, i.e., extracting method names, class names,
and the distance between them. In contrast, the neural network
alwaysmakespredictionsinstantly,anditconsumeslessthan1%
of the testing time (less than 5 seconds).
4.7 Threats to Validity
The first threat to validity is that the feature envy smells involved
in the evaluation are generated automatically. It is likely that such
automatically generated smells are different from those that are
manuallyintroducedbydevelopersduringrealdevelopments.Con-
sequently,conclusionsdrawnonsuchgenerateddatasetmaynot
hold on real applications. To reduce the threat, we randomly select
methodstomove,andrandomlyselectthetargetclassesforsuchmethods. Besides that, we also rigidly control the ratio of smellymethods (to all methods) to make sure that the ratio is close tothat (2.3%) in real applications [
46]. Finally, we carry out a case
study in Section 5where no automatically generated smells are
involved. The results of the case study confirm the conclusion that
the proposed approach improves the state-of-the-art.
Thesecondthreattovalidityisthattheevaluationisbasedon
the assumption that all methods in the subject applications areproperly distributed, i.e., there is no feature envy in the original
source code. However, the assumption may not hold, and thus the
calculation of performance (e.g., precision and recall) based on this
assumptionmaybeinaccurate.Toreducethethreat,weonlyselect
well-known high quality subject applications for the evaluation.
Thethirdthreattovalidityisthatonlysevensubjectapplications
areinvolvedintheevaluation.Specialcharactersofsuchapplica-
tions may bias the conclusions, and thus such conclusions may not
hold on other applications. To reduce the threat, we select applica-
tionsfromdifferentdomainsanddifferentdevelopers.Wealsocarry
out k-fold cross validity on such applications to reduce the bias
introduced by specific applications. To facilitate further evaluation,
we publish the source code of the implementation as well as the
evaluation data at https://github.com/liuhuigmail/FeatureEnvy.
5 CASE STUDY
In Section 4, we evaluate the proposed approach on applications
withautomaticallyinjectedsmells.Inthissection,weevaluateit
with real applications without any injection. This case study inves-
tigates the same research questions as introduced in Section 4.1,
but with real applications that have not be changed by us anyway.
5.1 Subject Applications
We search for subject applications from SourceForge as follows.
First, we search for Java applications. Second, we sort the resulting
applications by popularity in ascending order assuming that theless popular applications may contain more code smells. Third,
weexcludesuchapplicationswhoseLOC(linesofsourcecode)is
smallerthantenthousandorgreaterthanthirtythousand.Ifthe
subjectapplicationistoolarge,itmaytakealongtimetomanuallycheckthepotentialcodesmellsreportedbytheinvolvedapproaches.
392
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Deep Learning Based Feature Envy Detection ASE ’18, September 3–7, 2018, Montpellier, France
Table 4: Subject Applications for Case Study
Applications Domain Version NOCNOM LOC
XMD Download
Manager2.1198159942,604
JSmooth JavaWrap-
per0.9.9 9166916,782
Neuroph Neural
Network2.9214118626,513
In contrast, if the subject application is too small, the number of
codesmellsmaybesmall(ornosmellsatall),whichmayreduce
the statistical significance of the evaluation results. Consequently,
welimit thesize ofthesubjectapplicationto agiven range. Fourth,
weexcludethoseapplicationsthatcannotbecompiledsuccessfully.
Syntactical errors may prevent the proposed approach (as well
JDeodorant andJMove) to extract necessary information correctly.
Finally,weselectthetopthreeoftheremainingsubjectapplications.
Table4presents the information of such applications.
XDM[9](XtremeDownloadManager)isadownloadmanager
tosavestreamingvideosfromwebsites,resumebroken/deaddown-
loads, and schedule downloads. JSmooth[5] is a Java executable
wrapper that creates native Windows launchers for given Java ap-
plications. Neuroph[7] is a lightweight neural network framework
providing Java neural network library and GUI tool to facilitate
creating, training and saving of neural networks.
5.2 Process
For each of the subject applications, we carry out the case study as
follows. First, we train the proposed approach with data generated
from the 7 subject applications that are introduced in Table 1.S ec -
ond, weapply the proposedapproach (trainedclassifier), JDeodor-
ant,andJMovetotheselectedsubjectapplicationindependently,
and merge the detection results. Third, we present the detection
resultstothreedevelopersformanualchecking.Fourth,basedon
themanualchecking,wecomputetheperformanceoftheevaluated
approaches.
The manual checking is accomplished by three postgraduate
studentsinBeijingInstituteofTechnology.Allofthemaremajored
in computer science and have rich experience in Java development.
They check the detection results independently. After that, they
discusstogethertoremoveinconsistence.Notable,theevaluationis
conducted in an anonymous manner, and thus the students cannot
identify the tool that performed the recommendation.
5.3 Results
Results of the case study are presented in Table 5. The first column
presents different metrics, like precision and accuracy. Columns
2-4presentstheresultsoftheproposedapproachondifferentap-
plications,andthefifthcolumnpresentsitsaverageperformance
onallapplications.Theperformanceof JDeodorant andJMoveis
presented in columns 6-9 and columns 10-13, respectively. The sec-
ondrowpresentsthenumberofpotentialfeatureenvyreportedbydifferent approaches, and the third row presents the number of ac-
cepted (correct) feature envy. The fourth row presents the number
of correct recommendation of destinations for the accepted feature
envy.Thelasttworowspresenttheprecisionindetectingfeature
envy and accuracy in recommending destinations, respectively.
From Table 5, we make the following observations:
•First,theproposedapproachcanidentifyfeatureenvysmells
in real applications, and suggest the correct target classesfor smelly methods. In total, it successfully detect 114 fea-
ture envy smells from the three subject applications, among
which 47 are manually confirmed. It also successfully rec-
ommends the correct destinations for 78.72% (=37/47) of the
confirmed smelly methods.
•Second, the proposed approach significantly outperformsJDeodorant andJMovein detecting feature envy smells. It
improvestheprecisionfrom27.59%(JDeodorant )and15.35%
(JMove)significantlyto41.23%.Italsoidentifymuchmore
truepositivesthan JDeodorant andJMove,whichsuggests
that the proposed approach achieves greater recall than
JDeodorant andJMove.
•Third,theproposedapproachismoreaccuratethan JDeodor-
antandJMovein recommending destinations for feature
envy methods. Compared to JDeodorant andJMove,i ti m -
provestheaccuracyby41.22%(=78.72%-37.5%)and48.42%
(=78.72%-30.3%), respectively.
We conclude from the preceding analysis that the proposed ap-
proach significantly outperform the state-of-the-art in both detect-
ing feature envy smells and recommending destinations for smelly
methods.
5.4 Threats to Validity
Thefirstthreattovalidityisthatonlythreesubjectapplicationsare
involved in the evaluation. Special characters of such applications
may bias the conclusions, and thus such conclusions may not hold
onotherapplications.Toreducethethreat,weselectapplications
from different domains and different developers. Although addi-tional subject applications would significantly increase the cost
(manual checking), it would be interesting in future to evaluate the
approaches with more applications.
The second threatto validity is that manualchecking of the re-
ported potentialfeatureenvy smellscouldbe inaccurate. Thethree
participants are not theoriginal developers of the subject applica-
tions, and they may not fully understand the design. Consequently,
they may make incorrect judgements on the potential smells. To
reduce the threat, we select three participants who have rich expe-
rience in software refactoring and Java development. Besides that,
wealsoaskthemtodiscusstogetherandreachanagreementonall
smells.Finally,wealsoconductanevaluationinSection 4where
manual checking is not required.
6 DISCUSSION
6.1 Evaluation with Original Developers
ThecasestudyinSection 5recruitsexternaldeveloperstomanually
checkthepotentialcodesmellsreportedbysmelldetectiontools.
393
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Hui Liu, Zhifeng Xu, and Yanzhen Zou
Table 5: Results of Case Study
MetricsProposed Approach JDeodorant JMove
XMDJSmooth Neuroph Total XMDJSmooth Neuroph Total XMDJSmooth Neuroph Total
#Reported 32 26 56 114 8 3 18 29 106 27 82 215
#Accepted 15 11 21 47 3 1 4 8 12 5 16 33
#Accepted
targets12 9 16 37 1 1 1 3 3 2 5 10
Precision 46.88% 42.31% 37.5% 41.23% 37.5% 33.33% 22.22% 27.59% 11.32% 18.52% 19.51% 15.35%
Accuracy
(destination)80% 81.82% 76.19% 78.72% 33.33% 100% 25% 37.5% 25% 40% 31.25% 30.3%
Such external developers are not familiar with the subjection appli-
cations, and thus may make mistakes during the manual checking.
If the original developers of such applications could be recruited, it
would significantly improve the accuracy of the manual checking
because they have much better understanding of the subject appli-
cations.However,itischallengingtorecruittheoriginaldevelopers
formanualchecking.Oneofthereasonsisthatthecheckingistime
consumingand tedious.Another possiblereason isthat resolving
code smells often have low priority in companies.
An alternativeway torecruit original developersin theevalua-
tionistointegratetheimplementationoftheproposedapproach
into IDEs, and collect feedbacks (i.e., which reported items are con-firmed or rejected) automatically by such IDEs. A similar approach
has been proposed by Liu et al. [ 30] to collect manual feedbacks in
smell detection tools automatically. They collect such feedbacks to
optimize the setting of smell detection tools. Such feedbacks can
alsobeemployedtoestimatetheperformance,especiallyprecision,
of smell detection tools.
6.2 Generality of the Generated Data
Theproposedapproachgenerateslabeledtrainingdataautomati-
cally by randomly moving methods among classes. Such generated
dataserveasthebasisofdeeplearningbasedfeatureenvydetec-
tion. However, they may be different from real feature envy smells
introduced by developers. As a result, the classifier trained with
such generated data may learn to distinguish the randomly moved
methodsinsteadofthoseassociatedwithfeatureenvysmells.To
reduce the threat, weevaluate the proposed approach with acase
study in Section 5where the detected feature envy smells are man-
ually confirmed. The evaluation results suggest that the proposed
approach can identify real feature envy smells accurately even if it
istrainedwithgenerateddata.Infuture,wewouldinvestigatehow
toimprovetheapproachbyaddingrealcodesmellstothegener-
atedtrainingdata.Besidesthat,consideringmultiplerefactoring
tools in future during the data generation may help to improve the
generality as well.
6.3 Misplaced Fields
In this paper, we follow a rather narrow definition of feature envy
and thus the proposed approach is designed to detect misplacedmethods only. In a broad definition, however, feature envy alsocovers misplaced fields. We follow the narrow definition because it
iswellrecognized[ 19]andmostoftheexistingcodesmelldetection
tools follow this definition. However, it is interesting to extend the
proposedapproachinfuturetodetectmisplacedfieldsaswellas
misplaced methods.
6.4 Extension to Other Code Smells
The proposed approach is currently confined to feature envy. How-
ever,theunderlingrationale,i.e.,deeplearningtechniquescould
learn useful featuresfor smell detection andthe required training
datacouldbegeneratedautomatically,maybeapplicabletoother
code smells as well. For example, we may generate God classes
(positive samples) by combining classes in the same project, and
take other classes as negative samples. With such positive and neg-
ativesamples(trainingdata),wecantrainadeepneuralnetwork
to determine whether a given class is a God class.
7 CONCLUSIONS
Inthispaperweproposeadeeplearningbasedapproachtoidentify
feature envy smells, one of the most common code smells. It au-
tomatically selectsuseful textual features, andmaps such features
to predictions automatically. To train the deep neural network, we
also propose an approach to generate numerous labeled training
dataautomatically.Tothebestofourknowledge,wearethefirst
to exploit deep learning in feature envy detection. We are also the
first to automatically generate labeled training data for code smell
detection.Theevaluationoftheproposedapproachiscomposed
oftwoparts.Inthefistpart,weevaluateitonopen-sourceappli-
cationswithinjectedsmells.Inthesecondpart,weevaluateiton
theoriginalsourcecodeofopen-sourceapplicationswithoutany
revision.Evaluation results inboth parts suggestthat the proposedapproachsignificantlyimprovesthestate-of-the-artinbothfeature
envy detection and recommendation of refactoring solutions.
ACKNOWLEDGMENTS
TheauthorswouldliketosaythankstothereviewersandPCchairs
for their insightful comments and constructive suggestions.
This work is supported by the National Natural Science Founda-
tionofChinaunderGrantNo.:61690205,61472034,61772071,and
National Key Researchand DevelopmentProgram ofChina under
Grant No.: 2016YFB1000801
394
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Deep Learning Based Feature Envy Detection ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1] 2018. Areca. http://www.areca-backup.org/.
[2] 2018. Freeplane. https://www.freeplane.org/.
[3] 2018. jEdit. http://www.jedit.org/.
[4] 2018. JExcelAPI. http://jexcelapi.sourceforge.net/.
[5] 2018. JSmooth. http://jsmooth.sourceforge.net/.
[6] 2018. JUnit. https://junit.org/.
[7] 2018. Neuroph. http://neuroph.sourceforge.net/.
[8] 2018. PMD. https://pmd.github.io/.
[9] 2018. XDM. http://xdman.sourceforge.net/.
[10]LucasAmorim,EvandroCosta,NunoAntunes,BaldoinoFonseca,andMárcio
Ribeiro.2015. Experiencereport:Evaluatingtheeffectivenessofdecisiontrees
fordetectingcodesmells.In SoftwareReliabilityEngineering(ISSRE),2015IEEE
26th International Symposium on. IEEE, 261–269.
[11]Francesca Arcelli Fontana, Mika V. Mäntylä, Marco Zanoni, and Alessandro
Marino.2016. Comparingandexperimentingmachinelearningtechniquesfor
codesmelldetection. EmpiricalSoftwareEngineering 21,3(01Jun2016),1143–
1191.https://doi.org/10.1007/s10664-015-9378-4
[12]V.Arnaoudova,L.M.Eshkevari,M.D.Penta,R.Oliveto,G.Antoniol,andY.G.
GuÃľhÃľneuc. 2014. REPENT: Analyzing the Nature of Identifier Renamings.
IEEE Transactions on Software Engineering 40, 5 (May 2014), 502–532. https:
//doi.org/10.1109/TSE.2014.2312942
[13]G.Bavota,R.Oliveto,M.Gethers,D.Poshyvanyk,andA.DeLucia.2014. Method-
book: Recommending Move Method Refactorings via Relational Topic Mod-
els.Software Engineering, IEEE Transactions on 40, 7 (July 2014), 671–694.
https://doi.org/10.1109/TSE.2013.60
[14]D. Bobkov, S. Chen, R. Jian, M. Z. Iqbal, and E. Steinbach. 2018. Noise-Resistant
Deep Learning for Object Classification in Three-Dimensional Point Clouds
UsingaPointPairDescriptor. IEEERoboticsandAutomationLetters 3,2(April
2018), 865–872. https://doi.org/10.1109/LRA.2018.2792681
[15]Jehad Al Dallal. 2014. Identifying Refactoring Opportunities in Object-Oriented
Code:ASystematicLiteratureReview. InformationandSoftwareTechnology 0
(2014), –. https://doi.org/10.1016/j.infsof.2014.08.002
[16]Francesca Arcelli Fontana, Mika V Mäntylä, Marco Zanoni, and Alessandro
Marino.2016. Comparingandexperimentingmachinelearningtechniquesfor
code smell detection. Empirical Software Engineering 21, 3 (2016), 1143–1191.
[17]Francesca Arcelli Fontana and Marco Zanoni. 2017. Code smell severity classifi-
cation using machine learning techniques. Knowledge-Based Systems 128 (2017),
43–58.
[18]Francesca Arcelli Fontana, Marco Zanoni, Alessandro Marino, and Mika V
Mantyla. 2013. Code smell detection: Towards a machine learning-based ap-
proach. In Software Maintenance (ICSM), 2013 29th IEEE International Conference
on. IEEE, 396–399.
[19] MartinFowler,KentBeck,JohnBrant,WilliamOpdyke,andDonRoberts.1999.
Refactoring:ImprovingtheDesignofExistingCode. AddisonWesleyProfessional.
[20]William G. Griswold and David Notkin. 1993. Automated assistance for pro-
gram restructuring. ACM Transactions on Software Engineering and Methodology
(TOSEM) 2, 3 (July 1993), 228–269.
[21]XiaodongGu,HongyuZhang,DongmeiZhang,andSunghunKim.2016. Deep
APILearning.In Proceedingsofthe201624thACMSIGSOFTInternationalSym-
posiumonFoundationsofSoftwareEngineering (FSE2016).ACM,NewYork,NY,
USA, 631–642. https://doi.org/10.1145/2950290.2950334
[22]K.HwangandW.Sung.2016. Character-levelincrementalspeechrecognition
with recurrent neural networks. In 2016 IEEE International Conference on Acous-
tics,Speech andSignalProcessing(ICASSP).5335–5339. https://doi.org/10.1109/
ICASSP.2016.7472696
[23]Keras. 2018. Flatten Layer. Retrieved July 21, 2018 from https://github.com/
keras-team/keras/blob/master/keras/layers/core.py#L467
[24]Keras. 2018. Keras: The Python Deep Learning Library. https://github.com/
keras-team/keras/blob/master/keras/models.py
[25]Keras. 2018. Merge Layer. Retrieved July 21, 2018 from https://github.com/
keras-team/keras/blob/master/keras/layers/merge.py
[26]Foutse Khomh, Stéphane Vaucher, Yann-Gaël Guéhéneuc, and Houari Sahraoui.
2009. Abayesianapproachforthedetectionofcodeanddesignsmells.In Quality
Software, 2009. QSIC’09. 9th International Conference on. IEEE, 305–314.
[27]Foutse Khomh, Stephane Vaucher, Yann-Gaël Guéhéneuc, and Houari Sahraoui.
2011. BDTEX:AGQM-basedBayesianapproachforthedetectionofantipatterns.
Journal of Systems and Software 84, 4 (2011), 559–572.
[28]Jochen Kreimer. 2005. Adaptive detection of design flaws. Electronic Notes in
Theoretical Computer Science 141, 4 (2005), 117–136.
[29]HuiLiu,XueGuo,andWeizhongShao.2013. Monitor-BasedInstantSoftware
Refactoring. IEEE Transactionson SoftwareEngineering 39,8 (2013),1112–1126.
https://doi.org/10.1109/TSE.2013.4
[30]H. Liu, Q. Liu, Z. Niu, and Y. Liu. 2016. Dynamic and Automatic Feedback-Based
Threshold Adaptationfor Code SmellDetection. IEEE Transactionson Software
Engineering 42,6(June2016),544–558. https://doi.org/10.1109/TSE.2015.2503740
[31]H. Liu, Y. Wu, W. Liu, Q. Liu, and C. Li. 2016. Domino Effect: Move More
Methods Once a Method is Moved. In 2016 IEEE 23rd International ConferenceonSoftwareAnalysis,Evolution,andReengineering(SANER),Vol.1.1–12. https:
//doi.org/10.1109/SANER.2016.14
[32]HuiLiu, ZhifengXu,andYanzhenZou.2018. ReplaceCNN withDenseLayers.
RetrievedJuly21,2018from https://github.com/liuhuigmail/FeatureEnvy/tree/
master/Algorithm/DenseVScnn
[33]Abdou Maiga, Nasir Ali, Neelesh Bhattacharya, Aminata Sabane, Yann-Gael
Gueheneuc, and Esma Aimeur. 2012. SMURF: A SVM-based incremental anti-
pattern detection approach. In Reverse engineering (WCRE), 2012 19th working
conference on. IEEE, 466–475.
[34]Abdou Maiga, Nasir Ali, Neelesh Bhattacharya, Aminata Sabané, Yann-Gaël
Guéhéneuc,GiulianoAntoniol,andEsmaAïmeur.2012. Supportvectormachines
for anti-pattern detection. In Proceedings of the 27th IEEE/ACM International
Conference on Automated Software Engineering. ACM, 278–281.
[35]Mika V. Mäntylä and Casper Lassenius. 2006. Subjective evaluation of software
evolvabilityusingcodesmells:Anempiricalstudy. EmpiricalSoftwareEngineering
11, 3 (01 Sep 2006), 395–431. https://doi.org/10.1007/s10664-006-9002-8
[36]Tom Mens, Niels Van Eetvelde, and Serge Demeyer. 2005. Formalizing Refactor-
ingswithGraphTransformations. JournalofSoftwareMaintenanceandEvolution:
Research and Practice 17, 4 (2005), 247–276.
[37]Tom Mens and Tom Tourwé. 2004. A Survey of Software Refactoring. IEEE
Transactions on Software Engineering 30, 2 (2004), 126–139.
[38]Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
Estimation of Word Representations in Vector Space. CoRRabs/1301.3781 (2013).
arXiv:1301.3781 http://arxiv.org/abs/1301.3781
[39]TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffDean.2013.
DistributedRepresentationsofWordsandPhrasesandtheirCompositionality. In
Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou,
M. Welling, Z. Ghahramani, and K. Q. Weinberger (Eds.). Curran Associates, Inc.,
3111–3119.
[40]D.DiNucci,F.Palomba,D.A.Tamburri,A.Serebrenik,andA.DeLucia.2018.
Detecting code smells using machine learning techniques: Are we there yet?.In2018 IEEE 25th International Conference on Software Analysis, Evolution and
Reengineering (SANER). 612–621. https://doi.org/10.1109/SANER.2018.8330266
[41]D.DiNucci,F.Palomba,D.A.Tamburri,A.Serebrenik,andA.DeLucia.2018.Detecting code smells using machine learning techniques: Are we there yet?.In2018 IEEE 25th International Conference on Software Analysis, Evolution and
Reengineering (SANER). 612–621. https://doi.org/10.1109/SANER.2018.8330266
[42]William F. Opdyke. 1992. Refactoring Object-Oriented Frameworks. Ph.D. Disser-
tation. University of Illinois at Urbana-Champaign.
[43]WilliamF.Opdyke.1992. RefactoringObject-orientedFrameworks. Ph.D.Disserta-
tion. Champaign, IL, USA. UMI Order No. GAX93-05645.
[44]H.Palangi,L.Deng,Y.Shen,J.Gao,X.He,J.Chen,X.Song,andR.Ward.2016.
Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis
and Application to Information Retrieval. IEEE/ACM Transactions on Audio,
Speech, and Language Processing 24, 4 (April 2016), 694–707. https://doi.org/10.
1109/TASLP.2016.2520371
[45]F. Palomba, G. Bavota, M. Di Penta, R. Oliveto, D. Poshyvanyk, and A. De Lucia.
2015. Mining Version Histories for Detecting Code Smells. Software Engineering,
IEEE Transactions on 41, 5 (May 2015), 462–489. https://doi.org/10.1109/TSE.
2014.2372760
[46]FabioPalomba,GabrieleBavota,MassimilianoDiPenta,FaustoFasano,Rocco
Oliveto, and Andrea De Lucia. 2017. On the diffuseness and the impact on
maintainabilityofcodesmells:alargescaleempiricalinvestigation. Empirical
SoftwareEngineering (07Aug 2017). https://doi.org/10.1007/s10664-017-9535-z
[47]F.Palomba,A.Panichella,A.DeLucia,R.Oliveto,andA.Zaidman.2016.Atextual-
basedtechniqueforSmellDetection.In 2016IEEE24thInternationalConferenceon
ProgramComprehension(ICPC).1–10. https://doi.org/10.1109/ICPC.2016.7503704
[48]F.Palomba,A.Panichella,A.DeLucia,R.Oliveto,andA.Zaidman.2016.Atextual-
basedtechniqueforSmellDetection.In 2016IEEE24thInternationalConferenceon
ProgramComprehension(ICPC).1–10. https://doi.org/10.1109/ICPC.2016.7503704
[49]Y.Pan,T.Mei,T.Yao,H.Li,andY.Rui.2016. JointlyModelingEmbeddingand
Translation to Bridge Video and Language. In 2016 IEEE Conference on Computer
Vision and Pattern Recognition (CVPR) . 4594–4602. https://doi.org/10.1109/CVPR.
2016.497
[50]S.Ren,K.He,R.Girshick,andJ.Sun.2017. FasterR-CNN:TowardsReal-Time
ObjectDetectionwithRegionProposalNetworks. IEEETransactionsonPattern
AnalysisandMachineIntelligence 39,6(June2017),1137–1149. https://doi.org/
10.1109/TPAMI.2016.2577031
[51]V. Sales, R. Terra, L.F. Miranda, and M.T. Valente. 2013. Recommending Move
Method refactorings using dependency sets. In Reverse Engineering (WCRE),
2013 20th Working Conference on. 232–241. https://doi.org/10.1109/WCRE.2013.
6671298
[52]Olaf Seng, Johannes Stammel, and David Burkhart. 2006. Search-based deter-
mination of refactorings for improving the class structure of object-oriented
systems.In InProceedingsofthe8thannualconferenceongeneticandevolutionary
computation. 1909–1916.
[53]TusharSharmaandDiomidisSpinellis.2018.Asurveyonsoftwaresmells. Journal
of Systems and Software 138 (2018), 158 – 173.
395
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Hui Liu, Zhifeng Xu, and Yanzhen Zou
[54]F. Simon,F.Steinbrucker, andC.Lewerentz. 2001. MetricsBased Refactoring.In
ProceedingsofEuropenConferenceonSoftwareMaintenanceandReengineering .
30–38.
[55]RicardoTerra,MarcoTulioValente,SergioMiranda,andVitorSales.2018. JMove:
A novel heuristic and tool to detect move method refactoring opportunities.
Journal of Systems and Software 138 (2018), 19 – 36. https://doi.org/10.1016/j.jss.
2017.11.073
[56]FrankTip,AdamKiezun,andDirkBaeumer.2003. RefactoringforGeneralization
UsingTypeConstraints.In ProceedingsoftheEighteenthAnnualConferenceon
Object-Oriented Programming Systems, Languages, and Applications (OOPSLA’03).
Anaheim, CA, 13–26.
[57]Nikolaos Tsantalis and Alexander Chatzigeorgiou. 2009. Identification of Move
MethodRefactoringOpportunities. IEEETransactionsonSoftwareEngineering
35, 3 (2009), 347–367. https://doi.org/10.1109/TSE.2009.1
[58]Stephane Vaucher, Foutse Khomh, Naouel Moha, and Yann-Gaël Guéhéneuc.
2009. Tracking design smells: Lessons from a study of god classes. In ReverseEngineering, 2009. WCRE’09. 16th Working Conference on. IEEE, 145–154.
[59] Weka. [n. d.]. http://www.cs.waikato.ac.nz/ml/weka/.
[60]D.Wu,N.Sharma,andM.Blumenstein.2017. Recentadvancesinvideo-based
humanactionrecognitionusingdeeplearning:Areview.In 2017International
JointConferenceonNeuralNetworks(IJCNN) .2865–2872. https://doi.org/10.1109/
IJCNN.2017.7966210
[61]ZhifengXu.2018. SourceCode. RetrievedJuly21,2018from https://github.com/
liuhuigmail/FeatureEnvy/blob/master/Algorithm/train-CNN.py
[62]K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. 2017. Beyond a Gaussian
Denoiser:ResidualLearningofDeepCNNforImageDenoising. IEEETransactions
on Image Processing 26, 7 (July 2017), 3142–3155. https://doi.org/10.1109/TIP.
2017.2662206
[63]Min Zhang, Tracy Hall, and Nathan Baddoo. 2011. Code Bad Smells: a review of
current knowledge. Journal of Software Maintenance and Evolution: Research and
Practice23, 3 (2011), 179–202. https://doi.org/10.1002/smr.521
396
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. 