Have We Seen Enough Traces?
Hila Cohen and Shahar Maoz
School of Computer Science
Tel Aviv University, Israel
Abstract —Dynamic speciﬁcation mining extracts candidate
speciﬁcations from logs of execution traces. Existing algorithms
differ in the kinds of traces they take as input and in thekinds of candidate speciﬁcation they present as output. Onechallenge common to all approaches relates to the faithfulnessof the mining results: how can we be conﬁdent that the extractedspeciﬁcations faithfully characterize the program we investigate?Since producing and analyzing traces is costly, how would weknow we have seen enough traces? And, how would we know wehave not wasted resources and seen too many of them?
In this paper we address these important questions by
presenting a novel, black box, probabilistic framework based ona notion of log completeness, and by applying it to three differentwell-known speciﬁcation mining algorithms from the literature:k-Tails, Synoptic, and mining of scenario-based triggers andeffects. Extensive evaluation over 24 models taken from 9 differentsources shows the soundness, generalizability, and usefulness ofthe framework and its contribution to the state-of-the-art indynamic speciﬁcation mining.
I. I NTRODUCTION
Much literature has been published on dynamic speciﬁ-
cation mining, which extracts candidate speciﬁcations from
logs of program execution traces. Different approaches suggestdifferent algorithms, which differ in the kinds of traces theytake as input and in the kinds of candidate speciﬁcation theypresent as output (in terms of content, expressive power, andformat). Example approaches include [5], [13]–[15], [17], [18],[21], [22], [26], [27], [29]–[31], [37], [38], [41], [42].
One challenge common to all approaches relates to the
faithfulness of the mining results: how can we be conﬁdentthat the extracted speciﬁcations faithfully characterize theprogram we investigate? As the mined speciﬁcations may beused for comprehension, test generation, and veriﬁcation, theirfaithfulness to the program we investigate is important. Y et,producing and analyzing traces is costly, so how would weknow we have seen enough of them? And, how would weknow we have not wasted resources and seen too many ofthem?
In this paper we address these important questions by
presenting a novel, black box, probabilistic framework basedon a notion of log completeness. We consider logs of executiontraces extracted from a running system under investigation.Intuitively, a log is complete with regard to a speciﬁc systemand a mining algorithm, if adding any new system trace to thelog will not change the output of the algorithm. In dynamicspeciﬁcation mining, the system and its full set of systemtraces is unknown. Therefore, given a log of system traces,we estimate the probability that the log is complete. We saythat this estimation is the log’s conﬁdence.A log’s conﬁdence may be practically used as follows. If
not many traces are available, one can compute the conﬁdenceof the available log in order to estimate the expected faith-fulness of the mining results. A low conﬁdence of, say, 0.2,hints that the mining results may be far off from characterizingthe behavior of the system under investigation. A very highconﬁdence of, say, 0.95, hints that the mining results areprobably very close to correctly characterize the behavior ofthe system under investigation. If producing and analyzingmore traces is possible but costly, one can set a high conﬁdencethreshold of, say, 0.85, and stop adding new traces when thethreshold is reached.
We apply the new framework to three different well-known
dynamic speciﬁcation mining algorithms from the literature: k-Tails [6], Synoptic [5], and mining of scenario-based triggersand effects [25]. Inspired by InvariMint [4], we represent eachalgorithm using a set of log properties. For k-Tails, we usea property describing the existence of possible sequences oflength k in the log. For Synoptic, we use four different prop-erties, corresponding to the k-Tails property with k=2 and
to the three temporal invariant properties used by the Synopticalgorithm. For triggers and effects, we use a single three-valuedproperty representing the possible relation between the triggerand all of the possible effects (or vice versa). The frameworkassumes that mining randomly and independently samplestraces from the log. For all three algorithms, we compute theconﬁdence of a set of traces, by estimating the probability thatit manifests the complete properties that any log of the systemunder investigation can manifest. Each log property requires adifferent probabilistic estimation.
An interesting feature of our notion of completeness is that
it is relative to a system under investigation and a speciﬁcmining algorithm: a log may be complete with regard to onealgorithm and incomplete with regard to another. Y et, comput-ing a log’s conﬁdence with regard to a speciﬁc algorithm doesnot require running the speciﬁcation mining algorithm itself.
An important feature of our notion of conﬁdence is its non-
monotonicity: adding traces to a log does not guarantee anincrease in conﬁdence and may even decrease it (still, a log’sconﬁdence doesn’t depend on the order of traces in it). Wediscuss this apparently counter-intuitive feature in Sect. VII.
Finally, we present an extensive evaluation of our work,
including the results of experiments with 24 models of real-world systems taken from publicly available previously pub-lished works. The results show that for all three algorithms, theprobability that a log is complete can be estimated efﬁcientlyand be effectively applied, with high reliability, to improvethe use of the dynamic speciﬁcation mining algorithm and theconﬁdence one may have in its results.
2015 30th IEEE/ACM International Conference on Automated Software Engineering
978-1-5090-0025-8/15 $31.00 © 2015 IEEE
DOI 10.1109/ASE.2015.6293
In recent preliminary work [8] (ASE’14 New Ideas Track)
we have presented a notion of conﬁdence computation for k-
Tails, termed k-conﬁdence, with preliminary evaluation of itseffectiveness. Our present paper extends this previous worksigniﬁcantly, and makes the following contributions:
• The presentation of a general framework for log con-ﬁdence and its application, beyond k-Tails, to two ad-ditional well-known speciﬁcation mining algorithms;
• An extensive evaluation over 24 real-world models,which provides strong evidence for the correctness andeffectiveness of the conﬁdence computations;
• An implementation available for reproduction and ex-tension for additional speciﬁcation mining algorithms.
Sect. II presents examples for the use of log conﬁdence, for
Synoptic and for mining triggers and effects. Sect. III presentsthe formal foundations of the log completeness frameworkand Sect. IV presents its application to the three dynamicspeciﬁcation mining algorithms. Sect. V presents an exampleconﬁdence computation. Sect. VI presents the evaluation,Sect. VII discusses design decisions and limitations, Sect. VIIIdiscusses related work, and Sect. IX concludes.
II. E
XAMPLES
We use small examples to demonstrate the usage of log
conﬁdence. All traces and models discussed in the examplesbelow are available in [1]. The presentation of the examplesis semi-formal, for illustrative purposes.
A. Example I
In [5], the authors use an example of a shopping cart to
demonstrate how Synoptic is able to reveal a bug where the
user can use an invalid coupon to reduce the price. To revealthis bug, the problematic behavior must appear in the traces.
Consider an engineer having a log of 34 traces of the
shopping cart system, adapted from the example traces of [5].Fig. 1 shows the model suggested by Synoptic for this log (thedashed transition invalid-coupon toreduce-price is
not part of the model suggested by Synoptic for this 34 traces
log). The model does not include the bug so at this stage, theuser may wrongly conclude that the shopping cart system hasno bugs. How would she know if more traces are needed?
Indeed, adding 15 more traces, and feeding the resulting log
of 49 traces to Synoptic, results in a revised model as shownin Fig. 1 (including the dashed transition), which reveals theinvalid coupon bug.
Our tool computes a conﬁdence of 0.59 to the ﬁrst log
and of 0.98 to the second log. This conﬁdence is essentiallyan estimation for the probability that the log is complete,computed solely based on the traces themselves. If the userhas set a minimum conﬁdence threshold of 0.95 (which is avery safe threshold according to our evaluation), she would nothave stopped analyzing traces too soon, i.e., before ﬁnding thebug.
Should she continue to analyze more traces? Given the
computed conﬁdence of 0.98, the probability that additionaltraces will reveal new behaviors is very small. Indeed in ourexample, an extension of the log with 22 additional traces (all
Fig. 1: Shopping cart model as mined by Synoptic from thelog of 34 traces (without the dashed transition) and from thelog of 49 traces (including the dashed transition)
new traces, not duplicates of any of the traces seen before)
resulted in a slightly higher conﬁdence of 0.99 but in the same
model as was suggested by Synoptic for the 49 traces. Thus,by stopping the analysis when conﬁdence reached 0.95 theengineer saved the resources required in order to produce andanalyze the additional traces, yet did not lose any information.
B. Example II
In mining scenario-based triggers and effects [25], the
engineer provides a trigger scenario (a sequence of events)
as input, and receives a set of candidate effects (sequences ofevents) as output, with the following semantics: whenever thetrigger scenario occurs in the traces (in the speciﬁed eventsorder but possibly with other events interleaved), eventuallyeach of the candidate effects occurs too (again, in the speciﬁedevents order but possibly with other events interleaved).
In [17], the authors use an example set of execution traces
from CrossFTP, an open-source FTP server [11]. The full data
set, available from [16], contains 54 traces with an averagetrace length of 34, over an alphabet of 50 events.
Consider an engineer investigating the behavior of the
CrossFTP server, looking for scenario-based effects to thetrigger consisting of a call to open a new connection and acall to transfer data (used in CrossFTP both in the context ofupload and in the context of download):ConnectionManagerImpl.newConnection(...)RequestHandler.transfer(...).
When the engineer executed the mining with this trigger,
on a sub log of randomly selected 24 traces from the fulllog, more than 12 unique candidate effects were reported. For
94example, one of these candidate effects was the scenario:
ConnectionManagerImpl.closeConnection(...)ConnectionManagerImpl.dispose(...).
However, none of these candidate effects truly characterizes
the behavior of the CrossFTP . When executing mining oftriggers and effects with the same trigger on the full log of 54traces, no effect is reported, since a few traces include multiplecalls to the transfer(...) method with no occurrence
of an effect between them. Indeed, in CrossFTP , no scenarioexists which always occurs in this log after the given trigger.
Our tool computes a conﬁdence of 0.2 to the 24 traces
log, and a conﬁdence of 0.98 to the 54 traces log. Again,this conﬁdence is essentially an estimation for the probabilitythat the log is complete, computed solely based on the tracesthemselves. Indeed, mining scenario-based triggers and effectsfrom the log with the low conﬁdence produced results thatdo not characterize the true behavior of the system underinvestigation. In other words, the results of mining from a logthat has a low conﬁdence should not be trusted.
C. Running Example
We take the java.util.zip.ZipOutputStream
model from [20] as a small running example for this paper.
The model consists of 3 states over an alphabet of 5 events. Weconsider a randomly generated log for this model, consistingof 7 traces. See Fig. 2.
III. L
OG COMPLETENESS FRAMEWORK
A. Basic Deﬁnitions
A trace over an alphabet Σis a ﬁnite word
σ=/angbracketlefte1,e2,...,e m/angbracketrightwheree1,...,e m∈Σ.F o rj ≥1we
useσ(j)to denote the jth element in σ.
LetMbe a model over an alphabet Σ.W eu s eT (M)⊆Σ∗
to denote all traces accepted by the model M. A log of M,
l⊆T(M)is a ﬁnite set of traces from T(M). We denote the
set of all possible logs of MbyL(M).
The basic deﬁnition underlying log completeness is the
log-property LP, consisting of a pair of functions. The ﬁrst
function, LPtr, maps every trace σand a sequence of events
esto a value in some domain Dtr. Intuitively, LPtrassigns a
value to the relation between the property LP and the trace.
The second function, LPlog, maps subsets of DtrtoDlog;i t
aggregates the trace level results to the log level.
Example 1. IfDtr=Dlog={0,1},LPtrmay be used to
represent whether a property holds in the trace, and LPlog
may represent whether it holds in an entire log. An example
property is an invariant of the form ‘a always precedes b’.
Deﬁnition 1 (log-property). A log-property
LP=/angbracketleftLPtr,LP log/angbracketrightis a pair of functions LPtr:Σ∗×Σi→
DtrandLPlog:P(Dtr)→Dlog.
We say that a log l∈L(M)is complete with regard to
a log-property LP if the information one may extract about
the property from the log lis equal to the information one
may extract about it from any log that includes l(and thus
speciﬁcally from all the traces in T(M)). Formally:Deﬁnition 2 (LP-log-completeness). Al o gl ∈L(M)is
complete with regard to a log-property LP=/angbracketleftLPtr,LP log/angbracketright
iff∀l/prime∈L(M)s.t.l⊆l/prime,∀es∈Σi
LPlog({LP tr(σ,es)|σ∈l})=LPlog({LP tr(σ,es)|σ∈l/prime}).
We now lift the completeness deﬁnition from properties to
algorithms. A speciﬁcation mining algorithm Aaccepts a log
l∈L(M)as input and outputs a candidate model A(l)=M/prime.
We represent an algorithm Aby a set of log properties
LP(A)={LP1,LP2,...,LPk}. We say that a log lis
complete with regard to an algorithm Aifflis complete with
regard to each of the log-properties of A. Formally:
Deﬁnition 3 (A-log-completeness). A logl∈L(M)is
complete with regard to an algorithm Aiff∀LP∈LP(A),l
is complete with regard to LP.
Note that to make the framework useful, one should deﬁne
the set of log-properties LP(A) such that, if l∈L(M)is
complete with regard to A, adding any trace σ∈T(M)tol
will not affect the candidate model Acomputes for l(indeed
this is part of our evaluation, see Sect. VI-B). Also note that logcompleteness is deﬁned relative to an algorithm (speciﬁcallya set of log-properties). The same log may be complete withregard to one algorithm and incomplete with regard to anotheralgorithm.
B. Estimating Log Completeness
Given an algorithm Aand a log l∈L(M), our goal is
to estimate the probability that lis complete with regard to
A, i.e., to compute l’s conﬁdence. To do this, we compute
l’s conﬁdence with regard to the LPsi nLP(A)and take the
minimum (intuitively, choosing the minimum is a conservative
choice).
For each LP∈LP(A), we deﬁne a random variable
Y
LP(σ)overΩ=T(M), which maps a trace to its property
results. Formally:
YLP(σ):YLP(σ)[es]=LPtr(σ,es).
Example 2. We denote the invariant property ‘a always
precedes b’ mentioned above by LP←. For the trace tr2
of our running example in Fig. 2 and the sequences/angbracketleftinit,closeEntry /angbracketrightand/angbracketleftputNextEntry,closeEntry /angbracketright,w e
haveY
LP←(tr2)[/angbracketleftinit,closeEntry /angbracketright]=1 and
YLP←(tr2)[/angbracketleftputNextEntry,closeEntry /angbracketright]=0 , because the
ﬁrst holds in the trace while the second does not.
Fory∈D|Σ|i
tr we denote the probability that YLP equals
ybyπLP(y):
πLP(y)=P[YLP=y].
Example 3. To continue our example above, where Dtr=
Dlog={0,1}, for the invariant property ‘a always precedes
b’, we have i=2 and soycan be viewed as a Σ×Σ
2-dimensional array (a matrix) over {0,1}. In our running
example the alphabet size is |Σ|=5 and so for this property
we will use a 5×5matrix (see later in Table I).
95tr1:init,closeEntry,close,close
tr2:init,closeEntry,putNextEntry,closeEntry,putNextEntry,closeEntry,close,close
tr3:init,putNextEntry,write,putNextEntry,putNextEntry,closeEntry,close
tr4:init,putNextEntry,write,close
tr5:init,close
tr6:init,putNextEntry,write,close,close
tr7:init,closeEntry,putNextEntry,write,closeEntry,closeEntry,putNextEntry,close
Fig. 2: The running example model of java.util.zip.ZipOutputStream from [20], and 7 randomly generated traces
used to demonstrate conﬁdence computation.
πLP(y)is the probability that in a random trace from
T(M)we get the values of LP as they are encoded in y.
It is determined by MbutMis considered unknown.
We consider all traces from a log lto be samples from
YLP. We assume that traces are randomly and indepen-
dently chosen from T(M).I f|l|=nwe denote them
byYLP1,YLP2,...,Y LP n . These are independent, identically
distributed random variables, versions of YLP. Another random
variable we deﬁne is Yn
LP, which aggregates all these samples
to the property values for the entire log:
Yn
LP:Yn
LP[es]=LPlog({YLP i[es])|1≤i≤n})
We now deﬁne the true, but unknown, log-property values,
fLP(π), in order to later compute the probability that Yn
LP is
equal to it:
fLP(π):fLP(π)[es]=LPlog({y[es]|π(y)>0}).
Example 4. For the running example model in Fig. 2,
the log property ‘always precedes’ LP←, and the sequence
/angbracketleftputNextEntry,closeEntry /angbracketright, since there are traces in T(M)
where the invariant is not violated (e.g., tr3) and others where
it is violated (e.g., tr2), the property does not hold in the log
and sofLP←(π)[/angbracketleftputNextEntry,closeEntry /angbracketright]=0 .
Note that Mdetermines fLP(π). We can now write Def. 3
using the above notation as follows: a log lis complete with
regard to an algorithm Aiff
∀LP∈LP(A).Yn
LP=fLP(π).
Recall that our goal is to estimate the probability that lis
complete with regard to A. Using the notation deﬁned above,
what we are looking to estimate is P[Yn
LP=fLP(π)].
The above represents l’s conﬁdence with regard to a single
log-property LP. We deﬁne the conﬁdence of a log lwith
regard to an algorithm A, to be the minimum of l’s conﬁdence
with regard to all LPsi nLP(A). Formally:
Deﬁnition 4 (A-log-conﬁdence). The conﬁdence of a log l∈
L(M)with regard to an algorithm Ais
min{P[Yn
LP=fLP(π)]|LP∈LP(A)}.
IV . L OG COMPLETENESS APPLIED
We now present the application of the framework to three
different previously published dynamic speciﬁcation mining
algorithms: k-Tails [6], Synoptic [5], and mining of scenario-based triggers and effects [25]. For each algorithm we deﬁnethe relevant log-properties LP(A)and show the estimation of
P[Y
n
LP=fLP(π)]for eachLP∈LP(A).A. k-Tails
k-Tails [6] is a dynamic speciﬁcation mining algorithm
based on merging states whose future kstates are identical.
It has been used in several variants in many recent works,e.g., [3], [9], [24], [28], [29], [39]. Below we reformulate thecomputations of [8] using the framework deﬁned above.
1) Log Properties: To apply the log completeness frame-
work to k-Tails we deﬁne a single log-property, LP
⊿k,
for the existential property ‘k-directly-follows’. Roughly, theproperty ‘k-directly follows’ for a sequence of events es=
/angbracketlefte
1,e2,...,e k/angbracketrightholds in a trace iff the sequence appears
somewhere in the trace.
The intuition behind the use of this property is as follows.
Consider a model produced by k-Tails for a log, and a newtrace whose all subtraces of length k+1 appear in the produced
model. Applying k-Tails to a new log that consists of theoriginal log and the new trace, produces the same model. Theproof for this claim, albeit using a different formulation, canbe found in [4].
The deﬁnitions of LP
⊿k
tr andLP⊿k
logbelow follow the
semantics of ‘k-directly-follows’ as an existential property.Formally, we use D
tr=Dlog={0,1}and deﬁne:
LP(Ak-Tails)={LP⊿k}where
LP⊿k
tr(σ,/angbracketlefte1,e2,...,e k/angbracketright)=/braceleftBigg1∃j/logicalandtext
1≤m≤kσ(j+m−1) =em
0otherwise
LP⊿k
log(S)=/braceleftbigg
11∈S
0otherwise
2) Computing Log Conﬁdence: The probability that an
existential property does not hold in T(M)but appears in one
of the traces is zero. Thus, we only need to consider the othercase, where the sequence of length kdoes not appear in the
traces (Y
n[es]=0 ) but is possible in the model (f [es]=1 ).
Formally:1
P[Yn=f]=1−P[∃es.Yn[es]=0∧f[es]=1 ]
≥1−Σ
esP[Yn[es]=0∧f[es]=1 ]
P[Yn[es]=0∧f[es]=1 ]=/braceleftbigg
P[Yn[es]=0 ] f[es]=1
0 f[es]=0
=/braceleftBigg/producttext
1≤i≤nP[Yi[es]=0 ] f[es]=1
0 f[es]=0
We useqesto denote the probability that the existential
property for esholds on a random trace from T(M), i.e., that
1Since they are ﬁxed, we omit the speciﬁc LP andπfrom the formulas in
this section
96the sequence /angbracketlefte1,e2,...,e k/angbracketrightappears somewhere in the trace.
Whenf[es]=1 we have qes>0and/producttext
1≤i≤nP[Yi[es]=0 ]=
(1−qes)n.
Sinceqesis unknown, we estimate it using the average of
thenrandom variables Yi
ˆqes=n/summationdisplay
i=1Yi[es]
n
and so overall, we have
P[Yn=f]≥1−/summationdisplay
{es|ˆqes>0}(1−ˆqes)n.
B. Synoptic
Synoptic [5] is a dynamic speciﬁcation mining algorithm
based on three temporal invariants of length 2 and a process
of reﬁnement/coarsening using counter-example-guided-abs-traction-reﬁnement (CEGAR) and a variant of k-Tails.
1) Log Properties: To apply the framework to Synoptic
we deﬁne four log-properties, for three invariant propertiesand for one existential property. The three invariant propertiesare ‘always followed by’ (denoted →), ‘always precedes’
(denoted ←), and ‘never followed by’ (denoted /notarrowright). The exis-
tential property is ‘2-directly-follows’ (denoted ⊿
2). Formally:
LP(ASynoptic)={LP→,LP←,LP/notarrowright,LP⊿2}, and all four
Synoptic’s log-properties use Dtr=Dlog={0,1}.
The intuition behind the use of these properties is as
follows. First, the three invariants are mined by Synopticand then used during the reﬁnement process; the ﬁnal modelproduced by Synoptic is guaranteed to satisfy all three in-variants. Second, the existential ‘2-directly-follows’ propertycorresponds to the initial step in the Synoptic algorithm, whichbuilds a permissive model that accepts all traces. Formalcorrectness proof for the selection of these properties appearin [4].
The deﬁnition of LP
→=/angbracketleftLP→
tr,LP→
log/angbracketrightis based on its
semantics. LP→
trtakes two events as input and outputs 1 iff
every occurrence of the ﬁrst is followed by an occurrenceof the second. LP
→
log(S)takes the result of applying LP→
tr
to all traces and outputs 1 iff all traces satisfy the invariant.Formally:
LP
→
tr(σ,/angbracketlefte1,e2/angbracketright)=/braceleftbigg
1∀kσ(k)=e1⇒∃ m>kσ(m)=e2
0otherwise
LP→
log(S)=/braceleftbigg
10/∈S
0otherwise
The deﬁnition of the two other invariants is similar: LP←
tr
takes two events as input and outputs 1 iff every occurrenceof the second is preceded by an occurrence of the ﬁrst; LP
/notarrowright
tr
takes two events as input and outputs 1 iff no occurrence ofthe ﬁrst is followed by an occurrence of the second. Formally:
LP
←
tr(σ,/angbracketlefte1,e2/angbracketright)=/braceleftbigg
1∀kσ(k)=e2⇒∃ m<kσ(m)=e1
0otherwise
LP/notarrowright
tr(σ,/angbracketlefte1,e2/angbracketright)=/braceleftbigg
1∀kσ(k)=e1⇒¬ ∃ m>kσ(m)=e2
0otherwise
All three log-properties are invariants, so they have the
sameLPlogfunction, that is LP→
log=LP←
log=LP/notarrowright
log.Finally, the log-property LP⊿2, relating to the existential
property ‘2-directly-follows’, is a special case of the ‘k-directlyfollows’ property deﬁned above for k-Tails (see Sect. IV -A1),fork=2 .
2) Computing Log Conﬁdence: We estimate the probability
of log completeness with regard to Synoptic by taking theminimum of the probabilities of log completeness for eachproperty alone.
The three invariant properties .W eu s ees to denote the
sequence /angbracketlefte
1,e2/angbracketright.
For the three invariant properties, the computation is the
same. The probability that the invariant holds in T(M)but is
violated in one of the traces is zero. Thus, we only need to
consider the other case, where the invariant holds in all tracesthat we have seen (Y
n[es]=1 ) but not in T(M)(f[es]=0 ).
Formally:
P[Yn=f]=1−P[∃es.Yn[es]=1∧f[es]=0 ]
≥1−Σ
esP[Yn[es]=1∧f[es]=0 ]
P[Yn[es]=1∧f[es]=0 ]=/braceleftbigg
P[Yn[es]=1 ] f[es]=0
0 f[es]=1
=/braceleftBigg/producttext
1≤i≤nP[Yi[es]=1 ] f[es]=0
0 f[es]=1
We useqesto denote the probability that the invariant holds
foreson a random trace from T(M). Whenf[es]=0 we
haveqes<1and/producttext
1≤i≤nP[Yi[es]=1 ]=qn
es.
Sinceqesis unknown we estimate it using the average of
thenrandom variables Yi
ˆqes=n/summationdisplay
i=1Yi[es]
n(1)
and overall, for each of the three invariant properties we have
P[Yn=f]≥1−/summationdisplay
{es|ˆqes<1}(ˆqes)n. (2)
The existential property. Computing conﬁdence for the exis-tential property ‘2-directly-follows’ is again a special case ofthe computation of ‘k-directly follows’ we have shown abovein Sect. IV -A2, so we do not repeat it here.
Finally, we consider the log’s conﬁdence with regard to the
Synoptic algorithm as a whole to be the minimum of the fourprobabilities of the log completeness properties.
C. Mining Scenario-Based Triggers & Effects
Mining scenario-based triggers and effects (mining t/e) was
presented in [25]. Roughly, given a trigger scenario (a sequence
of events), the miner looks for all effect scenarios (sequencesof events) such that for each, whenever the trigger occurs ina trace (in the speciﬁed events order but possibly with otherevents interleaved), eventually the effect occurs in this trace
97(in the speciﬁed events order but possibly with other events
interleaved). Below we use the notation from [25].
Given a trigger scenario tgand an effect scenario es,
pos(tg ++es) is the set of all positive witnesses of the combined
scenario tg ++es, i.e., all cases where an occurrence of tgis
eventually followed by an occurrence of es; andneg(tg ++es)
is the set of all negative witnesses of the combined scenariotg
++es, i.e., all cases where an occurrence of tgis not followed
by an occurrence of es. Formal deﬁnitions appear in [25].
We consider the case where the input consists of a trigger
and the miner looks for effects. The other case is symmetric.
1) Log Properties: We deﬁne a single log-property, cor-
responding to the following: given a trigger and a candidateeffect, is it true that whenever the trigger occurs, eventuallythe effect occurs too? We denote this trigger/effect property
byt/e:LP(A
Trigger/Effect )={LPt/e}.
The intuition behind the use of this property is that it
is equivalent to the property which the algorithm looks for:
log completeness with regard to this property entails that themining algorithm results are indeed correct and complete withregard to the true model.
The deﬁnition of LP
t/e=/angbracketleftLPt/e
tr,LPt/e
log/angbracketrightis based on
its semantics. LPt/e
tr takes a trace and a candidate effect as
input and outputs 1 (true) iff the trace has at least one positivewitness and no negative witnesses for the combined triggereffect, 0 (false) iff the trace has at least one negative witnessfor the combined trigger effect, and -1 (unknown) if the triggernever occurs in the trace. The domains for the log-property
{LP
t/e}are three valued: Dtr=Dlog={1,0,−1}.
LPt/e
log(S)takes the result of applying LPt/e
tr to all traces
and outputs 1 iff it returned 1 for at least one trace and
returned 0 for no trace. Formally:
LPt/e
tr(σ,es)=/braceleftBigg1|pos(tg ++es)|>0∧|neg(tg ++es)|=0
0|neg(tg ++es)|>0
−1otherwise
LPt/e
log(S)=/braceleftBigg11∈S∧0/∈S
00∈S
−1otherwise (S={−1})
2) Computing Log Conﬁdence: We useesto denote the
sequence /angbracketlefte1,e2,.../angbracketright; the length of the effect we are looking
for is unbounded.
The computation considers the possible cases where the log
and the model do not agree. First, the case where the triggerdoes not occur in the log (Y
n[es]=−1) although it is possible
inT(M)(f[es]/negationslash=−1). Second, the case where the trigger
occurs in the log with no negative witnesses ( Yn[es]=1 )
although the combined trigger effect is not true T(M)(f[es]=
0). (Other cases are impossible, e.g., the case where we seea negative witness in the log although the combined triggereffect is true in T(M)). Formally:
P[Y
n=f]=1−(P[∃esYn[es]/negationslash=f[es]])
≥1−/parenleftbig
Σ
esP[Yn[es]=−1∧f[es]/negationslash=−1]
+Σ
esP[Yn[es]=1∧f[es]=0 ]/parenrightbig
We compute each of the two probabilities above as follows.
We useqtg++esandqtgto denote the probability that a randomtrace from T(M)has only positive witnesses of tg ++esandtg
respectively. For the ﬁrst probability, we have
P[Yn[es]=−1∧f[es]/negationslash=−1] =/braceleftbigg
P[Yn[es]=−1]f[es]/negationslash=−1
0 otherwise
=/braceleftbigg
P[Yn[es]=−1]qtg>0
0 otherwise
Whenf[es]/negationslash=−1we haveqtg>0becausetgis possible
in the model. In this case, by deﬁnition of LPt/e
log(S),w eh a v e
the probability that the trigger will not occur in any of the n
traces:
P[Yn[es]=−1 ]=( 1−qtg)n.
For the second probability, we have
P[Yn[es]=1∧f[es] = 0] =/braceleftbigg
P[Yn[es]=1 ] f[es]=0
0 otherwise
Whenf[es]=0 we haveqtg/negationslash=qtg++esbecausetg ++esdoes
not hold in the model. In this case, by deﬁnition of LPt/e
log(S),
we have to consider the case where in the ntraces we have
seen the trigger at least once and we have not seen any negativewitnesses:
P[Y
n[es]=1 ]=( 1 −(1−qtg)n)×(1−(qtg−qtg++es))n
Finally, since qtgandqtg++esare unknown we estimate them
using the nrandom variables Yi
ˆqtg=/summationdisplay
Yi[es]∈{1,0}1
n,ˆqtg++es=/summationdisplay
Yi[es]=11
n
and so overall we have
P[Yn=f]≥1−/parenleftbig
Σ
ˆqtg>0(1−ˆqtg)n
+Σ
ˆqtg/negationslash=ˆqtg++es(1−(1−ˆqtg)n)×(1−(ˆqtg−ˆqtg++es))n/parenrightbig
.
D. Implementation
We have implemented the computation of log conﬁdence
for the three dynamic speciﬁcation algorithms. For each ofthe three algorithms, the implementation gets as input a log(a set of traces) and algorithm speciﬁc parameters (none forSynoptic, kfor k-Tails, and the trigger or effect sequence for
scenario-based trigger and effect). Note that the conﬁdencecomputation does not need to run the mining algorithm.
Given a log land an algorithm A, computing the log’s
conﬁdence starts with separately computing its conﬁdence foreach of the log-properties in LP(A). For each log-property
LP, for each trace σ∈l, and for each sequence es,w e
compute LP
tr(σ,es). The computed values are used as input
for the computation of the log’s conﬁdence with regard toLP. The reported log’s conﬁdence of lwith regard to A,i s
the minimum of all the conﬁdences for the log-properties.
98event close closeEntry init putNextEntry write
close - 0.43 (-0.00) 0.00 (-0.00) 0.29 (-0.00) 0.43 (-0.00)
closeEntry 0.57 (-0.02) - 0.00 (-0.00) 0.57 (-0.02) 0.57 (-0.02)
init 1.00 (-0.00) 1.00 (-0.00) - 1.00 (-0.00) 1.00 (-0.00)
putNextEntry 0.71 (-0.10) 0.57 (-0.02) 0.00 (-0.00) - 1.00 (-0.00)
write 0.57 (-0.02) 0.57 (-0.02) 0.00 (-0.00) 0.29 (-0.00) -
TABLE I: Example log conﬁdence computation with regard to the invariant property ‘always precedes’ ( LP←), for the log of
7 traces shown in Fig. 2. The computed conﬁdence for this property is 0.78. See Sect. V.
V. E XAMPLE COMPUTA TION
We demonstrate log conﬁdence computation on our running
example model and 7 randomly generated traces from this
model, shown in Fig. 2. For these traces, Table I shows thecomputation of log conﬁdence with regard to the invariantproperty ‘always precedes’ (LP
←, as used in the conﬁdence
computation for Synoptic, see Sect. IV -B).
The table cell i,j corresponds to the invariant ‘i al-
ways precedes j’, e.g., the table cell in the row of
closeEntry and column of close corresponds to the
property ‘closeEntry always precedes close’. The value
in table cell i,j isˆq/angbracketlefti,j/angbracketrightfrom Equ. 1. For example, the value
ˆqcloseEntry;close =0.57is the probability to have an instance
ofcloseEntry;close with ‘always precedes’ in a random
trace, given the log that we have (the invariant holds in 4 of the7 traces (tr
1,tr2,tr3, andtr7), so4/7=0.57is the probability
thatcloseEntry always precedes close). Since the log
has 7 traces, the negative contribution to the accumulatingconﬁdence for this property is (0.57)
7=0.02(see Equ. 2)
(that’s the probability that in a random log of size 7, thisinvariant will hold).
The overall conﬁdence for the ‘always precedes’ property
is computed by assigning all the numbers from the table to the
ˆq
ess in Equ. 2 (we omit the zeros from the formula):
1−(0.02+0.1+0.02+0.02+0.02+0.02+0.02) = 0.78.
VI. E V ALUA TION
The research questions guiding our evaluation are:
RQ1 Is the representation of the three speciﬁcation
mining algorithms using LPs sound?
RQ2 Can log conﬁdence be efﬁciently computed and
serve as an effective proxy for true log complete-
ness?
A. Models Used in Evaluation
In the evaluation we used 24 ﬁnite-state automaton models,
taken from 9 publicly available previously published works andreports: [12], [19], [23], [28], [32], [34]–[36] and [40]. Themodels varied in size and complexity: the alphabet size rangedfrom 7 to 42 (mean 14.42), the number of states ranged from5 to 24 (mean 12.62), and the number of transitions rangedfrom 15 to 209 (mean 37.58).
All logs, models, and implementation code described in this
paper are available for inspection and reproduction togetherwith documentation from [1].B. RQ1: Soundness of Representation
1) Methodology: To evaluate the soundness of the rep-
resentation of the three speciﬁcation mining algorithms us-ingLPs we use two deﬁnitions: LP-equivalence and A-
equivalence.
First, roughly, given a log-property LP, two logs are LP-
equivalent if their results agree on all sequences. Formally:
Deﬁnition 5 (LP -equivalence). For a log-property LP,t w o
logsl
1,l2areLP-equivalent iff ∀es∈Σi
LPlog({LP tr(σ,es)|σ∈l1})=LPlog({LP tr(σ,es)|σ∈l2}).
We trivially lift the above deﬁnition to a set of LPs, that
is, from each LP alone to the set LP(A).
Second, roughly, given a speciﬁcation mining algorithm
A, two logs are A-equivalent if they agree on the result of the
algorithm. Formally:Deﬁnition 6 (A-equivalence). For a speciﬁcation mining al-
gorithmA, two logs l
1,l2areA-equivalent iff A(l1)=A(l2).
Finally, we say that the LP representation of an algo-
rithmA,LP(A), is sound, iff LP(A)-equivalence implies A-
equivalence.
2) Experiment Design: For each model we used the follow-
ing experiment protocol. First, we generated traces from the
model using a trace generator. Second, for each algorithm, wefound the minimal sub log (in some arbitrary order of traces)which isLP(A)-equivalent to the entire log. Third, we ran the
speciﬁcation mining algorithm Aon the two logs and checked
whether the output is the same.
For each of the 24 models, and for each speciﬁcation
mining algorithm, k-Tails, Synoptic, and mining t/e, we ranthe experiment three times. In all experiments we used thetrace generator from [28] with path coverage (but high statecoverage for some of the models because the generator ran outof memory when computing path coverage for these models).
3) Results: In all executions, i.e., for all models and for all
algorithms, the model generated from the sub log was identical
to the one generated from the entire log.
To answer [RQ1], we have strong evidence for the sound-ness of the LPs representation, for all three algorithms.
C. RQ2: Effectiveness of Log Conﬁdence
1) Methodology: To evaluate the effectiveness of log con-
ﬁdence we use two key measures, reliability and redundancy.
99For a ﬁxed algorithm A, we deﬁne the reliability of a log to
be 1 if the log is complete with regard to Aand 0 otherwise.
For a set of logs L, a mean reliability close to 1 hints that
most of the logs are complete. For a ﬁxed algorithm A,w e
deﬁne the redundancy of a log to measure how close is it to its
minimal preﬁx log which is complete (assuming an arbitraryﬁxed order of traces). For a set of logs L, a mean redundancy
close to 0 and a low standard deviation hint that the logs donot include much redundant traces. Formally:
Deﬁnition 7 (reliability). For an algorithm A, the reliability
of a loglisrel(l)=/braceleftbigg
1lis complete with regard to A
0otherwise.
Deﬁnition 8 (redundancy). For an algorithm A,g i v e nal o gl
(in a ﬁxed arbitrary order), let i
min(l)be the minimal index
of traces in lsuch that the set of traces σ1,σ2,...,σ imin∈l
is complete with regard to A. The redundancy of a log lis
red(l)=1−imin(l)
|l|.
Example 5. Recall the log and model of our running example
shown in Fig. 2, and the results of computing its conﬁdence
with regard to the ‘always precedes’ property, as shown inTable I. This log’s reliability with regard to this property isrel(l)=1 . Since it reaches completeness for this property
already after the 4th trace and we have 7 traces, its redundancywith regard to this property is red(l)=1−4/7=0.43.
Note that to calculate reliability and redundancy, as in the
above example, one must know the system from which thetraces were extracted, so that she can calculate a true valuefor each property. This is typically unknown in a real-worldsetting, but it is known in our controlled evaluation setting.
In order to answer [RQ2], we are interested in the per-
formance of the conﬁdence computation, in the values of thereliability and their correlation with the conﬁdence values, andin the redundancy values, across the 24 models, for each ofthe three algorithms.
2) Experiment Design: For each model we used the follow-
ing experiment protocol. First, we generated traces from themodel using a trace generator. Second, we created an initial logby randomly selecting a minimal number of traces. Third, forseveral ﬁxed thresholds, we iteratively computed the currentlog’s conﬁdence and added a trace to it; adding traces to thecurrent log until we reached the ﬁxed conﬁdence threshold(or we ran out of traces to add). Finally, we computed thereliability and redundancy of the ﬁnal log.
For each model and for each algorithm, we repeated the
above protocol 200 times and computed the mean of reliabilityand redundancy for the sets of 200 logs.
In all experiments we used the trace generator of [28] with
path coverage (high state coverage for some of the modelsbecause the generator ran out of memory when computingpath coverage for them), a minimal number of 10 traces, and aseries of ﬁxed conﬁdence thresholds, from 0.20 to 0.95; i.e., foreach threshold th, we started with an initial log by randomly
selecting 10 traces, and continued the addition of traces to thelog until the probability that it is complete was at least th(or
we ran out of traces to add). We checked true completenessusing a model-checker, i.e., by expressing the relevant log-properties in temporal logic and verifying them against themodel.
We usedk=2 for k-Tails, and manually selected a trigger
of length 2 or 3 for the triggers and effects algorithm.
3) Results: Performance. All experiments were executed
on an ordinary laptop computer, Intel i7 CPU 3.0GHz, 8GBRAM with Windows 7 64-bit OS, Java 1.7.0
09 64-bit. For all
models, in all our experiments, conﬁdence computation neverexceeded 15 milliseconds. This shows that the log conﬁdencecomputation for the three speciﬁcation mining algorithms wedeal with is fast. It is not surprising as the computation is, bydeﬁnition, linear in the number of traces in the log.
Reliability. Fig. 3 shows the reliability results across the 24
models, for increasing conﬁdence thresholds, for each of the
three algorithms. The boxplots show the median reliability, the25th and 75th percentile with range 3/2 for whiskers.
For all three algorithms, the boxplots show that in general,
the reliability increases as the conﬁdence threshold increases,and the variance in reliability across the different modelsdecreases as the conﬁdence threshold increases. Speciﬁcally,when the conﬁdence threshold is 0.95, the reliability is veryhigh, and its variance across the different models is very low.
The boxplots also show that the reliability is always greater
or equal to the conﬁdence threshold. This is a result of theconservative nature of our conﬁdence computation; it is muchmore likely to underestimate completeness than to overestimateit. It is also a result of our experiment design: we stop addingtraces to the log once its conﬁdence pass the given threshold,i.e, the actual conﬁdence is higher than the threshold used andshown in the ﬁgure (the lower the threshold, the higher thepossible difference).
The Spearman’s rank correlation between conﬁdence and
reliability was ρ=.68(p<.05),ρ=.70(p<.05), and
ρ=.52(p<.05), for k-Tails, Synoptic, and triggers and
effects, respectively. These values are considered to expressstrong correlation [10, p. 140]. A power analysis for thecorrelation tests shows that our sample size of n= 120 is
much above the minimal size required with signiﬁcance levelα=.05, power = .8, and our resulting correlation coefﬁcients.
Redundancy. Fig. 4 shows the redundancy results across the
24 models, for increasing conﬁdence thresholds, for each of thethree mining algorithms. For all algorithms, the boxplots showthat in general, as expected, the redundancy increases as theconﬁdence threshold increases. When conﬁdence threshold is.95, the maximal redundancy is of about .74 and the maximalmedian redundancy is about .63. The worst case for the threealgorithms was reaching the .95 threshold with a log that isabout 4 times longer than its minimal complete sublog.
Log sizes differed much between the different models and
across the different conﬁdence thresholds, roughly rangingfrom 20 to 2000 traces per log. Some models required manymore traces than others to reach high conﬁdence (across allthree algorithms). The results for the individual models areavailable from [1].
We observe that the variance between the different models,
for both reliability and redundancy, seems higher for miningt/e than for the other two algorithms. This may be viewed as
100/g19/g17/g21/g19
/g19/g17/g22/g24
/g19/g17/g24/g19/g19/g17/g25/g24
/g19/g17/g27/g19/g19/g17/g28/g24/g19/g17/g23/g19/g17/g25/g19/g17/g27/g20/g17/g19
/g38/g82/g81/g73/g76/g71/g72/g81/g70/g72/g53/g72/g79/g76/g68/g69/g76/g79/g76/g87/g92
/g78/g237/g55/g68/g76/g79/g86
/g19/g17/g21/g19
/g19/g17/g22/g24
/g19/g17/g24/g19/g19/g17/g25/g24
/g19/g17/g27/g19/g19/g17/g28/g24/g19/g17/g23/g19/g17/g24/g19/g17/g25/g19/g17/g26/g19/g17/g27/g19/g17/g28/g20/g17/g19
/g38/g82/g81/g73/g76/g71/g72/g81/g70/g72/g53/g72/g79/g76/g68/g69/g76/g79/g76/g87/g92
/g54/g92/g81/g82/g83/g87/g76/g70
/g19/g17/g21/g19
/g19/g17/g22/g24
/g19/g17/g24/g19/g19/g17/g25/g24
/g19/g17/g27/g19/g19/g17/g28/g24/g19/g17/g21/g19/g17/g23/g19/g17/g25/g19/g17/g27/g20/g17/g19
/g38/g82/g81/g73/g76/g71/g72/g81/g70/g72/g53/g72/g79/g76/g68/g69/g76/g79/g76/g87/g92
/g48/g76/g81/g76/g81/g74/g3/g87/g18/g72
Fig. 3: Reliability results for the three speciﬁcation mining algorithms. See Sect. VI-C./g19/g17/g21/g19
/g19/g17/g22/g24
/g19/g17/g24/g19/g19/g17/g25/g24
/g19/g17/g27/g19/g19/g17/g28/g24/g19/g17/g22/g24/g19/g17/g23/g19/g19/g17/g23/g24/g19/g17/g24/g19/g19/g17/g24/g24/g19/g17/g25/g19/g19/g17/g25/g24
/g38/g82/g81/g73/g76/g71/g72/g81/g70/g72/g53/g72/g71/g88/g81/g71/g68/g81/g70/g92/g78/g237/g55/g68/g76/g79/g86
/g19/g17/g21/g19
/g19/g17/g22/g24
/g19/g17/g24/g19/g19/g17/g25/g24
/g19/g17/g27/g19/g19/g17/g28/g24/g19/g17/g22/g19/g17/g23/g19/g17/g24/g19/g17/g25/g19/g17/g26
/g38/g82/g81/g73/g76/g71/g72/g81/g70/g72/g53/g72/g71/g88/g81/g71/g68/g81/g70/g92/g54/g92/g81/g82/g83/g87/g76/g70
/g19/g17/g21/g19
/g19/g17/g22/g24
/g19/g17/g24/g19/g19/g17/g25/g24
/g19/g17/g27/g19/g19/g17/g28/g24/g19/g17/g19/g19/g17/g20/g19/g17/g21/g19/g17/g22/g19/g17/g23/g19/g17/g24/g19/g17/g25/g19/g17/g26
/g38/g82/g81/g73/g76/g71/g72/g81/g70/g72/g53/g72/g71/g88/g81/g71/g68/g81/g70/g92/g48/g76/g81/g76/g81/g74/g3/g87/g18/g72
Fig. 4: Redundancy results for the three speciﬁcation mining algorithms. See Sect. VI-C.
a weakness. However, the median values for mining t/e, are
higher for reliability and lower for redundancy, compared tothe other two algorithms, which may be viewed as a strength.Note though that the kind of candidate speciﬁcation mined bymining t/e is very different from the kind mined by the othertwo algorithms, hence they are not comparable.
To answer [RQ2], we have strong evidence that logconﬁdence can be efﬁciently computed and is an effectiveproxy for true completeness for the three speciﬁcationmining algorithms.
D. Threats to V alidity
We discuss threats to the validity of our results. First, the
selection of models in our evaluation may not represent typicalsystems. To mitigate this, we used 24 publicly available modelstaken from 9 previous works (see Sect. VI-A). Y et, we do notknow if these are representative of real-world systems.
Second, in our evaluation we used a publicly available
trace generator [28] with path coverage (when the model wastoo complex for the trace generator to handle, we used statecoverage). It is possible that one may get different results ifa different trace generator or a different coverage criterion areused. In a real-world setting, when the model is unknown, codecoverage methods may be used.
Third, the selection and order of traces in the log affect thepoint where the analysis may reach the conﬁdence thresholdand thus affect the point used to compute redundancy. Wemitigated this by using randomization in the selection of tracesand in the order in which they were analyzed, and by repeatingall evaluation experiments 200 times.
Fourth, we have evaluated the soundness of the LPs
empirically against speciﬁc implementations of the three algo-rithms. All have variants, which may produce slightly differentoutputs, e.g., Synoptic chooses the order in which invariantsare used in the CEGAR process arbitrarily. Thus, when wewriteA(l)in Sect. VI-B, we refer to a speciﬁc implementation
only.
Finally, our work presents a general framework for log
completeness and conﬁdence but the evaluation is limited tothree algorithms. One may get different results when the frame-work is applied to other algorithms. Still the results providesome evidence for the generalizability of the framework.
VII. D
ISCUSSION
We now discuss some important features, design decisions,
and several limitations of our present work. An importantfeature of our log conﬁdence computation is that it is notmonotonic but converges to 1 when the size of the logapproaches inﬁnity (for all three algorithms). On the one hand,as traces are added to a log, its conﬁdence may increase ordecrease; in the absence of additional information, e.g., aboutthe order in which traces are produced, a new trace may
101introduce new information (e.g., invalidate an invariant, reveal
an e wk-length sequence), which leads us to revise our previous
estimations. Thus, conﬁdence is not necessarily monotonic.Still, in contrast, it is important to note that our notion of logcompleteness is monotonic, i.e., by deﬁnition, any extension ofa complete log is complete. On the other hand, despite the nonmonotonicity, the expected conﬁdence converges to 1 when thesize of the log approaches inﬁnity (for the three algorithms).For example, for k-Tails, we have
lim
n→+∞E⎡
⎣1−/summationdisplay
{es|ˆqes>0}(1−ˆqes)n⎤⎦=1.
Thus, as the size of the log grows, the expected change in
conﬁdence that an additional trace may cause approaches zero.The proof for this claim can be found in [1].
In the presence of multiple LPsi nLP(A), we have chosen
to deﬁne conﬁdence as the minimum of conﬁdences overallLPs. We consider this to be a preliminary, conservative
choice, which, in the tradeoff between high reliability and lowredundancy, favors the former over the latter. Alternatively,one may choose other less conservative yet perhaps morerobust aggregate functions, e.g., the harmonic mean, or someweighted average in case some LPs are considered more
important than others. We leave the investigation of thesealternatives, per algorithm, to future work.
An important assumption underlying our framework is that
the traces are randomly and independently chosen from T(M).
This assumption may not always hold, e.g., if traces depend onrunning tests that were generated according to some strategy.We note, however, that our work is meant to be used to evaluatethe conﬁdence one may have in the results of applying miningalgorithms to logs of execution traces. This should not beconfused with evaluating the quality of a test suite.
Finally, an apparent limitation relates to the size of the log.
For logs with only a few traces, conﬁdence results are verysensitive and ﬂuctuate much, so they are practically useless.In practice however this is typically not a problem becausereal-world logs consist of many traces. Moreover, as statedabove, as the size of the log grows, the expected ﬂuctuationsapproach zero.
VIII. R
ELA TED WORK
Dynamic Speciﬁcation Mining. Much literature deals with
looking for candidate speciﬁcations in execution traces(e.g., [5], [13]–[15], [17], [18], [21], [22], [26], [27], [29]–[31],[37], [38], [41], [42]). The works differ in the kinds of tracesthey take as input and in the kinds of candidate speciﬁcationthey present as output.
In recent work, Beschastnikh et al. [4] have presented
InvariMint, a framework for declarative speciﬁcation of FSM-inference dynamic log analysis algorithms. Our work maybe viewed as building on InvariMint’s presentation of modelinference algorithms using declarative properties, as a key toits ability to deﬁne log completeness for k-Tails and Synoptic.Formally, however, we deﬁne properties in a different way.While InvariMint uses parameterized FSM and evaluationfunctions to describe property types, and applies compositionfunctions to combine them, our framework describes propertiesusing the functions LP
trandLPlog, which enable the compu-
tation of probabilities. It may be possible to deﬁne our notionof log completeness on top of the InvariMint framework. Weleave this for future work.
Addressing Completeness. Dallmeier et al. [12] consider
dynamic speciﬁcation mining and ask: what makes us believe
that we have seen sufﬁciently many executions? While it seemsthat we ask a similar question, our work is fundamentallydifferent. In [12], a partial set of traces is heuristically enrichedin order to explore previously unobserved aspects of theexecution space. In contrast, we consider a black box settingand provide a formal probabilistic measure to the notion of‘sufﬁciently many traces’. This allows engineers to assess thecompleteness of the traces they have, relative to the dynamicspeciﬁcation mining algorithm of their choice.
Hee et al. [33] presented a probabilistic approach to log
completeness of the α-algorithm [2], which mines Petri nets
and is used in the ﬁeld of process mining. Our work extendsthe work of Hee et al. signiﬁcantly: we present an algorithm-independent framework for log completeness and demonstrateits application to three algorithms from the dynamic speciﬁca-tion mining literature, k-Tails, Synoptic, and mining t/e.
Apart from our own recent preliminary work [8], where we
have presented a notion of conﬁdence computation for k-Tails,with preliminary evaluation, to the best of our knowledge,no other work has considered the question of estimating logcompleteness with regard to these three algorithms speciﬁcallyand with regard to dynamic speciﬁcation mining in general.
IX. C
ONCLUSION
In this paper we addressed the question of analyzing too
few or too many traces, in the context of dynamic speciﬁcationmining, by presenting a novel, black box, probabilistic frame-work based on a notion of log completeness. We applied theframework to three dynamic speciﬁcation mining algorithmsfrom the literature. Our evaluation over 24 models from theliterature provided evidence for the effectiveness and useful-ness of our work.
Given large logs as input, whose analysis may require too
much time and memory to the extent that make it impractical,our work can be used to analyze only a fraction of the logyet to construct a candidate speciﬁcation which is with highconﬁdence identical to the speciﬁcation one could build fromthe complete log. The work is part of our larger project oninvestigating ways to scale up speciﬁcation mining and otherlog analysis algorithms in face of long and complex logs,see [7].
Acknowledgements. We thank the anonymous reviewers for
their helpful comments. This work has been partly supported
by Len Blavatnik and the Blavatnik Family Foundation.
102REFERENCES
[1] Supporting materials website. http://smlab.cs.tau.ac.il/logcompleteness.
[2] Wil M. P . van der Aalst, T. Weijters, and L. Maruster. Workﬂow mining:
Discovering process models from event logs. IEEE Trans. Knowl. Data
Eng., 16(9):1128–1142, 2004.
[3] M. Acharya, T. Xie, J. Pei, and J. Xu. Mining API patterns as partial
orders from source code: from usage scenarios to speciﬁcations. In
ESEC/SIGSOFT FSE, pages 25–34, 2007.
[4] I. Beschastnikh, Y . Brun, J. Abrahamson, M. D. Ernst, and A. Kr-
ishnamurthy. Unifying FSM-inference algorithms through declarativespeciﬁcation. In ICSE, pages 252–261, 2013.
[5] I. Beschastnikh, Y . Brun, S. Schneider, M. Sloan, and M. D. Ernst.
Leveraging existing instrumentation to automatically infer invariant-constrained models. In T. Gyim ´othy and A. Zeller, editors, SIGSOFT
FSE, pages 267–277. ACM, 2011.
[6] A. W. Biermann and J. A. Feldman. On the synthesis of ﬁnite-
state machines from samples of their behavior. IEEE Trans. Comput.,
21(6):592–597, June 1972.
[7] N. Busany and S. Maoz. Behavioral Log Analysis with Statistical
Guarantees. In SIGSOFT FSE, 2015.
[8] H. Cohen and S. Maoz. The Conﬁdence in our k-Tails. In ASE, 2014.
[9] J. E. Cook and A. L. Wolf. Discovering models of software processes
from event-based data. ACM Trans. Softw. Eng. Methodol., 7(3):215–
249, 1998.
[10] G. W. Corder and D. I. Foreman. Nonparametric Statistics: A Step-by-
Step Approach. Wiley, 2nd edition, 2014.
[11] CrossFTP Server. http://sourceforge.net/projects/crossftpserver/.
[12] V . Dallmeier, N. Knopp, C. Mallon, G. Fraser, S. Hack, and A. Zeller.
Automatically generating test cases for speciﬁcation mining. IEEE
Trans. Software Eng., 38(2):243–257, 2012.
[13] F. C. de Sousa, N. C. Mendonc ¸a, S. Uchitel, and J. Kramer. Detecting
implied scenarios from execution traces. In WCRE, pages 50–59, 2007.
[14] M. El-Ramly, E. Stroulia, and P . G. Sorenson. From run-time behavior
to usage scenarios: an interaction-pattern mining approach. In KDD,
pages 315–324. ACM, 2002.
[15] M. Ernst, J. Cockrell, W. Griswold, and D. Notkin. Dynamically
discovering likely program invariants to support program evolution.
TSE, 27(2):99–123, 2001.
[16] D. Fahland, D. Lo, and S. Maoz. Mining Branching LSCs:
CrossFTP , Columba traces and results. 3TU.DataCentrum, 2013.doi:10.4121/uuid:aa7db920-aae6-4750-8975-cb739262f432.
[17] D. Fahland, D. Lo, and S. Maoz. Mining branching-time scenarios. In
ASE, pages 443–453. IEEE, 2013.
[18] M. Gabel and Z. Su. Online inference and enforcement of temporal
properties. In ICSE, pages 15–24, 2010.
[19] W. Grieskamp, N. Tillmann, and M. V eanes. Instrumenting scenarios
in a model-driven development environment. Information & Software
Technology, 46(15):1027–1036, 2004.
[20] I. Krka, Y . Brun, and N. Medvidovic. Automatic Mining of Speciﬁca-
tions from Invocation Traces and Method Invariants. In SIGSOFT FSE.
ACM, 2014.
[21] S. Kumar, S.-C. Khoo, A. Roychoudhury, and D. Lo. Mining message
sequence graphs. In ICSE, pages 91–100, 2011.
[22] C. Lee, F. Chen, and G. Rosu. Mining parametric speciﬁcations. In
ICSE, pages 591–600, 2011.[23] D. Lo and S.-C. Khoo. Quark: Empirical assessment of automaton-
based speciﬁcation miners. In WCRE, pages 51–60. IEEE Computer
Society, 2006.
[24] D. Lo and S.-C. Khoo. SMArTIC: towards building an accurate, robust
and scalable speciﬁcation miner. In SIGSOFT FSE, pages 265–275,
2006.
[25] D. Lo and S. Maoz. Mining scenario-based triggers and effects. In
ASE, pages 109–118. IEEE, 2008.
[26] D. Lo and S. Maoz. Scenario-based and value-based speciﬁcation
mining: better together. In ASE, pages 387–396, 2010.
[27] D. Lo, S. Maoz, and S.-C. Khoo. Mining modal scenario-based
speciﬁcations from execution traces of reactive systems. In R. E. K.Stirewalt, A. Egyed, and B. Fischer, editors, ASE, pages 465–468. ACM,
2007.
[28] D. Lo, L. Mariani, and M. Santoro. Learning extended FSA from
software: An empirical assessment. Journal of Systems and Software,
85(9):2063–2076, 2012.
[29] D. Lorenzoli, L. Mariani, and M. Pezz `e. Automatic generation of
software behavioral models. In W. Sch ¨afer, M. B. Dwyer, and V . Gruhn,
editors, ICSE, pages 501–510. ACM, 2008.
[30] L. Mariani, S. Papagiannakis, and M. Pezz `e. Compatibility and
regression testing of COTS-component-based software. In ICSE, pages
85–95. IEEE Computer Society, 2007.
[31] L. Mariani and M. Pezz `e. Behavior capture and test: Automated analysis
of component integration. In ICECCS, pages 292–301, 2005.
[32] S. Mouchawrab, L. C. Briand, Y . Labiche, and M. Di Penta. Assessing,
comparing, and combining state machine-based testing and structuraltesting: A series of experiments. IEEE Trans. Softw. Eng., 37(2):161–
187, Mar. 2011.
[33] Kees M. van Hee, Z. Liu, and N. Sidorova. Is my event log complete? -
a probabilistic approach to process mining. In RCIS, pages 1–7. IEEE,
2011.
[34] E. Poll and A. Schubert. V erifying an implementation of ssh. In WITS,
volume 7, pages 164–177, 2007.
[35] J. Postel. Transmission control protocol. RFC 793, Internet Engineering
Task Force, September 1981.
[36] M. Pradel, P . Bichsel, and T. R. Gross. A framework for the evaluation
of speciﬁcation miners based on ﬁnite state machines. In ICSM, pages
1–10. IEEE Computer Society, 2010.
[37] M. Pradel and T. R. Gross. Automatic generation of object usage
speciﬁcations from large method traces. In ASE, pages 371–382. IEEE
Computer Society, 2009.
[38] J. Quante and R. Koschke. Dynamic protocol recovery. In WCRE,
pages 219–228, 2007.
[39] S. P . Reiss and M. Renieris. Encoding program executions. In H. A.
M¨uller, M. J. Harrold, and W. Sch ¨afer, editors, ICSE, pages 221–230,
2001.
[40] J. Sun and J. Song Dong. Design synthesis from interaction and state-
based speciﬁcations. IEEE Trans. Softw. Eng., 32(6):349–364, June
2006.
[41] N. Walkinshaw and K. Bogdanov. Inferring ﬁnite-state models with
temporal constraints. In ASE, pages 248–257. IEEE, 2008.
[42] J. Y ang, D. Evans, D. Bhardwaj, T. Bhat, and M. Das. Perracotta:
mining temporal API rules from imperfect traces. In ICSE, pages 282–
291, 2006.
103