FLYAQ: Enabling Non-Expert Users to Specify and
Generate Missions of Autonomous Multicopters
Darko Bozhinoski1, Davide Di Ruscio2, Ivano Malavolta1, Patrizio Pelliccione2;3, Massimo Tivoli2
1Gran Sasso Science Institute, L’Aquila (Italy)
2University of L’Aquila, Department of Information Engineering, Computer Science and Mathematics (Italy)
3Chalmers University of Technology jUniversity of Gothenburg, Dep. of Comp. Science and Eng. (Sweden)
darko.bozhinoski@gssi.infn.it, davide.diruscio@univaq.it, ivano.malavolta@gssi.infn.it,
patrizio.pelliccione@gu.se, massimo.tivoli@univaq.it
Abstract —Multicopters are increasingly popular since they
promise to simplify a myriad of everyday tasks. Currently,
vendors provide low-level APIs and basic primitives to program
multicopters, making mission development a task-speciﬁc and
error-prone activity. As a consequence, current approaches are
affordable only for users that have a strong technical expertise.
Then, software engineering techniques are needed to support
the deﬁnition, development, and realization of missions at the
right level of abstraction and involving teams of autonomous
multicopters that guarantee the safety today’s users expect.
In this paper we describe a tool that enables end-users with
no technical expertise, e.g., ﬁreﬁghters and rescue workers,
to specify missions for a team of multicopters. The detailed
ﬂight plan that each multicopter must perform to accomplish
the speciﬁed mission is automatically generated by preventing
collisions between multicopters and obstacles, and ensuring the
preservation of no-ﬂy zones.
I. I NTRODUCTION
The near future will be pervaded by multicopters per-
forming a variety of tasks, like damage assessment after
earthquakes, searching for survivors after airplane accidents
and disasters, coastal surveillance, securing large public events,
monitoring oil and gas pipelines, observing trafﬁc ﬂows,
monitoring pollution emission, and protection of water re-
sources [14]. However, at the state of the art and practice
on-site operators must deeply know all the types of used
multicopters in terms of e.g., ﬂight dynamics and hardware
capabilities in order to correctly operate with them. On-site
operators have to simultaneously control a large number of
multicopters during the mission execution. Moreover, pro-
fessional use of multicopters often is realized by allocating
two operators for each multicopter, where the ﬁrst operator
controls the movements, while the second one controls the
instrumentation, like photo camera, its gimball, and other
sensors.
Nowadays, vendors provide low-level APIs and basic prim-
itives to program multicopters, thus making mission devel-
opment an (error-prone) activity that can be performed by a
restricted number of highly skilled professional stakeholders.
Tasks are very speciﬁc and this limits the possibilities for their
reuse across missions and organizations. Consequently, current
approaches are affordable only for users that have a strong
expertise in the dynamics and technical characteristics of
the used multicopters. Then, software engineering approaches
and methodologies are needed to support the deﬁnition, thedevelopment, and the realization of missions involving teams
of autonomous multicopters while guaranteeing safety.
This paper describes a tool for the deﬁnition of missions of
teams of multicopters and the generation of the detailed ﬂight
plan of each multicopter in the team. Speciﬁcally, starting from
a high-level description of the mission, FLYAQ automatically
generates a detailed ﬂight plan for a team of autonomous
multicopters that will satisfy the speciﬁed mission while pre-
venting collisions with other multicopters and obstacles, and
respecting no-ﬂy zones. End-users of FLYAQ have expertise
neither in ICT nor in multicopters dynamics, e.g., ﬁreﬁghters
and rescue workers. The webpage of the tool is available at
http://www.ﬂyaq.it .
II. O VERVIEW OF THE TOOL
FLYAQ ensures a strong adherence with the application
domain by providing an extensible domain speciﬁc language,
named Monitoring Mission Language (MML), which permits
to graphically deﬁne the missions. Extension mechanisms of
the language allow domain experts to specialize MML with
additional tasks that are speciﬁcally tailored to the considered
domain. For example, if operators are interested on monitoring
solar panel installations in a rural environment, the language
might be extended with tasks representing the concept of,
e.g., solar panel groups, thermal image acquisition, solar panel
damage discovery and notiﬁcation.
Mission Context Map MML 
QBL QBL model generation Multicopters configuration 
Mission Execution Engine 
Fig. 1. Overview of the FLYAQ tool
As shown in Figure 1, MML is composed of three layers:
i)to specify the mission by means of the modeling constructsMMLQBL model automatic generation 
QBL … Mission entering Mission exiting Mission tasks  execution 
… … … d1 d2 dn State transition State Synchronization and communication message Fig. 2. Overview of the approach
provided by the language, ii)to specify the context in which
the swarm of multicopters has to operate, such as no-ﬂy zones,
obstacles, etc., and iii)amap representing the geographical
zone where the mission will be executed.
Once the mission has been speciﬁed, waypoints and tra-
jectories are automatically calculated. They are represented
in an intermediate language named QBL. Examples of QBL
actions include: land,take off ,hover ,head to ,goto,read from a
sensor, send feedback to the ground station, and send/receive a
notiﬁcation to/from other multicopters. QBL has been deﬁned
through an iterative process involving experts of the application
domain considered by FLYAQ. QBL models are interpreted at
mission run-time by a set of software controllers, each of them
commanding a single multicopter according to the various
movements and actions contained into the QBL model. Each
controller is dedicated to a speciﬁc type of multicopter so that
it is able to account for the speciﬁc ﬂight dynamics and other
characteristics of the managed multicopter.
As shown in Figure 2, the QBL model automatically
generated out of the MML one is organized into nparts, each
of them describing the detailed ﬂight plan of a speciﬁc multi-
copter. The ﬂight plan of a multicopter can be abstracted as a
ﬁnite state transition system where each transition corresponds
to a QBL operation. Both cyclic and alternative behaviours
can be performed. Multicopters can exchange synchronization
and communication messages (see dashed arrows in the Fig-
ure 2). FLYAQ assumes that at the beginning of the mission
each multicopter will be positioned at its home location and
that at the end of the mission it will land to a (possibly
different) location. Then, the ﬁnite state system is structured
in three parts:
-Mission entering consisting of the operations required to start
the mission, e.g., take-off;
-Mission tasks execution consisting of the operations required
to accomplish each mission-speciﬁc task, e.g., searching for
an object in an area, taking a picture in the waypoints of an
area, detecting the level of carbon dioxide in a speciﬁc point;
-Mission exiting consisting of the operations required to
conclude the mission, e.g., going back to home, landing.
The main difﬁculty of the approach is that MML is
extensible and hence it is not possible to deﬁne once all the
translation rules needed to translate MML tasks into QBLoperations. Therefore, the automated generation is based on
three main concepts: (i) typology and characteristics of the
zone that is affected by the mission, (ii) strategies to be applied
to calculate the concrete movements that drones have to
perform, and ﬁnally (iii) actions to be performed while visiting
the identiﬁed waypoints. These concepts pose constraints and
permit to use consolidated and optimised algorithms (e.g.,
shortest-path calculation between two points, path planning,
etc.) that will be exploited by the generation process to, e.g.,
determine how a drone should visit a ﬂy-zone according to spe-
ciﬁc path planning policies. Then, a FLYAQ tool extender can
deﬁne concrete tasks for the considered domain by associating
these tasks to the general concepts deﬁned in the tool. In this
way the generation of drone speciﬁcation is fully automated.
The translation from MML to QBL relies on three auxiliary
functions that implement suitable operations to (i) distribute
the geographical area of each task into a set of (sub-)areas,
each of them assigned to a speciﬁc drone (function Divide );
(ii) let a drone approach the mission by reaching the starting
point in the zone assigned to it (function Appr ), and (iii)
cover the assigned zone according to the speciﬁed strategy
and by performing the speciﬁed actions for each way point
(function Cover ). The generation of auxiliary functions builds
on state-of-the-art and well-established algorithms for solving
problems like polygon partitioning, path ﬁnding, and graph
traversals [13]. The modularity of the current implementation
of FLYAQ allows a straightforward inclusion of alternative
algorithms and/or future advances of existing ones without
affecting the generation process.
The generation from MML to QBL has been implemented
by following the model-driven engineering paradigm. More
precisely, the outputs of the three auxiliary functions applied to
the source MML model are represented as three corresponding
models. Such models are taken as input by the model transfor-
mation MM2QBL , which is able to generate QBL models out of
MML ones (see Listing 1). Such transformation is developed by
means of the Atlas Transformation Language (ATL) [8], which
is a hybrid language containing declarative and imperative con-
structs. The fragment of the MM2QBL transformation consists
of a header section (line 2), transformation rules (lines 14-36),
and a number of helpers, which are used to navigate models
and to deﬁne complex calculations on them (lines 4-12).
According to the header section the MM2QBL transforma-
tion takes as input four input models to generate a QBL model
out of them. Helpers and rules are the constructs used to
specify the transformation behaviour. Each rule deﬁnes the
elements to be generated by means of target patterns (e.g., lines
32-35) that specify the instances of the target metamodel to be
generated (i.e., the DBS metaclass of the QBL metamodel) and
a set of bindings. A binding refers to a feature of the type, i.e.,
an attribute or a reference, and speciﬁes an expression whose
value initializes the feature.
To implement the generation of auxiliary functions, corre-
sponding helpers have been deﬁned. For instance, the divide
helper in lines 4-9 is able to read the source Divide model
and retrieves as output the sub-zones representing a spatial
partition of the task space.
TheMM2QBL transformation has been designed so to have
three main rules to manage the generation of target model frag-ments related to mission entering, tasks execution, and exiting
(see lines 20-22). Additional rules are speciﬁed for generating
speciﬁc elements of the target QBL models. For instance, the
generation of target TakeOff elements is performed by the
MissionEntering_TAKEOFF rule, which is called by the
MissionEntering rule (see line 34).
Listing 1. Fragment of the MM2QBL transformation
1module mml2qbl;
2create OUT : QBL from IN : MML, IN_APPR : APPR, IN_COVER :
COVER, IN_DIVIDE : DIVIDE;
3...
4helper def : divide(task : MML!Task, positions : Sequence(
MML!Coordinate), _context : MML!Context) : DIVIDE!
Output =
5DIVIDE!Mapping.allInstances()->
6select(m | m.input.task.name = task.name and
7 thisModule .sameCoordinates(m.input.positions,
positions) and
8 thisModule .sameContext(m.input._context,_context)
9 )->first().output;
10
11helper def : appr(...) : Sequence(APPR!Coordinate) = ...;
12helper def : cover(...) : Sequence(COVER!Output) = ...;
13...
14rule DroneTasks {
15from
16 s: MML!DroneTasks
17to
18 d: QBL!Drone (name <- s.drone.name)
19do{
20 thisModule .MissionEntering(d);
21 thisModule .MissionTasks(d);
22 thisModule .MissionExiting(d);
23}
24}
25...
26rule MissionEntering(d : QBL!Drone) {
27using {
28 approachingPoints : Sequence(APPR!Coordinate) = ...;
29 lastApproachingPoint : APPR!Coordinate = approachingPoints
->last();
30}
31to
32 t:QBL!DBS (
33 drone <- d,
34 transitionFunctions <- thisModule .MissionEntering_TAKEOFF
(t,si,lastApproachingPoint.altitude) ...
35 ) ...
36}
Due to space limitations, we do not provide the reader with
the full implementation of the MML2QBL transformation; the
interested reader can download it from http://www.ﬂyaq.it .
III. I NTENDED USERS OF THE TOOL AND SCENARIOS
The intended users of FLYAQ are public or private entities
that have to perform missions via multicopters. We also
expect that multicopters manufacturers will be interested in
participating in the industrial exploitation of the idea with the
aim of including in the produced multicopters the software
developed by FLYAQ. In fact, the software layer produced
by the project will allow to specify monitoring missions
at a high level of abstraction, that is, making possible the
deﬁnition for users non-expert in ICT, and that are experts
in a speciﬁc mission. Additional users of FLYAQ are model-
driven engineering experts that have to perform the extension
of the FLYAQ tool to support the speciﬁcation and execution
of new tasks and types of speciﬁc missions according to the
knowledge extracted from domain experts.
Within the panorama of missions [14], typical scenarios
concern: (i) Disaster Prevention and Management , like damageassessment after earthquakes, searching for survivors after
airplane accidents and disasters; (ii) Homeland Security , such
as coastal surveillance, securing large public events; (iii) Pro-
tection of Critical Infrastructure , such as monitoring oil and
gas pipelines, protecting maritime transportation from piracy,
observing trafﬁc ﬂows; (iv) Communications , like broadband
communication, telecommunication relays; (v) Environmental
Protection , such as pollution emission, protection of water
resources.
Figure 3 shows a screenshot of the FLYAQ editor while the
on-site operator is specifying by means of MML a mission to
monitor a large public event in a small city for security reasons
(tasks of the mission have been graphically manipulated so to
improve the readability of the ﬁgure). The editor consists of
four main components: an interactive map for drawing and
editing missions, a dedicated palette with all the available
types of tasks according to MML and its extensions ( Ain
Figure 3), a palette for managing the available drones to be
used in the mission ( Bin Figure 3), and a panel for managing
the execution order of the speciﬁed tasks ( Cin Figure 3). For
more details about MML interested readers can refer to [4].
A FLYAQ mission essentially results in a set of geograph-
ical areas, movement strategies that drones involved in the
mission should perform on selected areas, such as coverage,
search for an object, etc. and actions to be performed while
traversing the interested waypoints, e.g., taking a picture or
performing a video. The speciﬁed mission is composed of two
tasks to be performed in parallel:
-Photo Grid Task (PGT) - this task is performed above a
square (see the rectangle in Figure 3 within the circle PGT) to
monitor it. The photo grid task identiﬁes a virtual grid within
the area, each cell of the grid having a size of 10meters. The
drones executing the task will ﬂy over each cell of the grid at
an altitude of 25meters, and then will take a picture of the
area directly below them.
-Road Task (RT) - this task refers to a polyline corresponding
to the streets to be monitored (see the polyline in Figure 3
identiﬁed by the circle RT). Drones are required to ﬂy along
the polyline at an altitude of 25meters, and take a picture
every 200meters along the polyline.
The mission will be realized by three drones that will be
positioned in a large parking lot close to the city center (see the
NF1 NF2 RT 
home PGT 
ABC
Fig. 3. Screenshot of the tool while editing an MML models10 TakeOff(p1.z) s1 GoTo(c1) s'1 GoTo(c2) s''1 GoTo(p1) v1 Mission entering v11 GoTo(q1) / DoPhoto(…) v21 v161 v171 … NoOp 
s2 s'''2 GoTo(c1) s''2 GoTo(c2) s'2 GoTo(p1) GoTo(home1) Land s1f land1 Mission tasks execution 
Mission exiting non-fluid transition fluid transition Transition label syntax = <OP> |  <ACT> | <OP> / <ACT> GoTo(q16) / DoPhoto(…) NoOp r1 NoOp Fig. 4. QBL-based speciﬁcation of d1
home circle in Figure 3): two drones will take care of executing
PGT, whereas a single drone will execute RT independently.
FLYAQ allows the user to deﬁne also contextual information
about the mission. In this example, the context speciﬁcation
contains two no-ﬂy zones and an obstacle. The two no-ﬂy
zones, called NF1 and NF2, are the ones within the city center.
The obstacle is within the area involved in the PGT task and it
represents the area reserved by televisions to record activities
performed during the event in the main square of the city. The
obstacle is better visible in Figure 5.
Figure 4 shows the transition system corresponding to the
QBL-based behaviour speciﬁcation of drone d1in our scenario.
We recall that such a speciﬁcation is automatically generated
out of the speciﬁed MML model. As described in Section II,
the behaviour of d1consists of three phases:
Mission entering : This phase concerns the mission entering
(see the transition from s1
0tos1in Figure 4): d1takes off from
home and reaches the altitude of the mission’s starting point.
Mission tasks execution : This phase concerns the execution
of each task in which d1is involved. d1is involved in only
one task, i.e., task t1. Since t1involves both d1andd2,d1has
to monitor half of it (see the area delimited by p1,p2,q7, and
q10) by discretizing its sub-area according to the grid of points
shown in Figure 5. The other half is monitored by d2. This
zone for d2 q4= p2 
q1= p1 q3 q14 q5 q6 q15 q16 q2 q13 q12 q11 q7 q8 q9 q10 p3 
p4 d1 visit plan c1 c2 p1 
Fig. 5. Reasoning to obtain the drone behaviour speciﬁcationavoids collisions between d1andd2during the execution of
t1. According to the speciﬁed strategy and grid dimension, d1
covers its discretized sub-area by performing a speciﬁc visit
plan (see the sequence of arrows shown in the right-hand side
of the ﬁgure).
First, d1reaches the starting point of the mission by means
of a sequence of GoTo operations. The mission entering path
is calculated in order to avoid both collisions with other drones
in the mission and traversing no-ﬂy zones. In fact, as shown
in the right-hand side of Figure 5, d1approaches the mission
by traversing the c1andc2points, hence reaching p1, which
is a vertex of the area speciﬁed for the execution of task PGT.
Traversing these points means that d1avoids speciﬁed no-ﬂy
zones and the path speciﬁed for the execution of task RT by
drone d3, hence avoiding also collisions with d3. Accordingly,
ford2andd3different mission entering paths are calculated.
Second, d1covers its sub-area by means of a sequence
of GoTo operations and DoPhoto actions; the sequence of
waypoints is: q1;;q16(see the mission task execution part
of Figure 4). Notice that q1coincides with p1, then the ﬁrst
GoTo, i.e., GoTo( q1), will have no effect since the d1will be
already in p1. This is a side effect of having the code generated,
however this has no effect on the mission execution and this
GoTo operation can be removed by minimizing the ﬁnal drone
behaviour speciﬁcation.
Mission exiting : This phase concerns exiting the mission
hence leading d1to come back to home and land (see transi-
tions from s2tos1
fin Figure 4).
IV. P RELIMINARY ASSESSMENT OF THE TOOL
As a ﬁrst step towards a realistic assessment of the
feasibility of our automatic generation method, we executed
generated QBL models by using a Software-In-The-Loop
(SITL) simulation platform. The main characteristic of SITL
simulations is that the used software stack is exactly the
same as the one used in real ﬂights; the only difference
with respect to real ﬂights is that the key low level hardware
drivers (e.g., GPS sensors, accelerometers, etc.) are simulated
via a dedicated software. The main component of our SITL
simulation stack is MAVProxy1, that is a developer-oriented,
minimalist and extendable ground control station for any
unmanned autonomous vehicle. Moreover, we performed real
tests involving the Parrot AR.Drone2.0 multicopter2; a video of
a demo might be found at: http://cs.gssi.infn.it/ﬁles/ﬂyaq.mp4 . We
considered missions involving different tasks, various numbers
of tasks, and various context descriptions.
V. R ELATED WORK
A comprehensive survey of approaches for cooperative
teams of UA V operating as distributed processing systems can
be found in [3]. The work in [12] introduces CSL, which
is a high-level feedback control language for mobile sensor
networks. The style of the language is similar to that of Petri
nets (missions are made of tasks with tokens and transitions).
The run-time architecture of the proposed approach allows
engineers to update a modelled mission at run-time by means
1http://tridge.github.io/MA VProxy
2http://ardrone2.parrot.com/of a patching system for the mission speciﬁcation. Differently
from our approach, the CSL language does not support any
kind of check on the feasibility and safety of the modelled
mission; also, trajectory plan in 3D is not supported.
Many algorithms have been proposed for automatic tra-
jectory generation and control, with a strong focus on either
trajectory optimization [7], feasibility [1], or safe obstacle and
trajectories intersection avoidance [11]. The interested reader
can refer to [6], which proposes an overview of existing motion
planning algorithms speciﬁc for UA V guidance.
From a slightly different perspective, the work in [10]
proposes a new paradigm called cyber-physical computing
cloud (CPCC). It allows any customer to assign, check, and
distribute sensing services on virtual vehicles. Essentially, this
approach ports the principle of Platform-as-a-Service (PaaS)
to the distributed robotics domain. According to this principle,
the system can perform multi-customer information acquisition
missions on swarms of UA V operated and maintained by
a third party, similarly to how traditional web-based PaaS
systems work. Differently from our approach, in [10] free-
space environment is assumed and collisions are not taken into
consideration. Moreover, location movements related to the
tasks are manually given by the customers of the PaaS system,
then tasks are assigned to physical vehicles by using a binding
algorithm based on V oronoi cells. For what concerns the
activity of mission planning and deﬁnition , many approaches
focus on the deﬁnition of (either GPS-based or vision-based)
waypoints and trajectories in the real world that must be
navigated by the multicopter in the ﬁeld [2], [9].
Differently from these approaches, our main objective is to
provide an extensible software tool that makes the speciﬁcation
and generation of missions possible for people that are neither
expert on ICT nor in robotics. In other words we address
the problem from the software engineering perspective, as our
tool (i) focusses on the deﬁnition of the various tasks of a
monitoring mission at an higher level of abstraction, i.e., tasks
and tasks dependencies; (ii) allows engineers to automatically
generate detailed ﬂight plans from a user friendly, domain-
speciﬁc, and graphical description of a mission; (iii) generates
ﬂight plans that avoid obstacles, collisions and no-ﬂy zones;
(iv) does not demand to manually specify each single waypoint
of the mission (that actually may be hundreds in complex
missions), rather it is able to automatically compute, plan,
and assign all the waypoints that must be visited by each
multicopter of the swarm to accomplish the mission; and (v) is
independent from the used task allocation, geometric and path
ﬁnding algorithms, thus enabling for the use of state-of-the-art
and well-established algorithms depending either on the next
advances of those algorithms and on the traits of the missions
to be performed in the future.
VI. P OTENTIAL IMPACT
The major beneﬁts related to the adoption of the FLYAQ
tool by organizations that need to carry out dangerous and
difﬁcult missions are:
Low cost - the use of FLYAQ and its multicopters permits
to reduce the costs due to the employment of personnel on
the site to be monitored, and to the adoption of complex
communication means for synchronizing the teams.Enhanced safety - the employment of autonomous multi-
copters in dangerous missions permit to avoid to expose the
staff on-site to signiﬁcant risks in case of particular situations
due to ﬁre, earthquake, ﬂood, etc.
Improved timing - usually monitoring activities are very time
consuming, the staff assigned to monitoring is subjected to
gruelling shifts, and often the missions are stopped during the
night. The autonomous multicopters instructed by means of
the FLYAQ environment help to reduce such difﬁculties.
Graphical language - missions are graphically deﬁned in the
ground station. The graphical language is integrated with the
Open Street Map well-known open source product in order to
visualize the geographical points that have to be monitored dur-
ing the missions being speciﬁed. Having a graphical language
for deﬁning monitoring missions, permit to hide the detailed
ﬂight plan, which may be very hard to use and understand by
non-expert users.
Versatility - the graphical language used for deﬁning monitor-
ing missions is very simple, and provides the concepts which
are familiar to the domain experts. Thus there is no need for
expensive training sessions or special maintenance activities.
Tool support - research and development groups who are
willing to work on self multicopters and instruct them at a
high level of abstraction, will have access to the source code
of the FLYAQ tool, extend, reuse individual components, and
then carry out their research without having to develop an
entirely new framework from scratch.
VII. C ONCLUSIONS AND FUTURE WORK
This paper describes the FLYAQ tool to generate from a
user friendly, domain-speciﬁc, and graphical description of a
mission, the detailed ﬂight plan that each multicopter in a team
has to perform. The generation approach avoids (i) collisions
among multicopters and between multicopters and obstacles,
(ii) violations of no-ﬂy zones, and (iii) unexpected behaviours
that may come from the collaboration of independent multi-
copters. FLYAQ has been conceived to allow non-experienced
users to easily specify missions for a team of multicopters.
As future work we are planning to enhance the current imple-
mentation of FLYAQ by integrating methodologies to control
the mission execution at run-time. The idea is to exploit the
synthesized ﬂight plan at run-time so to force the drones to
exhibit only desired behaviours [5]. Another interesting future
work concerns the ability of accounting for time and resources
consumption that are extremely important in this domain.
This will enable, e.g, the possibility of statically checking
mission end-to-end timelines, or the realization of resource-
aware missions. We will investigate also the possibility of
making communication between drones more ﬂexible, so to
enable also emerging behaviours; this will open challenging
and futuristic scenarios where intelligent swarms of drones
will decide at run-time operations to be performed in order
to satisfy the goal of a (possibly evolving) mission. Finally,
the current beneﬁts and limitations of the FLYAQ languages
and their supporting tools will be assessed by means of studies
involving the various stakeholders of FLYAQ. This will permit
also to identify potential directions for improvements.REFERENCES
[1] F. Augugliaro, A. P. Schoellig, and R. D’Andrea. Generation of
collision-free trajectories for a quadrocopter ﬂeet: A sequential convex
programming approach. In IEEE/RSJ International Conf. on Intelligent
Robots and Systems (IROS) , pages 1917 –1922, 2012.
[2] S. Bouabdallah and R. Siegwart. Full control of a quadrotor. In Intl.
Conf. on Intelligent Robots and Systems , pages 153 –158, 2007.
[3] G. Chmaj and H. Selvaraj. Distributed processing applications for
uav/drones: A survey. In H. Selvaraj, D. Zydek, and G. Chmaj, editors,
Progress in Systems Engineering , volume 1089 of Advances in Intel-
ligent Systems and Computing , pages 449–454. Springer International
Publishing, 2015.
[4] D. Di Ruscio, I. Malavolta, and P. Pelliccione. Engineering a platform
for mission planning of autonomous and resilient quadrotors. In Fifth
International Workshop, SERENE 2013 , pages 33–47. Springer Berlin
Heidelberg, LNCS, 2013.
[5] D. Di Ruscio, I. Malavolta, and P. Pelliccione. The role of parts in
the system behaviour. In Sixth International Workshop, SERENE 2014 .
Springer Berlin Heidelberg, LNCS, 2014.
[6] C. Goerzen, Z. Kong, and B. Mettler. A survey of motion planning
algorithms from the perspective of autonomous uav guidance. Journal
of Intelligent and Robotic Systems , 57(1-4):65–100, 2010.
[7] M. Hehn and R. D’Andrea. Quadrocopter trajectory generation and
control. In IFAC World Congress , volume 18, n. 1, pages 1485–1491,
2011.[8] F. Jouault, F. Allilaire, J. B ´ezivin, and I. Kurtev. Atl: A model
transformation tool. Science of Computer Programming , 72(1-2):31–
39, 2008.
[9] F. Kendoul, Y . Zhenyu, and K. Nonami. Embedded autopilot for
accurate waypoint navigation and trajectory tracking: Application to
miniature rotorcraft uavs. In Intl. Conf. on Robotics and Automation ,
pages 2884 –2890, may 2009.
[10] C. Krainer and C. M. Kirsch. Cyber-physical cloud computing imple-
mented as paas. In Proceedings of the 4th ACM SIGBED International
Workshop on Design, Modeling, and Evaluation of Cyber-Physical
Systems , CyPhy ’14, pages 15–18, New York, NY , USA, 2014. ACM.
[11] J. Leonard, A. Savvaris, and A. Tsourdos. Towards a fully autonomous
swarm of unmanned aerial vehicles. In Control (CONTROL), 2012
UKACC International Conf. on , pages 286 –291, sept. 2012.
[12] J. Love, J. Jariyasunant, E. Pereira, M. Zennaro, K. Hedrick, C. Kirsch,
and R. Sengupta. Csl: A language to specify and re-specify mobile
sensor network behaviors. In Real-Time and Embedded Technology and
Applications Symposium, 2009. RTAS 2009. 15th IEEE , pages 67–76.
IEEE, 2009.
[13] S. S. Skiena. The algorithm design manual, 1997. Stony Brook, NY:
Telos Pr , 504.
[14] T. Skrzypietz. Unmanned Aircraft Systems for Civilian Missions .
BIGS policy paper: Brandenburgisches Institut f ¨ur Gesellschaft und
Sicherheit. BIGS, 2012.