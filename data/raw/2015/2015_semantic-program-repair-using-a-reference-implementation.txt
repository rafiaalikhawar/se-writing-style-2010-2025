Semantic Program Repair Using a Reference Implementation
Sergey Mechtaev∗
National University of Singapore
mechtaev@comp.nus.edu.sgManh-Dung Nguyen∗
National University of Singapore
nguyenmanhdung1710@gmail.comYannic Noller
Humboldt University of Berlin
yannic.noller@informatik.hu-berlin.de
Lars Grunske
Humboldt University of Berlin
grunske@informatik.hu-berlin.deAbhik Roychoudhury
National University of Singapore
abhik@comp.nus.edu.sg
ABSTRACT
Automated program repair has been studied via the use of tech-
niquesinvolvingsearch,semanticanalysisandartificialintelligence.
Most of these techniques rely on tests as the correctness criteria,
which causes the test overfitting problem. Although various ap-
proaches suchas learning from code corpus have been proposed to
address this problem, they are unable to guarantee that the gener-
atedpatchesgeneralizebeyondthegiventests.Thisworkstudies
automated repair of errors using a reference implementation. The
referenceimplementationissymbolicallyanalyzedtoautomatically
infer a specification of theintended behavior. This specification is
thenusedtosynthesizeapatchthatenforcesconditionalequiva-
lence of the patched and the reference programs. The use of the
reference implementation as an implicit correctness criterion alle-
viates overfitting in test-based repair. Besides, since we generate
patches by semantic analysis, the reference program may have a
substantially different implementation from the patched program,
which distinguishes our approach from existing techniques for
regression repair like Relifix. Our experiments in repairing the
embedded Linux Busybox with GNU Coreutils as reference (and
vice-versa)revealedthattheproposedapproachscalestoreal-world
programs and enables the generation of more correct patches.
CCS CONCEPTS
•Software and its engineering →Automatic programming ;
Software verification ;
KEYWORDS
Debugging, Program repair, Verification
ACM Reference Format:
SergeyMechtaev,Manh-DungNguyen,YannicNoller,LarsGrunske,andAb-
hikRoychoudhury.2018.SemanticProgramRepairUsingaReferenceIm-
plementation. In Proceedings of 40th International Conference on Software
Engineering , Gothenburg, Sweden, May 27-June 3, 2018 (ICSE ’18), 11 pages.
https://doi.org/10.1145/3180155.3180247
∗Joint first authors
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.31802471 INTRODUCTION
Software developers spend a significant amount of time and re-
sourcesforbugfixing.Automatedprogramrepairhasgainedpromi-
nenceduetoitspotentialtoreducethemanualdebuggingeffortby
automaticallysuggestingpatchesforgivendefects.Indeed,state-
of-the-artprogramrepairsystemshavebeenshowntobeableto
address defects in real-world software. However, the low quality
ofautomaticallygeneratedpatchesremainsagreatbarriertothe
adoption of this technology by software developers in practice.
Problem. Theprimaryreasonforthelowqualityofautomatically
generatedpatchesis thelackofspecifications oftheintendedbehav-
ior.Mostprogramrepairsystemsrelyontestsasthecorrectness
criteria, because a formal specification is often unavailable in prac-
tice. However, since tests is an incomplete specification, generated
patchesoftendonotcorrespondtodeveloperintentions,butmerely
overfit thetests.Inordertoincreasethe qualityofautomatically
generatedpatches,researchershaveproposedsuchtechniquesas
patchprioritization[ 22],anti-patterns[ 37],testgeneration[ 43,46],
etc.Althoughthesetechniquesincreasetheprobabilityoffinding
correctpatches,theyneverthelessdonotprovideany correctness
guarantees beyond the tests in a given test suite.
Intuition. To address the overfitting problem, we propose to au-
tomatically infer the missing specification for a buggy program
from a correct reference program. A reference program is an alter-
nativerealizationofthesamefunctionality,whichisoftenavailable
forlibraries(e.g.standardlibraryimplementations,audiocodecs,
compressionalgorithms,parsers,cryptographicalgorithms),net-
work protocols [ 20], commodity software (e.g. GNU Coreutils and
BusyboximplementthesamesetofUNIXutilities),intheareaofdig-
ital signal processing [ 19], web servers anddatabase management
systems.Notethatareferenceprogrammayhaveasubstantially
different implementation (different data structures and algorithms),
which distinguishes our approach from repair techniques [ 35] that
employ previous program versions. The use of a reference pro-
gramenablesustoalleviatetestoverfittingandprovidesadditional
correctness guarantees.
Challenges. Ideally,ageneratedpatchshouldenforcetheequiva-
lence of the patched and the reference programs, which poses two
challenges: scalability and applicability. First, a recent work [ 14]
reported that a straightforward combination of an equivalence
checkingsystem[ 13]withcounterexample-guidedinductivesyn-
thesis[1]tosynthesizeequivalence-enforcingpatchesisnotscal-
able. Second, real-world implementations of the same functionality
rarelyfollow preciselythesamespecification,e.g.GNUCoreutils
1292018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Mechtaev et al.
implementsasupersetofthefunctionalityimplementedinBusybox
and therefore cannot be directly used for equivalence checking.
Solution. Toaddresstheabovechallenges,weintroduceamethod-
ologyofpatchgenerationbasedonareferenceimplementationthat
integratesthenotionofconditionalequivalence[ 10]andarecent
scalable patch generation algorithm [ 26]. We rely on the user in-
sighttoprovidean inputcondition forpatchgenerationthatshould
(1)includeabug-triggeringinputand(2)correspondtofunction-
alitysharedbythebuggyandthereferenceprograms.Then,our
systemautomaticallygeneratesapatchforthebuggyprogramthat
enforcesconditionalequivalence ofthepatchedandthereference
programs, that is equivalence for all inputs satisfying the provided
condition.Althoughtheuserisonlyrequiredtoprovideaninput
condition(the propertybeingcheckedisderivedautomaticallyfrom
thereferenceprogram),thisstillmaybenon-trivialforapplications
that involve a complex execution setup. To tackle this problem,
we propose a practical approach of introducing an input condition
basedontheideaofparameterizedtests[ 38],i.e.theconditionis
defined by injecting symbolic parameters into existing tests.
Contributions. The main contributions of this work are:
(1)We propose to infer a correct specification from a reference
implementation and use it to guide program repair in order
to address the test overfitting problem.
(2)Weintroduceascalablealgorithmofpatchgenerationbased
on a reference implementation that guarantees conditional
equivalence of the patched and the reference programs w.r.t.
a user-defined input condition.
(3)We conduct an evaluation on two implementations of UNIX
utilities(GNUCoreutilsandBusybox)thatdemonstratesthat
ourmethodologyaddressesthetestoverfittingproblemof
program repair and scales to real-world software.
2 OVERVIEW
Ourapproachtakesfourinputs:atestsuite,abuggyandareference
program, and a user-defined input condition (Figure 1).
Asthefirststep,thenode Faultlocalization ofFigure1represents
the identification of suspiciousexpressions that might need to get
repaired.Thisisdonebyapplyingstatisticalfaultlocalization[ 9]
based on the given test suite and the buggy program. The suspi-
ciousexpressionsinthebuggyprogramgetreplacedwithsymbolic
variables, denoted as the instrumented buggy program.
As the second step, the module Symbolic analysis of Figure 1
contains the symbolic execution of the reference program and the
instrumentedbuggyprogramusingtheuser-definedinputcondi-
tionasaprecondition.Theresultofeachsymbolicexecutionisa
set of pairs of resulting path conditions and symbolic output states
(see Definition 4.2) that is used as a specification.
As the last step, the inferred specifications for the reference
andthebuggyprogramsarepassedintothepatchgeneratorthat
performsa counterexample-guidedinductiverepair loop.Specifically,
itperformsthefollowingiterationsstartingfromtheoriginalbuggy
expression as the initial (empty) patch:
(1) Construct a verification condition (VC) for the patch.
(2)Generate a counterexample input that violates the condi-
tional equivalence property by solving VC.Buggy program Test suite
User-defined
input conditionReference
implementation
Fault localization
Symbolic execution of in-
strumented buggy programSymbolic execution
of reference program
Conditional
equivalence checker
Angelic forest
extractorPatch
synthesizer
Patchinput
symbolic analysis
counterexample-guided inductive repair
Figure 1: Overall workflow of the approach.
(3) Extract an angelic forest [26] for the generated input.
(4) Synthesize a patch that satisfies the angelic forest.(5) Go to step (1).
Thislooprepeatsuntilaconditionalequivalence-enforcingpatch
is synthesized or the next patch/angelic forest cannot be found.
Toillustrateourapproach,weconsiderthereferenceprogram
in Figure 2a and the buggy program in Figure 2c. The reference
programimplementsanalgorithmofsearchingforanelementof
anarrayvialinearsearch,whilethebuggyprogramsusesbinary
search. The buggy program contains a bug in line 16.
Acrucialelementofourapproachistheinputcondition ϕthat
hastobedefinedbytheuser.Themosttrivialchoiceoftheinput
conditionwouldbesimply True,i.e.,checkingequivalenceforall
programinput.However,thisapproachmayhaveapoorscalability
as it has been reported in previous works [ 14]. Instead, we suggest
definingtheinputconditionbyparameterizingexistingtests.Specif-
ically, not all inputs of a test case must be considered concretely,
some of them can be handled symbolically. Therefore, the user can
transform the test cases in logical constraints and possibly add
additionalconstraints.Thisrepresentsapracticalsolutiontobal-
ancethecompletenessandscalabilityofautomatedprogramrepair.
The wider the input condition is formulated, the more complete, in
terms of covered input space, will be the generated patch.
Todefinetheinputcondition ϕ,assumethattheuserformulates
itinformallyinthefollowingway:weonlyconsidersortedarraysof
the length 3 and without duplicates. First, we introduce a mapping
between program variables and symbolic variables:
{x/mapsto→γ,a/mapsto→[α0,α1,α2],length/mapsto→δ}
130
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. Semantic Program Repair Using a Reference Implementation ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
1intsearch( intx,inta[],intlength) {
2inti;
3for(i=0; i<length; i++) {
4 if(x == a[i])
5 return i;
6}
7return−1;
8}
(a) Reference programIDπrθr
out
r1γ=α0 0
r2γ/nequalα0∧γ=α1 1
r3γ/nequalα0∧γ/nequalα1∧γ=α22
r4γ/nequalα0∧γ/nequalα1∧γ/nequalα2-1
(b) Summary of reference program
9intsearch( intx,inta[],intlength) {
10 intL=0 ;
11 intR = length−1;
12 do{
13 intm = (L+R)/2;
14 if(x == a[m]) {
15 return m;
16 } else if (x < a[m]) { // bug fix : x > a[m]
17 L = m+1;
18 } else{
19 R = m−1;
20 }
21 } while(L <= R);
22 return−1;
23 }
(c) Buggy programIDπbθc θb
out
b1γ=α1 - 1
b2γ/nequalα1∧β0∧γ=α2 β0:{x/mapsto→γ,a[m]/mapsto→α1}2
b3γ/nequalα1∧β0∧γ/nequalα2∧β1β0:{x/mapsto→γ,a[m]/mapsto→α1}-1
β1:{x/mapsto→γ,a[m]/mapsto→α2}
b4γ/nequalα1∧β0∧γ/nequalα2∧¬β1β0:{x/mapsto→γ,a[m]/mapsto→α1}-1
β1:{x/mapsto→γ,a[m]/mapsto→α2}
b5γ/nequalα1∧¬β0∧γ=α0 β0:{x/mapsto→γ,a[m]/mapsto→α1}0
b6γ/nequalα1∧¬β0∧γ/nequalα0∧β1β0:{x/mapsto→γ,a[m]/mapsto→α1}-1
β1:{x/mapsto→γ,a[m]/mapsto→α0}
b7γ/nequalα1∧¬β0∧γ/nequalα0∧¬β1β0:{x/mapsto→γ,a[m]/mapsto→α1}-1
β1:{x/mapsto→γ,a[m]/mapsto→α0}
(d) Specification of buggy program
Negative input x/mapsto→2
a/mapsto→[2,4,6]
length/mapsto→3
Expected output 0
Symbolic inputs x/mapsto→γ
a/mapsto→[α0,α1,α2]
length/mapsto→δ
Input condition ϕ/colonequalα0<α1<α2∧δ=3
(e) Test and input conditionVC=∀α0∀α1∀α2∀γ/logicalanddisplay
(πr,θr
out)/logicalanddisplay
(πb,θb
out)πr∧πb∧(β=e/dblbracketleftθc/dblbracketright)⇒θr
out=θb
out
≡∀α0∀α1∀α2∀γ(
(r1,b3)¬(γ=α0∧γ/nequalα1∧β0∧β0=γ<α1∧γ/nequalα2∧β1∧β1=γ<α2)
(r1,b4)∧¬(γ=α0∧γ/nequalα1∧β0∧β0=γ<α1∧γ/nequalα2∧¬β1∧β1=γ<α2)
(r3,b6)∧¬(γ=α2∧γ/nequalα1∧¬β0∧β0=γ<α1∧γ/nequalα0∧β1∧β1=γ<α0)
(r3,b7)∧¬(γ=α2∧γ/nequalα1∧¬β0∧β0=γ<α1∧γ/nequalα0∧¬β1∧β1=γ<α0))
(f) Verification condition
Figure 2: Artifacts of motivating example
Then, the input constraint is defined as follows:
ϕ/colonequalα0<α1<α2∧δ=3
The given test suite contains one negative test case with the
input{x/mapsto→2,a/mapsto→[2,4,6],length/mapsto→3}and the expected output
0, because the first element is equal to the searched value 2. The
testcasepassesforthereferenceprogram,butfailsforthebuggy
program. The statistical fault localization identifies the expression
in line 16 as a suspicious expression, hence, we introduce the sym-
bolicvariable βandgenerateaninstrumentedbuggyprogramby
replacing (x<a[m])withβ. Note that the test case is not encoded
intheinputcondition ϕ,i.e.,therepairstepsthemselvesareinde-
pendentfromanygivenconcretetestinput.Thistestcaseisonly
needed for the identification of suspicious expressions.
Assuming ϕ, we execute the reference and instrumented buggy
program with a preconditioned symbolic execution. Preconditioned
symbolic execution (see Definition 4.1) explores only a subset of
programpathsthatareconsistentwiththecondition ϕ.Wewillget
theresultspresentedinFigure2bandFigure2d.Thetablescontain
so calledspecifications (see Definition 4.3), which describe the path
condition ( πrfor the reference program and πbfor the buggy
program), the current context for the suspicious expression θc, and
the output symbolic state ( θr
outfor the reference program and θb
out
for the buggy program). The superscript index of βindicates theoccurrence id (or instance id) of this expression, since it can be
visited more than once during the execution.
Withtheresultsofthepreconditionedsymbolicexecutionwe
canbuildtheformulaoftheverificationconditionfortheconsid-
eredexpression (x<a[m]).Averificationcondition(VC)encodes
thefollowingidea:ifbothexecutionsinthereferenceandbuggy
program follow the same path, then their outputs should be the
same. The VC will also encode the values of the visible variables
intheexpression (x<a[m])computedinthesymboliccontext θc
that we denote as β=(x<a[m])/dblbracketleftθc/dblbracketright. The simplified version of
this first iteration VC is presented in Figure 2f. We skipped contra-
dictingpairsofpathconditionsfromthebuggyandthereference
program and discarded pairs that contradict the input condition ϕ.
Additionally,wesimplifiedtheformulabyremovinglineswhere
the symbolic output states match already, i.e., θr
out=θb
out. In such
casestheimplicationisalways Trueand,hence,itdoesnotprovide
anyadditionalvalue.Theremainingformulaincludesthefollowing
combinationsofpaths(representedbytheaccordingidsinFigure2b
and Figure 2d): (r1,b3),(r1,b4),(r3,b6),(r3,b7), as also indicated at
the beginning of each line in the shown VC.
In order to check the validity of the verification condition, we
checktheunsatisfiabilityofitsnegationasinpreviousworks[ 13,
28].ThenegatedVCwillbesolvedusinganoff-the-shelfSMTsolver
to generate satisfying values representing counterexamples, which
131
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Mechtaev et al.
donotsatisfytheVCwiththecurrentreplacementforthesuspi-
cious expression. After negating the VC, the SMT solver generates
a counterexample input {x/mapsto→−1,a/mapsto→[−1,0,1]}.
In order to find the correct truth value for β, also called angelic
value(seeDefinition3.6),welookatthepathconditionofthebuggy
programthatleadstothecorrectoutputsymbolicstate,whichis
hereθr
out=0accordingtothereferenceprogram.Comparingwith
thetableinFigure2d,thisoutputcanonlybereachedinthebuggy
program by following the path b5. In order to take this specific
pathwiththegiveninputvalues, β0needstobe False.Thisleads
to the following angelic forest, which is the input structure for
our synthesizer and represents all needed values for the specific
suspicious expression (see Definition 3.8):
{(β0,c,σ)},given that c/colonequalFalse,σ/colonequal{x/mapsto→−1,a[m]/mapsto→0}
wherecrepresentsanangelicvalueoftheconsideredexpression
(a value that enables the program to pass the counterexample test)
andσrepresentsanangelicstate(theconcretevaluesofprogram
variables in the context in which the expression is executed).
Thegeneratedvaluesareusedtobuildtheinputforacomponent-
based synthesizer, which generates a new patch matching the cur-
rent synthesizerinput. Given this input,the synthesizer returnsa
plausiblepatch (x==a[m]).After insertingthisexpression inthe
VC and negating it, the SMT solver generates a second counterex-
ample input{x/mapsto→1,a/mapsto→[−1,0,1]}. The correct output symbolic
stateforthisinputis θr
out=2andthismatchesonlythepath b2.In
ordertotakethisspecificpathwiththesecondcounterexample, β0
needstobe True.Thisleadstoanextensionofourangelicforestto:
{(β0,False,{x/mapsto→−1,a[m]/mapsto→0)},
(β0,True,{x/mapsto→1,a[m]/mapsto→0})}.
Given this input, the synthesizer returns the patch (x>=a[m]).
After inserting this expression in the VC and negating it, the SMT
returnsunsatisfiable,i.e.,thesynthesizedpatchfulfillsallrequire-
ments.Notethat (x>=a[m])isnotsyntacticallyequivalentwith
thecorrectpatch (x>a[m]),butinthiscontext(i.e.withthepre-
ceding if-condition) both expressions are semantically equivalent.
Our approach results in a patch for the buggy program, so that
given the input condition ϕ, the patched programis conditionally
equivalent with the reference program.
For comparing with test-driven repair techniques, we applied
Angelix[26],whichusesasimilarpathgenerationalgorithm,and
hence,itrepresentstheclosestexistingapproachandmeansamore
fair comparison than using any other test-driven repair technique.
For our motivating example we observed that Angelix only canproduce the plausible patch
(a[m]<a[m]). It fixes only the given
negative test case, so in order to generate a correct patch it would
be necessary to include more test cases. Since our repair approach
is capable of using another program as correctness reference, itgenerates the input for the synthesizer itself with the presented
counterexample-guided approach.
Inthismotivatingexampleweshowedthatwithourapproach
it is possible to use a relatively simple reference program (e.g.,
thelinearsearch)torepairanoptimizedprogram(e.g.,thebinary
search).Thetwoprogramsdonotneedtobestructurallysimilar,
as long as they solve the same problem.3 BACKGROUND
Inthissection,weintroducethenotationusedtoformallydescribethe presentedalgorithms, define underlyingprogram analysistech-niques,andalsointroducerelatedpartsofpreviouspatchgeneration
methods that are reused in our approach.
Weconsiderprogramswritteninanimperativeprogramming
language. Programs are denoted as p1, ...,pkand the set of all
program asP. We define p[e/mapsto→e/prime] as a program obtained from
pby substituting an expression ewithe/prime. Program variables are
represented as v1,...,vkand the set of all program variables as V.
The considered programming language contains a statement
assumedefined as follows:
assume(ϕ)/colonequalif(¬ϕ){LOOP:goto LOOP;}
thatisthisstatementtriggersanon-termination(aninfiniteloop)
when the given condition does not hold.
Concrete program states (functions from program variables to
values)areindicatedas σandthesetofallconcreteprogramstates
isdenotedas Σ;twoconcreteprogramstates σ1andσ2areequal
iff∀v∈V.σ1(v)=σ2(v).Thevalueofanexpression eevaluated
in the context σis denoted as e/dblbracketleftσ/dblbracketright. We define a concrete program
execution as in the following:
Definition 3.1 (Concrete execution). A concrete execution proce-
dureExec:P×Σ→Σ∪{ω}isafunctionthatforagivenprogram
pandaconcreteinputstate σinreturnsthecorrespondingoutput
stateσoutif the program terminates, and the literal ωotherwise.
We consider a first-order language L. We use the letters α,β,
γandδto denote variables from L, and the letters πandϕto
designateformulasfrom L.Weusetheletter θtoindicate symbolic
program states, that is functions from program variables to logical
terms fromL(for a program variable v, the corresponding logical
term isθ(v)). We express the equality of two symbolic program
statesθ1andθ2as the formula θ1=θ2/colonequal/logicalandtext
v∈Vθ1(v)=θ2(v).
Wedenotealogicaltermcomputedbyevaluatinganexpression e
in the context θase/dblbracketleftθ/dblbracketright.
Assume that{α1/mapsto→n1,...,αk/mapsto→nk}is an assignment of the
variables fromL(a mapping from the variables to values). We
say that this assignment satisfiesa formula πiff a substitution
of the variables αiwith the corresponding values ni(denoted as
π/dblbracketleftα1/mapsto→n1,...,αk/mapsto→nk/dblbracketright) evaluates to True. We also introduce a
concretization of symbolic states defined as follows:
Definition 3.2 (Concretization). Letθbe a symbolic state, {α1/mapsto→
n1,...,αk/mapsto→nk}be an assignment of the variables from L.A
concretization θ/dblbracketleftα1/mapsto→n1,...,αk/mapsto→nk/dblbracketrightofθwiththeassignment
{α1/mapsto→n1,...,αk/mapsto→nk}is defined as follows:
θ/dblbracketleftα1/mapsto→n1,...,αk/mapsto→nk/dblbracketright/colonequalλv.θ(v)/dblbracketleftα1/mapsto→n1,...,αk/mapsto→nk/dblbracketright
thatisasaconcreteprogramstate(amappingofprogramvariables
into values expressedusing lambda notation) computedby substi-
tuting all the variables αiin the logical terms in the codomain of θ
with the corresponding values ni.
In order to infer a specification, we rely on symbolic execu-
tion[12] that we non-constructively define as follows:
Definition 3.3 (Symbolic execution). A symbolic execution pro-
cedureSymExec :P×Θ→2L×Θis a function that for a given
132
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. Semantic Program Repair Using a Reference Implementation ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
programpandasymbolicinputstate θinreturnsafinitesetofpairs
{(π,θout)},whereπisthepathconditionand θoutisthecorrespond-
ing symbolic output state. For each assignment of the symbolic
variables{α1/mapsto→n1,...,αk/mapsto→nk}, if this assignment satisfies the
formulaπ, thenσout=Exec(p,σin), given that σin/colonequalθin/dblbracketleftα1/mapsto→
n1,...,αk/mapsto→nk/dblbracketrightandσout/colonequalθout/dblbracketleftα1/mapsto→n1,...,αk/mapsto→nk/dblbracketright.
Definition 3.4 (Partial equivalence under σ).Letp1andp2be
programs, σbeaprogramstate.Wesaythat p1andp2arepartially
equivalent underσiff at least one of the following holds:
•Exec(p1,σ)=ω;
•Exec(p2,σ)=ω;
•Exec(p1,σ)=Exec(p2,σ).
Sinceprovingpartialequivalenceforallinputsiscurrentlyin-
feasible when dealing with large real-world programs, this work
focusesonconditionalequivalence[ 10]—arelaxednotionofpartial
equivalence that checks equivalence only for a subset of inputs.
Definition 3.5 (Conditional partial equivalence). Letp1andp2be
programs, ϕ∈Lbeaninputcondition. Wesaythat p1andp2are
conditionallypartiallyequivalent underaninputcondition ϕiffthey
are partially equivalent under each input in {σ|ϕ/dblbracketleftσ/dblbracketright=True}.
Inordertosynthesizepatches,werelyonascalablepatchgener-
ation methodology proposed in Angelix [ 26] that infers a compact
synthesis specification based on angelic values [5] and synthesizes
a patch using component-based patch synthesis [26].
Definition3.6(Angelicvalue). Letpbeaprogram, tbeafailing
test,ebe a program expression and eibe itsi-th instance in the ex-
ecutiontraceof t.Angelicvalue cissuchthatreplacingexpressions
eiwithcduring the execution of tmakesppass the test t.
Definition 3.7 (Angelic path). Letpbe a program, Ebe a set of
program expressions in p,tbe a test. An angelic path is a set of
triples(ei,c,σ)whereeiis thei-th instance of an expression e∈E
appearingintheexecutiontraceof t,cisanangelicvalueof ei,and
σrepresents an angelic state at ei, such that replacing all eiin the
execution trace of twith the corresponding angelic values cforces
(1)theprogram ptopassthetest tand(2)theprogram ptobein
the stateσwhen the expression eiis evaluated.
Definition3.8(Angelicforest). Letpbeaprogram, Ebeasetof
programexpressionsin p,tbeatest. Angelicforest Atforthetest t
is a set of angelic paths for t.
AnangelicforestcanbeextractedasshowninAlgorithm1.Fora
given program pwith an expression e, this algorithm accepts a test
(apairofinputandoutputstates)andasetoftriples {(π,θc,θout)}.
Thesetoftriplesiscomputedusingsymbolicexecutioninsucha
way that πrepresents apath conditionin p,θcdepicts asymbolic
state that the program preaches when the expression eis eval-
uated along the path π, andθoutrepresents the symbolic output
statecomputedalongthepath π.Thealgorithmiteratesthrough
the given triples and extracts angelic values by solving the path
constraint conjoined with the given input-output relation.
Givenanangelicforest,Angelix[ 26]canconstructanexpression
from a given library of components that satisfies a given angelic
forest. More formally, for a given angelic forest Atand a set ofAlgorithm 1: Angelic forest extraction
Data: test (σin,σout), set of triples{(π,θc,θout)}
Result: angelic forest At
1At:=∅;
2foreach(π,θc,θout)do
3ψ:=π∧θ=σin∧θout=σout;
4ifisSAT(ψ)then
5{α/mapsto→n1,β/mapsto→n2,...}:= getSatisfyingAssignment( ψ);
6 c:=n2;
7 σc:=θc/dblbracketleftα/mapsto→n1,β/mapsto→n2,.../dblbracketright;
8 At:=At∪{(e,c,σc)};
9end
10end
11returnAt;
components c1,...,cn,itproducesanexpression econstructedfrom
c1, ...,cnthat satisfies the following property:
/logicalordisplay
path∈At/logicalanddisplay
(ei,c,σ)∈pathe/dblbracketleftσ/dblbracketright=c
Suchetakes the angelic value cfor each angelic state σand there-
fore passes the test tby construction.
4 OUR APPROACH
Inthissection,weformallydefinethreemaincomponentsofoural-
gorithm:specificationinference,verificationconditionconstruction
and patch synthesis.
4.1 Specification inference
Themainintuitionofourapproachisthatitispossibletoinferacor-
rect specification from a reference implementation and synthesize
apatchthatenforcesthisspecificationinagivenbuggyprogram.
Hereinafter, we refer to the given reference implementation as the
programprand the given buggy program as the program pb.
Inordertoinferaspecification,weusepreconditionedsymbolic
execution defined as follows:
Definition 4.1 (Preconditioned symbolic execution). Aprecondi-
tionedsymbolicexecution procedure PSymExec :P×Θ×L→2L×Θ
is a symbolic execution, in which each path condition is conjoined
with a given formula. It can be defined as PSymExec (p,θ,ϕ)/colonequal
SymExec(p/prime,θ), wherep/prime/colonequalassumeϕ;p.
Theimplementationofpreconditionedsymbolicexecutionisdis-
cussedinSection5.Asaresultofaddingthecondition ϕ,precon-
ditioned symbolic execution is significantly more efficient than
conventional symbolic execution, since it explores only a subset of
program paths that is consistent with the condition ϕ.
For a given reference program and an input condition, we infer
asymbolicsummaryoftheprogramcomputedthroughprecondi-
tioned symbolic execution:
Definition 4.2 (Symbolic summary). Letpbe a program, ϕbe
an input condition, θis a symbolic state. A symbolic summary
is a set of pairs Sum(p,θ,ϕ)/colonequal{(π,θout)}such that{(π,θout)}=
PSymExec (p,θ,ϕ).
133
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Mechtaev et al.
Foragivenbuggyprogram,asuspiciousexpressionandaninput
condition, we infer the following specification:
Definition4.3(Specification). Letpbeaprogram, ebeaprogram
expression, ϕbe an input condition, θis a symbolic state over vari-
ablesα1,...,αk.Aspecification is a set of triples Spec(p,e,θ,ϕ)/colonequal
{(π,θc,θout)}suchthat{(π,θout)}=PSymExec (p/prime,θ,ϕ),wherep/prime/colonequal
p[e/mapsto→choose()],choose()isafunctionthatreturnsafreshsym-
bolicvariable βieachtimeit isexecuted.Foreach path π,θcindi-
catesasymbolicstateinthecontextofwhichthefunction choose()
is called when the program is symbolically executed along π.
Wesaythatasummary Sum(p,θ,ϕ)iscompleteifforeachinput
σsatisfying the condition ϕone of the following holds:
•Exec(p,σ)=ω;
•∃(π,θout)∈Sum(p,θ,ϕ).π/dblbracketleftσ/dblbracketright=True.
Thecompletenessofaspecification Spec(p,e,θ,ϕ)canbedefined
in a similar manner.
In order to simplify further definitions, we assume (without loss
of generality) that all formulas contain only a single variable α
representingprograminputsandasinglevariable βrepresenting
the values of the replaced program expression.
4.2 Verification condition
Tocheckprogramequivalence,weconstructaverificationcondi-
tion for agiven patch using the inferredspecification. Ideally, this
conditionshould expresstheproperty “foreachinput satisfyinga
giveninputcondition,ifthereisapathinthereferenceprogram
followed by thisinput, then there shouldbe a path inthe patched
program followed by this input and the outputs produced along
these paths are equal”. We refer to this condition as strict.
Definition 4.4 (Strict verification condition). Letprbe a reference
program, pbbeabuggyprogram, ebeasuspiciousexpressionin pb,
e/primebeacandidatepatch, ϕbeaninputcondition, θinisasymbolic
stateoverthevariable α.Astrictverificationcondition VCstrictfor
the program pb[e/mapsto→e/prime] is defined as follows:
∀α∃β/logicalanddisplay
(πr,θr
out)(πr⇒/logicalordisplay
(πb,θb
c,θb
out)πb∧β=e/prime/dblbracketleftθb
c/dblbracketright∧θr
out=θb
out)
where the symbolic summary {(πr,θr
out)}/colonequalSum(pr,θin,ϕ)and
the specification{(πb,θbc,θb
out)}/colonequalSpec(pb,e,θin,ϕ).
However, the above condition cannot be used in many practical
situations, where the existing symbolic execution engines reach
theirlimits.Forinstance,wehavetorestrictthenumberofexplored
pathsbyperformingloopunrollinginupto kiterations.Asaresult,
theinferredspecificationisincomplete,andtheintroducedstrict
verification condition may classify two equivalent programs as
non-equivalent. For example, if an input is captured by some path
condition πr,butnotcapturedbyany πb,thentheprogramswillbe
considerednon-equivalent.Toaddressthis,weuseamorepractical
version of the verification condition that we refer to as liberal.
Definition4.5(Liberalverificationcondition). Letprbeareference
program, pbbeabuggyprogram, ebeasuspiciousexpressionin pb,
e/primebeacandidatepatch, ϕbeaninputcondition, θinisasymbolic
state over the variable α.Aliberal verification condition VCliberalStart with
original
expressionRef. prog.
summary
Sum(pr,θ,ϕ)
Buggy prog.
specification
Spec(pb,e,θ,ϕ)VCliberal Is SAT? Patch found
Candidate
patchCounter-
example
Is SAT? No patchBuggy prog.
specification
Spec(pb,e,θ,ϕ)
Is SAT?No angelic
values
Angelic
forestSynthesis
constraintComponent
librarynegate no
yes
no
yesnoyesconditional eqivalence checker
patch synthesizer angelic forest extractor
Figure 3: Counterexample-guided inductive repair.
for the program pb[e/mapsto→e/prime] is defined as follows:
∀α∃β/logicalanddisplay
(πr,θr
out)/logicalanddisplay
(πb,θbc,θb
out)πr∧πb∧β=e/prime/dblbracketleftθb
c/dblbracketright⇒θr
out=θb
out
where the symbolic summary {(πr,θr
out)}/colonequalSum(pr,ϕ,θin)and
the specification{(πb,θbc,θb
out)}/colonequalSpec(pb,e,ϕ,θin).
Comparedwiththestrictverificationcondition, theliberalone
only requires that for all intersections between a path condition
πrin the reference program and πbin the buggy program (i.e.
inputs satisfying πr∧πb), the symbolic outputs are the same in
both programs. In the other words, this verification condition only
checksequivalenceofthefunctionalityforwhichaspecification
has been inferred from both programs.
4.3 Patch generation
Toimplementascalablepatchgenerationthatenforcesconditional
equivalence of the referenceand the buggy programs, we propose
amethodologyof counterexample-guidedinductiverepair (CEGIR)
that effectively combines counterexample-guided inductive synthe-
sis (CEGIS) [1] and a patch synthesis algorithm of Angelix [26].
The overall workflow of the patch generator is shown in Fig-
ure 3 and illustrated by an example in Section 2. It performs acounterexample-guided refinement loop starting from the origi-nal expression as the initial candidate patch. The loop combines
three modules: a conditional equivalence checker, an angelic forest
extractorandapatchsynthesizerthataredescribedindetailsbelow.
134
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. Semantic Program Repair Using a Reference Implementation ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Conditionalequivalencechecker. Inordertoverifythatagiven
candidatepatchmakesthebuggyprogramconditionallyequivalent
tothereferenceprogram,wesolvetheliberalverificationcondition
given in Definition 4.5. In order to solve the universally-quantified
formula,wechecktheunsatisfiabilityofitsnegation,soasinprevi-
ous works [ 13,28]. Note that the introduced verification condition
isan∀∃formula,thereforeitsnegationalsoproducesauniversally-
quantified formula. However, the quantifiers ∀∃can be replaced
with∀∀,sinceforeach αthevaluesof βisuniquelyidentifiedby
theconstraint πb∧β=e/prime/dblbracketleftθbc/dblbracketright.Thus,thenegationoftheliberal
verification condition in Definition 4.5 is
∃α∃β/logicalordisplay
(πr,θr
out)/logicalordisplay
(πb,θbc,θb
out)πr∧πb∧β=e/prime/dblbracketleftθb
c/dblbracketright∧θr
out/nequalθb
out
The above formula is an ∃∃formula, therefore it can be solved
using an off-the-shelf SMT solver. If the formula is unsatisfiable,
then the patch is correct (conditionally equivalent to the reference
program). Otherwise, a counterexample test is generated.
Angelicforestextractor. Givenacounterexampletestandaspeci-
fication inferred from the buggy program, our algorithm computes
a compact specification for the expression based on angelic values
(angelicforest).Thealgorithmofangelicforestextractionissimilar
to that used in Angelix [ 26]. It is presented in Algorithm 1. If an-
gelicvaluescannotbeextracted,thenthebugcannotbefixedatthe
considered location (or the specification is incomplete). Otherwise,
the values are extracted and passed to the synthesizer.
Patchsynthesizer. Sincetheinputtothesynthesizerisanangelic
forest, we used the Angelix implementation of a patch synthesizer
that extends SMT-based component-based program synthesis [ 26].
If a patch cannot be synthesized, then the search space (the set
ofconsideredtransformations)isinsufficienttofindarepair.Ifa
patch is found, it is passed to the conditional equivalence checker.
Proposition 4.6 (Correctness guarantee). Letpbbe a buggy
program, prbe a reference program, ϕbe an input condition, ebe
asuspicious expressionin pb.Assume that e/primeisapatch thatispro-
ducedbytheCEGIRalgorithm(Figure3)givencompletespecifications
Sum(pr,θ,ϕ)andSpec(pb,e,θ,ϕ)asinputs.Then, pb[e/mapsto→e/prime]andpr
are conditionally partially equivalent w.r.t. the condition ϕ.
5 IMPLEMENTATION
We have implemented the tool SemGraft for evaluating our tech-
nique.SemGraftconsistsofthreemaincomponents: preconditioned
symbolic executor, verification condition generator andpatch genera-
tor. SemGraft receives a buggy and a reference program, an input
condition and a test suite as input, and produces a patch for the
buggyprogramastheoutput.Figure4showsthearchitectureofour
tool. Below, we explain how these components are implemented.
Preconditioned symbolic executor (PSE). PSE is built on top of
KLEE[4]—awidelyusedsymbolicexecutionengine.Tosupport
preconditionedsymbolic execution,themodified versionofKLEE
takestheuser-definedinputcondition ϕinSMTLIB2formatasinput.
Specifically,wemodifythefunction forkoftheKLEEinterpreter
whichiscalledwhenKLEEencountersasymbolicbranch.Thepath
conditionsofbothbranchesareconjoinedwiththeinputcondition
to determine whether a path is terminated immediately or furtherKLEE
Z3 serverPreconditioned
symbolic executor
Strict VC
generator
Liberal VC
generatorVerification condition
generatorPatch generator
Conditional
equivalence checker
Angelix forest
extractor
Patch synthesizer
Figure 4: Architecture of SemGraft.
explored. We integrate Z3 solver [ 6] with KLEE and pass symbolic
constraintsbetweenthemforcheckingthesatisfiabilityofsymbolicexpressions.PSEoutputssymbolicformulainSMTLIB2formatand
invokes Z3 solver via a wrapper function.
Verificationconditiongenerator(VCG). VCGtakesthesymbolic
summary of the reference program and the specification of the
buggy program, both of which are obtained by executing PSE with
the input condition. Our tool SemGraft supports both kinds of
verification condition as per Subsection 4.2, but the default option
of VCG is the liberal verification condition which is more practical
for real-world programs. We use an open-source library jSMTLIB1
for processing SMT files generated by PSE.
Patch generator (PG). PG takes the liberal verification condi-
tion in SMTLIB2 format and executes a counterexample-guided
inductive repair loop until it finds a patch that satisfies the desired
property. The workflow of PG is shown in Figure 3.
6 EXPERIMENTAL EVALUATION
Toevaluatetheeffectivenessofourapproach,weaimtoinvestigate
the following research questions:
(RQ1)Can SemGraft generate repairs for real-world software?
(RQ2)Can SemGraft alleviate the overfitting problem of exist-ing test suite based program repair techniques using the
reference implementation?
RQ1 is designed to investigate the applicability of our approach
for repairing real-world applications. A previous study [ 14] has
reportedthatastraightforwardcombinationofastate-of-the-art
equivalencecheckingsystemwithcounterexample-guidedinduc-
tivesystemsscalesonlytosmallprograms.Tobeapplicabletoreal-
worldprogramssuchasBusyboxandGNUCoreutils,ourapproach
sacrifices discovers a partial specification for checking conditional
equivalence w.r.t. a user-provided condition. Therefore, we also
discuss how such a condition can be derived from existing tests.
RQ2assessesthecorrectnessofgeneratedpatchescomparedwith
test-drivenprogramrepairapproaches.Asinpreviousworks[ 22,
26],weidentifyageneratedpatchas correctonlyifitis syntactically
equivalent to the developer patch (modulo trivial refactorings).
1jSMTLIB website: https://github.com/smtlib/jSMTLIB
135
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Mechtaev et al.
Table 1: Busybox subject programs
Buggy
Prog.BuggyCommitRef. Prog.Ref. Prog.VersionFailure Description Angelix’ SemGraft
sedc35545a sed of GNU sed version 3.01 Failed to handle zero-length match Correct Correct
seqf7d1c59 seq of Coreutils version 6.10 Wrong output when 2 input arguments are equal Correct Correct
sed7666fa1 sed of GNU sed version 3.01 Wrong output when handling s///NUM Incorrect Correct
sortd1ed3e6 sort of Coreutils version 8.27 Wrong output when handling -kSTART,N.ENDCHAR Incorrect Correct
seqd86d20b seq of Coreutils version 8.27 seqno longer accepts 0 value as increment argument Incorrect Correct
sed3a9365e sed of GNU sed version 3.01 Failed to handle s///which has empty matches Incorrect Correct
Table 2: Coreutils subject programs
BuggyProg. BuggyCommitRef. Prog.Ref. Prog.VersionFailure Description Angelix’ SemGraft
mkdir f7d1c59 mkdir of Busybox version 1.27.2 Segmentation fault Incorrect Correct
mkfifo cdb1682 mkfifo of Busybox version 1.27.2 Segmentation fault Incorrect Correct
mknod cdb1682 mknod of Busybox version 1.27.2 Segmentation fault Incorrect Correct
copy f3653f0 copy of Busybox version 1.27.2 Failed to copy a file Correct Correct
md5sum 739cf4e md5sum of Busybox version 1.27.2 Segmentation fault Correct Correct
cut6f374d7 cut of Busybox version 1.27.2 Failed to handle -b 2-,3- like-b 2-Incorrect Correct
6.1 Experimental setup
Inordertoaddressthedescribedresearchquestions,wechoosethesubjectsinourexperimentsaccordingtothefollowingfourcriteria.
(1) The subjects are real-world software that is widely used.(2)
Referenceprogramsareavailablethatprocessthesamein-
puts as the buggy programs but exhibit the correct behavior.
(3)Thebuggyandthereferenceprogramaresubstantiallydif-
ferent in their structure.
(4)Thedeveloperpatchesarewithinthesearchspacesofourimplementation. By the search space we mean the set of
consideredtransformationsdefinedthroughthecomponents
used for component-based synthesis.
The last criteria allows us to reason about correctness of generated
patches (e.g. if the developer patch was not in the search space,
then any generated patch would a prioribe identified as incorrect).
Our subjects are 12 real software errors of two open-source C
projectsBusybox[ 39]andGNUCoreutils[ 40]extractedfrom(1)
commit logs, (2) bug reports and (3) previous research [ 4]. Both
Busybox and GNU Coreutils provide many common UNIX utilities,
but Busybox has been implemented with size-optimization, limited
resources, andismainly usedforsmall orembeddedsystems. We
employ our tool SemGraft to repair the embedded Linux Busybox
with GNU tools like Coreutils as reference, and vice versa.
To address the second question (RQ2), we compared our tech-
nique with a state-of-the-art test-driven program repair approach,
Angelix[26].Angelixiscloselyrelatedtoourtechniquesinceitalso
appliessymbolicexecutiontoinferspecificationandsynthesizes
patches. We selected this approach for our evaluation because this
enables us to more objectively investigate the impact of specifi-cation inferred from a reference program. Specifically, since ourimplementation reuses the synthesizer of Angelix, both Angelixand SemGraft explore the same space of candidate patches. Inorder to ensure that the systems have access to the same seman-tic information about the program, we integrated the algorithmof Angelix into SemGraft in such a way that both tools use thesamespecificationinferredfromthebuggyprogram(werefertothis version of Angelix as Angelix’). The main difference of thetwo tools is that SemGraft performs a counterexample-guidedinductive repair loop to ensure conditional equivalence with the
reference implementation, while Angelix’ relies solely on the test
suite provided by GNU Coreutils/Busybox developers and stops
immediately when finding an expression satisfying the tests.
AllourexperimentswereperformedonIntelXeonCPUE5-2630
v4 @ 2.20GHz CPU with Ubuntu 14.04 64-bit operating system.
6.2 Summary of experiments
Table 1 summarizes our experiments with Busybox and Table 2
summarizes our experiments with GNU Coreutils. For each pair of
a buggy and a reference program, the tables show the name of the
buggyprogramanditsversioninthecommithistory,thereferenceprogramanditsversion,adescriptionofthebug,andtheresultsof
executing Angelix’ and SemGraft for repairing the defect.
SemGraft demonstrated that the proposed approach can be ap-
plied to real-worldprograms. Specifically, it managed torepair all
defects that are repaired by Angelix. Since the workflow of Sem-
Graftalsoincludesinferringspecificationforareferenceprogram
andcheckingverificationconditions,itrequiredalongertimeto
generatedpatches.Specifically,Angelix’required15minuteson
average to generate patches, while SemGraft required 45 minutes.
Intheexperiments,SemGraftinferredspecificationsconsisting
of up to 81 paths from a reference program and up to 250 paths
inabuggyprogram.Thenumberofpaths,ingeneral,dependson
the structure of the buggy and the reference programs, bounds
used for symbolic execution and the chosen condition ϕ. Typically,
thespecificationinferredfromthebuggyprogramincludesmore
136
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. Semantic Program Repair Using a Reference Implementation ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
if (!rhs_specified)
{
if ( eol_range_start ==0||eol_range_start ==3)
eol_range_start = initial;
field_found = true;
}
(a) Patch generated by Angelix’ based on tests.
if (!rhs_specified)
{
if ( eol_range_start ==0||initial <eol_range_start)
eol_range_start = initial;
field_found = true;
}
(b) Patch generated by SemGraft based on reference program.
Figure 5: Generated patches for cut(ver. 6f374d7).
paths due to additional symbolic variables injected into the buggy
program for suspicious expressions.
As can be seen from the tables, SemGraft generated repairs
equivalent to developer patches for all considered examples, while
Angelix’ that relies only on tests repaired less than half of the
defects correctly. This shows that the reference implementation
indeed can help to alleviate test overfitting.
6.3 Deriving input condition
Aninputconditionusedforenforcingconditionalequivalenceof
the patched and the reference program is an important part of our
approachandithastobedefinedbytheuser.Weuseanexample
ofabugin cut(ver.6f374d7)todemonstratehowsuchacondition
can be defined in practice. cutextracts sections from each line
ofits input.The buggyversionof cutofGNU Coreutilswrongly
interprets the command -b 2-,3- as-b 3-(extract input bytes
staring from the third byte) instead of -b 2-(extract input bytes
staringfromthesecondbyte).Thedeveloperprovidesthefollowing
two tests that cover the buggy functionality:
echo -ne '1234' | cut -b 2-,3-
echo -ne '1234' | cut -b 3-,2-
Forboth ofthese tests,theexpected outputis 234.The abovetwo
testscoverprogrambehaviorfortwoconcretepairsofindexes (2,3)
and(3,2). However, this is insufficient for a test-driven program
repair to produce a patch that generalizes beyond the tests.
In this work, we propose to define an input condition for gener-
atingconditionalequivalence-enforcingpatchesby parametrizing
existing tests. Note that the purpose of parametrizing the test is
tomakegeneratedpatchesgeneralize,yetensuringtractabilityof
specification inference. Therefore, the user should parametrize the
essentialpartinthetestrelatedtothefailure.Inthiscase,weinject
parametersinsteadoftheindexes {2,3}thataffectthewaythedata
is processed. As a result, we obtain the following input:
echo -ne '1234' | cut -b α0-,α1-
whereα0andα1indicate the injected parameters. Given such a
parametrization, the condition ϕwill be accordingly defined as:
ϕ/colonequalarg0[0]=“−”∧arg0[1]=“b”∧
arg1[1] =“−”∧arg1[2] =“,”∧arg1[4] =“−”∧in=“1234”wherearg0andarg1denote command-line arguments, inis the
standard input stream.
This example demonstrates that defining an input condition for
ourapproachmayrequireasmalleffortfromtheuser.However,we
believethatsuchaconditioncanbepotentiallyderivedautomati-
cally.Onepossiblewaytodothatwouldbetoexecutethefailing
testconcolically to collect input constraints (e.g. using ZESTI [ 23]),
and construct an input condition for our approach by generalizing
the obtained constraint. We leave this for future work.
6.4 Impact of reference program
Inthissection,weshowhowtheuseofareferenceimplementation
can enable SemGraft to find a correct path, while Angelix’ finds
a plausible (passing the given tests), but incorrect repair.
Forthe discussedbugin cutprogram,Angelix’uses thetests
given above to construct a patch in Figure 5a. This patch adds
a condition into the program that changes the way how indexes
in the given command are handled. The expression includes the
disjunct eol_range_start == 3 thatensuresthattheindex3isnot
used by the command -b 2-,3-. However, this condition does not
generalize to other values of the indexes that can appear in such
command but merely overfit the given test.
AsoppositetoAngelix’,SemGraftextractsaspecificationfrom
thebuggyandthereferenceprogramsviapreconditionedsymbolic
execution with ϕ. In this example, it extracts 30 paths from the
buggy program and 18 paths from the donor program (Busybox
cut). Then, it performs a counterexample-guided inductive repair
loop until it finds a patch that enforces conditional equivalence of
Coreutils cutandBusybox cutw.r.t.ϕ.Specifically,afterobtaining
a candidate patch as in Figure 5a, it generates a counterexample
test-b 3-,4- for which the output of Coreutils cutdiverges from
Busybox cut. Based on this test, it extracts the angelic path
{(β0,True,{initial/mapsto→3,eol_range_start /mapsto→0,}),
(β1,False,{initial/mapsto→4,eol_range_start /mapsto→3,})}.
Given the extracted path, SemGraft generates the patch in Fig-
ure5b,whichisidenticaltothedeveloperrepair.SemGraftalso
provesthatitiscorrect(equivalenttoBusybox cut)forallpossible
combinations of indexes in the described command.
7 THREATS TO VALIDITY
Internal validity. The main threat to internal validity is the man-
ual construction of the input condition ϕfor our experiments that
were based on the negative, developer-written tests. In general,
creatingsuchconditionsmaynotbetrivial.However,existingtech-niqueslikedeltadebugging[
48]couldhelptheusertominimizethe
testinputargumentsstillshowingthebuggybehavior,andhence,
tosimplifytheinputcondition.Additionally,theperformedmanual
inspection of the experimental results might be error-prone. To
mitigate this, two authors of the paper double-checked the created
input conditions and the generated patches.
External validity. The main threat to external validity is that the
chosen selection of subjects may not generalize to other programs.
We could not use existing repair benchmarks [ 17,36] due to the
137
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Mechtaev et al.
lack of reference programs. However, we focused on subjects from
theGNUCoreutilsandBusybox,whicharewell-knownthroughout
the community and provide implementation of similar function-
ality.Anotherthreattoexternalvaliditymaybethescalabilityof
our approach. It mainly depends on the number of explored paths
during the symbolic analysis and the size of the generated ver-
ification condition. Therefore, among others, we introduced theuser-defined correctness property, which enables the limitationof the search space to a practical usable scope. Furthermore, the
approachislimitedbythecapabilitiesoftheunderlyingsymbolic
executionengine,whichwetriedtoimprovebyusinganefficient
preconditioned symbolic execution approach.
Constructvalidity. Themainthreattoconstructvalidityisthe
correctnessofourimplementationbecauseourstatementabouttheconditionalpartialequivalenceofthegeneratedpatchholdsonlyif
the implementation is correct. We implemented our approach as
extensions of existing works: KLEE symbolic execution engine and
a synthesizer adapted from Angelix [ 26]. Therefore, our extension
inherits the incorrectness of the baseline. However, face-validity
showed that the results are consistent with the expected outcome.
8 RELATED WORK
8.1 Program repair
In the last years,several program repair approaches havebeen de-
veloped. These approaches can be classified into syntax-based and
semantics-based techniques. Syntax-based (generate-and-validate)
program repair techniques such as e.g., GenProg [18, 42], AE [41],
RSRepair[ 30]andACS[ 44]requiresubtasksincludingfaultlocal-
ization, patch generation and execution of regression test cases.
Mechanizing these tasks has received significant attention from
the automated and search-based software engineering community.
Approachesdeveloped byLe Goueset al.[ 16,18,42],Martinez and
Monperrus[ 7,24]showmeaningfulresultstowardstheautomation
of bug fixing. The main idea of these approaches is to use failed
testcasestolocalizepotentialfaultsandthenapplymutationsto
thesourcecodeuntiltheprogramsatisfiesallunittestcases.The
mutations that are applied to the program code can range from
smallchangeslikemodification,additionorremovingasinglecode
line[18,42]tocomplexeditoperations[ 24]minedfromsoftware
repositories.Relifix[ 35]utilizespreviousprogramversionsinorder
toperformautomatedrepairofregressionbugs,howeveritrelies
on syntactic similarity of the previous and the buggy programs,
whichdistinguishesitfromourapproach.Thequalityofpatches
produced by test-based repair approaches may be low, since thepatches may overfit the test data. A study on the correlation of
patchqualitywiththequalityofthetest-suiteguidingtherepair
has been recently conducted [ 47]. Semantics-based techniques like
SemFix [27], Nopol [ 45], DirectFix [ 25], SPR [21], Angelix [ 26] and
JFIX[15] splitpatch generationinto twophases. First, theyinfer a
synthesisspecificationfortheidentifiedprogramstatements.Sec-
ond, they synthesize a patch for these statements based on theinferred specification. However, since most of semantics-basedtechniques rely on tests as the correctness criteria, the inferred
specification only captures the property of “passing the tests”.Our approach seeks to solve the test overfitting problem in pro-
gramrepair.Weshowthat,subjecttotheavailabilityofareferenceimplementation,ourscalablesymbolicanalysiscanproducehigher
quality patches and provide partial correctness guarantees.
8.2 Software transplantation
Automatedsoftwaretransplantation[ 2,8,29]toolslike μScalpel[3]
and CodeCarbonCopy [ 31] aim at transplanting new functional-
ity from a donor application into a recipient application. Code-
Phage[32]canfixprogramerrorslikeoutofboundsaccess,integer
overflow, and divide by zero errors. They focus on finding an er-ror checking code in the donor application that can serve as acompensation for a missing check in the host application. Sincetheir approach tries to copy code, it is necessary to translate the
checkfromthedatastructuresandnamespaceofthedonorinto
an application-independent representation suitable for insertion
into the recipient application. The advantage of SearchRepair [ 11]
compared to other repair approaches is the use of semantic code
search[33,34]toidentifysuitablecodefragmentsforrepair.Our
approach differs from software transplantation literature, since we
do not seek to inject any new functionality lifted from a donor
program.Ourgoalistoincreasethequalityofgeneratedpatches
usingadifferentcorrectnesscriteria,namelythereferenceprogram.
We also differ from recent works on grafting of code clones [ 49],
since this line of work seeks to achieve greater test-reuse across
code clones for the sake of differential testing.
8.3 Equivalence checking
Lahiri et al. [ 13] proposed an approach to find the rootcause for
equivalencefailuresbyleveragingsemanticsimilaritybetweentwoprogrambinaries.Sincetheyaimtoextractacompletespecification,
theirapproachscalesonlytosmallprograms.Ourworksacrifices
completeness for the sake of applicability by checking conditional
equivalenceofabuggyprogramandareferenceprogramw.r.t.a
user-defined input condition.
9 CONCLUSION
Weproposedamethodologyofgeneratingpatchesbasedonarefer-
ence implementation. Our technique addresses the test-overfitting
problem by providing additional correctness guarantees. Specifi-
cally, it synthesizes a conditional equivalence-enforcing patch w.r.t.auser-definedinputcondition.Ourexperimentsdemonstratedthat
ourmethodscalestoreal-worldprogramssuchasGNUCoreutils
and Busybox and helps to generate more correct repairs.
ACKNOWLEDGEMENTS
We thank the participants of Dagstuhl Seminar 17022 on Auto-
matedProgramRepairforinspiringdiscussions.Thisresearchis
supportedinpartbytheNationalResearchFoundation,PrimeMin-
ister’s Office, Singapore under its National Cybersecurity R&D
Program (Award No. NRF2014NCR-NCR001-21) and administered
by the National Cybersecurity R&D Directorate. This work is also
supportedby theGermanResearch Foundation(GR3634/4-1 EM-
PRESS). This work is also supported by Office of Naval Research
grant ONRG-NICOP-N62909-18-1-2052.
138
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. Semantic Program Repair Using a Reference Implementation ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]Rajeev Alur, Rastislav Bodík, Eric Dallal, Dana Fisman, Pranav Garg, Garvit
Juniwal, Hadas Kress-Gazit, P. Madhusudan, Milo M. K. Martin, Mukund
Raghothaman,ShambwadityaSaha,SanjitA.Seshia,RishabhSingh,Armando
Solar-Lezama, Emina Torlak, and Abhishek Udupa. 2015. Syntax-Guided Synthe-
sis. InDependable Software Systems Engineering. 1–25.
[2]EarlT.Barr,YuriyBrun,PremkumarT.Devanbu,MarkHarman,andFederica
Sarro. 2014. The plastic surgery hypothesis. In FSE. ACM, 306–317.
[3]Earl T. Barr, Mark Harman, Yue Jia, Alexandru Marginean, and Justyna Petke.
2015. Automated Software Transplantation. In ISSTA. ACM, New York, NY, USA,
257–269.
[4]CristianCadar,DanielDunbar,DawsonREngler,etal .2008.KLEE:Unassistedand
Automatic Generation of High-Coverage Tests for Complex Systems Programs..
InOSDI, Vol. 8. 209–224.
[5]SatishChandra,EminaTorlak,ShaonBarman,andRastislavBodík.2011. Angelic
debugging. In ICSE. 121–130.
[6]LeonardoDeMouraandNikolajBjørner.2008. Z3:AnEfficientSMTSolver.In
TACAS. Springer-Verlag, Berlin, Heidelberg, 337–340.
[7]Thomas Durieux, Matias Martinez, Martin Monperrus, Romain Sommerard, and
Jifeng Xuan. 2015. Automatic Repair of Real Bugs: An Experience Report on the
Defects4J Dataset. CoRRabs/1505.07002 (2015).
[8]MarkHarman,YueJia,andWilliamB.Langdon.2014. BabelPidgin:SBSECan
Grow and Graft Entirely New Functionality into a Real World System. In SSBSE,
Vol. 8636. Springer, 247–252.
[9]JamesAJones,MaryJeanHarrold,andJohnStasko.2002. Visualizationoftest
information to assist fault localization. In ICSE. ACM, 467–477.
[10]Ming Kawaguchi, Shuvendu Lahiri, and Henrique Rebelo. 2010. Conditional
equivalence. Technical Report.
[11]Yalin Ke, Kathryn T. Stolee, Claire Le Goues, and Yuriy Brun. 2015. Repairing
Programs with Semantic Code Search. In ASE. IEEE Computer Society, 295–306.
[12]James C. King. 1976. Symbolic Execution and Program Testing. Commun. ACM
19, 7 (1976), 385–394.
[13]ShuvenduK.Lahiri,ChrisHawblitzel,MingKawaguchi,andHenriqueRebêlo.
2012. SYMDIFF: A Language-Agnostic Semantic Diff Tool for Imperative Pro-
grams. In CAV. 712–717.
[14]ShuvenduK.Lahiri,RohitSinha,andChrisHawblitzel.2015. AutomaticRoot-
causing for Program Equivalence Failures in Binaries. In CAV. 362–379.
[15]Xuan-Bach D. Le, Duc-Hiep Chu, David Lo, Claire Le Goues, and Willem Visser.
2017. JFIX: semantics-based repair of Java programs via symbolic PathFinder. In
ISSTA. ACM, 376–379.
[16]ClaireLeGoues,MichaelDewey-Vogt,StephanieForrest,andWestleyWeimer.
2012. A Systematic Study of Automated Program Repair: Fixing 55 out of 105
Bugs for $8 Each. In ICSE. IEEE Press, 3–13.
[17]Claire Le Goues, Neal Holtschulte, Edward K Smith, Yuriy Brun, Premkumar
Devanbu, Stephanie Forrest, and Westley Weimer. 2015. The ManyBugs and
IntroClassbenchmarksforautomatedrepairofCprograms. TSE41,12(2015),
1236–1256.
[18]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2012.
GenProg: A generic method for automatic software repair. IEEE TSE 38, 1 (2012),
54–72.
[19]Rainer Leupers. 2013. Code optimization techniques for embedded processors:
Methods, algorithms, and tools. Springer Science & Business Media.
[20]Qing Li, Tatuya Jinmei, and Keiichi Shima. 2010. IPv6 Core Protocols Implementa-
tion. Morgan Kaufmann.
[21]Fan Long and Martin Rinard. [n. d.]. Staged program repair with condition
synthesis. In ESEC/FSE. ACM, 166–178.
[22]Fan Long and Martin Rinard. 2016. Automatic patch generation by learning
correct code. In POPL. ACM, 298–312.
[23]Paul Dan Marinescu and Cristian Cadar. 2012. Make test-zesti: A symbolic
execution solution for improving regression testing. In ICSE. IEEE Press, 716–
726.
[24]MatiasMartinezandMartinMonperrus.2015. Miningsoftwarerepairmodelsfor
reasoning on the search space of automated program fixing. Empirical Software
Engineering 20, 1 (2015), 176–205.
[25]SergeyMechtaev,JooyongYi,andAbhikRoychoudhury.2015. Directfix:Looking
for simple program repairs. In ICSE. IEEE Press, 448–458.
[26]Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2016. Angelix: Scalable
Multiline Program Patch Synthesis via Symbolic Analysis. In ICSE. 691–701.
[27]Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra.2013. SemFix:ProgramRepairviaSemanticAnalysis.In ICSE.IEEEPress,
Piscataway, NJ, USA, 772–781.
[28]SuzettePerson,MatthewB.Dwyer,SebastianG.Elbaum,andCorinaS.Pasareanu.
2008. Differential symbolic execution. In FSE. 226–237.
[29]JustynaPetke,MarkHarman,WilliamB.Langdon,andWestleyWeimer.2014.
Using Genetic Improvement and Code Transplants to Specialise a C++ Program
to a Problem Class. In EuroGP, Vol. 8599. Springer, 137–149.[30]YuhuaQi,XiaoguangMao,YanLei,ZiyingDai,andChengsongWang.2014. The
strengthofrandomsearchonautomatedprogramrepair.In ICSE.ACM,254–265.
[31]Stelios Sidiroglou-Douskos, Eric Lahtinen, Anthony Eden, Fan Long, and Martin
Rinard. 2017. CodeCarbonCopy. In ESEC/FSE. ACM, 95–105.
[32]SteliosSidiroglou-Douskos,EricLahtinen,FanLong,andMartinRinard.2015.
AutomaticErrorEliminationbyHorizontalCodeTransferAcrossMultipleAp-
plications. In PLDI. ACM, New York, NY, USA, 43–54.
[33]Kathryn T. Stolee, Sebastian G. Elbaum, and Daniel Dobos. 2014. Solving the
SearchforSourceCode. ACMTrans.Softw.Eng.Methodol. 23,3(2014),26:1–26:45.
[34]Kathryn T. Stolee, Sebastian G. Elbaum, and Matthew B. Dwyer. 2016. Code
searchwithinput/outputqueries:Generalizing,ranking,andassessment. Journal
of Systems and Software 116 (2016), 35–48.
[35]Shin Hwei Tan and Abhik Roychoudhury. 2015. relifix: Automated repair of
software regressions. In ICSE. IEEE Press, 471–482.
[36] ShinHwei Tan,JooyongYi,SergeyMechtaev,AbhikRoychoudhury,etal.2017.
Codeflaws: a programming competition benchmark for evaluating automated
program repair tools. In ICSE Companion. 180–182.
[37]Shin Hwei Tan, Hiroaki Yoshida, Mukul R Prasad, and Abhik Roychoudhury.
2016. Anti-patterns in search-based program repair. In FSE. ACM, 727–738.
[38]Nikolai Tillmann and Wolfram Schulte. 2005. Parameterized unit tests. In ACM
SIGSOFT Software Engineering Notes, Vol. 30. ACM, 253–262.
[39] Busybox Website. 2017. Busybox. https://busybox.net/. (2017).[40]
GNU Coreutils Website. 2017. GNU Coreutils.
https://www.gnu.org/software/coreutils/coreutils.html. (2017).
[41]WestleyWeimer,ZacharyP.Fry,andStephanieForrest.2013.Leveragingprogram
equivalenceforadaptiveprogramrepair:Modelsandfirstresults.In ASE.IEEE,
356–366.
[42]Westley Weimer, ThanhVu Nguyen, Claire Le Goues, and Stephanie Forrest.
2009. Automatically Finding Patches Using Genetic Programming. In ICSE. IEEE
Computer Society, 364–374.
[43]QiXinandStevenPReiss.2017. Identifyingtest-suite-overfittedpatchesthrough
test case generation. In ISSTA. ACM, 226–236.
[44]Yingfei Xiong, Jie Wang, Runfa Yan, Jiachen Zhang, Shi Han, Gang Huang, and
LuZhang.2017. Preciseconditionsynthesisforprogramrepair.In ICSE.IEEE/
ACM, 416–426.
[45]Jifeng Xuan, Matias Martinez, Favio Demarco, Maxime Clement, Sebastian
R.LamelasMarcote,Thomas Durieux,DanielLeBerre,andMartinMonperrus.
2017. Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs.
IEEE TSE 43, 1 (2017), 34–55.
[46]Jinqiu Yang, Alexey Zhikhartsev, Yuefei Liu, and Lin Tan. 2017. Better test cases
for better automated program repair. In ESEC/FSE. ACM, 831–841.
[47]JooyongYi,ShinHweiTan,SergeyMechtaev,MarcelBoehme,andAbhikRoy-
choudhury.2018. CorrelationofTest-suiteMetricswithPatchQualityinProgram
Repair.Empirical Software Engineering To appear (2018).
[48]Andreas Zeller. 1999. Yesterday, My Program Worked. Today, It Does Not. Why?.
InFSE. Springer-Verlag, London, UK, UK, 253–267.
[49]TianyiZhangandMiryungKim.2017.Automatedtransplantationanddifferential
testing for clones. In ICSE. IEEE / ACM, 665–676.
139
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:07 UTC from IEEE Xplore.  Restrictions apply. 