AutomaticallyAnalyzing GroupsofCrashes
forFinding Correlations
MarcoCastelluccio
Mozilla
London,UK
UniversityFederico II of Naples
Naples, Italy
marco.castelluccio@unina.itCarloSansone
UniversityFederico II of Naples
Naples, Italy
carlo.sansone@unina.it
LuisaVerdoliva
UniversityFederico II of Naples
Naples, Italy
verdoliv@unina.itGiovanni Poggi
UniversityFederico II of Naples
Naples, Italy
poggi@unina.it
ABSTRACT
We devised an algorithm, inspired by contrast-set mining algo-
rithmssuchasSTUCCO,toautomaticallyfindstatisticallysignifi-
cant properties (correlations) in crash groups. Many earlier works
focusedonimprovingtheclusteringofcrashesbut,tothebestof
our knowledge, the problem of automatically describing properties
of a cluster of crashes is so far unexplored. This means developers
currentlyspendafairamountoftimeanalyzingthegroupsthem-
selves, which in turn means that a) they are not spending their
time actually developing a fix for the crash; and b) they might miss
something in their exploration of the crash data (there is a large
numberofattributesincrashreportsanditishardanderror-prone
tomanuallyanalyzeeverything).Ouralgorithmhelpsdevelopers
and release managers understand crash reports more easily and
in an automated way, helping in pinpointing the root cause of the
crash. The tool implementingthe algorithm has been deployed on
Mozilla’scrash reportingservice.
CCS CONCEPTS
·Software andits engineering →Software reliability ;
KEYWORDS
Crashes; Crash Reports; Crash Analysis.
ACMReference format:
Marco Castelluccio, Carlo Sansone, Luisa Verdoliva, and Giovanni Poggi.
2017. Automatically Analyzing Groups of Crashes for Finding Correlations.
InProceedingsof201711thJointMeetingoftheEuropeanSoftwareEngineering
Conference and the ACM SIGSOFT Symposium on the Foundations of Soft-
wareEngineering,Paderborn,Germany,September4ś8,2017(ESEC/FSE’17),
10pages.
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE’17, September 4ś8, 2017, Paderborn, Germany
©2017 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-5105-8/17/09...$15.00
https://doi.org/10.1145/3106237.3106306https://doi.org/10.1145/3106237.3106306
1 INTRODUCTION
Fixingcrashesisoneofthetopprioritiesforsoftwareorganizations,
as they are one of the main pain points for users and might lead
them to leave. Even a single crash can dramatically worsen how
usersperceiveasoftware,especiallyifitcausesthelossofimportant
data.Actingquicklyisthusreallyimportanttoavoidlosingusers
andkeepahigh qualitysoftware.
Severalsoftware organizationshavedeployedautomatedcrash
reportingsystems,suchasMozilla’sSocorro[ 1]andWindowsError
Reporting [ 12], whichare used to collect reports from users at the
time of crash. A report received by Socorro comprises typically
more than a hundred attribute-value fields. These reports are then
analyzed by dedicated personnel to find out fixes and improve
software quality. It should be realized, however, that these systems
collectahugenumberofcrashreportsdaily,aboutthreehundred
thousandreports/dayforSocorro,whichcannotbeprocessedon
anindividualbasis.Therefore,thetypicalworkflowconsistsoftwo
key phases
(1) crash report clustering;
(2) clusterfeaturingandanalysis.
The goalof clustering istogrouptogether similar reports,asthey
are likely originated by multiple instances of the same software
problem. Once the problem is fixed, all these reports can be dis-
cardedatoncefromfurtheranalysis.Moreover,clusteringallows
one to compute precious statistics on the cluster itself, enabling
the second phase of the workflow. In fact, the typical features of
interestinaclusterconcernthefrequencyofoccurrenceofattribute-
value pairs, which may provide useful hints for the solution of the
problem.Asanexample,assumethataperfectclusteringprocess
succeeds in grouping together all crash reports originated by a
given software bug, and assume also that all such reports are char-
acterizedbyadistinctivefeaturewhichisneverobservedinreports
ofotherclusters.Whilenotconclusive,thisobservationwouldpro-
videastrongcluefortheanalyst,andwouldprobablyallowaquick
fixoftheproblem.Thisidealizedprocessissummarizedgraphically
inFigure 1.
717ESEC/FSE’17,September4–8, 2017, Paderborn,Germany M. Castelluccio,C.Sansone,L. Verdoliva, andG.Poggi
CLUSTERING
FEATURING…
Group 1 Group 2
G1 features G2 features Overall features
Dataset
Figure 1: Idealized process: with perfect clustering, proper-
tiesthat define thegroupsare easily found.
Needlesstosay,real-worldoperationsareveryfarfromthissim-
plisticcase.On/offfeaturesrarelyoccur,andtheanalystmustfocus
onminorvariationsinthefrequenciesofoccurrenceofattribute-
valuepairsacrossgroups.Moreover,themostdistinctivefeatures
concern usually jointoccurrences. If the number of elementary
featuresisalreadylarge,thenumberoffeaturesconcerningmore
complex behaviors, possibly involving tuples of attribute-value
pairs, makes brute force analysis simply infeasible. It requires very
skilledanalyststonavigateeffectivelythroughthesedataandex-
tract useful clues. To further complicate things, the preliminary
clustering of crashes is itself far from perfect, which may strongly
affecttheresultsofsubsequentanalyses.Whenaclusterincludes
reports that have no relation with one another, the resulting fea-
tures are averaged together and hardly distinctive anymore. On
the contrary, when there are too small groups, since reports for
the same crash are divided in multiple clusters, features become
unstable,leadingto erroneous conclusions.
Theabovediscussionunderlinestheneedofeffectiveautomated
toolsthatsupporttheanalyst’sworkinbothphasesontheprocess
toi)perform a reliable clustering of crash reports, and ii)single
out the most meaningful features. Many previous studies in the
literaturehavefocusedonthefirstproblem,namely,proposinga
number of competing solutions to best cluster crashes in groups.
Section 6 contains a more detailed explanation of some of them. In
thispaper,instead,wefocusonthesecondproblem,andpropose
anautomatedtooltosupportgroupunderstandingaftertheclus-
tering has already taken place. The proposed tool finds statistically
significant properties in crash groups, sorts them by decreasing
importance, and submits them to the analyst. Developers are there-
fore freed from this tedious preliminary analysis, and can focus
on fixing the crash. It should be also underlined that the manual
analysis,giventhelargenumberofattributesincrashreports,isnot
onlytediousbutalsoerror-prone(alsoduetotheeffectsoffatigue).
Theproposedtoolmayhappentofindinterestingpropertiesthat
Figure 2: Dialog window presented to the users when they
experienceacrash.
theanalystcouldmiss.Automaticallyfindingpropertiesofcrash
groups also allows release managers to quickly act with temporary
workarounds, for example by blocking updates to a crashy version
for aparticularsetofusers.
Specifically,ourapproachisbasedonadataminingtechnique,
contrast-setlearning[ 24],appliedsuccessfullytoanumberofother
problems in software engineering [ 27] and beyond (e.g. [ 16]). The
approachwepresentinourstudycanalsohelpwiththetriageof
crashgroups,infactreleasemanagerscandecideontheirimpor-
tance,afterunderstandingthepossiblecausesandpropertiesofa
crash. We evaluatethe systemusing crash datacollected from the
Mozilla crash reporting system and bug tracking system. Although
asystematic analysisofperformanceinnot feasibleforpractical
reasons, we collected significant evidencethat the systemmay ac-
tuallyhelpunderstandingagroupofcrashesandreducethetime
neededto solve the problem.
The remainder of this paper is organized as follows. Section 2
provides background information about Socorro, the Mozilla crash
reportingsystemusedinourstudy.Section3describestheproposed
algorithm. Section 4 presents the validation of the results of our
algorithm,appliedtorealworldcasesforMozillaFirefoxcrashes.
Section 5 discusses threats to the validity of this study. Section 6
summarizes relatedworks andSection 7concludes the paper.
2 SOCORRO AND CRASH REPORTS
Mozilla’sapplicationsareshippedwithabuilt-inautomaticcrash
reporting tool [ 1]. When end users encounter a crash, they are
presented with a dialog window that asks them to submit a report
(see Figure 2).
Crash reports include stack traces of the threads that were run-
ningatthetimeofthecrashandotherinformationabouttheuser’s
environment (e.g. operating system, memory-relatedinformation,
modulesloadedintheprocess,etc.).Asubsetofthefieldscontained
in a crash report is depicted in Table 1. The reader may refer to
[21] for an up-to-date JSON schema of a crash report. Some of the
information containedina crash report mightbe sensitive,which
718Automatically Analyzing GroupsofCrashes
for FindingCorrelations ESEC/FSE’17,September4–8, 2017, Paderborn,Germany
Table 1:Asubset oftheattributes present inacrashreport.
Name Description
Platform Thename ofthe Operating System.
PlatformVersion ThedetailedversionoftheOperatingSystem
(e.g.uname -a on Linux).
Addons A list of the addons, with their version, in-
stalled in the Firefox profile.
Modules Alistofthemodules(DLLfilesonWindows,
SO files on Linux, dylib files on Mac), with
theirversion,loadedintheapplication’spro-
cess.
UserComment A(usuallybrief)commentleftbytheuserat
the time ofcrashing.
CPU Info Detailed information (vendor, family, model,
stepping,numberofcores)abouttheCPUof
the user.
Adapter VendorID Thevendorofthegraphicscardontheuser’s
machine.Thereareotherrelatedattributes
suchasAdapterDeviceID,AdapterDriver
Version, etc.
SafeMode A boolean variable that indicates whether
Firefox was runningin safe mode.
UserAgentLocale Thelanguage ofthe user.
... ...
is why the submission of crash reports is not silent, but requires
the userto acceptaprompt.
As can be seen from Figure 2, the user has a chance to enter a
short comment at the time of crash. This allows users to specify
detailsabouttheircrashreport.Forexample,whattheyweredoing
rightbeforetheyexperiencedthecrash.Crashreportsarethensent
to the Socorroserver [23], which:
(1) assignsaunique ID to eachreport;
(2) performs somepost-processing onthe reports;
(3)groups the reports together using an extremely fast, but
not very reliable,algorithm, describedbelow.
See Figure 3for an overviewofthe Socorroarchitecture.
The reports are clustered based on the top method signature
ofthestacktraceofthecrashingthread(oranotherthread,ifthe
crashisduetotheapplicationwillinglyterminatingitselfaftera
hang).Table2showsanexampleofastacktrace,withthegroup
name itwasassignedbythe Socorroalgorithm.
There areseveral rules that allowto skip somemethods if they
aredeemedtobeuselessforgroupingpurposes(e.g.averygeneric
function, a function from an external driver, etc.). Some of the
rules are general purpose (e.g. C++ standard library functions),
some are really specific to the Mozilla applications (e.g. XPCOM
[22] functions). This large set of rules has been built over time,
manually,bydevelopers.
This algorithm is sometimes ineffective, as two crashes that
happen in the same function might be completely different fromTable 2:Example stack trace.The group name is inbold.
Frame Module Signature
0 xul.dll mozilla::storage::Service::getSingleton()
1 xul.dll mozilla::storage::ServiceConstructor
2 xul.dll nsComponentManagerImpl::CreateInstanceByContractID(char const*,nsISupports*,nsID const&, void**)
3 xul.dll nsComponentManagerImpl::GetServiceByContractID(char const*,nsID const&, void**)
4 xul.dll nsCOMPtr_base::assign_from_gs_contractid(nsGetServiceByContractID,nsID const&)
5 xul.dll nsCOMPtr <mozIStorageService >::nsCOMPtr<mozIStorageService >(nsGetServiceByContractID)
6 xul.dll nsPermissionManager::OpenDatabase(nsIFile*)
7 xul.dll nsPermissionManager::InitDB(bool)
8 xul.dll nsPermissionManager::Init()
9 xul.dll nsPermissionManager::GetXPCOMSingleton()
10 xul.dll nsIPermissionManagerConstructor
11 xul.dll nsComponentManagerImpl::CreateInstanceByContractID(char const*,nsISupports*,nsID const&, void**)
12 xul.dll nsComponentManagerImpl::GetServiceByContractID(char const*,nsID const&, void**)
13 xul.dll nsCOMPtr_base::assign_from_gs_contractid(nsGetServiceByContractID,nsID const&)
14 xul.dll nsCOMPtr <nsIPermissionManager >::nsCOMPtr<nsIPermissionManager >(nsGetServiceByContractID)
15 xul.dll mozilla::services::GetPermissionManager()
16 xul.dll mozilla::dom::NotificationTelemetryService::RecordPermissions()
17 xul.dll NotificationTelemetryServiceConstructor
18 xul.dll nsComponentManagerImpl::CreateInstanceByContractID(char const*,nsISupports*,nsID const&, void**)
19 xul.dll nsComponentManagerImpl::GetServiceByContractID(char const*,nsID const&, void**)
20 xul.dll nsCOMPtr_base::assign_from_gs_contractid(nsGetServiceByContractID,nsID const&)
21 xul.dll nsCOMPtr <nsISupports>::nsCOMPtr<nsISupports>(nsGetServiceByContractID)
22 xul.dll NS_CreateServicesFromCategory(char const*,nsISupports*,char const*,char16_tconst*)
23 xul.dll nsXREDirProvider::DoStartup()
24 xul.dll XREMain::XRE_mainRun()
25 xul.dll XREMain::XRE_main(int,char**const, nsXREAppDataconst*)
26 xul.dll XRE_main
27 firefox.exe do_main
28 firefox.exe wmain
29 firefox.exe __scrt_common_main_seh
30 kernel32.dll BaseThreadInitThunk
31 ntdll.dll __RtlUserThreadStart
32 ntdll.dll _RtlUserThreadStart
Figure 3:Overview ofthe crashreporting system
eachother.Thisisparticularlynoticeablewithcrashesrelatedto
the JavaScript JIT compiler. However, processing speed isdeemed
moreimportantthanaccuracyinthiscontextandnewclustering
methodsshould be alsovery fast to qualifyas aviable alternative.
3 AUTOMATICANALYSISOFCRASH
GROUPS
The analysis method adopted here is a slightly modified version of
the contrast set mining algorithm STUCCO (Searching and Testing
forUnderstandableConsistentCOntrasts)proposedoriginallyby
BayandPazzani[ 3,4].Toillustratethemethodwewillrefertoa
toyexample,withthedatasetpartitionedintwoclusters,orgroups,
with cardinalities|G1|=700 and|G2|=300, and reports including
onlyn=2attributes,platform( p),andgraphicscard( д),whichcan
719ESEC/FSE’17,September4–8, 2017, Paderborn,Germany M. Castelluccio,C.Sansone,L. Verdoliva, andG.Poggi
ROOT
p=W
 p=L
 p=M
 g=N
 g=A
p=W, g=N
 p=W, g=A
 p=L, g=N
 p=L, g=A
 p=M, g=N
 p=M, g=A
Figure 4:Root andallpossible specializations
takethreeandtwovaluesrespectively, p∈{W,L,M}(forWindows,
Linux, andMac)and д∈{N,A}(forNVIDIA, andAMD).
3.1 The Contrast Set MiningProblem
In the contrast set mining framework, the dataset is a set of n-
dimensionalvectors,whosecomponentsarediscretevalues.The
vectors are partitioned beforehand in mutually exclusive groups,
G1,G2,...,according to external criteria.
A contrast-set is defined as a set of attribute-value pairs. For
example, cset1={p=W}is a contrast set concerning a single
attribute-value pair, while cset2={p=W,д=N}concerns a
coupleofattribute-valuepairs,andisactuallya specialization ofthe
former.Thesupportofacontrast-setinagroup, S(cset,G),isthe
percentageofvectorsinthegroupforwhichthecontrast-setistrue.
Contrast-set supports are the features used to characterize groups.
So, for example, having S(cset1,G1)=0.7 andS(cset1,G2)=0.3,
means that, in Group 1, 70% of crashes occurred on a Windows
platform,whileinGroup2thepercentagewas30%.Suchalarge
difference seems to indicate that the platform is not irrelevant
for these crashes. Accordingly, the goal of contrast-set mining is
tofindcontrast-sets,alsocalled deviations ,whosesupportdiffers
meaningfullyacrossgroups.
More formally, for a contrast set to be declared a deviation, it
must be both largeandsignificant . The first condition is expressed
as
max
ij/barex/barexS(cset,Gi)−S(cset,Gj)/barex/barex≥δ (1)
whereδis a constant (minimum support difference) defined by the
user. Significance, instead, is declared based on the outcome of a
statisticaltest ofhypotheses,
/braceleftbiggH0:P(cset=true|Gi)=P(cset=true|Gj)
H1:P(cset=true|Gi)/nequalP(cset=true|Gj)(2)
carried out for all couples of groups, Gi,Gj, with a user-defined
false alarm level, α.
3.2 STUCCO
In STUCCO, contrast-set mining is cast as a tree search problem.
The root node is an empty contrast-set. Then, for each step of
the algorithm, existing nodes are specialized by appending new
attribute-valuepairsto existingones.A canonical orderingofthe
attributes is used to avoid visiting the same node twice. With refer-
encetoourtoyexample,Figure4showsthesearchtreeaftertwo
levels of specialization. Note that the nodes д=Nandд=Ahave
nochildren, as дcomes after pinour orderedattribute list.
STUCCOperformsabreadth-firstlevel-wisesearchinthetree.
We provide, here, a very high-level description of the algorithm,
going into more details in the following subsection. For each node
atagivenlevel,thenumberofoccurrencesforeachgroupinthe
dataset is counted. Based on such data, some heuristics are appliedAlgorithm1: STUCCOalgorithm
Setofcandidates C←{};
Setofdeviations D←{};
Setofprunedcandidates P←{};
Letprune(c)returnTrueifcshould be pruned;
whileCis not empty do
scan data andcount support ∀c∈C;
foreachc∈Cdo
ifsiдnificant(c)∧larдe(c)then
D←D∪c
end
ifprune(c)=Truethen
P←P∪c
else
Cnew←Cnew∪GenChildren(c,P)
end
end
C←Cnew
end
Dsurprisinд←FindSurprisinд(D)
todecideonwhetherthenodeshouldbepruned,becomeaterminal
node,orgeneratenewchildren.Thetreegrowsuntilnomorechild
node can be generated, or a suitable stopping condition (applied
to limit processing time) is met. After the whole tree is grown,
each surviving node corresponds to a valid candidate contrast-
set. Contrast-sets that are found to be both large and significant
(deviations),andalsosurprising,areeventuallykept,andsubmitted
totheanalystasanorderedlist,fromlargesttosmallest.Algorithm1
providesapseudo-codedescriptionoftheprocess.Figure5,instead,
showsthefirstfewstepsofthealgorithmappliedtoourtoyexample.
In particular:
(1)allpossibleattribute-valuepairs(łcandidatesž)are gener-
atedfor eachattribute inacrash report (figure 5a);
(2)thenumberofoccurrencesforeachcandidateineachgroup
iscounted(figure 5b);
(3)somenodesareprunedbasedonsuitableheuristics(figure
5c);
(4)newcandidatesaregeneratedbymergingpreviousones
which survived pruning, for example {p=W}and{д=
N}give riseto{p=W,д=N}(figure 5d).
Steps 2-4 are repeated until there are no more candidates or a suit-
able stopping condition is met, for example, the maximum number
ofiterations.Eventually,allnodes/contrast-setsaretested,andonly
thosethatarelarge,significant,andsurprisingaresubmittedtothe
analyst.
Thefollowingsubsectionsprovidethenecessarydetailsforafull
comprehension ofthe algorithm, describing thetests on largeness,
significance, and surprise, as well as the heuristic rules for tree
pruning.
3.2.1 Selecting Large Contrast-Sets. This is a straightforward
test: For a contrast-set to be large, its support must be larger than
the threshold, δ,definedbythe user.
720Automatically Analyzing GroupsofCrashes
for FindingCorrelations ESEC/FSE’17,September4–8, 2017, Paderborn,Germany
ROOT
g1=700
g2=300
p=W
 p=L
 p=M
 g=N
 g=A
(a)Generationof allpossible attribute-valuepairs
ROOT
g1=700
g2=300
p=W
g1=600
g2=295
p=L
g1=70
g2=5
p=M
g1=30
g2=0
g=N
g1=200
g2=200
g=A
g1=500
g2=100
(b)Countof the occurrences for allcandidates
ROOT
g1=700
g2=300
p=W
g1=600
g2=295
X
 X
g=N
g1=200
g2=200
g=A
g1=500
g2=100
(c) Pruning of candidates using a set of heuristics
ROOT
g1=700
g2=300
p=W
g1=600
g2=295
X
 X
g=N
g1=200
g2=200
g=A
g1=500
g2=100
p=W, g=N
 p=W, g=A
(d)Generationof a new level of candidates
Figure5:Samplerunofthealgorithminthecontextofcrash
reports
3.2.2 Selecting Significant Contrast-Sets. To evaluate whether a
contrast-setissignificant,werelyonthetestofhypothesesofEq.2.
The null hypothesis is that the support of the contrast-set is equal
across all groups or, differently said, it is independent of group
membership. To this end, we build a contingency table like that
shown in Table 3 reporting the occurrences of a contrast set across
groups and the corresponding supports, our features of interest,
that is, the frequencies ofoccurrence inthe group.Table 3:Example contingency table
p=Wp/nequalWgroup size
Group 1 600(85%) 100(15%) 700
Group 2 295(98%) 5( 2%) 300
Overall 895(90%) 105(10%) 1000
In ourexampleweanalyze cset1,namely,platform=Windows.
Ifgroupandthe platformwereindependentvariables,thepropor-
tionofcrashreportswiththeWindowsplatformshouldbeabout
the same across all groups. This is not the case in our example.
However,thesupportsmaydifferjustbecauseofrandomfluctua-
tions, and the difference may not be statistically significant. Hence,
weneedtodeterminewhethersuchdifferencesaretheeffectofa
true dependency between the variables or if it can be attributed
torandomness,whichiswhyweneedastatisticaltest.Thestan-
dard test for independence of variables in contingency tables is the
chi-square test:
χ2=r/summationdisplay.1
i=1c/summationdisplay.1
j=1(oij−eij)2
eij(3)
whereoijistheobservedfrequencyincell ijandeijisthefrequency
expectedunderthehypothesisofindependencebetweenrowand
column variables. We then compare the resulting value against
theχ2distribution under the null hypothesis, selecting level of
significance α, which represents the probability of rejecting the
null hypothesiswhen itholds(false alarm).
For a single test, a level α=0.05, implying a false alarm prob-
ability of 5%, could be considered acceptable for our application.
However, since a large number of contrast sets are typically tested
for significance, the overall number of false alarms may be dis-
turbinglylarge.Forexample,ifweran100testsat α=0.05,andthe
nullhypothesiswerealwaystrue,wewoulddetectontheaverage5
significant differences that are not actually there. To keep the false
alarm rate within acceptable limits, STUCCO reduces αaccording
totheBonferronicorrection:given H1,H2,...,Hkhypotheses,and
their corresponding p-valuesp1,p2,...,pk, the hypothesis Hiis
rejectedif pi<α/k.TheBonferronicorrectioncontrolsthefami-
lywise error rate (FWER), which is the probability of incorrectly
rejecting at leastone true hypothesis Hi,at<=α.
FWER=P 
ktrue/uniondisplay.1
i=1/parenleftBig
pi≤α
k/parenrightBig 
(4)
≤ktrue/summationdisplay.1
i=1/braceleftBig
P/parenleftBig
pi≤α
k/parenrightBig/bracerightBig
≤ktrueα
k≤α
Thisholdsnomatterhowmanyofthenullhypothesesaretrueand
even withdependent tests [26].
There are two problems in the application of the Bonferroni
correctioninthecontextofSTUCCO:firstofall,ifwereportresults
in a level-wise fashion (shorter first, then longer), we cannot know
howmanytestswewillperformintotal,whichmakesitimpossible
to know the exact value of k. Moreover, as αgets smaller, the
statisticalpowerofthetestsdecreases,increasingtheprobabilityof
producing falsenegatives. This cannot be avoided, sincewewant
721ESEC/FSE’17,September4–8, 2017, Paderborn,Germany M. Castelluccio,C.Sansone,L. Verdoliva, andG.Poggi
to reduce the probability of false positives. However, we can use
differentvaluesof αfortestsconcerningdifferentlevelsofthetree,
ensuring a high power for tests at higher levels (which are more
general and easier to understand) and accepting a lower power for
tests more down the tree. Since the Bonferroni method holds as
longas/summationtext.1
iαi≤α,STUCCOadopts level-dependent values
αl=min/parenleftbiggα
2l/|Cl|,αl−1/parenrightbigg
(5)
whereαlisthecutoffforlevel l,and|Cl|isthenumberofcandidates
atlevell.Thiswayweassign1
2ofthetotal αrisktotestsatlevel
1,1
4totestsatlevel2,etc.Theminruleensuresthat,aswemove
to deeper levels, the αcutoff can onlydecrease,makingthe tests
more likely not to rejectthe null hypothesis.
3.2.3 SelectingSurprisingContrast-Sets. Asalreadysaid,contrast-
setsareshowninalevel-wisefashiongivenhigherprioritytohigher
levels (e.g. level 1, with a single attribute-value pair) as they are
easiertointerpret.Furtherspecializationsarethenincludedonly
if they are łsurprisingž, namely, when the observed frequencies
depart significantly from the expected frequencies. For example,
if for allGi’s,S(p=W,д=N|Gi)≃S(p=W|Gi)×(д=N|Gi),
that is the support of the specialization can be derived based on
an independence conjecture, than the specialization itself does not
add information (is not surprising) and thus can be discarded even
when itisadeviation according to the definition.
3.2.4 Pruning the Search Space. When building the contrast-set
tree,anumberofheuristicscanbeappliedtolimititssizeandhence
reduce the computationalburden.
Minimumdeviationsize. Whenacontrast-sethassupportless
thanδfor every node, it can be pruned. In fact, if the support is
smallerthan δforanygivengroup,thedifferencebetweenanytwo
supports cannotbe larger than δ.
Expected cellfrequencies. The validity of a test depends on the
size of the available sample, becoming scarcely reliable when only
a small number of items are available. A typical lower bound for
theχ2testis5[11].Therefore,whenwereachacontrast-setwitha
numberofoccurrencessmallerthan5,wecansafelypruneit,since
anyfurtherspecializationcanonlyfurtherreducethenumberof
occurrences.
χ2bounds. BayandPazzanishowedthatitispossibletodefinean
upperboundonthe χ2statistic.Thiscanbeusedtoprunenodes,
when we know that the corresponding statistic will not exceed the
αcutoff.
Identical support. Specializations with the same support as the
parent might be not interesting and can be discarded. Theytarget
the same set of dataset entries as the parent and often represent
findings that are common knowledge (e.g. the support of {plat-
form_detail=DebianWheezy}willobviouslybethesameasthe
supportof{platform=Linux,platform_detail=DebianWheezy}:
the additionof{platform=Linux}providesnoinformation).
Fixed relations. Often a group has larger support for a given
contrast-set than any other group and specializing the contrast-set
with additional attribute-value pairs does not change the situation.
In thosecases,the node can be pruned.
platform
platform_version
 cpu_brand
 adapter_vendor_id
LIST OF modules
 cpu_microcode_version
 adapter_device_id
adapter_subsys_id
 adapter_driver_version
Figure 6:Detail ofthe dependencygraph
3.3 Domain-Specific Variations
Theimplementationofthealgorithmmusttakeintoaccountthe
largenumberofitemstodealwithinourreal-worldapplication.At
the time of writing, around 500000 crash reports per week are gen-
eratedforasingleFirefoxversion1.Moreover,eachreportcontains
a large number of attributes (more than 200) spanning different
possible values. This means that the number of possible candi-
dates explodes very rapidly as soon as contrast-sets are specialized
beyond level 1. Testing candidates for each couple of groups is
clearlyinfeasible.Therefore,inourimplementation,wetesteach
groupagainsttherestofthedataset,thatis,welookforfeatures
thatpresentanomaliesw.r.t.theaveragebehavioroverthe whole
dataset.Inaddition,forperformancereasons,wehaveimplemented
the toolusing Apache Spark [28].
Another specific feature of our application is the existence of
strong dependencies among groups of attributes. For example, the
presence of a given DLL might be directly linked to a particular
version of Windows; the CPU microcode version is directly linked
totheCPUvendor;etc.WemodifiedSTUCCOtotakeintoaccount
suchinformationbymeansofagraphofdependencies(seeFigure6
foradetailofthedependencygraph).Whenadependencyisfound,
thepercentageofoccurrenceisrecalculatedrestrictingthegroup
to the reports where the dependency holds true.For example, in a
groupwestudied,themodulełbcryptPrimitives.dllžwaspresent
in83.9%ofcrashreportsvs.33.91%overall,qualifyingforalikely
deviation.However,ifwetakeintoaccounttheoperatingsystem
(Windows10),thepercentageschangeto100%vs98.44%,andhence
this rulecould be ignored.
Oneofthefieldsofthecrashreportsisasmalltextareawhere
the user who experiences the crash can write a short comment.
Mostusersdonotprovideusefulinformationbutexpressonlytheir
frustration, which makes the comments field widely different from
usualbugreports.Nonetheless,inourmanualinspections,wehave
foundcomments to be sometimes useful, even if just as hints.
With the aim to extract some useful information from the com-
ments field, we employed a well known information retrieval tech-
nique,termfrequencyandinversedocumentfrequency(TF-IDF),
which highlights the words most frequently used in the comments
for a given crash group vs. other groups. This allows developers to
quicklyglanceifthereissomethingwrongwithaparticularsetting.
For example, in one particular instance, many users were mention-
ing łplayingž, and the crash turned out to be due to a resource
exhaustion dueto videogamesrunning inthe background.
1https://crash-stats.mozilla.com/search/?product=Firefox&version=51.0.1&date=>%
3D2017-02-14&date=<2017-02-21#crash-reports
722Automatically Analyzing GroupsofCrashes
for FindingCorrelations ESEC/FSE’17,September4–8, 2017, Paderborn,Germany
Table 4:Summary oftheresults ofthevalidation.
Type Numberofbugs
Very useful ś results that directly
helpedfixing the bug.19
Compatible ś results that were compat-
iblewiththeresolutionofthebug,but
were not useful for fixing the bug.19
Misleading ś results not compatible
withthe resolutionofthe bug.3
4 VALIDATION OFRESULTS
Inordertovalidatetheresults,wehaveselectedasetofbugreports
where we knew developers used our tool and we have verified
whether the tool
•helpedinthe resolutionofthe bug,
•gave compatible clues but didnot helpsolving the bug,
•gave somemisleadingclues.
The tool has been integrated in Socorro, but we do not know
whenthedevelopersuseitfortheirinvestigations.Somedevelopers,
whenusingthetool,copiedtheresultsofthetoolinthebugreport
they are working on. This allows us to select a set of real world
casesthatwecananalyze,giventhatdevelopershavefixedthem
already,sowecanevaluateiftheresultsofthetoolhavebeenuseful
for fixing the bug.
We considered about800 crash bug reports (approximately400
closed)generatedfromSeptember2016,whenourtoolhasbeenput
inproduction,toFebruary2017,mostlyfromMozilladevelopers.
For 90 of these reports (41 closed) we have definitive evidence
that our tool was used. We have manually analyzed this set of bug
reports and the code changes that are attached to them, finding 19
caseswherethetoolhasbeenreallyuseful;19caseswherethetool
generated compatible results, but did not help solving the bug; 3
caseswherethetoolhasproducedmisleadingresults.Theseresults
are summarizedinTable4.
In some of the caseswhere thetool hasbeen useful, we believe
thebugwouldnothavebeensolvedifnotwithverylargeinvestiga-
tiveeffort.Outofthethreecaseswherethetoolhasbeenmisleading,
we believe that, by improving the initial clustering algorithm, two
misleadingresults wouldhave beenavoided. These are analyzedin
moredetailinsection4.1.4and4.1.5.AsalreadysaidintheIntro-
duction,thequalityofclusteringcanstronglyaffecttheresultsof
the algorithm, polluting group statistics with unrelated reports, or
generating groups too small to provide meaningful statistics at all.
Whentheclusteringalgorithmfailsbygeneratinggroupsthat
aretoolarge(clusteringtogethercrashesthathavenorelationwith
eachother),itisharderforthecorrelationtooltofindinteresting
properties.Indeed,asmanycrasheswhichareactuallyreallydif-
ferent from each other get clustered together, it gets more difficult
to analyze them(both manually andautomatically).
Whentheclusteringalgorithmfailsbygeneratinggroupsthat
are too small (allocating reports for the same crash to differentgroups),thecorrelationtool,andmanualanalysis,ismoreproneto
find spuriouscorrelations.
The clusters’ dimensions can vary wildly between thousands of
reports(themostcrowdedclustercontainsaround20000crashes)
and a very small number of reports (even a single one). We only
apply the tool to the largest 200 clusters, as they are the most
important ones (after the 200th cluster, we only have clusters with
lessthan100reports).Thesetopclustersaccountforaround55%
of all reports, but there is a very long tail of clusters with very few
reports.
4.1 Deploymenton Socorro
We tested the tool on crash groups which we already analyzed
in the past, to assess its validity, and we put it in production for
new crash groups. In this section, we summarize a few interesting
results that we obtainedduringour analysis.
4.1.1 AMDCPUBug. Agroupofcrasheswasfoundtobecor-
related with a particular family of AMD CPUs. We later found that
the particular family of AMD CPUs that was involved in the crash
groupwasaffectedbyahardwarebug,anddeveloperswereableto
find aworkaround for it.
4.1.2 Antivirus-Related Crash. A group of crashes was found to
be correlated with a version of an addon of an antivirus suite. In
cases like this, the tool allows us to act quickly and simply block
theaddons(ormodules)thatcauseproblems,whilewetalkwith
the vendorsto solve the problem inthe longterm.
4.1.3 CrashWithoutAdBlock. Interestingly,thetoolalsogen-
erates results that are quite open to intepretation. For example,
therewasacrashgroupthatwasmorecommontouserswithout
ad-blocking addons. It was a crash happening often with a very
famousFlashgame.Webelievethecrashwascausedbysomead
network serving particular advertisement that would cause the
browser to crash. The crash disappeared quickly on its own, which
supports that hypothesis.
4.1.4 MisleadingResultCausedbyClusteringFailure(TooFew
Clusters). CrashesrelatedtotheJITcompilerforJavaScriptarea
clearexample of howcrashclusteringcan affecttheresultsof the
tool. The clustering algorithm employed by Socorro does not work
well for those kind of crashes, often lumping unrelated crashes
together.The correlationtool isonly abletotell thatthegroupof
crashesisrelatedto the JIT,but cannotsay muchmore.
4.1.5 Misleading Result Caused by Clustering Failure (Too Many
Clusters). There wasa crash, whichwaslaterdiagnosed to be due
to concurrency issues, which was happening in different functions
accordingtoCPUbrandorgraphicscard.Thiscausedtheclustering
algorithm used by Socorro to generate a new cluster for each CPU
brand / graphics card, making each cluster obviously correlated to
those.Clearly,the correlations were spurious.
4.1.6 Analyzing Crash Reports Before/After a Change. The al-
gorithmisreallyusefulwhenanalyzingacrashgroupgenerated
bySocorro,butcanbeusedforgenericgroupsaswell.Forexam-
ple, to analyze the differences in the properties of crash reports
723ESEC/FSE’17,September4–8, 2017, Paderborn,Germany M. Castelluccio,C.Sansone,L. Verdoliva, andG.Poggi
before/after a change, e.g. to assess the effectiveness of the change
andas anothermeans to ensure that itdidnot cause regressions.
We employed the tool to analyze the differences between the
crashesbefore/afterachangethatrelaxedtheblocklistforgraphics
acceleration on NVIDIA graphics cards. We found that the change
improved the stability with a particular version of the NVIDIA dri-
vers(onewherehardwareaccelerationwaspreviouslyblockedand
unblockedbythechange),probablybecausehardwareacceleration
isamore common andthoroughlytestedcode path.
4.2 Feedbackfrom Developers
Developers and people triaging crash bugs generally expressed
favourable opinions about thetool. We collected suggestionsfrom
them since the deployment to Socorro. Most of the suggestions
were requests of addition of new possible fields to the analysis
(sometimes meta-information dynamically generated from already
existingfields).Someofthesuggestionswereinsteadrelatedtothe
way results are shown, which is actually a pretty important aspect.
Indeed, we empiricaly noticed that, if the information presented
to the user is too crowded (e.g. too many useless attributes, too
much information), the user is more likely to complain or overlook
something.Intheremainderofthissection,wepresentsomeofthe
more specific suggestionsthat we receivedfrom developers.
4.2.1 Employing theCorrelation ResultsThemselves to Improve
Clustering. The correlation analysis itself might be useful to im-
prove the clustering algorithm. For example, two groups which
present similar correlations might be clustered together. Groups
which do not have any interesting correlation, might be candidates
to be split.
We observed that this operation was done manually by devel-
opers in the results validation. Concerning two bugs where the
correlations were very similar, the developers noticed that the two
groupswere actually a single one (and closed a bugas a duplicate
ofthe other).
4.2.2 ExtractInformationfromUnstructuredCrashReportFields.
The algorithm we presented only works with discrete fields, but
crash reports often contain unstructured information too. The user
comment is a clear example. The TF-IDF solution works for simple
casesanditcouldbegreatlyimproved.Forexample,ifseveralusers
mention the same thing in different ways, TF-IDF will not notice it.
Usingamorepowerfultextminingalgorithmmightimprovethe
results, although it is still not clear to us how much information is
actually contained in the users’ comments. We noticed some cases
where it turnedout to be useful, butdevolvingtime and resources
for this mightnot be toovaluable.
4.2.3 Driving Automated Tests Configuration. At Mozilla, we
developed a tool which automatically tries to reproduce crashes
with different settings and under different configurations, called
BugHunter[ 20].Thecorrelationresultscouldhelpindrivingthe
tool to directly test under a configuration that is more likely to
reproduce the crash, both saving running time (e.g. if a crash is
only happening with a specific graphics card vendor and a specific
driver,there isnopoint intryingto reproduce it with a graphics
cardfrom adifferentvendor) andmakingreproducibility easier.4.2.4 Predicting Volume of a Crash in a Release Channel from
Pre-releaseChannels. Bylinkingthedatageneratedbythecorre-
lation tool with data about the user population distribution, we
can estimate how a crash that is affecting a pre-release version
will affect the release version. The reader can refer to the work
by Khomh et al. [ 14] for an explanation of the Firefox pipelined
releasemodel.Thishasbeenattemptedinthepastusingmachine
learning techniques: in Kim et al. [ 10] it was used to predict which
crashstackismoreprobabletobecomeałtopcrashžandshouldbe
fixed first. For example, Firefox Beta users are predominantly from
theUnitedStates.Thepercentageofthoseusersisfairlylowerin
FirefoxRelease.Thismeansthatcrashesthatareeasilyreproducible
ona website that isnot in the English language,are very likely to
go unnoticed during the Beta cycle and explode when Firefox is
released. If we had a way to re-rank the crashes considering the
attributesto whomtheyare correlatedandtheincidenceofthose
attributesindifferentchannels,thenthosecrasheswouldlesslikely
gounnoticed.
5 THREATS TO VALIDITY
Internalvaliditythreats concernfactorsthatmayaffectadependent
variableandwerenotconsideredinthestudy.Weevaluatedourtool
on41closedbugs,whichmightnotbearepresentativedataset.We
have chosen to evaluate the results on the fixed bugs as we needed
to check if the fix was compatible with the findings of the tool.
External validity threats are concerned with the generalizability
of our results. In this paper, we only evaluated the results of the
tool applied to Mozilla Firefox crashes, because its crash data, bug
reports andsourcecode are publiclyavailable.
6 RELATED WORK
Bird et al. [ 5] studied the effect of extrinsic factors on software
reliability.Inourexperiencewefoundevidencethatcorroborates
their findings: there are several crashes that are due to external
softwarebadlyinteractingwithFirefox.Inourcasethoughweoften
noticedsecurity applicationsbeing the root cause of the crashes.
6.1 AutomaticCrash Reporting Systems
Several past studies have shown how a crash reporting system,
such as Socorro, can be very valuable for discovering and fixing
crashes. For example, Glerum et al. [ 12] presented their experience
with WER (Windows Error Reporting). Ahmed et al. [ 1] studied
the Mozilla crash reporting system. One of the problems presented
in[1]istheoverwhelmingamountofdatathatismadeavailable
through a crash reporting system. Our work tries to solve this
problem by using data mining techniques to handle the complexity
ofthe data andprovideawayto automaticallyunderstandit.
6.2 Crash Clustering
Thecrashclusteringproblemhasbeenstudiedextensivelyinthe
literatureandiscloselyrelatedtothetechniquepresentedinourpa-
per.Indeed,agoodclusteringtechniqueisneededinordertoavoid
false positives or false negatives. Lohman et al. [ 18] and Modani et
al.[19] adaptedstop-wordremoval tocall stacks, removingrecur-
sive calls, and using similarity measures like edit distance, longest
common subsequence, and prefix matching. Bartz et al. [ 2] used
724Automatically Analyzing GroupsofCrashes
for FindingCorrelations ESEC/FSE’17,September4–8, 2017, Paderborn,Germany
editdistance,proposingseventypesofeditsassignedwithdifferent
weights. Dhaliwal et al. [ 9] proposed a two-level grouping of crash
reports, using Levenshtein distance [ 25] to evaluate the similar-
ity between stack traces. Dang et al. [ 8] presented ReBucket, an
algorithm for clustering crashes based on a custom method (called
PDM, Position Dependent Model) that uses the position of a func-
tion in the stack trace and the offset between matched functions
for calculating the similarity between stack traces. Lerch et al. [ 17]
proposedusingawellknowninformationretrievaltechnique,term
frequency and inverse document frequency, to rate stack traces.
Campbell et al. [ 6] presented an overview of several clustering
algorithms, including the one presented by Lerch et al., evaluating
their results in the same setting (Ubuntu Apport crashes). They
foundtraditionalinformationretrievaltechniquestooutperform
techniquesspecificallydesignedforcrashclustering.The proposed
algorithmisstronglyrelatedtocrashclustering,asitoperateson
clustersofcrashes.Thus,itsperformanceisdirectlyaffectedbythe
qualityofthe clustering algorithm employed.
6.3 VisualizationofCrash Reports
Anotherrelatedareaofresearchisthevisualizationofcrashreports
toaidintheunderstandingbydevelopers.Forexample,Kimetal.
[15] proposedanapproachbased onanaggregated graphview of
multiplecrashes.Theyalsopresentedawaytousethecrashgraphs
for clustering. Chan et al. [ 7] presented three types of graphs to
analyze field testing results under three different perspectives. The
above approaches could be combined with our proposed approach
to improve understanding ofgroup ofcrash reports.
6.4 Triaging ofCrash Reports
Kimetal.[ 10]presentedamachinelearningtechniquetopredict
which crash stacks are more probable to become łtop crashersž
and should be fixed first. Khomh et al. [ 13] proposed an entropy
evaluationapproach,takingintoaccountvolumeofcrashgroups
anddistribution among users, to rank thecrash clustersby impor-
tance. The above approaches focused on prioritizing the groups
of crash reports for bug fixing. Our approach instead identifies
generic properties of the groups, which can be later used by devel-
opers and managers, not only for prioritization, but also to directly
understandpossible causes.
7 CONCLUSION
Crashes are one of the main pain points for users of a software.
Fixing them promptly can improve the users’ perception of the
quality of a software. We found that analyzing crash reports in
an automated manner can help developers in fixing crashes, by
removingmanualanalysisburdenfromdevelopers,orbyfinding
propertiesthatwouldhavebeenreallydifficulttofindwithmanual
analysis,orcangivecluesinthecharacterizationofcrashes.Soft-
ware organizations can use these data mining techniques to speed
upandsimplifytheresolutionofcrashesandtoreducetheamount
ofmanual tediouswork for developers.
7.1 FutureWork
Weidentifiedtwointerestingdirectionsforfuturework.First,as
discussed in the Validation section (section 4), with examples insection4.1.4and4.1.5,theresultsofthecrashclusteringcangreatly
affect the results of our tool. Thus, improvements to the clustering
algorithm used by Socorro, other than being useful by themselves,
wouldbenefit ourresults as well.Second, itcould beuseful to have
adashboardtosimplifyfindingreproduciblecrashes.AtMozilla,
we are often helped by volunteers in reproducing crashes that
are specific to some configuration that we do not have readily
available.Thecorrelationresultsmightbeusefultocreateaway
for volunteers to automatically find the crashes that they might be
abletoreproduce,byshowingthemthecrashgroupsthatarerelated
to their hardware or software (e.g. installed addons, antivirus, etc.)
configuration.
ACKNOWLEDGMENTS
TheauthorswouldliketothanktheSocorrodevelopersfortheir
helpinthedeploymentofthetoolintheSocorrocrashreporting
system. The authors would also like tothank the Mozilla develop-
ers that have used the tool and gave us important feedback and
comments.
This research was carried out within the Fault-Injection-Driven
Approach project in the frame of Programme STAR, financially
supportedby University FedericoII ofNaples and Compagnia di
SanPaolofoundation.
REFERENCES
[1]I. Ahmed, N. Mohan, and C. Jensen. 2014. The impact of automatic crash re-
portsonbugtriaginganddevelopmentinMozilla.In Proc.oftheInternational
SymposiumonOpenCollaboration . 1:1ś1:8.
[2]K.Bartz,J.W.Stokes,J.C.Platt,R.Kivett,D.Grant,S.Calinoiu,andG.Loihle.2008.
Findingsimilarfailuresusingcallstacksimilarity.In Proc.oftheThirdConference
on Tackling Computer Systems Problems with Machine Learning Techniques . 1ś1.
[3]S.D.BayandM.J.Pazzani.1999. Detectingchangeincategoricaldata:mining
contrast sets. In Proc. of the Fifth ACM SIGKDD International Conference on
KnowledgeDiscoveryand Data Mining . 302ś306.
[4]S.D.BayandM.J.Pazzani.2001. Detectinggroupdifferences:miningcontrast
sets.DataMiningand KnowledgeDiscovery 5,3 (July2001),213ś246.
[5]C. Bird, V.P. Ranganath, T. Zimmermann, N. Nagappan, and A. Zeller. 2014.
Extrinsic Influence Factors in Software Reliability: A Study of 200,000 Windows
Machines. In Companion Proceedings of the 36th International Conference on
SoftwareEngineering . 205ś214.
[6]J.C. Campbell, E.A. Santos, and A. Hindle. 2016. The unreasonable effectiveness
of traditional information retrieval in crash report deduplication. In Proc. of the
13thInternationalConference onMiningSoftwareRepositories . 269ś280.
[7]B.Chan,Y.Zou,A.E.Hassan,andA.Sinha.2010. VisualizingtheResultsofField
Testing.In IEEE InternationalConference onProgramComprehension . 114ś123.
[8]Y.Dang,R.Wu,H.Zhang,D.Zhang,andP.Nobel.2012. ReBucket:amethodfor
clusteringduplicatecrashreportsbasedoncallstacksimilarity.In Proc.ofthe
34thInternationalConference onSoftwareEngineering . 1084ś1093.
[9]T.Dhaliwal,F.Khomh,andY.Zou.2011. Classifyingfieldcrashreportsforfixing
bugs:acasestudyofMozillaFirefox.In IEEEInternationalConferenceonSoftware
Maintenance (ICSM) . 333ś342.
[10]K. Dongsun, W. Xinming, K. Sunghun, A. Zeller, S.C. Cheung, and S. Park. 2011.
Which crashes should I fix first?: Predicting top crashes at an early stage to
prioritize pebugging efforts. IEEE Transactions on Software Engineering 37, 3
(May2011),430ś447.
[11] B.S. Everitt. 1992. The AnalysisofContingencyTables . Chapman& Hall/CRC.
[12]K. Glerum, K. Kinshumann, S. Greenberg, G. Aul, V. Orgovan, G. Nichols, D.
Grant, G. Loihle, and G. Hunt. 2009. Debugging in the (very) large: ten years of
implementationandexperience.In Proc.oftheACMSIGOPS22NdSymposiumon
OperatingSystemsPrinciples . 103ś116.
[13]F.Khomh,B.Chan,Y.Zou,andA.E.Hassan. Anentropyevaluationapproachfor
triagingfieldcrashes:acasestudyofMozillaFirefox.In 18thWorkingConference
onReverse Engineering . 261ś270.
[14]F.Khomh, T.Dhaliwal,Y.Zou,andB.Adams.2012. Do fasterreleasesimprove
softwarequality?AnempiricalcasestudyofMozillaFirefox.In IEEEWorking
Conference onMiningSoftwareRepositories(MSR) . 179ś188.
[15] S. Kim,T. Zimmermann, and N.Nagappan. 2011. Crash graphs: Anaggregated
viewofmultiplecrashestoimprovecrashtriage.IEEEComputeSociety,486ś493.
725ESEC/FSE’17,September4–8, 2017, Paderborn,Germany M. Castelluccio,C.Sansone,L. Verdoliva, andG.Poggi
[16]P. Kralj, N. Lavrač, D. Gamberger, and A. Krstači `c. 2007. Contrast Set Mining
forDistinguishingbetweenSimilarDiseases.In Proc.ofthe11thconferenceon
Artificial IntelligenceinMedicine . 109ś118.
[17]J.LerchandM.Mezini.2013. Findingduplicatesofyouryetunwrittenbugreport.
InProc. of European Conference on Software Maintenance and Reengineering . 69ś
78.
[18]G.Lohman,J.Champlin,andP.Sohn.2005. QuicklyFindingKnownSoftware
Problems via Automated Symptom Matching. In Proc. of the Second International
Conference onAutomaticComputing . 101ś110.
[19]N. Modani, R. Gupta, G.M. Lohman, T. Syeda-Mahmood, and L. Mignet. 2007.
Automatically identifying known software problems. In Proc. of the 23rd Interna-
tional Conference onData Engineering Workshops . 433ś441.
[20]Mozilla. 2017. BugHunter. https://wiki.mozilla.org/Auto-tools/Projects/
BugHunter. (2017). Online;Accessed February21st,2017.
[21]Mozilla.2017.SocorroCrashReportSchema.https://github.com/mozilla/socorro/
blob/master/socorro/schemas/crash_report.json.(2017). Online;AccessedFebru-
ary21st,2017.[22]Mozilla. 2017. Socorro Crash Report Schema. https://developer.mozilla.org/
en-US/docs/Mozilla/Tech/XPCOM.(2017). Online;AccessedFebruary21st,2017.
[23]Mozilla.2017. Socorroserver. https://crash-stats.mozilla.com/.(2017). Online;
Accessed February21st,2017.
[24]P.K.Novak,N.Lavrač,andG.I.Webb.2009. Superviseddescriptiverulediscovery:
aunifyingsurveyofcontrastset,emergingpatternandsubgroupmining. Journal
ofMachineLearning Research 10(2009), 377ś403.
[25]D. Sankoff and J.B. Kruskal. 1983. Time Warps, String Edits, and Macromolecules:
The Theoryand Practice ofSequenceComparison . 1ś44pages.
[26]J.P. Shaffre. 1995. Multiple Hypothesis Testing. Annual Review of Psychology 46,
1 (1995), 561ś584.
[27]X. Yu, S. Han, D. Zhang, and T. Xie. 2014. Comprehending performance from
real-worldexecutiontraces:adevice-drivercase.In Proc.ofthe19thInternational
ConferenceonArchitecturalSupportforProgrammingLanguagesandOperating
Systems. 193ś206.
[28]M. Zaharia, M. Chowdhury, M.J. Franklin, S. Shenker, and I. Stoica. 2010. Spark:
clustercomputing with workingsets. In Proc.ofthe2NdUSENIX Conferenceon
HotTopics inCloudComputing . 10ś10.
726