Exposing Library API Misuses via Mutation Analysis
Ming Wen, Yepang Liuyk, Rongxin Wu, Xuan Xiez, Shing-Chi Cheungand Zhendong Sux{
Department of Computer Science and Engineering
The Hong Kong University of Science and Technology, Hong Kong, China
Email:fmwenaa, wurongxin, scc g@cse.ust.hk
yShenzhen Key Laboratory of Computational Intelligence
Southern University of Science and Technology, Shenzhen, China. Email: liuyp1@sustc.edu.cn
zSun Yat-sen University, China. Email: xiex27@mail2.sysu.edu.cn
xETH Zurich, Switzerland. Email: zhendong.su@inf.ethz.ch{UC Davis, USA
Abstract ‚ÄîMisuses of library APIs are pervasive and often
lead to software crashes and vulnerability issues. Various static
analysis tools have been proposed to detect library API misuses.
They often involve mining frequent patterns from a large number
of correct API usage examples, which can be hard to obtain
in practice. They also suffer from low precision due to an
over-simpliÔ¨Åed assumption that a deviation from frequent usage
patterns indicates a misuse.
We make two observations on the discovery of API misuse
patterns. First, API misuses can be represented as mutants of
the corresponding correct usages. Second, whether a mutant will
introduce a misuse can be validated via executing it against
a test suite and analyzing the execution information. Based
on these observations, we propose M UTAPI, the Ô¨Årst approach
to discovering API misuse patterns via mutation analysis. To
effectively mimic API misuses based on correct usages, we Ô¨Årst
design eight effective mutation operators inspired by the common
characteristics of API misuses. M UTAPIgenerates mutants by
applying these mutation operators on a set of client projects and
collects mutant-killing tests as well as the associated stack traces.
Misuse patterns are discovered from the killed mutants that are
prioritized according to their likelihood of causing API misuses
based on the collected information. We applied M UTAPIon 16
client projects with respect to 73 popular Java APIs. The results
show that M UTAPIis able to discover substantial API misuse
patterns with a high precision of 0:78. It also achieves a recall
of0:49on the M UBENCH benchmark, which outperforms the
state-of-the-art techniques.
Index Terms ‚ÄîMutation Analysis, Library API Misuses
I. I NTRODUCTION
The use of third-party libraries in Java projects is common.
According to a recent study [1], a Java project directly depends
on 14 different libraries on average. The Maven repository [2]
has indexed over 8.77 millions third-party libraries. However,
correct usages of Application Programming Interfaces (APIs)
provided by many third-party libraries are loosely documented
or left unrevised after API updates [3]‚Äì[5]. As a result, API
misuses are pervasive and account for a major cause of
software bugs (e.g., performance issues, software crashes and
vulnerability issues [6]‚Äì[11]). To detect API misuses, various
static analysis tools have been proposed [12]‚Äì[20]. These tools
commonly mine API usage patterns from software codebases.
Those frequent patterns are deemed as correct API usages,
whereas deviations from such patterns are regarded as misuses.
kYepang Liu is the corresponding authorA recent study reported that existing static-analysis based
API misuse detectors suffer from low recall and precision
in practical settings [6]. The study also made suggestions to
address the two limitations. First, to improve recall, existing
detectors need to mine frequent patterns from more correct
API usage examples . However, it is difÔ¨Åcult to obtain sufÔ¨Åcient
correct API usage examples in practice, especially for newly
released libraries. Second, to improve precision, the detectors
need to go beyond the oversimpliÔ¨Åed assumption that a devia-
tion from frequent usage patterns is a misuse . An uncommon
usage of an API is not necessarily an incorrect usage.
In this study, we propose to approach the problem of API
misuse patterns‚Äô discovery from a new perspective through
mutation analysis [21]. Mutation analysis has been widely
used in software debugging and testing [21]. It mainly contains
two steps. First, it creates substantial mutants by making small
modiÔ¨Åcations to a program with a set of well-deÔ¨Åned mutation
operators that mimic different kinds of programming mistakes.
Second, it runs a given test suite on the mutants and collects
execution information for various quality analyses [22]‚Äì[26].
Our solution is inspired by two observations. First, various
misuses of an API can be viewed as the mutants of this API‚Äôs
correct usages. Therefore, API misuses can be created via
applying speciÔ¨Åcally-designed mutation operators on correct
API usages. The design of these mutation operators can be
guided by the characteristics of common API misuse patterns,
which have been well investigated by existing studies [4], [6].
For instance, one misuse pattern is missing exception handling
[6]. Many APIs could throw exceptions and the correct usages
of these APIs require appropriate exception handling. Given
one correct usage of such APIs, we can actively violate the
correct usage (e.g., by deleting the exception handlers ) to
create an API misuse. Other patterns of API misuses (e.g.,
missing method call [6]) can be similarly created via applying
certain mutation operators (e.g., deleting method call ). In this
way, we can obtain substantial mutants based on an API‚Äôs
correct usages. Unlike existing work [12]‚Äì[20], our solution
does not require pattern mining from a large number of correct
API usages. Instead, it actively creates substantial mutants
mimicking API misuses of different patterns. However, de-
ciding if a mutant such created introduces an API misuse is
challenging since the manifestation patterns of different API
8662019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ¬©2019 IEEE
DOI 10.1109/ICSE.2019.00093
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. misuses are divergent. Our intuition to address this challenge
is that we can validate whether a mutant introduces an API
misuse via executing it against the correct usages‚Äô test suites
and analyzing the execution information. This intuition is
inspired by the observation that substantial ( 42:8%) tests of
well-maintained projects would trigger library usages during
execution (Section II-C). Therefore, we conjecture that library
API misuses can be exposed and validated via running the
test suites of client projects (conÔ¨Årmed in Section V-A). In
this way, our solution does not make the assumption that a
deviation from frequent API usage patterns is a misuse.
In this paper, we propose M UTAPI, an automatic approach
that leverages MUTation analysis to discover APImisuse
patterns. To effectively discover API misuse patterns, M U-
TAPIaddresses the following three challenges.
First, discovering API misuse patterns requires M UTAPIto
generate mutants that violate existing correct usages, and thus
how to effectively generate mutants that mimic API misuses is
the key. Conventional mutation operators such as those deÔ¨Åned
by P IT[27] are less likely to achieve such a goal (Section
V-C). To address the challenge, we Ô¨Årst investigate how to
model correct API usages and then break the modelled usages
systematically. Inspired by a recent study [4], M UTAPImodels
correct API usages as structured call sequences based on a
predeÔ¨Åned grammar. We then designed eight types of novel
mutation operators with the aim to actively violate such mod-
eled usages in a systematic way (Section III-A). With these
mutation operators, M UTAPIgenerates substantial mutants by
applying them on certain client projects that use a target API.
MUTAPIthen runs those mutants against the test suites of the
client projects and collects killing relations , which includes the
killed mutants and the corresponding killing tests . A mutant is
killed if its test output differs from that of the original program.
Second, how to validate whether a mutant indeed introduces
an API misuse is another challenge. One possible way is to
check whether a mutant has been killed by the test suite.
However, a mutant can be killed due to multiple reasons (e.g.,
a logic bug unrelated to any API misuses). How to precisely
identify those killing relations arising from API misuses is
a key challenging. M UTAPIaddresses this challenging via
analyzing the failing stack traces of the killing tests (denoted as
killing stack trace ). SpeciÔ¨Åcally, it leverages the killing stack
traces to prioritize killing relations based on the following
observations. First, given a killing stack trace, the failure‚Äôs
root cause appears closer to the failure point [28]. Therefore,
if the top frames of a killing stack trace are library functions,
it is more likely to be caused by API misuses (i.e., the root
cause resides in the API calls). Second, killing stack traces of
a target API should be speciÔ¨Åc to this API. If a killing stack
trace is also observed in the mutation analysis of other APIs, it
is less likely to be caused by the target API‚Äôs misuses. Third,
killing stack traces of a target API should not be speciÔ¨Åc to
a certain usage. If a killing stack trace is only observed in
the mutation analysis of a speciÔ¨Åc project, it is more likely
to be caused by the bugs speciÔ¨Åc to this project instead of
a general misuse of the target API. M UTAPIleverages thesethree observations to prioritize observed killing realtions, and
assumes those top ranked ones to be caused by the misuses
of the target API.
Third, how to effectively distill API misuse patterns after
identifying a set of killing relations arising from API misuses
is also a challenge. To address this challenge, M UTAPIdistills
API misuses from substantial killed mutants of the identiÔ¨Åed
killing relations. SpeciÔ¨Åcally, it Ô¨Årst models an API misuse as
a pair of a violation type and an API usage element , following
the Ô¨Åndings of recent studies [4], [6]. It then selects those most
frequently observed violation pairs as API misuse patterns.
To evaluate M UTAPI, we selected 73 popular Java APIs
collected by recent studies [4], [6], and 16 client projects
collected from popular repositories on GitHub. The evaluation
results show that M UTAPIis able to achieve a high precision
of0:78in discovering real misuse patterns of popular APIs.
It also achieves a higher recall on the benchmark dataset
MUBENCH [6] compared with the state-of-the-art techniques.
In summary, this paper makes the following contributions.
Originality: To the best of our knowledge, this is the
Ô¨Årst study that applies mutation analysis to discover API
misuse patterns, and empirical evidences have shown that it is
effective in exposing and discovering API misuse patterns.
Implementation: We implemented our approach M UTAPI
as a tool that can detect API misuse patterns of Java libraries.
It employs a set of new mutation operators, which have shown
to be effective in dicovering different API misuse patterns.
Evaluation: Our evaluation results show that M UTAPIcan
discover real misuse patterns of popular Java APIs with high
precisions. It also detects more misuse instances on the bench-
mark dataset M UBENCH compared with existing approaches.
II. R ELATED WORK AND PRELIMINARIES
In this section, we Ô¨Årst introduce related work on mutation
analysis and API misuse detection. We then introduce the
motivation of this study together with its challenges.
A. Mutation Analysis
Given a program pand a set of mutation operators O,
the key idea of mutation analysis is to generate substantial
mutants,M, in which each mutant mis a variant of p. The
generated mutants are then executed against p‚Äôs test suiteT.
A mutant miskilled if there exists a test t2 T whose
execution on pand that on mresult in different observable
Ô¨Ånal states. Mutation analysis has many applications (e.g.,
[22], [24]‚Äì[26], [29]‚Äì[32]), such as evaluating the quality of a
test suite (e.g., [22]), test suite reduction (e.g., [30]), improving
fault localization (e.g., [23], [26]), security analysis (e.g., [24],
[25]), program repair (e.g., [31], [32]) and so on. For instance,
to evaluate the quality of a test suite T[22], mutation score ,
the proportion of killed mutants in M, is computed. The
higher the mutation score, the more likely that Tcan detect
real bugs, and thus the higher quality of the test suite. To
the best of our knowledge, we are the Ô¨Årst to apply mutation
analysis in discovering API misuse patterns. In this study, we
usekto denote a killing relation that a mutant mis killed by
a test t. By executing a test suite Ton all mutantsM, we
obtain a set of killing relations K.
867
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. TABLE I: The Ratio of Test Classes Triggering Target APIs
Project Apache BCEL Apache Lang Apache Text HttpClient Lucene-Core
Ratio 0.324 0.483 0.328 0.431 0.573
B. Library API Misuse Detection
Uses of library APIs are often subject to constraints such
as call orders and call conditions [6]. Unfortunately, many of
such constraints are insufÔ¨Åciently speciÔ¨Åed by APIs‚Äô docu-
mentations [3]. As a result, developers also refer to informal
references, such as Stack OverÔ¨Çow, to understand the usages of
an API [33]. However, as revealed by a recent study [4], code
snippets on Stack OverÔ¨Çow can be unreliable, even for those
accepted and upvoted answers. Violations of the constraints
that should be satisÔ¨Åed may induce software bugs [6]‚Äì[11]
(e.g., crashes and security issues). Therefore, it motivates a
wealth of researches on mining and detecting API misuses
automatically [12]‚Äì[20]. These existing approaches commonly
mine frequent API usage patterns and assume an outlier that
deviates from frequent patterns as an API misuse. They differ
from each other mainly in how to encode API usages and
model frequency. For example, P R-MINER encodes API us-
ages as a set of function calls invoked within the same method,
and then leverages frequent itemset mining to identify patterns
with a minimum support of 15 usages [12]. J ADET builds a
directed graph based on method call orders and call receivers
[14]. In the graph model, a node represents a method call
and an edge represents a control Ô¨Çow relation. G ROUP MINER
creates a graph-based object usage representation to model
API usages for each method. It then leverages subgraph mining
techniques to detect frequent usage patterns with a minimum
support of 6 [16]. D MMC detects missing calls in a set of
method invocations triggered by an object [7]. T IKANGA is
built on top of J ADET [20]. It extends the properties of call
orders to general Computation Tree Logic Formulae on object
usages. It then leverages model checking to identify those
formulae with a minimum support of 20 in a given codebase.
C. Observation and Motivation
As mentioned earlier, the philosophy of mutation analysis
is to mimic program bugs via applying mutation operators. In
this study, we aim to adopt such a philosophy to detect API
misuse patterns, which are a common type of program bugs.
The idea is inspired by the following two observations.
First, various misuses of an API can be represented
as mutants of its correct usages . Let us illustrate this
using the code snippet in Figure 1, which is from project
Apache Commons Lang [34]. It contains a correct usage of
API java.lang.Float.parseFloat . Based on this usage,
we can generate multiple mutants. Two of them are given
as examples in Figure 1, where the second one Mutant#2
repesents an API misuse. It is stated in the API‚Äôs signature that
NumberFormatException can be thrown. Mutant#2 is ob-
tained by deleting the try-catch statement that encloses the
API call. It violates the correct usage of Float.parseFloat
and follows a well-known API misuse pattern, i.e., missing
exception handling [4], [6].
Second, a program‚Äôs test suite can be leveraged to validate
whether a generated mutant of the program indeed misuses
publicstaticfloattoFloat(Stringstr, floatdefaultValue) {if(str== null) {returndefaultValue;}try{returnFloat.parseFloat(str);//returndefaultValue;      Mutant#1 Replace ReturnExpression} catch(finalNumberFormatExceptionnfe) {returndefaultValue;}   //  try{                        Mutant#2Delete Try {} Catch       returnFloat.parseFloat(str);                //  } catch(finalNumberFormatExceptionnfe) {//      returndefaultValue;//  }        } Fig. 1: Two Mutants of API Usage of Float.parseFloat()
100100.5101101.5102
Apache BCEL Apache Lang Apache Text HttpClient Lucene‚àíCoreThe Number of Target API Calls
Fig. 2: The Number of Target API Calls Triggered Per Test Class
an API . To study the feasibility of leveraging this observation,
we randomly selected Ô¨Åve popular projects on GitHub and
analyzed whether the execution of the associated test suites
can trigger popular API calls. SpeciÔ¨Åcally, we selected the
100 popular APIs collected by an existing study [4]. Table
I shows the results. On average, the execution of 42:8%
of the test classes (i.e., ranging from 32:4%to57:3%for
different projects) triggers at least one of these APIs. For
each test class, we further investigated the number of in-
vocations of these APIs. Figure 2 shows the results, which
indicate that substantial library APIs are triggered by test
executions. Furthermore, 60:0%of these APIs can throw ex-
ceptions, over 85:0%of which are unchecked exceptions .
The Ô¨Åndings suggest that if we violate the correct usages
of these APIs via applying mutation operators, there is a
high probability that the mutants representing API misuses
can be detected by the associated test suite in the form of
runtime exceptions. For instance, Mutant#2 can be killed
by the test NumberUtilsTest.testToFloatStringF() via
throwing NumberFormatException . The corresponding fail-
ing stack trace is shown in Figure 3b.
Based on the above observations, we are motivated in this
study to leverage mutation analysis on multiple open-source
projects in the wild to discover API misuse patterns.
D. Challenges
Applying mutation analysis to discover API misuse patterns
needs to address three challenges. First, how to design muta-
tion operators that can effectively mimic API misuses remains
unknown. Second, differentiating mutants that induce API
misuses from those that do not is non-trivial. As mentioned
before, we can leverage test information to identify whether
a mutant introduces an API misuse. However, tests might fail
due to multiple reasons. The example of Mutant#1 shown in
Figure 1, which is not an API misuse, can also be killed by
the test testToFloatStringF() with the stack trace shown
in Figure 3a. Therefore, we cannot simply conclude that a
mutant introduces an API misuse by checking whether it is
killed by tests designed for the original program. Conceptually,
868
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. java.lang.AssertionError: toFloat(String,int) 1 failedat org.junit.Assert.fail(Assert.java:88)at org.junit.Assert.assertTrue(Assert.java:41)at org.apache.commons.lang3.math.NumberUtilsTest.testToFloatStringF(NumberUtilsTest.java:119)at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:564)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)12345678910(a) Killing Stack Trace #1 of Mutant #1
java.lang.NumberFormatException: For input string: "a"at jdk.internal.math.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2054)at jdk.internal.math.FloatingDecimal.parseFloat(FloatingDecimal.java:122)at java.lang.Float.parseFloat(Float.java:455)at org.apache.commons.lang3.math.NumberUtils.toFloat(NumberUtils.java:81)at org.apache.commons.lang3.math.NumberUtilsTest.testToFloatStringF(NumberUtilsTest.java:120)at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:564)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)12345678910 (b) Killing Stack Trace #2 of Mutant #2
Fig. 3: Two Examples of Killing Stack Traces from Mutants Made on API Float.parseFloat
TABLE II: Notations Used in This Study
Notation Description
P;p A set of client projects Pand one client project p
A;a A set of target library APIs Aand APIa
M;m A set of mutantsMand one single mutant m
T;t A test suiteTand one test case t
K;k A set of killing relations Kand one killing relation k
S;s A set of stack traces Sand one stack trace s
atarget The target API for mutation testing
khp;a;m;t iMutantmmade on API aof projectpkilled byt
sk The failing stack traces observed in killing relation k
killing relations can arise from three types of causes. The Ô¨Årst
type resides in the library (Type 1), which indicates that the
test fails due to the buggy implementation of the API. The
other two types of causes reside in the client project, which
indicates that the client program is ‚Äúbuggy‚Äù after applying
mutation operators. Among them, one type of ‚Äúbug‚Äù is caused
by misuses of the API (Type 2) while the other is not (Type 3).
Useful API misuse patterns can only be mined from Type 2
‚Äúbugs‚Äù (e.g., Mutant#2 in Figure 1), and patterns mined from
Type 3 ‚Äúbugs‚Äù (e.g., Mutant#1 in Figure 1) will result in false
positives. Distinguishing the root cause for a killing relation
is challenging. Third, even if we can successfully identify a
set of mutants that introduce API misuses, generalizing these
mutants to API misuse patterns is non-trivial.
III. M UTAPIAPPROACH
This section presents our approach, the overview of which
is shown in Figure 4. The input of M UTAPIis a set of client
projects (i.e., including source code and the associated test
suite) and a set of target APIs. The analysis process consists
of three main steps. First, M UTAPIgenerates mutants by
applying a predeÔ¨Åned set of mutation operators on the target
APIs‚Äô usages in the client projects and then runs the tests.
Second, it collects the killing relations and prioritizes these
relations with respect to each target API. Third, it selects the
top ranked killing relations and mines API misuse patterns
from the associated killed mutants. The output of M UTAPIis
a list of misuses of the target APIs. The following subsections
introduce the details of each step. To ease presentation, Table
II summarizes the notations used in this study.
A. Conducting Mutation Testing
A set of mutation operators, which can systematically vio-
late correct API usages, is desired in order to apply mutation
analysis to discover API misuse patterns. Conventional muta-
tion operators (e.g., those deÔ¨Åned in P IT[27]) are less likely to
achieve the goal. For instance, one major type of API misuses
ismissing control statements [4], [6], e.g., missing exception
handling orif check statements. Conventional operators focus
on mutating conditional ormathmatics operators [27], and areTABLE III: Grammar of Structured API Call Sequences
sequence ::=jcall ;sequencejif(checker )fg;sequence
jstructuref;sequence ;g;sequence
call ::=API (v1;::;v i;::;v n)jvrev=API (v1;::;v i;::;v n)
structure ::=if(cond )jelsejloopjtryjcatch (ve)jfinally
cond ::=condition expression jcalljtruejfalse
checker ::=cond involves receiver vrcvor parameter vi
API ::=method name
v::=variablejexceptionj
not designed to manipulate such control statements. Therefore,
they cannot effectively mimic such misuse patterns.
Motivated by a recent study [4], M UTAPImodels correct
API usages as structured call sequences to effectively mimic
various types of API misuses. Such structured call sequences
abstract away the syntactic details such as variable names, but
keep the temporal ordering, control structures and checkers
of API calls in a compact manner [4]. We adapt the grammar
deÔ¨Åned by the study [4] to represent structured call sequences,
which is shown in Table III. A structured call sequence
consists of several API calls, each of which can be guarded by
structure statements (e.g., try-catch ) or followed by checker
statements (e.g., null pointer checker). Overloaded API
calls are differentiated via considering the parameters and their
types. Figure 5 shows an usage of the class Iterator . Sup-
pose our target API (i.e., atarget ) isIterator<>.next() at
line 5. To model the usage of atarget , M UTAPIÔ¨Årst identiÔ¨Åes
the object (e.g., iterator ), on which atarget is invoked, and
then identiÔ¨Åes other APIs invoked by this object within the
same method. In this example, API Iterator<>.hasNext()
triggered at line 4 will be included in the modeled sequence.
MUTAPIthen conducts program slicing [35] (both backward
and forward) to extract those structure and checker statements
for each of the API call based on its receiver variables vrev
(e.g., value is the receiver variable at line 5) and parameters
vi. As a result, the ifstatement at line 7 will also be
included in the modeled sequence. Note that M UTAPIonly
identiÔ¨Åes those statements that directly depend on the variables
involved in API calls because such a setting is able to achieve
the best performance in modeling API usages for misuse
detection according to an existing work [4]. As a result, the
ifchecker at line 9 will not be sliced into the structured
sequence since the checked variable result does not directly
depend on the receiver variable value of our target API.
Therefore, the modeled structured sequence for the API usage
in Figure 5 is ‚Äú if (hasNext()) f;rrev=next();g; if
(rrev)fg;‚Äù. The delimiter ‚Äú;‚Äù here is a separator in the
grammar, which is different from the semi-colon used in Java.
Based on the modeled structured sequences of correct
usages of atarget , M UTAPIthen tries to break such usages
869
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. Client	
Projects
 Target	API s
Model ingAPI	Usages
Mutation	Testing
Input	of	 MutAPI Conducting	Mutation	 Testin g
Collecting	Killing	Relations
Grouping	&	Ranking	Killing	Relations
Prioritizing	Killing	Relations
Selecting	Killing	Relations
Mining	API	Misuse	Patterns
Discovering	API	 Misuse Pattern s
Violation
Patterns ofthe
Target APIs
Output	of	 MutAPIFig. 4: Overview of M UTAPI
public doublefoo() {
Iterator< Double> iterator = getValues ();
Doublevalue=null;
if(iterator.hasNext ()) {
value=iterator.next (); //our target API
}
if(value==null)returngetResult (0);
Doubleresult=getResult (value);
if(result <0)return0;
returnresult;
} 1
2
3
4
5
6
7
8
9
10
11
Fig. 5: An Usage Example of Iterator<>.next()
via applying mutation operators systematically with the aim to
mimic various kinds of API misuses. SpeciÔ¨Åcally, we designed
eight types of mutation operators, as shown in Table IV, guided
by the common characteristics of API misuse patterns [4], [6].
For the case of incorrect order of API calls [4], M UTAPIswaps
the orders of two call sequences (Type 1), deletes an API call
(Type 2) and inserts a new API call (Type 3). For the case
ofmissing checkers [6], M UTAPIdeletes a checker if there is
one (Type 4). For the case of missing control structures [4],
[6], M UTAPIdeletes the structures but keeps the enclosing
API calls (Type 5) or deletes the structures together with
the enclosing API calls (Type 6). For the case of missing
correct condition [4], [6], in a checker or an ifstatement,
MUTAPIrandomly replaces the condition expression with
other condition expressions or boolean values (Type 7).
MUTAPIalso mutates the arguments of API calls (Type 8). It
replaces the arguments of an API call with other compatible
variables (Type 8:1), inserts an argument (Type 8:2) or deletes
an argument (Type 8:3) to change the original method call to
a call of an overloaded method.
MUTAPIadopts an evolutionary process to generate mutants
randomly as described in Algorithm 1. SpeciÔ¨Åcally, it applies
at most Nmutation operators to the original program to
generate a mutant. Certain operators (e.g., replace one condi-
tion with another) require necessary code ingredients. In such
cases, M UTAPIsearches from the original program to select
appropriate code elements randomly. By default, Nis set to
1, and the effects of Nis discussed in Section VI-A.
B. Prioritizing Killing Relations
MUTAPIcollects plenty of killing relations Kafter exe-
cuting all mutants Magainst the test suites. SpeciÔ¨Åcally, a
killing relation kis collected if mutant mwith respect to
APIain client project pis killed by p‚Äôs test case t. In
particular, kis also denoted as khp;a;m;t i. As described in
Section II-D, there are multiple inducing factors for a killing
relation, and determining whether the failure of the killing
testtis caused by the misuse of the target API atarget
is challenging. To tackle this problem, M UTAPIleverages
thekilling stack traces stto prioritize those killing relations
induced by API misuses. For example, Figure 3 shows the
top 10 frames of the two killing stack traces for the two
mutants shown in Figure 1, respectively. One is induced byAlgorithm 1: Generating Mutants
input :p: the original program that has usages of atarget
input :O: the predeÔ¨Åned eight types of mutation operators
input :Max iter: the maximum number of iterations (set to 105)
input :N: the maximum number of operations to be applied
output:M: a set of generated mutants
1M p;iter 0
2while iter++<Max iter do
3m SelectAnMutantRandomly (M)
4 ifGetNumberOfAppliedOperators (m)<N then
5o SelectOneMutationOperatorRandomly (O)
6i SelectOneCodeIngredientRandomly (p)
7mnew GenerateNewMutant (m;o;i )
8 ifMdoes not contain mnew then
9M M[ mnew
10 end
11 end
12end
API misuse (i.e., missing exception handling), and fails due to
java.lang.NumberFormatException . The other is induced
by general errors unrelated to API misuses, and fails due to
java.lang.AssertionError . M UTAPIdifferentiates those
killing stack traces that are induced by API misuses from those
that are not through prioritization based on stack traces.
The prioritization is based on the analysis of substantial
killing stack traces collected from multiple client projects P.
To enable such cross-project analysis, M UTAPIpreprocesses
these killing stack traces to remove frames related to client
projects (e.g., Frame 4 in Figure 3b) or the JUnit framework
(e.g., Frame 1 in Figure 3a) since these frames are unlikely
to characterize the patterns of stack traces induced by misuses
of library APIs. As a result, only those frames displayed in
blue background in Figure 3 are kept for further analysis.
The failing signature (e.g., java.lang.AssertionError or
java.lang.NumberFormatException ) is also important to
understand the failure cause. Therefore, we also keep such
information in the processed stack traces. However, project-
speciÔ¨Åc information (e.g., toFloat() in stack trace #1 or for
input string: ‚Äúa‚Äù in stack trace #2) has been Ô¨Åltered out. Two
killing stack traces are regarded as the same if both their failing
signature and the processed frames are the same.
After preprocessing each killing stack trace, M UTAPIob-
tains a set of unique traces S. M UTAPIthen groups those
killing relations whose killing stack traces are the same. With
respect to atarget , M UTAPIthen tries to identify those killing
stack traces inSthat are induced by the misuse of atarget
(denoted as target API misuse induced killing stack traces )
via prioritization based on the following insights.
Target API misuse induced killing stack traces should
not be speciÔ¨Åc to a certain usage. If a killing stack trace is
indeed induced by the misuse of atarget , it should be observed
in the mutation analysis of multiple usages of atarget across
different projects. Otherwise, such a stack trace is more likely
to be caused by the bugs speciÔ¨Åc to an API usage in a speciÔ¨Åc
870
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. TABLE IV: Mutation Operators to Violate API Usages
Type Designed Mutation Operator Description
1 sequence 1;sequence 2)sequence 2;sequence 1 Swapping API call sequences
2 sequence 1)sequence 1;sequence 2 Adding an API call to a call sequence
3 sequence 1;sequence 2)sequence 2 Deleting an API call from a call sequence
4 if(checker )fg;sequence )sequence Deleting the checker of receivers or parameters
5 structure fsequence 1;g;sequence 2)sequence 1;sequence 2 Deleting the control structure of a sequence
6 structure fsequence 1;g;sequence 2)sequence 2 Deleting the control structure together with the enclosing APIs of a sequence
7 if(cond 1jchecker )) if(cond 2jtruejfalse ) Changing the control condition to other conditions or boolean values
8:1 API (t1; :::; t i; :::; t n))API (t1; :::; t j; :::; t n) Replacing arguments (from titotj) of a method call
8:2 API (t1; :::; t i; :::; t n))API (t1; :::; t i; :::; t n+1) Inserting arguments of a method call (changing API to an overloaded method)
8:3 API (t1; :::; t i; :::; t n))API (t1; :::; t i; :::; t n 1)Deleting arguments of a method call (changing API to an overloaded method)
project instead of general misuses of atarget . Therefore, M U-
TAPImeasures the ratio of usages whose mutation analyses
have observed the killing stack trace sto prioritize whether s
is caused by the misuse of atarget as follows:
freq (s) =jfuijui2 U; mutation analysis of u iobserved s gj
jfuijui2 U; uiis theithusage of atarget gj(1)
whereUcontains all the usages of atarget extracted from all
the client projects P.
Target API misuse induced killing stack traces should be
speciÔ¨Åc to this API. If a killing stack trace is induced by
the misuse of a target API, it should not be observed in the
mutation analysis of other APIs. Otherwise, such a stack trace
is less likely to be induced by the misuses of the target API
since it is general to multiple divergent APIs. Motivated by
this, M UTAPImeasures the inverse frequency of s, which is
the ratio of the number of sobserved in the mutation analysis
ofatarget to that of all target APIs A, as follows:
inverseFreq (s) =jfkhp;atarget ;m;tijk2K;sk=sgj
jfkhp;ai;m;tijk2K;ai2A;sk=sgj(2)
where khp;atarget ;m;tiis a killing relation observed in the
mutation analysis of the target API atarget , while khp;ai;m;ti
is a killing relation observed in that of another API ai.
The top frames of the target API misuse induced killing
stack traces should be the target library‚Äôs functions. As
revealed by existing studies, in a stack trace, functions where
the root causes reside appear closer to the failure point
[28]. The top frames of stack trace #2 shown in Figure
3a are functions from the library containing the target API
java.lang.Float.parseFloat . However, the top frames
of stack trace #1 are those functions related to the JUnit
framework. Here, we examine the original stack traces instead
of the processed ones in order to investigate the position
of each frame at the failure time. Therefore, killing stack
trace #2 is more likely to be induced by the misuse of API
java.lang.Float.parseFloat . Motivated by these obser-
vations, for a given stack trace, we propose to use the rankings
of those frames from the target library to approximate its
likelihood to be induced by misusing the library APIs.
likelihood (s) =nX
i=1library (fi)1=i (3)
where firepresents the ithframe of stack trace s. Function
library (fi)returns 1 if ficomes from the target library and
0 otherwise. For the stack trace shown in Figure 3a, the
likelihood 0:76, which is computed as1
4+1
5+1
6+1
7.
MUTAPIprioritizes all the unique stack traces Swithrespect to the target API atarget via computing the following
score for each stack trace s.
score (s) =freq (s)inverseFreq (s)likelihood (s)(4)
C. Discovering API Misuse Patterns
For each unique killing stack trace sinS, M UTAPIcom-
putes its score with respect to atarget . M UTAPIthen re-
trieves all killing relations whose killing stack traces are the
same as s. LetKsdenote such a set of killing relations,
whereKs=fkjk2K; sk=sg. M UTAPIdistills API misuse
patterns from those killed mutants Msassociated withKs.
To effectively distill API misuses, M UTAPImodels an API
misuse as a violation pair, p=hviolation type ,API usage
elementi, following a recent work [6]. SpeciÔ¨Åcally, there
are three violation types, missing ,redundant and incorrect ,
according to existing studies [4], [6]. An API usage element
can refer to a method call ,null checker ,condition ,exception
handling ,iteration ,parameter and so on [4], [6]. SpeciÔ¨Åcally,
MUTAPIleverages the following rules to distill violation pairs
from mutants via investigating the applied mutation operators.
MUTAPIdistills violation pairs of type missing from mutants
created by mutation operators #3, #4, #5, #6, and #8.3 since
they delete code elements; violation pairs of type redundant
are distilled from mutants created by mutation operators #2
and #8.2 since they add code elements; and violation pairs
of type incorrect are distilled from mutation operators #1, #7
and #8.1 since they replace existing code elements with others.
ForAPI usage element , M UTAPIdistills it via analyzing the
code element that has been mutated. For instance, the second
mutant shown in Figure 1 is generated by applying mutation
operator #5. Therefore, the violation type is missing . The code
element being mutated is a try-catch statement. As a result,
the distilled violation pair is hmissing ,exception handling i.
Multiple violation pairs can be distilled based on those mu-
tantsMs. Therefore, M UTAPIfurther prioritizes these pairs
based on their frequencies. SpeciÔ¨Åcally, M UTAPIidentiÔ¨Åes
a set of unique pairs PMsbased onMs. It records the
number of occurrences for each vpinPMs(i.e., denoted as
count (vp)). M UTAPIthen prioritizes all the violation pairs
based on their occurrences among all the pairs distilled:
ratio (vp) =count (vp)P
vpi2PMscount (vpi)(5)
Finally, the suspicious score for a violation pair vpto be the
misuse of the target API atarget is computed as:
suspicious (vp; a target ) =score (s)ratio (vp) (6)
871
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. where score (s)measures the likelihood of those killing re-
lationsKssharing the same stack trace sto be induced by
the misuses of atarget , and ratio (vp)measures the frequency
of the violation pair vpobserved among all violation pairs
distilled from those killed mutants associated with Ks.
IV. E XPERIMENT SETUP
This section presents our experiment setup and the research
questions to be investigated.
A. Target APIs Selection
To evaluate the effectiveness of M UTAPI, we selected 73
popular Java APIs collected by a recent study [4] for exper-
iments1. Among them, 43 are the most frequently discussed
APIs in Stack OverÔ¨Çow (e.g., Iterator<>.next() ). These
APIs are often used in practice, and developers are frequently
confused by their usages. The remaining 30 APIs come
from M UBENCH [6], which is a benchmark dataset of API
misuses. These APIs are in diverse domains, and the majority
of them come from four categories: Common Library (e.g.,
math, collection, time, xml), GUI (e.g., Swing), Security (e.g.,
java.security.Cipher() ) and Database.
B. Client Projects Selection
In order to discover API misuse patterns, M UTAPIrequires
a set of client projects to perform mutation analysis. In this
study, we selected 16 open-source Java projects from four
different categories as shown in Table V. These projects are
selected randomly from GitHub that satisfy the following two
criteria. First, the number of unique target APIs that it covers
should be greater than 15. Since M UTAPIaims at detecting
misuses with respect to the selected target APIs, the selected
client projects should contain as many usages of those APIs
as possible. It is hard to Ô¨Ånd a client project that triggers all
the 73 target APIs since those APIs are from diverse domains.
Therefore, we set a reasonable threshold of 15. Our second
criterion is that the mutation coverage (measured using P IT
[27]) of a client project should be greater than 0:70. We
set this threshold to ensure the test suite‚Äôs quality [39] since
MUTAPIrelies on the associated test suite to validate whether
a mutant introduces an API misuse. We will further discuss
the effect of the test suite‚Äôs quality on the performance of
MUTAPIin Section VI. With the two criteria, we randomly
selected four Java projects from each of the four categories of
domains where the 73 APIs commonly come from (i.e., GUI,
Library, Security and Database). The categorization of the
client projects is based on the Apache ofÔ¨Åcial deÔ¨Ånition [40]
and GitHub Topics [41]. In total, the selected 16 projects cover
55 distinct APIs among the selected 73 APIs. The remaining
18 APIs are not covered because they are rarely used by large-
scale and popular projects (e.g., jsoup.Jsoup.connect() ).
1The prior study collected 100 popular APIs [4]. We excluded 27 Android
APIs in our study because the mutation analysis for Android apps is different
from that for general Java projects [36]‚Äì[38] (e.g., the former requires
mutation operators to mutate the AndroidManifest.xml Ô¨Åle)TABLE V: Selected Client Projects
Category Project #Covered API #Source #Test #KLOC
GUIApache FOP [42] 35 1577 391 363.2
SwingX [43] 28 551 340 215.4
JFree Chart [44] 19 637 350 294.8
iTextPdf [45] 34 894 609 298.6
LibraryApache Lang [34] 24 153 174 144.1
Apache Math [46] 19 826 498 307.1
Apache Text [47] 17 85 63 40.8
Apache BCEL [48] 23 417 75 75.7
SecurityApache Fortress [49] 22 214 74 122.2
Santuario [50] 24 467 198 135.6
Apache Pdfbox [51] 28 598 103 154.1
WildÔ¨Çy -Eytron [52] 36 763 151 161.3
DatabaseJackRabbit [53] 34 2443 646 611.4
Apache BigTop 22 176 52 20.4
H2Database [54] 20 566 317 305.4
Curator [55] 18 197 52 20.4
C. Research Questions
We study three research questions to evaluate M UTAPI:
RQ1: Can M UTAPIdiscover API misuse patterns? What
kinds of misuse patterns can be more easily detected by it?
MUTAPIgenerates a ranked list of API misuse patterns.
In RQ1, we investigate whether those top-ranked API misuse
patterns detected by M UTAPIaretrue positives . SpeciÔ¨Åcally,
we use the metric Precision@N to evaluate the performance of
MUTAPI.Precision@N reports the percentage of true positives
among the top NAPI misuse patterns ( N= 1;5;10; :::)
reported by M UTAPI. To judge whether a detected misuse
pattern is a true positive or not, we follow the strategy adopted
by an existing study [4]. SpeciÔ¨Åcally, we manually inspected it
based on online documentations (i.e., whether the misuse has
been documented online) and existing literature (e.g., whether
the misuse pattern has been reported by existing studies). We
then investigate the characteristics of the APIs whose misuse
patterns have been detected by M UTAPIby checking the
associated Java documentations.
RQ2: Can M UTAPIdetect API misuse instances on the
state-of-the-art benchmark dataset M UBENCH ?
Based on the discovered misuse patterns (i.e., violation
pairs), M UTAPIis able to detect misuse instances. SpeciÔ¨Åcally,
MUTAPIapplies the same analysis as described in Section
III-A to model usage of an API in the form of Structured
API Call Sequences. Then, it checks whether the modelled
sequences violate conÔ¨Årmed misuse patterns. We applied M U-
TAPIto M UBENCH [6] to see if it can detect the API misuses
in the benchmark dataset. SpeciÔ¨Åcally, we investigate the recall
of M UTAPI, i.e., the ratio of the API misuses that can be
detected by M UTAPIamong the 53 real instances used in
the Experiment R in the M UBENCH work [6]. We chose
those misuses in Experiment R since they are all real misuse
instances identiÔ¨Åed from open-source projects. To compare
with existing approaches, we chose four baselines (i.e., J ADET
[14], G ROUP MINER [16], DMMC [7] and TIKANGA [20])
that have been systematically evaluated by existing study [6].
RQ3: Compared with conventional mutation operators, how
effective and efÔ¨Åcient do our proposed mutation operators
perform in detecting API misuse patterns?
In this work, we propose eight types of mutation operators
speciÔ¨Åc for API misuse detection, which are adopted by
MUTAPIin mutation analysis. In this research question, we
compare our proposed mutation operators with the traditional
872
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. TABLE VI: Generated Mutatns and Killing Relations
Project #Mutant #Killing Relation #Unique Trace #PitMutant
Fop 4024 6539 64 12845
SwingX 1063 9373 36 12348
Chart 1951 1603 139 6250
iTextPdf 9323 36083 102 11753
Lang 6144 16890 174 6502
Math 1599 34882 42 14726
Text 837 1408 64 6740
Bcel 4072 10338 86 9827
Santuario 2171 22521 27 3909
Pdfbox 4807 45735 29 11381
Fortress 1947 9015 55 3115
WildÔ¨Çy 2478 6473 40 4091
Rabbit 1431 5033 48 4175
BigTop 937 2107 37 2508
H2 6155 2036 67 9087
Curator 3321 5406 43 5431
Average 3266 13465 65 7793
00.20.40.60.8115913172125293337414549RankPrecision@N
Fig. 6: Precision@N of M UTAPIfor the Top-Ranked Misuses
ones used in P IT[27] using two metrics: (1) efÔ¨Åciency (i.e.,
the time required for mutation analysis) and (2) effectiveness
(i.e., the number of API misuse patterns detected).
V. E XPERIMENTAL RESULTS
A. RQ1:Effectiveness of MUTAPI
We applied M UTAPIto all client projects to discover misuse
patterns of our selected target APIs. M UTAPIgenerated lots
of mutants and collected substantial killing relations with the
associated killing stack traces. Table VI shows the statistics.
SpeciÔ¨Åcally, M UTAPIgenerated 3,266 mutants and collected
13,465 killing relations per client project. After processing the
killing stack traces (i.e., removing client project frames), it ob-
tained 65 unique stack traces per client project. M UTAPIthen
analyzed those killing relations across different client projects
and distilled around 300 API misuse patterns (i.e., violation
pairs). We manually examined the top 50 patterns following
the procedures as described in Section IV-C. Figure 6 shows
the results of Precision@N . It shows that M UTAPIachieves
a high precision of 0:90within the top 10 candidates. The
precision slightly drops to 0:78within the top 50 ones. Table
VII shows several selected top-ranked violation pairs that are
real API misuse patterns, which cover different types: missing
checker ,missing call ,missing exception ,incorrect condition
and redundant call . These results show that M UTAPIcan
discover real API misuse patterns with a high precision.
In the detected patterns, missing necessary checker if
(rev==null) on the receiver of API Line.intersection()
is ranked at the Ô¨Årst place. For the two correct usages
of this API in the codebase, one of which is shown in
Figure 7, M UTAPIgenerated mutants (i.e., deleting the
checker) that were killed by the associated test suite with
NullPointerException . The killing stack trace is unique
to this API (i.e., the inverse frequency is high) whose topframes are method invocations from the target library (i.e.,
thelikelihood is high). Furthermore, the killing stack trace
has been observed in the mutation analysis for both of the two
correct usages (i.e., the frequency is high). As a result, missing
the checker is deemed as a misuse of Line.intersection()
with high conÔ¨Ådence. This misuse has been conÔ¨Årmed by
existing literature [6]. Figure 8 shows another example, which
shows a correct usage of the API Iterator<>.next() , and
the associated killing stack trace after deleting the structure
containing API call Iterator<>.hasNext() . Such a killing
stack trace was observed during the mutation analysis of
multiple correct usages across different client projects (e.g.,
jfreechart ,commons-bcel andcommons-math ).
We further investigated the documentations of APIs whose
misuse patterns were discovered by M UTAPIto see whether
they share similar characteristics. We found that 78:9%of
them will throw unchecked exceptions . Figure 9 shows the
distributions of these unchecked exceptions. Note that, the sum
of the distributions for all the exceptions is greater than 1, since
an API might throw multiple types of exceptions. The above
results indicate that M UTAPIis more effective in detecting
misuses of those APIs that will throw unchecked exceptions.
This is because those mutants representing such misuses are
more likely to be killed in the form of runtime exceptions
(i.e., their killing does not require strong test oracles). There
are also other types of APIs whose misuses are less likely to
be detected by M UTAPI(see Section VI-B).
B. RQ2:Performance of MUTAPIonMUBENCH Benchmark
Figure 10 shows the recall of M UTAPIand the baselines
on the benchmark of M UBENCH . The results of baselines are
directly extracted from the previous study [6]. Note that there
are two experimental settings for the baseline approaches. One
is a practical setting which does not include any hand crafted
API usages (denoted as Recall#Practical in Figure 10). The
other setting involves hand crafted API correct usages (denoted
as Recall#Crafted in Figure 10). The two settings are detailedly
//lineisanobjectoftype Linepassedfromtheparameter s
Cartesian3D v1D = line.intersection (subLine.line );
if(v1D == null) { //Necessary Checke r
return null;
} 
Location loc1 = remainingRegion. checkpoint (line.toSubSpace (v1D)); 
Fig. 7: A Correct Usage of API Line.intersection()
if(!iterator.hasNext ()) {                
return EMPTY;
}
finalObject first = iterator.next ();-1:java.util.NoSuchElementException
0:java.util.ArrayList$Itr. next()
6:java.lang.reflect.Method. invoke()
(a)	A	Correct	Usage (b)	Killing	Stack	Trace
Fig. 8: A Correct Usage and the Associated Killing Stack Trace of
Iterator<>.next()
0.000.050.100.150.200.250.300.350.400.45NoSuchElementExceptionIndexOutOfBoundsExceptionNullPointerExceptionClassNotFoundExceptionSecurityExceptionNumberFormatExceptionIllegalStateExceptionNoSuchAlgorithmExceptionUnsupportedEncodingExceptionInputMismatchException
Fig. 9: Distributions of Detected Unchecked Exceptions
873
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. TABLE VII: Examples of Top-Ranked Discovered Violation Pairs
Rank API VIolation Pair API Element Description & ConÔ¨Årming References
1rcv = Line.intersection()1MISSING CHECKER if (rcv == null) fg The returning value could be null [6]
2Iterator<>.next() MISSING CALL Iterator<>.hasNext() Should check if there are sufÔ¨Åcient tokens [4], [6]
3StringTokenizer.nextToken() MISSING CALL StringTokenizer.hasMoreTokens() Should check if there are sufÔ¨Åcient tokens [4], [6]
4Integer.parseInt() MISSING EXCEPTION tryfgcatch(NumberFormatException) Might throw exceptions [6]
5Double.parseDouble() MISSING EXCEPTION tryfgcatch(NumberFormatException) Might throw exceptions [6]
6PdfArray.getPdfObject()2INCORRECT CONDITION if (!PdfArray.isEmpty()) fg Should check if the object is empty [6]
7rcv = SortedMap.firstKey() MISSING CHECKER if (rcv == null) fg The returning value could be null [4], [6]
8rcv = StrBuilder.getNullText()3MISSING CHECKER if (rcv == null) fg The returning value could be null [6]
10MessageDigest.getInstance() MISSING EXCEPTION tryfgcatch(NoSuchAlgorithmException) Might throw exceptions [56]
12Matcher.group() MISSING CALL Matcher.find() Required to be used together [57]
25Iterator.next() REDUNDANT CALL Iterator.remove() Shouldn‚Äôt call remove during iteration [6]
1: from library org.apache.commons.math ; 2: from library com.itextpdf.text ; 3: from library org.apache.commons.lang ; the others from Java
explained in the existing study [6] and we do not make further
explanations in this study. M UTAPIis not evaluated on the
crafted setting since the crafted API usage examples are not
equipped with a test suite required for mutation analysis.
As shown in Figure 10, M UTAPIis able to detected 26 out
of the 53 real API misuses. It achieves the highest recall of
0:49. In the practical setting, M UTAPIsigniÔ¨Åcantly outper-
forms all the baseline approaches. The second best approach
is DMMC, which achieves a recall of 0:21. GROUP MINER is
unable to detect any API misuses in the benchmark. One of
the major reasons that limit existing approaches in detecting
more API misuses is that the number of usage examples
in the codebase is too small (below the minimal support
values required by existing approaches for pattern mining). For
instance, G ROUP MINER [16] detects frequent usage patterns
with a minimum support of 6 and T IKANGA[14] sets the min-
imum support to 20. This means that they require at least 6 or
20 usage examples in the codebase. In the crafted setting, since
more correct usage examples have been added to the codebase
manually, the recall of existing approaches have improved
accordingly. Nonetheless, the results of M UTAPIobtained in
the practical setting still outperform all the baseline approaches
under this crafted setting.
We further investigated the reasons why certain patterns of
API misuse instances cannot be detected by M UTAPIand
found three major types of reasons: no correct API usages ,
no mutant coverage and inadequate test suite (see Section
VI-B). We plan to evaluate M UTAPIon more datasets other
than M UBENCH [6] in the future since one threat to validity
of our results here is that the design of our mutation operators
was partially inspired by the study of this benchmark.
C. RQ3:EfÔ¨Åciency and Effectiveness of Mutation Operators
Table VI shows the number of mutants generated by M U-
TAPIand P ITin column #Mutants and#PitMutants , respec-
tively. Note that when generating mutants using P IT, we only
target at those source Ô¨Åles that involve usages of our selected
target APIs. As shown in the table, on average, P ITgenerates
00.10.20.30.40.5
JADETGroupMinerDMMCTIKANGAMutAPIRecall#PracticalRecall#Crafted
Fig. 10: Recall of M UTAPIand the Baseline Approaches2:39times more mutants than M UTAPI. Mutation analysis
is known to be computationally expensive since it needs to
compile the mutants and execute them against the associalted
test suite [58], [59]. As a result, it takes 9:87minutes for
MUTAPIto Ô¨Ånish the analysis per project on average while it
takes 20:93minutes for conventional mutation operators.
We fed the mutants generated by P ITand the associated
killing relations to M UTAPI. We manually checked the Top-
50 ranked results following the same procedure adopted in
RQ1. Figure 11 shows the number of real API misuse patterns
(i.e., true positives) detected by P IT. In total, P ITis only able
to detect 5 true positives of the type incorrect condition and
missing call . This is because that the conventional mutation
operators focus on mutating arithmetic and conditional oper-
ators [27], which mostly result in assertion errors general to
all client projects. Therefore, it is hard to leverage them to
distill real API misuses. The conventional mutation operators
also mutate conditions (e.g., forcing conditions to ture or
false ) and remove void method calls. This explains why P IT
discovers Ô¨Åve real API misuses.
These results demonstrate that our proposed mutation opera-
tors are more effective and efÔ¨Åcient in discovering API misuse
patterns than conventional ones, which reÔ¨Çect the need to
propose domain-speciÔ¨Åc mutation operators for the discovert
of API misuse patterns. Figure 11 also shows the distributions
of different types of misuse patterns that are detected by
MUTAPI. It indicates that missing checker ,missing exception
andmissing call are the most frequently ones. This is in line
with the Ô¨Åndings of existing studies [4], [6].
VI. D ISCUSSIONS
A. Effects of the Number of Applied Mutation Operators
MUTAPIcan apply Nmutation operators when generating
mutants (see Algorithm 1). By default, Nis set to 1. The effect
of the maximum number of mutation operators can be applied
on the effectiveness of M UTAPIis unknown. We investigate
such effects in this subsection.
02468101214
MISSINGCHECKERMISSINGEXCEPTIONINCORECTCONDITIONMISSINGCALLREDUDANTCALLMutAPIPitMutant
Fig. 11: The Number of True API Misuse Patterns Detected by
MUTAPIand P ITamong the Top 50 Results
874
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. Figure 12 shows the number of mutants generated when N
is set to 1 to 5. We can see that, the number of generated
mutants signiÔ¨Åcantly grows with the increase of N. Thus,
it becomes more expensive to conduct mutation analysis.
However, we observe that the number of the unique failing
stack traces increases marginally as Ngrows. For instance,
the total number of unique stack traces is 543when N=1. The
number only increases by 5when N=2, while the number of
mutants increases by 20;501in total for the 16 client projects.
This indicates that applying a single mutation operator is
sufÔ¨Åcient to discover most of the error spaces (i.e., in the form
of failing stack traces) for exposing library misuses.
B. Limitations of MUTAPI
There are three major reasons that hinder M UTAPIto
discover misuse patterns for a target API.
No correct usages . If there are no correct usages of
the target API in the input client projects, M UTAPIcannot
discover the corresponding misuses via mutation analysis. For
example, in our experiments, we found that there are no correct
usages for API org.kohsuke.args4j.api.Parameters.
getParameter() in all the 16 client projects. We did not
pick additional projects that have correct usages of this API
in order to guarantee the generality of our results and Ô¨Åndings.
Thus, M UTAPIdid not discover any misuse patterns for
this API. Existing approaches also suffer from this limitation
as discussed before, and, even worse, they require a larger
number of correct usages than our approach.
No mutant coverage . We observe that certain API misuse
patterns require speciÔ¨Åc values that can not be discovered by
our approach. For instance, javax.crypto.Cipher("DES")
is a misuse since it should not be used with the DES mode
[60]. However, M UTAPIonly searches from the same source
Ô¨Åle in order to Ô¨Ånd appropriate code elements when replacing
parameters or conditions. As a result, if there is no string
‚ÄúDES‚Äù in the same source Ô¨Åle, M UTAPIcannot create a mutant
which represents this API misuse. Similar cases are observed
for other APIs such as String.getBytes() .
Inadequate test suite . The effectiveness of M UTAPIis
subject to the quality of the associated test suite. Even if M U-
TAPIhas generated a mutant that represents a real API misuse,
it still has no chance to detect the misuse if the associated
test suite cannot kill the mutant. For example, for the misuse
of API StatisticalCategoryDataset.getDtDevValue()
in M UBENCH , M UTAPIsuccessfully created a mutant that
mimicked a misuse. Unfortunately, it could not be killed by the
associated test suite. As a result, the misuse pattern cannot be
detected. For other I/O related APIs, such as InputStream()
orFile.open() , missing method call File.close() is a
common type of misuse. However, mutants representing such
103103.5104104.5105
N=1 N=2 N=3 N=4 N=5The Number of Mutants
Fig. 12: The Number of Mutants Generated with Different Nmisuses can hardly be killed by the test suite. The reason is that
such misuses are likely to induce performance issues. The test
cases of client projects are rarely equipped with a proper oracle
to identify such issues. Nonetheless, our empirical results
(Section V-A) already conÔ¨Årm that a large number of real API
misuse patterns can be detected via mutation analysis.
C. Threats to Validity
The validity of our study is subject to the following threats.
First, our study is limited to 73 Java APIs, and thus the gen-
erality to other APIs might be a threat. However, these APIs
are popular (i.e., frequently discussed in Stack OverÔ¨Çow [4])
and systematically evaluated by existing studies [6]. Therefore,
we believe that they are representative Java APIs. Performing
experiments using more Java APIs is left as our future work.
Second, our experiments involve only 16 client projects, and
thus the results might not be generalizable to other projects.
However, these projects are randomly selected based on the
criteria described in Section IV-B. They are popular and from
diverse domains. It is also worth mentioning that these projects
only cover 55 of the 73 selected APIs. We did not purposely
select more projects to cover the remaining 18 APIs in order
to ensure the generality of our experiments.
VII. CONCLUSION AND FUTURE WORK
We present M UTAPIin this study, the Ô¨Årst approach that
leverages mutation analysis to discover API misuse patterns. It
offers two major beneÔ¨Åts compared with existing approaches.
First, it does not require a large number of correct API usage
examples. Therefore, it can be applied to detect misuse pat-
terns of newly released APIs, whose number of usages might
be limited, while existing approaches are less likely to work in
such scenarios. Second, it goes beyond the simple assumption
that a deviation from the most frequent patterns is a misuse.
Existing approaches suffer from low precision due to such an
assumption. We applied M UTAPIon 16 client projects with
respect to 73 popular APIs. The results show that M UTAPIis
able to detect substantial API misuse patterns. It also achieves
a recall of 0:49on the M UBENCH benchmark dataset [6],
which signiÔ¨Åcantly outperforms existing approaches.
In future, we plan to apply M UTAPIto those less frequently
used APIs (e.g., those from newly released libraries) instead
of popular ones to investigate whether M UTAPIcan detect
unknown API misuse patterns. We also plan to systematically
investigate the effects of the test suite‚Äôs quality on the effec-
tiveness of our approach.
ACKNOWLEDGMENT
We thank Tianyi Zhang for his discussions toward this idea
and anonymous reviewers for their constructive comments.
This work was supported by the Hong Kong RGC/GRF Grant
16202917, the MSRA Collaborative Research Award, the GPU
Grant Program by NVIDIA, the National Natural Science
Foundation of China (Grant No. 61802164), the Science and
Technology Innovation Committee Foundation of Shenzhen
(Grant No. ZDSYS201703031748284) and the Program for
University Key Laboratory of Guangdong Province (Grant No.
2017KSYS008). Zhendong Su was supported in part by United
States NSF Grants 1528133 and 1618158.
875
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] Y . Wang, M. Wen, Z. Liu, R. Wu, R. Wang, B. Yang, H. Yu, Z. Zhu,
and S.-C. Cheung, ‚ÄúDo the dependency conÔ¨Çicts in my project matter?‚Äù
inProceedings of the 2018 26th ACM Joint European Software En-
gineering Conference and Symposium on the Foundations of Software
Engineering (ESEC/FSE 2018) . ACM, 2018, pp. 1‚Äì12.
[2] ‚ÄúMaven repository,‚Äù https://maven :apache:org/, 2018, accessed: 2018-
02-28.
[3] U. Dekel and J. D. Herbsleb, ‚ÄúImproving api documentation usability
with knowledge pushing,‚Äù in Proceedings of the 31st International
Conference on Software Engineering . IEEE Computer Society, 2009,
pp. 320‚Äì330.
[4] T. Zhang, G. Upadhyaya, A. Reinhardt, H. Rajan, and M. Kim, ‚ÄúAre
code examples on an online q&a forum reliable?: a study of api misuse
on stack overÔ¨Çow,‚Äù in Proceedings of the 40th International Conference
on Software Engineering . ACM, 2018, pp. 886‚Äì896.
[5] L. Seonah, R. Wu, S.-C. Cheung, and S. Kang, ‚ÄúAutomatic detection
and update suggestion for outdated api names in documentation,‚Äù IEEE
Transactions on Software Engineering , 2019.
[6] S. Amann, H. A. Nguyen, S. Nadi, T. N. Nguyen, and M. Mezini, ‚ÄúA
systematic evaluation of static api-misuse detectors,‚Äù IEEE Transactions
on Software Engineering , 2018.
[7] M. Monperrus and M. Mezini, ‚ÄúDetecting missing method calls as viola-
tions of the majority rule,‚Äù ACM Transactions on Software Engineering
and Methodology (TOSEM) , vol. 22, no. 1, p. 7, 2013.
[8] J. Sushine, J. D. Herbsleb, and J. Aldrich, ‚ÄúSearching the state space: a
qualitative study of api protocol usability,‚Äù in Proceedings of the 2015
IEEE 23rd International Conference on Program Comprehension . IEEE
Press, 2015, pp. 82‚Äì93.
[9] S. Fahl, M. Harbach, T. Muders, L. Baumg ¬®artner, B. Freisleben, and
M. Smith, ‚ÄúWhy eve and mallory love android: An analysis of android
ssl (in) security,‚Äù in Proceedings of the 2012 ACM conference on
Computer and communications security . ACM, 2012, pp. 50‚Äì61.
[10] M. Egele, D. Brumley, Y . Fratantonio, and C. Kruegel, ‚ÄúAn empirical
study of cryptographic misuse in android applications,‚Äù in Proceedings
of the 2013 ACM SIGSAC conference on Computer & communications
security . ACM, 2013, pp. 73‚Äì84.
[11] M. Georgiev, S. Iyengar, S. Jana, R. Anubhai, D. Boneh, and
V . Shmatikov, ‚ÄúThe most dangerous code in the world: validating ssl
certiÔ¨Åcates in non-browser software,‚Äù in Proceedings of the 2012 ACM
conference on Computer and communications security . ACM, 2012,
pp. 38‚Äì49.
[12] Z. Li and Y . Zhou, ‚ÄúPr-miner: automatically extracting implicit program-
ming rules and detecting violations in large software code,‚Äù in ACM
SIGSOFT Software Engineering Notes , vol. 30, no. 5. ACM, 2005, pp.
306‚Äì315.
[13] C. Lindig, ‚ÄúMining patterns and violations using concept analysis,‚Äù in
The Art and Science of Analyzing Software Data . Elsevier, 2016, pp.
17‚Äì38.
[14] A. Wasylkowski, A. Zeller, and C. Lindig, ‚ÄúDetecting object usage
anomalies,‚Äù in Proceedings of the the 6th joint meeting of the European
software engineering conference and the ACM SIGSOFT symposium on
The foundations of software engineering . ACM, 2007, pp. 35‚Äì44.
[15] M. K. Ramanathan, A. Grama, and S. Jagannathan, ‚ÄúStatic speciÔ¨Åcation
inference using predicate mining,‚Äù in ACM SIGPLAN Notices , vol. 42,
no. 6. ACM, 2007, pp. 123‚Äì134.
[16] T. T. Nguyen, H. A. Nguyen, N. H. Pham, J. M. Al-Kofahi, and T. N.
Nguyen, ‚ÄúGraph-based mining of multiple object usage patterns,‚Äù in
Proceedings of the the 7th joint meeting of the European software
engineering conference and the ACM SIGSOFT symposium on The
foundations of software engineering . ACM, 2009, pp. 383‚Äì392.
[17] M. Acharya and T. Xie, ‚ÄúMining api error-handling speciÔ¨Åcations from
source code,‚Äù in International Conference on Fundamental Approaches
to Software Engineering . Springer, 2009, pp. 370‚Äì384.
[18] S. Thummalapenta and T. Xie, ‚ÄúMining exception-handling rules as se-
quence association rules,‚Äù in Proceedings of the IEEE 31st International
Conference on Software Engineering, 2009 . IEEE, 2009, pp. 496‚Äì506.
[19] ‚Äî‚Äî, ‚ÄúAlattin: Mining alternative patterns for detecting neglected condi-
tions,‚Äù in Proceedings of the 2009 IEEE/ACM International Conference
on Automated Software Engineering . IEEE Computer Society, 2009,
pp. 283‚Äì294.
[20] A. Wasylkowski and A. Zeller, ‚ÄúMining temporal speciÔ¨Åcations from
object usage,‚Äù Automated Software Engineering , vol. 18, no. 3-4, pp.
263‚Äì292, 2011.[21] Y . Jia and M. Harman, ‚ÄúAn analysis and survey of the development of
mutation testing,‚Äù IEEE transactions on software engineering , vol. 37,
no. 5, pp. 649‚Äì678, 2011.
[22] P. Ammann and J. Offutt, Introduction to software testing . Cambridge
University Press, 2016.
[23] S. Hong, B. Lee, T. Kwak, Y . Jeon, B. Ko, Y . Kim, and M. Kim,
‚ÄúMutation-based fault localization for real-world multilingual programs
(t),‚Äù in Proceedings of the 30th IEEE/ACM International Conference on
Automated Software Engineering . IEEE, 2015, pp. 464‚Äì475.
[24] T. Loise, X. Devroey, G. Perrouin, M. Papadakis, and P. Heymans,
‚ÄúTowards security-aware mutation testing.‚Äù in ICST Workshops , 2017,
pp. 97‚Äì102.
[25] T. Mouelhi, Y . Le Traon, and B. Baudry, ‚ÄúMutation analysis for
security tests qualiÔ¨Åcation,‚Äù in Testing: Academic and Industrial Confer-
ence Practice and Research Techniques-MUTATION, 2007. TAICPART-
MUTATION 2007 . IEEE, 2007, pp. 233‚Äì242.
[26] B. Baudry, F. Fleurey, and Y . Le Traon, ‚ÄúImproving test suites for
efÔ¨Åcient fault localization,‚Äù in Proceedings of the 28th international
conference on Software engineering . ACM, 2006, pp. 82‚Äì91.
[27] ‚ÄúPit,‚Äù http://pitest :org/quickstart/mutators/, 2018, accessed: 2018-02-28.
[28] R. Wu, H. Zhang, S.-C. Cheung, and S. Kim, ‚ÄúCrashlocator: locating
crashing faults based on crash stacks,‚Äù in Proceedings of the 2014
International Symposium on Software Testing and Analysis . ACM,
2014, pp. 204‚Äì214.
[29] W. Ying, W. Ming, W. Rongxin, L. Zhenwei, T. Shin Hwei, Z. Zhiliang,
Y . Hai, and C. Shing-Chi, ‚ÄúCould I Have a Stack Trace to Examine the
Dependency ConÔ¨Çict Issue?‚Äù in Proceedings of the 41th International
Conference on Software Engineering . IEEE, 2019.
[30] I. Ahmed, C. Jensen, A. Groce, and P. E. McKenney, ‚ÄúApplying mutation
analysis on kernel test suites: an experience report,‚Äù in IEEE Inter-
national Conference on Software Testing, VeriÔ¨Åcation and Validation
Workshops (ICSTW) . IEEE, 2017, pp. 110‚Äì115.
[31] C. S. Timperley, S. Stepney, and C. Le Goues, ‚ÄúAn investigation into the
use of mutation analysis for automated program repair,‚Äù in International
Symposium on Search Based Software Engineering . Springer, 2017, pp.
99‚Äì114.
[32] M. Wen, J. Chen, R. Wu, D. Hao, and S.-C. Cheung, ‚ÄúContext-aware
patch generation for better automated program repair,‚Äù in Proceedings
of the 40th International Conference on Software Engineering , ser.
ICSE ‚Äô18. New York, NY , USA: ACM, 2018, pp. 1‚Äì11. [Online].
Available: http://doi :acm:org/10:1145/3180155 :3180233
[33] Y . Acar, M. Backes, S. Fahl, D. Kim, M. L. Mazurek, and C. Stransky,
‚ÄúYou get where you‚Äôre looking for: The impact of information sources
on code security,‚Äù in Proceedings of the IEEE Symposium on Security
and Privacy . IEEE, 2016, pp. 289‚Äì305.
[34] ‚ÄúApache lang,‚Äù https://github :com/apache/commons-lang :git, 2018, ac-
cessed: 2018-02-28.
[35] M. Weiser, ‚ÄúProgram slicing,‚Äù in Proceedings of the 5th international
conference on Software engineering . IEEE Press, 1981, pp. 439‚Äì449.
[36] M. Linares-V ¬¥asquez, G. Bavota, M. Tufano, K. Moran, M. Di Penta,
C. Vendome, C. Bernal-C ¬¥ardenas, and D. Poshyvanyk, ‚ÄúEnabling mu-
tation testing for android apps,‚Äù in Proceedings of the 2017 11th Joint
Meeting on Foundations of Software Engineering . ACM, 2017, pp.
233‚Äì244.
[37] K. Moran, M. Tufano, C. Bernal-C ¬¥ardenas, M. Linares-V ¬¥asquez,
G. Bavota, C. Vendome, M. Di Penta, and D. Poshyvanyk, ‚ÄúMdroid+:
a mutation testing framework for android,‚Äù in Proceedings of the
40th International Conference on Software Engineering: Companion
Proceeedings . ACM, 2018, pp. 33‚Äì36.
[38] R. Jabbarvand and S. Malek, ‚Äú droid: an energy-aware mutation testing
framework for android,‚Äù in Proceedings of the 2017 11th Joint Meeting
on Foundations of Software Engineering . ACM, 2017, pp. 208‚Äì219.
[39] R. Just, D. Jalali, L. Inozemtseva, M. D. Ernst, R. Holmes, and G. Fraser,
‚ÄúAre mutants a valid substitute for real faults in software testing?‚Äù in
Proceedings of the 22nd ACM SIGSOFT International Symposium on
Foundations of Software Engineering . ACM, 2014, pp. 654‚Äì665.
[40] ‚ÄúApache category,‚Äù https://projects :apache:org/projects:html?category,
2018, accessed: 2018-02-28.
[41] ‚ÄúGithub topics,‚Äù https://github :com/topics, 2018, accessed: 2018-02-28.
[42] ‚ÄúApache fop,‚Äù https://github :com/apache/fop :git, 2018, accessed: 2018-
02-28.
[43] ‚ÄúSwingx,‚Äù https://github :com/ebourg/swingx :git, 2018, accessed: 2018-
02-28.
876
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. [44] ‚ÄúJfreechart,‚Äù https://github :com/jfree/jfreechart :git, 2018, accessed:
2018-02-28.
[45] ‚Äúitextpdf,‚Äù https://github :com/itext/itextpdf :git, 2018, accessed: 2018-02-
28.
[46] ‚ÄúApache math,‚Äù https://github :com/apache/commons-math :git, 2018, ac-
cessed: 2018-02-28.
[47] ‚ÄúApache text,‚Äù https://github :com/apache/commons-text :git, 2018, ac-
cessed: 2018-02-28.
[48] ‚ÄúApache bcel,‚Äù https://github :com/apache/commons-bcel :git, 2018, ac-
cessed: 2018-02-28.
[49] ‚ÄúFortress core,‚Äù https://github :com/apache/directory-fortress-core :git,
2018, accessed: 2018-02-28.
[50] ‚ÄúSantuario-java,‚Äù https://github :com/apache/santuario-java :git, 2018, ac-
cessed: 2018-02-28.
[51] ‚ÄúPdfbox,‚Äù https://github :com/apache/pdfbox :git, 2018, accessed: 2018-
02-28.
[52] ‚ÄúWildÔ¨Çy,‚Äù https://github :com/wildÔ¨Çy-security/wildÔ¨Çy-elytron :git, 2018,
accessed: 2018-02-28.
[53] ‚ÄúApache jackrabbit,‚Äù https://github :com/apache/jackrabbit :git, 2018, ac-
cessed: 2018-02-28.[54] ‚ÄúH2database,‚Äù https://github :com/h2database/h2database :git, 2018, ac-
cessed: 2018-02-28.
[55] ‚ÄúCurator,‚Äù https://github :com/apache/curator :git, 2018, accessed: 2018-
02-28.
[56] ‚ÄúMessagedigest,‚Äù https://stackoverÔ¨Çow :com/questions/16133881/
messagedigest-nosuchalgorithmexception, 2018, accessed: 2018-02-28.
[57] ‚ÄúMatcher group api,‚Äù https://stackoverÔ¨Çow :com/questions/25851293/
java-regex-why-matcher-group-does-not-work-without-matcher-Ô¨Ånd,
2018, accessed: 2018-02-28.
[58] J. Zhang, L. Zhang, M. Harman, D. Hao, Y . Jia, and L. Zhang, ‚ÄúPre-
dictive mutation testing,‚Äù IEEE Transactions on Software Engineering ,
2018.
[59] B. Wang, Y . Xiong, Y . Shi, L. Zhang, and D. Hao, ‚ÄúFaster mutation
analysis via equivalence modulo states,‚Äù in Proceedings of the 26th ACM
SIGSOFT International Symposium on Software Testing and Analysis .
ACM, 2017, pp. 295‚Äì306.
[60] R. Paletov, P. Tsankov, V . Raychev, and M. Vechev, ‚ÄúInferring crypto api
rules from code changes,‚Äù in Proceedings of the 39th ACM SIGPLAN
Conference on Programming Language Design and Implementation .
ACM, 2018, pp. 450‚Äì464.
877
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:39:03 UTC from IEEE Xplore.  Restrictions apply. 