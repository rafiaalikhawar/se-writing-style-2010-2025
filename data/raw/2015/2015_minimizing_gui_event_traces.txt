Minimizing GUI Event Traces
Lazaro Clapp
lazaro@stanford.eduOsbert Bastani
obastani@cs.stanford.edu
Saswat Anand
saswat@cs.stanford.eduAlex Aiken
aiken@cs.stanford.edu
Stanford University
Stanford CA, USA
ABSTRACT
GUI input generation tools for Android apps, such as An-
droid’s Monkey [13], are useful for automatically producing
test inputs, but these tests are generally orders of magni-
tudelargerthannecessary, makingthemdiﬃcultforhumans
to understand. We present a technique for minimizing the
output of such tools. Our technique accounts for the non-
deterministicbehaviorofmobileapps, producingsmallevent
traces that reach a desired activity with high probability.
We propose a variant of delta debugging [36, 38], aug-
mented to handle non-determinism, to solve the problem
of trace minimization. We evaluate our algorithm on two
sets of commercial and open-source Android applications,
showing that we can minimize large event traces reaching a
particular application activity, producing traces that are, on
average, less than 2% the size of the original traces.
CCS Concepts
•Software and its engineering →Software testing
and debugging;
Keywords
testing; trace minimization; delta debugging; Android
1. INTRODUCTION
Test cases are time consuming to write, especially for ap-
plications dealing with rich graphical user interfaces (GUIs).
Many properties can only be reliably tested once the pro-
gram has reached a particular state, such as a speciﬁc screen
or view in its GUI. Part of the challenge of GUI testing is in
creating a sequence of user interactions that cause the pro-
gram to reliably reach a target GUI state, under which the
test one cares about can be performed. Automatically gen-
erating a sequence of GUI events to reach a particular point
in the program is a diﬃcult problem to solve in general.
In many cases, it is possible to reach the desired point
in an application by randomly generating GUI events until
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
FSE ’16 November 13-19, 2016, Seattle, WA, USA
c/circlecopyrt2016 ACM. ISBN 978-1-4503-2138-9.
DOI:10.1145/1235the right view is displayed, or by capturing and replaying
the GUI events generated by a user, or a human tester, in-
teracting with the application. However, these randomly
generated or tester-captured event traces generally contain
more interactions than necessary to reach the desired state.
Furthermore, traces generated by capture and replay of con-
crete user interactions might not be robust in the face of ap-
plication non-determinism, and thus might break if the pro-
gramchangesbehavior, evenslightly, betweenexecutions. In
modern mobile and web apps, which often include internal
A/Btestinglogicandpersonalization, GUInon-determinism
is a common obstacle for simple capture and replay systems.
In this paper, we:
•Present an algorithm basedondelta-debugging [36, 38]
tominimizeatraceofGUIevents. Ouralgorithmisro-
bust to application non-determinism. When the appli-
cation is deterministic, the output trace is 1-minimal,
meaning no element of the trace can be removed with-
out changing the behavior we care about [38].
•Minimization proceeds by checking whether subtraces
of a trace still reach the desired state. This prob-
lem is highly parallelizable, but it is not obvious how
to take maximal advantage of the information gained
from each subtrace trial (see Section 4). We deﬁne
the subtrace selection problem and provide an eﬃcient
heuristic, as well as an optimal solution based on the
problem’s characterization as a Markov Decision Pro-
cess (MDP).
•We show the eﬀectiveness of the above techniques in
minimizing randomly generated traces for two repre-
sentative datasets: one set of popular Android apps
taken from the Google Play Store, and a set of open-
source apps from the F-droid application repository.
Section 2 provides a brief overview of the problem of GUI
traceminimizationinthefaceofapplicationnon-determinism ,
the relevant characteristics of the Android platform, and a
motivating example for our technique. Section 3 describes
our trace minimization algorithm while Section 4 explores
the problem of subtrace selection embedded in the algo-
rithm’sinnerloop, includingthecharacterizationasaMarkov
Decision Process (4.3). Section 5 presents our results, con-
trasting the performance of diﬀerent solutions to the sub-
trace selection problem. Finally, Section 6 brieﬂy describes
related work and Section 7 presents our conclusions.2. PROBLEM OVERVIEW
The GUI of an Android application (also called an app),
consists of a set of activities . Each activity corresponds to
a top-level view (e.g., a page) of the user interface. Addi-
tionally, each app has one main activity , which is the ﬁrst
one invoked when the app is launched. In the course of
interacting with an application’s GUI, the user commonly
transitions between diﬀerent activities, as actions in one ac -
tivity trigger another activity.
A GUIevent trace is a sequence of user interface events
such as screen taps, physical keyboard key presses and com-
plete multi-touch gestures. One way to obtain such a trace
is to record the actions of a user. Another option uses a
random or programmatic input generation tool to generate
the trace without human involvement. In our experiments,
we took the second approach, using Monkey [13], a standard
ﬁrst-party random input generation tool for Android.
Monkeytracescanbegeneratedbasedonlyonthenumber
and types of desired events, then replayed for a particular
app. By generating multiple large random traces for each
app under test, we are able to reach various activities within
the app. These traces could conceivably serve as system
tests for the app, especially if augmented by state checks
or log monitoring. However, using automatically generated
traces as tests can be problematic for the following reasons:
1. Because traces are randomly generated, the majority
of the events do not trigger any interesting app behav-
ior (e.g. they are taps on inactive GUI elements), or
trigger behavior unrelated to the functionality we care
about for a given test. Large random event traces are
hard for humans to interpret, particularly if most of
the trace is irrelevant for the desired behavior. The
traces produced by Monkey typically consist mostly of
irrelevant events.
2. Replaying a large trace is a time consuming process, as
a delay must be introduced before sending each event
to the app, to ensure previous events have been fully
processed. In our experiments, we set this delay to 4
seconds, which we found necessary to allow for events
that trigger network requests or other expensive oper-
ations to be fully handled by the app before the next
event is triggered.
In summary, given a large event trace, we would like to
ﬁnd a minimal subtrace that triggers the same app behav-
ior. In particular, we focus on subtraces that reach the same
activity. If we assume that the app is deterministic in the
sense that the same event trace always visits the same ac-
tivities in the same order, then the algorithm from Section 3
extracts, from a given event trace that reaches a particular
activity, a 1-minimal subtrace that reaches that activity.
Note that we use activity reachability as a proxy for un-
covering user triggered behavior in the app. All the tech-
niques and checks in this paper apply just as well if the
behavior we seek to trigger involves reaching the execution
point of a particular GUI widget callback or the point at
which a particular web request is sent. We only require that
we have a small ﬁnite set of behaviors that shall be trig-
gered in the app, so that every system test is built on top
of a minimal trace triggering that behavior.2.1 Trace minimization example
One of the apps we use for our experiments (see Section 5)
is Yelp’s Eat24 ( com.eat24.app.apk ), a popular commercial
food delivery app. To generate minimized traces that reach
this app’s activities, we run the app on an Android emula-
tor and use Monkey to generate multiple GUI event traces.
Each trace consists of 500 single-touch events at random co-
ordinates within the app’s portion of the screen. To capture
non-determinism in the app, we replay each trace multiple
times (we use 20 repetitions), clearing any local data or app
state in the device between replays.
For a particular trace Twe generated, the activity Logi-
nActivity is always reached by replaying Ton this app.
LoginActivity is a relatively easy to reach activity for this
particular app, as there are at least two ways to launch this
activity immediately from the app’s main activity: either
by clicking on an item in the application’s menu or on the
lower portion of the app’s home screen (which displays rec-
ommendations if the user is already logged in). The second
method requires only a single GUI event: the click on the
bottom of the screen. However, approximately 50% of the
timewhentheappislaunchedfromacleaninstall, itshowsa
dialog asking for the user’s address and zip code. This dialog
blocks interaction with the main activity and, in our set-up,
automatically brings up Android’s software keyboard. Dis-
missing the dialog is as simple as clicking anywhere in the
screen outside the dialog and the virtual keyboard. How-
ever, this does not dismiss the keyboard itself, so the state
of the screen is diﬀerent than if the dialog had never ap-
peared. After dismissing the dialog, it is still possible to
navigate to the LoginActivity with one more click, but the
area of the screen that must be clicked is diﬀerent than if
the dialog had never appeared at all.
Suppose now we wanted to manually select, out of the
500 events T, a minimal subtrace T′such that replaying
the events of T′in order reaches the LoginActivity activ-
ity regardless of whether the app shows the location dialog
or not. This subtrace must exist, since the original trace
always reaches LoginActivity (among other activities), in
both cases. However, we cannot simply select the single click
subtrace that would launch LoginActivity if the dialog is
not present, since it won’t work when the dialog does ap-
pear. We have the same problem if we focus on picking the
two clicks when the dialog appears, as such a trace does not
necessarily work when the dialog is absent. For example,
most clicks that would simply dismiss the dialog might also
trigger diﬀerent behavior if the dialog is missing by clicking
on active GUI widgets underneath the dialog.
This sort of behavior is not exclusive to the EAT24 app.
In fact, many Android apps behave non-deterministically,
either because of internal A/B testing logic or just because
of the non-determinism of the app’s external environment.
We could always manually write GUI testing scripts that are
aware of the app’s speciﬁc non-determinism and generate
diﬀerent GUI events when faced with diﬀerent app states.
However, as we will show, it is possible to automatically
generate small subtraces that are robust against application
non-determinism, while still treating the app itself as a blac k
box. We require only a way to run subtraces on top of the
appfromaninitialstatemultipletimesandlisttheactivitie s
being reached.
Figure 1 shows the execution of a 3 event trace – the
minimal subtrace obtained by the technique in this paperFigure 1: Reaching LoginActivity oncom.eat24.app.apk
– that accomplishes our goal without checking at any point
the state of the application’s GUI. If there is no location
dialog, the ﬁrst event in the trace triggers the direct tran-
sition to LoginActivity by clicking on the bottom of the
screen. The second and third events click inactive areas
of theLoginActivity GUI layout, having no eﬀect in this
case. If the dialog appears, the ﬁrst click hits a portion of
the virtual keyboard layout, typing a whitespace character
into the location dialog. The second click immediately dis-
misses the dialog without using the whitespace character.
Finally, the third click happens in the new location of the
panel that launches LoginActivity , without dismissing the
keyboard1. Thus, whether or not the dialog appears, the
script will reach LoginActivity and stop there. It is worth
noting that at no point is our technique aware of the dialog;
it only knows that this script reaches LoginActivity with
high probability over multiple runs of the app.
3. MINIMIZATION ALGORITHM
In this section we present our trace minimization algo-
rithm and discuss its basic properties. Our algorithm is
based on Zeller’s delta debugging algorithm (see [38]), refor-
mulated for our problem and augmented to deal with appli-
cation non-determinism.
Intuitively, delta debugging starts with a large input se-
quence that passes a particular test oracle and attempts to
remove part of the sequence at every step, such that the
remaining subtrace still passes the oracle. This is repeated
until we have a 1-minimal subtrace that is accepted by the
oracle. A 1-minimal subtrace with property Psatisﬁes P,
but removing any single element does not satisfy P.
Our version of delta debugging takes as input an An-
droid app A, a trace T(which is an ordered sequence T=
{e0,e1,...}of GUI events) and a target activity awithin
A. A subtrace T′ofTis a subsequence of T. The algo-
rithm has access to a test oracle O(A,T,a), which consists
of starting a new Android emulator, installing A, running
traceTonAand verifying that awas launched during that
execution. The oracle returns either 0 (the target activity
awas not reached) or 1 (activity awas reached). Because
of application non-determinism, our test oracle may accept
1Transitioning between activities does dismiss the keyboard ,
so we don’t need to do so explicitly.globals : O,n,nr,st
1defND3MIN(A,T,a):
2 return MinR(A,T,a,n);
3defMinR(A,T,a,k ):
4 size←len(T)/k;
5 foriinrange(0,k):
6 Ti←T[i∗size: (i+1)∗size];Ti←T\Ti;
7 Tsub←get_passing( A,{∀i∈[0,k).Ti},a);
8 ifTsub/\⌉}atio\slash=None:
9 return MinR(A,Tsub,a,n);
10 Tcompl←get_passing( A,{∀i∈[0,k).Ti},a);
11 ifTcompl/\⌉}atio\slash=None:
12 return MinR(A,Tcompl,a,max(k−1,2));
13 ifk <len(T):
14 return MinR(A,T,a,min( 2k,len(T)));
15 returnT;
16defget_passing( A,S,a):
17 if∃Tc∈S.passes(A,Tc,a):
18 returnTc;
19 return None ;
20defpasses(A,T,a):
21 s←0;
22 foriinrange(0,nr):
23 s←s+O(A,T,a);
24 returns≥st;
Figure 2: ND3MIN: Non-Deterministic Delta Debug-
ging MINimization.
a trace with some probability p, and reject it with prob-
ability 1−p. Fixing Aanda, we deﬁne the probability
PT=Pr[O(A,T,a) = 1], which is the trace’s underlying
probability of reaching awhen run on app A.
Figure 2 shows the pseudo-code for the general form of
our trace minimization algorithm ( ND3MIN). Besides A,T
anda, the algorithm uses 4 global parameters: the oracle
O, a starting number nof subtrace candidates to test, a
number of times to run each candidate ( nr) and the success
threshold required to accept it ( st).
For the algorithm to select a particular subtrace T′at the
endofanyminimizationstep, calling O(A,T′,a)nrtimesre-
sults in the oracle returning 1 at least sttimes. This require-
ment is enforced by function passes() in line 20. We say
that a trace is successful if it passes the check in passes() .
Function get_passing() in line 16 takes a set Sof subtraces
and selects a subtrace Tc∈Ssuch that passes(A,Tc,a)re-
turns true. It returns None iﬀ no such subtrace exists insetS. Note that get_passing() speciﬁes no order in which
traces are passed to passes() . We assume oracle calls are
expensive but we have the ability to make multiple oracle
callsinparallel. InSection4, weusetheﬂexibilityinthedef-
inition of get_passing() to minimize the number of rounds
of (parallel) calls to Orequired by our algorithm.
ND3MIN() calls the recursive function MinR()which uses
the two helper functions described above to implement our
version of delta debugging. MinR()follows the classic struc-
ture of delta debugging. First (lines 4–6), it partitions trace
Tinksubtraces Tiof contiguous events of roughly equal
size (starting with k=non the ﬁrst recursive call). It also
generates the complement of each subtrace Ti, deﬁned as
Ti←T\Ti. It then proceeds in four cases:
Case #1: If any candidate subtrace Tiis successful, the
algorithm selects that Tias its new current trace T,
and calls itself recursively with k=n(lines 7–9).
Case #2: Otherwise, if any complement subtrace Tiis suc-
cessful, the algorithm selects that Tito be the next T.
Ifk≥3,k=k−1 before the next recursive call, oth-
erwise it is set to 2 (lines 10–12). Reducing kby 1
ensures that the candidate subtraces Tigenerated in
the next call will be a subset of those in this call, so the
algorithm will keep reducing to complement subtraces
untilk= 2 or no Tiis successful. Note that when
k= 2, both the set of candidate subtraces and that of
complements are identical ( T0=T1andT1=T0).
Case #3: Ifkis smaller than the number of events left
inT, we double the number of partitions, up to k=
len(T) (lines 13–14). Note that when we reach k=
len(T), this implies that on the next recursive call,
every subtrace consists of a single event.
Case #4: Otherwise, return Tas our minimized subtrace
Ideally, we would like to show that, given a probability
(lower) bound pb, ifPT≥pbandTmin=ND3MIN(A,T,a)
then, with high probability, Tminis a 1-minimal subtrace of
Tsuch that PTmin≥pb. Unfortunately, this is not possible.
Toseewhy, imagine ∃T′/subsetnoteqlTmin,PT′=pb−δ. Asδ→0, the
number of checks required to distinguish T′from a subtrace
which fulﬁlls PT′≥pbgrows without bound. If T′can
be obtained from Tminby removing a single event, then
testingTminfor 1-minimality must take unbounded time.
We consider instead the following property:
Definition 1.A traceTisapproximately1-minimal with
respect to the bound pband distance ǫ, ifPT≥pb−ǫ, and
any subtrace T′which can be obtained by removing a single
event from Tis such that PT′< pb.
We would like to bound the probability that ND3MINre-
turns an approximately 1-minimal trace with bound pb=
st/nrand distance ǫ. We would ﬁrst like to show that if
PT≥pbandTmin=ND3MIN(A,T,a), then, with high prob-
ability,PTmin≥pb−ǫfor a small ǫ. Given a single indepen-
dent subtrace T′, if the check X=passes(A,T’,a)returns
true, then the probability that PT′≥px, for a given px, is:˜p=Pr[PT′≥px|X] (1)
=/integraldisplay1
0Pr[PT′≥px|X,PT′=p]·fPT′|X(p)dp(2)
=/integraldisplay1
pxfPT′|X(p)dp (3)
wherefPT′|X(p) is the probability density of PT′givenX.
Note that Pr[PT′≥px|PT′=p] is 1 if p≥px, and 0
otherwise. By Bayes’ theorem:
˜p=/integraltext1
pxPr[X|PT′=p]·fPT′(p)dp
Pr[X](4)
=/integraltext1
pxPr[X|PT′=p]·fPT′(p)dp
/integraltext1
0Pr[X|PT′=p]·fPT′(p)dp(5)
By deﬁnition of X=passes(A,T’,a):
Pr[X|PT′=p] =nr/summationdisplay
i=st/parenleftBigg
nr
i/parenrightBigg
·pi(1−p)nr−i(6)
Note that if we assume a discrete probability distribution,
we can replace the integrals above by sums over p, and the
density functions fPT′(p) by probabilities Pr[PT′=p]. Us-
ing this approximation and plugging the parameters nr= 20
andst= 18, as well as the (discrete) prior probability dis-
tribution Pr[PT′=p] obtained experimentally (see Section
5), we have Pr[PT′≥0.85|passes(A,T’,a)]>0.95. So,
selecting pb= 0.9 andǫ= 0.05 would at ﬁrst seem like an
option to prove a bound on the probability of PTmin≥pb−ǫ.
Unfortunately, most executions of our algorithm perform a
largenumberofcallsto passes() , andtheerroraccumulates
rapidly. After just 20 calls, the naive bound on Pr[PTmin≥
0.85] in our example would become 0 .9520≈0.36. Bound-
ing the error in our algorithm more tightly is non-trivial.
Instead, when running our experiments, we perform a ﬁnal
independent check, calling passes(A,Tmin,a)one last time
on the ﬁnal output of our algorithm. In Section 5 we ob-
serve that this ﬁnal check passes often. For the minimized
traceswherethisﬁnalchecksucceeds, wecanindeedsaythat
PTmin≥0.85 with probability >0.95, as per the example
above, which uses our experimental parameters.
We can now get a bound on the probability of the second
requirement in the deﬁnition of approximate 1-minimality:
Lemma 1.IfTmin=ND3MIN(A,T,a), then the probabil-
ity/hatwidepthat there exists no subtrace T′, obtained by removing
a single event from Tmin, such that PT′≥pbis:
/hatwidep=
1−/integraldisplay1
pb/parenleftigg
1−nr/summationdisplay
i=st/parenleftignr
i/parenrightig
·pi(1−p)nr−i/parenrightigg
·fPT′(p)dp
/integraldisplay1
0/parenleftigg
1−nr/summationdisplay
i=st/parenleftignr
i/parenrightig
·pi(1−p)nr−i/parenrightigg
·fPT′(p)dp
l
wherelis the number of events in Tmin.
Proof. Consider only the last call to the recursive pro-
cedureMinR(), which returns Tmin. Note that MinR()re-
turnsTminonly in Case #4 which executes only when cases
#1 to #3 are not satisﬁed. Thus, for the last execution
ofMinR(), Case #3 must have been skipped, which meansk≥len(Tmin). Since k≥len(Tmin), the set{∀i∈[0,k).Ti}
contains every subtrace which can be obtained by removing
a single event from Tmin. Because Case #2 was also not
satisﬁed, we know that calling get_passing() on this set at
line 10 returns None. By deﬁnition, this is equivalent to
callingpasses() on eachTiand having it return false.
TakingYi=¬passes(A,Ti,a), we have:
Pr[Yi|PTi=p] = 1−nr/summationdisplay
i=st/parenleftBigg
nr
i/parenrightBigg
·pi(1−p)nr−i(7)
And, using steps analogous to equations 1 to 5 above:
/hatwidepi=Pr[PTi≥pb|Yi] (8)
=/integraltext1
pbPr[Yi|PTi=p]·fPTi(p)dp
/integraltext1
0Pr[Yi|PTi=p]·fPTi(p)dp(9)
which is the probability Pr[PTi≥pb] for each Tigiven the
behavior of passes() the algorithm must have observed.
Finally, the probability that no Tiis such that PTi≥pb
is given by/hatwidep=/producttext
Ti(1−/hatwidepi) which expands to the formula
for/hatwidepgiven in the lemma’s statement, since the formula for
/hatwidepiis the same for every Ti, and there are l=k= len(Tmin)
such subtraces.
4. TRACE SELECTION
Recall that the method get_passing() takes a set Sof
subtraces of T, and must return a subtrace Tc∈Ssuch
that calling the oracle O(A,Tc,a)nrtimes would succeed
sttimes. If no such Tc∈Sexists,get_passing() must be
able to determine that and return None. Calls to oracle O
are time consuming, so we wish to minimize the number of
such calls that execute non-concurrently. We assume that
we have a maximum of minstances of Owhich can be run in
parallel. In our implementation, these represent individual
instances of the Android emulator.
For each call to get_passing() , we have a set of ntraces
S={T0,...,Tn−1}. We deﬁne a schedule as an array sch=
[v0,...,vn−1]suchthat/summationtextn−1
j=0vj≤m. Astepfor get_passing()
consists on generating a new schedule sch, running vjoracle
callsO(A,Tj,a) for each j∈[0,n−1] and capturing the re-
sults. Since the total number of calls to Ois at most m, the
calls corresponding to a single step of get_passing() can
be executed in parallel. We accumulate the results of all
steps before the current one as pairs ( sj,fj), where sjis the
number of successes seen so far for Tj(i.e. 1 was returned by
O(A,Tj,a)) andfjthe number of failures (0 was returned).
We can see that given the deﬁnition of get_passing() , we
never gain anything from running a single Tjmore than nr
times, soweforbidthis, andthus ∀j.sj+fj≤nr. Weseekto
minimize the number of steps in each call to get_passing()
before we can either identify a Tjwhich satisﬁes passes()
(i.e.∃j.sj≥st) or we have concluded that no such Tjcan
exist. We note that, given the previous constraints, if ever
fj>nr−st,Tjcannot be a trace that satisﬁes passes() .
We give 3 strategies for minimizing the number of steps
ofget_passing() . Section 5 compares them empirically.
4.1 Naive Scheduling
There are two obvious ways to generate the schedule sch
at every step of get_passing() , which depend very little onthe observed pairs ( sj,fj).
The ﬁrst method is to schedule all nrexecutions for each
trace one after the other, so at every step vj=min(nr−
sj−fj,m−/summationtextk<j
k=0vk). This strategy goes from j= 0 ton−1
and greedily tries to add another execution of Tjtoschuntil
doing so would either mean that more than nrexecutions of
Tjhave been scheduled over all steps of get_passing() or
would push the schedule beyond the limit of mcalls toO.
A common sense optimization is, at every step, to return
immediately if a Tjwithsj≥sthas been found, and ignore
anyTjwithfj>nr−stfor scheduling. The worst-case for
this strategy happens when no trace in Ssatisﬁespasses() .
The following is a particular example of this greedy strategy
in action with nr= 20,st= 18,n= 3 and m= 15. We
represent each step as a transition between two lists of pairs
(sj,fj)∀j= 1,2,3, representing the accumulated results
before and after the step. Each step is also annotated with
the corresponding schedule sch:
[(0,0),(0,0),(0,0)]− − − − − →
15,0,0[(13,2),(0,0),(0,0)]
[(13,2),(0,0),(0,0)]− − − − − →
5,10,0[(17,3),(3,7),(0,0)]
[(17,3),(3,7),(0,0)]− − − − − →
0,0,15[(17,3),(3,7),(15,0)]
[(17,3),(3,7),(15,0)]− − − − →
0,0,5[(17,3),(3,7),(19,1)]
Another naive strategy is to schedule traces in a round–
robin fashion. Each step scans j= 0 ton−1 multiple times,
adding an additional invocation of Tjifsj+fj+vj≤nr
andfj≤nr−st. It stops when the schedule is full ( mcalls
scheduled) and proceeds to run sch. Again, we stop as soon
as there is nothing else to run or we have found a Tjwith
sj≥st. The worst-case for this strategy happens when all
traces succeed with high probability. We repeat the example
above with the round–robin strategy:
[(0,0),(0,0),(0,0)]− − − − →
5,5,5[(4,1),(2,3),(5,0)]
[(4,1),(3,2),(5,0)]− − − − →
8,0,7[(11,2),(2,3),(12,0)]
[(11,2),(2,3),(12,0)]− − − − →
7,0,8[(17,3),(2,3),(19,1)]
Both of these naive strategies are similar in that they are
likely to do plenty of unnecessary work in the average case.
We chose the round–robin variant as our baseline for com-
parison, since it performs better in the case in which is com-
mon for many of the traces in Sto fail the oracle often and
stis close to nr(this matches our scenario).
4.2 Heuristic: Exploration followed by greedy
The naive algorithms don’t exploit all of the information
contained in the pairs ( sj,fj) in deciding what to do next.
Clearly, if we have a trace Tj1for which ( sj1,fj1) = (5,0),
andatrace Tj2forwhich( sj2,fj2) = (3,2), thenTj1issignif-
icantly more promising than Tj2, and we should try checking
it ﬁrst. Conversely, it should be possible to discard Tj2by
scheduling it for execution only a few more times; adding
15 copies of Tj2to the next schedule, while allowed, would
likely be a waste. We use these observations to propose a
heuristic that, at every step: a) tries to conﬁrm traces that
seem likely to be successful, and b) tries to discard traces
that seem likely to be unsuccessful, in that order of priority.
Before scheduling the ﬁrst step, we have ∀j.(sj,fj) =
(0,0). Since we have no information, we simply schedule
the traces in Sin a round–robin fashion. This gives us at
least some information about every Tj. In every round after
that, we follow the algorithm outlined in Figure 3.globals : c
1defschedule( S,[(sj,fj)]):
2∀j.vj←0;
3∀j.pj←sj/(sj+fj);
4 sortSbypj,sjdesc;
5 Sc←[Tj∈S|pj≥c];
6 Sd←∅;
7 Sf←[Tj∈S|pj< c];
8 while/summationtext
jvj< m:
9 ifSc/\⌉}atio\slash=∅:
10 Tk←remove_first( Sc);
11 xk←min(nr−sk−fk,⌈(st−sk)/pk)⌉);
12 ifxk≤m−/summationtext
jvj:
13 vk←xk;
14 elifxk≤m:
15 Sd←Sd∪[Tk];
16 else:
17 vk←m−/summationtext
jvj;
18 elifSd/\⌉}atio\slash=∅:
19 Schedule from Sdby round–robin.;
20 elifSf/\⌉}atio\slash=∅:
21 Tk←remove_first( Sf);
22 yk←min(nr−sk−fk,⌈(nr−st+1)−fk
(1−pk)⌉);
23 vk→min(yk,m−/summationtextvj);
24 else:
25 Schedule from original Sby round–robin.;
Figure 3: Trace selection heuristic.
We ﬁrst compute pj=sj/(sj+fj) for each j, the empiri-
cal success probability of Tjso far. We sort Sin descending
order, ﬁrst by pjand then by sj. Then we partition the
sorted array Sinto two sections: Sccontains the traces such
thatpj≥cfor a certain constant c(c= 0.8 in our imple-
mentation) and Sfthe rest. We assume that traces in Sc
are likely to succeed after nrcalls toO, while traces in Sf
are likely to fail, and we predict accordingly. While there
are traces in Sc, and our schedule is not full, we remove Tk
fromScin order. We compute xkin line 11, which is the
expected number of runs of Tkneeded to get to the point
wheresk=st. If we can schedule that many runs, we do
so (line 13). If we can’t schedule xkruns ofTkin this step,
but we can do it in the next step, we move TktoSd, a list
of ‘deferred’ traces from Sc. We do this so that if we can
pack the expected number of runs for multiple traces in Sc
we do so, even if those aren’t the traces with the highest pj.
Ifxkis too large to schedule in any single step, then we just
schedule as many copies of Tkas we can.
Only when Scis empty, we revisit the traces in Sdand
schedule them in round–robin fashion. If there are no traces
inSdthen we begin removing TkfromSfin order. We
compute ykin line 22 for these traces, which is the ex-
pectednumberofrunsof Tkneededtogettothepointwhere
fk=nr−st+1 (at which time we can declare that trace as
failingpasses() ). We could run the traces in Sdin order of
increasing empirical success probability, which would allow
us to discard some of them more quickly, but this doesn’t re-
duce the expected number of steps for get_passing() , since
we need to discard all traces before we can return None. We
run them in order of the decreasing probability instead, as
this will allow us to more quickly correct course in the rare
case in which we have misclassiﬁed a passing trace as being
inSd: after running a few more copies of the trace, instead
of discarding it, we would observe its empirical probability
increasing, and we reclassify it into Scon the next step.
If there is space left in the schedule after scheduling Sc,SdandSfas described, we add additional runs of the traces
inSin a round–robin fashion, that is, copies beyond the ex-
pected number of executions required to ‘prove’ or ‘disprove’
eachTj, but without running any Tjmore than nrtimes.
We show the execution of our heuristic on our same ex-
ample from the previous two techniques:
[(0,0),(0,0),(0,0)]− − − − →
5,5,5[(4,1),(2,3),(5,0)]
[(4,1),(2,3),(5,0)]− − − − − →
2,0,13[(6,1),(2,3),(18,0)]
4.3 Solving trace selection as an MDP
WecanformulatetheproblemoftraceselectionasaMarkov
Decision Process (MDP), which allows us to solve for the op-
timal strategy, for given values of the parameters n,m,nr,st.
AMarkovDecisionProcessisatuple( S,A,P,γ,R), where:
Sis a set of states, Ais a set of actions and P:S×A→
{Pr[S]}isamapfromeverystateandactionpairtoaproba-
bility distribution over possible state transitions. R:S→R
is the reward function, which associates a value with reach-
ingeachstate. Finally, γ∈[0,1]iscalledthediscountfactor.
To execute an MDP, we start from some initial state σ0∈
S, then choose an action a0∈A. The MDP then transitions
to a state σ1chosen at random over the probability distri-
butionP(σ0,a0). The process is then repeated, selecting a
newaifor each σiand choosing σi+1from the distribution
P(σi,ai). The value of the execution of the MDP is then/summationtext
iγiR(σi), which is the reward of each state visited, mul-
tiplied by γi. The discount factor γis used to decrease the
reward of reaching“good”states, in proportion to how late
in the execution these states are reached.
Given a policy π:S→A, which is simply a mapping
from states to actions, we calculate the value of the policy
as the expected value Vπ(σ0) =E[/summationtext
iγiR(σi)] where σ0is
the initial state, and for every i≥0,ai=π[σi] andσi+1
is chosen from P(σi,ai). Solving an MDP is equivalent to
ﬁnding a policy πthat maximizes Vπ(σ0).
We encode trace selection as an MDP as follows:
•S={[(s0,f0),...,(sn−1,fn−1)]}is the set of possible
combinations of observed values of ( sj,fj) for each
Tj∈S. The initial state is σ0= [(0,0),...,(0,0)]
•A={[v0,...,vn−1]|/summationtextn−1
j=0vj≤m}is the set of possi-
ble schedules sch.
•P(σi,a)[σj] whereσi= [(si0,fi0),...],a= [v0,...] and
σj= [(sj0,fj0),...]with∀k.(sjk+fjk)−(sik+fik) =vk
is:
n−1/productdisplay
k=0/summationdisplay
p/parenleftBigg
vk
sδ/parenrightBigg
psδ(1−p)(vk−sδ)Pr[PTk=p]
withsδ=sjk−sik.P(σi,a)[σj] is 0 if∃k.(sjk+fjk)−
(sik+fik)/\⌉}atio\slash=vk.
•R(σ′) is−1 for every state σ′, andγ= 1
We make the reward negative and the discount factor 1,
since we wish to ﬁnd only a policy that minimizes the num-
ber of reached states, which is equivalent to minimizing the
number of steps in get_passing() . Any state containing
(sj,fj) withsj≥stfor anyj, as well as any state where
fj>nr−stfor every j, is a terminal state of the MDP: once
such a state is reached, the execution of the MDP ends.Note too that the precise deﬁnition of P(σi,a)[σj] requires
knowledge of Pr[PTk=p] for each subtrace Tk. But we have
no way of precisely knowing this distribution. In practice, if
we have a prior (discrete) probability distribution Pr[PT′=
p] over the set of all possible subtraces, we can approximate:
Pr[PTk=p] =/summationdisplay
p/parenleftBigg/parenleftBigg
sk+fk
sk/parenrightBigg
psk(1−p)fk/parenrightBigg
Pr[PT′=p]
InSection5, weapproximatethepriorbyrunning ND3MIN()
with naive round–robin trace selection on a few (app, trace,
activity)tuples. Weusethatexperimentallydiscoveredprior
to approximate P(σi,a)[σj].
TherearemethodsforsolvinganMDPinthegeneralcase,
but they require iterating multiple times over the set Sand
calculating the expected value Vπ(σ′) of each state based on
the value of other states, until a ﬁx-point is reached. In our
formulation, the number of states, enumerated naively, is:
|S|=/parenleftBiggk≤nr/summationdisplay
k=0(k+1)/parenrightBiggn
=/parenleftbigg(nr+1)(nr+2)
2/parenrightbiggn
since we can construct k+1 pairs ( sj,fj) withsj+fj=k.
Forn= 5 (nr= 20), this gives us over 6 ×1011states.
We can signiﬁcantly optimize our solution for this par-
ticular MDP in two ways, however: by getting rid of the
ﬁx-point iteration requirement (changing it to a single pass
overS), and by reducing the size of Sitself.
First, we observe that in our MDP we can never visit the
same state twice. In fact, our MDP is a DAG, where each
statemusttransitiontooneinwhichthesumoftheelements
of the tuples ( sj,fj) has a higher value. This type of MDP
is called a ﬁnite horizon MDP [17].
We now restrict all candidate policies πto include only
schedules for which/summationtextn−1
j=0vj=mexactly, except in the case
in which doing so would violate the constraint ∀j.sj+fj≤
nr. In the latter case, every πalways chooses to schedule as
many runs of each Tjas needed to reach nr. We note that
this last action must always lead to a ﬁnal state.
Every state σ′= [(s0,f0),...,(sn−1,fn−1)] reachable from
the initial state σfollowing any πwith the above restric-
tions, is either a ﬁnal state or is such that/summationtextn−1
j=0(sj+fj)
modm= 0. We then deﬁne I, the state’s iteration, such
thatI[σ′] =/parenleftBig/summationtextn−1
j=0(sj+fj)/parenrightBig
/mfor every non-ﬁnal state.
I[σ′] is always an integer. We assign all ﬁnal states to iter-
ationI[σ′] =⌈nr×n
m⌉. We note that for every σi∈S,πas
above, and σj∈P(σi,π[σi]) we have I[σj]> I[σi].
Given the partition of Sinto subsets Si={σ∈S|I[σ] =
i}induced by I, we can solve the MDP by visiting each Si
once in reverse order of iand computing the optimal π[σ′]
andVπ(σ′) for each σ′∈Si. We do not need to iterate to
reach a ﬁx-point, since
Vπ(σ′) =R(σ′)+maxa∈A/summationdisplay
σ′′/parenleftbig
P(σ′,π[σ′])[σ′′]/parenrightbig
Vπ(σ′′)
depends only on the values Vπ(σ′′) of states reachable from
σ′by actions in π. Since all such states satisfy I[σ′′]>
I[σ′], their value has already been calculated when visiting
a previous Sj>i. The time to solve the MDP by this method
isO(|A||S|). Note that within a single Si, the problem of
computing Vπ(σ′)forthestatesin Siishighlyparallelizable.We can further reduce |S|by merging states which are
isomorphic in our model. First, we can coalesce all ﬁnal
states into two: a success state σswhenever sj≥stfor
anyj, and a failure state σfwhenfj>nr−stfor every
j. Furthermore, if state σ′hasfj>nr−stfor anyj, this
is equivalent (for the purposes of get_passing() ) to the
same state after replacing ( sj,fj) with ( X,Y) withY >
nr−st. We pick a single state in this equivalence set as
representative, takingcare tochooseone whichpreservesthe
invariant/summationtextn−1
j=0sj+fjmodm= 0 and falls into the latest
possible iteration. We can also reorder the tuples ( sj,fj) in
every state, since the order of the subtraces in Sdoes not
aﬀect the result of get_passing() , and the generated policy
πwill be identical, up to a reordering of a′=π[σ′]. After
applying all optimizations, for n= 5,m= 15,nr= 20 and
st= 18, our algorithm must examine |S′|= 729,709 states
in order to compute the optimal strategy π.
After pre-computing πfor a particular set of parameters
n,m,nr,st, we can use it to generate a schedule schat each
step of the trace selection process. Section 5 compares the
number of steps required by get_passing() when using this
strategy versus our heuristic from Section 4.2.
5. RESULTS
This section presents our empirical evaluation and results.
Section 5.1 describes our experimental setup and presents
the data discussed in the rest of the section. Section 5.2 ex-
plores the size of the minimized subtraces and the number of
calls toget_passing() performed by the algorithm. Section
5.3 contrasts the performance of the diﬀerent trace selec-
tion methods of Section 4. Finally, Section 5.4 explores the
prevalence of application non-determinism in our dataset.
Our tests were performed in an Amazon EC2 cloud en-
vironment, in which we ran m= 15 Android emulator in-
stances, each on its own virtual machine, as our test oracles.
As mentioned before, the rest of the parameters used for
ND3MIN() aren= 5,nr= 20 and st= 18.
5.1 Datasets
We evaluate our event trace minimization approach on
two diﬀerent datasets: one composed of 7 applications from
the Google Play store selected among the top 20 most pop-
ular apps in their category across diﬀerent app categories
(gplay), and another of 4 redistributable open-source appli-
cations from the F-droid open-source application repository
(fdroid). For each application, we generated 10 random
Monkey traces, of 500 events each, restricting ourselves to
tap events exclusively. Although our approach can poten-
tially be used to minimize traces with any type of events,
reaching activities requiring events other than taps, such as
structured keyboard input or complex touch gestures, often
produces an unfeasibly large original trace when performing
random testing alone.
We ran these traces on the corresponding application and
recorded the activities reached during their execution. For
the Google Play apps, we arbitrarily selected an average of
4 such activities per app, with the minimum being 3 activi-
ties. For the F-Droid dataset, we selected an average of 5.25
activities per app, with a minimum of 3. For each app A,
and activity a, we took a trace Tin our 10 generated traces
which reached awithPT≥0.9 (observed over 20 trace re-
plays). In the cases where many traces reached awith equal
probability, we picked one at random. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
0.00.050.10.150.20.250.30.350.40.450.50.550.60.650.70.750.80.850.90.951.0Proportion of traces with probability p in prior
Proportion of traces with probability p in final experimental runs
Figure 4: Prior probability distribution of subtraces.
We ﬁrst ran ND3MIN() on nine activities from two apps
(com.eat24.app andcom.duolingo ) of thegplayset, using
the naive (round–robin) trace selection strategy of Section
4.1. This produced calls to our test oracle Owith 402 dis-
tinct subtraces in total. We used the oracle responses ob-
tained from this preliminary experiment to generate a prob-
ability prior Pr[PT′=p] given an unknown T′and a prob-
abilityp. We restricted ourselves to only two apps and nine
activities for generating this prior for two reasons. First,
minimizing traces under the naive strategy is a time con-
suming process, compared with either the heuristic or MDP
methods. Second, we want to show that the prior computed
for a few apps generalizes over unrelated Android applica-
tions, meaning that computing this prior is a one time cost,
leading to a solution for the MDP model that can be applied
without changes to minimizing traces for unknown apps.
Figure 4 shows this prior probability distribution. As ob-
served in Section 4.3, we can use this prior to approximate
the transition probabilities used in the MDP for computing
the optimal policy for trace selection. To check the quality
of this prior, we also plot the probability distribution as esti-
mated by examining all queries to the test oracle performed
by the rest of the experiments in this section (from a total
of 3490 subtraces). This distribution shows more traces as
always failing ( PT′= 0) and fewer traces as having low but
non-zero probability. Otherwise, the distribution looks very
similar to our prior, which increases our conﬁdence in using
said prior as our estimate of Pr[PT′=p].
Foreachdataset( gplayandfdroid)wethenran ND3MIN()
on each tuple ( A,T,a) in the set, under two diﬀerent con-
ﬁgurations for trace selection (see Section 4):
•One using the heuristic in Section 4.2 exclusively for
every invocation of method get_passing() .
•One using the pre-computed optimal policy (Section
4.3) when get_passing() receives a set Swith 2 to
5 subtraces (the values of nfor which we are able
to compute the optimal policy in reasonable time2).
In this conﬁguration, get_passing() defaults to us-
ing the same heuristic of the previous conﬁguration,
whenever get_passing() is passed n≥6 subtraces.
On average 66% of the steps executed in the MDP based
trace selection case are steps in which get_passing() was
invoked with fewer than 6 subtraces, and thus uses the opti-
mal policy, based on solving the MDP. The remaining 34%
fall back to using the same heuristic of Section 4.2.
2Solving the MDP using 4 2-vCPU EC2 VMs takes 8 min
forn= 3, 43 min for n= 4 and 83 hours for n= 5.For the applications in the Google Play dataset, Table 1
shows the size of the minimal subtrace obtained by our mini-
mizationalgorithmforeachtargetactivity, togetherwiththe
number of steps and wall-clock time that our algorithm took
to extract it in each conﬁguration. Table 2 shows the anal-
ogous information for the F-Droid open-source apps. The
performance of the naive method on the 2 apps of the gplay
set, used to compute the PT′priors, is listed in Table 3.
5.2 Size of minimized traces, steps and check
The column labeled eventsin our tables speciﬁes the
number of events in the minimized trace Tminas gener-
ated by our algorithm. Recall that our input traces are
500 events long in each experiment. The average length of
the minimized traces is 4.57 for the gplaydataset using
the heuristic trace selection, 4.18 using the MDP-based ver-
sion. For the fdroiddataset, these numbers are 3.05 and
2.9, respectively. The fact that only a few events are needed
in each case to reach the desired activity shows the value
of minimization. Our minimized traces are smaller than the
original Monkey traces by an average factor of roughly 100x.
The column labeled stepscounts the number of times the
methodget_passing() generated a schedule and called our
15 test oracles in parallel. Equivalently, stepsis the max-
imum number of sequential calls to each of the test oracles
required during our minimization algorithm. To make sure
the trace is suitable for minimization, our implementation
ﬁrst runs the original trace T20 times, and aborts running if
the oracle doesn’t accept Tin at least 15 of those calls. We
include the two steps required for this check in our count.
The column labeled checkcontains a triplet of the form
c(p1/p2). After our minimization algorithm has ﬁnished, we
run the resulting trace 20 additional times, and record as c
the number of times it succeeds. We use this number to cal-
culatep1=Pr[PTmin≥0.85] andp2, the probability that,
ifPTmin≥0.85, then Tminis approximately 1-minimal, as
deﬁned by Lemma 1. For p1, we use a formula analogous to
that of Section 3, but taking into account the exact number
of successful oracle queries:
p1=/summationtext
p≥0.85/parenleftbignr
c/parenrightbig
·pc(1−p)nr−cPr[PT′=p]
/summationtext
p/parenleftbignr
c/parenrightbig
·pc(1−p)nr−cPr[PT′=p]
For the probability prior required for these calculations,
we use the same prior from Figure 4 used by the MDP trace
selection method. All probabilities in the tables are trun-
cated, not rounded, as we wish to obtain a lower bound. As
observed in Section 3, since the error of passes() accumu-
lates through multiple trace reductions in our algorithm, our
ﬁnalPTmincan fall below pb, so it is not always true that
c≥18. The vast majority of our minimized traces fullﬁl
PTmin≥0.9, and all but one succeed over 50% of the time.
Note that for the same (app, trace, activity) tuple, our
algorithm sometimes produces minimized traces of diﬀerent
sizeswhenusingdiﬀerenttraceselectionstrategies. Thiscan
happen for one of two reasons. First, diﬀerent trace selec-
tion strategies cause delta debugging to pick diﬀerent sub-
traces during recursive invocations of the MinR()method,
which can guide the algorithm towards discovering diﬀerent
1-minimal solutions. A 1-minimal solution does not imply
the returned trace is of minimum length among all possible
successful subtraces, and an input trace can contain multiple
distinct 1-minimal subtraces that reach the desired activityTable 1: Results for the Google Play apps
heuristic opt:mdp
Application Key Activity events steps time check events steps time check
com.eat24.app 1-1 SplashActivity 0 44:34:01 20 (0.99/1.0) 0 44:17:47 20 (0.99/1.0)
1-2 HomeActivity 0 43:45:04 20 (0.99/1.0) 0 45:48:18 20 (0.99/1.0)
1-3 LoginActivity 3 1813:27:12 20 (0.99/0.94) 3 1712:22:16 20 (0.99/0.94)
1-4 CreateAccountActivity 5 5135:17:52 19 (0.94/0.91) 5 4532:33:16 19 (0.94/0.91)
com.duolingo 2-1 LoginActivity 0 43:34:23 20 (0.99/1.0) 0 44:19:35 20 (0.99/1.0)
2-2 HomeActivity 2 2111:11:34 20 (0.99/0.96) 2 1512:51:19 20 (0.99/0.96)
2-3 WelcomeFlowActivity 2 1812:06:37 20 (0.99/0.96) 2 1613:11:39 20 (0.99/0.96)
2-4 SkillActivity 19 7340:46:06 18 (0.69/0.72) 16 6251:01:40 12 (0.00/0.76)
2-5 LessonActivity 25 8750:16:46 11 (0.00/0.65) 23 110 87:56:06 11 (0.00/0.67)
2-6 FacebookActivity 2 6452:14:13 20 (0.99/0.96) 7 8548:02:17 20 (0.99/0.88)
com.etsy.android 3-1 HomescreenTabsActivity 0 43:18:15 20 (0.99/1.0) 0 43:27:18 20 (0.99/1.0)
3-2 CoreActivity 3 2821:27:39 20 (0.99/0.95) 3 7143:27:56 20 (0.99/0.95)
3-3 DetailedImageActivity 8 5038:55:17 15 (0.11/0.87) 7 3526:31:25 7 (0.00/0.88)
com.ted.android 4-1 SplashScreenActivity 0 45:27:51 20 (0.99/1.0) 0 44:11:50 20 (0.99/1.0)
4-2 MainActivity 1 13 8:28:01 20 (0.99/0.98) 1 10 7:04:49 20 (0.99/0.98)
4-3 TalkDetailActivity 7 3117:45:40 19 (0.94/0.88) 7 2415:59:37 20 (0.99/0.88)
4-4 VideoActivity 15 5739:02:54 19 (0.94/0.77) 11 3222:27:27 18 (0.69/0.82)
4-5 BucketListInfoActivity 5 1313:45:54 20 (0.99/0.91) 5 1110:26:14 19 (0.94/0.91)
com.zhiliaoapp.musically 5-1 SignInActivity 2 1613:52:34 20 (0.99/0.96) 2 1615:04:38 20 (0.99/0.96)
5-2 OAuthActivity 1 1314:32:24 20 (0.99/0.98) 1 1413:55:28 20 (0.99/0.98)
5-3 TermOfUsActivity 1 1212:53:04 20 (0.99/0.98) 1 1312:44:12 20 (0.99/0.98)
com.pandora.android 6-1 SignUpActivity 1 1821:12:14 20 (0.99/0.98) 1 1416:38:10 20 (0.99/0.98)
6-2 SignInActivity 1 1318:32:25 20 (0.99/0.98) 1 1415:48:11 20 (0.99/0.98)
6-3 ForgotPasswordActivity 8 7261:41:23 18 (0.69/0.87) 3 4947:00:46 17 (0.43/0.94)
com.google.android 7-1 LicenseActivity 6 4651:34:31 20 (0.99/0.90) 5 4740:44:01 18 (0.69/0.91)
.apps.photos 7-2 LicenseMenuActivity 5 5051:35:34 19 (0.94/0.91) 5 4639:18:00 18 (0.69/0.91)
7-3 SettingsActivity 3 2734:18:45 20 (0.99/0.94) 2 3631:02:26 20 (0.99/0.96)
7-4 PhotosAboutSettingsActivity 3 3432:21:50 20 (0.99/0.94) 4 3428:26:12 20 (0.99/0.93)
Average 4.57 30.18 24:34:17 4.18 29.86 23:48:40
Median 2.5 19.5 18:09:03 2.5 16.5 15:53:54
Table 2: Results for the F-Droid apps
heuristic opt:mdp
Application Key Activity events steps time check events steps time check
com.evancharlton 8-1 Mileage 0 43:09:23 20 (0.99/1.0) 0 43:06:46 20 (0.99/1.0)
.mileage 8-2 VehicleStatisticsActivity 2 17 8:35:44 20 (0.99/0.96) 2 15 8:48:25 20 (0.99/0.96)
8-3 TotalCostChart 3 2512:46:05 20 (0.99/0.95) 3 2513:16:33 20 (0.99/0.95)
8-4 FillupInfoActivity 10 8441:21:14 20 (0.99/0.84) 10 8536:39:12 20 (0.99/0.84)
8-5 FillupActivity 0 43:12:27 20 (0.99/1.0) 0 43:31:56 20 (0.99/1.0)
8-6 FillupListActivity 2 16 9:09:12 19 (0.94/0.96) 2 2110:58:12 19 (0.94/0.96)
8-7 MinimumDistanceChart 3 15 7:46:58 20 (0.99/0.95) 3 1411:07:33 20 (0.99/0.95)
8-8 AverageFuelEconomyChart 3 14 7:39:26 20 (0.99/0.95) 3 14 8:09:53 20 (0.99/0.95)
de.delusions.measure 9-1 MeasureTabs 0 43:35:59 20 (0.99/1.0) 0 43:23:09 20 (0.99/1.0)
9-2 MeasureActivity 0 43:12:24 20 (0.99/1.0) 0 42:56:53 20 (0.99/1.0)
9-3 BmiTableActivity 2 17 8:52:07 20 (0.99/0.96) 2 2611:32:35 20 (0.99/0.96)
9-4 BmiCalcActivity 4 4822:47:29 20 (0.99/0.93) 3 2713:01:08 20 (0.99/0.93)
org.liberty.android 10-1 AnyMemo 0 43:20:17 20 (0.99/1.0) 0 43:12:32 20 (0.99/1.0)
.fantastischmemo 10-2 OptionScreen 3 16 8:18:16 20 (0.99/0.95) 3 14 8:06:41 20 (0.99/0.95)
10-3 AlgorithmCustomizationScreen 5 6136:57:50 20 (0.99/0.91) 5 5130:44:08 20 (0.99/0.91)
10-4 StudyActivity 2 1710:29:14 20 (0.99/0.96) 2 17 9:40:59 20 (0.99/0.96)
10-5 CardEditor 6 4924:30:42 18 (0.69/0.90) 6 3516:52:17 20 (0.99/0.90)
10-6 SpreadsheetListScreen 3 2919:02:10 20 (0.99/0.95) 3 4024:33:01 20 (0.99/0.95)
org.totschnig 11-1 CalculatorInput 0 43:24:06 20 (0.99/1.0) 0 43:19:23 20 (0.99/1.0)
.myexpenses 11-2 MyExpenses 3 5226:12:57 20 (0.99/0.95) 3 4321:40:33 20 (0.99/0.95)
11-3 ExpenseEdit 13 7032:22:06 16 (0.23/0.80) 11 6636:05:57 17 (0.43/0.82)
Average 3.05 26.38 14:07:55 2.9 24.61 13:22:16
Median 3 17 8:52:07 3 1710:58:12
and have diﬀerent lengths. Because of the probabilistic na-
ture of our algorithm, it is also possible that the trace re-
turned by ND3MIN() is not truly 1-minimal, especially if it
contains a subtrace which reaches the activity with a prob-
ability very close to 0 .9, which our algorithm might have
trouble classifying either way.
We can observe this situation when contrasting the mini-
mized traces discovered by the naive and heuristic trace se-
lectionmethodsfor CreateAccountActivity incom.eat24.app .
The heuristic method produces a 5 event minimized trace
that passes 19 out of 20 oracle calls in its ﬁnal check, while
the naive method returns a 4 event subtrace, which is actu-
ally a subtrace of the one returned by the heuristic case, but
which only passes 17/20 checks. We re-ran both traces 300
times, which suggests the underlaying probability of the 5
event trace is≈0.89 and that of the 4 event trace is ≈0.84.
5.3 Performance comparison
Figure 5 plots the number of steps and wall-clock time for
each experiment, comparing the naive, heuristic and MDP-
based trace selection methods. We normalize in each exper-
iment to the value obtained in the heuristic case, since we
only have the performance of the naive method for the lim-
ited set of (app, trace, activity) tuples in Table 3. Thus the
red line at 1 represents the performance of our heuristic, and
the bars represent the performance of the naive and MDPmethods relative to that of the heuristic. The dashed ver-
tical line separates the experiments for which we have data
on the naive method from those for which we don’t.
We note that the conﬁguration using the MDP policies
doesn’t always outperform our heuristic. This is not unrea-
sonable, since: a) the MDP method only guarantees to min-
imize the number of steps in get_passing() , but it might
pick diﬀerent subtraces than other methods, thus failing to
minimize the number of steps over the whole algorithm, b)
even within a call to get_passing() we are approximat-
ing the prior of PT′based on previous experiments, which
could lead to non-optimal results if the distribution of un-
derlying trace probabilities is very diﬀerent in the particular
app under test, versus the set used to compute the prior,
and c) since the oracle is non-deterministic, the number of
stepsouralgorithmmustperform, evenwhenusingthesame
trace selection method, varies across runs. Our results do
indicate, however, that using the heuristic method for trace
selection is a reasonable option, which performs similarly
to solving the MDP formulation and avoids the expensive
pre-computation for every value of n.
Two outliers in our plots bear explaining. In experiment
2-5, both our heuristic and the MDP based method seem
to under-perform the naive method on the number of steps.
However, this is also a case in which the naive method pro-
duces a larger trace (30 events) than either the heuristic (25Table 3: Performance for naive trace selection
naive
Application Key Activity # events # steps exec. time check
com.eat24.app 1-1 SplashActivity 0 8 7:00:20 20 (0.99/1.0)
1-2 HomeActivity 0 8 6:41:37 20 (0.99/1.0)
1-3 LoginActivity 3 50 37:22:56 20 (0.99/0.95)
1-4 CreateAccountActivity 4 66 48:01:59 17 (0.43/0.93)
com.duolingo 2-1 LoginActivity 0 8 6:53:19 20 (0.99/1.0)
2-2 HomeActivity 2 26 14:07:33 20 (0.99/0.96)
2-3 WelcomeFlowActivity 2 27 15:47:21 18 (0.69/0.96)
2-4 SkillActivity 15 86 62:55:47 15 (0.11/0.77)
2-5 LessonActivity 30 80 62:41:16 14 (0.04/0.59)
Average 6.2 39.9 29:03:34
Median 2 27 15:47:21
(a) Proportion of mdp and naive steps versus heuristic
 (b) Times of mdp and naive versus heuristic
Figure 5: Trace selection performance comparison
events) or the MDP based method (23 events), so this out-
come can be explained as the result ofthe naive method hav-
ing stopped the minimization process earlier than the other
two. In experiment 3-2 the MDP based method performs
much worse than our heuristic while producing a trace of
identical size. In this case, the heuristic found a trace con-
sisting of 3 consecutive events of the original trace, while
the MDP based method found a trace of non-consecutive
events. The structure of delta debugging is such that it
generally makes faster progress towards a contiguous subse-
quence than towards a non-contiguous one.
The average running time of our minimization algorithm
using the heuristic approach is 24:34 hours for the activities
in thegplayset (median: 18:09 hours) and 14:08 hours for
thefdroidset (median: 8:52 hours). Using the MDP based
method, we have an average of 23:49h and median of 15:54h
for thegplayset, and an average of 13:22h and median of
10:58h for fdroidapps. Thus, our approach ﬁts comfortably
in the time frame of software processes that can be run on
a daily (i.e., overnight) or weekly basis.
We tested the sequence of time measurements for all apps
(gplayandfdroid) under the Wilcoxon Signed-Rank Test
[32] and found a mean rank diﬀerence between the heuristic
and MDP based methods with p≈0.08, which is not quite
enough to be considered statistically signiﬁcant. We do not
have enough samples under the naive method to compare
it against the other two under a similar test, but it can
be seen from Figure 5 that this method often signiﬁcantly
underperforms compared to the other two.
5.4 Effects of application non-determinism
One ﬁnal question regarding the trace minimization prob-
lemisonwhetherornothandlingapplicationnon-determinis m
is truly a signiﬁcant problem. As we discussed in Section
2, some Android applications present non-deterministic be-
havior under the same sequence of GUI events, motivating
the need for running each event trace multiple times dur-
ing minimization and estimating trace probabilities. How-ever, if this is a problem that occurs only rarely, it might
be that the techniques presented in this paper are not of-
ten required. We argue that application non-determinism is
in reality a common problem, as can already be somewhat
discerned from the fact that the check columns of tables 1
and 2 often show traces as succeeding in reaching the target
activity less than 20 times in 20 runs.
To explore the impact of application non-determinism for
trace minimization, we took the output minimized traces of
our MDP condition for the gplaydataset, and attempted to
further minimize them by using traditional non-probabilistic
delta-debugging (i.e. by following the algorithm in [38] or,
equivalently, by running ND3MIN() withnr=st= 1). In
8 out of 28 cases (29%), this produced a further reduced
trace. We then ran each of these resulting traces an ad-
ditional 20 times. Table 4 contrasts the size and reliabil-
ity of the traces minimized under the original MDP based
non-determinism aware condition, with that of the result of
further applying traditional delta debugging to these traces.
As we can see, these resulting traces succeed in reaching the
target activity much less frequently than the originally min-
imized traces. Thus, it is clear that for traces that succeed
non-deterministically, it is important to take into account
their corresponding success probabilities during minimiza-
tion. This likely becomes more signiﬁcant the more steps
delta debugging takes, as we can see by looking at the cases
of the table above in which the minimal trace obtained by
the MDP strategy is larger than 5 events.
6. RELATED WORK
Many tools exist for generating GUI event traces to drive
Android apps. These tools, sometimes collectively called
‘monkeys’, are commonly used to automatically generate
coverage of an app’s behavior or to drive app execution as
part of a dynamic analysis system.
Dynodroid [20] improves on the standard Android Mon-
key by automatically detecting when the application regis-Table 4: Eﬀect on application non-determinism in our datase t
Application Key Activity non-deterministic mdp + deterministic DD
# events check # events check
com.eat24.app 1-3 LoginActivity 3 20/20 2 6/20
1-4 CreateAccountActivity 5 19/20 3 15/20
com.duolingo 2-4 SkillActivity 16 12/20 11 4/20
2-5 LessonActivity 23 11/20 15 1/20
com.etsy.android 3-2 CoreActivity 3 20/20 2 12/20
com.ted.android 4-4 VideoActivity 11 18/20 10 1/20
com.google.android 7-2 LicenseMenuActivity 5 18/20 4 18/20
.apps.photos 7-4 PhotosAboutSettingsActivity 4 20/20 3 18/20
Average 8.75 17.25/20 6.25 9.38/20
ters for system events and triggering those events as well as
standard GUI events. It also provides multiple event gen-
eration strategies which take the app context into account
and it allows the user to manually provide inputs when ex-
ploration is stalled (e.g. at a login screen). Tools such
as GUIRipper [1]/ MobiGUITAR [2], AppsPlayground [24],
ORBIT [34], SwiftHand [9], and A3E[4] dynamically crawl
each app while building a model which records observed
states, allowed events in each state, and state transitions.
The generated model is used to systematically explore the
app. PUMA [15] provides a general framework over which
diﬀerent model-based GUI exploration strategies can be im-
plemented. ACTEve [3] is a concolic-testing framework for
Android, which symbolically tracks events from the point in
the framework where they are generated, up to the point
at which the app handles them. EvoDroid [21] generates
Android input events using evolutionary algorithms, with a
ﬁtness function designed to maximize coverage. Brahmastra
[5] is another tool for driving the execution of Android apps,
which uses static analysis and app rewriting to reach speciﬁc
components deep within the app.
A recent survey paper by Choudhary et al. [10] compares
many of the tools above and seems to suggest that the stan-
dard Android Monkey is competitive in coverage achieved
in a limited time. One explanation is that Monkey com-
pensates for what it lacks in sophistication by maintaining a
higher rate of event generation. Of course, this unexpected
result could also be the eﬀect of comparing research pro-
totypes against an industry standard tool, which performs
morerobustlyevenwhileusinglesssophisticatedtechniques.
In either case, the eﬀectiveness of the standard Monkey to
achievehighcoverage, alongwiththerelativenoisinessofth e
traces produced, justiﬁes our focus on trace minimization.
In addition to general test input generation tools for An-
droid, manydynamicanalysistoolsincludecomponentsthat
drive exploration of the app being analyzed (e.g. [18, 23,
19, 25]). Input fuzzers can also generate application inputs,
albeit restricted to testing for particular scenarios, such as
inter-app communication errors [27] or invalid data handling
[35], rather than aiming at GUI exploration.
BesidesminimizingtracesgeneratedbyMonkey-styletools,
our approach is also applicable to minimizing recorded user-
interaction traces. Tools such as RERAN [11], Mosaic [14]
and VALERA [16] could be used to record the actions of a
human tester as an input event trace for our method.
In addition to automated input generation tools, GUI-
aware tests for Android applications tend to be encoded
as testing scripts in frameworks such as Selendroid [30],
Robotium [26], Calabash [33] or Espresso [12]. These frame-
works allow scripting speciﬁc interaction scenarios with an
Android app and adding checks to generate an eﬀective ap-
plication test suite. A promising line of future work is to
automatically transform automatically-generated and mini-mized execution traces into test scripts expressed in any of
these frameworks, as a way to provide a starting point for
test suite writers.
Regardingourspeciﬁctechnique, thecoreofouralgorithm
is based on delta debugging. Delta debugging is a family of
algorithmsforsequenceminimizationandfaultisolation, de -
scribed originally by Zeller et al. [36, 38]. This technique
has been extended to many scenarios [37, 8, 22, 6]. In partic-
ular, the work by Scott et al. [29, 28], extends delta debug-
ging to minimize execution traces which trigger bugs within
non-deterministic distributed systems. They run standard
delta debugging over the traces of external (user triggerable)
events. Then, tocheckeachsubtraceofexternalevents, they
instrument the system under test and explore the space of
possible interleavings of internal events. By contrast, we
treat non-deterministic Android applications in a blackbox
manner and rely on modeling the probability of success of
tracesofexternalevents, independentlyoftheinternalwork-
ings of the system being tested. For the speciﬁc case of
minimizingGUIeventtracesinAndroidapplications, anim-
portant source of non-determinism turns out to be responses
fromnetworkservicesoutsideourcontrol, justifyingtheneed
for a blackbox approach. In other scenarios, the tradeoﬀ be-
tween both approaches likely depends on the complexity of
the internals of the system being tested and the ‘success’
probability of the original trace to be minimized.
AMarkovDecisionProcessisastandard modelwithinthe
reinforcement learning literature (see e.g. [17, 31]). MDPs
are used to solve a variety of problems across multiple do-
mains, including optimizing resource consumption in mobile
phones [7]. To the best of our knowledge, we are the ﬁrst to
apply them to the problem of trace minimization in testing.
7. CONCLUSIONS
We have presented the problem of minimizing large GUI
event traces as a ﬁrst step towards producing scripted test
cases from the output of random input testing tools, such as
Android’s Monkey. We have shown a delta debugging exten-
sion that handles non-determinism, which we have shown is
a pervasive issue in app behavior. We have also presented
two strategies for eﬃcient trace selection. Evaluation of our
trace minimization method shows that the resulting traces
are 55 times smaller while still reaching the same activity
with high probability.
8. ACKNOWLEDGMENTS
This material is based on research sponsored by the Air
ForceResearchLaboratory, underagreementnumberFA8750-
12-2-0020. The U.S. Government is authorized to reproduce
and distribute reprints for Governmental purposes notwith-
standing any copyright notation thereon. Additionally, this
work was partially supported by the Amazon Web Services
(AWS) Cloud Credits for Research program.9. REFERENCES
[1] D. Amalﬁtano, A. R. Fasolino, P. Tramontana, S. D.
Carmine, and A. M. Memon. Using GUI rip-
ping for automated testing of Android applications.
InIEEE/ACM International Conference on Auto-
mated Software Engineering, ASE’12, Essen, Germany,
September 3-7, 2012 , pages 258–261, 2012.
[2] D. Amalﬁtano, A. R. Fasolino, P. Tramontana, B. D.
Ta, and A. M. Memon. MobiGUITAR: Automated
model-based testing of mobile apps. IEEE Software ,
32(5):53–59, 2015.
[3] S. Anand, M. Naik, M. J. Harrold, and H. Yang.
Automated concolic testing of smartphone apps. In
20th ACM SIGSOFT Symposium on the Foundations
of Software Engineering (FSE-20), SIGSOFT/FSE’12,
Cary, NC, USA - November 11 - 16, 2012 , page 59,
2012.
[4] T. Azim and I. Neamtiu. Targeted and depth-ﬁrst ex-
ploration for systematic testing of Android apps. In
Proceedings of the 2013 ACM SIGPLAN International
Conference on Object Oriented Programming Systems
Languages & Applications, OOPSLA 2013, part of
SPLASH 2013, Indianapolis, IN, USA, October 26-31,
2013, pages 641–660, 2013.
[5] R. Bhoraskar, S. Han, J. Jeon, T. Azim, S. Chen,
J. Jung, S. Nath, R. Wang, and D. Wetherall. Brah-
mastra: Driving apps to test the security of third-party
components. In Proceedings of the 23rd USENIX Secu-
rity Symposium, San Diego, CA, USA, August 20-22,
2014., pages 1021–1036, 2014.
[6] M. Burger and A. Zeller. Minimizing reproduction of
software failures. In Proceedings of the 20th Interna-
tional Symposium on Software Testing and Analysis,
ISSTA 2011, Toronto, ON, Canada, July 17-21, 2011 ,
pages 221–231, 2011.
[7] T. L. Cheung, K. Okamoto, F. M. III, X. Liu, and
V. Akella. Markov decision process (MDP) framework
for optimizing software on mobile phones. In Proceed-
ings of the 9th ACM & IEEE International confer-
ence on Embedded software, EMSOFT 2009, Grenoble,
France, October 12-16, 2009 , pages 11–20, 2009.
[8] J. Choi and A. Zeller. Isolating failure-inducing thread
schedules. In Proceedings of the 11th International Sym-
posium on Software Testing and Analysis, ISSTA 2002,
Rome, Italy, July 22-24, 2002 , pages 210–220, 2002.
[9] W.Choi, G.C.Necula, andK.Sen. GuidedGUItesting
of Android apps with minimal restart and approximate
learning. In Proceedings of the 2013 ACM SIGPLAN
International Conference on Object Oriented Program-
ming Systems Languages & Applications, OOPSLA
2013, part of SPLASH 2013, Indianapolis, IN, USA,
October 26-31, 2013 , pages 623–640, 2013.
[10] S. R. Choudhary, A. Gorla, and A. Orso. Automated
test input generation for Android: Are we there yet?
In30th IEEE/ACM International Conference on Auto-
mated Software Engineering, ASE 2015, Lincoln, NE,
USA, November 9-13, 2015 , pages 429–440, 2015.[11] L. Gomez, I. Neamtiu, T. Azim, and T. D. Millstein.
RERAN: timing- and touch-sensitive record and replay
for Android. In 35th International Conference on Soft-
ware Engineering, ICSE ’13, San Francisco, CA, USA,
May 18-26, 2013 , pages 72–81, 2013.
[12] Google. Espresso -
https://developer.android.com/training/testing/ui-
testing/espresso-testing.html.
[13] Google. UI/Application exerciser monkey -
https://developer.android.com/tools/help/monkey.html.
[14] M. Halpern, Y. Zhu, R. Peri, and V. J. Reddi. Mo-
saic: cross-platform user-interaction record and replay
for the fragmented Android ecosystem. In 2015 IEEE
International Symposium on Performance Analysis of
Systems and Software, ISPASS 2015, Philadelphia, PA,
USA, March 29-31, 2015 , pages 215–224, 2015.
[15] S. Hao, B. Liu, S. Nath, W. G. J. Halfond, and
R. Govindan. PUMA: programmable ui-automation for
large-scale dynamic analysis of mobile apps. In The
12th Annual International Conference on Mobile Sys-
tems, Applications, and Services, MobiSys’14, Bretton
Woods, NH, USA, June 16-19, 2014 , pages 204–217,
2014.
[16] Y. Hu, T. Azim, and I. Neamtiu. Versatile yet
lightweight record-and-replay for Android. In Pro-
ceedings of the 2015 ACM SIGPLAN International
Conference on Object-Oriented Programming, Systems,
Languages, and Applications, OOPSLA 2015, part of
SLASH 2015, Pittsburgh, PA, USA, October 25-30,
2015, pages 349–366, 2015.
[17] L. P. Kaelbling, M. L. Littman, and A. W. Moore. Re-
inforcement learning: A survey. J. Artif. Intell. Res.
(JAIR), 4:237–285, 1996.
[18] K. Lee, J. Flinn, T. J. Giuli, B. Noble, and C. Peplin.
AMC: verifying user interface properties for vehicular
applications. In The 11th Annual International Con-
ference on Mobile Systems, Applications, and Services,
MobiSys’13, Taipei, Taiwan, June 25-28, 2013 , pages
1–12, 2013.
[19] B. Liu, S. Nath, R. Govindan, and J. Liu. DECAF:
detecting and characterizing ad fraud in mobile apps.
InProceedings of the 11th USENIX Symposium on
Networked Systems Design and Implementation, NSDI
2014, Seattle, WA, USA, April 2-4, 2014 , pages 57–70,
2014.
[20] A. Machiry, R. Tahiliani, and M. Naik. Dynodroid:
an input generation system for Android apps. In Joint
Meeting of the European Software Engineering Confer-
ence and the ACM SIGSOFT Symposium on the Foun-
dations of Software Engineering, ESEC/FSE’13, Saint
Petersburg, Russian Federation, August 18-26, 2013 ,
pages 224–234, 2013.
[21] R. Mahmood, N. Mirzaei, and S. Malek. EvoDroid:
segmented evolutionary testing of Android apps. In
Proceedings of the 22nd ACM SIGSOFT International
Symposium on Foundations of Software Engineering,
(FSE-22), Hong Kong, China, November 16 - 22, 2014 ,
pages 599–609, 2014.[22] G. Misherghi and Z. Su. HDD: hierarchical delta de-
bugging. In 28th International Conference on Software
Engineering (ICSE 2006), Shanghai, China, May 20-
28, 2006 , pages 142–151, 2006.
[23] S. Nath, F. X. Lin, L. Ravindranath, and J. Padhye.
SmartAds: bringing contextual ads to mobile apps.
InThe 11th Annual International Conference on Mo-
bile Systems, Applications, and Services, MobiSys’13,
Taipei, Taiwan, June 25-28, 2013 , pages111–124, 2013.
[24] V. Rastogi, Y. Chen, and W. Enck. AppsPlayground:
automatic security analysis of smartphone applications.
InThird ACM Conference on Data and Application Se-
curity and Privacy, CODASPY’13, San Antonio, TX,
USA, February 18-20, 2013 , pages 209–220, 2013.
[25] L. Ravindranath, S. Nath, J. Padhye, and H. Balakrish-
nan. Automatic and scalable fault detection for mobile
applications. In The 12th Annual International Con-
ference on Mobile Systems, Applications, and Services,
MobiSys’14, Bretton Woods, NH, USA, June 16-19,
2014, pages 190–203, 2014.
[26] Robotium. Robotium -
https://github.com/robotiumtech/robotium.
[27] R. Sasnauskas and J. Regehr. Intent fuzzer: crafting
intents of death. In Proceedings of the 2014 Joint In-
ternational Workshop on Dynamic Analysis (WODA)
and Software and System Performance Testing, De-
bugging, and Analytics (PERTEA), WODA+PERTEA
2014, San Jose, CA, USA, July 22, 2014 , pages 1–5,
2014.
[28] C. Scott, A. Panda, V. Brajkovic, G. Necula, A. Kr-
ishnamurthy, and S. Shenker. Minimizing faulty exe-
cutions of distributed systems. In 13th USENIX Sym-
posium on Networked Systems Design and Implementa-
tion (NSDI 16) , pages 291–309, Santa Clara, CA, 2016.
USENIX Association.
[29] C. Scott, A. Wundsam, B. Raghavan, A. Panda, A. Or,
J. Lai, E. Huang, Z. Liu, A. El-Hassany, S. Whit-
lock, H. B. Acharya, K. Zariﬁs, and S. Shenker. Trou-bleshooting blackbox SDN control software with mini-
mal causal sequences. In ACM SIGCOMM 2014 Con-
ference, SIGCOMM’14, Chicago, IL, USA, August 17-
22, 2014 , pages 395–406, 2014.
[30] Selendroid. Selendroid - http://selendroid.io/.
[31] R. S. Sutton and A. G. Barto. Reinforcement learning:
An introduction , volume 28. MIT press, 1998.
[32] F. Wilcoxon. Individual comparisons by ranking meth-
ods.Biometrics bulletin , 1(6):80–83, 1945.
[33] Xamarin. Calabash - http://calaba.sh/.
[34] W. Yang, M. R. Prasad, and T. Xie. A grey-box ap-
proach for automated GUI-model generation of mobile
applications. In Fundamental Approaches to Software
Engineering - 16th International Conference, FASE
2013, Held as Part of the European Joint Conferences
on Theory and Practice of Software, ETAPS 2013,
Rome, Italy, March 16-24, 2013. Proceedings , pages
250–265, 2013.
[35] H. Ye, S. Cheng, L. Zhang, and F. Jiang. DroidFuzzer:
Fuzzing the Android apps with intent-ﬁlter tag. In The
11th International Conference on Advances in Mobile
Computing & Multimedia, MoMM ’13, Vienna, Aus-
tria, December 2-4, 2013 , page 68, 2013.
[36] A. Zeller. Yesterday, my program worked. today, it does
not. why? In Software Engineering - ESEC/FSE’99,
7th European Software Engineering Conference, Held
Jointly with the 7th ACM SIGSOFT Symposium on
the Foundations of Software Engineering, Toulouse,
France, September 1999 , pages 253–267, 1999.
[37] A. Zeller. Isolating cause-eﬀect chains from computer
programs. In Proceedings of the Tenth ACM SIGSOFT
Symposium on Foundations of Software Engineering
2002, Charleston, South Carolina, USA, November 18-
22, 2002 , pages 1–10, 2002.
[38] A. Zeller and R. Hildebrandt. Simplifying and isolat-
ing failure-inducing input. IEEE Trans. Software Eng. ,
28(2):183–200, 2002.