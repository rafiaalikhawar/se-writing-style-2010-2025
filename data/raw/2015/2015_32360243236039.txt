Singularity: Pattern Fuzzing forWorst CaseComplexity
Jiayi Wei
The Universityof Texasat Austin
Austin, Texas,USA
wjydzh1@gmail.comJia Chen
The Universityof Texasat Austin
Austin, Texas,USA
grievejia@gmail.comYu Feng
The Universityof Texasat Austin
Austin, Texas,USA
yufeng@cs.utexas.edu
KostasFerles
The Universityof Texasat Austin
Austin, Texas,USA
kferles@cs.utexas.eduIsil Dillig
The Universityof Texasat Austin
Austin, Texas,USA
isil@cs.utexas.edu
ABSTRACT
Wedescribeanewblackboxcomplexitytestingtechniquefordeter-
miningtheworst-caseasymptoticcomplexityofagivenapplication.
Thekeyideaistolookforan inputpattern Ðratherthanaconcrete
inputÐ that maximizes the asymptotic resource usage of the tar-
get program. Because input patterns can be described concisely as
programs ina restricted language, our method transforms the com-
plexity testing problem to optimal program synthesis . In particular,
we express these input patterns using a new model of computation
calledRecurrentComputationGraph(RCG) andsolvetheoptimal
synthesisproblembydevelopingageneticprogrammingalgorithm
that operates onRCGs.
We have implemented the proposed ideas in a tool called Sin-
gularity and evaluate it on a diverse set of benchmarks. Our
evaluation shows that Singularity can effectively discover the
worst-casecomplexityofvariousalgorithmsandthatitismorescal-
able compared to existing state-of-the-art techniques. Furthermore,
ourexperimentsalsocorroboratethat Singularity candiscover
previously unknown performance bugs and availability vulnerabili-
ties in real-world applications such as Google Guavaand JGraphT.
CCS CONCEPTS
·Softwareanditsengineering →Softwareperformance ;Soft-
ware testing and debugging ;·Securityandprivacy →Denial-of-
service attacks ;
KEYWORDS
Complexity testing; optimal program synthesis; fuzzing; genetic
programming;performance bug; availability vulnerability
ACMReference Format:
Jiayi Wei, Jia Chen, Yu Feng, Kostas Ferles, and Isil Dillig. 2018. Singu-
larity: Pattern Fuzzing for Worst Case Complexity. In Proceedings of the
26th ACM Joint European Software Engineering Conference and Symposium
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE ’18, November 4ś9, 2018, Lake BuenaVista,FL,USA
©2018 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-5573-5/18/11...$15.00
https://doi.org/10.1145/3236024.3236039on the Foundations of Software Engineering (ESEC/FSE ’18), November 4ś
9, 2018, Lake Buena Vista, FL, USA. ACM, New York, NY, USA, 11pages.
https://doi.org/10.1145/3236024.3236039
1 INTRODUCTION
Reasoningaboutaprogram’sworst-casecomplexityisanimportant
problemthathasmanyreal-worldapplications,includingperfor-
mancebugdetectionandidentificationofsecurityvulnerabilities.
For instance, automated complexity analysis can identify cases
where an algorithm’s expected worst-case complexity does not
matchthatofitsimplementation,thusindicatingthepresenceof
aperformancebug.Suchtechniquesarealsousefulfordetecting
availabilityvulnerabilitiesthatallowattackerstocausedenial-of-
service (e.g., throughalgorithmic complexity attacks [ 5,9,19,37]).
While there is a large body of literature on worst-case complex-
ityanalysis[ 6,16,17,29],mostofthesetechniquesdonotproduce
worstperformanceinputs ,henceforthcalled WPIs,thattriggerthe
worst-caseperformancebehaviorofthetargetprogram.SuchWPIs
can be used to debug performance problems and confirm the pres-
enceofsecurityvulnerabilities. Furthermore,WPIs canshed light
onthe cause of worst-caseexecutions and help programmerswrite
suitablesanitizerstoguardtheircodeagainstpotentialDoSattacks.
In this paper, we propose a new black-box complexity testing
technique to efficiently generate inputs that trigger the worst-case
performanceofagivenprogram.Thekeyinsightunderlyingour
approach is thatWPIsalmost alwaysfollowa specific pattern that
canbeexpressedasasimpleprogram.Forinstance,totriggerthe
worst-caseperformanceofaninsertionsortalgorithm,theinputar-
raymustbeinreversesortedorder,whichcanbeprogrammatically
generatedbyappendinglargerandlargernumberstoanemptylist.
Based on this observation, our key insight is to transform the
complexity testing problem to a program synthesis problem, where
the goal is to find a programthat expresses the common pattern
shared by allWPIs.In particular, given a targetprogramPwhose
resource usage we want to maximize, our algorithm synthesizes
another programG, called a generator , such that the outputs of G
correspond preciselyto the WPIs of P.Since the common pattern
underlyingWPIscanoftenberepresentedusing smallgenerator
programs,thisapproachallowsustodiscoverWPIsveryefficiently.
Inthesimplestcase,agenerator Gconsistsofaninitialinputseed
stogetherwithafunction fwhoseoutputislargerthanitsinput.
Sincesize(fi(s))>size(fj(s))whenever i>j,ourmethodcangen-
eratearbitrarilylargeinputsbyapplying fsufficientlymanytimes.
213
ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA JiayiWei, Jia Chen,Yu Feng, KostasFerles,andIsilDillig
Forinstance,theinputpattern ([0],f=λx.append(x,last(x)))cor-
respondstoaninfinitesequenceofinputsoftheform {[0],[0,0],
[0,0,0],...}. Thus, we can determine the worst-case complexity of
the target program by using the synthesized generator to obtain
manyWPIsandthen fittingacurve throughthesedata points.
The problem of finding patterns that characterize WPIs corre-
spondstoan optimalsynthesisproblem ,wherethegoalistosynthe-
sizeageneratorGsuchthatthevaluesproducedby Gmaximizethe
targetprogram’sresourceusage.Ourmethodsolvesthisoptimal
synthesis problem by performing feedback-guided optimization
usinggeneticprogramming.Specifically,werepresentgenerators
usingasetofDSLscalled RecurrentComputationGraphs(RCG) that
are (a)expressive enough to model most inputpatterns ofinterest
andyet(b)restrictiveenoughtomakethesearchspacemanageable.
Giventhisrepresentation,ourmethodlooksforanoptimalRCGby
applying genetic operators (e.g., mutation, crossover) to existing
RCGsandbiasingthesearchtowardsgeneratorsthatmaximizethe
target program’s resourceusage.
We have implemented these ideas in a tool called Singularity ,
publiclyavailableonGithub[ 36].Weevaluate Singularity ’sef-
fectiveness on severalbenchmarks, includingthosefrom previous
literature, real-world applications, and challenge problems from
the DARPA STACprogram1. Ourexperiments demonstrate Singu-
larity’s effectiveness at finding inputs that trigger the worst-case
performance of various textbook algorithms whose average and
worst-casecomplexityaredifferent.Ourexperimentsalsodemon-
stratetheadvantagesofourapproachover(a) SlowFuzz ,astate-of-
the-artfuzzingtechniqueforfindingavailabilityvulnerabilities,and
(b)Wise,acomplexitytestingtechniquebasedondynamicsymbolic
execution. Finally, our experiments corroborate that Singularity
can find previously unknown performance bugs in widely-used
Java applicationssuch as Google Guava [ 15]andJGraphT [ 18].
In all,this paper makesthe following key contributions:
•Weintroducethenotionof inputpatterns andshowhowtoreduce
the complexity testing problem to an optimal program synthesis
problem,wherethegoalistofindaninputpatternthatmaximizes
the target program’s resourceusage.
•We introduce anew model of computation called recurrent com-
putationgraphs(RCG) forexpressinginputpatterns.ThisRCG
modelcanbeinstantiated indifferentwaystoobtain adomain-
specific languagefor generatinginputsofmanydifferenttypes.
•Weshowhowtosolvetheunderlyingoptimalsynthesisproblem
using genetic programming. Our method defines new genetic
operators overRCGs and guides the searchtowards those input
patterns that maximizeresourceusage.
•We implement our method in a tool called Singularity and
evaluate it on a diverse set of benchmarks. Our experiments
show the benefits of our approach over prior techniques and
demonstrate that Singularity can discover interesting security
vulnerabilitiesandperformance bugs.
2 OVERVIEW
Inthis section, wepresentourproblem definitionandgivea brief
overviewofour approach throughasimplemotivatingexample.
1TheSTACprogramaimstodevelopprogramanalysistechniquesforfindingavail-
ability and confidentiality vulnerabilities.defquick_sort (xs):
if(xs.length<= 1):
returnxs
pivot=xs[xs.length/2]
left, middle, right =[]
forxinxs:
if(x==pivot):
middle.append(x)
elif(x<pivot):
left.append(x)
else:
right.append(x)
left=quick_sort(left)
right=quick_sort(right)
returnconcat(left, middle, right)
Figure 1:QuickSort with middle pivot selection
2.1 ProblemDefinition
Given a target program P, our goal is to find an input pattern that
triggersP’s worst-case resource usage. As mentioned in Section 1,
we represent input patterns as generator programs Gthat produce
an infinite sequenceof increasingly larger inputsforP.
Definition 1. (Generator) Given a program Pwith signature
τ→τ′,ageneratorGforPisaprogramwithsignature unit→
Stream(τ).WewriteGitoindicatethe i’thelementinthestream
producedbyGandrequirethat size(Gi)>size(Gj)whenever i>j.
Becauseourgoalistomaximizetheresourceusageofagiven
program, we need a way to measure the size of an input and its
correspondingresourceusage.Thus,a problemconfiguration inour
settingconsistsofatriple (P,Σ,Ψ),wherePisthetargetprogram
with signature τ→τ′,Σis a metric that defines the size of any
value of type τ, andΨis a function of type τ→Rthat measures
the resource usage of Pon any input of type τ. In particular, we
writeΨ(s)todenotetheresourceusageof Ponaconcreteinput
sof typeτ. We also use the notation G≤nto denote the largest
elementGisuchΣ(Gi)≤n.
Tocomparetheasymptoticresourceusageoftwopatterns,we
definethe following binary relation ≻onapair of generators:
Definition2. (Relation≻)AgeneratorGisasymptoticallybetter
thananother generator G′, writtenG≻G′, iff the resource usage
ofGon the target program exceeds that of G′forall sufficiently
largesizes :
∃ˆn.∀n>ˆn.Ψ(G≤n)>Ψ(G′
≤n)
Given a problem configuration (P,Σ,Ψ), we now formalize our
goalas the complexity testingproblem :
Definition 3. (Complexity Testing )Thegoalofthe complexity
testingproblemistofindaninputpatternsuchthatnootherpattern
isasymptoticallybetterthan it.Thatis, wewantto finda Gwhere:
∄G′.G′≻G
2.2 Motivating Example
Wenowinformallydescribeourcomplexitytestingtechniqueon
the simple quickSort example shown in Figure 1as Python code.
For concreteness, let us assume that generators are expressed in
214Singularity: Pattern Fuzzing for WorstCaseComplexity ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA
P≔(C,λx.LE)
E≔IE|LE
C≔Int|List
IE≔Int|x|plus(IE,IE)|minus(IE,IE)
|times(IE,IE)|length(LE)
LE≔List|x|append(LE,E)|prepend(E,LE)
|concat(LE,LE)
Figure2:ADSLwhere prepend/appendaddsanelementtothe
head/tailofalist,respectively.
Figure3: Output Yisobtainedbyrepeatedlyapplyingfunc-
tionFto seed value C.
a simplified DSL shown in Figure 2. Specifically, a program Gin
this language is a tuple (c,f)wherecis a constant seedvalue and
fisafunctionthatoperatesoveralistofintegers.Asillustrated
in Figure 3, we can compute an infinite sequence of values from
(c,f)by repeatedly applying ftoc, where the i’th value yiin the
sequence is given by fi(c), denoting isuccessive applications of f
to valuec.
Using the DSL from Figure 2, we can express the worst-case
pattern for the quickSort implementation from Figure 1as follows:
G∗=/parenleftBig
[0],λx.append(prepend(length(x)+1,x),length(x))/parenrightBig
This program produces the following sequenceofinputs:
[0],[2,0,1],[4,2,0,1,3],[6,4,2,0,1,5],...
Observe that these inputs indeed trigger the worst-case running
time of the quickSort implementation from Figure 1, because (a)
thesmallestvalueineachlistofthesequenceisthemiddleelement,
and (b) the quicksort implementation Figure 1chooses the middle
element as its pivot.
Wenowexplainhow Singularity findsthispattern G∗using
genetic programming (GP). Singularity startswithapopulation
of randomly-generated programs that conform to the context-free
grammargiveninFigure 2andevaluatesthefitnessofeachprogram.
Since our goal is to maximize running time, the fitness function
assigns a higher score to programs that take longer. For simplicity,
let us assume that we evaluate running time on some particular
inputsize,such as arrays oflength 100.
Even though it is highly unlikely that the target generator G∗
occursintheinitialpopulation P,itmightbethecasethat Pcon-
tains several useful, albeit suboptimal, functions such as f1=
λx.append(x,length(x))andf2=λx.prepend(length(x),x). These
functions are useful since the desiredpattern can be obtainedby
mixing thesefunctionsusing genetic operators.
For thenextiteration, the genetic programming algorithmran-
domly picks łfitž generators from the previous iteration. For exam-
ple,theinputpatterns ([0],f1)and([0],f2)arelikelytobeselected
becausetheyhavehigherthanaverageresourceusage. Singular-
itythen uses these input patterns to generate a new population
ofcandidatepatternsbycombiningthemusinggeneticoperators,
Figure 4: An RCG with cinternal states and moutput states.
such as mutation and crossover. For example, we can obtain the
followingprogram f3fromf1andf2usingthecrossoveroperation:
λx.append(prepend(length(x),x),length(x))
In particular, crossover replaces a random sub-expression in one
programwithasub-expressiontakenfromanotherprogram.Inthis
case,wecanobtain f3fromf1,f2bysubstitutingthesub-expression
xinf1withtheentirebodyof f2.Furthermore, f3resultsinhigher
resourceconsumption comparedto f1andf2.
We continue the process of generating new populations and
monitor both their maximal and average performance. In gen-
eral, average performance will keep increasing over generations
and, at some point, Singularity will generate the desired pro-
gramG∗from([0],f3)by mutating the sub-expression length(x)
tolength(x)+1. Since([0],f∗)can be used to generate an input
of size100that achieves the maximal possible resource usage, our
algorithm will eventually terminate with the desired input pattern
G∗.Observethatwecannowdeterminetheworst-casecomplexity
ofthisquicksort implementationbymeasuringtherunningtimeof
quickSort on the input values generated by G∗and using standard
techniques to fitacurve throughthesedata points.
3 RECURRENTCOMPUTATION GRAPHS
Inthissection,weintroduce recurrentcomputationgraphs(RCGs)
as a family of DSLs for representing generators. Intuitively, we
chooseRCGsasourcomputationmodelbecausetheyareexpressive
enough to capture most input patterns of interest that arise in
practice, but they are also restrictive enough to keep the search
spacemanageable.
Definition4. (RecurrentComputationGraph) Arecurrentcom-
putationgraphGisatriple (I,F,O)whereIisatuple of initial-
ization expressions, Fis a tuple of update expressions (where
|I|=|F|), andOisatuple of outputexpressions.
BeforeconsideringtheformalsemanticsofRCGs,wefirstexplain
theminformally:AnRCG (I,F,O)isageneralizationofthesimple
computational model described in Section 2.2. As illustrated in
Figure4,insteadofusingoneinternalstate,anRCGgeneratesan
infinitesequenceofvaluesbymaintaining |I|internalstatesthat
are initialized using Iand updated using F. An RCG also uses an
output layerOto transform its internal states before outputting
them.Thisdecouplingallowsthenumberofinternalstatestobe
215ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA JiayiWei, Jia Chen,Yu Feng, KostasFerles,andIsilDillig
si[0]=/llbracketIi/rrbracket
si[t+1]=/llbracketFi/rrbracket[s1/ma√sto→s1[t],...,sc/ma√sto→sc[t]]
yj[t]=/llbracketOj/rrbracket[s1/ma√sto→s1[t],...,sc/ma√sto→sc[t]]
where 1≤i≤c=|I|and1≤j≤m=|O|
/llbracket(I,F,O)/rrbracket=/bracketleftBig
(y1[t],...,ym(t))|t∈[0,∞]/bracketrightBig
Figure 5:Recurrentcomputation graphsemantics
different from the number of arguments that the target program
takes. As before, we can generate the k’th value in the infinite
sequencebyupdatingthe internal states exactly ktimes.
RCGsemantics. Moreformally,thesemanticsofanRCG (I,F,O)
isgivenbytherulesshowninFigure 5.Here,si[t]representsthe
i’thinternalstateattimestep t,andyi[t]correspondstothe i’th
outputvalueattime t.AsshowninFigure 5,si[0]iscomputedusing
thei’thinitializationexpressionin I,andsi[t+1]isobtainedfrom
(s1[t],...,sc[t])by applyingthe updatefunction Fi. Finally,yj[t]
is obtained from the internal state at time tby applying the output
expressionOjto(s1[t],...,sc[t]). The semantics of the RCG is
then given by the infinite sequence of values (y1[t],...,ym[t])for
t=0,1,2,...GivenanRCGGandavalue y,wesaythat yisinthe
language ofG, writtenL(G), ify=(y1[t],...,ym[t])for some
time step t.
RCGexpressions. Ourdefinitionofrecurrentcomputationgraphs
intentionally does not fix the expression language over which
I,F,Oare specified. To maximize theflexibilityof our approach,
RCGsareparametrizedbyasetofcomponents Coverwhichtheini-
tialization,update,andoutputexpressionsareconstructed.Recall
thatbothFandOare functions, and their arguments correspond
to the RCG’s internal states. Hence, expressions eforFandOcan
be generatedaccording to the following grammar:
e≔si|c|f(e1,...,ek)
wheresirepresents the i’th internal state, cis a constant value,
andf∈Cisafunctionofarity k.Sinceinitializationexpressions
are required to be constants, initfollows a similar grammar except
thatwedonotallowinitializationexpressionstorefertotheRCG’s
internal states.
Example 1. ThequickSort pattern from Section 2.2can be ex-
pressedasthefollowing2-stateRCGusingthecomponents plus,
append,prepend,inc,as well as integerconstants {0,1,2}.
I=(1,[0])
F=(plus(s1,2),append(prepend(inc(s1),s2),s1))
O=s2
The first few iterations of the pattern’s evaluation are shown
below,whereweuse (▷),(◁),(+)todenote append,prepend,and
plusrespectively:
s1[0]=1 s2[0]=[0]
s1[1]=1+2=3s2[1]=(inc(1)◁[0])▷1=[2,0,1]
s1[2]=3+2=5s2[2]=(inc(3)◁[2,0,1])▷3))=[4,2,0,1,3]Inthepreviousexample,theoutputstatewasexactlythesameas
one of the internal states. However,as illustratedby the following
example,this isnot alwaysthe case.
Example 2. Consider the following sequence of inputs: [ ], [1 ,1],
[1,2,1,2],[1,2,3,1,2,3],[1,2,3,4,1,2,3,4],...Thisinputpattern
can be representedusing the following RCG:
I=(0,[])
F=(plus(s1,1),append(s2,s1))
O=concat(s2,s2)
The output here is obtained by concatenating two copies of the
input state s2; however, there is no simple way to express this
pattern without distinguishing between internal and output states.
4 COMPLEXITYTESTINGASDISCRETE
OPTIMIZATION
In this section, we formulate the complexity testing problem in-
troduced inSection 2.1asanoptimalprogram synthesisproblem2.
Towards this goal, we first introduce the concept of a measurement
modelfor assigning scores to recurrentcomputationgraphs:
Definition5. (Idealmeasurementmodel) GivenanRCGG,an
ideal measurement model MmapsGto a numeric value such that:
∀G,G′.(G≻G′→M(G)>M(G′)) (4.1)
Inotherwords,anidealmeasurementmodel Massignsahigher
scoretoGcomparedtoG′ifGinducesasymptoticallyworsebe-
haviorofthetargetprogramcomparedto G′.Usingthisnotion,we
nowformulatecomplexitytestingintermsofthefollowingpattern
optimization problem:
Definition 6. (Pattern Optimization) Given an ideal measure-
mentmodelM,thepatternoptimization problemistofind anRCG
that maximizesM,i.e.,find the solution of:
argmax
GM(G) (4.2)
Because RCGs correspond to programs, Definition 6is a form of
optimal program synthesis problem, where the goal is to maximize
asymptoticresourceusage.Thefollowingtheoremstatesthatthe
pattern optimization problem is equivalent to our definition ofthe
complexitytestingproblem from Section 2.1:
Theorem 4.1. Eqn.4.2gives asolutionto Definition 3.
Proof: Suppose pattern Gsatisfies Eqn. 4.2. IfGis not a solution to
Definition 3,thenwehavesome G′suchthatG′≻G.UsingEqn. 4.1,
weknowthatM(G′)>M(G),which meansGisnot thesolution
to Eqn.4.2(i.e.,contradiction). □
Theorem 4.1isusefulbecauseitallowsustoturnthecomplexity
testingproblemintoadiscreteoptimizationproblem,assumingthat
wehaveaccesstoanidealmeasurementmodel M.However,due
to the black-box nature of our approach, Mis difficult to obtain
in practice. In particular, the ideal measurement model requires
reasoning about the asymptotic resource usage of the program
on all inputs of a given shape, but this is clearly a very difficult
2Inoptimalprogramsynthesis[ 2]thegoalistosynthesizeaprogramthatnotonly
satisfies the specification butalso maximizesthe valueof some objectivefunction
216Singularity: Pattern Fuzzing for WorstCaseComplexity ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA
staticanalysisproblem.Thus,asaproxytothisidealizedmetric,we
insteadestimatethequalityofaninputpatternbyusingan empirical
measurementmodel Mˆn.Specifically,ameasurement model Mˆn
evaluatesthequalityofagenerator Gbyrunningtheinputprogram
Pon inputs up to size ˆn. In the remainder of this paper, we use the
following empirical modelas aproxyfor Definition 5:
Definition 7. (Empirical Measurement Model) Ourempirical
measurement model , denotedMˆn, evaluates an input pattern by
returning the maximum resource usage among all inputs whose
size does not exceedbound ˆn.More formally:
Mˆn(G)=max
x∈L(G)∧Σ(x)≤ˆnΨ(x) (4.3)
Thefollowingtheoremstatestheconditionsunderwhich Mˆn
isagoodapproximation ofthe ideal model:
Theorem4.2.Mˆnisanidealmeasurementmodel(i.e.,satisfies
equation4.1)ifˆnis sufficientlylargeand wehave:
limn→∞Ψ(G≤n)=∞
Proof:Weshowthat G≻G′impliesMˆn(G)≻Mˆn(G′)underthe
conditions stated in the theorem. Suppose G≻G′. From Definition 2,
this means there exists n1such that∀n≥n1.Ψ(G≤n)>Ψ(G′
≤n).
Because we assume all patterns’ resource usage increase to infinity as
the input size grows, we can show that there exists some n2such that
∀n≥n2.Mn(G)=Ψ(G≤n)andMn(G′)=Ψ(G′
≤n)usingEqn. 4.3.
Thus,for ˆn≥max(n1,n2),wehaveMˆn(G)>Mˆn(G′).□
5 FINDING OPTIMAL RCGUSINGGP
Wenowdescribeageneticprogramming(GP)algorithmforsolving
the discrete optimization problem from Section 4. We first present
the top-level algorithm andthen explainits subroutines.
5.1 AlgorithmOverview
Our pattern maximization algorithm is summarized in Algorithm 1
and follows the typical structure of genetic programming.Specifi-
cally,westartwitharandomly-generatedinitialpopulationofRCGs
(lines 2-3) and repeatedly create a new population by combining
the fittest individualsfrom the old population.
To create a new population pop’, we create mnew RCGs by
combining individuals from the existing population popÐ this
corresponds to the forloop at lines 6-14. A new individual Gis
created by randomly choosing a genetic operator op(line 7) and
combining op.arityindividuals from the current population. While
there are several different techniques that can be used to select
individualsfromthepopulation,ouralgorithmusestheso-called
deterministictournamentmethod (lines8-9).Specifically,wesample
KRCGs and choose the RCG with the best fitness as the winner.3
GiventhenewRCG Gcreatedatline10,weevaluate G’sfitness
(line 11) using a fitness function that we discuss in more detail
in Section 5.3. IfGis fitter than the previously fittest RCG, we
3Kis a hyper-parameter called tournament size and controls the evolution pressure of
the GP process: When Kis set to 1, there is no evolution pressure and all individuals
from the population, regardless of their fitness, have the same chance to be picked by
the tournament method; hence, in this case, GP degenerates to random search. When
Kissettothesizeofthewholepopulation,onlythebestindividualofeachpopulation
canbeselected to participatein the creationof newindividuals.Algorithm1 Pattern Maximizationusing GP
Input:gpOps- the setof genericoperators to use
Input:m- population size
Input:K- tournament size
Input:ˆn- size bound for performance measurement.
Input:µ,α- hyper-parametersusedfor calculatingfitness
Output: the pattern withthe highestfitness score sofar
1:procedure FindOptimalRCG (gpOps,m,K,ˆn,µ,α)
2:pop←initPopulation (m)
3:best←findBest(pop)
4:while not converged ()do
5: pop’←∅
6: forifrom1tomdo
7: op←randomPick (gpOps)
8: forjfrom1toop.aritydo
9: argsj←tournament (pop,K)
10:G←op(args)
11:G.fitness←Mˆn(G)·e−(size(G)/µ)4·αcost(G)
12: ifG.fitness>best.fitnessthen
13: best←G
14: pop’←pop’∪{G}
15: pop←pop’
16:returnbest
Figure 6:Mutation operator
thenupdate besttobeG.Thealgorithmterminateswithsolution
bestif there has been no fitness improvement on bestfor many
generations(line4).
5.2 GeneticOperators
We nowdescribe the genetic operators usedinAlgorithm 1.
Mutation operator. The mutation operator is used to maintain
diversity from one generation to the next and prevents the algo-
rithmfrom convergingon alocalś ratherthan globalśoptimum.
ItcreatesanRCGG′fromanexistingRCG Gbyapplyingmodifica-
tions to a node in the abstract-syntax tree (AST) representation of
G.Specifically,wefirstrandomlychooseaninitialization,update,
or output expression eand then select a random node n, called
themutationpoint ,ine.Ourmutationoperatorthenreplacesthe
sub-treeTrooted at nwith a randomly generated AST with the
same type as T.Figure6illustrates this process.
217ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA JiayiWei, Jia Chen,Yu Feng, KostasFerles,andIsilDillig
Figure 7:Crossoveroperator
Crossover operator. The crossover operator is used to combine
existingmembersofapopulationintonewindividuals.Specifically,
givenRCGsG1andG2, we choose a mutation point n1of typeτin
G1aswellasanothermutationpoint n2ofthesametype τfromG2.
WethencreatetwonewRCGsbyswappingthesub-treesrooted
atn1andn2and randomly pick one of the two new RCGs. The
crossover operation isillustratedinFigure 7.
Reproductionoperator. Thereproductionoperatorisjustaniden-
tityfunctionśitsimplycopiestheselectedindividualintothenext
generation. Reproduction is used to maintain stability between
generationsbypreservingthe fittest individuals.
ConstFoldoperator. TheConstFold operatorissimilartoreproduc-
tionexceptthatitalsoperformslight-weightconstantfoldingon
the AST. Using ConstFold allows continuous evolution of constants
usedinthe RCGswithoutgrowing totalAST size.
5.3 FitnessFunction
SinceourgoalistofindanRCGthatmaximizesthetargetprogram’s
resourceusage,thesimplestimplementationofthefitnessfunction
simply uses the measurement model M. However, as standard
ingeneticprogramming,thefitnessfunctiondoesnothavetobe
exactlythesameastheoptimizationobjective.Wedesignourfitness
function to have the following three properties:
(1)It should be consistent with the measurement model M, mean-
ingthatGisconsideredfitter than G′ifM(G)>M(G′).
(2)It should prevent individuals from evolving to unboundedly
large programs bypenalizingRCGswithvery large AST size.
(3)WhentwoRCGshavesimilarsizeandresourceusage,itshould
use the Occam’srazor principleto prefer the simpler one.
Basedonthesecriteria,our fitness function Fisdefinedas:
F(G)=Mˆn(G)·e−(size(G)/µ)4·αcost(G)
wheresizemeasuresthe total ASTsize of G,andcostisa measure
of the complexity of the RCG4. Bothµandαare tunable hyper-
parameters. Specifically, µis used for bloat control: If the AST size
ofGis smaller than µ, thene−(size(G)/µ)4is close to 1; but, when
size(G)>µ,thefitnessquicklydecaysto 0.Thehyper-parameter
αmustbechosenasavaluelessthan 1anddeterminesthepenalty
factor associatedwithcomplexity.
4WedefinecomplexityintermsoftheconstantsusedintheRCG.Intuitively,thelarger
the constants used in the RCG, the higherthe cost.6 IMPLEMENTATION
We have implemented the proposed method in a tool called Singu-
larity,which consistsofapproximately6,000linesofScala code,
andmadeitpublicly avaibale onGithub[ 36]. In what follows, we
discussimportant design and implementation choices underlying
Singularity .
Resource usage measurement. Recall that our problem defini-
tionandfitnessevaluationfunctionusearesourcemeasurement
functionΨ. Weimplement Ψbycounting thenumber ofexecuted
instructionsratherthanmeasuringabsoluterunningtime,asthe
latterstrategyistoonoisyduetofactorssuchascachewarm-up,
contextswitching,garbage collection etc.
To measure the executed number of instructions, we perform
static instrumentation using the Soot framework [ 33] for Java pro-
gramsandtheLLVMframework[ 20]forC/C++programs.Inmore
detail, we initializeaninteger counterwhen theapplication starts
andincrementitbyoneaftereachinstruction.Ourimplementation
also provides a lighter-weight version of this instrumentation that
onlyincrementsthecounteratmethodentrypointsandloophead-
ers. In practice, we found this alternative strategy to work quite
well,asitstrikesagoodbalancebetweenprecisionandoverhead.
Unlessstatedotherwise,allofourbenchmarksareinstrumented
using this lightweightstrategy.
RCG components. RecallfromSection 3thatourrecurrentcom-
putation graphs are parameterized by a set of components that are
usedtoconstructexpressions.Ourimplementationcomeswitha
library of such components for most built-in types and collections.
Forinstance,thecomponentlibraryforintegersincludemethods
such asinc,dec,plus,minus,times,modetc. Similarly, for lists,
we have generic components such as append,prepend,access,
concat,lengthandsoforth.Forgraphs,wehavecomponentsthat
representemptygraphsaswellasoperationsthataddnodesand
edges (see Table 4). Since our framework is fully extendable, the
user can apply Singularity to programs that take custom data
typesτbyprovidingnewcomponentsthat operate over τ.
Parameter tuning. As mentioned earlier, genetic programming
algorithms have many tunable parameters such as population size,
tournament size, threshold µand cost penalty factor αused in
thefitnessfunctionetc.Unfortunately,theseparametersareoften
hard to configure manually due to the complex dynamics of ge-
netic programmingand the intricate interactionbetween different
parameters.Toaddressthisproblem,wedevelopedanautomatic
parameter generator which samples these parameters from a joint
distribution. When we run Singularity multipletimes ona prob-
lem,wealwaysusedifferentparametersetssampledfromthisjoint
distribution.Inourexperience,thisstrategyincreasesthelikelihood
thatSingularity willfind the desiredworst-case pattern.
7 EVALUATION
Toevaluate the usefulnessof Singularity ,we designa series of
experiments that are intendedto address the following questions:
(1)IsSingularity useful for revealing the worst-case complexity
ofagiven program?
(2)Howdoes Singularity comparewithstate-of-the-arttesting
toolsthat addressthe same problem?
218Singularity: Pattern Fuzzing for WorstCaseComplexity ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA
Table 1:Evaluationon textbook algorithms.
Algorithm Name Best Case Worst CaseFound
Worst?
Optimized Insertion Sort Θ(n) Θ(n2) ✓
Quick Sort Θ(nlogn)Θ(n2) ✓
Optimized Quick Sort Θ(nlogn)Θ(n2) ✓
3-wayQuick Sort Θ(nlogn)Θ(n2) ✓
Sequential Search Θ(1) Θ(n) ✓
Binary Search Θ(1) Θ(logn) ✓
Binary Search TreeLookup Θ(1) Θ(n) ✓
Red-Black TreeLookup Θ(1) Θ(logn) ✓
Separate Chain HashLookup Θ(1) Θ(n) ✓
Linear Probing HashLookup Θ(1) Θ(n) ✓
NFARegex Match Θ(m+n)Θ(mn) ✓
Booyer-MooreSubstring Θ(m+n)Θ(mn) ✓
PrimMinimumSpanningTree Θ(V+E)Θ(ElogV) ✓
Bellman-Ford Shortest Path Θ(1)Θ(V(V+E)) ✓
Dijkstra Shortest Path Θ(1)Θ(ElogV) ✓
Alternating PathBipartite Θ(V)Θ(V(V+E)) ✓
Hopcroft-Karp Bipartite Θ(V)Θ(E√
V) ✗
(3)IsSingularity useful for detecting algorithmic complexity
vulnerabilitiesandperformance bugsinreal world systems?
Unless stated otherwise, experiments are conducted on an Intel
Xeon(R) computer with an E5-1620 v3 CPU and 64G of memory
running onUbuntu16.04.
7.1 AsymptoticBoundAnalysis
Inthissection,weevaluate Singularity onstandardalgorithms,
such as sorting, searching, graph algorithms, and string match-
ing, that are taken from a widely-used algorithms textbook by
Sedgewick and Wayne[ 28]. The goalof this experiment is to deter-
minewhether Singularity can identify the worst-caseasymptotic
complexityofthesealgorithms.
Toensurethe benchmarksare nontrivial,we onlyfocusonal-
gorithms whose worst-case running time is known to us and is
differentfromtheirbestcases.Basedonthesecriteria,weobtain
a total of 17 algorithms. For each of them, we run Singularity
foratotaltimeof3hoursandrestartfuzzingwithadifferentran-
dom seed whenever the fitness has no improvement for more than
150generations.Finally,we determineworst-casecomplexitiesby
using input patternsthat maximize resource usage at size ˆn=250.
TheresultsofthisexperimentaresummarizedinTable 1.The
first three columns of this table provide the name of the algorithm
along withits corresponding best-caseand worst-case asymptotic
performance, and the final column shows whether Singularity is
abletotriggertheexpectedworst-casecomplexity.Todetermine
whether a pattern’s worst-case complexity has been found, we
measure its performance at different input sizes and try to fit a
linearrelationshipbetweenthetheoreticalworst-caseperformance
and the actual performance. If the data show a linear trend and the
R2metric is greater than 0 .95, we conclude that Singularity is
ableto generateinputswiththe desiredworst-case complexity.
Aswecanseefromthistable, Singularity cantriggertheworst-
case behavior in 16 of the 17 cases. For the Hopcroft-Karp bipartite
matching algorithm, the inputs generated by Singularity trigger
O(V+E)complexityratherthantheexpected O(E√
V)complexitybecause the worst-case pattern cannot be represented using our
standardsetofgraph componentslistedinTable 4.
7.2 ComparisonAgainst Wise
Toexplorehow Singularity comparesagainstothercomplexity
testingtechniques,weperformacomparisonbetween Singularity
andWise[4].UnlikeSingularity ,Wiseisawhite-boxtestingtool
based on dynamic symbolic execution. Specifically, Wiseproceeds
in two phases: In the first phase, it performs exhaustive search
onsmallinputstolearnso-called branchpolicygenerators ,which
exerciseworst-caseexecutionpaths.Inthesecondphase, Wiseuses
the output of the first phase to prune program paths that do not
conform to the learntbranchpolicygenerator.
We perform this experiment on the benchmarks that are used
for evaluating Wise[4]. We give both tools a time limit of three
hours and compare the performance of each benchmark on the
inputsgeneratedby Singularity andWise.Specifically,wełtrainž
Wiseon the same training size reported in their paper [ 4] and use
both tools to generate inputs up to size nforn∈{30,500,1000}.
Specifically,we use n=30tomatch thevalue used intheoriginal
Wisepaper.Wealsoreport n=500andn=1000todemonstrate
the advantagesofour approach over Wise.
The results of this experiment are summarized in Table 2. Here,
thesymbol ✗indicatesthatthetoolfailedtogenerateanyinputs
withinthe3hourtime-limit.Otherwise,thenumberindicatesthe
worst-case performance (in terms of instruction count) of the algo-
rithmoninputsgeneratedbyeachtool.
Themaintake-awayfromthisexperimentisthat Singularity
andWisetrigger roughly the same performance behavior in all
caseswhere Wisedoesnottimeout(i.e.,generatesaninputwithin
the 3-hour time limit). However, as we increase the value of n,
Wisefails to generate inputs on more and more benchmarks. In
particular, Wisecantriggertheworst-casebehavioron8outofthe
9 benchmarks for n=30, but this number drops to 6 for n=500
andto3for n=1000.Specifically, Wisefailstogenerateanyinputs
for large values of nbecause all paths explored by the concolic
executionenginewithinthetimelimitareprunedbythegenerator,
meaningthat Wisefailstofindanyinputsthatcantriggerworst-
casebehavior.Incontrast,bylookingforinputpatternsratherthan
concrete inputs, Singularity can scale to much larger values of n.
7.3 ComparisonAgainst SlowFuzz
Inournextexperiment,wecompare Singularity againstSlow-
Fuzz[26],astate-of-the-artfuzzingtoolforfindingavailabilityvul-
nerabilities. Similar to our approach, SlowFuzz performs resource-
usage-guided evolutionary search but generates concrete inputs , as
opposedto inputpatterns ,that maximizeresourceusage.
Wecompare Singularity withSlowFuzz intermsofscalability
andthequalityof thegeneratedinputs.SimilartoSection 7.2,we
assess scalability by running each tool on increasing input sizes
rangingfrom 64bytes to 2Kbytes. Toevaluate the qualityofthe
results,werunbothtools30timeswitha2-hourtimelimitforeach
runand compare the largestresource usageobtained byeachtool.
To reduce the time required to perform this experiment, we run
both tools on an HPC cluster with Intel Xeon Phi 7250 CPU (68
cores at 1.4GHz)and96GRAM running CentOS6.3.
219ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA JiayiWei, Jia Chen,Yu Feng, KostasFerles,andIsilDillig
Table 2:Worst-casenumberofinstructionsexecuted on the Wisebenchmarks
Benchmarksize=30 size=500 size=1000
Wise Singularity Wise Singularity Wise Singularity
SortedListinsert 262 262 4022 4023 ✗ 8023
Heap insert(JDK 1.5) 160 160 280 281 310 311
RedBlackTreeinsert 221 221 403 404 455 456
QuickSort (JDK 1.5) 3,522 3,638 ✗ 470,232 ✗ 1,815,732
BinarySearchTreeinsert 205 212 3,495 3,510 ✗ 7,010
MergeSort(JDK 1.5) 3,922 3,954 113,771 107,601 251,039 238,999
Bellman-Ford (adjacency matrix) 303,152 333,357 ✗ 1.94×109✗1.55×1010
Dijkstra (adjacency matrix) 12,363 12,620 3,496,003 3,510,006 ✗1.40×107
TravelingSalesman ✗ >1012✗ >1012✗ >1012
Symbol ✗indicates thatthe tool fails to produceany inputswithin3hour.
��������
64 128 256 512 1024 20481248163264100
FuzzingSizeUsageRatio
GeometricMean
 WeightedGeometricMean
Figure 8: Comparison against SlowFuzz .The usage ratio rep-
resents the ratio between the worst-case resource usage found by
Singularity and bySlowFuzz .
Thebenchmarksforthisexperimentincludethosereportedin
theSlowFuzz paper [26], which consist of several sorting algo-
rithms,ahashtableimplementationfromPHP,19regularexpres-
sionmatchingproblems,andaziputilityfromthe bzip2applica-
tion. We do not use the bzip2example in our evaluation since the
vulnerability is triggered only when certain bits in the input file
header are set; hence, this benchmark is not related to the input
pattern generationproblem addressedinthis paper.
Since this experiment involves 27 benchmarks and 6 different
input sizes, we report the aggregate results for each size. For each
benchmark bandsizen,weuseinputs IandI′generatedby Sin-
gularity andSlowFuzz to compute the usage ratio rn
b:
rn
b=Ψb(I)
Ψb(I′)
whereΨb(I)denotes the running time (in terms of instruction
count) of benchmark bon input I. Observe that rn
b>1indicates
that inputsgeneratedby Singularity take longer to run.
Toaggregateoverallbenchmarksforeachinputsize,weconsider
twodifferentmetrics:
•Geometricmean: Foreachinputsize sandbenchmarks b1,...,bk,
we compute the geometric mean, denoted GM(rn
b1,...,rn
bk), of
ratiosrn
b1,...,rn
bk.
•Weightedgeometricmean: Sincetheusageratio rn
biscloseto 1
forabouthalfofthebenchmarks,thegeometricmeandoesnotconveythefullstory.Instead,wewant toassignasmallweight
tocaseswherebothtoolshavesimilarperformance,andassigna
larger weight when there is a significant performance difference.
Hence,wealsocomputethefollowing weightedgeometricmean5:
WGM(rn
b1,...,rn
bk)=exp/parenleftBig/summationtextk
i=1ln(rn
bi)3
/summationtextk
i=1ln(rn
bi)2/parenrightBig
The results ofthiscomparison are summarizedinFigure 8.We
can observe two main trends based on this figure: First, Singular-
ityis able to generate inputs that cause the applications to run
significantlylongerwithinthetimeframe,showingthat Singular-
ityismore efficient than SlowFuzz in terms of fuzzing efficiency.
Second,theperformanceratiosgrowas nincreases,showingthat
Singularity scales better compared to SlowFuzz . Hence, these
resultshighlightthescalabilityadvantageofpatternfuzzingover
concrete inputfuzzing.
7.4 AvailabilityVulnerabilityDetection
To demonstrate that Singularity can generate inputs that exer-
cise non-trivial algorithmic complexity vulnerabilities, we evaluate
Singularity on ten benchmarks taken from the DARPA STAC
program. Specifically, we choose exactly those benchmarks that (a)
exhibitanavailabilityvulnerability,and(b)whereitispossibleto
constructan exploit using amalicious inputpattern.
In more detail, each STAC benchmark is a Java application con-
taining between 500 to 20,000 lines of code. Furthermore, each
benchmarkcomeswithapre-definedinputbudget bandatarget
running time t, and the goal is to craft an attack vector that causes
the running time ofthe application to exceed tusing an inputof
size at most b. Table3provides more detailed information about
theseSTAC benchmarks.
Toperformthisexperiment,werun Singularity foratotalof3
hoursoneachbenchmark.Bydefault,weuseafuzzingsizeof1KB,
unless the specifiedinputbudget bissmaller.
As summarized by the results in Table 3,Singularity is able
to generate the desired attack vector for 8 out of these 10 bench-
marks.Tounderstandthelimitationsof Singularity ,wemanually
5Likethegeometricmean,thismetricisfairbecauseifweswitch Singularity and
SlowFuzz (i.e., replace rn
biwith1/rn
bifor alli),WGM(⃗rn)becomes1/WGM(⃗rn).
Many othercommon averaging functions(e.g., arithmeticorquadraticmean)donot
havethisproperty.
220Singularity: Pattern Fuzzing for WorstCaseComplexity ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA
Table 3:Evaluationon STAC Benchmarks.
Benchmark Description InputType DSLUsed Inputbudget Target time AV found?
blogger Bloggingwebapplication URL string 5KB 300s ✓
graphAnalyzer DOT to PNG/PS converter DOT file graph 5KB 3600s ✓
imageProcessor Image classifier PNG file array 70KB 1080s ✓
textCrunchr Textanalyzer textfile string 400KB 300s ✗
linearAlgebra Matrixcomputation service Matrix array 15.25KB 230s ✓
airplan1 Online airline scheduler Graph graph 25KB 500s ✓
airplan2 Online airline scheduler Graph graph 25KB 500s ✓
airplan3 Online airline scheduler Graph graph 25KB 500s ✗
searchableBlog Webpage search engine Matrix array 1KB 10s ✓
braidit1 Online multiplayergame String string 2KB 300s ✓
investigate thosebenchmarks for which Singularity fails to find
an attackvector.
FortextCrunchr ,therootcauseoftheproblemistheempirical
measurementmodel.Inparticular, Singularity evaluatesthefit-
ness of an individual based on its performance on inputs at size
1KB, butthis ismuch smaller than theinput budget of 400KBand
results in sub-optimal patterns. While we could circumvent this
problembyusingamuchlargerinputsize,thatwouldsignificantly
increase the time to evaluate the fitness of a given input pattern,
thereby slowing downthe fuzzingalgorithm.
Forairplan3, the evaluationtime takestoo long.During fitness
evaluation, running the application on an input of size 1KB can
take more than 3 minutes, and as a result, Singularity fails to
convergeto the fittest pattern within the 3-hourtime limit.
7.5 Performance Bug Detection
To evaluate whether Singularity can help with discovering un-
knownperformance bugs in real-world projects, we run Singu-
larityon three popular Java libraries, namely Google Guava [ 15],
Vavr[34],andJGraphT[ 18].Alloftheselibrarieshavemorethan
1000starsonGithubandareusedbymorethan70otherprojects
on Maven Central. Hence, any performance issue in these libraries
islikely to have significant real-world impact.
Foreach library,we identifyaset ofpublicAPIs relatedtocon-
tainer operations or graph algorithms and write driver code to
invoke these APIs using inputs generated by Singularity . We
thenusetheinputpatternsgeneratedby Singularity todetermine
worst-case complexities by (a) generating inputs of different sizes,
and (b) fitting a curve through these data points. If the complexity
obtained by Singularity is worse than the expected worst-case,
wereporttheanomalytodevelopersandletthemconfirmwhether
this isaperformance bug.
Usingthismethodology,weidentifiedfive previouslyunknown
performance bugs, all of which have been confirmed by the devel-
opers. In what follows, we include brief descriptions of the perfor-
mance problems uncoveredby Singularity :
Performance bugs in Guava. Singularity identified two perfor-
mancebugs in the ImmutableBiMap andImmutableSet container
classesintheGuavalibrary.Bothoftheseclassesprovideamethod
calledcopyOfthatreturnsan ImmutableBiMap orImmutableSet
thatcontainsthesameelementsastheinputcollection.Whileboth
ofthesecopyOfmethodsareexpectedtotakelineartime,theinputs
generated by Singularity causeO(n2)performance. In particular,Table 4:Graph-related Components
Signature Description
emptyGraph() createan empty graph
addN(д) add anewnodeto the graph д
addE(д,v) add a new edge with two new vertices and
edgevalue vto the graph д
growE(д,v,i) add a new edge with one endpoint being an
existingnode i
growLoop( д,v,i)add anewselfloop to an existingnode i
bridgeE(д,v,i1,i2)add an edgebetween twovertices i1,i2
deleteE(д,i) delete the ithedgefrom graph д
mergeGraph( д1,д2)mergetwographs into onegraph
updateEValue( д,v,i)updatethe ithedge’svalue in graph д
addCompleteN( д,v)add a new node, then connect it to all existing
nodes withedgevalue v
Singularity triggers this worst-case behavior by causing hash
collisionsdespitetheexistenceofamechanismthattriestoprotect
against hash collisions.The inputsgeneratedby Singularity are
complexenoughtobypasstheseexistingmitigationmechanisms.
Thedetails,includingthebugreportandinputpatternsdiscovered,
are explainedin Singularity ’sdocumentation [ 35].
PerformancebuginJGraphT. Singularity identifiedaserious
performancebugintheJGraphTimplementationofthepush-relabel
maximum flow algorithm [ 13]. While the theoretical worst-case
behavior of this algorithm is O(n3),Singularity is able to find
inputsthattrigger O(n5)runningtime.Thispatterncorrespondsto
an RCG with 2 internal states and 3 output states, as shown below,
andwhere the componentsemantics are listedinTable 4:
I=(0,addNode(emptyGraph ()))
F1=plus(s1,2)
F2=growE(bridgeE(growE(s2,3,0),4,inc(s1),s1),0,0)
O=(2,1,s2)
PerformancebuginVavr. Singularity alsoidentifiedtwoper-
formanceproblemsintheVavrlibrarythatprovidesimmutableand
persistent collections. In particular, while the addAllandunion
methods of LinkedHashSet are supposed to have worst-case lin-
earcomplexity, Singularity foundinputsthattriggerquadratic
behavior. The developers have acknowledged this issue and added
acaveattothecorresponding JavaDocsthatthesemethodshave
quadratic ratherthanthe (expected)linearcomplexity.
221ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA JiayiWei, Jia Chen,Yu Feng, KostasFerles,andIsilDillig
7.6 Threatsto Validity
Randomness. SinceSingularity leveragesrandomizedalgorithms,
its performance can be affected by various factors like parame-
ter sampling and individual selection. Hence, our results may be
skewedbyunusuallyluckyorunluckyruns.Tomitigatethiscon-
cern, we run Singularity (as well as SlowFuzz ) multiple times
(≥30) andconsiderthe bestresult acrossallofthese.
Benchmark selection. Due to their own technical limitations, we
are not able to run SlowFuzz andWiseon a common set of bench-
markprograms.Instead,wecompare Singularity againstSlow-
FuzzandWiseseparately on their own benchmarks. While a com-
monbenchmarksetforalltoolsmayprovideamorecomprehen-
sive view, we believe our comparison is sufficient for showing the
strengths andweaknessesofthesetechniques.
8 LIMITATIONS
Generality. Whilethe Singularity frameworkcanbeapplied
to many different programs, it requires the user to provide suitable
componentsthatoperateovertheinputtypeofthetargetprogram.
Singularity already comes with a library of components for stan-
darddatatypes(e.g.,integers,lists,graphs),buttheuserneedsto
provideadditionalcomponentsfor customdata types.
Drivercode. WhileSingularity supportsawiderangeofcom-
monlyuseddatatypes,itexpectstheusertowritedrivercodeto
translate these DSL data structures into the format accepted by the
targetprogram.Althoughthiskindoftranslationnormallyrequires
littlemanualeffortandcanevenbeautomated,sometargetAPIs
only accept inputs with special property or of special format. In
such cases, to improve fuzzing efficiency, additional effort from the
usermay beneededtointegrate such domainknowledge intothe
driver code.
9 RELATED WORK
Testing for performance. There is a long line of work on auto-
matedtestingtechniquestouncoverperformanceproblems[ 4,8,
14,27,32,38,39].Amongthesepriortechniques, Wiseisthefirst
one to introduce the complexity testing problem, where the goal
is to determine the complexity of a given program by construct-
ing test cases that exhibit worst-case behavior. At a high level,
Wiseuses an optimized version of dynamic symbolic execution
to guide the search towards execution paths with high resource
usage. While Wiseis a white-box testing technique, our approach
ispurelyblack-box andcan scaleto larger inputsizes.
Fromatechnicalperspective,PerfSyn[ 32]ismoresimilartoour
approach in that it uses black-box evolutionary search to generate
teststhatcauseperformancebottlenecks.Specifically,PerfSynstarts
withaminimalusageexampleofthemethodundertestandapplies
a sequence of mutations that modify the original code. However, a
key difference is that PerfSynfocuses on performance bottlenecks
related to API usage, whereas our approach focuses on finding
inputpatterns that trigger worst-case complexity.
Another idea related to performance testing is empirical com-
putationalcomplexity [14].Inparticular,Goldsmithetal.propose
a technique for measuring empirical complexity by running the
program on workloads spanning several orders of magnitude insizeandfitting theseobservationstoa modelthatpredictsperfor-
mance as a function of input size. Since this technique requires the
user to manually providerepresentative workloads, our approach
iscomplementary to theirs.
Performance bug detection. As argued earlier in Section 1and
demonstratedthroughourexperiments, Singularity canbeuseful
for uncovering performance bugs. In this sense,our technique is
relatedtoalonglineofworkonperformancebugdetection[ 10,23ś
25].Mostofthesetechniquestargetnarrowclassesofperformance
problems, such as redundant traversals [ 10,23ś25], loop inefficien-
cies[11,22,31],andunnecessaryobjectcreation[ 12].Comparedto
these techniques, Singularity can to detect a broader class of per-
formancebugsbutrequirestheusertodecidewhetherthereported
worst-case complexitycorrespondsto aperformance bug.
Algorithmiccomplexity vulnerabilities. Recently,there hasbeen
significant interest in automated techniques for detecting algorith-
mic complexity (AC) vulnerabilities [ 5,7,9,21,30,30,37]. Some of
these techniques target a specific class of vulnerabilities, such as
thoserelatedtoregularexpressions[ 37].Amongapproachesthat
target a broader class of AC vulnerabilities, SlowFuzz [26] is most
closelyrelatedtoour approach.Inparticular, SlowFuzz alsouses
evolutionary search for generating inputs but performs mutations
atthebytelevel.Incontrast,ourmethodlooksforinputpatterns
rather than concrete inputs and can therefore scale better when
large inputsizesare required.
Asymptotic complexity analysis. SinceSingularity can be used
todetermineworst-casecomplexity,itisrelatedtostatictechniques
foranalyzingtheasymptoticbehaviorofprograms[ 1,3,6,16,17,
29]. Our approach is complementary to static techniques in that
wecangenerateconcreteinputsthattriggerworst-casebehavior.
For instance, our method can be used to validate the complexity
bounds reported by a static analyzer and help programmers debug
performance problems.
10 CONCLUSION
We have presented a new black-box fuzzing technique for generat-
ing inputs that trigger worst-case performance of a given program.
The key idea underlying our method is to look for input patterns
ratherthanconcreteinputsandformulatethecomplexitytesting
problemintermsofoptimalprogramsynthesis.Specifically,express
inputpatternsusingrecurrentcomputationgraphsandusegenetic
programmingtofindanRCGthatresultsinworst-casebehavior.
Ourexperimentsdemonstratetheadvantagesofourapproachcom-
paredtoothertechniquesandshowthatourmethodisusefulfor
(a) finding worst-case asymptotic complexity bounds of interesting
algorithms,(b)detectingavailabilityvulnerabilitiesinnon-trivial
programs, and (c) discovering previously unknown performance
bugsinwidely usedJava libraries.
ACKNOWLEDGEMENTS
WethanktheanonymousFSE’18reviewers,CalvinLin,andmem-
bers of the UToPiA group for their helpful feedback on earlier
drafts of this paper. This work was sponsored by DARPA award
FA8750-15-2-0096andNSF AwardCCF-1712067.
222Singularity: Pattern Fuzzing for WorstCaseComplexity ESEC/FSE’18,November4ś9, 2018, Lake Buena Vista,FL,USA
REFERENCES
[1]ElviraAlbert, Jesús CorreasFernández,andGuillermoRomán-Díez.2015. Non-
cumulative Resource Analysis. In Proceedings of the 21st International Conference
on Tools and Algorithms for the Construction and Analysis of Systems - Volume
9035. Springer-VerlagNewYork, Inc.,85ś100.
[2]James Bornholt, Emina Torlak, Dan Grossman, and Luis Ceze. 2016. Optimizing
Synthesiswith Metasketches.In Proceedingsofthe 43rdAnnualACM SIGPLAN-
SIGACTSymposiumonPrinciplesofProgrammingLanguages (POPL’16) .ACM,
NewYork, NY, USA,775ś788.
[3]Marc Brockschmidt, Fabian Emmes, Stephan Falke, Carsten Fuhs, and Jürgen
Giesl. 2016. Analyzing Runtime and Size Complexity of Integer Programs. ACM
Trans. Program. Lang. Syst. 38,4,Article13(Aug.2016),50pages.
[4]JacobBurnim,SudeepJuvekar,andKoushikSen.2009. WISE:AutomatedTest
GenerationforWorst-caseComplexity.In Proceedingsofthe31stInternational
Conference on Software Engineering (ICSE ’09) . IEEE Computer Society, Washing-
ton, DC, USA,463ś473.
[5]XiangCai,YuweiGui,andRobJohnson.2009. ExploitingUnixFile-SystemRaces
via Algorithmic Complexity Attacks. In 30th IEEE Symposium on Security and
Privacy (S&P2009), 17-20May 2009, Oakland,California, USA . 27ś41.
[6]Quentin Carbonneaux, Jan Hoffmann, and Zhong Shao. 2015. Compositional
Certified ResourceBounds.In Proceedings ofthe36th ACMSIGPLANConference
on Programming Language Design and Implementation (PLDI ’15) . ACM, New
York, NY, USA,467ś478.
[7]Richard Chang, Guofei Jiang, Franjo Ivancic, Sriram Sankaranarayanan, and
Vitaly Shmatikov. 2009. Inputs of coma: Static detection of denial-of-service
vulnerabilities. In Computer Security Foundations Symposium, 2009. CSF’09. 22nd
IEEE. IEEE,186ś199.
[8]Emilio Coppa, Camil Demetrescu, and Irene Finocchi. 2012. Input-sensitive
Profiling.In Proceedingsofthe33rdACMSIGPLANConferenceonProgramming
Language Design and Implementation (PLDI ’12) . ACM, New York, NY, USA,
89ś98.
[9]Scott A. Crosby and Dan S. Wallach. 2003. Denial of Service via Algorithmic
Complexity Attacks. In Proceedings of the 12th USENIX Security Symposium,
Washington,D.C.,USA, August 4-8,2003 .
[10]Luca Della Toffola, Michael Pradel, and Thomas R. Gross. 2015. Performance
ProblemsYouCanFix:ADynamicAnalysisofMemoizationOpportunities.In
Proceedingsofthe2015ACMSIGPLANInternationalConferenceonObject-Oriented
Programming, Systems,Languages, and Applications (OOPSLA2015) . ACM,New
York, NY, USA,607ś622.
[11]Monika Dhok and Murali Krishna Ramanathan. 2016. DirectedTestGeneration
to Detect Loop Inefficiencies. In Proceedings of the 2016 24th ACM SIGSOFT
InternationalSymposiumonFoundationsofSoftwareEngineering (FSE2016) .ACM,
NewYork, NY, USA,895ś907.
[12]Bruno Dufour, Barbara G. Ryder, and Gary Sevitsky. 2007. Blended Analysis for
Performance Understanding of Framework-based Applications. In Proceedings of
the 2007 International Symposium onSoftware Testing and Analysis (ISSTA ’07) .
ACM,NewYork, NY, USA,118ś128.
[13]A V Goldberg and R E Tarjan. 1986. A New Approach to the Maximum Flow
Problem.In ProceedingsoftheEighteenthAnnualACMSymposiumonTheoryof
Computing (STOC’86) . ACM,NewYork, NY, USA,136ś146.
[14]Simon F Goldsmith, Alex S Aiken, and Daniel S Wilkerson. 2007. Measuring
empirical computational complexity. In Proceedings of the the 6th joint meeting of
theEuropeansoftwareengineeringconferenceandtheACMSIGSOFTsymposium
onThe foundations ofsoftwareengineering . ACM,395ś404.
[15]Google. [n. d.]. Google core libraries for Java. https://github.com/google/guava .
[16]SumitGulwani,KrishnaK.Mehra,andTrishulChilimbi.2009. SPEED:Precise
and Efficient Static Estimation of Program Computational Complexity. In Pro-
ceedingsofthe36thAnnualACMSIGPLAN-SIGACTSymposiumonPrinciplesof
ProgrammingLanguages (POPL ’09) . ACM,127ś139.
[17]Jan Hoffmann, Ankush Das, and Shu-Chun Weng. 2017. Towards Automatic
ResourceBoundAnalysisforOCaml.In Proceedingsofthe44thACMSIGPLAN
SymposiumonPrinciplesofProgrammingLanguages (POPL2017) .ACM,359ś373.
[18] JGraphT. [n. d.]. A freeJavaGraphLibrary. http://jgrapht.org/ .
[19]Alexander Klink and Julian WÃďlde. 2011. Efficient Denial of Service Attacks
on Web Application Platforms. https://events.ccc.de/congress/2011/Fahrplan/
attachments/2007_28C3_Effective_DoS_on_web_application_platforms.pdf .
[Online;accessed 1-Feb-2018].
[20]Chris Lattner and Vikram Adve. 2004. LLVM: A Compilation Framework for
Lifelong Program Analysis & Transformation. In Proceedings of the InternationalSymposium on Code Generation and Optimization: Feedback-directed and Runtime
Optimization (CGO ’04) . IEEE Computer Society, 75ś.
[21]KasperLuckow,RodyKersten,andCorinaPăsăreanu.2017. SymbolicComplexity
AnalysisusingContext-preservingHistories.In SoftwareTesting,Verificationand
Validation (ICST),2017IEEE InternationalConference on . IEEE,58ś68.
[22]Adrian Nistor, Po-Chun Chang, Cosmin Radoi, and Shan Lu. 2015. Caramel:
Detectingand FixingPerformance ProblemsThat HaveNon-intrusiveFixes.In
Proceedings of the 37th International Conference on Software Engineering - Volume
1 (ICSE’15) . IEEE Press,902ś912.
[23]AdrianNistor,LinhaiSong,DarkoMarinov,andShanLu.2013.Toddler:Detecting
Performance Problems via Similar Memory-access Patterns. In Proceedings of
the2013 InternationalConference onSoftwareEngineering (ICSE’13) .IEEE Press,
562ś571.
[24]OswaldoOlivo,Isil Dillig, andCalvin Lin. 2015. Static Detectionof Asymptotic
Performance Bugs in Collection Traversals. In Proceedings of the 36th ACM SIG-
PLANConferenceonProgrammingLanguageDesignandImplementation(PLDI
’15). ACM,NewYork, NY, USA,369ś378.
[25]RohanPadhyeandKoushikSen.2017.Travioli:ADynamicAnalysisforDetecting
Data-structure Traversals.In Proceedings ofthe 39thInternational Conference on
SoftwareEngineering (ICSE’17) . IEEE Press,Piscataway, NJ, USA,473ś483.
[26]Theofilos Petsios, Jason Zhao, Angelos D. Keromytis, and Suman Jana. 2017.
SlowFuzz:AutomatedDomain-IndependentDetectionofAlgorithmicComplexity
Vulnerabilities.In Proceedingsofthe2017 ACM SIGSACConference on Computer
and Communications Security, CCS 2017, Dallas, TX, USA, October 30 - November
03,2017. 2155ś2168.
[27]Michael Pradel, Markus Huggler, and Thomas R Gross. 2014. Performance
regression testingof concurrent classes. In Proceedings ofthe 2014 International
SymposiumonSoftwareTestingand Analysis . ACM,13ś25.
[28]RobertSedgewickandKevinWayne.2011. Algorithms (4thed.). Addison-Wesley
Professional.
[29]Moritz Sinn, Florian Zuleger, and Helmut Veith. 2017. Complexity and Resource
BoundAnalysisofImperativeProgramsUsingDifferenceConstraints. Journal
ofAutomatedReasoning (2017), 1ś43.
[30]RandySmith,CristianEstan,andSomeshJha.2006. BacktrackingAlgorithmic
Complexity Attacksagainst a NIDS.In 22nd AnnualComputer Security Applica-
tions Conference (ACSAC 2006), 11-15 December 2006, Miami Beach, Florida, USA .
89ś98.
[31]Linhai Song and Shan Lu. 2017. Performance Diagnosis for Inefficient Loops. In
Proceedings of the 39th International Conference on Software Engineering (ICSE
’17). IEEE Press,Piscataway, NJ, USA,370ś380.
[32]Luca Della Toffola, Michael Pradel, and Thomas R. Gross. 2018. Synthesizing
Programs That Expose Performance Bottlenecks. In Proceedings of the 2018 Inter-
nationalSymposiumonCodeGeneration and Optimization . 1ś13.
[33]RajaVallée-Rai,PhongCo,EtienneGagnon,Laurie Hendren,PatrickLam,and
Vijay Sundaresan. 1999. Soot - a Java Bytecode Optimization Framework. In Pro-
ceedingsofthe1999ConferenceoftheCentreforAdvancedStudiesonCollaborative
Research (CASCON ’99) . IBM Press,13ś.
[34]Vavr.[n.d.]. Anobject-functionallanguageextensiontoJava8. https://github.
com/vavr-io/vavr .
[35]Jiayi Wei. [n. d.]. Singularity DSL Documentation. https://github.com/
MrVPlusOne/Singularity/blob/develop/doc/GraphComponents.md .
[36]JiayiWei.[n.d.]. SingularityGithubRepository. https://github.com/MrVPlusOne/
Singularity .
[37]ValentinWüstholz,OswaldoOlivo,MarijnJ.H.Heule,andIsilDillig.2017. Static
DetectionofDoSVulnerabilitiesinProgramsthatUseRegularExpressions.In
Tools and Algorithms for the Construction and Analysis of Systems - 23rd Interna-
tional Conference, TACAS 2017, Held as Part of the European Joint Conferences on
TheoryandPracticeofSoftware,ETAPS2017,Uppsala,Sweden,April22-29,2017,
Proceedings,Part II . 3ś20.
[38]DmitrijsZaparanuksandMatthiasHauswirth.2012. AlgorithmicProfiling.In
Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language
Designand Implementation (PLDI’12) . ACM,NewYork, NY, USA,67ś76.
[39]Pingyu Zhang, Sebastian Elbaum, and Matthew B. Dwyer. 2011. Automatic
Generation of Load Tests. In Proceedings of the 2011 26th IEEE/ACM International
ConferenceonAutomatedSoftwareEngineering (ASE’11) .IEEEComputerSociety,
Washington, DC, USA,43ś52. https://doi.org/10.1109/ASE.2011.6100093
223