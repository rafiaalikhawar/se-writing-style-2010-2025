Concolic Testing with Adaptively Changing Search Heuristics
Sooyoung Cha
Korea University
Republicof Korea
sooyoungcha@korea.ac.krHakjoo Oh∗
Korea University
Republicof Korea
hakjoo_oh@korea.ac.kr
ABSTRACT
We present Chameleon , a new approach for adaptively chang-
ing search heuristics during concolic testing. Search heuristicsplay a central role in concolic testing as they mitigate the path-explosion problem by focusing on particular program paths that
arelikelytoincreasecodecoverageasquicklyaspossible.Avariety
of techniques for search heuristics have been proposed over the
past decade. However, existing approaches are limited in that they
use the same search heuristics throughout the entire testing pro-
cess, which is inherently insufficient to exercise various execution
paths.Chameleon overcomes this limitation by adapting search
heuristicsontheflyviaanalgorithmthatlearnsnewsearchheuris-
ticsbasedontheknowledgeaccumulatedduringconcolictesting.
Experimental results show that the transition from the traditional
non-adaptive approaches to ours greatly improves the practicality
of concolic testing in terms of both code coverage and bug-finding.
CCSCONCEPTS
•Software and its engineering →Software testing and de-
bugging.
KEYWORDS
ConcolicTesting, Dynamic Symbolic Execution, Online Learning
ACM Reference Format:
Sooyoung Cha and Hakjoo Oh. 2019. Concolic Testing with Adaptively
Changing Search Heuristics. In Proceedings of the 27th ACM Joint European
Software Engineering Conference and Symposium on the Foundations of Soft-
ware Engineering (ESEC/FSE ’19), August 26–30, 2019, Tallinn, Estonia. ACM,
New York, NY, USA, 11pages.https://doi.org/10.1145/3338906.3338964
1 INTRODUCTION
Concolic testing [ 11,27] is a promising software testing technique
popular in both academia and industry [ 1,5,6,19,20,30,32,33].
Thetechniqueaimstoincreasecodecoverageasquicklyaspossible,
ultimatelyenablingeffectivebug-findinginalimitedtimebudget.
To do so, unlike random testing or fuzzing, concolic testing sys-
tematicallygeneratestest-casesbyrepeatingthefollowingprocess:
(1)itconcolically executesthesubjectprogramtocollectthepath
∗Corresponding author
Permissionto make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-5572-8/19/08 ...$15.00
https://doi.org/10.1145/3338906.3338964condition, i.e., the sequence of symbolic branch conditions exer-
cised by the current program execution, (2) it produces a new path
conditionbyselectingandnegatingabranchofthecurrentpath
condition, and (3) it solves the resulting path condition to generate
anewtest-casethatguidesthenextprogramexecutiontowardsthe
opposite ofthe selectedbranch. Becauseof this systematicnature,
concolic testing is increasingly used in diverse domains, including
operatingsystems[ 19],embeddedsystems[ 10,14],andevenneural
networks [ 30], among others.
Concolictestingincludessearchheuristicsasacriticalingredient.
To be practical for real-world applications, concolic testing must
be able to adequately address the path-explosion problem; because
real-world programs exhibit infinitely many different paths, it is
impossibletoexerciseallofthembytesting.Toaddressthischal-
lenge,concolictestingusesasearchheuristic,abranchselection
strategy that takes a path condition and selects a branch based on
itsowncriterion(itisusedinthesecondstepoftheconcolictesting
process described in the preceding paragraph). Search heuristics
allow concolic testing to preferentially explore particular classes
ofexecutionpathsthattheythinkaremosteffectivetomaximize
code coverage within a given time limit. It has been well-known
thathowtochooseandusesearchheuristicsiscriticallyimportant,
and diverse approaches have been proposed to improve concolic
testingin practice over the past decade [ 3–5,19,22,26,28].
In this paper, we propose a new approach, called Chameleon ,
for effectively employing search heuristics during concolic test-
ing. The key novelty of Chameleon isadaptively changing search
heuristics on the fly, so that the branch-selection criterion changes
as necessary throughout concolic testing in a way that maximizes
thefinalperformance.Bycontrast,alloftheexistingapproaches
foremployingsearchheuristics[ 3–5,19,22,26,28]arenotadaptive
as they use the same search heuristics over the whole process of
concolictesting.Inthispaper,wedemonstratethatthisisakeylim-
itingfactoroftheexistingapproaches,andwecanmakeconcolic
testingmuchmorepracticalforreal-worldapplicationsbybeing
adaptive.Weillustratethelimitationofexistingsearchheuristics
in more detail in Section 2.
Toenableadaptation,wepresentanalgorithmthatautomatically
learnsandswitchessearchheuristicsduringconcolictesting.The
algorithm maintains a set of search heuristics and continuously
changesthem duringthetestingprocess. Todoso,wefirstdefine
the space of possible search heuristics using the idea of parametric
searchheuristicrecentlyproposedinpriorwork[ 5].Atechnical
challengeishow toadaptively switchsearch heuristicsin thepre-
definedspace.Weaddressthischallengewithanewconcolictesting
algorithmthat(1)accumulatestheknowledgeaboutthepreviouslyevaluatedsearchheuristics,(2)learnstheprobabilisticdistributions
oftheeffectiveandineffectivesearchheuristicsfromtheaccumu-
lated knowledge, and (3) samples a new set of search heuristicsESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Sooyoung Cha and Hakjoo Oh
from the distributions. The algorithm iteratively performs these
three steps until it exhausts a given time budget.
Experimentalresultsdemonstratethatshiftingfromtheclassi-
cal non-adaptive approaches to ours is essential for improving the
practicality of concolic testing. We implemented Chameleon on
top of CREST [ 8] and compared it with six existing approaches on
8 open-source C programs (up to 165KLoC). For all benchmarks,
Chameleon outperformed all existing non-adaptive search heuris-
ticsintermsofbothbranchcoverageandbug-findinginapractical
setting.Inparticular, Chameleon washighlyeffectiveinfinding
various types of bugs, including segmentation faults, abnormal
termination, and memory exhaustion. For the latest versions of
vim,gawk, andgrep,Chameleon succeeded to trigger those bugs
whereas all non-adaptive techniques failed to do so.
Contributions .Our contributionsare as follows:
•We present Chameleon , a new approach for performing
concolictesting,whichadaptivelylearnsandchangessearch
heuristics online. To our knowledge, our work is the first
thatraises theneed foradapting searchheuristics. Existing
workshavefocusedoncomingupwithnewbutnon-adaptive
search heuristics [ 3–5,19,22,26,28].
•We provide extensive evaluation by comparing Chameleon
with six existing search heuristics in terms of branch cover-
ageandbug-finding.Wemakeourtool1anddatapublicly
available.
2 CONVENTIONAL CONCOLIC TESTING
In this section, we describe traditional concolic testing and ex-
plain in what sense it is non-adaptive. Algorithm 1and2describe
a conventional method for performing concolic testing, which
encapsulates the commonality of the approaches used in prior
work [3,5,11,12,28].
Theprocedure Concolic inAlgorithm 1takesasinputaprogram
(P) under test and a search heuristic ( Heuristic ), runs the program
concolically withthegivensearchheuristic,andproducesasoutput
the set (B) of branches covered during the concolic execution. We
assumethataninitialinput v0isfixedandgivenforthesubjectpro-
gramP(line2).Thealgorithminitiallysets Btotheemptyset(line
3) and repeats the body of the loop at lines 4–9 for Ntimes, where
Ndetermines the number of times to execute the program with
the current search heuristic. At line 5, the program is concolically
executedwiththecurrentinputvector v(i.e.,Execute(P,v)),which
producesthepathcondition Φ=ϕ1∧···∧ϕn,i.e.,aconjunction
of symbolic branch conditions taken in the current execution. For
instance,assumethatthetwobranchconditionsexercisedbythe
execution are (x>1)and(x>10). When the symbolic variable
forxisα, the path condition Φisϕ1∧ϕ2, whereϕ1=(α>1)and
ϕ2=(α>10). At line 6, the algorithm accumulates the covered
branches in the set B(where we write Branches (Φ)for the branch
ids covered by the current execution path). At line 7, the algorithm
uses the search heuristic ( Heuristic) to choose a branch ϕito be
negated in the next iteration. Then, at line 8, we generate a new
input vector vby finding a model of the constraint/logicalandtext.1
j<iϕj∧¬ϕi
1Chameleon : https://github.com/kupl/ChameleonAlgorithm1 Basic ConcolicTesting Procedure
Input:A program ( P) under test and a search heuristic ( Heuristic )
Output: The set (B) of covered branches
1:procedure Concolic(P,Heuristic )
2: v←v0 ⊿initial input v0
3:B←∅
4:form=1toNdo
5: Φ←Execute(P,v) ⊿Φ=(ϕ1∧···∧ϕn)
6: B←B∪Branches (Φ)
7: ϕi←Heuristic (Φ) ⊿choose a branch
8: v←model(/logicalandtext.1
j<iϕj∧¬ϕi)
9:end for
10:returnB
11:end procedure
viaanSMT solver.2Thealgorithmrepeats theprocessdescribedso
far, and returns the set Bupon termination.
Algorithm2 Conventional Method for Running Concolic Testing
Input:ProgramP, A setHof search heuristics
Output: The setTof covered branches
1:procedure Run(P,H)
2:T←∅
3:repeat
4: for eachh∈Hdo
5: B←Concolic(P,h)
6: T←T∪B
7: end for
8:untiltimeout
9:returnT
10:end procedure
Algorithm 2describes how the procedure Concolic is used in
practice. The procedure Runtakes a program Punder test. Also, in
ordertogeneralizeexistingapproaches[ 3–5,11,12,22,28],ittakes
a finite set Hof search heuristics as input. Then, the algorithm
repeats the following process: 1) it performs Concolic with each
heuristic hinH(line 5), and 2) it adds covered branches ( B)t o
the setTof total branches (line 6). When the given time budget is
exhausted, the algorithm returns the set of branches covered so far.
Readersmightwonder why we use Algorithm 2insteadof simply
using Algorithm 1with larger N. In practice, running Algorithm 2
typically performs better than running Algorithm 1alone because
oftherandomnessofsearchheuristics.Weempiricallycorroborate
this claimin Section 4.5.
Existingapproachesforperformingconcolictestingcanbeun-
derstood as instances of Algorithm 2. Most of the existing ap-
proaches to concolic testing use the algorithm with a single search
heuristic.Forexample,BurnimandSen[ 3]performconcolictest-
ing by running Run(P,{CFDS}), whereCFDSis a search heuristic
that exploits the control-flow information of the program. Seo and
Kim [28] propose to run Run(P,{CGS}), whereCGSis a search
heuristic that performs the context-guided breadth-first search on
the execution tree. Cha et al. [ 5] also use the algorithm with a
single heuristic, i.e., Run(P,{Param}), whereParamis a search
2If the constraint is unsatisfiable, the algorithm uses the search heuristic again to
choose another branch, which we omit in Algorithm 1for simplicity.Concolic Testing with Adaptively Changing Search Heuristics ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
Figure1:Venndiagramsofthenumberofbranchescovered
by each search heuristic.
heuristicgeneratedautomaticallybyalearningalgorithm.Afew
approaches[ 4,22]usethealgorithmwithanumberofsearchheuris-
tics(e.g.,Run(P,{CFDS,CGS}))soastocombineexistingheuristics
in a round-robin fashion.
Note that the conventional approach to concolic testing (i.e.,
Algorithm 2)isnon-adaptive inthatitusesthesameset Hofsearch
heuristicsineveryiterationoftheouterloopatlines3–8.Inthispa-per,wearguethatthisisakeylimitingfactorinexistingapproaches.Usingafixedsetofsearchheuristicsimpliesfixedbranch-selectioncriteria,whichisessentiallylimitedtofavoringspecificareasoftheprogramonly.Inotherwords,differentsearchheuristicsarelargelyincomparableintermsofthebranchsetsthattheycancoverduring
concolic testing. For example, Figure 1shows that there is no clear
winneramongthetopthreeheuristicsforeachprogram,wherewe
ranAlgorithm 2for24hoursperheuristictocomparethesetsof
branches covered by them. In this paper, we aim to mitigate this
problemby adaptively changingsearchheuristicsduringconcolic
testing.
3 OUR APPROACH TO CONCOLIC TESTING
Unlike conventional concolic testing, our approach is adaptive and
changestheset Hofsearchheuristicsoverthecourseofthetesting
process.Toachievethis,weneedtodefineaspaceofpossiblesearch
heuristics and to develop an algorithm that can continuously learn
anewsetofsearchheuristicsfromthespaceduringtheconcolic
testingprocess. Thelatter constitutes thekey contributionofthis
paper(Section 3.2).Fortheformer,weusetheideaofparametric
search heuristic recently proposed in prior work [ 5].
3.1 ParametricSearch Heuristics
Our work builds on the idea of parametric search heuristics [ 5],
whichdefinesthespaceofpossiblesearchheuristicsusedinourap-
proach.Chaetal.[ 5]definedasearchheuristic,denoted Heuristic w,
whichhas a parameter was follows:
Heuristic w(Φ)=argmax
ϕj∈Φscore w(ϕj)(Φ=ϕ1∧···∧ϕn)
where the parameter w=/angbracketleftθ1,...,θd/angbracketrightis ad-dimensional vector
of real numbers. Heuristic wtakes a path-condition Φand selects a
branchϕjwiththehighestscore.Tocomputescoresofbranches,
each branch ϕis represented by a feature vector. A feature featiAlgorithm3 Our Approach to Concolic Testing
Input:ProgramP
Output: The setTof covered branches
1:/angbracketleftK,T/angbracketright←/angbracketleft∅,∅/angbracketright
2:H←{ (ϵ,h1),...,(ϵ,hη1)|hi∼ U([−10,10]d)}
3:repeat
4:G←∅
5:for each (_,h)∈Hdo
6: B←Concolic(P,Heuristic h)
7: T←T∪B
8: G←G∪{ (h,B)}
9:end for
10:K←ifK=∅thenGelseRefine(K,G,H)
11:(K1,K2)←Select(K)
12:H←Switch(K1,K2)
13:untiltimeout
14:returnT
denotes a predicate describing characteristics of branches:
feati:B→{0,1}.
whereBisthesetofbranchesintheprogram.Forinstance,afeature
maydescribewhetherthebranch ϕislocatedinsidealoopbodyor
not.Iftrue,the feati(ϕ)is1;otherwise,itis0.Withapredefinedset
ofdfeatures, we are able to represent a branch by a d-dimensional
boolean vector as follows:
feat(ϕ)=/angbracketleftfeat1(ϕ),feat2(ϕ),...,featd(ϕ)/angbracketright.
In this paper, we reused the 40 features (i.e., d=40) presented in [ 5],
where these are divided into 12 static and 28 dynamic features.
Using the predefined features, we transform each branch in a path-
conditionintoafeaturevector.Then,thescoreforeachbranch ϕ
iscalculatedbyalinearcombinationofthefeaturevector feat(ϕ)
and a given d-dimensionalweight vector w:
score w(ϕ)=feat(ϕ)·w.
Lastly, we choose a branch ϕjwith thehighestscore in Φ.
Withtheparametricsearch heuristic described above, a search
heuristicscorresponds to a d-dimensionalweight vector. Thus, in
therestofthispaper,wewillcallthe d-dimensionalreal-number
vectors search heuristics when there is no confusion. With this
convention, we write H=Rdfor the space of possible search
heuristics,where Rdenotes real numbers between −10 and 10.
3.2 Overall Algorithm
OurapproachreusesAlgorithm 1withoutmodificationbutreplaces
Algorithm 2by Algorithm 3. Unlike Algorithm 2, our algorithm
doesnottakesearchheuristicsasinput;instead,itadaptivelylearns
andchangesthemthroughouttheprocessofconcolictesting.At
eachiterationoftheouterloop(i.e.,therepeat-untilloopatlines
3–13),thealgorithmevolvesthreesets: H⊆H×Hisasetofsearch
heuristics, K⊆H×℘(B)theaccumulatedknowledgeaboutprevious
searchheuristicsfromwhichwelearnnewheuristics,and T⊆B
thesetofbranchescoveredsofar.Ouralgorithmrepresentsasearch
heuristic by a pair (h/prime,h)in order to keep track of the birthplace
information; the second component his the actual heuristic that
weareinterestedinthecurrentiterationwhilethefirstcomponent
h/primeis theparentofhthat gave rise to hin the previous iteration.ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Sooyoung Cha and Hakjoo Oh
The algorithm begins with η1randomly generated heuristics (line
2) (we fixed η1=100 in experiments):
H={(ϵ,h1),(ϵ,h2),...,(ϵ,hη1)}
whereh1,...,hη1areindependentrandomsamplesfromtheuni-
form distribution U([−10,10]d)andϵindicates that the initial
search heuristics do not have parents. Initially, KandTare empty
(line1).Withtheinnerloopatlines5–9,thealgorithmperforms
concolic testing (i.e., Concolic(P,Heuristic h)) with each heuristic
inHand generatesthe data Gas follows:
G={(h1,B1),...,(h|H|,B|H|)}
wherehiisthecurrentheuristic(i.e., (h/prime,hi))inHandBiistheset
ofbranchescoveredbyrunningconcolictestingwith hi.Atthefirst
iteration, KbecomesGatline10since Kisinitiallyempty.Starting
with this initial knowledge and search heuristics, the algorithm
keeps updating them. The knowledge is refined at line 10 usingtheprocedure
Refine,andatlines11and12,anewsetofsearch
heuristicsisgeneratedfromtheknowledgeusingtheprocedures
SelectandSwitch.Thealgorithmrepeatstheprocessaboveuntil
a given time budget is exhausted. Upon termination, it returns the
setTof covered branches.
Example 3.1. Suppose that we have a set Hof four initial heuris-
tics,h1,h2,h3andh4, and running the Concolic procedure with
each heuristicproduces the following data:
G={(h1,{1,2,3,4}),(h2,{1,2,3}),(h3,{5,6}),(h4,{2,3})}(1)
ThesetGmeansthattheheuristic h1succeedsincoveringbranches
1,2,3and4,theheuristic h2coveredbranches1,2,and3,andso
on. Notethatat the end of the firstiteration, the knowledge Kis
identical to G. This way, the algorithm accumulates Kthat will be
usedinlateriterationstoadaptivelyproducenewsearchheuristics.
Inessence,ouralgorithmaimstocontinuouslyswitchthecur-
rent setHof search heuristics to a new one H/prime, so that concolic
testing with H/primecan exercise new branches that were not explored
in previous iterations. That is, we would like to find a sequence of
sets of search heuristics H0,H1,H2,...suchthat/uniondisplay.1
(_,h)∈H0Concolic(P,h)∪/uniondisplay.1
(_,h)∈H1Concolic(P,h)∪···
ismaximizedwithinagiventimebudget.Algorithm 3canbeun-
derstood as a practical solution for this problem, which does so
by combining the three procedures Refine,Select, andSwitch
described below.
3.3 Select
Letusfirstdescribetheprocedure Select.Thegoalof Selectisto
select two sets, namely K1andK2, of search heuristics from K:
Select(K)=(K1,K2).
Intuitively, K1andK2representthemosteffectiveandmostineffec-
tivecombinationsofsearchheuristicsin Kthatcollectivelyachieve
thehighestandlowestcoverages,respectively,wherethesizesof
K1andK2are fixed to η2, a predetermined hyperparameter of our
algorithm. In practice, we set η2to be⌊|K|×0.03⌋, selecting 3% of
K. Formally, K1is defined to be a set satisfying the two conditions:
(1)K1is a subset of Ksuchthat |K1|=η2, and(2) for all K/prime
1⊆s.t.|K/prime
1|=η2,
/barex/barex/uniondisplay.1
(h,B)∈K/prime
1B/barex/barex≤/barex/barex/uniondisplay.1
(h,B)∈K1B/barex/barex.
Similarly, K2isasubsetof Ksuchthat |K2|=η2and|/uniontext.1
(h,B)∈K2B|
isminimized.Thesetop- η2andbottom- η2heuristicswillbeusedfor
adaptivelylearningthedistributionsoftheeffectiveandineffective
search heuristics in the next step.
Example 3.2. Consider Example 3.1, where the current knowl-
edgeKis identical to the set Gin (1). Then,Select(K)produces
the following K1andK2whenη2=2:
K1={(h1,{1,2,3,4}),(h3,{5,6})},K2={(h2,{1,2,3}),(h4,{2,3})}
Inwords: h1andh3aretop-2heuristicsthatcancoverasdiverse
branches as possible. On the other hand, h2andh4are bottom-2
heuristicsthatcovertheleastnumberofbranches.Thebranches
covered by K1andK2are{1,2,3,4,5,6}and{1,2,3}, respectively.
Findingthesets K1andK2correspondstosolvingthemaximum
coverageproblem(MCP),whichisNP-hard.Weuseasimplegreedy
algorithm[ 15]thatprogressivelyselectssetelementsthatcollec-
tivelymaximize(orminimize)thenumberofbranchescoveredat
each step.
3.4 Switch
Once we select K1andK2, we learn new search heuristics based
on the distributions of K1andK2. The idea is to produce search
heuristics that are statistically similar to those in K1but dissimilar
to those in K2. To do so, we collect the following set:
/uniondisplay.1
(h,B)∈K1Offspring (h,K2). (2)
That is, we consider each heuristic h∈K1in turn, and produce its
offspringas follows:
Offspring (h,K2)={(h,h1),...,(h,hη3)}.
η3is a hyperparameter that determines the number of offspring of
each parent h∈K1(we setη3=10 in experiments). To generate
his that are similar to hbut dissimilar to those in K2, we randomly
sampleeachheuristic hi,whichisa d-dimensionalvectorofweights,
fromthesamplespace S1×S2×···×Sd,whereSjisasetofreal
numbersdefined as follows:
Sj=Sample({hj}) \\Sample({h/primej|(h/prime,_)∈K2})(3)
wherehjdenotes the j-th component of vector handSample(R)
samples real numbers from the truncated normal distribution with
meanμ(R), standard deviation σ(R), and the interval [−10,10]:
Sample(R)={r1,r2,...,rn|ri∼N(μ(R),σ(R),−10,10)}.
where the number ( n) of samples, unless too small, does not matter
andμ(R)andσ(R)denotethemedianandstandarddeviationofthe
setRof real numbers:
μ(R)=/summationdisplay.1
r∈Rr
|R|,σ(R)=⎧⎪⎪⎨
⎪⎪⎩/radicalbigg/summationtext.1
r∈R(r−μ(R))2
|R|if(|R|>1)
1 otherwise
andS\\S/primecomputesthefollowing:
S\\S/prime={{ ⌊e⌋|e∈S}} \ {{ ⌊e⌋|e∈S/prime}}.Concolic Testing with Adaptively Changing Search Heuristics ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
Thenotation {{ }}indicatesthat thesetsare multisetsallowingdu-
plicated elements. For instance, for S={2.7,3.1,3.4,5.2}and
S/prime={1.6,2.4,3.3,4.9},S\\S/prime={{2,3,3,5} }\{ {1,2,3,4}}={{3,5}}.
Notethat,whenweconstructthesamplespacein( 3),wegenerate
distributionsbyconsidering allweightsofthe j-thfeaturevector h/prime
inK2(i.e.,Sample({h/primej|(h/prime,_)∈K2}))whereaswetreatheuristics
inK1separately. The intuition is to maintain the relationships
between the features that each top heuristic in K1mayhave, while
maintaining the relationships between the features that all bottom
ones inK2musthave. We found that this is an important choice
for our algorithm to fully exploit the current knowledge; it enables
thealgorithmtoproducenewheuristicsthatresemblegoodones
whileeffectivelyavoiding bad ones.
With the set collected in ( 2), the procedure Switch(K1,K2)is
defined as follows:
Switch(K1,K2)=Exploit∪Explore
whereExploitis the set that contains η1×η4heuristics selected
from the set in ( 2) andExploreis the set of η1×(1−η4)randomly
generated heuristics to enable exploration:
Explore={h1,...,hη1×(1−η4)|hi∼ U([−10,10]d)}
whereη4is the hyperparameter that controls the tradeoff between
exploitation and exploration. We set η4to 0.8 in experiments.
Feature Selection .Toreducethespaceofcandidatesearchheuris-
tics,wecanoptimizetheprocedure Switchviafeatureselection.
When we construct the sample space Sjfor thej-th weights in ( 3),
wesimplydefine Sj={0}ifthej-thfeatureisuninformative.We
consider the i-th feature is uninformative if the weights of that
feature in K1are statistically similar to those in K2. To calculate
the similarity, we first define the two sets, GiandBi, as follows:
Gi={θi|( /angbracketleftθ1,θ2,···,θd/angbracketright,_)∈K1}
Bi={θi|( /angbracketleftθ1,θ2,···,θd/angbracketright,_)∈K2}
whereGiandBiaresetsconsistingofthe i-thcomponentsofthe
weight vectors in K1andK2, respectively. Second, we collect the
features whose weights are similar in K1andK2:
F={i∈[1,d]|similar(Gi,Bi)}
wheresimilar(Gi,Bi)is true when the distributions of GiandBi
are similar in the following sense:
similar(Gi,Bi)⇐ ⇒|μ(Gi)−μ(Bi)|+|σ(Gi)−σ(Bi)|<1.
Once we compute the set Fof uninformative features, we define
Sj={0}ifj∈F.
3.5 Refine
The role of Refinerefines the current knowledge Kto make learn-
ingmoreeffective.Theprocedure Refinetakesthreesets: K,G,and
H, whereKis the knowledge from the previous iteration, Gis the
newlygeneratedknowledgefromthecurrentiteration,and Histhe
current set of search heuristics. Given (K,G,H),Refine(K,G,H)
produces the refined knowledge K/primeas follows:
K/prime=(K∪G)\Kill
Itfirstaugmentsthepreviousknowledge Kwiththenewone Gand
thenremovestheset Killfromtheresult.Intuitively, Killdenotesthe parent heuristics that are turned out to be no longer useful
atthecurrentiterationofthealgorithm; Killisthesetofparents
whoseoffspringtotallyfailedtocovernewbranches.Weremove
thoseheuristicsin Kinordernottoexploittheminvainagainin
lateriterations,whichmakes the overall learning process smarter.
Formally, Killis defined as follows:
Kill={(h/prime,B/prime)∈K|(h/prime,_)∈H,/uniondisplay.1
(h/prime,h)∈H,(h,B)∈GB⊆/uniondisplay.1
(h,B)∈KB}.
In words: (h/prime,B/prime)inKis removed if h/primeis a parent of some cur-
rent search heuristics in H, i.e.,(h/prime,_)∈H, and the offspring of
h/primefail to exercise new branches over the current knowledge, i.e.,/uniontext.1
(h/prime,h)∈H,(h,B)∈GB⊆/uniontext.1
(h,B)∈KB.
Example3.3. Consider thesecond iteration of Algorithm 3and
the set in ( 1) is the previous knowledge:
K={(h1,{1,2,3,4}),(h2,{1,2,3}),(h3,{5,6}),(h4,{2,3})}
andthecurrent H(withη3=2)is{(h1,h5),(h1,h6),(h3,h7),(h3,h8)}
with thefollowingprofiles:
G={(h5,{1,3,4,6}),(h6,{1,2,3,4,5,6}),(h7,{5,7}),(h8,{3,8})}
Then, the set Killis as follows:
Kill={(h1,{1,2,3,4})}
becausetheoffspringof h1areh5andh6,andtheset {1,2,3,4,5,6}
of branches covered by h1andh5according to Gis subsumed by
the set of branches contained in the previous knowledge K. The
refined knowledge is:
K/prime={(h2,{1,2,3}),(h3,{5,6}),(h4,{2,3}),(h5,{1,3,4,6}),
(h6,{1,2,3,4,5,6}),(h7,{5,7}),(h8,{3,8})}.
Note that h1is removed from K, so it will not be selected for ex-
ploitationin the future iterations of Algorithm 3.
Hyperparameters .Ouralgorithminvolvesfourhyperparame-
ters(η1,η2,η3,andη4)forwhichappropriatevaluesareassumedto
begivenbeforehand.Thefirsthyperparameter η1determinesthe
poolsizeofsearchheuristics. η2intheSelectproceduredenotes
the number of effective (and ineffective) search heuristics to be se-
lectedfromtheknowledge K.Theremainingtwohyperparameters
arerequiredinthe Switchprocedure; η3determinesthenumber
ofoffspringtobegeneratedfromeacheffectiveheuristicandthe
lastoneη4isthe exploitationrate.Inexperiments, weset η1=100,
η2=⌊|K|×0.03⌋,η3= 10, and η4=0.8. Basically, we decided these
hyperparameters by trial and error but found that most of them
require no fine tuning. An exception was η4, for which choosing a
rightvalue wasimportantfortheperformance.InSection 4.5,w e
discuss how the performance changes with different values of η4.
4 EXPERIMENTS
Inthissection,weevaluatetheeffectivenessofourapproach.We
implemented our approach in a tool, called Chameleon, on top
ofCREST[ 8]andParaDySE[ 5].CRESTisanopen-sourceframe-
work for concolic testing of C programs widely used in prior work
(e.g., [3,5,6,9,22,24,28]). ParaDySE provides a publicly available
implementation3oftheparametricsearchheuristicinSection 3.1.
We evaluateChameleonfrom the three perspectives:
3https://github.com/kupl/ParaDySEESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Sooyoung Cha and Hakjoo Oh
Table 1: 8 benchmark programs
Program #Branches LOC Source
vim-5.7 35,464 165K [ 3,5,6,25]
gawk-3.0.3 8,038 30K [ 5,6]
grep-2.2 3,836 15K [ 3,5,6,28]
sed-1.17 2,650 9K [ 5,6,21]
cdaudio 358 3K [ 5,17,28]
floppy 268 2K [ 5,17,28]
kbfiltr 204 1K [ 5,17,28]
replace 196 0.5K [ 3,5,21,28]
(1)Branch coverage: How effectively does Chameleon in-
crease branch coverage? How does it compare to conven-tional concolic testing with existing non-adaptive search
heuristics?(Section 4.2)
(2)Bug-finding: How effectively does Chameleon find bugs?
Doesitfindmorebugsthanconventionalconcolictesting?
Doesitfindnontrivialbugsthatarehardtofix?(Section 4.3)
(3)Efficacyoflearningalgorithm: Isourlearningalgorithm
(Section3) essential for achieving the desired results? How
effective is it compared to simpler techniques? (Section 4.4)
4.1 ExperimentalSetup
Benchmarks .Weevaluated Chameleon on8open-sourcepro-
grams in Table 1. We used these benchmarks because they were
commonlyusedinpreviousworksonconcolictesting[ 3,5,6,17,
21,25,28].Thesebenchmarks aredividedinto4largeand 4small
programs. The former consists of vim,gawk,grep, andsed, which
haveatleast2,000branches;thelatterincludes cdaudio,floppy,
kbfiltr, andreplace. We did not use expat-2.10, which is used
in[5,28],becausewefounditislesssuitableforconcolictesting
withoutpriorknowledge about the input format (XML).
Existing Search Heuristics .We compared Chameleon with
six recent or well-known search heuristics: Param(Parametric
Search) [5],CGS(Context-Guided Search) [ 28],CFDS(Control-Flow
Directed Search) [ 3],Gen(Generational search) [ 12], andRandom
(Randombranchsearch) [ 3],andRoundRobin (RR).RoundRobin is
a combination of the first five heuristics, which uses them in a
round-robin fashion. CFDSandRandomare available in CREST, and
Param,GenandCGSareavailableinParaDySE.Wedidnotconsider
naive heuristics such as DFSandBFS, because their performance is
not competitive as shown in the prior works [ 3,5,28].
Time Budget .Weallocated 24hours asatesting budgetto the
fourlargeprogramswhileallocatingonehourtothefoursmallones.
Forthelargeprograms,wegaveenoughtimebudget(i.e.,24hours)
to compare the performance of Chameleon and existing search
heuristicsinatrulypracticalsetting.Bycontrast,weobservedthat
thetimebudgetscommonlyusedinpreviousworksarenotvery
realistic.Forexample,previousworksonsearchheuristics[ 3,5,28]
conducted experiments with small time budgets needed to execute
each program4,000 times,which correspondsto 1–30minutes for
thebenchmarkprogramsinTable 1inourenvironment.According
to our experience, these budgets are too small to appropriatelyTable 2: Average branch coverage achieved by Chameleon
and 6 search heuristics on 4 small benchmarks
Chameleon RR CFDS CGS Param Gen Random
cdaudio 250 250 250 250 250 250 250
floppy 205 205 205 205 205 205 196replace 181 181 181 181 181 181 181kbfiltr 149 149 149 149 149 149 149
Table 3: The number of branches exclusively covered by
each technique on 4 large benchmarks
Chameleon RR CFDS CGS Param Gen Random
vim-5.7 36437 62 163 272 50 82
gawk-3.0.3 13643 4 0 1 4
grep-2.2 5504 3 0 0 0
sed-1.17 4309 3 7 3 0
Total 59841 78 173 279 54 86
evaluatethepracticalperformanceofconcolictesting,especially
for large programs such as vim.
Others.All experiments were conducted under the same set-
tings. First, we used the same initial inputs provided together with
eachbenchmarkprogram.Second,weconductedallexperiments
on the same machine withtwo Intel Xeon Processors E5-2630 and
192GB RAM. Third, we performed concolic testing on a single core
forallbenchmarksexceptfor vim.Thisisbecausewefoundthat
the branch coverage did not converge within 24 hours for vim.W e
accelerated the convergence by running concolic testing for vim
using10coresinparallel,whichmeansatotalof240hoursarein
fact spent for testing vim.4Forth, we set Nin Algorithm 1to 4,000.
Finally, to calculate the average performance of the six existing
heuristicsand Chameleon ,werepeatedalltheexperiments3times
and averaged the results.
4.2 BranchCoverage
Let us first compare Chameleon and conventional concolic test-
ing in terms of branch coverage. We use two metrics, average
branchcoverageandexclusivelycoveredbranches.Inbothcases,
Chameleonperforms much better than existing approaches.
Average Branch Coverage .Figure2compares average branch
coverageachievedby Chameleon andconventionalapproacheson
four large benchmarks. The results show that Chameleon impres-
sivelyoutperformstheexistingapproachesinallcases.Inparticular,
theresultsforthetwolargestprograms( vimandgawk)arenotewor-
thy:Chameleon was able to reach 15,468 branches covering 399
morebranchesthan Param,astate-of-the-artthatalreadycovers283
more branches over RoundRobin . Forgawk,Chameleon covered
3,564 branches while the second best heuristic ( RoundRobin ) man-
agedtoexercise3,350brancheswithinthesametimebudget.For
grepandsed,Chameleon was the clear winner as well, covering
2,271and1,696branches,respectively.Forthesmallbenchmarks,
4Algorithms 2and3are easily parallelizable without dependency between parallel
tasks.Concolic Testing with Adaptively Changing Search Heuristics ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
Figure 2: Average branch coverage achieved byChameleonand 6 search heuristics on 4 large benchmarks
Figure 3: Venn-diagrams depicting the sets of branches covered by the top-3 heuristics for each large benchmark
Chameleon andothers,exceptfor Random,achievedexactlythe
same branchcoverage within the 1 hour time budget (Table 2).
Exclusively Covered Branches .Wealsocompared Chameleon
andtheexistingapproachesintermsofthesetofcoveredbranches.
Table3reports the number of branches that each technique exclu-
sivelycovered over the other 6 techniques. In this metric as well,
Chameleon ismuchbetterthantheexistingsearchheuristics.In
total, 598 branches were covered exclusively by Chameleon .I n
particular,notethat,forallbenchmarksexceptfor vim,thenumber
ofuniquebranchescoveredby Chameleon aloneisgreaterthanthenumberofuniquebranchescoveredby alltheothertechniques,
which implies that Chameleon is better than anycombinations
ofthesixexistingheuristics.Forexample,for gawk,theformeris
136 while thelatteris 16. Similarly,for grep, the number ofunique
branches covered by Chameleon is about 8 times more than the
numberofbranchesthatalltheothertechniquesexclusivelycan
cover.For vim,Chameleon isstillthebestbutitisnotenoughto
say it is a clear winner. This is because the size of vimis so large
that all the techniques, including Chameleon , have not converged
yet even though we performed concolic testing for 24 hours usingESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Sooyoung Cha and Hakjoo Oh
Table 4: Comparison of bug-finding ability of ours (Chameleon) and existing approaches on 4 large benchmarks.
Benchmarks Versions Error Types Bug-Triggering Inputs OURS Param RR CGS CFDS Gen Random
vim8.1* Non-termination K1!1000100100111110(    
5.7Abnormal-termination H:w>>ˋ"ˋ\ [press ‘Enter’]    
Segmentation fault =ipI\-9∼qOqw     
Non-termination v(ipaprq&T$T    
gawk4.2.1* Memory-exhaustion '+E_Q$h+w$8==++$6E8#'    
3.0.3Abnormal-termination 'f[][][][][y]^/#['      
Non-termination '$g?E2^=-E-2"?^+$=":/?/#["'    
grep3.1*Abnormal-termination '\(\)\1*?*?\|\W*\1W*'    
Segmentation fault '\(\)\1^*@*\?\1*\+*\?'     
2.2Segmentation fault "_^^*9\|^\(\)\'\1*$"     
Non-termination '\({**+**\)*\++*\1*\+'      
sed 1.17 Segmentation fault '{:};:C;b'     
10 cores in parallel. Figure 3shows the Venn-diagrams that depict
the relationships between the branches covered by each technique,
where we only consider top-3 techniques for each benchmark.
4.3 Bug-Finding
Nowwecompare Chameleon andconventionalconcolictesting
in terms of bug-finding. In short, Chameleon is highly effective
in finding real-bugs; for the latest versions of vim,gawk, andgrep,
Chameleon succeeded to generate bug-triggering inputs while all
the othertechniques failed to do so.
Setup.While conducting the experiments in Section 4.2,w e
monitoredprogram executionand collectedbug-triggering inputs
generatedby Chameleon andothersixtechniques.Specifically,we
consideredtwotypesofbugs:programcrashesandperformance
bugs. First, to collect crashing inputs, we monitored the system
signals(e.g.,SIGSEGV)afterexecutingtheprogramwitheachinput
thatChameleon and othertechniques generated.Second, we col-
lected the performance bugs by checking if the program execution
with each input would exhaust a time or memory bound. After
collecting the bug-triggering inputs for each technique, we filtered
the genuine bugs that are reproducible on the original binary of
each benchmark program without annotations for concolic testing
andexcludedirreproducibleones.Finally,wefurtherclassifythe
collected bugs into 4 categories: segmentation fault (SIGSEGV),
abnormal-termination (SIGABRT), non-termination,and memory-
exhaustion.
Results.Table4showstheresultsontwoversionsofeachbench-
markprogram:theoriginalversionusedinSection 4.2(onwhich
we found bugs) and the latest version at the time of writing. For
eachbenchmark,thetableshowstheprogramversion(Versions),
the error type (Error Types), one of the bug-triggering inputs gen-
eratedby Chameleon (Bug-TriggeringInputs),andthesuccess( )
and failure ( ) results for each technique. The success mark ( ) for
atechniqueindicatesthatthetechniquesucceededtogenerateatleastoneinputthatcausesthecorrespondingerrortype,whereas
the failure mark ( ) means the technique totally failed to trigger
the error type.
The results show that Chameleon outperforms the existing
techniques in terms of bug-finding. In particular, Chameleon was
uniqueinfindingbugsthatcanbetriggeredinthelatestversionsof
vim,gawk,andgrep.Furthermore, Chameleon wasabletofindvar-
ioustypesoferrors,includingnon-termination( vim-8.1),memory-
exhaustion ( gawk-4.21 ), and abnormal termination ( grep-3.1 ). In
total,Chameleon couldtrigger12differenttypesoferrorsacross
all programs and their versions. On the other hand, the other tech-
niquesmanagedtotrigger6typesoferrorsatbest.Theperformance
ofexistingtechniquesvarieddependingonthebenchmarkwhile
Chameleonconsistentlyperformed well on 4 large benchmarks.
We found that Chameleon is effective in finding hard-to-find
bugs.Forexample,theinput '\(\)\1*?*?\|\W*\1W*' generated
byChameleon causesasegmentationfaultin grep-3.1 .Surpris-
ingly,thisbugsurvivedoverthelast20yearsfrom grep-2.2 (1998)
togrep-3.1 (2018).Chameleon also found deadly bugs. For ex-
ample, on gawk-4.21 , the input '+E_Q$h+w$8==++$6E8#' found
byChameleon causes a serious performance bug that may con-
sume all the memory of the machine. All the bug-triggering inputs
inTable4areeasilyreproducible.Forinstance,on grep-3.1 ,the
command ./grep '\(\)\1*?*?\|\W*\1W*' file (wherefileis
an arbitrary file) immediately aborts the program execution.
Figure4alsoaddstoevidencethat Chameleon isgoodatfinding
difficultbugs.Thefiguresshowhowmanybug-triggeringinputs
foundbyeachtechniqueintheinitialprogramssurviveasprograms
evolve,wherethe hypothesis isthatdifficultbugs wouldsurvive
longer than shallow bugs. In the case of grep,Chameleon consis-
tently achieves the highest number of reproducible bug-triggering
inputs over the subsequent program versions. Meanwhile, all bugs
found by other techniques, except for CGS, did not survive after
grep-2.4 , and only a single bug-triggering input found by CGS
remains in grep-2.6 . Forgawk-3.0.3 (the initial version), noteConcolic Testing with Adaptively Changing Search Heuristics ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
2 . 22 . 42 . 62 . 83 . 0010203006009001200
  # of bug-triggering inputs
grep version Chameleon
 RoundRobin
 CFDS
 Gen
 CGS
 Random
 Param
3.0.3 3.0.4 3.0.5 3.0.6 3.1.0020406080400080001200016000200002400028000 Chameleon
 RoundRobin
 CFDS
 Gen
 CGS
 Random
 Param
  # of bug-triggering inputs
gawk version
Figure 4: Comparison of the number of bug-triggering inputs that survive over program evolution
123456789 1 0 1 1 1 2 1 301200012500130001350014000145001500015500# of covered branches
Iterations RandomSamping
 Learningvim-5.7
2 4 6 8 10 12 14 16 18 20 22 24 26 280130013501400145015001550160016501700# of covered branches
Iterations RandomSampling
 Learning sed-1.17
Figure 5: Comparison between random-sampling and our learning algorithm
thatChameleon isnotthewinneras RandomandCFDSfindmore
bug-triggering inputs. However, as the program evolves, the situa-
tionis completely reversed;all of the 28,000 bug-triggering inputs
generatedby Randomintheoriginalversionfailedtosurviveinthe
next version ( gawk-3.0.4 ). That is, Randomis likely to find bugs
that are comparatively easy to fix. On the other hand, 22 inputs
discovered by Chameleon are reproducible until the version 3.1.0
withoutbeing fixed for more than 4 years.
4.4 Efficacyof Learning Algorithm
We evaluated the efficacy of our algorithm by comparing it with a
muchsimpleralgorithmthatrandomlychangessearchheuristics.
The naive algorithm can be easily implemented by sampling the
setHrandomly before line 5 of Algorithm 3and ignoring the lines
10–12 for Refine,Select, andSwitch. For each iteration of the
outer loop of Algorithm 3, we compared the cumulative branch
coverage achieved by our algorithm and the naive algorithm for
vim-5.7 andsed-1.17 .Figure5showsthatourlearningalgorithmfor adaptively chang-
ingsearchheuristicsisessential.For vim-5.7,whenthetestingbud-
get(24h)isexhausted,ouralgorithmisabletocover15,468branches,
covering 588 more branches than the random sampling method. In
thefirstiterationwherebothalgorithmsreliedonrandomsampling,
ouralgorithmunfortunatelystartedwithinitialsearchheuristics
withlowerqualitycomparedtothenaivealgorithm.However,in
the next iteration, our algorithm immediately succeeded in switch-
ing search heuristics that can cover more branches than the naive
one. As the iteration of both algorithms goes on, the differencein branch coverage achieved by each algorithm becomes larger
as follows: I2(146),I3(300),I4(417),···,I13(588). Forsed-1.17 ,w e
obtained the similar conclusion; until the fourth iteration at which
the knowledge ( K) was not accumulated sufficiently, our algorithm
hadsimilarperformancecomparedtotherandomsamplingmethod.
However, ours covered around 1,700 branches in the end, where it
learns to increase the branch coverage over the random method by
around 100.ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Sooyoung Cha and Hakjoo Oh
Table 5: Coverage variation by exploitation rate (sed-1.17)
exploitation rate 0% 20% 40% 60% 80%100%
# branches 1,612 1,611 1,638 1,679 1,6961,672
Table 6: Average branch coverage achieved by each heuris-
tic on Algorithm 1and2(24h). We set Nto∞and 4,000 for
Algorithm 1(A1) and Algorithm 2(A2), respectively.
gawk-3.0.3 grep-2.2 sed-1.17
A1A2A1A2A1A2
CFDS[3] 3,350 3,349 2,132 2,125 1,548 1,632
CGS[28] 2,767 3,095 1,922 2,074 1,208 1,487
Random[3] 3,113 3,091 1,924 2,014 1,481 1,253
Gen[12] 2,336 3,184 1,797 2,003 1,106 1,550
Param[5] 2,828 2,939 2,014 1,956 1,031 1,517
Total 14,394 15,658 9,78910,172 6,3747,439
4.5 Discussions
Exploration and Exploitation .In our algorithm (Section 3),
the hyperparameter η4for balancing exploration and exploitation
wascrucialforobtainingthedesiredresults.Forexample,Table 5
showsthat Chameleon achievesthehighestbranchcoverageon
sed-1.17 whentheexploitationrateisaround80%.Weobtained
similarresultsforotherprogramsandset η4to0.8.Inexperiments,
wefoundhyperparametersbytrialanderror.Tobesystematic,it
would be possible to use algorithms for tuning hyperparameters
automaticallyfrom the machine-learning community (e.g., [ 2]).
Algorithm 1vs Algorithm 2.Inpractice,withinthesametime
budget,performingconcolictestingwithasmallbudgetmultiple
times (i.e., Algorithm 2) is more effective than performing Algo-
rithm1alone with large Nuntil timeout. Table 6shows that using
Algorithm1with N=∞isfarinferiortousingAlgorithm2with
smallN(4,000) on 3 large benchmarks. For instance, for gawk, run-
ningAlgorithm 2covered15,658branchesintotal,whilerunning
Algorithm 1covered 14,394 branches only.
Threats to Validity .First, our evaluation used 8 benchmark
programsthathavebeencommonlyusedinpriorworks[ 3,5,6,17,
21,25,28]. However, these programs may not be sufficient to draw
afirmconclusioningeneral.Second,torun Chameleon ,wemanu-
allytunedthehyper-parametersthatworkwellonourbenchmarks.
However, these values may not suit arbitrary programs.
5 RELATED WORK
In this section, we discuss two lines of researches that are most
relatedtoours:techniquesforemployingsearchheuristics[ 3–5,12,
22,28]andcombininglearningandsoftwaretesting[ 6,7,13,16,18,
23,29,31].Theformeraimstomitigatethepath-explosionproblem
of concolic testing by presenting search heuristics. The latter aims
to solve various problems of software testing with learning.
Search Heuristics .All previous works on search heuristics [ 3–
5,12,22,28]havefocusedoncomingupwithanewbranchselection
strategy. However, in this paper, we claim that any single searchheuristicsortheirlimitedcombinationsarenotsufficient.These-
lectioncriterionof CFDS[3]istorandomlypickoneofthebranches
thatareclosesttouncoveredbranchesinthecurrentexecutionpath.
TheCGS[28] heuristic is to randomly select one of the branches at
the same depth of execution tree by BFSheuristic, while excluding
brancheswithalreadyexplored"context".Thestrategyof Param[5]
is toselect thebranch with thehighest score inthe current path,
whereeachbranchscoreiscalculatedasalinearcombinationofthe
branchfeaturevectorandagivenweightvector.Todoso,thetech-
niqueworksintwosteps:offlineandonlinephases.Intheoffline
phase, a learning algorithm is run to produce a search heuristic
thatisoptimalforasubjectprogram.Then,thelearnedheuristic
(Param)isusedfortestingthesubjectprogram(theonlinephase).
Note that the Paramheuristic does not change during the online
phaseand therefore wecall it non-adaptive. In contrast, ourwork
focusesonadaptingsearchheuristicsduringconcolictesting(i.e.,
Chameleoncan be used without the offline learning phase).
Combining Testing and Learning .Atahigh-level,ourwork
belongs to the techniques that combine software testing and learn-
ing [6,7,13,16,18,23,29,31], which leverage machine-learning
technologies to solve various problems of software testing. Con-
Test[6]aimstoreducethesearchspaceofconcolictestingbyonline
learning, where the goal is to selectively generate symbolic vari-
ables. In Continuous Integration (CI), RECTECS [ 29] first uses a
reinforcement learning to effectively select and prioritize failingtest cases. In Android GUI testing, QBE [
23] also employs a rein-
forcement learning algorithm (Q-learning) to learn the GUI actions
thatarelikelytoincreaseactivitycoverage,enablingcrashdetec-
tion. In fuzzing, Learn&Fuzz [ 13] aims to learn the structure of
PDF objects to increase the effectiveness of input fuzzing by using
neural-network-basedlearningtechniques.Similarly,forfuzzing,
Skyfire [31] aims to generate well-distributed seed inputs, thereby
achieving the highest code coverage. To do so, it learns a proba-bilisticcontext-sensitivegrammarfromlargeamountofexisting
samples. Unlike the previous works, our work employs a learning
algorithm to adaptively change search heuristics online in concolic
testing.
6 CONCLUSION
Designing effective ways of employing search heuristic is an on-going challenge in concolic testing. In this paper, we presented
Chameleon to adaptively learn and change search heuristics dur-
ingconcolictesting.Experimentswithopen-sourceprogramsshowthat
Chameleon outperformsanumberofstate-of-the-art,yetnon-
adaptive,approachesinbothcodecoverageandbugdetection.Ourresultssuggestthat,unlikeexistingapproachesthatrelyonspecific
heuristics,searchheuristicsshouldbechangedadaptivelyduring
concolictesting.
ACKNOWLEDGMENTS
This work was supported by Samsung Research Funding & In-
cubation Center of Samsung Electronics under Project Number
SRFC-IT1701-09. This work was supported by Next-Generation In-
formation Computing Development Program through the National
Research Foundation of Korea (NRF) funded by the Ministry of
Science, ICT (2017M3C4A7068175).Concolic Testing with Adaptively Changing Search Heuristics ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
REFERENCES
[1]Thanassis Avgerinos, Alexandre Rebert, Sang Kil Cha, and David Brumley. 2014.
Enhancing Symbolic Execution with Veritesting. In Proceedings of the 36th Inter-
national Conferenceon Software Engineering (ICSE ’14) . 1083–1094.
[2]James Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. 2011. Algo-
rithmsforHyper-parameterOptimization.In Proceedingsofthe24thInternational
Conference on Neural Information Processing Systems (NIPS’11) . 2546–2554.
[3]Jacob Burnim and Koushik Sen. 2008. Heuristics for Scalable Dynamic Test Gen-
eration. In Proceedings of 23rd IEEE/ACM International Conference on Automated
Software Engineering (ASE ’08) . 443–446.
[4]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: Unassisted and
AutomaticGenerationofHigh-coverageTestsforComplexSystemsPrograms.
InProceedings of the 8th USENIX Conference on Operating Systems Design and
Implementation (OSDI ’08) . 209–224.
[5]SooyoungCha,SeongjoonHong,JunheeLee,andHakjooOh.2018.Automatically
Generating Search Heuristics for Concolic Testing. In Proceedings of the 40th
International Conference on Software Engineering (ICSE ’18) . 1244–1254.
[6]Sooyoung Cha, Seonho Lee, and Hakjoo Oh. 2018. Template-guided Concolic
TestingviaOnlineLearning.In Proceedingsofthe33rdACM/IEEEInternational
Conference on Automated Software Engineering (ASE ’18) . 408–418.
[7]Wontae Choi, George Necula, and Koushik Sen. 2013. Guided GUI Testing of
AndroidAppswithMinimalRestartandApproximateLearning.In Proceedingsof
the2013ACMSIGPLANInternationalConferenceonObjectOrientedProgramming
Systems Languages &#38; Applications (OOPSLA ’13) . 623–640.
[8]CREST. A concolic test generation tool for C. 2008. https://github.com/jburnim/
crest.
[9]PrzemysławDaca,AshutoshGupta,andThomasA.Henzinger.2016. Abstraction-
driven Concolic Testing. In Proceedings of the 17th International Conference on
Verification,ModelChecking,andAbstractInterpretation-Volume9583 (VMCAI
’16). 328–347.
[10]DrewDavidson,BenjaminMoench,ThomasRistenpart,andSomeshJha.2013.
FIE on Firmware: Finding Vulnerabilities in Embedded Systems Using Symbolic
Execution. In Presented as part of the 22nd USENIX Security Symposium (USENIX
Security ’13) . 463–478.
[11]Patrice Godefroid, Nils Klarlund, and Koushik Sen. 2005. DART: Directed Auto-
mated Random Testing. In Proceedings of the 2005 ACM SIGPLAN Conference on
Programming Language Design and Implementation (PLDI ’05) . 213–223.
[12]PatriceGodefroid,MichaelYLevin,andDavidAMolnar.2008. AutomatedWhite-
boxFuzzTesting.In ProceedingsoftheSymposiumonNetworkandDistributed
System Security (NDSS ’08) . 151–166.
[13]Patrice Godefroid, Hila Peleg, and Rishabh Singh. 2017. Learn&fuzz: Machinelearning for input fuzzing. In Proceedings of the 32nd IEEE/ACM International
Conference on Automated Software Engineering (ASE ’17) . 50–59.
[14]GrantHernandez, FarhaanFowze, Dave (Jing) Tian, Tuba Yavuz, and Kevin R.B.
Butler.2017. FirmUSB:VettingUSBDeviceFirmwareUsingDomainInformed
Symbolic Execution. In Proceedings of the 2017 ACM SIGSAC Conference on Com-
puter and Communications Security (CCS ’17) . 2245–2262.
[15]Dorit S. Hochbaum (Ed.). 1997. Approximation Algorithms for NP-hard Problems .
PWS Publishing Co., Boston, MA, USA.
[16]GangHu,LinjieZhu,andJunfengYang.2018. AppFlow:UsingMachineLearning
to Synthesize Robust, Reusable UI Tests. In Proceedings of the 2018 26th ACM
JointMeetingonEuropeanSoftwareEngineeringConferenceandSymposiumon
the Foundations of Software Engineering (ESEC/FSE ’18) . 269–282.
[17]JoxanJaffar,VijayaraghavanMurali,andJorgeA.Navas.2013. BoostingConcolic
Testing viaInterpolation. In Proceedings ofthe 9thJoint Meetingon Foundations
of Software Engineering (ESEC/FSE ’13) . 48–58.[18]Yue Jia, Myra B. Cohen, Mark Harman, and Justyna Petke. 2015. Learning Com-
binatorialInteractionTestGenerationStrategiesUsingHyperheuristicSearch.In
Proceedings of the 37th International Conference on Software Engineering - Volume
1 (ICSE ’15) . 540–550.
[19]Su Yong Kim, Sangho Lee, Insu Yun, Wen Xu, Byoungyoung Lee, Youngtae Yun,
and Taesoo Kim. 2017. CAB-Fuzz: Practical Concolic Testing Techniques for
COTS Operating Systems. In 2017 USENIX Annual Technical Conference (USENIX
ATC ’17). 689–701.
[20]Yunho Kim, Yunja Choi, and Moonzoo Kim. 2018. Precise Concolic Unit Testing
ofCProgramsUsingExtendedUnitsandSymbolicAlarmFiltering.In Proceedings
of the 40th International Conference on Software Engineering (ICSE ’18) . 315–326.
[21]YunhoKimandMoonzooKim. 2011. SCORE:AScalableConcolic TestingTool
forReliableEmbeddedSoftware.In Proceedingsofthe19thACMSIGSOFTSympo-
siumandthe13thEuropeanConferenceonFoundationsofSoftwareEngineering
(ESEC/FSE ’11) . 420–423.
[22]YunhoKim,MoonzooKim,YoungJooKim,andYoonkyuJang.2012. Industrial
Application of Concolic Testing Approach: A Case Study on Libexif by Using
CREST-BV and KLEE. In Proceedings of the 34th International Conference on
Software Engineering (ICSE ’12) . 1143–1152.
[23]YavuzKoroglu,AlperSen,OzlemMuslu,YunusMete,CeydaUlker,TolgaTan-
riverdi, and Yunus Donmez. 2018. QBE: QLearning-based exploration of android
applications. In 2018 IEEE 11th International Conference on Software Testing, Veri-
fication and Validation (ICST ’18) . 105–115.
[24]Hongbo Li, Sihuan Li, Zachary Benavides, Zizhong Chen, and Rajiv Gupta. 2018.
COMPI: Concolic Testing for MPI Applications. 2018 IEEEInternational Parallel
and Distributed Processing Symposium (2018), 865–874.
[25]RupakMajumdarandKoushikSen.2007. HybridConcolicTesting.In Proceedings
of the 29th International Conference on Software Engineering (ICSE ’07) . 416–426.
[26]Sangmin Park, B. M. Mainul Hossain, Ishtiaque Hussain, Christoph Csallner,
MarkGrechanik,KunalTaneja,ChenFu,andQingXie.2012. CarFast:Achieving
Higher Statement Coverage Faster. In Proceedings of the ACM SIGSOFT 20th
International Symposium on the Foundations of Software Engineering (FSE ’12) .
35:1–35:11.
[27]KoushikSen,DarkoMarinov,andGulAgha.2005. CUTE:AConcolicUnitTestingEngineforC.In Proceedingsofthe10thEuropeanSoftwareEngineeringConference
Held Jointly with 13th ACM SIGSOFT International Symposium on Foundations of
Software Engineering (ESEC/FSE ’05) . 263–272.
[28]HyunminSeoandSunghunKim.2014. HowWeGetThere:AContext-guided
Search Strategy in Concolic Testing. In Proceedings of the 22nd ACM SIGSOFT
International SymposiumonFoundations ofSoftware Engineering (FSE’14) .413–
424.
[29]HelgeSpieker,ArnaudGotlieb,DusicaMarijan,andMortenMossige.2017. Re-
inforcement Learning for Automatic Test Case Prioritization and Selection in
ContinuousIntegration.In Proceedingsofthe26thACMSIGSOFTInternational
Symposium on Software Testing and Analysis (ISSTA ’17) . 12–22.
[30]Youcheng Sun, Min Wu, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska,and Daniel Kroening. 2018. Concolic Testing for Deep Neural Networks. In
Proceedingsofthe33rdACM/IEEEInternationalConferenceonAutomatedSoftware
Engineering (ASE ’18) . 109–119.
[31]Junjie Wang, Bihuan Chen, Lei Wei, and Yang Liu. 2017. Skyfire: Data-drivenseed generation for fuzzing. In 2017 IEEE Symposium on Security and Privacy
(S&P ’17). 579–594.
[32]Xinyu Wang, Jun Sun, Zhenbang Chen, Peixin Zhang, Jingyi Wang, and Yun Lin.
2018. Towards Optimal Concolic Testing. In Proceedings of the 40th International
Conferenceon Software Engineering (ICSE ’18) . 291–302.
[33]InsuYun,SanghoLee,MengXu,YeongjinJang,andTaesooKim.2018. QSYM:APracticalConcolicExecutionEngineTailoredforHybridFuzzing.In 27thUSENIX
Security Symposium (USENIX Security ’18) . 745–761.