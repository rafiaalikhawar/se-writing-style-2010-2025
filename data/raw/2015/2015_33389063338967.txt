An Empirical Study ofReal-WorldVariability Bugs
Detected byVariability-ObliviousTools
AustinMordahl
Universityof Texasat Dallas
USA
austin.mordahl@utdallas.eduJeho Oh
Universityof Texasat Austin
USA
jeho.oh@utexas.eduUgur Koc
Universityof Maryland, CollegePark
USA
ukoc@cs.umd.edu
ShiyiWei
Universityof Texasat Dallas
USA
swei@utdallas.eduPaul Gazzillo
Universityof CentralFlorida
USA
paul.gazzillo@ucf.edu
ABSTRACT
Many critical software systems developed in C utilize compile-
time configurability. The many possible configurations of this soft-
ware make bug detection through static analysis difficult. While
variability-aware static analyses have been developed, there re-
mainsagapbetweenthoseandstate-of-the-artstaticbugdetection
tools. In order to collect data on how such tools may perform and
todevelopreal-worldbenchmarks,wepresentawaytoleverage
configuration sampling, off-the-shelf łvariability-obliviousž bug
detectors,andautomaticfeatureidentificationtechniquesto sim-
ulatea variability-aware analysis. We instantiate our approach
using four popular static analysis tools on three highly config-
urable, real-world C projects, obtaining 36,061 warnings, 80% of
whicharevariabilitywarnings.Weanalyzethewarningswecollect
from these experiments, finding that most results are variability
warnings of a variety of kinds such as NULL dereference. We then
manually investigate these warnings to produce a benchmark of
77 confirmed true bugs (52 of which are variability bugs) useful for
future developmentofvariability-aware analyses.
CCS CONCEPTS
·Generalandreference →Empiricalstudies ;·Softwareand
its engineering →Automated static analysis ;Software test-
inganddebugging .
KEYWORDS
staticanalysis,configurable C software,variability bugs
ACMReference Format:
Austin Mordahl, Jeho Oh, Ugur Koc, Shiyi Wei, and Paul Gazzillo. 2019.
An Empirical Study of Real-World Variability Bugs Detected by Variability-
Oblivious Tools. In Proceedings of the 27th ACM Joint European Software
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE ’19, August 26ś30,2019, Tallinn,Estonia
©2019 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-5572-8/19/08...$15.00
https://doi.org/10.1145/3338906.3338967EngineeringConferenceandSymposiumontheFoundationsofSoftwareEn-
gineering (ESEC/FSE ’19), August 26ś30, 2019, Tallinn, Estonia. ACM, New
York, NY, USA, 12pages.https://doi.org/10.1145/3338906.3338967
1 INTRODUCTION
Systems developed in C form some of the largest and most im-
portantsoftwareinfrastructure.Thissoftware,suchastheLinux
kernelortheBusyBox embeddedtoolkit,isusedinabroadrange
ofapplications,fromlarge-scaledatacenterstomillionsofInternet-
of-Thingsdevices.Cprogrammersuse compile-timevariability to
enableasingle codebasetobecustomizedtothisdiverserangeof
settings. Theyimplement software configurations inthe Makefile
and C preprocessor to decide which part of the source code is built
by the compiler, allowing for billions or trillions of variations of
the compiledprogram.
Variabilitybugs arebugsthatonlyexistundercertainconfigu-
rationsofthesoftware.Thesearemadepossiblebythebuildand
configurationsystem,whichmodifythesourcecodetofitachosen
configuration.1Suchconfigurablecode isnecessaryforcodebases
to support a wide variety of hardware and application settings, but
studies show it also creates problems for debugging and mainte-
nanceofhighly configurable codebases[ 1ś3].
Variability bugs create a serious challenge for automatic bug
detection.Moststaticanalysistoolsoperateononeconfigurationat
a time, i.e., are variability-oblivious , orusead-hoc heuristics [ 4,5],
makingthemblindtocodeinotherconfigurations.Checkingconfig-
urations one-at-a-time is intractable when even small configurable
systemshave trillions ofconfigurations[ 6].
To address this problem, researchers have developed variability-
awareanalyses[ 4,5,7ś13]thatprocessallconfigurationssimultane-
ously.Tothebestofourknowledge,thestate-of-the-artvariability-
aware bug detector applies control- and data-flow analyses to
discover bugs such as double free and freeing of static memory
[7]. While these advances in bug detection are highly promising,
they are still in the early stages when compared to widely-used
variability-obliviousbugdetectorssuchasInfer[ 14],whichuses
separationlogictofindmemorysafetybugs,andCBMC[ 15],which
usesabstractinterpretationandmodelchecking.Theseanalyses,
whichcandetectbugssuchasbufferoverflow,array-out-of-bounds,
andsecurity vulnerabilities, are inwide use.
1Inthisworkwefocusonvariabilitybugsduetocompile-timevariability,butsuch
bugs canalso bedue to run-time variability.
50
ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia AustinMordahl,JehoOh,Ugur Koc, ShiyiWei, andPaulGazzillo
The continued development of variability-aware analyses is im-
portant. But given the gap between such tools and state-of-the-art
bugdetectors,thereisstillalackofdataabouttheutilityofsuch
analyseswhencomparedtotheirvariability-obliviouscounterparts.
Moreover,thereisalackofbenchmarkstoprovidegroundtruthsfor
developingvariability-awareanalysis.Tothebestofourknowledge,
thelargestvariability bugdatabase [ 1]containsbugs encountered
byusersoverthepastdecade,makingitdifficulttoreproducethese
bugsinthe originalsoftware.
How can we find variability bugs that existing variability-aware
analysismaynotdetect?Ideally,wewouldliketotakeoff-the-shelf
bugdetectorsandconvertthemtobevariability-awaretogather
data and develop benchmarks. But this Herculean task requires
largetimeresourcesandwoulditselfbenefitfromhavingground-
truthbenchmarks duringdevelopment.In ordertocollectdataon
howsuchtoolsmayperformandtodevelopreal-worldbenchmarks,
wepropose simulating variability-awarenesswithoff-the-shelfbug
detectors.
Simulatingvariability-awarenessisbasedonasimpletechnique:
runbugdetectorsonasampleofconfigurations.Samplingofconfig-
uration spaces has been studied extensively [ 10,16ś30], and some
previous work hasappliedabugdetector to samplesofconfigura-
tions [30] in the context of comparing sampling algorithms. But
tobeasimulation ,wearguethat(i)thesampleofconfigurations
should be representative of complete variability-awareness and (ii)
itshouldintegratetheresultsofthemanyvariability-obliviousruns
intovariability-awareresults.Toachievearepresentativesample,
we use a recent advance in configuration sampling that guarantees
uniformityyetscalestocolossalconfigurationspaces[ 31].Previous
sampling algorithms could doone orthe other,but not both.
To achieve integration we have developed a new simulation
frameworkthatwrapsexistingbugdetectors.Itautomaticallyap-
pliesabugdetectortoallsampledconfigurations,aggregatesand
deduplicates the resulting warnings, and finds feature interactions,
therebysimulatingtheoutputofavariability-awareanalysis.Using
thisframework,weanalyzethewarningsfromfouroff-the-shelf
bugdetectiontools(Infer,CBMC,Clang,andCppcheck)onthree
highly-configurablecodebases(theaxTLSwebserver,theToybox
andBusyBox embeddedtoolkits). Thesecodebases have hundreds
of configuration options leading to trillions of valid configurations.
Representingweeksofcomputing time,wecollected36,061warn-
ings, ofwhich28,631(almost80%) are variability warnings.
We performed data analysis of the resulting warnings that con-
firmsmostwarningsareduetovariability,thatshowsvariability
warnings are of many types, even those not currently supported
by existing variability-aware analysis tools, and that proves warn-
ings may appear in few configurations, indicating the need for
variability-awareness.Perhapssurprisingly,wealsoshowthatall
warningsproducedbyany tool/programcombinationcan be cov-
ered by a small numberof configurations. Our data demonstrate a
trade-offbetweentheaddedcomplexityofvariability-awareness
and the need to cover all possible defects, e.g., for safety-critical
software.
Finally,weconstructareproducibledatasetincludingvariability
bugs in recent, real-world software, useful as a benchmark for
future analysis development. We manually investigated many of
our variability warnings to confirm whether they are true bugs.1#ifdefCONFIG_BIGINT_SLIDING_WINDOW
2for(j = i; j > 32; j /= 5) /* work out an optimum size */
3 window_size++;
4/* work out the slide constants */
5precompute_slide_window(ctx, window_size, bi);
6#else/* just one constant */
7ctx->g = (bigint **)malloc( sizeof(bigint *));
8ctx->g[0] = bi_clone(ctx, bi); // warning
9ctx->window = 1;
10bi_permanent(ctx->g[0]);
11#endif
Figure 1: An example of a confirmed bug found during our
experiments. FromaxTLS,crypto/bigint.c.
This investigation yielded a set of 77 true positive bugs showing
that our simulation framework can be used to find new variability
bugs.Wehavemadeourframeworkanddatasetpubliclyavailable.2
The contributionsofthis paper are the following:
•A framework that simulates variability-aware analysis by
integrating off-the-shelf static analysis tools and running
themonuniformrandomsamplesoftheconfigurationspace
(Section3).
•Anempiricalevaluationofthewarningsproducedbyfour
static bug detectors on three highly-configurable C code-
basesandananalysisofwarningsthatshowspotentialde-
fectsare indeedobscuredbyvariability (Section 4).
•Areal-worldvariabilitybug benchmark foundby manually
investigatingthewarningsfromourevaluationaswellasthe
feature interactions that lead to these bugs. This benchmark
isbeneficialfortooldeveloperstoevaluatefutureanalyses
(Section5).
2 WHATARE VARIABILITYBUGS?
Figure1is an example of a variability bug, in this case a NULL
dereference, found during our experiments running the Infer static
analysis tool on axTLS. Line 7 sets ctx->gto the return value of
malloc, which can be NULL, and line 8 dereferences that value,
ctx->g[0] ,withoutcheckingforNULL,awell-knowndefect.3This
isavariabilitybug,becauseitonlyappearsincertainconfigurations
ofthe codebase.
Even though static analyses suchas Inferare sound,4theyonly
operate on a single configuration at a time, i.e., the soundness
guarantees only apply to the chosen configuration. To see why
thisisthecase,noticethatthisvulnerablesourcecodeisguarded
byapreprocessorconditional indicatedbythe #ifdef,#else,and
#endifonlines1,6,and11,respectively.Preprocessorconditionals
arenotpartoftheClanguage,butareevaluatedbeforetheCsource
code iscompiledto implement variations of the sourcecode.
CONFIG_BIGINT_SLIDING_WINDOW is apreprocessor macro that
the preprocessor conditional tests to decide whether to include
either lines 2ś5 or lines 7ś10, but never both. The macro is set via
theconfigurationsystembytheuser.Thisusageofthepreprocessor
illustrates howcompile-time variability istypicallyimplemented.
In our example in Figure 1, the NULL dereference bug on line 8
only appears when the CONFIG_BIGINT_SLIDING_WINDOW config-
uration option is disabled, because that line is never compiled
2https://github.com/paulgazz/kconfig_case_studies/releases/tag/v1.0
3CWE-690. https://cwe.mitre.org/data/definitions/690.html
4Theyaresoundwithrespecttoasubsetofthelanguagesemantics,i.e.,soundiness[ 32].
51AnEmpirical Studyof Real-WorldVariabilityBugs ... ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
Figure 2:Anoverview ofour approach.
into the final binary. Therefore, if a static analysis tool, even a
sound one, is only run on a configuration that enables the op-
tion, it will not find the bug. Interestingly, there is a different
NULL dereference bug when the option is enabled. Inside of the
precompute_slide_window functioncalledonline5isacodeclone
of lines 7ś10. These two bugs live in mutually exclusive configu-
rations, so finding and fixing one does nothing to help with the
other.
If there were a small number of configurations, trying every
combination of configuration options might be feasible, but axTLS
has94configurationoptionsandaroundtwotrillionvalidcombi-
nationsofthem.Checkingallconfigurationsisnotfeasible,andwe
donot knowaprioriwhichconfigurationsmaybe vulnerable.
In C, configurations are typically implemented using the pre-
processor,asshownintheexampleabove,andwithMakefilesor
a related build specification language (e.g., Kbuild). The configu-
ration system takes configuration option settings from the user
andpassesthemtothebuildsystemandthepreprocessor,which
then select a subset of the source code to compile and link into
the final binary. Prior work shows how extensively configurable
code is implemented with the preprocessor and Makefiles [ 1,4ś
6,33].Compile-timevariabilityresultsincodebasesthatareboth
highly-configurableandefficient,resultinginasmaller,fasterbi-
nary,particularlyimportantfor low-level systemssoftware.
AsweseeinFigure 1,however,thisconfigurabilityalsoobscures
software defects. Previous studies show that such configurable
codeisdangerous:ithasbeencorrelatedwithmorebugs[ 2]and
shown to be more difficult for developers to debug [ 3]. We use our
simulation framework to find variability bugs.
3 FRAMEWORKAND STUDYSETUP
Figure2shows an overview of our simulation framework. It takes
in a codebase and produces a set of warnings for later manual
investigation. The framework itself consists offour main steps: (i)
thesamplegeneration,usinganexistingtooltogetuniformrandom
samples for the given codebase [ 31]; (ii) automatically applying
a chosen static analysis tool on all sampled configurations; (iii)
aggregating and deduplicating the results, finding which warnings
appear in multiple configurations; and (iv) identifying features,
usingthelistofconfigurationseachwarningoccurredintoinfer
whichconfigurationoptions(i.e.,features)produce the warning.
We apply this framework to multiple static analysis tools and
highly configurable codebases. After running our framework onTable 1:Details ofthe targetprograms.
Program Version C SLoC Options Valid Configs
axTLS 2.1.4 17,232 94 2 .0×1012
Toybox 0.7.5 42,190 316 1 .4×1081
BusyBox 1.28.0 162,732 998 2 .0×10213
eachcombinationoftoolandcodebase,wehaveacollectionofwarn-
ingsforeachcombinationthatsimulatesvariability-awareanalysis
results. The remainder of Figure 2shows our process for manually
investigating these variability warnings to collect a dataset of true
bugs,useful as abenchmark.
We nowdescribe eachstep of our approach indetail.
3.1 SampleGeneration
Generating a configuration sample is not as simple as randomly
combining configuration options, as constraints exist between dif-
ferent options, e.g., some options are mutually exclusive. A config-
uration is invalid if the constraints defined by the configuration
systemarenot satisfied. Off-the-shelfbugdetectorsoftenrequire
compilation of the program to resolve preprocessor directives and
generate intermediate representations for the analysis. We thus
require every configurationinthe sample be valid.
The state-of-the-art toolfor generating representative samples
from highly-configurable software is Smarch [ 31]. Smarch is a uni-
form sampling algorithm for software product lines based on a
#SATsolver[ 34].Smarch scalesto largeconfigurable softwareby
obviating the need to exhaustively enumerate configurations from
the constraints. Instead, Smarch generates a uniqueconfiguration
from a randomly-chosen number on demand. Sampling of valid
configurationsrequiresfirstknowingthesetofconstraintsbetween
configurationoptions,i.e.,thefeaturemodel.Thestate-of-the-art
tool,Kclause [ 31]from theKmax[ 35]project isusedfor automat-
icallyextractingtheseconstraintsfromtheKconfigspecification
languageusedinourtargetprojects.ItworksbyinterpretingKcon-
fig language constructs as formal logical models and optimizing
themto reduce the size of the reusltingmodel.
While our framework is modular and accepts samples from any
sampling algorithm that generates valid configurations, a uniform
randomsamplingalgorithmallowsustodrawstatisticallysound
conclusionsaboutthepopulationofconfigurationsbasedonsample
results, within a small margin of error and confidence level. For
example, with a configuration sample having a 5% margin of error
and1%confidencelevel,ifweobservethat80%ofallbugsdetected
inasamplearevariabilitybugs,wecansayweare95%surethat
between79%and81%ofallbugsthatexistinthetargetsoftwareare
variabilitybugs,allowingustoforeseetheresultsofavariability-
aware analysis.
WeusedtheprogramslistedinTable 1forourempiricalstudy,
becausetheyall(i)areopensource,(ii)arehighlyconfigurable,and
(iii)useKbuild,whichallowstoautomaticallyextractconfiguration
constraintswithKclause.Foreachtargetprogram,wegenerated
1,000 valid configurations. This sample size ensures the results are
within a5% margin oferrorand1% confidence interval.
3.2 UsingOff-the-Shelf Bug Detectors
We chose four off-the-shelf bug detectors from a list [ 36] for our
investigation: CBMC 5.3 [ 15], Facebook Infer 0.15.0 [ 14], Cppcheck
52ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia AustinMordahl,JehoOh,Ugur Koc, ShiyiWei, andPaulGazzillo
Table 2:Descriptions ofthewarningtypes.
Warning Type Description
Array_Bounds Array accessed beyond allocated length.
Assertion Failedassertions eitherprovided bythe userorgen-
erated automaticallyby the model checker.
Overflow Overflowofintegers.
NaN Floating point arithmetic producing NaN (i.e., infini-
tiesorthe resultsofcomputationswithinfinities).
Pointer Mismatched types between pointer usage and defini-
tion.
Null_Deref Dereferencinganull pointer.
Dead_Store Values thatarestored in variables butneverused.
Memory_Leak Memory that is dynamically allocated but never
freed.
Resource_Leak Resources (e.g., file descriptors, sockets) that are
opened butneverclosed.
Uninitialized_Val Values thatareused withoutbeing initialized.
API Improperuse ofvariousAPIs.
Unix_API improperusage ofaUnixAPI.
Logic_Error A wide variety of warnings, such as unallowed func-
tion callsafter vforksandundefined behaviors.
Memory_Error Memory andresource leaks.
Security Useofinsecurefunctioncalls(e.g., vfork).
Undef_Behavior Undefinedbehavior ofconstructionsorexpressions.
1.72[37],andthebuilt-inanalyzerinClang7.0[ 38].Ourcriteriafor
choosingbugdetectorswerethat(i)theyworkedonCcode,and
(ii)they produced bug warnings asopposed to other codemetrics,
such as linecounts.
The detectors we chose reported a variety of warnings, defined
inTable2.CBMCreportsArray_Bounds,Assertion,NaN,Overflow,
Pointer,andNull_Deref.InferreportsDead_Store Memory_Leak,
Null_Deref,Resource_Leak,andUninitialized_Val.Clangreports
API, Unix_APIs, Dead_Store, Logic_Error, Memory_Error, and Se-
curity. Cppcheck does not report discrete warning types, so we
manually mapped Cppcheck warnings to types that were found in
othertools: Array_Bounds, Memory_Error, Null_Deref,Overflow,
andUninitialized_Val.Additionally,wedefinedtheUndef_Behavior
warning type for Cppcheck.
These detectors represent two different ways of running an
off-the-shelf bug detector. CBMC and Infer attach themselves to
the build process (in all of our target programs, this was make),
collectinginformationaboutthebuildprocessandgeneratinginter-
mediate representations of the program. For these, we use a script
thatiterativelyrunstheappropriatetoolasanattachmenttothe
build process. Cppcheck and Clang both run on individual files, so
for those, we instead use custom scripts that first preprocess the
code.We then run the toolsiterativelyoneachpreprocessedfile.
Inourstudy,werantheseexperimentsontwodifferentmachines.
PreprocessingofBusyBoxtookplaceonaDesktopPCwithanIntel
Corei5-3570KCPU@3.40GHzand16GBRAMrunningDebian9.
All other experiments took place on a server with 24 Intel Xeon
Silver4116CPUs@2.10GHzand128GBRAMrunningUbuntu16.04
LTS. We used a virtual machine to ensure the consistencies in
environment across the machines. In total, experiments took on
theorderofweeksofprocessortimetorun;however,wewereable
to reduce this inreal time throughparallelization.3.3 DeduplicationandFormatting
Althoughconfigurationoptionsgoverntheinclusionorexclusion
ofdifferentpartsofsourcecode,someofaprogram’scodebaseis
commonacrossallconfigurations.Therefore,manyofthewarnings
obtained by running a bug detector on each configuration in the
sampleareduplicates.Weperformpost-processingtodeduplicate
thesewarnings, andthen outputtheminaunifiedformat.
Weconsidertwowarningsequivalentiftheyrefertothesame
lineinthesamesourcecodefile.5Wewritetheuniquewarnings
setforeachtool/programcombinationinJSONformatforeasier
processing.Figure 3showstheJSONoutputofthevariabilitybug
wediscussedinSection 2.Thełvariabilityžfieldisourautomated
estimation of whether this warning is a variability warning or not.
Inourstudy,awarningisestimatedtobe generic(i.e.,thevariability
field is false) if it was detected by the tool in all the configurations
in our sample.6Otherwise, we regard a warning as variability (i.e.,
thevariabilityfieldistrue).Thełautomatic_featuresžfieldrefers
to the configurationoptionsidentifiedinthe following step.
1{
2"variability": true,
3"description": "pointer `ctx->g` last assigned on line 1372
could be null and is dereferenced at line 1373, column 5.",
4"num_configs": 503,
5"tool": "infer",
6"filename": "crypto/bigint.c",
7"line": 1373,
8"type": "NULL_DEREFERENCE",
9"configs": [ "263", "562", "575", "..."],
10"target": "axtls_2_1_4"
11"automatic_features": [ "CONFIG_BIGINT_SLIDING_WINDOW" ]
12}
Figure 3: The JSON format of the warning in Figure 1. The
list ofconfigurationsis truncated forspace.
3.4 AutomaticFeatureIdentification
We perform automatic feature identification by referencing the list
ofconfigurationseachwarningispresentin.Foranywarning w,
letCwbe the set of configurations in which wwas emitted, and
letC′wbe the set of configurations in which wwas not emitted.
We automatically determine the set of configuration options F
that are common to Cw, and the set of configuration options F′
thatarecommonto C′w.Ifforanyconfigurationoption f,where
fdenotes the option being turned on and f′denotes the option
being turned off, if f∈Fandf′/nelementF, then we select fas the
configurationoptionassociatedwiththiswarning(similarly,if f′∈
Fandf∈F′, then we consider f′to be associated with w). We do
notconsideraconfigurationoptiontobeassociatedwithawarning
iffiscommonacrossboth CwandC′w.Thismethodologycanbe
extendedtodeterminewhenconjunctionsordisjunctionsofoptions
are associated with a warning. As an automated algorithm, this
processsucceededinestimatingassociatedconfigurationoptions
inmostcases.
5Recall that Cppcheck and Clang run on preprocessed files. The preprocessed files
containlinemarkersthatallowustomappreprocessedcodetoitsoriginalsourcecode
line.
6A warning we estimateas generic may be a variability warning if thereexists some
valid configuration (notin the sample) on which a tool cannot reportthe warning. We
believethisestimationisaccurate based onourinvestigation of bugs in Section 5.
53AnEmpirical Studyof Real-WorldVariabilityBugs ... ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
3.5 Manual Classification
We performmanual classificationof warningsby codeinspection
andteamreviews.Ourcriterionfordeterminingwhetherawarning
is a true or false positive is whether the description emitted by the
bugdetectoriscorrect.Foreachwarning,wehand-tracedexecution
aroundthereport,recordingthevaluesofvariablesandpointers.
The manual classification was performed by the first author of the
paper,andthenpresentedtoallmembersinthisproject.Weasa
teamexaminedthewarningsclassifiedastruepositivesandcon-
firmedthem. Ourprimarygoalwassoundness in our bug dataset,
i.e.,avoidreportingawarningasatruepositivewhenitwasafalse
positive. It is possible, however, that there were still true positives
mistakenly labeled as false positives, since we did not construct
exploits.
3.6 Manual FeatureConfirmation
We manuallyverifytheresultsoftheautomaticfeatureidentifica-
tionthroughcode inspection. We perform the following tasks:
•FindCpreprocessordirectivesthatsurroundthesourcecode
withthebug,andextracttheconfigurationoptionsconstrain-
ingthe directives.
•Find Makefile commands that compile the C file containing
thebug,andextracttheconfigurationoptionsthatactivate
the commands.
•Toensure correctness,checkwhethertheconfigurationop-
tions found from the above two steps appeared in the auto-
maticfeature identification result.
3.7 Discussion:NewAnalyses andPrograms
Eachstepinthesimulationframeworkisautomated,andisdesigned
topermitłplugginginžnewstaticanalysistoolsandnewcodebases
to investigate. To add a new codebase, we need two things (1) a
featuremodeldescribingtheconfigurationconstraintsforsampling
and(2)asmallsetofshellinstructionstoconfigureandbuildthetool
for a given configuration. Technically, our framework can support
anysamplingalgorithm,becausetheexecutionenginetakesonlya
set of configurations to evaluate. Currently, our evaluation is on
codebases that use Kbuild, the Linux build system, because the
sampling toolwe use isknown to samplethese uniformly, but we
havetesteditonothercodebasesforwhichwedonothaveuniform
sampling.
Addingnewstaticanalysistoolsisassimpleascreatinganew
script that executes the tool. The challenge of supporting a new
static analysis tool, however, is due to their idiosyncrasies. For
instance,theClangstaticanalyzerprovidesaconvenienttoolcalled
scan-buildthatusesłpoorman’sinterpositionžtoanalyzeanentire
project [39]. This tool does not always work, as the manual warns,
requiring us to customize the analysis process for codebases we
evaluatebutarenotsupportedbyscan-build.Foreachcombination
of tool and codebase,we have created plugins that overcome most
of thelimitations of thestatic tools for the complex build systems
ofour codebases.
4 EMPIRICALEVALUATION OFWARNINGS
Weappliedourframeworktothethreehighlyconfigurablecode-
basesshowninTable 1,andthefouroff-the-shelftoolsdescribed
inSection 3.2.Thegoalofthisempiricalevaluationistoevaluatewhatkinds
of variability warnings off-the-shelf bug finders detect and to what
extentsuchwarningsareaffectedbyconfigurability.Tothisend,
we ask three researchquestions:
RQ1Whatvariabilitywarningscanoff-the-shelfbugdetectors
find?
RQ2Howare variabilitywarnings distributedoverthespace
ofsampledconfigurations?
RQ3Howdoourresultscomparetocheckingamaximumor
minimumconfiguration?
RQ1.Weexpecttodiscoverhowoftenandwhattypesofvari-
abilitywarningsarefound.Iftherearemany,thisconfirmsprior
work thatshows variability bugsare a serious problem forhighly-
configurable software [ 1,7]. Moreover, if the types of variability
warnings include serious potential defects that current analyses do
not support, e.g., Null_Deref, then we provide further justification
for the research community to continue developing such analyses.
Ontheotherhand,ifvariabilitywarningsarerare,variability-aware
analysesmaynot be needed.
RQ2.Examiningthedistributionofvarioustypesofwarnings
across the set of samples will show us how difficult it is to identify
suchwarningswithoutvariability-awareanalyses.Ifonlycertain
typesofwarningsarevariabilitywarnings,perhapstheresearch
community shouldinitially focusonanalysesfor specific kindsof
bugs. If more serious warnings tend not to be variability warnings,
then this would provide evidence that such analyses may not be
necessary. Moreover, we examine how many configurations are
requiredtocoverthesetofwarnings.Ifmanyconfigurationsarere-
quired, this provides further justification for variability-awareness,
while few configurations may mean that further effort on algo-
rithmsfor configurationcoverageisneeded.
RQ3.Wecomparetheresultsofrunningthebugdetectorson
the maximum configuration defined by each of our codebases. If
we find thatthemaximum configurationsfindvery fewwarnings,
this provides further justification for variability-aware analyses.
Otherwise,suchanalysesmaynotbemuchmoresuccessfulthan
selecting one good configuration. Note that our results are only
fromasampleofconfigurations,sowecannotruleoutallvariability
warnings in all configurations. Additionally we compare against
the minimum and the default configuration (if provided by the
codebase)asabaselinefor thenumberof warningsinour dataset.
4.1 RQ1: WhatVariabilityWarnings Can
Off-the-Shelf Bug DetectorsFind?
We use a large, representative configuration sample with our ap-
proach, allowing us to examine how often the same warning ap-
pearsacrossdifferentconfigurations.Byusingthededuplication
approach described in Section 3.3, we can examine the subset of
configurations in which a warning occurs to discover how it is dis-
tributedacrosstheconfigurationspace.Whenawarningappears
in all sampled configurations, we can assume it is unlikely to be
a variability warning. Ruling out such warnings, our results still
showalargenumberofvariabilitywarnings,i.e.,thosethatonly
appear inasubsetofthe sampledconfigurations.
Table3shows thenumber ofwarnings produced byeachstatic
analysistoolforeachtargetcodebase.Eachrowshowsthenumber
54ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia AustinMordahl,JehoOh,Ugur Koc, ShiyiWei, andPaulGazzillo
(a)CBMC
 (b) Clang
 (c) Infer
 (d)Cppcheck
Figure 4:Numberofvariabilityandgeneric warnings,overallprograms, categorized by warningtype.
Table 3: Summary of warnings found for each combination
of target codebase and static analysis tool. *No warnings
were foundforCppcheck. †Inferdidnotrun on BusyBox.
CBMC Clang Infer Cppcheck
axTLS
Total warnings 2,010 13 46 0
Variability(count) 668 9 20 0
Variability(percent) 33% 69% 43% *
Toybox
Total 4,292 56 112 20
Variability(count) 3,498 49 78 19
Variability(percent) 82% 88% 70% 95%
BusyBox
Total 29,188 324 † 125
Variability(count) 23,896 276 † 118
Variability(percent) 82% 85% † 94%
of total warnings and the numberand percentage of the total that
are variability warnings. Each column shows these numbers for
each of the four static analysis tools tested. Note that Infer did
not run on BusyBox because it threw an Assertion failure from its
Clang backend.
Overall, the data show that variability warnings are not uncom-
mon. In most combinations of target system and analysis tool, the
majorityofwarningsfoundarevariabilitywarnings.Whenlooking
at Toybox and BusyBox, the proportion of variability warnings
is high and fairly consistent across all four static analysis tools,
ranging from 70% to 95%. axTLS had a lower number of variability
warnings. Indeed, Cppcheck reported no warnings at all in our
axTLS sample. In spite of this, the Clang static analyzer appears
to find a higher percentage of variability warnings. Because the
numberofwarningsissosmallinthiscase,itisdifficulttocome
to any conclusions for axTLS.
While not necessarily conclusive for all configurable systems,
thisprovidesevidencethatmoreconfigurabilitycouldbecorrelated
tomorepotentialdefectsmadehardertofindduetoconfigurability.We observed that most C files in Toybox and BusyBox require
turningonatleastoneconfigurationoptiontobeincludedinthe
compilation. Therefore, warnings from these files will be classified
asbeingduetovariabilityaslongasthereexistsomeconfigurations
inour sample that do not compilethem.
We conclude from the data that variability warnings are very
frequent,andthat existingstaticanalyseswouldrevealmorepotential
defectsifmadevariability-aware.
Tofurtherunderstandtheaboveresults,wecategorizethewarn-
ings by their types. Figure 4shows the distribution of variability
andgenericwarningsundereachtype.EachbarinFigures 4ato4d
aggregates the warnings from all three programs of a certain type.
Overall,variabilitywarningsspanalltypesof warnings,except
forthesingleUnix_APIgenericwarningreportedbyClang.Certain
types dominate the total number of warnings for each tool. 94%
of the CBMC warnings are Null_Deref or Overflow; 80% of the
Clang warnings are Logic_Error or Dead_Store; Uninitialized_Val
countsfor86%ofCppcheckwarnings;91%oftheInferwarnings
are Uninitialized_Val, Null_Deref, or Dead_Store. Nevertheless, the
percentage of variability over all warnings of each warning type
islargelyconsistentwiththeoveralltoolperformance.Forexam-
ple, 85% of Clang warnings are due to variability. When catego-
rizedbytypes,thepercentageofvariabilitywarnings(exceptthe
Unix_API warning) ranges from 72% (for Memory_Error) to 90%
(for Logic_Error). The only type that has more generic warnings
than variability warnings is Null_Deref by Infer, i.e., 23 generic
warnings vs. 13 variability warnings.
In summary, these data show that variability warnings represent
alltypesofwarningsfoundbythesestaticanalysistools,including
thepotentially dangerous Null_Deref and Overflow .
4.2 RQ2: HowAreVariabilityWarnings
Distributed OvertheSpaceofSample
Configurations?
RQ1 provides evidence that variability warnings are very frequent,
and we would like to evaluate how these warnings are distributed
55AnEmpirical Studyof Real-WorldVariabilityBugs ... ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
(a)CBMC-[axtls&toybox]
 (b) Clang
 (c) Infer
 (d)Cppcheck
Figure 5:Numberofconfigurationsreporting variabilitywarnings,overallprograms, categorized by warningtype.
Figure6:Thesubsetofconfigurationsthatfindallwarnings.
acrossthesampleset.Foreachwarning,wecountthenumberof
sampled configurations in which it appears. This quantity gives us
anideaabouthowłrarežawarningis,i.e.,howlikelywearetofind
this warning when checking a single configuration. Examining the
distribution of configuration counts across all warnings gives us
insightabouthowvariabilitywarningsaredistributed.Forthese
experiments, we only consider variability warnings, since generic
warnings are assumed to appear in all configurations and RQ1
already showshowcommon such warnings are.
Figure5showsbox-and-whiskerplotsofthedistributionofvari-
ability warnings across the sampled configurations. Each chart
representsthedistributionsforonestaticanalysistoolbytypeof
warning.Eachbox-and-whiskerisanaggregateofthevariability
warningsfromallthreeprograms,exceptforCBMCinFigure 5a,
which summarizes axTLS and Toybox results due to the failure
to analyze every sample configuration of BusyBox. In Figure 5,
the median number of configurations of most warning types is
between400and600.ThethreeoutliersareNaNfromCBMC(355),Memory_Error from Clang (379), and API from Clang (651). In or-
der to determine whether there were actual statically significant
differences between the different warning types or if the differ-
enttypeswere independent,weperformedANOVA testsoneach
tool’soutput.InallcasesexceptCppcheck,ANOVArejectsthenull
hypothesisofindependence at α=0.01.
We additionally observe wide distributions of the number of
configurations in most warning types. This means that some warn-
ings were detected in either a small or a large subset of sampled
configurations.Forexample,Inferdiscovered9Toyboxwarnings
in 976 configurations. We found that these variability warnings
exist in the same Toybox file (i.e., ps.c). This file is included in
compilationifanyoneoffiveconfigurationoptionsisturnedon;
specifically, these options are PS,PKILL,PGREP,IOTOP, andTOP.
Thisdisjunctiveconstraintissatisfiedinmostconfigurationsinour
sample,resultinginthe detection of thesevariability warnings.
On the other hand, the Toybox warning that was detected by
Cppcheck with least number of configurations (i.e., 98) appears
in the file axhttpd.c . Upon checking the feature interaction as-
sociatedwiththiswarning,wefoundthatitisaconjunctionof5
configuration options, which explainswhyitcan only be detected
ina fewconfigurations.Inanotherexample, oneToybox warning
wasonlydiscoveredbyCppcheckin4configurations.Thiswarning
is emitted by the tool only if the configuration option LSM_NONE
is turned on. In our sample, only 4 configurations turned on this
option because Toybox’s build system only allows this option to
beturnedonwhenmanyotheroptionsareturnedoff.Theabove
observations illustrate that the detection of variability warnings
from a sample is affected by the build system implementation of
thetargetprogram,aswellasthegenerationofsamples.Overall,
Figure5hasshownthat whilethemajorityofvariabilitywarnings
are detected in many configurations in our sample, some can only be
detected in afew due to the configurability ofthe target software .
Figure6showsthesubsetofconfigurationsinoursamplethat
may produce the same results, for each tool and program combina-
tion. The number above each column shows the size of the subset,
56ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia AustinMordahl,JehoOh,Ugur Koc, ShiyiWei, andPaulGazzillo
and the different colors/patterns in each column indicate differ-
ent configurations. We computed this subset by greedily searching
for the configuration that adds the most warnings. Algorithm 1
describes this processindetail.
Data:Cis the set of configurations, Wis the set of warnings, Sis a
subset ofC
Result:S
C′:=C,W′:=W,S:=∅;
LetW′cdenotethesetofwarnings w∈W′thatareinconfiguration
c;
whileW′is notempty do
findc∈C′thatproduces the most w∈W′;
S:=S∪ {c};W′:=W′−W′c;C′:=C′−c;
end
Algorithm1: Findasubsetofconfigurationswithallwarnings.
InFigure 6,atmost29configurations(forCBMC-BusyBox)were
neededtocoverallwarningsthatwerefoundbyoursamples.Itonly
required 4configurationstodetect all Toybox warningsby Clang.
On average, the subsets cover 92% and 80% of values of a single
option and of the2-way combinations of options in theconfigura-
tionsample,respectively.Thisresultsuggeststhat runningstatic
bugdetectorsona small,well-constructedset ofconfigurationsmay
revealmanyvariabilitywarnings .Weregardthisasanimportant
future researchdirection.
Fordevelopersdecidingbetweenvariability-awareorvariability-
obliviousanalyses,theseresultsindicateatradeoff.Forsituations
where software reliability is less of a priority than faster bug detec-
tion, using a variability-oblivious analysis may be sufficient, albeit,
findingtherightsetofconfigurationstotestmaybedifficult.On
the other hand, for critical software, finding every potential defect
requiresusingvariability-awareanalysestoguaranteethesafety
ofevery configuration.
4.3 RQ3: HowDoOurResults Compareto
Checking aMaximumor Minimum
Configuration?
Tofurtherunderstandhowthevariabilitywarningscanbedetected
and affected by the choice of configurations we compare the warn-
ings of sample configurations to that of minimum, default, and
maximum configurations.
Table4shows the results of our comparison to maximum, mini-
mum,anddefaultconfigurations.ToyboxandBusyBoxshipwith
adefault,butnotaxTLS.Turningonmoreconfigurationoptions
typicallymeansmorecode,thereforeaconfigurationwithmoreop-
tionsshouldthenresultinmorewarnings.Whilethe allyesconfig
command for these codebases’ build systems will generate a maxi-
mumconfiguration,duetothesystemdependencies,noneofthe
allyesconfig syieldbuildableconfigurationsonwhichtorunbug
finderssuccessfully.Instead,wegeneratedałmaximum"configu-
ration for each target program using the optimization algorithm
presentedbyOhetal.[ 31].Similarly, totestthetools’capabilities
in discovering warnings when most options are set to false, we
generated a łminimum" configuration using the same optimization
algorithm. We madethe following observations from Table 4.Table 4: Comparisons to warnings detected by maximum,
default and minimum configurations. Each cell shows the
number of configurations that are shared by the configura-
tionandourresults,onlyinthesingleconfiguration,oronly
in our sampled results, i.e., łshared ·single·samplež. *No
warningswerefoundbyCppcheckonaxTLS. †Inferdidnot
run on BusyBox.
cbmc clang infer cppcheck
axTLS
Maximum 1.9k·0·82 10 ·0·3 42·0·4 *
Minimum 1.6k·382·434 5 ·1·8 25·8·19 *
Toybox
Maximum 4.2k·0·29 48 ·0·8 110·0·2 14 ·0·6
Minimum 757·0·3.5k 10 ·0·46 31·0·78 4 ·2·16
Default 4.2k·0·69 52 ·0·4 110·0·2 16 ·0·4
BusyBox
Maximum 26k·128·2.7k 256 ·3·68 †82·9·43
Minimum 3.1k·3·26k 21 ·2·303 †4·5·117
Default 3.1k·3·26k 249 ·2·75 †83·11·42
First,maximumconfigurationsoftenproducedalargeportionof
warnings discovered by running the tool on our sample, but never
discoveredallwarnings .Morethan90%ofCBMCandInferwarnings
were found by maximum configurations. In other cases, maximum
configurations discovered 66% (Cppcheck-BusyBox) to 86% (Clang-
Toybox)ofallwarnings producedbyour sample.
Second,minimumconfigurationsdiscoveredfewerwarnings,but
also discovered some new warnings . It is expected that with most
configurationoptionsturnedoff,minimumconfigurationswould
miss most warnings found by our study samples. For example,
only 21 out of 324 and 4 out of 121 BusyBox warnings were found
by Clang and Cppcheck running on the minimum configuration,
respectively. Note, however, that minimum configurations also
discovered several warnings that were never found in our samples,
for example, 382 new axTLS warnings when using CBMC. Upon
inspection,webelieveonecauseisthatastaticbugdetectormay
consider certain code feasible only when most/all configuration
optionsare settofalse. Anotherreasonisthat someoptionswere
never enabled in our configuration samples, due to the constraints
we enforce.
Third,manywarnings maybe missed if tools are onlyrun on de-
fault configurations . Almost 90% of BusyBox warnings from CBMC
would have been missed if only the default configuration was used.
Similarly,abouthalfoftheaxTLSwarningsfromClangandInfer
wouldhave been missed.
The above results suggest that it is not sufficient to only test and
analyzethedefault(oranothersingle)configurationofthetargetsoft-
ware, while it may be worthwhile to include the special configuration
(e.g.,minimum) as partofthe test .
5 BUG DATASET
Using the methodology described in Section 3.5, we manually clas-
sifiedallClang,Infer,andCppcheckwarningsexceptforClang’s
warningsonBusyBoxandUninitialized_Valwarningsemittedby
CppcheckonBusyBox.AllwarningtypesexceptDead_Store7were
7WhileaDead_Storecanbeasymptomofanotherbug,theconfirmationofDead_Store
warningsoften resultsin optimization insteadof bugfixes in the code.
57AnEmpirical Studyof Real-WorldVariabilityBugs ... ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
Table 5: Manually inspected true positive bugs from our
study ofvariability warnings. *Nowarnings were foundfor
Cppcheck. †Infer did not run on BusyBox. ‡We did not in-
vestigate ClangBusyBox warnings.
clang infer cppcheck
axTLS
Variabilitybug 6 11 *
Generic bug 1 18 *
Toybox
Variabilitybug 16 6 9
Generic bug 1 5 0
BusyBox
Variabilitybug † ‡ 2
Generic bug † ‡ 2
Figure 7: The distribution of number of configurations re-
porting variabilitybugs.
inspected. Because we confirm each true bug and its associated
feature interactions as a team to gain more confidence on the re-
sults, manual classification of all warnings were prohibitive for
thethousandsofCBMCresults,the324ClangonBusyBoxwarn-
ings,andthe117Uninitialized_ValwarningsraisedbyCppcheck
onBusyBox. Nevertheless, we have generateda truebug dataset
consisting of 77 previously-unpublished bugs from recent versions
of axTLS, Toybox, and BusyBox (Table 5). Among them, 52 are
variabilitybugs.Thisbugdatasetalsocoversawiderangeofbug
types:Null_Deref(32),Logic_Error(14),Uninitialized_Val(7),Secu-
rity(6),Memory_Error(6),Resource_Leak(5),Memory_Leak(4),
Array_Bounds (2), and Undef_Behavior (1). We now study the bug
characteristics to providemore insightsonthis dataset.
Figure7shows the distribution of the number of configurations
on which variability bugs were discovered. The majority of vari-
ability bugs were detected by about half of the configurations in
our samples, consistent with our observation from Figure 5. Figure
8showsthenumberofconfigurationoptionsaffectingthebugs.Re-
call that these options were initially automatically identified, then
manuallyconfirmed(Section 3.6).Inourdataset,40variabilitybugs
areassociatedwithonly1configurationoption.Amongthesebugs,
30aredefinedinMakefiles,and10aredefinedwithCpreprocessor
directivesinthesourcecode.Additionally,wesee9bugsassociated
with some kind of dependency. Figure 9shows an example of a
configurationoption, AXHTTPD,inaMakefile,whichgovernsthein-
clusionofafile, axhttpd.c ,inwhichwefoundfourbugs.Figure 10
Figure 8:Feature interactions ofvariabilitybugs.
ifndef CONFIG_AXHTTPD
web_server:
else
web_server :: $(TARGET)
Figure 9:Anexample ofvariabilityinan axTLS Makefile.
shows another configuration option, HTTP_HAS_AUTHORIZATION ,
which depends on AXHTTPD (i.e.,HTTP_HAS_AUTHORIZATION can
onlybeenabledif AXHTTPD isenabled). HTTP_HAS_AUTHORIZATION
includes the file htpasswd.c ,inwhichwe foundtwobugs.
menu "Axhttpd Configuration"
depends on CONFIG_AXHTTPD
...
config CONFIG_HTTP_HAS_AUTHORIZATION
bool "Enable authorization"
default y
...
endmenu
Figure 10: An example of dependencies between configura-
tionoptionsinanaxTLSKconfigfile.Alloptionsdefinedin
thismenudepend on CONFIG_AXHTTP.
The other 12 bugs are associated with 2 or 3 options. Figure 8
shows that regardless of the number of options, those options can
come from either preprocessor directives or from Makefiles. In
bugsthatare causedbythe interactionof 2 or 3 options,thoseop-
tionscanoriginatefromanycombinationofMakefile,preprocessor,
anddependencyonanotheroption.Thisresultsuggeststhatitis
importanttoconsiderthebuildsystemconstraints,Makefile,and
preprocessorsaccurately to detectsomevariability bugs.
Webelievethisbugdatasetcanserveasavaluablebenchmarkfor
futurestudies,bothintestingvariability-awareanalysesandintest-
ingmethodsoffindingvariabilitybugswithvariability-oblivious
analysis.Wealsobelievethatalthoughwecouldonlymanuallyclas-
sify a small percent of the emitted warnings, this dataset supports
our methodology as being useful for findingvariability bugs.
6 THREATS TO VALIDITY
Weidentifytwothreatstothevalidityofourconclusions.First,our
empiricalstudyusedfourstaticbugdetectorsandthreeopensource
C programs. Although these are real-world tools and programs,
58ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia AustinMordahl,JehoOh,Ugur Koc, ShiyiWei, andPaulGazzillo
theymaynotberepresentativeofbugdetectorsandconfigurable
C software as a whole. Second, there are approximations in our
approachthatcouldleadtoinaccurateresults.Ourdeduplication
processmayidentifytwowarningsasequivalenteveniftheyare
not, so long as they are on the same line and in the same source
code file. Our estimation of variabilitymay incorrectly label some
variabilitywarningsasgenericwarnings.Ourmanualclassification
approachmayproduceincorrectresults.Weincreasetheconfidence
thatthetruebugswereportaretruebyconfirmingtheseasagroup.
7 RELATED WORK
Our work is related to (i) recent studies on variability bugs and
dataset generation, (ii) research in finding variability bugs, and (iii)
methodsthat identifyfeature interactionsanddependencies.
Variability Bug Study and Dataset. Abal et al. [ 1,40] studied
previouslyreported(andfixed)variabilitybugsfromthebugrepos-
itories of Apache, Busybox, Marlin, and Linux software. They cre-
atedadatabaseof98variabilitybugs,eachofwhich hasafeature
interactionandsimplifiedcodeversion.Thesebugsareofsimilar
types to the ones that we find. Bugs in this dataset span over a
decadeofsoftwaredevelopmentandonesthatexistinoldsoftware
versions are challenging to be reproduced. Our work was inspired
by their effort to create a variability bug dataset. Instead, we focus
on previously-unpublished bugs in recent versions of the target
programsthatcanbefoundbystaticanalysistoolstosupportthe
evaluation offuture analysis.
Other empirical work has been performed to study variability
bugs[2,29,41ś43].Forexample,Medeirosetal.[ 41]investigatedC
programstofindundeclared/unusedvariablesandfunctionsarising
from variability through global analysis using TypeChef [ 4]. They
found how those issues were introduced from revision histories,
andobservedthatthoseissuesoftentookalongtimetobefixed.
Propersamplingstrategy is beneficialfor earlydetectionofthose
issues.Thisworkcreatedadatasetconsistingof39variabilitybugs.
Variabilitybugdetection. Twoimportantlinesofresearchinfind-
ingvariabilitybugsareCombinatorialInteractionTesting(CIT)[ 16,
44ś46],andvariability-awarestaticanalysis.CITaimstosystem-
atically sample configurations that satisfy certain coverage con-
ditions[17ś20].ManyadaptationsofCIThavebeenproposedto
addresstheneedsofdifferentconfigurationspaces,e.g.,accounting
for configuration constraints [ 47ś49], test case constraints [ 23,24],
and cost aware-CIT [ 22]. Although CIT approaches have been
shown to be effective in finding variability bugs, CIT test suites
are not adequate to isolate and identify the specific interactions
ofconfigurationoptionsthatleadtothedetectedvariabilitybugs.
Usinguniformrandomsampling,ourapproachfocusesonstudying
warnings and bugs to make observations that are representative of
thecompleteconfigurationspace.Also,weintegratestaticanalysis
toolsto detectvariability bugs.
Overthelastdecade,researchershavedevelopednewvariability-
aware static analysis techniques [ 7,50ś56]. Rhein et al. [ 7] pre-
sentedaframeworkthatimplementedmultiplevariability-aware
bugdetectors.Theresultsoftheseanalyseswerecomparedwith
three sampling-based approaches, demonstrating the effectiveness
and efficiency of variability-aware analyses. Characteristics of the
warnings detected were also studied. Our study complements this
worktounderstandthetypesofvariabilitywarningsreportedbyoff-the-shelf static bug detectors. In addition, we have generated a
bugdatasetviamanualclassification,potentiallyusefulforevaluat-
ingthis andothervariability-aware analyses.
Understanding Feature Models of Existing Systems. Under-
standingthefeaturesandtheirdependenciesfromexistingsystems
is vital for understanding the variability. Researchers developed
methodsandtoolstoidentifyfeatureinteractionsanddependen-
cies statically from source code [ 57ś59], make systems and con-
figuration specifications [ 35,60ś62], or dynamically running the
systems [ 63ś66]. For example, Nguyen et al. [ 64] presented iGen
that dynamically discovers feature interactions with counter exam-
pleguidedrefinement.Ourframeworkpresentsanalgorithmfor
automaticallyidentifyingfeatures,andwealsostudythefeature
interactions of the dataset. Several works in this line of research
(e.g., iGen) can potentially be integrated into the framework we
built as an alternative approach to identifying feature interactions.
8 CONCLUSIONS& FUTUREWORK
Variability bugsin configurable Csoftware presenta seriouschal-
lenge for automatic bug detection through static analysis. State-of-
the-art variability-aware static analyses are promising, but there
is currently a gap between them and variability-oblivious tools.
Our work shows how to simulate variability-awareness with these
toolsthroughourframework.Weappliedthisframeworktosev-
eral state-of-the-art, but variability-oblivious, bug detectors and
several highly-configurable codebases. With our results, we gain a
deeper understanding of how these tools would perform, showing
that variability warnings are very frequent, represent many kinds
of potential defects, and are distributed across the configuration
space. To support future research on highly-configurable code and
analyses,ourbugdatasetprovides77truepositivesbugsthatwe
know can be found with static analysis tools. We hope this dataset
willbe avaluable benchmarkfor future tooldevelopers.
WebelievethatthefindingspresentedinSections 4and5will
helpdrivefutureresearchintovariability-awareanalysis.Oneof
ourmostinterestingfindingswasthatgivenanysetofwarnings
obtainedfrom1,000configurations,thatsamesetofwarningscould
be obtained from a small subset of those configurations. Finding
an algorithm to identify these configurations in advance would
improve variability-aware testing. Future analyses of the small
configurationsetspresentedinSection 4mayleadtoinsightson
how to carefully construct configuration sets that exhibit a wide
varietyofvariability warnings.
We have plans to continue to develop our toolchain and dataset
togatherfurtherdataonvariabilitybugs.Weintendtomakeour
framework pluggable to new bug detectors. We plan to continue
to improve our framework with better feature identification and
deduplicationalgorithms.Specifically,wewouldliketodeduplicate
bugsacrosstools,allowingustocomparedifferenttools.Wealso
plan to perform more classification of warnings to expand the bug
dataset.Leveragingtestingtools likeprogramslicers and tracers
canbothspeedupclassificationandenableclassificationofmore
complex warnings.
ACKNOWLEDGMENTS
This work is supported by NSF grants CCF-1840934 and CCF-
1816951.
59AnEmpirical Studyof Real-WorldVariabilityBugs ... ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
REFERENCES
[1]I.Abal,C.Brabrand,andA.Wasowski,ł42variability bugsinthelinuxkernel:A
qualitativeanalysis,žin Proceedingsofthe29thACM/IEEEInternationalConference
onAutomatedSoftwareEngineering ,ser.ASE’14. NewYork,NY,USA:ACM,2014,
pp. 421ś432. [Online].Available: http://doi.acm.org/10.1145/2642937.2642990
[2]G. Ferreira, M. Malik, C. Kästner, J. Pfeffer, and S. Apel, łDo #ifdefs influence
the occurrence of vulnerabilities? an empirical study of the linux kernel,ž in
Proceedingsofthe20thInternationalSystemsandSoftwareProductLineConference ,
ser. SPLC’16. New York, NY,USA: ACM, 2016, pp. 65ś73.[Online]. Available:
http://doi.acm.org/10.1145/2934466.2934467
[3]J. Melo, F. B. Narcizo, D. W. Hansen, C. Brabrand, and A. Wasowski, łVariability
through the eyes of the programmer,ž in Proceedings of the 25th International
ConferenceonProgramComprehension ,ser.ICPC’17. Piscataway,NJ,USA:IEEE
Press, 2017, pp. 34ś44. [Online]. Available: https://doi.org/10.1109/ICPC.2017.34
[4]C.Kästner,P.G.Giarrusso,T.Rendel,S.Erdweg,K.Ostermann,andT.Berger,
łVariability-aware parsing in the presence of lexical macros and conditional
compilation,ž in ACM SIGPLAN Notices , vol. 46, no. 10. ACM, 2011, pp. 805ś824.
[5]P.GazzilloandR.Grimm,łSuperc:Parsingallofcbytamingthepreprocessor,ž
inProceedingsof the33rdACM SIGPLANConference onProgramming Language
Design andImplementation ,ser. PLDI ’12. New York,NY,USA: ACM, 2012, pp.
323ś334. [Online].Available: http://doi.acm.org/10.1145/2254064.2254103
[6]R.Tartler,C.Dietrich,J.Sincero,W.Schröder-Preikschat,andD.Lohmann,łStatic
analysisofvariabilityinsystemsoftware:The90,000#ifdefsissue.žin USENIX
Annual TechnicalConference , 2014,pp. 421ś432.
[7]A.vonRhein,J.Liebig,A.Janker,C.Kästner,andS.Apel,łVariability-awarestatic
analysis at scale: An empirical study,ž ACM Transactions on Software Engineering
and Methodology , vol. 27,no. 4,p. ArticleNo. 18,2018.
[8]A. Garrido and R. Johnson, łAnalyzing multiple configurations of a C program,ž
inICSM, Sep. 2005,pp. 379ś388.
[9]E.Bodden,T.Tolêdo,M.Ribeiro,C.Brabrand,P.Borba,andM.Mezini,łSPLLIFT:
StaticallyAnalyzingSoftwareProductLinesinMinutesInsteadofYears,žin PLDI.
ACM,2013.
[10]J.Liebig,A.vonRhein,C.Kästner,S.Apel,J.Dörre,andC.Lengauer,łScalable
analysis of variable software,ž in Proceedings of the 2013 9th Joint Meeting on
FoundationsofSoftwareEngineering . ACM,2013,pp. 81ś91.
[11]E. Walkingshaw, C. Kästner, M. Erwig, S. Apel, and E. Bodden, łVariational
Data Structures: Exploring Tradeoffs in Computing with Variability,ž in Onward!
ACM,2014,pp. 213ś226.
[12]C. Kästner, K. Ostermann, and S. Erdweg, łAVariability-aware ModuleSystem,ž
inOOPSLA. ACM,2012,pp. 773ś792.
[13]A.F.Iosif-Lazar,J.Melo,A.S.Dimovski,C.Brabrand,andA.Wasowski,łEffective
Analysis of CProgramsby RewritingVariability,ž CoRR, 2017.
[14] łInfer static analyzer.ž[Online].Available: https://github.com/facebook/infer
[15] łCBMC.ž[Online].Available: https://github.com/diffblue/cbmc
[16]C.Yilmaz,S.Fouché,M.B.Cohen,A.Porter,G.Demiroz,andU.Koc,łMoving
Forward with Combinatorial Interaction Testing,ž Computer , vol. 47, no. 2, pp.
37ś45, Feb. 2014.
[17]K.-C. Tai and Y. Lei, łA test generation strategy for pairwise testing,ž IEEE Trans-
actions onSoftwareEngineering , vol. 28,no. 1,pp. 109ś111, Jan. 2002.
[18]S. Oster, F. Markert, and P. Ritter, łAutomated incremental pairwise testing of
software product lines,ž in International Conference on Software Product Lines .
Springer, 2010,pp. 196ś210.
[19]M.F.Johansen,Ø.Haugen,andF.Fleurey,łAnalgorithmforgeneratingt-wise
coveringarraysfromlargefeaturemodels,žin Proceedingsofthe16thInternational
SoftwareProductLineConference-Volume 1 . ACM,2012,pp. 46ś55.
[20]D. Marijan, A. Gotlieb, S. Sen, and A. Hervieu, łPractical pairwise testing for
softwareproductlines,žin Proceedingsofthe 17thinternational softwareproduct
lineconference . ACM,2013,pp. 227ś235.
[21]C. Nie and H. Leung, łA Survey of Combinatorial Testing,ž ACM Comput.
Surv., vol. 43, no. 2, pp. 11:1ś11:29, Feb. 2011. [Online]. Available: http:
//doi.acm.org/10.1145/1883612.1883618
[22]G. Demiroz, łCost-aware Combinatorial Interaction Testing (Doctoral Sym-
posium),ž in Proceedings of the 2015 International Symposium on Software
Testing and Analysis , ser. ISSTA 2015. New York, NY, USA: ACM,
2015, pp. 440ś443, event-place: Baltimore, MD, USA. [Online]. Available:
http://doi.acm.org/10.1145/2771783.2784775
[23]C.Yilmaz,łTestCase-AwareCombinatorialInteractionTesting,ž IEEETransac-
tions onSoftwareEngineering , vol. 39,no. 5,pp. 684ś706, May 2013.
[24]U. Koc and C. Yilmaz, łApproaches for computing test-case-aware covering
arrays,žSoftware Testing, Verification and Reliability , vol. 28, no. 7, p. e1689, 2018.
[Online].Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1689
[25]C.Yilmaz,E.Dumlu,M.B.Cohen,andA.Porter,łReducingMaskingEffectsin
CombinatorialInteractionTesting: A FeedbackDrivenAdaptiveApproach,ž IEEE
Transactions onSoftwareEngineering , vol. 40,no. 1,pp. 43ś66, Jan. 2014.
[26]C. Song, A. Porter, and J. S. Foster, łiTree: Efficiently Discovering High-coverage
ConfigurationsUsingInteractionTrees,žin Proceedingsofthe34thInternational
ConferenceonSoftwareEngineering ,ser.ICSE’12. Piscataway,NJ,USA:IEEEPress,2012,pp.903ś913.[Online].Available: http://dl.acm.org/citation.cfm?id=
2337223.2337329
[27]R. Tartler, D. Lohmann, C. Dietrich, C. Egger, and J. Sincero, łConfiguration
coverage in the analysis of large-scale system software,ž in Proceedings of the 6th
Workshop on Programming Languages and Operating Systems . ACM, 2011, p. 2.
[28]C. Henard, M. Papadakis, M. Harman, and Y. Le Traon, łCombining multi-
objectivesearchandconstraintsolvingforconfiguringlargesoftwareproduct
lines,žinICSE, 2015.
[29]J. Melo, E. Flesborg, C. Brabrand, and A. Wasowski, łA quantitative analysis
of variability warnings in linux,ž in Proceedings of the Tenth International
Workshop on Variability Modelling of Software-intensive Systems , ser. VaMoS
’16. New York, NY, USA: ACM, 2016, pp. 3ś8. [Online]. Available:
http://doi.acm.org/10.1145/2866614.2866615
[30]F. Medeiros, C. Kästner, M. Ribeiro, R. Gheyi, and S. Apel, łA comparison of
10 sampling algorithms for configurable systems,ž in Proceedings of the 38th
InternationalConference onSoftwareEngineering . ACM,2016,pp. 643ś654.
[31]J.Oh,P.Gazzillo,D.Batory,M.Heule,andM.Myers,łUniformsamplingfrom
kconfig feature models,ž The University of Texas at Austin, Department of Com-
puter Science, Tech. Rep. TR-19-02, 2019.
[32]B. Livshits, M. Sridharan, Y. Smaragdakis, O. Lhoták, J. N. Amaral, B.-Y. E.
Chang, S. Z.Guyer,U.P.Khedker,A.Mùller,andD.Vardoulakis,łIn defense of
soundiness: A manifesto,ž Commun. ACM , vol. 58, no. 2, pp. 44ś46, Jan. 2015.
[Online].Available: http://doi.acm.org/10.1145/2644805
[33]M.D.Ernst,G.J.Badros,andD.Notkin,łAnempiricalanalysisofCpreprocessor
use,žIEEE TSE, pp. 1146ś1170,Dec2002.
[34]M. Thurley,łsharpsatścountingmodelswithadvancedcomponent cachingand
implicitbcp,žin InternationalConferenceonTheoryandApplicationsofSatisfiabil-
ity Testing . Springer, 2006,pp. 424ś429.
[35]P.Gazzillo,łKmax:Findingallconfigurationsofkbuildmakefilesstatically,žin
Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering ,
ser. ESEC/FSE 2017. New York, NY, USA: ACM, 2017, pp. 279ś290. [Online].
Available: http://doi.acm.org/10.1145/3106237.3106283
[36]M. Endler, łAwesome static analysis!ž 2018. [Online]. Available: https:
//github.com/mre/awesome-static-analysis
[37] łcppcheck.ž[Online].Available: https://github.com/danmar/cppcheck
[38] łLLVM.ž[Online].Available: https://llvm.org
[39]łscan-build.ž [Online]. Available: https://clang-analyzer.llvm.org/scan-build.html
[40]I. Abal, J. Melo, x. Stănciulescu, C. Brabrand, M. Ribeiro, and A. Wasowski,
łVariability bugs in highly configurable systems: A qualitative analysis,ž ACM
Trans. Softw. Eng. Methodol. , vol. 26, no. 3, pp. 10:1ś10:34, Jan. 2018. [Online].
Available: http://doi.acm.org/10.1145/3149119
[41]F. Medeiros, I. Rodrigues, M. Ribeiro, L. Teixeira, and R. Gheyi, łAn
empirical study on configuration-related issues: Investigating undeclared and
unused identifiers,ž in Proceedings of the 2015 ACM SIGPLAN International
Conference on Generative Programming: Concepts and Experiences , ser. GPCE
2015. New York, NY, USA: ACM, 2015, pp. 35ś44. [Online]. Available:
http://doi.acm.org/10.1145/2814204.2814206
[42]J.Melo,C.Brabrand,andA.Wasowski,łHowdoesthedegreeofvariabilityaffect
bug finding?ž in Proceedings of the 38th International Conference on Software
Engineering , ser. ICSE ’16. New York, NY, USA: ACM, 2016, pp. 679ś690.
[Online].Available: http://doi.acm.org/10.1145/2884781.2884831
[43]R. Muniz, L. Braz, R. Gheyi, W. Andrade, B. Fonseca, and M. Ribeiro, łA
qualitative analysis of variability weaknesses in configurable systems with
#ifdefs,žin Proceedingsofthe12thInternationalWorkshoponVariabilityModelling
of Software-Intensive Systems , ser. VAMOS 2018. New York, NY, USA: ACM,
2018, pp. 51ś58. [Online]. Available: http://doi.acm.org/10.1145/3168365.3168382
[44]R.Brownlie,J.Prowse,andM.S.Phadke,łRobusttestingofat&tpmx/starmail
using oats,ž AT&T TechnicalJournal , vol. 71,no. 3,pp. 41ś47, 1992.
[45]M. B. Cohen, P. B. Gibbons, W. B. Mugridge, and C. J. Colbourn,
łConstructing test suites for interaction testing,ž in Proceedings of the 25th
International Conference on Software Engineering , ser. ICSE ’03. Washington,
DC, USA: IEEE Computer Society, 2003, pp. 38ś48. [Online]. Available:
http://dl.acm.org/citation.cfm?id=776816.776822
[46]D. M. Cohen, S. R. Dalal, M. L. Fredman, and G. C. Patton, łThe aetg system:
An approach to testing based on combinatorial design,ž IEEE Transactions on
SoftwareEngineering , vol. 23,no. 7,pp. 437ś444, 1997.
[47]R. C. Bryce and C. J. Colbourn, łPrioritized interaction testing for pair-wise
coverage with seeding and constraints,ž Information and Software Technology ,
vol. 48,no. 10,pp. 960ś970, 2006.
[48]P.Danziger,E.Mendelsohn,L.Moura,andB.Stevens,łCoveringarraysavoiding
forbiddenedges,ž TheoreticalComputerScience ,vol.410,no.52,pp.5403ś5414,
2009.
[49]B. J. Garvin, M. B. Cohen, and M. B. Dwyer, łAn improved meta-heuristic search
forconstrainedinteractiontesting,žin 20091stInternationalSymposiumonSearch
BasedSoftwareEngineering . IEEE,2009,pp. 13ś22.
[50]K. Lauenroth,K. Pohl, and S. Toehning,łModel checkingof domainartifacts in
productlineengineering,žin 2009IEEE/ACMInternationalConferenceonAuto-
matedSoftwareEngineering . IEEE,2009,pp. 269ś280.
60ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia AustinMordahl,JehoOh,Ugur Koc, ShiyiWei, andPaulGazzillo
[51]S. Apel, C. Kästner, A. Größlinger, and C. Lengauer, łType safety for feature-
oriented product lines,ž Automated SoftwareEngineering , vol.17,no. 3, pp. 251ś
300, 2010.
[52]A. Classen, P. Heymans, P.-Y. Schobbens, A. Legay, and J.-F. Raskin, łModel
checking lots of systems: efficient verification of temporal properties in software
productlines,žin Proceedingsofthe32ndACM/IEEEInternationalConferenceon
SoftwareEngineering-Volume 1 . ACM,2010,pp. 335ś344.
[53]J. Liebig, S. Apel, C. Lengauer, C. Kästner, and M. Schulze, łAn analysis of the
variability in forty preprocessor-based software product lines,ž in Proceedings of
the32ndACM/IEEEInternationalConferenceonSoftwareEngineering-Volume1 .
ACM,2010,pp. 105ś114.
[54]T. Thüm, S. Apel, C. Kästner, M. Kuhlemann, I. Schaefer, and G. Saake, łAnalysis
strategiesforsoftwareproductlines,ž SchoolofComputerScience,Universityof
Magdeburg, Tech.Rep. FIN-004-2012 , 2012.
[55]C.Kästner,S.Apel,T.Thüm,andG.Saake,łTypecheckingannotation-basedprod-
uct lines,ž ACM Transactions on Software Engineering and Methodology (TOSEM) ,
vol. 21,no. 3,p. 14,2012.
[56]J.Liebig,A.vonRhein,C.Kästner,S.Apel,J.Dörre,andC.Lengauer,łScalable
Analysis of Variable Software,ž in Proceedings of the 2013 9th Joint Meeting on
Foundations of Software Engineering , ser. ESEC/FSE 2013. New York, NY, USA:
ACM, 2013, pp. 81ś91, event-place: Saint Petersburg, Russia. [Online]. Available:
http://doi.acm.org/10.1145/2491411.2491437
[57]S.Nadi,T.Berger,C.Kästner,andK.Czarnecki,łMiningconfigurationconstraints:
Static analyses and empirical results,ž in Proceedings of the 36th International
Conference onSoftwareEngineering . ACM,2014,pp. 140ś151.
[58]S.Nadi,T.Berger,C.Kästner,andK.Czarnecki, łWhereDoConfigurationCon-
straints Stem From? An Extraction Approach and an Empirical Study,ž IEEE
Transactions onSoftwareEngineering , vol. 41,no. 8,pp. 820ś841, Aug.2015.
[59]M.Lillack,C.Kästner,andE.Bodden,łTrackingLoad-TimeConfigurationOp-
tions,žIEEETransactionsonSoftwareEngineering ,vol.44,no.12,pp.1269ś1291,Dec. 2018.
[60]C.Dietrich,R.Tartler,W.Schröder-Preikschat,andD.Lohmann,łArobustap-
proachforvariabilityextractionfromthelinuxbuildsystem,žin Proceedingsof
the16thInternationalSoftwareProductLineConference-Volume1 . ACM,2012,
pp. 21ś30.
[61]T.Berger,S.She,R.Lotufo,A.Wasowski,andK.Czarnecki,łAstudyofvariability
models and languages in the systems software domain,ž IEEE Transactions on
SoftwareEngineering , vol. 39,no. 12,pp. 1611ś1640,2013.
[62]S. Zhou, J. Al-Kofahi, T. N. Nguyen, C. Kästner, and S. Nadi, łExtracting Configu-
rationKnowledgefromBuildFileswithSymbolicAnalysis,žin 2015IEEE/ACM
3rdInternationalWorkshop onReleaseEngineering , May 2015,pp. 20ś23.
[63]J. Meinicke, C.-P. Wong, C. Kästner, T. Thüm, and G. Saake, łOn essential
configuration complexity: Measuring interactions in highly-configurable
systems,ž in Proceedings of the 31st IEEE/ACM International Conference on
AutomatedSoftwareEngineering ,ser.ASE2016. NewYork,NY,USA:ACM,2016,
pp. 483ś494. [Online].Available: http://doi.acm.org/10.1145/2970276.2970322
[64]T. Nguyen, U. Koc, J. Cheng, J. S. Foster, and A. A. Porter, łiGen: Dynamic
Interaction Inference for ConfigurableSoftware,ž in Proceedings ofthe 2016 24th
ACMSIGSOFT InternationalSymposiumonFoundations ofSoftwareEngineering ,
ser.FSE2016. NewYork,NY,USA:ACM,2016,pp.655ś665.[Online].Available:
http://doi.acm.org/10.1145/2950290.2950311
[65]L.S.Ghandehari,Y.Lei,R.Kacker,D.R.R.Kuhn,D.Kung,andT.Xie,łACom-
binatorialTesting-BasedApproachtoFaultLocalization,ž IEEETransactionson
SoftwareEngineering , pp. 1ś1, 2018.
[66]L. R. Soares, J. Meinicke, S. Nadi, C. Kästner, and E. S. de Almeida, łExploring
Feature Interactions Without Specifications: A Controlled Experiment,ž in
Proceedings of the 17th ACM SIGPLAN International Conference on Generative
Programming:ConceptsandExperiences ,ser.GPCE2018. NewYork,NY,USA:
ACM, 2018, pp. 40ś52, event-place: Boston, MA, USA. [Online]. Available:
http://doi.acm.org/10.1145/3278122.3278127
61