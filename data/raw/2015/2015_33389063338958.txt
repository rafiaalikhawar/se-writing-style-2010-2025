REINAM: Reinforcement Learning for Input-Grammar Inference
Zhengkai Wu
zw3@illinois.edu
University of Illinois at
Urbana-Champaign
Illinois, USAEvan Johnson
enjhnsn2@illinois.edu
University of Illinois at
Urbana-Champaign
Illinois, USAWei Yang
wei.yang@utdallas.edu
University of Texas at Dallas
Texas, USA
Osbert Bastani
obastani@seas.upenn.edu
University of Pennsylvania
Pennsylvania, USADawn Song
dawnsong@cs.berkeley.edu
University of California, Berkeley
California, USAJian Peng
jianpeng@illinois.edu
University of Illinois at
Urbana-Champaign
Illinois, USA
Tao Xie
taoxie@illinois.edu
University of Illinois at
Urbana-Champaign
Illinois, USA
ABSTRACT
Program input grammars ( i.e.,grammars encoding the language
of valid program inputs) facilitate a wide range of applications in
software engineering such as symbolic execution and delta debug-
ging. Grammars synthesized by existing approaches can cover only
a small part of the valid input space mainly due to unanalyzable
code ( e.g.,native code) in programs and lacking high-quality and
high-variety seed inputs. To address these challenges, we present
REINAM, a reinforcement-learning approach for synthesizing prob-
abilistic context-free program input grammars without any seed
inputs. REINAM uses an industrial symbolic execution engine to
generate an initial set of inputs for the given target program, and
then uses an iterative process of grammar generalization to proac-
tively generate additional inputs to infer grammars generalized
from these initial seed inputs. To efficiently search for target gen-
eralizations in a huge search space of candidate generalization
operators, REINAM includes a novel formulation of the search
problem as a reinforcement learning problem. Our evaluation on
11 real-world benchmarks shows that REINAM outperforms an
existing state-of-the-art approach on precision and recall of synthe-
sized grammars, and fuzz testing based on REINAM substantially
increases the coverage of the space of valid inputs. REINAM is able
to synthesize a grammar covering the entire valid input space for
some benchmarks without decreasing the accuracy of the grammar.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia
¬©2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5572-8/19/08. . . $15.00
https://doi.org/10.1145/3338906.3338958CCS CONCEPTS
‚Ä¢Theory of computation ‚ÜíProgram analysis ;‚Ä¢Software and
its engineering ‚ÜíSoftware testing and debugging .
KEYWORDS
reinforcement learning, grammar synthesis, dynamic symbolic exe-
cution, fuzzing
ACM Reference Format:
Zhengkai Wu, Evan Johnson, Wei Yang, Osbert Bastani, Dawn Song, Jian
Peng, and Tao Xie. 2019. REINAM: Reinforcement Learning for Input-
Grammar Inference. In Proceedings of the 27th ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software En-
gineering (ESEC/FSE ‚Äô19), August 26‚Äì30, 2019, Tallinn, Estonia. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3338906.3338958
1 INTRODUCTION
Many programs take strings of symbols as inputs. The set of such
strings that a program accepts is called a language, which is rep-
resented by a program input grammar. Program input grammars
facilitate understanding of the input structure and are essential for a
wide range of applications such as symbolic execution [ 20,28] (gen-
erally for test-input generation), reverse engineering, protocol spec-
ification [ 18], delta debugging [ 29], prevention of exploits [ 34,39],
and improvement of system resilience [ 33]. Despite the importance
of program input grammars, acquiring the grammars often requires
much manual effort, and these grammars are often either not speci-
fied or specified in a machine-unfriendly form ( e.g.,text documents).
For example, the full specification of the PDF format is available
only in the form of a text document with over 1,300 pages [1].
For a program whose input grammar is not specified in a machine-
friendly form, existing approaches have been proposed for attempt-
ing to infer the input grammar using program analysis [ 12,13,
22,23], language induction [ 11,14,16,25,31], and machine learn-
ing [ 17,21,32]. However, these existing approaches of grammar
inference are not able to produce grammars of sufficient quality
488
ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia Z. Wu, E. Johnson, W. Yang, O. Bastani, D. Song, J. Peng, and T. Xie
(in terms of completeness and accuracy) for real-world software
systems due to the following three main challenges.
Unanalyzable code. Existing approaches based on program
analysis [ 12,13,22,23] infer input grammars based on static-analysis
information of the target program‚Äôs code or from runtime program
information collected via instrumentation of the program. However,
these approaches cannot handle programs that cannot be instru-
mented (such as web services) or parts of programs that are too
difficult for static program analysis to handle (such as native code
or dynamic language features).
Low variety and quality of seed inputs. Existing approaches
based on language induction [ 11,14,16,25,31] leverage language
induction algorithms to synthesize input grammars given a set
of seed inputs. However, the effectiveness of language induction
algorithms heavily depends on the variety and quality of the seed
inputs. For example, to infer an input grammar for a program that
parses IP addresses, if the seed inputs contain only IPv4 addresses,
then the grammar inferred by the language induction algorithms
cannot capture the IPv6 format.
Lack of seed inputs. Given a large number of seed inputs, ex-
isting approaches based on machine learning [ 17,32] can train
machine learning models representing input grammars that can be
used to generate inputs for fuzz testing. However, there are often
not sufficiently many valid examples to learn from.
We aim to tackle the preceding challenges by addressing a key
limitation of existing state-of-the-art approaches for grammar infer-
ence (e.g., Glade [ 14]). Existing approaches usually leverage active
learning‚Äî i.e.,they use an iterative process of generalization steps,
each of which generates new candidate grammars from the given
seed inputs (see Section 2 for details). Such approaches discard a
candidate grammar if anyof its generated strings are rejected by
the target program [ 14]. This design choice is common in active
learning approaches, resulting in a rigid strategy of ‚Äúno overgen-
eralization allowed‚Äù to ensure that candidate grammars in each
generalization step are precise ( i.e.,all strings generated from a
synthesized grammar are covered by the ideal input grammar).
However, this design choice forgoes the opportunity to poten-
tially expand the coverage achieved by the final synthesized gram-
mar ( i.e.,the overlapping scope of all the strings generated from
the final synthesized grammar and all the ones generated by the
ideal input grammar). For instance, a generalization operator may
increase coverage at the expense of a tiny amount of overgeneraliza-
tion, yet existing approaches would still reject such a generalization.
Furthermore, as we illustrate in Section 3, even if a generalization
operator often results in an inaccurate grammar, the composition
of multiple such inaccurate generalizations may complement each
other in a way that forms an accurate composite generalization.
We propose REINAM, a novel framework that uses reinforce-
ment learning to synthesize program input grammars. In particular,
REINAM improves over existing approaches by retaining the ability
to accept inaccurate generalization steps while still synthesizing
a final grammar that achieves high accuracy. REINAM achieves
this goal using three key design choices. First, rather than rep-
resenting the grammar as a deterministic context-free grammar
(CFG), REINAM represents the accuracy of each production rule
as a probability in a probabilistic context-free grammar (PCFG).
This representation allows REINAM to quantify the quality of acandidate production rule beyond simply whether the rule overgen-
eralizes. For example, it enables REINAM to retain an inaccurate
production rule during a single generalization step, and later de-
crease/eliminate the inaccuracy via a composite generalization.
Second, REINAM enhances the completeness of the final syn-
thesized grammar by incrementally improving imperfect candidate
grammars instead of discarding these grammars as done by the
rigid ‚Äúno overgeneralization allowed‚Äù strategy used in prior ap-
proaches [ 14]. In particular, REINAM incrementally adjusts the
probability of candidate production rules in the PCFG model using
machine learning to make the rules more accurate. A challenge
is that a large dataset of seed inputs is usually needed to train
a probabilistic generative model such as PCFG. Thus, REINAM
uses reinforcement learning [ 30] to tune the PCFG. In particular,
reinforcement learning uses the generative PCFG model itself to
generate new training data. Then, REINAM runs the target program
as a black-box oracle to check whether the generated inputs are
valid, and uses this feedback to improve the PCFG model. Finally,
REINAM iteratively generates more data to further tune the PCFG.
Figure 1 shows how REINAM formulates the grammar synthesis
task as a reinforcement learning problem. In our formulation, an
agent (the PCFG) is interacting with an environment (the target
program). The agent chooses an action (the choice of productions to
use to generate a program input) that causes a state transition (the
portion of the program input constructed so far). Upon taking an
action, the agent observes the next state. Eventually (once the pro-
gram input is completely constructed), the agent receives a reward
from the environment (based on whether the input is accepted or
rejected). Then, REINAM uses a reinforcement learning algorithm
to update the agent parameters (the PCFG probabilities).
A key challenge is that REINAM needs to adjust not only the
probabilities of the PCFG, but also the structure of the PCFG ( e.g.,
by adding new candidate productions) to synthesize a more general
grammar. However, traditional reinforcement learning algorithms
(e.g.,Deep Q-learning [ 30]) tune only the parameters of the agent
(e.g.,a deep neural network). Thus, in addition to using reinforce-
ment learning to adjust the weights of the PCFG, REINAM addition-
ally adjusts the PCFG using generalization operators that modify the
structure of the PCFG. In particular, REINAM first applies general-
ization operators to construct candidate grammars, then optimizes
the probabilities of the corresponding PCFG, and finally uses the
PCFG probabilities to determine whether to accept productions in
the candidate grammar.
Finally, REINAM uses automatic test generation algorithms to
generate additional seed inputs [ 38,40]. By doing so, REINAM
improves generalization and alleviates the shortcomings of existing
state-of-the-art approaches such as Glade [ 14] caused by their focus
on avoiding overgeneralization.
We evaluate REINAM on 11 real-world benchmarks with man-
ually written grammars used in real scenarios. We measure the
precision and recall of the synthesized grammars, as well as the
benefits of the synthesized grammars in grammar-based fuzz test-
ing. Our evaluation results show that REINAM outperforms Glade
in terms of precision, recall, and fuzz testing coverage for most
of the benchmarks. In one of our benchmarks‚Äînamely, the input
grammar encoding regular expressions that are accepted by the
GNU Grep [ 7]‚ÄîREINAM improves recall from 0.02 to 1.0, indicating
489REINAM: Reinforcement Learning for Input-Grammar Inference ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia
ùëÜ‚Ä≤($ùëáùëé‚Ä≤)$1.00.10.71.00.4Agent: The PCFG
Environment: The target programAction: ùëé(The choice of production rule to apply in each stepReward: ùëüWhether the program accepts or rejects the constructed input
Figure 1: Formulation of grammar synthesis as a reinforce-
ment learning problem.
that the grammar inferred by REINAM actually covers the entire
program input space.1
In summary, this paper makes the following main contributions:
‚Ä¢A novel formulation of grammar synthesis as a reinforce-
ment learning problem with a PCFG as the agent, sampled
inputs as the actions, and input acceptance as the rewards.
‚Ä¢A corresponding learning algorithm, called REINAM, which
iteratively chooses a generalization operator to apply to the
current PCFG, adjusts the probabilities of the PCFG using
reinforcement learning, and then retains only general and
accurate production rules.
‚Ä¢An evaluation of on 11 real-world benchmarks for showing
that REINAM effectively synthesizes program input gram-
mars, and furthermore improves the effectiveness of fuzz
testing.
2 BACKGROUND
Grammar synthesis. We first describe Glade [ 14], an existing
state-of-the-art approach for synthesizing a program input gram-
mar from a given set of seed inputs specified by the users for a
program that includes input validation. Glade requires only black-
box access to the program and uses the program as an oracle in
order to determine whether a given input is valid. In particular,
Glade iteratively generates new candidate grammars by applying
generalization operators (from a predefined set) to the given seed
inputs. Glade then checks the correctness of these candidate gram-
mars by generating new inputs from the candidate grammars and
seeing whether the new inputs are accepted by the target program.
Glade consists of two steps (which they call phases). The first step
learns a regular grammar by applying generalization operators such
asrepetition andalternation on the given seed inputs. The second
step transforms the learned regular grammar into a context-free
grammar by applying merging operators. Between the first and
second steps, the character generalization operator is applied to
generalize characters. The following includes more details:
1For conciseness, we describe the key features of our approach in this paper and
relegate implementation details to an appendix available on our project website: https:
//sites.google.com/site/reinamlearning/.‚Ä¢Alternation: Decompose a substring in the grammar (inside
a repetition) and form an alternation. For example, ‚Äú (ab)‚àó‚Äù
can be generalized to (a|b)‚àó.
‚Ä¢Repetition: Repeat a given substring in the grammar. For
example, ‚Äú a‚Äù can be generalized to ‚Äú a(a)‚àó‚Äù.
‚Ä¢Merging: Equate two non-terminal symbols in the context-
free grammar translated from the regular grammar resulted
from Step 1. For example, suppose we have a CFG S‚Üí
(‚Ä≤a‚Ä≤T‚Ä≤a‚Ä≤)‚àó;T‚Üí(‚Ä≤b‚Ä≤|‚Ä≤c‚Ä≤)‚àó.2We can merge SandT
by substituting Twith S, so the grammar becomes S‚Üí
(‚Ä≤a‚Ä≤S‚Ä≤a‚Ä≤)‚àó;S‚Üí(‚Ä≤b‚Ä≤|‚Ä≤c‚Ä≤)‚àó.
‚Ä¢Character generalization : Allow certain terminal symbols
(e.g.,‚Ä≤a‚Ä≤) to be substituted for other ones ( e.g.,‚Ä≤b‚Ä≤,‚Ä≤c‚Ä≤,...).
Glade performs a set of checks to avoid overgeneralization. In
particular, Glade constructs a set Chk of strings such that each
Œ±‚ààChk uses the candidate production rule added by the general-
ization operator in its derivation. Then, Glade executes the program
on eachŒ±‚ààChk and determines whether it is accepted or rejected.
IfanyŒ±is rejected, then Glade rejects this generalization. This
mechanism is designed to enforce the ‚Äúno overgeneralization al-
lowed‚Äù strategy. However, generalization can still occur, because
it could be the case that all Œ±‚ààChk are accepted, but there exists
other inputs generated by the grammar that would be rejected by
the program. Indeed, in our evaluation, we find that Glade occa-
sionally overgeneralizes.
Probabilistic context-free grammar (PCFG). A PCFG is a
CFG augmented with a probabilistic distribution. In particular, a
PCFG Gis a tuple G=(M,T,R,S,P), where Mis the set of non-
terminal symbols, Tis the set of terminal symbols, Ris the set
of production rules, Sis the start symbol, and Pis a set of the
probability distributions over production rules. More precisely, for
each non-terminal symbol A, if there are kdifferent production rules
r1, ...,rkwith Aas the left-hand side, then PA(i)is the probability
of choosing production rule ri. These probabilities should satisfy√çk
i=1PA(i)=1andPA(i)‚â•0.
3 MOTIVATING EXAMPLE
A key shortcoming of Glade is its reliance on the ‚Äúno overgener-
alization allowed‚Äù condition. In this section, we give an example
showing why this design choice can be problematic. In particular,
we find that as a consequence of this design choice, the Grep pro-
gram used in the evaluation of Glade can achieve only very low
coverage of the valid input space [14].
Figure 2 shows that the grammar of the Grep program consists of
many special characters ( nbchar andnpchar ). These special charac-
ters not only form the basic building blocks for the grammar ( char ),
but also serve as the special control characters in the grammar (see
the production rule of sin–¥le). Therefore, in Step 1 of Glade ( i.e.,
generalization to a regular language), the generalization process
can fail. For example, suppose the seed input is ‚Äú [‚àßa]‚Äù; then, the
generalization operators in Step 1 are unable to cover the grammar
‚Äú[=(a)‚àó=]‚Äù (here,‚Ä≤=‚Ä≤can also be‚Ä≤.‚Ä≤or‚Ä≤:‚Ä≤since they appear in
the same production rule). The best that we can do is to apply the
repetition operator, in which case the grammar is generalized to
‚Äú[‚àß(a)‚àó]‚Äù. Next, at the intermediate step of character generalization
step, we consider the generalization ‚Äú [(‚àß|=)(a)‚àó]‚Äù, but find that
2Note that this CFG is not in normal form.
490ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia Z. Wu, E. Johnson, W. Yang, O. Bastani, D. Song, J. Peng, and T. Xie
–¥enchar‚Üí‚Ä≤0‚Ä≤|‚Ä≤A‚Ä≤|‚Ä≤a‚Ä≤
nbchar‚Üí–¥enchar|s|t|‚Ä≤!‚Ä≤|‚Ä≤‚Äù‚Ä≤|‚Ä≤#‚Ä≤|‚Ä≤$‚Ä≤|‚Ä≤%‚Ä≤|‚Ä≤&‚Ä≤|‚Ä≤‚Ä≤‚Ä≤
|‚Ä≤,‚Ä≤|‚Ä≤.‚Ä≤|‚Ä≤/‚Ä≤|‚Ä≤:‚Ä≤|‚Ä≤;‚Ä≤|‚Ä≤<‚Ä≤|‚Ä≤=‚Ä≤|‚Ä≤>‚Ä≤
|‚Ä≤@‚Ä≤|‚Ä≤_‚Ä≤|‚Ä≤8‚Ä≤|‚Ä≤‚àº‚Ä≤
...
sin–¥le‚Üísin–¥le‚Ä≤[‚Ä≤tok‚Ä≤]‚Ä≤|sin–¥le‚Ä≤[‚Ä≤‚Ä≤‚àß‚Ä≤tok‚Ä≤]‚Ä≤
|sin–¥le‚Ä≤[‚Ä≤‚Ä≤=‚Ä≤tok‚Ä≤=‚Ä≤ ‚Ä≤]‚Ä≤|sin–¥le‚Ä≤[‚Ä≤‚Ä≤.‚Ä≤tok‚Ä≤.‚Ä≤‚Ä≤]‚Ä≤
|sin–¥le‚Ä≤[‚Ä≤‚Ä≤:‚Ä≤tok‚Ä≤:‚Ä≤ ‚Ä≤]‚Ä≤
re–¥ex‚Üísin–¥le|re–¥ex sin–¥le
re–¥ex‚Üíre–¥ex‚Ä≤\‚Ä≤‚Ä≤(‚Ä≤re–¥ex‚Ä≤\‚Ä≤‚Ä≤)‚Ä≤
Figure 2: The ground-truth grammar of Grep (some rules are
omitted).
this generalization is invalid. Thus, Glade is unable to insert the
‚Ä≤=‚Ä≤both before and after ‚Äú (a)‚àó‚Äù to generalize the grammar to cover
‚Äú[=(a)‚àó=]‚Äù.
This example demonstrates two shorcomings of Glade. First, it
shows that Glade is very sensitive to the given seed inputs. For
example, Glade will not cover ‚Äú [=(a)‚àó=]‚Äù unless the user provides
a seed input that includes an expression of the form ‚Äú [=a=]‚Äù. In
the evaluation of Glade‚Äôs grammar generation, the authors use 50
seed inputs that are randomly generated from the ideal grammar.
However, in a real world scenario, the developers using Glade most
likely do not know the ideal grammar‚Äîotherwise, they would not
need to use Glade. Therefore, we can expect that the quality of
seed inputs will be far worse than those sampled from the ideal
grammar.
Additionally, the grammar of Grep queries is very coarse in the
sense that special characters can be used as both the content of
queries as well as control characters in the queries. This property
makes Grep challenging for Glade, since the seed inputs must cover
the behaviors of all the special characters. Thus, randomly gener-
ated seed inputs are not enough for Glade to synthesize the desired
grammar.
Since the quality of seed inputs greatly affects the performance of
Glade, we propose to use test generation tools such as Pex [ 38,40]
toautomatically generate seed inputs. Pex is a white-box automated
testing tool based on dynamic symbolic execution. It explores pos-
sible program execution paths to generate test inputs that cover as
many parts as possible of the program. Our results show that we
substantially increase both the precision and the recall on the Grep
benchmark with the help of Pex.
The second shortcoming is that Glade works very hard to avoid
overgeneralizing; even when overgeneralization occurs, it is due
to a shortcoming in the checks used to detect overgeneralization
rather than a deliberate choice. In our example, to generalize ‚Äú [.a.]‚Äù
to a grammar that covers ‚Äú [=a=]‚Äù, Glade would have to perform
character generalization in two places simultaneously ( i.e.,at each
of the two ‚Äò =‚Äô characters). If we instead allow for overgeneralization,
then we can keep the intermediate grammar ‚Äú ([=a(=|.)])‚àó‚Äù after
applying character generalization to the second ‚Äú =‚Äù. Note that this
grammar can generate the input ‚Äú [=a.]‚Äù being rejected by Grep,
so Glade does not retain this generalization. However, if we sub-
sequently apply another character generalization to the first‚Ä≤=‚Ä≤,then grammar can be transformed into ‚Äú ([(=|.)a(=|.)])‚àó‚Äù, which
increases coverage since it now covers ‚Äú [=a=]‚Äù. Thus, Glade‚Äôs
strategy of ‚Äúno overgeneralizations allowed‚Äù makes performing this
pair of generalization steps impossible.
In contrast, REINAM represents the grammar as a PCFG and
uses reinforcement learning to adjust the probabilities of this PCFG
to improve performance.3Thus, REINAM can retain some amount
of overgeneralization at each step, enabling it to achieve larger
coverage while sacrificing only a small amount of accuracy. This
ability is even more powerful if the ideal grammar is not context-
free. In this case, REINAM would learn an overgeneralized grammar
that can achieve high coverage, whereas Glade would frequently
fail to generalize due to non-context-free constraints on valid inputs
that it is unable to capture.
Finally, the third shortcoming of Glade is that the generalization
operators are divided rigidly into two steps‚Äî i.e.,repetition and
alternation in Step 1, and merging in Step 2. Glade performs only
the repetition and alternation in Step 1 and transforms the resulting
regular expression into a CFG in Step 2. However, the repetition
and alternation are still viable and often needed in Step 2.
For example, consider Figure 3. Suppose that the left-most gram-
mar is an intermediate state during execution of Step 2 of Glade.
The middle and right grammar are constructed by first applying an
alternation operator that changes the production of Tform P Qto
P|Q(left to middle), and then applying a merging operator on the
symbols TandS. However, in Glade, such a generalization is not
possible since repetition and alternation are not performed in Step
2. In contrast, REINAM combines the two steps of Glade‚ÄîREINAM
can perform any of the different kinds of generalization steps on
the current CFG.
4 REINAM
At a high level, REINAM takes as input the target program for which
we want to synthesize an input grammar, and then proceeds in two
phases. In Phase 1, REINAM generates high-variety, high-quality
seed inputs using automatic test generation ( e.g., the symbolic
execution engine Pex [ 38]), and then uses an existing grammar
synthesizer ( e.g.,Glade) to synthesize an initial CFG. In Phase 2,
REINAM converts the CFG from Phase 1 to a PCFG, and then
uses reinforcement learning to refine this PCFG. An overview of
REINAM is shown in Figure 4.
Reinforcement learning consists of iteratively performing five
steps: (i) apply generalization operators, (ii) sample strings from the
PCFG, (iii) calculating the reward for each production rule, (iv) ad-
justing the probability distribution based on the calculated reward,
and (v) removing low-probability rules. Note that the generalization
operators applied to modify the current PCFG can be customized for
different grammars, including operators beyond the ones described
in this paper, thereby bringing flexibility to our approach.
4.1 Phase 1: Generating Seed Inputs using Pex
Phase 1 first runs a symbolic execution engine (we use Pex [ 38]) on
the assembly code of the target program. Next, it runs a grammar
synthesizer (we use Glade) using the output of the engine as the
3Note that Glade uses a PCFG to generate new inputs only for fuzzing, not for synthesis.
491REINAM: Reinforcement Learning for Input-Grammar Inference ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia
S‚Üí‚Ä≤a‚Ä≤T‚Ä≤a‚Ä≤
T‚ÜíP Q T|P Q
P‚Üí...
Q‚Üí...=‚áíS‚Üí‚Ä≤a‚Ä≤T‚Ä≤a‚Ä≤
T‚ÜíP T|Q T|P|Q
P‚Üí...
Q‚Üí...
=‚áíS‚Üí‚Ä≤a‚Ä≤S‚Ä≤a‚Ä≤
S‚ÜíP|Q|P S|Q S
P‚Üí...
Q‚Üí...
Figure 3: An example of an initial grammar (top left), and
two generalization steps (top right, bottom).
Phase 1Phase 2Source Code
Symbolic 
Execution 
Engine
Seed Inputs
Language 
Inference 
Algorithm
Initial CFG
Initial PCFG
 Generalization Mutated PCFG
Input Sampling
Reward 
Calculation
Probability 
AdjustmentRefined PCFG
Result CFG
Figure 4: Workflow of REINAM.
seed inputs. Pex performs path-bounded dynamic symbolic execu-
tion by repeatedly executing the program to generate path-based
constraints and using an SMT (satisfiability modulo theory) solver
to solve these constraints to obtain the program inputs that would
lead to different execution paths. As discussed in Section 3, the
quality of a set of seed inputs is primarily determined by the var-
ious ‚Äúcategories‚Äù of inputs that the set can cover, corresponding
to inputs that achieve high code coverage. Test generation tools
such as Pex are designed to generate inputs that achieve high code
coverage.
4.2 Phase 2: Generalizing PCFGs via
Reinforcement Learning
Initializing the PCFG. Phase 2 first converts the CFG from Phase
1 to a PCFG. For each nonterminal S, we count the number kof
production rules that expand S(i.e.,Sis on the left-hand side of the
rule); then, we assign each of these rules probability1
k.
Reinforcement Learning. Reinforcement learning (RL) is an
area of machine learning inspired by behavioral psychology. The
basic idea is that software agents take actions in the environment
to maximize a given metric called the reward . In our context of the
grammar synthesis problem, these concepts are
‚Ä¢Agent: The PCFG.
‚Ä¢Environment: The target program.
‚Ä¢State: A partial derivation of the PCFG ( i.e.,a sequence Œ±
consisting of both terminal and non-terminal symbols).‚Ä¢Action: The choice of the production rule to apply to one
non-terminal symbol in Œ±in current state.
‚Ä¢Reward: Whether the constructed input is accepted by the
target program‚Äî i.e.,1if it is accepted and 0if it is rejected.
In other words, the agent is taking actions that choose producitons
used to construct a program input. For the PCFG agent, the pro-
ductions are chosen randomly according to the PCFG probabilities;
we describe this process in detail below. The reward is whether the
input constructed by the agent is accepted by the program.
The goal of RL is to optimize parameters of the agent so it takes
actions that maximize the reward. The purpose in our context is
to increase the quality ( i.e.,precision and recall) of the grammar.
However, existing RL algorithms are designed to maximize real-
valued parameters [ 30]. In contrast, we may also need to modify the
structure of the PCFG itself ( i.e.,which productions are available). To
do so, we interleave a traditional RL algorithm with the application
of generalization operators to the PCFG. In particular, we iteratively
perform the following: (i) apply a generalization operator, (ii) run
a traditional RL algorithm‚Äîin particular, policy gradients [ 37]‚Äîto
adjust the PCFG probabilities, and (iii) remove any production rule
with probability lower than a fixed threshold from the PCFG.
Generalization operators. We use four kinds of generalization
operators. First, we use the character generalization operator de-
scribed in Section 2, adapted to work for PCFGs. We assign the
probability of1
#current charactersto the newly added character and
reduce other probabilities proportionally.
Second, the repetition operator changes part of the grammar
from ‚Äú p‚Äù to ‚Äú p(p)‚àó‚Äù. In particular, the operator picks a production
rule and tries to repeat the symbols on the right-hand side‚Äî i.e.,for
the rule S‚ÜíP Q, we would try two generalizations: (i) add the
ruleS‚ÜíP P‚àóQ, and (ii) add the rule S‚ÜíP Q Q‚àó.
Third, the alternation operator changes part of the grammar
from ‚Äú pq‚Äù to ‚Äú p|q‚Äù. In particular, the operator picks a production
rule, randomly decomposes the right-hand side of the rule into two
parts, and replaces the right-hand side with an alternation of these
two parts‚Äî e.g.,for the rule S‚ÜíP Q‚Ä≤a‚Ä≤, it may add new rules
S‚ÜíP1 ‚Äòa‚Ä≤andP1‚ÜíP|Q. The probability of the original rule
S‚ÜíP Q‚Ä≤a‚Ä≤is split equally between S‚ÜíP Q‚Äòa‚Ä≤andS‚ÜíP1 ‚Äòa‚Ä≤,
and the probability of P1‚ÜíP|Qis1.
Fourth, the merging operator merges two nonterminal symbols
by substituting all usage of one symbol for another. In particular,
to merge PandQ, we add rules P‚ÜíQandQ‚ÜíP. We assign
probability1
#production rules of PtoP‚ÜíQand reduce the other
probabilities proportionally, and similarly for Q‚ÜíP.
These generalization operators have two advantages: (i) they are
already used by Glade (and other grammar synthesis algorithms use
similar operators [22, 26]), and (ii) they are simple to implement.
Constructing inputs using a PCFG. We perform the following
steps to inputs from our PCFG:
‚Ä¢InitializeŒ±=S(where Sis the start symbol of the PCFG).
‚Ä¢WhileŒ±contains non-terminal symbols, uniformly randomly
choose a random non-terminal AinŒ±, and then randomly
apply a production rule to Abased on the PCFG probabilities.
‚Ä¢ReturnŒ±=Œ±1...Œ±k(now, each Œ±iis a terminal symbol).
After sampling an input, we execute the program on this input and
record whether the program accepts or rejects the input.
492ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia Z. Wu, E. Johnson, W. Yang, O. Bastani, D. Song, J. Peng, and T. Xie
Probability adjustment. Recall that in our PCFG, each proba-
bility quantifies the correctness of the corresponding production
rule‚Äî i.e.,whether this rule exists in the ideal grammar. Unlike
Glade, we allow occasional overgeneralization. In Glade, if any
input generated using a new production rule is rejected by the
program, then that rule is rejected. In contrast, our algorithm does
not necessarily reject a rule if the rule fails a check as long as it
produces at least one input that is accepted. In particular, we use re-
inforcement learning to automatically adjust the probability of each
production rule. To do so, we track which new production rules
are used to construct each input. Then, we define the following
aggregate reward for each new production rule ri:
reward(ri)=#accepted inputs that use ri
#inputs that use ri
We use the policy gradient algorithm to tune the PCFG probabili-
ties [ 37]. We consider different non-terminal symbols separately
since the probability of a production rule is related only to those of
other production rules for the same non-terminal symbol. Consider
a non-terminal symbol Aand the probability distribution for its
productions is Œ∏‚Äîi.e.,Ahaskproduction rules rA
1, ...,rA
k, and the
probability for rule rA
iisŒ∏(rA
i). The policy gradient [ 37] update
gives us the following adjusted probabilities Œ∏‚Ä≤:
Œ∏‚Ä≤=Œ∏+Œ∑¬∑‚àáŒ∏logœÄŒ∏(st,at)¬∑v,
whereœÄŒ∏(st,at)is the probability that the agent chooses action at
in state st,Œ∑is a fixed learning rate, and vis the reward. In our
setting, we have
Œ∏‚Ä≤(rA
i)=Œ∏(rA
i)+Œ∑¬∑‚àáŒ∏log(Œ∏(rA
i))¬∑reward(rA
i)
=Œ∏(rA
i)+Œ∑¬∑reward(rA
i)
Œ∏(rA
i)(1)
Finally, we normalize the new probability distribution Œ∏‚Ä≤(rA
i)so it
sums to 1.4After each application of a generalization operator, we
iteratively sample new inputs and run the policy gradient update
until the PCFG probabilities converge. We use the convergence
threshold1
10¬∑(#production rules of A)‚Äîi.e.,we terminate if no probabil-
ity changes by more than this threshold.
Rule removal. Finally, after adjusting the probabilities, our al-
gorithm removes production rules with probability lower than the
convergence threshold (or equivalently, we set their probabilities
to zero). This step plays the role of undoing failed generalization
operators, and also avoids wasting computation time on adjusting
the probabilities of incorrect production rules.
4.3 Discussion
Negative probability adjustments. Note that in the probability
adjustment formula (1), the gradientreward(rA
i)
Œ∏(rA
i)is non-negative.
Thus, a potential concern is that the gradient can only ever increase
Œ∏(rA
i). The reason why this is not an issue is that because after
taking a gradient step, we normalize the updated probabilities Œ∏‚Ä≤so
that√ç
iŒ∏‚Ä≤(rA
i)=1. In particular, if a production rule rA
iachieves
higher reward reward(rA
i), then the gradient computed using for-
mula (1) is larger, so the probability increases‚Äî i.e.,Œ∏‚Ä≤(rA
i)>Œ∏(rA
i).
4This normalization can formally be derived using Lagrange multipliers.Conversely, if rA
iachieves lower reward, then the probability be-
comes decreases‚Äî i.e.,Œ∏‚Ä≤(rA
i)<Œ∏(rA
i).
Time complexity. We can compute the time complexity of our
approach by estimating the number of sampling and probability
adjustment steps needed for the convergence. Suppose the threshold
used by us to determine stability of the probability is œµ(i.e.,if
no probability changes by more than œµ, then we terminate this
round of RL and start the next generalization step), and assume that
the set of sampled inputs produces the same reward each time.5
Then, the gradient difference each step is Œ∑¬∑reward(rA
i)
Œ∏(rA
i), whereŒ∑¬∑
reward(rA
i)remains constant by assumption. Thus, Œ∏(rA
i)converges
proportionally to the ratio of accepted strings among all strings
using that rule. The number of sampling and adjustment steps for
convergence is approximately O(1
Œ∑¬∑œµ), which is constant.
Therefore, the (expected) time complexity of our approach is
O(n¬∑m¬∑RL(n)), where nis the number of symbols in the grammar,
RL(n)is the time needed for one iteration of RL, and mis the total
number of possible production rules. In particular, O(n¬∑m)is an
upper bound on the number of generalizations that may be tried
(while generalization operators can introduce new production rules,
but we apply only generalization to the initial production rules set).
Also, RL(n)equals the time used for sampling strings and executing
the program on these input strings. The time used for probability
adjustment is negligible. By our previous discussion, each gen-
eralization takes O
1
Œ∑¬∑œµ
rounds of sampling and adjustment, so
RL(n)=O(total #strings sampled)¬∑(average execution time )
Œ∑¬∑œµ
. We discuss
the choice of the number of strings sampled in our appendix avail-
able on our project website.
PCFG probabilities. We note that the PCFG probability of a
production rule represents how likely a resulting string would
be accepted by the program if we apply that rule, not the actual
frequency with which the production rule used to construct real-
world inputs. The reason is that we do not have any information
about the distribution of real-world program inputs. As mentioned
above, we initially set the probability of each production rule rA
ifor
a fixed non-terminal symbol Ato be constant. Afterwards, we are
adjusting the probabilities such that they converge proportionally
to the ratio of accepted strings among all strings using a given
rule. We then eliminate production rules with small probability
(corresponding to unreasonable overgeneralizations).
5 EMPIRICAL EVALUATION
To evaluate the effectiveness of REINAM and the contribution of
each phase to the effectiveness, we conduct an empirical evalua-
tion on 11 benchmarks. We seek to answer the following research
questions:
‚Ä¢RQ1 : How effective is the final grammar synthesized by
REINAM in terms of precision and recall?
‚Ä¢RQ2 : How effective is the final grammar synthesized by
REINAM in terms of improving fuzz testing?
‚Ä¢RQ3 : How do the two phases of REINAM contribute to the
grammar‚Äôs precision/recall and performance in fuzz testing?
5This assumption may not be true in practice due to random noise; we make the
assumption to simplify our analysis of convergence.
493REINAM: Reinforcement Learning for Input-Grammar Inference ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia
‚Ä¢RQ4 : What is the execution time of REINAM?
In RQ1, we compare REINAM with Glade in terms of the pre-
cision and recall of the final synthesized grammar. We compute
the two metrics using the manually written ideal grammar for the
benchmarks as ground truth. In RQ2, we evaluate the capability of
REINAM to learn a grammar for a fuzz testing task. We feed the
grammar synthesized by REINAM to a grammar-based fuzzer to
perform fuzz testing on programs. We compare our results with
Glade and an industrial fuzzer. In RQ3, we compare the grammar
after Phase 1 of our algorithm to the final grammar after Phase 2 of
our algorithm. We compare the difference both in precision/recall
and in fuzz testing coverage. In RQ4, we measure the time used by
each phase of REINAM.
5.1 Benchmarks
We include the benchmarks of manually written grammars from
the Glade evaluation [14]:
‚Ä¢A grammar used to match URLs [ 3]. We separate this gram-
mar into four benchmarks based on the protocols ( i.e.,‚Äúhttp‚Äù,
‚Äúhttps‚Äù, ‚Äúmailto‚Äù, and ‚Äúnntp‚Äù). We test whether REINAM can
infer a complete grammar starting from seed inputs includ-
ing only one of the four protocols.
‚Ä¢A grammar for the regular expressions accepted as input by
GNU Grep [7]. This grammar is shown in Figure 2.
‚Ä¢A grammar for a simple Lisp parser [ 2], including support
for quoted strings and comments.
‚Ä¢A grammar for an XML parser [ 5], including all XML con-
structs except that only a fixed number of tags are included
(to ensure that the grammar is context-free). We use the .NET
XML library and it has an alphabet of tags to choose from.
Neither Glade nor REINAM are provided with the alphabet.
‚Ä¢A grammar for a Cascading Style Sheets (CSS) parser [ 4];
CSS is a language used to describe the presentation of a
document written in a markup language such as HTML.
In addition to the Glade benchmarks, we include a grammar used
to match IPv4 and IPv6 addresses, and two benchmarks generated
from ANTLR [ 6], a widely used parser generator. We use these
two benchmarks to evaluate the performance of REINAM on syn-
thesizing a grammar for a program generated by an automatic
parser generator. We select the following grammars (from the offi-
cial website of ANTLR [ 6]) that have less than 100 non-terminal
symbols:
‚Ä¢A grammar used to match CSV files [8].
‚Ä¢A grammar used to describe simple first-order logic (FOL)
formulas [9].
The data and benchmarks of our evaluation are available on our
project website.
5.2 Evaluation Setup
Precision and recall. Precision measures the probability that a
randomly generated string from our synthesized lanugage Lis ac-
cepted by the target program (i.e., included in the ideal language
L‚àó), and recall measures the probability that a randomly gener-
ated string from the ideal language L‚àóbelongs to our synthesized
language L. In other words, the precision of REINAM indicates
whether our synthesized language Loverapproximates the ideallanguage L‚àó, and the recall indicates whether Lunderapproximates
L‚àó. We calculate precision as|Eprec‚à©L‚àó|
|Eprec|, where Eprecis a set of
1000 strings randomly sampled from L, and we calculate recall as
|Erec‚à©L|
|Erec|, where Erecis a set of 1000 strings randomly sampled from
a reference grammar used to specify L‚àó.
Generation of seed inputs. We use Pex‚Äôs dynamic symbolic
execution capabilities to generate input strings that are accepted
by the parser, and then use these strings as seed inputs to Glade.
Sampling from PCFG. We sample a string matching a nonter-
minal Ain the CFG Gas follows:
‚Ä¢Randomly select a production A‚ÜíA1...AnforA.
‚Ä¢For each i‚àà{1, ...,n}, ifAiis a nonterminal, then recursively
sample a string matching Ai, and if Aiis a terminal, then
return Ai.
For simplicity, we use a uniform distribution over productions when
sampling strings to measure precision and recall. In contrast, our
RL algorithm samples strings using the probabilities in the PCFG
G. Here, we discard the probabilities since they do not necessarily
capture the true distribution of inputs.
Programs used for evaluation. Because Pex requires source
code to perform dynamic symbolic execution and generate program
inputs, we write C# programs to parse the grammars described in
Section 5.1. We use parsers in the .NET system library to parse
the grammars of URLs, IP addresses, regular expressions, and XML
documents. We also test against an open-source Lisp parser and
an open-source CSS parser. The programs for the two ANTLR
grammars are generated by using ANTLR in C# mode.
Fuzz testing. Fuzz testing (or fuzzing) is an automated software
testing technique. An effective fuzzer generates ‚Äúsufficiently valid‚Äù
inputs and then monitors the execution of the program on these
inputs. One of the purposes of using fuzz testing is to observe the
behavior of the target program under various inputs, so we want
the fuzzer to achieve high code coverage.
Grammar-based fuzzer. Both Glade and REINAM synthesize a
CFG Lthat approximates the ideal language L‚àó. We use a grammar-
based fuzzer to leverage the synthesized grammar to improve
fuzzing. The fuzzer is similar to the step of input sampling described
earlier. We randomly sample 1000 strings from the grammar, using
a uniform distribution over productions. As before, for REINAM,
we use a uniform distribution instead of using the PCFG probabili-
ties since these probabilities have no relation to the distribution of
real inputs. Then, we execute the program on the sampled inputs
and use Visual Studio to measure the code coverage as the number
of blocks covered. We use the code coverage achieved using the
manually written ideal grammar as an upper bound. We compare
our fuzzer against a state-of-the-art fuzzer that does not employ
grammar-based fuzzing, Radamsa [ 10]. Radamsa combines random
bit-flipping with domain-independent heuristics designed to test
edge cases to create high quality mutation. Note that the Learn &
Fuzz [ 21] tool is not available to us, so we cannot compare against
their approach.
5.3 RQ1: Precision and Recall
As shown in Table 1, REINAM performs well across all benchmarks.
The row ‚ÄúLI‚Äù shows the result of the grammar synthesized by solely
494ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia Z. Wu, E. Johnson, W. Yang, O. Bastani, D. Song, J. Peng, and T. Xie
Table 1: Precision (P) and Recall (R).
Benchmarkhttp https nntp mailto ip css xml grep lisp csv fol
P R P R P R P R P R P R P R P R P R P R P R
LI 0.79 0.06 0.77 0.07 0.80 0.05 0.99 0.13 1.00 0.50 0.99 1.00 0.32 1.00 0.79 0.02 0.65 1.00 1.00 0.24 0.90 0.30
LI+SE 0.96 0.50 0.96 0.64 0.97 0.49 0.97 0.42 0.91 1.00 0.99 1.00 0.56 1.00 0.98 0.40 0.91 1.00 1.00 0.40 0.88 0.45
LI+SE+RL 0.87 0.77 0.91 0.70 0.95 0.82 0.93 0.77 0.82 1.00 0.86 1.00 0.50 1.00 0.78 1.00 0.73 1.00 0.94 1.00 0.75 0.45
Figure 5: Code coverage achieved by different fuzzers (as per-
centages)
Table 2: Coverage (numbers are #basic blocks covered in
code).
Benchmark http https nntp mailto ip lisp css xml grep csv fol
Radamsa 1579 1558 1461 1157 2272 131 737 1349 1819 82 216
LI 1625 1623 1618 1691 2241 175 1819 1349 1819 88 348
LI+SE 1750 1796 1673 1829 2318 176 1642 1349 1819 88 353
LI+SE+RL 1784 1811 1716 1863 2325 211 1809 1349 1819 92 353
Total 2164 2164 2164 2164 2421 211 1948 1349 1819 111 414
LI(Language Inference algorithm): results of Glade only
LI+SE (Symbolic Execution engine): results of REINAM Phase 1
LI+SE+RL (Reinforcement Learning): results of REINAM Phase 1+2
Radamsa : code coverage achieved by Radamsa
running Glade, while the row ‚ÄúLI+SE+RL‚Äù shows the result of the
final grammar synthesized by REINAM. On average, the precision
stays almost the same, with a less than 1% change (-0.36% on av-
erage), while the recall improves drastically by 49.2%. This rate is
calculated by subtracting the number on the third row by the first
row and taking the average across benchmarks. On all of our 11
benchmarks, REINAM outperforms Glade in recall without losing
precision. In the three benchmarks ‚Äúcss‚Äù, ‚Äúxml‚Äù, and ‚Äúlisp‚Äù, Glade
already achieves 1.0 recall, indicating that the grammar synthe-
sized by Glade already covers the entire input space of the three
programs. For these benchmarks, REINAM cannot further improve
recall, but manages to keep the perfect score as expected.
As mentioned in Section 5.1, we intentionally split the ‚Äúurl‚Äù gram-
mar into four benchmarks ‚Äúhttp‚Äù, ‚Äúhttps‚Äù, ‚Äúnntp‚Äù, and ‚Äúmailto‚Äù. For
these four benchmarks, we see a substantial increase in recall. Glade
performs poorly, with recall lower than 0.15 on all four benchmarks,
due to the limitation of Glade that the quality of the synthesized
grammar highly depends on the quality of the seed inputs. Since
Glade starts with input strings starting with ‚Äúhttp‚Äù (‚Äúhttps‚Äù, ‚Äúnntp‚Äù,
or ‚Äúmailto‚Äù in other three benchmarks) as the seed inputs, Glade
is not able to explore other possible URL protocols. Meanwhile,REINAM leverages the help of Pex in Phase 1 in order to generate
a set of seed inputs for achieving higher coverage. Therefore, the
final synthesized grammar of REINAM for these four benchmarks
has recall above 0.70 without substantial loss of precision. The ‚Äúip‚Äù
benchmark is similar. Glade starts with the seed inputs in IPv4, is
unable to generalize the grammar to cover the IPv6 case.
The performance on benchmarks ‚Äúgrep‚Äù and ‚Äúcsv‚Äù is similar. We
have already analyzed why Glade achieves only 0.02 recall on ‚Äúgrep‚Äù
in Section 3. We can see that REINAM gets 1.0 recall‚Äîi.e. all possible
strings that can be accepted by the program are covered by the final
synthesized grammar of REINAM. Given that the precision is similar
(0.78 vs. 0.79), the improvement is substantial. The ‚Äúcsv‚Äù benchmark
is similar to the ‚Äúgrep‚Äù benchmark in the sense that it includes many
characters with special behaviors. In particular, since the grammar
describes all possible CSV files, there are many special characters
that can be in a data field, and several special characters serve
as both separating symbols and content symbols. As discussed in
Section 3, this property makes the benchmark challenging for Glade
since the seed inputs must cover all of these behaviors. Therefore,
REINAM outperforms Glade by improving recall from 0.24 to 1.0.
The case for the ‚Äúfol‚Äù benchmark is unique. Although REINAM
improves recall from 0.3 to 0.45, it decreases precision from 0.90
to 0.75. This benchmark is the only one for which REINAM can-
not achieve a recall above 0.5. Intuitively, first-order logic (FOL)
formulas are more complex to write. For example, to write a valid
HTTP address, it only needs to start with ‚Äúhttp://‚Äù and have a ‚Äú.‚Äù
between the site and domain segments. However, FOL formulas are
much more strictly formatted. Intuitively, the ideal language of FOL
formulas is quite sparse, indicating that if we consider the entire
input space of a FOL parser, it would be much smaller than the
input space of a URL parser. Therefore, the generalization operators
in REINAM may have difficulty generalizing to the complicated
structure of the FOL grammar.
5.4 RQ2: Application in Fuzzers
In the fuzz testing experiment, we can see from Table 2 and Figure 5
that REINAM greatly improves code coverage. If we compare the
rows ‚ÄúRadamsa‚Äù, ‚ÄúLI‚Äù, and ‚ÄúLI+SE+RL‚Äù, we find that on average,
REINAM improves coverage by 18.4% compared to the Radamsa
fuzzer and by 4.9% compared to Glade‚Äôs grammar-based fuzzer.
In the benchmarks ‚Äúxml‚Äù and ‚Äúgrep‚Äù, all fuzzers achieve perfect
code coverage. Interestingly, the grammar synthesized by Glade
(‚ÄúLI‚Äù) achieves only 0.02 recall in Table 1, but the fuzzer using this
grammar still achieves perfect code coverage. The reason is that
different strings generated from the same grammar can share same
or similar execution paths that would cover similar basic blocks in
code. Therefore, coverage is not always correlated with recall.
Ignoring the two benchmarks with perfect coverage for all ap-
proaches, REINAM outperforms the na√Øve fuzzer on all benchmarks.
495REINAM: Reinforcement Learning for Input-Grammar Inference ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia
Table 3: Execution time breakdown of REINAM (number in seconds and percentage of total time).
Benchmark http https nntp mailto ip lisp css xml grep csv fol
SE 900 (33.5%) 900 (32.3%) 900 (37.8%) 900 (35.3%) 14 (22.2%) 208 (20.5%) 900 (62.5%) 605 (32.2%) 44 (7.8%) 190 (50.5%) 307 (40.8%)
LI 624 (23.2%) 834 (29.9%) 84 (3.5%) 825 (32.3%) 14 (22.2%) 358 (35.2%) 49 (3.4%) 01 (0.0%) 167 (29.7%) 4 (1.1%) 11 (1.5%)
RL 1160 (43.2%) 1051 (37.7%) 1398 (58.7%) 827 (32.3%) 35 (55.6%) 450 (44.3%) 492 (34.1%) 1273 (67.8%) 351 (62.5%) 182 (48.4%) 435 (57.8%)
Total 2684 2785 2382 2612 63 1016 1441 1878 562 376 753
When compared to Glade‚Äôs grammar-based fuzzer, REINAM per-
forms slightly worse in the ‚Äúcss‚Äù benchmark, but outperforms Glade
on all other benchmarks. This advantage is due to the benefit that
we get from allowing overgeneralization, since REINAM produces
more rejected inputs than Glade. These rejected inputs cover parts
of source code that the accepted inputs cannot cover‚Äî e.g.,the code
used to handle invalid inputs.
Another observation is that the Radamsa fuzzer performs poorly
on the benchmarks of parenthesis matching pattern ‚Äúlisp‚Äùand ‚Äúcss‚Äù,
and also on the benchmark ‚Äúfol‚Äù. Especially for the ‚Äúcss‚Äù benchmark,
Radamsa cannot even reach 40% code coverage. The reason is that
as we discussed, the ideal grammars for ‚Äúlisp‚Äù, ‚Äúcss‚Äù, and ‚Äúfol‚Äù are
more structured than those for other benchmarks. The character-
level modifications used by a non-grammar-based fuzzer cannot
synthesize these structured strings, whereas the generalization
operators used by REINAM can infer these kinds of structures.
5.5 RQ3: Comparison of Phases 1 & 2
From Table 1, Table 2, and Figure 5, we see that Phase 1 and Phase
2 contribute differently to the improvements over Glade in terms
of precision/recall and fuzzing.
In RQ1, if we compare row ‚ÄúLI+SE‚Äù, which shows the result of
the grammar synthesized by running Glade on the Pex-generated
seed inputs (REINAM Phase 1), against row ‚ÄúLI‚Äù, which shows the
result of synthesized grammar of Glade itself, we find that Phase 1
on average improves precision by 9.2% and recall by 29.1%.
In the three parenthesis matching pattern benchmarks ‚Äúcss‚Äù,
‚Äúxml‚Äù, and ‚Äúlisp‚Äù, Glade already achieves 1.0 recall, which cannot be
improved upon. However, Phase 1 does improve precision in both
the ‚Äúxml‚Äù and ‚Äúlisp‚Äù benchmarks, and maintains the same precision
in the ‚Äúcss‚Äù benchmark. The reason is that Pex generates a set of
seed inputs with higher coverage. As described in Section 2, the
first step of Glade directly synthesizes a regular grammar that only
captures the seed inputs. Therefore, a set of seed inputs with higher
coverage would result in an initial regular grammar with higher
coverage, so fewer further generalizations are needed to infer the
ideal grammar. Since imprecision happens during generalization,
fewer generalizations result in higher precision. We observe similar
behaviors for other benchmarks, especially when the grammar
synthesized by Glade has low precision.
However, for the three benchmarks ‚Äúfol‚Äù, ‚Äúip‚Äù, and ‚Äúmailto‚Äù, we
find that the grammar synthesized by Glade already achieves perfect
or near perfect precision. In these cases, recall improves substan-
tially after Phase 1; however, precision after Phase 1 is reduced. This
reduction is a sacrifice for achieving better recall. The reason is that
a set of seed inputs with higher coverage brings more opportunities
for generalization, but also causes the check mechanism in Glade to
fail more frequently, resulting in more uncaught overgeneralization,
which thereby reduces precision.Next, in RQ1, if we compare row ‚ÄúLI+SE‚Äù, which shows the result
of the grammar synthesized by running Glade on the Pex-generated
seed inputs (REINAM Phase 1), and row ‚ÄúLI+SE+RL‚Äù, which shows
the result of the final grammar synthesized by REINAM, we find
that on average, the results after Phase 2 improve recall by 20.1%
but worsen precision by 9.5%.
In particular, we observe that precision decreases for all bench-
marks compared to the results of Phase 1. This finding is expected
since the reinforcement learning algorithm in Phase 2 allows over-
generalization to further generalize the grammar. Compared to
the ‚Äúno overgeneralization allowed‚Äù strategy used in Glade, our
allowance of overgeneralization leads to reduced precision.
Furthermore, we observe that in the benchmarks from the URL
grammar ( i.e.,‚Äúhttp‚Äù, ‚Äúhttps‚Äù, ‚Äúnntp‚Äù, and ‚Äúmailto‚Äù), and the ‚Äúgrep‚Äù
and ‚Äúcsv‚Äù benchmarks, after Phase 1, the recall is still low. The high-
est is ‚Äúhttps‚Äù with a recall of 0.64; all others are less than 0.50. The
reinforcement learning in Phase 2 further generalizes the grammar
to achieve higher coverage. Table 1 shows that among these six
benchmarks, recall improves by an average of 35.1% over Phase
1 alone. In addition, ‚Äúgrep‚Äù and ‚Äúcsv‚Äù actually achieve 1.0 recall,
indicating that the final grammar synthesized by REINAM can per-
fectly cover the entire program input space. This result suggests
that our reinforcement learning approach is effective especially in
cases when the input space is large but existing approaches can
synthesize a grammar that covers only part of the input space.
In the fuzz testing task, the average improvement in coverage
achieved by the grammar-based fuzzer using REINAM‚Äôs grammar
(row ‚ÄúLI+SE+RL‚Äù) to the coverage achieved by the grammar-based
fuzzer using the Phase 1 grammar (row ‚ÄúLI+SE‚Äù) is 3.2%. Similarly,
the average improvement of row ‚ÄúLI+SE‚Äù to row ‚ÄúLI‚Äù is 1.7%. From
the data, we can see that Phase 2 contributes more to the improve-
ment in coverage. This comparison shows the benefits of keeping
some overgeneralized rules in our RL algorithm. We see that for
benchmarks such as ‚Äúcss‚Äù, Phase 2 does not increase recall, which
remains at 1.0. However, the final synthesized grammar improves
coverage by 8.6% (1809 vs. 1642) compared to Phase 1. Thus, while
Phase 2 does not improve the coverage of the ideal language, it
improves the actual code coverage acheived using fuzz testing. This
result further demonstrates that our reinforcement learning ap-
proach is effective not only for exploring the input space of all valid
program inputs, but also for generating invalid program inputs that
cover execution paths that cannot be covered by valid inputs.
5.6 RQ4: Execution Time
We can see from Table 3 that the RL phase (Phase 2) takes an average
of 49.2% of the total execution time. Pex takes an average of 34.2%
of the time in Phase 1. The execution time of Pex can be tuned by
setting the timeout parameters. The timeout in the evaluation is
set to 900 seconds; Pex times out in five benchmarks.
496ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia Z. Wu, E. Johnson, W. Yang, O. Bastani, D. Song, J. Peng, and T. Xie
Based on the discussion in Section 4.3, the execution time of the
RL phase is primarily dependent on the size of the grammar and
the execution time of the program. The time overhead of the RL
phase is unsatisfying; however, the bottleneck in Phase 2 is waiting
for the results of executing the program on sampled strings. This
step can be parallelized by executing the program on ksampled
strings simultaneously. Currently, we execute the program on 1500
sampled strings in parallel on 4 threads. The results can be improved
by parallelizing the program execution across more threads.
6 THREATS TO VALIDITY
Threats to external validity. Our evaluation uses manually writ-
ten ideal grammars to measure precision and recall. Additionally,
the grammars in evaluation benchmarks may not be complicated
enough to reflect real-world scenarios. We attempt to combat this
threat by selecting complex grammars such as the CSS grammar.
Threats to internal validity. We randomly sample strings from
the ideal grammars for Glade to match with the increased num-
ber of seed inputs (generated by Pex) included in REINAM. The
randomly generated seed inputs for Glade may not be sufficiently
representative, and may affect Glade‚Äôs effectiveness. The technique
by which we sample from the PCFG is simpler and is potentially
more biased compared to more sophisticated techniques. Also, a
different learning rate Œ∑may affect the evaluation results. Never-
theless, we synthesize grammars using different Œ∑, and find that the
results are quite close‚Äî i.e.,less than 0.5% difference in precision
and recall and no difference in coverage.
7 RELATED WORK
Our approach draws on both existing work in grammar inference
as well as techniques used in machine learning and automated test
generation.
Inferring input grammars. H√∂schele et al. [ 22,24] propose the
AUTOGRAM approach based on dynamic taint tracing to extract
syntactic entities of a given seed input. By tracing the data flow of
particular characters of the seed input in the parsing method of the
target program, AUTOGRAM decomposes formats into meaningful
fields. However, since AUTOGRAM traces only paths taken by a
given seed input, it requires that the given set of seed inputs capture
all meaningful features of the input grammar in order to infer a
complete grammar.
Coverage-guided fuzzing. In recent years, coverage-guided
fuzzing has achieved substantial success with tools such as Amer-
ican Fuzzy Lop (AFL)6and Fairfuzz [ 26]. However, AFL does not
support fuzzing .NET executables, and does not have an appropriate
replacement that we can compare to.
Many fuzzers fail to explore paths that involve a difficult check
such as string-equality comparisons. Recent advances in grey-box
fuzzing have utilized lightweight program analysis to mitigate this
problem. Steelix [ 27] tracks progress in string-comparison checks
to incrementally discover inputs that can bypass these checks. An-
gora [ 19] solves path constraints via a searching algorithm based on
gradient descent. Other tools, such as Driller [ 36], use more heavy-
weight program analysis to bypass these checks by symbolically
executing an intermediate representation and solving constraints to
6http://lcamtuf.coredump.cx/afl/bypass these checks. REINAM is able to discover the ‚Äúconstants‚Äù in
grammar to bypass these checks in the grammar-inference process.
As we can see in the inference of the URL protocol, the discovery
of protocol names such as ‚Äúmailto‚Äù and ‚Äúhttps‚Äù is unlikely to be
discovered using grey-box approaches.
Machine learning for fuzzing. Godefroid et al. [ 21] use a re-
current neural network to learn an input model and generate inputs
for fuzzing with the Learn & Fuzz algorithm. They have recently
formalized fuzzing as a reinforcement learning problem [ 17]. Their
work does not produce an explicit grammar, but instead uses a
generative deep neural network to serve as the grammar.
PCFG inference from examples. The problem of inferring a
probabilistic context free grammar (PCFG) from a set of examples
has been studied extensively for the purpose of natural language
processing. Belz [ 15] extends standard split/merge grammar infer-
ence techniques to optimize grammars from examples, but requires
a large corpus of annotated examples, which are not viable for infer-
ring program input grammars. Scicluna and Higuera [ 35] propose
an unsupervised approach to grammar inference without anno-
tated examples. While they show that this approach works for
small samples with respect to NLP standards (the polynomial num-
ber of examples with respect to the number of productions in ideal
grammars), this approach is still not viable for inferring program
input grammars. REINAM addresses these issues by expanding seed
inputs using Pex before synthesizing the grammar.
8 CONCLUSION
We have presented REINAM, a reinforcement learning approach
for synthesizing a PCFG that encodes the language of valid pro-
gram inputs. To address the challenge of lacking high-variety and
high-quality seed inputs faced by the existing approaches, REINAM
includes an industrial symbolic execution engine, Pex [ 38], to gen-
erate initial seed inputs for the given target program, and includes
a grammar-generalization loop to proactively generate additional
inputs during grammar inference. In the grammar-generalization
loop, instead of eliminating production rules in a candidate gram-
mar that may not be accurate initially (as done by Glade [ 14], an
existing state-of-the-art approach), REINAM keeps and evolves
inaccurate grammars, enabling it to infer ground-truth grammars
whose inference requires composite generalizations from the initial
seed inputs. To efficiently search for such composite generaliza-
tions in a huge search space of candidate generalization operators,
REINAM includes a novel formulation of the search problem as a
reinforcement learning problem. Our evaluation results show that
REINAM outperforms Glade on both precision and recall of the
synthesized grammars, and fuzz testing based on REINAM substan-
tially increases the coverage of the space of valid inputs. REINAM is
often able to synthesize a grammar covering the whole valid input
space without decreasing the precision of the grammar.
ACKNOWLEDGMENTS
This material is in part based upon work supported by the National
Science Foundation under Grant No. CNS-1513939, CNS-1564274,
CCF-1816615 and TWC-1409915. Any opinions, findings, and con-
clusions or recommendations expressed in this material are those of
the author(s) and do not necessarily reflect the views of the National
Science Foundation.
497REINAM: Reinforcement Learning for Input-Grammar Inference ESEC/FSE ‚Äô19, August 26‚Äì30, 2019, Tallinn, Estonia
REFERENCES
[1] 2009. PDF Reference. https://www.adobe.com/devnet/pdf/pdf_reference.html
[2] 2010. Norvig Lisp. http://norvig.com/lispy.html
[3]2010. What is a good regular expression to match a URL? https://stackoverflow.
com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url
[4] 2015. Grammar of CSS. https://www.w3.org/TR/CSS21/grammar.html
[5] 2015. XML standard. https://www.w3.org/standards/xml/core
[6] 2018. ANTLR. https://www.antlr3.org/
[7] 2018. GNU Grep. https://www.gnu.org/software/grep/
[8] 2019. CSV grammar. http://www.harward.us/~nharward/antlr/csv.g
[9]2019. First Order Logic grammar. https://www.antlr3.org/grammar/
1336156363937/FOL.g
[10] 2019. Radamsa. https://gitlab.com/akihe/radamsa
[11] Dana Angluin. 1987. Learning regular sets from queries and counterexamples.
Information and Computation 75, 2 (1987), 87‚Äì106.
[12] Domagoj Babiƒá, Matko Botinƒçan, and Dawn Song. 2012. Symbolic grey-box
learning of input-output relations . Technical Report UCB/EECS-2012-59. EECS
Department, University of California, Berkeley.
[13] Domagoj Babiƒá, Daniel Reynaud, and Dawn Song. 2011. Malware analysis with
tree automata inference. In Proceedings of the International Conference on Com-
puter Aided Verification . Springer, 116‚Äì131.
[14] Osbert Bastani, Rahul Sharma, Alex Aiken, and Percy Liang. 2017. Synthesizing
program input grammars. In Proceedings of the 38th ACM SIGPLAN Conference
on Programming Language Design and Implementation . ACM, 95‚Äì110.
[15] Anja Belz. 2002. PCFG learning by nonterminal partition search. In Proceedings
of the International Colloquium on Grammatical Inference . Springer, 14‚Äì27.
[16] Matko Botinƒçan and Domagoj Babiƒá. 2013. Sigma*: Symbolic learning of input-
output specifications. In Proceedings of the 40th Annual ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages . ACM, 443‚Äì456.
[17] Konstantin B√∂ttinger, Patrice Godefroid, and Rishabh Singh. 2018. Deep re-
inforcement fuzzing. CoRR abs/1801.04589 (2018). arXiv:1801.04589 http:
//arxiv.org/abs/1801.04589
[18] Juan Caballero, Heng Yin, Zhenkai Liang, and Dawn Song. 2007. Polyglot: Au-
tomatic extraction of protocol message format using dynamic binary analysis.
InProceedings of the 14th ACM conference on Computer and Communications
Security . ACM, 317‚Äì329.
[19] Peng Chen and Hao Chen. 2018. Angora: Efficient fuzzing by principled search.
InProceedings of 2018 IEEE Symposium on Security and Privacy . IEEE, 711‚Äì725.
[20] Patrice Godefroid, Adam Kiezun, and Michael Y. Levin. 2008. Grammar-based
whitebox fuzzing. In Proceedings of the 29th ACM SIGPLAN Conference on Pro-
gramming Language Design and Implementation . ACM, 206‚Äì215.
[21] Patrice Godefroid, Hila Peleg, and Rishabh Singh. 2017. Learn&fuzz: Machine
learning for input fuzzing. In Proceedings of the 32nd IEEE/ACM International
Conference on Automated Software Engineering . IEEE Press, 50‚Äì59.
[22] Matthias H√∂schele, Alexander Kampmann, and Andreas Zeller. 2017. Active
learning of input grammars. arXiv preprint arXiv:1708.08731 (2017).
[23] Matthias H√∂schele and Andreas Zeller. 2016. Mining input grammars from
dynamic taints. In Proceedings of the 31st IEEE/ACM International Conference on
Automated Software Engineering . ACM, 720‚Äì725.
[24] Matthias H√∂schele and Andreas Zeller. 2017. Mining input grammars with
AUTOGRAM. In Proceedings of 2017 IEEE/ACM 39th International Conference on
Software Engineering Companion . 31‚Äì34.[25] Hiroki Ishizaka. 1990. Polynomial time learnability of simple deterministic
languages. Machine Learning 5, 2 (1990), 151‚Äì164.
[26] Caroline Lemieux and Koushik Sen. 2018. FairFuzz: A targeted mutation strategy
for increasing greybox fuzz testing coverage. In Proceedings of the 33rd ACM/IEEE
International Conference on Automated Software Engineering . ACM, 475‚Äì485.
[27] Yuekang Li, Bihuan Chen, Mahinthan Chandramohan, Shang-Wei Lin, Yang Liu,
and Alwen Tiu. 2017. Steelix: Program-state based binary fuzzing. In Proceedings
of the 2017 11th Joint Meeting of the European Software Engineering Conference
and the ACM SIGSOFT Symposium on the Foundations of Software Engineering .
ACM, 627‚Äì637.
[28] Rupak Majumdar and Ru-Gang Xu. 2007. Directed test generation using symbolic
grammars. In Proceedings of the 22nd IEEE/ACM International Conference on
Automated Software Engineering . ACM, 134‚Äì143.
[29] Ghassan Misherghi and Zhendong Su. 2006. HDD: Hierarchical delta debugging.
InProceedings of the 28th International Conference on Software Engineering . ACM,
142‚Äì151.
[30] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing Atari with
deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).
[31] Jos√© Oncina and Pedro Garcia. 1992. Identifying regular languages in polynomial
time. In Advances in Structural and Syntactic Pattern Recognition . World Scientific,
99‚Äì108.
[32] Michael Pradel and Koushik Sen. 2018. DeepBugs: A learning approach to name-
based bug detection. Proc. ACM Program. Lang. 2, OOPSLA, Article 147 (Oct.
2018), 25 pages.
[33] Martin Rinard. 2003. Acceptability-oriented computing. In Companion of the
18th Annual ACM SIGPLAN Conference on Object-oriented Programming, Systems,
Languages, and Applications . ACM, 221‚Äì239.
[34] Martin C. Rinard. 2007. Living in the comfort zone. In Proceedings of the 22Nd
Annual ACM SIGPLAN Conference on Object-oriented Programming Systems and
Applications . ACM, 611‚Äì622.
[35] James Scicluna and Colin De La Higuera. 2014. PCFG induction for unsupervised
parsing and language modelling. In Proceedings of the 2014 Conference on Empirical
Methods in Natural Language Processing . 1353‚Äì1362.
[36] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang,
Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna.
2016. Driller: Augmenting fuzzing through selective symbolic execution. In
Proceedings of the Network and Distributed System Security Symposium , Vol. 16.
1‚Äì16.
[37] Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. 2000.
Policy gradient methods for reinforcement learning with function approximation.
InProceedings of Advances in Neural Information Processing Systems . 1057‚Äì1063.
[38] Nikolai Tillmann and Jonathan De Halleux. 2008. Pex‚ÄìWhite box test generation
for .NET. In Proceedings of International Conference on Tests and Proofs . Springer,
134‚Äì153.
[39] Helen J. Wang, Chuanxiong Guo, Daniel R. Simon, and Alf Zugenmaier. 2004.
Shield: Vulnerability-driven network filters for preventing known vulnerabil-
ity exploits. In Proceedings of the 2004 Conference on Applications, Technologies,
Architectures, and Protocols for Computer Communications . ACM, 193‚Äì204.
[40] Tao Xie, Nikolai Tillmann, Jonathan de Halleux, and Wolfram Schulte. 2009.
Fitness-guided path exploration in dynamic symbolic execution. In Proceedings of
2009 IEEE/IFIP International Conference on Dependable Systems & Networks . IEEE,
359‚Äì368.
498