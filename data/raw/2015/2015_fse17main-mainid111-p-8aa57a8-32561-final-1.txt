See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/318872310
Toward full elasticity in distributed static analysis: the case of callgraph analysis
Conf erence Paper  · August 2017
DOI: 10.1145/3106237.3106261
CITATIONS
29READS
269
3 author s:
Diego Garber vetsky
Univ ersity of Buenos Air es
76 PUBLICA TIONS    729 CITATIONS    
SEE PROFILE
Edg ardo Z oppi
Univ ersity of Buenos Air es
4 PUBLICA TIONS    42 CITATIONS    
SEE PROFILE
Ben Livshits
Micr osoft
99 PUBLICA TIONS    5,574  CITATIONS    
SEE PROFILE
All c ontent f ollo wing this p age was uplo aded b y Diego Garber vetsky  on 22 Oct ober 2017.
The user has r equest ed enhanc ement of the do wnlo aded file.TowardFullElasticityin Distributed Static Analysis:
TheCaseofCallgraph Analysis
Diego Garbervetsky
Edgardo Zoppi∗
Universidadde Buenos Aires,FCEyN,DC
ICC,CONICET
ArgentinaBenjaminLivshits
ImperialCollegeLondon
UnitedKingdom
ABSTRACT
In this paper we present the design and implementation of a dis-
tributed,whole-programstaticanalysisframeworkthatisdesigned
to scale with the size of the input. Our approach is based on the
actor programming model and is deployed in the cloud. Our re-
liance on a cloud cluster provides a degree of elasticity for CPU,
memory, and storage resources. To demonstrate the potential of
our technique, we show how a typical call graph analysis can be
implementedinadistributedsetting.Thevisionthatmotivatesthis
work isthateverylarge-scale softwarerepositorysuch asGitHub,
BitBucket or Visual Studio Online will be able to perform static
analysisonalarge scale.
We experimentally validate our implementation of the dis-
tributed call graph analysis using a combination of both synthetic
and real benchmarks. To show scalability, we demonstrate how
the analysis presented in this paper is able to handle inputs that
are almost10 millionlines of code(LOC) insize, without running
out of memory. Our results show that the analysis scales well in
termsofmemorypressureindependentlyoftheinputsize,aswe
addmorevirtualmachines(VMs).AsthenumberofworkerVMs
increases, we observe that the analysis time generally improves
as well. Lastly, we demonstrate that querying the results can be
performedwithamedian latency of15 ms.
CCS CONCEPTS
·Theory of computation →Distributed algorithms ;·Soft-
ware and its engineering →Automated static analysis ;In-
tegratedandvisualdevelopmentenvironments ;·Computer
systemsorganization →Cloud computing ;
KEYWORDS
Development environments and tools, Parallel, distributed, and
concurrentsystems,Performanceandscalability,Programanalysis,
Program comprehensionandvisualization
∗Partof thisworkwas donewhen the authorswerevisitingMicrosoft.
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forproitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the irst page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspeciicpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE’17, September 04-08, 2017, Paderborn, Germany
©2017 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-5105-8/17/09...$15.00
https://doi.org/10.1145/3106237.3106261ACMReference format:
DiegoGarbervetsky,EdgardoZoppi,andBenjaminLivshits.2017.Toward
FullElasticityinDistributedStaticAnalysis:TheCaseofCallgraphAnal-
ysis. InProceedings of 2017 11th Joint Meeting of the European Software
EngineeringConferenceandtheACMSIGSOFTSymposiumontheFounda-
tions of Software Engineering, Paderborn, Germany, September 04-08, 2017
(ESEC/FSE’17), 12pages.
https://doi.org/10.1145/3106237.3106261
1 INTRODUCTION
In the last decade, we have seen a number of attempts to build
increasinglymorescalablewholeprogramanalysistools.Advances
inscalabilityhaveoftencomefromimprovementsinunderlying
solvers such as SAT and Datalog solvers as well as sometimes
improvements tothedatarepresentationintheanalysis itself; we
have seen much of this progress in the space of pointer analysis [ 3,
15, 16, 22, 25, 26, 42].
Limits of scalability: A typical whole-program analysis is de-
signed to run on a single machine,primarily storingits data struc-
tures in memory. Despite the intentions of the analysis designer,
this approach ultimately leads to scalability issues as the input pro-
gram size increases, with even the most lightweight of analyses.
Indeed, if the analysis is stateful, i.e. it needs to store data about
the programas it progresses, typically, in memory, eventually this
approachceasestoscaletoverylargeinputs.Memoryisfrequently
a bottleneck even if the processing time is tolerable, despite var-
ious memory compression techinques such as BDDs. We believe
thatthe needtodevelopscalable program analyses is nowgreater
thanever.Thisisbecauseweseeashifttowarddevelopinglarge
projectsincentralizedsourcerepositoriessuchasGitHub,which
opens up opportunities for creating powerful and scalable analysis
backends that go beyond what any developer’s machine may be
ableto accomplish.
Distributed analysis: Inthispaperweexploreanalternativeap-
proachtobuilddistributedstaticanalysistools,designedtoscale
with the input size, with the goal of achieving full elasticity. In
otherwords,nomatterhowbigtheinputprogramis,givenenough
computingresources ,i.e.machinestoexecuteon,theanalysiswill
completeinareasonabletime.Ouranalysisarchitectureassumes
thatthestaticanalysisrunsinthecloud,whichgivesuselasticity
for CPU and memory resources, as well as storage. More specif-
ically, in the context of large-scale code repositories, even code
understandingandcodebrowsingtasksaremadechallengingby
thesizeofthecodebase.Wehaveseentheemergenceofscalable
online code browsers such as Mozilla’s LXR [ 28]. These tools of-
tenoperateinbatchmode,andthushaveahardtimekeepingup
442ESEC/FSE’17,September04-08,2017, Paderborn,Germany DiegoGarbervetsky,EdgardoZoppi, andBenjamin Livshits
with a rapidly changing code repository in real time, especially for
repositorieswithmanysimultaneouscontributors.Weaimtoshow
howanimblersystemcanbedesigned,whereanalysisresultsare
largely stored in memory, spread across multiple machines. This
design results in more responsive queries to obtain analysis results.
1.1 Motivation: Static Analysis Backend
Imaginealargeprojecthostedwithinacentralizedsourcereposi-
tory such as GitHub, BitBucket or Visual Studio Online1. We see
anemergingopportunitytoperformserver-sideanalysisinsuch
asetting.Indeed,the backendsofmanysuchrepositoriesconsists
of a large collection of machines, not all of which are fully utilized
at any given time. During the downtime, some of the available
cycles could be used to do static analysis of the code base. This can
helpdeveloperswithbothprogramunderstandingtasks,suchas
code browsing as well as other static analysis applications, such as
indingbugs.
The ever-changing code base: As is typical for large projects,
multiple developers constantly update the code base, so it is imper-
ative that the server-side analysis be both responsive to read-only
user queries and propagate code updates fast. At the same time,
within a large code base, many parts of the code, often entire di-
rectories remain unchanged for days or months at a time. Often,
there is no reason to access these for analysis purposes. Therefore,
to ensure that we do not run out of memory, it is important to
have a system that is able to bring analysis nodes into memory on
demandandpersistthemtodisk(putthemtosleep)whentheyare
nolonger needed.
1.2 CallGraphComputation
Inthispaperweadvocatetheuseofthe actormodel asabuilding
blockoftypicalworklist-basedanalysisapproaches.Morespecii-
cally,weusethisapproachtoimplementatypicalcallgraphcon-
struction algorithm. While the algorithm itself is quite well-known
andisnotacontributionofthispaper,thewayitisimplemented
in a distributed setting is. Also note that call graph information is
used for interactive tasks such as autocomplete (or Intellisense), as
shown in Figure 6. For tasks like this, both accuracy and respon-
sivenessareimportant.Callgraphconstructionisafundamental
stepofmostwhole-programanalysistechniques.However,mostof
thetime, call graph analysis computationis a batchprocess: start-
ingwithoneormoreentrypointssuchas Main,thecallgraphis
iterativelyupdateduntil nomore methodsare discovered.
Interactiveanalysis: Our setting in this paper is a little diferent.
Our goal is to answer interactive user queries quickly. Our queries
arethekind thataremostfrequentlyposed inthecontextofcode
browsing and debugging, and are already supported on a syntactic
levelbymanyIDEs.Speciically,ouranalysisinthispaperhasbeen
developed to provide semantic, analysis-backed answers for the
followingIDE-basedtasks:(1) Gotodeinition: Givenasymbolin
theprogram,inditspossibledeinitions2;(2)Whocallsme: Given
1Visual Studio Online: https://www.visualstudio.com/team-services/ .
2Note that this process is challenging due to the presence of polymorphism, common
inobject-orientedlanguages.Givenacallsite,itisnotalwayspossibletodetermine
whichistheactualmethodimplementationbeinginvoked.Thisproblemknownas
call site devirtualization is well-studied in the literature. Therefore, a static analysis
canonly approximate the targetmethod deinitions for avirtual method invocation.amethoddeinition,indallofitscallers;(3) Auto-complete: Auto-
completion,invokedwhenthedeveloperpressesadotisoneofthe
most common and well-studied tasks within an IDE [ 7,19,23,29ś
31].Ifthevariableorexpressionsontheleft-handsideofthedotisof
agenericinterfacetype,completionsuggestionsarenotparticularly
usefulortoogeneral.Itisthereforehelpfultoknowwhichconcrete
type lowto agiven abstract location.
WehavearchitectedouranalysisbackendtorespondtoREST
calls[1]thatcorrespondtothequeriesabove.Thesequeriesconsti-
tuteanimportantpartofwhatiscollectivelyknownas language
servicesand canbe issued bybothonline IDEs,sophisticated code
editorssuchasSublimeText,andfull-ledgedIDEssuchasEclipse
andVisualStudio.Figure 6showsexamples of an IDE inaction.
Soundness: Given the nature of such tasks that focus on program
understanding ,thegoalisnottoalwaysbeabsolutelyprecise,but
to be both useful to the end user and responsive. Our analysis judi-
ciouslycutscornersinthespiritofsoundiness[ 21].Astheanalysis
resultsareusedinanadvisoryroleinthecontextofprogramun-
derstandinginaninteractivesetting,completesoundnessisnotthe
goal.Forinstance,wedonotattempttomodelrelectiveconstructs.
WhilewefocusonC#astheinputlanguage,ourworkshouldapply
equallywelltoanalyzinglargeprojectsinJavaandothersimilar
object-oriented languages. It is not, however, our goal to faithfully
handleallthetrickylanguagefeaturessuchasrelection,runtime
code generation, and pinvoke-basednative calls.
1.3 Contributions
This paper makesthe following contributions:
•Weproposeadistributedstaticanalysisapproach,basedonthe
monotone framework, and show how to apply it to call graph
construction for answering program understanding and code
browsing queries.
•We describe how the analysis is implemented on top of the
Orleansdistributedprogramming platformand isdeployed on
legacy hardware inthe cloud using MicrosoftAzure.
•We experimentally demonstrate the scalability of our distributed
call graph implementation using a range of synthetic and real
benchmarks. The results show that our analysis scales well in
terms of memory pressure independently of the input size, as
we add more machines. Despite using stock hardware and incur-
ringanon-trivialcommunicationoverhead,wescaletoinputs
containing10millionLOC:forinputsof1MLOC,theanalysisre-
quires at least 4 machines; for 10M LOC, 16 machines. While the
communicationoverheadcanbecomeabottleneck,weshowthat
asthenumberofmachinesincreases(upto64),theanalysistime
generally drops. Depending on the setting, partial results can be
queried before theanalysis has inished.Lastly,we demonstrate
that querying the results can be performed with an acceptable
median latency of15 ms.
2 OVERVIEW
Ourgoalistohavetheanalysisbackendrespondtoqueriesquickly,
independentlyoftheinputsize.Ofcourse,wealsoneedtomake
sure that the backend does not run out of memory or timeout in
someunpredictableway.Ourrequirementsforceustorethinksome
ofthe typicalassumptions of whole-program analysis.
443TowardFullElasticity in DistributedStaticAnalysis: The Caseof
CallgraphAnalysis ESEC/FSE’17,September04-08,2017, Paderborn,Germany
1:while|MQ|>0do
2:⟨a,m⟩:=MQ.choose()
3:v:=UNPACK (m)⊔VALUE[a]
4:ifv⊑VALUE[a]then
5: continue
6:endif
7:v′:=TF[a](v)
8:9:ifv⊑v′then
10:U:=DELTA(v,v′)
11: for eachuinUdo
12: MQ:=MQ∪PACK(a,u)
13: endfor
14: VALUE[a] :=v′
15:endif
16:endwhile
Figure 1:Distributed worklistalgorithm.
2.1 Analysis Design Principles
Weusea distributedactormodel [2]asthebasisofourdistributed
static analysis engine. For a program written in an object-oriented
language such as Java or C#, a natural it is to have an actor per
methodwithin the program. We could choose to have an actor per
classinaprogram,oranyotherwell-deinedprogramentity.These
actors are responsible for receiving messages from other actors,
processingthemusinglocalstate(arepresentationofthemethod
body, for instance), and sending information to other methods that
dependonit.Forexample,foracallgraphconstructionanalysis,
actorsrepresentingindividualmethodsmaysendmessagestoactors
for their callers and callees. Our analysis design adhere to the
following distilledprinciples.
Minimalin-memorystateperactor: Wewanttołpackžasmany
actors per machine as possible without creating undue memory
pressure,leadingto swapping, etc.
Design for lightweight serialization: We have designed our
analysis so that the updates sent from one actor to another are
generally small and easily serialized. There is minimal sharing
amongactors,asactorholdsontoitslocalstateandoccasionally
sends small updates to others. The same principle applies to persis-
tent per-actor state as well. We only serialize the bare minimum
to disk, before the actor is put to sleep. This can happen when the
actorruntimedecidestopageanactoroutduetomemorypressure
orlackofrecent use.
State can be recomputed on demand: In a distributed setting,
we have to face the reality that processes may die due to hardware
and/orsoftwarefaults.Itisthereforeimperativetobeabletorecover
in case of state loss. While it is possible to commit local state to
persistent store, we eschew the overhead of such an approach and
instead choose to recompute per-node state ondemand.
Locality optimizations to minimize communication: We at-
tempt to place related actors together on the same machine. In the
caseofacallgraphanalysis, this oftenmeans that entirestrongly
connectedcomponentsco-existonthesamephysicalbox,which
minimizesthenumberofmessagesthatweactuallyneedtodispatch
acrossthe network.
2.2 DistributedWorklist Algorithm
Wenowpresentahigh-levelviewofadistributedanalysisproblem
as apair⟨A,L⟩where:
•Aisasetofactors distributedinanetwork.
•⟨L,⊑,⊔⟩isacomplete semi-lattice ofiniteheight3.
Eachactor a∈Ahas the following associatedfunctions:
•VALUE[a]=v∈Listhe local state ofactor a;
3The initeheightrequirementcanbeavoided with the useof awidening operator.•TF[a] :L/maps⊔o→Lis thetransfer functionfor thelocal computation
performedwithin actor a.We assumeall TFare monotone;
Thefollowinghelperfunctionsareforcommunicatingstatechanges
among actors:
•DELTA(v,v′)computesaset Uof(global)updatesrequiredwhen
switchingfrom local state vtov′∈L;
•PACK(a,u)is a function that given an update at actor a∈A
producesoneorseveralmessagestocommunicatetootheractors.
•UNPACK (m)is a function that unpacks a message and returns a
valuev∈L.
Figure1showsthepseudocodeforadistributedworklistalgorithm.
The algorithm makes use of a global message queue, denoted as
MQ4.Thequeueisinitializedwithasetofstartingmessagesthat
willdepend onthe actual analysisinstance.
2.3 TerminationandNon-Determinism
We would like to show that the presented distributed worklist
algorithm terminates.
LetHdenotethe(inite5)heightofsemi-lattice LandletN=|A|.
Consideriterationsthroughthelooponline1.Let’sconsidertwo
sets of sequences of iterations, I1are iterations that lead to a value
increaseonline7and I2are thosethat do not.
We can have at most H×Niterations in I1given the inite size
of the lattice. For iterations in I2, the size of MQdecreases because
at least one message is consumed but it does not generate other
messages. We considertwopossibilities:
•Startingfromsomeiteration i,weonlyhaveiterationsin I2.This,
however,meansthatoneveryiterationthesizeof MQdecreases,
until iteventually becomes empty.
•Theotherpossibilityisthatwewillhaveanininitenumberof
iterationsin I1.Thisisclearlyimpossiblebecausethesizeof I1
isboundedby H×N.
Itisimportanttoemphasizethediferencebetweenthisdistributed
algorithmandasingle-nodeworklistapproach.Ifamessageisin
light, we do not wish the program analysis to terminate. However,
detectingtheemptinessof MQisnottrivial,soinpracticewemust
have an efective means for detecting termination. We make use of
anorchestrator mechanism for termination detection, as described
inSection 4.2.
WhilethealgorithminFigure1reachesaixpointindependently
of the arrival order of messages, it is natural to ask whether that
is the only ixpoint that can be reached. Given that TF[a] is mono-
tone and Lis of a inite height the uniqueness of least ixpoint is
guaranteed[9, 18].
3 CALL GRAPH ANALYSIS
Inthissectionwepresentaninstantiationofthegeneralframework
described in the previous section for computing call graphs. Our
analysisisadistributedinterproceduralinclusion-basedstaticanal-
ysisinspiredbytheVariableTypeAnalysis(VTA)presentedin[ 36].
Thislow-insensitiveanalysiscomputesthesetofpotentialtypes
4Note thatMQis amathematical abstraction : we do not actually use a global mes-
sage queue in our implementation. Conceptually, we can think of a (local) worklist
maintainedonaper-actorbasis.Terminationisachievedwhenalltheworklistsare
empty.
5Note that our approach can also terminate for an ininite hight lattice with the use of
awidening operator.
444ESEC/FSE’17,September04-08,2017, Paderborn,Germany DiegoGarbervetsky,EdgardoZoppi, andBenjamin Livshits
for eachobject reference (variable, ield, etc.) by solving a system
of inclusion constraints. Because it propagates type constraints
from object allocation sites to their uses, this kind of analysis is
sometimes referredto as concretetype analysis.
3.1 ProgramRepresentation
Propagation graphs: At the method level, the inclusion-based
analysisisimplementedusingadatastructurewecalla propaga-
tiongraph (PG)[36].APGisa directedgraphusedtołpushžtype
information to follow data low in the program, as described by
analysis rules. Our analysis naturally lands itself to incrementality,
although we do not evaluate this experimentally in this paper. A
typical change in the program would require often minimal recom-
putation within the modiied code fragment as well as propagation
of that information to its łneighborsž. Propagation graphs support
incrementalupdatessincethepropagationofinformationistrig-
geredwhen anewtype reaches anode.
Terminology: More formally, let PG=⟨R,E⟩whereRdenotes a
set of nodes representing abstract locations in the method (such as
variables and ields) and Erefers to a set of edges between them.
An edgee=(v1,v2)∈Econnects nodes in the PG to model the
potentiallowoftypeinformationfrom v1tov2.Essentially,anedge
representsarulestatingthat Types(v2)⊇Types(v1)(e.g,v2=v1).
Tomodelinterproceduralinteraction,thePGalsoincludesnodes
representing method invocations ( invloc) and return values ( rv).
Finally,I⊆Rdenotes the set of invocations. Let Tbe the set of all
possible types, dTypecontains declared types (compile-time types)
for abstract locations and Typesdenotes concrete types inferred
byour analysis.
3.2 Analysis Phases
Intheactormodel,thechoiceofgranularityiskeyforperformance.
Wedecidedtouseoneactorpermethod,althoughotherdesigndeci-
sionssuchasoneactorperclassarealsopossible.Eachmethod-level
actor contains a PG that captures type information that propagates
through the method. The analysis starts by analyzing an initial set
ofrootmethods M0.Wedescribebothintra-andinterprocedural
processing below.
3.2.1 IntraproceduralAnalysis.
This phaseis the responsible of computing the local state of an
actor representing amethod.
Instantiatingtheproblem: Thelattice Lforouranalysisconsists
ofamappingfromabstractlocationstosetsofpossibletypesand
isdeinedas
L=⟨Types:R/maps⊔o→2T,⊑type,⊔type⟩
with⊑typedeinedas
l1⊑typel2ifl1.Types(r)⊆l2.Types(r),∀r∈R
and⊔typedeinedas l1⊔typel2=l3where
l3.Types(r)=l1.Types(r)∪l2.Types(r),∀r∈R.
Analysis rules that compute TF[a] are summarized in Figure 2 and
cover the typical statement types such as loads, stores, allocations,
etc. Object dereferences (i.e., v.f) are represented by using thev1=v2=⇒Types(v1)⊇Types(v2)
v1=v2.f=⇒Types(v1)⊇Types(dType(v2).f)
v1.f=v2=⇒Types(dType(v1).f)⊇Types(v2)
v=newC()=⇒C∈Types(v)
returnv=⇒Types(rv)⊇Types(v)
loc:v=v0.m(v1. ..vn)=⇒Types(invloc)⊇/uniondisplay
j=0..nTypes(vj)
Figure 2:VTAanalysis rules.
name of the class deining the ield. That is, the analysis is ield-
sensitivebutnotobject-sensitive.Inthecaseofinvocationsthere
is an inclusion relation to model the low of all the arguments to
theinvocationabstractlocation invloc∈I⊆R.Notethattheleft-
hand side vof the invocation is not updated by the rule since it
depends on the result of the invoked method. This will be handled
byinterproceduralanalysis.
Noticethat TF[a]ismonotonicbecausethepropagationoftypes
never removes a type and Lsatisies the inite-height condition
because itisainitelattice.
3.2.2 Interprocedural Analysis. Once the intraprocedural phase
inishes,relevantupdatesmustbecommunicatedtothecorrespond-
ingmethods(calleesandcallers).Asmentioned,theanalysiscon-
sidersinvocationsusingtheset I⊆R.Tohandlecallers’updates,
we need to extend the lattice to include the caller’s information
for the current method. This has the form ⟨m,lhs⟩, wherem∈A
denotes the caller’s name and lhs∈Rrepresents the left-hand side
of the invocation made by the caller. The extended lattice is shown
below.
L=⟨Types:R/maps⊔o→2T×Callers: 2A×R,⊑,⊔⟩
l1⊑l2ifl1⊑typel2∧
l1.Callers⊆l2.Callers
l1⊔l2=(ts,cs)where
ts=l1⊔typel2∧
cs=l1.Callers∪l2.Callers
A message mhas the form⟨kind,d,data⟩, where kind∈
{callMsg,retMsg}is the kind of message, d∈Ais the destina-
tionactor and dataisatuple.
Instantiating DELTA:InFigure3aweshowthedeinitionofthe
DELTAoperation described in Section 2. It computes the set of
invocationsthatwereafectedbythepropagation.Aninvocation
is afected if the set of types lowing to any of its parameters grew.
Additionally,wealsomustconsiderchangesintypesthatthereturn
valuemaycorrespondto,sincetheyneedtobecommunicatedto
the callers.
Instantiating PACK:Figure3bshowsadeinitionof PACK.This
function is in charge of converting local updates to messages that
can be serialized and sent to other actors. For each invocation,
the analysis uses the computed type information of the receiver
argument to resolve potentialcallees.
Then, it builds a caller message including the potential types for
each argument. Those types will be added to the set of types of the
parameters on the caller actor. In case of an update in return value
itbuildsamessagetoinformthecalleraboutchangestothereturn
value’stypes.Thismessageincludesthe(original)caller’sleft-hand
side,sothat the caller can updateits types.
445TowardFullElasticity in DistributedStaticAnalysis: The Caseof
CallgraphAnalysis ESEC/FSE’17,September04-08,2017, Paderborn,Germany
letdif(v,v′,r):=v′.Types(r)−v.Types(r)
letInv(v,v′):={inv|inv∈I∧dif(v,v′,inv)/nequal∅}
letRv(v,v′):=/braceleftBigg
{rv}ifdif(v,v′,rv)/nequal∅
∅otherwise
DELTA(v,v′)def=Inv(v,v′)∪Rv(v,v′)
(a)Deinition of DELTA(v,v′)
letcallees(inv):={C.m|C∈l.Types(arдs(inv)0)}
letcallMsg(a,inv):=⟨a,lhs(inv),l.Types(arдs(inv))⟩
letcallMsgs(a,inv):={⟨callMsg,d,callMsg(a,inv)⟩
|d∈callees(inv)}
letreturnMsg (a,c):=⟨a,lhs(c),l.Types(rv)⟩
letretMsgs(a):={⟨retMsg,method(c),returnMsg (a,c)⟩
|c∈l.Callers}
PACK(a,u)def=/braceleftBigg
callMsgs(a,u)ifu∈I
retMsgs(a)ifu=rv
(b)Deinitionof PACK(a,u).l.Types(arдs)istheliftingof l.Typesto
the list of arguments, it returns a lists of set of types. Given inv=
⟨v=v0.m(v1...vn)⟩,arдs(inv)=[v0,v1, ...,vn],lhs(inv)=v.
For a caller c=(m,lhs)∈l.Callers,method(c)=m, the caller’s
nameand lhs(c)=lhs,theleft-handsideoftheoriginalinvocation
made by thecaller.
letl1.Types(r)=/braceleftBigg
arдTypes (m)iifr=pi
∅ otherwise
letl1.Callers={(sender(m),lhs(m))}
letl2.Types(r)=/braceleftBigg
retTypes (m)ifr=lhs(m)
∅ otherwise
UNPACK (m)def=/braceleftBigg
l1ifkind(m)=callMsg
l2ifkind(m)=retMsg
(c) Deinition of UNPACK (m). For a message m=
⟨callMsg,d,⟨a,lhs,[ts0,ts1, ...,tsn]⟩⟩arдTypes (m)i=tsi,
the set of potential types for the ithargument pi.lhs(m)=lhs,
sender(m)=a. For a return message m′=⟨retMsg,d,⟨a,lhs,ts⟩⟩,
retTypes (m′)=tsis the set of potential types of the method’s
returnvalue.
Figure 3:Deining DELTA,UNPACK,andPACK.
Instantiating UNPACK:Function UNPACK inFigure3cisrespon-
sibleforprocessingmessagesreceivedbyanactor.Thisfunction
convertsamessageintoavalueinthelatticeofthelocalanalysis
thatwillbethenjoinedintothelocalstate.Amessagecanbeeither
acall message (i.e., an invocation made by a caller) or a return mes-
sage(i.e.,toinformachangeinthecallee’sreturnvalue).Forcall
messages we produce an element that incorporates the types for
eachcallargumentintothemethodparameters.Wealsoupdatethe
set of callers. For return messages we need to update the left-hand
sideofthe invocation withthe potentialtypes ofthe return value.
Example 1 Thisexampleillustratestheadvantageofusingcon-
cretetypes asopposedto declaredtypes to obtain more precision.
Consider the small program in Figure 4a. In Figure 4b we show the
propagation graphsfor both methods. As theanalysisstarts,only
the left-handsidesofallocations (lines2and11) contain types.
Duringpropagation,type Blowsfromvariable xintoaninvo-
cation of Mas an argument. This triggers a message to the actor for
methodB.M. The low through parameter pandwmakes the return1public static void Main() {
2A x =newB();// allocation
3A y = x.M(x);
4A z = y;
5}
6public class A {
7public abstract A M(A p);
8}
9public class B : A {
10 public override A M(A p) {
11 A w =newB();// allocation
12 return (p !=null) ? p : w;
13 }
14}
(a)Codeexamplefor interproceduralpropagation.
A actual argument
of call M(x)
{}
A y
{}A z
{}A x
{B}
A p
{}
A returnValue
{}A w
{B}A actual argument
of call M(x)
{B}
A y
{B}A z
{B}A x
{B}
A p
{B}
A returnValue
{B}A w
{B}call messagereturn message
(b) PGs for methods MainandB.Mbefore (left) and after (right) the
propagationfor thecodeinFigure4a.
Figure 4:Codeandpropagation graphforExample 1.
valueofB.Mtocontaintype B.Thisinturntriggersareturnmessage
thatadds Btothetypesof y.Thispropagatesto z.Concretetype
analysis produces resultsthat are more accurate for y,z, etc. than
what we can obtain from their declaredtypes.
Typeapproximation: Intheinterproceduralstage,ouranalysis
sends information about concrete parameter types to its callees.
However,whenitcomestocomplex,nestedobjects,thisinforma-
tionispotentiallyinsuicient,asitonlyconcernsonelevelofthe
objecthierarchy.Considerthe following example:
voidMain { voidM(A p) {
A x =newB(); A z = p.f;
x.f =newB(); return z;
y = M(x) }
}
Function PACKwill create a message that propagates the type of x
intoMandUNPACK will discover the type of pto beB. However,
noinformationisgivenforthetypeof p.f,potentiallyleadingto
unsoundness.Insteadofsendinginformationaboutnestedields,
whichleadstoincreasedmessagesizes,weoptedtousethetypeof
p.fgivenbyadistributedversionoftheRapidTypeAnalysis[ 5]
thatrunssimultaneouslyoneachmethod-actor;whenRTAprovides
nousefulinformation,wefallbackondeclaredtypes.Wedidnot
observe imprecision causedbythis over-approximation.
3.3 OtherUses oftheAnalysis Framework
Thedistributed algorithm in Figure 1can be instantiated forother
program analyses that follow the same design principle. For in-
stance,consideraninclusion-basedanalysislikeAndersen’spoints-
to [4]. A possible instantiation may be as follows: (1) Each actor
representsamethod;(2)Thetransfer functionimplementsAnder-
sen’s inclusion rules locally and, in case there is a change in an
446ESEC/FSE’17,September04-08,2017, Paderborn,Germany DiegoGarbervetsky,EdgardoZoppi, andBenjamin Livshits
argumentofamethodinvocation,producesanupdatemessageto
be sentto the potentialcallees.
Similarly,byjustreplacingtheinclusionruleswithuniication
rulesinthetransferfunction,wecanturnitintoauniicationbased
points-toanalysislikeSteensgaard’s[ 35].Context-sensitivitycanbe
achieved by representing diferent context×methodcombinations
withdiferentactors.
It is worth noticing that our analysis has similar characteristics
asstandarddatalowanalyses,butanorderingonhowinformation
lowsbetweentheactorscannotbeassumed.Weenvisionfuture
work where our distributed back-end would be combined with a
natural front-end for this kind of analysis that uses Datalog, as
previously proposed for single-machine analysis [ 17]. However,
aswedescribeinSection1.2,ourevaluationinSection5focuses
on quickly answering interactive questions related to call graph
resolutioninthe contextofaIDE.
4 IMPLEMENTATION
We implemented a prototype of our distributed approach6to an-
alyze large-scale projects written in C#. This prototype relies on
Roslyn[27],acompilerframeworkforanalyzingC#codeandthe
Orleansframework[ 6],animplementationofadistributedactor
model thatcan bedeployedinthecloud. Althoughotherdeploy-
ment options such AWS are possible, for this paper we used Azure
as aplatform for running our experiments.
4.1 Orleans andtheActorModel
Orleans[ 6]isaframeworkdesignedtosimplifythedevelopment
of distributed applications. It is based on the abstraction of virtual
actors. In Orleans terminology, these actors are called grains. Or-
leanssolvesanumberofthecomplexdistributedsystemsproblems,
such as deciding where Ð on which machine Ð to allocate a given
actor, sending messages across machines, etc., largely liberating
developers from dealing with those concerns. At the same time,
the Orleans runtime is designed to enable applications that have
high degrees of responsiveness and scalability. Grains are the basic
building blocks of Orleans applications and are the units of iso-
lation and distribution. Every grain has a unique global identity
that allows the underlying runtime to dispatch messages between
actors.Anactorencapsulatesbothbehaviorandmutablelocalstate.
Stateupdatesacrossgrains can be initiatedusing messages.
The runtime decides which physical machine ( siloin Orleans
terminology) a given grain should execute on, given concerns such
asmemorypressure,amountofcommunicationbetweenindividual
grains,etc. Thismechanism isdesignedtooptimizeforcommuni-
cation locality because even within the same cluster the amount of
cross-machine messages are considerably smaller than the amount
oflocal messages, within the same machine.
We follow a speciic strategy in organizing grains at runtime.
This strategy is driven by the input structure. The input consists of
anMSBuild solution,a.slnilethatcanbeopenedinVisualStudio.
Each solution consists of a set of project iles ,∗.csproj, which may
depend on each other. Roslyn allows us to enumerate all project
iles within a solution, source iles withina project, classes within
6Source codeand benchmarks available onGitHubat:
https://github.com/too4words/Call-Graph-Builder-DotNet .a ile, methods within a class, etc. Furthermore, Roslyn can use its
built-inC#compilertocompilesourcesonthely. Wedeinegrains
for solutions, projects and methods. We did not ind it necessary
toprovidegrainsforclassesandotherhigher-levelcodeartifacts
such asnamespace s.
Asolutiongrainisasingletonresponsibleformaintainingthe
listofprojectsandproviding functionality to ind methodswithin
projects; A project grain contains the source code of all iles for
that project and provides functionality to compute the information
requiredbymethodgrains(e.g.,tobuildpropagationgraphsbypars-
ingthemethodcode)aswellastyperesolution(e.g.,methodlockup,
subtypingqueries,etc).Finally,amethodgrainisresponsiblefor
computingthelocaltypepropagationandresolvingcaller/callees
queries; it stores type information for abstract locations within the
method.
Thesolutiongrainreadsthe ∗.slnilefromcloudstorage;inour
implementation we used Azure Files, but other forms of input that
support ile-like APIs such as GitHub or Dropbox are also possible.
Projectgrains read ∗.csprojilesandalsoproceedtocompilethe
sourcescontainedintheprojecttogetaRoslyn Compilation object.
Thisinformationisonlycontainedintheprojectgraintominimize
duplication. To obtain information about the rest of the project,
method grains can consult the project grain. We use caching to
reducethenumberofmessagesbetweenmethodandprojectgrains.
Example2 Toillustratepersistentstateforatypicalmethodgrain,
consider the example in Figure 4a. The state of both methods is as
follows.
MethodMain:
Callers = {}
Types = {(x,{B}), (y,{B}), (z,{B}), (3,{B})}
MethodB.M:
Callers = {(A.Main, y)}
Types = {(p,{B}), (w,{B}), (returnValue,{B})}
This minimal state iseasily serialized to disk if thegrainsare ever
deactivated by the Orleans runtime. Orleans deactivates grains
whentheyaren’tusedforalongtime,however,thisneverhappened
inour experiments.
4.2 Distributed Analysis Challenges
Implementing a distributed system like ours is fraught withsome
fundamental challenges.
Reentrancy: Sincethecallgraphcanhavecycles,agraincanstarta
propagationwhichwillinturneventuallypropagatetotheoriginal
method. However, since Orleans uses turn-based concurrency this
willcreateadeadlock.Evenwithoutrecursionitispossiblefora
methodgrain thatis currentlybeing processedtoreceive another
message(i.e.areturn message).
Termination: In a distributed setting, detecting when we achieve
termination is not so easy. This is in part because even if all the
local worklists are empty, we may have messages in light or those
that have been delayed.
A naïve implementation is not going to work well because of
reentrancyissues:wecanblockwaitingforamessagethatwaits
for our response. In our implementation, we use orchestrators to
447TowardFullElasticity in DistributedStaticAnalysis: The Caseof
CallgraphAnalysis ESEC/FSE’17,September04-08,2017, Paderborn,Germany
Orleans client
Dispatcher grain Dispatcher grain Dispatcher grain
m manalyze
enqueue
effectm
enqueue
effectsubscribe
notify
m m
enqueue
effectdequeuesubscribe
notify notifysubscribe
enqueue
effectanalyze analyze analyze
enqueue
effectanalyze
queuequeuequeuequeue
queuequeueenqueue
effectdequeue
dequeue
enqueue
effectanalyzeanalyzeSilo 1 Silo 2 Silo 3
Figure 5: The multi-queue approach, illustrated. Method
grains are circles shown in light blue. Solid and dashed ar-
rows represent standard invocations and callbacks respec-
tively.Each silo haseachowndispatchergrain.
establish somedegree ofcentralized controlover thepropagation
process.Grains communicatewith an orchestrator exclusively,in-
stead of communicating with each other peer-to-peer. This avoids
theissueofreentrancybyconstruction;onlytheorchestratorcan
send messages to grains via a single message queue . The orchestra-
torkeepstrackoftheoutstandingtasksandcanthereforedetect
both terminationandpreventreentrant calls from taking place.
Thekeydisadvantageofthisdesignisthatitispossibletohavea
great deal of contention for access to the orchestrator. We observed
thisinpractice,suggestingadiferentvariantofthisidea.Weuse a
collection of queues distributed across the distributed system. Each
methodgrainisapotentialproducerof efectstobeprocessedby
othermethodgrains.Toavoidreentrancy,thisinformationisnot
sentdirectlytothetargetmethodgrainbutitisenqueuedinone
of the queues in a round robin fashion. The information is then
consumed by dispatchers grains that pullthe data from the queues
anddeliverittothecorrespondingmethodgrains;thisisillustrated
inFigure 5.
Usingthismechanismweavoidbothreentrancy,bottlenecksand
single points of failure. The drawback is that detecting termination
is more complex. For that, we use timers to determine when a
dispatcher becomes idle (i.e., inactive longer than a predetermined
threshold),atwhichpointwenotifytheclient.Theanalysisinishes
when the client is sure that all dispatchersare idle7. In practice, we
set the number of queues to be four times higher than the number
ofworkerVMs(forexample,128queuesfor32workerVMs)and
setthe terminationthreshold to 10 seconds.
4.3 DeploymentDetails
Our analysis is deployed in Azure as illustrated in Figure 7. On the
left, there is the analysis client such as an IDE or a code editor like
SublimeText. The cluster we used consists on one front-end VM
and a number of worker VMs. The client used REST requests to
communicatetothefront-endVM.Thejobofthefront-endVMisto
(1)acceptandprocessexternalanalysisclientrequests;(2)dispatch
jobstotheworkerVMsandprocesstheresults;and(3)providea
WebUIwithanalysisresults andstatistics.
Interactive deployment within an IDE: In Figure 6 we show
twoscreen-shotsofanexperimentalIDEprototypethatusesthe
7Wehavea mechanism to detect when anidledispatcherbecomes activeagain.
(a)Visualizing callees: callsite on line 20 invokes function DoTest.
(b) Visualizing callers: method Baris calledon line 23.
Figure 6: Anexperimental online IDE that usesanalysis for
resolving references forcalleesand callers.
APIexposedbyouranalysistoresolvecallers/calleesqueries.We
should point out that the precision achieved by our analysis is
enough for the autocomplete task.
5 EVALUATION
We aim to answer the following three research questions.
RQ1:Is our analysis capable of handling arbitrary amounts of
input(i.e.,morelinesofcode,iles,projects,etc.)byincreas-
ing the number of worker VMs, without running out of
memory?
RQ2:Whilethecommunicationoverheadcanbecomesigniicant,
as more worker VMs are added, does an increase in the
number of worker VMs signiicantly increase the overall
analysistimes?
RQ3:Is the analysis query latency small enough to allow for
interactive use8?
The focus of our analysis is on being used in an interactive set-
ting. Given the low latency times we can use our analysis in-
teractively as a replacement of source code browsers such as
http://source.roslyn.io .Thisbrowserprovidescodesearch
and basic navigation facilities but lacks more advanced features
likeactualcallers/calleesinspection/navigationthatwecanprovide
8Generally, querylatenciesof 10to 20ms areconsidered to beacceptable.
448ESEC/FSE’17,September04-08,2017, Paderborn,Germany DiegoGarbervetsky,EdgardoZoppi, andBenjamin Livshits
Orleans clientWeb roleAnalysis client
(IDE, visualizer, etc.)Analysis client
(IDE, visualizer, etc.)
load and store experimental statistics
Figure 7: Azure-based deployment of our analysis. Actual
work happens within worker VMs. The analysis client in-
teractswith thecluster viaafront-endVM.
withouranalysis.Atthesametime,wearenotasconcernedabout
the completion time for the analysis as a whole as we are about
its memory requirements on legacy VMs. Even if it takes longer to
process, our goal is to engineer an always-on system that responds
tomessagessenttothecloudtoserviceuserrequests,inthecontext
ofcodebrowsing,andothertaskslistedinSection1.2.Thiswork
was performed incollaborationwith the Roslyn team,and while
wehavenotperformeduserstudies,webelievelatencynumbers
(most queries took under 20 ms) to be more than acceptable for
interactive use.
5.1 ExperimentalSetup
Alltheexperimentspresentedinthispaperwereexecutedinthe
cloud, on a commercially available Azure cluster. We could also
have used an AWS cluster, as our dependency on Azure is small.
The Azure cluster we used for the experiments consists on one
front-end VMand up to 64 worker roleVMs. Thefront-end VM is
an Azure VM with 14 GB of RAM (this is an A4\ExtraLarge VM in
Azureparlance9).EachworkerroleisanAzureVMwith7GBof
RAM(called A3\LargeinAzure).Forbenchmarkingpurposes,we
runouranalysiswithconigurationsthatinclude1,2,4,8,16,32,
and 64 worker VMs. To collect numbers for this paper, we used
a custom-written experimental controller as our analysis client
throughout this section; this setup is illustrated in Figure 7. The
controllerisscriptedtoissuecommandstoanalyzethenext .sln
ile,collecttimings, etc.
We heavily instrumented our analysis to collect a set of rele-
vant metrics. We instrumented our analysis code to measure the
analysiselapsedtime.Weintroducedwrappersaroundourgrains
(solution, project, and method grains) to distinguish between lo-
calmessages(withinthesameVM)andnetworkmessages.Using
Orleans-providedstatistics,wemeasuredthemaximummemory
consumption per VM. Lastly,we also have addedinstrumentation
tomeasurequeryresponsetimes.Whilethesemeasurementsare
collectedatthelevelofanindividualgrain,wegenerallywanted
to report aggregates. To collect these, we post grain-level statistics
to aspecialauxiliary grain.
5.2 Benchmarks
Forourinputs,wehaveusedtwocategoriesofbenchmarks, syn-
theticbenchmarkswehavegeneratedspeciicallytotestthescal-
ability of our call graph analysis and a set of 3 real applications
9Up-to-date VM speciications are available at: https://azure.microsoft.com/
en-us/documentation/articles/virtual-workerVMs-size-specs/ .written in C# that push our analysis implementation to be as com-
pleteaspossible,intermsofhandlingtrickylanguagefeaturessuch
asdelegate ,lambdas,etc.andseetheimpactofdealingwithpoly-
morphic method invocations. In all cases, we start with a solution
ile (.sln)which referencesseveral projectiles ( .csproj), eachof
whichinturnreferences anumber of C#sourceiles( .cs).
Benchmark LOC Projects Classes Methods
X1,000 9,196 10 10 1,000
X10,000 92,157 50 50 10,000
X100,000 904,854 100 100 100,000
X1,000,000 9,005,368 100 1001,000,000
Figure 8:Informationaboutsyntheticbenchmarks.
Synthetic benchmarks: We designed a set of synthetic bench-
markstotestthescalabilityofouranalysisapproach.Thesearesolu-
tionilesgeneratedtohavetherequisitenumberofmethods(forthe
experiments, we ranged that number between 1,000 and 1,000,000).
The Figure 8 summarizes some statistics about the synthetic
projectswehaveusedforthisevaluation.Syntheticbenchmarks
weregeneratedtohavetherequisitenumberofmethods,organized
inclassesandprojectsaccordingtoamaximumpredeinednum-
ber.Eachmethodinvokesbetween1ś11othermethods,withthe
only requirement that all methods be reachable. While synthetic
programs measure the input size in a controlled way (e.g., LOCs,
methods, invocations), the real benchmarks measure the overall
complexity(e.g.,polymorphism,complex program constructs).
Real-world benchmarks: We have selected several large open-
source projects from GitHub for our analysis. A summary of infor-
mationabouttheseprogramsinshowninFigure9.Wetriedtofocus
on projects that are under active development. To illustrate, one
ofourbenchmarks,AzurePowershellisoneofthemostpopular
projectswritteninC#onGitHub.Accordingtotheprojectstatistics,
overaperiodofonemonth,51authorshavepushed280commits
to the main branch and 369 commits to all branches. There have
been342,796additionsand195,366deletions.Wepickedsolution
ResourceManager .ForRefactoringOnly .slnfrom Azure Power-
shellbecauseitistheonlyonethatcontainsalltheprojects.Gen-
erally, discovering good root methods to serve as starting points
for the call graph analysis is not trivial. Because there is no nat-
uralMainmethod in several of these projects, we have decided
to use as entry points the included unit tests,event handlers , and
otherpublicmethodswithintheprojecttoincreasethenumber
ofmethodsour analysisreaches10.
[RQ1]:Scaleswithinputsize: ToanswerRQ1, wemeasuredthe
memoryconsumptionofeachVMandcomputedtheaverageand
maximummemoryconsumptionacrossallVMs.Figure10shows
theaveragememory consumption for each benchmark during the
run, for each experimental coniguration, i.e. number of worker
VMs used. As can be observed from the chart, the memory con-
sumptiondecreasessteadilyasthenumberofworkerVMsincreases.
RecallthatworkerVMscomeequippedwith7GBofmemory,so
thesememoryconsumptionnumbersarenowherenearthatlimit.
10NotethatwedonotanalyzelibrariesprovidedasDLLs;ouranalysisimplementation
works at the source level only.
449TowardFullElasticity in DistributedStaticAnalysis: The Caseof
CallgraphAnalysis ESEC/FSE’17,September04-08,2017, Paderborn,Germany
Benchmark URL
LOC
ProjectsClasses Methods
MainTestEventhandlersPublic Total
Reachablemethods
Azure-PW https://github.com/Azure/azure-powershell 416,833 602,61823,617 0997 118,747 18,759 23,663
ShareX https://github.com/ShareX/ShareX 110,038 1182710,177 201,122 6,257 7,377 10,411
ILSpy https://github.com/icsharpcode/ILSpy 300,426 142,60625,098 1011914,343 14,498 21,944
Figure 9: Summary of information about real-world projects from GitHub. The number of reachable methods include also
library methodsinvoked by theapplication methods. Notethat someapplication methods mightnotbe reachable.
05001,0001,5002,0002,5003,0003,5004,000
1 2 4 8 1632641 2 4 8 1632644 816 326416 32641 2 4 8 16 32641 2 4 8 16 32641 2 4 8 1632 64
X1000 X10000 X100000 X1000000 Azure-PW ILSpy ShareX
Figure 10: Average memory consumption in MB, for each
benchmarkasafunctionofthenumberofworkerVMs.We
see asteadydecrease across theboard.
Looking at Figure 10, we can see peaks of about 3.2 GB for a single
worker VM whileanalyzing X1,000,00011.
These experiments naturally highlight the notion of analysis
elasticity. While we run the analysis with diferent number of VMs
setforthesakeofmeasurement,inreality,moremachineswould
be added (or removed) due to memory pressure (or lack thereof)
ortorespondtohowfullanalysisprocessingqueuesget.Wecan
similarly choose to increase (or decrease) the number of queues
anddispatchersinvolvedinefectpropagation.Itisthejobofthe
Orleans runtime to redistribute the grains to update the system
withthe newconiguration.
RQ1: capable ofhandlinginput size?
ThememoryconsumptionperworkerVMssteadilydecreasesasthenumber
of worker VMs increases.
[RQ2]: Scales with the # of worker VMs: To answer RQ2, we
proceededtomeasurethetotalelapsedanalysistimeforeachbench-
markonalltheconigurations.Figure11showstheelapsedanalysis
timenormalized by the number of methods in the input12. Note
thatthereal-worldbenchmarksshownontheright-handsideofthe
chart,despitecontainingfewermethods,requiremoretimethan
the synthetic benchmarks with 100,000 methods. This is simply
becauseoftheanalysistimethatgoesintoanalyzingmorecomplex
methodbodies.Real-worldbenchmarksallocatemoreobjectsper
method, involving more type propagation time, and perform more
virtualinvocations,addingtothemethodresolutiontime,whilethe
synthetic benchmarks only perform static invocations and allocate
11Note also that for that benchmark, we needed to use at least 16 worker VMs to
it all the methods into (their shared) memory. We needed at least 4 worker VMs
for X100,000.
12Wallclocktimes range betweenless than 1minute (64 VMs)toabout5minutes(1
VM) in ShareX and 9 to 20 minutes in ILSpy. For other benchmarks elapsed time is
tipically less than 5 minutes for 16 VMs, except X1,000,000 that takes about 1 hour (40
minutes in 64VMs). - 10 20 30 40 50 60
X1000 X10000 X100000 X1000000 Azure-PW ILSpy ShareX1 2 4 8 16 32 64
Figure 11: Elapsed analysis time in ms, as a function of the
number of worker VMs per test, normalized by the number
of reachable methods. The number of worker VMs is indi-
cated incolorinthelegendabove the igure.
relatively few objects. As the number of worker VMs increases, we
see a consistent drop in the normalized analysis times. However,
thisefectgenerallydiminishesafter16VMs.Thishastodowiththe
tension between more parallel processing power of more machines
andthe increaseinthe network overhead, as shownbelow.
Degradation due to 
increased network overheadImprovement due to 
increase parallelismBalance between parallelism 
and network overheadnumber of machinesanalysis time
Itisinstructivetofocusontheaveragenumberof(unprocessed)
messagesintheanalysisqueues.Ifthequeuesare toofull,adding
moremachineswillincreasethenumberofqueues,reducingthe
size of each one. More machines will increase the parallelism be-
cause of more dispatchers to process the messages in the new
queues. As we addmore resources, however, when the queues be-
comemostlyempty ,theirassociateddispatcherswillbemostlyidle.
So the cluster as a whole will have more computing resources than
needed.Additionally,ifmoremachinesareadded,theprobabilityof
sendingamessagetoagrainonthesamemachineasthesenderwill
be reduced, leading to more network overhead. So after reaching a
certaincut-ofpoint,addingmoremachinesisnotonlynothelping
the analysis,but startsto degrade its performance.
RQ2:doesaddingmoreworkerVMsincreaseanalysis
time?
Normalized analysis time generally decreases, as the number of worker VMs
increases,up to apoint, wherethe lawof diminishing returnskicksin.
[RQ3]: Fast enough for interactive queries: One of the goals
of our approach is to enable interactive queries submitted by an
450ESEC/FSE’17,September04-08,2017, Paderborn,Germany DiegoGarbervetsky,EdgardoZoppi, andBenjamin Livshits
Figure 12: Mean and median query time (ms) for each
workerVMsandsynthetictest.
analysisclientsuchasanIDEorasophisticatedcodeeditor.Insuch
a setting, responsiveness of such queries is paramount [ 31]. The
user is unlikely to be happy with an IDE that takes several seconds
to populatea list ofauto-completesuggestions.We wantto make
surethatasthequerytimesremaintolerable(under20ms)evenas
the size ofinputincreasesandthe number ofVMs goes up.
Toevaluatequeryperformance,we automatically generated se-
quences of 100 random queries, by repeating the following process.
We would irst pick a random method name from the list of all
methods. Then we would (1) Request the solution grain for the
correspondingmethod grain;(2) Selecta randominvocationfrom
method and request the set of potential callees. In Figure 12 we
showthemeanandmedianquerytimes(thelatencyofthetwosteps
above) for each benchmark and worker VM coniguration. Approx-
imately70%ofqueriestookunder20ms,97%under35ms,99.5%
under60 ms.Proper systemwarm-up mayreduce the outliers.
RQ3: isresponse latencysmall enough?
The query median response time is consistently between 10 and 20 ms.
IncreasingthenumberofworkerVMsandtheinputsizedoesnotnegatively
afect the queryresponsetimes.
6 RELATED WORK
There exists a wealth of related work on traditional static analysis
algorithmssuchascallgraphconstruction[ 13,14,37].Acompar-
ison of analysis precision is presented in Lhoták et al.[20]. As
mentioned, our implementation is inspired in VTA [ 36]. While we
have seendedicated attemptsto scale up important analysessuch
aspoints-tointheliterature,weareunawareofprojectsthataim
to bringcallgraph analysisto the cloud.
Manyprojectsfocusonspeedinguptheanalysisthroughparallel
computation(usuallyononemachine).Instead,welargelyfocuson
handling memory pressure when analyzing large programs. There
are two orthogonal ways to do that: 1) make compositional anal-
ysis using specs/summaries (like [ 8,38]), abstractions, compact
representations [ 40], demand-driven [ 34], and other techniques to
scale-up; 2) partition analysis memory among several machines.
Our analysis focuses on the latter by presenting an approach de-
signedtorunonastandardcluster.Theengineeringchallengesare
quitediferent,includingstatepartitioning,decentralizedcontrol,
number/sizeofmessagessent,terminationandnetwork latency.Scaling Points-to analysis: Hardekopf et al.[16] show how to
scaleupapoints-toanalysisusingastagedapproach.Theirlow-
sensitive algorithm is based on a sparse representation of program
code created by a staged, low-insensitive pointer analysis. They
cananalyze1.9MLOCprogramsinunder14minutes.Thefocus(as
alleged by the authors) is in obtaining speedups, not in reducing
memorypressure.Infact,theirlargestbenchmarkrequiredama-
chinewith100GBofmemory,whichisgenerallybeyondthereach
of most people. In contrast, we aim at analyzing large programs
inclustersoflow-costhardware.Yu etal.[42]proposeamethod
for analyzing pointers in a program level by level in terms of their
points-to levels. This strategy enhances the scalability of a context-
and low-sensitive pointer analysis and can handle some programs
with over a million lines of C code in minutes. The approach is
neither parallel non-distributed, the focus is on speedups but some
memoryissavedbytheuseofBDDs.Mendez-Lojo etal.[26]pro-
poseaparallelanalysisalgorithmforinclusion-basedpoints-toand
showaspeedupofupto3 ×onan8-coremachineoncodebases
withsizevaryingfrom53KLOCto0.5MLOC.Ourfocusisonbring-
ing our approach to the cloud using legacy machines and going
beyondmulticore,toultimatelysupportcodebasesofarbitrarysize,
not being limited by the size of main memory. Voung et al.[38]
proposeatechniquethatusesthenotionofa relativelockset ,which
allows functions to be summarized independent of the calling con-
text.This,inturn,allowsthemtoperformamodular,bottom-up
analysisthat iseasyto parallelize.Theyhave analyzed4.5 million
linesofCcodein5hours,and,afterapplyingsomeilters,found
several dozen races. Knowing which methods to group together
ahead oftime wouldhelpour actor-machine allocation as well.
Frameworks: Albarghouthi et al.[3] present a generic framework
to distribute top-down algorithms using a map-reduce strategy.
Their focus is in obtaining speed ups in analysis elapsed times;
theyadmitthatalimitingscalingfactorismemoryconsumption.
McPeaketal.[25]proposeamulticoreanalysisthatallowsthemto
handlemillionsLOCinseveralhoursonan8-coremachine.Incon-
trast,ourapproachfocusesonadistributedanalysiswithinacloud
clusteronoftenlesspowerfulhardware.Boa(Dyer etal.[10ś12])
is a domain-speciic language for mining large code repositories
likeGitHub.However,whileitusesadistributedbackend,Boais
not a static analysis. Xie et al.[41] propose a bottom-up analysis
thatbeneits fromparallelprocessing on a multicore cluster. They
relyonacentralscheduler/server,whileweuseseveralorchestra-
tors. They use method summaries while we low the data from one
method to another. Finally, we do not rely on a centralized DB,
we use grains, which can be persisted or recomputed on-the-ly as
needed. Rodriguez et al.[32] use an actor model approach in Scala
to solve interprocedural distributive subset datalow problems and
evaluateitonan8-coremachine.Ourworksharestheideaofusing
actors for analysis but they focused on speed-ups, not memory
pressure. Their approach leverages on the use of one computer
to implement a global counter to monitor the size of a (virtual)
global worklist. In contrast, we run in a cloud setting and must
deal with network latency and serialization due to distribution.
Pregel[24]isasystemforlarge-scalegraphprocessingthatusesan
asynchronous message passing model similar to actors, but execu-
tion on vertices happens in lockstep; the approach is illustrated for
451TowardFullElasticity in DistributedStaticAnalysis: The Caseof
CallgraphAnalysis ESEC/FSE’17,September04-08,2017, Paderborn,Germany
algorithms such as PageRank and shortest path computation. Gras-
pan [39], is a single-machine, disk-based parallel graph processing
system for interprocedural static analyses. Graspan ofers two ma-
jorperformanceandscalabilitybeneits:(1)thecorecomputation
oftheanalysisisautomaticallyparallelizedand(2)out-of-coredisk
support is exploited if the graph is too big to it in memory. Our
approachfocusesonacloud-basedcomputation,incontrast.Tri-
corder [33] is a cloud-based tool from Google, designed for scaling
program analysis. However, it is meant for simple, intraprocedural
analyses,not distributedwhole-program analyses.
7 CONCLUSIONS
As modern development is increasingly moving to large online
cloud-backedrepositoriessuchasGitHub,andVisualStudioOnline,
isnaturaltowonderwhatkindofanalysiscanbeperformedonlarge
bodiesofcode.Inthispaper,weexploreananalysisarchitecturein
which static analysis is executed on a distributed cluster composed
oflegacyVMs available from acommercialcloud provider.
Wepresentanstaticanalysisapproachbasedontheactormodel
anddesignedfor elasticity,i.e.toscalegracefullywiththesizeof
theinput.Todemonstratethepotentialofouranalysis,weshow
howatypicalcallgraphanalysiscanbeimplementedanddeployed
in Microsoft Azure. Our call graph analysis implementation is able
to handle inputs that are almost 10 million LOC in size. Our results
show that our analysis scales well in terms of memory pressure
independent of the input size, as we add more VMs. Despite using
stockhardwareandincurringanon-trivialcommunicationover-
head, our processing time for some of the benchmarks of close
to 1 million LOC can be about 5 minutes, excluding compilation
time.AsthenumberofanalysisVMsincreases,weshowthatthe
analysis time does not sufer. Lastly, we demonstrate that querying
the results can be performedwithamedian latency of15 ms.
As future work we plan to investigate the performance of other
instances of our distributed framework and understand the impact
ofchangingthegranularityofactors(e.g.,frombasicblockstomod-
ules).Wewanttocombinedistributedprocessingwithincremental
analysis: we are ultimately interested in deploying an Azure-based
distributed incremental analysis that can respond quickly to fre-
quentupdatesinthecoderepository.Weplantoincorporatethe
analysisintoan IDE andto alsoperform userstudies.
ACKNOWLEDGMENTS
ThisworkwaspartiallysupportedbytheprojectsANPCYTPICT
2013-2341, 2014-1656 and 2015-1718, UBACYT 20020130100384BA,
CONICET PIP11220130100688CO,11220150100931CO.
REFERENCES
[1]Representational state transfer. https://en.wikipedia.org/wiki/
Representational_state_transfer , 2015.
[2]G. Agha. Actors: A Model of Concurrent Computation in Distributed Systems . MIT
Press,1986.
[3]A. Albarghouthi, R. Kumar, A. V. Nori, and S. K. Rajamani. Parallelizing top-
downinterproceduralanalyses. In ProceedingsoftheConferenceonProgramming
Language Designand Implementation , 2012.
[4]L. O. Andersen. Program analysis and specialization for the C programming
language. PhD thesis, Universityof Cophenhagen, 1994.
[5]D.F.BaconandP.F.Sweeney. FaststaticanalysisofC++virtualfunctioncalls. In
ProceedingsoftheConferenceonObject-orientedProgramming,Systems,Languages,
and Applications , 1996.[6]P. A. Bernstein, S. Bykov, A. Geller, G. Kliot, and J. Thelin. Orleans: Distributed
virtual actors for programmability and scalability. Technical Report MSR-TR-
2014-41, Microsoft Research, 2014.
[7]J. Bornholt and E. Torlak. Scaling program synthesis by exploiting existing code.
MachineLearning for ProgrammingLanguages , 2015.
[8]C.Calcagno,D.Distefano,J.Dubreil,D.Gabi,P.Hooimeijer,M. Luca,P.OâĂŹ-
Hearn, I. Papakonstantinou, J. Purbrick, and D. Rodriguez. Moving fast with
softwareveriication. In NASAFormalMethodsSymposium ,pages3ś11.Springer,
2015.
[9]P.Cousot. Asynchronousiterativemethodsforsolvingaixedpointsystemof
monotoneequationsinacompletelattice. Technicalreport,LaboratoireIMAG,
UniversitéscientiiqueetmédicaledeGrenoble, 1977.
[10]R. Dyer, H. A. Nguyen, H. Rajan, and T. N. Nguyen. Boa: A language and
infrastructureforanalyzingultra-large-scalesoftwarerepositories. In Proceedings
ofthe InternationalConference onSoftwareEngineering . IEEE Press,2013.
[11]R. Dyer, H. Rajan, H. A. Nguyen, and T. N. Nguyen. Mining billions of ast nodes
tostudyactualandpotentialusageofJavalanguagefeatures. In Proceedingsof
the InternationalConference onSoftwareEngineering , 2014.
[12]R. Dyer, H. Rajan, and T. N. Nguyen. Declarative visitors to ease ine-grained
sourcecodemining withfullhistoryonbillionsofastnodes. In ACM SIGPLAN
Notices. ACM,2013.
[13]D. Grove and C. Chambers. A framework for call graph construction algorithms.
ACMTransactions onProgrammingLanguages and Systems , 2001.
[14]D. Grove, G. DeFouw, J. Dean, and C. Chambers. Call graph construction in
object-oriented languages. ACMSIGPLAN Notices , 1997.
[15]B.HardekopfandC.Lin. Theantandthegrasshopper:Fastandaccuratepointer
analysisformillionsoflinesofcode. In ProceedingsoftheConferenceonProgram-
mingLanguage Designand Implementation , 2007.
[16]B. Hardekopf and C. Lin. Flow-sensitive pointer analysis for millions of lines
ofcode. In ProceedingsoftheInternationalSymposiumonCodeGenerationand
Optimization , 2011.
[17]M.S.Lam,J.Whaley,B.Livshits,M.C.Martin,D.Avots,M.Carbin,andC.Unkel.
Context-sensitive program analysis as database queries. In Proceedings of the
SymposiumonPrinciples ofDatabaseSystems , June2005.
[18] J.-L. Lassez,V. Nguyen,and E. Sonenberg. Fixed pointtheorems and semantics:
Afolktale. InformationProcessingLetters , 1982.
[19]Y.Y.Lee,S.Harwell,S.Khurshid,andD.Marinov. Temporalcodecompletionand
navigation. In ProceedingsoftheInternationalConferenceonSoftwareEngineering ,
2013.
[20]O.LhotákandL.Hendren. Context-sensitivepoints-toanalysis:Isitworthit? In
Proceedingsofthe InternationalConference onCompiler Construction , 2006.
[21]B.Livshits,M.Sridharan,Y.Smaragdakis,O.Lhoták,J.N.Amaral,B.-Y.E.Chang,
S.Z.Guyer,U.P.Khedker,A.Mùller,andD.Vardoulakis. Indefenseofsoundiness:
Amanifesto. Communications ofthe ACM , 2015.
[22]N. P. Lopes and A. Rybalchenko. Distributed and predictable software model
checking. In Proceedings of the International Conference on Veriication, Model
Checking,and AbstractInterpretation , 2011.
[23]M.Madsen,B.Livshits,andM.Fanning. PracticalstaticanalysisofJavaScript
applicationsinthepresenceofframeworksandlibraries. In Proceedingsofthe
InternationalSymposiumonthe FoundationsofSoftwareEngineering , 2013.
[24]G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser, and
G. Czajkowski. Pregel: A system forlarge-scale graph processing. In Proceedings
of the ACM SIGMOD International Conference on Management of Data , SIGMOD,
2010.
[25]S.McPeak,C.-H.Gros,andM.K.Ramanathan. Scalableandincrementalsoftware
bugdetection. In ProceedingsoftheSymposiumontheFoundationsofSoftware
Engineering , 2013.
[26]M.Mendez-Lojo,A.Mathew,andK.Pingali. Parallelinclusion-basedpoints-to
analysis. In Conference on Object Oriented Programming Systems Languages and
Applications , 2010.
[27]MicrosoftCorporation. .NETCompiler Platform("Roslyn"). https://roslyn.
codeplex.com/ , 2015.
[28]Mozilla.LXR. https://en.wikipedia.org/wiki/LXR_Cross_Referencer ,
2015.
[29]K. Murray, J. P. Bigham, et al. Beyond autocomplete: Automatic function dei-
nition. In Proceedings of the Visual Languages and Human-Centric Computing
Symposium , 2011.
[30]A.T.Nguyen,T.T.Nguyen,H.A.Nguyen,A.Tamrawi,H.V.Nguyen,J.Al-Kofahi,
and T. N. Nguyen. Graph-based pattern-oriented, context-sensitive source code
completion. In ProceedingsoftheInternationalConferenceonSoftwareEngineering .
[31]C. Omar, Y. Yoon, T. D. LaToza, and B. A. Myers. Active code completion. In
Proceedingsofthe InternationalConference onSoftwareEngineering , 2012.
[32] J. Rodriguez and O. Lhoták. Actor-BasedParallel DatalowAnalysis . 2011.
[33]C. Sadowski, J. van Gogh, C. Jaspan, E. Soederberg, and C. Winter. Tricorder:
Buildinga programanalysis ecosystem. In InternationalConference onSoftware
Engineering (ICSE) , 2015.
[34]M.Sridharan,D.Gopan,L.Shan,andR.Bodík. Demand-drivenpoints-toanalysis
forjava. In Proceedingsofthe 20thAnnualACM SIGPLANConferenceonObject-
oriented Programming, Systems, Languages, and Applications , OOPSLA ’05, pages
452ESEC/FSE’17,September04-08,2017, Paderborn,Germany DiegoGarbervetsky,EdgardoZoppi, andBenjamin Livshits
59ś76, NewYork, NY, USA,2005.ACM.
[35]B. Steensgaard. Points-to analysis in almost linear time. In Proceedings of the
SymposiumonPrinciples ofProgrammingLanguages . ACM,1996.
[36]V.Sundaresan,L.Hendren,C.Razaimahefa,R.Vallée-Rai,P.Lam,E.Gagnon,and
C.Godin. Practicalvirtualmethod callresolutionfor Java. In Proceedingsofthe
ConferenceonObject-orientedProgramming,Systems,Languages,andApplications ,
2000.
[37]F.Tipand J. Palsberg. Scalable propagation-basedcallgraph construction algo-
rithms. In ProceedingsoftheConferenceonObject-orientedProgramming,Systems,
Languages, and Applications , 2000.
[38]J.W.Voung,R.Jhala,andS.Lerner. Relay:Staticracedetectiononmillionsof
lines of code. In Proceedings of the Symposium on the Foundations of Software
Engineering , 2007.[39]K.Wang,A.Hussain,Z.Zuo,G.Xu,andA.AmiriSani.Graspan:Asingle-machine
disk-basedgraphsystemforinterproceduralstaticanalysesoflarge-scalesystems
code. InProceedingsoftheInternationalConferenceonArchitecturalSupportfor
ProgrammingLanguages and OperatingSystems , 2017.
[40]J. Whaley and M. S. Lam. Cloning-based context-sensitive pointer alias analysis
using binarydecisiondiagrams. In ACMSIGPLAN Notices , volume39,2004.
[41]Y. Xie and A. Aiken. Saturn: A scalable framework for error detection using
boolean satisiability. ACMTrans. Program. Lang. Syst. , 29(3),May 2007.
[42]H. Yu, J. Xue, W. Huo, X. Feng, and Z. Zhang. Level by level: Making low-
andcontext-sensitivepointeranalysisscalableformillionsoflinesofcode. In
Proceedings of the International Symposium on Code Generation and Optimization ,
2010.
453
View publication stats