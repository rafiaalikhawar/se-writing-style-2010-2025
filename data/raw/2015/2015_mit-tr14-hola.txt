MIT Open Access Articles
Alloy*: a general-purpose higher-order relational constraint solver
The MIT Faculty has made this article openly available. Please share
how this access benefits you. Your story matters.
As Published: 10.1007/S10703-016-0267-2
Publisher: Springer Science and Business Media LLC
Persistent URL: https://hdl.handle.net/1721.1/135729
Version: Author's final manuscript: final author's manuscript post peer review, without 
publisher's formatting or copy editing
Terms of use: Creative Commons Attribution-Noncommercial-Share Alike
Alloy*: A Higher-Order Relational Constraint Solver
Aleksandar Milicevic Joseph P. Near Eunsuk Kang Daniel Jackson
Massachusetts Institute of Technology
Cambridge, MA, USA
{aleks,jnear,eskang,dnj}@csail.mit.edu
Abstract
The last decade has seen a dramatic growth in the use of
constraint solvers as a computational mechanism, not only
for analysis and synthesis of software, but also at runtime.
Solvers are available for a variety of logics but are generally
restricted to ﬁrst-order formulas. Some tasks, however, most
notably those involving synthesis, are inherently higher or-
der; these are typically handled by embedding a ﬁrst-order
solver (such as a SAT or SMT solver) in a domain-speciﬁc
algorithm.
Using strategies similar to those used in such algorithms,
we show how to extend a ﬁrst-order solver (in this case Kod-
kod, a model ﬁnder for relational logic used as the engine of
the Alloy Analyzer) so that it can handle quantiﬁcations over
higher-order structures. The resulting solver is sufﬁciently
general that it can be applied to a range of problems; it is
higher order, so that it can be applied directly, without em-
bedding in another algorithm; and it performs well enough
to be competitive with specialized tools on standard bench-
marks. Although the approach is demonstrated for a partic-
ular relational logic, the principles behind it could be ap-
plied to other ﬁrst-order solvers. Just as the identiﬁcation of
ﬁrst-order solvers as reusable backends advanced the perfor-
mance of specialized tools and simpliﬁed their architecture,
factoring out higher-order solvers may bring similar beneﬁts
to a new class of tools.
Categories and Subject Descriptors I.2.2 [ Program syn-
thesis ]; D.3.2 [ Language Classiﬁcations ]: Very high-level
languages; D.3.2 [ Language Classiﬁcation ]: Constraint
and logic languages
General Terms Logic, Higher-Order, Alloy, Languages
Keywords constraint solving; higher order logic; relational
logic; program synthesis; Alloy
1. Introduction
As constraint solvers become more capable, they are in-
creasingly being applied to problems previously regarded
as intractable. Program synthesis, for example, requires the
solver to ﬁnd a single program that computes the correct out-
put for all possible inputs. This “ ∃∀” quantiﬁer pattern is aparticularly difﬁcult instance of higher-order quantiﬁcation,
and no existing general-purpose constraint solver can reli-
ably provide solutions for problems of this form.
Instead, tools that rely on higher-order quantiﬁcation use
ad hoc methods to adapt existing solvers to the problem.
A popular technique for the program synthesis problem is
called CEGIS (counterexample guided inductive synthe-
sis) [36], and involves using a ﬁrst-order solver in a loop:
ﬁrst, to ﬁnd a candidate program, and second, to verify that
it satisﬁes the speciﬁcation for all inputs. If the veriﬁcation
step fails, the resulting counterexample is transformed into a
constraint that is used in generating the next candidate.
In this paper, we present Alloy* , a general-purpose,
higher-order, bounded constraint solver based on the Alloy
Analyzer [15]. Alloy is a speciﬁcation language combining
ﬁrst-order logic with relational algebra; the Alloy Analyzer
performs bounded analysis of Alloy speciﬁcations. Alloy*
admits higher-order quantiﬁer patterns, and uses a general
implementation of the CEGIS loop to perform bounded anal-
ysis. It retains the syntax of Alloy, and changes the seman-
tics only by expanding the set of speciﬁcations that can be
analyzed, making it easy for existing Alloy users to adopt.
To solve “∃∀” constraints, Alloy* ﬁrst ﬁnds a candidate
solution by changing the universal quantiﬁer into an exis-
tential and solving the resulting ﬁrst-order formula. Then, it
veriﬁes that candidate solution by attempting to falsify the
original universal formula (again, a ﬁrst-order problem); if
veriﬁcation fails, Alloy* adds the resulting counterexample
as a constraint to guide the search for the next candidate, and
begins again. When veriﬁcation succeeds, the candidate rep-
resents a solution to the higher-order quantiﬁcation, and can
be returned to the user.
To our knowledge, Alloy* is the ﬁrst general-purpose
constraint solver capable of solving formulas with higher-
order quantiﬁcation. Existing solvers either do not admit
these quantiﬁer patterns, or fail to produce a solution in most
cases. Alloy*, by contrast, is both sound and complete for
the given bounds. And while Alloy* is unlikely to scale
as well as purpose-built solvers for particular higher-order
applications, it uses a backend model ﬁnder that performs
incremental solving, making it more efﬁcient than naive
approaches.We have evaluated Alloy* on a variety of case studies
taken from the work of other researchers. In the ﬁrst, we
used Alloy* to solve classical higher-order NP-complete
graph problems like max-clique , and found it to scale well
enough for uses in teaching, fast prototyping, modeling, and
bounded veriﬁcation. In the second, we encoded a subset of
the SyGuS [3] program synthesis benchmarks, and found
that, while state-of-the-art synthesis engines are faster, Al-
loy* at least beats all the reference synthesizers provided by
the competition organizers.
The contributions of this paper include:
•The recognition of higher-order solving as the essence of
a range of computational tasks, including synthesis;
•A framework for extending a ﬁrst-order solver to the
higher-order case, consisting of the design of datatypes
and a general algorithm comprising syntactic transfor-
mations (skolemization, conversion to negation normal
form, etc.) and an incremental solving strategy;
•A collection of case study applications demonstrating the
feasibility of the approach in different domains (includ-
ing synthesis of access control policies, synthesis of code,
execution of NP-hard algorithms, and bounded veriﬁca-
tion of higher-order models), and showing encouraging
performance on standard benchmarks;
•The release of a freely available implementation for oth-
ers to use, comprising an extension of Alloy [1].
2. Examples
2.1 Classical Graph Algorithms
Classical graph algorithms have become prototypical Alloy
examples, showcasing both the expressiveness of the Alloy
language and the power of the Alloy Analyzer. Many com-
plex problems can be speciﬁed declaratively in only a few
lines of Alloy, and then in a matter of seconds fully automat-
ically animated (for graphs of small size) by the Alloy An-
alyzer. This ability to succinctly specify and quickly solve
problems like these—algorithms that would be difﬁcult and
time consuming to implement imperatively using traditional
programming languages—has found its use in many applica-
tions, including program veriﬁcation [8, 12], software test-
ing [24, 31], fast prototyping [25, 32], as well as teach-
ing [10].
For a whole category of interesting problems, however,
the current Alloy engine is not powerful enough. Those are
the higher-order problems, for which the speciﬁcation has to
quantify over relations rather than scalars. Many well-known
graph algorithms fall into this category, including ﬁnding
maximum cliques, max cuts, minimum vertex covers, and
various coloring problems. In this section, we show such
graph algorithms can be speciﬁed and analyzed using the
new engine implemented in Alloy*.Suppose we want to check Turán’s theorem, one of the
fundamental results in graph theory [2]. Turán’s theorem
states that a ( k+1)-free graph with nnodes can maximally
have(k−1)n2
2kedges. A graph is ( k+1)-free if it contains no
clique withk+1nodes (a clique is a subset of nodes in which
every two nodes are connected by an edge).
Figure 1 shows how Turán’s theorem might be formally
speciﬁed in Alloy. First, a signature is deﬁned to represent
the nodes of the graph (line 1). Next, the clique property is
embodied in a predicate (lines 3–5): for a given edge rela-
tion and a set of nodes clq, it asserts that every two different
nodes in clqare connected by an edge; the maxClique pred-
icate (lines 7–10) additionally asserts that no other clique
contains more nodes.
Having deﬁned maximum cliques in Alloy, we can pro-
ceed to formalize Turán’s theorem. The Turan command
(lines 16–23) asserts that for all possible edge relations that
are symmetric and irreﬂexive (line 17), if the max-clique in
that graph has knodes ( k=#mClq ), the number of selected
edges ( e=(#edges).div [2]) must be at most(k−1)n2
2k(the
number of tuples in edges is divided by 2 because the graph
in setup of the theorem in undirected).
Running the Turan command was previously not possible.
Although the speciﬁcation, as given in Figure 1, is allowed
by the Alloy language, trying to execute it causes the An-
alyzer to immediately return an error: “Analysis cannot be
performed since it requires higher-order quantiﬁcation that
could not be skolemized”. In Alloy*, in contrast, this check
can be automatically performed to conﬁrm that indeed no
counterexample can be found within the speciﬁed scope. The
scope we used (7 nodes, ints from 0 to 294) allows for all
possible undirected graphs with up to 7 nodes. The upper
bound for ints was chosen so that it ensures that the formula
for computing the maximal number of edges ((k−1)n2
2k) never
overﬂows for n≤7(which implies k≤7). The check com-
pletes in about 100 seconds.
To explain the analysis problems that higher-order quan-
tiﬁers pose to the standard Alloy Analyzer, and how those
problems are tackled in Alloy*, we look at a simpler task:
ﬁnding an instance of a graph with a subgraph satisfying the
maxClique predicate. The problematic quantiﬁer in this case
is the inner “ noclq2: set Node |:::” constraint, which re-
quires checking that for all possible subsets of Node, not one
of them is a clique with more nodes than the given set clq.
A direct translation into propositional logic (and the current
SAT-based backend) would require the Analyzer to explic-
itly, and upfront, enumerate all possible subsets of Node—
which would be prohibitively expensive. Instead, Alloy*
implements the CEGIS approach. To satisfy the maxClique
predicate, Alloy* proceeds in the following steps:
1. First, it ﬁnds a candidate instance, by searching for a
clique clqandonly one set of nodes clq2 thatis not a
clique larger than clq. A possible ﬁrst candidate is given
in Figure 2(a) (the clique nodes are highlighted in green).1some sig Node {}
2// between every two nodes there is an edge
3pred clique [edges: Node -> Node, clq: set Node ] {
4 all disj n1, n2: clq |n1 -> n2 inedges
5}
6// no other clique with more nodes
7pred maxClique [edges: Node -> Node, clq: set Node ] {
8 clique [edges, clq ]
9 noclq2: set Node |clq2!=clq and clique [edges,clq2 ] and #clq2>#clq
10 }
11 // symmetric and irreflexive
12 pred edgeProps [edges: Node -> Node ] {
13 (~edges inedges) and (noedges & iden )
14 }
15 // max number of edges in a ( k+1)-free graph with nnodes is(k−1)n2
2k
16 check Turan {
17 all edges: Node -> Node |edgeProps [edges ] implies
18 some mClq: set Node {
19 maxClique [edges, mClq ]
20 let n = #Node, k = #mClq, e = (#edges).div [2] |
21 e <= k.minus [1].mul [n].mul [n].div [2].div [k]
22 }
23 } for 7but 0..294 Int
Figure 1. Speciﬁcation of Turan’s theorem for automatic check-
ing in Alloy*.(a) A maxClique candidate
 (b) A counterexample for (a)
(c) Final maxClique instance
 (d) A maxMaxClique instance
Figure 2. Automatically generated sample instances satisfying
themaxClique andmaxMaxClique predicates.
At this point clq2 could have been anything that is either
not a clique or not larger than clq.
2. Next, Alloy* attempts to falsify the previous candidate
by ﬁnding, again, only one set of nodes clq2, but this
time such that clq2 isa clique in larger than clq, for the
exact (concrete) graph found in the previous step. In this
case, it ﬁnds one such counterexample clique (red nodes
in Figure 2(b)) refuting the proposition that clqfrom the
ﬁrst step is a maximum clique.
3. Alloy* continues by trying to ﬁnd another candidate
clique, encoding the knowledge gained from the previous
counterexample (explained in more detail in Section 3
and 4) to prune the remainder of the search space. After a
couple of iterations, it ﬁnds the candidate in Figure 2(c)
which cannot be refuted, so it returns that candidate as a
satisfying solution.
Alloy* handles higher-order quantiﬁers in a generic and
model-agnostic way, meaning that it allows higher-order
quantiﬁers to appear anywhere where allowed by the Al-
loy syntax, and does not require any special idiom to be fol-
lowed. Once written, the maxClique predicate (despite con-
taining a higher-order quantiﬁcation) can be used in other
parts of the model, like any other predicate, just as we used
it to formulate and check Turán’s theorem.
Using a higher-order predicate inside another higher-
order predicate is also possible. It might not be obvious that
theTuran check contains nested higher-order quantiﬁers, so
a simpler example would be ﬁnding a max clique with a
maximum sum of node values:
sig Node {val: one Int }
// Auxiliary function: returns the sum of all node values
fun valsum [nodes: set Node ]:Int { sum n: nodes |n.val }
// ’clq’ is a max clique with maximum sum of node values
pred maxMaxClique [edges: Node -> Node, clq: set Node ] {maxClique [edges, clq ]
noclq2: set Node |
clq2!=clq and maxClique [edges,clq ] and valsum [clq2 ]>valsum [clq]
}
run maxMaxClique for 5
Running the maxMaxClique command spawns 2 nested CEGIS
loops; every candidate instance and counterexample gener-
ated in the process can be opened and inspected in the stan-
dard Alloy visualizer. A sample generated instance is shown
in Figure 2(d).
2.2 Policy Synthesis
Policy design and analysis is an active area of research. A
number of existing tools [11, 14, 27, 33] use a declarative
language to specify policies, and a constraint-based analysis
to verify them against a high-level property. In this section,
we demonstrate how Alloy* can be used to automatically
synthesize a policy that satisﬁes given properties.
Figure 3 shows an Alloy model that describes the problem
of grade assignment at a university, based on the running ex-
ample from [11]. A policy speciﬁcation contains three basic
concepts: roles ,actions , and resources . A system consists of
a set of users, each having one or more roles and performing
some actions on a set of resources. A policy (acl) is a set of
tuples from Role toAction toResource , describing a set of
allowed actions. For example, a policy containing only a sin-
gle tuple Faculty->Assign->ExtGrade means that a user may
assign an external grade only if it has the Faculty role.
There are two desirable properties over this system: (1)
students should not be able to assign external grades, and (2)
no user should be able to both assign and receive external
grades. A policy is considered valid if and only if, when
quantiﬁed over every possible combination of user roles and
behaviors, it ensures that the properties hold. This higher-
order property is encoded in the valid predicate.Running Alloy* to search for an instance satisfying the
valid predicate completes in about 0.5 seconds, and retuns
anempty policy, which is technically valid but not very use-
ful (since it allows no actions to be performed by anyone!).
Fortunately, we can leverage the higher-order featur of Al-
loy* to synthesize more interesting policies. For example,
3 additional lines of Alloy are enough to describe the most
permissive policy as a policy that is valid such that no other
valid policy has more tuples in it (lines 39–41). It takes about
3.5 seconds to generate one such policy:
{Faculty,Receive,ExtGrade}, {Faculty,Assign,Resource},
{Student,Receive,Resource}, {Student,Assign,IntGrade},
{TA,Receive,Resource}, {TA,Assign,IntGrade}
This policy provides a starting point for further exploration
of the policy space. The designer may decide, for example,
that students should not be able to assign IntGrade , add
another property, and then repeat the synthesis process.
1/*Basic signatures */
2abstract sig Resource {}
3abstract sig Action {}abstract sig Role {}
sig User {}
5/*’performs’ describes the behavior of users */
6pred enforce [acl: Role->Action->Resource,
7 roles: User->Role,
8 performs: User->Action->Resource ] {
9 all u: User, a: Action, r: Resource |
10 /*’u’ can perform ’a’ on ’r’ only if allowed by ’acl’ */
11 u->a->r inperforms => ( some ro: u.roles |ro->a->r inacl)
12 }
13 /*Domain-specific concepts */
14 one sig Faculty, Student, TA extends Role {}
15 one sig IntGrade, ExtGrade extends Resource {}
16 one sig Assign, Receive extends Action {}
17 /*Properties */
18 pred prop1 [roles : User->Role, performs : User->Action->Resource ] {
19 /*no student can assign external grade */
20 nou: User |u.roles = Student and Assign->ExtGrade inu.performs
21 }
22 pred prop2 [roles : User->Role, performs : User->Action->Resource ] {
23 /*no user can both receive and assign external grades */
24 nou: User |Assign + Receive inu.performs.ExtGrade
25 }
26 /*Assumption: no user can both be a faculty and a student/TA */
27 pred noDualRoles [roles : User->Role ] {
28 nou: User |Faculty inu.roles and some (Student + TA) & u.roles
29 }
30 /*’acl’ satisfies properties over every user role and behavior */
31 pred valid [acl: Role->Action->Resource ] {
32 all roles: User->Role, performs : User->Action->Resource |
33 (enforce [acl, roles, performs ] and noDualRoles [roles ])implies
34 (prop1 [roles, performs ] and prop2 [roles, performs ])
35 }
36 /*’acl’ allows the most number of actions while being valid */
37 pred mostPermissive [acl: Role->Action->Resource ] {
38 valid [acl]
39 noacl’: Role->Action->Resource |
40 acl != acl’ and valid [acl’ ] and #acl’ > #acl
41 }
Figure 3. Grade Assignment Policy in Alloy*
3. Background and Key Ideas
Skolemization Many ﬁrst-order constraint solvers allow
some form of higher-order quantiﬁers to appear at the lan-
guage level. Part of the reason for this is that, in certain
cases, quantiﬁers can be eliminated in a preprocessing stepcalled skolemization . In a model ﬁnding setting, every top-
level existential quantiﬁer is eliminated by (1) introducing
askolem constant for the quantiﬁcation variable, and (2)
replacing every occurrence of that variable with the newly
created skolem constant. For example, solving the following
higher-order formula
some s:set univ | #s > 2
means ﬁnding one set swith more than 2 elements, i.e.,
$sin univ && #$s > 2 ,
which is ﬁrst-order and thus solvable by general purpose
constraint solvers. (Throughout, following the convention of
the Alloy Analyzer, skolem constants will be identiﬁed with
a dollar sign as a preﬁx.)
CEGIS CounterExample-Guided Inductive Synthesis [36]
is an approach for solving higher-order synthesis problems,
which is extended in Alloy* to the general problem of solv-
ing higher-order formulas. The goal of CEGIS is to ﬁnd one
instance (e.g., a program) that satisﬁes some property for all
possible environments (e.g., input values):
some p: Program | all env: Var-> Int | spec [p, env ].
Step 1: Search. Since this formula is not immediately
solvable by today’s state-of-the-art solvers, the CEGIS strat-
egy is to ﬁrst ﬁnd a candidate program and oneenvironment
for which the property holds:
some p: Program | some env: Var-> Int | spec [p, env ].
This formula is amenable to automated ﬁrst-order constraint
solving, as both quantiﬁers can now be skolemized.
Step 2: Veriﬁcation. If a candidate is found, the next step
is to check whether that candidate might actually satisfy the
speciﬁcation for all possible environments. The veriﬁcation
condition, thus, becomes
all env: Var-> Int | spec [$p, env ].
The outer quantiﬁer from the previous step ( some p: Program )
is not present in this formulation, because the veriﬁcation
condition is to be checked for exactly the candidate program
generated in Step 1 (the concrete program $p). This check
is typically done by refutation, that is, by trying to ﬁnd a
counterexample for which the veriﬁcation condition does
not hold. Negating the veriﬁcation condition and pushing
the negation through to the leaf nodes changes the quantiﬁer
from alltosome, which becomes skolemizable, resulting in
a ﬁrst order formula that is now easily solved:
some env: Var-> Int | not spec [$p, env ]
Step 3: Induction. The previous step either veriﬁes the
candidate or returns a counterexample—a concrete environ-
ment for which the program does not satisfy the spec. In-
stead of simply continuing the search for some other can-
didate program and repeating the whole procedure, a key
idea behind the CEGIS method is adding an encoding of the
counterexample to the original candidate condition:some p: Program | some env: Var-> Int |
spec [p, env ] && spec [p, $env _cex]
Consequently, all subsequent candidate programs will have
to satisfy the spec for the concrete environment $env _cex.
This strategy in particular tends to be very effective at reduc-
ing the search space and improving the overall scalability.
CEGIS for a general purpose solver. Existing CEGIS-
based synthesis tools implement this strategy internally, op-
timizing for the target domain of synthesis problems. A key
insight of this paper is that the CEGIS strategy can be
implemented, generically and efﬁciently, inside a general
purpose constraint solver . For an efﬁcient implementation,
however, it is important that such a solver be optimized with
the following features:
•Partial Instances . The veriﬁcation step requires that the
veriﬁcation condition be solved against the previously
discovered candidate; being able to explicitly set that can-
didate as a part of the solution to the veriﬁcation problem
known upfront (i.e., as a “partial instance”) tends to be
signiﬁcantly more efﬁcient than encoding the candidate
with constraints [40].
•Incremental solving . Except for one additional constraint,
the induction step solves exactly the same formula as the
search step. Many modern SAT solvers already allow new
constraints to be added to already solved propositional
formulas, making subsequent runs more efﬁcient (be-
cause all previously learned clauses are readily reusable).
•Atoms as expressions . The induction step needs to be
able to convert a concrete counterexample (given in terms
of concrete atoms, i.e., values for each variable) to a
formula to be added to the candidate search condition. All
atoms, therefore, must be convertible to expressions. This
is trivial for SAT solvers, but requires extra functionality
for solvers offering a richer input language.
•Skolemization . Skolemizing higher-order existential quan-
tiﬁers is necessary for all three CEGIS steps.
We formalize our approach in Section 4, assuming availabil-
ity of a ﬁrst-order constraint solver offering all the features
above. In Section 5 we present our implementation as an
extension to Kodkod [38] (a ﬁrst-order relational constraint
solver already equipped with most of the required features).
4. Semantics
We give the semantics of our decision procedure for bounded
higher-order logic (as implemented in Alloy*) in two steps.
First, we formalize the translation of a boolean (possibly
higher-order) formula into a Proc datatype instance (corre-
sponding to an appropriate solving strategy); next we for-
malize the semantics of Proc satisﬁability solving.
Figure 4 gives an overview of all syntactic domains used
throughout this section. We assume the datatypes in Fig-(a) Alloy* syntactic domains
QP =QP(forAll : Quant, pExists : Proc)
Proc =FOL( form : Formula)
|OR(disjs: Proc[])
|EA(conj: FOL, qps: QP[])
(b) Solver data types
Mult =ONE | SET
Decl =Decl( mult: Mult, var: Expr)
QuantOp =∀|∃
BinOp =∧|∨|⇐⇒ |/Leftrightline⇒
Formula =Quant( op: QuantOp, decl: Decl, body : Formula)
|BinForm( op: BinOp, lhs,rhs: Formula)
|NotForm( form : Formula)
|...
Expr =... // relational expressions, irrelevant here
Figure 4. Overview of the syntactic domains.
(a) Semantic functions
T:Formula →Proc top-level formula translation
S:Proc→Instance Proc evaluation (solving)
:Formula →Proc intermediate formula translation
⋏:Proc→Proc→Proc Proc composition: conjunction
⋎:Proc→Proc→Proc Proc composition: disjunction
(b) Functions exported by ﬁrst-order solver
solve :Formula →Instance option ﬁrst-order solver
eval :Instance →Expr→Value evaluator
replace :Formula →Expr→Value→Formula
nnf :Formula →Formula NNF conversion
skolemize :Formula →Formula skolemization
∧ :Formula →Formula →Formula conjunction
∨ :Formula →Formula →Formula disjunction
TRUE :Formula true formula
FALSE :Formula false formula
(c) Built-in functions
fold :(A→E→A)→A→E[]→A functional fold
reduce :(A→E→A)→E[]→A fold w/o init value
map :(E→T)→E[]→T[] functional map
length :E[]→int list length
hd :E[]→E list head
tl :E[]→E[] list tail
+ :E[]→E[]→E[] list concatenation
× :E[]→E[]→E[] list cross product
fail :String →void runtime error
Figure 5. Overview of used functions: (a) semantic functions, (b)
functions provided by the ﬁrst-order solver, (c) built-in functions.
ure 4(b) are provided by the solver; on top of these basic
datatypes, Alloy* deﬁnes the following additional datatypes:
•FOL—a wrapper for a ﬁrst-order formula that can be
solved in one step by the solver;
•OR—a composite type representing a disjunction of Proc s;•EA—a composite type representing a conjunction of a
ﬁrst-order formula and a number of higher-order univer-
sal quantiﬁers (each enclosed in a QPdatatype). The in-
tention of the QPdatatype is to hold the original univer-
sally quantiﬁed formula (the forAll ﬁeld), and a transla-
tion of the same formula but quantiﬁed existentially (the
pExists ﬁeld); the latter is later used to ﬁnd candidate so-
lutions (formalized in Section 4.2).
Figure 5(a) lists all the semantic functions deﬁned in
this paper. The main two are translation of formulas into
Proc s (T, deﬁned in Figure 6) and satisﬁability solving
(S, deﬁned in Figure 7). Relevant functions exported by
the solver are given in Figure 5(b), while other functions,
assumed to be provided by the host programming language,
are summarized in Figures 5(c).
For simplicity of exposition, we decided to exclude the
treatment of bounds from our formalization, as it tends to
be mostly straightforward; we will, however, come back
to this point and accurately describe how the bounds are
constructed before a solver invocation.
Syntax note. Our notation is reminiscent of ML. We use
the “.” syntax to refer to ﬁeld values of datatype instances.
If the left-hand side in such constructs resolves to a list, we
assume the operation is mapped over the entire list (e.g.,
ea.qps.forAll , is equivalent to mapq⋅q:forAll;ea.qps).
4.1 Translation of Formulas into Proc Objects
The top-level translation function ( T, Figure 6, line 1) en-
sures that the formula is converted to Negation Normal Form
(NNF), and that all top-level existential quantiﬁers are sub-
sequently skolemized away, before the formula is passed to
thefunction. Conversion to NNF pushes the quantiﬁers
towards the roots of the formula, while skolemization elim-
inates top-level existential quantiﬁers (including the higher-
order ones). Alloy* aggressively uses these techniques to
achieve completeness in handling arbitrary formulas.
Translating a binary formula (which must be either a con-
junction or disjunction, since it is in NNF) involves translat-
ing both left-hand and right-hand sides and composing the
resulting Proc s using the corresponding composition opera-
tor (⋏for conjunction, and ⋎for disjunction, lines 2–3). An
important difference between the two cases, however, is that
a disjunction demands that both sides be skolemized again
(thus the use of Tinstead of), since they were surely un-
reachable by any previous skolemization attempts. This en-
sures that any higher-order quantiﬁers found in a clause of a
disjunction will eventually either be skolemized or converted
to an EAProc .
A ﬁrst-order universal quantiﬁer (determined by d.mult
being equal to ONE) whose body is also ﬁrst-order (line 6)
is simply enclosed in a FOL Proc (line 7). Otherwise, an
EAProc is returned, wrapping both the original formula
(∀d /divides.alt0f) and the translation of its existential counterpart
(p=TJ∃d /divides.alt0fK). The existential version is later used to ﬁndT:Formula →Proc
1.TJfK≡Jskolemize nnf fK
:Formula →Proc
2.Jf1∨f2K≡TJf1K⋎TJf2K
3.Jf1∧f2K≡Jf1K⋏Jf2K
4.J∃d/divides.alt0fK≡fail“can’t happen ”
5.J∀d/divides.alt0fK≡let p=TJ∃d/divides.alt0fKin
6. ifd.mult isONE && pisFOL then
7. FOL(∀d/divides.alt0f)
8. else
9. EA(FOL(TRUE );[QP(∀d/divides.alt0f;p)])
10.JfK≡FOL(f)
⋏:Proc→Proc→Proc
11.p1⋏p2≡matchp1; p2with
12.|FOL, FOL →FOL(p1.form∧p2.form)
13.|FOL, OR →OR(mapp⋅p1⋏p; p 2.disjs)
14.|FOL, EA→EA(p1⋏p2.conj; p2.qps)
15.|OR , OR →OR(mapp;q⋅p⋏q; p 1.disjs×p2.disjs)
16.|OR , EA→OR(mapp⋅p⋏p1; p 1.disjs)
17.|EA,EA→EA(p1.conj⋏p2.conj; p1.qps+p2.qps)
18.|_,_→p2⋏p1
⋎:Proc→Proc→Proc
19.p1⋎p2≡matchp1; p2with
20.|FOL, FOL →FOL(p1.form∨p2.form)
21.|FOL, OR →OR(mapp⋅p1⋎p; p 2.disjs)
22.|FOL, EA→OR([p1; p2])
23.|OR , OR →OR(p1.disjs+p2.disjs)
24.|OR , EA→OR(p1.disjs+[p2])
25.|EA,EA→OR([p1; p2])
26.|_,_→p2⋎p1
Figure 6. Translation of boolean Formula s toProc s.
candidate solutions (which satisfy the body for some binding
ford), whereas the original formula is needed when check-
ing whether generated candidates also satisfy the property
forallpossible bindings (i.e., the veriﬁcation condition).
In all other cases, the formula is wrapped in FOL(line 10).
4.1.1 Composition of Proc s
Composition of Proc s is straightforward for the most part,
directly following the distributivity laws of conjunction over
disjunction and vice versa. The common goal in all the cases
in lines 11–26 is to reduce the number of Proc nodes. For
example, instead of creating an ORnode for a disjunction
of two ﬁrst-order formulas (line 20), a FOLnode is created
containing a disjunction of the two. Other interesting cases
involve the EAProc . A conjunction of two EAnodes can be
merged into a single EAnode (line 17), as can a conjunction
of a FOLand an EAnode (line 14). A disjunction involving
anEAnode always results in the creation of a new ORnode.S:Proc→Instance option
27.SJpK≡matchpwith
28. |FOL→solvep.form
29. |OR→iflengthp.disjs = 0 then None else match SJhdp.disjsKwith
30. |None →SJOR(tlp.disjs)K
31. |Some( inst)→Some( inst)
32. |EA→letpcand =fold⋏; p.conj; p.qps.pExists in
33. match SJpcand Kwith
34. |None →None
35. |Some( cand )→letfcheck =fold∧;TRUE; p.qps.forAll in
36. match SJTJ¬fcheck KKwith
37. |None →Some( cand )
38. |Some( cex)→fun repl( q)=replace (q.body;q.decl.var;eval(cex;q.decl.var))
39. letf∗
cex=map repl; p.qps.forAll in
40. letfcex=fold∧;TRUE; f∗
cexin
41. SJpcand⋏TJfcexKK
Figure 7. Satisﬁability solving for different Proc s. The resulting Instance object encodes the solution, if one is found.
4.2 Satisﬁability Solving
The procedure for satisﬁability solving is given in Figure 7.
A ﬁrst-order formula (enclosed in FOL) is given to the
solver to be solved directly, in one step (line 28).
AnOR Proc is solved by iteratively solving its disjuncts
(lines 29–31). An instance is returned as soon as one is
found; otherwise, None is returned.
The procedure for the EAProc s implements the CEGIS
loop (lines 32–41). The candidate search condition is a con-
junction of the ﬁrst-order p.conjProc and all the existential
Proc s fromp.qps.pExists (line 32). If solving the candidate
condition returns no instance, the formula as a whole is un-
satisﬁable (line 34). If a candidate is found, the procedure
checks whether that candidate actually satisﬁes all possible
bindings for the involved quantiﬁers. The veriﬁcation condi-
tion (fcheck ) becomes a conjunction of all original universal
quantiﬁers within this EA(line 35). The procedure proceeds
by trying to refute this proposition, that is, by attempting to
satisfy the negation of the veriﬁcation condition (line 36). If
the refutation step is unsuccessful (line 37), the previously
discovered candidate is returned as a satisfying instance for
the formula as a whole; otherwise, the search continues by
asking for another candidate which additionally satisﬁes the
returned counterexample (line 41). Encoding the counterex-
ample into a formula boils down to obtaining a concrete
value that each quantiﬁcation variable has in that counterex-
ample (by means of calling the evalfunction exported by the
solver) and embedding that value directly in the body of the
corresponding quantiﬁer (lines 38-40).
4.3 Treatment of Bounds
Bounds are a required input of any bounded analysis; for
an analysis involving structures, the bounds may include not
only the cardinality of the structures, but may also indicate
that a structure includes or excludes particular tuples. Suchbounds serve not only to ﬁnitize the universe of discourse
and the domain of each variable, but may also specify a
partial instance that embodies information known upfront
about the solution to the constraint. If supported by the
solver, specifying the partial instance through bounds (as
opposed to enforcing it with constraints) is an important
mechanism that generally improves scalability signiﬁcantly.
Although essential, the treatment of bounds in Alloy* is
mostly straightforward—including it in the above formaliza-
tion (Figures 6 and 7) would only clutter the presentation
and obscure the semantics of our approach. Instead, we in-
formally (but precisely) provide the relevant details in the
rest of this section.
Bounds may change during the translation phase by
means of skolemization: every time an existential quantiﬁer
is skolemized, a fresh variable is introduced for the quantiﬁ-
cation variable and a bound for it is added. Therefore, we
associate bounds with Proc s, as different Proc s may have
different bounds. Whenever a composition of two Proc s is
performed, the resulting Proc gets the union of the two cor-
responding bounds.
During the solving phase, whenever the solve function is
applied (line 28), bounds must be provided as an argument—
we simply use the bounds associated with the input Proc in-
stance (p). When supplying bounds for the translation of the
veriﬁcation condition ( TJ¬fcheck K, line 36), it is essential
to encode the candidate solution ( cand ) as a partial instance,
to ensure that the check is performed against that particular
candidate, and not some other arbitrary one. That is done by
bounding every variable from p.bounds to the exact value it
was given in cand :
fun add_bound(b;var )=b+r/uni21A6eval(cand; var )
bcheck =fold add_bound; p: bounds; p: bounds:variables
Finally, when translating the formula obtained from the
counterexample ( fcex) to be used in a search for the nextcandidate (line 41), the same bounds are used as for the
current candidate ( pcand.bounds ).
5. Implementation
We implemented our decision procedure for higher-order
constraint solving as an extension to Kodkod [38]. Kodkod,
the backend engine used by the Alloy Analyzer, is a bounded
constraint solver for relational ﬁrst-order logic (thus, ‘vari-
able’, as used previously, translates to ‘relation’ in Kodkod,
and ‘value’ translates to ‘tuple set’). It works by translating
a given relational formula (together with bounds ﬁnitizing
relation domains) into an equisatisﬁable propositional for-
mula and using an of-the-shelf SAT solver to check its satis-
ﬁability. The Alloy Analyzer delegates all its model ﬁnding
(constraint solving) tasks to Kodkod. No change was needed
to the Alloy Analyzer’s existing translation from the Al-
loy modeling language to the intermediate logic of Kodkod;
loosening Kodkod’s restrictions on higher-order quantiﬁca-
tion exposes the new functionality immediately at the level
of Alloy models.
The ofﬁcial Kodkod distribution already offers most of
the required features identiﬁed in Section 3. While efﬁ-
cient support for partial instances has always been an in-
tegral part of Kodkod, only the latest version (2.0) comes
with incremental SAT solvers and allows new relational con-
straints, as well as new relations, to be added incrementally
to previously solved problems. By default, Kodkod performs
skolemization of top-level existential quantiﬁers (including
higher-order ones); the semantics of our translation from
boolean formulas to Proc s ensures that all quantiﬁers, re-
gardless of their position in the formula, eventually get pro-
moted to the top level, where they will be subject to skolem-
ization.
Conversion from atoms to expressions, however, was not
available in Kodkod prior to this work. Kodkod imposes
a strict separation between the two abstractions; doing so
allows it to treat all atoms from a single relation domain as
indistinguishable from each other, which helps generate a
stronger symmetry-breaking predicate. Since encoding each
counterexample back to the candidate condition is absolutely
crucial for CEGIS to scale, we extended Kodkod with the
ability to create a singleton relation for each declared atom,
after which converting atoms back to expressions (relations)
becomes trivial. We also updated the symmetry-breaking
predicate generator to ignore all such singleton relations
that are not used in the formula being solved. As a result,
this modiﬁcation does not seem to incur any performance
overhead; we ran the existing Kodkod test suite with and
without the modiﬁcation and observed no time difference (in
both cases the total time it took to run 249 tests was around
230s).
Aside from the fact that it is written in Java, our imple-
mentation directly follows the semantics deﬁned in Figures 6
and 7. Additionally, it performs the following important op-timizations: (1) the constructor for ORdata type ﬁnds all FOL
Proc s in the list of received disjuncts and merges them into
one, and (2) it uses incremental solving to implement line 41
from Figure 7 whenever possible.
6. Case Study: Program Synthesis
Program synthesis is one of the most popular applications of
higher-order constraint solving. The goal of program synthe-
sis is to produce a program that satisﬁes a given (high-level)
speciﬁcation. Synthesizers typically also require a loose def-
inition of the target program’s structure, and most use an ad
hoc CEGIS loop relying on an off-the-shelf ﬁrst-order con-
straint solver to generate and verify candidate programs.
The SyGuS [3] (syntax-guided synthesis) project has pro-
posed an extension to SMTLIB for encoding program syn-
thesis problems. The project has also organized a competi-
tion between solvers for the format, and provides three ref-
erence solvers for testing purposes.
We encoded a subset of the SyGuS benchmarks in Al-
loy* to test its scalability. These benchmarks have a standard
format, are well tested, and allow comparison to the perfor-
mance of the reference solvers, making them a good target
for evaluating Alloy*. We found that Alloy* scales better
than all three of the reference solvers.
6.1 Example Encoding
To demonstrate our strategy for encoding program synthesis
problems in Alloy*, we present the Alloy* speciﬁcation for
the problem of ﬁnding a program to compute the maximum
of two numbers (the max-2 benchmark). The original SyGuS
encoding of the benchmark is reproduced in Figure 8.
(synth-fun max2 ((x Int) (y Int)) Int
((Start Int (x y 0 1 (+ Start Start) (- Start Start)
(ite StartBool Start Start)))
(StartBool Bool ((and StartBool StartBool)(or StartBool StartBool)
(not StartBool)
(<= Start Start)(= Start Start)(>= Start Start)))))
(declare-var x Int)
(declare-var y Int)
(constraint (>= (max2 x y) x))
(constraint (>= (max2 x y) y))
(constraint (or (= x (max2 x y)) (= y (max2 x y))))
Figure 8. max-2 benchmark from the SyGuS project.
We encode the max-2 benchmark in Alloy* using signa-
tures to represent the production rules of the program gram-
mar, and predicates to represent both the semantics of pro-
grams and the constraints restricting the target program’s se-
mantics. Programs are composed of abstract syntax nodes,
which can be integer- or boolean-typed.
abstract sig Node {}
abstract sig IntNode, BoolNode extends Node {}
abstract sig Var extends IntNode {}
one sig X, Y extends Var {}
sig ITE extends IntNode {
condition: BoolNode,
then, elsen: IntNode,
}sig GTE extends BoolNode {
left, right: IntNode
}Integer-typed nodes include variables and if-then-else ex-
pressions, while boolean-typed nodes include greater-than-
or-equal expressions. Programs in this space evaluate to in-
tegers or booleans; integers are built into Alloy, but we must
model boolean values ourselves.
abstract sig Bool {}
one sig BoolTrue, BoolFalse extends Bool {}
The standard evaluation semantics of these programs can
be encoded in a predicate that constrains the evaluation re-
lation. It works by constraining all compound syntax tree
nodes based on the results of evaluating their children, but
does not constrain the values of variables, allowing them to
range over all values.
pred semantics [eval: Node -> ( Int + Bool) ] {
all n: ITE |
eval [n] in Int and
eval [n.condition ]= BoolTrue implies
eval [n.then ]= eval [n] else eval [n.elsen ]= eval [n]
all n: GTE |
eval [n] in Bool and
eval [n.left ]>= eval [n.right ] implies
eval [n]= BoolTrue else eval [n]= BoolFalse
all v: Var | one eval [v] and eval [v] in Int
}
The program speciﬁcation says that the maximum of two
numbers is greater than or equal to both numbers, and that
the result is one of the two.
pred spec [root: Node, eval: Node -> ( Int + Bool) ] {
(eval [root ]>= eval [X] and eval [root ]>= eval [Y])and
(eval [root ]= eval [X] or eval [root ]= eval [Y])
}
Finally, the problem itself requires solving for some ab-
stract syntax tree such that for all valid evaluation relations
(i.e. all possible valuations for the variables), the speciﬁca-
tion holds.
pred synth [root: IntNode ] {
all eval: Node -> ( Int + Bool) |
semantics [eval ] implies spec [root, eval ]
}(A.1)
run synth for 4but 2Int
We present the results of our evaluation, including a per-
formance comparison between Alloy* and existing program
synthesizers, in Section 8.2.
7. Optimizations
Originally motivated by the formalization of the synthesis
problem (as presented in Section 6), we designed and imple-
mented two general purpose optimization for Alloy*.
7.1 Quantiﬁer Domain Constraints
As deﬁned in Listing A.1, the synth predicate, although log-
ically sound, suffers from serious performance issues. The
most obvious reason is how the implication inside the univer-
sal higher-order quantiﬁer (“the semantics implies the spec”)
affects the CEGIS loop. To trivially satisfy the implication,
the candidate search step can simply return and instance for
which the semantics does not hold. Furthermore, adding theencoding of the counterexample refuting the previous in-
stance is not going to constrain the next search step to ﬁnd a
program and a valuation for which the spec holds. This cycle
can go on for unacceptably many iterations.
This reﬂects an old philosophical problem in ﬁrst-order
logic: “all men are mortal" is only equivalent to “for all x,
if x is a man, then x is mortal” in a rather narrow, model-
theoretic sense. The case of a non-man being non-mortal is
a witness to the second but not to the ﬁrst.
To overcome this problem, we can add syntax to identify
the constraints that should be treated as part of the bounds of
a quantiﬁcation. The synth predicate now becomes
pred synth [root: IntNode ] {
all eval: Node -> ( Int + Bool) when semantics [eval ] |
spec [root, eval ]
}
The existing ﬁrst-order semantics of Alloy is unaffected, i.e.,
all xwhen D[x] | P[x]⇐⇒ all x|D[x] implies P[x]
some xwhen D[x] | P[x]⇐⇒ some x|D[x] and P[x](A.2)
The rule for pushing negation through quantiﬁers (used
by the converter to NNF) becomes:
not (all xwhen D[x] | P[x])⇐⇒ some xwhen D[x] | not P[x]
not (some xwhen D[x] | P[x])⇐⇒ all xwhen D[x] | not P[x]
(which is consistent with classical logic).
The formalization of the Alloy* semantics needs only a
minimal change. The change in semantics is caused by es-
sentially not changing how the existential counterpart of a
universal quantiﬁer is obtained— only by ﬂipping the quan-
tiﬁer, and keeping the domain and the body the same (line
5, Figure 6). Consequently, the candidate condition always
searches for an instance satisfying both the domain and the
body constraint (or in terms of the synthesis example, both
the semantics and the spec). The same is automatically true
for counterexamples obtained in the veriﬁcation step. The
only actual change to be made to the formalization is ex-
panding q.body in line 38 according to the rules in List-
ing A.2.
Going back to the synthesis example, even after rewriting
thesynth predicate, unnecessary overhead is still incurred
by quantifying over valuations for all the nodes, instead of
valuations for just the input variables. Another consequence
is that the counterexamples produced in the CEGIS loop do
not guide the search as effectively. This observation leads
us to our ﬁnal formulation of the synth predicate, which we
used in all benchmarks presented in Section 8.2:
pred synth [root: IntNode ] {
all env: Var -> Int |
some eval: Node -> ( Int + Bool) when
env ineval &&semantics [eval ] |
spec [root, eval ]
}(A.3)
Even though it uses nested higher-order quantiﬁers, it
turns out to be the most efﬁcient. The reason is that the in-
nermost quantiﬁer (over eval) always takes exactly one iter-
ation (to either prove or disprove the current env), because
for a ﬁxed env,eval is uniquely determined.7.2 Strictly First-Order Increments
We already pointed out the importance of implementing the
induction step (line 41, Figure 7) using incremental SAT
solving. A problem, however, arises when the encoding of
the counterexample (as deﬁned in lines 38-40) is not a ﬁrst-
order formula—since not directly translatable to SAT, it can-
not be incrementally added to the existing SAT translation of
the candidate search condition ( pcand). In such cases, the se-
mantics in Figure 7 demands that the conjunction of pcand
andTJfcexKbe solved from scratch, loosing any beneﬁts
from previously learned SAT clauses.
This problem occurs in our ﬁnal formulation of the synth
predicate (Listing A.3), due to the nested higher-order quan-
tiﬁers. To address this issue, we relax the semantics of the in-
duction step by replacing SJpcand⋏TJfcexKK(line 41) with
funTfo(f)=match p=TJfKwith
|FOL→p
|OR→reduce ⋎;map(Tfo; p:disjs)
|EA→fold⋏; p:conj;map(Tfo; p:qps:pExists )
SJpcand⋏Tfo(fcex)K
TheTfofunction ensures that fcexis translated to a ﬁrst-
order Proc , which can always be added as an increment to
the current SAT translation of the candidate condition. The
trade-off involved here is that this new encoding of the coun-
terexample is potentially not as strong, and therefore may
lead to more CEGIS iterations before a resolution is reached.
For that reason, Alloy* accepts a conﬁguration parameter
(accessible via the “Options” menu), offering both seman-
tics. In Section 8 we provide experimental data showing that
for all of our synthesis examples, the strictly ﬁrst-order in-
crements yielded better performance.
8. Evaluation
8.1 Micro Benchmarks
To assess how well Alloy* scales on higher-order graph
problems, we selected the following 4 classical problems:
max clique ,max cut ,max independent set , and min vertex
cover . We speciﬁed each of the four problems in Alloy*
(see Figure 9 for the full Alloy speciﬁcation), and executed
them on a set of pre-generated graphs, measuring the perfor-
mance of the tool in successfully producing a correct output.
It can be expected that veriﬁcation problems requiring the
discovery of a graph with such properties would require
comparable computational resources.
Experiment Setup We used the Erd ˝os-Rényi model [9] to
randomly generate graphs to serve as inputs to the bench-
mark problems. To cover graphs with a wide range of den-
sities, we used 5 probabilities (0.1, 0.3, 0.5, 0.7, 0.9) for in-
serting an edge between a pair of nodes in a graph. In total,
we generated 210 different graphs, with sizes ranging from
2 to 50 nodes.
To additionally test the correctness of our implementa-
tion, we compared the results return by Alloy* to those ofsig Graph {nodes: set Node, edges: set Edge }{
edges.(src+dst) innodes
}
sig Edge {src: one Node, dst: one Node }{
src != dst
}
sig Node {}
/*every two nodes in ’clq’ are connected */
pred clique [g: Graph, clq: set Node ] {
clq ing.nodes
all n1: clq, n2: clq - n1 | some e: g.edges |
e.src = n1 and e.dst = n2 ore.src = n2 and e.dst = n1
}
pred maxClique [g: Graph, clq: set Node ] {
clique [g, clq ]
noclq2: set Node |clq2 != clq and clique [g, clq2 ] and #clq2 > #clq
}
/*edges that cross the two disjoint node set as determined by the cut */
fun crossing [g: Graph, cut: set Node ]:set Edge {
let cut’ = g.nodes - cut |
{e: g.edges |(e.src incut and e.dst incut’) or
(e.dst incut and e.src incut’) }
}
pred maxCut [g: Graph, cut: set Node ] {
cut ing.nodes
nocut2: set Node |
cut2 ing.nodes and cut2 != cut and #crossing [g,cut2 ]> #crossing [g,cut ]
}
/*An independent set is a set of nodes, no two of which are neighbours */
pred independentSet [g: Graph, indset: set Node ] {
indset ing.nodes
all disj n1, n2: indset | no e: g.edges |
(e.src = n1 and e.dst = n2) or(e.src = n2 and e.dst = n1)
}
pred maxIndependentSet [g: Graph, indset: set Node ] {
independentSet [g, indset ]
noindset2: set Node |
indset2 != indset and clique [g, indset2 ] and #indset2 > #indset
}
/*A vertex cover is a set of nodes such that every edge in g is
adjacent to at least one node in the set */
pred vertexCover [g: Graph, cover: set Node ] {
cover ing.nodes
all e: g.edges |e.src incover ore.dst incover
}
pred minVertexCover [g: Graph, cover: set Node ] {
vertexCover [g, cover ]
nocover2: set Node |
cover != cover2 and vertexCover [g, cover2 ] and #cover2 < #cover
}
Figure 9. Four micro benchmark problems in Alloy*
known imperative algorithms for the above problems1and
made sure they matched. The timeout for each run (solving
a single problem for a given graph) was set to 100 seconds.
Results Figure 10 plots the average solving time across
graphs size. The results show that for all problems but
max cut , Alloy* was able to handle graphs of sizes up to
50 nodes in less than a minute ( max cut started to time out at
around 25 nodes). Our original goal for this benchmarks was
to be able to solve graphs with 10-15 nodes, and claim that
Alloy* can be effectively used for teaching, speciﬁcation
animation, and small scope checking, all within the Alloy
Analyzer GUI (which is one of the most common uses of
the Alloy technology). These results, however, indicate that
executing higher-order speciﬁcations can be feasible even
1Formax clique andmax independent set , we used the Bron-Kerbosch
heuristic algorithm; for the other two, no good heuristic algorithm is known,
and so we implemented enumerative search. In both cases, we used Java.0	  10	  20	  30	  40	  50	  60	  70	  80	  
2	  3	  5	  7	  9	  13	  15	  20	  25	  30	  35	  40	  45	  50	  Solving Time (s) # Nodes max clique max cut max indep. set min vertex cover Figure 10. Average solving times for benchmark algorithms
0	  2	  4	  6	  8	  10	  12	  14	  
2	  3	  5	  7	  9	  13	  15	  20	  25	  30	  35	  40	  45	  50	  # Candidates # Nodes max clique max cut max indep. set min vertex cover 
Figure 11. Average number of candidates considered for bench-
mark algorithms
for declarative programming (where a constraint solver is
integrated with a programming language, e.g., [25, 26]),
which is very encouraging.
Figure 11 shows the average number of candidate solu-
tions Alloy* explored before producing a ﬁnal output. As
the graph size became larger, the number of candidates also
increased, but in most cases, Alloy* was able to ﬁnd a cor-
rect solution under 6 candidates. One exception was the max
cut problem: For graphs of size 25, Alloy* considered up to
13 candidates, after which the resulting constraints became
too hard for the SAT solver, leading to a timeout.
Figure 12 show average solving times for individual prob-
ability thresholds used to generate graphs for the micro
benchmark experiments. Lower the threshold (T), denser the
graph is (similarly, higher T values lead to sparser graphs).
In general, the solving time tends to be greater for denser
graphs, as the search space is bigger. This trend is espe-
cially evident in the max cut problem (Figure 12(b)), where
the solving time increases drastically for T=0.1 until Alloy*
times out at graphs of size 20.
On the other hand, sparsity does not necessarily lead to
faster performance. For example, in the max clique and max
independent set, note how Alloy* takes longer on graphs
with T=0.9 (Figures 12(a) and (c)) than on those with lower
threshold as the graph size increases. We believe that this
0	  10	  20	  30	  40	  50	  60	  70	  80	  
2	  3	  5	  7	  9	  13	  15	  20	  25	  30	  35	  40	  45	  50	  Solving Time (s) # Nodes T=0.1	  T=0.3	  T=0.5	  T=0.7	  T=0.9	  (a)max clique
0	  20	  40	  60	  80	  100	  120	  140	  
2	  3	  5	  7	  9	  13	  15	  20	  25	  Solving	  Time	  (s)	  
# Nodes T=0.1	  T=0.3	  T=0.5	  T=0.7	  T=0.9	  
(b)max cut
0	  10	  20	  30	  40	  50	  60	  
2	  3	  5	  7	  9	  13	  15	  20	  25	  30	  35	  40	  45	  50	  Solving Time (s) # Nodes T=0.1	  T=0.3	  T=0.5	  T=0.7	  T=0.9	  
(c)max independent set
0	  0.2	  0.4	  0.6	  0.8	  1	  1.2	  1.4	  1.6	  1.8	  
2	  3	  5	  7	  9	  13	  15	  20	  25	  30	  35	  40	  45	  50	  Solving Time (s) # Nodes T=0.1	  T=0.3	  T=0.5	  T=0.7	  T=0.9	  
(d)min vertex cover
Figure 12. Avg. times per each threshold for graph benchmarks
is because sparser graphs tend to permit fewer cliques (and
independent sets) than more densely connected graphs.
8.2 Program Synthesis
Out of 124 total benchmarks in the SyGuS project, we en-
coded the 10 that do not involve bit vectors and compared the
performance of Alloy* in ﬁnding correct programs to thatof the provided reference solvers. While it is possible to en-
code bit vectors in Alloy, the language does not support them
natively, and a relational encoding would almost certainly
incur performance penalties. We ran the same benchmarks
on the same computer using the three reference solvers. Our
test machine had an Intel dual-core CPU, 4GB of RAM, and
ran Ubuntu GNU/Linux and Sun Java 1.6. We set Alloy*’s
solver to be MiniSAT.
Figure 13 compares the performance of Alloy* against
the three SyGuS reference solvers and Sketch [36], a highly-
optimized, state-of-the-art program synthesizer. According
to these results, Alloy* scales better than the three refer-
ence solvers, and is even competitive with Sketch. On the
array-search benchmarks, Sketch outperforms Alloy* for
larger problem sizes, but on the maxbenchmarks, the oppo-
site is true. Both solvers scale far more predictably than the
reference solvers, but Alloy* has the additional advantage,
due to its generality, of a ﬂexible encoding of the target lan-
guage’s semantics, while Sketch relies on the semantics of
the benchmark problems being the same as its own.
We also used the program synthesis benchmarks to an-
swer two questions unique to Alloy*. First, we evaluated the
optimization discussed in Section 7.2 by running the bench-
marks with and without it. Figures 14(a) and (b) show that
for the maxandarray benchmarks, respectively, using ﬁrst-
order increments decreases solving time signiﬁcantly, and
often causes the solver to scale to slightly larger sizes.
Second, we evaluated the beneﬁts to be gained by specify-
ing tighter bounds on the problem domain by placing tighter
limits on the abstract syntax tree nodes considered by the
solver. Figures 14(c) and (d) show that for maxandarray
respectively, signiﬁcant gains can be realized by tightening
the bounds—in the case of max, tighter bounds allow Al-
loy* to improve from solving the 6-argument version of the
problem to solving the 8-argument version. For these ex-
periments, Scope 1 speciﬁes the exact number of each AST
node required; Scope 2 speciﬁes exactly which types of AST
nodes are necessary; and Scope 3 speciﬁes only how many
total nodes are needed. Other solvers also ask the user to
bound the analysis—Sketch, for example, requires both an
integer and recursion depth bound—but do not provide the
same ﬁne-grained control over the bounds as Alloy*.
Table 1 contains both the running time and the number of
candidates considered in solving each benchmark under each
of the three scopes discussed above. Because they involve
so few nodes, the bounds for the poly benchmarks could
not be tightened beyond the most general scope. The results
for the other benchmarks indicate that carefully considered
scopes can result in signiﬁcantly better solving times (other
researchers have also reported similar ﬁndings [16]).
These results show that Alloy* not only scales better than
naive approaches to program synthesis, but can also, in cer-
tain cases, be competitive with state-of-the-art solvers based
on years of optimization. Moreover, Alloy* requires only
 0.01 0.1 1 10 100 1000
max-2 max-3 max-4 max-5 array-search-2 array-search-3 array-search-4 array-search-5Solving Time (s)
BenchmarkAlloy*
Enumerative
Stochastic
Symbolic
SketchFigure 13. Performance Comparison between Alloy* and Refer-
ence Solvers.
the simple model presented here—which is easier to pro-
duce than even the most naive purpose-built solver. Due to
its generality, Alloy* is also, in some respects, a more ﬂexi-
ble program synthesis tool—it makes it easy, for example, to
experiment with the semantics of the target language, while
solvers like Sketch have their semantics hard-coded.
Problem Scope 1 Scope 2 Scope 3
Steps Time(ms) Steps Time Steps Time
poly – – – – 2 37
poly-1 – – – – 2 36
poly-2 – – – – 4 281
poly-3 – – – – 3 121
poly-4 – – – – 3 891
max-2 3 311 3 432 3 416
max-3 6 923 7 901 8 1,236
max-4 8 1,536 8 2,983 15 5,928
max-5 25 4,152 23 36,344 19 28,580
max-6 29 16,349 n/a t/o n/a t/o
max-7 44 163,643 n/a t/o n/a t/o
max-8 32 987,345 n/a t/o n/a t/o
array-2 8 1,638 8 2,352 8 1,923
array-3 13 4,023 9 8,129 7 3,581
array-4 15 16,102 11 97,983 15 310,492
array-5 18 485,698 n/a t/o n/a t/o
Table 1. Performance on Synthesis Benchmarks
9. Related Work
The ideas and techniques used in this paper span a number of
different areas of research including (1) constraint solvers,
(2) synthesizers, (3) program veriﬁers, and (4) executable
speciﬁcation tools. A brief discussion of how a more pow-
erful analysis engine for Alloy (as offered by Alloy*) may
affect the plethora of existing tools built on top of Alloy is
also in order.
Constraint solvers SMT solvers, by deﬁnition, ﬁnd satis-
fying interpretations of ﬁrst-order formulas over unbounded
domains. In that context, only quantiﬁer-free fragments are
decidable. Despite that, many solvers (e.g., Z3 [7]) sup-
port certain forms of quantiﬁcation by implementing an efﬁ-(a)
 0.1 1 10 100 1000
 2  3  4  5  6  7  8Solving Time (s)
Arguments to MaxPartial Increments
Full Increments (b)
 0.1 1 10 100 1000
 2  3  4  5Solving Time (s)
Array SizePartial Increments
Full Increments
(c)
 0.1 1 10 100 1000
 2  3  4  5  6  7  8Solving Time (s)
Arguments to MaxScope 1
Scope 2
Scope 3 (d)
 0.1 1 10 100 1000
 2  3  4  5Solving Time (s)
Array SizeScope 1
Scope 2
Scope 3
Figure 14. Effects of Increment Type and Scope on Solving Time
cient matching heuristic based on patterns provided by the
user [6]. Certain non-standard extension allow quantiﬁca-
tion over functions and relations for the purpose of checking
properties over recursive predicates [5]. In the general case,
however, this approach often leads to “unknown” being re-
turn as the result. Many tools that build on top of an SMT
solver raise the level of abstraction of the input language, so
that they can provide quantiﬁcation patterns that work more
reliably in practice. For instance, Boogie [4] is an intermedi-
ate veriﬁcation language that effectively uses quantiﬁers for
the task of program veriﬁcation, but does not allow asser-
tions to be higher-order.
SAT solvers, on the other hand, are design to work with
bounded domains. Even though they accept only proposi-
tional formulas, tools built on top may support richer log-
ics, including higher-order quantiﬁers. One such tool is Kod-
kod [38], which, at the language level, allows quantiﬁca-
tion over arbitrary relations. The Kodkod analysis engine,
however, is not capable of handling any higher-order formu-
las. Rosette [39] builds on top of Kodkod a whole suite of
tools for embedding automated constraint solvers into pro-
grams for a variety of purposes, including program synthe-
sis. Rosette, like many other synthesizers, implements a syn-
thesis algorithm internally. In contrast to Alloy*, at the user
level, this approach enables only one predetermined form of
synthesis (namely, the user speciﬁes a grammar and a prop-
erty, and Rosette then ﬁnds an instantiation of that grammar
satisfying the property).Synthesizers State-of-the-art synthesizers today are mainly
purpose-built. Domains of application include program syn-
thesis (e.g., Sketch [36], Storyboard [34], Jennisys [22],
Comfusy [19], PINS [37]), automatic grading of program-
ming assignments [35], synthesis of data manipulation reg-
ular expressions [13], and so on, all using different ways for
the user to specify the property to be satisﬁed. A recent effort
has been made to establish a standardized format for pro-
gram synthesis problems [3]; this format is syntax-guided,
similar to that of Rosette, and thus less general than the for-
mat offered by Alloy*. In other words, while each such tool
is likely to beat Alloy* in its own concrete domain, it would
be hard to apply the tool at all in a different domain.
Program Veriﬁers Program veriﬁers beneﬁt directly from
more expressive speciﬁcation languages equipped with more
powerful analysis tools. In recent years, many efforts have
been made towards automatically verifying programs in
higher-order languages. Liquid types [30] and HMC [17]
respectively adapt known techniques for type inference and
abstract interpretation for this task. Bjørner et al. examine
direct encodings into Horn clauses, concluding that cur-
rent SMT solvers are effective at solving clauses over in-
tegers, reals, and arrays, but not necessarily over algebraic
datatypes. Dafny [21] is the ﬁrst SMT-based veriﬁer to pro-
vide language-level mechanisms speciﬁcally for automating
proofs by co-induction [23].
Executable Speciﬁcations Many research projects explore
the idea of extending a programming language with sym-bolic constraint-solving features (e.g., [18, 25, 32, 39, 41]).
Limited by the underlying constraint solvers, none of these
tools can execute a higher-order constraint. In contrast, we
usedRby [26] (our most recent take on this idea where
we embed the entire Alloy language directly into Ruby),
equipped with Alloy* as its engine, to run all our graph ex-
periments (where Rby automatically translated input par-
tial instances from concrete graphs, as well as solutions re-
turned from Alloy back to Ruby objects), demonstrating how
a higher-order constraint solver can be practical in this area.
Existing Alloy Tools Certain tools built using Alloy al-
ready provide means for achieving tasks similar to those we
used as Alloy* examples. Aluminum [28], for instance, ex-
tends the Alloy Analyzer with a facility for minimizing solu-
tions. It does so by using the low-level Kodkod API to selec-
tively remove tuples from the resulting tuple set. In our graph
examples, we were faced with similar tasks (e.g., minimiz-
ing vertex covers), but, in contrast, we used a purely declara-
tive constraint to assert that there is no other satisfying solu-
tion with fewer tuples. While Aluminum is likely to perform
better on this particular task, we showed in this paper (Sec-
tion 8.1) that even the most abstract form of specifying such
minimization/maximization tasks scales reasonably well.
Rayside et al. used the Alloy Analyzer to synthesize it-
erators from abstraction functions [29], as well as com-
plex (non-pure) A VL tree operations from abstract speciﬁ-
cations [20]. In both cases, they target a very speciﬁc cate-
gories of programs, and their approach is based on insights
that hold only for those particular categories.
10. Conclusion
Software analysis and synthesis tools have typically pro-
gressed by the discovery of new algorithmic methods in spe-
cialized contexts, and then their subsequent generalization
as solutions to more abstract mathematical problems. This
trend—evident in the history of dataﬂow analysis, symbolic
evaluation, abstract interpretation, model checking, and con-
straint solving—brings many beneﬁts. First, the translation
of a class of problems into a single, abstract and general
formulation allows researchers to focus more sharply, result-
ing in deeper understanding, cleaner APIs and more efﬁcient
algorithms. Second, generalization across multiple domains
allows insights to be exploited more widely, and reduces the
cost of tool infrastructure through sharing of complex an-
alytic components. And third, the identiﬁcation of a new,
reusable tool encourages discovery of new applications.
In this paper, we have argued that the time is ripe to view
higher-order constraint solving in this context, and we have
proposed a generalization of a variety of algorithms that we
believe suggests that the productive path taken by ﬁrst-order
solving might be taken by higher-order solving too. The
value of our generalization does not, in our view, rest on
its performance in comparison to today’s specialized tools(although we think it is quite respectable), but instead on the
potential for future development of tools that exploit it.
Acknowledgments
This material is based upon work partially supported by
the National Science Foundation under Grant No. CCF-
1138967.
References
[1] Alloy* Home Page. http://alloy.mit.edu/alloy/hola .
[2] M. Aigner and G. M. Ziegler. Turán’s graph theorem. In
Proofs from THE BOOK , pages 183–187. Springer, 2001.
[3] R. Alur, R. Bodík, G. Juniwal, M. M. K. Martin,
M. Raghothaman, S. A. Seshia, R. Singh, A. Solar-Lezama,
E. Torlak, and A. Udupa. Syntax-guided synthesis. In FM-
CAD , pages 1–17. IEEE, 2013.
[4] M. Barnett, B.-Y . E. Chang, R. DeLine, B. Jacobs, and
K. R. M. Leino. Boogie: A modular reusable veriﬁer for
object-oriented programs. In FMCO 2005 , volume 4111 of
lncs, pages 364–387. Springer, 2006.
[5] N. Bjørner, K. McMillan, and A. Rybalchenko. Program veri-
ﬁcation as satisﬁability modulo theories. In SMT Workshop at
IJCAR , volume 20, 2012.
[6] L. De Moura and N. Bjørner. Efﬁcient e-matching for smt
solvers. In Automated Deduction–CADE-21 , pages 183–198.
Springer, 2007.
[7] L. de Moura and N. Bjørner. Z3: An efﬁcient SMT solver. In
TACAS 2008 , volume 4963 of lncs, pages 337–340. Springer,
2008.
[8] G. Dennis. A Relational Framework for Bounded Program
Veriﬁcation . PhD thesis, MIT, 2009.
[9] P. Erdos and A. Renyi. On the evolution of random graphs.
Mathematical Institute of the Hungarian Academy of Sci-
ences, 5: 17-61 , 1960.
[10] J. F. Ferreira, A. Mendes, A. Cunha, C. Baquero, P. Silva,
L. S. Barbosa, and J. N. Oliveira. Logic training through
algorithmic problem solving. In Tools for Teaching Logic ,
pages 62–69. Springer, 2011.
[11] K. Fisler, S. Krishnamurthi, L. A. Meyerovich, and M. C.
Tschantz. Veriﬁcation and change-impact analysis of access-
control policies. In Proceedings of the 27th ICSE , pages 196–
205. ACM, 2005.
[12] J. P. Galeotti, N. Rosner, C. G. López Pombo, and M. F. Frias.
Analysis of invariants for efﬁcient bounded veriﬁcation. In
ISSTA , pages 25–36. ACM, 2010.
[13] S. Gulwani, W. R. Harris, and R. Singh. Spreadsheet data
manipulation using examples. Commun. ACM , 55(8):97–105,
2012.
[14] G. Hughes and T. Bultan. Automated veriﬁcation of access
control policies using a sat solver. STTT , 10(6):503–520,
2008.
[15] D. Jackson. Software Abstractions: Logic, language, and
analysis . MIT Press, 2006.[16] S. Jha, S. Gulwani, S. A. Seshia, and A. Tiwari. Oracle-
guided component-based program synthesis. In ICSE , ICSE
’10, pages 215–224, New York, NY , USA, 2010. ACM.
[17] R. Jhala, R. Majumdar, and A. Rybalchenko. Hmc: Verifying
functional programs using abstract interpreters. In Computer
Aided Veriﬁcation , pages 470–485. Springer, 2011.
[18] A. S. Köksal, V . Kuncak, and P. Suter. Constraints as control.
ACM SIGPLAN Notices , 2012.
[19] V . Kuncak, M. Mayer, R. Piskac, and P. Suter. Comfusy: A
tool for complete functional synthesis. In CAV, pages 430–
433, 2010.
[20] D. Kurilova and D. Rayside. On the simplicity of synthesizing
linked data structure operations. In Proceedings of the 12th in-
ternational conference on Generative programming: concepts
& experiences , pages 155–158. ACM, 2013.
[21] K. R. M. Leino. Dafny: An automatic program veriﬁer for
functional correctness. In LPAR-16 , volume 6355 of lncs,
pages 348–370. Springer, 2010.
[22] K. R. M. Leino and A. Milicevic. Program extrapolation
with Jennisys. In Proceedings of the International Conference
on Object Oriented Programming Systems Languages and
Applications , pages 411–430, 2012.
[23] K. R. M. Leino and M. Moskal. Co-induction simply: Au-
tomatic co-inductive proofs in a program veriﬁer. Techni-
cal report, Technical Report MSR-TR-2013-49, Microsoft Re-
search, 2013.
[24] D. Marinov and S. Khurshid. Testera: A novel framework for
automated testing of java programs. In Automated Software
Engineering, 2001. , pages 22–31. IEEE, 2001.
[25] A. Milicevic, D. Rayside, K. Yessenov, and D. Jackson. Uni-
fying execution of imperative and declarative code. In ICSE ,
pages 511–520, 2011.
[26] A. Milicevic, I. Efrati, and D. Jackson. aRby—An Embedding
of Alloy in Ruby (to appear). In Abstract State Machines,
Alloy, B, VDM, and Z . 2014. URL http://people.csail.
mit.edu/aleks/website/arby .
[27] T. Nelson, C. Barratt, D. J. Dougherty, K. Fisler, and S. Kr-
ishnamurthi. The Margrave tool for ﬁrewall analysis. In Pro-
ceedings of the International Conference on Large Installa-
tion System Administration , pages 1–8, 2010.
[28] T. Nelson, S. Saghaﬁ, D. J. Dougherty, K. Fisler, and S. Krish-
namurthi. Aluminum: principled scenario exploration through
minimality. In ICSE , pages 232–241. IEEE Press, 2013.
[29] D. Rayside, V . Montaghami, F. Leung, A. Yuen, K. Xu, and
D. Jackson. Synthesizing iterators from abstraction functions.InProceedings of the International Conference on Genera-
tive Programming and Component Engineering , pages 31–40,
2012.
[30] P. M. Rondon, M. Kawaguci, and R. Jhala. Liquid types. In
ACM SIGPLAN Notices , volume 43, pages 159–169. ACM,
2008.
[31] N. Rosner, J. Galeotti, S. Bermúdez, G. M. Blas, S. P.
De Rosso, L. Pizzagalli, L. Zemín, and M. F. Frias. Parallel
bounded analysis in code with rich invariants by reﬁnement of
ﬁeld bounds. In ISSTA , pages 23–33. ACM, 2013.
[32] H. Samimi, E. D. Aung, and T. D. Millstein. Falling back on
executable speciﬁcations. In ECOOP , pages 552–576, 2010.
[33] A. Schaad and J. D. Moffett. A lightweight approach to spec-
iﬁcation and analysis of role-based access control extensions.
InSACMAT , pages 13–22, 2002.
[34] R. Singh and A. Solar-Lezama. Synthesizing data structure
manipulations from storyboards. In Proceedings of the Sym-
posium on the Foundations of Software Engineering , pages
289–299, 2011.
[35] R. Singh, S. Gulwani, and A. Solar-Lezama. Automated feed-
back generation for introductory programming assignments.
InProceedings of the 34th PLDI , pages 15–26. ACM, 2013.
[36] A. Solar-Lezama, L. Tancau, R. Bodik, S. Seshia, and
V . Saraswat. Combinatorial sketching for ﬁnite programs. In
Proceedings of the International Conference on Architectural
Support for Programming Languages and Operating Systems ,
pages 404–415, 2006.
[37] S. Srivastava, S. Gulwani, S. Chaudhuri, and J. S. Foster. Path-
based inductive synthesis for program inversion. In PLDI
2011 , pages 492–503. ACM, 2011.
[38] E. Torlak. A Constraint Solver for Software Engineering:
Finding Models and Cores of Large Relational Speciﬁcations .
PhD thesis, MIT, 2008.
[39] E. Torlak and R. Bodik. Growing solver-aided languages
with rosette. In Proceedings of the 2013 ACM international
symposium on New ideas, new paradigms, and reﬂections on
programming & software , pages 135–152. ACM, 2013.
[40] E. Torlak and D. Jackson. Kodkod: A relational model ﬁnder.
InTools and Algorithms for the Construction and Analysis of
Systems , pages 632–647. Springer, 2007.
[41] J. Yang, K. Yessenov, and A. Solar-Lezama. A language
for automatically enforcing privacy policies. In Proceedings
of the Symposium on Principles of Programming Languages ,
pages 85–96, 2012.