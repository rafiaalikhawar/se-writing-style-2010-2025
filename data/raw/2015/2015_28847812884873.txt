Learning API Usages from Bytecode:
A Statistical Approach
T am The Nguyen, Hung Viet Pham, Phong Minh Vu, T ung Thanh Nguyen
Computer Science Department
Utah State University
{tam.nguyen,hung.pham,phong.vu}@aggiemail.usu.edu
tung.nguyen@usu.edu
ABSTRACT
Mobile app developers rely heavily on standard API frame-
works and libraries. However, learning API usages is often
challenging due to the fast-changing nature of API frame-
works for mobile systems and the insuﬃciency of API docu-mentation and source code examples. In this paper, we pro-pose a novel approach to learn API usages from bytecode ofAndroid mobile apps. Our core contributions include HAPI,
a statistical model of API usages and three algorithms to
extract method call sequences from apps’ bytecode, to trainHAPI based on those sequences, and to recommend methodcalls in code completion using the trained HAPIs. Our em-
pirical evaluation shows that our prototype tool can eﬀec-
tively learn API usages from 200 thousand apps containing350 million method sequences. It recommends next methodcalls with top-3 accuracy of 90% and outperforms baselineapproaches on average 10-20%.
Keywords
Statistical model, API usage, mobile apps
1. INTRODUCTION
Mobile apps are software applications developed specially
for mobile devices like smartphones and tablets. Due to the
exploding in popularity and usage of those devices, millions
of mobile apps have been developed and made available toend-users. Due to the ﬁerce competition, those mobile appsoften need to have very short time-to-market and upgrade
cycles, andthus, shortdevelopmenttime. Toaddressthisre-
quirement, mobile app developers often rely heavily on APIapplication frameworks and libraries such as Android andiOS frameworks, Java APIs, etc and mobile apps extensivelyre-use API components. For example, a prior study reports
some Android apps having up to 42% of their external de-
pendencies to Android APIs and 68% to Java APIs [38].
Learning API usages is usually challenging due to sev-
eral reasons. First, an API framework often consists a large
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributedfor proﬁt or commercial advantage and that copies bear this notice and the full cita-tion on the ﬁrst page. Copyrights for components of this work owned by others thanACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-publish, to post on servers or to redistribute to lists, requires prior speciﬁc permissionand/or a fee. Request permissions from permissions@acm.org.
ICSE ’16, May 14-22, 2016, Austin, TX, USA
c/circlecopyrt2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI: http://dx.doi.org/10.1145/2884781.2884873number of components. For example, the Android applica-
tion framework contains over 3,400 classes and 35,000 meth-ods which are organized in more than 250 packages [23].Moreover, while common API usage scenarios often involve
several API elements and follow special rules for pre- and
post-conditions or for control and data ﬂows [31, 28, 10],documentation of such usages is generally insuﬃcient. Forexample, the Javadoc of a class mainly contains only de-
scriptions of its ﬁelds and methods and rarely has code ex-
amples describing in details the usages of its objects andmethods [22]. Descriptions and code examples for API us-ages involving several objects are usually non-existed.
These challenges are even more severe for learning APIs
of mobile frameworks. Due to the fast development of mo-bile devices and the strong competition between softwareand hardware vendors, those frameworks are often upgradedquickly and include very large changes. For example, 17 ma-
jor versions of Android framework containing nearly 100,000
method-levelchangeshavebeenreleasedwithinﬁveyears[23].Additionally, source code of most mobile apps is not publiclyavailable. With few apps with source code available, ﬁnd-ing and learning code examples from existing mobile app
projects would be diﬃcult and insuﬃcient.
In this paper, we introduce SALAD ( “S
tatistical A pproach
for L earning A PIs from D VM bytecode” ), a novel approach
to address the problem of learning API mobile frameworks.
To address the problem of insuﬃcient documentation andsource code examples, SALAD learns API usages from byte-
codeof Android mobile apps, of which millions are publicly
available. As a statistical approach, SALAD can learn com-plex API usages involving several API objects and methods.Finally, SALAD can automatically generate recommenda-tions for incomplete API usages, thus it could reduce thechance of API usage errors and improve code quality.
The key component of our approach is HAPI, standing for
“H
idden Markov Model of API usages”.AH A P Ii saH i d -
den Markov Model (HMM) [34] representing method callsequences involving one or multiple related API objects. It
has several states aimed to represent the internal states of
the represented API objects. It also associates with prob-abilities for selecting the starting state, for transiting fromone state to another, and for calling a method at a given
state. Those probabilities describe the statistical patterns
of API states and method calls.
SALAD also consists of three new algorithms involving
HAPI. One algorithm is designated to train a HAPI i.e.inferring its internal states and estimating the associated
probabilities from a very large collection of method call se-
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   416
quences. AnotheralgorithmusesatrainedHAPItocompute
the generating probabilities of several method sequences and
rank those sequences based on those probabilities. This
ranking result is used for API usage recommendation.
The last algorithm extracts API method sequences from
apps’ bytecode which are then used for training HAPIs. Itﬁrst analyzes bytecode and builds GROUMs. A GROUM
(“GR
aph-based O bject U asge M odel”) [31] is a graph-based
model in which the nodes represent method calls and data
objects and the edges indicate control and data ﬂows be-tween those methods and objects. With that design, a
GROUM can represent an usage scenario including many
objects and methods and complex control and data ﬂowsbetween them. Once a GROUM is built, our algorithm cantravel all its paths following the control and data dependen-cies and extracts the corresponding method sequences.
We have conducted several experiments to evaluate the
usefulness and eﬀectiveness of SALAD. The experiment re-sults show several important points. First, our approachSALAD is highly eﬃcient and scalable. It is able to extract
nearly 350 millions method sequences and train 24 thou-sands HAPIs from more than 200 thousands mobile apps
downloaded from Google’s Android app market. With thathuge amount of training data, SALAD can predict and rec-ommend the next method call for a given API method call
sequence with a top-3 accuracy of nearly 90% and a top-10
accuracy of more than 98%. In addition, our model HAPIconsistently outperforms two baseline models n-gram and
recurrent neural network [35] with the average improvement
around 10-20%.
Based on SALAD, we have developed an API usage rec-
ommendation tool named DroidAssist. This tool is imple-
mented as a plug-in of Android Studio and available on-line at http://useal.cs.usu.edu/droidassist. More informa-
tion about this tool can be found in [32] and that web-
site. Source code and experiment data of this work (e.g.extracted API method sequences, GROUMs, and HAPIs)are also made available there.
The remaining of this paper is organized as the follow-
ing. Section 2 presents an example of Android APIs andtheir usages in practice. It also illustrates how HAPIs couldbe used to model API usages. Section 3 introduces HAPIas the main conceptual contributions of SALAD. Section 4
discusses the overall architecture of SALAD and its key al-
gorithms. Our empirical evaluation is presented in Section5. We discuss related work in Section 6.
2. EXAMPLE
This section brieﬂy introduces API usages and HAPI via
an example. Figure 1, reproduced from Android Developerwebsite [18], illustrates usages of a MediaRecorder object in
Android API framework as a state diagram. This state di-agram is a ﬁnite state machine in which each node (drawn
as a rounded rectangle) represents an internal state of the
MediaRecorder object and each edge (drawn as an arrow)
represents a state transition when a method (drawn as thelabel of the edge) is called.
Welearnfromthisstatediagramthata MediaRecorder ob-
ject has seven states during its lifetime. It is at one state ata time and can change to another state if a method is called.For example, as after being created, the MediaRecorder ob-
ject is in the Initialstate. If method setAudioSource or
setVideoSource is called, it changes to the Initialized state.
Error Initial
Released
Recording
PreparedInitialized
DataSource
Conﬁguredreset()reset()
setAudioSource()
setVideoSource()
setAudioSource()
setVideoSource()
setOutputFormat()
setAudioEncoder()
setVideoEncoder()
setOutputFile()
setVideoSize()
setVideoFrameRate()
setPreviewDisplay()reset()reset()
prepare()release()
start()reset()/
stop()Error occurs or 
an invalid call
Figure 1: State diagram of MediaRecorder object
Then, it will change from the Initialized state to the Data-
SourceConﬁgured s t a t ei fw ec a l lm e t h o d setOutputFormat.
However, at any time, if method resetis called, the object
will come back to its Initialstate.
It could be seen from this example that state diagrams
can represent usages of API objects precisely and concisely.
Thus, they are useful to learn and understand API usages.
For example, we could infer from Figure 1 the following
method call sequence to perform an audio recording task.
setAudioSource(...)
setOutputFormat(...)
setAudioEncoder(...)
setOutputFile(...)prepare()
start()
stop()release()
Unfortunately, documentationofmostofAPIobjectsdoes
not contain state diagrams representing their usages. In
addition, state diagrams can be used to to check for thevalidityof method call sequences, but not their popularity .
For example, we cannot know from a state diagram that a
sequence is validbuthas never been used , or compare if a
sequence is more likely to be used in practice than another.
Last but not least, current code completion engines like the
thebuilt-inengineinAndroidStudioIDEdonotincorporatestate diagrams in their recommendations.
We design HAPI to take advantages of the usefulness of
state diagrams in representing API usages and address theirdiscussed limitations. In essential, a HAPI is a probabilistic
state diagram . Its nodes and edges associate with probabil-
ities which can be used to estimate the probability of anymethod call sequences. More importantly, its structure andprobabilistic parameters can be learned directly from data.
Figure 2 illustrates a HAPI model learned by SALAD to
represent the usages of a MediaRecorder object. In this ﬁg-
ure, each node of the HAPI represents a state of the object.But diﬀerent from the state diagram in Figure 1, each stateof a HAPI has a probability πfor being the starting state
in a method sequence. It also has a distribution specifying
the probability to call a particular method (i.e. emission
probabilities) and another distribution specifying the prob-
417π = 0.83
setAudioSource() - 0.82
setVideoSource() - 0.170.47
π = 0.0
setAudioEncoder() - 0.80
setVideoEncoder() - 0.190.16
π = 0.01
setOutputFile() - 0.82
setVideoSize() - 0.160.05
π = 0.03
prepare() - 0.82
setPreviewDisplay() - 0.18
setVideoFrameReate() - 0.08
π = 0.02
start() - 0.92
release() - 0.04
stop() - 0.030.43
π = 0.07
reset() - 0.99765431
π = 0.04
setOutputFormat() - 0.9920.52
0.630.16
0.16
0.05
0.30
0.83
0.240.160.70.75
0.110.68
0.19 0.16
Figure 2: HAPI model for usages of MediaRecorder object
ability to change to another state (i.e. transition probabil-
ities). To simplify the drawing, we only show method callsand transition edges with signiﬁcant probabilities in the ﬁg-ure. By design, the states of a HAPI model aim to representthe internal states of the corresponding API objects. The
transition probabilities capture switching patterns of thoseinternal states; and the emission probabilities describe the
method calling patterns at each of those states.
For example, accordingly to the HAPI model in Figure 2,
aMediaRecorder object starts in state (1) with probability
of 83%. In this state, method setAudioSource can be called
with a probability of 82% and when that happens, the ob-ject can change to state (2) with a probability of 52%. Instate (2), setOutputFormat can be called with a probability
of 99% and so on. Technically, a HAPI is a Hidden MarkovModel [34] which can be trained, i.e. inferring its structureand the associating probabilities, from a given collection ofmethod call sequences. Once trained, we can use it to com-
pute and compare the probabilities of any given method se-
quences. For example, the sequence setAudioSource ,setOut-
putFormat, setAudioEncoder would have higher probability
than the sequence setAudioSource ,setOutputFormat, start.
HAPI models have several advantages over plain state di-
agrams. First, the state diagram only speciﬁes the generalrules for using objects but not specify the common usages.In contrast, once learned from code examples, HAPI couldinfer common usages of an API object by searching for the
method sequences that have highest probabilities. Second, a
HAPI could be used to predict the most likely next methodcall in a given API method call sequence. Thus, we canuse HAPI to recommend API usages while developers arewriting code.
3. API USAGE MODEL
In this section, we will discuss HAPI, our proposed sta-
tistical model for API usages in more details. We also re-protected void startRecording(String ﬁle) {
MediaRecorder recorder = newMediaRecorder();
recorder.setAudioSource(MediaRecorder.AudioSource.MIC);
recorder.setOutputFormat(MediaRecorder.OutputFormat.THREE GPP);
recorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR NB);
recorder.setOutputFile(ﬁle);
try{
recorder.prepare();
}catch(IllegalStateException e) {
e.printStackTrace();
}catch(IOException e) {
e.printStackTrace();
}
recorder.start();
}
Figure 3: Code example using MediaRecorder object
introduce GROUM, a graph-based model for object usagesdeveloped previously by Nguyen et al.[31]. SALAD uses
GROUM as a temporary representation for API usages ex-
tracted from mobile apps’ bytecode.
3.1 HMM-based API Usage Model
A HAPI is a generative, probabilistic model that describes
the process of generating method call sequences involving
oneormultipleAPIobjects. AsaHiddenMarkovModel[34],a HAPI formally has a set Q={q
1,q2,...,q K}ofKhidden
states and associates with a set V={v1,v2,...,v M}ofM
API methods of the API object(s) it is modeling. Each stateq
ihas a probability πito be selected as the starting state of
the model. When being in one state, a HAPI can emit (i.e.generate) a method call and/or switch to another state. The
transition matrix A={a
ij|i,j∈1..K}speciﬁes the state
transition probabilities. That means, aijis the probability
that the model changes from state qito state qj. The gen-
erating matrix B={bik|i∈1..K,k∈1..M}speciﬁes the
emission probabilities. Specially, bikis the probability to
call method vkwhen the model is in state qi. As seen, this
HAPI model has K+K2+KMparameters.
With those parameters, the HAPI model can generate a
method sequence Y=(y1,y2,..,y T) via the following gener-
ating process:
1. Sett= 1 and sample the state qitfrom the initial state
distribution π={π1,π2,...,π K}
2. Sample a method call ytfrom the calling distribution
of stateqit,i . e .{bit1,bit2,...,b itM}
3. Sample the next state qit+1from the transition distri-
b u t i o no fs t a t eq it,i . e .{ait1,ait2,...,a itK}
4. Increase ta n dl o o pb a c ks t e p2f o r Titerations.
Modeling API usages using HAPI involves two problems.
The ﬁrst problem is training (i.e. estimate the parameters
of) a HAPI model for one or multiple API objects from ex-isting method call sequences involving. The second problemis using the trained HAPI models to compute the generatingprobabilities of any method call sequences for recommend-
ing API usages. In Section 4, we will present two algorithms
we developed in SALAD to solve those two problems.
3.2 Graph-based Object Usage Model
A HAPI model for one or multiple API objects is trained
by a collection of method sequences involving those objects.Toextractthosesequencesfrombytecode, weemployGROUM,a graph-based model of object usages [31], as a temporary
representation of API usages.
418MediaRecorder.<init>
MediaRecorder.setAudioSource
MediaRecorder.outputFormat
MediaRecorder.setAudioEncorder
MediaRecorder.setOutputFile
MediaRecorder.prepare
MediaRecorder.startMediaRecorder
Stringint
int
int
Figure4: GROUMmodelforusagesof MediaRecorder object
Figure 3 lists a code example with the usage of a Medi-
aRecorder object. Figure 4 illustrates the GROUM built for
the main execution path of that code example. As seen in
this ﬁgure, a GROUM is a labeled, directed graph. It hastwo kinds of nodes: object nodes andaction nodes .A no b -
ject node represents an object. It is labeled by the nameo ft h eo b j e c tt y p e( e . g . MediaRecorder ) and illustrated as
a rounded rectangle in the ﬁgure. An action node repre-sents a method call. It is labeled the method qualiﬁed name(e.g.MediaRecorder.start) and illustrated as a ﬂat rectangle.
There are two kinds of edges representing control ﬂow and
data ﬂow. In the ﬁgure, solid arrows illustrate control ﬂowedges between action nodes while dashed arrows illustratedata ﬂow edges between object nodes and other nodes.
Using GROUM to represent API usage scenarios has two
main advantages. First, we can easily identify all action
nodes having data-dependency with a given object node or
set of object nodes, from which we can extract method se-quences. Second, we could determine if a given set of objectnodes have usage-dependency. A set of object nodes has
usage-dependency if there is at least one action node that
have data-dependency with all of them. SALAD only ex-tracts method sequences of usage-dependent objects becausethey are more likely to represent legitimate API usages in-volving multiple objects.
4. SYSTEM ARCHITECTURE
Figure 5 shows the overall architecture and processing
pipeline of SALAD. For the pre-processing phase, it has
two components to extract GROUMs from bytecode and
source code and another component to extract API methodsequences from those GROUMs. In the training phase, theHAPILearnercomponentisresponsibletousethosemethodsequences to train the HAPI models. Once trained, those
models can use two components Method Call Recommender
andMethodSequenceAnalyzertorecommendanextmethodcalls for a given method sequence and to estimate the like-lihood of that sequence, respectively. In the rest of this sec-
tion, we will present the design and implementation details
of those components.
4.1 Bytecode GROUM Extractor
This component is responsible to extract GROUMs from
Source Code 
GROUM Extractor
Android 
BytecodeCurrent 
Editing Code
API Usage 
Model
API Sequence 
Extractor
ARUSARUSAPI Call 
Sequences
Method Call 
Recommender
Method Sequence 
AnalyzerBytecode GROUM 
Extractor
ARUSARUSAPI Usage 
Models
HAPI Learner
ARUSARUSHAPI 
ModelsARUSARUSAPI Call 
SequencesAPI Sequence 
Extractor
Figure 5: The overview of SALAD’s architecture
apps’ bytecode instructions. Bytecode of Android apps isstored as .dex ﬁles and available on online app markets like
Google Play Store. Thus, the extraction process has three
steps: 1) Downloading the .dex ﬁles, 2) Parsing those ﬁlesinto control ﬂow graphs (CFGs), and 3) Analyzing thoseCFGs to build the GROUMs.
4.1.1 Downloading .dex ﬁles
SALAD has a built-in app crawler developed based on the
Google Play Crawler project [20]. This crawler simulates
an Android device, thus it can access the app store like a
normal smartphone. We program it to download all thetop free/new free apps in all categories. For each downloadapplication package (.apk ﬁles), we extract and store the.dex ﬁles which contain all of its bytecode.
4.1.2 Parsing .dex ﬁles
The next step is to parse .dex ﬁles to build control ﬂow
graphs. SALAD employs smali[19], an assembler/disassem-
bler for Android .dex ﬁles, to obtain bytecode instructionsimplemented for each class and method available in the .dexﬁles. Based on those instructions, SALAD constructs a Con-trol Flow Graph (CFG) for each method to simplify the fur-
ther analysis tasks. Let us discuss this in more details.
Dalvik Virtual Machine. Android apps are originally
developed in Java and re-targeted for execution in Dalvik
Virtual Machine (DVM). DVM is a register-based virtual
machine. It has a set of 32-bit registers for storing primitive
values (e.g. integers and ﬂoating point numbers) and object
419publicString readTextFile(String ﬁleName) throwsIOException {
FileReader fr = newFileReader(ﬁleName);
BuﬀeredReader br = newBuﬀeredReader(fr);
StringBuilder strBuilder = newStringBuilder();
String line;
while((line = br.readLine()) != null) {
strBuilder.append(line);
}
br.close();
returnstrBuilder.toString();
}
Figure 6: A source code example
|[0001dc] IOManager.readTextFile:(Ljava/lang/String;)Ljava/lang/String;
|0000: new−instance v1, Ljava/io/FileReader;
|0002: invoke−direct {v1, v6 },L j a v a / i o / F i l e R e a d e r ; . <init>:(Ljava/lang/String;)V
|0005: new−instance v0, Ljava/io/BuﬀeredReader;
|0007: invoke−direct {v0, v1 }, Ljava/io/BuﬀeredReader;.<init >:(Ljava/io/Reader;)V
|000a: new−instance v3, Ljava/lang/StringBuilder;
|000c: invoke −direct {v3}, Ljava/lang/StringBuilder;.<init >:()V
|000f: invoke−virtual {v0}, Ljava/io/BuﬀeredReader;.readLine:()Ljava/lang/String;
|0012: move −result −object v2
|0013: if−nez v2, 001d
|0015: invoke−virtual {v0}, Ljava/io/BuﬀeredReader;.close:()V
|0018: invoke−virtual {v3}, Ljava/lang/StringBuilder;.toString:()Ljava/lang/String;
|001b: move −result −object v4
|001c: return−object v4
|001d: invoke −virtual {v3, v2 }, Ljava/lang/StringBuilder;.append:(Ljava/lang/String;)Ljava/lang/
StringBuilder;
|0020: goto000f
Figure 7: Dalvik bytecode of code example in Figure 6
references. A frame (activation record) of a method has a
ﬁxed size and consists of a particular number of registersfor storing local variables, parameters (including the this
reference), return values, and temporary values.
Figure6listsacodesnippetandFigure7showstheDalvik
bytecode compiled for the method readTextFile in that snip-
pet. For execution, this method is allocated 7 registers v0-
v6.v5is for the receiver object (i.e. this).v6is for the
parameter, a String object for the ﬁle name. Registers v0-v4
are used for local or temporary variables. Instructions inDalvik bytecode operate on registers. For example, instruc-tionmul-int v2,v5,v3 multiples the values of registers v2and
v5and stores the result to v3. Or instruction new-instance
v1, Ljava/io/FileReader; creates a new FileReader object and
returns the reference of that object to register v1.
Control Flow Graph. WeconstructControlFlowGraph
(CFG) as a representation of bytecode instructions. A nodein the constructed CFG contains a single bytecode instruc-tion and an edge is the control ﬂow between the two instruc-tions. There are two types of nodes in CFG. Control nodesrepresent control instructions in bytecode, e.g. if,return,
throw,o rgotoinstructions. Other instructions are normal
nodes. Normal nodes in a CFG only have one out-goingedge points to the next instruction while control nodes couldhave several out-going edges (if ,switchnodes) or do not have
any (return nodes). Techniques used for constructing CFGs
are quite standard. First, we create all nodes in the CFG,eachonecorrespondstoaninstructionintheinstructionlist.Then, for each node, we use oﬀsets to identify nodes thatare executed after it and add edges from the current node
to those nodes.
4.1.3 Building GROUM
In this step, SALAD takes a CFG as input and produce
GROUMs which describes usage scenario for each execution1 function BuildGROUM(Method M)
2CFG=B u i l d C F G ( M)
3A=∅//list of GROUMs
4St= CreateStartState( CFG,M )
5F=∅
6Push(F,St)
7 whileF/negationslash=∅
8 S=P o p (F)
9 SN= GetStartNode(S )
10 whileSN is nota control node
11 BuildTemporaryGROUM( S,SN)
12 AddExploredNode( S,SN)
13 CN= GetNextNode(SN )
14 ifSN isthereturnnode
15 AddGROUM(A,S )
16 else
17 forNN∈GetNextNodes(SN )
18 ifNN /∈GetExploredNodes( S)
19 Sc=G e t C o p y ( S)
20 SetStartNode( Sc,NN)
21 Push(F,Sc)
22 returnA
Figure 8: Building GROUM Algorithm
path. The main idea of the algorithm to construct GROUM
is to explore all the execution path in CFG and build tem-porary GROUMs when exploring those paths. Once a pathhas been explored, it collects the GROUM that have been
built for that path. Each CFG has a start node which is the
ﬁrst instruction and a termination node which is the returnnode. Our algorithm needs to ﬁnd all execution paths fromthe start node to the termination node. One problem that
the algorithm needs to consider is to handle loops that oc-
cur in the CFG. These loops represent whileorforloops in
source code. The instructions inside loops may be executedeither several times or zero time, thus, could lead to inﬁnitynumber of execution paths. On the other hand, consider-
ing these instructions once can help build usage scenario
associated with loops. Therefore, our algorithm consider in-structions inside a loop to be executed either once or none.In other words, a loop is executed at most once.
Detailed Algorithm. Figure 8 show the pseudo-code
for our algorithm. Input of the algorithm is the bytecodeof a method M. The algorithm starts with creating CFG
from the bytecode instructions using techniques describedthe previous section (line 1). Similar to depth ﬁrst search
algorithm, we maintain a stack Fto store states which are
frontiers to explore (line 4). Each state of our algorithm rep-
resents an incomplete execution path and contains followinginformation: 1) start node: the current node in CFGwhen
a state is pop from stack F, 2) explored nodes: a set of
all nodes in CFG that have been visited 3) a temporaryGROUM. The initial state S
ti sc r e a t e di nl i n e3w i t hs t a r t
node is the begin node of CFG,e x p l o r e dn o d e sa n dt h e
temporary GROUM of this state are empty. The stack Fis
initialized with Stin line 4. In the main whileloop of the
algorithm, each time, a state Sis pop from F.W e s t a r t
withSN, which is the start node of S(line 8) and explore
the path from SNto the next control node in CFG. When-
everSNis a normal node in CFG,w eu s e SNto build
and update the temporary GROUM of S(we will describe
the algorithm to build a temporary GROUM in the nextsection). We then add SNto the set of explored nodes of
Sand update SNequal to the next node of SNinCFG
(because SNis still a normal node in CFG, it only has one
420FileReader.<init>
BufferedReader.<init>
StringBuilder.<init>
BufferedReader.readLine
BufferedReader.close
StringBuilder.toStringFileReader
StringBuilder
StringBufferedReaderFileReader.<init>
BufferedReader.<init>
StringBuilder.<init>
BufferedReader.readLine
StringBuilder.append
BufferedReader.readLineFileReader
StringBuilder StringBufferedReader
BufferedReader.close
StringBuilder.toString
Figure 9: GROUMs
next node). After the loop from line 9 to line 12. SNnow
is a control node in CFG.I fSNis the return node of CFG
then we have explored one execution path of CFG,t h et e m -
porary GROUM of Snow becomes a ﬁnal GROUM, thus,
it is added to the list A(line 14). If SNis not the return
node, we need to consider all unexplored out going edges of
SN. For each next node NNofSN,i fNNis not in the
set of all explored nodes of S, we copy all information of S
into a new state Sc,s e tNNis the start node of Sc,a n d
pushScintoF. The algorithm terminates when the stack
Fbecomes empty. Our algorithm explores all the paths of
CFGand only go through each loop at most one time. The
listAnow contains all GROUM of the method M.W en e x t
describe algorithm to build temporary GROUM.
Building temporary GROUM . Initially, before con-
sidering any instructions, we create an empty GROUM. For
each parameter of the method we create a corresponding
object node and add to the GROUM. When an instruc-tion is considered (line 14), it creates a new action nodeand add that node to the current GROUM. After addingt h en e wa c t i o nn o d e ,w en e e dt ou p d a t ee d g e s . W ea d d
a control edge from the last inserted action node to the
new action node. For data edges, we ﬁrst need to add dataedges from object nodes that are parameters of the instruc-tion to the new action node. To do that, we maintain a
mapM
currentto store the current mapping between regis-
ters and object nodes. When an action node is created, we
useMcurrentto identify all object nodes that are used as
parameters of the action, and we add data edges from thoseobject nodes to the action node. Consider the instruction
000f: invoke-virtual v0, Ljava/io/BuﬀeredReader;.readLine:()
Ljava/lang/String;, it has an input parameter, which is theregisterv0,u s i n g M
currentwe know that when we create an
action node from the instruction, v0 is currenty holding a
reference to a BuﬀeredReader object node. We then add a
data edge from the object node to the newly created actionnode. An instruction may return a value to a register. If itdoes not create a new object i.e. it returns a reference ofan object has already been created before, then we identify
the object node represent that object by M
currentand add a
data edges from the action node to this node. Otherwise, we
create a new object, add a data edge from the action nodeto the new object node and update mappings in M
current.
4.2 API Sequence Extractor
In this section, we describe how to extract API method se-quences for one object or multiple objects from of a methodusing GROUM. For single object, sequence extractor scansthrough a GROUM to ﬁnd object nodes associates with An-
droidAPIobjects. Foreachobjectnode O
iweﬁndallaction
nodes that have data edges connected with Oiand sort these
action nodes by execution order. From the sorted action se-
quence, we only consider action nodes that represent APImethods to get an API method sequence. For example, in
Figure 9, for the ﬁrst GROUM, there are three action nodes
related to the object node BuﬀeredReader and all of them are
Android API methods, thus, the API method sequence asso-ciates the object node BuﬀeredReader is(BuﬀeredReader.init,
BuﬀeredReader.readLine, BuﬀeredReader.close) .
To extract action sequences that involve multiple API ob-
jects, we ﬁrst identity usage-dependent object sets. Foreach action node that represents API methods, we collectall API object nodes that have data-dependent with it, then
we form the set of object types correspond to those objectnodes. In the ﬁrst GROUM of Figure 9, there are two sets of
usage-dependent objects: (FileReader, BuﬀeredReader) has
data-dependency with the action node BuﬀeredReader.init,
and(BuﬀedReader, String) has data-dependency with the
action node BuﬀeredReader.readLine.After collecting usage-
dependent object sets, for each object set, we extract cor-responding API method sequences using same technique forsingle object. For example, the API method sequence for
the set(FileReader, BuﬀeredReader) in the ﬁrst GROUM is
(FileReader.init, BuﬀeredReader.init, BuﬀeredReader.readLine,
BuﬀeredReader.close).
There should be only one method sequence for an ob-
ject or a set of usage-dependent objects in each GROUMof a method. Thus, after extracting method sequences inall GROUMs of the method, we remove duplicate sequencesa n do n l yk e e pd i s t i n c t i v es e q u e n c e s .
4.3 HAPI Learner
T h eH A P Il e a r n e ru s e sac o l l e c t i o no fA P Im e t h o ds e -
quences of an object (a set of usage-dependent objects) tolearn the API usages model. In this section, we describe thetraining algorithm to estimate parameters of HAPI modelfrom training data. We also present a method to choosingt h en u m b e ro fh i d d e ns t a t e s .
4.3.1 Training Algorithm
The training algorithm aims to estimate HAPI’s param-
etersλ=(A,B,π) given a collection of API method se-
quences. In general, Baum-Welch algorithm is often used toestimate parameters of Hidden Markov Model [34]. In thispaper, we present a modiﬁed version of Baum-Welch algo-
rithm for the problem of learning API usages. The input
of the algorithm is a collection of API method sequences.We observed that there are many method sequences are du-plicated in the colllection. Thus, to save space and speedup the training algorithm, we store training data as a map,
where each method sequence is mapped to the number of
time it occurs in the collection. Initially, the parameters ofa HAPI are assigned with random values. The main idea ofthe algorithm is to iteratively estimate parameters to max-
imize the likelihood function (the probability of generating
data given model). The iterative process terminates whenthe estimated values of parameters converge.
Figure10showsthealgorithmfortrainingHAPI.Itsinput
includes training data Sand the number of hidden states K.
4211 function TrainHAPI(TrainSet S, NHiddenStates K)
2initialize λ=(A,B,π )by random values
3 repeat
4 for(Yn=(y1,y2,...,yT),cn)∈S
5 α=F o r w a r d ( λ,Yn,T)
6 β=B a c k w a r d ( λ,Yn,1)
7 fori∈1..K:{compute state transition probabilities}
8 γn
i(t)=αi,tβi,t/summationtextK
j=1αj,tβj,t
9 forj∈1..K,t∈1..T−1:
10 ξn
ij(t)=αi,taijβj,t+1bj(yt+1)
/summationtextK
k=1αk(t)βk,t
11 fori∈1..K:{update model parameters }
12 π(s+1)
i=1
D/summationtextN
n=1cn×γn
i(1)
13 forj∈1..K:
14 a(s+1)
ij=/summationtextN
n=1cn×/summationtextT−1
t=1ξn
ij(t)
/summationtextNn=1cn×/summationtextT−1
t=1γn
i(t)
15 forvm∈V:
16 b(s+1)
i(vm)=/summationtextNn=1cn×/summationtextTt=11yt=vmξn
i(t)
/summationtextNn=1cn×/summationtextTt=1γn
i(t)
17 untilconvergence
18returnλ
19
20 function Forward(HAPI λ, APISequence Y, Position P)
21α={αi,t}1≤i≤K,1≤t≤P
22 fori∈1..K:αi,1=πibi(y1)
23 fori∈1..K,t∈2..P:
24 αi,t=bi(yt)/summationtextK
j=1αi,t−1aij
25returnα
26
27 function Backward(HAPI λ, APISequence Y, Position P)
28β={βi,t}1≤i≤K,P≤t≤T
29 fori∈1..K:βi,T=1
30 fori∈1..K,t∈T−1..P:
31 βi,t=/summationtextKj=1βj,t+1aijbj(yt+1)
32returnβ
Figure 10: Training Algorithm
The parameters of the model are initialized randomly (line
1). Let us describe steps in the main loop of the algorithm:
Step 1. Compute forward and backward probabilities. For
each method sequence in training data we use dynamic pro-gramming to compute forward probabilities α
i,t(usingFor-
wardfunction) and backward probabilities βi,t(usingBack-
wardfunction) [34]. αi,tis deﬁned as the probability of see-
ing partial method sequence y1,y2,...,y tand being in state
qiat timetgiven the model λ:
αi,t=P(y1,y2,...,y t,it=qt|λ)( 1 )
βi(t) is the probability of seeing the ending partial sequence
yt+1,...,y Tgiven state qiat timetand the model λ:
βi,t=P(yt+1,...,y T|it=qi,λ)( 2 )
Step 2. Compute state probabilities γand state transi-
tion probabilities ξusing forward and backward probabili-
ties.γn
i(t) is probability of being at state qiat timetgiven
method sequence Ynand the model λ:
γn
i(t)=P (it=qt|Yn,λ)=αt,iβi,t
P(Y|λ)(3)
The state transition probability ξn
ij(t) is the probability of
being in state qiat timetand making transition to state qj
at timet+1 given method sequence Yand the model λ:
ξn
ij(t)=P(it=qi,it+1=qj|Yn,λ)( 4 )
Step 3. Reestimate model parameters. In this step, the
model parameters are estimated as expected values of prob-
abilities that we computed in the previous step. γn
i(t)i sπ = 0.99
FileReader.init(String) - 0.72
FileReader.init(File) - 0.281
π = 0.01
BufferedReader.init(FileReader) - 0.90
BufferedReader.init(FileReader, int) - 0.092
π = 0.0
BufferedReader.readLine() - 0.993
π = 0.0
BufferedReader.read(char[]) - 0.64
BufferedReader.ready() - 0.33
BufferedReader.skip(long) - 0.024
π = 0.0
BufferedReader.close() - 0.89
FileReader.close() - 0.1151.0
0.920.07
0.14
0.590.01 0.530.46
0.26
1.0
Figure 11: HAPI for FileReader andBuﬀeredReader objects
c o m p u t e da st h ee x p e c t e dn u m b e ro ft i m es t a t eq iis at time
1.a(s+1)
ijis estimated as the expected number of transitions
from state qito state qjcompared to the expected total
number of transitions from state qi.b(s+1)
i(vm) is the ex-
pected number of times the output method have been equal
tovmwhile in state iover the expected total number of
times in state qi. In the update equations, Dis the total
number of method sequences in the training set, and 1 yt=vm
is the indicator function.
4.3.2 Choosing the number of hidden states
When training the HAPI model for an object (or a set
of objects), we need to specify number of the hidden states
as an input for the training algorithm, but we often do notknow the how many states that the object has. Our idea in
choosing the number of hidden states Kis try to build mod-
els with diﬀerent Kand ﬁnd a model that best describe new
method sequences. This problem is equivalent to ﬁnding K
that maximizes the probability of generating new data, i.e.
likelihood function. In this method, we divide a training set
into two sets, one is used to train models and one is used
as validation data to optimize the number of hidden states.For each Kin a range, we train a HMM model with Kas the
number of hidden states. Then, for each model, we compute
the likelihood of validation data which is the probability of
generating the validation data given the model. We thenchooseKof the model that maximize the likelihood of the
validation set. Figure 11 shows graph representation theHAPI model for the pair of objects FileReader andBuﬀere-
dReader as a result of HAPI learner component. To make it
easier to display, we round probabilities and ignore proba-bilities that is less than 0.01.
4.4 API Usage Recommendation
In this section, we present an algorithm for recommending
API method call using HAPI. The input of the algorithm isthe HAPI model Hof an object (set of objects) and the
incomplete API method calls Y=(y
1,...,y N)a s s o c i a t e d
with the object (set of objects) in current editing code. The
location TofYis missing. The output of the suggestion
algorithm is a ranked list of API methods that could be
ﬁlled as the method call at position T. The idea of our
algorithm is to place each API method as the method call of
Yat location Tand compute score of this assignment as the
probability of generating the updated sequence (including
4221 function NextAPICall(HAPI λ, APISequence Y,L o c a t i o nT )
2R=∅/ /ar a n k e dl i s to fc a n d i d a t e s
3α=F o r w a r d ( λ,Y,T−1)
4β=B a c k w a r d ( λ,Y,T +1)
5 forv∈V:
6 fori∈1..K:
7 αi,T=bi(v)/summationtextK
j=1αj,T −1aij
8 βi,T=/summationtextKj=1βj,T+1aijbj(v)
9 score =/summationtextK
i=1αi,Tβi,T
10 UpdateCandidateList( R,v,score )
11 returnR
Figure 12: Algorithm for suggesting next method call
Table 1: Data Collection
Number of apps 207,603
Number of classes 32,080,884
Number of methods 59,636,164
Number of bytecode instructions 1,759,540,508
Space for storing .dex ﬁles 689.8 GB
the new API method) given the HAPI model. Then we
a d dt h eA P Im e t h o dw i t hs c o r et ot h er a n k e dl i s to fa l lcandidates.
Figure 12 shows the algorithm. In the ﬁrst part of our al-
gorithm, we compute forward probabilities at position T−1
(usingForward function). We also compute backward prob-
abilities at position T+1(using Backward function). Then,
we place each API method vas the method call of Yat po-
sitionTand compute forward and backward probabilities at
that position (line 6-8). The scoreofvis the probability of
generating sequence ( y
1,...,y T=v,...,y N) is computed by
summing all product of forward and backward probabilities:
P(Y,y T=v|λ)=K/summationdisplay
i=1P(Y,y T=v,iT=qi|λ)=K/summationdisplay
i=1αi,Tβi,T
The algorithm returns a ranked list of all the API method
candidates with scores for suggestion.
5. EMPIRICAL EV ALUATION
We conducted several experiments to study the run-time
performance of SALAD and compare the accuracy of HAPImodels and baseline models in recommending API methodcalls. All experiments are executed on a computer running
64-bit Ubuntu 14.04 with Intel Core i7 3.4Ghz CPU, 16GBRAM, and 1TB HDD storage.
5.1 Data Collection
Table 1 summarizes data collected for our experiments.
In total, we downloaded and analyzed 207,603 apps from
26 categories in Google Play Store. We only downloadedapps with the average rating of at least 3 (out of 5). Thisis based on the assumption that the high-rating apps wouldhave high quality code, and thus, would contain API usages
of high interest for learning.
Since Android mobile apps are distributed as .apkﬁles,
SALAD unpacked each .apkﬁle and kept only its .dexﬁle.
The total storage space for the .dexﬁles of all downloaded
apps is around 700 GB. SALAD parsed those .dexﬁles and
obtained 32 millions classes .I ta n a l y z e de a c hc l a s sa n d
looked for all methods in the class to build GROUM models.Table 2: Extracting API method sequences
Single object Multiple object
Number of distinct object types (sets) 4,877 43,408
Total number of method sequences 195,692,154 143,678,399
Average number of method sequences 40,125 3,309
Average length of method sequences 3.32 7.72
Table 3: Training HAPI models
Single object Multiple object
Number of trained models 3,042 21,526
Average number of hidden states 14.07 15.65
Total training time 1h 20m 2h 30m
Total space to store trained models 30.3 MB 134.1 MB
Since an Android mobile app is self-contained, its .dexﬁle
contains bytecode of all external libraries it uses. That leadsto the duplication of bytecode of shared libraries. Thus,SALAD maintains a dictionary of the analyzed methods,thus, is able to analyze each method only once. In the end,
itanalyzed 60 millions methods whichhaveintotalnearly
1.8 billions bytecode instructions.
5.2 Extracting API Method Sequences
SALAD built GROUM for each remaining method in the
dataset and extracted API method sequences from those
models. It extracted sequences for both single object us-ages and multiple object usages. Since we focus on learningAndroid API usages, only sequences involving classes and
methods of Android application framework were extracted.
Sequences with only one method call were disregarded.
Table2summarizestheextractionresult. Intotal, SALAD
has extracted nearly 195 millions method sequences
involving single object usages of more than 4,800classes.
There are more than 43,000distinct usage-dependent ob-
ject sets made from those types and SALAD has extractedover 143 millions method sequences involving them.
The running time and space is eﬃcient. SALAD took to-
tally 28 hours to build GROUMs and extract method se-
quences for 200 thousands apps, i.e. 0.5 seconds per app
on average. It needed less than 1.5 GB of working memory.
5.3 Training API Usage Models
Once all API method sequences are extracted and stored,
SALAD trained HAPI models for each object type or usage-dependent object sets. For example, a HAPI is trained forthe usages involving any MediaRecorder object and another
HAPI is trained for the usages involving any two objects{FileReader ,BuﬀeredReader }. However, some HAPIs have
too few sequences for training, making the training proce-dure unstable. Therefore, we do not train usage models forAPI objects with less than 10 method sequences. Overall,
we discarded less than 237,170 sequences out of 350 millions.
The training process for the remaining models is summa-
rized in Table 3. As seen in the table, SALAD is time-
and space-eﬃcient. It trained nearly 24,000 HAPI models
in about 3 hours 50 minutes i.e. 0.55 second/model on
average. The total storage for all of them is of 160 MB, i.e.
7K B / m o d e l on average.
Table 2 and Table 3 show that SALAD can train HAPI
models for 60% (3,042/4,877) of encountering API single
object usages and 50% (21,526/43,408) of multiple object
423usages. However, untrained APIs are rarely used, each has
less than 10 usages in 207,603 apps (59,636,164 methods).
5.4 API Usage Recommendation
We performed an experiment to measure the accuracy of
HAPI in recommending API usages and compare to base-
line models. In this experiment, we chose the task of rec-
ommending the next method call. That is, given an APImethod sequence and the model is expected to recommendthe most probable next method call. This task has beenused in the evaluation of prior approaches [28, 5].
In the experiment, we predicted and evaluated all method
callsin every method sequence from the testing set. For
a method call c
iat position i, we provided its i−1 prior
method calls as the input and used the model to infer the
top-kmost probable next method calls Rk={r1,r2,...,r k}.
Ifciis inRk, we consider it as a hit, i.e. an accurate top-
krecommendation. The top-k accuracy is the ratio of the
t o t a lh i t so v e rt h et o t a ln u m b e ro fe v a l u a t e dm e t h o dc a l l s .
5.4.1 Baseline models
We chose n-gram and recurrent neural network (RNN)
trained for method call sequences as two baseline models for
comparison due to the following reasons. First, both of themare statistical models, thus, is comparable to HAPI, whichis also a statistical model. In addition, n-gram is widely
used in recent research on code completion [14, 30]. More
importantly, Raychev et al.recently evaluated RNN and
n-gram and reported RNN as the best approach.
n-gram model is a simple statistical model for modeling
sequences. An n-gram model learns all possible conditional
probabilities P(m
i|mi−n+1...m i−1), where miis the current
method call and mi−n+1...m i−1is the sub-sequence of n−1
prior method calls. This is the probability that mioccurs as
the next method call of mi−n+1...m i−1. Using the chaining
rule, we can use an n-gram model to compute the generat-
ing probability of any given method sequence m1...m n.I n
our experiment, we used a 3-gram model (i.e. the occur-
rence probability of a method call depends on its two previ-ous calls) as used in prior work [35]. We also implemented
Witten-Bell smoothing [43] technique for this model.
Recurrent neural network (RNN) is a class of neural
networks for learning sequences. Like a HAPI, a RNN can
be trained with a collection of method sequences and thenis able to compute the probability of the next method call
for any given method sequence. In other words, RNN can
compute all conditional probabilities P(m
i|m1...m i−1)f o r
any given a method sequence m1...m n.T od ot h a t ,i tm a i n -
tains a context vector cirepresents current context of sub-
sequence up to m1...m i−1. A function fis learned from data
to compute the context vector at position i,ci=f(mi,ci−1)
given the current method call miand previous context ci−1
while another function gis learned to compute the proba-
bility of the next call mi+1,P(mi+1|m1...m i)=g(ci)g i v e n
the current context ci. In our experiment, we used a pub-
licly available implementation of RNN1with the number of
hidden states of 40 which is also used in prior work [35].
5.4.2 Experiment results
Our experiment is a 5-fold cross validation. That is, for
each object type or object set in the experiment data, we
1http://www.rnnlm.org2 4 6 8 10405060708090100Accuracy (%)Single Object Usages
  
HAPI
RNN
N−GRAM
2 4 6 8 10405060708090100Accuracy (%)Multiple Object Usages
  
HAPI
RNN
N−GRAM
Figure 13: Accuracy of next method call recommendation
divided its method sequences into ﬁve equal folds. HAPIand two baseline models are trained in four folds and testedin the remaining folds (i.e. they are trained and tested in
t h es a m ed a t a ) . W er e p e a t e dt h i sp r o c e s sﬁ v et i m e s ,e a c h
for an individual fold as test data and computed the averageaccuracy of each model in ﬁve iterations as its ﬁnal result.We chose 5-fold cross validation over the popular 10-fold
cross validation to reduce experiment time because RNN is
very time-consuming.
Figure 13 shows the experiment results for method se-
quencesextractedfrombytecodeof200thousandappsdown-loaded from Google Play. As seen in the charts, all three
models have consistent accuracy for single and multiple ob-
ject usages. More importantly, HAPI can recommend APIusages with very high levels of accuracy. For example, forsingle object usage, it has a top-3 accuracy of 90% and a
top-10 accuracy of 98%. In addition, HAPI signiﬁcantly
outperforms RNN and n-gram models. For example, the
corresponding top-3 and top-10 accuracy of n-gram model
are 62% (28% lower) and 82% (16% lower). The top-3 andtop-10 accuracy of RNN model are 76% (14% lower) and
93% (5% lower). On average, HAPI has 11% improvement
over RNN and 21.5% improvement over n-gram.
5.4.3 Discussions
Occam’s razor principle could explain HAPI’s improve-
ment over n-gram and RNN. To model usages involving M
methods, a HAPI with Khidden states uses K+K2+KM
parameters, while an n-gram uses Mnparameters (i.e. all
possible sub-sequences of nmethod calls), and a RNN of H
hidden nodes uses MH+H2+HMparameters. Since Kis
o f t e nm u c hs m a l l e rt h a nH andM, HAPI has less parame-
ters thus easier to train and generalize.
6. RELATED WORK
There exist several works that proposed statistical mod-
els for learning API usages. The most similar research toSALAD is SLANG [35]. SLANG uses n-gram and recurrent
neural networks (RNN) to learn API usage patterns per ob-
ject which are used to predict and suggest next API calls.
Compared with these two models, HAPI has less parametersthus easier to train and generalize. Nguyen et al. [29] in-troduced GraLan, a graph-based statistical language modelthat learns common API usage (sub)graphs from a source
code corpus and computes the probabilities of generating
424Table 4: Experiment settings in recent research about statistical language models for source code
Approach Model Code token Code form Training Testing
SALAD 3-gram, RNN, HAPI Method call (Android) Bytecode 207,603 apps/59,636,164 methods 5-fold cross validation
SLANG [35] 3-gram, RNN Method call (Android) Source code 3,090,194 methods 20 pre-selected examples
GraLan [29] 9-gram Method call (Java) Source code 1,000 projects 5 independent projects
SLAMC [30] 3-gram Semantic token Source code 9 (Java) + 9 (C#) projects 10-fold cross validation
Tu et. al [39] 3-gram (cache) Lexical token Source code 9 (Java) + 9 (Python) projects 10-fold cross validation
Hindle et. al [14] 3-gram Lexical token Source code 5 projects 200 held-out source ﬁles
new usage graphs given the observed (sub)graphs. Although
graphs are better than sequences in capturing context infor-
mation, the number of sub-graphs can grow exponentially.
That means, training sequence-based models would be moretime-andspace-eﬃcient. Inourexperiment, wedonotchoseGraLan as a baseline to compare with HAPI because as a
graph-based statistical model for API usages, it is incom-
patible with the sequence-based models. (GraLan modelsgraphs, not method sequences, thus, cannot operate in thesameexperimentsettingswith HAPI, n-gram, andRNN).In
addition, it is potentially unscalable and likely less accurate.
It is reported in [29] that training GraLan on 1,000 projects
needs 20 hours and 4.5GB [29] (while we have 207,603 appsand its top-3 accuracy is just of 63% (while top-3 accuracyof HAPI is 90%).
Statisticalmodelsforcapturingrulesandpatternsinsource
code become a hot research topic in software engineeringin the recent years. Hassan et al. [12] indicated “natural”software analytics based on statistical modeling will becomeone of the most important of aspects of software analyt-
ics. Hindle et al. [14] showes that source code is repetitive
and predictable like natural language and they adopted n-
gram model on lexical tokens to suggest the next token.SLAMC [30] represents code by semantic tokens, i.e. anno-
tations of data types, method/ﬁeld signatures, etc. rather
than lexical tokens. SLAMC combines n-gram modeling of
consecutive semantic tokens, topic modeling of the wholecode corpus, and bi-gram of related API functions. Tu etal. [39] exploited the localness of source code. White et al.
[42] proposed deep learning approach modeling source code.
Allamanis and Sutton [3] trains n-gram language model a
giga-token source code corpus. NATURALIZE [2] use n-
gram language model to learns the style of a codebase and
suggestnaturalidentiﬁernamesandformattingconventions.
Jacob et al. [21] uses n-gram model to learn code templates.
Hidden Markov Model has been used infer the next tokenfrom user-provided abbreviations [11] and detect coded in-formation islands, such as source code, stack traces, and
patches, from free tex [8]. Maddison et al. [25] proposed
tree-based generative models for source code. Hsiao et al.[17] learns n-gram language model on program dependence
graph and uses the model for ﬁnding plagiarized code pairs.
Table 4 summarizes the diﬀerences of SALAD and some of
those approaches. It suggests that the diﬀerences betweenour results and those published studies might result fromdiﬀerences in code token types and experiment data.
Pattern mining approaches represent usage patterns us-
ing various data structure such as sequences, sets, trees, andgraphs. JADET [41] extracted a usage model as a set of par-tial order pairs of method calls. MAPO [45] mined frequentA P Ic a l ls e q u e n c e sa n ds u g g e s t sa s s o c i a t e dc o d ee x a m p l e s .
Wang et al. [40] mines succinct and high-coverage API us-
age patterns from source code. Acharya et al. [1] proposedan approach to mine partial orders among APIs. Buse andWeimer [7] propose an automatic technique for mining syn-thesizing succinct and representative human-readable API
examples. Other techniques includes mining associate rules
[24], item sets [6], subgraphs [31], [9], code idioms [4], topicmodeling [27], etc.
One application of usage patterns mined from existing
code is to support code completion. Grapacc [28] mines
and stores API usage patterns as graphs and suggest these
graphs in current editing code. Bruch et al. proposed threeapproaches for code completion. First, FreqCCS recom-mends the most frequently used method call. Second, Ar-
CCS mines associate rules and suggest methods that often
occur together. Finally, a best matching neighbors codecompletiontechniquethatmakesused k-nearest-neighboral-
gorithm. SLANG [35] uses n-gram to suggest the next API
call based on a window of n−1 previous methods. Precise
[44] mines existing code bases and builds a parameter usagedatabase. Upon request, it queries the database and rec-ommends API parameters. Graphite [33] allows library de-velopers to introduce interactive and highly-specialized code
generation interfaces that could interact with users and gen-
erates appropriate source code.
Other approaches have been proposed to improve code
completion tasks. Robbes et al. [36] improves code comple-tion with program history. They measure the accuracy of
replaying entire change history of programs with completion
engine and gather information for improvement. In [16], theauthors found that ranking method calls by frequency ofpast usages is eﬀective and propose new strategies for or-
ganizing APIs in the code completion proposals. Hill and
Rideout [13] matches the code fragment under editing withsmall similar-structure code segments that frequently existin large software projects. The authors of [26] and [37]use API documentation to suggest source code examples to
developers. Holmes and Murphy [15] describe an approach
for locating relevant code examples based on heuristicallymatching with the structure of the code under editing.
7. CONCLUSIONS
We propose a statistical approach to learn API usages
from bytecode of Android mobile apps. The key componentof our approach is HAPI, a statistical, generative model
of API usages. We developed three algorithms to extract
method sequences from apps’ bytecode, to train HAPI basedon those method sequences, and to recommend method callsin code completion engines using the trained HAPIs. Ourempiricalevaluationonaverylargedatasetofmorethan200
thousands apps indicates that our approach can eﬀectively
learn API usages from apps’ bytecode and provide API rec-ommendations with high levels of accuracy and outperformt h eb a s e l i n em o d e l s .
4258. REFERENCES
[ 1 ]M .A c h a r y a ,T .X i e ,J .P e i ,a n dJ .X u .M i n i n ga p i
patterns as partial orders from source code: From
usage scenarios to speciﬁcations. In Proceedings of the
the 6th Joint Meeting of the European SoftwareEngineering Conference and the ACM SIGSOFTSymposium on The Foundations of SoftwareEngineering , ESEC-FSE ’07, pages 25–34, New York,
NY, USA, 2007. ACM.
[2] M. Allamanis, E. T. Barr, C. Bird, and C. Sutton.
Learning natural coding conventions. In Proceedings of
the ACM SigSoft Symposium on Foundations ofSoftware Engineering .A C Mˆa˘A¸S Association for
Computing Machinery, November 2014.
[3] M. Allamanis and C. Sutton. Mining source code
repositories at massive scale using language modeling.
InMining Software Repositories (MSR), 2013 10th
IEEE Working Conference on, pages 207–216, May
2013.
[4] M. Allamanis and C. Sutton. Mining idioms from
source code. In Proceedings of the 22Nd ACM
SIGSOFT International Symposium on Foundationsof Software Engineering , FSE 2014, pages 472–483,
New York, NY, USA, 2014. ACM.
[5] M. Asaduzzaman, C. K. Roy, K. A. Schneider, and
D. Hou. CSCC: simple, eﬃcient, context sensitive codecompletion. In 30th IEEE International Conference on
Software Maintenance and Evolution, Victoria, BC,Canada, September 29 - October 3, 2014 , pages 71–80,
2014.
[6] M. Bruch, M. Monperrus, and M. Mezini. Learning
from examples to improve code completion systems. InProceedings of the the 7th Joint Meeting of the
European Software Engineering Conference and the
ACM SIGSOFT Symposium on The Foundations ofSoftware Engineering , ESEC/FSE ’09, pages 213–222,
New York, NY, USA, 2009. ACM.
[7] R. P. L. Buse and W. Weimer. Synthesizing api usage
examples. In Proceedings of the 34th International
Conference on Software Engineering , ICSE ’12, pages
782–792, Piscataway, NJ, USA, 2012. IEEE Press.
[8] L. Cerulo, M. Ceccarelli, M. Di Penta, and G. Canfora.
A hidden markov model to detect coded informationislands in free text. In Source Code Analysis and
Manipulation (SCAM), 2013 IEEE 13th InternationalWorking Conference on, pages 157–166, Sept 2013.
[9] R.-Y. Chang, A. Podgurski, and J. Yang. Discovering
neglected conditions in software by mining dependencegraphs. Software Engineering, IEEE Transactions on,
34(5):579–596, Sept 2008.
[10] R. Dyer, H. A. Nguyen, H. Rajan, and T. N. Nguyen.
Boa: A language and infrastructure for analyzingultra-large-scale software repositories. In Proceedings
of the 2013 International Conference on SoftwareEngineering , ICSE ’13, pages 422–431, Piscataway,
NJ, USA, 2013. IEEE Press.
[11] S. Han, D. R. Wallace, and R. C. Miller. Code
completion from abbreviated input. In Proceedings of
the 2009 IEEE/ACM International Conference onAutomated Software Engineering , ASE ’09, pages
332–343, Washington, DC, USA, 2009. IEEE
Computer Society.[12] A. E. Hassan, A. Hindle, P. Runeson, M. Shepperd,
P. T. Devanbu, and S. Kim. Roundtable: What’s next
in software analytics. IEEE Software, 30(4):53–56,
2013.
[13] R. Hill and J. Rideout. Automatic method completion.
InProceedings of the 19th IEEE International
Conference on Automated Software Engineering ,A S E
’04, pages 228–235, Washington, DC, USA, 2004.IEEE Computer Society.
[14] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and
P. Devanbu. On the naturalness of software. In
Proceedings of the 34th International Conference on
Software Engineering, ICSE ’12, pages 837–847,Piscataway, NJ, USA, 2012. IEEE Press.
[15] R. Holmes and G. C. Murphy. Using structural
context to recommend source code examples. In
Proceedings of the 27th International Conference on
Software Engineering, ICSE ’05, pages 117–125, NewYork, NY, USA, 2005. ACM.
[16] D. Hou and D. M. Pletcher. An evaluation of the
strategies of sorting, ﬁltering, and grouping apimethods for code completion. In ICSM,p a g e s
233–242.
IEEE, 2011.
[17] C.-H. Hsiao, M. Cafarella, and S. Narayanasamy.
Using web corpus statistics for program analysis. InProceedings of the 2014 ACM InternationalConference on Object Oriented Programming SystemsLanguages &#38; Applications, OOPSLA ’14, pages
49–65, New York, NY, USA, 2014. ACM.
[18] http://developer.android.com.
[19] https://code.google.com/p/smali/.[20] https://github.com/Akdeniz/google-play crawler.[21] F. Jacob and R. Tairas. Code template inference using
language models. In Proceedings of the 48th Annual
Southeast Regional Conference, ACM SE ’10, pages
104:1–104:6, New York, NY, USA, 2010. ACM.
[22] J. Kim, S. Lee, S. won Hwang, and S. Kim. Towards
an intelligent code search engine. In M. Fox and
D. Poole, editors, AAAI. AAAI Press, 2010.
[23] M. Linares-V´ asquez, G. Bavota, C. Bernal-C´ ardenas,
M. Di Penta, R. Oliveto, and D. Poshyvanyk. Api
change and fault proneness: A threat to the success ofandroid apps. In Proceedings of the 2013 9th Joint
Meeting on Foundations of Software Engineering,ESEC/FSE 2013, pages 477–487, New York, NY,USA, 2013. ACM.
[24] D. Lo and S. Maoz. Mining scenario-based triggers
and eﬀects. In Proceedings of the 2008 23rd
IEEE/ACM International Conference on Automated
Software Engineering, ASE ’08, pages 109–118,
Washington, DC, USA, 2008. IEEE Computer Society.
[25] C. J. Maddison and D. Tarlow. Structured generative
models of natural source code. In The 31st
International Conference on Machine Learning(ICML), June 2014.
[26] C. McMillan, D. Poshyvanyk, and M. Grechanik.
Recommending source code examples via api callusages and documentation. In Proceedings of the 2Nd
International Workshop on Recommendation Systemsfor Software Engineering , RSSE ’10, pages 21–25, New
York, NY, USA, 2010. ACM.
[27] E. Moritz, M. Linares-Vasquez, D. Poshyvanyk,
426M. Grechanik, C. McMillan, and M. Gethers. Export:
Detecting and visualizing api usages in large source
code repositories. In Automated Software Engineering
(ASE), 2013 IEEE/ACM 28th International
Conference on , pages 646–651, Nov 2013.
[28] A. Nguyen, T. T. Nguyen, H. A. Nguyen, A. Tamrawi,
H. Nguyen, J. Al-Kofahi, and T. Nguyen. Graph-basedpattern-oriented, context-sensitive source code
completion. In Software Engineering (ICSE), 2012
34th International Conference on, pages 69–79, June
2012.
[29] A. T. Nguyen and T. N. Nguyen. Graph-based
statistical language model for code. In Proceedings of
the 37th International Conference on Software
Engineering - Volume 1 , ICSE ’15, pages 858–868,
Piscataway, NJ, USA, 2015. IEEE Press.
[30] T. T. Nguyen, A. T. Nguyen, H. A. Nguyen, and
T. N. Nguyen. A statistical semantic language model
for source code. In Proceedings of the 2013 9th Joint
Meeting on Foundations of Software Engineering,ESEC/FSE 2013, pages 532–542, New York, NY,USA, 2013. ACM.
[31] T. T. Nguyen, H. A. Nguyen, N. H. Pham, J. M.
Al-Kofahi, and T. N. Nguyen. Graph-based mining ofmultiple object usage patterns. In Proceedings of the
the 7th Joint Meeting of the European SoftwareEngineering Conference and the ACM SIGSOFTSymposium on The Foundations of SoftwareEngineering , ESEC/FSE ’09, pages 383–392, New
York, NY, USA, 2009. ACM.
[32] T. T. Nguyen, H. V. Pham, P. M. Vu, and T. T.
Nguyen. Recommending api usages for mobile appswith hidden markov model. In Automated Software
Engineering (ASE), 2015 30th IEEE/ACMInternational Conference on, pages 795–800, Nov 2015.
[33] C. Omar, Y. Yoon, T. D. LaToza, and B. A. Myers.
Active code completion. In Proceedings of the 34th
International Conference on Software Engineering ,
ICSE ’12, pages 859–869, Piscataway, NJ, USA, 2012.IEEE Press.
[34] L. R. Rabiner and B. H. Juang. An introduction to
hidden markov models. IEEE ASSp Magazine , 1986.
[35] V. Raychev, M. Vechev, and E. Yahav. Code
completion with statistical language models. InProceedings of the 35th ACM SIGPLAN Conferenceo nP r o g r a m m i n gL a n g u a g eD e s i g na n dImplementation, PLDI ’14, pages 419–428, New York,NY, USA, 2014. ACM.
[36] R. Robbes and M. Lanza. How program history can
improve code completion. In Proceedings of the 2008
23rd IEEE/ACM International Conference onAutomated Software Engineering , ASE ’08,pages 317–326, Washington, DC, USA, 2008. IEEEComputer Society.
[37] S. Subramanian, L. Inozemtseva, and R. Holmes. Live
api documentation. In Proceedings of the 36th
International Conference on Software Engineering,
ICSE 2014, pages 643–652, New York, NY, USA,
2014. ACM.
[38] M. D. Syer, M. Nagappan, A. E. Hassan, and
B. Adams. Revisiting prior empirical ﬁndings formobile apps: An empirical case study on the 15 most
popular open-source android apps. In Proceedings of
the 2013 Conference of the Center for Advanced
Studies on Collaborative Research , CASCON ’13,
pages 283–297, Riverton, NJ, USA, 2013. IBM Corp.
[39] Z. Tu, Z. Su, and P. Devanbu. On the localness of
software. In Proceedings of the 22Nd ACM SIGSOFT
International Symposium on Foundations of SoftwareEngineering, FSE 2014, pages 269–280, New York,NY, USA, 2014. ACM.
[40] J. Wang, Y. Dang, H. Zhang, K. Chen, T. Xie, and
D. Zhang. Mining succinct and high-coverage apiusage patterns from source code. In Mining Software
Repositories (MSR), 2013 10th IEEE WorkingConference on , pages 319–328, May 2013.
[41] A. Wasylkowski, A. Zeller, and C. Lindig. Detecting
object usage anomalies. In Proceedings of the the 6th
Joint Meeting of the European Software Engineering
Conference and the ACM SIGSOFT Symposium on
The Foundations of Software Engineering, ESEC-FSE’07, pages 35–44, New York, NY, USA, 2007. ACM.
[42] M. White, C. Vendome, M. Linares-V´ asquez, and
D. Poshyvanyk. Toward deep learning softwarerepositories. In Proceedings of the 12th Working
Conference on Mining Software Repositories , MSR
’15,
pages 334–345, Piscataway, NJ, USA, 2015. IEEE
Press.
[43] I. H. Witten and T. Bell. The zero-frequency problem:
estimating the probabilities of novel events in adaptivetext compression. Information Theory, IEEE
Transactions on , 37(4):1085–1094, Jul 1991.
[44] C. Zhang, J. Yang, Y. Zhang, J. Fan, X. Zhang,
J. Zhao, and P. Ou. Automatic parameterrecommendation for practical api usage. InProceedings of the 34th International Conference on
Software Engineering, ICSE ’12, pages 826–836,
Piscataway, NJ, USA, 2012. IEEE Press.
[45] H. Zhong, T. Xie, L. Zhang, J. Pei, and H. Mei. Mapo:
Mining and recommending api usage patterns. InProceedings of the 23rd European Conference onECOOP 2009 — Object-Oriented Programming ,
Genoa, pages 318–343, Berlin, Heidelberg, 2009.Springer-Verlag.
427