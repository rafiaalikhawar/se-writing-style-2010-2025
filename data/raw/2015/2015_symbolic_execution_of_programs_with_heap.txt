Symbolic Execution of Programs with Heap Inputs
Pietro Braione§, Giovanni Denaro§, Mauro Pezzè§♯
§University of Milano-Bicocca♯Università della Svizzera italiana (USI)
Viale Sarca, 336 Via Giuseppe Bufﬁ, 13
Milano, Italy 20126 Lugano, Switzerland 6900
{braione, denaro}@disco.unimib.it pezzem@usi.ch
ABSTRACT
Symbolic analysis is a core component of many automatic
testgenerationandprogramveriﬁcationapproaches. Tover-
ify complex software systems, test and analysis techniques
shall deal with the many aspects of the target systems at
diﬀerent granularity levels. In particular, testing software
programs that make extensive use of heap data structures
at unit and integration levels requires generating suitable
input data structures in the heap. This is a main challenge
for symbolic testing and analysis techniques that work well
when dealing with numeric inputs, but do not satisfactorily
cope with heap data structures yet.
In this paper we propose a language HEX to specify in-
variants of partially initialized data structures, and a deci-
sion procedure that supports the incremental evaluation of
structural properties in HEX. Used in combination with the
symbolic execution of heap manipulating programs, HEX
prevents the exploration of invalid states, thus improving
the eﬃciency of program testing and analysis, and avoiding
false alarms that negatively impact on veriﬁcation activities .
The experimental data conﬁrm that HEX is an eﬀective and
eﬃcient solution to the problem of testing and analyzing
heap manipulating programs, and outperforms the alterna-
tive approaches that have been proposed so far.
Categories and Subject Descriptors
D.2.5 [Software Engineering ]: Testing and Debugging—
Symbolic Execution
Keywords
Symbolic execution, lazy initialization, data structure in-
variants
1. INTRODUCTION
Many approaches for automatic test case generation and
program veriﬁcation exploit symbolic execution, which con-
sists of executing a program with symbolic values, to com-pute the execution conditions of program paths ( path condi-
tions) [26]. Path conditions are used to both generate test
cases that execute the speciﬁc paths and verify programs
against code assertions on those paths.
Symbolic execution handles well programs with numeric
input values like integers and reals, but does not cope well
with heap data structures, thus limiting the eﬃcacy of pro-
gram testing and veriﬁcation approaches. Many popular
embodiments of symbolic execution can analyze complete
programs with numeric inputs, but experience limitations
when testing software programs that make extensive use of
heap data structures at the unit, integration and subsystem
levels [19, 6, 7, 29, 14, 5, 4]. For example, intra- and inter-
class object oriented testing challenges symbolic execution
with objects that depend on parameters and state variables
of structured data types in the heap.
The few attempts to extend symbolic execution to analyze
object oriented programs deal with dynamic heap structures
by enriching the path conditions with assumptions on the
objects in the initial heap. Such assumptions identify the
heap conﬁgurations that determine the execution of the dif-
ferent paths [18, 31, 8, 30, 3, 13]. For example, when ana-
lyzing a program that accesses the ﬁrst node of an input list,
symbolic execution distinguishes the case of an empty list,
which causes an exception, from the case of a non-empty
list, which results in accessing the ﬁrst item of the list. The
mainstream approach, referred to as lazy initialization , con-
sists in the brute force enumeration of all heap objects that
can bind to the structured inputs accessed by the program,
for example either the empty or the non-empty list. When
symbolic execution accesses for the ﬁrst time a reference to
an input object, it systematically enumerates all the possibl e
input objects that can bind to that reference, and identiﬁes
an alternative path condition for each binding.
The brute force enumeration of the input objects may
identify many invalid heap conﬁgurations that violate prop-
erties of the data structures in the heap. Possible properties
include data type invariants, class contracts, implicit pro-
gram assumptions and method preconditions. Symbolic ex-
ecution approaches that overlook the structural properties
can engage in the extensive exploration of invalid program
executions that depend on inputs that contradict the prop-
erties, thus diverging and raising false alarms.
For example, let us consider the class NodeTraversal of
the Google Closure Compiler1that takes as input a parse
tree encoded as an object of type Node. Objects of type
Noderefer to a (linked) list of children Nodes, which can
1https://code.google.com/p/closure-compilerPermission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ESEC/FSE’15 , August 30 – September 4, 2015, Bergamo, Italy
c/circlecopyrt2015 ACM. 978-1-4503-3675-8/15/08...$15.00
http://dx.doi.org/10.1145/2786805.2786842
602recursively refer to other generations of Nodes. The soft-
ware system maintains the implicit property that the Nodes
of any parse tree form indeed a tree-shaped data structure.
Symbolically executing class NodeTraversal with the lazy
initialization approach enumerates many non-tree shaped
parse trees, thus leading to exploring several invalid pro-
gram traces rooted in the symbolic states that include these
invalid parse trees. The enormous amount of invalid traces
mayexceedbyordersofmagnitudethenumberofvalidones,
and thus analyzing the invalid traces wastes most of the
veriﬁcation budget. For example symbolically executing (to
generate test cases) class NodeTraversal with lazy initial-
ization and a time budget of 6 hours led to the exploration
of millions of invalid traces, that is, invocations of the cla ss
with invalid inputs, without producing any valid test case
(we report more details in Section 4). With reference to the
buggy version of class NodeTraversal reported by Just et
al. in [17], the invalid traces led to many false alarms, that
is, invalid tests cases that incorrectly reveal the bug. The
readers should notice that we refer to unit testing, where the
input values are not ﬁltered by the compiler API. System
testing exercises the compiler APIs that builds only valid
parse trees, but it is infeasible to build a symbolic unit test
generator that aﬀords the cost of symbolically analyzing all
the compiler software to generate test cases for a single class.
The problem of representing and reasoning about heap
data structures with rich structural constraints is widely
studied in the context of logic-based automated veriﬁcation
of heap manipulating programs [25, 24, 32, 27, 21, 1, 22, 11].
The diﬀerent proposals compete on their ability to handle
speciﬁc kinds of data structures, for instance lists or trees.
Conversely, the symbolic execution community has payed
little attention to this problem so far. There exist only few
preliminary proposals to reason about the properties of heap
data structures in the context of symbolic execution [31, 8,
30, 3, 13]. These approaches either re-evaluate the consis-
tency of the whole heap structure after every new assump-
tion, or enumerate in advance the sets of valid structures.
The experimental data reported in Section 4 indicate that
none of the existing approaches provides a satisfactory solu-
tion to the problem.
Inthispaper, wepresentanovelapproachforsymbolically
executing programs that take as input both numeric values
and heap data structures, and require rich representation
constraints over these inputs. We thus provide a new tool to
eﬀectively generate test cases and verify software programs
by means of symbolic execution. The core of the approach is
a language and a corresponding decision procedure, jointly
referred to as HEap eXploration Logic (HEX). The language
speciﬁes the properties of the data structures as structural
constraints in a way that enables to check the constraints
against the incremental assumptions on the input objects
that emerge during symbolic execution. Symbolic execution
augmented with HEX evaluates the constraints incremen-
tally, as the heap is progressively reﬁned by symbolic exe-
cution, with advantages on both precision and scalability.
This radically diﬀers from previous approaches.
We evaluated HEX in terms of both analysis speedup
and eﬀectiveness in supporting the automatic generation
of test cases for software programs, and compared the re-
sults with competing approaches based on structural prop-
erties encoded as executable methods of the data struc-
tures [31, 8] and based on bounded/unbounded heap reach-ability provers [25, 16]. We estimated the relative analysis
speedup referring to a set of recursive data structures (lists,
trees, etc.) to investigate the diﬀerent aspects of the ap-
plication domains in breath. We evaluated the eﬀectiveness
of test case generation referring to a set of third-party Java
components with structured input data to gain empirical
evidence of the applicability of the approach in practical
software engineering contexts.
In previous work, we introduced LICS, a framework that
allowed us to experiment the preliminary ideas on a case
study [3]. In this paper we explicitly introduce and deﬁne
HEX, and present an extensive evaluation, which indicates
that HEX improves on the state-of-the-art approaches. The
new results provide evidence that HEX outperforms previ-
ous approaches along diﬀerent dimensions of precision and
performance.
The paper is organized as follows. Section 2 overviews
lazy initialization to make the paper self-contained. Sec-
tion 3 presents HEX and the decision procedure based on
HEX that we propose in this paper. Section 4 presents the
techniques considered in the experiment. Section 5 discusses
the results and the empirical comparison of the diﬀerent ap-
proaches. Section 6 surveys the related work, and Section 7
summarizesthemaincontributionofthepaperandindicates
future research directions.
2. LAZY INITIALIZATION
Symbolic execution supports test case generation and pro-
gram analysis by identifying the execution conditions of the
paths that we want to cover in testing and verify in analysis.
The execution conditions, also known as path conditions , are
symbolic expressions where symbols represent the input val-
ues. When dealing with programs that refer to heap data
structures, like the getList program in Figure 1 that we
use as working example in the paper, symbols may repre-
sent structured objects, for instance a list that contains a
given number of generic objects.
Current symbolic executors handle accesses to heap data
structures by means of a technique commonly referred to as
lazy initialization [31, 8]. Lazy initialization enumerates all
the diﬀerent structures of the heap objects that can bind
to the references accessed while executing the program. For
example, Figure 2 shows the symbolic data structures cre-
ated while symbolically executing the getList program in
Figure 1. These symbolic data structures correspond to the
assumptions that lazy initialization incrementally adds to
the path conditions while symbolically executing the pro-
gram. The ﬁgure presents the assumptions graphically, by
indicating the objects and the relations among them that
are incrementally assumed during the execution.
1 List getList ( List list , intfoo ){
2 if( foo<0){
3 List first = list ;
4 List second = first . next ;
5 return second . next ;
6 }
7 else{
8 if( foo>10)return null ;
9 if( foo>5)return new List ();
10 }
11}
Figure 1: A program that manipulates heap objects.
6031. list ?
1.1 list null
1.2 list ? n0next
1.2.1 list null n0next
1.2.2 list
1.2.3 list ? n1 n0next next
1.2.3.1 list null n1 n0next next
1.2.3.2 list n0next
1.2.3.3 list n1 n0next
nextnext
1.2.3.4 list ? n2 n0next
n1nextn0
next
n1
n0
Figure 2: Symbolic data structures analysed during
symbolic execution.
When starting symbolically executing the program, the
lazy initialization algorithm does not make any assumption
on the input data structure list. This corresponds to a list
that can link to any value, and is concretized in the data
structure labeled 1on the top of Figure 2.
When executed with negative values of the input param-
eterfoo, the program getList navigates through the list
by accessing the ﬁeld nextof the nodes of the list. To ex-
ecute the statement that accesses the ﬁrst node of the list
(line 3), the symbolic executor must distinguish whether th e
parameter listhas value nullor points to a non empty
list. Lazy initialization analyses these two cases separate ly,
by branching the execution in two distinct traces that cor-
respond to the assumptions 1.1and1.2in the ﬁgure, re-
spectively. These two assumptions represent the diﬀerent
behavior of the program that leads to a runtime exception
when executed with data structures that correspond to the
assumption 1.1, and proceeds with a normal execution with
data structures that correspond to the assumption 1.2.
The execution of line 4 with the assumption 1.2navi-
gates ﬁeld nextto access the second node of the list, and
the symbolic execution branches into three assumptions la-
beled1.2.1(nextisnull),1.2.2(nextpoints to a com-
patible heap object – we have only one so far) or 1.2.3
(nextpoints to a heap object that has not been met in the
analysis yet). Similarly when executing line 5 from state
1.2.3, the symbolic execution branches into the assumptions
1.2.3.1,1.2.3.2,1.2.3.3and1.2.3.4. The readers should no-
tice that in this case there are two heap objects compatible
withnextthat are treated separately (assumptions 1.2.3.2
and1.2.3.3). The analysis of the statements at lines 8 and 9
does not depend on new assumptions on the data structure,
and thus proceeds with the initial assumption 1without
distinguishing further subcases.
As illustrated in the example, lazy initialization exhaus-
tively enumerates all possible assumptions on objects and
references when needed to symbolically execute a statement.
Enumerating all possible assumptions without considering
theprograminvariantsthatcharacterizethesemanticsofthe
data structures may produce many data structures infeasi-
ble in the speciﬁc analysis context. For example if getListrequired a circular list, the assumptions 1.2.1, 1.2.3.1 and
1.2.3.2would correspond to invalid inputs that can generate
false alarms and reduce the eﬃciency of symbolic execution.
Thescalabilityandprecisionproblemsofplainlazyinitial-
ization have been addressed by either enumerating the valid
symbolic data structures before starting symbolic execution
or by interleaving symbolic execution with checking engines
that evaluate structural properties. The current approaches
that we discuss in more details in Section 4 address either
scalability or precision, but not both aspects. In the next
section, we introduce the HEap eXploration Logic (HEX), a
property speciﬁcation language that provides a scalable and
precise solution to the lazy initialization problem by sup-
porting the incremental evaluation of structural properties
on partial heaps.
3. HEap eXploration Logic (HEX)
We address the problems that derive from the explicit
enumeration of all possible assumptions on the heap data
structures by deﬁning a new language HEX that speciﬁes
structural constraints over heap data structures in a way
particularly suited to handle input objects during symbolic
execution. HEX speciﬁes the structural properties of the
heap objects as constraints on the incremental reﬁnements
that derive from the lazy inizialization process. The seman-
tics of HEX is given with a decision procedure that is partic-
ularly eﬃcient to evaluate the satisﬁability of a HEX spec-
iﬁcation over partial heap models, as the ones considered
during symbolic execution.
3.1 Partial Heaps
HEX is a language to specify invariants to be veriﬁed on
partiallyinitializeddatastructuresthatwerefertoas partial
heaps. Partial heaps are heap structures where some objects
and references may be missing. They represent inﬁnitely
many complete heaps, that is, the heaps that include all the
objects and references in the partial heap, and may diﬀer in
other objects and references.
Definition 3.1.A partial heap H≡ /an}bracketle{tO,root,R /an}bracketri}htis a
structure where Ois a ﬁnite set of typed heap objects, root
models the external environment that holds the initial refe r-
ences to heap objects, and R⊆(O∪{root})×(O∪{null})
is a set of (named) object references, where nullmodels the
null value. All objects in Omust be reachable from root
through some sequence of references in R. /square
Partial heaps are well suited to model the symbolic data
structures that we described in Section 2. For instance, we
can model the symbolic state 1.2of Figure 2 with the partial
heap/an}bracketle{t{n0},root,list={root→n0}/an}bracketri}htthat assumes the
existence of the object n0and the reference listfromroot
ton0.
The initial state of symbolic execution in general, and in
particular the symbolic state 1in Figure 2, can be modeled
as the most abstract partial heap H⊤=/an}bracketle{t∅,root,∅/an}bracketri}ht.H⊤rep-
resents a partial heap that does not assume any object and
reference. The incrementally reﬁned symbolic data struc-
tures along a program path, as for instance the sequence of
symbolic states /an}bracketle{t1,1.2,1.2.3,1.2.3.4,.../an}bracketri}ht, result in an ordered
set of incrementally reﬁned partial heaps.
The readers should notice that the most abstract heap
H⊤is the top element of a partial order ≤on partial heaps,
604whereHa≤Hbif the sets of objects and references in Hb
are subsets of the ones in Ha, that is, Hais more concrete
(more reﬁned) than Hb. Complete heaps are the minimal
elements of the partial order. The order is partial because
not all heaps are comparable.
Partial heaps can be interpreted as connected directed
graphs of objects linked by references rooted in root. Refer-
ring to this graph interpretation, a partial heap Hcan be
covered by a ﬁnite number of directed spanning trees rooted
inroot, which we refer to as the backbones ofH. Informally,
a backbone is the structure induced by a visit of the partial
heap starting from root. From hence we will write BHfor
the sets of the possible backbones of H.
3.2 HEX Language
AHEXspeciﬁcationdescribesstructuralpropertiesofheap
data structures by introducing constraints on the possible
visits of the partial heaps. A HEX speciﬁcation is inter-
preted by a veriﬁer that either accepts of refuses a partial
heap by visiting the heap starting from root. At each step
of the visit, the veriﬁer visits a (not yet visited) reference,
r∈R, that may point to null(null-reference), to a previ-
ously visited object ( alias-reference) or to a not yet visited
object (expand-reference), and infers the acceptability of the
structures visited so far. The expand-references of a visit
deﬁne a backbone on the heap. HEX sentences specify on
which paths the veriﬁer should expect to ﬁnd null-, alias- or
expand-references.
We now deﬁne HEX in three steps. We ﬁrst deﬁne the
HEXformulas , i.e., the atomic propositional formulas of
HEX predicating over sets of heap paths, and their seman-
tics for a generic partial heap Hrelative to a speciﬁc visiting
order (Deﬁnition 3.2). We then extend HEX with proposi-
tional connectives, and specify the language for path ex-
pressions that identify sets of heap paths (Deﬁnition 3.3).
We ﬁnally generalize the semantics of HEX sentences for all
possible visiting orders of H(Deﬁnition 3.4).
Definition 3.2.LetHbe a partial heap, B∈BHbe a
backbone of H,ˆBbe the set of all the rooted paths of B,
ˆHdef={ˆp·(o→o′)|ˆp∈ˆB, o→o′∈R,target(ˆp) =o}be
the set of the backbone paths leading to all the references, π
andπ′be path expressions denoting two sets of paths ˆπ,ˆπ′
respectively, and typebe a data type. Then HEX formulas
and their respective semantics are:
HEX formula φ= /a\}bracketle{tH,B/a\}bracketri}ht |=φiﬀ
πnot null null /∈target(ˆπ∩ˆB)
πexpands to nothing target(ˆπ∩ˆB)\{null}=∅
πexpands to type target(ˆπ∩ˆB)\{null} ⊆/llbrackettype/rrbracket
πaliases nothing ˆπ∩(ˆH\ˆB) =∅
πaliases some type target(ˆπ∩(ˆH\ˆB))⊆/llbrackettype/rrbracket
πaliases π′target(ˆπ∩(ˆH\ˆB))
⊆target(ˆπ′∩ˆB)
πaliases max π′target(ˆπ∩(ˆH\ˆB))
⊆target(max(ˆ π′∩ˆB))
wheretarget(ˆπ)is a function that returns the objects reached
by paths ˆπ;max(ˆπ)is a function that selects the maximal
paths in ˆπ, i.e., the path that cannot be extended by any
suﬃx to other paths in ˆπ;/llbracket−/rrbracketis the extension of a data
type, deﬁned as the set of the heap objects of that type. /square
Informally, the not null HEX formula accepts a partial
heap where the references visited through the paths ˆ πdo
not point to null. Similarly, the expands to nothing for-mula forbids the paths ˆ πto point to newly visited objects
via expand-references. The expands to formula accepts the
partial heaps only if the expand-references visited through
the paths ˆ πpoint to objects of a given type. The ﬁrst two
aliases formulas accept the partial heaps only if the refer-
ences visited through the paths ˆ πare never alias-references
(ﬁrst formula) or, if they are, they point to objects of a given
type (second formula), respectively. The last two aliases
formulas accept the partial heaps only if the alias-references
visited through the paths ˆ πpoint to objects visited through
either paths ˆ π′or max(ˆπ′), respectively.
Definition 3.3.HEX is the propositional logic language
whose path language is the language of regular expressions
over sequences of reference names. /square
Definition 3.4.LetHbe a partial heap and φbe a HEX
sentence. Then φistrue for HiﬀH|=φiﬀ∀B∈BH:
/an}bracketle{tH,B/an}bracketri}ht |=φ. /square
For example, the HEX sentence
root.list(.next)+not null ∧ (1)
root.list(.next)+aliases root.list (2)
speciﬁes that the list in Figure 2 is circular by requiring a
veriﬁerthatscansthechainof nextﬁelds(identiﬁedwiththe
regular expression root.list(.next)+) to reject the structure
should it meet a null-reference (1) or an alias-reference that
does not point to the ﬁrst node of the list root.list(2).
This leaves as acceptable only expand-references to unseen
list nodes, or a backlink to the ﬁrst node, and leads to re-
jecting the symbolic states 1.2.1,1.2.3.1and1.2.3.2in Fig-
ure 2. As a ﬁnal remark note that (1) does not predicate
anything on expand- and alias-references, nor (2) predicates
on null- and expand-references—in particular (2) does not
forceroot.list(.next)+references to be alias-references.
3.3 HEX Incremental Checking
HEX supports the incremental evaluation of structural
properties on partial heaps, thus improving symbolic exe-
cution. We now present an inductive decision procedure
to evaluate HEX formulas on incrementally reﬁned partial
heaps, and we discuss the use of this decision procedure dur-
ing symbolic execution to eﬃciently check the validity of th e
symbolic states.
The HEX decision procedure determines whether a partial
heapHsatisﬁesaHEXformula φwithrespecttoabackbone
B∈BH. We denote this decision problem as /an}bracketle{tH,B/an}bracketri}ht |=?φ.
From the HEX deﬁnition (Deﬁnition 3.2), we can demon-
strate that we can solve the decision problem /an}bracketle{tH,B/an}bracketri}ht |=?φ
by proving the formula φseparately against each reference
of the partial heap H. We formalize this result in Deﬁni-
tion 3.5 and Theorem 3.6. Deﬁnition 3.5 indicates how the
decision procedure evaluates a HEX formula with respect to
a single reference of a partial heap. Theorem 3.6 demon-
strates that we can solve a decision problem by proving the
formula for all references in the partial heap.
Definition 3.5.Let/an}bracketle{tH,B/an}bracketri}ht |=?φbe a HEX decision
problem; ˆB,ˆH,ˆπandˆπ′the sets of rooted paths as de-
ﬁned in Deﬁnition 3.2; rbe a reference of the partial heap
H;pr∈ˆHbe the path that leads to the visit of the refer-
encerstarting from the backbone; p′
r∈ˆBbe the backbone
605path that reaches the object target(r). Then, the function
¯φ(H,B,r)evaluates the HEX formula φwith respect to the
single reference rof the partial heap Has:
HEX formula φ ¯φ(H,B,r)def=
πnot null pr/∈ˆπ∨r /∈B∨null /∈target(pr)
πexpands to nothing pr/∈ˆπ∨r /∈B∨null∈target(pr)
πexpands to type pr/∈ˆπ∨r /∈B∨null∈target(pr)
∨target(pr)⊆/llbrackettype/rrbracket
πaliases nothing pr/∈ˆπ∨r∈B
πaliases some type pr/∈ˆπ∨r∈B∨target(pr)⊆/llbrackettype/rrbracket
πaliases π′pr/∈ˆπ∨r∈B∨p′
r∈ˆπ′
πaliases max π′pr/∈ˆπ∨r∈B
∨target(pr)∈target(max(ˆ π′∩ˆB))
Theorem 3.6.Let/an}bracketle{tH,B/an}bracketri}ht |=?φbe a decision problem.
Then:/an}bracketle{tH,B/an}bracketri}ht |=φiﬀ∀r∈H:¯φ(H,B,r) /square
Informally, the theorem is a consequence of the fact that
the deﬁnition of ¯φis a direct interpretation of the semantics
of HEX (Deﬁnition 3.2) against the heap path that reaches
a given reference in one step from the backbone. Thus eval-
uating¯φfor all the references of a partial heap is equivalent
to evaluating the formula for all paths ˆHandˆBconsidered
in Deﬁnition 3.2. The readers interested in the proof of the
theorem can ﬁnd the details in our online report on HEX.2
Theorem 3.6 allows us to solve the decision problem in-
crementally when dealing with incrementally reﬁned partial
heaps. For a partial heap Hbthat is more reﬁned (less ab-
stract) than a heap Ha, we decompose the decision problem
/an}bracketle{tHb,Bb/an}bracketri}ht |=?φin two parts: The ﬁrst part corresponds to
solving the decision problem /an}bracketle{tHa,Ba/an}bracketri}ht |=?φfor some back-
boneBathat is a preﬁx of the backbone Bb. The second
part corresponds to proving the formula on the references of
Hbthat are not in Ha.
We instantiate the above decision procedure inductively
to eﬃciently evaluate the structural properties against heap
structures that are incrementally assumed during symbolic
execution, thus preventing the exploration of invalid sym-
bolic states.
As discussed in the previous section, the symbolic exe-
cution of a program both produces an ordered sequence of
incrementally reﬁned partial heaps and identiﬁes incremen-
tal backbones of the partial heaps in the sequence. Thus,
our inductive decision procedure evaluates the validity of th e
partial heaps produced during symbolic execution starting
from the empty partial heap H⊤that represents the input
objects at the beginning of the execution. For the partial
heapHnthat represents the assumptions on the input data
structures at a given symbolic state Sn, the decision proce-
dure deals with the decision problem /an}bracketle{tHn,Bn/an}bracketri}ht |=?φ, where
Bnis the backbone of Hnidentiﬁed on the symbolic trace
that led to Sn. To solve this problem, the decision pro-
cedure assumes that the problem /an}bracketle{tHn−1,Bn−1/an}bracketri}ht |=?φhas
already been solved at the immediate predecessor symbolic
stateSn−1, and evaluates the formula under concern against
the single reference assumed in Hnafter the last execution
step.
Working incrementally, our decision procedure radically
diﬀers from previous approaches that either re-evaluate the
consistency of the whole input structures upon any single
new assumption on the heap structures, or enumerate the
sets of valid assumptions in advance. In the experiments
reported in Section 4, we present empirical evidence that
2http://www.lta.disco.unimib.it/tools/hex/HEX outperforms state-of-the-art other approaches that can
be used to prevent the exploration of invalid data structures
in symbolic execution.
The inductive decision procedure may produce some false
positives due to backbone generalization and aliases max
propositions. The decision procedure works on the back-
bones identiﬁed during symbolic execution, and the satis-
ﬁability verdicts cannot be always generalized to all possi-
ble backbones, as required in Deﬁnition 3.4. The incremen-
tal embodiment of the decision procedure over-approximates
the decisions involved in aliases max propositions. In fact,
the satisﬁability verdicts computed with respect to the max-
imum paths of a backbone could be invalidated after ex-
tending the backbone with new paths in some future sym-
bolic state. As discussed in Section 4, none of these sources
of unsoundness manifested in our experiments, indicating
that these issues are rare in many practical situations. Con-
versely, our empirical data indicate that the imprecision due
to the other approaches can be high.
3.4 HEX Prototype Implementation
We implemented the HEX incremental decision procedure
in our JBSE3symbolic executor [3]. The implementation of
the HEX decision procedure augments the symbolic states
withassumptionsontheconsistencybetweennumericinputs
and the data structures in the partial heaps. For example,
if the data type Listof Figure 2 would maintain an integer
ﬁeldsizeto cache the size of the list, it might be neces-
sary to enforce the assumption that ﬁeld sizeis always at
most/exactly equal to the number of list nodes in the par-
tial/complete data structure assumed in the partial heaps.
JBSE accepts an extension of HEX where an atomic pred-
icate can be associated with a companion method : When
the incremental decision procedure computes the satisﬁabil-
ity of a reﬁned partial heap, JBSE executes the compan-
ion methods associated with the atomic predicates whose
path expressions were satisﬁed by the last reference assumed
in the heap. The users can exploit this mechanism to en-
code the assumptions on the numeric ﬁelds as assume state-
ments in the companion methods. Our experiment repli-
cation package2includes several examples of data structure
properties speciﬁed in HEX.
4. DESIGN OF THE EXPERIMENT
We experimentally evaluate the precision and eﬃciency
of HEX with respect to both the plain lazy initialization
algorithm that we refer to as baseline, and the alternative
state-of-the-art approaches. The precision of the diﬀerent
approaches is the ability to identify executions that do not
violate the constraints on the input data structures. We
quantify the precision of an approach in terms of valid ver-
sus invalid symbolic states identiﬁed by the corresponding
decision procedure, sizing the set of invalid states that resul t
in false alarms. We measure the eﬃciency of the approaches
comparing the time overhead on symbolic execution.
We executed the experiments on a benchmark that in-
cludes third party implementations of classic data structures
and classes of open source programs. In the next subsec-
tions, we discuss the approaches that we considered in the
experiment, the programs used as inputs to the symbolic
3http://pietrobraione.github.io/jbse/
606executor and the metrics that we collected to measure eﬀec-
tiveness and eﬃciency.
4.1 Techniques
We identify the main classes of alternative approaches
as enumerating the valid (non-partial) symbolic data struc-
tures before starting symbolic execution [8], and interleav-
ing symbolic execution with checking engines that evaluate
structural properties. The latter approaches include execut-
ing checking programs that encode the structural proper-
ties operationally [31] and querying some established satisﬁ-
ability prover that evaluates property speciﬁcations in some
logic [16, 25, 21, 27, 24, 32, 1, 22, 11]. The provers may ad-
dress either bounded (for instances speciﬁed in Alloy [16])
or unbounded (for instance speciﬁed in PALE [25]) satis-
ﬁability problems. In detail, our experiments consider the
following set ( T) of techniques:
Lazy: The plain lazy initialization algorithm, outlined in
Section 2, without techniques for dealing with constraints.
This is the baseline to evaluate the diﬀerent approaches.
HEX: The HEX approach, that is, the technique that instan-
tiates the decision procedure presented in the previous sec-
tion to incrementally check structural properties speciﬁed in
HEX.
PrEP: Theclassicapproachofpre-evaluatingexecutableprop-
erties that consists of enumerating the valid symbolic data
structures in advance by symbolically executing their con-
straints encoded as executable properties [8]. Encoding the
representation invariants of an abstract data type in the
form of executable methods, referred to as repOkmethods,
is a common practice in object oriented programming [20].
As an example, the code on white background in Figure 3
illustrates a possible repOkmethod for the class LinkedList
partially reported in the ﬁgure: repOkreturnsfalseif the
headerisnull(line 7), the nextandprevious references do
not match between the data nodes (line 15) or the value of
the ﬁeld sizediﬀers from the count of data nodes (line 19).
Technically, given a program Pthat takes as input the data
structures iniwith invariants encoded as repOkmethods,
the technique PrEPconsists of symbolically executing the
program if(/logicalandtext
iini.repOk())P(in1,...,inn).As a drawback,
thistechniquecanover-constrainthesymbolicinputs, foster-
ing the analysis of multiple distinct assumptions on objects
and ﬁelds that are not accessed by the program.
ConsP: The extension of the repOkapproach proposed by
Visser et al. that consists of evaluating the executable prop -
erties during (rather than before) symbolic execution [31].
The approach relies on the concept of conservative repOk
methods, an extended version of the executable properties
thatcanbeevaluatedagainstpartiallyinitializeddatastru c-
tures. As an example, Figure 3 reports the conservative
extensions of the repOkmethod on grey background. The
conservative repOkmethod returns trueeither if the ﬁeld
headeris not initialized (line 6) or if ﬁeld nextof the tra-
versed node is not initialized (line 11). The conservative
repOkskips the next-previous check if the ﬁeld ” previous ”
of the next node is not initialized (line 14). The eﬀectivene ss
of this technique depends on the quality of the conservative
properties, since a direct extension of the original repOkmay
miss some invalid partial models, for instance, the imple-
mentation in Figure 3 misses the invalid partial models in1class LinkedList {...
2 intsize = 0;
3 Entry header = newEntry ();
4 class Entry{Entry next , previous ; ... }
5 boolean repOk() {
6 if(σ(header )) return true ;
7 if(header == null)return false ;
8 Entry e = header ;
9 intpos = 0;
10 do{
11 if(σ(e . next )) return true ;
12 if(e . next == null)return false ;
13 if(
14 ! σ(e . previous . next) &&
15 e . previous . next != e) return false ;
16 e = e . next ;
17 if(e != header) pos++;
18 }while (e != header );
19 return pos == size ;
20 }
21}
σ(·) denotes a query to the symbolic executor on whether a refere nce
holds a symbolic (not yet initialized) value in the current st ate.
Figure 3: Class LinkedList with arepOkmethod and
its conservative version.
which nodes are linked through ﬁeld previous while some
ﬁeldsnextare not initialized yet. A further limitation is
that the conservative repOkevaluates single data structure
instances and cannot enforce constraints over multiple struc-
tures, and this may impact on the ﬁnal results, as discussed
in Section 4.
Alloy: Theapproachofusingaboundedsatisﬁabilityprover
to verify the validity of the data structures explored during
symbolic execution. We instantiate this approach with Al-
loy, a relational logic language to describe the properties of
object structures [16]. We rely on the Alloy analyzer to ver-
ify the satisﬁability of the properties in conjunction with the
structural assumptions that emerge during symbolic execu-
tion. The Alloy analyzer computes the satisﬁability of the
formulas provided an upper bound to the number of objects
that can be assumed in the initial heap. As all bounded
veriﬁers, Alloy can decide the satisﬁability of a problem if
it identiﬁes a solution, otherwise the result is inconclusive ,
since a solution may always exist in a larger scope. Alloy
requires the user to specify the bound limit, and accepts
only the symbolic states whose satisﬁability can be proved
within the given bound limit. The choice of the upper bound
impactsontheprecisionandperformanceofsymbolicexecu-
tion: small bounds increase the likelihood of rejecting valid
symbolic states, big bounds slow down the process.
PALE: The approach of expressing the structural properties
in some logic that comes with a decision procedure for un-
bounded problems. We instantiate the technique with the
Pointer Assertion Logic Engine (PALE [25]). PALE builds
on monadic second order logic to express properties for tree-
shaped graphs of objects. The decision procedure is imple-
mented on top of MONA, an established tool to address de-
cision problems over a restriction of monadic second order
logic [15]. PALE can yield conclusive results both against
satisﬁable and unsatisﬁable problems, while the possible in -
607Table 1: Size of the subject programs
P1P2P3P4P5P6P7 All
LOC 3615143222116077,972 5,972 15,959
LOC = Non-comment lines of code in the class under analysis an d in
the classes invoked by the class under analysis.
conclusive outcomes depend on the incompleteness of the
decision procedure. For example, PALE does not handle
numeric constraints and cyclic graphs of objects. The tech-
niquePALErejects the symbolic states with conclusive unsat-
isﬁability results, and accepts all others as either satisﬁab le
or potentially satisﬁable.
For the experiment reported in this paper, we extended
the symbolic executor JBSE [3] to support the techniques
HEX,PrEP,ConsP,AlloyandPALE. We would like to em-
phasize that only Lazy,PrEPandConsPhave been already
proposed in the context of the symbolic execution of heap
data structures. HEXis proposed in this paper, and Alloy
andPALEare experimented in the context of symbolic exe-
cution for the ﬁrst time in this paper.
4.2 Subject Programs
In the experiments, we challenge symbolic execution to
analyze third party Java programs. The subject programs
include both classes that incapsulate classic recursive data
structuresandopensourceJavacomponentswithstructured
input data. We consider the following subject programs,
whose size is reported in Table 1:
P1: ClassLinkedList taken from the SIR repository [10]
that implements doubly linked lists.
P2: ClassTreeMap taken from the SIR repository that im-
plements red-black trees, a type of balanced binary trees.
P3: An implementation of AVL trees taken from the exper-
imental benchmark used by Galeotti et al. [12].
P4: A caching circular double linked list that implements
the interface Listfrom the Apache Commons project, taken
fromtheexperimentalbenchmarkusedbyGaleottietal.[12].
P5: ClassTrajectorySynthetizer of the TSAFE prototype
described in [9] that takes as input the position coordinates
of a ﬂight and the ﬂight plan represented as a linked list
of ﬂight points, and computes the current trajectory of the
ﬂight.
P6: ClassNodeTraversal oftheGoogleClosure-compilerfor
JavaScript (Git hub commit 509fec1) that takes as input a
parse tree encoded as an object of type Nodeand refers to a
linked list of function control ﬂow graphs, and implements
a traversal of the nodes in the parse tree.
P7: ClassRenameLabels of the Google closure-compiler for
JavaScript (Git hub commit 393fceb) that takes as input
a parse tree encoded as an object of type Nodeand some
external Nodes, and processes the nodes of type LABEL.
The experiments on the methods of the recursive data
structures ( P1—P4) study the relative strengths of the dif-
ferent approaches in breath, since these methods take ob-
jects of the type of the considered data structures as inputand make several diﬀerent computations that rely on the
implicit assumption that the input objects satisfy the struc-
tural properties of the data structures. For these subject
programs, we symbolically executed all single methods and
pairs of method calls for a total of 274 analysis targets.
Theexperimentsontheopensourcecomponents( P5—P7)
provide preliminary evidence of the eﬀectiveness of the dif-
ferent approaches when using symbolic execution for testing
and veriﬁcation in practical software engineering contexts.
For these programs, we symbolically executed methods with
either correctness properties or known faults, referring to
the correctness properties of P5described in [3] and to the
faults of P6andP7mined by Just et al. and identiﬁed as
bug37andbug72, respectively [17].
P1andP2include the repOkimplementation of the repre-
sentation invariant of the data structures, P3andP4include
JML representation invariants. P5andP6refer to a linked
list and share the same invariant of P1.P6andP7refer to
a parse tree, and thus we implemented the invariant that
encodes the tree properties.
For all programs, we rephrased the structural properties
as required by the considered technique: We implemented
thelogicspeciﬁcationsof P3andP4asexecutablepredicates;
We adapted all the executable predicates to a conservative
version, by relaxing the constraints of the ﬁelds not yet ini-
tialized; We implemented the HEX and Alloy versions of all
the representation invariants, and the PALE version of the
representation invariants of P2andP3. The invariants of
the data types P1,P4,P5,P6andP7cannot be modelled in
PALE that does not handle cyclic graphs of objects, thus we
do not experiment technique PALEon these programs. All
property speciﬁcations are available as part of the experi-
ment replication package.2
We executed the experiments with the JBSE symbolic
executor ([3]) suitably extended to deal with the diﬀerent
techniques. Each experiment corresponds to an execution
of JBSE instantiated with a technique in Ton a method
or a pair of methods of a subject program. We allocated a
maximum time of 2 hours for each experiment with the re-
cursive data structures P1—P4that include many small size
analysis targets, and of 6 hours for the experiments with the
open source components P5—P7that represent medium size
analysis targets.
Some subject programs include loops and recursive calls,
and thus the symbolic execution may not terminate. To en-
force termination, we bound both the number of objects in
the explored partial heaps, and the maximum depth of the
execution traces. In the experiments, we bounded the size
of the input list or tree of P1—P7to 5, 3, 4, 4, 3, 4 and 4,
respectively. The bounds take into consideration the com-
plexity of the data structure that impacts on the duration
of the symbolic execution.
The experiments with Alloy required us to specify a veri-
ﬁcation bound for the Alloy analyzer. This bound expresses
the maximum number of objects that can be used to show
that there exists a valid concrete heap that satisﬁes a par-
tial heap assumed during symbolic execution. To avoid false
negatives, the Alloy bound must be set higher than the heap
bound of symbolic execution that constrains the size of the
partial heaps. In all experiments with Alloy, we carefully op-
timized the Alloybound as the minimal value to achieve the
maximum precision, that is, to exclude all spurious traces
without incurring false negatives.
6084.3 Metrics
We quantify the precision of the symbolic execution in
terms of the avoidance of invalid symbolic states and the
side-eﬀects induced by the techniques Ton the valid sym-
bolic states. We quantify the eﬃciency in terms of the
time elapsed to complete the symbolic execution of the valid
states.
Wemeasuretheavoidanceofinvalidsymbolicstatesasthe
number of end-of-trace symbolic states that depend on some
invalid initialization of the input objects. If there are no
invalid end-of-trace symbolic states the precision is optimal ,
that is, the symbolic execution explores only valid symbolic
states. Increasing amounts of invalid end-of-trace symbolic
states correspond to increasingly less precise approaches.
We measure the side-eﬀects induced by a given technique
as the ratio Rbetween the number of valid end-of-trace
symbolic states counted when using the technique and us-
ing no technique ( Lazy), respectively. The ratio Rindi-
cates if the technique ¯T∈Tinterferes with the ability
of the symbolic executor to discriminate the valid inputs.
The interferences may result in either under-approximating
or under-generalising the results of the symbolic execution.
The technique ¯Tunder-approximates the results if the sym-
bolic executor explores less valid symbolic states when us-
ing the technique ¯Tthan when using no techniques. The
technique under-generalizes the results when some symbolic
states computed when using ¯Tare subsumed by smaller sets
of symbolic states when using no technique, meaning that
thetechniquereducestheabilityofgeneralisingthesymbolic
execution. Under-approximation corresponds to R <1, no
eﬀect to R= 1 and under-generalization to R >1. The
readers should notice that, when under-approximation and
under-generalization eﬀects interfere, values of the ratio R
that strongly diﬀer from 1 capture the dominance of either
type of eﬀect.
Wemeasuretheeﬃciencyasthetimerequiredtocomplete
the symbolic execution of each program, aiming to quantify
the relative impact of the speciﬁc technique on the time cost
of the symbolic execution.
We designed a measurement infrastructure that evaluates
thestructuralpropertiesoftheﬁnalstates. Theexperiments
were executed on a linux server equipped with 4 Intel Xeon
8-core CPUs and 64 GB of RAM memory, using a make-
ﬁle to parallelize the symbolic execution of the benchmark
programs.
5. DATA ANALYSIS
This section presents the results of the experiments. Each
ofthe6techniquesin Tisexperimentedagainstboththe274
analysis targets of P1—P4and the methods related to cor-
rectness properties or faults in P5—P7. Some experiments
ran out of memory, and are not included in the results. The
ﬁnal dataset includes data from 1,352 experiments.
5.1 Invalid Symbolic States
Figure 4 plots the distribution of invalid end-of-trace sym-
bolic states that we measured across the experiments, and
Table 2 reports the details of the experiments with the sub-
ject programs P5—P7that represent practical software
engineering cases. The experimental data conﬁrm that the
lazy initialization algorithm produces a huge amount of spu-
rious symbolic traces in the presence of structural proper-
ties of the symbolic data structures. The technique LazyTable 2: Experiments on the open source subjects
Elapsed
minutes#Traces #Invalid
traces#Alarms #False
alarms
P5Lazy timeout 23,854 23,675 12,434 12,434
HEX 2 290 0 0 0
PrEP 92,250 1,690 0 0
ConsP 52 1,130 840 0 0
Alloy 56 290 0 0 0
P6Lazy timeout 2,419,860 2,419,860 62,260 62,260
HEX 72,856 0 128 0
PrEP 154 96,256 90,240 4,096 3,840
ConsP 41 6,426 3,570 288 160
Alloy 306 2,856 0 128 0
P7Lazy timeout 41,723 41,717 14,494 14,494
HEX 2 925 0 30 0
PrEP 1226,960 25,850 2,130 2,100
ConsP 251 25,045 24,120 2,100 2,070
Alloy 17 925 0 30 0
yielded invalid symbolic traces in 184 experiments with a
median value of 2,114 invalid traces and up to a maximum
ofover2,419,860traces(in P6where, duetothetimelimit, it
yielded invalid traces only). The techniques ConsPandPALE
yielded invalid symbolic traces in 110 and 53 experiments,
with third quartile values of 301 and 186 invalid traces, and
maximum of 48,267 and 2,328, respectively, thus perform-
ing better than pure lazy initialization but still incurring
precision problems in several cases. The techniques PrEP
does not yield spurious traces for the recursive data struc-
tures (P1—P4) but computes several invalid traces for the
open source programs P5—P7, as shown in Table 2. The
techniques HEXandAlloydo not produce any false positive
across all subject programs, that is, they always succeed in
discarding the invalid symbolic structures produced by the
lazy initialization algorithm.
With reference to the faults and the veriﬁcation goals in-
volved with the analysis of the programs P5—P7, the last
two columns of Table 2 indicate that the spurious traces
computed during the symbolic execution can result in large
amounts of annoying false alarms that may impact on the
software engineering practice.
ThePrEPtechniquefailsindiscardingalltheinvalidtraces
because of the inability of the repOkmethods to deal with
alias relationships between distinct input structures. For
example, the conservative repOkof the two parse tree pa-
rametersofclass RenameLabels failstoidentifyillegalaliases
between the input trees. This limit of the repOkapproach
with inter object constraints aﬀects the ConsPtechnique too.
Furthermore, the ConsPtechnique suﬀers from the incom-
pleteness of the considered conservative predicates derived
as straight adaptation of the repOkmethods. For example,
we already commented that the conservative adaptation of
therepOkof classLinkedList of Figure 3 iterates only for-
ward on the list, and cannot enforce the invariant on the
partialdatastructurescomputedwhenanalysingtargetcode
that accesses the list in the opposite direction. Thus our ex-
periments provide empirical evidence that relying on repOk
methods is not suﬃcient to discard all the invalid traces
produced by the lazy initialization algorithm.
The invalid traces in PALEdepend on the limits of PALE
in accounting for the numeric constraints in the invariants.
5.2 Under-Generalization Effects
Figure 5 plots the distribution of the portion of valid end-
of-trace symbolic states measured when using a given tech-
609The box-plots report the minimum, the ﬁrst quartile, the med ian (in
bold), the third quartile and the maximum number of invalid t races.
Figure 4: Distribution of the invalid end-of-trace
states yielded by symbolic execution when combined
with the considered techniques.
nique with respect to the baseline case of relaying on lazy
initialization only. Only PrEPincurs in under approximation
eﬀects, meaning that it causes symbolic execution to explore
less traces than when using Lazy(values less than 1 in Fig-
ure 5). The reason is that enumerating all objects in the in-
put data structures beforehand results in over-constraining
the scalar ﬁelds that depend on such objects, for instance,
the ﬁeld sizeof classLinkedList .
BothPrEPandHEXincur some under generalization ef-
fect, meaning that they cause symbolic execution to explore
more traces than when using Lazy(values greater than 1 in
Figure 5), PrEPto a large and HEXonly to a partial extent.
The relevant under generalization eﬀects in PrEPdepend on
the early enumeration of the possible input structures that
competes with the goal of lazy initialization of reducing the
number of traces to be analyzed by delaying the resolution
of the symbolic references.
The under generalization of the HEXapproach manifests
only for the red-black tree case study ( P2), and depends on
the tight relation between the valid shapes of the data struc-
tureandthescalarvaluesthatrepresentthered/blackstatus
of the internal data nodes: Evaluating the valid initializa-
tions of the data nodes requires HEX companion methods
that foster the symbolic executor to enumerate the possible
conﬁgurations of red and black nodes for the incrementally
assumed partial heaps. Table 2 conﬁrms that HEXdoes not
incuranyundergeneralizationontheconsideredopensource
programs.
5.3 Efﬁciency
Figure 6 presents the time for completing the symbolic
execution of the subject programs when using each consid-
ered technique with respect to HEX. We observe that only the
performance of PALEis comparable with the average execu-
tion time of HEX, while the median execution times of PrEP,
ConsPandAlloyare 2.4, 3.4 and 4.3 times the execution
time ofHEX, respectively.
Table 2 emphasizes the performance advantages of HEX
Figure 5: Distribution of the ratio between the valid
end-of-trace states yielded by symbolic execution
when combined with the considered techniques with
respect to plain lazy initialization.
with respect to Alloy, the only competing technique in line
withHEXin terms of precision: For the analysis of the sub-
jectsP5,P6andP7,HEXis faster than Alloyof a factor
28, 44 and 8, respectively. The data conﬁrm the well-known
problem that the performance of a bounded veriﬁer quickly
falls down with the increase of the bound value, and indi-
cate that Alloycan result in unacceptable performance even
with medium bound values, for instance the optimal Alloy
bound was 13 for P5andP6and 9 for P7, that are likely to
be minimal requirements in the case of realistic applications.
5.4 Summary
The experimental data conﬁrm that the main merit of
HEX is the scalability of the approach without giving up
precision. The HEX approach outperforms PrEP,ConsPand
PALEin terms of precision, in that it does not incur any false
positive or false negative, and does not result in under gen-
eralization eﬀects for 6 out of the 7 subject programs. Alloy
shares similar precision ﬁgures as HEX, but the performance
of the analysis is signiﬁcantly better with HEX than with
Alloy. The good performance of HEX is a result of the incre-
mentality of its decision procedure that represents a major
improvement of HEX on the state of the art approaches.
5.5 Threats to Validity
A main threat to the validity of the results springs from
the dependence of the ConsPapproach on the implementa-
tion of the conservative properties. We mitigate this threat
in two ways: In the experiments with P1—P4we use the
transformation of the properties speciﬁed by the developers
into conservative properties according to the approach of the
ConsPproposers [31]; In the experiments P5—P7we have
implement optimal versions of the conservative properties
based on our experience with the partial models generated
during the symbolic execution of the target programs. The
results of the experiments conﬁrm that diﬀerent implemen-
tation choices do not aﬀect the results of the experiments.
The quality of the measurements depends on the relia-
610Figure 6: Distribution of the relative time spent to
complete the symbolic execution when using either
a technique ¯TorHEXfor the experiments where both
¯TandHEXcomplete within the time budget.
bility of both the symbolic executor and the measurement
infrastructure used in the experiments. We have been devel-
oping and testing JBSE for several years. The implementa-
tion of the techniques HEX,ConsP,AlloyandPALEin JBSE
is new, but the consistent number of valid traces that JBSE
computes when these techniques are activated and deacti-
vated, supports the trustability of the current implementa-
tion. We have crosschecked the results from the diﬀerent
techniques and manually veriﬁed samples of the traces iden-
tiﬁed as spurious to increase our conﬁdence in the reliability
of the measurements.
We are aware that the result of few experiments cannot
be directly generalized. Nonetheless, the consistency of the
measured data across the subject programs is a promising
indication that our results may generalize. Our future plans
include extending the experiment to other data structures
and beyond the experimental samples of this paper.
6. RELATED WORK
In this section we brieﬂy survey the main approaches to
deal with the symbolic representation of dynamically allo-
cated structured data. The problem of limiting the assump-
tions on heap structures by considering their structural con-
straints has been considered in the context of both symbolic
execution and logic-based automated veriﬁcation of heap
manipulating programs.
In the context of symbolic execution, the problem has
been initially investigated by Visser et al., who proposed
the lazy initialization approach [18, 31] that has been fur-
ther extended by Deng et al. [8]. We discussed the com-
parison of HEX with Visser’s PrEPand Deng’s ConsPap-
proaches in Section 5. Boyapati et al., Galeotti et al. and
Majumdar et al. proposed approaches that enumerate the
valid data structures through a bounded search of the input
space [2, 12, 23]. Recently, Geldenhuys et al. instantiated
the approach of Galeotti et al. to pre-compute the sets of
possibly valid inter-object edges for the objects of the in-
put structures, and exploited this information within thelazy initialization algorithm to evaluate the validity of th e
incrementally assumed references [13]. Being based on a
bounded veriﬁer, the precision of this approach depends on
the choice of the bound value, with similar implications to
the ones that we discussed in Section 4.1 with reference to
Alloy. Furthermore, the set of pre-computed inter-object
edges over approximates the edges that are valid for any
path condition, and thus the approach of Geldenhuys et al.
cannot guarantee the precision ﬁgures observed with Hex
and Alloy in our experiments.
In the context of logic-based automatic veriﬁcation, sev-
eral authors proposed logics and decision procedures to ad-
dress heap manipulating programs that must maintain reach
invariants for the data structures in the heap [16, 25, 21, 27,
24, 32, 1, 22, 11]. Bounded checkers, like Alloy, compute the
satisﬁability of structural properties within bounded scopes
of objects in the solution, translating the decision problems
in boolean logic and using a SAT-solver to ﬁnd a satisfying
assignment for the boolean formula [16]. The need to accept
aboundedsolutionisthemainlimitofthisapproach. Logics
like PAL (the Pointer Assertion Logic) and STRAND (the
STRucture ANd Data logic) build on monadic second order
logic to prove unbounded properties of graphs of objects [25,
21]. STRANDcombinestheabilitytoreasonongraphstruc-
tures, with the ability to reason on the numeric data encap-
sulated in the objects. Other authors restrict their logics to
selected types of reachability properties to enable the imple-
mentation of the corresponding decision procedures within
SMT solvers [27, 24, 32]. Yet other researchers investigate
the use of separation logic , aiming to take advantage of the
local and compositional reasoning provided by the separa-
tion logic [28, 1, 22, 11]. These approaches have not been
exploited in the context of symbolic execution yet. In this
paper we have experimented with the techniques Alloyand
PALEas representatives of this class of approaches.
7. CONCLUSIONS
Symbolic execution is the core component of many ap-
proaches to automatically generate test cases and verify sys-
tem properties. While symbolic execution has been success-
fully exploited to generate test cases for complete programs
with numeric inputs, generating unit, integration and sub-
system test cases for programs that make extensive use of
heap data structures is still an open challenge. The main-
stream approach to deal with heap data structures, referred
to as lazy initialization, does not take into account satis-
factorily the structural constraints of data structures, and
results in a waste of eﬀort and in many false positives that
limit its eﬀectiveness.
In this paper we propose a new approach that prunes in-
put data structures that violate structural constraints incre-
mentally while symbolically executing the target program.
In this way symbolic execution focuses on valid data struc-
tures, avoidingwastingeﬀortandresourceswithinvaliddata
structures, and preventing many consequent false alarms.
The experimental results reported in the paper conﬁrm
that the HEX approach improves over lazy initialization and
over the most relevant state-of-the-art approaches.
We believe that the diﬀerent approaches can be further
strengthened by exploring their complementarities, and we
are currently working on combining the diﬀerent approaches
in light of the results obtained so far.
6118. REFERENCES
[1] A. Bouajjani, C. Drˇ agoi, C. Enea, and M. Sighireanu.
Accurate invariant checking for programs
manipulating lists and arrays with inﬁnite data. In
S. Chakraborty and M. Mukund, editors, Automated
Technology for Veriﬁcation and Analysis , LNCS, pages
167–182. Springer, 2012.
[2] C. Boyapati, S. Khurshid, and D. Marinov. Korat:
automated testing based on java predicates. In
International symposium on Software testing and
analysis. ACM, 2002.
[3] P. Braione, G. Denaro, and M. Pezz` e. Enhancing
symbolic execution with built-in term rewriting and
constrained lazy initialization. In Proc. of the 2013 9th
Joint Meeting on Foundations of Software
Engineering , ESEC/FSE 2013, pages 411–421, New
York, NY, USA, 2013. ACM.
[4] C. Cadar, D. Dunbar, and D. Engler. KLEE:
Unassisted and automatic generation of high-coverage
tests for complex systems programs. In USENIX
Symposium on Operating Systems Design and
Implementation , 2008.
[5] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill,
and D. R. Engler. EXE: automatically generating
inputs of death. In ACM Conference on Computer and
Communications Security . ACM, 2006.
[6] L. A. Clarke. A system to generate test data and
symbolically execute programs. IEEE Trans. on Soft.
Eng., 2(3):215–222, Sept. 1976.
[7] A. Coen-Porisini, G. Denaro, C. Ghezzi, and
M. Pezz` e. Using symbolic execution for verifying
safety-critical systems. In Proceedings of the Joint
European Software Engineering Conference and ACM
SIGSOFT Symposium on the Foundations of Software
Engineering , 2001.
[8] X. Deng, J. Lee, and Robby. Bogor/Kiasan: A
k-bounded symbolic execution for checking strong
heap properties of open systems. In International
Conference on Automated Software Engineering , 2006.
[9] G. D. Dennis. TSAFE: Building a trusted computing
base for air traﬃc control software. Master’s thesis,
Massachusetts Institute of Technology, 2003.
[10] H. Do, S. G. Elbaum, and G. Rothermel. Supporting
controlled experimentation with testing techniques:
An infrastructure and its potential impact. Empirical
Software Engineering: An International Journal ,
10(4):405–435, 2005.
[11] C. Enea, V. Saveluc, and M. Sighireanu.
Compositional invariant checking for overlaid and
nested linked lists. In Proceedings of the European
Conference on Programming Languages and Systems ,
ESOP’13, pages 129–148. Springer-Verlag, 2013.
[12] J. P. Galeotti, N. Rosner, C. G. L´ opez Pombo, and
M. F. Frias. Analysis of invariants for eﬃcient bounded
veriﬁcation. In Proceedings of the 19th International
Symposium on Software Testing and Analysis , ISSTA
’10, pages 25–36, New York, NY, USA, 2010. ACM.
[13] J. Geldenhuys, N. Aguirre, M. Frias, and W. Visser.
Bounded lazy initialization. In G. Brat, N. Rungta,
and A. Venet, editors, NASA Formal Methods , LNCS
7871. Springer Berlin Heidelberg, 2013.
[14] P. Godefroid, N. Klarlund, and K. Sen. DART:directed automated random testing. In ACM
Conference on Programming language design and
implementation . ACM, 2005.
[15] J. G. Henriksen, J. L. Jensen, M. E. Jørgensen,
N. Klarlund, R. Paige, T. Rauhe, and A. Sandholm.
Mona: Monadic second-order logic in practice. In
Proc. of the Int. Workshop on Tools and Algorithms
for Construction and Analysis of Systems , TACAS.
Springer-Verlag, 1995.
[16] D. Jackson. Software Abstractions: Logic, Language,
and Analysis . The MIT Press, 2006.
[17] R. Just, D. Jalali, and M. D. Ernst. Defects4J: A
database of existing faults to enable controlled testing
studies for Java programs. In Proceedings of the
International Symposium on Software Testing and
Analysis (ISSTA) , pages 437–440, 2014.
[18] S. Khurshid, C. S. Pˇ asˇ areanu, and W. Visser.
Generalized symbolic execution for model checking
and testing. In Tools and Algorithms for Construction
and Analysis of Systems , LNCS 2619. Springer, 2003.
[19] J. C. King. Symbolic execution and program testing.
Communications of the ACM , 19(7):385–394, 1976.
[20] B. Liskov and J. Guttag. Program Development in
Java: Abstraction, Speciﬁcation, and Object-Oriented
Design. Addison-Wesley Longman Publishing Co.,
Inc., Boston, MA, USA, 1st edition, 2000.
[21] P. Madhusudan and X. Qiu. Eﬃcient decision
procedures for heaps using strand. In Proc. of the 18th
International Conference on Static Analysis , SAS’11,
pages 43–59. Springer-Verlag, 2011.
[22] P. Madhusudan, X. Qiu, and A. Stefanescu. Recursive
proofs for inductive tree data-structures. In
Proceedings of the 39th Annual ACM
SIGPLAN-SIGACT Symposium on Principles of
Programming Languages , pages 123–136, New York,
NY, USA, 2012. ACM.
[23] R. Majumdar and R.-G. Xu. Directed test generation
using symbolic grammars. In Proc. of the Int.
Conference on Automated Software Engineering , ASE
’07, New York, NY, USA, 2007. ACM.
[24] S. McPeak and G. C. Necula. Data structure
speciﬁcations via local equality axioms. In Proc. of the
17th International Conference on Computer Aided
Veriﬁcation , CAV’05. Springer-Verlag, 2005.
[25] A. Møller and M. I. Schwartzbach. The pointer
assertion logic engine. In Proceedings of the ACM
SIGPLAN 2001 Conference on Programming
Language Design and Implementation , PLDI ’01,
pages 221–231, New York, NY, USA, 2001. ACM.
[26] C. S. Pasareanu and W. Visser. A survey of new
trends in symbolic execution for software testing and
analysis. International Journal on Software Tools for
Technology Transf. , 11(4):339–353, Oct. 2009.
[27] Z. Rakamari´ c, R. Bruttomesso, A. J. Hu, and
A. Cimatti. Verifying heap-manipulating programs in
an SMT framework. In Proc. of the 5th International
Conference on Automated Technology for Veriﬁcation
and Analysis , ATVA’07, pages 237–252.
Springer-Verlag, 2007.
[28] J. C. Reynolds. Separation logic: A logic for shared
mutable data structures. In Proceedings of the 17th
Annual IEEE Symposium on Logic in Computer
612Science, LICS ’02, pages 55–74, Washington, DC,
USA, 2002. IEEE Computer Society.
[29] K. Sen, D. Marinov, and G. Agha. CUTE: a concolic
unit testing engine for C. In European Software
Engineering Conference and ACM Symposium on
Foundations of Software Engineering , 2005.
[30] J. H. Siddiqui and S. Khurshid. Staged symbolic
execution. In ACM Symposium on Applied Computing ,
2012.
[31] W. Visser, C. S. Pˇ asˇ areanu, and S. Khurshid. Testinput generation with Java PathFinder. In Proceedings
of the 2004 ACM SIGSOFT International Symposium
on Software Testing and Analysis (ISSTA 2004) ,
pages 97–107. ACM, 2004.
[32] G. Yorsh, A. Rabinovich, M. Sagiv, A. Meyer, and
A. Bouajjani. A logic of reachable patterns in linked
data-structures. In Proc. of the 9th European Joint
Conference on Foundations of Software Science and
Computation Structures , FOSSACS’06.
Springer-Verlag, 2006.
613