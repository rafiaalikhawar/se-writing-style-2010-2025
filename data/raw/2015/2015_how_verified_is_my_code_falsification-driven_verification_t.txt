How V eriﬁed is My Code?
Falsiﬁcation-Driven V eriﬁcation
Alex Groce, Iftekhar Ahmed, Carlos Jensen
School of Electrical Engineering and Computer Science
Oregon State University, Corvallis, Oregon
Email: agroce@gmail.com, ahmedi@onid.oregonstate.edu, cjensen@eecs.orst.eduPaul E. McKenney
IBM Linux Technology Center
Email: paulmck@linux.vnet.ibm.com
Abstract —Formal veriﬁcation has advanced to the point that
developers can verify the correctness of small, critical modules.
Unfortunately, despite considerable efforts, determining if a
“veriﬁcation” veriﬁes what the author intends is still difﬁcult.
Previous approaches are difﬁcult to understand and often limited
in applicability. Developers need veriﬁcation coverage in terms of
the software they are verifying, not model checking diagnostics.
We propose a methodology to allow developers to determine
(and correct) what it is that they have veriﬁed, and tools to
support that methodology. Our basic approach is based on a novel
variation of mutation analysis and the idea of veriﬁcation driven
by falsiﬁcation. We use the CBMC model checker to show that
this approach is applicable not only to simple data structures
and sorting routines, and veriﬁcation of a routine in Mozilla’s
JavaScript engine, but to understanding an ongoing effort to
verify the Linux kernel Read-Copy-Update (RCU) mechanism.
I. I NTRODUCTION
Software model checking [1] has recently, thanks to im-
provements in model checking tools (and advanced SA T/SMT
solvers), become a potentially valuable tool for developers of
critical software modules who want to either perform a very
aggressive search for bugs or, ideally, prove correctness of
their code. Tools such as CBMC [2] (the C Bounded Model
Checker) allow a software engineer to model check code by
writing what is essentially a generalized test harness [3], [4]1
in the language of the Software Under Test (SUT). Figure 1
shows an example CBMC harness for sorting routines. Only
a few aspects differ from normal testing. First, nondet_int
in CBMC can return any value. It is not equivalent to a
“random” choice but true nondeterminism: CBMC will explore
all values of the type. The __CPROVER_assume statement
has the usual assume semantics [5], [6]: CBMC ignores all
executions that violate assumptions.
CBMC compiles a harness and the SUT (here a quicksort
implementation) into a goto-program, instruments this program
with property checks for assertions, array bounds violations,
etc., and then unrolls loops based on a user-provided un-
winding bound to produce a SA T problem or SMT constraint
such that satisfying assignments are representations of a trace
demonstrating a property violation, known as a counterexam-
ple [7]. For CBMC, this means that if any possible execution
allowed by the harness violates any properties checked, a
counterexample will be produced. This includes user-speciﬁed
1By a harness we mean a program that deﬁnes an environment and the form
of valid tests, and provides correctness properties.#include "sort.h"
int a[SIZE];
int ref[SIZE];
int nondet_int();
int main () {
int i, v, prev;
int s = nondet_int();
__CPROVER_assume((s > 0) && (s <=SIZE));
f o r( i=0 ;i<s ; i++){
v = nondet_int();
printf ("LOG: ref[%d] = %d\n", i, v);
ref[i] = v; a[i] = v;
}
sort(a, s);
prev = a[0];
f o r( i=0 ;i<s ; i++){
printf ("LOG: a[%d] = %d\n", i, a[i]);
assert (a[i] >= prev);
prev = a[i];
}
}
Fig. 1. CBMC harness to check a sorting routine.
assertions and automatically generated properties such as array
bounds and pointer validity checks. One generated property is
that no loop in the program executes more than the unwinding
bound times. For example, if we run CBMC on the harness
shown and set the unwinding bound to 3 and add -DSIZE=2 ,
we will check the correctness of the SUT over all possible
arrays of size 2 or less, including checking that sorting never
requires passing through any loop more than 3 times.
When a model checker produces a counterexample, a de-
veloper’s task is straightforward, if sometimes difﬁcult: either
the SUT has a fault, or the harness itself is ﬂawed. In both
cases, the output of the veriﬁcation effort is the counterexample
trace, which is full of evidence as to the reason for the failure
to verify the SUT. Moreover, any solution (ﬁx to SUT or
harness) is easily checked: if it is correct, the model checker
stops reporting the previous counterexample.
Unfortunately, model checkers do not invariably report
counterexamples: eventually the SUT is likely to satisfy the
properties encoded in the harness! It is in this case that
problems arise: what, precisely, has been veriﬁed? Is the SUT
actually correct? Formal veriﬁcation is not only subject to
the problems that make “no faults detected” results dubious
in testing [8], [9], but also to more subtle problems. For
example, an incorrect assume statement may constrain a
system so that not only are there no counterexamples, there
are no (interesting) executions of the system at all. Moreover,
formal veriﬁcation tools are themselves extremely complex
software artifacts, and, like production compilers [10], may
2015 30th IEEE/ACM International Conference on Automated Software Engineering
978-1-5090-0025-8/15 $31.00 © 2015 IEEE
DOI 10.1109/ASE.2015.40737
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. themselves have serious bugs that produce wrong results [11].
In the course of this research, we have ourselves encountered
several tool-induced incorrect veriﬁcations.
The problem of checking veriﬁcation results has concerned
the model checking community for some time, and resulted in
efforts to deﬁne coverage metrics for model checking [12],
[13]. While such metrics are interesting and useful, they
have typically been aimed at hardware veriﬁcation, and most
useful to experts in formal veriﬁcation. In this paper, we
adapt traditional mutation testing [14], [15] to the problem
of software veriﬁcation. A mutant of a program is a version
of the program with a small syntactic change. The idea behind
mutation testing is that a good test suite will be able to detect
when (as is usually the case) such a change introduces a bug
in the SUT. In the case of bounded model checking, since we
aim at (bounded) veriﬁcation rather than merely good testing,
surviving mutants are likely to indicate a real problem.
In software engineering research, mutation is often used
only as a way to compare competing test suites by comparing
kill rates [16], [17]. This is not enough for veriﬁcation. The
typically small scope of the code to be veriﬁed, and the
presumed importance of veriﬁed code suggests an approach
in which individual mutants are examined by the developer.
Without additional assistance, such an approach cannot scale.
This paper aims to describe how to make this seemingly too-
demanding approach practical for real veriﬁcation tasks.
The contribution of this paper is a falsiﬁcation-driven
veriﬁcation methodology that uses mutants to aid developers
in understanding “successful” veriﬁcation results, determining
when a harness is ﬂawed, and correcting the harness. We
show how to use mutation testing to choose a problem size in
bounded model checking, how to mutate a harness to determine
if any similar harnesses have an equal (or better) mutation kill
rate, and most importantly, how to modify CBMC, a harness,
and mutants to automatically produce successful high-coverage
executions covering mutated code in order to understand
mutant (and thus harness) behavior. This approach, unlike a
simpler method of searching for cases where the mutated and
original code behave differently for identical inputs, applies to
veriﬁcation of reactive and concurrent systems, where there
is no simple notion of identical inputs. At a more general
level, we discuss the fundamental nature of “veriﬁcation” in
a real-world context where speciﬁcations are never known to
be complete. We propose that falsiﬁcation, as in Popper’s phi-
losophy of science [18], is a useful conceptual framework for
veriﬁcation efforts: rather than focusing on what can be proven
about a program, we focus on how a veriﬁcation distinguishes
the “real” program from similar alternative programs that do
not match the theory of program behavior. This approach still
aims at veriﬁcation, but continually evaluates and reﬁnes a
veriﬁcation effort by its ability to falsify rather than to verify.
II. A S IMPLE EXAMPLE VERIFICA TION
As an example of the proposed veriﬁcation methodology,
consider again the harness shown in Figure 1. If we take an
early Google result for “quicksort in C” [19], shown in Figure
22, we can model check it using the harness, deﬁning SIZE=2
2In fact, that actual code is incorrect, with an access a[i] that does not
properly use short circuiting logical operators to protect array bounds; CBMC
detected this, and we ﬁxed it for this paper.#include "sort.h"
void quickSort( int a[], int l, int r)
{
printf ("LOG: called with l=%d, r=%d\n", l, r);
int j;
9i f (l<r)
{
// divide and conquer
j = partition( a, l, r);
quickSort( a, l, j-1);
quickSort( a, j+1, r);
}
}
int partition( int a[], int l, int r) {
int pivot, i, j, t;
pivot = a[l];
i = l; j = r+1;
26while( 1)
{
28 do ++i; while( i <= r && a[i] <= pivot );
do --j; while( a[j] > pivot );
30 if( i >= j ) break;
31 t = a[i]; a[i] = a[j]; a[j] = t;
}
t = a[l]; a[l] = a[j]; a[j] = t;
return j;
}
void sort(int a[], unsigned int size) {
quickSort(a, 0, size-1);
}
Fig. 2. Quicksort code.
and setting the unwinding bound to 3 (we need one more
unwinding than the maximum number of items in the array).
CBMC reports VERIFICATION SUCCESSFUL in less than
a second. Have we veriﬁed what we want to verify?
A. Finding a Good Problem Size
The ﬁrst question we face is whether 2 is a good max-
imum array size to examine. The problem of determining a
completeness threshold (an execution-length bound sufﬁcient
to prove correctness in all cases for a given property) for
bounded model checking is fundamentally difﬁcult [20] and
is, for real-world C programs, more an art than a science at
present3. Are there bugs for which 2 is too small an array
size? In order to ﬁnd out, we generate a set of mutants for
quicksort.c . Using the mutation tool for C code developed
by Jamie Andrews [21], we can produce 81 mutants of this
code in less than a second. We then run the harness with
unwinding bound 2 (and SIZE=1 ) on each of the 81 mutants.
The process takes less than a minute and a half (on a MacBook
Pro with 16GB RAM and dual-core 3.1GHz Intel Core i7,
using only one core). CBMC reports that 6 mutants do not
compile (these remove variable declarations, for the most part),
4 are detected by the harness (a counterexample is produced:
we say the mutant is killed), and 71 mutants pass without
detection (the veriﬁcation is successful, in which case we say
the mutant survives). Clearly length 1 arrays are not sufﬁcient
to detect even the most glaring bugs in a sort algorithm (no
surprise: all size 1 arrays are sorted). What about our choice
of size 2? Re-checking the mutants with this bound (dropping
those already killed by the smaller bound) takes slightly over
13 minutes (due to one mutant requiring over 8 minutes to
model check) and reduces the number of surviving mutants
to 26. We could inspect these mutants by hand, but it seems
3In our own practice, the most common way of setting it is to guess a bound
and see if the resulting problem is too large for the available resources.
738
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. 9: / *(rep_op) */i f( l< =r )
26 : / *(rep_const) */ while(-1)
26 : / *(rep_const) */ while( ((1)+1))
28 : / *(rep_op) */ do ++i; while(i<r && a[i]<=pivot);
28 : / *(rep_op) */ do ++i; while(i!=r && a[i]<=pivot);
28 : / *(rep_op) */ do ++i; while(i<=r && a[i]<pivot);
30 : / *(rep_op) */i f (i>j) break;
31 : / *(del_stmt) */ t=a[i]; / *a[i]=a[j]; */ a[j]=t;
Fig. 3. Surviving mutants at SIZE=3 .
highly unlikely that a complete veriﬁcation over all possible
arrays with a good speciﬁcation for sorting would produce
such a poor mutation kill rate. If we increase the size limit
to 3 and unwinding 4 (now the analysis takes just over 33
minutes), only 8 mutants survive. Note that each problem, due
to the harness’ assignment of sto any size smaller than the
current size, includes all smaller problem sizes. This makes the
behavior of the veriﬁcation problem size setting match that of
CBMC where an unwinding bound is a maximum, rather than
a ﬁxed size. We assume inclusiveness in this paper4.
At this point, we can increase SIZE to 4 (which will
kill one additional mutant), but the time required to check
the remaining mutants is growing rapidly. In fact, completing
the check for size 4, even though only the original program
and 8 mutants have to be checked, requires nearly 9 hours.
When the model checking difﬁculty grows more slowly with
problem size, we propose the simple (if highly imprecise)
heuristic of increasing size until the number of mutants killed
does not increase with a step up in size (we call such a size
mutant-stable ). However, in many cases, such as this one, the
time required to check mutants starts growing unacceptably.
We propose a more efﬁcient algorithm for ﬁnding a mutant-
stable size below (Figure 7), and mutations can be checked in
parallel, but the fundamental problem for size 4 (and above)
is that some individual mutants require hours to model check.
What is a developer to do?
B. Examining Surviving Mutants
The developer should turn to the surviving mutants. The
8 surviving mutants for size 3 are shown in Figure 3. The
comment indicates the type of mutant, and the line number
in the quicksort ﬁle is also given for reference. The relevant
lines are marked in Figure 2. Some of these mutants are easily
seen to be equivalent to the original code. For example, the
tworep_const mutations simply change a while(1) into
an equivalent inﬁnite loop with a different constant non-zero
value. These two mutants could in fact have been automatically
removed from the set, like uncompilable mutants, by checking
their compiled code for equivalence with the original program
[22]. We suggest always pruning mutants via Trivial Compiler
Equivalence (TCE). The remaining 6 mutants produce differ-
ent binaries when compiled with an optimizing compiler, so
require manual analysis. The 5 rep_op mutations all alter
comparison operators by changing their value on one corner
case, and we may suspect that quicksort is robust to, for
example, changing i< =r toi! =r since iis initially
set to l, which we know to be less than r.
Thedel_stmt mutant, however, is clearly problematic.
How can quicksort be correct if the inner loop’s swapping of
4There is one noted exception in Section IV -D.LOG: ref[0] = 2147414872
LOG: ref[1] = 2147480408
LOG: ref[2] = -1073743560
LOG: called with l=0, r=2
LOG: called with l=0, r=-1
LOG: called with l=1, r=2
LOG: called with l=1, r=1
LOG: called with l=3, r=2
LOG: a[0] = 2147414872
LOG: a[1] = 2147480408
LOG: a[2] = 2147480408
Fig. 4. Witness to the harness’ inability to kill the del_stmt mutant.
...
int i, v, count, qcount, prev;
...
sort(a, s);
// Pick a value to check
v = nondet_int();
count = 0;
qcount = 0;
...
f o r( i=0 ;i<s ; i++){
...
if (ref[i] == v)
count++;
if (a[i] == v)
qcount++;
...
assert (count == qcount);
}
Fig. 5. Modifying the harness to ensure ais a permutation of ref .
a[i] anda[j] is changed to instead copy a[i] toa[j] ?
The consequences of this mutant are clearly drastic, but why
are they not detected by our harness? We ﬁnd out by asking
CBMC to produce an execution such that 1) the mutated code
is covered 2) other coverage is maximized (to avoid degenerate
executions, e.g., over size 1 arrays) and 3) the execution is
not a counterexample. We have modiﬁed CBMC, and written
instrumentation tools that produce a modiﬁed mutant and
harness, allowing us to pose such queries (see Section III).
Running CBMC in this mode, with the target of maximum
branch coverage and statement coverage of the del_stmt
mutant (actually the statement after it, since it no longer exists),
we produce the witness in Figure 4 in less than a minute5. Our
harness checks that the array ais sorted after the call to sort ,
but it does not check that it is a permutation of the input!
We might have discovered this problem by a different
method: if we remove the call to sort in the harness, and
replace it by a loop assigning nondet_int to every element
in array a(a kind of most-general any-order type-correct
“mutant” of sort ), we can run the modiﬁed CBMC and
see examples of executions our harness allows, which should
include any sorted array. The problem with this method is
that, while it sometimes works, CBMC is also free to set
all elements in all arrays to 0, and to generally provide
an uninformative example of a successful execution. The
requirement to cover a mutant (and as much other code as
possible) helps guide CBMC to a successful execution that is
likely to be incorrect, because a non-equivalent mutant changes
the original program’s behavior. Moreover, while the problem
with the harness in this case is simple, understanding arbitrary
“passing” but wrong executions can be very difﬁcult without
the ability to think about a speciﬁc bug the model checker
5We show the output of the print statements, not the full CBMC trace: this
is what a developer will examine ﬁrst.
739
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. is missing. Moreover, basing the production of witnesses on
mutants allows us to compare harnesses even over killed
mutants: if one harness reduces the set of passing executions
for a mutant, it is arguably a better veriﬁcation of correctness
than one allowing more executions of the mutant, even if
both produce a counterexample killing the mutant. Unlike
traditional mutation analysis, we can take the question “how
killed is this mutant?” seriously because we aim at exhaustive
testing. A harness is most effective with respect to a mutant if
it allows no executions covering the mutant to pass.
The witness tells us that the sorting harness is too weak. We
say that a harness is weak if it fails to detect incorrect execu-
tions. One harness is stronger than another if it detects more
failures; we can indirectly estimate strength by determining
how many mutants a harness can kill at a given problem size,
and how executions covering killed mutants can still satisfy the
harness. Figure 5 shows how to modify the sorting harness
to check for permutations6. Because CBMC is exhaustive,
instead of performing a complete check for permutation, we
can detect violation of the property by letting vbe any value,
and ensuring that both aandref contain the same number
of elements equal to v.I fais not a permutation of ref ,
there exists a vsuch that this is not true, and we can rely
on CBMC to report it as part of a counterexample. While a
CBMC harness resembles a program to test the SUT, it can
make use of unusual speciﬁcations relying on exhaustiveness.
If we modify the harness as shown, we can re-check our
mutants (including those TCE would remove). With the revised
harness, checking mutants at SIZE=1 takes slightly longer (8
more seconds) and kills the same number of mutants, since
the problem is the size, not the harness. At SIZE=2 mutant
kill results are again unchanged, but analysis now completes in
about 5 minutes. Finally, at SIZE=3 , we kill the del_stmt
mutant that previously survived, after only 14 minutes, not
much longer than at SIZE 2 with the weaker harness. The
SIZE 3 veriﬁcation is stable. Checking stability by running
SIZE 4 now only requires slightly more than an hour, nearly
an order of magnitude faster than before.
As brieﬂy mentioned in the introduction, it is also possible
to understand a mutant by modifying the harness to call both
the mutated code and the original code on the same inputs,
and search for witnesses where 1) the execution is passing
but 2) the return value(s) for the mutant differ(s) from the
original. However, this increases the complexity of the model
checking problem (checking equivalence of two functions is
often harder than specifying valid executions) and does not
easily apply to any veriﬁcations other than simple function
calls. For example, forcing the same interleavings in threaded
programs, or detecting all differences in state-modiﬁcation for
reactive code is often infeasible or requires signiﬁcant human
intervention. While we do apply differential checks in some
cases below, we do not propose this as a core technique suitable
for general-purpose falsiﬁcation-driven veriﬁcation.
C. Mutating the Harness
Previous efforts to understand model checking results have
also considered mutants to the property, usually given as a
6In fact, if we choose a val to check before we assign to ref , we could
completely dispense with storing ref at all.temporal logic formula [23]. Once a developer is satisﬁed with
a harness, has a mutant-stable bound for veriﬁcation, and is
convinced all surviving mutants are semantically equivalent to
the original program (or, if not equivalent, also satisfy the same
correct speciﬁcation), we propose the developer mutate the test
harness itself. The idea is to check that 1) most mutants of the
harness reject the SUT and 2) the remaining mutants have a
mutant kill rate no greater than that of the harness. For the
ﬁxed sort harness, there are 61 mutants, of which 2 do not
compile. Of these, 40 produce an incorrect counterexample
for the original, correct, quicksort. An additional 10 have
mutant kill rates worse than the original harness (from as
low as 5% of mutants killed to only a few percent worse
than the ﬁxed harness). The remaining 9 harness mutants
have the same ability to kill mutants as the original harness.
Most of these involve modifying a relational operator in a
loop or an assumption in a way that preserves semantics.
The only interesting surviving harness mutant is one that
removes the assignment of a fresh non-deterministic value to v
after the call to sort . This means the check for permutation
difference will always be performed on the last element of
ref . On reﬂection, it seems plausible that this is sufﬁcient to
produce a counterexample for all the quicksort mutants, but it
is clearly not an improvement to the harness, in terms of either
veriﬁcation strength or clarity.
In addition to showing the current harness is at least a
“local minima” with respect to mutants, mutation analysis of
the harness also provides some evidence of our technique’s
ability to detect subtle speciﬁcation and environment ﬂaws.
In particular, it shows the value of inspecting all surviving
mutants. One mutant modiﬁes the assumption on sto be s<
SIZE rather than s <= SIZE , which is the same as lowering
theSIZE by one; this is a fairly easy mistake to make in a
harness (or any code). This reduces the effectiveness of the
veriﬁcation by 19 mutants, so is likely not to escape notice,
and would also (in our framework) simply result in a higher
size being chosen as mutant-stable. Deleting the assignment
prev = a[i] , however, only kills 4 fewer mutants than
the original harness. Traditional coverage and some model
checking coverages cannot detect this problem: because of the
assignment to prev outside the loop, the variable isused in
the speciﬁcation, and in fact used to detect many faults (it
eliminates any mutants that can cause a[0] to not be the
least element). The harness “covers” all behavior of quicksort
in general, since the permutation requirement remains in place.
However, it cannot detect versions of quicksort that 1) preserve
permutation and 2) make the ﬁrst element correct, but 3)
don’t always sort the array correctly. In particular, the call to
quickSort withj+1 can be removed or modiﬁed to j
+2 . Examining the deleted/removed recursive calls shows the
developer the problem in this case. Our modiﬁed CBMC easily
produces a witness showing a permuted array with correct
a[0] but with out-of-order later elements.
III. A LGORITHMS AND TECHNIQUES
Falsiﬁcation-driven veriﬁcation is a semi-automated ap-
proach that relies heavily on algorithmic and tool support.
While the typically smaller scope of code targeted for veriﬁ-
cation (vs. testing) makes the work easier, it is not likely to be
feasible without automation of many subtasks. Existing tools
make producing a set of mutants and checking them using a
740
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. harness relatively easy, but other tasks require new algorithms
and tools. Figure 6 shows the basic ﬂow, which is directed
not by a ﬁxed algorithm but by the intelligence (guided by
experience) [24] of the developer. Novel tools or techniques
are on the right side of the diagram (mutation analysis itself
is not novel, but our tool for integrating this with the model
checker and recording results for use by other parts of the tool-
chain is non-standard), other than the model checker itself.
Figures 7-9 show core algorithms (implemented as proto-
type tools in our framework). In these algorithms O(S)is a
function mapping an abstract size into particular options, e.g.
-DSIZE . The uses of these algorithms are described at a high
level in the introductory example, and in the case studies be-
low. One additional requirement is a version of CBMC capable
of converting built-in assertions checks (e.g, bounds checks,
pointer dereference, division by zero) to assumptions. For har-
ness assumptions, this is done by automatic source-to-source
transformation (Figure 8, procedure cover-harness ), but
CBMC’s internal constraints have to be handled inside the
model checker. We implemented a new CBMC command-line
option, --find-success that provides this functionality.
In all algorithms, check means running CBMC as usual,
with any needed automatic property checks, while scheck
indicates running CBMC with find-success enabled. In
Figure 6 we assume the use of a modiﬁed version of CBMC.
Thefind-size algorithm (Figure 7) ﬁnds a suitable
problem size and returns the set of surviving mutants for
a harness and program, performing as few model checker
calls as possible (once we know a bound is not stable, we
move on to the next bound). This algorithm can be easily
parallelized by running mutants in the for loop at the same
time, with any goto TOP killing all CBMC runs not ter-
minated. The maxcover algorithm (Figure 8) returns for a
given mutant and harness, a witness program trace that 1)
covers the mutant and 2) covers as much other code as possible
(in terms of branch coverage), using the cover-harness
andcover-mutant procedures to instrument harness and
mutant; it proceeds by starting with a minimal constraint on
coverage (the trace must cover the mutated code) and increases
this bound by incrementing it to one more than the actual
coverage of the last witness found, until the model checker
can prove the coverage is impossible. Other strategies for
maximal coverage are possible (trying maximal coverage ﬁrst,
and decreasing the required coverage as attempts fail) but this
approach minimizes the number of model checker runs that
will fail to produce a witness, which is critical for performance
reasons (see Section IV -D). The check-harness algorithm
(Figure 9) analyzes harness mutants, producing a report of 1)
harness mutants that are killed (either they do not verify the
SUT or they have worse kill rates than the original harness),
that are equal to the original harness in strength, and that are
stronger than the original harness. It also returns information
on all mutants killed by any harness mutant (except those that
reject the SUT) that are not killed by the original harness.
The algorithm killed , not shown, simply returns the set of
mutants killed by a given harness. In our implementations,
these tools perform additional record-keeping. For example,
harness analysis records killing counterexamples and execu-
tion times for each run. We also make use of convenience
scripts such as a tool to automatically call maxcover on
all mutants, which provides a measure of harness strength/g5/g23/g13/g14/g20/g1
/g12/g17/g14/g12/g19/g14/g25/g1
/g4/g10/g25/g22/g14/g26/g26/g1
/g3/g14/g31/g14/g20/g23/g24/g14/g25/g36/g31/g14/g25/g18/g15/g12/g10/g28/g23/g22/g1
/g14/g22/g16/g18/g22/g14/g14/g25/g1
/g6/g8/g7/g1/g5/g30/g27/g10/g28/g23/g22/g1
/g27/g23/g23/g20/g1
/g2/g23/g30/g22/g27/g14/g25/g14/g33/g10/g21/g24/g20/g14/g26/g1
/g10/g22/g13/g1/g31/g14/g25/g18/g15/g12/g10/g28/g23/g22/g26/g1
/g5/g20/g18/g7/g15/g10/g16/g1/g21/g13/g29/g10/g20/g1
/g32/g11/g17/g9/g31/g21/g13/g29/g10/g33/g1/g3/g6/g20/g17/g10/g21/g21/g1
/g6/g17/g6/g15/g28/g21/g13/g21/g1
/g32/g8/g12/g10/g8/g14/g31/g12/g6/g20/g17/g10/g21/g21/g33/g1
/g4/g25/g22/g6/g17/g22/g1
/g10/g27/g19/g15/g6/g17/g6/g23/g18/g17/g1
/g32/g16/g6/g27/g8/g18/g26/g10/g20/g33/g1
/g2/g6/g21/g13/g8/g1/g16/g25/g22/g6/g23/g18/g17/g1
/g6/g17/g6/g15/g28/g21/g13/g21/g1
/g3/g6/g20/g17/g10/g21/g21/g1
/g6/g17/g6/g15/g28/g21/g13/g21/g1
/g32/g8/g12/g10/g8/g14/g31/g12/g6/g20/g17/g10/g21/g21 /g33
/g4/g25/g22/g6/g17/g22
/g10/g27/g19/g15/g6/g17/g6/g23/g18/g17
/g32
/g16/g6/g27/g8/g18/g26/g10/g20
/g33/g1
/g6/g8/g7/g1
/g5/g30/g27/g10/g28/g23/g22
/g27/g23/g23/g20
/g4/g10/g25/g22/g14/g26/g26
/g22
/g6/g30/g25/g31/g18/g31/g18/g22/g16/g1
/g17/g10/g25/g22/g14/g26/g26/g14/g26/g1/g39/g1
/g19/g18/g20/g20/g1/g25/g10/g27/g14/g26/g1
/g9/g18/g27/g22/g14/g26/g26/g1/g1/g27/g25/g10/g12/g14/g1
/g37/g17/g23/g32/g1/g21/g30/g27/g10/g22/g27/g1/g12/g10/g22/g1
/g24/g10/g26/g26/g1/g17/g10/g25/g22/g14/g26/g26/g38/g1
/g6/g27/g10/g11/g20/g14/g1/g26/g18/g34/g14/g1/g39/g1
/g26/g30/g25/g31/g18/g31/g18/g22/g16/g1/g21/g30/g27/g10/g22/g27/g26/g1
/g6/g30/g25/g31/g18/g31/g18/g22/g16/g1/g21/g30/g27/g10/g22/g27/g26/g1
Fig. 6. Basic ﬂow of falsiﬁcation-driven veriﬁcation.
(int, survivors) find-size (H,M,S0: int,
O: int→options,
U: int→int)
S= S0-1
r’ ={}: mutant →result
TOP:
S=S+1
r=r ’
r’ ={}
for m∈M:
ifm/negationslash∈domain (r):
r[m] = check( H,m,U(S),O(S))
if r[m] == VERIFICATION FAILED:
//once killed, assume always killed
M=M\m
if r[m] == VERIFICATION SUCCESSFUL:
r’[m] = check( H,m,U(S+1 ),O(S+1 ))
if r’[m] == VERIFICATION FAILED:
M=M\m
goto TOP
// No result changed, so S is mutant-stable
return (S-1, M)
Fig. 7. Algorithm 1: Finding size/unwinding bound and surviving mutants.
that is more ﬁne-grained than a simple kill rate: harnesses
can be compared by the maximum coverage of all mutants,
even if they have the same kill rate. If one harness produces
executions with lower coverage (or no executions at all) for
some killed mutants, it is stronger. For some mutants, any
passing executions show a harness ﬂaw. While not polished
enough for release, these tools (implemented as Python scripts)
have proven robust in our experiments and are available, along
with our experimental data and CBMC patch, at https:
//github.com/agroce/cbmcmutate .
IV . C ASE STUDIES AND EXPERIMENT AL RESUL TS
A. Algorithm Implementations
Our initial experiments involved relatively small veriﬁca-
tion problems, based on implementations taken from the web
or student code for popular algorithms and data structures.
Here we highlight the most interesting of these; we also
successfully applied the method to bubble sort, a duplicate-
removing array merge function, an A VL tree, and a student’s
harness for verifying a version of Dijkstra’s shortest path
741
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. harness cover-harness (H,TA R G ET )
H/prime=H
for stmt ∈H/prime:
if stmt == assert(P):
stmt = assume(P);
cover = [
assume(total_coverage >= TA R G ET );
assert(!mutant_covered);]
insert cover at end of H/prime.main()
return H/prime
mutant cover-mutant (m)
n=0
m/prime=m
for if_stmt c in m/prime:
if c has no else:
add [else {}]t oc
for basic_block b in m/prime:
b = [if !covered[n] {
covered[n] = 1;
total_covered += 1;
}
b]
n=n+1
for stmt s in m/prime:
if MUTANT(s):
s=[{mutant_covered = 1;
s}]
m/prime= [int total_covered = 0;
int mutant_covered = 0;
int covered[n];
m/prime]
return m/prime
trace maxcover (m,H,S,O,U)
m/prime= cover-mutant( m)
T=0
trace = ∅
failed = False
while (not failed)
H/prime= cover-harness( H,T )
r = scheck( H,m/prime,U(S),O(S))
if r == VERIFICATION SUCCESSFUL:
failed = True
else if r == VERIFICATION FAILED:
trace = r.trace
T = trace.read(total_covered) + 1
return trace
Fig. 8. Algorithm 2: Find a maximally covering execution trace that covers
a mutant.
report check-harness (SUT ,M,H,M(H),S,O,U)
KH= killed( M,H,S)
Hkills = ∅; Hequal = ∅; Hbetter = ∅;N=∅
for H iinM(H):
original = check( Hi,SUT ,U(S),O(S))
if original == VERIFICATION FAILED:
Hkills += H i
else: // check if this kills fewer mutants
KHi= killed( M,H,S)
for k∈KHi:
if k/negationslash∈KH:N+ =( Hi,k )
if |K Hi|>| K H|:
Hbetter += (H i,K Hi)
if |K Hi|= =| K H|:
Hequal += (H i,K Hi)
else:
Hkills += (H i,K Hi)
return (Hkills, Hequal, Hbetter, N)
Fig. 9. Algorithm 3: Analyze a harness.algorithm that enables path reconstruction [25]. In the case of
the A VL tree, the harness we were working with was unable to
reach a mutant-stable unwinding without exhausting memory
on the veriﬁcation of the main program (for A VL trees of
up to size 5). We are investigating a more efﬁcient harness
encoding, based on the inability to reach mutant-stability. For
the Dijkstra harness, the low mutant kill rate of only 58%
showed that while the harness checks incorrect returned paths,
it cannot detect when return values indicate there is no path
but one exists. Improving the harness is a substantial exercise,
but can be guided by the survival witnesses.
1) Binary Search: The ideas in this paper grew out of a side
project of the ﬁrst author: to write a follow-up to Jon Bentley’s
article on verifying binary search [26] in the context of modern
software veriﬁcation tools (and Joshua Bloch’s discovery of
a bug in the assumptions behind Bentley’s proof [27]). The
modeling required is moderately complex (to scale well, an
abstract “sorted array” that represents all sorted arrays but only
introduces variables equal to the number of probes made by the
search is essential). In this case, we did not produce an initial,
weaker version of the harness, but checked the existing harness
using mutants, and determined that all 3 surviving mutants are
equivalent to a true binary search.
Checking harness mutants (which took 37 minutes, includ-
ing computing the kills for the original harness) produced
results conﬁrming the belief this is a good harness. Of the
31 compiling harness mutants, 19 failed to verify the correct
binary search, and 7 had worse kill rates than the original
harness. The remaining 5 harnesses, all with equal kill rates
of 86.7%, all modify an assumption to allow the harness
to also check size 0 arrays. This doesn’t kill any additional
mutants, but is harmless as expected. Of the harness mutants
with worse kill rates, three are mutants of the assumptions on
the nondeterministic value used to make sure that if binary
search returns -1, no index in the array actually contains the
searched-for item. Two of these mutants are off-by-one-errors
that exclude item 0 from the check, an easy-to-make mistake.
Both of these fail to kill exactly one mutant killed by the
correct harness: the mutant that sets the lower bound initially
to 1 instead of 0. Traces of passing runs for these mutants
show the problem clearly (the sought item at index 0).
2) Doubly-linked-list Insertion Sort: Another example,
making use of recursive data structures and pointer validity
checks, is code for inserting an item (in sorted order) into a
doubly-linked list [28]. Our initial harness omitted a check
for correctness of prev pointers. This problem didn’t directly
prevent mutants from being detected, but pushed the stable
size larger, as with the quicksort example above. Looking at
a trace of a size 3 run that fails to kill a clearly problematic
mutant easily reveals the problem (the results are correct up
toprev pointers). This example also showed another use
of mutants, in that some seemingly problematic surviving
mutants actually just showed a pointless redundancy in the
implementation, enabling the removal of an entire conditional
branch. A harness check (requiring 30 minutes, including
computing the mutant kills for the original harness) showed
that of the 105 compiling harness mutants, 92 fail to verify
the original code. Another 2 have a worse kill rate than the
original (which kills 81% of mutants, a low rate due to the code
redundancy), and 11 survive. The large number of survivors
742
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. jsint
js_BoyerMooreHorspool(const jschar *text, jsint textlen,
const jschar *pat, jsint patlen,
jsint start)
{
jsint i, j, k, m;
uint8 skip[BMH_CHARSET_SIZE];
jschar c;
JS_ASSERT(0 < patlen && patlen <= BMH_PATLEN_MAX);
for (i = 0; i < BMH_CHARSET_SIZE; i++)
skip[i] = (uint8)patlen;
m = patlen - 1;
f o r( i=0 ;i<m ; i++){
c = pat[i];
if (c >= BMH_CHARSET_SIZE)
return BMH_BAD_PATTERN;
skip[c] = (uint8)(m - i);
}
for (k = start + m;
k < textlen;
k += ((c = text[k]) >= BMH_CHARSET_SIZE) ?
patlen : skip[c]) {
f o r( i=k ,j=m ;; i--, j--) {
if (j < 0)
retur ni+1 ;
if (text[i] != pat[j])
break;
}
}
return -1;
}
Fig. 10. SpiderMonkey 1.6 Boyer-Moore-Horspool code.
is due to a redundancy of the ﬁnal harness, which checks
sortedness and the permutation property for both a forward
next traversal of the list and a prev traversal. Omitting any
one of these (e.g. prev sortedness or next permutation) the
harness can still detect all mutants. Removing two, however,
fails to kill mutants. The two harness mutants with worse kill
rates have extremely poor kill rates ( <50% and <25%).
B. SpiderMonkey Boyer-Moore-Horspool Implementation
Figures 10 and 11 show, respectively, the source code
and an initial harness for veriﬁcation of the Boyer-Moore-
Horspool substring ﬁnding algorithm [29], [30] in version
1.6 of Mozilla’s SpiderMonkey JavaScript engine. V erifying
this code presents one immediate issue that is not unusual
in veriﬁcation: how to handle an assert in the code being
veriﬁed. An assert at the end of a function or in the main
body is typically an additional part of the speciﬁcation, and
is often best left unchanged. An assert at the beginning of
a function’s body, however, is typically a precondition for the
code [30]. It is natural to consider changing such an assertion
into an assume and ignoring any problems produced by
calling the code with non-conforming inputs. While this can
be a useful technique (for instance when it is hard to write a
harness that only produces valid inputs, but easy to ﬁlter out
the invalid inputs and only verify behavior for those) it is also a
dangerous technique. Mutation analysis of the harness shows
that 4 is a mutant-stable size (where the same size is used
for text length, pattern length, and character set size), with a
kill rate of 72.3%. On initial examination, the 20 surviving
mutants do not seem problematic. A large number involve the
JS_ASSERT converted to a __CPROVER_assume , showing
the harness cannot tell if the assumption is incorrect, which
is not surprising (the harness only generates good inputs, and
some of the mutants simply discard too many inputs).
At this point, we were satisﬁed with our harness, and ran#include "bmh.h"
int main() {
int i;
unsigned int v;
char itext[TSIZE];
char ipat[PSIZE];
unsigned int itext_s = nondet_uint();
__CPROVER_assume(itext_s < TSIZE);
unsigned int ipat_s = nondet_uint();
__CPROVER_assume(ipat_s < PSIZE);
printf ("LOG: size text=%u, pat=%u\n", itext_s, ipat_s);
for (i = 0; i < itext_s; i++) {
v = nondet_unit();
__CPROVER_assume((long)v < (long)BMH_CHARSET_SIZE);
itext[i] = v;
__CPROVER_assume(itext[i] < BMH_CHARSET_SIZE);
printf ("LOG: text[%d] = %u\n", i, itext[i]);
}
for (i = 0; i < ipat_s; i++) {
v = nondet_uint();
__CPROVER_assume((long)v < (long)BMH_CHARSET_SIZE);
ipat[i] = v;
__CPROVER_assume(ipat[i] < BMH_CHARSET_SIZE);
printf ("LOG: pat[%d] = %u\n", i, ipat[i]);
}
jsint r = js_BoyerMooreHorspool(itext, itext_s,
ipat, ipat_s, 0);
printf ("LOG: return = %d\n", r);
int pos, ppos, found;
v = nondet_uint();
printf ("LOG: looking at %u\n", v);
__CPROVER_assume(v >= 0);
if (r == -1) {
__CPROVER_assume(v < itext_s);
pos = v; ppos = 0; found = 1;
while (ppos < ipat_s) {
printf ("LOG: itext[%d] = %u, ipat[%d] = %u\n",
pos, itext[pos], ppos, ipat[ppos]);
if ((pos>=itext_s)||(itext[pos]!=ipat[ppos])) {
found = 0; break;
}
pos++; ppos++;
}
assert (!found);
}else{
p o s=r ;p p o s=0 ;
while (ppos < ipat_s) {
assert (itext[pos] == ipat[ppos]);
pos++; ppos++;
}
v = nondet_uint();
printf ("LOG: looking at %u\n", v);
__CPROVER_assume(v < r);
pos = v; ppos = 0; found = 1;
while (ppos < ipat_s) {
printf ("LOG: itext[%d] = %u, ipat[%d] = %u\n",
pos, itext[pos], ppos, ipat[ppos]);
if ((pos>=itext_s)||(itext[pos]!=ipat[ppos])) {
found = 0; break;
}
pos++; ppos++;
}
assert (!found);
}
}
Fig. 11. Boyer-Moore-Horspool harness.
a check on mutants of the harness itself. To our surprise, three
mutants of the harness had a better kill rate than the “correct”
harness, killing 73.5% of mutants. Investigating these “better”
harnesses showed mutants that broke processing of some return
values in such a way that, while these harnesses failed to
detect certain major bugs in the code, they were able to detect
some JS_ASSERT assumption mutants. Guided by this, we
produced a revised harness that raised the kill rate to 79.52%.
However, on examining the surviving mutants, we realized that
our veriﬁcation was still unsatisfactory as a good regression for
the Boyer-Moore-Horspool code: in particular, if the assertion
743
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. 1 static int rcu_read_nesting_global;
2
3 static void rcu_read_lock(void)
4{
5 (void)__sync_fetch_and_add(&rcu_read_nesting_global, 2);
6}
7
8 static void rcu_read_unlock(void)
9{
10 (void)__sync_fetch_and_add(&rcu_read_nesting_global, -2);
11 }
12
13 static void synchronize_rcu(void)
14 {
15 for (;;) {
16 if (__sync_fetch_and_xor(&rcu_read_nesting_global, 1)<2)
17 return;
18 SET_NOASSERT();
19 return;
20 }
21 }
Fig. 12. Approximate model of RCU
were ever modiﬁed to allow bad inputs to pass through, or
otherwise incorrectly changed, we would those bugs. We then
changed the JS_ASSERT into code that returned a special
value to signal assertion failure, and modiﬁed the harness
once more, allowing some incorrect values to pass through
and checking that “assertion failure” happened if, and only if,
the inputs were invalid. This harness killed 89.2% of mutants,
and the six surviving mutants were easily understood to be
equivalent to the BMH code under all valid inputs (in one
case we weren’t certain about, we had CBMC verify that for
all non-assertion violating inputs, this was true up to size 10).
The new harness, informed by the harness mutations, in fact
had a better mutant kill rate for size 3 (80.7%) than our ﬁrst
harness had at the mutant-stable point. This examples serves
as our best evidence of the value of harness mutation.
C. Linux Kernel RCU V eriﬁcation Challenges
Read-Copy-Update (RCU) is a synchronization mechanism
sometimes used as a replacement for reader-writer locking
for linked structures, allowing extremely lightweight readers
[31]. In the limiting case, achieved in server-class builds of
the Linux kernel, overhead for entering and exiting an RCU
read-side critical section (using rcu_read_lock() and
rcu_read_unlock() , respectively) is exactly zero [32],
making RCU an excellent choice for read-mostly workloads
[31], [33], [34]. However, lightweight readers mean updaters
cannot exclude readers, so must take care to avoid disrupting
readers. Updaters typically maintain multiple versions of the
portion of the data structure being updated, removing old ver-
sions only when readers are no longer accessing them. To this
end, RCU provides synchronize_rcu() , which waits for
agrace period : when all pre-existing RCU readers complete.
RCU updaters typically remove a data element (rendering it
inaccessible to new readers), invoke synchronize_rcu() ,
and then reclaim a removed element.
Because both RCU and the Linux kernel are moving
targets, any validation and veriﬁcation must be both automated
and repeatable, for inclusion in a regression-test suite. At
present the rcutorture stress-test provides some assurance
in the form of automated testing, but ideally would be comple-
mented by some formal veriﬁcation of the implementation(s) in
the kernel. An important question is whether available formalveriﬁcation tools can provide effective additional regression
checking for RCU. We use a pair of RCU-related benchmarks
[35], [36] to provide the beginnings of an answer to this
question. The ﬁrst benchmark applies formal veriﬁcation to
the simplest of the Linux kernel’s RCU implementations, Tiny
RCU [37], which targets single-CPU systems. This model in-
cludes Tiny RCU’s handling of idle CPUs as well as its (trivial)
grace-period detection scheme. The second benchmark creates
the trivial model approximating an RCU implementation for
multiprocessor systems shown in Figure 12. In this model, the
number of RCU read-side critical sections currently in ﬂight
is tracked by the global rcu_read_nesting_global ,
which is atomically incremented by rcu_read_lock()
and atomically decremented by rcu_read_unlock() .
This allows synchronize_rcu() to atomically XOR
rcu_read_nesting_global ’s bottom bit to detect
whether the current execution has waited for all pre-existing
readers (over-approximated by checking the absence of all
readers), with SET_NOASSERT() being invoked to suppress
all future assertions. Although this model has a number of
shortcomings, perhaps most prominently excessive read-side
ordering, it is capable of detecting common RCU-usage bugs,
including failure to wait for an RCU grace period and failure
to enclose read-side references in an RCU read-side critical
section. Can falsiﬁcation aid in these two complex, in-progress,
veriﬁcation efforts?
Our efforts are ongoing, due to the complexity of the
targeted code (even with support from the primary developer,
a co-author of this paper). At this time the investigation of
mutants has already provided valuable information about these
veriﬁcations benchmarks. First, there are two versions of the
Tiny RCU veriﬁcation. The earliest, very preliminary version,
kills only 10 of 169 Tiny RCU mutants. Adding code to the
harness to account for interrupts in the dyntick-idle handling
kills an additional 12 mutants, conﬁrming that the modiﬁcation
increases the strength of the harness. More importantly, the
modeling of concurrency in the harness has two versions,
one using CBMC support for pthread mutex locks, the other
using disabling of assertions to ignore executions that violate
locking semantics. The native mutex version allows much
faster veriﬁcation, and catches the original, hand-constructed
checks to ensure the harness can detect faults in Tiny RCU.
However, the native mutex version fails to kill any mutants,
a fact we are currently investigating: without mutants, we
would not have been aware of this possibly critical problem,
which may be a CBMC bug (in the course of this paper’s
work, we have uncovered several CBMC bugs) or a harness
ﬂaw. In support of the veriﬁcation, we also generated passing
maximal-coverage executions for all mutants of the Tiny RCU
code. For 97 of the mutants, there is no passing execution;
in many cases, these are not killed: the mutant modiﬁes the
concurrency semantics so CBMC has no valid executions to
analyze (potentially invalid in some cases, which must be
investigated). For 79 mutants the maximal-coverage passing
runs are currently being examined, to determine the best next
steps in improving the Tiny RCU harness. For the second
benchmark, we have computed mutant kills and ﬁnd that the
kill rates range between 40% and 46%. While these bench-
marks are far from complete, and over-simplify the modeling
process, they are already able to catch a substantial number of
potential RCU usage errors. Again, we have produced passing
744
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. /g1/g2/g3/g2/g4/g1/g2/g3/g4/g1/g4/g1/g4/g2/g1/g4/g2/g2/g1/g4/g2/g2/g2/g1/g4/g2/g2/g2/g2/g1/g4/g2/g2/g2/g2/g2
/g1/g2/g3/g2/g4 /g1/g2/g3/g4 /g1/g4 /g1/g4/g2 /g1/g4/g2/g2/g1/g2/g3/g4 /g5/g6/g3/g7/g2/g3/g4/g8/g9/g10/g7/g11/g8/g12 /g3/g7/g13/g14/g15/g6/g7/g16/g17
/g5/g6/g7/g8/g9/g10/g7 /g1/g11/g12/g13/g13/g1/g14/g12/g15/g7 /g1/g16/g13/g17/g10 /g1/g18/g19
Fig. 13. Average times for killing/verifying mutants, in seconds.
runs for the surviving mutants to use in enhancing the process.
The good news is that while the RCU veriﬁcation is much more
substantial than the above case studies, the time to analyze
mutants is not prohibitive. No single model checking run
for the Tiny RCU benchmark takes more than 40 seconds,
and total runtime for all mutants in the usage benchmarks
ranges from just over 12 seconds for a basic litmus test to
less than 5 minutes for the most complex of the benchmarks.
Our belief that analyzing all surviving mutants is plausible for
code of this size and criticality is supported by our concurrent
preliminary work on using mutants to analyze the effectiveness
ofrcutorture , which has improved rcutorture itself
and (by doing so) exposed a previously undetected RCU bug.
D. Experiments: Plausible V eriﬁcation by Failure to Falsify
A key problem in model checking is the state explosion
problem, or, more simply (and more accurately, in that number
of states is not always the determining factor in symbolic
methods) the problem of scalability. As discussed above, even
proving binary search correct over the full domain of integer
inputs is not possible within a reasonable time frame. Even
when veriﬁcation is impossible at the desired problem size
falsiﬁcation can provide limited conﬁdence in the correctness
of a program. In particular, we observe from all of our experi-
ments that the average time, for any program and harness pair,
to verify the original code and all surviving mutants is much
higher than the average time to produce a counterexample
for killed mutants. Showing that a constraint is satisﬁable
is, usually, easier than proving it is unsatisﬁable. This is not
limited to SA T solvers; we used SA T rather than SMT in our
experiments because we generally found Z3 to be slower than
CBMC’s built in version of MiniSA T[38] in almost all cases,
but Z3 also aims to be fast at producing satisfying assignments,
not proving UNSA T [39], and our few runs with Z3 showed
the same pattern.
Figure 13 shows (with log scales on both axes) the average
running times for all experiments (including faulty versions
of the harness, incorrect runtime parameters, harness mutation
checks, etc.) performed in the course of this work. The general
trend is clear: time to verify is usually worse than time to
kill, and the worst average time to kill (about 350 seconds)
is much better than many average veriﬁcation times. One use
of this relationship is that, in cases where all (non-equivalent)mutants of the SUT are killed, but the SUT veriﬁcation fails to
complete, the SUT might be considered provisionally veriﬁed.
In particular, the larger the ratio between the timeout for failed
veriﬁcation and the longest kill time for any mutant, the “more
likely” to be correct we can consider the SUT (the same holds
with respect to memory use limits). This belief can be further
justiﬁed by modifying the harness to force mutant kills to use
large problem sizes, violating the usual inclusiveness rule (that
way, if the new size allows a counterexample not previously
existing, the mutant killing problem for mutants killable at
smaller sizes better approximates the counterexample construc-
tion problem for the actual fault).
Additionally, the times shown here (with mean mutant kill
time of 16.4 seconds and median mutant kill time of 0.54
seconds) show the general feasibility of the falsiﬁcation-driven
approach. Most of the time, killing mutants is cost-effective.
The outliers come from a few difﬁcult problems, arising from
buggy harnesses (or harness mutants that resemble buggy
harnesses). The much worse cost for surviving mutants is due
to a few expensive stubborn mutants: the median veriﬁcation
success time is only 1.5 seconds.
V. D ISCUSSION
A. Falsiﬁcation vs. V eriﬁcation
The core idea of this paper is that, while successful
veriﬁcation is the result that a developer seeks when verifying
a program, it is most meaningful in a context provided by many
failed veriﬁcations. The useful model checking harness (e.g.,
speciﬁcation) essentially, is one that prohibits certain execution
sequences. This is not controversial; a good property is deﬁned
by its rejection of bad behavior. However, in most veriﬁcation
efforts, there is a focus on arriving at a successful veriﬁcation,
which sheds very little light on exactly what has been veriﬁed.
By focusing on mutants throughout the veriﬁcation process,
our approach shifts the emphasis to one of “verifying” the
veriﬁcation itself by repeatedly falsifying claims that various
incorrect programs satisfy the property. This is, at a conceptual
level, akin to Karl Popper’s philosophy of science [18].
For Popper, all scientiﬁc knowledge is provisional, and
the key to the scientiﬁc approach is a critical effort, based
onprohibitive theories. In brief, Popper proposes that proper
science must be strongly grounded in a search for counterex-
amples. Using mutants as a basis for veriﬁcation is akin to
this approach, with the harness taken to be the “theory” of
the empirical behavior of the world. Mutants, in this view,
are counterfactual worlds that are likely to violate any correct
theory of the actual world. A “scientiﬁc theory” (that is, a
harness) is proven effective by its ability to be shown to be
false in these counterfactual worlds. If we can prove a theory
is incorrect for an “incorrect” world and cannot prove it is
incorrect for the real world, that gives us greater conﬁdence
(always provisional, since our understanding of the world,
e.g., any complex software system, is almost always limited
and prone to error) that the theory is indeed true of the real
world/program. Of course, generating alternative worlds and
showing that, for example, special relativity is easily falsiﬁed
in a world where special relativity does not in fact hold, is not
practical in scientiﬁc discovery. It is, however, quite easy in the
artiﬁcial “scientiﬁc discovery” sense of verifying properties of
computer programs.
745
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. B. The Power of Exhaustive Nondeterminism
The ability to improve a harness based on surviving mu-
tants (or on passing runs of killed mutants) essentially relies
on the nature of exhaustive bounded model checking based
on constraint solving. In non-exhaustive automated testing,
the answer to why a mutant is not killed is, often, neither
“the oracle is not good enough” nor even “the test process
is inadequate and needs to be modiﬁed” but “you didn’t
get lucky.” That is, killing all mutants is, in many cases,
not something we can expect of non-exhaustive test suites.
Random testing [40], [41] can perform well in general as a
bug-ﬁnding method, but its failure to kill any individual mutant
is likely to be a matter of probability, rather than a ﬂaw per
sein the testing itself. In veriﬁcation, however, there are no
accidents: if a harness veriﬁes an incorrect program, either
the assumptions, the speciﬁcation, or the problem size are
necessarily in need of correction. However, the approach we
propose is most suited to the analysis space in which CBMC
is situated: on the one hand, within a known bound, its results
are exhaustive; on the other hand, the method behaves much
like a dynamic analysis, in that there are no false positives.
VI. R ELA TED WORK
The idea that a “successful veriﬁcation” in model checking
(or even theorem proving) often simply indicates an inadequate
property is long-standing [13], [12]. Use of mutants [23],
[42] to provide a coverage measure dates back both to these
early explorations and relatively recent work [43], [44], [45].
However, in these efforts the mutation was usually applied to
hardware models, and (critically) the surviving mutants were
used to, e.g., identify “uncovered” portions of a model, rather
than presented to a developer for examination and understand-
ing directly. To our knowledge, no previous work presented
passing executions of a source code mutant as a guide to
understanding speciﬁcation weakness. Our modiﬁcation of the
harness is a source-code analogue to attempts to modify logical
formulas, e.g., the effort to (in a narrow, vacuity-based sense)
produce the strongest passing L TL formula of Chockler et
al. [46]. We are not the ﬁrst to note that model checking,
at present, due to the “many obstacles” in proving a system
correct, is primarily used for falsiﬁcation [47]. Previous work
on the topic [47] focused on abstractions based on under-
approximation, to ensure counterexamples were not spurious.
We instead preserve the goal of veriﬁcation7, but drive the
veriﬁcation process, from the human point of view, by repeated
falsiﬁcation of incorrect systems.
More distantly related is the general effort to determine
the quality not only of test suites (which is often focused on
missing tests within the “range” of testing, not a problem for
CBMC) but of test oracles and entire testing infrastructures.
The problem of “testing the tester” [8] is fundamental to all
efforts to improve software quality. Recent efforts of most
interest have focused on measuring checked coverage [48],
[49], [50], where a metric tries to make sure the code under
test potentially changes the value of an assert, using dynamic
slicing [51], [52]. This is weaker than requiring the oracle kill
a mutant, our goal, but more manageable for testing, where
7Note that we use a model checking approach that already guarantees non-
spurious counterexamples, and provides bounded rather than full veriﬁcation.complete behavioral coverage is less feasible than in model
checking (and where source code sizes combined with test
inadequacy may make hand mutation analysis infeasible).
VII. C ONCLUSIONS AND FUTURE WORK
This paper proposes a falsiﬁcation-driven methodology
for formal veriﬁcation, particularly when veriﬁcation is per-
formed by the developers of critical software systems. These
developers are not experts in formal veriﬁcation, but in the
systems they are verifying. V eriﬁcation is, we claim, always
provisional, in that the potential ﬂaws in our assumptions,
speciﬁcation, and understanding of system behavior tend to
leave room for doubt about the correctness of any veriﬁcation
result. V eriﬁcation of code is not self-explanatory, unlike a
counterexample. We propose to take advantage of the use of
counterexamples and witnesses and center veriﬁcation around
the incorrect programs a veriﬁcation fails to prove incorrect.
A veriﬁcation is considered effective when it ﬁnds no faults
in the SUT and detects every faulty variation of the SUT.
An obvious source of faulty SUT variations is mutants; we
also suggest that known-ﬂawed versions of code be included
in this set, which all of our tools support, but the key to
the method is the generation of a large set of potential
buggy versions without additional developer effort. Given
these faulty versions, a developer can examine mutants that
a veriﬁcation effort fails to detect, and (with the algorithms
and tools presented in this paper) examine executions showing
precisely how a program mutant can “make it through” a
veriﬁcation without being detected, with assurance that these
executions will have high coverage (and thus likely be non-
trivial). Developers can also check that a veriﬁcation harness
does not have any mutants that 1) verify the SUT while 2)
killing more mutants than the original harness. This can help
detect very subtle ﬂaws in harnesses, especially those based on
bad reasoning about “equivalent” mutants. We demonstrate, as
a proof-of-concept, that our approach can be useful for simple
but realistic veriﬁcation efforts, and can contribute to serious
systems veriﬁcation and modeling efforts for complex code
such as the Linux kernel RCU implementations. The bigger
picture is that our approach attempts to apply the ideas of
Karl Popper’s falsiﬁcation-centered approach to the philosophy
of science to the understanding of software systems. In this
view, veriﬁcation is almost always provisional, but we can gain
considerable conﬁdence in a veriﬁcation by making serious
attempts to prove its inadequacy.
In future work we plan to continue to apply this
falsiﬁcation-driven approach to the RCU veriﬁcation, and to
other critical systems-software targets, which we expect will
lead to discovery of new ways a model checker’s ability to
ask “what if” questions about program behavior [53], [54] can
improve developer understanding of veriﬁcation efforts. We
would also like to integrate falsiﬁcation-driven veriﬁcation sup-
port into the CBMC Eclipse tools, and use speculative model
checking calls and incremental SA T to make mutant analysis
available to developers continuously as part of their develop-
ment/debugging process. Finally, these techniques should also
be applicable to veriﬁcation using, e.g., Java Pathﬁnder [55] (at
least in symbolic mode [56]; in pure explicit-state exploration
the problems of non-exhaustive exploration may dominate).
A portion of this work was funded by NSF grants CCF-1217824 and CCF-1054786.
746
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] E. M. Clarke, O. Grumberg, and D. Peled, Model Checking . MIT
Press, 2000.
[2] D. Kroening, E. M. Clarke, and F. Lerda, “A tool for checking ANSI-C
programs,” in Tools and Algorithms for the Construction and Analysis
of Systems , 2004, pp. 168–176.
[3] A. Groce and M. Erwig, “Finding common ground: choose, assert, and
assume,” in Workshop on Dynamic Analysis , 2012, pp. 12–17.
[4] A. Groce and R. Joshi, “Random testing and model checking: Building
a common framework for nondeterministic exploration,” in Workshop
on Dynamic Analysis , 2008, pp. 22–28.
[5] E. W . Dijkstra, A Discipline of Programming . Prentice-Hall, Engle-
wood Cliffs, New Jersey, 1976.
[6] A. Groce and R. Joshi, “Exploiting traces in program analysis,” in Tools
and Algorithms for the Construction and Analysis of Systems , 2006, pp.
379–393.
[7] E. Clarke, O. Grumberg, K. McMillan, and X. Zhao, “Efﬁcient gener-
ation of counterexamples and witnesses in symbolic model checking,”
inDesign Automation Conference , 1995, pp. 427–432.
[8] A. Groce, “(Quickly) testing the tester via path coverage,” in Workshop
on Dynamic Analysis , 2009.
[9] A. Groce, M. A. Alipour, and R. Gopinath, “Coverage and its discon-
tents,” in Onward! Essays , 2014, pp. 255–268.
[10] X. Y ang, Y . Chen, E. Eide, and J. Regehr, “Finding and understanding
bugs in C compilers,” in ACM SIGPLAN Conference on Programming
Language Design and Implementation , 2011, pp. 283–294.
[11] P . Cuoq, B. Monate, A. Pacalet, V . Prevosto, J. Regehr, B. Y akobowski,
and X. Y ang, “Testing static analyzers with randomly generated pro-
grams,” in NASA F ormal Methods Symposium , 2012, pp. 120–125.
[12] Y . Hoskote, T. Kam, P .-H. Ho, and X. Zhao, “Coverage estimation for
symbolic model checking,” in ACM/IEEE Design Automation Confer-
ence , 1999, pp. 300–305.
[13] H. Chockler, O. Kupferman, R. P . Kurshan, and M. Y . V ardi, “A
practical approach to coverage in model checking,” in Computer Aided
V eriﬁcation , 2001, pp. 66–78.
[14] T. A. Budd, R. J. Lipton, R. A. DeMillo, and F. G. Sayward, Mutation
analysis . Y ale University, Department of Computer Science, 1979.
[15] R. J. Lipton, “Fault diagnosis of computer programs,” Carnegie Mellon
Univ., Tech. Rep., 1971.
[16] M. Gligoric, A. Groce, C. Zhang, R. Sharma, A. Alipour, and D. Mari-
nov, “Comparing non-adequate test suites using coverage criteria,” in
International Symposium on Software Testing and Analysis , 2013, pp.
302–313.
[17] ——, “Guidelines for coverage-based comparisons of non-adequate test
suites,” ACM Transactions on Software Engineering and Methodology ,
accepted for publication.
[18] K. Popper, The Logic of Scientiﬁc Discovery . Hutchinson, 1959.
[19] R. Lawlor, “quicksort.c,” http://www.comp.dit.ie/rlawlor/Alg DS/
sorting/quickSort.c, referenced April 20, 2015.
[20] D. Kroening and O. Strichman, “Efﬁcient computation of recurrence di-
ameters,” in V eriﬁcation, Model Checking, and Abstract Interpretation ,
2003, pp. 298–309.
[21] J. H. Andrews, L. C. Briand, and Y . Labiche, “Is mutation an appropriate
tool for testing experiments?” in International Conference on Software
Engineering , 2005, pp. 402–411.
[22] M. Papadakis, Y . Jia, M. Harman, and Y . L. Traon, “Trivial compiler
equivalence: A large scale empirical study of a simple fast and effective
equivalent mutant detection technique,” in International Conference on
Software Engineering , 2015.
[23] P . E. Black, V . Okun, and Y . Y esha, “Mutation of model checker
speciﬁcations for test generation and evaluation,” in Mutation 2000 ,
2000, pp. 14–20.
[24] R. Stout, If Death Ever Slept . Viking, 1957.
[25] scvalex, “Finding all paths of minimum length to a node using
dijkstras algorithm,” https://compprog.wordpress.com/2008/01/17/
ﬁnding-all-paths-of-minimum-length-to-a-node-using-dijkstras-algorithm/,
January 2008.[26] J. Bentley, “Programming pearls: Writing correct programs,” Commu-
nications of the ACM , vol. 26, no. 12, pp. 1040–1045, Dec. 1983.
[27] J. Bloch, “Extra, extra - read all about it: Nearly all binary searches
and mergesorts are broken,” http://googleresearch.blogspot.com/2006/
06/extra-extra-read-all-about-it-nearly.html, June 2006.
[28] visar, “[SOL VED] doubly linked list insertion sort in
C,” http://www.linuxquestions.org/questions/programming-9/
doubly-linked-list-insertion-sort-in-c-4175415860/, July 2012.
[29] R. N. Horspool, “Practical fast searching in strings,” Software - Practice
& Experience , vol. 10, no. 6, pp. 501–506, 1980.
[30] M. A. Alipour, A. Groce, C. Zhang, A. Sanadaji, and G. Caushik,
“Finding model-checkable needles in large source code haystacks: Mod-
ular bug-ﬁnding via static analysis and dynamic invariant discovery,” in
International Workshop on Constraints in F ormal V eriﬁcation , 2013.
[31] P . E. McKenney, “Structured deferral: synchronization via
procrastination,” Commun. ACM , vol. 56, no. 7, pp. 40–49, Jul. 2013.
[Online]. Available: http://doi.acm.org/10.1145/2483852.2483867
[32] P . E. McKenney and J. D. Slingwine, “Read-copy update: Using
execution history to solve concurrency problems,” in Parallel and
Distributed Computing and Systems , Las V egas, NV , October 1998, pp.
509–518.
[33] D. Guniguntala, P . E. McKenney, J. Triplett, and J. Walpole, “The read-
copy-update mechanism for supporting real-time applications on shared-
memory multiprocessor systems with Linux,” IBM Systems Journal ,
vol. 47, no. 2, pp. 221–236, May 2008.
[34] P . E. McKenney, D. Eggemann, and R. Randhawa, “Improving energy
efﬁciency on asymmetric multiprocessing systems,” June 2013, https:
//www.usenix.org/system/ﬁles/hotpar13-poster8-mckenney.pdf.
[35] P . E. McKenney, “V eriﬁcation challenge 4: Tiny RCU,” http://paulmck.
livejournal.com/39343.html, March 2015.
[36] ——, “V eriﬁcation challenge 5: Uses of RCU,” http://paulmck.
livejournal.com/39793.html, April 2015.
[37] ——, “Re: [P A TCH fyi] RCU: the bloatwatch edition,” January
2009, available: http://lkml.org/lkml/2009/1/14/449 [Viewed January
15, 2009].
[38] N. Een and N. Sorensson, “An extensible SA T-solver,” in Symposium
on the Theory and Applications of Satisﬁability Testing (SAT) , 2003,
pp. 502–518.
[39] L. M. de Moura and N. Bjørner, “Z3: an efﬁcient SMT solver,” in Tools
and Algorithms for the Construction and Analysis of Systems , 2008, pp.
337–340.
[40] R. Hamlet, “When only random testing will do,” in International
Workshop on Random Testing , 2006, pp. 1–9.
[41] A. Groce, G. Holzmann, and R. Joshi, “Randomized differential testing
as a prelude to formal veriﬁcation,” in International Conference on
Software Engineering , 2007, pp. 621–631.
[42] T.-C. Lee and P .-A. Hsiung, “Mutation coverage estimation for model
checking,” in Automated Technology for V eriﬁcation and Analysis , 2004,
pp. 354–368.
[43] O. Kupferman, W . Li, and S. Seshia, “A theory of mutations with ap-
plications to vacuity, coverage, and fault tolerance,” in F ormal Methods
in Computer-Aided Design ,2008, pp. 1–9.
[44] G. Auerbach, F. Copty, and V . Paruthi, “Formal veriﬁcation of arbiters
using property strengthening and underapproximations,” in F ormal
Methods in Computer-Aided Design , 2010, pp. 21–24.
[45] H. Chockler, D. Kroening, and M. Purandare, “Computing mutation
coverage in interpolation-based model checking,” IEEE Trans. on CAD
of Integrated Circuits and Systems , vol. 31, no. 5, pp. 765–778, 2012.
[46] H. Chockler, A. Gurﬁnkel, and O. Strichman, “Beyond vacuity: Towards
the strongest passing formula,” in Proceedings of the 2008 International
Conference on F ormal Methods in Computer-Aided Design , 2008, pp.
24:1–24:8.
[47] T. Ball, O. Kupferman, and G. Y orsh, “Abstraction for falsiﬁcation,” in
Computer Aided V eriﬁcation , 2005, pp. 67–81.
[48] D. Schuler and A. Zeller, “Assessing oracle quality with checked
coverage,” in International Conference on Software Testing, V eriﬁcation
and V alidation , 2011, pp. 90–99.
[49] ——, “Checked coverage: an indicator for oracle quality,” Software
Testing, V eriﬁcation, and Reliability , vol. 23, no. 7, pp. 531–551, 2013.
747
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. [50] A. Murugesan, M. W . Whalen, N. Rungta, O. Tkachuk, S. Person,
M. P . E. Heimdahl, and D. Y ou, “Are we there yet? determining the
adequacy of formalized requirements and test suites,” in NASA F ormal
Methods Symposium , 2015, pp. 279–294.
[51] X. Zhang, R. Gupta, and Y . Zhang, “Precise dynamic slicing algo-
rithms,” in International Conference on Software Engineering , 2003,
pp. 319–329.
[52] F. Tip, “A survey of program slicing techniques,” Journal of program-
ming languages , vol. 3, pp. 121–189, 1995.
[53] A. Groce, “Error explanation with distance metrics,” in Tools and
Algorithms for the Construction and Analysis of Systems , 2004, pp.108–122.
[54] A. Groce and D. Kroening, “Making the most of BMC counterexam-
ples,” Electron. Notes Theor . Comput. Sci. , vol. 119, no. 2, pp. 67–81,
Mar. 2005.
[55] W . Visser, K. Havelund, G. Brat, S. Park, and F. Lerda, “Model checking
programs,” Automated Software Engineering , vol. 10, no. 2, pp. 203–
232, Apr. 2003.
[56] C. S. Pasareanu, W . Visser, D. H. Bushnell, J. Geldenhuys, P . C.
Mehlitz, and N. Rungta, “Symbolic pathﬁnder: integrating symbolic
execution with model checking for java bytecode analysis,” Automated
Software Engineering , vol. 20, no. 3, pp. 391–425, 2013.
748
Authorized licensed use limited to: Access paid by The UC Irvine Libraries. Downloaded on January 26,2023 at 02:31:10 UTC from IEEE Xplore.  Restrictions apply. 