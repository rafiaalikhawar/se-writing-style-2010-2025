Witness Validation and Stepwise Testiﬁcation
across Software Veriﬁers
Dirk Beyer1, Matthias Dangl1, Daniel Dietsch2, Matthias Heizmann2, Andreas Stahlbauer1
1University of Passau, Germany2University of Freiburg, Germany
ABSTRACT
It is commonly understood that a veriﬁcation tool should
provide a counterexample to witness a speciﬁcation violation .
Until recently, software veriﬁers dumped error witnesses in
proprietary formats, which are often neither human- nor
machine-readable, and an exchange of witnesses between dif-
ferent veriﬁers was impossible. To close this gap in software-
veriﬁcation technology, we have deﬁned an exchange format
for error witnesses that is easy to write and read by veriﬁca-
tion tools (for further processing, e.g., witness validation) a nd
that is easy to convert into visualizations that conveniently
let developers inspect an error path. To eliminate manual
inspection of false alarms, we develop the notion of stepwise
testiﬁcation : in a ﬁrst step, a veriﬁer ﬁnds a problematic pro-
gram path and, in addition to the veriﬁcation result false,
constructs a witness for this path; in the next step, another
veriﬁer re-veriﬁes that the witness indeed violates the speci-
ﬁcation. This process can have more than two steps, each
reducing the state space around the error path, making it
easier to validate the witness in a later step. An obvious
application for testiﬁcation is the setting where we have two
veriﬁers: one that is eﬃcient but imprecise and another one
that is precise but expensive. We have implemented the
technique of error-witness-driven program analysis in two
state-of-the-art veriﬁcation tools, CPAchecker andUltimate
Automizer , and show by experimental evaluation that the
approach is applicable to a large set of veriﬁcation tasks.
Categories and Subject Descriptors: D.2.4 [Software
Engineering ]: Software/Program Veriﬁcation
General Terms: Theory, Veriﬁcation
Keywords: Error Witness, Counterexample Validation,
Software Veriﬁcation, Program Analysis, Model Checking
1. INTRODUCTION
Software veriﬁcation becomes more and more important in
practice; several breakthroughs in veriﬁcation research were
achieved during the last decade, and several successful veriﬁ-
cation tools were developed. The TACAS International Com-petition on Software Veriﬁcation ( SV-COMP )1[4,5] serves
as a showcase of the state-of-the-art. Users can choose from
a wide range of veriﬁers, and the SV-COMP categories give
an approximate guidance on which veriﬁer is good for which
kind of programs. One important and unsolved problem
of applying veriﬁcation technology in practice is that ver-
iﬁcation tools sometimes produce false alarms, and it still
requires an enormous manual eﬀort to ﬁnd out if a reported
bug indeed represents a genuine speciﬁcation violation.
Our solution comprises two components: we developed
anexchange format for error witnesses and evaluated its
eﬀectiveness by a thorough experimental evaluation, and we
develop the notion of stepwise testiﬁcation , as the technique
of witness validation immediately leads to the notion of
witness reﬁnement, enabling a chain of veriﬁers (or testiﬁers)
to continuously reﬁne the erroneous state space until a test
vector for the error is found.
Testiﬁcation is the process of giving evidence for a claim
that a given program satisﬁes, or violates, its speciﬁcation.
The evidence of the absence, or presence, of a speciﬁcation
violation is given by one or more witnesses. A veriﬁcation
tool is a testiﬁer if it provides evidence to support its claim,
i.e., if it produces a witness for correctness or for a violation
of the speciﬁcation. Stepwise testiﬁcation is the process of ap-
plying testiﬁcation in several steps, on ever reﬁned witnesses ,
possibly using diﬀerent veriﬁcation tools, combining diﬀer-
ent strengths. Figure 1 illustrates the process of stepwise
testiﬁcation. In this paper, we focus on stepwise testiﬁca-
tion of speciﬁcation violations by producing error witnesses
(left part), while conditional model checking [10] focuses on
stepwise testiﬁcation of correctness.
We accompany the bug report of veriﬁer V1with an error
witness, which represents information that can eﬀectively
guide another veriﬁer V2to eﬃciently re-explore the state
space that veriﬁer V1reported to contain a bug. Our ex-
perimental study conﬁrms the following insights: (1) our
exchange format makes it possible to communicate error
witnesses across veriﬁers, (2) veriﬁer V2needs on average
considerably less resources to validate the witness than veri-
ﬁerV1needed to ﬁnd the error, even if V2uses a more ex-
pensive veriﬁcation technology (e.g., V1using linear and V2
using bit-precise arithmetic), (3) stepwise testiﬁcation ca n
be more eﬃcient than veriﬁcation, i.e., the CPU time for
V1-veriﬁcation + V2-witness-validation can be less than the
CPU time for V2-veriﬁcation alone, (4) the state-space to be
analyzed by V2is eﬀectively reduced.
1http://sv-comp.sosy-lab.org/
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ESEC/FSE’15 , August 30 – September 4, 2015, Bergamo, Italy
c2015 ACM. 978-1-4503-3675-8/15/08...$15.00
http://dx.doi.org/10.1145/2786805.2786867
721Our technique was already used in the most recent edition
of the competition on software veriﬁcation. The SV-COMP
community manifested in the competition rules that each
answer FALSEmust be accompanied by an error witness.
Previously, only the existence of an error witness was checked,
but not its meaning . The last edition of the competition
rules [5] required the organizer to reasonably validate each
witness in order to get more conﬁdence that the error witness
indeed represents a valid bug before assigning a success score.
On the syntactic level, we use XML, more speciﬁcally
GraphML [19], as a language to represent error witnesses.
On the semantic level, we use the standard concept of (non-
deterministic) ﬁnite automata to represent an error witness.
A witness automaton observes the paths that the veriﬁer
explores and directs the exploration engine along the paths
that the witness describes, i.e., towards the violation of the
speciﬁcation. Witnesses can be read by humans (perhaps
using a visualization or inspection tool) or a witness valid ator.
Witness automata allow diﬀerent levels of abstraction.
A most abstract error-witness automaton allows all paths
through the program, i.e., it does not restrict the state-
space exploration. A most concrete error-witness automaton
represents one concrete error path, which is annotated with
value assignments for all variables (i.e., a concrete test vect or
is represented). Many interesting witnesses occur in between
the two extremes: there is a continuous spectrum of reﬁned
witness automata, reducing the number of possible choices
through a program until the most concrete level —the test
vector— is reached. Sometimes it is eﬃcient to represent
several (or even inﬁnitely many) error paths in one witness.
Contributions. We make the following novel contributions:
•We develop a syntactical exchange format based on XML
for exchanging and archiving witnesses across software
veriﬁers, and instantiate the format for C programs.
•We introduce witness automata as a semantical basis
from which a program analysis can be constructed as an
extension for existing veriﬁers (two examples given).
•Our approach validates witnesses against the given pro-
gram and speciﬁcation, independently from the computing
resource and veriﬁer used to produce the witness, i.e., nei-
ther this resource nor this veriﬁer need to be trusted.
•We develop the notion of stepwise testiﬁcation , which
continuously reﬁnes witnesses using diﬀerent veriﬁers or
diﬀerent approaches on perhaps diﬀerent platforms.
•We provide an extensive experimental evaluation that
shows the potential and feasibility of using error witnesses
and stepwise testiﬁcation.
Advantages and Applications. Our solution has various
application scenarios in research and industry, for example:
•Witness validation can be used to automatically eliminate
false alarms in program analysis (e.g., as used in [30]).
•A common exchange format can boost the development
of various tools for collecting, correlating, explaining, and
visualizing error witnesses from diﬀerent sources.
•Error witnesses can accompany bug reports.
•It is sound to use untrusted computing resources and veri-
ﬁcation engines if followed by witness validation on trusted
computing resources and trusted witness validators. This
is especially interesting for veriﬁcation in the cloud.
•Diﬀerent veriﬁcation approaches and tools have diﬀerent
strengths, and thus, it is interesting to combine diﬀerent
veriﬁcation approaches via stepwise testiﬁcation.Stepwise
Testiﬁcation
Error-T esti ﬁcation
Step 1
Error-T esti ﬁcation
Step kConditional 
Model Checking kConditional 
Model Checking 1
FALSE 
+ Violating T est VectorTRUE
+ Correctness Proof... ...
Figure 1: Stepwise testiﬁcation: conceptual view
Testiﬁcationreached
Error1#concrete 
paths
iterationpStepwiseT esti
ﬁcation
0
nn+1r
0
Figure 2: Testiﬁcation reduces the state space (left) and
the number of paths (right) that need to be (re-)veriﬁed.
•Error witnesses can describe program parts that should
be covered by a (regression) test suite.
•Witness validation implies a notion of witness quality:
a more concrete witness (less resources needed for valida-
tion) might be considered better than an abstract witness.
Figure 2 (left) illustrates how testiﬁcation gives evidence
of the presence of a speciﬁcation violation by reducing the
state space that the witness validator needs to verify, i.e.,
the state-space to be explored gets narrower. Figure 2 (right)
illustrates that testiﬁcation reduces the number of paths tha t
the witness validator has to verify. For example, given a
program that contains rerror paths, an error witness might
represent more paths, e.g., ppaths, including some infeasible
error paths, but testiﬁcation might further reﬁne such an
error witness until only one concrete path is represented
(e.g., in iteration n). Testiﬁcation might also ﬁnd out that
all paths of the witness are not violating the speciﬁcation
(error witness rejected, cf. iteration n+1).
Example. We illustrate how error witnesses are validated
and reﬁned across veriﬁers: We start with an overview of
the process and then describe the process of producing and
consuming error witnesses in more detail.
We run three veriﬁer instances in sequence. Each of them
takes the program shown in Fig. 3a as input, and produces
an error witness. The speciﬁcation of the program is that nei-
ther label ERROR1norERROR2is reachable from the program
entry. The ﬁrst veriﬁer runs an analysis based on predicate
abstraction [8,31] with counterexample-guided abstraction
reﬁnement (CEGAR) [21], and produces the error witness
in Fig. 3b. The second veriﬁer takes this witness (and the
program) as input and runs an analysis based on an interval
domain [27], and produces the error witness in Fig. 3c. In
the last step, we run a test-case generator [6,13] that takes
the error witness from Fig. 3c as input and produces the test
vector in Fig. 3d (Witness 3).
Before we continue with the example, we will informally
introduce several basic concepts. We model the program
as a control-ﬂow automaton (CFA); its locations represent
7221int foo(int s, int t) {
2int d = s-t;
3if (d < 2 || d > 8) {
4 return 0;
5}
6int x = nondet_int();
7int a = x ? 512 : 64;
8int b = a*d;
9if (b >= 2048) {
10 ERROR1: exit(2);
11}
12if (b < 128) {
13 ERROR2: exit(3);
14}
15while (a > 0) {
16 a--;
17 // code omitted
18}
19return b;
20}
(a)Source codeq0START
q1
q2q⊥1
qE1
qE2
q⊥23,else:o/w
3,then:
o/w
9,else: 9,then:
12,then:o/w
12,else:
(b)Witness 1q0START
q1
q2
qE1q⊥1
q⊥33,then:
d<=1
|| d>=9;o/w3,else:
d>=2
&& d<=8;
o/w
7:
a>=64
&& a<=512;o/w
9,else:
b>=128
&& b<=2047;9,then:
b>=2048
&& b<=4096;
(c)Witness 2q0START
q1
q2
qE11:
s==10
&& t==4;o/w
6:
x==1;o/w
9:o/w
(d)Witness 3
Figure 3: Example C program (a) and a testiﬁcation sequence of three witne ss automata: accepting control states are drawn
as double circles, sink states are labeled with the subscript ⊥, non-accepting control states are drawn as single circle.
program-counter values (we denote the location before the
operation on line iasli), and its edges represent program op-
erations. Error witnesses are represented as ﬁnite automata
that describe a set of program paths that should contain at
least one path that violates the speciﬁcation. Paths that en d
in a sink control state (not accepted by the witness automa-
ton) should not be explored by a veriﬁer that consumes the
witness (during witness validation). In our ﬁgures, each tran-
sition of a witness automaton has a label, which is divided
into two parts (by colon): The ﬁrst part is the source-code
guard, which is used to matchthe control-ﬂow and can be
given, e.g., as a line number. The second, optional part
is thestate-space guard , given as a C expression, which is
used torestrictthe abstract successor state of an analysis,
i.e., the set of concrete program states that it represents.
The exploration of the state space can be restricted either
by transitions to sink control states (that have no outgoing
transitions, and thus the path exploration ends) or by restrict-
ing the state space using state-space guards at transitions.
A state-space guard needs to be checked if the corresponding
source-code guard matches the current control-ﬂow edge. We
only consider analyses that construct reachability graphs
of abstract states. In our example, an abstract state is a
tuple (q,l,e) that is composed from the current state qof the
witness automaton, the current location lof the CFA, and a
component ethat represents the information that is tracked
by the chosen abstract domain (for example, the interval
domain, or the predicate-abstraction domain). The analysis
that consumes a witness automaton proceeds along those
CFA edges that match transitions of the witness automaton.
The ﬁrst witness automaton (Fig. 3b) is produced by
a veriﬁer with predicate abstraction [8,31], CEGAR [21],
and lazy abstraction [9,36]. The analysis detects that tak-
ing thethen-branch in line 3 cannot lead to a violation of
the speciﬁcation, and thus, writes a transition to the sink
stateq⊥1(with source-code guard 3,then:), and similarly
for theelsebranch in line 12. The multiplication in line 8
is overapproximated by the analysis (this predicate analysisuses linear arithmetics), and thus, it reports paths to both
error locations. Despite the infeasible error path that is
included in the witness, the loop of lines 15 −18 has already
been analyzed, i.e., a successive witness validation can ig nore
the loop completely.
In the next testiﬁcation step, the error witness in Fig. 3b
is validated by a veriﬁer that runs an interval analysis. The
veriﬁer starts with the abstract state ( q0,l1,·), i.e., the wit-
ness automaton is in its initial state q0, and the CFA is
on its initial location l1(which corresponds to the function
entry). The ﬁrst analyzed operation is the declaration of
the function parameters and their initialization. In the wit-
ness automaton, only the self transition on state q0labeled
with“o/w”(otherwise) matches; self-transitions such as this
one match only if no other transition matches. Thus, the ver-
iﬁer proceeds to line 2 with the abstract state ( q0,l2,·). The
assignment d=s-tis matched (again) by the self-transition
and the witness automaton stays in q0. From abstract state
(q0,l3,·), we compute one successor state for each case of the
condition in line 3: one for the then-case, and one for the
else-case; each case is matched by a corresponding edge of
the witness automaton. The then-branch of the if-statement
in line 3 is matched by the transition to the sink state q⊥1;
the analysis does not continue on that branch because q⊥1
has no successor. Thus, the else-branch of the if-statement
is taken by proceeding to q1in the witness automaton. For
the assignments of lines 6 and 7, the witness automaton
takes the self-transition in q1, where the analysis has to
branch due to the conditional assignment in line 7: on one
branch, the value of ais 64, on the other branch it is 512.
The paths immediately join again and the value of ais in
the interval [64 ,512]. The automaton stays in q1and the
analysis continues (with bin [128,4096] after line 8) until
it reaches line 9 with the abstract state ( q1,l9,·). We com-
pute a separate abstract successor state for each case of the
condition in line 9: the successor state for the then-case
is (qE1,l10,·), because the next operation (label) ERROR1is
reached. Since this is the (accepting) error state qE1, we
723have conﬁrmed the ﬁrst error path of the witness. The
analysis continues at line 12 by computing successors for
(q2,l12,ok) which was the result of the else-case of the condi-
tion in line 9. The state component ok, which represents the
information tracked by the interval analysis, stores the inter-
vals{a/maps⊔o→[64,512],b/maps⊔o→[128,2047],d/maps⊔o→[2,8]}. The analysis
can not take the then-branch from q2(reaching the accepting
stateqE2, which corresponds to ERROR2in the CFA), because
the interval analysis stored that the value of bis in the inter-
val [128,2047]. Therefore, the label ERROR2is not reachable
(the previous analysis that produced this witness automaton
could not detect this because the predicate analysis over-
approximated the multiplication in line 8). Proceeding the
else-branch from line 12, we enter q⊥2of the witness au-
tomaton and reach line 15. The analysis that produced the
witness was able to prove that the code from line 15 onwards
does not violate the speciﬁcation. Therefore, the sink control
stateq⊥2concludes the analysis.
Upon completion, the interval analysis produces the wit-
ness automaton in Fig. 3c. The automaton is constructed by
encoding all abstract paths that lead to the violating abstrac t
state in line 10, and adding transitions to sink control states
along the paths such that a witness validator can stop the
exploration of branches that are not relevant for reaching
the violating abstract state.
In the last testiﬁcation step, the error witness from Fig. 3c
is used to restrict a test-case generator [6] in order to derive a
speciﬁc test vector for the path to ERROR1. The test vector is
derived by extracting a satisfying assignment of the formula
that represents the program path to the error location. The
third witness automaton (Fig. 3d) represents the result of
the test-case generation, i.e., a test vector.
Related Work. There is a large body of work on combining
diﬀerent veriﬁcation approaches, starting in the 1970’s with
reduced products of abstract domains [28]. There are many
combinations of model checking with data-ﬂow analysis, wit h
testing, and with deduction (cf. [22] for an overview). Most
existingapproachescombinediﬀerenttechniquesinparallel as
a product or as portfolio veriﬁcation. More recently, stepwise
sequential combinations were conceptualized as conditiona l
model checking [10], where veriﬁcation artifacts (‘conditions ’)
are passed from one veriﬁer to another. Our contribution
focuses on stepwise testiﬁcation of speciﬁcation violation s,
based on passing error witnesses from one veriﬁer to another.
Model-checking tools usually produce and provide counter-
examples in some form. However, there is an increasing
awareness for the need of (fast and automatic) validation of
program error paths in order to increase the conﬁdence in
the automatic bug reports, especially to reduce the number
of false alarms [5,18,29,40]. A cheap data-ﬂow analysis can
be combined with a high-precision feasibility analysis to ﬁlt er
out as many false alarms as possible within one instance of
a veriﬁer [29]. Experiments illustrate that the validation of
error witnesses is usually signiﬁcantly faster than re-verifying
the (full) program [18]. The tool that produced an error wit-
ness can work with a diﬀerent abstract domain than the tool
that is used for the validation [40]. There was, however, no
uniﬁed exchange format for error witnesses across veriﬁers.
The process of reﬁning witnesses has been addressed for
safety proofs from software veriﬁcation [10,26], but not yet
for counterexamples. Clarke and Veith [24] mention the
fact that already a full Kripke structure with a violation
of the speciﬁcation would be a valid counterexample; theydeﬁne a set of criteria that make counterexamples more
useful for tools and potential users. We extended this idea
to stepwise testiﬁcation. Witness testiﬁcation can be seen as
the counterpart of conditional model checking [10].
The exchange of veriﬁcation (and inference) results across
veriﬁers has not been discussed in detail before. Counter-
examples were exported by deriving full programs from
counterexamples in order to provide them as input to another
tool [11,14,41]. This approach is not feasible for witness
validation because the witness needs to be checked against
the original program. There is a number of trace formats in
the context of distributed high-performance computing, e.g.,
the Open Trace Format [37], or the MPI trace format [1];
their primary intent is to keep record of events in the system,
for example, the exchange of messages between processes.
These formats have a strong focus on time-stamped events
in distributed systems and are not applicable to our prob-
lem. The Certiﬁcation Problem Format2was designed for
ﬁrst-order term-rewrite systems and termination analysis.
Error witnesses have many applications [25,32,33,39,44],
and a common exchange format for veriﬁcation tools will
foster further research in this direction, in particular, on
combinations of veriﬁcation and debugging techniques.
2. PROTOCOL ANALYSIS
Preliminaries. We adopt the same notion of programs
to describe the theoretical aspects of our ideas as in previ-
ous work [12]. The presentation is restricted to a simple
imperative programming language that contains only as-
sume operations and assignments, and all program variables
are integers.3Programs are represented by control-ﬂow
automata (CFA). A control-ﬂow automaton C= (L,l0,G)
consists of a set Lof program locations, modeling the pro-
gram counter, the initial program location l0, which models
the program entry, and a set G⊆L×Ops×Lof control-ﬂow
edges, each of which models the operation that is executed
during the ﬂow of control from one program location to an-
other. All variables that occur in operations from Opsare
contained in the set Xof program variables.
Aprogram path is a sequence l0op1− − →...opn− − →lnwith
(li−1,opi,li)∈Gfor 1≤i≤nandl0is the initial pro-
gram location. A program path is called feasibleif there
exists a test vector [6] for which the program path can be
executed, otherwise the program path is called infeasible ; a
feasible path with concrete test values is called concrete path .
Protocol Automata. A protocol automaton A=
(Q,Σ,δ,q0,F) for a CFA C= (L,l0,G) is a non-deterministic
ﬁnite automaton with the following components: the ﬁnite
setQrepresents the control states of the automaton, the
alphabet Σ ⊆2G×Φ consists of pairs of a ﬁnite set of CFA
edges from Gand a state condition, the transition relation
δ⊆Q×Σ×Qdeﬁnes the control-state transitions, the initial
control state q0∈Qdeﬁnes the start of the automaton, and
the setFcontains the accepting control states. We write
qσ− →q′if (q,σ,q′)∈δandq− →q′if there exists a σwithqσ− →q′.
Protocol Analysis. Aprotocol analysis for a protocol au-
tomatonAis a conﬁgurable program analysis (CPA) [12]
O= (DO,/squigglerightO,mergeO,stopO), which tracks the control state
2http://cl-informatik.uibk.ac.at/software/cpf/
3Our implementations are based on CPAchecker [14] and
Ultimate Automizer [34], both of which support C programs.
724of a protocol automaton A= (Q,Σ,δ,q0,F) and consists of
the following components (for a given CFA ( L,l0,G)):
1.The abstract domain DO= (C,Q,[[·]]) consists of the
setCof concrete states, the semi-lattice Q, and a concretiza-
tion function [[ ·]]. The semi-lattice Q= (Z,⊑,⊔,⊤Q), with
Z= (Q∪{⊤})×Φ, consists of the set Zof abstract data
states, which are pairs of a control state from Q(or spe-
cial lattice element ⊤) and a condition from Φ, a partial
order⊑, the join operator ⊔, and the top element ⊤Q.
The partial order ⊑is deﬁned such that ( q,ψ)⊑(q′,ψ′)
if (q′=⊤orq=q′)andψ⇒ψ′, the join ⊔is the least
upper bound of two abstract data states, and the top el-
ement⊤Q= (⊤,true) is the least upper bound of the
set of all abstract data states. The concretization func-
tion [[·]] :Z→2Cis a mapping that assigns to each abstract
data state ( q,ψ) the set [[ψ]] of concrete states.
2.The transfer relation /squigglerightOhas the transfer (q,·)g/squigglerightO(q′,ψ′)
if the protocol automaton Ahas a transition qσ→q′such that
σ= (D,ψ′) andg∈D. The condition ψ′of the control-state
transition is stored in the successor in order to enable a
composite strengthening operator [12] to strengthen the suc-
cessor abstract data state of another component analysis in
the composite analysis using information from condition ψ′.
3.The merge operator combines elements with the same
control state:
mergeO((q,ψ),(q′,ψ′)) =/braceleftbigg
(q′,ψ∨ψ′) ifq=q′
(q′,ψ′) otherwise .
4.The termination check stopO((q,ψ),R) returns true, i.e.,
terminates the state-space exploration of the current path
if the abstract data state is covered by an existing abstract
data state: stopO((q,ψ),R) =∃(q,ψ′)∈R:ψ⇒ψ′.
Composition. The protocol CPA is used as one component
in a composite CPA, in which other component CPAs track
the data and control state, i.e., information about the values
of the variables and the control-ﬂow location. Let Pbe a
component CPA that tracks the abstract data states. In
the composite abstract transfer relation, the abstract data
states from the protocol CPA Oand the other CPA Pcan
be used to strengthen the composite abstract successor in
the following way: the composite abstract transfer restricts
the abstract data state in Pto represent only those concrete
states that satisfy the state condition ψinO. This way,
each abstract data state on a program path that the com-
posite CPA explores, always implies the corresponding state
condition of the protocol automaton.
Simulation. Arunof a protocol automaton Afor a
program path l0op1− − →...opn− − →lnis a simulation sequence
q0σ1− →...σn− − →qnsuch that every step liopi− − →li+1is matched by
a stepqiσi− →qi+1withσi= (D,ψ) and (li,opi,li+1)∈Dand
all variable assignments at program location li+1satisfyψ.
Protocol automaton Aacceptsthe run ifqn∈F. We say
Aaccepts the program path πif there exists an accepting
run ofAforπ. The projection of an accepted run to its
alphabet symbols σ1...σnis called accepted word . The set
of all accepted words of Adeﬁnes the language L(A).
Speciﬁcation by Observer Automata. Safety properties
and security aspects [42] can be modeled using ﬁnite ob-
server automata (also called ‘monitor automata’) that run
in parallel to the system to be veriﬁed and ‘observe’ the
behavior of the system without inﬂuencing it. Observer au-
tomata are an established concept for providing a formal
speciﬁcation [3,7,14,43]. Separating speciﬁcation from im-plementation supports the idea of separation of concerns;
tools can support the user in providing and maintaining the
speciﬁcation. A software speciﬁcation is either weaved into
the source code before veriﬁcation (cf. Slic[3] and Blast[7]),
or checked on-the-ﬂy in parallel to the program (cf. Blast-
cpa[43],CPAchecker [14],Orion[29]). A set of properties
can be checked simultaneously within one run of a veriﬁer.
Anobserver automaton is a protocol automaton that sat-
isﬁes the following condition: for every control state qofA,
and every control-ﬂow edge gofC, the state conditions can
partition, but not restrict, the state space of the program:/logicalortext{ψ| ∃q′∈Q:∃σ∈Σ :∃D⊆G:qσ− →q′,σ= (D,ψ),
g∈D}=true.
Anobserver analysis is a protocol CPA for an observer
automaton, i.e., anobserveranalysis‘observes’(or‘monito rs’)
the paths of the observed program, but does not restrict the
exploration of the program analysis. The observer CPA can
be used to split abstract paths to observe them separately.
3. TESTIFICATION
The goal of our work is to represent error paths —
paths through the program source code that violate the
speciﬁcation— in such a way that they are reproducible,
machine-readable, and exchangeable between various veri-
ﬁcation tools. Conceptually, a witness is information that
provides evidence of the veriﬁcation result. This paper fo-
cuses on error witnesses, i.e., witnesses that provide evidenc e
that the given program violates a given speciﬁcation. For the
representation of error witnesses we use witness automata.
Witness Automata. Awitness automaton is a protocol
automaton, and a witness analysis is a protocol CPA for a
witness automaton, which runs as one component CPA of a
composite program analysis in parallel to other component
CPAs. One of the other component CPAs is an observer
CPA that encodes the speciﬁcation. In contrast to observer
automata, witness automata not only observe, but also re-
stricthow the program analysis explores the program’s state
space. While an observer automaton has abstract successor
states for allconcrete successor states, a witness automaton
can restrict the successor states to those successor states th e
lead the exploration towards the speciﬁcation violation. In
other words, the witness automaton guides the program anal-
ysis to explore the state space that violates the speciﬁcatio n.
Automata that guide the analysis towards speciﬁc program
locations are also used for test-case generation [13].
Veriﬁcation with Witnesses (Testiﬁcation). We require
a veriﬁer, whenever a violating program path is found, to
produce a witness automaton for exemplifying the violation;
we call such averiﬁer also testiﬁer, because ittestiﬁes that the
bug exists, and we call this process testiﬁcation , as illustrated
in Fig. 4a. The purpose of the witness automaton is to later
restrict the state-space exploration of a veriﬁer such that
the error path can be conﬁrmed with less eﬀort than with a
completely independent veriﬁcation run. In this paper, we
focus on errorwitnesses only.
Witness Validation. Witness validation is the process of
determining if, for a given program, speciﬁcation, result, and
witness, the same result can be re-established independently
(Fig. 4b). In this paper speciﬁcally for error witnesses, we
validate if an error path can be found in the state space that
the witness describes. One way of implementing witness vali-
dation is to construct a composite program analysis that has
725Program
WitnessSpeci ﬁcation
Result (True/False)VeriﬁerProgram
Speci ﬁcation
(a)Veriﬁcation with witnesses (Testiﬁcation)
Witness
ValidatorResult (True/False)Program
WitnessSpeci ﬁcation
Result (True/False)
(b)Validation of witnesses
Witness
T estiﬁerProgram
WitnessSpeci ﬁcation
Result (True/False)Program
WitnessSpeci ﬁcation
Result (True/False)
(c)Stepwise testiﬁcation with witnesses
Figure 4: From veriﬁcation and witness validation to step-
wise testiﬁcation
a speciﬁcation analysis and a witness analysis as component s,
which simultaneously observe and restrict the state-space
exploration: the witness validation restricts the search of
the composite program analysis such that only paths are
explored that the witness automaton can match, and the
speciﬁcation analysis checks if the path indeed violates th e
speciﬁcation. If, during the analysis of a program path, the
witness automaton takes a transition to a sink state, the
analysis stops exploring the path, thus, restricting the state -
space exploration. The witness is conﬁrmed by the witness
validator if both, the speciﬁcation automaton and the witne ss
automaton, take a transition to their respective (accepting)
error control state. We call such a veriﬁer witness validator .
A widely-used instance of error-witness validation is coun-
terexample checking (e.g., [30]), for example during the re-
ﬁnement phase in CEGAR [21], where an abstract counterex-
ample (which is an error witness) is checked for feasibility
(the witness testiﬁes against the program’s claim to correct-
ness). The given error witness is either rejected, which means
that it describes no feasible counterexample, or it is accepte d
because it contains a concrete error path and CEGAR stops.
Abstraction Levels of Witness Automata. A witness au-
tomaton can represent more than one error path; in fact, the
veriﬁer that constructs the witness automaton is not bound
to a certain level of abstraction. Obviously, for the purpose
of witnessing a violation of a speciﬁcation, the witness is t he
better the more the witness automaton restricts the search
space, in order for the validating program analysis to explore
fewer paths and validate the witness faster.
Stepwise Testiﬁcation with Witnesses. Stepwise testi-
ﬁcation of witnesses is the iterative process of improving
witnesses, by removing unnecessary state space. This pro-
cess combines witness validation with testiﬁcation: it tak es
as input a witness and produces as output a better witness,
as illustrated in Fig. 4c. Here, for error witnesses, a testiﬁ-
cation step starting with witness wproduces a witness w′
that describes a subset of paths that contains an error path.
Each testiﬁcation step reduces the state space that the next
testiﬁcation step has to explore.The most concrete level of error witnesses describes one
single concrete path that violates the speciﬁcation (cf. Fig. 2,
right). Such a concrete error path contains value assignments
for all variables, and is equivalent to a test vector.
Stepwise Testiﬁcation Across Veriﬁers. In order to en-
able witness validation and stepwise testiﬁcation across di f-
ferent veriﬁers, we propose a veriﬁer-independent exchange
format, which was already successfully used in SV-COMP
2015 [5]. The exchange of error witnesses across diﬀerent
veriﬁers enables a wide range of applications, some of which
were outlined in the introduction. The following section gives
more detail on the proposed exchange format.
4. EXCHANGE FORMAT
Using a common exchange format for (error) witnesses,
tools that support stepwise testiﬁcation may be chained ar-
bitrarily. We instantiate these concepts for programs written
in C, and an exchange format based on XML.
4.1 Witness Exchange Format
Our format for exchanging error witnesses is based on
GraphML [19], an XML-based format for storing and ex-
changing graph structures. A number of libraries support
reading and writing GraphML (or at least XML), and thus
make the adoption of the format convenient. The graph
nodes and graph edges represent the control states and the
transitions of the witness automaton, respectively.
We make use of the extensible nature of GraphML to
extend it with custom data for storing error-witness informa-
tion. Both the node and edge elements in GraphML can take
additional data within a datatag that has an attribute key.
The meaning of a data tag is determined by its keyattribute.
More details on the error-witness format can be found on
our supplementary web page.4
Automata States and Transitions. The control states Q
and the corresponding transitions δ⊆Q×Σ×Qof the
witness automaton are the central information to be encoded
in the format. The format also encodes the diﬀerent roles
that a control state can take: (1) the initial state q0of
the automaton, (2) a sink state q⊥, (3) an error state qE,
or (4) a ‘normal’ state. Depending on the role we add
a data tag with the key attribute (1) entry, (2)sink, or
(3)violation , with the value true(the default is falsefor
all three, declaring the control state as ‘normal’).
The behavior of transitions between control states is de-
ﬁned by a set of guards. The conditions at the transitions rep-
resent source-code guards and state-space guards. A source-
code guard is used by the validator to check if a control-ﬂow
edge of the CFA matches a control-state transition based
on the source code. Line numbers are an example of such
guards. State-space guards are used to strengthen the ab-
stract successor states that are computed by the transfer
relation of an analysis after the source-code guard matches
the transition to the next control state of the witness au-
tomaton. Assumptions like x == 0; y > 5; are examples of
such guards. A summary of the guards that we use for our
experiments is given in Sect. 7.1.
4.2 Format Implementation
This section provides guidance towards robust implementa-
tions for writing and reading error witnesses, describes some
4http://sosy-lab.org/ ∼dbeyer/verification-witnesses/
726best practices, and presents how common real-world issues
with exchanging (error) witnesses across diﬀerent veriﬁers
can be addressed.
Writing a Witness Automaton from an ARG. A veriﬁ-
cation tool can produce witnesses by transforming the desired
parts of the abstract reachability graph (ARG) [9] (which is
often available from an analysis) into a witness automaton.
The nodes along an error path in the ARG become control
states in the witness automaton. The initial control state q0
of the witness automaton corresponds to the root node of
the ARG. For every ARG node that violates the speciﬁca-
tion, we add a corresponding accepting (error) control state.
The edges of the ARG become transitions in the witness
automaton. Edges that leave the error path in the ARG
become transitions to a sink state, i.e., a state with no out-
going transitions. Based on the desired level of abstraction,
we add source-code guards to the transitions. Those can
be based, for example, on the line number, character oﬀset,
and branching (control case) information of the ARG edge.
Constraints on variable values at the target state of an ARG
edge may be encoded as state-space guards. After producing
the witness automaton from the ARG, we perform several
minimizations: for example, we remove transitions without
any guard, and reduce sequences of similar transitions, i.e.,
given a sequence of transitions with the same set of guards,
we often leave only one of those transitions in the automaton.
Reading a Witness Automaton for Validation. An
error-witness validator reconstructs the witness automaton
that is stored in our exchange format. For every node in the
witness ﬁle, there is a state in the witness automaton. For
every edge in the witness ﬁle, there is a transition in the wit-
ness automaton, guarded by, for example, information about
line numbers, branchings, and assumptions from the data
tags. We add an unguarded self-transition to each accepting
(error) state in order to express that given a program path t,
for any preﬁx t′oftthat causes the automaton to switch to
an error state, tis also an accepted error path. To states
that are neither sink nor accepting (error) state, we also
add a self-transition that is guarded by the negation of the
disjunction of the source-code guards of all other outgoing
transitions of this control state, such that it matches if no
other outgoing transition matches. We label these transi-
tions with“ o/w”. This is done in order to address diﬀerences
in program representations between veriﬁers, which we will
discuss in more detail below. After the witness validator has
reconstructed the witness automaton, it is able to apply the
concepts described in Sect. 3 to validate the witness.
Addressing Diﬀerences in Program Representations
Between Veriﬁers by Stuttering. The ANSI C standard
speciﬁes that it is not required to evaluate all parts of an
expression if some parts are suﬃcient to determine its out-
come. This has to be considered during witness validation.
Therefore, in addition to the transitions that are explicitly
deﬁned in the error witness, control states that are neither
sink control state nor accepting control state have the transi-
tion“o/w”to itself. This self-transition is required in all cases
where the veriﬁer that produced the witness skipped parts
of the code, either due to simpliﬁcations or optimizations
in the front-end of the veriﬁer, or simply due to a higher
level of abstraction than applied by the witness validator.
For instance, the witness automaton might not contain any
information about a block of C code that is unreachable. We
consider imposing rules about what to include in witnessesand what can safely be omitted to be too restrictive and
a barrier to applying front-end optimizations. Therefore,
the witness automaton is allowed to stutter until the actual
analysis catches up in its exploration. On the other hand,
this implies that a witness validator must use an internal
representation of the program that is at least as ﬁne-grained
and complete as the witnesses. Another eﬀect of this solutio n
is that the end of a path must be explicitly marked as a sink
control state by the witness writer if the state-space guards
are not strong enough to contradict the abstract state of
the witness validator: otherwise, the state-space reduction
may not be as eﬀective, because the witness validator has to
consider all remaining branches as well.
Handling Ambiguity. In some cases, the source-code
matching information at a transition might be ambiguous.
One line might contain several statements:
1int c = 0;
2int x = 1; ++x; ++x;
3if (c == 0) { ERROR: exit(1); }
A witness automaton might have the assumption x==3after
a match of line 2, because it is valid after the third statement
in line 2. An analysis that would require the truth of x==3
after the ﬁrst statement (ﬁrst match) of line 2 could termi-
nate the analysis since the path formula x= 1∧x= 3 is
unsatisﬁable. These cases can be identiﬁed by considering the
direct successor edges in the CFA (lookahead). For a given
witness transition with source-code guards, an additional
transition from the source control state back to itself is intro-
duced. This transition is guarded by the same source-code
guard and additionally by the condition that two successive
CFA edges (hence the lookahead) match these guards. If
this case is encountered during the analysis, the transitions
provide a non-deterministic choice between proceeding to
the next control state or staying in the current control state.
The downside of this approach is that the non-determinism
inﬂates the state space. However, a smart witness valida-
tor may detect cases where there is no semantic diﬀerence
between the choices. The witness validator then makes a
choice, thus avoiding the state-space inﬂation. For exampl e,
if the one-line sequence int x = 0, n = nondet(); is en-
countered, it does not matter which of the two declarations
an assumption about variable xis applied to, because the
initialization of ndoes not change the value of x. In the
given example, the ambiguity can also be resolved by the
witness writer by providing an exact oﬀset value.
Imprecise Witnesses. A veriﬁer that runs an analysis
with a coarse precision might not be able to choose a speciﬁc
path to the error location that is feasible in the concrete
program. Instead of choosing an arbitrary path, we produce
an automaton that describes several paths, assuming that one
of these paths is feasible in the concrete program. A witness
validator can therefore produce a reﬁned version of the error
witness that describes a smaller number of paths.
Best Practices. Diﬀerent veriﬁers use diﬀerent internal
representations of programs. An exchange of error witnesses
across veriﬁers is only possible if the witness automata —
especially their transitions— refer to program fragments that
can be identiﬁed by all veriﬁers in the testiﬁcation chain.
Therefore, we recommend brevity for witness production:
Instead of creating several transitions about the same pro-
gram operation, the veriﬁer should try to merge them into a
single transition. Conversely, a witness validator must not
prune parts of the source code that might be referenced by a
727witness. Due to these requirements for witness validators, it
is arguably more diﬃcult to implement a witness validator
than a veriﬁer that only writes witnesses, but we consider
this to be an acceptable trade-oﬀ for the ﬂexibility that is
gained by enabling a veriﬁer to reﬁne and improve upon the
results of other tools.
Open Problems. There are several open problems that we
do not yet address in the current error-witness exchange for-
mat. Our format does not deﬁne a means to specify context
switches, so it is currently not possible to express witnesses
to speciﬁcation violations that depend on concurrency. A
counterexample to termination, or more general, a counterex-
ample to a liveness property, is not a ﬁnite execution. Yet,
we can use witness automata to narrow down a program
to a set of inﬁnite paths that contains an inﬁnite execution.
However, the current syntax does not allow to distinguish
loops that may be executed inﬁnitely often and loops that
may be executed for an arbitrary but ﬁnite number of times.
5. EXPERIMENTAL EV ALUATION
To demonstrate the eﬀectiveness and eﬃciency of error-
witness validation, we performed a large number of diﬀerent
experiments. The experimental work ﬂow consists of instruct-
ing the veriﬁer (1) to produce an error witness and (2) to
validate an error witness.
Experiment Goals. We perform a feasibility study to sup-
port the following claims:
Claim 1: We developed an error-witness format that is
machine-readable and can be used to exchange witnesses
for bugs in C programs between diﬀerent veriﬁers.
Claim 2: Witness validation can take considerably less ef-
fort than veriﬁcation, i.e., the witness successfully guides
the veriﬁer through a considerably smaller state space.
Claim 3: A high-precision witness validator may improve
the overall eﬀectiveness if an eﬃcient but low-precision
veriﬁer produces witnesses and the validator rejects a
substantial number of incorrect witnesses.
The witness validator is only applied to a veriﬁcation
task (a program and its speciﬁcation) if the previous veriﬁca-
tion step produced a witness. An error witness may describe
only a subset of the (possibly inﬁnite) paths that violate th e
speciﬁcation; rejecting an error witness does therefore not
imply that the veriﬁcation task satisﬁes the speciﬁcation, b ut
only that the given error witness does not encode a violating
path. Therefore, in our experiments that are restricted to
errorwitnesses, the result of witness validation is to be in-
terpreted as follows: falsemeanswitness conﬁrmed ;true
meanswitness rejected , i.e., the part of the program that the
witness describes does not violate the speciﬁcation.
Benchmark Set. Our benchmark is composed of the
3964 veriﬁcation tasks from all categories of SV-COMP
2015 [5] except Arrays,BitVectors ,Concurrency ,Floats,
MemorySafety ,Termination , andRecursive , which are not
supported by one or both of the evaluated veriﬁers. A total
of 1148 of these tasks contain known speciﬁcation violation s.
Experimental Setup. All experiments were conducted on
machines with two 2.6GHz 8-Core CPUs (Intel Xeon E5-
2650 v2) with 135GB of RAM. The operating system was
Ubuntu 14.04 (64 bit), using Linux 3.13 and OpenJDK 1.7.
Each veriﬁcation task was limited to two CPU cores, a CPU
runtimeof15minandamemoryusageof15GB. CPAchecker
was used in revision 17283 from the trunk, with MathSAT5as SMT solver. CPAchecker was conﬁgured to perform a
predicate analysis, using the theory of linear arithmetic over
integers and uninterpreted functions. Ultimate Automizer
was used in revision 14553 from the trunk and used its SV-
COMP’15 conﬁguration with Z3as SMT solver. The bench-
marks were executed using BenchExec [17] in version 0.5.
Presentation and Availability. The results, tools, and ver-
iﬁcation tasks that we used in our evaluation are available on
our supplementary web page.4All reported times (CPU time)
are rounded to two signiﬁcant digits. For veriﬁcation runs
where the veriﬁer claims to have found a bug, we distinguish
between expected alarms, which are alarms for programs
with a known speciﬁcation violation, and unexpected alarms,
which are alarms for programs without known speciﬁcation
violations. Unexpected alarms may occur if, due to a lack
of precision, a veriﬁer reports an infeasible error path. An
expected alarm can still be a false alarm, if the witness is
incorrect, i.e., it does not describe a feasible error path. Our
knowledge about existing violations is based on the verdicts
of the SV-COMP community.5
Claim 1: Witness Validation Across Veriﬁers. Our
ﬁrst experiment represents a feasibility study showing that
we were able to implement a witness exchange format for
bugs in C programs for two diﬀerent veriﬁers, CPAchecker
andUltimate Automizer , which both can take the roles of a
veriﬁer (producing witnesses) and a witness validator.
Results. We produced error witnesses with CPAchecker and
Automizer , and then used them as input for both veriﬁers,
so that each veriﬁer had to validate its own witnesses, and
the witnesses of the other veriﬁer. In total, CPAchecker
produced 634 witnesses, 38 of which are considered to be
unexpected alarms, and Automizer produced 309 witnesses,
15 of which are considered to be unexpected alarms.
Validation Times. Figure 5a displays the results for validating
witnesses produced by CPAchecker withCPAchecker itself
and shows that validating the witnesses is at least as fast,
and often much faster, than producing the witnesses. This
conﬁrms our expectations and matches the results of ear-
lier work [18], where an internal, non-exchangeable witness
format was used. The same trend is observable in Fig. 5b,
which displays the results for cross-validating witnesses pro-
duced by Automizer withCPAchecker , and in Fig. 5c, which
displays the results for validating witnesses produced by Au-
tomizerwithAutomizer itself. We also note that Automizer
has a slightly higher start-up time (about 6 seconds) than
CPAchecker (about3seconds)beforeanyresultsarereturned.
Figure 5d displays the results for cross-validating witnesses
produced by CPAchecker withAutomizer . Due to the diﬀer-
ent start-up times observed above, there are some veriﬁcation
tasks where validating the witnesses with CPAchecker was
quicker than validating them with Automizer , but the trend
of witness validation often being faster than veriﬁcation is
observable here, too.
Acceptance and Rejection Rates. Inordertoshowthatthever-
iﬁers actually use and check the witnesses provided to them,
a closer inspection of the witness acceptance and rejection
rates is required. Table 1 shows the total amounts of accepted
and rejected witnesses for each of the four combinations.
Runs where the witness validation timed out are counted as
rejections. The high rate of accepted expected alarms across
veriﬁers, 69% and 70%, respectively, conﬁrms the earlier
5https://github.com/dbeyer/sv-benchmarks
728 2 20 200
 2  20  200
(a)CPAchecker /CPAchecker 2 20 200
 2  20  200
(b)Automizer /CPAchecker 2 20 200
 2  20  200
(c)Automizer /Automizer 2 20 200
 2  20  200
(d)CPAchecker /Automizer
Figure 5: Scatter plots for pairwise composition for witness validation : CPU seconds for producing a witness on the x axis,
CPU seconds for witness validation on the y axis. A caption“ p/c”abbreviates“witnesses produced by pthat are accepted by c”
Table 1: Accepted and Rejected Witnesses
Validator CPAchecker Automizer
Producer CPAchecker Automizer CPAchecker Automizer
Accepted 615 205 419 305
Rejected 19 104 215 4
Expected alarms only:
Accepted 585 204 418 291
Rejected 11 90 178 3
Accept. rate 98% 69% 70% 99%
Unexpected alarms only:
Accepted 30 1 1 14
Rejected 8 14 37 1
Reject. rate 21% 93% 97% 7%
observation that the tools understand each other’s witnesses.
The high rejection rates of 93% and 97% for the unexpected
alarms across the tools, on the other hand, conﬁrm that
our approach is suitable for increasing the conﬁdence in
counterexamples. It is also important to notice that not all
expected alarms are in fact accompanied by correct witnesses.
A veriﬁer may produce an incorrect witness that does not
describe a feasible error path while missing the actual bug.
For example, CPAchecker produces a witness for the ver-
iﬁcation task elevator_spec3_product31_false-unreach-
call.cil.c , butAutomizer rejects this witness. Manual
inspection reveals that the witness contains a sequence where
the value 200 is assumed for a variable __cil_tmp4 in line
3673 of the veriﬁcation task, followed by assuming the value 0
for the result of the expression __cil_tmp4 / 3 , in line 3675
of the veriﬁcation task, an error caused by a technical lim-
itation of the chosen SMT conﬁguration. The rejection of
the described path is therefore justiﬁed and desirable. For
validating their own witnesses, both the high rate of accepte d
expected alarms (98% and 99%) and the low rate of rejected
unexpected alarms (21% and 7%) is to be expected, be-
cause both the veriﬁcation run and the witness validation are
equally (im)precise, and thus veriﬁers will repeat the same
mistakes they made when producing the witnesses.
Claim 2: State-Space Reduction. In order to support
the claim that the guidance provided by witnesses is able to
signiﬁcantly reduce the state space that has to be explored
by the validator, we compare the code coverage between
producing witnesses and validating those witnesses as an
approximate indicator of the explored state space. The term
code coverage in this section refers to the code that is visited 0 0.2 0.4 0.6 0.8 1
 0  0.2  0.4  0.6  0.8  1
(a)Line Coverage 0 0.2 0.4 0.6 0.8 1
 0  0.2  0.4  0.6  0.8  1
(b)Condition Coverage
Figure 6: Scatter plots that illustrate a reduction of the
code coverage with values for the veriﬁcation runs on the x
axes and values for the witness-validation runs on the y axes
by the veriﬁer in order to determine the veriﬁcation result.
Another indicator that could be used would be the amount
of states in the abstract reachability graphs, however, this
measure would not be comparable across diﬀerent abstract
domains, and even though we used the same abstract domain
forbothconﬁgurationsinourcomparison, wewantourresults
to be comparable to future experiments. For this experiment,
we chose the predicate analysis of CPAchecker . We applied
two code-coverage measures: line coverage, which counts
each visited line once, and condition coverage, which counts
each visited case of each boolean sub-expression once.
Results. Figure 6a illustrates that the line coverage of the
witness-validation run never exceeds and is often signiﬁcant ly
lower than during the initial veriﬁcation run. Figure 6b shows
the same trend for condition coverage, but with an even more
extreme reduction of coverage during witness validation in
comparison to the initial veriﬁcation run. Condition coverage
is a better indicator for the reduction of the number of
explored program paths.
Claim 3: Witnesses Improve Eﬀectiveness and Eﬃ-
ciency. One of our claims is that for many veriﬁcation
tasks, it is faster to use a quick, low-precision veriﬁcation
followed by a high-precision witness validation (thereby ob-
taining high-precision conﬁdence in the counterexamples),
than to use the slow, high-precision veriﬁcation exclusively .
To support this claim, we selected the DeviceDrivers bench-
mark set of SV-COMP’15, which contains 1650 veriﬁcation
tasks, 203 of which contain a known speciﬁcation violation.
We used two diﬀerent predicate-analysis conﬁgurations of
CPAchecker , one using linear arithmetic ( LA) and one using
bit-precise arithmetic ( BP). We used both conﬁgurations to
validate the witnesses produced by LA.
729 10 100 1000
 0  200  400  600  800  1000  1200CPU time (s)BP
LA followed by BP witness validation and a BP rerun
Figure 7: Quantile plot showing that LAfollowed by a BP
witness validation and rerunning BPon rejections is more
eﬃcient and eﬀective than just running BP
Results. We made the following observations:
1.BPproduces 1128 expected proofs, while LAproduces
1164 expected proofs. The diﬀerence of 36 results is
because the bit-precise conﬁguration BPtimes out on tasks
for which LAis quick enough to provide a proof.
2.BPproduces 59 expected alarms for programs with known
speciﬁcation violations, and 10 unexpected alarms for
programs without a known violation, whereas LAproduces
77 expected alarms and 14 unexpected alarms (91 in total).
The conﬁdence in the alarms reported by LAis initially
restricted to the limitations of linear arithmetics.
3.50 of the 91 witnesses produced by LAwere conﬁrmed by a
BPvalidation. The conﬁdence in these remaining witnesses
is thus strengthened by the bit-precise analysis. Among
the 41 rejected witnesses were 11 of the 14 unexpected
alarms. 3 witnesses for tasks where both conﬁgurations
produced unexpected alarms were conﬁrmed by BP.
4.The sum of CPU time required to verify the tasks with
conﬁrmed witnesses with LAand conﬁrming those wit-
nesses with BPamounts to 0.74h, while verifying the same
veriﬁcation tasks with BPtakes 3.1h.
5.If we sum the CPU time of all tasks with LA-veriﬁcation
andBP-validation and add the sum of CPU time used
byBPto verify those tasks from scratch for which the
LA-witness was rejected by BP(which is 4.2h), we obtain a
total CPU time of 53h. This is 9h less than the total CPU
time for verifying all tasks with BP(62h), even though we
now have 1164 expected proofs as well as 66 witnesses in
which we have bit-precise conﬁdence, only 3 of which are
unexpected alarms (50 from LAwhich were conﬁrmed by
BPand 16 from consecutively running BPon the tasks for
which the witness was rejected). This eﬀect is visualized
in the quantile plot in Fig. 7. We know that the BPrerun
could also solve another 9 tasks, however, the sum of the
CPU time for running LA, validating the witnesses, and
rerunning BPwould exceed the time limit in these cases.
In summary, we observe that for this set of veriﬁcation
tasks, using plain bit-precise predicate analysis for veriﬁca-
tion is slower than verifying the tasks with predicate analysis
with linear arithmetics ( LA) followed by witness validation
with a bit-precise predicate analysis ( BP), while both provide
the same bit-precise conﬁdence in the counterexamples. At
the same time, the eﬃciency of the predicate analysis with
linear arithmetics allows to produce more proofs before the
timeout than the bit-precise predicate analysis. Therefore,
we propose a workﬂow where the tasks are ﬁrst veriﬁed by
LA, the witnesses of LAare validated by BP, and tasks for
which the witnesses were rejected are veriﬁed by BP.
As a sanity check, we also validated the witnesses produced
byLAwithLA. As expected, almost all of the witnesses areconﬁrmed, so we are conﬁdent that the increased precision of
theBPwitness validation is really the cause of the observed
witness rejections, and that the witnesses conﬁrmed by BP
are valid even with bit-precise semantics, even though they
were produced by an analysis restricted to linear arithmetics.
Validity. We chose the DeviceDrivers benchmark set for this
experiment, because it contains real-world C code, and, con-
trary to some of the other SV-COMP’15 benchmark subsets,
it contains many programs that are large in terms of lines of
code and use a wide variety of the programming-language
features, such as structs, pointers, pointer arithmetics, and
arrays. For veriﬁcation tasks from other sets that are not
as complex, we observed that the bit precise analysis of-
ten performs as well as the predicate analysis using linear
arithmetics. In our experiment, the goal was to show that
witnesses can be used to improve the results for cases where
the more precise analysis is too slow, so it would be invalid
to include tasks where this premise does not hold.
6. CONCLUSION
If the goal is as ambitious as verifying large software sys-
tems, it is required to combine the strengths of diﬀerent
veriﬁcation techniques and as a precondition, unify their
results and make them exchangeable. The objective of our
work was to close the gap of a missing exchange format for
error witnesses and to establish witness validation as part
of the veriﬁcation and validation process. It is important to
have such a format in the veriﬁcation community, in order to
eliminate false alarms by witness validation, and in order to
leverage the potential of combining diﬀerent veriﬁcation tools :
Once a veriﬁer outputs its error witness in the exchangeable
format, no extra implementation work is necessary for wit-
ness validation; the witness can be given directly as input to
an oﬀ-the-shelf external witness validator (we provide two
open-source implementations). Our experience shows that it
is feasible to support such a format, despite the diﬀerences in
the internal representation of the control-ﬂow of programs.
Stepwise testiﬁcation goes one step beyond witness vali-
dation: Thanks to exchangeable error witnesses, it is easy
to design veriﬁcation and validation processes where vari-
ous tools can interact, complementing and enriching each
other. Our experiments reveal that it is worthwhile to chain
testiﬁers that produce increasingly more restricted witnesses.
We performed an extensive experimental evaluation to
show that (1) the proposed error-witness exchange format
is ﬂexible enough to enable the combination of two very dif-
ferent veriﬁcation tools, (2) witnesses eﬀectively reduce the
state space that a validator needs to explore, and (3) witness
validation is on average signiﬁcantly faster than veriﬁcation
without the guidance of a witness, and witness validation ca n
conﬁrm and accept witnesses with reasonably good accep-
tance and rejection rates. Considering that this is the initial
study on witness validation, the results look very promising
to continue in this direction. Evidence of the success of
witness validation was also given by its application in the
last edition of the competition SV-COMP 2015.
Acknowledgments. We thank Marek Trt´ ık and Michael
Tautschnig for the discussions on a preliminary version of the
witness format and the participants of SV-COMP 2015 for
supporting error witnesses and providing valuable feedback.
We thank the reviewers for their comments to improve the
experimental evidence and presentation of our contributions.
7307. APPENDIX: REPLICATION PACKAGE
This paper comes with a replication package, which has
been successfully evaluated by the Replication Packages Eval-
uation Committee . Our supplementary web page4provides
all experimental data, and a virtual machine that contains
our implementations and has been prepared such that our re-
sults can be replicated easily. In this section, we will give a n
overview over our provided reference implementations, such
that the reader may understand our approach and derive an
own implementation of our concepts. Further details on how
to replicate our experiments inside or outside of our virtual
machine can be found on the supplementary web page.4
7.1 Implemented Guards
In our experiments, we used several of the source-code and
state-space guards that are mentioned in Sect. 4.1. The most
important ones are listed below.
Source-Code Guards. The guards startline andendline
are source-code guards that map a transition to lines in the
program. Valid values are integer numbers that correspond
to actual line numbers in the original program. A transi-
tion matches if the observed analysis takes a control-ﬂow
edge that starts at the given startline and, if applicable,
ends at the optionally given endline. We strongly recom-
mendstartline as a baseline to be supported by all imple-
mentations, such that veriﬁers (testiﬁers) can rely on their
witnesses being consumable by a wide range of witness val-
idators. Program line numbers are an established concept
in computer science that programmers are familiar with:
there is tool support for navigation based on line numbers
in development environments, debuggers, and editors. The
source-code guard control is used to distinguish between
diﬀerent branches in the program. Valid values for this guard
arecondition-true andcondition-false , where for a con-
ditional branching in the original program, condition-true
refers to the then-branch and condition-false to the else-
branch. The transition matches if the observed analysis takes
a control-ﬂow edge that represents the speciﬁed branch of a
branching edge, but not its counterpart.
State-Space Guards. The guard assumption is the only
state-space guard that we used so far. Valid values for this
guard are expressions of the input programming language,
such asx == 0; y > 5; . The variables used in these assump-
tions must appear in the original program code (auxiliary
variables that veriﬁers use internally are not allowed to ap-
pear in these expressions). Local variables that have the
same name as global variables or local variables of other
functions can be qualiﬁed by using a tag with the key as-
sumption.scope (see below). After the witness automaton
takes a transition with an assumption guard, the assump-
tions can be used by the analysis to reduce (strengthen) the
state space. By using the syntax of the input programming
language for expressing the assumptions, parsing the expres-
sions becomes an easy task for a witness validator; the same
parser that was already used to parse the program can be
reused. With this decision, we follow the examples of the
ANSI/ISO C Speciﬁcation Language6and the BlastQuery
Language [7]. The witness validator must map the variables
in the given assumptions to the variables in the program.
Due to scopes, there may be name conﬂicts. We propose to
explicitly state the variable scope along with the assumption ;
6http://frama-c.com/download/acsl_1.8.pdftherefore we use the key assumption.scope . Valid values for
tags with this key are names of functions that are deﬁned
in the program. The witness validator will ﬁrst look for a
variable with a matching name in the scope of the provided
function name before checking the global scope. The value
of a data tag with this key applies to the assumption as a
whole. It is not possible to specify assumptions about local
variables of diﬀerent functions.
7.2 Witnesses in CPAchecker
InCPAchecker , the successor of a witness control state for
a given CFA edge is computed by matching the source-code
guards of the transitions against the CFA edge as described
earlier, such that there is one successor control state for
every transition that matches the CFA edge. During the
strengthening phase of the conﬁgurable program analysis
(CPA), the other component program analyses that run in
composition with the witness CPA may strengthen their in-
formation based on the state-space guards of the transition.
This strengthening from witness assumptions is currently
implemented for the value analysis and the predicate analy-
sis. For the value analysis, we conjunct the abstract state
with concrete variable values (the new values were previ-
ously unknown, or contradict the value analysis state and
thus make the abstract state unreachable, which results in
reducing the state-space that has to be explored). For the
predicate analysis, the assumption is conjuncted to the path
formula. For more information on these analyses and their
implementation within CPAchecker , we refer to our previous
work [15,16].
7.3 Witnesses in Ultimate Automizer
The validation of witnesses in Ultimate Automizer is done
in two steps. In the ﬁrst step, a new CFA is constructed.
The paths of this CFA represent the paths of the original
CFA that comply with the source-code guards of the witness
automaton: the new CFA is constructed as a product of
the original CFA and the witness automaton. The nodes
of this product are pairs ( l,q), wherelis a location of the
CFA andqis a control state of the witness automaton. The
product contains an edge from ( l,q) to (l′,q′) labeled with op
if (l,op,l′) is a CFA edge and
1.qσ− →q′is a transition in the witness automaton such that
the CFA edge ( l,op,l′) is one of the edges that is repre-
sented byσ,
2. there is an epsilon transition from qtoq′, or
3. the states qandq′coincide (implicit stuttering edge).
Note that in the current implementation, the state-space
guards and the source-code guard control of the witness are
ignored.
In the second step, Ultimate Automizer veriﬁes if the re-
sulting CFA satisﬁes the speciﬁcation using an automata-
theoretic veriﬁcation approach [35]. The witness is conﬁrmed
if a violation of the speciﬁcation is found.
When writing a witness automaton, Ultimate Automizer
produces the source-code guards startline ,endline, and
control, as well as the state-space guard assumption . The
production of a witness is straightforward, because Ultimate
Automizer already computes the necessary information in
order to provide human-readable counter-examples.
7318. REFERENCES
[1] L. Alawneh and A. Hamou-Lhadj. MTF: A scalable
exchange format for traces of high performance
computing systems. In Proc. ICPC , pages 181–184.
IEEE, 2011.
[2] T. Ball and S. K. Rajamani. The Slamproject:
Debugging system software via static analysis. In Proc.
POPL, pages 1–3. ACM, 2002.
[3] T. Ball and S. K. Rajamani. SLIC: A speciﬁcation
language for interface checking (of C). Technical Report
MSR-TR-2001-21, Microsoft Research, 2002.
[4] D. Beyer. Status report on software veriﬁcation. In
Proc. TACAS , LNCS 8413, pages 373–388. Springer,
2014.
[5]D. Beyer. Software veriﬁcation and veriﬁable witnesses
(Report on SV-COMP 2015). In Proc. TACAS ,
LNCS 9035, pages 401–416. Springer, 2015.
[6] D. Beyer, A. J. Chlipala, T. A. Henzinger, R. Jhala,
and R. Majumdar. Generating tests from
counterexamples. In Proc. ICSE , pages 326–335. IEEE,
2004.
[7] D. Beyer, A. J. Chlipala, T. A. Henzinger, R. Jhala,
and R. Majumdar. The Blastquery language for
software veriﬁcation. In Proc. SAS , LNCS 3148, pages
2–18. Springer, 2004.
[8] D. Beyer, A. Cimatti, A. Griggio, M. E. Keremoglu,
and R. Sebastiani. Software model checking via
large-block encoding. In Proc. FMCAD , pages 25–32.
IEEE, 2009.
[9]D. Beyer, T. A. Henzinger, R. Jhala, and R. Majumdar.
The software model checker Blast.Int. J. Softw. Tools
Technol. Transfer , 9(5-6):505–525, 2007.
[10] D. Beyer, T. A. Henzinger, M. E. Keremoglu, and
P. Wendler. Conditional model checking: A technique
to pass information between veriﬁers. In Proc. FSE .
ACM, 2012.
[11] D. Beyer, T. A. Henzinger, R. Majumdar, and
A. Rybalchenko. Path invariants. In Proc. PLDI , pages
300–309. ACM, 2007.
[12] D. Beyer, T. A. Henzinger, and G. Th´ eoduloz.
Conﬁgurable software veriﬁcation: Concretizing the
convergence of model checking and program analysis. In
Proc. CAV , LNCS 4590, pages 504–518. Springer, 2007.
[13] D. Beyer, A. Holzer, M. Tautschnig, and H. Veith.
Information reuse for multi-goal reachability analyses.
InProc. ESOP , LNCS 7792, pages 472–491. Springer,
2013.
[14]D. Beyer and M. E. Keremoglu. CPAchecker : A tool
for conﬁgurable software veriﬁcation. In Proc. CAV ,
LNCS 6806, pages 184–190. Springer, 2011.
[15]D. Beyer, M. E. Keremoglu, and P. Wendler. Predicate
abstraction with adjustable-block encoding. In Proc.
FMCAD , pages 189–197. FMCAD, 2010.
[16] D. Beyer and S. L ¨owe. Explicit-state software model
checking based on CEGAR and interpolation. In Proc.
FASE, LNCS 7793, pages 146–162. Springer, 2013.
[17]D. Beyer, S. L ¨owe, and P. Wendler. Benchmarking and
resource measurement. In Proc. SPIN , LNCS 9232.
Springer, 2015.
[18] D. Beyer and P. Wendler. Reuse of veriﬁcation results:
Conditional model checking, precision reuse, andveriﬁcation witnesses. In Proc. SPIN , LNCS 7976,
pages 1–17. Springer, 2013.
[19] U. Brandes, M. Eiglsperger, I. Herman, M. Himsolt,
and M. S. Marshall. GraphML progress report. In
Graph Drawing , LNCS 2265, pages 501–512. Springer,
2001.
[20]S. Chaki, E. M. Clarke, A. Groce, S. Jha, and H. Veith.
Modular veriﬁcation of software components in C.
IEEE Trans. Softw. Eng. , 30(6):388–402, 2004.
[21] E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and
H. Veith. Counterexample-guided abstraction
reﬁnement for symbolic model checking. J. ACM,
50(5):752–794, 2003.
[22]E. M. Clarke, T. A. Henzinger, and H. Veith. Handbook
of Model Checking . Springer.
[23] E. M. Clarke, M. Talupur, H. Veith, and D. Wang.
SAT-based predicate abstraction for hardware
veriﬁcation. In Proc. SAT , LNCS 2919, pages 78–92.
Springer, 2003.
[24] E. M. Clarke and H. Veith. Counterexamples revisited:
Principles, algorithms, applications. In Veriﬁcation:
Theory and Practice, Essays Dedicated to Zohar Manna
on the Occasion of His 64th Birthday , LNCS 2772,
pages 208–224. Springer, 2003.
[25] H. Cleve and A. Zeller. Locating causes of program
failures. In Proc. ICSE , pages 342–351. ACM, 2005.
[26]L. Correnson and J. Signoles. Combining analyses for C
program veriﬁcation. In Proc. FMICS , LNCS 7437,
pages 108–130. Springer, 2012.
[27] P. Cousot and R. Cousot. Static determination of
dynamic properties of programs. In Proc. Int. Symp. on
Programming , pages 106–130. Dunod, 1976.
[28] P. Cousot and R. Cousot. Systematic design of
program-analysis frameworks. In Proc. POPL , pages
269–282. ACM, 1979.
[29] D. Dams and K. S. Namjoshi. Orion: High-precision
methods for static error analysis of C and C++
programs. In Proc. FMCO , LNCS 4111, pages 138–160.
Springer, 2005.
[30] M. Dangl, S. L ¨owe, and P. Wendler. CPAchecker
with support for recursive programs and ﬂoating-point
arithmetic. In Proc. TACAS , LNCS 9035, pages
423–425. Springer, 2015.
[31] S. Graf and H. Sa ¨ıdi. Construction of abstract state
graphs with Pvs. InProc. CAV , LNCS 1254, pages
72–83. Springer, 1997.
[32] A. Groce, S. Chaki, D. Kr ¨oning, and O. Strichman.
Error explanation with distance metrics. STTT,
8(3):229–247, 2006.
[33]A. Groce and W. Visser. What went wrong: Explaining
counterexamples. In Proc. SPIN , LNCS 2648, pages
121–135. Springer, 2003.
[34] M. Heizmann, D. Dietsch, J. Leike, B. Musa, and
A. Podelski. Ultimate Automizer with array
interpolation. In Proc. TACAS , LNCS 9035, pages
455–457. Springer, 2015.
[35] M. Heizmann, J. Hoenicke, and A. Podelski. Software
model checking for people who love automata. In Proc.
CAV, LNCS 8044, pages 36–52. Springer, 2013.
[36]T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre.
Lazy abstraction. In Proc. POPL , pages 58–70. ACM,
2002.
732[37] A. Kn ¨upfer, R. Brendel, H. Brunst, H. Mix, and W. E.
Nagel. Introducing the open trace format (OTF). In
Proc. ICCS , LNCS 3992, pages 526–533. Springer, 2006.
[38] D. Kr ¨oning and N. Sharygina. Formal veriﬁcation of
SystemC by automatic hardware/software partitioning.
InProc. MEMOCODE , pages 101–110. IEEE, 2005.
[39]A. Leitner, M. Oriol, A. Zeller, I. Ciupa, and B. Meyer.
Eﬃcient unit test-case minimization. In Proc. ASE ,
pages 417–420. ACM, 2007.
[40] K. S. Namjoshi. Certifying model checkers. In Proc.
CAV, LNCS 2102, pages 2–13. Springer, 2001.[41] H. Rocha, R. S. Barreto, L. Cordeiro, and A. D. Neto.
Understanding programming bugs in ANSI-C software
using bounded model checking counter-examples. In
Proc. IFM , LNCS 7321, pages 128–142. Springer, 2012.
[42] F. B. Schneider. Enforceable security policies. ACM
Trans. Inf. Syst. Secur. , 3(1):30–50, 2000.
[43] O.ˇSer´ y. Enhanced property speciﬁcation and
veriﬁcation in Blast. InProc. FASE , LNCS 5503,
pages 456–469. Springer, 2009.
[44] A. Zeller. Isolating cause-eﬀect chains from computer
programs. In Proc. FSE , pages 1–10. ACM, 2002.
733