Synthesising Interprocedural Bit-Precise
Termination Proofs
Hong-Yi Chen, Cristina David, Daniel Kroening, Peter Schrammel and Bj ¬®orn Wachter
Department of Computer Science, University of Oxford, Ô¨Årst.lastname@cs.ox.ac.uk
Abstract ‚ÄîProving program termination is key to guaranteeing
absence of undesirable behaviour, such as hanging programs and
even security vulnerabilities such as denial-of-service attacks. To
make termination checks scale to large systems, interprocedural
termination analysis seems essential, which is a largely unex-
plored area of research in termination analysis, where most effort
has focussed on difÔ¨Åcult single-procedure problems. We present
a modular termination analysis for C programs using template-
based interprocedural summarisation. Our analysis combines a
context-sensitive, over-approximating forward analysis with the
inference of under-approximating preconditions for termination.
Bit-precise termination arguments are synthesised over lexico-
graphic linear ranking function templates. Our experimental
results show that our tool 2LS outperforms state-of-the-art alter-
natives, and demonstrate the clear advantage of interprocedural
reasoning over monolithic analysis in terms of efÔ¨Åciency, while
retaining comparable precision.
I. I NTRODUCTION
Termination bugs can compromise safety-critical software
systems by making them irresponsive, e.g., termination bugs
can be exploited in denial-of-service attacks [1]. Termination
guarantees are therefore instrumental for software reliability.
Termination provers, static analysis tools that aim to construct
a termination proof for a given input program, have made
tremendous progress. They enable automatic proofs for com-
plex loops that may require linear lexicographic (e.g. [2], [3])
or non-linear termination arguments (e.g. [4]) in a completely
automatic way. However, there remain major practical chal-
lenges in analysing real-world code.
First of all, as observed by [5], most approaches in the
literature are specialised to linear arithmetic over unbounded
mathematical integers. Although, unbounded arithmetic may
reÔ¨Çect the intuitively-expected program behaviour, the pro-
gram actually executes over bounded machine integers. The
semantics of C allows unsigned integers to wrap around when
they over/underÔ¨Çow. Hence, arithmetic on k-bit-wide unsigned
integers must be performed modulo- 2k. According to the C
standards, over/underÔ¨Çows of signed integers are undeÔ¨Åned
behaviour, but practically also wrap around on most architec-
tures. Thus, accurate termination analysis requires a bit-precise
analysis of program semantics. Tools must be conÔ¨Ågurable
with architectural speciÔ¨Åcations such as the width of data
types and endianness. The following examples illustrate that
termination behaviour on machine integers can be completely
different than on mathematical integers. For example, the
following code:
void foo1 ( unsigned n )ff o r(unsigned x =0; x <=n ; x + + ) ;gdoes terminate with mathematical integers, but does notter-
minate with machine integers if nequals the largest unsigned
integer. On the other hand, the following code:
void foo2 ( unsigned x )fwhile ( x>=10) x ++;g
does not terminate with mathematical integers, but terminates
with machine integers because unsigned machine integers
wrap around.
A second challenge is to make termination analysis scale to
larger programs. The yearly Software VeriÔ¨Åcation Competition
(SV-COMP) [6] includes a division in termination analysis,
which reÔ¨Çects a representative picture of the state-of-the-art.
The SV-COMP‚Äô15 termination benchmarks contain challeng-
ing termination problems on smaller programs with at most
453 instructions (average 53), contained at most 7 functions
(average 3), and 4 loops (average 1).
In this paper, we present a technique that we have suc-
cessfully run on programs that are one magnitude larger,
containing up to 5000 instructions. Larger instances require
different algorithmic techniques to scale, e.g., modular inter-
procedural analysis rather than monolithic analysis. This poses
several conceptual and practical challenges that do not arise in
monolithic termination analysers. For example, when proving
termination of a program, a possible approach is to try to
prove that all procedures in the program terminate universally ,
i.e., in any possible calling context. However, this criterion is
too optimistic, as termination of individual procedures often
depends on the calling context, i.e., procedures terminate
conditionally only in speciÔ¨Åc calling contexts.
Hence, an interprocedural analysis strategy is to verify uni-
versal program termination in a top-down manner by proving
termination of each procedure relative to its calling contexts ,
and propagating upwards which calling contexts guarantee
termination of the procedure. It is too difÔ¨Åcult to determine
these contexts precisely; analysers thus compute preconditions
for termination. A sufÔ¨Åcient precondition identiÔ¨Åes those pre-
states in which the procedure will deÔ¨Ånitely terminate, and is
thus suitable for proving termination. By contrast, a necessary
precondition identiÔ¨Åes the pre-states in which the procedure
may terminate. Its negation are those states in which the
procedure will not terminate, which is useful for proving
nontermination.
In this paper we focus on the computation of sufÔ¨Åcient pre-
conditions. Preconditions enable information reuse, and thus
scalability, as it is frequently possible to avoid repeated anal-
ysis of parts of the code base, e.g. libraries whose proceduresare called multiple times or did not undergo modiÔ¨Åcations
between successive analysis runs.
Contributions:
1) We propose an algorithm for interprocedural termination
analysis . The approach is based on a template-based static
analysis using SAT solving. It combines context-sensitive,
summary-based interprocedural analysis with the infer-
ence of preconditions for termination based on template
abstractions. We focus on non-recursive programs, which
cover a large portion of software written, especially in
domains such as embedded systems.
2) We provide an implementation of the approach in 2LS, a
static analysis tool for C programs. Our instantiation of
the algorithm uses template polyhedra and lexicographic,
linear ranking functions templates. The analysis is bit-
precise and purely relies on SAT-solving techniques.
3) We report the results of an experimental evaluation on
597 procedural SV-COMP benchmarks with in total 1.6
million lines of code that demonstrates the scalability and
applicability of the approach to programs with thousands
of lines of code.
II. P RELIMINARIES
In this section, we introduce basic notions of interprocedural
and termination analysis.
Program model and notation. We assume that programs
are given in terms of acyclic1call graphs, where individual
procedures fare given in terms of symbolic input/output
transition systems. Formally, the input/output transition system
of a procedure fis a triple (Initf;Trans f;Outf), where
Trans f(x;x0)is the transition relation; the input relation
Initf(xin;x)deÔ¨Ånes the initial states of the transition sys-
tem and relates them to the inputs xin; the output relation
Outf(x;xout)connects the transition system to the outputs
xoutof the procedure. Inputs are procedure parameters, global
variables, and memory objects that are read by f. Outputs
are return values, and potential side effects such as global
variables and memory objects written by f. Internal states x
are commonly the values of variables at the loop heads in f.
These relations are given as Ô¨Årst-order logic formulae
resulting from the logical encoding of the program semantics.
Fig. 2 shows the encoding of the two procedures in Fig. 1 into
such formulae.2The inputsxinoffare(z)and the outputs
xoutconsist of the return value denoted (rf). The transition
relation ofhencodes the loop over the internal state variables
(x;y). We may need to introduce Boolean variables gto model
the control Ô¨Çow, as shown in f. Multiple and nested loops can
be similarly encoded in Trans .
Note that we view these formulae as predicates, e.g.
Trans (x;x0), with given parameters x;x0, and mean the
substitution Trans [a=x;b=x0]when we write Trans (a;b).
1We consider non-recursive programs with multiple procedures.
2c?a:b is the conditional operator, which returns aifcevaluates to true ,
andbotherwise.1unsigned f (unsigned z )f
2 unsigned w=0;
3 i f( z>0) w=h ( z ) ;
4 return w;
5g1unsigned h (unsigned y )f
2 unsigned x ;
3 f o r( x =0; x <10; x+=y ) ;
4 return x ;
5g
Fig. 1. Example.
Init f((z);(w0; z0; g0))(w0=0^z0=z^g0)
Trans f((w; z; g );(w0; z0; g0))(g^h0((z);(w1))^
w0=(z>0?w1:w)^:g0)
Out f((w; z; g );(rf))(rf=w)^:g
Init h((y);(x0; y0))(x0=0^y0=y)
Trans h((x; y);(x0; y0))(x0=x+y^x<10^y0=y)
Out h((x; y);(rh))(rh=x^:(x<10))
Fig. 2. Encoding of Example 1.
Moreover, we write xandxwith the understanding that the
former is a vector, whereas the latter is a scalar.
Each call to a procedure hat call siteiin a procedure f
is modeled by a placeholder predicate hi(xpini;xpouti)
occurring in the formula Trans fforf. The placeholder pred-
icate ranges over intermediate variables representing its actual
input and output parameters xpiniandxpouti, respectively.
Placeholder predicates evaluate to true, which corresponds
to havocking procedure calls. In procedure fin Fig. 2, the
placeholder for the procedure call to hish0((z);(w1))with
the actual input and output parameters zandw1, respectively.
A full description of the program encoding is given in the
extended version of our paper [7].
Basic concepts. Moving on to interprocedural analysis, we
introduce formal notation for the basic concepts below:
DeÔ¨Ånition 1 (Invariants, Summaries, Calling Contexts) .For a
procedure given by (Init;Trans;Out)we deÔ¨Åne:
Aninvariant is a predicate Invsuch that:
8xin;x;x0:Init(xin;x) =)Inv(x)
^Inv(x)^Trans (x;x0) =)Inv(x0)
Given an invariant Inv, asummary is a predicate Sum
such that:
8xin;x;x0;xout:Init(xin;x)^Inv(x0)^Out(x0;xout)
=)Sum(xin;xout)
Given an invariant Inv, the calling context for a pro-
cedure call hat call site iin the given procedure is a
predicate CallCtx hisuch that
8x;x0;xpini;xpouti:
Inv(x)^Trans (x;x0) =)CallCtx hi(xpini;xpouti)
These concepts have the following roles: Invariants abstract
the behaviour of loops. Summaries abstract the behaviour of
called procedures; they are used to strengthen the placeholder
predicates. Calling contexts abstract the caller‚Äôs behaviour
w.r.t. the procedure being called. When analysing the callee,
the calling contexts are used to constrain its inputs and outputs.
In Sec. III we will illustrate these notions on the program in
Fig. 1.
Since we want to reason about termination, we need the
notions of ranking functions and preconditions for termination.DeÔ¨Ånition 2 (Ranking function) .Aranking function for a
procedure (Init;Trans;Out)with invariant Invis a function
rfrom the set of program states to a well-founded domain
such that8x;x0:Inv(x)^Trans (x;x0) =)r(x)>r(x0):
We denote by RR(x;x0)the constraints that guarantee that
ris a ranking function. The existence of a ranking function
for a procedure guarantees its universal termination.
The weakest termination precondition for a procedure de-
scribes the inputs for which it terminates. If it is true, the
procedure terminates universally; if it is false , then it does
not terminate for any input. Since the weakest precondition
is intractable to compute or even uncomputable, we under-
approximate the precondition. A sufÔ¨Åcient precondition for
termination guarantees that the program terminates for all xin
that satisfy it.
DeÔ¨Ånition 3 (Precondition for termination) .Given a proce-
dure(Init;Trans;Out), a sufÔ¨Åcient precondition for termina-
tion is a predicate Precond such that
9RR;Inv:8xin;x;x0:
Precond (xin)^Init(xin;x) =)Inv(x)
^Inv(x)^Trans (x;x0) =)Inv(x0)^RR(x;x0)
Note that false is always a trivial model for Precond , but
not a very useful one.
III. O VERVIEW OF THE APPROACH
In this section, we introduce the architecture of our interpro-
cedural termination analysis. Our analysis combines, in a non-
trivial synergistic way, the inference of invariants, summaries,
calling contexts, termination arguments, and preconditions,
which have a concise characterisation in second-order logic
(see DeÔ¨Ånitions 1, and 3). At the lowest level our approach
relies on a solver backend for second-order problems, which
is described in Sec. V.
To see how the different analysis components Ô¨Åt together,
we now go through the pseudo-code of our termination
analyser (Algorithm 1). Function analyze is given the entry
procedurefentry of the program as argument and proceeds in
two analysis phases.
Phase one is an over-approximate forward analysis, given
in subroutine analyzeForward , which recursively descends
into the call graph from the entry point fentry . Subroutine
analyzeForward infers for each procedure call in fan over-
approximating calling context CallCtxo, using procedure sum-
maries and other previously-computed information. Before
analyzing a callee, the analysis checks if the callee has already
been analysed and, whether the stored summary can be re-
used, i.e., if it is compatible with the new calling context
CallCtxo. Finally, once summaries for all callees are available,
the analysis infers loop invariants and a summary for fitself,
which are stored for later re-use by means of a join operator.
The second phase is an under-approximate backward anal-
ysis, subroutine analyzeBackward , which infers termination
preconditions. Again, we recursively descend into the call
graph. Analogous to the forward analysis, we infer for eachAlgorithm 1: analyze
1global Sumso;Invso;Precondsu;
2function analyzeForward (f;CallCtxo
f)
3 foreach procedure call hinfdo
4 CallCtxo
h=compCallCtxo(f;CallCtxo
f;h);
5 ifneedToReAnalyzeo(h;CallCtxo
h)then
6 analyzeForward (h;CallCtxo
h);
7 joino((Sumso[f];Invso[f]);compInvSumo(f;CallCtxo
f))
8function analyzeBackward (f;CallCtxu
f)
9 termConds =CallCtxu
f;
10 foreach procedure call hinfdo
11 CallCtxu
h=compCallCtxu(f;CallCtxu
f;h);
12 ifneedToReAnalyzeu(h;CallCtxu
h)then
13 analyzeBackward (h;CallCtxu
h);
14 termConds termConds^Precondsu[h];
15joinu(Precondsu[f];
compPrecondTerm (f;Invso[f];termConds );
16function analyze (fentry)
17 analyzeForward (fentry;true);
18 analyzeBackward (fentry;true);
19 return Precondsu[fentry];
procedure call in fan under-approximating calling context
CallCtxu(using under-approximate summaries, as described
in Sec. IV), and recurs only if necessary (Line 12). Finally, we
compute the under-approximating precondition for termination
(Line 15). This precondition is inferred w.r.t. the termination
conditions that have been collected: the backward calling
context (Line 9), the preconditions for termination of the
callees (Line 14), and the termination arguments for fitself
(see Sec. IV). Note that superscripts oanduin predicate
symbols indicate over- and underapproximation, respectively.
Challenges. Our algorithm uses over- and under-
approximation in a systematic way in order to address
the challenging problem of Ô¨Ånding meaningful preconditions
by a context-sensitive interprocedural termination analysis.
The precondition in DeÔ¨Ånition 3 admits the trivial so-
lution false forPrecond . How do we Ô¨Ånd a good
candidate? To this end, we ‚Äúbootstrap‚Äù the process with
a candidate precondition: a single value of xin, for
which we compute a termination argument. The key
observation is that the resulting termination argument is
typically more general, i.e., it shows termination for many
further entry states. The more general precondition is then
computed by precondition inference w.r.t. the termination
argument.
A second challenge is to compute under-approximations.
Obviously, the predicates in the deÔ¨Ånitions in Sec. II can
be over-approximated by using abstract domains such as
intervals. However, there are only few methods for under-
approximating analysis. In this work, we use a method
similar to [8] to obtain under-approximating precondi-
tions w.r.t. property p: we infer an over-approximating
precondition w.r.t. :pand negate the result. In our case,
pis the termination condition termConds .Example 1. We illustrate the algorithm on the simple example
given as Fig. 1 with the encoding in Fig. 2. fcalls a procedure
h. Procedure hterminates if and only if its argument yis
non-zero, i.e., procedure fonly terminates conditionally. The
call of his guarded by the condition z>0, which guarantees
universal termination of procedure f.
Let us assume that unsigned integers are 32 bits wide, and
we use an interval abstract domain for invariant, summary
and precondition inference, but the abstract domain with the
elementsftrue;falsegfor computing calling contexts, i.e., we
can prove that calls are unreachable. We use M:= 232 1.
Our algorithm proceeds as follows. The Ô¨Årst phase is
analyzeForward , which starts from the entry procedure f.
By descending into the call graph, we must compute an over-
approximating calling context CallCtxo
hfor procedure hfor
which no calling context has been computed before. This
calling context is true. Hence, we recursively analyse h. Given
thathdoes not contain any procedure calls, we compute the
over-approximating summary Sumo
h= (0yM^0rhM)
and invariant Invo
h= (0xM^0yM). Now, this
information can be used in order to compute Sumo
f=
(0zM^0rfM)and invariant Invo
f=true for the
entry procedure f.
The backwards analysis starts again from the entry proce-
duref. It computes an under-approximating calling context
CallCtxu
hfor procedure h, which is true, before descending
into the call graph. It then computes an under-approximating
precondition for termination Precondu
h= (1yM)or, more
precisely, an under-approximating summary whose projection
onto the input variables of his the precondition Precondu
h.
By applying this summary at the call site of hinf, we can
now compute the precondition for termination Precondu
f=
(0zM)off, which proves universal termination of f.
We illustrate the effect of the choice of the abstract domain
on the analysis of the example program. Assume we replace
theftrue;falsegdomain by the interval domain. In this
case, analyzeForward computes CallCtxo
h= (1zM^
0w1M). The calling context is computed over the actual
parameterszandw1. It is renamed to the formal parameters y
andrh(the return value) when CallCtxo
his used for constrain-
ing the pre/postconditions in the analysis of h. Subsequently,
analyzeBackward computes the precondition for termination
ofhusing the union of all calling contexts in the program.
Since hterminates unconditionally in these calling contexts,
we trivially obtain Precondu
h= (1yM), which in turn
proves universal termination of f.
IV. I NTERPROCEDURAL TERMINATION ANALYSIS
We can view Alg. 1 as solving a series of formulae
in second-order predicate logic with existentially quantiÔ¨Åed
predicates, for which we are seeking satisÔ¨Åability witnesses.3
In this section, we state the constraints we solve, including all
the side constraints arising from the interprocedural analysis.
3To be precise, we are not only looking for witness predicates but (good
approximations of) weakest or strongest predicates. Finding such biased
witnesses is a feature of our synthesis algorithms.Algorithm 2: analyze for universal termination
1global Sumso;Invso;termStatus ;
2function analyzeForward (f;CallCtxo
f)
3 foreach procedure call hinfdo
4 CallCtxo
h=compCallCtxo(f;CallCtxo
f;h);
5 ifneedToReAnalyzeo(h;CallCtxo
h)then
6 analyzeForward (h;CallCtxo
h);
7 joino((Sumso[f];Invso[f]);compInvSumo(f;CallCtxo
f))
8function analyzeBackward0(f)
9 termStatus [f] =compTermArg (f);
10 foreach procedure call hinfdo
11 ifneedToReAnalyzeu(h;CallCtxo
h)then
12 analyzeBackward0(h);
13 join(termStatus [f];termStatus [h]);
14function analyze (fentry)
15 analyzeForward (fentry;true);
16 analyzeBackward0(fentry);
17 return termStatus [fentry];
Note that this is not a formalisation exercise, but these are
precisely the formulae solved by our synthesis backend, which
is described in Section V.
A. Universal Termination
For didactical purposes, we start with a simpliÔ¨Åcation of
Algorithm 1 that is able to show universal termination (see
Algorithm 2). This variant reduces the backward analysis to
a call to compTermArg and propagating back the qualitative
result obtained: terminating, potentially non-terminating , or
non-terminating .
This section states the constraints that are solved to compute
the outcome of the functions underlined in Algorithm 2 and
establish its soundness:
compCallCtxo(Def. 4)
compInvSumo(Def. 5)
compTermArg (Lemma 3)
DeÔ¨Ånition 4 (compCallCtxo).A forward calling context
CallCtxo
hiforhiin procedure fin calling context CallCtxo
f
is a satisÔ¨Åability witness of the following formula:
9CallCtxo
hi;Invo
f:8xin;x;x0;xout;xpini;xpouti:
CallCtxo
f(xin;xout)^Summso
f=) 
Initf(xin;x) =)Invo
f(x)
^ 
Invo
f(x)^Trans f(x;x0)
=)Invo
f(x0)^(ghi)CallCtxo
hi(xpini;xpouti)
with Summso
f=V
callshjinfghj=)
Sumso[h](xpinj;xpoutj)
whereghjis the guard condition of procedure call hjin
fcapturing the branch conditions from conditionals. For
example,gh0of the procedure call to hinfin Fig. 1 is
z > 0.Sumso[h]is the currently available summary for h
(cf. global variables in Alg. 1).Lemma 1. CallCtxo
hiis over-approximating.
Proof sketch. CallCtxo
fwhenfis the entry-point procedure
istrue; also, the summaries Sumo
hjare initially assumed to
betrue, i.e. over-approximating. Hence, given that CallCtxo
f
andSummso
fare over-approximating, CallCtxo
hiis over-
approximating by the soundness of the synthesis (see Thm. 3
in Sec. V).
Example 2. Let us consider procedure fin Fig. 1. fis the
entry procedure, hence we have CallCtxo
f((z);(rf)) = true
(= (0zM^0rfM)whereM:= 232 1when using
the interval abstract domain for 32 bit integers). Then, we
instantiate Def. 4 (for procedure f) to compute CallCtxo
h0. We
assume that we have not yet computed a summary for h, thus,
Sumo
histrue. Remember that the placeholder h0((z);(w1))
evaluates to true.
9CallCtxo
h0;Invo
f:8z;w 1;w;w0;z0;g;g0;rf:
0zM^0rfM^(z>0 =)true) =) 
w=0^z0=z^g=)Invo
f((w;z;g ))
^ 
Invo
f((w;z;g ))^
g^h0((z);(w1))^w0=(z>0?w1:w)^z0=z^:g0
=)Invo
f((w0;z0;g0))^(z>0)CallCtxo
hi((z);(w1))
A solution is Invo
f=true, and CallCtxo
h0((z);(w1)) =
(1zM^0w1M).
DeÔ¨Ånition 5 (compInvSumo).A forward summary Sumo
fand
invariants Invo
ffor procedure fin calling context CallCtxo
f
are satisÔ¨Åability witnesses of the following formula:
9Sumo
f;Invo
f:8xin;x;x0;x00;xout:
CallCtxo
f(xin;xout)^Summso
f=) 
Initf(xin;x)^Invo
f(x00)^Outf(x00;xout)
=)Invo
f(x)^Sumo
f(xin;xout)
^ 
Invo
f(x)^Trans f(x;x0) =)Invo
f(x0)
Lemma 2. Sumo
fandInvo
fare over-approximating.
Proof sketch. By Lemma 1, CallCtxo
fis over-approximating.
Also, the summaries Sumso
fare initially assumed to be
true, i.e. over-approximating. Hence, given that CallCtxo
fand
Summso
fare over-approximating, Sumo
fandInvo
fare over-
approximating by the soundness of the synthesis (Thm. 3).
Example 3. Let us consider procedure hin Fig. 1. We have
computed CallCtxo
h0((y);(rh)) = (1yM^0rhM)
(with actual parameters renamed to formal ones). Then, we
need to obtain witnesses Invo
h0andSumo
h0to the satiÔ¨Åability
of the instantiation of Def. 5 (for procedure h) as given below.
9Invo
h0;Sumo
h0:8y;x;x0;y0;x00;y00;rf:
1yM^0rhM^true=) 
(x=0^y0=y)^Invo
h((x00;y00))^(rh=x00^:(x00<10)
=)Invo
h((x;y0))^Sumo
h((y);(rh))
^ 
Invo
h((x;y))^(x0=(x+y^x<10)^y=y0)
=)Invo
h((x0;y0))
A solution is Invo
h0= (0xM^1yM)andSumo
h0=
(1yM^10rhM), for instance.Remark 1. Since Def. 4 and Def. 5 are interdependent, we can
compute them iteratively until a Ô¨Åxed point is reached in order
to improve the precision of calling contexts, invariants and
summaries. However, for efÔ¨Åciency reasons, we perform only
the Ô¨Årst iteration of this (greatest) Ô¨Åxed point computation.
Lemma 3 (compTermArg ).A procedure fwith forward
invariants Invo
fterminates if there is a termination argument
RRf:
9RRf:8x;x0:
Invo
f(x)^Trans f(x;x0)^Summso
f^Assertions f(x)
=)RRf(x;x0)
Assertions in this formula correspond to assert() state-
ments in the code. They can be assumed to hold because
assertion-violating traces terminate. Over-approximating for-
ward information may lead to inclusion of spurious non-
terminating traces. For that reason, we might not Ô¨Ånd a
termination argument although the procedure is terminating.
As we essentially under-approximate the set of terminating
procedures, we will not give false positives. Regarding the
solving algorithm for this formula, we refer to Sec. V.
Example 4. Let us consider function hin Fig. 1. Assume we
have the invariant 0xM^1yM. Thus, we have to solve
9RRh: 0xM^1yM^x0=x+y^x<10^y0=y^
true^true=)RRh((x;y);(x0;y0))
When using a linear ranking function template c1x+c2y,
we obtain as solution, for example, RRh= ( x> x0).
If there is no trace from procedure entry to exit, then we can
prove non-termination, even when using over-approximations:
Lemma 4 (line 7 of analyze ).A procedure fin forward
calling context CallCtxo
f, and forward invariants Invo
fnever
terminates if its summary Sumo
fisfalse .
Termination information is then propagated in the (acyclic)
call graph ( join in line 13 in Algorithm 2):
Proposition 1. A procedure fis declared
(1)non-terminating if it is non-terminating by Lemma 4.
(2)terminating if
(a) all its procedure calls hithat are potentially reach-
able (i.e. with CallCtxo
hi6=false ) are declared termi-
nating, and
(b)fitself is terminating according to Lemma 3;
(3)potentially non-terminating , otherwise.
Our implementation is more efÔ¨Åcient than Algorithm 2
because it avoids computing a termination argument for fif
one of its callees is potentially non-terminating.
Theorem 1. If the entry procedure of a program is declared
terminating, then the program terminates universally. If the
entry procedure of a program is declared non-terminating,
then the program never terminates.
Proof sketch. By induction over the acyclic call graph using
Prop. 1.Algorithm 3: compPrecondTerm
Input : procedurefwith invariant Inv, additional termination
conditions termConds
Output : precondition Precond
1(Precond;p) (false;true);
2let'=Init(xin;x)^Inv(x);
3while true do
4  p^:Precond (xin)^';
5 solve forxin;x;x0;
6 ifUNSAT then return Precond ;
7 else
8 letinbe a model of  ;
9 letInv0=compInv (f;xin=in);
10 letRR=compTermArg (f;Inv0);
11 ifRR=true thenp p^(xin6=in);
12 else
13 let=termConds^RR ;
14 letPrecond0=:compNecPrecond (f;:);
15 Precond Precond_Precond0;
B. Preconditions for Termination
Before introducing conditional termination, we have to talk
about preconditions for termination.
If a procedure terminates conditionally like procedure hin
Fig. 1 compTermArg (Lemma 3) will not be able to Ô¨Ånd
a satisfying predicate RR. However, we would like to know
under which preconditions, i.e. values of yin above example,
the procedure terminates.
We can state this problem as deÔ¨Åned in Def. 3. In Algo-
rithm 3 we search for Precond ,Inv, andRRin an interleaved
manner. Note that false is a trivial solution for Precond ; we
thus have to aim at Ô¨Ånding a good under-approximation of the
maximal solution (weakest precondition) for Precond .
We bootstrap the process by assuming Precond =false
and search for values of xin(Line 5). If such a value in
exists, we can compute an invariant under the precondition
candidatexin=in(Line 9) and use Lemma 3 to search for
the corresponding termination argument (Line 10).
If we fail to Ô¨Ånd a termination argument ( RR=true),
we block the precondition candidate (Line 11) and restart
the bootstrapping process. Otherwise, the algorithm returns a
termination argument RR that is valid for the concrete value
inofxin. Now we need to Ô¨Ånd a sufÔ¨Åciently weak Precond
for whichRR guarantees termination. To this end, we com-
pute an over-approximating precondition for those inputs for
which we cannot guarantee termination ( :in Line 14, which
includes additional termination conditions coming from the
backward calling context and preconditions of procedure calls,
see Sec. IV-C). The negation of this precondition is an under-
approximation of those inputs for which fterminates. Finally,
we add this negated precondition to our Precond (Line 15)
before we start over the bootstrapping process to Ô¨Ånd precon-
dition candidates outside the current precondition ( :Precond )
for which we might be able to guarantee termination.
Example 5. Let us consider again function hin Fig. 1. Thistime, we will assume we have the invariant 0xM(with
M:= 232 1). We bootstrap by assuming Precond =false
and searching for values of ysatisfying true^:false^x=0^
0xM. One possibility is y= 0. We then compute
the invariant under the precondition y= 0 and getx= 0.
Obviously, we cannot Ô¨Ånd a termination argument in this case.
Hence, we start over and search for values of ysatisfying
y6= 0^:false^x=0^0xM. This formula is for instance
satisÔ¨Åed by y= 1. This time we get the invariant 0x10
and the ranking function  x. Thus, we have to solve
9e:P(y;e)^0xM^x0=x+y^x<10
):( x> x0)
to compute an over-approximating precondition over the
templateP(for details on templates see Section V). In this
case,P(y;e)turns out to be y= 0, therefore its negation
y6= 0 is the Precond that we get. Finally, we have to check
for further precondition candidates, but y6= 0^:(y6=
0)^x=0^0xMis obviously UNSAT. Hence, we return
the sufÔ¨Åcient precondition for termination y6= 0.
C. Conditional Termination
We now extend the formalisation to Algorithm 1, which
additionally requires the computation of under-approximating
calling contexts and sufÔ¨Åcient preconditions for termination
(procedure compPrecondTerm , see Alg. 3).
First, compPrecondTerm computes in line 9 an over-
approximating invariant Invo
fpentailed by the candidate pre-
condition. Invo
fpis computed through Def. 5 by conjoining
the candidate precondition to the antecedent. Then, line 10
computes the corresponding termination argument RRfby
applying Lemma 3 using Invo
fpinstead of Invo
f. Since the
termination argument is under-approximating, we are sure that
fterminates for this candidate precondition if RRf6=true.
Then, in line 14 of compPrecondTerm , we compute under-
approximating (sufÔ¨Åcient) preconditions for traces satisfying
the termination argument RR via over-approximating the
traces violating RR.
Now, we are left to specify the formulae corresponding to
the following functions:
compCallCtxu(Def. 6)
compNecPrecond (Def. 7)
We use the superscriptuto indicate negations of under-
approximating information. We compute under-approximating
calling contexts as follows:
DeÔ¨Ånition 6 (compCallCtxu).The backward calling context
CallCtxu
hifor procedure call hiin procedure fin backward
calling context CallCtxu
fand forward invariants Invo
fis
CallCtxu
hi :CallCtxu
hi, the negation of a satisÔ¨Åabilitywitnesses for:
9CallCtxu
hi;Invu
f:8xin;x;x0;xpini;xpouti;xout:
:CallCtxu
f(xin;xout)^Invo
f(x)^
Summso
f^Summsu
f^Assertions f(x) =) 
Out(x;xout) =)Invu
f(x)
^ 
Invu
f(x0)^Trans (x;x0)
=)Invu
f(x)^(ghi=)CallCtxu
hi(xpin;xpout))
withSummsu
f=V
callshjinfghj=)
:Sumu[h](xpinj;xpoutj)
Lemma 5. CallCtxu
hiis under-approximating.
Proof sketch. The computation is based on the negation of
the under-approximating calling context of fand the negated
under-approximating summaries for the function calls in f. By
Thm. 3, this leads to an over-approximation of the negation
of the calling context for hi.
Example 6. Let us assume that in procedure fin Fig. 1, we
have CallCtxu
f((z);(rf)) = (11rfM), i.e.fis called in
a context where a return value of less than 11 would cause
non-termination of the caller. Then, we instantiate Def. 6
(for procedure f) to compute CallCtxu
h0. We assume that
we have already computed the over-approximating summary
Sumo
h0= (1zM^10w1M), but not yet computed an
under-approximating summary for h, thus, Sumu
hisfalse .
9CallCtxu
h0;Invu
f:8z;w 1;w;w0;z0;g;g0;rf:
0rf10^true^
(z>0)1zM^10w1M)^(z>0)true)^true=) 
rf=w^:g=)Invu
f((w;z;g ))
^ 
Invu
f((w;z;g ))^
g^h0((z);(w1))^w0=(z>0?w1:w)^z0=z^:g0
=)Invu
f((w0;z0;g0))^(z>0)CallCtxu
hi((z);(w1))
A solution is Invu
f=true, and CallCtxu
h0= (1zM^
0w110), i.e. CallCtxu
h0= (z=0_11w1M).
DeÔ¨Ånition 7 (Line 14 of compPrecondTerm ).A precondi-
tion for termination Precondu
fin backward calling context
CallCtxu
fand with forward invariants Invo
fisPrecondu
f
:Precondu
f, i.e. the negation of a satisÔ¨Åability witness
Precondu
ffor:
9Precondu
hi;Invu
f;Sumu
f:8xin;x;x0;x00;xout:
:CallCtxu
f(xin;xout)^Invo
f(x)^
Summso
f^Summsu
f^Assertions f(x) =) 
Init(xin;x00)^Invu
f(x00)^Out(x;xout)
=)Invu
f(x)^Sumu
f(xin;xout)^Precondu
f(xin)
^ 
(:RR f(x;x0)_Precondsu
f_:CallCtxu
f(xin;xout)^
Init(xin;x)^Out(x0;xout))^
Invu
f(x0)^Trans (x;x0) =)Invu
f(x)withPrecondsu
f=W
callshjinfghj=)
:Precondu[h](xpinj;xpoutj):
This formula is similar to Def. 5, but w.r.t. backward calling
contexts and summaries, and strengthened by the (forward)
invariants Invo
f. We denote the negation of the witnesses found
for the summary and the invariant by Sumu
f:Sumu
fand
Invu
f:Invu
f, respectively.
Lemma 6. Precondu
f,Sumu
fand Invu
fare under-
approximating.
Proof sketch. We compute an over-approximation of the
negation of the precondition w.r.t. the negation of the
under-approximating termination argument and the nega-
tion of further under-approximating information (backward
calling context, preconditions of procedure calls) ‚Äî by
the soundness of the synthesis (see Thm. 3 in Sec. V),
this over-approximates the non-terminating traces, and hence
under-approximates the terminating ones. Hence, the pre-
condition is a sufÔ¨Åcient precondition for termination. The
term:RRf(x;x0)_Precondsu
f_:CallCtxu
f(xin;xout)^
Init(xin;x)^Out(x0;xout)characterises non-terminating
states in the invariants of f: for these, either the termination
argument for fis not satisÔ¨Åed or the precondition for termi-
nation of one of the callees does not hold or we are outside
the calling context.
Example 7. We will instantiate Def. 7 for procedure h
in Fig. 1, assuming that we have CallCtxu
h((y);(rh)) =
(y=0_11rhM), as computed in the previous example.
Invo
h=true andhdoes not have any procedure calls, thus
Summso
h=true,Summsu
h=true, and Precondsu
h=false .
Assume we have the termination argument candidate RRh=
( x> x0).
The second conjunct in the consequent of the top-level
implication is satisÔ¨Åed either for y=0making:RRhtrue or
y10violating the calling context (third disjunct).
Hence, a solution is Precondu
h= (0y10),
Invu
h= (0x19^0y10), and Sumu
h= (0y10^
0rh10). I.e. a sufÔ¨Åcient precondition for termination is
Precondu
h= (11yM).
Theorem 2. A procedure fterminates for all values of xin
satisfying Precondu
f.
Proof sketch. By induction over the acyclic call graph using
Lemmae 5 and 6.
D. Context-Sensitive Summaries
The key idea of interprocedural analysis is to avoid re-
analysing procedures that are called multiple times. For that
reason, Algorithm 1 Ô¨Årst checks whether it can re-use already
computed information. For that purpose, summaries are stored
as implications CallCtxo)Sumo. As the call graph is
traversed, the possible calling contexts CallCtxo
hifor a proce-
durehare collected over the call sites i.NeedToReAnalyzeo
(Line 5 in Alg. 1) checks whether the current calling contextCallCtxo
hiis subsumed by calling contextsW
iCallCtxo
hithat
we have already encountered, and if so, Sumso[h]is reused;
otherwise it needs to be recomputed and joined conjunctively
with previously inferred summaries. The same considerations
apply to invariants, termination arguments and preconditions.
V. T EMPLATE -BASED STATIC ANALYSIS
In this section, we give a brief overview of our synthesis
engine, which serves as a backend for our approach (it solves
the formulae in DeÔ¨Ånitions 4, 5, 7, and 6 (see Sec. IV)).
Our synthesis engine employs template-based static anal-
ysis to compute ranking functions, invariants, summaries,
and calling contexts, i.e., implementations of functions
compInvSumoandcompCallCtxofrom the second-order con-
straints deÔ¨Åned in Sec. IV. To be able to effectively solve
second-order problems, we reduce them to Ô¨Årst-order by
restricting the space of solutions to expressions of the form
T(x;d)where
dare parameters to be instantiated with concrete values
andxare the program variables.
Tis a template that gives a blueprint for the shape of
the formulas to be computed. Choosing a template is
analogous to choosing an abstract domain in abstract
interpretation. To allow for a Ô¨Çexible choice, we consider
template polyhedra [9].
We state here a soundness result:
Theorem 3. Any satisÔ¨Åability witness dof the reduction of
the second order constraint for invariants in Def. 1 using
templateT
9d;8xin;x;x0:Init(xin;x) =)T(x;d)
^ T (x;d)^Trans (x;x0) =)T(x0;d)
satisÔ¨Åes8x:Inv(x) =)T (x;d), i.e.T(x;d)is a sound
over-approximating invariant. Similar soundness results hold
true for summaries and calling contexts.
This ultimately follows from the soundness of abstract
interpretation [10]. Similar approaches have been described,
for instance, by [11], [12], [13]. However, these methods
consider programs over mathematical integers.
Ranking functions require specialised synthesis techniques.
To achieve both expressiveness and efÔ¨Åciency, we generate
linear lexicographic functions [14], [15]. Our ranking-function
synthesis approach is similar to the TAN tool [16] but extends
the approach from monolithic to lexicographic ranking func-
tions. Further, unlike TAN, our synthesis engine is much more
versatile and conÔ¨Ågurable, e.g., it also produces summaries and
invariants.
Due to space limitations, we refer to the extended ver-
sion [7], which includes a detailed description of the synthesis
engine, our program encoding, encoding of bit-precise arith-
metic, and tailored second-order solving techniques for the
different constraints that occur in our analysis. In the following
section, we discuss the implementation.VI. I MPLEMENTATION
We have implemented the algorithm in 2LS [17], a static
analysis tool for C programs built on the CPROVER frame-
work, using MiniSat 2.2.0 as back-end solver. Other SAT and
SMT solvers with incremental solving support would also be
applicable. Our approach enables us to use a single solver
instance per procedure to solve a series of second-order queries
as required by Alg. 1. This is essential as our synthesis algo-
rithms make thousands of solver calls. Architectural settings
(e.g. bitwidths) can be provided on the command line.
Discussions about technical issues w.r.t. bit-preciseness and
the computation of intraprocedural termination arguments can
be found in the extended version [7].
VII. E XPERIMENTS
We performed experiments to support the following claims:
1) Interprocedural termination analysis (IPTA) is faster than
monolithic termination analysis (MTA).
2) The precision of IPTA is comparable to MTA.
3) 2LS outperforms existing termination analysis tools.
4) 2LS‚Äôs analysis is bit-precise.
5) 2LS computes usable preconditions for termination.
We used the product line benchmarks of the [18] benchmark
repository. In contrast to other categories, this benchmark set
contains programs with non-trivial procedural structure. This
benchmark set contains 597 programs with 1100 to 5700
lines of code (2705 on average),433 to 136 procedures (67
on average), and 4 to 10 loops (5.5 on average). Of these
benchmarks, 264 terminate universally, whereas 333 never
terminate.
The experiments were run on a Xeon X5667 at 3 GHz
running Fedora 20 with 64-bit binaries. Memory and CPU time
were restricted to 16 GB and 1800 seconds per benchmark,
respectively (using [19]). Using 2LS with interval templates
was sufÔ¨Åcient to obtain reasonable precision.
Modular termination analysis is fast We compared IPTA
with MTA (all procedures inlined). Table I shows that IPTA
times out on 2.3 % of the benchmarks vs. 39.7 % for MTA.
The geometric mean speed-up of IPTA w.r.t. MTA on the
benchmarks correctly solved by both approaches is 1.37.
In order to investigate how the 30 m timeout affects MTA,
we randomly selected 10 benchmarks that timed out for 30 m
and re-ran them: 1 Ô¨Ånished in 32 m, 3 after more than 1 h,
6 did not Ô¨Ånish within 2 h.
Modular termination analysis is precise Again, we com-
pare IPTA with MTA. Table I shows that IPTA proves 94 % of
the terminating benchmarks, whereas only 10 % were proven
by MTA. MTA can prove all never-terminating benchmarks
including 13 benchmarks where IPTA times out. MTA times
out on the benchmarks that cause 13 additional potentially
non-terminating outcomes for IPTA.
2LS outperforms existing termination analysis tools We
compared 2LS with two termination tools for C programs from
4Measured using cloc 1.53.TABLE I
TOOL COMPARISON (see text ).2LS IPTA
2LS MTA
TAN
Ultimate
terminating 249 26 18 50
non-terminating 320 333 3 324
potentially non-term. 14 1 425 0
timed out 14 237 150 43
errors 0 0 1 180
total run time (h) 58.7 119.6 92.8 23.9
the SV-COMP termination competition, namely TAN [20]
and Ultimate [21].
Unfortunately, the tools [22], [23], [24], [25], and [26] have
limitations regarding the subset of C that they can handle that
make them unable to analyze any of the benchmarks out of the
box. We describe these limitations in the experiments log in
[17]. Unfortunately, we did not succeed to generate the correct
input Ô¨Åles in the intermediate formats required by T2 [27] and
KiTTeL [28] using the recommended frontends [29] and [30].
TAN [16] and KiTTeL/KoAT [5] support bit-precise C
semantics. Ultimate uses mathematical integer reasoning but
tries to ensure conformance with bit-vector semantics. Also,
Ultimate uses a semantic decomposition of the program [31]
to make its analysis efÔ¨Åcient.
For each of the tools, Table I lists the number of instances
solved, timed out or aborted because of an internal error. We
also give the total run time, which shows that analysis times
are roughly halved by the modular/interprocedural approaches
(2LS IPTA, Ultimate) in comparison with the monolithic
approaches (2LS MTA, TAN). Ultimate spends less time on
those benchmarks that it can prove terminating, however, these
are only 19 % of the terminating benchmarks (vs. 94 % for
2LS). If Ultimate could solve those 180 benchmarks on which
it fails due to unsupported features of C, we would expect its
performance to be comparable to 2LS.
Ultimate and 2LS have different capabilities regarding non-
termination. 2LS can show that a program never terminates for
all inputs, whereas Ultimate can show that there exists a poten-
tially non-terminating execution. To make the comparison fair,
we counted benchmarks Ô¨Çagged as potentially non-terminating
by Ultimate, but which are actually never-terminating, in the
non-terminating category in Table I (marked).
2LS‚Äôs analysis is bit-precise We compared 2LS with
Loopus on a collection of 15 benchmarks ( ABC_ex01.c to
ABC_ex15.c ) taken from the Loopus benchmark suite [23].
While they are short (between 7 and 41 LOC), the main
characteristic of these programs is the fact that they exhibit
different terminating behaviours for mathematical integers and
bit-vectors. For illustration, ABC_ex15.c (Fig. 3) terminates
with mathematical integers, but not with machine integers
if, for instance, mequals INT_MAX . Next, we summarise1void ex15 ( i n t m, i n t n , i n t p , i n t q )f
2 f o r (i n t i = n ; i >= 1 ; i = i 1)
3 f o r (i n t j = 1 ; j <= m; j = j + 1)
4 f o r (i n t k = i ; k <= p ; k = k + 1)
5 f o r (i n t l = q ; l <= j ; l = l + 1)
6 ;
7g
Fig. 3. Example ABC_ex15.c from the Loopus benchmarks.
1void c r e a t e B a c k ( s t r u c t SDL Surfaceb a c k s u r f )
2f
3 s t r u c t SDL Rect pos ;
4 s t r u c t SDL Surfaceimg = images [ img back] >image ;
5
6 f o r(i n t x =0; ! ( s >=(b a c k s u r f) >h ) ; s +=img >h )f
7 f o r(i n t y =0; ! ( y >=(b a c k s u r f) >w ) ; y+=img >w)f
8 pos . x = ( s i g n e d s h o r t i n t ) x ;
9 pos . y = ( s i g n e d s h o r t i n t ) y ;
10 SDL UpperBlit ( img , NULL, b a c k s u r f , &pos ) ;
11 . . .
12g g g
Fig. 4. Example createBack from Debian package abe.
the results of our experiments on these benchmarks when
considering machine integers:
Only 2 of the programs terminate, and are correctly
identiÔ¨Åed by both 2LS and Loopus.
For the rest of 13 non-terminating programs, Loopus
claims they terminate, whereas 2LS correctly classiÔ¨Åes 9
as potentially non-terminating (including ABC_ex15.c
in Fig. 3) and times out on 4.
2LS computes usable preconditions for termination This
experiment was performed on benchmarks extracted from
Debian packages and the linear algebra library CLapack.
The quality of preconditions, i.e. usability or ability to help
the developer to spot problems in the code, is difÔ¨Åcult to
quantify. We give several examples where functions terminate
conditionally. The abe package of Debian contains a function,
given as Fig. 4, where increments of the iteration in a loop
are not constant but dynamically depend on the dimensions
of an image data structure. Here, 2LS infers the precondition
img!h>0^img!w>0.
The example in Fig. 5 is taken from the benchmark
basename in the busybox -category of SVCOMP 2015,
which contains simpliÔ¨Åed versions of Debian packages. The
termination of function full_write depends on the return
value of its callee function safe_write . Here, 2LS infers
the calling context cc > 0, i.e. the contract for the function
safe_write , such that the termination of full_write is
guaranteed. Given a proof that safe_write terminates and
returns a strictly positive value regardless of the arguments it
is called with, we can conclude that full_write terminates
universally.
The program in Fig. 6 is a code snippet taken from the
summation procedure sasum within [32], the C version of the
popular LAPACK linear algebra library. The loop in procedure
fdoes not terminate if incx = 0. Ifincx> 0(incx< 0) the
termination argument is that iincreases (decreases). Therefore,
incx6= 0 is a termination precondition for f.1s i g n e d long i n t f u l l w r i t e ( s i g n e d i n t fd ,
2 c o n s t voidbuf , unsigned long i n t len ,
3 unsigned long i n t cc )f
4 s i g n e d long i n t t o t a l = ( s i g n e d long i n t ) 0 ;
5 f o r( ; ! ( l e n == 0 u l ) ;
6 l e n = l e n (unsigned long i n t ) cc )f
7 cc= s a f e w r i t e ( fd , buf , l e n ) ;
8 i f( cc<0 l )f
9 i f( ! ( t o t a l == 0 l ) )
10 return t o t a l ;
11 return cc ;
12g
13 t o t a l = t o t a l + cc ;
14 buf = ( c o n s t void) ( (c o n s t char) buf + cc ) ;
15g g
Fig. 5. Example from SVCOMP 2015 busybox .
1i n t f (i n tsx , i n t n , i n t i n c x )f
2 i n t n i n c x = ni n c x ;
3 i n t stemp =0;
4 f o r (i n t i =0; incx <0 ? i >= n i n c x : i <= n i n c x ;
5 i += i n c x )f
6 stemp += sx [ i 1];
7g
8 return stemp ;
9g
Fig. 6. Non-unit increment from CLapack .
VIII. L IMITATIONS , RELATED WORKS
AND FUTURE DIRECTIONS
Our approach makes signiÔ¨Åcant progress towards analysing
real-world software, advancing the state-of-the-art of termina-
tion analysis of large programs. Conceptually, we decompose
the analysis into a sequence of well-deÔ¨Åned second-order pred-
icate logic formulae with existentially quantiÔ¨Åed predicates. In
addition to [33], we consider context-sensitive analysis, under-
approximate backwards analysis, and make the interaction
with termination analysis explicit. Notably, these seemingly
tedious formulae are actually solved by our generic template-
based synthesis algorithm, making it an efÔ¨Åcient alternative to
predicate abstraction.
An important aspect of our analysis is that it is bit-precise.
As opposed to the synthesis of termination arguments for lin-
ear programs over integers (rationals) [34], [35], [2], [36], [37],
[14], [15], this subclass of termination analyses is substantially
less covered. While [16], [38] present methods based on a
reduction to Presburger arithmetic, and a template-matching
approach for predeÔ¨Åned classes of ranking functions based
on reduction to SAT- and QBF-solving, [39] only compute
intraprocedural termination arguments.
There are still a number of limitations to be addressed, all
of which connect to open challenges subject to active research.
While some are orthogonal (e.g., data structures, strings,
reÔ¨Ånement) to our interprocedural analysis framework, others
(recursion, necessary preconditions) require extensions of it. In
this section, we discuss related work, as well as, characteristics
and limitations of our analysis, and future directions (cost
analysis and concurrency).
Dynamically allocated data structures We currently ig-
nore heap-allocated data. This limitation could be lifted byusing speciÔ¨Åc abstract domains. For illustration, let us consider
the following example traversing a singly-linked list.
L i s t x ; while ( x != NULL)fx = x >n e x t ;g
Deciding the termination of such a program requires knowl-
edge about the shape of the data structure pointed by x,
namely, the program only terminates if the list is acyclic. Thus,
we would require an abstract domain capable of capturing
such a property and also relate the shape of the data structure
to its length. Similar to [15], we could use [40] in order
to abstract heap-manipulating programs to arithmetic ones.
Another option is using an abstract interpretation based on
separation logic formulae which tracks the depths of pieces of
heaps similarly to [41].
Strings and arrays Similar to dynamic data structures,
handling strings and arrays requires speciÔ¨Åc abstract domains.
String abstractions that reduce null-terminated strings to inte-
gers (indices, length, and size) are usually sufÔ¨Åcient in many
practical cases; scenarios where termination is dependent on
the content of arrays are much harder and would require
quantiÔ¨Åed invariants [42]. Note that it is favorable to run a
safety checker before the termination checker. The latter can
assume that assertions for buffer overÔ¨Çow checks hold which
strengthens invariants and makes termination proofs easier.
Recursion We currently use downward Ô¨Åxed point iterations
for computing calling contexts and invariants that involve
summaries (see Remark 1). This is cheap but gives only
imprecise results in the presence of recursion, which would
impair the termination analysis. We could handle recursions by
detecting cycles in the call graph and switching to an upward
iteration scheme in such situations. Moreover, an adaptation
regarding the generation of the ranking function templates is
necessary. An alternative approach would be to make use of
the theoretic framework presented in [43] for verifying total
correctness and liveness properties of while programs with
recursion.
Template reÔ¨Ånement We currently use interval templates
together with heuristics for selecting the variables that should
be taken into consideration. This is often sufÔ¨Åcient in practice,
but it does not exploit the full power of the machinery in place.
While counterexample-guided abstraction reÔ¨Ånement (CE-
GAR) techniques are prevalent in predicate abstraction [44],
attempts to use them in abstract interpretation are rare [45].
We consider our template-based abstract interpretation that
automatically synthesises abstract transformers more amenable
to reÔ¨Ånement techniques than classical abstract interpretations
where abstract transformers are implemented manually.
SufÔ¨Åcient preconditions to termination Conditional ter-
mination has recently attracted increased interest [8], [46],
[47], [48], [49]. In this paper, we compute sufÔ¨Åcient precon-
ditions, i.e. under-approximating preconditions to termination
via computing over-approximating preconditions to potential
non-termination. The same concept is used by other works
[8], [46]. However, they consider only a single procedure
and do not leverage their results to perform interproceduralanalysis on large benchmarks which adds, in particular, the
additional challenge of propagating under-approximating in-
formation up to the entry procedure (e.g. [50]). Moreover,
by contrast to Cook et al [8] who use an heuristic F INITE -
operator left unspeciÔ¨Åed for bootstrapping their preconditions,
our bootstrapping is systematic through constraint solving.
We could compute necessary preconditions by computing
over-approximating preconditions to potential termination (and
negating the result). However, this requires a method for
proving that there exist non-terminating executions, which
is a well-explored topic. While [51] dynamically enumerate
lasso-shaped candidate paths for counterexamples, and then
statically prove their feasibility, [52] prove nontermination
via reduction to safety proving and [53] uses bi-abduction
to construct summaries of terminating and non-terminating
behaviors for each method. In order to prove both termination
and non-termination, [54] compose several program analyses
(termination provers for multi-path loops, non-termination
provers for cycles, and safety provers).
Cost analysis A potential future application for our work is
cost and resource analysis. Instances of this type of analyses
are the worst case execution time (WCET) analysis [55], as
well as bound and amortised complexity analysis [56], [57],
[58]. The control Ô¨Çow reÔ¨Ånement approach [59], [60] instru-
ments a program with counters and uses progress invariants
to compute worst case or average case bounds.
Concurrency Our current analysis handles single-threaded
C programs. One way of extending the analysis to multi-
threaded programs is using the rely-guarantee technique which
is proposed in [61], and explored in several works [62], [63],
[64] for termination analysis. In our setting, the predicates
for environment assumptions can be used in a similar way as
invariants and summaries are used in the analysis of sequential
programs.
IX. C ONCLUSIONS
While many termination provers mainly target small, hard
programs, the termination analysis of larger code bases has
received little attention. We present an algorithm for interpro-
cedural termination analysis for non-recursive programs. To
our knowledge, this is the Ô¨Årst paper that describes in full detail
the entire machinery necessary to perform such an analysis.
Our approach relies on a bit-precise static analysis combining
SMT solving, template polyhedra and lexicographic, linear
ranking function templates. We provide an implementation of
the approach in the static analysis tool 2LS, and demonstrate
the applicability of the approach to programs with thousands
of lines of code.
REFERENCES
[1] http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2009-1890.
[2] A. M. Ben-Amram and S. Genaim, ‚ÄúOn the linear ranking problem
for integer linear-constraint loops,‚Äù in Principles of Programming Lan-
guages , pp. 51‚Äì62, ACM, 2013.
[3] J. Leike and M. Heizmann, ‚ÄúRanking templates for linear loops,‚Äù in Tools
and Algorithms for the Construction and Analysis of Systems , vol. 8413
ofLNCS , pp. 172‚Äì186, Springer, 2014.[4] A. R. Bradley, Z. Manna, and H. B. Sipma, ‚ÄúTermination of polynomial
programs,‚Äù in VeriÔ¨Åcation, Model Checking, and Abstract Interpretation ,
vol. 3385 of LNCS , pp. 113‚Äì129, Springer, 2005.
[5] S. Falke, D. Kapur, and C. Sinz, ‚ÄúTermination analysis of imperative
programs using bitvector arithmetic,‚Äù in VeriÔ¨Åed Software: Theories,
Tools, Experiments , vol. 7152 of LNCS , pp. 261‚Äì277, Springer, 2012.
[6] D. Beyer, ‚ÄúStatus report on software veriÔ¨Åcation ‚Äì (competition summary
SV-COMP 2014),‚Äù in Tools and Algorithms for the Construction and
Analysis of Systems , vol. 8413 of LNCS , Springer, 2014.
[7] H.-Y . Chen, C. David, D. Kroening, P. Schrammel, and B. Wachter,
‚ÄúSynthesising interprocedural bit-precise termination proofs (extended
version),‚Äù tech. rep., University of Oxford, 2015. http://arxiv.org/abs/
1505.04581.
[8] B. Cook, S. Gulwani, T. Lev-Ami, A. Rybalchenko, and M. Sagiv, ‚ÄúProv-
ing conditional termination,‚Äù in Computer-Aided VeriÔ¨Åcation , vol. 5123
ofLNCS , pp. 328‚Äì340, Springer, 2008.
[9] S. Sankaranarayanan, H. B. Sipma, and Z. Manna, ‚ÄúScalable analysis of
linear systems using mathematical programming,‚Äù in VeriÔ¨Åcation, Model
Checking, and Abstract Interpretation , vol. 3385 of LNCS , pp. 25‚Äì41,
Springer, 2005.
[10] P. Cousot and R. Cousot, ‚ÄúAbstract interpretation: A uniÔ¨Åed lattice model
for static analysis of programs by construction or approximation of
Ô¨Åxpoints,‚Äù in Principles of Programming Languages , pp. 238‚Äì252, 1977.
[11] T. M. Gawlitza and H. Seidl, ‚ÄúPrecise relational invariants through
strategy iteration,‚Äù in Computer Science Logic , vol. 4646 of LNCS ,
pp. 23‚Äì40, Springer, 2007.
[12] S. Gulwani, S. Srivastava, and R. Venkatesan, ‚ÄúProgram analysis as con-
straint solving,‚Äù in Programming Language Design and Implementation ,
pp. 281‚Äì292, ACM, 2008.
[13] Y . Li, A. Albarghouthi, Z. Kincaid, A. GurÔ¨Ånkel, and M. Chechik, ‚ÄúSym-
bolic optimization with SMT solvers,‚Äù in Principles of Programming
Languages , pp. 607‚Äì618, ACM, 2014.
[14] A. R. Bradley, Z. Manna, and H. B. Sipma, ‚ÄúLinear ranking with
reachability,‚Äù in Computer-Aided VeriÔ¨Åcation , pp. 491‚Äì504, 2005.
[15] B. Cook, A. See, and F. Zuleger, ‚ÄúRamsey vs. lexicographic termination
proving,‚Äù in Tools and Algorithms for the Construction and Analysis of
Systems , pp. 47‚Äì61, 2013.
[16] D. Kroening, N. Sharygina, A. Tsitovich, and C. M. Wintersteiger, ‚ÄúTer-
mination analysis with compositional transition invariants,‚Äù in Computer-
Aided VeriÔ¨Åcation , vol. 6174 of LNCS , pp. 89‚Äì103, Springer, 2010.
[17] http://www.cprover.org/wiki/doku.php?id=2ls forprogram analysis
(version 0.1).
[18] https://svn.sosy-lab.org/software/sv-benchmarks/tags/svcomp14/
product-lines/.
[19] O. Roussel, ‚ÄúControlling a solver execution with the runsolver tool,‚Äù
Journal on SatisÔ¨Åability, Boolean Modeling and Computation , vol. 7,
no. 4, pp. 139‚Äì144, 2011.
[20] http://www.cprover.org/termination/ (version SV-COMP-2014).
[21] M. Heizmann, D. Dietsch, J. Leike, B. Musa, and A. Podelski, ‚ÄúUltimate
automizer with array interpolation - (competition contribution),‚Äù in Tools
and Algorithms for the Construction and Analysis of Systems , vol. 9035
ofLNCS , Springer, 2015. http://ultimate.informatik.uni-freiburg.de/
(version SV-COMP-2015).
[22] T. Str ¬®oder, C. Aschermann, F. Frohn, J. Hensel, and J. Giesl, ‚ÄúAProVE:
Termination and Memory Safety of C programs - (competition contri-
bution),‚Äù in Tools and Algorithms for the Construction and Analysis of
Systems , vol. 9035 of LNCS , Springer, 2015. http://aprove.informatik.
rwth-aachen.de (version 2014).
[23] http://forsyte.at/software/loopus/ with http://sourceforge.net/projects/
virtualboximage/Ô¨Åles/Ubuntu%20Linux/11.10/ubuntu 11.10-x86.7z/
download.
[24] http://www.di.ens.fr/ urban/sv-comp2015.zip (version SV-COMP-
2015).
[25] T. C. Le, C. Gherghina, A. Hobor, and W. Chin, ‚ÄúA resource-based
logic for termination and non-termination proofs,‚Äù in ICFEM , vol. 8829
ofLNCS , Springer, 2014. http://loris-7.ddns.comp.nus.edu.sg/ project/
hiptnt/plus/.
[26] A. Podelski and A. Rybalchenko, ‚ÄúARMC: the logical choice for
software model checking with abstraction reÔ¨Ånement,‚Äù in Practical
Aspects of Declarative Languages , vol. 4354 of LNCS , Springer, 2007.
https://www7.in.tum.de/ rybal/armc/ (version August 2011).
[27] http://research.microsoft.com/en-us/projects/t2/ (version 2014-10).
[28] https://github.com/s-falke/kittel-koat (revision c05eab4b3c).
[29] http://research.microsoft.com/en-us/projects/slayer/ (version 1.1).[30] https://github.com/mmjb/llvm2kittel (revision 6fc38707f7).
[31] M. Heizmann, J. Hoenicke, and A. Podelski, ‚ÄúTermination analysis
by learning terminating programs,‚Äù in Computer-Aided VeriÔ¨Åcation ,
vol. 8559 of LNCS , pp. 797‚Äì813, Springer, 2014.
[32] http://www.netlib.org/clapack/cblas/sasum.c.
[33] S. Grebenshchikov, N. P. Lopes, C. Popeea, and A. Rybalchenko,
‚ÄúSynthesizing software veriÔ¨Åers from proof rules,‚Äù in Programming
Language Design and Implementation , pp. 405‚Äì416, 2012.
[34] B. Cook, A. Podelski, and A. Rybalchenko, ‚ÄúTermination proofs for
systems code,‚Äù in Programming Language Design and Implementation ,
pp. 415‚Äì426, ACM, 2006.
[35] W. Lee, B.-Y . Wang, and K. Yi, ‚ÄúTermination analysis with algorithmic
learning,‚Äù in Computer-Aided VeriÔ¨Åcation , pp. 88‚Äì104, 2012.
[36] A. Podelski and A. Rybalchenko, ‚ÄúTransition invariants,‚Äù in Logic in
Computer Science , pp. 32‚Äì41, IEEE Computer Society, 2004.
[37] M. Heizmann, J. Hoenicke, J. Leike, and A. Podelski, ‚ÄúLinear ranking
for linear lasso programs,‚Äù in Automated Technology for VeriÔ¨Åcation and
Analysis , pp. 365‚Äì380, 2013.
[38] B. Cook, D. Kroening, P. R ¬®ummer, and C. M. Wintersteiger, ‚ÄúRanking
function synthesis for bit-vector relations,‚Äù in Tools and Algorithms for
the Construction and Analysis of Systems , vol. 6015 of LNCS , pp. 236‚Äì
250, Springer, 2010.
[39] C. David, D. Kroening, and M. Lewis, ‚ÄúUnrestricted termination and
non-termination arguments for bit-vector programs,‚Äù in European Sym-
posium on Programming , pp. 183‚Äì204, 2015.
[40] S. Magill, M.-H. Tsai, P. Lee, and Y .-K. Tsay, ‚ÄúAutomatic numeric
abstractions for heap-manipulating programs,‚Äù in Principles of Program-
ming Languages , pp. 211‚Äì222, 2010.
[41] J. Berdine, B. Cook, D. Distefano, and P. W. O‚ÄôHearn, ‚ÄúAutomatic
termination proofs for programs with shape-shifting heaps,‚Äù in CAV,
pp. 386‚Äì400, 2006.
[42] K. L. McMillan, ‚ÄúQuantiÔ¨Åed invariant generation using an interpolating
saturation prover,‚Äù in Tools and Algorithms for the Construction and
Analysis of Systems , vol. 4963 of LNCS , pp. 413‚Äì427, Springer, 2008.
[43] A. Podelski, I. Schaefer, and S. Wagner, ‚ÄúSummaries for while programs
with recursion,‚Äù in European Symposium on Programming , vol. 3444 of
LNCS , pp. 94‚Äì107, Springer, 2005.
[44] E. M. Clarke, O. Grumberg, S. Jha, Y . Lu, and H. Veith,
‚ÄúCounterexample-guided abstraction reÔ¨Ånement,‚Äù in Computer-Aided
VeriÔ¨Åcation , vol. 1855 of LNCS , pp. 154‚Äì169, Springer, 2000.
[45] F. Ranzato, O. Rossi-Doria, and F. Tapparo, ‚ÄúA forward-backward
abstraction reÔ¨Ånement algorithm,‚Äù in VeriÔ¨Åcation, Model Checking, and
Abstract Interpretation , vol. 4905 of LNCS , pp. 248‚Äì262, Springer, 2008.
[46] M. Bozga, R. Iosif, and F. Konecn ¬¥y, ‚ÄúDeciding conditional termination,‚Äù
inTools and Algorithms for the Construction and Analysis of Systems ,
vol. 7214 of LNCS , pp. 252‚Äì266, Springer, 2012.
[47] P. Ganty and S. Genaim, ‚ÄúProving termination starting from the end,‚Äù
inComputer-Aided VeriÔ¨Åcation , vol. 8044 of LNCS , Springer, 2013.
[48] D. Mass ¬¥e, ‚ÄúPolicy iteration-based conditional termination and ranking
functions,‚Äù in VeriÔ¨Åcation, Model Checking, and Abstract Interpretation ,
vol. 8318 of LNCS , Springer, 2014.
[49] C. Urban and A. Min ¬¥e, ‚ÄúA decision tree abstract domain for provingconditional termination,‚Äù in Static Analysis Symposium , vol. 8723 of
LNCS , Springer, 2014.
[50] P. Ganty, R. Iosif, and F. Konecn ¬¥y, ‚ÄúUnderapproximation of procedure
summaries for integer programs,‚Äù in Tools and Algorithms for the
Construction and Analysis of Systems , vol. 7795 of LNCS , pp. 245‚Äì259,
Springer, 2013.
[51] A. Gupta, T. A. Henzinger, R. Majumdar, A. Rybalchenko, and R.-
G. Xu, ‚ÄúProving non-termination,‚Äù in Principles of Programming Lan-
guages , pp. 147‚Äì158, ACM, 2008.
[52] H. Y . Chen, B. Cook, C. Fuhs, K. Nimkar, and P. W. O‚ÄôHearn, ‚ÄúProving
nontermination via safety,‚Äù in Tools and Algorithms for the Construction
and Analysis of Systems , pp. 156‚Äì171, 2014.
[53] T. C. Le, S. Qin, and W. Chin, ‚ÄúTermination and non-termination spec-
iÔ¨Åcation inference,‚Äù in Conference on Programming Language Design
and Implementation , pp. 489‚Äì498, 2015.
[54] W. R. Harris, A. Lal, A. V . Nori, and S. K. Rajamani, ‚ÄúAlternation for
termination,‚Äù in Static Analysis Symposium , pp. 304‚Äì319, 2010.
[55] R. Wilhelm, J. Engblom, A. Ermedahl, N. Holsti, S. Thesing, D. Whal-
ley, G. Bernat, C. Ferdinand, R. Heckmann, T. Mitra, F. Mueller,
I. Puaut, P. Puschner, J. Staschulat, and P. Stenstr ¬®om, ‚ÄúThe Worst-case
Execution Time Problem‚ÄîOverview of Methods and Survey of Tools,‚Äù
Transactions on Embedded Computing Systems , vol. 7, no. 3, 2008.
[56] C. Alias, A. Darte, P. Feautrier, and L. Gonnord, ‚ÄúMulti-dimensional
rankings, program termination, and complexity bounds of Ô¨Çowchart
programs,‚Äù in Static Analysis Symposium , vol. 6337 of LNCS , pp. 117‚Äì
133, Springer, 2010.
[57] M. Brockschmidt, F. Emmes, S. Falke, C. Fuhs, and J. Giesl, ‚ÄúAlternat-
ing runtime and size complexity analysis of integer programs,‚Äù in Tools
and Algorithms for the Construction and Analysis of Systems , vol. 8413
ofLNCS , pp. 140‚Äì155, Springer, 2014.
[58] M. Sinn, F. Zuleger, and H. Veith, ‚ÄúA simple and scalable static analysis
for bound analysis and amortized complexity analysis,‚Äù in Computer-
Aided VeriÔ¨Åcation , vol. 8559 of LNCS , pp. 745‚Äì761, Springer, 2014.
[59] S. Gulwani, S. Jain, and E. Koskinen, ‚ÄúControl-Ô¨Çow reÔ¨Ånement and
progress invariants for bound analysis,‚Äù in Programming Language
Design and Implementation , pp. 375‚Äì385, 2009.
[60] H. Y . Chen, S. Mukhopadhyay, and Z. Lu, ‚ÄúControl Ô¨Çow reÔ¨Ånement and
symbolic computation of average case bound,‚Äù in Automated Technology
for VeriÔ¨Åcation and Analysis , pp. 334‚Äì348, 2013.
[61] C. B. Jones, ‚ÄúTentative steps toward a development method for interfer-
ing programs,‚Äù ACM Trans. Program. Lang. Syst. , vol. 5, pp. 596‚Äì619,
Oct. 1983.
[62] B. Cook, A. Podelski, and A. Rybalchenko, ‚ÄúProving thread termina-
tion,‚Äù in Programming Language Design and Implementation , pp. 320‚Äì
330, ACM, 2007.
[63] A. Gupta, C. Popeea, and A. Rybalchenko, ‚ÄúPredicate abstraction and
reÔ¨Ånement for verifying multi-threaded programs,‚Äù in Principles of
Programming Languages , pp. 331‚Äì344, ACM, 2011.
[64] C. Popeea and A. Rybalchenko, ‚ÄúCompositional termination proofs for
multi-threaded programs,‚Äù in Tools and Algorithms for the Construction
and Analysis of Systems , vol. 7214 of LNCS , pp. 237‚Äì251, Springer,
2012.