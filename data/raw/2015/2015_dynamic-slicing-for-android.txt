Dynamic Slicing for Android
Tanzirul Azim‚àó, Arash Alavi‚àó, Iulian Neamtiu‚Ä°and Rajiv Gupta‚àó
‚àóUniversity of California, Riverside, USA
Email: mazim002@cs.ucr.edu, aalav003@ucr.edu, gupta@cs.ucr.edu
‚Ä°New Jersey Institute of Technology
Email: iulian.neamtiu@njit.edu
Abstract ‚ÄîDynamic program slicing is useful for a variety
of tasks, from testing to debugging to security. Prior slicing
approaches have targeted traditional desktop/server platforms,
rather than mobile platforms such as Android. Slicing mobile,
event-based systems is challenging due to their asynchronous
callback construction and the IPC (interprocess communication)-
heavy, sensor-driven, timing-sensitive nature of the platform. To
address these problems, we introduce AndroidSlicer1, the Ô¨Årst
slicing approach for Android. AndroidSlicer combines a novel
asynchronous slicing approach for modeling data and control
dependences in the presence of callbacks with lightweight and
precise instrumentation; this allows slicing for apps running on
actual phones, and without requiring the app‚Äôs source code. Our
slicer is capable of handling a wide array of inputs that Android
supports without adding any noticeable overhead. Experiments
on 60 apps from Google Play show that AndroidSlicer is effective
(reducing the number of instructions to be examined to 0.3%
of executed instructions) and efÔ¨Åcient (app instrumentation and
post-processing combined takes 31 seconds); all while imposing
a runtime overhead of just 4%. We present three applications
of AndroidSlicer that are particularly relevant in the mobile
domain: (1) Ô¨Ånding and tracking input parts responsible for an
error/crash, (2) fault localization, i.e., Ô¨Ånding the instructions
responsible for an error/crash, and (3) reducing the regression
test suite. Experiments with these applications on an additional
set of 18 popular apps indicate that AndroidSlicer is effective for
Android testing and debugging.
Index T erms ‚ÄîMobile apps, Android, Dynamic analysis
I. I NTRODUCTION
While mobile platforms have been very successful ‚Äì An-
droid alone runs on more than 2 billion devices [1] ‚Äì they are
prone to development, testing, and reliability issues that affect
users, developers, and manufacturers [2], [3]. We propose
an approach for tackling such issues via dynamic slicing, a
technique that isolates relevant code and data dependences
in an execution. Slicing has proven useful in many contexts,
from security (e.g., taint analysis) to debugging (e.g., fault
localization) and testing, but prior slicing approaches have not
targeted mobile platforms [4]‚Äì[6].
The smartphone platform, compared to ‚Äútraditional‚Äù desk-
top/server platforms, has unique challenges and constraints.
This renders traditional slicing approaches inapplicable and
has allowed us to design novel solutions. First, reconstructing
control Ô¨Çow is difÔ¨Åcult ‚Äì Android apps employ callbacks
which process events asynchronously . To cope with this,
we introduce the concept of asynchronous dependences to
1https://github.com/archer29m/AndroidSlicercapture control- and data-dependences between callbacks as
supernodes in a supergraph . Second, Android apps are time-
sensitive: even slight delays in sensor input can change
input semantics, perturbing app execution. We use an on-
demand static-after-dynamic analysis to permit low-overhead
yet precise slicing. Third, Android has a wide range of inputs:
multi-touch gestures, sensors, mic, camera, etc. Capturing this
input correctly without losing precision is challenging, and
introduces signiÔ¨Åcant overhead in other tools, e.g., Pin [7].
We solve this challenge by combining lightweight tracking
(AF wrappers) with a layered abstraction (supergraph). Fourth,
Android uses IPC heavily for inter- and intra-app communica-
tion, which requires tracking dependences from apps, through
system calls, to external apps.
Section III presents our model and dependence rules. Sec-
tion IV describes our approach to handling Android-speciÔ¨Åc
challenges, e.g., sensor input, low overhead, and IPC.
Our implementation, AndroidSlicer , is described in Section V;
AndroidSlicer works on Android apps running on actual phones
and does not require app source code.
Next, we show how AndroidSlicer serves as a building block
for constructing three applications that facilitate bug Ô¨Ånding,
bug Ô¨Åxing, and testing. First, Failure-inducing Input Analysis ,
i.e., Ô¨Ånding the input parts that are relevant to an error or
a crash and tracking their propagation to the error/crash site
(Section VI-A). Second, Fault Localization , i.e., Ô¨Ånding the
part of the code (a set of instructions) responsible for an
error or crash (Section VI-B). Third, we show how slicing
helps reduce the number of tests for Regression Testing (Sec-
tion VI-C). Our analyses are robust and scalable: we applied
them to isolate causes of real bugs in widely-popular apps
such as SoundCloud, Etsy, K9-Mail, and NPR News.
In Section VII we evaluate AndroidSlicer on 60 popular apps
from Google Play. Of these, we manually analyzed 10 apps
to check AndroidSlicer ‚Äôs correctness. Experiments indicate that
AndroidSlicer is efÔ¨Åcient: it typically instruments an app in just
19.1 seconds and slice computation during post-processing
typically takes just 11.9 seconds. At most, slice computation
took 293.5 seconds for the substantial Twitter app, whose
bytecode size is 50.6 MB. Moreover, AndroidSlicer h a sal o w
runtime overhead, typically 4%. Finally, AndroidSlicer is effec-
tive: it manages to reduce large executions (on average, 14491
instructions) down to small slices (on average, 44 instructions)
that are much more manageable for developers. In summary,
this work makes four contributions:
11542019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ¬©2019 IEEE
DOI 10.1109/ICSE.2019.00118
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. 1) A novel asynchronous slicing model.
2) A precise approach for slicing Android apps that ad-
dresses the speciÔ¨Åc challenges and constraints of this
platform and environment.
3) AndroidSlicer , a tool for slicing Android apps while they
run on actual phones.
4) A novel approach to reducing runtime overhead and
handling the large array of inputs supported by Android.
5) Three slicing applications that facilitate development,
debugging, and testing for Android apps.
II. B ACKGROUND
We Ô¨Årst present a brief overview of program dependence
graphs and program slicing; next, we discuss the Android
platform and its event-based model.
Program dependence graph (PDG). A PDG captures a
program‚Äôs data and control dependences. Each PDG edge
represents a data or control dependence between nodes that can
either represent an instruction or a basic block. A directed data
dependence edge nj‚Üêdnimeans any computation performed
innidepends on the computed value at node nj. A control
dependence edge nj‚Üêcniindicates that the decision to
execute niis made by nj, that is, njcontains a predicate
whose outcome controls the execution of ni. A static PDG
consists of all possible data and control dependence relations.
A dynamic PDG is a subgraph that contains only those nodes
and edges that are exercised during a particular run.
Program slicing. Dynamic program slicing, a class of
dynamic analysis, was introduced by Korel and Laski [4]. The
backward dynamic slice at instruction instance swith respect
toslicing criterion /angbracketleftt, s, value /angbracketright(where tis a timestamp)
contains executed instructions that have a direct or indirect
effect on value ; more precisely, it is the transitive closure over
dynamic data and control dependences in the PDG starting
from the slicing criterion. The slicing criterion represents an
analysis demand relevant to an application, e.g., for debugging,
the criterion means the instruction execution that causes a
crash.
Android platform. The Android software stack comprises
of: apps; a middleware component named Android Framework
(AF) which orchestrates control Ô¨Çow and mediates inter- and
intra-app communication, as well as communication between
apps and the lower layers; libraries and services; a run-time
environment;2and the OS, an embedded version of Linux.
Android‚Äôs event-based model. Android apps do not have
amain() method but rather consist of components (e.g., an app
with a GUI consists of screens, named Activities3) and one
or more entry points. Unlike traditional programs, apps use
an event-driven model that dictates control Ô¨Çow. An event can
be a user action (e.g., touch), a lifecycle event (e.g., onPause()
2Dalvik VM for Android prior to 5.0; in Android version 5.0 and later,
Android uses ART, a runtime system and ahead-of-time compilation. Our
implementation (Section V) is on Android 5.1.1.
3The vast majority of Google Play apps consist of Activities. There are
other component types such as Services, Content Providers, and Broadcast
Receiver [8] but these are used much more sparsely.when the app is paused), arrival of sensor data (e.g., GPS), and
inter- or intra-app messages. All these traits, from externally-
orchestrated control Ô¨Çow to time-sensitive sensor input, render
traditional slicing approaches inapplicable to Android.
III. M ODEL
In this section we present the model underlying our ap-
proach. Slicing precision depends on accurately identifying
control and data dependences ‚Äì these dependences form the
PDG. Our callback-centric design achieves low-overhead event
capture without sacriÔ¨Åcing precision (all input data is captured
natively from the framework). Instead of considering a single
instruction instance as a node, we collectively deÔ¨Åne callbacks
as a node containing other nodes (instructions) or a supernode.
Just like a regular node, callbacks or supernodes can invoke
other events/callbacks directly (a control dependence), or by
passing an argument to the framework which in turn is
passed to another callback (a data dependence). Our model
captures both of these dependences for callbacks/supernodes,
and instructions/single nodes. We use a ‚Äúhierarchical‚Äù PDG,
constructed as follows. High-level supernodes Nrepresent
callbacks and their dynamic context; superedges represent
asynchronous control- or data-dependences between supern-
odes. Within supernodes, we use low-level instruction nodes
Sit, and edges which capture sequential dependences.
Supernodes N, the core of our model, are deÔ¨Åned as:
N:=/angbracketleftc, t, a,{[Sit‚ÜêcSjt|Sit‚ÜêdSjt]‚àó}/angbracketright
where callback variables ccontain the address of a callback,
tis the timestamp for node creation, ais the activity context
(activity‚Äôs runtime state), while Sit(a regular node) represents
the instance of instruction Siat time t. Data and control de-
pendences are denoted ‚Üêdand‚Üêc, respectively. Superedges
connect supernodes and regular edges connect regular nodes.
Note that supernodes might contain sub-graphs (consisting
of regular nodes Sit‚ÜêcSjtorSit‚ÜêdSjt); hence the
hierarchical PDG notion. We now explain our dependence
rules, shown in Figure 1.
A. Asynchronous Dependences
Asynchronous data dependence. Intuitively, asynchronous
data dependences capture communication via message passing
(IPC, objects, etc.). We denote the set of registers deÔ¨Åned in
callback c1asDef (c1); and the reference stored in register
vxat time tasref(vx,t). Then, callback instance c2is data-
dependent on callback instance c1(i.e., N1‚ÜêdN2) if at time
t,c1deÔ¨Ånes an inter- or intra-process messaging object (intent)
in a register v1, and c2receives the same reference in register
v2as a parameter. This also introduces a data dependence from
the Ô¨Årst instruction S2tinc2that uses v2, to the instruction
S1tinc1that deÔ¨Ånes v1. Depending on the callback, data
dependence can be inter-app or intra-app; we track both.
Asynchronous control dependence. Effective asyn-
chronous slicing hinges on capturing dependences between
asynchronous events precisely, via superedges N‚ÜêcN2
whenever Ndetermines (initiates) the execution of N2via
1155
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. Asynchronous data dependence Sequential data dependence
N1=/angbracketleftc1,t1,a1,.../angbracketright,N2=/angbracketleftc2,t2,a2,.../angbracketright
v2‚ààparam (c2),v1‚ààDef (c1),r e f (v1,t1)=ref(v2,t2)
N1‚ÜêdN2 S1t‚ÜêdS2tv1‚ààS1t,v2‚ààS2t,v1‚ààdins (S1t),v2‚ààuins (S2t)
ref(v1,t)=ref(v2,t)
S1t‚ÜêdS2t
Asynchronous control dependence Sequential control dependence
N1=/angbracketleftc1,t1,a1,.../angbracketright,N2=/angbracketleftc2,t2,a2,.../angbracketright,a1/negationslash=a2,i n i t i a t o r (N2)=N1,¬¨(N1‚ÜêdN2)
N1‚ÜêcN2isBool (S1t)=true
Sipdt=ipd(S1t),i s Po s t (S2t,Sipdt)=true
S1t‚ÜêcS2tN1=/angbracketleftc1,t1,a1,.../angbracketright,N2=/angbracketleftc2,t2,a2,.../angbracketright,a1/negationslash=a2,i n i t i a t o r (N2)=N1,N1‚ÜêdN2,N0‚ÜêcN1
N0‚ÜêcN2Fig. 1: Dependence rules.
activity context transitions. Being an event-based model, An-
droid‚Äôs runtime system switches between different UI states
(‚ÄúActivity contexts‚Äù) when asynchronous callbacks are in-
voked. Assuming the current activity context is a2, the current
callback is c2whose supernode is N2, the previous activity
context was a1and its ‚Äòexit‚Äô (i.e., callback that triggered
the context transition) was c1whose supernode is N1,w e
use the shorthand initiator (N2)= N1to indicate that N1
has triggered the transition to a2. We deÔ¨Åne two rules that
capture who has initiated N2. The Ô¨Årst rule captures a simple
transition ‚Äì no intent passed between the two events, i.e.,
¬¨(N1‚ÜêdN2).4The second rule applies when N2is data
dependent on N1; in that case, the initiator is that super node
N0thatN1is control-dependent on. We then apply the same
rule recursively on N0. Put otherwise, these two rules help
capture event causality by Ô¨Ånding which event Ncaused event
N2; this is recorded as superedge N‚ÜêcN2.
B. Sequential Dependences
Sequential data dependence is captured by tracking the
propagation of values through instructions sequentially , that
is, control Ô¨Çow does not leave the current callback or its
callees. Note that Android is a register-based machine, hence
registers are used to hold values, pass values in and out of
methods, perform computation, etc. We track memory refer-
ences through these registers. We denote the set of registers
deÔ¨Åned in instruction sasdins (s), and the set of registers
used in instruction sasuins (s). Then, instruction S2tis data-
dependent on instruction S1tif at least one of the registers
v2used in S2tis deÔ¨Åned in S1tin a particular execution
at time t. In other words, this register appears in both the
set of deÔ¨Ånitions dins (S1t)and the set of uses uins (S2t);a
condition also known as V2tbeing ‚Äúlive‚Äù in S2t.
Sequential control dependence. For instructions that are
executed sequentially, certain predicates govern control Ô¨Çow,
i.e., determine which instructions to execute next. Let ipd(si)
be the immediate post dominator of instruction si‚Äì always a
unique instruction sj. The check isP ost (si,sj)returns true
iffsjis a post dominator of si. We deÔ¨Åne S2tas being
control-dependent on S1tifS1tis a conditional (e.g., if) and
S2tbelongs to the set of instructions between S1tand its
immediate post-dominator Sipdt.
4Without loss of generality we ignore other callbacks cthat precede c2
in the current context a2;candc2are both available to dispatching hence
cannot be control-dependent upon each other.TABLE I: AndroidSlicer and Pin comparison.
App Original AndroidSlicer Pin AndroidSlicer
run run run overhead
(s) (s) (s) (%)
Indeed Job Search 15.8 17.1 Crashed at 14.7 8
Geek 29.4 32.2 Crashed at 17.4 9
Scanner Radio 29.5 30.9 Crashed at 15.1 5
Daily Bible 23.9 24.2 Crashed at 23.6 1
CheapOair 21.7 22.8 Crashed at 12.2 5
Kmart 24.5 25.2 Crashed at 14.6 3
IV . A NDROID SLICING CHALLENGES
We now show how the Android programming model/plat-
form introduce challenges for constructing a dynamic slicer,
and discuss how we have overcome these challenges.
A. Low Overhead
Dynamic slicing (as with any dynamic analysis) on mobile
platforms must not interfere with the execution of the app
that is being analyzed. Mobile apps do not tolerate delays
gracefully: we illustrate this with three examples. First, even
just attaching the standard dynamic analyzer Pin [7] to an
Android app ‚Äì a trivial operation on desktop/server ‚Äì can
have unacceptable overhead, or outright crash the app. We
instrumented 6 well-known apps using AndroidSlicer and Pin
(Pintool prints simple instructions). Table I presents the re-
sults. We used Monkey to send the apps 5,000 UI events.
Pin instrumentation crashed all examined apps due to non-
responsiveness5while AndroidSlicer instrumentation had a low
overhead of 5%. Second, introducing delays in GUI event pro-
cessing can alter the semantics of the event: an instrumented
app running slower might interpret one long swipe as two
shorter swipes [9]. Third, harmful interference due to delays
in GPS timing, or in event delivery and scheduling, can easily
derail an execution [10].
Our approach. We address this challenge by optimizing
register tracking at the AF/library boundary. First, in the
runtime tracing phase, for a call into the AF/library we
only track live registers, and only up to the boundary; upon
exiting the AF/library we resume tracking registers. Second,
in the static analysis phase we compute taint (source ‚Üísink)
information to identify those methods that take values upward
to the AF (sources) as well as those methods which return
values downward to the app code (sinks). Finally, in the trace
5https://developer.android.com/reference/java/util/concurrent/TimeoutException
1156
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. processing phase we instantiate the static taint information
with the registers tracked into and out of the framework.
B. High-throughput Wide-ranging Input
Android apps are touch- and sensor-oriented, receiving high-
throughput, time-sensitive input from a wide range of sources.
Typical per-second event rates are 70 for GPS, 54 for the
camera, 386 for audio, and 250 for network [10]. A simple
swipe gesture is 301 events per second [9]. Thus, we require
low-overhead tracking of high-throughput multi-sourced input.
Our approach. Android employs AF-level event handlers
for capturing external events. We achieve both scalability and
precision by intercepting the registers at event processing
boundary, as illustrated next. Swipes are series of touches,
with the event handler onFling(MotionEvent e1,MotionEvent e2,Ô¨Çoat
velocityX ,Ô¨Çoat velocityY ). We intercept the event by tracking
the registers that hold the event handler parameters, i.e., e1,
e2,velocityX ,velocityY , and tagging them as external inputs .
This approach has two advantages. First, register tracking
is efÔ¨Åcient, ensuring scalability. Second, being able to trace
program behavior, e.g., an app crash, to a particular external
input via a backward slice allows developers to ‚ÄúÔ¨Ånd the
needle in the haystack‚Äù and allows us to perform efÔ¨Åcient
and effective fault localization (Sections VI-A and VI-B).
Although our implementation targets Android, it is agnostic
of the low-level OS layer.
C. Inter- and Intra-app Communication
Android relies heavily on IPC. The fundamental IPC mech-
anism is called Intent: using an intent, an activity can start
another activity, or ask another app for a service. For example,
the Facebook app can send an intent to the Camera app asking
it to take a picture; the picture is returned via an intent as
well. There are two types of intents: implicit and explicit .
An implicit intent starts any component that can handle the
intended action without specifying a destination component.
An explicit intent speciÔ¨Åes the destination component (an
Activity instance) by name.
Implicit intents and consequently, inter-app communica-
tions, complicate slicing. We illustrate this in Figure 2.6The
example shows the GetContacts activity that allows the user
to pick a contact. An intent can launch an activity via the
startActivity or startActivity ForResult methods. Upon completion,
Android calls the onActivityResult method with the request code
that we have passed to the startActivity ForResult method (line 5
in the example). Without understanding the impact of inter-
app intents, we would not be able to Ô¨Ånd complete slices.
Assume we want to compute the slice with respect to variable
name starting at statement 14. The resulting slice should contain
statements {14, 9, 10, 12, 13, 8, 11, 5, 4 }. However, traditional
slicing would not Ô¨Ånd the complete slice because it only adds
statements {14, 13, 12, 11, 10, 9 }to the slice ‚Äì it will miss
statements 4 and 5 for two main reasons. First, traditional
6The purpose of the PDGs in Figures 2 and 3 is to compare with traditional
slicing, hence we only show the ‚Äúregular‚Äù PDGs without supernodes. Figures 5
and 6 show supernodes and superedges.slicing fails to pair startActivityForResult with onActivityResult ‚Äì
which are similar to a caller-callee ‚Äì and thus it fails to
reconstruct control Ô¨Çow to account for IPC. Second, note how
we cross memory spaces into the Contacts app, hence we need
to account for Android‚Äôs sandboxing to be able to trace the
initial (request) and result intents.
Explicit intents also complicate slicing, as shown in Fig-
ure 3. The example shows ActivityOne starting ActivityT wo ; the
message ‚Äú Some Value ‚Äù is passed via IPC, the Bundle in this case.
Consider computing the slice with respect to variable value
starting at statement 8. The dynamic slice should contain
statements {8, 7, 4, 3, 2 }. However, traditional slicing cannot
Ô¨Ånd the precise slice because it does not account for intra-app
communication. SpeciÔ¨Åcally, the example uses Bundle ‚ÄôsputExtra
and getExtra to pass data between the two activities; the Bundle is
a system component, so in this case the dataÔ¨Çow is mediated
by the system, and would elude a traditional slicer. Hence
traditional slicing would not traverse statements {4, 3, 2}due
to the missing dependences between the two activities and
would yield slice {8, 7}which would be incorrect .
Our approach. To address challenges due to inter- and
intra-app communication, we analyze app inputs and track
callbacks and AF APIs to construct asynchronous data de-
pendence edges accordingly (Section III-A). For example, if
an activity calls another activity by sending an intent via
startActivity or sendBroadcast , we trace the receiver callback and
the parameter referencing the intent. For example we introduce
data dependences n‚Üêdm, where nis the node associated
with the instruction that sends the broadcast with the intent
as parameter reference in a register vn, while mis the node
associated with the instruction that receives the intent, by
reference, in register vm.
Analyzing intra-app communication is complicated by sev-
eral factors. Android allows developers to only receive in-
tents within the app‚Äôs context for certain internal activities.
Intercepting these intents to construct data-Ô¨Çow facts requires
further analysis of app bytecode. The task can be challenging,
e.g., for intents that receive custom Parcelable objects (Android‚Äôs
form of serialization). To address this challenge, we add
instrumentation routines to track the registers containing intent
references. These intents are passed as parameters in different
AF or API calls.
To summarize, by recording callbacks and intents,
AndroidSlicer captures inter-app and intra-app communication
precisely, with no under- or over-approximation.
V. I MPLEMENTA TION
In this section, we describe AndroidSlicer ‚Äôs implementation.
An overview is shown in Figure 4. In the Ô¨Årst stage, the
app is instrumented to allow instruction tracing. Next, as the
app executes, runtime traces are collected. We perform an on-
demand static analysis to optimize trace processing, and then
compute the PDG. Finally, we calculate slices for a given
slicing criterion. We now discuss each phase.
1157
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. 1 public class GetContacts extends Activity {
2 @Override
3 public void onCreate(Bundle savedInstanceState) {
4 S Intent i = new Intent( Intent .ACTION PICK, Uri.parse(‚Äùcontent://contacts‚Äù));
5 S startActivityForResult ( i , PICK CONT ACT REQUEST);
6}
7 @Override
8 S public void onActivityResult( int requestCode, int resultCode, Intent data) {
9 S if (requestCode == PICK CONT ACT REQUEST) {
10 S if (resultCode == RESUL T OK){
11 S Uri contactData = data.getData();
12 S Cursor c = getContentResolver().querty(contactData,null,null , null , null ) ;
13 S if (c.moveT oFirst()) {
14 S String name =c.getString(c.getColumnIdx(ContactsContract.Ctcs.DISP NAME));
15}}}}}Program


	



 
	


PDG
Fig. 2: Program and its associated PDG. In the program: lines marked with an Sdenote the slice with respect to variable name
on line 14. In the PDG: solid edges denote data dependences; dashed edges denote control dependences; graph nodes marked
with an Mdenote nodes that would be missed by traditional slicing techniques. Labels on solid edges denote the variables
which cause the data dependence.
1 public class ActivityOne extends Activity {...
2 S Intent i = new Intent( this , ActivityT wo.class) ;
3 S i .putExtra(‚ÄùValue‚Äù, ‚ÄùSome Value‚Äù);
4 S startActivity ( i ) ;
5 ...}
6 public class ActivityT wo extends Activity {...
7 S Bundle extras = getIntent () .getExtras() ;
8 S String value = extras.getString( ‚ÄùValue‚Äù);
9 ...}Program 




PDG
Fig. 3: Program and its associated PDG. Lines marked with Sdenote the slice with respect to variable value on line 8.


	

	
		 
	
	
		 
	

 
Fig. 4: AndroidSlicer overview.
A. Instrumentation
The purpose of this stage is three-fold: identify app entry
points; construct method summaries; and add instruction/meta-
data tracing capabilities to the app.
Constructing method summaries. We Ô¨Årst build a call-
graph for each app class from the analyzed app entry points
to create method sumamries (i.e., in/out registers and method
type). For each node in the callgraph (i.e., method) we
add instrumentation tags that summarize that method. This
instrumentation is an extended version of the method sig-
nature present in the Dexcode (Android bytecode); we save
information for parameter registers and return value registers.We also detect callbacks at this time and add necessary
information about input parameters. We identify intents ref-
erenced through registers used as callback parameters and
construct metadata such as caller information (i.e., name of
the callback-generating and broadcasting the intent), as well
as string properties associated with the intent‚Äôs action Ô¨Ålter.
This information helps reveal callers and their callees during
ofÔ¨Çine trace analysis.
Adding tracing instructions. We add tracing capabilities
via Soot [11]. AndroidSlicer ‚Äôs instrumenter takes the app binary
as input; the output is the instrumented app, which we run
on the phone. To support tracing, we inject a new Dexcode
instruction for every app instruction or callback routine we
encounter. The trace format is described next.
B. Runtime Trace Collection
We collect the traces while the instrumented app is running
on the phone. Traces have the format:
trace entry := <t, instruction number offset, instruction , [summary] >
summary := <type, invoked method, parameter registers,
return registers , callback parameter registers,
intent source, intent action Ô¨Ålters >
Trace entries have the following semantics: tis the ac-
tual time the instruction was executed ( tin the model);
instruction number offset is the instruction‚Äôs relative line number
in the printed dex code; instruction is the opcode ( opin the
model); therefore we have the Sitfrom the model. Summary
information is only used for method invocations; it contains
the method‚Äôs type, e.g., an IPC or a non-IPC call, in/out register
values, caller information (i.e., current callback), and, where
applicable, the action string (Ô¨Ålter) associated with the intent.
1158
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. C. On-demand Static Analysis
To build the PDG efÔ¨Åciently, we conduct a post-run on-
demand static analysis that uses the collected runtime infor-
mation to narrow down the scope of the static analysis to
only those app parts that have been exercised during the run.
The advantage of this on-demand approach is that, instead of
statically analyzing the whole program (which for Android
apps raises scalability and precision issues) we only analyze
those methods encountered during execution. The on-demand
analysis phase performs several tasks.
D. Trace Processing and PDG Construction
With the static analysis information at hand, we analyze the
application traces to generate the PDG of that particular exe-
cution. The PDG is built gradually via backward exploration
of dependences, adding nodes and edges as explained shortly.
Our prior static analysis produces two sets: (1) StaticData si
‚Äì the set of static data dependence nodes for an instruction si,
and (2) StaticControl si‚Äì the set of static control dependence
nodes for an instruction si. As mentioned in Section III, sufÔ¨Åx
tdistinguishes between different occurrences of an instruction;
the implementation uses a global counter for this purpose.
Sequential data dependence edges. For every occurrence
of an instruction si, add a data dependence edge to the last
executed occurrence of every instruction in its StaticData si.
Sequential control dependence edges. For every occur-
rence of an instruction si, add a control dependence edge
to the last executed occurrence of every instruction in its
StaticControl si.
Asynchronous data dependence superedges. For every oc-
currence of a callback callee node, add a data dependence to
the last occurrence of its caller . This information is revealed
via static callback analysis. We also identify the instruction
sipct that contains the actual IPC method call in the caller that
passed the intent reference at time t. The callee receives the
intent through one of its parameter registers vintent . We then
identify the last occurrence of the Ô¨Årst instruction in callee at
time tthat uses vintent . Let us name this Sint. We then add
a data dependence Sipct‚ÜêdSint.
Asynchronous control dependence superedges. Based on
our two asynchronous control dependence rules (Figure 1),
if there is no data dependence between the corresponding
supernodes from two consecutive activity contexts, i.e., call-
back callee and its caller (N1andN2), we add a control
dependence superedge N1‚ÜêcN2. Otherwise, we add a
control dependence superedge N0‚ÜêcN2, where N0is the
supernode N1is control-dependent on.
E. Generating Program Slices from the PDG
We now discuss our approach for generating slices given the
PDG and a slicing criterion. Algorithm 1 provides the high-
level description. The slicing criterion /angbracketleftt, st,vs/angbracketrightrepresents the
register vsin instruction sat a particular timestamp t. Since
an instruction is a regular node in the PDG we will use both
terms interchangeably, i.e., strefers to both the exact instance
of the instruction at time tand the PDG node. We maintainAlgorithm 1 Dynamic program slicing
Input: PDG, slicing criterion SliceCriterion =(t, st,vs)
Output: set of nodes OUT st
1:procedure SLICE (SliceCriterion )
2: Ts‚Üê{st}// initialize workset Ts
3: OUT st‚Üê{st}
4: for all nodes nthat are in Tsdo
5: calculate set Pn=Def n‚à™Ctrl n
6: for all nodes n/primeinPndo
7: ifn/primeis a supernode then
8: Expand & extract the last regular node nr
9: Add nrtoDef n
10: else if n/prime‚â°n&Pn/prime‚â°Pnthen
11: Merge (n/prime,n); remove n/primefrom Pn/prime
12: else if previous occurrence of nis in Pn/prime&
Pn/prime‚äÇPnthen
13: Merge (n/prime,n); remove n/primefrom Pn/prime
14: else
15: addn/prime
itoOUT st; add n/primetoTs; remove n
from Ts
16: end if
17: end for
18: end for
19:end procedure
a workset Tsthat holds the nodes yet-to-be-explored (akin to
the working queue in Breadth-Ô¨Årst search). The output OUT st
is the set of distinct nodes in the PDG we encounter while
backward traversing from stto any of the app entry points
affecting the value held in register vs. We Ô¨Årst traverse the
edges in the PDG starting from stand create a dynamic data
dependence table Def nand a control dependence table Ctrl n
for each node non paths to entry points. For each regular node
n/primein the set Pn=Def n‚à™Ctrl nwe add n/primetoOUT st.I fn/prime
is a supernode and n/prime‚ààDef nwe expand n/prime. The expansion
adds the last occurrence of the regular node nrinside n/primethat
broadcasts an intent to Def nand recalculates Pn. Note that
nrpasses the IPC reference (intents) in a register to the next
supernode, and hence it should be included in the slice. Since
the same instruction can appear multiple times because of
different occurrences at different timestamps, this procedure
adds nodes with the same instructions to the slice for each
occurrence. This increases the size of the slice. To reduce the
number of nodes in OUT stwe make two optimizations.
1. Node merging. Given different occurrences (i.e., at times
tandt/prime) of a regular node (i.e., n‚â°st,n/prime‚â°st/prime)i fPn=Pn/prime
we merge nandn/primeintonmerged . For two different occurrences
NandN/primeof the same supernode, we also apply merging: if
NandN/primehave incoming or outgoing data dependence edges
we expand the nodes and merge the individual instructions,
i.e., regular nodes inside them; if NandN/primeare connected by
control dependence edges only, we merge them.
2. Loop folding. In loops, for every new occurrence of a
loop body instruction s, we will add a new node in the slice.
1159
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. But these nodes may point to the same set of data and control
dependence in the PDG ‚Äì they are different occurrences of
s. To reduce these duplications, we merge two distinct nodes
nandn/primein the loop if the following conditions are met: (a)
current occurrence of n/primedepends on the previous execution
ofn; (b) current occurrence of ndepends on the current
occurrence of n/prime; and (c) Pn/prime‚äÇPn.
Let us call the new node created after the merge nmerged .
Each time we Ô¨Ånd a different occurrence of the merged node
we compute the set Pnmerged . Then we apply reduction rule 1
to further reduce it to a single node.
F . Limitation
Since AndroidSlicer ‚Äôs instrumenter is based on Soot, it inherits
Soot‚Äôs static analysis size limitations, e.g., we could not handle
extremely large apps such as Facebook. Note that this is not a
slicing limitation per se, but rather a static analysis one, and
could be overcome with next-generation static analyzers.
VI. A PPLICA TIONS
We describe three applications that leverage AndroidSlicer to
facilitate debugging and testing Android apps.
A. Failure-inducing Input Analysis
This analysis Ô¨Ånds the input parts responsible for a crash
or error. Note that unlike traditional programs where input
propagation and control Ô¨Çow largely depend on program logic,
in event-driven systems propagation depends on the particular
ordering of the callbacks associated with asynchronous events .
Leveraging our PDG, we can reconstruct the input‚Üí...‚Üí
failure propagation path.
Problem statement. LetIbe the set of app inputs I1,I2, ...
(e.g., coming from GUI, network, or sensors) through registers
v1,v2, .... Let the faulty register be verr, i.e., its value deviates
from the expected value (including an incorrect numeric value,
crash, or exception). Hence the analysis‚Äô input will be the
tuple/angbracketleftI,v err,PD G/angbracketrightwhile the output will be a sequence of
registers v1,v2, ..., v nalong with the callbacks c1,c2, ..., c m
the registers are used in.
Tracking input propagation. In the PDG, for every asyn-
chronous callback, we can create an input propagation path by
tracking the data dependence for the value of any register vi.
We determine whether the values propagated through registers
are inÔ¨Çuenced by any of the app inputs I. This is particularly
useful for identifying faults due to corrupted Ô¨Åles or large
sensor inputs (e.g., a video stream).
Example. We illustrate our analysis on an actual bug, due
to a malformed SQL query, in Olam , a translator app.7The
app takes an input word from a text box and translates it. In
Figure 5 (top) we show the relevant part of the code: the num-
ber of distinct dynamic instances of an instruction(left), the
actual instruction (center) and the value propagation through
registers v1,v2, ..., v nalong the PDG edges (right). In the
method getSimilarItems , the app attempts to query the SQLite
database, which generates an exception, resulting in a crash.
7https://play.google.com/store/apps/details?id=com.olamThe exception trace from the Android event log indicates that
the query is ill-formed. The PDG (bottom left) points out the
callback in which the exception was thrown: the onClick event
associated with the search button in the MainSearch activity. We
analyze the event inputs by following the data dependence
edges backwards and see that the registers‚Äô values are pointing
towards the input text from the textbox editT ext . We compute
the slice using the faulty register reference as slicing criterion.
The execution slice is shown in Figure 5: we see that the ill-
formatted string was stored in register v1. Our approach back-
propagates the value of v1through the slices to determine
whether it was impacted by any part of the input. Back-
propagation starts from the error location, i.e., instruction
instance 29754 . The value propagates to register v5which
references the return value from getT ext invoked on an
instance of v4that is pointing to the GUI control element
EditT extBox . Our analysis ends by returning the register v5with
the corresponding callback information. The second part of
the Ô¨Ågure shows the associated supernodes which reveal that
the executed slices belong to the MainSearch:onClick callback. The
failure-inducing input was thus essentially identiÔ¨Åed analyzing
a much smaller set of instructions, and more importantly, in
the presence of non-deterministic callback orders.
B. Fault Localization
This analysis helps detect and identify the location of a fault
in an app. For sequential programs, fault localization is less
challenging in the sense that it does not need to deal with the
non-determinism imposed by asynchronous events. Android
apps are not only event-driven but also can accept inputs at
any point of the execution through sensors, Ô¨Åles, and various
forms of user interactions. For this reason, fault localization
on Android can be particularly challenging for developers.
Problem statement. The input to the analysis will be the
application trace, and the register verrholding the faulty value
in a speciÔ¨Åc occurrence of an instruction. The output this time
will be the sequence of instructions s1,s2, ..., s nthat deÔ¨Åne
and propagate the value referenced in verr.
Tracking fault propagation. Our slicing approach aids
fault localization as follows. Given a fault during an execution,
we determine the faulty value reference inside a register
verr by mapping the Android event log to our execution
trace. Then we compute the execution slice for verr by back
propagating through the execution slice. While we traverse
the PDG backwards, we consider asynchronous callbacks and
their input parameters if they have a direct data or control
dependence to the Ô¨Ånal value of verr. This way, we can both
handle the non-determinism of the events and also support the
random inputs from internal and external sources.
Example. We illustrate our approach on a real bug in
the comic book viewing app ACV .8Figure 6 shows the
generated sequential and asynchronous dependences for the
faulty execution. The bug causes a crash when the user opens
the Ô¨Åle explorer to choose a comic book. If the user long-taps
8https://play.google.com/store/apps/details?id=net.androidcomics.acv
1160
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. :A?=<.$"$#.//$# ".5(=B("$'(5(;/C"/$#/#!$/
$$#."/$#/'"#"
")'"+0(//$"-(//$"231D0 &)-'1 	 	
:A?=;.$"$#.//$# ".5(9B("$'( &*/C(//$"'".(//$"$$"01D01
:A?<A.$"$#.//$# ".5(<B("$'(5(</C(//$"'".(//$"'"  0(//$"1D0 &)1
:A?<:.	"'.//"5".5(AB("$'(5(@/C//$# ".(/'%/ 
$"$#0(//$"1D0 &-1
:@<=9.	"'.//"5".5(?B &(/C//"5".(//$"#"$"D
:@<<8.	"'.//"5".5(8/C//"5".(//$"#"$"DB &-
:@<;A.	"'.//"5".5(?B("$'( &,/C(//$.(//$"$$"01D01
:@<;@.	"'.//"5".5(>B("$'( &+/C"/)$/$*$."/$*$/$$*$01D01
:@<;?.	"'.//"5".5(=B0"/)$/$*$15(<
:@<9;..//"59.("$'(5(@/C//"5"."/#/#+#*'$0(//$231D05(A1#)$
#*$
#)$
#-$
#($
#-$
#,$
#+$
)$
*$
)$
-$
($
-$
,$
+$
	 '$" %
,! *! )!
""
	"' $"$# $"$#
0"*1

"$
0"1' "#
"" " 
!'%$ #	#$"'%'".	#$"'% ' " %
Fig. 5: Failure-inducing input analysis.
?9=;. 	$
 .$/"  $/(/'/" )#"%($+5:.58A$  %+-

 
?9=:. 	$
 .$/"  $/(/'/" )#"%($+5:.5(>A("$'(  %*B(/ /.(//$"23
#$0(/ /$"1C05(=1
?9<<. 	$
 .$/"  $/(/'/" )#"%($+5:.5(<A0(/ /1 %)
?9<;.$	$.$/"  $/(/'/" )#"%($+5
#$!$".5(;A0(/ /1 %(
?9<:.$	$.$/"  $/(/'/" )#"%($+5
#$!$".5(:A("$'(  %'/B(/'%/""+
#$.(//$
$0$1C0581
‚Ä¶
>@8;.$).$/"  $/(/'/" )#"%($+5
#$!$".5(9A("$'(  %)B(/ /.(//$"/$01C01






 	


!	#$"'% '".	#$"'% 
*$%($+ $"$
 )"%($+ #'
 
 "!"!% #'
 !% #	$$
  #
" )#"%($+ "$ )"%($+ (	#$$$
 $ !
 )"%($+ $ !
*$%($+ $ !
" )#"%($+ 	$
 
" "
!"! '$!" !% 
"%'#"%*#
"%)#
"%(#"%+#
"%)#
Fig. 6: Fault localization.
on an inaccessible directory, the app crashes with a nullpointer
exception. From Figure 6 we can see that the object reference
stored in register v6at instruction 7153 was the primary cause
of the error. The corresponding callback is revealed to be
onItemLongClick in activity SDBrowserActivity . Our analysis tracks
back the object reference in v6through the slices, reaching
instruction 6803 . Here we can see a Ô¨Åle system API invocation
(java. io . File .getName() ) that attempts to return a Ô¨Ålename, but fails
because the Ô¨Åle‚Äôs directory is inaccessible. Our value propaga-
tion ends here, revealing the source of the error. We return the
set of instructions {6803 , ...,7142 ,7143 ,7144 ,7152 ,7153},
and the traversed PDG nodes. For simplicity, we only show
the data dependence edges and relevant parts of the slices. Our
approach then back-propagates through the PDG according
to the execution slice to localize the fault (for presentation
simplicity we have combined consecutive supernodes in the
same activity into a single node).
C. Regression Test Suite Reduction
Regression testing validates that changes introduced in a
new app version do not ‚Äúbreak‚Äù features that worked in the
previous version. However, re-running the previous version‚Äôs
entire test suite on the new version is time-consuming and
inefÔ¨Åcient. Prior work [12], [13] has shown that slicing reducesthe number of test cases that have to be rerun during regression
testing (though for traditional apps).
Problem statement. Given two app versions (V 1and V 2),
and a test suite T 1(set of test cases) that has been run on V 1,
Ô¨Ånd T 2, the minimal subset of T 1, that needs to be rerun on
V2to ensure that V 2preserves V 1‚Äôs functionality.
Test case selection. Agrawal et al. [12] used dynamic slic-
ing to Ô¨Ånd T 2as follows: given a program, its test cases, and
slices for test cases, after the program is modiÔ¨Åed, rerun only
those test cases whose slices contain a modiÔ¨Åed statement.
This reduces the test suite because only a subset of program
statements (the statements in the slice) have an effect on the
slicing start point (program output, in their approach [12]).
However, this technique can be unsound, because it only
considers whether a statement has been modiÔ¨Åed, not how
it has been modiÔ¨Åed . When the changed instructions affect
predicates leading to an asynchronous control dependence
(see Section III-A), missed control dependences will lead to
potentially missing some test cases. Our approach considers
such dependences to maintain soundness.
VII. E V ALUA TION
We Ô¨Årst evaluate AndroidSlicer ‚Äôs core slicing approach; next,
we evaluate it on the three applications from Section VI.
1161
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. TABLE II: AndroidSlicer evaluation: core slicing results.
App Dex Installs Instructions Log CD Callback Time (seconds) Over-
code Executed In slice size +DD events Stage 1 Original Stage 2 Stage 3 head
size (KB) (thousands) (KB) Instrumentation run Instrumented run Slicing (%)
Twitter 50,688 500,000-1,000,000 107,847 559 11,623 790 557 293.5 233.4 245.2 40.3 5
Evernote 7,219 100,000-500,000 191,304 22 20,377 34 17 81.3 221.7 228.6 45.9 3
Du Recorder 62,338 50,000-100,000 36,672 316 3,187 409 31 41.0 245.1 254.8 53.7 4
Indeed Job Search 2,458 50,000-100,000 21,752 246 3,399 356 235 24.0 222.2 230.3 12.1 4
Twitch 30,106 50,000-100,000 2,025,505 5,969 219,850 9,429 5,965 144.2 260.3 281.9 103.0 8
Across min 47 10-50 17 2 1.6 3 1 2.3 205.4 212.8 2.0 0
all 60 median 1,485 500‚Äì1000 14,491 44 2,195 63 23 19.1 229.85 239.7 11.9 4
apps max 78,684 500,000-1,000,000 2,025,505 5,969 219,850 9,429 5,965 293.5 260.7 281.9 103.0 14
Environment. An LG Nexus 5 phone (Android version
5.1.1, Linux kernel version 3.4.0, 2.3 GHz processor) for
online and an Intel Core i7-4770 CPU (3.4 GHz, 24 GB RAM,
64-bit Ubuntu 14.04 version 4.4.0) for ofÔ¨Çine processing.
A. Core Slicing
App dataset. We ran AndroidSlicer on 60 apps selected
from a wide range of categories (shopping, entertainment,
communication, etc.) with various bytecode sizes. In Table II
we present detailed results for the top-5 apps sorted by number
of installs. We summarize the Ô¨Åndings (min/median/max) in
the last three rows. The second column and third column
show the app‚Äôs bytecode size (median size = 1,485 KB).
and popularity (number of installs, in thousands , per Google
Play as of August 2018) respectively. 28 apps had more than
one million installs (median popularity 500,000 - 1,000,000
installs).
Generating inputs and slicing criteria. To drive app
execution, we used Monkey [14] to send the app 1,000
UI events and then collected traces for ofÔ¨Çine analysis. To
measure AndroidSlicer ‚Äôs runtime overhead, same event sequence
was used in instrumented and uninstrumented runs. As slicing
criteria, variables were selected to cover all types of regis-
ters ( local variables, parameters, Ô¨Åelds) from a variety of
instructions (static invokes, virtual invokes, conditions, method
returns). This allows us to draw meaningful conclusions about
slicing effectiveness and efÔ¨Åciency.
Correctness. We manually analyzed 10 out of the 60 apps to
evaluate AndroidSlicer ‚Äôs correctness. The manual analysis effort
in some apps can be too high, because of the large number
of instructions and dependences (e.g., in the T witch app, there
are 5,969 instructions in the slice and 9,429 dependences).
Therefore, we picked 10 apps whose traces were smaller and
veriÔ¨Åable within a reasonable amount of effort. We decompiled
each app to get the Java bytecode, and manually computed the
slices w.r.t. the slicing criterion. The slices were then compared
with AndroidSlicer ‚Äôs; we conÔ¨Årmed that slice computation is
correct.
Effectiveness. Table II demonstrates that AndroidSlicer is
effective. The ‚ÄúInstructions Executed‚Äù column shows the total
number of instructions executed during the entire run. The
median number of instructions is 14,491. If the programmer
has to analyze these, the analysis task will be challenging.
AndroidSlicer reduces the number of instructions to be analyzed
to44, i.e., 0.3% (column ‚ÄúInstructions In slice‚Äù). The ‚ÄúLog
size‚Äù column shows the storage size required for traces. Themedian number of dependences to be analyzed, data and
control, is not much larger, 63, (column ‚ÄúCD+DD‚Äù). The next
column shows the number of callback events Ô¨Åred during the
run: the median was 23 across all apps.
EfÔ¨Åciency. The remaining columns (‚ÄúTime‚Äù and ‚ÄúOver-
head‚Äù) show that AndroidSlicer is efÔ¨Åcient. Stage 1 (instru-
mentation), typically takes just 19.1 seconds, and at most
293.5 seconds for the 50.6 MB T witter app. The ‚ÄúOriginal
run‚Äù column shows the time it took to run the uninstrumented
app ‚Äì typically 229.85 seconds, and at most 260.7 seconds.
Column ‚ÄúStage 2 Instrumented run‚Äù shows the time it took to
run the instrumented app, while collecting traces. The typical
run time increases to 239.7 seconds. The ‚ÄúOverhead‚Äù column
shows the percentage overhead between the instrumented and
uninstrumented runs; the typical Ô¨Ågure is 4% which is very
low not only for dependence tracking, but for any dynamic
analysis in general. Furthermore, our instrumentation strategy
does not require monitoring the app or attaching the app
to a third-party module ‚Äì this allows the app to run at its
native speed. We emphasize that AndroidSlicer ‚Äôslow overhead
is key to its usability, because Android apps are timing-
sensitive (Section IV-A). Finally, the ‚ÄúStage 3 Slicing‚Äù column
shows post-processing time, i.e., computing slices from traces,
including on-demand static analysis; this time is low, typically
just 11.9 seconds, and at most 103 seconds.
B. Failure-inducing Input Analysis
We evaluated this application on real bugs in 6 sizable apps
(Table III) by reproducing the bug traces. Our failure-inducing
input analysis is very effective at isolating instructions and
dependences of interest ‚Äì the number of executed instructions
varies from 320 to 182,527, while slices contain just 16‚Äì57
instructions. The CD and DD numbers are also low: 18‚Äì73.
C. Fault Localization
We evaluated our approach on 7 apps. Table IV shows the
results. Note how fault localization is effective at reducing the
number of instructions to be examined from thousands down
to several dozen. SoundCloud and NPR News have large slices
due to intense network activity and background services (audio
playback), which increase the callback count substantially.
D. Regression Test Suite Reduction
We evaluated our reduction technique on 5 apps. For each
app, we considered two versions V 1and V 2and ran a test
suite T 1that consisted of 200 test cases; on average, the suite
achieved 62% method coverage. Next, we used AndroidSlicer to
1162
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. TABLE III: AndroidSlicer evaluation: Failure-inducing input analysis.
App Dex Installs Instructions Log CD+ Call- Time (seconds) Over-
code Executed In slice size DD back Stage 1 Original Stage 2 Stage 3 head
size (KB) (thousands) (KB) events Instrumentation run Instrumented run Slicing (%)
Etsy 5,400 10,000‚Äì50,000 182,527 19 20,623 24 9 94 8.7 10.4 129.2 19
K-9 Mail 1,700 5,000‚Äì10,000 13,042 30 1,937 34 16 89.1 107.4 125.3 58.8 16
AnyPlayer M. Player 780 100‚Äì500 26,936 16 3,714 18 11 21.9 7.6 7.8 17.2 2
Olam M. Dictionary 651 100‚Äì500 31,599 57 3,802 73 22 17.3 46.7 50.1 19.4 3
VuDroid 475.5 100‚Äì500 320 21 38 27 20 8.7 6.2 6.7 6.4 8
Slideshow 3,700 10‚Äì50 68,013 43 9,918 52 22 52.6 7.2 8.1 28.9 12
TABLE IV: AndroidSlicer evaluation: Fault localization.
App Dex Installs Instructions Log CD+ Call- Time (seconds) Over-
code Executed In slice size DD back Stage 1 Original Stage 2 Stage 3 head
size (KB) (thousands) (KB) events Instrumentation run Instrumented run Slicing (%)
SoundCloud 516.3 100,000‚Äì500,000 9,590 128 1,910 173 62 41.7 63.5 71.6 32.7 9
Notepad 44.2 10,000‚Äì50,000 2,366 15 343 17 6 4.5 36.5 41 9.1 12
A Comic Viewer 569.1 1,000‚Äì5,000 12,679 18 2,007 24 13 26.7 52.6 61.3 18.7 16
AnkiDroid Flashcards 804.6 1,000‚Äì5,000 27,164 32 3,722 38 27 87.6 17.3 19.5 28.7 12
APV PDF Viewer 52.9 1,000‚Äì5,000 24,672 67 3,436 79 45 11 10.3 11.2 27.2 8
NPR News 285.1 1,000‚Äì5,000 45,298 239 5,473 327 107 28.7 49.3 52.7 42.5 6
Document Viewer 3,900 500‚Äì1000 5,451 8 854 11 2 11.2 34 36.1 9 6
TABLE V: AndroidSlicer evaluation: Regression testing.
App Dex code Installs Test Covered Instructions Reduced
size V 1‚ÄìV2 suite methods test
(KB) size (%) V1 V2 suite
Mileage 443.8-471.3 500-1,000 200 66 28,252 36,531 22
Book Catalogue 444.9-445.4 100-500 200 69 28,352 28,450 7
Diary 125.5-129.8 100-500 200 53 4,591 4,842 47
Root V eriÔ¨Åer 462.9-1700 100-500 200 58 23,482 83,170 5
Traccar Client 49.4-51.6 50-100 200 66 1,833 1,937 8
compute the reduced test suite as described in Section VI-C.
Table V shows the results: the bytecode sizes for V 1and
V2, the number of installs, the coverage attained by T 1on
V1, and the instructions executed when testing V 1and V 2,
respectively. The last column shows the size of T 2. Notice
how our approach is very effective at reducing the test suite
size from 200 test cases down to 5‚Äì47 test cases.
VIII. R ELA TED WORK
Slicing event-based programs has been investigated for
Web applications [6], [15], [16] written in HTML, PHP , and
JavaScript. These approaches record traces through a browser
plugin [6] and construct the UI model to generate the event
nodes. While both Web and Android apps are event-based,
their slicing approaches differ signiÔ¨Åcantly. First, due to the
Android apps‚Äô life-cycle, they run in different scopes (i.e., ac-
tivity, app, system), and handle various sets of requests (launch
another activity, respond to action, pass data). In contrast, Web
apps have different build phases, such as UI building phase
(HTML nodes) and event-handling phase (JavaScript nodes).
Second, unlike in Android, a Web app slicing tool (e.g., as a
browser plugin) does not require low-overhead. Third, Android
requires IPC tracking; that is not the case for Web.
Traditional program slicing of Java bytecode has only
targeted single-entry sequential Java programs [17]‚Äì[20]. Zhou
et al. [21] and Zeng et al. [22] have used bytecode slicing for
Android apps, but to achieve entirely different goals: mining
sensitive credentials inside the app and generating low-level
equivalent C code. They create slices at bytecode level andconsider data dependences only; this makes the approach
imprecise as there is no tracking of code dependences or
accounting for many Android features (e.g., callbacks, IPC,
input from sensors).
Compared to Agrawal and Horgan‚Äôs slicing for traditional
programs [23], we add support for Android‚Äôs intricacies, node
merging for control dependence edges, dealing with slicing
in the presence of restarts as well as asynchronous callback
invocation. We support loop folding for regular nodes inside
the supernodes. Slicing multithreaded programs is tangentially
related work, where slicing was used to debug multithreaded
C programs [24]‚Äì[28] ‚Äî this setup differs greatly from ours.
Hoffmann et. al. developed SAAF [29], a static slicing
framework for Android apps. A static slicing framework such
as SAAF would not be sufÔ¨Åcient to achieve our goals as it
does not consider myriad aspects, from late binding to the
highly dynamic event order in real-world Android apps.
IX. C ONCLUSIONS AND FUTURE WORK
We presented AndroidSlicer , a novel slicing approach and
tool for Android that addresses challenges of event-based
model and unique traits of the platform. Our asynchronous
slicing approach that is precise yet low-overhead, overcomes
the challenges. Experiments on real Android apps show that
AndroidSlicer is effective and efÔ¨Åcient. We evaluated three
slicing applications that reveal crashing program inputs, help
locate faults, and reduce the regression test suite.
In the future we plan to investigate forward slicing [30],
[31] and language-agnostic slicing that would permit slicing
apps containing code written in different programming lan-
guages [32].
ACKNOWLEDGMENT
This material is based upon work supported by the National
Science Foundation under Grants CNS-1617424 and CNS-
1617584.
1163
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] B. Popper, ‚ÄúGoogle announces over 2 billion monthly active
devices on android,‚Äù https://www.theverge.com/2017/5/17/15654454/
android-reaches-2-billion-monthly-active-users, accessed: August 23,
2018.
[2] B. Zhou, I. Neamtiu, and R. Gupta, ‚ÄúExperience report: How do bug
characteristics differ across severity classes: A multi-platform study,‚Äù in
Software Reliability Engineering (ISSRE), 2015 IEEE 26th International
Symposium on , Nov 2015, pp. 507‚Äì517.
[3] ‚Äî‚Äî, ‚ÄúA cross-platform analysis of bugs and bug-Ô¨Åxing in open source
projects: Desktop vs. android vs. ios,‚Äù in 19th International Conference
on Evaluation and Assessment in Software Engineering, EASE 2015 ,
April 2015, p. 10.
[4] B. Korel and J. Laski, ‚ÄúDynamic program slicing,‚Äù Information Process-
ing Letters , vol. 29, pp. 155‚Äì163, October 1988.
[5] N. Sasirekha, A. E. Robert, and M. Hemalatha, ‚ÄúProgram slicing
techniques and its applications,‚Äù CoRR , vol. abs/1108.1352, 2011.
[Online]. Available: http://arxiv.org/abs/1108.1352
[6] J. Maras, J. Carlson, and I. Crnkovic, ‚ÄúClient-side web application
slicing,‚Äù in ASE , 2011.
[7] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,
S. Wallace, V . J. Reddi, and K. Hazelwood, ‚ÄúPin: Building
customized program analysis tools with dynamic instrumentation,‚Äù in
Proceedings of the 2005 ACM SIGPLAN Conference on Programming
Language Design and Implementation , ser. PLDI ‚Äô05. New Y ork,
NY , USA: ACM, 2005, pp. 190‚Äì200. [Online]. Available: http:
//doi.acm.org/10.1145/1065010.1065034
[8] Android Developers, ‚ÄúApp Components,‚Äù 2017, https://developer.
android.com/guide/components/index.html.
[9] L. Gomez, I. Neamtiu, T. Azim, and T. Millstein, ‚ÄúReran: Timing- and
touch-sensitive record and replay for android,‚Äù in ICSE , 2013.
[10] Y . Hu, T. Azim, and I. Neamtiu, ‚ÄúV ersatile yet lightweight record-and-
replay for android,‚Äù in Proc. of the 2015 ACM SIGPLAN International
Conference on Object-Oriented Programming, Systems, Languages, and
Applications , ser. OOPSLA 2015. ACM, 2015, pp. 349‚Äì366.
[11] R. V all ¬¥ee-Rai, P . Co, E. Gagnon, L. Hendren, P . Lam, and V . Sundaresan,
‚ÄúSoo t-aj a v a bytecode optimization framework,‚Äù in Proceedings of the
1999 Conference of the Centre for Advanced Studies on Collaborative
Research , ser. CASCON ‚Äô99. IBM Press, 1999, pp. 13‚Äì. [Online].
Available: http://dl.acm.org/citation.cfm?id=781995.782008
[12] H. Agrawal, J. R. Horgan, E. W. Krauser, and S. London,
‚ÄúIncremental regression testing,‚Äù in Proceedings of the Conference
on Software Maintenance , ser. ICSM ‚Äô93. Washington, DC, USA:
IEEE Computer Society, 1993, pp. 348‚Äì357. [Online]. Available:
http://dl.acm.org/citation.cfm?id=645542.658149
[13] R. Gupta, M. J. Harrold, and M. L. Soffa, ‚ÄúAn approach to regression
testing using slicing,‚Äù in Proceedings Conference on Software Mainte-
nance 1992 , Nov 1992, pp. 299‚Äì308.
[14] Android Developers, ‚ÄúUI/Application Exerciser Monkey,‚Äù November
2017, http://developer.android.com/tools/help/monkey.html.
[22] J. Zeng, Y . Fu, K. A. Miller, Z. Lin, X. Zhang, and D. Xu, ‚ÄúObfuscation
resilient binary code reuse through trace-oriented programming,‚Äù in
Proceedings of the 2013 ACM SIGSAC Conference on Computer &#38;
Communications Security , ser. CCS ‚Äô13, 2013, pp. 487‚Äì498.[15] P . Tonella and F. Ricca, ‚ÄúWeb application slicing in presence of dynamic
code generation,‚Äù Automated Software Engg. , pp. 259‚Äì288.
[16] F. Ricca and P . Tonella, ‚ÄúConstruction of the system dependence
graph for web application slicing,‚Äù in Proceedings of the Second IEEE
International Workshop on Source Code Analysis and Manipulation , ser.
SCAM ‚Äô02, 2002, pp. 123‚Äì.
[17] Wang, T. and Roychoudhury, A., ‚ÄúUsing compressed bytecode traces
for slicing java programs,‚Äù 2004.
[18] T. Wang and A. Roychoudhury, ‚ÄúDynamic slicing on java bytecode
traces,‚Äù ACM Trans. Program. Lang. Syst. , pp. 10:1‚Äì10:49, 2008.
[19] ‚Äújslice,‚Äù November 2017, http://jslice.sourceforge.net/.
[20] A. Szegedi and T. Gyimothy, ‚ÄúDynamic slicing of java bytecode pro-
grams,‚Äù 2013 IEEE 13th International Working Conference on Source
Code Analysis and Manipulation (SCAM) , pp. 35‚Äì44, 2005.
[21] Y . Zhou, L. Wu, Z. Wang, and X. Jiang, ‚ÄúHarvesting developer creden-
tials in android apps,‚Äù in Proceedings of the 8th ACM Conference on
Security & Privacy in Wireless and Mobile Networks , ser. WiSec ‚Äô15,
2015, pp. 23:1‚Äì23:12.
[23] H. Agrawal and J. R. Horgan, ‚ÄúDynamic program slicing,‚Äù in Proceed-
ings of the ACM SIGPLAN 1990 Conference on Programming Language
Design and Implementation , ser. PLDI ‚Äô90, 1990, pp. 246‚Äì256.
[24] X. Zhang, S. Tallam, and R. Gupta, ‚ÄúDynamic slicing long running
programs through execution fast forwarding,‚Äù ser. SIGSOFT ‚Äô06/FSE-
14, 2006, pp. 81‚Äì91.
[25] S. Tallam, C. Tian, R. Gupta, and X. Zhang, ‚ÄúEnabling tracing of long-
running multithreaded programs via dynamic execution reduction,‚Äù ser.
ISSTA ‚Äô07, 2007, pp. 207‚Äì218.
[26] S. Tallam, C. Tian, and R. Gupta, ‚ÄúDynamic slicing of multithreaded
programs for race detection,‚Äù in ICSM‚Äô08 , 2008, pp. 97‚Äì106.
[27] D. Weeratunge, X. Zhang, W. N. Sumner, and S. Jagannathan, ‚ÄúAna-
lyzing concurrency bugs using dual slicing,‚Äù ser. ISSTA ‚Äô10, 2010, pp.
253‚Äì264.
[28] Y . Wang, H. Patil, C. Pereira, G. Lueck, R. Gupta, and I. Neamtiu,
‚ÄúDrdebug: Deterministic replay based cyclic debugging with dynamic
slicing,‚Äù in Proceedings of Annual IEEE/ACM International Symposium
on Code Generation and Optimization , ser. CGO ‚Äô14. New Y ork,
NY , USA: ACM, 2014, pp. 98:98‚Äì98:108. [Online]. Available:
http://doi.acm.org/10.1145/2544137.2544152
[29] J. Hoffmann, M. Ussath, T. Holz, and M. Spreitzenbarth, ‚ÄúSlicing droids:
Program slicing for smali code,‚Äù in Proceedings of the 28th Annual ACM
Symposium on Applied Computing , ser. SAC ‚Äô13, New Y ork, NY , USA,
2013, pp. 1844‚Äì1851.
[30] D. Binkley, S. Danicic, T. Gyimothy, M. Harman, A. Kiss, and B. Korel,
‚ÄúTheoretical foundations of dynamic program slicing,‚Äù in Theoretical
Computer Science , 2006, pp. 23‚Äì41.
[31] S. Horwitz, T. Reps, and D. Binkley, ‚ÄúInterprocedural slicing using
dependence graphs,‚Äù in ACM Transactions on Programming Languages
and Systems , 1990, pp. 26‚Äì61.
[32] D. Binkley, N. Gold, M. Harman, S. Islam, J. Krinke, and S. Y oo, ‚ÄúOrbs:
Language-independent program slicing,‚Äù in Proceedings of the 22Nd
ACM SIGSOFT International Symposium on F oundations of Software
Engineering , ser. FSE 2014. ACM, 2014.
1164
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:41:52 UTC from IEEE Xplore.  Restrictions apply. 