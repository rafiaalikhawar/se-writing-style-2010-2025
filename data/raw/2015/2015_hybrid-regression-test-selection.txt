Hybrid Regression Test Selection
Lingming Zhang
The University of Texas at Dallas
lingming.zhang@utdallas.edu
ABSTRACT
Regressiontestingiscrucialbutcanbeextremelycostly.Regression
Test Selection (RTS) aims to reduce regression testing cost by only
selectingandrunningtheteststhatmaybeaffectedbycodechanges.
Todate,variousRTStechniquesanalyzingatdifferentgranularities
(e.g.,atthebasic-block,method,andfilelevels)havebeenproposed.
RTStechniquesworkingonfinergranularitiesmaybemorepreciseinselectingtests,whiletechniquesworkingoncoarsergranularities
may have lower overhead. According to a recent study, RTS at
the file level (FRTS) can have less overall testing time compared
with a finer grained technique at the method level, and represents
state-of-the-art RTS. In this paper, we present the first hybrid RTS
approach,HyRTS,thatanalyzesatmultiplegranularitiestocombine
thestrengthsoftraditionalRTStechniquesatdifferentgranularities.
We implemented the basic HyRTS technique by combining the
method and file granularity RTS. The experimental results on 2707
revisionsof32projects,totallingover124MillionLoC,demonstratethatHyRTSoutperformsstate-of-the-artFRTSsignificantlyinterms
of selected test ratio and the offlinetesting time. We also studied
the impacts of each type of method-level changes, and further
designed two new HyRTS variants based on the study results. Our
additionalexperimentsshowthattransforminginstancemethod
additions/deletions into file-levelchanges produces an evenmore
effective HyRTS variant that can significantly outperform FRTS in
bothofflineandonlinetesting time.
ACM Reference Format:
Lingming Zhang. 2018. Hybrid Regression Test Selection. In ICSE â€™18: ICSE
â€™18: 40th International Conference on Software Engineering , May 27-June
3, 2018, Gothenburg, Sweden. ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/3180155.3180198
1 INTRODUCTION
Regressiontestinghasbeenwidelyusedtoensurethatsoftwareevo-
lution does not break existing functionalities. However, simply re-
runningentireregressiontestsuitescanbeextremelytimeconsum-ing,e.g.,somereal-worldtestsuitestakeweekstorun[
38].Besides,
regressiontestingcanalsoconsumealotofcomputingresources,
e.g.,Googlehasover100Milliontestsrunningeachday,occupying
variousmachinesandclusters[ 7,8,20,33].Asaresult,shownin
apriorsurveybyYooandHarman[ 47],variousapproacheshave
beenproposedtoreducethecostsofregressiontesting,including
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Â© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.3180198regressiontestselection[ 15,21,23,26,27,34,35,37,46,50],regres-
sion test-suite reduction [ 17,18,24,28,41,43,51,52], regression
test-case prioritization [19, 25, 32, 38, 40, 48, 49].
Regression Test Selection (RTS) [ 13,15,21,23,26,34,35,37,46,
50]aimstoselectandrunonlytheteststhatareaffectedbycode
changes,sincethetestsnotaffectedbycodechangesshouldhave
the same results with prior runs. In this way, RTS can greatly save
the regression testing efforts, and has been widely used in prac-
tice[23,30,42].AtypicalRTStechniquerequirestwodimensionsof
information: (1) the test dependency information (i.e., the program
elementsthatcanbeexecutedduringeachtestexecution)onanold
programversion,(2)thechangedprogramelements.Then,a safe
RTStechniqueselectsanytestwhosedependenciesoverlapwith
thechangedprogramelementsastheaffectedtests,sincemissing
any of those tests may fail to detect some regression bugs.
Dependingonhowthetestdependenciesarecollected,RTStech-
niques can be categorized as dynamic [ 23,26,34,35,37,50] and
static[29,30,36]techniques;dependingonthegranularitiesofpro-
gramelementsintestdependenciesandprogramchanges,RTStech-
niques can be categorized as basic-block-level [ 26,34,37], method-
level [35,50], file-level [ 23,30], and even module-level [ 42,44]
techniques.SincestaticRTSusesstaticanalysistooverapproximate
thetestdependenciesandthusmayselectmoreteststhannecessary,
dynamicRTStechniquesatdifferentgranularitieshavebeenlargely
studiedintheliterature.Accordingtoarecentstudy[ 23],RTSat
the file granularity can have less end-to-end time (i.e., including
both RTS overhead and actual testing time) compared with a finer
grained technique at the method level due to its lower overhead,
and represents state-of-the-art RTS. Actually, various open-source
projects have already adopted file-level RTS in their daily develop-
ment, e.g., Apache Camel [9], Math [10], and CXF [11].
Although the file-level RTS has been demonstrated to be cost-
effective,itmayselectmoreteststhanfiner-grainedRTS.Forex-
ample,priorstudyshowedthatfile-levelRTSmayselecttwiceas
many tests as method-level RTS on five GitHub Java projects [23].
Actually,dynamicRTStechniquesatdifferentgranularitieshave
there own strengths â€“ while techniques working on coarser granu-
laritiesmayhaveloweroverhead,RTStechniquesworkingonfiner
granularities may be more precise in selecting tests. Our insight is
tocombinethestrengthsofRTSatdifferentgranularities to
design a hybrid RTS approach that can be more cost-effective than
any of the existing RTS techniques.
In this paper, we propose the first hybrid RTS approach that
analyzestestdependencyandchangeinformationatmultiplegran-
ularities.WethenimplementabasichybridRTStechnique,HyRTS,
that combines method-level and file-level analysis for more cost-
effectiveRTSformodernJavaprograms.Thebasicideaistoperform
the method-level analysis just for the class files with only finer-
grained method-level changes, while performing file-level analysis
foralltheothercases,e.g.,file-leveladditions/deletions,orclassfile
1992018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Lingming Zhang
header changes. To evaluate the proposed technique, we compare
it against state-of-the-art file-level RTS (denoted as FRTS) on 2707
revisionsof32GitHubJavaprojects,totalling124,764,602LoC.The
experimental results demonstrate that HyRTS significantly outper-
formsstate-of-the-artFRTStechniqueintermsofbothselectedtest
ratioandthe offlinetestingtime(whenthetestdependenciesare
collected offline) â€“ HyRTS/FRTS selects 18.35%/27.18% tests (i.e.,
8.83ppmore precise) and costs 31.60s/40.06s offlinetesting time
(i.e.,21.1%faster)onaverageacrossallsubjects.Wealsoperformed
an extensive study on the impacts of each type of method-level
changesonHyRTS,anddesignedtwonewHyRTSvariantsbased
on the study results. Additional experimental results show that:
(1) further including the basic-block-level analysis in HyRTS does
not pay off; (2) further transforming instance method addition-
s/deletions intofile-level changesactually producesan evenmore
cost-effectivevariantthatsignificantlyoutperformsFRTSinboth
theofflineandonlinemodes.
The paper makes the following contributions:
â€¢ThedesignandimplementationofthefirsthybridRTSap-
proach, HyRTS, that combines method and file level RTS.
â€¢Experimental results demonstrating the effectiveness andefficiency of the HyRTS technique on 2707 revisions of 32
projects, totalling 124,764,602 LoC.
â€¢Anextensivestudyontheimpactsofeachtypeofmethod-
level changes on RTS during real-world software evolution.
â€¢TwoadditionalHyRTSvariantsdesignedbasedonthestudy
results, and experimental results demonstrating that further
transforming instance method additions/deletions to file-
level changes can make RTS even more cost-effective.
2 BACKGROUND AND EXAMPLE
TraditionalRegression TestSelection(RTS)techniques[ 23,26,34,
35,37,50]usuallyapplyatcertainlevelofcodegranularity.Pioneer
RTS techniques [ 26,34,37] usually apply at the level of program
basicblocks.Suchtechniquescollectdynamictestdependenciesforoldprogramversionsatthebasic-blocklevel,andcomputedetailed
programchangeinformationbytraversingControl-FlowGraphs
(CFGs)usingDepth-FirstSearch(DFS).Then,thetestswhosede-
pendencies overlap with the computed changes are selected forexecution. Although precise, such techniques need to computedetailed test dependency and change information, and can incur
non-trivial overhead [23, 34].
ToreducetheRTSoverhead,researchersalsoproposedRTSat
themethodlevel.Suchtechniques(e.g.,FaultTracer[ 50]andChi-
anti [35]) compute program changes at the method level (denoted
asatomic changes ). For example, a CM atomic change denotes a
changetoamethodbody.Besidesnormalatomicchanges,theyalso
capture changes of instance method overriding hierarchy to detect
dynamic dispatch changes, denoted as LC (i.e., look-upchanges).
A LC change is usually formulated as /angbracketleftX,Y.m()/angbracketright , which denotes
that an invocation to Y.m()with Xas the runtime object may be
resolved into a different target method due to software changes.Such LC changes are additionally generated whenever instancemethods are added (AM) or deleted (DM). Then, the tests whose
method-leveldependenciesmayoverlapwiththeatomicchanges
are selected. To illustrate, Figure 1 presents an example program1// source code classes
2class A{
3A(){...}
4int m1(){...}
5static int m2(){...}
6}
7class Bextends A{
8B(){...}
9static int m2(){...}
10}1// test classes
2class T1 {
3void t(){A a=new A(); a.m1();}}
4class T2 {
5void t(){A.m2();}}
6class T3 {
7void t(){A b=new B(); b.m1();}}
8class T4 {
9void t(){B.m2();}}
Figure 1: Example
Table 1: Example test dependencies
TestMethod dependency File dependency
T1 T1.t(), A.A(), A.m1() T1, A
T2 T2.t(), A.m2() T2, A
T3 T3.t(), A.A(), B.B(), A.m1() T3, A, B
T4 T4.t(), B.m2() T4, B
together with its tests and Table 1 presents the corresponding test
dependenciesatboththemethodandfilelevels.When A.m2()is
changed in the next revision (denoted as CM: A.m2()), only test
T2needs to be selected and re-run, since all the other tests cannot
execute the change at all. However, when B.m1()is added, a naive
method-level RTS technique fails to select any test since no test
directly executed the added tests in the prior revision. Therefore, a
safe method-level technique [ 35,50] additionally annotates each
instancemethoddependency elementwithbothruntime andstatic
receiver object types (Note that such additional information can
incur extra overhead during the dependency collection). For exam-
ple, the method-level dependency A.m1()forT3will be annotated
with/angbracketleftB,A.m1()/angbracketright toindicatethattheinvocationwasto A.m1()with
runtimeobject typeof B.Therefore, themethod-level RTSwillbe
able to match the annotation with the corresponding LC change to
select the truly impacted test T3.
Recently,researchershavealsoproposedEkstazi[ 23],aneven
coarser-grainedRTStechniqueatthebinaryclassfilelevel.Such
file-level RTS collects test dependencies and computes programchanges both at the file level. Although the coarse granularity
makesthetechniqueselectmoreteststhanthemethod-levelRTS,
operatingatthefileleveloffersmuchloweroverhead:(1)collecting
test dependencies at the file level can be faster than the method
level; (2) computing the program changes at the file level can be
directlyachievedbycomputingbinaryfile checksums,whichcanbe
extremelyfast;(3)file-levelRTSalsodoesnotneedtotrackdynamic
dispatchchanges[ 23].Forexample,accordingtothefile-levelde-
pendencyshowninTable1,when B.m2()isadded,file-levelRTS
will directly be able to detect that T3(and also T4due to the impre-
cisionoffile-levelRTS)isimpactedwithoutcollectingexpensive
runtimetypeinformation,sincefile Bisalreadyaccessedbythetest.
Althoughfile-levelRTSselectsmoreteststhanmethod-levelRTS,
it has much lower overhead. Overall, the file-level RTS has been
shown to save the end-to-end testing time for real-world projects,
andsignificantlyoutperformthemethod-levelRTS.Similarwith
recent advances in flaky test detection using hybrid coverage [ 14],
this work aims to further advance RTS using hybrid RTS analysis.
200
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Hybrid Regression Test Selection ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
	
		

	
 

 
 
 


 


 



Figure 2: HyRTS design overview
3 TECHNIQUE AND IMPLEMENTATION
In this section, we present our hybrid RTS approach, HyRTS, to
combine the strengths of traditional RTS techniques at different
granularities. We first introduce a basic HyRTS technique that
simply computes detailed method-level changes only when the
corresponding files are modified, while simply computing file-level
changes for file deletions and additions (Section 3.1). Then, we
introduce various HyRTS extensions to further study/improve RTS
cost-effectiveness (Section3.2). Finally,we summarize thebasis of
HyRTSâ€“changetransformation,anddiscussitssafety(Section3.3).
3.1 Basic HyRTS
TheoveralldesignofourbasicHyRTStechniqueisshowninFig-
ure2.Thetechniquecanbeinvokedwhenevertheunderlyingbuild
system fires the run test command. The analysis phase of RTS
performs two levels of RTS analysis: (1) file-level analysis takesthefiledependenciesandselectsalltheteststhatcoverfile-level
changesfortheexecutionphase( Â‚),(2)method-levelanalysistakes
the method dependencies and selects all the tests that overlap with
thedetailedmethod-levelchangesforactualexecution( Âƒ).Then,
bothsetsofselectedtestswillexecuted.Duringtheexecutionphase,
the user can choose to also collect the test dependencies for future
RTS, or collect the dependencies after the execution phase. Theexecution phase results will be stored as test results (
Â„), while
the collection phase results will be method-level dependencies ( Â…).
Thenforthenextsoftwarerevision,themethod-leveldependencies
will be directly used for the method-level analysis ( Â†). In addition,
file-leveldependenciescanalsobederivedfrommethod-levelanaly-sis(e.g.,adependencyonclass
Acanbederivedfromadependency
on method A.m()) for file-level analysis (Â‡).
NotethattheHyRTStoolhasbeenimplementedasaMavenplu-
gin for testing Java programs with JUnit tests, and is publicly avail-
ableonourHyRTShomepage[ 2].HyRTScurrentlysupportstest-
class level RTS for both single-module and multi-module Maven
projects, JUnit3 and JUnit4 tests,as well asunit (via MavenSure-
fire [6]) and integration (via Maven Failsafe [ 5]) tests. We next
describe the three key components for HyRTS:
3.1.1 Change Computation. We could have built HyRTS based
ontheexistingmethod-levelRTStool,FaultTracer[ 50],orfile-level
RTS tool, Ekstazi [ 23]. However, Ekstazi is not open-source, while
FaultTracer computes program changes at the source-code level
based on the Eclipse Java Development Tools (JDT) [ 4], which can
incur large overhead for large projects [ 23]. Therefore, we build
ourhybridRTStoolfromscratch,followingthedesigndecisions
of state-of-the-art Ekstazi tool [ 22]. For example, we also compute
thechecksums of bytecode files to efficiently detect file changes.
Furthermore,wealsouse smartchecksums tocomputebytecodefileAlgorithm 1: HyRTS change computation
Input :V1: Old program revision, V2: New program revision
Output:Î”: The hybrid code changes
/* Read old checksums, and initialize new ones */
1Map<File, CSUM> oldFileCSUM, Map<File, Map<Meth,CSUMÂ»
oldMethCSUM=deserializeCSUM( V1)
2Map<File, CSUM> newFileCSUM, Map<File, Map<Meth,CSUMÂ»
newMethCSUM=âˆ…
3forFile f inV2do
/* Compute new file checksums */
4newFileCSUM[f]=computeFileCSUM(f)
/* Compute new method checksums when necessary */
5ifnewFileCSUM[f]==oldFileCSUM[f] then
6 newMethCSUM[f]=oldMethCSUM[f]
7else
8 forM e t hmi nf do
9 newMethCSUM[f][m]=computeMethCSUM(m)
/* Serialize new checksums for next RTS */
10serializeCSUM(newFileCSUM, newMethCSUM)
/* File-level change computation [23] */
11AF,DF,CH,CF=FileDiff(oldFileCSUM, newFileCSUM)
12Î´f=AFâˆªDFâˆªCH
/* Meth-level change computation for changed files[35] */
13Î´m=/uniontext
fâˆˆCFMethDiff(oldMethCSUM[f],newMethCSUM[f])
14return{Î´f,Î´m}
contentswithoutdebugginginformation(e.g.,linenumberinfor-
mation).DifferentfromEkstazi,wealsoneedtotracemethod-levelchanges.Toefficientlystoremethod-levelinformationforthepriorrevisionandcomputemethod-levelchanges,wecomputethesmart
checksum foreach method.The detailedHyRTS changecomputa-
tionisshowninAlgorithm1.ShowninLines5-9,fortheunchangedfiles, all the method-level checksums are directly copied from prior
revision without further detailed analysis. During the actual file-level change computation (Line 11), HyRTS computes 4 types of
changesshowninthetophalfofTable2.Notethatweintroduce
CH to model the global changes to a file, e.g., interface/super classchanges or recompiled bytecode for a newer JDK version, to avoid
returning all enclosing methods as changed. In case of AF/DF/CH
changes, any test executing the corresponding class files will be
directlyselectedbasedonfile-levelRTSanalysis;incaseofother
file changes (CF), the basic HyRTS does not keep file-level changes,
and performs method-level detailed change computation (Line 13).
HyRTSsupportsallthemethod-levelchangessupportedbyprior
method-levelRTS[ 35,50],asshowninthebottompartTable2.Fol-
lowingexistingsafemethod-levelRTS[ 35,50],wealsocomputeLC
changesincaseofinstancemethodadditionsordeletions.Notethat
fieldchangesdo notneedtobetraced,sinceall fieldchangeswill
reflectinthecorrespondingmethod-levelchanges(e.g.,initializer
changes) at the bytecode level [ 35]. Also, we split non-initializer
method changes into instance and static method changes (e.g., AM
to ASM and AIM) to study the impact of each detailed type of
changes. In this work, we denote all changes computed by HyRTS
asÎ”={Î´m,Î´f},whereÎ´mdenotesthemethod-levelchanges,such
as DIM, andCSI, while Î´fdenotes the file-level changes, suchas
DF and CH.
201
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Lingming Zhang
3.1.2 Dependency Collection. Ourtestdependencycollection
component is implemented based on the ASM bytecode manipu-
lation framework [ 12] with the Java Agent [ 3] support for JVM
load-time code instrumentation. We override ClassVisitor and
MethodVisitor to record the method dependency information to-
getherwiththeruntimeandstaticobjecttypesforeachinstance
method invocation for safe method-level RTS. Following recent
advances on RTS [ 23,30], we focus on test-class level test selection
since test methods can be hard to isolate in practice, e.g., test meth-
ods may be parameterized or depend on other methods within the
test class. We also create another Java Agent to dynamically wrap
thecorrespondingrunnerclasses(e.g., org.junit.runner.Runner
forJUnit4)tocapturethetestclassstart/endeventsforbothJUnit3
and JUnit4 tests in order to trace the per-test dependency informa-
tion.WealsousethesameJavaAgenttoexcludetheunselectedtestsfortestexecution. Inthiswork,wedenoteallthetestdependencies
usedinHyRTSas TD={TDm,TDf},whereTDmrepresents
the method-level test dependencies (e.g., methods invoked as well
as runtime type information for receiver objects during test exe-cution) while
TDfis the file-level dependencies (i.e., the set of
classfilesaccessedduringtestexecution).NotethatHyRTSonly
collectsTDmduring runtime for sake of efficiency, and TDf
can be derived offline from TDmvia skipping detailed method
information, e.g., accessing method A.m()can be converted into
accessing file A.
3.1.3 RTS and Application Modes. Withthechangeinformation
(Î”) and test dependencies collected from the prior revision ( TD),
theselectedtestsTsforthecurrentrevisioncanbecomputedasthe
testswhose dependencieson thepriorrevision haveoverlap with
the changes, i.e.,Ts=Î”â‹’TD={Î´mâˆ©mTDm}âˆª{Î´fâˆ©fTDf},
whereâˆ©mdenotes the method-level test selection rules [ 35], while
âˆ©fdenotes the file-level test selection rules [ 23]. As shown in Fig-
ure 2, the time costs during the RTS process can be categorizedas the Analysis, Execution, and Collection time. In practice, the
users usually can choose two different RTS modes â€“ (1) the offline
mode that collects test dependencies offline (i.e., after running the
selected tests), and (2) the onlinemode that collects test dependen-
ciesonlineduringtheRTSprocess.Notethatthe offlinemodecosts
moreoverallCPUtime,buttheuserscangetfastertestfeedback
andthenpreparethetestdependenciesforthenextRTSrunafter
obtainingthetestresults,whilethe onlinemodereturnsboththe
test results and test dependencies at the same time [ 23,30]. Our
HyRTS technique supports both modes â€“ dependency collection
willbetriggeredonlyduringthe onlinemode,whiletestselection
will be triggered for both modes. In the experimental study sec-
tion, we evaluate HyRTS under both modes, i.e., measuring the AE
(Analysis and Execution) time for the offlinemode and the AEC
(Analysis, Execution, and Collection) time for the onlinemode.
3.2 HyRTS Extensions
3.2.1 HyRTS Study Variants. BesidesthebasicHyRTS,wefur-
ther study the impacts of each type of method-level changes by
transforming it into file-level changes to explore the directions for
further improving HyRTS. For example, when studying the impact
ofCIMchanges,HyRTStreatstheentirefileashavingaCFchange
(CF changes are kept and analyzed in the file-level RTS analysisTable 2: Supported change types
Name Description
DF Delete a class file
AF Add a class file
CH Change file head
CFChange a class file (not kept in basic HyRTS)
DSI Delete a static initializer
ASI Add a static initializerCSI Change a static initializer
DI Delete an instance initializer
AI Add an instance initializer
CI Change an instance initializerDSM Delete a static non-initializer method
ASM Add a static non-initializer methodCSM Change a static non-initializer method
DIM Delete an instance non-initializer method
AIM Add an instance non-initializer method
CIM Change an instance non-initializer method
for these variants) whenever there is any CIM change within a file,
while still tracing all the other changes in the same way as the
basic HyRTS.In thisway,HyRTS does notneed traceCIM changes
anymore,sincetheyarealreadysubsumedbythecorrespondingfilechanges.Clearly,suchHyRTSvariantmayselectmoreunnecessarytestsandbemoreimprecise,sinceanytestaccessingtheCFfilewill
be selected. However, such HyRTS variant can show the impact of
eachtypeoffine-grainedmethod-levelchanges,andprovideguide-linesformorecost-effectiveRTS.Thedetailedexperimentalresultsstudyingtheimpactofeachfine-grainedmethod-levelchangetype
can be found in Section 5.2.
3.2.2 HyRTS B.According to the study results in Section 5.2,
CIM and CSM changes tends to have the highest impact on HyRTSeffectiveness,i.e.,transformingCIMandCSMchangesintofile-level
changesincursHyRTStoselectmanymoretests,indicatingthat
CIM and CSM changes require even finer-grained analysis instead
ofcoarser-grainedanalysis.Therefore,wefurtherproposeHyRTS B
toextendbasicHyRTStoperformfiner-grainedbasic-blocklevel
analysis in the case of CIM and CSM changes to investigate thecost-effectiveness of more precise HyRTS (while keeping the ba-sic HyRTS method-level and file-level analyses for other cases).
Westrictlyfollowpriorwork onbasic-block-levelRTS[ 26]inim-
plementingthebasic-block-levelanalysisbasedonControl-Flow
Graph (CFG) analysis, and also analyze the try-catch constructs to
handle Java Exceptions. Note that HyRTS Brequires to also collect
detailedtestdependenciesatthebasic-blocklevel.Weimplement
both the CFG analysis and the basic-block level dependency collec-
tion using the ASM framework [12].
3.2.3 HyRTS F.ThestudyresultsinSection5.2alsodemonstrate
that AIM (i.e., instance method addition) and DIM (i.e., instance
methoddeletion)changesdonothavehighimpactsonHyRTSeffec-tiveness,i.e.,transformingeitherAIMorDIMintofile-levelchangesdonotincurmuchtestselectionimprecision.Therefore,wefurther
proposeHyRTS FtoextendbasicHyRTSbyfurthertransforming
both AIM and DIM changes into file-level changes (CF). Although
HyRTSFmay select more tests than basic HyRTS, without AIM
and DIM changes, HyRTS Fdoes not need to consider the class
inheritancehierarchychanges(i.e.,computingLCchanges)ortrace
202
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Hybrid Regression Test Selection ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
the runtime type information for each instance method invocation,
since the LC changes andruntime type information are both used
to handle safety issues in case of instance method additions or
deletions[ 23,35,50].Forexample,wheninstancemethod A.m()is
added, test Tis affected due to method dynamic dispatch change
althoughitdoesnothave A.m()initsolddependency.If Tdoesnot
execute other changes, Tmust invoke m()with a receiver object
objof type Aor subtype of Ain the old revision (otherwise only
adding A.m()cannotimpact T).No matter objisof type Aorsub-
typesof A,accordingtoJVMspecifications, Aâ€™sinitializer(s)mustbe
invokedfirsttocreate obj.Therefore, Aisaccessedby T,andsimply
recording file Aas changed will be sufficient to select T. Without
tracing LC changesand runtime type information, HyRTS Fmay
be much faster than the basic HyRTS in end-to-end time.
3.3 Hybrid RTS Safety
OurHyRTSapproachtransformscodechangesintofiner/coarser
grainedchangestoimplementdifferentRTSvariants.Beforetalking
about HyRTS safety, we first define two types of transformations.
Definition3.1(BasicTransformation). Whenallfine-grained
elements under acoarse-grained element are changed, abasic trans-
formation can simply mark the coarse-grained element as changed to
lowerRTSoverheads,i.e., [âˆ€eiâˆˆe,Î´(ei)]â‡’Î´(e),whereÎ´(.)denotes
the corresponding element is treated as changed.
Toillustrate,ifclass BinFigure1iscompletelydeletedinthenew
revision, traditional method-level techniques still need to dig into
Btodetectallthedeletedmethods,whilefile-levelRTScandirectly
return a file deletion change. The actual selection phase for the
file-levelRTScanalsobefasterduetothesmallnumberoffile-leveltestdependenciestoanalyze.Therefore,wecaneasilycomeupwith
hybrid RTS techniques that keep changes at the coarse granularity
when all the fine-grained elements under a coarse-grained element
arechanged,whilekeepingchangesatthefinegranularityatthe
other cases.Note thatour basicHyRTS andHyRTS Bare example
techniques in this category.
Besidesthebasicchangetransformationsthatwillnotsufferfrom
accuracy lost, this work also investigates transformations that mayincuraccuracylost,e.g.,HyRTSvariantsshowninSection3.2.1andSection3.2.3.Toillustrate,whenonly
B.m2()inFigure1ischanged,
we can still mark the entire class Bas changed. Although such
aggressive transformationmayselectmoreteststhannecessary,the
RTSoverheadandend-to-endtestingtimemaybefurtherlowered:
Definition3.2(AggressiveTransformation). Aggressivetrans-
formation marks a coarse-grained element as changed when onlypart of its fine-grained children elements get changed, i.e., [
âˆƒeiâˆˆ
e,Î´(ei)]â‡’Î´(e).
Note that when applying hybrid RTS using either basic or ag-
gressive changetransformations,the testdependenciesshould be
tracedatthefinegranularity(e.g.,methodlevelforbasicHyRTS,
while basic-block level for HyRTS B) since the coarse-grained de-
pendencies can be derived from the fine-grained ones. Then, thehybrid changes at different granularities can be matched againstcorresponding test dependencies to select tests. Despite the fact
that hybrid RTS via change transformation may incur imprecision,
we next discuss that hybrid RTS will not incur new safety issues.Theorem3.1. HybridRTSviachangetransformationcannotin-
troduce new safety issues for dynamic RTS.
Proof.In general, hybrid RTS collects test dependencies at dif-
ferent levels, denoted as TD={TD1,TD2, ...,TDn}, whereTDi
(1â‰¤iâ‰¤n)denotesthetestdependenciesatlevel i.Forexample,for
HyRTSB,TD={TDb,TDm,TDf}, which includes basic-block,
method, and file level test dependencies. Furthermore, hybrid RTS
also transforms all the changes into different levels, denoted as
Î”={Î´1,Î´2, ...,Î´n}, whereÎ´idenote the changes at level i. For ex-
ample, for HyRTS B,Î”={Î´b,Î´m,Î´f}, which includes basic-block,
method, and file level changes. Then, the selected test set Tscan
be computed asTs=TDâ‹’Î”=/uniontext
1â‰¤iâ‰¤n{TDiâˆ©iÎ´i}, wherreâˆ©i
denotestheRTSrulesatlevel i.IfhybridRTSintroducesnewsafety
issues, then the test selection must made some unsafe selectionat some level, e.g., there should exist level
i(1â‰¤iâ‰¤n), such
that{TDiâˆ©iÎ´i}failed to select some tests that should have been
selected by safe RTS.
Then,wecaneasilyconstructarevision V/prime
2betweentheoriginal
oldversionV1andtheoriginalnewversion V2,withonlychanges
withinÎ´i.Then,applyingtraditionalRTSatlevel ibetweenV1and
V/prime
2will perform{TDiâˆ©iÎ´i}, and thus makingunsafe selection.
However,ourhybridRTSisbuilton safeRTStechniquesatdifferent
levels, and thus the traditional RTS at level ialso cannot make
unsafe test selection. Contradiction. /square
4S T U D Y
4.1 Research Questions
In this study, we are interested in the following research questions:
â€¢RQ1:How does our basic hybrid RTS technique (HyRTS)
compare with state-of-the-art file-level RTS (FRTS)?
â€¢RQ2:Howdodifferenttypesofmethod-levelchangesimpact
the RTS results?
â€¢RQ3:Can we further transform method-level changes of
HyRTS into finer-grained or coarser-grained changes for
even more cost-effective RTS?
NotethatwedonotcompareHyRTSwiththemethod-levelRTS
that compares the detailed contents of all methods regardless of
file-level changes (e.g., FaultTracer [ 50]), since prior work [ 23] has
shownthatmethod-levelRTSismuchslowerthanFRTS,makingit
sufficient to compare HyRTS against state-of-the-art FRTS.
4.2 Subjects
Table3presentsallthesubjectsystemsforthisstudy.Forafaircom-
parisonwithstate-of-the-artFRTS,weusedallthesingle-module
MavenprojectsfromrecentstudiesonRTS[ 23,30].Followingprior
work [30], for each project, we started from the Head revision, and
selected 100 revisions before it (Note that if fewer than 100 revi-
sions are available, we just use all of them). Then, we use all the2,707 revisions (of the studied 32 projects) that can pass all the
regressiontestsinourevaluation.Inthetable,allthesubjectsare
sorted in the ascending order of their test execution time. Column
1 presents all the projects used as the subject systems. Note that
following prior RTS work [ 23], we categorize the subjects into two
subsets,i.e.,short-runningsubjects(withtestexecutiontimebelow60s)andlong-runningsubjects(withtestexecutiontimeabove60s).
203
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Lingming Zhang
Subs Head Revs Tests (Head) Size (LoC)
# Time (s) Head Total
invokebinder 004d2fd 100 107 2 3,036 214,867
compile-testing e4269a6 73 176 4 6,071 309,745
logstash-logback-encoder 4336fdc 95 208 4 9,435 829,731
commons-cli b486fbd 96 371 4 6,601 611,755
joda-time d7d1620 100 4,203 5 85,847 8,557,599
commons-dbutils 633749d 66 300 5 6,763 367,111
commons-validator e36fc4b 97 527 5 15,635 1,446,859
commons-fileupload f542f18 94 72 6 4,289 405,347
asterisk-java 61ecf80 59 220 7 43,102 2,538,060
commons-functor 3da1a4b 40 1,079 7 18,174 710,725
la4j db20416 99 801 8 13,414 1,411,825
commons-jxpath e48043d 87 411 9 24,910 2,131,230
commons-email 4ad899d 57 138 10 6,756 372,836
commons-compress d5f3062 100 614 10 34,347 3,358,789
commons-codec 1a4d9cc 79 847 11 19,530 1,523,899
jfreechart 54eeb32 100 2,261 12 140,671 14,071,394
commons-collections 3c1867e 46 16,069 23 61,637 2,811,369
commons-lang 0136218 100 3,946 24 73,781 7,292,816
commons-imaging 0aec9fd 100 441 28 38,020 3,784,160
commons-configuration 4239889 99 2,739 31 67,461 6,647,286
commons-net 2b0f338 100 276 61 27,525 2,726,739
closure-compiler e5ca4a7 100 11,309 62 297,130 29,637,121
java-apns a7d1e9f 48 111 73 5,626 253,403
commons-io 593de77 99 1,309 75 29,267 2,887,098
commons-math 79c4719 72 6,008 79 182,030 12,871,938
commons-dbcp 6a65042 100 560 81 20,547 1,995,908
log4j 7be00ee 57 344 95 30,287 1,922,801
stream-lib a13064c 99 147 105 8,492 819,463
HikariCP 980d8dc 92 109 117 10,283 916,531
OpenTripPlanner cc4dc2e 87 388 244 78,696 6,847,618
commons-pool e35320b 96 272 400 13,567 1,264,314
mapdb ad7102c 70 5,168 867 48,239 3,224,265
Total â€“ 2,707 61,531 2,472 1,431,169 124,764,602
Table 3: Subject statistics
Columns2and3presenttheshortSHA-1hashfortheHeadrevision
and the number of revisions for each studied project. Columns 4
and5presentthetestsize(i.e.,numberoftestmethods)andtestex-
ecutiontimeforthefirstexecutablerevisionofeachstudiedproject.Finally,Columns6and7presentthelinesofcode(LoC)information
(computedbySLOCCount[
1],excludingcommentsandspaces)for
the Head revision and allthe revisions for each studied project. In
total,ourexperimentalstudyinvolves2,707revisionsof32projects,
totalling over 124 Million LoC, and has a significantly larger scalethan prior studies on RTS [23, 30].
4.3 Experimental Setup
For each studied RTS technique, we compute the following widely
used RTS metrics to measure its effectiveness:Selected Test Ratio
The ratio of selected tests directly reflects
the precision of RTS techniques, and has been widely used in RTS
evaluation since the first proposal of RTS [ 23,26,30,34,35,37,
39,50].Wealsousethismetrictostudytheselectionprecisionof
different studied RTS techniques.End-to-EndTestingTime
Althoughtheratioofselectedtestscan
tell how precise a RTS technique is, it does not show the overhead
incurred by the RTS technique. Actually, a RTS technique that is
extremely precise but costs even more than re-executing the entire
test suite can be useless in practice. Therefore, recent work onRTS [
23,30] begins to consider the actual time savings of RTS
techniques. Following recent RTS work [ 23,30], we measure the
end-to-endtestingtimeforbothmodessupportedbyHyRTS,i.e., 




 







     





 
 

    
    
   









  
    
 










      
		
	
& " !$#$
#$#  "
  #
 $
  #%$#
  #&$ "
  #%! #$"#&
  #%$ "
  #'!$
  #
  # !"##
  # ""$
  # $ #  #
  #
  # %"$   #$
 #%" !"&!#  # 
  #$
  #! 
#$"
"
!"!"  #!  !$#$%"











































		
& " !$#$
#$#  "
  #
 $
  #%$#
  #&$ "
  #%! #$"#&
  #%$ "
  #'!$
  #
  # !"##
  # ""$
  # $ #  #
  #
  # %"$   #$
 #%" !"&!#
  # 
  #$
  #! 
#$"
"
!"!"  #!  !$#$















 


























		
& " !$#$
#$#  "
  #
 $
  #%$#
  #&$ "
  #%! #$"#&
  #%$ "
  #'!$
  #
  # !"##
  # ""$
  # $ #  #
  #
  # %"$   #$
 #%" !"&!#
  # 
  #$
  #! 
#$"
"
!"!"  #!  !$#$

Figure 3: Comparison between basic HyRTS and FRTS
the AE (Analysis and Execution) time for the offlinemode and the
AEC(Analysis,Execution,andCollection)timeforthe onlinemode.
Allourexperimentsareperformedona3.70GHzIntel(R)Xeon(R)
E5-1620V2machinewith128GBofRAM,runningUbuntuLinux
14.04.5 LTS and Oracle Java 64-Bit Server version 1.8.0_101. We ap-
plyeachstudiedRTSvariantoneachcoderevisionwithactualcode
changes (otherwise RTS should not be applied). Our experimental
data and implementation are available online [2].
5 RESULT ANALYSIS
5.1 RQ1: Basic Hybrid RTS vs. File-level RTS
Figure 3 presents the comparison results between our basic HyRTS
andstate-of-the-artFRTS.Thethreesub-figurespresenttheresults
intermsofselectedtestratio,the offlineend-to-endtime(i.e.,the
AEtime),andthe onlineend-to-endtime(i.e.,theAECtime),respec-
tively.Notethatthetwotimemetricshavebeennormalizedinto
ratioswithrespecttotheoriginaltestexecutiontimefortheeaseofpresentation.Ineachsubfigure,the x-axispresentsallthesubjects,
while the y-axis presents the corresponding metric distributions
204
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Hybrid Regression Test Selection ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
using boxplots (with median values marked as lines and mean val-
ues marked as hollow diamonds). From the first sub-figure, we can
observethatHyRTSconsistentlyselectsfewertestscomparedwith
FRTS across allthe studied subjects. On average, HyRTS and FRTS
select18.35%and27.18%ofallthetests,respectively(i.e.,HyRTS
is 8.83pp more precise). This is expected, since the finer-grained
analysiswithinHyRTScanselecttestsmorepreciselyincaseofCF
changes.Fromthesecondsub-figure,wefoundthattheHyRTScan
outperform FRTS on the majorityof subjects in terms of the offline
testing time, demonstrating the effectiveness of the HyRTS tech-
nique. For example, on average, FRTS and HyRTS cost 54.35% and
42.87% of the original test execution time, respectively (i.e., HyRTS
is 21.1% faster). Different from the observations on selected testratio,wealsofoundthatHyRTStendstooutperformFRTSmore
onsubjectswithlongrunningtime,sincetheoverheadincurredbythemethod-levelanalysismaytakealargerratioforshort-running
subjects. From the last sub-figure, we find that the performance
differencebetweenHyRTSandFRTSistheleaston onlineAECtime.
Forexample,theaverageAECtimeacrossallsubjectsis58.67%and
53.66% of the original testing time for FRTS and HyRTS, respec-
tively. Actually, HyRTS may even cost more than FRTS for several
subjects with long-running time (e.g., OpenTripPlanner). The mainreason is that the method-level dependency information (including
the runtime type information for each instance method invocation
forsafeRTS)requiredbyHyRTScanbemorecostlytocollectthan
the file-level dependency information required by FRTS.
5.2 RQ2: Impacts of Fine-grained Changes
Inthissection,wefurtherstudytheimpactsofeachtypeofmethod-
levelchanges(bytransformingitintofile-levelchangesshownin
Section3.2.1)toexplorethepotentialdirectionsforfurtherimprov-ingHyRTS.Tables4and5presenttheresultsintermsoftheselected
testratioand offlineAEtime,respectively.Notethattheimpacts
forAECtimearequitesimilartothoseforAEtime,therefore,we
skipthoseresultsduetothespacelimitation.Ineachtable,Column
1 presents all the studied subjects. Columns 2 presents the selected
test ratio or AE time by the basicHyRTS technique. Columns 3 to
14 present theincreased/decreased selectedtest ratio or AEtime
when transforming each type of method-level changes into file-
level changes. Finally, Column 15 presents the increased/decreased
selected test ratio or AE time by the FRTS technique as a refer-
ence. To further understand the results, we perform the Wilcoxon
Signed-Rank Test [ 45](Î±=0.05) to compare the result difference on
allthe revisionsofeach subject,because itissuitable evenforthe
casethatthesampledifferencesmaynotbenormallydistributed.
We highlight the cells with statistical differences in gray, and also
useH,, andto denote â€œno statistical differenceâ€, â€œsignificantly
betterâ€,and â€œsignificantlyworseâ€,respectively. Fromthetable, we
have the following observations:
First, overall, FRTS performs the worst comparing with trans-
forminganytypeof method-levelchangesintofile-levelchanges.
For example, the selected test ratio increase for FRTS is 8.83%,
while it is only 3.68% when transforming CIM changes, the type of
method-level changes with the highest impact. The findings on AE
timearealsosimilar.Furthermore,FRTSsometimesselectsmore
tests than transforming all method-level changes into file-levelchanges.Forexample,whenMapdbevolvesfromrevision 45e7679
torevision 1de4c60,theorderingoftwomethodsischangedinfile
org/mapdb/HTreeMap$values$1.class . Although such modifica-
tiondoesnotimpactanymethodbytecodenordynamicprogram
behavior, the class file is actually changed. Therefore, based on
thisfinding,itispossibletodesignmorecost-effectiveHyRTSvari-
ants by further transforming a subset of method-level changes into
file-level changes.
Second,transforming initializerchanges intofile-levelchanges
cannotimpacttheRTSeffectivenessmuchintermsofbothselected
testratioandtestingtime.Forexample,theinitializerchangesat
mostincur0.41%increaseinselectedtestratioforCSI,and0.70s
increase in AE time for CI. We looked into the code and found the
reasontobethatwheneveratestaccessesaclass,itusuallyalsohas
toinvoketheclassâ€™sstaticinitializerorinstanceinitializer.There-
fore, transforming the initializer changes into file-level changes
wonâ€™t impact the RTS results much. This finding shows that it is
not necessary to build HyRTS specifically considering initializer
changes since they wonâ€™t impact the RTS results much.
Third,method-bodychanges(e.g.,CIMandCSM)usuallyhave
the most impacts on the RTS results. For example, among the
changes on instance non-initializer methods, CIM has the high-est average impacts on both selected test ratio and AE time (e.g.,
significantlyworsethanHyRTSfor23and8subjects,respectively).
Similarly, CSM also has high impacts among the changes on static
non-initializermethods(e.g.,significantlyworsethanHyRTSfor
8 and 3 subjects in terms of selected test ratio and AE time, re-spectively). This finding shows that method-body changes have
highimpactonRTSeffectiveness,andmaydeservefiner-grained
analysis (e.g., at the basic-block level) to further improve RTS.
Fourth,instancemethodadditionsanddeletions(i.e.,AIMand
DIM)havelowtomoderateimpactsonRTSeffectiveness.Forexam-
ple,transformingAIMandDIMchangesintofile-levelchangesonly
incurs1.64sand0.23sincreasesinAEtime,respectively.Wefindthe
main reason to be that AIM and DIM changes are not as prevalent
as CIM changes, e.g., CIM changes are 1.6X as many as the sum of
AIM and DIM changes on average. We also find that AIM changes
tend to have higher impacts than DIM changes. The reason is that
thereisusuallyalatencytoaddteststoexecutethenewlyadded
methods, thus transforming AIM to file-level changes can cause to
selectmanyteststhatdonotdirectlyexecutethenewlyaddedmeth-
ods.Therefore,transformingAIMchangesintofile-levelchanges
may incur to select more tests than transforming DIM changes.
The low to moderate impacts of AIM and DIM changes indicate
that it may be possible to transform both AIM and DIM changes
intofile-levelchangestohavemorepowerfulRTS.Thereasonis
that without AIM and DIM changes, it is not necessary to consider
the class-inheritance changes (i.e., computing the LC changes) and
traceruntimetypeinformationforeachinstancemethodinvocation
(which can be expensive) for safe RTS [23] (Section 3.2.3).
5.3 RQ3: More Hybrid RTS Variants
Basedonthefourfindingslearntfromtheabovestudy,wecomeup
withtwonewHyRTSvariants,HyRTS B(Section3.2.2)andHyRTS F
(Section3.2.3),furtheroptimizingHyRTSinthefollowingtwodi-
rections: (1) even finer-grained analysis in case of method-body
205
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Lingming Zhang
Transformed method-level Changes
Subs HyRTS DSI ASI CSI DI AI CI DSM ASM CSM DIM AIM CIM FRTS
invokebinder 63.11% 0.00%H0.00%H0.00%H0.00%H1.09%H0.00%H0.00%H2.19%H0.00%H1.09%H9.84%3.28%H13.66%
compile-testing 35.67% 0.00%H0.00%H0.00%H0.27%H0.27%H0.00%H3.87%H3.87%H6.91%0.00%H0.00%H5.07%H15.25%
logstash-logback-encoder 12.06% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.67%H0.67%H0.36%H1.79%1.13%3.53%
commons-cli 27.89% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H5.55%H3.51%H13.64%
joda-time 12.65% 0.00%H0.00%H1.12%H0.00%H0.00%H0.08%H1.04%H5.68%H7.15%H0.08%H3.36%3.39%16.45%
commons-dbutils 14.83% 0.00%H0.00%H3.85%H0.00%H0.00%H0.00%H0.00%H0.00%H0.49%H0.00%H1.25%H5.10%11.61%
commons-validator 4.77% 0.00%H0.00%H0.66%0.00%H0.00%H0.41%H0.00%H0.11%H0.74%H0.00%H0.41%2.20%4.09%
commons-fileupload 25.00% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.60%H0.30%H0.30%H6.55%8.63%
asterisk-java 1.50% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.06%H0.69%0.87%1.00%3.56%
commons-functor 9.72% 0.00%H0.00%H0.12%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.15%H1.69%2.02%
la4j 42.01% 0.00%H0.00%H0.58%H0.05%H0.00%H1.35%H0.00%H0.73%H6.47%4.51%13.27%18.31%33.50%
commons-jxpath 32.36% 0.00%H0.00%H1.06%H0.00%H0.00%H0.00%H1.61%H1.99%H4.89%0.29%H1.69%H5.04%13.39%
commons-email 22.02% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H5.95%H1.19%H7.14%H
commons-compress 8.48% 0.00%H0.00%H0.00%H0.00%H1.30%0.36%H0.17%H1.18%H0.55%H0.27%H0.67%1.87%4.25%
commons-codec 2.17% 0.00%H0.00%H0.12%H0.00%H0.97%H2.18%1.28%H1.28%0.61%H0.97%0.79%H0.43%H4.31%
jfreechart 10.89% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.49%H1.13%H0.00%H0.02%H0.02%H1.92%2.73%
commons-collections 0.73% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H1.62%H1.18%H0.00%H3.16%H
commons-lang 3.81% 0.00%H0.00%H0.00%H0.00%H0.00%H0.03%H0.13%H2.68%5.55%0.03%H0.05%H0.37%7.11%
commons-imaging 13.07% 0.00%H0.00%H0.00%H0.00%H0.00%H0.05%H0.00%H0.03%H0.09%H1.75%H1.78%H9.22%11.72%
commons-configuration 7.25% 0.00%H0.00%H0.40%H0.00%H0.00%H0.02%H0.00%H0.86%H1.37%H0.33%H4.05%3.45%9.33%
commons-net 3.72% 0.00%H0.00%H0.08%H0.00%H0.65%H0.00%H0.00%H0.00%H0.00%H0.00%H0.15%H2.30%2.99%
closure-compiler 16.80% 0.00%H0.00%H1.92%H0.02%H0.02%H0.03%H0.04%H1.43%4.04%1.39%2.06%10.09%16.38%
java-apns 35.89% 0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H2.32%H1.05%H0.00%H2.36%4.12%3.44%9.41%
commons-io 8.49% 0.00%H0.00%H0.90%H0.00%H0.00%H0.00%H0.00%H0.49%H6.84%0.00%H0.00%H0.03%H7.88%
commons-math 3.86% 0.00%H0.00%H0.02%H0.07%H0.08%H0.04%H0.00%H1.11%H0.53%0.00%H0.18%H1.56%5.00%
commons-dbcp 22.68% 0.00%H0.00%H1.48%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H0.00%H1.46%H8.99%10.47%
log4j 9.23% 0.00%H0.00%H0.00%H0.00%H0.00%H1.23%H0.00%H6.46%H0.00%H0.00%H1.23%H2.77%H14.46%H
stream-lib 11.89% 0.00%H0.00%H0.00%H0.00%H0.00%H0.57%0.25%H0.49%H0.00%H0.08%H0.33%H0.08%H1.15%
HikariCP 48.46% 0.00%H0.00%H0.33%H0.00%H0.00%H0.00%H0.08%H0.08%H0.08%H0.00%H0.25%H2.45%3.37%
OpenTripPlanner 18.83% 0.01%H0.01%H0.31%H0.00%H0.01%H0.06%0.22%H0.42%H0.51%1.12%1.67%3.59%5.44%
commons-pool 29.26% 0.00%H0.00%H0.00%H0.00%H0.00%H0.29%H0.00%H0.15%H0.00%H0.00%H3.09%4.56%9.26%
mapdb 28.06% 0.00%H0.00%H0.05%H0.00%H0.00%H0.25%H0.00%H0.72%H0.77%H0.00%H1.11%H3.19%7.67%
Avg. 18.35% 0.00% 0.00% 0.41% 0.01% 0.14% 0.22% 0.36% 1.09% 1.53% 0.54% 2.14% 3.68% 8.83%
Table 4: Selection ratio change when transforming different atomic changes into file changes
Transformed method-level Changes
Subs HyRTS DSI ASI CSI DI AI CI DSM ASM CSM DIM AIM CIM FRTS
invokebinder 1.58s 0.00sH0.00sH0.01sH0.00sH0.03s0.00sH-0.01sH0.00sH-0.01sH-0.02sH0.03sH-0.01sH-0.03sH
compile-testing 3.14s 0.00sH0.00sH0.00sH0.01sH0.01sH-0.01sH0.01sH-0.01sH0.04sH0.01sH-0.01sH-0.04sH0.06sH
logstash-logback-encoder 3.18s 0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH-0.01sH-0.02sH0.01sH0.00sH-0.01sH-0.01sH-0.02sH
commons-cli 3.62s 0.00sH0.00sH-0.03sH0.00sH0.00sH-0.04sH0.00sH0.00sH-0.01sH0.00sH0.01sH-0.01sH0.08sH
joda-time 3.75s 0.00sH0.00sH0.01sH0.00sH0.00sH0.00sH0.03sH0.16sH0.12sH0.02sH0.09sH0.25s0.33sH
commons-dbutils 3.29s 0.00sH0.00sH-0.01sH0.00sH0.00sH-0.04sH0.00sH0.00sH0.00sH-0.01sH0.00sH0.02sH0.04sH
commons-validator 3.72s 0.00sH0.00sH0.04sH0.00sH0.00sH0.02sH0.00sH0.01sH0.05sH0.00sH0.02s0.04sH0.23s
commons-fileupload 3.91s 0.00sH-0.01sH0.00sH0.00sH-0.21sH-0.21sH0.00sH0.00sH0.22sH0.03sH-0.07sH0.68s0.13sH
asterisk-java 3.26s 0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.03sH0.04s0.04sH0.16sH
commons-functor 4.02s 0.00sH0.00sH0.01sH-0.01sH0.01sH0.05sH0.01sH0.00sH0.00sH-0.02sH-0.15sH-0.19sH-0.25sH
la4j 2.49s 0.00sH0.00sH0.01sH0.00sH0.00sH0.08sH0.00sH0.00sH0.26s0.04s0.33s0.34s0.93s
commons-jxpath 3.54s 0.00sH0.00sH0.02sH0.00sH0.00sH0.00sH0.04sH0.03sH0.10sH0.01sH0.03sH0.07sH0.17sH
commons-email 6.29s 0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH-0.02sH0.13sH
commons-compress 6.09s 0.00sH0.00sH0.01sH0.00sH0.08s0.16s0.06sH0.13s0.11sH-0.04sH0.10sH0.08sH0.32sH
commons-codec 4.93s-0.01sH0.00sH0.05sH-0.01sH0.33sH0.73s0.44sH0.50s0.21sH0.53s0.24sH0.42sH1.31s
jfreechart 9.80s 0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.04sH0.12sH0.00sH-0.11sH-0.15sH0.21sH0.18sH
commons-collections 8.72s 0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH0.00sH-0.15sH0.00sH0.20sH0.52sH0.06sH0.13sH
commons-lang 8.58s 0.00sH0.00sH-0.01sH0.01sH-0.01sH0.03sH0.05sH0.60s1.35s0.02sH0.04sH0.18sH1.31sH
commons-imaging 14.35s 0.00sH0.00sH0.06sH0.02sH0.05sH0.27sH0.00sH0.02sH-0.04sH0.46sH0.50sH2.10s2.48s
commons-configuration 16.12s 0.00sH0.00sH0.11sH0.00sH0.00sH-0.01sH0.00sH0.12sH0.03sH-0.03sH2.98s2.28sH5.18s
commons-net 9.37s 0.00sH0.00sH0.04sH0.00sH-0.01sH-0.02sH0.00sH0.00sH0.04sH0.00sH-0.03sH1.44sH1.43sH
closure-compiler 38.41s 0.00sH0.00sH0.52sH-0.05sH0.05sH-0.02sH0.03sH0.44sH1.19sH0.65sH1.00sH5.44s7.34s
java-apns 49.16s 0.00sH0.04sH0.00sH0.00sH0.00sH0.08sH0.44sH1.67sH0.11sH2.04s3.68s3.00s4.79s
commons-io 16.59s 0.00sH0.00sH2.63sH0.01sH0.00sH-0.02sH0.00sH1.04sH14.03s0.03sH0.02sH-0.01sH15.06s
commons-math 20.71s 0.00sH0.00sH-0.02sH0.00sH-0.01sH0.01sH-0.01sH0.95sH0.56sH-0.01sH0.01sH1.98sH4.18sH
commons-dbcp 36.16s 0.01sH0.00sH1.73sH0.00sH-0.37sH-0.37sH0.00sH0.04sH0.00sH0.03sH1.31sH3.88sH5.35s
log4j 11.59s 0.00sH0.00sH0.00sH0.00sH0.00sH0.02sH-0.01sH8.37sH0.02sH0.00sH0.02sH0.04sH19.45sH
stream-lib 26.18s 0.00sH0.00sH0.00sH0.01sH0.01sH3.49s1.62sH2.97s0.03sH0.09sH0.94sH0.59sH4.91s
HikariCP 45.10s 0.00sH0.00sH0.17sH0.00sH0.00sH0.05sH0.00sH0.00sH-0.02sH0.01sH-0.01sH0.72sH1.29sH
OpenTripPlanner 121.88s 0.15sH0.17sH2.50sH0.07sH0.07sH0.17sH2.97sH6.13sH0.91sH3.31sH12.07s29.17sH37.10s
commons-pool 202.10s 0.00sH0.00sH0.00sH0.00sH0.00sH5.44sH0.00sH6.06sH0.00sH0.00sH15.66s37.67s61.40s
mapdb 319.59s 0.00sH-0.07sH0.16sH-0.05sH0.19sH12.65s0.12sH5.39sH5.26sH0.14sH13.39sH41.51s95.60s
Avg. 31.60s 0.00s 0.00s 0.25s 0.00s 0.01s 0.70s 0.18s 1.08s 0.77s 0.23s 1.64s 4.12s 8.46s
Table 5: AE time change when transforming different atomic changes into file changes
changes(i.e., CSMandCIMchanges), and(2)fasterHyRTS analy-
sisviafurthertransformingAIMandDIMchangesintofile-level
changes.NotethatHyRTS Bfocusesontheselectionprecisionwhile
HyRTSFfocusesontheoveralloverhead.Themainexperimental
results forcomparingdifferentHyRTSvariants (i.e.,basic HyRTS,
HyRTSBand HyRTS F) are shown in Table 6. In the table, Column
â€œSubsâ€listsallthestudiedsubjects;Columnâ€œSelectedTestsâ€presentstheselectedtestratiosforeachHyRTSvariant;Columnsâ€œAETimeâ€
andâ€œAECTimeâ€presenttheAEandAECend-to-endtestingtime
including the ratio to the original testing time in brackets. We also
applied Wilcoxon Signed-Rank Test at the significance level of 0.05
tocompareeachHyRTSvariantagainststate-of-the-artFRTS.All
the cellswith statistical differences aremarked in gray,and H,,
206
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Hybrid Regression Test Selection ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Selected Tests AE Time AEC Time
Subs HyRTS HyRTS BHyRTS F HyRTS HyRTS B HyRTS F HyRTS HyRTS B HyRTS F
invokebinder 63.11%61.47%72.95%H1.58sH(166.02%) 1.59s H(167.76%) 1.58s H(167.22%) 1.64sH(173.18%) 1.68s H(176.76%) 1.61s H(169.75%)
compile-testing 35.67%33.57%35.67%3.14sH(99.54%) 3.15s H(99.60%) 3.13s H(99.12%) 3.27sH(103.52%) 3.21s H(101.68%) 3.24s H(102.89%)
logstash-logback-encoder 12.06%11.87%13.96%3.18sH(88.60%) 3.13s H(87.35%) 3.21s H(89.28%) 3.17s(88.58%) 3.11s(87.07%) 3.19s H(89.22%)
commons-cli 27.89%27.69%33.44%3.62sH(101.26%) 3.64s H(102.23%) 3.64s H(101.86%) 4.01s(112.62%) 3.76s(105.30%) 3.73s H(105.12%)
joda-time 12.65%12.05%16.11%3.75sH(70.05%) 3.93s H(73.41%) 3.89s H(72.72%) 5.64s(105.80%) 5.86s(109.95%) 4.35s H(81.27%)
commons-dbutils 14.83%15.16%16.73%3.29sH(96.76%) 3.42s H(100.82%) 3.24s H(95.67%) 3.30sH(97.78%) 3.40s H(100.69%) 3.36s H(99.20%)
commons-validator 4.77%4.66%5.55%3.72s(76.93%) 3.83s H(79.02%) 3.72s(76.86%) 3.85sH(79.65%) 4.06s H(84.11%) 3.84s H(79.58%)
commons-fileupload 25.00%21.43%25.59%3.91sH(96.53%) 4.09s H(99.34%) 4.26s H(105.99%) 4.60sH(114.69%) 4.49s H(111.37%) 4.11s H(101.20%)
asterisk-java 1.50%1.44%3.12%3.26sH(47.70%) 3.25s(47.54%) 3.31s H(48.44%) 3.42s(49.99%) 3.46s(50.61%) 3.47s H(50.83%)
commons-functor 9.72%9.72%9.87%4.02sH(57.34%) 3.94s(56.07%) 3.79s H(54.07%) 3.85sH(55.00%) 3.93s H(55.92%) 3.93s H(56.10%)
la4j 42.01%41.67%56.44%2.49s(85.80%) 2.54s(87.77%) 2.83s H(93.87%) 4.19sH(121.15%) 6.10s(178.94%) 3.46s H(112.79%)
commons-jxpath 32.36%28.03%34.22%3.54sH(71.92%) 3.52s H(71.56%) 3.52s H(71.93%) 4.13sH(83.74%) 4.97s H(98.46%) 3.78s H(77.00%)
commons-email 22.02%H19.64%H27.97%H6.29sH(80.23%) 6.44s H(81.63%) 6.31s H(81.18%) 6.69sH(85.45%) 6.70s H(85.26%) 6.91s H(88.09%)
commons-compress 8.48%8.10%9.15%6.09sH(59.87%) 6.53s H(64.17%) 6.19s H(60.96%) 6.74sH(66.28%) 7.34s H(72.32%) 6.46s H(63.55%)
commons-codec 2.17%100.00% 3.51%4.93s(43.35%) 13.60s(119.53%) 5.75s H(50.70%) 5.14s(45.15%) 13.60s(119.53%) 5.77s(50.84%)
jfreechart 10.89%10.89%10.91%9.80sH(87.66%) 10.08s H(90.36%) 9.82s H(88.03%) 10.86sH(97.09%) 12.02s(107.50%) 10.34s H(92.26%)
commons-collections 0.73%H0.73%H3.52%H8.72sH(41.30%) 8.36s H(39.53%) 9.09s H(43.12%) 8.91sH(42.24%) 9.22s H(43.66%) 9.03s H(42.76%)
commons-lang 3.81%3.71%3.93%8.58sH(35.38%) 8.76s H(36.06%) 8.73s H(35.94%) 8.92s(36.78%) 9.31s H(38.39%) 9.10s(37.48%)
commons-imaging 13.07%13.05%14.97%14.35s(49.50%) 14.54s(50.14%) 14.64s(50.54%) 16.64sH(57.39%) 27.61s(94.76%) 15.80s(54.59%)
commons-configuration 7.25%7.19%11.30%16.12s(51.36%) 16.21s(51.63%) 19.02s H(60.93%) 13.29s(42.39%) 13.66s(43.56%) 14.36s(45.93%)
commons-net 3.72%3.23%3.95%9.37sH(15.30%) 9.35s H(15.27%) 10.05s H(16.42%) 9.41sH(15.36%) 9.60s H(15.67%) 10.14s H(16.57%)
closure-compiler 16.80%15.09%19.64%38.41s(61.88%) 38.10s(61.25%) 39.86s(64.25%) 64.45sH(103.88%) 71.72s H(115.65%) 55.44s(89.41%)
java-apns 35.89%34.42%40.85%49.16s(68.18%) 47.10s(65.37%) 52.80s H(73.26%) 49.27s(68.33%) 47.11s(65.38%) 52.85s H(73.32%)
commons-io 8.49%7.62%8.49%16.59s(22.12%) 14.48s(19.31%) 16.68s(22.23%) 16.83s(22.44%) 14.74s(19.66%) 16.77s(22.36%)
commons-math 3.86%3.39%4.03%20.71sH(27.45%) 19.78s H(26.18%) 21.11s H(28.00%) 42.11s(56.02%) 70.29s(93.23%) 35.94s H(47.82%)
commons-dbcp 22.68%20.70%23.39%36.16s(45.40%) 33.49s(42.02%) 35.40s H(44.38%) 36.57sH(45.92%) 33.76s H(42.37%) 35.46s(44.46%)
log4j 9.23%H8.92%H10.15%H11.59sH(13.36%) 11.62s H(13.39%) 11.67s H(13.45%) 11.80sH(13.57%) 11.87s H(13.66%) 11.67s(13.43%)
stream-lib 11.89%11.89%12.30%26.18s(26.03%) 26.41s(26.26%) 27.23s H(27.11%) 30.87sH(30.70%) 60.26s(59.94%) 28.99s H(28.88%)
HikariCP 48.46%45.39%48.71%45.10sH(55.21%) 43.81s H(53.70%) 45.16s H(55.34%) 45.23sH(55.41%) 44.03s H(54.03%) 45.26s H(55.46%)
OpenTripPlanner 18.83%17.42%21.10%121.88s (51.48%) 109.49s (46.37%) 137.34s (57.83%) 194.21s H(82.08%) 243.13s (103.08%) 151.80s H(63.92%)
commons-pool 29.26%27.94%32.94%202.10s (51.16%) 202.53s (51.27%) 218.42s (55.30%) 203.81s (51.59%) 200.24s (50.69%) 216.54s (54.83%)
mapdb 28.04%25.84%29.05%319.59s (38.58%) 270.82s (32.89%) 332.87s (40.19%) 438.99s H(52.97%) 530.96s H(64.47%) 357.80s (43.19%)
Avg. 18.35% 20.43% 20.74% 31.60s (42.87%) 29.73s (40.33%) 33.38s (45.28%) 39.56s (53.66%) 46.41s (62.96%) 35.58s (48.26%)
Table 6: Experimental results for HyRTS variants
andrepresent â€œno statistical differenceâ€, â€œsignificantly betterâ€,
andâ€œsignificantlyworseâ€.AccordingtotheresultsshowninTable6:
HyRTSBselects similar ratio of tests with basic HyRTS, which
is counter-intuitive. We looked into the data and found two rea-
sons.First,modernsystemdesignprinciplesrecommendwriting
simple method bodies for the ease of maintenance, making the
majorityof methodbodychangesdirectly occuronthe firstbasic
blockofthemethods.Insuchcases,thedetailedbasic-block-level
analysisselectssimilarnumberoftestswithbasicHyRTS.Forexam-
ple,whenInvokebinderevolvesfrom c35f3ee to9c59df3,method
SmartBinder.from() , the only changed source method actually
onlyhasonelineofcode.Second,thebasic-block-leveldependency
collectionfailed foronesubject, Commons-Codec,whichhas sev-
eral huge methods (e.g., initSTRINGS andinitBYTES ) inside class
Base64Codec13Test .Afterthedetailedcodeinstrumentationfor
tracing the basic-block-level test dependencies, the code size be-
camelargerthantheJVMspecifiedmaximumsize(i.e.,64KB),crash-ingJVMwithexceptionâ€œ
java.lang.RuntimeException: Method
code too large! â€.Insuchcases,ourimplementationsimplyre-
runsalltheregressionteststoensuresafety.Thatâ€™sactuallywhy
HyRTSBon average selects even slightly more tests than basic
HyRTS.Furthermore,HyRTS Bmayperformevenworsethanba-
sic HyRTS and FRTS in terms of AE or AEC time. Based on the
Wilcoxontest,HyRTS BcostssignificantlymoreAE/AECtimethan
FRTS on 2/9 subjects due to the additional overhead for analyzing
basic-blockchangesandtracingbasic-blockdependencies.Onav-
erageHyRTS Bcosts46.41sAECtime,whichisevenhigherthan
thatofFRTS(43.25s).Therefore,includingfiner-grainedanalysis
may not be a good direction for more practical RTS.HyRTS
FextendsbasicHyRTSbyfurthertransformingAIMand
DIM changes into file-level changes. Although HyRTS Fmay se-
lect more tests than basic HyRTS, without AIM and DIM changes,HyRTSFdoes not need to consider the class inheritance hierarchy
changes (i.e., computing LC changes) or trace the runtime type
information for each instance method invocation, and thus may be
muchfaster thanthe basicHyRTS. AccordingtoTable 6,HyRTS F
incurs small increase in selected test ratio (2.39%) and AE time
(1.78s)comparedwithbasicHyRTSduetothemoreimpreciseanal-
ysis. However, i n terms of the AEC time, HyRTS Fis even much
more efficient than both basic HyRTS and state-of-the-art FRTS.
Forexample,HyRTS Fonlycosts48.26%oftheoriginaltestingtime
(35.58s), while FRTS and HyRTS cost 58.67% (43.25s) and 53.66%(39.56s),respectively.Furthermore,HyRTS
Fisneverstatistically
significantlyworsethanFRTSintermsofalltheusedmetricswhile
the basic HyRTS is significantly worse than FRTS on three sub-
jectsintermsofAECtime.Overall,HyRTS Fis16.7%/17.7%faster
than state-of-the-art FRTS in AE/AEC time, and can be a more
cost-effective technique than the basic HyRTS in practice.
5.4 Threats to Validity
Threats to Internal Validity. The main threat to internal valid-
itymainlyliesintheimplementationoftheRTStechniquesstud-
ied in the work. To reduce this threat, we built the proposed and
studied techniques on mature frameworks/libraries (e.g., ASM and
JavaAgent),andcarefullyreviewedourcodeandexperimentscripts
beforeand duringtheexperimental study. Furthermore,sincethe
binary version of the FRTS tool Ekstazi is publicly available, we
also comparedour FRTSimplementation withEkstazi interms of
selectedtestratioandtheend-to-endAECtimeonsampledprojects.
We found that our FRTS selects the same number of tests with Ek-
stazi, and have competitive end-to-end time. To illustrate, Figure 4
presentstheselectedtestnumberandAECtimeforEkstaziandour
FRTSonCommons-Math.WecanobservethatEkstaziandFRTS
207
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Lingming Zhang


















     

	 





























    	 




Figure 4: Ekstazi vs. FRTS on Commons-Math revisions
select exactly the same number of tests for all the studied revisions
of Commons-Math with quite close end-to-end testing time.
ThreatstoExternalValidity. Themainthreattoexternalvalidity
mainlyliesinthesubjectsystemsusedinthisstudy.Toreducethis
threat,weincludedallthesingle-moduleMavenprojectsusedin
recent RTS work [ 23,30], and strictly followed prior RTS work
inselectingprojectrevisions.Actually,ourstudyincludesallthe
projects used on Legunsen et al.â€™s work [ 30], and involves much
more code revisions than recent RTS work. However, it is still not
clear whether our findings can generalize to other projects.
Threats to Construct Validity. Themainthreattoconstructva-
lidityliesinthemetricsthatweusedtoevaluatethestudiedRTS
techniques. To reduce this threat, we use all the three widely used
metricsinRTS,i.e.,theselectedtestratio,the offlinetestingtime
(i.e., AE time), and the onlinetesting time (i.e., AEC time).
6 RELATED WORK
DynamicRTS. RothermelandHarrold[ 37]firstlyinvestigateddy-
namicRTSforCprogramsatthebasic-blockgranularity.Harrold
etal.[26]thenextendedthebasic-block-levelRTStoJavaprograms
withObject-Orientedfeatures.Orsoetal.[ 34]furtherproposeda
two-phase RTS analysis, including a partitioning phase to exclude
the non-affected classes from detailed CFG analysis and a selection
phase that performs CFG analysis only on the remaining classes.
Note that our work is different from their work: (1) their work
simplyexcludesthenon-affectedclassesandstillperformsuniform
detailed analysis (i.e., basic-block-level analysis) on the affected
classes, whereas our work performs RTS analysis at multiple levels
in tandem (with only detailed analysis when necessary); (2) our
workdemonstratesthatcombiningmethod-levelandfile-levelanal-
ysis can outperform state-of-the-art file-level RTS, while further
including basic-block-level analysis is not cost-effective.
Since finer-grained analysis may incur larger overheads, besides
thebasic-block-levelRTS,researchershavealsoinvestigatedRTSatcoarser-granularitiestoimprovetheefficiencyofRTS.Renetal.[
35]
and Zhang et al. [ 50] performed RTS at the method level â€“ they
performed bytecode or source code analysis to detect the changed
methods/fieldsandthenselectedanytestthatexecutedthechanged
methods/fields in the old program version. With the increasing
scalesofmodernreal-worldprojects,method-levelRTSmaystill
incur large overheads. Therefore, Gligoric et al. [ 23] proposed file-
level RTS for Java projects, which traces the changed bytecode
classfilesbasedonfastchecksumcomputation,andselectsanytest
accessing the changed files. Although imprecise, the file-level RTS
canhavenegligibleoverheadandhasbeenshowntooutperformthe method-level RTS in terms of end-to-end testing time. Vasic
etal.alsocomparedfile-levelRTSwithevencoarsergrainedRTS
at the module level for .NET programs [ 44]. Recently, Celik et
al. [16] designed dynamic file-level RTS across JVM boundaries.
Despiteitseffectiveness,file-levelRTSmaystillselectmoretests
due to the coarse-grained analysis. Therefore, in this work, we
propose the first hybrid RTS approach to combine the strengths of
RTS at multiple granularities. Our work differs from all prior RTS
techniquesthatonlyworkatafixedgranularityandopensanew
dimension for further advancing RTS.StaticRTS.
AlthoughdynamicRTShasbeenwidelystudied,itmay
notbesuitableforalltypesofsystems.Forexample,thedynamic
test dependencies required by dynamic RTS may be challenging to
collectforreal-timesystemssincethecodeinstrumentationmay
breakthetimeconstraintsandinterruptnormaltestruns.There-
fore,staticRTSthatusesstaticanalysistoover-approximatetest
dependencies has also been proposed to further complement dy-
namic RTS. Kung et al. [ 29] proposed the first static RTS technique
based on the class firewall analysis, which computes classes that
may be affected by the changes using static class analysis. Since
classfirewallanalysismaybeimprecise,RyderandTip[ 39]further
proposedstaticRTSatthemethodlevel,i.e.,usingstaticcallgraphs
to over-approximate the dependenciesfor each test. Although the
static RTS techniques have been proposed for decades, their ef-
fectivenesshavebeenlargelyunknownduetothelackofstudies
on modern software systems. Legunsen et al. [ 30,31] performed a
timely and extensive study on static RTS recently, and showed that
static file-level RTS can have close end-to-end testing time with
state-of-the-artdynamicfile-levelRTS,butissometimesunsafedue
toreflections.Inthispaper,weproposetocombinethestrengths
of both fine and coarse grained dynamic RTS analysis. Actually
our idea is general and can also be applied to static RTS and other
levels. We plan to further explore this direction in the future.
7 CONCLUSION
This paper proposes the first hybrid RTS approach that analyzes
at multiple granularities to combine the strengths of traditional
RTStechniquesatdifferentgranularities.Weevaluatetheproposed
approach in both the onlineandofflinemodes on 2707 revisions of
32projects,totallingover124MillionLoC.Thestudyshowsthat
HyRTS,ourfirsthybridtechniquethatcombinesmethodandfile
granularityRTSanalysis,canbesignificantlyfasterthanstate-of-
the-artFRTSinthe offlinemode,butsometimesslowerthanFRTSin
theonlinemodeduetothecollectionofmethod-leveldependencies.
We then further studied the impact of each type of method-level
changesontheRTSresults,anddesignedtwonewHyRTSvariants
based on the study results. The additional study shows that further
integrating finer-grained analysis at the basic-block level is notcost-effective, whereas transforming instance method additionsand deletions into file-level changes can produce a cost-effectiveHyRTS variant that consistently outperforms existing FRTS for
bothonlineandofflinemodes.
8 ACKNOWLEDGMENTS
We thank the anonymous reviewers for the valuable comments.
This work is supported in part by NSF Grant No. CCF-1566589, UT
Dallas start-up fund, Google, Huawei, and Samsung.
208
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. Hybrid Regression Test Selection ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1] SLOCCount. http://www.dwheeler.com/sloccount/.
[2] HyRTS Homepage. http://hyrts.org/.
[3]Java Agent. https://docs.oracle.com/javase/7/docs/api/java/lang/instrument/
package-summary.html.
[4] JDT home page. http://www.eclipse.org/jdt/.
[5]Maven Failsafe Plugin. http://maven.apache.org/surefire/maven-failsafe-plugin/.
[6]Maven Surefire Plugin. http://maven.apache.org/surefire/
maven-surefire-plugin/.
[7] Testing at the speedandscaleof Google, Jun 2011. http://goo.gl/2B5cyl.
[8]ToolsforcontinuousintegrationatGooglescale,Jan2011. https://goo.gl/Gqj7uL.
[9] Apache Camel. http://camel.apache.org/.
[10]Apache Commons Math. https://commons.apache.org/proper/commons-math/.
[11] Apache CXF. https://cxf.apache.org/.
[12] ASM. http://asm.ow2.org/.[13]
T.Ball. Onthelimitofcontrolflowanalysisforregressiontestselection. ACM
SIGSOFT Software Engineering Notes, 23(2):134â€“142, 1998.
[14]J. Bell, O. Legunsen, M. Hilton, L. Eloussi, T. Yung, and D. Marinov. DeFlaker:
Automatically detecting flaky tests. In International Conference on Software
Engineering, 2018. to appear.
[15]L.C.Briand,Y.Labiche,andG.Soccar.Automatingimpactanalysisandregression
test selection based on uml designs. In International Conference on Software
Maintenance and Evolution, pages 252â€“261, 2002.
[16]A. Celik, M. Vasic, A. Milicevic, and M. Gligoric. Regression test selection
acrossjvmboundaries. In JointEuropeanSoftwareEngineeringConferenceand
Symposium on the Foundations of Software Engineering, pages 809â€“820, 2017.
[17]J.Chen,Y.Bai,D.Hao,L.Zhang,L.Zhang,andB.Xie. Howdoassertionsimpact
coverage-based test-suite reduction? In International Conference on Software
Testing, Verification and Validation, pages 418â€“423, 2017.
[18]D.DiNardo,N.Alshahwan,L.Briand,andY.Labiche. Coverage-basedregression
testcaseselection,minimizationandprioritization:Acasestudyonanindustrial
system.Software Testing, Verification and Reliability, 25(4):371â€“396, 2015.
[19]H. Do and G. Rothermel. On the use of mutation faults in empirical assessments
of test case prioritization techniques. Transactions on Software Engineering,
32(9):733â€“752, 2006.
[20]S. Elbaum, G. Rothermel, and J. Penix. Techniques for improving regression
testing in continuous integration development environments. In Joint European
SoftwareEngineeringConferenceandSymposiumontheFoundationsofSoftware
Engineering, pages 235â€“245, 2014.
[21]S. Fujiwara, G. v. Bochmann, F. Khendek, M. Amalou, and A. Ghedamsi. Test
selection based on finite state models. IEEE Transactions on software engineering,
17(6):591â€“603, 1991.
[22]M.Gligoric,L.Eloussi,andD.Marinov. Ekstazi:Lightweighttestselection. In
InternationalConferenceonSoftwareEngineering,ToolDemonstrationTrack ,pages
713â€“716, 2015.
[23]M.Gligoric,L.Eloussi, andD.Marinov. Practicalregressiontestselectionwith
dynamic file dependencies. In International Symposium on Software Testing and
Analysis, pages 211â€“222, 2015.
[24]D. Hao, L. Zhang, X. Wu, H. Mei, and G. Rothermel. On-demand test suite
reduction. In InternationalConferenceonSoftwareEngineering,pages738â€“748,
2012.
[25]D. Hao, L. Zhang, L. Zhang, G. Rothermel, and H. Mei. A unified test case
prioritization approach. Transactions on Software Engineering and Methodology,
24(2):10:1â€“10:31, 2014.
[26]M.J.Harrold,J.A.Jones,T.Li,D.Liang,A.Orso,M.Pennings,S.Sinha,S.A.Spoon,
and A. Gujarathi. Regression test selection for Java software. In International
ConferenceonObject-OrientedProgrammingSystems,Languages,andApplications,
pages 312â€“326, 2001.
[27]H. Hemmati and L. Briand. An industrial investigation of similarity measures
for model-based test case selection. In International Symposium on Software
Reliability Engineering, pages 141â€“150, 2010.
[28]J. A. Jones and M. J. Harrold. Test-suite reduction and prioritization for modified
condition/decisioncoverage. IEEETransactionsonsoftwareEngineering,29(3):195â€“
209, 2003.
[29]D. C. Kung, J. Gao, P. Hsia, J. Lin, and Y. Toyoshima. Class firewall, test order,
andregressiontestingofobject-orientedprograms. JournalofObject-Oriented
Programming, 8(2):51â€“65, 1995.
[30]O. Legunsen, F. Hariri, A. Shi, Y. Lu, L. Zhang, and D. Marinov. An extensive
studyofstaticregressiontestselectioninmodernsoftwareevolution. In JointEuropean Software Engineering Conference and Symposium on the Foundations of
Software Engineering, pages 583â€“594, 2016.
[31]O.Legunsen,A.Shi,andD.Marinov. Starts:Staticregressiontestselection. In
International Conference on Automated Software Engineering, Tool Demonstration
Track, pages 949â€“954, 2017.
[32]Y.Lu,Y.Lou,S.Cheng,L.Zhang,D.Hao,Y.Zhou,andL.Zhang. Howdoesregres-siontestprioritizationperforminreal-worldsoftwareevolution? In International
Conference on Software Engineering, pages 535â€“546, 2016.
[33]A. Memon, Z. Gao, B. Nguyen, S. Dhanda, E. Nickell, R. Siemborski, and J. Micco.
Taming google-scale continuous testing. In International Conference on Software
Engineering, Software Engineering in Practice Track, pages 233â€“242, 2017.
[34]A.Orso,N.Shi,andM.J.Harrold. Scalingregressiontestingtolargesoftware
systems. In JointEuropeanSoftwareEngineeringConferenceandSymposiumon
the Foundations of Software Engineering, pages 241â€“251, 2004.
[35]X. Ren, F. Shah, F. Tip, B. G. Ryder, and O. Chesley. Chianti: a tool for change
impact analysis of Java programs. In International Conference on Object-oriented
Programming, Systems, Languages, and Applications, pages 432â€“448, 2004.
[36]X.Ren,F.Shah,F.Tip,B.G.Ryder,O.Chesley,andJ.Dolby. Chianti:Aprototype
change impact analysis tool for Java. Technical Report DCS-TR-533, Rutgers
University CS Dept., 2003.
[37]G.RothermelandM.J.Harrold. Asafe,efficientregressiontestselectiontech-
nique.Transactions on Software Engineering and Methodology, 6(2):173â€“210, 1997.
[38]G. Rothermel, R. H. Untch, C. Chu, and M. J. Harrold. Test case prioritization:
An empirical study. In International Conference on Software Maintenance and
Evolution, pages 179â€“189, 1999.
[39]B. G. Ryder and F. Tip. Change impact analysis for object-oriented programs. In
WorkshoponProgramAnalysisforSoftwareToolsandEngineering,pages46â€“53,
2001.
[40]R. K. Saha, L. Zhang, S. Khurshid, and D. E. Perry. An information retrieval
approachforregressiontestprioritizationbasedonprogramchanges. In Interna-
tional Conference on Software Engineering, volume 1, pages 268â€“279, 2015.
[41]A.Shi,A.Gyori,M.Gligoric,A.Zaytsev,andD.Marinov. Balancingtrade-offs
intest-suitereduction. In JointEuropeanSoftwareEngineeringConferenceand
Symposium on the Foundations of Software Engineering, pages 246â€“256, 2014.
[42]A.Shi,S.Thummalapenta,S.K.Lahiri,N.Bjorner,andJ.Czerwonka. Optimizing
test placement for module-level regression testing. In Proceedings of the 39th
International Conference on Software Engineering, pages 689â€“699, 2017.
[43]A. Shi,T. Yung, A.Gyori, and D.Marinov. Comparing and combiningtest-suite
reductionand regressiontest selection. In JointEuropean SoftwareEngineering
Conference and Symposium on the Foundations of Software Engineering, pages
237â€“247, 2015.
[44]M. Vasic, Z. Parvez, A. Milicevic, and M. Gligoric. File-level vs. module-level re-
gressiontestselectionfor.net. In JointEuropeanSoftwareEngineeringConference
andSymposiumontheFoundationsofSoftwareEngineering,IndustryTrack,pages
848â€“853, 2017.
[45]F.Wilcoxon. Individualcomparisonsby rankingmethods. Biometricsbulletin,
1(6):80â€“83, 1945.
[46]G. Xu and A. Rountev. Regression test selection for aspectj software. In Interna-
tional Conference on Software Engineering, pages 65â€“74, 2007.
[47]S. Yoo and M. Harman. Regression testing minimization, selection and prior-
itization: a survey. Software Testing, Verification and Reliability, 22(2):67â€“120,
2012.
[48]K.Zhai,B.Jiang,andW.K.Chan. Prioritizingtestcasesforregressiontesting
oflocation-based services:Metrics,techniques, andcasestudy. Transactionson
Services Computing, 7(1):54â€“67, 2014.
[49]L. Zhang, D. Hao, L. Zhang, G. Rothermel, and H. Mei. Bridging the gap be-
tween the total and additional test-case prioritization strategies. In International
Conference on Software Engineering, pages 192â€“201, 2013.
[50]L.Zhang,M.Kim,andS.Khurshid. Localizingfailure-inducingprogramedits
based on spectrum information. In International Conference on Software Mainte-
nance and Evolution, pages 23â€“32, 2011.
[51]L.Zhang,D.Marinov,L.Zhang,andS.Khurshid. AnempiricalstudyofJUnittest-
suitereduction. In InternationalSymposiumonSoftwareReliabilityEngineering,
pages 170â€“179, 2011.
[52]H. Zhong, L. Zhang, and H. Mei. An experimental study of four typical test suite
reduction techniques. Information and Software Technology , 50(6):534â€“546, 2008.
209
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:51:40 UTC from IEEE Xplore.  Restrictions apply. 