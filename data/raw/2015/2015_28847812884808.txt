SWIM: Synthesizing What I Mean
Code Search and Idiomatic Snippet Synthesis
Mukund Raghothaman
University of Pennsylvania
rmukund@seas.upenn.eduYi Wei
Microsoft Research,
Cambridge
jasonweiyi@gmail.comY oussef Hamadi
Laboratoire d‚ÄôInformatique
√âcole Polytechnique,
Palaiseau
youssefh@lix.polytechnique.fr
ABSTRACT
Modern programming frameworks come with large libraries,
with diverse applications such as for matching regular expres-
sions, parsing XML les and sending email. Programmers
often use search engines such as Google and Bing to learn
about existing APIs. In this paper, we describe swim , a
tool which suggests code snippets given API-related natural
language queries such as \generate md5 hash code". The
query does not need to contain framework-specic trivia such
as the type names or methods of interest.
We translate user queries into the APIs of interest using
clickthrough data from the Bing search engine. Then, based
on patterns learned from open-source code repositories, we
synthesize idiomatic code describing the use of these APIs.
We introduce structured call sequences to capture API-usage
patterns. Structured call sequences are a generalized form of
method call sequences, with if-branches and while -loops to
represent conditional and repeated API usage patterns, and
are simple to extract and amenable to synthesis.
We evaluated swim with 30common C# API-related
queries received by Bing. For 70% of the queries, the rst
suggested snippet was a relevant solution, and a relevant
solution was present in the top 10results for all benchmarked
queries. The online portion of the workow is also very
responsive, at an average of 1:5 seconds per snippet.
1. INTRODUCTION
Modern software engineering is reliant on large standard
libraries, such as the .NET Framework class library, the Java
SDK, and the Android SDK. These libraries provide a large
variety of pre-implemented functionality, such as for matching
regular expressions, parsing XML les, sending email, and
platform-specic features such as accessing the GPS sensors
and the phone camera. When faced with an API-related task,
This work was done when Mukund Raghothaman was
an intern in Yi Wei and Youssef Hamadi's group at Microsoft
Research, Cambridge. The authors gratefully thank Abhishek
Udupa for suggesting the name swim .
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from permissions@acm.org.
ICSE ‚Äô16, May 14-22, 2016, Austin, TX, USA
c2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI:http://dx.doi.org/10.1145/2884781.2884808most programmers rely on search engines such as Google and
Bing. They seek answers to two main questions: ( a) what
APIs to use to solve their specic problem, and ( b) how to
write the code involving those APIs. Developers will often
read a few returned web pages to see if their code must follow
certain programming idioms, or common usage practices.
For example, good practice dictates that les be closed after
I/O is complete, and data may be transmitted via a socket
only after a connection is successfully established. In many
cases, developers search for API usage examples on online
code repositories such as GitHub and Bitbucket, or directly
in their company's proprietary code bases. This learning
process is possible due to widely available information related
to programming. However, a developer still needs to read
multiple web pages, and many programs written by others
to learn about these APIs and their usage patterns.
This paper introduces swim , a tool to automate some of
this discovery process. swim is a code generator whose input
is a natural language query in English, such as\match regular
expression" or \read text le", i.e. the usual queries that a
developer would enter in a search engine. In response, swim
outputs snippets of C# code, such as that shown in gure 2,
which hopefully implement the task described in the query.
The query and the synthesized code snippets are API-related,
meaning that they require the use of APIs in the solution.
Given that most programmers heavily use API libraries in
their daily development activities, this is an important class
of queries submitted to search engines.
In this paper, the word API refers to a eld or method from
a class in the framework. swim consists of two components:
the rst component, the natural language to API mapper,
suggests a set of APIs given a user query in English. The
second component, the synthesizer, generates code snippets
using the suggested APIs.
To suggest a set of APIs from a user query, the natural
language to API mapper builds a model of the form Pr(tjQ),
wheretis an API name, and Qis a user query. This is the
probability of the API tappearing in a snippet that solves
the task described by Q. This model Pr(tjQ)is learned
from clickthrough data collected by Bing. The clickthrough
data is a log of (query;URL )pairs which is recorded by most
search engines. Each (query;URL )pair indicates that the
user clicked on the result URL when presented with a list
of results for query . For programming related queries, the
returned web pages often mention API names, or contain
code snippets which invoke APIs. The clickthrough data
thus establishes a connection between English words in user
queries and API names in our target programming language,
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   357
O
ine analysisU
ser query
A
PI lookup
R
anked APIs
S
tructured call
sequence selection
Co
de
synthesis
S
olution
snippetsQu
ery to
API modelClickthrough
data
S
tructured call
sequence indexS
tructured call
sequence extractionGitHub
code corpus
V
ariable name
model
Figure 1: Architecture of the swim tool.
C#.
Note that the natural language to API name mapper only
suggests which API names should be used. There is often
more detail to the use of an API than just the method to be
invoked or the eld to be queried. This includes contracts
such as \ T.foo() may only be called after a call to T.bar()
returned true", and best practices such as ushing a stream
after writing to it. This data and control ow information,
along with other code artifacts such as variable names, is not
provided by the natural language to API mapper. This is
a deliberate design decision, because: ( a) we want to make
use of most of the clickthrough data. Many clicked web
pages may only mention the API name, without giving code
snippets, so no program analysis can be performed. In such
cases, we still want to record the fact that a particular API
name is mentioned. ( b) The insight is that to solve a task, if
a few key API names are given, the rest of the program is
quite predictable, so a simpler model, which is consequently
easier to implement and train, may suce.
To synthesize code snippets from a set of suggested API
names, the synthesizer decides how to combine (some of) the
APIs together to form a valid and human-readable snippet.
There are several parts to code synthesis: ( a) deciding how
the object is to be constructed, ( b) deciding the sequence
of methods to be invoked, and elds to be queried and
set in this object before the target API method may be
invoked, ( c) the control ow between these object actions,
and ( d) choosing appropriate variable names. The synthesizer
relies on another model, structured call sequences , to generate
code with control- and data-ows. Structured call sequences
describe typical usage patterns for API classes. These usage
patterns reveal how API classes are used, for example, which
method calls precede other method invocations, and how
control ows between these statements. Using structured
call sequences allows the synthesizer to generate code which
covers the suggested APIs from the natural language to
API mapper, and at the same time, obeys common coding
conventions.
Structured call sequences are extracted from open-sourceprojects on GitHub. This is because for most classes Tin the
API framework, GitHub contains many more usage samples
than can be extracted from web pages. For each supported
type, swim extracts structured call sequences from the source
les in the code corpus. In general, there may be multiple
ways of using any given type, and so multiple structured call
sequences may be extracted for each type. They are grouped
by syntactic equality, and their occurrence frequencies are
recorded for later use in ranking the generated solutions.
Figure 1 shows the overall architecture of swim . The rst
thread builds the natural language to API mapper using
clickthrough data from Bing. The second thread analyses
the GitHub code corpus and builds an index of structured
call sequences and a dictionary of variable names to be used
during code generation. Both threads are run oine. Finally,
on receiving the user query, we consult the natural language
model to suggest a ranked list of APIs, and nd relevant
structured call sequences from the index using those APIs as
search keys. These structured call sequences are synthesized
into solution snippets. This last thread is what is run online
in response to a user query.
To evaluate swim , we trained the natural language model
with 15 days of clickthrough data from Bing, and learned
structured call sequences from a corpus of 25,000 open-source
projects from GitHub. For each type, we extracted structured
call sequences from 10,000 source les using the type. We
then asked swim 30 commonly occurring API-related queries
from the Bing query logs. A professional developer graded the
results: for 70% of the queries, the rst solution snippet was
marked relevant, and for all the queries, a relevant snippet
was present in the top 10 generated solutions. 88% of the
chosen variable names were marked appropriate, and our
response time was very fast, averaging about 1:5 seconds per
produced snippet.
Contributions.
In summary, the main contributions of this paper are:
1.a technique to map natural language queries to API
358string pattern ;
RegexOptions options ;
var regex = new Regex ( pattern , options );
string input ;
var match = regex . Match ( input );
if ( match . Success )
{
var groups = match . Groups ;
}
Figure 2: Example code to match a string against a regular
expression.
names;
2.the concept of structured call sequences to express com-
mon API usage patterns, and an algorithm to extract
structured call sequences from C# code;
3.a synthesis algorithm to generate code snippets from
structured call sequences; and
4.a prototype implementation of these ideas in the tool
swim , with experiments showing that relevant code
snippets are generated for frequently asked API-related
queries.
Paper outline.
The rest of this paper is organized as follows. We introduce
structured call sequences, describe their extraction from the
code corpus, and describe the synthesis of code snippets
in section 2. Next, in section 3, we introduce the natural
language to API model, explain how the model is trained
from the search engine clickthrough data, and how user
queries are translated into structured call sequences for the
synthesizer. We then present a preliminary evaluation of
swim in section 4, and conclude with a summary of related
work in section 5.
2. STRUCTURED CALL SEQUENCES
2.1 Motivation
In gure 2, we present C# code to match a string against a
regular expression. Focus on the object referred to by the vari-
able match . It has type System.Text.RegularExpressions.
Match , and is created by the method Regex.Match(string) ,
which accepts a single argument input of type string . Next,
theGroups property of the object is accessed depending
on the value of Success . Observe that this pattern of ob-
ject creation, method invocation and eld accesses, summa-
rized as Regex.Match(string); if (get(Match.Success))
{ get(Match.Groups) } , is a common way to use the Match
type: the Match.Groups eld is only relevant if the input
string matched the regular expression, given by the eld
Match.Success .
As another example, in gure 3, we present code to read
the contents of a text le using the System.IO.Stream-
Reader class. It is usual practice to release the associ-
ated system resources by calling StreamReader.close() af-
ter I/O is complete. In this case, the pattern of object
usage may be summarized as: new StreamReader(string);
StreamReader.ReadToEnd(); StreamReader.Close() .string path ;
var reader = new StreamReader ( path );
reader . ReadToEnd ();
reader . Close ();
Figure 3: Example code to read a text le using the Stream-
Reader class.
We introduce the term structured call sequences to refer
to these patterns of object creation, method invocation, and
eld accesses. A structured call sequence describes the object
creation technique and a permissible sequence of methods
invoked and elds accessed, with control ow blocks such
asifand while to describe conditional and repeated usage
patterns. They can express more complicated object usage
patterns than just the construction technique or even specic
sequences of invoked methods, but can still be extracted
easily, and can be readily synthesized into code snippets.
The thesis of this paper is that when grouped by syntac-
tic equality, commonly occurring structured call sequences
largely describe idiomatic API usage.
We will formally dene structured call sequences in sub-
section 2.2, and then describe their extraction from the code
corpus in subsection 2.3. Finally, in subsection 2.4, we will de-
scribe how structured call sequences are used in synthesizing
code snippets to be presented to the user.
2.2 Formal deÔ¨Ånition
swim works with a simple subset of the C# programming
language. We assume a nite set Types of types. Each type
Thas a nite set of constructors, methods, and elds, and
some methods and elds may be marked static . Methods
are uniquely identied by their signature : the containing
type, method name and the list of argument types. Each
method optionally has a return type, and is otherwise marked
void. Notably, the language model disallows generic types,
anonymous classes, rst-class functions, downcasts and ex-
ceptions.1
Given an object of type T, an individual program statement
might either ( a) invoke a method T.method(a1,a2,:::), with
arguments a1,a2, . . . , or ( b) get or set the value of a eld
T.field . Following the terminology of [21], we term these
atomic constructs actions :
action T::=get(T.field)jset(T.field)
jT.method(a1,a2,:::)
If the member is static , such as Console.WriteLine() , then
the action can be performed without actually possessing an
object of type T. If the type of the queried eld is U, or if the
return type of the invoked method is U, we write action T:U.
As notational convenience, we also treat constructors of the
classTas static methods named newwith return type T.
A structured call sequence chTfor a classTbegins with
the creation of an object with type T, and is a nite sequence
of actions, together with conditional statements and loops to
represent repeated method invocations. Formally, structured
1This limitation is because synthesizing a term with a
given type is computationally hard in languages with generics
and rst-class functions [27]. Extending our techniques to
these language features is an important direction of future
work.
359call sequences are productions of the following grammar:
chT::=creation Tjaction Tjunknown
jchT1;chT2;;chTk
jif ( chT1) { chT2} else { chT3}
jwhile ( chT1) { chT2}
creation T::=action U:T
The special construct unknown indicates unknown object
usage, for example, when objects are passed to or returned
by methods with unknown bodies. For ease of presentation,
we omit control structures such as for-loops and do while -
loops, even though these are also handled by swim .
2.3 Extracting structured call sequences
Our rst problem is to scan the code corpus and extract, for
each typeTin the framework, all structured call sequences
corresponding to T. We use the recently developed Microsoft
Roslyn compiler framework [20] to analyze source les from
the code corpus. Informally, Roslyn exports the compiler ser-
vices and associated parsing and analysis algorithms as a C#
library. It is a convenient framework because of two reasons:
(a) It gracefully handles errors in source les, and performs
best-eort parsing, type resolution and variable binding in
the presence of syntax errors and missing libraries. Because
of its nature, we cannot expect all projects in the corpus
to be free of compile-time errors, and diverse build systems
make building or even identifying library dependencies in-
feasible. Furthermore, ( b) Roslyn transforms the source les
into an AST representation with simple visitors, and this
makes structured call sequence extraction straightforward.
The extraction algorithm works at the level of individual
methods in the code corpus. Let vbe a local variable of
typeTwhich is not aliased by other variables. We extract
the structured call sequence chvdescribing its lifetime by
traversing the AST of the method body:
1.For each assignment statement of the form v=u.
member , if we can resolve the referenced member to
a (possibly static) member U.method() of the frame-
work, we produce the creation action U.method() .
2.For each method call v.method() or eld access v.
field =:::orvar f =v.field , we emit the cor-
responding action: set(T.field) orget(T.field)
respectively.
3.Given a sequence of statements stmt 1;stmt 2;;stmt k,
we extract the structured call sequence chifor the vari-
ablevfrom each statement stmt i, and produce the
structured call sequence ch1;ch2;;chk.
4.For the conditional statement if ( stmt 1) { stmt 2}
else { stmt 3}, we produce the structured call se-
quence if ( ch1) { ch2} else { ch3}, where ch1,
ch2andch3are the structured call sequences obtained
from stmt 1,stmt 2andstmt 3respectively. While -loops
are similarly handled.
5.Whenevervis passed as an argument to another method,
we insert a unknown inchv.
Finally, we simplify the structured call sequences thus
obtained by a few straightforward rules. For example, ch1;
if ( empty ) { ch2} else { empty }, where empty is the
empty sequence, is transformed into ch1;ch2.Algorithm 1 code-gen (chT;v). Given the type T, linear call
sequence chT, and variable name v, the algorithm synthesizes
the corresponding code snippet.
1.IfchT=creation TorchT=action T, the synthesis
procedure is described in subsections 2.4.1 and 2.4.2
respectively.
2.IfchT=chT1;chT2;;chTkis a sequence, then the
code snippet stmt iis synthesized for each element chTi.
The concatenated snippet stmt 1;stmt 2;;stmt kis
produced as output.
3.IfchT=if ( chT1){chT2} else { chT3}, then a
boolean expression boolExpr is synthesized from chT1
as described in subsection 2.4.3. If chT2and chT3are
synthesized into stmt 2andstmt 3respectively, then we
emit the snippet if (boolExpr) { stmt 2} else {
stmt 3}. A similar procedure is used for while -loops.
By not performing inter-procedural analysis or considering
aliased variables, our structured call sequence extraction tech-
nique is admittedly conservative. In our anecdotal experience,
while individual structured call sequences may be ignored
during extraction, because of the large number of source les
used, pervasive idioms are not missed. We postpone the
development of more sophisticated extraction techniques to
future work.
2.4 Synthesis from structured call sequences
We now consider the problem of transforming a linear call
sequence chTinto a code snippet, given the user query and
the chosen variable name v. We will discuss the choice of
variable names later in subsection 2.4.4, and section 3 is
devoted to obtaining the structured call sequence chTfrom
the user query.
The overall snippet synthesis procedure is described in
algorithm 1. There are three important details, correspond-
ing to object creation, the synthesis of method arguments,
and the synthesis of boolean expressions, described in sub-
sections 2.4.1, 2.4.2 and 2.4.3 respectively.
2.4.1 Object creation and tracer methods
Recall that a linear call sequence chThas a single creation
action creation T, which is also the rst element in chT. If
creation Tis of the form U.method() , where method() is a
static member of the class U, then we can simply declare
the variable vasvarv=U.method(:::). However, in the
case that method() is an instance variable, we rst need an
objectuof typeU. For example, constructing the object
match in gure 2 requires that we already have an object of
type Regex .
Furthermore, it is conceivable that objects of type Uthem-
selves maintain state, and it is therefore insucient to blindly
construct objects of type Uand invoke method() . Construct-
ing the object uis therefore similar to the original snippet
synthesis problem, except for the additional constraint that
it contain an invocation of method() . We call method() the
tracer of interest.
We now describe the return value of code-gen (chT;v),
where chT=creation T;usageTandcreation T=U.method() .
Letstmt Tbe the snippet synthesized by code-gen (usageT;v).
360Given the user query, let chUbe the top-ranked structured
call sequence over Uwhich also contains an invocation of
U.method() , andube the chosen name for the object of
typeU. Then code-gen (creation T;usageT;v) returns the
output of code-gen-tracer . The procedure code-gen-tracer is
similar to code-gen , except that it inserts the snippet stmt T
immediately after the rst invocation of U.method() .
For example, for the snippet in gure 2, we start with the
structured call sequence Regex.Match(string); if (get(
Match.Success)) { get(Match.Groups) } . We rst syn-
thesize the snippet:
if ( match . Success )
{
var groups = match . Groups ;
}
To construct the Regex object, we then pick the structured
call sequence new Regex(string, RegexOptions); Regex.
Match(string) and merge the two snippets to produce the
nal synthesized code.
While it is possible that the recursive object construction
procedure may not terminate, we have not observed this prob-
lem in practice. If necessary, we can force termination after
a pre-determined recursive depth with the default snippet:
default(U).method() .
2.4.2 Synthesizing method arguments
A second diculty is in synthesizing method arguments.
Given a method T.method(v1,v2,:::,vk),swim currently
chooses the default value for each argument ( null for refer-
ence types and zero for value types):
varv1= default ( T1);
varv2= default ( T2);
:::
varvk= default ( Tk);
T. method (v1,v2,:::,vk);
whereT1,T2, . . . ,Tkare the types of the respective ar-
guments. More involved schemes can be used to generate
argument values, but would require much greater computa-
tional resources, and are therefore not used.
2.4.3 Boolean conditions
The nal interesting detail is in the synthesis of boolean
expressions for conditional statements and loop bodies. Syn-
thesizing meaningful conditions would require deep semantic
knowledge: consider for example, distinguishing between the
pair of code snippets in gures 4 and 5. Deciding which of
these code snippets is more \standard" requires understand-
ing the semantics of the IEnumerator.MoveNext() method,
and that a return value of true indicates that the iterator
was successfully advanced to the next position.
We instead use the following simple procedure to obtain
condition expressions. Recall that every conditional in a
linear call sequence has a single action. We can readily
convert every non- void methodT.method() into the boolean
expression T.method(:::) == default( U), and every eld
access get(T.field) into the boolean expression T.field
== default( U), whereUis the return type of the method
or the type of the eld respectively. While we generally
generate non-standard code, accessing the correct elds in the
conditions is usually valuable guidance to the programmer.List list ;
var enumerator = list . GetEnumerator ();
while ( enumerator . MoveNext ())
{
var current = enumerator . Current ;
}
Figure 4: Idiomatic conversion of the return value to a
boolean.
List list ;
var enumerator = list . GetEnumerator ();
while (! enumerator . MoveNext ())
{
var current = enumerator . Current ;
}
Figure 5: Non-standard conversion of the return value to a
boolean.
2.4.4 Picking variable names
Consider the solution snippet from gure 2 where the vari-
ables pattern andinput were instead called var1 andvar2
respectively. This hypothetical solution snippet is clearly
inferior as it obscures the role of the variables pattern and
input . Therefore, an important part of a good solution
snippet is the choice of descriptive variable names.
A similar problem has been considered by Raychev et
al [24], in the context of deobfuscating JavaScript programs.
However, the statically-typed setting, and the fact that we
are synthesizing target code rather than analyzing it means
that simpler techniques suce in our setting.
At each step during synthesis, we maintain a set of for-
bidden identiers F. This includes identier names which
have already been used and the set of reserved C# keywords.
Whenever we declare a new variable, we accumulate a list
of candidate names C, sorted by preference, and pick the
rst name in Cwhich does not appear in the forbidden set
F. If all candidate names are unviable, we use the following
simple fallback naming convention: the variable name is the
rst non-forbidden identier in the innite list var1,var2,
var3, . . . .
We will now describe the procedure to assemble the list
of candidate names C. For each method T.m() in the API
framework, we scan the code corpus and construct a list l
of name-frequency pairs, ( name 1;n1);(name 2;n2);:::, where
niis the number of times the result of the invocation T.m()
was assigned to a variable named name i. Now consider an
object vdescribed by the structured call sequence var v =
T.m();:::. For this object, we choose the candidate names
Cto be the list of names name 1;name 2;:::inl, arranged in
descending order of frequency. A similar algorithm is used
to choose the candidate names for each eld assignment T.f.
Thus, for example, we observed that objects constructed
using the new Regex(string, RegexOptions) constructor
are most frequently assigned to a variable named regex , and
objects returned by the Regex.Match(string) method are
most frequently stored in a variable named match . Note that
the construction of the name-frequency lists is performed of-
ine and the online variable naming algorithm simply chooses
361the rst non-forbidden name in this list.
For objects intended as method arguments, the candidate
name listCis the singleton list [ name ], where name is the
formal name of the argument in the method declaration.
3. MAPPING USER QUERIES TO STRUC-
TURED CALL SEQUENCES
Structured call sequences represent empirically observed
API usage idioms, but do not directly tell us which high-level
problems they solve. Since the swim synthesizer accepts
a natural language query as input, we rst need to nd
a mapping from natural language queries to the C# API.
In this section we describe how we use query expansion to
model this mapping and explains how we train the model
from clickthrough data.
3.1 Query expansion
The mapping from a natural language query to API names
can be modeled as Pr(tjQ), the probability of a C# API
tappearing in the solution snippet, given the user query
Q. The higher the probability, the more likely it is that t
appears in the code to solve the task described in Q. The
synthesizer applies this model to the query Q, nds the most
likely APIs that should appear in the synthesized snippet,
and uses the structured call sequences extracted from the
code corpus to output the appropriate snippets.
The key idea is to view the computation of Pr(tjQ) as a
query expansion problem. Query expansion is a commonly
used technique in search engines, where the user input is
usually vague. Experience and research have shown that
adding one or more words to the queries can enhance the
precision of the search result. This process is called query
expansion. Usual candidates for word expansion include
synonyms of the words appearing in the user queries. In our
case, we want to nd the API names that are relevant to the
user query, i.e. expand the user query with API names.
People have proposed many ways to formulate the query
expansion problem. In this paper, we follow the method
proposed by Gao et al. [9], which uses clickthrough data to
nd relevant words for expansion. When a user types a
query in a search engine, and the engine returns a list of
results, the user may click on one or more links. Search
engines typically record a lot of information about this click,
but in the present paper, we only consider the set of pairs
(query;URL ), indicating the url URL the user clicked on in
response to the search term query .
For a programming-related query, the clicked web page
will possibly contain one or more program fragments. To
nd candidate API names tfor the expansion, we look at
code fragments appearing on those web pages. We examine
text contained within HTML tags such as <pre> ,<code>
and <p>, which are likely to contain code fragments. We
then use the C# parser from Roslyn to parse the text (the
text has been preprocessed before parsing, to correct obvious
syntax errors), and determine whether it is a fragment of
C# code. Finally, API names are extracted from the parsed
code fragments. Besides code fragments, we also collect API
names that are mentioned in the text.
LetPbe the list of API names in the code fragment,
in their appearance order. Then a single clickthrough pair
(query;URL) can be represented as a set of (Q;P ) pairs
(because there may be multiple fragments on a web page).The mapping from the user query Qto an API name t,
or the probability of tbeing the expansion term given Q, is
given by:
Pr(tjQ) = Pr(tjq1;q2;:::;q n)
=nX
i=1Pr(tjqi)Pr(q ijQ); (1)
whereQ= [q 1;q2;:::;qn] represents the user query contain-
ing the words q1,q2, . . . ,qn;Pr(tjqi) is the probability of
the APItgiven a single query word qi;Pr(qijQ) is the
unsmoothed unigram probability of the query word qiin the
queryQ.
Equation 1 decomposes the calculation of Pr(tjQ) into
the calculation of two simpler probabilities Pr(tjqi) and
Pr(qijQ). The former quanties the connection between an
API and a single word in the user query. The latter quanties
how likely the query term qiappears in queries; it serves as
normalization. We now describe how we estimate these two
probabilities from data.
3.2 Estimating Pr(tjq)
Pr(tjq) represents the probability of the API element t
appearing in the solution snippet, given the occurrence of
the wordqin the user query. It establishes the connection
from English words to C# API elements. We estimate this
model using clickthrough data, which also links user queries
to web pages containing API names.
As described above, clickthrough data contains (Q;P )
pairs, where Qis the user query and Pis the list of API names
appearing in code fragments on the clicked web page. Note
however that this still does not relate individual query words
q2Qto API elements t2P. To solve the problem, we use
a standard procedure for training statistical word alignment
models [5] by applying an expectation maximization (EM)
algorithm. The EM algorithm rst initializes Pr(tjq) to
random values for each tandq, and then iteratively updates
the probabilities to maximize the likelihood of generating
the training data.
As an example, if the user query is \match regular ex-
pression", then Q= [\match";\regular";\expression" ]. If the
clicked web page contains the snippet shown in gure 2, then
the API sequence is P= [Regex;Match;Success;Groups ].
Given enough data, the EM algorithm will eventually as-
sign values to Pr(tjq) such that Pr(Regexj\regular" )>
Pr(Groupsj\regular").
3.3 Estimating Pr(qjQ)
This probability quanties how likely the query term qis
to appear in a query and is calculated as follows:
Pr(qjQ) =qP
q02Qq0; (2)
whereqis the appearance frequency of qin all possible
queries. To estimate q, we use the same clickthrough data,
focussing on just the queries:
q=# of times qoccurs in query log
Total term count in query log: (3)
3.4 Retrieving structured call sequences from
user queries
Given a user query Q, the Pr(tjQ) model oers a list of
possible API elements, ranked by their probabilities. Each
362API element tmay be a member of a dierent type Tin the
framework. However, to generate code, the swim synthesizer
needs to start with a single structured call sequence. This
section describes how we use document similarity to choose
the structured call sequence from a ranked list of API names.
LetA= [a1;a2;:::;aN] be the list of all API names that
the system supports, where Nis the number of APIs. Then
a real-valued vector of length Nwith each element chosen
from the range [0; 1] can represent the weight of each API.
Note that conceptually, this vector is very long, its length is
equal to the number of API names that are supported in the
system. For example, the current implementation of swim
includes 30,345 types in common .NET libraries and over
500,000 methods from those types. The vector is sparse, most
of its elements are zeros (or very small probability values if
we perform smoothing while training the Pr( tjQ) model).
From a ranked list of probabilities Pr(tjQ), we create
thequery vector by setting the corresponding element to
the values of those probabilities. For example, if Pr(Regexj
\regular" ) = 0: 1 and Pr(Matchj\regular" ) = 0: 05, then we
set the elements corresponding to the APIs Regex andMatch
in the query vector to 0 :1 and 0:05 respectively.
We can also similarly represent each structured call se-
quence chby a vector vchof lengthN: for each API tthat
appears in ch, we set the corresponding element in vchto 1,
and all other elements are set to 0. We call this the struc-
tured call sequence vector ofch. The synthesizer maintains a
repository of vectors for all structured call sequences mined
from the code corpus.
With query vectors and structured call sequence vectors
dened, the synthesizer uses cosine similarity among those
vectors to nd the most relevant ones. The cosine similarity
function is widely used in information retrieval. It is dened
by the following formula:
similarity(A;B ) =PN
i=1AiBiqPN
i=1A2
iqPN
i=1B2
i; (4)
whereAandBare two vectors of length N. Given two
documents, the higher the similarity, the more relevant the
documents are to each other. We use the implementation
provided by the open-source information retrieval package
Lucene [1], which compares the query vector against all
structured call sequence vectors and returns a ranked list of
structured call sequences. These structured call sequences
are then fed to the synthesis algorithm of section 2.4.
4. EV ALUATION
In this section, we present some initial results from the
swim synthesizer. The tool is currently implemented as a C#
library: we are working on the design of an intuitive interface,
so that more comprehensive user studies and measurements
of programmer productivity can be performed.
4.1 Setup
swim needs large amount of C# code to extract structured
call sequences, and clickthrough data to train the natural lan-
guage to API mapper. To prepare the data, we downloaded
25,000 C# projects from GitHub. These projects together
contain about 3 million les.
We extracted structured call sequences for 30,345 common
.NET types. For each type, we located 10,000 C# les where
that type appears and used those les for extraction.To train the natural language to API mapping model, we
used 15 days of clickthrough data from the Bing search engine.
We ltered the data to only focus on queries that contain
the keyword \C#". The training is done through a standard
implementation of expectation maximization algorithm.
To evaluate the synthesis process, we selected 30 API-
related queries from the Bing search log. These queries
are frequently asked, and they cover various API usages,
from simple to more involved. The column labeled Query in
table 1 lists the chosen queries. The typical APIs column
of the table lists some APIs that are commonly used to
implement tasks described in the queries, as suggested by
the NLP model of section 3. Note that the listed APIs are
not exhaustive, because the same task can be implemented
by many dierent APIs in dierent ways. Only the most
likely APIs are listed in the table. The full list of generated
solutions may be downloaded from http://arxiv.org/src/
1511.08497v2/anc/ .
4.2 Experiment results
We asked a professional developer to grade the top 10
swim solutions for each benchmark query. The snippets
were marked relevant / irrelevant, indicating whether the
developer thought that it implements the task described in
the query. We also asked the developer to annotate all the
chosen variable names as appropriate or inappropriate. A
variable name was annotated as appropriate if it adequately
conveyed the purpose of the variable.
4.2.1 Snippet relevance
The FRank column of table 1 reports the rank of the rst
generated solution that is relevant to the query. This metric
is important because most users will scan through the results
from top to bottom. For the benchmark queries, in 70%
of the cases, the rst generated snippet is relevant. This
shows the synthesizer is able to locate the correct APIs and
further choose the likely control ow structures to generate
snippets. Also observe that in all cases, at least one of the
top 10 solutions was marked relevant.
The %Top5 and %Top10 columns of table 1 report the
percentage of relevant snippets in the top 5 and 10 gener-
ated solutions. Observe that the user queries are vague, and
there are usually many ways to implement a given task using
dierent APIs, and so there is no single correct solution to a
query. By exploring dierent APIs and dierent usage pat-
terns, the synthesizer generates variations of the same topic,
so the users can browse through and understand dierences
among them. These two metrics quantify how relevant a
list of suggestions are to a query. On average, 65% of the
synthesized snippets from the top 5 generated solutions, and
54% from the top 10 solutions are observed to be relevant.
This suggests that the overall list of presented solutions is
itself relevant to the user.
4.2.2 Variable name choices
The proper choice of variable names is an important part
of program comprehensibility, and particularly so in program
synthesis. The column marked Var (%) in table 1 lists
the number of variable names that the synthesizer chose
for the 10 most relevant snippets. The numbers outside
the parentheses are the number of variable names, and the
numbers inside the parentheses are the fraction of meaningful
names as annotated by the professional developer. The
363Table 1: Benchmark queries. The columns are described in section 4.2.
Query Typical APIs FRank %Top5 %Top10 Var (%) Time (in s)
append strings StringBuilder.Append, ToString 1 100 100 36(83) 30
append text le File.AppendText, AppendAllText 4 40 40 12(100) 6
binaryformatter BinaryFormatter.Serialize, Deserialize 1 60 80 21(76) 10
connect to database SqlConnection.Open 1 100 100 22(95) 13
convert int to string Convert.ToString 3 20 30 11(100) 6
convert string to int Convert.ToInt32 1 80 50 13(92) 6
copy le File.Copy 3 60 40 16(100) 5
create le File.Create, WriteAllText 3 40 30 13(100) 7
current time DateTime.Now 1 80 70 13(85) 10
download le from url WebClient.DownloadFile 1 100 80 27(89) 13
execute sql statement SqlCommand.ExecuteNonQuery, ExecuteReader 2 60 50 22(73) 17
generate md5 hash code MD5.ComputeHash 2 60 40 17(88) 8
get current directory Directory.GetCurrentDirectory 2 20 10 1(100) 8
get les in folder Directory.GetFiles 2 40 40 12(100) 8
launch process Process.Start, WaitForExit; ProcessStartInfo 8 0 20 19(84) 29
load bitmap image Bitmap.FromImage, FromFile 1 80 90 65(77) 28
load dll Assembly.Load 1 100 80 20(95) 7
match regular expression Regex.Match; Match.Success 1 80 70 40(90) 23
open le dialog OpenFileDialog.ShowDialog, FileName 1 100 90 20(50) 23
parse datetime from string DateTime.Parse 1 80 40 46(89) 33
parse xml XmlTextReader.Create, Read 1 40 20 44(77) 33
play sound SoundPlayer.Play, PlaySync 1 80 40 11(100) 13
random number Random.Next, NextBytes, NextDouble 1 100 100 27(93) 11
read binary le File.OpenRead, Read, FileStream.Read 1 80 40 55(87) 26
read text le File.ReadAllText, StreamReader.ReadLine 1 80 60 14(100) 23
send mail SmtpClient.Send, MailMessage.From, MailAddress 1 60 60 28(86) 24
serialize xml XmlSerializer.Serialize 1 100 80 41(95) 12
string split String.Split, Regex.Split 1 60 40 28(82) 8
substring STring.Substring 1 40 30 37(54) 13
test le exists File.Exists 1 20 10 25(92) 9
Average 1.6 65 54 25(88) 15
numbers reveal that in majority of cases, 88% on average,
the synthesizer is able to nd meaningful variable names.
It also shows that for very specic tasks, such as \random
number", \serialize xml", the chosen variable names are more
likely to be meaningful; while for more general tasks such as
\substring", the variable names contain more noise. This is
because the synthesizer chooses the variable names according
to their appearance frequency in GitHub repositories. For
specic tasks, the distribution of variable names given by
programmers are more focused on a small range of names,
while for general tasks the variable name distribution tends
to be more uniform.
4.2.3 Synthesis time
Finally, responsiveness was an important requirement while
creating swim . The column marked Time in table 1 shows
the time required by the synthesizer to generate the top 10
solutions. The experiments were run on a desktop worksta-
tion with a 3.6GHz processor and 16 GB of RAM. Observe
that we require an average of 1.5 seconds to produce each
solution snippet, and believe that this is responsive enough
for practical use. Also note that the current prototype syn-
thesizer is not optimized and contains many redundant calls
to Roslyn and the reection APIs. Better engineering is
likely to further reduce the response time by a large fraction.
4.3 Examples of synthesized snippets
We now provide concrete examples of synthesized snippets
and discuss the behavior of swim . We will also describe the
limitations of the current tool and ideas for future improve-
ments.
Figure 6 shows the top snippet for the query \convert int
to string". This is an incorrect snippet because the snippet
converts a string to an integer by using the Convert.ToInt32var value = default ( string );
System . Convert . ToInt32 ( value );
Figure 6: Incorrect solution snippet for query \convert int to
string".
var dlg = new OpenFileDialog ();
dlg. Title = null ;
dlg. InitialDirectory = null ;
dlg. Filter = null ;
dlg. FilterIndex = 0;
if (dlg. ShowDialog ())
{
var fName = dlg. FileName ;
}
Figure 7: Snippet for query \open le dialog".
()method, instead of converting an integer to a string. The
third solution (not shown here) generated by swim actually
chooses the right method Convert.ToString() . In this case,
the natural language to API mapper favors ToInt32() since
it happens much more often. In future work, natural language
processing techniques such as pattern detection can be used
to disambiguate APIs. For example, if the query contains
patternT1toT2, whereT1andT2are types, we then require
the input and output type of the synthesized snippets to be
T1andT2.
Figure 7 shows the top snippet for the query \open le
dialog". The snippet rst initializes a FileOpenDialog object,
and then sets a few properties such as title of the dialog,
364var startInfo = new ProcessStartInfo ();
startInfo . FileName = null ;
var process = Process . Start ( startInfo );
process . WaitForExit ();
Figure 8: Snippet for query \launch process" (complete).
initial directory of the le explorer location when the dialog
starts, the le pattern lters, and the lter index. Then, the
snippet shows the dialog and gets the user selected le (if
any) when the dialog is closed. Notice that all the properties
are initialized to the default value of the corresponding types.
In C#, the default value for string isnull, and for intis0.
This is the default behavior of the synthesizer. While this is
appropriate for properties such as InitialDirectory , it is
incorrect for properties such as Filter . The FileOpenDialog
.Filter property expects strings in a certain format. For
example, a lter to select text les and all les looks like
"Text Files (.txt)|*.txt|All Files (*.*)|*.*" . Such
properties are common in API libraries. Other examples
include database connection strings, which is needed in the
query \open database connection" and the datetime format
strings, such as "yyyy mm dd" , in the query \parse datetime
from string".
Ideally, for properties required to be in a certain format,
the synthesizer should provide some common patterns, in-
stead of just generating the type-wise default values. The
diculty is in automatically determining which properties
require formats. Potential solutions include: ( a) scanning the
documentation of class properties to detect the mention of
particular formats; and ( b) scanning code repositories to nd
properties which are frequently assigned constants and use
heuristics to decide if those constants have some structure.
Figure 8 shows the 8th solution snippet for the query
\launch process". This snippet rst creates a ProcessStart-
Info object and sets the FileName property to null (actually,
the user will set the property to the proper le name to
launch), and then uses the static method Process.Start()
from the Process class to start the process. The return value
of the Start() method is an object of type Process . Calling
WaitForExit() on the object waits for the launched process
to nish. To come up with this snippet, the synthesizer
chooses the root type Process to rst generate the third and
the fourth line. And then, since the Start() method requires
an object of type ProcessStartInfo , the synthesizer nds a
structured call sequence of type ProcessStartInfo to come
up with the rst and second line.
However, if the synthesizer starts with the type Process-
StartInfo , then the result will not be a complete snippet.
Figure 9 shows this case. This snippet is the top snippet for
the query\launch process". It only includes the statements to
initialize a ProcessStartInfo object, but misses the statements
on the Process class to start and terminate the process. Thus,
the snippet is incomplete. The reason for the incompleteness
is that after the part for ProcessStartInfo is generated,
the synthesizer stops because the generated statements for
ProcessStartInfo do not rely on any other objects. How-
ever, the synthesizer does not know ProcessStartInfo alone
does not fully implement the user query.
To solve this problem, future work will allow the synthesizer
to focus on more than one root types, by modeling the jointvar startInfo = new ProcessStartInfo ();
startInfo . FileName = null ;
startInfo . CreateNoWindow = false ;
startInfo . RedirectStandardOutput = false ;
startInfo . RedirectStandardError = false ;
startInfo . UseShellExecute = false ;
Figure 9: Snippet for query \launch process" (incomplete).
probability Pr(T1;T2), representing the probability of T1and
T2appearing together. If two types are more likely to appear
together, the synthesizer will generate fragments for both
types and combine them together. To estimate such joint
probability, we may need to do inter-procedure analysis when
extracting structured call sequences.
5. RELATED WORK
There is a large body of work on programmer assistance
and snippet synthesis tools. With the wide availability of
open source software, there is a growing realization that
existing code corpuses can be used in program analysis and
code synthesis (including contemporary initiatives such as the
DARPA MUSE program [7]). In this section, we summarize
existing work and contrast it with the present paper.
Snippet synthesis as type inhabitation.
Traditional IDE tools such as IntelliSense are derived from
early systems such as Project Marvel [14]. These tools typ-
ically provide interactive feedback listing the methods and
elds in the highlighted object, and expressions of appropri-
ate type available for use in the highlighted context.
The Prospector tool [17] considered the problem of synthe-
sizing \jungloids": snippets of code which construct an object
of typeTout, given an input object of type Tin. Prospector
works with a very simple type system, where the set of types
is nite, and a set of pre-determined functions convert ob-
jects of one type into another. Unfortunately, in languages
with richer type-systems, such as with generics and rst-class
functions, type inhabitation is computationally intractable.
More recent work [13, 12] focusses on developing practical
heuristics and techniques to rank completions so that short,
natural code snippets are ranked higher than longer snippets
of code. Synthesis of partial expressions [23] has also been
considered as a way to generalize IntelliSense, where the tool
automatically suggests expressions with holes that consume
one or more objects with known types, and emit an object
whose type is optionally known.
Lastly, tools such as CodeHint [8] are very interesting
because they perform type inhabitation at runtime. At a
very high level, CodeHint is a debugger plugin which can
be queried for expressions of a given type or whose values
satisfy some assertion.
One major limitation of these techniques is that the devel-
oper is required to have some prior knowledge of the API
framework (such as the names of types). Expressing queries
in natural language allows developers who are new to the
development environment to easily nd their way around.
Typestate aware code completion.
Another shortcoming of type-inhabitation-based code com-
pletion techniques is their ignorance of object state, which is
365central to the imperative programming method. The notion
of typestate was rst considered by Strom and Yemini [26].
While the original proposal required syntactic extensions for
API designers to describe typestate, there have been eorts
to automatically learn typestate by program analysis [4] and
from code corpuses [10, 19].
Eorts to describe API usage by n-grams [3] and method
call sequences [18] can be seen as typestate-aware code syn-
thesis. slang [25] similarly analyses method call sequences
from a code corpus, and uses statistical techniques to in-
sert method calls at designated holes in the user program.
There are several challenges with these approaches, including:
(a) sensitivity to algorithm parameters, such as n, which are
dicult to set accurately, and ( b) diculty with API usage
idioms which are inexpressible as nite state machines (such
as library-provided stack data structures), and where the
next permissible methods depend on previous return values
(for example, where IEnumerator.Current contains a mean-
ingful value only if the last call to IEnumerator.MoveNext()
returned true). Furthermore, given two method call se-
quencess1ands2from dierent les in the code corpus,
\merging" these into a single suggested call sequence sis
dicult. In our work, we do not try to merge structured call
sequences, and instead group them by syntactic equality and
suggest multiple solution snippets.
Groums [22] are similar to structured call sequences, but
while structured call sequences deal with the lifetime of a sin-
gle object, groums relate data ows between multiple objects.
Groums were initially proposed to perform anomaly detec-
tion, but more recently, GraLan [21] has been proposed as a
similar statistical model for code completion. Because swim
synthesizes snippets from scratch, rather than attempting to
ll holes in existing programs, the simpler model oered by
structured call sequences suces for our purposes.
Answering free-form queries.
A major component of our problem setting is the use of
free-form natural language queries, while most existing work
on snippet synthesis requires prior knowledge of relevant
types such as ProcessStartInfo orXmlTextReader . The
SNIFF system [6] attempts to solve the same problem as us,
but diers in technical details. In SNIFF, each method call in
the codebase is annotated with the text of the associated API
documentation while indexing. On receiving an input query,
all annotated source les matching the query are retrieved,
and a \type-based intersection" of these is returned as the
synthesized code. The main dierences from this system
are two-fold. First, the use of search engine clickthrough
data rather than relying on documentation text allows us to
use a larger body of text and more reliably convert natural
language queries into the APIs of interest. Second, because
structured call sequences are extracted oine, rather than
by online codebase analysis, we can respond quickly to input
queries, currently at an average of 1:5 seconds per synthesized
snippet, even in our unoptimized implementation.
In [15], Keivanloo et al propose a method to spot code
examples from free-form user queries. The idea is to rst
group code fragments together according to their structural
similarity using clone detection, and then a set of associative
keywords, such as identier names, are extracted from each
group of code. These keywords are matched against the user
query to retrieve and rank the code. The method is similar to
SNIFF, where the code is represented by the documentationof the APIs that are used in it.
Gvero et al [11] developed the anyCode tool to synthesize
snippet expressions from free-form queries. Given a query,
the tool is able to synthesize an expression invoking a single
API that implements the desired task. anyCode locates
which API method to use by string matching. To handle
the problem of API name and search query term mismatch,
anyCode includes words with similar meanings to API names
by using WordNet. anyCode also uses parse tree from a
natural language processing toolkit to nd relations among
variable names and constant expressions mentioned in the
query to put them in the synthesized expression. anyCode
is similar to what we built in Bing Developer Assistant [28],
in which we also use NLP parse trees to handle variable
generation in code synthesis. The main dierence between
anyCode and our current work is that anyCode is only able to
synthesize an expression; swim can synthesize snippets with
multiple statements and control ows. To synthesize such
snippets, we face a much larger search space than anyCode
does, hence a code model describing popular usage patterns
is key to making the tool practical.
Le et al [16] introduced the SmartSynth tool, which syn-
thesizes mobile applications from free-form user descriptions.
SmartSynth focuses on a predened set of APIs to use, and
builds a model to map words in user queries to the set of APIs.
It also uses dataow analysis to nd missing statements to
synthesize. SmartSynth can generate larger snippets than
swim , but a user needs to provide a longer description to
the tool. Another dierence is that SmartSynth focuses a
predened set of APIs while our tool handles all possible
APIs in the open domain.
In [2], Allamanis et al developed a bimodal model to map
natural language queries to snippets. The work builds a
separate model for each query type and is able to synthesize
snippets for variations of the type of query. For example,
for the query type \create array", the method can synthesize
snippets for dierent ways to create arrays, such as \create a
2d array", \make int array". The model for each query type is
built manually by ning all possible ways that people might
ask for a query type, and this manual process is expensive.
In contrast, the work presented in current paper is fully
automated, but cannot understand subtle dierences in the
phrasing of a query.
6. CONCLUSION
In this paper, we described swim , a tool to synthesize
API-related code snippets given natural language queries.
We mined API usage patterns, in the form of structured
call sequences, from open-source C# projects, and used
clickthrough data from Bing to map queries to the types
and methods of interest. We believe that structured call
sequences are a fundamental empirical artifact of API design,
and that they can be used in numerous applications such as
code anomaly detection.
There are several potential directions of future work. First,
better NLP techniques would help to distinguish between
similar APIs, such as Convert.ToInt32() and Convert.To-
String() . Second, better structured call sequence extraction
algorithms and handling of language features such as excep-
tions would expand the range of expressible API-usage idioms.
Finally, modeling joint probability distributions would help
to solve the incomplete snippet problem of gure 9.
3667. REFERENCES
[1]Apache Lucene. https://lucene.apache.org , 2015.
Accessed on August 18, 2015.
[2]A. Allamanis, D. Tarlow, A. Gordon, and Y. Wei. Bi-
modal modelling of source code and natural language.
InProceedings of the 32th International Conference on
Machine Learning, ICML 2015, 2015.
[3]M. Allamanis and C. Sutton. Mining source code repos-
itories at massive scale using language modeling. In
Proceedings of the 10th Working Conference on Mining
Software Repositories , MSR '13, pages 207{216. IEEE
Press, 2013.
[4]R. Alur, P. Cern y, M. Parthasarathy, and W. Nam.
Synthesis of interface specications for Java classes. In
Proceedings of the 32nd Symposium on Principles of Pro-
gramming Languages , POPL '05, pages 98{109. ACM,
2005.
[5]P. Brown, V. D. Pietra, S. D. Pietra, and R. Mercer. The
mathematics of statistical machine translation: Param-
eter estimation. Computational Linguistics , 19(2):263{
311, June 1993.
[6]S. Chatterjee, S. Juvekar, and K. Sen. SNIFF: A search
engine for Java using free-form queries. In Fundamen-
tal Approaches to Software Engineering , volume 5503
ofLecture Notes in Computer Science , pages 385{400.
Springer, 2009.
[7]DARPA. Mining and understanding software en-
claves (MUSE). http://www.darpa.mil/program/
mining-and-understanding-software-enclaves ,
2014. Accessed on August 18, 2015.
[8]J. Galenson, P. Reames, R. Bodik, B. Hartmann, and
K. Sen. CodeHint: Dynamic and interactive synthesis of
code snippets. In Proceedings of the 36th International
Conference on Software Engineering , ICSE 2014, pages
653{663. ACM, 2014.
[9]J. Gao and J.-Y. Nie. Towards concept-based transla-
tion models using search logs for query expansion. In
Proceedings of the 21st ACM International Conference
on Information and Knowledge Management , CIKM '12,
pages 1:1{1:10. ACM, 2012.
[10]N. Gruska, A. Wasylkowski, and A. Zeller. Learning
from 6,000 projects: Lightweight cross-project anomaly
detection. In Proceedings of the 19th International Sym-
posium on Software Testing and Analysis , ISSTA '10,
pages 119{130. ACM, 2010.
[11]T. Gvero and V. Kuncak. Interactive synthesis using free-
form queries. In Proceedings of the 37th International
Conference on Software Engineering , volume 2 of ICSE
2015, pages 689{692, May 2015.
[12]T. Gvero, V. Kuncak, I. Kuraj, and R. Piskac. Complete
completion using types and weights. In Proceedings of
the 34th ACM SIGPLAN Conference on Programming
Language Design and Implementation , PLDI '13, pages
27{38. ACM, 2013.
[13]T. Gvero, V. Kuncak, and R. Piskac. Interactive syn-
thesis of code snippets. In Computer Aided Verication ,
volume 6806 of Lecture Notes in Computer Science,
pages 418{423. Springer, 2011.
[14]G. Kaiser, P. Feiler, and S. Popovich. Intelligent assis-
tance for software development and maintenance. IEEE
Software, 5(3):40{49, 1988.
[15]I. Keivanloo, J. Rilling, and Y. Zou. Spotting workingcode examples. In Proceedings of the 36th International
Conference on Software Engineering , ICSE 2014, pages
664{675. ACM, 2014.
[16]V. Le, S. Gulwani, and Z. Su. SmartSynth: Synthesizing
smartphone automation scripts from natural language.
InProceeding of the 11th Annual International Con-
ference on Mobile Systems, Applications, and Services ,
MobiSys '13, pages 193{206. ACM, 2013.
[17]D. Mandelin, L. Xu, R. Bod k, and D. Kimelman. Jun-
gloid mining: Helping to navigate the API jungle. In
Proceedings of the 2005 ACM SIGPLAN Conference
on Programming Language Design and Implementation ,
PLDI '05, pages 48{61. ACM, 2005.
[18]A. Mishne, S. Shoham, and E. Yahav. Typestate-based
semantic code search over partial programs. In Pro-
ceedings of the International Conference on Object Ori-
ented Programming Systems Languages and Applications ,
OOPSLA '12, pages 997{1016. ACM, 2012.
[19]M. Monperrus and M. Mezini. Detecting missing
method calls as violations of the majority rule. ACM
Transactions on Software Engineering and Methodology ,
22(1):7:1{7:25, Mar. 2013.
[20]K. Ng, M. Warren, P. Golde, and A. Hejlsberg. The
Roslyn project: Exposing the C# and VB compiler's
code analysis. Microsoft white paper , Oct. 2011.
[21]A. T. Nguyen and T. Nguyen. Graph-based statistical
language model for code. In Proceedings of the 37th
International Conference on Software Engineering , ICSE
2015. ACM, 2015.
[22]T. T. Nguyen, H. A. Nguyen, N. Pham, J. Al-Kofahi, and
T. Nguyen. Graph-based mining of multiple object usage
patterns. In Proceedings of the the 7th Joint Meeting of
the European Software Engineering Conference and the
Symposium on The Foundations of Software Engineering ,
ESEC/FSE '09, pages 383{392. ACM, 2009.
[23]D. Perelman, S. Gulwani, T. Ball, and D. Grossman.
Type-directed completion of partial expressions. In Pro-
ceedings of the 33rd ACM SIGPLAN Conference on Pro-
gramming Language Design and Implementation, PLDI
'12, pages 275{286. ACM, 2012.
[24]V. Raychev, M. Vechev, and A. Krause. Predicting
program properties from \Big Code". In Proceedings
of the 42nd Symposium on Principles of Programming
Languages , POPL '15, pages 111{124. ACM, 2015.
[25]V. Raychev, M. Vechev, and E. Yahav. Code comple-
tion with statistical language models. In Proceedings of
the 35th ACM SIGPLAN Conference on Programming
Language Design and Implementation , PLDI '14, pages
419{428. ACM, 2014.
[26]R. Strom and S. Yemini. Typestate: A programming lan-
guage concept for enhancing software reliability. IEEE
Transactions on Software Engineering , 12(1):157{171,
Jan. 1986.
[27]P. Urzyczyn. Inhabitation in typed lambda-calculi (a
syntactic approach). In 3rd International Conference on
Typed Lambda Calculi and Applications , pages 373{389.
Springer, 1997.
[28]Y. Wei, N. Chandrasekaran, S. Gulwani, and Y. Hamadi.
Building Bing Developer Assistant. http://research.
microsoft.com/apps/pubs/default.aspx?id=245188 ,
2015.
367