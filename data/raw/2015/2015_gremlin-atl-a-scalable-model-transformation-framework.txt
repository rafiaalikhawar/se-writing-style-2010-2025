Gremlin-A TL: A Scalable Model Transformation
Framework
Gwendal Daniel
AtlanMod Team
Inria, IMT Atlantique, LS2N
Nantes, France
gwendal.daniel@inria.frFr√©d√©ric Jouault
TRAME Team
Groupe ESEO
Angers, France
frederic.jouault@eseo.frGerson Suny√©
AtlanMod Team
Inria, IMT Atlantique, LS2N
Nantes, France
gerson.sunye@inria.frJordi Cabot
ICREA
UOC
Barcelona, Spain
jordi.cabot@icrea.cat
Abstract ‚ÄîIndustrial use of Model Driven Engineering tech-
niques has emphasized the need for efÔ¨Åciently store, access,
and transform very large models. While scalable persistenceframeworks, typically based on some kind of NoSQL database,
have been proposed to solve the model storage issue, the same
level of performance improvement has not been achieved for themodel transformation problem. Existing model transformation
tools (such as the well-known ATL) often require the input models
to be loaded in memory prior to the start of the transformationand are not optimized to beneÔ¨Åt from lazy-loading mechanisms,
mainly due to their dependency on current low-level APIs offered
by the most popular modeling frameworks nowadays.
In this paper we present Gremlin-ATL, a scalable and efÔ¨Åcient
model-to-model transformation framework that translates ATLtransformations into Gremlin, a query language supported by
several NoSQL databases. With Gremlin-ATL, the transfor-
mation is computed within the database itself, bypassing the
modeling framework limitations and improving its performance
both in terms of execution time and memory consumption. Toolsupport is available online.
Index T erms‚ÄîATL; Gremlin; OCL Scalability; Persistence
Framework; model transformation; NoSQL
I. I NTRODUCTION
Models are used in various engineering Ô¨Åelds as abstract
views helping designers and developers understand, manipu-
late, and transform complex systems. They can be manuallyconstructed using high-level modeling tools, such as civilengineering models [1], or automatically generated in model-reverse engineering processes such as software evolution tasks[2] or schema discovery from existing documents [3].
Models are then typically used in Model Driven Engineering
(MDE) processes that rely intensively on model transformationengines to implement model manipulation operations like viewextraction, formal veriÔ¨Åcation or code-generation [4].
With the growing accessibility of big data (such as national
open data programs [5]) as well as the progressive adoptionof MDE techniques in the industry [6], [7], the volume anddiversity of data to model has grown to such an extent thatthe scalability of existing technical solutions to store, query,and transform these models has become a major issue [8].
For example, reverse engineering tools such as MoDisco [2]
rely on MDE technologies to extract a set of high-levelmodels representing an existing code base. These models arethen operated by model transformations to create a set ofartifacts providing a better understanding of the system, suchas UML [9] class diagrams, code documentation, or qualitymetrics. However, these tools typically face scalability issueswhen the input code base increases because the underlyingmodeling frameworks are not designed to store and transformlarge models efÔ¨Åciently.
Scalable modeling storage systems [10]‚Äì[12] have been
proposed to tackle this issue, focusing on providing a solutionto store and manipulate large models in a constrained memoryenvironment with minimal performance impact. Relational andNoSQL databases are used to store models, and existing solu-tions rely on a lazy-loading mechanism to optimize memory
consumption by loading only the accessed objects from thedatabase.
While these systems have improved the support for man-
aging large models, they are just a partial solution to the
scalability problem in current modeling frameworks. In itscore, all frameworks are based on the use of low-level modelhandling APIs. These APIs are then used by most otherMDE tools in the framework ecosystem to query, transform,
and update models. These APIs are focused on manipulating
individual model elements and do not offer support for generic
queries and transformations.
This low-level design is clearly inefÔ¨Åcient when combined
with persistence framework because (i) the API granularity istoo Ô¨Åne to beneÔ¨Åt from the advanced query capabilities of thebackend, and (ii) an important time and memory overhead is
necessary to construct navigable intermediate objects neededto interact with the API. As shown in Figure 1, this is par-
ticularly true in the context of model transformations, whichheavily rely on high-level model navigation queries (such astheallInstances() operation returning all instances of a
given type) to retrieve input elements to transform and createthe corresponding output elements. This mismatch betweenhigh-level modeling languages and low-level APIs generatesa lot of fragmented queries that cannot be optimized andcomputed efÔ¨Åciently by the database [13].
To overcome this situation, we propose Gremlin-A TL, an al-
ternative transformation approach. Instead of translating high-level model transformation speciÔ¨Åcations into a sequence ofinefÔ¨Åcient API calls, we translate them into database queriesand execute them directly where the model resides, i.e. in the
978-1-5386-2684-9/17/$31.00 c/circlecopyrt2017 IEEEASE 2017, Urbana-Champaign, IL, USA
T echnical Research462
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. $3,&DOO
¬´
$3,&DOOQ'DWDEDVH
0RGHO
7UDQVIRUPDWLRQ7UDQVIRUPDWLRQ
(QJLQH
0RGHOLQJ
)UDPHZRUN
$DOO,QVWDQFHVQDPHJHWD
JHWDQDPH
¬´
JHWDQ
JHWDQQDPH
Fig. 1. Model Transformation Engine and Modeling Framework Integration
database store. This approach is based on a Model Mapping
that allows to access an existing database using modeling
primitives, and on a Transformation Helper that lets modelers
tune the transformation execution to Ô¨Åt their performance
needs.
The rest of this paper is structured as follow: Section II
introduces the input transformation language and the output
database query language of our approach and presents a run-
ning example that will be used through the paper. Section IIIpresents Gremlin-A TL and its key components, Section IVpresent how a transformation is executed from a user point
of view. Sections V and VI present our prototype and thebenchmarks used to evaluate our solution. Section VII showsan application example where Gremlin-A TL is used to specify
data extraction rules between two data sources. Finally, Sec-
tion VIII presents the related work and Section IX summarizesthe key points of the paper, draws conclusion, and presents ourfuture work.
II. B
ACKGROUND
In this section we introduce the key features of A TL [4],
the model transformation language we use as the input of ourframework, and Gremlin [14], a multi-database graph traversalquery language we use as our output language. We also presentalong the section a running example that is used through this
article to illustrate the different steps of our approach.
A. ATL Transformation Language
In MDE, models are key elements in any software engineer-
ing activity. Models are manipulated and reÔ¨Åned using model-
to-model transformations, and the Ô¨Ånal software artifacts are
(partially) generated with a model-to-text transformation. Each
model conforms to a metamodel that describes its structure and
the possible relationships between model elements and theirproperties.
As an example, Figure 2(a) shows a simple metamodel
representing Types, Methods, and Blocks. Methods are deÔ¨Åned
by a name,avisibility, and contain a set of Blocks representing
their body.AMethod is associated with a return Type, and
can have type parameters.A Constructor is deÔ¨Åned as a
subclass of Method. An instance of this metamodel is shown
in Figure 2(b).
A TL [4] is a declarative rule-based model transformation
language that operates at the metamodel level. Transformationswritten in A TL are organized in modules, that are used to grouptransformation rules and deÔ¨Åne libraries. The language deÔ¨Ånesthree types of rules: (i) matched rules that are declarativeand automatically executed, (ii) lazy rules that have to beinvoked explicitly from another rule, and (iii) called ruleswhich contain imperative code
1. A TL does not assume any
order between matched rules, and keeps a set of trace links
between the source and target models that are used to resolve
elements, and set target values that have not been transformedyet.
The language also deÔ¨Ånes helpers expressed in OCL [15]
that are used to compute information in a speciÔ¨Åc context,
provide global functions, and runtime attributes computed on
the Ô¨Çy. OCL helpers can be invoked multiple times in a
transformation, and are a good solution to modularize similarnavigation chains and condition checking.
Finally, A TL programs are themselves described as models
that conform to the A TL metamodel. This feature allows todeÔ¨Åne high-order transformations, that take an A TL transfor-mation as their input and manipulate it to check invariant
properties that should hold in the output model, infer type, orreÔ¨Åne the transformation. Our approach relies on this reÔ¨Çective
feature to translate A TL transformations into efÔ¨Åcient databasequeries.
Note that in this paper we focus on A TL as our input
language, but our approach can be adapted to other rule-basedtransformation languages, notably the QVT [16] standard.
(a) Metamodel (b) Instance Model
Fig. 2. Example Metamodel and Model
Listing 1 shows a simple A TL transformation based on the
metamodel shown in Figure 2(a). The rule MethodToMethod-
Unit (line 10) matches all the Method elements from the input
model that do not contain a typeParameter and creates the
corresponding MethodUnit in the target model. The attributes
and references of the created element are set using binding
speciÔ¨Åcations: the Ô¨Årst one (line 13) checks if the source ele-ment is a Method or a Constructor and sets the kind attribute
accordingly. The second binding (line 15) sets the value ofthe export attribute by calling the OCL helper getVisibility on
the source element. Finally, the codeElement reference is set
with the Block elements contained in the body reference of the
1Imperative constructs are not discussed in this paper
463
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. source Method. Note that an additional rule has to be speciÔ¨Åed
to map Block instances to their corresponding output elements,
that will be resolved by the A TL engine using its trace links
mechanism.
1-- returns a String representing the visibility of a
Method
2helper context java!Method def: getVisibility():String=
3 let result : VisibilityKind = self.visibility in
4 ifresult.oclIsUndefined() then
5 "unknown"
6 else
7 result.toString()
8 endif;
9-- Transforms a Java Method into a KDM Method unit
10 rule MethodToMethodUnit {
11 from src : java!Method(src.typeParameters.isEmpty())
12 totgt : kdm!MethodUnit(
13 kind <- if(src.oclIsKindOf(java!Constructor))
14 then ‚Äôconstructor‚Äô else ‚Äômethod‚Äô endif,
15 export <- src.getVisibility(),
16 codeElement <- src.body->asSet() }
Listing 1. SimpliÔ¨Åed Java2KDM Rule Example
B. Gremlin Query Language
NoSQL databases are an efÔ¨Åcient option to store large
models [17], [18]. Nevertheless, their diversity in terms of
structure and supported features make them hard to unifyunder a standard query language to be used as a genericsolution for our approach.
Blueprints [19] is an interface designed to unify NoSQL
database access under a common API. Initially developed for
graph stores, it has been implemented by a large number ofdatabases such as Neo4j, OrientDB, and MongoDB. Blueprintsis, to our knowledge, the only interface unifying severalNoSQL databases
2.
Blueprints is the base of the Tinkerpop stack: a set of tools
to store, serialize, manipulate, and query graph databases.
Gremlin [14] is the query language designed to queryBlueprints databases. It relies on a lazy data-Ô¨Çow frameworkand is able to navigate, transform, or Ô¨Ålter a graph.
Gremlin is a Groovy domain-speciÔ¨Åc language built on top
ofPipes, a data-Ô¨Çow framework based on process graphs. A
process graph is composed of vertices representing computa-tional units and communication edges which can be combinedto create a complex processing. In Gremlin terminology, thesecomplex processing vertices are called traversals, and are
composed of a chain of simple computational units namedsteps. Gremlin deÔ¨Ånes three types of steps: (i) transform steps
that compute values from their inputs, (ii) Ô¨Ålter steps that
select or rejects elements w.r.t a given condition, and (iii) side-
effect steps that compute side-effect operations such as vertex
creation or property updates. In addition, the step interface
provides a set of built-in methods to access meta information,such as the number of objects in a step, output existence,or the Ô¨Årst element in a step. These methods can be calledinside a traversal to control its execution or check conditionson particular elements in a step.
Gremlin allows the deÔ¨Ånition of custom steps, functions,
and variables to handle query results. For example, it is
2Implementation list is available at https://github.com/tinkerpop/blueprintspossible to assign the result of a traversal to a variable anduse it in another traversal, or deÔ¨Åne a custom step to handlea particular processing.
Fig. 3. Persisted Model
Figure II-B presents a possible graph database representa-
tion of the model shown in Figure 2(b): grey vertices representMethod, Type, and Block metaclasses that are linked to their in-
stance through instanceof edges. The Method m1 is linked to a
Block instance through the body edge, and the Types void and
Tusing returnType and typeParameters edges, respectively.
Finally, m1 contains a property visibility that holds a
string representation of the VisibilityKind enumeration. This
graph mapping of metamodel instances is based on the oneused in NeoEMF/Graph [20].
In what follows, we describe some simple Gremlin exam-
ples based on this model. A Gremlin traversal begins with aStart step, that gives access to graph level information such as
indexes, vertex and edge lookups, and property based queries.For example, the traversal below performs a query on the
classes index that returns the vertices indexed with the name
Method, representing the Method class in the Figure 2(a). In
our example, this class matches vertex 1.
g.idx("classes")[[name:"Method"]]; // -> v(1)
The most common steps are transform steps, which allow
navigation in a graph. The steps outE(rel) and inE(rel) navigate
from input vertices to their outgoing and incoming edges,respectively, using the relationship rel as Ô¨Ålter. inV and outV
are their opposite: they compute head and tail vertices of
an edge. For example, the following traversal returns all thevertices that are related to the vertex 4 by the relationship
typeParameters. The Start step
g.v(4) is a vertex lookup that
returns the vertex with the id 4.
g.v(4).outE("typeParameters").inV;/ /- >[ v(6)]
Filter steps are used to select or reject a subset of input
elements given a condition. They are used to Ô¨Ålter vertices
given a property value, remove duplicate elements in thetraversal, or get the elements of a previous step. For example,the following traversal returns all the vertices related to vertex4 by the relationship typeParameters that have a property name
containing at least one character.
g.v(4).outE("typeParameters").inV
.has("name").filter{it.name.length > 0}; // -> [v(6)]
464
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. Finally, side-effect steps modify a graph, compute a value, or
assign variables in a traversal. They are used to Ô¨Åll collections
with traversal results, update properties, or create elements.For example, it is possible to store the result of the previoustraversal in a table using the Fill step.
def table = [];
g.v(3).outE("typeParameters").inV.has("name")
.filter{it.name.length > 0}.fill(table); // -> [v(6)]
III. G REMLIN -A TL F RAMEWORK
In this section we present Gremlin-A TL, our proposal for
handling complex model-to-model transformations by taking
advantage of the features of the database backends where
the model resides. We Ô¨Årst introduce an overview of theframework and its query translation process. We then presentthe A TLtoGremlin transformation that maps A TL transforma-
tions into Gremlin traversals. Finally, we present the auxiliarycomponents used within the Gremlin query to specify thedatabase on which to compute the query on and the speciÔ¨Åc
conÔ¨Åguration to use.
A. Overview
Figure 4 presents an overview of the translation used in
Gremlin-A TL to create Gremlin Traversals from ATL Trans-
formations. An input transformation is parsed into an ATL
Transformation Model conforming to the ATL metamodel.
This model constitutes the input of our ATLtoGremlin high-
order transformation that creates an output Gremlin Traversal
representing the query to compute.
The ATLtoGremlin transformation uses two generic libraries
to produce the output query: (i) a Model Mapping DeÔ¨Ånition
allowing to access a database as a model by mapping its im-
plicit schema to modeling primitives, and (ii) a Transformation
Helper DeÔ¨Ånition used to tune the transformation algorithm
according to memory and execution time requirements.
The generated traversal can be returned to the modeler
or directly computed in a Gremlin engine that manages theunderlying database. Note that our approach also allows tocompute directly the generated query in a preset NeoEMFdatabase, as explained in Section V.
In the following we detail the ATLtoGremlin transformation,
the Model Mapping and Transformation Helper DeÔ¨Ånition
used in the generated traversal. A dynamic view of ourapproach is provided in Section IV.
B. ATLtoGremlin Transformation
1) Transformation Mapping: Table I shows the mapping
used by Gremlin-A TL to translate A TL constructs into Gremlin
steps. An A TL Module is translated into a Gremlin script, that
represents the top-level container storing the entire query to
execute.
Matched Rule DeÔ¨Ånitions inside the A TL module are
mapped to a sequence of steps that access all the elements ofthe type of the rule. For example, the matched rule deÔ¨ÅnitionMethodToMethodUnit in Listing 1 is translated into the Grem-
lin expression
g.allOfKind("Method") that searches in the
input graph all the elements representing Method instances.
$7/7UDQVIRUPDWLRQ
0RGHO0RGHO0DSSLQJ
,PSO
7UDQVIRUPDWLRQ
+HOSHU,PSOXVHV0RGHO0DSSLQJ
'HILQLWLRQ
7UDQVIRUPDWLRQ
+HOSHU'HILQLWLRQ
$7/WR*UHPOLQ
7UDQVIRUPDWLRQ*UHPOLQ7UDYHUVDOUHPOLQ 7XVHVLPSOHPHQWV
*
LPSOHPHQWVXVHV
XVHV
$7/
0HWDPRGHO
FRQIRUPV7R
Fig. 4. Overview of the Mogwa√Ø-A TL Framework
Abstract Rule DeÔ¨Ånitions are not translated, because they are
called only when a specialized rule is matched. Lazy rule
deÔ¨Ånitions are translated into function deÔ¨Ånitions named with
the rule‚Äôs identiÔ¨Åer and containing their translated body.
Matched rule bodies are mapped to a transform step contain-
ing the translated expressions representing rule‚Äôs out patternand bindings. This transform step is followed by an iterate stepthat tells the Gremlin engine to execute the query. Abstract
rule bodies are directly mapped without creating a transform
step, and generated Gremlin steps are added to the ones of the
translated bodies of the corresponding specialized rules. This
approach Ô¨Çattens the inheritance hierarchy of a transformation
by duplicating parent code in each concrete sub-rule.
Rule Guards deÔ¨Åning the set of elements matched by a rule
are translated into a Gremlin Ô¨Ålter step containing the trans-lated condition to verify. For example, the guard of the ruleMethodToMethodUnit is translated into the following Gremlin
expression that Ô¨Årst navigates the reference typeParameters
and searches if it contains at least one value:
filter{!(src
.getRef("typeParameters").hasNext())} .
Rules‚Äô body can contain two types of A TL constructs:
out patterns representing the target element to create, and
attribute/reference bindings describing the attribute and refer-
ences to set on the created element. Out patterns are mapped
to a variable deÔ¨Ånition storing the result of the createElement
function which creates the new instance and the associatedtrace links. This instruction is followed by a resolveTraces
call that tells the engine to resolve the potential trace linksassociated to the created element. In our example it generatesthe sequence
tHelper.createElement("MethodUnit",
src) that creates a new MethodUnit instance in the target
model and associates it with the src element from the source
model. Attribute and Reference Bindings are respectively trans-
lated into the mapping operation setAtt and a Transformation
Helper‚Äôs link call.
Our mapping translates helper deÔ¨Ånitions into global meth-
ods, which deÔ¨Åne a self parameter representing the context
of the helper and a list of optional parameters. This globalfunction is dynamically added to the Object metaclass to allow
method-like invocation, improving query readability. Global
helper deÔ¨Ånitions are also mapped to global methods, but
465
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. do not deÔ¨Åne a self parameter. Finally, Global V ariables are
translated into unscoped Gremlin variables.
A TL embeds its own speciÔ¨Åcation of OCL, which is used to
navigate the source elements to Ô¨Ånd the objects to transform,
express the guard condition of the transformation rules, anddeÔ¨Åne helpers‚Äô body. We have adapted the mapping deÔ¨Ånedin the Mogwa√Ø framework [21] to Ô¨Åt the OCL metamodelembedded in A TL. In addition, we integrated our Model
Mapping DeÔ¨Ånition component in the translation in order to
provide a generic translation based on an explicit mapping.
The current version of Gremlin-A TL supports an importantpart of the OCL constructs, allowing to express complex
navigation queries over models. As an example, the inline
ifconstruct used in MethodToMethodUnit to check whether
the source element represents a constructor can be translatedinto the equivalent Gremlin ternary operator:
src.isKindOf
("Constructor")? "constructor": "method" .
T ABLE I
AT L TO GREMLIN MAPPING
ATL expression Gremlin step
module Gremlin Script
matched_rule deÔ¨Ånition g.allOfType(type)
abstract_rule deÔ¨Ånition not mapped
lazy_rule deÔ¨Ånition def name(type) { body }
matched_rule body transform{ body }.iterate()
abstract_rule body body3
specialized_rule body transform{ body Uparent.body }.iterate()
rule_guard(condition) Ô¨Ålter{condition}
out_pattern(srcEl, tgtEl) var out = thelper
.createElement(tgtEl.type, srcEl)
tHelper.resolveTraces(srcEl,tgtEl);
attribute_binding e1.setAtt(exp)
reference_binding e1.link(exp)
helper_deÔ¨Ånition def name(var self, params){ expression }
Object.metaClass.name = {
(params) -> name(delegate, params)}
obj.helper(params) obj.helper(params)
global_helper_deÔ¨Ånition def name(params) { expression }
global_helper_computation name(params);
global_variable def name = expression
OCL_Expression Mogwa√Ø4
2) Operation Composition: The above mappings explain
how A TL constructs are mapped individually into the corre-sponding Gremlin steps. In this section we present an overviewof the algorithm used to compose these generated steps into acomplete query. Listing 2 shows the Ô¨Ånal Gremlin output forthe transformation example shown in Listing 1.
In order to generate a complete Gremlin query, our trans-
formation has to navigate the input A TL model and link thegenerated elements together. First, the transformation searchesall the helper deÔ¨Ånitions (including global ones) and trans-
lates them according to the mapping shown in Table I. The
generated functions are added to the Gremlin script container,making them visible for the translated A TL rules. This Ô¨Årst
3The body of abstract rules is duplicated in the transform step of all its
sub-rules
4OCL expression are translated by an improved version of the Mogwa√Ø
frameworkstep generates the lines 1 to 8 for the helpers getVisibility.
Note that this initial phase also generates the function thatregisters contextual helpers to the Object metaclass (lines 10-
13), allowing method-like invocation in generated expressions.
Lazy_rule deÔ¨Ånitions are then translated into global func-
tions, and added to the Gremlin script container. Out pattern
and bindings contained in the Lazy_rule body are translated
into their Gremlin equivalent following the mapping presented
in the previous section and appended in the generated functionbody.
1 // getVisibility() helper
2 def getVisibility(var vertex) {
3 var result = vertex.getAtt("visibility");
4 if(result == null)
5 return "unknown";
6 else
7 return result;
8 }
9
10 // Add getVisibility to Vertex method list
11 Vertex.metaClass.getVisibility =
12 { -> getVisibility(delegate) }
13
14 // MethodToMethodUnit
15 g.allOfKind(Method).filter{
16 def src = it;
17 !(src.getRef("typeParameters").hasNext())
18 }.transform{
19 def src = it;
20 var tgt = tHelper.createElement("MethodUnit", src);
21 tHelper.resolveTraces(src, tgt);
22 tgt.setAtt("kind", src.isKindOf("Constructor") ? "
constructor" : "method");
23 tgt.setAtt("export", src.getVisibility());
24 tgt.setRef("codeElement", src.getRef("body").toList
()asSet);
25 }.iterate();
Listing 2. Generated Gremlin Traversal
Once this initial step has been performed the transformation
searches all the matched rules deÔ¨Ånitions and creates the
associated Gremlin instructions. If the rule deÔ¨Ånes a guardthe generated Ô¨Ålter step is directly linked after the allOfKind
operation in order to select the elements that satisfy the guard‚Äôscondition. Then, the transform step (and the associated iterate
call) corresponding to the matched rule body is created and
added at the end of the traversal. In our example this operationgenerates lines 15 to 18.
Out pattern elements contained in the matched rule body are
retrieved and the corresponding Gremlin instructions (lines 19
to 24) are added to the transform step closure. Finally, Rule‚Äôs
bindings are transformed following the mapping and added in
the closure‚Äôs instructions. Note that helper calls inside bind-
ing‚Äôs expressions are also translated into the correspondingmethod calls during this operation.
C. Auxiliary Components
1) Model Mapping: The Model Mapping library deÔ¨Ånes the
basic modeling operations that can be computed by a given
database storing a model. It provides a simple API allowingdesigners to express the implicit schema of their database withmodeling primitives. Model Mapping can be manually imple-
mented for a given database, or automatically extracted usingschema inference techniques such as NoSQLDataEngineering[22]. This mapping is used within the generated Gremlin query
466
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. to access all the elements of a given type, retrieve element‚Äôs
attribute values, or navigate references.
Table II summarizes the mapping operations used
in Gremlin-A TL and groups them into two categories:metamodel-level and model-level operations. The Ô¨Årst group
provides high-level operations that operate at the metamodel
level, such as retrieving the type of an element, type con-formance checks, new instances creation, and retrieve all theelements conforming to a type. The second group providesmethods that compute element-based navigation, such as re-trieving a referenced element, computing the parent/childrenof an element, and access its attributes. Finally, these model-level methods allow to update and delete existing referencesand attributes.
Note that the ATLtoGremlin transformation only relies on
the deÔ¨Ånition of these operations to generate a Gremlin query,and is not tailored to a speciÔ¨Åc Model Mapping implementa-
tion.
T ABLE II
GRAPH MAPPING API
Operation Description
allOfType(type) Returns all the strict instances of the given type
allOfKind(type) Returns all the instances of the given type or
one of its sub-types
getType(el) Returns the type of the element el
isTypeOf(el, type) Computes whether elis a strict instance of type
isKindOf(el, type) Computes whether elis an instance of type or
one of its sub-types
newInstance(type) Creates a new instance of the given type
getParent(el) Returns the element corresponding to the par-ent of el
getChildren(el)
Returns the elements corresponding to the chil-dren of el
getRef(from, ref)
Returns the elements connected to from with
the reference ref
setRef(from, ref, to) Creates a reference ref between from and to
delRef(from, ref, to) Deletes the reference ref between from and to
getAtt(from, att) Returns the value of the attribute attcontained
in the element from
setAtt(from, att, v) Set the value of the attribute attof the element
from to the given value v
delAtt(from, att) Deletes the attribute att contained in the ele-
ment from
2) Transformation Helper: The second component used by
the ATLtoGremlin transformation is a Transformation Helper
library that provides transformation-related operations that can
be called within the generated Gremlin traversal. It is basedon the A TL execution engine (presented in Section II-A), andprovides a set of methods wrapping a Model Mapping with
transformation speciÔ¨Åc operations. Note that this library aimsto be generic and can be used directly in ad hoc Gremlinscripts to express transformation rules.
SpeciÔ¨Åcally, our TransformationHelper provides the follow-
ing interface:
-createElement(type, source): creates a new instance ofthe given type mapped to the provided source element.
-link(from, ref, to): creates a link between from and to.
-resolveTraces(source, target): resolves the trace linksconnected to source with the target.-getTarget(source, bindingName): retrieves the target
element mapped to source. If multiple target elements are
created from a single source an optional. bindingName
can be speciÔ¨Åed to tell the engine which one to choose.
-isResolvable(el): computes whether an element can be
resolved.
-isTarget(el): computes whether an element is in the target
model.
-isSource(el): computes whether an element is in the
source model.
The two Ô¨Årst operations are wrappers around mapping
operations that add model transformation speciÔ¨Åc behavior tothe mapping. The
createElement(type, sourceElement
)operation delegates to the mapping operation newInstance
(type) , and adds a trace link between the created element
and the source one. link(from, ref, to) delegates to the
mapping operation setRef to create a regular reference between
from and to or a trace link if tois not yet part of the target
model.
The Ô¨Åve last operations deÔ¨Åne transformation speciÔ¨Åc be-
haviors, such as retrieving the target element from an input
one, resolve trace links, or compute whether an element ispart of the source of the target model. Note that Gremlin-
A TL provides two implementations (one in memory and onein a database) of this library that can be directly plugged tocompute a transformation.
IV . R
UNTIME FRAMEWORK
The Gremlin script generated by the ATLtoGremlin trans-
formation is generic and relies on the Model Mapping and
Transformation Helper interfaces. In order to execute it on an
existing database, the framework needs to bind these abstractinterfaces to their concrete implementations designed to access
a speciÔ¨Åc database.
Figure 5 shows our framework from a user point of view:
the user provides an A TL query to the Query Translation
component (1), which compiles the query into a Gremlin
script and returns it to the user (2). The generated scriptis then sent to the Query Execution API with the concrete
implementation of the Model Mapping and a Transformation
Helper (3) the user wants to use during the execution. The
internal Gremlin engine Ô¨Ånally computes the transformationusing these implementations (4) and returns the result (suchas execution traces, or transformation errors if any) to the user(5).
This architecture allows to pre-compile transformations into
Gremlin scripts and execute them later with speciÔ¨Åc imple-mentations of the Model Mapping. In addition, generated
scripts can be executed multiple times on different mappingswithout recompilation. The framework can also process andcompile new input transformations on the Ô¨Çy, generating thecorresponding Gremlin scripts dynamically.
As an example, we can deÔ¨Åne a possible Model Mapping
implementation for the persisted model of Figure II-B that
would compute the allOfType(Type) operation with an
access to the vertex representing the metaclass Type and
467
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. 0DSSLQJ4XHU\
7UDQVODWLRQ
4XHU\
([HFXWLRQ
$7/
7UDQVIRUPDWLRQ
*UHPOLQ
6FULSW
SSL




*UHPOLQ
6FULSW

0DSSLQJ
DSSL0DS
DS7B+HOSHU
+HOS
7B+HOSHU
+HOS
Fig. 5. User Point of View
a backward navigation of its incoming instanceof edges.
ThegetAtt andgetRef operations can be translated into
property access and edge navigation, respectively, and the
newInstance operation can be computed by adding a
new vertex in the database with an outgoing edge linked tothe vertex representing its metaclass. Note that Gremlin-A TLembeds preset Model Mapping implementations for accessing
NeoEMF, Neo4j, and relational databases.
Once the Model Mapping interface is bounded to its imple-
mentation, the modeler can choose the Transformation Helper
he needs to compute the transformation. The choice of aspeciÔ¨Åc implementation is a trade-off between execution timeand memory consumption: a Transformation Helper storing
transformation information (such as trace links) in memorywill be efÔ¨Åcient when computing transformations on top ofrelatively small models, but will not scale to larger ones.Conversely, an implementation relying on a dedicated databasecan scale to larger models but would not be optimal when
using small models. Gremlin-A TL deÔ¨Ånes two default imple-
mentations (one in memory and one in database) that can bedirectly plugged to compute a transformation and extended toprovide further performances.
V. T
OOL SUPPORT
Gremlin-A TL is released as a set of open source Eclipse
plugins publicly available on GitHub.5
Input A TL transformations are parsed using the standard
A TL parser, which creates a model representing the abstractsyntax of the transformation. The generated model is sent totheATLtoGremlin A TL transformation, which contains around
120 rules and helpers implementing the translation presentedin Section III. Once the Gremlin model has been generated,it is transformed into a textual Gremlin query using a model-to-text transformation. A Ô¨Ånal step binds the Model Mapping
and the Transformation Helper deÔ¨Ånitions to their concrete
implementation and the resulting script is then sent to aGremlin script engine, which is responsible of computing thequery on top of the database. The updated database is Ô¨Ånallysaved with the transformed content.
Additionally, a preconÔ¨Ågured implementation of Gremlin-
A TL is bundled with the NeoEMF model persistence frame-
5https://github.com/atlanmod/Mogwaiwork that extends the standard Resource API with transforma-
tion operations. A TL transformations are computed using theGremlin-A TL engine transparently, on top of a preset NeoEMFModel Mapping implementation. The resulting model is com-
patible with NeoEMF and its content can be reiÔ¨Åed and
manipulated using the standard modeling API if needed. Thistransparent integration allows the use of Gremlin-A TL forcritical model transformations, while keeping the rest of theapplication code unchanged. We believe that this approach canease the integration of Gremlin-A TL into existing modelingapplications that have to compute complex transformations onthe top of large models.
The current implementation embeds a set of predeÔ¨Åned
Model Mappings and Transformation Helpers. Both can easily
be adapted to specify how you want transformation-related
operations to be computed. This is done by extending a setof abstract classes with limited implementation effort. As anexample, the model mapping used to access Neo4j databasesstoring NeoEMF models deÔ¨Ånes 23 methods (around 250LOC), and the in-database Transformation Helper deÔ¨Ånes 9
methods (around 100 LOC) implementing the transformationoperations and storing intermediate results in the database.
VI. E
V ALUA TION
In this section we evaluate the performance of the Gremlin-
A TL framework by comparing the execution performance ofthe same set of A TL transformations using the standard A TLengine and the Gremlin-A TL framework. Note that we donot consider alternative transformation frameworks in thisevaluation, because they are either based on the same low-level modeling API as A TL (such as QVT [16]), or are notdesigned to optimize the same transformation scenario (suchas Viatra [23]).
Our evaluation aims to address the following research
questions: (i) is Gremlin-A TL faster than standard A TL whenapplied to large models stored in scalable persistence frame-works? and (ii) does our approach scales better in terms ofmemory consumption?
In the following we benchmark our approach with two
transformations, a toy one created on purpose for this analysisand a more complex one taken from an industrial projectinvolving a reverse engineering scenario. Transformations areevaluated on a set of models of increasing size, stored in Neo4jusing the NeoEMF mapping. Transformed models are alsostored in NeoEMF using the same mapping. Experiments areexecuted on a computer running Fedora 20 64 bits. Relevanthardware elements are: an Intel Core I7 processor (2.7GHz),16GB of DDR3 SDRAM (1600MHz) and a SSD hard-disk.Experiments are executed on Eclipse 4.6.0 (Neon) runningJava SE Runtime Environment 1.8.
A. Benchmark Presentation
Experiments are run over Ô¨Åve models (sets 1 to 5) of increas-
ing sizes, automatically constructed by the MoDisco [2] Java
Discoverer, a reverse engineering tool that extracts low-levelmodels from Java code. The Ô¨Årst two models are generated
468
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. from internal projects containing few dozens of classes, and
the larger ones are computed from the MoDisco frameworkitself, and the Java Development Tool (JDT) plugins embeddedin Eclipse. Table III presents the size of the input modelsin terms of number of elements and XMI Ô¨Åle size. Thesemodels are migrated to NeoEMF/Graph before executing thebenchmark to enable scalable access to their contents.
T ABLE III
BENCHMARKED MODELS
Model # Elements XMI Size (MB)
set1 659 0.1
set2 6756 1.7
set3 80665 20.2
set4 1557007 420.6
set5 3609354 983.7
In order to evaluate our approach, we perform two trans-
formations that take as input the Java models conforming to
MoDisco‚Äôs Java metamodel, and translate them into models
conforming to the Knowledge Discovery Model (KDM) [24]that is a pivot metamodel used to represent software artifactindependently of their platform.
The AbstractTypeDeclaration2DataType transformation
matches all the AbstractTypeDeclaration elements (declared
classes, interfaces, enumerations, etc.) of the input model
and create the corresponding KDM DataType.I ti s
composed of a single rule that matches all the subtypesof AbstractTypeDeclaration. The second benchmarked
transformation is a subset of the Java2KDM transformation.
It is extracted from an existing industrial transformation thattakes a low-level Java model and creates the correspondingabstract KDM model. The transformations are run ina 512MB JVM with the arguments -server and
UseConcMarkSweepGC that are recommended by Neo4j.
B. Results
Tables IV and V present the results of executing the transfor-
mations on top of the input model sets. First columns containthe name of the input model of the transformation, secondand third columns present the execution time and the memoryconsumption of A TL engine and Gremlin-A TL, respectively.Execution times are expressed in milliseconds and memory
consumption in megabytes.
The correctness of the output models are checked by com-
paring the results of our approach with the ones generated
by running the A TL transformation on the original input XMIÔ¨Åle using a large Java virtual machine able to handle it. Thecomparison is performed using EMF Compare [25].
C. Discussion
The results presented in Tables IV and V show that
Gremlin-A TL is a good candidate to compute model trans-
formations on top of large models stored in NeoEMF/Graph.Our framework is faster than the standard A TL engine for
the two benchmarked transformations, outperforming it both
6The application threw an OutOfMemory error after two hoursT ABLE IV
ABSTRACT TYPE DECLARA TION 2D ATA TYPE RESULTS
Model Execuction Time (ms) Memory Consumption (MB)
ATL Gremlin-ATL ATL Gremlin-ATL
set1 1633 710 2.0 8.3
set2 3505 1139 3.2 10.0
set3 11480 1649 17.6 11.7
set4 67204 3427 99.3 23.0
set5 OOM611843 OOM 100.0
T ABLE V
JAVA 2KDM R ESULTS
Model Execuction Time (ms) Memory Consumption (MB)
ATL Gremlin-ATL ATL Gremlin-ATL
set1 1735 1341 3.2 11.2
set2 4874 2469 11.0 12.8
set3 33407 4321 45.2 23.2
set4 5156798 38402 504.5 52.0
set5 OOM 129908 OOM 96.0
in terms of execution time and memory consumption for the
larger models.
Results from Tables IV and V show that the complexity of
the transformation has a signiÔ¨Åcant impact on A TL‚Äôs perfor-
mances. This is particularly visible when the transformations
are evaluated on the large models: Java2KDM is 2.9 times
slower than AbstractType2DataType on set3, and up to 76
times on set4. This difference is explained by the large
number of low-level modeling API calls that are generatedby Java2KDM in order to retrieve the matching elements,
computes rules‚Äô conditions, and helpers.
Gremlin-A TL‚Äôs execution time is less impacted by the trans-
formation complexity, because the generated Gremlin queryis entirely computed by the database, bypassing the modelingAPI. The database engine optimizes the query to detect accesspatterns and cache elements efÔ¨Åciently, and allows to beneÔ¨Åtfrom the database indexes to retrieve elements efÔ¨Åciently.Results on set4 show that Gremlin-A TL‚Äôs approach is faster
than A TL by a factor of 19 and 134 for AbstractType2DataType
and Java2KDM, respectively.
The results also show that A TL‚Äôs performance on set4 and
set5 are tightly coupled to the memory consumption. Indeed,
in our experiments we measured that most of the executiontime was spent in garbage collection operations. This highmemory consumption is caused by the in-memory nature of
the engine, that keeps in memory all the matched elements
as well as the trace links between source and target models.When the input model grows, this in-memory informationgrows accordingly, triggering the garbage collector, whichblocks the application until enough memory has been freed. Inaddition, the intensive usage of the low-level model handling
API increases the memory overhead, by reifying intermediate
modeling elements that also stay in the memory.
Conversely, Gremlin-A TL does not require these complex
structures, because trace links are stored within the database
itself, and can be removed from the memory if needed. This
469
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. implementation avoids garbage collection pauses, and allows
to scale to very large models. Our approach operates onthe optimized database structures, and thus does not have toreify modeling elements, improving the memory consumption.Looking at the Java2KDM transformation, this strategy re-
duces the memory consumption by a factor of 10 for set4.
A TL requires less memory than Gremlin-A TL to compute
the transformations on top of the small models ( sets 1 and
2). This difference is caused by the initialization of the
Gremlin engine (and its underlying Groovy interpreter) usedto evaluate the generated scripts. However, this extra memory-
consumption has a Ô¨Åxed size and does not depend on the
evaluated transformation nor on the transformed model.
Note that the results only show execution time and memory
consumption related to the computation of the transformations,
we did not take into account the time and memory requiredto generate an executable Ô¨Åle that can be interpreted by theA TL engine nor the time needed to produce the Gremlin
script to compute, because this extra cost is Ô¨Åxed for a giventransformation and does not depend on the model size. In
addition, Gremlin-A TL allows to pre-compile and to cache
existing Gremlin queries in order to limit script generation.
As a summary, our experiments report that using Gremlin-
A TL to compute a well-known model transformation out-performs the standard A TL engine when applied on top oflarge models stored in current model persistence frameworks.Still, additional experiments could reinforce these conclusions.We plan to extend this preliminary evaluation by reusingtransformations available in the A TL Zoo
7.
VII. A NAPPLICA TION TO DATA MIGRA TION
We have seen how Gremlin-A TL can improve performance
of transformations for large models. In this section, we showhow Gremlin-A TL can also be useful in the context of a datamigration process when the schema of the data is unavailable(the common scenario in many schemaless NoSQL databases).To do so, we implement a simple migration operation on top oftwo data sources, and emphasize that using A TL as a migrationlanguage shortens the amount of required code to write witha limited impact on the application performance.
The input of our example process is the ICIJ Offshore
Leaks Database
8that contains the results of the Panama papers
investigations stored in Neo4j. The output of the process is asimple relational database containing the migrated data.
The input database contains one million elements divided
into four categories represented as node‚Äôs labels: OfÔ¨Åcers,
Entities, Addresses, and Intermediates. Connections between
elements are represented by labeled edges, for example theshareholder of an entity is represented by an edge with thelabel SHAREHOLDER_OF between the corresponding OfÔ¨Åcer
and Entity nodes. Other edges are used to represent the differ-
ent roles of an OfÔ¨Åcer, the connections between Entities and
Intermediates, and their Addresses. Finally, node‚Äôs properties
7https://www.eclipse.org/atl/atlTransformations/
8Available online at https://offshoreleaks.icij.org/pages/databaseare used to represent additional information, such as thedifferent Ô¨Åelds of an Address record.
The operation to perform is a simple data extraction task
that retrieves from the input database all the OfÔ¨Åcer elements
that are shareholders of a company. Results are stored in arelational table containing the OfÔ¨Åcer names and the name of
the corresponding Entity.
We deÔ¨Åne a Neo4j mapping allowing to navigate the
input database as a model:
allOfType(type) operations
are computed by searching for the nodes labeled by type,
andnewElement(type) instructions are mapped to a node
creation with a label representing the type. We also deÔ¨Åne
getRef(from, ref) navigation operations as edge naviga-
tions, and getAtt(from, att) property accesses on the
node representing from. Note that this mapping does not
contain any information speciÔ¨Åc to the ICIJ Offshore LeaksDatabase, and can be reused on top of any Neo4j databaseusing the same data representation.
To let the framework store the results in the desired rela-
tional database we deÔ¨Åned an additional mapping that is ableto access a relational database and serialize model elements intables representing their types. Attributes are mapped to tablecolumns, and references to foreign keys. Note that due to thelack of space we do not detail this mapping, but the completedeÔ¨Ånition is available on the project repository.
Listing 3 shows the A TL transformation rule that expresses
our operation: it matches all the OfÔ¨Åcer entities that corre-
sponds to Entity shareholders in the input database and creates
a corresponding CompanyShareholder record in the output
model containing the names of the OfÔ¨Åcer and the related
Entity. Listing 4 presents the corresponding Java code thatuses the Neo4j and JDBC APIs to manipulate the databases.
When the transformation is computed, source and target
mappings are used to execute modeling operations deÔ¨Åned inthe A TL transformation. For example, the navigation of theSHAREHOLDER_OF reference is delegated to the Neo4j map-
ping, while the creation of the CompanyShareholder instance
is computed by the relational mapping that creates a new tableCompanyShareholder if it does not exist and inserts a new
record in it containing the provided information.
As illustrated by the provided examples, the A TL program
is around two times shorter than the corresponding Javaimplementation. In addition, the A TL transformation onlyrelies on A TL language constructs, and does not contain anyexplicit database speciÔ¨Åc operation. We believe that using A TLas a common language to perform data migration is interestingwhen modelers have to integrate data from heterogeneoussources, and do not have the expertise to write efÔ¨Åcient queriesboth in the input and output database languages.
The execution of this data migration operation creates
296041 records in the output database. The Java implemen-tation is computed within 10342 ms, and the Gremlin-A TLone in 11006 ms. This execution time increase of 6.4% iscaused by the underlying Gremlin engine that adds a smallexecution overhead, and our modeling layer that wraps thenative APIs. Still, we think that the gains in terms of code
470
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. readability and maintainability can balance this slight overhead
increase and constitute an interesting solution to integrate datafrom multiple sources.
1rule shareholder2relationalOfficer {
2 from s : IN!Officer (not(s.name.oclIsUndefined()
3 and s.SHAREHOLDER_OF->isEmpty())
4 tot : OUT!CompanyShareholder(
5 name <- s.name,
6 company <- s.SHAREHOLDER_OF.name) }
Listing 3. Company Shareholder Migration A TL Rule
1Connection c = ds.getConnection();
2c.createStatement().execute("create table ifnot exists
CompanyShareholder (id integer not null
auto_increment, name varchar(200), company varchar
(200), primary key (id));");
3c.commit();
4try (Transaction tx = graphdb.beginTx()) {
5 try (ResourceIterator<Node> officers = graphdb.
findNodes(Label.label("Officer"))) {
6 while (officers.hasNext()) {
7 Node off = officers.next();
8 Iterable<Relationship> rels = off.
getRelationships(Direction.OUTGOING,
RelationshipType.withName("SHAREHOLDER_OF"));
9 for (Relationship r : rels) {
10 Node hd = r.getEndNode();
11 if(off.hasProperty("name") && hd.hasProperty("
name")) {
12 String oName =(String)off.getProperty("name");
13 String cName =(String)hd.getProperty("name");
14 c.createStatement().execute("insert into
CompanyShareholder values (NULL, ‚Äô"+ oName
+"‚Äô, ‚Äô"+ cName + "‚Äô);");
15 }}}
16 officers.close();}}
Listing 4. Company Shareholder Migration Java
VIII. R ELA TED WORK
Several solutions have proposed to parallelize and distribute
model transformations to improve the efÔ¨Åciency and scalability
of existing transformation engines. A TL-MR [26] is a map-reduce based implementation of the A TL engine that computestransformations on top of models stored in HBase. The toolbeneÔ¨Åts from the distributed nature of the database to computeA TL rules in parallel, improving the overall execution time.Parallel-A TL [27] is an implementation of the A TL engineable to beneÔ¨Åt from a multicore environment by splitting theexecution into several workers that access a global sharedmodel asynchronously. The LinTra [28] platform is another
solution that relies on the Linda coordination model to enable
concurrency and distribution of model transformations.
Compared to these approaches, Gremlin-A TL does not
require a parallel infrastructure to optimize the transformation
but instead relies on the scalability mechanisms of the database
engine, one of the strong points and initial motivations for theapparition of NoSQL databases. For example, the distributedNeo4j database provides a Gremlin endpoint that is able toexecute efÔ¨Åciently traversals on graph databases stored in a
cluster, by splitting the computation according to the data
localization. The Gremlin language itself provides native par-allization constructs (e. g., the split-merge step) that could be
used to further improve transformation execution performance.
The Viatra project [23] is an event-driven and reactive model
transformation platform that relies on an incremental patternmatching language to access and transform models. Viatrareceives model update notiÔ¨Åcations and uses its incrementalengine to re-compute queries and transformation in an efÔ¨Åcientway at the cost of a higher memory consumption. Viatra andGremlin-A TL work best in different scenarios. Viatra is veryefÔ¨Åcient when a set of query/transformations are executedmultiple times on a model, while Gremlin-A TL is designedto efÔ¨Åciently perform single transformation computations.
Transforming large models stored in databases is also re-
lated to the schema matching and data migration problems
targeted in the database community [29]. Several approaches
such as COMA [30] or Cupid [31] have been proposed todetect equivalent constructs in data schemas (using schemainformation or instances analysis), and integrated into datamigration frameworks [32] to semi-automate data migrationbetween heterogeneous sources. While Gremlin-A TL could
beneÔ¨Åt from these approaches (e. g., by automatically con-structing Model Mappings), they usually focus on the schema
matching phase and not on the efÔ¨Åcient execution of the data
migration processes based on those mappings.
Our approach can also be combined with proposals on
efÔ¨Åcient graph transformation computation, such as the ap-proach proposed by Krause et al. that parallelizes graphtransformations using the Bulk Synchronous Parallel (BSP)framework Apache Giraph [33]. The Gremlin language pro-
vides a connector to enable Giraph computation on top of
graph databases, that could be used to link both approaches.
IX. C
ONCLUSION
In this article we presented Gremlin-A TL, a framework
that computes rule-based transformations by reexpressing them
as database queries written in the Gremlin graph traversal
language. Our evaluation shows that using Gremlin-A TL totransform models signiÔ¨Åcantly improves the performance bothin terms of execution time and memory consumption.
As future work we plan to extend our approach into a
family of mappings adapted to different NoSQL backends inorder to provide a set of NoSQL modeling frameworks ableto both store and manipulate models ‚Äúnatively‚Äù. We also planto complete our mapping with the A TL constructs that are notyet supported and study translations from other transformationlanguages, which could reuse many of the patterns deÔ¨Ånedfor A TL. Finally, we want to explore how Gremlin-A TL canbe used in other scenarios involving the query, evolutionand integration of unstructured data. Manipulating such datarequires Ô¨Årst to discover its implicit schema/s. This schemacan be naturally expressed as an explicit model and thereforebe a natural Ô¨Åt for our framework that could then be used tofacilitate its manipulation.
A
KNOWLEDGEMENT
This work has been partially funded by the Electronic Com-
ponent Systems for European Leadership Joint Undertakingunder grant agreement No. 737494 (MegaM@Rt2 project) andthe Spanish government (TIN2016-75944-R project).
471
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] S. Azhar, ‚ÄúBuilding information modeling (BIM): Trends, beneÔ¨Åts, risks,
and challenges for the AEC industry,‚Äù Leadership and Management in
Engineering, vol. 11, no. 3, pp. 241‚Äì252, 2011.
[2] H. Bruneliere, J. Cabot, G. Dup√©, and F. Madiot, ‚ÄúMoDisco: A model
driven reverse engineering framework,‚Äù Information and Software Tech-
nology, vol. 56, no. 8, pp. 1012 ‚Äì 1032, 2014.
[3] J. L. C. Izquierdo and J. Cabot, ‚ÄúJSONDiscoverer: Visualizing the
schema lurking behind JSON documents,‚Äù Knowledge-Based Systems,
vol. 103, pp. 52‚Äì55, 2016.
[4] F. Jouault, F. Allilaire, J. B√©zivin, and I. Kurtev, ‚ÄúA TL: A model
transformation tool,‚Äù Science of Computer Programming, vol. 72, no. 1,
pp. 31 ‚Äì 39, 2008.
[5] N. Huijboom and T. V an den Broek, ‚ÄúOpen data: an international
comparison of strategies,‚Äù European journal of ePractice, vol. 12, no. 1,
pp. 4‚Äì16, 2011.
[6] J. Hutchinson, J. Whittle, and M. RounceÔ¨Åeld, ‚ÄúModel-driven engineer-
ing practices in industry: Social, organizational and managerial factors
that lead to success or failure,‚Äù Science of Computer Programming,
vol. 89, pp. 144‚Äì161, 2014.
[7] J. Whittle, J. Hutchinson, and M. RounceÔ¨Åeld, ‚ÄúThe state of practice
in model-driven engineering,‚Äù IEEE software, vol. 31, no. 3, pp. 79‚Äì85,
2014.
[8] D. S. Kolovos, L. M. Rose, N. Matragkas, R. F. Paige, E. Guerra, J. S.
Cuadrado, J. De Lara, I. R√°th, D. V arr√≥, M. Tisi et al., ‚ÄúA research
roadmap towards achieving scalability in model driven engineering,‚Äù inProceedings of BigMDE‚Äô13. ACM, 2013, pp. 1‚Äì10.
[9] OMG, ‚ÄúUML SpeciÔ¨Åcation,‚Äù 2017. [Online]. Available: www.omg.org/
spec/UML
[10] Eclipse Foundation, ‚ÄúThe CDO Model Repository (CDO),‚Äù 2017.
[Online]. Available: http://www.eclipse.org/cdo/
[11] G. Daniel, G. Suny√©, A. Benelallam, M. Tisi, Y . V ernageau, A. G√≥mez,
and J. Cabot, ‚ÄúNeoemf: a multi-database model persistence frameworkfor very large models,‚Äù in Proceedings of the MoDELS 2016 Demo and
Poster Sessions. CEUR, 2016, pp. 1‚Äì7.
[12] J. E. Pag√°n, J. S. Cuadrado, and J. G. Molina, ‚ÄúA repository for scalable
model management,‚Äù Software & Systems Modeling, vol. 14, no. 1, pp.
219‚Äì239, 2015.
[13] R. Wei and D. S. Kolovos, ‚ÄúAn efÔ¨Åcient computation strategy for
allinstances(),‚Äù Proceedings of BigMDE‚Äô15, pp. 32‚Äì41, 2015.
[14] Tinkerpop, ‚ÄúThe Gremlin Language,‚Äù 2017. [Online]. Available:
www.gremlin.tinkerpop.com
[15] OMG, ‚ÄúOCL SpeciÔ¨Åcation,‚Äù 2017. [Online]. Available: www.omg.org/
spec/OCL
[16] ‚Äî‚Äî, ‚ÄúQVT SpeciÔ¨Åcation,‚Äù 2017. [Online]. Available: http://www.omg.
org/spec/QVT
[17] J. E. Pag√°n, J. S. Cuadrado, and J. G. Molina, ‚ÄúMorsa: A scalable
approach for persisting and accessing large models,‚Äù in Proceedings of
the 14th MoDELS Conference. Springer, 2011, pp. 77‚Äì92.[18] A. Benelallam, A. G√≥mez, G. Suny√©, M. Tisi, and D. Launay,
‚ÄúNeo4EMF, a Scalable Persistence Layer for EMF Models,‚Äù in Pro-
ceedings of the 10th ECMF A. Springer, 2014, pp. 230‚Äì241.
[19] Tinkerpop, ‚ÄúBlueprints API,‚Äù 2017. [Online]. Available: www.blueprints.
tinkerpop.com
[20] A. G√≥mez, G. Suny√©, M. Tisi, and J. Cabot, ‚ÄúMap-based transparent
persistence for very large models,‚Äù in Proceedings of the 18th F ASE
Conference. Springer, 2015, pp. 19‚Äì34.
[21] G. Daniel, G. Suny√©, and J. Cabot, ‚ÄúMogwa√Ø: a framework to handle
complex queries on large models,‚Äù in Proceedings of the 10th RCIS
Conference. IEEE, 2016, pp. 225‚Äì237.
[22] D. S. Ruiz, S. F. Morales, and J. G. Molina, ‚ÄúInferring versioned schemas
from NoSQL databases and its applications,‚Äù in Proceedings of the 34th
ER Conference. Springer, 2015, pp. 467‚Äì480.
[23] G. Csert√°n, G. Huszerl, I. Majzik, Z. Pap, A. Pataricza, and D. V arr√≥,
‚ÄúViatra-visual automated transformations for formal veriÔ¨Åcation andvalidation of UML models,‚Äù in Proceedings of the 17th ASE Conference .
IEEE, 2002, pp. 267‚Äì270.
[24] OMG, ‚ÄúKnowledge Discovery Metamodel (KDM),‚Äù 2017. [Online].
Available: http://www.omg.org/technology/kdm/
[25]
C. Brun and A. Pierantonio, ‚ÄúModel differences in the eclipse modeling
framework,‚Äù UPGRADE, The European Journal for the Informatics
Professional, vol. 9, no. 2, pp. 29‚Äì34, 2008.
[26] A. Benelallam, A. G√≥mez, M. Tisi, and J. Cabot, ‚ÄúDistributed model-
to-model transformation with A TL on MapReduce,‚Äù in Proceedings of
the 8th SLE Conference. ACM, 2015, pp. 37‚Äì48.
[27] M. Tisi, S. Martinez, and H. Choura, ‚ÄúParallel execution of A TL
transformation rules,‚Äù in Proceedings of the 16th MoDELS Conference.
Springer, 2013, pp. 656‚Äì672.
[28] L. Burgue√±o, M. Wimmer, and A. V allecillo, ‚ÄúA linda-based platform for
the parallel execution of out-place model transformations,‚Äù Information
and Software Technology, vol. 79, pp. 17‚Äì35, 2016.
[29] E. Rahm and P . A. Bernstein, ‚ÄúA survey of approaches to automatic
schema matching,‚Äù The VLDB Journal, vol. 10, no. 4, pp. 334‚Äì350,
2001.
[30] H.-H. Do and E. Rahm, ‚ÄúComa: a system for Ô¨Çexible combination of
schema matching approaches,‚Äù in Proceedings of the 28th international
conference on V ery Large Data Bases. VLDB Endowment, 2002, pp.
610‚Äì621.
[31] J. Madhavan, P . A. Bernstein, and E. Rahm, ‚ÄúGeneric schema matching
with cupid,‚Äù in The VLDB Journal, vol. 1, 2001, pp. 49‚Äì58.
[32] C. Drumm, M. Schmitt, H.-H. Do, and E. Rahm, ‚ÄúQuickmig: automatic
schema matching for data migration projects,‚Äù in Proceedings of the
16th CIKM conference. ACM, 2007, pp. 107‚Äì116.
[33] C. Krause, M. Tichy, and H. Giese, ‚ÄúImplementing graph transforma-
tions in the bulk synchronous parallel model.‚Äù in Proceedings of the
17th F ASE Conference, vol. 14, 2014, pp. 325‚Äì339.
472
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:58:07 UTC from IEEE Xplore.  Restrictions apply. 