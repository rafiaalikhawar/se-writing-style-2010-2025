IncA: A DSL for the DeÔ¨Ånition of
Incremental Program Analyses
Tam√°s Szab√≥
itemis, Germany /
Delft University of Technology,
Netherlands
tamas.szabo@itemis.deSebastian Erdweg
Delft University of Technology,
Netherlands
s.t.erdweg@tudelft.nlMarkus Voelter
independent /
itemis, Germany
voelter@acm.org
ABSTRACT
Program analyses support software developers, for example,
through error detection, code-quality assurance, and by en-
abling compiler optimizations and refactorings. To provide
real-time feedback to developers within IDEs, an analysis
must run eciently even if the analyzed code base is large.
To achieve this goal, we present a domain-specic language
called IncA for the denition of ecient incremental program
analyses that update their result as the program changes.
IncA compiles analyses into graph patterns and relies on exist-
ing incremental matching algorithms. To scale IncA analyses
to large programs, we describe optimizations that reduce
caching and prune change propagation. Using IncA, we have
developed incremental control ow and points-to analysis
for C, well-formedness checks for DSLs, and 10 FindBugs
checks for Java. Our evaluation demonstrates signicant
speedups for all analyses compared to their non-incremental
counterparts.
CCS Concepts
Software and its engineering !Automated static
analysis; Data ow languages; Integrated and visual de-
velopment environments;
Keywords
Static Analysis; Incremental Computation; Domain-specic
Language; Language Workbench
1. INTRODUCTION
Static program analysis is the basis of compiler optimiza-
tions and IDE features such as error detection or behavior-
preserving refactorings. Program analyses trade o precision
for runtime performance and memory use, and there is a
large body of research on techniques that enable increasingly
precise and ecient analyses. For example, by giving up
ow-sensitivity and context-sensitivity, points-to analysis can
analyze millions of lines of Java code in under a minute [9].
Our work improves the performance of program analyses
through incrementality: When part of the code changes (forexample, through user edits), we only reanalyze the changed
part, plus all the code whose analysis result depends on the
changed results. This way, incremental program analysis can
provide signicant improvements compared to reanalyzing
the whole code base from scratch. Such incremental analyses
are useful in IDEs that perform real-time analysis upon user
edits and in continuous integration servers that continuously
analyze an evolving code base.
We present IncA, a domain-specic language (DSL) for
the denition of ecient incremental program analyses, as
well as an optimizing compiler and a runtime system for
IncA. Conceptually, IncA represents computations as graph
patterns [30] on top of the abstract syntax tree (AST) of
the analyzed program. Graph patterns express relationships
between AST nodes, for example, to describe the control
ow between individual statements of the analyzed program.
The IncA compiler translates a user-dened program anal-
ysis into a set of interconnected graph patterns. The IncA
runtime system maintains the analysis results incrementally
by performing incremental graph pattern matching.
Semantically, a graph pattern describes a set of tuples that
relate program entities. However, using graph patterns is
dicult for many developers, because, instead of mapping
input to output, they construct tuples for related entities by
splitting, joining and ltering sets of tuples. IncA introduces
pattern functions to abstract from graph patterns: Instead of
operating on sets, a pattern function takes a single input and
either rejects it or computes a corresponding output. This
way, a pattern function denes what we call the primary
linearization of the underlying graph pattern, for example,
in the style of a forward or backward analysis. Our compiler
translates pattern functions into regular graph patterns.
We have implemented IncA on top of JetBrains MPS,1an
IDE that relies on projectional editing, where code changes
occur in the form of user-issued AST change requests. This
aligns well with incrementalization because each AST change
triggers an incremental update of the analysis results. The
design and implementation of IncA is independent of the
analyzed language and we developed a generic architecture
for the integration of IncA into other IDEs.
To evaluate IncA, we implemented incremental analyses
for C and Java programs and measured their runtime perfor-
mance. For C, we developed incremental control ow analysis,
ow-sensitive points-to analysis, and domain-specic well-
formedness checks. For Java, we reimplemented 10 FindBugs
analyses [20]. Our evaluation shows that IncA-based incre-
mental program analyses yield signicant speedups without
1https://www.jetbrains.com/mps
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ASE‚Äô16 , September 3‚Äì7, 2016, Singapore, Singapore
c2016 ACM. 978-1-4503-3845-5/16/09...$15.00
http://dx.doi.org/10.1145/2970276.2970298
320
(1)(2)(3)(3a)(4)3a4213pthread_mutex_lock(sensorLock);int7temp7=7readSensor(...);if7(outOfRange(temp))7{77log("Beyond7threshold7%d!",7temp);}pthread_mutex_unlock(sensorLock);Figure 1: A simple C program and its control ow
introducing unacceptable memory or initialization overheads.
In summary, we make the following contributions:
We introduce IncA, a language for the denition of
incremental program analyses that is independent of
the analyzed language. Our compiler translates IncA
code into graph patterns (Section 3).
We implement compiler optimizations for IncA that
reduce the memory required for incrementalization and
the time required for change propagation (Section 4).
We describe the runtime system of IncA as a generic
architecture that allows the integration of IncA analyses
into dierent IDEs. Technically, the runtime system
employs incremental graph pattern matching on the
AST of the analyzed program (Section 5).
We develop three incremental analyses for C, including
an incremental ow-sensitive points-to analysis, and
reimplement 10 FindBugs analyses for Java (Section 6).
We evaluate the memory and runtime performance
of IncA through extensive case studies on real-world
C and Java software projects (Section 7). We show
that program analyses developed with IncA provide
real-time feedback and scale to large code bases.
We reuse the IncQuery [35] incremental evaluator in our
system; thus the core incremental evaluator is not our con-
tribution. There exist several incremental algorithms for
a particular analysis [7, 25, 18, 26] and frameworks for a
particular class of analyses [3, 14, 39] in the literature. In
contrast to these solutions, our analysis framework is not
bound to a specic class of analyses (Section 6) and employs
incremental graph pattern matching for program analysis as
a novel approach.
2. INCREMENTAL PROGRAM ANALYSIS
BY EXAMPLE
Using control ow analysis for C as an example, this section
explains the problem of incremental program analysis and
illustrates our solution.
Control ow analysis IDEs and compilers use control ow
analysis to reason about the execution order of statements in
a program and as a building block for further analyses such
as points-to analysis.
The input of control ow analysis is the AST of the pro-
gram and its output is a control ow graph (CFG) [24]. As
an example, consider the C program and its control ow in
Figure 1. Each node in the CFG represents a statement in
the program. A source statement is connected to a target
statement in the CFG if there exists an execution trace in
which the execution of the source statement immediately
precedes the execution of the target statement. Note how
control can ow from statement 3both to 3aand 4in Fig-
ure 1, depending on the condition of the ifstatement, which
is why the CFG contains edges from 3to3aand from 3to4.
The result of our control ow analysis is a set of CFG
edges. In this section, we restrict ourselves to a subset of
C with ifstatements and simple statements that entail a
Statement1, 2, 3, 3a, 4IfStatement3LastStatementparentchild33aSimpleStmt1, 2, 3a, 4CSimplesrc2231trgCFlow343a4src3trg33a221PrecedingStmt3beforeafter12324IntCIf4srctrg33a33a4Figure 2: Computation graph of the CFG analysis eval-
uation
sequential control ow such as assignments. We dene the
relation CFlow for the edges of the CFG and we compute it
as the union of two helper relations. (1) CSimple consists
of those control ow edges (src,trg) where srcis a simple
statement that syntactically precedes trgin the source code.
(2)CIfconsists of control ow edges (src,trg) that lead
into or out of an ifstatement or its branches, which is the
case if (a) srcsyntactically precedes trgand srcis an if
statement without an else part, (b) srcis an ifstatement
and trgis the rst statement of one of its branches, or (c)
srcis the last statement of one of the branches of an ifthat
syntactically precedes trg.
In our example, CSimple has two elements (1,2) and
(2,3) , while CIfhas three elements (3,3a) ,(3a,4) , and
(3,4) . The union of the two relations constitutes CFlow .
Evaluation with graph patterns To compute the ele-
ments of the relations CSimple ,CIf, and CFlow , we need to
traverse the AST and discover the relevant structural rela-
tions between the AST nodes and their attributes. A natural
representation of such computations is a graph pattern [30].
Much like our informal description of the relations above,
a graph pattern describes sets of related entities through
structural constraints on AST nodes and on instances of
other graph patterns.
Given a set of interconnected graph patterns, we can com-
pute their results by using a computation graph as illus-
trated in Figure 2 for our example. A computation graph
consists of two kinds of nodes, each of which yields a set
of related entities. Input nodes (grey) represent the AST
structure directly, do not perform any computation, and do
not depend on any other node. In Figure 2, Statement
and PrecedingStatement are the only input nodes; the
former enumerates the nodes of type Statement from the
AST and the latter enumerates the pairs of statements
where the rst statement syntactically precedes the other.
Computation nodes (white) use the results of input nodes
and other computation nodes to relate program entities.
For example, node CSimple uses information from node
Statement ,SimpleStatement , and PrecedingStatement to
identify statements related through simple control ow. Node
CFlow combines the results from two computation nodes to
produce the complete CFG.
Incremental control ow analysis We encode program
analyses as graph patterns and computation graphs because
this provides a good basis for incrementalizing the computa-
tion. Suppose the user modies the analyzed program and
adds an else branch 3bto the ifstatement as illustrated in
321AST of the program code(1)(2)(3)(3a)(3b)(4)incremental change updatestraverse A3a4213bXB
C3pthread_mutex_lock(sensorLock);int7temp7=7readSensor(...);if7(outOfRange(temp))7{77log("Beyond7threshold7%d!",7temp);}7else7{77calibrate_env(temp,7...);}pthread_mutex_unlock(sensorLock);
+3src4343b233btrg43a3a321+-+-4343b43aifstrg3b33a3+childparent33a33b+1, 2, 3a, 3b, 4+1, 2, 3, 3a, 3b, 4+StatementIfStatement3LastStatementSimpleStmtCSimplesrc2231trgCFlowPrecedingStmt3beforeafter12324CIfFigure 3: Example analysis evaluation; (A) example C
program code after modication, (B) CFG of the pro-
gram code, (C) computation graph for incremental eval-
uation
Figure 3. This invalidates the old CFG. Using graph patterns
and computation graphs, instead of recomputing a new CFG
from scratch, we can incrementally update the existing CFG.
To this end, computation graphs use memoization and
perform incremental graph pattern matching: When code
gets changed, we send change events to the input nodes of the
computation graph. The nodes then transitively propagate
changes to all dependent computation nodes and trigger the
reanalysis of changed program entities. This way, we avoid
any reanalysis of unchanged parts of the program. In our
example, the introduction of the else branch triggers the
following changes in the computation graph (cf. Figure 3):
Addition of 3btoStatement and SimpleStatement .
Removal of (3,4) from CIfbecause ifstatement 3now
has an else branch. That is, the conditional treatment
is exhaustive and control is guaranteed to pass through
one of the branches before reaching 4.
Addition of (3,3b) toCIfbecause 3bis the rst state-
ment of the else branch.
Addition of (3,3b) toLastStatement because 3bis
the last statement of else branch of ifstatement 3.
Addition of (3b,4) toCIfbecause (3,3b) was added
toLastStatement and 3precedes 4.
Propagation of all changes from CIftoCFlow .
In our implementation based on projectional editing, we
receive change events for user-issued AST changes directly
from the IDE. Fine-grained AST change notications align
perfectly with incrementalization and there is no need for a
potentially costly parsing step to compute AST dierences.
After an AST change, a projectional editor derives a new
projection from the AST and displays it to the programmer.
A DSL for program analysis A DSL based on graph
patterns is a good semantic basis for incrementally analyzing
programs. However, programming with graph patterns is
dicult because graph patterns operate on sets of related
program entities, using operations such as lter, map, and1 def cFlow(trg : Statement) : Statement = {
2 return cSimple(trg)
3 }alt {
4 return cIf(trg)
5 }
6 def cSimple(trg : Statement): SimpleStatement={
7 src := precedingStatement(trg)
8 assert src instanceOf SimpleStatement
9 return src
10 }
11 def cIf(trg : Statement): Statement = {
12 src := precedingStatement(trg)
13 assert src instanceOf IfStatement
14 return lastStatement(src)
15 }alt {
16 src := precedingStatement(trg)
17 assert src instanceOf IfStatement
18 assert undef src.else
19 return src
20 }alt {
21 assert undef precedingStatement(trg)
22 parent := trg.parent
23 assert parent instanceOf IfStatement
24 return parent
25 }
Figure 4: Control ow analysis for a subset of C in IncA
cross product. This is far removed from the usual way of
dening program analyses as forward or backward analy-
ses [24]. Additionally, considerable anecdotal evidence at
companies itemis and IncQueryLabs , where developers use
the IncQuery graph pattern language [35] for commercial
projects, shows that developers would rather rely on more
familiar core abstractions; functions, distinguishing input
from output, direction in the function body and assignments.
This experience was the main driver when we designed a
DSL called IncA which abstracts from graph patterns.
Instead of operating on sets of program entities, IncA
supports the denition of program analyses using what we
call pattern functions . A pattern function is a linearized
graph pattern: It takes a single tuple of inputs and either
rejects the input or produces a single tuple of outputs through
a sequence of statements in the body of the pattern function.
Semantically, a pattern function corresponds to a graph
pattern that relates the program entities that occur as either
input or output. In particular, the separation of entities into
input and output and the order of statements in the body of
a pattern function are semantically irrelevant. Nevertheless,
linearization simplies the denition of program analyses.
Since many dierent linearizations of the same graph pattern
are possible, we say a pattern function denes the primary
linearization of the underlying graph pattern. We illustrate
IncA through the denition of the control ow analysis for
our subset of C, where the linearization enables us to write
the denition in the style of a backward analysis.
Figure 4 shows the IncA code that denes the control ow
analysis. We show three pattern functions that follow the
informal description of the corresponding relations above,
while the other helper functions are omitted. Function cFlow
takes a target statement trgand nds and returns the control
ow predecessors of trgusing functions cSimple and cIf.
We write altto provide alternative results for a pattern
function. Note that the functions are dened over the mbeddr
C [37] dialect in this example. The tight connection with
the analyzed language makes it possible to use its types and
language concepts in the IncA code and to provide the usual
322IDE features, such as highlighting and proposals, during the
development of the analysis.
Function cSimple queries pattern precedingStatement
fortrg. The function can return multiple results, but IncA
abstracts over this. Next, cSimple asserts that the prede-
cessor of trgis indeed a simple statement. If it is, cSimple
yields this statement as a control ow predecessor. Otherwise,
cSimple fails for trgand does not yield any output.
Function cIfis composed of three alternatives that com-
pute the control ow when an ifstatement is involved. IncA
provides direct access to the AST structure. For example, in
the second alternative, src.else represents the else branch
of the if statement src. As shown by cIf, IncA also sup-
ports the language construct undef to ascertain that a given
pattern-function call does not yield any result or that an
AST node is undened.
Our compiler translates pattern functions into regular
graph patterns, but also analyzes the pattern functions to
perform optimizations. In particular, our compiler deter-
mines which parts of an AST are irrelevant for an analysis
and uses this information to prune the propagation of change
notications and to reduce caching (Section 4).
3. INCREMENTAL PROGRAM ANALYSIS
WITH IncA
In this section we discuss IncA in greater detail. Specically,
we describe the syntax of IncA and explain how we translate
its syntactic constructs into graph patterns.
3.1 Syntax of IncA
Figure 5 shows the syntax of IncA. We write afor a sequence
ofaelements, which includes the empty list.
Amodule groups related pattern functions. Modules can
import other modules to gain access to their public pattern
functions. Functions are public by default, but can be marked
private to restrict their visibility to the containing module.
Apattern function represents the primary linearization
of a graph pattern. A function takes a tuple of typed in-
put parameters and either rejects the input or produces an
output tuple. A function may dene multiple alternative
linearizations for the same input.
Each alternative consists of a sequence of statements , end-
ing with a return statement that denes the output tuple. An
assignment statement binds variables to the components of
a tuple. An assertion statement aborts the computation and
rejects the current input if the condition fails. As conditions
we support equality, inequality, AST node-type membership,
AST node-type exclusion, and undenedness testing.
Anexpression can refer to a variable, represent a value
literal, refer to a property of an AST node, call another
pattern function, or compute the transitive closure of another
pattern function. For the transitive closure, the called pattern
function must take a single input and provide a single output.
The evaluation of such expressions yields all intermediate
outputs, but IncA's syntax abstracts over this and permits
the use as if there was only a single denite output.
3.2 Compilation to Graph Patterns
The theory of graph patterns is well established [30] and we
dene the semantics of IncA through translation to graph
patterns. A graph pattern consists of pattern variables and
constraints over these variables. The constraints can refer to
other graph patterns. We use the following constraints:(module) m::=module nimport nffg
(function) f::=visdefn(n:T) :T=a
(visibility) vis::=private jpublic
(alternative) a::=s
(statement) s::=n:=ejassert cjreturn e
(condition) c::=e==eje!=ejeinstanceOf Tj
enot instanceOf Tjundef e
(expression) e::=njlje:n jn(e)jn+(e)
(literal) l::= number jstring jenum jboolean
(type) T::= AST node type (from analyzed language)
(name) n::= name
Figure 5: Syntax of IncA
Entity(v,T) holds if variable vhas type T.
Relation(l,v1,v2) holds if there is an edge labeled l
between variables v1and v2.
Eq(v1,v2) andNeq(v1,v2) hold if variables v1andv2
point to the same/dierent element.
PC(p, v)andNPC(p, v)hold if the pattern paccepts/re-
jects the tuple v.
TC(p,v1,v2) holds if the transitive closure of the binary
pattern pcontains the tuple (v1,v2) .
Alt( p,v)holds if any of the patterns in paccepts the
tuple v.
We map IncA constructs to graph-pattern constraints as fol-
lows. An IncA variable becomes a pattern variable and a lit-
eral becomes a pattern variable with an Eqconstraint. A prop-
erty access e.ntranslates to a constraint Relation(n,e,v) ,
where vis a fresh pattern variable that represents the result
of the lookup. A function call f(e)becomes a constraint
PC(f, ev), where vare fresh and represent the result of the
call (the notation evmeans concatenation). For transitive
closure, we use the TCconstraint.
Next, we translate IncA conditions to constraints. Equality
and inequality straightforwardly translate to Eqand Neq
constraints, and node-type membership test with instanceof
becomes an Entity constraint. Negative conditions require
helper patterns and calls to them with NPC. The helper
function contains an Entity for a not instanceOf while
it contains the corresponding subpattern for the expression
in case of an undef . The function call with an undef is an
exception, because it is directly translated to an NPC.
For statements, we proceed as follows. An assertion simply
promotes the constraints of its condition. An assignment
matches up the variables on the left-hand side with the
variables that result from the expression on the right-hand
side. We generate Eqconstraints for the pairs of variables
from the two sides. To represent the output tuple of a
function, we use designated variables. We handle a return
statement as an assignment to these variables.
Finally, we collect the functions from a module and its tran-
sitively imported modules and generate graph patterns for the
functions and their alternatives. Function input parameters
become pattern variables viand we create designated pattern
variables vofor the output tuple. The type annotations on in-
put and output of a function become Entity constraints over
vivo. We combine the patterns pof a function's alternatives
using an alternative constraint Alt( p,vivo).
This translation process also shows the driving forces for
the abstraction from graph patterns. Graph patterns are
verbose, because they require explicit variables for allin-
termediate expressions, explicit Entity for type constraints
and helper patterns for negative conditions. Additionally,
they are nondirectional which is in contrast to the usual
directional nature of program analyses.
323To achieve incrementality, we reuse the incremental graph
pattern-matching implementation that is part of IncQuery [35],
but there are also many other alternatives for matching [30].
The expressive power of our program analysis language (and
of the core IncQuery engine) is classied as FO(LFP) [28,
21] which stands for First Order logic extended with the
Least Fixed Point operator. We believe that this formalism
is expressive enough for a wide variety of program analysis
as we demonstrate in Section 6.
4. COMPILER OPTIMIZATIONS FOR IncA
The performance of IncA depends on both the memory re-
quired for caching as well as the eciency of change propaga-
tion in the computation graph. In this section, we describe
compiler optimizations for IncA that improve both of them.
Our approach for performance improvement relies on the
observation that the evaluation of a program analysis usually
only depends on a relatively small part of an AST. For
incremental analysis, this means that many AST changes
do not aect the analysis result and can be safely ignored.
We can use this observation to improve caching and change
propagation. There is no need to write a changed element to
the input nodes of the computation graph if it is known to
be irrelevant for the analysis. This saves both memory and
time, because by discarding irrelevant input nodes we avoid
subsequent change propagation in the computation graph,
which in turn also avoids caching of unneeded results.
To make use of this observation in practice, we must be able
to distinguish relevant from irrelevant changes. To this end,
we have developed an analysis for IncA programs, that is, an
analysis of the program analysis code. Our analysis inspects
the IncA code to compute a conservative approximation of all
changes that can aect the result of the IncA program. We
analyze each module of the IncA program with its transitive
imports separately because the IncA compiler creates one
computation graph for each module.
As a rst approximation of the relevant changes, we can col-
lect the declared types of all mentioned AST nodes from the
functions. For example, consider again the control ow anal-
ysis in Figure 4. The IncA code refers to AST nodes of type
Statement ,SimpleStatement ,IfStatement , and ElsePart
(via src.else ). Since type Statement is a supertype of the
other two statement types, a sound approximation is given
by the set of changes that modify nodes of type Statement
orElsePart . Accordingly, when incrementally executing the
control ow analysis in the IncA runtime system, we can
ignore changes to expressions, function declarations, and
others. Note that the type information is not an additional
assumption about the analysis, it is part of the IncA code.
The subtyping relationship between the AST node types is
determined by the analyzed program's language.
Using the declared types of AST nodes is a good starting
point for optimization; however it is rather imprecise. To
improve the eectiveness of the optimization, we can take
type assertions ( instanceOf ) into account to determine the
actually relevant AST node types. Consider an excerpt
of a points-to analysis for C shown in Figure 6. Function
pointsTo computes pairs of C variables for assignments of the
form u = &v . It uses function varInExpr to reject expressions
that are not variables (such as additions or multiplications)
and otherwise to extract the variable of an expression.
If we only consider the declared types and ignore type
assertions, we have to assume that a change to any node
 left ‚àà GlobalVarRef or LocalVarReffrom ‚àà GlobalVar or LocalVarright ‚àà AddressOfExprright.expr ‚àà GlobalVarRef or LocalVarRefto ‚àà GlobalVar or LocalVarFigure 6: Identifying relevant AST node types in IncA
of type Assignment ,Var, orExpression aects the analysis
result. However, we can apply the following reasoning to
narrow the set of relevant changes in Figure 6:
Initially, both variables left and right have type
Expression according to the properties of Assignment .
The type assertion at line 5 constrains the type of
right to the more specic type AddressOfExpr .
The function call in line 6 calls varInExpr with a refer-
ence to the variable left. Function varInExpr has two
alternatives, the rst one restricting etoGlobalVarRef ,
while the second one restricts it to LocalVarRef . Ex-
pressions that satisfy neither restriction are rejected
byvarInExpr . So the call in line 6 only succeeds,
and thus contribute to the analysis result, if left is a
GlobalVarRef or a LocalVarRef . Moreover, the type
of variable from must be GlobalVar orLocalVar .
The same reasoning applies to the function call at line 7
forright.expr and variable to.
This reasoning shows that we only need to observe changes
to statement nodes of type Assignment , to expression nodes
of type AdressOfExpr ,GlobalVarRef , and LocalVarRef and
to variable nodes of type GlobalVar and LocalVar . Consid-
ering that, for example, the mbeddr dialect of C with its
language extensions has more than 200 dierent kinds of
expressions, our analysis can yield signicant improvements
for the memory and runtime performance of an IncA analysis.
We empirically conrm this in Section 7.
We now provide a detailed description of our interproce-
dural data-ow analysis for IncA programs:
Traverse call chains We perform a depth-rst traversal
of the pattern-function call graph, starting at publicly visible
functions. The analysis is inter-procedural, that is, we pass
type information from the caller to the callee. Dierent call
chains may result in dierent type constraints for parameters
and variables; thus we analyze all call chains separately.
Type intersection During traversal, for each alternative
of a pattern function, we collect the type constraints from
assertions and function calls for each parameter and local
variable. An alternative can only succeed if each parameter
and variable satises all type constraints. This corresponds
to constructing the intersection of all type constraints for
each parameter and variable.
324UserIDEtransformsAST changesoptimizationbased on static analysistraverseAnalyzed program (AST)IncA analysis codeIncremental evaluatorNavigatorAnalysis resultprogram changesAST changes
reportrelevant AST chg.access ASTcomputesFigure 7: Architecture for integrating IncA into IDEs
Type union A pattern function succeeds if at least one of
its alternatives succeeds. Thus, it is sucient if the parame-
ters satisfy the type constraints of at least one alternative.
We approximate this by constructing the union of the type
constraints for parameters and variables from all alternatives.
Optimization The analysis result is the union of the type
constraints for the dierent call chains. Only changes that
aect nodes of these types can aect the analysis result. We
prune the propagation of irrelevant changes, thus avoiding
the computation and caching of irrelevant pattern matches.
As opposed to using a library for program analysis, an
advantage of specifying the program analysis as DSL code
is that the analysis itself becomes analyzable which enables
our optimization. Additionally, our optimization is generic
as it is not bound to the IncA DSL, for example, it could be
applied on the graph patterns as well.
5. TECHNICAL REALIZATION AND IDE
INTEGRATION
We elaborate on the architecture of IncA's runtime system,
identifying components that enable integration of incremental
program analyses into IDEs and explain their interactions.
5.1 Overview
Figure 7 shows the architecture for integrating IncA into an
IDE. The analysis code is an IncA program that runs on the
analyzed program. As detailed in Section 5.3, our architec-
ture requires that the IDE translates user edits into AST
change notications, which trigger the incremental analysis.
The navigator is the entry point of the incremental analysis.
As an adapter between the IDE and the incremental evalua-
tor, it gets notied about AST changes by the IDE. It also
allows the evaluator to traverse the input AST during initial-
ization of the computation graph. Later, when the navigator
receives an AST change notication, it noties the incremen-
tal evaluator about relevant AST changes, as determined by
our compiler optimization (Section 4). Since the navigator
knows the IDE-internal AST representation, it constitutes a
language-independent but IDE-specic component.
The incremental evaluator is responsible for the incremen-
tal maintenance of the analysis results. The component is
independent of the IDE and of the analyzed language. The
evaluator uses the navigator to navigate in the AST and
to receive notications about AST changes; this way, the
evaluator does not depend on the internals of the IDE.
The incrementally maintained results of a program analysis
can be used to inform the user about new errors or as part
of a refactoring in the IDE. This connection closes the loop
between the user and our system and shows how incremental
analysis supports interactive development.5.2 Implementation for MPS
We instantiated the architecture for the Meta Programming
System (MPS) using IncQuery [35] as the incremental evalu-
ator. Both tools are available as open-source software, as is
our implementation.2
MPS is an IDE that uses projectional editing [38] instead
of a parser-based approach. When editing the program in a
projectional editor, every user edit (for example, inserting
an operator) directly corresponds to an AST change. After
an AST change, a projectional editor renders new projection
from the changed AST based on projection rules of the AST
nodes and displays it to the programmer. Projectional editing
is well-suited for incremental program analysis because the
user's edits directly correspond to incremental AST changes
and no incremental parsing is necessary.
Our system reuses the incremental graph pattern match-
ing component of IncQuery. This component realizes the
computation graph presented in Section 2. The component
expects the graph patterns to be specied using the Java API
PSystem.3We implemented the IncA compiler to translate
graph patterns into a PSystem specication. After startup,
IncQuery uses the navigator to initialize its computation
graph and to retrieve AST changes.
5.3 Applicability in other IDEs
The applicability of our solution is ultimately determined by
the granularity of an IDE's incremental change notications
as the analyzed program changes. We see three kinds of
IDEs where our solution can be applied eciently. (1) Pro-
jectional IDEs (like MPS) where code manipulations directly
correspond to incremental AST change events. (2) Graphical
IDEs, which, like projectional IDEs, also directly manipulate
structures and can thus easily derive AST changes after a
change. (3) Finally, textual IDEs that are backed by an
incremental parser (cf. [27] for example incremental parsers
and the Eco language workbench [8] which relies on an in-
cremental parser). In this case, the degree of incrementality
that our approach can achieve depends on the granularity of
the incremental AST dierences the parser can provide.
6. CASE STUDIES
To validate our approach, we have used IncA to implement
three program analyses for mbeddr C and one program anal-
ysis for Java. mbeddr C is an extensible C dialect and IDE
for embedded software built on top of MPS. This section
describes the program analyses and gives details about their
implementation, while Section 7 contains the performance
evaluation. We show only the most interesting parts of the
implementations; the full implementation is available online.
6.1 Control Flow Analysis
The introductory example in Section 2 already gave an intu-
ition about control ow analysis. The incremental construc-
tion of a control ow graph (CFG) is an important building
block for incremental, ow-sensitive analyses such as the
ow-sensitive points-to analysis described next. These two
analyses combined enable further precise analyses such as
uninitialized read and unused assignment analysis.
We implemented an incremental control ow analysis
that handles all of mbeddr C, including conditionals ( if
2https://szabta89.github.io/projects/inca.html
3https://wiki.eclipse.org/EMFIncQuery/
DeveloperDocumentation/PSystem
325u = &vu      vu = xu      vy      vx      vu = *xu      v*x = yu      vx      y,x      u,y      v(1)(2)(3)(4)Figure 8: Andersen's rules for points-to analysis
and switch ), loops ( for,while , and do while ), and jumps
(break andcontinue ). The implementation follows the style
of the introductory example, extending the cFlow relation
with further alternatives to handle all control statements.
The complete control ow analysis produces a CFG where
the nodes not only represent statements of the program,
but also other control ow points like the alternative case
branches of a switch statement or the else if parts of an
ifstatement. To this end, we dened an interface ICFGNode
as supertype for all nodes that can appear in the CFG. We
use this type in the points-to analysis as well.
6.2 Points-to Analysis
Our second case study is a points-to analysis for mbeddr C.
Given a variable that stores a pointer, the goal of a points-to
analysis is to identify the possible targets of the variable.
There is a vast amount of research in this area [22, 32, 41],
because the precision of points-to analysis directly benets
optimizations such as lock elision in a concurrent system and
program analyses such as uninitialized read analysis.
We represent the result of a points-to analysis as a relation
PointsTo(from,to) , which consists of those tuples where
both from and toare variables and from potentially points
totoat runtime. A points-to analysis is sound if PointsTo is
a conservative approximation of the actual targets of the vari-
ables. A well-known algorithm for computing the PointsTo
relation is Andersen's algorithm [1]. It considers four basic
kinds of assignments as shown in Figure 8 and derives the
points-to relation for the whole program from them.
Our points-to analysis in IncA builds on Andersen's rules
but extends them in three ways. First, by implementing
the analysis in IncA we immediately improve the run time
after code changes through incrementality. Second, we add
ow-sensitivity by building on top of our incremental control
ow analysis. Third, we do not require the code to only
use the four kinds of assignments in Andersen's rules, rather
support all of mbeddr C except pointer arithmetics.
Figure 9 shows an excerpt of the points-to analysis in
IncA. We use three main pattern functions for ow-sensitive
points-to analysis. Function pointsToBefore(n,u) com-
putes the potential targets of variable ubefore the execution
of node nof the CFG. We compute pointsToBefore by pro-
moting the bindings of pointsToAfter along the control
ow graph. Function pointsToAt(n) computes the eect
of node nin the form of changed bindings (x,y) . We de-
scribe function pointsToAt in greater detail below. Function
pointsToAfter(n,u) yields the potential targets of variable
uafter the execution of node n. If there is no new binding
at all at node n(rst alternative) or the new binding has no
eect on variable u(second alternative), pointsToAfter re-
tains the targets described by pointsToBefore . Otherwise, if
node naects variable u(third alternative), pointsToAfter
yields the new targets of u.
A single CFG node can contain multiple assignments
due to expression nesting as in (x=&u)+(y=&v) . Function
pointsToAt(n) gathers all assignments that occur in node
nand computes the corresponding points-to tuples. Given
an assignment, we can extract the pointer variable ufrom
the assignment's left hand side expression and the pointed-to
variable vfrom the right with Andersen's rules. However,1 def pointsToBefore(n:ICFGNode, u:Var) : Var = {
2 pred := cFlow(n)
3 return pointsToAfter(pred, u)
4 }
5 def pointsToAfter(n:ICFGNode, u:Var) : Var = {
6 assert undef pointsToAt(n)
7 return pointsToBefore(n, u)
8 }alt {
9 (x, y) := pointsToAt(n)
10 assert x != u
11 return pointsToBefore(n, u)
12 }alt {
13 (x, y) := pointsToAt(n)
14 assert x == u
15 return y
16 }
17 def pointsToAt(n : ICFGNode) : (Var, Var) = {
18 (lhs, rhs) := assignmentAt(n)
19 u := varInExprLeft(lhs)
20 v := varInExprRight(rhs)
21 return (u, v)
22 }
Figure 9: Flow-sensitive points-to analysis in IncA
1 def varInExprLeft(lhs : Expression) : Var = {
2 return varInExpr(lhs)
3 }alt {
4 assert lhs instanceOf DerefExpr
5 e := lhs.expression
6 u := varInExprLeft(e)
7 n := ancestorCFGNode(lhs)
8 v := pointsToBefore(n, u)
9 return v
10 }
11 def varInExprRight(rhs : Expression) : Var = {
12 assert rhs instanceOf AddressOfExpr
13 e := rhs.expression
14 return varInExpr(e)
15 }alt {
16 u := varInExpr(rhs)
17 n := ancestorCFGNode(rhs)
18 v := pointsToBefore(n, u)
19 return v
20 }alt {
21 assert rhs instanceOf DerefExpr
22 e := rhs.expression
23 u := varInExprRight(e)
24 n := ancestorCFGNode(rhs)
25 v := pointsToBefore(n, u)
26 return v
27 }
Figure 10: Extracting points-to variables in IncA
depending on the side of the assignment, the computation
is dierent. pointsToAt calls varInExprLeft to look up the
pointer variable and varInExprRight to obtain the pointed-
to variable and returns them as a new points-to tuple.
Function varInExprLeft in Figure 10 computes the pointer
variable of an assignment's left-hand side expression. If the
expression is a plain variable reference, function varInExpr
from Figure 6 extracts the variable. Otherwise, based on the
fourth Andersen rule (Figure 8), a pointer dereferencing *e
requires the lookup of the points-to targets of e. Function
varInExprLeft calls itself recursively on eto handle multiple
dereferencings **e, until nally reaching a plain variable. We
look up the points-to targets of the dereferenced variable uby
calling pointsToBefore , using ancestorCFGNode to retrieve
the surrounding CFG node. Function varInExprRight im-
plements three alternatives corresponding to the rst three
Andersen rules (in order). The implementation for deref-
3261 def CI_CONFUSED_INHERITANCE(c: Class): Void = {
2 assert c.isFinal == true
3 member := c.member
4 assert member instanceOf Field
5 assert member.visibility instanceOf Protected
6 }
Figure 11: FindBugs CI_CONFUSED_INHERITANCE in IncA
erencing (second alternative) is identical to varInExprLeft
and the other two alternatives are straightforward.
6.3 Well-formedness Checks for mbeddr C
We implemented four well-formedness checks for mbeddr C
and its language extensions. While the control ow analysis
and the points-to analysis inspected each function declara-
tions in separation, our well-formedness checks require global
knowledge about the source code. This case study shows
that IncA scales to support whole-program analyses. The
checks are as follows:
CYCLE mbeddr C provides modules for organizing code.
This check detects cyclic module dependencies.
GLOBAL This check detects conicting global variables
with the same name across modules.
REC This check detects recursive functions by construction
and inspection of a call graph. In embedded systems with
constrained memory, the stack space required for recursive
functions is often unacceptable.
COMP mbeddr C supports interfaces and composable
components. This check detects components that fail to
implement all functions declared by their interfaces.
6.4 FindBugs for Java
FindBugs [20] is a suite of predened patterns to detect
potential bugs in Java code. To show that our system is inde-
pendent of the analyzed language, we implemented 10 Find-
Bugs analyses in IncA for MPS' Java dialect. Apart from
a few language extensions, this Java language is identical
to the original Java language. As an example, we show
the implementation of the CI_CONFUSED_INHERITANCE rule
in Figure 11. It detects final classes that have at least
one protected eld. Since the class is nal, it cannot be
subclassed and the eld should be private or public. The
implementation runs incrementally thanks to IncA.
7. PERFORMANCE EVALUATION
In this section, we present the performance evaluation of
our system for the case studies introduced in Section 6. We
answer the following questions:
(Q1) Run time: How does the run time of IncA program
analyses compare to their non-incremental counterpart?
(Q2) Memory: How does the memory requirement of IncA
analyses compare to their non-incremental counterpart?
(Q3) Optimization impact: How does our optimization
(Section 4) aect the run time and memory requirements?
7.1 Evaluation Setup
For each case study, we start with an initial code base (intro-
duced below). After the initial, non-incremental run of the
analysis, we programmatically make 100 updates of the code
base and run the analysis after each update. Each update
consists of 1 to 20 random code changes, such as duplicating
a statement, deleting a function, renaming a variable, or in-troducing a new import. This approach allows us to imitate
how a user would modify the source code.
We measure the wall-clock time of processing the initial
code and of processing each update step. For the memory
measurement, we call the garbage collector after each analysis
run and measure the required heap memory. We subtract
the heap memory used before running the rst analysis to
obtain the memory usage of our system. We repeat each
measurement ve times and discard the results of the rst
and second run to account for Java VM warm-up.
As the rst benchmark, we run the control ow and points-
to analysis on the Toyota ITC code4, a collection of C code
snippets with intentional bugs to test the precision of static
analysis tools. The code base comprises about 15,000 lines
of C code. We compare the performance of the incremental
analyses to a non-incremental ow-sensitive points-to analy-
ses that was already available in mbeddr. The two analyses
produce exactly the same results on the benchmark.
The second benchmark was running the well-formedness
checks on a commercial Smart Meter software implemented
in mbeddr C [36]. A smart meter is an electric meter that
continuously records the consumption of electrical power,
calculates derived quantities, and sends the data back to the
utility provider for monitoring and billing. The whole project
comprises about 44,000 lines of mbeddr C code. For com-
parison, we implemented non-incremental well-formedness
checks in MPS Java that produce exactly the same results.
Running the 10 FindBugs checks consituted the third
benchmark; we ran it on the Java implementation of the
mbeddr importer which is responsible for migrating legacy C
code to mbeddr C. The importer comprises about 10,000 lines
of MPS Java code. Because of the MPS Java code base, we
would need to generate textualized Java code after every
code change to be able to use the original FindBugs tool.
For our large code base this is impractical, and thus for this
benchmark we do not have a non-incremental counterpart.
We ran the benchmarks on a 64-bit OSX 10.10.3 machine
with an Intel Core i7 2.5 GHz processor and 16 GB of RAM,
using MPS version 3.3 and Java 1.8.0 65. The raw data and
the sequence of code changes are available online.5
7.2 Run Time Measurements (Q1 & Q3)
Figure 12 (A) - (C) show the results of our run time measure-
ments. For points-to analysis and well-formedness checks
we show the results of the incremental and non-incremental
solutions using a logarithmic scale, for FindBugs we only
show the incremental results on a linear scale.
Box plots (A) and (B) immediately show that incremental
program analyses in IncA perform signicantly better than
non-incremental analyses. Box plots (A) - (C) also show that
the optimization has a signicant impact on the run time.
The following table summarizes the median run time data:
Non-inc. Inc w/o opt Inc w/ opt
init update init update
Points-to (A) 5 :8s 5 :6s 83 :2ms 1 :6s 23 :3ms
W.-form. (B) 209ms 12 :1s 104 :8ms 1 :2s 12 :8ms
FindBugs (C) n/a 4 :5s 40 :2ms 2 :3s 7ms
The initialization times, especially for the optimized versions,
do not pose an unduly run time requirement considering that
4https://github.com/regehr/itc-benchmarks
5https://szabta89.github.io/projects/inca.html
327‚óè‚óè‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè‚óèNon‚àíInc Inc w/o opt Inc w/ opt10 50 500 5000(Re)analysis time (ms) ‚àí log scale(A) Points‚àíto run times
‚óè‚óè‚óè
‚óè‚óè‚óè‚óè‚óè
‚óè‚óè‚óè‚óè
Non‚àíInc Inc w/o opt Inc w/ opt1 10 100 1000 10000(Re)analysis time (ms) ‚àí log scale(B) Well‚àíformedness run times
Inc w/o opt Inc w/ opt0 50 100 150(Re)analysis time (ms)(C) FindBugs run times
0 100 200 300 400 500 600 70010 20 30 40 50 60 70# of affected AST nodesReanalysis time (ms)(G) Points‚àíto reanalysis times
‚óè‚óè‚óè‚óè‚óè
Inc w/o opt Inc w/ opt230 240 250 260 270 280 290Memory req. (MB)(D) Points‚àíto memory req.
Inc w/o opt Inc w/ opt40 60 80 100 140 180Memory req. (MB)(E) Well‚àíformedness memory req.
Inc w/o opt Inc w/ opt90 100 110 120 130Memory req. (MB)(F) FindBugs memory req.
0 500 1000 1500 20000 10 20 30 40 50 60# of affected AST nodesReanalysis time (ms)(H) Well‚àíformedness reanalysis timesFigure 12: Run time and memory measurements for the case studies
loading large programs into MPS also takes a few seconds. Af-
ter initialization, incremental analysis without optimization
achieves speedups of A= 70x and B= 2x compared to non-
incremental analysis. With optimization, we even achieve
speedups of A=249x and B=16x. Indeed, the optimization
accounts for an additional speedup of 2 - 10x for initializa-
tion and of 3-8x for change-processing time. IncA and
its optimization provide good runtime performance across
analyses and for both analyzed languages.
Figure 12 (G) and (H) show the points-to and well-formed-
ness analysis times as a function of the input change size
(the number of deleted or added AST nodes). IncA scales
well, because the plots remain roughly linear with increasing
input change sizes. We conclude:
(Q1) Incremental program analysis with IncA provides
signicant speedups of up to 249x compared to non-
incremental analysis. The analyses scale linearly with
increasing input change sizes.
(Q3) The IncA compiler optimization improves initializa-
tion time by 2{10x and change-processing time by 3{8x.
7.3 Memory Measurements (Q2 & Q3)
Figure 12 (D) - (F) show the results of our memory measure-
ments. We measured the memory required by incrementality
for each of the 100 update steps and created the box plots
from this data. We summarize the median memory require-
ments in the following table:
Inc w/o opt Inc w/ opt
Points-to (D) 273MB 242MB
Well-form. (E) 163MB 50MB
FindBugs (F) 124MB 100MB
The points-to analysis is the most complex case study and it
has the biggest memory requirement, because its computation
graph caches major part of the input AST to compute a
complete CFG and to handle a large variety of assignments,
including nested ones. The optimization helps to reduce the
memory requirement with A= 11%, B= 69%, and C= 19%.
Based on our experience with real world usage of MPS, the
IDE typically requires about 1 :2GB of memory. This meansthat the optimized analyses have a memory overhead of
A=20%, B=4%, and C=8% relative to MPS. We conclude:
(Q2) For real world scenarios, incremental program anal-
ysis with IncA requires an acceptable amount of 20%
additional memory for our most complex case study.
(Q3) The IncA compiler optimization reduces the required
memory by 11 - 69%.
8. RELATED WORK
Improving the performance of program analyses has attracted
a lot of research, because of their widespread use in compilers
and IDEs. In particular, the use of incrementality to speed
up program analyses has a long tradition.
Specialized algorithms While we present a framework
for incremental program analyses, the manual enhancement
ofspecic program analyses to support incrementality is
also subject to research. Yur et al. propose an algorithm
for incremental ow-sensitive and context-sensitive points-to
analysis [41]. The paper assumes that the CFG is maintained
incrementally. This in itself is a challenging problem which
we address as part of our work. Saha and Ramakrishnan
propose an incremental ow-insensitive points-to analysis for
a subset of C using logic programming [32]. Lu et al. present
a context-sensitive and eld-sensitive points-to analysis for
Java based on context-free language reachability [22].
All of these approaches target only a particular analysis
(e.g. points-to analysis). There are also many algorithms [7,
25, 18, 26] tailored specically to incrementally handle a class
of analyses (e.g. data-ow analyses). IncA goes one step fur-
ther than those because it supports a wider spectrum of anal-
yses (data-ow, syntactic analyses such as well-formedness,
FindBugs) as a language-agnostic framework.
The previously mentioned algorithms come with their own
incrementalization engine that could play the role of the
incremental evaluator in our architecture (although limiting
expressivity to a particular class of analyses). Once embedded
into our architecture, their eciency could be improved with
our optimizations.
Analysis Frameworks Several systems in model-driven
development incrementally reapply consistency rules on mod-
328els [12, 16, 6]. These systems are only incremental in the
sense that they selectively reapply aected consistency rules
after a change; once selected, the rules run non-incrementally
on the whole input. This form of incrementalization is not
practical for complex program analyses or for large inputs.
In contrast, our system incrementally reanalyzes only those
program entities that are actually aected by a change.
EMF-IncQuery is a framework for incremental queries over
EMF models [35]. Like IncA, it is based on the IncQuery
evaluator. We have generalized EMF-IncQuery in several
ways. First, we have designed the IncA DSL for the descrip-
tion of program analyses that abstracts from graph patterns
and supports more conventional descriptions as forward or
backward analyses. Second, we extended our runtime sys-
tem with the data-ow analysis-based optimization, whereas
EMF-IncQuery requires manual registration of relevant parts
of the metamodel. Third, we describe an architecture that
supports the integration with IDEs other than Eclipse. Fi-
nally, the focus of EMF-IncQuery is ecient model queries,
while we show that graph patterns can be used to implement
program analyses that scale to real world programs.
Wachsmuth et al. introduce a language-independent task
engine for incremental name and type analysis in the Spoofax
language workbench [39]. Evaluation starts by collecting
analysis tasks, which are executed in a second step. When
the analyzed program changes, the task engine recollects
analysis tasks and executes only the aected ones. IncA,
in contrast, is not limited to name or type analysis, but
supports a wider range of analyses.
Arzt and Bodden present an extension of the IFDS frame-
work [31] that selectively re-derives changed parts of a pro-
gram's data-ow graph upon program manipulation, enabling
incremental data-ow analysis. The IFDS framework reduces
data-ow problems into a graph reachability problem and
associates semantic information to program nodes whereas
IncA relates program nodes. There are analyses (e.g., points-
to) that can be cast as both, but there are certain analyses
that are not supported by either one of the frameworks.
For example, IncA cannot handle analyses that require the
generation of runtime data (e.g., an interval for an inter-
val analysis), while IFDS cannot handle the more syntactic
analyses (e.g., well-formedness or FindBugs). Supporting
semantic analyses in IncA would require IncA extensions to
generate and incrementally maintain runtime data that is
not in the AST. However, this is non-trivial because such an
extension must consider the trade-o between the expressive
power needed for computing derived data and the feasibility
of incrementalizing these computations. We investigate this
direction in future work.
Datalog-based analyses The IncA runtime system trans-
lates analysis code into graph patterns, and we showed that
the solution can scale to real-world programs. Datalog, a
logic programming language used in deductive databases, is
often used as a denition language of program analyses [40,
5, 29]. In fact, IncQuery's graph patterns and Datalog with
stratied negation [15] and recursion share the same expres-
sive power [21, p. 225]. This suggests that Datalog could
replace IncQuery as the target language for IncA and a cor-
responding incremental Datalog backend could be used as
the evaluator in our system. However, to the best of our
knowledge there is only the commercial LogicBlox [2] backend
which employs incrementalization. From the literature, it is
clear that LogicBlox scales to large inputs for from-scratchanalyses, but the performance of the incremental part is not
documented. While there are specialized algorithms for incre-
mentalizing Datalog queries [10, 11], we emphasise that our
contributions build around an o-the-shelf evaluator. Also,
abstracting from the relational nature of Datalog with IncA
helps language developers to deal with abstractions that they
are usually already familiar with, such as functions, direction
from input to output, and assignments. This is important,
because, for DSLs it is often infeasible to spend large ef-
forts on program analyses; a straightforward implementation
approach is crucial.
The DOOP framework [33] uses Datalog and LogicBlox to
dene various (ow-insensitive) points-to analyses for Java.
The authors of DOOP pose the question whether a high-level
language can be expressive enough to implement various
program analyses. They show that Datalog is well-suited
for Java points-to analyses. However, our work shows that
a high-level language (which can itself be analyzed) is also
useful for other kinds of syntactic analyses in a language-
agnostic way. We will experiment with extensions of IncA
for generating runtime data, which would further extend the
kinds of analyses that IncA could support.
General-purpose incrementalization i3QL [23] makes
incremental computations available as an embedded Scala
DSL using an SQL-like syntax. Its runtime system builds
on relational algebra and applies optimizations known from
database engines, but, unlike IncA, it does not detect and
lter irrelevant program changes. Adapton [17] is an ML-
style general-purpose language for incremental self-adjusting
computations. The runtime system of Adapton tracks mem-
ory dependencies in order to retrigger computations when a
change to a data structure occurs. Compared to our evalu-
ation, these tools were tested only on small programs with
simple analyses, and it is thus unclear whether they can scale
to support complex program analysis of large code bases.
Analysis DSLs Other researchers have proposed DSLs for
specic program analyses, but, in contrast to IncA, do not
provide incrementalization. Examples include the declarative
DSL for CFG construction in the JastAdd compiler [34, 13],
the data-ow rules of DCFlow [19], fact extraction with De-
Facto [4], and MPS' DSL for constructing data-ow graphs.
9. CONCLUSIONS
We presented IncA, a DSL for the denition and ecient
evaluation of incremental program analyses in IDEs. IncA
provides a declarative notation for analyses in the style of
pattern functions that our optimizing compiler translates
into graph patterns. We demonstrated the applicability of
IncA by developing incremental program analyses for C and
Java. Our performance evaluation shows that IncA provides
signicant speedups compared to non-incremental analyses
and acceptable memory overhead.
We plan to use IncA in the future to enforce secure coding
standards (e.g. Misra, CERT) in mbeddr. These standards
dene well-formedness rules which IncA can check incremen-
tally as the program is edited.
10. ACKNOWLEDGEMENT
The authors would like to thank Daco Harkes, Johannes
Lerch, and the members of the EMF-IncQuery team for
feedback and useful discussions on this work. This work was
supported in part by Oracle Labs.
32911. REFERENCES
[1]Andersen, L. O. Program Analysis and Specialization
of the C Programming Language . PhD thesis,
University of Copenhagen, 1994.
[2]Aref, M., ten Cate, B., Green, T. J., Kimelfeld,
B., Olteanu, D., Pasalic, E., Veldhuizen, T. L.,
and Washburn, G. Design and Implementation of the
LogicBlox System. In Proceedings of the 2015 ACM
SIGMOD International Conference on Management of
Data (New York, NY, USA, 2015), SIGMOD '15, ACM,
pp. 1371{1382.
[3]Arzt, S., and Bodden, E. Reviser: Eciently
Updating IDE-/IFDS-based Data-ow Analyses in
Response to Incremental Program Changes. In
Proceedings of the 36th International Conference on
Software Engineering (New York, NY, USA, 2014),
ICSE 2014, ACM, pp. 288{298.
[4]Basten, H. J. S., and Klint, P. Defacto:
Language-parametric fact extraction from source code.
InSoftware Language Engineering: First International
Conference, SLE 2008, Toulouse, France, September
29-30, 2008. Revised Selected Papers , D. Ga sevi c,
R. Lammel, and E. Wyk, Eds. Springer Berlin
Heidelberg, Berlin, Heidelberg, 2009, pp. 265{284.
[5]Besson, F., and Jensen, T. Modular class analysis
with datalog. In Proceedings of the 10th International
Conference on Static Analysis (2003), Springer-Verlag.
[6]Cabot, J., and Teniente, E. Incremental Integrity
Checking of UML/OCL Conceptual Schemas. J. Syst.
Softw. 82 , 9 (Sept. 2009), 1459{1478.
[7]Cooper, K. D., and Kennedy, K. Ecient
computation of ow insensitive interprocedural
summary information. In Proceedings of the 1984
SIGPLAN Symposium on Compiler Construction (New
York, NY, USA, 1984), SIGPLAN '84, ACM,
pp. 247{258.
[8]Diekmann, L., and Tratt, L. Eco: A Language
Composition Editor. In Software Language Engineering:
7th International Conference, SLE 2014, V aster  as,
Sweden, September 15-16, 2014. Proceedings ,
B. Combemale, D. J. Pearce, O. Barais, and J. J.
Vinju, Eds. Springer International Publishing, Cham,
2014, pp. 82{101.
[9]Dietrich, J., Hollingum, N., and Scholz, B.
Giga-scale Exhaustive Points-to Analysis for Java in
Under a Minute. In Proceedings of the 2015 ACM
SIGPLAN International Conference on Object-Oriented
Programming, Systems, Languages, and Applications
(New York, NY, USA, 2015), OOPSLA 2015, ACM,
pp. 535{551.
[10]Dong, G., and Su, J. First-order incremental
evaluation of datalog queries. In Proceedings of the
Fourth International Workshop on Database
Programming Languages - Object Models and
Languages (London, UK, UK, 1994), DBLP-4,
Springer-Verlag, pp. 295{308.
[11]Dong, G., Su, J., and Topor, R. Nonrecursive
incremental evaluation of datalog queries. Annals of
Mathematics and Articial Intelligence 14 , 2 (1995),
187{223.
[12]Egyed, A. Instant Consistency Checking for the UML.
InProceedings of the 28th International Conference onSoftware Engineering (New York, NY, USA, 2006),
ICSE '06, ACM, pp. 381{390.
[13]Ekman, T., and Hedin, G. The JastAdd System |
Modular Extensible Compiler Construction. Sci.
Comput. Program. 69 , 1-3 (Dec. 2007), 14{26.
[14]Erdweg, S., Bra cevac, O., Kuci, E., Krebs, M.,
and Mezini, M. A Co-contextual Formulation of Type
Rules and Its Application to Incremental Type
Checking. In Proceedings of the 2015 ACM SIGPLAN
International Conference on Object-Oriented
Programming, Systems, Languages, and Applications
(New York, NY, USA, 2015), OOPSLA 2015, ACM,
pp. 880{897.
[15]Green, T. J., Huang, S. S., Loo, B. T., and Zhou,
W.Datalog and recursive query processing. Found.
Trends databases 5 , 2 (Nov. 2013), 105{195.
[16]Groher, I., Reder, A., and Egyed, A. Incremental
Consistency Checking of Dynamic Constraints. In
Fundamental Approaches to Software Engineering ,
D. Rosenblum and G. Taentzer, Eds., vol. 6013 of
Lecture Notes in Computer Science . Springer Berlin
Heidelberg, 2010, pp. 203{217.
[17]Hammer, M. A., Phang, K. Y., Hicks, M., and
Foster, J. S. Adapton: Composable, Demand-driven
Incremental Computation. In Proceedings of the 35th
ACM SIGPLAN Conference on Programming Language
Design and Implementation (New York, NY, USA,
2014), PLDI '14, ACM, pp. 156{166.
[18]Hermenegildo, M., Puebla, G., Marriott, K.,
and Stuckey, P. J. Incremental analysis of constraint
logic programs. ACM Trans. Program. Lang. Syst. 22 , 2
(Mar. 2000), 187{223.
[19]Hills, M. Streamlining Control Flow Graph
Construction with DCFlow. In Software Language
Engineering , B. Combemale, D. Pearce, O. Barais, and
J. Vinju, Eds., vol. 8706 of Lecture Notes in Computer
Science . Springer International Publishing, 2014,
pp. 322{341.
[20]Hovemeyer, D., and Pugh, W. Finding Bugs is Easy.
SIGPLAN Not. 39 , 12 (Dec. 2004), 92{106.
[21]Immerman, N. Descriptive complexity . Springer
Science & Business Media, 2012.
[22]Lu, Y., Shang, L., Xie, X., and Xue, J. An
Incremental Points-to Analysis with CFL-Reachability.
InCompiler Construction , R. Jhala and
K. De Bosschere, Eds., vol. 7791 of Lecture Notes in
Computer Science . Springer Berlin Heidelberg, 2013,
pp. 61{81.
[23]Mitschke, R., Erdweg, S., K ohler, M., Mezini,
M., and Salvaneschi, G. I3QL: Language-Integrated
Live Data Views. In Proceedings of the 2014 ACM
International Conference on Object Oriented
Programming Systems Languages & Applications,
OOPSLA 2014, part of SPLASH 2014, Portland, OR,
USA, October 20-24, 2014 (2014), pp. 417{432.
[24]Nielson, F., Nielson, H. R., and Hankin, C.
Principles of Program Analysis . Springer-Verlag New
York, Inc., Secaucus, NJ, USA, 1999.
[25]Pollock, L. L., and Soffa, M. L. An incremental
version of iterative data ow analysis. IEEE Trans.
Softw. Eng. 15 , 12 (Dec. 1989), 1537{1549.
330[26]Puebla, G., and Hermenegildo, M. Optimized
algorithms for incremental analysis of logic programs.
InStatic Analysis: Third International Symposium,
SAS '96 Aachen, Germany, September 24{26, 1996
Proceedings , R. Cousot and D. A. Schmidt, Eds.
Springer Berlin Heidelberg, 1996, pp. 270{284.
[27]Ramalingam, G., and Reps, T. A categorized
bibliography on incremental computation. In
Proceedings of the 20th ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages
(New York, NY, USA, 1993), POPL '93, ACM,
pp. 502{510.
[28]Rensink, A. Representing First-Order Logic Using
Graphs. In Graph Transformations , H. Ehrig,
G. Engels, F. Parisi-Presicce, and G. Rozenberg, Eds.,
vol. 3256 of Lecture Notes in Computer Science .
Springer Berlin Heidelberg, 2004, pp. 319{335.
[29]Reps, T. W. Demand interprocedural program
analysis using logic databases. In Applications of Logic
Databases , R. Ramakrishnan, Ed. Springer US, Boston,
MA, 1995, pp. 163{196.
[30]Rozenberg, G. , Ed. Handbook of Graph Grammars
and Computing by Graph Transformation: Volume I.
Foundations . World Scientic Publishing Co., Inc.,
River Edge, NJ, USA, 1997.
[31]Sagiv, M., Reps, T., and Horwitz, S. Precise
Interprocedural Dataow Analysis with Applications to
Constant Propagation. Theor. Comput. Sci. 167 , 1-2
(Oct. 1996), 131{170.
[32]Saha, D., and Ramakrishnan, C. R. Incremental
and Demand-driven Points-to Analysis Using Logic
Programming. In Proceedings of the 7th ACM
SIGPLAN International Conference on Principles and
Practice of Declarative Programming (New York, NY,
USA, 2005), PPDP '05, ACM, pp. 117{128.
[33]Smaragdakis, Y., and Bravenboer, M. Using
Datalog for Fast and Easy Program Analysis. In
Datalog Reloaded: First International Workshop,
Datalog 2010, Oxford, UK, March 16-19, 2010. Revised
Selected Papers , O. Moor, G. Gottlob, T. Furche, and
A. Sellers, Eds. Springer Berlin Heidelberg, Berlin,
Heidelberg, 2011, pp. 245{251.
[34]Soderberg, E., Ekman, T., Hedin, G., and
Magnusson, E. Extensible intraprocedural ow
analysis at the abstract syntax tree level. Science of
Computer Programming 78 , 10 (2013), 1809 { 1827.Special section on Language Descriptions Tools and
Applications (LDTA'08 & '09) & Special section on
Software Engineering Aspects of Ubiquitous Computing
and Ambient Intelligence (UCAmI 2011).
[35]Ujhelyi, Z., Bergmann, G., Abel Heged us,Akos
Horv ath, Izs o, B., R ath, I., Szatm ari, Z., and
Varr o, D. EMF-IncQuery: An integrated development
environment for live model queries. Science of
Computer Programming 98, Part 1 , 0 (2015), 80 { 99.
Fifth issue of Experimental Software and Toolkits
(EST): A special issue on Academics Modelling with
Eclipse (ACME2012).
[36]Voelter, M., Deursen, A. v., Kolb, B., and
Eberle, S. Using C Language Extensions for
Developing Embedded Software: A Case Study. In
Proceedings of the 2015 ACM SIGPLAN International
Conference on Object-Oriented Programming, Systems,
Languages, and Applications (New York, NY, USA,
2015), OOPSLA 2015, ACM, pp. 655{674.
[37]Voelter, M., Ratiu, D., Kolb, B., and Schaetz,
B.mbeddr: Instantiating a language workbench in the
embedded software domain. Automated Software
Engineering 20 , 3 (2013), 339{390.
[38]Voelter, M., Siegmund, J., Berger, T., and Kolb,
B.Towards User-Friendly Projectional Editors. In
Software Language Engineering , B. Combemale,
D. Pearce, O. Barais, and J. Vinju, Eds., vol. 8706 of
Lecture Notes in Computer Science . Springer
International Publishing, 2014, pp. 41{61.
[39]Wachsmuth, G., Konat, G., Vergu, V.,
Groenewegen, D., and Visser, E. A Language
Independent Task Engine for Incremental Name and
Type Analysis. In Software Language Engineering ,
M. Erwig, R. Paige, and E. Van Wyk, Eds., vol. 8225
ofLecture Notes in Computer Science . Springer
International Publishing, 2013, pp. 260{280.
[40]Whaley, J., and Lam, M. S. Cloning-based
context-sensitive pointer alias analysis using binary
decision diagrams. In Proceedings of the ACM
SIGPLAN 2004 Conference on Programming Language
Design and Implementation (2004), ACM.
[41]Yur, J.-s., Ryder, B. G., and Landi, W. A. An
Incremental Flow- and Context-sensitive Pointer
Aliasing Analysis. In Proceedings of the 21st
International Conference on Software Engineering (New
York, NY, USA, 1999), ICSE '99, ACM, pp. 442{451.
331