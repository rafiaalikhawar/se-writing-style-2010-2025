DetReduce: Minimizing Android GUI Test Suites for Regression
Testing
Wontae Choiâˆ—
University of California, Berkeley
wtchoi@cs.berkeley.eduKoushik Sen
University of California, Berkeley
ksen@cs.berkeley.edu
George Necula
University of California, Berkeley
necula@cs.berkeley.eduWenyu Wangâ€ 
University of Illinois, Urbana-Champaign
wenyu2@illinois.edu
ABSTRACT
In recent years, several automated GUI testing techniques for An-
droid apps have been proposed. These tools have been shown to
be effective in achieving good test coverage and in finding bugs
withouthumanintervention.Beingautomated,thesetoolstypically
runforalongtime(say,forseveralhours),eitheruntiltheysaturate
test coverage or until a testing time budget expires. Thus, these
automated tools are not good at generating concise regression test
suites that could be used for testing in incremental development of
the apps and in regression testing.
Weproposeaheuristictechniquethathelpscreateasmallregres-
sion test suite for an Android app from a large test suite generatedby an automated Android GUI testing tool. The key insight behind
our technique is that if we can identify and remove some com-
mon forms of redundancies introduced by existing automated GUI
testing tools, then we can drastically lower the time required to
minimize a GUI test suite. We have implemented our algorithm in
a prototype tool called DetReduce. We applied DetReduce to sev-
eral Android apps and found that DetReduce reduces a test-suite
by an average factor of 16 .9Ã—in size and 14 .7Ã—in running time.
We also found that for a test suite generated by running Swift-
Hand and a randomized test generation algorithm for 8 hours,
DetReduce minimizes the test suite in an average of 14 .6 hours.
CCS CONCEPTS
â€¢Software and its engineering â†’Software testing and de-
bugging;
KEYWORDS
Android, GUI, Test minimization
âˆ—Currently at Google Inc.
â€ This work has been done while the author was a visiting student at University of
California, Berkeley
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Â© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.3180173ACM Reference Format:
Wontae Choi, Koushik Sen, George Necula, and Wenyu Wang. 2018. De-
tReduce: Minimizing Android GUI Test Suites for Regression Testing. In
ProceedingsofICSEâ€™18:40thInternationalConferenceonSoftwareEngineering
, Gothenburg, Sweden, May 27-June 3, 2018 (ICSE â€™18), 11 pages.
https://doi.org/10.1145/3180155.3180173
1 INTRODUCTION
In recent years, there has been a significant surge in the usage and
developmentofappsforsmartphonesandtablets.Developersare
writingmoreappsformobileplatformsthanfordesktops.Thecom-
plexityofmobileappsoftenliesintheirgraphicaluserinterfaces
(GUIs).Testingeffortsofsuchappsmostlyfocusonthebehavior
of graphical user interfaces.
Several automated GUI testing techniques have recently been
proposed. The techniques include learning-based testing [ 8,29,31,
32], model-based testing [ 1,23,45], genetic programming [ 27,28],
fuzztesting[ 25,26,37],andstatic-analysisbasedapproaches[ 4,33,
34,44,49].Thegoalofthemajorityofthesetechniquesistoachieve
good code and screen coverage (i.e. covering all distinct screens of
anapp),andtofindcommonbugssuchascrashesandunrespon-
siveness. Most of these techniques work by injecting sequences of
automaticallygenerateduserinputsoractionstoanappforseveral
tens of hours. We consider each sequence of actions injected by
these techniques to be a test case, and the set of all sequences of
actions to be a test suite.
Although automated GUI testing techniques could find bugs,
they tend to generate large test suites containing thousands oftest cases. Each test case can contain tens to thousands of useractions. Such a large test suite can take several hours to execute,
becausetherunningtimeofatestsuiteislinearinthesizeofthe
test suite.1However, regression tests should be fast so that they
canbeusedfrequentlyduringdevelopment.Therefore,suchtest
suites are difficult to use in regression testing.
In this paper, we address the problem of generating a small
regressionGUItestsuiteforanAndroidapp.Weassumethatwe
are given a large test suite generated by an existing automatedGUI testing tool. We also assume that the test suite is replayablein the sense that if we rerun the test suite multiple times we get
thesamecoverageandobservethesamesequenceofappscreens.
(Theevaluationsectionhasdetailsonhowtoobtainareplayable
1For aGUI app, it isrecommended to restrict theamount of computation performed
by each event handler to improve responsiveness. Therefore, the running time of a
GUI test case tends to be linear in the length of the test case.
4452018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Wontae Choi, Koushik Sen, George Necula, and Wenyu Wang
test suite from an automated GUI testing tool.) We assume that
thetest suitetakes severalhours torunon theapp. Ourgoalis to
spendareasonableamountoftime,sayaday,togenerateasmall
regression test suite for the app that runs for less than an hour and
that achieves similar code and screen coverage as the original test
suite provided as input.
A couple of techniques have been proposed to minimize test
suitesforGUIs.Forexample,Clappetal . [7]andHammoudietal .
[17]proposeddelta-debugging[ 48]basedalgorithms.Thesetech-
niquesworkwellifthesizeoftheinputtestsuiteissmall,containing
less than one thousand user inputs. However, they fail to scale for
large test suites because they depend heavily on the rapid gen-
eration and feasibility checking of new test cases. Unfortunately,for most real-world GUI apps, it takes few minutes to check the
feasibility of a new input sequence. Therefore, for large test suites
containing tens of thousands of user actions, a delta-debugging
basedapproachcouldtakemorethanamonthtoeffectivelymini-
mizeatestsuite.McMasterandMemon [30]proposedaGUItest
suite reduction techniquefor reducing the numberof test cases in
a test suite. However, this technique does not make any effort to
reducethesizeofeachtestcase.Inourexperimentalevaluation,weobservedthattestcasesgeneratedbyanautomatedtoolcancontain
subsequences of redundant user actions, which can be removed to
obtain smaller test suites.
We propose an Android GUI test suite reduction algorithm that
can scalably and effectively minimize large test suites. The key
insight behind our technique is that if we can identify and remove
some common forms of redundancies introduced by existing au-
tomatedGUItestingtools,thenwecandrasticallylowerthetime
required to minimize a test suite. We manually analyzed test suites
generatedbyexistingautomatedGUItestingtools andfoundthere
are three kinds of redundancies that are common in these testsuites: 1) some test cases can be safely removed from a test suite
without impacting code and screen coverage, 2) within a test case,
certainloopscanbeeliminatedwithoutdecreasingcoverage,and
3)manytestcasessharecommonsubsequencesofactionswhose
repeatedexecutioncanbeavoidedbycombiningfragmentsfrom
different action sequences. Based on these observations, we devel-
oped an algorithm that removes these redundancies one-by-one
whilepreservingtheoverallcodeandscreencoverageofthetest
suite.
In orderto identifyredundant loopsand commonfragments of
test cases, we define a notion of state abstraction which enables
us to approximately determine if we are visiting the same abstract
stateatleasttwicewhileexecutingatestcase.Ifanabstractstate
is visited twice during the execution, we have identified a loop
which can potentially be removed. Similarly, if the executions of
two test cases visit an identical subsequence of abstract states, we
knowthatfragmentsfromthetwotestcasescanbecombinedto
obtain a longer test case which avoids re-executing the commonfragment. Whenever we get a new test case by removing a loopor by combining two fragments, the resulting test case may nottraverse the same abstract states as expected. In our algorithm,
wecheckthefeasibilityofanewlycreatedtestcasebyexecuting
it a few times and by checking if the execution visits the samesequence of abstract states every timeâ€”we call this replayability.
Wenoticedthatifourstateabstractionistoocoarse-grainedourfeasibility checks often fail, leading to longer running time. On the
otherhand,ifweuseatoofine-grainedstateabstraction,wefailto
identifymanyredundancies.Onecontributionofthispaperisto
design a good enough abstraction that works well in practice.
Oneadvantage ofour algorithmoverdelta-debugging orother
black-boxalgorithmsisthatwedonotblindlygenerateallpossible
newtestcasesthatcanbeconstructedbydroppingsomeactions.
Rather, we use a suitable state abstraction to only drop potentially
redundantloops.Anotheradvantageisthatwecreatenewtestcases
bycombiningfragmentsfrominputtestcases.Thisenablesusto
come up with new, longer test cases which cannot be generatedusing delta-debugging or other test suite reduction techniques.
Longertestcasesareusuallybetterthanmultipleshortertestcasesbecausewedonothavetoperformacleanrestartofanapp.Aclean
restart of an app requires us to kill the app, erase app data, anderase SD card contents, which is very time consuming. A longer
testcaseinplaceofseveralshortertestcasesavoidsseveralsuch
expensive restarts.
We have implemented our algorithm in a prototype tool, called
DetReduce,forAndroidapps.Thetoolispubliclyavailableathttps:
//github.com/wtchoi/swifthand2.WeappliedDetReducetoseveral
appsandfoundthatDetReducecouldreduceatest-suitebyafactorof16
.2Ã—insizeandafactorof14 .7Ã—inrunningtimeonaverage.We
alsofoundthatforatestsuitegeneratedbyrunningSwiftHand[ 5]
and a random testing algorithm [ 5] for 8 hours, DetReduce can
reduce the test suite in an average of 14 .6 hours. We are not aware
of any existing technique that could get such huge reduction inthe size of a large GUI test suite in such a reasonable amount of
time.NotethatDetReduceoftenrunslongerthangeneratingall
testcases;however,runningDetReduceisaone-timecost.Oncea
regression suite has been generated, it will be run many times and
each run will take a fraction of the time required to generate all
test cases.
2 OVERVIEW
AutomatedGUItestingtools,suchasMonkey[ 12],A3E[2],Dyn-
odroid[26],MobiGUITAR[ 1],andOrbit[ 45],exploretheGUIofan
appautomaticallywithoutanypriorknowledgeaboutthebehavior
of the app. These automated tools are, however, not good at gener-
atingconciseregressiontestsuitesthatcouldbe usedfortestingin
incremental development of the apps and in regression testing. We
proposeaheuristictechniquethathelpstocreateasmallregression
test suite for a GUI app given a large test suite generated by an
automatedGUItestingtool.Wenextgiveabriefoverviewofour
technique using formal notation and a series of examples.
2.1 Definitions and Problem Statement
Trace.Theexecutionofanapponasequenceofuserinputscanbe
denotedbya traceoftheform s0a1,C1âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1a2,C2âˆ’âˆ’âˆ’âˆ’âˆ’â†’...an,Cnâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’sn.Eachsi
isanabstractstateoftheprogram,usuallycomputedbyabstracting
the screen of the app. Each siâˆ’1ai,Ciâˆ’âˆ’âˆ’âˆ’âˆ’â†’siis atransition, denoting
thattheapptransitionedfromstate siâˆ’1tostatesionuserinput(or
action)aiand covered the set of branches Ciduring the transition.
Severaleventhandlerscouldbetriggeredduringatransition:the
branches covered during the transition are the branches of the
triggered event handlers (and the methods transitively called from
446
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. DetReduce: Minimizing Android GUI Test Suites for Regression Testing ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
theseeventhandlers)thatareexecutedduringthistransition.Here
we focus on branch coverage, but one could use other kinds of
coverage for Ci.
Coverage. Ifsiâˆ’1ai,Ciâˆ’âˆ’âˆ’âˆ’âˆ’â†’siis a transition, then Ciâˆª{si}is
thecoverage of the transition. In the coverage we include both
the set of branches and the abstract states visited by the tran-
sition. We can similarly define the coverage of a trace Ï„=
s0a1,C1âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1a2,C2âˆ’âˆ’âˆ’âˆ’âˆ’â†’...an,Cnâˆ’âˆ’âˆ’âˆ’âˆ’â†’snas the union of the coverage of all
the transitions in the trace, i.e. C(Ï„)=âˆªiâˆˆ[1,n](Ciâˆª{si}).
Replayable traces. Inourtechnique,weareonlyinterestedin
replayable traces. A trace Ï„=s0a1,C1âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1a2,C2âˆ’âˆ’âˆ’âˆ’âˆ’â†’...an,Cnâˆ’âˆ’âˆ’âˆ’âˆ’â†’snof an
appisreplayable ifeverytimetheappisgiventhesequenceofuser
actionsa1,a2,...,anin a state s0(the initial state of the app), it
generates the exact trace Ï„.
Test suite: A set of replayable traces. We assume that an au-
tomated testing tool for GUI generates a setTsof replayable traces
thatcanbetreatedasaregressiontestsuite.The coverageofaset
oftracesT,denotedby C(T),isdefinedastheunionofthecoverage
of the traces contained in the set. The cost of a set of traces Tis the
pair(/summationtext.1
Ï„âˆˆT|Ï„|,|T|). The first component of the pair gives the num-
beroftransitionspresentinthetracesin T.Thisnumberroughly
estimates the amount of time necessary to replay the traces in T.
Between the replay of two traces, one needs to perform a cleanrestart of the app by erasing the app data and SD card contents,
which has high cost. In order to take that cost into account, we
have a second component in the pair corresponding to the number
of clean restarts necessary to replay all the traces in T.
Problem statement. Givenasetofreplayabletraces Ts,thegoal
is to find a minimal set of traces T0such that T0is replayable, T0
consists of transitions from the traces in Ts,C(Ts)=C(T0), and
the cost of T0is minimal. Unfortunately, finding a minimal T0is
intractableforthefollowingreasons.First,withoutthereplayabilityrequirement,theproblemcanbereducedtoaninstanceoftheprize-
collectingtravelingsalesman problem(PCTSP),awell-knownNP-
hard problem [ 3]. With the replayability requirement, a solution
foundbysolvingthecorrespondingPCTSPproblemmayinclude
non-replayable traces. Therefore, we need to solve multiple PCTSP
problems until finding a replayable solution. Instead of solving the
problemoffindingtheglobalminimum,wedevelopedatwo-phaseheuristicalgorithm,whichwefoundtoworkeffectivelyinpractice.
2.2 Limitations of Existing Approaches
In any test-case reduction technique, we need to construct new
traces.Althoughthecreationofatracetakeslittletime,wehavetoensurethatthetracecanbereplayed.Itisimpossibletopreciselyde-termineifatraceisreplayable.Inourtechnique,wecheckifatrace
isreplayablebyexecutingitfewtimes.Wefoundexperimentally
thatifatraceisnon-replayable,itwillfailtoreplaywithineight
executions withvery high probability. Faithfully executinga single
transition ina tracecould take afew secondsbecause after inject-
inganinputoraction,weneedtowaituntilthescreenstabilizes.
Therefore, executing a trace composed of several transitions could
takeseveralminutes.Moreover,afterexecutingeachtraceweneed
to perform a clean restart, which takes several seconds. Therefore,
itisgenerallytimeconsumingtocheckifatraceisreplayable.This
is the key bottleneck faced by a GUI test suite reduction technique.





%





%	
! " # 

%



%



%
"
! ! $ 
#
% %
Figure 1: A partial model of a file browser app.
Existing test minimization techniques, such as delta-
debugging [ 48] and genetic algorithms [ 27], will create and
checkthereplayabilityof manytraces.Therefore, thesetechniques
cannotscalewhen theinitialsetof tracesislarge.But allexisting
automatedtechniquesforGUItestgenerationcreatelargenumbers
of traces. According to Clapp et al . [7]â€™s experimental results, their
variantofdelta-debuggingcantakeafewhourstoseveraltensof
hours to handle traces composed of only 500 transitions. In our
experiments, we had to handle test cases having 10,000 transitions.
If we linearly extrapolate the timings reported by Clapp et al. to
10,000 transitions, delta-debugging could potentially take a month.
We seek a technique that can minimize a test suite in a day or less.
2.3 Our Observations
We observed that the set of traces generated by an automated
testing tool has many redundancies. Our technique for GUI test
suitereductiontriestoremovetheseredundancies.Wenextdescribe
these redundancies using a series of examples.
2.3.1 Redundant Traces. Among the traces in a test suite, the
coverage provided by some traces is a subset of coverage provided
by the remaining traces. Such traces can be removed from the test
suitewithoutdecreasingthecumulativecoverage.Ourtechnique
finds such redundant traces and removes them from the test suite.
2.3.2 Redundant Loops. Wealsoobservedthattherecouldbe
redundancies within a trace, for example, if the trace contains aredundant loop. A loop in a trace is a sub-trace of the trace thatbegins and ends in the same abstract state. Traces generated by
automatedtestingtoolstendtocontainmanyloops,andsomesuchloopsdonotprovideadditionalcoverageoverthecoveragethatcanbeachievedbythetracewithouttheloopandtheremainingtraces.
Such loops are redundant and can be removed from the trace if the
resulting trace can be replayed.We next illustrate such redundant
loops using a couple of examples.
AllexamplesutilizethefilebrowserappshowninFigure1.When
the app starts, it shows the root directory (abstract state/screen s0).
In this initial state/screen, a user can invoke a pop-up menu ( s1)b y
touchingthemenubuttononthescreen(thebuttonatthetop-rightcornerwiththreedotcharacters).Oncethemenuisvisible,theuser
can close the menu by touching the same button. Selecting an item
on the menu results in a completely different abstract state/screen
of the app. Pressing the Option button leads the app to the option
screen (s2). The app also allows the user to navigate the file system
(abstract state/screen s0ands3). Note we intentionally made the
directories /fooand/foo/foo to have the same look in order to
keep the example simple.
447
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Wontae Choi, Koushik Sen, George Necula, and Wenyu Wang
Example2.1. (Aredundant loop)Assumethat theusertouches
the menu button three times. This input sequence will open the
pop-upmenu,closeit,andthenopenitagain.Theuserthenselects
the first item (i.e. the Option button) of the menu. This action
will lead the app to the configuration screen. Assume there are no
event handlers associated with the menu open and close events.
The execution of the above action sequence will then generate
the followingtrace: s0Menu,âˆ…âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1Menu,âˆ…âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s0Menu,âˆ…âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1Option ,Coâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ â†’s2
whereâˆ…istheemptysetand Codenotesthetestcoveragegenerated
whenthe appmoves totheconfiguration screen.Inthis trace,the
sub-trace s0Menu,âˆ…âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1Menu,âˆ…âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s0forms a loop since it begins and
endswiththesameabstractstate.Thecoverageofthislooponly
containsthestates s1ands0.Thecoverageoftheloopisasubset
of the coverage of the rest of the trace ( Coâˆª{s0,s1,s2}). Thus, the
loopdoesnotaddanyextracoveragethanwhatisalreadyachieved
by the rest of the trace. This makes sense because the loop merely
opensand closesthe pop-upmenu.After removingthe loopfrom
the trace, if the modified trace is replayable, we can replace the
original trace with the modified trace. Removing the loop gives us
the following shorter replayable trace: s0Menu,âˆ…âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1Option ,Coâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ â†’s2.
Example 2.2. (A non-redundant loop) A loop is non-redundant
when the loop provides coverage that cannot be achieved
by the rest of the trace(s). Let us assume that the app nowhas event handlers attached to the menu open and closeevents. Re-executing the same sequence of actions from Ex-ample 2.1 will generate the following slightly different trace:
s0Menu,Cpâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1Menu,Ccâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s0Menu,Cpâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1Option ,Coâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ â†’s2,whereCpand
Ccdenote the coverage generated by executing the menu open
andcloseeventhandlers,respectively.Inthismodifiedtrace,the
loop contributes the test coverage Ccwhich cannot be achieved by
any other transition in the trace. Therefore, the loop should not be
removed from the trace.
Example 2.3. (Another non-redundant loop) A loop can be non-
redundantiftheremovaloftheloopmakesthetracenon-replayable,
evenifitdoesnotachieveanynewcoverage.Notethatifweuse
theconcretestateoftheappinsteadofascreenabstraction,atrace
willbereplayableifweremovealoop.However,duetoabstraction,
thestartandendstates ofaloopmaynotcorrespondtothesame
concrete state. Therefore, the trace may not be replayable after theremoval of a loop. Let us illustrate this with an example. This time,
wearegoingtonavigatethefilesystemtoreachthefoldercontain-
ingpictures(i.e. state s3).Thistaskcanbedonebysimplytouching
thefoofolderthreetimes.Theexecutionofthesequenceofactions
willgeneratethefollowingtrace: s0foo,Cf1âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s0foo,Cf1âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s0foo,Cf2âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’s3,
whereCf1denotes the test coverage generated when opening a
folderonlycontainingsubfolders,and Cf2denotesthetestcover-
age generated when opening a folder only containing files. The
tracehasthreeloops(thefirsttransition,thesecondtransition,and
thesub-tracecontainingthefirsttwotransitions).Thethirdloopcannotberemovedbecauseremovingitwillreducethecoverage
of the trace. The first and seconds loops, however , look identical
and one may think that one of the two loops can be removed from
the trace. However, removing one of these two loops will make the
tracenon-replayablebecausetouchingthe foofoldertwiceleads
theapptothescreenshowingthecontentsof /foo/foo folderand
we will miss Cf2. The trace obtained after removing one of theloopsisnon-replayablebecauseourcoarse-grainedstateabstrac-
tion maps three distinct app states to s0. However, if we do not use
theabstraction,wewillhaveunboundednumberofstates,which
will make both automated test generation and test minimization
fail.Thisexampleshowsthataloopisnon-redundantifitsremoval
makes the trace non-replayable. Note that determining whether
removing a loop will have an impact on the rest of a trace can only
be determined by trying to replay the modified trace.
2.3.3 Redundant Trace Fragments. While analyzing traces in
automatically generated test suites of several apps, we observedthat many traces share common sub-traces. If we execute these
traces,thecommonsub-tracesgetexecutedmultipletimes(once
for each trace) but new coverage is only achieved when a common
sub-trace is executed for the first time. We can avoid redundant
executionofthesecommonsub-tracesifwecancombinefragmentsoftracesinamannerthatavoidsrepetitionsofcommonsub-traces.Combiningfragmentsoftraceswillalsoresultinlongertraces.Such
longertraceswillreducethenumberofrestarts,whicharemore
expensiveoperationsthantriggeringanaction.Thenextexample
describes how common sub-traces contribute to redundancy.
Example2.4. (Splicingthreetraces)Considerthefollowingthree
artificially-crafted traces:
s0a,C1âˆ’âˆ’âˆ’âˆ’â†’s1b,C2âˆ’âˆ’âˆ’âˆ’â†’s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3d,C4âˆ’âˆ’âˆ’âˆ’â†’s4
s0a,C1âˆ’âˆ’âˆ’âˆ’â†’s1d,C4âˆ’âˆ’âˆ’âˆ’â†’s4e,C5âˆ’âˆ’âˆ’âˆ’â†’s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3d,C4âˆ’âˆ’âˆ’âˆ’â†’s4
s0a,C1âˆ’âˆ’âˆ’âˆ’â†’s1b,C2âˆ’âˆ’âˆ’âˆ’â†’s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3f,C6âˆ’âˆ’âˆ’âˆ’â†’s5
Note the first and second traces have two common sub-traces:
s0a,C1âˆ’âˆ’âˆ’âˆ’â†’s1ands2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3d,C4âˆ’âˆ’âˆ’âˆ’â†’s4. Similarly, the first and third
traces have the common prefix s0a,C1âˆ’âˆ’âˆ’âˆ’â†’s1b,C2âˆ’âˆ’âˆ’âˆ’â†’s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3. By com-
bining fragments of the traces, we can create the followingtrace:
s0a,C1âˆ’âˆ’âˆ’âˆ’â†’s1b,C2âˆ’âˆ’âˆ’âˆ’â†’s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3d,C4âˆ’âˆ’âˆ’âˆ’â†’s4e,C5âˆ’âˆ’âˆ’âˆ’â†’s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3f,C6âˆ’âˆ’âˆ’âˆ’â†’s5.
The spliced trace is constructed by appending sub-trace
s4e,C5âˆ’âˆ’âˆ’âˆ’â†’s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3tothe firsttrace,and thenbyappending thesub-
traces3f,C6âˆ’âˆ’âˆ’âˆ’â†’s5to the resulting trace. The new trace gets rid of six
actions and two restart operations from the original traces. Notethat the spliced trace still contains two copies of the sub-trace
s2c,C3âˆ’âˆ’âˆ’âˆ’â†’s3,whichwecouldnotgetridof.Ifthesplicedtraceisre-
playable, it can replace the original traces in the test suite. The
running time of the spliced trace will be approximately half of the
originaltraces,whileprovidingthesamecoverage.Thisexample
showsthatwecanaggressivelycombinefragmentsfrommultiple
traceswhilegettingridofredundantfragments(includingredun-
dantprefixes).However,inpractice,wefoundthattracescomposed
of a large number of fragments from different traces tend to be
non-replayable.Therefore,inourtechniquewelimitthenumber
of different trace fragments that we can combine to a small bound,
which is three in our implementation.
2.4 Our Approach
State abstraction. Inourdiscussionsofar,weassumedwehave
asuitablestateabstractionthatenablesustoclustersimilar-looking
screens. The performance of our technique for test reduction de-pends heavily on our choice of state abstraction. If we choose a
fine-grainedabstraction,thenourtechniquerunsfaster,butmay
miss many opportunities for reduction. On the other hand, if we
448
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. DetReduce: Minimizing Android GUI Test Suites for Regression Testing ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
pick a coarse-grained abstraction, many of the traces that our tech-
nique constructs become non-replayable. Therefore, our technique
spendsmoretimeincheckingreplayabilityofvarioustraces,butwe
get a bigger reduction. We observed that a human tester can easily
identify screens that are similar by analyzing what is visible on the
screen.Ideallyweneeded anabstractionthatjudgesthattwoapp
screenstobethesameifandonlyifahumantesterfindsthetwo
screens visuallyidentical. Afteranalyzing several apps,we picked
a state abstraction based on information from the GUI component
tree. The details of the abstraction are described in Section 4.
Removing redundancies. Weproposeatwo-phasealgorithm
toremoveredundanciesfromaGUItestsuite.Thefirstphasere-
moves redundant traces and redundant loops greedily. It first re-
moves redundant traces by greedily selecting traces such that each
selectedtracecontributesnewcoveragetothecoverageofthesetofalreadyselectedtraces.Thenon-selectedtracesarethenredundant
and are removed from the test suite. It then removes redundantloops from each remaining trace. In order to remove redundant
loops in a trace, the algorithm creates the set of all traces obtained
from the trace by removing zero or more loops. It then selectsa trace from the set that does not decrease cumulative coverage,
lowerscostofthetracemaximally,andisreplayable.Suchatrace
replaces the original trace in the test suite.
The second phase removes redundant trace fragments as much
as possible. For that it constructs a new set of traces by combining
fragmentsofthetracesinthesetcomputedbythefirstphase.When
splicing trace fragments, we found it useful to limit the number of
fragments in spliced trace to a small number (three in our case),because a trace composed of many fragments tends to be non-
replayableinpractice.Thus,thesecondphaseofthealgorithmfirst
creates the set of candidate traces composed of a bounded number
oftracefragments.Itthenconstructsanewtestsuitebygreedily
selecting traces from the set of candidate traces.
Inbothphases,wheneverouralgorithmgeneratesanewtrace,it
checks whether the trace is replayable or not by executing it a few
times.Thispreventsthealgorithmfromaddinganon-replayable
trace to the resulting regression test suite. If the algorithm findsa trace to be non-replayable, it identifies and saves the shortestnon-replayable prefix of the trace. In the future, if the algorithm
finds that a new trace starts with one of these saved prefixes, then
it can safely infer that the trace is non-replayable and discard it.
This optimization helps the algorithm aggressively discard some
non-replayabletraceswithoutexecutingthemmultipletimes.We
describe the reduction algorithm formally in the next section.
3 ALGORITHM
3.1 Redundant Loop and Trace Elimination
In order to construct a minimal set of traces, we only retain the
traces from Tswhose cumulative coverage is same as the coverage
ofTs. Then we remove as many loops from the remaining traces
aspossiblewhilemaintainingthesamecumulativecoverageand
the replayability of the traces. This results in a set of traces Tr
whose cost is much lower than the cost of Ts. During the removal
of loops, our algorithm discovers that certain trace prefixes are not
replayable. We speedup the loop elimination phase by pruning outthetraceswhoseprefixmatchesthenon-replayableprefixes.We
next describe this algorithm formally.
Given a trace Ï„, we say that a sub-trace of Ï„is aloopif it be-
gins and ends in the same state. For example, if in the trace Ï„=
s0a1,C1âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1a2,C2âˆ’âˆ’âˆ’âˆ’âˆ’â†’...an,Cnâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’snthere exists two states siandsjsuch
thati/nequaljandsi=sj,thenthesub-trace /lscript=siai+1,Ci+1âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’...aj,Cjâˆ’âˆ’âˆ’âˆ’âˆ’â†’sj
is a loop. If we remove the loop from Ï„, we get a shorter trace
Ï„/lscript=s0a1,C1âˆ’âˆ’âˆ’âˆ’âˆ’â†’...ai,Ciâˆ’âˆ’âˆ’âˆ’âˆ’â†’siaj+1,Cj+1âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’...an,Cnâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’sn.Atraceobtainedaf-
ter eliminating one or more loops from Ï„may no longer be re-
playable.Thus,anytimeouralgorithmremovesaloopfromatrace,
weneedtocheckiftheresultingtraceisstillreplayable.Let L(Ï„)be
thesetofalltracesobtainedbyremovingdifferentcombinationsof
zero or more loops from Ï„. Note that L(Ï„)containsÏ„.
The pseudocode of thealgorithm is shown in Algorithm 1. The
algorithm uses a function Replaywhich takes a trace Ï„and returns
Ï„if the trace is replayable; otherwise, the function returns the
shortest prefix of Ï„that is not replayable. Therefore, the check
Ï„=Replay(Ï„)telluswhether Ï„isreplayableornot.Inthefirstpart
ofthealgorithm,weremoveallredundanttraces.Todosowecreate
anemptyset Ttostorethenon-redundanttraces.Thealgorithm
goesovereach trace Ï„inTs.IfC(Ï„)hassomecoverage thatisnot
already present in C(T), thenÏ„is not redundant and we add Ï„to
T.Aftergoingoveralltracesin Ts,Twillcontainnon-redundant
traces ofTssuch that C(T)=C(Ts).
In the second part, the algorithm performs redundant loop elim-
ination. It maintains a set of reduced traces Trwhich is initialized
to the empty set. The algorithm goes over each trace Ï„inT.I t
thengoesovereachtrace Ï„/primeinL(Ï„)(thesetofalltracesobtained
fromÏ„by removing zero or more loops) in the increasing order
of cost. If C(Ï„/prime)âˆªC(Tr)=C(Ï„)âˆªC(Tr)andÏ„/primeis replayable, i.e. if
Ï„/prime=Replay(Ï„/prime),thealgorithmadds Ï„/primetoTrandstopsprocessing
elementsof L(Ï„).Thisindicatesthatthealgorithmhascomputed
a trace possibly shorter than Ï„. On the other hand, if Ï„/primeis not
replayable, then any trace in L(Ï„)havingReplay(Ï„/prime)as a prefix
is removed from the set L(Ï„)because all such traces will also be
non-replayable.Thisreducesthenumberthetracesthatwehave
to process from the set L(Ï„), and thus reduces the running time
ofthealgorithm.Notethatduringtheprocessingofthetracesin
L(Ï„), we will end up adding Ï„toTrif none of the loops in Ï„can
be eliminated without reducing coverage or without making the
resultant trace non-replayable.
Practicalconcerns. Thealgorithmreliesonarobustimplementa-
tion ofReplay(Ï„). However, in practice it is not easy to have a pre-
ciseimplementationof Replay(Ï„)thatwillguaranteethat Replay(Ï„)
returnsÏ„if and only if Ï„is replayable. Such an implementation
wouldrequireustotracktheentirestateoftheappincludingthe
state of any internet server it might be interacting with. Moreover,
ifwemaketheimplementationof Replay(Ï„)tooprecise,inmany
acceptablecasesitwillreportthat Ï„isnotreplayable.Inourtool,
we make a practical trade-off where we re-execute the trace Ï„a
few times, which is ten in our experiments, and report the shortest
prefixofÏ„thatisnon-replayableoveralltenre-executions.Ifinall
the ten executions we find that Ï„is replayable, Replay(Ï„)returnsÏ„.
Thealgorithmalsoneedstocompute L(Ï„),i.e.thesetoftraces
obtainedfrom Ï„byremoving0ormoreloops.Ourimplementation
doesnotcomputetheset L(Ï„)aheadoftime.Ratheritperformsa
449
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Wontae Choi, Koushik Sen, George Necula, and Wenyu Wang
Algorithm 1 Eliminate redundant traces and loops
1:procedure EliminateRedundantTracesAndLoops( Ts)
2:Tâ†âˆ… âŠ¿Part 1: Eliminate redundant traces.
3:forÏ„âˆˆTsdo âŠ¿Loop over the input trace set.
4: ifC(Ï„)/notsubseteqlC(T)then
5: Tâ†Tâˆª{Ï„}
6:Trâ†âˆ… âŠ¿Part 2: Eliminate redundant loops.
7:forÏ„âˆˆTdo âŠ¿Loop over the filtered trace set T.
8:TLâ†L(Ï„)
9: whileTL/nequalâˆ…do
10: Ï„/primeâ†argmin
Ï„âˆˆTL|Ï„|
11: TLâ†TL\{Ï„/prime}
12: ifC(Ï„/prime)âˆªC(Tr)=C(Ï„)âˆªC(Tr)then
13: ifÏ„/prime=Replay(Ï„/prime)then
14: Trâ†Trâˆª{Ï„/prime}
15: breakthe inner loop
16: else
17: TLâ†{Ï„âˆˆTL|Replay(Ï„/prime)is not a prefix of Ï„}
18:returnTr
depth-firsttraversalofthetrace Ï„toenumeratethetracesin L(Ï„)
one-by-one from the shortest to the longest one.
Finally, the result of the first phase of the algorithm will change
depending on the order of picking elements from Ts(line 3) and T
(line 7). Our implementation uses queues to store test cases, which
guarantees that test cases are always handled in first-come first-
serveorder. Wetriedvariousotherorderings,butweobservedthat
the results did not vary significantly.
3.2 Trace Splicing
While analyzing traces in the set Tr, i.e. the traces generated by
loop and trace elimination, we noticed traces often share common
sub-traces.Therefore,ifwecancombinetracesinordertoavoid
common sub-traces as much as possible, we generate longer traces.
This isgood,since longer tracesavoid expensive restarts and avoid
execution of redundant sub-traces. However, we also found that
the more traces we combine, the more likely we are to get non-replayable traces. We found experimentally that if we combine
threeorfewertracefragments,wecouldstillreaptherewardsof
longer traces (avoiding restarts and redundant execution) while
creatingreplayabletraces.Basedontheseobservations,wedevised
the second part of our minimization algorithm where we combine
fragments from different traces to create longer replayable traces.
Atrace fragment is a contiguous portion of a trace obtained
by removing a prefix and a suffix of the trace. For example, if
Ï„=s0a1,C1âˆ’âˆ’âˆ’âˆ’âˆ’â†’s1a2,C2âˆ’âˆ’âˆ’âˆ’âˆ’â†’...an,Cnâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’snis a trace, then for any i,jâˆˆ[0,n]
whereiâ‰¤j,siai+1,Ci+1âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’...aj,Cjâˆ’âˆ’âˆ’âˆ’âˆ’â†’sjis afragment of the trace Ï„.A
setoftracefragments Ï„1,Ï„2,...,Ï„mcanbecombinedtoformthe
traceÏ„1Ï„2...Ï„mifÏ„1beginswith thestate s0andfor all iâˆˆ[2,m],
the end state of Ï„iâˆ’1is the same as the first state in Ï„i. Given a set
of tracesTr, letTkbe the set of all traces obtained by combining at
mostktrace fragments from the traces in Tr.
The pseudocode of thealgorithm is shown in Algorithm 2. The
algorithm first constructs the set Tkfrom the set Tr. The algorithm
initializesthefinalsetofminimizedtraces Tmtotheemptyset.The
algorithm then does the following in a loop: it finds a trace Ï„inTk
such that Ï„results in the maximal increase in coverage over the
coverage of Tm, i.e.Ï„maximizes |C(Ï„)\C(Tm)|. If no such trace is
foundinTk,thealgorithmreturns Tm.Otherwise,if Ï„isreplayable,
it removes Ï„fromTkand adds it to Tm.I fÏ„is not replayable, thenAlgorithm 2 Bounded splicing
1:procedure BoundedSplicing( Tr,k)
2:Tkâ†{Ï„|Ï„is a trace composed of at most kfragments of traces in Tr}
3:Tmâ†âˆ…
4:while âˆƒÏ„âˆˆTk.C(Ï„)\C(Tm)/nequalâˆ…do
5:Ï„â†argmax
Ï„âˆˆTk|C(Ï„)\C(Tm)|
6:Tkâ†Tk\{Ï„}
7: ifÏ„=Replay(Ï„)then
8: Tmâ†{Ï„}
9: else
10: Tkâ†{Ï„âˆˆTk|Replay(Ï„)is not a prefix of Ï„}
11:returnTm
alltracesin TkhavingReplay(Ï„)asaprefixareremovedfrom Tk.
This step speeds up the search for optimal Ï„in future iterations.
The loop is then repeated.
Theabovealgorithmterminatesandcomputesa Tmsuchthat
C(Tm)=C(Tr).Thealgorithmterminatesbecauseineachiteration
we increase the coverage of Tm, and the coverage of Tmcannot be
increasedbeyondthecoverageof Tr(whichissameasthecoverage
ofTk). The algorithm also ensures that C(Tm)=C(Tr)because
for any finite k,Tkcontains the traces in Tr. Therefore, in the
worstcaseifnoneofthetracesobtainedbycombiningtwoormore
tracefragmentsfromdifferenttracesarereplayable,wewillendup
adding all the traces in TrtoTm. This ensures that C(Tm)=C(Tr).
Computing Tk.Algorithm 2 uses a declarative specification to
describethetraceset Tk.Wenextdescribeanalgorithmtocompute
the set efficiently. For any set of traces, we can construct a labeled
transitionsystemcomposedofthetransitionsofthetracesinthe
set.Formally,if Trisasetoftraces,weconstructalabeledtransition
systemQTr=(S,s0,L,A,C,Î´), where
â€¢Sis the set of all states in Tr,
â€¢LâŠ†NÃ—N is a set of labels,â€¢s0is the initial state of the app,
â€¢Ais the set of all actions in Tr,
â€¢Cis the set of coverage sets in Tr, and
â€¢Î´is a set of labeled transitions of the form siâˆ’1ai,Ciâˆ’âˆ’âˆ’âˆ’âˆ’â†’
lsi, where
Î´={siâˆ’1ai,Ciâˆ’âˆ’âˆ’âˆ’âˆ’â†’
(j,i)si|âˆƒÏ„jâˆˆTrs.t.siâˆ’1ai,Ciâˆ’âˆ’âˆ’âˆ’âˆ’â†’siis theithtransition in Ï„j}.
Informally, an element of Î´is a transition from a trace in Tr,
augmentedwithapairofindicesdenotingthetracetowhichthe
transition belongs and the position of the transition in the trace.
Notethatforanytracein Tr,thereisapathinthelabeledtransition
systemQTr.Moreover,anypathin QTrrepresentsatracethatcould
beobtainedbycombiningtracefragmentsfrom Tr.Wecancheckif
apathfrom QTrbelongsto Tkbyanalyzingthelabelsofthepathas
follows. Two consecutive transitions with labels (j1,i1)and(j2,i2)
inapathconstitutea switchifeitherj1/nequalj2ori1+1/nequali2.Apath
inQTrbelongsto Tkifthenumberofswitchesinthepathisless
thank. The algorithm to construct Tkenumerates the paths in QTr
using depth-first search and discards a path as soon as the number
of switches along the path reaches k. The algorithm terminates
sincekis finite and the number of trace fragments is bounded.
4 IMPLEMENTATION
Weimplementedourtestreductionalgorithminaprototypetool,
called DetReduce. DetReduce works for Android apps, but could
beimplementedforotherplatformssupportinggraphicaluserin-
terfaces.Thetoolispubliclyavailableathttps://github.com/wtchoi/
swifthand2.
450
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. DetReduce: Minimizing Android GUI Test Suites for Regression Testing ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Screen abstraction. DetReduce uses a suitable screen abstrac-
tiontoclusterappstates.Wefoundthattheabstractionmechanism
usedinSwiftHand[ 5]isappropriatetogroupscreensthatuser
might find to be similar. We next briefly explain the screen abstrac-
tion mechanism. A screen abstraction is computed from a raw
GUI component tree collected from an app via UIAutomator. A
GUI component tree contains detailed information about a screen.
We observed that the following information are useful and often
sufficient to characterize a screen:
â€¢Which GUI components are actionable? For example, Checkbox
and TextButton components are actionable in Android, while
TextBox and DecorationBar components are not.
â€¢Which attribute values of actionable GUI components are visible
on the screen? For example, for a screen with a checkbox, one
could observe if the checkbox is checked or not.
WeextractthisinformationfromarawGUIcomponenttree.The
abstractioniscomputedbyfirstcollectingasetofactionableGUI
components (i.e. the components with event handlers) from a GUI
component tree. Each collected component is augmented with the
accesspathtothecomponentfromtherootintheGUItree.Unnec-
essary attributes are then removed from each component.
5 EVALUATION
We aim to answer the following research questions.
â€¢RQ1: How effective is DetReduce in reducing test suites?
â€¢RQ2: Does DetReduce run in a reasonable amount of time?
â€¢RQ3: Does DetReduce preserve test coverage?
â€¢RQ4: Does DetReduce preserve fault-detection capability?
â€¢RQ5: How many re-executions are required to demonstrate the
replayability of a trace?
â€¢RQ6: What will happen to the splicing algorithm if the number
of fragments in traces is increased beyond three?
To answer RQ1toRQ5, we generated test suites using two test
generation algorithms(SwiftHand[5] andRandom [5])on eigh-
teen benchmark apps and applied DetReduce to reduce them. To
answerRQ6, we analyzed the relationship between the likelihood
of finding a replayable trace and the bound on the number of frag-
ments in traces using four relatively complicated apps. We used
five smartphones (Motorola XT1565) to run benchmark apps.
5.1 Experimental Setup
5.1.1 Benchmark Apps. WeappliedDetReducetoeighteenfree
appsdownloadedfromtheGooglePlaystore[ 11]andF-Droid[ 39].
Table 1 lists these apps along with their package name, the type of
app,andthenumberof branchesintheapp(whichoffersarough
estimateofthesizeoftheapp.)Sincetheappsweredownloadeddirectly from app stores, we have access to only their bytecode.
Thirteenappswereusedforexperimentalevaluationinpreviousre-
searchprojects[ 6,9,49];otherapps,whichwemarkwithasterisks,
arenewlyselected.WeexcludedappsforwhichSwiftHandand
Random saturate the test coverage in less than an hour. Note thataddingsuch appswouldonly improveexperimentresults because
most of traces in test suites for such apps are redundant.
5.1.2 Generating a Replayable Test Suite to be Used for Minimiza-
tion.TogeneratetestsuitestobeusedasinputstoDetReduce,weTable 1: Benchmark Apps
app package name type #br
acar com.zonewalker.acar car manager 20380
amemo liberty.android.fantastischmemo flashcard 6394
amoney* com.kpmoney.android finance 28141
astrid org.tasks task manager 16844
cnote* dictapps.notepad.color.note note 14524
dmoney com.bottleworks.dailymoney finance 5099
emobile org.epstudios.epmobile fitness tracker 3201
explore com.speedsoftware.explorer filesystem 54302mileage com.evancharlton.mileage car manager 7728mnote jp.gr.java_conf.hatalab.mnv text editor 1959
monefy com.monefy.app.lite finance 22615
sanity cri.sanity device manager 4610
tippy net.mandaria.tippytipper tip calculator 5243
todo* com.splendapps.splendo task manager 11858ttable* com.gabrielittner.timetable scheduler 11858vlc* org.videolan.vlc media player 14410
whohas de.freewarepoint.whohasmystuff inventory 369xmp org.helllabs.android.xmp media player 5855
firstcollectedexecutiontracesbyrunninganimplementationofthe
SwiftHand[ 5]andRandom[ 5]algorithms.Weraneachforeight
hours,thencheckedwhetherthegeneratedtracesarereplayablebyre-executingeachtracetentimes.Foreachnon-replayabletrace,we
identifiedanon-emptyreplayableprefixofthetraceandretained
the prefix rather than throwing the entire trace away.
An app can generate a non-replayable trace for several reasons:
a) the app has external dependency (e.g., it receives messages from
theoutsideworld,dependsonatimer,orreadsandwritestothe
filesystem),orb)theapphasinherentnon-determinismduetotheuseofarandomnumbergeneratorormulti-threading.Weremoved
dependencyontheoutsideworldbyresettingthecontentsoftheSDcardandtheappdataeverytimewerestart.Nonetheless,itis
impossible to eliminate all sources of non-determinism. Therefore,
we replayed each trace generated by the SwiftHand and Random
algorithmstentimestoremovethenon-replayablesuffixesoftraces.
Wedeterminedexperimentallythateightre-executionsissufficient
to detect most of non-replayable traces for the benchmark apps.
5.1.3 Why we did not use Monkey to generate initial test suite?
Monkey [ 12] is a fuzz testing tool for Android apps. Monkey is
widely-used to automatically find bugs in real-world Android apps.
WeinitiallyattemptedtouseMonkeytogenerateinputsforDetRe-
duce;however,wefoundthatMonkeyisnotcapableofgenerating
replayable traces. We now describe our experience with Monkey.
Monkeyisasimpleblackboxtoolthatreportsonlythesequence
of actions it used to drive a testing session. To get a trace would re-quirenon-trivialmodificationstoMonkey.Beforejumpingintothis
effort, we performed an experiment to determine whether Monkey
is even capable of generating replayable tracesâ€”if Monkey cannot
generate replayable traces, there is no point in the modification.
In this experiment, we used a script to generate traces with
partialinformationfromMonkeyandcheckedifthosetracescould
be replayed. The script injects user actions at the rate of mactions
persecond,collectingbranchcoverageandscreenabstractionafter
injecting every nactions. The script picks the value of mfrom the
set{1,2,5,10,20,100}and value of nfrom{2,10,50,100,200}. For
each pair of values for mandn, the script runs Monkey until it
injects2000actions.Bycombiningthesequenceofactionsreported
by Monkey with the collected coverage information, the scriptcan generate traces that have coverage and screen information
451
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Wontae Choi, Koushik Sen, George Necula, and Wenyu Wang
after every nactions (instead of having the information after every
event.) We call such traces partial traces.
Usingthisscript,wecollectedthreepartialtracesforeachpos-
siblevalueof mandnusingthesamerandomseedandcompared
thepartialtraces.Ifthepartialtracesdonotmatch,thisindicates
thatMonkeycannotgenerateareplayabletrace.Weperformedthe
experiment using ten apps with three different random seeds.
TheresultsofthisexperimentshowedthatMonkeypassesthe
test for four apps when n=2 andm=2. For the other six apps,
Monkeyfailsthetestevenwheninjectingoneactionpersecond.At
thisspeedMonkeybecomesuselessinpracticebecauseitspower
comesprimarilyfromitsabilitytoinjectmanyactionsquickly.It
will take too long to generate a sufficiently good test suite using
Monkey at this speed . Therefore, we have concluded that using
Monkey is not viable for generating initial replayable test suite.
Why is Monkey testing highly non-deterministic? We found that
Monkey injects actions asynchronouslyâ€”that is, Monkey injects
an action without checking whether the previously injected action
has been fully handled. This allows Monkey to inject an order
ofmagnitudemoreactionsthantestingtoolsthatsynchronously
injectactions,butthisalsomakesMonkeyhighlynon-deterministic.
Forexample,wenoticedthatifactionsareinjectedwhiletheapp
isunresponsive,thoseactionsaredropped.Becausetheperiodof
unresponsiveness variesfrom execution to execution,the number
of dropped actions varies across executions.
5.2 Evaluation of DetReduce
Table2andTable3showtheresultsofapplyingDetReducetothe
testsuitesgeneratedbytheSwiftHandandRandomalgorithms,
respectively. Each table has four parts. The first part shows the
following information aboutthe test suites to be minimized: total
branch coverage (#br.), total screen coverage (#s.), total number of
transitions(#act.),andtotalnumberoftraces(#tr.)ofeachinitial
testsuite.Thesecondandthirdpartsofthetableshowinformation
aboutthetestsuitesgeneratedafterrunningthefirstandsecond
phases, respectively, of DetReduce. The fourth part shows im-
portant statistics summarizing the experiment results: the running
timeofeachphaseofthealgorithm(t p1andtp2),theexecutiontime
(tr)oftheresultingreducedregressiontestsuite,andtheratioof
theexecutiontimeoftheresultingregressionsuitetotheexecution
time of the original test suite in percentage (t r/t). We make the
following observations from the data shown in the tables.
â€¢RQ1: The execution time of the reduced test suites ( tr)i ss e v -
eral orders of magnitude shorter than that of the original test
suites (8 hours). This shows that DetReduce is highly effective
in minimizing the test suites for the benchmark apps. Regarding
the sizes of test suites, phase 1 of DetReduce removes 91.27%
oftransitions(median)and90.5%ofrestarts(median).Phase2
of DetReduce further removes 33.07% of transitions and 31.81%
of restarts from the test suites obtained after Phase 1. These two
phasesof DetReducecumulativelyremove93.84%oftransitions
and93.52%ofrestarts.Wealsofoundthattherateofreduction
is higher for test suites generated from Random. This is because
thesetestsuiteshavelowertestcoverageandmoreredundancies.
â€¢RQ2: The running time of the algorithm is within a factor of 6 Ã—
of the execution time of the original test suites generated by thetestgenerationalgorithms.Morethanhalfoftherunningtime
wasspentindetectingandeliminatingloopsinphase1(notethat
DetReduce spends no time removing redundant traces because
such traces do not require any execution). The time spent in
phase1isreasonablebecausethephasesearchesforaminimized
test suite while eliminating redundant loops from each trace.
Note that these experiments employed a conservative parameter
(ten)forthenumberofre-executionstoperformtochecktrace
replayability, and the running cost of DetReduce can be further
reduced by setting this parameter to eight.
â€¢RQ3: Despite using an approximate method for checking if a
traceisreplayable,theminimizedtestsuitesnonethelesscover
themostoftheoriginalbranchandscreencoverage.DetReduce
failstoprovide100%coveragefor amoney,explorer ,ttable,and
vlc.Wemanuallyanalyzedthereasonsforthemissingbranches
andscreens,anddeterminedthatnon-replayabletraceswerenot
fully removed while generating the original test suites before
phase 1 of DetReduce.
â€¢RQ4: In order to check how DetReduce affects the fault-
detection capability of test suites, we collected exceptions raised
while executing each test suite. We identified seven distinct ex-
ceptions based on their stacktrace. All survived after applying
DetReduce. Note that DetReduce does not consider exceptions
to be part of the test coverage it tries to preserve.
â€¢RQ5: We measured how many re-executions were required to
identify each non-replayable trace created during our experi-
ments. The following table summarizes the results.
T n=1 n=2 n=3 n=4 n=5 n=6 n=7 n=8 n=9 n=10
18043 10956 120 86 55 35 27 14 3 0 0
The first column (T) shows the total number of traces created
during the experiments, and the remaining columns show the
numberofnon-replayabletracesthatrequired nre-executions
for detection. The results show that all non-replayable traces
were detected within the first eight iterations. The results also
showthat37 .5%oftracesattemptedduringtheexperimentswere
replayabletraces,suggestingthatDetReduceisgoodatselecting
candidate traces in our benchmarks.
5.3 Splicing and the Number of Fragments in
Traces
RQ6: To understand the effect of bounding the number of trace
fragmentsinphase2ofouralgorithm,wemeasuredtherelationship
between the bound and the likelihood of finding a replayable trace,
and the average number of trace fragments in a trace generated by
splicing. For these measurements, we used four relatively complex
benchmark apps.
5.3.1 Bounding the Number of Fragments and the Replayability
of Traces. We measured the correlation between the bound on the
number of fragments and the possibility of finding a replayabletrace using ten different bounds on
k(1â‰¤kâ‰¤10). For each k,
we constructed 200 random traces by combining ktrace fragments
fromthetestsuiteafterphase1.Furthermore,werestrictedeach
tracetocontainonly20transitions.Inordertoconstructthetraces,
wefirstcollectedatmost20,000tracessatisfyingtherequirement
usingbreadth-firstsearchofthetransitionsystem QTr(describedin
section3.2).Notethatthepathsof QTrconsistoftracesthatcanbe
452
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. DetReduce: Minimizing Android GUI Test Suites for Regression Testing ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Table 2: Test suite reduction result using DetReduce on SwiftHand traces
appinitial test suites phase 1 phase 2 running time in hours
#br #sc #act #tr #br #sc #act #tr #br #sc #act #tr t p1tp2trtr/t
acar 4427 171 13478 822 4427 171 1808 170 4427 171 1283 121 11.86 8.31 0.90 11.22%
amemo 2955 114 13604 835 2955 114 1380 135 2955 114 1030 101 11 8.03 0.72 9.06%amoney 4481 159 13213 779 4481 159 2793 269 4462 157 1595 146 11.27 12.07 1.14 14.21%astrid 6201 170 10532 680 6201 170 1828 188 6201 170 1168 120 15.95 9.20 1.07 13.32%cnote 5089 102 13584 157 5089 102 1515 156 5089 102 1083 117 12.3 7.84 1.09 13.61%dmoney 2387 47 13511 785 2387 47 728 74 2387 47 574 63 5.9 3.53 0.43 5.45%emobile 1554 214 13261 782 1554 214 1593 179 1554 214 1224 137 10.2 8.49 0.95 11.89%explore 6647 105 7559 703 6647 105 1458 153 6596 103 867 92 19.35 10.57 1.07 13.42%mileage 1766 81 13570 809 1766 81 507 61 1766 81 402 46 4.43 4.14 0.31 3.84%
mnote 889 76 13697 1003 889 76 988 96 889 76 718 71 9.14 7.59 0.47 5.92%
monefy 4966 62 13703 806 4966 62 2001 121 4966 62 1331 85 11.32 10.98 0.80 9.98%sanity 978 186 12735 764 978 186 1639 142 978 186 1045 94 13.59 10.39 0.76 9.54%tippy 712 15 14200 819 712 15 294 32 712 15 198 23 13.28 7.18 0.15 1.83%todo 1415 58 10164 641 1415 58 735 82 1415 58 520 57 5.96 3.96 0.50 6.38%ttable 2651 125 13028 1516 2651 125 1385 152 2251 125 891 97 9.71 10.25 0.53 6.36%vlc 2341 60 11978 770 2341 60 719 76 2279 59 440 45 5.89 3.83 0.35 4.41%whohas 230 15 12857 757 230 15 179 20 230 15 119 12 1.26 1.14 0.09 1.14%xmp 2079 50 11326 761 2079 50 617 64 2079 50 342 34 3.98 2.27 0.28 3.53%
median 2333 91.5 13237 780.5 2333 91.5 1384 128 2333 91.5 879 88.5 9.96 7.92 0.63 7.84%
Table3:TestreductionresultusingDetReduceonRandom
traces. Coverage results for DetReduce are omitted, since
DetReduceonlymissed0.8%ofbranchesand4screensfor
amoney.
appinitial test suites phase 1 phase 2 running time in hours
#br #sc #act #tr #act #tr #act #tr t p1tp2trtr/t
acar 2897 102 6990 2162 943 96 719 70 6.07 4.85 0.54 6.70%
amemo 2663 99 11680 1358 1072 108 768 74 10.06 5.4 0.48 6.03%amoney 3285 110 10290 1406 921 88 671 66 6.81 4.61 0.42 5.32%astrid 4797 112 7297 954 1095 115 760 79 17.01 6.38 0.66 8.22%cnote 5000 88 12909 1140 1252 123 885 82 11.95 9.26 0.56 7.00%dmoney 2057 46 7202 577 567 59 435 45 5.47 2.95 0.44 5.44%emobile 1359 195 10500 847 1276 153 978 121 10.99 7.07 0.90 11.20%explore 6145 76 5960 747 913 86 604 55 9.54 9.51 0.70 8.75%
mileage 1722 80 7013 670 530 60 344 44 4.74 3.19 0.39 4.84%
mnote 909 65 9559 1087 824 82 636 59 8.32 4.57 0.48 5.94%monefy 3549 36 11435 970 1449 78 622 37 10.57 2.42 0.38 4.78%sanity 701 110 8778 1350 706 66 433 42 4.64 3.84 0.31 3.93%tippy 686 15 10999 1057 269 28 174 19 1.63 1.14 0.13 1.68%todo 1312 39 7873 975 557 76 317 38 6.58 5.57 0.57 7.12%ttable 2589 100 9242 1125 1034 114 730 71 17.56 14.48 0.32 3.96%vlc 2001 44 7706 922 528 62 316 33 5.53 3.73 0.32 4.00%whohas 206 16 7879 1179 141 19 81 11 1.2 0.75 0.08 0.98%
xmp 1798 45 9734 844 566 48 318 27 5.25 2,31 0.26 3.24%
median 2029 78 9269 1016 868 80 613 50 6.29 4.59 0.43 5.38%
Table 4: The frequency of replayable traces.
app#replayable traces (out of 200 samples per app and k)
k=1 k=2 k=3 k=4 k=5 k=6 k=7 k=8 k=9 k=10
acar 195 159 119 96 94 80 70 47 54 47
astrid 189 108 93 64 51 41 22 16 19 14cnote 186 117 77 73 53 31 22 31 16 11emobile 199 169 139 116 96 93 62 41 50 57
constructedviasplicing.Wethensampled200tracesfromthesetof
20,000 traces. Finally, we checked how many of the sampled traces
are replayable by executing each trace ten times. Table 4 shows
the results. The first column shows the name of the app and the
rest of the columns show the number of replayable traces for each
k. Our hypothesis was that increasing the number of fragments
would decrease the possibility of finding replayable traces, and the
results confirm this hypothesis for the four apps.
5.3.2 Number of Fragments in Traces Generated by Splicing.
Even if traces containing many trace fragments tend to be non-
replayable, we would not need to bound the number of fragments
during phase 2 of DetReduce if most of the traces that can beTable 5: The frequency of traces composed of kfragments.
app#traces composed of kfragments (out of 1000 samples per app)
k=1 k=2 k=3 k=4 k=5 k=6 k=7 k=8 k=9 k=10+
acar 25 14 22 28 37 24 42 48 73 689
astrid 29 3 15 16 10 13 23 38 70 783cnote 12 4 11 2 7 8 10 6 13 927emobile 25 16 20 23 24 59 33 59 88 685
constructed from QTrcontain a small number of fragments. Our
hypothesis was that, without a proper bound, a significant num-
beroftracesgeneratedfrom QTrwouldcontainmanytracefrag-
ments,makingthemnon-replayablewithhighprobability.There-
fore, phase 2 of DetReduce would spend considerable amount of
timecheckingthe replayabilityofnon-replayabletraces. Inorder
tovalidatethishypothesis,weconstructed1000tracescomposed
of at most 20 transitions by sampling random paths from QTr, and
checked the number of trace fragments in each sampled trace.
Table5showstheresults.Thefirstcolumnshowsthenameof
theappandtherestofthecolumnsshowsthenumberoftracescom-
posed ofkfragments for each kbetween 1 to 10. The results show
that there are many more traces composed of a large number of
fragmentsthantracescomposedoffewerfragments.Consequently,
if we perform splicing without bounding the number of fragments,
we are more likely to get traces composed of a large number of
fragments. Theresults ofthe previous experiment(Section 5.3.1)
suggestthatsuchtracesarelikelytobenon-replayable.Thisvali-
datesourhypothesisthat phase2of DetReducewillnotscaleif
the number of trace fragments is unbounded.
5.4 Threats to Validity
WeusedalimitednumberofbenchmarkappstoevaluateDetRe-
duce, so it is possible that our results to not generalize. To address
thisissue,wecarefullyselectedthebenchmarkapps,andthedetails
of the selection process are explained in Section 5.1.1.
The selectionof thetest generationalgorithms could potentially
biastheevaluationresults.Specifically,theresultsobtainedfrom
a single algorithm cannot determine whether the results can be
generalized to the other test generation algorithms. To address this
issue, we used both SwiftHand and Random algorithm. We could
not use Monkey because it cannot generate replayable traces, as
explainedinSection5.1.3.TheresultsobtainedusingRandomshow
453
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden Wontae Choi, Koushik Sen, George Necula, and Wenyu Wang
thatDetReduceisnotanartifactthatonlyworkswithSwiftHand.
However, the results arestill not strong enoughto decisively con-
clude that DetReduce can effectively reduce test suites generated
from an arbitrary test generation tool.
Finally, in the evaluation, we checked whether the exceptions
raised by the original test suites are also raised by the test suites
reduced by DetReduce. However, this is a limited evaluation. A
morerobustevaluationwouldinvolveinjectingartificialfaultsinto
thebenchmark appsandmeasuringthe numberofinjectedfaults
detected before and after thetest suite reduction. We did not take
thisapproachbecauseofthedifficultyofinjectingfaultsintothe
binary of an Android app.
6 RELATED WORK
GUI test minimization. ND3MIN[ 7]isthemostcloselyrelated
worktoourresearch.ItisaGUItestminimizationalgorithmforAn-
droidapps,basedondelta-debugging[ 48].WecompareND3MIN
and DetReduce in three aspects: a) They have different goals:
ND3MINaimstominimizeeachtestcaseinisolationwhilekeep-
ing the final activity. DetReduce tries to minimize a whole testsuite while keeping the branch and screen coverage of the test
suite.b)Handlingnon-determinism:ND3MINaimstotoleratenon-
deterministic behaviors occurringduring theexecution of anapp.
Onthecontrary,DetReduceisdesignedtoactivelydetectandavoid
non-deterministic behaviors during the process of minimization. c)
Runningtime:ND3MINisavariationofdelta-debugging,whose
worstcasetimecomplexityisO( n2)wherenisthesizeofinputtest
case [48]. This could make the algorithm fail to scale since the cost
ofperformingeachtestrunisexpensiveinGUItesting.ND3MIN
usesupto50hourstominimizeatestcasecomposedof500actions.
DetReduceiscapableofhandlingatestsuitecomposedofmore
than10,000transitionsinlessthan30hours.Wecouldnotperform
an empirical comparison because the implementation of ND3MIN
was not available to us.
Hammoudietal .[17]alsoproposedadelta-debuggingbasedtest
minimization algorithm. Unlike ND3MIN and DetReduce, their
work aims to minimize manually written test cases for web ap-
plications. Their results showed that the execution time of theminimized test cases are on average 22% shorter than that of the
original test cases. This shows that there is room to minimize even
manually written test cases. Since they used relatively small testcases composed of less than 150 actions, it is hard to say if their
delta-debugging approach would scale on a large GUI test case.
Testminimizationingeneral. Testsuitereductiontechniques[ 18,
19,21,22,24,30,41,42,46,50] automatically reduce the size of a
testsuite withoutlosing thecoverage ofthe testsuite. Unlikeour
work, these techniques assume that test suites consist of already
compactedtestcases;thesetechniquesdonotfocusonreducingthesizeofeachtestcase.Theyonlyfocusonselectingasmallsetoftestcasesfromatestsuite.Thefirstpartofthefirstphaseof DetReduce,
where we remove redundant traces, can be seen as a test suite
reductiontechnique.InthecontextofGUItesting,McMasterand
Memon[30]proposed call-stack history as a metric for reducing
GUI test suites. We might be able to reduce more redundant traces
byadoptingthistechnique.However,itispossiblethatremovingtoo many traces at the first phase of DetReduce might negatively
affect the capability of the second phase of DetReduce.
Delta-debugging[ 47,48]isprobablythemostwidely-knowntest
minimizationtechnique.Wefounditdifficulttousedelta-debugging
to minimize a large GUI test suite because of the cost of running
thetestsuite.Itisoftenpossibletoacceleratedelta-debuggingby
exploiting domain specific knowledge. For example, hierarchicaldelta-debugging (HDD) [
35] works on structured texts, such as
XML, by first performing delta-debugging on top-level structures,
then gradually moving into substructures. This allows HDD tosignificantly reduce the time required to reduce structured texts
compared to the original delta-debugging. A similar idea has been
usedinDEMi[ 40]tominimizetestcasesforadistributedsystem.
However, we have yet to find a way to make delta-debugging scale
better on GUI test suites.
Prior to our work, Groce et al . [15]proposed cause-reduction, a
test reduction technique combining delta-debugging and greedy
test-caseselection.Therearetwonotabledifferencesbetweencause-
reduction and DetReduce. First, cause-reduction is comparable to
phase 1 of DetReduce, and it does not have a component corre-
spondingtophase2.Second,cause-reductionusesdelta-debugging
as a component. On the contrary, DetReduce uses highly domain-
specific components such as loop-elimination and splicing.
AutomatedAndroidGUItestingtechniques. Inthispaperweused
SwiftHand[ 5]togeneratetestsuites.Onecanuseanyautomated
GUI testing technique, such as A3E [ 2], Dynodroid [ 26], AppsPlay-
ground [38], or MobiGUITAR [ 1], to generate initial test suites.
Onemayarguethattestminimizationmightnotbenecessaryin
the future if automated testing techniques continue to improve.
AutomatedGUItestingtechniquesareindeedbecomingbetterin
maximizingtestcoverageandfindingbugsinalimitedperiodof
time [8,28]. However, recent studies [ 17,46] suggest that even
test cases and test suites created by human experts need to be
compacted. Therefore, we predict that GUI test suite minimization
techniques will remain useful, even though automated GUI testing
techniques continue to improve.
Arecentsurvey[ 6]comparestheperformanceofseveralauto-
mated testing tools for Android apps. Their results suggest thatMonkey outperforms other more sophisticated tools in terms of
maximizing coverage in a limited period of time. However, we ob-
served that it is difficult to replay test cases generated by Monkey.
EvenifMonkeyfindsabug,itmightbedifficulttoreproducethebug
or minimize the sequence of actions obtained from Monkey [43].
GUI test scripts [ 13,14,39] and record-and-replay tools [ 10,
14,16,20,36]aremeanstogeneratereusabletestcasesreflecting
humanknowledge.Thesetoolscomplementourapproach.Onecanusethesetoolseithertogenerateasetoftestcasestobeminimized,
or to add more test cases to already minimized test suites.
ACKNOWLEDGMENTS
This research is supported in part by NSF grants CCF-1409872 and
CCF-1423645.
REFERENCES
[1]DomenicoAmalfitano,AnnaRitaFasolino,PorfirioTramontana,BryanDzung
Ta, and AtifM Memon. 2015. MobiGUITAR: Automated model-based testing of
mobile apps. IEEE Software 32, 5 (2015), 53â€“59.
454
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. DetReduce: Minimizing Android GUI Test Suites for Regression Testing ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
[2]TanzirulAzimandIulianNeamtiu.2013. Targetedanddepth-firstexploration
for systematic testing of Android apps. In ACM SIGPLAN Notices, Vol. 48. ACM,
641â€“660.
[3]Egon Balas. 1989. The prize collecting traveling salesman problem. Networks 19,
6 (1989), 621â€“636.
[4]Ravi Bhoraskar, Seungyeop Han, Jinseong Jeon, Tanzirul Azim, Shuo Chen,
Jaeyeon Jung, Suman Nath, Rui Wang, and David Wetherall. 2014. Brahmas-
tra:DrivingAppstoTesttheSecurityofThird-PartyComponents..In USENIX
Security. 1021â€“1036.
[5]Wontae Choi, George Necula, and Koushik Sen. 2013. Guided GUI testing of
Android apps with minimal restart and approximate learning. In ACM SIGPLAN
Notices, Vol. 48. ACM, 623â€“640.
[6]Shauvik Roy Choudhary, Alessandra Gorla, and Alessandro Orso. 2015. Auto-
mated test input generation for Android: Are we there yet?(e). In Automated
SoftwareEngineering(ASE),201530thIEEE/ACMInternationalConferenceon.IEEE,
429â€“440.
[7]Lazaro Clapp, Osbert Bastani, Saswat Anand, and Alex Aiken. 2016. Minimizing
GUI event traces. In Proceedings of the 2016 24th ACM SIGSOFT International
Symposium on Foundations of Software Engineering. ACM, 422â€“434.
[8]Markus Ermuth and Michael Pradel. 2016. Monkey see, monkey do: effective
generation of GUI tests with inferred macro events. In Proceedings of the 25th
International Symposium on Software Testing and Analysis. ACM, 82â€“93.
[9]Mattia Fazzini, Eduardo Noronha de A Freitas, Shauvik Roy Choudhary, and
Alessandro Orso. 2016. From Manual Android Tests to Automated and Platform
Independent Test Scripts. arXiv preprint arXiv:1608.03624 (2016).
[10]Lorenzo Gomez, Iulian Neamtiu, Tanzirul Azim, and Todd Millstein. 2013. Reran:
Timing-and touch-sensitive record and replay for Android. In Software Engineer-
ing (ICSE), 2013 35th International Conference on. IEEE, 72â€“81.
[11]Google Inc. 2008. Google Play. https://play.google.com/store?hl=en. (2008).
Accessed: 2017-04-11.
[12]GoogleInc.2008. UI/ApplicationExerciserMonkey. https://developer.android.
com/studio/test/monkey.html. (2008). Accessed: 2017-04-11.
[13]Google Inc. 2010. Monkeyrunner. https://developer.android.com/studio/test/
monkeyrunner/index.html. (2010). Accessed: 2017-04-11.
[14]Google Inc. 2011. Espresso. https://google.github.io/android-testing-support-library/docs/espresso/. (2011). Accessed: 2017-
04-11.
[15]Alex Groce, Mohammed Amin Alipour, Chaoqiang Zhang, Yang Chen, and John
Regehr. 2014. Cause reduction for quick testing. In Software Testing, Verification
and Validation (ICST), 2014 IEEE Seventh International Conference on. IEEE, 243â€“252.
[16]
MatthewHalpern,YuhaoZhu,RameshPeri,andVijayJanapaReddi.2015.Mosaic:
cross-platformuser-interactionrecordandreplayforthefragmentedAndroid
ecosystem.In PerformanceAnalysisofSystemsandSoftware(ISPASS),2015IEEE
International Symposium on. IEEE, 215â€“224.
[17]Mouna Hammoudi, Brian Burg, Gigon Bae, and Gregg Rothermel. 2015. On the
use of delta debugging to reduce recordings and facilitate debugging of webapplications. In Proceedings of the 2015 10th Joint Meeting on Foundations of
Software Engineering. ACM, 333â€“344.
[18]Dan Hao, Lu Zhang, Xingxia Wu, Hong Mei, and Gregg Rothermel. 2012. On-
demandtestsuitereduction.In Proceedingsofthe34thInternationalConference
on Software Engineering. IEEE Press, 738â€“748.
[19]Hwa-YouHsuandAlessandroOrso.2009. MINTS:Ageneralframeworkandtool
for supporting test-suite minimization. In Software Engineering, 2009. ICSE 2009.
IEEE 31st International Conference on. IEEE, 419â€“429.
[20]Yongjian Hu, Tanzirul Azim, and Iulian Neamtiu. 2015. Versatile yet lightweight
record-and-replay for Android. In ACM SIGPLAN Notices. ACM.
[21]Dennis Jeffrey and Neelam Gupta. 2005. Test suite reduction with selective
redundancy. In Software Maintenance, 2005. ICSMâ€™05. Proceedings of the 21st IEEE
International Conference on. IEEE, 549â€“558.
[22]Dennis Jeffrey and Neelam Gupta. 2007. Improving fault detection capability by
selectively retainingtest cases duringtest suite reduction. IEEE Transactionson
software Engineering 33, 2 (2007).
[23]CasperSJensen,MukulRPrasad,andAndersMÃ¸ller.2013. Automatedtesting
with targeted event sequence generation. In Proceedings of the 2013 International
Symposium on Software Testing and Analysis. ACM, 67â€“77.
[24]JamesAJones andMaryJeanHarrold.2003. Test-suite reductionandprioriti-
zationformodifiedcondition/decisioncoverage. IEEETransactionsonsoftware
Engineering 29, 3 (2003), 195â€“209.
[25]Chieh-Jan Mike Liang, Nicholas D Lane, Niels Brouwers, Li Zhang, BÃ¶rje F
Karlsson, Hao Liu, Yan Liu, Jun Tang, Xiang Shan, Ranveer Chandra, and others.
2014. Caiipa: Automated large-scale mobile app testing through contextual
fuzzing. In Proceedings of the 20th annual international conference on Mobile
computing and networking. ACM, 519â€“530.
[26]Aravind Machiry, Rohan Tahiliani, and Mayur Naik. 2013. Dynodroid: An inputgeneration system for Android apps. In Proceedings of the 2013 9th Joint Meeting
on Foundations of Software Engineering. ACM, 224â€“234.[27]RiyadhMahmood,NarimanMirzaei,andSamMalek.2014. Evodroid:Segmented
evolutionarytestingofAndroidapps.In Proceedingsofthe22ndACMSIGSOFT
InternationalSymposiumonFoundationsofSoftwareEngineering.ACM,599â€“609.
[28]KeMao,MarkHarman,andYueJia.2016.Sapienz:Multi-objectiveautomatedtest-
ing for Android applications. In Proceedings of the 25th International Symposium
on Software Testing and Analysis. ACM, 94â€“105.
[29]Leonardo Mariani, Mauro Pezze, Oliviero Riganelli, and Mauro Santoro. 2012.
Autoblacktest:Automaticblack-boxtestingofinteractiveapplications.In Software
Testing,VerificationandValidation(ICST),2012IEEEFifthInternationalConference
on. IEEE, 81â€“90.
[30]Scott McMaster and Atif Memon. 2008. Call-stack coverage for GUI test suite
reduction. IEEE Transactions on Software Engineering 34, 1 (2008), 99â€“115.
[31]AliMesbah,Arie Van Deursen,andStefanLenselink.2012. CrawlingAjax-based
webapplicationsthroughdynamicanalysisofuserinterfacestatechanges. ACM
Transactions on the Web (TWEB) 6, 1 (2012), 3.
[32]AminMilaniFard,MehdiMirzaaghaei,andAliMesbah.2014. Leveragingexisting
tests in automated test generation for web applications. In Proceedings of the
29thACM/IEEEinternationalconferenceonAutomatedsoftwareengineering.ACM,
67â€“78.
[33]Nariman Mirzaei, Hamid Bagheri, Riyadh Mahmood, and Sam Malek. 2015. Sig-
droid: Automated system input generation for Android applications. In Software
ReliabilityEngineering(ISSRE),2015IEEE26thInternationalSymposiumon .IEEE.
[34]NarimanMirzaei,JoshuaGarcia,HamidBagheri,AlirezaSadeghi,andSamMalek.
2016. ReducingcombinatoricsinGUItestingofAndroidapplications.In Proceed-
ings of the 38th International Conference on Software Engineering. ACM.
[35]Ghassan Misherghi and Zhendong Su. 2006. HDD: hierarchical delta debugging.
InProceedings of the 28th international conference on Software engineering. ACM,
142â€“151.
[36]Zhengrui Qin, Yutao Tang, Ed Novak, and Qun Li. 2016. Mobiplay: A remote
execution based record-and-replay tool for mobile applications. In Proceedings of
the 38th International Conference on Software Engineering. ACM, 571â€“582.
[37]SiegfriedRasthofer,StevenArzt,StefanTriller,andMichaelPradel.2017. Making
Malory Behave Maliciously: Targeted Fuzzing of Android Execution Environ-
ments. In Proceedings of the 39th International Conference on So ware Engineering.
ACM. To appear.
[38]VaibhavRastogi,YanChen,andWilliamEnck.2013. AppsPlayground:automatic
security analysis of smartphone applications. In Proceedings of the third ACM
conference on Data and application security and privacy. ACM, 209â€“220.
[39]RenasReda.2010. Robotium,UserscenariotestingforAndroid. https://github.
com/RobotiumTech/robotium. (2010). Accessed: 2017-04-11.
[40]Colin Scott, Andreas Wundsam, Barath Raghavan, Aurojit Panda, Andrew Or,
Jefferson Lai, Eugene Huang, Zhi Liu, Ahmed El-Hassany, Sam Whitlock, and
others. 2015. Troubleshooting blackbox SDN control software with minimal
causal sequences. ACM SIGCOMM Computer Communication Review 44, 4 (2015),
395â€“406.
[41]August Shi, Alex Gyori, Milos Gligoric, Andrey Zaytsev, and Darko Marinov.
2014. Balancingtrade-offsintest-suitereduction.In Proceedingsofthe22ndACM
SIGSOFT International Symposium on Foundations of Software Engineering. ACM,
246â€“256.
[42]August Shi, Tifany Yung, Alex Gyori, and Darko Marinov. 2015. Comparing and
combiningtest-suitereductionandregressiontestselection.In Proceedingsofthe
201510thJointMeetingonFoundationsofSoftwareEngineering.ACM,237â€“247.
[43]StackOverFlow. 2014. Stack Overflow: what would bethe base optimal throttle and seed for an application us-ing monkey test? http://stackoverflow.com/questions/9778881/
what-would-be-the-base-optimal-throttle-and-seed-for-an-application-using-monkey.
(2014). Accessed: 2017-04-14.
[44]ShengqianYang,DacongYan,HaoweiWu,YanWang,andAtanasRountev.2015.
Static control-flow analysis of user-driven callbacks in Android applications. In
Software Engineering(ICSE), 2015 IEEE/ACM 37thIEEE International Conference
on, Vol. 1. IEEE, 89â€“99.
[45]WeiYang,MukulRPrasad,andTaoXie.2013. Agrey-boxapproachforautomated
GUI-model generation of mobile applications. In International Conference on
Fundamental Approaches to Software Engineering. Springer, 250â€“265.
[46]Shin Yoo and Mark Harman. 2012. Regression testing minimization, selection
and prioritization: a survey. Software Testing, Verification and Reliability 22, 2
(2012), 67â€“120.
[47]Andreas Zeller. 1999. Yesterday, my program worked. Today, it does not. Why?.
InSoftware EngineeringÃ¢Ä‚Å¤ESEC/FSEÃ¢Ä‚Å¹99. Springer, 253â€“267.
[48]Andreas Zeller and Ralf Hildebrandt. 2002. Simplifying and isolating failure-
inducing input. IEEE Transactions on Software Engineering 28, 2 (2002), 183â€“200.
[49]HailongZhang,HaoweiWu,andAtanasRountev.2016. Automatedtestgener-
ationfordetectionofleaksinAndroidapplications.In AutomationofSoftware
Test (AST), 2016 IEEE/ACM 11th International Workshop in. IEEE, 64â€“70.
[50]Hao Zhong, Lu Zhang, and Hong Mei. 2008. An experimental study of four
typical test suite reduction techniques. Information and Software Technology 50,
6 (2008), 534â€“546.
455
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. 