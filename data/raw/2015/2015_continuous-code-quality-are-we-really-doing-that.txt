Continuous Code Quality: Are We (Really) Doing That?
Carmine Vassallo
University of Zurich
Zurich, Switzerland
vassallo@ifi.uzh.chFabio Palomba
University of Zurich
Zurich, Switzerland
palomba@ifi.uzh.ch
Alberto Bacchelli
University of Zurich
Zurich, Switzerland
bacchelli@ifi.uzh.chHarald C. Gall
University of Zurich
Zurich, Switzerland
gall@ifi.uzh.ch
ABSTRACT
Continuous Integration (CI) is a software engineering practice
where developers constantly integrate their changes to a project
throughanautomatedbuildprocess.ThegoalofCIistoprovide
developers with prompt feedback on several quality dimensions
aftereachchange.Indeed,previousstudiesprovidedempiricalev-
idence on a positive association between properly following CI
principles and source code quality. A core principle behind CI is
Continuous Code Quality (alsoknownasCCQ,whichincludesauto-
mated testing andautomated code inspection) mayappear simple
andeffective,yetweknowlittleaboutitspracticaladoption.Inthis
paper,weproposeapreliminaryempiricalinvestigationaimedat
understandinghowrigorouslypractitionersfollowCCQ.Ourstudy
revealsastrongdichotomybetweentheoryandpractice:develop-
ers do not perform continuous inspection but rather control for
qualityonlyattheendofasprintandmostofthetimesonlyonthe
release branch. Preprint [https://doi.org/10.5281/zenodo.1341036].
Data and Materials [http://doi.org/10.5281/zenodo.1341015].
CCS CONCEPTS
•Software and its engineering →Maintaining software ;
KEYWORDS
Continuous Integration, Code Quality, Empirical Studies
ACM Reference Format:
Carmine Vassallo, Fabio Palomba, Alberto Bacchelli, and Harald C. Gall.
2018.ContinuousCodeQuality:AreWe(Really)DoingThat?.In Proceedings
of the 2018 33rd ACM/IEEE International Conference on Automated Software
Engineering (ASE ’18), September 3–7, 2018, Montpellier, France. ACM,New
York, NY, USA, 6pages.https://doi.org/10.1145/3238147.3240729
1 INTRODUCTION
“Improving software quality and reducing risks” [ 8]. This is how
Continuous Integration (CI) has been put forward by Duvall et
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3240729al. [8] and is widely perceived by developers and students [ 22].
Concretely,CIisanagilesoftwaredevelopmentprocessaimedat
continuouslyintegratingchangesmadebydevelopersworkingona
sharedrepository;abuildserverthatisusedtobuildeverycommit,
run all tests, and assess source code quality [15].
Duvalletal.[ 8]haveproposedasetofprinciplesthatdevelop-
ersshouldmethodicallyfollowtoadoptCI.Forinstance,CIusers
shouldbuildsoftwareassoonasanewchangetothecodebaseis
performed, instead of building software at certain scheduled times
(e.g.,nightlybuilds).AkeyprincipleofCI,asadvocatedbyDuvallet
al. [8], iscontinuous inspection, which includes running automated
testsandperformingstatic/dynamicanalysisofthecodeatevery
build, as a way to ensure code quality. This aspect of CI is also
known as Continuous Code Quality (CCQ) [28].
PreviousworkprovidedevidenceonthepotentialofCIinachiev-
ing its stated goals. Vasilescu et al. [ 35] quantitatively explored the
effectofintroducingCIonthequalityofthepullrequestprocess,
finding that it improves the number of processed pull requests.Khohm et al. [
17] studied whether and how shifting toward a
shorterreleaseworkflow(i.e.,monthlyreleases)hadaneffectonthe
software quality of Firefox, reporting significant benefits. Othersfound evidence of reduced time-to-market associated with CI [
39]
and the possibility to catch software defects earlier [14].
However,empiricalknowledgeisstilllackingontheactualprac-
ticeofCCQ:HowstrictlydopractitionersadoptCCQ?Whatare
theeffectsresultingfrompractitioners’approachtoCCQ?Toscien-tificallyevaluateCCQanditseffects,aswellastohelppractitioners
in their software quality efforts, one has to first understand and
quantifycurrentdevelopers’practices.Infact,anupdatedempirical
knowledge on CCQ is paramount both to focus future research on
the most relevant aspects of CCQ and on current problems in CI
adoption,as wellasto effectivelyguide thedesignof toolsand pro-
cesses. To this aim, we conduct a large-scale analysis that involves
atotalof148,734buildsand5yearsofthedevelopmentchangehis-
toryof119JavaprojectsminedbySonarCloudandTravisCI,two
well-knownprovidersofcontinuouscodequalityandcontinuous
integrationdata,respectively.Westudytheadoptionofcontinuous
codequalitybymeasuringmetricslikethenumberofbuildssubject
to quality checks and frequency of the measurements.
Ourfindingsrevealthatonly11%ofthebuildsaresubjecttoa
code quality check and that practitioners do not apply CCQ, rather
runmonitoringtoolsjustattheendofasprint.Moreover,only36%
of branches are checked.
790
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:28:00 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Carmine Vassallo, Fabio Palomba, Alberto Bacchelli, and Harald C. Gall
2 BACKGROUND AND RELATED WORK
This section provides an overview of the principles behind contin-
uous code quality as well as the related literature.
2.1 Continuous Code Quality
There are a few basic principles at the basis of continuous inte-
gration [8]. Besides maintaining a single source code repository,
the idea behind CI is to automate the correct integration of code
changesappliedbydevelopersasmuchaspossible.Thisisnormally
obtained by having a dedicated build server responsible for taking
all the new commits as input and automatically build, test, and
deploy them. In addition, code quality assessment tools are used
inordertocontrolhowmuchtheperformedchangerespectsthe
qualitativestandardsoftheorganization.Thus,theprincipleof con-
tinuous code quality translates into having a development pipeline
composed of a repository, a CI build server, and a CCQ Service.
The developer commits a change to a repository (e.g., hosted on
GitHub [ 12]), triggering a new build on the CI build server (e.g.,
TravisCI[ 31]).Theservertransfersthechangetoadifferentserver
(called CCQ Service ) that is in charge of performing the quality
analyses and reporting back the outcome to the CI build server.
Based on its configuration, the CI build server decides on whether
the build fails depending on the results of the CCQ service.
CI build server users can configure the build in a customized
way,e.g.,sendingonlyspecificbuildsorbuildsonspecificbranches
to the CCQ service for inspection. This configuration allows users
to depart from the continuous quality practice as prescribed [ 8]
andto followadifferent strategy.The decisiontodepart fromthe
prescribedCCQpracticeisatthebasisofourwork,whichisfocused
on a deeper understanding of the actual CCQ practices.
2.2 Related Work
Inthelastyears,researchershaveproposedagrowingnumberof
studies targeting CI practices [ 2,38,39], also thanks to the increas-
ing availability of publicly available CI data [3].
Hiltonetal.[ 14]employedamixed-methodapproachtostudy
the use of CI in open-source projects. They first mined the change
history of 34,544 systems, finding that CI is already adopted by the
mostpopularprojectsandthattheoverallpercentageofprojects
usingCIisgrowingfast.Inthesecondplace,theresearcherssur-
veyed 442 developers on the perceived benefits of CI. The main
perceived advantage is that CI helps projects release more often.
Hilton et al. [ 13] proposed a qualitative study targeting the bar-
riers developers face when using CI. The study comprised twosurveys with 574 industrial developers, with the main findingspresenting the trade-offs between (i) speed and certainty, (ii) in-
formationaccessandsecurity,and(iii)configurationoptionsand
usability. The authors motivated the need for new methods andtoolsabletofindacompromisebetweenthoseperspectives.Theresults discussed so far were also confirmed by Laukkanen et al.[
21] and Kim et al. [ 18], who reported on industrial experiences
when using CI.
Complementing the studies mentioned above, our investigation
aims at understanding how rigorously developers adopt CCQ.
Other researchers investigated the use of automated static anal-
ysistools(knowasASATs)inCI.Specifically,Zampettietal.[ 40]observed that a low number of builds fail because of warnings
raisedbyASATs,whileVassalloetal.[ 37]reportedthatdevelopers
configuredstaticanalysistoolsonlyatthebeginningofaproject.
OurstudyfurtherelaboratesonhowdevelopersuseASATsinCI,
by exploring how they use them in order to perform CCQ.
3 OVERVIEW OF THE RESEARCH
METHODOLOGY
As Duvall et al. stated in previous work [ 8], the time between
discoveryandfixofcodequalityissuescanbesignificantlyreduced
bycontinuouslyinspectingthecode.Thus,theapplicationofthecontinuous inspection principleisstatedtobecrucialforfulfilling
the main advantage of CI, i.e., “improving software quality and
reducing risks" [8].
The goalof the study is to quantify the gap (if any) between
thecontinuous inspection principle (also known as continuous code
quality[28])andtheactualpracticesappliedbydeveloperswiththe
purposeof providing initial guidelines and tools for future research
in the field of continuous integration. Thus, our investigation isstructured around one research question: how is CCQ applied to
projects in CI?.
The perspective is of researchers and practitioners interested
in understanding whether code quality assessment is performed
continuously in CI.
In order to answer our research question and guide future re-
searchonCCQpractice,wefirstneedtoconstructadatasetcon-
taining projects developed through a CCQ pipeline. The contextof
our study consists of such a dataset, which includes 119 projects
selected as reported in Section 4.3.
Then, we devise a set of CCQ metrics for assessing the actual
CCQ adoption (described in Section 5.1) and measure them over
the history of the projects in our dataset (Section 5.2).
4 CONTINUOUS CODE QUALITY DATA
COLLECTION
To conduct our investigation, we need to study projects that not
only use CI, but also: (i) adopt a CCQ pipeline, (ii) adopt a static
analysis tool that stores the quality measurements performed over
theirhistory,and(iii)haveCI-relatedeventsavailable,sothatwe
can contextualize CCQ measurements in their evolution.
Sinceanalreadybuiltdatasetthatfulfillsourcriteriaisnotavail-
able, we build our own. The definition of an ad-hoc data collection
strategy is necessary because CCQ and CI events are stored on
different servers and the alignment of the CCQ change history
overthechangehistoryrecordingalltheeventsoccurredontheCI
build server required the definition of heuristics to properly match
the two sources. In the next sections, we describe the procedure
we follow to build the dataset, which is composed of three main
steps such as (i) collecting data from the CCQ server, (ii) collecting
data fromthe CI buildserver, and(iii) aligning thechange history
coming from the two sources.
791
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:28:00 UTC from IEEE Xplore.  Restrictions apply. Continuous Code Quality: Are We (Really) Doing That? ASE ’18, September 3–7, 2018, Montpellier, France
4.1 Collecting CCQ Data
SonarCloud1is a cloud service based on SonarQube [ 28] that
continuouslyinspectscodequalityanddetectsbugs,vulnerabilities,
andcodesmells.SonarQubeisoneofthemostwidelyadoptedcodeanalysistoolsinthecontextofCI[
28].SonarQubeisaSonarSource
productthatisadoptedbymorethan85,000organizationsandthat
support more than 20 languages—including the most popular ones
accordingtotheTIOBEindex[ 30].SonarQubeprovidesdevelopers
with its own rules and incorporates rules of other popular static
and dynamic code analysis tools [ 28]. As an example, SonarQube
runs all the most popular code analysis tools (i.e., CheckStyle,PMD, Findbugs, Cobertura) by default on Java projects. Thus,the relevance of SonarQube in the context of CI motivates the
decision to focus on systems using SonarCloud as CCQ service.
Overall, 14,152 projects are actively using SonarCloud, even
thoughsomeofthemareprivateand,thus,notaccessible.Wequery
SonarCloud using the available web APIs [ 27] and extract the list
of all the open source projects that use the free analysis service,
reaching 1,772 candidate systems2.
4.2 Collecting CI Data
Starting from the initial population of 1,772 candidate systems, we
keepprojectsthatuseTravisCIasbuildserver[ 31],asthisensures
thattheprojectactuallyadoptsaCCQpractice.WeselectTravisCI
as it provides the entire build history, as opposed to other buildservers (e.g., Jenkins) where only the recent builds are typically
stored [35].
SelectingprojectsusingTravisCIasCIserverandSonarCloud
as CCQ service is not trivial. While TravisCI provides a direct
andeasyintegrationwithSonarCloud3,thereisnoexplicitlink
betweenthosetwoservices,meaningthatonecannotdirectlyin-
fer which projects use both services at the same time. Thus, weneed to create such a link. Among the information available on
SonarCloud,theprojectsreporttheURLreferringtothesource
code repository; this URL provides us with an exploitable solution
toidentifythedesiredsystems.Inparticular,TravisCIisusedto
build projects hosted on GitHub: therefore, we first consider all
the projects available on SonarCloud that expose a GitHub URL.
This step reduces the number of candidate projects to 439 (i.e., 25%
of all SonarCloud systems). Subsequently, using the GitHub URL
we query the TravisCI APIs [ 32] and check if a certain URL is
presentontheplatform:390projectsmatchtheselectioncriteria,
i.e., SonarCloud systems that are on TravisCI. As a final step, we
removeprojectshavinglessthan20CCQchecksovertheirhistory4.
This filter is needed to avoid the analysis of projects that do not
really integrate a CCQ service in their pipeline; in other words, we
onlyconsider projectsthat activelyapplyCCQ.Atthe endofthis
process, our dataset comprises 119 projects.
4.3 Overlaying CCQ and CI Information
Once the explicit link between SonarCloud and TravisCI is avail-
able,thefinalstepofthedatacollectionprocessistooverlaythe
1https://about.sonarcloud.io
2The complete list is available in our online appendix [36].
3https://docs.travis-ci.com/user/sonarcloud/
4The threshold of 20 is fixed in a similar way as done in previous work [6, 16,24].separate change history information available in two sources. Also,
inthiscase,thereisnoexplicitwaytolinkadatapointavailable
SonarCloudtooneonTravisCI.Wesolvethisasinthefollowing.For each of the 148734 builds available on TravisCI we first collect
(i)build id , (ii) triggering commit (i.e., commit message and
id),(iii) build status (i.e.,failed,errored,passed),(iv) starting
date,and(v) ending date .Then,weusethe starting date pa-
rameter of the build to identify the corresponding data point on
SonarCloud.
Specifically,let bi∈Tibeabuilddoneonthebranch brintheCI
historyTiof the project iavailable on TravisCI, and let mik∈Sik
beameasurementofacertainmetric kforproject ionthebranch br
in the CCQ history Hikavailable on SonarCloud, we considered
mikto be the measurement corresponding to biif the following
relation held:
date (mik)≥startinдDate (bi)
∧date (mik)≤startinдDate (bi+1)
In other words, for each of the 119 considered projects, we com-
pute the time interval in which two subsequent builds (i.e., biand
bi+1) are performed on TravisCI and assign a quality measure-
ment to the build biif it was started within that time window. For
eachconsideredproject,thefinalresultisan overlaid change his-
tory,whichcontainsinformationaboutthemeasuredmetric(s)and
value(s), for each measured build (i.e., a build subject to a measure-
ment on SonarCloud).
5 CONTINUOUS CODE QUALITY IN
PRACTICE
Inthissection,wediscusshowcontinuouscodequalityisappliedin
the selected projects. Specifically, we first present the CCQ metrics
thatweconceivetoautomaticallyassesstheCCQpractice.Then,
weshowhowourprojectsperformagainsttheCCQmetricsover
their development’s history.
5.1 Definition of CCQ Metrics
Our study aims at assessing the practical use of CCQ. Based on the
constructed overlaid change history of the 119 subject projects, we
devise four indicators for measuring the actual CCQ usage:
CQCR – Code Quality Checking Rate : Number of builds sub-
ject to a code quality check divided by the total number of builds.
EFC – Elapsed Frame between Checks : Average number of
builds between two builds subject to a code quality check.
ETC –ElapsedTimebetweenChecks :Averagenumberofdays
between two builds subject to a code quality check.
CB – Percentage of Checked Branches : Number of branches
containingatleastonebuildsubjecttoacodequalitycheckdivided
by the number of total branches scheduled for build.
We design these CCQ usage indicators (based on the guidelines
byDuvalletal.[ 9])tounderstandhowwellCCQisperformedfrom
different perspectives. CQCR is the basic metric that reveals the
fractionofbuildsthatarequalitativelymeasuredduringthehistory
of a project, thus giving a view on the extent to which developers
use to check builds in their projects. EFC and ETC measure the
frequencyofthequalitychecksintheconsideredprojects,interms
792
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:28:00 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Carmine Vassallo, Fabio Palomba, Alberto Bacchelli, and Harald C. Gall
Table 1: CCQ usage indicators applied to our projects.
Project Set CCQ Usage Indicators
Feature Level # projects CQCR EFC ETC CB
AgeLow 30 0.14 7.72 14.49 0.62
Medium 58 0.17 10.86 18.33 0.25
High 30 0.06 39.08 16.49 0.33
ContributionLow 27 0.14 8.99 16.67 0.39
Medium 61 0.12 9.74 16.69 0.41
High 30 0.05 36.76 17.33 0.22
PopularityLow 30 0.14 9.42 15.63 0.49
Medium 58 0.12 10.61 15.47 0.33High 30 0.06 37.34 20.20 0.27
Overall 0.11 18.30 16.91 0.36
of the average number of builds and days, respectively, that are
waitedbeforeperforminganewqualitycheck.CBindicatesifthere
are branches that are not checked at all: in this case, we want tomeasure whether there are branches that are more prone to be
subject of qualitative checks.
5.2 On the Current Application of CCQ
Table1reports the results of our study aimed at investigating how
CCQisappliedinpractice.Thetablereportstheoverallvalues(row
“Overall”)ofeachconsideredmetric,i.e., Code Quality Checking Rate
(CQCR), Elapsed Frame between Checks (EFC), Elapsed Time between
Checks (ETC),and Percentage of Checked Branches (CB).Moreover,
withtheaimofdeeperunderstandingwhetherthecharacteristicsof
the projects influence our observations, we also report the overall
metric values when splitting the systems by age, contribution, and
popularity.
WeexploittheGitHubAPIs[ 12]toidentify(i)thenumberof
performed commits, (ii) the number of contributors, and (iii) thenumbers of stars of a certain repository, respectively. For each
considered perspective (i.e., age, contribution, and popularity), we
split projects into three different subsets, i.e., low, medium, and
high. Specifically, we calculate the first (Q 1) and the third (Q 3)
quartile of the distribution representing the number of commits,
contributors, and stars of the subject systems. Then, we classify
themintothefollowingcategories:(i) lowiftheyhaveanumberof
commits/contributors/stars nlower than Q 1; (ii) mediumifQ1≤
n<Q3, and (iii) highifnis higher than Q 3. As shown in Table 1
(column “# projects”), we inadvertently achieved a good balance
amongthedifferentsubsetsintermsofthenumberofcontained
projects.
Looking at the results, we can first observe that, overall, only
11%ofthebuildsarequalitativelychecked(CQCRvalue).Thisis
aquitesurprisingresult,becauseitclearlyindicatesthatprojects
arenotcontinuously inspected. In the lights of this finding, we
canclaimthatthe continuous inspection principleisgenerallynot
respected in practice.
When considering projects split by categories, i.e., low, medium,
andhighforage,contribution,andpopularity,wecanperceivea
trend in the results. Young and medium-age projects exhibit higher
values for CQCR with respect to the more mature projects, yet still
have a pretty low percentage of monitored builds (14% and 17%,respectively). This finding seems to suggest that the application of
CCQbecomesevenharderwhenincreasingthenumberofcommits,
andconsequentlythenumberofbuildsofasoftwareproject.We
findthatonly6%ofthebuildspassforaqualitycheckinlong-lived
systems, while the percentage is 5% in case of an high number
ofcontributors.ThisresulttriangulatesthefindingsbyHiltonetal. [
14], revealing that developers are still not very familiar with
all the CI principles and tend to not apply them properly. At the
sametime,itseemsthatcommunity-relatedfactorsplayarolein
theapplicationofCCQ.Indeed,ourfindingssuggestthatcommu-
nitieswithalargenumberofcontributorsarelesspronetoapply
CCQ: this is in line with previous work that showed how largecommunities generally have more coordination/communication
issues, possibly resulting in technical pitfalls [5, 11,29].
The most popular projects are generally more likely to use
CI[14],however—accordingtoourresults—theydonotapplyCCQ
properly. This isvisible in Table 1, wherewe observe that only 6%
ofthebuildsofpopularprojectsarequalitativelymonitored.Con-
versely, low and medium-popular systems exhibit a higher number
of measured builds.
Finding 1. The projects using CI do not continuously inspect the
source code. Moreover, the percentage of qualitatively monitoredbuilds is lower for systems with large numbers of commits and
contributors.
Elapsed Frame between Checks (EFC) measures the average num-
ber of builds between two builds subject to a code quality checkon the same branch. The overall result for EFC strengthens ourinitial findings on the lack of CCQ. On the average, developersperform a code quality check every 18 builds. This number still
increaseswheretakingintoaccountthesizeoftheprojects.Indeed,
systems with a high numberof commits and contributors have an
EFC score of 39 and 37, respectively. It is important to highlight
thatsuchprojectshaveahighernumberofbuildswithrespectto
smallprojects,andthereforemightbenefitmoreofacontinuous
check of code quality.
Looking at and Elapsed Time between Checks (ETC), we can con-
firm what we observe for the elapsed time between quality checks:
developersdonotperformacontinuouscodequalityassessment,
butrathertheymonitorthequalityattimeintervalsof17days.This
number is very close to the usual duration of a SCRUM Sprint [1],
whichisoftenusedintheCIcontext[ 20]:thus,ourfindingssuggest
that likely the current practice merely consists of checking code
qualityattheendofasprint.Thisobservationholdswhensplitting
projectsbasedontheircharacteristics,asweconfirmthatquality
checks are performed at fixed intervals.
Finding 2. Developers perform a code quality inspection after several
builds (on average every 18 builds) and, most likely, at the end of a
sprint.
As the last indicator, we compute the percentage of Checked
Branches (CB). Table 1shows a similar trend as for the other CCQ
usageindicators.Alsointhiscase,thehigherthenumberofcom-
mitsandcontributors,thelowerthepercentageofbranchesthatare subject to a quality check. This result confirms the possible
role of community-related factors, as large communities tend to be
more reluctant to apply CCQ.
793
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:28:00 UTC from IEEE Xplore.  Restrictions apply. Continuous Code Quality: Are We (Really) Doing That? ASE ’18, September 3–7, 2018, Montpellier, France
Overall,only36%ofbranchesarechecked,meaningthatmost
of them are developed without a formal quality control.
Finding 3. A low percentage of branches follow CCQ.
6 DISCUSSION AND FUTURE WORK
Our results highlight a number of points to be further discussed,
and in particular:
•CCQIsnotAppliedinPractice. Aclearresultofourstudy
demonstratesapoorusageofcontinuouscodequality,and
thatindeedonlyaverylownumberofbuilds(11%)arequali-
tativelymonitored.Thisfindingopensupanumberofobser-
vations.Inthefirstplace,thelowuseofCCQmaybeduetoa
general biased perception that developers have with respect
to source code quality [ 4,25]: code quality is not the top-
priorityfordevelopers[ 10],whoprefernottoimprovethe
existingcodefordifferentreasons,includingtimepressure
or laziness [ 34]. Most of the time developers and product
managersdonotconsideraqualitydecrementenoughtofailthebuildprocess,ortheydonotknowhowtoproperlysetupqualitygates[
26].Besidesthis,ourstudysomehowconfirms
the findings reported by Hilton et al. [ 13], highlighting once
again that developers face several barriers when adopting
CI principles.
•The Relevance of a Development Community. Ak e y
findinginourstudyreportsthatthesizeofaprojectplays
a role in the adoption of continuous code quality. While
projectshavingfewdevelopersperforma(slightly)higher
percentage of code quality checks, systems with a larger
communityface moredifficulties.This canbeexplained by
thepresenceof community-relatedfactorsthat mightpre-
cludeaneffectivemanagementofthedevelopmentactivities.Indeed,wrongcommunicationandcoordinationwithinsoft-
ware communities have been not only largely associated
to the emergence of socio-technical issues [ 7,11,23], but
also related to continuous integration aspects. In particu-lar, Kwan et al. [
19] reported a strong negative impact of
socio-technical congruence, i.e., a measure indicating the
alignmentbetweentechnicaldependenciesworkrelations
amongsoftwaredevelopers, onbuildsuccess.Ourfindings
confirm the importance of studying such factors and how
theyinfluencetechnicalaspectsofsoftwaresystemsmore
deeply.
•On the Size of Change History. According to our results,
projects having a longer change history are less likely toapply CCQ. This may suggest that a possible co-factor in-fluencing the lack of continuous code quality control fallsin the difficulty of developers to switch toward such new
continuous monitoring in case the project is already mature.
Ourinitialfindingspavethewaytofurtherstudythatweplan
to conduct in future work:
(1)On theValue of Continuous CodeQuality. Despite pre-
viousworkintheareaofagileprocesses[ 17],thereisstill
a lack of study empirically assessing the benefits derivingfrom the actual practice of code quality assessment in CI.
WebuildadatasetofprojectsusingbothCIServerandCCQService(asexplainedinSection 2).Thus,comparedtopre-
viouswork[ 35,40]weareabletoanalyzethedecisionsof
developers (i.e., whether perform code quality or not) and
the obtained measurements without rerunning the analysis
onprojects’snapshotsthatmightcauseseveralthreats,such
astheunavailabilityoftheconfigurationfileortheimpos-
sibility to build a snapshot [ 33]. As future work, we plan
tomeasuretheeffectivenessoftheactualCCQpracticein
maintaining software quality.
(2)Key Scenarios in Continuous Code Quality. Given the
fact that code quality is not continuously assessed in CI, we
are interested in determining the circumstances (e.g., devel-
opment tasks) where the use of CCQ should be particularly
encouraged, as they can lead to significantly decrease the
qualityofsourcecode.It mightbethatCCQisparticularly
effective in certain scenarios compared to others.
(3)CodeQualityRecommendationinCI. Slowbuildsarese-
rious barriers faced by developers using CI [ 13]. Automated
testing and code quality assurance tasks and are possible
causesinslowingdownbuilds.Codequalitytasksareusually
postponedandscheduledin nightly builds,thuspreventing
CCQ to be performed. We aim at finding a good trade-off
between scheduling code quality tasks at every new change
andslowingdownthebuild.Ourvisionistopredictwhich
qualitymeasurementsperformbeforetriggeringanewbuild.
Given the actual build context described in terms of several
features(e.g.,checked-outbranch,typeofdevelopmenttask,etc.),arecommenderwillautomaticallyscheduleanewcode
quality task enabling the proper warnings.
7 THREATS TO VALIDITY
This section discusses possible threats that might have affected the
validity of our observations.
We mined information from different sources and combined
themusingheuristicsthatwereneededbecauseofthelackofan
explicit link between them. To infer projects using both Sonar-
Cloud and TravisCI we used theirGithub URL—exposed on the
firstplatform—asameansforunderstandingwhethertheyalsouse
TravisCI as build server. This linking process can be considered
safe, as the Github URL of a project is unique and, thus, therecannot be cases where the history of a project on SonarCloud
wasoverlaidwiththeoneofanotherprojectonTravisCI.Asfor
theoverlayofthechangehistoryinformationofthetwoplatforms,
we exploited the build and measurement dates to understand to
whichbuildacertainmeasurementreferredto.Also,inthiscase,
the linking procedure cannot produce false positives because there
are not cases in which different builds might have been performed
between the dates considered.
Asforthegeneralizabilityoftheresults,weconductedthisstudy
on a large dataset composed of 119 projects. We also made some
precautionstotakeintoaccountonlyprojectsthatactivelyadopt
CI and CCQ. We limited our study to Java projects since someof the exploited platforms (e.g., SonarCloud) mainly contained
informationonthistypeofsystems.Replicationsaimedattargeting
projects written in different programming languages as well as
industrial ones would be desirable.
794
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:28:00 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Carmine Vassallo, Fabio Palomba, Alberto Bacchelli, and Harald C. Gall
8 CONCLUSION
Inthispaper,weanalyzedthecurrentpracticeofContinuousCode
Quality (CCQ). Our findings showed that the theoretical principles
reported by Duvall et al. [ 8] are not followed in practice. We found
that only 11% of the builds are subject to a quality control. More
importantly, the current CCQ practice merely consists of checking
code quality at the end of a sprint, thus basically ignoring the CCQ
principle.
Based on the dataset that we built overlaying change history
informationcomingfromSonarCloudandTravisCI,weplanto
investigate the impact of the current CCQ practice on the software
quality and the circumstances where developers are particularly
encouragedtocheckcodequalitymorefrequently.Ourfuturere-
searchagendaincludesalsothedefinitionoftechniquesforassisting
developers during continuous monitoring of code quality.
ACKNOWLEDGMENTS
VassalloandGallacknowledgethesupportoftheSwissNational
ScienceFoundationfortheproject“SURFMobileAppsData”(SNF
Project No. 200021-166275). Bacchelli and Palomba also gratefully
acknowledgethesupportoftheSwissNationalScienceFoundation
through the SNF Project No. PP00P2_170529.
REFERENCES
[1]Kent Beck, Mike Beedle, Arie Van Bennekum, Alistair Cockburn, Ward Cunning-
ham,MartinFowler,JamesGrenning,JimHighsmith,AndrewHunt,RonJeffries,
et al. 2001. The agile manifesto.
[2]Moritz Beller, Georgios Gousios, and Andy Zaidman. 2017. Oops, my tests broke
the build: An explorative analysis of Travis CI with GitHub. In International
Conference on Mining Software Repositories.
[3]MoritzBeller,GeorgiosGousios,andAndyZaidman.2017. TravisTorrent:Synthe-
sizing Travis CI and GitHub for Full-Stack Research on Continuous Integration.
InProceedings of the 14th working conference on mining software repositories.
[4]Nigel Bevan. 1999. Quality in use: Meeting user needs for quality. Journal of
systems and software 49, 1 (1999), 89–96.
[5]Andrea Bonaccorsi and Cristina Rossi Lamastra. 2004. Altruistic individuals,
selfish firms? The structure of motivation in Open Source software. (2004).
[6]Laura Dabbish, Colleen Stuart, Jason Tsay, and Jim Herbsleb. 2012. Social coding
in GitHub: transparency and collaboration in an open software repository. In
Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work.
ACM, 1277–1286.
[7]Nicolas Ducheneaut. 2005. Socialization in an open source software community:
A socio-technical analysis. Computer Supported Cooperative Work (CSCW) 14, 4
(2005), 323–368.
[8]PaulDuvall,StephenM.Matyas,andAndrewGlover.2007. Continuous Integration:
Improving Software Quality and Reducing Risk. Addison-Wesley.
[9]Paul M. Duvall. 2010. Continuous integration. Patterns and Antipatterns. DZone
refcard #84 (2010).http://bit.ly/l8rfVS
[10]Neil A Ernstand John Mylopoulos. 2010. On the perception ofsoftware quality
requirements during the project lifecycle. In International Working Conference on
Requirements Engineering: Foundation for Software Quality. Springer, 143–157.
[11]Simon Gibbs, Eduardo Casais, Oscar Nierstrasz, Xavier Pintado, and Dennis
Tsichritzis. 1990. Classmanagement for softwarecommunities. Commun. ACM
33, 9 (1990), 90–103.
[12]GitHub. 2018. GitHub APIs. https://developer.github.com/v3/. Online; accessed
24 July 2018.
[13]MichaelHilton, NicholasNelson,Timothy Tunnell,DarkoMarinov,and Danny
Dig. 2017. Trade-Offsin ContinuousIntegration: Assurance,Security, andFlex-
ibility. In Proceedings of the 25th ACM SIGSOFT International Symposium on
Foundations of Software Engineering, FSE 2017. To Appear.
[14]MichaelHilton,TimothyTunnell,KaiHuang,DarkoMarinov,andDannyDig.
2016. Usage,costs,andbenefitsofcontinuousintegrationinopen-sourceprojects.
InProceedings of the 31st IEEE/ACM International Conference on Automated Soft-
ware Engineering (ASE). 426–437.
[15]JezHumbleandDavidFarley.2010. Continuous Delivery: Reliable Software Releases
Through Build, Test, and Deployment Automation. Addison-Wesley Professional.
[16]Eirini Kalliamvakou, Georgios Gousios, Kelly Blincoe, Leif Singer, Daniel M
German,andDanielaDamian.2016. Anin-depthstudyofthepromisesandperilsof mining GitHub. Empirical Software Engineering 21, 5 (2016), 2035–2071.
[17]Foutse Khomh, Bram Adams, Tejinder Dhaliwal, and Ying Zou. 2015. Under-standingtheimpactofrapidreleasesonsoftwarequality-Thecaseoffirefox.
Empirical Software Engineering 20, 2 (2015), 336–373.
[18]Seojin Kim, Sungjin Park, Jeonghyun Yun, and Younghoo Lee. 2008. Automated
continuous integration of component-based software: An industrial experience.
InProceedings of the 2008 23rd IEEE/ACM International Conference on Automated
Software Engineering. IEEE Computer Society, 423–426.
[19]IrwinKwan,AdrianSchroter,andDanielaDamian.2011. Doessocio-technical
congruence have an effect on software build success? a study of coordination
in a software project. IEEE Transactions on Software Engineering 37, 3 (2011),
307–324.
[20]Lina Lagerberg, Tor Skude, Par Emanuelsson, Kristian Sandahl, and Daniel Stahl.
2013. The impact of agile principles and practices on large-scale software devel-
opment projects: A multiple-case study of two projects at ericsson. In Empirical
Software Engineering and Measurement, 2013 ACM/IEEE International Symposium
on. IEEE, 348–356.
[21]E. Laukkanen, M. Paasivaara, and T. Arvonen. 2015. Stakeholder Perceptions
of theAdoption of ContinuousIntegration – ACase Study. In Agile Conference
(AGILE), 2015. 11–20.
[22]Eero Laukkanen, Maria Paasivaara, and Teemu Arvonen. 2015. Stakeholder
PerceptionsoftheAdoptionofContinuousIntegration–ACaseStudy.In Agile
Conference (AGILE), 2015. IEEE, 11–20.
[23]Mikael Lindvall, Dirk Muthig, Aldo Dagnino, Christina Wallin, Michael Stup-
perich, David Kiefer, John May, and Tuomo Kahkonen. 2004. Agile software
development in large organizations. Computer 37, 12 (2004), 26–34.
[24] Jennifer Marlow,Laura Dabbish,and JimHerbsleb.2013. Impression formation
in online peer production: activity traces and personal profiles in github. In
Proceedings of the 2013 conference on Computer supported cooperative work. ACM,
117–128.
[25]Fabio Palomba, Gabriele Bavota, Massimiliano Di Penta, Rocco Oliveto, and An-
dreaDeLucia.2014. Dotheyreallysmellbad?astudyondevelopers’perception
of bad code smells. In Software maintenance and evolution (ICSME), 2014 IEEE
international conference on. IEEE, 101–110.
[26]GeraldSchermann,JürgenCito,PhilippLeitner,andHaraldC.Gall.2016.Towards
quality gates in continuous delivery and deployment. In International Conference
on Program Comprehension.
[27]SonarCloud.2018. SonarCloudWebAPIs. https://sonarcloud.io/web_api. Online;
accessed 24 July 2018.
[28] SonarSource S.A. 2018. SonarQube. https://www.sonarqube.org.
[29]Damian A Tamburri, Rick Kazman, and Hamed Fahimi. 2016. The Architect’s
Role in Community Shepherding. IEEE Software 33, 6 (2016), 70–79.
[30]Tiobe. 2018. Tiobe Ranking. https://www.tiobe.com/tiobe-index/. Online;
accessed 24 July 2018.
[31] TravisCI. 2018. Travis CI. https://travis-ci.org. Online; accessed 24 July 2018.
[32]TravisCI. 2018. Travis CI APIs. https://developer.travis-ci.com. Online; accessed
24 July 2018.
[33]Michele Tufano, Fabio Palomba, Gabriele Bavota, Massimiliano Di Penta, Rocco
Oliveto,AndreaDeLucia,andDenysPoshyvanyk.2017. Thereandbackagain:
Can you compile that snapshot? Journal of Software: Evolution and Process 29, 4
(2017).
[34]MicheleTufano,FabioPalomba,GabrieleBavota,RoccoOliveto,Massimiliano
Di Penta, Andrea DeLucia, and Denys Poshyvanyk. 2017. Whenand why your
code starts to smell bad (and whether the smells go away). IEEE Transactions on
Software Engineering 43, 11 (2017), 1063–1088.
[35]BogdanVasilescu,YueYu,HuaiminWang,PremkumarT.Devanbu,andVladimir
Filkov. 2015. Quality and productivity outcomes relating to continuous integra-
tion in GitHub. In ESEC/SIGSOFT FSE. ACM, 805–816.
[36]Carmine Vassallo, Fabio Palomba, Alberto Bacchelli, and Harald C. Gall. 2018.
ContinuousCodeQuality:AreWe(Really)DoingThat?OnlineAppendix. https:
//doi.org/10.5281/zenodo.1341015
[37]CarmineVassallo,SebastianoPanichella,FabioPalomba,SebastianProksch,Andy
Zaidman,andHaraldC.Gall. 2018. Contextisking:Thedeveloperperspective
on the usage of static analysis tools. In SANER. IEEE Computer Society, 38–49.
[38]CarmineVassallo,GeraldSchermann,FiorellaZampetti,DanieleRomano,Philipp
Leitner, Andy Zaidman, Massimiliano Di Penta, and Sebastiano Panichella. 2017.
ATaleofCIBuildFailures:AnOpenSourceandaFinancialOrganizationPer-
spective. In ICSME. IEEE Computer Society, 183–193.
[39]CarmineVassallo,FiorellaZampetti,DanieleRomano,MoritzBeller,Annibale
Panichella, Massimiliano Di Penta, and Andy Zaidman. 2016. Continuous De-livery Practices in a Large Financial Organization. In 32nd IEEE International
Conference on Software Maintenance and Evolution (ICSME). 41–50.
[40]Fiorella Zampetti, Simone Scalabrino, Rocco Oliveto, Gerardo Canfora, and Mas-
similiano Di Penta. 2017. How open source projects use static code analysis
tools in continuous integration pipelines. In Proceedings of the 14th International
Conference on Mining Software Repositories. IEEE Press, 334–344.
795
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:28:00 UTC from IEEE Xplore.  Restrictions apply. 