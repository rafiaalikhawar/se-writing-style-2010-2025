Effective API Recommendation without Historical Software
Repositories
Xiaoyu Liu
Department of Computer Science and
Engineering, Southern Methodist
University
Dallas, Texas, USA
xiaoyul@smu.eduLiGuo Huang
Department of Computer Science and
Engineering, Southern Methodist
University
Dallas, Texas, USA
lghuang@smu.eduVincent Ng
Human Language Technology
Research Institute, University of
Texas at Dallas
Richardson, Texas, USA
vince@hlt.utdallas.edu
ABSTRACT
It is time-consuming and labor-intensive to learn and locate the
correctAPIforprogrammingtasks.Thus,itisbeneficialtoperform
API recommendation automatically. The graph-based statistical
model has been shown to recommend top-10 API candidates ef-
fectively. It falls short, however, in accurately recommending an
actualtop-1API.Toaddressthisweakness,weproposeRecRank,
anapproachandtoolthatappliesanovelranking-baseddiscrim-
inative approach leveraging API usage path features to improve
top-1 API recommendation. Empirical evaluation on a large corpus
of (1385+8) open source projects shows that RecRank significantly
improvestop-1APIrecommendationaccuracyandmeanrecipro-calrankwhencomparedtostate-of-the-artAPIrecommendation
approaches.
CCS CONCEPTS
•Software and its engineering →API languages ;Software
maintenance tools ;
KEYWORDS
API Recommendation, Machine Learning
ACM Reference Format:
Xiaoyu Liu, LiGuo Huang, and Vincent Ng. 2018. Effective API Recommen-
dation without Historical Software Repositories. In Proceedings of the 2018
33rd ACM/IEEE International Conference on Automated Software Engineering
(ASE ’18), September 3–7, 2018, Montpellier, France. ACM, New York, NY,
USA,11pages.https://doi.org/10.1145/3238147.3238216
1 INTRODUCTION
During daily software development, Application Programming In-
terfaces (APIs) are provided as functional building blocks to pro-
gramsoftwaresystems.APIsareclasses,methods,andfieldspro-
vided by the library’s designers [ 25] to enable developers to access
the functionality of a code library. However, developers need to
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3238216spendalotofeffortonfamiliarizingthemselveswiththecapabil-
ities provided by a large number of APIs in the library and pick
the correct API for development tasks. For instance, developersneed to manually browse a long list of APIs to identify Buffered-
Writer.write(), the API that enables them to efficiently write to a
file by buffering the characters in Java memory. As another exam-
ple, developers have to choose from a list of 67 candidate member
methodsof StringintheJavaDevelopmentKit(JDK)toidentifythe
appropriate API for converting all of the corresponding characters
to upper case (i.e., String.toUpperCase() ). To address this challenge,
many automatedAPI recommendation approachesand tools have
beenproposedtorelievetheburdenofdevelopersinunderstandingandlocatingAPIs,eitherbytakingadvantageofAPIusagepatterns[
4,10,14,33]orbyusingstatisticallearningtorecommendthenext
token[6,16,23,24].Forinstance, Gralanusesastatisticallanguage
model for API recommendation that relies on features extracted
from the preceding context (i.e., the code that has been written so
far). The model was trained by collecting statistics on how oftenacandidateAPIco-occurswiththeAPIsinitsprecedingcontext
[24]. Being a generative model, however, Gralanis sensitive to the
presenceof overlapping featuresand irrelevant features.Specifically,
if two features encode overlapping information (e.g., two features
arecomputedbasedonthesameAPIintheprecedingcontext),it
willundesirablyamplifytheimportanceofthisAPIinthepredic-
tion process, thus possibly harming model performance. Irrelevant
features(i.e.,featuresthatarelargelynotpredictiveofthetarget
API),too,couldbeharmful:whilethestatisticscollectedduringthe
trainingprocesscouldtosomeextentindicate whetherafeature
is relevant, the multiplicativeeffect resulting from a large number
ofirrelevantfeaturesinagenerativemodelcouldoverwhelmthe
positiveeffectoftherelevantfeatures,againharmingmodelperfor-
mance.Hence,featureengineeringisimportantwhenemploying
generative models. Unfortunately, as we will see in the next sec-
tion, a number of features that Gralanemploys are by design both
overlapping and irrelevant.
More recently, APIREC[23], a state-of-the-art API recommenda-
tion approach, was proposed by Gralan’s authors. APIRECmakes a
key assumption: changes that serve the same higher-level intent
ofthedeveloperswillco-occurmorefrequentlythannon-related
changes[ 23].Hence,byleveragingtheregularityandrepetitiveness
of software changes of a software system, APIRECcan identify and
focus on changes/features that are relevant to API recommenda-
tion,therebyreducingtheimpactofthefeatureirrelevanceproblem
mentionedearlier.Nevertheless,theapplicabilityof APIRECisse-
verely limited by the large number of historical software change
282
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiaoyu Liu, LiGuo Huang, and Vincent Ng
repositories it requires. Specifically, not only does it need to be
trainedon 471,730 changed source code files and 113,103 change
commits, but it can only be appliedto files with a similarly long
change history.
Ourgoalinthispaperistoadvancethestate-of-the-artinAPI
recommendation,specificallybyimprovingthetop-1APIrecom-
mendationaccuracy.Inviewoftheaforementionedlimitationsof
APIREC,wedesireanapproachthatdoes notrelyoncodechange
history. The design of our system, RecRank, is motivated by akey observation: while Gralanis unable to achieve a high top-1
recommendation accuracy, it achieves a reasonably high top-10
recommendationaccuracy(73.4–80.6%).Giventhisobservation,we
take the top-10 API candidates identified by Gralanas our starting
point and re-rankthese candidates so that the correct API surfaces
tothetopofthelist.Thequestion,then,is:howshouldwere-rank?
Recall that a key weakness of Gralanconcerns the use of a genera-
tivemodel,whichissensitivetothepresenceofoverlappingand
irrelevant features. RecRank is specifically designed to address this
weakness.First,RecRankemploysa discriminative re-rankerthat
is trained to re-rank Gralan’s top-10 candidate APIs. The key ad-
vantage of a discriminative approach (over a generative approach)
is that the former can automatically discriminate relevant from
irrelevant features (by assigning high weights to the relevant ones
andlowweightstotheirrelevantones).Second,weproposeanovel
kind of features for use in conjunction with our discriminative
re-ranker, APIusagepath basedfeatures.Thesefeaturespartially
address the feature irrelevance problem and can arguably better
capturethelinguistictopicoftheprogramexpressingtheintention
of the developer.
In sum, our contribution in this paper lies in the proposal of
RecRank, a novel discriminative ranking approach that employs a
novelkindoffeaturesbasedonusagepathstoautomaticallyrecom-
mend top-1 APIs based on the top-10 API candidates suggested by
Gralan. In an evaluation on eight large-scale open source projects,
RecRank outperforms APIRECwith respect to two evaluation met-
rics, top-1 recommendation accuracy and mean reciprocal rank
(MRR), a commonly used metric for evaluating ranking tasks in
information retrieval, achieving state-of-the-art results.
2 PRELIMINARIES AND MOTIVATING
EXAMPLES
2.1 Graph-based Generative API
Recommendation (Gralan)
SinceRecRankisbuiltuponthetop-10APIcandidatessuggestedby
Gralan, we will provide an overview of Gralanin this subsection.
As mentioned before, given a recommendation point ,Gralanrec-
ommends an API using its preceding context (i.e., the code that has
beenwrittensofar).1Gralanencodestheprecedingcontextasa
set ofAPI usage graphs. In an API usage graph, each node is an
API used in a method call, operator overloading, field access or
branching(e.g., if,while,for,etc.).AllAPInodesareconnectedby
directededges.Eachedgerepresentsadataflowdependency(i.e.,
1The reason that only the preceding context is used is to mimic the realistic situation
thatwhenanAPIistoberecommendedtoadeveloper,onlythecodethathasbeen
written so far is available.
(a) Child graph
(b) Parent graph
Figure 1: Parent-child graph example
overloading operator, method calls, and field accesses) or a control
flow dependency (i.e., condition and repetition) between two APIs.
AnexampleofanAPIusagegraphisshowninFigure1(a),where
nodeNistherecommendationpoint.Thecorrespondingcontext
graph(i.e.,thegraphthatencodesthecontextinwhichNoccurs)is
shown in Figure 1(b). As can be seen, this context graph is created
by removing node N as well as all of its incoming and outgoing
edges.Throughoutthepaper,iftwographs(e.g.,theonesshownin
Figure 1) have a parent-child relationship, we will refer to the one
withouttherecommendationpointastheparentgraphandtheone
with the recommendation point as the corresponding child graph.
Asmentionedbefore, Gralanusestheparentgraphforpredicting
the API at the recommendation point. One way to make use of the
parent graph is to estimate the probability that a candidate APIco-occurs with the parent graph in the training data. The higherthe co-occurrence probability is, the more likely that the candi-
dateAPIisthecorrectAPI.However,aparentgraph(suchasthe
one shown in Figure 1(b)) could be fairly complex. Complex par-
entgraphscouldyieldadatasparsityproblem:themorecomplex
a parent graph is, the less likely it will be seen in the trainingdata. To alleviate data sparsity, Gralanalso makes use of all the
(non-empty)subgraphsoftheparentgraphintheAPIprediction
process. For instance, from the parent graph in Figure 1(b), we
canextractsubgraphs withoneAPI(e.g., CONTROL.WHILE ),sub-
graphs with two APIs (e.g., [FileWriter. <init>,CONTROL.WHILE ]),
subgraphs with three APIs (e.g., [FileWriter. <init>,BufferedReader.-
<init>,CONTROL.WHILE ]), and subgraphs with four APIs (e.g.,
[FileWriter. <init>,BufferedReader. <init>,BufferedReader.readLine,
CONTROL.WHILE ]).
Specifically, given a parent graph дand subgraphs д1,...,дnof
д,Gralancomputes the probability of a child graph, C(д), which is
283
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Effective API Recommendation without Historical Software Repositories ASE ’18, September 3–7, 2018, Montpellier, France
created by filling the recommendation point with a candidate API,
using Bayesian statistical inference as follows:
log(Pr(C(д)|д1,д2,...,дn,д))
∝log(Pr(д1|C(д))...Pr(дn|C(д))Pr(C(д)))
=n/summationdisplay.1
j=1log(#methods(дj,C(д))+α)
+log(#methods(д,C(д)))
−(n−1)log(#methods(C(д))+α#methods)
−log(#methods(д))(1)
wheretheexpressioninthesecondlineisobtainedusingBayesrule,
andthethirdlineshowshowtheprobabilitiesinthesecondlinecan
beestimated.Specifically,# methods(д,C(д))isthenumberoftimes
дappears as the parent of C(д)in the training data, # methods(д)is
thenumberoftimes дappearsinthetrainingdata,and# methodsis
thetotalnumberofmethodsinthetrainingdata.2Toavoidfloating
underflow, Logarithm ( log) is applied to all the probabilities in the
equation.Toassignnon-zeroprobabilitiestoeventsnotseeninthe
training data, a smoothing factor (i.e., α) is used. Note that each of
the graphs being conditioned on in Equation 1 (i.e., д,д1,...,дn)
can be viewed as a feature used by Gralanin the recommendation
process. Because the дi’s are subgraphs of д, these features are
by design overlapping, which could harm the performance of a
generative model like Gralan, as noted in the introduction.
Thereisanothercaveat.RecallthatFigure1(a)onlyshows one
of the many API usage graphs that Gralangenerates for the rec-
ommendation point N. The exact number of API usage graphs that
Gralangenerates for a recommendation point depends on a pa-
rameter,d, which specifies the maximum distance between the
recommendationpointandanyofthenodesinanAPIusagegraph.
For instance, if d=3,Gralanwill generate allAPI usage graphs that
can possibly be generated by including any subset of nodes whose
distance is no larger than 3 from the recommendation point. For
eachoftheseAPIusagegraphs, Gralangeneratesthecorrespond-
ing parent graph. Given each parent graph д(and its subgraphs
д1,...,дn),Gralancomputes the probability of each child graph
C(д)using Equation (1). The candidate API that corresponds to the
most probable child graph over all the parent graphs will be the
API recommended by Gralanfor a given recommendation point.
2.2 Motivating Example
WemotivatethedevelopmentofRecRankthroughthefollowing
example. A developer is developing a software function to readtext from a .txt file (“input.txt”) and write the processed text toanother .txt file (“output.txt”). The code snippet is shown in Fig-ure 2, in which the input text file “input.txt” is read using Java
DevelopmentKit(JDK)API BufferedReader (line6)andwrittento
“output.txt” using JDK API BufferedWriter (line 7). A while loop
is used to iteratively read each line of the input text file (line 11).
Now this developer needs to decide what API should be used in
line 12 to write to the “output.txt” file. Modern Integrated Devel-
opmentEnvironment(IDE)tools,suchasEclipse,providealistof
2Our training data is composed of the set of API usage graphs generated from all the
methods in the source code collected from 1385 open source projects (see Section 4.1
for details).
Figure 2: A code snippet
Figure 3: An API recommendation example from Eclipse
APIs for developers to choose. This list of methods and fields is
usuallyrankedinalphabeticalordersinceitsimplyshowsallmem-
bermethods/fieldsofthecallingAPI.Figure3showsthatEclipse
recommends16APIsforline12inFigure2.Notethatthesemember
methods and fields of the calling API BufferedWriter arenotpri-
oritizedbasedonrelevance:theyaresimplylistedinalphabetical
order.
SincethedeveloperstillcannotdecidewhichAPItochoosefrom
thelist recommendedby IDEtools, shewould liketoask forhelp
fromGralan.Asaforementioned, GralanrankscandidateAPIsby
theprobabilitiesofthecorrespondingchildgraphsgivenaparent
graph and its subgraphs. Specifically, it starts by building a setofAPIusagegraphs(suchastheoneshowninFigure1-a)ofthe
code snippet in Figure 2. For each of the API usage graphs, Gralan
extractsthecorrespondingparentgraphand its subgraphs.These
context graphs are then used in calculating the probability of each
candidate API using Equation (1). However, not all context graphs
arerelevanttotherecommendationpoint.Inotherwords,notall
context graphs implement the same linguistic topics as that of the
recommendation point. For example, the recommendation pointN in Figure 1(a) implements the linguistic topic “write to outputtext file” with its context graph in the green rectangle, while its
context graph in the blue rectangle implements the linguistic topic
“read from input text file”. However, based on Equation (1) this
contextgraph isconsideredasimportant asothercontext graphs:
likeothergenerativemodels,theoneemployedby Gralanmerely
multipliestheprobabilitiesassociatedwiththeparentgraphand
all of its subgraphs.
Table1showsafewexamplesoftheparentgraphs(i.e., д)and
their corresponding child graphs (i.e., C(д)) for the code snippet in
Figure2aswellastheprobability(i.e.,score)ofeachchildgraph.
The scores of the child graphs over all of the parent graphs are
284
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiaoyu Liu, LiGuo Huang, and Vincent Ng
Table 1: Probability scores of candidate APIs
д C(д) Candidate API Score
FileReader. <init>,
BufferedReader.-
<init>, Buffere-
dReader.readLine,
CONTROL.WHILEFileReader. <init>,
...,Buffere-
dReader.closeBufferedReader.-
close0.33
FileReader. <init>,
..., CON-
TROL.WHILE,
Buffered-
Writer.writeBufferedWriter.-write 0.15
... ... ...
BufferedWriter.-
<init>, CON-
TROL.WHILEBufferedWriter.-
<init>, CON-
TROL.WHILE,
Buffered-Writer.writeBufferedWriter.-write 0.25
BufferedWriter.-
<init>, CON-
TROL.WHILE,
Buffere-dReader.closeBufferedReader.-close 0.02
... ... ...
CONTROL.WHILECONTROL.WHILE,
Buffere-dReader.closeBufferedReader.-
close0.1
CONTROL.WHILE,
Buffered-
Writer.writeBufferedWriter.-write 0.05
... ... ...
... ... ... ...
calculatedandsorted.AswecanseeinTable1,eventhoughAPI
BufferedWriter.write is the correct API for the recommendation
point N, Gralanrecommended BufferedReader.close since it has
the highest score (i.e., 0.33). The main reason behind this miss
isthatBufferedReader.close co-occurredmorefrequentlywiththe
irrelevant context graph in the blue rectangle in Figure 1, whichimplements the linguistic topic “read from input text file” rather
than the topic that corresponds to the developer’s intent, “write to
output text file”. Note that this is just oneexample of an irrelevant
feature employed by Gralan: because of the way parent graphs
aregeneratedfor arecommendationpoint,many ofthem(aswell
as the subgraphs generated from them) are irrelevant. Together
with the overlapping features, these irrelevant features could harm
Gralan’s performance.
Then the developer decides to try a state-of-the-art approach,
APIREC[23].Thekeyideabehind APIRECistoleveragetheregular-
ity and repetitiveness of API usage patterns learned from software
change history. It assumes that the changes that serve the same
higher-level intent will co-occur more frequently than unrelated
changes [ 23]. In other words, those APIs in the context graphs
that have a higher frequency of source code change co-occurrence
(andhenceareassumedtohaveahigherpredictivepowerinAPIrecommendation) will be given more importance in the API recom-mendation process. For each candidate API, APIRECfirst computes
a score based on the change history, and then adds the resulting
score to the one computed by Gralanto form the final score.
Notallchangesareapplicable,however,sincesomeofthemcould
be specific to a historical project and could therefore incur noise in
the change patterns.In the example in Figure 1(a), after analyzing
a large number of historical fine-grained changes, APIREClearned
thatBufferedWriter.write changed with BufferedReader. <init>with
a probability of 0.3 and that it changed with FileReader. <init>
withaprobabilityof0.05.Meanwhile,italsolearnedthat Buffere-
dReader.close changedwith BufferedReader. <init>withaprobability
of0.7andthatitchangedwith FileReader.- <init>withaprobability
of0.5.Hence,usingonlythecodechangehistory, APIRECwillselect
the wrong API, BufferedReader.close, for the given recommendation
pointsinceitsprobabilityofchangeco-occurrence(0 .7∗0.5=0.35)
is larger than that of BufferedWriter.write (0.3∗0.05=0.015). In
otherwords,usingthecodechangehistory, APIRECcannotoverride
Gralan’serroneousrecommendationforthisrecommendationpoint.
In addition, APIRECrequires a long source code change history
ofeachsubjectproject,whichlimitsitsapplicabilitytoscenarios
where long code change history is unavailable or inaccessible.
ToaddressthechallengeofaccurateAPIrecommendation,we
propose RecRank, which recommends APIs based on the API us-age paths generated from API usage graphs. An API usage path
(henceforth usage path) is generated to represent a data/control
flowsequenceofAPIsthatcanarguablybetterencodetheintentionofthedeveloper.Usingdiscriminativelearningincombinationwith
usage paths as features, higher weights can be learned for usage
paths that are more relevant and coherent to the given recommen-
dation point, thereby reducing the noise possibly introduced by
irrelevantorincoherentusagepaths.Forexample,inFigure1(a)we
extract one usage path [FileWriter. <init>→BufferedWriter. <init>
→(recommendation point) ] from the code snippet in lines 7 −12 in
Figure 2. This usage path implements the linguistic topic “write to
output text file”, which is weighted higher than other usage paths
extracted in Figure 1(a). Since RecRank seeks to improve the accu-
racy of recommending the top-1 API, it could save the developer’s
timeandeffortinmanuallyselectingthecorrectAPIfrommultiple
candidates.NotethatRecRankseekstoachievethisgoal without
mining and using long fine-grained code change histories.
3 DISCRIMINATIVE RE-RANKING FOR API
RECOMMENDATION (RECRANK)
3.1 Overview
Inthissection,wepresentanovelapproachtoAPIrecommenda-
tion, RecRank, which operates by re-ranking the top-10 candidate
APIsrecommendedby Gralanforeachrecommendationpointus-
ing a learned discriminative re-ranker in combination with our
usage path-based features. Before describing RecRank, we present
two re-ranking systems that could help the reader better under-
stand the power of discriminative re-ranking. The first re-ranking
system is trained using the Naïve Bayes (NB) generative model
onourusagepath-basedfeatures.Thesecondre-rankingsystem
isadiscriminativeclassifiertrainedusingthesupportvectorma-
chinelearner(henceforthSVC)onourusagepath-basedfeatures.
285
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Effective API Recommendation without Historical Software Repositories ASE ’18, September 3–7, 2018, Montpellier, France
TheperformancedifferencebetweentheNBsystemandtheSVC
systemcanshedlightsontherelativeeffectivenessofgenerative
models, which are sensitive to the presence of overlapping and
irrelevant features, and discriminative models, which are robust to
such features. Note that the SVC system is one step closer to Re-
cRankthantheNBsysteminthesensethatbothSVCandRecRank
are discriminative in nature: the primary difference between them
lies in the fact that SVC recasts the API recommendation task as a
classification task whereas RecRank recasts the task as a ranking
task. The performance difference between them can therefore shed
lightsontherelativeeffectivenessofclassificationandranking.We
willdiscussthedifferencesbetweenclassificationandrankinglater
in this section.
3.2 NB
InNB,weemploytheNaïveBayeslearningalgorithmimplemented
in scikit-learn Python library to train a binary classifier to classify
whether a given recommended API is the correct API at the recom-
mendationpoint (i.e.,a “hit”)ornot (i.e.,a “miss”).Recallthat NB
employs the following generative model:
P(c|candidate API) =P(c)n/summationdisplay.1
i=1P(fi|c)
wherecis the class (which in our case is either “hit” or “miss”),
and each ficorresponds to a usage path-based feature extracted
for the candidate API under consideration. As can be seen, theNB generative model assumes that the values of the usage path-
basedfeaturesareconditionallyindependentofeachothergiven
theclass.Eachoftheprobabilitiesinthegenerativemodelcanbe
estimated using maximum likelihood estimation from the training
data. Specifically, P(c)is the fraction of instances in the training
set that are labeled as c.P(fi|c)is the fraction of training instances
labeled as cthat contain feature fi.
WeemploythetrainedNBmodeltore-rankthetop-10candidate
APIs suggested by Gralanas follows. Since the model computes for
each candidate API the probability that it is a “hit”, we rank the
candidateAPIsusingtheirassociatedprobabilities,wherehigher
probabilities correspond to higher ranks.
Next, we discuss how the training instances are created and
how the usage path-based features are extracted for each training
instance.
Creating training instances. For each API recommendation point
inthetrainingset,wecreateonetraininginstanceforeachofthe
10 API candidates recommended by Gralan, labeling an instance as
“hit” or “miss” depending on whether the corresponding candidate
API is the correct API for the recommendation point under consid-
eration.Eachinstanceisrepresentedusingasetofusagepath-based
features,eachofwhichcorrespondstoanusagepath.Thissetof
usage paths is the union of the usage paths extracted from each of
the API usage graphs created for the given recommendation point
(seeSection2onhowtheseAPIusagegraphsarecreated).Below
we define usage paths.
Each usage path is extracted from an API usage graph and is
definedbythreeconstraints.First,ausagepathisformedbyase-
quenceofAPIsconnectedbydirecteddataand/orcontrolflowedges.Second,theAPIsinausagepatharesequentiallyconnected/listedinAPI usage order with one entry API and one exit API. Finally, each
usage path contains a candidate API (one of the 10 candidate APIs
recommended by Gralan) that appears either at the end (where
the directed flow ends) or at the beginning (where the directed
flow starts) of the path. Usage paths of various lengths could be
generated from an API usage graph. The length of a usage pathis between 2 and the threshold parameter
d, which determines
the maximum distance between any node and the recommenda-tion point in the graph (defined in Section 2.1). For example, 13usage paths can be generated from the API usage graph in Fig-ure 1(a), such as: [FileReader.
<init>→BufferedReader. <init>→
BufferedReader.readLine →CONTROL.WHILE →(candidate API) ].
To model different data/control flow in usage paths, we have
designed different types of usage path features, as described below.
Aforwardusagepath feature is created from a usage path in
which the APIs in the path are connected by edges in the point-
forwarddirectionwiththecandidateAPIappearingattheendof
thepath.Aforwarddata/controlflowtowardstherecommendation
point usually implies that the API at the recommendation point
“consumes” the data passed by data/control flow. As an example,
consider the API usage graph in Figure 1. From this graph, we can
createaforwardusagepathfeature fromthepath[FileReader. <init>
→BufferedReader. <init>→BufferedReader.readLine →CONTROL.-
WHILE→(candidate API) ]. We create forward usage path features
frompathsofdifferentlengths,wherethelengthofapathisdefined
as the number of APIs involved in the path. For instance, the path
[CONTROL.WHILE →(candidateAPI) ]is oflength2. Weconsider
all paths of up to length d.
Abackward usage path feature iscreatedfromausagepath
thatstartswiththecandidateAPI,andinwhichtheAPIsarecon-
nected by edges with a point-backward direction. A backward
data/control flow from the recommendation point usually impliesthattheAPIattherecommendationpoint“produces”or“returns”
thedatatobedeliveredtotheAPIsinthebacktrack.InFigure1(a),
wecancreatea backwardusagepathfeature fromthepath[CON-
TROL.WHILE ←(candidate API) ]. Similar to forward usage path
features,backward usage path features are generated from paths of
different lengths.
In addition, we derive fuzzy usage path features from the
forwardusagepathfeatures andthebackwardusagepathfeatures .
To motivate fuzzy usage path features, we note the correspondence
betweentheseusagepathsandtheword n-gramsusedinnatural
language processing (NLP). Specifically, the sequence of APIs in
aforward/backwardusagepathisreminiscentofthesequenceof
w or dsinaw or dn -gram.NLPresearchershavenotedaweakness
of using word n-grams as features in natural language learning:
ifnis large, the resulting n-grams will suffer from data sparsity;
and ifnis small, the n-grams will fail to capture longer-distance
dependencies.Toaddressthisweakness,theyhaveproposedthe
use ofskipgrams, in which they allow all but the first word and the
last word in an n-gram to match any words. For instance, given
the word n-gram“Iamaboy”,onecangenerateaskipgram“I**
boy”, where each wildcard * can match any word. This provides
generalization of the original n-gram (and therefore addresses data
sparsity) but at the same time captures the relationship between
non-adjacent words (in this case “I” and “boy”).
286
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiaoyu Liu, LiGuo Huang, and Vincent Ng
Fuzzyusagepathfeatures aremotivatedbyskipgrams.Specifi-
cally,afuzzyusagepathfeature iscreatedfromaforward/backward
usagepathfeaturebyreplacingallbuttheentryAPIandtheexitAPI
inthecorrespondingpathwithwildcards.ReturningtotheexampleinFigure1(a),[FileReader.
<init>→*→*→CONTROL.WHILE →
(candidateAPI) ]isafuzzyusagepathfeaturewithtwo“fuzzy”APIs
in the path (represented as “*”). As in skipgrams, wildcards (i.e.,
fuzzyAPIs)canonlyappearinthemiddleofafuzzyusagepath.As
with skipgrams, the goal of these fuzzy path features is to provide
generalizations of the forward/backward usage path features.
Incomparisontotheparentgraphsandsubgraphsthat Gralan
uses as features, our usage paths are arguably more relevant to
API recommendation. First, since each usage path has to begin
orendwithacandidateAPI,itensuresthatthepathcontainsan
API that is immediately adjacent to the candidate API, thereby
increasing its relevance for API prediction. In contrast, a subgraph
employedby Gralanmaynotcontainanynodesthatareadjacentto
therecommendationpoint,thuspossiblymakingitlessrelevantfor
API prediction. Second, from the example in Figure 1, each context
graphcanpotentiallycontainmorethanonelinguistictopic(e.g.,
both read and write to a file). On the other hand, a usage path
cantypicallyallowustofocusonjustonelinguistictopic.Thisis
especially important when it comes to discriminative learning: adiscriminative learner can assign high weights to those features
that encode the intended linguistic topic and low weights to those
features that do not. If context graphs encoding multiple linguistic
topics were used as features, the learner could find it difficult todecide whether high or low weights should be assigned to suchfeatures. Note that the computation of these usage path features
can be doneoffline (i.e., during training) with theresulting values
stored in a database. During testing, their values can simply be
retrieved from the database.
Afinalissuethatwehaveeludedsofarconcernshowweobtain
Gralan’stop-10candidateAPIsonthe trainingset.Recallthatwe
createonetraininginstancefromeachof Gralan’stop-10candidate
APIs. This means that before we can create training instances, we
need toproduce Gralan’s top-10 candidate APIs on the training
set. We do so using 5-fold cross validation on the training set:
we partition the training set randomly into five folds of roughly
equal sizes. In each fold experiment, we train Gralanon four folds
andapplyingthetrained Gralantogeneratethetop-10candidate
APIs on the remaining fold. We repeat this five times, each time
generating top-10 candidates on a different fold.
Applying the NB classifier. Test instances are created in the same
way as the training instances. Specifically, we create one test in-
stance from each of Gralan’s top-10 candidate APIs. This means
thatbeforewecreatetestinstances,weneedtoproduce Gralan’s
top-10candidateAPIsforeachrecommendationpointinthetest
set.Todoso,wetrain Gralanontheentiretrainingsetandapply
the trained Gralanto generate top-10 candidate APIs on the test
set.
Asmentionedbefore,theresultingNBclassifiercanbeusedto
compute the probability that each candidate API is a “hit” for a
recommendationpoint.Theseprobabilitiesarethenusedtore-rank
the 10 candidate APIs.3.3 SVC
Oursecondre-rankingsystem,SVC,isadiscriminativeclassifier
trainedusingthe SVMlearningalgorithmwithalinear kernel,as
implemented in the libSVM software package [ 9]. As in NB, we
first use cross validation on the training set to produce Gralan’s
top-10 candidate APIs on the training set, and then create one
traininginstancefromeachofthe10candidateAPIs.Eachtraining
instance in SVC is represented using the same set of usage path-
basedfeaturesasinNB.Theonlydifferenceliesinthevalueofeach
feature. As NB is generative, each feature is conditioned on the
class.Incontrast,SVCisdiscriminative,sowedesirethatthevalueofafeatureprovidessomeindicationofhowusefulitis.Specifically,
wedesirethat higherfeaturevaluesimplymorerelevant features.
To this end, we compute the value of a feature as follows. First, we
countthenumberoftimesthecorrespondingusagepathappearsin
the training set (call this number a). Second, we count the number
of times the path appears in the training set afterremoving from it
thecandidateAPI(callthisnumber b).Finally,wesetthefeature
value tob
a. In other words, the more often the candidate API co-
occurswiththerestofthepathinthetrainingset,thelargerthe
featurevalueis.AsinNB,thevaluesoftheseusagepathfeatures
canbecomputedandstoredinadatabaseduringtraining,andthey
can simply be retrieved from the database during testing.
TrainingtheSVCclassifier. Giventhetraininginstances,theSVM
learnerlearnsamaximummarginhyperplanethatminimizesthe
training error (i.e., the error of the hyperplane in classifying the
traininginstances).Ahyperplaneisdefinedbyasetofweights,eachof which is associated with exactly one feature. In other words, theSVMlearnerlearnsasetoffeatureweightsthatminimizestraining
error, specifically by associating larger absolute weights with rele-
vantfeaturesandlowerabsoluteweightswithirrelevantfeatures.
Thisdistinguishesadiscriminativelearnerfromagenerativemodel
such as NB.
ApplyingtheSVCclassifier. Aftertraining,theresultinghyper-
planecanbeused toclassifythetestinstances,which arecreated
inthesamewayasthetraininginstances.AsinNB, Gralan’stop-
10 candidates on the test set are obtained by training Gralanon
the entire training set and applying the trained Gralanon the test
set. We re-rank the top-10 candidate APIs based on their distances
from the hyperplane. Specifically, the candidate API on the “hit”
sideofthehyperplanethatisfarthestawayfromthehyperplane
receives the highest rank, whereas the one on the “miss” side of
the hyperplane that is farthest away from the hyperplane receives
the lowest rank.
3.4 RecRank
Next, we describe RecRank, which differs from SVC in one respect:
SVCclassifies candidate APIs, whereas RecRank ranks candidate
APIs.Tounderstandthedifferencebetweenclassificationandrank-
ing, we first note that API recommendation is inherently a ranking
task:itsgoalistocompare/rankcandidateAPIsandpickthebest
(i.e., highest-ranked) candidate API for a given recommendation
point. When applying SVC, we essentially recast API recommenda-
tion as a classification task, where each candidate API is classified
(as “hit” or “miss”) independently of other candidate APIs. In other
words, SVC does notcompare candidate APIs against each other,
287
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Effective API Recommendation without Historical Software Repositories ASE ’18, September 3–7, 2018, Montpellier, France
Table 2: Dataset statistics
Training Test
Total projects 1385 8
Total classes 138,791 8,621
Total methods 732,645 38,036
Total distinctive JDK API elements 18,166 7,272
Total recommendation points 70,37711,872
Average features per API candidate 3024
andwithoutsuchcomparisons,itfailstodeterminewhichcandi-
date API is the best. In contrast, the goal of ranking is precisely to
compare candidate APIs by imposing a ranking on them.
TrainingRecRank.RecRank trainsanSVMrankerusingthelinear-
kernel ranker learning algorithm implemented in SVMrank[15].
Thetraininginstances(andthefeaturesthatrepresenteachtrain-
ing instance) are created in the same way as in SVC. The resulting
traininginstancesarethengroupedintodifferentrankingproblems.
Specifically, each ranking problem corresponds to exactly one rec-
ommendationpointandiscomposedofthe10traininginstances
correspondingtothetop-10candidateAPIsforthisrecommenda-
tion point. The goal of the ranker training procedure is to learn
a hyperplane (by adjusting the feature weights) to minimize the
numberofviolationsofpairwiserankinginthetrainingset.Specif-
ically, a violation occurs if a training instance labeled as “hit” is
ranked below a training instance labeled as “miss” by the ranker.
Applying RecRank. After training, the ranker can be used to
directly rank the top-10 candidate APIs for each recommendation
point in the test set. Specifically, the ranker assigns each candidate
API a value, based on which a ranking can be imposed on the
candidate APIs. RecRank then recommends the candidate API that
has the highest rank.
4 EMPIRICAL EVALUATION
4.1 Experiment Setup
Datasets. Wecollectedalargedatasetof1385Javaprojectsfrom
GitHub for training API recommendation systems and another
eight for evaluation. Statistics of this dataset are shown in Table
2. In order to obtain high quality API usage graphs, we follow pre-
vious work [ 24]: we filter out the projects that are not parsable,
experimentalortoyprograms.Also,weuseonlythelatestsnapshot
of each project. For generalization purposes, we focus solely on
Java Development Kit (JDK) APIs. To facilitate comparison with
previouswork,theeightprojectsinourevaluationsetarethesameasthoseusedtoevaluate APIREC,astate-of-the-artAPIrecommen-
dationsystem[ 23].Trainingandtestrecommendationpointsare
created from these projects in thesame way as in previous work[
23,24]: except for the first two APIs in each method, we create
one recommendation point for each API.
Evaluation Measures. We employ two evaluation measures,
top-1accuracyandmeanreciprocalrank(MRR)[ 34].Top-1accu-
racyisameasureusedinpreviousworkonAPIrecommendation
[24].ForeachAPIrecommendationpointinthetestset,ifthetop-1
APIcandidatereturnedbyasystemisthecorrectAPIattherecom-
mendationpoint,wecountitasa“hit”.Thetop-1accuracyistheTable 3: Re-implemented and original Gralanresults
ProjectTop-1 Accuracy Top-10 Accuracy
Dupli-catedGralanOriginGralan ErrorDupli-catedGralanOriginGralan Error
antlr 38.326.0 +12.376.579.0 -2.5
Galaxy 22.422.0 +0.480.680.0 +0.6
Froyo-
Email25.546.0 -20.573.981.0 -7.1
Grid-
Sphere31.226.0 +5.276.985.0 -8.1
Itext 24.733.0 -8.380.576.0 +4.5
jGit 33.620.0 +11.677.174.0 +3.1
log4j 28.029.0 -1.075.274.0 +1.2
spring 30.228.0 +2.273.467.0 +6.4
ratio of the total number of hits to the total number of recommen-
dation points. MRR is an evaluation measure commonly used in
informationretrievaltoevaluatesearchresults.Liketop-1accuracy,ascoreof1isgiventoarecommendationpointforwhichthetop-1candidateisthecorrectAPI.Unliketop-1accuracy,whereasystem
isnotrewardedatallifthecorrectAPIisnotthetop-1candidate
API, MRR partially rewards a system as follows: a score of1
ris
giventoarecommendationpointifthecorrectAPIappearsinrank
r.Inotherwords,the(partial)rewardisinverselyproportionalto
the rank of the correct API. MRR then averages the scores over the
recommendationpointsinthetestset.Thus,MRRcanbeviewed
as a relaxed version of top-1 accuracy that partially rewards a sys-
tem where the correct API is not the top-1 candidate. Since we are
re-ranking Gralan’stop-10candidateAPIs,recommendationpoints
where the correct API is not in Gralan’s top-10 will receive a score
of 0.
BaselineSystems. Weemploytwobaselinesystems,neitherof
whichispubliclyavailable.Asourfirstbaseline,weemploy APIREC.
TheAPIRECresults reported in this paper are taken verbatim from
the original APIRECpaper [23].3
Asoursecondbaseline,weemploy Gralan.SinceNB,SVC,and
RecRank are all built upon Gralan’s top-10 candidate APIs, we
re-implement Gralan, following the steps mentioned in Section
2.1. Specifically, we first build the API usage graphs from the col-
lected1385opensourceprojectsinthetrainingset.Then,following
Nguyenetal.[24],foreachAPIusagegraphwesimulatetheAPI
recommendationprocess by predictingeachAPI givenitspreced-
ing context. We set the parameter dto 3, meaning that only the
context graphs involving the one, two or three APIs preceding arecommendation point are considered. The reason for setting
d
to3isthataccordingtoNguyenetal.[ 24],whend=3,thetop-10
accuracyachievedby Gralan(86.0%)isclosetothebestaccuracy
(87.1%).
Table3comparestheoriginal Gralanresults[23]withourduplica-
ted/re-implemented Gralanresultsonthesameeightsubjectprojects.
3Thereasonwedidnotre-implement APIRECisthatthesignificantlargehistorical
changerepositorydataset(i.e.,113,103changecommitsand471,730changedsource
code files according to Nguyen et al. [23]) is hard to acquire.
288
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiaoyu Liu, LiGuo Huang, and Vincent Ng
As can be seen, duplicated Gralanachieves better or comparable
top-1and top-10accuraciesthan original Gralanresultsacross all
projectsexcept Froyo-Email(top-1). Notethata strictcomparison
isnotpossibleowingtothefactthatoriginal Gralanandduplicated
Gralanwere trained on different projects.4
Evaluation Settings. For NB, SVC and RecRank, we use the
1385 projects in the training set for model training. We conduct an
8-foldcrossvalidationonthe8projectsinthetestsetasfollows.In
eachfoldexperiment,weholdoutexactlyoneprojectfortesting
andusetheremaining7projectsfordevelopment(i.e.,parameter
tuning). We repeat this experiment 8 times, each time choosing
a different project as our held-out test set. For parameter tuning,
we tune NB’s Laplace smoothing parameter αas well as libSVM
andSVMrank’s regularization parameter C to maximize the top-1
accuracyonthedevelopmentset.Welimitthelengthanusagepath
based feature to no more than 4.
4.2 Experimental Results
This section empirically answers our research questions.
RQ1.How accurate do RecRank, NB, and SVC recommend APIs in
comparison to the two baselines?
Results of NB, SVC, RecRank and the two baselines, APIREC
andduplicated Gralan (a.k.a., D-Gralan), expressed in terms of per-
project and overall top-1 accuracy and MRR, are shown in Table
4. As we can see, our proposed approaches (rows 3–5) outperform
D-Gralan (row2)inbothtop-1accuracyandMRRacrossallsubject
projects. In particular, RecRank is the best performer in terms of
both measures, achieving better top-1 accuracy than APIRECin all
eight projects.5
We further make several interesting observations. First, the pro-
posed learning-based approaches (NB, SVC, and RecRank) achieve
better top-1 accuracy and MRR than D-Gralan : top-1 accuracy im-
provesby0.7 −50%andMRRimprovesby0.13 −0.49.Comparedto
APIREC’stop-1accuracy(59.5%),SVCandRecRankachievecom-
parable or better results (i.e., 59.6 and 64.8% respectively). Encour-
agingly, RecRank improves the state-of-the-art top-1 accuracies
across all eight subject projects by 1.7-23.7%.
Todeterminewhethertheimprovementsinoveralltop-1accu-
racy and overall MRR between RecRank and other approaches are
statistically significant or not, we conduct the Wilcoxon rank-sum
test.FollowingMiller[ 20],theresultofasignificancetestcanbe
interpreted as follows. The performance difference between the
twosystemsundercomparisonis(1) highlysignificant ifthenull
hypothesis(i.e.,thereisnoperformancedifferencebetweenthetwo
systems) can be rejected at the 0.01 level (represented as “***” in
the table); (2) significant if it can be rejected at the 0.05 level (repre-
sented as “**”); and (3) moderately significant if it can be rejected at
the0.1level(representedas“*”).Otherwise,thedifferenceis statisti-
cally indistinguishable. As can be seen in Table 4, RecRank is either
highlyormoderatelysignificantlybetterthanothersystems.6To
evaluatetheamountofperformancedifferencebetweenRecRank
andeachoftheotherapproaches,wecomputeCliff’sdelta[ 7],a
non-parametric effect size measure. Results show that in each case
4The list of projects used to train original Gralanis not revealed by the authors.
5MRR results are missing for APIRECbecause they are not reported in the original
paper.
6Significancetestscannotbeconductedon APIRECbecausewedonothaveitsoutput.the delta value is greater than 0 .474, which, according to Romano
et al.[30], implies a large effect size.
RQ2.How effectiveare usagepath featuresfor APIrecommenda-
tion compared with context graphs?
To compare the effectivenessof these twotypes of features,we
employthemtotrainfourapproaches:RecRank,NB,SVCand D-
Gralan.ThisresultsintheeightcombinationsshowninTable5.For
instance, RecRank+E is the variant of RecRank trained using the
usage path features, whereas RecRank+C is the variant of RecRank
trained using context graphs. Note that the two variants within
each of the four approaches differ only with respect to the feature
set. In particular, the value of a feature is computed in the same
wayinthetwo variantsofanapproach.Forinstance,thevalue of
a feature in RecRank+C is computed in the same way as that in
RecRank+E, which was described in Section 3.4.
As can be seen in Table 5, for NB, SVC, and RecRank, the E
variant is highly significantly better than the C variant in terms
of both top-1 accuracy and MRR with a large effect size. Theseresults provide suggestive evidence that the usage path features
areconsiderablymoreeffectivethanthecontextgraph-basedfea-
turesforbothdiscriminativemodels(SVCandRecRank)andtheNB generative model. The only exception is Gralan, where its C
variantishighlysignificantlybetterthanitsEvariant.Wespeculate
that context graphs were specifically designed by their original au-
thors so that they could work well when used in conjunction with
Gralan’s generative model, but additional experiments are needed
to determine the reason.
RQ3.How effective are different classes of usage path features for
API recommendation?
To answer this question, we divide our usage path features into
12groupsbasedon(1)whetherthepathisforwardorbackward;
(2) whether the path contains fuzzy APIs or not; and (3) the length
of the path, which could be 2, 3 or 4 (recall that we limit the length
to no more than 4 in Section 4.1). To determine the contribution of
each ofthese 12groups offeatures toRecRank’s performance,we
conduct ablation experiments, where in each ablation experiment,
were-trainRecRankbyleavingoutoneormoreofthe12feature
typesand measurethe performanceof there-trainedRecRank on
thetestprojects.Intuitively,thelargerthedropinperformanceis
in an ablation experiment, the more important the missing feature
group(s) are as far as performance is concerned.
AblationresultsareshowninTable6.Foreaseofcomparison,we
show in row 1 the results of RecRank when all usage path features
are used. The remaining rows show the results when one or more
ofthefeaturegroupsareremoved.IncomparisontotheRecRank
thatusesalloftheusagepathfeatures,performancedropshighly
significantly with respect to both top-1 accuracy and MRR in three
cases:(1)whenthelength2forwardfeaturesareremoved;(2)whenallforwardfeaturesareremoved;and(3)whenalllength2features
are removed. Interestingly, removal of other feature groups does
notresultinsignificantdropsinperformance.Inparticular,removal
of any of the length 3 and 4 features causes little and sometimesno change in performance. However, it is important to note that
this by no means implies that features of lengths 3 and 4 are not
useful: these experiments only suggest that the feature group that
is being removed is not useful in the presence of the remaining
features. In other words, if two feature groups encode redundant
289
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Effective API Recommendation without Historical Software Repositories ASE ’18, September 3–7, 2018, Montpellier, France
Table 4: Evaluation results of API recommendation systems
System Top-1 Accuracy
Overall antlrGalaxy Froyo-Email Grid-Sphere ItextjGitlog4jspring
1APIREC 59.5 57.0 56.0 60.0 58.0 44.054.052.057.0
2D-Gralan 29.5*** 38.3 22.4 25.5 31.2 24.733.628.030.2
3NB34.8*** 45.1 37.3 35.3 38.3 29.438.235.630.9
4SVC 59.6* 60.1 61.2 51.1 58.9 57.356.151.447.4
5RecRank 64.8 69.4 72.4 63.5 67.6 67.767.462.958.7
System MRR
1APIREC − − − − − −−−−
2D-Gralan 0.27*** 0.29 0.37 0.30 0.34 0.250.300.270.23
3NB0.60*** 0.64 0.64 0.57 0.64 0.640.620.600.56
4SVC 0.69* 0.71 0.73 0.67 0.73 0.730.720.660.66
5RecRank 0.70 0.73 0.69 0.69 0.73 0.740.730.690.66
Table 5: Evaluation results fordifferent model-feature com-
binations
Combination Overall Top-1 Accuracy Overall MRR
1RecRank+E 64.8 0.70
2RecRank+C 36.6*** 0.58***
3SVC+E 59.6 0.69
4SVC+C 25.4*** 0.58***
5NB+E 34.8 0.60
6NB+C 16.1*** 0.47***
7D-Gralan+E 24.1*** 0.25***
8D-Gralan+C 29.5 0.27
Table 6: Feature ablation results of RecRank
System Overall Overall
Top-1 Acc MRR
All features 64.8 0.70
No length2 forward 55.8*** 0.64***
No length3 forward fuzzy 64.5 0.70
No length3 forward no-fuzzy 64.2 0.70
No length4 forward fuzzy 64.7 0.70
No length4 forward no-fuzzy 64.0 0.70
No length2 backward 64.5 0.68
No length3 backward fuzzy 64.0 0.70
No length3 backward no-fuzzy 64.7 0.70
No length4 backward fuzzy 64.1 0.70
No length4 backward no-fuzzy 64.8 0.70
No backward 60.1 0.65
No forward 39.9*** 0.48***
No length 3or4 no-fuzzy 65.1 0.70
No fuzzy 64.4 0.70
No length2 47.2*** 0.53***
information,thenremovalofoneofthemwillnotcauselargedrops
in performance. In fact, the usefulness of features of length 3 and 4
canbeseenwhencomparingthe“Nolength2forward”resultsand
Figure 4: Learning curves of API recommendation ap-
proaches on the entire test set
then “No forward” results: the performance differences between
thesetwoablatedsystemscanbeattributedtothelength3and4
features.Specifically,top-1accuracydropsbymorethan15%points
and MRR drops by 16% points when the length 3 and 4 features
areremoved.Similarly,theusefulnessofthebackwardfeaturescan
be seen by comparing the “No length 2 forward” results and the
“Nolength2”results:theperformancedifferencesbetweenthese
two ablated systems can be attributed to the backward features.
Specifically, top-1 accuracy drops by 8% points.
RQ4.What is the learning curve of each system?
Toanswerthisquestion,Figure4presentsthelearningcurvefor
each of these four systems when measured in terms of top-1 accu-
racy.Eachcurveisplottedusingfivedatapointsthatcorrespond
to using 20%, 40%, 60%, 80%, and 100% of the available trainingprojects collected in Section 4.1. As we can see, in none of the
systemsdoestop-1accuracyplateauevenwhenweuseallofthe
availabletrainingdataset.Thisimpliesthattheperformanceofeach
API recommendation system will likely to improve further as addi-
tionaltrainingprojectsaremadeavailable,whichisencouragingas
additional projects canbe easily obtained. Inaddition, we observe
thatSVCachievesconsistentlybetteroveralltop-1accuracythan
D-Gralan regardlessoftheamountofavailabletrainingdata.NB
achievesbetteroveralltop-1accuracythan D-Gralan whenmore
290
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiaoyu Liu, LiGuo Huang, and Vincent Ng
than40%oftrainingprojectsareavailablefortraining.Themost
effective learner, however, is RecRank.
5 THREATS TO VALIDITY
Our main threats to internal validity can occur to our training and
testsets.Toaddressthisconcern,wetrainallAPIrecommendation
systems on the same training set. Then each system is evaluated
on each subject project with parameters tuned on the rest of the
seven subject projects.
In addition, threats to external validity can occur during data
collection. For generalization purposes, similar to previous works
ourexperimentsareperformedonJDKAPIsonly.Meanwhile,for
comparison purposes we run experiments on the same subject
projects as the baseline API recommendation systems (i.e., Gralan
andAPIREC).
6 RELATED WORK
6.1 Code Suggestion based on Mined Software
Repositories
Inthissubsectionwesummarizesourcecodesuggestionapproaches
based on mined software repositories. Bruch et al.[5] adapt the
k-nearest-neighboralgorithmtofindmethodcallstorecommend
for particular objects. Robbes et al.[29] use change history such as
code insertion and modification to improve code completion. Hou
et al.[14] present a way of grouping API proposals from histori-
cal data for better code completion. Hill et al.[12] build a tool to
automatically complete a method by cloned code. Asaduzzaman
et al.[3] and Zhang et al.[39] both use parameter filtering to do
code recommendation. Omar et al.[26] uses an interactive wayto
generatecode.Reiss etal.[28]andStolee etal.[32]usesemantic
searchtomapretrievedcodeintowhatisaskedforbyusers.Thung
et al.[33] present an approach that learns from records of other
changes made to software systems and compares the textual de-
scriptionoftherequestedfeaturewiththetextualdescriptionsof
various API methods. Wang et al.[35] propose two quality metrics
(succinctnessandcoverage)forminedusagepatterns.Xie etal.[37]
presentMAPOtogeneratepatternsbyminingandrankingfrequent
sequencesineachclusteraccordingtothesimilarityheuristicsof
source code such as method names. Most of these approach rely
on alarge number ofsoftware historical repositories.This kind of
approach is not applicable when such repository is not available.
Differentfromtheaboveapproaches,RecRankdoesnotrelyonany
software historical repository.
6.2 Code Suggestion Using Statistical Models
Thissubsectionsummarizessourcecodesuggestionapproachesus-
ing statistical models. Gu et al.[11] adapt a neural language model
named RNN Encoder-Decoder, which encodes a word sequence
(user query) into a fixed-length context vector, and generates an
APIsequencebasedonthecontextvector.White etal.[36]apply
the RNN-LM model on lexically analyzed source code to code sug-
gestion.Allamanis etal.[1]presentNATURALIZE,whichlearns
coding conventionsto suggest naturalidentifier names andformat-
tingconventions.Theyalsoapplythebinomialmodeltoretrieve
sourcecodesnippetsgivenanaturallanguagequeryandretrievenaturallanguagedescriptionsgivenasourcecodequery[ 2].Maddi-
sonetal.[17]useProbabilisticContextFreeGrammar(PCFG)-based
modeltorepresentsourcecode.McMillan etal.[18]proposeacom-
binationofassociationbetweenqueriesandfunctionsmodeland
navigation behavior of programmers model to retrieve and visual-
ize relevant functions and their usages. Chan et al.[6] perform API
recommendation based on the textual similarity between code and
queryphrases.CodeHow[ 16]expandsthequerywiththeAPIsand
performs code retrieval by applying the Extended Boolean model,
which considers the impact of both text similarity and potential
APIsoncodesearch.MULAPI[ 38]recommendsfeaturerelatedAPI
from feature request documents. In this paper, we propose a novel
ranking-baseddiscriminativemodeltoimprovethestate-of-the-art
top-1 API recommendation accuracy.
6.3 Code Suggestion based on Code Structure
This subsection overviews source code structure based approaches.
Asaduzzaman et al.[4] recommend API by ranking the similarities
between code contexts and thecontext of the targetAPI method
call. Raychev et al.[27] extract indexed sequences of method calls
and use a statistical language model to find the highest rankedsentences to synthesize a code completion. Mou et al.[
22]p r o -
pose a tree-based convolutional neural network (TBCNN) on AST
treestructuretodetectcodesnippetsofcertainpatterns.Holmes
et al.[13] present an approach for locating relevant code that is
based on heuristically matching the structure of the code under
development to the example code. Saul et al.[31] use a random
walk approach on asubset of a callgraph inorder to recommend
source code. Ekoko et al.[8] propose an approach that leverages
thestructuralrelationshipsbetween APIstodiscoverinaccessible
APImethodsortypes.McMillan etal.[19]recommendsourcecode
examples by querying against API calls and documentations about
code structural information. Moritz et al.[21] present an approach
to recommend API usage by representing software as a Relational
TopicModel.Fowkes etal.[10]proposeaprobabilisticalgorithm
to find the most informative and parameter-free API call patterns.
In our approach, RecRank recommends API based on API usage
graphs, which includes data flow dependencies and control flowdependencies among APIs. And compared with the state-of-the-
artgraph-basedAPIrecommendationapproach Gralan,RecRank
significantly improves the top-1 accuracy of API recommendation.
7 CONCLUSIONS AND FUTURE WORK
Weproposedanoveldiscriminativere-ranking-basedAPIrecom-
mendation system, RecRank, which uses usage path-based featurestorankthetop-10APIcandidatesgeneratedby Gralan.Inanevalua-
tiononeightlargescaleopensourceprojects,RecRanksignificantly
improved top-1 accuracy by 28.5%–50.0% and MRR by 0.32–0.49in comparison to Gralan. When compared to APIREC, RecRank
improved top-1 accuracy by as much as 23.7%, yielding an overall
improvementof5.3%absolute.Perhapsevenmoreencouragingly,
we saw performance improvements in each of the eight projects.
Importantly, RecRank does not require access to a large number of
historicalcodechangesfortrainingandapplication.Infuturework,
we will extend our approach on a wider spectrum of API types and
experiment on additional projects.
291
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. Effective API Recommendation without Historical Software Repositories ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1]MiltiadisAllamanis,EarlT.Barr,ChristianBird,andCharlesSutton.2014. Learn-
ingnaturalcodingconventions.In Proceedingsofthe22ndACMSIGSOFTInterna-
tional Symposium on the Foundations of Software Engineering. ACM, 281–293.
[2]Miltos Allamanis, Daniel Tarlow, Andrew Gordon, and Yi Wei. 2015. Bimodal
modelling of source code and natural language. In Proceedings of the 32nd Inter-
national Conference on Machine Learning. JMLR.org, 2123–2132.
[3]MuhammadAsaduzzaman,ChanchalK.Roy,SamiulMonir,andKevinA.Schnei-
der. 2015. Exploring API method parameter recommendations. In Proceedings
of the 31st IEEE International Conference on Software Maintenance and Evolution.
IEEE.
[4]Muhammad Asaduzzaman, Chanchal K. Roy, Kevin A. Schneider, and Daqing
Hou.2016. ASimple,Efficient,Context-sensitiveApproachforCodeCompletion.
Journal of Software: Evolution and Process 28, 7 (2016), 512–541.
[5]MarcelBruch,MartinMonperrus,andMiraMezini.2009.Learningfromexamples
to improve code completion systems. In Proceedings of the 7th ACM SIGSOFT
Symposium on the Foundations of Software Engineering. ACM, 213–222.
[6]Wing-Kwan Chan,Hong Cheng, andDavid Lo.2012. Searchingconnected API
subgraph via text phrases. In Proceedings of the 20th ACM SIGSOFT International
Symposium on the Foundations of Software Engineering. ACM, 10.
[7]Norman Cliff. 1993. Dominance statistics: Ordinal analyses to answer ordinal
questions. Psychological bulletin 114, 3 (1993).
[8]Ekwa Duala-Ekoko and Martin P. Robillard. 2011. Using structure-based rec-
ommendations to facilitate discoverability in APIs. In Proceedings of the 25th
European Conference on Object-oriented Programming. Springer, 79–104.
[9]Rong-EnFan,Kai-WeiChang,Cho-JuiHsieh,Xiang-RuiWang,andChih-JenLin.
2008. LIBLINEAR: A library for large linear classification. Journal of Machine
Learning Research 9, Aug (2008), 1871–1874.
[10]Jaroslav Fowkes and Charles Sutton. 2016. Parameter-free probabilistic API
mining at github scale. In Proceedings of the 24th ACM SIGSOFT International
Symposium on the Foundations of Software Engineering. ACM.
[11]XiaodongGu,HongyuZhang,DongmeiZhang,andSunghunKim.2016. Deep
APIlearning.In Proceedingsofthe24thACMSIGSOFTInternationalSymposium
on the Foundations of Software Engineering. ACM, 631–642.
[12]Rosco Hill and Joe Rideout. 2004. Automatic method completion. In Proceedings
ofthe19thIEEEInternationalConferenceonAutomatedSoftwareEngineering.IEEE
Computer Society, 228–235.
[13]Reid Holmes and Gail C. Murphy. 2005. Using structural context to recom-
mendsourcecodeexamples.In Proceedingsofthe27thIEEE/ACMInternational
Conference on Software Engineering. IEEE, 117–125.
[14]Daqing Hou and David M. Pletcher. 2011. An evaluation of the strategies of
sorting, filtering, and grouping API methods for code completion. In Proceedings
ofthe27thIEEEInternationalConferenceonSoftwareMaintenance.IEEE,233–242.
[15] Thorsten Joachims. 2006. Training linear SVMs in linear time. In Proceedings of
the12thACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandData
Mining. ACM, 217–226.
[16]Fei Lv, Hongyu Zhang, Jian-guang Lou, Shaowei Wang, Dongmei Zhang, and
JianjunZhao.2015. Codehow:EffectivecodesearchbasedonAPIunderstanding
andextendedbooleanmodel(e).In Proceedingsofthe30thIEEE/ACMInternational
Conference on Automated Software Engineering. IEEE, 260–270.
[17]Chris Maddison and Daniel Tarlow. 2014. Structured generative models of natu-
ralsourcecode.In Proceedingsofthe31thInternationalConferenceonMachine
Learning. JMLR.org, 649–657.
[18]CollinMcMillan,MarkGrechanik,DenysPoshyvanyk,QingXie,andChenFu.
2011. Portfolio:finding relevantfunctions andtheir usage.In Proceedingsof the
33rdIEEE/ACMInternationalConferenceonSoftwareEngineering.ACM,111–120.
[19]CollinMcMillan,DenysPoshyvanyk,andMarkGrechanik.2010. RecommendingsourcecodeexamplesviaAPIcallusagesanddocumentation.In Proceedingsofthe
2nd International Workshop on Recommendation Systems for Software Engineering .
ACM, 21–25.
[20]DavidA.Miller.1966. Significantandhighlysignificant. Nature210,5041(1966).
[21]EvanMoritz,MarioLinares-Vásquez,DenysPoshyvanyk,MarkGrechanik,Collin
McMillan, and Malcom Gethers. 2013. Export: Detecting and visualizing APIusages in large source code repositories. In Proceedings of the 28th IEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering.IEEEPress,646–651.
[22]LiliMou,GeLi,LuZhang,TaoWang,andZhiJin.2016. Convolutionalneuralnet-
worksovertreestructuresforprogramminglanguageprocessing..In Proceedings
of the 30th AAAI Conference on Artificial Intelligence. 1287–1293.
[23]Anh Tuan Nguyen, Michael Hilton, Mihai Codoban, Hoan Anh Nguyen, Lily
Mast,EliRademacher,TienNNguyen,andDannyDig.2016. APIcoderecom-
mendation using statistical learning from fine-grained changes. In Proceedings of
the 24thACM SIGSOFT InternationalSymposium onthe Foundations ofSoftware
Engineering. ACM, 511–522.
[24]Anh Tuan Nguyen and Tien N. Nguyen. 2015. Graph-based statistical language
modelforcode.In Proceedingsofthe37thIEEEInternationalConferenceonSoftware
Engineering. IEEE, 858–868.
[25]Trong Duc Nguyen, Anh Tuan Nguyen, Hung Dang Phan, and Tien N. Nguyen.
2017. Exploring API embedding for API usages and applications. In Proceedings
of the 39th IEEE/ACM International Conference on Software Engineering . IEEE,
438–449.
[26]Cyrus Omar, YoungSeok Yoon, Thomas D. LaToza, and Brad A. Myers. 2012.
Active code completion. In Proceedings of the 34th IEEE/ACM International Con-
ference on Software Engineering. IEEE Press, 859–869.
[27]VeselinRaychev,MartinVechev,andEranYahav.2014. Codecompletionwith
statistical language models. In ACM SIGPLAN Notices, Vol. 49. ACM, 419–428.
[28]Steven P. Reiss. 2009. Semantics-based code search. In Proceedings of the 31st
IEEE/ACM International Conference on Software Engineering. IEEE Computer
Society, 243–253.
[29]Romain Robbes and Michele Lanza. 2008. How program history can improve
codecompletion.In Proceedingsofthe23rdIEEE/ACMInternationalConference
on Automated Software Engineering. IEEE Computer Society, 317–326.
[30]JeanineRomano,JeffreyD.Kromrey,JesseCoraggio,andJeffSkowronek.2006.
Appropriate statistics for ordinal level data: Should we really be using t-test and
Cohen’sd for evaluating group differences on the NSSE and other surveys. In the
Annual Meeting of the Florida Association of Institutional Research. 1–33.
[31]ZacharyM.Saul,VladimirFilkov,PremkumarDevanbu,andChristianBird.2007.Recommendingrandomwalks.In Proceedingsofthe6thACMSIGSOFTSymposium
on the Foundations of Software Engineering. ACM, 15–24.
[32]Kathryn T. Stolee and Sebastian Elbaum. 2012. Toward semantic search via SMT
solver.In Proceedingsofthe20thACMSIGSOFTInternationalSymposiumonthe
Foundations of Software Engineering. ACM, 25.
[33]Ferdian Thung, Shaowei Wang, David Lo, and Julia Lawall. 2013. Automaticrecommendation of API methods from feature requests. In Proceedings of the
28thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering .IEEE
Press, 290–300.
[34]Ellen M. Voorhees. 1999. The TREC-8 Question Answering Track Report.. In
TREC, Vol. 99. 77–82.
[35]Jue Wang, Yingnong Dang, Hongyu Zhang, Kai Chen, Tao Xie, and Dongmei
Zhang.2013. Miningsuccinctandhigh-coverageAPIusagepatternsfromsource
code. InProceedings of the 10th Working Conference on Mining Software Reposito-
ries. IEEE Press, 319–328.
[36]Martin White, Christopher Vendome, Mario Linares-Vásquez, and Denys Poshy-
vanyk. 2015. Toward deep learning software repositories. In Proceedings of
the 12th IEEE/ACM Working Conference on Mining Software Repositories. IEEE,
334–345.
[37]Tao Xie and Jian Pei. 2006. MAPO: Mining API usages from open source reposi-
tories. In Proceedings of the 3rd International Workshop on Mining Software Repos-
itories. ACM, 54–57.
[38]CongyingXu,XiaobingSun,BinLi,XintongLu,andHongjingGuo.2018. MU-
LAPI: Improving API method recommendation with API usage location. Journal
of Systems and Software 142 (2018), 195 – 205.
[39]ChengZhang,JuyuanYang,YiZhang,JingFan,XinZhang,JianjunZhao,and
Peizhao Ou. 2012. Automatic parameter recommendation for practical API
usage. In Proceedings of the 34th IEEE/ACM International Conference on Software
Engineering. IEEE Press, 826–836.
292
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. 