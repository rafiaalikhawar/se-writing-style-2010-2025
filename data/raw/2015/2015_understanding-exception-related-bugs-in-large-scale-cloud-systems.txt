Understanding Exception-Related Bugs in
Large-Scale Cloud Systems
Haicheng Chen‚Ä†, Wensheng Dou‚Ä°, Yanyan Jiang‚àó, Feng Qin‚Ä†
‚Ä†Department of Computer Science and Engineering, The Ohio State University, United States
‚Ä°State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China
‚àóState Key Lab for Novel Software Technology, Nanjing University, China
‚Ä†{chen.4800, qin.34 }@osu.edu,‚Ä°wsdou@otcaix.iscas.ac.cn,‚àójyy@nju.edu.cn
Abstract ‚ÄîException mechanism is widely used in cloud sys-
tems. This is mainly because it separates the error handling codefrom main business logic. However, the huge space of potentialerror conditions and the sophisticated logic of cloud systems
present a big hurdle to the correct use of exception mechanism.
As a result, mistakes in the exception use may lead to severeconsequences, such as system downtime and data loss. To addressthis issue, the communities direly need a better understanding ofthe exception-related bugs, i.e., eBugs , which are caused by the
incorrect use of exception mechanism, in cloud systems.
In this paper, we present a comprehensive study on 210 eBugs
from six widely-deployed cloud systems, including Cassandra,HBase, HDFS, Hadoop MapReduce, Y ARN, and ZooKeeper. For
all the studied eBugs, we analyze their triggering conditions,
root causes, bug impacts, and their relations. To the best of ourknowledge, this is the Ô¨Årst study on eBugs in cloud systems, andthe Ô¨Årst one that focuses on triggering conditions. We Ô¨Ånd thateBugs are severe in cloud systems: 74% of our studied eBugsaffect system availability or integrity. Luckily, exposing eBugs
through testing is possible: 54% of the eBugs are triggered by
non-semantic conditions, such as network errors; 40% of theeBugs can be triggered by simulating the triggering conditionsat simple system states. Furthermore, we Ô¨Ånd that the triggeringconditions are useful for detecting eBugs. Based on such relevantÔ¨Åndings, we build a static analysis tool, called DIET , and apply
it to the latest versions of the studied systems. Our results show
that DIET reports 31 bugs and bad practices, and 23 of themare conÔ¨Årmed by the developers as ‚Äúpreviously-unknown‚Äù ones.
I. I NTRODUCTION
Exception mechanism is widely used to handle errors in
cloud systems. At the time of this writing, about 7% of
the source code in twelve popular open source distributed
systems [ 1] involves exception mechanism (Figure 1), i.e.,
throwing exceptions, or being enclosed in try,catch ,o r Ô¨Ånally
code blocks. Such a widespread use of exception mechanismis mainly due to its advantages over the traditional checking-
return-value mechanism [ 2]. First, it separates the error han-
dling code from main business logic, making programs easierto reason about. Second, the runtime system automaticallypropagates exceptions up along the call stacks until they arecaught, so that error conditions will not remain unnoticed.Third, it allows developers to combine multiple exceptions by
using their common superclass exception, providing greater
Ô¨Çexibility to write the error handling code.
Unfortunately, highly diverse environments and system
complexity make exception handling in cloud systems prone
/g10/g8/g7/g12/g16
/g12/g16/g16/g16
/g9/g15/g7/g15/g11
/g15/g11
/g9/g8/g7/g15/g16
/g15/g16/g15/g7/g16/g11
/g15/g7/g15/g14
/g15/g14
/g15/g7/g11/g12
/g15/g7/g8/g16
/g8/g16/g14/g7/g16/g17
/g14/g7/g15/g13
/g15/g13/g12/g7/g8/g16
/g11/g7/g17/g10
/g11/g7/g9/g11
/g11
/g15/g7/g10/g11
/g8/g9/g8/g10/g8
/g20/g35/g46/g37/g48/g28
/g27/g41/g41/g22/g32/g32/g42/g32/g43/g24/g36/g34
/g21/g28/g31/g41/g41/g42/g5/g21/g19/g28/g44/g32/g26/g32/g50/g21/g36/g47/g32
/g20/g28/g44/g44/g28/g40/g31/g43/g28/g18/g39/g29/g28/g43/g36/g23/g28/g35/g41/g46/g45/g18/g47/g43/g41/g25/g42/g28/g43/g37/g18/g47/g32/g43/g28/g34/g32/g24/g43/g41/g42/g41/g43/g45/g36/g41/g40/g1/g41/g33/g1
/g32/g49/g30/g32/g42/g45/g36/g41/g40/g6
/g43/g32/g38/g28/g45/g32/g31/g1/g30/g41/g31/g32/g1
/g3/g2/g4
Fig. 1. Statistics of source code (excluding empty lines) that involves
exception mechanism in twelve cloud systems.‚àóThe Hadoop project includes
Hadoop common, Hadoop MapReduce, HDFS, and YARN.
to errors, which can severely hurt system reliability [ 3],
[4]. When implementing a cloud system, developers need
to constantly anticipate various conditions that may causeexceptions. Such conditions can either come from the externalenvironment (e.g., a remote node is unreachable), or be causedby internal program states (e.g., a variable is set to a wrongvalue). Furthermore, the sheer scale of cloud systems (bothhardware size and software complexity) dramatically increasesthe hurdle of correct exception handling. In this paper, we referto the mistakes in using exception mechanism as exception-related bugs, or eBugs .
Existing studies on eBugs mainly investigate the root causes
based on source code patterns [ 5]‚Äì[8], the relation between
eBugs and certain language features (e.g., aspect-oriented
programming [ 9] and Android abstractions [ 6], [8]), and devel-
opers‚Äô perception on eBugs [ 5], [6]. While having discovered
useful characteristics of eBugs, none of these studies considerthe exception triggering conditions and their relations witheBugs. These relations are essential for understanding the rootcauses and facilitating exposure and detection of eBugs. Cloud
systems often encounter complicated external and internal
triggering conditions for exceptions. This unique characteristicmotivates us to investigate the root causes of eBugs throughunderstanding their exception triggering conditions.
In this paper, we perform a comprehensive study on eBugs
in cloud systems from the perspective of triggering conditions.
In particular, this study covers 210 well-documented eBugs
selected from about 5,000 exception-related JIRA [ 10] issues
across six popular open source cloud systems, includingCassandra [ 11], HBase [ 12], HDFS [ 13], Hadoop MapRe-
duce [ 14], YARN [ 15], and ZooKeeper [ 16]. We thoroughly
analyze both their bug reports and Ô¨Åxing patches to answer
UI*&&&"$.*OUFSOBUJPOBM$POGFSFODFPO"VUPNBUFE4PGUXB SF&OHJOFFSJOH	"4&
¬•*&&&
%0*"4&
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. the following key research questions:
‚Ä¢RQ1 : How are eBugs triggered in cloud systems? It helps
us understand the conditions that trigger eBug-bound ex-ceptions. Our Ô¨Åndings can beneÔ¨Åt developers to effectivelyexpose eBugs in cloud systems.
‚Ä¢RQ2 : What is the relation between the triggering conditions
and the root causes of eBugs? Our in-depth analysis on the
root causes and their relations with the triggering conditionscan facilitate eBug detection in cloud systems.
‚Ä¢RQ3 : What are the impacts of eBugs on cloud systems? By
analyzing their impacts, we can understand the severity ofeBugs in cloud systems.
To the best of our knowledge, this is the Ô¨Årst comprehensive
study on eBugs in real-world cloud systems, and the Ô¨Årstone from the perspective of triggering conditions. Throughthis study, we have obtained many interesting Ô¨Åndings thatopen up new research opportunities to combat eBugs in the
cloud. The main Ô¨Åndings are: (1) More than half (54%) of
the studied eBugs are exposed by non-semantic triggeringconditions, most (75%) of which are network errors and Ô¨Ålesystem errors (Finding 1). (2) Most (86%) of the eBugs do not
have strong timing requirements on their triggering conditions(Finding 2). (3) 41% of the eBugs are caused by handling an
exception in an overly-general (thus incorrect) way. Among
them, many (34%) are caused by incorrectly applying thesame handling operations to the exceptions that have differenttriggering condition types (Finding 7). (4) 10% of the eBugs
are caused by creating exception objects that do not describe
their triggering conditions accurately (Findings 3,4, and 5).
(5) Most (74%) of the eBugs affect the dependability of cloudsystems, e.g., by crashing nodes or losing data, and developersconsider most (82%) of them severe (Finding 8).
These Ô¨Åndings show the severity of eBugs in cloud systems,
while revealing many new opportunities to combat them. First,we can expose eBugs by simulating non-semantic triggeringconditions at simple system states, e.g., consistent globalstates. Second, we can detect eBugs by analyzing exception
triggering conditions. For instance, we can detect inaccurate
exceptions by checking whether the exceptions accuratelydescribe their triggering conditions. As another example, wecan detect overly-general handlers by examining if the samehandling code is applied to exceptions with different triggering
condition types. Based on these Ô¨Åndings, we build a static
analysis tool, called DIET , to detect inaccurate exceptions
by analyzing their exception classes and error messages. Byapplying DIET to the latest versions of the studied systems,we Ô¨Ånd 31 new bugs and bad practices. At the time of this
writing, developers have conÔ¨Årmed 23 of them. Note that, an
inaccurate exception can be an eBug if it affects the correctness
or performance of a checked system or a bad practice if it may
introduce a potential eBug in future system versions.
In summary, we make the following key contributions:
‚Ä¢We present the Ô¨Årst comprehensive study on eBugs from the
perspective of triggering conditions in six widely-deployedcloud systems.TABLE I
INVESTIGATED BUGREPORTS IN THE STUDIED SYSTEMS
System CA HB HF MR YN ZK Total
Retrieved 1,336 1,576 763 460 457 210 4,802
Studied 40 92 31 16 23 8 210
‚Ä¢We unveil many interesting Ô¨Åndings and explain their impli-
cations for combating eBugs in cloud systems. For example,we Ô¨Ånd that triggering conditions and their relations withroot causes provide valuable information for the developersof cloud systems.
‚Ä¢Based on our Ô¨Åndings, we build a static analysis tool, called
DIET, and evaluate it using the latest versions of the studied
systems. We have exposed many new bugs and bad practicesthat have been conÔ¨Årmed by the developers of these systems.
‚Ä¢We provide a large benchmark of eBugs in cloud systems,which can be used to evaluate the effectiveness of the toolsthat expose and detect eBugs in cloud systems. Our eBugdatabase is available at [ 17].
II. M
ETHODOLOGY
A. Target Systems
To understand the characteristics of eBugs in real-world
cloud systems, we select the target systems based on threecriteria: (i) The systems must be diverse for an unbiased
dataset. (ii) The systems should be mature and popular, so
that we can understand the real problems faced by developers.(iii) The systems should be open source and have public issuetracking systems.
With these requirements in mind, we identify the following
six cloud systems: (i) Cassandra [ 11], a highly available
peer-to-peer NoSQL database; (ii) HBase [ 12], a master-
slave NoSQL database; (iii) HDFS [ 13], a distributed Ô¨Åle
system; (iv) Hadoop MapReduce [ 14], a distributed data
processing framework; (v) YARN [ 15], a distributed resource
management system; and (vi) ZooKeeper [ 16], a distributed
coordination service.
B. EBug Collection
All the target systems use JIRA [ 10] to manage their issues.
Over a time span of more than ten years (from 2007 to 2018),more than 60,000 issues were submitted for these systems.It is time-consuming and impractical to manually inspect allthese issues and identify eBugs from them. We therefore applya few Ô¨Åltering rules to identify the relevant issues.
First, we use the following JQL (JIRA Query Language)
statement to retrieve potentially relevant issues:
issuetype = Bug ANDstatusIN(Resolved,
Closed) ANDresolution = Fixed ANDtext
Àú"exception *"
With this JQL statement, we narrow down all the issues to only
fully-resolved (Resolved orClosed instatus ) and Ô¨Åxed bugs

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. that contain the keyword exception orexceptions . This JQL
returns us with 4,802 issues (Row ‚ÄúRetrieved‚Äù in Table I1).
We further narrow down the retrieved issues by requiring
each selected bug report to include a full exception stack traceand a Ô¨Åxing commit. The exception stack trace and the Ô¨Åxingcommit are critical for us to fully understand an eBug becausethey contain information like what exception is thrown andhow the eBug occurs. We further remove the ones whose bugsare located in test Ô¨Åles or non-Java Ô¨Åles, because they are notrelated to the core functionality of the target systems. Thisleaves us with 1,561 reports.
Finally, we manually inspect the remaining 1,561 reports
and keep the ones that are related to exception mechanism as
discussed in ¬ß III. This leaves us with 210 issues for further
analysis (Row ‚ÄúStudied‚Äù in Table I). In this paper, we denote
an eBug using its bug ID in JIRA, i.e.,
SYS-### , whereSYS
is the system name and ### is the eBug‚Äôs issue ID.
C. EBug Analysis
To answer our three research questions, we perform an in-
depth analysis on each eBug based on the bug description(including the exception stack trace), the discussion amongdevelopers in the report, and the source code of the targetsystem (including the Ô¨Åx). We also refer to online resources,
e.g., documentation, to facilitate our understanding on eBugs.Through this process, we recover the full picture of how each
eBug is triggered (RQ1), how the target system incorrectlyuses exception mechanism (RQ2), and how each eBug affectsthe system (RQ3). Then, we classify eBugs according to their
triggering conditions, root causes, and bug impacts.
D. Threats to V alidity
To maintain the accuracy of our study, we employ different
measures to improve our understanding. For example, we usethe Ô¨Ånal Ô¨Åxing commit and sometimes reproduce an eBug toconÔ¨Årm its triggering condition and root cause.
Even though we try to be unbiased, readers need to un-
derstand the following limitations of our study. First, all ofour subject systems are open source cloud systems. EBugs incommercial cloud systems or other types of software systemsmay have different characteristics. Additionally, we may misssome eBugs due to our selection process. For example, we may
exclude eBugs that do not have full exception stack traces in
their bug reports. Finally, we only study eBugs in Java. Whilethe exception mechanism in Java is generally similar to theones in other languages (e.g., C++, C#, and Python), Java hasa few unique features, which may affect developers‚Äô practicein using exceptions. Therefore, readers need to be cautiouswhen extending our Ô¨Åndings to other scenarios.
III. E
XCEPTION MECHANISM
Figure 2shows the model of exception mechanism. During
program execution, an unexpected error, referred to as atriggering condition , occurs. Based on the error type, Java
1For simplicity, we use CA, HB, HF, MR, YN, and ZK to represent
Cassandra, HBase, HDFS, MapReduce, YARN, and ZooKeeper, respectively./g5/g24/g12/g14/g21/g23/g17/g20/g19
/g3/g22/g14/g11/g23/g17/g20/g19/g5/g24/g12/g14/g21/g23/g17/g20/g19
/g8/g22/g20/g21/g11/g15/g11/g23/g17/g20/g19/g9/g14/g11/g12/g23/g14/g13
/g7/g14/g23/g16/g20/g13/g5/g24/g12/g14/g21/g23/g17/g20/g19
/g6/g11/g19/g13/g18/g17/g19/g15
/g10/g22/g17/g15/g15/g14/g22/g17/g19/g15
/g3/g20/g19/g13/g17/g23/g17/g20/g19/g3 /g1 /g2 /g4
 /g1
 /g2
 /g4
1void B(...) throws OtherException {
2 try { A(...);
3 }catch (SomeException e) {
4 someHandling(...);
5 throw new OtherException(e);
6 }}
Fig. 2. The model of exception mechanism, and the code snippet of method
B() that handles the exception thrown from method A().
runtime creates and propagates an exception. The propagation
starts from a throw statement and ends at a catch statement,
along the call stack in the reverse call order. After a methodcatches the exception and performs exception handling (BoxesA, B, and D), it can optionally re-throw the caught exception(Box A), or wrap the caught exception in a new exceptionbefore re-throwing it (Box B). Either way, the re-thrown ex-
ception starts a new propagation. Along the propagation path,
some methods (including the one where the
throw statement
locates) may not catch the exception. Instead, these methodscan specify the exception class in the method signatures usingthe
throws keyword. In this way, a method notiÔ¨Åes its callers
that it can propagate the speciÔ¨Åed exception, so that the callers
can implement proper exception handling as needed. Box C
represents the scenario where a method does not catch theexception but speciÔ¨Åes it in the signature. We consider bothcatching an exception and specifying an exception in thesignature as a method reacting to the exception.
The lower-half in Figure 2shows the code snippet of
B(). WhenA() throws aSomeException ,B() catches and
handles it (Lines 3-4). B() then wraps the SomeException in
a newly created OtherException , which it throws at Line 5.
B() also speciÔ¨Åes the re-thrown OtherException (Line 1)
so that its callers can react to the exception accordingly.
We further deÔ¨Åne the following terms used in our study:
‚Ä¢Root exception : The initially-created exception due to the
triggering condition, e.g., the left diamond shape in Figure 2.
‚Ä¢Cause exception : If an exception eais wrapped by another
exception eb,eais the cause exception ofeb. In the example
above, the SomeException is the cause exception of the
OtherException .
‚Ä¢EBug : A bug that occurs in creating, throwing, catching, or
handling an exception.
IV . T RIGGERING CONDITIONS
The triggering condition is the key to trigger an eBug. In
this section, we study both the types of triggering conditions(¬ßIV-A ) and their timing requirements (¬ß IV-B ).
A. Triggering Condition Types
We Ô¨Årst examine whether the triggering conditions are re-
lated to program semantics. Semantic conditions are speciÔ¨Åc toeach individual target system, while Ô¨Åndings on non-semantic

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. TABLE II
TRIGGERING CONDITIONS OF THE STUDIED E BUGS AND THEIR TYPICAL SCENARIOS IN EACH SYSTEM
Triggering Condition (# eBugs) Scenario (# eBugs) CA HB HF MR YN ZK
Non-semantic condition (114)Network error (46)Premature disconnection (17) 085112
Local timeout (12) 252030
Connection refused (11) 180110
Other network errors (6) 060000
File system error (40)File corrupted (23) 10 11 1 1 0 0
File not found (13) 353200
Other Ô¨Åle system errors (4) 202000
Out of resource (16)Out of memory (5) 121100
Out of disk space (5) 101111
Port conÔ¨Çicted (3) 111000
Out of other resources (3) 003000
Untimely interrupt (12)Thread interrupted when invoking a210360blocking method (12)
Semantic condition (96) - - 17 45 12 6 11 5
Total 210 40 92 31 16 23 8
conditions are general to a broader class of cloud systems.
We notice that the majority of the studied eBugs (114 outof 210) are triggered by non-semantic conditions such as anode being unreachable. The remaining eBugs (96 out of 210)are triggered by semantic conditions such as a variable beingassigned with an incorrect value.
To better understand non-semantic conditions, we further
classify them into the following four categories based onthe error types: (i) Network error : The system encounters a
failed network connection. (ii) File system error : The system
encounters a failed Ô¨Åle system operation, e.g., opening a non-existent Ô¨Åle. (iii) Out of resource : System resource, such as
memory space, is used up. (iv) Untimely interrupt : A system
interrupt occurs when a thread is sleeping or waiting, e.g., aftercalling
Thread.sleep() . Table IIshows the typical scenarios
of each condition type and their distribution.
Finding 1 :Most (75%) of the non-semantic conditions are
either network errors or Ô¨Åle system errors.
1) Network Error: Cloud systems are deployed on network
and thereby strive to handle network errors in both designand implementation phases. However, network error is stillthe most common (40%) type of non-semantic condition in
the studied eBugs. With further investigation, we Ô¨Ånd that
most (87%) of the network errors occur in the followingthree scenarios: (i) Premature disconnection . For example,
in
HDFS-7009 , a DataNode throws an EOFException when
a NameNode terminates the connection after sending par-tial data to the DataNode. (ii) Local timeout . For instance,
in
HBASE-6299 , an HMaster throws a SocketTimeout-
Exception if it times out before receiving a response from
a RegionServer. (iii) Connection refused .I nYARN-196 ,a
NodeMagager tries to connect to a ResourceManager thathas not started. As a result, the remote operating systemrejects the connection, causing the NodeManager to throw a
ConnectException . The remaining (13%) network errors
are caused by various reasons, such as failed routing andunsuccessful host name resolution.
2) File System Error: Cloud systems store critical user
and system data on Ô¨Åle systems. Since Ô¨Åle systems are never
perfect [ 18], cloud systems are expected to correctly react to
Ô¨Åle system errors. For example, when failing to read a datachunk, a distributed Ô¨Åle system (e.g., HDFS) may start thedata recovery process using a remote data replica. However,we Ô¨Ånd that a signiÔ¨Åcant number of eBugs are triggered byÔ¨Åle system errors. Among these errors, the most frequentscenarios are Ô¨Åles being corrupted and Ô¨Åles not found: (i) File
corrupted . For example, in
CASSANDRA-12728 , a Cassan-
dra server throws an EOFException when it unexpectedly
reads the end of a truncated hint Ô¨Åle. (ii) File not found .
For instance, in HBASE-9563 , a restarted HMaster throws a
FileNotFoundException when it fails to Ô¨Ånd a znode Ô¨Åle
to read. Other Ô¨Åle system errors include access mode violation,Ô¨Åle path resolution failure, and disk failure.
3) Out of Resource: Cloud systems interact with system
resources extensively. However, the desired resource may notbe always available. 14% of the non-semantic eBugs aretriggered when certain resource is exhausted. Among the 16out-of-resource eBugs, 13 are triggered due to running outof (i) memory space , (ii) disk space , or (iii) host ports .F o r
example, in
CASSANDRA-11540 , a Cassandra server throws a
BindException when it tries to bind an occupied port. Other
resources include opened Ô¨Åle handlers and disk quotas.
4) Untimely Interrupt: Cloud systems are highly concur-
rent. They may try to perform two conÔ¨Çicting operations atthe same time. When this happens, one operation may stop theother via interrupt. We Ô¨Ånd that, a considerable amount (11%)
of non-semantic eBugs are triggered by untimely interrupts.
For example,
YARN-2846 is triggered when one thread of a

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. TABLE III
TIMING REQUIREMENTS ON E BUGTRIGGERING CONDITIONS
Condition TypeTiming Requirement
Weak Moderate Strong
Network error 9 36 1
File system error 32 5 3Out of resource 5 11 0
Untimely interrupt 0 10 2
Semantic condition 39 34 23
Total 85 96 29
NodeManager process is checking the status of a container,
while another thread is shutting down the whole process.
5) Semantic Condition: About half (46%) of the root
exceptions are triggered by semantic conditions . Semantic
conditions are closely related to program logic, and thereby
can be speciÔ¨Åc to each individual system. For example, in
CASSANDRA-5725 , a Cassandra server throws an Unknown-
ColumnFamilyException when it tries to access a nonex-
istent column family. From this example, we can see that
triggering this type of eBugs needs domain knowledge about
the target systems, e.g., column family is a data structureused in Cassandra to organize both user data and system data.However, other systems, e.g. HDFS, do not have this concept.Since 46% of the conditions are relevant to semantics, theycall for more attention from our communities.
B. Timing Requirements on Triggering Conditions
Finding 2 :Most (86%) of the eBugs do not have strong
timing requirements on their triggering conditions.
EBugs can be triggered only when triggering conditions
occur at certain system states. To understand the difÔ¨Åculty of
triggering eBugs in cloud systems, we further analyze eacheBug‚Äôs timing requirement on its triggering condition. Weuse a similar measurement as a previous bug study in cloudsystems [ 19], and classify the timing requirements into three
categories, as shown in Table III.
‚Ä¢Weak (85 eBugs). To trigger this type of eBugs, the trig-
gering condition can occur at any consistent global state, orbefore the system starts. For example,
ZOOKEEPER-2757
can be triggered whenever a user issues a delete commandwith an invalid pathname.
‚Ä¢Moderate (96 eBugs). The triggering condition needs to
occur on a node when it is in certain states. To trigger theseeBugs, we only need to consider the runtime state of onenode. For example,
MAPREDUCE-5251 can be triggered by
simulating out of disk space when a reduce task tries towrite a map output to disk. There is no need to check the
states of other nodes in the system.
‚Ä¢Strong (29 eBugs). The triggering condition needs to occur
on a node when both the current node and other nodes are incertain states. To trigger these eBugs, we need to consider/g6/g20/g11/g12/g12/g26/g23/g11/g25/g14 /g1/g5/g29/g12/g14/g22/g25/g17/g21/g20
 /g8/g17/g24/g24/g17/g20/g15 /g1/g10/g14/g11/g12/g25/g17/g21/g20
/g9/g27/g14/g23/g18/g30/g2/g15/g14/g20/g14/g23/g11/g18 /g1/g10/g14/g11/g12/g25/g17/g21/g20
/g4/g1/g19/g14/g25/g16/g21/g13 /g1/g25/g16/g11/g25/g1/g23/g14/g11/g12/g25/g24/g1/g25/g21/g1
/g21/g20/g18/g30/g1/g24/g21/g19/g14/g1/g14/g29/g12/g14/g22/g25/g17/g21/g20/g24/g3/g6/g20/g12/g21/g23/g23/g14/g12/g25 /g1/g10/g14/g11/g12/g25/g17/g21/g20 /g1/g7/g21/g15/g17/g12
/g1/g2
 /g1/g2
/g4/g1/g19/g14/g25/g16/g21/g13 /g1/g28/g17/g25/g16/g1
/g11/g20/g30/g1/g23/g14/g11/g12/g25/g17/g21/g20/g3/g4/g1/g19/g14/g25/g16/g21/g13 /g1/g28/g17/g25/g16/g1
/g20/g21/g1/g23/g14/g11/g12/g25/g17/g21/g20/g3
Fig. 3. Four different types of eBug root causes. For each type, we show the
correct version on the left (green) and the buggy version on the right (red).
TABLE IV
STATISTICS OF E BUGROOT CAUSES
Root Cause eBug # CA HB HF MR YN ZK
Inaccurate exception 21 384330
Missing reaction 36 12 11 3 3 4 3
Overly-general reaction 87 13 42 14 6 11 1
Incorrect reaction logic 66 12 31 10 4 5 4
Total 210 40 92 31 16 23 8
the states of multiple nodes. For example, YARN-3842 can
only be triggered when a MapReduce ApplicationMasterasks a NodeManager to start a container, while the Node-Manager is still in the initialization phase.
V. R
OOT CAUSES
Based on the exception mechanism shown in Figure 2,
eBugs can be classiÔ¨Åed into three categories: (1) Inaccurate
exception , if the eBug is caused by creating an inaccurate ex-
ception; (2) Missing reaction , if the eBug is caused by neither
catching nor specifying an exception in the method signature;
and (3) Incorrect reaction , if the eBug incorrectly reacts to
an exception. Incorrect reaction can be further broken downinto overly-general reaction , where different exceptions are
incorrectly handled in the same way, and incorrect reaction
logic , where the reaction logic is incorrect for all exceptions.
Figure 3illustrates these four types of eBugs, and Table IV
shows their distribution. Note that, previous studies have also
classiÔ¨Åed eBugs based on their root causes [ 5]‚Äì[8]. Unlike
them, the focus of our classiÔ¨Åcation is on the relation betweenthe triggering conditions and the root causes (RQ2).
A. Inaccurate Exception
A newly-created exception is expected to accurately repre-
sent the triggering condition so that the system can correctlyreact to the error. This requires the exception to instantiate thecorrect class and contain correct information such as an error
message and a cause exception . Table Vshows the number of
eBugs where the exception instantiates a wrong class, has awrong error message, or misses a cause exception.
1) Wrong Exception Class: Exception class is the primary
source to indicate the triggering condition. An exception
instance with a wrong class will not be handled correctly.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. TABLE V
THETYPE DISTRIBUTION OF INACCURATE EXCEPTION E BUGS
Type Wrong Class Wrong Message Lacking Cause Total
eBug # 13 5 3 21
1 void updateMetaLocation() throws IOException {
2 if(waitForRootServerConnection() == null )
3- throw new NullPointerException(...);
4+ throw new IOException(...);
5 }
6 void process() {
7 try { updateMetaLocation();
8 }catch (IOException e) { cleanup(); }
9 }
Fig. 4. EBug HBASE-3164 .ANullPointerException is thrown when
a remote node is unreachable.
We Ô¨Ånd two ways of creating incorrect exceptions: (i) In
Ô¨Åve eBugs, the incorrect exception class is the superclass ofthe intended one. (ii) In the other eight eBugs, the incorrectexception class has no relation with (i.e., neither a superclassnor a subclass of) the intended one.
Finding 3 :Using a superclass of the intended exception
makes it difÔ¨Åcult to perform correct exception handling.
We Ô¨Ånd that IOException is the only culprit class in all the
Ô¨Åve eBugs that use a superclass of the intended exception. Forexample, in
HDFS-8224 , a DataNode throws an IOException
when it tries to read the checksum granularity from a corruptedÔ¨Åle. Since other disk failures, e.g., out of disk space, alsotrigger
IOException , the DataNode cannot differentiate the
exceptions to perform data recovery only for Ô¨Åle corruption.To Ô¨Åx this bug, a dedicated subclass exception,
Invalid-
ChecksumSizeException , is used to denote the case where
the Ô¨Åle storing the checksum granularity is corrupted.
Finding 4 :In half of the eBugs that create a totally
misleading exception, the exception class is inconsistent
with its triggering condition.
When the newly-created class is neither a superclass nor
a subclass of the intended one, the exception cannot be
correctly caught by its intended catch block. Take eBug
HBASE-3164 in Figure 4as an example. When a Region-
Server opens a META region, it needs to report the up-
date to the RootServer. If the RootServer is currently un-reachable,
waitForRootServerConnection() will return
anull (Line 2). Instead of throwing an IOException that
semantically matches the triggering condition (i.e., network
error), the buggy code throws a NullPointerException
(Line 3). ‚ÄúWe actually throw the NPE [when] it‚Äôs not an actualNPE‚Äù, a developer also points out. As a result, even thougha proper
catch block exists (Line 8), it will not catch the
exception, leaving the META region inaccessible.TABLE VI
THETRIGGERING CONDITIONS AND EXCEPTION CLASSES OF FOUR
EBUGS WITH TOTALLY MISLEADING EXCEPTION CLASSES
Bug ID Triggering Cond. Exception Class
CASSANDRA-11448 Out of resource RuntimeException
HBASE-3164 Network error NullPointerException
HDFS-2484 File system error LeaseExpiredException
YARN-2846 Untimely interrupt IOException
TABLE VII
EXCEPTION CLASSES THAT ARE TRIGGERED MORE THAN ONCE BY
NON-SEMANTIC TRIGGERING CONDITIONS
Triggering Cond. N‚Ä†P‚àóTop 4 Exception Class (#)‚ô£
Network error 8 91%ConnectException (11)
IOException (10)
SocketTimeoutException (6)
EOFException (5)
File system error 4 78%EOFException (11)
FileNotFoundException (10)
IOException (8)
IllegalArgumentException (2)
Out of resource 3 75%OutOfMemoryError (5)
IOException (4)
BindException (3)
Untimely interrupt 1 75% InterruptedException (9)
‚Ä†N is the number of exception classes.‚àóP is the percentage of eBugs the
classes cover the triggering condition.‚ô£Due to space limit, we only show
the top four exception classes for network errors.
Among the eight eBugs in this category, four of them are
triggered by non-semantic conditions. We Ô¨Ånd that all the
incorrect classes are inconsistent with their conditions (Table
VI). This makes us wonder: Does each type of non-semantic
condition have a set of frequently triggered exception classes?If so, the inconsistency between the common classes and thetriggered ones may help detect inaccurate exception eBugs.
We analyze all the 114 eBugs with non-semantic triggering
conditions. For each eBug, we use the root exception class
because it is directly related to the triggering condition.To prevent using the wrong exception classes in inaccurateexception eBugs, we employ their Ô¨Åxing patches to retrievethe correct exception classes.
Finding 5 :F or non-semantic triggering conditions, a few
(1-8) exception classes can cover most eBugs (75-91%).
As Table VII shows, each condition type triggers only
a few exception classes more than once, and these classes
cover a majority of eBugs with the corresponding conditiontype. For example, three exception classes cover 75% of theeBugs that are exposed by the triggering condition of ‚Äúoutof resource‚Äù. We also notice that these frequently triggeredclasses do not include the misleading ones shown in Table VI.
For example, the
RuntimeException inCASSANRA-11448
is not a frequently triggered class for the ‚Äúout of resource‚Äù

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. /g2/g4
/g3/g3/g2/g2
/g1/g5/g2/g1/g2/g5
/g2/g3/g4/g5/g6/g6/g19/g14/g9/g11/g17 /g1/g16/g12/g1
/g5/g13/g8/g18/g18/g11/g18NullPointerExceptionIllegalArgumentException
/g7/g10/g10/g19/g17/g17/g11/g15/g10/g11
Fig. 5. Exception classes that occur in missing reaction eBugs.
1 void call() {
2 try { reacquireContainer(...);
3+ } catch (InterruptedIOException e) {
4+ LOG.warn(...);
5 }catch (IOException e) {
6 // FileNotFoundException can reach here.
7 deactivateContainer(...);
8 }}
9
10 int reacquireContainer(...) throws IOException {...}
Fig. 6. EBug YARN-5103 . Handling IOException and its subclasses in
the same way stops a running YARN container prematurely.
triggering condition.
2) Wrong Error Message or Lacking Cause Exception:
When an exception carries a wrong error message, or anexception does not wrap a cause exception, developers may
lack critical information about the triggering condition for
diagnosing the failure. For example, in
HDFS-7899 ,i fa
DataNode disconnects with an HDFS client, the client willthrow an
EOFException with a message stating: ‚ÄúPremature
EOF: no length preÔ¨Åx available‚Äù. As the bug reporter pointsout, this error message ‚Äúis not very clear to a user‚Äù because
it does not indicate that the DataNode is unreachable.
B. Missing Reaction
Once an exception is thrown, some methods in the call
stack need to react to it. If these methods neither catch the
exception, nor specify it in their signatures, we refer to this
type of mistake as a missing reaction eBug. We examine the
Ô¨Åxing patch of an eBug to identify which methods should reactto an exception. To gain more insights, we also analyze theexception classes that are missed.
Finding 6 :IllegalArgumentException (19%) and NullPoint-
erException (14%) are the dominant exception classes thatcause missing reactions.
As shown in Figure 5, we Ô¨Ånd that many exception
classes can be missed by developers. Among them, twoclasses are more frequent than others:
IllegalArgument-
Exception andNullPointerException . For example, in
CASSANDRA-5701 , a Cassandra server throws an Illegal-
ArgumentException when a client queries a nonexistent
column family from it. Since none of the methods in the callstack handles this exception, the Java thread crashes, and theclient gets disconnected abruptly.TABLE VIII
THERELATION BETWEEN THE TRIGGERING CONDITIONS OF THE
INCORRECTLY REACTED EXCEPTION AND THE CORRECTLY REACTED
ONES IN OVERLY -GENERAL REACTION E BUGS
Relation Same Type Different Types Unknown Total
eBug # 48 30 9 87
C. Overly-General Reaction
If a method can throw multiple exception classes, it
is a norm for developers to specify only their com-mon parent class in the method signature. For exam-ple, method
reacquireContainer() in Figure 6speci-
Ô¨Åes only an IOException (Line 10), but it can throw
subclasses like InterruptedIOException andFileNot-
FoundException .
However, this common practice poses a big challenge for
accurate exception handling, because developers need to beaware of all the potential exceptions a method can throw. Asa result, developers can make overly-general reaction eBugs,i.e., incorrectly handling multiple exceptions in the same waywhile they should be treated differently. We Ô¨Ånd that overly-
general reaction causes many (41%) eBugs.
For example, eBug
YARN-5103 in Figure 6incorrectly
applies the same handling to IOException and its subclasses,
such asInterruptedIOException andFileNotFound-
Exception . When a NodeManager restarts, it will invoke
reacquireContainer() to reload the information of a
running container and wait for its completion (Line 2). Ifthe NodeManager interrupts the waiting thread because itneeds to restart again,
reacquireContainer() will throw
anInterruptedIOException . The method call() incor-
rectly catches and handles this exception in the same wayas other
IOException s (Lines 5-7). Therefore, the running
container stops prematurely for a benign interrupt (Line 7).Instead, the method
call() should catch the Interrupted-
IOException separately and let the container continue run-
ning (Lines 3-4).
Finding 7 :In many (34%) overly-general reaction eBugs,
the incorrectly reacted exception and the correctly reacted
ones are caused by different types of tiggering conditions.
Although multiple exceptions can be combined and handled
in the same way, exceptions with different triggering conditiontypes (i.e., network error, Ô¨Åle system error, out of resource,untimely interrupt, and semantic condition in ¬ß IV-A ) usually
represent different errors and may require different handling.
We analyze the relation between the correctly reacted excep-
tions (whose reaction is not changed in the Ô¨Åxing patch) andthe incorrectly reacted one (as speciÔ¨Åed in the eBug report) ineach eBug to see if they are triggered by different triggeringcondition types (Table VIII). If the incorrectly reacted excep-
tion and the correctly reacted ones are caused by different
triggering condition types, we label the eBug as different type .

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. 1 List<ServerName> fetchServerAddresses() {
2 try {return listServerNames();
3 }catch (KeeperException e) {
4- return null;
5+ return new ArrayList<ServerName>(0);
6 }}
Fig. 7. EBug HBASE-4045 . Instead of a null , the handler should return
an emptyArrayList when server names cannot be retrieved.
TABLE IX
EBUGFAILURE SYMPTOMS
Symptom eBug #
Node downtime 48
Incorrect error message 44
Data loss or potential data loss 31
Hang or performance downgrading 26
Resource leak/exhaustion 10
Operation failure‚Ä†51
Total 210
‚Ä†We only consider an eBug as causing operation failure if it does not have
any other symptom.
If their triggering condition types overlap, we label the eBug
assame type . We cannot infer the triggering conditions of the
correctly handled exceptions in nine eBugs due to insufÔ¨Åcientinformation around the
throw statements. So, we label them
asunknown . We observe that, in many (34%) overly-general
reaction eBugs, the exceptions are triggered by differentcondition types. For example in
YARN-5103 (Figure 6), the
InterruptedIOException is triggered by an untimely in-
terrupt, while other IOException s are triggered by different
condition types, like a FileNotFoundException triggered
by a Ô¨Åle system error.
D. Incorrect Reaction Logic
If a handler is incorrect for all the exceptions it handles,
we say that it has incorrect reaction logic . TakeHBASE-4045
in Figure 7as an example. In HBase, when a RegionServer
tries to replicate its data to a different cluster, it needs tofetch the destination server names from ZooKeeper (Line 2).If ZooKeeper is unreachable, an exception will be thrown.
The handler catches it (Line 3) and returns a
null (Line 4).
The caller of fetchServerAddresses() does not expect the
return value to be null , and dereferences it (not shown in the
Ô¨Ågure), which crashes the thread. Instead, the handler should
return an empty ArrayList , which the caller can handle
properly. Detecting this type of eBugs requires understandingthe system logic, which remains a challenge for future work.
VI. B
UGIMPACTS
We study the eBug impacts from two perspectives. First, we
analyze their failure symptoms to understand how they affectthe systems (Table IX). Then, we use the issue priority to infer
if developers consider an eBug as a severe defect (Table X).TABLE X
JIRA I SSUE PRIORITY OF E BUGS
Priority Blocker Critical Major Minor Trivial Total
eBug # 21 42 110 33 4 210
Finding 8 :74% of the eBugs affect the availability (e.g.
node downtime) and integrity (e.g., data loss) of cloudsystems. Moreover , developers consider most (82%) of themas severe defects (i.e., priority not lower than major).
Overall, we Ô¨Ånd that, eBugs have various failure symptoms.
Many of them affect the system availability (e.g., node down-time) and integrity (e.g., data loss). Sometimes, eBugs can turna transient and benign error (i.e., an exception) into a severefailure. For example, in
YARN-196 , a NodeManager aborts
only because it fails to register itself with the ResourceMan-ager due to a transient network partitioning. A simple retryÔ¨Åxes the eBug, and allows the NodeManger to start.
We also Ô¨Ånd that, developers consider most (82%) of the
eBugs as severe defects, i.e., having a priority of blocker ,
critical ,o r major . Even the seemingly most benign type of
symptoms, i.e., incorrect error message , can cause much
trouble for end users of cloud systems: two thirds of these
cases are marked as major or a higher priority in JIRA.
VII. L
ESSONS LEARNED AND APPLICATIONS
Our study shows that eBugs seriously affect the depend-
ability of cloud systems (Finding 8). In this section, we
discuss implications for existing approaches and opportunitiesfor new research to combat eBugs in cloud systems (¬ß VII-A ,
¬ßVII-B , and ¬ß VII-C ). Additionally, we discuss our experiences
in applying the Ô¨Åndings to detect new inaccurate exceptionsin the studied cloud systems (¬ß VII-D ).
A. Testing Cloud Systems under Adversarial Conditions
Software testing is critical in exposing bugs before software
release. Many testing techniques have been proposed forexposing or detecting software bugs [ 20]‚Äì[22], but few are
designed for cloud systems [ 23]‚Äì[25].
Cloud systems usually run in complex cluster environments,
and may encounter different kinds of adversarial conditions,e.g., network errors and Ô¨Åle system errors. Improperly han-dling these conditions can lead to severe consequences. AsFigure 1shows, cloud systems often use exception mechanism
to handle adversarial conditions. However, Finding 1indicates
that there are issues in handling some conditions. Existing
testing techniques on cloud systems have tried to inject adver-sarial conditions such as network partitioning [ 23], [25]‚Äì[28],
Ô¨Åle corruption, and out of disk space [ 29]. However, other
adversarial conditions in Table II, such as connection refused,
Ô¨Åle not found, port conÔ¨Çict, and untimely interrupt, have not
been attempted in cloud systems. Moreover, researchers and
developers can use the triggering conditions summarized in¬ßIVas a checklist to test cloud systems. For example, by

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. limiting the available memory and disk space during normal
testing, eBugs that are triggered by either ‚Äúout of memory‚Äù or‚Äúout of disk space‚Äù become more likely to be exposed.
To trigger an eBug, testing tools need to simulate the
triggering condition at proper system states. Luckily, Finding 2
shows that most (86%) eBugs, e.g.,
ZOOKEEPER-2757 and
MAPREDUCE-5251 , have weak or moderate requirements on
system states. This Ô¨Ånding indicates that simple simulation oftriggering conditions can expose most eBugs in cloud systems.
B. Avoiding eBugs in Cloud Systems
Our Ô¨Åndings imply that enhancing exception Ô¨Çow analysis
can help avoid eBugs. Exception Ô¨Çow analysis [ 30]‚Äì[35] helps
developers better understand the exception propagation in thesystem and thereby better react to exceptions. Throughoutour study, we consistently observe that the root causes ofmany eBugs are related to their exception triggering conditions
(Findings 1,4,5, and 7). Therefore, by combining exception
Ô¨Çow analysis with the related triggering conditions, developerscan obtain deeper understanding about what error triggers anexception, and thus handle it correctly. For example, HBasedeÔ¨Ånes 72 exception subclasses that extend
IOException .F o r
a method handling IOException , it will be greatly helpful
to avoid overly-general reactions if developers can know eachconcrete exception and its triggering condition.
C. Detecting eBugs in Cloud Systems
Unlike existing eBug detection tools that focus on empty
or incomplete exception handlers [ 3], overly-general handlers
that stop the system [ 3], missing recovery operations [ 36],
or violations of predeÔ¨Åned exception propagation rules [ 37],
our Ô¨Åndings (Findings 3,4,5, and 7) reveal the important
correlation between the root causes and triggering conditions,which suggests new opportunities for detecting eBugs.
Findings 3-5indicate that inaccurate exceptions do not
accurately describe their triggering conditions. Therefore, it ispossible to detect these eBugs by checking if the exceptionsare consistent with their triggering conditions. In this way, wecan detect eBugs like
HBASE-3164 , where HBase incorrectly
throws aNullPointerException for a network error. Table
VIIalso provides the commonly triggered exceptions for each
non-semantic condition type. Detection tools can use it as achecklist to detect inaccurate exceptions.
Similarly, Finding 7shows that some overly-general reac-
tions incorrectly apply the same handling code to the excep-tions that are caused by different triggering condition types.This suggests a new way to detect overly-general reactions,i.e., by checking if the handled exceptions are triggered by
different condition types. Therefore, we can detect eBugslike
YARN-5103 , where two exceptions ( InterruptedIO-
Exception andFileNotFoundException ) are triggered by
different condition types (untimely interrupt and Ô¨Åle systemerror, respectively) but are handled in the same way.D. DIET: D
etecting I naccurate E xceptions using Triggering
Condition T ypes
Findings 3and4in ¬ßV-A show that inaccurate exceptions
cannot describe the triggering conditions precisely, and may
mislead developers to handle them incorrectly. We also obtaintwo interesting observations from our study: (1) There existstrong relations among exception classes and their triggeringcondition types (Finding 5). (2) An exception‚Äôs error message
usually convey information about its triggering condition type.
Ideally, an exception‚Äôs class and error message should conveythe consistent information about its triggering condition type.If an exception‚Äôs class and its error message imply differenttypes of triggering conditions, the exception is likely to beinaccurate. Inspired by these observations, we build a static
analysis tool, DIET , to automatically detect inaccurate excep-
tions, by inspecting the inconsistency between an exception‚Äôsclass and its error message.
1) DIET‚Äôs Approach: DIET works in two phases: a learning
phase and a detection phase. In the learning phase, given a set
of(e, t)pairs, where edenotes a root exception and tdenotes
e‚Äôs triggering condition type, DIET learns two probabilities:
(i)P
c,t: the probability that the triggering condition of an
exception with class cis of type t, and (ii) Pw,t: the prob-
ability that the triggering condition of an exception containing
keyword win its error message is of type t. In the detection
phase, for a given root exception, DIET employs the aboveprobabilities to examine whether its exception class and errormessage imply different triggering condition types. Note that,DIET focuses on root exceptions because they usually describethe triggering conditions more accurately than their wrapperexceptions. DIET identiÔ¨Åes root exceptions by Ô¨Ånding the onesthat have no cause exceptions.
In the DIET design and experiment, we use the Ô¨Åve trig-
gering condition types summarized in ¬ß IV-A , i.e., network
error, Ô¨Åle system error, out of resource, untimely interrupt,and semantic condition. We further use all the 210 eBugs inour empirical study to learn P
c,tandPw,t.
Learn Pc,t:We Ô¨Årst extract the root exception‚Äôs class ci
and its corresponding triggering condition type tifrom each
studied eBug ei. This step generates 210 pairs of (ci,ti).F o r
each exception class cin these 210 pairs, the probability that
c‚Äôs triggering condition is of type tis computed using the
following equation:
Pc,t=number of (ci,tj)where ci=c, ti=t
number of (ci,ti)where ci=c(1)
Learn Pw,t:We Ô¨Årst extract the root exception‚Äôs error
message miand its triggering condition type tifrom each
studied eBug ei. Since the root exceptions in 44 eBugs do
not have error messages, this step generates 166 pairs of
(mi,ti). Next, DIET extracts the unique keywords from each
error message. Note that, DIET does not consider numbers,conjunctions, determiners, and adverbs as keywords becausethey do not reÔ¨Çect the essence of triggering conditions. For
each ( m
i,ti) pair, DIET can generates multiple ( wi,j,ti) pairs,

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. /g1/g2/g1/g3/g1/g4/g1
/g9/g19/g30/g32/g26/g28/g22
/g6/g28/g28/g26/g28/g7/g21/g23/g19/g1/g13/g33/g29/g30/g19/g24
/g6/g28/g28/g26/g28/g10/g31/g30/g1/g26/g20
/g12/g19/g29/g26/g31/g28/g17/g19/g14/g25/g30/g21/g24/g19/g23/g33
/g8/g25/g30/g19/g28/g28/g31/g27/g30/g13/g19/g24/g15/g25/g30/g21/g17
/g5/g26/g25/g18/g21/g30/g21/g26/g25/g11/g28/g26/g16/g15/g16/g21/g23/g21/g30/g33/g1/g3/g2/g4
 /g2/g3/g1/g5 /g2/g4/g1/g5
/g30
Fig. 8. The Pc,tandPm,tof an exception. For example, when tis network
error, Pc,tis 60% and Pm,t is 40%. The overlapping areas are highlighted
with the dashed boxes. The total overlap is 60%.
where wi,jdenotes the jthunique keyword extracted from
message mi. For each keyword win all these ( wi,j,ti) pairs,
the probability that the triggering condition of keyword wis
of type tis computed using the following equation:
Pw,t=number of (wi,j,ti)where wi,j=w, t i=t
number of (wi,j,ti)where wi,j=w(2)
Detect inaccurate exceptions: Given a target system, DIET
extracts all its root exceptions, which have no cause excep-tions. DIET then analyzes each root exception as follows.
First, DIET extracts the root exception‚Äôs class c, and looks
up the learned probability P
c,tfor each triggering condition
type tsummarized in ¬ß IV-A , which indicates how likely the
triggering condition of the exception is of type t.
Second, DIET extracts the exception error message m, and
unique keywords ( w1, ..., w n) from the error message m.F o r
each keyword wi, DIET looks up the learned probability Pwi,t
for each triggering condition type t, which indicates how
likely the triggering condition of keyword wiis of type t.
DIET computes the probability that the triggering conditionof exception eis of type tby averaging P
wi,tfor all unique
keywords in the error message m.
Pm,t=/summationtext
wi‚ààmPwi,t
n(3)
Finally, DIET uses the following equation to compute the
probability that the root exception‚Äôs class and error messageimply the same triggering condition type:
P
same-type =/summationdisplay
t‚ààFive typesmin( Pc,t,Pm,t) (4)
Intuitively, Psame-type is the minimal common probability for
all Ô¨Åve triggering condition types. As shown in Figure 8,
Psame-type can be represented as the overlapping area when
plotting the Pc,tand the Pm,tfor all Ô¨Åve condition types in
the same histogram. The smaller Psame-type is, the more likely
the root exception‚Äôs class and error message imply differenttypes of triggering conditions, and the more likely the rootexception is inaccurate.
2) Experiments on Cloud Systems: We evaluate DIET using
the latest versions of the studied systems (Table XI). For
these cloud systems, DIET extracts 18,125 exceptions in total(Row
Throw ), and 5,905 of them are considered as root
exceptions (Row Root ex. ). For each root exception, DIETTABLE XI
APPLYING DIET ONREAL-WORLD CLOUD SYSTEMS
System Cassandra Hadoop‚Ä†HBase ZooKeeperTotal(Version) (3.11) (3.1.2) (2.1.4) (2.4.14)
Throw 2,823 9,853 5,020 429 18,125
Root ex. 1,282 3,090 1,374 159 5,905
Calculated 550 1,579 716 84 2,929
Reported 100 136 73 5 314
Candidate 92 0 2 0 31
‚Ä†Hadoop includes Hadoop common, HDFS, MapReduce, and YARN.
TABLE XII
BUGS AND BADPRACTICES DETECTED BY DIET
SystemBug Bad Practice
ConÔ¨Årmed ConÔ¨Årmed Pending Rejected
Cassandra 0 8‚àó10
Hadoop 2( 1Ô¨Å x e d ) 13 (9 Ô¨Åxed) 2 3
HBase 0 00 2
ZooKeeper 0 00 0
Total 2 (1 Ô¨Åxed) 21 (9 Ô¨Åxed) 3 5
‚àóCassandra developers will Ô¨Åx six out of eight conÔ¨Årmed bad practices
in the next major update.
calculates its Psame-type using Equation 4(Row Calculated ).
If its Psame-type‚â§0.2(a conÔ¨Ågurable threshold), DIET will
report it as an inaccurate exception. Finally, DIET reports 314inaccurate exceptions (Row Reported ). We manually inspected
all the reports, and identiÔ¨Åed 31 candidates for real inaccurateexceptions (Row Candidate ). Note that, DIET fails to calculate
P
same-type for half of the root exceptions (Row Calculated ), and
DIET‚Äôs false positive rate is high (283 out of 314 reported
exceptions). This is mainly because we use only a small dataset(the studied 210 eBugs) to train DIET, and many exceptionclasses and keywords of error messages in our experimentalsubjects are not contained in these 210 eBugs. This can be
improved by training DIET with a larger dataset of eBugs.
Among the 31 candidates, we found two eBugs in which
the inaccurate exceptions can cause failure symptoms. The
remaining 29 candidates are bad practices, in which theirexception classes and error messages are indeed misleading.Although a bad practice has not caused failure symptoms,it may introduce eBugs in the future because it is difÔ¨Åcult
to correctly handle an inaccurate exception. For example,
since the inaccurate exceptions in eBugs
HDFS-8224 and
HBASE-3164 (discussed in ¬ß V-A1 ) are misleading, when
developers implemented the corresponding exception handlerslater, the exceptions were not handled properly.
We report all these bugs and bad practices to developers
of these cloud systems. So far, developers have conÔ¨Årmed thetwo bugs and 21 bad practices (Table XII). More importantly,
all of these 23 conÔ¨Årmed issues are ‚Äúpreviously-unknown‚Äù. Atthe time of writing, developers have Ô¨Åxed 10 issues, and willÔ¨Åx another six issues in next major updates.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. Bugs: DIET detected two bugs, which are conÔ¨Årmed by the
developers. Both eBugs are caused by using incorrect classes.For example, in one of them,
HADOOP-16295 , a DataNode
throws an IOException when it is interrupted during Ô¨Åle
renaming. This leads to a checking of disk health, which isnecessary only when the
IOException is triggered by a Ô¨Åle
system error, e.g., when the renaming actually fails.
These bugs highlight the importance of throwing exceptions
with accurate classes. When the exception class does not
match its triggering condition, the system may misbehavein two ways. First, the unintended handling operations maybe executed, such as both bugs found by DIET. Second, theintended handling operations may be skipped. Although DIEThas not found any new bugs with this symptom, they do exist
in our eBugs dataset, e.g.,
CASSANDRA-11448 .
Bad practices: DIET detected 29 bad practices, where
21 have been conÔ¨Årmed by developers. Although these badpractices have not caused any failure symptoms, developers
act proactively to these reported bad practices. For example,
Hadoop developers have Ô¨Åxed nine out of thirteen conÔ¨Årmedbad practices [ 38], and Cassandra developers will Ô¨Åx six out
of eight conÔ¨Årmed bad practices in their next major update[39]‚Äì[43]. Developers rejected Ô¨Åve bad practices, because they
believed that these reported candidates work as intended. For
example, in HBase, a
RuntimeException is used to represent
a Ô¨Åle system error. Developers thought it is a norm in HBaseto use
RuntimeException for a fatal Ô¨Åle system error [ 44].
As a preliminary attempt to detect eBugs in cloud systems,
DIET has found many unknown issues in popular and maturecloud systems. We believe that, by integrating other Ô¨Åndings
in our study, DIET can be further extended to detect more
eBugs and bad practices. For instance, by integrating Finding 7
and exception Ô¨Çow analysis [ 30]‚Äì[35], DIET can help detect
exception handlers that apply the same handling to exceptionstriggered by different condition types, which is an indicator
for overly-general reaction eBugs (Finding 7).
VIII. R
ELATED WORK
In this section, we discuss related work that are not dis-
cussed in previous sections.
EBug studies in other systems: Prior studies have exam-
ined the root causes of eBugs in general systems and Android
applications from source code patterns [ 5]‚Äì[8]. These studies
provide valuable insights on developers‚Äô common mistakeswhen handling exceptions in their target systems. However,due to the inherent system differences, their Ô¨Åndings may notbe applicable to cloud systems. Some studies have analyzed
the relation between eBugs and certain language features, e.g.,aspect-oriented programming [ 9] and Android abstractions [ 6].
Other studies try to understand developers‚Äô perception oneBugs [ 5], [6], and the common exception handling practices
[45]‚Äì[47]. Complementary to these studies, our eBug study
focuses on analyzing the relations between triggering condi-
tions and the root causes in cloud systems, which are critical
in eBug exposure and detection.EBug detection: A few tools have been designed to detect
eBugs. Aspirator detects empty or incomplete (e.g., contain-ing ‚ÄúTODO‚Äù) exception handlers, as well as overly-generalhandlers that abort the whole system [ 3]. CAR-Miner detects
missing recovery operations by inferring methods that should
have executed together when exceptions occur [ 36]. EPE
detects incorrect exception propagation by Ô¨Ånding exceptionsthat are thrown or caught in unintended methods [ 37]. Unlike
these tools, DIET detects inaccurate exceptions by analyzingthe inconsistency between the triggering conditions inferred
from exception classes and error messages.
Other bug studies: In cloud systems, prior works have
focused on other types of bugs, including general bugs [ 4],
concurrency bugs [ 48], crash recovery bugs [ 19], timeout
related bugs [ 49], and system failures [ 3]. They have identiÔ¨Åed
invaluable observations on different types of bugs, helping im-prove cloud system reliability in many ways. Complementary
to these studies, our work examines a different and important
threat in cloud systems, i.e., eBugs. We hope the combinedefforts can greatly help developers improve the reliability ofcloud systems.
Previous works have also studied other types of bugs in
general systems [ 50]‚Äì[52]. These studies have inspired lots
of research that combat bugs in various ways [ 53]‚Äì[55]. We
believe our study can help better understand eBugs in cloud
systems and reveal opportunities to alleviate them.
IX. C
ONCLUSION
In this paper, we present a comprehensive analysis of 210
eBugs in six popular cloud systems, from the perspectiveof triggering conditions. Most of these eBugs affect theavailability or integrity of the cloud systems. Through this
study, we have made many interesting Ô¨Åndings, which revealimportant opportunities for combating eBugs in cloud systems.
Based on our Ô¨Åndings, we develop DIET to detect inaccurateexceptions in cloud systems. DIET has detected 31 eBugs andbad practices, and developers have conÔ¨Årmed 23 of them.
A
CKNOWLEDGMENT
We would like to thank the anonymous reviewers for their
thorough and insightful comments. We are grateful to DejunTeng for helping us calculate the proportion of exception-related code in popular cloud systems. In this work, HaichengChen and Feng Qin were partially supported by National
Science Foundation grants #CNS-1513120 and #CCF-0953759
(CAREER Award). Wensheng Dou and Yanyan Jiang werepartially supported by National Key R&D Program of China(2017YFB1001800), National Natural Science Foundation ofChina (#61732019, #61932021, #61802165), Youth Innova-tion Promotion Association at Chinese Academy of Sciences,
Alibaba Innovative Research Program, and the CollaborativeInnovation Center of Novel Software Technology and Industri-alization, Jiangsu, China. Both Haicheng Chen and WenshengDou are the corresponding authors of this paper.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] Apache Hadoop. [Online]. Available: https://hadoop.apache.org
[2] Advantages of exceptions. [Online]. Available: https://docs.oracle.com/
javase/tutorial/essential/exceptions/advantages.html
[3] D. Yuan, Y . Luo, X. Zhuang, G. R. Rodrigues, X. Zhao, Y . Zhang, P. Jain,
and M. Stumm, ‚ÄúSimple testing can prevent most critical failures: Ananalysis of production failures in distributed data-intensive systems,‚ÄùinProceedings of the 11th USENIX Conference on Operating Systems
Design and Implementation , 2014, pp. 249‚Äì265.
[4] H. S. Gunawi, M. Hao, T. Leesatapornwongsa, T. Patana-anake, T. Do,
J. Adityatama, K. J. Eliazar, A. Laksono, J. F. Lukman, V . Martin et al. ,
‚ÄúWhat bugs live in the cloud? A study of 3000+ issues in cloud systems,‚ÄùinProceedings of the ACM Symposium on Cloud Computing , 2014, pp.
1‚Äì14.
[5] F. Ebert, F. Castor, and A. Serebrenik, ‚ÄúAn exploratory study on
exception handling bugs in Java programs,‚Äù Journal of Systems and
Software , vol. 106, pp. 82‚Äì101, 2015.
[6] J. Oliveira, D. Borges, T. Silva, N. Cacho, and F. Castor, ‚ÄúDo Android
developers neglect error handling? A maintenance-centric study on therelationship between Android abstractions and uncaught exceptions,‚ÄùJournal of Systems and Software , vol. 136, pp. 1‚Äì18, 2018.
[7] R. Coelho, L. Almeida, G. Gousios, and A. van Deursen, ‚ÄúUnveiling
exception handling bug hazards in Android based on GitHub and Googlecode issues,‚Äù in Proceedings of the 12th Working Conference on Mining
Software Repositories , 2015, pp. 134‚Äì145.
[8] L. Fan, T. Su, S. Chen, G. Meng, Y . Liu, L. Xu, G. Pu, and Z. Su, ‚ÄúLarge-
scale analysis of framework-speciÔ¨Åc exceptions in Android Apps,‚Äù inProceedings of the 40th International Conference on Software Engi-neering , 2018, pp. 408‚Äì419.
[9] R. Coelho, A. Rashid, A. von Staa, J. Noble, U. Kulesza, and C. Lucena,
‚ÄúA catalogue of bug patterns for exception handling in aspect-oriented
programs,‚Äù in Proceedings of the 15th Conference on Pattern Languages
of Programs , 2008, p. 23.
[10] Jira Software. [Online]. Available: https://www.atlassian.com/software/
jira
[11] Apache Cassandra. [Online]. Available: http://cassandra.apache.org
[12] Apache HBase. [Online]. Available: http://hbase.apache.org
[13] HDFS architecture. [Online]. Available: http://hadoop.apache.org/docs/
current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html
[14] MapReduce tutorial. [Online]. Available: http://hadoop.apache.org/
docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html
[15] Apache Hadoop YARN. [Online]. Available: http://hadoop.apache.org/
docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html
[16] Apache ZooKeeper. [Online]. Available: http://zookeeper.apache.org
[17] EBugs in cloud systems. [Online]. Available: https://hanseychen.github.
io/eBugs/
[18] O. R. Gatla, M. Hameed, M. Zheng, V . Dubeyko, A. Manzanares,
F. Blagojevi ¬¥c, C. Guyot, and R. Mateescu, ‚ÄúTowards robust Ô¨Åle system
checkers,‚Äù in Proceedings of the 16th USENIX Conference on File and
Storage Technologies , 2018, pp. 105‚Äì122.
[19] Y . Gao, W. Dou, F. Qin, C. Gao, D. Wang, J. Wei, R. Huang, L. Zhou,
and Y . Wu, ‚ÄúAn empirical study on crash recovery bugs in large-scaledistributed systems,‚Äù in Proceedings of the 26th ACM Joint Meeting
on European Software Engineering Conference and Symposium on theF oundations of Software Engineering , 2018, pp. 539‚Äì550.
[20] C. Cadar, D. Dunbar, D. R. Engler et al. , ‚ÄúKLEE: Unassisted and auto-
matic generation of high-coverage tests for complex systems programs,‚ÄùinProceedings of the 8th USENIX Conference on Operating Systems
Design and Implementation , 2008, pp. 209‚Äì224.
[21] P. Godefroid, M. Y . Levin, D. A. Molnar et al. , ‚ÄúAutomated whitebox
fuzz testing,‚Äù in Proceedings of the 16th Network and Distributed System
Security Symposium , 2008, pp. 151‚Äì166.
[22] M. Zheng, J. Tucek, D. Huang, F. Qin, M. Lillibridge, E. S. Yang,
B. W. Zhao, and S. Singh, ‚ÄúTorturing databases for fun and proÔ¨Åt,‚Äù
inProceedings of the 11th USENIX Conference on Operating Systems
Design and Implementation , 2014, pp. 449‚Äì464.
[23] H. S. Gunawi, T. Do, P. Joshi, P. Alvaro, J. M. Hellerstein, A. C. Arpaci-
Dusseau, R. H. Arpaci-Dusseau, K. Sen, and D. Borthakur, ‚ÄúFATE andDESTINI: A framework for cloud recovery testing,‚Äù in Proceedings
of the 8th USENIX Conference on Networked Systems Design and
Implementation
, 2011, pp. 1‚Äì18.[24] R. Alagappan, A. Ganesan, Y . Patel, T. S. Pillai, A. C. Arpaci-Dusseau,
and R. H. Arpaci-Dusseau, ‚ÄúCorrelated crash vulnerabilities,‚Äù in Pro-
ceedings of the 12th USENIX Conference on Operating Systems Designand Implementation , 2016, pp. 151‚Äì167.
[25] H. Liu, X. Wang, G. Li, S. Lu, F. Ye, and C. Tian, ‚ÄúFCatch: Automat-
ically detecting time-of-fault bugs in cloud systems,‚Äù in Proceedings
of the 23rd International Conference on Architectural Support forProgramming Languages and Operating Systems , 2018, pp. 419‚Äì431.
[26] Jepsen. [Online]. Available: https://jepsen.io/
[27] A. Alquraan, H. Takruri, M. Alfatafta, and S. Al-Kiswany, ‚ÄúAn analysis
of network-partitioning failures in cloud systems,‚Äù in Proceedings of the
13th USENIX Conference on Operating Systems Design and Implemen-tation , 2018, pp. 51‚Äì68.
[28] T. Leesatapornwongsa, M. Hao, P. Joshi, J. F. Lukman, and H. S.
Gunawi, ‚ÄúSAMC: Semantic-aware model checking for fast discoveryof deep bugs in cloud systems,‚Äù in Proceedings of the 11th USENIX
Conference on Operating Systems Design and Implementation , 2014,
pp. 399‚Äì414.
[29] A. Ganesan, R. Alagappan, A. C. Arpaci-Dusseau, and R. H. Arpaci-
Dusseau, ‚ÄúRedundancy does not imply fault tolerance: Analysis of dis-tributed storage reactions to single errors and corruptions,‚Äù in Proceed-
ings of the 15th USENIX Conference on File and Storage Technologies ,
2017, pp. 149‚Äì166.
[30] G. B. de P ¬¥adua and W. Shang, ‚ÄúRevisiting exception handling practices
with exception Ô¨Çow analysis,‚Äù in Proceedings of 17th International
Working Conference on Source Code Analysis and Manipulation , 2017,
pp. 11‚Äì20.
[31] D. Sena, R. Coelho, U. Kulesza, and R. Bonif ¬¥acio, ‚ÄúUnderstanding the
exception handling strategies of Java libraries: An empirical study,‚Äù in
Proceedings of the 13th International Conference on Mining Software
Repositories , 2016, pp. 212‚Äì222.
[32] S. Liang, W. Sun, M. Might, A. Keep, and D. Van Horn, ‚ÄúPruning,
pushdown exception-Ô¨Çow analysis,‚Äù in Proceedings of 14th International
Working Conference on Source Code Analysis and Manipulation , 2014,
pp. 265‚Äì274.
[33] H. Melo, R. Coelho, U. Kulesza, and D. Sena, ‚ÄúIn-depth characterization
of exception Ô¨Çows in software product lines: An empirical study,‚ÄùJournal of Software Engineering Research and Development , vol. 1,
no. 1, p. 3, 2013.
[34] P. Prabhu, N. Maeda, G. Balakrishnan, F. Ivan Àáci¬¥c, and A. Gupta,
‚ÄúInterprocedural exception analysis for C++,‚Äù in Proceedings of the 25th
European Conference on Object-Oriented Programming , 2011, pp. 583‚Äì
608.
[35] M. Bravenboer and Y . Smaragdakis, ‚ÄúException analysis and points-
to analysis: Better together,‚Äù in Proceedings of the 18th International
Symposium on Software Testing and Analysis , 2009, pp. 1‚Äì12.
[36] S. Thummalapenta and T. Xie, ‚ÄúMining exception-handling rules as
sequence association rules,‚Äù in Proceedings of the 31st International
Conference on Software Engineering , 2009, pp. 496‚Äì506.
[37] T. Montenegro, H. Melo, R. Coelho, and E. Barbosa, ‚ÄúImproving
developers awareness of the exception handling policy,‚Äù in Proceedings
of the 25th International Conference on Software Analysis, Evolutionand Reengineering , 2018, pp. 413‚Äì422.
[38] HDFS-14486. [Online]. Available: https://issues.apache.org/jira/browse/
HDFS-14486
[39] CASSANDRA-15111. [Online]. Available: https://issues.apache.org/
jira/browse/CASSANDRA-15111
[40] CASSANDRA-15112. [Online]. Available: https://issues.apache.org/
jira/bro wse/CASSANDRA-15112
[41] CASSANDRA-15114. [Online]. Available: https://issues.apache.org/
jira/browse/CASSANDRA-15114
[42] CASSANDRA-15116. [Online]. Available: https://issues.apache.org/
jira/browse/CASSANDRA-15116
[43] CASSANDRA-15117. [Online]. Available: https://issues.apache.org/
jira/browse/CASSANDRA-15117
[44] HBASE-22369. [Online]. Available: https://issues.apache.org/jira/
browse/HBASE-22369
[45] S. Nakshatri, M. Hegde, and S. Thandra, ‚ÄúAnalysis of exception handling
patterns in Java projects: An empirical study,‚Äù in Proceedings of the
13th International Conference on Mining Software Repositories , 2016,
pp. 500‚Äì503.
[46] M. Monperrus, M. G. de Montauzan, B. Cornu, R. Marvie, and
R. Rouvoy, ‚ÄúChallenging analytical knowledge on exception-handling:An empirical study of 32 Java software packages,‚Äù Tech. Rep. hal-01093908, 2014.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. [47] M. B. Kery, C. Le Goues, and B. A. Myers, ‚ÄúExamining programmer
practices for locally handling exceptions,‚Äù in Proceedings of the 13th
International Conference on Mining Software Repositories , 2016, pp.
484‚Äì487.
[48] T. Leesatapornwongsa, J. F. Lukman, S. Lu, and H. S. Gunawi, ‚ÄúTaxDC:
A taxonomy of non-deterministic concurrency bugs in datacenter dis-tributed systems,‚Äù in Proceedings of the 21st International Conference
on Architectural Support for Programming Languages and OperatingSystems , 2016, pp. 517‚Äì530.
[49] T. Dai, J. He, X. Gu, and S. Lu, ‚ÄúUnderstanding real-world timeout prob-
lems in cloud server systems,‚Äù in Proceeding of the IEEE International
Conference on Cloud Engineering , 2018, pp. 1‚Äì11.
[50] S. Lu, S. Park, E. Seo, and Y . Zhou, ‚ÄúLearning from mistakes: A
comprehensive study on real world concurrency bug characteristics,‚ÄùinProceedings of the 13th International Conference on Architectural
Support for Programming Languages and Operating Systems , 2008, pp.
329‚Äì339.
[51] A. Chou, J. Yang, B. Chelf, S. Hallem, and D. Engler, ‚ÄúAn empiricalstudy of operating systems errors,‚Äù in Proceedings of the 18th Sympo-
sium on Operating Systems Principles , 2001, pp. 73‚Äì88.
[52] Z. Yin, D. Yuan, Y . Zhou, S. Pasupathy, and L. Bairavasundaram, ‚ÄúHow
do Ô¨Åxes become bugs?‚Äù in Proceedings of the 19th ACM SIGSOFT
Symposium and the 13th European Conference on F oundations ofSoftware Engineering , 2011, pp. 26‚Äì36.
[53] S. Park, S. Lu, and Y . Zhou, ‚ÄúCTrigger: Exposing atomicity violation
bugs from their hiding places,‚Äù in Proceedings of the 14th International
Conference on Architectural Support for Programming Languages andOperating Systems , 2009, pp. 25‚Äì36.
[54] W. Zhang, C. Sun, and S. Lu, ‚ÄúConMem: Detecting severe concurrency
bugs through an effect-oriented approach,‚Äù in Proceedings of the 15th
International Conference on Architectural Support for Programming
Languages and Operating Systems , 2010, pp. 179‚Äì192.
[55] B. Kasikci, B. Schubert, C. Pereira, G. Pokam, and G. Candea, ‚ÄúFailure
sketching: A technique for automated root cause diagnosis of in-production failures,‚Äù in Proceedings of the 25th Symposium on Operating
Systems Principles , 2015, pp. 344‚Äì360.

Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:31 UTC from IEEE Xplore.  Restrictions apply. 