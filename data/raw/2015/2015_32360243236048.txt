Concurrency Verification with Maximal Path Causality
Qiuping Yi
Texas A&M University
College Station, Texas, USA
qiuping@tamu.eduJeff Huang
Texas A&M University
College Station, Texas, USA
jeff@cse.tamu.edu
ABSTRACT
We present a technique that systematically explores the state spaces
of concurrent programs across both the schedule space and the in-
put space. The cornerstone is a new model called Maximal Path
Causality (MPC ), which captures all combinations of thread sched-
ules and program inputs that reach the same path as one equiva-
lency class, and generates a unique schedule+input combination to
explore each path. Moreover, the exploration for different paths
can be easily parallelized. Our extensive evaluation on both pop-
ular concurrency benchmarks and real-world C/C++ applications
shows that MPC significantly improves the performance of existing
techniques.
CCS CONCEPTS
‚Ä¢Software and its engineering ‚ÜíFormal software verifica-
tion;Software testing and debugging ;
KEYWORDS
Concurrency, Verification, Dynamic Symbolic Execution
ACM Reference Format:
Qiuping Yi and Jeff Huang. 2018. Concurrency Verification with Maximal
Path Causality. In Proceedings of the 26th ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software Engi-
neering (ESEC/FSE ‚Äô18), November 4‚Äì9, 2018, Lake Buena Vista, FL, USA. ACM,
New York, NY, USA, 11 pages. https://doi.org/10.1145/3236024.3236048
1 INTRODUCTION
The challenge of interleaving explosion has inspired a number of
significant work [ 3,11,19,20,25] in testing and verification of
concurrent programs. An essential idea is to identify redundant in-
terleavings, which can be ignored because they produce equivalent
program states. For example, in partial order reduction [ 3,11,19],
an interleaving is identified as redundant if it can be generated
from another interleaving by swapping non-conflicting events of
different threads.
Maximal causality reduction (MCR) [ 20] is a more recent tech-
nique that minimizes redundant interleavings by exploiting the
maximal causality between events in an execution trace with a
constraint solver. A key idea of MCR is to capture the value of reads
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA
¬©2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5573-5/18/11. . . $15.00
https://doi.org/10.1145/3236024.3236048
T1                    1.i = input();   2.x =  i; 3.x = 2; T2                    4.j = input();   5.x =  j; 6.x = 4; T3                    7.if(x >= 100); 8.     error; 9.else y = 2; Figure 1: An example with inputs iand j.
and writes in a trace and use the value to drive new executions,
such that every new execution reaches a distinct program state.
MCR is shown effective for finding extremely subtle bugs in both
sequential and weak consistency models, such as TSO and PSO [ 22].
However, all these techniques suffer from a serious limitation:
they only explore program state spaces under a fixed program input,
but leave the whole input-space except the fixed input unverified. In
other words, they may fail to verify states that can only be reached
by a certain combination of schedule and input.
Consider a simple example in Figure 1 with three threads and two
inputs iandj. There is an error state at line 8. When input (i,j)
is fixed to (0,1) , there are 15interleavings totally. POR explores
all the 15interleavings; MCR explores only 4because the program
has only four different values for the read of xat line 7(written by
the four writes to xat lines 2-3and5-6). However, neither POR
nor MCR can find the error at line 8. In fact, the error can never
be exposed with the input (0,1) . One way to find the error is to
check all possible inputs and for each input use MCR to explore
the interleavings. Unfortunately, the input-space is huge: even if
both iandjare restricted to [0, 100], to verify this program there
are 150,000 executions that must be explored. It poses a significant
challenge to verify both the input-space ( M) and schedule-space
(N). In theory, the whole search space is M√óN, where Mis often
infinite and Nis exponential in the program size.
In this paper, we present a new technique, Maximal Path Causal-
ity (MPC ), that systematically explores the state spaces of concur-
rent programs while reducing redundant explorations across both
the schedule space and the input space. The key idea is to com-
bine MCR with dynamic symbolic execution (DSE), a well-known
systematic path exploration technique. In DSE, each execution is
symbolically analyzed to find the next input that triggers the exe-
cution of an unexplored path. Similar to that, MCR analyzes each
execution trace symbolically and generates thread schedules that
are not explored before. By combining these two techniques that
have conceptual similarities, MPC can systematically explore both
the input space and the schedule space at the same time.
More specifically, MPC captures both schedules and inputs as
a set of constraints, which encode all schedule+input (SI) combi-
nations that drive the program to the same path as one equiva-
lency class. For each equivalency class, it generates a unique SI
(through solving the MPC constraints) to explore each path once
366
ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA Qiuping Yi and Jeff Huang
only. Back to the example in Figure 1. For input (i=0,j=0) , all the
15schedules reach the same path which takes the false -branch
at line 7.MPC only explores the path p1={1-6,7,9} once and
ignores the other 14schedules. After p1is explored, MPC gener-
ates a new SIto explore an unexplored path with path condition
R7x‚â•100, where R7xdenotes the value of xat line 7. Thus, the
schedule {T1-T1-T1-T2-T2-T3-T3-T2} with input (i=0,j=100)
is generated to cover a new path p2={1-5,7,8,6} , which triggers
the error. MPC terminates after two executions, because no other
reachable (but unexplored) paths exist.
Moreover, MPC can be easily parallelized with two types of
parallelism. First, dynamic executions for different SIs can be par-
allelized, because each execution is independent with previously
explored paths. Second, the offline analysis for generating SIs for
different paths can be parallelized, because the offline analysis only
depends on the observed execution.
For the last decade, DSE has enabled addressing diverse software
engineering problems ‚Äì not only software testing [ 8] but also auto-
mated debugging [ 27,34] and automated program repair [ 24,26].
We expect that MPC can be used to extend many of those work
done for sequential programs to concurrent programs, given the
similarity of MPC to DSE.
We highlight our contributions as follows:
‚Ä¢To our knowledge, MPC is the first technique that systemat-
ically explores state spaces of concurrent programs while re-
ducing redundant explorations across both input and sched-
ule spaces.
‚Ä¢To ensure the verification soundness, a key challenge in
MPC is how to systematically explore all reachable program
paths. We present a sound path exploration algorithm based
on the unsatisfiable cores of the MPC formulas.
‚Ä¢We evaluate MPC extensively on both popular benchmarks
and real-world applications in C/C++. We show that MPC
is significantly more effective and efficient than MCR and
Con2Colic [18].
‚Ä¢OurMPC tool is open source [1].
2 OVERVIEW
We start with a motivating example in Figure 2 (slightly more com-
plicated than the example in Figure 1) to illustrate the challenges of
verifying concurrent programs. We then use this example to illus-
trate how MCR works and identify its advantages and limitations.
Finally, we show how MPC addresses these limitations and draw
its overview.
2.1 Motivating Example
As shown in Figure 2(a), our motivating example contains three
threads ( T1-T3) which access two shared variables ( xandy) and
use a lock lto synchronize some (but not all) accesses to y. The
program has an error at line 13, which crashes the program when
both the two branch conditions at lines 11and12are satisfied. The
error, however, is difficult to manifest because it requires a specific
combination of thread schedule and program input (e.g., i=3and
j=2).
Specifically, to satisfy the branch condition at line 11, line 14
should be executed as the latest write to xbefore line 4; meanwhileline11should be executed after line 4. Note that, the condition
at line 3must be true to execute line 4, which requires the in-
putito be 3. To satisfy the branch condition at line 12, line 10
must be followed by line 18, and at the same time no other writes
toyshould happen before line 12. In addition, the input jmust
be larger or equal to 2to ensure that the while loop at line 16
is executed at least twice. One such error-triggering schedule is
T1-T1-T1-T1-T2-T3-T3-T1-T1-T1-T1-T2- T3-T3-T3-T3-T3-
T3-T3-T3-T3-T2-T2-T2 , corresponding to a path denoted by lines
{0-3,9,14,15,4-7,10,16-19,16-19,16,11-13} .
To detect this error, a technique must find both a correct schedule
and a correct input. For example, the error can never be revealed if
the program input is fixed to (i=0,j=0) or(i=3,j=1) , no matter
what thread schedule the program executes. This example shows
the importance of cross-input verification of concurrent programs.
However, existing state-space exploration techniques [ 3,11,19,20,
25] all assume a fixed input.
2.2 Maximal Causality Reduction
MCR [ 20] is an effective stateless model checking approach for
concurrent programs under a fixed input. A main advantage of MCR
over the other popular approaches (e.g., DPOR [ 19] and context
bounding [ 25]) is that it uses a maximal thread causality model
(MCM [ 21]) to capture redundant schedules, such that only those
unique schedules reaching distinct program states are explored. In
other words, MCR never explores the same program state twice
given a fixed input, and it ensures a provably minimal number
of program executions for exploring all program states under the
given input.
More specifically, MCR encodes each explored trace as a maximal
causality formula Œ¶mcm with first-order logical constraints. It uses
Œ¶mcm to generate new thread schedules to explore by enforcing a
new-state condition: each new schedule must contain at least one
new event, i.e., aRead that returns a new value.
InŒ¶mcm , each event efrom an input trace œÑis represented by
an order variable Oe, and the order relation between Oefor dif-
ferent events is used to capture all the possible thread schedules
that the same program (which generates œÑ) can execute in alter-
native runs. Œ¶mcm is constructed by a conjunction of two subfor-
mulas: Œ¶mcm‚â°Œ¶sync‚àßŒ¶rw, where Œ¶synccaptures the ordering
constraints determined by thread synchronizations, and Œ¶rwthe
data-validity constraints over Read andWrite events determined
by memory consistency requirements (e.g., sequential consistency
or relaxed consistency). Œ¶synccan be further decomposed as a
conjunction of the must-happen-before constraints Œ¶mhb and the
lock-mutual-exclusion constraints Œ¶lock. For space reasons, we refer
the readers to [ 20] for the encodings of Œ¶mhb andŒ¶lock, and focus
on describing Œ¶rw, which is extended in our new model to handle
program inputs.
Data-Validity Constraints ( Œ¶rw).For an event eto be feasible
in an inferred trace, MCM requires every read event rthat must-
happen-before eto return the same value as that returned by rin the
input trace. Otherwise, emay become infeasible due to a conditional
right after the read event r. For example, if in an observed trace a
read rreads value 42, then in the inferred trace it must also read
value 42. However, it can read the value 42 written by any write on
367Concurrency Verification with Maximal Path Causality ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA
Data-Validity Constraints „ΩøSX(Rx11 = Wx1 ‚àß (O11 > O1 ‚àß (O9 < O1 ‚à® O9 > O11)           ‚àß (O14 < O1 ‚à® O14 > O11))    ‚à®Rx11 = Wx9 ‚àß (O11 > O9 ‚àß (O1 < O9 ‚à® O1 > O11)          ‚àß (O14 < O9 ‚à® O14 > O11))    ‚à®Rx11 = Wx14 ‚àß (O11 > O14 ‚àß (O1 < O14 ‚à® O1 > O11)          ‚àß (O9 < O1 ‚à® O9 > O11)))      ‚àß(Wx1 = 2 ‚àß Wx9 = 5 ‚àß Wx14 = 100)Synchronization Constraints „ΩøTZODO0<O1<O2<O3 ‚àß O9<O10<O11‚àß O14<O15<O16                        Initially, x = y = 0;     T1                        T2                     T3 0 i=input();   9    x=5;             14  x=100;1 x=2;           10  y=0;             15  j=input();2 y=5;           11  if(x==101){   16  while(j-->0){3 if(i==3){      12    if(y==2)     17       lock(l);4     x++;       13       crash;    18       y++;5     lock(l);          }                  19       unlock(l);6     y- -;                                        }7     unlock(l);8  }
(a)(b)Path Condition Constraints „ΩøQD i‚â†3 ‚àß Rx11‚â†101 ‚àß j‚â§0
           T1                        T2                        T3                                 Initially x=0;  1. i = input();       4. j = input();     7. if (x >= 100)  2. x = i;                5. x = j;               8.   error;  3. x = 2;               6. x = 4;              9. else y = 2;
Figure 2: (a) The crash can only be triggered by a specific combination of schedule and input. (b) The constraints generated by
MCR and MPC based on an execution with input (i, j)=(0, 0) and a random schedule.
the same address as long as the written value is 42 (not necessarily
the same write as in the observed trace). We refer to this as the
data-validity condition .
More formally, let‚â∫edenote the set of events that must-happen-
before an event e. Consider a Read rin‚â∫ethat accesses a memory
location xand returns value v, and let Wxdenote the set of Writes
in the trace that write to x, and Wxvthose Writes inWxwith value
v. The data-validity constraint of an event e,Œ¶rw(e), is defined as√ì
r‚àà‚â∫eŒ¶value(r), where Œ¶value(r)‚â°
√î
w‚ààWxv(Œ¶rw(w)‚àßOw<Or√ì
w,w‚Ä≤‚ààWx(Ow‚Ä≤<Ow‚à®Or<Ow‚Ä≤))
The constraint Œ¶value(r)enforces the Read rto read the value
vwritten by any Write winWxv(which writes vto the memory
location x), subject to the condition that the order of wis smaller
than that of rand there are no other Writes in between that write
a different value to x.
It is worth noting that Œ¶rwis recursive. Because in Œ¶value(r), to
enforce a Read rto read from a Write w,wmust be feasible, which
requires Œ¶rw(w)to hold.
For this example, suppose the given input is (i=0,j=0) and the
first schedule explored by MCR is œÑ1={0-3,9-11,
14-16} . The formula Œ¶mcm generated by MCR is shown in Figure
2(b) (ignore the path-condition constraint Œ¶pcfor now). Let Wix
andRixdenote the written and read values of xat line irespectively.
R11xmay return any value among W1x,W9xandW14x. IfR11xreturns
W1x, then line 11must be executed after line 1and no other writes
toxshould happen between lines 1and11.
Finally, MCR explores three executions, each corresponding to a
schedule in which the only read at line 11 is matched with one of
the three writes at lines 1, 9 and 14. Unfortunately, none of these
three executions can trigger the crash at line 13. To trigger the crash,
MCR would need a correct input (e.g., i=3,j=2 ). Nevertheless, even
with the correct input, to hit the bug MCR still needs to explore 85
executions in our experiment.
SchedulerStateless Model Checker
Path p:  Trace + Path ConditionWork List[schedule1 + input1][schedule2 + input2]‚Ä¶[schedulei + inputi]‚Ä¶‚Ä¶
Program[schedule + input]Symbolic Execution
PathExplorer
UpdateSchedule-SpaceInput-Space
‚ûïFigure 3: Overview of MPC .
2.3 MPC in a Nutshell
Inspired by MCR, our approach addresses two main problems. First,
it extends MCR to handle program inputs, i.e., it not only generates
new schedules, but also new inputs. Second, it advances MCR to
capture not only redundant schedules, but also redundant inputs
and redundant combinations of schedules and inputs. This is a major
advance because the space of schedule+input (SI) combinations
explodes much faster than the input-space or the schedule-space
alone, yet significant redundancy often exists across the two spaces.
We also note that our approach is applicable to a wide range of
memory models (such as TSO and PSO), but we focus on sequential
consistency (SC) in this paper.
Figure 3 shows an overview of MPC , which systematically ex-
plores all reachable paths in the program. At runtime, MPC per-
forms both dynamic scheduling and symbolic execution to explore
new program paths. Offline, it formulates constraints from the in-
formation observed at runtime, and generates new SI combinations
368ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA Qiuping Yi and Jeff Huang
PathWork ListBranchP0I1I2I3I4I5I6I7b300001111b1100110011b16101010101PathWork ListBranchP0P1I2I3I4I5I6I7I8b3000011110b11001100110b161010101011b16201All Explored PathsBranchP0P1P2P3P4P5P6P7P8P9b30011110111b110000110011b120001b1610101011111b1620111001Initial input:  (j, j) = (0, 0)Initial Schedule:  empty
Input: (i, j) = (0, 1)Schedule: O0=1,O1=2,O2=3,O9=4,O10=5,O11=6,O14=7,O15=8,O16=9‚Ä¶Path PreÔ¨Åx: emptyNew identiÔ¨Åed Branch:       b3, b11, b161
Path PreÔ¨Åx: I1New identiÔ¨Åed Branch:            b162(a)
(b)
(c)
Figure 4: MPC on the motivating example in Fig. 2.
(by solving the constraints) to explore new paths. By leveraging
MCR, the advantage of MPC over conventional symbolic execution
is that it does not need to reason about symbolic pointers on shared
data, because concrete addresses of shared data accesses are all
observed at runtime.
MPC maintains a WorkList of the to-be-checked SIs. The Work-
Listis initialized with a random SI (i.e., an empty schedule and
a random input), and is augmented with new SIs generated from
each iteration. In each iteration, the Scheduler consumes one SI
from the WorkList to guide a concrete execution, accompanied by
a symbolic execution to collect the path condition. Then, the of-
fline PathExplorer finds unexplored paths or path prefixes across
the schedule-space and input-space based on previously observed
paths. For each such path, it further generates a corresponding SI
(which is added to the WorkList ) for exploring the path. MPC termi-
nates when the WorkList is empty and there is no new SI that can
be generated, meaning that all reachable paths have been explored.
Figure 4 illustrates MPC on the motivating example. To ease the
presentation, we directly add the paths (instead of the correspond-
ing SIs) into the WorkList .MPC starts with an input ( i=0,j=0 ) and
an empty schedule (which means the schedule can be arbitrary).
Suppose path P0with the path condition i,3‚àßR11x,101‚àßj‚â§0is
explored in the first execution, which exhibits three new branches
(b3,b11,b16 11) and for all these branches the false -branch is
taken, denoted by 0 in Figure 4(a).
1We use b16ito denote the ith instance of the branch at line 16.Then, based on P0,MPC identifies 7 new path prefixes I1-I7,
which are different combinations of the branch choices at b3,b11
andb16 1, and which have not been explored. For each path pre-
fix,MPC then tries to generate a concrete SI (via a constraint-
based approach) to enforce an execution that follows the path pre-
fix. Specifically, MPC uses an SMT solver to solve the formula
Œ¶mpc‚â°Œ¶sync‚àßŒ¶pc‚àßŒ¶dc, where Œ¶mpc is the constraint con-
structed from the maximal path causality model, which will be
described in Section 3.2. Compared to Œ¶mcm in MCR, Œ¶mpc is a
relaxation that captures the path condition Œ¶pcand the data con-
sistency Œ¶dcover the reads and writes in the path prefix instead of
the whole trace.
For example, for I1which contains the false -branch of b3
andb11and the true -branch of b16 1, the path condition Œ¶pcis
i,3‚àßR11x,101‚àßj>0, meaning that iis not equal to 3,jis
larger than 0, and the value returned by the read of xat line 11, R11x,
is not equal to 101. The MPC constraints are shown in Figure 2(b).
The MPC constraint Œ¶mpc is a conjunction of the path-condition
constraint Œ¶pc, the synchronization constraint Œ¶sync, and the data-
consistency constraint Œ¶dc. The synchronization constraints Œ¶sync
is the same as that in Œ¶mcm . The data-consistency constraint Œ¶dc
concerns R11xand three writes to x,W1x,W9xandW14x. For this
example, Œ¶dc(shown in the gray area) is similar to the data-validity
constraint Œ¶rw, except that it does not enforce the values of the
three writes (i.e., W1x=2‚àßW9x=5‚àßW14x=100).
One solution (i.e., an SI combination) to Œ¶mpc is shown above
Figure 4(b). The solution drives MPC to explore a new path P1,
which exhibits a new branch b16 2with its false -branch taken.
Again, based on P1,MPC identifies a new path prefix I8, which
extends I1with the true -branch of b16 2, and generates a new SI
for it.
MPC repeats the previous analysis for each SI until the WorkList
is empty. For our motivating example, MPC terminates after ex-
ploring 10paths, including the crash-triggering path P9, as shown
in Figure 4(c).
3 THE MPC APPROACH
In this section, we present the MPC approach in detail, including
the basic definitions, the MPC model, the overall MPC algorithm,
the path exploration algorithms, and the parallel MPC algorithm.
3.1 Basic Definitions
A central notion of our approach is the path prefix of a multi-
threaded program:
Definition 3.1. (Path and Path Prefix). A path pcorresponding to
a complete execution trace œÑis defined as p‚â°{p(T1), . . . , p(TN)},
where p(Ti)is the executed path of thread Ti.p‚Ä≤‚â°{p‚Ä≤(T1), . . . ,
p‚Ä≤(TN)}is a path prefix of p, if for all threads Ti(i=1, . . . , N),
p‚Ä≤(Ti)is a prefix of p(Ti). Thus p‚Ä≤may be an incomplete path and
|p‚Ä≤(Ti)|‚â§| p(Ti)|, where|p(Ti)|represents the length of p(Ti). Each
path pis also a path prefix of itself.
Definition 3.2. (Path Subsumption). Let PS(p)denote the set of all
paths with the same path prefix p. For two path prefixes p1andp2,
we call p1subsumes p2(orp2is subsumed by p1) ifPS(p2)‚äÇPS(p1).
369Concurrency Verification with Maximal Path Causality ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA
Based on the path prefixes, all paths can be organized into a path
tree, defined as follows:
Definition 3.3. (Path Tree). The path tree of a multithreaded pro-
gram is a Tree(N, E) , where the node set Nrepresents path prefixes
and the edge set Erepresents the following relations between nodes:
‚Ä¢For non-leaf node n,‚àÄm‚ààchildren(n),nsubsumes m, i.e.,
PS(m)‚äÇPS(n).
‚Ä¢For non-leaf node n,‚àÄa,b‚ààchildren(n),PS(a)‚à©PS(b)=‚àÖ,
where a,b.
‚Ä¢For non-leaf node n,PS(n)=√ê
‚àÄm‚ààchildren(n)PS(m).
In a path tree, the root represents all paths (because all paths
share an empty prefix). Each leaf node represents one concrete path
or an unreachable path prefix, and each non-leaf node is a reachable
path prefix, which contains one or more paths. For example, Figure 5
shows the path three of the program in Figure 1. It contains three
nodes: the root node representing path prefix p0:True , and two
leaf nodes representing the paths p1:R7x‚â•100andp2:R7x<100
respectively.
p0: Truep1: Rx7>=100p2: Rx7<100
Figure 5: Path tree of the example in Figure 1.
3.2 Maximal Path Causality
In MCM [ 21], a multithreaded program is modeled as a prefix-
closed set of finite traces that can be produced when completely
or partially executed. A trace is abstracted as a sequence of events
performed by threads on concurrent objects in a concrete execution,
such as Read /Write ,Lock/Unlock , etc. We note that the event value
is also a part of the model. If the value of an event (e.g., the value
returned by a read) is changed, it becomes a different event, such
that a conditional branch after the event may produce a different
trace.
Compared to MCM, a key difference of Maximal Path Causality
(MPC) is that the event value is ignored in MPC. Because the path
condition of each thread is also captured in the trace, to ensure the
feasibility of an event, it suffices to require that the path condition of
the event is satisfied (instead of requiring the data-validity condition
as in MCM). This relaxation not only significantly increases the
power of MCM, but also reduces the complexity of the generated
constraints. Consider an example in Figure 6. Suppose the input
trace follows lines 1-2-3 , then the two traces 1-3-2 and3-1are
also feasible in MCM. However, the trace 3-1-2 is not feasible,
because in MCM the feasibility of the event at line 2 requires the
read at line 1 to return the same value as that in the input trace
(which is 0), but in the trace 3-1-2 it returns the value written
by line 3 (which is 1). Therefore, to expose the assertion violation,
MCR based on MCM must enforce a new execution following 3-1,
which explores the trace 3-1-2 .
However, the trace 3-1-2 is feasible in MPC. The reason is that
the path condition for the event at line 2 is true (because there is
    T1                       T2          Initially x=0 1.r1=x               3. x=1 2.r2=x          assert(r1+r2<2);Figure 6: Example of Maximal Path Causality.
no branch), so the event is feasible regardless of the value read by
the event at line 1. Hence, the assertion violation in this example
can be directly exposed in MPC without requiring a new execution.
Given a trace and the corresponding path condition for each
thread, the MPC constraint Œ¶mpc captures the maximal path causal-
ity among events in the trace and is defined as Œ¶mpc‚â°Œ¶sync‚àß
Œ¶pc‚àßŒ¶dc. There are two types of symbolic variables in the path
condition constraint Œ¶pc: the value of program inputs and the
value of reads on shared data. For example, in the path condition
i,3‚àßR11x,101‚àßj‚â§0of our motivating example in Figure 2, i
andjare program inputs, and R11xis the symbolic value of reads.
The first type can get arbitrary value allowed by program inputs.
The second type can only choose certain values written by writes
in the input trace, which is constrained by the data-consistency
constraint Œ¶dc. More specifically, consider a Read r, all the Write
events on the same memory location, denoted by a set W, and the
possible value returned by r, denoted by Vr. The data-consistency
constraint for ris defined as Œ¶dc(r)‚â°
√ú
‚àÄwi‚ààW(Vr=wi‚àßOwi<Or√õ
‚àÄwj,wi(Owj<Owi‚à®Owj>Or))
(1)
The constraint Œ¶dc(r)states that if the Read rreturns the value
written by a Write w, then the Write ‚Äôs order Owmust be smaller
than the Read ‚Äôs order Orand there are no other Writes between
them. The value of any Write wcan be either concrete or symbolic,
represented by the symbolic inputs or symbolic read values. The
size of Œ¶dc, in the worst case, is cubic in the size of the whole trace
(i.e., linear in the number of reads and quadratic in the number of
writes).
Compared to Œ¶rwin MCM, Œ¶dcin MPC is much simpler and
is not recursive. There are two main differences. First, Œ¶dconly
specifies the possible values a read can return, but does not enforce
it to return a specific value (as enforced in Œ¶rw). Second, Œ¶dcis
constructed over events in a given path (instead of the whole trace).
Since the path condition constraint Œ¶pcensures the feasibility of
all events in the path, Œ¶dcdoes not need the feasibility constraints
for the matched writes (as required in Œ¶rw).
3.3 The Basic MPC Algorithm
Our goal is to effectively explore the path tree of a concurrent
program. Algorithm 1 describes the overall flow of our algorithm.
The basic idea is to incrementally construct the path tree based
on the MPC model. Each item‚ü®si,pre f ix‚ü©in the workList is used
to drive an execution to follow the path prefix pre f ix with the
schedule+input (SI) combination si.
To start, the workList is initialized with an empty prefix (i.e., the
root of the path tree), a random input and an empty schedule. In
each iteration (lines 4-7), an SI from the workList is consumed, and
370ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA Qiuping Yi and Jeff Huang
Algorithm 1: The MPC Algorithm
1:si‚ÜêRandom input and empty schedule;
2:workList .add(si,True);
3:while (!workList .empty())
4:(si,prefix)‚ÜêworkList .pop();
5:œÑ‚ÜêGuidedSE(si,prefix);
6: list‚ÜêGenerateNewSI( œÑ,prefix );
7: workList .add(list);
8:end while
Algorithm 2: GenerateNewSI (œÑ,prefix )
1:SI‚Üê‚àÖ;
2:P‚ÜêIdentifyNewPathPrefixes( œÑ,prefix );
3:for each p‚ààP
4:œÑ‚Ä≤‚ÜêextractSubTrace( œÑ,p);
5: Œ¶pc=PathConditionConstraints( p);
6: Œ¶sync=SynchronizationConstraints( œÑ‚Ä≤);
7: Œ¶dc=DataConsistencyConstraints( œÑ‚Ä≤);
8: Œ¶mpc(p)=Œ¶pc‚àßŒ¶sync‚àßŒ¶dc;
9: si‚Üêsolve( Œ¶mpc(p));
10: if(si,null)then
11: SI.add(si,p);
12:Return SI.
two steps are performed: dynamic path exploration and static path-
prefix identification. The first step carries out a guided symbolic
execution along with the concrete execution triggered by the SI to
collect the trace œÑtogether with the path condition. In the second
step, there are two important tasks: 1) identifying new path prefixes
(e.g., unexplored branches) and 2) generating new SIs for each new
path prefix. Task 1 is crucial to the verification soundness and it
turns out to be highly challenging, which we will elaborate in the
next subsection. Task 2 is based on the MPC model, for which we
present our algorithm next.
Algorithm 2 describes our algorithm for generating the new SIs
from a trace œÑand a path prefix prefix . It first identifies a set of poten-
tial new path prefixes, P, based onœÑandprefix (recall Section 3.4).
For each new path prefix pinP, it constructs a formula Œ¶mpc(p)of
constraints to generate a corresponding SI (which should exist if
pis feasible). Œ¶mpc(p)corresponds to the MPC constraints of the
path prefix p, which considers a subtrace of œÑcontaining only those
events in p. Any solution to Œ¶mpc(p)produces a concrete thread
schedule and a concrete input that can drive the program to execute
the path prefix p.
It is important to note that the formula Œ¶mpc(p)is sound, i.e., it
only captures the space of feasible SIs with respect to path prefix p.
Those events that are not on pare excluded from Œ¶dcandŒ¶sync.
Consider an example in Figure 7. For exploring the path prefix AB
with path condition R1y=1‚àßR3x=2, the writes at lines 2 and 4 are
not considered because they are not executed on this path prefix.
Another advantage of MPC over MCR is that the complexity of
generated constraints can be significantly reduced. To generate a
new schedule that manifests an event, MCR has to ensure that all
dependent reads of this event (which are conservatively assumed in
MCM as all events that must happen before this event) must return
                T1                                  T2                             Initially x=0; 1. if (x>0) x=1;    // A           4. if (x==2)   // C     else {                               5.     error; 2.    if (j>0) x=2;  // B 3.    else x=3;     }                T1                       T2                       T3                                  Initially x=0; 1. if (i>0)   // A      3. if (j>0)   // B      5. if (x==2)  // C 2.    x++;               4.    x++;               6.     error;                       T1                       T2                                                  Initially x=y=0; 1. if (y==1) x=1;   // A      3. if (x==2) y=2;  // B 2. else  x=2;                     4. else y=1;Figure 7: Example for explaining Œ¶mpc(p).
the same value as that in the observed execution. This often leads
to a large number of data-validity constraints that are expensive to
solve. However, such constraints are avoided in MPC .
3.4 Path Exploration
The key challenge in MPC is how to systematically explore the path
tree such that it does not miss any reachable path. We first present
an efficient and intuitively sound (but in fact unsound) algorithm.
We then present a sound algorithm based on the Unsat-Core [9] of
unsatisfiable MPC formulas.
3.4.1 Strategy 1: Combining Unexplored Path Suffixes. Our first
strategy is to combine unexplored path suffixes, which are exposed
in the newly observed execution trace. This is a natural extension
of how existing symbolic execution engine (e.g., KLEE) explores
paths for sequential programs. For example, consider a trace œÑwith
two threads driven by a path prefix pre. Suppose preis extended
with suffixes AandBfor each of the two threads, respectively. That
is, the newly explored path pispre-A-B. Note that AandBare path
conditions with respect to two branch choices. Hence, there are
three new possible path prefixes identified by combining different
branch choices: pre-A-B,pre-A-Bandpre-A-B, where Xmeans
the negation of X, i.e., the path follows the opposite choice of the
corresponding branch.
More generally, let split(pre,p)refer to the set of new path prefix
combinations based on a newly explored path pand a corresponding
path prefix pre, and let suffix(pre,p,Ti)(suffix(Ti)for short) denote
the path extension for thread Tifrom pretop. Then split(pre,p)
contains new path prefixes formed by all combinations of suffix(Ti)
and its negations among all threads. For each individual thread,
suffix(Ti)may exhibit more than one new branch. For example,
suppose suffix(Ti)=b1-b2-b3, then three path prefixes b1,b1-b2and
b1-b2-b3are identified. Note that other combinations such as b1-
b2-b3are not valid because the execution of a branch may depend
on the preceding branch choices. In total, split(pre,p)contains
N√ñ
i=1(|suffix(Ti)|+1)path prefixes, where Nis the number of threads
and|suffix(Ti)|the number of branches in suffix(Ti).
On the surface, this strategy appears sound as it explores each
combination of path prefixes once. However, it is unsound that
it may miss certain reachable paths. Consider an example in Fig-
ure 8(a), which contains two inputs iandj, and one shared variable
x. Let A,BandCdenote the branches at lines 1, 2 and 4, respec-
tively. Suppose the first explored path is p0={T1:A,T2:C}, where the
branch at line 1 is true (i>0) and the branch at line 4 is false
(R4x,2). Three unexplored path prefixes are identified: p1={T1:A,
T2:C},p2={T1:A,T2:C}, and p3={T1:A,T2:C}. Among them, both p1
371Concurrency Verification with Maximal Path Causality ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA
                T1                                  T2                             Initially x=0;                    i = input(); j = input(); 1. if (i>0) x=1;    // A                4. if (x==2)   // C     else {                                   5.     error; 2.    if (j>0) x=2;  // B 3.    else x=3; }(a)Truep1: ACp2: ACp4: ABCp5: ABCp0: ACp3: AC (b)
Truep1: ACp2: ACp3: AC p4: ABCp0: ACp5: ABCp6: ABCp7: ABC(c)
Figure 8: (a) An example. (b) Strategy 1 fails to explore the error path ABC. (c) Strategy 2 is sound.
andp3are unreachable (based on the constraints generated from
the observed trace), and only p2is reachable. Hence, p2is further
explored, which generates p4={T1:AB,T2:C}. Based on p4, a new
path prefix p5={T1:AB,T2:C} is identified.
The final path tree constructed by Strategy 1 is depicted in Fig-
ure 8(b). The error path ABC is missed. The reason is that Strategy
1 relies only on the observed trace to determine if a path prefix
is reachable or not. However, the first trace œÑ1only observes the
true-branch at line 1, and thus does not provide any information
along the false-branch, which affects the branch decision at line 4.
3.4.2 Strategy 2: Unsat-Core (UC)-based Thread-independent Explo-
ration. The key idea behind Strategy 2 is to distinguish unreachable
path prefixes from those overly-subsuming path prefixes (defined
below). For example, the path prefix p3in Figure 8(b) subsumes
two concrete paths: an unreachable path { T1:AB,T2:C} and a reach-
able path { T1:AB,T2:C}, which is the error path. Strategy 2 splits
such overly-subsuming path prefixes by discovering new behav-
iors through extending each thread independently. More formally,
overly-subsuming path prefixes can be defined as follows:
Definition 3.4. (Overly-subsuming Path Prefix). Given a trace œÑ
with Nthreads and its corresponding path p, and let p(Ti)denote
the path prefix along thread Ti. For path prefix pre,p‚Ä≤‚ààsplit(pre,p)
is an over-subsuming path prefix, if the following two conditions
are satisfied:
‚Ä¢C1:Œ¶mpc(p‚Ä≤)is unsatisfiable.
‚Ä¢C2: There exists a thread set Tset, based on which a reach-
able path prefix pextcan be constructed, where Tset‚äÜ
Threads(UC(Œ¶mpc(p‚Ä≤)))and for each Ti,pext(Ti)is defined
as follows:
pext(Ti)=Ô£±Ô£¥Ô£¥ Ô£≤
Ô£¥Ô£¥Ô£≥pre(Ti),ifTi‚ààTset ;
p‚Ä≤(Ti), otherwise .
The above conditions state that p‚Ä≤is an overly-subsuming path
prefix if it is not reachable based on œÑ(by satisfying C1), but there
exists a reachable path, pext, in which each thread Tiwhich follows
pre(Ti)orp‚Ä≤(Ti)(by satisfying C2).
We propose to identify the overly-subsuming path prefixes based
on the root causes of unsatisfiability (i.e., the UCs of the unsatisfiable
formula). An Unsat Core (UC) of a formula Fis a subset of the
clauses in Fthat contribute to its unsatisfiability. For example,
{x=1,y=1,x>2,y<0}is an UC of the formula (x=1‚àßy=
1‚àßx>2‚àßy<0‚àßz>0). Condition z>0is excluded from the
UC, because it makes no contribution to the unsatisfiability.Strategy 2 identifies the UCs of formula Œ¶mpc(p‚Ä≤)for each un-
reachable path prefix p‚Ä≤, and maps them back to a thread set
Threads(UC(Œ¶p‚Ä≤)), which contains threads that contribute clauses
to the UCs. Then, it tries to explore a path prefix pextwhich extends
the prefixes along all threads except those in Threads(UC).
We note that to ensure soundness, all threads that contribute to
the unsatisfiability of Œ¶mpc(p‚Ä≤)must be considered. Without the UC,
one would have to extend the path prefix along all possible thread
combinations to check the reachability, which may introduce many
redundant explorations. Therefore, the use of the UCs is important
to both the soundness and the performance of Strategy 2. In our
implementation, we first consider the biggest UC because it may
exclude the most threads from being extended, and thus avoiding
unnecessary redundant explorations. When failed, to guarantee
the soundness, we continue to consider the smaller UCs, until it
succeeds or no more UCs can be further identified.
Consider again the example in Figure 8. Although there exists
no SI to satisfy p3={T1:A,T2:C}, Strategy 2 finds that p3is an overly-
subsuming path prefix. First, the basic condition C1is satisfied be-
cause p3is unsatisfiable based on p0. Second, C2is satisfied, because
it can generate an SI to extend T1along the path prefix p3(T1)=A.
Specifically, when p3is identified as unreachable by checking that
Œ¶pc={i‚â§0‚àßR4x=2}is unsatisfiable, Strategy 2 checks condi-
tionC2as follows. First, it computes UC(Œ¶pc), which is R4x=2.
Thus, the corresponding Threads(UC)is{T2}, which means that
only thread T2contributes to the unsatisfiability. Then, Strategy 2
constructs path condition of pextasp3(T1)‚àßTrue(T2). Finally, a new
SI is generated to drive the program to explore path pext={T1:AB,
T2:C}, which extends prefix Aalong T1as expected. Then p3is split
into two new path prefixes: p6={T1:AB,T2:C}, and p7={T1:AB,T2:C}.
At this time, p6is a reachable path prefix based on pext. Thus, it
successfully generates a new SI combination for triggering an ex-
ecution along path prefix p6. Figure 8(c) shows the final path tree
constructed by Strategy 2 for this example. In total, 4 reachable
paths are explored.
We next prove the soundness of Strategy 2:
Theorem 1 (Soundness). Strategy 2 will explore all reachable
paths if the solver is sound, i.e., for a satisfiable constraint formula it
always returns a correct solution.
Proof .By contradiction. Suppose a reachable path pis missed by
Strategy 2 (S2). There are only two possible reasons. First, pis not
identified. This is impossible because upon observing any new path,
all possible path prefix combinations are identified in split(pre,p).
Second, pis determined to be unreachable. For this, since the solver
372ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA Qiuping Yi and Jeff Huang
Algorithm 3: Parallel- MPC (si,prefix )
1:œÑ‚ÜêGuidedSE(si,prefix);
2:SI‚ÜêParallel-GenerateNewSI( œÑ,prefix ):
3:par-forall (si,p)‚ààSI
4: Parallel- MPC (si,p);
is sound, pmust not be an overly-subsuming path prefix, meaning
thatpviolates C1 or C2. If C1 is violated, then an SI can be directly
generated. If C2 is violated, then S2 must have missed a certain way
to break the identified Unsat Core. However, S2 has enumerated
all possible ways to break the root cause of an unreachable path
prefix. Thus, pmust be unreachable when S2 fails to further extend
it, contradicting to the initial hypothesis.
3.5 The Parallel MPC Algorithm
Different from other state-space exploration techniques [ 19,25]
which are difficult to parallelize, the MPC algorithm can be eas-
ily parallelized. Specifically, the online path exploration can be
parallelized because it only depends on the provided SI. Similarly,
the offline path identification can be parallelized, because it only
depends on the trace information collected from the observed exe-
cution. Algorithm 3 describes the parallelized MPC algorithm. For
each SI and the corresponding path prefix, Parallel-MPC first car-
ries out a guided symbolic execution as in the sequential algorithm,
and then invokes Parallel-GenerateNewSI to generate new SIs and
path-prefixes in parallel. For each new SI and path prefix, it then
starts a parallel instance of Parallel-MPC to continue exploring.
4 EVALUATION
We implemented MPC [1] for Pthread-based C++ programs based
on KLEE [ 7] and Z3 [ 16].MPC contains an application-level sched-
uler, a runtime tracer, and an offline SI generator. The scheduler
takes an SI as input to guide the thread execution by intercept-
ing critical events on shared variables. The runtime tracer per-
forms symbolic execution along the controlled execution to collect
path conditions and the trace, such as reads and writes on shared
variables, and synchronization operations by Pthread library calls.
When a new execution is completed, the offline generator reads the
trace information and constructs the constraints. Then it invokes
Z3 to identify newly unexplored paths. The output of the offline
generator is a set of SIs to trigger the iterative analysis process.
The parallelized implementation initializes a new iteration of path
exploration whenever a new SI is generated and an idle worker is
available.
To compare MPC with MCR, we also implemented MCR for
checking C/C++ programs (the original MCR [ 20] was implemented
for Java).
We evaluated MPC with three sets of experiments. All experi-
ments were run on a four-core Linux machine with 2.7GHz Intel i5
CPU and 8GB RAM. The timeout for each benchmark was set to
one hour.
4.1 Finding Tricky Concurrency Bugs
We first evaluated MPC for finding tricky bugs in a set of micro-
benchmarks and a specially designed third-party benchmark, racey [32],which contains intensive races for evaluating concurrency bug find-
ing and reproduction techniques. For the micro-benchmarks (code
omitted due to page limit), we generated nine variants ( M1-M9) of
the example ( M0) in Figure 2 by varying the number of threads.
Mirepresents the program that contains i+3threads, including
the original threads ( T1-T3), and iextra threads, each of which
executes code {int k=input(); if(k==10)x++;} . In addition,
the statement at line 11 in Figure 2 is changed to if(x==i+101)
from if(x==101) . With more threads involved, the chance of trig-
gering the crash at line 13 becomes smaller. To ensure program
termination, the maximal value of jis set to 2.
Because MCR does not handle program inputs, we conducted
three types of experiments. First, providing MCR with a random
input in each execution. Second, providing it with a fixed but in-
correct input that cannot trigger the error. Third, providing it with
a fixed correct input where iandjare set to 3 and 2 respectively,
and other inputs to 10. This guarantees that MCR will trigger the
error under certain schedules. For the first two experiments, our
results confirm that MCR cannot find the error before timeout. In
fact, when provided with a random input, MCR often fails at the
runtime scheduling phase because the seed interleavings (which
are used to control the schedule) are computed for a different input.
Table 1 reports the results for the third experiment. Overall, MPC
with the sound path exploration strategy (S2) outperforms MCR
consistently by finding the error with significantly fewer executions
and more identified paths. In most cases ( M3-M9), MCR runs time-
out without finding the error even though the bug-triggering input
is provided. For MPC with the unsound strategy (S1), although it
is much faster than S2, due to the unsoundness it fails to find the
tricky error. For S2, it finds all the errors except the timeout case in
M9.
Forracey , due to its intensive races it typically computes different
outputs in different runs. We seed an error by inserting an assertion
at the end of the program to check if the program can produce a
certain output. To ensure termination, we set the maximal number
of checking the barrier states in each thread to 10. All techniques
explored the same number of paths, but MCR took the longest
time, 4X slower than S1 and 2X slower than S2. The reason is that
compared to MPC , MCR generates significantly more constraints
and also more solver invocations due to more executions.
Performance of Parallel MPC. Table 1 Columns 11-14 report
the performance of the parallelized MPC on the same benchmarks.
Compared to the sequential version, the parallel MPC achieves
as much as 3.3X speedup on the four-core machine. Nevertheless,
we note that our current implementation is not fully optimized.
To balance parallelism and resource consumption, the verification
tasks are not totally parallelized. In addition, the task partition
and thread dispatching in our implementation introduce additional
overhead.
4.2 Evaluation on Concurrency Libraries
We next evaluated MPC on a collection of real-world concurrency
libraries, including Dekker‚Äôs mutual exclusion algorithm ( dekker ),
CAS-based Spinlock ( spinlock ), Linux reader-write lock ( linuxr-
wlock ), Michael and Scott lock-free queue ( MSQueue ), Linux reader-
write lock ( linuxrwlock ), and Linux sequential lock ( seqlock ). For
373Concurrency Verification with Maximal Path Causality ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA
Table 1: Results of finding tricky bugs. TO: timeout of one hour. ‚úì(‚úó): the error is found (not found).
Benchmark#Paths Time Parallel-Time SpeedUp
MCR MPC -S1 MPC -S2 MCR MPC -S1 MPC -S2 MPC -S1 MPC -S2 MPC -S1 MPC -S2
M0 3/‚úì 6/‚úó 10/‚úì 14s.49 0s.31 0s.79 0s.26 0s.48 1.19 1.65
M1 3/‚úì 12/‚úó 16/‚úì 2m13s.33 0s.71 1s.55 0s.39 0s.77 1.82 2.06
M3 1/‚úó 48/‚úó 52/‚úì TO 2s.98 5s.43 1s.64 3s.33 1.82 2.14
M5 1/‚úó 192/‚úó 196/‚úì TO 16s.23 38s.11 8s.88 20s.37 1.83 2.05
M7 1/‚úó 768/‚úó 772/‚úì TO 1m30s.28 13m50s.01 50s.66 3m17s.02 1.78 2.65
M9 1/‚úó 3,072/‚úó 2,462/‚úó TO 8m27s.32 TO 5m21s.43 22m42s.17 1.58 >2.64
Racey 432/‚úì 432/‚úì 432/‚úì18m52s.51 4m27s.83 7m39s.65 2m25s 3m23s 1.72 2.26
Table 2: Results on real-world concurrency libraries.
Program Setting#Paths Time
MCR MPC MCR MPC
Dekker1 T=2,P=20 729 929 2m13s.34 1m24s.47
Dekker2 T=2,P=30 2,623 2,970 12m52s.34 5m46s.23
Spinlock1 T=2,K=5 363 522 15m49s.16 1m6s.38
Spinlock2 T=3,K=3 375 1,357 20m53s.72 3m28s.47
Linuxrwlock T=2,K=5 116 1,910 TO 35m8s.39
MSQueue T=2,K=5 152 539 TO 4m6s.12
Seqlock T=3,K=3 204 3,877 TO 13m2s.51
each concurrency library, we wrote a driver such that their in-
puts can be configured (i.e., not fixed). For all benchmarks, we also
compared with MCR by running it with a fixed correct input.
Table 2 summarizes the results. Tis the number of threads, Pis
the maximal number of attempts to enter the critical section (for
Dekker ) and Kis the number of attempts to acquire and release the
lock (for the others). Overall, MPC significantly outperforms MCR
on all these benchmarks in terms of efficiency and effectiveness.
For most benchmarks, MCR explores many redundant paths (i.e.,
repeatedly explores the same path), because it generates schedules
for unique states only, but multiple states can be exhibited by the
same path. For MPC (with the sound path exploration strategy), it
explores orders of magnitude more unique paths than MCR with
less time or within the same timeout period.
4.3 Comparison with Con2Colic
We have also compared MPC with Con2Colic [ 18], a concolic test-
ing technique for concurrent programs. Con2Colic maintains a list
of interference scenarios that capture inter-thread data flow, and
systematically explores program branches by enumerating all inter-
ference scenario candidates (ISC) upto a degree K (the number of
inter-thread data flow edges in the ISC). Because an unrealizable ISC
may become realizable after new states are explored in the future,
a challenge faced by Con2Colic is memoizing all the unrealizable
ISCs. It stores all ISCs in a global interference forest and upon a new
branch is explored it validates the realizability of each ISC. This
incurs both a large memory overhead and expensive validations of
unrealizable ISCs. Differently, MPC does not memorize any states
but tracks the path prefixes through constraint solving, and it mod-
els both the path condition constraints and thread interleavings in
a uniform constraint formula, thus simultaneously checking all SI
combinations that cover the same path.Table 3: MPC and Con2colic on real applications.
ProgramCon2colic MPC
K#Runs Success? Time #Paths Success? Time
aget 7 6 ‚úì(3) 23s.6 4‚úì(2) 13s
apache-a 15 411 ‚úì(17/18) 1m32s 80‚úì(6/37) 9s.53
apache-b 11 43 ‚úì(16) 3s.24 22‚úì(3) 1s.6
bluetooth 1 11 ‚úì(7) 0s.8 36‚úì(3) 2s.5
ctrace1 1 5 ‚úì‚úó(4) 0s.75 10‚úì(1/2) 3s.1
ctrace2 2 37 ‚úì(4/5) TO 393‚úì(2/3) 2m23s
pfsan - - ‚úó(OOM ) - 112‚úì(1/3) 3m39s
rbtree - - -( crash ) - 1 -(no bug) 0s.5
sor 4 8 ‚úì(1/2/7) 0s.8 4‚úì(1/2/4) 1s.2
splay 17 34 -(no bug) 4s.6 13 -(no bug) 2s.3
Table 3 reports the results on the benchmarks collected from
the ConCREST tool [ 13]. Because Con2Colic is not parallel, we
compare it with the sequential MPC . Columns Kand#Runs respec-
tively report the largest degree of interferences and the number
of executions explored by Con2colic. Column #Paths reports the
number of paths explored by MPC . Note that there is no correspon-
dance between #Runs and#Paths . Because Con2colic is driven by
ISCs rather than unique paths, Con2colic tends to explore many
executions that exercise the same path. Column Success? reports if
the technique detects the known bugs in the benchmark, and if yes
‚úì(x/y) shows the first bug was identified in the xth execution and
the second bug was identified in the yth execution, etc. Column
Time reports the total exploration time for each technique.
Overall, MPC is more effective than Con2colic for verification:
MPC finds more bugs than Con2colic and incurs fewer executions
to find the same bug. Our results also show that Con2colic is un-
sound, e.g., it finishes without detecting the second bug in Ctrace1
and it missed the bugs in pfscan due to out of memory. Although
in three out of the ten cases, MPC takes longer than Con2colic to
finish, MPC always explores more unique paths than Con2colic.
For example, for Apache-a ,MPC explores 1364 unique paths but
Con2colic explores at most 411 paths (bounded by the 411 execu-
tions explored by Con2colic). Although MPC timeouts, it is able to
verify 953 more paths than Con2colic. This also explains why MPC
can find the second bug in Ctrace1 whereas Con2colic cannot.
We also designed a micro-benchmark (Figure 9) to quantify the
performance differences between MPC and Con2colic. The asser-
tion can only be violated if every execution of lines 4 and 5 in
thread T1is interleaved by the execution of line 9 from the same
loop iteration in thread T2. Our results shows that MPC is more
efficient and effective than Con2colic. When Nis small (from 1 to
374ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA Qiuping Yi and Jeff Huang
    T1                       T2          Initially x=0 1.r1=x               3. x=1 2.r2=x          assert(r1+r2<2);                     1. for(int i=0;i<N;i++){ 2.      int tmp = x; 3.      tmp=tmp+1; 4.      x=tmp; 5.      if(x==tmp) 6.         x=0; 7.  }                     8.   for(int i=0;i<N;i++) 9.           x++;        assert(x!=2*N);T1T2
1277
1278
1279
1280
1281
1282
1283
1284
1285
1286
1287
1288
1289
1290
1291
1292
1293
1294
1295
1296
1297
1298
1299
1300
1301
1302
1303
1304
1305
1306
1307
1308
1309
1310
1311
1312
1313
1314
1315
1316
1317
1318
1319
1320
1321
1322
1323
1324
1325
1326
1327
1328
1329
1330
1331
1332
1333
1334ESEC/FSE 2018, 4-9 November, 2018, Lake Buena Vista, Florida, United States Anon.
1335
1336
1337
1338
1339
1340
1341
1342
1343
1344
1345
1346
1347
1348
1349
1350
1351
1352
1353
1354
1355
1356
1357
1358
1359
1360
1361
1362
1363
1364
1365
1366
1367
1368
1369
1370
1371
1372
1373
1374
1375
1376
1377
1378
1379
1380
1381
1382
1383
1384
1385
1386
1387
1388
1389
1390
1391
1392Table 4: Results of MPCand Con2colic on the micro-benchmark in Figure 10.
NCon2colic MPC
K#Runs Success? Time #Paths Success? Time
1 25 3(5) 0s.2 43(2) 0s.1
2 3 12 3(12) 1s 63(3) 0s.4
3 5 123 3(123) 6m47s 10 3(4) 0s.7
4 4 462 7 TO 18 3(6) 1s.6
5 3 697 7 TO 34 3(22) 4s.3
REFERENCES
[1][n. d.]. SV-COMP. http://sv-comp.sosy-lab.org. ([n. d.]).
[2]Parosh Abdulla, Stavros Aronis, Bengt Jonsson, and Konstantinos Sagonas.
2014. Optimal Dynamic Partial Order Reduction. In Proceedings of the 41st
ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages .
[3]Parosh Aziz Abdulla, Stavros Aronis, Mohamed Faouzi Atig, Bengt Jons-
son, Carl Leonardsson, and Konstantinos Sagonas. 2015. Stateless Model
Checking for TSO and PSO. In Proceedings of the 21st International Conference
on Tools and Algorithms for the Construction and Analysis of Systems .
[4]Tom Bergan, Luis Ceze, and Dan Grossman. 2013. Input-covering Schedules
for Multithreaded Programs. In Proceedings of the 2013 ACM SIGPLAN
International Conference on Object Oriented Programming Systems Languages
&#38; Applications .
[5]Sebastian Burckhardt, Rajeev Alur, and Milo M. K. Martin. 2007. Check-
Fence: Checking Consistency of Concurrent Data Types on Relaxed Memory
Models. In Proceedings of the 28th ACM SIGPLAN Conference on Programming
Language Design and Implementation .
[6]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: unas-
sisted and automatic generation of high-coverage tests for complex systems
programs. In Proceedings of the 8th USENIX conference on Operating systems
design and implementation .
[7]Alessandro Cimatti, Alberto Griggio, and Roberto Sebastiani. 2011. Com-
puting Small UnsatisÔ¨Åable Cores in SatisÔ¨Åability Modulo Theories. J. Artif.
Int. Res. (2011).
[8]Edmund Clarke, Daniel Kroening, and Flavio Lerda. 2004. A tool for
checking ANSI-C programs. In In Tools and Algorithms for the Construction
and Analysis of Systems . Springer, 168‚Äì176.
[9]E M Clarke, O Grumberg, M Minea, and D Peled. 1999. State space reduction
using partial order techniques. International Journal on Software Tools for
Technology Transfer (1999).
[10] E M Clarke, O Grumberg, M Minea, and D Peled. 1999. State space reduction
using partial order techniques. International Journal on Software Tools for
Technology Transfer (1999).
[11] ConCREST. last accessed May 2017. ConCREST.
http://forsyte.at/software/concrest/. (last accessed May 2017).
[12] Heming Cui, Jingyue Wu, John Gallagher, Huayang Guo, and Junfeng Yang.
2011. E  cient Deterministic Multithreading Through Schedule Relaxation.
InProceedings of the Twenty-Third ACM Symposium on Operating Systems
Principles .
[13] Heming Cui, Jingyue Wu, Chia-Che Tsai, and Junfeng Yang. 2010. Stable De-
terministic Multithreading Through Schedule Memoization. In Proceedings
of the 9th USENIX Conference on Operating Systems Design and Implementation .
[14] Leonardo De Moura and Nikolaj Bj√∏rner. 2008. Z3: An E  cient SMT
Solver. In Proceedings of the Theory and Practice of Software, 14th International
Conference on Tools and Algorithms for the Construction and Analysis of Systems .
[15] Brian Demsky and Patrick Lam. 2015. SATCheck: SAT-directed Stateless
Model Checking for SC and TSO. In Proceedings of the 2015 ACM SIGPLAN
International Conference on Object-Oriented Programming, Systems, Languages,
and Applications .
[16] Azadeh Farzan, Andreas Holzer, Niloofar Razavi, and Helmut Veith. 2013.
Con2Colic Testing. In Joint European Software Engineering Conference and
ACM SIGSOFT Symposium on Foundations of Software Engineering .
[17] Cormac Flanagan and Patrice Godefroid. 2005. Dynamic Partial-order
Reduction for Model Checking Software. In Proceedings of the 32Nd ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages .
[18] Je Huang. 2015. Stateless Model Checking Concurrent Programs with
Maximal Causality Reduction. In PLDI .
[19] Je Huang, Patrick O‚ÄôNeil Meredith, and Grigore Rosu. 2014. Maximal
Sound Predictive Race Detection with Control Flow Abstraction. In Proceed-
ings of the 35th ACM SIGPLAN Conference on Programming Language Design
and Implementation .
[20] Shiyou Huang and Je  Huang. 2016. Maximal Causality Reduction for TSO
and PSO. In Proceedings of the 2016 ACM SIGPLAN International Conference
on Object-Oriented Programming, Systems, Languages, and Applications .[21] Omar Inverso, Ermenegildo Tomasco, Bernd Fischer, Salvatore La Torre,
and Gennaro Parlato. 2014. Bounded Model Checking of Multi-threaded C
Programs via Lazy Sequentialization. In Proceedings of the 16th International
Conference on Computer Aided VeriÔ¨Åcation - Volume 8559 . 585‚Äì602.
[22] Maged M. Michael and Michael L. Scott. 1996. Simple, Fast, and Practical
Non-blocking and Blocking Concurrent Queue Algorithms. In Proceedings
of the Fifteenth Annual ACM Symposium on Principles of Distributed Computing .
[23] Madanlal Musuvathi, Shaz Qadeer, Thomas Ball, Gerard Basler, Pira-
manayagam Arumuga Nainar, and Iulian Neamtiu. 2008. Finding and
Reproducing Heisenbugs in Concurrent Programs. In Proceedings of the 8th
USENIX Conference on Operating Systems Design and Implementation .
[24] Shaz Qadeer and Dinghao Wu. 2004. KISS: Keep It Simple and Sequential. In
Proceedings of the ACM SIGPLAN 2004 Conference on Programming Language
Design and Implementation . 14‚Äì24.
[25] Zvonimir Rakamaric and Michael Emmi. 2014. SMACK: Decoupling Source
Language Details from VeriÔ¨Åer Implementations. In 26th International Con-
ference on Computer Aided VeriÔ¨Åcation . 106‚Äì113.
[26] Stephen F. Siegel, Manchun Zheng, Ziqing Luo, Timothy K. Zirkel, Andre V.
Marianiello, John G. Edenhofner, Matthew B. Dwyer, and Michael S. Rogers.
2015. CIVL: The Concurrency Intermediate VeriÔ¨Åcation Language. In
Proceedings of the International Conference for High Performance Computing,
Networking, Storage and Analysis . 61:1‚Äì61:12.
[27] Emina Torlak, Mandana Vaziri, and Julian Dolby. 2010. MemSAT: Checking
Axiomatic SpeciÔ¨Åcations of Memory Models. In Proceedings of the 31st ACM
SIGPLAN Conference on Programming Language Design and Implementation .
[28] Anthony Williams. 2012. Dekker‚Äôs algorithm implementation. In
https://www.justsoftwaresolutions.co.uk/threading/ .
[29] Min Xu, Rastislav Bodik, and Mark D. Hill. 2003. A ‚ÄùFlight Data Recorder‚Äù
for Enabling Full-system Multiprocessor Deterministic Replay. In Proceed-
ings of the 30th Annual International Symposium on Computer Architecture .
[30] Naling Zhang, Markus Kusano, and Chao Wang. 2015. Dynamic Partial Or-
der Reduction for Relaxed Memory Models. In Proceedings of the 36th ACM
SIGPLAN Conference on Programming Language Design and Implementation .
Figure 9: MPC and Con2colic on benchmark.
3), both Con2colic and MPC can identify the assertion violation.
However, MPC takes significantly fewer executions and much less
time to expose the bug than Con2colic. When Nbecomes larger
than 3, Con2colic starts to run timeout in an hour without finding
the bug, whereas MPC identifies the bug within a few seconds.
5 RELATED WORK
We would also like to compare with the SV-COMP [ 2] tools such as
Yogar-CMBC [ 33] and Laze-CSeq [ 23] in future work. Most existing
tools for concurrency verification are based on BMC [ 10,29,33]
or lazy sequentialization [ 23,28]. Different from MPC , BMC uses
bounded loop unfolding, and lazy sequentialization translates a
multithreaded program into a nondeterministic sequential program.
These approaches target the interleaving space but not the input
space.
Many improvements on partial order reduction (POR) [ 11,12]
have been proposed to optimize its performance and effective-
ness, such as sleep set [ 19] and source set [ 3]. These methods
have also been extended to handle weak memory models [ 4,35].
However, they cannot handle different program inputs. Several
other constraint-based approaches have been proposed for verify-
ing concurrent programs, such as MemSAT [ 31], CheckFence [ 6]
and SATCheck [ 17]. These approaches also assume a fixed program
input.
Minion [ 30] synthesizes concurrency tests with heuristics which
also generate schedule+input to violate a given assertion. While
Minion requires sophisticated static analysis (e.g., data-flow analy-
sis, alias analysis and program slicing), MPC is purely dynamic (it
uses concrete executions and dynamic symbolic execution). More-
over, Minion is unsound in that it provides no guarantee if the
assertion holds or not when it cannot generate a test that falsifies
the assertion.
Several approaches [ 5,14,15] based on schedule memoization
have been developed to reduce redundant schedules across inputs.
These approaches can be expensive due to the cost of memoizing
schedules for many different inputs.6 CONCLUSION
We have presented MPC , a new approach that effectively verifies
concurrent programs across both the input space and the sched-
ule space. As MPC shares the same workflow with dynamic sym-
bolic execution, we expect that many testing, debugging and repair
techniques developed based on symbolic execution for sequential
programs can be naturally extended to concurrent programs by
utilizing MPC .
ACKNOWLEDGEMENTS
We wish to thank the anonymous reviewers for many insightful
comments and constructive feedback. This work was supported by
NSF awards CCF-1552935 and CNS-1617985.
REFERENCES
[1] MPC. https://github.com/parasol-aser/MPC. (2018).
[2] SV-COMP. http://sv-comp.sosy-lab.org. (2018).
[3]Parosh Abdulla, Stavros Aronis, Bengt Jonsson, and Konstantinos Sagonas.
2014. Optimal Dynamic Partial Order Reduction. In Proceedings of the 41st ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages .
[4]Parosh Aziz Abdulla, Stavros Aronis, Mohamed Faouzi Atig, Bengt Jonsson, Carl
Leonardsson, and Konstantinos Sagonas. 2015. Stateless Model Checking for
TSO and PSO. In Proceedings of the 21st International Conference on Tools and
Algorithms for the Construction and Analysis of Systems .
[5]Tom Bergan, Luis Ceze, and Dan Grossman. 2013. Input-covering Schedules for
Multithreaded Programs. In Proceedings of the 2013 ACM SIGPLAN International
Conference on Object Oriented Programming Systems Languages and Applications .
[6]Sebastian Burckhardt, Rajeev Alur, and Milo M. K. Martin. 2007. CheckFence:
Checking Consistency of Concurrent Data Types on Relaxed Memory Models.
InProceedings of the 28th ACM SIGPLAN Conference on Programming Language
Design and Implementation .
[7]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: unassisted
and automatic generation of high-coverage tests for complex systems programs.
InProceedings of the 8th USENIX conference on Operating systems design and
implementation .
[8]Cristian Cadar and Koushik Sen. 2013. Symbolic Execution for Software Testing:
Three Decades Later. Commun. ACM 56, 2 (2013), 82‚Äì90.
[9]Alessandro Cimatti, Alberto Griggio, and Roberto Sebastiani. 2011. Computing
Small Unsatisfiable Cores in Satisfiability Modulo Theories. J. Artif. Int. Res.
(2011).
[10] Edmund Clarke, Daniel Kroening, and Flavio Lerda. 2004. A tool for checking
ANSI-C programs. In In Tools and Algorithms for the Construction and Analysis of
Systems . Springer, 168‚Äì176.
[11] E M Clarke, O Grumberg, M Minea, and D Peled. 1999. State space reduction using
partial order techniques. International Journal on Software Tools for Technology
Transfer (1999).
[12] E M Clarke, O Grumberg, M Minea, and D Peled. 1999. State space reduction using
partial order techniques. International Journal on Software Tools for Technology
Transfer (1999).
[13] ConCREST. last accessed May 2017. ConCREST.
http://forsyte.at/software/concrest/. (last accessed May 2017).
[14] Heming Cui, Jingyue Wu, John Gallagher, Huayang Guo, and Junfeng Yang.
2011. Efficient Deterministic Multithreading Through Schedule Relaxation. In
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles .
[15] Heming Cui, Jingyue Wu, Chia-Che Tsai, and Junfeng Yang. 2010. Stable Deter-
ministic Multithreading Through Schedule Memoization. In Proceedings of the
9th USENIX Conference on Operating Systems Design and Implementation .
[16] Leonardo De Moura and Nikolaj Bj√∏rner. 2008. Z3: An Efficient SMT Solver. In
Proceedings of the Theory and Practice of Software, 14th International Conference
on Tools and Algorithms for the Construction and Analysis of Systems .
[17] Brian Demsky and Patrick Lam. 2015. SATCheck: SAT-directed Stateless Model
Checking for SC and TSO. In Proceedings of the 2015 ACM SIGPLAN International
Conference on Object-Oriented Programming, Systems, Languages, and Applica-
tions .
[18] Azadeh Farzan, Andreas Holzer, Niloofar Razavi, and Helmut Veith. 2013.
Con2Colic Testing. In Joint European Software Engineering Conference and ACM
SIGSOFT Symposium on Foundations of Software Engineering .
[19] Cormac Flanagan and Patrice Godefroid. 2005. Dynamic Partial-order Reduction
for Model Checking Software. In Proceedings of the 32Nd ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages .
375Concurrency Verification with Maximal Path Causality ESEC/FSE ‚Äô18, November 4‚Äì9, 2018, Lake Buena Vista, FL, USA
[20] Jeff Huang. 2015. Stateless Model Checking Concurrent Programs with Maximal
Causality Reduction. In PLDI .
[21] Jeff Huang, Patrick O‚ÄôNeil Meredith, and Grigore Rosu. 2014. Maximal Sound Pre-
dictive Race Detection with Control Flow Abstraction. In Proceedings of the 35th
ACM SIGPLAN Conference on Programming Language Design and Implementation .
[22] Shiyou Huang and Jeff Huang. 2016. Maximal Causality Reduction for TSO
and PSO. In Proceedings of the 2016 ACM SIGPLAN International Conference on
Object-Oriented Programming, Systems, Languages, and Applications .
[23] Omar Inverso, Ermenegildo Tomasco, Bernd Fischer, Salvatore La Torre, and
Gennaro Parlato. 2014. Bounded Model Checking of Multi-threaded C Programs
via Lazy Sequentialization. In Proceedings of the 16th International Conference on
Computer Aided Verification - Volume 8559 . 585‚Äì602.
[24] Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2016. Angelix: Scalable
multiline program patch synthesis via symbolic analysis. In Proceedings of the
38th International Conference on Software Engineering . 691‚Äì701.
[25] Madanlal Musuvathi, Shaz Qadeer, Thomas Ball, Gerard Basler, Pira-
manayagam Arumuga Nainar, and Iulian Neamtiu. 2008. Finding and Reproducing
Heisenbugs in Concurrent Programs. In Proceedings of the 8th USENIX Conference
on Operating Systems Design and Implementation .
[26] Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra. 2013. SemFix: Program Repair via Semantic Analysis. In Proceedings of the
2013 International Conference on Software Engineering . 772‚Äì781.
[27] Chris Parnin and Alessandro Orso. 2011. Are Automated Debugging Techniques
Actually Helping Programmers?. In ACM International Symposium on Software
Testing and Analysis . 199‚Äì209.[28] Shaz Qadeer and Dinghao Wu. 2004. KISS: Keep It Simple and Sequential. In
Proceedings of the ACM SIGPLAN 2004 Conference on Programming Language
Design and Implementation . 14‚Äì24.
[29] Zvonimir Rakamaric and Michael Emmi. 2014. SMACK: Decoupling Source
Language Details from Verifier Implementations. In 26th International Conference
on Computer Aided Verification . 106‚Äì113.
[30] Malavika Samak, Omer Tripp, and Murali Krishna Ramanathan. 2016. Directed
Synthesis of Failing Concurrent Executions. In Proceedings of the 2016 ACM
SIGPLAN International Conference on Object-Oriented Programming, Systems,
Languages, and Applications . 430‚Äì446.
[31] Emina Torlak, Mandana Vaziri, and Julian Dolby. 2010. MemSAT: Checking
Axiomatic Specifications of Memory Models. In Proceedings of the 31st ACM
SIGPLAN Conference on Programming Language Design and Implementation .
[32] Min Xu, Rastislav Bodik, and Mark D. Hill. 2003. A "Flight Data Recorder" for
Enabling Full-system Multiprocessor Deterministic Replay. In Proceedings of the
30th Annual International Symposium on Computer Architecture .
[33] Liangze Yin, Wei Dong, Wanwei Liu, and Ji Wang. 2017. Scheduling Constraint
Based Abstraction Refinement for Multi-Threaded Program Verification. CoRR
abs/1708.08323 (2017). arXiv:1708.08323
[34] Cristian Zamfir and George Candea. 2010. Execution synthesis: a technique for
automated software debugging. In European Conference on Computer Systems .
321‚Äì334.
[35] Naling Zhang, Markus Kusano, and Chao Wang. 2015. Dynamic Partial Order
Reduction for Relaxed Memory Models. In Proceedings of the 36th ACM SIGPLAN
Conference on Programming Language Design and Implementation .
376