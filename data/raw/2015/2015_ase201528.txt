Practically Tunable Static Analysis Framework for
Large-Scale JavaScript Applications
Y oonseok Ko
KAIST
mir597@kaist.ac.krHongki Lee
KAIST
petitkan@kaist.ac.krJulian Dolby
IBM Research
dolby@us.ibm.comSukyoung Ryu
KAIST
sryu.cs@kaist.ac.kr
Abstract —We present a novel approach to analyze large-scale
JavaScript applications statically by tuning the analysis scala-
bility possibly giving up its soundness. For a given sound static
baseline analysis of JavaScript programs, our framework allows
users to deﬁne a sound approximation of selected executions
that they are interested in analyzing, and it derives a tuned
static analysis that can analyze the selected executions practically.
The selected executions serve as parameters of the frameworkby taking trade-off between the scalability and the soundnessof derived analyses. We formally describe our framework inabstract interpretation, and implement two instances of theframework. We evaluate them by analyzing large-scale real-worldJavaScript applications, and the evaluation results show that theframework indeed empowers users to experiment with differentlevels of scalability and soundness. Our implementation providesan extra level of scalability by deriving sparse versions of derived
analyses, and the implementation is publicly available.
I. I NTRODUCTION
JavaScript applications are prevalent these days and their
sizes become larger and their program logics become more
complex. One can ﬁnd various kinds of applications writtenin JavaScript including games [1], compilers [2], and evenoperating systems [3], [4]. The extensive uses of multiplelarge-scale libraries
1such as jQuery2, MooTools3, Prototype4,
and YUI5are one of the sources of the problem.
However, statically analyzing large-scale JavaScript appli-
cations is very challenging. Extremely dynamic features ofJavaScript like run-time code generation and heavy uses ofﬁrst-class functions complicate static analysis of programﬂows [5]. In addition to normal control ﬂows in programs,JavaScript involves diverse exception ﬂows, which add com-plications to control ﬂow graphs of programs and, in turn,to their static analysis. While most C program analysesignore infrequent uses of exception behaviors by
setjmp
andlongjmp , and ML-like program analyses use strongly-
typed language features to analyze exception ﬂows and todetect uncaught exceptions [6], [7], dynamic changes of objectproperties including prototypes and the lack of static typesystem in JavaScript make the static analysis of its exceptionﬂows much more complex and unscalable.
1JavaScript libraries are often called frameworks.
2http://jquery.com
3http://mootools.net
4http://prototypejs.org
5http://yuilibrary.comFor large-scale C programs, a general sparse analysis frame-
work [8], [9], [10] has been very successful in implementingpractical analyzers, but it may not be applicable to otherlanguages like JavaScript. The authors discussed it as an openissue as follows:
Applying our framework for other languages maybe more difﬁcult than that for C. For instance, fordynamic languages such as JavaScript, our simpleﬂow-insensitive pre-analysis may not be effective,since too imprecise analyses can take much timefor those languages. Designing a pre-analysis thatis cheap yet precise for other languages remains anopen problem.
Indeed, our experimental results show that simply applyingthe general sparse analysis framework to JavaScript is noteffective.
Unfortunately, even state-of-the-art JavaScript analysis tech-
niques are often sound but impractical, or practical but un-sound. Most JavaScript analysis frameworks like SAFE [11],[12], T AJS [13], [14], and W ALA [15], [16], [17] providetraditional sound static analyzers, which are not yet practicallyscalable. In addition, W ALA provides a new intentionally
unsound static analysis especially designed for scalability.
Since W ALA was originally designed for sound static analysisof Java programs, it provides a sound Propagation-Based anal-
ysis (PB) of JavaScript programs similarly for Java program
analysis. However, because such a sound analysis has shownto be impractical not being able to analyze the most widelyused JavaScript library, jQuery, W ALA provides yet anotherJavaScript analysis, an unsound Field-Based analysis (FB),b y
constructing lightweight and unsound call graphs [18], whichhas been successfully used for a commercial product IBMSecurity AppScan [19].
Given that the problem of scalable sound static analysis
of large JavaScript applications is still an open problem,users may get more beneﬁts from focusing on a subset ofprogram executions. Instead of attempting to analyze the entireprogram ﬂows, analyzing program executions selectively maybe a reasonable option. As a recently introduced term soundi-
ness [20] denotes, “attempting to capture the balance, prevalent
in practice, of over-approximated handling of most languagefeatures, yet deliberately under-approximated handling of afeature subset well recognized by experts” may be a desirable
2015 30th IEEE/ACM International Conference on Automated Software Engineering
978-1-5090-0025-8/15 $31.00 © 2015 IEEE
DOI 10.1109/ASE.2015.28541
approach to take, and many modern analysis applications like
IDEs, security analyses, and bug detectors do not requiresoundness. As we describe in more detail later in this paper,one may prefer to use a sound and elaborate analysis tounderstand every possible execution ﬂow of a given program.Or, one may want to use an efﬁcient analysis for a selectedsubset of program executions that they are interested in.
In this paper, we present a novel approach to analyze large-
scale JavaScript applications statically by tuning sound base-
line analyses for scalability using approximation of selected
executions of interest to users possibly giving up soundness.
Our framework takes a static baseline analysis that over-approximates the JavaScript semantics and a pre-analysis
that over-approximates a subset of program executions, andproduces a tuned static analysis that can analyze the selected
executions practically. The framework allows users to identifya subset of program execution ﬂows that they are interestedin analyzing to take trade-off between the scalability and thesoundness of derived analyses.
Users can tune the trade-off between the scalability and the
soundness of derived analyses by using pre-analyses of se-lected executions as parameters. The fewer program executionﬂows a pre-analysis covers, the more a derived analysis wouldbe scalable but unsound. We formally describe our frameworkin the abstract interpretation setting [21], [22] and evaluate theframework by using two instances: 1)
SWP derived from SAFE
as a sound baseline analysis and W ALA ’s PB as a sound pre-analysis; and 2)
SWF derived from SAFE as a sound baseline
analysis and W ALA ’s FB as an unsound pre-analysis. Ourexperiments with real-world JavaScript applications show that
SWF may miss some analysis results that SWP can obtain, but
it is indeed more scalable and still precise. Users may wantto ﬁnd an appropriate balance between the soundness and thescalability by tuning the coverage of pre-analyses. Our imple-mentation also provides an extra level of scalability in termsof analysis performance by deriving sparse versions of derived
analyses, and the implementation is publicly available [23].
The contributions of this paper are as follows:
●We present a novel approach that allows users to decidethe trade-off between the scalability and the soundnessof static analysis.
●We formally present the framework in the abstract in-
terpretation setting. It clearly describes assumptions andrequirements to use the framework, and it proves thesafety of derived analyses.
●We show how to use the general framework with two
concrete instances using the state-of-the-art JavaScript
analyzers, SAFE and W ALA. The instance SWP shows
that simply applying the general sparse analysis frame-work to JavaScript may not be effective, and the instance
SWF shows that focusing on selected program executions
enables analysis of large-scale JavaScript applications.
●We make our implementation publicly available [23].
Our experimental results show that the framework de-rives tuned static analyses that can analyze real-worldJavaScript applications practically.The rest of the paper is organized as follows. We illustrate
complications of statically analyzing JavaScript libraries usinga concrete code example from the YUI library (Section II). Weformally present the framework that takes a baseline analysisand a pre-analysis as inputs and derives a tuned static analysisin the abstract interpretation setting, and we prove the safety ofthe derived analyses (Section III). To show how to instantiatethe general framework, we describe two concrete instancesof the framework using SAFE as a baseline analyzer andtwo analyses of W ALA as pre-analyses (Section IV). Then,we describe our implementation (Section V) and evaluatethe framework using two instances (Section VI). We discussrelated work (Section VII) and conclude (Section VIII).
II. M
OTIV A TING EXAMPLE
While much progress has been made in analyzing modern
JavaScript applications that rely heavily on multiple libraries,signiﬁcant challenges still remain for achieving a good balanceof the analysis cost and precision. This is largely due to librarycode making extensive use of dynamic JavaScript features,especially ﬁrst-class property accesses. We use Figure 1 takenfrom the YUI library to illustrate the situation.
The
mix function in Figure 1 essentially implements a form
of mixin-based inheritance [24] to provide object-orientedfeatures within JavaScript code. The mechanism is to copyproperties (both code and data) from its second argument
supp
to its ﬁrst argument recv mimicking the effect of inheritance.
The other arguments of mix determine the details of copying:
overwrite andmerge denote whether to overwrite or merge
properties; white , if speciﬁed, lists properties to be copied
and excludes all other properties from copying; and mode
denotes whether and how to copy prototypes of objects. Thus,lines 8∼22 determine the source
from and the destination to
of copying depending on mode , lines 26∼42 copy only the
whitelisted properties, and lines 44 ∼62 copy all the properties.
This poses a challenge to analyses that have to reason about
statements like to[key] = from[key] on lines 40 and 56;
an a ¨ıve analysis that simply approximates the values of key
with the set of all possible property names will produce anextremely imprecise result that all properties of
from ﬂow
into all properties of to. In addition, traditional analyses have
also suffered from extreme cost, as the level of imprecisionhas caused tremendous amounts of propagation. Attempts toprovide better results have largely taken two approaches.
One approach [16], [17], [25], [26] has been to apply
ever-more-aggressive forms of analysis sensitivity to disam-biguate the behavior, such as aggressive ﬂow- and contextsensitivity, transformations of
for-in loop bodies to expose
more opportunities for context sensitivity and even exploitingdynamic information to improve static analysis. This approachhas shown the ability to handle ever-increasing complexity inJavaScript but nothing has yet been shown to robustly handlemodern framework-based code.
For any calls to
mix , for example, distinguishing the use
of different properties in each loop iteration requires multipleapplications of techniques such as correlation tracking [16].
5421Y.mix = function(recv, supp, overwrite, white,
2 mode, merge) {
3 var alwaysOverwrite, exists, from, i, key,
4 len, to;
5
6 if(!recv || !supp) return recv || Y;
78 if(mode) {
9 if(mode === 2) {
10 Y.mix(recv.prototype,supp.prototype,
11 overwrite, white, 0, merge);
12 }
13 from = mode === 1 || mode === 3 ?
14 supp.prototype : supp;
15 to = mode === 1 || mode === 4 ?
16 recv.prototype : recv;
1718 if(!from || !to) return recv;
19 }else {
20 from = supp;
21 to = recv;
22 }
2324 alwaysOverwrite = overwrite && !merge;
25 if(white) {
26 for (i=0,len=white.length; i<len; ++i) {
27 key = white[i];
2829 if(!hasOwn.call(from, key))
30 continue;
31 exists = alwaysOverwrite ?
32 false : key into;
3334 if(merge && exists &&
35 isObject(to[key], true)& &
36 isObject(from[key], true)) {
37 Y.mix(to[key], from[key], overwrite,
38 null, 0, merge);
39 }else if (overwrite || !exists) {
40 to[key] = from[key];
41 }
42 }
43 }else {
44 for (key infrom) {
45 if(!hasOwn.call(from, key))
46 continue;
47 exists = alwaysOverwrite ?
48 false : key into;
4950 if(merge && exists &&
51 isObject(to[key], true)& &
52 isObject(from[key], true)) {
53 Y.mix(to[key], from[key], overwrite,
54 null, 0, merge);
55 }else if (overwrite || !exists) {
56 to[key] = from[key];
57 }
58 }
59 if(Y.Object._hasEnumBug) {
60 Y.mix(to, from, overwrite,
61 Y.Object._forceEnum, mode, merge);
62 }
63 }
64 return recv;
65};
Fig. 1: Code excerpt from the YUI libraryBut more is required, since precision also depends on precise
handling of merge to avoid potential pollution from extrane-
ous recursive copies on lines 37 and 53. And beyond that, notethat calls to
mix may use different values of mode : 0 on lines
10, 37, and 53 but mode on line 60. There are four possible
options which require understanding constants to distinguish,once again needed to avoid pollution from extraneous copies.
Given this degree of complication, the other approach [18],
[27] has gone the other way, making the analysis less pre-cise to address the cost explosion of traditional analysis.The ﬁeld-based approach [18], for example, abandons objectsensitivity entirely, using a single location globally for eachﬁeld. This approach addresses the issue of statements like
to[key] = from[key] , since they become no-ops for anal-
ysis and can be ignored. While this approach has been shownto scale, it loses precision and/or soundness in many cases.
However, this approach suffers from severe, but different,
issues of its own. Even a very simple code like the following:
1var f={x :function a ( ){. . .}} ;
2var g={x :function b ( ){. . .}} ;
3f.x();
will be imprecise; because a ﬁeld-based analysis does notdistinguish between ﬁelds in different objects with the samename, it concludes that
f.x on line 3 points to either function
aorb. Thus, there is still no technique in the state of the art
that robustly handles modern JavaScript libraries and reliablyprovides good precision and performance.
This motivates our tunable static analysis framework. Even
though a sound analysis alone or the ﬁeld-based analysis alonemay not produce precise analysis results, a combination oftwo analyses may generate better results than that of eachanalysis. For example, consider the following code using the
mix function:
1var f={x :function a() { ... },
2 y:function b ( ){. . .}} ;
3var g={x :function c ( ){. . .}} ;
4var h = Y.mix({}, f);
5h.x();
A sound analysis may conclude that h.x on line 5 points to
either function aorbdue to the analysis complexity of mix .
On the contrary, the ﬁeld-based analysis will conclude that
h.x points to either function aorcbecause it considers only
the property names. Now, consider a tuned analysis whichperforms a sound analysis but only within the results of theﬁeld-based analysis; the analysis results will lie inside theintersection of the results of the two analyses. The tunedanalysis gets beneﬁts from both analyses, which makes itsstatic analysis simpler, more efﬁcient, and more precise thanstatic analysis of each of them.
Our goal is to present a general framework that automati-
cally derives a tuned analysis from two analyses. The frame-work takes a sound baseline analysis and a (possibly unsound)pre-analysis generating a boundary of analysis results likethe ﬁeld-based analysis, and it produces a tuned analysis thatperforms the baseline analysis only within the boundary.
543/c53/c46/c42/c44/c49/c42/c43/c4d/c46/c01/c54/c55/c42/c55/c46/c54/c01
/c56/c4f/c53/c46/c42/c44/c49/c42/c43/c4d/c46/c01/c54/c55/c42/c55/c46/c54/c01
/c54/c55/c42/c55/c46/c54/c01/c4a/c4f/c01/c54/c46/c4d/c46/c44/c55/c46/c45/c01/c46/c59/c46/c44/c56/c55/c4a/c50/c4f/c54/c01
/c54/c55/c42/c55/c46/c54/c01/c4a/c4f/c01/c42/c01/c51/c53/c46/c0e/c42/c4f/c42/c4d/c5a/c54/c4a/c54/c01
Fig. 2: Program execution ﬂows
III. T UNABLE STAT I C ANALYSIS FRAMEWORK
In this section, we describe our framework which en-
ables to tune the scalability of static analysis. Consider the
execution ﬂows illustrated in Figure 2. Light gray circlesdenote reachable states during evaluation, white circles denoteunreachable states during evaluation, and dark gray circlesdenote states in selected execution ﬂows. A sound baselineanalysis approximates all the reachable states possibly includ-ing some unreachable states (Section III-A), and a pre-analysisapproximates the states in the selected execution ﬂows asdenoted by a closed loop in Figure 2 (Section III-B). It isa “sound” approximation of the selected execution ﬂows, and,at the same time, it is an “unsound” approximation of theentire execution ﬂows. The framework allows users to tunethe derived analysis (Section III-C) by choosing appropriatesubsets of program executions. We discuss the impacts of se-lected program executions in terms of the analysis scalability,soundness, and precision (Section III-D).
A. Baseline Analysis for the Entire Semantics
The ﬁrst input to the framework is a baseline static analysis
that over-approximates the entire semantics of given programs.
The framework assumes that the baseline analysis is designedin the abstract interpretation setting [21], [22].
Collecting Semantics. We denote a program Pas a directed
graph⟨C,E⟩where CandErepresent a set of nodes and a set
of edges, respectively. A node c∈Cdenotes a control point in
the program and an edge (c,c
′)∈E⊆C×Cdenotes a control
ﬂow from ctoc′.
Given a programP, we deﬁne its collecting semantics using
⟨C,℘(S),f,→φ⟩where:
●C: a ﬁnite set of control points;
●σ∈℘(S): a powerset of concrete states;
●f(c)∈℘( S)→℘( S): a set of local semantic functions at
a given control point c;
●φ∈C→℘( S): a set of program states mapping control
points to sets of concrete states; and
●→φ: a set of control ﬂows for a given program state φ
for a set of concrete states S. A local semantic function f(c)
takes a set of concrete states and returns a union of sets ofresulting states for each of the given states. A set of controlﬂows→
φis a subset of control ﬂows Eand it is conﬁned
by a given program state φ. Then, the collecting semantics of
a programPis the least ﬁxpoint of the following semantic
function:
F∈(C→℘( S))→(C→℘( S))
F(φ)=λc∈C.f(c)(⋃c′→φcφ(c′)).Baseline Abstraction. For a baseline analysis that our
framework tunes for scalability, we require a static analysisdesigned in the abstract interpretation framework. We assumethat it abstracts a set of concrete states σto an abstract state
ˆσ∈ˆSby the following Galois connection:
℘(S)−−−−−→←−−−−−
αSγSˆS.
While the framework does not require any structure on ˆS, when
ˆSis a function cpo (complete partial order) ˆL→ˆVfor a
ﬁnite set of abstract locations ˆl∈ˆLand an arbitrary cpo of
abstract values ˆv∈ˆV, the framework provides an extra level of
scalability in terms of the analysis performance as we discussin Section V. Then, the abstraction of a program state φand
the concretization of an abstract program state ˆφ∈C→ˆSfor
the baseline analysis are as follows:
α
m(φ)=λc∈C.α S(φ(c))
γm(ˆφ)=λc∈C.γ S(ˆφ(c)).
The abstract semantics of the baseline analysis is the least
ﬁxpoint of the following semantic function:
ˆF∈(C→ˆS)→( C→ˆS)
ˆF(ˆφ)=λc∈C.ˆf(c)(⊔c′↪ˆφcˆφ(c′))
whereˆf(c)∈ˆS→ˆSis an abstract semantic function at a given
control point cand↪ˆφ⊆C×Cis a set of abstract control ﬂows
for a given abstract program state ˆφ.
The abstract semantic function ˆfis a monotonic function
designed in the abstract interpretation framework such that:
●∀c∈C.∀ˆσ,ˆσ′∈ˆS.ˆσ⊑ˆσ′⇒ˆf(c)(ˆσ)⊑ˆf(c)(ˆσ′)
●∀c∈C.α S○f(c)⊑ˆf(c)○αS
The set of abstract control ﬂows ↪⊆( C→ˆS)→ C×Cis
an abstract counterpart of →⊆( C→℘( S))→ C×Csatisfying
the following conditions:
1)↪αm(φ)⊇→φ
2)∀ˆφ,ˆφ′∈C→ˆS.ˆφ⊑ˆφ′⇒↪ ˆφ⊆↪ ˆφ′
The ﬁrst condition means that the set of abstract control ﬂows↪
αm(φ)is a sound approximation of the concrete control ﬂows
for a given program state φ, and the second condition means
that↪is monotonic.
B. Pre-Analysis for Selected Semantics
The second input to the framework is a pre-analysis that
over-approximates a set of selected execution ﬂows of a givenprogram. In order to analyze only the execution ﬂows of inter-est, our framework asks for an approximation of the selectedsubset of the whole program executions. The scalability of theanalysis is parameterized by this set of selected executions.
Selected Collecting Semantics. Suppose that we are in-
terested in analyzing selected execution ﬂows speciﬁed by alocal semantic function f
ssuch that:
∀c∈C,σ∈℘(S).f s(c)(σ)⊆f(c)(σ).
544Then, we can deﬁne a selected collecting semantics that
subsumes only the selected execution ﬂows denoted by fsas
the least ﬁxpoint of the following semantic function:
Fs∈(C→℘( S))→(C→℘( S))
Fs(φ)=λc∈C.f s(c)(⋃c′→φcφ(c′)).
Abstraction for Selected Collecting Semantics. For a pre-
analysis that our framework uses to tune the baseline analysis
for scalability, we do not require it be designed in the abstractinterpretation framework unlike for the baseline analysis. Theframework does not assume anything about the pre-analysisexcept that it produces a contour which over-approximates the
selected execution ﬂows we are interested in. A contour˙C∈˙X
for some poset (partially ordered set) ˙Xover-approximates the
selected collecting semantics: α
s(lfpFs)⊑˙Cholds for the
following Galois connection:
C→℘( S)−−−−−→←−−−−−
αsγs˙X.
Note that ˙Xmay be C→℘( S)like the collecting domain,
C→ˆSlike the abstract domain, or some other domain.
Because the contour is an element in the domain ˙X, our
framework requires an “interpretation” of the contour in termsof the abstract domain by an interpretation function:
I∈˙X→(C→ˆS)such that α
m○γs⊑I.
Then,I(˙C) denotes an over-approximation of the selected
executions in the abstract domain. When ˙XisC→℘ ( S)
orC→ˆS,Iisαmor the identity function, respectively.
In summary, the relations between the collecting domain, theabstract domain, and ˙Xare as follows:
C→℘( S) C→ˆS−−−−−→←−−−−−
αmγm
/leftrightline→S)−−−−−→←−−−−−αsγs
CalI
˙X
C. Tuned Static Analysis
Finally, using the baseline analysis ˆFand the contour ˙C,
our framework derives a tuned static analysis which over-approximates the selected set of program executions approx-imated by ˙C. Using the sound abstract semantic function
ˆffrom the baseline analysis and the interpretation of the
contourI(˙C), we can deﬁne a tuned analysis which over-
approximates selected executions as the least ﬁxpoint of thefollowing abstract semantic function:
ˆF
s(ˆφ)=λc∈C.ˆf(c)⎛
⎜
⎝⊔
c′s↪ˆφcˆφ(c′)⎞
⎟
⎠⊓I(˙C),
where the abstract semantic function ˆfconsiders only the
control ﬂows restricted by the given contour:
s↪ˆφdef=↪ ˆφ∩↪I(˙C).
Thus, the derived analysis ˆFsconsiders only the control ﬂows
restricted by the contour, and the resulting abstract states from
ˆfremain within the interpretation of the contour because ˆFs
performs the meet operation with I(˙C).The derived analysis ˆFsis an over-approximation of the
selected program executions approximated by the contour.
Theorem 1 (Correctness of ˆFs):αm(lfpFs)⊑lfpˆFs
Also, the interpretation of the contour I(˙C) is an over-
approximation of the derived tuned analysis of the selected
executions:
Theorem 2: lfpˆFs⊑I(˙C)
Proofs of both theorems are straightforward.
D. Discussion
Our framework allows users to tune the analysis scalability
by choosing appropriate contours. Because a derived tuned
analysis performs its analysis within the boundary conﬁnedby its contour, the contour determines the scalability of thetuned analysis. Good contours trim spurious execution ﬂowsfrom consideration of tuned analyses leading to reducing falsepositives from the analysis results.
Depending on a selected contour, the derived analysis may
not be scalable enough. In such cases, choosing an unsound butscalable contour that contains a strict subset of all executionﬂows may be an option. By choosing speciﬁc cases to focuson, tuned analyses can get beneﬁts for the scalability whilegiving up the soundness. Of course, one can focus on othercases one by one or collectively by selecting different contours.
As the selection of contours explicitly tunes the analysis
scalability by conﬁning the scope of tuned analyses, it alsoimproves the precision of tuned analyses. No matter whatcontours we select, the tuned analysis has less false alarmsthan that of the baseline analysis. At the same time, becausecontours trim any spurious execution ﬂows not contained inthem by the meet operation with I(˙C), the tuned analyses
become more precise than the baseline analysis.
Note that the tuned analysis is more scalable than the
baseline analysis because it trims the analysis target with thegiven contour by performing the meet operation with I(˙C).
In addition, when the abstract state domain ˆSis a function
cpo (complete partial order) ˆL→ˆVas we discussed in
Section III-A, we can improve the analysis scalability furtherin terms of the analysis performance by applying the sparseanalysis framework [9], [8], [10]. We describe how we applyit in our implementation of the framework in Section V.
IV . I
NST ANCES
To demonstrate how to use the general framework in
practice, this section shows two instances, SWP and SWF .
They both use the SAFE analysis [11], [12] as a baselineanalysis, and
SWP and SWF use W ALA ’s propagation-based
analysis (PB) [15], [16], [17] and W ALA ’s ﬁeld-based analysis(FB) [18] as pre-analyses that construct contours, respectively.
A. Instance:
SWP
Selected Collecting Semantics . Because PB is a sound
analysis, using PB as a pre-analysis effectively means that
SWP uses all the possible execution ﬂows as selected execu-
tions. Thus, the selected collecting semantics ⟨C,℘(S),fP,→φ
⟩for some fPis the same as the collecting semantics in
Section III-A.
545Abstraction for Selected Collecting Semantics. Since PB
is a ﬂow-insensitive analysis, which does not consider control
points during analysis, it abstracts a set of concrete states foreach control point to a singleton abstract state:
C→℘( S)−−−−−→←−−−−−
αsγsˆSαs(φ)=⊔c∈CαS(φ(c))
γs(ˆσ)=λc∈C.γ S(ˆσ).
Then, a contour ˙CWP∈ˆSis the least ﬁxpoint of the following
semantic function ˆFP∈ˆS→ˆS:
ˆFP(ˆσ)=⊔
c∈CˆfP(c)(ˆσ)
whereˆfP∈C→ˆS→ˆSis an abstract counter part of fP.W e
assume that the abstract semantic function ˆfP(c)is monotonic
designed in the abstract interpretation framework. Therefore,the following condition holds:
α
s(lfpFP)⊑lfpˆFP.
Since we use the same abstraction for abstract states, thedeﬁnition ofI
Pis simply as follows:
IP(ˆσ)=λc∈C.ˆσ
which satisﬁes the condition αm○γs⊑IP.F o rag i v e n
abstract state, it produces a function that returns the abstractstate for any control point. Then, we can design a tunedanalysis ˆF
SWP for the contour ˙CWP as follows:
ˆFSWP(ˆφ)=λc∈C.ˆf(c)⎛
⎜⎜
⎝⊔
c′P↪ˆφcˆφ(c′)⎞
⎟⎟
⎠⊓IP(˙CWP)
whereP↪ˆφdef=↪ ˆφ∩↪IP(˙CWP).
Note that the derived analysis ˆFSWP is as precise as SAFE,
and because it is tuned by the contour ˙CWP, it may be
more precise than SAFE. In addition, since the contour over-
approximates the collecting semantics, the tuned analysis over-approximates all the possible program executions by Theo-rem 1.
B. Instance:
SWF
Selected Collecting Semantics. To lessen the analysis
complexity, FB abandons elaborate object-sensitive analy-
sis entirely using a single location globally for each ﬁeld.Thus, we can denote the selected collecting semantics as⟨C,℘(S),f
F,→φ⟩for some local semantic function fF, where
fF(c)speciﬁes the selected collecting semantics at a given
control point c, which is a subset of the collecting semantics
f(c):
∀c∈C,σ∈℘(S).f F(c)(σ)⊆f(c)(σ).
Then, we can deﬁne the selected collecting semantics asfollows:
F
F∈(C→℘( S))→(C→℘( S))
FF(φ)=λc∈C.f F(c)(⋃c′→φcφ(c′)).
Abstraction for Selected Collecting Semantics. Because
FB is a ﬂow-insensitive and object-insensitive analysis, it doesnot consider control points nor objects during analysis. Thus,it basically abstracts a set of concrete states for each controlpoint to a global single abstract object ˆO:
C→℘( S)−−−−−→←−−−−−
αsγsˆOαs(φ)=⊔ˆl∈ˆL(⊔c∈CαS(φ(c)))(ˆl)
γs(ˆo)=λc∈C.γ S(λˆl∈ˆL.ˆo)
Then, a contour ˙CWF∈ˆOis the least ﬁxpoint of the following
semantic function ˆFF∈ˆO→ˆO:
ˆFF(ˆo)=⊔
c∈CˆfF(c)(ˆo)
whereˆfF(c)is an abstract counter part of fF(c). We assume
that the abstract semantic function ˆfF(c)is monotonic de-
signed in the abstract interpretation framework. Therefore, thefollowing condition holds:
α
s(lfpFF)⊑lfpˆFF.
In this case, we can deﬁne IF∈ˆO→(C→ˆS)as follows:
IF(ˆo)=λc∈C.(λˆl∈ˆL.ˆo),
and we can design a tuned analysis that subsumes the selectedcollecting semantics as follows:
ˆF
SWF(ˆφ)=λc∈C.ˆf(c)⎛
⎜⎜
⎝⊔
c′F↪ˆφcˆφ(c′)⎞
⎟⎟
⎠⊓IF(˙CWF)
whereF↪ˆφdef=↪ ˆφ∩↪IF(˙Cwalaq).
To see the effects of the tuned analysis more clearly, let us
revisit the code example presented in Section II:
1var f={x :function a() { ... }, 2
y:function b ( ){. . .}} ; 3
var g={x :function c ( ){. . .}} ; 4
var h = Y.mix({}, f); 5
h.x();
While the actual evaluation of the code calls the function a
on line 5, the sound baseline analysis SAFE will conclude
that either function aorbwill be called, and an unsound
FB will conclude that either function aorcwill be called.
However, the tuned analysis will precisely conclude that onlythe function
awill be called by performing the meet operation
with the contour.
C. Discussion
While both PB and FB, two pre-analyses used in the
instances, are standalone static analyzers, the framework does
not require a pre-analysis be a separate static analysis. Instead,one can use a collection of dynamic execution traces thatcontain the states during particular executions as a pre-analysisresult. For such a collection of dynamic execution traces, wedo not even need to abstract a set of concrete states to constructa contour. Thus, we can use the following Galois connection:
C→℘( S)−−−−−→←−−−−−
αsγsC→℘( S)
where both αsandγsare the identify function. The interpre-
tation functionIis the same as αmin this case.
546Indeed, we can formalize the blended analysis [27] in
this setting where a tuned analysis performs the baseline
SAFE analysis on only extracted execution ﬂows. Also, whena contour contains information about dynamically generatedcode, the corresponding tuned analysis can get beneﬁts fromthe extracted code. Although we could not experiment withsuch a pre-analysis that collects concrete execution tracesbecause the tool is not publicly available, we plan to pursuethis direction.
V. I
MPLEMENT A TION
This section describes main technical challenges in inte-
grating two independently developed analyzers and derivingsparse analyses for JavaScript programs, and explains how wesolve them.
A. Interpretation of WALA Analysis Results in SAFE
We implemented the framework using SAFE as the baseline
analysis and two versions of W ALA analyses PB and FB as
pre-analyses. The analysis results of PB and FB correspond totheir contours ˙C
WP and˙CWF, respectively. To use the contours
in tuned analyses, we develop concrete versions of the inter-pretation function I
PandIFfor PB and FB, respectively.
In other words, to use the pre-analysis results in the SAFEanalysis, we should transform program states in W ALA toprogram states in SAFE, which requires various mappingsbetween W ALA domains and SAFE domains. For example,we should transform an abstract location in W ALA to that inSAFE, and an abstract value in W ALA to that in SAFE. Hereare some representative transformation due to the differencesbetween W ALA and SAFE in the implementation of JavaScriptstatic analysis.
User objects . For user-deﬁned objects generated by func-
tion declarations, array literals, object literals, or object con-struction, we use their source locations to map the same userobjects in W ALA and SAFE. For built-in functions that donot have source locations of their deﬁnition sites, we use theirnames.
Lexical environments. JavaScript maintains variable in-
formation in lexical environments; each function call createsa new lexical environment to keep the information of thevariables in the function. While SAFE creates a lexical en-vironment for each function call site as the ECMAScript stan-dard speciﬁes, W ALA creates a lexical environment for eachfunction declaration. Thus, for each lexical environment for afunctionfin W ALA, we map it to the lexical environments
of the call sites of fin SAFE.
Arguments objects. Each JavaScript function except for the
global function has an implicitly declared
arguments object.
While SAFE generates arguments objects in function call
sites as the ECMAScript standard speciﬁes, W ALA generatesthem in function deﬁnition sites. Similarly for lexical envi-ronments, we map each
arguments object for a function f
in W ALA to the arguments object of the call sites of fin
SAFE.V ariables. Both W ALA and SAFE deal with user-deﬁned
variables from input JavaScript programs and analyzer-deﬁnedtemporary variables to keep intermediate results of complexexpressions. For example, when SAFE translates a complexexpression like “
x = obj.prop1.prop2 ” into its own inter-
mediate representation, it generates a temporary variable for
obj.prop1 . While it is straightforward to map user-deﬁned
variables using their source locations, mapping analyzer-deﬁned variables is not trivial because W ALA and SAFE havedifferent strategies to create temporary variables. For tempo-rary variables, we use source locations of their correspondingcomplex expressions.
Implicit type conversions. JavaScript has implicit type
conversions for primitive values such as strings, numbers,and booleans. When primitive values are used as built-inobjects like
String ,Number , and Boolean , they implicitly
convert to corresponding built-in objects. While SAFE modelsimplicit type conversions as the ECMAScript standard deﬁnes,W ALA does not support them. Thus, we transform implicittype conversions in JavaScript applications to explicit typeconversions.
B. Sparse Analysis for JavaScript Applications
To make tuned analyses even more scalable, we applied
the general sparse analysis framework [9], [10] in our im-
plementation after addressing two issues. The ﬁrst issuesis that while the sparse analysis framework requires a pre-analysis be a conservative approximation of a given baselineanalysis, contours in our framework may not be a conservativeapproximation of the baseline analysis. However, because theformalization presented in Section III guarantees that contourssupport conservative approximation of tuned analyses by The-orem 2, we can safely apply the sparse analysis framework totuned analyses.
The second issue is that the general sparse analysis frame-
work is often inefﬁcient in JavaScript analysis because re-building data dependencies whenever analysis results change iscostly [10]. The proposed approach that postpones rebuildingdata dependencies may work well for C-like languages, butit may not work for languages with prevalent exception ﬂowslike JavaScript. A reasonable solution may be an incrementalalgorithm that newly builds data dependencies only for partsthat have been changed [28]. However, the algorithm is im-practically expensive for JavaScript analysis because wheneverthe algorithm creates a new join (φ ) node during analysis,
it requires elimination of related edges to the join node.To address this problem of prevalent exception ﬂows, weimproved the incremental algorithm. Instead of eliminatingexisting edges and adding φnodes on the ﬂy as in the
traditional incremental algorithm, we devised an improvedalgorithm that pre-computes all the possible φnodes and
constructs data dependencies using the pre-computed φnodes.
Our algorithm may create more φnodes than the original
incremental algorithm, but it certainly reduces the costs ofdata dependency construction, which is especially necessaryfor JavaScript analysis.
547VI. E V ALUA TION
In this section, we evaluate the proposed tunable analysis
framework using four analyzers. We ﬁrst describe research
questions, evaluation methodology, and evaluation subjects,and we show the evaluation results.
A. Research Questions
We design our evaluation to address the following research
questions:
●RQ1. Scalability: Given the same timeout, how many
subjects does each analyzer ﬁnish analyzing? An analyzer
ﬁnishing analysis of more subjects is more scalable.
●RQ2. Precision: For the callsites in each subject, how
many called function objects does each analyzer approx-imate on average? An analyzer that ﬁnds fewer functionobjects for each function call on average is more precise.
●RQ3. Coverage: Given the same timeout, how many
basic blocks does each analyzer ﬁnish analyzing? Ananalyzer ﬁnishing analysis of more basic blocks hashigher coverage.
●RQ4. Global sparse analysis: Is the global sparse
analysis framework applicable to JavaScript?
B. Evaluation Methodology and Subjects
To answer the research questions, we performed various
experiments using four analyzers: 1) SAFE , a sound baseline
analyzer, 2) SWP , a tuned analyzer with SAFE as a baseline
analyzer and W ALA ’s PB as a pre-analyzer 3) SWF , a tuned
analyzer with SAFE as a baseline analyzer and W ALA ’s FB asa pre-analyzer, and 4)
FB, an unsound W ALA ’s FB analysis.
For all the experiments, SAFE used 5 call-context sensitivityand location cloning [29]. The pre-analyses, PB and FB, arecontext-insensitive, and they do not perform string analysis. Inaddition, PB used correlation tracking [16] for
for-in loops.
While the quality of analysis results relies on the quality of theunderlying analyzers, because it is not the main focus of thispaper, we refer the interested readers to relevant papers [12],[26], [16], [17].
For evaluation subjects, we used 3 categories–benchmark,
library, and website–and used 5 subjects from each category.We distinguished benchmarks and websites because they havedifferent behaviors [30], and we included libraries becausethey have been the major targets for JavaScript analysis [16],[17], [31]. For the benchmark category, we used RayTrace,Richards, Splay, and NavierStokes from the V8 benchmarksuite version 7
6and Box2dWeb7. For the library category, we
used jQuery, MooTools, Prototype, YUI, and Underscore8.F o r
the website category, we used live.com ,wikipedia.org ,
facebook.com ,youtube.com , and baidu.com . For each
category, we selected subjects that show the differences be-tween analyzers most explicitly. We conducted the experimentson a machine with 3.4GHz Intel Core i7 CPU and 32GBMemory.
6https://v8.googlecode.com/svn/data/benchmarks/v7/run.html
7http://code.google.com/p/box2dweb/
8http://underscorejs.orgT ABLE I: Scalability of the analyzers. Entries marked denote that
the analyzers do not ﬁnish analysis within the timeout of 10 minutes.
The analysis time is in seconds, and parenthesized numbers (m/n )
denote that a pre-analysis took mseconds and a baseline analysis
tooknseconds. The analysis time for FB is the same as the pre-
analysis time for SWF .
Subject (LOC) SAFE SWP SWFBenchmarkRayTrace (679)  576.3 (4.8/571.5) 600.3 (2.9/597.4)
Richards (288) 2.1 3.7 (2.4/1.3) 3.9 (2.2/1.7)
Splay (205) 9.2 8.6 (2.1/6.5) 15.8 (1.8/14.0)
NavierStokes (331) 1.0 4.4 (3.1/1.3) 3.2 (2.0/1.2)
Box2dWeb (10918) 45.0 58.5 (15.6/42.9) 48.2 (45.4/2.8)LibraryjQuery (6206)   28.6 (23.9/4.7)
MooTools (4022)   27.6 (25.7/1.9)
Prototype (5914)   26.2 (24.2/2.0)
YUI (7181)  8.6 (6.9/1.7) 18.7 (13.7/5.0)
Underscore (1065)   5.2 (4.6/0.6)Websitelive.com (6325) 240.8  128.0 (32.2/95.8)
wikipedia.org (291) 0.1 5.8 (5.8/0.0) 5.8 (5.8/0.0)
facebook.com (5584)   64.1 (62.1/2.0)
youtube.com (5061)   382.6 (247.6/135.0)
baidu.com (9739)   119.0 (100.2/18.8)
C. Scalability
To compare the scalability of four analyzers, we show which
analyzer ﬁnishes analysis of each subject in Table I with
the timeout of 10 minutes. We measured the analysis timein seconds. For tuned analyzers, we show how much time apre-analysis and a baseline analysis each took in parentheses.Because the analysis time for
FBis the same as the pre-analysis
time for SWF , we do not show FB in the table. While all SAFE ,
SWP ,SWF ,a n d FBcan ﬁnish analyzing most benchmarks, they
show differences in analyzing libraries and websites.
Comparing SAFE and SWP in analyzing libraries, they both
cannot analyze most of them; SWP ﬁnishes analysis of the YUI
library. To analyze YUI in a sound manner, SAFE analyzes
many (possibly spurious) execution ﬂows of YUI, whichcauses much (possibly unnecessary) analysis computation. Onthe contrary,
SWP uses a contour produced by PB to trim
unnecessary execution ﬂows, which makes a set of executionﬂows to analyze smaller than
SAFE . Therefore, it decreases
the amount of analysis computation leading to ﬁnish analysisof YUI by
SWP . Because SWP takes sound analysis results of
PB to generate contours, our framework guarantees that SWP
provides a sound analysis result of YUI.
For the analysis of websites, both SAFE and SWP cannot
analyze most of them except for the simple wikipedia.org ;
SAFE can ﬁnish analysis of live.com in addition. We ob-
served that SWP did not ﬁnish analysis of live.com because
its pre-analysis PB did not ﬁnish analyzing it.
Not surprisingly, SWF is the most scalable one; it success-
fully ﬁnishes analysis of all the benchmarks, libraries, andwebsites within 8 minutes. Because contours derived from theFB pre-analysis are deliberately unsound,
SWF can analyze
large-scale programs more effectively than SAFE and SWP .
The experimental results show that the analysis scalability
is tunable by contours. We believe that reasonably designedcontours will enable analysis of large and sophisticated pro-grams.
548D. Precision
To evaluate how precise results each tuned analysis produces
by conﬁning analysis targets with its contour, we measured
the average number of callees the analyzer estimates over thenumber of call sites as shown in Table II. We also present themaximum number of calls in parentheses. Note that comparinganalysis precision between sound analyses
SAFE and SWP and
unsound analyses SWF and FB is not trivial. Although the
numbers in the table do not represent the analysis precisionof whole programs, it shows speculative analysis precision forthe analysis targets of each analyzer.
Splay and NavierStokes in benchmarks show the same
numbers for all the analyzers except for
FB. Richards in
benchmarks has the same precision in SAFE and SWP , and
YUI in libraries shows the same precision between SWP and
SWF . We conﬁrmed that they have the same call sites and each
call site has the same callees, which means that they have thesame precision at each call site. For Richards, Box2dWeb, and
live.com ,SWF shows smaller numbers than SAFE and SWP
due to its unsound pre-analysis, FB. As the FB column for
precision in Table II suggests, FB may miss some call sites
(unsound) and, at the same time, it may include unreachablecall sites (imprecise) as well. Because FB ignores propertyaccesses with imprecise property names, it may miss actualexecution ﬂows. Also, because FB is context-insensitive,i t
over-approximates functions to be called at call sites. Thus,numbers of call sites analyzed by
FB are smaller than those by
SWF for some cases (RayTrace, Richards, Splay, and Navier-
Stokes) but larger in most cases. However, since SWF performs
the meet operation with the contours derived from FB, SWF
presents the best results. Note that FB has been successfullyused in ﬁnding security vulnerabilities in the AppScan product.Because the analysis results from
SWF subsumes the concrete
execution ﬂows analyzed by FB, SWF can detect the same
security vulnerabilities as AppScan. Moreover, because SWF
produces more precise analysis results, AppScan may be ableto reduce false positives by using
SWF instead of FB. The
experimental results show that the analysis precision is tunableby contours. When analysis results are not precise enough, onemay shrink contours to achieve better analysis precision.
E. Coverage
Finally, we compare the analysis coverage of the analyzers
using numbers of reachable basic blocks that they analyze.
We can expect that
SAFE and SWP subsume all the possible
execution ﬂows but they may not terminate. On the contrary,
SWF and FB may subsume partial execution ﬂows but, because
they are more scalable, they may cover more lines of sourcecode even when
SAFE and SWP do not terminate. Table II
shows that SWF and FB indeed cover more subjects. Splay
and NavierStokes in benchmarks cover the same basic blocksin
SAFE ,SWP , and SWF . We can speculate from this result that
contours generated in SWP and SWF include SAFE analysis
results, so that each analysis result is sound for the wholeprogram. Richards shows that
SAFE covers more basic blocks
than SWP , and SWP covers more basic blocks than SWF .Indeed, because both SAFE and SWP are sound, their analysis
targets should include that of SWF . At the same time, because
SWP performs the meet operation with the contours derived
from PB, the analysis targets of SWP should be smaller than
that of SAFE . Even though FB shows the largest coverage
for all subjects, FB may miss some actual basic blocks
(unsound) and, simulataneously, it may include unreachablebasic blocks (imprecise) as we discussed in Section VI-D.While
FB analyzes more than thousand basic blocks for most
websites, SWF does not analyze that many basic blocks by the
meet operation with the contours from FB. The experimentalresults show that generating smaller contours helps analysis oflarge-scale programs while giving up some analysis coverage.To improve the analysis coverage, one may enlarge contoursto cover more program execution ﬂows.
F . Sparse
As we discussed in Section V -B,
SWP and SWF are in-
stances of the global sparse analysis framework [10]. We
consider SWP as an application of the global sparse analysis
framework as it is. Table I shows that applying the globalsparse analysis as is to JavaScript analysis helps in analyzingYUI; while
SAFE did not ﬁnish analysis of YUI, SWP did.
However, it does not work well in general in the sense that
SWP does not outperform SAFE noticeably. We believe that
an a ¨ıve application of the general sparse analysis framework
to analysis of JavaScript programs, represented by SWP ,i s
likely to be ineffective. For languages with frequent changesin control ﬂow graphs like JavaScript, additional techniquesare necessary as in
SWF .
G. Threats to V alidity
We identify the following threats to the validity:
●The subjects used in the experiments may not berepresentative. We selected 5 widely used subjects for
3 different categories that have different behaviors [30]each from real-world JavaScript applications. However,they may not be representative of all JavaScript programs.
●The experimental results on precision may not rep-resent the precision of the whole program analysisresults. Because we measured only average numbers of
callees and numbers of call sites in analysis targets, theanalysis precision results may not apply to whole programanalysis results. Therefore, direct comparison betweenaverage numbers of callees is meaningful if analyses havethe same call sites. If a contour of
SWF excludes call
sites that have small numbers of callees, then SWF may
have larger average numbers of callees than other soundanalyses,
SAFE and SWP .
VII. R ELA TED WORK
Because JavaScript applications are prevalent these days,
researchers have proposed various techniques to staticallyanalyze JavaScript programs. Similarly for statically typedlanguages like Java, most analysis techniques are sound butimpractical [16], [17]. Moreover, static analysis of JavaScript
549T ABLE II: Precision and coverage. Each entry for precision denotes the average number of callees that the analyzer estiates (the maximum
number of calls) / the number of call sites. Each entry for coverage denotes the number of reachable basic blocks that the analyzer analyzes.
SubjectPrecision Coverage
SAFE SWP SWF FB SAFE SWP SWF FBBenchmarkRayTrace  1.05 (3)/1425 1.05 (3)/1425 1.38 (16)/ 168  813 813 1079
Richards 1.04 (4)/ 82 1.04 (4)/ 82 1.04 (4)/ 76 1.15 (5)/ 53 327 319 303 387
Splay 1.00 (1)/ 193 1.00 (1)/ 193 1.00 (1)/ 193 1.02 (2)/ 44 292 292 292 329
NavierStokes 1.00 (1)/ 77 1.00 (1)/ 77 1.00 (1)/ 77 1.04 (2)/ 57 340 340 340 465
Box2dWeb 1.03 (22)/ 698 1.03 (22)/ 698 1.00 (1)/ 111 2.90 (260)/1929 922 922 117 11728LibraryjQuery   1.03 (4)/ 95 14.82 (187)/1432   502 11847
MooTools   1.00 (1)/ 36 17.06 (207)/1290   134 9432
Prototype   1.00 (1)/ 32 4.10 (159)/1513   248 10881
YUI  1.11 (6)/ 47 1.11 (6)/ 47 3.12 (73)/ 864  324 312 8036
Underscore   1.00 (1)/ 28 3.45 (36)/ 194   137 1766Websitelive.com 1.02 (16)/ 884  1.00 (1)/ 766 3.55 (186)/2382 411  336 11741
wikipedia.org 0.00 (0)/ 0 0.00 (0)/ 0 0.00 (0)/ 0 1.21 (4)/ 75 6 6 6 647
facebook.com   1.00 (1)/ 12 5.93 (231)/1282   132 9546
youtube.com   1.00 (1)/ 107 10.85 (215)/2137   532 15028
baidu.com   1.04 (6)/ 125 20.54 (443)/3872   674 27729
is much more impractical than static analysis of Java due to its
extremely dynamic and functional features. Some analysis likecorrelation tracking [16] keeps track of relationships betweenobject properties, but it applies to only special patterns.Some sound analysis like dynamic determinacy [17] utilizesdeterminate values at compile time, but it loses the precisiongain by determinate values as soon as it reaches indeterminatevalues, which is not scalable enough.
Instead, recent studies have reported unsound analyses of
JavaScript programs. Because bug detection does not need toguarantee absence of bugs, bug detection may not need touse sound analysis. Similarly, a simple taint analysis may notrequire sound analysis; it may be enough to analyze unsoundcall graphs of target programs as long as the unsound analysisis scalable enough to ﬁnish analyzing large-scale JavaScriptapplications in the wild [18]. Once unsound analyses areacceptable, various combinations of dynamic and static anal-yses would be possible by performing such analyses on onlyextracted execution ﬂows [27].
Building on top of the static analysis techniques for
JavaScript programs, researchers have developed open-sourceJavaScript static analyzers. SAFE [11] is an abstract inter-pretation based static analysis framework. It supports a richset of modeled libraries, DOM APIs, and platform APIs foranalyzing real-world JavaScript web applications [12]. It alsoprovides various analysis techniques like multiple sensitivitiesand loop-sensitive analysis [26]. Like SAFE, T AJS [13] sup-ports a static analysis in the abstract interpretation framework.It provides several analysis techniques to improve the precisionand scalability of JavaScript analysis [32], [33], [31], [25],but it is not yet scalable for analyzing libraries like Mootolsand Prototype. W ALA [15] is originally developed for Javaprogram analysis, and now it also provides JavaScript pro-gram analysis. Using existing analysis supports for Java, itequips with a variety of tools for JavaScript analysis includinga sound propagation-based pointer analysis. However, dueto the signiﬁcant differences between Java and JavaScript,W ALA provides another unsound ﬁeld-based analysis [18] forJavaScript, which has been successfully used in academia [27],and applied to a commercial product IBM Security App-Scan [19]. JSAI [34] is a JavaScript analysis framework withconﬁgurable sensitivities. While JSAI supports sound analyses,our approach handles even unsound analyses.
For large-scale C programs, several scalable analyses are
available. A sparse analysis framework for C-like programs [8]has shown very effective in making existing sound staticanalyses scalable. Its extension to a general sparse analy-sis framework [10] proposes a mechanism to apply it toother languages like JavaScript. However, unfortunately, ourexperiments using the propagation-based W ALA analysis asits “simple ﬂow-insensitive pre-analysis” to make the SAFEanalysis scalable showed that the framework as it is may notbe practically applicable to analysis of JavaScript programs.
VIII. C
ONCLUSION
We present a general framework that enables designers of
analyses to tune the analysis scalability and precision. Giventhat the extremely dynamic and functional features of large-scale JavaScript applications make scalable static analysisalmost impossible, designers may get more beneﬁts fromexperimenting with the analysis scalability and precision thanpursuing for the ultimate sound and scalable static analysis.Our framework is parameterized by a sound baseline analysisthat analyzes a given program elaborately and a pre-analysisthat speciﬁes only a subset of execution ﬂows; designers cantune the scalability and precision of the resulting analysis bychanging the pre-analysis. Our framework is theoretically wellfounded in the abstract interpretation framework and practi-cally evaluated with state-of-the-art JavaScript analyzers. Weformally presented stepwise instructions to use our framework,and exempliﬁed differences resulted from different choices ofpre-analyses. Using open-source JavaScript analyzers, SAFEand W ALA, we implemented two instances of the frameworkand showed effectiveness of the framework.
A
CKNOWLEDGMENT
This work is supported in part by National Research
Foundation of Korea (Grant NRF-2014R1A2A2A01003235),Samsung Electronics, and Google Faculty Research A ward.
550REFERENCES
[1] “100 JavaScript online games,” http://www.lutanho.net/stroke/online.
html.
[2] “List of languages that compile to JS,” https://github.com/jashkenas/
coffeescript/wiki/list-of-languages-that-compile-to-js.
[3] “Node OS,” https://node-os.com.
[4] “Runtime.JS,” http://runtimejs.org.[5] G. Richards, S. Lebresne, B. Burg, and J. Vitek, “An analysis of
the dynamic behavior of JavaScript programs,” in Proceedings of the
ACM SIGPLAN Conference on Programming Language Design andImplementation, 2010.
[6] K. Yi and S. Ryu, “A cost-effective estimation of uncaught exceptions
in Standard ML programs,” Theoretical Computer Science, vol. 277, no.
1-2, pp. 185–217, 2002.
[7] X. Leroy and F. Pessaux, “Type-based analysis of uncaught exceptions,”
ACM Transactions on Programming Languages and Systems, vol. 22,no. 2, pp. 340–377, Mar. 2000.
[8] H. Oh, K. Heo, W . Lee, W . Lee, and K. Yi, “Design and implementation
of sparse global analyses for C-like languages,” in Proceedings of the
ACM SIGPLAN Conference on Programming Language Design andImplementation, 2012, pp. 229–238.
[9] Y . Ko, K. Heo, and H. Oh, “A sparse evaluation technique for detailed
semantic analyses,” Computer Languages, Systems & Structures, 2014.
[10] H. Oh, K. Heo, W . Lee, W . Lee, D. Park, J. Kang, and K. Yi, “Global
sparse analysis framework,” ACM Transactions on Programming Lan-
guages and Systems, vol. 36, no. 3, 2014.
[11] KAIST PLRG, “SAFE: JavaScript analysis framework,” http://safe.kaist.
ac.kr, 2013.
[12] S. Bae, H. Cho, I. Lim, and S. Ryu, “
SAFEWAPI : Web API misuse
detector for web applications,” in Proceedings of the ACM SIGSOFT
Symposium and the European Conference on F oundations of SoftwareEngineering, 2014.
[13] A. Møller, S. H. Jensen, P . Thiemann, M. Madsen, M. D. Ingesman,
P . Jonsson, and E. Andreasen, “T AJS: Type analyzer for JavaScript,”https://github.com/cs-au-dk/T AJS, 2014.
[14] M. Madsen and A. Møller, “Sparse dataﬂow analysis with pointers
and reachability,” in Proc. 21st International Static Analysis Symposium
(SAS), 2014.
[15] IBM Research, “T.J. Watson Libraries for Analysis (W ALA),” http://
wala.sf.net.
[16] M. Sridharan, J. Dolby, S. Chandra, M. Sch ¨afer, and F. Tip, “Correlation
tracking for points-to analysis of JavaScript,” in Proceedings of the
European Conference on Object-Oriented Programming, 2012.
[17] M. Sch ¨afer, M. Sridharan, J. Dolby, and F. Tip, “Dynamic determinacy
analysis,” in Proceedings of the ACM SIGPLAN Conference on Pro-
gramming Language Design and Implementation, 2013.
[18] A. Feldthaus, M. Sch ¨afer, M. Sridharan, J. Dolby, and F. Tip, “Efﬁcient
construction of approximate call graphs for JavaScript IDE services,” inProceedings of the International Conference on Software Engineering,2013.
[19] “IBM Security AppScan,” http://www-03.ibm.com/software/products/
en/appscan.[20] B. Livshits, M. Sridharan, Y . Smaragdakis, O. Lhot ´ak, J. N. Amaral, B.-
Y . E. Chang, S. Z. Guyer, U. P . Khedker, A. Møller, and D. V ardoulakis,“In defense of soundiness: A manifesto,” Communications of the ACM,
pp. 44–46, 2015.
[21] P . Cousot and R. Cousot, “Abstract interpretation: a uniﬁed lattice model
for static analysis of programs by construction or approximation ofﬁxpoints,” in Proceedings of the ACM SIGACT-SIGPLAN Symposium
on Principles of Programming Languages, 1977, pp. 238–252.
[22] ——, “Systematic design of program analysis frameworks,” in Pro-
ceedings of the ACM SIGACT-SIGPLAN Symposium on Principles ofProgramming Languages, 1979, pp. 269–282.
[23] “Implementation of practically tunable static analysis framework for
large-scale JavaScript applications,” Omitted for anonymizing authors,2015.
[24] G. Bracha and W . Cook, “Mixin-based inheritance,” in Proceedings of
the European Conference on Object-oriented Programming / Object-oriented Programming Systems, Languages, and Applications , 1990, pp.
303–311.
[25] E. Andreasen and A. Møller, “Determinacy in static analysis for jQuery,”
inProceedings of the ACM International Conference on Object Oriented
Programming Systems Languages and Applications, 2014.
[26] C. Park and S. Ryu, “Scalable and precise static analysis of JavaScript
applications via loop-sensitivity,” in Proceedings of the European Con-
ference on Object-Oriented Programming, 2015.
[27] S. Wei and B. G. Ryder, “Practical blended taint analysis for JavaScript,”
inProceedings of the International Symposium on Software Testing and
Analysis, 2013, pp. 336–346.
[28] J.-D. Choi, V . Sarkar, and E. Schonberg, “Incremental computation
of static single assignment form,” in Proceedings of the International
Conference on Compiler Construction, 1996.
[29] C. Lattner, A. Lenharth, and V . Adve, “Making context-sensitive points-
to analysis with heap cloning practical for the real world,” in Proceedings
of the ACM SIGPLAN Conference on Programming Language Designand Implementation, 2007.
[30] W . T. Cheung, S. Ryu, and S. Kim, “Development nature matters: An
empirical study of code clones in javascript applications,” Empirical
Software Engineering, 2015.
[31] A. Feldthaus and A. Møller, “Checking correctness of TypeScript inter-
faces for JavaScript libraries,” in Proceedings of the ACM International
Conference on Object Oriented Programming Systems Languages andApplications , 2014.
[32] S. H. Jensen, P . A. Jonsson, and A. Møller, “Remedying the eval thatmen do,” in Proceedings of the International Symposium on Software
Testing and Analysis, 2012.
[33] S. H. Jensen, M. Madsen, and A. Møller, “Modeling the HTML DOM
and browser API in static analysis of JavaScript web applications,” inProceedings of the European Conference on F oundations of SoftwareEngineering, 2011.
[34] V . Kashyap, K. Dewey, E. A. Kuefner, J. Wagner, K. Gibbons, J. Sar-
racino, B. Wiedermann, and B. Hardekopf, “JSAI: A static analysisplatform for JavaScript,” in FSE ’14: Proceedings of the 22Nd ACM
SIGSOFT International Symposium on F oundations of Software Engi-neering, 2014.
551