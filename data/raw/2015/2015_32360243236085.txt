CodeVectors:Understanding Programs Through
Embedded Abstracted Symbolic Traces
JordanHenkel
Universityof WisconsinśMadison, USA
jjhenkel@cs.wisc.eduShuvendu K.Lahiri
Microsoft Research,USA
Shuvendu.Lahiri@microsoft.com
Ben Liblit
Universityof WisconsinśMadison, USA
liblit@cs.wisc.eduThomasReps
Univ. ofWisconsinśMadison andGrammaTech,Inc., USA
reps@cs.wisc.edu
ABSTRACT
Withtheriseofmachinelearning,thereisagreatdealofinterestin
treatingprogramsasdatatobefedtolearningalgorithms.However,
programsdonotstartoffinaformthatisimmediatelyamenable
tomostoff-the-shelflearningtechniques.Instead,itisnecessaryto
transformtheprogramtoasuitablerepresentationbeforealearning
techniquecan be applied.
Inthispaper,weuseabstractionsoftracesobtainedfromsym-
bolic execution of a program as a representation for learning word
embeddings. We trained a variety of word embeddings under hun-
dreds of parameterizations, and evaluated each learned embedding
on a suite of different tasks. In our evaluation, we obtain 93% top-1
accuracyonabenchmarkconsistingofover19,000API-usageanalo-
gies extracted from the Linux kernel. In addition, we show that
embeddingslearnedfrom(mainly)semanticabstractionsprovide
nearly triple the accuracy of those learned from (mainly) syntactic
abstractions.
CCS CONCEPTS
·Theoryofcomputation →Abstraction ;·Computingmethod-
ologies→Machinelearning ;Symbolicandalgebraicmanipulation;
·Softwareanditsengineering →Automatedstaticanalysis ;
Generalprogramminglanguages ;Softwareverificationandvalida-
tion;Softwaretestingand debugging ;
KEYWORDS
Word Embeddings, Analogical Reasoning, Program Understanding,
Linux
ACMReference Format:
JordanHenkel,ShuvenduK.Lahiri,BenLiblit,andThomasReps.2018.Code
Vectors: Understanding Programs Through Embedded Abstracted Symbolic
Traces. In Proceedings of the 26th ACM Joint European Software Engineer-
ingConferenceandSymposiumontheFoundationsofSoftwareEngineering
(ESEC/FSE ’18),November 4ś9, 2018, LakeBuena Vista, FL, USA. ACM, New
York, NY, USA, 12pages.https://doi.org/10.1145/3236024.3236085
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE ’18, November 4ś9, 2018, Lake BuenaVista,FL,USA
©2018 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-5573-5/18/11...$15.00
https://doi.org/10.1145/3236024.32360851 INTRODUCTION
Computer science has a long history of considering programs as
dataobjects[ 13,16].Withtheriseofmachinelearning,therehas
been renewed interest in treating programs as data to be fed to
learningalgorithms[ 3].However,programshavespecialcharac-
teristics, includingseveral layers ofstructure, suchas a program’s
context-freesyntacticstructure,non-context-freenameandtype
constraints, and the program’s semantics. Consequently, programs
do not start off in a form that is immediately amenable to most
off-the-shelflearningtechniques.Instead,itisnecessarytotrans-
form the program to a suitable representation before a learning
techniquecan be applied.
Thispapercontributestothestudyofsuchrepresentationsinthe
contextof wordembeddings .Wordembeddingsareawell-studied
methodfor convertinga corpusof natural-languagetext to vector
representations ofwords embedded into a low-dimensionalspace.
Thesetechniqueshavebeenappliedsuccessfullytoprogramsbe-
fore [17,37,43], but different encodings of programs into word
sequencesarepossible,andsomeencodingsmaybemoreappropri-
atethanothersas the inputto aword-vector learner.
The high-level goalsof our work can be statedas follows:
Deviseaparametricencodingofprogramsintowordsequences
that(i)canbetunedtocapturedifferentrepresentationchoices
on the spectrum from (mainly) syntactic to (mainly) semantic,
(ii) is amenable to word-vector-learning techniques, and (iii)
can be obtainedfrom programs efficiently.
Wealsowishtounderstandtheadvantagesanddisadvantagesof
ourencodingmethod.ğ 5śğ8summarizetheexperimentsthatwe
performedto provideinsightonhigh-level goal(ii).
We satisfy high-level goals (i) and (iii) by basing the encoding
onalightweightform of intraprocedural symbolicexecution .
•We base our technique on symbolic execution due to the
gap between syntax (e.g., tokens or abstract syntax trees
(ASTs)) and the semantics of a procedure in a program. In
particular,token-basedtechniquesimposeaheavyburdenon
the embedding learner. For instance,it is difficultto encode
the differencebetweenconstructions suchas a == band
!(a != b) via a learned, low-dimensional embedding [ 5].
•Ourmethodis intraprocedural sothatdifferentprocedures
can be processedinparallel.
163
ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA J. Henkel, S.Lahiri, B. Liblit,andT.Reps
•Ourmethodis parametric inthesensethatweintroducea
levelofmappingfromsymbolic-executiontracestotheword
sequencesthatareinputtotheword-vectorlearner.(Wecall
theseabstraction mappings orabstractions , although strictly
speakingtheyarenotabstractionsinthesenseofabstract
interpretation[ 11].)Differentabstractionmappingscanbe
usedtoextractdifferentwordsequencesthatareindifferent
positionsonthespectrumof(mainly)syntacticto(mainly)
semantic.
We have developed a highly parallelizable toolchain that is capable
ofproducingaparametricencodingofprogramstowordsequences.
Forinstance,wecanprocess311,670proceduresintheLinuxkernel1
in4hours,2usinga64-coreworkstation(4CPUseachclockedat
2.3 GHz)running CentOS7.4 with252GB ofRAM.
After we present our infrastructure for generating parametric
encodings of programs as word sequences (ğ 2), there are a number
ofnaturalresearchquestionsthat we consider.
First, we explore the utility of embeddings learned from our
toolchain:
Research Question 1 : Are vectors learned from abstracted
symbolic traces encoding usefulinformation?
Judgingutilityisadifficultendeavor.Natural-languageembed-
dings have the advantage of being compatible with several canon-
ical benchmarks for word-similarity prediction or analogy solv-
ing[14,20,27,30,47,48,52].Inthedomainofprogramunderstand-
ing, no such canonical benchmarks exist. Therefore, we designed a
suiteofovernineteenthousandcodeanalogiestoaidintheevalua-
tionofour learnedvectors.
Next,weexaminetheimpactofdifferentparameterizationsof
our toolchain by performing an ablation study. The purpose of this
study isto answer the following question:
ResearchQuestion2 :Whichabstractionsproducethebest
program encodings for word-vector learning?
There areseveral examplesof learningfrom syntacticartifacts,
such asASTs or tokens. Thesuccess of suchtechniques raises the
question of whether adding a symbolic-execution engine to the
toolchainimproves the qualityofour learnedrepresentations.
ResearchQuestion3 : Doabstractedsymbolictracesat the
semanticendofthespectrumprovidemoreutilityastheinput
toaword-vector-learningtechniquecomparedtoonesatthe
syntactic end ofthe spectrum?
Becauseoursuiteofanalogiesisonlyaproxyforutilityinmore
complexdownstreamtasksthatuselearnedembeddings,wepose
one more question:
1Specifically, we used a prerelease of Linux 4.3 corresponding to commit
fd7cd061adcf5f7503515ba52b6a724642a839c8 in the GitHub Linux kernel
repository.
2During trace generation, we exclude only vhash_update , fromcrypto/vmac.c ,
due to its size.Research Question 4 : Can we use pre-trained word-vector
embeddings onadownstream task?
The contributionsofour work can be summarizedas follows:
Wecreatedatoolchain fortakingaprogramorcorpusofpro-
gramsandproducingintraproceduralsymbolictraces.Thetoolchain
isbasedonDockercontainers,isparametric,andoperatesinamas-
sivelyparallelmanner.Oursymbolic-executionengineprioritizes
the amount of data generated over the precision of the analysis: in
particular, no feasibility checking is performed, and no memory
modelisusedduringsymbolic execution.
We generated severaldatasets ofabstractedsymbolictraces
from the Linux kernel. These datasets feature different parame-
terizations (abstractions), and are stored in a format suitable for
off-the-shelf word-vector learners.
Wecreatedabenchmarksuite ofover19,000API-usageanalo-
gies.
We report on severalexperiments using thesedatasets:
•Inğ5,weachieve93%top-1accuracyonasuiteofover19,000
analogies.
•Inğ6,weperformanablationstudytoassesstheeffectsof
differentabstractionsonthe learnedvectors.
•In ğ7, we demonstrate how vectors learned from (mainly)
semantic abstractions can provide nearly triple the accuracy
ofvectors learnedfrom (mainly) syntactic abstractions.
•Inğ8,welearnamodelofaspecificprogrambehavior(which
error a trace is likely to return), and apply the model in a
casestudytoconfirmactualbugsfoundviatraditionalstatic
analysis.
Our toolchain, pre-trained word embeddings, and code-analogy
suite are all available as part of the artifact accompanying this
paper; details are given inğ 11.
Organization. Theremainderofthepaperisorganizedasfollows:
ğ2providesanoverviewofourtoolchainandapplications.ğ 3details
the parametric aspect of our toolchain and the abstractions we
use throughout the remainder of the paper. ğ 4briefly describes
word-vectorlearning.ğ 5śğ8addressourfourresearchquestions.
ğ9considersthreatstothevalidityofourapproach.ğ 10discusses
related work. ğ 11describes supporting materials that are intended
to helpothersbuildonour work. ğ 12concludes.
2 OVERVIEW
Ourtoolchainconsists ofthree phases:transformation,abstraction,
and learning. As input, the toolchain expects a corpus of buildable
C projects, a descriptionof abstractionsto use, and a word-vector
learner.Asoutput,thetoolchainproducesanembeddingofabstract
tokenstodouble-precisionvectorswithafixed,user-supplied,di-
mension. We illustrate this process as applied to the example in
Fig.1.
Phase I: Transformation. Thefirstphaseofthetoolchainenu-
merates all pathsin each source procedure. We begin by unrolling
(and truncating) eachloop sothat its body is executed zero or one
time,therebymakingeachprocedureloop-freeatthecostofdis-
carding many feasible traces. We then apply an intraprocedural
164CodeVectors: UnderstandingPrograms Through EASTs ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA
intexample() {
buf = alloc(12);
if(buf != 0) {
bar(buf);
free(buf);
return 0;
}else{
return -ENOMEM;
}
}
Figure 1:Anexample procedure
callalloc(12);
assume alloc(12) != 0;
callbar(alloc(12));
callfree(alloc(12));
return 0;
(a)Trace 1callalloc(12);
assume alloc(12) == 0;
return -ENOMEM;
(b) Trace 2
Figure 2: Traces from the symbolic execution of the proce-
dure inFig. 1
Called(alloc)
RetNeq(alloc, 0)
Called(bar)
Called(free)
(a)AbstractedTrace 1Called(alloc)
RetEq(alloc, 0)
RetError (ENOMEM)
(b) AbstractedTrace 2
Figure 3:Resultofabstracting thetwotraces inFig. 2b
symbolic executor to each procedure. Fig. 2shows the results of
this processas appliedto the example code inFig. 1.
Phase II: Abstraction. Givenauser-definedsetofabstractions,
thesecondphaseofourtoolchainleveragestheinformationgleaned
from symbolic execution to generate abstracted traces. One key
advantageofperformingsomekindofabstractionisadrasticre-
duction in thenumber of possible tokens that appear in the traces.
ConsiderthetransformedtraceinFig. 2b.Ifwewanttounderstand
therelationshipbetweenallocatorsandcertainerrorcodes,then
we might abstract procedure calls as parameterized tokens of the
formCalled(callee); comparisons of returned values to constants
as parameterized RetEq(callee,value)tokens; and returned error
codes as parameterized RetError (code)tokens. Fig. 3shows the
result ofapplyingtheseabstractionsto the traces from Fig. 2.
Phase III: Learning. Ourabstractedrepresentationdiscardsir-
relevant details, flattens control flows into sequential traces, and
exposes key properties in the form of parameterized tokens that
capture domain information such as Linux error codes. These qual-
ities make abstracted traces suitable for use with a word-vector
learner. Word-vector learners place words that appear in similar
contexts close together in an embedding space. When applied to
naturallanguage,learnedembeddingscananswerquestionssuchas łking is to queen as man is to what?ž (Answer: woman.) Our
goalisto learn embeddings that can answer questionssuch as:
•If a lock acquired by calling spin_lock is released by call-
ingspin_unlock ,thenhowshouldIreleasealockacquired
by calling mutex_lock_nested ? That is, Called(spin_lock) is
toCalled(spin_unlock) asCalled(mutex_lock_nested) is to
what? (Answer: Called(mutex_unlock) .)
•Whicherrorcodeismostcommonlyusedtoreportallocation
failures? That is, which RetError (code)is most related to
RetEq(alloc, 0) ?(Answer: RetError (ENOMEM).)
•Which procedures and checks are most related to alloc?
(Answers: Called(free),RetNeq(alloc, 0) ,etc.)
The remainder of the paper describes a framework of abstrac-
tions and a methodology of learning embeddings that can effec-
tivelysolvetheseproblems.Alongtheway,wedetailthechallenges
that arise in applying word embeddings toabstract path-sensitive
artifacts.
3 ABSTRACTIONS
One difference between learning from programs and learning from
naturallanguageisthesizeofthevocabularyineachdomain.In
natural language, vocabulary size is bounded (e.g., by the words
in a dictionary, ignoring issues like misspellings). In programs, the
vocabularyisessentiallyunlimited:duetoidentifiernames,there
areahugenumberofdistinctwordsthatcanoccurinaprogram.
To address the issue of vocabulary size, we perform an abstraction
operation on symbolic traces, so that we work with abstracted
symbolic traces when learningwordvectors from programs.
3.1 Abstracted Symbolic Traces
We now introduce the set of abstractions that we use to cre-
ate abstracted symbolic traces. Selected abstractions appear in
the conclusions of the deduction rules shown in Fig. 4. The ab-
stractionsfallintoafewsimplecategories.The Called(callee)and
AccessPathStore (path)abstractions can be thought of as łeventsž
thatoccurduringatrace.Abstractionslike RetEq(callee,value)and
Errorserve to encode the łstatusž of the current trace: they pro-
vide contextual information that can modify the meaning of an
łeventž observed later in the trace. Near the end of the trace, the
RetError (code),RetConst (value), andPropRet(callee)abstractions
provide information about the result returned at the end of the
trace.Takentogether,thesedifferentpiecesofinformationabstract
thetrace;however,theabstractedtraceisstillarelativelyrichdigest
ofthe trace’sbehavior.
Withtheabstractionsdescribedabove,wefoundthatthelearned
vectors were sub-optimal. Our investigation revealed that some of
the properties we hoped would be learned required leveraging
contextual information that was outside the łwindowž that a word-
vectorlearnerwascapableofobserving.Forexample,tounderstand
the relationship between a pair of functions like lockandunlock, a
word-vectorlearnermustbeabletocopewithanarbitrarynumber
ofwordsoccurringbetweenthefunctionsofinterest.Suchdistances
are a problem, because lengthening the history given to a word-
vectorlearneralsoincreasesthecomputationalresourcesnecessary
to learn goodvectors.
165ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA J. Henkel, S.Lahiri, B. Liblit,andT.Reps
callfoo()
Called(foo)callbar(foo())
ParamTo(bar, foo)callfoo(obj)
callbar(obj)
ParamShare (bar, foo)assumefoo() == 0
RetEq(foo, 0)obj->foo.bar = baz
AccessPathStore (->foo.bar)
return-C∧C∈ERR_CODES
RetError (ERR_CODES[C]) ,ErrorreturnC∧C/nelementERR_CODES
RetConst (C)returnfoo()
PropRet(foo)PropRet(PTR_ERR)
Error
Figure 4:Example derivationsforselected abstractions
// 1,2 FunctionStart
lock(&obj->lock); // 1,2 Call(lock)
foo = alloc(12); // 1,2 Call(alloc)
if(foo != 0) { // 1 RetNeq(alloc, 0)
obj->baz = // 1 AccessPathStore(->baz)
bar(foo); // 1 ParamTo(bar, alloc)
// 1 Call(bar)
}else{ // 2 RetEq(alloc, 0)
unlock( // 2 ParamShare(unlock, lock)
&obj->lock); // 2 Call(unlock)
return -ENOMEM; // 2 RetError(ENOMEM)
// 2 Error
} // 2 FunctionEnd
unlock( // 1 ParamShare(unlock, lock)
&obj->lock); // 1 Call(unlock)
return 0; // 1 RetConst(0)
// 1 FunctionEnd
Figure 5: Sample procedure with generated abstractions
shownas comments
Due to the impracticality of increasing the context given to a
word-vector learner, we introduced two additional abstractions:
ParamToandParamShare .Theseabstractionsencodetheflowofdata
inthetracetomakerelevantcontextualinformationavailablewith-
out the need for arbitrarily large contexts. As shown in ğ 6, the
abstractions that encode semantic information, such as dataflow
facts, end up adding the most utility to our corpus of abstracted
traces. This observation is in line with the results of Allamanis
et al. [4], who found that dataflow edges positively impact the
performance ofalearnedmodelondownstream tasks.
WeaugmenttheabstractionsshowninFig. 4,withthefollowing
additional abstractions, which are similar to the ones discussed
above:
•RetNeq(callee,value),RetLessThan (callee,value),andothers
arevariantsofthe RetEq(callee,value)abstractionshownin
Fig.4.
•FunctionStart andFunctionEnd are abstractionsintroduced
at the beginningandend ofeachabstractedtrace.
•AccessPathSensitive (path)issimilarto AccessPathStore ;it
encodesanycomplexfieldandarrayaccessesthatoccurin
assumestatements.
3.2 Encoding Abstractionsas Words
Wenowturntohowtheencodingoftheseabstractionsaswords
and sentences (to form our trace corpus) can impact the utilityof learned vectors. To aid the reader’s understanding, we use a
sample procedure and describe an end-to-end application of our
abstractionsandencodings.
Fig.5showsasampleprocedurealongwithitscorresponding
abstractions. The number(s) before each abstraction signify which
of the two paths through the procedure the abstraction belongs to.
To encode these abstractions as words, we need to make careful
choices as to what pieces of information are worthy of being repre-
sented as words, and how this delineation affects the questions we
can answer using the learnedvectors.
Forinstance,considerthe RetNeq(alloc, 0) abstraction.There
areseveralsimplewaystoencodethisinformationasasequence
ofwords:
(1)RetNeq(alloc, 0)=⇒alloc,$NEQ,0
(2)RetNeq(alloc, 0)=⇒alloc,$NEQ_0
(3)RetNeq(alloc, 0)=⇒alloc_$NEQ ,0
(4)RetNeq(alloc, 0)=⇒alloc_$NEQ_0
Each of these four encodings comes with a different trade-off.
Thefirstencodingsplitstheabstractionintoseveralfine-grained
words, which, in turn, reduces the size of the overall vocabulary.
This approach may benefit the learned vectors because smaller
vocabulariescanbeeasiertoworkwith.Ontheotherhand,splitting
the information encoded in this abstraction into several words
makessomequestionsmoredifficulttoask.Forexample,itismuch
easiertoask whatis mostrelated to allocbeing notequal tozero
whenwehavejustasingleword, alloc_$NEQ_0 ,tocapturesuch
ascenario.
In our implementation, we use the fourth option. It proved diffi-
culttoaskinterestingquestionswhentheabstractionswerebroken
downintofine-grainedwords.Thisdecisiondidcomewiththecost
ofalarger vocabulary.3Encodingsfor therestofour abstractions
are shown in Fig. 6.4The sentences generated by applying these
encodings to Fig. 5are showninFig. 7.
4 WORD2VEC
Word2Vec is a popular method for taking words and embedding
themintoalow-dimensionalvectorspace[ 30].Insteadofusinga
one-hot encodingÐwhere each element of a vector is associated
withexactlyonewordÐword2veclearnsadenserrepresentation
3We mitigate theincrease invocabulary size from constructions like alloc_$NEQ_0
by restricting the constants we look for. Our final implementation only looks for
comparisonsto constants in the set {−2,−1,0,1,2,3,4,8,16,32,64}.
4Because it is not possible to have ParamShare (X, Y) orParamTo(X, Y)
without a Called(X)following them, the abstractions ParamShare (X, Y)and
ParamTo(X, Y)areencoded as Yto avoid duplicating X.
166CodeVectors: UnderstandingPrograms Through EASTs ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA
matchabstraction with
| Called (x) -> x
| ParamTo (_,x) -> x
| ParamShare (_,x) -> x
| RetEq (x,c) -> x ^ "_$EQ_" ^ c
| RetNeq (x,c) -> x ^ "_$NEQ_" ^ c
(* ... *)
| PropRet (x) -> "$RET_" ^ x
| RetConst (c) -> "$RET_" ^ c
| RetError (e) -> "$RET_" ^ ERR_CODES[e]
| FunctionStart -> "$START"
| FunctionEnd -> "$END"
| Error -> "$ERR"
| AccessPathStore (p) -> "!"^ p
| AccessPathSensitive (p) -> "?"^ p
Figure 6:Encoding ofabstractions
$START lock alloc alloc_$NEQ_0 !->baz
alloc bar lock unlock $RET_0 $END
(a)Trace 1
$START lock alloc alloc_$EQ_0 lock
unlock $ERR $RET_ENOMEM $END
(b) Trace 2
Figure 7: Traces for Fig. 5generated by the encoding from
Fig.6
thatcapturesmeaningfulsyntacticandsemanticregularities,and
encodes theminthe cosine distancebetween words.
Forourexperiments,weusedGloVe[ 41]duetoitsfavorableper-
formancecharacteristics. GloVe works byleveraging the intuition
thatword-wordco-occurrenceprobabilitiesencodesomeformof
meaning.Aclassicexampleistherelationshipbetweentheword
pair łicež and łsteamž and the word pair łsolidž and łgas.ž Gas and
steamoccurin thesamesentencerelatively frequently,compared
to the frequency with which the words gas and ice occur in the
same sentence. Consequently, the following ratio is significantly
less than 1:
Pr(gas|ice)
Pr(gas|steam)
If,instead,welookatthefrequencyofsentenceswithbothsolid
andicecomparedtothefrequencyofsentenceswithbothsolidand
steam, we find the opposite.The ratio
Pr(solid|ice)
Pr(solid|steam)
is much greater than 1. This signal is encoded into a large co-
occurrencematrix.GloVethenattemptstolearnwordvectorsfor
whichthedot-productoftwovectorsisclosetothelogarithmof
theirprobability ofco-occurrence.5 RQ1:ARE LEARNEDVECTORSUSEFUL?
ResearchQuestion 1askedwhethervectorslearnedfromabstracted
symbolic traces encode useful information. We assess utility via
three experimentsoverword vectors.Each of the followingsubsec-
tionsdescribes andinterpretsone experiment indetail.
5.1 Experiment 1: CodeAnalogies
An interesting aspect of word vectors is their ability to express
relationships between analogous words using simple math and
cosine distance. Encoding analogies is an intriguing byproduct of a
łgoodž embedding and, as such, analogies have become a common
proxyfor the overallquality of learnedwordvectors.
No standard test suite for codeanalogies exists, so we cre-
ated such a test suite using a combination of manual in-
spection and automated search. The test suite consists of
twenty different categories, each of which has some number
of function pairs that have been determined to be analogous.
Forexample,consider mutex_lock_nested/mutex_unlock and
spin_lock/spin_unlock ; these are two pairs from the łlock /
unlockžcategorygiveninTab. 1.Wecanconstructananalogyby
takingthesetwopairsandconcatenatingthemtoformtheanalogy
łmutex_lock_nested is tomutex_unlock asspin_lock is to
spin_unlock .žByidentifyinghigh-levelpatternsofbehavior,and
finding several pairs of functions that express this behavior, we
createdasuite that contains 19,042code analogies.
Tab.1listsourcategoriesandthecountsofavailablepairs,along
with a representative pair from each category. Tab. 1also provides
accuracymetricsgeneratedusingthevectorslearnedfromwhatwe
willrefer to as the łbaseline configuration,ž5whichabstracts sym-
bolictracesusingalloftheabstractionsdescribedininğ 3.Weused
a grid-search over hundreds of parameterizations to pick hyper-
parametersforourword-vectorlearner.Fortheresultsdescribed
in this section, we used vectors of dimension 300, a symmetric
windowsizeof50,andavocabulary-minimumthresholdof1,000
to ensure that the word-vector learner only learns embeddings for
words that occur a reasonable number of times in the corpus of
traces. We trained for 2,000 iterations to give GloVe ample time to
find goodvectors.
In each category, we assume that any two pairs of functions are
sufficiently similar to be made into an analogy. More precisely, we
form a test by selecting two distinct pairs of functions (A,B)and
(C,D)fromthesamecategory,andcreatingthetriple (A,B,C)to
givetoananalogysolverthatisequippedwithourlearnedvectors.
Theanalogysolverreturnsavector D′,andweconsiderthetest
passed if D′=Dand failed otherwise. Levy and Goldberg [25]
present the following objective to use when solving analogies with
word-vectors:
D′=argmax
d∈V\{A,B,C}cos(d,B)−cos(d,A)+cos(d,C)
Results. The łAccuracyž column of Tab. 1shows that overall ac-
curacyontheanalogysuiteisexcellent.Ourembeddingsachieve
5Thebaselineconfigurationisdescribedinmoredetailinğ 6,whereitisalsocalled
configuration (1).
167ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA J. Henkel, S.Lahiri, B. Liblit,andT.Reps
Table 1:Analogy Suite Details
Type Category Representative Pair #ofPairs PassingTests Total Tests Accuracy
Calls 16 / 32 store16/store32 18 246 306 80.39%
Calls Add / Remove ntb_list_add/ntb_list_rm 9 72 72 100.0%
Calls Create / Destroy device_create/device_destroy 19 302 342 88.30%
Calls Enable/ Disable nv_enable_irq/nv_disable_irq 62 3,577 3,782 94.58%
Calls Enter / Exit otp_enter/otp_exit 12 122 132 92.42%
Calls In / Out add_in_dtd/add_out_dtd 5 20 20 100.0%
Calls Inc/ Dec cifs_in_send_inc/cifs_in_send_dec 10 88 90 97.78%
Calls Input/ Output ivtv_get_input/ivtv_get_output 5 20 20 100.0%
Calls Join/ Leave handle_join_req/handle_leave_req 4 8 12 66.67%
Calls Lock/ Unlock mutex_lock_nested/mutex_unlock 53 2,504 2,756 90.86%
Calls On/ Off b43_led_turn_on/b43_led_turn_off 19 303 342 88.60%
Calls Read / Write memory_read/memory_write 64 3,950 4,032 97.97%
Calls Set/ Get set_arg/get_arg 22 404 462 87.45%
Calls Start / Stop nv_start_tx/nv_stop_tx 31 838 930 90.11%
Calls Up/ Down ixgbevf_up/ixgbevf_down 24 495 552 89.67%
Complex RetCheck/ Call kzalloc_$NEQ_0/kzalloc 21 252 420 60.00%
Complex RetError/ Prop write_bbt_$LT_0/$RET_write_bbt 25 600 600 100.0%
Fields Check/ Check ?->dmaops/?->dmaops->altera_dtype 50 2,424 2,450 98.94%
Fields Next/ Prev !.task_list.next/!.task_list.prev 16 240 240 100.0%
Fields Test/ Set ?->at_current/!->at_current 39 1,425 1,482 96.15%
Totals: 508 17,890 19,042 93.95%
greater than 90% top-1 accuracy on thirteen out of the twenty cate-
gories.ThelearnedvectorsdotheworstonthełRetCheck/Callž
category where the top-1 accuracy is only 60%. This category is
meanttorelatethecheckingofthereturnvalueofacallwiththecall
itself. However, we often find that one function allocates memory,
whileadifferentfunctionchecksforallocationsuccessorfailure.
For example, a wrapper function may allocate complex objects, but
leave callers to check that the allocation succeeds. Because our
vectorsarederivedfromintraproceduraltraces,itissensiblethat
accuracysuffers for interproceduralbehaviors.
Bycontrast,ourvectorsperformextraordinarilywellonthełRet
Error / Propž category (100% top-1). This category represents cases
where an outer function (i) performsan inner call, (ii) detectsthat
ithasreceivedan errorresult,and(iii) returns(łpropagatesž)that
errorresultastheouterfunction’sownreturnvalue.Unlikeforthe
łRetCheck/Callžcategory,thenatureofthełRetError/Propžcate-
goryensuresthatboththecheckandthereturnpropagationcanbe
observedinintraproceduraltraces,withoutlosinganyinformation.
5.2 Experiment 2: Simple Similarity
One of the most basic word-vector tasks is to ask for the knearest
vectorstosomechosenvector(usingcosinedistance).Weexpect
theresultsofsuchaquerytoreturnalistofrelevantwordsfromour
vocabulary.Oursimilarityexperimentswerebasedontwotypes
ofqueries:(i)givenaword,findtheclosestword,and(ii)givena
word,find the five closestwords.ret = new( /*...*/ , &priv->bo);
if(!ret) {
ret = pin(priv->bo, /*...*/ );
if(!ret) {
ret = map(priv->bo);
if(ret)
unpin(priv->bo);
}
if(ret)
ref(NULL, &priv->bo);
}
Figure 8: Excerpt from nv17_fence.c . Names have been
shortened to conserve space.
Similar pairs. We identified the single most similar word to each
word in our vocabulary V. This process produced thousands of
interesting pairs. In the interest of space, we have selected four
sampleswhicharerepresentativeofthevarietyofhigh-levelrela-
tionshipsencodedinour learnedvectors6:
•sin_mul andcos_mul
•dec_stream_header anddec_stream_footer
•rx_b_frame andtx_b_frame
6The artifact accompanying this paper includes a full listing of these pairs, ordered by
cosine-similarity.
168CodeVectors: UnderstandingPrograms Through EASTs ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA
•nouveau_bo_new_$EQ_0 andnouveau_bo_map7
The last pair is of particular interest, because it expresses a com-
plexpatternofbehaviorthatwouldbeimpossibletoencodewithout
some abstraction of the path condition. The last pair suggests that
there is a strong relationship between the function newreturn-
ing0(which signals a successful call) and then the subsequent
performance of some kind of map operation with the mapcall. To
gain a deeper understanding of what the vectors are encoding, we
searchedforinstances of thisbehaviorin the original sourcecode.
We foundseveral instancesofthe pattern showninFig. 8.
The code in Fig. 8raise a new question: why isn’t pinmore
closelyrelatedto new_$EQ_0 ?Weperformedadditionalsimilarity
queries to gain a deeper understanding of how the learned vectors
have encodedthe relationship between new,pin,andmap.
First,wecheckedtoseehowsimilar pinistonew_$EQ_0 .We
found that pinis the fourth-most related word to new_$EQ_0 ,
which suggests that a relationship does exist, but that the relation-
ship between new_$EQ_0 andpinis not as strong as the one
between new_$EQ_0 andmap. Looking back at the code snippet
(and remembering that several more instances of the same pattern
canbefoundinseparatefiles),weareleftwiththefactthat pin
directly follows from the successful new. Therefore, intuition dic-
tatesthat pinshouldbemorestronglyrelatedto newthanmap.
The disagreement between our intuition and the results of our
word-vector queriesmotivatedusto investigate further.
By turning to the traces for an answer, we uncovered a more
complete picture. In 3,194 traces, newco-occurs with pin. In
3,145 traces, newco-occurs with map. If we look at traces that
donotcontain a call to new, there are 11,354traces that have
nocallto new,butstillhaveacallto pin.Incontrast,only 352
traces have no call to new, but still have a call to map. Finally,
wehaveadefinitiveanswertotheencodinglearnedbythevectors:
it is indeed the case that newandmapare more related in our
corpus of traces, because almost every time a call to mapis made,
acorrespondingcallto newprecedesit.Ourintuitionfooledus,
because the snippets of source code only revealed a partial picture.
Top-5 similar words and the challenge of prefix dominance.
Anothersimilarity-basedtestistotakeawordandfindthetop- k
closest words in the learned embedding space. Ideally, we’d see
words that make intuitive sense. For the purpose of evaluation, we
picked two words: affs_bread , a function in the AFS file system
that reads a block, and kzalloc , a memory allocator. For each
target word, we evaluated the top-5 most similar words for rele-
vance.Intheprocess,wealsouncoveredaninterestingchallenge
when learning over path-sensitive artifacts, which we call prefix
dominance .
Ourcorpusofsymbolictracescanbethoughtofasacorpusof
execution trees. In fact, in the implementation of our trace gen-
erator, the traces only exist at the very last moment. Instead of
storingtraces,westoreatreethatencodes,withoutunnecessary
7In the following text, and in Fig. 8, we remove the nouveau_bo_ prefix to conserve
space.Table 2:Top-5closest words to affs_bread andkzalloc
affs_bread kzalloc
affs_bread_$NEQ_0 kzalloc_$NEQ_0
affs_checksum_block kfree
AFFS_SB _volume
affs_free_block snd_emu10k1_audigy_write_op
affs_brelse ?->output_amp
duplication,theinformationgainedfromsymbolicallyexecuting
a procedure. If we think about the dataset of traces as a dataset
of trees (each of which holds many traces that share commonpre-
fixes), we begin to see that learning word vectors from traces is an
approximation oflearningdirectlyfrom the executiontrees.
The approximation of trees by traces works, in the sense that
we can use the traces to learn meaningful vectors, but the approxi-
mation is vulnerable to learning rare behaviors that exist at the be-
ginningofaprocedurewhosetrace-treehasmanynestedbranches.
Theserarebehaviorsoccuronlyonceintheoriginalproceduretext
andcorrespondingexecutiontree,butarereplicatedmanytimesin
the traces. In a procedure with significant branching complexity,
a single occurrence of rare behavior can easily overwhelm any
arbitrary number ofoccurrences of expectedbehavior.
In Tab.2, we see two words, affs_bread andkzalloc ,
and the five most similar words to each of them. Word similar-
ity has captured many expected relationships. For example, the
fact that kzalloc is most commonly checked to be non-null
(kzalloc_$NEQ_0 )andthenalso kfreediswhatwewouldex-
pect, given the definition of an allocator. Similarly, we can see that
affs_bread is also checked to be non-null, checksummed, freed,
released, etc. However, in addition to these expected relationships,
the last three entries for kzalloc seem out of place. These un-
expectedentriesare presentinthetop-5 answerbecauseofprefix
dominance.
We searched our traces for places where kzalloc and the
three unexpected entries in the table co-occur. We found one func-
tion with 5,000 paths (5,000 being our łbudgetž for the number
of traces we are willing to generate via symbolic execution for
a single procedure), of which 4,999 have several instances of the
patternkzalloc followed by snd_emu10k1_audigy_write_op .
This one function, with its multitude of paths, overwhelms our
dataset,andcausesthewordvectorstolearnaspuriousrelationship.
Prefix dominance also explains the strong associations between
kzalloc and_volume and?->output_amp .
Ontheotherhand, affs_bread isrelativelyunaffectedbypre-
fix dominance. Examining our traces for the affsfile system
that contains this function, we found that no procedures had an
overwhelmingnumberofpaths.Therefore,weneverseeanover-
whelming number of affs_bread usage patterns that are rare at
the sourcelevel but common inour setof traces.
169ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA J. Henkel, S.Lahiri, B. Liblit,andT.Reps
5.3 Experiment 3: Queries Via Word-Vector
Averaging
Wordvectorshavethesurprisingandusefulabilitytoencodemean-
ing when averaged [ 23,24]. We devised a test to see if our learned
vectors are able to leverage this ability to capture a relationship
between allocation failure andreturning -ENOMEM .
To understand whether our word vectors are capable of answer-
ing such a high-level question, we evaluated their performance on
increasingly targeted queries (represented by averaged vectors).
Each query was restricted to search only for words in the subspace
of the embedding space that contains kernel error-codes. (Narrow-
ingtothesubspaceoferrorcodesensuresthatweareonlylooking
at relevantwords,andnot at the wholevocabulary.)
Results. Weidentifiedtwentydifferentfunctionsthatactasallo-
cators inthe Linux kernel.
First, for each such allocator, we took its word vector A, and
queried for the closest vector to A(in the subspace of error codes).
This method found the correct error code only twice out of twenty
tests (i.e.,10%accuracy).
Second, we asked for the vector closest to an average vector
that combined the vector for the allocator Aof interest and the
vector− −−− →$ERRfora generic error:8(A+− −−− →$ERR)/2.This queryfound
the correct ENOMEMcode fourteen times out of twenty (i.e., 70%
accuracy).
Third, instead of averaging the allocator’s Avector with− −−− →$ERR,
we triedaveraging Awiththe vector for the special $ENDtoken
that signals the end of a trace. Seeking the error code closest to
(A+− −−− →$END)/2found the correct result for sixteen of twenty test
cases (i.e., 80% accuracy). The fact that this method outperforms
ourpreviousqueryrevealsthatthecalltoanallocatorbeingnear
the end of a trace is an even stronger signal than the $ERRtoken.
Finally, we mixed the meaning of the allocator, the er-
ror token, and the end-of-trace token by averaging all three:
(A+− −−− →$ERR+− −−− →$END)/3. The error code whose vector is closest to
thisqueryisthecorrect ENOMEMcodeforeighteenofthetwenty
tests (i.e., 90% accuracy). The steadily increasing performance indi-
cates that targeted queries encoded as average word vectors can
indeedbe semantically meaningful.
The effectiveness of these queries, and the results from ğ 5.1
andğ5.2,supportapositiveanswertoResearchQuestion 1:learned
vectors doencode useful information aboutprogram behaviors.
6 RQ2:ABLATION STUDY
Inthissection,wepresenttheresultsofanablationstudytoisolate
theeffectsthatdifferentsetsofabstractionshaveontheutilityof
thelearnedvectors.Weusedthebenchmarksuiteof19,042code-
analogies from ğ 5to evaluate eight different configurations. We
scored each configuration according to the number of analogies
correctlyencodedbythewordvectorslearnedforthatconfiguration
(i.e.,we report top-1 results).
8The$ERRwordisaddedtoanytracethatreturnseither(i)theresultofan ERR_PTR
call, or (ii) aconstant lessthan zero that isalso a known error code.Consequently,a
vector− −− →$ERRis learned for the word $ERR.(1) (2) (3) (4) (5) (6) (7) (8)0%20%40%60%80%100%
85.8%
51.7%83.4%
61.7%83.0%85.5%83.8%82.4%
OOV
Failed
Passed
Figure9:Ablationstudy:top-1analogyresultsforeightcon-
figurations (baseline (1)with up to one individual abstrac-
tion class removed). The vocabulary minimum was 0, and
thenumberoftraining iterationswas 1,000.
In addition to the baseline configuration from ğ 5.1, we parti-
tioned the abstractions into six classes9and generated six new
embeddings,eachwithone of the sixabstractionclasses excluded.
We also used one more configuration in which stop words were
included.Innaturallanguageprocessing,stopwordsarewordsthat
are filtered out of a processing toolchain. Sometimes these are the
most common words in a language, but any group of words can be
designated as stop words for a given application. In our context,
stopwordsarefunctionnamesthatoccuroften,butaddlittlevalue
to the trace. Examples are __builtin_expect and automatically
generated __compiletime_assert s.
We evaluatedthe following eightconfigurations:
(1)baseline: allabstractionsfrom ğ 3;
(2) baselinewithout ParamToandParamShare ;
(3) baselinewithout RetEq,RetNeq,etc.;
(4)baselinewithout AccessPathStore andAccessPathSensitive ;
(5) baselinewithout PropRet,RetError,andRetConst;
(6) baselinewithout Error;
(7) baselinewithout FunctionStart andFunctionEnd ; and
(8) baselinewithstop wordsincluded.
Fig.9comparestheaccuracyoffortheseeightconfigurations.
Bluebars indicate the number of tests in the analogy suite that
passed;redindicates tests that failed; and brownindicates out-
of-vocabulary (OOV) tests. Configuration (4)had the most out-
of-vocabulary tests; in this configuration, we do not have words
like!->next and!->prev , which leaves several portions of
the analogy suite essentially unanswerable. Thus, we count out-of-
vocabulary tests as failedtests.
To create a fair playing field for evaluating all eight configu-
rations, we chose a single setting for the hyper-parameters that
wereusedwhenlearning wordvectors.Wereducedthethreshold
for how often a word must occur before it is added to the vocab-
ulary from 1,000 to 0. The latter parameter, which we refer to as
9Except for Called, whichwas used in allconfigurations.
170CodeVectors: UnderstandingPrograms Through EASTs ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA
thevocabulary minimum , significantly impacts performance by
forcingtheword-vectorlearnertodealwiththousandsofrarely-
seenwords.Tounderstandwhywemustsetthevocabularymin-
imum to zero, effectively disabling it, consider the following ex-
ampletrace: Called(foo),ParamShare (foo, bar), Called(bar).In
configuration (2),whereweignore ParamShare ,wewouldencode
thistraceasthesentence foo bar .Inconfiguration (1),thissame
traceisencodedas foo foo bar .Thefactthatsomeabstractions
caninfluencethefrequencywithwhichawordoccursinatracecor-
pusmakesanyword-frequency-basedfilteringcounterproductive
to our goalofperformingafair comparison.
We also lowered the number of training iterations from 2,000
to 1,000 to reduce the resources required to run eight separate
configurations of our toolchain. (These changes are responsible for
thechangeinthetop-1accuracyofthebaselineconfigurationfrom
93.9% inTab. 1to 85.8% inFig. 9.)
In Fig.9, one clearly sees that configuration (2)(the one without
any dataflow-based abstractions) suffers the worst performance
degradation.Configuration (4),whichomitsaccess-path-basedab-
stractions, has the second-worst performance hit. These results in-
dicate that dataflow information is critical to the quality of learned
vectors. This conclusion further confirms findings by Allamanis
etal.[4]regardingtheimportanceofdataflowinformationwhen
learningfrom programs.
Fig.9also reveals that removing łstatež abstractions ( RetEq,
RetNeq,etc.and Error)haslittleeffectonquality.However,these
abstractionsstilladdusefultermstoourvocabulary,andthereby
enlarge the set of potentially answerablequestions. Without these
abstractions,someofthe questionsinğ 5wouldbe unanswerable.
These results support the following answer to Research Ques-
tion2:dataflow-basedabstractionsprovidethegreatestbenefitto
word-vectorlearning.Theseabstractions,coupledwithaccess-path-
basedabstractions,providesufficientcontexttoletaword-vector
learner create useful embeddings. Adding abstractions based on
path conditions (or other higher-level concepts like Error) adds
flexibility without worsening the quality of the learned vectors.
Therefore,we recommendincludingtheseabstractions,as well.
7 RQ3:SYNTACTICVERSUSSEMANTIC
Nowthatwehaveseentheutilityofthegeneratedcorpusforword-
vector learning (ğ 5) and the interplay between the abstractions we
use(ğ6),wecompareourrecommendedconfiguration (1)fromğ6
withasimpler syntactic-basedapproach.
We explored several options for a syntactic-based approach
againstwhichtocompare.Intryingtomakeafaircomparison,one
difficultythatarisesistheamountofdataourtoolchainproducesto
use for the semantics-basedapproach. If we were to compare con-
figuration (1)against an approachbasedon ASTs or tokens, there
would be a large disparity between the paucity of data available
totheAST/token-basedapproachcomparedtotheabundanceof
dataavailabletotheword-vectorlearner:anAST-ortoken-based
approach wouldonly have one data pointper procedure,whereas
thepath-sensitiveartifactsgatheredusingconfiguration (1)provide
theword-vector learnerwithhundreds,ifnotthousands,ofdata
pointsper procedure.0% 20% 40% 60% 80%100%Semantic
Syntactic85.8%
31.4%Passed FailedOOV
Figure10:Top-1analogyresultsforsyntacticversusseman-
tic abstractions. (The vocabulary minimum was 0, and the
numberoftraining iterationswas 1,000.)
Tocontrolfor thiseffect andavoidsuch adisparity, we instead
comparedconfiguration (1)againstaconfigurationofourtoolchain
thatusesonlyłsyntacticžabstractionsÐi.e.,abstractionsthatcanbe
appliedwithoutanyinformationobtainedfromsymbolicexecution.
Thus, the syntactic abstractionsare:
•FunctionStart andFunctionEnd ,
•AccessPathStore (path),and
•Called(callee).
The rest of our abstractions use deeper semantic information, such
asconstantpropagation,dataflowinformation,or thepathcondi-
tionfor agiven trace.
Using only the syntactic abstractions, we generated a corpus of
traces, and then learned word vectors from the corpus. We com-
pared the newly learned word vectors to the ones obtained with
configuration (1).Fig.10clearlyshowsthatsemanticabstractions
arecrucial togivingthecontextnecessaryforsuccessfullearning.
Even if we assess performance using only the analogies that are
in-vocabulary for the syntactic-based approach, we find that the
syntactic-based approach achieves only about 44% accuracy, which
isabouthalf theaccuracyofvectorslearnedfrom(mainly)semantic
abstractions.
TheseresultssupportanaffirmativeanswertoResearchQues-
tion3: abstracted traces that make use of semantic information
obtained via symbolic execution provide more utility as the in-
puttoaword-vectorlearnerthanabstractedtracesthatuseonly
syntactic information.
8 RQ4:USE INDOWNSTREAM TASKS
Research Question 4asks if we can utilize our pre-trained word-
vector embeddings onsomedownstream task.
To address this question, we selected a downstream task that
models bug finding, repair, and code completion in a restricted
domain:error-codemisuse.Wechoseerror-codemisusebecause
it allows us to apply supervised learning. Because there are only a
finitenumberofcommonerrorcodesintheLinuxkernel,wecan
formulateamulti-classlabelingproblemusingtracesgeneratedvia
our toolchainandour pre-trainedword-vector embeddings.
To build an effective error-code-misuse model, we gathered a
collectionoffailingtraces(tracesinwhichthe $ERRtokenoccurs).
Wethenconstructedadatasetsuitableforsupervisedlearningasfol-
lows: we took each trace from configuration (2)10and removed the
10Thedataflowabstractionspresentin(1)werecreatedtoaidword-vectorlearners;
for thisexperiment,weuseconfiguration(2)to excludethoseabstractions.
171ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA J. Henkel, S.Lahiri, B. Liblit,andT.Reps
lastthreeabstracttokens,namely, $ERR,$RET_E* ,and$END;11
weusedthe $RET_E* tokenasthelabelforthetrimmedtrace.We
sampled a subset of 20,000 traces from this large trace collection to
use for training our model.
Thisdatasetisagoodstartingpoint,butfeedingittoamachine-
learningtechniquethatacceptsfixed-lengthinputsrequiresfurther
processing.Topreprocessthedata,wekeptonlythelast100tokens
ineachtrace.Wethentookthetrimmedtraces,andusedourlearned
word-vectorembeddingto transformeachsequenceof words into
a sequence of vectors (of dimension 300). If, originally, a trace had
fewer than100tokens, we paddedthe beginningofthetrace with
the zero vector. We paired each of the trimmed and encoded traces
with its label (which we derived earlier). Finally, to complete the
preprocessingofthedatasetweattachedaone-hotencodingofthe
label.
Tocollectachallengingtestsettoevaluateourlearnedmodel,
weturnedtorealbug-fixingcommitsappliedtotheLinuxkernel.
Wesearchedforcommitsthatreferencedanłincorrectreturnžin
their description. In addition, we leveraged Min et al.’s [31] list of
incorrect return codes fixed by their JUXTA tool. Next, we gen-
eratedabstractedsymbolictracesbothbeforeapplyingthefixing
commitandafter.Finally,wekeptthetracesgeneratedbeforeap-
plyingthe fixthat, afterthe fix,had changedonly inthe errorcode
returned.Usingthisprocess,wecollected68tracesÐfrom15unique
functionsÐthathadbeen patchedto fixan incorrectreturn code.
Using the preprocessed dataset, we trained a model to predict
theerrorcodethateachtraceshouldreturn.Weusedarecurrent
neural network with long short-term memory (LSTM) [ 22]. We
evaluated the trained model, using our test set, in two different
ways:
(1)BugFinding: weuseourlearnedmodeltopredictthethree
mostlikelyerrorcodesforeachtraceinourtestset.Ifagiven
traceinitiallyendedintheerrorcode A,butwaspatched
to return the error code B, we check to see if the incorrect
Aerrorcode isabsent from our model’stop-3 predictions.
(2)Repair/Suggestion: weagainusethelearnedmodeltopredict
thethreemostlikelyerrorcodesforeachtraceinthetestset.
This time, we determine the fraction of traces for which the
correcterrorcode(i.e., B)ispresentinthetop-3prediction
madebythe model.
In evaluation (1), we found that the learned model identified an
incorrecterrorcodein57ofour68tests.Thisresultispromising,
because it suggests that there is enough signal in the traces of
encoded vectors to make good predictions that could be used to
detectbugsearly.
In evaluation (2), we observed that the learned model had a
top-3 accuracy of 76.5%, meaning that the correct error code is
amongourtopsuggestedfixesformorethanthreefourthsofthe
buggy traces. This result is a strong indicator that the learned
vectors and abstracted symbolic traces are rich enough to make
high-level predictions that could be used to augment traditional
IDEs with predictive capabilities. Such a feature could operate like
autocomplete,butwithanawarenessofwhatothercontributors
11We exclude traces that included the $RET_PTR_ERR token because these traces do
not haveanassociated errorcode.havedoneandhowtheir(presumablycorrect)codeshouldinfluence
new contributions. This feature would be similar to the existing
applications of statistical modelingto programming taskssuch as
autocompletion [ 2,10,34,38,45].
TheseresultssupportanaffirmativeanswertoResearchQues-
tion4:ourpre-trainedword-vectorembeddingscanbeusedsuc-
cessfullyondownstreamtasks.Theseresultsalsosuggestthatthere
aremanyinterestingapplicationsforourcorpusofabstractedsym-
bolic traces. Learning from these traces to find bugs, detect clones,
oreven suggestrepairs,are allwithin the realmof possibility.
9 THREATS TO VALIDITY
There are several threatsto the validity of our work.
We leverage a fast, but imprecise, symbolic-execution engine. It
is possible that information gained from the detection of infeasible
pathsandtheuseofamemorymodelwouldimprovethequality
of our learned vectors. In addition, it is likely that a corpus of
interproceduraltraces wouldimpact our learnedvectors.
We chose to focus our attention on the Linux kernel. It is pos-
siblethatlearninggoodword-embeddingsusingartifactsderived
from the Linux kernel does not translate to learning good word-
embeddingsforprogramsingeneral.Tomitigatethisrisk,wemaxi-
mizedtheamountofdiversityintheingestedproceduresbyingest-
ingthe Linux kernel withallmodularandoptionalcode included.
Our analogies benchmark and the tests based on word-vector
averaging are only proxies for meaning, and, as such, only serve as
an indirectindicator of the qualityof the learned word vectors. In
addition,wecreatedthesebenchmarksourselves,andthusthere
is a risk that we introduced bias into our experiments. Unfortu-
nately,wedonothavebenchmarksasextensiveasthosecreated
throughout the years in the NLP community. Similar to Mikolov
etal. [29],wehopethatourintroductionofasuitablebenchmark
willfacilitatecomparisonsbetweendifferentlearnedembeddings
inthe future.
10 RELATED WORK
Recently,severaltechniqueshaveleveragedlearnedembeddingsfor
artifacts generated from programs. Nguyen et al . [36,37]leverage
word embeddings (learned from ASTs) in two domains to facilitate
translation from Java to C#. Pradel and Sen [43]use embeddings
(learned from custom tree-based contexts built from ASTs) to boot-
strapanomalydetectionagainstacorpusofJavaScriptprograms.
Guetal.[17]leverageanencoder/decoderarchitecturetoembed
wholesequencesintheir DeepAPI toolforAPIrecommendation.
API2API by Ye et al . [51]also leverages word embeddings, but it
learns the embeddings from API-related natural-language docu-
mentsinstead ofan artifact deriveddirectlyfrom sourcecode.
Moving toward more semantically rich embeddings, DeFreez
et al. [12]leverage labeled pushdown systems to generate rich
traces which they use to learn function embeddings. They apply
theseembeddingstofindfunctionsynonyms,whichcanbeusedto
improve traditional specification mining techniques. Alon et al . [8]
learn from paths through ASTs to produce general representations
ofprograms;in[ 7]theyexpanduponthisgeneralrepresentationby
172CodeVectors: UnderstandingPrograms Through EASTs ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA
leveragingattentionmechanisms.Ben-Nunetal .[9]utilizeanin-
termediate representation (IR) to produce embeddings of programs
that are learned from both control flow and data flow information.
Venturingintogeneralprogramembeddings,thereareseveral
recent techniques that approach the problem of embedding pro-
grams(or,moregenerally,symbolic-expressions/trees)inunique
ways.Usinginput/outputpairsastheinputdataforlearning,Piech
et al.[42]and Parisotto et al .[39]learn to embed whole programs.
Usingsequencesoflivevariablevalues,Wangetal . [49]produce
embeddingstoaidinprogramrepairtasks.Allamanisetal .[4]learn
toembed wholeprograms viaGatedGraphRecurrent Neural Net-
works(GG-RNNs)[ 26].Allamanisetal .[5]approachthemorefoun-
dationalproblemoffindingcontinuousrepresentationsofsymbolic
expressions.Mouetal .[32]introducetree-basedconvolutionalneu-
ralnetworks(TBCNNs),anothermodelforembeddingprograms.
Pengetal .[40]provideanAST-basedencodingofprogramswith
the goal of facilitating deep-learning methods. Allamanis et al . [3]
give a comprehensive survey ofthese techniques,andmany other
applicationsofmachine learningto programs.
We are not aware of any work that attempts to embed traces
generatedfromsymbolicexecution.Onthecontrary,Fowkesand
Sutton[15]warnofpossibledifficultieslearningfrompath-sensitive
artifacts. We believe that our success in using symbolic traces as
theinput toa learnerisduetothe additionofpath-conditionand
dataflow abstractionsÐthe extra information helps to ensure that a
complete picture isseen, even inapath-sensitive setting.
In the broader context of applying statistical NLP techniques
toprograms,therehasbeenalargebodyofworkusinglanguage
modelstounderstandprograms[ 1,6,21,35,46];tofindmisuses[ 33,
50];andto synthesize expressionsandcode snippets[ 18,44].
11 EXPERIMENTALARTIFACTS
Ourc2ocaml tool, which performs a source-to-source transfor-
mation during the compilation of C projects (to generate inputs
to our lightweight symbolic execution engine) is available at
https://github.com/jjhenkel/c2ocaml .
Ourlightweightsymbolicexecutionengine, lsee,isalsoavail-
ableathttps://github.com/jjhenkel/lsee .
Additionally,weprovidetoolstodemonstrateourexperimentsat
https://github.com/jjhenkel/code-vectors-artifact [19].
Thisartifactallowstheusertorunourtoolchainend-to-endona
smaller open-source repository (Redis). The artifact uses pre-built
Docker [28] images to avoid complex installation requirements.
Our raw data (two sets of learned vectors and a full collection of
abstractedsymbolic traces) are alsoincludedinthis artifact.
12 CONCLUSION
The expanding interest in treating programs as data to be fed to
general-purposelearningalgorithmshascreatedaneedformeth-
ods to efficiently extract, canonicalize, and embed artifacts derived
from programs. In this paper, we described a toolchain for effi-
ciently extracting program artifacts; a parameterized framework of
abstractionsforcanonicalizingtheseartifacts;andanencodingof
theseparameterized embeddings ina format thatcan be usedby
off-the-shelf word-vector learners.
Ourworkalsoprovidesanewbenchmarktoprobethequalityof
word-vectors learned from programs. Our ablationstudy used thebenchmarktoprovideinsightaboutwhichabstractionscontributed
themosttoourlearnedwordvectors.Wealsoprovidedevidence
that (mostly) syntactic abstractions are ill-suited as the input to
learningtechniques.Lastly,weusedthesetoolsanddatasetstolearn
a model of a specific program behavior (answering the question,
łWhich error is a trace likely to return?ž), and applied the model
inacasestudytoconfirmactualbugsfoundviatraditionalstatic
analysis.
ACKNOWLEDGMENTS
This research was supported, in part, by a gift from Rajiv and
Ritu Batra; by AFRL under DARPA MUSE award FA8750-14-2-0270
andDARPASTACawardFA8750-15-C-0082;byONRundergrant
N00014-17-1-2889;byNSFundergrantsCCF-1318489,CCF-1420866,
andCCF-1423237;andbytheUWśMadisonOfficeoftheViceChan-
cellor for Research and Graduate Education with funding from the
WisconsinAlumniResearchFoundation.Anyopinions,findings,
and conclusions or recommendations expressed in this publication
are those of the authors, and do not necessarily reflect the views of
the sponsoring agencies.
REFERENCES
[1]MiltiadisAllamanis,EarlT.Barr,ChristianBird,andCharlesSutton.2014. Learn-
ingNaturalCodingConventions.In Proceedingsofthe22NdACMSIGSOFTIn-
ternational Symposium on Foundations of Software Engineering (FSE 2014) . ACM,
NewYork, NY, USA,281ś293. https://doi.org/10.1145/2635868.2635883
[2]MiltiadisAllamanis, EarlT.Barr, ChristianBird, and CharlesSutton.2015. Sug-
gesting Accurate Method and Class Names. In Proceedings of the 2015 10th Joint
MeetingonFoundationsofSoftwareEngineering (ESEC/FSE2015) .ACM,NewYork,
NY, USA,38ś49. https://doi.org/10.1145/2786805.2786849
[3] Miltiadis Allamanis,Earl TBarr, Premkumar TDevanbu,and CharlesA Sutton.
2017. A Survey of Machine Learning for Big Code and Naturalness. CoRR
abs/1709.0(2017). arXiv: 1709.06182 http://arxiv.org/abs/1709.06182
[4]MiltiadisAllamanis,MarcBrockschmidt,andMahmoudKhademi.2017. Learning
toRepresentPrograms withGraphs. CoRRabs/1711.0 (2017). arXiv: 1711.00740
http://arxiv.org/abs/1711.00740
[5]MiltiadisAllamanis,PankajanChanthirasegaran,PushmeetKohli,andCharles
Sutton.2016. LearningContinuousSemanticRepresentationsofSymbolicEx-
pressions. arXiv preprint arXiv:1611.01423 (2016).
[6]MiltiadisAllamanis,DanielTarlow,AndrewD.Gordon,andYiWei.2015.Bimodal
Modelling of Source Code and Natural Language. In Proceedings of the 32Nd
InternationalConferenceonInternationalConferenceonMachineLearning-Volume
37 (ICML’15) . JMLR.org,2123ś2132. http://dl.acm.org/citation.cfm?id=3045118.
3045344
[7]Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2018. code2vec:
Learning Distributed Representations of Code. CoRRabs/1803.09473 (2018).
arXiv:1803.09473 http://arxiv.org/abs/1803.09473
[8]Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2018. A General Path-
basedRepresentationforPredictingProgramProperties.In Proceedingsofthe39th
ACMSIGPLANConferenceonProgrammingLanguageDesignandImplementation
(PLDI2018) .ACM,NewYork,NY,USA,404ś419. https://doi.org/10.1145/3192366.
3192412
[9]Tal Ben-Nun, Alice Shoshana Jakobovits, and Torsten Hoefler. 2018. Neural
Code Comprehension: A Learnable Representation of Code Semantics. CoRR
abs/1806.07336 (2018). arXiv: 1806.07336 http://arxiv.org/abs/1806.07336
[10]Pavol Bielik, Veselin Raychev, and Martin Vechev. 2016. PHOG: Probabilistic
ModelforCode.In Proceedingsofthe33rdInternationalConferenceonInternational
Conference on Machine Learning - Volume 48 (ICML’16) . JMLR.org, 2933ś2942.
http://dl.acm.org/citation.cfm?id=3045390.3045699
[11]P. Cousot and R. Cousot. 1977. Abstract Interpretation: A Unified Lattice Model
forStaticAnalysisofProgramsbyConstructionorApproximationofFixpoints.In
Proc.ACMSIGPLAN-SIGACTSymposiumonPrinciplesofProgrammingLanguages .
238ś252.
[12]Daniel DeFreez, Aditya V. Thakur, and Cindy Rubio-González. 2018. Path-
BasedFunctionEmbeddinganditsApplicationtoSpecificationMining. CoRR
abs/1802.07779 (2018). arXiv: 1802.07779 http://arxiv.org/abs/1802.07779
[13]V.Donzeau-Gouge,G. Huet, G. Kahn, andB.Lang.1980. Programming environ-
ments based on structurededitors: The MENTOR experience . Technical Report 26.
INRIA.
173ESEC/FSE’18,November4–9, 2018, Lake Buena Vista,FL,USA J. Henkel, S.Lahiri, B. Liblit,andT.Reps
[14]LevFinkelstein,EvgeniyGabrilovich,YossiMatias,EhudRivlin,ZachSolan,Gadi
Wolfman, and Eytan Ruppin. 2001. Placing Search in Context: The Concept
Revisited. In Proceedings of the 10th International Conference on World Wide Web
(WWW’01) .ACM,NewYork,NY,USA,406ś414. https://doi.org/10.1145/371920.
372094
[15]Jaroslav Fowkes and Charles Sutton. 2016. Parameter-free Probabilistic API
MiningAcrossGitHub.In Proceedingsofthe201624thACMSIGSOFTInternational
Symposiumon Foundations ofSoftware Engineering (FSE2016) .ACM,NewYork,
NY, USA,254ś265. https://doi.org/10.1145/2950290.2950319
[16]H. Ganzinger and N.D. Jones (Eds.). 1986. Proc. Programs as Data Objects . LNCS,
Vol. 217.
[17]XiaodongGu,HongyuZhang,DongmeiZhang,andSunghunKim.2016. Deep
APILearning.In Proceedingsofthe201624thACMSIGSOFTInternationalSym-
posiumonFoundationsofSoftwareEngineering (FSE2016) .ACM,NewYork,NY,
USA,631ś642. https://doi.org/10.1145/2950290.2950334
[18]TihomirGveroandViktorKuncak.2015.SynthesizingJavaExpressionsfromFree-
form Queries. In Proceedings of the 2015 ACM SIGPLAN International Conference
on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA
2015). ACM, New York, NY, USA, 416ś432. https://doi.org/10.1145/2814270.
2814295
[19]JordanHenkel,ShuvenduK.Lahiri,BenLiblit,andThomasReps.2018.Artifactfor
CodeVectors:UnderstandingProgramsThroughEmbeddedAbstractedSymbolic
Traces.https://doi.org/10.5281/zenodo.1297689
[20]Felix Hill, Roi Reichart, and Anna Korhonen. 2015. Simlex-999: Evaluating
Semantic Models with Genuine Similarity Estimation. Comput. Linguist. 41, 4
(Dec. 2015),665ś695. https://doi.org/10.1162/COLI_a_00237
[21]AbramHindle,EarlTBarr,ZhendongSu,MarkGabel,andPremkumarDevanbu.
2012. On the Naturalness of Software. In Proceedings of the 34th International
Conferenceon SoftwareEngineering (ICSE’12) .IEEE Press,Piscataway,NJ,USA,
837ś847. http://dl.acm.org/citation.cfm?id=2337223.2337322
[22]Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory.
Neural Comput. 9, 8 (Nov. 1997), 1735ś1780. https://doi.org/10.1162/neco.1997.9.
8.1735
[23]Tom Kenter, Alexey Borisov, and Maarten de Rijke. 2016. Siamese CBOW: Opti-
mizingWordEmbeddingsforSentenceRepresentations.In ProceedingsoftheThe
54th Annual Meeting of the Association for Computational Linguistics (ACL 2016) .
[24]QuocLeandTomasMikolov.2014. DistributedRepresentationsofSentencesand
Documents.In Proceedingsofthe31stInternationalConferenceonInternational
ConferenceonMachine Learning-Volume32 (ICML’14) .JMLR.org,IIś1188śIIś
1196.http://dl.acm.org/citation.cfm?id=3044805.3045025
[25]OmerLevyandYoavGoldberg.2014.LinguisticRegularitiesinSparseandExplicit
Word Representations.In Proceedingsof theEighteenthConferenceonComputa-
tional Natural Language Learning . Association for Computational Linguistics,
AnnArbor,Michigan,171ś180. http://www.aclweb.org/anthology/W/W14/W14-
1618
[26]YujiaLi,DanielTarlow,MarcBrockschmidt,andRichardSZemel.2015. Gated
Graph Sequence Neural Networks. CoRRabs/1511.0 (2015). arXiv: 1511.05493
http://arxiv.org/abs/1511.05493
[27]ThangLuong,RichardSocher,andChristopherDManning.2013. BetterWord
Representationswith RecursiveNeural Networks for Morphology. In CoNLL.
[28]Dirk Merkel. 2014. Docker: Lightweight Linux Containers for Consistent
Development and Deployment. Linux J. 2014, 239, Article 2 (March 2014).
http://dl.acm.org/citation.cfm?id=2600239.2600241
[29]Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
Estimation of Word Representations in Vector Space. CoRRabs/1301.3781 (2013).
arXiv:1301.3781 http://arxiv.org/abs/1301.3781
[30]TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffDean.2013.
DistributedRepresentationsofWordsandPhrasesandtheirCompositionality.
InAdvances in Neural Information Processing Systems 26 , C J C Burges, L Bottou,
MWelling,ZGhahramani,andKQWeinberger(Eds.).CurranAssociates,Inc.,
3111ś3119. http://papers.nips.cc/paper/5021-distributed-representations-of-
words-and-phrases-and-their-compositionality.pdf
[31]Changwoo Min, Sanidhya Kashyap, Byoungyoung Lee, Chengyu Song, and Tae-
sooKim.2015. Cross-checkingSemanticCorrectness:TheCaseofFindingFile
SystemBugs.In Proceedingsofthe25thSymposiumonOperatingSystemsPrin-
ciples (SOSP’15) .ACM,NewYork,NY,USA,361ś377. https://doi.org/10.1145/
2815400.2815422
[32]LiliMou,GeLi,LuZhang,TaoWang,andZhiJin.2016. ConvolutionalNeural
NetworksoverTreeStructuresforProgrammingLanguageProcessing. https:
//www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11775/11735
[33]Vijayaraghavan Murali, SwaratChaudhuri,and ChrisJermaine.2017. Bayesian
SpecificationLearningforFindingAPIUsageErrors.In Proceedingsofthe2017
11th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2017) . ACM,NewYork, NY, USA,151ś162. https://doi.org/10.1145/3106237.3106284
[34]Anh Tuan Nguyen, Hoan Anh Nguyen, Tung Thanh Nguyen, and Tien N
Nguyen. 2012. GraPacc: A Graph-based Pattern-oriented, Context-sensitive
Code Completion Tool. In Proceedings of the 34th International Conference on
Software Engineering (ICSE ’12) . IEEE Press, Piscataway, NJ, USA, 1407ś1410.
http://dl.acm.org/citation.cfm?id=2337223.2337431
[35]Anh Tuan Nguyen and Tien N. Nguyen. 2015. Graph-based Statistical Language
ModelforCode.In Proceedingsofthe37thInternationalConferenceonSoftware
Engineering - Volume 1 (ICSE ’15) . IEEE Press, Piscataway, NJ, USA, 858ś868.
http://dl.acm.org/citation.cfm?id=2818754.2818858
[36]Trong Duc Nguyen, Anh Tuan Nguyen, and Tien N. Nguyen. 2016. Mapping
API Elements for Code Migration with Vector Representations. In Proceedings of
the 38thInternational Conference on SoftwareEngineeringCompanion (ICSE’16) .
ACM,NewYork, NY, USA,756ś758. https://doi.org/10.1145/2889160.2892661
[37]TrongDucNguyen,AnhTuanNguyen,HungDangPhan,andTienNNguyen.
2017. Exploring API Embedding for API Usages and Applications. In Proceedings
ofthe39thInternationalConferenceonSoftwareEngineering (ICSE’17) .IEEEPress,
Piscataway, NJ, USA,438ś449. https://doi.org/10.1109/ICSE.2017.47
[38]TungThanhNguyen,AnhTuanNguyen,HoanAnhNguyen,andTienN.Nguyen.
2013. A Statistical Semantic Language Model forSource Code. In Proceedings of
the20139thJointMeetingonFoundationsofSoftwareEngineering (ESEC/FSE2013) .
ACM,NewYork, NY, USA,532ś542. https://doi.org/10.1145/2491411.2491458
[39]Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong
Zhou, and Pushmeet Kohli. 2016. Neuro-Symbolic Program Synthesis. CoRR
abs/1611.0(2016). arXiv: 1611.01855 http://arxiv.org/abs/1611.01855
[40]Hao Peng, Lili Mou, Ge Li, Yuxuan Liu, Lu Zhang, and Zhi Jin. 2015. Building
Program Vector Representations for Deep Learning. In Proceedings of the 8th
International Conference on Knowledge Science, Engineering and Management -
Volume9403 (KSEM2015) .Springer-VerlagNewYork,Inc.,NewYork,NY,USA,
547ś553. https://doi.org/10.1007/978-3-319-25159-2_49
[41]JeffreyPennington,RichardSocher,andChristopherDManning.2014. GloVe:
GlobalVectorsforWordRepresentation.In EmpiricalMethodsinNaturalLan-
guage Processing (EMNLP) . 1532ś1543. http://www.aclweb.org/anthology/D14-
1162
[42]Chris Piech, Jonathan Huang, Andy Nguyen, Mike Phulsuksombati, Mehran
Sahami,andLeonidasGuibas.2015. LearningProgramEmbeddingstoPropagate
FeedbackonStudentCode.In Proceedingsofthe32NdInternationalConferenceon
InternationalConference onMachineLearning-Volume 37 (ICML’15) . JMLR.org,
1093ś1102. http://dl.acm.org/citation.cfm?id=3045118.3045235
[43]Michael Pradel and Koushik Sen. 2017. Deep Learning to Find Bugs . Technical
ReportTUD-CS-2017-0295.TechnischeUniversitätDarmstadt,Departmentof
Computer Science.
[44]Mukund Raghothaman, Yi Wei, and Youssef Hamadi. 2016. SWIM: Synthesizing
What I Mean: Code Search and Idiomatic Snippet Synthesis. In Proceedings of
the38thInternationalConferenceonSoftwareEngineering (ICSE’16) .ACM,New
York, NY, USA,357ś367. https://doi.org/10.1145/2884781.2884808
[45]Veselin Raychev, Martin Vechev, and Andreas Krause. 2015. Predicting Program
Propertiesfrom"BigCode". Popl(2015).https://doi.org/10.1145/2676726.2677009
[46]VeselinRaychev,MartinVechev,andEranYahav.2014. CodeCompletionwith
StatisticalLanguageModels.In Proceedingsofthe35thACMSIGPLANConference
on Programming Language Design and Implementation (PLDI ’14) . ACM, New
York, NY, USA,419ś428. https://doi.org/10.1145/2594291.2594321
[47]Herbert Rubenstein and John B Goodenough. 1965. Contextual Correlates of
Synonymy. Commun.ACM 8,10(Oct.1965),627ś633. https://doi.org/10.1145/
365628.365657
[48]SeanSzumlanski,FernandoGomez,andValerieKSims.2013. Anewsetofnorms
for semantic relatedness measures. In Proceedings of the 51st Annual Meeting
oftheAssociationforComputationalLinguistics(Volume2:ShortPapers) ,Vol.2.
890ś895.
[49]Ke Wang, Rishabh Singh, and Zhendong Su. 2017. Dynamic Neural Program
EmbeddingforProgramRepair. CoRRabs/1711.07163(2017). arXiv: 1711.07163
http://arxiv.org/abs/1711.07163
[50]SongWang,DevinChollak,DanaMovshovitz-Attias,andLinTan.2016. Bugram:
BugDetectionwithN-gramLanguageModels.In Proceedingsofthe31stIEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering (ASE2016) .ACM,
NewYork, NY, USA,708ś719. https://doi.org/10.1145/2970276.2970341
[51]XYe,HShen,XMa,RBunescu,andCLiu.2016. FromWordEmbeddingstoDoc-
umentSimilarities for Improved Information Retrievalin SoftwareEngineering.
In2016IEEE/ACM38thInternationalConferenceonSoftwareEngineering(ICSE) .
404ś415. https://doi.org/10.1145/2884781.2884862
[52]Geoffrey Zweig and Chris J C Burges. 2011. The Microsoft Research Sentence
Completion Challenge . Technical Report. https://www.microsoft.com/en-us/
research/publication/the-microsoft-research-sentence-completion-challenge/
174