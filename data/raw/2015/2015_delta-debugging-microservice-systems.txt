Delta Debugging Microservice Systems
Xiang Zhou∗
Fudan University
ChinaXin Peng∗†
Fudan University
ChinaTao Xie
University of Illinois at
Urbana-Champaign
USA
Jun Sun
Singapore University of Technology
and Design
SingaporeWenhai Li∗
Fudan University
ChinaChao Ji∗
Fudan University
China
Dan Ding∗
Fudan University
China
ABSTRACT
Debugging microservice systems involves the deployment and ma-
nipulationofmicroservicesystemsonacontainerizedenvironment
and faces unique challenges due to the high complexity and dy-
namismofmicroservices.Toaddressthesechallenges,inthispaper,
we propose a debugging approach for microservice systems based
on the delta debugging algorithm, which is to minimize failure-
inducing deltas of circumstances (e.g., deployment, environmental
configurations) for effective debugging. Our approach includes
novel techniques for defining, deploying/manipulating, and exe-
cutingdeltasfollowingtheideaofdeltadebugging.Inparticular,
toconstructa(failing)circumstancespacefordeltadebuggingto
minimize, our approach defines a set of dimensions that can affect
the execution of microservice systems. Our experimental study
on a medium-size microservice benchmark system shows that our
approachcaneffectivelyidentifyfailure-inducingdeltasthathelp
diagnose the root causes.
CCS CONCEPTS
•Software and its engineering →Cloud computing ;Soft-
ware testing and debugging;
KEYWORDS
Microservice, Delta Debugging, Testing
∗X.Zhou,X.Peng,W.Li,C.Ji,andD.DingarewiththeSchoolofComputerScienceand
Shanghai Key Laboratory of Data Science, Fudan University, China and the Shanghai
Institute of Intelligent Electronics & Systems, China.
†X. Peng is the corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3240730ACM Reference Format:
Xiang Zhou, Xin Peng, Tao Xie, Jun Sun, Wenhai Li, Chao Ji, and Dan Ding.
2018.DeltaDebuggingMicroserviceSystems.In Proceedingsofthe201833rd
ACM/IEEEInternationalConferenceonAutomatedSoftwareEngineering(ASE
’18), September 3–7, 2018, Montpellier, France. ACM, New York, NY, USA,
6pages.https://doi.org/10.1145/3238147.3240730
1 INTRODUCTION
Beyondtheimplementationsofindividualmicroservices,manyfail-
uresofmicroservicesystemsareduetotheirruntimeenvironments
(e.g.,containers),communications,orcoordinations[ 19].Therefore,
debuggingafailureinmicroservicesystemsfacesuniquechallenges
due to the high complexity and dynamism of microservices in four
dimensions: node, instance,configuration, and sequence. First, nu-
merousmicroserviceinstancesrunonalargenumberof nodes(e.g.,
physicalorvirtualmachines)andthedistributionofmicroservice
instances over nodes is constantly changing, bringing great uncer-
tainties to microservice communication. Second, the instances of a
microservicemaybeininconsistentstatesandthusbehavediffer-
ently. Third, microservice systems involve complex environmental
configurations suchasmemory/CPUlimitsofmicroserviceandcon-
tainers,andimproperorinconsistentenvironmentalconfigurations
mayincurruntimefailures.Fourth,microserviceinvocationsare
executed or returned in an unexpected sequence due to the use
of asynchronous invocations (via REST invocations or message
queues).
Toaddresstheprecedingchallenges,inthispaper,wepropose
anapproachfordebuggingmicroservicesystems,basedonrepre-
senting microservice system settings as circumstances (specified
fromvariousdimensions)suchasmulti-nodeandmulti-instance
deployment.Suchrepresentationenablesustoconductdeltadebug-ging[
18],atechniqueforsimplifyingorisolatingfailurecauses(e.g.,
searching for minimum failure-inducing circumstances) among all
circumstances. During delta debugging, a series of delta testing
tasks are created to run the test cases with different circumstances.
Note that the execution of delta testing tasks consumes numer-
ous resources (e.g., virtual machines) and involves complex setting
of thedeployment, environmental configurations, andinteraction
sequences of microservice instances.
802
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiang Zhou, Xin Peng, Tao Xie, Jun Sun, Wenhai Li, Chao Ji, and Dan Ding
Ourapproachincludestwomaintechniquestoaddressachal-
lenging requirement for delta debugging microservice systems:
high efficiency of executing delta testing tasks. In particular, toautomate the testing of deltas, our approach includes the design
ofaninfrastructurelayer(witheasy-to-useAPIs)forautomating
deploymentandmanipulationofmicroservicesystems.Thisinfras-
tructurelayerisbasedontheexistinginfrastructureofcontainer
orchestrationandservicemesh.Tooptimizethedeltadebugging
process, our approach includes the design of parallel execution for
delta testing tasks. Our experimental study on a medium-size open
microservice benchmark system [ 19] shows that our approach can
effectively identify failure-inducing deltas that help identify the
root causes.
2 BACKGROUND
Our work is enabled by recent advances in infrastructures and
runtimemanagementof microservices.Suchadvancesallow usto
manipulate the runtime deployment, configuration, and interac-
tions of microservice systems as required to test the target system
with different settings.
Industrialmicroservicesystemsusuallyrelyonruntimeinfras-
tructures for automating deployment, scaling, and management.
Kubernetes [ 9] is the most widely used runtime infrastructure for
microservicesystems.Itsupportstheconfigurationmanagement,
service discovery, service registry, and load balancing of microser-
vice systems.
The rise of cloud native applications such as microservice-based
ones promotes the introduction of service mesh [ 11] as a separate
layer for handling service-to-service communication. Istio [ 8]i s
the most recognized implementation of service mesh for microser-
vices. It supports managing traffic flows between microservices,
enforcing access policies, and aggregating telemetry data. Istio can
bedeployedonKubernetes.Theyarecombinedtoprovidethere-
quiredinfrastructurefortheruntimemanagementofmicroservices
in our work.
3 APPROACH OVERVIEW
Our delta debugging approach for microservice systems can be
usedwhenasetoftestcasesareexecutedonamicroservicesystemusingthesameconfiguration,andatleastoneofthetestcasesfails.
The approach needs to be run on a containerized environment, al-
lowingtheapproachtotestthetargetsystemwithdifferentsettings.
Figure1shows an overview of the approach.
The approach includes an infrastructure layer (gray boxes) that
automatesthedeploymentandmanipulationofmicroservicesys-
tems. The infrastructure layer is built on existing container orches-
tration platforms (e.g., Kubernetes) and service mesh platforms
(e.g.,Istio)formicroservices.Wedevelopaninfrastructurewrap-
per to provide easy-to-use APIs for applying our delta-debugging
approach.
Based on the infrastructure layer, the approach takes as input
asetoftestcases(includingafailingoneandsomepassingones)
and a failure-inducing circumstance, and returns a minimum set of
deltasthatcausethefailure.Inparticular,acircumstanceisdefinedbasedonvariousdimensions(seeSection 4.1).Thefailure-inducing
circumstance is the circumstance extracted from the execution
Figure 1: Approach Overview
of the failing test case. The returned deltas specify a minimumset of differences on the failure-inducing circumstance that can
changethetestingresultofthefailingtestcaseandatthesametimemaintain the testing results of the passing test cases. The approach
includes three components: the delta debugging controller, task
scheduler, and task executor.
Delta DebuggingController. Thedeltadebuggingcontroller
controlsthewholedeltadebuggingprocess.Itfirstconfirmsthat
the failing test case can pass with the simplest circumstance, theone where the value of each dimension is the simplest setting. It
then uses the delta debugging algorithm to iteratively search for a
minimumsetofdeltasofthesimplestcircumstancetomakethetestcasefail.Duringtheprocess,thecontrollertestsaseriesofdeltasetsandforeachdeltasetitcreatesadeltatestingtaskthatrunsthetest
caseswiththecircumstanceobtainedbyapplyingthedeltasetto
thesimplestcircumstance.Tooptimizethedeltadebuggingprocess,
thecontrollerdynamicallydeterminesthedeltatestingtasksthat
needtobeexecuted,andnotifiesthetaskscheduler(describednext)
to add or revoke tasks.
Task Scheduler. The task scheduler schedules the execution
of delta testing tasks based on the availability of infrastructureresources (e.g., virtual machines). It maintains a queue of delta
testing tasks, andadds or revokes tasks according tonotifications
from the delta debugging controller. The scheduler monitors theresource availability of the infrastructure and schedules tasks to
execute when the required resources are available.
Task Executor. The task executor executes a scheduled delta
debugging task on the infrastructure. The executor uses the in-frastructure APIs to deploy the target system with the allocatedresources and set the environmental configurations and interac-
tionsofinvolvedmicroservicesaccordingtothegivencircumstance.
Then the executor runs the test cases and returns test results for
further analysis.
The delta debugging controller is the key of the approach and is
presented in details in Section 4.
4 DELTA DEBUGGING CONTROLLER
Ourdeltadebuggingapproachformicroservicesystemsisdesignedtoaddressuniquecharacteristicsofmicroservices.Inparticular,thecircumstances(eachofwhichisspecifiedfromfivedimensions)andcorrespondingdeltasconsideredinourapproachreflectthedeploy-
ment,environmental configurations,andinteraction sequencesof
microservices.
4.1 Dimensions
In general, delta debugging determines circumstances that are rel-
evantforproducingafailure[ 18].Foramicroservicesystem,the
803
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. Delta Debugging Microservice Systems ASE ’18, September 3–7, 2018, Montpellier, France
relevant circumstances include not only the inputs but also the
deployment, environment, and interactions of microservices. A
circumstance can be specified from the following five dimensions.
•Node. The node dimension specifies the number of nodes
(e.g.,physicalorvirtualmachines)thatcanbeusedbythe
targetsystem.Themorenodesthatareprovided,themore
distributedtheinstancesofthesamemicroserviceare.The
distributed deployment of the instances of a microservice
leads to uncertainties in the network communicationswith
the microservice, thus incurring failures caused by unex-
pected network failures or timeout.
•Instance .Theinstancedimensionspecifiesthenumberof
instancesofamicroservice.Somemicroserviceshaveexplic-
itly or implicitly defined states. For example, a microservice
may store some critical variables in local or remote cache.
Withoutpropercoordination,differentinstancesofthesame
microservice may be in inconsistent states, thus causing
failures.
•Configuration .Theconfiguration dimensionspecifiesthe
environmental configurations of a microservice, such as the
network configurations and resource (e.g., memory, CPU)
limits of microservices or containers. For example, inconsis-
tent configurations of the memory limit of a microservice
instance and that ofa container where the instance resides
may cause the instance to be killed when its memory usage
exceeds the memory limit of the container.
•Sequence . The sequence dimension specifies the execution
andreturningsequenceofmicroserviceinvocations.Forase-ries of asynchronous invocations, the sequence of execution
and returning of the invoked microservices is often varying
and not consistent with the sequence of requesting. With-
out proper coordination, the asynchronous invocations may
incur unexpected sequences of microservice execution or
returning, which in turn cause failures.
•Input. The input dimension determines the input of a mi-
croservice system. Its influence on a microservice system is
similar to the influence of input on an ordinary C program.
Currently we focus on the first four dimensions for reflecting
amicroservicesystem’scharacteristics.Theinputdimensioncan
be handled in a way similar to the original delta debugging ap-proach [
18]. Acircumstance is a specific combination of the four
dimensionsinvolvedintestexecution.Thedifferencesbetweentwo
circumstances are the deltas. The purpose of delta debugging is to
isolatetheminimumsetoffailure-inducingdeltaswithreferencetothe simplest circumstance. Table 1shows the values of each dimen-
sioninitssimplestsettinganditsgeneralsetting.Forthefirstthree
dimensions,thesimplestsettingis1orthedefaultvalue,andthe
generalsettingcanbethevaluesfromthegivenfailure-inducing
circumstance (i.e., the circumstance derived from the given failing
test case). For example, a microservice has 5 instances in the given
failure-inducing circumstance, and then its instance number is 1
in the simplest setting and the general setting can be 5. For the se-
quencedimension,theexecutionandreturningsequenceofaseries
of asynchronous invocations is exactly the requesting sequence of
the invocations in the simplest setting, and the general setting can
be any other sequences of the invocations. For example, if threemicroservices are invoked asynchronously in a sequence of S1,S2,
S3, then their execution and returning sequence in the simplest
setting is also S1,S2,S3, and thegeneral setting can be any other
sequence of S1,S2,S3(e.g., S3,S2,S1).
4.2 Circumstance and Delta Representation
Acircumstanceisrepresentedasabitvectorthatincludesoneor
multiplebitstospecifywhatvaluetoadoptforeachdimension.Forthenodedimension,abitisusedtoindicatethenumberofnodesofthewholesystem:0foradoptingthesimplestsetting(i.e.,onlyone
node) and 1 for adopting the number of nodes in the given failure-
inducingcircumstance.Fortheinstancedimension,multiplebits
are used each indicating the number of instances of a microservice:0foradoptingthesimplestsetting(i.e.,onlyoneinstance)and1for
adopting the number of instances of the microservice in the given
failure-inducing circumstance. For the configuration dimension,
multiple bits are used each indicating the value of a configuration
item:0foradoptingthesimplestsetting(i.e.,thedefaultvaluebeing
predefined) and 1 for adopting the value of the configuration item
in the given failure-inducing circumstance.
For the sequence dimension, multiple bits are used to represent
the execution/returning sequence of a series of asynchronous invo-
cations, and each bit indicates the order of a pair of invocations: 0
(1)fortheorderthatthefirst(second)invocationisexecutedand
returned before the second (first) one. Therefore, for nasynchro-
nous invocations, C2nbits are needed to represent the setting of
execution/returningsequence.Figure 2showsanexampleofthe
representation of execution/returning sequence. In this example, a
microservice MS1asynchronously invokes a series of microservice
MS2,MS3,MS4, and MS5, and 6 ( C2
4) bits are used to capture the
execution/returningsequenceoftheseinvocations.Ifthefourmi-
croservicesareinvokedintheordershowninFigure 2,thesimplest
setting of execution/returning sequence for this series of asynchro-
nous invocations is [0, 0, 0, 0, 0, 0] based on the pairs defined inthe figure. Note that some value combinations of the bits are in-
validasthesecombinationsimplycyclesintherelativeordersof
microservice invocations. For the example shown in Figure 2, [0, 1,
0,0,0,0]isaninvalidexecution/returningsequenceasthereisa
cycle among MS2,MS3, and MS4.
Based on the representation, the simplest circumstance (i.e., the
onewitheachdimensioninthesimplestsetting)canberepresentedbyabitvectorwhereeachbitissetto0.Thus,anatomicdeltabased
on the simplest circumstance can be represented by a change from
0to1forabitofthevector,andthepurposeofourdeltadebugging
process is to find a minimum set of atomic deltas that cause the
failure of a test case.
Notethattherepresentationsofthefirstthreedimensions(i.e.,
node, instance, configuration) can be refined to represent more
values. For example, the number of nodes can be any value be-
tween 1 and the number of nodes in the given failure-inducing
circumstance. Toreduce thehigh costof deltadebugging, wecon-
sider only the simplest setting and the general setting from the
given failure-inducing circumstance. This strategy can reveal criti-
caldeltasinmanycases.Notethatforthesequencedimension,our
representationcancoverallthepossibleexecutionandreturning
sequences.
804
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiang Zhou, Xin Peng, Tao Xie, Jun Sun, Wenhai Li, Chao Ji, and Dan Ding
Table 1: Values of Different Dimensions in a Circumstance
Dimension Target Simplest Setting General Setting
Node the whole system 1 the number of nodes in the given failure-inducing circumstance
Instance a microservice 1 the number of its instances in the given failure-inducing circumstance
Configuration a configuration item the default value its value in the given failure-inducing circumstance
Sequence a series of asynchronous invocations the requesting sequence of the invocations any other sequences of the invocations
Figure 2: Representation of Execution/Returning Sequence
4.3 Delta Debugging Algorithm
Our delta debugging process starts with the confirmation of the
testingresultwiththesimplestcircumstance.Accordingtothesim-
plestcircumstance,allthemicroservicesaredeployedononenode;
each microservice has only one instance; all the environmentalconfiguration is set to its default value (e.g., unlimited memory);all the asynchronous microservice invocations are executed andreturned by the same orders of requests. If the given failing testcase still fails with the simplest circumstance, the failure can be
thoughttobecausedbyinternalfaultsofrelatedmicroservices,and
furtheranalysisoftherootcausecanbesupportedbytraditional
debuggingapproaches.Otherwise,thesimplestcircumstancecan
be used as the base for delta debugging.
Given the large number of deltas in a microservice system, our
aim is to identify a minimum set of deltas such that applying the
deltastothesimplestcircumstancecausesthefailingtestcaseto
producefailingresultsandatthesametimecausesthepassingtest
casestomaintain passingresults.Intheidealcase,theminimum
setcontains1delta,whichcanhelpthedevelopersidentifytherootcauseofthefailure.Theminimizingdeltadebuggingalgorithm[
18]
isavariantoftheoriginaldeltadebuggingalgorithm[ 16],which
can be applied to solve our problem. Next, we first present the
details on the delta debugging algorithm and then discuss how we
apply it in our setting.
Givenafailure-inducingcircumstance fcandthesimplestcir-
cumstance sc,letU/primebeasetofatomicdeltasbetweencircumstance
fcandsc. Inother words, applying alldeltas in U/primetoscresults in
fc.In thesequence dimension,multiple bitsareused torepresent
the sequence of a series of asynchronous invocations, and thus we
needtousetheunionof U/primeandthesetofalltheatomicdeltasin
thebitsforsequencerepresentationastheuniversalsetofdeltas,
represented as U.
Lettest (K)where K⊆Ube the testingresults of the testcases
with the circumstances obtained by applying Ktosc. We have
test (∅)=/checkwhere/checkindicates that all the test cases pass and
test (U)=×where×indicates that the failing test case fails in the
same way of the initial failure and the passing test cases pass. It
ispossiblethat test (K)forasubset Kresultsinanunknowncase
test (K)=?,where?indicatesthatthefailingtestcasefailsinother
waysorsomepassingtestcasesfail.Formally,thegoalistoidentify
a subset of U, say N, such that test (N)=×andNis 1-minimal,
i.e.,test (N/prime)=/checkfor all N/prime⊆Nand|N/prime|=|N|−1 where|X|is
thecardinalityofset X.Intuitively,inotherwords,wewouldlike
tofindasetofdeltas Nsuchthattakingawayanyoneofthedeltas
can change the testing result.
Figure3showsthedetailsofthealgorithm,denotedas ddmin (X,n),
withtwoinputs.Oneisasetofdeltasdenotedas X.Initially Xis1: partition Xintonequal subsets/triangle1,···/triangle n;
2:foreach subset/triangleido
3:iftest (/trianglei)=×then
4: return ddmin (/trianglei,2);
5:end if
6:end for
7:foreach subset/triangleido
8:iftest (X\/trianglei)=×then
9: return ddmin (X\/trianglei,max (n−1,2));
10:end if
11:end for
12:ifn<|X|then
13:return ddmin (X,min (|X|,2n));
14:end if
15:return X;
Figure 3: DDMin Algorithm: ddmin (X,n)
settobe U.Theotherisagranularity,denotedas n,forpartition
usedinthealgorithm.Initially,itissettobe2.AtLine1ofthealgo-
rithm, we partition the set of deltas Xintonequal-sized partitions
/triangle1,···,/trianglen. Afterwards, we distinguish four cases.
•Reduce to subset. If there exists a partition /triangleisuch that
test (/trianglei)fails,weknowthat /triangleiisfailure-inducing.Insuch
case,wemakearecursivecall ddmin (/trianglei,2)sothatwepro-
ceed to reduce/triangleifurther. This case yields a “divide and
conquer” approach.
•Reduce to complement. Otherwise, if there exists a parti-
tion/triangleisuch that its complement X\/triangleiis failure-inducing,
i.e.,test (X\/trianglei)fails, we make a recursive call ddmin (X\
/trianglei),max (n−1,2))so that we proceed to reduce X\/triangleifur-
ther.Notethatthesecondparameterissettobe n−1sothat
the granularity is not reduced.
•Increasegranularity. Otherwise,ifwecanincreasethegranu-
larity(i.e., n<|X|),werecursivelycall ddmin (X,min (|X|,2n))
sothatwecananalyzethedeltasin Xwithafiner-grained
manner.
•Done.Otherwise,wereturn Xaswecannotreduce Xfurther.
The ddminalgorithm is designed to reduce the deltas in a way
similar to binary search and thus is reasonably efficient (e.g., more
efficient compared to the original delta-debugging algorithm [ 16]).
We refer the readers to [ 18] for detailed discussion on the cor-
rectness and complexity of the algorithm. Note that the preceding
algorithmassumesthatdeltasareindependentofeachother,andit
is known [ 18] that partitioning related deltas in the same partition
improves the efficiency of the algorithm.
5 EVALUATION
We conduct an experimental study to evaluate the effectiveness of
our approach.
5.1 Settings
We implement our approach itself as a microservice system (in-
cluding the delta debugging controller, task scheduler, and taskexecutor) running on a containerized environment. We conduct
thestudybasedonamedium-sizeopenbenchmarkmicroservice
805
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. Delta Debugging Microservice Systems ASE ’18, September 3–7, 2018, Montpellier, France
systemnamedTrainTicket[ 19](with41microservicesreflecting
real-world industrial practices) after adapting it to the implementa-
tion of our infrastructure layer. The environment used in the study
includes 13 virtual machines (VMs) provided by a private cloud of
FudanUniversity.EachVMhasa8-coreCPU(IntelXEON3GHz)
and24GBmemory,andCentOS7installedastheoperatingsystem.
One of the VMs is used to run our microservice debugging system.
5.2 Results
Weconductanexperimentalstudythatusestheapproachtodebug
realmicroservicefailures.ThebenchmarksystemTrainTicketin-
cludes 11 representativefault cases that are replicatedfrom indus-
trial fault cases identified through an industrial survey. Among the
11 fault cases, we choose 3 fault cases that are related to deploy-
ment, environmental configurations, or asynchronous interactions,
asshowninTable 2.The3faultcasescorrespondtoadimension
(i.e., instance, configuration, or sequence), respectively.
Weincorporatetheimplementationsofthe3faultcasesintothe
benchmarksystem.Foreachfaultcase,weusethecorresponding
testcasesprovidedbythebenchmarksystemtorunthesystemand
produceafailure.Weperformadeltadebuggingprocessforeach
faultcasewiththemultiple-clustersetting:12VMsaredividedinto
6clustersandeachclusterhas2VMs.Werecordandanalyzethe
deltadebuggingprocessforeachfaultcaseandobtaintheresultsas
shown in Table 3. For each fault case, the table reports the number
ofdeltasintheuniversalset(#Delta(U)),thenumberofdeltasinthe
returned delta set (#Delta (R)), the number of tasks created during
the process (#Task (C)), the number tasks scheduled to execute
(#Task (S)), the number of tasks finished (#Task (F)), the time used
(Time), and the indication of the returned deltas. It can be seen
thatthesefaultcasesinvolve36-63deltasandthereturnedresult
includes1-2deltas.Thewholedeltadebuggingprocessneeds18-30
minutes to finish. During the process, 32-41 delta testing tasks are
created, 20-26 ofthem are scheduled to execute,and 8-12 of them
finish their executions.
To confirm the effectiveness of the approach, we analyze the re-
turneddeltasforeachfaultcase.Wefirstunderstandtheindication
ofthereturneddeltasandthenexaminewhethertherootcauses
can be identified based on the deltas.
For F1, the returned delta indicates that the failure is induced
by the multi-instance deployment of a microservice. The delta
accuratelyrevealsthecircumstancedeltathatinducesthefailure.
Basedontheindication,thedevelopersneedtofurthercheckthe
states of the microservice to identify the root cause.
For F2, the returned delta indicates that the failure is induced
by the memory limit of a microservice. Actually the fault involves
the improper memory limitsof multiple microservices and any of
them can cause a failure. The delta reveals the problem of memory
limitsetting ofone ofthe microservices.Basedon theresult, the
developerscansoonidentifytherootcauseofonemicroservice,and
subsequently identify the root causes of the other microservices,
e.g., by iteratively performing the delta debugging process.
ForF3,thereturned2deltasindicatethatthefailureisinduced
bythe ordersof twopairs ofasynchronousinvocations, say( MS1,
MS2)and( MS1,MS3).Therealcauseofthisfailureisonlytheorder
ofthepair( MS1,MS3).Inthiscase,thesimplestcircumstanceforthesequenceis <MS1,MS2,MS3>andthegivenfailure-inducing
circumstanceis <MS2,MS3,MS1>.Theorderbetween MS1and
MS2, and the order between MS1and MS3are included in the
returned deltas as they aredifferent inthe twocircumstances, but
the failure is induced by only the order between MS1andMS3.I n
this case, the right failure-inducing delta (i.e., the order between
MS1andMS3)isincludedinthereturneddeltas,andthedevelopers
need to eliminatethe other returned delta (i.e., the orderbetween
MS1andMS2) by further analyzing the data.
Fromthe precedinganalysis,wecan seethatourapproach can
effectively perform a delta debugging process, and can identify
failure-inducingdeltasofdifferentdimensionsforhelpingdiagnose
the root causes:
1.Instancedeltasusuallycanaccuratelyindicatethemulti-instance-
deployment problems of microservices. The developers need to
further analyze the states of the microservices to identify the root
causes.
2.Configuration deltascan identifythe configurationproblems
of some microservices but may miss the same problems of other
microservices.Thedevelopersneedtoiterativelyperformthedelta
debugging process to identify the problems of more microservices.
3. Sequence deltas can identify the pairs of microservice invo-
cationsthatinducethefailurebutmayincludeirrelevantpairsof
invocationsinthesamesequence.Thedevelopersneedtofurther
confirm the pairs involved in the deltas to identify the root causes.
5.3 Threats to Validity
Themajorthreatstotheexternalvalidityofourstudylieintherep-
resentativeness of the benchmark system, failure cases, and testing
environmentusedinourstudy.Althoughthebenchmarksystem
isthelargestamongevaluationsubjectsformicroservicesystems
in the researchliterature, it is smaller andless complex than large
industrialmicroservicesystems.Althoughtheusedfailurecasesare
derivedfromrealindustrialcases,thesefailurecasesmaybeless
complexthanvariousfailurecasesinindustrialsystems.Therefore,
the results of our experimental study may not be generalized to
more complex systems, failure cases, or testing environments.
A major threat to the internal validity of our study lies in the
uncertainties of the testing environment used in the study. Theenvironment consists of virtual machines provided by a private
cloud,andthe performanceandreliabilityof thevirtualmachines
areuncertain,thusmakingthedata(e.g.,debuggingtime)collected
from the environment likely inaccurate.
6 RELATED WORK
Delta Debugging. Ourworkisanextensionofexistingworkon
debugging,particularly,deltadebugging.Deltadebuggingispro-
posed for traditional monolithic systems. Zeller et al.[16] propose
deltadebuggingforsimplifyingandisolatingfailure-inducingin-
puts. Since then, there have been many extensions. For example,
it is extended toisolate cause-effect chains from programsby con-
trastingprogramstatesbetweensuccessfulandfailedexecutions
in [17,18]. Cleveet al.[4] extend delta debugging to identify the
locations and times where the cause of a failure changes from one
variable to another. Sumner et al.[12,13] improve delta debugging
in its precision and efficiency by combining it with more precise
806
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Xiang Zhou, Xin Peng, Tao Xie, Jun Sun, Wenhai Li, Chao Ji, and Dan Ding
Table 2: Fault Cases Used in the Evaluation
Fault Description Dimension
F1 Amicroserviceinvocationchaininvolvestwoinvocationsofthesamemicroservice,buttheinvocationsareservedbytwomicroserviceinstancesin
different states.Instance
F2 JVM’smaxmemoryconfigurationconflictswithDocker cluster’smemorylimitationconfiguration. As aresult,Dockersometimeskillsthe JVMprocess. Configuration
F3 A series of asynchronous microservice invocations are returned in an unexpected order. Sequence
Table 3: Evaluation Results
Fault #Delta (U) #Delta (R) #Task (C) #Task (S) #Task (F) Time Indication of Returned Deltas
F1 36 1 32 20 1030 mthe multi-instance deployment of a microservice
F2 63 1 36 23 818 mthe memory limit of a microservice
F3 43 2 41 26 1229 mthe orders of two pairs of asynchronous invocations
executionalignmenttechniques.Acauseinferencemodel[ 14]is
also proposed to provide a systematic way of explaining the differ-
ence between a failed execution and a successful execution. Burger
etal.[3]propose anapproachcalled JINSIthatcombines deltade-
bugginganddynamicslicingforeffectivefaultlocalization.JINSI
can reduce the number of method calls and returns to the mini-
mum number required to reproduce a failure. Misherghi et al.[10]
propose hierarchical delta debugging tospeedup delta debugging
by considering hierarchical constraints in the system under debug-
ging. Recently, it is further extended to coarse hierarchical delta
debugging[ 7].Multipletools(e.g.,[ 15])havealsobeendevelopedto
supportdeltadebugging.Theprecedingapproachesarealldesigned
fordeltadebuggingtraditionalmonolithicsystems.Asdiscussed
earlier,theseexistingdelta-debuggingapproachesareineffective
formicroservicesduetotheuniquecharacteristicsofmicroservices
(i.e., unique deltas and ways of constructing and executing delta
testing tasks).
Microservice Analysis. Our work is also related to existing
workonanalyzingmicroservicesystems.Francesco etal.[6]present
a systematic study on the state of the art on microservice architec-
tures from three perspectives: publication trends, focus of research,
and potential for industrial adoption. One of their conclusions is
thatresearchonarchitectingmicroservicesisstillinitsinitialphase
andthe balancedinvolvement ofindustrial andacademicauthors
is promising. Alshuqayran et al.[2] present a study on architec-
turalchallengesofmicroservicesystems,thearchitecturaldiagrams
used for representing them, and the involved quality requirements.
Dragoniet al.[5] review the development history from objects,
services, to microservices, present the current state of the art, and
raisesomeopenproblemsandfuturechallenges.Carlos etal.[1]
present an initial set ofrequirements for a candidate microservice
benchmark system to be used in research on software architecture.
Withinthebestofourknowledge,thereexistsnopreviousresearch
on systematic debugging dedicated to microservices, as focused by
our work.
7 CONCLUSION
In this paper, we have proposed a delta debugging approach for
microservice systems with the objective of minimizing failure-
inducing deltas of circumstances (e.g., deployment, environmental
configurations,orinteractionsequences)foreffectivedebugging.
Ourapproachincludesnoveltechniquesfordefining,manipulating,
andexecutingdeltasduringdeltadebugging.Ourevaluationcon-
firms that our approach can effectively identify failure-inducing
deltas that help diagnose the root causes.ACKNOWLEDGMENTS
This work was supported by the National Key Research and Devel-
opmentProgramofChinaunderGrantNo.2018YFB1004803.Tao
Xie’s work was supported in part by National ScienceFoundation
under grants no. CNS-1513939 and CNS-1564274.
REFERENCES
[1]Carlos M. Aderaldo, Nabor C. Mendonca, Claus Pahl, and Pooyan Jamshidi.
2017. Benchmark Requirements for Microservices Architecture Research. InProc. IEEE/ACM International Workshop on Establishing the Community-Wide
Infrecaseructure for Architecture-Based Software Engineering (ECASE’17). 8–13.
[2]Nuha Alshuqayran, Nour Ali, and Roger Evans. 2016. A Systematic MappingStudy in Microservice Architecture. In Proc. IEEE International Conference on
Service-Oriented Computing and Applications (SOCA’16). 44–51.
[3]Martin Burger and Andreas Zeller. 2011. Minimizing Reproduction of Software
Failures.In Proc.InternationalSymposiumonSoftwareTestingandAnalysis(IS-
STA’11). 221–231.
[4]Holger Cleve and Andreas Zeller. 2005. Locating Causes of Program Failures. In
Proc. International Conference on Software Engineering (ICSE’05). 342–351.
[5]NicolaDragoni,SaverioGiallorenzo,AlbertoLluch-Lafuente,ManuelMazzara,
FabrizioMontesi,RuslanMustafin,andLarisaSafina.2016. Microservices:Yes-
terday, Today, and Tomorrow. CoRRabs/1606.04036 (2016).
[6]Paolo Di Francesco, Ivano Malavolta, and Patricia Lago. 2017. Research on
Architecting Microservices: Trends, Focus, and Potential for Industrial Adoption.
InProc. IEEE International Conference on Software Architecture (ICSA’17) . 21–30.
[7]Renáta Hodován, Ákos Kiss, and Tibor Gyimóthy. 2017. Coarse Hierarchical
Delta Debugging. In Proc. IEEE International Conference on Software Maintenance
and Evolution (ICSME’17). 194–203.
[8] Istio. 2018. Istio. Retrieved February 21, 2018 from https://istio.io/
[9]Kubernetes.Com. 2018. Kubernetes. Retrieved February 21, 2018 from https:
//kubernetes.io/
[10]GhassanMisherghiandZhendongSu.2006. HDD:HierarchicalDeltaDebugging.
InProc. International Conference on Software Engineering (ICSE’06). 142–151.
[11]William Morgan. 2017. What’s a Service Mesh? And Why Do I NeedOne? Retrieved February 21, 2018 from https://buoyant.io/2017/04/25/
whats-a-service-mesh-and-why-do-i-need-one/
[12]William N. Sumner and Xiangyu Zhang. 2009. Algorithms for AutomaticallyComputing the Causal Paths of Failures. In Proc. International Conference on
Fundamental Approaches to Software Engineering (FASE’09). 355–369.
[13]WilliamN.SumnerandXiangyuZhang.2010. MemoryIndexing:Canonicalizing
Addresses Across Executions. In Proc. ACM SIGSOFT International Symposium on
Foundations of Software Engineering (FSE’10). 217–226.
[14]WilliamN.SumnerandXiangyuZhang.2013. ComparativeCausality:Explaining
theDifferencesbetweenExecutions.In Proc.InternationalConferenceonSoftware
Engineering (ICSE’13). 272–281.
[15]DeltaTool.2015. DeltaTool. RetrievedFebruary21,2018from http://delta.tigris.
org/
[16]Andreas Zeller. 1999. Yesterday, My Program Worked. Today, It Does Not. Why?.
InProc.jointmeetingoftheEuropeanSoftwareEngineeringConferenceandtheACM
SIGSOFTSymposiumontheFoundationsofSoftwareEngineering(ESEC/FSE’99).
253–267.
[17]AndreasZeller.2002. Isolatingcause-effectchainsfromcomputerprograms.In
Proceedings of the Tenth ACM SIGSOFT Symposium on Foundations of Software
Engineering 2002, Charleston, South Carolina, USA, November 18-22, 2002. 1–10.
[18]Andreas Zeller and Ralf Hildebrandt. 2002. Simplifying and Isolating Failure-
Inducing Input. IEEE Trans. Software Eng. 28, 2 (2002), 183–200.
[19]XiangZhou,XinPeng,TaoXie,JunSun,ChenjieXu,ChaoJi,andWenyunZhao.
2018. Poster: Benchmarking Microservice Systems for Software Engineering
Research. In Proc. InternationalConference on Software Engineering:Companion
Proceeedings (ICSE’18). 323–324.
807
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. 