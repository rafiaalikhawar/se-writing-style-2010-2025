DKVF: A Framework for Rapid Prototyping and Evaluating
Distributed Key-Value Stores∗
Mohammad Roohitavaf
Computer Science and Engineering Department,
Michigan State University
East Lansing, MI, USA
roohitav@cse.msu.eduSandeep Kulkarni
Computer Science and Engineering Department,
Michigan State University
East Lansing, MI, USA
sandeep@cse.msu.edu
ABSTRACT
WepresentourframeworkDKVFthatenablesonetoquicklypro-
totypeandevaluatenewconsistencyprotocolsforkey-valuestores.
DKVF is designed based on the separation of concerns in creat-
ing distributed data stores. This separation of concerns allowsthe designers of consistency protocols to only focus on the high-level consistency protocols which gives them the opportunity to
quicklydeployaconsistencyprotocolandevaluateitsperformance.
Moreover,theloosecouplingofthedifferentcomponentsallowsus to easily change different components (e.g. storage engine) of
animplementation.WedemonstrateDKVFbyimplementingfour
existing protocols –eventual consistency, COPS, GentleRain and
CausalSpartan–withit.Theimplementationoftheseprotocolswas
very convenient with DKVF, as it only required to write a piece
of code for the consistency component that is very close to the
pseudocodeoftheoriginalpapers.Hence,itwaspossibletoachieve
thisinjust1-2 daysperprotocol.DKVFalsocomeswithatoolset
that facilitates running clusters and performing experiments. Tuto-
rial video: https://www.youtube.com/watch?v=MFJQzsJkwfc&list=
PLErtSVEHsnBJvoQQI6iqGn61oNrUVVuST
CCS CONCEPTS
•Computer systems organization →Cloud computing;
KEYWORDS
DistributedDataStores,Key-valueStores,Framework,Prototyping,
YCSB, Geo-replication
ACM Reference Format:
Mohammad Roohitavaf and SandeepKulkarni. 2018. DKVF: A Framework
for Rapid Prototyping and Evaluating Distributed Key-Value Stores . In
Proceedings of the 2018 33rd ACM/IEEE International Conference on Automated
Software Engineering (ASE ’18), September 3–7, 2018, Montpellier, France.
ACM,NewYork,NY,USA, 4pages.https://doi.org/10.1145/3238147.3240476
∗This work is supported in part by NSF XPS 1533802.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.32404761 INTRODUCTION
With the huge amount of data and very high query throughput
produced by a large number of users across the world, storing
data in a single machine does not work for any major business.
Thus,wehavetodistributethedataacrossseveralmachines.When
wedistributeourdata,animportantchallengeistheconsistency
betweendifferentcopies(i.e.,replicas)ofthedata.Thereisanin-
herent trade-off between consistency and availability/performance
[5]. Different levels of consistency come with different levels of
availability/performance overhead. Even to achieve a certain level
of consistency, two different protocols may have different levels of
overhead.
Ingeneral,thissuggeststhatdevelopersneedtodevelopnewpro-
tocolstoimproveperformance,providehigherlevelsofconsistency,
reduce communication requirements, reduce storage requirements,
andsoon.Whenthedevelopersintuitivelyidentifyanewapproachtodesignsuchaprotocol,thenaturalquestionthatarisesishowto
evaluatethenewprotocolbycomparingitwithdifferentexisting
protocols.Distributeddatastoresarecomplexsystemswhichmakes
an accurate analytical performance evaluation infeasible for them.
A more practical option is experimental performance evaluation
via benchmarking a prototype running the protocol.
In this paper, we introduce Distributed Key-Value Framework
(DKVF) [ 3] that allows protocol designers to quickly create pro-
totypesrunningtheirprotocolstoseehowtheyworkinpractice.
Using separation of concerns, DKVF allows researchers to onlyfocus on their high-level protocol, and rely on DKVF for all the
lower-leveltasks.Thisapproachgreatlyexpeditesimplementing
aprototypeforagivenprotocolcomparedwithcreatingaproto-
typefromscratch. Forinstance,considerthe GentleRainprotocol
proposed in [ 4]. The server-side of this protocol is only 31 lines
of pseudocode provided in Algorithm 2 of [ 4]. However, to have
a prototype running this protocol, we need to write hundreds of
linesofcodetohandlelower-leveltasksthatareindependentoftheprotocol.Ourgoalistoprovideaframeworkthathelpsresearchers
to create their prototypes by writing codes that are very close tothe pseudocodes that they publish in their research papers. We
believe this framework together with a toolset that helps us to
runexperimentscansignificantlysavetimeinimplementingand
benchmarking new protocols.
Therestofthispaperisorganizedasfollows:Section 2discusses
the separation of concerns in designing distributed data stores,
Section3reviews the implementation using DKVF. Section 4intro-
duces the tools that comes with DKVF. Section 5provides some of
theexperimentalresults.Finally,Section 6concludesthepaperand
provides future work.
912
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:50:20 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Mohammad Roohitavaf and Sandeep Kulkarni
2 SEPARATION OF CONCERNS
DKVFisdesignedbasedontheseparationofconcernsofimplement-
ing a distributed key-value store. Figure 1shows three different
componentsofadistributeddatastore.Thestoragecomponentisre-
sponsibleforthestorageandretrievalofthedatainasinglemachine.
It does not interact with either the clients or other servers. It only
serves the read/write requests from the consistency component.
The communication component is responsible for server-server
andclient-servercommunications.Thecommunicationcomponent
can provide different guarantees. For instance, it may provide total
order, per-channel FIFO, or no ordering guarantee; be reliable or
unreliable;besynchronousorasynchronous,andsoon.Thecon-
sistency component is responsible for defining replication strategy
and consistency protocol that guarantees clients always observe
a consistent view of the data. Different levels of consistency is de-
fined for replicated data stores. The highest level of consistency is
called strong consistency thatprovidestheillusionthatthereisonly
a single copy of the data. On the other end, eventual consistency
only guarantees that all replicas finally converge to the same data
if westop writing newvalues. In between, we have differentlev-
elsofintermediateconsistencymodelssuchas causal consistency
[7].Aconsistencyprotocolrequiresasetofrequirementsforthe
storageandcommunicationcomponents.However,theconsistency
protocolshouldnotbeinvolvedinprovidingtheserequirements.
Thisloosecouplingletsuseasilychangedifferentcomponentsin
both design and implementation of a distributed data store.
^ƚŽƌĂŐĞ ŽŵŵƵŶŝĐĂƚŝŽŶŽŶƐŝƐƚĞŶĐǇ
Figure 1: Components of a distributed data store.
3 IMPLEMENTATION USING DKVF
To implement a protocol using DKVF, the protocol designer needs
to provide three sub-components of the consistency component of
Figure1.
3.1 Metadata Description
For a consistency protocol, in addition to actual data consisting
ofthe key-valuepairs, wewilllikely needto storesomemetadata
with eachrecord. For example,we may needto store atimestamp
with each version, or we may need to store the ID of the replicawhere the version has been written. Each protocol requires its
own metadata. DKVF relies on Google Protocol Buffers [
6] for
marshaling/unmarshalingdataforstorageand transmission. The
protocoldesignerneedstowritea .prototextfiledescribingthe
metadata.Thisfilealsodescribesthestructureofthemessagessent
in the system.
3.2 Server-side
Toimplementtheserver-sideofaprotocol,theprotocoldesigner
needstowriteaclassthatextendstheabstractclass DKVFServer .DKVFfollowsanevent-drivenapproachtodefineaprotocol.Specif-
ically, we can define a protocol as a set of event handlers. The
two main event handlers that will be calledby the framework are
handleServerMessage andhandleClientMessage ofDKVFServer
class.Inside thesetwo maineventhandlers, theprotocol designercan call detailed event handlers for different events. While we are
processingserverorclientmessagesin handleServerMessage and
handleClientMessage , we may need to send messages to other
servers,orsendclientresponses.DKVFprovidesmethodstoreli-
ably send/receive messages to/from clients and servers. We also
needtostore/retrievedatafromthestorageenginethatcanbedone
via that DKVF storage interface. Any data storage engine can be
usedwithDKVF.Touseastorageengine,wehavetoprovideDKVF
driver for it by implementing the DKVF storage interface. DKVF
comes with a driver for Oracle Berkeley-DB [9].
3.3 Client-side
Toimplementtheclient-sideofaprotocol,weneedtoextendthe
clientpart ofthe framework.Specifically, weneed towrite aclass
thatextendsclass DKVFClient .Whenweextend DKVFClient ,w e
have to implement two abstract methods putandgetthat are the
basicPUTandGEToperationsofakey-valuestore.Thesemethods
are operationsthat the protocoldesigner needs toprovide for the
applicationdeveloper.Theapplicationdeveloperlatercanusethese
methodstousethedatastore.Theprotocoldesignercanalsoadd
more complex operations for its implementation, but these two
methods are required for any implementation.
4 TOOLSET
In this section we reviews tools that come with the framework.
4.1 Cluster Manager
Cluster Manager is a command line application to facilitate manag-
ingclustersrunningkey-valuestorescreatedwithDKVF.Cluster
Manageralsoenablesustomonitortheservers.Forinstance,we
canseeifservershaveproperlystartedandconnectedtoeachother,
how much are the network latencies, or how many clients are con-
nected to each server. Cluster Manager also helps us to test and
debugour key-valuestore. Specifically,after runninga clusterwe
can connect to any server in the cluster and run commands on the
servers.
ItalsohelpsustorundistributedYCSB[ 2]experiments.YCSBis
atoolforevaluatingtheperformanceofkey-valueorcloudserving
stores [2]. To use YCSB, we need to write a YCSB driver that lets
YCSB client class use our key-value store. DKVF comes with its
YCSBdriver.Thus,anykey-valuestoreusingDKVFhasitsYCSB
driver ready. Also using Cluster Manager tool, we can benchmark
ourkey-valuestorewithoutdirectlysettingupYCSB;weonlyneedtodefineourdesiredworkload,andClusterManagertakescaresof
the rest. It runs all clients and obtains the results. Cluster Manager
provides an interactive environment with a query language that
lets us aggregate the results.
4.2 Cluster Designer
AlthoughClusterManagerisaconvenienttoolthatcansignificantly
reduce time and headache of debugging and benchmarking our
913
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:50:20 UTC from IEEE Xplore.  Restrictions apply. DKVF: A Framework for Rapid Prototyping and Evaluating Distributed... ASE ’18, September 3–7, 2018, Montpellier, France
Figure 2: The graphical interface of Cluster Designer
protocol,writingclusterandexperimentdescriptorfilescanbea
tedious and error-prone task for larger clusters. To solve this issue,
weprovideClusterDesignertool.ClusterDesignerisagraphical
toolthatallowsustodefineourclusterandexperimentsvisually.
The tool provides an area where we can add servers and clients.
We can connect servers and clients by lines to specify network
connections. When we have several components that need to be
allconnectedtoeachother,wecanusehubstoavoidconnecting
them one-by-one. Figure 2shows the interface of Cluster Designer.
In this network, we have 6 servers and 6 clients. We will talk about
this network in more details in 5.
5 EXPERIMENTAL RESULTS
Inthissection,wepresentsomeoftheresultsthatweobtainedfrom
implementing and evaluating three causal consistency protocols
namely COPS [ 7]1, GentleRain [ 4], and CausalSpartan [ 10] using
DKVF. We also implemented eventual consistency for comparison.
Duetolackofspace,wecannotprovidethesketchoftheseprotocols.
Thereadercanrefertotheoriginalpaperstolearnmoreaboutthese
protocols. We assume the reader is familiar with these protocols in
the rest of this section.
WeconsiderareplicatedandpartitioneddatastoreshowninFig-
ure2. The data store consists of two replicas. Each replica consists
ofthreepartitions.Replica0includespartitions0 _0,0_1,and0_2.
Replica 1, on the other hand, consists of partitions 1 _0, 1_1, and
1_2. We assume full replication, i.e., each replica has a copy of the
entirekeyspace.Thekeyspaceinsideeachreplicaispartitioned
among servers. In Figure 2, we have connected servers inside each
replicatogetherwithahub.Partitionsarealsoconnectedtotheir
peers in the other replica. For servers, we use AWS [ 1]m3.medium
instances with the following specification: 1 vCPUs, 2.5 GHz, Intel
XeonE5-2670v2,3.75GiBmemory,1x4(GB)SSDStorageCapacity.
Connected to each replica, we have a set of clients. We allocate
three client machines to run clients. We run 30 threads of YCSB
clients on each client machine. All causal consistency protocolsthat we study here assume locality of traffic, i.e., clients always
access one replica. Thus, clients are connected to only one replica
as shown Figure 2. We run clients on c3.large machines with the
following specification: 2 vCPUs, 2.8 GHz, Intel Xeon E5-2680v2,
1We have implemented a simplified version of COPS without garbage collection.3.75 GiB memory, 2 x 16 (GB) SSD Storage Capacity. We have used
more powerful machines for clients to better utilize our servers.
5.1 The Effect of Workload on Performance
The workload of different applications has different characteristics.
Some workloads are write-heavy, others like those in data ana-lytics are read-heavy. In this section, we want to study how thecharacteristics of our workload affect the performance of differ-
ent consistency protocols. In all experiment, we set the size of the
values written by clients to 64 bytes.
Figure3ashows how GET:PUTproportion affects thethrough-
put. As we move from the left side of the plot to its right side,
the workload nature changes from write-heavy to read-heavy. The
throughputs of all protocol increase as the proportion of GET oper-
ationsincreases.Thisresultsconfirmpreviousstudies[ 4,7],and
are expected, as GET operations are lighter than PUT. As expected,
eventual consistency has the highest throughput. COPS, on the
other hand, has the lowest throughput. This results confirm results
publishedin[ 4],andisduetotheoverheadofdependencycheck
messages that partitions send to each other to make sure causal
dependencies of an update in other partitions are visible [4, 7].
Figure3bshows how GET:PUT proportion affects the response
time of PUT operations. In all protocols, the response time of PUT
operationsdecreases aswemoveto read-heavierworkloads.This
isduetothelessloadonserversforread-heavierworkloads.The
eventualconsistencyhastheshortestresponsetimethankstoits
minimal metadata. CausalSpartan has more metadata than Gen-
tleRainresultinginhigherPUTresponsetime.COPShasthehighest
response time because of its dependency check messages and itsexplicitdependencytrackingapproach.Likeotherprotocols,thetrend of PUT response time for COPS is decreasing as we move
towardread-heavierworkloadsthatcanbeexplainedbylessload
on the machines. However, for 0.05:0.95, the PUT response time
increases.Thisincreasecanbeunderstoodbyconsideringthede-
pendency tracking mechanism of COPS. At point 0.05:0.95, clients
read many keys before writing a key. That results in longer de-
pendency lists which make PUT messages heavier to transmit and
process.NotethatwehaveimplementedabasicversionofCOPS
protocol without client metadata garbage collection. COPS authors
suggest a garbage collection mechanism to cope with this problem
[7].
Figure3cshows how GET:PUT proportion affects the response
time of GET operations. Like the case of PUT operations, the re-sponse time of GET operations also decreases, as we move to-
wards read-heavier workloads. It is interesting that GentleRain
and CausalSpartan have a lower response time for GET operations
comparing to the eventual consistency for write-heavy workloads.
This can be explained by the synchronization that occurs between
threads in GentleRain and CausalSpartan. Specifically, there is a
contentionbetweenthreadswhileperformingPUToperationsin
GentleRain/CausalSpartan. This contention occurs for obtaining a
lock that we used toguarantee updates with smaller timestampsare replicated to other nodes before updates with higher times-
tamps.ThisincreasesthePUTresponsetimethatresultsinalower
overallthroughputofGentleRain/CausalSpartanforwrite-heavy
workloads.WhilethreadsservingPUToperationsarewaitingfor
914
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:50:20 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Mohammad Roohitavaf and Sandeep Kulkarni
synchronization, the server can handle GET operations. On the
other hand, in the eventual consistency, there is no competition
between PUT operations. Thus, there are more active threads serv-
ingPUToperationsleadingtohighercompetitionoverCPUthat
finally results in higher GET response time comparing to Gen-tleRain/CausalSpartan. Note that this happens for write-heavy
workloadswithlowGETproportion.Therefore,theeventualcon-
sistency still has the highest overall throughout in all cases (See
Figure3a).
5.2 The Effect of Query Amplification
Inthissection,westudytheeffectofqueryamplificationthatcauses
a single end user request translate to several internal operations.In this section, we only consider one replica consisting of three
partitions.Weconsideraworkloadthatpurelyconsistsofamplified
insert operations. Each amplified insert consists of several internal
PUToperations.ThenumberofinternalPUToperationsisdefined
by the amplification factor.
Figure3dshowstheeffectofamplificationfactorontheclient
request throughput. Note that this throughput represents the num-
berofclientmacrooperations(notindividualPUToperations)that
are served in one second. As the amplification factor increases, the
throughput of all protocol decreases which is expected, as requests
withhigheramplificationfactorincludemoreinternaloperations
which meanmore jobto dofor each request.The eventualconsis-
tencyhasthehighestthroughput.Thepure-writeworkloadisan
idealwritescenarioforCOPS,asdependencylistshaveatmostone
entry. Thus,thethroughputofCOPS isthehighest aftereventual
consistencyforthisscenario.GentleRainhasthelowestthroughput.
ThatisduetothedelaythatGentleRainimposesonPUToperations
in case of clock skew between servers. Note that we synchronized
the physical clocks of the system with NTP [ 8], but the effect of
clockskewstillshowsupintheresults.Theseresultsconfirmprevi-ousresultspresentedin[
10].CausalSpartanhashigherthroughput
thanGentleRain,asCausalSpartaneliminatestheneedforthede-
lay before PUT operations by utilizing HLCs instead of physical
clocks[10]. Figure 3eshows the request response time for differ-
entprotocols.Again,becauseofdelaysthatGentelRainforceson
PUT operations, request response time has the highest value for
GentleRain.
6 CONCLUSION
In this paper, we introduced DKVF which is a framework for rapid
prototyping and benchmarking distributed key-value stores. It
streamlines the evaluation of the performance of consistency pro-
tocolsfordistributedkey-valuestores.Toshowtheeffectivenessof
our framework, we implemented four consistency protocols using
DKVF.ThankstotheconvenienceofDKVF,wewereabletoimple-
menteachoftheseprotocolsinlessthan2days.Wewereableto
implement CausalSpartan and GentleRain with significantly less
effort than our previous implementations without DKVF.
The toolset that comes with the framework helps protocol de-
signers to easily evaluate their prototype. Using these tools we can
easily run and manage clusters of machines running our proto-
col. We can also run clients to benchmark the performance of our
key-value store. DKVF relies on YCSB for benchmarking.0.5:0.95 0.25:0.75 0.5:0.5 0.75:0.25 0.95:0.5
GET:PUT proportion1.522.533.544.5Throughput (op/s)104
Eventual Consistency
COPS
GentleRain
CausalSpartan
(a) Throughput0.05:0.95 0.25:0.75 0.5:0.5 0.75:0.25 0.95:0.05
GET:PUT proportion24681012PUT response time (ms)Eventual Consistency
COPS
GentleRain
CausalSpartan
(b) PUT Response Time
0.05:0.95 0.25:0.75 0.50:0.50 0.75:0.25 0.95:0.05
GET:PUT proportion34567GET response time (ms)Eventual Consistency
COPS
GentleRain
CausalSpartan
(c) GET Response Time20 40 60 80 100
Amplification Factor02004006008001000 Throughput (request/s)Eventual Consistency
COPS
GentleRain
CausalSpartan
(d) Request Throughput
20 40 60 80 100
Amplification Factor050100150200250300Request Response Time (ms)Eventual Consistency
COPS
GentleRain
CausalSpartan
(e)RequestResponseTime
Figure 3: Some of results obtained from DKVF
We can use any storage systems as the storage engine for the
key-valuestoresthatwedevelopwithDKVF.Thisenablesprotocol
designers to flexibility change their storage engine. To use a given
storage system with DKVF, we need to write a driver for it that
enables DKVF to interact with it. DKVF comes with a driver for
Berkeley-DB.Writingdriversforotherstoragesystemsispartof
the future work.
REFERENCES
[1] Amazon. 2018. AWS. (2018). https://aws.amazon.com/
[2]BrianFCooper,AdamSilberstein,ErwinTam,RaghuRamakrishnan,andRussell
Sears.2010. BenchmarkingcloudservingsystemswithYCSB.In Proceedings of
the 1st ACM symposium on Cloud computing. ACM, 143–154.
[3] DKVF. 2018. GitHub repository. (2018). https://github.com/roohitavaf/DKVF
[4]Jiaqing Du,Călin Iorgulescu,Amitabha Roy,and WillyZwaenepoel. 2014. Gen-
tleRain: Cheap and Scalable Causal Consistency with Physical Clocks. In Pro-
ceedings of the ACM Symposium on Cloud Computing (SOCC ’14). New York, NY,
USA, Article 4, 4:1–4:13 pages.
[5]Seth Gilbert and Nancy Lynch. 2002. Brewer’s Conjecture and the Feasibility of
Consistent, Available, Partition-tolerant Web Services. SIGACT News 33, 2 (June
2002), 51–59.
[6]Google. 2018. Protocol Buffers. (2018). https://developers.google.com/
protocol-buffers/
[7]WyattLloyd,MichaelJ.Freedman,MichaelKaminsky,andDavidG.Andersen.
2011. Don’T Settle for Eventual: Scalable Causal Consistency for Wide-area
Storage with COPS. In Proceedings of the Twenty-Third ACM Symposium on
Operating Systems Principles (SOSP ’11). New York, NY, USA, 401–416.
[8] NTP. 2018. Network Time Protocol. (2018). http://www.ntp.org/
[9]Oracle.2018. BerkeleyDB. (2018). http://www.oracle.com/technetwork/database/
database-technologies/berkeleydb/overview/index.html
[10]Mohammad Roohitavaf, Murat Demirbas, and Sandeep Kulkarni. 2017.
CausalSpartan: Causal Consistency for Distributed Data Stores using Hybrid
LogicalClocks.In Reliable Distributed Systems (SRDS), 2017 IEEE 36th Symposium
on. IEEE, 184–193.
915
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:50:20 UTC from IEEE Xplore.  Restrictions apply. 