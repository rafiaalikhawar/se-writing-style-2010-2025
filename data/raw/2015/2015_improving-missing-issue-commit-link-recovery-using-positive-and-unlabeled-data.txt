Improving Missing Issue-Commit Link Recovery
using Positive and Unlabeled Data
Yan Sun1,2,3, Celia Chen4,5, Qing Wang1,2,3,∗, Barry Boehm4,5
1University of Chinese Academy of Sciences, Beijing, 100049, P.R. China
2Laboratory for Internet Software Technologies,3State Key Laboratory of Computer Science,
Institute of Software Chinese Academy of Sciences, Beijing, 100190, P.R. China
{sunyan, wq}@itechs.iscas.ac.cn
4Department of Computer Science, Occidental College, Los Angeles, CA
5Center for Systems and Software Engineering, University of Southern California, Los Angeles, USA
{qianqiac,boehm}@usc.edu
Abstract —Links between issue reports and corresponding ﬁx
commits are widely used in software maintenance. The quality
of links directly affects maintenance costs. Currently, such links
are mainly maintained by error-prone manual efforts, whichmay result in missing links. To tackle this problem, automatic
link recovery approaches have been proposed by building tra-
ditional classiﬁers with positive and negative links. However,these traditional classiﬁers may not perform well due to the
inherent characteristics of missing links. Positive links, which
can be used to build link recovery model, are quite limited asthe result of missing links. Since the construction of negative
links depends on the number of positive links in many existing
approaches, the available negative links also become restricted.
In this paper, we point out that it is better to consider the missing
link problem as a model learning problem by using positiveand unlabeled data, rather than the construction of traditional
classiﬁer . We propose PULink, an approach that constructs the
link recovery model with positive and unlabeled links. Our
experiment results show that compared to existing state-of-the-
art technologies built on traditional classiﬁer, PULink can achieve
competitive performance by utilizing only 70% positive links that
are used in those approaches.
I. I NTRODUCTION
Issue reports and commits, as different software artifacts,
are usually managed in separate systems [1]. Links between
issue reports and commits reﬂect the ﬁx relationship between
the two kinds of artifacts and are widely used in softwaremaintenance activities, such as bug prediction [1] and commitanalysis [2]. The maintenance of such links are normally reliedon labor-intensive manual efforts by developers, which arevulnerable to human errors. As a result, some considerablelinks are missing and the quality problem of the links mayincrease software maintenance costs [3, 4].
Many automatic approaches such as ReLink [1], MLink
[5], RCLinker [6], and FRLink [7] have been proposed to
recover missing links between issues and commits. Existing
approaches solve the missing link problem by constructing atraditional binary classiﬁer with positive and negative links. A
positive link indicates that the corresponding commit is a ﬁx
for the issue. A negative link, in contrast, indicates that thecommit is not related to the issue. Developers usually record
*Corresponding author.the ﬁxed issue ID in the commit log message to maintain thelinks between issues and commits [1, 3]. As a result, positive
links can be found by analyzing the issue ID in commit logmessages [1, 2]. However, negative links cannot be achieveddirectly since developers do not explicitly identify commitsthat are not for the issue ﬁx. The construction of negative
links can be implemented as follows: If a commit is conﬁrmedto be a ﬁx for one or more issue reports by developers, we
can safely consider the links between the commit and otherissues, which are not explicitly mentioned by developers, asnegative links. For example, if Commit
1is a ﬁx for Issue 1
andIssue 2(i.e., developers only record the IDs of Issue 1and
Issue 2in the log message of Commit 1), we can assume that
Commit 1is not ﬁx for issues other than Issue 1andIssue 2.
The links between other issues (e.g., Issue 4) and Commit 1
are considered as negative links. This assumption is widely
applied in existing link recovery approaches to get the negativelinks in order to build the traditional binary classiﬁer [1, 5–7].
However, considering the inherent characteristics of missing
link problem, there are two major problems found in existinglink recovery approaches:
1) Limited Positive Links. Several studies have showed
that positive links are quite limited in software projects[2, 3]. Bachmann et al. [2] found that links recorded bydevelopers only cover 33% of the ﬁxed issues in Eclipseproject. Brindescu et al. [4] analyzed 132 softwareprojects and noticed that less than 40% of the links arerecorded in the code repositories. The limited positivelinks result in a small training dataset, which may leadto an underperformed link recovery model.
2) Negligence of Unlabeled Links. In existing link re-
covery approaches, negative links are built based onpositive links. Links constructed from commits thatare not found in the positive links are considered asunlabeled (i.e., such links can be positive or negative).
According to existing link recovery approaches, theseunlabeled data cannot be used in the model training.However, many studies have demonstrated that whenpositive data are limited in model learning problems,
978-1-5386-2684-9/17/$31.00 c/circlecopyrt2017 IEEEASE 2017, Urbana-Champaign, IL, USA
T echnical Research - New Ideas147
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:48:35 UTC from IEEE Xplore.  Restrictions apply. unlabeled data can be used as data source for model
learning [8]. Proper usage of unlabeled links may helpto improve the performance of link recovery approaches.
In this paper, we propose PULink, a missing link recovery
approach built with Positive and Unlabeled links. By introduc-
ing unlabeled links into the model training, PULink utilizes
the usage of data that cannot be used in existing link recovery
approaches. The major contributions of our work include:
i) To the best of our knowledge, we are the ﬁrst to point out
that the missing link problem should be considered as a model
learning problem with positive and unlabeled links rather than
a traditional binary classiﬁer construction problem.
ii) We propose PULink, a novel automatic link recovery
approach built on positive and unlabeled links. Throughcomparison experiments, we demonstrate that our proposedapproach can effectively reduce the maintenance costs inrecovering missing links.
iii) Compared to the latest state-of-the-art technologies,
PULink can achieve better performance with only 70% of
positive links used in existing link recovery approaches.
II. B
ACKGROUND
In this section, we introduce a binary classiﬁer based on
positive and unlabeled data proposed in [8]. Assuming xis
an instance and yis the corresponding classiﬁcation of x.
y=1 means xis a positive instance. y=0 means xis a
negative instance. sindicates whether an instance is labeled
or not. s=1 means the instance is labeled. s=0 means
the instance is unlabeled. With the deﬁnition of x,y, and s,
the model learning problem using positive and unlabeled datacan be described as follows: For any instance with s=1, the
corresponding yequals to 1, which indicates that the instance
is positive. For any instance with s=0 , the corresponding
ycan be 1 or 0, which indicates that the instance can be
either positive or negative. Considering x,y, and sas random
variables, the overall distribution of these three variables canbe represented as p(x, y, s) .
The objective is to achieve a classiﬁer f(x)= p(y=1|x)
built on positive and unlabeled data. A traditional binaryclassiﬁer g(x)= p(s=1|x)can be trained by applying
all labeled data (i.e., data with s=1 ) as positive instances
and all unlabeled data (i.e., data with s=0 )a sn e g a t i v e
instances. It can be proved that g(x)can
be transferred to f(x)
using f(x)=g (x)/c, in which c=p(s=1 |x, y =1 ) .
To calculate c, we need Vwhich is extracted according to
the overall distribution of p(x, y, s) .Prepresents all labeled
instances in V. With g(x),V, and P,ccan be estimated as the
average value of g(x)forxinP, that is e=1
n/summationtext
x∈Pg(x).
eis the estimated value for c. With g(x)and the estimated
value of c, the classiﬁer f(x)with positive and unlabeled data
can be constructed.
III. O VERVIEW OF PULink
In this section, we explain and further elaborate on the
design of our proposed link recovery approach PULink. Figure
1 presents the overall framework of PULink.
Figure 1. Overall framework of PULink
A. Data Selection
In our data selection process, each issue report is ﬁrst
compared with all commits in the code repository. If thedifference between the submission date of a commit and any ofthe four date attributes (i.e., create date, ﬁx date, last modiﬁeddate, and comment create date) in the issue report is withinseven days (before or after), a potential link is constructed. Thepotential link is then put into the Positive Link Index dataset
if it is positive. Otherwise, it will be put into the Unlabeled
Link Index dataset. The Positive Link Index dataset is then
applied in F eature Extraction and Model Learning; while the
Unlabeled Link Index dataset is used in F eature Extraction ,
Model Learning, and Missing Link Recovery.
The construction of training links in PULink is different
from existing link recovery approaches such as FRLink. As-
suming two issues (i.e., I
1andI2) and three commits (i.e.,
C1,C2andC3).I1is ﬁxed by C1and the developer recorded
the issue ID in C1.I2is ﬁxed by C2but the issue ID is
missing. Link (I1,C1)represents the link between I1andC1.
To recover the missing link, six potential links are generatedby two issues and three commits. In FRLink, the training data
is constructed with the positive link Link (I
1,C1)and the
negative link Link (I2,C1). The other four links cannot be
used in the training data as the status (i.e., positive or negative)cannot be identiﬁed. However, in PULink, according to the
deﬁnition in Section II, Link (I
1,C1)is considered as labeled.
And other ﬁve links including the negative link Link (I2,C1)
could be considered as the unlabeled links. The labeled and
unlabeled data together consist of the training data in PULink.
B. Feature Extraction
There are two types of feature exaction in PULink : metadata
feature extraction and similarity feature extraction. Metadata
148
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:48:35 UTC from IEEE Xplore.  Restrictions apply. Table I
DEFINITION OF METADA TA FEATURES AND SIMILARITY FEATURES IN PULink
Type Name Description Used in FRLink
Metadata IssueType Type of an issue report, e.g., bug, task, etc. No
Feature CommitType Type of a commit. It indicates whether all modiﬁed ﬁles in the commit are non-source documents. Yes
Interval Result from comparison using date attributes of issue reports and commits. Yes
IntervalType Type of Interval. It depends on the type of attributes which are used to get Interval.N o
Similarity SimV al The larger value between code feature similarity and text feature similarity. Yes
Feature SimSource It indicates where SimV al gets its value (i.e. code feature similarity or text feature similarity). Yes
SimByIssue For potential links constructed by the same issue, get SimV al sorted according to the issue. No
SimByCommit For potential links constructed by the same commit, get SimV al sorted according to the commit. No
features describe the basic characteristics of issues and com-
mits, such as the type of an issue report or a commit. Similarityfeatures are exacted based on the fact that similar terms may
exist in issues and corresponding ﬁx commits. The same idea
of similarity can be found in some existing studies such as[1, 5–7]. Both metadata and similarity features are extractedfrom each potential link. Table I summarizes the metadatafeatures and similarity features.
1) Metadata Features: Four kinds of metadata features
are extracted according to each link. These features includeIssueType, CommitType, Interval, and IntervalType.
IssueType describes the type of a given issue report (e.g.,
bug, new feature, improvement, task, sub-task, wish, story,dependency upgrade, documentation etc). It is important to
know the speciﬁc type of an issue report as ﬁx commits may
have different characteristics due to the differences among
each issue type [9].
CommitType describes the type of a given commit. Sun et
al. [7, 10] pointed out that separate processing of code ﬁxesand non-source documents in commits lead to performance
improvement in link recovery approaches. Therefore, we dis-
tinguish the types of commits. If all modiﬁed ﬁles in a givencommit are non-source documents, we set CommitT ype =1.
Otherwise, set CommitT ype =0.
Interval records the comparison results of date attributes
found in commits. Assuming that an issue report includes2 comments, time periods between submission date of thecommit and date attributes of the issue (i.e., creation date,ﬁx date, last modiﬁed date, comment creation date 1, andcomment creation date 2) are 2, 3, 4, -1, and 5 respectively.According to [7], Interval is the corresponding time period of
the minimum absolute value, which is -1.
IntervalType is used to further explain the values of Interval.
IntervalType with value 0,1,2, and 3 implies that Interval is
calculated by comparing commit submission date with creationdate, ﬁx date, last modiﬁed date, and comment creation date
respectively.
2) Similarity Features: For each link, we extract four kinds
of similarity features including SimV al, SimSource, SimByIs-
sue, and SimByCommit. Detailed steps to get SimV al and
SimSource features can be found in FRLink [7]. Steps to get
SimByIssue and SimByCommit are as follows:
SimByIssue: Many potential links may be constructed from
the same issue in Positive Link Index and Unlabeled LinkIndex. For potential links with the same issue, we sort these
links according to SimV al and record results in SimByIssue.
SimByCommit : The idea of SimByCommit is similar to
SimByIssue. Many potential links may be constructed from thesame commit in Positive Link Index orUnlabeled Link Index.
For potential links with the same commit, we sort these linksaccording to SimV al and record the results in SimByCommit.
C.
Model Learning
Once we have all of the eight extracted features, we then
can build the binary classiﬁer f(x)based on positive and
unlabeled links. As mentioned in Section II, there are two steps
to get f(x). First, we take all of the positive links as positive
instances and unlabeled links as negative instances to build a
traditional classiﬁer g(x). Then we estimate the value of c(i.e.,
c=p(s=1|x, y=1 ) ). According to the overall distribution
ofPositive Links and Unlabeled Links, we form a validation
dataset. The estimate value of cis calculated by applying the
validation dataset and the equation e=1
n/summationtext
x∈Pg(x). With
g(x)andc, we can get our binary classiﬁer f(x).
D. Missing Link Recovery
With the binary classiﬁer f(x), we can decide whether links
in the unlabeled dataset are positive or negative. The naturalthreshold of f(x)is set to 0.5c[8]. For each potential link
in the unlabeled dataset, f(x)yields the probability of the
link being positive. We then compare the probability of thelink with the natural threshold 0.5c. If the probability is no
less than the natural threshold, the potential link is consideredas a positive link. Otherwise, the link is considered negative.Identiﬁed results are generated after all links in the unlabeleddataset have been compared.
IV . E
MPIRICAL EV ALUA TION
A. Subject Projects
We compare and evaluate our PULink with the baseline
FRLink [7]. FRLink reported its performance in 18 active
Apache Software Foundations projects [10]. Among the 18
projects, there are six projects which have less than 200positive links in the Ground Truth data. The limited number
of positive links in these six projects may lead to unreliabletraining results or incomplete training model. Based on this
consideration, we exclude these six projects and keep theremaining 12 projects for the comparison.
149
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:48:35 UTC from IEEE Xplore.  Restrictions apply. Table II
SUBJECT PROJECT STA TISTICS
Project Fixed Issue Commit Ground Truth Studied Period
Avro 1125 1389 1255 04/2009 – 12/2015
Buildr 499 4029 791 12/2007 – 11/2015
Chukwa 290 743 353 03/2009 – 12/2015
Falcon 497 957 427 05/2013 – 12/2015
Giraph 397 930 419 08/2011 – 10/2015
Ivy 328 1944 404 01/2007 – 06/2015
Knox 241 545 214 04/2014 – 12/2015
Log4net 183 570 227 06/2005 – 11/2015
Nutch 654 2064 614 04/2005 – 12/2015
OODT 296 1686 392 05/2010 – 12/2015
Tez 867 1887 941 06/2013 – 12/2015
Tika 608 2768 1109 06/2007 – 12/2015
Total 5985 19512 7146 –
Table II lists the data of the 12 projects. ‘Ground Truth’
represents the number of all positive links indicated in the is-
sue tracking system. Ground Truth data are built by analyzingissue IDs in the commit log message according to existingstudies such as [2, 6, 7]. Manual inspection has been taken byauthors on more than 200 links (i.e, 20 links per project) andall veriﬁed links are positive.
B. Experiment Settings and Evaluation Metrics
First we need to remove issue IDs from commits before
utilizing them in PULink. The reason for the ﬁltering operation
is that with the instruction of explicitly issue IDs, recovering
missing links becomes an easy task for the automatic link re-covery approach [6, 7]. Similar process has been implementedto remove the commit IDs from issue reports as well.
Traditional binary classiﬁer g(x)and the objective classiﬁer
f(x)are built by Random Forest as existing studies [6]
and our practical experience both suggest that it is a betterchoice compared to other methods such as SVM. Ten-foldcross validation is applied in each project. Potential links arepartitioned into ten equal size subsets randomly. One subset isreserved as testing data and the other nine subsets are used astraining data. The validation process is then repeated for tentimes and the average result is used for the evaluation.
We expect PULink to achieve high recalls in order to reduce
maintenance costs. The natural threshold is set to 0.5cwith
0≤c≤1inPULink. To attain high recalls, the threshold
needs to be set to small values. In the experiment, we set thethreshold from 0.9cto0.1c, with a decreasing step of 0.1c.W e
also include the performance of PULink when the threshold
is set to 0.05c and0.01c respectively. In the baseline method
FRLink, Input training recall (ITR) represents the minimum
recall that the model should satisfy in the training data. Alarger ITR value results in higher recalls in the performance
ofFRLink. According to [7], we set the ITR values to range
from 0.76 to 0.96, with an increasing step of 0.02. There are11 sampling performance points in both PULink and FRLink
approaches for the performance comparison.
Precision, recall, and F-measure, are utilized to evaluate
our approach. These metrics are widely used in evaluating the
efﬁciency of many existing link recovery approaches [1, 5–7].C. Experiment Results
1) The Effectiveness of PULink: In order to get the best
performance of PULink, all positive links are labeled and
the unlabeled data contain only negative links. Figure 2
demonstrates the performance of PULink in each project.
The experiment results show two major ﬁndings. First, as
shown in Figure 2, the highest precision of PULink is
higher
than 90% in 11 out 12 of the projects. In 7 out 12 of theprojects, the median of precision is above 90%. Similarly, in9 out 12 of the projects, PULink has the highest recall that is
greater than 90%. And in 7 out 12 of the projects, the medianof recall is also above 90%. These two ﬁndings illustrate thatPULink can recover most of the missing links in software
projects without introducing many negative links. With thehelp of PULink, developer can identify missing links without
too many manual efforts.
2) PULink VS. FRLink: Existing approaches, such as FR-
Link, build their models based on positive and negative trainingdata. To get the best performance of FRLink, all positive links
in the training data are labeled and unlabeled data containsonly negative links.
We calculate the average precision, recall, and F-Measure
ofPULink and FRLink in all 12 projects. Figure 3 shows the
Precision-Recall Curve ( PR Curve) of the two approaches.
As shown in Figure 3, the PR Curve ofPULink is above
FRLink in all circumstances. It indicates that PULink can
outperform FRLink even when FRLink gets its optimal perfor-
mance. Moreover, when FRLink gets the highest recall (i.e.,
92.51%), the precision and F-Measure are 52.01% and 64.91%
respectively. By contrast, when PULink achieves the recall of
92.87%, the precision is 61.00% and F-Measure is 72.63%.
With a slightly higher recall (i.e., 0.36% = 92. 87%−92.51%),
the improvement of PULink over FRLink in precision and
F-Measure are 8.99% and 7.72% respectively. When FRLink
reaches its lowest recall (i.e., 81.98%), the precision is 84.82%and F-Measure is 83.26%. However, when PULink reaches a
higher recall than FRLink ’s lowest recall, which is 83.59%,
the improvement in precision and F-Measure is 9.52% and
5.15% respectively.
These ﬁndings indicate that PULink can outperform FRLink
even when FRLink achieve its optimal performance using the
training data with only positive and negative data.
3) Small Amount of Positive Links: In practical software
development, positive links recorded by developers are quitelimited. Link recovery approaches can only rely on quite fewpositive links to construct the model. In order to compare
the performance of two approaches when the training datasetcontains only a small amount of positive links, we remove
a certain amount of positive links from the training data. To
be more speciﬁc, 10% of the positive links from the trainingdataset
are removed. For PULink, we make the 10% of the
positive links as unlabeled (i.e., their class is set to 0), thenwe exclude them from the positive link data and put theminto unlabeled link data. The remaining positive link data,which contain 90% of the positive links and the new generatedunlabeled link data, which include 10% of the positive links
150
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:48:35 UTC from IEEE Xplore.  Restrictions apply. Figure 2. Performance of PULink in each individual project
Figure 3. Performance comparison between PULink and FRLink
without label, are used for training PULink.F o rFRLink, 10%
of the positive links are removed from the training data, the
remaining 90% of the positive links are used for generating
negative links. The new training dataset include the 90% ofthe positive links and corresponding negative links generatedby 90% of the positive links. The new training dataset will beused for constructing the FRLink model. The performance of
two approaches are evaluated as we iteratively remove 10% ofthe positive links from the training dataset at a time. Positivelinks remain in the training data fall from 90% to 10%.
Figure 4 shows the performance comparison between
PULink and FRLink when training data contain 10% to 90%
of the positive links. 10%PULink and 10%FRLink represent
the performance of PULink and FRLink when the training
data contain 10% of the positive links. Other legends suchas 20%PULink, 20%FRLink, etc. are similar. In Figure 4,
we notice that the decrease of positive links in the trainingdata leads to performance decline in both approaches. When
the training data contain 60%-90% of the positive links, the
PR Curve ofPULink is above FRLink. For the training data
that includes 10%-50% of the positive links, the PR Curve of
PULink is also above FRLink within the highest recall that
both approaches can achieve. Additionally the highest recallofPULink is less than the highest recall of FRLink. When the
train data contains 50% of the positive links, the loss in recall
is minimum with the value of 0.07%. When only 10% of thepositive links remains, the loss in recall is 1.73%, which is themaximum. Therefore, we conclude that in most cases, PULink
can outperform FRLink when the training data contain only a
small amount of positive links. There might be a loss in the
highest recall of PULink compared to FRLink. However, the
loss is usually minor since it ranges from 0.07% to 1.73%.
We further analyze the data to answer the question: to
what extent PULink compared to FRLink, can reduce the
reliance on the positive link data. When considering theoptimal performance of FRLink, Figure 5 shows that the
performance of 70%PULink (i.e., training data that contain
only 70% of the positive links) is superior to the optimalperformance of FRLink. When considering the worst per-
formance of PULink, we iteratively compare 10%FRLink
to 90%FRLink with 10%PULink. The results indicate that
although the highest recall of 10%PULink is 3.33% lower than
that of 40%FRLink, the performance of 10%PULink, withinthe highest recall it can reach, is superior to 40%FRLink .
Ov
erall, in most cases, PULink can achieve a much better
performance compared to FRLink when only a small amount
of positive links remain in the training data. PULink can get
a comparable performance as FRLink when the positive links
required by PULink is 30% less than that of FRLink.
4) Important Features: We use the Gain Ratio [11] to
evaluate the contribution of the eight extracted features in
PULink. A larger Gain Ratio value indicates that the feature
is more effective in recovering missing links.
According to the effectiveness in recovering missing links,
the eight features are sorted by importance from high to
low: SimV al, SimByIssue, SimByCommit, Interval, SimSource,
IntervalType, CommitType, and IssueType. The most important
three features are all from similarity features. Compared to
metadata features, similarity features are more effective in
recovering missing links. Although similarity features areimportant in all projects, the signiﬁcance order of the speciﬁcsimilarity features is different for each project.
V. R
ELATED WORK
Missing links between issue reports and commits can cause
negative impacts on maintenance activities [3]. In release
151
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:48:35 UTC from IEEE Xplore.  Restrictions apply. Figure 4. Performance comparison between PULink and FRLink when 10% – 90% positive links remain in training data
Figure 5. Positive links required by each approach when PULink and FRLink
get comparable performance
documents, important information about changes may be left
out. Consequently, maintenance cost can be raised as usersmay get incorrect expectations on software behaviors [2].Results in commit analysis studies can be inaccurate and havelimited generalizability due to the missing link problems [3].Models of prediction (e.g., defect prediction and bug ﬁx time
prediction) or recommendation (e.g., bug localization and bug
ﬁxer recommendation) may suffer from performance loss orevaluation biases [1, 3] if built on low quality link data.
Consider the impact of missing link problems in software
maintenance, many approaches have been proposed to recovermissing links. These existing approaches, such as ReLink [1],
MLink [5], RCLinker [6], and FRLink [7], were built based
on positive and negative links. However, for problems that donot have explicitly negative data, many studies have shownthat considering as an learning problem using positive andunlabeled data would be a better choice [8].
VI. C
ONCLUSION
This paper presents a new approach, PULink, built on pos-
itive and unlabeled links. PULink is evaluated in 12 projectsand the experiment results show that it can effectively recovermissing links from those projects. We also compare PULink
against FRLink, which is the state-of-the-art technique. As a
result, with only 70% of the positive links as used in FRLink,
PULink has competitive performance compared to FRLink.
A
CKNOWLEDGMENTS
This work is supported by National Natural Science Foun-
dation of China under Grant Nos. 61432001, 61602450.
REFERENCES
[1] R. Wu, H. Zhang, S. Kim, and S.-C. Cheung, “Relink: recovering links
between bugs and changes,” in FSE’11, 2011, pp. 15–25.
[2] A. Bachmann and A. Bernstein, “Software process data quality and
characteristics: a historical view on open and closed source projects,” in
IWPSE/Evol’09, pp. 119–128.
[3] A. Bachmann, C. Bird, F. Rahman, P. Devanbu, and A. Bernstein, “The
missing links: bugs and bug-ﬁx commits,” in FSE’10, 2010, pp. 97–106.
[4] C. Brindescu, M. Codoban, S. Shmarkatiuk, and D. Dig, “How do
centralized and distributed version control systems impact softwarechanges?” in ICSE’14, pp. 322–333.
[5] A. T. Nguyen, T. T. Nguyen, H. A. Nguyen, and T. N. Nguyen, “Multi-
layered approach for recovering links between bug reports and ﬁxes,”inFSE’12, 2012, p. 63.
[6] T.-D. Le, M. Linares-Vasquez, D. Lo, and D. Poshyvanyk, “Rclinker:
Automated linking of issue reports and commits leveraging rich contex-tual information,” in ICPC’15, 2015, pp. 36–47.
[7] Y . Sun, Q. Wang, and Y . Yang, “Frlink: Improving the recovery of
missing issue-commit links by revisiting ﬁle relevance,” Information and
Software Technology, vol. 84, pp. 33–47, 2016.
[8] C. Elkan and K. Noto, “Learning classiﬁers from only positive and
unlabeled data,” in KDD ’08, pp. 213–220.
[9] A. Mockus and L. G. V otta, “Identifying reasons for software changes
using historic databases,” in ICSM’00, 2000, pp. 120–130.
[10] Y . Sun, Q. Wang, and M. S. Li, “Understanding the contribution of
non-source documents in improving missing link recovery: An empiricalstudy,” in ESEM ’16, pp. 39:1–39:10.
[11] I. H. Witten, E. Frank, and M. A. Hall, Data Mining: Practical Machine
Learning Tools and Techniques, 3rd ed. Morgan Kaufmann Publishers
Inc., 2011.
152
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:48:35 UTC from IEEE Xplore.  Restrictions apply. 