Craig vs. Newton in Software Model Checking
Daniel Dietsch
University of Freiburg
dietsch@cs.uni-freiburg.deMatthias Heizmann
University of Freiburg
heizmann@cs.uni-freiburg.deBetim Musa
University of Freiburg
musab@cs.uni-freiburg.de
Alexander Nutz
University of Freiburg
nutz@cs.uni-freiburg.deAndreas Podelski
University of Freiburg
podelski@cs.uni-freiburg.de
ABSTRACT
Ever since the seminal work on SLAM and BLAST, software model
checking with counterexample-guided abstraction refinement (CE-
GAR) has been an active topic of research. The crucial procedure
here is to analyze a sequence of program statements (the counterex-
ample ) to find building blocks for the overall proof of the program.
We can distinguish two approaches (which we name Craig andNew-
ton) to implement the procedure. The historically first approach,
Newton (named after the tool Newton from the SLAM toolkit),
is based on symbolic execution. The second approach, Craig , is
based on Craig interpolation . It was widely believed that Craig is
substantially more effective than Newton. In fact, 12 out of the 15
CEGAR-based tools in SV-COMP are based on Craig. Advances
in software model checkers based on Craig, however, can go only
lockstep with advances in SMT solvers with Craig interpolation.
It may be time to revisit Newton and ask whether Newton can
be as effective as Craig. We have implemented a total of 11 vari-
ants of Craig and Newton in two different state-of-the-art software
model checking tools and present the outcome of our experimental
comparison.
CCS CONCEPTS
•Software and its engineering →Formal software verifica-
tion;•Mathematics of computing →Interpolation ;
KEYWORDS
Formal Verification, Craig Interpolation, Unsatisfiable Cores
ACM Reference format:
Daniel Dietsch, Matthias Heizmann, Betim Musa, Alexander Nutz, and An-
dreas Podelski. 2017. Craig vs. Newton in Software Model Checking. In
Proceedings of 2017 11th Joint Meeting of the European Software Engineering
Conference and the ACM SIGSOFT Symposium on the Foundations of Soft-
ware Engineering, Paderborn, Germany, September 4–8, 2017 (ESEC/FSE’17),
11 pages.
https://doi.org/10.1145/3106237.3106307
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany
©2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-5105-8/17/09. . . $15.00
https://doi.org/10.1145/3106237.31063071 INTRODUCTION
Ever since the seminal work on automatic predicate abstraction
of C programs in the SLAM toolkit [ 4], software model checking
has been an active topic of research [ 2,9,10,17,22,27,30–32,34,
36,39,45,48,49,51]. There have been several variations, but the
basic idea of counterexample-guided abstraction refinement (CEGAR)
remains often the same. The idea is to use the correctness proof of
a sequence of program statements (the spurious counterexample)
to find building blocks for the overall proof of the program.
The building blocks (often called predicates ) are extracted by a
procedure that de-assembles the correctness proof of the sequence
of program statements. It is this procedure which is crucial for
the effectiveness of CEGAR-based software model checking. It is
crucial because, without finding the right predicates, the CEGAR
loop must diverge (the predicates extracted so far must be sufficient
to assemble a correctness proof of the program).
In this paper, we present an experimental assessment of two pos-
sible approaches which we name Craig andNewton , respectively.
The name Newton refers to a variant of the approach which was
implemented already in Newton [5]. The original version of New-
ton is based on symbolic execution (here, the symbolic execution
of the sequence of statements in the counterexample). Historically,
Newton is the first approach for extracting predicates from coun-
terexamples. It was used also in the first version of BLAST [ 37].
However, a subsequent version of BLAST [ 36] introduced the ap-
proach which is based on Craig interpolation [43]. Since then, it was
widely believed that Craig is substantially more effective than New-
ton. In fact, 12 out of the 15 CEGAR-based tools in SV-COMP are
based on Craig [ 7]. The rationale is that, in contrast with Newton,
Craig can discover the right predicates that go beyond the syntax
of the program. The work on IMPACT in [ 45] has shown that the
predicates produced by an SMT solver with Craig interpolation can
even be used directly ,i.e., without disassembling them further as it
was done in SLAM and BLAST, following the scheme of predicate
abstraction . Their use as a module in software model checkers has
been a major motivation for very active research on SMT solvers
with Craig interpolation (see, e.g., [ 3,15,18,29,44,50]), with more
and more support for theories to cope with data structures such as
arrays and floats [ 14,26,28]. It must be said, however, that the sup-
port of theories in procedures for Craig interpolation generally lags
behind (relative to procedures for checking satisfiability). Hence, it
may be time to revisit Newton and ask whether Newton can be as
effective as Craig.
We have implemented a series of variants of software model
checking which arise from different variants of the two approaches.
487
ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany D. Dietsch, M. Heizmann, B. Musa, A. Nutz, A. Podelski
procedure example1 (){
var a,b : [ int]bool ;
var p,x : int;
ℓ0 b := a;
ℓ1 x := 0;
while (*) {
ℓ2 havoc p;
ℓ3 assume !a[p];
ℓ4 a[p] := true ;
ℓ5 x := x + 1;
ℓ6 a[p] := false ;
}
assert a == b;
}
ℓ0
ℓ1
ℓ2ℓ3
ℓ4
ℓ5
ℓ6 ℓerrb:=a
x:=0havoc p!a[p]
a[p]:=true
x:=x+1
a[p]:=falsea!=b
Figure 1: Code and control flow graph of a program. The vari-
ables aand bare arrays with integer indices and Boolean
values. The condition of the while loop *represents a non-
deterministic choice. The specification is given by the assert
statement in the last line and states that the arrays aand b
store the same values.
This allows us to compare them in an experimental evaluation. In
both approaches, Craig and Newton, we can translate a sequence
of statements (here, from the possibly spurious counterexample) to
an conjunction of logical formulas (the conjunction is unsatisfiable
if the counterexample is spurious). Craig then computes a sequence
of Craig interpolants [ 40] along the conjunction using an interpo-
lating SMT solver and considers each interpolant as a predicate at
the corresponding position of the statement sequence. Newton uses
thepost (orwp) predicate transformer instead of Craig interpolants
to compute predicates for each position. As expected, this leads
to rather concrete predicates, which are mostly useless for com-
plex programs. Thus, instead of applying the predicate transformer
directly on the counterexample, Newton first computes an abstrac-
tion of the counterexample. The crux is to find a coarse abstraction
that is precise enough to preserve the spuriousness of the coun-
terexample. In our implementation the abstraction is computed
by projecting all statements away that are not contained in the
unsatisfiable core of the logical formula of the full counterexample.
2 EXAMPLE
We will give a formal account of the Newton approach (in the ver-
sion presented in [ 5]) and variants in the subsequent sections. In
this section, we give an example to illustrate the approach. Figure 1
shows a condensed version of a larger verification problem (en-
coding the check whether a C program has a memory leak). The
array astores which addresses on the heap are allocated. Its indices
are pointers and its values are Booleans. The statements at the
locations ℓ2−ℓ4encode memory allocation. A non-deterministic
address ( havoc p ) that is not yet allocated ( !a[p] ) is taken and
it is stored that this address is now allocated ( a[p]:=true ). The
statement at the location ℓ6encodes memory deallocation: it stores
that the address pis not allocated anymore ( a[p]:=false ). This
program is written in the Boogie [ 42] language. Hence the state-
ment at ℓ0assigns to the array ba copy of the array a. The assertstatement at the end holds if the array aand the array bstore the
same values at the same positions, i.e., if each allocated memory
cell was deallocated.
Following the algorithm of a model checker we analyze the cor-
rectness of this program as follows. First, we pick some error trace
(i.e., some sequence of statements that starts at the initial location
and ends at the error location). Let us take the trace depicted in
the first column of Figure 2 which takes the while loop once. We
analyze this trace and find that it is infeasible. Next, we construct
a proof for the infeasibility of this trace and try to generalize this
proof to an infeasibility proof for all error traces of this program.
A naive approach for this generalization is computing a sequence
of assertions along this trace using the post operator. The resulting
sequence of state assertions is depicted in the second column of
Figure 2. The assertion φ7before the statement a!=b does not
imply the state assertion φ2after the statement x:=0 . Hence the
state assertion φ2is not a loop invariant and we fail to generalize
this infeasibility proof.
Now, we augment the generation of state assertions by exploit-
ing unsatisfiable core information that we can get from the SMT
solver. First, we detect the core reason for the infeasibility of τby
constructing the trace formula for the trace τand using an SMT
solver to compute an unsatisfiable core of this formula. Here, the
unsatisfiable core does not contain the conjuncts of the trace for-
mula that correspond to the two assignments to x(st2andst6). We
conclude that both statements are irrelevant for the infeasibility of
τand construct an abstraction τ#of the trace τ. This abstraction is
depicted in the third column of Figure 2 and obtained by abstracting
each statement that is irrelevant for the infeasibility of τ–x:=0
and x:=x+1 – by havoc x . We call the trace τ#an infeasible
core ofτsince it abstracts τonly to an extent that preserves a rea-
son for infeasibility of τ. Next, we use the post operator to compute
a sequence of assertions along the infeasible core τ#. The resulting
sequence is depicted in the last column of Figure 2 and satisfies the
following three properties.
(1)The assertion φ7implies the assertion φ2, i.e.,φ2is a loop
invariant.
(2)The last assertion is false. This means that this sequence
of assertions is a proof for the infeasibility of τ#.
(3)Since the infeasible core τ#is an abstraction of the trace τ
this sequence of assertions is also a proof for the infeasi-
bility ofτ.
From these three properties we conclude that all error traces
of the program depicted in Figure 1 are infeasible and hence the
program is correct. Note that the statements x:=0 and x++
represent the case where some statements make it difficult to find
a loop invariant but do not affect the correctness of the program.
In general, more statements are irrelevant for the infeasibility of a
trace.
3 INDUCTIVE SEQUENCE OF ASSERTIONS
FOR A TRACE
In this section we fix the notation and the terminology for the cen-
tral notion discussed in this work, which is a sequence of assertions
that represents a proof for the infeasibility of a trace.
488Craig vs. Newton in Software Model Checking ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany
trace τ
b:=a st1
x:=0 st2
havoc p st3
!a[p] st4
a[p]:=true st5
x:=x+1 st6
a[p]:=false st7
a!=b st8state assertions
forτ
trueφ0
a=b φ1
a=b∧x=0 φ2
a=b∧x=0 φ3
a=b∧x=0∧a[p]=f alse φ4
a=b[p:=true] ∧x=0∧a[p]=true φ5
a=b[p:=true] ∧x=1∧a[p]=true φ6
a=b∧x=1∧a[p]=f alse φ7
f alseφ8interpolating
trace τ#
b:=a
havoc x
havoc p
!a[p]
a[p]:=true
havoc x
a[p]:=false
a!=bstate assertions
forτ#
trueφ0
a=b φ1
a=b φ2
a=b φ3
a=b∧a[p]=f alse φ4
a=b[p:=true] ∧a[p]=true φ5
a=b[p:=true] ∧a[p]=true φ6
a=b∧a[p]=f alse φ7
f alseφ8
Figure 2: The first column shows a trace taken from the program in Figure 1. The third column shows an infeasible core of the
traceτ. This abstraction of τis obtained by abstracting x:=0 by havoc x and x:=x+1 by havoc x . The second and the
last column show the sequence of state assertions obtained by iteratively applying post to theτandτ#, respectively. In both
columns the sequences are slightly interleaved to emphasize that assertion φiholds after the execution of statement sti.
In our formal presentation we consider a programming language
that consists of three different types of statements, namely
•assume statements, denoted by assumeψ, whereψis a
Boolean expression over the set program variables Var,
•assignment statements, denoted by x:=e , where xis
a program variable an eis a expression over the set of
program variables, and
•havoc statements, denoted by havoc x , where xis a
program variable.
The havoc statement assigns non-deterministically some value to
a variable and is used e.g., to model input that is read during a
program execution. We represent an assert statement by an assume
statement whose successor location in the control flow graph is an
error location. We use first-order formulas over program variables
to denote assertions. Each statement has the usual semantics, which
we can define formally using the post operator.
post(φ,assumeψ)=φ∧ψ
post(φ,x:=e) =∃x0.x=e[x7→x0]∧φ[x7→x0],
where x0is a fresh variable
post(φ,havoc x) =∃x.φ
We call a sequence of statements τ=st1, . . . , stnatrace . Given
a traceτ, we define the sequence of assertions that we obtain by
applying the post operator successively along the statements in the
traceτ, starting with the assertion true.
Definition 3.1 (Sequence of assertions computed by post for a trace).
The sequence of assertions computed by post for the trace τ=
st1, . . . , stnis the sequence φ0, . . . ,φndefined as follows.
φ0 = true,
φi+1=post(φi,sti+1)fori=0, . . . , n−1The postcondition of the trace τis the last assertion in the se-
quence above, i.e., post(true,τ)=ϕn.
As usual, we call a trace infeasible if it does not correspond to a
possible program execution. This is equivalent to the fact that the
postcondition of the trace is false, i.e., a trace τis infeasible if and
only if post(true,τ)=false.
A proof for the infeasibility of a trace can thus be given by the
sequence of assertions computed by post for the trace – if the trace
is infeasible, the last assertion in the sequence is necessarily false.
If the trace is of the form τ=st1, . . . , stn, then the intermediate
assertions are of the form post(true,st1, . . . , sti), fori=1, . . . , n−1.
We now consider proofs for the infeasibility of a trace in a more
general form of sequences where the intermediate assertions can
be weaker than post(true,st1, . . . , sti).
Definition 3.2 (Inductive sequence of assertions). The sequence
of assertions φ0, . . . ,φnisinductive for the trace τ=st1, . . . , stnif
the following three conditions hold:
(1) the sequence starts with true, i.e.,φ0=true,
(2)the sequence is inductive, i.e., post(φi,sti+1)⇒φi+1for
i=0, . . . , n−1,
(3) the sequence ends with false, i.e.,φn=false.
Ifφ0, . . . ,φnis an inductive sequence for the trace τ=st1, . . . , stn,
then post(true,st1, . . . , sti)(the postcondition of the i-th prefix of
the trace) entails φifori=1, . . . , n−1. The converse is generally
not true.
Remark 1. A trace is infeasible if and only if the sequence of
assertions computed by post for the trace is an inductive sequence
of state assertions for the trace.
An example for an inductive sequence of assertions computed
by post for an infeasible trace is given in the second column of
489ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany D. Dietsch, M. Heizmann, B. Musa, A. Nutz, A. Podelski
Figure 2. We can compute an inductive sequence of assertions via
Craig interpolation by encoding the sequence of statements as a
conjunction of formulas [40].
4 INFEASIBLE CORES
In this section we define an abstraction of a trace that is precise
enough to preserve infeasibility and we show how we use this
abstraction to compute an inductive sequence of assertions.
Definition 4.1 (Abstraction of a statement). We define the abstrac-
tion of a statement stas follows.
abstract(st)= 
assume true ifstis of the form assumeψ
havoc x ifstis of the form x:=e
havoc x ifstis of the form havoc x
Remark 2 (Soundness) .For each statement stand each assertion
φthe implication post(φ,st)⇒ post(φ,abstract(st))holds.
One may wonder if a “skip statement” like assume true is also a
sound abstraction of an assignment statement. This is not the case,
since an assume statement guarantees that no variable is modified.
Definition 4.2 (Abstraction of a trace). We call a trace τ#=st#
1, . . .st#n
anabstraction of a trace τ=st1, . . .stnif each st#
iis either the state-
ment stior the abstraction abstract(sti).
Remark 3 (Soundness) .If the trace τ#=st#
1, . . .st#nis an abstrac-
tion ofτ=st1, . . .stnthen the implication post(φ,st1. . .sti)⇒
post(φ,st#
1. . .st#
i)holds for each index iand each assertion φ.
Definition 4.3 (Infeasible core). We call an abstraction τ#of an
infeasible trace τaninfeasible core ifτ#is infeasible.
The traceτ#depicted in the third column of Figure 2 is an infea-
sible core of the trace τdepicted in the first column of Figure 2.
Lemma 4.4. Given an infeasible core τ#=st1, . . . , stnof an infea-
sible traceτ, the sequence of assertions φ0, . . . ,φncomputed by post,
i.e.,φ0:=true,φi:=post(true,st1. . .sti)is an inductive sequence
of assertions for the trace τ.
Proof. By Remark 1 the sequence of assertions computed by
post is an inductive sequence of assertions for τ#. Since theτ#is an
abstraction of τwe can use Remark 3 to conclude that it is also an
inductive sequence of assertions for τ. We use Remark 2 to prove
Remark 3 by induction. 
4.1 Infeasible Cores from Unsatisfiable Cores
Given a trace τ=st1, . . . , stnwe construct the trace formula Fas
the conjunction F1∧. . .∧Fnwhere each conjunct Fiis defined as
follows.
Fi= 
rename i(ψ) ifstiisassumeψ
xi=rename i(e)ifstiisx:=e
true ifstiishavoc x
The function rename i(φ)replaces each variable xin the formula φ
by the “indexed” variable xk, where the index kis the last position
where xwas modified. We use the following function index(x,i)to
define the index k=index(x,i)formally.
index(x,i)= 
0 ifi=0
i ifstiisx:=e orhavoc x
index(x,i−1)otherwiseRemark 4. The traceτ=st1, . . . , stnis infeasible if and only if its
trace formula F=F1∧. . .∧Fnis unsatisfiable.
Proof. We show by induction that for all 0≤i≤nthe implica-
tionF1∧. . .∧Fi⇒rename i(post(true,st1. . .sti))holds. 
Given an unsatisfiable conjunction of formulas F1∧···∧ Fn, an
unsatisfiable core UCis a subset of conjuncts UC⊆{F1, . . . , Fn}
such that the conjunction of all conjuncts in the unsatisfiable core
UCis unsatisfiable. We note that an unsatisfiable core is neither
required to be minimal nor unique, e.g., the set of all conjuncts
{F1, . . . , Fn}is always an unsatisfiable core.
Next, we define our abstraction of an infeasible trace for a given
unsatisfiable core of its trace formula. The idea is to replace each
statement in the trace by its abstraction (i.e., havoc orassume
true ) if the unsatisfiable core of the trace formula has dropped the
conjunct corresponding to the statement.
Definition 4.5 (Abstract trace τ#for an unsatisfiable core UC).
Given an unsatisfiable core UCfor the trace formula F=F1∧···∧ Fn
of the infeasible trace τ=st1, . . . , stn, the abstract trace of τforUC
is the trace τ#=st#
1, . . . , st#nwhere the statement st#
iis defined as
follows.
st#
i=(
sti ifFi∈UC
abstract(sti)otherwise
Remark 5. An abstract trace τ#defined by an unsatisfiable core
UCis an infeasible core.
Proof. LetF=F1∧. . .∧Fnbe the trace formula of τ, let
UC⊆{F1, . . . , Fn}be the unsatisfiable core that defines τ#. The
trace formula of τ#isF′=F′
1∧. . .∧F′n, where each Fiis defined
as follows.
F′
i=(
Fi ifFi∈UC
true otherwise
Since the conjunction of all formulas in UCis unsatisfiable the trace
τ#is infeasible. 
4.2 Backward Analysis
In this subsection we demonstrate how one can use, analogously
topost, the weakest precondition wpto construct an inductive
sequence of assertions.
As usual, we define the weakest precondition wpdually to post,
which means that the equivalence post(φ,st)→φ′⇔φ→
wp(φ′,st)holds and for our three kinds of statements the following
equalities hold.
wp(φ,assumeψ)=ψ→φ
wp(φ,x:=e) =φ[x7→e],
wp(φ,havoc x) =∀x.φ
Inductively, the definition of wpis lifted to traces.
wp(φ,st1. . .stn)=wp(wp(φ,stn),st1. . .stn−1)
Remark 6. A traceτis infeasible iff wp(false,τ)=true
Definition 4.6 (Sequence of assertions computed by wpfor a trace).
Thesequence of assertions computed by wpfor the trace τ=st1, . . . , stn
is the sequence φ0, . . . ,φndefined as follows.
φn= false,
φi=wp(φi+1,sti+1)fori=0, . . . , n−1
490Craig vs. Newton in Software Model Checking ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany
var k,y : int;
k := 0;
assume y >= k;
while (*) {
k := 1;
y := y + k;
}
assert y >= 0;
k:=0
y>=k
k:=1
y:=y+k
y>0trueφ0
k=0 φ1
k=0∧y≥k φ2
k=1∧y≥0 φ3
k=1∧y≥1 φ4
f alseφ5
Figure 3: Example program and trace of that program. Note
that kis not live at position 2in the trace, but it occurs in φ2.
Lemma 4.7. Given an infeasible core τ#=st1, . . . , stnof an infea-
sible traceτ, the sequence of assertions φ0, . . . ,φncomputed by wp,
i.e.,φn:=f alse ,φi:=wp(f alse ,sti. . .stn)is an inductive sequence
of assertions for the trace τ.
5 LIVE VARIABLES
We can optimize inductive sequences of assertions based on the idea
of live variables. Our goal is to transform the assertion sequence
such that it is more likely to contain loop invariants.
Figure 3 shows a program on the left and a trace τof the pro-
gram on the right. Next to τis the sequence of inductive assertions
computed by post. Note that τhas only one infeasible core, which
isτitself, and that neither the assertion φ2at the loop entry, nor
the assertion φ4at the loop exit are loop invariants. Furthermore,
the value of kat position 2 will never be used because it is over-
written by k:=1 . In such a case, our optimization existentially
quantifies the variable in this assertion. The resulting formula,
∃k.k=0∧y≥k≡y≥0is a loop invariant.
5.1 Future-Live and Past-Live Variables
In the following we will introduce the notions of future-live and
past-live variables. Intuitively, a variable is future live at a position
in a trace, if its current value will be read later in the trace. A variable
is past-live at a position in a trace, if its current value was written
or read at an earlier position in the trace. We say that a statement
stwrites a variable x, ifsthas the form x:=e . We say that a
statement streads a variable x, ifsthas the form y:=e or the
form assume e where xoccurs in e. We say that the statement
havoc x havocs x.
Definition 5.1 (Future-live and past-live). Letτ=st1, . . . , stnbe
a trace. We call a variable xfuture-live inτat position iif there is
a statement stjinτwith j>i, and stjreads x, and for all kwith
i<k<jthe statement stkneither writes nor havocs x. We call
a variable xpast-live inτatiif there is a statement stjinτwith
j≤i, such that stjwrites xor reads x, and for all kwith j<k≤i
the statement stkdoes not havoc x. We denote the set of future-live
variables at position iinτasFLτ(i)and the the set of past-live
variables atiinτasPLτ(i). Formally:
FLτ(i)={x∈Var|xis future-live in τati}
PLτ(i)={x∈Var|xis past-live in τati}Definition 5.2 (Projection to future-/past-live variables). Letφbe
an assertion and let V⊆Varbe a set of program variables. Let
V=Var\Vbe the complement of VinVar. The existential projection
ofφtoVis the existential quantification of φby all variables in V.
ep(φ,V)=∃v1, . . . ,vn.φwhere{v1, . . . ,vn}=V
Analogously, the universal-projection ofφtoVis the universal
quantification of φby all the variables in V.
up(φ,V)=∀v1, . . . ,vn.φwhere{v1, . . . ,vn}=V
Lemma 5.3 (Projection preserves inductivity). Letτ=st1. . .stn
be a trace. Let A=φ0, . . . ,φnbe an inductive sequence of assertions
forτ. Then the following two sequences of assertions are also inductive.
ep(φ0,FLτ(0)), . . . , ep(φn,FLτ(n))
up(φ0,PLτ(0)), . . . , up(φn,PLτ(n))
Proof. Conditions 1. and 3. are met trivially because quantifi-
cation has no effect on trueorfalse.post(ep(φi,FLτ(i)),sti+1)⇒
ep(φi+1,FLτ(i+1))is proven by induction and case distinction on
the type of the statement sti, where we use the following fact. If
the variable x is read at position i+1and there is a k≤isuch that
x is not live at all positions from ktoithen x cannot occur in the
subsequence φk, . . . ,φi. The proof for wp, with upandPLworks
analogously. 
6 ALGORITHM
In this section we describe a Newton-inspired algorithm for com-
puting an inductive sequence of assertions φ0, . . . ,φnfor a given
infeasible trace τ=st1, . . . , stn.
This algorithm comes in eight different variants described by
the following steps. The steps with a bold abbreviation in front
of their description are optional. Step 2 is optional, for step 3 one
may choose (a) or (b), and step 4 is optional again. 4(a) can only be
applied if 3(a) has been chosen, and analogously, 4(b) can only be
applied if 3(b) has been chosen.
(1) Compute trace formula F=F1∧. . .∧Fnof the trace τ.
(2)ITOptionally, let an SMT solver compute an unsatisfiable
core UC⊆{F1, . . . , Fn}for the trace formula F.
Compute the abstract trace τ#ofτforUCand use it instead
ofτfor the remaining computations.
(3) Execute one of the following:
(a)SPCompute post along the trace st1, . . . , stn, i.e., set
φ0totrue andφitopost(φi−1,sti)for1≤i≤n.
(b)WP Compute wpalong the trace st1, . . . , stn, i.e., set
φntof alse andφitowp(φi+1,sti+1)for0≤i≤n−1.
(4)LV Optionally and depending on the choice in step 3.,
execute one of the following
(a)For each position i, compute the set of future-live vari-
ables FLτ(i). Project each assertion φito the variables
that are future-live in τat position i.
(b)For each position i, compute the set of past-live vari-
ables PLτ(i). Project each assertion φito the variables
that are past-live in τat position i.
491ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany D. Dietsch, M. Heizmann, B. Musa, A. Nutz, A. Podelski
7 IMPLEMENTATION AND EVALUATION
We implemented the eight Newton variations in the software model
checkers provided by the open-source program analysis framework
Ultimate1and ran experiments with two state-of-the-art software
model checkers, Ultimate Automizer andUltimate Kojak .
Ultimate Automizer [32] combines counter-example guided ab-
straction refinement with proof generalization based on automata [ 35],
while Ultimate Kojak [49] is based on lazy abstraction with in-
terpolants through graph splitting [ 24,25]. We implemented the
Newton algorithm variants as alternative source of state assertions
during the trace infeasibility check of the tool.
Both tools can be applied to C programs. In a first preprocessing
step, the C program is translated into a Boogie program [ 42]. After-
wards we apply a procedure inlining, which allows us to directly
handle programs with procedures. The resulting Boogie program
uses arrays to model the heap of the system, hence an SMT solver
that supports arrays can be necessary even if the C program does
not contain any arrays. Arrays also introduce quantified formulas,
and since quantified formulas are known to be difficult for SMT
solvers we implemented various simple preprocessing steps that
try to eliminate quantifiers. The two most noteworthy steps of our
partial quantifier elimination make use of the following two facts.
Destructive Equality Resolution (DER) ∃x.x=t∧φis equiv-
alent toφ[x7→t]iftdoes not contain x.
Unconnected Parameter Drop (UPD) ∃v1, . . .∃vn.φ1∧φ2is
equivalent to φ1ifφ2is satisfiable and each symbol that
occurs inφ2is an element of{v1, . . .vn}that does not
occur inφ1or a symbol that occurs in a theory axiom.
For our experimental evaluation, we applied both tools to a large
set of C programs taken from the repository2of the software verifi-
cation competition SV-COMP 2017 [ 8]. Based on those programs,
we created the following three benchmark sets.
Bitvector consists of 264 verification tasks that describe a single
reachability problem. They are taken randomly from the five SV-
COMP subcategories ReachSafety-Arrays, ReachSafety-BitVectors,
ReachSafety-Heap, ReachSafety-ControlFlow, and Systems_Device-
DriversLinux64_ReachSafety. We configured both tools to use a
bit-precise analysis and the Bitvector theory.
Integer consists of the same verification tasks as Bitvector , but
this time the tools were configured to use unbounded integers and
overapproximate bit-wise operations. Hence, the theory of bitvec-
tors was not needed. Note that if an overappoximated violation is
found, the tools give up and report “unknown” as a result.
Memsafety contains 188 verification tasks that require the tools
to prove the absence of memory leaks, i.e., memory safety. They are
randomly and evenly selected from the two SV-COMP subcategories
MemSafety-Arrays and MemSafety-Heap. Ultimate ’s preprocess-
ing encodes the memory safety property as the (in)equality of two
arrays that track the state of the heap of the C program (the ex-
ample from Figure 2 shows such an encoding). A violation of the
specification is expressed by the two arrays being different, thus
often requiring array extensionality.
Float contains 129 verification tasks that, again, describe a single
reachability problem. They represent the SV-COMP subcategory
1https://ultimate.informatik.uni-freiburg.de
2https://svn.sosy-lab.org/software/sv-benchmarks/tags/svcomp17ReachSafety-Floats. These programs contain IEEE floating point
operations and thus require the theory of floating-point arithmetic,
which is notoriously difficult for SMT solvers. Furthermore, many
of the programs do not contain loops.
Both tools use two different SMT solver instances. The auxiliary
solver is used for simplification and unification of formulas and
for other optimizations where an “Unknown” result does not lead
to the failure of the whole verification algorithm. The trace solver
is used exclusively to decide feasibility of traces and, if enabled,
to generate Craig interpolants that can be used as an inductive
sequence of assertions.
We configured both tools to always use Z33[23,46] as auxiliary
solver. The computation of an inductive sequence of assertions
was done by either an interpolating SMT solver or one variant of
the Newton algorithm. In order to minimize the influence of the
solver on the algorithm, we compared one variant of Newton with
different solvers. We chose SMT solvers based on their capabilities
and the benchmark set. Princess is unable to compute unsatisfiable
cores, but supports the theory of arrays and is able to compute
Craig interpolants. SMTInterpol is able to compute unsatisfiable
cores and interpolants, but is yet unable to compute interpolants
that contain arrays and does not support quantified formulas. Z3is
able to compute Craig interpolants, unsatisfiable cores and supports
quantified formulas. Neither Princess norSMTInterpol support
interpolation for the theory of bitvectors. The solvers CVC4 and
Mathsat both support arrays and bitvectors and can produce un-
satisfiable cores. CVC4 can handle quantified formulas, Mathsat
is restricted to formulas that do not contain nested arrays.
Hence, we used either Princess4[16],SMTInterpol5[19], orZ3
for Craig interpolation. For computing unsatisfiable cores we used
either CVC46[6],Mathsat7[21],SMTInterpol orZ3. We always
used the unsatisfiable core that was provided by the solver after
calling (get-unsat-core) . We used version 1.5 r4671 of CVC4 ,
84cb666a6c83 of Mathsat , build 2016-12-26 of Princess , 2.1-327-
g92cafef of SMTInterpol , and master bfd1bbc13 of Z3.
The hard timeout for all benchmark was 120 seconds. Auxiliary
solvers had a time limit of 2s except for the benchmark set Float ,
where we increased the limit to 12s due to the complexity of the
theory of floats. Each auxiliary solver had a memory limit of 2GB
and the software model checkers had a separate memory limit of
6GB. We ran the benchmark sets on an Intel i7-4790 with 3.6GHz.
7.1 Discussion of Evaluation Results
Table 1 shows the qualitative results of the evaluation. Based on
these numbers we can see that the Newton variant that combines
strongest post, unsatisfiable cores and live variables (IT-SP-LV)
outperforms Craig interpolation on all benchmark sets while being
applicable to all scenarios when choosing an appropriate SMT solver
(e.g., Mathsat orZ3). If we compare the portfolios against each
other or Z3IT-SP-LV against Z3with interpolation we see that
variations of Newton, especially the IT-SP-LV variant, can solve
substantially more tasks than Craig interpolation-based techniques.
3https://github.com/Z3Prover/z3
4http://www.philipp.ruemmer.org/princess.shtml
5https://ultimate.informatik.uni-freiburg.de/smtinterpol
6https://cvc4.cs.nyu.edu
7http://mathsat.fbk.eu
492Craig vs. Newton in Software Model Checking ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany
Table 1: The evaluation results. The columns contain for each tool, Ultimate Automizer andUltimate Kojak , the four
benchmark sets and the sum of all four sets. Rows are split into 5 groups. The first group contains the size of the benchmark
sets. In all following groups each cell contains the number of verification tasks this particular configuration could solve. The
number in parenthesis shows how many tasks were solved exclusively by this configuration. The second group contains the
results for configurations where Craig was used as source for inductive state assertions. The third and fourth group show the
results for the different Newton variants. We refer to these variants based on the options we chose with SP or WP and the
presence or absence of IT and LV. For IT-SP-LV, we prefixed the name with the used trace solver. The fifth group contains
portfolios , i.e., how many verification tasks could be solved by any of the configurations using Craig interpolation ( PCraiд),
IT-SP-LV ( P⋆+IT−SP−LV), or all variants ( PAll), respectively. The difference between the total number of tasks and the number
of solved tasks is due to timeouts or unknowns.
Automizer Kojak
Bitvector Integer Memsafety FloatÍBitvector Integer Memsafety FloatÍ
No. of tasks 264 264 188 129 845 264 264 188 129 845
Princess – 100 (0) 62 (3) – 162 (3) – 39 (0) 28 (0) – 67 (0)
Z3 70 (0) 125 (1) 49 (2) – 244 (3) 27 (0) 50 (1) 34 (3) – 111 (4)
SMTInterpol – 139 (4) 24 (0) – 163 (4) – 49 (1) 29 (0) – 78 (1)
CVC4 IT-SP-LV 112 (4) 106 (1) 67 (0) – 285 (5) 54 (0) 54 (0) 45 (0) – 153 (0)
Mathsat IT-SP-LV 105 (1) 117 (0) 78 (1) 53 (14) 353 (16) 50 (0) 56 (0) 47 (1) 45 (4) 198 (5)
SMTInterpol IT-SP-LV – 137 (2) 77 (2) – 214 (4) – 56 (0) 47 (0) – 103 (0)
Z3IT-SP-LV 107 (0) 119 (0) 81 (0) 44 (0) 351 (0) 48 (0) 58 (0) 48 (0) 45 (0) 199 (0)
IT-WP-LV 111 (0) 117 (0) 66 (0) 43 (0) 337 (2) 56 (0) 52 (0) 57 (0) 43 (0) 208 (0)
IT-SP 107 (1) 116 (0) 81 (0) 45 (0) 349 (1) 49 (0) 53 (0) 64 (0) 44 (0) 210 (0)
IT-WP 111 (0) 116 (0) 60 (0) 45 (1) 332 (1) 54 (0) 50 (0) 61 (0) 46 (0) 211 (0)
SP-LV 63 (0) 67 (0) 65 (0) 44 (0) 239 (0) 45 (0) 47 (0) 59 (0) 44 (0) 195 (0)
WP-LV 79 (0) 76 (0) 45 (0) 45 (1) 245 (1) 51 (0) 49 (0) 42 (0) 45 (0) 187 (0)
SP 45 (0) 48 (0) 64 (0) 43 (0) 200 (0) 43 (0) 49 (0) 64 (5) 45 (0) 201 (5)
WP 75 (0) 73 (0) 44 (0) 44 (0) 236 (0) 48 (0) 49 (0) 42 (0) 46 (0) 185 (0)
PCraiд 70 152 72 – 294 27 59 45 – 131
P⋆+IT−SP−LV 118 145 88 58 409 55 62 55 50 222
PAll 136 164 94 61 455 68 78 82 51 279
CVC4 IT-SP-LV Mathsat IT-SP-LV IT-SP SP-LV SP IT-WP
IT-WP-LV WP-LV WP Z3 Z3IT-SP-LV
0 20 40 60 80 100 1200.0010.010.1110100
Sampleslog(s)Time
0 20 40 60 80 100 120050100150200
SamplesIterationsIter
0 20 40 60 80 100020406080100
Samples% perfect interpolantsPerfInter
Figure 4: Ultimate Automizer statistics for the benchmark set Bitvector .
493ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany D. Dietsch, M. Heizmann, B. Musa, A. Nutz, A. Podelski
CVC4 IT-SP-LV Mathsat IT-SP-LV Princess SMTInterpol SMTInterpol IT-SP-LV
IT-SP SP-LV SP IT-WP IT-WP-LV
WP-LV WP Z3 Z3IT-SP-LV
0 10 20 30 40 500.010.1110100
Sampleslog(s)Time
0 10 20 30 40 50020406080100120
SamplesIterationsIter
0 10 20 30 40 50020406080100
Samples% perfect interpolantsPerfInter
0 20 40 60 80 100 120 1400.0010.010.1110100
Sampleslog(s)Time
0 20 40 60 80 100 120 140050100150
SamplesIterationsIter
0 20 40 60 80 100 120 140020406080100
Samples% perfect interpolantsPerfInter
Figure 5: Ultimate Automizer statistics for the benchmark sets Memsafety (upper three plots) and Integer (lower three plots).
Mathsat IT-SP-LV IT-SP SP-LV SP IT-WP
IT-WP-LV WP-LV WP Z3IT-SP-LV
0 10 20 30 40 500.010.1110100
Sampleslog(s)Time
0 10 20 30 40 500102030
SamplesIterationsIter
0 10 20 30 40 50020406080100
Samples% perfect interpolantsPerfInter
Figure 6: Ultimate Automizer statistics for the benchmark set Float .
Nevertheless, using Craig interpolation allows one to solve cer-
tain tasks that could not be solved by any other approach. For
example, with Z3both tools could solve tasks from the Memsafety
exclusively.Surprisingly, the combination of live variables and infeasible
cores ( ⋆-IC-LV) is in general not superior over only using infea-
sible cores ( ⋆-IC). The reason for this are the quantifiers intro-
duced by the live variable projection. While using live variables it
is more likely that more general assertions are obtained, however
it is also more likely that those assertions contain quantifiers. Z3
494Craig vs. Newton in Software Model Checking ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany
is significantly slower if SMT queries contain quantified formulas,
SMTInterpol is unable to answer these queries at all.
One important strength of the Newton variations is their in-
dependence from specific SMT theories. While all selected SMT
solvers support interpolation for the logics used in the Integer set,
none provide a technique for Float . But contrary to the other bench-
mark sets, Float can be solved effectively by only using SP or WP.
The reason for this perhaps counter-intuitive result is that many
tasks in Float do not contain loops.
While Ultimate Kojak is not as successful as Ultimate Au-
tomizer , we can see that both tools show the same behavior re-
garding the variation of assertion sources. Hence, we infer that
the software model checking algorithm is not responsible for the
differences between the results, but indeed the assertion source.
The plots in Figures 4, 5 and 6 show qualitative results obtained
from Ultimate Automizer for each of the four benchmark sets.
Due to space constraints, we omit the results obtained from Ul-
timate Kojak . Each figure contains three plots. Each plot shows
successfully solved verification tasks of a certain configuration
ordered from smallest metric value to largest metric value. For ex-
ample, consider the plot Time and the configuration SP in Figure 4.
The first point of the graph represents the fastest sample that could
be solved by this configuration. It took around 0.001 seconds. The
last point represents the slowest sample (“sample no. 45”) that could
be solved, which took around 100 seconds.
The plot Time shows the total time needed for solving a veri-
fication task in seconds on a logarithmic scale, and the plot Iter
shows the total number of CEGAR iterations performed on a linear
scale. The plot PerfIter shows the percentage of perfect state asser-
tion sequences among all state assertion sequences obtained on a
linear scale. A sequence of state assertions is perfect if the state
assertions are not only inductive w.r.t to the trace, but also to the
path program induced by the trace. The path program induced by
a trace is obtained by projecting the complete program to the state-
ments occurring in the trace. A perfect state assertion sequence
also provides loop invariants for all loops of the path program.
As the total runtime ( Time ) is determined by the interpolation
time, we can see that the overall runtime as well as the number
of iterations ( Iter) correspond to a technique’s expected ability to
derive inductive invariants if we account for the startup time of
SMTInterpol andPrincess (both implemented in Java), which
shifted their plots in comparison. Both plots shows that SP and WP
perform poorly in this regard on Memsafety andBitvector , but not
onFloat . This is due to the fact that many tasks in Float consist of
loop-free programs. Hence, inductive invariants are not necessarily
needed and simple trace iteration can solve these tasks.
The importance of perfect state assertion sequences is illustrated
by our results. Nearly all successful cases in Memsafety andBitvector
contained only perfect state assertion sequences. An exception are
nearly a quarter of the Float tasks that could be solved without
any perfect state assertion sequence. In those cases, Ultimate
Automizer simply unrolled loops and could solve the task anyway
because not many unrollings were necessary. In general, having
perfect state assertion sequences is the decisive factor for successful
verification, as without them only loop unrolling remains as option.Our comparison of the Newton algorithm variants against the
Craig interpolation algorithms shows that Craig interpolation is
clearly outperformed by the Newton algorithms. Even if we remove
theFloat set, the (then) best Newton variant Z3-IT-SP-LV solves
327 and 154 tasks as opposed to the 244 and 111 for Z3with Craig
interpolation. The reasons for this unexpected outcome are the
following.
(1)The solver is unable to interpolate a certain combination
of theories.
(2)During interpolation, the SMT solver has no timeout but
can answer with “Unknown” if it uses an incomplete algo-
rithm for the sake of interpolation.
(3)There are multiple proofs for the infeasibility of a trace,
but the solver selects one that does not lead to perfect state
assertion sequences.
(4)The solver selects a useful proof, but the interpolation
algorithm of the solver creates imperfect state assertions.
(5)The solvers interpolants contain many quantifiers. These
quantifiers are hard for later stages of the software model
checking process and can lead to timeouts during simplifi-
cation and quantifier elimination. Z3’s interpolation engine
often suffers from this problem.
Reason 4 is an inherent drawback of the Newton-style algorithms:
they are limited to formulas that syntactically occur in the program.
Overall we can say that if one is faced with the question which
technique to use for some arbitrary verification task, then the an-
swer is two-fold: If you are restricted to use just one method to
obtain state assertions then use a Newton-style algorithm. If you
do not have this restriction – e.g., because time is not important
for your task – then try to use a combination of all the presented
techniques and stop in each iteration after you have found perfect
state assertions.
7.2 Threats to Validity
Our experiments are subject to some threats to validity. First, al-
though our benchmark source is the SV-COMP’17 repository, which
is widely regarded as the de-facto standard for software model
checking benchmarks, we did not control for the complexity of
state assertions in a proof. The randomly selected verification tasks
may require only simple state assertions that consist only of for-
mulas syntactically contained in the program. This would prevent
Craig interpolation to show its full potential. We believe that this
was not the case, as the benchmark set Float shows that for such
simple programs, even SP/ WP is sufficient.
Second, our selection of software model checking algorithms
(trace abstraction [ 33] inUltimate Automizer and lazy abstraction
with splitting [ 25] inUltimate Kojak ) may benefit state assertions
obtained by Newton or may not be generalizable to other software
model checking algorithms that require state assertions. We can
not rule out that other algorithms may exhibit additional char-
acteristics. As there are many different tools and variations, it is
nearly impossible to consider them all. Nevertheless, our evaluation
also shows the significance of obtaining inductive loop invariants
and the direct connection to the source of state assertions, we are
confident that our results can be generalized to other tools.
495ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany D. Dietsch, M. Heizmann, B. Musa, A. Nutz, A. Podelski
8 RELATED WORK
Our work touches the very active areas of abstract interpretation,
software model checking, and Craig interpolation. The technique
for generating interpolating state assertions described in this pa-
per is closely related to the Newton tool [ 5]. The main technical
difference of our algorithm compared to Newton ’s is that New-
ton iteratively computes the strongest post condition, adding one
more statement to the trace prefix in each step. Each constraint set
inferred this way is checked for consistency by a theorem prover.
When Newton encounters an inconsistent constraint set, the trace
is infeasible. Then Newton attempts to minimize the constraint
set by leaving out constraints until none can be dropped without
the set becoming consistent. Afterwards, Newton analyzes which
statements in the trace can be projected out such that all the con-
straints in the minimized set are still in the strongest post of the
projected trace. Our formalization assumes that the model checker
gives a whole path formula to the solver and asks for its feasibility,
which is the common approach in state of the art interpolating
model checkers. The analogue to Newton ’s projected path can
then be obtained through an unsatisfiable core request to the SMT
solver. Also the quantification of non-live variables, which we de-
scribe in section 5 is not done by Newton .Newton utilizes only
the strongest-post operator to automatically obtain predicates for
an abstraction, the idea of using weakest preconditions (wlp) for
that task was proposed in [48].
Abstract interpretation, where abstract domains with join and
widening are used to define an abstraction, is geared towards gen-
eralizing from multiple symbolic executions. It provides the guar-
antee that a fixpoint (a loop invariant) will always be found, but
it may result in overapproximations that are too coarse to prove a
given property. A wide range of techniques have been developed
to identify and recover the corresponding loss of precision; see,
e.g., [ 22,27,51]. SMT solvers can be used in order to identify the
loss of precision [ 31]. Craig interpolants can be used in order to help
recover from the loss of precision [ 30]. Our work adds to this line
of work in abstract interpretation the idea of using the unsatisfiable
core in order to define an abstraction.
Software model checking, where counterexample-guided abstrac-
tion refinement is used to define an abstraction, is geared towards
generalizing from a single symbolic execution (of the counterexam-
ple trace). The success of the generalization relies on the succinct-
ness of the reasons for infeasibility. Since Craig interpolants are a
way to capture the essence of the reasons for infeasibility, they are
used indirectly (for extracting predicates) [ 36] or directly [ 34,45].
The approach in [ 39] constructs a path slice incrementally and
does not use unsatisfiable cores. Template-based techniques like [ 9]
derive loop invariants from paths. Because they obtain a path in-
variant from a template via linear constraint solving, they are not
theory-independent.
The unsatisfiable core of a trace formula can be seen as another
way to capture the essence of the reasons for infeasibility, e.g. as
used in [ 47]. The work in [ 1] uses the unsatisfiable core to address
problems with the scalability of current implementations of Craig
interpolation by decreasing the size of the input formula to the SMT
solver in a preprocessing step. Our work investigates techniquesbased on the unsatisfiable core as an alternative to computing a
sequence of state assertions.
One can usually extract different unsatisfiable cores from a single
trace formula. One way of accomplishing this is iteratively replac-
ing statements that are part of the current unsatisfiable core with
sound abstractions (e.g., as described in Def. 4.1) and then comput-
ing a new abstraction from the resulting new trace formula [ 12].
The different trace formulas obtained by this approach can lead to
very different generalizations and thus an interesting problem is
choosing the “best” one. In [ 11], the authors present and evaluate
different heuristics for this problem. In contrast to our work, they
do not compare a theory-independent method against Craig inter-
polation, but consider the impact of different abstractions of a trace
formula (i.e., different inputs for an interpolation engine) on the
model checking algorithm.
Property-directed reachability (PDR, also known as IC3) is an-
other technique that computes generalizing inductive sequences of
state assertions. While PDR has been introduced for model checking
of propositional formulas first [ 13], several adaptations for sym-
bolic model checking exist [ 20,38,41]. The PDR algorithm holds a
sequence of candidate formulas in conjunctive normal form. Those
formulas are iteratively strengthened and (by prolonging the se-
quence) weakened in the hope that one of them becomes a safe
inductive invariant. In contrast to Newton and Craig interpola-
tion, PDR always attempts to find a safe inductive invariant for
a program whereas the state assertions from Newton or Craig
interpolation need not be invariants.
9 CONCLUSION
We considered a central problem in software model checking: com-
pute an abstraction that is precise enough to prove the infeasibility
of a given trace while coarse enough to prove infeasibility of other
traces. We reimplemented (and enhanced) the algorithm used by the
Newton tool into the context of current state-of-the-art software
model checkers and SMT solvers by implementing it in the software
model checkers Ultimate Automizer andUltimate Kojak and
gave a formal description of the algorithm and several variants of
it. We then compared Newton with various Craig interpolation
techniques implemented in different SMT solvers. The evaluation
shows that when faced with an unknown problem, one has a higher
chance of success using the “old” Newton approach then relying
on specialized Craig interpolation techniques.
The conclusion that one may be tempted to draw from the out-
come of the experimental evaluation may be that Newton wins
over Craig, that the effort for implementations of Craig for new
theories is not need, and that years of research are basically futile.
Clearly, such a conclusion would be wrong. We believe that, on
the contrary, our work opens a new line of research that aims at
understanding the difference between Newton and Craig. Such a
line of research may be worthwhile, along with the existing line
of research on new procedures that excel on specific application
domains. As always, an experimental comparison can only be part
of a series of experimental comparisons.
REFERENCES
[1] Aws Albarghouthi, Arie Gurfinkel, and Marsha Chechik. 2012. Craig Interpreta-
tion. In SAS 2012 . Springer, 300–316.
496Craig vs. Newton in Software Model Checking ESEC/FSE’17, September 4–8, 2017, Paderborn, Germany
[2]Aws Albarghouthi, Yi Li, Arie Gurfinkel, and Marsha Chechik. 2012. Ufo: A
Framework for Abstraction- and Interpolation-Based Software Verification. In
CAV (Lecture Notes in Computer Science) , Vol. 7358. Springer, 672–678.
[3]Aws Albarghouthi and Kenneth L. McMillan. 2013. Beautiful Interpolants. In
CAV (Lecture Notes in Computer Science) , Vol. 8044. Springer, 313–329.
[4] Thomas Ball, Rupak Majumdar, Todd D. Millstein, and Sriram K. Rajamani. 2001.
Automatic Predicate Abstraction of C Programs. In PLDI 2001 . 203–213. DOI:
http://dx.doi.org/10.1145/378795.378846
[5] Tom Ball and Sriram Rajamani. 2002. Generating Abstract Explanations of Spurious
Counterexamples in C Programs . Technical Report. 15 pages.
[6]Clark Barrett, Christopher L Conway, Morgan Deters, Liana Hadarean, Dejan
Jovanović, Tim King, Andrew Reynolds, and Cesare Tinelli. 2011. CVC4. In CAV
2011. Springer, 171–177.
[7] Dirk Beyer. 2016. Reliable and Reproducible Competition Results with BenchExec
and Witnesses (Report on SV-COMP 2016). In TACAS 2016 . 887–904. DOI: http:
//dx.doi.org/10.1007/978-3-662-49674-9_55
[8] Dirk Beyer. 2017. Software Verification with Validation of Results - (Report on
SV-COMP 2017). In TACAS 2017 . 331–349. DOI: http://dx.doi.org/10.1007/978-3-
662-54580-5_20
[9] Dirk Beyer, Thomas A. Henzinger, Rupak Majumdar, and Andrey Rybalchenko.
2007. Path Invariants. In PLDI 2007 . 300–309. DOI: http://dx.doi.org/10.1145/
1250734.1250769
[10] Dirk Beyer and M. Erkan Keremoglu. 2011. CPA checker : A Tool for Configurable
Software Verification. In CAV 2011 . 184–190.
[11] Dirk Beyer, Stefan Löwe, and Philipp Wendler. 2015. Refinement Selection. In
SPIN 2015 . 20–38. DOI: http://dx.doi.org/10.1007/978-3-319-23404-5_3
[12] Dirk Beyer, Stefan Löwe, and Philipp Wendler. 2015. Sliced Path Prefixes: An
Effective Method to Enable Refinement Selection. In FORTE 2015 . 228–243. DOI:
http://dx.doi.org/10.1007/978-3-319-19195-9_15
[13] Aaron R. Bradley. 2011. SAT-Based Model Checking without Unrolling. In VMCAI
2011. 70–87. DOI: http://dx.doi.org/10.1007/978-3-642-18275-4_7
[14] Martin Brain, Vijay D’Silva, Alberto Griggio, Leopold Haller, and Daniel Kroening.
2013. Interpolation-Based Verification of Floating-Point Programs with Abstract
CDCL. In SAS (Lecture Notes in Computer Science) , Vol. 7935. Springer, 412–432.
[15] Angelo Brillout, Daniel Kroening, Philipp Rümmer, and Thomas Wahl. 2010. An
Interpolating Sequent Calculus for Quantifier-Free Presburger Arithmetic. In
IJCAR (Lecture Notes in Computer Science) , Vol. 6173. Springer, 384–399.
[16] Angelo Brillout, Daniel Kroening, Philipp Rümmer, and Thomas Wahl. 2011. An
Interpolating Sequent Calculus for Quantifier-Free Presburger Arithmetic. J.
Autom. Reasoning 47, 4 (2011), 341–367. DOI: http://dx.doi.org/10.1007/s10817-
011-9237-y
[17] Franck Cassez, Takashi Matsuoka, Edward Pierzchalski, and Nathan Smyth. 2015.
Perentie: Modular Trace Refinement and Selective Value Tracking - (Competition
Contribution). In TACAS (Lecture Notes in Computer Science) , Vol. 9035. Springer,
439–442.
[18] Jürgen Christ and Jochen Hoenicke. 2016. Proof Tree Preserving Tree Interpola-
tion. J. Autom. Reasoning 57, 1 (2016), 67–95.
[19] Jürgen Christ, Jochen Hoenicke, and Alexander Nutz. 2012. SMTInterpol: An
Interpolating SMT Solver. In SPIN 2012 . 248–254. DOI: http://dx.doi.org/10.1007/
978-3-642-31759-0_19
[20] Alessandro Cimatti and Alberto Griggio. 2012. Software Model Checking via
IC3. In CAV (Lecture Notes in Computer Science) , Vol. 7358. Springer, 277–293.
[21] Alessandro Cimatti, Alberto Griggio, Bastiaan Joost Schaafsma, and Roberto
Sebastiani. 2013. The MathSAT5 SMT Solver. In TACAS 2013 . 93–107. DOI:
http://dx.doi.org/10.1007/978-3-642-36742-7_7
[22] Patrick Cousot. 2015. Abstracting Induction by Extrapolation and Interpolation.
InVMCAI 2015 . 19–42. DOI: http://dx.doi.org/10.1007/978-3-662-46081-8_2
[23] Leonardo Mendonça de Moura and Nikolaj Bjørner. 2008. Z3: An Efficient SMT
Solver. In TACAS 2008 . 337–340. DOI: http://dx.doi.org/10.1007/978-3-540-78800-
3_24
[24] Klaus Dräger, Andrey Kupriyanov, Bernd Finkbeiner, and Heike Wehrheim. 2010.
SLAB: A Certifying Model Checker for Infinite-State Concurrent Systems. In
TACAS 2010 . 271–274. DOI: http://dx.doi.org/10.1007/978-3-642-12002-2_22
[25] Evren Ermis, Jochen Hoenicke, and Andreas Podelski. 2012. Splitting via In-
terpolants. In VMCAI 2012 . 186–201. DOI: http://dx.doi.org/10.1007/978-3-642-
27940-9_13
[26] Sicun Gao and Damien Zufferey. 2016. Interpolants in Nonlinear Theories Over
the Reals. In TACAS (Lecture Notes in Computer Science) , Vol. 9636. Springer,
625–641.
[27] Denis Gopan and Thomas Reps. 2006. Lookahead Widening. In CAV 2006 .
Springer, 452–466.[28] Alberto Griggio. 2011. Effective word-level interpolation for software verification.
InFMCAD . FMCAD Inc., 28–36.
[29] Alberto Griggio, Thi Thieu Hoa Le, and Roberto Sebastiani. 2011. Efficient
Interpolant Generation in Satisfiability Modulo Linear Integer Arithmetic. In
TACAS (Lecture Notes in Computer Science) , Vol. 6605. Springer, 143–157.
[30] Bhargav S. Gulavani, Supratik Chakraborty, Aditya V. Nori, and Sriram K. Ra-
jamani. 2008. Automatically Refining Abstract Interpretations. In TACAS 2008 .
443–458. DOI: http://dx.doi.org/10.1007/978-3-540-78800-3_33
[31] Bhargav S. Gulavani and Sriram K. Rajamani. 2006. Counterexample Driven
Refinement for Abstract Interpretation. In TACAS 2006 . 474–488. DOI: http:
//dx.doi.org/10.1007/11691372_34
[32] Matthias Heizmann, Daniel Dietsch, Marius Greitschus, Jan Leike, Betim Musa,
Claus Schätzle, and Andreas Podelski. 2016. Ultimate Automizer with Two-
track Proofs - (Competition Contribution). In TACAS 2016 . 950–953. DOI: http:
//dx.doi.org/10.1007/978-3-662-49674-9_68
[33] Matthias Heizmann, Jochen Hoenicke, and Andreas Podelski. 2009. Refinement
of Trace Abstraction. In SAS 2009 . 69–85. DOI: http://dx.doi.org/10.1007/978-3-
642-03237-0_7
[34] Matthias Heizmann, Jochen Hoenicke, and Andreas Podelski. 2010. Nested
Interpolants. In POPL 2010 . 471–482. DOI: http://dx.doi.org/10.1145/1706299.
1706353
[35] Matthias Heizmann, Jochen Hoenicke, and Andreas Podelski. 2013. Software
Model Checking for People Who Love Automata. In CAV 2013 . 36–52. DOI:
http://dx.doi.org/10.1007/978-3-642-39799-8_2
[36] Thomas A. Henzinger, Ranjit Jhala, Rupak Majumdar, and Kenneth L. McMillan.
2004. Abstractions from Proofs. In POPL 2004 . 232–244. DOI: http://dx.doi.org/
10.1145/964001.964021
[37] Thomas A. Henzinger, Ranjit Jhala, Rupak Majumdar, and Grégoire Sutre. 2002.
Lazy Abstraction. In POPL 2002 . 58–70. DOI: http://dx.doi.org/10.1145/503272.
503279
[38] Krystof Hoder and Nikolaj Bjørner. 2012. Generalized Property Directed Reacha-
bility. In SAT (Lecture Notes in Computer Science) , Vol. 7317. Springer, 157–171.
[39] Ranjit Jhala and Rupak Majumdar. 2005. Path Slicing. In PLDI 2005 . 38–47. DOI:
http://dx.doi.org/10.1145/1065010.1065016
[40] Ranjit Jhala and Kenneth L. McMillan. 2006. A Practical and Complete Approach
to Predicate Refinement. In TACAS (Lecture Notes in Computer Science) , Vol. 3920.
Springer, 459–473.
[41] Aleksandr Karbyshev, Nikolaj Bjørner, Shachar Itzhaky, Noam Rinetzky, and
Sharon Shoham. 2015. Property-Directed Inference of Universal Invariants or
Proving Their Absence. In CAV (1) (Lecture Notes in Computer Science) , Vol. 9206.
Springer, 583–602.
[42] K. Rustan M. Leino. 2008. This is Boogie 2. Manuscript Working Draft. (24 jun
2008). Microsoft Research, Redmond, WA, USA (http://research.microsoft.com/
en-us/um/people/leino/papers/krml178.pdf).
[43] Kenneth L. McMillan. 2003. Interpolation and SAT-Based Model Checking. In
CAV (Lecture Notes in Computer Science) , Vol. 2725. Springer, 1–13.
[44] Kenneth L. McMillan. 2004. An Interpolating Theorem Prover. In TACAS (Lecture
Notes in Computer Science) , Vol. 2988. Springer, 16–30.
[45] Kenneth L. McMillan. 2006. Lazy Abstraction with Interpolants. In CAV 2006 .
Springer, 123–136. DOI: http://dx.doi.org/10.1007/11817963_14
[46] Kenneth L. McMillan. 2011. Interpolants from Z3 Proofs. In FMCAD 2011 . 19–27.
http://dl.acm.org/citation.cfm?id=2157661
[47] Kenneth L. McMillan and Nina Amla. 2003. Automatic Abstraction Without
Counterexamples. In TACAS 2003 . 2–17. DOI: http://dx.doi.org/10.1007/3-540-
36577-X_2
[48] Kedar S. Namjoshi and Robert P. Kurshan. 2000. Syntactic Program Transfor-
mations for Automatic Abstraction. In CAV (Lecture Notes in Computer Science) ,
Vol. 1855. Springer, 435–449.
[49] Alexander Nutz, Daniel Dietsch, Mostafa Mahmoud Mohamed, and Andreas
Podelski. 2015. Ultimate Kojak with Memory Safety Checks - (Competition
Contribution). In TACAS 2015 . 458–460. DOI: http://dx.doi.org/10.1007/978-3-
662-46681-0_44
[50] Andrey Rybalchenko and Viorica Sofronie-Stokkermans. 2010. Constraint solv-
ing for interpolation. J. Symb. Comput. 45, 11 (2010), 1212–1233.
[51] Chao Wang, Zijiang Yang, Aarti Gupta, and Franjo Ivancic. 2007. Using Coun-
terexamples for Improving the Precision of Reachability Computation with Poly-
hedra. In CAV 2007 . 352–365. DOI: http://dx.doi.org/10.1007/978-3-540-73368-
3_40
497