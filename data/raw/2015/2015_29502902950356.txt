Multi-representational Security Analysis
Eunsuk Kang
EECS, UC Berkeley
Berkeley, CA USA
eunsuk.kang@berkeley.eduAleksandar Milicevic
TSE, Microsoft
Redmond, WA USA
almili@microsoft.comDaniel Jackson
CSAIL, MIT
Cambridge, MA USA
dnj@mit.edu
ABSTRACT
Security attacks often exploit aws that are not anticipated
in an abstract design, but are introduced inadvertently when
high-level interactions in the design are mapped to low-level
behaviors in the supporting platform. This paper proposes a
multi-representational approach to security analysis, where
models capturing distinct (but possibly overlapping) views
of a system are automatically composed in order to enable
an end-to-end analysis. This approach allows the designer
to incrementally explore the impact of design decisions on
security, and discover attacks that span multiple layers of
the system. This paper describes Poirot, a prototype imple-
mentation of the approach, and reports on our experience
on applying Poirot to detect previously unknown security
aws in publicly deployed systems.
CCS Concepts
Software and its engineering !Formal software ver-
ication
Keywords
Security, representation, modeling, verication, composition.
1. INTRODUCTION
Abstraction is a key ingredient of any successful formal
analysis. Most systems are too complex to be fully described
at once, and so a typical model focuses on a particular aspect
of a system at one abstraction layer, and omits details that
are deemed irrelevant for the analysis at hand. For example,
when reasoning about the business workow of an online
store, the designer may ignore or defer lower-level design
decisions, such as the choice of underlying communication
protocols, web frameworks, and data structures used.
However, in certain domains, especially those where secu-
rity is a paramount concern, abstraction can be a double-
edged sword. A key observation, noted since the early days
This work was done when the authors were at MIT.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full cita-
tion on the Ô¨Årst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission
and/or a fee. Request permissions from permissions@acm.org.
FSE ‚Äô16 Seattle, WA USA
c2016 ACM. ISBN 978-1-4503-4218-6/16/11. . . $15.00
DOI:http://dx.doi.org/10.1145/2950290.2950356
PoirotView)modelsPar/al)mappingPropertyElaboratedmodelViola/onFigure 1: Overview of Poirot.
of security research [22], is that many security attacks arise
due to discrepancies between the designer's concep-
tual view of the system and that of an attacker .
While the designer tends to work with one abstraction at
a time, the attacker is not bound by such restrictions, and
may exploit weaknesses across multiple layers of the system.
For example, a malicious user of the online store may chain
together an attack that exploits a weakness in a standard
browser's handling of cookies, with a lower-level network at-
tack that intercepts packets between two machines.
In this paper, we propose a new methodology called multi-
representational security analysis . Our approach allows a
designer to perform a security analysis to nd attacks that
involve the behavior of the system across multiple abstrac-
tion layers. The analysis can be carried out incrementally:
Starting with an abstract model that represents an initial
design of the system, the designer can elaborate a part of
the model with a choice of representation, transforming the
model into a more detailed one.
A key element of our approach is a mechanism for system-
atically composing independent models of a system in order
to enable an end-to-end analysis. However, these models
may not be readily amenable to composition due to abstrac-
tion mismatch : A pair of models may describe a common
aspect of the system at dierent layers of abstraction, using
distinct sets of vocabulary terms. To resolve this mismatch,
we allow the designer to specify how various parts of the
models are related through their representations . If some of
these relationships are unknown (as often is the case during
early design stages), the designer may leave them unspec-
ied. Our mechanism then automatically generates candi-
date mappings that may leave the resulting system vulner-
able to attacks, allowing the designer to explore security
implications of alternative design decisions.
To demonstrate the feasibility of our approach, we have
built a prototype tool called Poirot . As shown in Figure 1,
the tool takes three inputs from the designer: a desired se-
curity property, a set of models that describe dierent views
of a system, and a (potentially partial) mapping that relates
parts of those models. Poirot then produces (1) an elabo-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
FSE‚Äô16 , November 13‚Äì18, 2016, Seattle, WA, USA
c2016 ACM. 978-1-4503-4218-6/16/11...$15.00
http://dx.doi.org/10.1145/2950290.2950356
181
rated model that captures the end-to-end behavior of the
system across those views, and (2) a scenario (if it exists)
that demonstrates how the resulting system may violate the
given security property.
We have applied Poirot to two publicly deployed systems:
(1) IFTTT, a system for composing web services, and (2)
HandMe.In, an online system for tracking personal proper-
ties. We identied several security aws in the designs of
these systems, some of which could be used to carry out
previously unknown attacks.
The contributions of this paper are:
Amulti-representational approach to security analysis
(outlined in Section 2), in which composition expands the
range of behaviors to allow for new security violations
that lower-level design decisions might introduce;
A formal specication framework that allows distinct views
of a system to be modeled and composed using a repre-
sentation mapping (Section 3);
An analysis technique for automatically generating a map-
ping that leads to a violation of a property (Section 4);
An experience report on applying Poirot, our prototype
tool (Section 5), to two case studies (Section 6).
2. MOTIV ATING EXAMPLE
Consider the task of designing an online store. A typical
store oers a variety of services, but we will focus on two
basic functions: logging in and adding an item to a shopping
cart. A desirable property of the store is the shopping cart
integrity ; that is, every item in a customer's cart must be one
of the items that were intentionally added by the customer.
(1) Initial Design and Analysis: Figure 2(a) shows a
high-level model of the store system, consisting of three dif-
ferent processes :Store , which provide Login and Addser-
vices, and Alice and Eve, customers who interact with the
store by invoking these two services. Login accepts a user
ID and a password, and returns a token that can be used
in subsequent interaction with the store. Addtakes an item
ID and a token, and adds the item to the shopping cart of
the customer that is identied by the token. In addition, we
will assume that Eve is a malicious person, and will delib-
erately attempt to violate the integrity property by causing
the store to add an item of her choice to Alice's cart. Each
process is associated with a specication that describes its
behavior; for example, the specication on Store may state
that it only accepts Addrequests that contain a valid token.
The designer wishes to perform an analysis on this initial
model to check whether the system satises the integrity
property. Let us rst consider a conventional analysis in
which security violations are found by exploring all possi-
ble behaviors of the processes, including the malicious one.
Running an analysis tool, such as a model checker, might
reveal counterexamples to this property:
Ex1:Eveinvokes the Login service with a victim cus-
tomer's (i.e., Alice ) user ID and password, and receives
a token that identies Alice .Evethen invokes Addwith
this token and an item ID of her choosing, successfully
causing the store to add that item to Alice's cart.
Ex2:Eveinvokes Login with her own ID and password,
and receives a token that matches Alice's token. Eveuses
this token to add an item of her choice to Alice's cart.
AliceStoreBrowserServerReq(Method,5URL,5Set<Header>,...)Add(ItemID,5Token)Alice5||BrowserStore5||Server{Add,Req}Eve5||5(Server5||Browser){Req}EveStore5‚Üí5ServerAlice5‚Üí5BrowserEve5‚Üí5?Add5‚Üí5ReqLogin5‚Üí5Req(a)$Ini(al$store$model(b)$HTTP$model
(c)$A$mapping$speciÔ¨Åed$between$(a)$and$(b),$and$their$composi(onLogin(UID,Pwd,Token)
{Login,Req}Figure 2: Graphical depictions of system models. A rectangle
represents a process; grey ones are considered malicious. A circle
represents the participation of a certain type of events by two pro-
cesses; e.g., in (a), Alice and Store engage in Login events. pkq
corresponds to the composition of pand q. Some events may be
associated with multiple representations; e.g., in (c), fLogin ;Reqg
means that every Login is realized as an HTTP request.
The designer examines the counterexamples, and derives ad-
ditional constraints on the behaviors of the individual pro-
cesses that would prevent those attacks:
C1:Evedoes not initially have access to the password of
another customer (prevents Ex1).
C2: The store returns a unique token to each customer
in response to Login (prevents Ex2).
Re-running the analysis with these constraints no longer re-
turns any counterexample, suggesting that the store design
ensures the shopping cart integrity. The constraints repre-
sent component specications (on Store ) and environmental
assumptions ( Eve) that together establish the property.
Note that the level of abstraction in Figure 2(a) is suitable
for reasoning about the essential functionality of the system;
it omits details that are irrelevant to the business workow,
such as what devices Store will be deployed on, how Login
and Addoperations are implemented, or the type of data
structure used to represent tokens and item IDs. However,
as we will see, it may be exactly these details that are ex-
ploited by the attacker to undermine the store's integrity.
(2) Design Elaboration: Being satised with the initial
design of the store, the designer wishes to explore dierent
implementation choices and analyze their impact on the se-
curity of the system. In particular, she decides that Store
is to be deployed on a standard HTTP server, with Login
and Addimplemented as HTTP requests.
Figure 2(b) shows an application-independent model that
describes interactions between a generic HTTP server and
a browser, including details about HTTP requests and re-
sponses. The designer would like to reuse the domain knowl-
edge captured in this HTTP model by integrating it with
the application-specic store model in Figure 2(a). How-
ever, these two models, in their current form, are not read-
ily amenable to composition due to abstraction mismatch :
They describe the system at dierent levels of abstraction
using two distinct sets of vocabulary terms.
The designer's task is then to determine how various parts
of the abstract store design are to be realized in terms of
182ReqAddURLItemIDiTokentOriginmystore.comPathaddItemSet<Query>?Method?URL?Set<Header>?Body?Response?Figure 3: The structures of the Addoperation, an HTTP re-
quest, and a URL. The leftmost column in each structure contains
the types of parameters. Dotted edges represent dierent choices
for encoding the token ( t) inside a request; \?" represents an
unknown value for the parameter.
their counterparts in the HTTP model. For example, as
shown in Figure 3, the Addoperation has a very dierent
structure from an HTTP request, which itself consists of
complex data types with their own structures, such as URLs.
Thus, realizing Addas an HTTP request involves a series of
decisions such as:
Which HTTP method should be used for this operation?
Which URL should be allocated?
How should the parameters of Add(the item ID and
token) be transmitted inside an HTTP request?
Some of these decisions may be xed as design constraints
(e.g., the hostname for the store site), while the rest may be
open for the designer to explore. For instance, she may
choose to transmit the store token as a browser cookie, or
encode it as a query parameter inside the URL. But each
of these decisions also carries security implications. Once
represented as a cookie, the token may be subject to cookie-
related vulnerabilities on the web. On the other hand, when
carried inside a URL, the token may be exposed to through-
out parts of the browser that operate on the URL. Exploring
design alternatives is a challenging task that requires sys-
tematic tool support. The space of possible design decisions
may be large, prohibiting any kind of manual exploration,
and some of those decisions may be irrelevant to the security
property being analyzed.
The key idea behind our methodology is to allow the devel-
oper to (1) specify a relationship between a pair of abstract
and concrete entities by using a representation mapping , and
(2) express uncertainty over design decisions by leaving some
part of the mapping as unspecied. Given a partial mapping
specication, our analysis automatically explores the space
of candidate mappings, and selects ones that lead to a vio-
lation of a given security property; such a mapping, if exist,
corresponds to a set of insecure design decisions that may
leave the resulting system vulnerable to attacks, undermin-
ing a property that has previously been established.
(3) Analysis with Partial Mapping: Suppose that the
designer provides a mapping indicating that the Addopera-
tion is to be realized as a GET request with a xed domain
and path ( http://mystore.com/add ), but does not specify
how the item or token parameters associated with Addshould
be transmitted as part of the request (similarly, for Login ).
Intuitively, this partial specication yields a space of pos-
sible mappings, including ones where the token is encodedinside a header, the request body, or a query parameter in
URL, as shown in Figure 3.
Given the store and HTTP models, and the mapping spec-
ication, our analysis engine automatically searches for an
insecure mapping (if it exists), and uses it to construct an
elaborated model that describes the deployment of the store
onto an HTTP server, as shown in Figure 2(c). In this nal
system, the item parameter of Addis encoded as a query pa-
rameter inside the URL, and the token is encoded as a cookie
header in the request. In addition, Evecan now act as both
aBrowser , interacting with other servers by sending poten-
tially malicious requests, and as a Server , providing its own
web pages that may be visited by Alice on her browser.
Along with the elaborated model, the analyzer also pro-
duces newcounterexamples to the integrity property|absent
from the initial design but introduced by insecure design de-
cisions in the generated mapping:
Ex3:Alice visits a fake login page set up by Eve(through
Req) and is tricked into sending her password to Eve, who
then uses this information to log onto the store and add
an item of her choosing to Alice's cart. This counterex-
ample corresponds to a type of phishing attack.
Ex4:Alice visits Eve's malicious page, which, when
loaded by Alice's browser, triggers an additional request
to be sent to a URL of Eve's choosing. In particular,
the attacker causes Alice's browser to send an AddHTTP
request that contains Alice's token as a cookie, and thus,
is accepted by the store as valid. This counterexample
corresponds to a cross-site request forgery (CSRF).
At this point, the developer may directly modify the model
to rule out these attacks; for example, she may add an as-
sumption that Alice does not give out her password to an
untrusted site, or require that every Addrequest to carry a
special CSRF token as an additional proof of authentication.
If these modications are undesirable, she may ask the an-
alyzer to generate an alternative mapping, where the token
is mapped to a dierent part of an HTTP request (which,
in turn, may enable dierent types of attacks). The steps
(2) - (3) may be repeated until the analyzer no longer de-
tects a counterexample|implying that the current mapping
captures a set of design decisions that preserve the security
property in the nal, deployed system.
3. SYSTEM MODELING
In this section, we introduce the underlying formalism
for constructing models of systems. We describe a simple
process algebra in the style of Hoare's CSP [14], where the
behavior of a system is dened as a set of event traces per-
formed by concurrent processes. We then propose an exten-
sion to this framework where certain parts of a system may
be assigned multiple representations , to enable a new kind of
composition where models specied using distinct alphabets
are brought together through a representation mapping .
3.1 Basic Framework
As the underlying formalism, we adapt the trace-based se-
mantics of CSP [14]. Compared to state-based formalisms,
process algebras emphasize communication between dier-
ent parts of a system, and have been successfully used for
security modeling and verication [1, 33, 5].
183A system consists of a set of processes that interact with
each other by together performing various types of events .
LetPbe a set of processes, Ea set of events, and Ta set
oftraces , each of which is a nite sequence of events. Each
process pis associated with an alphabet (denoted(p)
E), which describes the set of events that it may engage
in. We say that t2Tis a trace of process piftdescribes
one possible history of events that pperforms up to some
moment in time. Then, the overall behavior of pcan be
dened as the set of all traces that pmay perform, and is
denoted as beh(p)T.
A pair of processes, pandq, can be combined into a more
complex process that embodies their interaction using the
parallel composition operator ( pkq). The composition rule
states that that both pand qmust synchronize on events
that are common to their alphabets:
beh(pkq) =ft2Tjt2((p)[(q))^
(t(p))2beh(p)^
(t(q))2beh(q)g
where ( tX) is the projection of tonto the event set X.
Example. LetStore2Pbe a process that behaves like
an online store, oering two types of services:
(Store ) =Login[Add
fhi;
hloginAlice;add choci;
hloginAlice;add toff;add chocig beh(Store )
Here, LoginEis the set of events that describe some
user logging onto the store; loginAliceis a particular event
that corresponds to the login action of the user named
Alice . Three possible traces of Store are shown above:
an empty trace, one that begins with Alice logging in and
adding a chocolate ( choc) to her cart, and another one
where a toee ( toff) is added before a chocolate.
We are interested in understanding not just how the
store behaves on its own, but also how it interacts with
customers. Let us introduce a process named Alice , who
communicates to the store by invoking the latter's services:
(Alice ) =Login[Add
hloginAlice;add choci2beh(Alice )
Consider the above trace that describes Alice logging onto
the store and adding a chocolate to her cart. Since both
the store and Alice are able to synchronize on these events,
this trace is also a valid behavior of their composition; i.e.,
hloginAlice;add choci2beh(AlicekStore )
But suppose that Alice does not like toees, and so she
would never add such an item to her cart on her initiation;
thus, event add toffdoes not appear in any trace of Alice .
Then, the following is not a trace of the composition:
hloginAlice;add toff;add choci=2beh(AlicekStore )
even though it is allowed by Store , since the two processes
cannot synchronize on the second event.
3.2 Multi-Representation Extension
Suppose that our designer wishes to reason about the be-
havior of the online store when it is deployed as an HTTPserver. She is given a process named Server (developed
independently by a domain expert), which describes the be-
havior of a generic web server that is ready to accept any
arbitrary HTTP requests:
(Server ) =Req
Ideally, she should be able to reuse the knowledge captured
inServer by integrating it with the Store process. The re-
sulting process (named StoreServer ) would describe a spe-
cialized web server that oers the services of an online store.
ButStore andServer engage in two distinct sets of events,
and so applying the parallel composition operator would
simply result in a system where the two behave completely
independent of each other. A new composition mechanism
is needed, in order to allow processes from dierent views of
a system to interact with each other. In the next section,
we propose a simple extension to the trace-based semantics
introduced earlier to achieve this composition.
3.2.1 Events as Sets of Labels
A key idea behind our extension is to allow each event to
be associated with multiple representations, by establishing
alabel of an event as a separate notion from the event it-
self. Let Lbe a set of event labels . Then, an event is now
dened to be a set of labels (E= 2L), where each label
corresponds to one possible description or representation of
the event. Similarly, the alphabet of a process ( p) is rede-
ned to be the set of labels that may appear in any one of
p's events ((p)L).
Example. Recall the Store process from our running ex-
ample, which can now be reformulated as follows:
(Store ) =Login[Add
hfloginAliceg;fadd chocgi2 beh(Store )
Note that every event in the above trace contains one la-
bel; this corresponds to the basic case where each event has
exactly one representation, as in CSP. More complex cases
arise when two or more representations, possibly originat-
ing from independent models of a system, are associated
with the same event in the world. Recall the structure of
an HTTP request event:
req(m;u;hds;b;resp)
where mis the HTTP method, uthe URL of the request,
hdsa set of headers, bthe request body, and resp its re-
sponse. To deploy the store as a web server, the designer
may allocate a certain set of URLs for the store operations.
For instance, the following URL may be designated for the
operation of adding a chocolate:
url choc=url(originStore;pathAdd;fquery (item;choc)g)
where originStore and pathAddare particular origin and
path values; query is a function that constructs a query
parameter given some (name, value) pair; and urlis a
function that constructs a URL from an origin, a path,
and a set of query parameters. Then, the HTTP request
corresponding to this operation can be described as:
reqchoc=req(GET;url choc;fcookie (token;jAx2cE )g;;)
where the token capturing Alice's identity (value jAx2cE )
is encoded as a cookie header (the body and response of
184the request are irrelevant to our discussion, and denoted by
the placeholder variable ). Then, in the process Store-
Server , an event that results in a chocolate being added
to Alice's cart contains two distinct representations:
e=fadd choc;reqchocg
Intuitively, this event can be regarded as an abstract Add
action or as an HTTP request, depending on the process
that engages in the event.
3.2.2 Composition with a Representation Mapping
Let us propose a new composition operator
pk
mq
which introduces a relationship between events with distinct
labels as specied in the representation mapping m and al-
lows pand qto interact through those events. A represen-
tation mapping is a relation of type LL, where ( a;b)2m
means that \every aevent should also be considered as a b."
More precisely, this operator requires that whenever porq
performs a, the other process synchronizes by performing b
at the same moment; in the composed process, the synchro-
nized event appears as the union of the two original events
from pand q.
This new operator is dened similarly to the standard
parallel composition ( k):
beh(pk
mq) =ft2Tj
(t(p))2beh(p)^(t(q))2beh(q)^
8e2events (t);a2e;b2L(a;b)2m)b2eg
where the constraint on the second line ensures that every
event containing aas a label is assigned bas an additional
label in the composite process1.
Example. To express the relationship between Store and
Server , the following entries may be added in a mapping:
m=f(add choc;reqchoc);(loginalice;reqalice);:::g
where reqchocand reqalice are HTTP encodings of the
add chocand loginalice operations, respectively. Using this
mapping, we can construct a process that behaves like the
deployment of the store as a HTTP server:
StoreServer =Storek
mServer
InStoreServer , every event containing add chocis accom-
panied by reqchocas an additional label, signifying that the
abstract addoperation is implemented as a concrete HTTP
request (and similarly, for loginalice). For instance, con-
sider the following traces from Store and Server :
hfloginaliceg;fadd chocgi2 beh(Store )
hfreqaliceg;freqxg;freqchocgi2 beh(Server )
where reqxis an HTTP request that remains unused for
1The projection ( aX) is now dened to operate on sets of
labels, by removing labels from athat do not appear in X.store operations. During the composition step, these two
traces are combined into the following trace:
hfloginalice;reqaliceg;freqxg;fadd choc;reqchocgi
2beh(StoreServer )
Note that the event containing reqxdoes not require syn-
chronization between the two original processes, since it is
not mapped to any other label in m.
3.2.3 Behavioral Implications
The multi-faceted nature of events in our approach en-
ables a modular ,open extension of a process alphabet. Given
some process pthat interacts with qthrough events labeled
from set XL,pcan be extended to interact with another
process, r|possibly through the same events|by assigning
additional labels to them from a dierent set, YL; this
extension does not require any modication to the exist-
ing interaction between pand q. For instance, when Store
is elaborated into StoreServer , customers (e.g., Alice and
Eve) can continue to make use of the store services without
being aware of their underlying details as HTTP requests.
Similarly, the browser will continue to treat each event in
StoreServer as an HTTP request served at some designated
URL, without necessarily knowing that it implements a par-
ticular piece of store functionality.
This type of composition may also introduce new interac-
tions among processes in the world. When an event in pro-
cess pgains an additional label during composition, it may
now be engaged by processes that previously were not able
to interact with p. From the security standpoint, some of
these interactions may be undesirable, allowing a malicious
actor to undermine an existing property of the system.
For instance, let Browser be a process that depicts the
behavior of a generic browser connected to the web, capable
of engaging in arbitrary HTTP requests, including add toff:
(Browser ) =Req
hfreqtoffgi2 beh(Browser )
Recall that in Section 3.1, we introduced Alice as a process
that never engages in an add toffevent. Alice and Browser
do not share any labels in their alphabets, and thus cannot
inuence each other's behavior.
Suppose that during the composition of Store andServer ,
add toffis mapped to its HTTP counterpart, reqtoff, inside
the representation mapping. Consequently, every event in
StoreServer that involves adding a toee to Alice's cart
contains two labels; i.e., e=fadd toff;reqtoffg. Since reqtoff
is a label that appears in (Browser ),StoreServer and
Browser may engage in etogether; in other words, Browser
is able to get the store to add a toee to Alice's cart indi-
rectly by exploiting the fact that add toffis implemented as
an HTTP request.
4. ANALYSIS
4.1 Declarative Mapping SpeciÔ¨Åcation
In our approach, a representation mapping can be speci-
eddeclaratively in the following style:
S=fa;b2LjC(a;b)g
where Cis a constraint that describes a relationship between
185the parameters of aand b; we will call this set comprehen-
sion Samapping specication . A candidate mapping m
satises a specication SifCevaluates to true over every
tuple in m; i.e., msatises Sif and only if mS.
A key feature of this declarative approach is the partiality
of a specication; that is, the constraint in Smay leave
unspecied how certain parameters of labels are related to
each other.
Example. Consider the following specication of a map-
ping between labels of type Addand Req:
Sm=fadd(t;i);req(m;u;hds;body;resp)2Lj
m=GET^
u=url(originStore;pathAdd;fquery (item;i)g)g
This specication stipulates that the item ID ( i) from the
Addoperation is to be encoded as a query parameter in-
side the URL, but does not say anything about how the
token ( t) is encoded, or what should be contained inside the
headers, body, or response of the request. Conceptually,
this specication describes the relationships between Add
andReqin Figure 3; the parameters that are not explicitly
constrained in Scorrespond to unknown design decisions,
and may take on any values from their respective types.
4.2 Property-Guided Search
A partial specication of a mapping yields a space of can-
didate mappings. Among these candidates, ones that are
of particular importance from the analysis perspective are
those that may admit \unsafe" traces in the resulting sys-
tem. Intuitively, these mappings encode insecure design de-
cisions, in that they may introduce new behavior into the
system that can potentially be exploited for an attack.
Given a mapping specication S, a single analysis can be
used to not only nd a counterexample trace that violates
a given property, but also generate a mapping that permits
such a trace to be a valid behavior of the composed system.
Letp1;p2;:::;pnbe the set of nprocesses in the system, and
S1;S2;:::;Sn 1be the set of user-specied mapping specica-
tions, where Skspecies the relationship between processes
pkand pk+1. Then, the mapping generation problem can
be stated as nding witnesses to the following existential
formula:
n 1
9
i=1miLL(n 1^
j=1miSj)^
9Sys2PSys=compose (fp1;:::;png;fm1;:::;mn 1g)^
9t2beh(Sys):Prop (t)
where compose (X;M) returns a process that results from
the pairwise composition of the processes in Xusing the set
of mappings in M:
compose (fp1;:::;png;fm1;:::;mn 1g) = (( p1k
m1p2)k
m2:::)k
mn 1pn
Informally, this problem involves generating a set of map-
pings that (1) satisfy the user-specied specications ( S1;:::Sj),
and (2) when used in the composition of given processes, al-
low the resulting system ( Sys) to produce a trace that leads
to the violation of a given property ( Prop ).
{reqimp}{reqtrig}{addtoÔ¨Ä,0reqimp}{addtoÔ¨Ä}{loginalice}{reqcookie}{loginalice,0reqcookie}X{reqtrig}(b)0HTTP0view(a)0Store0view(c)0composi?on0Figure 4: Sample traces from the store example. An event
highlighted red is one that results in a violation of a property.
An \X" mark on an edge between events e1and e2means e2
cannot occur following e1, rendering the entire trace invalid.
4.3 Example
Let us apply Sfrom Section 4.1 to partially specify a map-
ping mbetween Store and Server . In addition, to model
a customer who interacts with the store through a browser,
we will use the same mapping to construct a process where
Alice's events are represented as HTTP requests:
StoreServer =Storek
mServer
AliceBrowser =Alicek
mBrowser
To model the behavior of an attacker, we will allow Eve
to act both as a Browser , interacting with other servers by
sending malicious requests, and as a Server , providing its
own pages that may be visited by Alice on her browser:
Attacker =Evek
m0(ServerkBrowser )
We want to perform a security analysis against an attacker
that behaves non-deterministically in the worst possible man-
ner, and so we will specify a mapping that does not constrain
how Evemay make use of Server and Browser :
S0=fa;b2LjTrueg
Essentially, S0allows the analysis to explore all possible ways
of mapping Eve's events onto those of Browser orServer .
Finally, we can construct the overall system where the
attacker interacts with the store and Alice as an attempt to
undermine the security of the system:
StoreSys =StoreServerkAliceBrowserkAttacker
Given these processes, the specications Sand S0, and the
cart integrity property, the analysis engine will attempt to
generate mand m0such that when used for composition,
the resulting process StoreSys allows at least one trace that
violates the property.
Analysis Figure 4 shows traces from three dierent views:
(a) the initial store design ( AlicekStore ), (b) the generic
server-browser architecture ( ServerkBrowser ), and (c) the
deployed store system ( StoreSys ). As discussed earlier in
Section 3.1, trace (a) is not a valid trace of AlicekStore ,
since Alice would never perform add toff.
Consider trace (b), which describes the following generic
HTTP requests in sequence:
reqcookie (o;c): A request that returns a value cand
stores it as a cookie at the origin oof the request URL,
reqtrig(u): A request that returns an HTML document
containing an imgtag with a URL uin its srcattribute;
reqimp(u;cs): A request made to a URL u, implicitly
generated by the browser after it receives an HTML doc-
186ument containing an imgtag. Also, all cookies ( cs) as-
sociated with the origin of uare automatically included
in the request headers (standard browser behavior).
Our analysis generates a mapping that relates event labels
from the store and HTTP models, including ones in Figure 4:
m=f(loginAlice;reqcookie (originStore;loginAlice:t));
(add toff;reqimp(url toff;fadd toff:tg));:::g
where l:tis the token parameter associated with event label
l, and url toffis a URL that has the following structure:
url(originStore;pathAdd;fquery (item;toff)g)
The generated mapping indicates that the token given to Al-
ice after the log-in is stored as a cookie in her browser, which
then includes the same cookie in subsequent Addrequests to
the store server.
Along with this mapping, the analysis also generates a
counterexample trace to demonstrate how the resulting sys-
tem, StoreSys , violates the integrity of the shopping cart
(trace (c) in Figure 4). In this sequence, Alice rst logs onto
the store on her browser, and then visits a malicious site set
up by Eve's server through reqtrig. This request is speci-
cally crafted by Eve to trigger Alice's browser to generate a
request at the URL ( url toff) that corresponds to the Add toff
event. Since this triggered request ( reqimp) includes Alice's
token as a cookie, it is deemed by the store as coming from
Alice, causing in the unwanted item to be added to her cart.
5. IMPLEMENTATION
We have implemented a prototype of our approach in a
tool called Poirot. The user interacts with the tool by spec-
ifying models in Poirot's input language, and running the
analysis, which, in turn, leverages a constraint solver for
generating mappings and counterexamples. In this section,
we briey describe notable aspects of Poirot; more details
about the tool can be found in [20, Chapter 5].
Modeling Language Poirot provides an input language
for specifying a system model, security properties, and rep-
resentation mappings; it is embedded as a domain-specic
language in Ruby. Notable features of the language includes
a module system for encapsulating domain models, declara-
tive constraints for dening guards and mappings, and ad-
ditional language constructs for dening component states.
Analysis Engine A Poirot model is translated into Al-
loy [18], a modeling language based a rst-order relational
logic. Its backend tool, the Alloy Analyzer, uses an o-the-
shelf SAT solver to generate sample instances or check prop-
erties of a given model. The analysis in Alloy is exhaustive
but bounded up to a user-specied scope on the size of the
domains; in the context of Poirot, these bounds correspond
to the number of processes, data values, and events as well
as the length of event traces that will be analyzed.
Domain Model Library Poirot contains an extensible li-
brary of domain models that can be used to elaborate the
user's input system model. Domain models encode dier-
ent types of knowledge, including descriptions of protocols,
architecture styles, features, and security threats. For our
case studies, we populated the library with a number of do-
main models that describe dierent layers of a web system,
based on well-known security sources such as OWASP [31]
and CAPEC [28]; the models can be categorized as:HTTP-related: HTTP protocol, browser scripting, same-
origin policy (SOP), cross-origin resource sharing (CORS);
Network-related: network packets, routing, DNS;
Authentication mechanisms: symmetric and public-key
encryption, OAuth.
The models are approximately 1200 LOC in total, and took
around 4 man-months to build; most of the eort was spent
on gathering the domain knowledge and ensuring the delity
and generality of the models. Note that Poirot is not tied to
a particular domain, and can be used to model other types of
systems, as long as they can be captured in our formalism.
6. CASE STUDIES
We describe our experience on applying Poirot to ana-
lyze two publicly deployed systems: IFTTT and Handme.In.
Our goal was to answer whether (1) Poirot can be used to
nd attacks that exploit the details of the system across mul-
tiple abstraction layers, and (2) its analysis scales to nding
realistic attacks.
6.1 Methodology
Each case study involved the following steps: (1) con-
structing a model of the system in Poirot, (2) performing an
analysis to generate potential attack scenarios and (3) con-
rming that the scenarios are feasible on the actual system.
In each study, we constructed and analyzed the system
model in an incremental fashion, beginning with an abstract
design of the system and mapping it to relevant domain
models from Poirot's library. Some domain models were em-
ployed in both systems (e.g., HTTP protocol, browser script-
ing), but others were not (e.g, OAuth was relevant only for
IFTTT). The complete models for the case studies and the
tool are available at http://sdg.csail.mit.edu/projects/poirot .
Each counterexample trace generated by Poirot describes
a possible attack on at the modeling level . To conrm whether
such an attack is feasible in reality, we constructed concrete
HTTP requests that correspond to the events, and replayed
them from our browser using the TamperData tool [19].
In total, Poirot generated 7 counterexamples for IFTTT,
and 8 for HandMe.In; out of these, 4 were conrmed to be
feasible attacks (2 for each). The rest were false positives,
either due to inaccuracies in our models or generated map-
pings that do not reect the actual design of the system.
Most of these were caused by our initial misunderstanding
of the system behavior; had we ourselves been the develop-
ers of the systems, we believe that the false positive rate
would have been lower.
6.2 IFTTT
IFTTT is a system that allows a user to connect tasks
from dierent web services using simple conditional state-
ments. The basic concept in IFTTT is a channel |a service
that exports a number of functions through its API. IFTTT
allows a user to make a recipe , which consists of a trigger and
anaction . Once the recipe is created, each time a trigger is
performed, IFTTT automatically executes the correspond-
ing action. For example, one recipe may say that whenever
the user is tagged in a Facebook photo, a post containing
the photo should be created on the user's Blogger account.
Since IFTTT performs tasks automatically on the user's
behalf, possibly accessing her private data, the user must
187{approve}{getToken}{doAc1onEve}{authen1cate}(b)&OAuth(a)&IFTTT(c)&HTTP(d)&composi9on{ac1vateEve}X{mkRecipe}{doTriggerAlice}{reqimp,;loginEve,;authen1cate}{mkRecipe}{approve,ac1vateEve}{getToken}{doAc1onEve}{doTriggerAlice}{reqtrig}{reqimp}{loginAlice}{reqtrig}Figure 5: Sample traces from IFTTT models.
give IFTTT a permission to access her accounts on the se-
lected channels; for this purpose, IFTTT employs a third-
party authorization protocol called OAuth [16]. For exam-
ple, before the recipe can take eect, the user must approve
IFTTT to (1) access her photos on Facebook, and (2) create
new blog posts on her Blogger account. When IFTTT is
given a permission to access an account on a channel, we
say that the channel has been activated for that account.
The goal of this case study was to use Poirot to check
whether IFTTT channels could be connected in an insecure
way, allowing a malicious person to access information that
would not have been possible without IFTTT. In particular,
we analyzed the following security property: A user's private
data on a channel should only be accessible from the same
user's accounts on other channels.
For our study, we constructed a model of the IFTTT work-
ow (around 140 LOC in Poirot), and composed it against
(1) a model of OAuth, to elaborate its authorization pro-
cess, and (2) the HTTP model from the domain library, to
reason about how IFTTT behaves when deployed on a web
server. Constructing and analyzing the overall model took
us around 1.5 weeks in total. Since our goal was to analyze
the security of IFTTT's service composition mechanism|
instead of looking for aws in a particular web service|we
did not explicitly model the details of individual web ser-
vices themselves. Instead, we built archetypal descriptions
of channels, triggers, and actions that over-approximate all
possible dataow throughout the system.
We discuss one of the discovered attacks, which exploits
details across the three dierent layers of the system: IFTTT,
OAuth, and HTTP.
Information Leakage with Login CSRF One way the
attacker (named Eve) may attempt to access private data
owned by another user (Alice) is to get IFTTT to link Alice's
and Eve's accounts through the same recipe. This way, when
a trigger is performed on Alice's account, IFTTT would per-
form the corresponding action on Eve's account, inadver-
tently directing data from Alice's account to Eve's.
Figure 5 shows sample traces from the three dierent mod-
els and their composition. In the abstract IFTTT model,
which describes its high-level workow, such an attack is
not possible, given an assumption (encoded in the Alice
process) that when Alice makes a recipe, she activates the
associated channels only for her accounts. Thus, a trace
where the creation of Alice's recipe ( mkRecipe ) is followed by
the activation of a channel for Eve's account ( activate Eve),
as shown in Figure 5(a), is not a valid trace in this model.
Figure 5(b) shows a sequence of events that occurs in a
typical OAuth workow. It begins with a user authenticat-ing herself with an identity provider (e.g., Blogger), which
then asks the user to conrm whether she approves access
to her account by a third-party (e.g., IFTTT). If so, then
the third-party may obtain an access token to her account
directly from the identity provider (through getToken ).
Finally, Figure 5(c) shows a simple trace where one HTTP
request ( reqimp) is triggered by another ( reqtrig) inside a
browser; in Section 4.3, we discussed how this generic se-
quence may be exploited for a CSRF attack in the context
of another system.
In the composition of the three models, an attack on
IFTTT becomes possible, as shown in Figure 5(d). It be-
gins with a variant of CSRF (called login CSRF ), where
a victim is unknowingly logged into a site under the at-
tacker's account2. This login event has three representations
assigned to it by the generated mapping: (1) reqimp, which is
caused indirectly by Eve when Alice visits Eve's site through
reqtrig, (2) loginEve, which results in Alice getting logged
onto a channel site as Eve, and (3) authenticate , which
fullls the initial authentication step of an OAuth process.
In the next step, Alice proceeds to make a new recipe
with an action on that same channel. Since she is already
logged onto the site (albeit as Eve), she is not required to au-
thenticate herself with the action channel during the OAuth
workow; she simply needs to approve IFTTT's access to
Blogger. Once IFTTT obtains a token to access Eve's ac-
count from the action channel, this account remains associ-
ated with the new recipe. As a result, whenever the trigger
is performed on Alice's account ( doTriggerAlice), IFTTT
immediately performs the corresponding action on Eve's ac-
count ( doAction Eve), leaking Alice's data to Eve.
As far as we are aware, this was a previously unknown
issue with IFTTT. The insecure design decision that en-
ables this attack is the encoding of the login operation on
a channel as an HTTP request without protection against
CSRF. We conrmed that 4 channel sites on IFTTT were
vulnerable to this attack, and notied their developers of
the security aw; 3 of them have since addressed the issue,
by adding CSRF protection to their login page.
6.3 HandMe.In
Handme.In (http://handme.in) is a web application de-
signed to facilitate easy recovery of personal items. In a
typical workow, the user purchases a sticker with a unique
code written on it, and places the sticker on a physical item
to be tracked. If the item is lost, its nder can notify the
owner of by entering the code and other relevant informa-
tion (e.g., an arrangement to return the item in person) on
the site. It currently has over 20,000 registered stickers.
The process for the payment of stickers is delegated to
Paypal, which oers a service called Instant Payment No-
tication (IPN). When a customer initiates to purchase a
sticker, HandMe.In redirects her to the Paypal IPN site.
After she makes a successful payment on Paypal, the IPN
system will send the customer and billing information to the
merchant site, which may then nalize the order.
For our study, we constructed the models of HandMe.In
and Paypal IPN protocols in Poirot (around 200 LOC), and
2Normally, login CSRF is considered a minor form of attack,
because at most it allows the attacker to access a log of the
victim's actions (e.g., search history on Google). In context
of IFTTT, however, it can be used to carry out an attack
with far more serious consequences, as discussed here.
188Figure 6: Average analysis times over trace lengths.
composed them together with the HTTP model. Construct-
ing and analyzing the overall model took around 2 weeks.
We analyzed the following property of the system: Infor-
mation about a lost item entered by the nder should be
accessible only to the owner of the item. We briey describe
one feasible attack on the system:
Missing Check during Payment The IPN service pro-
vides no guarantee that the person paying for a product
is the same person who will receive the product. Paypal
sends back information about the payer (e-mail, billing ad-
dress, etc.,), and the merchant may perform further checks
to ensure that the product will be delivered to the same per-
son. HandMe.In does not perform such checks, because it
assumes that a user will be directed to the IPN site only
by following the standard workow on HandMe.In. This
assumption is reasonable at the business logic layer, but
is violated when the user interacts with the site through
a browser. In particular, a web attacker may redirect the
user to an IPN site for a sticker that has already been as-
signed to the attacker; the victim might then unknowingly
pay for and receive a sticker that is linked to the attacker,
leading to a violation of property (1). This attack combines
details from the HandMe.In, Paypal, and HTTP models.
We notied the result of our analysis to the developer,
who have since addressed all of the reported security aws.
6.4 Analysis Performance
We evaluate the scalability of Poirot's analysis over the
two case studies. As discussed in Section 5, the analysis
relies on constraint solving over nite domains, and so it
must be given an explicit scope to bound the number of
processes, data values, events, and the maximum length of
traces. Figure 6 shows the average analysis times for the two
cases studies as the maximum length of traces is varied; we
used a xed scope of 8 for processes and 12 for data values.
The analyses were performed on a Mac OS X 1.8 GHz with
4G RAM, with the Lingeling [4] SAT solver.
Figure 6 shows an exponential growth trend for the analy-
sis times as the trace length increases; this is not surprising,
since the number of possible event combinations that must
be explored also grows exponentially. Among the counterex-
amples that were generated, the shortest trace had 4 events,
and the longest one had 11 events; we performed additional
analysis up to the trace length of 16 without discovering any
more counterexamples. In all cases, the analysis took under
15 seconds. The results do not necessarily imply that the
checked properties are valid, as there might exist a coun-
terexample beyond the maximum scope that we used. How-
ever, based on our experience applying Poirot to a number
of examples, we believe that the bounds we used were largeenough to capture many common web security attacks.
6.5 Discussion
Threats to Validity There are two potential sources of
errors in our case studies: (1) delity of the models, and
(2) insucient scope used in analysis (as discussed above).
To ensure the accuracy of the HandMe.In system model, we
closely worked with its lead developer throughout the entire
process; for IFTTT and Paypal IPN, we consulted available
documentation on the system, and studied the details of its
behavior by inspecting HTTP requests throughout the site.
Like in any model-based analysis, however, it is possible that
our models inadvertently excluded a detail that would have
lead to the discovery of a new counterexample.
Building a faithful model is a challenging task in general,
but we believe that it is not an inherent limitation to our
composition and analysis approach. For example, to reduce
the modeling eort and improve its delity, Poirot could be
complemented with techniques on extracting models from
logs or implementation, some of which have been developed
in the context of security [2, 7].
Lessons Learned We have used Poirot to model and ana-
lyze a number of small and large systems, the most complex
ones being the two systems above. We were successfully able
to reuse the domain models across most of these systems, in
part because we invested considerable eort (4 months) into
ensuring the generality of the models; based on our experi-
ence, we believe that reusability justies this upfront cost.
We also expect Poirot's library to grow in size and applica-
bility over time. For example, we initially created a model
of the OAuth protocol [16] in order to analyze it, and we
were able to reuse the same model for the IFTTT study.
The implementation for each of the two systems was not
available, and the public documentation only described the
system behavior at the high-level workow or APl level.
Thus, we had to deal with some uncertainty about how the
system was actually implemented as a web application. Be-
ing able to express these unknown information as a par-
tial mapping, and having an automatic analysis to suggest
us potentially insecure design decisions, was crucial for our
analysis; without this ability, we would need to manually try
out possible mappings in an ad-hoc manner.
Incrementality In each of the case studies, we constructed
three increments of the system model: (1) composition of an
initial design with another abstract model (e.g., IFTTT and
OAuth), (2) with an HTTP protocol model, and nally, (3)
with a model of browser scripts. Some of the discovered at-
tacks involved only the logic in the abstract design, whereas
others also relied on the details in the HTTP and browser
models. For example, the attack in Section 6.3 combined a
weakness in the business logic of HandMe.In and a browser
redirection feature, and thus, was not discovered until the
increment (3). But we were also able to nd a much sim-
pler attack in (1), which exploited only a aw in the way
HandMe.In assigned codes to its stickers.
Coming up with a complete model of a system at once is
often too onerous, and so we believe that being able to dis-
cover and address security issues in this incremental manner
is crucial to reducing the designer's burden. On the other
hand, during each increment, the analysis step became com-
putationally more challenging, as the SAT instance gener-
ated by the Alloy Analyzer increased in size. It would be
desirable to be able to reuse (where possible) some of the re-
189sults from prior analyses; we plan to investigate this problem
as a way to improve the scalability of our analysis approach.
7. RELATED WORK
Views Our work was strongly inuenced by previous re-
search on views in software engineering [10, 17, 30]. In a
typical development process, various stakeholders may have
diering views on the system, hampering the construction
of a single, coherent global model. In the context of secu-
rity, the attacker can be regarded as one of the stakeholders
(with a malicious intent to sabotage the system), exploiting
details in a view that diers from that of the designer.
Model merging is an active line of research on techniques
and tools for composing independent models. Merging tech-
niques have been developed for various types of models, in-
cluding architectural views [26], behavioral models [3, 29,
37], database schemas [32], and requirements [34]. Among
these, the works on behavioral models are most closely re-
lated to our work [3, 29, 37]. A common property guar-
anteed by their frameworks is the preservation of behavior:
that is, when two models M1and M2are merged, the re-
sulting model M0renes the behavior of both M1andM2In
comparison, our goal is to explore ways in which a property
inM1may be violated by added behavior from M2.
Reasoning with Uncertainty Researchers have studied
the problem of constructing and analyzing a partial model ,
where certain behavioral or structural aspects of a system
are specied to be unknown , and an analysis is performed
to check properties of the system in the absence of those
information [6, 11, 15, 21]. Our work diers from the above
approaches in two ways. First, all of these approaches ad-
dress uncertainty that arises due to delayed decisions about
whether a particular feature or characteristic of a system
should be included in the nal design. In comparison, our
approach deals with uncertainty over potential relationships
between two distinct but possibly overlapping views of a sys-
tem. Such uncertainty may stem from, for instance, alter-
native decisions about how a particular abstract operation
or data type is to be represented in terms of another, more
concrete element. Second, in the existing approaches, un-
certainty is expressed over a set of modeling terms with a
xed vocabulary. As a result, they do not handle cases in
which new, distinct elements may be introduced and related
to parts of an existing model.
In this sense, our work is more closely related to the one
by Li, Krishnamurthi, and Fisler [23], where they propose
a methodology for composing a system model against in-
dependent features and analyzing their potential impact on
the system behavior. Like ours, their approach allows new
propositions to be introduced into an existing \base" model,
giving rise to new behavior and, possibly, a violation of a
previously established property. The two approaches dier
in the type of composition performed. Their composition
involves conjoining a feature with a base model at special,
designated states called interfaces , and is particularly suited
at reasoning about ordered, sequential composition of fea-
tures. In comparison, our composition involves relating a
pair of models across dierent abstraction layers, and is in-
tended to reason about the impact of design choices on the
underlying representation of a system entity.
Security Modeling and Composition A large body of
work exists on modeling systems and protocols for secu-
rity analysis. Most protocol languages describe a system interms of abstract agents and messages between them, and
are not designed for elaborating their underlying representa-
tions [1, 24, 36]. Several compositional security frameworks
have been proposed as a way of establishing the end-to-end
security of a system by combining the properties of individ-
ual component models [9, 12, 25]. In these approaches, com-
position involves bringing together two parallel processes
that communicate through a xed interface at the same level
of abstraction (e.g., a server and a client). In comparison,
our approach involves composing processes that partly or
entirely overlap with each other, in that they represent the
same entity at dierent levels of abstraction (e.g., abstract
store and concrete server on which it is deployed).
Another related work is Georg and her colleagues' work on
an aspect-oriented approach to security modeling and anal-
ysis [13]. In this approach, a set of generic attack models
(called security aspects) are instantiated against a primary
system model, and the Alloy Analyzer is used to check the
composed model against a security property. Our approach
diers from theirs in two ways. First, during the instan-
tiation step, the user must provide a full correspondence
between two models, unlike our approach where a partial
mapping is sucient for performing an analysis. In addi-
tion, our notion of representation is more general than their
notion of correspondence, which is limited to a mapping be-
tween the names of modeling elements. Their approach does
not allow, for example, a more complex mapping that relates
thestructures of two elements (e.g., encoding AddasReq).
8. LIMITATIONS AND CONCLUSIONS
In our approach, all events are treated as atomic entities.
But sometimes it may be desirable to specify a certain event
as itself consisting of a set of more detailed events performed
in a particular order. For instance, an HTTP request, rep-
resented as a single event at a high-level of abstraction, may
actually involve a series of handshakes between the server
and the client. To accurately model such hierarchical rela-
tionships, our mapping would need to be extended to allow
an event to be mapped to a sequence of events.
Poirot currently allows the user to specify and check trace
properties |a type of properties that can be evaluated by
inspecting a single execution trace (e.g., \nothing bad ever
happens"). However, certain classes of security properties
inherently talk about multiple traces of a system [8]. For
instance, a non-interference property says that an attacker
should not be able to learn new information by observing
how the system behavior changes when other users partic-
ipate in its services. In order to analyze such properties,
our analysis would need to be extended to perform a higher-
order reasoning where setsof traces are explored at once.
Given a partially specied m, our analysis generates map-
pings that lead to security violations. It may also be possible
to instead generate a mapping that guarantees that the re-
sulting system satises a given property; this would involve
reasoning about each candidate mapping over all possible
traces of a system, and thus require a higher-order analysis.
As a next step, we plan to incorporate techniques from soft-
ware synthesis [27, 35] to provide this capability in Poirot.
Acknowledgement We thank St ephane Lafortune, Matt
McCutchen, Joseph Near, Stavros Tripakis, and our review-
ers for their insightful comments and suggestions. This work
was supported in part by the NSF Award CRD-0707612, and
by the Singapore University of Technology and Design.
1909. REFERENCES
[1] M. Abadi and A. D. Gordon. A calculus for
cryptographic protocols: The spi calculus. In CCS '97,
Proceedings of the 4th ACM Conference on Computer
and Communications Security, Zurich, Switzerland,
April 1-4, 1997. , pages 36{47, 1997.
[2] G. Bai, J. Lei, G. Meng, S. S. Venkatraman,
P. Saxena, J. Sun, Y. Liu, and J. S. Dong.
AUTHSCAN: automatic extraction of web
authentication protocols from implementations. In
20th Annual Network and Distributed System Security
Symposium, NDSS 2013, San Diego, California, USA,
February 24-27, 2013 , 2013.
[3] S. Ben-David, M. Chechik, and S. Uchitel. Merging
partial behaviour models with dierent vocabularies.
InCONCUR 2013 - Concurrency Theory - 24th
International Conference, CONCUR 2013, Buenos
Aires, Argentina, August 27-30, 2013. Proceedings ,
pages 91{105, 2013.
[4] A. Biere. Lingeling essentials, A tutorial on design and
implementation aspects of the the SAT solver
lingeling. In POS-14. Fifth Pragmatics of SAT
workshop, a workshop of the SAT 2014 conference,
part of FLoC 2014 during the Vienna Summer of
Logic, July 13, 2014, Vienna, Austria , page 88, 2014.
[5] B. Blanchet. An ecient cryptographic protocol
verier based on prolog rules. In 14th IEEE Computer
Security Foundations Workshop (CSFW-14 2001),
11-13 June 2001, Cape Breton, Nova Scotia, Canada ,
pages 82{96, 2001.
[6] G. Bruns and P. Godefroid. Model checking partial
state spaces with 3-valued temporal logics. In 11th
International Conference on Computer Aided
Verication, CAV 1999, Italy , pages 274{287, 1999.
[7] K. Z. Chen, W. He, D. Akhawe, V. D'Silva, P. Mittal,
and D. Song. ASPIRE: iterative specication synthesis
for security. In 15th Workshop on Hot Topics in
Operating Systems, HotOS XV, Kartause Ittingen,
Switzerland, May 18-20, 2015 , 2015.
[8] M. R. Clarkson and F. B. Schneider. Hyperproperties.
Journal of Computer Security , 18(6):1157{1210, 2010.
[9] A. Datta, A. Derek, J. C. Mitchell, and A. Roy.
Protocol composition logic (PCL). Electr. Notes
Theor. Comput. Sci. , 172:311{358, 2007.
[10] S. M. Easterbrook and B. Nuseibeh. Managing
inconsistencies in an evolving specication. In RE,
pages 48{55, 1995.
[11] M. Famelis, R. Salay, and M. Chechik. Partial models:
Towards modeling and reasoning with uncertainty. In
34th International Conference on Software
Engineering, ICSE 2012, Zurich, Switzerland , pages
573{583, 2012.
[12] D. Garg, J. Franklin, D. K. Kaynar, and A. Datta.
Compositional system security with interface-conned
adversaries. Electr. Notes Theor. Comput. Sci. ,
265:49{71, 2010.
[13] G. Georg, I. Ray, K. Anastasakis, B. Bordbar,
M. Toahchoodee, and S. H. Houmb. An
aspect-oriented methodology for designing secure
applications. Information & Software Technology ,
51(5):846{864, 2009.
[14] C. A. R. Hoare. Communicating sequential processes.
Commun. ACM , 21(8):666{677, 1978.[15] M. Huth, R. Jagadeesan, and D. A. Schmidt. Modal
transition systems: A foundation for three-valued
program analysis. In 10th European Symposium on
Programming Languages and Systems, ESOP 2001,
Genova, Italy , pages 155{169, 2001.
[16] Internet Engineering Task Force. OAuth Authorization
Framework. http://tools.ietf.org/html/rfc6749, 2014.
[17] D. Jackson. Structuring Z specications with views.
ACM Trans. Softw. Eng. Methodol. , 4(4):365{389,
1995.
[18] D. Jackson. Software Abstractions: Logic, language,
and analysis . MIT Press, 2006.
[19] A. Judson. Tamper data plugin for refox. https://
addons.mozilla.org/en-us/refox/addon/tamper-data.
Accessed: 2015-03-15.
[20] E. Kang. Multi-Representational Security Modeling
and Analysis . PhD thesis, MIT, 2016.
[21] O. Kupferman, M. Y. Vardi, and P. Wolper. Module
checking. Information and Computation ,
164(2):322{344, 2001.
[22] B. W. Lampson. A note on the connement problem.
Commun. ACM , 16(10):613{615, 1973.
[23] H. C. Li, S. Krishnamurthi, and K. Fisler. Verifying
cross-cutting features as open systems. In 10th
Symposium on Foundations of Software Engineering,
South Carolina, USA , pages 89{98, 2002.
[24] G. Lowe. Casper: A compiler for the analysis of
security protocols. In 10th Computer Security
Foundations Workshop (CSFW '97), June 10-12,
1997, Rockport, Massachusetts, USA , pages 18{30,
1997.
[25] H. Mantel. On the composition of secure systems. In
2002 IEEE Symposium on Security and Privacy,
Berkeley, California, USA, May 12-15, 2002 , pages
88{101, 2002.
[26] S. Maoz, J. O. Ringert, and B. Rumpe. Synthesis of
component and connector models from crosscutting
structural views. In ESEC/FSE'13, Saint Petersburg,
Russian Federation, August 18-26, 2013 , pages
444{454, 2013.
[27] A. Milicevic, J. P. Near, E. Kang, and D. Jackson.
Alloy*: A general-purpose higher-order relational
constraint solver. In 37th IEEE/ACM International
Conference on Software Engineering, ICSE 2015,
Florence, Italy, May 16-24, 2015, Volume 1 , pages
609{619, 2015.
[28] Mitre. Common Attack Pattern Enumeration and
Classication. http://capec.mitre.org, 2014.
[29] S. Nejati, M. Sabetzadeh, M. Chechik, S. M.
Easterbrook, and P. Zave. Matching and merging of
statecharts specications. In ICSE , pages 54{64, 2007.
[30] B. Nuseibeh, J. Kramer, and A. Finkelstein.
Expressing the relationships between multiple views in
requirements specication. In ICSE , pages 187{196,
1993.
[31] Open Web Application Security Project. OWASP Top
Ten Project. http://www.owasp.org/index.php, 2014.
[32] R. Pottinger and P. A. Bernstein. Merging models
based on given correspondences. In VLDB , pages
826{873, 2003.
[33] P. Y. A. Ryan and S. A. Schneider. Modelling and
191analysis of security protocols .
Addison-Wesley-Longman, 2001.
[34] M. Sabetzadeh and S. M. Easterbrook. An algebraic
framework for merging incomplete and inconsistent
views. In RE, pages 306{318, 2005.
[35] A. Solar-Lezama, L. Tancau, R. Bod k, S. A. Seshia,
and V. A. Saraswat. Combinatorial sketching for nite
programs. In Proceedings of the 12th International
Conference on Architectural Support for Programming
Languages and Operating Systems, ASPLOS 2006,San Jose, CA, USA, October 21-25, 2006 , pages
404{415, 2006.
[36] F. J. Thayer, J. C. Herzog, and J. D. Guttman.
Strand spaces: Why is a security protocol correct? In
1998 IEEE Symposium on Security and Privacy,
Oakland, CA, USA, May 3-6, 1998, Proceedings ,
pages 160{171, 1998.
[37] S. Uchitel and M. Chechik. Merging partial
behavioural models. In SIGSOFT FSE , pages 43{52,
2004.
192