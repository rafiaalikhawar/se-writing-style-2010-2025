DIFFUZZ: Differential Fuzzing for Side-Channel
Analysis
Shirin Nilizadeh∗
University of Texas at Arlington
Arlington, TX, USA
shirin.nilizadeh@uta.eduYannic Noller∗
Humboldt-Universit ¨at zu Berlin
Berlin, Germany
yannic.noller@hu-berlin.deCorina S. P ˘as˘areanu
Carnegie Mellon University Silicon V alley,
NASA Ames Research Center
Moffett Field, CA, USA
Abstract —Side-channel attacks allow an adversary to uncover
secret program data by observing the behavior of a program
with respect to a resource, such as execution time, consumedmemory or response size. Side-channel vulnerabilities are difﬁcultto reason about as they involve analyzing the correlationsbetween resource usage over multiple program paths. We present
D
IFFUZZ , a fuzzing-based approach for detecting side-channel
vulnerabilities related to time and space. D IFFUZZ automatically
detects these vulnerabilities by analyzing two versions of theprogram and using resource-guided heuristics to ﬁnd inputs thatmaximize the difference in resource consumption between secret-
dependent paths. The methodology of D
IFFUZZ is general and
can be applied to programs written in any language. For thispaper, we present an implementation that targets analysis of
J
AVA programs, and uses and extends the K ELINCI and AFL
fuzzers. We evaluate D IFFUZZ on a large number of J AVA
programs and demonstrate that it can reveal unknown side-channel vulnerabilities in popular applications. We also show that
D
IFFUZZ compares favorably against B LAZER and T HEMIS ,t w o
state-of-the-art analysis tools for ﬁnding side-channels in J AVA
programs.
Index T erms—vulnerability detection; side-channel analysis;
dynamic analysis; fuzzing
I. I NTRODUCTION
Side-channel attacks enable an adversary to uncover sensi-
tive information from programs by observing non-functional
characteristics of program behavior, such as execution time,memory usage, response size, network trafﬁc, or power con-sumption. There is a large literature on side channels showingevidence that they are practical and can have serious securityconsequences [13], [22], [31]. For instance, exploitable tim-ing channel information ﬂows were discovered for Google’sKeyczar Library [28], the Xbox 360 [5] and implementationsof RSA encryption [13]. More recently, the Meltdown andSpectre side-channel attacks [4] have shown how to exploitcritical vulnerabilities in modern processors to uncover secretinformation. These vulnerabilities highlight the increased needfor tools and techniques that can effectively discover sidechannels before they are exploited by a malicious user inthe ﬁeld. However, side-channel vulnerabilities are difﬁcult toreason about as they involve analyzing correlations betweenresource usage over multiple program paths.
In this paper we present D
IFFUZZ, a dynamic analysis ap-
proach for the detection of side channels in software systems.
*Joint ﬁrst authorsGiven a program whose inputs are partitioned into public andsecret variables, D
IFFUZZ uses a form of differential fuzzing
to automatically ﬁnd program inputs that reveal side chan-nels related to a speciﬁed resource, such as time, consumedmemory, or response size. We focus speciﬁcally on timing andspace related vulnerabilities, but the approach can be adaptedto other types of side channels, including cache based.
Differential fuzzing has been successfully applied before for
ﬁnding bugs and vulnerabilities in a variety of applications,such as LF and XZ parsers, PDF viewers, SSL/TLS libraries,and C compilers [36], [38], [41]. However, to the best ofour knowledge, we are the ﬁrst to explore differential fuzzingfor side-channel analysis. Typically such fuzzing techniquesanalyze different versions of a program, attempting to discoverbugs by observing differences in execution for the sameinputs. In contrast D
IFFUZZ works by analyzing two copies
of the same program, with the same public inputs but withdifferent secret values, and computing the difference in side
channel measurements (time or space) observed over the twoexecutions. If the difference is large, then it means that theprogram has a side-channel vulnerability, which should beremedied by the developer.
The approach is similar to the well-known method of self-
composition [10]), which is used to check that no matter what
the secret is, the program yields the same output. If thatis the case, the program is said to satisfy non-interference,
meaning that the program leaks noinformation; otherwise,
the program is vulnerable. However, it has been argued [8],[14] that non-interference with regard to side channels istoo strong a property for most realistic programs, as it isalmost always the case that some variation in resource usage,particularly execution time, exists for different program paths.If the difference is small, it may not be exploitable in practice,since it may not be actually observable by an attacker. Forexample, consider the case of a client-server application. Smallvariations in execution time on the server side may not beobservable (and therefore exploitable) on the client side. Insuch cases the program can be considered secure although itdoes not satisfy non-interference. If on the other hand, thedifference is large, this indicates a side-channel vulnerabilitysince an attacker can use differences between measurementsto distinguish between secrets. For this reason, D
IFFUZZ
does not merely check non-interference, but instead employs
1762019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ©2019 IEEE
DOI 10.1109/ICSE.2019.00034
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. resource-guided heuristics to automatically ﬁnd inputs that
attempt to maximize the difference in resource consumption
between secret-dependent paths.
The methodology that we advocate with D IFFUZZ is general
and can be applied to programs written in any language. For
this paper we present an implementation that targets J AVA
programs and is based on A MERICAN FUZZY LOP(AFL) [42]
and K ELINCI [24]. AFL is a fuzz testing tool that uses genetic
algorithms to mutate user-provided inputs using byte-level
operations with the goal of increasing coverage; K ELINCI pro-
vides an interface to execute AFL on J AVA programs. To per-
form side-channel analysis, D IFFUZZ instruments a program
to record resource consumption, in addition to coverage, along
the paths that are executed by the fuzzed inputs. Furthermore,
DIFFUZZ records the difference in resource consumption in a
user-deﬁned cost. This difference is sent back to the fuzzer,
whose mutants are marked as important if there is an increase
in the computed difference, thus guiding the fuzzer towards
inputs that expose vulnerabilities.
We have applied D IFFUZZ on well-known, widely used
JAVA applications, such as Apache FtpServer [1] and Auth-
MeReloaded [2], where we found new, previously unknown,
vulnerabilities, which were conﬁrmed by the developers. Ad-
ditionally we have applied our approach on complex examples
from the DARPA Space/Time Analysis for Cybersecurity
(STAC) program [20], IBASys, an image-based authentication
system, and CRIME, an instance of the Compression Ratio
Info-leak Made Easy attack [19], where we found vulnerabil-
ities related to both time and space consumption.
We also compared D IFFUZZ with B LAZER [8] and T HEMIS
[14], two state-of-the-art analysis tools for ﬁnding side chan-
nels in J AVA programs. Both tools perform static analysis and
can in principle guarantee absence of side channels, but may
also give false alarms due to underlying over-approximation.
In contrast D IFFUZZ performs a dynamic analysis, and thus
does not give false alarms (provided that the fuzzing driver is
meaningful, see Section 2.3.), but it can not prove absence of
vulnerabilities.
We evaluated D IFFUZZ on the same benchmarks from
THEMIS and B LAZER and were able to ﬁnd the same vulnera-
bilities. We also ran D IFFUZZ on the corrected (safe) versions
(when they were available). For the majority of these cases,
we found that as expected, D IFFUZZ correctly ﬁnds zero or a
small differences thus showing the usefulness of the approach
also in the case of absence of vulnerabilities. However, we
have also found that, in some cases, D IFFUZZ uncovered new
vulnerabilities in versions which were shown to be safe with
BLAZER and T HEMIS .
In summary, this work makes the following contributions:
•We present D IFFUZZ, the ﬁrst differential fuzzing ap-
proach for ﬁnding side-channel vulnerabilities.
•We evaluate D IFFUZZ on multiple security-critical J AVA
applications and we report new vulnerabilities in well
known J AVA applications, such as Apache FtpServer.
•We compare with state-of-the-art tools B LAZER and
THEMIS , where we highlight some new vulnerabilitiesin programs that were previously deemed safe.
II. A PPROACH
Figure 1 shows the overview of our differential fuzzing
approach. To start the analysis, the user needs to provide initial
seed ﬁles that exercise the program under test (cf. step 1 in
Figure 1). The user also needs to provide a driver , which
parses an input ﬁle into three elements pub (common public
value),sec1, andsec2(two secret values, one for each program
copy) and executes two copies of the program on these inputs.
The program is instrumented to record resource consumption
and coverage information.
The seed ﬁles are put into a queue for further processing
(cf. step 2 in Figure 1). This queue is used during the whole
process as the central data structure that includes all the inputs
that are deemed interesting by the analysis. The fuzzer will
take the inputs from the queue and will mutate them repeatedly
(cf. step 3 in Figure 1). In order to decide whether a mutated
input is interesting for further processing, D IFFUZZ executes
the driver with this input, computes the cost difference between
two executions, which is handled as the score for this input,
and compares it with the maximum cost difference (aka cost
difference high-score ), which was observed in the previous
executions (cf. step 4 in Figure 1).
Only the inputs that either lead to increased high-score or to
increased overall program coverage will be forwarded to the
fuzzing queue (cf. step 5 in Figure 1). The process is repeated
until a user-speciﬁed timeout occurs.
We describe the D IFFUZZ approach in more detail below.
A. Side-Channel Analysis
Information ﬂow analysis is typically used to determine that
a program manipulates secret data in a secure manner. The
analysis accepts programs as secure if the secret data can not
be inferred by an attacker through their observations of the
systems. This intuitive property is called non-interference .I n
the case of side-channels, the observations consist of the side-
channel measurements that an attacker can make.
There are many techniques for checking non-interference.
The simplest one is through self-composition [10]. At a high
level the technique reduces the problem of secure information
ﬂow of a program to analyzing two copies of the same
program, where the secret inputs are renamed, but the public
values stay the same, and checking that these two copies create
the same observation.
LetPbe a program, and P/llbracketpub,sec /rrbracketbe the execution of
the program Pwith inputs pub andsec. As it is customary
in the security literature, we break down the program inputs
to a tuple of public (low) values and secret (high) values. We
abbreviate the public values as pub and the secret values as
sec. Furthermore let c(.)be the evaluation of a program exe-
cution with respect to a particular cost encoding the resource
usage (e.g., execution time or response size) of the program.
The non-interference requirement can then be formalized as
follows:
∀pub,sec 1,sec 2:c(P/llbracketpub,sec 1/rrbracket)=c(P/llbracketpub,sec 2/rrbracket)
177
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. initial seed
filesqueuemutate
repeatedlymutated files that
showed (new) 
interesting behavior
assess input for
instrumented program Pparse input
1 23
45
pub, sec 1P[pub, sec 1]
P[pub, sec 2]pub, sec2calculate cost
differencecov1, cost1
cov2, cost2check: 
increased
cost difference
orincreased
coverage ?fuzzing driver
costdiff= 
|cost1-cost2|
Fig. 1: Overview of D IFFUZZ approach.
Intuitively, the property states that any two secrets are
indistinguishable through the side-channel observations and
therefore can not be uncovered by an attacker.
Although satisfying non-interference is a sound guarantee
for a system to be secure, this requirement is too strict for
the side-channel analysis of most realistic programs. Particu-larly for timing channels, small differences in computationsmay be imperceptible to an attacker and can thus not beexploited in practice. This problem was observed in variouspapers before [8], [14] and was formalized as checking /epsilon1-
bounded non-interference in [14]: not only programs withzero interference can be accepted as secure, but also programswhere the difference between observations is too small (belowa threshold /epsilon1) to be exploitable in practice. Thus the program
is deemed to be secure if the following condition holds:
∀pub,sec
1,sec 2:|c(P/llbracketpub,sec 1/rrbracket)−c(P/llbracketpub,sec 2/rrbracket)|</epsilon1
One can perform the above check by enumerating all the
possible input combinations, measuring the resource con-sumption for each run, and performing the check for thetwo versions of the program, but this could become quickly
intractable for most realistic programs.
We therefore advocate the use of fuzzing to address the
problem. However typical fuzzing tools are engineered to only
increase code coverage and can thus be very slow in generatinginputs that expose a signiﬁcant difference in resource con-sumption. The key ingredient of our approach is the incorpora-tion of heuristics that guide the fuzzing towards conﬁgurationsthat maximize this difference, as explained in the followingsections. Note that, unlike previous techniques, that use staticanalysis to check /epsilon1-bounded non-interference [8], [14], we do
not require the user to provide an a-priori threshold /epsilon1; instead
we let the tool try to maximize the difference between secret-dependent paths.
B. Attacker Model
We review here the attacker model considered in this paper,
which is similar to previous work on the topic [8], [14]. We
assume the program is deterministic and that the side-channelmeasurements are precise. We further assume that the attackercan not observe anything else (i.e., the attacker does not use themain-channel to infer information). When measuring resourceusage we assume that any variations are caused by the applica-tion software, and we are thus ignoring side-channels relatedto the hardware architecture or the physical environment. Inprinciple we can handle all these side-channels by using anavailable model of the corresponding resource. Even in the
absence of a model, we could use the inputs generated by the
fuzzer to run the programs on a speciﬁc platform and performactual, precise measurements with respect to the resource ofinterest. Furthermore, we could measure the wall-clock timeand also the JIT (just-in-time compilation) effect.
The mentioned assumptions are realistic. For example imag-
ine a server-client scenario in a distributed environment (sim-ilar described in [14]), in which the attacker is physicallyseparated from the victim application, i.e. there is no chance toobserve any physical side-channel. For an encrypted networkcommunication the attacker cannot read the content of thesent messages, and hence, relies on the metrics that can beobserved during communication with the server, like responsesizes and response times. Additionally, based on the physical
distribution the attacker should not have the possibility to
manipulate the victim application to observe any hardware-level side-channels.
Note that D
IFFUZZ is also applicable to non-deterministic
code and in the experiments we report on such an application.However, in general the results could be imprecise in thiscase, due to the noise introduced in the measurements. More
analysis would be necessary, which is left for future work.
C. Differential Fuzzing
Our approach aims to use fuzzing to analyze the two copies
of the program and to guide it to ﬁnd inputs that maximize
the cost difference between two program executions, for which
only the secret values are different:
maximize:
pub,sec 1,sec 2δ=|c(P/llbracketpub,sec 1/rrbracket)−c(P/llbracketpub,sec 2/rrbracket)|(1)
Fuzzing Driver: In order to apply fuzzing we need a driver
that parses the inputs from the fuzzer and executes the twocopies of the code under test, while also measuring the costdifference. Procedure 1 shows the general driver of our fuzzing
approach. It starts with parsing the input (cf. line 1), i.e.,
reading three different input values: the public value and twosecret values, which are used to execute the program twice, asformulated in Equation 1. Additionally, the parsing can take
178
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. some simple constraints for these input values, as described
below. For each execution we measure the costs (cf. line 2
and 3) and calculate the absolute cost difference (cf. line 4).
This value is used to guide the fuzzer (cf. line 5) to generate
more inputs with the goal of increasing the difference. In our
implementation this notion of cost difference is realized by
setting user-deﬁned cost values.
Procedure 1 Differential Fuzzing Driver
1:pub,sec 1,sec 2←parse(input,constraints )
2:cost 1←measure(P(pub,sec 1))
3:cost 2←measure(P(pub,sec 2))
4:cost diff←|cost 1−cost 2|
5:setUserDeﬁnedCost (cost diff)
Input Constraints :Solving the maximization problem
described in Equation 1 for two totally arbitrary chosen
input tuples might not be expedient because most applications
assume certain properties of the secret values. For example if
a password is stored as a hash, the application would assume
that the hashed values have the same ﬁxed length. Using secret
values with arbitrary lengths for testing this application would
lead to results that are not meaningful. Therefore, in practice
it is useful to set some simple constraints on the inputs. In
our approach we have a constructive solution, i.e. we rely on
the user to encode input constraints in the driver such that
only the inputs that satisfy these constraints are passed to the
programs. For example the driver can limit the size of a string
during parsing by simply not reading more characters than a
given threshold, or the driver can ensure a certain character set
for a string that should represent a hash value by mapping all
non-member characters to member characters during parsing.
Analysis Outcome :The result of the analysis is a set of
concrete public and secret inputs that expose the maximum
cost difference between two secret-dependent paths found by
the fuzzer. If the difference is large, it indicates a side-channel
vulnerability and the developer can use the provided inputs to
precisely pinpoint the problem and ﬁx the vulnerability, e.g.,
by making the cost similar on both program paths. If on the
other hand the difference is small (or zero) it could mean that
the program has no vulnerabilities or that the fuzzer was not
run long enough. The developer can then run the fuzzer longer
to get enough conﬁdence that the software indeed has no
vulnerability. The fuzzer also records the coverage achieved on
the analyzed code and this information can also be examined
to increase the conﬁdence in the reported results.
Manual Effort :DIFFUZZ requires manual effort in writing
the drivers and the input constraints. In the driver, the user
needs to specify: how to parse the input ﬁle to retrieve valid
input values, the entry point to start the target application,
and how to measure the execution cost. As many applications
come with test cases, we use them to determine entry points.
We believe that the manual effort is not high as all the drivers
are very similar (and follow Procedure 1); the constraints are
minimal and application speciﬁc (e.g., passwords have certain
lengths). One can also envision using fuzzing to discover theseconstraints automatically, following the work on grammar
inference from [21]. However this is left for future work.
D. Fuzzing Programs
For fuzzing we use off-the-shelf tools such as AFL [42].
AFL is a state-of-the-art, security-oriented grey-box fuzzer
that employs compile-time instrumentation and genetic algo-
rithms to automatically generate test inputs that improve the
branch coverage of the analyzed code.
Fuzz testing tools have been very successful at ﬁnding bugs
and vulnerabilities in a variety of applications, ranging from
image processors and web browsers to system libraries and
various language interpreters. For example, AFL was instru-
mental in ﬁnding several of the Stagefright vulnerabilities in
Android, the Shellshock related vulnerabilities, vulnerabilities
in BIND, as well as numerous bugs in (security-critical)
applications and libraries such as O PENSSL, O PENSSH,
GNUTLS, G NUPG, PHP, A PACHE , IJG JPEG ,LIBJPEG -
TURBO and many more (cf. bug list on AFL’s website [42]).
Motivated by the success of fuzzing, we aim to use this
technology for ﬁnding side-channel vulnerabilities. Typically,
fuzzers use heuristic algorithms to mutate user-provided inputs
to increase coverage, with the goal of ﬁnding crashes and
other vulnerabilities. In contrast, D IFFUZZ uses fuzzing to
perform a relational analysis, where the goal is to maximize
the difference in resource usage for two copies of the program.
To realize this goal, an off-the-shelf fuzzer can be extended
as follows: (1) the instrumentation is modiﬁed to collect
additional information related to a resource consumption,
such as timing, memory usage and response size; and (2)
the difference between the costs observed for two program
copies is recorded and sent back to the fuzzer, whose logic
is modiﬁed to consider as important the inputs that increase
this difference. In particular, the fuzzer maintains the so far
observed difference high-score and prioritizes inputs leading to
new high-score in addition to improved coverage, attempting
to maximize the difference and thus ﬁnd side-channels.
The timing cost is approximated by counting every (byte-
code) instruction executed by the program. A similar cost is
used in previous static analysis tools (T HEMIS and B LAZER )
allowing us to compare with them. Note that we can also mea-
sure the wall-clock time directly, by recording the execution
time for each execution. The measurements can be performed
on a clean, un-instrumented version of the program, using
the inputs provided by fuzzing. However, we found that these
measurements could sometimes be imprecise due to garbage
collection and other processes running on the same machine.
One can perform multiple runs for the same input, and take
the average of these measurements, but we did not explore
this direction further in this work, as we found that counting
the instructions provides a good approximation.
Memory usage is measured by intermittent polling using a
timer, which results in measuring the maximum consumption
at any point during program execution. D IFFUZZ also mea-
sures response size (in bytes) for the values that are returned
and the messages that are sent by the application.
179
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. We note that AFL supports programs written in C, C++, or
Objective C. To make it applicable to J AVA programs, we use
KELINCI [24], which provides an AFL-style instrumentation
for J AVA programs, executes the instrumented programs and
sends results back to a simple C program that interfaces with
AFL. AFL does not know about the J AVA program in the
background because it only communicates with the mentioned
interface program, and hence, AFL can use its heuristics to
generate inputs that are then executed on the Java programs.
E. Example
We illustrate the side-channel analysis on a password check-
ing example. Listing 1 and Listing 2 show the code for
the comparison of a user password with a server-side stored
password in an unsafe and safe way respectively.
0boolean pwcheck_unsafe (byte[]pub,byte[]sec){
1 if(pub.length !=sec.length ){
2 return false ;
3}
4 for(inti=0 ;i<pub.length ;i++){
5 if(pub[i]! =sec[i]){
6 return false ;
7 }
8}
9 return true ;
10}
Listing 1: Unsafe Password Checking
0boolean pwcheck_safe (byte[]pub,byte[]sec){
1 boolean unused ;
2 boolean matches =true;
3 for(inti=0 ;i<pub.length ;i++){
4 if(i<sec.length ){
5 if(pub[i]! =sec[i]){
6 matches =false ;
7 }else{
8 unused =true;
9 }
10 }else{
11 unused =false ;
12 unused =true;
13 }
14}
15 return matches ;
16}
Listing 2: Safe Password Checking
The unsafe variant contains a timing side channel because its
early-return in lines 2 and 6. These two locations were ﬁxed in
the safe variant by iterating over the complete password, even
when the two passwords already do not match at an earlier
point. To apply D IFFUZZ, we built a driver for the unsafe
variant based on Procedure 1 with length limit of 16 bytes for
each fuzzed value (see Listing 3). The way we parse the input
in this example ensures that all three values have same length.
The ﬁeld Mem.instrCost holds the current cost measured
by the instrumentation, i.e., in our case the number of executed
bytecode instructions. The method Mem.clear() resets the
current cost, which is necessary to measure the cost for each
execution separately. Kelinci.addCost(diff) tells thefuzzer to use the cost difference diff as cost metric during
the input assessment. We did run the fuzzer for 30 minutes
and obtained a maximum cost difference of 47 bytecode
instructions, with the inputs shown in Listing 4.
The value of sec 2is matching the complete value of pub,
whereas the value of sec 1is not matching at all. Note that the
fuzzer generated these values on its own, without any further
inﬂuence by the driver. The initial input ﬁle (the seed ﬁle),
generated randomly, leads to the cost difference 0. In fact the
difference of 47 instructions is the worst-case scenario and
was already retrieved by the fuzzer within 69 seconds. A value
greater than 0 was retrieved by the fuzzer within 5 seconds.
0voiddriver (String []args ){
1 intmaxLen = 16;
2 intmaxData =3*maxLen ;
3 byte[]allBytes =readDataUpToMax (args [0],
maxData );
4 intlen =allBytes .length /3 ;
5 byte[]pub =Arrays .copyOfRange (allBytes ,0 ,len);
6 byte[]sec_1 =Arrays .copyOfRange (allBytes ,len,
2*len);
7 byte[]sec_2 =Arrays .copyOfRange (allBytes ,2*len
,3*len);
8
9Mem.clear ();
10 boolean answer1 =pwcheck_unsafe (pub,sec_1 );
11 longcost1 =Mem.instrCost ;
12
13Mem.clear ();
14 boolean answer2 =pwcheck_unsafe (pub,sec_2 );
15 longcost2 =Mem.instrCost ;
16
17 longdiff =Math .abs(cost1 −cost2 );
18Kelinci .addCost (diff );
19}
Listing 3: Password Checking Driver
pub=[−48,−4,−48, 7, 17, 0, −24,−48,−48, 16, −48,−3,
108, 72, 32, 0]
sec_1 =[72, 77, −16,−66,−48,−48,−48,−48,−28, 0, 100, 0,
0, 0, 0, −48]
sec_2 =[−48,−4,−48, 7, 17, 0, −24,−48,−48, 16, −48,−3,
108, 72, 32, 0]
Listing 4: Input for Max Cost Difference after 30 min.
Afterwards, we used a similar fuzzing driver on the safevariant
for 30 minutes as well, and we ran D IFFUZZ again. In this case
we have observed no cost differences (i.e., δ=0). To further
check that the program was indeed repaired, we executed the
safe variant with the inputs obtained with the previous fuzzer
run on the unsafe variant, obtaining again zero difference.
III. E V ALUATION
To assess the effectiveness of D IFFUZZ in identifying
side-channel vulnerabilities, we evaluated it on two sets of
benchmarks. The ﬁrst set, taken from [8] and [14], contains
programs with known time and space side-channels, as well
as repaired versions. The second set contains new complex
examples from the DARPA Space/Time Analysis for Cyber-
security (STAC) program [20] as well as popular real-world
applications, on which we identiﬁed new vulnerabilities.
180
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. For the ﬁrst set of benchmarks, we compare D IFFUZZ
with B LAZER [8] and T HEMIS [14], two state-of-the-art static
analysis tools for detecting side-channel vulnerabilities in
JAVA programs. B LAZER uses decomposition techniques for
proving bounded non-interference while T HEMIS uses Quan-
titative Cartesian Hoare Logic reasoning to check bounded
non-interference for J AVA programs, where the bound /epsilon1is
set to either 0 or 64 [14]. Since B LAZER and T HEMIS are
not available, we perform the comparison on the same set of
benchmarks that were used to evaluate the respective tools [8],
[14]. We received the code for all the benchmarks from the
THEMIS developers. We note that three examples were missing
(Apache Shiro, Apache Crypto and bc-java); we therefore
could not analyze them. Our tool and the benchmarks are avail-
able at our GitHub repository: https://github.com/isstac/diffuzz
A. Experimental Setup
For each target application, we wrote a driver in J AVA,
following the steps in Procedure 1 (Section II). Note that by
default, the instrumentor ignores all library code and hence, we
speciﬁcally copied methods from libraries into the application
to instrument them as well.
Due to the randomness in fuzzing, we run D IFFUZZ on each
application ﬁve times, and we report the averaged results. All
the experiments were performed on a server with OPEN SUSE
LEAP 42.3 featuring 8 Quad-Core-AMD 8384 2.7 GHz and
64 GB of memory. We used O PENJDK 1.8.0 151 and GCC
4.8.5. Although typically D IFFUZZ is able to identify a
side-channel vulnerability in a few seconds, we run each
experiment for 30 minutes.
As mentioned, D IFFUZZ reads the inputs to a program from
an initial seed ﬁle. In general, we used a randomly generated
ﬁle. Some applications get speciﬁc types of inputs, such as
IBASys that needs an image ﬁle. In that case, we extracted
the byte encoding from a random image and used it as the
initial input ﬁle. For ﬁnding timing side-channels, we use a
simple cost model that counts the bytecode instructions during
the program run. Both B LAZER and T HEMIS similarly count
the instructions for their timing side-channel analysis.
B. Evaluating DIFFUZZ on the BLAZER Examples
We employed D IFFUZZ on the examples from [8] for eval-
uating B LAZER , which were also analyzed with T HEMIS [14].
They consist of programs with timing side-channels and re-
paired safe versions. They are small applications with up to a
hundred lines of code.
Note that the safe version of unixlogin was not executable
due to a NullPointerException during hash comparison
(cf. the Figure 3 in the B LAZER paper [8], second example
line 7). Although T HEMIS did not include this subject, we
ﬁxed the issue by adding a dummy comparison of the same
MD5 hash of the provided password.
Results: We summarize the results in Table I. The Average
column shows the (average) cost difference δbetween two
executions of an application. The Time column includes the
time that each of the tools (D IFFUZZ,B LAZER ,THEMIS )needed to identify a vulnerability. The numbers for B LAZER
and T HEMIS are extracted from [14]; for the T HEMIS exper-
iments, the bound /epsilon1was set to zero. For D IFFUZZ, the time
shows the average earliest time that cost difference is bigger
than zero, δ> 0. The time values for some safe versions are
not provided because in those cases the δis zero.
The results indicate that D IFFUZZ is able to accurately iden-
tify all the side-channel vulnerabilities in the unsafe versions.
The average cost difference for all unsafe programs is more
than zero and sometimes it is very large.
DIFFUZZ behaves as expected on the majority of the safe
versions, ﬁnding zero difference, but it also found some dis-
crepancies. In two cases ( Array and unixlogin ) the differences
found (1 and 3) may be attributed to slight discrepancies
between the intermediate representations of the different anal-
yses, and can thus be considered negligible. However, in two
other cases D IFFUZZ found large δvalues indicating that the
repaired versions are in fact notsafe. We discuss them below.
LoopAndbranch: Both B LAZER and T HEMIS deemed the
repaired version of LoopAndbranch function as safe.
DIFFUZZ instead identiﬁed a huge difference δ=
1,389,926,404in computed costs, which occurs due to integer
overﬂow. In particular, the value assigned by the fuzzer to one
of the secrets is the maximum integer value in Java, which gets
added to 10, becoming a negative value. As a result, none of
the loops in the code get executed and the cost is very small
compared to the cost of the other execution, with the second
secret value. This vulnerability, which was conﬁrmed by the
developers of B LAZER , highlights the importance of handling
overﬂow in analysis tools.
gpt14: This function computes the modular exponentiation,
abmod (p), used for the encryption and decryption of mes-
sages. Here, aandpare public values and bis the secret.
BLAZER reported this example as safe for a non-zero bound
whereas T HEMIS reported it as safe for a zero bound (non-
interference). D IFFUZZ found that even though the repair has
substantially reduced the cost difference, still δ= 517 (which
is consistent with the B LAZER results). This vulnerability is
due to an extra ifstatement that depends on the secret and it
was conﬁrmed by the Themis’ developers.
C. Evaluating DIFFUZZ on the THEMIS Examples
We further evaluated D IFFUZZ on the larger J AVA programs
with time and space side-channels from [14]. These programs
have up to 20K LOC (although only some smaller parts were
analyzed with all three tools), and are extracted from complex-
real world applications, such as Tomcat, Spring-Security and
Eclipse Jetty HTTP web server.
All benchmarks except DynaTable ,Advanced table ,Open-
MRS and OACC come with a repaired version. Some of
the benchmarks ( Tomcat ,pac4j ) include interactions with
a database. In our experiments, we created the required
databases and run them instead of simulating them with other
data structures. We used the H2 database engine [3] to create
an SQL database accessible via the JDBC API.
181
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. TABLE I: The results of applying D IFFUZZ to the B LAZER examples. Discrepancies are highlighted in red and italics.
Benchmark Version Average δ Std. Error Maximum Time (s)
DIFFUZZ,δ>0 BLAZER THEMIS
MicroBench
Array Safe 1.00 0.00 1 7.40 (+/- 1.21) 1.60 0.28
Array Unsafe 192.00 2.68 195 7.40 (+/- 0.93) 0.16 0.23
LoopAndbranch Safe 1,468,212,312.40 719,375,479.77 4,278,268,702 18.60 (+/- 6.40) 0.23 0.33
LoopAndbranch Unsafe 4,283,404,852.40 4,450,278.15 4,294,838,782 10.60 (+/- 2.62) 0.65 0.16
Sanity Safe 0.00 0.00 0 - 0.63 0.41
Sanity Unsafe 4,213,237,198.00 60,857,888.00 4,290,510,883 163 (+/- 40.63) 0.30 0.17
Straightline Safe 0.00 0.00 0.00 - 0.21 0.49
Straightline Unsafe 8.00 0.00 8 14.60 (+/- 6.53) 22.20 5.30
unixlogin Safe 3.00 0.00 3 510 (+/- 91.18) 0.86 -
unixlogin Unsafe 2,880,000,008.00 286,216,701.00 3,200,000,008 464.20 (+/- 64.61) 0.77 -
STAC
modPow1 Safe 0.00 0.00 0 - 1.47 0.61
modPow1 Unsafe 2,576.00 168.21 3,068 4.80 (+/- 1.11) 218.54 14.16
modPow2 Safe 0.00 0.00 9 - 1.62 0.75
modPow2 Unsafe 1,471.00 891.00 5,206 23 (+/- 3.48) 7813.68 141.36
passwordEq Safe 0.00 0.00 0.00 - 2.70 1.10
passwordEq Unsafe 86.40 20.31 127 8.60 (+/-2.11) 1.30 0.39
Literature
k96 Safe 0.00 0.00 0 - 0.70 0.61
k96 Unsafe 338.00 185.13 3,087,339 3.40 (+/- 0.98) 1.29 0.54
gpt14 Safe 163.20 79.84 517 4.20 (+/- 0.80) 1.43 0.46
gpt14 Unsafe 6,673,760.00 2,211,811.00 12,965,890 4.40 (+/- 1.03) 219.30 1.25
login Safe 0.00 0.00 0 - 1.77 0.54
login Unsafe 62.00 0.00 62 10 (+/- 2.92) 1.79 0.70
Results: Table II displays our results; the results for
THEMIS are taken from [14]. Once again, D IFFUZZ suc-
cessfully identiﬁed vulnerabilities in the unsafe versions of
these examples and for the majority of the repaired versions,
DIFFUZZ found only small differences, as expected. In one
case (jetty), D IFFUZZ identiﬁed a new vulnerability in the
repaired version. Some other examples (Tomcat, pac4j, OACC)
also show some discrepancies. We provide more details below.
Jetty: THEMIS was used to analyze a known vulnerability
in the Eclipse Jetty HTTP web server and a repaired version
of it. Furthermore, T HEMIS found a similar vulnerability in
another part of the Jetty application.
The original unsafe version of the code performs
some checking over sensitive credential information by
calling the built-in equality method provided by the
java.lang.String library . Since this method returns
false as soon as it ﬁnds a mismatch between two characters,
it introduces a timing side-channel vulnerability. The method
has been repaired with the one in Listing 5. This repair is very
common and has been used in many implementations to avoid
time channels.
0boolean stringEquals (String s1 ,String s2 ){
1 boolean result =true;
2 intl1=s1.length ();
3 intl2=s2.length ();
4 if(l1!=l2)result =false ;
5 intn=(l1<l2)?l1:l2;
6 for(inti=0 ;i<n;i++)
7 result &=s1.charAt (i)= =s2.charAt (i);
8 return result ;
9}
Listing 5: Jetty safe string comparison analyzed in [14]Interestingly, for this example, D IFFUZZ found that it is still
vulnerable with δ=5,454. The reason for this vulnerability
is subtle. It turns out that the operation at line 7 is not
constant time: it takes either 2 or 3 bytecodes, depending on
the outcome of the equality check between the two characters
(the operation is optimized for the case that the outcome is
false). Although there is a difference of only one bytecode
instruction, having this operation in the loop ampliﬁes its
impact. This could not be discovered by T HEMIS because in
its intermediate representation (Jimple), the operation at line
7 takes constant time. We further note that we imposed no
constraints on the input and this is in line with the T HEMIS
experiments. The observed difference is proportional with the
size of the input, and for small input sizes, both versions could
be considered safe. However, for large input sizes, both safe
and unsafe versions are in fact not safe.
Tomcat, pac4j, OACC: The vulnerability of pac4j is due
to the encoding of a password, which is performed during user
authentication, and is assumed to be expensive. Nevertheless,
the code provided by the T HEMIS developers did not include
an expensive implementation of the password encoding (they
instead used a model which was not provided to us). Since we
did not use any models we could not ﬁnd a noteworthy cost
difference between the provided safe and unsafe versions (cf.
Table II subject pac4j Safe and pac4j Unsafe ). We also used
another more expensive password encoding method, denoted
with a star (*) in Table II, which iterates over the password,
to get a stronger indication that there is an actual timing side-
channel vulnerability (cf. Table II subject pac4j Unsafe* ).
We also found vulnerabilities in the unsafe versions of
Tomcat and OACC, however the generated δs were small.
Upon consulting with the T HEMIS developers, it appears that,
182
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. TABLE II: Comparison against T HEMIS
Benchmark Version DIFFUZZ THEMIS
Averageδ Std. Error Maximum Time (s) δ>0/epsilon1=6 4/epsilon1=0 Time (s)
Spring-Security Safe 1.00 0.00 1 9.00 (+/- 1.26)  1.70
Spring-Security Unsafe 149.00 0.00 149 8.80 (+/- 1.16)  1.09
JDK7-MsgDigest Safe 1.00 0.00 1 15.80 (+/- 3.93)  1.27
JDK6-MsgDigest Unsafe 10,215.00 6,120.00 34,479 7.40 (+/- 1.29)  1.33
Picketbox Safe 1.00 0.00 1 29.20 (+/-5.00)  1.79
Picketbox Unsafe 4,954.00 1,295 8,794 16.80 (+/- 2.58)  1.55
Tomcat Safe 12.20 1.61 14 13.80 (+/- 1.29)  9.93
Tomcat Unsafe 33.20 3.40 37 128.60 (+/- 87.20)  8.64
Jetty Safe 5454.00 1330.88 8898 9.40 (+/- 1.86)  2.50
Jetty Unsafe 10786.60 2807.51 16020 7.00 (+/- 1.05)  2.07
orientdb Safe 6.00 0.00 6 3.20 (+/- 0.97)  37.99
orientdb Unsafe 6,604.00 3,681 19,300 3.00 (+/- 0.84)  38.09
pac4j Safe 10.00 0.00 10 5.00 (+/- 1.22)  3.97
pac4j Unsafe 11.00 0.00 11 8.00 (+/- 2.76)  1.85
pac4j Unsafe* 39.00 0.00 39 10.80 (+/- 5.80) -- -
boot-auth Safe 5.00 0.00 5 5.20 (+/- 0.20)  9.12
boot-auth Unsafe 101.00 0.00 101 5.20 (+/- 0.20)  8.31
tourPlanner Safe 0.00 0.00 0 -  22.22
tourPlanner Unsafe 522.40 18.60 576 19.20 (+/- 0.80)  22.01
DynaTable Unsafe 95.80 0.44 97 3.60 (+/- 1.21)  1.165
Advanced table Unsafe 92.40 1.54 97 11.20 (+/- 1.62)  2.01
OpenMRS Unsafe 206.00 0.00 206 11.60 (+/- 3.22)  9.71
OACC Unsafe 47.00 0.00 47 7.00 (+/- 1.30)  1.83
similar to pac4j , some manually built models were used, which
we could not obtain.
D. Employing DIFFUZZ on New Examples
We also applied D IFFUZZ on new J AVA examples, includ-
ing two complex applications taken from the Cybersecurity
(STAC) program [20]: IBASys and CRIME, and two real-
world open-source projects: Apache FtpServer [1] and Au-
thMeReloaded [2].
Results: Table III shows the results. For the reported
zero-day vulnerabilities, all are conﬁrmed and, collaborating
with the developers and the community, solutions have been
proposed and at this point most of them have been ﬁxed. We
explain our ﬁndings in more details.
CRIME: CRIME is an instance of the CRIME attack
(“Compression Ratio Info-leak Made Easy”) [19], which is
as follows. Suppose a user is tricked into visiting a website
attack.com , which has a malicious script making several
requests to bank.com . Each request is a concatenation of
public input generated by the script and the login (secret)
cookie of the user. To avoid latency, protocols such as HTTPS
and SPDY compress the requests before they are sent. The
communication channel is encrypted, but the adversary can
observe the size of the compressed package. When the public
input is close to the secret, the compression is more efﬁcient
due to the redundancies, and the reduction in the size of the
compressed package is more signiﬁcant. Hence, the adversary
can infer information about the secret. We analyzed the string
compression procedure (160 LOC). It uses various input-
output streams and involves complex string manipulations that
are difﬁcult to analyze with existing static analysis tools.
DIFFUZZ correctly identiﬁes a space side-channel that re-
veals the secret through the size of the compressed output.IBASys: IBASys is a network-based authentication server
that uses images in place of textual passwords. To log in,
a user supplies a username and a passcode image ( e.g., a
JPEG image). Following a successful authentication, IBASys
replies with a response containing an encrypted session token.
This session token could then be used to interact with other
services that rely on IBASys for their authentication needs.
We analyzed the authentication procedure (707 LOC), which
performs complex image manipulations.
DIFFUZZ managed to generate input ﬁles that are bytecode
representations of valid images and it was also able to uncover
a timing-channel that is due to early termination in a loop that
matches the two (public and private) provided images. The
maximum cost difference found by D IFFUZZ isδ= 262 ,
where the length of image_public is 18,995 bytes.
Apache FtpServer: We also applied D IFFUZZ on the open-
source project Apache FtpServer [1], which has a very large
code base; we focused our analysis on speciﬁc classes as
reported below.
We identiﬁed a previously unknown timing side-channel
in the class ClearTextPasswordEncryptor (115
LOC), in which the method boolean matches(String,
String) uses the String.equals method for the com-
parison of the user provided password and the server-side
stored password. This comparison returns false as soon as
a character does not match, and hence, it could be used by
a potential attacker to obtain knowledge about the hidden
secret password. We have found this kind of vulnerability also
in the classes Md5PasswordEncryptor (185 LOC) and
SaltedPasswordEncryptor (211 LOC). We reported
the issues to the developers who conﬁrmed and ﬁxed all of
them. We also analyzed safe versions (provided by the devel-
opers) which ﬁxed the issue. For all of them but one, the safe
variant of string comparison did eliminate the vulnerability.
183
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. TABLE III: The results of applying D IFFUZZ on new examples
Benchmark Version Average δ Std. Error Maximum Time (s) δ>0
STAC
CRIME unsafe 295.40 117.05 782 7.40 (+/- 1.12)
ibasys (imageMacher) unsafe 191 20.88 262 6.20 (+/- 0.66)
Zero-day Vulnerabilities
Apache ftpserver Clear safe 1.00 0.00 1 7.20 (+/- 1.24)
Apache ftpserver Clear unsafe 47.00 0.00 47 6.80 (+/- 1.07)
Apache ftpserver MD5 safe 1.00 0.00 1 4.20 (+/- 1.93)
Apache ftpserver MD5 unsafe 151.00 0.00 151 2.80 (+/- 1.11)
Apache ftpserver SaltedPW (safe) 176.40 6.25 198 2.20 (+/- 0.73)
Apache ftpserver SaltedPW unsafe 178.80 5.13 193 3.60 (+/- 1.08)
Apache ftpserver SaltedPW* unsafe 163.40 3.80 178 5.40 (+/- 0.98)
Apache ftpserver StringUtils safe 0.00 0.00 0 -
Apache ftpserver StringUtils unsafe 53.00 0.00 53 3.00 (+/- 1.05)
AuthMeReloaded safe 1.00 0.00 1 7.60 (+/- 0.75)
AuthMeReloaded unsafe 383.00 0.00 383 9.20 (+/- 1.96)
For the class SaltedPasswordEncryptor DIFFUZZ still
detected a vulnerability, so we continued our investigation and
discovered that in addition to the matching method the used
encryption method leaks information about the generated salt.
We have thus analyzed method String encrypt(String
pw, String salt) , marked with a star (*) in Table III.
We are discussing with the developers with regard to this new
vulnerability.
0public ﬁnal static String pad_unsafe (String src ,char
padChar ,boolean rightPad ,inttotalLength ){
1 intsrcLength =src.length ();
2 if(srcLength >=totalLength )return src;
3 intpadLength =totalLength −srcLength ;
4 StringBuilder sb =newStringBuilder (
padLength );
5 for(inti=0 ;i<padLength ;+ +i){
6 sb.append (padChar );
7 }
8 if(rightPad ){
9 return src +sb.toString ();
10 }else{
11 return sb.toString () +src;
12 }}
Listing 6: Apache FtpServer StringUtils.pad unsafe version
Note that the salt in SaltedPasswordEncryptor gets
randomly generated during encryption. Nevertheless for the
matches method we fuzz the complete stored password
including the salt. Furthermore, for the more focused analysis
of the encrypt method we test if the algorithm leaks some
information about the used salt via a side-channel.
We have also found a timing side-channel in the
method String StringUtils.pad(String, char,
boolean, int) (Listing 6), which was also conﬁrmed by
the developers. This method leaks the padding in a timing
side-channel, from which a potential attacker could obtain the
length of the src String. The padding is used to extend a
username to ﬁxed length, hence, a potential attacker could
obtain the length of a given username, which might be used
for further attacks. The vulnerability is caused by: (1) the early
return in line 2, and (2) the for loop in line 5-7, which only
runs for padLength iterations. The safe version, provided in
our repository solves both issues.AuthMeReloaded: We have also found an unknown timing
side-channel in the open-source project AuthMeReloaded
[2], which is an authentication plugin for Minecraft servers
available on GitHub. It provides features like username spoof
protection and anti-bot measures. Speciﬁcally, we found a
vulnerability in the class RoyalAuth (209 LOC), in the
inherited method boolean comparePassword(String
password, HashedPassword hashedPassword,
String name) . Similar vulnerabilities have been found
in the classes Sha256 andPbkdf2 . The developers ﬁxed
these vulnerabilities within a few days by using a constant
time comparison algorithm.
E. Discussion
One advantage of D IFFUZZ compared to the other tools is
that it not only shows whether an application is vulnerable, but
also shows the magnitude of the vulnerability. This observation
can be leveraged to estimate the severity of a vulnerability and
it also makes it possible for the developers to compare different
repaired versions of an application.
Analysis Time: Tables I, II and III also show the time
that each of the tools needed for analysis. Both B LAZER and
THEMIS were run on different hardware, making the timing
reported incomparable. In general, static analysis is shown
to be much faster than dynamic analysis; our results show
that nonetheless D IFFUZZ is able to identify vulnerabilities
in a reasonable time. In principle D IFFUZZ can run for a
long time and it can still generate new inputs that increase
the cost difference. However, we observed in preliminary
test executions that our experiments ﬁnd a plateau within 30
minutes, which is the time bound we applied.
For our experiments, we observed three different kinds of
behavior: (a) D IFFUZZ identiﬁes a small cost difference very
fast, and it increases it over time; (b) D IFFUZZ identiﬁes a
big cost difference very fast and remains in a plateau after a
few seconds; and (c) D IFFUZZ needs a long time to ﬁnd a
cost difference at all. Cases (a) and (b) were almost equally
distributed on our experiments and covered almost all of
them. Only for three experiments we observed case (c). As an
illustration the plots in Figure 2 show the average maximum
cost development within the ﬁrst 5 minutes for the three cases.
184
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. 0 100 200 30001020
time (seconds)cost (# instructions)orientdb
0 100 200 300050100150200
time (seconds)cost (# instructions)IBASys
0 100 200 30001234
time (seconds)cost (# instructions)LoopAndbranch
Fig. 2: Averaged cost over time for orientdb ,IBASys , and LoopAndbranch (unsafe versions).
Orientdb (case (a)) checks passwords by comparing be-
tween user-given and stored passwords. The longer the match-
ing preﬁx is, the higher will be the processing cost. Exact
value matching is in general very difﬁcult for fuzzing because
it is hard to randomly generate the exact (unlikely) values that
match the stored password. While D IFFUZZ ﬁnds quickly a
small preﬁx, which reveals a cost difference greater than zero,
it needs some time to reach a higher value.
For IBASys (case (b)), D IFFUZZ ﬁnds the maximum average
value already after a few seconds, and thus leads very fast to
the shown plateau value. The reason could be that the initial
seed ﬁle guides the fuzzer already into a costly path or that
the costly paths have a high probability, and hence, the fuzzer
can easily catch them.
For LoopAndbranch (case (c)) D IFFUZZ reaches some parts
of the code only with speciﬁc values for the secret and this is
difﬁcult to achieve with fuzzing. We believe that the limitations
illustrated with cases (a) and (c) can be mitigated by adding
further guidance to the fuzzer and by, e.g., combining fuzzing
and symbolic execution.
Vulnerability vs Exploit: DIFFUZZ can identify side-
channel vulnerabilities but can not assess whether they are
exploitable by a real attack. The synthesis of a real attack,
which would be necessary to assess the severity of the found
vulnerability, is out of scope for this work. Nevertheless, we
believe that our contribution is a ﬁrst step in this direction.
IV . R ELATED WORK
DIFFUZZ is related to a large body of work on checking
non-interference via self-composition [10]. For instance, re-
lated work [7] presents a self-composition approach to timing-
channel analysis, which however does not check bounded non-
interference. We already compared with the most recent related
tools, B LAZER [8] and T HEMIS [14].
CoCoChannel [12] uses static analysis for ﬁnding side-
channel vulnerabilities and presents a comparison with
THEMIS and B LAZER on the same benchmarks, showing bet-
ter scalability. While CoCoChannel also found discrepancies
in the T HEMIS and B LAZER benchmarks, the approach still
fails to report vulnerabilities for the repaired versions in, e.g.,
loopAndBranch and jetty.
Stacco [40] also uses a differential analysis for ﬁnding
timing side-channels, using random inputs. However, Staccodoes not perform directed fuzzing, it does not check bounded
non-interference, and it does not address Java.
There is a large amount of related work on side-channel
analysis, for example [6], [13], [15], [17], [25], [26], [33].
The most successful approaches use abstract interpretation (for
cache side-channels analysis) [18], [27], [32] and are thus quite
different than D IFFUZZ. Other techniques [9], [35], [37] use
symbolic execution and constraint solving with model count-
ing for quantifying side-channel leakage and for synthesis of
attacks. They address J AVA programs, but may have scalability
issues, due to the expensive constraint manipulation.
Other related techniques aim to quantify leakage using
Monte Carlo sampling [16], [23]. In contrast to D IFFUZZ,
these techniques provide quantitative results, but they may be
imprecise in practice.
Fuzzing has received renewed interest in the software
engineering community, with many recent approaches re-
ported [29], [30], [34], [39]. Most related are techniques that
use fuzzing alone [29], [39] or a combination of fuzzing and
symbolic execution [34] to analyze the algorithmic complexity
of programs, by monitoring a resource consumption. In par-
ticular, Badger [34] also uses Kelinci and AFL for the fuzzing
part. None of these works address side-channel analysis.
V. C ONCLUSIONS AND FUTURE WORK
We presented D IFFUZZ, the ﬁrst differential fuzzing ap-
proach for automatically ﬁnding side-channel vulnerabilities.
We have shown that D IFFUZZ can keep up with existing
approaches such as B LAZER and T HEMIS . Furthermore, D IF-
FUZZ found new vulnerabilities in popular open-source J AVA
applications such as Apache FtpServer. In the future, we
plan to explore automated repair methods to eliminate the
vulnerabilities discovered with D IFFUZZ. Additionally, we
plan to augment our work with statistical guarantees similar
to the STADS framework [11].
ACKNOWLEDGMENT
This material is based on research sponsored by DARPA
under agreement number FA8750-15-2-0087. The U.S. Gov-
ernment is authorized to reproduce and distribute reprints
for Governmental purposes notwithstanding any copyright
notation thereon. This work is also supported by the German
Research Foundation (GR 3634/4-1 EMPRESS).
185
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] Apache FtpServer. https://mina.apache.org/ftpserver-project/. Accessed:
2018-08-21.
[2] Authentication plugin for the Bukkit/Spigot API. https://github.com/
AuthMe/AuthMeReloaded. Accessed: 2018-08-21.
[3] H2 database engine. http://www.h2database.com/html/main.html. Ac-
cessed: 2018-05-06.
[4] The Meltdown Attack. https://meltdownattack.com/. Accessed: 2018-
08-21.
[5] Xbox 360 Timing Attack. http://beta.ivc.no/wiki/index.php/Xbox 360
Timing Attack. Accessed: 2018-08-21.
[6] Dakshi Agrawal, Josyula R. Rao, and Pankaj Rohatgi. Multi-channel
Attacks. In Colin D. Walter, C ¸ etin Kaya Koc ¸, and Christof Paar,
editors, Cryptographic Hardware and Embedded Systems - CHES 2003,
5thInternational Workshop, Cologne, Germany, September 8-10, 2003,
Proceedings , volume 2779 of Lecture Notes in Computer Science , pages
2–16. Springer, 2003.
[7] B. Almeida, M. Barbosa, J. S. Pinto, and B. Vieira. Formal veriﬁcation
of side-channel countermeasures using self-composition. In Science of
Computer Programminga78(7) , 2013.
[8] Timos Antonopoulos, Paul Gazzillo, Michael Hicks, Eric Koskinen,
Tachio Terauchi, and Shiyi Wei. Decomposition instead of self-
composition for proving the absence of timing channels. In Proceedings
of the 38th ACM SIGPLAN Conference on Programming Language
Design and Implementation, PLDI 2017, Barcelona, Spain, June 18-23,
2017 , pages 362–375, 2017.
[9] Lucas Bang, Abdulbaki Aydin, Quoc-Sang Phan, Corina S. P ˘as˘areanu,
and Tevﬁk Bultan. String Analysis for Side Channels with Segmented
Oracles. In Proc. of the 2016 24thACM SIGSOFT International
Symposium on F oundations of Software Engineering , FSE 2016, pages
193–204, New York, NY , USA, November 2016. ACM.
[10] Gilles Barthe, Pedro R. D’Argenio, and Tamara Rezk. Secure infor-
mation ﬂow by self-composition. In Proceedings of the 17th IEEE
Workshop on Computer Security F oundations , CSFW ’04, pages 100–,
Washington, DC, USA, 2004. IEEE Computer Society.
[11] Marcel B ¨ohme. STADS: Software testing as species discovery. ACM
Transactions on Software Engineering and Methodology , 27(2):7:1–
7:52, June 2018.
[12] Tegan Brennan, Seemanta Saha, Tevﬁk Bultan, and Corina S. P ˘as˘areanu.
Symbolic path cost analysis for side-channel detection. In Proceedings
of the 27th ACM SIGSOFT International Symposium on Software Testing
and Analysis , ISSTA 2018, pages 27–37, New York, NY , USA, 2018.
ACM.
[13] David Brumley and Dan Boneh. Remote Timing Attacks Are Practical.
InProc. of the 12thConf. on USENIX Security Symposium - V olume 12 ,
SSYM’03, Berkeley, CA, USA, 2003. USENIX Association.
[14] Jia Chen, Yu Feng, and Isil Dillig. Precise detection of side-channel
vulnerabilities using quantitative cartesian hoare logic. In Proceedings of
the 2017 ACM SIGSAC Conference on Computer and Communications
Security, CCS 2017, Dallas, TX, USA, October 30 - November 03, 2017 ,
pages 875–890, 2017.
[15] Shuo Chen, Rui Wang, XiaoFeng Wang, and Kehuan Zhang. Side-
Channel Leaks in Web Applications: A Reality Today, a Challenge
Tomorrow. In Proc. of the 2010 IEEE Symposium on Security and
Privacy , SP ’10, pages 191–206, Washington, DC, USA, 2010. IEEE
Computer Society.
[16] Tom Chothia, Yusuke Kawamoto, and Chris Novakovic. LeakWatch:
Estimating Information Leakage from Java Programs. In 19th European
Symposium on Research in Computer Security - V olume 8713 , ESORICS
2014, pages 219–236, New York, NY , USA, 2014. Springer-Verlag New
York, Inc.
[17] Quoc Huy Do, Richard Bubel, and Reiner H ¨ahnle. Exploit Generation
for Information Flow Leaks in Object-Oriented Programs. In ICT
Systems Security and Privacy Protection: 30thIFIP TC 11 Intl. Conf.,
SEC 2015, Hamburg, Germany , pages 401–415. Springer, 2015.
[18] Goran Doychev, Dominik Feld, Boris K ¨opf, Laurent Mauborgne, and
Jan Reineke. CacheAudit: A Tool for the Static Analysis of Cache Side
Channels. In Proc. of 22ndUSENIX Conf. on Security , SEC’13, pages
431–446, Berkeley, CA, USA, 2013. USENIX Association.
[19] Thai Duong and Juliano Rizzo. The CRIME attack. In Presentation at
ekoparty Security Conf. , 2012.[20] Mr. Dustin Fraze. Space/Time Analysis for Cybersecurity (STAC). https:
//www.darpa.mil/program/space-time-analysis-for-cybersecurity. Ac-
cessed: 2018-08-21.
[21] Matthias H ¨oschele and Andreas Zeller. Mining input grammars from
dynamic taints. In Proceedings of the 31st IEEE/ACM International
Conference on Automated Software Engineering , ASE 2016, pages 720–
725, New York, NY , USA, 2016. ACM.
[22] Ralf Hund, Carsten Willems, and Thorsten Holz. Practical timing side
channel attacks against kernel space aslr. In Security and Privacy (SP),
2013 IEEE Symposium on , pages 191–205. IEEE, 2013.
[23] Yusuke Kawamoto, Fabrizio Biondi, and Axel Legay. Hybrid Statistical
Estimation of Mutual Information for Quantifying Information Flow. In
FM, volume 9995 of Lecture Notes in Computer Science , pages 406–
425, 2016.
[24] Rody Kersten, Kasper Luckow, and Corina S. P ˘as˘areanu. Poster: Aﬂ-
based fuzzing for java with kelinci. In Proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security , CCS
’17, pages 2511–2513, New York, NY , USA, 2017. ACM.
[25] Paul C. Kocher. Timing Attacks on Implementations of Difﬁe-Hellman,
RSA, DSS, and Other Systems. In Proc. of the 16thAnnual International
Cryptology Conf. on Advances in Cryptology , CRYPTO ’96, pages 104–
113, London, UK, UK, 1996. Springer-Verlag.
[26] Boris K ¨opf and David Basin. An Information-theoretic Model for
Adaptive Side-channel Attacks. In Proc. of the 14thACM Conf. on
Computer and Communications Security , CCS ’07, pages 286–296, New
York, NY , USA, 2007. ACM.
[27] Boris K ¨opf, Laurent Mauborgne, and Mart ´ın Ochoa. Automatic quan-
tiﬁcation of cache side-channels. In Proc. of the 24thinternational
Conf. on Computer Aided V eriﬁcation , CA V’12, pages 564–580, Berlin,
Heidelberg, 2012. Springer-Verlag.
[28] Nate Lawson. Timing attack in Google Keyczar library. https://rdist.root.
org/2009/05/28/timing-attack-in-google-keyczar-library/, 2009. Ac-
cessed: 2018-08-21.
[29] Caroline Lemieux, Rohan Padhye, Koushik Sen, and Dawn Song.
Perffuzz: Automatically generating pathological inputs. In Proceedings
of the 27th ACM SIGSOFT International Symposium on Software Testing
and Analysis , ISSTA 2018, pages 254–265, New York, NY , USA, 2018.
ACM.
[30] Caroline Lemieux and Koushik Sen. Fairfuzz: A targeted mutation
strategy for increasing greybox fuzz testing coverage. In Proceedings
of the 2018 33rd ACM/IEEE International Conference on Automated
Software Engineering , ASE 2018, New York, NY , USA, 2018. ACM.
[31] Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B Lee.
Last-level cache side-channel attacks are practical. In Security and
Privacy (SP), 2015 IEEE Symposium on , pages 605–622. IEEE, 2015.
[32] Heiko Mantel, Alexandra Weber, and Boris K ¨opf. A systematic study
of cache side channels across aes implementations. In Eric Bodden,
Mathias Payer, and Elias Athanasopoulos, editors, Engineering Secure
Software and Systems , pages 213–230, Cham, 2017. Springer Interna-
tional Publishing.
[33] P. Mardziel, M. S. Alvim, M. Hicks, and M. R. Clarkson. Quantifying
information ﬂow for dynamic secrets. In 2014 IEEE Symposium on
Security and Privacy (SP) , pages 540–555, May 2014.
[34] Yannic Noller, Rody Kersten, and Corina S. P ˘as˘areanu. Badger: Com-
plexity analysis with fuzzing and symbolic execution. In Proceedings of
the 27th ACM SIGSOFT International Symposium on Software Testing
and Analysis , ISSTA 2018, pages 322–332, New York, NY , USA, 2018.
ACM.
[35] Corina S Pasareanu, Quoc-Sang Phan, and Pasquale Malacaria. Multi-
run side-channel analysis using symbolic execution and max-smt. In
Computer Security F oundations Symposium (CSF), 2016 IEEE 29th ,
pages 387–400. IEEE, 2016.
[36] Theoﬁlos Petsios, Adrian Tang, Salvatore J. Stolfo, Angelos D.
Keromytis, and Suman Jana. NEZHA: efﬁcient domain-independent
differential testing. In 2017 IEEE Symposium on Security and Privacy,
SP 2017, San Jose, CA, USA, May 22-26, 2017 , pages 615–632, 2017.
[37] Quoc-Sang Phan, Lucas Bang, Corina S. Pasareanu, Pasquale Malacaria,
and Tevﬁk Bultan. Synthesis of adaptive side-channel attacks. In 30th
IEEE Computer Security F oundations Symposium, CSF 2017, Santa
Barbara, CA, USA, August 21-25, 2017 , pages 328–342, 2017.
[38] S. Sivakorn, G. Argyros, K. Pei, A. D. Keromytis, and S. Jana. Hvlearn:
Automated black-box analysis of hostname veriﬁcation in ssl/tls imple-
mentations. In 2017 IEEE Symposium on Security and Privacy (SP) ,
pages 521–538, May 2017.
186
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. [39] Jiayi Wei, Jia Chen, Yu Feng, Kostas Ferles, and Isil Dillig. Singularity:
Pattern fuzzing for worst case complexity. In Proceedings of the 26th
ACM Joint European Software Engineering Conference and Symposium
on the F oundations of Software Engineering , ESEC/FSE 2018, New
York, NY , USA, 2018. ACM.
[40] Yuan Xiao, Mengyuan Li, Sanchuan Chen, and Yinqian Zhang. Stacco:
Differentially analyzing side-channel traces for detecting ssl/tls vulner-
abilities in secure enclaves. In Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security , CCS ’17, pages859–874, New York, NY , USA, 2017. ACM.
[41] Xuejun Yang, Yang Chen, Eric Eide, and John Regehr. Finding
and understanding bugs in c compilers. In Proceedings of the 32Nd
ACM SIGPLAN Conference on Programming Language Design and
Implementation , PLDI ’11, pages 283–294, New York, NY , USA, 2011.
ACM.
[42] Michal Zalewski. American fuzzy lop (aﬂ). http://lcamtuf.coredump.cx/
aﬂ/, 2014. Accessed: 2018-05-06.
187
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:59:16 UTC from IEEE Xplore.  Restrictions apply. 