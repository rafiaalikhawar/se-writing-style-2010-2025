1052018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô18, May 27-June 3, 2018, Gothenburg, Sweden S. Zhou et al.
The goal of our work is to identify and label cohesive code
changes, features, among changes in forks to provide a compact
overviewoffeaturesandtheirimplementations.Thisisastepto
establish an overview of development activities in various forks of
a project.
In contrast to GitHub‚Äôs network view (Fig. 1a), we deempha-
size commits, which frequently have unreliable descriptions and
frequently are unreliable indicators of cohesive functionality, asit is common that commits tangle code of multiple features and
even morecommon thata single featureis scatteredacross multi-
ple commits [ 5,38,39,43,48,54]. Instead, we cluster changed code
based on relationships and dependencies within those code frag-
mentsandlabeleachfeaturewith representativekeywords extracted
from commitmessages, code,and comments.Technically,we take
inspirationfromClusterChanges[ 5]tountanglecodechanges
during code review based on a graph of code dependencies andrepurpose the idea for our problem; furthermore we incorporatecommunity-detection techniques [
34] to refine an initial cluster-
ingand information-retrievaltechniques[ 67]for derivingconcise
labels (See Fig. 1b).
WeimplementedouranalysisintheInfoxtool1thatproduces
web pages describing the features in individual forks and across
multipleforksofaC/C++projectasillustratedinFig.1.Inamixed-
methodsevaluation,wedemonstrate(1)thatInfoxiseffectiveat
identifying features among changes in 10 open-source projects
with a median accuracy of 90 percent, (2) that Infox‚Äôs technical
innovations improve clustering accuracy over an existing state-of-the-art technique designed to cluster individual commits [
5],
and (3) that the produced overview provides useful insights for
contributors and maintainers of projects with many forks.
To summarize, we contribute (a) Infox, an approach and cor-
responding tool, which automatically identifies and summarizes
featuresinforksofaproject,usingsourcecodeanalysis,community
detection,andinformation-retrievaltechniques,and(b)evidence
thatInfoximprovesaccuracyoverexistingtechniquesandprovides
meaningful insights to maintainers of forks.
While Infox currently aims at supporting exploration and nav-
igation by summarizing features, it lays a foundation for future
interactivetoolsupportthatcanrefineandpersistfeatures(e.g.,for
a product-line platform [ 4,9,65]) and support developers in merg-
ing selective changes across forks (e.g., generating pull requests).
2 MONITORING FORKS IN PRACTICE
GitHub‚Äôsmainfacilitytonavigateforksisthenetworkview(Fig.1),
whichvisualizesthehistoryofcommitsovertimeacrossallbranches
and forks of a project. This cross-fork visualization provides trans-
parencytodeveloperswhowanttotrackongoingchangesbyothers,
wanttoknowwhoisactiveandwhattheyaretryingtodowiththe
code [19]. For example, one of the developers we have interviewed
said:‚ÄúI check the more updated forks. I think this view is helpful,
because I am not gonna look at all 60 forks. 60 is a lot, probably this
projecthasthousands,thatwillberidiculous.Iwillneverdothat‚Äù [P4].
1Infox is short for IdeNtifying Features in f OrKS.
Source code is publicly available at https://github.com/shuiblue/INFOX.
A lightweight web service is available at: forks-insight.com.Althoughthenetworkviewisagoodstartingpointtounderstand
how the project evolves, it is tedious and time consuming to use if
aprojecthasmanyforks.Inordertoseeolderhistory,usersclick
and drag within the graph, and if users want to see the commit
information, they hover the mouse over each commit dot and read
the commit message. Also, they ‚Äúhave to scroll back a lot to find
theforkpointandthengototheendagainforseeingwhatchanged
sincethenintheparentandinthefork‚Äù [2].Ifdeveloperswantto
investigatethecodechangesofcertainforks,theyhavetomanually
openand checkeachfork. Asonedeveloper stated ‚ÄúIdon‚Äôt lookat
the graphs on GitHub... it is very hard to find the data, you haveto scroll for 5 minutes to find stuff‚Äù [P5]. The view does not even
loadwhenthereareover1000forks,nomattertheyareactiveor
inactive.
Subsequently,itisdifficultfordeveloperstomaintainanoverview
of forks, which can lead to several additional problems:‚Ä¢
Redundant development: Unaware of activities in other forks, de-
velopers may reimplement functionality already developed else-
where. StƒÉnciulescu et al. report that, in an open source project,
14percentofallpullrequestswererejectedbecauseofconcur-
rent development [ 71]. Redundant development further leads to
merge conflicts, which would demotivate or prevent developers
from continuously contributing to the repository [ 35,69], and
significantly increases the maintenance effort for maintainers
[23,71].Adeveloperweinterviewedforthispaperdescribedthe
problemasfollows: ‚ÄúIthinktherearealotofpeoplewhohavedone
work twice, and coded in completely different coding style‚Äù [P3].
‚Ä¢Lost contributions: Developers may explore interesting ideas, fix
bugs,oraddusefulfeaturesinforks,butunlesstheycontribute
thosechangesbacktotheoriginalproject,thosecontributionsare
easily lost to the larger community. Even though contemporary
social-codingplatformslistallknownforks(seeFig.1),project
maintainers are unlikely to identify interesting contributions
among the thousands of forks many open source projects attract.
Furthermore, even when a feature of interest is identified in a
fork, because of independent development in each fork, it can
be difficult to port features from one fork to another [ 23]. A
frequentlymentionedcomplaintisthatforksrarelychangethe
Readme file to describe what the fork changes.
‚Ä¢Suboptimalforkingpoint: Withoutanoverviewofforksandtheir
different contributions, developers might not fork from the code-basethatisclosesttotheirintendedgoals.Dubinskyetal.report
that in industrial fork-based development projects developers of-
ten struggle to identify which of multiple existing forks to select
as a starting point [23].
There are many different reasons to fork a project: adding a fea-
ture,fixingabug,preparingapullrequest,continuinganabandoned
project, customizing or configuring the project to create a variant,
or making a private copy [ 23,52,64,71]. In fact, many forks of a
project tend to be inactive. For example, one of the subject systemsinourstudy, Smoothieware,has623forksintotal,ofwhich89forks
performed unique non-merged code changes, of which 33 were
active within the last 12 months. To an observer, the function of a
fork and its activity level is difficult to identify; somebody looking
forinterestingactivities(e.g.,forksdevelopingfeatures,fixingbugsorexperimentingwithcode[
71])willoftenhastonavigateallforks.
106
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. Identifying Features in Forks ICSE ‚Äô18, May 27-June 3, 2018, Gothenburg, Sweden
GitHubhas notaddressed theincreasingissue withnavigating
manyforksdespitemanyfeaturerequests[ 1,2].Externaldevelopers
haveexploredonlyverybasicimprovements,mostnotablyaweb
browserextensionthatshowsthemoststarredfork,forthecommon
usecaseofidentifyinganactiveforktoanabandonedproject[ 3].In
our user study, we learned there are mainly two ways practitioner
currently use to find interesting forks: Developers either look at
forks they know about and go through the fork‚Äôs commits and
commitmessages(e.g., ‚ÄúIdocompareonebranchtoanother‚Äù [P5]),or
useGoogleandGitHubtosearchforparticularkeywords.Searching
is mentioned by several participants as the preferred choice, e.g., ‚ÄúI
usually will use Google but set to only look inside GitHub‚Äù [P6].
Inthiswork,wesuggestamoresystematicapproachtocreatean
overview of forks that identifies the changes in each forks, clusters
them into features, and provides concise descriptions through a set
of characteristic keywords.
3 INFOX
INFOXidentifiesandlabelsfeatureswithinalargerchangeofafork.
It takes the diff between the latest commit of the upstream (source
snapshot) and the latest commit of the fork (target snapshot) from
GitHub,whichreturnsthenon-mergedchangesfromfork.2Then
it proceeds in three steps (as shown in Fig. 2):
‚Ä¢Identifyadependencygraphamongalladdedorchangedlines
ofcode byparsingand analyzingthe codeformultiple kindsof
dependencies (Sec. 3.1).
‚Ä¢Clusterthelinesofthechangebasedonthedependencygraph
using a community-detection technique, mapping each line of
codetoafeature,suchthatlineswithmanyconnectionsinthe
dependency graph are mapped to the same feature (Sec. 3.2).
‚Ä¢Labeleachclusterbyextractingrepresentativekeywordswith
an information-retrieval technique (Sec. 3.3).
The first step is inspired by ClusterChanges, an approach to
untanglecodeincommitsforcodereview[ 5].ClusterChanges
clusters changed code fragments based on a dependency graph of
linesofcode.Weadoptthisideaforadifferentpurpose(identify-
ingandnamingfeaturesinmultipleforksratherthanuntangling
changesinasinglecommit)andweextendtheapproachwithaddi-tionalkindsofdependencyedges,additionalstepsintheclustering
process, and labeling of clusters, as we will explain.
3.1 Generating a dependency graph
We generate a dependency graph for all lines of code of the target
snapshotbyparsingthetargetsnapshotandanalyzingtheresultingabstractsyntaxtree.Weaddedgesbetweenlinesforseveralkindsofrelationshipsofcodefragmentswithinthoselinesthatmayindicate
that the two fragments are that are more likely to be related. We
collectthefollowingkindsofdependencies,whichwealsoillustrate
on a simple excerpt of an email system in Fig. 3:‚Ä¢
Definition-usage edges: We add edges between the definition and
use of functions and variables in the program, and the definition
anduseofstructsorclassesandtheirmembers.Weconjecture
that def-use relationships between two code fragments often
2Whiledevelopedforchangesinasinglefork,ourapproachcanbetechnicallyused
toclusterthechangesbetweenanytwocodesnapshots,includingtwocommitsina
single repository or two copies of code maintained without a version control system."&&















 
	


$ #
#!
% 
!




	
	


	

Figure 2: Generating and clustering dependency graphs to
identify features, and labeling features.
pointtotwocodefragmentsthatfulfillajointpurposeandare
thus more likely to be part of the same cohesive change in a
larger change.
‚Ä¢Control-flow edges: We generate a control-flow graph for the
sourcecodeandaddedgesbetweentwolinesifthereisacontrol
dependency relation between the statements of each line. In line
with Emerson‚Äôs cohesion metrics [ 27], we think that the flow of
control information contributes to the cohesion of code changes.
‚Ä¢Adjacency and hierarchy edges: We add edges between consec-
utive lines and lines that represent hierarchical structures in
thesourcecode(struct/classmemberspointtotheouterstruct
definition).Adjacencyedgesandhierarchyedgesrepresentthe
structure of the source code and indicate that code fragmentsthat are located close to each other are more likely to belongto the same cohesive fragment than code fragments scattered
across different places.
The result is a labeled, weighted, undirected graph, in which
nodes represent lines of code and edges represent the identified de-
pendencies listed above. We assign a low weight of 1 for adjacency
edges,andaweightof5forallotheredges.Intuitively,semanticde-pendenciesintheprogramshouldbestrongerindicatorsoffeatures
than structural relations. We use an undirected dependency graph,
asourexperimentsshowednobenefitinmaintainingdirectionality.
Usingadiffcommandbetweenthesourceandthetargetsnap-
shot, we identify and mark all nodes that have been added or
changed in the target snapshot (highlighted in Fig. 2).
ComparedtoClusterChanges[ 5],weaddedgesbetweennodes
with hierarchical and control-flow relations, and add weights.
107
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. 108
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. 109
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. 110
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. 111
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô18, May 27-June 3, 2018, Gothenburg, Sweden S. Zhou et al.
edgesandwithandwithoutsplittingandjoining. Regarding RQ2,
we observe that splitting & joining steps improves accuracy
by 4-14 % (stat.sign., p<.05).Removinganykindofedgesfromthe
clustering approach significantly affects accuracy as well ( p<.05);
all kinds of edges are important for the clustering quality ,
but the definition-usage edges are the most influential ones.
5.2 Human-subject study (RQ3 & RQ4)
ToevaluatetheusabilityofINFOX,wecontactedopen-sourcedevel-
operswhomaintainforkstovalidateidentifiedfeaturesandexplore
whether the generated summaries provide meaningful insights.
Studydesign. Weinviteddevelopersofactiveforks(seeselection
below)foraremoteinterview.Weconductedeachinterviewina
semi-structured fashion divided into four phases:
‚Ä¢Opening and introduction: We started each interview by briefly
explainingourresearchtopicandthegeneralpurposeofour
study. We asked whether the participants would share their
screen with us and whether they consent to screen and audio
recording.
‚Ä¢Validating clustering result (RQ3): In order to help participants
remember what the code changes are, and also help us to gain
domain knowledge for a better conversation, we first asked
participantstobrieflydescribetheprojectandcodechanges.Subsequently, we sent them the clustering result of Infox
for their own fork as a folder of HTML files (as illustrated
in Fig. 5). Within those results, participants could split and
join clusters interactively. We started with an initial clustering
result(withoutanysplitting)andexplainedhowtoreadand
navigate the results.
Inasubsequentdiscussion,wepursuedtwoquestions:Whether
thekeywordsarerepresentativeoftheirfeatureimplementa-
tion and whether the clustering of the source code is meaning-
ful to them. Most of the participants were communicative, and
rightafterspendingsometimelearninghowtointeractwith
Infox,theystartedtonavigateamongcodechanges,explaining
themeaning ofthecode, andwhetherclustersmade senseor
not.Inlinewithmethodsforthink-aloudprotocols[ 42],ween-
couraged participants that were interacting with INFOX with-
out sayinganything for along time to speakout loud, asking
probingquestions,suchas ‚ÄúCouldyoutelluswhatareyoulook-
ing at?‚Äùor‚ÄúWould you explain what this code cluster means?‚Äù
‚Ä¢Exploring the project overview (RQ4): Before exploring Infox‚Äôs
summaryofotherforks,wetransitionedthediscussionwith
the question ‚ÄúDo you check what other forks are doing in this
project?‚Äù and followed up with questions on how and for
what purpose they do this. Afterward, we sent them the
project overview (cf. Fig. 1b) and encouraged them to look
through the list of forks. By clicking on the name of a fork,theycouldalsoexplorethatfork‚ÄôscodewithInfox‚Äôsresults,just as they previously did for their own fork. Participants
were usually actively exploring other forks at this point
without our prompting and shared discoveries with us. When
participants explored the code of a fork, we asked whether the
keyword summary provided them a reasonable approximation
of what they found in the implementation. In addition, weopportunistically asked questions about the relevance ofkeywords and the accuracy of clustering results in other forks
based on their understanding (similar to questions about their
own fork previously) when it fit the flow of the exploration.
‚Ä¢Opendiscussionandclosing: Weconcludedeachsessionwith
general and open-ended questions about further use cases and
suggestions for improvement.
We compensated each participants with a $10 Amazon gift card.
The interviews lasted between 30 and 90 minutes.
Participant selection. We searched for projects with active forks
using two strategies. First, we used the GitHub search to findprojects written in C/C++, selecting projects with more than 30forks. Second, we queried GHTorrent [
36] for the 100 C/C++
projects with the most first-level forks.
Amongtheseprojects,weselectedforksthat:(a)hadatleastone
commitwithinthelastyear(increasingthechancethatintervieweescanremembertheirchanges),(b)haveaddedatleast10linesofcode
(smaller changes are less likely to be a feature implementation),(c) have a large portion of commits submitted by the fork owner(excluding forks that aggregate changes of others), and (d) have
a public email address or website of the fork owner. To enable
questionsabouttheoverviewpage,weexcludedprojectsforwhich
we could not find at least three forks that fit these criteria.
In the end, we analyzed 58 projects on Github and found 12
projects fit our filtering criteria. We identified 81 fork owners. We
sent out an email to candidate developers briefly describing our
study.Weinterviewed11developersfrom7differentprojects(re-
sponserate13.6%).Wequicklyreachedsaturationinthatadditionalinterviewsprovidedonlymarginaladditionalinsights.InTable2we
listthecharacteristicsoftheprojectsfromwhichweinterviewed
developers.Alldevelopersareexperiencedopen-sourcedevelopers.
Analysis. We analyzed the interviews primarily qualitatively,
analyzing what participants learned and how they interacted with
the tool. Two of the authors transcribed and coded the interviews,
following standard methods of qualitative empirical research [66].
Threatstovalidity. Regardingexternalvalidity,ourstudymay
sufferfromaselectionbias,ascommonforthesekindsofstudies.
Many of our participants work on 3D printers, which may have
differentcharacteristics.However,overallwereacheddevelopers
from several different domains and did not observe any systematic
differences. Finally, we focus on open source whereas results may
differ in industrial settings in which forks are centrally managed.
Regarding internal validity, communication issues may have
affected some answers; we mitigated this threat by refining our
interviewguidewhenquestionsraisedconfusionandinvolvedtwo
researchersineachinterview.Despiteopen-endedquestionsand
carefuldesign(seeabove),wecannotentirelyexcludeconfirmation
bias,inwhichparticipantsmightavoidraisingcriticalpoints;we
mitigate this by focusing on insights gained, not just claims.
Results.Regarding RQ3 (clustering quality), participants mostly
confirmed that the clustering results were appropriate, but often
fine-tunedthemwithfurthersplittingandjoining.Thisfurthersup-ports the need for interactive tools. Overall, participants supported
ourdecisiontoclusterchangesinafork.Forexample,participant
P4 said:‚ÄúIt is necessary to split code changes into pieces, even though
they cannot be executed in isolation.‚Äù Of the 11 participants, 10 said
112
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. Identifying Features in Forks ICSE ‚Äô18, May 27-June 3, 2018, Gothenburg, Sweden
Table 2: Participants of our user study and their projects
Project #Forks #Active Forks LOC Change size (LOC) Domain Participant
MarlinFirmware/Marlin 4149 1901 19,799 2-3753 3D printer P1 P3
Smoothieware/Smoothieware 566 237 61,425 19-11, 263 3D printer P5 P6 P7
grpc/grpc 2226 470 95,838 3-480,901 general-purpose RPC framework P2
timscaffidi/ofxVideoRecorder 60 24 611 7-23,228 multi-threaded video recording extension P4
arduino/Arduino 5592 669 112,692 23-7,643 electronic prototyping platform P4
bitcoin/bitcoin 9696 1242 99,746 6-647 experimental digital currency P8 P9 P10
ariya/phantomjs 4,921 749 10,031 45-2,358 Scriptable Headless WebKit P11
that INFOX correctly identified the clusters most of the time, al-
thoughtherearesmallclusters(containingoneortwolines)should
havebeenmergedintobiggerclusters.Theremainingparticipant
pointed out a cluster containing unrelated code that was automati-
cally generated by libraries and should be removed.
Aswediscussedearlier,INFOXprovidesflexibilitytodevelopers
by allowing them to split or join clusters interactively. During the
interviews, participants compared thesplitting and joining results
carefully, and after several steps, they usually identified clusters
that they agreed with. For example a typical interaction flowed as
follows,herefromparticipantP5: ‚ÄúIthinkthisblueandyellowcluster
should belong together.. [clicks the join button] ..oh, so your software
correctlyidentifiesallofthisbeingonethingnottwodifferentthings.‚Äù
Theparticipantsidentifiedsomecasesinwhichtheclustering
resultcouldbeimproved,usuallycausedbytechnicallimitations
of the dependency analysis in our prototype (see Section 7). For
example, when P4 found a 1-line cluster that should belong toanother bigger cluster, the participant said: ‚ÄúI know it is related,
accelerationandvolumetric(arerelated),butlookingatjustthesyntaxitisnot,itisnotusingthesamewords.Addingcheck-boxtomanually
merge selected clusters (could solve this problem)‚Äù.
In summary, participants generally agreed that INFOX
could identify correct clusters at certain splitting or joiningsteps
(RQ3).ParticipantssuggestedthatINFOXcouldprovidemore
flexibility for manually refining the clustering result. Even though
limited to few participants, our interviews corroborate the high-
accuracy results from our quantitative study in a realistic setting.
With regard to RQ4 (overview), we looked particularly for signs
that developers learned new insights while exploring the overview.
Of the 11 participants, we showed 10 participants (P2-P11) theoverview of forks in their project and 8 gained different kinds of
new information from the overview page:‚Ä¢
Finding redundant development. Two participants found other
forks that are working on the same feature implementation as
theydidbefore.Whentheyfoundtheseinstancesofredundant
development, they explored the fork‚Äôs source code. For example,
P3 said :‚ÄúIt does look like somebody did a very simple one-function
[...]system.Ithinktheyshoulduseourcode,thereisgreatreasontouseit.‚Äù Afterskimmingtheoverviewpage,P4said: ‚ÄúIcansee
multiple forksare workingon the similarproblem. Thisone looks
like it is adding [...] that I already added.‚Äù
‚Ä¢Find interesting and potentially reusable feature. When skimming
alltheforks,6participantsidentifiedspecificfeaturesofinterest;
For example, P5 expressed ‚Äúthis is all laser stuff, this is useful.‚Äù
Whenparticipantsmentionedsomethingisinteresting,weasked
themwhy.Theanswersallidentifyfeaturesthatareimportant
totheprojectorthattheycouldreuseintheirownforks,suchas P5‚Äôs statement ‚ÄúIf it is only exists in this fork, then I want to
somehow get this fork into my fork.‚Äù
Beyond these specific actionable insights, many participants
more generally indicated that this overview would be useful: By
lookingattheoverviewpage,ourparticipantsfoundmanyforks
thattheydidnotknowbefore,andbyreadingthesummarytableof
eachfork,theyusuallygottheideaofwhathashappenedineach
fork. For example, participant P3 said: ‚ÄúIt is going to make it a lot
easiertofindthethingsyouarelookingforasaprogrammer.‚Äù andP6
explained ‚ÄúI see all the differences for all the forks. Basically it is the
samethingIamdoingthroughGitHub,(but)onlyitissummarized
in the same place, I don‚Äôt have to jump and open 50 tabs to do it.‚Äù
ParticipantP7expressedinteresttousethetoolforanotherproject
he maintained, for which he always wanted to know what is going
on in forks, but was limited by current tools.
Regardinglabelsforcodetheydidnotknow,wecouldobserve
that they clearly gave some initial idea to participants and could
typicallydescribewhattheywouldexpectfromtheimplementation.Forexample,participantP5described ‚Äúthe[keywords]givemesome
clues of temperature; I know which part of Smoothie is modified.‚Äù
Overall,allparticipantsthoughttheinterpretationofkeywordsis
similar to their understanding of the source code.
In summary, even though we interviewed only a small num-
ber of participants, we found frequent and concrete evidence
of new insights gained from the overview page, including re-dundant development and reusable contributions
(RQ4).This
is encouraging for the usefulness of the approach and its capability
to provide actionable insights.
6 RELATED WORK
Transparency in social coding. Transparency in modern social cod-
ingplatformshasbeenshowntobeessentialfordecisionmaking
infastpacedanddistributedsoftwaredevelopment[ 19,20].Visible
clues,suchasdeveloperactivitiesorprojectpopularity,influence
decisionmakingandreputationinanecosystem.Withthiswork,
wemakeoften-lostcontributionsinforksandbranchestranspar-
ent to developers with the aim of reducing inefficiencies in the
development process.
Forking Practices. Before the rise of social coding, forking tra-
ditionally referred to splitting off a new independent development
branch, to compete with or supersede the original project. Theright for such hard forks (codified in open source licenses) was
seen as essential for guaranteeing freedom and useful for fosteringdisruptive innovations [
31,55,56], but hard forks themselves were
oftenseenasantisocialandasrisktoprojects[ 31,45,55,60].Inthe
context of modern forking, alower bar of forking may encourage
developers to maintain multiple variants of a product in parallel,
113
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô18, May 27-June 3, 2018, Gothenburg, Sweden S. Zhou et al.
often not intended ashard forks. Gousios et al. exploredGitHub‚Äôs
pull-request model, in which forking is an essential component.
Their work confirms that forking provides increased opportunities
for community engagement, but also highlights that only few con-
tributions are integrated and pull requests arefrequently rejected
due to redundant development and missing coordination [35].
Understanding branches and forks. Conceptually closest to our
workisBirdandZimmerman‚ÄôsanalysisofbranchesatMicrosoft,
revealingthattoomanybranchescanbeanissueand what-ifanaly-
sistoexplorethecostsofmergingcansupportdecisionmaking[ 7].
In addition, several studies have studied forking practicesin open
source and industrial product line development [ 23,52,64,71].
Those studies have revealed the discussed problems, but did not
provide any solutions.
Untanglingcodechanges. Technically,ourworkrelatestowork
onuntanglingcodechanges.Originally,untanglingcodechanges
was driven by biases in mining repositories and predicting de-
fects[21,37].Barnettetal .[5]proposedClusterChangestode-
compose tangled code changes in order to identify independent
parts of changes, especially large commits, to facilitate understand-
ing during the code reviewing process. A key assumption is that
commits are not always cohesive and reliable. These approachesoften analyze dependencies within a change and our implemen-tation was inspired by and improves upon ClusterChanges, as
discussed and evaluated.
Otherstrategieshavebeenexploredtountanglechanges,includ-
ingsemantichistoryslicing thatcomparestestexecutions[ 47,48],
andEpiceaUntangler [21] andThresher [73] which interact with
developerswhencommittingachange,toencouragemorecohesive
commits. All these approaches are less applicable in our setting, as
they would require test cases for all added functionality or upfront
clean commits by all developers. In fact, Herzig and Zeller [38]
arguethattangledchangesarenaturalandshouldnotbeforbidden;
we support this view and build tooling that extracts features after
the fact, but at much larger granularity of differences in forks.
Concern location. Concern location (or concept or feature
location) is the challenge of identifying the parts of the sourcecode that correspond to a specific functionality, typically formaintenance tasks [
59]. Based on a keyword or entry-point,
developers or tools attempt to identify all code relevant for that
feature. Concern location typically uses either a static, a dynamic,
or an information-retrieval strategy [ 22,76]: Static analyses
examine structural information such as control or data flow depen-
dencies [11,62], whereasdynamic analyses examinethe system‚Äôs
execution[ 15,26].Incontrast,information-retrieval-basedanalyses
perform some sort of search based on keywords [ 13,22,33,50,57]
withmoreorlesssophisticatednaturallanguageprocessing[ 41,68].
Combinations of these strategies are common [ 22]. Our analysis
has similarities with static concern-location approaches, but the
setting is different: Instead of identifying code related to a specific
givencodefragmentinasinglecodebase,weaimatdividingthe
difference between two snapshots into cohesive code fragments
without starting points. Whereas location usually identifies one
concern at a time, we identify multiple features in a fork. At the
same time, if execution traces or external keywords were available,
thosecouldlikelybeintegratedintoaclusteringprocesslikeInfox.Code summarization. Finally, there are many approaches to
summarize source code [ 44,53,58,70] using information retrieval
to derive topics from the vocabulary usage at the source code level.
So far, we use only a standard lightweight information-retrieval
technique to identify keywords for clusters, but combinations with
more advanced summarization strategies might improve results
significantly.
7 DISCUSSION AND CONCLUSION
Evidencefrombothacademiaandindustryshowsthatcurrentfork-baseddevelopmentispopularbuthasmanypracticalproblemsthat
can be traced to a lack of transparency. Because developers do not
have an overview of forks of a project, problems like redundant
development,lostcontributionsandsuboptimalforkingpointarise.
To improve the transparency, we designed an approach to identify
featuresfromforksandgenerateanoverviewoftheprojectinorder
to inform developers of what has happened in each active fork.
Infoxisafirststepinmakingtransparentwhathappensinforks
ofaproject,anditcanbeabuildingblockinalargerendeavorto
supportfork-baseddevelopment,suchthatitkeepsitsmainbenefits,
such as ease of use and distributed and independent development,
while addressing many of its shortcomings through tool support.
Thisnewtransparency,mightaddressproblemsincludinglost
contributionsand redundantdevelopment.Allparticipants inour
human subject study had immediate ideas of who might benefitfrom such a tool, including ‚Äúthe person who maintains the main
branch‚Äù[P4]and‚Äúitissuperusefulforeverybody,especiallyformajor
main Smoothieware developers‚Äù [P6]. In addition our evaluation has
shown that clustering results are accurate (90% on average) and
labels are meaningful summaries.
Atthesametime,Infoxisjustaninitialprototypewithtechnical
limitations and many opportunities for extensions:‚Ä¢
Theinitialclusteringstrategyaswellasthecommunity-detection
algorithm [ 34] are designed to divide a change into disjoint clus-
ters. Boundaries between features are not always easy to define
andfeaturesmayoverlapormaybesplitintosubfeatures.Explor-ingothernetworkanalysistechniquestoidentifyoverlappedfea-turesorsub-featuresisaninterestingavenueforfurtherresearch.
‚Ä¢Although our clustering approach achieved high accuracy
results, it would be worth to explore additional information that
might provide insights about relationships of code fragments
(even if unreliable generally), such as data-flow dependencies,
syntacticorstructuralsimilaritybetweencodefragments,code
fragments that have been changed together in the same commit
or by the same author. To identify which of these provide useful
insights and which just create more noise.
ACKNOWLEDGMENTS
K√§stnerandZhou‚ÄôsworkhasbeensupportedinpartbytheNational
Science Foundation (awards 1318808, 1552944, and 1717022) and
AFRL and DARPA (FA8750-16-2-0042). St Àáanciulescu‚Äôs work has
been supported in part by the EliteForsk travel scholarship fromthe Danish Ministry of Higher Education and Science. Xiong‚Äôs
work has been supported in part by National Key Research and
Development Program 2016YFB1000105.
114
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. Identifying Features in Forks ICSE ‚Äô18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]2016. DearGithubIssue109:TellusConciselyWhatOtherPeopleChangedin
Their Forks. (2016). https://github.com/dear-github/dear-github/issues/109
[2]2016. DearGithubIssue 175:Betteroverview overforks. (2016). https://github.
com/dear-github/dear-github/issues/175
[3]2017. LovelyForksBrowserExtension:ShownotableforksofGithubrepositories
under their names. (2017). https://github.com/musically-ut/lovely-forks
[4]Micha≈ÇAntkiewicz,WenbinJi,ThorstenBerger,KrzysztofCzarnecki,Thomas
Schmorleiz, Ralf Laemmel, Stefan StƒÉnciulescu, Andrzej WƒÖsowski, and Ina
Schaefer. 2014. Flexible Product Line Engineering with a Virtual Platform. In
Comp. Int‚Äôl Conf. Software Engineering (ICSE). ACM, 532‚Äì535.
[5]MikeBarnett,ChristianBird,JoaoBrunet,andShuvenduKLahiri.2015. Help-
ing Developers Help Themselves: Automatic Decomposition of Code Review
Changesets.In Proc.Int‚ÄôlConf.SoftwareEngineering(ICSE),Vol.1.IEEE,134‚Äì144.
[6]Thorsten Berger, Divya Nair, Ralf Rublack, Joanne M Atlee, Krzysztof Czarnecki,
andAndrzejWƒÖsowski.2014. ThreeCasesofFeature-basedVariabilityModeling
in Industry. In Proc. Int‚Äôl Conf. Model Driven Engineering Languages and Systems
(MoDELS). Springer, 302‚Äì319.
[7]ChristianBirdandThomasZimmermann.2012. AssessingtheValueofBranches
withWhat-ifAnalysis.In Proc.Int‚ÄôlSymposiumFoundationsofSoftwareEngineer-
ing (FSE). ACM, 45.
[8]J√ºrgenBitzerandPhilippJHSchr√∂der.2006.TheImpactofEntryandCompetition
byOpenSourceSoftwareonInnovationActivity. Theeconomicsofopensource
software development (2006), 219‚Äì245.
[9]JanBosch. 2009. FromSoftwareProduct LinestoSoftwareEcosystems.In Proc.
Int‚Äôl Software Product Line Conf. (SPLC). Carnegie Mellon University, 111‚Äì119.
[10]Simon Butler, Michel Wermelinger, Yijun Yu, and Helen Sharp. 2011. Improv-ing the Tokenisation of Identifier Names. Proc. Europ. Conf. Object-Oriented
Programming (ECOOP) (2011), 130‚Äì154.
[11]KunrongChenandV√°clavRajlich.2000. CaseStudyofFeatureLocationusing
DependenceGraph.In Proc.Int‚ÄôlWorkshoponProgramComprehension(IWPC).
IEEE, 241‚Äì247.
[12]Bredan Cleary and Chris Exton. 2007. Assisting Concept Location in Software
Comprehension. Ph.D. Dissertation. University of Limerick.
[13]BrendanCleary,ChrisExton,JimBuckley,andMichaelEnglish.2009. AnEm-
pirical Analysis of Information Retrieval based Concept Location Techniques in
Software Comprehension. Empirical Software Engineering 14, 1 (2009), 93‚Äì130.
[14]MichaelLCollard,MichaelJohnDecker,andJonathanIMaletic.2013. srcML:An
InfrastructurefortheExploration,Analysis,andManipulationofSourceCode:
A Tool Demonstration. In Proc. Int‚Äôl Conf. Software Maintenance (ICSM). IEEE,
516‚Äì519.
[15]BasCornelissen,AndyZaidman,ArieVanDeursen,LeonMoonen,andRainer
Koschke. 2009. A Systematic Survey of Program Comprehension through Dy-
namic Analysis. IEEE Trans. Softw. Eng. (TSE) 35, 5 (2009), 684‚Äì702.
[16]Davor ƒåubraniƒá and Gail C Murphy. 2003. Hipikat: Recommending Pertinent
Software Development Artifacts. In Proc. Int‚Äôl Conf. Software Engineering (ICSE) .
IEEE Computer Society, 408‚Äì418.
[17]DavorƒåubraniƒÜ,GailCMurphy,JaniceSinger,andKelloggSBooth.2004. Learn-
ing from Project History: a Case Study for Software Development. In Proc. Conf.
Computer Supported Cooperative Work (CSCW). ACM, 82‚Äì91.
[18]DavorCubranic,GailCMurphy,JaniceSinger,andKelloggSBooth.2005.Hipikat:
A Project Memory for Software Development. IEEE Trans. Softw. Eng. (TSE) 31, 6
(2005), 446‚Äì465.
[19]LauraDabbish,ColleenStuart,JasonTsay,andJimHerbsleb.2012. SocialCoding
in GitHub: Transparency andCollaboration in an Open Software Repository.In
Proc. Conf. Computer Supported Cooperative Work (CSCW). ACM, 1277‚Äì1286.
[20]LauraDabbish,ColleenStuart,JasonTsay,andJamesHerbsleb.2013. Leveraging
Transparency. IEEE Software 30, 1 (2013), 37‚Äì43.
[21]Mart√≠n Dias, Alberto Bacchelli, Georgios Gousios, Damien Cassou, and St√©phane
Ducasse.2015. Untanglingfine-grainedcodechanges.In Proc.Int‚ÄôlConf.Software
Analysis, Evolution, and Reengineering (SANER). IEEE, 341‚Äì350.
[22]Bogdan Dit, Meghan Revelle, Malcom Gethers, and Denys Poshyvanyk. 2013.
FeatureLocationinSourceCode:aTaxonomyandSurvey. Journalofsoftware:
Evolution and Process 25, 1 (2013), 53‚Äì95.
[23]Yael Dubinsky, Julia Rubin, Theodore Berger, Slawomir Duszynski, MatthiasBecker, and Krzysztof Czarnecki. 2013. An Exploratory Study of Cloning in
Industrial Software Product Pines. In Proc. Europ. Conf. Software Maintenance
and Reengineering (CSMR). IEEE, 25‚Äì34.
[24]Anh Nguyen Duc, Audris Mockus, Randy Hackbarth, and John Palframan. 2014.
Forking and Coordination in Multi-platform Development: A Case Study. In
Proc. Int‚Äôl Symp. Empirical Software Engineering and Measurement (ESEM) . ACM,
59:1‚Äì59:10.
[25]Marc Eaddy, Alfred V Aho, Giuliano Antoniol, and Yann-Ga√´l Gu√©h√©neuc. 2008.
Cerberus:TracingRequirementstoSourceCodeusingInformationRetrieval,Dy-
namicAnalysis,andProgramAnalysis.In Proc.Int‚ÄôlConf.ProgramComprehension
(ICPC). Ieee, 53‚Äì62.[26]Thomas Eisenbarth, Rainer Koschke, and Daniel Simon. 2003. Locating Features
in Source Code. IEEE Trans. Softw. Eng. (TSE) 29, 3 (2003), 210‚Äì224.
[27]ThomasJEmerson.1984. ADiscriminantMetricforModuleCohesion.In Proc.
Int‚Äôl Conf. Software Engineering (ICSE). IEEE Press, 294‚Äì303.
[28]MichaelD.Ernst,GregJ.Badros,andDavidNotkin.2002. AnEmpiricalAnalysis
of C Preprocessor Use. IEEE Trans. Softw. Eng. (TSE) (2002), 1146‚Äì1170.
[29]Neil A Ernst, Steve Easterbrook, and John Mylopoulos. 2010. Code Fork-
ing in Open-source Software: a Requirements Perspective. arXiv preprint
arXiv:1004.2889 (2010).
[30]Janet Feigenspan, Maria Papendieck, Christian K√§stner, Mathias Frisch, and
RaimundDachselt.2011. FeatureCommander:Colorful#ifdefWorld.In Proc.Int‚Äôl
Software Product Line Conf. (SPLC). ACM, 48.
[31]KarlFogel.2005. ProducingOpenSourceSoftware:HowtoRunaSuccessfulFree
Software Project. " O‚ÄôReilly Media, Inc.".
[32]SantoFortunato.2010. CommunityDetectioninGraphs. Physicsreports 486,3
(2010), 75‚Äì174.
[33]GregoryGay,SoniaHaiduc,AndrianMarcus,andTimMenzies.2009. OntheUseofRelevanceFeedbackinIR-basedConceptLocation.In Proc.Int‚ÄôlConf.Software
Maintenance (ICSM). IEEE, 351‚Äì360.
[34]Michelle Girvan and Mark EJ Newman. 2002. Community Structure in Social
andBiologicalNetworks. Proceedingsofthenationalacademyofsciences 99,12
(2002), 7821‚Äì7826.
[35]Georgios Gousios, Martin Pinzger, and Arie van Deursen. 2014. An Exploratory
Study of the Pull-based Software Development Model. In Proceedings of the 36th
International Conference on Software Engineering. ACM, 345‚Äì355.
[36]Georgios Gousios, Bogdan Vasilescu, Alexander Serebrenik, and Andy Zaidman.
2014. Lean GHTorrent: GitHub Data on Demand. In Proc. Int‚Äôl Conf. Mining
Software Repositories (MSR). ACM, 384‚Äì387.
[37]Kim Herzig and Andreas Zeller. 2011. Untangling Changes. Unpublished manu-
script, September 37 (2011), 38‚Äì40.
[38]Kim Herzig and Andreas Zeller. 2013. The Impact of Tangled Code Changes. In
Proc. Int‚Äôl Conf. Mining Software Repositories (MSR). IEEE Press, 121‚Äì130.
[39]Kim Herzig and Andreas Zeller. 2013. The Impact of Tangled Code Changes. In
Proc. Int‚Äôl Conf. Mining Software Repositories (MSR). IEEE, 121‚Äì130.
[40]EmilyHill,LoriPollock,andKVijay-Shanker.2007. ExploringtheNeighborhood
with Dora to Expedite Software Maintenance. In Proc. Int‚Äôl Conf. Automated
Software Engineering (ASE). ACM, 14‚Äì23.
[41]Emily Hill, LoriPollock, and K Vijay-Shanker. 2009. AutomaticallyCapturing
SourceCodeContextofNL-queriesforSoftwareMaintenanceandReuse.In Proc.
Int‚Äôl Conf. Software Engineering (ICSE). IEEE, 232‚Äì242.
[42]Riitta J√§√§skel√§inen. 2010. Think-aloud Protocol. Handbook of translation studies
1 (2010), 371‚Äì374.
[43]DavidKawrykowandMartinP.Robillard.2011.Non-essentialChangesinVersion
Histories. In Proc. Int‚Äôl Conf. Software Engineering (ICSE). ACM, 351‚Äì360.
[44]AdrianKuhn,St√©phaneDucasse,andTudorG√≠rba.2007. SemanticClustering:
Identifying Topics in Source Code. Information and Software Technology (IST) 49,
3 (2007), 230‚Äì243.
[45]AndrewMStLaurent.2004. UnderstandingOpenSourceandFreeSoftwareLicens-
ing:GuidetoNavigatingLicensingIssuesinExisting&NewSoftware. "O‚ÄôReilly
Media, Inc.".
[46]Sungjick Lee and Han-joon Kim. 2008. News Keyword Extraction for Topic
Tracking. In Proc. Int‚Äôl Conf. Networked Computing and Advanced Information
(NCM). IEEE, 554‚Äì559.
[47]Yi Li, Chenguang Zhu, Julia Rubin, and Marsha Chechik. 2016. Precise Semantic
HistorySlicingthroughDynamicDeltaRefinement.In Proc.Int‚ÄôlConf.Automated
Software Engineering (ASE). 495‚Äì506.
[48]Y.Li,C.Zhu,J.Rubin,andM.Chechik.2017. SemanticSlicingofSoftwareVersion
Histories. IEEE Trans. Softw. Eng. (TSE) (2017), 1‚Äì1.
[49]J√∂rg Liebig, Sven Apel, Christian Lengauer, Christian K√§stner, and Michael
Schulze.2010. AnAnalysisoftheVariabilityinFortyPreprocessor-basedSoft-
ware Product Lines. In Proc. Int‚Äôl Conf. Software Engineering (ICSE).
[50]Andrian Marcus, Andrey Sergeyev, Vaclav Rajlich, and Jonathan I Maletic. 2004.
An information retrieval approach to concept location in source code. In Proc.
Working Conf. Reverse Engineering (WCRE). IEEE, 214‚Äì223.
[51]Fl√°vio Medeiros, Christian K√§stner, M√°rcio Ribeiro, Sarah Nadi, and Rohit Gheyi.
2015. The Love/Hate Relationship with the C Preprocessor: An Interview Study.
InProc. Europ. Conf. Object-Oriented Programming (ECOOP). Schloss Dagstuhl‚Äì
Leibniz-Zentrum fuer Informatik, 495‚Äì518.
[52]Tommi Mikkonen and Linus Nyman. 2011. To Fork or Not to Fork: Fork Motiva-
tionsinSourceForgeProjects. Int.J.OpenSourceSoftw.Process. 3,3(July2011),
1‚Äì9.
[53]Gail Cecile Murphy. 1996. Lightweight Structural Summarization as an Aid to
Software Evolution. Ph.D. Dissertation.
[54]Emerson Murphy-Hill, Chris Parnin, and Andrew P. Black. 2009. How We
Refactor,andHowWeKnowIt.In Proc.Int‚ÄôlConf.SoftwareEngineering(ICSE).
IEEE Computer Society, 287‚Äì297.
[55]Linus Nyman. 2014. Hackers on forking. In Proceedings of The International
Symposium on Open Collaboration. ACM, 6.
115
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô18, May 27-June 3, 2018, Gothenburg, Sweden S. Zhou et al.
[56]Linus Nyman, Tommi Mikkonen, Juho Lindman, and Martin Foug√®re. 1999. Per-
spectives on Code Forking and Sustainability in Open Source Software. Why
Linux on‚Äôt fork (1999). http://linuxmafia.com/faq/Licensing_and_Law/forking.
html.
[57]Maksym Petrenko, V√°clav Rajlich, and Radu Vanciu. 2008. Partial Domain Com-
prehension in Software Evolution and Maintenance. In Proc. Int‚Äôl Conf. Program
Comprehension (ICPC). IEEE, 13‚Äì22.
[58]Denys Poshyvanyk and Andrian Marcus. 2007. Combining Formal Concept
Analysis with Information Retrieval for Concept Location in Source Code. In
Proc. Int‚Äôl Conf. Program Comprehension (ICPC). IEEE, 37‚Äì48.
[59]V. Rajlich and N. Wilde. 2002. The Role of Concepts in Program Comprehension.
InProc. Int‚Äôl Conf. Program Comprehension (ICPC). 271‚Äì278.
[60]EricSRaymond.2001. TheCathedral&theBazaar:Musingsonlinuxandopen
source by an accidental revolutionary. " O‚ÄôReilly Media, Inc.".
[61]MeghanRevelle,BogdanDit,andDenysPoshyvanyk.2010. UsingDataFusion
and Web Mining to Support Feature Location in Software. In Proc. Int‚Äôl Conf.
Program Comprehension (ICPC). IEEE, 14‚Äì23.
[62]Martin P Robillard. 2005. Automatic Generation of Suggestions for Program
Investigation. In SIGSOFT Softw. Eng. Notes, Vol. 30. ACM, 11‚Äì20.
[63]MartinPRobillard,DavidShepherd,EmilyHill,KVijay-Shanker,andLoriPollock.
2007.AnEmpiricalStudyoftheConceptAssignmentProblem. SchoolofComputer
Science, McGill University, Tech. Rep. SOCS-TR-2007.3 (2007).
[64]Gregorio Robles and Jes√∫s M. Gonz√°lez-Barahona. 2012. A Comprehensive
Study of Software Forks: Dates, Reasons and Outcomes. In Open Source Systems:
Long-TermSustainability-8thIFIPWG2.13InternationalConference,OSS2012,
Hammamet, Tunisia, September 10-13, 2012. Proceedings. 1‚Äì14.
[65]Julia Rubin and Marsha Chechik. 2013. A Framework for Managing Cloned
Product Variants. In Proc. Int‚Äôl Conf. Software Engineering (ICSE). IEEE Press,
1233‚Äì1236.
[66] Johnny Salda√±a. 2015. The Coding Manual for Qualitative Researchers. Sage.
[67]GerardSaltonandChristopherBuckley.1988. Term-weightingApproachesin
Automatic Text Retrieval. Information processing & management 24, 5 (1988),513‚Äì523.
[68]DavidShepherd,ZacharyPFry,EmilyHill,LoriPollock,andKVijay-Shanker.
2007. Using Natural Language Program Analysis to Locate and Understand
Action-oriented Concerns. In Proc. Int‚Äôl Conf. Aspect-Oriented Software Develop-
ment (AOSD). ACM, 212‚Äì224.
[69]IgorSTEINMACHER,GustavoH.L.PINTO,IgorScalianteWIESE,andMarcoAu-
r√©lio GEROSA. 2018. Almost There: A Study on Quasi-Contributors in Open-
Source Software Projects. In Proc. Int‚Äôl Conf. Software Engineering (ICSE). 1‚Äì12.
[70]Margaret-Anne Storey, Li-Te Cheng, Ian Bull, and Peter Rigby. 2006. Shared
WaypointsandSocialTaggingtoSupportCollaborationinSoftwareDevelopment.
InProc. Conf. Computer Supported Cooperative Work (CSCW). ACM, 195‚Äì198.
[71]≈ûtefanStƒÉnciulescu,SandroSchulze,andAndrzejWƒÖsowski.2015. Forkedand
Integrated Variants in an Open-Source Firmware Project. In Proc. Int‚Äôl Conf.
Software Maintenance (ICSM). IEEE, 151‚Äì160.
[72]Ching Y Suen. 1979. N-gram Statistics for Natural Language Understanding and
Text Processing. IEEE transactions on pattern analysis and machine intelligence 2
(1979), 164‚Äì172.
[73]MarcelTaeumel,StephaniePlatz,BastianSteinert,RobertHirschfeld,andHide-
hiko Masuhara. 2017. Unravel Programming Sessions with THRESHER: Iden-
tifying Coherent and Complete Sets of Fine-granular Source Code Changes.
Information and Media Technologies 12 (2017), 24‚Äì39.
[74]LeiTangandHuanLiu.2010. CommunityDetectionandMininginSocialMedia.
Synthesis Lectures on Data Mining and Knowledge Discovery (2010), 1‚Äì137.
[75]Greg R Vetter. 2007. Open Source Licensing and Scattering Opportunism in
Software Standards. BCL Rev. 48 (2007), 225.
[76] Norman Wilde and Michael C Scully.1995. Software Reconnaissance: Mapping
Program Features to Code. Journal of Software: Evolution and Process 7, 1 (1995),
49‚Äì62.
[77]Andrew Y Yao. 2001. CVSSearch: Searching through Source Code using CVSComments. In Proc. Int‚Äôl Conf. Software Maintenance (ICSM). IEEE Computer
Society, 364.
116
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:50:08 UTC from IEEE Xplore.  Restrictions apply. 