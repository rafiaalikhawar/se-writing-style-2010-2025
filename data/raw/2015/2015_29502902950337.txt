Titanium: Efï¬cient Analysis of Evolving Alloy
Speciï¬cations
Hamid Bagheri
Department of Computer Science & Engineering
University of Nebraska-Lincoln
bagheri@unl.eduSam Malek
Department of Informatics
University of California, Irvine
malek@uci.edu
ABSTRACT
The Alloy specication language, and the corresponding Al-
loy Analyzer, have received much attention in the last two
decades with applications in many areas of software engi-
neering. Increasingly, formal analyses enabled by Alloy are
desired for use in an on-line mode, where the specications
are automatically kept in sync with the running, possibly
changing, software system. However, given Alloy Analyzer's
reliance on computationally expensive SAT solvers, an im-
portant challenge is the time it takes for such analyses to
execute at runtime. The fact that in an on-line mode, the
analyses are often repeated on slightly revised versions of a
given specication, presents us with an opportunity to tackle
this challenge. We present Titanium, an extension of Alloy
for formal analysis of evolving specications. By leveraging
the results from previous analyses, Titanium narrows the
state space of the revised specication, thereby greatly re-
ducing the required computational eort. We describe the
semantic basis of Titanium in terms of models specied in
relational logic. We show how the approach can be realized
atop an existing relational logic model nder. Our experi-
mental results show Titanium achieves a signicant speed-up
over Alloy Analyzer when applied to the analysis of evolving
specications.
CCS Concepts
Software and its engineering !Formal methods;
Software verication; Software evolution;
Keywords
Formal Verication, Evolving Software, Relational Logic,
Partial Models.
1. INTRODUCTION
Formal specication languages and the corresponding anal-
ysis environments have long been applied to a variety of
software engineering problems. Most notably, the Alloy lan-
guage and the corresponding analysis engine, Alloy Ana-lyzer [23], have received a lot of attention in the software
engineering community. Alloy provides a lightweight object
modeling notation that is especially suitable for modeling
structural properties of a software system. It has been used
to solve a variety of software engineering problems, includ-
ing software design [12,13,15,24], code analysis [8,9,33,41],
and test case generation [26, 30]. Given a model of a soft-
ware system in Alloy, the Alloy Analyzer uses a SAT solver
to automatically analyze the software system's properties,
specied in the form of predicates and formulas.
Formal specications have much in common with the com-
plex software systems they represent; namely they are hard
to develop and tend to evolve. Construction of formal
specications is a non-trivial task. Just like most complex
software systems, formal specications are developed iter-
atively [17], where in each iteration some elements of the
model are modied, removed, and new ones are added, until
the desired delity is achieved. In each iteration, the spec-
ication is analyzed to help the developer assess its utility,
x aws, and plan the next set of changes.
In addition, as software systems tend to evolve over time,
formal specications representing them need to evolve as
well. The evolution of specications, however, is not limited
to those that are constructed manually. In fact, automated
means of generating formal specications from software ar-
tifacts [11,16,26,33,35,41], often through some form of pro-
gram analysis, have made it signicantly easier to maintain
an up-to-date specication for a changing software system.
Such techniques have made it possible to verify an evolving
specication of a software system, after the initial deploy-
ment of software, possibly at runtime, and as it changes.
In such settings, the evolving specication is continuously
analyzed in real-time to assess the properties (e.g., secu-
rity [8,9,33]) of the corresponding software.
In spite of its strengths, Alloy Analyzer's reliance on com-
putationally heavy SAT solvers means that it can take a sig-
nicant amount of time to verify the properties of software.
The ability to analyze the specications eciently is quite
important, especially when they are developed through an
iterative process. The development of a complex specica-
tion often involves repeated runs of the analyzer for debug-
ging and assessment of its semantics. In an online mode,
where the specications are kept in sync with the chang-
ing software, and the analysis is performed at runtime, the
time it takes to verify the properties of software is of even
greater importance. There is, thus, a need for mechanisms
that facilitate ecient analysis of evolving specications in
response to incremental changes. An opportunity to reduce
the analysis time is presented by the fact that in the afore-
mentioned scenarios, specications are unlikely to change
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proï¬t or commercial advantage and that copies bear this notice and the full citation
on the ï¬rst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciï¬c permission and/or a
fee. Request permissions from Permissions@acm.org.
FSEâ€™16 , November 13â€“18, 2016, Seattle, WA, USA
c2016 ACM. 978-1-4503-4218-6/16/11...$15.00
http://dx.doi.org/10.1145/2950290.2950337
27
completely from one analysis to the next. It is, therefore,
desirable to be able to leverage the results of analysis per-
formed on a specication to optimize any subsequent anal-
yses on its revisions. However, Alloy Analyzer, as well as
its other variants (e.g., Aluminum [34]), do not provide any
mechanism to leverage the results of analysis across evolving
specications, even if they are substantially overlapping.
In this paper, we introduce Titanium, an extension of Al-
loy Analyzer for ecient analysis of evolving Alloy speci-
cations. The eciency gain is due to a new method of
determining the analysis bounds. In the conventional Alloy
Analyzer, the user-dened bounds used to run the analysis
determine the scope of search for models within a nite do-
main. The user-dened bound, however, is typically not the
tightest bound for a problem. The tightest bound for a prob-
lem is eectively determined when all model instances are
found. While this observation by itself is of little value when
analyzing an Alloy specication from scratch, it is quite valu-
able when the analysis is targeted at evolving, substantially
overlapping specications, and forms the intuition behind
our research.
Titanium rst analyzes the structure of a revised speci-
cation, and identies a set of relational variables that are
shared with the originating specication. It then uses the in-
stances produced for the original specication to potentially
calculate tighter bounds for such relational variables in the
revised specication. By tightening the bounds, Titanium
reduces the search space, enabling the SAT solver to nd the
model instances at a fraction of time needed for the origi-
nal bounds. The experimental results show that, with the
proposed optimization, Titanium achieves signicant gains
in speed compared to the conventional Alloy Analyzer.
This paper makes the following contributions:
Ecient analysis of evolving specications. We pro-
pose a novel approach for analyzing evolving Alloy
specications that reduces the state space by adjust-
ing the analysis bounds, thereby achieving signicant
speed-ups.
Formal description. We formally describe the semantic
basis of this approach in terms of models specied in
relational logic, and demonstrate how it can be realized
atop an existing relational logic model nder, without
compromising soundness and completeness.
Implementation. We have realized the analysis tech-
nique by modifying the Alloy Analyzer environment,
resulting in a new version of the tool, which we have
made publicly available [4].
Experiments. We present empirical evidence of the
eciency gains using both Alloy specications found
in the prior work and those synthesized in a systematic
fashion.
The remainder of this paper is organized as follows. Sec-
tion 2 uses an illustrative example to describe the intuition
behind our technique as well as the necessary background.
Section 3 provides a formal description of our approach. Sec-
tion 5 presents our experimental results obtained in our anal-
ysis of both real and synthesized specications. Section 6 re-
views the related research. Finally, Section 7 concludes the
paper with a summary of our contributions and the avenues
of future research.1(a) a simple model of typing in Java
2abstract sig Typef
3 subtypes: setType
4g
5sigClass, Interface extends Typefg
6one sig Object extends Classfg
7sigInstancef
8 type: Class
9g
10fact TypeHierarchyf
11 // Object, root of subtype hierarchy
12 Type inObject.subtypes
13 // no self subtyping
14 not: Typejtint.^subtypes
15 // subtype at most one class
16 allt: Typejlone t.~subtypes & Class
17g
18pred Showf
19 some Class Object
20 some Interface
21g
22runShow for2 but 3 Type
1(b) an updated version of the model
2sigVariablef
3 holds: lone Instance,
4 type: Type
5g
6fact TypeSoundnessf
7 allv: Variablejv.holds.type inv.type
8g
Listing 1: Alloy specication examples: (a) a
specication describing Java typing and (b) new
constructs added to the revised specication.
2. ILLUSTRATIVE EXAMPLE
This section motivates our research and illustrates our op-
timization technique using a simple example. We describe
the example using the Alloy [6] and Kodkod notations [43].
Section 3 presents a more detailed discussion of our ap-
proach.
Consider the Alloy specication for a simplied model of
typing in Java, shown in Listing 1. This specication is
adopted from [6], and distributed with the Alloy Analyzer.
Each Alloy specication consists of (1) data types, (2) for-
mulas that dene constraints over data types, and (3) com-
mands to run the analyzer. Essential data types are specied
in Alloy by their type signatures ( sig), and the relationships
between them are captured by the the declarations of elds
within the denition of each signature. The running exam-
ple denes 5 signatures (lines 2{9): Types are partitioned
into Class and Interface types, with Object introduced as a
singleton extending Class. Each Type may have a set of
subtypes , and each Instance has a specic Class type.
Facts ( fact) are formulas that take no arguments, and de-
ne constraints that every instance of a specication must
satisfy, thus restricting the instance space of the specica-
tion. The formulas can be further structured using pred-
icates ( pred) and functions ( fun), which are parameterized
formulas that can be invoked. The TypeHierarchy fact para-
graph (Listing 1, lines 10{17) states that Object is the root
281fT1 , T2 , O1 , I1 , I 2 g
2
3Object : ( 1 , 1 ) : : ffO1g,fO1gg
4C l a s s : ( 0 , 2 ) : : ffg,ffT1g,fT2ggg
5I n t e r f a c e : ( 0 , 2 ) : : ffg,ffT1g,fT2ggg
6I n s t a n c e : ( 0 , 2 ) : : ffg,ffI 1g,fI 2ggg
7s u b t y p e s : ( 0 , 9 ) : : ffg,ffO1 , O1 g,fO1 , T1 g,fO1 , T2 g,fT1 , O1 g,fT1 , T1 g,fT1 , T2 g,fT2 , O1 g,fT2 , T1 g,fT2 , T2 ggg
8type : ( 0 , 6 ) : : ffg,ffI1 , O1 g,fI1 , T1 g,fI1 , T2 g,fI2 , O1 g,fI2 , T1 g,fI2 , T2 ggg
9
10(a l l t : Object + C l a s s + I n t e r f a c e j! ( t i n( t . ^ s u b t y p e s ) ) ) && . . .
11// ||||||||||||||||||||||||||||||||||||||||||
12// The upper bound for the subtypes relation in the updated specication is tightened by Titanium:
13s u b t y p e s : ( 0 , 4 ) : : ffg,ffO1 , T1 g,fO1 , T2 g,fT1 , T2 g,fT2 , T1 ggg
Listing 2: Kodkod representation of the Alloy module of Listing 1.
of the subtype hierarchy; that no Type is a subtype of itself
(neither directly nor indirectly); and that each Type may be
a subtype of at most one Class.
Analysis of specications written in Alloy is completely
automated, but bounded up to user-specied scopes on the
size of data types. In particular, to make the state space
nite, certain scopes need to be specied that limit the num-
ber of instances of each type signature. The runspecication
(lines 18{22) then asks for model instances that contain at
least one Interface and one Class distinct from Object, and
species a scope that bounds the search for model instances
with at most two elements for each top-level signature, ex-
cept for Type bounded to three elements.
In order to analyze such a relational specication bounded
by the specied scope, both Alloy Analyzer and Titanium
then translate it into a corresponding nite relational model
in a language called Kodkod [43]. Listing 2 partially shows
a Kodkod translation of Listing 1(a). A model in Kodkod's
relational logic is a triple consisting of a universe of elements
(also called atoms ), a set of relation declarations including
their lower and upper bounds specied over the model's uni-
verse, and a relational formula, where the declared relations
appear as free variables [43].
The rst line of Listing 2 declares a universe of ve un-
interpreted atoms.1In this section, we assume an interpre-
tation of atoms, where the rst two ( T1and T2) represent
Type elements, the next one ( O1) an Object element, and
the last two ( I1andI2) Instance elements.
Lines 3{8 declare relational variables. Similar to Alloy,
formulas in Kodkod are constraints dened over relational
variables. While in Alloy these relational variables are sep-
arated into signatures , that represent unary relations estab-
lishing a type system, and elds , that represent non-unary
relations, in Kodkod all relations are untyped, with no dif-
ference between unary and non-unary relational variables.
Kodkod further allows specifying a scope over each re-
lational variable from both above and below by two rela-
tional constants . In principle, a relational constant is a pre-
specied set of tuples drawn from a universe of atoms. These
two sets are called upper and lower bounds, respectively.
Every relation in a model instance must contain all tuples
in the lower bound, and no tuple that is not in the upper
bound. That is, the upper bound represents the whole set
of tuples that a relational variable may contain, and a lower
bound a partial solution for a given model.
1Abbreviated atom names are chosen for readability, and do
not indicate type, as in Kodkod all relations are untyped.// model instance 1
Object : ffO1gg
C l a s s : ffT1gg
I n t e r f a c e : f fT2gg
I n s t a n c e : ffgg
s u b t y p e s : ffO1 , T2 g,fT2 , T1 gg
type : ffgg
// model instance 2
Object : ffO1gg
C l a s s : ffT1gg
I n t e r f a c e : f fT2gg
I n s t a n c e : ffI 1g,fI 2gg
s u b t y p e s : ffT2 , T1 g,fO1 , T1 gg
type : ffI1 , T1 g,fI2 , T1 gg
Listing 3: Two arbitrarily selected instances for the
specication of Listing 1(a).
Consider the Object declaration (line 3), its upper and
lower bounds both contain just one atom, O1, as it is dened
as a singleton set in Listing 1. The upper bound for the
variable subtypesTypeType (line 7) is a product of
the upper bound set for its corresponding domain and co-
domain relations, taking every combination of an element
from both and concatenating them.
The Kodkod's nite model nder then explores within
such upper and lower bounds dened for each relational
variable to nd instances of a formula, which are essentially
bindings of the formula's relational variables to relational
constants in a way that makes the formula true. Listing 3
shows two dierent instances for the specication of List-
ing 1(a). A model instance can essentially be viewed as an
exact bound , where the upper and lower bounds are equal.
After analyzing the specication, both Alloy Analyzer and
Titanium produce the same instance set comprising 72 mod-
els (including symmetries), through enumerating all valid in-
stances, in relatively the same amount of time, i.e., 421 and
419 ms, respectively. However, if the specication were to
change, Titanium would leverage the instances produced for
the original specication to potentially set a tighter bound
for the shared relational variables, which in turn reduces the
size of the state space, and improves the analysis time.
Figure 1 shows a simplied, schematic view of the Tita-
nium approach, using an example consisting of 5 relational
variables. As shown in Figure 1(a), the user-dened bounds
scope the state space in the analysis of original specication.
29(a)
 (b)
 (c)
Figure 1: Simplied, schematic view of the Titanium approach, where the dimensions represent relational variables,
in this case ve hypothetical relational variables R1, R2, R3, R4 and R5: (a) user-dened bounds for the original
specication, (b) instance set for the original specication, and (c) tightened bounds for the relations that remain
unaected in the revised specication, i.e., R1, R2 and R3.
Each relational variable can be assigned a value within the
user-dened bounds. A value assignment to all relational
variables in such a way that do not violate constraints de-
rived from the specication represents a satisfying model
instance, and depicted as a pentagon in Figure 1b. The
key observation is that once the satisfying model instances
are found, we are able to tighten the bounds for a given
specication, such that the same specication, or one that
is substantially the same, can be solved signicantly faster.
Figure 1(c) shows a situation in which the revised specica-
tion does not aect R1, R2, and R3, and thus Titanium is
able to set tighter bounds than those specied by the user
for those relations. Of course, changed relations and those
newly added or aected by changed relations (R4' and R5'
in the case of this example) would maintain the user-dened
bounds for the analysis.
Consider Listing 1(b), for example, where a new signature
Variable is added, which may hold an Instance, and has a
declared Type. The additional fact paragraph then states
that each Instance held by a Variable should have types that
are subtypes of the Variable's declared Type.
Given the updated specication, this time Titanium lever-
ages the results of the previous run to set a tighter bound
for relational variables that have not been changed and have
no dependency on the other changed variables. In this par-
ticular example, the upper bound for the subtypes relation
in the updated model is tightened by Titanium (Listing 1,
lines 12{13). Out of 9 possible combination of TypeType
elements, just 4 pairs are valid, as the Object element ( O1)
is the root in the subtype hierarchy (line 11), and it can-
not be a subtype for the other Type elements ( T1andT2).
This can be easily calculated by taking the union of satisfy-
ing model instances from the previous run. The exploration
space thus would be reduced. As a result, Titanium is faster
in nding a model instance, taking 51 ms for it compared to
275 ms that it takes for Alloy Analyzer to produce the rst
model instance. The time required to compute the whole
instance set would also improve from 1574 ms to 1099 ms,
in this simple example.
3. APPROACH
Editing an Alloy specication produces a new nite re-lational specication, i.e., a Kodkod problem, with nitely
many distinct model instances. In this section, we show
how solutions for the original specication can potentially
be used to narrow the exploration space of the revised spec-
ication, and in particular, whether they constitute a partial
solution, i.e., a lower bound, and/or a (partial) upper bound
for variables in the new specication.
Our algorithm is described in two steps. First, we assume
that the set of relations for the two models are equal. We
then discuss the general algorithm where the universe of
discourse, including relations, may change.
3.1 Basic Reasoning
Denition 1 (instance set) .Let i be a model instance sat-
isfying the model specication S,ij=S. We callI(S)an
instance set for a model specication S, where each model
instance i2I(S)satises the model specication S:
I(S) =fiji2I(S)^ij=Sg)
Denition 2 (model specialization) .LetSandS0be model
specications dened over the same set of relational vari-
ables. We saySis a specialization of S0,S S0, if and
only if each model in the instance set of Sis also a model
instance forS0,I(S)I(S0).
Four dierent scenarios are possible, depending on the
model specialization relation between instance sets of the
two specications:
Superset :SS0, where the instance set of the re-
vised specication includes the original specication's
instance set.I(S) thus constitutes the lower bound for
relations inS0, as each model instance for Sis also a
valid instance for S0. They essentially represent a pri-
ori known part, i.e., a partial instance, for the changed
model specication, S0, reducing the scope of the SAT
problem to be solved to nd potentially new instances,
and thereby improving performance of the analysis.
Subset :S0S, where the instances of the revised
specication are contained in the original specica-
tion's instance set. I(S) thus constitutes the upper
bound for relations in S0, as each model instance for
30S0is among model instances already found by solving
S, relieving the need to be rediscovered.
Equivalent :SS0^S0S, where a set of model
instances forS0is equivalent to that of the model S,
orI(S) =I(S0).
Arbitrary : No specialization relation exists, thus no
eciency gains are possible for the analysis of speci-
cationS0.
Note that when the user specied scope has been increased
in the analysis of the revised specication, Titanium is still
able to adjust the lower bound, but not the upper bound.
We can then reduce the problem of model specialization to
the following propositional formula [42], where P(S) denotes
the propositional formula for a model S:
P(S)P(S0)(P(S))P(S0)) (1)
Intuitively, it states that all satisfying solutions to P(S)
are solutions toP(S0), or more formally, the set of model
instances forP(S) is a subset of the instance set of P(S0),
I(P(S))I(P(S0)), if and only if P(S) implies P(S0).
Note that nite relational models can be represented as
propositional models using standard techniques [19, 23, 43].
Indeed, the Alloy Analyzer relies on Kodkod [43] that trans-
lates specications in Alloy's relational logic into proposi-
tional formulas, which then can be solved by o-the-shelf
SAT solvers. Specically, a relational model, S, in Kodkod
translates into a formula, P(S), in propositional logic. There
is a one-to-one correspondence between a relational model,
S, and its counterpart propositional model, P(S), notwith-
standing the peripheral variables introduced as a byproduct
of the translation process. The relationship between a model
specication and its correspondence model instances dened
above for propositional models are thus preserved for nite
relational models under this mapping.
For each pair of specications Sand its revisionS0, we
can check whether any model specialization holds between
them with a SAT solver, by determining whether the for-
mula P(S))P(S0) is a tautology (i.e., whether its negation
is not satisable). However, solving the negation formula
P(S)^:P(S0) can be expensive for large specications of
substantial systems. To alleviate this problem and render
it more cost-eective, we adjusted the formula by leverag-
ing the fact that the two specications have many clauses
in common, as one is derived from the other. Specically,
inspired by Th um et al. [42], we state P(S) and P(S0) as
follows:
P(S) =pS^c (2)
P(S0) =pS0^c (3)
where pSandpS0denote the conjunction of clauses exclu-
sive toP(S) andP(S0), respectively, and c the common
clauses. Because pS^c^:cis a contradiction, the formula
P(S)^:P(S0) = (ps^c^:ps0)_(ps^c^:c) then can be
rendered as:
P(S)^:pS0 (4)
The formula can be further simplied as a disjunction of
several easier to solve formulas, each one is represented as
as a conjunction of P(S) and a sub-expression in the CNF
representation of pS0. Specically, consider pS0with theAlgorithm 1: ExtractBase
Input: F:formulas; R :relations
Output:hbRelations; bFormulas i
1bFormulas fg
2bRelations fg
3forformula2Fdo
4 rels=getRelationalV ars (formula )
5 ifrelsRthen
6 bFormulas bFormulas[formula
7 bRelations bRelations[rels
8 end
9end
10returnhbRelations; bFormulas i
CNF representation of pS0
1^pS0
2^:::^pS0n. The formula
P(S)^:pS0then equals:
_
16i6nP(S)^:pS0
i(5)
The problem of categorization of model changes per our
specialization denition is now reduced to a disjunction
of several sub-expressions, where each one is signicantly
smaller and easier to solve than the original formula. In-
stead of calling a SAT solver to determine satisability of
a rather large formula, we can use multiple calls to a SAT
solver, posing a more tractable sub-expression each time. If
any sub-expression determines to be satisable, the entire
model specialization evaluates to false, possibly before rea-
soning about all sub-expressions, further improving the ef-
fectiveness of the approach. Moreover, except for one clause
(pS0
i), multiple calls to a SAT solver solve exactly the same
formula. This enables leveraging the incremental solving
capabilities featured in many modern SAT solvers to make
subsequent runs more ecient (each sub-expression is mod-
eled as a separate addition of new constraints, pS0
i, to an
already solved formula, P(S)).
3.2 Extended Reasoning
In the following, we present our general approach for sit-
uations where both Alloy specications are not dened over
the same set of relational variables, i.e., relational variables
may be added or removed as a result of the specication
modication.
Our approach leverages declarative slicing [47], which is a
program slicing technique applicable to analyzable declara-
tive languages. Declarative slicing partitions a declarative
formula specication, such as Alloy and Kodkod, into two
slices of base and derived , where each slice is a disjoint sub-
set of the formula constraints. A base slice is dened by
a set of relational variables, called slicing criterion , to be
constrained by the formula constraints specied in the base
slice, and an instance of which represents a partial solution
that can be extended by an instance of a derived slice for
the entire specication.
More formally, let S=hR; Fibe a specication, consist-
ing of a set of relational variables Rand a set of relational
formulas, F, dened over R. Let Sb:rRandSd:rR
partition R, and Sb:fFbe the formulas that only involve
relations in Sb:r. We call Sb:ra base slice forSif and only
if:
31Algorithm 2: Superset
Input: F:S0:formulas; R :S:relations\S0:relations
Output: lb//adjusted lower bound set
1hbRelations; bFormulas i ExtractBase (F; R)
2lb S0:lb
3ifbFormulasS:formulas then
4 forr2bRelations do
5 lb(r) T
i2I(s)i:val(r)
6 end
7end
8return lb
Algorithm 3: Subset
Input: F:S:formulas; R :S:relations\S0:relations
Output: ub//adjusted upper bound set
1hbRelations; bFormulas i ExtractBase (F; R)
2ub S0:ub
3ifbFormulasS0:formulas then
4 forr2bRelations do
5 ub(r) S
i2I(s)i:val(r)
6 end
7end
8return ub
8ib2I(Sb)j9id2I(Sd): ibid2I(S) (6)
To derive a base slice from the revised specication in a
way that its relations are shared with those of the original
specication, we use a constraint partitioning algorithm.
Algorithm 1 outlines the partitioning process. It gets as
input a set of relational variables, R, and a set of relational
formulas, F. Without loss of generality, we assume that Fis
a conjunction of several sub-formulas, i.e., F=^formulas .
As an example, the formula in Listing 2, line 10, repre-
sents this form for the constraints specications in our run-
ning example (Listing 1). The algorithm then iterates over
each such sub-formulas, extracts the set of relational vari-
ables, rels, constrained by the given formula, and evaluates
it against the given set of relational variables, R. If the for-
mula's variable set, rels, is a subset of R, it is added to the
formulas in the base slice, bFormulas , and relsto the base
slice relation set, bRelations , whose bounds will potentially
be adjusted.
As a result of calling ExtractBase with the formulas of a
specication and the shared relational variables of another
specication, the algorithm produces a bases slice. We thus
can reason about and update the bounds of the revised spec-
ication base slice according to the model specialization re-
lations described in Section 3.1.
Algorithm 2 computes the lower bound for the superset
scenario outlined in Section 3.1. It rst calls ExtractBase
with a a set of relational formulas dened in S0and a set of
relational variables shared between the two specications as
inputs. Note that the base slice relation set, bRelations , is
a subset of those relations shared between the two speci-
cations, and they are not necessarily equal. The algorithm
then evaluates a set of formulas in the base slice against
those specied in S. If the extracted formulas form a subset
ofS:formulas , that means Sbaseis a model specializationofS0
base, orSbaseS0
base, as formula (1) is a tautology.
The instance set of Sbasethus constitutes the lower bound
for the corresponding relational variables in S0. Recall from
Section 2 that a lower bound for a relational variable repre-
sents the tuples that the variable must contain. The inter-
section of values assigned to a relation in all instances thus
constitutes a lower bound for that relational variable.
Algorithm 3 computes the upper bound for the subset sce-
nario outlined in Section 3.1. It rst calls ExtractBase with
a set of relational formulas dened in Sand a set of re-
lational variables shared between the two specications as
inputs, because this time we want to see whether S0
baseis a
model specialization of Sbase. It then evaluates a set of for-
mulas in the base slice against those specied in S' (rather
than S as done in Algorithm 2). If the extracted formulas
is a subset of S0:formulas , that means S0
baseSbase. The
instance set of Sbasethus constitutes the upper bound for
their corresponding relational variables in S0. Recall that an
upper bound for a relational variable represents the tuples
that a relational variable may contain. The union of values
assigned to a relation in all instances thus constitutes an
upper bound for that relational variable.
Finally, in the case of equivalent relation (recall Sec-
tion 3.1), both upper and lower bounds need to be tightened.
In essence, the equivalent relation implies the existence of
both superset and subset relations (i.e., SS0^S0S).
Titanium calculates the bounds for equivalent relations by
making consecutive calls to Algorithms 2 and 3.
Titanium, similar to Alloy, is both sound and complete for
the given bounds, yet more ecient for analysis of evolving
specications. Space constraints prevented us from includ-
ing a proof. But they follow naturally from the algorithms in
Section 3.2 and the discussions, backed with mathematical
notations in Section 3.1.
Note that because the problem of reasoning about Alloy
model edits has been reduced to a satisability problem, as
presented in Section 3.1, it could still have an exponential
run-time in the worst case. Therefore, in the implementation
(line 4 in Algorithms 2 and 3), we have taken a computa-
tionally eective approach, in which whenever pS0
iin for-
mula (5) is not equal to true, we conclude that the formula
P(S))P(S0) is not a tautology, and skip the adjustment
of the corresponding bound (either lower or upper). In the
next section, we evaluate the execution time of our algo-
rithm empirically and show that the proposed optimization
technique achieves signicant improvement compared to the
Alloy Analyzer.
4. TOOL IMPLEMENTATION
We have implemented Titanium as an extension to the
Alloy relational logic analyzer. To implement the algo-
rithms presented in the previous sections, Titanium modies
both the Alloy Analyzer and its underlying relational model
nder, Kodkod [43]. The dierences between Alloy Analyzer
and Titanium lie in the translation of high-level Alloy mod-
els into low-level bounded relational models, and the facility
to eectively determine the scopes of the updated models
given the instance set of the original specication. The Ti-
tanium tool is publicly available at the project website [4]
5. EXPERIMENTAL EV ALUATION
This section presents the experimental evaluation of Tita-
nium. Our evaluation addresses the following research ques-
tions:
32Table 1: Results for publicly available and automatically extracted Alloy specications.
Alloy Analyzer 4.2 Titanium
Specication #Rels Vars ClausesAnalysisVars ClausesAdj. Analysis
Time (S) Time (S) Time (S)
Decider 47 2,384 3,526 2.549 1,819 2,657 0.507 0.533
Wordpress 54 2,419 3,479 3.718 1,385 1,615 0.245 1.198
Moodle 39 1,054 1,477 2.370 1,034 1,453 0.014 1.598
Ecommerce 70 3446 4705 5.462 1,618 1,682 0.133 0.711
DBLP 80 385 498 1.967 279 352 0.507 1.174
Library 78 254 341 7.411 129 177 0.616 0.510
Coach 86 275 369 0.260 21 24 0.032 0.031
WebML 47 122 178 0.738 119 172 0.050 0.592
GMF Graph 36 350 439 6.186 186 223 0.275 2.488
App Bundle 1 1,288 1,570,839 79,332,736 427.405 5,589 11,822 11.344 16.202
App Bundle 2 1,313 1,874,758 81,500,102 673.887 5,690 12,657 11.070 25.052
App Bundle 3 1,175 1,233,843 63,408,733 168.225 4,835 10,278 10.461 4.235
App Bundle 4 1,064 1,195,927 49,633,639 242.387 4,756 10,082 8.788 8.431
App Bundle 5 1,185 1,454,029 55,447,247 451.082 5,360 11,489 10.990 17.527
RQ1 What is the performance improvement achieved
by Titanium's incremental analysis compared to Alloy
Analyzer?
RQ2 What is the overhead of Titanium? How does the
Titanium's overhead relate to the size of the original
instance set?
RQ3 How do the eciency gains in Titanium relate
to the extent of change in the specication?
Our experimental subjects are Alloy specications drawn
from a variety of dierent sources and of dierent problem
domains. These specications further vary much in terms
of size and complexity. We have compared the performance
of Titanium to that of the Alloy Analyzer (version 4.2) on
three sets of specications:
Publicly available Alloy specications. We used sev-
eral Alloy specications taken from the work of other
researchers that were publicly available [11,15].
Extracted specications. We used several specications
extracted automatically by various analysis techniques
that leverage Alloy for analysis of real-world software
systems [9,29].
Automatically synthesized specications. We devel-
oped a tool for generating a large number of synthe-
sized Alloy specications.
The complete list of subject systems and their specica-
tions are available from the project website [4].
5.1 Improvements in Practice
For an initial evaluation, we wanted to assess the kinds
of improvement one could expect in practice. We thus used
several Alloy specications that were either publicly avail-
able or automatically extracted from real-world software sys-
tems, as shown in Table 1.
Decider [2] is an object model of a system to support de-
sign space exploration. Its model contains 10 Classes, 11
Associations, and 5 inheritance relationships, all represented
as signature extensions in Alloy.
WordPress and Moodle are object models from two open-
source applications, obtained by reverse engineering their
database schemas. The WordPress model, which is an opensource blog system [5], includes 13 classes connected by 10
associations with 8 inheritance relationships. Moodle is a
learning management system [3], widely used in colleges and
universities. Its model has 12 classes connected by 8 associ-
ations and consists of 4 inheritance relationships.
Ecommerce is the object model of an E-commerce sys-
tem adopted from Lau and Czarnecki [27], that represents
a common architecture for open source and commercial E-
commerce systems. It has 15 classes connected by 9 associ-
ations with 7 inheritance relationships.
The next ve specications, i.e., DBLP, Library, Coach,
WebML, GMF Graph, are class diagrams automatically
transformed into Alloy specications by the CD2Alloy ap-
paratus [29]. The selected class diagrams are all publicly
available, taken from dierent sources, and previously pub-
lished as case studies and research papers in the area of UML
analysis.
Finally, the last ve rows represent large specications in-
tended for the assessment of security properties in mobile
platforms. Each one represents a bundle of Android apps
installed on a mobile device for detecting security vulnera-
bilities that may arise as a result of inter-application com-
munication, adopted from [1].
For some of the specications whose change histories were
available, we actually used dierent versions of the specica-
tion, which had been manually developed or automatically
extracted at dierent times. For others, we made three to
ve changes to each specication, such that the updated
specications still had valid model instances. We used a PC
with an Intel Core i7 2.4 GHz CPU processor and 8 GB of
main memory, and leveraged SAT4J as the SAT solver to
keep the extraneous variables constant during all the exper-
iments. We then compared the performance of Titanium to
that of the Alloy Analyzer (version 4.2) in all these revised
specications.
The results are provided in Table 1. The table shows the
number of relations for each specication, the size of the
generated CNF, given as the total number of variables and
clauses, the analysis time taken for the model nder, as well
as the overhead time taken by Titanium for adjusting the
analysis bounds. As shown, for some experiments, the size
of CNF variables generated by Titanium is less than those
generated by Alloy. This is because relations with exact
bound, that essentially represent partial instances, do not
33need to be translated into a SAT formula, thus reducing the
size of the generated CNF.
The results demonstrate the eectiveness of our algorithm,
as in every case, and for every update, the analysis time
taken by Titanium for computing the instance set of modi-
ed specications is less than that of using the Alloy Ana-
lyzer. However, we can also see that the results could vary
greatly, because the improvements could depend on several
factors, most notably the amount of change, and the size of
instance set. This called for further evaluation to determine
how such variations aect the eciency gains, as described
next.
5.2 Efï¬ciency vs. Size of Instance Set
Since in Titanium we use the instance sets from the prior
run to tighten the bounds for the next run, we expect the
eciency gains to be more pronounced in cases with larger
instance sets. In this set of experiments, we attempted to
corroborate our intuition and obtain empirical evidence of
this relationship. Since we needed access to a large number
of Alloy specications and their revisions, we developed a
tool for generating synthesized Alloy models.
Independent variables in our experiments are (a) the size
of an Alloy model, represented as the total number of signa-
tures and elds, as both are indeed translated into relations
in the underlying relational logic, (b) the number of update
operations, and (c) the type of update operations. As depen-
dent variables, we measured the time needed to update the
bounds and the time needed to determine the instance set
for the updated model. We discarded all synthesized Alloy
specications that do not have any valid model instances,
and repeated the entire process until the appropriate num-
ber of models were generated. In the following, we describe
the approach taken for synthesis of Alloy specications and
their revisions.
Alloy specication synthesis. Our tool for synthesiz-
ing Alloy specications takes as input ranges for the size of
signatures, elds, and formulas and generates an Alloy spec-
ication as follows. It starts with the top-level signatures,
which are signatures that are declared independent of any
other signature and do not extend another signature. A top-
level signature may also be dened as an abstract signature,
meaning that it has no elements except those belonging to
its extensions, or dened as a nonempty signature. The gen-
erator then iterates over the set of top-level signatures, and
adds sub-signatures. Within the same iteration, singleton
signatures|that contain a single element|are also added.
In the next step, elds are added as multi-relations (in ad-
dition to signatures that represent unary relations), whose
domains and ranges are given by the already dened signa-
tures.
The last part of the generated module is a set of con-
straints in a freestanding fact paragraph. The constraints
are generated using formula templates that cover operators
dened in the Alloy core language [6], including subset and
equality operators in comparison formulas, conjunction and
universal quantication formulas, and some binary (union
(+), intersection (&), join (.) and product ( {>)) and unary
(transpose () and transitive closure (^)) expressions. Note
that the other types of Alloy formulas, such as existential
quantication and disjunction, can be derived from the core
language the generator supports. As a concrete example of
a synthesized specication, Listing 4 shows an Alloy speci-
cation automatically generated, given 6, 5, and 4 as the size
of signatures, elds and constraint formulas, respectively.a b s t r a c t s i g A0 f
f 3 : some (A3 + A1)
g
s i g A1 f
f 0 : one A0
g
s i g A2 extends A0 f g
one s i g A3 f
f 1 : some A2 ,
f 4 : one A4
g
s i g A4 f g
one s i g A5 extends A2 f
f 2 : l o n e A0
g
f a c t f
(a l l o : A5 jsome o . ( A5 <: f 2 ) )
(a l l o : A3 j# o . ( A3 <: f 1 ) <= # o . ( A3 <: f 4 ) )
# A5 = # A1
# A2 = 3
g
pred show fg
run show f o r 4
Listing 4: An automatically generated Alloy
specication.
Figure 2: Analysis time for bound adjustment over the
size of the original specication instance set.
Revised specication synthesis. To produce an up-
date for an Alloy model, our generator takes as input an
Alloy model and the number of edits. It supports the fol-
lowing edit operations on the Alloy models:
create or delete a signature without children;
change the signature multiplicity2, i.e., to set,one,lone
orsome (one that is dierent from the multiplicity de-
ned in the original specication);
make an abstract signature non-abstract or vice versa;
move a sub-signature to a new parent signature;
add a new eld to a signature declaration or delete a
eld;
change a multiplicity constraint in a eld declaration;
nally, create a new constraint or delete a constraint.
2A signature multiplicity constrains the size of a set corre-
sponding to that signature type.
34Figure 3: Performance comparison: Analysis time taken
for Alloy Analyzer and Titanium vs. the size of the in-
stance set.
While the rst six types of edits revise relations in the
specication, the last one modies the specication's formu-
las. The generation and execution of Alloy models and their
updates are done using Alloy's APIs.
Experimental Results. We ran the generator with pa-
rameters specifying the size of signatures, elds, and formu-
las varying in the ranges of 5{15, 5{10, and 5{10, respec-
tively. The number of edits to create a revised specication
ranged from 1 to 7. For each edit, one of the 7 types of op-
eration was randomly selected and applied. We generated
500 original specications, and another 500 corresponding
revised specications, for a total of 1,000 specications.
Figure 2 shows the boxplots of the analysis time for bound
adjustment over the varying size of instance sets for the orig-
inal specications. According to the diagram, the execution
time increases roughly linearly with the size of instance sets,
and for a space of size 224,856, it takes just about 7.1 sec-
onds for Titanium to produce an adjusted bound set, show-
ing that the Titanium approach is eective in practice on
specications with large-scale instance sets.
We then compared performance of Titanium with the Al-
loy Analyzer 4.2. In Figure 3, we show the results of our
measurements, comparing the analysis time taken by each
of the tools as boxplots with a logarithmic scale. On aver-
age, Titanium exhibited a 61% improvement over that of the
Alloy Analyzer. For specications with very small instance
sets, the dierence in performance of the two techniques is
negligible, yet the eects of adjusted bounds are clearly visi-
ble when the size of instance sets increases. As illustrated in
the diagram, the analysis time by the Alloy Analyzer grows
faster than the corresponding time for Titanium. In sum-
mary, Titanium is able to analyze the revised specications
in a fraction of time it takes to run Alloy Analyzer, and the
dierence in analysis time is more pronounced for the larger
instance sets, as we expected.
5.3 Efï¬ciency vs. Extent of Change
We then assessed how the eciency gains in Titanium re-
late to the extent of change. As a given specication diverges
from the original specication, and the shared variables and
formulas are reduced, the eciency gains are expected to
gradually diminish. In this set of experiments, we attempted
Figure 4: Percentage of average improvement vs. the
proportion of change for model specications of size 20
relations.
to corroborate this expectation, and to obtain an empirical
understanding of this relationship.
We generated a specication with a xed size of 20 re-
lations, and automatically revised the specication by ran-
domly applying the edit operators described in the prior sec-
tion on 1 to 10 of its relations, resulting in a revised speci-
cation with 5% to 50% change. We then measured the time
taken by both Alloy Analyzer and Titanium in analyzing the
revised specication. We repeated this experiment for 100
times. In this way, we were able to determine whether more
changes decrease the eciency gains in analysis achieved
through bound adjustments.
The boxplots in Figure 4 show the eciency gains of us-
ing Titanium over Alloy Analyzer. On average, for speci-
cations of size 20 relations, one can expect to obtain more
than 50% reduction in analysis time (compared to that of
the Alloy Analyzer) for up to 10% change in the speci-
cation. After that, the eciency achieved through bound
adjustments decrease, and for changes above 40% of speci-
cation, the improvements are reduced to less than 5%. Thus,
the extent to which edits can negatively aect Titanium's
eciency gains depends on the proportion of the original
specication that has changed.
6. RELATED WORK
Much work is related to this research. Here, we provide a
discussion of the related eorts in light of our research.
Alloy extensions. The widespread use of Alloy has
driven a number of extensions to the language and its under-
lying automated analyzer [31,32,34,45]. Certain techniques
have been developed for exploring model instances from Al-
loy's relational logic constraints [18, 28, 34, 39, 43]. Among
others, Aluminum [34] extends the Alloy Analyzer to gen-
erate minimal model instances. It relies on a procedure in
which tuples are iteratively removed from the tuple set of
found model instances until a minimal instance is reached.
Macedo et al. [28] studied the space of possible scenario ex-
plorations in the context of relational logic. This work, sim-
ilar to Aluminum [34], mainly focuses on the order in which
model instances are explored, rather than facilitating the ex-
ploration of the solution space for evolving models. Torlak
and Jackson introduced a heuristic, polynomial-time algo-
rithm to substantially exclude symmetric instances of rela-
tional models [44], given that such model instances present
no additional information. Identifying isomorphisms of rela-
35tional models has no known polynomial-time solution. Mon-
taghami and Rayside [31] extended Alloy to explicitly sup-
port specication of partial models. However, this research
eort does not consider the analysis of evolving specica-
tions. Indeed, it is commonly acknowledged that develop-
ment of ecient techniques for the analysis of Alloy speci-
cations is a much needed area of research [45]. However, to
the best of our knowledge, no prior research has attempted
to optimize the performance of analysis time for evolving
Alloy specications.
Incremental analysis. The other relevant thrust of
research has focused on incremental solving of constraints
specied in the rst-order logic [22, 46{48]. Among others,
Uzuncaova and Khurshid partitioned a model of constraints
into a base and derived slices, where solutions to the base
model can be extended to generate a solution for the en-
tire model [47]. Titanium is fundamentally dierent in that
the problem addressed by Uzuncaova and Khurshid is in the
context of a xed specication and the evolution of spec-
ication is not considered. Moreover, the two approaches
use declarative slicing for totally dierent purposes: In [47],
declarative slicing is used to prioritize constraints (to rst
analyze constraints with higher priorities). However, Tita-
nium uses declarative slicing to identify a base set of rela-
tions, the bounds of which can potentially be tightened in
the analysis of evolving specication. Ranger [40] uses a di-
vide and conquer method relying on a linear ordering of the
solution space to enable parallel analysis of specications
written in rst-order logic. While the linear ordering allows
for partitioning of the solution space into ranges, there is no
clear way in which it can be extended with incremental anal-
ysis capabilities, essential for analysis of evolving systems.
Eectively reducing the exploration space has been used
in a variety of forms to optimize bounded analysis tech-
niques [7,20,21,37]. Galeotti et al. [20,21] presented a tech-
nique, called TACO, that targets ecient analysis of JML-
specications for linked data structures, through translating
them into the Alloy language. TACO eliminates the values
that violate constraints introduced by class invariants via
adjusting only the upper bounds for the translated Alloy
elds. Titanium, however, is (1) a general solution, inde-
pendent of any particular domain, (2) capable of adjusting
both upper and lower bounds, and (3) aimed at ecient
analysis of any evolving Alloy specication. To the best of
our knowledge, Titanium is the rst, general solution that
supports analysis of evolving Alloy specications.
Optimization of other techniques relying on con-
straint solving. Related to our research are the applica-
tions of constraint solving techniques to software engineering
problems. Of particular relevance is symbolic execution of
software, which is a means of analyzing a program to de-
termine what inputs cause each part of a program to exe-
cute. A software program is rst abstractly interpreted to
identify a set of symbolic values for inputs and conditional
expressions, which when solved with the aide of a solver,
produce concrete values to exercise dierent branches of the
program. Similar to Alloy Analyzer, due to their reliance
on SAT solving engines, symbolic execution tools face scal-
ability problems. Substantial recent research has focused
on improving the performance of symbolic evaluation tech-
niques [25,36,49,50].
Some of these approaches [25,49] follow the general strat-
egy of storing and reusing previously solved constraints,
which result in less calls to the solver, thereby improving
the performance. But most closely related to our researchis regression symbolic execution [36, 38, 50], where one at-
tempts to co-analyze two program versions which are, often,
very similar. Here, the dierences between two versions of
a program are rst identied, and the new run of the sym-
bolic execution on the revised program is then only guided
through the regions of the program that have changed. Sim-
ilar to all of these approaches, Titanium aims to improve the
performance of analysis for Alloy specications. However, in
addition to targeting a dierent type of analysis (i.e., formal
specications rather than programs), it employs a dierent
technique that uses the previously calculated instances to
tighten the bounds on shared relational variables.
7. CONCLUSION
Alloy has found applications in a variety of software en-
gineering problems, from automated synthesis and explo-
ration of design alternatives [14, 15, 24] to analysis of pro-
grams [8,9,33,41] and generation of tests [26,30]. The devel-
opment of solutions for automatically extracting Alloy spec-
ications from software artifacts has made Alloy practical
for use even after the deployment of software, and possibly
at runtime [8, 10, 33]. Such applications of Alloy, however,
are challenged by the time it takes for an analysis to run,
especially given that the analysis may need to be repeated
frequently.
We presented an approach and an accompanying tool,
dubbed Titanium, that signicantly reduces the time it takes
to analyze evolving Alloy specications. While the approach
is particularly suitable in settings where a specication is
kept in sync with the changing software system, it could
also be as eective in settings where a specication is in-
crementally developed, often involving repeated analysis of
the specication to assess its semantics. Titanium is able
to achieve a signicant speed-up by tightening the analysis
bounds without sacricing soundness and completeness. It
rst identies the shared relational variables between two
versions of a given specication. It then uses the instances
produced for the original specication to determine a tighter
bound for the revised specication, thereby reducing the
state space, enabling the SAT solver to nd the model in-
stances for the revised specication at a fraction of time
needed for Alloy Analyzer. Our experimental results using
both real Alloy specications constructed in the prior work,
as well as synthesized Alloy specications, corroborate the
signicant performance gains achieved through Titanium.
While the results obtained so far are quite promising, we
believe further improvements are possible. Specically, in
spite of the adjustments made to the analysis bounds, the
solver still needs to solve for the shared constraints. A
promising avenue of future research is a memoization-based
approach, were the constraints solved in a prior analysis of
the model are stored, and retrieved as encountered in the
subsequent analyses. Such an approach would not eliminate
the need for adjusting the bounds for relational variables, as
some of those variables may be used in the derived speci-
cation.
We have made Titanium, as well as Alloy specications
and the model synthesizer used in conducting our experi-
ments, publicly available for use by other researchers [4].
8. ACKNOWLEDGMENT
The authors are grateful to Daniel Jackson for the discus-
sions regarding the initial idea of this work. We also thank
Tim Nelson for his help on Alloy's symmetry breaking.
369. REFERENCES
[1] Alloy models from the covert project.
http://www.sdalab.com/projects/covert.
[2] Alloy models from the trademaker project.
http://www.jazz.cs.virginia.edu:
8080/Trademaker/data/models.zip.
[3] Moodle. http:
//docs.moodle.org/dev/Grades#Database structures.
[4] Titanium. https://seal.ics.uci.edu/projects/titanium.
[5] WordPress.
http://codex.wordpress.org/Database Description/3.3.
[6]D. Jackson, Software Abstractions, 2nd ed. MIT
Press, 2012. MIT Press, 2012.
[7] P. Abad, N. Aguirre, V. Bengolea, D. Ciolek, M. F.
Frias, J. Galeotti, T. Maibaum, M. Moscato,
N. Rosner, and I. Vissani. Improving Test Generation
under Rich Contracts by Tight Bounds and
Incremental SAT Solving. In Verication and
Validation 2013 IEEE Sixth International Conference
on Software Testing , pages 21{30, Mar. 2013.
[8] H. Bagheri, E. Kang, S. Malek, and D. Jackson.
Detection of design aws in the android permission
protocol through bounded verication. In FM 2015:
Formal Methods , volume 9109 of Lecture Notes in
Computer Science , pages 73{89. 2015.
[9] H. Bagheri, A. Sadeghi, J. Garcia, and S. Malek.
COVERT: Compositional Analysis of Android
Inter-App Permission Leakage. IEEE Transactions on
Software Engineering , 41(9):866{886, Sept. 2015.
[10] H. Bagheri, A. Sadeghi, R. Jabbarvand, and S. Malek.
Practical, formal synthesis and automatic enforcement
of security policies for android. In Proceedings of the
46th IEEE/IFIP International Conference on
Dependable Systems and Networks (DSN) , pages
514{525, 2016.
[11] H. Bagheri and K. Sullivan. Monarch: Model-based
development of software architectures. In Proceedings
of the 13th ACM/IEEE International Conference on
Model Driven Engineering Languages and Systems
(MODELS) , pages 376{390, 2010.
[12] H. Bagheri and K. Sullivan. Bottom-up model-driven
development. In Proceedings of the International
Conference on Software Engineering (ICSE) , pages
1221{1224, 2013.
[13] H. Bagheri and K. Sullivan. Pol: Specication-Driven
Synthesis of Architectural Code Frameworks for
Platform-Based Applications. ACM SIGPLAN
Notices , 48(3):93{102, Mar. 2013.
[14] H. Bagheri and K. Sullivan. Model-driven synthesis of
formally precise, stylized software architectures.
Formal Aspects of Computing , 28(3):441{467, Mar.
2016.
[15] H. Bagheri, C. Tang, and K. Sullivan. Trademaker:
Automated dynamic analysis of synthesized
tradespaces. In Proceedings of the 36th International
Conference on Software Engineering , ICSE 2014,
pages 106{116, New York, NY, USA, 2014. ACM.
[16] H. Bagheri, C. Tang, and K. Sullivan. Automated
synthesis and dynamic analysis of tradeo spaces for
object-relational mapping. IEEE Transactions on
Software Engineering , 2016.
[17] J. Boyland, A. Sloane, X. Li, D. Shannon, J. Walker,
S. Khurshid, and D. Marinov. Analyzing the Uses of aSoftware Modeling Tool. Electronic Notes in
Theoretical Computer Science , 164(2):3{18, Oct. 2006.
[18] A. Cunha, N. Macedo, and T. Guimaraes. Target
oriented relational model nding. In Proc. of
International Conference on Fundamental Approaches
to Software Engineering , FASE'14, pages 17{31, 2014.
[19] J. Edwards, D. Jackson, E. Torlak, and V. Yeung.
Faster constraint solving with subtypes. In Proc. of
International Symposium on Software Testing and
Analysis , ISSTA'04, 2004.
[20] J. P. Galeotti, N. Rosner, C. G. Lopez Pombo, and
M. F. Frias. Analysis of invariants for ecient
bounded verication. In Proceeding of International
Symposium on Software Testing and Analysis ,
ISSTA'10, pages 25{36, 2010.
[21] J. P. Galeotti, N. Rosner, C. G. L. Pombo, and M. F.
Frias. Taco: Ecient sat-based bounded verication
using symmetry breaking and tight bounds. IEEE
Trans. Software Eng. , 39(9):1283{1307, 2013.
[22] S. Ganov, S. Khurshid, and D. E. Perry. Annotations
for alloy: Automated incremental analysis using
domain specic solvers. In Proc. of ICFEM , pages
414{429, 2012.
[23] D. Jackson. Alloy: a lightweight object modelling
notation. ACM Transactions on Software Engineering
and Methodology (TOSEM) , 11(2):256{290, 2002.
[24] D. Jackson, I. Shlyakhter, and M. Sridharan. A
micromodularity mechanism. In Proceedings of the 8th
European Software Engineering Conference Held
Jointly with 9th ACM SIGSOFT International
Symposium on Foundations of Software Engineering ,
ESEC/FSE-9, pages 62{73, New York, NY, USA,
2001. ACM.
[25] X. Jia, C. Ghezzi, and S. Ying. Enhancing reuse of
constraint solutions to improve symbolic execution. In
Proceedings of the 2015 International Symposium on
Software Testing and Analysis , ISSTA 2015, pages
177{187, New York, NY, USA, 2015. ACM.
[26] S. Khurshid and D. Marinov. Testera:
Specication-based testing of java programs using sat.
Automated Software Engineering , 11:2004, 2004.
[27] S. Q. Lau. Domain Analysis of E-Commerce Systems
Using Feature-Based Model Templates . Master's thesis,
University of Waterloo, Canada, 2006.
[28] N. Macedo, A. Cunha, , and T. Guimaraes. Exploring
scenario exploration. In Proc. of International
Conference on Fundamental Approaches to Software
Engineering , FASE'15, pages 301{315, 2015.
[29] S. Maoz, J. Ringert, and B. Rumpe. Cd2alloy: Class
diagrams analysis using alloy revisited. In Proceedings
of the 14th ACM/IEEE International Conference on
Model Driven Engineering Languages and Systems
(MODELS) , pages 592{607, 2011.
[30] N. Mirzaei, J. Garcia, H. Bagheri, A. Sadeghi, and
S. Malek. Reducing Combinatorics in GUI Testing of
Android Applications. In Proceedings of the 38th
International Conference on Software Engineering ,
ICSE '16, pages 559{570. ACM, 2016.
[31] V. Montaghami and D. Rayside. Extending alloy with
partial instances. In Proc. of ABZ , pages 122{135,
2012.
[32] V. Montaghami and D. Rayside. Staged evaluation of
partial instances in a relational model nder. In Proc.
of ABZ , pages 318{323, 2014.
37[33] J. P. Near and D. Jackson. Derailer: Interactive
security analysis for web applications. In Proceedings
of the 29th ACM/IEEE International Conference on
Automated Software Engineering , ASE '14, pages
587{598, New York, NY, USA, 2014. ACM.
[34] T. Nelson, S. Sagha, D. J. Dougherty, K. Fisler, and
S. Krishnamurthi. Aluminum: principled scenario
exploration through minimality. In Proc. of
International Conference on Software Engineering ,
ICSE'13, pages 232{241, 2013.
[35] J. Nijjar and T. Bultan. Bounded verication of ruby
on rails data models. In Proceedings of the 2011
International Symposium on Software Testing and
Analysis , ISSTA '11, pages 67{77, New York, NY,
USA, 2011. ACM.
[36] S. Person, G. Yang, N. Rungta, and S. Khurshid.
Directed incremental symbolic execution. In
Proceedings of the 32Nd ACM SIGPLAN Conference
on Programming Language Design and
Implementation , PLDI '11, pages 504{515, New York,
NY, USA, 2011. ACM.
[37] P. Ponzio, N. Rosner, N. Aguirre, and M. F. Frias.
Ecient tight eld bounds computation based on
shape predicates. In Proc. of International Symposium
on Formal Methods , FM'14, pages 531{546, 2014.
[38] D. Ramos and D. Engler. Practical, low-eort
equivalence verication of real code. In
G. Gopalakrishnan and S. Qadeer, editors, Computer
Aided Verication , volume 6806 of Lecture Notes in
Computer Science , pages 669{685. Springer Berlin
Heidelberg, 2011.
[39] N. Rosner, J. H. Siddiqui, N. Aguirre, S. Khurshid,
and M. F. Frias. Ranger: Parallel analysis of alloy
models by range partitioning. In Proc. of ASE , pages
147{157, 2013.
[40] N. Rosner, J. H. Siddiqui, N. Aguirre, S. Khurshid,
and M. F. Frias. Ranger: Parallel analysis of alloy
models by range partitioning. In Proceeding of the 28th
IEEE/ACM International Conference on Automated
Software Engineering (ASE) , pages 147{157, 2013.
[41] M. Taghdiri. Inferring specications to detect errors in
code. In Proceedings of the 19th IEEE InternationalConference on Automated Software Engineering , ASE
'04, pages 144{153, Washington, DC, USA, 2004.
IEEE Computer Society.
[42] T. Th um, D. Batory, and C. Kastner. Reasoning about
edits to feature models. In Proc. of International
Conference on Software Engineering , ICSE'09, 2009.
[43] E. Torlak. A Constraint Solver for Software
Engineering: Finding Models and Cores of Large
Relational Specications . PhD thesis, MIT, Feb. 2009.
[44] E. Torlak and D. Jackson. Kodkod: A relational
model nder. In Proceedings of the 13th International
Conference on Tools and Algorithms for the
Construction and Analysis of Systems , TACAS'07,
pages 632{647, Berlin, Heidelberg, 2007.
Springer-Verlag.
[45] E. Torlak, M. Taghdiri, G. Dennis, and J. P. Near.
Applications and extensions of alloy: past, present and
future. Mathematical Structures in Computer Science ,
23(4):915{933, 2013.
[46] E. Uzuncaova and S. Khurshid. Kato: A program
slicing tool for declarative specications. In Proc. of
International Conference on Software Engineering ,
ICSE'07, pages 767{770, 2007.
[47] E. Uzuncaova and S. Khurshid. Constraint
prioritization for ecient analysis of declarative
models. In Proc. of International Symposium on
Formal Methods , FM'08, 2008.
[48] E. Uzuncaova, S. Khurshid, and D. S. Batory.
Incremental test generation for software product lines.
IEEE Trans. Software Eng. , 36(3):309{322, 2010.
[49] W. Visser, J. Geldenhuys, and M. B. Dwyer. Green:
Reducing, reusing and recycling constraints in
program analysis. In Proceedings of the ACM
SIGSOFT 20th International Symposium on the
Foundations of Software Engineering , FSE '12, pages
58:1{58:11, New York, NY, USA, 2012. ACM.
[50] G. Yang, C. S. P as areanu, and S. Khurshid. Memoized
symbolic execution. In Proceedings of the 2012
International Symposium on Software Testing and
Analysis , ISSTA 2012, pages 144{154, New York, NY,
USA, 2012. ACM.
38