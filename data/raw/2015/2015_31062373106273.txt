Finding Near-Optimal Configurations in Product Lines by
Random Sampling
Jeho Oh, Don Batory, Margaret Myers
University of Texas at Austin
USANorbert Siegmund
Bauhaus-University Weimar
Germany
ABSTRACT
Software Product Lines (SPLs)are highly configurable systems. This
raisesthechallengetofindoptimalperformingconfigurationsfor
an anticipated workload. As SPL configuration spaces are huge,
itisinfeasibletobenchmarkallconfigurationstofindanoptimal
one.Priorworkfocusedonbuildingperformancemodelstopredict
and optimize SPL configurations. Instead, we randomly sample
and recursively searcha configuration space directlyto find near-
optimal configurations without constructing a prediction model.
Ouralgorithmsaresimplerandhavehigheraccuracyandefficiency.
CCSCONCEPTS
â€¢Softwareanditsengineering â†’Softwareconfigurationman-
agementandversioncontrolsystems ;Search-basedsoftware
engineering ;
KEYWORDS
software product lines, searching configuration spaces, finding
optimalconfigurations
ACM Reference format:
JehoOh,DonBatory,MargaretMyers,andNorbertSiegmund.2017.Finding
Near-Optimal Configurations in Product Lines by Random Sampling. In
Proceedings of 2017 11th Joint Meeting of the European Software Engineering
Conference and the ACM SIGSOFT Symposium on the Foundations of Soft-
wareEngineering,Paderborn,Germany,September4â€“8,2017(ESEC/FSEâ€™17),
11 pages.
https://doi.org/10.1145/3106237.3106273
1 INTRODUCTION
Software Product Lines (SPLs)are highly configurable systems. This
raisesthechallengetofindaconfigurationthathasnear-optimal
performance. An SPL configuration space is often astronomical in
size(exponentialintermsof featuresâ€“incrementsinprogramfunc-
tionality), and searching it efficiently is hard [ 35]. There are many
reasons: (1) A featureâ€™s influence on performance is not easy to
determine, because(2) feature interactionsintroduce performance
dependencies with other features [ 5,31]. (3) Techniques for true
random sampling of configuration spaces are not known; approxi-
mationstotruerandomsamplingareusedinstead.And(4)howfew
Permissionto make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany
Â© 2017 Association for Computing Machinery.
ACM ISBN 978-1-4503-5105-8/17/09 ...$15.00
https://doi.org/10.1145/3106237.3106273samplescanbetakenforperformancemodelstohaveacceptable
accuracy?
This paper focuses on a fundamental problem in SPLs to find
acceptable configurations whose performance is near-optimal. We
donotcreateaperformancepredictionmodel,whichthenrequires
an optimizer ( e.g.using a genetic algorithm [ 27]) to find good con-
figurations. Instead, we use BDDs to count the number of valid
configurations in a configuration space, thereby enabling true ran-
domsamplingofthespace.Doingsoallowsustoprovetheoretically
tightbounds on sampling results. Further,we identify features thatarestatisticallycertaintoimproveordegradeprogramperformance
[11].Weusethesefeaturestorecursivelyconstricttheconfigura-
tion space towards near-optimal configurations. The advantages
indoingsoare(a)weusesimpleralgorithmstoaccomplishwhat
more complicated algorithms do now, (b) our accuracy is better
thanexisting algorithms, and (c) we use fewer samples.
Thenovel contributions of our paper are:
â€¢True random sampling of valid configurations in an SPL;
â€¢Theoreticalboundsonsearchaccuracyfromuniformrandom
samplingof configurations;
â€¢A way to progressively shrink a configuration space by ex-
ploitingits shape and statistical reasoning;
â€¢Analyses of real systems that shows our approach outper-forms prior work in accuracy and the number of samples
needed;and
â€¢Ademonstrationofthescalabilityofourworktohugecon-
figurationspaces.
2 BIG PICTURE OF PRIOR WORK
TopredictperformanceofSPLproducts(programs),amathemat-
ical performance model is created. Historically, such models are
developedmanuallyusingdomain-specificknowledge[ 1,12].More
recently, emphasis has been on general approaches from which
performancepredictionmodelsarelearnedordeducedfromper-
formance measurements of sampled configurations. Such a perfor-
mancemodelisthengiventoanoptimizer,whichnotonlycanfind
near-optimal configurations, but also near-optimal configurations
that observe user-imposed feature constraints (e.g.configuration
predicates that exclude feature Fand includefeature G).
Prediction models estimate the performance of valid config-
urations [ 14,25,29,31,37]. They are deduced from performance
measurements of sampled configurations. The goal is to use as few
samples as possible to yield a model that is â€˜accurateâ€™. Finding a
good set of samples to use is one challenge; another is minimizing
the variancein predictions.
Given an SPL feature model [ 3], properties of features and their
interactions,anduser-imposedfeatureconstraints,anoptimizercan
61
ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany J. Oh, D. Batory, M. Myers, and N. Siegmund
derivevalidconfigurationsthatsatisfyoneormoreperformance
objectives using a general search strategy [15, 16, 27, 28, 35].
LetCbe the set of all legal SPL configurations. 1st-order per-
formance models have the following form: $ Pcis the estimated
performanceofanSPLproduct Pcwithconfiguration câˆˆC,wherec
isasetofselectedfeaturesand$ Fiistheperformancecontribution
of feature Fi:1
$Pc=/summationdisplay
iâˆˆc$Fi (1)
Linear models are inaccurate as they do not consider feature in-
teractions. Let $ Fijdenote the performance contribution of the
interaction of features FiandFj, which requires both FiandFj
to be present in a configuration; $ Fij=0i fFi/nelementcâˆ¨Fj/nelementc.2nd-order
models take into account 2-way interactions:
$Pc=/parenlefttpA
/parenleftbtA/summationdisplay
iâˆˆc$Fi/parenrighttpA
/parenrightbtA+/parenlefttpA/parenleftexA
/parenleftbtA/summationdisplay
iâˆˆc/summationdisplay
jâˆˆc$Fij/parenrighttpA/parenrightexA
/parenrightbtA(2)
andmoregenerally, n-wayinteractionsaddmorenested-summation
termsto Eq. (2)[31].
When compared to manually-developed performance models
[1,6,12],an importantdifference becomes apparent.A manually-
developed model:
â€¢Identifiesoperations {O1...}invoked by system clients,
â€¢Definesafunction$ Oitoestimatetheperformanceofeach
operation Oi,
â€¢Encodes system workloads in terms of operation execution
frequencies, where Î½iis the frequency of Oi, and
â€¢Expresses performance $ Pof a program Pas a weighted sum
of frequency times operation cost:
$P=/summationdisplay
iÎ½iÂ·$Oi (3)
Features complicate the cost function of each operation, where
configuration câˆˆCbecomes an explicit parameter:
$Pc=/summationdisplay
iÎ½iÂ·$Oi(c) (4)
The key observation is that manual performance models include
workload variances in their predictions , whereas current SPL perfor-
mance models use a fixedworkload. Workload variations play a
significant role in the performance of SPL products and should not
be omitted.
Random sampling. Optimizersandpredictionmodels[ 14â€“16,
25,27,28,37] rely on â€˜random samplingâ€™, but the samples used
arenotprovablyrandom.Truerandomsamplingwould,ineffect,
enumerateall nlegalconfigurations,randomlychooseanumber
kâˆˆ{1..n}, and use the kthconfiguration â€“ but this is not done
becausencould be astronomically large.
One popularalternative is to randomly select features tocreate
a configuration, followed by a filter to eliminate invalid configura-
tions [14,15,25,28,37]. The drawback of this approach is that it
creates too many invalid configurations [16]. Another approach
uses SAT solvers to generate valid configurations [ 16,27], but this
producesconfigurationswithsimilarfeaturesduetothewaysolvers
enumeratesolutions.Further,SATsolverscountthenumberofsolu-
tions by enumeration, which is inefficient [ 7,8]. Although Henard
1$Fineed not be a constant; it could be a sophisticated expression [14].et al. [16] mitigated these issues by randomly permuting the pa-
rameter settings in SAT solvers, true random sampling was not
demonstrated.
The top path of Figure 1 summarizes prior work: the configura-
tion space is pseudo-randomly sampled to derive a performance
model;samplingsareinterleavedwithperformancemodellearning
until a model is â€˜sufficientlyâ€™ accurate. That model is then used by
anoptimizer,alongwithuser-imposedfeatureconstraints,tofind
a near-optimal performing configuration.
ÆŒÄ‚Å¶ÄšÅ½ÅµÅ¯Ç‡ÆÄ‚ÅµÆ‰Å¯ÄÆÆ‰Ä‚ÄÄ
Ä¨Å½ÆŒÅ¶ÄÄ‚ÆŒÍ²Å½Æ‰ÆšÅÅµÄ‚Å¯
ÄÅ½Å¶Ä¨ÅÅÆµÆŒÄ‚ÆšÅÅ½Å¶ÆÄ¨ÄÄ‚ÆšÆµÆŒÄ
ÅµÅ½ÄšÄÅ¯
ÆµÆÄÆŒÅÅµÆ‰Å½ÆÄÄš
Ä¨ÄÄ‚ÆšÆµÆŒÄÄÅ½Å¶ÆÆšÆŒÄ‚ÅÅ¶ÆšÆÅ¶ÄÄ‚ÆŒÍ²Å½Æ‰ÆšÅÅµÄ‚Å¯
Æ‰ÄÆŒÄ¨Å½ÆŒÅµÅÅ¶Å
ÄÅ½Å¶Ä¨ÅÅÆµÆŒÄ‚ÆšÅÅ½Å¶Å¯ÄÄ‚ÆŒÅ¶
Æ‰ÄÆŒÄ¨Å½ÆŒÅµÄ‚Å¶ÄÄ
ÅµÅ½ÄšÄÅ¯ÆµÆÄ
Å½Æ‰ÆšÅÅµÅÇŒÄÆŒÆÄ‚ÅµÆ‰Å¯Ä
ÄÅ½Å¶Ä¨ÅÅÆµÆŒÄ‚ÆšÅÅ½Å¶ÆWÄÆŒÄ¨Å½ÆŒÅµÄ‚Å¶ÄÄDÅ½ÄšÄÅ¯Æ‰Æ‰ÆŒÅ½Ä‚ÄÅš
KÆµÆŒÆ‰Æ‰ÆŒÅ½Ä‚ÄÅš
Figure 1: Different ways to find good configurations.
Ourapproachisdifferent.First,wedonotuseperformancemod-
elsoroptimizers.Wefindgoodconfigurationsbyrandomlyprob-
ing the configuration space directly, measuring the performance of
these samples under the required workload. User-imposed feature
constraintssimplyreduce the space that we probe.
Second, we use true random sampling. We encode feature mod-
els asBinary Decision Diagrams (BDDs)[2], for which counting
the number of legal configurations is straightforward. Given the
numberoflegalconfigurations n,wecanrandomlyselectanumber
kâˆˆ{1..n}, and traverse a BDD to find the kthconfiguration. This
allows us to create accurate mathematical models based on true
randomselection.
Third, we progressively constrict the configuration space by
determining statistically significant features (or their absence) that
contributetogoodperformance.Selectingthesefeaturesfocuses
on progressively smaller regions of the configuration space that
have near-optimal configurations.
ThebottompathofFigure1summarizesourapproach:weuse
true random sampling of a constrained configuration space andmeasure the performance of selected configurations for a given
workload. We continue sampling until we reach a configuration
that exhibits a satisfactory â€˜accuracyâ€™. We demonstrate later that
ourtechniqueismoreefficientthanpriorworkinthenumberof
samplesused,andmoreaccuratethanpredictionmodels. Onlywhen
prediction models with fixed workloads are reused will they be less
costly â€“ but not necessarily more accurate â€“ than our approach.
3 SEARCH BY RANDOM SAMPLING
3.1 CountingBinary Decision Diagrams
Twotoolsarecommonlyusedtoanalyzepropositionalformulas:
SAT(isfiability)solvers [13]andBDDs.SATreliesona Conjunctive
NormalForm (CNF)representationofaformulatofindasolution
efficiently. In contrast, a BDD is a data structure that encodes a
disjunctionofformulasolutions, i.e.DisjunctiveNormalForm (DNF).
BDD tools convert non-DNF formulas into BDDs.
Figure 2 shows how a given feature model (feature diagram
+ cross-tree constraints) can be transformed into a propositional
62Finding Near-Optimal Configurations in Product Lines by Random Sampling ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany
formula[ 4],thenintoaBDD.2Fornow,ignoretheintegerlabels
on edges. The name of each node is a variable v; its dashed-line
child denotes a falseor 0 assignment to vand its bold-line child
is atrueor 1 assignment. A terminal node of a BDD is a 0 or 1
box. A path from the root to a box assigns values to variables. A
path terminating at the 1 box means that the variable assignments
are satisfiable. Path (1,1,1,0,âˆ’)means that all configurations with
root=1,A=1,C=1,andD=0(theremainingvariable Bisdonâ€™t
care) are valid solutions of this model.3
áˆºİİ‹İ‹İ Õ İİ‘İİáˆ»
×¨İİ‹İ‹İ Õ Ü£
×¨áˆºÜ¤Õœİİ‹İ‹İáˆ»
×¨Ü¥Õ×¨Ü£àµ“Ü¦
×¨Ü¦Õ×¨Ü£àµ“Ü¥
×¨áˆºÜ¦ÕœÜ¤áˆ»İİ‹İ‹İ
Ü£Ü¤
Ü¥Ü¦
Ü¦ÅÅµÆ‰Å¯ÅÄÆÜ¤)HDWXUH0RGHO 3URS)RUPXOD %''
İİ‹İ‹İ
Ü£
Ï¬ Ï­Ü¤Ü¥
Ü¦Ü¦ 
Ï¬Ï­Ï®Ï®
Ï¬Ï­Ï­
Ï¬Ï¬Ï¯
Ï¬Ï¯
Figure 2: Transforming a Feature Model into BDD.
BDDsmakeitfastandeasytocountthevalidconfigurationsfora
givenfeaturemodelanduser-imposedfeatureconstraints.Theinte-geroneachedgeinFigure2indicatesthenumberofsolutionswith
thosevariableassignments.Wecallthisa CountingBDD (CBDD).
The path (1,0,âˆ’,âˆ’,âˆ’)has zero solutions; path (1,1,0,âˆ’,âˆ’)has
one solution. The root or path (âˆ’,âˆ’,âˆ’,âˆ’,âˆ’)has three solutions,
the sum of edges from the root.
Here is why CBDDs are important: CBDDs solve an open prob-
lem of how to randomly and uniformly select configurations from
a valid configuration space. We can quickly count the size nof a
configuration space, generate a random number kâˆˆ{1..n}(where
all numbers in{1..n}are equally likely), and convert kinto an SPL
configuration by a CBDD traversal. In contrast, SAT solvers count
solutionsbyenumeration;foralargeconfigurationspaces,enumer-
ation is impractical. The downside of BDDs is that when formulas
arelarge,BDDcreationtimemayexceeduserpatienceorstorage
requirements of available memory [2].
AnalgorithmtocreateandtraverseaCBDDthatmapsanum-
bertoaconfigurationisstraightforwardandispresentedin[ 22].
Asimpleextensionincludesuser-imposedfeatureconstraints.In
short,ouralgorithmcreatesaCBDDandcountssolutionstofeature-
constrained configuration spaces to sample configurations.
3.2 PerformanceStairsin Configuration Spaces
Exploitingtheâ€˜shapeâ€™ ofaconfigurationspaceis keytosearching
it efficiently. We may not find the optimal configuration Î©â€“ the
configurationwiththe optimalperformance â€“ but if we can come
provably close to Î©, that will do nicely.
LetCbe set of all legal SPL configurations. Let câˆˆCand $(c)
denote the measured or predicted performance of configuration
c.Aperformanceconfigurationspace (PCS)isthesetofall(config,
2This is an ordered BDD , where Boolean variables are encountered from root-to-
terminals in the same order.
3This is a reducedBDD, meaning unnecessary nodes/variables whose values
are immaterial to a solution are eliminated. Otherwise a BDD would contain
2number of variablesnodes.performance) pairs:
PCS={(c,$(c))|câˆˆC} (5)
where configuration Î©âˆˆChas the best performance $ (Î©).
Now, sort the pairs of PCSfrom worst-performance to best and
plot configurations along the X-axis and performance along the
Y-axis.Wecallthisa PCSgraph .Weexpectedacontinuousgraph
suchasFigure3a,wherehigh-valued$isbad(worstperformanceis
at the far left) and low-valued $ is good (best performance is at the
farright). Î©anchorsthe far-rightpoint on X-axisof PCS graphs.
(b) Staired PCS graph (a) Continuous PCS graph
Performance ($)Performance ($) È³È³
Figure 3: PCS Graphs.
Interestingly, Markeret al.[ 18] discoveredthat PCSgraphs are
staired, as in Figure 3b. Stairs arise from discrete feature decisions ;
somefeaturesarehighly-influentialinperformancewhileothers
have little or no impact. Consequently, a few critical feature de-
cisions define the performance characteristics of a segment of a
PCS graph (the configuration membership of a stair) while less
importantfeaturedecisionsaltertheperformanceofnearbyconfig-
urationsonlyslightly(givingastairitswidth andslope).Inshort,
theconfigurationsof a stair share major design decisions [18].
Figure4illustratestwocommonsituations.First,likeafractal,
stairshavesubstairs,recursively.Substairswithindifferentstairs
repeatbecausethesamelesssignificantdecisionsareappliedwithin
eachstair(seeFigure4a).Second,distinctstairscanoverlapbecause
they have similar performance, making it difficult to distinguish
common decisions. We use the term pollution when the superposi-
tion of distinct stairs (forming a downward trending shelf) arises.
Figure 4b is the basic shape of a PCS graph that we believe is
commonin SPLs and will exploit in this paper.
(b) PCS graph with overlaps (a) PCS graph with substairs
Performance ($)Performance ($) È³stairs
within stairsdistinct stairs /
design decisions
È³
Figure 4: Stairs within Stairs.
3.3 RandomSelection in PCS Graphs
LetNbetheintervalofintegers[1 ,|C|],oneperconfigurationin C.
Randomlysampling nintegersfromthisintervalcanberegarded
as a combinatorial problem. As we are interested in finding Î©, the
probabilitythatthelargestselectedinteger, cbest,isiunitsaway
from|C|is:
p|C|,n(i)=/parenleftBigg|C|âˆ’iâˆ’1
nâˆ’1/parenrightBigg
//parenleftBigg|C|
n/parenrightBigg
(6)
63ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany J. Oh, D. Batory, M. Myers, and N. Siegmund
The expected value of i, or the mean distance cbestis to|C|, is:
E|C|,n=|C|âˆ’n/summationdisplay
i=0iÂ·p|C|,n(i) (7)
As weare interested inhuge configurationspaces, we cangen-
eralizethisanalysisbyreplacing Nwiththerealunitinterval I=
[0,1], with:
â€¢Dividing each number in N=[1,|C|]b y|C|to yield NN=
[1
|C|,1], and
â€¢Taking the limit lim|C|â†’âˆNNto produce I.
EveryPCSgraphismonotonicallydecreasing.Ifwerandomly
selectnpoints in I,cbestwill be closest to 1. The cumulative prob-
abilitydistributionfunctionfor cbestis:4
pn(Xâ‰¤x)=/integraldisplayx
0nÂ·xnâˆ’1Â·dx=xn(8)
The average error En, or the mean distance cbestis to 1, is:
En=/integraldisplay1
0(1âˆ’x)Â·nÂ·xnâˆ’1Â·dx=1
n+1(9)
That is,nrandomly selected points partition Ion average into n+1
uniform intervals of length1
n+1.Eq.(9)tells us a simple way to
search for a good configuration in a PCS graph: randomly select
nconfigurations and evaluate the performance of each. The best
performingselection, cbest,isonaverage adistance1
n+1fromthe
best performance at x=1.
Other useful statistics of pnareEn, the second-moment of En,
andÏƒn, its standard deviation:
En=/integraldisplay1
0(1âˆ’x)2Â·nÂ·xnâˆ’1Â·dx=2
(n+1)Â·(n+2)(10)
Ïƒn=/radicalBig
Enâˆ’E2n=/radicalBigg
2
(n+1)Â·(n+2)âˆ’/parenleftbigg1
n+1/parenrightbigg2
(11)
Figure 5 compares the result of Eq. (7)and Eq.(9), sampling
20, 60, and 100 numbers on spaces with different size |C|, shown
on the X-axis. To compare two equations, the results of Eq. (7)
were normalized by the size of |C|, so that both equations indicate
normalized distances to 1, shown on the Y-axis.
'LVFUHWH
&RQWLQXR
'LVFUHWH
&RQWLQXR
'LVFUHWH
&RQWLQXRÏ¯Í˜Ï±Ğ¹Ï°Í˜Ï¬Ğ¹Ï°Í˜Ï±Ğ¹Ï±Í˜Ï¬Ğ¹
6L]HRIWKHLQWHUYDO'LVWDQFHWR à«š1RUPDOL]HG
Ï¬Í˜Ï¬Ğ¹Ï¬Í˜Ï±Ğ¹Ï­Í˜Ï¬Ğ¹Ï­Í˜Ï±Ğ¹Ï®Í˜Ï¬Ğ¹
Ï¬ Ï®Ï¬Ï¬Ï¬ Ï°Ï¬Ï¬Ï¬ Ï²Ï¬Ï¬Ï¬ Ï´Ï¬Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬Ï¬à¢à¡±Ç¡à«›à«™È€à¢
à¡±à«›à«™
à¢à¡±Ç¡à«Ÿà«™È€à¢
à¡±à«Ÿà«™
à¢à¡±Ç¡à«šà«™à«™È€à¢
à¡±à«šà«™à«™
Figure 5: Comparing E|C|,nandEn.
For small spaces ( |C|â‰¤2000), Eq. (7)predictions are slightly
lowerthanEq. (9).When|C|â‰¥2000,thereisnodifferencebetween
Eq.(7)andEq.(9).Aswearemoreinterestedinhugeconfiguration
spaces,we resort to Eq. (9)for therest of this paper.
4xnâˆ’1Â·dxistheprobabilitythatthefirst nâˆ’1selectionsareintheinterval [0,x]and
dxis the probability that the last selection is at x;nis the normalization constant.
Eq.(8)is an instance of the Beta function [9].0%2%4%6%8%10%
10 20 30 40 50 60 70 80 90 100En
snÜ§à¯¡
ßªà¯¡Distance to à«š
# of random samples Q
Figure 6: EnandÏƒn.Figure 6 plots EnandÏƒnas
percentages in an infinite-size
configurationspace ;EnandÏƒn
valuesarevirtuallyidenticalas
they lie on top of each other.
Here is what Figure 6
means: If we randomly select
n=100 points, cbestwill be 1%
awayfrom1onthe I-axiswith
a standard deviation of 1%. If
we select n=50 points, cbest
will be 2% away from 1 with a standard deviation of 2%. As n
increases, the interval [ Enâˆ’Ïƒn,En+Ïƒn] shrinks. We will see later
that these numbers are good; they say that we do not need many
randomselections to find a good performing point.
3.4 Axes of Projections and Main Conjecture
0
1ÈˆÈˆÈˆ
ÈˆÔ§cc cc
CBDD
mapping$$
$
$
$Í„
mapping
à¥´È³$(È³)$
$
$
$
Figure 7: Axes of Projections.Consider the PCS graph of IÃ—$
plane of Figure 7. In the last
section, we analyzed the per-
formanceofselecting npoints
along the Iaxis and choosing
the point closest to1.
We are more interested in
the PCS graph of plane CÃ—$.
Each point in Ihas an equal
probability of being selected.
AstheCBDDmappingis1-to-1,
eachpointalong Caxisalsohas
anequallyprobabilityofbeingselected.Westillhavetomeasure
$(c)for each selected configuration c, but the theoretical results of
Eq.(8)âˆ’(11)abouterrordistancesfrom cbestto1inIaretransferred
to error distances from cbesttoÎ©inC.
Here is our main conjecture: there is a correspondence between
beingq%fromÎ©along X-axis and q%from$(Î©)along Y-axis in a
PCS graphfor small q.Supposea PCS graph is defined by $ k(x):
$k(x)=1âˆ’xk(12)
Figure 8a plots graphs for kâˆˆ{1/5,1/3,1,3,5}.W es a y kis the
curvature of a PCS graph.
0%10%20%30%40%50%60%70%80%90%100%
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
(a) Í„à¦‹İ”PCS Graphs0%2%4%6%8%10%12%14%16%18%20%
0.96 0.97 0.98 0.99 1.00
(b) Curvatures in Critical Zonek=1/5
k=1/3
k=1
k=3
k=5Performance difference to àª·
Performance difference to àª·
Figure 8: PCS Graphs and Their Critical Zones.
Letâ€™sfocus on the interval[.96,1], which contains all configura-
tions whose X-axis value is within 4% of Î©. We call this the critical
zone;4%withinoptimalisaball-parksettingforpriorwork.Fig-
ure 8b shows the critical zone of Figure 8a. The Y-axis plots the
%-distancefrom the best-performance at y=0, namely$ (Î©).
Although the PCS graphs in Figure 8a are non-linear, the cur-
vature kreduces to the graphâ€™s slope at x=1 in the critical zone.
64Finding Near-Optimal Configurations in Product Lines by Random Sampling ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany
Ï¬Í˜Ï´<Ï­Í˜Ï¯<Ï­Í˜Ï´<Ï®Í˜Ï¯<
Ï¬Ï± Ï¬ Ï­ Ï¬ Ï¬ Ï­ Ï± Ï¬$SDFKH
Ï¬Ï±Ï­Ï¬Ï­Ï±Ï®Ï¬Ï®Ï±Ï¯Ï¬Ï¯Ï±Ï°Ï¬
Ï¬ Ï±Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬ Ï­Ï±Ï¬Ï¬ Ï®Ï¬Ï¬Ï¬ Ï®Ï±Ï¬Ï¬%HUNHOH\'%&
Ï®Ï¬Ï¬Ï¯Ï¬Ï¬Ï°Ï¬Ï¬Ï±Ï¬Ï¬Ï²Ï¬Ï¬Ï³Ï¬Ï¬Ï´Ï¬Ï¬
Ï¬ Ï®Ï¬Ï¬ Ï°Ï¬Ï¬ Ï²Ï¬Ï¬ Ï´Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬;
Ï®Ï¬Ï¬Ï®Ï­Ï¬Ï®Ï®Ï¬Ï®Ï¯Ï¬Ï®Ï°Ï¬Ï®Ï±Ï¬Ï®Ï²Ï¬Ï®Ï³Ï¬
Ï¬ Ï®Ï¬Ï¬ Ï°Ï¬Ï¬ Ï²Ï¬Ï¬ Ï´Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬//90
3HUIRUPDQFH3HUIRUPDQFH3HUIRUPDQFH3HUIRUPDQFH
Figure 9: PCS Graphs of Different SPLs.
This slope is the first derivative,d
dx(1âˆ’xk)=âˆ’kÂ·xkâˆ’1, and in the
limit,limxâ†’1âˆ’kÂ·xkâˆ’1=âˆ’k. That is, the slope of a PCS graph in
the criticalregion is negative k. Observe:
â€¢When k=1,thePCSgraph$ k(x)isaline.Ifweare q%away
fromÎ©onthe X-axiswearealsoprecisely q%awayfrom$ (Î©)
on the Y-axis.
â€¢When k<1thegraphis convex.Ifweare q%fromÎ©,weknow
that performance is kÂ·q% away from $ (Î©). A convex PCS
graphmeansthat Î©liesonaflatshelfwhereanyconfiguration
on that shelf is near-optimal.
â€¢When k>1thegraphis concave.Ifweare q%awayfrom Î©,we
arekÂ·q% away from $ (Î©). A concave PCS means that Î©does
notlieonaflatshelfandfurthersearchingmaybewarranted.
Atthis point,weneedto lookatactual PCSgraphsto examine
theirshape and curvature.
3.5 PCSGraphsof Actual SPLs
Four SPLs were analyzed by Siegmund et al. [ 30], which were
extensively used as the test set for prediction models.5Figure 9
shows their PCS graphs. Each is described briefly:
â€¢LLVMis a compilerinfrastructure, written in C++. Ithas 11
featuresand1024configurations,wheretestsuitecompilation
timeswere measured.
â€¢X264isavideoencoderlibraryforH.264/MPEG-4AVCfor-
mat, writtenin C.It has16 features and1152 configurations;
Sintel trailerencoding timeswere measured.
â€¢BerkeleyDBC isanembeddeddatabasesystem,writteninC.
It has 18 features and 2560 configurations where benchmark
response times were measured.
â€¢Apacheis an open-source Web server. It has 9 features with
192 configurations, where the maximum server load size was
measured through autobench andhttperf.
Figure 10 shows their PCS graphs in the critical zone. Most
have k<1; this means that as cbestapproaches Î©on the X-axis, we
knowitsperformanceisverycloseto$ (Î©).Thereasonisthatall
configurationslieonaflatshelfwhoseperformancedifferencesare
minimal.Choosing any configurationon this shelf will do.
SPLs whose PCS graphs where k>1 pose more of a challenge.
Their configurations do not lie on a flat shelf; performance notice-
ablyimprovesasonegetscloserto Î©.Ifweknowthecurvature kof
aPCSgraph,wecanestimatehowfarwearefrom$ (Î©).Examples:
5Among6availabledatasets,weusedonlysystemsthathadalllegalconfigurations
measured. Our analyses of systems with incomplete datasets we felt were misleading,
although they exhibited similar performance to systems with complete dataset. Note
that gathering the performance data of all systems took 2months of CPU time [30].LLVMhas a curvature of k=2. If we believe our best sample is q%
fromÎ©, we can infer that we are2 Â·q%f r o m$(Î©).
From the above, a key metric that determines when to stop
samplingorifmoresamplingisneededistoestimateaPCSgraphâ€™s
curvature k. More on this in Section 4.2.3HUIRUPDQFHGLIIHUHQFHWR àª·
Ï¬Ğ¹Ï­Ğ¹Ï®Ğ¹Ï¯Ğ¹Ï°Ğ¹Ï±Ğ¹Ï²Ğ¹Ï³Ğ¹Ï´Ğ¹
Ï¬Í˜ÏµÏ² Ï¬Í˜ÏµÏ³ Ï¬Í˜ÏµÏ´ Ï¬Í˜ÏµÏµ Ï­Í˜Ï¬Ï¬//90
;
%HUNHOH\'%&
$SDFKH
N 
Figure 10: PCS Graphs of SPLs in the Critical Zone.
4 RECURSIVE SEARCHING
Thebestconfiguration cbestoutof10randomsampleswillhave
an average error/distance of 9% =1
11along the X-axis from Î©.
100randomsamples(or10 Ã—thepreviousnumber)areneededto
findcbetterthat reduces the error to 1% =1
101. Note that approx-
imately 90% of the additional 90 samples will not perform betterthan
cbest. This is wasteful. We call this Non-Recursive Searching
(NRS)to distinguish it from our upcoming approach.
Random sampling with recursion offers improvement. Ideally,
10 samples of the original configuration space can identify the best
10%ofthisspace,andanother10samplescanconstrictthissmaller
spacebyanother10%tothebest1%foratotalcostof20samples.
Thisis better; this is recursive searching .
Thekeydriverforrecursionisperformancestairs.Asstairshave
differentaverageperformancesduetodifferentfeaturedecisions,
finding the best performing stair that contains Î©improves the
result of sampling.
Consider thePCS graph of LLVM inFigure 9. This graph looks
almost linear with no stairs. However, stairs become visible as con-
figurationsareanalyzedbasedonfeaturestheyhaveincommon.In
each graph of Figure 11, configurations are partitioned by whether
they include a particular feature or not, which is done recursively.
Themostinfluentialfeature(oritsnegation)isselectedtopartition
the configurations. Then, from the remaining features, the most in-
fluential feature (or its negation) regarding the partition that better
performs in overall is selected as the next feature to partition.
Each graph in Figure 11 clearly shows the effect of performance
stairs,whereonepartitionisconstrictedbythenextviatheselection
65ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany J. Oh, D. Batory, M. Myers, and N. Siegmund
ofa â€˜good-performingâ€™or â€˜noteworthyâ€™ feature.Each suchfeature
defines a â€˜stairâ€™. Thus, devising an algorithm that finds a good stair
onwhichtorecurseisthecrucialnextstep.Weusethe Statistical
Recursive Searching (SRS)algorithmdefined next.
Ï®Ï¬Ï¬Ï®Ï­Ï¬Ï®Ï®Ï¬Ï®Ï¯Ï¬Ï®Ï°Ï¬Ï®Ï±Ï¬Ï®Ï²Ï¬Ï®Ï³Ï¬
Ï¬ Ï®Ï¬Ï¬ Ï°Ï¬Ï¬ Ï²Ï¬Ï¬ Ï´Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬//90Â¤OLFP ÅÇ€Å¶
É‰ÅÇ€Å¶
Ï®Ï¬Ï¬Ï®Ï­Ï¬Ï®Ï®Ï¬Ï®Ï¯Ï¬Ï®Ï°Ï¬Ï®Ï±Ï¬Ï®Ï²Ï¬Ï®Ï³Ï¬
Ï¬ Ï®Ï¬Ï¬ Ï°Ï¬Ï¬ Ï²Ï¬Ï¬ Ï´Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬//90HQWLUHVSDFH
Å¯ÅÄÅµ
É‰Å¯ÅÄÅµ
Ï®Ï¬Ï¬Ï®Ï­Ï¬Ï®Ï®Ï¬Ï®Ï¯Ï¬Ï®Ï°Ï¬Ï®Ï±Ï¬Ï®Ï²Ï¬Ï®Ï³Ï¬
Ï¬ Ï®Ï¬Ï¬ Ï°Ï¬Ï¬ Ï²Ï¬Ï¬ Ï´Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬//90Â¤OLFP Ş”Â¤JYQ
ÅÅ¶Å¯ÅÅ¶Ä
É‰ÅÅ¶Å¯ÅÅ¶Ä
Ï®Ï¬Ï¬Ï®Ï­Ï¬Ï®Ï®Ï¬Ï®Ï¯Ï¬Ï®Ï°Ï¬Ï®Ï±Ï¬Ï®Ï²Ï¬Ï®Ï³Ï¬
Ï¬ Ï®Ï¬Ï¬ Ï°Ï¬Ï¬ Ï²Ï¬Ï¬ Ï´Ï¬Ï¬ Ï­Ï¬Ï¬Ï¬//90Â¤OLFP Ş”Â¤JYQ Ş”Â¤LQOLQH
ÅÅ¶ÆÆšÄÅ½ÅµÄÅÅ¶Ä
É‰ÅÅ¶ÆÆšÄÅ½ÅµÄÅÅ¶Ä3HUIRUPDQFH
3HUIRUPDQFH3HUIRUPDQFH
3HUIRUPDQFH
Figure 11: Recursive Stairs of LLVM.
4.1 StatisticalRecursive Searching (SRS)
There are at least two basic approaches to find a good stair. One
directly focuses on the feature decisions that are expected to form
the best stair by using common feature decisions in the k-best
sampledconfigurations.Anotherexploitshowstairsarerecursively
formed, observing feature influence on performance from samples.
We discovered the k-best approach has drawbacks: finding a
goodkvalue is hard.Small koftenyields highlyvariant and inac-
curateresults.Larger krequiresmoresamplestocollectasfewer
commonalitiesare found among them.
Similarly,wediscoveredthesecondapproachalsohasdrawbacks:
feature interactions and constraints often led to misinterpreting a
featureâ€™s influence by making decisions inconsistent with Î©.
SRScombinestheadvantagesofbothapproacheswhileminimiz-
ing their disadvantages. SRS utilizes the k-best approach by setting
k=2. Then SRS identifies features that are common to the k=2 best
â€“andhereâ€™sthedifferenceâ€“identifying noteworthy featuresamong
themâ€“thosefeatures(ortheirnegation)thatstatisticallyarecertain
to improve performance [ 11]. SRS then constricts the search space
to configurations that comply with noteworthy features decisions,
and the SRS algorithmrecurses; see Algorithm 1.
4.1.1 Recursion Logic. At each recursive step, nrandom sam-
plesaretaken.Theperformanceinfluenceoffeaturedecision dis
determined as follows:
â€¢$(d)measures the average performance over the nsamples
that have feature d.$(Â¬d)measures the average performance
of thensamplesthat do not have d.
â€¢Î”(d)=$(d)âˆ’$(Â¬d)is the performance influence of feature
d. The sign of Î”(d)indicates whether dimproves (negative
value) or degrades (positive value) average performance.
â€¢t-Test(d)isthe resultof Welchâ€™st-test [ 34]on whether$ (d)
is better than$ (Â¬d)with 95% confidence.Welchâ€™s t-test evaluates the hypothesis that the mean of one
samplegroupishigherthantheother[ 34].Thatis,itdetermines
whether the Î”(d)from samples is reliable to distinguish whether d
orÂ¬disanoteworthyfeature.Noteworthyfeaturesconstrictthe
configuration space for the next recursion by becoming additional
constraintsthat samplesmust satisfyat the next recursive step.
4.1.2 Termination Logic. Recursion terminates when no new
noteworthy features are discovered. SRS assumes that the configu-
rationspacecannotbereducedfurther,sothatrandomsamplingon
thisregionyieldsagoodconfiguration.Ifthesizeoftheconstrictedconfigurationspaceissmallerthan
n,allconfigurationsinthespace
are measured.6
Algorithm1: SRSalgorithm
1Procedure SRS(n,FM,dSet ):
Input :n(number of samples per recursion)
FM(feature model propositional formula)
dSet(set of feature decisions (initially empty))
Output:cbest(best configuration found (set of features))
2samplesâ†samplenconfigs. from FMâˆ§dSet;
3sortsamples so thatsamples [0] has best performance;
4commonsâ†common feature decisions in samples [0] and
samples [1];
5foreachdecision incommons do
6 if(Î”(decision )<0)âˆ§tTest(decision )then
7 adddecision todSet;
8ifdSetunchanged from previous recursion then
9 returnsamples [0];
10else
11 return SRS(n,FM,dSet);
4.2 EstimatingPCSGraphCurvature k
LetÎ”x(r)denote the size of a stair in terms of the number of
configurations at the rthrecursion, where Î”x(1)=the number
of configurations in the original space. Î”x(r)decreases with in-
creasingr. Using CBBDs, we can compute Î”x(r)with pin-point
accuracy.
Therearetwoidealvaluesâ€“valuesthatcannotbecomputedun-
lessperformancedatafortheentireconfigurationspaceisavailable.
LetÎ´x(r)betheerror(distance)fromthebestsampledconfigura-
tioncbesttoÎ©along the X-axisatr-threcursion:
Î´x(r)=$(cbest)â‰¤#confiĞ´sâ‰¤$(Î©)
total#ofconfiĞ´s+ (13)
AndletÎ´y(r)betherelativeperformancedifferencebetweenthe
best configuration cbestandÎ©atr-threcursion as:
Î´y(r)=$(cbest)âˆ’$(Î©)
$(Î©)(14)
We estimate Î´x(r)andÎ´y(r)from random samples by making the
following best-case assumptions:
â€¢SamplesareÎ”x(r)
n+1awayfrom each other on X-axis.
â€¢Recursion always finds the best stair that contains Î©.
â€¢Pollutionis negligible between cbestandÎ©.
6SRSmostlyavoidslocalminimabysearchingaPCSgraph,whichismonotonically
decreasing [36]. This is elaborated in [22].
66Finding Near-Optimal Configurations in Product Lines by Random Sampling ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany
Figure 12 depicts how Î´x(r)andÎ´y(r)can be estimated with these
assumptions.
â€¢E(Î´x(r)), our estimate of Î´x(r), is based on the size of the
current stair and number of samples:
E(Î´x(r))=Î”x(r)
Î”x(1)Â·1
(n+1)(15)
wherecbestisÎ”x(r)
n+1configurationsfrom Î©along X-axis.
â€¢Wecomputetheslopeorcurvature kofastairusingtheright-
most1
3ofitssamples.Wefound1
3workswell,computedby
a standard least squares method [9].
â€¢E(Î´y(r)), our estimate of Î´y(r), is a linear extrapolation of
$(cbest), using slope kto estimate $ (Î©):
E($(Î©))=$(cbest)+kÂ·Î”x(r)
n+1(16)
ThenE(Î´y(r))is:
E(Î´y(r))=$(cbest)âˆ’E($(Î©))
E($(Î©))(17)
Í„áˆºà¢šà¢™à¢‹à¢ˆà¢‰áˆ»Î¿İ”İ
İŠàµ…Í³slope is à¦‹
Î¿İ”İ
İŠàµ…Í³È‰à¦‹: Estimated slope or curvature
: Samples
àª·
Î¿İ”áˆºİáˆ» Ú„İŠÎ¿İ”İ
İŠàµ…Í³Í„áˆºàª·áˆ»à¢šà¢™à¢‹à¢ˆà¢‰
İ” sorted configurationsperformance
Figure 12: Estimating Î´x(r)andÎ´y(r).
Ateachrecursion,wereport[ E(Î´x(r)),E(Î´y(r)),k]triplestothe
user to decide whether the best solution found so far is accurate
enough,therebystoppingtherecursionbeforeAlgorithm1stops
itself and eliminating the need for further costly sampling. The
results of the next section are based on Algorithm 1 stopping itself.
5 EVALUATION
Five research questions evaluate our work:
RQ1:DoesoursamplingtheoryforNRSmatchobservations?
RQ2: Is SRS more efficient than NRS?
RQ3: Why does SRS work?
RQ4: Is SRS better than existing approaches?
RQ5: Do NRS and SRS scale to large configuration spaces?
Toanswerthesequestions,weusedthedatabySiegmundetal.[ 30]
as ground-truth, presented in Section 3.5.
5.1 RQ1: Does Our Sampling Theory for NRS
MatchObservations?
WecomparedthetheoreticalpredictionsofNRSusing En,Eq.(9),
withtheaverageofmeasuredvaluesfor Î´x(1),Eq.(13).ForApache,
Eq.(7)was used instead as the configuration space is tiny. We
performed100experimentsforeachvalueof n.Foreachsystem,the
experiments started with nat 10 to 100 incremented by 10, plotted
forcomparisonwith En;seeFigure13.Thesegraphsconfirmaclose
agreement between NRS theory and observations: their differences
are imperceptible.
ForRQ1, our sampling theory matches empirical observations.Ï¬Ğ¹Ï­Ğ¹Ï®Ğ¹Ï¯Ğ¹Ï°Ğ¹Ï±Ğ¹Ï²Ğ¹Ï³Ğ¹Ï´Ğ¹ÏµĞ¹Ï­Ï¬Ğ¹
Ï­Ï¬ Ï®Ï¬ Ï¯Ï¬ Ï°Ï¬ Ï±Ï¬ Ï²Ï¬ Ï³Ï¬ Ï´Ï¬ ÏµÏ¬ Ï­Ï¬Ï¬//90
;
%HUNHOH\'%&
$SDFKH
7KHRUHWLFDO
$SDFKHB7KHRUHWLFDO'LVWDQFHWR àª·à¢à¢¾
RIUDQGRPVDPSOHV à¢”à¢”à¡±(T
à¡±à«šà«¢à«›Ç¡à¢”(T$SDFKH
Figure 13: NRS Theory vs. Empirical Observations.
5.2 RQ2: Is SRS More Efficient than NRS?
We compared the accuracy of SRS and NRS using an equal number
of samples and collected the following data:
â€¢Î´xis the true X-axisaccuracyof SRS when it terminates;
â€¢nis the number of samples per recursion;
â€¢Nis the total number of samples taken by SRS; and
â€¢ENis the theoretical accuracy of NRS assuming Nconfigura-
tions are randomly sampled.
Note:We do not report Î´yvalues here. A decrease in Î´xis
nevermatchedbyanincreasein Î´yinaPCSgraph. Î´yvalues
are important but only when comparing SRS with existing
approaches, whichwe do in RQ4.
Figure 14 plots averages of 100 experiments with different n
values.Whileboth Î´xandENdecreasesharply withincreasing n,
Î´xis on average better than EN.
Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±//90
Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹Ï­Ï°Ğ¹Ï­Ï²Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±%HUNHOH\'%&Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹Ï­Ï°Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±;
ßœà¯«0HDVXUHG'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”
'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”
Ü§à¯‡7KHRUHWLFDOÏ¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹Ï­Ï°Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±$SDFKH
Figure 14: Comparison between SRS and NRS.
ForRQ2, SRS is more efficient than NRS when the number of
samplesper recursion nexceeds 15.
67ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany J. Oh, D. Batory, M. Myers, and N. Siegmund
5.3 RQ3: WhyDoes SRS Work?
We collected the following measurements to understand how SRS
performs, all taken at SRS termination:
â€¢Nthe total # of samples taken,
â€¢dis the total # of noteworthy features selected,
â€¢Ïis the % of noteworthy features that belong to Î©, and
â€¢ris depth of recursion.
Figure15plotsthesemeasures w.r.t.nforall4systems.Reinforc-
ing the results of RQ2, thed,Ï, andrsaturate at n=15; indicating
that recursion works as desired. As nincreases, accuracy increases
at the cost of a linearly increasing N.
//90 ; %HUNHOH\'%& $SDFKH'HSWKRIUHFXUVLRQ à¢˜
RIIHDWXUHVLQ àª·à£‹ 7RWDORIVDPSOHV à¡º RIVHOHFWHGIHDWXUHV à¢Š
RIVDPSOHVSHUUHFXUVLRQ à¢” RIVDPSOHVSHUUHFXUVLRQ à¢”
RIVDPSOHVSHUUHFXUVLRQ à¢” RIVDPSOHVSHUUHFXUVLRQ à¢”Ï³Ï±Ğ¹Ï´Ï¬Ğ¹Ï´Ï±Ğ¹ÏµÏ¬Ğ¹ÏµÏ±Ğ¹Ï­Ï¬Ï¬Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±Ï¬Ï­Ï®Ï¯Ï°Ï±Ï²Ï³Ï´ÏµÏ­Ï¬
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±
Ï­Í˜Ï¬Ï­Í˜Ï±Ï®Í˜Ï¬Ï®Í˜Ï±Ï¯Í˜Ï¬Ï¯Í˜Ï±Ï°Í˜Ï¬Ï°Í˜Ï±
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±Ï¬Ï®Ï¬Ï°Ï¬Ï²Ï¬Ï´Ï¬Ï­Ï¬Ï¬Ï­Ï®Ï¬
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±
Figure 15: Results of SRS Recursion.
ForRQ3,SRSworksbecauseitrequiresrelativelyfewsamples
per recursion, it accurately predicts features that belong to Î©, and
relatively few recursions are needed.
5.4 RQ4:IsSRSBetterthanExistingApproaches?
Wedeterminedthebestconfigurationthatcanbereturnedbyexist-
ingpredictionmodels,andderivedtheir Î´yvaluewithrespecttothe
total number of samples Nused to construct the prediction model.
Wecomparedourresultswiththebestresultstodate,Sarkar2015
[25]andSiegmund2012[ 31],7whichhadtheirtoolandgenerated
prediction models available at [26, 30].
5.4.1 Comparison with Sarkar2015. Sarkar2015â€™spredictionmodel
uses aClassification And Regression Tree (CART)of features, based
on how randomly-sampled configurations can be partitioned by
features. Each leaf node of the CART is a group of sampled config-
urationsthatsharethesamedecisions(featureselections).Thetree
does not cover all features, but only the ones that are significant to
performance. When a configuration is queried, CART is traversed
tofindaleafthatmatchesitsdecisions.Theaverageperformance
7It is unclear to us on how to compare our results to a newer version of Sigmund2012
[29], as they extend their work with numerical features (features whose values are
within a range of real numbers); simply ignoring numerical features was not possible.of the sampled configurations within the leaf is returned as the
predicted performance.
To compare with SRS, the leaf with the smallest average per-
formance was regarded as the predicted performance of the best
configuration. Î´ywas derived as the relative error between $ (Î©)
and this value. Using their tool, 20 prediction models were created
to derive Î´yand averaged, for different sample sizes.
Figure16plots Î´yofSRSover N,aswellasthevaluesderived
from Sarkar2015, plotted as squares. The graphs show that SRS
obtainedthesame Î´yvaluewithfewersamples (N)andfoundbetter
Î´yvalues with same N, except when N<10, where statistical rea-
soningisnotmeaningful.Forexample,inBerkeleyDBC,Sarkar2015
used 110 samples to obtain an accuracy of Î´y=20% (see point /square/squaresmallsolidin
Figure 16). SRS needs 20 samples to produce this accuracy. And
whenSRS uses110 samples,it obtains an accuracy of Î´yâ‰¤0.5%.
Further,theirresultsdidnotshowacleartrendoverthenumber
of samples, as larger Ndidnotnecessarily leadto a smaller Î´y.I n
contrast,SRS clearlyshows a decrease of Î´yasNincreases.
Here is why: CART takes the average performance of configura-
tions as predicted performance, which cannot be better than the
best sampled configuration among them. Instead, SRS searches the
spacedirectly to find the best-performing configuration it can.
Ï¬Ğ¹Ï­Ï¬Ğ¹Ï®Ï¬Ğ¹Ï¯Ï¬Ğ¹Ï°Ï¬Ğ¹Ï±Ï¬Ğ¹Ï²Ï¬Ğ¹Ï³Ï¬Ğ¹Ï´Ï¬Ğ¹ÏµÏ¬Ğ¹
Ï¬ Ï®Ï¬ Ï°Ï¬ Ï²Ï¬ Ï´Ï¬ Ï­Ï¬Ï¬Ï­Ï®Ï¬Ï­Ï°Ï¬Ï­Ï²Ï¬Ï­Ï´Ï¬%HUNHOH\'%&Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹Ï­Ï°Ğ¹Ï­Ï²Ğ¹Ï­Ï´Ğ¹Ï®Ï¬Ğ¹
Ï¬ Ï® Ï¬Ï° Ï¬Ï² Ï¬Ï´ Ï¬ Ï­ Ï¬ Ï¬Ï­Ï²Ï¬Ğ¹Ï­Ï²Ï®Ğ¹Ï­Ï²Ï°Ğ¹;
Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹Ï­Ï°Ğ¹Ï­Ï²Ğ¹Ï­Ï´Ğ¹Ï®Ï¬Ğ¹
Ï¬ Ï® Ï¬Ï° Ï¬Ï² Ï¬Ï´ Ï¬ Ï­ Ï¬ Ï¬//903HUIRUPDQFHGLIIHUHQFHWR àª·à¢Ÿà¢¾
7RWDORIVDPSOHV à¡º3HUIRUPDQFHGLIIHUHQFHWR àª·à¢Ÿà¢¾
7RWDORIVDPSOHV à¡º
3HUIRUPDQFHGLIIHUHQFHWR àª·à¢Ÿà¢¾
656 6DUNDU 6LHJPXQG
3HUIRUPDQFHGLIIHUHQFHWR àª·à¢Ÿà¢¾
7RWDORIVDPSOHV à¡º7RWDORIVDPSOHV à¡º
Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹Ï­Ï°Ğ¹Ï­Ï²Ğ¹Ï­Ï´Ğ¹Ï®Ï¬Ğ¹
Ï¬ Ï® Ï¬Ï° Ï¬Ï² Ï¬Ï´ Ï¬$SDFKH
Figure16:ComparisonwithSarkar2015andSiegmund2012.
5.4.2 Comparison with Siegmund2012. Siegmund2012â€™s predic-
tion model assigns performance values to key features and their
interactionsusingconfigurationmeasurementsandlinearprogram-
ming.Theresultingmodelcanpredicttheperformanceofanylegal
configuration.We defined Î´yfor thisprediction model as follows:
Î´y=$(cpredicted best )âˆ’$(Î©)
$(Î©)(18)
where$(cpredicted best )is the actual, not predicted, performance
ofcpredicted best , the best performing configuration according to
theirpredictionmodel.Tobuildtheirmodel,Siegmund2012used
different strategies to select configurations. As different strategies
68Finding Near-Optimal Configurations in Product Lines by Random Sampling ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany
used different numbers of samples, we measured Î´yfor different
strategies. Figure 16 plots the prediction model results of Sieg-
mund2012as triangles.
As with Sarkar2015, SRS obtained the same Î´yvalue with fewer
samples(N)and found better Î´yvalues with the same N.For ex-
ample, Siegmund2012 used 62 samples to obtain an accuracy of
Î´y=4%forLLVM(seeseepoint /triangle/squaresmallsolidinFigure16).SRSneededonly17
samplestoproducethisaccuracy.AndwhenSRSuses62samples,it obtained an accuracy of Î´
y=0.2%.
Like Sarkar2015, more samples did not guarantee a better Î´y
value,norwasthereconsistencyacrosssystems,asgreatlydifferent
Î´yandNvalues were observed. SRS clearly shows a decrease of
Î´yasNincreases.
ForRQ4,SRS outperformsexistingprediction models,evenas-
suming an optimizer always finds the best configuration based on
the prediction model.
5.5 RQ5: Do NRS and SRS Scale to Large
ConfigurationSpaces?
Zhangetal.[ 37]createdlargeconfigurationspacesby Ã—-composing
multiple SPLs (see Table 1). Configurations from each SPL are com-
bined by taking the union of their features and summing their
performance values.
Table 1: Combined SPLs for Scalability Evaluation
Combined Systems # of Features # of Configs.
ApacheÃ—LLVMÃ—BerkeleyDBC 38 503,316,480
ApacheÃ—X264Ã—BerkeleyDBC 51 566,231,040
LLVMÃ—X264Ã—BerkeleyDBC 53 3,019,898,880
ApacheÃ—X264Ã—LLVMÃ—BerkeleyDBC 62 579,820,584,960
DemonstratingthescalabilityofNRSissimple:Eq. (9)defines
NRSperformanceforconfigurationspacesofsize2000toinfinity.
Figure 13 showed how SPLs of size up to 2560 match the predic-
tions of Eq. (9). Averaging 100 experiments for each value of n,
Figure 17 shows how the two smaller composite SPLs of Table 1,
whichare200Ktimeslargerthanthebiggest(2560ofBerkeleyDBC)
in Figure13, match Eq. (9). (ExtendingFigure 17 for n=10,20was
infeasible, asâ‰¥3.5% of these huge spaces exceeded the memory
capacityof our machines).
# of random samples ( à¢”)Distance to àª·(à¢à¢¾)
0.0%0.5%1.0%1.5%2.0%2.5%3.0%3.5%
30 50 70 90 110Apaches ;264 
s BerkeleyDBC 
Apaches LLVM
s BerkeleyDBC
E_n (Eqn. (9))à¢”à¡±(Eqn. (9))
Figure 17: NRS Theory vs Observations on Large Spaces.
Demonstrating the scalability of SRS is similar. Performance
graphs for composite SPLs should all have the same shape and
shouldmatch those of SPLs with small configuration spaces, as in
Figure 14. Figure 18 shows this isomorphism in all four composites.
Note that SRS performs betterthan NRS in large spaces than insmall;webelievethattheinitialnoteworthyfeaturesSRSselectsarethemosteffectivecandidatesforeachindividualSPLinacomposite,
hencethepercentageimprovementappearsbetter.Sothismight
be an artifact of using composite SPLs.
ForRQ5, NRS and SRS scale to large configuration spaces. As
before with smaller spaces, SRS outperforms NRS.
Ü§à¯‡Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±$SDFKHÃ® //90Ã® %HUNHOH\'%&
Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±//90Ã® ;Ã®%HUNHOH\'%&
Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±$SDFKHÃ®;Ã®//90Ã®%HUNHOH\'%&Ï¬Ğ¹Ï®Ğ¹Ï°Ğ¹Ï²Ğ¹Ï´Ğ¹Ï­Ï¬Ğ¹Ï­Ï®Ğ¹
Ï± Ï­ Ï±Ï® Ï±Ï¯ Ï±$SDFKHÃ®;Ã® %HUNHOH\'%&'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”
'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”'LVWDQFHWR àª·à¢à¢¾
RIVDPSOHVSHUUHFXUVLRQ à¢”
ßœà¯«
Figure 18: Î´xof Large Configuration Spaces.
5.6 Threatsto Validity
Internal Validity. We used ground-truth data of [ 30] which are
measurementsofrealsystems.Whiletheremaybeerrorsinmea-
surements,thisdatasetwasutilizedbyotherresearchers[ 14,25,29,
31,37].Webelievethatthethreatofcomparingdifferentapproaches
was sufficientlycontrolled.
To controlthe randomnessof sampling, weperformed100 ex-
perimentsandaveragedtheresults.Whilethereareoutliersthat
threaten our results, Î´xfor both NRS and SRS followed a Beta-
distribution,indicatingthattheyaremarginalandcanbecontrolled.
External Validity. We evaluated our approach based on 6real-
world systems with different domains and numbers of features. We
provided a mathematical argument on the system-independence
of NRS, statistical reasoning of SRS may depend on the number of
featuresandtheirinfluenceonperformance.WeareawarethatSRS
performancemaynotgeneralizetoallsystemsduetothis,identical
trends from our evaluations across systems and their combinations
gives confidence that our conclusions should hold for other SPLs.
6 RELATED WORK
Section3placedourresearchinperspectivewithpriorwork.We
elaboratekey topics in more detail below.
6.1 PerformancePrediction Models
A performance prediction model is a function Î¦(c)that returns an
estimateoftheexpectedperformanceofanSPLconfiguration c,for
alllegalconfigurations.Asidefromthetwoapproachesdescribedin
69ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany J. Oh, D. Batory, M. Myers, and N. Siegmund
Section 5.4, Sarkar et al. [ 25] used projective sampling to minimize
the cost of constructing a CART model for performance prediction.
Projective sampling attempts to find the optimal sample size by
approximatingthelearningcurveofthepredictionmodelâ€™saccu-
racy. Siegmundetal.[ 29]extendedtheir previouswork[ 31]with
numeric features and an iterative process to build performance-
influencemodels,whichwedonotcoveryet.Zhangetal.[ 37]used
Fouriertransformationtocreateapredictionmodelthatnotonly
predictsperformance,butalsoestimatesitsaccuracy;itisunclear
ifthisapproachscalesbeyond30features.Alloftheseworksare
notdirectlycomparablewithSRS,astheirevaluationmeasuredthe
average prediction accuracy over multiple test configurations and
do not provide means for finding the near-optimal configurations.
6.2 Optimizers
Anoptimizerfindsconfigurationsthatsatisfymultipleperformance
constraints from a given feature model and properties of each
feature. White et al. [ 35] proposed an approach based on linear
programming, which transforms the given feature model with bud-
get constraints into a knapsack problem. Guo et al. [ 15] applied
a geneticalgorithm tosearch forthe optimalconfiguration. From
randomly selected configurations, they crossover good perform-
ing configurations for mutation and modify invalid configurations.
Sayyad et al. [ 27,28] elaborated on Indicator-Based Evolutionary
Algorithm (IBEA)for selecting optimal features regarding multi-
ple objectives, which outperformed other evolutionary algorithms.
They also proposed a heuristic that uses precomputed valid config-
urationsasaseedfortheevolutionaryalgorithm,toimprovethe
scalability ofthe approach. Henardet al. [ 16] extendedIBEA with
SAT solver to generate random configurations and filter out the
invalidconfigurationsfrom mutations, to improve scalability.
Theseevolutionaryapproachesperformrandomizedmutation
ofconfigurations,whichoftenleadstoinvalidconfigurations.They
require significant effort to find suitable parameter settings, which
are system-specific and require more than 100 initial samples [ 23].
6.3 CountingConfigurations
Countingconfigurationsisknownasthe model counting problem ,
which is regarded as a more complicated problem than checking
thesatisfiability[ 8].SATsolverswereextendedtoexactly[ 32]or
approximately [ 10] count the number of solutions from a given
propositionalformula.BDDscancountthenumberofsolutionsvia
their construction. This is advantageous when multiple queries are
made to a single formula, as the BDD can be reused [8].
Benavidesetal.andPohletal.[ 7,24]comparedCSP,SAT,and
BDD solvers on counting configurations, where BDD was much
faster than the others, given enough memory. Mendonca et al. [ 20]
provided a reasoning and configuration engine SPLOT, which uses
BDD to count the number of valid configurations. Mendonca et
al. [21] proposed heuristics to reduce the size of BDD through
variableorderinginferredfromafeaturemodel,whichimproves
the scalabilityup to 2000 features.
6.4 SamplingConfigurableSystems
Efficient testing strategies for configurable systems rely on sam-pling. Liebig et al. [
17] compared different sampling algorithmswith regards to scalability. Random sampling was considered infea-
sible as most samples were invalid when features are randomly
selected,duetofeatureconstraints.Medeirosetal.[ 19]alsocom-
pareddifferentsamplingalgorithmsforfaultdetectioncapability.
Their work randomly selected features, eliminating invalid config-
urations. But again, random sampling features does not guarantee
randomsamplingof configurations [14, 15, 25, 28, 37].
Incontrast,werandomlysamplefromasetofvalidconfigura-
tions. #SAT solvers [ 10,32] are SAT solvers that also can count the
numberofsolutions.Thekeytousing#SATistodeterminehowto
uniquelymapagivennumbertoaspecificconfiguration.CBDDs
provide this capability directly [8, 33].
7 CONCLUSIONS
Creating performance models that can predict the performance of
any SPL configuration is a worthy goal; it must be used with anoptimizer that knows how to search a large configuration space
efficiently.Butitisalsoanexpensiveapproach,astheperformancemodelmustbereusedindifferentsituationstoamortizethecostofitsdevelopment.Akeyassumptioninthislineofworkismeasuring
performance for a fixed workload; should that workload change, a
new performance model may need to be created.
We eliminated the middle-men of performance models and opti-
mizersbyrandomsamplingtheconfigurationspacedirectlyand
usingsampledconfigurationstoprogressivelyconstrictthespace.
Our paper makes five contributions:
(1)WeshowedhowtruerandomsamplingofaSPLconfiguration
space can be achieved by Counting BDDs (CBDDs). Prior
work relied on pseudo-random sampling;
(2)Weexplainedhowconfigurationspacescanbesearchedby
usingnrandom samples and returning the best-performance-
in-n. We called this approach Non-Recursive Sampling (NRS),
which has theoretically good performance;
(3)Wedemonstratedthatinformationgleanedfromsampledcon-
figurations yields noticeably better performance than NRSusing Statistical Recursive Searching (SRS) at a minimal in-
crease in algorithm complexity;
(4)We compared SRS to prior work and showed that SRS con-
sistently found better-performing configurations using fewer
samples;and
(5) We demonstrated how our approach scales to huge spaces.
Webelievethatourworkadvancesandsimplifiesthestate-of-
the-artinfindingnear-optimalconfigurationsinlargeSPLconfigu-
ration spaces.
ACKNOWLEDGMENTS
WorkbyOh,Batory,andMyersissupportedbyNSFgrantsCCF-
1212683 and ACI-1550493. Siegmundâ€™s work is supported by the
DFG underthe contractSI 2171/2.
REFERENCES
[1]SanjayAgrawal,SurajitChaudhuri,andVivekRNarasayya.2000. Automated
selectionofmaterializedviewsandindexesinSQLDatabases.In 26thInternational
Conferenceon Very Large Databases (VLDB) . 496â€“505.
[2]Sheldon B. Akers. 1978. Binary decision diagrams. IEEE Trans. Comput. 27, 6
(1978), 509â€“516.
[3]Sven Apel, Don Batory, Christian Kaestner, and Gunter Saake. 2013. Feature-
oriented software product lines: concepts and implementation . Springer.
70Finding Near-Optimal Configurations in Product Lines by Random Sampling ESEC/FSEâ€™17, September 4â€“8, 2017, Paderborn, Germany
[4]Don Batory. 2005. Feature models, grammars, and propositional formulas. In 9th
International Software Product Line Conference (SPLC) . Springer, 7â€“20.
[5]Don Batory, Peter HÃ¶fner,and Jongwook Kim. 2011. Feature interactions,prod-
ucts,andcomposition.In 10thInternationalConferenceonGenerativeProgram-
ming and Component Engineering (GPCE) , Vol. 47. ACM, 13â€“22.
[6]D. S. Batory and C. C. Gotlieb. 1982. A unifying model of physical databases.
ACM Transactions on Database Systems (TODS) 4 (1982), 509â€“539.
[7]David Benavides, Sergio Segura, Pablo Trinidad, and Antonio Ruiz-CortÃ©s. 2006.
Afirststeptowardsaframeworkfortheautomatedanalysisoffeaturemodels.
In10th International Software Product Line Conference (SPLC) . 39â€“47.
[8]ArminBiere,MarijnHeule,andHansvanMaaren.2009. Handbookofsatisfiability .
Vol. 185. IOS press.
[9] Allan G Bluman. 1995. Elementary statistics . Brown Melbourne.
[10]Supratik Chakraborty, Kuldeep S Meel, and Moshe Y Vardi. 2013. A scalable
approximatemodelcounter.In InternationalConferenceonPrinciplesandPractice
of Constraint Programming . Springer, 200â€“216.
[11]Girish Chandrashekar and Ferat Sahin. 2014. A survey on feature selection
methods. Computers & Electrical Engineering 40, 1 (2014), 16â€“28.
[12]Surajit Chaudhuri. 1998. An overview of query optimization in relational sys-
tems.In7thACMSIGACT-SIGMOD-SIGARTSymposiumon PrinciplesofDatabase
Systems. ACM, 34â€“43.
[13]Carla P Gomes, Henry Kautz, Ashish Sabharwal, and Bart Selman. 2008. Satisfia-
bility solvers. Foundations of Artificial Intelligence 3 (2008), 89â€“134.
[14]JianmeiGuo,KrzysztofCzarnecki,SvenApel,NorbertSiegmund,andAndrzej
Wasowski.2013. Variability-awareperformanceprediction:Astatisticallearning
approach.In 28thInternationalConferenceonAutomatedSoftwareEngineering
(ASE). IEEE, 301â€“311.
[15]JianmeiGuo,JulesWhite,GuangxinWang,JianLi,andYinglinWang.2011. A
geneticalgorithmforoptimizedfeatureselectionwithresourceconstraintsin
softwareproductlines. JournalofSystemsandSoftware 84,12(2011),2208â€“2221.
[16]ChristopherHenard,MikePapadakis,MarkHarman,andYvesLeTraon.2015.
Combiningmulti-objective searchand constraintsolvingfor configuringlarge
software product lines. In 37th International Conference on Software Engineering
(ICSE), Vol. 1. IEEE, 517â€“528.
[17]JÃ¶rg Liebig, Alexander von Rhein, Christian KÃ¤stner, Sven Apel, Jens DÃ¶rre, and
Christian Lengauer. 2013. Scalable analysis of variable software. In 9th Joint
Meeting on Foundations of Software Engineering (FSE) . ACM, 81â€“91.
[18]Bryan Marker, Don Batory, and Robert Van De Geijn. 2014. Understandingperformance stairs: Elucidating heuristics. In 29th International Conference on
Automated Software Engineering (ASE) . ACM, 301â€“312.
[19]FlÃ¡vio Medeiros, Christian KÃ¤stner, MÃ¡rcio Ribeiro, Rohit Gheyi, and Sven Apel.
2016. A comparison of 10 sampling algorithms for configurable systems. In 38th
International Conference on Software Engineering (ICSE) . ACM, 643â€“654.
[20]Marcilio Mendonca, Moises Branco, and Donald Cowan. 2009. SPLOT: Software
productlinesonlinetools.In 24thACMSIGPLANConferenceCompaniononObject
Oriented Programming Systems Languages and Applications . ACM, 761â€“762.
[21]MarcilioMendonca,AndrzejWasowski,KrzysztofCzarnecki,andDonaldCowan.
2008. Efficient compilation techniques for large scale feature models. In 7th
International Conference on Generative Programming and Component Engineering
(GPCE). ACM, 13â€“22.[22]Jeho Oh, Don Batory, and Margaret Myers. 2016. Finding Product Line Configura-
tionswithHighPerformancebyRandomSampling . TechnicalReportTR-16-22.
Universityof Texas at Austin, Department of Computer Science.
[23]Rafael Olaechea, Derek Rayside, Jianmei Guo, and Krzysztof Czarnecki. 2014.
Comparison of exact and approximate multi-objective optimization for software
productlines.In 18thInternationalSoftwareProductLineConference(SPLC) ,Vol.1.
ACM, 92â€“101.
[24]RichardPohl,KimLauenroth,andKlausPohl.2011.Aperformancecomparisonof
contemporary algorithmic approaches for automated analysis operations on fea-ture models. In 26th International Conference on Automated Software Engineering
(ASE). IEEE, 313â€“322.
[25]AtriSarkar,JianmeiGuo,NorbertSiegmund,SvenApel,andKrzysztofCzarnecki.2015. Cost-efficientsamplingforperformancepredictionofconfigurablesystems.
In30th International Conference on Automated Software Engineering (ASE) . IEEE,
342â€“352.
[26]AtriSarkar,JianmeiGuo,NorbertSiegmund,SvenApel,andKrzysztofCzarnecki.
2015. Dataset for Sarkar2015. https://github.com/atrisarkar/ces. (2015).
[27]Abdel Salam Sayyad, Joseph Ingram, Tim Menzies, and Hany Ammar. 2013.
Scalableproductlineconfiguration:Astrawtobreakthecamelâ€™sback.In 28th
InternationalConferenceonAutomatedSoftwareEngineering(ASE) .IEEE,465â€“474.
[28]Abdel Salam Sayyad, Tim Menzies, and Hany Ammar. 2013. On the value of
user preferences in search-based software engineering: a case study in software
product lines. In 35th International Conference on Software Engineering (ICSE) .
IEEE, 492â€“501.
[29]NorbertSiegmund,AlexanderGrebhahn,SvenApel,andChristianKÃ¤stner.2015.
Performance-influence models for highly configurable systems. In 10th Joint
Meeting on Foundations of Software Engineering (FSE) . ACM, 284â€“294.
[30]Norbert Siegmund, Sergiy S Kolesnikov, K Christian, Sven Apel, and Gunter
Saake. 2012. Dataset for Siegmund2012. http://fosd.de/SPLConqueror. (2012).
[31]NorbertSiegmund,SergiySKolesnikov,ChristianKÃ¤stner,SvenApel,DonBatory,
MarkoRosenmÃ¼ller,andGunterSaake.2012. Predictingperformanceviaauto-
mated feature-interaction detection. In 34th International Conference on Software
Engineering (ICSE) . IEEE, 167â€“177.
[32]Marc Thurley. 2006. sharpSATâ€“counting models with advanced component
caching and implicit BCP. In International Conference on Theory and Applications
of Satisfiability Testing . Springer, 424â€“429.
[33]Takahisa Toda and Takehide Soh. 2016. Implementing efficient all solutions sat
solvers.Journal of Experimental Algorithmics (JEA) 21, 1 (2016), 1â€“12.
[34]BernardLWelch.1947. Thegeneralizationofstudentâ€™sâ€™problemwhenseveral
different population variances are involved. Biometrika 34, 1/2 (1947), 28â€“35.
[35]Jules White, Brian Doughtery, and Douglas C Schmidt. 2009. Filtered Cartesian
flattening:Anapproximationtechniqueforoptimallyselectingfeatureswhile
adheringtoresourceconstraints. JournalofSystemsandSoftware 82(8)(2009),
1268â€“1284.
[36]Wikipedia.2016. MonotonicFunction. https://en.wikipedia.org/wiki/Monotonic_
function. (2016).
[37]YiZhang, JianmeiGuo, EricBlais, andKrzysztof Czarnecki.2015. Performance
prediction of configurable software systems by fourier learning. In 30th Interna-
tional Conference on Automated Software Engineering (ASE) . IEEE, 365â€“373.
71