Work Practices and Challenges in Pull-Based
Development: The Contributor‚Äôs Perspective
Georgios Gousios
Radboud University Nijmegen
Nijmegen, the Netherlands
g.gousios@cs.ru.nlMargaret-Anne Storey
University of Victoria
BC, Canada
mstorey@uvic.caAlberto Bacchelli
Delft University of T echnology
Delft, the Netherlands
a.bacchelli@tudelft.nl
ABSTRACT
The pull-based development model is an emerging way of con-
tributing to distributed software projects that is gaining enormouspopularity within the open source software (OSS) world. Previouswork has examined this model by focusing on projects and their
owners‚Äîwe complement it by examining the work practices of
project contributors and the challenges they face.
We conducted a survey with 645 top contributors to active OSS
projects using the pull-based model on GitHub, the prevalent social
coding site. We also analyzed traces extracted from corresponding
GitHub repositories. Our research shows that: contributors havea strong interest in maintaining awareness of project status to getinspiration and avoid duplicating work, but they do not activelypropagate information; communication within pull requests is re-
portedly limited to low-level concerns and contributors often use
communication channels external to pull requests; challenges aremostly social in nature, with most reporting poor responsivenessfrom integrators; and the increased transparency of this setting is
a conÔ¨Årmed motivation to contribute. Based on these Ô¨Åndings, we
present recommendations for practitioners to streamline the contri-bution process and discuss potential future research directions.
Categories and Subject Descriptors
D.2.7 [Software Engineering]: Distribution, Maintenance, andEnhancement‚ÄîV ersion control ; D.2.9 [Software Engineering]: Man-
agement‚ÄîProgramming teams
Keywords
pull-based development, open source contribution, pull request, dis-tributed software development, GitHub
1. INTRODUCTION
Distributed software development projects employ collaboration
models and patterns to streamline the process of integrating incom-ing contributions [36]. The pull-based development model is a re-cent form of distributed software development [25] that is gain-ing tremendous traction in the open source software (OSS) world.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributedfor proÔ¨Åt or commercial advantage and that copies bear this notice and the full citationon the Ô¨Årst page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permissionand/or a fee. Request permissions from permissions@acm.org.
ICSE ‚Äô16, May 14 - 22, 2016, Austin, TX, USA
c/circlecopyrt2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI: http://dx.doi.org/10.1145/2884781.28848260200,000400,000600,000
2011 2012 2013 2014 2015 2016
Pull requests Repositories that received pull requests
Figure 1: Monthly growth of pull request usage on GitHub.
As Figure 1 shows, its popularity is constantly growing; in Jan-
uary 2016, 135,000 repositories on the GitHub social coding sitereceived more than 600,000 pull requests. In total, 1,000,000 col-
laborative GitHub projects ( i.e., 45% of all collaborative projects)
used at least one pull request during their lifetime.
As opposed to more classic ways of contributing (e.g. , change
sets sent to development mailing lists [4] to issue tracking sys-
tems [3] or through direct access to the version control system [17]),
in the pull-based model, contributors fork ( i.e., locally duplicate)
the main repository of the project they want to contribute to, make
their changes independently, then create a pull request (PR) to askthat their changes be merged into the main repository. Then the
members of the project‚Äôs core team (the integrators) are responsi-
ble for evaluating the quality of the contributions, proposing correc-
tions, engaging in discussion with the contributors, and eventuallymerging or rejecting the changes.
Social coding sites (e.g. , GitHub [20], Bitbucket [6], and Gi-
torious [21]) offer the pull-based development model in conjunc-tion with social media functions, which allow users to subscribe toand/or visualize information about activities of projects and usersand offer threaded asynchronous communication within PRs.
To grasp the complexity of the pull-based development model
offered by social coding sites, it is necessary to examine it frommultiple perspectives. Previous research considered the lifetimecharacteristics of PRs [25], macroscopic factors that lead to contri-bution acceptance [25, 45], the barriers faced by Ô¨Årst time contribu-
tors [44], how contributions are evaluated through discussions [46],
and the working habits and challenges faced by integrators [27].
Here we present the contributor‚Äôs perspective by investigating con-
tributors‚Äô work habits and the challenges they face.
The overall goal with this work is to understand how contribut-
ing to OSS projects works using the pull-based development modelin the context of social coding sites. Understanding the contrib-utor‚Äôs perspective is needed to reveal weaknesses with the pull-based model and to guide the design of tools and processes to sup-
port their work, which is an essential part of the workÔ¨Çow. More-
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   285
over, this understanding is required to help project owners address
the weak aspects of their development process and to take action
against the barriers that contributors face.
To achieve our goal, we performed an exploratory investigation
of contributors to projects hosted on GitHub. We conducted an
online survey that was answered by 645 top contributors to ac-tive projects, and we analyzed the results with traces from GHTor-
rent [24]. Since GitHub hosts diverse projects developed by many
different programmers, it gives us the opportunity to learn from avariety of cases.
We found that contributors have a strong interest in staying aware
of project status to get inspiration and to avoid duplicating work,but they do not actively try to propagate information about thepull requests they are preparing. The toughest and most frequentchallenges encountered by contributors are social in nature, mostly
related to poor responsiveness and a lack of empathy from inte-
grators, and difÔ¨Åculties in communicating change rationale. Inparticular, the communication within pull requests, although ef-
fective for discussing low-level issues, appears to be limited forother types of contributors‚Äô communication needs. Finally, con-
sidering the transparency offered by social coding sites using the
pull-based model, our respondents reported (in line with previous
Ô¨Åndings [11]) that building code portfolios is a motivation to con-tribute. The same transparency seems to encourage developers toreview their changes before submission, but also triggers a fear of
rejection that might harm their reputation.
2. BACKGROUND AND RELATED WORK
OSS projects form online collaborative communities [15] where
developers wishing to participate will submit contributions, usu-
ally as source code patches. The onion model is a widely accepted
way of organizing OSS communities by contributions [52]: a core
team (with an optional leader) receives contributions and deter-mines their fate based on technical merit or trust.
Despite a project‚Äôs best intentions, newcomers to OSS commu-
nities occasionally face challenges. Steinmacher et al. [44] ana-
lyzed related work and identiÔ¨Åed 58 barriers, most of which relateto social aspects such as community engagement and the need fororientation.
After contributions have been submitted, they must also be eval-
uated. In an early study, Mockus et al. [36] described the commit-
Ô¨Årst contribution evaluation pattern: code must be in the repositorybefore it is reviewed. Rigby and Storey examined the peer reviewprocess in OSS mailing lists and found that developers Ô¨Ålter emails
to reduce evaluation load, prioritize using progressive detail within
emails containing patches, and delegate by appending names to thepatch email recipients [41]. Baysal et al. [3] examined contribu-
tion evaluation over the bug tracking database and found that con-tributions from casual contributors received preferential treatment,
which they attribute to the size of the contributions ( i.e., new con-
tributors submit smaller contributions).
A number of social factors also affect how developers interact
with the project community in order to have their contributionsevaluated. Duchneaut found that developers hoping to get their
contributions accepted must Ô¨Årst be known to the core team [15];core team members use a developer‚Äôs previous actions as one ofthe signals for judging contributions. Similarly, Krogh et al. [49]
found that projects permit developers to contribute through estab-
lished implicit ‚Äújoining scripts‚Äù, which may permit access to the
main repository based on developers‚Äô past actions.
Due to increasing popularity, GitHub and the pull-based devel-
opment approach have attracted the attention of researchers inter-
ested in online collaboration and software development practices.Gousios et al. [25] quantitatively investigated the characteristics of
contributions in GitHub, Ô¨Ånding that contributions are relatively
small (20 lines) and processed very quickly (submissions are ac-cepted in less than a day). Moreover, both Gousios et al. [25] and
Tsay et al. [45] investigated the factors that inÔ¨Çuence the accep-
tance of contributions in GitHub: both found similar processes butdifferent dominating factors ( i.e., ‚Äòhotness‚Äô of project area and so-
cial distance, respectively).
Contribution evaluation is as important in pull-based develop-
ment as it is in traditional OSS practices. Pham et al. [38] reported
initial qualitative evidence on how integrators assess contributionsby focusing on the evaluation of testing practices. In a survey of in-tegrators of busy projects in GitHub, Gousios et al. [27] found that
integrators struggle to maintain the quality of their projects. Theyexperience difÔ¨Åculties prioritizing the contributions to be mergedand face challenges identifying factors that will reveal contributionquality. By focusing on how discussions affect contribution evalu-
ation in GitHub, Tsay et al. [46] found that stakeholders external to
the project may inÔ¨Çuence the evaluation discussions while power
plays are in effect. Social signals also play an important role: Mar-low et al. [34] found that core members form an impression of the
quality of incoming contributions by using social signals such as
the developer‚Äôs coding activity and the developer‚Äôs social actions
(e.g. , following other developers).
Social coding capabilities, in conjunction with pull-based devel-
opment, improve how projects engage with community members
and attract more contributions. In a study of integrators, Dabbish et
al.[11] found that transparency drives collaboration as social infer-
ences (around commitment, work quality, etc.) allow developers to
more effectively deal with incoming contributions. Similarly, inte-
grators of three large OSS projects hosted on GitHub, interviewed
by McDonald and Goggins, reported that the switch to GitHub al-
lowed them to become more democratic and transparent and to at-tract more participation, resulting in a doubling of the number ofcontributors [35].
Overall, all studies involving the pull-based development model
have focused on projects and integrators. In this paper, we comple-ment this view by analyzing contributors.
3. RESEARCH METHOD
The overall goal with this research is to understand how con-
tributing to OSS projects works using the pull-based developmentmodel in the context of social coding sites. Our examination of
the literature revealed that our scientiÔ¨Åc knowledge of OSS and the
case of pull-based development in social coding mostly considers
project or integrator perspectives, or investigates what happens af-ter a contribution has been submitted to a project.
We know that the pull-based development model facilitates a
more casual relationship with projects by making it easier to send
a pull request, while social coding features ease participation in
any subsequent discussion. This setting has given rise to phenom-ena such as drive-by commits [38, 34], where developers submitsmall Ô¨Åxes without expecting any (or at least, limited) compensa-
tion or recognition. What is currently lesser known, however, is
how contributors prepare (for) a contribution. This motivated ourÔ¨Årst research question:
RQ1: How do contributors prepare (for) a contribution in socialcoding sites using the pull-based development model?
Despite the increased transparency that social coding sites af-
ford, many contributions are still rejected as duplicate, conÔ¨Çicting
286or superseded [25]. We were interested in Ô¨Ånding out whether con-
tributors leverage transparency in the same ways that integrators
do [11]. Do they communicate prior to submitting a PR or does
communication occur only post-submission? Moreover, contribu-tion quality is a major concern for integrators [27]: we wished toknow if there is a match between what integrators and contributorsexamine to assess the quality of contributions. We reÔ¨Åned our Ô¨Årst
research question as follows:
RQ1.1: What do contributors do before and after coding a PR?
RQ1.2: How do contributors assess the quality of their PR?
RQ1.3: How do contributors communicate about an intended change?
Subsequently, we were interested in understanding the challenges
that contributors experience when working with the pull-based model
in GitHub. We also considered the barriers that make it difÔ¨Åcult for
new contributors to participate. This exploration is needed to guide
future work in this area and led to our last research question:
RQ2: What are the challenges of contributing in social coding
sites using the pull-based development model?
3.1 Study Design
Our study followed a mixed-method approach [10]. Since our
aim was to learn from a large number of projects, we used an on-
line survey as it is a data collection approach that scales well [16].
We enriched the gathered data with traces extracted from GHTor-
rent [24]. We collected survey data in two rounds. In the Ô¨Årstround, we ran a pilot survey with a limited number of selected con-tributors as it allowed us to clarify our questions and to identifyemerging themes we could explore further (i.e., we added a ques-
tion about motivations for contributing and one question on bar-
riers for newcomers). In the second round, we sent the survey‚Äî
augmented with questions addressing the themes that emerged inthe Ô¨Årst round‚Äîto several contributors of pull requests on GitHub-
hosted OSS projects.
Survey Design. Pilot and Ô¨Ånal survey were split into two sections:
(1) demographic information and (2) open-ended questions inter-mingled with multiple choice or Likert scale questions. Usually,the contributor had to answer an open-ended question and then a
related one with Ô¨Åxed answers. To further elicit the contributor‚Äôs
opinions, in all questions that had predeÔ¨Åned answers but no relatedopen-ended question, we included an optional ‚Äòother‚Äô response.Throughout the survey, we intentionally used even Likert scales to
force participants to make a choice. Excluding demographic ques-
tions, the Ô¨Ånal survey consisted of 4 open-ended questions, 4 Likertscale questions with an optional open-ended response, and 11 mul-tiple choice questions (5 with an optional Ô¨Åeld).
1The vast majority
(95%) of respondents completed the survey in less than 10 minutes.
Sampling projects and candidate respondents. Previous work
has revealed that most GitHub repositories are inactive and have a
single user [25, 31]. To ensure that our sample consisted of repos-itories that make effective and large-scale use of PRs, we selected
all repositories in the GHTorrent dataset [24] that have received at
least one PR per week during the year 2013 (3,400 repositories).For each repository, we extracted the top 3 pull request contribu-tors by the number of PRs they contributed. We sent them an emailif their address was registered with GitHub and if they were not
integrators in the same repository; we collected 4,617 emails.
1The survey questions are publicly available [26].Attracting participants. For the pilot phase, we randomly se-
lected and emailed 445 of the 4,617 contributors, and received 32answers (7% response rate). For the main data collection phase,
we emailed the remaining 4,172 contributors and received 760 an-swers (18% response rate, i.e., typical of online surveys in software
engineering, where the response rate is usually within the 14‚Äì20%range [39]). The survey was published online and its Web address
was sent by personal email to all participants. To encourage par-
ticipation, we created a customized project report for each of theemailed contributors. The report included plots on the project‚Äôsperformance in handling PRs (e.g. , mean close time) on a monthly
basis. The reports for all projects have been published online [23]and they were widely circulated among developers. We did notrestrict access to the survey to invited users only; several surveyrespondents forwarded the survey to colleagues or advertised it onsocial media (Twitter) without our consent. After comparing the
response set with the original set of projects, we found that 25% of
the responses came through third-party advertising. The survey ranfrom April 14 to May 1, 2014.Respondents. The majority of our respondents self-identiÔ¨Åed as
project contributors (76%), with 65% working for industry. Most(68%) reported more than 7 years of software development expe-rience and considerable experience (> 3 years) in geographically
distributed software development (59%).
3.2 Analysis
We applied manual coding [9] on the 4 open-ended questions as
follows: initially, the Ô¨Årst and last authors individually coded (in a
shared online spreadsheet) a different set of 50 (out of 760) answers
for each question. At least 1 and up to 3 codes were applied to eachanswer. Then, the coders met physically, grouped the extractedcodes together and processed them to remove duplicates and, in
some cases, to generalize or specialize them. The agreed-upon
codes were then applied to all the answers (each coder codiÔ¨Åed50% of the answers). When new codes emerged, they were inte-grated in the code set. Another round of code integration followedin a physical meeting, which led to the Ô¨Ånal result. On average,
20% more codes were discovered in the Ô¨Ånal integration round.
We asked respondents to optionally include their GitHub user
name and report a single repository to which they contribute many
PRs; 81% (610) and 95% (722) of the respondents did so, respec-
tively. Many responses (126) did not match to a GitHub reposi-
tory for reasons that ranged from spelling mistakes to using nameswith wild cards (e.g. ,
jenkinsci/* ) to denote contributions to multi-
ple repositories. We corrected the repository names as follows: weÔ¨Årst used GitHub‚Äôs search functionality to locate repositories whose
name was similar to the provided one and then chose the one that
had received PRs from the user. When a repository name containedwild cards, we searched the GHTorrent database for all repositoriesthe contributor had submitted PRs to and selected the one where
the contributor had submitted the most PRs. We excluded from
our further analysis any answers for which we could not obtain avalid repository name (5 answers) and those that did not include arepository name (38 answers).
3.3 Adding Project Metrics
After we resolved the repository names, we augmented the sur-
vey dataset with information from the GHTorrent MySQL database(version 2015-06-18) [24]. For each project, we calculated themean number of PRs (
mean.prs ) and the mean number of integra-
tors ( mean.integrators ) on a per month basis for the period July
2013 to July 2014. Per metric, we split projects into three equally
sized groups (small, medium and large). We also calculated whether
28724%
45%
49%
52%
59%
68%
84%76%
55%
51%
48%
41%
32%
16%Communicate my
changes to the
project core
teamLookup project
pull request
guidelinesLookup for
open issues
related to my
changes
Check whether
similar pull
requests were
processed
recently
Check other
project
branches, or
forks, for
related
featuresCheck project
discussions,
emails forums
IRC, for
related topics
Get assigned
some work by
my project
leader
100 50 0 50 100
PercentageResponse Never Occasionally Often AlwaysBefore starting to work on a pull request, I
19%
24%
56%
65%
76%81%
76%
44%
35%
24%Format it
according to
project
guidelinesRun the tests
against it
Check whether
similar pull
requests were
processed
recently
Check other
project
branches, or
forks, for
features
related to my
pull requestCheck project
discussions
for topics
related to it
100 50 0 50 100
PercentageResponse Never Occasionally Often AlwaysWhen I am ready to submit a pull request, I
Figure 2: Work practices before (left) and after (right) coding a contribution.
respondents belong to the top 10% of contributors ( top.10.perc.contrib )
for the repository they reported and whether they usually commit
to big, medium or large projects ( typical.size.of.project ).
To ensure that our answer set included developers that contribute
primarily or exclusively through PRs rather than through other means(e.g. , bug reports), we used one of the Ô¨Åxed answer questions ( Q9:
How do you contribute code to the project? ) as a further demarca-
tion point. Consequently, we Ô¨Åltered 77 respondents who did notindicate contributions exclusively through PRs or through branch-to-branch PRs. The Ô¨Ånal answer set contained 645 answers.
4. RESULTS
This section presents the results of our exploratory investigation.
When quoting survey respondents, we refer to them using a [rX]notation, where Xis the respondent‚Äôs ID. Codes resulting from cod-
ing open-ended answers are
underlined. When referring to quanti-
tative results, we annotate the metrics presented in Section 3.3 witha
sans-serif font. Where applicable, we integrate and compare our
Ô¨Åndings with related research Ô¨Åndings.
RQ1.1: What are contributors‚Äô work practices?
We wanted to understand which practices contributors use afterthey decide to create a PR, before and after the actual coding, but
before they submit it. A variety of survey questions led to this un-
derstanding and the answers are presented in Figure 2.
Work practices followed before coding.
To ask respondents about their work habits before coding, we
provided them with a set of 7 questions (based on our analysis ofthe literature and our vast GitHub experience) with a 4-level Lik-
ert scale. Only 24 (3%) respondents added information using the
‚Äòother‚Äô Ô¨Åeld, mostly providing clariÔ¨Åcations. Results show that, ingeneral, contributors reported to conduct all the mentioned activ-ities (as one developer put it: ‚ÄúThese are all reasonable things to
do‚Äù [r490]). Nevertheless, the activities receive different empha-
sis. In particular, contributors reported practices mostly related toincreasing their awareness (i.e., ‚Äúan understanding of the activities
of others, which provides a context for your own activity‚Äù [14]).They checked whether similar work had already been performedby consulting (in this order of frequency) the issue tracking sys-
tem, previous PRs, project communication channels, and exter-
nal branches/forks. In the ‚Äòother‚Äô Ô¨Åeld, respondents added thatthe sources are checked both to get inspiration from similar workand to ensure that the work is not going to be duplicated effort(e.g. ,‚ÄúI always create a Bug in Bugzilla to track the work if there is
no existing bug‚Äù [r51]). The top experienced contributors (metric:
top.10.perc.contrib ) said that they do not need to update awareness
because they maintain mental models of the status of the project: ‚ÄúIalmost always know what‚Äôs going on [in the issue tracker], on the
mailing lists, in the PR queue, so I have an idea how relevant my
PRs are long before I start working on them.‚Äù [r439]
Work practices followed after coding.
We asked developers to rate 5 common practices with a 4-level
Likert scale. The ‚Äòother‚Äô Ô¨Åeld was Ô¨Ålled in by only a few partici-
pants (1%), mostly to clarify their previous choices.
When the coding is Ô¨Ånished and contributors are ready to sub-
mit a pull request, most developers declared they do not recheck
whether similar work has been accomplished in the meanwhile‚Äîa
contrast to what they report to do before starting to code. The ac-
tivities that developers described as the most frequent before sub-
mitting a PR are formatting the code according to the project‚Äôsguidelines and running tests against the completed code. Some re-spondents complained how there was a lack of support for these
activities in the project (e.g. ,‚ÄúI WOULD run tests and format ac-
cording to guidelines but there are no tests or guidelines on this
project ‚Äù [r5], ‚Äúno tests available in this repo, but normally I would
run tests‚Äù [r1]).
RQ1.2: How do contributors assess their code?
We sought to understand how contributors evaluate the quality of
their code before submitting it as a PR. Examining the quality of
288validation scriptsWHVWLQJ√ØSHHUbranching strategyWHVWLQJ√ØVDQGE oxadvicestandard practicesaddress issuemakes sensecommit qualitycoveragecode revie Z√ØSHHUcode qualitydiscussionno assessmentcode revie Z√ØDIWHUVHOIDSSUHFLDWLRQbuildingdocumentationVHOIFRQWDLQHGcontinuous integrationstatic analysisproject complianceWHVWLQJ√ØPDnualcode revie Z√ØVHOItesting
0
20
40
PHUFHQWDJHRIUHVSRQVHVhow quality is evaluated
what is evaluated
Figure 3: How contributors determine their contributions‚Äô quality.
contributions is very important for contributors; similarly, contri-
bution quality is the number one factor integrators examined to de-
cide whether to accept a contribution or not [27]. To investigate
how contributors assess the quality of their contributions, we askedthem a compulsory open-ended question. Although the questionwas speciÔ¨Åc on how contributors evaluate quality, the analysis of
the results also revealed what contributors examine in their PRs.
(Figure 3 summarizes these results.)
How quality is evaluated.
The most common mechanism that contributors use to assess the
quality of their contributions is testing. More than 60% of the re-
sponses mentioned employing a form of automated testing (running
on the developer‚Äôs workstation or continuous integration servers).
This highlights the practicality of automated testing for evaluat-
ing contributions and complements the integrator‚Äôs opinion of test-ing as a contribution evaluation mechanism [27]. Around 10%
said they also perform
manual testing of their changes by running
their contribution against the main repository, either in specialized
sandbox environments or by their peers (i.e., collocated colleagues
[r125] or other project developers [r198]).
On the tool front, 7% of the respondents use static analysis tools
for automatically evaluating their contributions. A wide range of
these tools were reported, mostly belonging to three categories:lint tools that detect inconsistencies in coding style and target spe-ciÔ¨Åc programming languages (e.g. ,
PMD in Java), style checkers
that highlight formatting inconsistencies with respect to a prede-Ô¨Åned style (e.g. ,
CHECKSTYLE ), and formal method tools to detect
logical inconsistencies (e.g. ,CPPCHECK ). As an extra step, contrib-
utors build the software to catch simple errors with the compiler.
Building usually also invokes the project‚Äôs test suite.
A complementary examination mechanism that contributors men-
tioned is code review; usually (20%) of it is performed by the con-
tributors themselves before they submit a PR. During code review,the contributors examine properties in the source code and docu-
mentation as discussed above. When conditions allow, contributors
ask their
peers to do a code review before they submit a pull re-quest; the peers may be colleagues ( e.g., [r57,172]) or other mem-
bers of the project community [r382]. Some contributors may rely
on code reviews by the project owners or the community after they
submit the pull request (‚ÄúOthers, which have commit access to therepository check the changes if there are any [breaking] changes.‚Äù[r399]). A related response (given by 4% of the respondents) men-tioned that they do not explicitly assess the quality of their PR
as they either believe it is the project owner‚Äôs responsibility (e.g. ,
[r217,392]) or they count on immediate acceptance (e.g. , [r245]).
Finally, contributors examine the PRs‚Äô quality through
experience
(e.g. ,‚ÄúI try to look at what I‚Äôm presenting as if someone else had
written it and ask myself if I‚Äôd hate dealing with the merge or hav-
ing the code in my project with respect to functionality, clarity, andconciseness/elegance (in that order)‚Äù [r238]).
What is evaluated.
One of the top priorities for contributors when examining PR
quality is compliance, which had many manifestations in our re-
sponse set. The most common was compliance to project PR orcoding guidelines (e.g. ,‚ÄúBy following the contribution guidelines
for a PR of that repository.‚Äù [r164]). Contributors also try tocomply to de facto guidelines manifested in the original repository,
mainly code formatting (e.g. , [r105,584]) and design (e.g. , [r252]).
Another compliance form is adherence to
standard practices. Con-
tributors try to increase their chances of acceptance by followinglanguage code styles and design principles (e.g. ,‚ÄúFollowing clean
code principle and checking code style‚Äù [r143]).
On a related note, contributors examine two technical quality as-
pects:
code quality and commit quality. Code quality is usually as-
sessed subjectively by examining factors such as readability, clar-
ity, and whether the change is minimal (‚Äúthe code [...] contains
only the minimal amount of code change necessary to implement
the feature‚Äù [r15]). Several contributors reported that they strive tomake high-quality commits. For some developers, this means thatcommits are ‚Äúatomic and [can be] merge[d] at time of sending ‚Äù
[r74], while others assume a more aesthetic view: ‚ÄúAre the commitmessages clear and do the commits in the PR tell a story?‚Äù [r74]
In pull-based development, PRs are usually submitted to projects
without prior planning. To increase the chances of acceptance, con-
tributors eagerly examine the PR‚Äôs
suitability by analyzing whether
the PR fully addresses the issue it is trying to solve. The term ‚Äòis-
sue‚Äô is used in the broader sense of an existing problem the devel-
opers are addressing (e.g. , [r27,538]), even though in some cases it
is associated with existing bug tracker issues [r306].
Contributors strive for their PRs to be self contained (e.g. ,‚ÄúIt
should be focused on the feature to implement (or bug to Ô¨Åx). Noth-ing unrelated to the topic should be in there. ‚Äù [r52]) and they also
try to ensure that the
documentation of both their code and the PR
eases the comprehension of the PR and meets assumed project stan-dards (thereby enhancing compliance).
RQ1.3: How are changes communicated?
In the question about contributors‚Äô work habits before coding, weasked about how often they communicate the changes to the projectcore team. Most of the respondents (59%) reported they did notcommunicate with the core team or that they communicated with
the team very occasionally (see third item from the bottom in the
left-hand side of Figure 2). We analyzed the communication behav-ior in relation to the size of the projects (metric:
mean.prs ) reported
by the respondents. Although we found a signiÔ¨Åcant relationship(p < 0.001, assessed using the œá
2with df=6) between the size of
the reported project and the reported frequency in communication,which goes in the direction of communicating slightly more when
2890 20 40 60 80 I do not communicate my intended 
changes Other Twitter Skype/Hangouts/Other form of 
synchronous communication Face to face IRC Email Pull request: I open a minimal PR 
describing problem and potential fix Issue tracking: I open an issue 
describing problem and potential fix 
percentage of answers How do you communicate the intended changes? 
Figure 4: How contributors communicate with integrators.
projects are larger, the strength of the relationship2is very weak
(Cramer‚Äôs V = 0.14).
In a subsequent multiple choice question, we inquired about the
communication means contributors use when they decide to com-
municate on a change. The summarized results are presented in
Figure 4. Many respondents explained that they open an issue in the
tracker or a new PR, or both. They use emails or more synchronouscommunication channels (e.g. , IRC or instant messaging) less fre-
quently. This is in line with the Ô¨Åndings by Guzzi et al. [28], who
observed a shift in OSS developers‚Äô communication habits from
traditional channels, such as mailing lists, toward more structured
channels, such as issue trackers.
Those that added information in the ‚Äòother‚Äô Ô¨Åeld (6%), mainly
speciÔ¨Åed the communication channels they use. Many mentioned
forums (e.g. ,‚Äúonline forums for the project ‚Äù [r499]), others IRC-
like solutions (e.g. , Gitter [r76,77,399]) or project managements
tools ( e.g.,‚ÄúProject Management tool such as V ersionOne‚Äù [r61]),
and a few reported to use email-based communication (e.g. ,‚ÄúMail-
ing list to get the opinion of the community and core team‚Äù [r286]).
RQ2: What are the challenges of contributing?
To Ô¨Ånd the pain points experienced when contributing through the
pull-based model, we explicitly introduced a mandatory open-endedquestion in the survey and asked respondents to state the biggestchallenge they faced when contributing PRs. We learned that chal-
lenges revolve around three main themes: challenges about writing
the
code for the contribution, challenges on the tools and model to
be used for submitting the contribution, and challenges pertainingto
social aspects.
These themes are linked to the Ô¨Åner-grained challenges expressed
in the answers. For example, a challenge that emerged is project
compliance, which in some cases relates to the code theme (e.g. ,
‚Äúusing the project code style‚Äù [r66]), while in others it relates to
the social theme (e.g. ,‚ÄúNot knowing all the rules/process ‚Äù [r62]).
The results are summarized in Figure 5. From left to right, we Ô¨Årst
classify the answers on the contributor‚Äôs rank (i.e., whether it isin top 10% PR contributor or not), then we show the three main
2We obtained similar results aggregating into two groups both size
(i.e., ‚Äòsmall‚Äô and ‚Äòmedium‚Äô vs. ‚Äòlarge‚Äô) and communication fre-
quencies (i.e., ‚Äònever‚Äô and ‚Äòoccasionally‚Äô vs. ‚Äòoften‚Äô and ‚Äòalways‚Äô).
	


		
	
	


	

	
	




		 	
	
Figure 5: Challenges contributing with the pull-based model.
themes and how the answers Ô¨Çow into the speciÔ¨Åc challenges. The
thickness of a line represents the number of responses.
We expected the top contributors (metric: top.10perc.contrib )t o
be less affected by tools and model and code related challenges
given their greater experience, but to our surprise, both types ofcontributors had a very similar distribution of challenges amongthe three main themes. The theme reported by the majority of
the respondents to be the most challenging when contributing in
a pull-based model is the
social one, followed by code and tools
and model, respectively. We discuss the results in this order.
Social aspects.
The social theme is connected to most of the reported challenges
in different ways, with the most prominent being responsiveness.
More than 15% of the survey participants mentioned that gettingtimely feedback, if any, for their pull requests is hard and usuallyrelated to people issues (e.g. ,‚ÄúThe owner of the repo doesn‚Äôt ever
respond to the PR and leaves it hanging open forever ‚Äù [r15], ‚Äú[there
are] projects with lots of open PRs and few actually being accepted ‚Äù
[r98]). This situation seems to generate frustration for the contrib-utors and they start to lose interest in the project: ‚Äú Malaise and
abandonment. Few things are more frustrating than opening a PR
and having it go nowhere‚Äù [r698], ‚ÄúWhen contributing to less ac-
tive projects, it can be really frustrating to have a PR sit untouched
for months, since by the time the author gets back to it, I may havegiven up on it and no longer care‚Äù [r665]. Respondents speciÔ¨Åed
that they would rather receive a clear reject than have no response to
their PRs (‚Äúit‚Äôs annoying to go to the effort of making one and haveit ignored... Rejected is better . ‚Äù [r85]). Getting feedback on the
quality of their work is deemed important for improved
prediction
ofacceptance of future PRs. Not knowing whether a PR will be
accepted poses difÔ¨Åculties and stress on contributors (e.g. ,‚ÄúWhen
my own code depends on a PR, and I don‚Äôt know if the PR will getaccepted that causes uncertainty and stress.‚Äù [r618]).
Poor, delayed, but also general
communication was reported as
another issue. Some contributors speciÔ¨Åed that they Ô¨Ånd it chal-lenging to
explain the rationale of their changes, which can af-
290fect whether their PRs are thoroughly investigated (‚ÄúSometimes it‚Äôs
hard to explain the need for some changes. Some teams will imme-
diately reject them without analyzing them properly.‚Äù [r491])
A few contributors (e.g. , [r190,563]) reported a fear ofrejection
as they found it personally embarrassing when their work was judged
to be inadequate by people they have no relationship with. This fearcan be exacerbated by the various challenges in interacting with
core team members that many respondents reported (e.g. ,‚ÄúFear
of looking stupid. Fear of rude response.‚Äù [r190], ‚ÄúDiscourag-
ing project owners‚Äù [r228]). In particular, respondents describedsocial challenges related to
politics or how the project is governed
(e.g. ,‚ÄúProject owners who really don‚Äôt want contributions. ‚Äù [r122],
‚ÄúPolitics, or project owners not wanting a Ô¨Åx or change, or notactively maintaining it.‚Äù [r526]),
egotism and general arrogance
(e.g. ,‚ÄúPeople tend to merge only PRs for issues THEY see as bug.‚Äù
[r360], ‚ÄúUnconstructive/hostile maintainer attitude‚Äù [r536]), and
handling divergent opinions (e.g. ,‚Äúgetting all [...] to agree with a
feature you propose in a PR.‚Äù [r251]).
Furthermore, contributors reported that it is challenging to Ô¨Ånd
enough time to work on the project as they wish (e.g. ,‚ÄúTime to work
on complicated issues despite working full time‚Äù [r461]) and to pro-
pose contributions that Ô¨Åt in the project‚Äôs big picture and make it
grow instead of addressing their needs only (e.g. ,‚ÄúMaking sure it‚Äôs
in the interest of the project and not just mine.‚Äù [r183]).
Code aspects.
The code theme also permeates a number of challenges. The
most frequently reported one is understanding the code base of the
project, including layout and architecture (e.g. ,‚ÄúRead others code
and get understanding of the project design‚Äù [r564]). This problem
seems to be magniÔ¨Åed by project size and a lack of documentation
(e.g. , ‚Äú[there is] no guideline or documentation‚Äù [r223], ‚Äú Missing
knowledge about inner workings of a project [...] sometimes caused
by missing documentation‚Äù [r561]).
Contributors also Ô¨Ånd it difÔ¨Åcult to assess their changes‚Äô impact
on the rest of the code base ( impact analysis). Sometimes this is re-
lated to their limited understanding of the project (e.g. ,‚ÄúEnsuring
that my PR doesn‚Äôt have unintended side effects due to not being in-
timately familiar with the entire code base.‚Äù [r202]), and also to the
social theme since awareness is not maintained by all contributors
(e.g. ,‚ÄúBecause of the great complexity of our code, contributions
by others that are not directly related to my work can nonetheless
affect it, and our contributions are not necessarily synced or com-
municated.‚Äù [r229]). To tackle this, and avoid regression, contrib-
utors explained they would rely on testing, but a proper test suite
is not always available and running, and developing tests is also achallenge ( e.g.,‚ÄúIf there isn‚Äôt a good testing infrastructure in place,
then I‚Äôm not sure how to contribute tests related to a PRs‚Äù [r656]).
Writing PRs with proper
code quality is mentioned as the only
issue by 13 developers. Another 7% reported that being compliantwith the project style and guidelines is challenging. The
project
compliance on code regards style both at a low typographical level
and at a higher design level; this challenge also highlights the dif-Ô¨Åculties in knowing the format for PRs, commit messages, etc.
( [r277]). Some respondents explained that this challenge is due totribal knowledge, i.e., information only known within the project
team and not explicit to the outside world (e.g. , [r500,659]).
Tools and model.
Respondents reported challenges regarding the tools and model
less frequently. Among those, the use of gitand handling conÔ¨Çicts
between branches are the most prominent ones, especially for seem-ingly less experienced developers (e.g. ,‚ÄúUsage of git is not intu-
itive. Especially for me as [one] who does not contribute regu-larly, it is every time a challenge to [use it]‚Äù [r158], ‚Äúwhen projects
try to enforce workÔ¨Çow through branches, that is often confus-
ing.‚Äù [r120]). Some respondents mentioned having problems with
the local
infrastructure setup needed for development and testing.
The few explicit answers about the pull-based development model
mostly relate to its learning curve ( e.g., [r572]). More respondents
mentioned GitHub as a challenge, especially when it comes to hav-
ing discussions within PRs, thus connecting it to the social theme
(e.g. ,‚ÄúThe comments on a PR can get unwieldy quickly. Without
threading it can be hard to follow a conversation‚Äù [r102], ‚Äúeffec-tively communicating with other users over github‚Äù [r329]).
Reducing barriers for new contributors.
We further investigated what respondents think projects should
do to reduce barriers for new contributors. This was mapped in thesurvey to an open- ended question that we manually coded. The top5 barriers that emerged account for more than 50% of the answers.
The Ô¨Årst barrier (speciÔ¨Åed by more than 20% of the contributors)
deals with having good
guidelines on getting started with the de-
velopment and testing environment, on code style/formatting con-ventions, on the contribution process, and on communicating with
project owners. The second, third, and fourth barriers follow with
a very similar frequency (ca. 15%). For the second barrier, respon-dents explained that project members should have more
empathy
towards new contributors, providing encouragement, mentoring,
fairness, and having an overall positive attitude (e.g. ,‚ÄúEngage in
positive, responsive discussion [...] Giving a positive Ô¨Årst experi-
ence goes a long way.‚Äù [r202], ‚ÄúMaintain a ‚Äúpositive‚Äù culture; be
friendly, polite etc‚Äù [r73]). The third barrier reiterates on the con-
cept of responsiveness: respondents stated that improving it would
remove a serious barrier for new contributors, especially as theyneed more feedback on their work (e.g. ,‚Äúrespond to issues/PRs/list
posts in a timely fashion. Even just acknowledging the issue andsuggesting an attack plan is immensely helpful.‚Äù [r504]). The
fourth barrier is about the need for a clear project
roadmap and
a comprehensive task listwith open issues, including recommen-
dations for newcomers (e.g. ,‚ÄúThey should mark the open issues
with the level of difÔ¨Åculty, like these issues are easy and beginnerscan resolve them‚Äù [r27]). Finally, 12% of the respondents reported
better code
documentation as important to attract new contributors.
5. DISCUSSION
We now discuss our main Ô¨Åndings, contrasting them with Ô¨Ånd-
ings about the integrators‚Äô perspective. We suggest recommenda-tions for practitioners and consider the implications for researchers.
5.1 Main Ô¨Åndings
Awareness. Contributor practices for increasing awareness in the
pull-based development setting are not substantially different frompractices in settings where no social features are available. Sim-ilar to participants in other studies of OSS contributors [36, 38,
44], PR contributors Ô¨Årst attempt to build an understanding of the
project‚Äôs current status by examining existing contributions, theproject‚Äôs issue database, and any contribution guidelines. Whatwas surprising was that they did not explicitly discuss the socialfeatures [11] of GitHub as a source of information as much as (we)
expected. Actually, only one respondent speciÔ¨Åcally mentioned the
use of a GitHub social feature to build awareness about a project(‚ÄúI see changes in RSS channel ‚Äù [r600]). This situation raises ques-
tions about whether social features are useful to contributors. They
might, however, rely on subtle social signals that environments like
GitHub provide, without realizing it.
291Moreover, while most contributors report that they use the issue
tracker for Ô¨Ånding similar issues or PRs, at the same time, many
PRs are rejected because they are duplicate or superseded [25]. In-
tuitively, since contributors report that they are aware of the projectstatus before they start working on a contribution, one would ex-pect that very few PRs would be rejected for such reasons. Thisindicates a critical step between contemplating a contribution and
actually creating it, and it underlines the importance of improving
how awareness about projects is created and maintained.
We also noticed an interesting paradox. Contributors deem it is
important to spend time checking for existing work related to the
PR, but once they start coding a PR, they rarely (if ever) commu-
nicate the intended changes to the core team. The paradox is thatthey report it is important to be aware of what is going on in theproject, but they do not express the intention to personally investtheir own time to increase the overall awareness in the project.
Furthermore, the fact that contributors often prefer to use com-
munication means other than PRs (see Figure 4) hinders aware-ness. Not only are multiple discussions spread across different PRs,but also communication becomes scattered over multiple channels,
making it difÔ¨Åcult, if not impossible, for new contributors to under-
stand the rationale behind a change.Transparency. The pull-based development model, in conjunction
with the social media functions offered by GitHub, makes contri-butions and their authors more prominent than in other contribu-
tion models. As Dabbish et al. put it: ‚Äú[it makes] the work vis-
ible‚Äù [12]. Indeed, various developers discuss whether [1, 50] or
not [8] GitHub proÔ¨Åles should be the new de facto CV for devel-
opers. In our survey, we included an additional question asking
why participants contribute to the chosen project. We introduced
a closed question with 7 non-mutually exclusive answer options
(based on our analysis of the related literature) and an open textÔ¨Åeld to specify ‚Äòother‚Äô reasons. While most answers validated well-known motivations for contributing to OSS (e.g. , the main moti-
vation (60% of the respondents) was ‚Äòusage‚Äô of the project theycontribute to), approximately 35% of the respondents explainedthat they contributed for reasons related to personal career devel-opment, while 23% of the respondents mentioned enrichment of
their public proÔ¨Åle/CV as a motivating factor ( e.g.,‚ÄúMaking con-
tributions to [project] makes it easier for me to get new clients‚Äù
[r121]). Lerner and Tirole formalized that contributions to OSS
projects are also driven by a career concern incentive. This incen-
tive increases in strength as the audience‚Äôs visibility into the perfor-
mance increases [33]. Some of our respondents also indicated that
contributions to GitHub beneÔ¨Åt their career growth (e.g., ‚ÄúMy con-tribution to [projects] allowed me to obtain a job within my favorite
subjects‚Äù [r437].
Additionally, several contributors fear that rejection of their PRs
may harm their reputation. If this fear of rejection is caused bytransparency, as also suggested in the previous analysis by Dab-bish et al. [12], we have additional quantitative evidence about its
beneÔ¨Åts but also about potential risks.
Responsiveness. More than 100 participants complained about the
poor responsiveness from integrators. SpeciÔ¨Åcally, they reported
that they were worried they would not get a response or that theywould get it too late to be relevant. They also suggested that im-
proving the speed of responding to a PR would be an effective way
to reduce barriers for newcomers. This complements the Ô¨Åndingsreported by Zhou and Mockus on an analysis of the ecosystems ofMozilla and GNOME [54]. Zhou and Mockus found that ‚Äúlow at-tention [...] a se videnced by a too-rapid response to issue reports‚Äù
reduces the chances of a newcomer becoming a long-term contrib-utor. We note that our data is drawn from self-reported behaviorand suggestions given by contributors, while the study of Zhou andMockus was mostly performed on traces left on software reposito-ries, and therefore, the different development settings may lead todifferent ways of tuning out unwanted contributions.
Asynchrony. One of the distinguishing characteristics of the pull-
based model is asynchrony among the production of a contribution,
its evaluation, and its integration. Asynchrony is a pervasive con-cern for both contributors and integrators and its effects are usually
detrimental. Asynchrony hinders the observability of the overall
status of a project and burdens integrators and contributors with ex-tra communication obligations. Recently, several high proÔ¨Åle com-panies ( e.g., Facebook [22] and Google [32]) have moved away
from the pull-based model, while others use strictly bounded code
review processes and branching strategies (e.g. , Microsoft [5, 2])
to increase development speed for their internal repositories (how-
ever, they still use pull-based development for OSS projects).
From a distributed systems theoretic standpoint, mitigating the
results of asynchrony is impossible [42]. Therefore, integratorsand contributors should agree on minimal communication proto-cols that increase each other‚Äôs awareness and rendezvous pointsfor mandatory information exchange. In certain cases ( e.g., col-
located development), projects should be prepared to abandon the
pull-based model in favor of more direct feedback loops.
5.2 It takes two to tango
The pull-based development mechanism, and its GitHub imple-
mentation in particular, aims to facilitate the information exchange
between two interacting parties sharing a common goal, namely in-
tegrating a change into an existing code base. Due to the closeness
and asynchrony of the interaction, it is expected that good or badpractices of one interacting part will reÔ¨Çect on the other. Compar-ing this research with our previous work [27], we found a number
of technical and social pain points experienced by both integrators
and contributors. We report on these below.Quality. Contribution quality is a major concern for contributors.
It is one of the most frequently reported challenge items and alsosomething they deeply care about before PR submission. Not sur-
prisingly, quality is also a top priority for integrators. A cross ex-
amination of the factors that contributors and integrators examinein PRs reveals that there is also a high overlap in terms of com-pliance/conformance and code quality as top factors. Moreover,
automated testing is used by both integrators and contributors as
a commonly accepted way to ensure contribution quality. We hy-pothesize that this shared understanding of quality, and the ways ofachieving it, is the result of widely accepted technical norms. Posi-tively, this helps the majority of contributions to be accepted (85%),
while rejections are usually not due to technical reasons [25].
Lack of process. The pull-based model on GitHub lacks a spe-
ciÔ¨Åc patch acceptance process (as is the case with Gerrit [40] orCodeFlow [2]). Some integrators Ô¨Ånd the lack of a well-deÔ¨Åned
acceptance process (e.g. voting and sign-off) disturbing enough to
move to other reviewing platforms. In addition, experienced con-tributors are used to searching for PR process documents, thoughsuch policy documents are often not present in smaller projects. AGitHub-wide acceptance process deÔ¨Ånition and enforcement mech-
anism might be beneÔ¨Åcial to both integrators and contributors and
might deter one-off, low-quality contributions. More research isneeded to explore options concerning process policies.Workload and responsiveness. Integrators on large, active projects
reported that they have problems handling and prioritizing the largenumber of PRs those projects attract; perhaps as a result, contrib-utors complained about the lack of responsiveness. However, inte-grators also protested about the lack of responsiveness from con-
292tributors when they request additional changes during a code re-
view and complained about ‚Äúhit-and-run‚Äù PRs. These concerns
may be the result of the pull-based development model that sim-
pliÔ¨Åes experimentation with contributions to projects without re-ducing the reviewing burden on both parties.Communication tooling. A signiÔ¨Åcant portion of both integra-
tors and contributors Ô¨Ånd that the communication facilities afforded
by the GitHub PR mechanism are lacking in terms of immediacy
and structure. This hinders the effective discussion of high-levelconcerns (e.g. , system design) and has a negative impact on the
centralization of information about a contribution. Indeed, many
contributors and integrators reported that they use external tools,
mainly supporting synchronous communication ( e.g., IRC or in-
stant messaging), to exchange information. Two key features thatare missing, as reported from our respondents, are threaded com-munications and voting mechanisms.
Communication failures. Communicating about the rationale for
PRs was reported as difÔ¨Åcult not only by contributors, but also by
integrators wishing to understand the reasons for a PR. Integratorscomplained that discussions on PRs diverge from technical content,
while contributors expressed their concerns about having to cope
with project politics in order to get their contributions accepted.Contribution rejection is a concern for both parties: integrators re-ported that it is not easy to explain the rational behind a rejection,while contributors stated that it is hard to accept the rejection. We
conjecture that the above shared difÔ¨Åculties are the result of a com-
munication process that, while open and accessible, is lacking interms of immediacy and traceability.
5.3 Recommendations for practitioners
We present a set of recommendations that can help streamline
the experience for contributors when working with integrators inthe pull-based model. For one-off contributions, these guidelinesrevolve around two basic principles: minimizing friction and maxi-
mizing awareness. For more long-term involvement in a project, it
is crucial to build and maintain a contributor proÔ¨Åle.Minimizing friction. Contributions that are small and isolated are
easier for integrators to process. In previous work [51, 3, 25, 27],the size of the change was one of the most important factors re-lated to acceptance. This is because the impact of the change is
more easily evaluated, especially if the change does not cross log-
ical functionality or design boundaries. The contributors shouldalso make their changes adhere to guidelines and learn how to use
the underlying tools (
git), as this saves review time.
Projects should provide a policy or comprehensive set of con-
tribution guidelines. These guidelines should at least provide de-tails about the expected code style, commit format, PR process,and available communication options. Well-thought- out guidelineswill help developers format contributions using the expected style
and can act as a reference in code review discussions. Moreover,
projects should invest in good tests. Not only would contributors
gain conÔ¨Ådence about their contributions by testing them locally,but by doing so, integrators will evaluate them more quickly [25].
Automation is also important and it should at least cover the de-
velopment environment setup. Ideally, the contributor should beable to set up a fully working development environment by runninga simple command; existing tools allow this (e.g. , Vagrant and An-
sible). Projects should also invest time to set up automatic quality
evaluation of incoming contributions. This can include code style
compliance checks and perhaps more sophisticated static analy-sis tools. In the case of GitHub, external services are available toenable continuous integration (e.g. , Travis) and code quality ( e.g.,
Code Climate) monitoring on a per contribution basis.Maximizing awareness. Awareness can be increased by contact-
ing the development team using real-time communication channels(e.g. , IRC or its evolved counterpart G
ITTER , which is better inte-
grated in GitHub) or by following the minimal PR idiom [7] (de-
pending on project preferences). Integrators should be both proac-
tive, by establishing (and perhaps even documenting) a professional
communication etiquette, and reactive, by following discussions
and intervening in cases where discussion diverges from the eti-
quette. Similarly, contributors should be available after a submis-
sion to promptly discuss the results of the code review and thusmitigate some of the negative effects of asynchrony.Long-term involvement. For contributors seeking long-term in-
volvement in project communities, essential steps are proÔ¨Åle build-
ingthrough a stream of excellent contributions and participation in
other community activities (e.g. , discussion of issues); integrators
both evaluate [34, 27] and prioritize [27] work using a mixture ofsocial signals and developer track records, whose visibility is en-
sured by the transparency of the model.
5.4 Implications for researchers
Our work uncovers several future research directions.
Work prioritization. Low responsiveness is one of the most re-
curring challenges experienced by contributors. Integrators alsoreported problems in prioritizing PRs [27]. Automating the pri-
oritization of PRs could help integrators allocate their time moreeffectively but also show contributors the status of their PRs withrespect to the overall queue. Automated prioritization could takeadvantage of explicit integrators‚Äô preferences (e.g. , place bug Ô¨Åxes
Ô¨Årst), thus making contributors aware of such choices in a poten-tially automatically generated guideline. Initial work in this direc-tion has been carried out by van der Veen et al. [47].
Estimated time for merging. A widespread usability heuristic
states that a ‚Äúsystem should always keep users informed about whatis going on‚Äù [37]. This is often achieved, for example, throughprogress bars in application UIs. Contributors‚Äô frustration aboutnot knowing the status and fate of their PRs indicates that hav-ing a capability for estimating the time for merging a contribution
would be valuable. If the estimation engine could provide an indi-
cation on the most signiÔ¨Åcant factors considered for the prediction,contributors could take advantage of this prediction to understandwhat could be improved to speed up acceptance (e.g. , splitting a
PR into self-contained tasks), which would also help contributorsspeed up their decision on whether to continue contributing to aparticular project. Previous research has estimated merging timefor patches [30], closing time for issue reports [19, 53], etc. In the
context of PRs, Gousios et al. [25] developed a machine learning
approach to predict a pull request‚Äôs merge window. In addition,Vasilescu et al. [48] developed models to determine PR processing
time. This is a ripe opportunity for researchers to support a widepopulation of developers.
Untangling code changes. Integrators reported that code under-
standing and reviewing is simpliÔ¨Åed if code changes pertain to a
single, self-contained task [2, 27], however, contributors reportedthat creating them is a challenge. Recently, researchers have pro-posed automated approaches to split changes into self-contained
tasks [29, 13]. It is an interesting opportunity to apply these meth-
ods and integrate them into the pull-based model workÔ¨Çow.Impact analysis on PRs. All contributors and integrators are in-
terested in knowing the impact of the proposed PRs beyond the
changed code. The pull-based development model is a Ô¨Åne op-
portunity to provide results of impact analysis research to a broadcommunity and test its effects on the Ô¨Åeld. Tools‚Äô results could beintegrated in the PR interface as an optional service.
293Improved awareness and communication. Our respondents re-
ported the need to build awareness before working on a new PR, but
expressed little intent to communicate changes to the core project
team before starting work. Understanding this phenomenon is aninteresting avenue for further research on collaboration behavior inknowledge-intensive settings. Moreover, a number of drawbacksemerged in communication occurring within PRs, despite the ad-
vantage of being close to the changed code. Particularly, commu-
nication support should be improved for discussing high-level con-cerns and for scaling to longer discussions. Multidisciplinary stud-ies involving user interface designers, communication experts, and
software engineering can be designed and carried out to determine
how to improve communication within PRs.
5.5 Design implications
The pull request model offers a simple, yet solid basis for dis-
tributed collaboration. The lowered barrier to entry, transparencyof social platforms, and integration of both analysis tools and re-viewing mechanisms help projects expand their collaborator baseseamlessly. Considering their continuous growth in popularity, it is
reasonable to expect that pull requests will become the minimum
unit of software change in most collaborative projects. Our currentand previous Ô¨Åndings hint at the design of features that will facili-tate this transition. We imagine a contribution platform, which we
call
PR.next , that optimizes the contribution experience and helps
integrators handle the reviewing load by means of intelligent algo-
rithms, which we describe in the following.
Initially, PR.next assists contributors in evaluating their contri-
bution proposals against the state of the project. A contributor ex-
presses the proposed change in natural language and the system
searches i) the code base and ii) open or recently closed contribu-tions for similar changes. Then,
PR.next helps contributors for-
mat their contributions by running continuous integration and style
checks in a private staging space before the change becomes pub-
lic. In the mean time, PR.next compares the contributions to other
in-Ô¨Çight contributions and warns about duplicates. PR.next also
helps integrators prioritize their work. When a new contribution ar-
rives, PR.next combines information from multiple analysis tools
(e.g. , continuous integration) to rank pull requests according to
their readiness to be reviewed. The system gives integrators visualhints ( e.g., predicted time to merge) and mines information, such
as discussion status or voting results, from other in-Ô¨Çight contribu-
tions to help them evaluate priority. At the project level,
PR.next
supports community voting mechanisms to help projects evaluate
contribution desirability, where votes are ranked for importancebased on voter characteristics in the social (voter status in com-munity) or dependency (voter‚Äôs project status within the software
ecosystem) graph.
6. LIMITATIONS
We designed our survey with the stated aim of gaining insights
on a novel mechanism of collaboration in distributed software de-
velopment. For closed selection questions in the survey, the re-
sponse categories originated from our review of the literature and
also from our prior experience working with and researching [25,27] PRs and the pull-based model. The questions were phrased toavoid leading the respondent to a speciÔ¨Åc answer and were vali-
dated through (1) consultation with colleagues expert in qualitative
research, (2) a formal pilot run, and (3) several mini-runs of thesurvey. Despite our best efforts, there could be several reasons whyour study is limited.Internal validity ‚Äì Credibility. We used coding to classify the
contributors‚Äô responses in open-ended questions. The coding pro-cess is known to lead to increased processing and categorizationcapacity at the loss of accuracy of the original response. To allevi-ate this issue while coding, we allowed more than one code to be
assigned to the same answer. Question-order effect [43] ( e.g., one
question could have provided context for the next one) may lead the
respondents to a speciÔ¨Åc answer. One approach to mitigate this biascould have been to randomize the order of questions. In our case,we decided to order the questions based on the natural sequence ofactions to help respondents recall and understand the context of thequestions asked. Social desirability bias [18] (i.e., a respondent‚Äôs
possible tendency to appear in a positive light, such as by showingthey are fair or rational) may have inÔ¨Çuenced the answers. To mit-
igate this issue, we informed participants that the responses would
be anonymous and evaluated in a statistical form.Generalizability ‚Äì Transferability. Our selection of projects and
contributors to GitHub projects using the pull-based model may notbe indicative of the average project. Previous work [25] found that
the median number of PRs across repositories is 2; in our sampleand considering the initial selection of projects, the smallest projecthad more than 400. We expect that if the study is repeated usingrandom sampling for projects, the results may be different. This
may affect the results on obstacles such as low responsiveness and
inefÔ¨Åcient communication, as average projects do not use PRs ina high capacity. To reduce other limitations to the generalizabilityof our work, we did not impose other restrictions on the sampleprojects, such as programming language or use of technologies.
Moreover, GitHub is only one, albeit the biggest, of the social
coding sites featuring the pull-based development model and it hasspeciÔ¨Åc social media features. While this model remains the sameacross all these sites and the social features are similar, the im-
plementation of several GitHub features might inÔ¨Çuence the devel-oper‚Äôs opinions of the model. In both our question set and our in-
terpretation of the results, we avoided direct references to GitHub‚Äôsimplementation of the mechanism. However, bias in the contrib-utors‚Äô answers could not be completely eradicated, as can be wit-
nessed by the fact that many open-ended answers included direct
references to GitHub or tools in its ecosystem (e.g. , Travis CI).
7. CONCLUSIONS
We presented our investigation of the pull-based development
model as implemented in GitHub from the contributors‚Äô perspec-
tive. Our goal was to gain knowledge on the work practices of pull
request contributors and the challenges they face. We make thefollowing key contributions:
(1) A publicly available [26] iteratively-tested survey with ques-
tions for eliciting contributors‚Äô practices in the pull-based model,
and the anonymized answers of 760 respondents.
(2) The set of open-ended questions we coded manually, and the
R analysis scripts for the overall data analysis.
(3) A thorough analysis of the answers to our research questions
on contributors‚Äô work habits, PR preparation, and open challenges
in contributing with the pull-based model.
(4) A discussion comparing our Ô¨Åndings with previous literature,
recommendations for practitioners using the pull-based model, anddata-derived directions for future research and design.
Among our Ô¨Åndings, we identiÔ¨Åed reducing response time, main-
taining awareness, improving communication both in content andin form, and quality assessment as key components for support-ing contributions in the pull-based model. We hope that our in-
sights will lead to merging external contributions more effectively
in practice and to devise improved tools, to support developers inboth creating and handling code contributions more efÔ¨Åciently.
2948. REFERENCES
[1] GitHub is your new resume.
https://news.ycombinator.com/item?id=2763182. Accessed
2016/02/15.
[2] A. Bacchelli and C. Bird. Expectations, outcomes, and
challenges of modern code review. In Proceedings of the
2013 International Conference on Software Engineering,ICSE ‚Äô13, pages 712‚Äì721, Piscataway, NJ, USA, 2013. IEEEPress.
[3] O. Baysal, O. Kononenko, R. Holmes, and M. Godfrey. The
secret life of patches: A Ô¨Årefox case study. In Reverse
Engineering (WCRE), 2012 19th Working Conference on,pages 447‚Äì455, Oct 2012.
[4] C. Bird, A. Gourley, and P. Devanbu. Detecting patch
submission and acceptance in oss projects. In Proceedings of
the Fourth International Workshop on Mining SoftwareRepositories, MSR ‚Äô07, pages 26‚Äì, Washington, DC, USA,
2007. IEEE Computer Society.
[5] C. Bird and T. Zimmermann. Assessing the value of
branches with what-if analysis. In Proceedings of the 20th
International Symposium on Foundations of Software
Engineering, November 2012.
[6] Bitbucket. http://bitbucket.org/. Accessed 2016/02/15.
[7] B. Bleikamp. How we use pull requests to build GitHub.
https://github.com/blog/
1124-how-we-use-pull-requests-to-build-github. Accessed
2016/02/15.
[8] J. Coglan. Why GitHub is not your cv. https:
//blog.jcoglan.com/2013/11/15/why-github-is-not-your-cv/,November 2013. Accessed 2016/02/15.
[9] J. M. Corbin and A. Strauss. Grounded theory research:
Procedures, canons, and evaluative criteria. Qualitative
Sociology, 13(1):3‚Äì21, 1990.
[10] J. W. Creswell. Research design: Qualitative, quantitative,
and mixed methods approaches. Sage Publications, 3rdedition, 2009.
[11] L. Dabbish, C. Stuart, J. Tsay, and J. Herbsleb. Social coding
in Github: transparency and collaboration in an opensoftware repository. In Proceedings of the ACM 2012
conference on Computer Supported Cooperative Work,CSCW ‚Äô12, pages 1277‚Äì1286, New York, NY , USA, 2012.ACM.
[12] L. Dabbish, C. Stuart, J. Tsay, and J. Herbsleb. Leveraging
transparency. IEEE Software, 30(1):37‚Äì43, 2013.
[13] M. Dias, A. Bacchelli, G. Gousios, D. Cassou, and
S. Ducasse. Untangling Ô¨Åne-grained code changes. InProceedings of the 22nd International Conference onSoftware Analysis, Evolution, and Reengineering, SANER2015, pages 341‚Äì350. IEEE Computer Society, 2015.
[14] P. Dourish and V . Bellotti. Awareness and coordination in
shared workspaces. In Proceedings of the ACM conference
on Computer-supported cooperative work, pages 107‚Äì114.ACM, 1992.
[15] N. Ducheneaut. Socialization in an open source software
community: A socio-technical analysis. Computer Supported
Cooperative Work (CSCW), 14(4):323‚Äì368, 2005.
[16] U. Flick. An introduction to qualitative research.S A G E
Publications, 5th edition, 2014.
[17] K. Fogel. Producing Open Source Software. O‚ÄôReilly Media,
Ô¨Årst edition, 2005.[18] A. Furnham. Response bias, social desirability and
dissimulation. Personality and Individual Differences,
7(3):385 ‚Äì 400, 1986.
[19] E. Giger, M. Pinzger, and H. Gall. Predicting the Ô¨Åx time of
bugs. In Proceedings of the 2nd International Workshop on
Recommendation Systems for Software Engineering, pages52‚Äì56. ACM, 2010.
[20] GitHub. https://github.com/. Accessed 2016/02/15.
[21] Gitorious. http://gitorious.org/. Accessed 2016/02/15.[22] D. Goode and S. Agarwal. https://code.facebook.com/posts/
218678814984400/scaling-mercurial-at-facebook/.
Accessed 2016/02/15.
[23] G. Gousios. http://ghtorrent.org/pullreq-perf/. Accessed
2016/02/15.
[24] G. Gousios. The GHTorrent dataset and tool suite. In
Proceedings of the 10th Working Conference on MiningSoftware Repositories, MSR ‚Äô13, pages 233‚Äì236,Piscataway, NJ, USA, 2013. IEEE Press.
[25] G. Gousios, M. Pinzger, and A. van Deursen. An exploratory
study of the pull-based software development model. InProceedings of the 36th International Conference on
Software Engineering, ICSE 2014, pages 345‚Äì355, New
York, NY , USA, 2014. ACM.
[26] G. Gousios, M.-A. Storey, and A. Bacchelli. Pull request
contributors analysis dataset.http://dx.doi.or
g/10.5281/zenodo.46063, Feb. 2016.
[27] G. Gousios, A. Zaidman, M.-A. Storey, and A. v. Deursen.
Work practices and challenges in pull-based development:
The integrator‚Äôs perspective. In Proceedings of the 37th
International Conference on Software Engineering, ICSE
2015, 2015.
[28] A. Guzzi, A. Bacchelli, M. Lanza, M. Pinzger, and A. van
Deursen. Communication in open source software
development mailing lists. In Proceedings of MSR 2013
(10th IEEE Working Conference on Mining Software
Repositories), pages 277‚Äì286, 2013.
[29] K. Herzig and A. Zeller. The impact of tangled code
changes. In Proceedings of 10th Conference on Mining
Software Repositories, pages 121‚Äì130. IEEE, 2013.
[30] Y . Jiang, B. Adams, and D. M. German. Will my patch make
it? and how fast?: case study on the linux kernel. InProceedings of the 10th Working Conference on MiningSoftware Repositories, pages 101‚Äì110. IEEE Press, 2013.
[31] E. Kalliamvakou, G. Gousios, K. Blincoe, L. Singer, D. M.
German, and D. Damian. The promises and perils of mininggithub. In Proceedings of the 11th Working Conference on
Mining Software Repositories, pages 92‚Äì101, 2014.
[32] A. Kumar. http:
//www.infoq.com/presentations/Development-at-Google.Accessed 2016/02/15.
[33] J. Lerner and J. Tirole. Some simple economics of open
source. The journal of industrial economics, 50(2):197‚Äì234,
2002.
[34] J. Marlow, L. Dabbish, and J. Herbsleb. Impression
formation in online peer production: activity traces andpersonal proÔ¨Åles in GitHub. In Proceedings of the 2013
conference on Computer supported cooperative work,CSCW ‚Äô13, pages 117‚Äì128, New York, NY , USA, 2013.
ACM.
[35] N. McDonald and S. Goggins. Performance and participation
in open source software on GitHub. In Extended Abstracts on
295Human Factors in Computing Systems, CHI EA ‚Äô13, pages
139‚Äì144, New York, NY , USA, 2013. ACM.
[36] A. Mockus, R. T. Fielding, and J. D. Herbsleb. Two case
studies of open source software development: Apache and
Mozilla. ACM Trans. Softw. Eng. Methodol., 11(3):309‚Äì346,
2002.
[37] J. Nielsen. 10 usability heuristics for user interface design.
http://www.nngroup.com/articles/ten-usability-heuristics/,
January 1995.
[38] R. Pham, L. Singer, O. Liskin, F. Figueira Filho, and
K. Schneider. Creating a shared understanding of testingculture on a social coding site. In Proceedings of the 2013
International Conference on Software Engineering, ICSE‚Äô13, pages 112‚Äì121, Piscataway, NJ, USA, 2013. IEEE Press.
[39] T. Punter, M. Ciolkowski, B. Freimut, and I. John.
Conducting on-line surveys in software engineering. In
International Symposium on Empirical Software
Engineering, ISESE‚Äô03, pages 80‚Äì88. IEEE, 2003.
[40] P. C. Rigby and C. Bird. Convergent contemporary software
peer review practices. In Proceedings of the 2013 9th Joint
Meeting on Foundations of Software Engineering,ESEC/FSE 2013, pages 202‚Äì212, New York, NY , USA,
2013. ACM.
[41] P. C. Rigby and M.-A. Storey. Understanding broadcast
based peer review on open source software projects. In
Proceedings of the 33rd International Conference onSoftware Engineering, ICSE ‚Äô11, pages 541‚Äì550, New York,
NY , USA, 2011. ACM.
[42] J. Sheehy. There is no now. ACM Queue, 13(3):1‚Äì8, 2015.
[43] L. Sigelaman. Question-order effects on presidential
popularity. Public Opinion Quarterly, 45(2):199‚Äì207, 1981.
[44] I. Steinmacher, T. U. Conte, M. Gerosa, and D. Redmiles.
Social barriers faced by newcomers placing their Ô¨Årst
contribution in open source software projects. InProceedings of the 18th ACM conference on Computer
supported cooperative work & social computing, pages
1379‚Äì1392, 2015.
[45] J. Tsay, L. Dabbish, and J. Herbsleb. InÔ¨Çuence of social and
technical factors for evaluating contribution in GitHub. InProceedings of the 36th International Conference onSoftware Engineering, ICSE 2014, pages 356‚Äì366, New
York, NY , USA, 2014. ACM.
[46] J. Tsay, L. Dabbish, and J. Herbsleb. Let‚Äôs talk about it:
Evaluating contributions through discussion in github. In
Proceedings of the 22Nd ACM SIGSOFT InternationalSymposium on Foundations of Software Engineering, FSE2014, pages 144‚Äì154, New York, NY , USA, 2014. ACM.
[47] E. van der Veen, G. Gousios, and A. Zaidman. Automatically
prioritizing pull requests. In Proceedings of the 2015
International Working Conference on Mining SoftwareRepositories, pages 357‚Äì361, 2015.
[48] B. Vasilescu, Y . Yu, H. Wang, P. Devanbu, and V . Filkov.
Quality and productivity outcomes relating to continuous
integration in GitHub. In 10th Joint Meeting of the European
Software Engineering Conference and the ACM SIGSOFT
Symposium on the Foundations of Software Engineering,ESEC/FSE, page accepted. IEEE, 2015.
[49] G. von Krogh, S. Spaeth, and K. R. Lakhani. Community,
joining, and specialization in open source software
innovation: a case study. Research Policy, 32(7):1217 ‚Äì
1241, 2003. Open Source Software Development.[50] B. Weiss. GitHub is your resume now.
http://anti-pattern.com/github-is-your-resume-now, June
2012. Accessed 2016/02/15.
[51] P. Weissgerber, D. Neu, and S. Diehl. Small patches get in!
InProceedings of the 2008 International Working
Conference on Mining Software Repositories, MSR ‚Äô08,pages 67‚Äì76, New York, NY , USA, 2008. ACM.
[52] Y . Ye and K. Kishida. Toward an understanding of the
motivation of open source software developers. InProceedings of the 25th International Conference on
Software Engineering, 2003, pages 419‚Äì429, May 2003.
[53] H. Zhang, L. Gong, and S. Versteeg. Predicting bug-Ô¨Åxing
time: an empirical study of commercial software projects. In
Proceedings of the 2013 International Conference onSoftware Engineering, pages 1042‚Äì1051. IEEE Press, 2013.
[54] M. Zhou and A. Mockus. Who will stay in the FLOSS
community? modeling participant‚Äôs initial behavior. IEEE
Transactions on Software Engineering, 41(1):82‚Äì99, 2015.
296