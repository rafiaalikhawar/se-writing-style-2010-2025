Missing Data Imputation Based on Low-Rank Recovery and 
Semi-Supervised Regression fo r Software Effort Estimation
Xiao-Yuan Jing1,2,*, Fumin Qi1, Fei Wu1,2, Baowen Xu3,1 
1State Key Laboratory of Software Engineering, School of Computer, Wuhan University, China 
2School of Automation, Nanjing University of Posts and Telecommunications, China 
3Department of Computer Science and Technology, Nanjing University, China 
*Corresponding author: jingxy_2000@126.com  
 
ABSTRACT  
Software effort estimation (SEE) is a crucial step in software 
development. Effort data missi ng usually occurs in real-world 
data collection. Focusing on th e missing data problem, existing 
SEE methods employ the deletion, ignoring, or imputation 
strategy to address the problem , where the imputation strategy 
was found to be more helpful for improving the estimation performance. Current imputation methods in SEE use classical imputation techniques for missing data imputation, yet these 
imputation techniques have their respective disadvantages and 
might not be appropriate for effort data. In this paper, we aim to 
provide an effective solution for th e effort data missing problem. 
Incompletion includes the drive factor missing case and effort label missing case. We introduce the low-rank recovery technique for addressing the drive factor missing case. And we employ the 
semi-supervised regression techni que to perform imputation in the 
case of effort label missing. We then propose a novel effort data 
imputation approach, named low-rank recovery and semi-supervised regression imputation (LRSRI). Experiments on 7 widely used software effort datasets indicate that: (1) the proposed approach can obtain better effort data imputation effects 
than other methods; (2) the imputed data using our approach can 
apply to multiple estimators well.   
Categories and Subject Descriptors  
D.2.9 [ Software Engineering ]: Management– cost estimation. 
General Terms  
Algorithms, Management, Theory 
Keywords  
Software effort estimation, Miss ing data problem, Drive factor 
missing case, Effort label missing case, Low-rank recovery and 
semi-supervised regression imputation (LRSRI). 
1. INTRODUCTION 
Software effort estimation (SEE) is an important step when establishing a new software projec t. Accurate effort estimation 
will help project managers reasonably allocate the limited 
resource and help the marketers win the bid for external contracts. 
In recent years, several estimation methods have been presented 
[1-10]. Some well-known machine learning methods have also 
been employed for estimation, such as classification and regression tree (CART) [11] and neural networks (NN) [2, 12]. 
Menzies et al. [13] categorized effort estimation methods into two classes, i.e., expert-based and model-based methods. Literature [14] classifies the effort estimation methods into eleven categories, 
such as regression-based, anal ogy-based and expert judgement-
based methods. Dejaeger et al. [11] compared multiple estimation 
methods and classified them into tree/rule-based, line model-based and non-line model-based methods. 
When there lacks historic project  data in hand, making use of 
effort data collected by other projects is probably a good idea. 
However, there may exist missing da ta in history data of other 
projects. Many factors contribute to the data missing. The data collection requirements include consistence, experience, time, cost and methodology for a company. However, the data collectors may lack of time, cost, commitment, training. Besides, 
problems applying counting rules to a particular situation 
(especially where that situation has not been anticipated) and political reasons (refusal to release figures that “look bad”) [26] are also two reasons. Furthermore, privacy issues may also cause data missing.  
To solve the effort data missing problem, the deletion [17-18], 
ignoring [19], or imputation stra tegies are usually used. The 
imputation strategy was found to be more helpful for improving the estimation performance [20- 21]. These imputation methods 
include mean imputation (MEI) [ 20], regression imputation (RI) 
[23], multiple imputation (M I) [24], maximum likelihood 
imputation (MLI) [25] and hot -deck imputation (HI) [26] 
techniques.  
1.1 Motivation 
Organizations need to calibrate effort models with complete data if they wish to have more reliable estimates. However, in practice, an organization may not have many projects to obtain such 
complete data and even if the obtained data from other projects is 
also incomplete. The methods focusing on handling the missing data problem may offer some help in making full use of the data obtained. Although some methods have been presented to address the effort data missing problem, there still exists much room for improvement. Specifically, there exist the following three shortcomings: (1) the deletion and ignoring strategies will lead to 
loss of potential useful information; (2) current methods aiming to 
impute the incomplete effort data mainly focusing on the drive  
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be 
honored. Abstracting with credit is permitted. To copy otherwise, or 
republish, to post on servers or to redistribute to lists, requires prior 
specific permission and/or a fee. Request permissions from 
Permissions@acm.org. 
ICSE '16,  May 14-22, 2016, Austin, TX, USA  
© 2016 ACM. ISBN 978-1-4503-3900-1/16/05…$15.00  
DOI: http://dx.doi.org/10.1145/2884781.2884827 
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   607
factors (independent variables) missing case, while the effort 
labels  (dependent variables) missing case is not considered; (3) 
current imputation methods utilize several classical imputation techniques to impute missing data, yet these imputation techniques have their respective shortcomings.  
Mean imputation (MEI) [20] applies to the data that meets the 
normal distribution, and when th e observed data does not satisfy 
the normal distribution, MEI will attenuate the variance [6, 27]. 
Regression imputation (RI) requires the data to be imputed has strong connection with other data, yet there may not exist such strong connection between drive factors [23, 28-29]. Multiple 
imputation (MI) suffers from large influences of different data 
missing mechanisms [26, 30].  Maximum likelihood imputation 
(MLI) depends on the probability relationship between variables, and it is also affected by the data missing mechanisms. Hot-deck imputation (HI) tends to work well when there are strong correlation between the covariates and the variable with missing values, and thus it performs differently depending on the 
correlation structure among the vari ables. Hence, how to develop 
an effective imputation approach according to the characteristics 
of effort data is an important research topic. 
In practice, the collected effort dataset may contain missing data 
at any locations, including the missing of drive factors 
(independent variables) or effort labels (dependent variables), as 
shown in Figure 1. Figure 1(a) refers to the case that only the drive factors are incomplete, Figure 1(b) refers to the case that only the effort labels are incomplete, and Figure 1(c) refers to the general missing case that both drive factors and effort labels are incomplete. In this paper, we aim to answer the following three 
questions: 
RQ 1: For the drive factors missing case, how to design an 
effective imputation strategy? RQ 2:  For the effort labels missing case, how to provide an effective imputation strategy? 
RQ 3:  How to offer a unified solution for the general effort data 
missing problem, namely the situa tion that missing data occurs in 
both drive factors and effort labels? 
1.2 Contribution 
The contributions of our work are summarized as three points: 
(1) According to the locations of missing values in an effort data 
matrix, we consider that effort data missing includes the drive factor missing case and effort label missing case, and design a 
novel imputation approach. (2) For the case that only the drive factors (independent variables) are incomplete, we introduce the low-rank recovery technique, 
and design a data structurization strategy to structurize the effort data such that low-rank recovery can be effectively utilized to impute the missing drive factors. For the case that only the effort labels (dependent variables) are incomplete, we consider the imputation under this situation as a semi-supervised learning 
problem, and employ the semi-supervised regression technique 
for imputation. For the general case of missing data, namely both drive factors and effort labels are incomplete, we firstly employ low-rank recovery for imputing the drive factors, and then use semi-supervised regression for the imputation of effort labels. We thus propose the low-rank recovery and semi-supervised 
regression imputation (LRSRI) approach for this case. 
(3) We conduct experiments on 7 commonly used datasets. 
Experimental results demonstrate that the proposed approach can obtain better effort data imputation effects than other methods, and the imputed data using our LRSRI can apply to multiple 
estimators well. 
1.3 Organization 
The rest of this paper is organized as follows: Section 2 reviews 
the related work. Section 3 describes the proposed LRSRI approach. Experimental results are reported in Section 4. Threats to validity are provided in Section 5 and conclusions are drawn in Section 6. 
2. RELATED WORK 
2.1 Effort Estimation Methods 
According to the categorization of literature [13], effort 
estimation methods can be divided into expert-based and model-
based methods. The expert-based methods use human expertise for prediction. In [31-34], researchers presented the analogy-based methods, which find similar past projects and adapt the effort values of them for the target project to be estimated. The model-based methods build prediction model on old data and do 
prediction for a new projects with the obtained model. Literature 
[35] uses the classification and regression trees (CART) algorithm and adopts the up-to-bottom search strategy in a binary tree for 
finding the optimal effort. Ordinary least-squares (OLS) regression with a (absolute) relative error evaluative criterion was used in [18] for effort estimati on. Dejaeger et al. [11] made a 
comparative study about 13 data mining techniques, such as radial basis function networks (RBFN) and multivariate adaptive regression splines (MARS), to evaluate their performances for the application of effort estimation. Miyazaki et al. [36] employed robust regression (RoR) to predict effort of new project, which is 
an alternative to OLS regression with the advantage of being less 
vulnerable to the existence of outliers in the data. Recently, 
Whigham et al. [9] addressed an automatically transformed linear model (ATLM) and recommended it as a baseline model for comparison against SEE methods. 
2.2 Solutions for Missing Data Problem 
Deletion, ignoring, and data imput ation with other complete data 
are three main strategies for solving the missing data problem. 
And these strategies can be called missing data techniques (MDTs) 
[23]. Listwise deletion (LD) excludes the samples which contain some missing values [19]. For each variable, pairwise deletion [17] (PD), i.e., the ignoring strategy, removes the specific missing 
 
Figure 1. Illustration of data missing in effort data set: (a) 
drive factors missing, (b) effort  labels missing, (c) both drive 
factors and effort labels missing. Here, the matrix 
represents the effort data set, id is the thi drive factor, and 
ix is the thi sample. The marker “ ” represents the 
location of missing value.  
608values corresponding to the variable. As compared with LD, PD 
can preserve more information [29]. With respect to the missing 
data imputation strategy, the description and analysis can be found in the Introduction section. 
2.3 Solutions for Missing Data Problem in 
SEE 
Most of current effort estimation methods aiming to solve the missing data problem mainly focus on the drive factors missing case. Some works [17, 19, 37] employ LD or PD technique to tackle the missing data problem. In [20, 26, 21], the researchers concluded that the imputation strategy is more helpful for 
improving the estimation performan ce as compared with deletion 
and ignoring strategies. Regarding the classical imputation 
techniques including MEI, RI, MI, MLI and HI as the candidate set, literatures [20, 26, 30] select appropriate technique from the candidate set for specific drive factors missing problem. Some works [4, 38-39] integrate classi cal imputation techniques into 
their own effort estimation methods to make their estimators have 
the capability for dealing with the missing data problem. Zhang et 
al. [6] combined expectation maximization (i.e., MLI) with Bayesian regression to present the Bayesian regression and expectation maximization (BREM) effort estimation algorithm. Song and Shepperd [30] presented a class mean imputation (CMI) method to address the missing data problem in small project data 
sets. 
2.4 Low-rank Recovery and Semi-supervised 
Regression Techniques 
To deal with corrupted and incomplete data, recently the 1L-norm 
low-rank matrix factorization is commonly used [40]. Given a 
matrix 12(, , . . . , )dn
n Xx x x  , where 1, ,ixin  with the 
dimensionality of d denotes the thi column of the matrix. The 
missing entries of X is indicated by a matrix dnW , whose 
element ijW is 0 if the corresponding el ement is missing, and 1 
otherwise. Then, low-rank matrix recovery methods solve the 
following matrix factorization problem: 
,1min ( )T
UVWX U V ,                             (1) 
where   12,,,dk
k Uu u u  ,  12,,,nk
k Vv v v  , and 
 is the Hadamard product. After acquiring the factorized 
matrices U and V, we can obtain the imputed matrix 
TXU V  . Meng et al. [41] developed the cyclic weighted 
median (CWM) method to solve Formula (1), which achieves the 
state-of-the-art image data imputation performance. In this paper, 
we introduce CWM into SEE for solving the drive factors missing problem. 
In recent years, several semi-supervised regression methods have 
been developed. Brefeld et al. [42] presented the co-regularised 
least squares regression (coRLSR) method, which is a semi-
supervised regression algorithm based on the co-learning framework. A transductive regression model is developed in [43]. Zhou and Li [44] presented a co-training style semi-supervised regression (COREG) algorithm, which uses two K-nearest 
neighbor regressors with different distance metrics in a co-
training manner to label the unlabeled samples. The COREG 
algorithm has been successfully used in many other fields and has broad applicability [46-47]. In this paper, we employ COREG to 
impute missing effort labels. 
3. RESEARCH METHODOLOGY 
3.1 Low-rank Recovery with Structuralized 
Data Set for Driving Factors Missing Case 
In this section, we aim to answer  RQ 1  “For the drive factors 
missing case, how to design an effective imputation strategy?”. One important reason for the success of CWM [41] in the 
application of image data imputation is that it uses the median filter to help solve Formula (1), namely CWM considers the pixel-wise structure of images. However, for software effort data, samples are arranged randomly, that is there is no explicit structure within an effort data set. Thus, the CWM method cannot be used for imputing the incomplete effort data directly. In this 
subsection, we provide a data set structurization strategy to make 
the effort data structurized. 
Assume that 
  12;;;mn
m Xx x x   is an effort data set with 
missing values, which only contains drive factors,  1, ,ixim  
denotes the thi sample and  1, ,jxjn  represents the thj 
column of X. Here, m is the number of samples and n is the 
number of drive factors. Suppose that j
ix is a missing value 
located at the thj column of ix, before structurizing, we fill j
ix 
with the mean of jx. By this way, we can obtain the initialized 
data matrix X corresponding to X. Then, we realize 
structurization as the following two steps: 
(1) Determine the arrangement of samples with missing values in 
the final imputed matrix 
In order to make the key samples, namely the samples with 
missing values, to be structurized, we need to sort these samples reasonably. We require the adjacent structurized key samples have large correlation. In other words, the distance between two 
adjacent structurized key samples should be small. And this 
scheduling problem can be solved by addressing the minimum spanning tree (MST) problem [48]. 
Firstly, we select samples actually containing missing values from 
X to form the subset UX. Next, we regard the samples in UX as 
vertexes, and the Euclidean distance between any two vertexes in 
UX as the edge of these two vertexes. Then, a fully connected 
graph UG can be built, and the affinity matrix of the UG, i.e., 
UD, can be defined as: 
12 1
21 2
120 ...
0 ...
... 0l
l
U
lldd
ddD
dd 
 
   
 
   ,                              (2) 
where pqd is the distance between the thp and thq vertexes, and 
l is the number of vertexes (samples) in UG (UX). Based on 
UD, we can solve the minimum spanning tree problem with 
Prim [48] or Kruskal  [48] algorithm. Therefore, we can obtain 
the structurized key samples and store them in X. 
609(2) Determine the arrangement of samples without missing 
values in the final imputed matrix 
After the key samples have been structurized, we select the k 
nearest neighbors in X for the first structurized key sample 1Ux, 
namely the first line of X, and insert the selected neighbors into 
the front of 1Ux in X. When the selected k nearest neighbors 
of 1Ux are inserted into X, these k nearest neighbors are 
removed from X. For the  2thp pl  structurized key 
sample Upx, we select its nearest neighbors in the updated X 
and insert the selected neighbors into the front of Upx in X. By 
this manner, we can achieve the structurized effort data set X. 
It is noted that if there exist remaining samples after the 
neighbors of the last structurized key sample have been inserted 
into X, we place these remaining samples into the bottom of 
X. 
Based on the structurized effort data matrix X, we can realize 
missing data imputation column by column for the original effort 
data set X by using the CWM algorithm. The process of 
imputation for missing drive factors with our low-rank recovery 
solution is provided in Algorithm 1 and Figure 2. 
Figure 2. Flowchart of imputation for missing drive factors 
with our low-rank recovery solution. 
3.2 Semi-supervised Regression Imputation 
for Effort Labels Missing Case 
In practice, the effort labels of training data may be also missing 
other than the drive factors, yet current SEE methods aiming to 
deal with the missing data problem mainly focus on the drive 
factors missing case. In fact, the effort labels of training data are important for subsequent effort estimation. In this section, we answer 
RQ 2  “For the effort labels missing case, how to provide 
an effective imputation strategy?”. 
In the effort labels missing case, since only the effort labels of 
part of samples are missing, the imputation problem can be considered as a semi-supervised learning problem. Semi-supervised learning is a popular machine learning manner, which makes use of unlabeled training samples with a part of labeled samples for building the prediction model [49-50]. In addition, the 
regression technique is a good choice for imputation in this case, 
since there exists causality between effort labels and drive factors. Considering these two aspects, the semi-supervised regression is a suitable technique to be used for imputing the missing effort labels. The COREG algorithm [44] has broad applicability and achieves success in many other application fields [46-47]. In this paper, we employ COREG for imputing the missing effort labels. In the following, we describe the process of using COREG for 
missing effort data imputation. 
Given a training effort data set 
1 mn
TX  with incomplete 
effort labels, we divide the set into two subsets L and U, where 
1
11{( , ); ;( , )}gn
L L Lg Lg Lx y x y    is an subset of samples 
with effort labels and 
1;;mg n
U Um gUx x
   is an subset 
of samples without effort labels. Here, m denotes the number of 
samples, n denotes the number of drive factors, the 1thn  
columns of TX and L denote the effort labels, Lix is the thi 
sample in L, Liy is the effort label of Lix. According to COREG, 
we use two regressors, i.e., 1h and 2h, which are separately 
generated from 1L and 2L. Each of these two regressors is 
refined with the help of samples in U, which are labeled by the 
latest version of the other regressor. For each sample Ujx U, b 
nearest neighbors are selected from 1, 2rLr  and are stored in 
   11,; ;, , 1 , 2rr r r b r b xy xy r   . Each regressor can provide 
an estimated result  (, ) , 1 , 2Uj Ujrxy r   for Ujx, and then the 
training set of the other regressor can be updated as 
{( , ) } , = 1 , 2 ,ss U j U j rLLx y s s r   . Here, Ujry represents the 
estimated label with rh. Then, we can use rL to compute the 
following difference for samples in r: 
   22
Ur
rl rx rl r rl rl r rl
xyh x yh x 
    ,             (3) 
 
Figure 3. Flowchart of LRSRI.   Algorithm 1.  Low-rank recovery with structuralized data for 
driving factors missing case. 
Input:  Effort data set with missing values, i.e., X. 
Output:  The imputed data set X. 
1. Initialize the missing values in X to obtain X. 
2. For 1:s n  (n is the number of drive factors) do 
XX. 
If the ths drive factor has missing values, then 
2.1 Sort samples actually with missing values in X by 
solving the MST problem and achieve X. 
2.2 Select k nearest neighbors from X of each 
sample with missing values in X and insert the selected 
neighbors into X. 
Else 
Continue. 
End If 
2.3 Use CWM algorithm to impute the missing values of 
ths column in X. 
End 
3. XX . 
610where rly is the actual effort of thl sample in r, i.e., rlx, and 
rh is the updated regressor of rh. Finally, we can obtain the 
effort for Ujx by using the estimated result of the regressor that 
produces the larger value of Formula (3).  
By performing semi-supervised regression algorithm COREG on 
the effort data set with effort labels, we can solve the effort labels missing case. 
3.3 Low-rank Recovery and Semi-supervised 
Regression Imputation (LRSRI) Approach 
For this part, we answer RQ 3  “How to offer a unified solution for 
the general effort data missing problem, namely the situation that missing data occurs in both drive factors and effort labels?”. In this general case of effort data incompletion, we firstly employ the low-rank recovery method CWM with structurized data set to 
impute the drive factors, and then use the semi-supervised 
regression method COREG for imputing the effort labels. We name our effort data imputation solution as low-rank recovery and 
semi-supervised regression imputation (LRSRI) approach. The flowchart of LRSRI is illustrated in Figure 3.  
Table 1. Details of seven datasets. 
Dataset Number of 
samples Number of 
attributes Minimum 
effort value Maximum 
effort value
Albrecht 24 8 0.5 105.2 
China 499 18 26 54620 
Coc81 63 17 5.9 11400 
Kemerer 15 15 23.2 1107.31 
Kitchenham 145 5 219 113930 
Maxwell 62 26 583 63694 
Nasa93 93 18 8.4 8211 
4. EXPERIMENTS 
In this section, we evaluate the proposed LRSRI approach for solving the effort data missing problem empirically. We firstly introduce seven benchmark datasets and two commonly used evaluation measures. Next, we describe the experimental settings. Then, we separately perform experiments to evaluate the 
imputation effects of our approach and the applicability of our 
imputation approach for different effort estimators. 
4.1 Data Set 
In experiment, we employ 7 publicly available and commonly used datasets as the test data, which includes Albrecht [51], China [35], Coc81 [35, 52], Kemerer [53], Kitchenham [54], Maxwell 
[55] and Nasa93 [35, 52].  
The Albrecht dataset consists of projects completed at IBM in the 
1970s and the details can be found in [51]. It contains 24 software projects that are developed by using third generation languages such as COBOL, PL1, etc. The China dataset includes various software projects from multiple companies developed in China. 
The standard COCOMO datasets, which contains the Coc81 and 
Nasa93 datasets, was collected wi th the COCOMO approach [52, 
55]. Although the COCOMO datasets have been established for several years, it is still frequently used for validating various effort estimation methods. The Kemerer dataset is a relatively small dataset with 15 software projects described by 6 drive 
factors and 1 effort label, and the details can be found in [53]. The 
Kitchenham dataset contains effort data from 145 maintenance and development projects managed by a single outsourcing company. The Maxwell dataset comes from the finance domain and is composed of Finnish banking software projects. It is a 
relatively new dataset, which contains 62 projects described by 23 
attributes. Details of the Maxwel l dataset are given in [55]. All 
these 7 datasets are available in the Promise Repository [55]. 
Considering the noisy, redundant, or unreliable information in 
dataset, like in [17], we employ  the z-score normalization [56] to 
preprocess data. For a variable 
x with mean  and standard 
deviation , the normalized variable using z-score normalization 
can be represented as: ()
normxx
 . 
 
4.2  Evaluation Measures 
In this paper, we use three measures, namely Median Magnitude 
of Relative Error (MdMRE), PRED (25) [1, 11, 46, 56] and effect 
size[62], which are commonly used for evaluate the effort 
estimation accuracy of estimators. 
Assume that ix is a sample, its actual effort is iy, the predicted 
effort is iy, then the Magnitude of Relative Error (MRE) of ix 
can be calculated by ii
i
iyyMREy . Then, Median MRE 
(MdMRE) of N  samples can be computed as 
12 (, , , )N MdMRE median MRE MRE MRE  . PRED(25) is 
defined as the percentage of pred ictions falling within 25 percent 
of the actual values:  
11, 0.25 100(25)0,N
i
iif MREPREDotherwise N 
 . 
For these two measures, the lower of MdMRE represents the 
better performance of imputation or estimation, and the higher 
PRED(25) represents the prediction is more precise. 
4.3  Experimental Settings 
In experiment, we randomly select  fifty percent of samples in the 
dataset to construct the training set and use the remaining samples 
for testing. According to three missing data cases in Figure 1, we separately remove the values of a certain percentage of randomly 
selected locations for these three cases in the training set to get 
the training effort data with missing values.  
The missing ratio is set as 10%, 20% and 40%. The random 
selection may affect the predic tion performance. We perform 
selection of training samples 20 times (for each time, half of 
samples are randomly selected for training and the remaining half 
are used for testing), and for the selected training samples per 
 
Figure 3. Flowchart of LRSRI.  
611time, we further conduct random data removing 20 times at a 
certain missing ratio.  
4.4  Experimental Results and Analysis 
For this part, we perform experi ments to evaluate the imputation 
effects of our approach and the applicability of our imputation 
approach for different effort estimators, respectively. 
4.4.1 Comparison of imputation effects 
To validate the effectiveness of the proposed imputation approach, we compare LRSRI with five im putation methods including MEI 
[29], RI [23], MI [24], MLI [25] and HI [18]. The recently presented baseline effort estimation method ATLM [9] is used as 
estimator for reporting the estim ation results on two measures 
(MdMRE and PRED(25)). We also  use the method CART [61] as 
a baseline estimator to evaluate these imputation methods. Due to 
limited space, we report the results online
1. We also report the 
estimation results using original complete data for comparison, and the results are given by “normal”. 
Tables 2 and 4 separately tabulate the effort estimation results 
using ATLM based on the imputed data with different imputation 
methods on seven datasets for the MdMRE and PRED(25) measures. In these two tables, the estimation results of three cases are reported, including (1) only the drive factors are incomplete, 
(2) only the effort labels are incomplete, and (3) both drive factors 
and effort labels are incomplete. We also provide the estimation results at different missing ratios in these two tables, including 10%, 20% and 40%. 
As can be seen from these two tables, our LRSRI approach 
outperforms other imputation methods, especially for the case that 
both drive factors and effort labels are incomplete. For the case that only the drive factors are incomplete, LRSRI can obtain better imputation results than other imputation methods, which indicates the effectiveness of the low-rank recovery technique with our designed data structurization strategy. The low-rank 
recovery with structurized data makes full use of the information 
of similar samples and the correlation of all the samples. For the case that only the effort labels are incomplete, we take advantage of the regression technique and conduct regression in a semi-supervised manner, such that the imputed samples, i.e., labeled samples, can join in the training procedure of the regression 
model. For the case that both drive factors and effort labels are 
incomplete, LRSRI firstly employs low-rank recovery for imputing the drive factors, and then uses semi-supervised regression for the imputation of effort labels. Thus, LRSRI can achieve desirable imputation effects in this general case. 
In addition, we find that the pe rformance differences of different 
imputation methods are slight on small datasets, like Albrecht and 
Kemerer. When the missing ratio is large, all the imputation methods will suffer performance degradation on large datasets. The RI method can obtain good imputation results when the data to be imputed and other variables have strong connection, that is, 
the regression technique applies to the case that only the effort labels are incomplete. For the case that only drive factors are incomplete, EM and MI perform better than RI, which indicate that the probability-based methods, like EM and MI, can outperform regression or mean value based method in this case. HI can achieve good imputation results when the missing ratio is 
low. However, the imputation performance of HI is unstable when 
the missing ratio increases. To statistically analyze the results given in Tables 2 and 4, we 
conduct a statistical test, i.e., Wilcoxon test [58-59], with 95 
percent confidence to get the so-called win-tie-loss results. Assume that A and B are two methods, and Wilcoxon( A, B) 
denotes the Wilcoxon test between A and B. The detailed test 
process is described in Figure 4. In the figure, the better  function 
realizes the A-statistic test [60].Tables 3 and 4 give the statistical 
significance test results between LRSRI and other compared 
methods on seven datasets for the MdMRE and PRED(25) measures, respectively. We can see that the proposed approach makes a significant difference in  comparison with other methods. 
 
Figure 4. Win-tie-loss test process of two methods. 
To investigate the effects of our approach on model estimate variability and the relation to actual effort variability in Tables 2 and 4, we conduct an effect size test  (cliffs test), i.e., Cliff’s delta 
or d [62]. Here, d is a measure of how often one the values in one 
distribution are larger than the values in a second distribution. The 
sample estimate  d is given by: 
#( ) #( )ij ijxxx xdmn  , 
where the two distributions are of size n and m with items ix and 
jx, respectively, and # is defined as the number of times. Due to 
limited space, we also report the variability results online1. 
4.4.2 Evaluation of applicability for different 
estimators 
In this subsection, we specially design experiments to investigate 
whether the imputed data with our approach can apply to multiple estimators. We select five estimators for experiment, including classification and regression trees  (CART) [61], ordinary least-
squares (OLS) regression [18], ra dial basis function networks 
(RBFN) [11], multivariate adaptive regression splines (MARS) 
[11], and robust regression (RoR) [36]. We observe the general 
data missing case that both drive factors and effort labels are incomplete. We take the missing ratio of 20% as an example for experiment. 
Tables 8 and 9 report average effort estimation results of LRSRI 
and other imputation methods using five estimators on seven datasets for the MdMRE and PRED(25) measures, respectively. According to these two tables, in the general missing data case, the estimation results corresponding to our LRSRI approach are better than those corresponding to other imputation methods, 
which indicate that the imputed data by using our imputation 
approach can well apply to different estimators. In addition, the 
results in Tables 8 and 9 are also consistent with results in Tables 2 and 4, that is, our imputati on approach outperforms other 
imputation methods on specific estimators.
                                                                
 
1 https://sites.google.com/site/whuxyjfmq/ 
612 Table 2. Comparison of imputation effects using the ATLM estimator on MdMRE measure. 
Drive factors missing Effort labels missing Drive factors and effort labels missing Dataset/imputation 
method/missing rate 10% 20% 40% 10% 20% 40% 10% 20% 40% 
MEI 32.44 43.53 58.07 11.66 45.60 65.93 59.65 108.71 128.52 
RI 25.61 35.46 54.86 28.51 32.89 43.86 40.90 88.95 118.54 
EM 22.44 28.41 47.07 31.26 31.64 51.11 19.20 87.50 98.29 
MI 23.68 30.43 56.18 33.65 44.20 45.92 23.29 75.77 90.59 
HI 13.06 25.49 41.57 24.13 36.50 50.32 21.41 35.07 78.93 
Ours 13.68 18.20 35.95 12.12 28.22 31.69 15.39 30.82 70.27 Albrecht 
normal 10.33 
MEI 72.20 98.75 151.30 77.10 76.49 104.11 81.63 137.54 290.57 
RI 58.74 84.53 94.54 69.74 75.43 92.22 66.88 98.15 137.06 
EM 68.59 69.31 80.14 75.06 80.39 99.08 64.49 88.44 106.72 
MI 59.68 67.88 78.85 72.93 79.80 80.44 70.14 84.87 105.73 
HI 52.69 64.61 78.50 42.97 66.35 77.75 51.18 74.27 88.80 
Ours 43.20 58.25 62.97 43.01 58.49 63.05 48.03 65.84 71.80 China 
normal 42.12 
MEI 42.96 85.39 103.90 42.06 63.64 69.97 79.29 97.60 158.94 
RI 43.49 72.67 83.48 40.15 43.87 56.14 61.87 71.73 102.74 
EM 42.84 61.56 68.44 42.21 50.92 56.48 56.67 60.91 80.27 
MI 45.48 65.92 72.52 43.29 48.14 63.31 52.79 65.17 73.16 
HI 41.77 52.02 67.22 42.60 43.40 59.94 46.69 64.84 66.49 
Ours 41.34 48.32 55.71 41.13 42.52 50.25 43.34 57.93 68.34 Coc81 
normal 40.05 
MEI 16.98 49.01 47.32 14.23 37.12 40.92 32.21 53.07 78.84 
RI 18.31 20.29 35.45 15.55 32.71 28.62 34.60 57.32 89.57 
EM 14.31 19.43 35.12 10.23 15.39 38.87 39.52 49.77 76.32 
MI 9.77 18.57 37.31 12.52 24.42 27.63 16.36 50.32 61.36 
HI 16.19 20.75 30.82 10.20 16.57 28.15 20.45 37.13 47.68 
Ours 9.83 15.14 20.09 10.20 13.42 18.37 18.09 20.09 35.08 Kemerer 
normal 9.56 
MEI 38.92 59.25 84.55 34.29 41.62 73.68 53.38 90.45 143.61 
RI 34.58 49.05 62.84 39.81 35.30 58.03 43.10 71.41 107.21 
EM 35.50 52.25 106.46 41.37 37.70 68.04 39.69 58.09 80.09 
MI 36.84 48.03 78.61 35.59 39.26 61.59 44.70 54.91 82.06 
HI 35.48 38.70 85.59 34.11 35.55 44.90 34.30 48.31 73.27 
Ours 34.11 35.02 54.95 33.94 34.32 40.06 34.83 45.67 62.95 Kitchenham 
normal 33.83 
MEI 44.39 50.92 86.98 35.34 55.38 83.49 124.77 136.35 176.77 
RI 40.97 42.61 62.71 33.67 40.12 77.26 60.50 81.56 186.69 
EM 39.83 43.80 67.20 32.56 45.98 74.01 41.17 65.23 113.90 
MI 39.22 44.72 64.09 32.86 47.41 75.15 43.35 75.05 91.63 
HI 34.92 48.27 55.85 31.82 42.45 60.72 37.22 49.18 54.04 
Ours 30.45 40.42 51.31 31.01 34.02 59.42 31.49 40.34 50.44 Maxwell 
normal 30.32 
MEI 37.90 66.05 89.47 38.65 51.58 73.44 43.93 78.91 97.17 
RI 41.18 47.95 67.39 37.12 45.94 59.33 49.10 59.31 77.82 
EM 37.61 48.79 64.27 37.64 47.10 48.77 41.44 61.23 84.12 
MI 37.70 43.93 63.31 36.01 43.25 44.53 49.41 62.17 98.22 
HI 39.18 40.06 50.05 36.51 40.07 48.31 43.15 59.99 72.34 
Ours 35.69 37.60 42.58 36.14 39.47 40.36 36.47 39.64 45.27 Nasa93 
normal 35.63   
Table 3. Statistical significance test results between LR SRI and other compared methods on the MdMRE measure. 
Dataset MEI (w/t/l) RI (w/t/l) EM (w/t/l) MI (w/t/l) HI (w/t/l) 
Albrecht 8/1/0 8/1/0 7/2/0 7/2/0 8/1/0 
China 9/0/0 9/0/0 9/0/0 9/0/0 8/1/0 
Coc81 9/0/0 9/0/0 9/0/0 9/0/0 9/0/0 
Kemerer 9/0/0 7/2/0 6/3/0 6/3/0 8/1/0 
Kitchenham 9/0/0 8/1/0 9/0/0 9/0/0 9/0/0 
Maxwell 9/0/0 9/0/0 9/0/0 9/0/0 9/0/0 
Nasa93 9/0/0 9/0/0 9/0/0 9/0/0 9/0/0 
613 Table 4. Comparison of imputa tion effects using the ATLM estimator on PRED(25) measure. 
Drive factors missing Effort labels missi ng Drive factors and effort labels missing Dataset/imputation 
method/missing rate 10% 20% 40% 10% 20% 40% 10% 20% 40% 
MEI 33.33 13.33 0.32 37.00 25.00 11.37 8.38 5.43 1.50 
RI 28.67 8.34 2.31 33.33 16.67 15.18 28.39 12.02 10.32 
EM 33.30 14.60 1.50 36.67 8.33 1.13 31.67 8.93 5.32 
MI 35.00 12.01 1.66 31.67 10.00 2.19 34.31 16.97 8.42 
HI 29.67 16.21 18.37 28.33 20.67 8.74 25.43 19.03 13.21 
Ours 36.75 26.05 19.02 36.24 27.00 18.33 35.01 24.42 15.05 Albrecht 
normal 37.03 
MEI 62.77 42.21 19.28 40.56 43.09 20.68 55.94 25.86 1.96 
RI 61.85 58.59 36.55 67.51 59.76 44.94 68.59 42.21 19.68 
EM 74.66 62.88 45.46 68.67 53.45 33.01 61.45 42.25 39.88 
MI 72.25 63.86 43.49 69.48 57.43 38.23 66.27 53.09 37.51 
HI 74.74 60.32 46.67 64.26 61.22 41.23 69.96 57.72 37.11 
Ours 76.02 65.08 50.07 75.61 60.06 45.17 72.09 60.08 40.08 China 
normal  76.31 
MEI 51.08 29.71 10.03 53.84 32.58 22.58 29.03 12.26 18.03 
RI 48.13 39.35 15.08 53.13 45.68 27.68 38.13 22.90 16.13 
EM 53.81 40.48 20.58 52.71 41.61 18.81 49.48 36.13 13.81 
MI 52.13 39.81 22.90 51.03 44.57 20.58 45.16 39.03 15.90 
HI 52.16 46.13 29.58 52.90 42.48 28.16 50.48 41.45 16.21 
Ours 54.12 47.81 34.14 53.98 46.34 34.33 52.35 44.32 20.35 Coc81 
normal  54.32 
MEI 10.43 1.26 1.03 14.29 11.31 0.85 21.76 2.41 0.63 
RI 12.51 8.92 1.92 14.29 6.67 11.94 23.09 5.93 1.23 
EM 14.60 12.86 6.29 33.67 10.57 4.80 30.21 9.12 5.93 
MI 14.11 25.57 7.14 32.29 12.45 2.13 31.11 17.01 10.37 
HI 21.43 29.40 14.29 28.57 14.87 8.86 30.57 21.17 14.00 
Ours 34.67 28.54 18.91 33.21 28.55 19.34 34.98 27.54 19.45 Kemerer  
normal  35.23 
MEI 26.90 18.06 1.11 27.44 18.06 1.83 18.17 14.72 0.61 
RI 16.54 14.17 12.72 28.10 23.83 19.85 9.72 10.43 1.94 
EM 26.94 15.28 14.17 27.36 19.84 14.32 22.5 18.06 5.72 
MI 27.77 19.72 16.94 28.53 20.00 14.76 25.56 16.94 5.56 
HI 25.56 23.33 12.22 27.46 24.03 17.39 20.78 16.39 9.28 
Ours 29.01 25.96 18.01 28.23 25.10 20.00 28.19 22.03 15.97 Kitchenham 
normal  29.02 
MEI 39.58 16.46 8.45 41.89 22.90 9.68 36.45 17.78 4.90 
RI 22.58 26.13 12.90 41.71 38.35 24.68 28.97 16.17 10.08 
EM 38.46 35.01 18.71 40.85 25.57 16.37 39.68 29.35 18.90 
MI 39.81 36.13 19.68 41.67 22.32 13.83 36.13 31.37 20.81 
HI 42.10 31.68 21.13 40.45 38.91 23.23 39.35 32.90 19.35 
Ours 41.31 39.35 25.58 41.98 39.86 27.71 40.55 33.33 21.43 Maxwell 
normal 42.21 
MEI 47.83 33.48 13.04 36.96 33.83 10.39 46.96 11.30 0.91 
RI 45.04 20.61 17.39 54.07 49.04 17.76 52.61 23.21 4.35 
EM 55.91 22.67 23.93 50.43 32.67 20.26 48.27 32.67 23.04 
MI 57.26 23.97 23.91 55.43 32.61 17.33 43.91 28.91 26.43 
HI 55.62 43.31 29.56 58.34 48.43 25.13 50.54 35.56 28.56 
Ours 58.50 49.08 30.30 59.30 50.21 28.07 58.39 40.04 35.02 Nasa93 
normal  60. 43 
Table 5. Statistical significance test results between LRSR I and other compared methods on the PRED(25) measure. 
Dataset MEI(w/t/l) RI(w/t/l) EM(w/t/l) MI(w/t/l) HI(w/t/l) 
Albrecht 9/0/0 8/1/0 8/1/0 8/1/0 8/1/0 
China 9/0/0 9/0/0 9/0/0 9/0/0 9/0/0 
Coc81 9/0/0 9/0/0 9/0/0 9/0/0 9/0/0 
Kemerer 9/0/0 7/2/0 7/2/0 7/2/0 7/2/0 
Kitchenham 9/0/0 9/0/0 9/0/0 9/0/0 9/0/0 
Maxwell 9/0/0 8/1/0 7/2/0 7/2/0 7/2/0 
Nasa93 9/0/0 6/3/0 7/2/0 7/2/0 6/3/0 
614 
 
Table 8. Effort estimation results of imputation methods using five estimators on MdMRE measure. 
 
5. THREATS TO VALIDITY 
Followings are several potential threats to the validity with 
respect to experiments: 
(1) Bias of estimators. A bias in this study is the estimators we 
used for effort estimation. In experiments, we select six commonly used estimators to evaluate our approach. As to more other estimators, experiments might need to be done to evaluate our approach.  (2) Bias of evaluation measures. Another bias is the MdMRE and 
PRED(25) measures used to re port the imputati on or estimation 
performances. Other measures, such as Mean Balanced Relative Error (MBRE) [35], the Mean Inverted Balanced Relative Error (MIBRE) [35] and CLUSTER [57] are not used. In this work, we 
employ the widely used MdMRE and PRED(25) measures to 
show the empirical evaluation for the application of SEE. Estimator Imputation 
method Albrecht China Coc81 Kemerer Kitchenham Maxwell Nasa93 
MEI 38.94 20.83 60.32 9.93 26.05 47.64 45.61 
RI 26.25 27.93 55.37 29.77 26.56 37.37 37.55 
EM 21.10 11.89 54.64 103.95 20.23 38.95 33.54 
MI 25.59 13.77 56.04 98.85 21.04 38.14 37.01 
HI 14.72 15.64 54.03 16.98 19.34 39.43 35.21 
Ours 13.41 10.04 51.18 10.04 8.84 29.62 28.96 CART 
normal 12.90 8.62 48.66 6.25 4.37 22.86 20.50 
MEI 27.28 23.91 40.95 39.66 26.2 80.06 75.65 
RI 41.11 29.96 65.13 22.01 19.94 98.56 96.33 
EM 36.87 26.85 73.01 60.81 18.47 105.92 63.32 
MI 72.53 21.99 58.98 35.32 19.05 118.68 80.13 
HI 30.42 25.01 57.11 45.89 21.31 89.09 89.30 
Ours 29.03 19.55 41.26 20.57 11.43 59.31 41.71 OLS regression 
normal 25.60 19.28 27.14 18.28 10.80 52.38 35.93 
MEI 17.90 35.52 63.93 11.13 30.48 109.67 67.56 
RI 21.31 29.31 68.22 25.06 32.67 84.33 77.10 
EM 21.86 29.66 74.42 29.56 28.35 37.23 42.76 
MI 29.46 23.92 66.01 21.54 31.23 42.35 46.07 
HI 19.89 31.12 61.31 18.15 28.33 36.90 88.01 
Ours 13.22 20.14 53.81 12.29 20.38 28.65 40.45 RBFN 
normal 9.41 17.59 49.49 7.61 17.93 24.98 34.32 
MEI 40.32 25.02 65.29 12.85 17.40 27.40 37.07 
RI 43.54 36.25 69.59 9.77 33.41 39.49 71.94 
EM 39.13 32.07 49.60 193.95 14.46 29.15 49.03 
MI 35.26 29.74 53.81 9.93 19.67 29.73 36.67 
HI 38.92 31.89 48.95 23.67 10.01 32.01 32.71 
Ours 30.63 20.42 44.93 7.04 10.75 24.95 31.66 MARS 
normal 26.33 19.61 38.25 6.25 9.12 16.71 25.14 
MEI 68.31 46.18 43.84 22.66 12.16 79.40 33.21 
RI 173.10 28.74 71.59 45.89 14.01 80.20 82.93 
EM 48.93 22.40 69.03 30.01 9.85 106.47 62.02 
MI 51.68 22.58 59.58 35.32 8.59 128.74 73.81 
HI 31.21 34.00 67.97 56.09 10.98 67.90 56.09 
Ours 32.17 15.36 45.16 23.81 6.68 58.72 24.48 RoR 
normal 25.39 11.17 41.47 18.20 5.75 50.59 15.98 Table 6. Effect size test be tween our imputation approach and 
other imputation methods for the results in Table 2. 
Dataset MEI RI  EM MI HI 
Albrecht 0.56 0.58 0.63 0.48 0.66 
China 0.68 0.63 0.66 0.51 0.69 
Coc81 0.56 0.53 0.58 0.68 0.56 
Kemerer 0.83 0.73 0.76 0.76 0.61 
Kitchenham 0.58 0.53 0.53 0.61 0.63 
Maxwell 0.75 0.58 0.71 0.53 0.63 
Nasa93 0.6 0.65 0.68 0.53 0.46 Table 7. Effect size test between our imputation approach 
and other imputation methods fo r the results in Table 4. 
Dataset MEI RI EM MI HI 
Albrecht -0.65 -0.59 -0.46 -0.51 -0.53 
China -0.58 -0.63 -0.57 -0.63 -0.63 
Coc81 -0.67 -0.51 -0.62 -0.77 -0.62 
Kemerer -0.79 -0.78 -0.78 -0.66 -0.67 
Kitchenham -0.52 -0.64 -0.57 -0.68 -0.73 
Maxwell -0.69 -0.51 -0.62 -0.64 -0.79 
Nasa93 -0.54 -0.61 -0.58 -0.53 -0.51 
615 
6. CONCLUSION AND FUTURE WORK 
In this paper, we study the general missing situation of effort data 
and consider that the incompletion of effort data comprises drive factors missing and effort labels missing. For the specific case that only the drive factors are incomplete, we structurize the effort data and employ the low-rank reco very technique for imputation. 
We consider the imputation in the specific case that only the effort labels are incomplete as a semi-supervised learning problem, and introduce the semi-supervised regression technique for imputation, such that the imputed samples can join in the training procedure of the regression model. We then propose the LRSRI approach for the general case of missing data, namely both drive 
factors and effort labels are incomplete. We firstly utilize low-
rank recovery and the designed data structurization strategy jointly to impute the drive factors, and then take advantage of the regression technique and conduct regression in a semi-supervised manner for the imputation of effort labels. The results demonstrate that our LRSRI outperforms other imputation methods for missing effo rt data, and the imputed data 
by using LRSRI can well apply to multiple estimators.  
For the future work, we would like to utilize more effort datasets 
to validate the effectiveness of our approach and study the applicability of our approach in effort data missing situation with higher missing rate. 
7. ACKNOWLEDGEMENTS 
The authors want to thank the anonymous reviewers for their 
constructive comments and suggestions. The work described in 
this paper was supported by the National Nature Science Foundation of China under Projects No. 61272273, No. 61572375, No. 61233011, No. 91418202, No. 61472178, the Chinese 973 Program under Project No. 2014CB340702. 
 
 Table 9. Effort estimation results of imputation methods using five estimators on PRED(25) measure. 
Estimator Imputation 
method Albrecht China Coc81 Kemerer Kitchenham Maxwell Nasa93 
MEI 17.50 18.15 5.16 14.29 29.03 10.23 20.65 
RI 25.00 24.42 3.87 21.43 27.08 13.09 18.70 
EM 26.90 34.34 5.81 6.57 38.97 16.45 10.52 
MI 20.83 37.71 6.45 9.67 39.92 17.42 17.83 
HI 28.04 39.97 8.02 15.71 35.12 18.39 15.31 
Ours 30.83 45.68 12.45 20.57 40.89 18.06 22.39 CART 
normal 33.33 52.21 16.77 24.29 44.44 21.35 23.91 
MEI 15.00 21.08 11.29 5.71 28.19 6.77 9.78 
RI 13.33 17.51 7.10 10.21 21.25 4.52 6.74 
EM 14.17 19.02 4.84 14.42 39.83 5.81 6.96 
MI 4.17 23.09 8.06 8.98 25.89 2.26 4.57 
HI 16.87 16.89 9.21 7.14 34.03 10.34 8.77 
Ours 21.67 25.30 10.00 10.22 42.92 9.03 10.87 OLS 
regression 
normal 25.33 26.18 12.9 15.71 43.06 13.68 13.26 
MEI 25.00 19.64 7.10 30.29 13.19 6.45 15.43 
RI 25.83 19.44 3.23 22.86 11.81 13.23 10.03 
EM 22.50 20.09 6.13 30.02 28.02 11.29 8.70 
MI 21.67 18.39 5.81 28.57 23.33 9.01 14.35 
HI 14.78 13.01 7.23 31.43 24.01 14.84 10.98 
Ours 37.16 23.21 9.03 36.86 30.14 14.52 19.04 RBFN 
normal 41.67 24.06 9.35 42.86 31.94 17.42 25.65 
MEI 16.03 21.33 8.71 18.57 32.08 16.77 13.04  
RI 8.33 19.84 6.45 13.98 19.03 15.48 9.35 
EM 8.33 22.37 7.10 15.71 44.58 15.81 10.22 
MI 15.83 23.69 9.68 18.57 32.92 18.06 16.09 
HI 13.33 18.90 5.98 14.29 26.78 19.82 16.21 
Ours 17.50 24.06 9.35 21.43 46.25 18.71 18.91 MARS 
normal 18.33 25.30 12.90 24.29 51.39 25.81 19.13 
MEI 8.33 21.77 8.71 4.32 40.83 5.81 12.83 
RI 17.33 27.03 4.52 2.31 38.06 4.52 8.70 
EM 14.17 22.53 6.13 9.83 43.06 6.13 6.30 
MI 4.17 19.87 8.39 6.32 46.67 2.26 4.35 
HI 11.98 29.28 3.23 5.32 39.03 5.43 5.89 
Ours 18.67 31. 77 8.31 18.28 51.67 8.39 18.70 RoR 
normal 19.17 34.14 9.01 28.57 62.50 9.68 28.26 
616REFERENCES  
[1] E. Kocaguneli, T. Menzies, A. B. Bener, J. W. Keung. 
Exploiting the essential assumptions of analogy-based effort estimation. IEEE Transactions on Software Engineering , 
38(2):425-438, 2012. 
[2]
 F. S. Gharehchopogh, I. Maleki, S. Sadouni. Artificial neural 
networks based analysis of software cost estimation models. MAGNT Research Report , 2(6):597-605, 2014. 
[3] A. Idri, A. Zakrani, A. Zahi. Design of radial basis function 
neural networks for software effort estimation. International 
Journal of Computer Science , 7(4):11-17, 2010. 
[4] W. Zhang, Y. Yang, Q. Wang.  Handling missing data in 
software effort prediction with naive Bayes and EM 
algorithm. In ACM International Conference on Predictive 
Models in Software Engineering (ICPMSE) , pages 1-10, 
2011. 
[5] M. Jørgensen, B. Boehm, S. Rifkin. Software development 
effort estimation: Formal mo dels or expert judgment?. IEEE 
software , 26(2):14-19, 2009. 
[6] W. Zhang, Y. Yang, Q. Wang.  Using Bayesian regression 
and EM algorithm with missing handling for software effort 
prediction. Information and Software Technology, 58(2):58-
70, 2015. 
[7] J. Wen, S. Li, Z. Lin, Y. Hu, C. Huang. Systematic literature 
review of machine learning based software development 
effort estimation models. Information and Software 
Technology , 54(1):41-59, 2012. 
[8] N. Mittas, L. Angelis. Ranki ng and clustering software cost 
estimation models through a multiple comparisons algorithm. 
IEEE Transactions on Software Engineering , 39(4):537-551, 
2013. 
[9] P. A. Whigham, C. A. Owen, S. G. Macdonell. A Baseline 
Model for Software Effort Estimation. ACM Transactions on 
Software Engineering and Methodology , 24(3):1-11, 2015. 
[10] L. L. Minku, X. Yao. How to make best use of cross-
company data in software effort estimation?. In ACM 
International Conference on Software Engineering (ICSE) , 
pages 446-456, 2014. 
[11] K. Dejaeger, W. Verbeke, D. Martens, B. Baesens. Data 
mining techniques for software effort estimation: a 
comparative study. IEEE Transactions on Software 
Engineering , 38(2):375-397, 2012. 
[12] V. S. Dave, K. Dutta. Neural network based models for software effort estimation: a review. Artificial Intelligence 
Review , 42(2):295-307, 2014. 
[13] T. Menzies, Z. Chen, J. Hihn, K. Lum. Selecting best 
practices for effort estimation. IEEE Transactions on 
Software Engineering , 32(11): 883-895, 2006. 
[14] M. Jorgensen, M. Shepperd. A systematic review of software 
development cost estimation studies. IEEE Transactions on 
Software Engineering , 33(1):33-53, 2007. 
[15] B. Twala. Reasoning with Noisy Software Effort Data.  
Applied Artificial Intelligence , 28(6):533-554, 2014. 
[16] M. Shepperd, Q. Song, Z. Sun, C. Mair. Data Quality: Some 
Comments on the NASA Software Defect Data Sets. IEEE 
Transactions on Software Engineering , 39(9):1208-1215, 
2013. [17] S. K. Sehra, J. Kaur, S. S. Sehra.  Effect of data preprocessing 
on software effort estimation. International Journal of 
Computer Applications , 69(25):33-36, 2013. 
[18] K. Strike, K. EIemam, N. Madhavji. Software cost 
estimation with incomplete data. IEEE Transactions on 
Software Engineering , 27(10):890-908, 2001. 
[19] N. Ohsugi, M. Tsunoda, A. Monden,  K. I. Matsumoto. Effort 
estimation based on collaborative filtering. Product Focused 
Software Process Improvement , Springer Berlin Heidelberg , 
pages 274-286, 2004. 
[20] J. V. Hulse, T. M. Khoshgoftaar. A comprehensive empirical 
evaluation of missing value im putation in noisy software 
measurement data. Journal of Systems and Software , 
81(5):691-708, 2008. 
[21] J. L. Schafer, J. W. Graham. Missing data: our view of the 
state of the art. Psychological Methods, 7(2):147-177, 2002. 
[22] P. D. Allison. Missing data. Sage publications , 2001. 
[23] J. Huang, Y. F. Li, M. Xie. An empirical analysis of data 
preprocessing for machine learning-based software cost 
estimation. Information and Software Technology , 
67(11):108-127, 2015. 
[24] D. B. Rubin. Multiple imputation for nonresponse in surveys. 
John Wiley & Sons , 2004. 
[25] R. J. A. Little. Pattern-mixture models for multivariate 
incomplete data. Journal of the American Statistical 
Association , 88(421):125-134, 1993. 
[26] M. H. Cartwright, M. J. She pperd, Q. Song. Dealing with 
missing software project data. In IEEE International 
Software Metrics Symposium (METRICS) , pages 154-165, 
2003. 
[27] J. V. Hulse, T. M. Khoshgoftaar. Incomplete-case nearest 
neighbor imputation in software measurement data. 
Information Sciences , 259(3):596-610, 2014. 
[28] I. Myrtveit, E. Stensrud, U. H. Olsson. Analyzing data sets 
with missing data: An empirical evaluation of imputation 
methods and likelihood-based methods. IEEE Transactions 
on Software Engineering , 27(11):999-1013, 2001. 
[29] B. Twala, M. Cartwright, M. Shepperd. Ensemble of missing 
data techniques to improve software prediction accuracy. In 
ACM International Conference on Software Engineering 
(ICSE), pages 909-912, 2006. 
[30] Q. Song, M. Shepperd. A new imputation method for small 
software project data sets.  Journal of Systems and Software, 
80(1):51-62, 2007. 
[31] N. Mittas, L. Angelis. LSEbA: least squares regression and 
estimation by analogy in a semi-parametric model for 
software cost estimation. Empirical Software Engineering , 
15(5):523-555, 2010. 
[32] J. Li, G. Ruhe. Analysis of attribute weighting heuristics for 
analogy-based software effort estimation method AQUA+.  
Empirical Software Engineering , 13(1):63-96, 2008. 
[33] F. Walkerden, R. Jeffery. An empirical study of analogy-based software effort estimation. Empirical Software 
Engineering , 4(2):135-158, 1999. 
617[34] N. H. Chiu, S. J. Huang. The adjusted analogy-based 
software effort estimation based on similarity distances. 
Journal of Systems and Software , 80(4):628-640, 2007. 
[35] E. Kocaguneli, T. Menzies, J. W. Keung. On the value of 
ensemble effort estimation. IEEE Transactions on Software 
Engineering , 38(6):1403-1416, 2012. 
[36] Y. Miyazaki, M. Terakado, K. Ozaki, H. Nozaki. Robust 
regression for developing software estimation models. 
Journal of Systems and Software , 27(1):3-16, 1994. 
[37] M. Shepperd, C. Schofield, B. Kitchenham. Effort estimation 
using analogy. In IEEE International Conference on 
Software Engineering (ICSE) , pages 170-178, 1996. 
[38] Q. Song, M. Shepperd, X. Chen, J. Liu. Can k-NN 
imputation improve the perform ance of C4.5 with small 
software project data sets? A comparative evaluation. 
Journal of Systems and Software , 81(12):2361-2370, 2008. 
[39] W. E. Wong, J. Zhao, V. K. Y. Chan. Applying statistical 
methodology to optimize and simplify software metric 
models with missing data. In ACM Symposium on Applied 
Computing (SAC) , pages 1728-1733, 2006. 
[40] Q. Ke, T. Kanade. Robust L 1 norm factorization in the 
presence of outliers and missing data by alternative convex 
programming. In IEEE Computer Society Conference on 
Computer Vision and Pattern Recognition (CVPR) , pages 
739-746, 2005. 
[41] D. Meng, Z. Xu, L. Zhang, J. Zhao. A Cyclic Weighted 
Median Method for L 1 Low-Rank Matrix Factorization with 
Missing Entries. In Twenty-Seventh AAAI Conference on 
Artificial Intelligence , pages 704-710, 2013. 
[42] U. Brefeld, T. Gärtner, T. Sc heffer, S. Wrobel. Efficient co-
regularised least squares regression. In ACM International 
Conference on Machine Learning (ICML) , pages 137-144, 
2006. 
[43] C. Cortes, M. Mohri. On transductive regression. Advances 
in Neural Information Processing Systems 19 , MIT Press , 
305-312, 2007. 
[44] Z. H. Zhou, M. Li. Semi-Supervised Regression with Co-
Training. In International Joint Conference on Artificial 
Intelligence (IJCAI) , pages 908-913, 2005. 
[45] K. Maxwell. Applied statistics for software managers. 
Prentice Hall , 2002. 
[46] K. Liu, L. Xu, J. Zhao. Co-Extracting Opinion Targets and 
Opinion Words from Online Reviews Based on the Word 
Alignment Model. IEEE Transactions on Knowledge and 
Data Engineering , 27(3):636-650, 2015. 
[47] B. Tan, J. Zhang, L. Wang. Semi-supervised elastic net for 
pedestrian counting. Pattern Recognition , 44(10):2297-2304, 
2011. 
[48] D. B. West. Introduction to graph theory. Upper Saddle 
River: Prentice hall , 2001. [49] X. Zhu. Semi-supervised learning literature survey. 
Department of Computer Sciences, University of Wisconsin 
at Madison, Madison, WI, Tech. Rep. 1530, 
http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf , 2008 
[50] V. Sindhwani, P. Niyogi, M. Belkin. A co-regularization 
approach to semi-supervised learning with multiple views.  In 
ACM international conference on Machine learning (ICML) , 
pages 74-79, 2005. 
[51] A. J. Albrecht, J. E. Gaffney Jr. Software function, source 
lines of code, and development effort prediction: a software 
science validation. IEEE Transactions on Software 
Engineering , 9(6):639-648, 1983. 
[52] A. P. Dempster, N. M. Laird, D. B. Rubin. Maximum 
likelihood from incomplete data via the EM algorithm. 
Journal of the Royal Statistical Society, pages 1-38, 1977. 
[53] C. F. Kemerer. An empirical validation of software cost 
estimation models. Communications of the ACM , 30(5):416-
429, 1987. 
[54] B. Kitchenham, S. L. Pfleeger , B. McColl, S. Eagan. An 
empirical study of maintenan ce and development estimation 
accuracy, Journal of Systems and Software, 64(1):57-77, 
2002. 
[55] G. Boetticher, T. Menzies, T. Ostrand. PROMISE 
Repository of empirical software engineering data. West 
Virginia University, Department of Computer Science , 2007. 
[56] S. B. Kotsiantis, D. Kanellopoulos, P. E. Pintelas. Data 
preprocessing for supervised leaning. International Journal 
of Computer Science , 1(2):111-117, 2006. 
[57] J. Keung, E. Kocaguneli, T. Menzies. Finding conclusion 
stability for selecting the best effort predictor in software 
effort estimation. Automated Software Engineering , 
20(4):543-567, 2013. 
[58] M. Hollander, D. A. Wolfe, E. Chicken. Nonparametric 
statistical methods. John Wiley & Sons , 2013. 
[59] A. Arcuri, L. Briand. A practical guide for using statistical 
tests to assess randomized algorithms in software 
engineering. In IEEE International Conference on Software 
Engineering (ICSE) , pages 1-10, 2011. 
[60] A. Arcuri, L. Briand. A practical guide for using statistical te
sts to assess randomized algorithms in software engineering. 
In IEEE International Conference on Software Engineering (
ICSE) , pages 1-10, 2011.  
[61] B. Twala, M. Cartwright. Ense mble missing data techniques 
for software effort prediction. Intelligent Data Analysis , 
14(3):299-331, 2010. 
[62] Cliff N. Dominance statistics: Ordinal analyses to answer 
ordinal questions. Psychological Bulletin , 114(3):494-509, 
1993. 
 
618