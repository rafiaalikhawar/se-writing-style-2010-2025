A Neural Framework for Retrieval and Summarization of Source
Code
Qingying Chen
Minghui Zhou∗
qychen@pku.edu.cn
zhmh@pku.edu.cn
School of Electronics Engineering and Computer Science, Peking University
Key Laboratory of High Confidence Software Technologies, Ministry of Education, China
ABSTRACT
Coderetrievalandsummarizationaretwotasksoftenemployedby
softwaredeveloperstoreusecodethatspreadsoveronlinerepos-
itories. In this paper, we present a neural framework that allows
bidirectional mapping between source code andnatural language
to improve these two tasks. Our framework, BVAE, is designed
to have two Variational AutoEncoders (VAEs) to model bimodal
data: C-VAE for source code and L-VAE for natural language. Both
VAEs are trained jointly to reconstruct their input as much as pos-
siblewithregularizationthatcapturestheclosenessbetweenthe
latentvariablesofcodeanddescription.BVAEcouldlearnsemantic
vector representations for both code and description and generate
completelynewdescriptionsforarbitrarycodesnippets.Wedesign
twoinstancemodelsofBVAEforretrievalandsummarizationtasks
respectivelyandevaluatetheirperformanceonabenchmarkwhich
involvestwoprogramminglanguages:C#andSQL.Experiments
demonstrate BVAE’s potential on the two tasks.
CCS CONCEPTS
•Software and its engineering →Search-based software en-
gineering;
KEYWORDS
Code retrieval, code summarization, neural framework
ACM Reference Format:
QingyingChenandMinghuiZhou.2018.ANeuralFrameworkforRetrieval
andSummarizationofSourceCode.In Proceedingsofthe201833rdACM/IEEE
International Conference on Automated Software Engineering (ASE ’18), Sep-
tember 3–7, 2018, Montpellier, France. ACM, New York, NY, USA, 6pages.
https://doi.org/10.1145/3238147.3240471
1 INTRODUCTION
Developingandmaintainingsoftwareisacostlyandcomplicated
activity. In particular, the modern software engineering strongly
∗Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3240471reliesonthird-partylibrarieswhichsoftwaredevelopersmaynot
be familiar with. Developers tend to frequently resort to documen-
tation and online resources to reuse code written by others and
thereforecodereusebecomesacommonpractice.Nonetheless,this
process can still be challenging. On the one hand, it is not easy for
developers to locate quickly what they are looking for in the docu-
mentation; on the other hand, the documentation of a library may
be deficient, and online resources may not be well documented.
For example, although billions of lines of code reside in onlinerepositories, only a small fraction of them are paired with high-
qualitycomments orsummaries,whichmakes suchcodedifficult
to understand, let alone to reuse.
This challenge motivates two tasks:
•Code Retrieval :Givenonenaturallanguagequery,retrieve
themostrelevantcodesnippet,sothatdeveloperscanquickly
find code snippet that meets their needs.
•Code Summarization : Given one code snippet, generate a
natural language description automatically to help develop-
ers comprehend the snippet.
For code retrieval, there are two main challenges we want to
address:1)informationretrieval(IR)basedmethodsfailtomatch
semantically relevant snippets, in particular many snippets are not
pairedwith naturallanguage descriptions.How tobridgethe gap
between the high-level intent of queries and low-level implementa-tionofsourcecode?2)ExistingapproachessuchasCODE-NN[
13]
requiresequentialscanoverallcandidatecodesnippets,whichis
inefficient when retrieving on large scale datasets.
Toaddressthechallenges,wepresentaneuralframeworkthat
can project natural language and source code into a common se-
manticspace.Theframework,termedasBimodalVariationalAu-
toEncoder(BVAE),iscomposedoftwoVariationalAutoEncoders
(VAE, [15,24]). VAE assumes a latent variable that can be inter-
preted as a high-level semantic feature of the observed data [ 6].
By building the connection between the latent variables of natural
language and source code, BVAE bridges their semantic gap and
allows bidirectional mapping between them.
Specifically, BVAE can learn semantic vector representations for
bothcodesnippetsandqueriesandretrievesnippetsthatarenot
paired with descriptions. Owing to this feature, vector representa-
tions of snippets can be first computed and indexed offline. At the
onlineretrievalstage,afterthevectorrepresentationofthequery
iscomputed,similarity-searchalgorithms,suchasBest-Bin-First
[4], VA-File [ 5,30] and FFVA [ 28], can be applied to retrieve the
most relevant snippet without sequential scan.
826
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Qingying Chen and Minghui Zhou
AsVAEhasprovedtobeeffectiveatgeneratingnaturallanguage
[6], BVAE can also be applied to code summarization and generate
completely new descriptions for arbitrary code snippets.
WedesigntwoinstancemodelsofBVAEforcoderetrievaland
code summarization respectively, and evaluate their performance
on a recently introduced benchmark which involves two program-
ming languages: C# and SQL. Compared with previous best ap-
proach, BVAE leads to a significant improvement for retrieval
taskandachievescomparableperformanceforsummarizationtask.
Theseresults demonstrateBVAE’s potentialon retrievalandsum-
marization of source code.
2 RELATED WORK
Code retrieval is an active research topic in both Natural Language
Processing and Software Engineering communities. Some work
focusedonretrievingcodesnippetsgivencodetokens[ 2,14],which
is not applicable if developers have no idea which libraries or APIs
cansatisfytheirneeds.Themostrelevantstudiestooursarethat
ofAllamanisetal.[ 1]andIyeretal.[ 13],whichfocusonretrieving
snippetsgivennaturallanguagequery.Allamanisetal.[ 1]proposed
amodelthatrepresents sourcecodeasatre e.However, becausethis
modelconditionssourcecodeonnaturallanguage,itcannotbeusedforcodesummarization.Iyeretal.[
13]proposedanattention-based
sequence-to-sequencemodel,termedasCODE-NN,whichperforms
muchbetterthanthemodelofAllamanisetal.andsupportsboth
coderetrievalandcodesummarization.CODE-NNconsumessource
code tokens and generates words step by step. However, at the
onlineretrievalstage,CODE-NN,aswellasthemodelofAllamanis
et al. [1], requires sequential scan over all candidate code snippets
given one query due to its architectural design, and therefore is
inefficient for largescale retrieval. Our approach proposed inthis
paper addresses this problem.
There has been substantial effort devoted to code summariza-
tion and other similar tasks that predict natural language basedonsourcecode.SomeworktriedtogeneratesummariesforJava
classes, such as the template based approach [ 20], the topic and n-
gramsmodels[ 21].Giriprasadetal.[ 26]presentedanapproachthat
generatessummariesforJavamethodsautomaticallyusingcontent
selection and template based phrase generation, and McBurney et
al. [19] followed this line of work. Sridhara et al. [ 27] presented an
automaticrule-basedpipelineforidentifyingcodefragmentsthat
implement high level abstractions of actions within Java methods
and expressing them as a natural language description. Koutrika et
al.[17]presentedatemplatebasedapproachthatcantranslateSQL
queries to textual explanations. Ngonga Ngomo et al. [ 22] focused
ontranslatingSPARQLqueriesintonaturallanguageusingrulesto
processqueries.Thesestudieseitherfocusonaspecificprogram-
minglanguageorrequirecostlymanualeffort.Differentfromthese
studies, we attempt to generate completely new descriptions forarbitrary code snippets using machine learning techniques. The
mostrelevantworkisCODE-NN[ 13],whichisaneuralmodelas
described earlier.
Bythesubmissionduedateofthecamera-readyversion,there
is some recent work on the two tasks. Gu et al. [ 9] used two neural
modelstojointlyembedcodesnippetsanddescriptionsintoavector
spaceforretrievaltask.Forsummarizationtask,Huetal.[ 11,12]focusedonrepresentingsourcecodebetterbeforefeedingitinto
neural models, which is orthogonal to our work.
3 THE PROPOSED FRAMEWORK: BVAE
BVAE is a variant of VAE [ 15,24]. In this section we first review
VAE, and then present BVAE. After that, we introduce how the
tasksofcoderetrievalandcodesummarizationareaccomplished
based on BVAE.
3.1 VAE
VAE is a generative model, and can be considered as a regularized
versionofstandardautoencoder(AE).AnAEalwaysconsistsoftwo
parts, the encoder and the decoder. The encoder maps the input
xto a hidden code z, while the decoder takes zas its input and
reconstructs xasmuchaspossible.Insteadofusingadeterministic
function as the encoder in AE, VAE imposes a prior distribution
p(z)over the latent variable zand learns an approximate posterior
distribution qϕ(z|x)over zconditioned on the observed variable x,
whereϕarevariationalparameters.Intuitively,theencoderofVAE
maps xto a region rather than a single point in the latent space,
which makes VAEmore effective at extracting for global semantic
features than the standard AE [6].
From the perspective of VAE, the latent variable zis a high level
representation of the observed data x.
Usually,thestandardGaussian(Equation(1))andthediagonal
Gaussian (Equation (2))are used as the priordistribution p(z)and
the posterior distribution qϕ(z|x)respectively:
p(z)=N(z|0,1), (1)
qϕ(z|x)=N(z|μ(x),diag(σ2(x))), (2)
whereμandσ2are the mean and variance vector.
The goal of training VAE is to maximize the lower bound on the
true log likelihood of x, or to minimize its opposite (loss function):
L(ϕ,θ;x)=Eqϕ(z|x)[−logpθ(x|z)]+KL(qϕ(z|x)||p(z))
=R(ϕ,θ;x)+KL(qϕ(z|x)||p(z)),(3)
whereθaretheparametersofgenerativemodel(i.e.decoder)and
KL stands for Kullback-Leibler divergence1.
The loss function in Equation (3) can be considered as the re-
construction loss Rplus a regularization term. In the experiments
presentedinthispaper,weestimatethereconstructionlossusinga
single sample from qϕ(z|x)with reparameterization trick [ 15], and
use the standard Gaussian and the diagonal Gaussian for the prior
andposteriordistributionof z,suchthattheKLdivergencetermin
Equation (3) can be computed in closed form.
3.2 BVAE
BVAE is composed of two VAEs: C-VAE for source code and L-VAE
for natural language. Figure 1depicts the BVAE framework. All
components in the framework are used at training time. At test
time, the components inside blue dashed shape ( −·−) are used for
code retrieval, and those inside orange dashed shape ( −−) for code
summarization.
1https://en.wikipedia.org/wiki/KL_divergence
827
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. A Neural Framework for Retrieval and Summarization of Source Code ASE ’18, September 3–7, 2018, Montpellier, France
Encoder of C-VAEࣆ௖,ࢉ࣌ଶDecoder of C-VAE
Encoder of L-VAEࣆ௟,࢒࣌ଶDecoder of L-VAE
~
Figure 1: Illustration of BVAE framework.
ThecoreideaofBVAEisthatgivenapairofsourcecodesnippet
andnaturallanguagedescription,theirlatentvariablesshouldbe
closetoeachother.Toachievethat,BVAEremovestheKLdiver-
gencebetweentheposteriorandpriordistributionforbothVAEs
and instead adds another regularization to capture the closeness
betweenthetwolatentvariables.Specifically,weproposetwokinds
of closeness regularization:
1)Posterior Regularization (PReg) :ForeachofthetwoVAEs,
we use the KL divergence of the posterior distribution from that of
the other VAE. The loss function of BVAE, denoted by Lb, takes
the following form:
Lb(ϕc,θc,ϕl,θl;xc,xl)=Lc(ϕc,θc,ϕl,θl;xc,xl)
+Ll(ϕc,θc,ϕl,θl;xc,xl),(4)
Lc(ϕc,θc,ϕl,θl;xc,xl)=αc∗Rc(ϕc,θc;xc)
+βc∗KL(qϕc(zc|xc)||qϕl(zl|xl)),(5)
Ll(ϕc,θc,ϕl,θl;xc,xl)=αl∗Rl(ϕl,θl;xl)
+βl∗KL(qϕl(zl|xl)||qϕc(zc|xc)),(6)
whereαc+βc+αl+βl=1 and the subscript candlstand for
C-VAE and L-VAE respectively.
2)Mean-Posterior Regularization (MPReg) : Different from
PReg, MPReg forces the posterior distributions of both VAEs to
approach the mean posterior qm(zm|xc,xl), i.e.:
Lc(ϕc,θc,ϕl,θl;xc,xl)=αc∗Rc(ϕc,θc;xc)
+βc∗KL(qϕc(zc|xc)||qm(zm|xc,xl)),(7)
Ll(ϕc,θc,ϕl,θl;xc,xl)=αl∗Rl(ϕl,θl;xl)
+βl∗KL(qϕl(zl|xl)||qm(zm|xc,xl)),(8)
qm(zm|xc,xl)=N(zm|μc(xc)+μl(xl)
2,diag(σ2c(xc)+σ2
l(xl)
4).
(9)
Byapplyingoneofthetworegularizationtechniques,thecon-
nection can be built between the originally isolated C-VAE and
L-VAE. Specifically, given a pair of code snippet and natural lan-
guage description, C-VAE (taking code as input) and L-VAE (taking
description as input) would obtain close latent variables.
3.3 BVAE for Code Retrieval
Candidate networks for the encoder and decoder of BVAE include
MultilayerPerceptron(MLP),ConvolutionalNeuralNetwork(CNN),
Recurrent Neural Network (RNN), etc. As a proof-of-concept im-plementation, we use the simplest, i.e. MLP, as the encoder anddecoderfor retrievaltask,since morepowerful modelsareharder
to train when VAE is applied to text [6].
Weusethebag-of-wordsassumptionforbothsourcecodeand
natural language. We design the same architectures for C-VAE and
L-VAE. Given a sequence of tokens (code or natural language), em-
beddingsoftokensarefirstaveraged,followedbya tanhactivation.
Then,severalfully-connectedlayersareappliedtopredicttheposte-
rior distribution qϕ(z|x). Formally, the encoder takes the following
form:
h(0)=tanh(1
TT/summationdisplay.1
t=1et),
h(e)=FCle(h(0)),
μ=W(μ)·h(e)+b(μ),
diag(σ)=exp(W(σ)·h(e)+b(σ)),(10)
whereTis the number of tokens in the given code snippet cor
naturallanguage query l,etistheembedding ofthe tthtokenwt,
FCrepresentsthefully-connectedlayerwith tanhactivationand le
is the number of FClayers. It means identity function when leis 0.
The decoder generates each token independently conditioned
onz. Formally, it takes the following form:
z(s)∼N( z|μ,diag(σ2)),
h(d)=FCld(z(s)),
h(o)=softmax(W(o)·h(d)+b(o)),(11)
whereldisthenumberofFClayersinthedecoder,and h(o)∈R|V|
(|V|is the number of unique tokens) contains the probability of
each token conditioned on the latent variable z.
The reconstruction loss is:
R(ϕ,θ;x)=T/summationdisplay.1
t=1−logpθ(wt|z), (12)
wherepθ(wt|z)is gathered from h(o).
In order to force C-VAE and L-VAE to encode more important
information in the latent variables,we find it beneficial to use the
inverse document frequency (IDF) as weight in the reconstruction
loss, i.e.:
R(ϕ,θ;x)=T/summationdisplay.1
t=1−idf(wt)∗logpθ(wt|z)
=/summationdisplay.1
w∈W−tf(w)∗idf(w)∗logpθ(w|z),(13)
whereWis the set of unique tokens in given corl, andtfde-
notestermfrequency(TF).IDFofeachtokeniscomputedbasedon
training set.
After the training process of BVAE finishes, the mean μcfor
the posterior distribution qϕc(zc|xc)of the snippet can be com-
putedoff-lineforarbitrarycodesnippet c.Givenanaturallanguage
queryl,itsmean μlfortheposteriordistribution qϕl(zl|xl)should
be first calculated and then similarity-search algorithms in high-
dimensionalspacescanbeappliedtoretrievethehighlyrelevant
code snippets.
Otherthan sequentialscan, manysimilarity-search algorithms,
suchasBest-Bin-First[ 4],VA-File[ 5,30]andFFVA[ 28],havebeen
828
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Qingying Chen and Minghui Zhou

 
  
	
 	

Figure 2: The decoder of L-VAE for code summarization at
training time. Dashed lines are used to indicate that the in-put dropout technique is applied here.
proposed,andcanbeappliedheretocoderetrieval.Clearly,com-
pared with models that require sequential scan, BVAE is more
suitableforefficientretrievalonlargescaledatasets.Further,BVAE
supportsretrievingcodesnippetsthatarenotpairedwithnatural
language descriptions. This feature allows leveraging vast amount
of code available in open source repositories on GitHub.
While conducting the experiments, for simplicity, we use cosine
similaritybetween μlandμc(vectorrepresentationofqueryand
snippet) to rank candidate code snippets.
3.4 BVAE for Code Summarization
For code summarization task, we use the same architecture as that
forcoderetrieval,exceptthatthedecoderofL-VAEisanRNN,in
order to generate a sequence of words.
Figure2depicts the architecture of RNN decoder of L-VAE at
training time. Specifically, we use Gated Recurrent Unit (GRU, [ 7])
as the RNN cell. The latent variable is used as the initial state of
RNNafteranFCtransformation.Theinputofthedecoderiswords
from golden text. In order to force the decoder to rely more on the
latent variable, we adopt the input dropout technique [ 6], which
randomlyreplacessomefractionofinputswiththeunknowntoken
<UNK>. The target words are that of original text shifted left by
one word. The reconstruction loss is computed by:
Rl(ϕl,θl;xl)=T/summationdisplay.1
t=1−logpθl(wt|zl,w1,w2,···,wt−1),(14)
Givenonespecificcodesnippet c,itsμcofqϕc(zc|xc)shouldbe
firstcomputedandthenfed intothedecoderofL-VAE,whichcan
generate new text from latent space. The output of L-VAE is taken
asthesummaryofthegivencodesnippet c.Intuitively,thedecoder
ofL-VAEgeneratesthesummaryfromthelatentvariableofcode,
which is inferred by the encoder of C-VAE.
Different from training process, at test time, the input of one
RNN step is the word generated in its previous step. Beam search2
is employed here to help generate a better summary.
3.5 Implementation Details
3.5.1 Source Code Tokenization. We use modified versions of
an ANTLR parser for C# and python-sqlparse for SQL to tokenize
sourcecode.Inthetokenizationprocess,commentsareremoved,
2https://en.wikipedia.org/wiki/Beam_searchandliteralsarereplacedwiththeircorrespondingtypes.ForSQL,
names of tables and columns are replaced with numbered place-
holder tokens while preserving any dependencies in the query, for
example, SQL query “SELECT Max(score) FROM student_score”
is turned into “SELECT Max(col0) FROM tab0”. For C#, SQL and
natural language, tokens occurring less than 3 times in training set
are replaced with their corresponding <UNK> token.
3.5.2 Hyperparameters. WesetalltheembeddingsizesofC#,
SQLandnaturallanguageto256andlatentsizeto128.Aftertry-
ingsomeexplorativeexperiments,wefindthatMPRegperforms
slightly better than PReg on code summarization task for SQL and
on code retrieval for both C# and SQL, while PReg can achieve
better performance on code summarization for C# than MPReg.
Therefore,weuseMPRegforallexperimentsexceptthatofcode
summarization for C#. IDF is used to weigh the reconstruction lossofC-VAEandL-VAEonlyforSQLdataset,sincewefindthereisno
significant improvement for C# dataset after IDF is used. αc,βc,αl
andβlare set to 0.35, 0.15, 0.35 and 0.15 respectively. For code
retrieval,both leandldaresetto1,andhiddensizeinFClayeris
256. For code summarization, leandldare set to 0,GRU state size
is256,thekeepprobabilityofinputdropoutis0.2,thebeamsearch
size is 10 and the maximum summary length when decoding is 20.
Alltrainable parametersareinitialized withXavierinitialization
[8]. We use Adam optimizer to train the models with batch size of
64, start with a learning rate of 0.005 and decay it by a factor of 0.8
after 3 epochs if the loss on training set does not decrease in allrecent 3 epochs. When the model performance on DEV set does
not increase in a certain number of epochs, we save the model and
evaluate its performance on EVAL set.
4 EXPERIMENT SETUP
4.1 Dataset
ThedatasetforexperimentswascollectedfromStackOverflow(SO)
by Iyer et al. [ 13]. This dataset contains 52812 pairs of <C# code,
naturallanguagedescription>fortraining,6601pairsforvalidation
and 6602 pairs for test. For SQL, these numbers are 25671, 3326
and3340.These pairswereextractedfrompostsofSO, wherethe
title of a post was taken as the natural language description and
the code snippet in some accepted answer was considered as an
implementation of the corresponding title. To get a high-quality
dataset, Iyer et al. [ 13] trained a semi-supervised classifier to filter
out bad posts that have no relation to the corresponding code
snippet.
For code summarization task, a given code snippet can be de-
scribed in many different ways with little overlapping content
between them, which may make automatic evaluation less reli-
able. To mitigate this issue, Iyer et al. [ 13] provided two additional
human-annotated titles for each of 200 code snippets randomly
chosenfromthetestset.Halfofthe200codesnippetswasusedfor
model tuning (DEV set), and the rest for evaluation (EVAL set).
4.2 Code Retrieval
4.2.1 Baseline Models. RET-IR: Candidate code snippets are
rankedaccordingtocosinesimilaritybetweenthequeryandnat-
urallanguagedescriptionsthatareassociatedwithcodesnippets.
829
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. A Neural Framework for Retrieval and Summarization of Source Code ASE ’18, September 3–7, 2018, Montpellier, France
Herein,TF-IDFweightsareusedasfeaturestocomputecosinesim-
ilarity.Thismodelcanonlyretrievecodesnippetsthatarepaired
with descriptions.
MSAE[29]: MSAE is a multi-modal retrieval model based on
stackedautoencoders(AE).ItsoverallframeworkissimilartoBVAE,
butitconsistsofAEsandhasnolatentvariables.MSAEseeksto
ensure the closeness (Euclidean Squared distance) between the hid-
den states of two AEs. We design the same encoders and decoders
of MSAE as those of BVAE (see Section 3.3).
CODE-NN [13]: Prior to our study, CODE-NN achieves the-
state-of-the-art performance on the same dataset for both tasks. It
employs an attention-based sequence-to-sequence architecture to
modeltheprobabilityofnaturallanguageconditionedonsource
code. Source code is tokenized to a sequence and then fed into a
Long Short Term Memory (LSTM, [ 10]) encoder. The decoder, also
an LSTM network, computes the distribution of word step by step,
guided by a global attention mechanism [18].
4.2.2 Evaluation Method. For code snippet ciin DEV or EVAL,
one of the two human-annotated titles is taken as the query, while
thecollecteddescriptionassociatedwith ciisusedforcalculation
of cosine similarity in RET-IR and not used in both CODE-NN and
our model. Forty-nine snippets randomly chosen from the test set
areusedasdistractors,and,alongwiththegoldenone ci,comprise
the retrieval set. All the 50 snippets are ranked by a specific model,
and the rank of the golden snippet ci, denoted by ri,i su s e dt o
computetheMeanReciprocalRank(MRR)3.Werepeat20timesthe
procedure for different random distractor snippets and compute
the mean with 0.95 confidence interval of the MRR.
4.3 Code Summarization
4.3.1 Baseline Models. IR: Given snippet c, retrieve csmost
similar to cin terms of token Levenshtein distance and take the
description of csas the summary of c.
MOSES[16]: A phrase-based machine translation system.
SUM-NN [25]:Aneuralattentionmodelforabstractivesentence
summarizationwhichemploysanattention-basedencoder-decoder
architecturethatgeneratesnextwordconditionedonafixedwin-
dow of previously generated words.
MSAE[29]: MSAE focuses only on retrieval task originally. We
extend it to summarization task in the same way we extend BVAE.
CODE-NN [13]:Anattention-basedsequence-to-sequencemodel
asdescribedinSection 4.2.1.CODE-NNalsousesbeamsearchto
generate summary with the beam size of 10 and the maximum
summary length of 20. We use the same value for the two hyperpa-
rameters in our model.
4.3.2 Evaluation Method. There are three reference texts for
each code snippet in DEV and EVAL. We evaluate the generated
textbycomputingBLEU-4score[ 23]andMETEORscore[ 3]against
the reference texts. Both metrics are commonly used for automatic
evaluation of machine translation.
BLEU-4 measures the average n-gram precision with length
penalty for short texts. METEOR computes a matching score using
a combination of unigram-precision, unigram-recall and a measure
of fragmentation that is designed to directly capture how well-orderedthematchedwordsinthegeneratedtextsareinrelation
3https://en.wikipedia.org/wiki/Mean_reciprocal_rankTable 1: Results for code retrieval task. Results on DEV set
are in parentheses.
Model MRRC#RET-IR 0.42±0.02(0.44±0.01)
MSAE 0.49±0.01(0.53±0.01)
CODE-NN 0.58±0.01(0.66±0.02)
BVAE 0.73±0.01(0.80±0.01)SQLRET-IR 0.28±0.01(0.40±0.01)
MSAE 0.35±0.01(0.33±0.01)
CODE-NN 0.44±0.01(0.54±0.02)
BVAE 0.50±0.01(0.52±0.01)
Table 2: Results for code summarization task. Results on
DEV set are in parentheses.
Model BLEU-4 METEOR
C#IR 13.7 (12.6) 7.9 (6.1)
MOSES 11.6 (11.5) 9.1 (9.7)
SUM-NN 19.3 (18.2) 10.6 (10.3)
MSAE 16.1 (17.1) 8.1 (10.7)
CODE-NN 20.5 (20.4) 12.3 (13.4)
BVAE 20.9 (20.5) 12.9(12.6)
SQLIR 13.5 (13.0) 6.3 (8.0)
MOSES 15.4 (15.9) 6.3 (8.0)
SUM-NN 13.3 (14.2) 6.4 (8.7)
MSAE 16.7 (16.5) 8.3 (8.6)
CODE-NN 18.4 (17.0) 10.9 (14.0)
BVAE 19.7 (21.0) 10.6 (12.7)
to thereference texts. Inthe experiments, weuse METEOR asthe
mainmetric,i.e.reportBLEU-4scorewhenthemodelachievesbest
METEOR score on DEV set.
5 RESULTS
Table1shows the results for code retrieval task. For C#, our model
outperforms all baselines by a large margin. For SQL, our model is
somewhatworsethanCODE-NNonDEVset,butismuchbetter
on EVAL set.
Table2showstheresultsforcodesummarizationtask.ForC#,
ourmodeloutperformsallbaselinesonbothmetrics,exceptCODE-
NN on METEOR score on DEV set. For SQL, our model achievesbetter performance other than CODE-NN, but its BLEU-4 scores
arelowerthanours.Throughmanualinspection,wefindthatthe
summariesgeneratedbyCODE-NNareusuallylongerthanthose
generated by BVAE.
BVAE performs much better than MSAE. We can conclude that
incorporating latent variables benefits both tasks.
To sum up, BVAE leads to a significant improvement for re-
trieval task. For summarization task, BVAE achieves comparableperformance to previous best model CODE-NN, although with-out significant improvement, more powerful structure for latent
variables (diagonal Gaussian now) along with better encoders and
decoderscanbedesignedinthefuturetoimprovethetask,since
830
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Qingying Chen and Minghui Zhou
BVAE is a framework and current results have demonstrated its
potential.
6 THREATS TO VALIDITY
Internal validity : The dataset for experiments were extracted
from posts of StackOverflow [ 13], therefore its generation process
wasnotexactlythesameasthewaydevelopersretrieveorsumma-
rize snippets in the real world. This threat was mitigated by two
efforts.First,asemi-supervisedclassifierwastrainedtofilterout
bad posts that have no relation to the corresponding code snip-
pet. Second, two additional human-annotated descriptions were
provided for each test snippet.
Forretrievaltask,theretrievalsetconsistsofonegoldensnippet
and forty-nine randomly chosen distractors. Although this setting
differs from the real world, it is effective to demonstrate if a model
outperforms another one.
For summarization task, we use BLEU-4 and METEOR scores to
evaluate the quality of summaries automatically. Although the two
metricsarecommonlyusedinthefieldofmachinetranslation,it
would be better to perform another human-evaluation process.
External validity : Could the results be generalized to other
programming languages? Theoretically, BVAE can be applied to
anyprogramminglanguage.WeevaluateBVAEonC#,ageneral-
purposeimperativelanguage,andSQL,adeclarativelanguagefor
queryingdatabases.TheexperimentresultsdemonstrateBVAE’s
potential on both languages.
7 CONCLUSION AND FUTURE WORK
In this paper, we present a neural framework, termed as BVAE,for retrieval and summarization of source code. We design two
instancesofBVAEforretrievalandsummarizationrespectively,and
evaluate their performance on a benchmark involving C# and SQL.
Comparedwithpreviousbestapproach,BVAEleadstoasignificant
improvementforretrievalandachievescomparableperformance
for summarization task. The results demonstrate BVAE’s potential
on the two tasks.
In future work, we plan to employ morepowerful structure for
latentvariablesanddesignbetterencodersanddecodersforbothC-
VAE and L-VAE. Besides, since BVAE allows bidirectional mapping
between source code and natural language, we will attempt to
extend it to code generation task.
ACKNOWLEDGMENTS
ThisworkissupportedbytheNationalNaturalScienceFoundation
ofChinaGrants61432001and61690200,theNationalBasicResearch
ProgramofChinaGrant2015CB352200,andtheNationalkeyre-
searchanddevelopmentprogramofChinaGrant2018YFB10044200.
REFERENCES
[1]Miltos Allamanis, Daniel Tarlow, Andrew Gordon, and Yi Wei. 2015. Bimodal
modelling of source code and natural language. In ICML. 2123–2132.
[2]Sushil Bajracharya, Joel Ossher, and CristinaLopes. 2014. Sourcerer: An infras-
tructureforlarge-scalecollectionandanalysisofopen-sourcecode. Scienceof
Computer Programming 79 (2014), 241–259.
[3]Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for
MT evaluation withimproved correlation with humanjudgments. In Proceedings
of the acl workshop on intrinsic and extrinsic evaluation measures for machine
translation and/or summarization. 65–72.[4]Jeffrey S Beis and David G Lowe. 1997. Shape indexing using approximate
nearest-neighboursearchinhigh-dimensionalspaces.In CVPR.IEEE,1000–1006.
[5]Stephen Blott and Roger Weber. 1997. A simple vector-approximation file for
similarity search in high-dimensional vector spaces. ESPRIT Technical Report
TR19, ca(1997).
[6]Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz,
and Samy Bengio. 2016. Generating Sentences from a Continuous Space. In
ProceedingsofThe20thSIGNLLConferenceonComputationalNaturalLanguage
Learning. 10–21.
[7]Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase
representations using RNN encoder-decoder for statistical machine translation.
arXiv preprint arXiv:1406.1078 (2014).
[8]Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of trainingdeep feedforward neural networks. In Proceedings of the Thirteenth International
Conference on Artificial Intelligence and Statistics. 249–256.
[9]Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep code search. In
Proceedingsofthe40thInternationalConferenceonSoftwareEngineering.ACM,
933–944.
[10]SeppHochreiterandJürgenSchmidhuber.1997. Longshort-termmemory. Neural
computation 9, 8 (1997), 1735–1780.
[11]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code comment
generation. In ICPC.
[12]Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, and Zhi Jin. 2018. Summarizing
Source Code with Transferred API Knowledge.. In IJCAI. 2269–2275.
[13]Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.
Summarizing sourcecode usinga neural attentionmodel. In ACL, Vol.1. 2073–
2083.
[14]Iman Keivanloo, Juergen Rilling, and Ying Zou. 2014. Spotting working code
examples. In ICSE. ACM, 664–675.
[15]Diederik P Kingma and Max Welling. 2014. Auto-encoding variational bayes. In
ICLR.
[16]Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello
Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al .2007. Moses: Open source toolkit for statistical machine translation.
InProceedings of the 45th annual meeting of the ACL on interactive poster and
demonstration sessions. ACL, 177–180.
[17]Georgia Koutrika, Alkis Simitsis, and Yannis E Ioannidis. 2010. Explaining struc-
tured queries in natural language. In ICDE. IEEE, 333–344.
[18]Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective
approaches to attention-based neural machine translation. In EMNLP. 1412âĂŞ–
1421.
[19]PaulWMcBurneyandCollinMcMillan.2016. Automaticsourcecodesumma-
rization of contextfor java methods. IEEE Transactionson Software Engineering
42, 2 (2016), 103–119.
[20]Laura Moreno, Jairo Aponte, Giriprasad Sridhara, Andrian Marcus, Lori Pollock,
andKVijay-Shanker.2013. Automaticgenerationofnaturallanguagesummaries
for java classes. In ICPC. IEEE, 23–32.
[21]Dana Movshovitz-Attias and William W. Cohen. 2013. Natural language models
for predicting programming comments. In ACL. 35–40.
[22]Axel-Cyrille Ngonga Ngomo, Lorenz Bühmann, Christina Unger, Jens Lehmann,
and Daniel Gerber. 2013. Sorry, i don’t speak SPARQL: translating SPARQL
queries into natural language. In WWW. ACM, 977–988.
[23]KishorePapineni,SalimRoukos,ToddWard,andWei-JingZhu.2002. BLEU:a
method for automatic evaluation of machine translation. In ACL. ACL, 311–318.
[24]Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic
backpropagationandapproximateinferenceindeepgenerativemodels.In ICML.
[25]AlexanderMRush,SumitChopra,andJasonWeston.2015. Aneuralattention
model for abstractive sentence summarization. In EMNLP. 379âĂŞ–389.
[26]Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, and K Vijay-
Shanker.2010. Towardsautomaticallygeneratingsummarycommentsforjava
methods. In Proceedings of the IEEE/ACM international conference on Automated
software engineering. ACM, 43–52.
[27]Giriprasad Sridhara, Lori Pollock, and K Vijay-Shanker. 2011. Automatically
detecting and describing high level actions within methods. In ICSE. ACM, 101–
110.
[28]Quan Wang and Suya You. 2006. Fast similarity search for high-dimensionaldataset. In Multimedia, 2006. ISM’06. Eighth IEEE International Symposium on.
IEEE, 799–804.
[29]WeiWang,BengChinOoi,XiaoyanYang,DongxiangZhang,andYuetingZhuang.2014. Effectivemulti-modalretrievalbasedonstackedauto-encoders. Proceedings
of the VLDB Endowment 7, 8 (2014), 649–660.
[30]Roger Weber, Hans-Jörg Schek, and Stephen Blott. 1998. A quantitative analysis
andperformancestudyforsimilarity-searchmethodsinhigh-dimensionalspaces.
InVLDB, Vol. 98. 194–205.
831
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:53 UTC from IEEE Xplore.  Restrictions apply. 