Concolic Testing for Deep Neural Networks∗
Youcheng Sun
University of Oxford, UK
youcheng.sun@cs.ox.ac.ukMin Wu
University of Oxford, UK
min.wu@cs.ox.ac.ukWenjie Ruan
University of Oxford, UK
wenjie.ruan@cs.ox.ac.uk
Xiaowei Huang
University of Liverpool, UK
xiaowei.huang@liverpool.ac.ukMarta Kwiatkowska
University of Oxford, UK
marta.kwiatkowska@cs.ox.ac.ukDaniel Kroening
University of Oxford, UK
kroening@cs.ox.ac.uk
ABSTRACT
Concolictestingcombinesprogramexecutionandsymbolicanal-
ysis to explore the execution paths of a software program. This
paper presents the first concolic testing approach for Deep Neural
Networks(DNNs).Morespecifically,weformalisecoveragecriteria
forDNNsthathavebeenstudiedintheliterature,andthendevelop
a coherent method for performing concolic testing to increase test
coverage.Ourexperimentalresultsshowtheeffectivenessoftheconcolic testing approach in both achieving high coverage and
finding adversarial examples.
CCS CONCEPTS
•Software and its engineering →Software defect analysis;
KEYWORDS
neural networks, symbolic execution, concolic testing
ACM Reference Format:
YouchengSun,MinWu,WenjieRuan,XiaoweiHuang,MartaKwiatkowska,
and Daniel Kroening. 2018. Concolic Testing for Deep Neural Networks. In
Proceedingsofthe201833rdACM/IEEEInternationalConferenceonAutomated
Software Engineering (ASE ’18), September 3–7, 2018, Montpellier, France.
ACM,NewYork,NY,USA, 11pages.https://doi.org/10.1145/3238147.3238172
1 INTRODUCTION
Deep neural networks (DNNs) have been instrumental in solving a
rangeofhardproblemsinAI,e.g.,theancientgameofGo,image
classification,andnaturallanguageprocessing.Asaresult,many
potentialapplicationsareenvisaged.However,majorconcernshave
beenraisedaboutthesuitabilityofthistechniqueforsafety-and
security-critical systems, where faulty behaviour carries the risk
of endangering human lives or financial damage. To address these
concerns, a (safety or security) critical system comprising DNN-
based components needs to be validated thoroughly.
∗KwiatkowskaandRuanaresupportedbyEPSRCMobileAutonomyProgrammeGrant
(EP/M019918/1). Wu is supported by the CSC-PAG Oxford Scholarship.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5937-5/18/09.
https://doi.org/10.1145/3238147.3238172The software industry relies on testing as a primary means to
provide stakeholders with information about the quality of the
software product or service under test [ 12]. So far, there have been
onlyfewattemptstotestDNNssystematically[ 15,18,23,25,30].
Theseareeitherbasedonconcreteexecution,e.g.,MonteCarlotree
search[30]orgradient-basedsearch[ 15,18,25],orsymbolicexecu-
tionincombinationwithsolversforlineararithmetic[ 23].Together
withthesetest-inputgenerationalgorithms,severaltestcoverage
criteria have been presented, including neuron coverage [ 18], a
criterion that is inspired by MC/DC [ 23], and criteria to capture
particular neuron activation values to identify corner cases [ 15].
None of these approaches implement concolic testing [8,22], which
combines concrete execution and symbolic analysis to explore the
execution paths of a program that are hard to cover by techniques
such as random testing.
We hypothesise that concolic testing is particularly well-suited
forDNNs.TheinputspaceofaDNNisusuallyhighdimensional,
whichmakesrandomtestingdifficult.Forinstance,aDNNforimage
classification takes tens of thousands of pixels as input. Moreover,
owing to the widespread use of the ReLU activation function for
hiddenneurons,thenumberof“executionpaths"inaDNNissimply
toolargetobecompletelycoveredbysymbolicexecution.Concolictestingcanmitigatethiscomplexitybydirectingthesymbolicanal-
ysistoparticularexecutionpaths,throughconcretelyevaluating
given properties of the DNN.
In this paper, we present the first concolic testing method for
DNNs. The method is parameterised using a set of coverage re-
quirements, which we express using Quantified Linear Arithmetic
over Rationals(QLAR). For a given set Rof coveragerequirements,
we incrementally generate a set of test inputs to improve coverage
byalternating betweenconcrete executionand symbolicanalysis.
Given an unsatisfied test requirement r, we identify a test input
twithin our current test suite such that tis close to satisfying r
accordingtoanevaluationbasedon concreteexecution .Afterthat,
symbolic analysis is applied to obtain a new test input t/primethat satis-
fiesr. The test input t/primeis then added to the test suite. This process
is iterated until we reach a satisfactory level of coverage.
Finally, the generated test suite is passed to a robustness ora-
cle, which determines whether the test suite includes adversarial
examples [24], i.e., pairs of test cases that disagree on their clas-
sificationlabelswhenclosetoeachotherwithrespecttoagiven
distance metric. The lack of robustness has been viewed as a major
weakness of DNNs, and the discovery of adversarial examples and
the robustness problem are studied actively in several domains,
including machine learning, automated verification, cyber security,
and software testing.
109
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Y. Sun, M. Wu, W. Ruan, X. Huang, M. Kwiatkowska, D. Kroening
Overall, the main contributions of this paper are threefold:
(1) We develop the first concolic testing method for DNNs.
(2)We evaluate the method with a broad range of test coverage
requirements,includingLipschitzcontinuity[ 1,3,20,29,30]
andseveralstructuralcoveragemetrics[ 15,18,23].Weshow
experimentallythatour newalgorithmsupports thisbroad
range of properties in a coherent way.
(3)Weimplementtheconcolictestingmethodinthesoftware
toolDeepConcolic1. Experimental results show that Deep-
Concolicachieveshighcoverageandthatitisabletodiscover
a significant number of adversarial examples.
2 RELATED WORK
We briefly review existing efforts for assessing the robustness of
DNNs and the state of the art in concolic testing.
2.1 Robustness of DNNs
Current work on the robustness of DNNs can be categorised as
offensive or defensive. Offensive approaches focus on heuristic
search algorithms(mainly guided by theforward gradient orcost
gradient of the DNN) to find adversarial examples that are as close
as possible to a correctly classified input. On the other hand, the
goalofdefensiveworkistoincreasetherobustnessofDNNs.There
is an arms race between offensive and defensive techniques.
In this paper we focus on defensive methods. A promising ap-
proach is automated verification, which aims to provide robust-
ness guarantees for DNNs. The main relevant techniques include a
layer-by-layer exhaustive search [ 11], methods that use constraint
solvers[14],globaloptimisationapproaches[ 20]andabstractinter-
pretation[ 7,16]toover-approximateaDNN’sbehavior.Exhaustive
searchsuffersfromthestate-spaceexplosionproblem,whichcan
be alleviated by Monte Carlo tree search [ 30]. Constraint-based
approachesarelimitedtosmallDNNswithhundredsofneurons.
Global optimisation improves over constraint-based approaches
through its ability to work with large DNNs, but its capacity is sen-sitive to the number of input dimensions that need to be perturbed.
Theresultsofover-approximatinganalysescanbepessimisticbe-
cause of false alarms.
The application of traditional testing techniques to DNNs is dif-
ficult,andworkthatattemptstodosoismorerecent,e.g.,[ 15,18,
23,25,30]. Methods inspired by software testing methodologies
typicallyemploycoveragecriteriatoguidethegenerationoftest
cases; the resulting test suite is then searched for adversarial ex-
amples by querying an oracle. The coverage criteria considered
includeneuroncoverage [18],whichresemblestraditionalstatement
coverage.AsetofcriteriainspiredbyMD/DCcoverage[ 10]isused
in[23];Maetal.[ 15]presentcriteriathataredesignedtocapture
particular values of neuron activations. Tian et al. [ 25] study the
utility of neuron coverage for detecting adversarial examples in
DNNs for the Udacity-Didi Self-Driving Car Challenge.
We now discuss algorithms for test input generation. Wicker et
al.[30]aimtocovertheinputspacebyexhaustivemutationtesting
thathastheoreticalguarantees,whilein[ 15,18,25]gradient-based
search algorithms are applied to solve optimisation problems, and
Sunetal.[ 23]applylinearprogramming.Noneoftheseconsider
1https://github.com/TrustAI/DeepConcolicconcolic testing and a general means for modeling test coverage
requirements as we do in this paper.
2.2 Concolic Testing
By concretely executing the program with particular inputs, which
includes random testing, a large number of inputs can be tested at
low cost. However, without guidance, the generated test cases may
be restricted to a subset of the execution paths of the program and
the probability of exploring execution paths that contain bugs can
beextremelylow.Insymbolicexecution[ 5,26,32],anexecution
path is encoded symbolically. Modern constraint solvers can deter-
mine feasibility of the encoding effectively, although performance
stilldegradesasthesizeofthesymbolicrepresentationincreases.
Concolic testing[ 8,22] isan effective approach toautomated test
inputgeneration.Itisahybridsoftwaretestingtechniquethatalter-
nates between concrete execution, i.e., testing on particular inputs,
andsymbolicexecution,aclassicaltechniquethattreatsprogram
variables as symbolic values [13].
Concolic testing has been appliedroutinely in software testing,
and a wide range of tools is available, e.g., [ 4,8,22]. It starts by
executing the program with a concrete input. At the end of the
concreterun,anotherexecutionpathmustbeselectedheuristically.
This new execution path is then encoded symbolically and the
resulting formula is solved by a constraint solver, to yield a new
concreteinput. Theconcrete execution andthe symbolicanalysis
alternate until a desired level of structural coverage is reached.
Thekeyfactorthataffectstheperformanceofconcolictestingis
theheuristicsusedtoselectthenextexecutionpath.Whilethereare
simpleapproachessuchasrandomsearchanddepth-firstsearch,
morecarefullydesignedheuristicscanachievebettercoverage[ 4,9].
Automatedgenerationofsearchheuristicsforconcolictestingis
an active area of research [6, 27].
2.3 Comparison with Related Work
We briefly summarise the similarities and differences between
our concolic testing method, named DeepConcolic, and other ex-
isting coverage-driven DNN testing methods: DeepXplore [ 18],
DeepTest[ 25],DeepCover[ 23],andDeepGauge[ 15].Thedetails
are presented in Table 1, where NC, SSC, and NBC are short for
NeuronCoverage,SSCoverage,andNeuronBoundaryCoverage,
respectively. In addition to the concolic nature of DeepConcolic,
we observe the following differences.
•DeepConcolic is generic, and is able to take coverage re-
quirementsasinput;the othermethodsare adhoc,andare
tailored to specific requirements.
•DeepXplorerequiresasetofDNNstoexploremultiplegradi-
ent directions. The other methods, including DeepConcolic,
need a single DNN only.
•In contrast to the other methods, DeepConcolic can achieve
good coverage by starting from a single input; the other
methods need a non-trivial set of inputs.
•Untilnow,thereisnoconclusiononthebestdistancemetric.
DeepConcolic can be parameterized with a desired norm
distance metric ||·||.
Moreover,DeepConcolicfeaturesacleanseparationbetweenthe
generationoftestinputsandthetestoracle.Thisisagoodfitfor
110
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. Concolic Testing for Deep Neural Networks ASE ’18, September 3–7, 2018, Montpellier, France
Table 1: Comparison with different coverage-driven DNN testing methods
DeepConcolic DeepXplore [18] DeepTest [25] DeepCover [23] DeepGauge [15]
Coverage criteria NC, SSC, NBC etc. NC NC MC/DC NBC etc.
Test generation concolic dual-optimisation greedy search symbolic execution gradient descent methods
DNN inputs single multiple single single single
Image inputs single/multiple multiple multiple multiple multiple
Distance metric L∞andL0-norm L1-norm Jaccard distance L∞-norm L∞-norm
traditionaltestcasegeneration.Theothermethodsusetheoracle
as part of their objectives to guide the generation of test inputs.
3 DEEP NEURAL NETWORKS
A (feedforward and deep) neural network, or DNN, is a tuple N=
(L,T,Φ)such that L={Lk|k∈{1,...,K}}is a set of layers, T⊆
L×Lis a set of connections between layers, and Φ={ϕk|k∈
{2,...,K}}isasetof activationfunctions.Eachlayer Lkconsistsof
skneurons,andthe l-thneuronoflayer kisdenotedby nk,l.W euse
vk,lto denote the value of nk,l. Values of neurons in hidden layers
(with 1<k<K) need to pass through a Rectified Linear Unit
(ReLU)[17].Forconvenience,weexplicitlydenotetheactivation
value before the ReLU as uk,lsuch that
vk,l=ReLU(uk,l)=/braceleftBigg
uk,lifuk,l≥0
0 otherwise(1)
ReLU isthe mostpopular activationfunction for neuralnetworks.
Exceptforinputs,everyneuronisconnectedtoneuronsinthe
precedinglayerbypre-definedweightssuchthat ∀1<k≤K,∀1≤
l≤sk,
uk,l=/summationdisplay.1
1≤h≤sk−1{wk−1 ,h,l·vk−1 ,h}+bk,l (2)
wherewk−1 ,h,lis the pre-trained weight for the connection be-
tweennk−1 ,h(i.e., theh-th neuron of layer k−1) andnk,l(i.e., the
l-th neuron of layer k), andbk,lis thebias.
Finally, for any input, the neural network assigns a label, that
is,theindexoftheneuronoftheoutputlayerthathasthelargest
value, i.e., label=argmax1≤l≤sK{vK,l}.
Due to the existence of ReLU, the neural network is a highly
non-linearfunction. Inthis paper,we usevariable xtorange over
all possible inputs in the input domain DL1and uset,t1,t2,...to
denote concrete inputs. Given a particular input t, we say that the
DNNNis instantiated and we use N[t]to denote this instance of
the network.
•Given a network instance N[t], the activation values of
eachneuron nk,lofthenetworkbeforeandafterReLUare
denoted as u[t]k,landv[t]k,l, respectively, and the final
classificationlabelis label[t].Wewrite u[t]kandv[t]kfor
1≤k≤sktodenotethevectorsofactivationsforneurons
in layerk.
•When the input is given, the activation or deactivation of
each ReLU operator in the DNN is determined.
We remark that, while for simplicity the definition focuses on
DNNs with fully connected and convolutional layers, as shownin the experiments (Section 10) our method also applies to other
popular layers, e.g., maxpooling, used in state-of-the-art DNNs.
4 TEST COVERAGE FOR DNNS
4.1 Activation Patterns
Asoftwareprogramhasasetofconcreteexecutionpaths.Similarly,
a DNN has a set of linear behaviours called activation patterns [23].
Definition 4.1 (Activation Pattern). Given a network Nand an
inputt, the activation pattern of N[t]is a function ap[N,t]that
maps the set of hidden neurons to {true,false}. We write ap[t]for
ap[N,t]ifNis clear from the context. For an activation pattern
ap[t],w euseap[t]k,itodenotewhethertheReLUoperatorofthe
neuronnk,iis activated or not. Formally,
ap[t]k,l=false≡u[t]k,l<v[t]k,l
ap[t]k,l=true≡u[t]k,l=v[t]k,l(3)
Intuitively, ap[t]k,l=trueif the ReLU of the neuron nk,lis
activated, and ap[t]k,l=falseotherwise.
GivenaDNNinstance N[t],eachReLUoperator’sbehaviour(i.e.,
eachap[t]k,l)isfixedandthisresultsintheparticularactivation
patternap[t],whichcanbeencodedbyusingaLinearProgramming
(LP) model [23].
Computing a test suite that covers all activation patterns of
a DNN is intractable owing to the large number of neurons in
pratically-relevant DNNs. Therefore, we identify a subset of the
activation patterns according to certain coverage criteria, and then
generate test inputs that cover these activation patterns.
4.2 Formalizing Test Coverage Criteria
We use a specific fragment of Quantified Linear Arithmetic over
Rationals (QLAR) to express the coverage requirements on the test
suite for a given DNN. This enables us to give a single test input
generation algorithm(Section 8) fora varietyof coverage criteria.
We denote the set of formulas in our fragment by DR.
Definition 4.2. Given a network N, we write IV={x,x1,x2,...}
for a set of variables that range over the all inputs DL1of the
network. We define V={u[x]k,l,v[x]k,l|1≤k≤K,1≤l≤
sk,x∈IV}tobeasetofvariablesthatrangeovertherationals.We
fix the following syntax for DR formulas:
r::=Qx.e|Qx1,x2.e
e::=a⊿/triangleleft0|e∧e|¬e|| {e1,...,em}|⊿/triangleleftq
a::=w|c·w|p|a+a|a−a(4)
whereQ∈{∃,∀},w∈V,c,p∈R,q∈N,⊿/triangleleft∈{ ≤,<,=,>,≥},
andx,x1,x2∈IV. We callra coverage requirement, ea Boolean
111
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Y. Sun, M. Wu, W. Ruan, X. Huang, M. Kwiatkowska, D. Kroening
formula, and aan arithmetic formula. We call the logic DR+if the
negation operator ¬is not allowed. We use Rto denote a set of
coverage requirement formulas.
Theformula ∃x.eexpressesthatthereexistsaninput xsuchthat
eis true, while ∀x.eexpresses that eis true for all inputs x. The
formulas ∃x1,x2.eand∀x1,x2.ehave similar meaning, except that
theyquantifyovertwoinputs x1andx2.TheBooleanexpression
|{e1,...,em}|⊿/triangleleftqis true if the number of true Boolean expressions
intheset {e1,...,em}isinrelation⊿/triangleleftwithq.Theotheroperators
in Boolean and arithmetic formulas have their standard meaning.
Although Vdoesnotincludevariablestospecifyanactivation
patternap[x], we may write
ap[x1]k,l=ap[x2]k,landap[x1]k,l/nequalap[x2]k,l(5)
to require that x1andx2have, respectively, the same and different
activation behaviours on neuron nk,l. These conditions can be
expressedinthesyntaxaboveusingtheexpressionsinEquation (3).
Moreover,somenorm-baseddistancesbetweentwoinputscanbe
expressed using our syntax. For example, we can use the set of
constraints
{x1(i)−x2(i)≤q,x2(i)−x1(i)≤q|i∈{1,...,s1}}(6)
to express ||x1−x2||∞≤q, i.e., we can constrain the Chebyshev
distanceL∞between two inputs x1andx2, wherex(i)is thei-th
dimension of the input vector x.
Semantics. We define the satisfiability of a coverage requirement r
by a test suite T.
Definition 4.3. Given a set Tof test inputs and a coverage re-
quirement r, the satisfiability relation T|=ris defined as follows.
•T|=∃x.eif there exists some test t∈Tsuch that T|=
e[x/mapsto→t],wheree[x/mapsto→t]denotestheexpression einwhich
the occurrences of xare replaced by t.
•T|=∃x1,x2.eif there exist two tests t1,t2∈Tsuch that
T|=e[x1/mapsto→t1][x2/mapsto→t2]
The cases for ∀formulas are similar. For the evaluation of Boolean
expression eover an input t, we have
•T|=a⊿/triangleleft0i fa⊿/triangleleft0
•T|=e1∧e2ifT|=e1andT|=e2
•T|=¬eif notT|=e
•T|=|{e1,...,em}|⊿/triangleleftqif|{ei|T|=ei,i∈{1,...,m}}|⊿/triangleleftq
For the evaluation of arithmetic expression aover an input t,
•u[t]k,landv[t]k,lderive their values from the activation
patters of the DNN for test t, andc·u[t]k,landc·v[t]k,l
have the standard meaning where cis a coefficient,
•p,a1+a2, anda1−a2have the standard semantics.
Notethat Tisfinite.Itistrivialtoextendthedefinitionofthe
satisfaction relation to an infinite subspace of inputs.
Complexity. Givenanetwork N,aDRrequirementformula r,anda
testsuite T,checking T|=rcanbedoneintimethatispolynomial
in the size of T. Determining whether there exists a test suite T
withT|=ris NP-complete.4.3 Test Coverage Metrics
Now we can define test coverage criteria by providing a set of
requirements on the test suite. The coverage metric is defined inthestandardwayasthepercentageofthetestrequirementsthat
are satisfied by the test cases in the test suite T.
Definition 4.4 (Coverage Metric). Given a network N, a setRof
test coverage requirements expressed as DR formulas, and a test
suiteT, the test coverage metric M(R,T)is as follows:
M(R,T)=|{r∈R|T|=r}|
|R|(7)
The coverage is used as a proxy metric for the confidence in the
safety of the DNN under test.
5 SPECIFIC COVERAGE REQUIREMENTS
Inthissection,wegiveDR+formulasforseveralimportantcoverage
criteriaforDNNs,includingLipschitzcontinuity[ 1,3,20,29,30]
andtestcoveragecriteriafromtheliterature[ 15,18,23].Thecriteria
weconsiderhavesyntacticalsimilaritywithstructuraltestcoverage
criteria in conventional software testing. Lipschitz continuity is
semantic,specifictoDNNs,andhasbeenshowntobecloselyrelated
tothetheoreticalunderstandingofconvolutionalDNNs[ 29]and
therobustnessofbothDNNs[ 20,30]andGenerativeAdversarial
Networks [ 1]. These criteria have been studied in the literature
using a variety of formalisms and approaches.
Eachtestcoveragecriteriongivesrisetoasetoftestcoverage
requirements.Inthefollowing,wediscussthethreecoveragecri-
teria from [ 15,18,23], respectively. We use ||t1−t2||qto denote
thedistancebetweentwoinputs t1andt2withrespecttoagiven
distance metric ||·|| q. The metric ||·|| qcan be, e.g., a norm-based
metricsuch asthe L0-norm(the Hammingdistance), the L2-norm
(theEuclideandistance),or the L∞-norm(theChebyshevdistance),
or a structural similarity distance, such as SSIM [ 28]. In the follow-
ing, we fix a distance metric and simply write ||t1−t2||. Section10
elaborates on the particular metrics we use for our experiments.
Wemayconsiderrequirementsforasetofinputsubspaces.Given
arealnumber b,wecangenerateafiniteset S(DL1,b)ofsubspaces
ofDL1such that for all inputs x1,x2∈DL1,i f||x1−x2|| ≤b,
then there exists a subspace X∈S (DL1,b)such that x1,x2∈X.
The subspaces can be overlapping. Usually, every subspace X∈
S(DL1,b)canberepresentedwithaboxconstraint,e.g., X=[l,u]s1,
and therefore t∈Xcan be expressed with a Boolean expression as
follows.s1/logicalanddisplay.1
i=1x(i)−u≤0∧x(i)−l≥0 (8)
5.1 Lipschitz Continuity
In [20,24], Lipschitz continuity has been shown to hold for a large
class of DNNs, including DNNs for image classification.
Definition 5.1 (Lipschitz Continuity). A network Nis said to be
Lipschitzcontinuous ifthereexistsarealconstant c≥0suchthat,
for allx1,x2∈DL1:
||v[x1]1−v[x2]1|| ≤c·||x1−x2|| (9)
Recall that v[x]1denotes the vector of activation values of the neu-
ronsin theinput layer.The value ciscalled the Lipschitzconstant,
112
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. Concolic Testing for Deep Neural Networks ASE ’18, September 3–7, 2018, Montpellier, France
andthesmallestsuch ciscalledthe bestLipschitzconstant,denoted
ascbest.
Since the computation of cbestis an NP-hard problem and a
smallerccan significantly improve the performance of verification
algorithms [ 20,30,31], it is interesting to determine whether a
givencis a Lipschitz constant, either for the entire input space
DL1orforsomesubspace.TestingforLipschitzcontinuitycanbe
guided using the following requirements.
Definition5.2(LipschitzCoverage). Givenareal c>0andaninte-
gerb>0, the set RLip(b,c)of requirements for Lipschitz coverage
is
{∃x1,x2.(||v[x1]1−v[x2]1||−c·||x1−x2||>0)
∧x1,x2∈X|X∈S (DL1,b)}(10)
where the S(DL1,b)are given input subspaces.
Intuitively,foreach X∈S (DL1,b),thisrequirementexpresses
theexistenceoftwoinputs x1andx2thatrefutethat cisaLipschitz
constant for N. It is typically impossible to obtain full Lipschitz
coverage,becausetheremayexistinconsistent r∈RLip(b,c).Thus,
the goal for a test case generation algorithm is to produce a test
suiteTthat satisfies the criterion as much as possible.
5.2 Neuron Coverage
Neuron Coverage (NC) [ 18] is an adaptation of statement coverage
in conventional software testing to DNNs. It is defined as follows.
Definition 5.3. Neuron coverage for a DNN Nrequires a test
suiteTsuchthat,foranyhiddenneuron nk,i,thereexiststestcase
t∈Tsuch that ap[t]k,i=true.
Thisisformalisedwiththefollowingrequirements RNC,each
ofwhichexpressesthatthereisatestwithaninput xthatactivates
the neuron nk,i, i.e.,ap[x]k,i=true.
Definition5.4(NCRequirements). Theset RNCofcoveragere-
quirements for Neuron Coverage is
{∃x.ap[x]k,i=true|2≤k≤K−1,1≤i≤sk}(11)
5.3 Modified Condition/Decision (MC/DC)
Coverage
In[23],afamilyoffourtestcriteriaisproposed,inspiredbyMC/DC
coverage in conventional software testing. We will restrict the
discussion here to Sign-Sign Coverage (SSC). According to [ 23],
each neuron nk+1 ,jcan be seen as a decisionwhere the neurons in
the previous layer (i.e., the k-th layer) are conditions that define its
activation value, as in Equation (2). Adapting MC/DC to DNNs, we
mustshowthatallconditionneuronscandeterminetheoutcome
of the decision neuron independently. In the case of SSC coverage
we say that the value of a decision or condition neuron changes
if the sign of its activation function changes. Consequently, the
requirements for SSC coverage are defined by the following set.
Definition5.5(SSCRequirements). ForSCCcoverage,wefirstde-
finearequirement RSSC(α)forapairofneurons α=(nk,i,nk+1 ,j):
{∃x1,x2.ap[x1]k,i/nequalap[x2]k,i∧ap[x1]k+1 ,j/nequalap[x2]k+1 ,j∧/logicalandtext.1
1≤l≤sk,l/nequaliap[x1]k,l−ap[x2]k,l=0}
(12)and we get
RSSC=/uniondisplay.1
2≤k≤K−2 ,1≤i≤sk,1≤j≤sk+1RSSC((nk,i,nk+1 ,j))(13)
That is, for each pair (nk,i,nk+1 ,j)of neurons in two adjacent
layerskandk+1, we need two inputs x1andx2such that the
signchangeof nk,iindependentlyaffectsthesignchangeof nk+1 ,j.
Other neurons at layer kare required to maintain their signs be-
tweenx1andx2toensurethatthechangeisindependent.Theidea
of SS Coverage(and all other criteriain [ 23]) is to ensure that not
onlytheexistenceofafeatureneedstobetestedbutalsotheeffects
of less complex features on a more complex feature must be tested.
5.4 Neuron Boundary Coverage
NeuronBoundaryCoverage(NBC)[ 15]aimsatcoveringneuron
activationvaluesthatexceedagivenbound.Itcanbeformulated
as follows.
Definition 5.6 (Neuron Boundary Coverage Requirements). Given
two sets of bounds h={hk,i|2≤k≤K−1,1≤i≤sk}andl=
{lk,i|2≤k≤K−1,1≤i≤sk}, the requirements RNBC(h,l)are
{∃x.u[x]k,i−hk,i>0,∃x.u[x]k,i−lk,i<0|
2≤k≤K−1,1≤i≤sk}(14)
wherehk,iandlk,iaretheupperandlowerboundsontheactivation
value of a neuron nk,i.
6 OVERVIEW OF OUR APPROACH
This section gives an overview of our method for generating a test
suite for a given DNN. Our method alternates between concreteevaluation of the activation patterns of the DNN and symbolic
generation of new inputs. The pseudocode for our method is given
as Algorithm 1. It is visualised in Figure 1.
{t0}: seed input
TR: coverage requirements,
δ: a heuristic
δ(R)
concrete
executiont,rnew
inputt/prime
Oracle adversarial examplesAlgorithm 1
top
rankedsymbolic
analysis
Figure 1: Overview of our concolic testing method
Algorithm 1takes as inputs a DNN N, an input t0for the DNN,
aheuristic δ,andaset Rofcoveragerequirements,andproducesa
testsuite Tasoutput.Thetestsuite Tinitiallyonlycontainsthe
given test input t0. The algorithm removes a requirement r∈R
fromRonce it is satisfied by T, i.e.,T|=r.
Thefunction requirement _evaluation (Line7),whosedetailsare
given in Section 7, looks for a pair (t,r)2of input and requirement
that,accordingtoourconcreteevaluation,isthemostpromising
2Forsomerequirements,wemightreturntwoinputs t1andt2.Here,forsimplicity,we
describethecaseforasingleinput.Thegeneralisationtotwoinputsisstraightforward.
113
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Y. Sun, M. Wu, W. Ruan, X. Huang, M. Kwiatkowska, D. Kroening
Algorithm 1 Concolic Testing for DNNs
INPUT:N,R,δ,t0
OUTPUT: T
1:T←{t0}andF={}
2:t←t0
3:while R\S/nequal∅do
4:foreachr∈Rdo
5:ifT|=rthenR←R\{r}
6:while truedo
7:t,r←requirement _evaluation (T,δ(R))
8:t/prime←symbolic_analysis (t,r)
9:ifvalidity_check(t/prime)=truethen
10:T←T∪{ t/prime}
11:break
12:else ifcost exceeded then
13:F←F∪{r}
14:break
15:returnT
candidateforanewtestcase t/primethatsatisfiestherequirement r.The
heuristicδis a transformation function that maps a formula rwith
operator ∃to an optimisation problem. This step relies on concrete
execution.
Afterobtaining (t,r),symbolic_analysis (Line8),whosedetails
are in Section 8, is applied to obtain a new concrete input t/prime. Then
afunction validity_check(Line9),whosedetailsaregiveninSec-
tion9, is applied to check whether the new input is valid or not.
If so, the test is added to the test suite. Otherwise, ranking and
symbolicinputgenerationarerepeateduntilagivencomputational
cost is exceeded, after which test generation for the requirement is
deemed to have failed. This is recorded in the set F.
Thealgorithmterminateswheneitheralltestrequirementshave
been satisfied, i.e., R=∅, or no further requirement in Rcan be
satisfied, i.e., F=R. It then returns the current test suite T.
Finally, as illustrated in Figure 1, the test suite Tgenerated
by Algorithm 1, is passed to an oracle in order to evaluate the
robustness of the DNN. The details of the oracle are in Section 9.
7 RANKING COVERAGE REQUIREMENTS
ThissectionpresentsourapproachforLine7ofAlgorithm 1.Given
asetofrequirements Rthathavenotyetbeensatisfied,aheuristic δ,
and the current set Tof test inputs, the goal is to select a concrete
inputt∈Ttogether with a requirement r∈R, both of which will
be used later in a symbolic approach to compute the next concrete
inputt/prime(to be given inSection 8).The selectionof tandris done
by means of a series of concrete executions.
The general idea is as follows. For all requirements r∈R,
we transform rintoδ(r)by utilising operators argoptforopt∈
{max,min}that will be evaluated by concretely executing tests
inT.A sRmay contain more than one requirement, we return the
pair(t,r)such that
r=argmaxr{val(t,δ(r)) |r∈R}. (15)
Note that, when evaluating argoptformulas (e.g., argmin xa:e),
if an input t∈Tis returned, we may need the value ( minxa:e)as well. We use val(t,δ(r))to denote such a value for the returned
inputtand the requirement formula r.
Theformula δ(r)isanoptimisationobjectivetogetherwithaset
ofconstraints.WewillgiveseveralexampleslaterinSection 7.1.In
the following, we extend the semantics in Definition 4.3to work
with formulas with argoptoperators for opt∈{max,min}, includ-
ingargoptxa:eandargoptx1,x2a:e. Intuitively, argmax xa:e
(argmin xa:e,resp.)determinestheinput xamongthosesatisfy-
ing the Boolean formula ethat maximises (minimises) the value of
the arithmetic formula a. Formally,
•theevaluationof argmin xa:eonTreturnsaninput t∈T
such that, T|=e[x/mapsto→t]and for all t/prime∈Tsuch that
T|=e[x/mapsto→t/prime]we havea[x/mapsto→t]≤a[x/mapsto→t/prime].
•the evaluation of T|=argmin x1,x2a:eonTreturns two
inputst1,t1∈Tsuch that, T|=e[x1/mapsto→t1][x2/mapsto→t2]and
for allt/prime
1,t/prime
2∈Tsuch that T|=e[x1/mapsto→t/prime
1][x2/mapsto→t/prime
2]we
havea[x1/mapsto→t1][x2/mapsto→t2]≤a[x1/mapsto→t/prime
1][x2/mapsto→t/prime
2].
The cases for argmaxformulas are similar to those for argmin,b y
replacing ≤with≥. Similarly to Definition 4.3, the semantics is
forasetToftestcasesandwecanadaptittoacontinuousinput
subspace X⊆DL1.
7.1 Heuristics
We present the heuristics δwe use the coverage requirements dis-
cussed in Section 5. We remark that, since δis a heuristic, there
exist alternatives. The following definitions work well in our ex-
periments.
7.1.1 Lipschitz Continuity. WhenaLipschitzrequirement rasin
Equation ( 10) is not satisfied by T, we transform it into δ(r)as
follows:
argmaxx1,x2.||v[x1]1−v[x2]1||−c∗||x1−x2||:x1,x2∈X(16)
I.e., the aim is to find the best t1andt2inTto make ||v[t1]1−
v[t2]1||−c·||t1−t2||as large as possible. As described, we also
need to compute val(t1,t2,r)=||v[t1]1−v[t2]1||−c·||t1−t2||.
7.1.2 Neuron Cover. Whenarequirement rasinEquation(11)is
not satisfied by T, we transform it into the following requirement
δ(r):
argmaxxck·uk,i[x]:true (17)
Weobtaintheinput t∈Tthathasthemaximalvaluefor ck·uk,i[x].
The coefficient ckis a per-layer constant. It motivated by the
followingobservation.WiththepropagationofsignalsintheDNN,
activation values at each layer can be of different magnitudes. For
example, if the minimum activation value of neurons at layer k
andk+1ar e−10and−100,respectively,thenevenwhenaneuron
u[x]k,i=−1>−2=u[x]k+1 ,j, we may still regard nk+1 ,jas
being closer to be activated than uk,iis. Consequently, we define a
layerfactor ckforeachlayerthatnormalisestheaverageactivation
valuationsofneuronsatdifferentlayersintothesamemagnitude
level. It is estimated by sampling a sufficiently large input dataset.
7.1.3 SS Coverage. InSSCoverage,givenadecisionneuron nk+1 ,j,
the concrete evaluation aims to select one of its condition neurons
nk,iatlayerksuchthatthetestinputthatisgeneratednegatesthe
signsofnk,iandnk+1 ,jwhiletheremainderof nk+1 ,j’scondition
114
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. Concolic Testing for Deep Neural Networks ASE ’18, September 3–7, 2018, Montpellier, France
neurons preserve their respective signs. This is achieved by the
following δ(r):
argmaxx−ck·|u[x]k,i|:true (18)
Intuitively, given the decision neuron nk+1 ,j, Equation (18) selects
the condition that is closest to the change of activation sign (i.e.,
yields the smallest |u[x]k,i|).
7.1.4 Neuron Boundary Coverage. Wetransformtherequirement r
inEquation(19)intothefollowing δ(r)whenitisnotsatisfiedby T;
it selects the neuron that is closest to either the higher or lower
boundary.
argmax xck·(u[x]k,i−hk,i):true
argmax xck·(lk,i−u[x]k,i):true(19)
8 SYMBOLIC GENERATION OF NEW
CONCRETE INPUTS
This section presents our approach for Line 8 of Algorithm 1. That
is, given a concrete input tand a requirement r,w en e e dt ofi n d
the next concrete input t/primeby symbolic analysis. This new t/primewill
be added into the test suite (Line 10 of Algorithm 1). The symbolic
analysis techniques to be considered include the linear program-
mingin[23],globaloptimisationforthe L0normin[21],andanew
optimisationalgorithmthatwillbeintroducedbelow.Weregard
optimisationalgorithmsassymbolicanalysismethodsbecause,sim-
ilarly to constraint solving methods, they work with a set of test
cases in a single run.
To simplify the presentation, the following description may, for
each algorithm, focus on some specific coverage requirements, but
we remark that all algorithms can work with all the requirements
given in Section 5.
8.1 Symbolic Analysis using Linear
Programming
As explained in Section 4, given an input x, the DNN instance
N[x]maps to an activation pattern ap[x]that can be modeled
using Linear Programming (LP). In particular, the following linear
constraints [ 23] yield a set of inputs that exhibit the same ReLU
behaviour as x:
{uk,i=/summationdisplay.1
1≤j≤sk−1{wk−1 ,j,i·vk−1 ,j}+bk,i|k∈[2,K],i∈[1..sk]}(20)
{uk,i≥0∧uk,i=vk,i|ap[x]k,i=true,k∈[2,K),i∈[1..sk]}
∪{u k,i<0∧vk,i=0|ap[x]k,i=false,k∈[2,K),i∈[1..sk]}(21)
Continuous variables in the LP model are emphasized in bold.
•Theactivationvalueofeachneuronisencodedbythelinear
constraintin (20),whichisasymbolicversionofEquation (2)
that calculates a neuron’s activation value.
•Givenaparticularinput x,theactivationpattern(Definition
4.1)ap[x]is known: ap[x]k,iis either trueorfalse, which
indicateswhethertheReLUisactivatedornotfortheneu-
ronnk,i. Following (3)and the definition of ReLU in (1), for
everyneuron nk,i,thelinearconstraintsin (21)encodeReLU
activation (when ap[x]k,i=true) or deactivation (when
ap[x]k,i=false).Thelinearmodel(denotedas C)givenby (20)and(21)represents
an input set that results in the same activation pattern as encoded.
Consequently,thesymbolicanalysisforfindinganewinput t/primefrom
a pair(t,r)of input and requirement is equivalent to finding a new
activationpattern. Notethat,tomakesurethattheobtainedtestcase
ismeaningful, anobjective isaddedto theLP modelthatminimizes
the distance between tandt/prime.Thus, the use of LPrequires that the
distance metric is linear. For instance, this applies to the L∞-norm
in (6), but not to the L2-norm.
8.1.1 Neuron Coverage. Thesymbolicanalysisofneuroncoverage
takestheinputtestcase tandrequirement rontheactivationof
neuronnk,i,andreturnsanewtest t/primesuchthatthetestrequirement
is satisfied by the network instance N[t/prime]. We have the activation
patternap[t]of the given N[t], and can build up a new activation
patternap/primesuch that
{ap/prime
k,i=¬ap[t]k,i∧∀k1<k:/logicalanddisplay.1
0≤i1≤sk1ap/prime
k1,i1=ap[t]k1,i1}(22)
This activation pattern specifies the following conditions.
•nk,i’s activation sign is negated: this encodes the goal to
activatenk,i.
•Inthenewactivationpattern ap/prime,theneuronsbeforelayer k
preservetheiractivationsignsasin ap[t].Thoughtheremay
existmultipleactivationpatternsthatmake nk,iactivated,
for the use of LP modeling one particular combination of
activation signs must be pre-determined.
•Other neurons are irrelevant, as the sign of nk,iis only af-
fected by the activation values of those neurons in previous
layers.
Finally,thenewactivationpattern ap/primedefinedin (22)isencoded
by the LP model Cusing(20)and(21), and if there exists a feasible
solution, then the new test input t/prime, which satisfies the require-
mentr, can be extracted from that solution.
8.1.2 SS Coverage. TosatisfyanSSCoveragerequirement r,w e
needtofindanewtestcasesuchthat,withrespecttotheinput t,
the activation signs of nk+1 ,jandnk,iare negated, while other
signs of other neurons at layer kare equal to those for input t.
To achieve this, the following activation pattern ap/primeis con-
structed.
{ap/prime
k,i=¬ap[t]k,i∧ap/prime
k+1 ,j=¬ap[t]k+1 ,j
∧∀k1<k:/logicalandtext.1
1≤i1≤sk1ap/prime
k1,i1=ap[t]k1,i1}
8.1.3 Neuron Boundary Coverage. In case of the neuron boundary
coverage,thesymbolicanalysisaimstofindaninput t/primesuchthat
the activation value of neuron nk,iexceeds either its higher bound
hk,ior its lower bound lk,i.
To achieve this, while preserving the DNN activation pattern
ap[t], we add one of the following constraints to the LP program.
•Ifu[x]k,i−hk,i>lk,i−u[x]k,i:uk,i>hk,i;
•otherwise: uk,i<lk,i.
115
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Y. Sun, M. Wu, W. Ruan, X. Huang, M. Kwiatkowska, D. Kroening
8.2 Symbolic Analysis using Global
Optimisation
The symbolic analysis for finding a new input can also be imple-
mented by solving the global optimisation problem in [ 21]. That is,
by specifying the test requirement as an optimisation objective, we
applyglobaloptimisationtocomputeatestcasethatsatisfiesthe
test coverage requirement.
•ForNeuron Coverage,theobjectiveis tofinda t/primesuchthat
the specified neuron nk,ihasap[t/prime]k,i=true.
•Incase ofSSCoverage, giventheneuronpair (nk,i,nk+1 ,j)
and the original input t, the optimisation objective becomes
ap[t/prime]k,i/nequalap[t]k,i∧ap[t/prime]k+1 ,j/nequal
ap[t]k+1 ,j∧/logicalandtext.1
i/prime/nequaliap[t/prime]k,i/prime=ap[t]k,i
•Regarding the Neuron Boundary Coverage, depending on
whether the higher bound or lower bound for the activation
ofnk,iis considered, the objective of finding a new input t/prime
is eitheru[t/prime]k,i>hk,ioru[t/prime]k,i<lk,i.
Readers are referred to [21] for the details of the algorithm.
8.3 Lipschitz Test Case Generation
Given a coverage requirement as in Equation ( 10) for a subspace X,
we lett0∈Rnbe the representative point of the subspace Xto
whicht1andt2belong. The optimisation problem is to generate
two inputs t1andt2such that
||v[t1]1−v[t2]1||D1−c·||t1−t2||D1>0
s.t.||t1−t0||D2≤Δ,||t2−t0||D2≤Δ(23)
where||∗|| D1and||∗|| D2denotenormmetricssuchasthe L0-norm,
L2-normor L∞-norm,and Δistheradiusofanormball(forthe L1
andL2-norm)orthesizeofahypercube(forthe L∞-norm)centered
ont0. The constant Δis a hyper-parameter of the algorithm.
Theaboveproblemcanbeefficientlysolvedbyanovel alternating
compasssearch scheme.Specifically,wealternatebetweensolving
thefollowingtwooptimisationproblemsthroughrelaxation[ 19],
i.e., maximizing the lower bound of the original Lipschitz constant
insteadofdirectlymaximizingtheLipschitzconstantitself.Todoso,
wereformulatetheoriginalnon-linearproportionaloptimisation
asalinearproblemwhenbothnormmetrics ||∗|| D1and||∗|| D2
are theL∞-norm.
8.3.1 Stage One. We solve
mint1F(t1,t0)=−||v[t1]1−v[t0]1||D1
s.t.||t1−t0||D2≤Δ(24)
The objective above enables the algorithm to search for an optimal
t1in the space of a norm ball or hypercube centered on t0with
radius Δ,maximisingthenormdistanceof v[t1]1andv[t0]1.The
constraint implies that sup||t1−t0||D2≤Δ||t1−t0||D2=Δ. Thus, a
smallerF(t1,t0)yields a larger Lipschitz constant, considering that
Lip(t1,t0)=−F(t1,t0)/||t1−t0||D2≥−F(t1,t0)/Δ,i.e.,−F(t1,t0)/Δ
isthelowerboundof Lip(t1,t0).Therefore,thesearchforatrace
that minimises F(t1,t0)increases the Lipschitz constant.
Tosolvetheproblemaboveweusethe compasssearchmethod [2],
whichis efficient,derivative-free, andguaranteed toprovide first-
orderglobalconvergence.Becauseweaimtofindaninputpairthatrefutes the given Lipschitz constant cinstead of finding the largest
possibleLipschitzconstant,alongeachiteration,whenweget ¯t1,
wecheckwhether Lip(¯t1,t0)>c.Ifitholds,wefindaninputpair
¯t1andt0thatsatisfiesthetestrequirement;otherwise,wecontinue
the compass search until convergence or a satisfiable input pair
is generated. If Equation (24) is convergent and we can find an
optimalt1as
t∗
1=argmint1F(t1,t0)s.t.||t1−t0||D2≤Δ
butwestillcannotfindasatisfiableinputpair,weperformtheStage
Two optimisation.
8.3.2 Stage Two. We solve
mint2F(t∗
1,t2)=−||v[t2]1−v[t∗
1]1||D1
s.t.||t2−t0||D2≤Δ(25)
Similarly,weusederivative-freecompass search tosolvetheabove
problemandcheckwhether Lip(t∗
1,t2)>choldsateachiterative
optimisation trace ¯t2. If it holds, we return the image pair t∗
1and
¯t2that satisfies the test requirement; otherwise, we continue the
optimisation until convergence or a satisfiable input pair is gener-
ated.IfEquation(25)isconvergentat t∗
2,andwestillcannotfind
suchainputpair,wemodifytheobjectivefunctionagainbyletting
t∗
1=t∗
2inEquation(25)andcontinuethesearchandsatisfiability
checking procedure.
8.3.3 Stage Three. Ifthefunction Lip(t∗
1,t∗
2)failstomakeprogress
inStageTwo,wetreatthewholesearchprocedureasconvergent
and have failed to find an input pair that can refute the givenLipschitz constant
c. In this case, we return the best input pair
we found so far, i.e., t∗
1andt∗
2, and the largest Lipschitz constant
Lip(t∗
1,t2)observed. Note that the returned constant is smaller
thanc.
Insummary,theproposedmethodisanalternatingoptimisation
schemebasedoncompasssearch.Basically,westartfromthegiven
t0to search for an image t1in a norm ball or hypercube, where
the optimisation trajectory on the norm ball space is denoted as
S(t0,Δ(t0))) such that Lip(t0,t1)>c(this step is symbolic execu-
tion); if we cannot find it, we modify the optimisation objective
functionbyreplacing t0witht∗
1(thebestconcreteinputfoundin
thisoptimisationrun)toinitiateanotheroptimisationtrajectoryon
the space, i.e., S(t∗
1,Δ(t0)). This process is repeated until we have
gradually covered the entire space S(Δ(t0))of the norm ball.
9 TEST ORACLE
Weprovidedetailsaboutthevaliditycheckingperformedforthe
generatedtestinputs(Line9ofAlgorithm 1)andhowthetestsuite
is finally used to quantify the safety of the DNN.
Definition9.1(Validtestinput). Wearegivenaset Oofinputsfor
which we assume to have a correct classification (e.g., the training
dataset). Given a real number b, a test input t/prime∈Tis said to be
validif
∃t∈O:||t−t/prime|| ≤b. (26)
Intuitively,atestcase tisvalidifitisclosetosomeoftheinputs
for which we have a classification. Given a test input t/prime∈T,w e
116
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. Concolic Testing for Deep Neural Networks ASE ’18, September 3–7, 2018, Montpellier, France
Figure2:Adversarialimages,with L∞-normforMNIST(top
row) and L0-norm for CIFAR-10 (bottom row), generated by
DeepConcolic and DeepXplore, the latter with image con-
straints ‘light’, ‘occlusion’, and ‘blackout’.
writeO(t/prime)fortheinput t∈Othathasthesmallestdistanceto t/prime
among all inputs in O.
To quantify the quality of the DNN using a test suite T,w eu s e
the following robustness criterion.
Definition 9.2 (Robustness Oracle). Given a set Oof classified
inputs, a test case t/primepasses the robustness oracle if
argmax jv[t/prime]K,j=argmax jv[O(t/prime)]K,j (27)
Wheneverweidentifyatestinput t/primethatfailstopassthisoracle,
then it serves as evidence that the DNN lacks robustness.
10 EXPERIMENTAL RESULTS
Wehaveimplementedtheconcolictestingapproachpresentedin
this paper in a tool we have named DeepConcolic3. We compare it
with other tools for testing DNNs. The experiments are run on a
machinewith24coreIntel(R)Xeon(R)CPUE5-2620v3and2.4GHz
and 125GB memory. We use a timeout of 12h. All coverage results
are averaged over 10 runs or more.
10.1 Comparison with DeepXplore
We now compare DeepConcolic and DeepXplore [ 18] on DNNs
obtained from the MNIST and CIFAR-10 datasets. We remark thatDeepXplore has been applied to further datasets.
For each tool, we start neuron cover testing from a randomly
sampledimageinput.Notethat,sinceDeepXplorerequiresmore
than one DNN, we designate our trained DNN as the target model
andutilisetheothertwodefaultmodelsprovidedbyDeepXplore.
Table2givestheneuroncoverageobtainedbythetwotools.We
observe that DeepConcolic yields much higher neuron coveragethan DeepXplore in any of its three modes of operation (‘light’,
‘occlusion’,and‘blackout’).Ontheotherhand,DeepXploreismuch
faster and terminates in seconds.
Table 2: Neuron coverage of DeepConcolic and DeepXplore
DeepConcolic DeepXplore
L∞-normL0-norm light occlusion blackout
MNIST 97.60% 95.91% 80.77% 82.68% 81.61%
CIFAR-10 84.98% 98.63% 77.56% 81.48% 83.25%
3The implementation and all data in this section are available online at
https://github.com/TrustAI/DeepConcolic 0.2 0.4 0.6 0.8 1 1.2
MNIST CIFAR-10CoverageNC
SSC
NBC
(a)L∞-norm 0.2 0.4 0.6 0.8 1 1.2
MNIST CIFAR-10CoverageNC
NBC
(b)L0-norm
Figure 3: Coverage results for different criteria
Figure2presentsseveraladversarialexamplesfoundbyDeep-
Concolic (with L∞-norm and L0-norm) and DeepXplore. Although
DeepConcolic does not impose particular domain-specific con-
straints on the original image as DeepXplore does, concolic testing
generatesimagesthatresemble“humanperception”.Forexample,
based on the L∞-norm, it produces adversarial examples (Figure 2,
top row) that gradually reverse the black and white colours. For
theL0-norm, DeepConcolic generates adversarial examples similar
to those of DeepXplore under the ‘blackout’ constraint, which is
essentially pixel manipulation.
10.2 Results for NC, SCC, and NBC
WegivetheresultsobtainedwithDeepConcolicusingthecoverage
criteriaNC,SSC,andNBC.DeepConcolicstartsNCtestingwithone
singleseedinput.ForSSCandNBC,toimprovetheperformance,
aninitialsetof1000imagesaresampled.Furthermore,weonlytest
a subset of the neurons for SSC and NBC. A distance upper bound
of0.3(L∞-norm)and100pixels( L0-norm)issetupforcollecting
adversarial examples.
The full coverage report, including the average coverage and
standard derivation, is given in Figure 3. Table3contains the ad-
versarial example results. We have observed that the overhead for
the symbolicanalysis withglobal optimisation(Section 8.2)i st oo
high. Thus, the SSC result with L0-norm is excluded.
Overall, DeepConcolic achieves high coverage and, using the
robustnesscheck(Definition 9.2),detectsasignificantnumberof
adversarial examples. However, coverage of corner-case activation
values (i.e., NBC) is limited.
Concolic testing is able to find adversarial examples with the
minimumpossible distance:thatis,1
255≈0.0039forthe L∞norm
and 1 pixel for the L0norm. Figure 4gives the average distance of
adversarialexamples(fromoneDeepConcolicrun).Remarkably,for
the same network, the number of adversarial examples found with
NC can vary substantially when the distance metric is changed.
Thisobservationsuggeststhat,whendesigningcoveragecriteria
for DNNs, they need to be examined using a variety of distance
metrics.
10.3 Results for Lipschitz Constant Testing
This section reports experimental results for the Lipschitz constant
testing onDNNs.Wetest Lipschitzconstants rangingover {0.01 :
0.01 : 20}on50MNISTimagesand50CIFAR-10imagesrespectively.
Every image represents a subspace in DL1and thus a requirement
in Equation (10).
117
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Y. Sun, M. Wu, W. Ruan, X. Huang, M. Kwiatkowska, D. Kroening
(a)
 (b)
Figure 4: (a) Distance of NC, SSC,
and NBC on MINIST and CIFAR-
10 datasets based on L∞norm;
(b)DistanceofNCandNBConthe
two datasets based on L0norm.
(a)
 (b)
 (c)
Figure5:(a)LipschitzConstantCoveragegeneratedby1,000,000randomlygeneratedtestpairs and our concolic testing method for input image-1 on MNIST DNN; (b) LipschitzConstant Coverages generated by random testing and our method for 50 input imageson MNIST DNN; (c) Lipschitz Constant Coverage generated by random testing and our
method for 50 input images on CIFAR-10 DNN.
Table 3: Adversarial examples by test criteria, distance metrics, and DNN models
L∞-norm L0-norm
MNIST CIFAR-10 MNIST CIFAR-10
adversary % minimum dist. adversary % minimum dist. adversary % minimum dist. adversary % minimum dist.
NC 13.93% 0.0039 0.79% 0.0039 0.53% 1 5.59% 1
SSC 0.02% 0.1215 0.36% 0.0039 –– ––
NBC 0.20% 0.0806 7.71% 0.0113 0.09% 1 4.13% 1
10.3.1 Baseline Method. Since this paper is the first to test Lips-
chitz constants of DNNs, we compare our method with random
test case generation. For this specific test requirement, given a pre-
defined Lipschitz constant c, an input t0and the radius of norm
ball(e.g.,for L1andL2norms)orhypercubespace(for L∞-norm)
Δ, we randomly generate two test pairs t1andt2that satisfy the
space constraint (i.e., ||t1−t0||D2≤Δand||t2−t0||D2≤Δ), and
then check whether Lip(t1,t2)>cholds. We repeat the random
generation until we find a satisfying test pair or the number of rep-
etitionsislargerthanapredefinedthreshold.Wesetsuchthreshold
asNrd=1,000,000. Namely, if we randomly generate 1,000,000
test pairs and none of them can satisfy the Lipschitz constant re-
quirement>c, we treat this test as a failure and return the largest
Lipschitzconstantfoundandthecorrespondingtestpair;otherwise,
we treat it as successful and return the satisfying test pair.
10.3.2 Experimental Results. Figure5(a)depictstheLipschitzCon-
stantCoveragegeneratedby1,000,000randomtestpairsandour
concolic test generation method for image-1 on MNIST DNNs. As
we can see, even though we produce 1,000,000 test pairs by ran-
dom test generation, the maximum Lipschitz converage reaches
only3.23andmostofthetestpairsareintherange [0.01,2].Our
concolic method, on the other hand, can cover a Lipschitz rangeof
[0.01,10.38], where most cases lie in [3.5,10], which is poorly
covered by random test generation.
Figure5(b)and(c)comparetheLipschitzconstantcoverageof
test pairs from the random method and the concolic method on
bothMNISTandCIFAR-10models.Ourmethodsignificantlyout-
performsrandomtestcasegeneration.Wenotethatcoveringalarge
LipschitzconstantrangeforDNNsisachallengingproblemsince
most image pairs (within a certain high-dimensional space) canproducesmallLipschitzconstants(suchas1to2).Thisexplainsthe
reasonwhyrandomlygeneratedtestpairsconcentrateinarange
of less than 3. However, for safety-critical applications such as
self-driving cars, a DNN with a large Lipschitz constant essentially
indicates it is more vulnerable to adversarial perturbations [ 20,21].
As a result, a test method that can cover larger Lipschitz constants
provides a useful robustness indicator for a trained DNN. We ar-
guethat,forsafetytestingofDNNs,theconcolictestmethodfor
Lipschitzconstantcoveragecancomplementexistingmethodsto
achieve significantly better coverage.
11 CONCLUSIONS
Inthispaper,weproposethefirstconcolictestingmethodforDNNs.
Weimplementitinasoftwaretoolandapplythetooltoevaluatethe
robustness of well-known DNNs. The generation of the test inputs
can be guided by a variety of coverage metrics, including Lipschitz
continuity. Our experimental results confirm that the combination
ofconcreteexecutionandsymbolicanalysisdeliversbothcoverage
and automates the discovery of adversarial examples.
Acknowledgements. This document is an overview of UK MOD
(part)sponsoredresearchandisreleasedforinformationalpurposes
only.Thecontentsofthisdocumentshouldnotbeinterpretedas
representingtheviewsoftheUKMOD,norshoulditbeassumed
thattheyreflectanycurrentorfutureUKMODpolicy.Theinfor-
mationcontainedinthisdocumentcannotsupersedeanystatutory
or contractual requirements or liabilities and is offered without
prejudice or commitment.
118
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. Concolic Testing for Deep Neural Networks ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1]MartinArjovsky,SoumithChintala,andLéonBottou.2017. WassersteinGAN.
arXiv preprint arXiv:1701.07875 (2017).
[2]CharlesAudetandWarrenHare.2017. Derivative-FreeandBlackboxOptimization.
Springer.
[3] Radu Balan, Maneesh Singh, and Dongmian Zou. 2017. Lipschitz Properties for
Deep Convolutional Networks. arXiv preprint arXiv:1701.05217 (2017).
[4]Jacob Burnim and Koushik Sen. 2008. Heuristics for Scalable Dynamic Test Gen-
eration.In AutomatedSoftwareEngineering,ASE.23rdInternationalConference
on. IEEE, 443–446.
[5]CristianCadar,DanielDunbar,andDawsonR.Engler.2008.KLEE:Unassistedand
Automatic Generation of High-Coverage Tests for Complex Systems Programs.
InOSDI, Vol. 8. 209–224.
[6]SooyoungCha,SeongjoonHong,JunheeLee,andHakjooOh.2018.Automatically
Generating Search Heuristics for Concolic Testing. In Proceedings of the 40th
International Conference on Software Engineering, ICSE. ACM, 1244–1254.
[7]Timon Gehr, MatthewMirman, DanaDrachsler-Cohen, PetarTsankov, Swarat
Chaudhuri,andMartinVechev.2018. AI2:SafetyandRobustnessCertificationof
Neural Networks with Abstract Interpretation. In Security and Privacy (SP), 2018
IEEE Symposium on.
[8]Patrice Godefroid, Nils Klarlund, and Koushik Sen. 2005. DART: Directed Au-
tomated Random Testing. In Proceedings of the ACM SIGPLAN Conference on
Programming Language Design and Implementation. 213–223.
[9]PatriceGodefroid,MichaelYLevin,DavidAMolnar,andothers.2008. Automated
Whitebox Fuzz Testing. In NDSS, Vol. 8. 151–166.
[10]KellyHayhurst,DanVeerhusen,JohnChilenski,andLeannaRierson.2001. APrac-
tical Tutorial on Modified Condition/Decision Coverage. Technical Report. NASA.
[11]Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. 2017. Safety
Verification of Deep Neural Networks. In International Conference on Computer
Aided Verification, CAV. Springer, 3–29.
[12]Cem Kaner. 2006. Exploratory Testing. In Quality Assurance Institute Worldwide
Annual Software Testing Conference.
[13]Raghudeep Kannavara, Christopher J Havlicek, Bo Chen, Mark R Tuttle, Kai
Cong,SandipRay,andFeiXie.2015. ChallengesandOpportunitieswithConcolic
Testing. In Aerospace and Electronics Conference (NAECON), 2015 National. IEEE,
374–378.
[14]Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer.
2017. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. In
International Conference on Computer Aided Verification. Springer, 97–117.
[15]Lei Ma, Felix Juefei-Xu, Jiyuan Sun, Chunyang Chen, Ting Su, Fuyuan Zhang,
MinhuiXue,BoLi,LiLi,YangLiu,andothers.2018. DeepGauge:Comprehensive
and Multi-Granularity Testing Criteria for Gauging the Robustness of Deep
Learning Systems. arXiv preprint arXiv:1803.07519 (2018).
[16]MatthewMirman,TimonGehr,andMartinVechev.2018. DifferentiableAbstract
Interpretation for Provably Robust Neural Networks. In International Conference
on Machine Learning. 3575–3583.[17]VinodNairandGeoffreyEHinton.2010.RectifiedLinearUnitsImproveRestricted
Boltzmann Machines. In International Conference on Machine Learning. 807–814.
[18] KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017. DeepXplore:Auto-
mated Whitebox Testing of Deep Learning Systems. In Proceedings of the 26th
Symposium on Operating Systems Principles. ACM, 1–18.
[19]T.Roubicek.1997. RelaxationinOptimizationTheoryandVariationalCalculus.
Berlin: Walter de Gruyter.
[20]WenjieRuan,XiaoweiHuang,andMartaKwiatkowska.2018. ReachabilityAnaly-
sisofDeepNeuralNetworkswithProvableGuarantees.In The27thInternational
Joint Conference on Artificial Intelligence, IJCAI. 2651–2659.
[21]Wenjie Ruan, Min Wu, Youcheng Sun, Xiaowei Huang, Daniel Kroening, andMarta Kwiatkowska. 2018. Global Robustness Evaluation of Deep Neural Net-
works with Provable Guarantees for L0 Norm. arXiv preprint arXiv:1804.05805v1
(2018).
[22]KoushikSen,DarkoMarinov,andGulAgha.2005. CUTE:AConcolicUnitTesting
Engine for C. ACM SIGSOFT Software Engineering Notes 30, 5 (2005), 263–272.
[23]Youcheng Sun, Xiaowei Huang, and Daniel Kroening. 2018. Testing Deep Neural
Networks. arXiv preprint arXiv:1803.04792 (2018).
[24]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,Ian Goodfellow, and Rob Fergus. 2014. Intriguing Properties of Neural Networks.
InInternational Conference on Learning Representations (ICLR).
[25]YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018.DeepTest:Automated
TestingofDeep-Neural-Network-DrivenAutonomousCars.In Proceedingsofthe
40th International Conference on Software Engineering. ACM, 303–314.
[26]Willem Visser, Corina S. Pasareanu, and Sarfraz Khurshid. 2004. Test Input
Generation with Java PathFinder. ACM SIGSOFT Software Engineering Notes 29,
4 (2004), 97–107.
[27]Xinyu Wang, Jun Sun, Zhenbang Chen, Peixin Zhang, Jingyi Wang, and Yun Lin.
2018. Towards Optimal Concolic Testing. In Proceedings of the 40th International
Conference on Software Engineering. ACM, 291–302.
[28]Zhou Wang,Eero PSimoncelli, andAlan CBovik. 2003. MultiscaleStructural
Similarity for Image Quality Assessment. In Signals, Systems and Computers,
Conference Record of the Thirty-Seventh Asilomar Conference on.
[29]Thomas Wiatowski and Helmut Bölcskei. 2018. A Mathematical Theory of Deep
Convolutional Neural Networks for Feature Extraction. IEEE Transactions on
Information Theory 64, 3 (2018), 1845–1866.
[30]MatthewWicker,XiaoweiHuang,andMartaKwiatkowska.2018. Feature-Guided
Black-Box Safety Testingof Deep Neural Networks. In International Conference
on Tools and Algorithms for the Construction and Analysis of Systems, TACAS.
Springer, 408–426.
[31]MinWu,MatthewWicker,WenjieRuan,XiaoweiHuang,andMartaKwiatkowska.
2018. AGame-BasedApproximateVerificationofDeepNeuralNetworkswith
Provable Guarantees. arXiv preprint arXiv:1807.03571 (2018).
[32]Tao Xie, Darko Marinov, Wolfram Schulte, and David Notkin. 2005. Symstra:
A Framework for Generating Object-Oriented Unit Tests using Symbolic Execu-
tion. InInternational Conference on Tools and Algorithms for the Construction and
Analysis of Systems, TACAS (LNCS), Vol. 3440. Springer, 365–381.
119
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:23:07 UTC from IEEE Xplore.  Restrictions apply. 