JustFuzz It: SolvingFloating-PointConstraints
usingCoverage-Guided Fuzzing
Daniel Liew
dan@su-root.co.uk
ImperialCollegeLondon
UnitedKingdomCristian Cadar
c.cadar@imperial.ac.uk
ImperialCollegeLondon
UnitedKingdomAlastair F.Donaldson
afd@imperial.ac.uk
ImperialCollegeLondon
UnitedKingdomJ.RyanStinnett
jryans@gmail.com
Mozilla
UnitedStates
ABSTRACT
We investigate the use of coverage-guided fuzzing as a means of
proving satisfiability of SMT formulas over finite variable domains,
withspecificapplicationtofloating-pointconstraints.Weshowhow
anSMTformulacanbeencodedasaprogramcontainingalocation
that is reachable if and only if the program’s input corresponds to
asatisfyingassignmenttotheformula.Acoverage-guidedfuzzer
canthenbeusedtosearchforaninputthatreachesthelocation,
yieldingasatisfyingassignment.Wehaveimplementedthisidea
in a tool, JustFuzz-itSolver (JFS), and we present a large experi-
mentalevaluationshowingthatJFSisbothcompetitivewithand
complementary to state-of-the-art SMT solvers with respect to
solving floating-point constraints, and that the coverage-guided
approachofJFSprovidessignificantbenefitovernaivefuzzingin
thefloating-pointdomain.Appliedinaportfoliomanner,theJFS
approach thus has the potential to complement traditional SMT
solvers for program analysis tasks that involve reasoning about
floating-pointconstraints.
CCS CONCEPTS
·Theory of computation →Constraint and logic program-
ming;·Softwareanditsengineering →Softwaretestingand
debugging .
KEYWORDS
Constraintsolving, feedback-directedfuzzing
ACMReference Format:
DanielLiew,CristianCadar,AlastairF.Donaldson,andJ.RyanStinnett.2019.
Just Fuzz It: Solving Floating-Point Constraints using Coverage-Guided
Fuzzing.In Proceedingsofthe27thACMJointEuropeanSoftwareEngineer-
ingConferenceandSymposiumontheFoundationsofSoftwareEngineering
(ESEC/FSE ’19), August 26ś30, 2019, Tallinn, Estonia. ACM, New York, NY,
USA,12pages.https://doi.org/10.1145/3338906.3338921
1 INTRODUCTION
Satisfiability modulo theories (SMT)solvershave made tremendous
progress over the last decade [ 25] and now underpin many im-
portant software engineering tools, includingsymbolic execution
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrights forcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ’19, August 26ś30,2019, Tallinn,Estonia
©2019 Copyright heldby the owner/author(s). Publicationrightslicensed to ACM.
ACM ISBN 978-1-4503-5572-8/19/08...$15.00
https://doi.org/10.1145/3338906.3338921engines (e.g. [ 14,28,29,50,57]), program verifiers (e.g. [ 18,39])
andprogram synthesis frameworks (e.g.[ 31,32]).
Despitetheseadvances,SMTsolversoftenexhibitlimitedscal-
abilityonlargeproblems[ 48],andsolvingcanbechallengingfor
certain underlying theories. Scalable SMT solving in the theory of
floating-pointarithmeticisaparticularchallenge,andthesubject
ofalot ofrecent andongoing work [ 3,11,35,42].
Anunrelatedtechnology, coverage-guidedmutation-basedfuzzing ,
iswidelyusedtoautomaticallyfindinputstoasystemundertest
(SUT) that expose crashes and potentially exploitable undefined
behaviours [ 40,45]. For an SUT that has been instrumented to
record coverage information, a coverage-guided mutation-based
fuzzer takes an initial corpus of inputs and uses genetic algorithms
to synthesise further inputs by mutating and combining elements
of the corpus. Inputs that cover new parts of the SUT are added
tothecorpus,underthehypothesisthatviafurthermanipulation
theymayyieldinputsthatprovideevenmorecoverage,andthat
aimingfor high coverageisagoodstrategy for triggeringbugs.
Inthispaper,wepresentanin-depthinvestigationintothepo-
tentialforcoverage-guidedmutation-basedfuzzingtobeusedto
solve SMT formulas. Our idea is to transform an SMT formula
intoaprogramwhoseinputcorrespondstoanassignmenttothe
free variables of the formula, containing a statement, target, that is
reachableifandonlyiftheinputcorrespondstoasatisfyingassign-
ment. A coverage-guided fuzzer aims to find inputs that maximise
coverage,sowhenappliedtothisprogramitwillsearchrelentlessly
foraninputthatreaches target,i.e.forasatisfyingassignmentto
theformula. Our hypothesis is that thistechnique maysometimes
be able to rapidly find satisfying assignments for formulas that are
challengingforgeneral-purposesolvers.Themethodwepropose
doesnotintend to helpinproving unsatisfiability of formulas.
WepresentJFS( JustFuzzitSolver),aprototypeconstraintsolver
based on coverage-guided mutation-based fuzzing. JFS is sound:
a SAT result can be trusted. However, it is incomplete : JFS could
time out and, as discussed above, unsatisfiability cannot be proven.
We envision JFS would be run in parallel with a complete solver to
formaportfolio solver.JFS wasinspiredbythe limited scalability
wehaveobservedforstate-of-the-artSMTsolverswithrespectto
floating-point constraints, and currently supports the combination
of boolean, bitvector, and floating-point theories, but our idea of
SMTsolvingviacoverage-guidedfuzzingshouldbestraightforward
to adapt to any SMTtheory over finite-domainvariables.
We present a large experimental evaluation comparing JFS with
sevenfloating-point-capable SMT solvers, over a set of 1344bench-
marks from three different SMT-COMP [ 58] suites. Our evaluation
aims to answer the following research questions:
521ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia D. Liew, C.Cadar, A.F. Donaldson, andJ. R. Stinnett
RQ1Towhatextentiscoverage-guidedmutation-basedfuzzing
superiortonaiverandominputgenerationforSMTsolving?
RQ2Towhatextent canJFSbeacceleratedviałsmartseedsžde-
rived from the formula under analysis and/or the associated
SMTtheory?
RQ3HowdoestheexecutiontimeofJFScomparewithstate-of-
the-art SMT solvers when applied to satisfiable formulas
over Boolean,bitvector, andfloating-pointvariables?
Our main finding is that JFS is competitive with state-of-the-art
solvers such as MathSAT5 and Z3 on floating-point constraints,
complementing these solvers both in terms of number of solved
benchmarksand execution time.By contrast, it isuncompetitive
onbitvector-onlyconstraints.Intermsofdesignfeatures,wefound
coverage-guided mutation-based fuzzing superior to naive random
inputgeneration, andthe use ofsmart seedsto be beneficial.
We qualify the relative success of JFS with respect to floating-
pointconstraintsbyacknowledgingthatsolversupportforfloating
point, as well as available evaluation benchmarks, are relatively
recent, while traditional solvers are very mature for bitvector-only
constraints,andthebenchmarksavailableforthistheoryareknown
to be challenging.
In summary,our main contributionsare:
(1)Theideaofleveragingcoverage-guidedmutation-basedfuzzing
to find satisfying assignments to SMT formulas(illustrated
concretely viaaworkedexample in§ 3);
(2)JFS,asound,incompletesolverforfloating-pointandbitvec-
tor constraintsbasedonthis idea(§ 4);
(3)AnevaluationcomparingJFSwithsevenfloating-point-capable
SMT solvers over 1344SMT-COMP benchmarks, addressing
the above researchquestions(§ 5).
Aftercoveringrelevantbackground(§ 2),wegiveanoverview
of JFS (§3), discuss the design and implementation of the approach
andtool(§ 4),andpresentadetailedexperimentalevaluation(§ 5).
We then discuss related work (§ 6), and ideas for future research
directions (§ 7). Throughout the paper we discuss the limitations of
JFSandthreatsto the validity ofour approach.
2 BACKGROUND
We provide relevant background on coverage-guided fuzzing (§ 2.1)
andsomebriefnotesonfloating-pointarithmetic (§ 2.2).
2.1 Coverage-GuidedMutation-Based Fuzzing
Mutation-based fuzzing starts with a set of existing seedinputs,
knowntoalreadyexercisetheSUTinsomedepth,andgenerates
further inputs by mutating and combining seeds. Intuitively, the
resulting inputs are much more likely to exercise the SUT in inter-
estingwayscomparedwithinputsgeneratedinapurelyrandom
fashion.IfcodecoveragedatafortheSUTcanbeobtained,through
compile-time or binary instrumentation, a fuzzer can operate in a
coverage-guided manner. Code covered by an input can be used as
a proxy for measuring how interesting that input is, with an input
that covers newcode being deemedinteresting.
Coverage-guidedmutation-basedfuzzing combinestheseideas:
starting from an initial corpus, SUT inputs are generated via muta-
tion. An input that covers new code is added to the corpus to be
consideredasaseedforfuturemutation.Typicalmutationsincludemaking small changes to an input in isolation, and performing
łcrossoverž, where multiple inputs are combined into one. This ap-
proach is essentially an evolutionary algorithm [33] where an input
isconsidered fitifitcoversnewcode.Anevolutionaryalgorithm
used in this context is part of a broader research area known as
search-based test case generation [2].
Two popular coverage-guided mutation-based fuzzers, AFL [ 45]
andLibFuzzer[ 40](onwhichJFSisbased)havefoundnumerous
bugsinreal-world software [ 41,44].
2.2 Floating-PointArithmetic
AmotivatingusecaseforourworkisSMTformulasthatcontain
constraintsoverfloating-pointvariables.Werecaphereafewterms
andconceptsthat willbe usedlateron.
Single-anddouble-precisionfloating-pointnumbersarerepre-
sentedinSMT-LIB[ 8]bytheFloat32/Float64 types,whichcorre-
spondtotheIEEE-754binary32/binary64types[ 34].Thesemantics
of most floating-point operations match the process of performing
the operation with real number semantics then rounding the result
to a nearby floating-point number. Several rounding modes can be
used,includingroundingtothenearestfloating-pointnumberwith
ties favouring an even binary representation (RNE), and rounding
towards positive infinity (RTP). The set of floating-point bit pat-
ternsincludesspecialpatternstorepresentinfinities,aswellasłnot
a numberž (NaN), which handles the results of computations for
whichnonumerical representation makes sense (such as 0/0).
3 OVERVIEW OFJFS
Inbrief,JFSusesthefollowingmethodtofindasatisfyingassign-
mentto aformula Qpresentedas aconjunction of constraints:1
A program Pisconstructedsuch that:
•Ptakes a sequence of variables as input, with each variable
corresponding to afree variable in Q.
•Pcontains a sequence of constraint branches , one per con-
straint in Q, each of which is an ifstatement whose condi-
tioncorrespondsexactly to the associatedconstraint.
•Pcontains a targetstatement that returns 1 if and only if all
thetruebranches of the constraintbranches are traversed.
JFSthenpassestheprogram Ptoacoverage-guidedmutation-
basedfuzzer,whichrepeatedlyruns Pwithdifferentinputsuntilan
inputthatreachesthetargetisfound(correspondingtoasatisfying
assignment to Q), or the fuzzer reaches a given time limit. The
intuitionbehindapplyingacoverage-guidedfuzzeristhatitwill
relentlesslytrytogenerateinputsthatcover newcode.Inparticular,
the program location that returns 1isatarget for the fuzzer.
As an illustration of this idea, consider the example constraints
in Listing 1, shown in SMT-LIBv2.5 format [ 8]. Free variables a
andb, of type Float64 (see §2.2), are declared on lines 1and2
respectively. On lines 3and4, variables div_rne anddiv_rtp are
definedtobethedivisionof abybusingtheroundingtonearest,
ties to even (RNE) and rounding toward positive infinity (RTP)
roundingmodes, respectively.
Thesatisfiabilityproblemcapturedbytheexampleistheconjunc-
tion of the constraints specified in the five assertstatements. The
1Anyformulacanbetransformedtoanequisatisfiableformulainconjunctiveform,
e.g, by using the linear-timeTseytintransformation [ 65].
522JFS:SolvingFP Constraints usingCoverage-GuidedFuzzing ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia
Listing 1: An example conjunction of floating-point con-
straintsintheSMT-LIBv2.5 format.
1(declare-fun a () Float64)
2(declare-fun b () Float64)
3(define-fun div_rne () Float64 (fp.div RNE a b))
4(define-fun div_rtp () Float64 (fp.div RTP a b))
5(assert (not (fp.isNaN a)))
6(assert (not (fp.isNaN b)))
7(assert (not (fp.isNaN div_rne)))
8(assert (not (fp.isNaN div_rtp)))
9(assert (not (fp.eq div_rne div_rtp)))
10(check-sat )
Listing 2: A translation of the constraints in Listing 1to a
C++ program.
1intFuzzOneInput( constuint8_t * data, size_t size) {
2double a = makeFloatFrom(data, size, 0, 63);
3double b = makeFloatFrom(data, size, 64, 127);
4if(!isnan(a)) {} else return 0;
5if(!isnan(b)) {} else return 0;
6double a_b_rne = div_rne(a, b);
7double a_b_rtp = div_rtp(a, b);
8if(!isnan(a_b_rne)) {} else return 0;
9if(!isnan(a_b_rtp)) {} else return 0;
10 if(a_b_rne != a_b_rtp) {} else return 0;
11 return 1;// TARGET REACHED
12}
first four constraints state that none of a,b,div_rne anddiv_rtp
areNaN; the last states that div_rne isnot equal to div_rtp.
Theseconstraints are satisfiable.Using C++hexfloatnotation,
onesatisfyingassignmenthas asetto0x0.410815d750e65p-1022
(≈5.65235×10−309)andbto0x1.021c1b000e7cp+28 (≈2.70648×
108). Dividing abybrounding to nearest (ties to even) yields
0x0.0000000408001p-1022 (≈2.088452×10−317) and rounding
towardpositiveinfinityresultsin 0x0.0000000408002p-1022 (≈
2.088453×10−317).
ApossibletranslationoftheseconstraintsintoaC++program
is shown in Listing 2, where the guard of each ifstatement corre-
spondstoaconstraint.Thefuzzerwillrepeatedlycall FuzzOneInput
(line1),eachtimepassinganinputof sizebytesviathe databuffer.
If1isreturned,theinputcorrespondstoasatisfyingassignment,
otherwisethe fuzzerproceedsto try anotherinput.
The program first constructs the free variables from the input
bufferdata. Variables aandbcorrespond directly to the free vari-
ablesaandbinListing 1and areconstructedonlines 2and3from
thedatabuffer using bits 0to 63 ( a), andbits 64 to 127( b).
Anifstatement checks whether ais NaN (line 4), encoding the
constraintonline 5ofListing 1.Whether bisNaNishandledanalo-
gously(line 5).Variable a_b_rnecorrespondstothe div_rnemacro
on line3of Listing 1, and is set to the result of calling div_rne(a,
b)(line6).Thisperformsfloating-pointdivisionroundingtheresult
to the nearest value (ties to even). The assignment to a_b_rtpis
analogous,withroundingtowardspositive infinity.
The checks for whether a_b_rne anda_b_rtp andNaNare han-
dledsimilarlytothechecksforwhether aandbareNaN(lines8and
9). The comparison of a_b_rne anda_b_rtp (line10) corresponds
to the constraintonline 9ofListing 1.
Finally, on line 11the function returns 1, which tells the fuzzer
thatasatisfyingassignmenthasbeenfound.Notethatthislineis
only reachableif allpreviously evaluatedconstraintswere true.Therearemultiplewaysofencodingconstraintsasaprogram.
Listing2uses thefail-fastencoding, discussedfurther in§ 4.3.
4 DESIGN AND IMPLEMENTATION OFJFS
JFS is written in C++11 and builds on several existing projects:
theconstraintlanguageandAPIofZ3[ 24]isusedforin-memory
constraint representation, allowing reuse of Z3’s parser and con-
straint simplification tactics; Clang and LLVM are used to compile
generated C++ code [ 36]; and the coverage-guided mutation-based
fuzzerLibFuzzer [ 40]isusedto fuzz the resultingbinary.
JFSacceptsanSMT-LIBv2[ 8]formulaconsistingofaconjunction
oftop-levelconstraints.ProgramanalysistoolsÐsuchasthosebased
ondynamicsymbolicexecution[ 15],butnotonly[ 66]Ðgenerate
such conjunctions directly, and as mentioned in § 3, any formula
can be transformed to an equisatisfiable formula in conjunctive
form,e.g,byusing the linear-time Tseytin transformation [ 65].
The design of JFS in principle supports finding satisfying as-
signments to any theory using finite data types. Our current im-
plementation supports combinations of the Core(i.e. Boolean),
FixedSizeBitVectors ,andFloatingPoint SMT-LIBv2theories,
overFloat32andFloat64floating-pointvariables,andbitvector
variables ofarbitrary widthsupto 64 bits.
We now discuss practical issues related to the design of JFS,
covering simplification of formulas pre-fuzzing (§ 4.1); the mapping
of formula variables to the program input buffer (§ 4.2); choices for
howtoencodetheformulaasaprogram(§ 4.3);andtheinjection
ofłsmartseedsžtoguidethefuzzer(§ 4.4).Wealsobrieflydiscuss
JFS’s runtimelibrary (§ 4.5).
4.1 FormulaSimplification
TomaketheC++programthatJFSwillultimatelygeneratemore
friendly to LibFuzzer, JFS first applies the simplification passes
detailedinTable 1,inorder,totheinputformula.Thetableindicates
which passeswere alreadyavailable via callsinto the Z3 library, vs.
whichweimplementedusingtheZ3API.Thesepassesrepresent
various cheap ways to simplify formulas that we observed to be
usefulusefulduringearlyprototypingofJFS.Weremarkbrieflyon
theAndhoistingpass:JFSusesZ3toparseconstraints,andparsing
always returns a single conjunct; the AND hosting pass simply
splits this intoindependent conjuncts.
Ifaftersimplificationtheformulaissyntacticallyequivalentto
false, JFS immediately reports UNSAT without invoking LibFuzzer.
4.2 Input BufferPreparation
Havingsimplifiedtheformula,JFSmustdecidehowtorepresent
free variables ofthe formula inthe program’s inputbuffer.
First, an equality extraction pass is used to partition the free
variables and constants appearing in the formula into equivalence
classesbasedonsyntacticequalities,suchthatmembersofthesame
equivalenceclassareguaranteedtobeconstrainedtobeequal.Each
resultingclasscontainsat mostone constant:ifmultiple distinct
constantswereconstrainedtobeequal,JFSwouldhavereported
the formula as trivially UNSAT after formula simplification (§ 4.1).
Each equivalence class is then considered. If a class contains
a constant cthen there is no need to reserve space for variable
of the class in the input buffer: each variable is declared in the
523ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia D. Liew, C.Cadar, A.F. Donaldson, andJ. R. Stinnett
Table 1:The ordered set ofsimplifyingpassesrun by JFSon aformulabefore program generation
Simplification Description AlreadyinZ3?
Andhoisting Separatesthe constraint (and a b) intotwoseparate constraints No
Constant propagation Apply Z3’s propagate-values tactic to propagateconstants Yes
Duplicateconstraintelimination Removes duplicateconstraintsfrom the constraintset No
Expressionsimplification InvokesZ3’s expressionsimplifier,whichperforms e.g.constant folding Yes
Simplify contradictions Replaces (and a (not a)) withfalse No
Trueelimination Removes constraintsofthe form truefrom the constraintset No
Listing3:Exampleconstraintsusedtoillustrateequalityex-
traction.
1(declare-fun a () (_ FloatingPoint 11 53))
2(declare-fun b () (_ FloatingPoint 11 53))
3(declare-fun c () (_ FloatingPoint 11 53))
4(declare-fun d () (_ FloatingPoint 11 53))
5(assert (= a b))
6(assert (= b c))
7(assert (= d (_ +zero 11 53)))
8(assert (not (fp.isNaN (fp.add RNE c d))))
9(check-sat )
programandinitializedto c.Otherwise, kbitsoftheinputbuffer
are allocated to represent the common value of all free variables
in the class, where kis the width of the associated data type (e.g.
k=32forFloat32 variables).Thevariablesarealldeclaredlocally
intheprogramandinitializedviathesame kbitsoftheinputbuffer.
This process is illustrated by the formula of Listing 3(where
(_ + zero 11 53) denotesthe64-bitpositivezeroconstant)andthe
associatedprograminListing 4.Theequivalenceclassesare {a,b,c}
and{d,0.0}.Asaresult,theinputbuffer datarequires8bytesin
ordertostorethedouble-precisionvaluecommonto a,bandc.The
makeFloatFromData functioninitializes aviathisbuffer,andthe
valueofaisthencopiedinto bandc.Variable ddoesnotrequire
associatedspaceinthebuffer:itisinitializedwiththeconstantvalue
0.0. Because this process fully accounts for equality constraints
betweenvariablesandconstants,suchconstraintsdonotneedto
be modelledinthe controlflowofthe generatedprogram.
Equalityextractionbothreducesthesizeoftheinputbuffer,and
alleviates LibFuzzer from the onerous task of guessing equality
between certainsetsofvariables.
The input buffer is tightly packed, so that the chunks of data
associated with variables need not be aligned to word or even byte
boundaries. Chunks are ordered by the order they appear while
traversingtheinputformula.Thismakestheorderdeterministic
(usefulforreproducibility)butarbitrary.Non-alignedaccessesmake
readingfromthebuffersub-optimal,butavoidspaddingbitsthat
have no impact on program behaviour. Such bits would be detri-
mentaltoLibFuzzerasitwouldwastetimeattemptingtomutate
those bits to increase coverage. With additional engineering effort
we could adapt JFS to make LibFuzzer aware of padding bits and
instructitnottomutatethem,allowingtheperformancebenefits
associatedwithbetteralignment.
4.3 ProgramEncodings
We have experimented withtwowaystoencodeanSMTformula
as aprogram: fail-fastandtry-all.Listing 4: A translation of the constraints in Listing 3to a
C++ program based on the equalityextractionpass.
1intFuzzerTestOneInput( constuint8_t * data, size_t size) {
2double a = makeFloatFrom(data, size, 0, 63);
3double b = a;
4double c = a;
5double d = 0.0;
6double c_plus_d = add_rne(c, d);
7if(!isnan(c_plus_d)) {} else return 0;
8return 1;// TARGET REACHED
9}
Listing 5: A translation of the constraints in Listing 1to a
C++ program usingthe try-allencoding.
1intFuzzerTestOneInput( constuint8_t* data, size_t size) {
2double a = makeFloatFrom(data, size, 0, 63);
3double b = makeFloatFrom(data, size, 64, 127);
4size_t counter = 0;
5if(!isnan(a)) ++counter;
6if(!isnan(b)) ++counter;
7double a_b_rne = div_rne(a, b);
8double a_b_rtp = div_rtp(a, b);
9if(a_b_rne != a_b_rtp) ++counter;
10 if(!isnan(a_b_rne)) ++counter;
11 if(!isnan(a_b_rtp)) ++counter;
12 if(counter != 5)
13 return 0;
14 return 1;// TARGET REACHED
15}
With the fail-fastencoding (Listings 2and4) the program exits
as soon as an unsatisfied conjunct is found, without evaluating the
remaining conjuncts.Asatisfying assignment isfound if and only
if the end of the program is reached. With the try-allencoding
(Listings1and5)allnconjunctsoftheinputformulaareevaluated,
and azero-initialised counter is incrementedeach time a conjunct
is found to hold. A satisfying assignment is found if and only if the
counter equals nat the end of the program.
Thepotentialadvantageof try-allisthatevaluating everycon-
straint provides rich coverage information: if an input satisfies
somepreviously-unsatisfiedconjunct,coveragewillincreaseand
thecoverage-guidedfuzzerwillstoretheinputtobeconsideredfor
furthermutation.Thepotentialadvantageof fail-fastisthatitdoes
not waste time furtherevaluatingan inputonce it isknown that
it does not satisfy some constraint. Experimentally we have found
thatfail-fastenables JFS to solve significantly more benchmarks
thantry-all, thus we only consider the fail-fastencoding in our
evaluation (§ 5).
524JFS:SolvingFP Constraints usingCoverage-GuidedFuzzing ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia
4.4 SmartSeeds
Asdiscussedin§ 2.1,acoverage-guidedmutation-basedfuzzerrelies
onacorpusofinitialseedinputs,whichinthecaseofJFSareinitial
valuations of the input buffer. We have experimented with two
modes for selecting seeds.
Innaiveseeds mode,JFSgeneratestwoseeds:abufferofallzeros
andabufferofallones,whichatleastprovideLibFuzzer’scrossover
mutatorwithapair ofdiverseinputsto work with.
Insmart seeds mode, seeds are generated as follows. For each
distinctdatatypeassociatedwithafreevariable(e.g. Float64,bv32,
etc.),weconstructasetconsistingof(1)specialvaluesforthattype,
such as positive/negative zero, infinities, and NaN bit patterns for
floating-pointtypes(see§ 2.2),andbitpatternsencoding0,1and
-1 for bitvector types; and (2) values of constants of the given type
that appear in the input formula. We then construct a seed by
randomly sampling from the space of possible input permutations
thatcanbegeneratedfromthesesets.Thenumberofseedsselected
isconfigurable andsetto 100bydefault.
Ourhypothesesforwhysmartseedsmaybevaluablearethat
(1) special values are often important for particular data types
(e.g. afloating-point formula that looks unsatisfiable on first sight
often turns out to be satisfiable due to the subtle semantics of
NaNvalues),and(2)thesatisfiabilityofconstraintsismorelikely
to depend on values equal or similar to values appearing in the
formula than on arbitrary values (with mutations of seeds being
likelytoyieldsaidsimilarvalues).Weevaluatethebenefitsofsmart
seedsexperimentally in§ 5.
4.5 Runtime Library
TheprogramthatJFSgeneratescallsintoaruntimelibrarythatim-
plementsthesemanticsofrelevant FloatingPoint andBitVector
typesfromtheSMT-LIBv2standard,handlingroundingmodesthat
arenativelysupportedbythe x86_64architecture(allmodesexcept
round to nearest,ties to awayfrom zero).
5 EVALUATION
WenowturntotheevaluationofJFS,comparingitagainstseven
state-of-the-art SMT solvers that support solving floating-point
constraints. We discuss the benchmark selection process (§ 5.1), the
solversandhowweconfiguredthem (§ 5.2),and ourexperimental
setup(§5.3).Wethenpresenttheresultsoftheexperiments(§ 5.4),in
thecontextoftheresearchquestionsidentifiedin§ 1.Wehavemade
the sourcecode ofJFSandallour data setspubliclyavailable.2,3
5.1 Benchmark Selection
Table2summarisesthe QF_FP,QF_BVFP andQF_BVSMT-LIBsuites
from which we have drawn benchmarks for our experiments. A
subsetofthesesuitesareusedinSMT-COMP,theannualSMTsolver
competition.Allbenchmarksarequantifier-free( QF),beyondwhich
thesuitesarebuiltoverfloating-point( QF_FP),bitvector( QF_BV),
and a combination of bitvector and floating-point ( QF_BVFP) types.
For eachsuite, the Suitecolumn provides a reference to thegit
repository and SHA-1 hash associated with the version of the suite
that we used. The SATandUNSATcolumns under Unpruned
2https://github.com/mc-imperial/jfs
3https://github.com/mc-imperial/jfs-fse-2019-artifactshowthe total numberof benchmarks in each suite either already
labelledSATorUNSAT,or thatwereunlabelled butcouldbe clas-
sified empirically as SAT or UNSAT by either MathSAT5 or Z3
within900secondssecondsonourtestplatform.The UNKNOWN
andTotalcolumnsshowthenumberofbenchmarksthatremained
unlabelled,andthe totalnumber of benchmarks,respectively.
Since JFS is not designed to prove unsatisfiability, we pruned all
benchmarkslabelledUNSAT.Wealsoprunedallbenchmarksfor
whichthepre-processingstepsperformedbyJFS(§ 4.1)reducedthe
benchmark to contain only constants. We believe it was important
to removesuch trivial benchmarksto focusour evaluationonthe
effectivenessoffuzzingforconstraintsolving,ratherthantheef-
fectiveness of these well-known pre-processing steps. The pruned
benchmarks are summarized under Non-trivial, no UNSAT in
Table2.NoticethatmanySATbenchmarkswerefoundtobetrivial,
includingthe vastmajority of the QF_FPsuite.
Thelargenumbersofremaining QF_BVFPandQF_BVbenchmarks
would require prohibitive computation resources for our experi-
ments. Therefore, in a final step, we sampled a subset of these
benchmarks. To make sure we include benchmarks of varying dif-
ficulty,weperformed stratifiedrandomsampling [4]basedonthe
performanceofbothMathSAT5andZ3.Thatis,foreachbenchmark
suite,wecomputedtwohistograms(oneforMathSAT5andonefor
Z3) ofsolver executiontime withfive-second-wide bins. Toselect
abenchmark,firstahistogramisselected(round-robin),thenahis-
togram bin is selected (random), and then a benchmark is selected
fromthatbin(random).Thisprocesswasrepeateduntilthedesired
numberofbenchmarkswereselected.Weselected5%ofthebench-
marksfromeachofthepruned QF_BVFPandQF_BVsuites,usingthe
prunedQF_FPsuiteinitsentirety.Detailsofthefinalbenchmark
subsets are summarised under Final subsets in Table2, which we
refertoas QF_BVFPfs,QF_FPfsandQF_BVfs,respectively(where fs
stands for łfinalsubsetž).
5.2 SolverConfigurations
We compare JFS against seven state-of-the art constraint solvers
forfloating-point constraints. For eachsolver, Table 3summarizes
the version (v) or revision (r) used, and the main technique on
which the solver is based. We also include a synthetic portfolio
solver(JFS+MathSAT5)toaiddiscussionsofusingJFSinaportfolio
setting.JFS+MathSAT5modelsacompleteportfoliosolverthatruns
bothJFS-LF-SSandMathSAT5inparallelandreturnstheanswer
fromwhicheversolveranswersfirst.Itissyntheticbecausesolving
timeis computedas theminimum ofthesolving timesof existing
runs of JFS-LF-SS and MathSAT5. JFS-LF-SS and MathSAT5 are
combined because they are the best performing JFS configuration
(§5.4.1) andsolver for QF_FPfs(§5.4.2) respectively.
We acknowledge that some of these solvers are capable of prov-
ingUNSATaswellasSAT,whileJFSisonlycapableofprovingSAT.
This mightappear to give JFS an advantage,but we are not aware
of any way to configure those solvers to only focus on SAT, hence
we believe there isnofairer wayof performingthe comparison.
Atthe timeexperimentswere run,XSathadnotbeenofficially
released; weuse aversionofthesolveruploadedtoSTAR-EXEC4
for the 2017 SMT-COMPcompetition.
4https://www.starexec.org/
525ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia D. Liew, C.Cadar, A.F. Donaldson, andJ. R. Stinnett
Table 2:Summary oftheSMT-LIBbenchmarksuites we use as abasisforour experiments.
Unpruned Non-trivial, no UNSAT Final subset (fs)
Suite SAT UNSAT UNKNOWN Total SAT UNKNOWN Total SAT UNKNOWN Total
QF_FP[61]20,125 20,142 35 40 ,302125 35 160 125 35 160
QF_BVFP[60]14,033 3179 3 17 ,21514,033 3 14 ,036699 3 702
QF_BV[59]11,283 20,991 133 32 ,4079495 133 9628 466 16 482
Table 3:The solvers compared inour experiments.
Solver Version Technique
COLIBRI [ 13] r1572 Intervalsolving
CORAL[ 62] v0.7 Meta-heuristicsearch
CVC4[7] v1.6 Bit-blasting
goSAT[9] rb5a423c Mathematical optimisation
JFS(thispaper) r5ceecd1 Coverage-guidedfuzzing
MathSAT5 [ 17] v5.5.1 Bit-blasting
XSat[26] See text Mathematical optimisation
Z3[24] v4.6.0 Bit-blasting
TheCORAL,goSATandXSatsolversdonotsupportbitvector
reasoning, thus we can only apply them to the QF_FPfsbenchmark
suite. Instead of the SMT-LIBv2.5 format, CORAL uses its own
constraint language that only supports a subset of the semantics of
theQF_FPtheory.Toallowabest-effortcomparisonwithCORAL,
we have implemented a tool to convert SMT-LIBv2.5 constraints
intothis language.
We run each solver using its default configuration, edited if nec-
essarytoenablefloating-pointreasoningandtoenforceSMT-LIB
compliance.ExceptionsareCORAL,whichwerunusingoptions
suggested by the developersas we were unsure how to bestinvoke
the solver, and MathSAT5, which comes with a file describing pre-
ferredoptionsforeachbenchmarksuite( smtcomp2015_main.txt ).
WerunCORALintwodistinctmodes:alternatingvariablemethod
(CORAL-AVM)andparticleswarmoptimisation(CORAL-PSO).We
run JFSinthree modes: using LibFuzzer withnaive seeds(JFS-LF-
NS),usingLibFuzzerwithsmartseeds(JFS-LF-SS),andusingpurely
naive random input generation, i.e. without LibFuzzer (JFS-NR). In
allcasesthe fail-fastencoding isused(see § 4.3).
Where solvers support setting a random seed, we use a fixed
per-solver seedto try to ensure reproducibleresults.
5.3 ExperimentalSetup
We ran the 11 configurations (eight solvers, with CORAL in two
and JFS in three configurations respectively) on a machine with
two Intel®Xeon®E5-2450 v2 CPUs (8 physical cores each) with
256GiB of RAM running Ubuntu 16.04LTS . Each solver was run
five times per benchmark with a timeout of 900 seconds per run
andwithafixedrandomseed(ifsupported).Therepeatrunsofa
solverareusedtocomputeaverageexecutiontimeandobservenon-
deterministic behaviour. To allow experiments to complete within
a reasonable time-frame, each solver was executed in parallel over
the set of benchmarks, with at most 13 benchmarks running in
parallel.
Each time a solver is run on a benchmark we record a result
label. If solver reports UNKNOWN, crashes, or hits the memory ortimelimit,theresultislabelledasUNKNOWN.Ifthesolverreports
SAT (UNSAT) and that matches the expected satisfiability of the
benchmark or the expected satisfiability is UNKNOWN then the
resultislabelledasSAT(UNSAT).IfthesolverreportsSAT(UNSAT)
andtheexpectedsatisfiabilityofthebenchmarkisUNSAT(SAT)
then the result islabelledas WRONG.
Wecombinedresultslabelsforrepeatrunsofasolveronabench-
mark as follows: If at least one label is SAT (UNSAT) and all labels
are either SAT (UNSAT) or UNKNOWN, the combined label is SAT
(UNSAT). If at least one label is WRONG or the labels include a
mixtureofSATandUNSAT,thecombinedlabelisWRONG.Oth-
erwise, in the case where alllabels are UNKNOWN,the combined
label isUNKNOWN.
Tocombinetheexecutiontimes(wallclocktime),thearithmetic
mean andconfidence intervals (99.9%)are computed. Mean execu-
tiontimesareonlyconsidereddistinguishablebetweensolversif
theirconfidence intervals do not overlap.
5.4 Results
We now present and discuss our experimental results, relating
themtotheresearchquestionsidentifiedin§ 1.In§5.4.1weaddress
RQ1andRQ2bycomparingdifferentJFSconfigurations.Thenin
§5.4.2wecomparetheoverallbestJFSconfigurationfoundin§ 5.4.1
against othersolvers inorder to address RQ3.
Tovisualisesolverperformanceweusequantileplots(e.g.Fig-
ure1).Eachcurveonaplotcorrespondstoasolverconfiguration.A
curveisplottedbycomputingascoreforeachrunonabenchmark
(1 forcorrect,−1 forwrong, and 0 for unknown), sorting correct
results by solver execution time and then plotting accumulating
scoreagainstsolverexecutiontime.Anextraleftmostpointisthen
addedtothecurveandallotherpointsareoffsetalongthex-axisby
this value.The xvalueof this pointisthe sum of negative scores.
The resulting quantile plot has the following properties: (1)the
x-value of the leftmost point on a curve indicates the number of
incorrect solver answers(e.g.a valueof −5 onthe x-axisindicates
thesolverincorrectlyreportedsatisfiabilityonfivebenchmarks);
therefore,the x-valueoftheleftmostpointscanbecomparedbe-
tweencurves(rankedbyleastnumberofwronganswers);(2)the
x-valueoftheright-mostpointonacurveisthedifferencebetween
thenumberofcorrectvs.incorrectsolveranswers;therefore,the
x-valueoftherightmostpointscanbecomparedbetweencurves
(ranked by total solver score); (3) the total execution time of a
solveroncorrectlysolvedbenchmarksisequaltotheareaunder
the curve. We cannot compare the points with the same y-value
betweencurvesbecausethepointsdonotnecessarilyrefertothe
same benchmark. However, we can compare the general shapes of
curves. The quantileplots that followare bestviewedincolour.
526JFS:SolvingFP Constraints usingCoverage-GuidedFuzzing ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia
0
 20
 40
 60
 80
 100
 120
Accumulated score
0
100
101
102
Runtime (s)
JFS-NR JFS-LF-NS JFS-LF-SS
Figure 1:ComparingJFSconfigurationsover QF_FPfs.
0
 100
 200
 300
 400
 500
 600
Accumulated score
0
100
101
102
Runtime (s)
JFS-NR JFS-LF-NS JFS-LF-SS
Figure 2:ComparingJFSconfigurationsover QF_BVFPfs.
5.4.1 JFS Configuration Comparison. We compare JFS in three
different configurations JFS-LF-NS, JFS-LF-SS, JFS-NR (§ 5.2) on the
three benchmarksuites.
On theQF_BVfssuite, all JFS configurations performed poorly:
95.44%ofthebenchmarkscouldnotbesolvedbyanyconfiguration,
withverylittledifferenceinperformancebetweentheconfigura-
tions.WediscussthepoorperformanceofJFSonthissuitein§ 5.4.2,
restrictingourattentionto QF_FPfsandQF_BVFPfsfortheremainder
ofthis subsection.
The quantile plots of Figures 1and2summarise the perfor-
mance of the JFS configurations over the QF_FPfsandQF_BVFPfs
benchmarks, respectively. The zero leftmost x-values of all curves
indicatesthatnoincorrectresultswereproduced(thisalsoholds
forQF_BVfs).
ForQF_FPfs(Figure1), the right-most x-value of each curve
showsthatJFS-LF-SSsolvedthemostbenchmarks( 114),followed
byJFS-LF-NS( 110),andfinallybyJFS-NR( 91),providingpositive
support for RQ1 and RQ2. The shape of the curves shows that JFS-
LF-SS is generally faster than both JFS-LF-NS and JFS-NR (smaller
areaundercurveifcurvewidthsarenormalised),furthersupporting
RQ2.However,uponinvestigationwenoticedthatJFS-LF-SSwasTable 4:JFS-LF-SSvs.other JFSconfigurationsover QF_FPfs.
Solver Both OnlyLF-SS Onlyother Neither
JFS-LF-NS 108 (67.50%) 6 (3.75%) 2 (1.25%)44 (27.50%)
JFS-NR 90 (56.25%) 24 (15.0%) 1 (0.62%)45 (28.12%)
Allabove 108 (67.50%) 6 (3.75%) 3 (1.88%)43 (26.88%)
thefastestconfigurationfor22benchmarks,JFS-LF-NSfor6,and
JFS-NRfor24.Fortheremainingbenchmarks,itwasnotpossible
todeterminewhichconfigurationwasfastest,eitherbecausethe
solverexecutiontimeconfidenceintervalsoverlappedorbecause
none of the solvers reported SAT. It is expected that JFS-NR might
sometimesbefasterbecauseithasloweroverheadthantheother
configurations (e.g. no coverage instrumentation, no seeds to read).
ForQF_BVFPfs,Figure2shows thatJFS-LF-NS solvedthe most
benchmarks( 685),followedby JFS-LF-SS( 684)andfinally JFS-NR
(656). We can see that the shape of the curves for the LibFuzzer
configurationsaresimilar,suggestinglittledifferenceinoverallper-
formancebetweenthem.However,thenaiverandomconfiguration
is clearly worse. These results provide positive support for RQ1,
andare inconclusive withrespectto RQ2.
Quantile plots do not tell the complete story. Tables 4and5
show JFS-LF-SS similarity, complementarity, and limitations for
theQF_FPfsandQF_BVFPfsbenchmarks, compared to the other JFS
configurations.Ineachtable,the Bothcolumnstatesthenumber
ofbenchmarksshowntobesatisfiablebybothJFS-LF-SSandthe
other JFS configuration. The Only LF-SS (Only other ) column
showsthenumberofbenchmarksthatwereshowntobesatisfiable
by JFS-LF-SS (other configuration) and not by the other config-
uration (JFS-LF-SS). The Neithercolumn shows the number of
benchmarks that were shown to be satisfiable by neither JFS-LF-SS
northeotherconfiguration.Eachrowofthe tablecorrespondsto
theothersolver(specifiedbythe Solvercolumn).ThełAllabovež
row has a special meaning and is a combination of all the above
results. For the łAll abovež row: the Bothtable cell is the union of
all benchmarks thatbothJFS-LF-SS andanother JFSconfiguration
managed to solve (i.e. it is a union of intersections, not an intersec-
tion of intersections); the Only LF-SS table cell is the number of
benchmarksfoundsatisfiablebyJFS-LF-SSandnoneoftheother
configurations; the Only other table cell is the union of all bench-
marks found to be satisfiable by another configuration and not
JFS-LF-SS; and the Neithertable cell is the number of benchmarks
not foundsatisfiablebyany JFS configuration.
ForQF_FPfs, Table4shows that JFS-LF-SS and JFS-LF-NS are
quitesimilar( 67.50%ofthebenchmarkssolvedbybothand 27.50%
by neither); perhaps unsurprising given that they only differ in
the seeds fed to LibFuzzer. By contrast, JFS-NR is less similar, with
15.0%ofbenchmarks solvedonly byJFS-LF-SS.
In terms of complementarity, JFS-LF-SS always solved bench-
marksthattheotherconfigurationsdidnot.Althoughtheconverse
is true (other configurations solving benchmarks that JFS-LF-SS
did not) it is less frequent. Looking at limitations, 26.88% of the
benchmarks were not solvedbyany JFS configuration.
ForQF_BVFPfs,whilethequantileplotofFigure 2suggeststhat
JFS-LF-NS performs slightly better than JFS-LF-SS due to the num-
berofbenchmarksolved,Table 5showsthattherearetwobench-
marks that only JFS-LF-SS solved and three that only JFS-LF-NS
527ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia D. Liew, C.Cadar, A.F. Donaldson, andJ. R. Stinnett
Table5:JFS-LF-SSvs.otherJFSconfigurationsover QF_BVFPfs.
Solver Both OnlyLF-SS Onlyother Neither
JFS-LF-NS 682(97.15%) 2 (0.28%) 3 (0.43%)15(2.14%)
JFS-NR 655(93.30%) 29 (4.13%) 1 (0.14%)17(2.42%)
Allabove 682(97.15%) 2 (0.28%) 3 (0.43%)15(2.14%)
solved, showing that neither configuration is strictly superior to
theotheronthisbenchmarksuite.Regardinglimitations,theJFS
configurations performed collectively well on this suite, withonly
2.14%not solvedbyany JFSconfiguration.
Overall, for formulas involving floating-point constraints, the
results of this subsection show that using coverage-guided fuzzing
overnaiverandominputgenerationoffersbenefit,supportingRQ1.
TheresultsalsopartiallysupportRQ2inthisdomain,showingthat
smartseedsimprovetheperformanceofJFSover QF_FPfs.Whilethe
performanceresultsforJFS-LF-SSandJFS-LF-NSover QF_BVFPfsdo
notrevealaclearwinner,weuseJFS-LF-SSastheJFSconfiguration
for comparison against other solvers in § 5.4.2due to its superior
performance onthe QF_FPfssuite.
5.4.2 JFSComparedwithOtherSolvers. WenowaddressRQ3by
comparingtheJFS-LF-SSconfigurationofJFSagainstsevensolvers
ontheQF_FPfsbenchmarksandfouronthe QF_BVFPfsandQF_BVfs
benchmarks.
Comparison over QF_FPfs.The quantile plot of Figure 3sum-
marisesperformanceresultsfortheeightnon-portfoliosolversplus
JFS+MathSAT5over QF_FPfsbenchmarks.Theleftmostpointsfor
XSatandCOLIBRIindicatethattheygave 34and5wronganswers,
respectively. In all cases this was due to UNSAT being reported for
aSAT-labelledbenchmark.
In terms of the number of benchmarks found to be satisfiable,
JFS+MathSAT5 was the most successful ( 126) followed by Math-
SAT5 (125), JFS (114), CVC4 (110), COLIBRI ( 104), Z3 (102), goSAT
(91), XSat (69), CORAL-PSO ( 60), and finally CORAL-AVM ( 31).
Even though JFS does not rank the highest by number of bench-
marks solved, we can see from the shape of the curves that JFS’s
totalsolving time is significantlysmaller than MathSAT5’swhich
solved the most benchmarks out of the non-portfolio solvers. The
JFS+MathSAT5syntheticportfoliosolverillustratesthataportfo-
liocombinationofJFS-LF-SSandMathSAT5wouldperformwell
because it would solve the most benchmarks and in less time on
average.
Table6shows JFS’s capability, complementarity, and limitations
for theQF_FPfsbenchmarks. The columns and special All above
rowhavethesamemeaningasdiscussedforTable 4in§5.4.1.Table6
showsgreatdealofsimilarity( Bothcolumn)betweenMathSAT5
andJFS,followedbyCOLIBRIandCVC4,andthenZ3.Thesimilarity
withtheothersearch-basedsolvers(CORAL-AVM,CORAL-PSO,
goSAT, andXSat) issomewhat lower.
JFScomplementseveryothernon-portfoliosolver,i.e.thereisat
leastonebenchmarkthatJFScansolveandtheothersolvercannot.
However, every benchmark solved by JFS can be solved by at least
one other solver. For the search-based solvers (CORAL, goSAT, JFS,
andXSat)JFSfindsmanybenchmarkstobesatisfiablethattheother
solver does not. This shows that out of the all the search-based
solvers,JFSisthemostcompetitiveonthe QF_FPfsbenchmarksuite.
−40
 −20
 0
 20
 40
 60
 80
 100
 120
Accumulated score
0
100
101
102
Runtime (s)
COLIBRI
CORAL-AVM
CORAL-PSO
CVC4goSAT
JFS
MathSAT5XSat
Z3
JFS+MathSAT5Figure 3: Quantile plot comparing the performance of
solvers on the QF_FPfsbenchmarks
Table 6:JFScompared to other solvers over QF_FPfs.
Solver Both OnlyJFS Onlyother Neither
COLIBRI 98 (61.25%) 16(10.00%) 6 ( 3.75%) 40 (25.00%)
CORAL-AVM 31 (19.38%) 83(51.88%) 0 ( 0.00%) 46 (28.75%)
CORAL-PSO 59 (36.88%) 55(34.38%) 1 ( 0.62%) 45 (28.12%)
CVC4 98 (61.25%) 16(10.00%) 12( 7.50%) 34 (21.25%)
goSAT 86 (53.75%) 28(17.50%) 5 ( 3.12%) 41 (25.62%)
MathSAT5 113 (70.62%) 1( 0.62%) 12( 7.50%) 34 (21.25%)
XSat 62 (38.75%) 52(32.50%) 7 ( 4.38%) 39 (24.38%)
Z3 96 (60.00%) 18(11.25%) 6 ( 3.75%) 40 (25.00%)
Allabove 114 (71.25%) 0( 0.00%) 21(13.12%) 25 (15.62%)
Intermsoflimitations,everysolverexceptCORAL-AVMfindssome
benchmarks to be satisfiable that JFS does not (i.e. most solvers
are able to complement JFS). There are also some benchmarks that
neither JFS, noranothersolver manage to showas satisfiable.
JFS is also complementary in terms of execution time. Figures 4
and5showscatterplotscomparingtheexecutiontimeofJFSagainst
MathSAT5 and CVC4 respectively. We show MathSAT5 and CVC4
herebecausethesearethesolversthatfoundthehighestnumber
of benchmarks to be satisfiable that JFS did not. On these plots,
each point represents a benchmark. A diagonal line ( y=x) is
drawn,uponwhichabenchmarkwouldlieifbothsolverssolved
thebenchmarkinanidenticalamountof time.Pointsthatappear
belowthediagonalarecaseswhereJFSwasfaster,andpointsabove
the line are cases where the other solver was faster. The number
of points where this is the case (and where confidence intervals
do not overlap) are shown on the figures along with annotation
indicating howmanypointsare caseswherebothsolversreached
atimeout.Theseplotsonlyshowcaseswherebothsolverseither
reported SAT or reached a timeout because it does not make sense
to compare execution times if one of the solvers crashed. The plots
show that the solvers are highly complementary, with JFS being
faster for 86 benchmarks in each case, while MathSAT5 was faster
for 27 benchmarks andCVC4for 24.
InrelationtoRQ3,theseresultsshowthatJFSisverycompeti-
tive with other solvers on the QF_FPfsbenchmarks and is able to
complementevery solver considered.
528JFS:SolvingFP Constraints usingCoverage-GuidedFuzzing ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia
0
 100
 200
 300
 400
 500
 600
 700
 800
 900
MathSAT5 execution time (s)
0
100
200
300
400
500
600
700
800
900JFS execution time (s)27
86
34 dual timeouts160 benchmarks, 160 jointly SAT or timeout
Figure4:ScatterplotcomparingtheexecutiontimeofMath-
SAT5 andJFSon the QF_FPfsbenchmark.
0
 100
 200
 300
 400
 500
 600
 700
 800
 900
CVC4 execution time (s)
0
100
200
300
400
500
600
700
800
900JFS execution time (s)24
86
28 dual timeouts160 benchmarks, 151 jointly SAT or timeout
Figure5:ScatterplotcomparingtheexecutiontimeofCVC4
andJFSon the QF_FPfsbenchmark.
Comparisonover QF_BVFPfs.Figure6showsaquantileplotcom-
paringJFSagainstJFS+MathSAT5andtheotherthreenon-portfolio
solversthatsupportthe QF_BVFPfssuite.Theplotshowsthatthe
none of the solvers report incorrect answers and that they all re-
portasimilar numberofbenchmarksas satisfiable. JFS+MathSAT5,
CVC4, MathSAT5 and Z3 report 699benchmarks as satisfiable, fol-
lowedbyJFSwith 684,andCOLIBRIwith 666.Thefigurealsoshows
that for every solver, over 600 benchmarks were solved in under a
second. This suggeststhatthe benchmark suite (despite ourbest
efforts during stratifiedsampling) is not well balanced interms of
difficulty and may not accurately reflect the kind of constraints
that might be encountered inpractice. Table 7shows the similarity,
complementarity, and limitations of JFS on this benchmark com-
paredtoothernon-portfoliosolvers.Thetableshowsahighdegree
ofsimilaritybetweenthesolversandthatJFSisonlyabletocom-
plement COLIBRI. Every solver is able to solve benchmarks that
JFSisunabletosolve.However,ifwemakescatterplotscomparing
the execution time of JFS with that of other solvers, we find in
eachcaseasignificantnumberofbenchmarkswhereJFSsolvesthe
constraints faster (56 faster than CVC4, 27 faster than COLIBRI, 55
faster than MathSAT5, and 69 faster than Z3). We omit these plots
for brevity but they look very similar to Figures 4and5.
0
 100
 200
 300
 400
 500
 600
 700
Accumulated score
0
100
101
102
Runtime (s)
COLIBRI
CVC4JFS MathSAT5 Z3 JFS+MathSAT5Figure 6: Quantile plot comparing the performance of
solvers on the QF_BVFPfsbenchmarks.
Table 7:JFScompared to other solvers over QF_BVFPfs.
Solver Both OnlyJFS Onlyother Neither
COLIBRI 661 (94.16%) 23(3.28%) 5(0.71%) 13 (1.85%)
CVC4 684 (97.44%) 0(0.00%) 15(2.14%) 3 (0.43%)
MathSAT5 684 (97.44%) 0(0.00%) 15(2.14%) 3 (0.43%)
Z3 684 (97.44%) 0(0.00%) 15(2.14%) 3 (0.43%)
Allabove 684 (97.44%) 0(0.00%) 15(2.14%) 3 (0.43%)
With reference to RQ3, these results show that JFS is compet-
itive over QF_BVFPfs, complementing COLIBRI in the number of
benchmarkssolved,andallothersolversintermsofexecutiontime.
However, as discussed the results across all solvers suggest that
QF_BVFPfsmaynot be an especiallychallenging suite.
Comparisonover QF_BVfs.JFSisnotcompetitiveonthe QF_BVfs
suite, finding only 22benchmarks satisfiable, comparedtoe.g. 419
forZ3and 344forMathSAT5.(Weomittheassociatedquantileplot
forspacereasons.)However,foreachsolverexceptCVC4,thereare
alwayscaseswhere JFSisableto solve somebenchmarks faster.
WesuspecttwomainreasonsforthepoorperformanceofJFS
onthebitvector-onlytheory,comparedtothetheoriesinvolving
floating point. First, floating-point constraints result in much more
complex circuits, which often blow-up the underlying SAT solvers
usedbystate-of-the-artSMTsolvers.Asaresult,amorelightweight
approach like the one used by JFS is competitive on these theories.
Second,bitvectorsolvershavebeenavailableforoveradecade,
which has allowed a set of difficult and challenging benchmarks to
be developed over a long period of time. These benchmarks likely
evolvedindifficultyasbitvectorsolversgraduallyincreasedtheir
capability. On the other hand, solvers for floating-point constraints
are comparatively new and have had much less time to develop.
As a consequence, the available floating-point benchmarks are
a reflection of the relatively immature floating-point constraint
solvers currently available.
Itisalsoworthdrawingananalogywithcoverage-guidedfuzzers
applied to bug finding (their usual domain). These fuzzers are typi-
cally good at finding shallow bugs, and can only excel at finding
deep bugs with a large amount of compute time, good seeds, or
529ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia D. Liew, C.Cadar, A.F. Donaldson, andJ. R. Stinnett
domain-specificknowledge.Itcouldbethecasethatthefloating-
pointbenchmarkscurrentlyavailableinSMT-LIBaretheequivalent
ofshallowprograms, where bugsare easyfor afuzzerto find.
In summary, with respect to RQ3: the results across all three
benchmarksuitesshowthatJFSishighlycompetitiveontwosuites
(both involving floating point), and uncompetitive on the bitvector
benchmarksuite.
6 RELATED WORK
Thereisalargebodyofexistingworkthatseekstoimprovesolv-
ing floating-point constraints. The CORAL [ 62] and FloPSy [ 35]
solvers apply meta-heuristic search techniques to try to find sat-
isfying assignments to floating-point constraints. Like JFS, these
methodsare incompletebecausetheycanonlyshowsatisfiability.
All solvers construct a fitness function which they attempt to max-
imise.JFS’sfitnessfunctioniscoarseÐthenumberofnewbranches
coveredÐin contrast to CORAL’s and FloPSy’s fitness functions,
which gradually change as candidate solutions get closer to a satis-
fyingassignment.DespitethecoarsenessofJFS’sfitnessfunction,
ourresultsshowthatJFSperformsbetteroverallthanCORAL,both
in terms of the number of benchmarks it can show to be satisfiable,
and in execution time. We could not easily compare with FloPSy
duetoitstightintegrationwithPex[ 64],thesymbolicexecution
toolitisdesignedto work with.
CORAL supports using an interval solver to improve the quality
of its initial candidate inputs. It’s likely we could apply a similar
approach inJFSto generatehigher qualityseedsfor the fuzzer.
The goSAT [ 9] and XSat [ 26] solvers both reformulate finding a
satisfying assignment as a mathematical optimisation problem and
applyexistingmathematicaloptimisationalgorithmstotrytofinda
globalminimum.ThisissimilarinspirittoJFS,FloPSyandCORAL
in that the functions that goSAT and XSat seek to minimise are
essentiallyfitnessfunctions.Thedifferenceisinthealgorithmsused
to performthe search. LikeJFS, this strategy isincomplete. Again,
despite JFS’s coarser fitness functions, the experimental evaluation
foundJFSto perform betteronthosebenchmarks.
CVC4 [6], MathSAT5 [ 17], SONOLAR [ 51] and Z3 [ 24] solve
floating-point constraints by transforming floating-point opera-
tionsintobitvectorcircuitsandthenbit-blastingtheseintoaSAT
problem. This problem is then solved using a SAT solver. Unlike
JFS,thesesolversarecomplete,buttheycanendupgeneratingvery
large SAT problems, which are difficult to solve. Like JFS, these
solverssupportacombinationofthebitvectorandfloating-point
SMT-LIBv2.5 theories. Our comparison with CVC4, MathSAT5 and
Z3indicatesthattheapproachesarecomplementary,particularly
for the floating-point benchmarks, suggesting these solvers would
likely benefitfrom incorporatinga JFS-style search-based strategy
with their existing strategies, to form a portfolio solver. We did not
compare JFS with SONOLAR, but given that its design is similar
to that of SAT based solvers, we do not expect such experiments
to change our main conclusions. A prior study comparing SAT-
basedsolvingwithrandomand heuristic solversalsofound thata
portfolioapproach performs best[ 63].
COLIBRI[ 13]andFPCS[ 46]useintervalsolvingasacomplete
methodforsolvingfloating-pointconstraints.Asforthecomparison
with SAT based solvers, our comparison with COLIBRI showedcomplementarity,suggestingthatthesesolverscouldalsobenefit
from incorporating a search-based strategy. We did not compare
against FPCSbecause itisnot publiclyavailable.
REALIZER [ 38] tries to solve floating-point constraints by trans-
forming(inanequisatisfiablemanner)floating-pointconstraints
into constraints over reals, using Z3 as a back-end to solve these
constraints. REALIZER’s strategy is particularly suitable for work-
ingwithconstraintsthatchecktheaccuracyoffloating-pointex-
pressionscomparedtotheirrealcounterparts.JFScannotdothis
because it cannot handle constraints over reals. We have not yet
hadtime to compare JFSwithREALIZER.
More generally, floating-point constraint solving has gathered a
lot of attention from the research community, with several tools
based on symbolic execution, model checking, abstract interpreta-
tion, etc. using it to perform test-case generation, precision tuning,
verification, equivalence checking, peephole optimizations, branch
instabilityassessment,etc.involvingfloating-pointcode[ 1,3,5,10ś
12,16,19ś23,27,30,35,37,42,43,47,49,52ś56].
7 CONCLUSION
Wehaveinvestigatedusingcoverage-guidedmutation-basedfuzzing
toprovesatisfiabilityofSMTformulasoverfinitevariabledomains,
andfloating-pointconstraintsinparticular,viaaprototypesolver,
JFS. Our main experimental findings are that in the domain of
floating-point constraints, solving via coverage-guided fuzzing out-
performssolvingvianaivefuzzing,andperformancecanbefurther
improvedbygeneratinginitialseedsinasmartmanner;JFSishighly
competitivewithandcomplementarytoallsolverswecompared
with in the floating-point domain; and JFS is much less effective
whenappliedtothedomainofbitvectors.Oursyntheticportfolio
solving results indicate that JFS’s complementary nature would
make itauseful componentinaportfoliosolver.
Infuturework,wewouldliketobetterunderstandtheproperties
of benchmarks that dictate whether JFS performs well, with a view
to developing heuristics to help decide when it would be beneficial
to apply JFS. A first step in this direction would be to use model
countingsolversto understandwhether suitabilityfor solvingvia
fuzzing relates to number of solutions. A practical problem here is
that modelcountingsuffers from limitedscalability.
Regarding our smart seeds ,smarterseeds could be generated
basedondomain-specificknowledgeaboutthecontextinwhichJFS
isbeingused.For example,if JFS wereintegratedwithasymbolic
executionengine,seedsencodingknowledgeaboutfeasiblepaths
(andthusfeasibleinputs)couldbecommunicatedfromthesymbolic
execution engine to JFS. We also envisage severalimprovements
to the fuzzing component of JFS: designing mutators tailored to
thecontextofSMT formulas would likelybe beneficial;thefuzzer
couldbemadeawareofdataflow,usinginformationaboutthebytes
that caused a constraint to become satisfied to guide mutations;
andcandidatesformutationcouldbeprioritisedaccordingtothe
numberofconstraintstheysatisfy,whichwehypothesisewould
leadto fastersynthesis of satisfyingassignments.
ACKNOWLEDGEMENTS
ThisresearchwasgenerouslysponsoredbytheUKEPSRCthrough
grants EP/N007166/1,EP/P010040/1 andEP/R006865/1.
530JFS:SolvingFP Constraints usingCoverage-GuidedFuzzing ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia
REFERENCES
[1]MeravAharoni,SigalAsaf,LaurentFournier,AnatolyKoyfman,andRavivNagel.
2003. FPgen-atestgenerationframeworkfordatapathfloating-pointverification.
InEighthIEEEInternationalHigh-LevelDesignValidationandTestWorkshop2003,
San Francisco, CA,USA, November 12-14, 2003 . 17ś22.
[2]S.Ali,L.C.Briand,H.Hemmati,andR.K.Panesar-Walawege.2010. ASystematic
ReviewoftheApplicationandEmpiricalInvestigationofSearch-BasedTestCase
Generation. IEEETransactionsonSoftwareEngineering 36,6(Nov.2010),742ś762.
https://doi.org/10.1109/TSE.2009.52
[3]R.Bagnara,M.Carlier,R.Gori,andA.Gotlieb.2013. SymbolicPath-OrientedTest
DataGenerationforFloating-PointPrograms.In Proc.oftheIEEEInternational
Conference onSoftwareTesting,Verification, and Validation (ICST’13) .
[4]VicBarnett.2009. SampleSurveyPrinciplesandMethods (3ed.). JohnWiley&
Sons,Chapter 4.
[5]EarlT.Barr,ThanhVo,VuLe,andZhendongSu.2013. Automaticdetectionof
floating-pointexceptions.In The40thAnnualACMSIGPLAN-SIGACTSymposium
on Principles of Programming Languages, POPL ’13, Rome, Italy - January 23 - 25,
2013. 549ś560.
[6]Clark Barrett, Haniel Barbosa, Martin Brain, Duligur Ibeling, Tim King, Paul
Meng, Aina Niemetz, Andres Nötzli, Mathias Preiner, Andrew Reynolds, and
CesareTinelli.2018. CVC4 attheSMT Competition 2018. CoRRabs/1806.08775
(2018). arXiv: 1806.08775
[7]Clark Barrett, Christopher Conway, Morgan Deters, Liana Hadarean, Dejan
Jovanovic, Tim King, Andrew Reynolds, and Cesare Tinelli. 2011. CVC4. In Proc.
ofthe 23rdInternationalConference onComputer-AidedVerification (CAV’11) .
[8]ClarkBarrett,PascalFontaine,andCesareTinelli.2015. TheSMT-LIBStandard:
Version 2.5 . Technical Report. Department of Computer Science, The University
of Iowa. Available at www.SMT-LIB.org .
[9]M Ammar Ben Khadra, Dominik Stoffel, and Wolfgang Kunz. 2017. goSAT:
Floating-point Satisfiability as Global Optimization. In Proceedings of Formal
MethodsinComputer-AidedDesign(FMCAD’17) .11ś14.https://doi.org/10.23919/
FMCAD.2017.8102235
[10]Bruno Blanchet, Patrick Cousot, Radhia Cousot, Jérome Feret, Laurent
Mauborgne, Antoine Miné, David Monniaux, and Xavier Rival. 2003. A Static
Analyzer for Large Safety-critical Software. In Proceedings of the ACM SIGPLAN
2003ConferenceonProgrammingLanguageDesignandImplementation(PLDI’03) .
ACM,NewYork, NY, USA,196ś207. https://doi.org/10.1145/781131.781153
[11]MateusBorges,Marcelod’Amorim,SaswatAnand,DavidBushnell,andCorinaS.
Pasareanu.2012. SymbolicExecutionwithIntervalSolvingandMeta-heuristic
Search. In Proceedings of the 2012 IEEE Fifth International Conference on Software
Testing,VerificationandValidation(ICST’12) .IEEEComputerSociety,Washington,
DC, USA,111ś120. https://doi.org/10.1109/ICST.2012.91
[12]BernardBotella,ArnaudGotlieb,andClaudeMichel.2006. SymbolicExecutionof
Floating-point Computations. Softw. Test. Verif. Reliab. 16, 2 (June 2006), 97ś121.
https://doi.org/10.1002/stvr.v16:2
[13]Bruno Marre and FranÃğois Bobot and Zakaria Chihani. 2017. Real Behavior of
FloatingPointNumbers.In Proc.ofthe15thInternationalWorkshoponSatisfiabil-
ityModuloTheories(SMT’17) .http://smt-workshop.cs.uiowa.edu/2017/papers/
SMT2017_paper_21.pdf
[14]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: Unassisted
and Automatic Generation of High-Coverage Tests for Complex Systems Pro-
grams.In Proc.ofthe8thUSENIXSymposiumonOperatingSystemsDesignand
Implementation(OSDI’08) .
[15]Cristian Cadar and Koushik Sen. 2013. Symbolic Execution for Software Testing:
ThreeDecadesLater. CommunicationsoftheAssociationforComputingMachinery
(CACM)56,2 (2013), 82ś90.
[16]Wei-Fan Chiang, Mark Baranowski, Ian Briggs, Alexey Solovyev, Ganesh
Gopalakrishnan, and Zvonimir Rakamarić. 2017. Rigorous Floating-point Mixed-
precision Tuning. In Proceedings of the 44th ACM SIGPLAN Symposium on Princi-
ples of Programming Languages (POPL 2017) . ACM, New York, NY, USA, 300ś315.
https://doi.org/10.1145/3009837.3009846
[17]AlessandroCimatti,AlbertoGriggio,BastiaanSchaafsma,andRobertoSebastiani.
2013. The MathSAT5 SMT Solver. In Proceedings of TACAS (LNCS) , Nir Piterman
and Scott Smolka(Eds.),Vol. 7795.Springer.
[18]EdmundClarkeandDanielKroening.2003. HardwareVerificationusingANSI-
C Programs as a Reference. In Proc. of the 8th Asia and South Pacific Design
AutomationConference (ASP-DAC’03) .
[19]EdmundClarke,DanielKroening,andFlavioLerda.2004. AToolforChecking
ANSI-C Programs. In Proc. of the 10th International Conference on Tools and
Algorithmsfor the Construction and AnalysisofSystems(TACAS’04) .
[20]HélèneCollavizza,ClaudeMichel,OlivierPonsini,andMichelRueher.2014. Gen-
eratingtestcasesinsidesuspiciousintervalsforfloating-pointnumberprograms.
InProceedingsofthe6thInternationalWorkshoponConstraintsinSoftwareTesting,
Verification, and Analysis, CSTVA2014, Hyderabad,India, May 31,2014 . 7ś11.
[21]PeterCollingbourne,CristianCadar,andPaulH.J.Kelly.2011. SymbolicCross-
checkingofFloating-PointandSIMDCode.In Proc.ofthe6thEuropeanConference
onComputer Systems(EuroSys’11) .[22]Peter Collingbourne, Cristian Cadar, and Paul H.J. Kelly. 2011. Symbolic Testing
of OpenCLCode. In Proc. ofthe Haifa Verification Conference (HVC’11) .
[23]Marc Daumas, Laurence Rideau, and Laurent Théry. 2001. A Generic Library
for Floating-Point Numbers and Its Application to Exact Computing. In Theorem
Proving in Higher Order Logics , Richard J. Boulton and Paul B. Jackson (Eds.).
SpringerBerlin Heidelberg, Berlin, Heidelberg, 169ś184.
[24]LeonardodeMouraandNikolajBjùrner.2008.Z3:AnEfficientSMTSolver.In Proc.
of the 14th International Conference on Tools and Algorithms for the Construction
and AnalysisofSystems(TACAS’08) .
[25]Leonardo De Moura and Nikolaj Bjùrner. 2011. Satisfiability modulo theories:
introduction and applications. Communications of the Association for Computing
Machinery(CACM) 54,9 (Sept.2011),69ś77.
[26]ZhoulaiFuandZhendongSu.2016. XSat:AFastFloating-PointSatisfiabilitySolver .
Springer International Publishing, Cham, 187ś209. https://doi.org/10.1007/978-
3-319-41540-6_11
[27]ZhoulaiFu andZhendongSu. 2017. AchievingHighCoverageforFloating-point
Code via Unconstrained Programming. In Proceedings of the 38th ACM SIGPLAN
Conference on Programming Language Design and Implementation (PLDI 2017) .
ACM,NewYork, NY, USA,306ś319. https://doi.org/10.1145/3062341.3062383
[28]Patrice Godefroid, Nils Klarlund, and Koushik Sen. 2005. DART: Directed Auto-
matedRandomTesting.In Proc.oftheConferenceonProgramingLanguageDesign
and Implementation(PLDI’05) .
[29]Patrice Godefroid, Michael Y. Levin, and David A. Molnar. 2008. Automated
Whitebox Fuzz Testing. In Proc. of the 15th Network and Distributed System
SecuritySymposium(NDSS’08) .
[30]YijiaGu,ThomasWahl,MahsaBayati,andMiriamLeeser.2015. BehavioralNon-
portabilityinScientificNumericComputing.In Euro-Par2015:ParallelProcessing
- 21st International Conference on Parallel and Distributed Computing, Vienna,
Austria, August 24-28, 2015, Proceedings . 558ś569.
[31]Sumit Gulwani, Susmit Jha, Ashish Tiwari, and Ramarathnam Venkatesan. 2011.
SynthesisofLoop-freePrograms.In Proc.ofthe ConferenceonProgramingLan-
guage Designand Implementation(PLDI’11) .
[32]SumitGulwani,OleksandrPolozov,andRishabhSingh.2017. ProgramSynthesis.
FoundationsandTrendsinProgrammingLanguages 4,1-2(2017),1ś119. https:
//doi.org/10.1561/2500000010
[33]J.H.Holland.1975. Adaptationinnaturalandartificialsystems:anintroductory
analysis with applications to biology, control, and artificial intelligence . University
of Michigan Press.
[34]IEEE 754-2008 2008. IEEE Standard for Floating-Point Arithmetic . Standard.
InstituteofElectricalandElectronicsEngineers. https://doi.org/10.1109/IEEESTD.
2008.4610935
[35]Kiran Lakhotia, Nikolai Tillmann, Mark Harman, and Jonathan de Halleux. 2010.
FloPSy - Search-Based Floating Point Constraint Solving for Symbolic Execu-
tion.InTestingSoftwareand Systems:22ndIFIPWG6.1InternationalConference,
ICTSS 2010, Natal, Brazil, November 8-10, 2010. Proceedings , Alexandre Petrenko,
AdenilsoSimão,andJoséCarlosMaldonado(Eds.).SpringerBerlinHeidelberg,
Berlin, Heidelberg, 142ś157. https://doi.org/10.1007/978-3-642-16573-3_11
[36]Chris Lattner and Vikram Adve. 2004. LLVM: A Compilation Framework for
LifelongProgram Analysis& Transformation.In Proc.ofthe 2ndInternational
SymposiumonCodeGeneration and Optimization(CGO’04) .
[37]Wen-Chuan Lee, Tao Bao, Yunhui Zheng, Xiangyu Zhang, Keval Vora, and Rajiv
Gupta.2015. RAIVE:RuntimeAssessmentofFloating-pointInstabilitybyVec-
torization.In Proceedings ofthe2015ACMSIGPLANInternationalConference on
Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA
2015). ACM, New York, NY, USA, 623ś638. https://doi.org/10.1145/2814270.
2814299
[38]M. Leeser, S. Mukherjee, J. Ramachandran, and T. Wahl. 2014. Make it real:
Effectivefloating-pointreasoningviaexactarithmetic.In 2014Design,Automation
Test in Europe Conference Exhibition (DATE) . 1ś4.https://doi.org/10.7873/DATE.
2014.130
[39]K. Rustan M. Leino. 2009. Dafny: An Automatic Program Verifier for Functional
Correctness. In Proceedings of the 16th International Conference on Logic for
Programming, Artificial Intelligence, and Reasoning (LPAR’10) . 348ś370.
[40] libfuzzer[n.d.]. LibFuzzer. http://llvm.org/docs/LibFuzzer.html .
[41]libfuzzerbugs[n.d.]. LibFuzzertrophies. http://llvm.org/docs/LibFuzzer.html#
trophies.
[42]DanielLiew,DanielSchemmel,CristianCadar,AlastairDonaldson,RafaelZÃďhl,
and Klaus Wehrle. 2017. Floating-Point Symbolic Execution: A Case Study in
N-version Programming. In Proc. of the 32nd IEEE International Conference on
AutomatedSoftwareEngineering (ASE’17) .
[43]David Menendez, Santosh Nagarakatte, and Aarti Gupta. 2016. Alive-FP: Au-
tomated Verification of Floating Point Based Peephole Optimizations in LLVM .
SpringerBerlinHeidelberg,Berlin,Heidelberg,317ś337. https://doi.org/10.1007/
978-3-662-53413-7_16
[44]MichalZalewski.[n.d.]. AFLłbug-o-ramažtrophycase. http://lcamtuf.coredump.
cx/afl/#bugs .
531ESEC/FSE ’19, August 26ś30, 2019,Tallinn,Estonia D. Liew, C.Cadar, A.F. Donaldson, andJ. R. Stinnett
[45]Michal Zalewski. [n.d.]. Technical łwhitepaperž for afl-fuzz. http://lcamtuf.
coredump.cx/afl/technical_details.txt .
[46]C. Michel, M. Rueher, and Y. Lebbah. 2001. Solving Constraints over Floating-
PointNumbers.In Principlesand PracticeofConstraintProgrammingÐCP2001 ,
Toby Walsh (Ed.). SpringerBerlin Heidelberg, Berlin, Heidelberg, 524ś538.
[47]AndresNötzliandFraserBrown.2016.LifeJacket:VerifyingPreciseFloating-point
Optimizations in LLVM. In Proceedings of the 5th ACM SIGPLAN International
Workshop on State Of the Art in Program Analysis (SOAP 2016) . ACM, New York,
NY, USA,24ś29. https://doi.org/10.1145/2931021.2931024
[48]HristinaPalikarevaand CristianCadar.2013. Multi-solver Supportin Symbolic
Execution. In Proc. of the 25th International Conference on Computer-Aided Verifi-
cation (CAV’13) .http://srg.doc.ic.ac.uk/files/papers/klee-multisolver-cav-13.pdf
[49]Pavel Panchekha, Alex Sanchez-Stern, James R. Wilcox, and Zachary Tatlock.
2015. Automatically Improving Accuracy for Floating Point Expressions. In
Proceedings of the 36th ACM SIGPLAN Conference on Programming Language
DesignandImplementation(PLDI’15) .ACM,NewYork,NY,USA,1ś11. https:
//doi.org/10.1145/2737924.2737959
[50]Corina S. Păsăreanu, Willem Visser, David Bushnell, Jaco Geldenhuys, Peter
Mehlitz, and Neha Rungta. 2013. Symbolic PathFinder: integrating symbolic
execution with model checking for Java bytecode analysis. Automated Software
Engineering 20,3 (01 Sept. 2013),391ś425.
[51]JanPeleska,ElenaVorobev,andFlorianLapschies.2011. AutomatedTestCase
Generation with SMT-Solving and Abstract Interpretation. In NASA Formal
Methods,MihaelaBobaru,KlausHavelund,GerardJ.Holzmann,andRajeevJoshi
(Eds.).SpringerBerlin Heidelberg, Berlin, Heidelberg, 298ś312.
[52]SylviePutot,EricGoubault,andMatthieuMartel.2003. StaticAnalysis-Based
Validation of Floating-Point Computations. In Numerical Software with Result
Verification,InternationalDagstuhlSeminar,DagstuhlCastle,Germany,January
19-24, 2003, RevisedPapers . 306ś313.
[53]MinghuiQuan.2016. HotspotSymbolicExecutionofFloating-PointPrograms.
InProceedingsofthe201624thACMSIGSOFTInternationalSymposiumonFoun-
dationsofSoftwareEngineering (FSE2016) .ACM,NewYork,NY,USA,1112ś1114.
https://doi.org/10.1145/2950290.2983966
[54]Jaideep Ramachandran, Corina S. Pasareanu, and Thomas Wahl. 2015. Symbolic
ExecutionforCheckingtheAccuracyofFloating-PointPrograms. ACMSIGSOFT
SoftwareEngineering Notes 40,1 (2015), 1ś5.
[55]CindyRubio-González,CuongNguyen,BenjaminMehne,KoushikSen,James
Demmel, William Kahan, Costin Iancu, Wim Lavrijsen, David H. Bailey, andDavidHough.2016. Floating-pointPrecisionTuningUsingBlameAnalysis.In
Proceedingsofthe38thInternationalConferenceonSoftwareEngineering (ICSE’16) .
ACM, New York, NY, USA, 1074ś1085. https://doi.org/10.1145/2884781.2884850
[56]C.Rubio-GonzÃąlez,CuongNguyen,HongDiepNguyen,J.Demmel,W.Kahan,K.
Sen,D.H.Bailey,C.Iancu,andD.Hough.2013.Precimonious:Tuningassistantfor
floating-pointprecision.In 2013SC-InternationalConferenceforHighPerformance
Computing,Networking,StorageandAnalysis(SC) .1ś12.https://doi.org/10.1145/
2503210.2503296
[57]KoushikSen,DarkoMarinov,andGulAgha.2005. CUTE:AConcolicUnitTesting
EngineforC.In Proc.ofthejointmeetingoftheEuropeanSoftwareEngineering
ConferenceandtheACMSymposiumontheFoundationsofSoftwareEngineering
(ESEC/FSE’05) .
[58]SMT-COMP Competition 2006 2006. SMT-COMP Competition 2006. http://
smtcomp.sourceforge.net/2006/ .
[59] SMT-LIB. 2018. QF_BV benchmarks. https://clc-gitlab.cs.uiowa.edu:2443/SMT-
LIB-benchmarks/QF_BV.git , revision f7e691bf .
[60]SMT-LIB.2018. QF_BV_FPbenchmarks. https://clc-gitlab.cs.uiowa.edu:2443/
SMT-LIB-benchmarks/QF_BVFP.git , revision 57d0c730 .
[61]SMT-LIB.2018. QF_FPbenchmarks. https://clc-gitlab.cs.uiowa.edu:2443/SMT-
LIB-benchmarks/QF_FP.git , revision 3346ad7a .
[62]MatheusSouza,MateusBorges,Marcelod’Amorim,andCorinaS.Păsăreanu.2011.
CORAL: Solving Complex Constraints for Symbolic Pathfinder. In Proceedings of
theThird InternationalConferenceonNASAFormal Methods (NFM’11) .Springer-
Verlag,Berlin,Heidelberg,359ś374. http://dl.acm.org/citation.cfm?id=1986308.
1986337
[63]Mitsuo Takaki, Diego Cavalcanti, Rohit Gheyi, Juliano Iyoda, Marcelo d’Amorim,
andRicardoB.C.Prudêncio.2010. Randomizedconstraintsolvers:acomparative
study.Innovations in Systems and Software Engineering 6, 3 (01 Sept. 2010),
243ś253. https://doi.org/10.1007/s11334-010-0124-1
[64]Nikolai Tillmann and Jonathan De Halleux. 2008. Pex: white box test generation
for.NET.In Proc.ofthe2ndInternationalConferenceonTestsandProofs(TAP’08) .
[65]G. S. Tseytin. 1970. On the complexity of derivation in propositional calculus.
ConstructiveMathematics and Mathematical Logic (1970), 115ś125.
[66]XiWang,NickolaiZeldovich,FransKaashoek,andArmandoSolar-Lezama.2013.
TowardsOptimization-SafeSystems:AnalyzingtheImpactofUndefinedBehavior.
InProc. ofthe 24thACMSymposiumonOperatingSystemsPrinciples (SOSP’13) .
532