Automated Decomposition of Build Targets
Mohsen VakilianI, Raluca SauciucG, J. David MorgenthalerG, Vahab MirrokniG
IUniversity of Illinois at Urbana-Champaign,GGoogle
mvakili2@illinois.edu, {ralucas, jdm, mirrokni}@google .com
ABSTRACT
A(build) target speciﬁes the information that is needed to
automatically build a software artifact. Managing the de-
pendencies between the targets of a large code base is chal-
lenging. This paper focuses on underutilized targets —an im-
portant dependency problem that we identiﬁed at Google.
An underutilized target is one with ﬁles not needed by some
of its dependents. Underutilized targets result in less mod -
ular code, overly large artifacts, slow builds, and unneces -
sarybuild and test triggers . To mitigate these problems,
programmers decompose underutilized targets into smaller
targets. However, manually decomposing a target is tedious
and error-prone. Although we prove that ﬁnding the best
target decomposition is NP-hard, we introduce a greedy algo-
rithm that proposes a decomposition through iterative uni-
ﬁcation of the strongly connected components of the target.
Ourtool found19,994 decomposable targets inaset of40,000
Java library targets at Google. A decomposable target is one
that can be decomposed to at least two targets. Our tool
found that decomposing any of the 5,129 decomposable tar-
gets would save at least one build or test trigger. The eval-
uation results show that our tool is (1) eﬃcient because on
average, it analyzes a target in two minutes and (2) eﬀective
because for each of 1,010 targets, it would save more than
50% of the total execution time of the tests triggered by the
target.
1. INTRODUCTION
Software evolves rapidly. Google’s code repository has
over 100 million lines of code [6]. With over 15,000 program-
mers, the code base is growing rapidly. Half of the code base
changes every month [20,26,38].
To make the rapid evolution of software more economi-
cal and reliable, Google has developed an in-house Contin-
uous Integration (CI) [12] system. For each code change,
the CI system ﬁrst invokes the build system to build the
code aﬀected by the change. Then, it runs all the tests
that transitively depend on the aﬀected code [16,20,26,38] .
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and the full citation on the ﬁrst page. To cop y otherwise, to
republish, to post on servers or to redistribute to lists, re quires prior speciﬁc
permission and/or a fee.
Draft as of March 19, 2014.
Copyright 2014.The practice of CI is not unique to Google. Other compa-
nies [5,19,23,32,33] and open-source projects have adopte d
this practice [44,45,49].
The faster the software evolves, the heavier the load on
the CI system is. On average, the Google code repository
receives over 5,500 code changes per day, which make the
CI system run over 100 million test cases per day [6]. These
numbers grow as Google grows. Dedicating more compute
resources to the CI system is not suﬃcient to keep up with
this growth rate. Thus, Google employs advanced technolo-
gies to ensure that build and test results are delivered to
programmers correctly in a timely manner [6,9,16,20,26,28 ,
38,52].
The Google build system, like other build systems [40–
43,48], takes as input a set of build ﬁles that declare build
targets. We refer to a build target as atargetin the rest
of this paper. Targets specify whatis needed to produce an
artifact such as a library or binary. A target also speciﬁes i ts
unique name, kind, source ﬁles, and dependencies on other
targets (Figure 1). The build system decides howto build a
given target based on the target’s speciﬁcation.
Buildspeciﬁcationsareoftenthoughtofas merelyameans
to transform source code into executable and other arti-
facts. However, build speciﬁcations are used more widely in
practice because they capture an important architectural a s-
pect of software, namely, the dependency structure between
pieces of code. For example, at Google, several systems
other than the build system, e.g., Integrated Development
Environments (IDEs) and CI [12] systems rely on build spec-
iﬁcations. IDEs rely on the build speciﬁcations to determin e
the code that an IDE has to index for a given package. Sim-
ilarly, a CI system uses the build speciﬁcations to compute
the set of tests aﬀected by a code change. Despite the so-
phisticated caching and parallelism of Google’s build sys-
tem [6,9,16,20,52], slow builds, CI, and IDEs are still majo r
issues.
Like code in languages such as C and Java, build speciﬁca-
tions require signiﬁcant, continuous maintenance. Resear ch
suggests that build maintenance accounts for 27% and 44%
of code and test development, respectively [25]. Our prior
work [28] showed that build speciﬁcations are prone to code
smells such as unneeded andmissing direct dependencies .
This paper focuses on a speciﬁc code smell, which we call un-
derutilized targets . An underutilized target has source ﬁles
that some of its dependents do not need. Underutilized tar-
gets make the builds and IDEs slower, increase the size of
executables, and increase the load on the CI system by trig-
gering unnecessary builds and tests.
1
brought to you by CORE View metadata, citation and similar papers at core.ac.uk
provided by Illinois Digital Environment for Access to Learning and Scholarship RepositoryArefactoring is a code change that preserves the behavior
of the program [13,29]. Target decomposition , or simply
decomposition , is our term for a refactoring that mitigates
the problems of underutilized targets. It ﬁrst decomposes
an underutilized target into smaller targets, which we refe r
to asconstituent targets or simply constituents , and then
updates the dependents of the original target to depend on
only the needed constituents.
Identifyingandrefactoring underutilizedtargets is tedi ous
and error-prone to do manually for several reasons. First, a
large code base has many targets (over 40,000 targets at
Google). This makes it nontrivial, if not impossible, to ﬁnd
the targets whose decompositions would yield the largest
gains. Second, there are often many possible decomposi-
tions for a target. Choosing an eﬀective decomposition from
this large space is a daunting task. Third, manually decom-
posing a target is error-prone because a valid decompositio n
must obey the dependencies between the source ﬁles of the
target. Finally, decomposing a target without updating its
dependents will yield limited beneﬁts. Once a target is de-
composed into smaller, constituent targets, its dependent s
have to change so that they depend on the constituent tar-
gets. This refactoring is tedious and error-prone because a
target can have many dependents owned by diﬀerent devel-
opment teams.
We propose two tools, Decomposer andRefiner , for
identifying and refactoring underutilized targets. Decom-
poseridentiﬁes underutilized targets and suggests how to
decompose them to constituent targets. Refiner is a refac-
toring tool that updates the dependents of the underutilize d
targets to depend on only the needed constituent targets.
Decomposer estimates the impact of a decomposition
on the number of triggers, i.e., the number of binary and
test targets that the CI system builds and runs, respectivel y.
In addition, it suggests a decomposition using a greedy al-
gorithm that accounts for both the ﬁle-level dependencies
between the source ﬁles of a target and the target-level ones
between the target and its dependents. The algorithm ﬁrst
computes the strongly connected components (SCCs) of the
graph formed by the ﬁle-level dependencies of the target.
Then, it iteratively uniﬁes two SCCs at a time until only
two SCCs are left. Finally, the algorithm promotes each
SCC to a target.
Although we implemented Decomposer andRefiner at
Google, the underlying techniques are generalizable to oth er
environments. These tools can be adapted to any environ-
ment that can provide its ﬁle-level and target-level depen-
dencies. Our tools are sound assuming that the provided
ﬁle-level and target-level dependencies are sound.
The results of our large-scale empirical study show that
Decomposer is botheﬃcient andeﬀective (Section 9). We
ranDecomposer on a large, random sample of targets that
consisted of 40,000 Java library targets at Google1.Decom-
poseranalyzes a target within minutes (mean = 2, sd = 5).
Out of the 40,000 targets, Decomposer found 19,994 de-
composable targets. A decomposable target is one that has
at least one valid decomposition (Section 4). Decomposer
is also eﬀective at saving unnecessary triggers. It estimat ed
that its proposed decompositions would signiﬁcantly reduc e
the test execution time (minutes) per change to each tar-
get (mean = 98, sd = 1,250). On average, a decomposition
1Forconﬁdentialityreasons, wedonotreportexactstatisti cs
about the dimensions of the Google code base.proposed by Decomposer reduces the total execution time
of the tests triggered by the target by 12%. For each of
1,010 targets, thedecompositions proposedby Decomposer
would save more than 50% of the execution time of the tests
triggered by the target. Decomposer has been deployed at
Google and used by about a dozen programmers so far. This
work makes several research contributions:
•We quantify the beneﬁt of a decomposition in terms of
the number of triggers that it saves (Section 4).
•We formalize the decomposition problem as a graph
problem andprovethat ﬁndingthebest decomposition
is NP-hard (Section 5).
•We present the algorithm (Section 6) and implemen-
tation (Section 8) of Decomposer —a tool for decom-
posing targets.
•We present Refiner —a tool that refactors build spec-
iﬁcations to take advantage of a decomposition (Sec-
tion 7).
•We evaluate Decomposer through a large-scale em-
pirical study in an industrial environment (Section 9).
2. BUILD SYSTEM
A build system is responsible for transforming source code
into libraries, executable binaries, and other artifacts. The
build system takes as input a set of targets that program-
mers declare in build ﬁles. Figure 1 shows sample build
speciﬁcations.
When a programmer issues a command to the build sys-
tem to build a target, the build system ﬁrst ensures that
the required dependencies of the target are built. Then, it
builds the desired target from its sources and dependencies .
The ﬁnal artifact depends on the kind of the target. For
example, for Java targets, the build system produces JAR
ﬁles.
Build Targets
Programmers have to specify four attributes in the spec-
iﬁcation of a target τ: name, kind, source ﬁles, and depen-
dencies. The BUILDﬁles shown in Figure 1 specify three
targets with names b1,l1, andl2.S(τ) denotes the set of
source ﬁles of the target named τ. The targets shown in
Figure 1 set their source ﬁles to be the set of Java ﬁles in
the directory that encloses the BUILDﬁle.K(τ) denotes the
kind of target τ, which can be binary,library, ortest. In
Figure 1, K(b1) =binaryandK(l1) =K(l2) =library.
For both library andbinarytargets, the build system gen-
erates JAR ﬁles. The diﬀerence is that the JAR ﬁle for a
binary target has an entry mainmethod and contains all the
transitive dependencies of the target. Deps(τ) is the set of
targets that need to be built before building τ. In Figure 1,
Deps(b1) ={l1,l2}.
Dependency Graphs
Programmers havetoconsiderbothtarget-levelandﬁle-lev el
dependencieswhenspecifyingtargets. ThegraphinFigure2
illustrates both kinds of dependencies.
Build Graph (Target-levelDependencies) Targetsspec-
ify abuild graph B= (T,E), where Tis the set of all targets.
21java_binary(
2name="b1",
3srcs=glob(["*.java" ]),
4deps=[
5"//l1",
6"//l2",
7]
8)
(a) Contents of ﬁle //b1/BUILD1java_library(
2name="l2",
3srcs=glob(["*.java" ]),
4deps=[
5"//l1",
6]
7)
(b) Contents of ﬁle //l2/BUILD1java_library(
2name="l1",
3srcs=glob(["*.java" ]),
4deps=[]
5)
(c) Contents of ﬁle //l1/BUILD
Figure 1: Three BUILDﬁles that declare targets b1,l2, andl1shown in Figure 2. Attribute namespeciﬁes the
name of the target. The srcsattribute speciﬁes the source ﬁles of the target. The expres sionglob(["*.java"])
resolves to all Java ﬁles in the enclosing directory of the BUILDﬁle. The depsattribute lists the targets that
need to be built to compile the source ﬁles of the target.
Figure 2: A graph that illustrates both target-level and ﬁle -level dependencies for an underutilized target l1.
SCCirepresents a strongly connected component (Section 6.1) of the cross references graph of l1.
For each τ1,τ2∈T, there is an edge ( τ1,τ2)∈Eif and only
ifτ2∈Deps(τ1).
Figure 2 shows a build graph with ﬁve library ( {l1,l2,...,
l5}), two binary ({b1,b2}), and six test ({t1,t2,...,t6})
targets.
The build system expects to be able to build each target
after building the dependencies of the target. Thus, the
build graph must be a directed acyclic graph (DAG).
The notation u❀Gvdenotes that there is a path from
vertexutovin graph G, andu/ne}ationslash❀Gvdenotes the lack
thereof. For build graph B, we say that target τ1∈Ttran-
sitivelydepends on target τ2∈Tif and only if τ1❀Bτ2.
Cross References Graph (File-level Dependencies)
The shape of the build graph B= (T,E) is inﬂuenced by
the ﬁle-level dependencies. If a source ﬁle of τ1references a
symbol (e.g., class or method) deﬁned in a source ﬁle of τ2,
then(τ1,τ2)∈E(B). More formally, let f1→f2denotethat
ﬁlef1references a symbol deﬁned in ﬁle f2. Similarly, let
τ1→τ2denote that a ﬁle of τ1references a symbol deﬁned
in a ﬁle of τ2, i.e.,∃f1∈S(τ1),f2∈S(τ2)f1→f2. To simplify the
discussion in the rest of the paper, we assume that τ1→τ2if
and only if ( τ1,τ2)∈E(B).τ1/ne}ationslash→τ2indicates that τ1→τ2
does not hold.
Definition 1.The cross references between the source
ﬁles of a target τcan be represented as a graph Gτ, called the
cross references graph of τ. The vertices of Gτare members
ofS(τ)and there is an edge (f1,f2)∈E(Gτ)if and only if
f1→f2.The graph Gl1is a subgraph of the graph shown in Fig-
ure2. Inthisexample, Gl1consists of10verticescorrespond-
ing to the ﬁles of l1and the dependency edges between these
ﬁles. In graph theory terminology, Gl1is theinduced sub-
graphof the graph in Figure 2 with vertices {f1,f2,...,
f10}.
Continuous Integration
The Google ContinuousIntegration(CI)systemmonitorsev-
ery code change. The CI system computes the set of targets
that may be aﬀected by a code change. If a change aﬀects
the build graph, the CI system will update the build graph
accordingly. In Figure 2, if any of the source ﬁles of l1(i.e.,
{f1,f2,···,f10}) change, theCI system will invokethebuild
system to build the targets that transitively depend on l1,
i.e.,{b1,b2}∪{l2,l3,···,l5}∪{t1,t2,···,t6}and run the
tests included in the test targets that transitively depend on
l1, i.e.,{t1,t2,···,t6}.
3. UNDERUTILIZED TARGETS
Like ordinary source ﬁles in Java, C, and Python, build
ﬁles accumulate code smells over time. A code smell speciﬁc
to build ﬁles that we identiﬁed is underutilized target . If a
target has some dependent targets that need only a subset
of its source ﬁles, we consider the target underutilized. Un -
derutilized targets lead to large binaries, slow builds, an d
unnecessary builds and tests triggered by the CI system.
Consider the example in Figure 2. Target l1has two sets
ofﬁlesS1={f1,f2,···,f7}andS2={f8,f9,f10}. Suppose
thatS1is a set of implementation classes and S2is a set of
3interfaces and abstract classes. Files of S1depend on the
ﬁles ofS2but not vice versa. Target l1is underutilized by
one binary ( b2) and four test ( t3,t4,t5, andt6) targets. As a
result, if a change aﬀects only the ﬁles in S1, the CI system
will unnecessarily trigger the build of one binary ( b2) and
the execution of four test targets ( t3,t4,t5, andt6).
In theory, a CI system can save triggers by trackingdepen-
dencies at the ﬁle-level instead of target-level. However, the
Google CI system uses target-level dependencies to compute
the build and test triggers for twomain reasons. First, trac k-
ingdependenciesat theﬁle-levelis expensive. Second, sou nd
inference of all runtime dependencies and dependencies on
data ﬁles and generated code is undecidable in general. The
Google CI system avoids this problem by allowing the pro-
grammers document such dependencies of targets in build
speciﬁcations.
4. TARGET DECOMPOSITION
A refactoring to remove underutilized targets is to decom-
pose them into smaller targets. We call the refactoring tar-
get decomposition ordecomposition and the smaller targets
constituent targets or simply constituents . For the example
in Section 3, this refactoring would decompose the underuti -
lized target l1intotwoconstituenttargets l6andl7suchthat
S(l6) =S1,S(l7) =S2andl6depends on l7(i.e.,Deps(l6)
={l7}).
Granularity Intuitively, the best decomposition of a tar-
get is one that removes the largest number of unneeded de-
pendencies from binaries and tests on the ﬁles of the target.
Finer-grained decompositions can remove alarger numberof
unneeded dependencies. For example, decomposing a target
into three constituent targets can remove more unneeded de-
pendenciesthandecomposingthetargetintotwoconstituen t
targets.
While avoiding unnecessary triggers is important, there
are also other factors that inﬂuence modularity decisions.
Programmers may prefer coarse-grained modules because
such modules may be easier to name, may make it easier
to ﬁnd code, and may better match the structure of the or-
ganization. Thus, by default, Decomposer proposes a de-
composition of a given target into exactly two constituents .
Nonetheless, Decomposer can be conﬁgured to propose de-
compositions to more constituents.
Validity Letτ//an}bracketle{tτ1,τ2/an}bracketri}htdenote a decomposition of target τ
into two constituent targets τ1andτ2. The decomposition
partitions the ﬁles of target τbetween τ1andτ2. In other
words,S(τ) =S(τ1)∪S(τ2) andS(τ1)∩S(τ2) =∅. The
eﬀect of decomposing τis to add two new targets τ1andτ2,
changeτso thatS(τ) =∅, and make τdepend on both τ1
andτ2.
An arbitrary partitioning of the ﬁles of a target τinto two
targets may not produce a valid decomposition . A decompo-
sitionτ//an}bracketle{tτ1,τ2/an}bracketri}htis valid if and only if τ2/ne}ationslash→τ1. Otherwise, if
τ1→τ2andτ2→τ1, applying the decomposition will intro-
duce a cyclic dependency between τ1andτ2, which breaks
the modularity of the system and is disallowed by the build
system.
To simplify the exposition, we consider the decomposition
τ//an}bracketle{tτ1,τ2/an}bracketri}htwhereτ1/ne}ationslash→τ2andτ2→τ1invalid, despite the
fact that this decomposition keeps the build graph acyclic.
We do not lose any generality by considering such a decom-position invalid, because reordering τ1andτ2produces a
valid decomposition τ//an}bracketle{tτ2,τ1/an}bracketri}ht.
The decomposition l1//an}bracketle{tl6,l7/an}bracketri}htdescribed above is valid be-
causel7/ne}ationslash→l6.
Trigger Saving We measure the beneﬁt of a decomposition
by the number of binary and test triggers that it saves. Let
∆(τ//an}bracketle{tτ1,τ2/an}bracketri}ht) denote the quantitative beneﬁt of τ//an}bracketle{tτ1,τ2/an}bracketri}ht.
We refer to ∆( τ//an}bracketle{tτ1,τ2/an}bracketri}ht) as the trigger saving ofτ//an}bracketle{tτ1,τ2/an}bracketri}ht.
Note that a decomposition τ//an}bracketle{tτ1,τ2/an}bracketri}htalone does not re-
move any unneeded dependencies unless the dependents of
τare changed to depend on τ1orτ2. Thus, when quanti-
fying the beneﬁt of a decomposition, we assume that the
dependents of τwill be changed to depend on τ1and/orτ2
wherever possible.
Definition 2.D(τ)denotes the set of binary and test
targets that transitively depend on target τ, i.e.,{τ′∈T|
K(τ′)∈{binary,test},τ′❀Bτ}.
After applying the decomposition l1//an}bracketle{tl6,l7/an}bracketri}ht, we will have
|D(l6)|= 3,|D(l7)|= 8,|D(l6) -D(l7)|= 0, and|D(l7) -
D(l6)|= 5. Note that because l6→l7, we haveD(l6)⊆
D(l7). If a code change aﬀects only the ﬁles in S(l6), the de-
composition will save |D(l7) -D(l6)|triggers. Similarly, if a
code change aﬀects only the ﬁles in S(l7), the decomposition
will save|D(l6) -D(l7)|triggers.
Letp1be the probability that a change aﬀects only a
ﬁle inS(τ1). Similarly, let p2be the probability that a
change aﬀects only a ﬁle in S(τ2). We approximate p1by
|S(τ1)|/(|S(τ1)|+|S(τ2)|)andp2by|S(τ2)|/(|S(τ1)|+|S(τ2)|).
These formula are approximations and not exact values of p1
andp2because an accurate computation has to account for
any change to the transitive dependencies of τ1andτ2. We
approximate p1andp2because their accurate computations
are expensive.
Definition 3. ∆(τ//an}bracketle{tτ1,τ2/an}bracketri}ht), the trigger saving of decom-
position τ//an}bracketle{tτ1,τ2/an}bracketri}ht, is:
p1|D(τ2)−D(τ1)|+p2|D(τ1)−D(τ2)|,
where
p1=|S(τ1)|
|S(τ1)|+|S(τ2)|, p2=|S(τ2)|
|S(τ1)|+|S(τ2)|.
Intuitively, ∆( τ//an}bracketle{tτ1,τ2/an}bracketri}ht) is the expected numberof binary
andtesttargetsthatwon’tbetriggeredafterapplyingthed e-
composition and updating the dependents of τ. The greater
∆(τ//an}bracketle{tτ1,τ2/an}bracketri}ht)is, themoretriggerswillbesavedbythedecom-
position. Figure 3 illustrates what ∆( τ//an}bracketle{tτ1,τ2/an}bracketri}ht) measures.
For the decomposition l1//an}bracketle{tl6,l7/an}bracketri}ht, we have p1=7
10and
p2=3
10. Thus, ∆( l1//an}bracketle{tl6,l7/an}bracketri}ht) =7
10·5 +3
10·0 = 3.5. This
implies that decomposing target l1can save on average 3.5
triggers every time a change aﬀects only S(l6) or only S(l7).
Although the saving is small in this contrived example, de-
composing targets yields signiﬁcant beneﬁts in practice (S ec-
tion 9).
5. HARDNESS OF DECOMPOSITION
Theorem 1.Given a target τ, ﬁnding the decomposition
τ//an}bracketle{tτ1,τ2/an}bracketri}htthat maximizes ∆(τ//an}bracketle{tτ1,τ2/an}bracketri}ht)is an NP-hard prob-
lem.
4S(τ1) S(τ2)/Bullet/Bullet/BulletD(τ1)D(τ2)
τLegend
a set of
a set of ﬁles
a target
a dependency
after decompositionthat will remain
a dependency
after decompositionthat will be removeddependents
Figure 3: Decomposition τ//an}bracketle{tτ1,τ2/an}bracketri}htremoves un-
needed dependencies (dashed arrows) that cause un-
necessary build or test triggers. ∆(τ//an}bracketle{tτ1,τ2/an}bracketri}ht)is the
average number of triggers that the decomposition
would save every time a change aﬀects the ﬁles in
onlyS(τ1)or only S(τ2).
Proof. We prove NP-hardness by showing a reduction
from the maximum clique problem in graph theory. In an in-
stance ofthemaximum cliqueproblem, we are given anundi-
rected graph H(V,E) withnvertices and a number k, and
the goal is to compute a complete subgraph (a.k.a. clique)
of sizekin graph H. We give a reduction from the speciﬁc
problem with k=2n
3.
Given an instance H(V,E) of the maximum clique prob-
lem, we construct an instance of the decomposition problem
as follows: Consider a build graph B= (E(H)∪{τ}, J),
whereτis a target such that S(τ) =V(H)∪E(H). We as-
sume that each target ( u,v)∈V(B) is dependent on three
source ﬁles u,v,(u,v)∈S(τ). The cross reference graph
Gτis constructed as follows: For an edge ( u,v)∈E(H),
lets= (u,v)∈S(τ); we let u→sandv→s. In other
words, in order to form Gτ, we add an edge from each ver-
texu∈V(H) to all edges e∈E(H) that are adjacent to
u.
Now consider a decomposition ( τ1,τ2) of target τ. It is
not hard to see that for a decomposition with the maximum
saving, we have S(τ1)⊆V(H) since for any e= (u,v)∈
S(τ1), we can remove efromτ1and add it to τ2and not
decrease the saving.
Consider a decomposition S(τ1)⊆V(H). For any edge
(u,v)∈E(H) where u,v∈S(τ2), target ( u,v)∈V(B)
only depends on τ2and not τ1. Otherwise, if uorvare in
S(τ1), target ( u,v)∈V(B) depends on both τ1andτ2. As
a result, for any target corresponding to ( u,v)∈E(H), its
dependence to τ1is saved if and only if both uandvare in
S(τ2).
Therefore, in order to maximize the saving, we need to
maximize|S(τ1)|·|{(u,v)∈E(H)|u,v/ne}ationslash∈S(τ1)}|. This
shows that if we ﬁnd a clique of size kwith vertices Tof
graphH, we can set S(τ1) =V(H)−TandS(τ2) =E(H)∪
T. The saving of such a clique would be maximized when
|S(τ1)|·|δ(T,T)|= (n−k)/parenleftbigk
2/parenrightbig
is maximized, where δ(X,Y)
is the set of edges from set Xto setYof vertices.
The term ( n−k)/parenleftbigk
2/parenrightbig
is maximized at k=2n
3. Therefore,
there exists a decomposition with the maximum saving, if
and only if there exists a clique of size2n
3. NP-hardness
follows from the fact that ﬁnding a clique of size2n
3in an
n-vertex graph is also NP-hard.6. DECOMPOSITION ALGORITHM
Since ﬁnding the best decomposition is an NP-hard prob-
lem, we propose an eﬃcient greedy algorithm that ﬁnds ef-
fective decompositions in practice. Our algorithm suggest s
a decomposition in the following steps:
1. Compute the strongly connected components (SCC) of
the cross references graph of the given target.
2. Find the binary and test targets that transitively de-
pend on each SCC.
3. Partition the SCCs of the target into two sets with a
goal of maximizing the number of saved triggers (Def-
inition 3).
The rest of this section describes the above steps.
6.1 Strongly Connected Components (SCCs)
A directed graph Gisstrongly connected if and only if for
each pair of vertices v1,v2∈V(G),v1❀Gv2andv2❀Gv1.
A strongly connected component of a graph Gis a maximal
subgraph of Gthat is strongly connected. We refer to a
strongly connected component as an SCC.
Definition 4.For a ﬁle f∈S(τ),SCC(τ,f)denotes
the SCC of Gτthatfbelongs to. Also, S(τ,c)denotes the
set of ﬁles of target τin SCCc, i.e.,S(τ,c)={f∈S(τ)|
c=SCC(τ,f)}.
For example, target l1in Figure 2 consists of four SCCs.
We have SCC(l1,f1) =SCC(l1,f2) =SCC(l1,f3) =SCC(-
l1,f4) =SCC1because vertices f1,f2,f3, andf4induce a
maximal subgraph of Gl1that is strongly connected.
The SCCs of Gτform the smallest units of decomposing
targetτ. That is, any valid decomposition must assign all
ﬁles of an SCC to the same constituent target. Otherwise,
there will be a cyclic dependency between the constituent
targets. Thus, the decomposition problem reduces to de-
composing the set of SCCs instead of the set of ﬁles.
Condensation Graph If each SCC of Gis contracted to a
single vertex, the resulting graph is the condensation graph
ofGdenoted asC(G). In Figure 2,C(Gl1) has four vertices
SCC1,SCC2,SCC3, andSCC4and three edges. As a start-
ing point, our algorithm computes C(Gτ) using a standard
DFS-based algorithm [11] that runs in O(N) time and space,
whereN=|V(Gτ)|.
If there is no limit on the number of constituent targets
andC(Gτ) hasnvertices corresponding to SCCs ( c1,c2,···,
cn), then the best decomposition of τwill beτ//an}bracketle{tτ1,τ2,···,-
τn/an}bracketri}ht, whereS(τi) =S(τ,ci) for each i∈{1,...,n}. However,
due to the potential drawbacks of such a ﬁne-grained decom-
position(Section4), ouralgorithm proposesadecompositi on
to only two constituent targets by default.
6.2 Dependents
Adecomposition τ//an}bracketle{tτ1,τ2/an}bracketri}htisidealifitmaximizes∆( τ//an}bracketle{tτ1,-
τ2/an}bracketri}ht) (Deﬁnition 3). ∆( τ//an}bracketle{tτ1,τ2/an}bracketri}ht) depends onD(τ1) and
D(τ2) (Deﬁnition 2), i.e., the set of binary and test targets
that transitively depend on τ1andτ2, respectively. To ﬁnd
constituent targets τ1andτ2, our algorithm ﬁrst computes
D∗(τ,c) for each SCC c.D∗(τ,c) is the set of binary and
test targets that transitively depend on SCC cofGτ. In
Figure 2,D∗(l1,SCC i) is a set of bjandtktargets that can
5reach a ﬁle in SCCiby following the dependencyedges. The
following describes how the algorithm computes D∗(τ,c).
LetD(τ,f) be the set of binary and test targets that tran-
sitively depend on ﬁle f∈S(τ) through target τ:
D(τ,f) ={u|K(u)∈{binary,test},
u❀Bv,(v,τ)∈E(B),
∃g∈S(v)g→f}.
In Figure 2,D(l1,f9) ={b2,t2,t3,t4,t5}andD(l1,f8) =
∅.
LetD(τ,c) be the set of binary and test targets that tran-
sitively depend on SCC cofGτ(either directly or indirectly
through other targets). We compute D(τ,c) by taking the
union ofD(τ,f) over all f∈S(τ,c):
D(τ,c) =/uniondisplay
f∈S(τ,c)D(τ,f)
In Figure 2, we have D(l1,SCC 3) =D(l1,f8)∪D(l1,f9)
={b2,t2,t3,t4,t5}.
UnlikeD(τ,c),D∗(τ,c) takes the dependencies between
the ﬁles of SCCs into account. Intuitively, D∗(τ,c) is the
set of binary and test targets that transitively depend on a
ﬁle of SCC c(either directly or indirectly through other ﬁles
and targets). We deﬁne D∗(τ,c) to include the dependencies
captured by the condensation graph C(Gτ).
D∗(τ,c) =/uniondisplay
c′❀C(Gτ)cD(τ,c′)
In Figure 2, we have D∗(l1,SCC 3) =D(l1,SCC 1)∪D(l1,-
SCC3) ={b1,b2,t1,t2,t3,t4,t5}.
Finally, we compute D(τ), the set of binary and test tar-
gets that transitively depend on τ, in terms ofD∗(τ,c).
D(τ) =/uniondisplay
c∈V(C(Gτ))D∗(τ,c)
6.3 Unifying SCCs
We deﬁne uniﬁcation as an operation that takes two SCCs
c1andc2ofGτand creates a new SCC csuch that S(τ,c) =
S(τ,c1)∪S(τ,c2) and contracts the two vertices of C(Gτ)
corresponding to c1andc2to a vertex corresponding to c. If
c1andc2are uniﬁedto c, we will haveD∗(τ,c) =D∗(τ,c1)∪
D∗(τ,c2).
Figure 4 shows two subsequent uniﬁcations applied on the
condensation graph of target l1in Figure 2. The ﬁrst uniﬁ-
cation contracts vertices SCC2andSCC3to a new vertex
SCC23, where S(l1,SCC 23) =S(l1,SCC 2)∪S(l1,SCC 3)
={f5,f6,f7,f8,f9}.
6.3.1 Iterative Uniﬁcation
After computing the SCCs of the cross references graph
of a target, the algorithm iteratively uniﬁes two SCCs at
each step until only two are left. The two remaining SCCs
form the two new constituent targets. The trigger saving
cannot increase after a uniﬁcation step. Following a greedy
scheme, at each step, the algorithm uniﬁes two SCCs whose
uniﬁcation incurs the least cost. Let δ(τ,c1,c2) be the cost
of unifying SCCs c1andc2ofGτ. Intuitively, δ(τ,c1,c2)
is the average number of triggers per change that would be
saved if c1andc2are not uniﬁed. Similar to Deﬁnition 3,
we deﬁne δ(τ,c1,c2) as
p1|D∗(τ,c2)−D∗(τ,c1)|+p2|D∗(τ,c1)−D∗(τ,c2)|,Figure 4: Unifying the SCCs of the cross references
graph of target l1in Figure 2. The graph on the
left isC(Gl1). First, SCC2andSCC3are uniﬁed to
SCC23. Then, SCC1andSCC4are uniﬁed to SCC14.
The ﬁnal condensation graph (on the right) is invalid
because it has a cycle. As a result, a decomposition
corresponding to SCC14andSCC23is invalid, too.
where
p1=|S(τ,c1)|
|S(τ,c1)|+|S(τ,c2)|, p2=|S(τ,c2)|
|S(τ,c1)|+|S(τ,c2)|.
At each step, the greedy algorithm uniﬁes two SCCs c1
andc2such that δ(τ,c1,c2) = min i,jδ(τ,ci,cj). For target
l1in Figure 2, the algorithm ﬁrst uniﬁes SCC1andSCC2to
SCC12because it incurs the least cost ( δ(l1,SCC 1,SCC 2)
= 0). Next, it uniﬁes SCC3andSCC4toSCC34because
it has the smallest uniﬁcation cost ( δ(l1,SCC 3,SCC 4) =
2
3). Finally, it will turn SCC12andSCC34into constituent
targets.
6.3.2 Avoiding Invalid Decompositions
The uniﬁcation algorithm as described in Section 6.3.1
may produce invalid decompositions. Consider the example
condensation graph in Figure 4. Suppose the greedy algo-
rithm ﬁrst uniﬁes SCC2andSCC3intoSCC23, and then
SCC1andSCC4intoSCC14. These uniﬁcations produce
an invalid decomposition. This is because the targets corre -
sponding to SCC23andSCC14will depend on each other
and introduce a circular dependency to the build graph.
Lemma 1.Contracting two vertices that are adjacent in
a topological ordering of a DAG results in another DAG.
We use Lemma 1 to guarantee that unifying SCCs always
produces a valid decomposition. Rather than considering
the uniﬁcations of all pairs of SCCs, we make the algorithm
consider the uniﬁcations of only those pairs of SCCs that are
adjacent in a topological ordering of the condensation grap h.
This restriction guarantees that each uniﬁcation keeps the
condensation graph a DAG. This property ensures that the
iterative uniﬁcation produces a valid decomposition at eac h
step. As a special case, the ﬁnal condensation graph with
two vertices will be acyclic and result in a valid decomposi-
tion to two constituent targets.
7. DEPENDENCY REFINEMENT
Decomposing an underutilized target alone brings several
beneﬁts. First, it improves the modularity of the system.
Second, it reduces the build time when a code change does
not aﬀect all the constituent targets. Third, new targets
6input :B, the build graph
input :τ, an underutilized target
input :τ1,τ2, constituent targets of τ(τ1/ne}ationslash∈
Deps(τ2))
1foreach u∈V(B)where(u,τ)∈E(B)do
2E(B)←E(B)- (u,τ)
3if notbuilds(u)then
4 E(B)←E(B)∪(u,τ2)
5 if notbuilds(u)then
6 E(B)←E(B)- (u,τ2)∪(u,τ1)
7 if notbuilds(u)then
8 E(B)←E(B)- (u,τ1)∪(u,τ)
Figure 5: Given an underutilized target τ, Reﬁner
generates a patch for each dependent of τthat does
not need to depend on both constituents of τ.
that programmers will add in future can depend only on the
neededconstituenttargetsinsteadofthewholeunderutili zed
target. Such ﬁner-grained dependencies reduce the overall
build time and size of binaries.
Although decomposing an underutilized target brings sev-
eral advantages, it does not unleash the full beneﬁts of a
decomposition. This is because the existing dependents of
the underutilized target continue to depend on all of its con -
stituent targets. To gain the most from decomposing an
underutilized target, one has to change the existing depen-
dents of the target to depend on only the needed constituent
targets. This change is a refactoring because it just makes
the build-time dependencies ﬁner-grained and does not af-
fect the behavior of any program. We call this refactoring
dependency reﬁnement .
If the underutilized target has many dependents, the de-
pendencyreﬁnementwill becometime-consumingtodoman-
ually. Thus, we developed a tool called Refiner to auto-
mate this refactoring. Given an underutilized target, Re-
finerautomaticallyandsafelygeneratesapatchthatreﬁnes
the dependencies of the dependents of the underutilized tar -
get to only the needed constituents.
Figure 5 lists the pseudocode of Refiner .Refiner ex-
amines every dependent uof the given underutilized target
τ(line 1). Let τ1andτ2be the constituents of τsuch that τ2
does not depend on τ1. First,Refiner removes the depen-
dency of uonτ(line 2). If ucontinues to build successfully,
this suggests that the dependency on uwas unneeded. Oth-
erwise,Refiner ﬁrst tries a dependency on τ2(line 4) and
thenτ1(line 6). If ucannot be built successfully with a de-
pendency on either τ1orτ2, it means that uneeds both τ1
andτ2. In this case, Refiner adds back the dependency on
τ(line 8). While Decomposer proposes a change to a sin-
gle build ﬁle, Refiner often generates a patch that aﬀects
many build ﬁles.
Our prior work on enforcing direct dependencies [28] pre-
pares the foundation for applying Refiner . Previously, at
Google, targets did not have to declare their direct depen-
dencies on targets on which they transitively depended on.
For example, in Figure 1, target b1did not have to declare
a dependency on target l1(Figure 1a, line 5) even if b1de-
pended on a class declared by l1. Since b1depends on l1
transitively through l2,b1was not previously required to
declare its direct dependency on l1. A problem with mak-
ing the declaration of such direct dependencies optional is
that it forces a global reasoning for the safe removal of adependency such as the dependency of l2onl1. With miss-
ing direct dependencies, Refiner has to do an expensive,
global analysis to ensure that removing a dependency from
a target does not break any dependents of the target. Thus,
Refiner assumes that targets declare their direct dependen-
cies. Our prior work [28] presents the problems with missing
direct dependencies and our techniques to recover such de-
pendencies.
Dependingon the numberof dependentsof thetarget that
isbeingdecomposed, Refiner maytakeseveralhourstorun.
The bottleneck is in building all the dependents aﬀected by
the decomposition. We run all the tests that are aﬀected
by the patch that Refiner generates. If Refiner does not
cause new breakages, we submit the patch to be reviewed by
the programmers that own the build speciﬁcations aﬀected
by the patch. Depending on the number and availability of
the owners, the review process may take from several days
to weeks.
8. IMPLEMENTATION
Decomposer is a Java program that leverages several
internal Google services through Remote Procedure Calls.
It uses Google Protocol Buﬀers [47] to exchange data with
these services. Decomposer gets the ﬁle-level dependen-
cies of a target from a service. It uses these dependencies to
construct the cross references graph (e.g., Gl1in Figure 2)
and compute the dependencies of other targets on the ﬁles
of the target under analysis (e.g., dependency edges ( b1,f2),
(l2,f3), (l4,f9), and (t6,f10) in Figure 2). For target-level
dependencies, Decomposer uses an in-memory graph [16]
thattheCIsystemmaintainstocomputethetargets aﬀected
by a change. Decomposer queries a database that contains
the log data of the CI system to estimate the trigger savings
in terms of past test execution times. To make the imple-
mentation more reusable and extensible to open repositorie s
(e.g., the Maven Central Repository [46]), we employed the
Facade design pattern [14, pp. 185–193] to provide abstrac-
tions for the services that Decomposer relies on.
Weparallelized Decomposer usingFlumeJava[10]. Flume-
Java is a Java framework developed at Google for MapRe-
ducecomputations. Toparallelize Decomposer asaMapRe-
duce pipeline, we deﬁne a mapper that takes a target as
input and returns a decomposition as its output. Since the
target-level dependencygraphis large, Decomposer shipsa
compressedformofthegraphtothemappers. Finally, wede-
ﬁne areducerthat takes all the decompositions and outputs
them to a single ﬁle. When run in parallel mode, Decom-
poserdistributes the input list of targets among thousands
of FlumeJava mappers that run independently of each other
in Google’s data centers.
Refiner is a Python program that relies on the build
system, the target-level dependencies, and a headless tool
for rewriting build speciﬁcations.
9. EMPIRICAL RESULTS
We evaluated Decomposer to answer the following re-
search questions:
•RQ1:What percentage of targets can be decomposed?
•RQ2:How eﬀective are the decompositions that De-
composer suggests?
•RQ3:How eﬃcient is Decomposer ?
7Table 1: Statistics about the size of decomposable
targets and the beneﬁts of their decompositions as
estimated by Decomposer. “Trigger Time” of a tar-
get is the total execution time of the tests that a
change to the target triggers. “Saved Triggers” is
computed according to Deﬁnition 3. “Saved Trig-
gers Pct.” is the ratio of “Saved Triggers” over “De-
pendents”. “Saved Trigger Time” is the total test
execution time of the saved triggers. “Saved Trig-
ger Time Pct.” is the ratio of “Saved Trigger Time”
over “Trigger Time”. “Decomposer Exec. Time” is
the execution time of Decomposer itself.
Min Max Mean SD
Files 21,098 10 27
SCCs 2 903 9 22
Dependents 0674,992 2,062 24,234
Trigger Time
(mins)0127,860 845 5,978
Saved Triggers ( ∆)0396,360 276 6,245
Saved Triggers Pct.
(∆%)0 99 11 19
Saved Trigger Time
(mins)060,837 981,250
Saved Trigger Time
Pct.0 99 12 22
Decomposer Exec.
Time (mins)1 369 2 5
9.1 RQ1: What percentage of targets can be
decomposed?
We ranDecomposer on a random sample of targets at
Google comprising of 40,000 Java library targets. Decom-
poserreported that 19,994 (50%) of the analyzed targets
weredecomposable . A target is decomposable if and only if
its cross references graph has at least two SCCs. Decom-
poserfound that decomposable targets have on average ten
ﬁles, nine SCCs, and 2,062 dependents (Table 1).
9.2 RQ2: How effective are the decompositions
that Decomposer suggests?
We measure the eﬀectiveness of a decomposition by calcu-
lating the number (RQ2.1) and percentage (RQ2.2) of saved
triggers and the duration (RQ2.3) and percentage (RQ2.4) of
saved test execution time.
Tables 2–5 demonstrate the eﬀectiveness of Decomposer .
The ﬁrst column of each of these tables partitions the values
of a metric into multiple intervals. The second and third
columns report the number and percentage of the targets
that fall within each interval, respectively. The fourth an d
ﬁfth columnsare cumulativeversions ofthe secondand third
columns, respectively. The distributions consistently sh ow
that decomposing a small fraction of targets yields substan -
tial beneﬁts. Byestimatingthebeneﬁtsofdecomposingeach
target,Decomposer enables the programmers to focus on
the decompositions with the largest gains.
9.2.1 RQ2.1: How many triggers can Decomposer
save?
Decomposer estimates that the decompositions it sug-
gests for 26% of the decomposable targets (5,129 of 19,994)
would save at least one trigger. Moreover, it found that on
average decomposing a target saves 276 triggers (Table 1)Table 2: Distribution of the number of savedtriggers
Saved
Triggers Freq.Freq.
(%)Cum.
Freq.Cum.
Freq.
(%)
[900,∞)355 6.9355 6.9
[800,900) 290.6384 7.5
[700,800) 260.5410 8.0
[600,700) 360.7446 8.7
[500,600) 601.2506 9.9
[400,500) 721.457811.3
[300,400) 101 2.067913.2
[200,300) 184 3.686316.8
[100,200) 322 6.31,185 23.1
(0,100) 3,944 76.95,129100.0
Table 3: Distribution of the percentage of saved trig-
gers
Saved
Triggers
(%) Freq.Freq.
(%)Cum.
Freq.Cum.
Freq.
(%)
[90,100] 310.6 310.6
[80,90) 711.4102 2.0
[70,80) 124 2.4226 4.4
[60,70) 248 4.8474 9.2
[50,60) 53310.41,007 19.6
[40,50) 63212.31,639 32.0
[30,40) 61812.02,257 44.0
[20,30) 62912.32,886 56.3
[10,20) 70713.83,593 70.1
(0,10) 1,536 29.95,129100.0
per change to the target. Table 2 shows that decomposing
any one of 355 targets would save at least 900 triggers of the
target.
9.2.2 RQ2.2: What percentage of triggers can De-
composer save?
The decompositions suggested by Decomposer save 11%
of the triggers on average (Table 1). Table 3 shows that
decomposing any one of only 31 targets would save at least
90% of the triggers per change to the target.
9.2.3 RQ2.3: How much test execution time can De-
composer save?
Table 4: Distribution of saved trigger times
Saved
Trigger
Time
(min) Freq.Freq.
(%)Cum.
Freq.Cum.
Freq.
(%)
[60,∞)1,145 25.11,145 25.1
[30,60) 287 6.31,432 31.3
[10,30) 63313.92,065 45.2
[5,10) 442 9.72,507 54.9
[2,5) 64114.03,148 68.9
[1,2) 52111.43,669 80.3
(0,1) 90019.74,569100.0
8Table 5: Distribution of the percentage of saved trig-
ger time
Saved
Triggers
Time
(%) Freq.Freq.
(%)Cum.
Freq.Cum.
Freq.
(%)
[90,100] 621.4 621.4
[80,90) 871.9149 3.3
[70,80) 153 3.3302 6.6
[60,70) 246 5.454812.0
[50,60) 46210.11,010 22.1
[40,50) 60113.21,611 35.3
[30,40) 49210.82,103 46.0
[20,30) 448 9.82,551 55.8
[10,20) 53311.73,084 67.5
(0,10) 1,485 32.54,569100.0
The decompositions that Decomposer suggests save 98
minutes of the test execution time of a decomposable target
on average (Table 1). Decomposer estimates the execution
time of the saved test triggers by computing the average exe-
cution time of the saved test targets duringthe past day. Ta-
ble 4 indicates that decomposing any of 1,145 targets would
reduce the test execution time per change to the target by
at least an hour.
9.2.4 RQ2.4: What percentage of test execution time
can Decomposer save?
On average, a decomposition that Decomposer proposes
for a target would save 12% of the execution time of the
tests that are triggered by a change to the target (Table 1).
This number is close to the average percentage of triggers
that are saved by a decomposition (Section 9.2.2). This is
not surprising because saving more triggers tends to save
more test execution time. Table 5 indicates that the decom-
positions proposed by Decomposer for 1,010 decomposable
targets would save more than 50% of the test execution time
of each of these targets.
9.3 RQ3: How efﬁcient is Decomposer?
On average, Decomposer analyzes a target in two min-
utes (Table 1). This implies that if we had run Decom-
poseronthe40,000targetssequentially, itwouldhavetaken
it more than 55 days to ﬁnish. Decomposer analyzes all
thesetargetsinparallel overnight. Table6showstheavera ge
breakdown of the execution time of each phase of Decom-
poser. The table shows that the most expensive phases of
the algorithm are computing the target-level dependencies
and the dependents of SCCs. The target-level dependencies
are represented as a large directed graph. Each edge of this
graph indicates a dependency of a target on another target.
Deserializing this graph from the ﬁle system is expensive.
Computing the dependents of SCCs is expensive for targets
with many dependents.
10. RELATED WORK
Despite the recent move of the software industry to CI [5,
20,23,32,33], there has been little research on CI. The rest of
this section overviews several empirical studies, code sme ll
detection and refactoring tools for build speciﬁcations an dTable 6: The ratio of the duration of each phase of
Decomposer over the execution time of Decomposer
averaged over all of the 40,000 analyzed targets.
Phase Duration Pct.
Constructing the cross references graph 4
Computing the SCCs 0
Computing the target-level dependencies 66
Computing the dependents of SCCs 30
Unifying SCCs 0
discusses ourworkwithrespecttosoftware remodularizati on
and regression testing.
Empirical Studies McIntosh et al.[25] studied the version
histories of ten projects and found that build maintenance
accountsfor upto27%overheadonsourcecode development
and 44% overhead on test development. In addition, they
found that the churn rate of build ﬁles is close to that of
source ﬁles. Inanotherstudyofsixopen-sourceprojects [2 4],
McIntosh et al.found that the size of build ﬁles and source
ﬁles are highly correlated. In short, these studies show tha t
build maintenance incurs signiﬁcant engineering cost. Thi s
cost calls for tool support for evolving build speciﬁcation s.
Underutilized Targets Build Analyzer is an interactive
commercial tool for optimizing the build time of C/C ++
code [37]. It allows programmers to identify fat headers ,
the header ﬁles that are build bottlenecks, and decompose
them into two smaller header ﬁles. Little has been reported
about the decomposition algorithm and empirical evalua-
tion of Build Analyzer. Although Build Analyzer refactors
header ﬁles and not build speciﬁcations, fat headers and un-
derutilized targets are related code smells.
In our prior work [28], we discussed several code smells
speciﬁc to build speciﬁcations, including under-declared de-
pendencies, zombie targets, and visibility debt. We intro-
duced a tool called Clipper that takes a binary target as
input and ranks the libraries in the transitive closure of th e
dependencies of the binary by their utilization rates, i.e. , the
percentage of the symbols of the library that are used by the
binary. Clipperhelpsprogrammersﬁndthelibraries thatar e
bringing too many unneededsymbols to the binary. Clipper,
Decomposer , andRefiner are complementary tools. Pro-
grammers can use Clipper to ﬁnd underutilized targets and
then use Decomposer andRefiner to decompose them.
Software Remodularization Remodularization is decom-
posingacodebasethatisalmostmonolithicintomodules[50 ].
Researchers have developed tools for remodularizing legac y
software. These tools employ clustering [4,22,39,51], sea rch-
based [7,27,31], or information retrieval [21] techniques to
ﬁnd a set of modules that optimizes some metrics. These
metrics are usually inspired by properties such as high cohe -
sion and low coupling [1,8]. While existingremodularizati on
tools target legacy software with poor modularity, our tool s
are intended for modern software that is relatively modular
but can beneﬁt from ﬁner-grained modules.
Analyzing, Visualizing, and Refactoring Makeﬁles
MAKAO [2] is a tool that visualizes Makeﬁles by analyz-
ing their dynamic build traces. It also supports refactorin gs
such as target creation. SYMake [36] is a static analysis too l
thatcandetectseveral codesmells ofMakeﬁlessuchascycli c
9dependencies and duplicate prerequisites and supports ref ac-
torings such as target creation and renaming. MkDiﬀ [3] is
a tool for visualizing the diﬀerences between two Makeﬁles.
While MAKAO and SYMake support basic refactorings of
Makeﬁles, neither can detect or refactor underutilized tar -
gets.
Test Selection The goal of test-selection techniques [15,17,
18,30,34,35,53] is toselect asubsetofthe tests ofone vers ion
of a program to run on a future version of the program
without compromising the fault-detection capability of th e
test suite.
Since we deﬁned the eﬀectiveness of a decomposition in
terms of the triggers that it saves (Deﬁnition 3), decompos-
ing underutilized targets can be viewed as a test-selection
technique. Target decomposition is a refactoring that make s
the test-selection technique of the CI system more eﬀective .
However, thebeneﬁts of decomposingtargets are notlimited
to test selection. Decomposing underutilized targets can r e-
duce build time, binary size, and improve the modularity of
code and the performance of IDEs (Section 3).
Our work makes several contributions to test-selection
techniques. First, while existing techniques perform sele c-
tion within a target, Decomposer takes both target-level
and ﬁle-level dependencies into account. Second, Decom-
poserandRefiner automate a refactoring that makes an
existing test-selection technique more eﬀective. Finally , we
show the impact of decomposition on the eﬀectiveness of an
existing target-level test-selection technique through a large-
scale empirical study at Google.
11. LIMITATIONS AND FUTURE WORK
Generalizability We evaluated Decomposer only on Java
targets at Google. Thus, the evaluation results may be dif-
ferent on other languages. Nonetheless, Decomposer and
Refiner are both language independent. In future, we plan
to adapt Decomposer andRefiner to software reposito-
ries outside Google, e.g., Maven Central Repository. Simi-
lar toGoogle build speciﬁcations, Maven buildspeciﬁcatio ns
declare dependencies between targets. Sometimes, Google
programmers manually decompose underutilized JAR ﬁles
built from open-source code. This anecdote indicates the
practical value of automated decomposition of open-source
targets.
Soundness Decomposer andRefiner are sound as long
asthetarget-levelandﬁle-leveldependencygraphsaresou nd.
Currently, the target-level dependencies miss the depende n-
cies on generated targets, and the ﬁle-level dependencies i n-
clude only the static dependencies. We leave more accurate
computation of the dependency graphs to future work.
Objective Function Decomposer usesthenumberofsaved
triggers as an objective function to ﬁnd a decomposition. In
future, we plan to experiment with diﬀerent objective func-
tions. Alternative objective functions can optimize the de -
composition to reduce the size of binaries. Such objective
functions should analyze the overlaps between the transiti ve
closures of the dependencies of each ﬁle of the target. In
addition, the objective function can be extended to take the
change rates of ﬁles into account. Files that rarely change
trigger few tests. Suppose that many dependents of an un-
derutilized target depend on only a small part of the target.
If the ﬁles in the small part change frequently, decomposing
the target to this small part and the rest of the target willsave more triggers. Finally, future research can explore th e
impact of code co-evolution on decomposition. For instance,
decomposing a target into two constituents that are often
aﬀected by the same changes will save few triggers.
Decomposition Algorithm Decomposer employsagreedy
algorithm to suggest a decomposition. This algorithm is fas t
and can suggest decompositions to an arbitrary number of
constituents. However, ﬁnding an approximation algorithm
with a provable guarantee of closeness to the optimal decom-
position or proving the lack of such an algorithm are open
problems. Future research can study alternative decomposi -
tion algorithms.
Composing Targets While this paper focuses on a refac-
toring to decompose targets, the reverse refactoring, i.e. ,
composing targets , is also a potentially useful refactoring.
While underutilized targets are problematic, too many smal l
targets may be undesirable, too. For instance, the overhead
of compiling several small targets separately can be higher
than compiling a single target that consists of all the ﬁles o f
the small targets. As another example, too many small tar-
gets may result in too many libraries whose hosting is expen-
sive. Future work can study such trade-oﬀs when composing
or decomposing targets.
Adoption So far, about a dozen programmers at Google
have used Decomposer . Our vision is to integrate Decom-
poserinto the programming workﬂow to gain a wider adop-
tion. Ideally, Decomposer would continuously monitor ev-
ery code change and suggest that programmers decompose a
target whenever the beneﬁt of the decomposition goes above
a certain threshold. A code review tool is a potentially good
medium to present the results of Decomposer to program-
mers.
12. CONCLUSIONS
Build speciﬁcations embody the dependency structure of
large-scale software. Build speciﬁcations are code, too. Like
any other code, build speciﬁcations accumulate code smells
as software evolves. This paper focuses on a speciﬁc code
smell of build speciﬁcations that we identiﬁed in Google’s
code base, namely, underutilized build targets . We present
a tool for large-scale identiﬁcation anddecomposition of un-
derutilized build targets. Our evaluation results show tha t
our tool is both eﬀective andeﬃcient at (1) estimating the
beneﬁts of decomposing build targets, and (2) proposing de-
compositions of build targets. Besides the promising resul ts
of our tool at Google, perhaps a broader contribution of our
work is highlighting a challenging problem that the softwar e
industry faces: improving the quality of build speciﬁcations
at scale.
Acknowledgments
The ﬁrst author was employed by Google while working
on this project. We thank Nicholas Chen, Munawar Haﬁz,
Ralph Johnson, Darko Marinov, Stas Negara, Tao Xie, and
the student participants of the software engineering semi-
nar at the University of Illinois at Urbana-Champaign for
their comments on a draft of this paper. We also thank Ed-
die Aftandilian, John Penix, Sanjay Bhansali, Kevin Bourri l-
lion, Robert Bowdidge, Dana Dahlstrom, Sebastian Elbaum,
Misha Gridnev, Jeremy Manson, John Micco, Ben St. John,
Jeﬀrey van Gogh, Collin Winter, and many others at Google
for their suggestions and engineering support.
1013. REFERENCES
[1] H. Abdeen, H. Sahraoui, O. Shata, N. Anquetil, and
S. Ducasse. Towards Automatically Improving Package
Structure while Respecting Original Design Decisions.
InProceedings of the 20th Working Conference on
Reverse Engineering (WCRE) , pages 212–221, 2013.
[2] B. Adams, H. Tromp, K. De Schutter, and
W. De Meuter. Design Recovery and Maintenance of
Build Systems. In Proceedings of the 23rd IEEE
International Conference on Software Maintenance
(ICSM), pages 114–123, 2007.
[3] J. M. Al-Kofahi, H. V. Nguyen, A. T. Nguyen, T. T.
Nguyen, and T. N. Nguyen. Detecting Semantic
Changes in Makeﬁle Build Code. In Proceedings of the
28th IEEE International Conference on Software
Maintenance (ICSM) , pages 150–159, 2012.
[4] N. Anquetil and T. C. Lethbridge. Experiments with
Clustering as a Software Remodularization Method. In
Proceedings of the 6th Working Conference on Reverse
Engineering (WCRE) , pages 235–255, 1999.
[5] C. AtLee, L. Blakk, J. O’Duinn, and A. Z. Gasparnian.
Firefox Release Engineering. In The Architecture of
Open Source Applications , volume 2. Lulu, 2012.
[6] M. Barnathan, G. Estren, and P. Lebeck-Jobe.
Building Software at Google Scale.
http://www.youtube.com/watch?v=2qv3fcXW1mg ,
2012.
[7] G. Bavota, F. Carnevale, A. D. Lucia, M. D. Penta,
and R. Oliveto. Putting the Developer in-the-Loop:
An Interactive GA for Software Re-modularization. In
Proceedings of the 4th International Symposium on
Search Based Software Engineering (SSBSE) , pages
75–89, 2012.
[8] G. Bavota, A. De Lucia, A. Marcus, and R. Oliveto.
Software Re-Modularization Based on Structural and
Semantic Metrics. In Proceedings of the 17th Working
Conference on Reverse Engineering (WCRE) , pages
195–204, 2010.
[9] M. Besta, Y. Miretskiy, and J. Cox. Build in the
Cloud: Distributing Build Outputs. [Blog post]
http://goo.gl/jaQTiF , 2011.
[10] C. Chambers, A. Raniwala, F. Perry, S. Adams, R. R.
Henry, R. Bradshaw, and N. Weizenbaum. FlumeJava:
Easy, Eﬃcient Data-Parallel Pipelines. In Proceedings
of the 2010 ACM SIGPLAN Conference on
Programming Language Design and Implementation
(PLDI), pages 363–375, 2010.
[11] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and
C. Stein. Elementary Graph Algorithms. In
Introduction to Algorithms . The MIT Press, 2009.
[12] P. M. Duvall, S. Matyas, and A. Glover. Continuous
Integration: Improving Software Quality and Reducing
Risk. Addison-Wesley, 2007.
[13] M. Fowler. Refactoring: Improving the Design of
Existing Code . Addison-Wesley, 1999.
[14] E. Gamma, R. Helm, R. Johnson, and J. Vlissides.
Design Patterns: Elements of Reusable
Object-Oriented Software . Addison-Wesley, 1995.
[15] T. L. Graves, M. J. Harrold, J.-M. Kim, A. Porter,
and G. Rothermel. An Empirical Study of Regression
Test Selection Techniques. ACM Transactions onSoftware Engineering and Methodology , 10:184–208,
2001.
[16] P. Gupta, M. Ivey, and J. Penix. Testing at the Speed
and Scale of Google, 2011. [Blog post]
http://goo.gl/dmOUMN .
[17] M. J. Harrold, J. A. Jones, T. Li, D. Liang, and
A. Gujarathi. Regression Test Selection for Java
Software. In Proceedings of the 2001 ACM SIGPLAN
Conference on Object-Oriented Programming, Systems,
Languages, and Applications (OOPSLA) , pages
312–326, 2001.
[18] M. J. Harrold and M. L. Souﬀa. An Incremental
Approach to Unit Testing during Maintenance. In
Proceedings of the Conference on Software
Maintenance (ICSM) , pages 362–367, 1988.
[19] C. H. P. Kim, D. Marinov, S. Khurshid, D. Batory,
S. Souto, P. Barros, and M. d’Amorim. SPLat:
Lightweight Dynamic Analysis for Reducing
Combinatorics in Testing Conﬁgurable Systems. In
Proceedings of the ACM SIGSOFT Symposium on
Foundations of Software Engineering (FSE) , pages
257–267, 2013.
[20] A. Kumar. Development at the Speed and Scale of
Google. QCon San Francisco, http://goo.gl/hCPQxZ ,
2010.
[21] J. I. Maletic and A. Marcus. Supporting Program
Comprehension Using Semantic and Structural
Information. In Proceedings of the 23rd International
Conference on Software Engineering (ICSE) , pages
103–112, 2001.
[22] O. Maqbool and H. Babri. Hierarchical Clustering for
Software Architecture Recovery. IEEE Transactions
on Software Engineering , pages 759–780, 2007.
[23] D. Marsh. From Code to Monkeys: Continuous
Delivery at Netﬂix. QCon San Francisco,
http://goo.gl/lQWQrY , 2013.
[24] S. McIntosh, B. Adams, and A. E. Hassan. The
Evolution of Java Build Systems. Empirical Software
Engineering , pages 578–608, 2012.
[25] S. McIntosh, B. Adams, T. H. Nguyen, Y. Kamei, and
A. E. Hassan. An Empirical Study of Build
Maintenance Eﬀort. In Proceedings of the 33rd
International Conference on Software Engineering
(ICSE), pages 141–150, 2011.
[26] J. Micco. Tools for Continuous Integration at Google
Scale.
http://www.youtube.com/watch?v=KH2_sB1A6lA ,
2012.
[27] B. S. Mitchell and S. Mancoridis. On the Automatic
Modularization of Software Systems Using the Bunch
Tool.IEEE Transactions on Software Engineering ,
pages 193–208, 2006.
[28] J. D. Morgenthaler, M. Gridnev, R. Sauciuc, and
S. Bhansali. Searching for Build Debt: Experiences
Managing Technical Debt at Google. In Proceedings of
the 3rd International Workshop on Managing
Technical Debt (MTD) , pages 1–6, 2012.
[29] W. F. Opdyke. Refactoring Object-Oriented
Frameworks . PhD thesis, University of Illinois at
Urbana-Champaign, 1992.
[30] A. Orso, N. Shi, and M. J. Harrold. Scaling Regression
Testing to Large Software Systems. In Proceedings of
11the ACM SIGSOFT International Symposium on
Foundations of Software Engineering (FSE) , pages
241–251, 2004.
[31] K. Praditwong, M. Harman, and X. Yao. Software
Module Clustering as a Multi-Objective Search
Problem. IEEE Transactions on Software Engineering ,
pages 264–282, 2011.
[32] C. Prasad and W. Schulte. Taking Control of Your
Engineering Tools. Computer , pages 63–66, 2013.
[33] C. Rossi. Release Engineering at Facebook. QCon San
Francisco, http://goo.gl/b5LY80 , 2012.
[34] G. Rothermel and M. J. Harrold. Analyzing
Regression Test Selection Techniques. IEEE
Transactions on Software Engineering , 22(8):529–551,
1996.
[35] G. Rothermel and M. J. Harrold. Empirical Studies of
a Safe Regression Test Selection Technique. IEEE
Transactions on Software Engineering , 24:401–419,
1998.
[36] A. Tamrawi, H. A. Nguyen, H. V. Nguyen, and T. N.
Nguyen. Build Code Analysis with Symbolic
Evaluation. In Proceedings of the 34th International
Conference on Software Engineering (ICSE) , pages
650–660, 2012.
[37] A. Telea and L. Voinea. A Tool for Optimizing the
Build Performance of Large Software Code Bases. In
Proceedings of the 12th European Conference on
Software Maintenance and Reengineering (CSMR) ,
pages 323–325, 2008.
[38] J. Thomas and A. Kumar. Google Engineering Tools.
[Blog post] http://goo.gl/zOpl1T , 2011.
[39] V. Tzerpos and R. C. Holt. ACCD: An Algorithm for
Comprehension-Driven Clustering. In Proceedings of
the 7th Working Conference on Reverse Engineering
(WCRE) , pages 258–267, 2000.
[40] Apache Ant. http://ant.apache.org/ .
[41] Apache Maven. http://maven.apache.org/ .
[42] GNU Make. http://www.gnu.org/software/make/ .
[43] Gradle. http://www.gradle.org/ .
[44] Hudson. http://hudson-ci.org/ .
[45] Jenkins. http://jenkins-ci.org/ .
[46] Maven Central Repository.
http://search.maven.org/ .
[47] Google Protocol Buﬀers: Google’s Data Interchange
Format. Documentation and open-source release
https://developers.google.com/protocol-buffers/ .
[48] Rake. http://rake.rubyforge.org/ .
[49] Travis. https://travis-ci.org/ .
[50] T. Wiggerts. Using Clustering Algorithms in Legacy
Systems Remodularization. In Proceedings of the 4th
Working Conference on Reverse Engineering (WCRE) ,
pages 33–43, 1997.
[51] J. Wu, A. E. Hassan, and R. C. Holt. Comparison of
Clustering Algorithms in the Context of Software
Evolution. In Proceedings of the 21st IEEE
International Conference on Software Maintenance
(ICSM), pages 525–535, 2005.
[52] N. York. Build in the Cloud: Accessing Source Code,
2011. [Blog post] http://goo.gl/H9WUGe .
[53] J. Zheng, B. Robinson, L. Williams, and K. Smiley.
Applying Regression Test Selection for COTS-basedApplications. In Proceedings of the 28th International
Conference on Software Engineering (ICSE) , pages
512–522, 2006.
12