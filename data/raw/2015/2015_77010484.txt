Automated Multi-objective Control
for Self-Adaptive Software Design
Antonio Filieri
University of Stuttgart
Stuttgart, Germany
Ô¨Ålieri@
informatik.uni-stuttgart.deHenry Hoffmann
University of Chicago
Chicago, USA
hankhoffmann@
cs.uchicago.eduMartina Maggio
Lund University
Lund, Sweden
martina@
control.lth.se
ABSTRACT
While software is becoming more complex everyday, the require-
ments on its behavior are not getting any easier to satisfy. An
application should o er a certain quality of service, adapt to the
current environmental conditions and withstand runtime variations
that were simply unpredictable during the design phase. To tackle
this complexity, control theory has been proposed as a technique
for managing software‚Äôs dynamic behavior, obviating the need for
human intervention. Control-theoretical solutions, however, are ei-
ther tailored for the speciÔ¨Åc application or do not handle the com-
plexity of multiple interacting components and multiple goals. In
this paper, we develop an automated control synthesis methodol-
ogy that takes, as input, the conÔ¨Ågurable software components (or
knobs) and the goals to be achieved. Our approach automatically
constructs a control system that manages the speciÔ¨Åed knobs and
guarantees the goals are met. These claims are backed up by exper-
imental studies on three di erent software applications, where we
show how the proposed automated approach handles the complex-
ity of multiple knobs and objectives.
Categories and Subject Descriptors
D.2.4 [ Software Engineering ]: Design‚Äî Methodologies ; I.6.5
[Computing Methodologies ]: Model Development‚Äî Modeling
methodologies
General Terms
Design, Experimentation, Theory, Performance, Reliability
Keywords
Adaptive software, control theory, dynamic systems, non-
functional requirements, run-time veriÔ¨Åcation.
1. INTRODUCTION
Self-adaptation is a Ô¨Årst-class property of modern software
systems. Adaptive software incorporates monitoring, decision-
making, and actuation to maintain reliable behavior despite sud-
den, unpredictable changes like application workload Ô¨Çuctuations
and hardware failures. Adaptive software detects such changes inthe operating environment, determines how to respond, and imple-
ments the response with an actuation phase. Many methodologies
have arisen for designing and implementing such adaptive orauto-
nomic software systems [1‚Äì3].
Dynamic, feedback driven adaptation has been studied in control
theory for decades, where rigorous engineering techniques adapt
physical systems while providing formal guarantees of their be-
havior; e.g., cruise control in an automobile [4]. Recent research
has applied control theory to adaptive software systems, ensuring
software behaves predictably in dynamic environments (for exam-
ples see the survey [5]). Control theoretic solutions are particu-
larly attractive for software systems with strict requirements in un-
predictable environments because control techniques permit formal
analysis of a system‚Äôs dynamic behavior.
The drawback of using control theory in software is that software
engineers must master both their application domains and control
systems. Indeed, using control theory requires (1) understanding
all the actuators , or software components that can be changed dur-
ing runtime, (2) developing a suitable mathematical model relating
these components to observable feedback, and (3) implementing a
control strategy based on the model and the desired behavior [6].
While the Ô¨Årst point is typically easy for the software developer,
the other two items require deep background in control science
and might be not applicable for all the software adaptation prob-
lems [6].
Recent work proposed addressing points (2) and (3) by fully au-
tomating the construction of a mathematical model and the syn-
thesis of a suitable controller for software systems, putting con-
trol techniques in the hands of non-experts [7]. That approach ad-
dresses systems having a single quantitative goal and a single actua-
tor. It produces a controller using two phases: learning andsynthe-
sis. The former conducts a systematic exploration of the actuator
and builds a mathematical model relating this actuator to measur-
able changes in the software. The synthesis phase uses the model to
construct a controller that is formally guaranteed to meet the goal,
if feasible. Additional enhancements make this approach robust in
the face of unpredictable external changes; e.g., , those in third-
party components or services. Despite the variety of problems that
can be tackled with this approach [7], its guarantees are limited to
only a single quantitative goal. Software systems requiring guaran-
tees in multiple dimensions ( e.g., energy and performance) cannot
make use of this approach.
Automatic synthesis of controllers for multiple goals is usually
challenging and requires human intervention. A general approach
handling multiple goals and multiple actuators has been proposed
[8]. To deal with conÔ¨Çicting goals, this approach uses a cascade
control schema where higher priority goals are pursued before
lower priority ones. This approach assumes perfect knowledge of
This is the author‚Äôs version of the work. It is posted here for your personal use. Not for
redistribution. The deÔ¨Ånitive version was published in the following publication:
ESEC/FSE‚Äô15 , August 30 ‚Äì September 4, 2015, Bergamo, Italy
c2015 ACM. 978-1-4503-3675-8/15/08...
http://dx.doi.org/10.1145/2786805.2786833
13the system at design time and requires continuous knobs to be dis-
cretized, possibly leading to an overwhelming number of control
actions. To Ô¨Ånd the best conÔ¨Åguration within a large search space,
an optimization problem is formulated, but the approach relies on
heuristic solutions to avoid scalability problems [8]. Recent work,
however, has shown that the e ectiveness of such heuristics is sys-
tem dependent; i.e.,they are not general and not portable across
systems [9].
We address this need to generalize support for multiple goals
by extending our previous automated framework to synthesize con-
trollers to manage requirements for multiple non-functional quanti-
tative properties simultaneously by synthesizing cascade controller
systems given a prioritization of the control goals. We address
shortcomings in prior work by handling both discrete and continu-
ous actuators and by Ô¨Ånding exact solutions to optimization prob-
lems that translate control signals into knob settings.
The methodology we propose assumes the software system is a
equipped with multiple actuators and is required to satisfy multi-
ple quantitative goals. Each actuator is associated with a control
knob (or control variable) that may a ect multiple quantitative di-
mensions at the same time. After an initial (possibly rough) dis-
cretization of continuous knobs, the controller dynamically reÔ¨Ånes
the discretization between relevant values to increase control ac-
curacy at runtime. No constraints are imposed on the actual (un-
known) relationship between knob and goal, which can be linear or
nonlinear.
Multiple actuators a ecting multiple dimensions create an expo-
nential explosion of possible software conÔ¨Ågurations, which might
limit the scalability of prior work. The key insight of our approach
is to overcome this explosion by exploiting the ranking of the non-
functional properties (or goals) under control to design an e cient
control allocation [4] where multiple controllers operate in cascade
on subsequently smaller decision spaces. To this end, we partition
the knobs depending on the goals they a ect and decide on each
partition separately, whenever possible. This can reduce the num-
ber of knobs conÔ¨Ågurations involved in each separate decision.
Furthermore, we replace the heuristic solution of the internal op-
timization problems with an exact solution based on the analysis
of the dual problem. This analysis allows to e ciently reduce the
number of conÔ¨Ågurations that has to be considered for Ô¨Ånding an
optimal solution by several orders of magnitude. For example, in a
radar processing case study (see Sec. 5.2) this analysis reduces the
possible number of actuator combinations to consider from over 2
million to just under 2 thousand ‚Äì three orders of magnitude reduc-
tion.
In the proposed approach, the controllers are dynamically syn-
thesized based on the control actions selected for higher-ranked
goals. The only requirement is that at least one problem dimen-
sion must be free;i.e.,it will be minimized (or maximized) without
any guarantees on its value.
Our methodology supports two ranking schemes. The Ô¨Årst is
user-deÔ¨Åned ‚Äî users explicitly deÔ¨Åne the priority of di erent
goals. This schema resembles the elicitation of primary (manda-
tory) requirements and secondary (desirable) requirements. If some
goals cannot be achieved, the controllers Ô¨Årst meet the highest
ranked one, and then the subsequents, coming as close as possible
on infeasible goals. The second scheme is an automatic ranking
where the control system orders the goals to maximize the number
which can be achieved. As in prior work [7], continuous learning
mechanisms are applied to keep the system model updated at run-
time and maintain guarantees despite possible changes.
The methodology in this paper greatly extends the generality of
prior approaches to automated control design, moving existing ef-fort much closer to the requirements necessary for deployment in a
real system with multiple constraints, all of which must be met de-
spite unpredictable and uncertain execution environments. At the
same time, the proposed approach requires no prior knowledge of
the software under control nor special mathematical skills, mak-
ing control theoretic solutions available to non-experts who must
guarantee multiple aspects of a programs behavior.
We implement the proposed methodology and obtain results in
three case studies. In the Ô¨Årst, we manage performance, security
and energy for encrypted communications on a mobile device. In
the second, we manage hardware resources and software conÔ¨Ågu-
ration to achieve accurate and timely target localization in a cyber-
physical radar system. In the third we design a dynamic binding
mechanism for a service-oriented system to guarantee reliability,
response time, and cost e ectiveness. These examples demonstrate
the broad applicability of our proposed automated methodology.
The rest of the paper is organized as follows. Section 2 dis-
cusses prior work. Section 3 presents some control background.
The proposed methodology is discussed in Section 4 and evaluated
in Section 5. Section 6 concludes the paper.
2. RELATED WORK
Many modern software systems are self-adaptive [10, 11]; i.e.,
they select at runtime the best conÔ¨Åguration to achieve speciÔ¨Åc non-
functional requirements like reliability or response time. There are
many examples, from compiler-based support for alternative im-
plementations [12‚Äì14] to the exploitation of dynamic knobs for
power and energy management [15‚Äì17]. Hardware architectures
can be dynamically adjusted to target execution speed and much
more [18‚Äì20]. In High Performance Computing it is common to
adapt a running application; e.g., tuning FFTs for graphics process-
ing units [21]. Considerable e ort has been devoted to MapReduce,
which exposes many conÔ¨Ågurable parameters [22‚Äì24].
Self-adaptive techniques are also prominent in industry. For ex-
ample, companies like IBM [25] developed the IBM Touchpoint
Simulator and the K42 Operating System [26]. Oracle produced
the Automatic Workload Repository [27] and Intel the RAS Tech-
nologies for Enterprise [28].
Formal methods are often used to build self-adaptive systems be-
cause of their ability of providing mathematical guarantees on both
the eectiveness and the dependability of the adaptation mecha-
nism [29]. Among those methods, control theory [6, 30‚Äì32] has
been recognized by the software engineering community as a solu-
tion to meet quality of service requirements despite unpredictable
changes in the execution environment. Several recent surveys cap-
ture the current state-of-the-art applying control-theory to software
applications [5, 33], as well as highlighting the main criticisms of
early approaches [3]. Examples control delays for web servers [34],
manage data centers [35], allocate resources [36‚Äì38], tune operat-
ing systems [39‚Äì41], minimize energy [42], and coordinate across
the system stack [43]. These strategies adapt tunable knobs that can
be identiÔ¨Åed either o ine or at runtime [44].
The use of control theory in software engineering, however, is
still in a preliminary stage. It is di cult to develop accurate con-
trol models for software because strong mathematical skills are
needed to deal with the complex non-linear dynamics of real sys-
tems [45, 46]. These di culties result in control strategies that
solve a particular problem and operate in particular conditions, but
do not generalize. This paper‚Äôs goal is to increase the generality
of control solutions by introducing a methodology that automati-
cally constructs control systems for software adaptation. The pro-
posed methodology requires little prior knowledge, instead adopt-
ing a ‚Äúpush-button‚Äù approach that maintains the formal guarantees
14oered by traditional control approaches, but requires little mathe-
matical background.
The Ô¨Årst general and automated solution was recently pro-
posed [7]. The solution was based on very simple qualitative
equation-based models. While complex and precise quality models
have been used in the past to enable design-time optimizations [47],
such complexity is a drawback for runtime adaptation, due to its
overhead [48]. Despite its generality with respect to problems and
environments, the solution proposed in [7] su ers from restrictions
and limitations. This methodology is, in fact, only applicable to
single-input single-output systems, where the application developer
must identify one single actuator to be changed and the methodol-
ogy guarantees only a single non-functional requirement; e.g., re-
sponse time. In this paper, we further generalize this previous work
to obtain an automated solution capable of dealing with multiple
objectives and actuators simultaneously.
3. BACKGROUND
This section connects software engineering and control theoretic
terminology to provide the necessary background for following the
methodology presented in Sec. 4.
Applying control theory requires (1) the ability to measure the
quantitative property under control and (2) some desired values for
these properties. These quantitative properties are referred to as the
goals of the system and are related to non-functional requirements
like energy consumption, response time, and reliability. For exam-
ple, the measured response time of a web server can be of 500ms,
while its desired value is below 1s. In this paper, we assume it is
possible to measure every objective that the control system should
Ô¨Åx and that the system developer assigned some desired values for
the quantities under control. The desired value, in control terms,
is called the setpoint . A software systems will have multiple non-
functional requirements, which we refer to as the dimensions of
software behavior, or simply dimensions for brevity. The current
measurement of the system status in a particular dimension is a
feedback signal .
Control also requires adjustable system components, called con-
trolknobs oractuators . These actuators should a ect the measured
quantitative properties and allow the system to reach the desired
setpoints. The software can have multiple knobs and multiple set-
points. However, the methodology proposed here requires the num-
ber of knobs to be greater than or equal to the number of dimensions
under control.
The controller chooses the knobs‚Äô settings to drive the feedback
signal to the goals, a process called setpoint tracking . If the con-
troller has to counteract external factors that could interfere with
behavior, it is doing disturbance rejection . If it has to act also in
presence of unreliable measurement, e.g., noisy feedback, this calls
forrobustness to inaccuracies.
These requirements for the control system can themselves be
mapped into speciÔ¨Åc quantiÔ¨Åable properties. SpeciÔ¨Åcally, stability
refers to convergence to an equilibrium ‚Äî with a well designed
controller, the setpoint. Also, one can decide how the system
reaches the equilibrium point. Overshooting means that the mea-
sured feedback may be higher than the goal for some time. Avoid-
ing overhsoots avoids penalties; e.g., violating user requirements
or service level agreements. The time required to reach the equi-
librium point is the settling time . The system can also be robust ,
in control theoretical terms, and converge to the setpoint despite
quantiÔ¨Åable errors in the control model.
It is obviously desirable to design a stable system that avoids
overshooting, has low settling time, and high robustness. The main
advantage of a control-theoretical approach is that these propertiesare formally guaranteed on the system‚Äôs model. Thus, it is possible
to determine when the system behaves as expected and, when it
does not, how it will converge and what the values of the measured
quantities will be.
4. METHODOLOGY
This section presents our methodology for controlling multiple
dimensions of software behavior using multiple actuators. We as-
sume no prior knowledge about the e ect of these actuators on the
system. We do assume that each knob has a nominal value, which
is the knob‚Äôs value when it is not used to control any dimension.
When all the knobs are set to their nominal value, the i-th dimen-
sion ditakes value bi.
The term conÔ¨Åguration denotes a speciÔ¨Åc set of values for the
available knobs. For example, given the set of knobs K=fk1;k2;k3g
a possible conÔ¨Åguration is fk1=3;k3=0g, where k2is not assigned
and can be set to any of its feasible values.
4.1 Control Strategy
We propose a generalized feedback control strategy to guarantee
the behavior of the software system in multiple dimensions. The
new approach builds on prior work that controlled performance,
power, and application accuracy [8] by (1) extending the control
strategy to any set of non-functional quantitative goals, (2) au-
tomating the controller‚Äôs design, (3) solving internal optimization
problems exactly, and (4) incorporating continuous control knobs.
Such multi-dimensional control is a di cult problem because
decisions made to adjust behavior in one dimension will likely af-
fect others. To overcome these complications we impose an order-
ing on dimensions of control. Given an ordering, our approach ap-
plies control based on rank, where higher-ranking dimensions are
controlled before lower-ranking ones. For example, if performance
is ranked highest, and energy is lower-ranked, the controller will
Ô¨Årst tune knobs to satisfy the performance goal, then determine a
set of knobs that a ect energy but not performance, and Ô¨Ånally tune
those knobs to meet the energy goal.
We support two di erent ordering schemes. The Ô¨Årst allows
user-speciÔ¨Åed priorities . A user may be concerned more about soft-
ware‚Äôs performance than its accuracy. Performance will be higher
ranked and the control strategy will adjust for performance Ô¨Årst, us-
ing any knob. Knobs which do not a ect performance are used to
control accuracy. The second ordering scheme supports feasibility .
In this scheme, the controller automatically ranks dimensions based
on available actuators to achieve as many goals as possible. For ex-
ample, if three of the ten available actuators are necessary to con-
strain the performance behavior and Ô¨Åve of them would be needed
to address accuracy goals, the controller chooses performance as a
primary dimension, to leave as many actuators as possible free to
control accuracy.
The ordering scheme, whether priority or feasibility based, is the
key insight to our approach. At runtime, the control strategy se-
lects the actuators in the order of dimension ranking. After apply-
ing the control values for one dimension, we estimate the e ects on
the subsequent dimensions, remove the already constrained knobs
from the pool of available ones and execute the controller to opti-
mize for the new dimension. Adapting the control strategy during
runtime, based on decisions made for higher-ranking dimensions,
allows us to account for the dependence between dimensions. The
estimation strategy bases the decision on actual data about how the
system is reacting to changes in the previously controlled dimen-
sions, adjusting prior knowledge about the mentioned dependence.
Figure 1 shows an example of the proposed feedback control
strategy managing two dimensions: accuracy and performance. In
15this example, the highest ranking dimension is accuracy; perfor-
mance is lower ranking. At runtime, our approach Ô¨Årst collects the
current goals ga(t) and gp(t) and feedback measurements fa(t) and
fp(t), in the accuracy ( a) and performance ( p) dimensions at time t.
‚ó¶Accuracy
ControllerAccuracy
Translatorga(t) ea(t) ua(t)
‚ó¶Performance
ControllerPerformance
Translatorgp(t) ep(t) up(t)Software
Systemka(t)
kp(t)fa(t)‚àí
fp(t)‚àí
Figure 1: Block diagram for controlling accuracy and perfor-
mance.
The controller then computes the errors in both dimensions, the
dierences between the goals and current values ea(t) and ep(t).
The control system produces ua(t), a signal indicating how to
change accuracy to compensate for the measured error. The con-
trol signal ua(t) is passed to a translator, which determines the set of
possible knobs values that achieves the desired accuracy and among
those, the ones that allow for optimal performance. The predicted
performance of this conÔ¨Åguration is used to modify a second con-
trol system that produces up(t), a signal that drives the performance
error ep(t) to zero. This signal is then translated to a disjoint set of
knobs that achieves up(t) with minimal interference on any other
dimension. At the next time step, feedback and goals are measured
and new control signals are calculated.
4.2 Controller Synthesis
This section presents a formal description of the proposed con-
troller. For clarity, we Ô¨Årst present an approach for goals in two
dimensions, and then extend it to handle more. This approach is
based on classical control synthesis techniques [4] but extends them
to handle a general set of problems with a general set of knobs. In
classical control synthesis, the knobs and the goals are known in
advance and the synthesis is carried out to Ô¨Ånd a suitable controller
for the speciÔ¨Åc case and the speciÔ¨Åc system model to be used. Our
approach, instead, focuses on achieving generality and tackles the
problem of having a set of knobs and goals to match.
The approach has Ô¨Åve phases. The Ô¨Årst selects the lead dimen-
sion. For user-speciÔ¨Åed priorities, this phase is skipped and user
priorities become input for the second phase. Subsequent phases
are the control of the lead dimension, its translation into knob
settings, the control of the subordinate dimension, and its trans-
lation. If more dimensions are added, the last two steps are re-
peated for each additional dimension. We Ô¨Årst focus on discrete (or
discretized) knobs and discuss the dynamic reÔ¨Ånement continuous
knob discretization later in this section.
4.2.1 Selecting the Lead Dimension
If the controller does not receive user-speciÔ¨Åed priorities, the
Ô¨Årst step is to select the lead dimension. Given a set of Ndi-
mensionsD=fd1;d2;:::dNg, the lead dimension is the one that
can be controlled using the fewest actuators. A set of mknobs
K=fk1;k2:::;kmgdoes not a ect dimension diif
8~c2C;di(~c)'bi; (1)whereC=fK1K 2K mg;Kawith a2f1:::mgthe domain
of the a-th knob, or the set of values that the a-th knob can as-
sume; di(~c) is the value of dimension didue to the e ect of the
conÔ¨Åguration ~c;biis a baseline measurement of dimension di. In
other words, for any possible combination of actuator values (the
Cartesian product of the set of admissible values for each knob),
the behavior is unchanged.
With two dimensions, we would like to Ô¨Ånd dlead, the primary
dimension, and dsub, the secondary one. We start by Ô¨Ånding the
setK1of knobs a ecting the Ô¨Årst dimension, d1and the setK2
aecting the second one, d2. From these two sets we select the lead
dimension as the one which is inÔ¨Çuenced by a smaller number of
knobs.
K1=fkjd1(~c),b1g (2)
K2=fkjd2(~c),b2g (3)
dlead =argmindijKij (4)
dsub =argmaxdijKij (5)
Eqns. 2 and 3 determine the set of knobs a ecting the goal dimen-
sions, while Eqn. 4 chooses the lead dimension as the set with mini-
mal cardinality. The remaining one is the secondary dimension. To
control the lead dimension, fewer actuators are used. This means
that more knobs are available for subsequent dimensions.
4.2.2 Controlling the Lead Dimension
Letglead(t) and flead(t) denote the goal and feedback in the lead
dimension at time t. Control for the lead dimension eliminates
the error elead(t)=glead(t) flead(t), by computing a control signal
ulead(t) based on its prediction of the next feedback measurement
flead(t+1):
flead(t+1)=bleadulead(t)+dist lead(t); (6)
where bleadis the baseline behavior in the lead dimension, i.e.,
its behavior with all the knobs conÔ¨Ågurations set to their nominal
value. dist lead(t) represents a transient disturbance. For example,
if the lead dimension is performance, bleadis the performance with
the software in its default conÔ¨Åguration. flead(t) represents the mea-
sured performance at time t.ulead(t) represents the speedup (over
baseline) the translator should achieve at time t, and dist lead(t) rep-
resents a momentary disruption in performance ( e.g., due to a page
fault).
Given elead(t), our methodology Ô¨Ånds ulead(t) using a deadbeat
controller, based on the model deÔ¨Åned by Eqn. 6. The approach
followed is the same as proposed in [7], using zero as value for the
pole, i.e.,imposing that the controller is as fast as possible in mak-
ing the measured value converge to its speciÔ¨Åed goal. The control
signal ulead(t) then becomes
ulead(t)=ulead(t 1)+elead(t)
blead: (7)
The disturbance dist lead(t) disappears from Eqn. 7. This is not
surprising, since dist lead(t) models any fast, transient change that is
not under control and a ects flead. The fast transient disturbances
cannot be controlled in any way, unless a precise model of their ac-
tion exists. When the disturbance does not immediately disappear,
its action is slowly included into the model via a change in the
baseline bleadthat is kept updated at runtime. Thus, a temporary
page fault receives no correction, but a sudden lack of memory that
persists for some time is compensated for, due the feedback signal
itself. For now, we assume to know how bivaries, for each dimen-
sion, during the execution of the application. This assumption will
be relaxed in Sec. 4.3.
164.2.3 Translating the Lead Dimension
Once the control signal ulead(t) is computed, it must also be ac-
tuated. To this end, we must select speciÔ¨Åc settings for the knobs
in the setKlead(Eqns. 2‚Äì5), to obtain the desired control signal.
To convert the continuous control signal into a conÔ¨Åguration for
the available knobs, our approach schedules conÔ¨Ågurations for a
window oftime units, with sucient for the next feedback sig-
nal to reÔ¨Çect the e ects of the schedule. The schedule is a list `lead
of couples ( ~cw;w), where cwrepresents a speciÔ¨Åc conÔ¨Åguration
andwdenotes a time to spend in that conÔ¨Åguration. The con-
Ô¨Ågurations in the list are sequentially applied until the end of the
window. ConÔ¨Ågurations are chosen so that the average behavior
over the time window is equal to the control signal and the e ect
of the schedule on the subordinate dimension is minimized. The
resulting optimization problem is:
optimize
`leadX
(~cw;w)2`leaddsub(~cw)w (8)
subject to
X
(~cw;w)2`leadw
dlead(~cw)
blead=ulead(t) (9)
X
(~cw;w)2`leadw= (10)
8(~cw;w)2`lead;@ki2~cw;ki<Klead (11)
Here, the word optimize stands for either minimize or maximize,
depending on the speciÔ¨Åc dimension. For example, optimizing
power consumption minimizes it, while optimizing reliability max-
imizes it. This formulation assures the subordinate dimension is
optimized (Eqn. 8), the control signal for the lead dimension is re-
alized (Eqn. 9), and the total time does not exceed the time before
the next feedback measurement (Eqn. 10). It also guarantees that
every conÔ¨Åguration included in the schedule uses only knobs be-
longing toKlead(Eqn. 11).
While mathematical optimization problems are, in general, ex-
pensive to solve, the particular structure of this problem lends it-
self to a cost-e ective solution. This problem has two non-trivial
constraints (Eqns. 9 and 10), and the other constraints conÔ¨Åne so-
lutions to have non-negative components. The geometric structure
of this problem implies that the optimal solution will have at most
two conÔ¨Ågurations in `lead,i.e.,only two of the coe cientswin
Eqn. 8 will be nonzero [49]. A simple solution that returns the true
optimal, then, would divide the set of Cleadof all possible conÔ¨Åg-
urations of the knobs in Klead(the Cartesian product of all sets of
potential values for the selected knobs) into two subsets:
Co=fc2Cleadjdlead(~c)ulead(t)g (12)
Cu=fc2Cleadjdlead(~c)ulead(t)g (13)
Eqn. 12 Ô¨Ånds the set of all the conÔ¨Ågurations that exceed ulead,
while Eqn. 13 selects the conÔ¨Ågurations that approach the desired
control signal from below. Given these two sets, we can search over
all pairs where one entry in the pair is drawn from Coand one entry
is drawn fromCu.
This algorithm is guaranteed to return an optimal solution to the
problem, but it executes in O(jC2j) time. This exhaustive search
can be straightforwardly parallelized ( e.g., in with a map-reduce
strategy). For very large conÔ¨Åguration spaces, it is possible to fur-
ther reduce the complexity by creating a table of buckets for each
dimension (essentially a hash table), where each bucket represents
a range of behavior in that dimension. We employ this approach for
largeC, conÔ¨Åning the search to the small number of conÔ¨Ågurationsthat map to the same bucket, requiring O(1) operations when the
table is large enough to avoid bucket collisions. Finally, an analy-
sis of the dual problem of the (mixed integer) linear optimization
in Eqns. 8‚Äì11 can lead to a dramatic reduction of the search space
by pruning out the conÔ¨Ågurations dominated by others toward the
identiÔ¨Åcation of the optimal point [50]. A deeper discussion of the
possible optimization strategies is beyond the scope of this paper.
Notably, state of the art optimization tools have a variety of them
built in and can be used o -the-shelf, provided the user knows how
to structure the problem.
The lead dimension is now controlled with a set of knobs that is
as small as possible, leaving the other knobs free for other dimen-
sions.
4.2.4 Controlling the Subordinate Dimension
Having selected ~coand~cu, the proposed approach calculates
ÀÜbsub(t), an estimate of how the choice for the lead dimension will
aect the subordinate one:
ÀÜbsub(t)=bsubdsub(~co)~co+dsub(~cu)~cu
(14)
We use Eqn. 14 and the integral-control-law to calculate a control
signal that eliminates the error esub(t)=gsub(t) fsub(t) in the sub-
ordinate dimension.
usub(t+1)=usub(t)+esub(t)
ÀÜbsub(t)(15)
The value of usub(t) is then passed to the translator to obtain the
remaining knob conÔ¨Åguration.
4.2.5 Translating the Subordinate Dimension
For stability, usub(t) must be translated into knob settings without
aecting the behavior of dlead. From Eqns. 2‚Äì5, we know the two
sets of knobsKleadandKsubaecting the lead and subordinate
dimensions. The controller then computes the set Kvalid aecting
only the subordinate one. If Kvalid is the empty set, the problem is
not feasible and the system reports that it is not possible to achieve
the subordinate dimension‚Äôs goal without compromising that of the
lead dimension.
Kvalid=(KnK lead)\K sub (16)
Letdf reebe the dimension for which there is no goal. Then the sig-
nalusub(t) is translated to knob conÔ¨Ågurations that optimize df ree
by computing a schedule `subof couples ( ~cs;s), solving the fol-
lowing optimization problem
optimize
`subX
(~cs;s)2`subdf ree(~cs)s (17)
subject to
X
(~cs;s)2`subs
subdsub(~cs)
bsub=usub(t) (18)
X
(~cs;s)2`subs=sub (19)
8(~cs;s)2`sub;@ki2~cs;ki<Kvalid (20)
wheresubrepresents the sampling time of the subordinate loop,
which can be di erent than the lead one. Eqn. 17 optimizes the free
dimension, Eqn. 18 ensures the control signal is realized, Eqn. 19
ensures the time window is respected, and Eqn. 20 ensures that
conÔ¨Ågurations come from Eqn. 16. This optimization problem is
solved using the same optimal algorithm as presented previously
for the lead dimension.
17Extension to More Dimensions: The process above can be extended
to an arbitrary set of dimensions. Instead of a lead and subordinate
dimension, the methodology ranks dimensions. The highest rank
dimension is equivalent to the lead dimension in the above. For
each subsequent dimension, the process described in the last two
steps is applied, substituting the set of all the used knobs Kleadin
Eqn. 16. This set is computed as the union of Kleadwith all the
already prescribed Ksub.
In the hash table implementation of the above, control for each
dimension takes O(1) time. Therefore, applying this process to
multiple dimensions takes O(N) time, where Nis the number of
dimensions under control.
Discretization reÔ¨Ånement The controller schema introduced in this
section identiÔ¨Åes a sequence of discrete conÔ¨Ågurations ~ciapprox-
imating the enforcement of a continuous reference uiprovided by
a deadbeat abstract controller. Whenever a continuous knob kcas-
sumes di erent values between two consecutive conÔ¨Ågurations in
the sequence, the transition between them is linearly smoothed over
one or more steps for the continuous knob kc, while the discrete
knobs follow the original plan.
In practice, assuming at time ithe plan requires a transition be-
tween the two conÔ¨Ågurations ~c:::iand~ci+1:::, a one step smooth-
ing of kcwould replace this step change with a subsequence
~c:::i 1;~ci;~ci+1:::, where the value of kcat time iiskic=(ki 1c+ki+1c)=2.
This reÔ¨Ånement explore a new conÔ¨Åguration for knob kc, smooth-
ing the discretization level.
This linear smoothing can be also extended over more steps.
However, since no assumptions have been made on the actual func-
tion that is being discretized, it is possible that the new values for
kcmake the control plan deviate from its expected behavior, e.g.,
in presence of a nonlinear behavior around those values. For this
reason, the length of the smoothed transition should be kept short
when nonlinear behaviors are expected. Nonetheless, the possible
deviations are only transitory for the current actuation steps, while
providing additional information for the next control decision.
To avoid an unnecessary growth of the discretized conÔ¨Åguration
space for control knobs, it is a good practice to introduce a max-
imum resolution threshold, such that smoothing is only enforced
when the di erence between two subsequent values of a continuous
knob kcis larger than such threshold. This threshold also bounds
the error incurred through discretization of continuous knobs.
4.3 Learning and Runtime Adaptation
We have assumed the values di(~c) for each dimension iand each
valid conÔ¨Åguration ~care known. However, in many cases these
values might be unknown or subject to runtime changes. In control
theory, updating the model parameters is called system identiÔ¨Åca-
tion. We review some existing techniques [4], and propose guide-
lines to Ô¨Ånd the best identiÔ¨Åcation method for a speciÔ¨Åc problem.
A naive solution applies only a statistical estimator to learn, and
update, each value di(~c) depending on ~c. Several such approaches
have been proposed both in control theory and in software engineer-
ing [51‚Äì53]. Despite its simplicity, this approach is realistic only
for small numbers of conÔ¨Ågurations because of the prohibitively
large number of samples needed to guarantee convergence [54].
Surrogate models approximate software behavior as a function
of knob conÔ¨Ågurations. Examples are radial basis function, spline
models, or Gaussian processes, such as the popular Kriging mod-
els [55‚Äì57]. These models may require fewer samples for a suitable
approximation the software behavior, but their increased computa-
tional complexity may reduce the reaction time of the controllers.
Whenever possible, a computationally e cient parametric
model is preferred. Such models deÔ¨Åne families of possible behav-iors; the objective of learning then reduces to Ô¨Ånding the best pa-
rameter assignment to describe the behavior of the system with re-
spect to each non-functional requirement dimension. Several para-
metric models are already used in software engineering, especially
to reason about reliability and performance, [48, 51, 58].
Furthermore, parametric models are usually easy to keep up-
dated with online tracking mechanisms such as Bayesian estima-
tion [52], Kalman Ô¨Åltering [51], or other techniques for statistical
learning [59]. This has a twofold beneÔ¨Åt: (1) the model tracks
changes in the system and (2) the quality of the estimates is contin-
uously improved while the system is running, overcoming possible
inaccuracies in the information collected during an initial learning
phase. In the third case study on quality-driven dynamic binding,
we Ô¨Åt and continuously update a parametric model based on incre-
mental estimation and quasi-Montecarlo sampling.
4.4 Discussion and Formal Assessment
Our methodology uses a control theoretic runtime decision en-
gine to adapt a running application in response to unpredictable
events. This control theoretic approach allows formal analytical
assessment. Such analysis is based on the assumption that soft-
ware behavior is bounded ;i.e.,an uncontrolled application cannot
continually increase or decrease its performance, power consump-
tion, or output accuracy. Bounded also implies that every situation
can be recovered. This is not always the case with control strat-
egy, where a signal could indeÔ¨Ånitively grow, therefore leading to
instability that cannot be addressed. Having bounded inputs and
outputs simpliÔ¨Åes the analysis and the formal assessment of the
system. We analyze here the properties mentioned in Sec. 3: sta-
bility, overshooting, and settling time.
Stability: To study the convergence of the system, the time-
based quantities can be converted to their frequency domain coun-
terparts using the Z-transform [4], a frequency domain representa-
tion of a discrete time control signal. In particular, to assess the sys-
tem stability, we consider the closed loop system Z-transform, and
determine if the poles of said Z-transform lie in the unit circle [4].
The controlled system is composed of multiple cascade loops (one
for each dimension under control). The Ô¨Årst closed loop system,
controlling the lead dimension, is stable by design. In fact, given
the controller synthesis method (we generate a deadbeat controller
‚Äì in control terms this means generating the controller that is less
robust to noise but brings the desired signals as close as possible to
their setpoints, as fast as possible [4]) its Z-transform is 1 =z, there-
fore there is only one pole, at zero. The analysis of the subsequent
subordinate loop is more complicated, since some of the signals
depend on previous loops, and are thus time-varying. In principle,
these loops should be analyzed as a switching system, where some
signals are rapidly changed from one value to another. However, it
is possible to make the simplifying assumption that the loops cor-
responding to the dimensions controlled beforehand ( i.e.,the lead
and the subsidiaries with higher priority) have already stabilized
to their goals. In this case, the analysis becomes straightforward,
since again the deadbeat nature of the control strategy guarantees a
closed loop Z-transform of 1 =z. [4] contains an exhaustive descrip-
tion of deadbeat controllers‚Äô stability properties.
To guarantee that the loops for higher-ranked dimensions are al-
ready stabilized, the time constant subthat appears in Eqn. 18
should be long enough. More precisely, sub2whereis the
one used in Eqn. 9. For each additional subordinate dimension, the
sampling time of the controller should be increased to twice the
value of the previous loop. This guarantees that the values set by
the previous loop have already settled to their regime values. The
control signal of such systems is seen as a disturbance from the
18subsequent ones in the chain. To guarantee the stability in face of
disturbance one could do a robustness analysis and verify what is
the maximum amount of change that the subordinate dimensions
could tolerate. The Z transform function of the closed loop, aug-
mented with the disturbance, has the same poles as the original one,
so the stability property is preserved whenever the goals are feasi-
ble. The augmented settling time is therefore a su cient condition.
In principle, it could be relaxed with a switching system analysis.
Such analysis, however, is system-dependent and unsuitable for an
automated control strategy. It is common in practice to select the
sampling period of each loop multiples of one another, so that the
sucient condition for system stability is fulÔ¨Ålled.
Overshoot: The deadbeat controller converges to the set point
without overshoot if the system operates under perfect informa-
tion. However, short overshoots are expected because of transient
disturbances that cannot be canceled without additional knowledge
on the system‚Äôs behavior; e.g., the eects of an outlier reported by
the monitors will be reduced by the integral action of the control,
though it may be too large to be fully compensated [4]. However,
the fast controller reaction (the Z-transform has only one pole, at
zero) guarantees overshoots are quickly acted upon and canceled
by the control strategy [4]. Indeed, the experimental results in the
following section show that the system can be found in overshoot
conditions, but they are promptly lowered by the controller action.
Settling Time: The settling time of the closed loop system is
by deÔ¨Ånition the settling time of the slowest loop in the system.
Assuming the sampling strategy indicated above is employed to
guarantee the system‚Äôs stability ( sub=2), the settling time of the
overall system is given by 2n 1, where nis the number of di-
mensions under control. Clearly, one can select to be as small as
possible, for faster convergence. However, the choice of is lim-
ited by the fact that the control action taken at time tshould have
a measurable e ect at time t+. This last assumption is unavoid-
ably application dependent. For example, changing the distribution
policy for a load balancer can be enforced in fraction of seconds,
while starting a virtual machine in the cloud may take a potentially
unpredictable time. has to be greater than the maximum actuation
time in the application, and may limit the applicability of the pro-
posed control approach when faster reactions are desired. Including
an online estimation procedure, also, may extend the time that the
system needs to settle, since the estimator settling time should also
be taken into account before correct information about the system
become available. For every loop, one should consider the time that
the corresponding estimation strategy takes to converge as part of
the total convergence time.
Optimality of the translation: The optimality of the translation
from the continuous reference value to a sequence of discrete
conÔ¨Ågurations is subject to several assumptions. If the knobs are
all discrete, the only way to guarantee the optimality of the trans-
lation is to know the e ects of every possible conÔ¨Åguration. The
exhaustive exploration of such (Ô¨Ånite) conÔ¨Åguration space is often
infeasible and replaced by a systematic or randomized exploration
of a smaller subspace (as described in Section 4.3). This introduces
an approximation of the optimal solution that should be taken into
account when implementing a speciÔ¨Åc application. This observa-
tion extends naturally to discretized continuous functions, where
the quality of the Ô¨Ånite discretization may not capture all possible
nonlinearities in the approximated continuous function. These lack
of information may lead to sub-optimal plans, though the stability
of the system is not compromised since only known conÔ¨Ågurations
will be enforced, whose e ect are known.
The problem of discrete knowledge can be overcame when an
analytical model of the system is available. In such case the op-timization problems can be straightforwardly restated taking into
account the actual function relating knobs to goals, however this
esulates from the scope of this paper.
The use of online learning techniques introduce additional uncer-
tainty. Indeed, until the estimators converged, the decisions might
be transitory biased. As side e ect, a conÔ¨Åguration might be not
enforced on the base of wrong knowledge, preventing the gather-
ing of additional information and in turn the slower convergence
of the estimators. The initial learning phase can be leveraged to
reduce this risk, while at runtime it is possible force the periodic
exploration of conÔ¨Ågurations that have not been visited for a while.
If a parametric model of the system is available, the goal of learning
and online updating moves to the estimation of unknown model pa-
rameters (see Sections 4.3). In such case the risk of outdated or not
converged estimates is compensated by the additional knowledge
of the model structure.
Knobs: Finally, besides the possible feasibility limitations due to
a bad prioritization schema discussed in Section 4.1, another lim-
itation of the proposed strategy is that the number of controlled
dimensions can never exceed the number of knobs available in the
system. Notice that the controlled dimensions do not include the
free one (or possibly more than one, if several dimensions can eval-
uated through a utility function) that is used for the optimization in
Eqn. 17.
5. EXPERIMENTAL EVALUATION
We present three case studies that evaluate our methodology
and its ability to automatically manage multiple quantitative non-
functional properties for a software system. In our Ô¨Årst study, we
create an adaptive encryption system for mobile communication.
In the second, we present a cyberphysical managing a radar infras-
tructure required to provide timely and accurate target localization.
The Ô¨Ånal study deals with an adaptive web infrastructure, which
balances load between di erent heterogeneous servers o ering the
same service. For each study, we describe the knobs used to control
the system, the dimensions managed, and the results of deploying
the adaptive software system to respond to dynamic events. The
secure mobile system responds to changes in user goals controlling
the encryption algorithm settings, the radar case manages both the
hardware and the application to achieve the target localization qual-
ity, and the load balancer operates at application level responding to
changes in server reliability, performance, and cost. The Ô¨Årst case
study has only discrete knobs, while the others both continuous and
discrete ones.
5.1 Secure Mobile Communication
Mobile systems are a natural match for our methodology. They
are limited by battery life, making energy is a primary concern.
Further, their applications are primarily interactive, so predictable
performance is essential. In this scenario, we add an additional
non-functional property: security, as users might want a certain
level of privacy for their communication. To accommodate such
users, we apply our methodology to create an adaptive system man-
aging performance, energy, and security on a mobile device using
the Advanced Encryption Standard (AES) [60] for privacy. AES
encodes 128 bit data blocks using keys of size 128, 192, or 256
bits. We create an adaptive encryption system which dynamically
selects the block size and processor frequency to manage perfor-
mance, energy, and security.
Controllable Dimensions:
Performance : 128 bit blocks encoded per second. We mea-
sure this directly from the application.
190 10 20 30 40 500.80.91.01.11.2
time [block]Performance
0 10 20 30 40 500.70.80.91.01.11.2
time [block]EnergyGoal Adaptive Software
0 10 20 30 40 50128160192224256
time [block]Average SecurityFigure 2: Secure Mobile Communication results: normalized performance and energy consumption, and average security over time.
Energy : joules per block. Energy is measured using the
hardware performance counter on our test platform.
Security : average key size over 1024 blocks. This value is
read directly from the application.
Knobs: We manage two di erent knobs for this adaptive soft-
ware application. The Ô¨Årst is based on the hardware and controls
the energy and performance tradeo . The second is based on the
AES application and controls the performance and security trade-
o. The mobile system is a Sony V AIO SVT11226CXB Tablet
with a dual core Intel Haswell processor. The processor supports
eleven clock speed settings, ranging from 600MHz to 1 :501GHz.
Each system conÔ¨Åguration shows di erent tradeo s between per-
formance and power consumption. Here, therefore, the clock speed
aects performance and energy simultaneously.
Our application is based on OpenAES [61]. It supports 3 key
sizes each with a di erent tradeo between security and perfor-
mance. The 256 bit key size is the most secure and slowest. The
192 bit key size increases performance by 18%, and the 128 bit
key size is40% faster.
Adapting to Changing Users Needs: We demonstrate how the
security application constructed with our methodology responds to
changing user goals. Fig. 2 shows the performance, energy, and
security for our adaptive application over time (where time is mea-
sured in the application progress, i.e.,encoded blocks). The perfor-
mance and energy are normalized to the default setting, i.e.,when
the actuators have their default values.
We show the system reacting to a change in user goals. This
change represents a shift from operating on wall power (where en-
ergy is not an issue) to battery power (where energy consumption
becomes paramount). Initially, the goal is to obtain real-time per-
formance (represented by 1 in the Ô¨Årst plot of Fig. 2) and maximum
security, which means using a key size of 256 bits). At time 30, we
switch from wall power to battery and set new goals: the applica-
tion should still maintain real-time performance but reduce energy
consumption to 80% of the default value, increasing battery life by
25%. The areas corresponding to the two di erent goals are marked
in the plot by a white background a striped pattern background. No-
tice that we are using two knobs to control two dimensions, while
optimizing in the third one.
The initial goals are highest security and real-time performance,
and they switch to the same performance with less energy con-
sumption. As shown in the Ô¨Ågure, the performance goal is main-
tained throughout the application‚Äôs execution ‚Äî with some minor
disturbances due to random system activity. When, at block 30,
the goals change, the control system makes energy consumption
immediately drop to the desired value. After a minor degradation,
performance quickly returns to real-time, by reducing security.5.2 Radar Signal Processing
Radar signal processing is another example application which
must balance the competing demands of multiple quantitative non-
functional properties, this time in a cyberphysical system. Signal
processing applications are composed of individual kernels, each
of which might support a tradeo between the computational com-
plexity of the kernel and the accuracy of the result. The accuracy of
the radar ( i.e.,its ability to detect targets in noise) will be a function
of the composition of the accuracy of these individual kernels. As
with our previous examples, energy consumption is a major con-
cern in many platforms. For example, in an autonomous vehicle,
the vehicle‚Äôs range will be determined by its energy consumption.
A Ô¨Åelded radar system will have goals in all of these dimensions:
performance ensures that targets are detected in time, accuracy en-
sures targets are detected in noise, and energy determines mission
lifetime. This case study demonstrates the methodology proposed
in this paper, but here accuracy /performance tradeo s are deter-
mined by a combination of continuous and discrete knobs.
Controllable Dimensions:
Performance : radar pulses processed per second. This value
is measured directly from the application.
Power : Watts per pulse. This is measured using a hardware
power meter available on our test platform.
Accuracy : Signal to noise ratio for detected targets. The
application reports these values.
Knobs: We use our methodology to control several di erent
knobs at both the system and application level. Our hardware plat-
form is a 32-core Intel Xeon E5-2690 processor running Linux
3.2.0. The processor supports hyper-threading and has 16 di erent
speeds including TurboBoost. We read total system power from
a WattsUp power meter. Like our prior example, there are three
system-level knobs that alter the performance and energy tradeo s.
The Ô¨Årst uses the cpufrequtils package to control clockspeed
(the highest setting actually turns control over to the hardware by
enabling TurboBoost). Higher clockspeeds increase performance
at the cost of increased power consumption. The second adaptation
uses thread a nity to reduce the number of cores actively perform-
ing computation. The processor supports power-gating, so reducing
core usage will reduce both power consumption and performance.
The Ô¨Ånal adaptation is to idle the processor to take advantage of
the low-power idle state. This adaptation supports racing to idle,
where the system attempts to complete work as quickly as possible
and maximize idle time. Idling will not increase power consump-
tion, but can decrease it for a decrease in performance. The total
number of system conÔ¨Ågurations is 512 (counting the use of idle
states, the number of conÔ¨Ågurations is e ectively inÔ¨Ånite).
200 10 20 30 400.050.070.09
time [radar pulses]Pulse Latency (s)
0 10 20 30 400.000.250.500.751.00
time [radar pulses]Normalized
Signal-to-Noise RatioProposed Approach Application Only System Only
0 10 20 30 4050150250
time [radar pulses]Power (Watts)Figure 3: Radar results: performance, energy consumption and accuracy over time.
We use an existing radar benchmark, which represents a generic
processing chain for a phased array sensor [62]. The radar supports
application-level tradeo s that can reduce signal to noise ratio (ac-
curacy) in exchange for increased performance. There are a number
of parameters a ecting the radar‚Äôs accuracy /performance tradeo s.
Two of these are discrete parameters: the strength of an initial low-
pass Ô¨Ålter, which has 16 settings, and the number of beams (number
of directions to search simultaneously), which can be set from 8 to
96, in multiples of 8. The third parameter is e ectively continuous.
It is the number of range bins (the resolution in distance from the
radar). This value can be anywhere from 1 to 9000. While it is
possible to model this as a discrete variable with 9000 settings, it is
impractical, so we treat it as a continuous variable.
The total number of possible conÔ¨Ågurations considering both ap-
plication and system is greater than 1 billion. It is simply impos-
sible to build empirical models of every possible combination of
knob settings. Thus, this case study further tests our methodol-
ogy‚Äôs ability to approximate the e ect control of one property will
have on another (learning is indeed limited to a grid sampling of 2
million conÔ¨Ågurations; at runtime, thanks to the analysis of the dual
optimization problem described in [50], the search space is reduced
to just 2 thousand, reducing the runtime computational overhead).
Adapting to Changing Mission Requirements: To demonstrate
the beneÔ¨Åt of our proposed approach, we consider an autonomous
vehicle in the Ô¨Åeld performing radar processing. During its mis-
sion, the vehicle gets a change in requirements. Initially, the system
was deployed with a latency and accuracy goal: it was to meet a tar-
get latency (1 =20th of a second per radar pulse) and maximize the
signal to noise ratio. Halfway through this mission, the vehicle re-
ceives a new set of goals: it must still maintain the same latency, but
now has to increase its mission lifetime (reducing power to 145 W).
To demonstrate the power of this paper‚Äôs proposed approach we
compare to two other approaches. The Ô¨Årst adapts only the appli-
cation. The second adapts only the system. We measure the per-
formance (as latency), power, and accuracy for each of these three
approaches. The results are shown in Fig. 3. The left chart shows
latency, the middle shows power, and the right shows accuracy. The
x-axis of each chart shows time measured in radar pulses.
The results demonstrate the power of our technique. The system-
level approach reduces power, but exceeds the target latency by al-
most 30%. The application-level approach meets the target latency
and power, but sacriÔ¨Åces accuracy (reducing signal to noise ratio to
just 50% of the default. The approach in this paper provides the best
outcome: it meets the latency and power goals, but when the mis-
sion changes it reduces signal to noise ratio to 75% of the default,
a considerable savings over the the application-level approach.5.3 Multi-objective Service Dynamic Binding
Our Ô¨Ånal example is the problem of multi-objective dynamic
binding in the context of Service Oriented Architecture (SOA). Dy-
namic binding Ô¨Çexibly assigns abstract service interfaces to con-
crete implementations, possibly provided by third parties and is one
of the principal means to adapt the behavior of SOAs [63]. In this
example, an abstract service interface can delegate an incoming re-
quest to one out of three third-party services. Although functionally
equivalent, each of the three services provides a distinct reliability
and performance depending on the paid service level agreement.
The measurable performance depends on the service level and ex-
ternal factors including the underlying communication and execu-
tion infrastructure and the workloads of the three services.
The controller selects which service should process any incom-
ing request and, for each service, the service level for each time
step. The controller is synthesized to achieve the desired reliability
and performance, while minimizing the cost due the selection of
higher service levels. We considered the problem of dynamic bind-
ing in previous work, controlling only a single objective with a sin-
gle knob [7, 64]. Here we provide a solution to the multi-objective
problem.
Controllable Dimensions:
Reliability : the probability of processing an request without
exceptions. We estimate this from the counts of forwarded
requests and thrown exceptions each time step.
Performance : average response time. The binder measures
its perceived end-to-end service time for each forwarded re-
quest and averages over a time step.
Cost : depending on the service level requested for the three
services. Each service reports this through an API.
Knobs: The controller can decide a service level from 1 to 5
for each of the three services and the distribution of the incom-
ing requests by setting two probabilities p1andp2. In particular,
the probability of selecting the Ô¨Årst service is p1, while the second
service has probability (1  p1)p2, and, consequently, the third
service is selected with probability (1  p1)(1 p2). The domain
of both p1andp2is continuous and incrementally discretized up
to a maximum resolution of 0 :01 (leading to at most 1 ;275;125
conÔ¨Ågurations to be potentially explored).
Each service si, has a measurable reliability ri, performance co-
ecient ti, and cost coe cient ci. Also, the controller can decide
a service level li. For every request, a fair coin is Ô¨Çipped in our
implementation, to decide whether it will raise an exception or not
according to pi; the response time for each request is sampled from
an exponential distribution with mean ti=(l2
i),i.e.,the time required
to process the request is an inverse quadratic function of the service
level; the cost of processing an incoming request is cili.
210100 300 420520 650 8000.000.250.500.751.00
time [seconds]Reliability
0100 300 420520 650 8000246810
time [seconds]PerformanceGoal Adaptive Software
0100 300 420520 650 80001020304050
time [seconds]CostFigure 4: Service Dynamic Binding results: reliability, performance and cost over time.
The nominal values ri,ti, and ciare not known by the controller,
which can only measure the time it takes to process a request it
forwards to si, how many of such requests are successful or failed,
and how much it cost to process each request. In order to quantify
the values dj(~c) needed to decide the control actions, the controller
undergoes an initial learning phase where the conÔ¨Åguration space
is explored to Ô¨Åt a parametric model of the system behavior. The
two problems to undertake are thus two: 1) what could be a suit-
able parametric model to Ô¨Åt and 2) how to sample the conÔ¨Åguration
space since its exhaustive exploration may be unpractical.
For the Ô¨Årst problem, by reasoning on the structure of the system
we can identify a simple polynomial parametric family of models to
describe the possible behaviors of the system: p1q1+(1 p1)(p2
q2+(1 p2)q3). The values of p1andp2are set by the controller
and therefore known, while qiis a placeholder for the estimators of
the values dj(jin {reliability, performance, cost}) when the service
operates at level li. Fitting this parametric model requires only 15
values to be estimated for each service (three dimensions times Ô¨Åve
service levels), for a total of 45 estimates.
The exploration of the conÔ¨Åguration space is performed in two
phases. In the Ô¨Årst phase the baseline conÔ¨Åguration is thoroughly
assessed. In the second phase a systematic exploration of the con-
Ô¨Åguration space is performed through a quasi-Montecarlo sampling
based on the Halton sequence, a low-discrepancy sequence with
demonstrated e ectiveness for multidimensional spaces [54] (the
exploration of the extreme values for each knob‚Äôs domain are man-
ually added to the sample set to span the learning over the full con-
trol domain). The use of the Halton sequence may increase the
convergence of the estimators for the qualities qiup to be linear in
the number of samples. In practice, with only 1000 samples rea-
sonably good initial estimates for dj(~c) have been achieved.
To overcome possible inaccuracy of the initial estimation and
to deal with changes of the services behavior during runtime, the
initial estimates are kept updated during the control phase; i.e.,at
each time step a new sample is pushed to the estimators and used
to continuously reÔ¨Åne the estimate. The estimator we use here has
been proposed in [65] and allows for the incremental estimation of
both the mean and the variance of each parameter qi. Each estima-
tor requires only three Ô¨Çoating point values to be stored and a few
arithmetic operations to update the estimate after each new sample.
Furthermore, given the variance of the parameters is estimated too,
a simple change point detection mechanism can be implemented
based on the frequency of outliers in the new samples ( e.g., those
lying further than ntimes the standard deviation away from the
mean). When such frequency gets too high, it is possible that the
system undergone an abrupt change which invalidates the current
model and requires a new learning phase [7, 59].The results of this experiment are reported in Fig. 4. The setting
for these experiment is: r1=:9,t1=2,c1=15,r2=:65,t2=10,
c2=10,r3=:45,t3=20, and c3=5. On the three plots the set-
point for the reliability (leading dimension) and the performance
(subsidiary) are represented by a dashed black line, while the ob-
tained quality is in a red continuous line. The initial learning phase
is marked with a striped pattern. The control starts from time 100
and achieves both the goals, though it takes some e ort to keep
performance to the setpoint given the required reliability. At time
300 the goal for reliability is reduced; both the goals are still fea-
sible but the performance can be achieved more smoothly. At time
420 the setpoint for reliability is changed to an infeasible goal; the
controller therefore approaches the goal, being as close as possi-
ble; performance is instead achievable. At time 520 the required
performance is stressed more; the goal is still achievable, though
at an higher cost ( i.e.,higher service levels are required). Finally,
at time 650 the goal for reliability is raised to a higher value; both
reliability and performance are achievable, though the cost is much
higher than before.
6. CONCLUSION AND FUTURE WORK
In this paper we proposed an automated control strategy to
achieve multiple objectives using the many knobs available in pro-
duction software systems. To take advantage of the formal guaran-
tees that the proposed methodology o ers, users need only identify
a set of knobs and the maximum timescale of all the knobs that
belong to the set ( e.g., the time it takes to change the processor
frequency). With this information, our methodology automatically
devises a control strategy, composed of multiple connected loops,
which guarantees, whenever feasible, all the chosen dimensions,
and optimizes the last free one. We have shown three case stud-
ies, introducing the features of our system in order of increasing
complexity. The Ô¨Åst case study assumes perfect knowledge of the
actions that can be taken on the system and all the involved di-
mensions, while more uncertainty is introduced in the following
two. In the last case study, we have shown how the system deals
with infeasible goals. This work advances the state-of-the-art on
automated control strategies for software systems, moving existing
eorts much closer to what is necessary in a real system.
7. ACKNOWLEDGMENTS
This work was partially supported by the Swedish Research
Council (VR) for the projects ‚ÄúCloud Control‚Äù and ‚ÄúPower and
temperature control for large-scale computing infrastructures‚Äù, and
through the LCCC Linnaeus and ELLIIT Excellence Centers.
Henry Ho mann is funded by the U.S. Government under the
DARPA PERFECT program, by the Dept. of Energy under DOE
DE-AC02-06CH11357, and by the NSF under CCF 1439156.
22References
[1] J. O. Kephart and D. M. Chess. ‚ÄúThe Vision of Autonomic
Computing‚Äù. In: Computer 36.1 (2003), pp. 41‚Äì50. doi:10.
1109/MC.2003.1160055 .
[2] R. Laddaga. ‚ÄúGuest Editor‚Äôs Introduction: Creating Robust
Software through Self-Adaptation‚Äù. In: IEEE Intelligent Sys-
tems 14 (3 1999), pp. 26‚Äì29. doi:10.1109/MIS.1999.
769879 .
[3] M. Salehie and L. Tahvildari. ‚ÄúSelf-adaptive Software:
Landscape and Research Challenges‚Äù. In: ACM Trans. Au-
ton. Adapt. Syst. 4.2 (2009), 14:1‚Äì14:42. doi:10 . 1145 /
1516533.1516538 .
[4] W. Levine. The control handbook . CRC Press, 2005.
[5] T. Patikirikorala, A Colman, J. Han, and L. Wang. ‚ÄúA sys-
tematic survey on the design of self-adaptive software sys-
tems using control engineering approaches‚Äù. In: SEAMS.
2012, pp. 33‚Äì42. doi:10.1109/SEAMS.2012.6224389 .
[6] A. Filieri, M. Maggio, K. Angelopoulos, N. D‚ÄôIppolito, I.
Gerostathopoulos, A. B. Hempel, H. Ho mann, P. Jamshidi,
E. Kalyvianaki, C. Klein, F. Krikava, S. Misailovic, A. V . Pa-
padopoulos, S. Ray, A. M. ShariÔ¨Çoo, S. Shevtsov, M. Ujma,
and T. V ogel. ‚ÄúSoftware Engineering Meets Control The-
ory‚Äù. In: SEAMS . IEEE, 2015.
[7] A. Filieri, H. Ho mann, and M. Maggio. ‚ÄúAutomated De-
sign of Self-adaptive Software with Control-theoretical For-
mal Guarantees‚Äù. In: ICSE. ACM, 2014, pp. 299‚Äì310. doi:
10.1145/2568225.2568272 .
[8] H. Ho mann. ‚ÄúCoAdapt: Predictable Behavior for
Accuracy-Aware Applications Running on Power-
Aware Systems‚Äù. In: ECRTS. IEEE CS, 2014. doi:
10.1109/ECRTS.2014.32 .
[9] C. Imes and H. Ho mann. ‚ÄúMinimizing energy under per-
formance constraints on embedded platforms: resource allo-
cation heuristics for homogeneous and single-ISA heteroge-
neous multi-cores‚Äù. In: SIGBED Review 11.4 (2014), pp. 49‚Äì
54.doi:10.1145/2724942.2724950 .
[10] J. Kramer and J. Magee. ‚ÄúSelf-Managed Systems: An Ar-
chitectural Challenge‚Äù. In: FOSE. IEEE CS, 2007, pp. 259‚Äì
268. doi:10.1109/FOSE.2007.19 .
[11] B. Cheng, R. de Lemos, H. Giese, P. Inverardi, J. Magee, J.
Andersson, B. Becker, N. Bencomo, Y . Brun, B. Cukic, G.
Di Marzo Serugendo, S. Dustdar, A. Finkelstein, C. Gacek,
K. Geihs, V . Grassi, G. Karsai, H. Kienle, J. Kramer, M.
Litoiu, S. Malek, R. Mirandola, H. M√Éijller, S. Park, M.
Shaw, M. Tichy, M. Tivoli, D. Weyns, and J. Whittle. ‚ÄúSoft-
ware Engineering for Self-Adaptive Systems: A Research
Roadmap‚Äù. In: Software Engineering for Self-Adaptive Sys-
tems. V ol. 5525. LNCS. Springer, 2009, pp. 1‚Äì26. doi:10.
1007/978-3-642-02161-9_1 .
[12] N. Thomas, G. Tanase, O. Tkachyshyn, J. Perdue, N. M.
Amato, and L. Rauchwerger. ‚ÄúA Framework for Adaptive
Algorithm Selection in STAPL‚Äù. In: PPoPP. ACM, 2005,
pp. 277‚Äì288. doi:10.1145/1065944.1065981 .
[13] J. Ansel, C. Chan, Y . L. Wong, M. Olszewski, Q. Zhao, A.
Edelman, and S. Amarasinghe. ‚ÄúPetaBricks: A Language
and Compiler for Algorithmic Choice‚Äù. In: PLDI. ACM,
2009, pp. 38‚Äì49. doi:10.1145/1542476.1542481 .
[14] T. Karcher and V . Pankratius. ‚ÄúRun-time Automatic Perfor-
mance Tuning for Multicore Applications‚Äù. In: Euro-Par.
Springer-Verlag, 2011, pp. 3‚Äì14. doi:10.1007/978- 3-
642-23400-2_2 .
[15] H. Ho mann, S. Sidiroglou, M. Carbin, S. Misailovic, A.
Agarwal, and M. Rinard. ‚ÄúDynamic Knobs for Respon-sive Power-aware Computing‚Äù. In: ASPLOS. ACM, 2011,
pp. 199‚Äì212. doi:10.1145/1950365.1950390 .
[16] W. Baek and T. M. Chilimbi. ‚ÄúGreen: A Framework for Sup-
porting Energy-conscious Programming Using Controlled
Approximation‚Äù. In: PLDI. ACM, 2010, pp. 198‚Äì209. doi:
10.1145/1806596.1806620 .
[17] J. Sorber, A. Kostadinov, M. Garber, M. Brennan, M. D.
Corner, and E. D. Berger. ‚ÄúEon: A Language and Runtime
System for Perpetual Systems‚Äù. In: SenSys. ACM, 2007,
pp. 161‚Äì174. doi:10.1145/1322263.1322279 .
[18] M. A. Suleman, O. Mutlu, M. K. Qureshi, and Y . N. Patt.
‚ÄúAccelerating Critical Section Execution with Asymmet-
ric Multi-core Architectures‚Äù. In: ASPLOS. ACM, 2009,
pp. 253‚Äì264. doi:10.1145/1508244.1508274 .
[19] R. Bitirgen, E. Ipek, and J. F. Martinez. ‚ÄúCoordinated Man-
agement of Multiple Interacting Resources in Chip Multi-
processors: A Machine Learning Approach‚Äù. In: MICRO.
IEEE CS, 2008, pp. 318‚Äì329. doi:10.1109/MICRO.2008.
4771801 .
[20] E. Ipek, M. Kirman, N. Kirman, and J. F. Martinez. ‚ÄúCore
Fusion: Accommodating Software Diversity in Chip Multi-
processors‚Äù. In: ISCA. ACM, 2007, pp. 186‚Äì197. doi:10.
1145/1250662.1250686 .
[21] Y . Dotsenko, S. S. Baghsorkhi, B. Lloyd, and N. K. Govin-
daraju. ‚ÄúAuto-tuning of Fast Fourier Transform on Graph-
ics Processors‚Äù. In: PPoPP. ACM, 2011, pp. 257‚Äì266. doi:
10.1145/1941553.1941589 .
[22] J. Dean and S. Ghemawat. ‚ÄúMapReduce: SimpliÔ¨Åed Data
Processing on Large Clusters‚Äù. In: Commun. ACM 51.1
(2008), pp. 107‚Äì113. doi:10.1145/1327452.1327492 .
[23] N. B. Rizvandi, J. Taheri, and A. Y . Zomaya. ‚ÄúOn Using Pat-
tern Matching Algorithms in MapReduce Applications‚Äù. In:
ISPA. IEEE CS, 2011, pp. 75‚Äì80. doi:10 . 1109 / ISPA .
2011.24 .
[24] S. Babu. ‚ÄúTowards Automatic Optimization of MapReduce
Programs‚Äù. In: SoCC. ACM, 2010, pp. 137‚Äì142. doi:10.
1145/1807128.1807150 .
[25] IBM Inc. IBM Autonomic Computing website .http : / /
www.research.ibm.com/autonomic/ . 2009.
[26] O. Krieger, M. Auslander, B. Rosenburg, R. W. Wis-
niewski, J. Xenidis, D. Da Silva, M. Ostrowski, J. Ap-
pavoo, M. Butrico, M. Mergen, A. Waterland, and V . Uh-
lig. ‚ÄúK42: Building a Complete Operating System‚Äù. In: Eu-
roSys. ACM, 2006, pp. 133‚Äì145. doi:10.1145/1217935.
1217949 .
[27] Oracle Corp. Automatic Workload Repository (AWR) in Or-
acle Database 10g .http://www.oracle- base.com/
articles / 10g / AutomaticWorkloadRepository10g .
php.
[28] Intel Inc. Reliability, Availability, and Serviceability for the
Always-on Enterprise .www . intel . com / assets / pdf /
whitepaper/ras.pdf . 2005.
[29] D. Weyns, M. U. Iftikhar, D. G. de la Iglesia, and T. Ahmad.
‚ÄúA Survey of Formal Methods in Self-adaptive Systems‚Äù.
In: C3S2E. 2012, pp. 67‚Äì79. doi:10 . 1145 / 2347583 .
2347592 .
[30] Y . Diao, J. L. Hellerstein, S. Parekh, R. Gri th, G. Kaiser,
and D. Phung. ‚ÄúSelf-Managing Systems: A Control Theory
Foundation‚Äù. In: ECBS. IEEE CS, 2005, pp. 441‚Äì448. doi:
10.1109/ECBS.2005.60 .
[31] J. L. Hellerstein, Y . Diao, S. Parekh, and D. M. Tilbury.
Feedback Control of Computing Systems . John Wiley &
Sons, 2004.
23[32] A. Filieri, C. Ghezzi, A. Leva, and M. Maggio. ‚ÄúSelf-
adaptive Software Meets Control Theory: A Preliminary
Approach Supporting Reliability Requirements‚Äù. In: ASE.
IEEE CS, 2011, pp. 283‚Äì292. doi:10.1109/ASE.2011.
6100064 .
[33] E. Yuan, N. Esfahani, and S. Malek. ‚ÄúA Systematic Survey
of Self-Protecting Software Systems‚Äù. In: ACM Trans. Au-
ton. Adapt. Syst. 8.4 (2014), 17:1‚Äì17:41. doi:10 . 1145 /
2555611 .
[34] C. Lu, Y . Lu, T. F. Abdelzaher, J. A. Stankovic, and S. H.
Son. ‚ÄúFeedback Control Architecture and Design Methodol-
ogy for Service Delay Guarantees in Web Servers‚Äù. In: IEEE
Trans. Parallel Distrib. Syst. 17.9 (2006), pp. 1014‚Äì1027.
doi:10.1109/TPDS.2006.123 .
[35] X. Dutreilh, A. Moreau, J. Malenfant, N. Rivierre, and I.
Truck. ‚ÄúFrom Data Center Resource Allocation to Control
Theory and Back‚Äù. In: CLOUD. IEEE CS, 2010, pp. 410‚Äì
417. doi:10.1109/CLOUD.2010.55 .
[36] D. Kusic and N. Kandasamy. ‚ÄúRisk-aware Limited Looka-
head Control for Dynamic Resource Provisioning in En-
terprise Computing Systems‚Äù. In: Cluster Computing 10.4
(2007), pp. 395‚Äì408. doi:10.1007/s10586-007-0022-y .
[37] H. Ho mann, M. Maggio, M. D. Santambrogio, A. Leva,
and A. Agarwal. ‚ÄúA Generalized Software Framework for
Accurate and E cient Management of Performance Goals‚Äù.
In: EMSOFT. IEEE Press, 2013, 19:1‚Äì19:10. doi:10.1109/
EMSOFT.2013.6658597 .
[38] C. Imes, D. H. K. Kim, M. Maggio, and H. Ho mann.
‚ÄúPOET: a portable approach to minimizing energy under soft
real-time constraints‚Äù. In: RTAS . 2015.
[39] S. Oberth√ºr, C. B√∂ke, and B. Griese. ‚ÄúDynamic Online Re-
conÔ¨Åguration for Customizable and Self-optimizing Operat-
ing Systems‚Äù. In: EMSOFT. ACM, 2005, pp. 335‚Äì338. doi:
10.1145/1086228.1086288 .
[40] C. Karamanolis, M. Karlsson, and X. Zhu. ‚ÄúDesigning Con-
trollable Computer Systems‚Äù. In: HOTOS. USENIX Asso-
ciation, 2005, pp. 9‚Äì15.
[41] M. Maggio, H. Ho mann, M. Santambrogio, A Agarwal,
and A Leva. ‚ÄúControlling software applications via resource
allocation within the heartbeats framework‚Äù. In: CDC. IEEE,
2010, pp. 3736‚Äì3741. doi:10.1109/CDC.2010.5717893 .
[42] M. Maggio, H. Ho mann, M. Santambrogio, A. Agarwal,
and A. Leva. ‚ÄúPower Optimization in Embedded Systems via
Feedback Control of Resource Allocation‚Äù. In: IEEE Trans.
Control Syst. Technol. 21.1 (2013), pp. 239‚Äì246. doi:10.
1109/TCST.2011.2177499 .
[43] H. Ho mann, J. Holt, G. Kurian, E. Lau, M. Maggio, J. E.
Miller, S. M. Neuman, M. Sinangil, Y . Sinangil, A. Agar-
wal, A. P. Chandrakasan, and S. Devadas. ‚ÄúSelf-aware Com-
puting in the Angstrom Processor‚Äù. In: DAC. ACM, 2012,
pp. 259‚Äì264. doi:10.1145/2228360.2228409 .
[44] M. Harman, Y . Jia, W. B. Langdon, J. Petke, I. H.
Moghadam, S. Yoo, and F. Wu. ‚ÄúGenetic Improvement for
Adaptive Software Engineering (Keynote)‚Äù. In: SEAMS.
ACM, 2014, pp. 1‚Äì4. doi:10.1145/2593929.2600116 .
[45] R. C. Dorf. Modern Control Systems . 7th. Addison-Wesley
Longman Publishing Co., Inc., 1995.
[46] X. Zhu, M. Uysal, Z. Wang, S. Singhal, A. Merchant, P.
Padala, and K. Shin. ‚ÄúWhat Does Control Theory Bring
to Systems Research?‚Äù In: SIGOPS Oper. Syst. Rev. 43.1
(2009), pp. 62‚Äì69. doi:10.1145/1496909.1496922 .[47] A. Aleti, B. Buhnova, L. Grunske, A. Koziolek, and I. Mee-
deniya. ‚ÄúSoftware Architecture Optimization Methods: A
Systematic Literature Review‚Äù. In: IEEE Trans. Softw. Eng.
39.5 (2013), pp. 658‚Äì683. doi:10.1109/TSE.2012.64 .
[48] A. Filieri, C. Ghezzi, and G. Tamburrelli. ‚ÄúRun-time E -
cient Probabilistic Model Checking‚Äù. In: ICSE. ACM, 2011,
pp. 341‚Äì350. doi:10.1145/1985793.1985840 .
[49] S. Bradley, A. Hax, and T. Magnanti. Applied mathematical
programming . Addison-Wesley Pub. Co., 1977.
[50] D. H. Kim and H. Ho mann. Racing and Pacing to Idle:
Minimizing Energy Under Performance Constraints . Tech.
rep. TR-2014-10. University of Chicago, 2014.
[51] T. Zheng, M. Woodside, and M. Litoiu. ‚ÄúPerformance Model
Estimation and Tracking Using Optimal Filters‚Äù. In: IEEE
Trans. Softw. Eng. 34.3 (2008), pp. 391‚Äì406. doi:10.1109/
TSE.2008.30 .
[52] A. Filieri, C. Ghezzi, and G. Tamburrelli. ‚ÄúA formal ap-
proach to adaptive software: continuous assurance of non-
functional requirements‚Äù. In: Formal Aspects of Computing
24.2 (2012), pp. 163‚Äì186. doi:10.1007/s00165- 011-
0207-2 .
[53] R. Calinescu, Y . RaÔ¨Åq, K. Johnson, and M. E. Bakir. ‚ÄúAdap-
tive Model Learning for Continual VeriÔ¨Åcation of Non-
functional Properties‚Äù. In: ICPE. ACM, 2014, pp. 87‚Äì98.
doi:10.1145/2568088.2568094 .
[54] C. Robert and G. Casella. Monte Carlo Statistical Methods .
Springer Texts in Statistics. Springer-Verlag, 2010.
[55] S. Russell and P. Norvig. ArtiÔ¨Åcial Intelligence: A Modern
Approach . Prentice Hall series in artiÔ¨Åcial intelligence. Pren-
tice Hall, 2010.
[56] S. Marsland. Machine Learning: An Algorithmic Perspec-
tive. Taylor & Francis, 2011.
[57] M. Zakerifar, W. Biles, and G. Evans. ‚ÄúKriging metamod-
eling in multi-objective simulation optimization‚Äù. In: WSC.
IEEE, 2009, pp. 2115‚Äì2122. doi:10 . 1109 / WSC . 2009 .
5429645 .
[58] A Filieri and C. Ghezzi. ‚ÄúFurther steps towards e cient run-
time veriÔ¨Åcation: Handling probabilistic cost models‚Äù. In:
FormSERA. 2012, pp. 2‚Äì8. doi:10 . 1109 / FormSERA .
2012.6229785 .
[59] A. Filieri, L. Grunske, and A. Leva. ‚ÄúLightweight Adaptive
Filtering for E cient Learning and Updating of Probabilistic
Models‚Äù. In: ICSE . IEEE, 2015.
[60] F. P. Miller, A. F. Vandome, and J. McBrewster. Advanced
Encryption Standard . Alpha Press, 2009.
[61] OpenAES .http://code.google.com/p/openaes .
[62] H. Ho mann, A. Agarwal, and S. Devadas. ‚ÄúSelecting Spa-
tiotemporal Patterns for Development of Parallel Applica-
tions‚Äù. In: IEEE Trans. Parallel Distrib. Syst. 23.10 (2012),
pp. 1970‚Äì1982. doi:10.1109/TPDS.2011.298 .
[63] E. Di Nitto, C. Ghezzi, A. Metzger, M. Papazoglou, and K.
Pohl. ‚ÄúA journey to highly dynamic, self-adaptive service-
based applications‚Äù. In: Automated Software Engineering
15.3-4 (2008), pp. 313‚Äì341. doi:10.1007/s10515-008-
0032-x .
[64] A Filieri, C. Ghezzi, A Leva, and M. Maggio. ‚ÄúReliability-
driven dynamic binding via feedback control‚Äù. In: SEAMS .
2012, pp. 43‚Äì52. doi:10.1109/SEAMS.2012.6224390 .
[65] D. Knuth. The Art of Computer Programming: Seminumeri-
cal algorithms . v. 2. Addison-Wesley, 1997.
24