Mining Apps for Abnormal Usage of Sensitive Data
Vitalii Avdiienko|, Konstantin Kuznetsov|, Alessandra Gorla, Andreas Zeller|,
Steven Arzty, Siegfried Rasthofery, and Eric Boddenyz
|Saarland UniversityIMDEA Software InstituteyTU DarmstadtzFraunhofer SIT
Saarbr Â¨ucken, Germany Madrid, Spain Darmstadt, Germany Darmstadt, Germany
Abstract â€”What is it that makes an app malicious? One
important factor is that malicious apps treat sensitive data
differently from benign apps. To capture such differences, we
mined 2,866 benign Android applications for their data ï¬‚ow from
sensitive sources, and compare these ï¬‚ows against those found
in malicious apps. We ï¬nd that (a) for every sensitive source,
the data ends up in a small number of typical sinks; (b) these
sinks differ considerably between benign and malicious apps;
(c) these differences can be used to ï¬‚ag malicious apps due to
their abnormal data ï¬‚ow; and (d) malicious apps can be identiï¬ed
by their abnormal data ï¬‚ow alone, without requiring known
malware samples. In our evaluation, our MUDFLOW prototype
correctly identiï¬ed 86.4% of all novel malware, and 90.1% of
novel malware leaking sensitive data.
I. I NTRODUCTION
Most existing malware detectors work retrospectively,
checking an unknown app against features and patterns known
to be malicious. Such patterns can either be given explicitly
(â€œText messages must only be sent after userâ€™s consentâ€), or
induced implicitly from samples of known malware (â€œThis app
contains code known to be part of the TDSS trojan.â€). If a novel
app is sufï¬ciently different from known malware, though, this
retrospective detection can fail.
In this work, we thus conversely investigate the idea that,
given access to a sufï¬ciently large set of â€œbenignâ€ apps, one
might be able to detect novel malware not by its similarity
with respect to existing malware, but rather through its dis-
similarity with respect to those benign applications. Checking
for dissimilarity is different from checking for similarity,
though, because in terms of functionality or code fragments,
we already have lots of dissimilarity across benign applica-
tions themselves. As a measure for establishing similarity or
dissimilarity with respect to the norm, we thus explore the
usage of sensitive data in an app. Speciï¬cally, we apply static
taint analysis on the 2,866 most popular Android apps from
the Google Play Store to determine, for every sensitive data
source, the sensitive APIs to which this data ï¬‚ows. We consider
these ï¬‚ows to constitute the â€œnormalâ€ usage of sensitive data;
as we assume the most popular Google Play Store apps to be
benign, these ï¬‚ows also resemble â€œbenignâ€ usage.
As an example of such ï¬‚ows, consider the well known
Android Twitter app. Table I shows its extracted data ï¬‚ows.
We can see that, while the Twitter app accesses sensitive
account information, it uses this information only to manage
synchronization across multiple devices. Network information
is being accessed (as part of the main functionality of the app),
saved in logs, and passed on to other components.TABLE I
FLOWS IN ANDROID TWITTER APP
AccountManager.get() ;ContentResolver.setSyncAutomatically()
AccountManager.get() ;AccountManager.addOnAccountsUL()
AccountManager.get() ;Activity.setResult()
AccountManager.get() ;Log.w()
AccountManager.getAccountsByType() ;ContentResolver.setSyncAutomatically()
AccountManager.getAccountsByType() ;Activity.setResult()
AccountManager.getAccountsByType() ;Log.w()
Uri.getQueryParameter() ;Activity.startActivity()
Uri.getQueryParameter() ;Activity.setResult()
Uri.getQueryParameter() ;Activity.startActivityForResult()
Uri.getQueryParameter() ;Log.w()
SQLiteDatabase.query() ;Log.d()
SQLiteOpenHelper.getReadableDatabase() ;Log.d()
SQLiteOpenHelper.getWritableDatabase() ;Log.d()
TABLE II
FLOWS IN COM .KEJI.DANTI 604 MALWARE
TelephonyManager.getSubscriberId() ;URL.openConnection()
TelephonyManager.getDeviceId() ;URL.openConnection()
In contrast, consider the com.keji.danti604 malware from
the VirusShare database [28]. Table II shows the two ï¬‚ows in
that application; they leak the subscriber and device ID to a
Web server. Both these ï¬‚ows are very uncommon for benign
applications; furthermore, danti604 does not contain any of
the ï¬‚ows that would normally come with apps that use the
TelephonyManager for legitimate reasons. Thus, danti604 is
an anomalyâ€”not only because it may be similar to known
malware, but in particular because its data ï¬‚ows are dissimilar
to ï¬‚ows found in benignware such as Twitter.
We have built a tool called MUDFLOW1which leverages
the FLOWDROID [3] static analysis tool to determine such
ï¬‚ows for all sensitive Android sources. MUDFLOW implements
multiple classiï¬ers, trained on the data ï¬‚ow of benign apps, to
automatically ï¬‚ag apps with suspicious features. To the best
of our knowledge, MUDFLOW is the ï¬rst approach to massively
mine application collections for patterns of â€œnormalâ€ data ï¬‚ow,
and to use these mined patterns to detect malicious behavior.
The remainder of this paper is organized as follows. After
introducing data ï¬‚ow and taint analysis in Section II, this paper
presents the following contributions:
1) We present MUDFLOW , an approach to mine, compare, and
classify the data ï¬‚ow in large sets of Android applications
(Section III).
2) We apply MUDFLOW to the 2,866 most popular apps
collected from the Google Play Store (Section IV). For
each signiï¬cant sensitive data source, we summarize
1MUDFLOW = Mining Unusual Data Flowthetypical usage of this source across these apps, and
contrast it against the usage found in a collection of
15,338 malware apps.
3) We use the data-ï¬‚ow differences to automatically identify
malware based on its ï¬‚ow of sensitive data (Section V).
In particular, we train a model using data ï¬‚ows of benign
apps only, and use it to detect novel malware even if no
earlier malware samples are known.
Our experiments show that dissimilarity with benign apps,
determined through data ï¬‚ow from sensitive sources, can be a
signiï¬cant factor in characterizing malware. In our experiment
on a set of 10,552 malicious apps leaking sensitive data,
MUDFLOW recognized 90.1% of the malware as such, with
a false positive rate of 18.7%, which is remarkable given that
MUDFLOW is not trained on malware samples.
After discussing threats to validity (Section VI) and relating
to existing work (Section VII), we close with conclusion and
future work (Section VIII).
II. D ATA FLOW AND TAINT ANALYSIS IN ANDROID
When installing an Android application, a user only sees
a textual description of the alleged behavior of the app and
a list of required permissions that the app needs in order to
work. An app may, for instance, require access to the list of
contacts on the mobile device but, unless clearly stated in the
description, it is vague how the app is using this data. A benign
messaging application may need to access the contact list to
send messages, while a malicious application may collect the
list of contacts and send them to a third-party server that
gathers them for spamming. To detect this kind of behavior,
one can use taint analysis, which is a particular instance of
data ï¬‚ow analysis . In essence, given a source of information
(e.g., the SQLite database containing the list of contacts) and
a sink (e.g., an HTTP connection to a third party server), taint
analysis can tell whether that information can ï¬‚ow to the
undesired sink.
Information ï¬‚ow can be analyzed statically, i.e., the analysis
would report whether there exist some paths in the program
that may lead to this information ï¬‚ow, or dynamically, i.e.,
by reporting information ï¬‚ows that actually occur during a
speciï¬c execution. In the ï¬rst case, the analysis might report
false positives, i.e., information ï¬‚ows that are not feasible in
practice. In the second case, the analysis would likely miss
information ï¬‚ows, namely if those ï¬‚ows occur in part of the
behavior that was not observed.
Both static and dynamic data and information ï¬‚ow analysis
techniques have been used to analyze Android applications,
since several malicious applications use this platform to collect
sensitive information of users. In fact, compared to the list of
requested permissions, information ï¬‚ows can better describe
the behavior of an Android application, as they can show how
the application is using a speciï¬c piece of information.
Data and information ï¬‚ow analysis has been used to detect
typical spyware behavior such as collecting sensitive infor-
mation and sending it to third-party servers. However, ï¬‚ows
of sensitive data are quite present in benign applications aswell. The sole fact that an app has speciï¬c ï¬‚ows does not
necessarily mean that the app is malicious.
A. Static Taint Analysis with FLOWDROID
Internally, MUDFLOW uses the static taint tracking tool
FLOWDROID [3] to identify data ï¬‚ows in Android applications.
We chose FLOWDROID because of its precise analysis and
because it accurately models the lifecycle of Android applica-
tions and their interactions with the operating system. Unlike
normal Java programs, Android apps are tightly coupled with
their execution framework which can, for instance, pause and
resume them at any time. Callbacks notify the application of
system events, such as a low battery level or an incoming text
message. FLOWDROID ï¬rst analyzes the apps for all registered
event handlers and components, and then creates dummy code
that simulates these interactions with the operating system,
causing the static analysis to take this possible runtime be-
havior correctly into account. FLOWDROID provides a highly
precise taint analysis that is fully object-, ï¬‚ow-, and context-
sensitive. High precision is required to reduce false positives
during data ï¬‚ow analysis; it also reduces the amount of noise
within the input data on which the machine-learning approach
ofMUDFLOW is later trained.
Listing 1 shows an example of how an Android application
can obtain leaked data. The example reads the phoneâ€™s unique
identiï¬er and sends it to the example telephone number
â€œ+1 234â€ using an SMS message. In real-world applications,
the path between source (the call to getDeviceId() and sink (the
call to sendTextMessage() can be substantially longer, and may
include ï¬eld and array accesses, polymorphic (library) method
calls, conditionals, etc.
FLOWDROID uses an instantiation of the IFDS framework by
Reps and Horwitz [24]. IFDS reduces data ï¬‚ow problems to
reachability in a graph whose nodes represent combinations
of possible facts about the program (e.g., â€œvariable devId is
tainted at line xin ï¬lefâ€). If one fact can be derived from
another, the respective nodes are connected with an edge,
causing the latter to be reachable from the former. If a certain
fact at a sink is reachable from the node modeling a source,
the analysis has discovered a leak from this source to this sink.
In the example in Listing 1, the node for variable devId
at Line 4 forms the root of the graph. It is connected to
the node that models â€œ ais taintedâ€ at Line 5 due to normal
1 void onCreate() f
2 TelephonyManager mgr = (TelephonyManager)
3 this.getSystemService(TELEPHONY SERVICE);
4 String devId = mgr.getDeviceId();
5 String a = devId;
6 String str = preï¬x(a);
7 SmsManager sms = SmsManager.getDefault();
8 sms.sendTextMessage(â€+1 234â€, null, str, null,null);
9g
10 String preï¬x(String s) f
11 return â€DeviceId: â€ + s;
12 g
Listing 1. Android Data Leak Exampleforward propagation. When processing a method invocation,
the algorithm creates an edge into the callee, in the example
causing the node representing â€œ sis taintedâ€ in Line 11 to
become reachable. On method returns, the return values are
mapped back into the caller, creating an edge to â€œ stris
taintedâ€ in Line 8. The analysis then recognizes this line as
a sink. The fact that parameter â€œ stris taintedâ€ is transitively
reachable from the source, means that there exists a leak of
the device id. The context-sensitivity of FLOWDROID makes it
possible to distinguish different calls to the preï¬x() method
with different parameter values. A context-insensitive analysis
would act conservatively, marking as tainted all program
variables capturing the return value of preï¬x() , even at those
call sites that call preï¬x() with benign values.
FLOWDROID uses special hand-written summaries for calls
to library methods for which no source code is available. Nu-
merous optimizations make sure that the taint analysis scales
to large apps such as the popular social network applications
in the Google Play Store. Space limitations preclude us from
explaining these optimizations further. We kindly point the
interested reader to the original FLOWDROID paper [3].
B. Sensitive Sources
MUDFLOW leverages static taint analysis with FLOWDROID
tocharacterize the behavior of individual apps with respect to
their usage of sensitive data. The key idea is to identify data
ï¬‚ows that originate from sensitive sources. We ï¬rst describe
our concept of a â€œsensitive sourceâ€, followed by how we
characterize the originating ï¬‚ows.
In Android, all sensitive data can be accessed
through speciï¬c APIsâ€”for instance, the Android method
getLastKnownLocation() returns the userâ€™s current location.
By tracing where this data ï¬‚ows to, it is possible to
characterize the appâ€™s behavior. For this, though, we need to
identify the APIs that access sensitive data. This is less easy
than it might seem, because several Android APIs are not or
hardly documented; furthermore, lists crafted by researchers
get outdated with every new Android version.
We therefore leverage the SUSI technique by Rasthofer et
al. [23], which automatically classiï¬es all methods in the
whole Android APIas a source, sink, or neither, using a small
hand-annotated fraction of an Android APIto train a classiï¬er.
Beside providing a list of APIs that access sensitive sources,
SUSI also provides a categorization of these APIs, listed in
Table III. The method getLastKnownLocation() , for instance,
falls into the LOCATION INFORMATION category.
In addition to the originally published SUSI categories,
we created three new categories to further break down the
behavior of Android apps, marked with (*) in Table III.
Sensitive Resources. During our investigation, we found that
Android apps also access sensitive resources through
content providers â€”external components that resolve
appropriate resource identiï¬ers; a CalendarContract
provider, for instance, can access calendar data. All these
ï¬‚ows start from the android.content.ContentResolver API,
which gets the desired resource identiï¬er as an argument.TABLE III
SUSI API CATEGORIES OF SENSITIVE SOURCES AND SINKS
Sources
HARDWARE INFO
UNIQUE IDENTIFIER
LOCATION INFORMATION
NETWORK INFORMATION
ACCOUNT INFORMATION
EMAIL INFORMATION
FILE INFORMATION
BLUETOOTH INFORMATION
VOIP INFORMATION
DATABASE INFORMATION
PHONE INFORMATION
CONTENT RESOLVER (*)
NO SENSITIVE SOURCE (*)
(*) New category, see textSinks
PHONE CONNECTION
VOIP
PHONE STATE
EMAIL
BLUETOOTH
ACCOUNT SETTINGS
VIDEO
SYNCHRONIZATION DATA
NETWORK
EMAIL SETTINGS
FILE
LOG
INTENT (*)
NO SENSITIVE SINK (*)Shared
AUDIO
SMS MMS
CONTACT INFORMATION
CALENDAR INFORMATION
SYSTEM SETTINGS
IMAGE
BROWSER INFORMATION
NFC
SUSI assigns the ContentResolver APItoNO CATEGORY
because the same APIcan be used to access all sorts of
resources, sensitive or non-sensitive. In 2012, however,
Au et al. [4] published a list of sensitive resource schemes
as used in Android. We therefore conducted an additional
step of static analysis: Using SOOT [16], we extracted
android.net.URI usages from all Android applications and
assigned them to the appropriate SUSI source categories.
Any resource usage not in the list would be classiï¬ed into
theCONTENT RESOLVER sensitive source category.
Intents. We found that several ï¬‚ows end in communication
between multiple app components (â€œIntentâ€ in Android
parlance). As of now, the precise identiï¬cation of ac-
tivities launched by intents, as well as identiï¬cation of
ï¬‚ows across intents is out of scope for this paper; our
main objective, namely classiï¬cation of malware, is still
fulï¬lled despite this imprecision. To mark ï¬‚ows into
intents, we introduced a special category INTENT for this
kind of potentially sensitive sink.
Non-sensitive Sources and Sinks. Almost all applications in
the Google Play Store access sensitive sources. However,
the data accessed does not necessarily end up in a sensi-
tive sinkâ€”wallpaper apps, for instance, access the userâ€™s
images as sensitive sources, but the userâ€™s display is not
a sensitive sink. To leverage these accesses, every source
used that does not ï¬‚ow into a sensitive sink is modeled
as a ï¬‚ow from that source â€œtoâ€ the special category NO -
SENSITIVE SINK. Similarly, we modeled ï¬‚ow that does
not start from sensitive source and ends up in a sensitive
sink from the special category NO SENSITIVE SOURCE .
III. M INING AND CLASSIFYING FLOWS
A. Extracting Flows
Applied on a single app,MUDFLOW uses FLOWDROID to
extract all data ï¬‚ows from all sensitive data sources toall
sensitive data sinks. The result is a set of pairs that char-
acterizes the sensitive ï¬‚ows in the applicationâ€”and thus the
application itself:
Flows (app) =
source 1;sink 1;source 2;sink 2;:::	
where each source iand sink iis a sensitive Android API
method. (Again, â€œsensitiveâ€ means that it falls into one of
the SUSI categories listed in Table III). As examples of such
ï¬‚ows, consider Table I and Table II discussed in Section I.TABLE IV
FLOWS IN ANDROID TWITTER APP,BYSUSI CATEGORY
ACCOUNT INFORMATION ;SYNCHRONIZATION DATA
ACCOUNT INFORMATION ;ACCOUNT SETTINGS
ACCOUNT INFORMATION ;INTENT
ACCOUNT INFORMATION ;LOG
NETWORK INFORMATION ;INTENT
NETWORK INFORMATION ;LOG
DATABASE INFORMATION ;LOG
B. Flow Granularity
By default, each source and sink contains the full method
name and signature. For the sake of obtaining a coarser granu-
larity, this information can be shortened, allowing for multiple
sources and sinks to be aggregated. MUDFLOW supports the
following three granularity levels, from ï¬nest to most coarse:
Method. This is the full method signatureâ€”for instance,
LocationManager.requestLocationUpdates(. . . ) .
Class. Considering only the class name ( LocationManager )
allows to express ï¬‚ows between classes rather than meth-
ods. This treats all methods of a class uniformly.
Category. Considering only the SUSI category of the API
(LOCATION INFORMATION ) allows to express ï¬‚ows be-
tween categories. This is the coarsest way of expressing
ï¬‚ows, yet one that could be made accessible to end users.
Table IV shows the ï¬‚ows in the Android Twitter app at
the category level. Here, it is indeed easy to spot how the
sensitive data is being used.
C. Automatic Classiï¬cation
As shown above, the ï¬‚ow within malicious apps may differ
signiï¬cantly from the ï¬‚ow within benign apps. MUDFLOW
leverages such differences to automatically classify novel apps
whether they are malicious or not. While most malware detec-
tion is retrospective in natureâ€”checking apps against patterns
found in known malwareâ€”, MUDFLOW is able to compare
a new app against benignware only , and check whether it
contains abnormal ï¬‚ows with respect to this set. This allows
MUDFLOW to detect malware as abnormal even if the speciï¬c
attack is the ï¬rst of its kind.
The MUDFLOW malware classiï¬cation takes a set sof benign
apps (say, all apps from an app store) and then works in three
steps, detailed below.
1) Outlier Detection in Category: In its ï¬rst step, illustrated
in Figure 1, MUDFLOW identiï¬es which apps have unusual
ï¬‚ows within each category using sas a ground set. Speciï¬-
cally, for a category c,MUDFLOW :
takes all apps in sthat use at least one APIfromc,
extracts all ï¬‚ows within these apps (that is, ï¬‚ows orig-
inating from sources in cas well as ï¬‚ows originating
from other sources). To compute the ï¬‚ows in this step,
MUDFLOW uses the APImethods classiï¬ed as sources and
sinks,
assigns 0.5 as a weight to all ï¬‚ows that lead to LOG,
since these ï¬‚ows are highly prevalent in apps, but are
less harmful, since starting from Android 4.1 LOG ï¬lescan only be accessed by diagnostic and administrative
tools. Finally, it
determines outlierness score of apps considering these
ï¬‚ows as features by using ORCA method [5] with sas a
reference set.
The resulting model can then be used to assess a novel
(potentially malicious) app awhich also uses at least one API
fromc. For this purpose, MUDFLOW extracts the ï¬‚ows from a,
and computes the distance betweenaand itsk nearest
neighbors from the set s. For this step MUDFLOW resorts to the
ORCA outlier detector, and considers, by default, the 5 nearest
neighbors of a sample a. To measure the dissimilarity between
samples, MUDFLOW uses the weighted Jaccard distance metric,
since it is more suitable for data with a huge number of
features, as in this case.
The resulting distance serves as an outlier score: The higher
aâ€™s distance, the less â€œnormalâ€ are its featuresâ€”resulting,
according to our hypothesis, in a higher likelihood of being
malicious.
2) Aggregating Scores: In its second step, MUDFLOW ap-
plies the above outlier detection on all SUSI source categories,
resulting in a single outlier detector for each sensitive source.
We can now take an app aand determine its scores for each
category. As illustrated in Figure 2, we thus obtain a vector
of distances, telling for each sensitive category how much a
deviates from the norm. If an application does not use the
APIs of the appropriate source, its outlierness score is set
to zero. We have dubbed this vector a â€œmaliciogramâ€, as it
may guide investigators towards potential issues, or inform
end users about potential risks, allowing them to focus on the
categories they care about most.
However, the quality of SUSI categories depends on how
similar the benign applications are within the particular cat-
egory. To take this fact into account, MUDFLOW assigns a
App1âœ”LOG1ID4App2âœ”App?
ID4
ID4?
SMS2......âœ”
LOG2ID2
App1
App3Outlier DetectionTrainingd = 0.76Outlier Detectorâœ”âœ˜
Fig. 1. Per-category outlier detection. For each SUSI category such as
UNIQUE IDENTIFIER (shortened to â€œIDâ€), MUDFLOW selects apps that use
APIs of that category as source and uses their ï¬‚ows as features. It then takes
a new unknown app, and determines its outlierness score with respect to the
â€œnormalâ€ apps. The higher the score, the less â€œnormalâ€ the app behaves inside
a particular SUSI category.weight to each category, emphasizing its importance. When
the mean value of scores within a category is high, it means
that all benign apps considerably differ from each other. As
a consequence of this induced noise, we have less conï¬dence
that an outlier would be malicious. For this reason we give
a lower weight to such categories; if, in contrast, the mean
of score values is low, the category will have higher weight.
More precisely, we use exp(1=mean )as the formula to weigh
categories.
3) Overall Classiï¬cation: In the third and last step, MUD-
FLOW leverages one-class classiï¬cation to determine whether
an appaoverall would be considered malicious or not. This
decision would be based on the individual scores in each
category, as determined in the past two steps.
The process is illustrated in Figure 3:
MUDFLOW constructs a training set based on benign
applications. Their score vectors (â€œmaliciogramsâ€) across
the SUSI source categories are used as features.
It trains a-SVM one-class classiï¬er [7], which is com-
monly used for novelty detection purposes.
After training, it uses the -SVM forclassiï¬cation of a
novel appa, based on its score vector, into either â€œlikely
benignâ€ or â€œlikely maliciousâ€.
The result is a fully automatic warning ï¬‚ag for any novel
app, which when raised, would trigger further investigation
such as additional analysis or testing. This investigation would
be guided by the individual category scores as reported by
MUDFLOW (â€œHow does this app deviate from the norm?â€) as
well as the individual ï¬‚ows detected within the app (â€œWhich
ï¬‚ows in this app are abnormal?â€).
D. Advertisement Frameworks
Many Android apps generate revenue through advertise-
ments, which are delivered through speciï¬c advertising frame-
works. These frameworks access sensitive sources such as
account data to deliver personalized advertisements; How-
ever, these ï¬‚ows are separate from the actual app code. As
advertising frameworks are frequently used, their ï¬‚ows thus
become â€œnormalâ€ and make malicious ï¬‚ows harder to detect.
Furthermore, malicious software may use an advertisement
framework to motivate and mask its malicious ï¬‚ows.
Assuming that advertisement frameworks are to be trusted,
MUDFLOW therefore ignores all sensitive ï¬‚ows taking place
within advertisement frameworks only, allowing it to focus on
the actual app code. Table V shows the list of frequently used
frameworks whose ï¬‚ows are excluded in MUDFLOW . Currently
App??âœ”âœ˜âœ”âœ˜âœ”âœ˜âœ”âœ˜âœ”âœ˜d = 0.76d = 0.62d = 0.30d = 0.08d = 0.63
Fig. 2. Aggregating probabilities across APIusage. Given an app, for each
SUSI category, we use the approach from Figure 1 to determine the distance
of the app with respect to the benign training set. The resulting vector of
scores (â€œmaliciogramâ€) tells how abnormal the app is in each category.
App1âœ”App2âœ”App??......âœ”App1
App3ClassifyingTraining
Classiï¬erâœ”âœ˜Appâœ˜Fig. 3. Classifying apps across multiple categories. For each â€œbenignâ€ app
in the Google Play store, we determine its vector of probabilities of being an
outlier in each SUSI category (Figure 2). A one-class classiï¬er trained from
these vectors can label an unknown app as â€œlikely benignâ€ if it is normal
across all categories, or â€œlikely maliciousâ€ instead.
TABLE V
AD FRAMEWORKS WHOSE FLOWS ARE EXCLUDED
com.admob.android com.adsdk.sdk
com.adsmogo com.aduwant.ads
com.applift.playads com.google.ads
com.inneractive.api.ads com.mopub.mobileads
com.revmob.ads com.smartadserver.android
com.swelen.ads de.selfadservice
MUDFLOW is unable to detect such advertisement frameworks
in presence of code obfuscation. This problem is in the scope
of our future work and will be discussed in Section VIII.
IV. A PPS AND THEIR FLOW
To evaluate MUDFLOW , we used two sets of â€œbenignâ€ and
â€œmaliciousâ€ apps for training and classifying. Let us describe
these datasets, as well as their characteristic ï¬‚ows.
A. Apps Mined
Benign apps. As source for â€œbenignâ€ apps, we used the
Google Play Store, the most popular app store for An-
droid. For each of the 30 app categories in the store, we
downloaded the top 100 most popular free applications
as of March 1, 2014. As not all categories had 100 such
entries, this gave us a total of 2,950 apps as our initial
â€œbenignâ€ dataset.
Malicious apps. We used two sources for â€œmaliciousâ€ apps:
1,260 malware apps from the Genome project [30].
This is the dataset already used in the CHABADA
project [12].
The full set of 24,317 malicious applications from the
VirusShare database [28] as of 24 March 2014.
Our initial â€œmaliciousâ€ set thus contained a total of
25,577 apps.
B. Analysis Settings
Running a precise static taint analysis on real-world appli-
cations is not without challenges. In favor of a faster analysisor the ability to analyze a larger application which would
otherwise not ï¬t in memory, we used the following FLOWDROID
settings [3]:
No ï¬‚ow across intents. Android apps use special compo-
nents, called intents, to implement messaging between
components, in particular to start activities or provide
services in the background. We do not track ï¬‚ows across
intents; when sensitive data is sent to an intent, the ï¬‚ow
is marked with the INTENT category as a sink;
Explicit ï¬‚ow only. Our static taint analysis settings do not
consider conditionals controlling speciï¬c ï¬‚ows, nor the
ï¬‚ows leading to these conditionals. This is in contrast to
information ï¬‚ow analysis, which also takes such implicit
ï¬‚ow into account;
Flow-insensitive alias search . Making the alias search
ï¬‚ow-insensitive may generate false positives, but greatly
reduces runtime for large applications;
Maximum access path length of 3, again possibly reduc-
ing precision with respect to the default setting of 5;
No-layout mode, ignoring Android GUIcomponents, such
as input ï¬elds, as data ï¬‚ow sources;
No static ï¬elds, ignoring the tracking of static ï¬elds.
All these choices sacriï¬ce some amount of precision for
speed and memory. As a result, the list of ï¬‚ows determined by
MUDFLOW can have false positives (ï¬‚ows that are infeasible
during executions) as well as false negatives (missing ï¬‚ows
that actually might be possible); but still, FLOWDROID is much
more precise than a basic object- or context-insensitive data
ï¬‚ow analysis. As ever when applying precise static analysis on
real-world programs with ï¬nite time and resources, striking a
good balance between false positives and false negatives is an
important challenge. Let us remind at this point, that our goal
isto detect anomalies, not to prove the presence or absence
of ï¬‚ows; and thus, we can tolerate imprecision as long as the
overall results are ï¬ne.
Still, let us state what â€œï¬nite time and resourcesâ€ mean
in our setting, and why compromises are badly needed. The
main machine we used to run MUDFLOW was a compute
server with 730 GB of RAM and 64 Intel Xeon CPU cores,
far exceeding the standard memory sizes of todayâ€™s personal
computers. Even with all the compromises listed above, the
server sometimes used all its memory, running on all cores
for more than 24 hours to analyze one single Android app,
as shown in Figure 4. Overall, we had this machine run for
two months without interruption to extract data ï¬‚ows from
Android applications.
C. Analysis Results
A small proportion of downloaded apps proved to be a
challenge for precise taint analysis.
Of the 2,950 â€œbenignâ€ apps, 84 (3%) were not analyzable:
16 apps exceeded the RAM limit of 730 GB or the 24-
hour timeout, and 68 apps caused a SOOT exception while
transforming DEX bytecode to JIMPLE representation. Of the
â€œmaliciousâ€ apps, 10,239 (40%) were not analyzable because
of corrupted or incomplete APKs; most frequently, the required
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—5010050050005000050000010100100010000
Callgraph size as # of edges (log scale)Time in seconds (log scale)Fig. 4. Analysis time of benign applications with respect to their call graph
sizes. All times obtained on an Intel 64-core machine with 730 GB RAM .
Android manifest was missing. We also removed all such non-
analyzable apps from our dataset. This resulted in ï¬nal datasets
of 2,866 â€œbenignâ€ apps and 15,338 â€œmaliciousâ€ apps.
D. Data Flow in Benign Apps
Table VI summarizes the data ï¬‚ows detected in our set of
â€œbenignâ€ apps. Most interesting, 68.3% of all accesses to sen-
sitive data do not end in a sensitive sink. Across the sensitive
sinks, we detected 43,371 different data ï¬‚ows, i.e., 43,371
distinct pairs of code locations accessing a sensitive source
APIand a sensitive sink API, linked by data ï¬‚ow between
them. The most important source is DATABASE INFORMATION ,
followed by CALENDAR INFORMATION ,NETWORK INFORMA-
TION , and LOCATION INFORMATION . This reï¬‚ects what most
Android apps are doing: interacting with external services,
using information maintained in their own databases.
As it comes to the least frequently used sources, we ï¬nd
results that reï¬‚ect programming practices in Android. The
source EMAIL shows no ï¬‚ows at all, which might be sur-
prising, considering the number of apps that handle phone
calls or e-mails. This is because most e-mail accesses take
place via IMAP and POP protocols and thus belong to the
NETWORK INFORMATION source category. The sources SYS-
TEM SETTINGS and BROWSER INFORMATION rarely ever end
in sensitive sinks.
The most important sinks are LOG andINTENT , which make
up more than 94% of all sinks in sensitive ï¬‚ows. As discussed
in Section IV-B, the INTENT category means that the data was
used by another activity in the app, a ï¬‚ow we currently cannot
analyze; LOG, however, is a true sink, but it is less harmful,
as starting from Android 4.1 log ï¬les can only be accessed by
diagnostic and administrative tools.
The data set coming with this paper contains detailed
information on all ï¬‚ows, showing the exact ï¬‚ows between
APIs for all of the benign applications.
In â€œbenignâ€ apps, 94% of all sensitive data ï¬‚ows are to
logging and Inter-Process-Communications (i.e. intents).
E. Data Flow in Malicious Apps
Table VII summarizes the data ï¬‚ows detected in our set
of â€œmaliciousâ€ apps, showing similarities, but also importantTABLE VI
DATA FLOWS IN BENIGN APPLICATIONS ,BYSUSI CATEGORIES
SourceLOGINTENTNETWORKFILESYSTEM_SETTINGSACCOUNT_SETTINGSSMS_MMSAUDIONFCSYNCHRONIZATION_DATACALENDAR_INFORMATIONLOCATION_INFORMATIONBLUETOOTHNO_SENSITIVE_SINKTotalDATABASE_INFORMATION6643617412798108430610003018046313039,2%CALENDAR_INFORMATION35297199244305189170121507430252083679510,9%NETWORK_INFORMATION47741529122705337852400000278093450310,2%LOCATION_INFORMATION37581242372212001520028014187193035,7%CONTENT_RESOLVER1769823742422251240210357263101,9%UNIQUE_IDENTIFIER796514171231500000181931580,9%ACCOUNT_INFORMATION477264182626602080000103221470,6%CONTACT_INFORMATION3909200050000000215080,2%FILE_INFORMATION25013641450020000092113320,4%NFC531297600007300001654330,1%BLUETOOTH_INFORMATION15323001002000006097880,2%SMS_MMS4200000810000001562790,1%SYNCHRONIZATION_DATA1900000000100001371660,0%IMAGE1500000000000058730,0%BROWSER_INFORMATION5300000000000190,0%SYSTEM_SETTINGS500000000000026310,0%NO_SENSITIVE_SOURCE14793645028409226263553961123514922262020147259,5%Total1706146315647423168753412233137095139986129376733861050,4%18,7%1,4%0,9%0,2%0,1%0,1%0,4%0,0%0,0%0,0%0,0%0,0%27,7%
TABLE VII
DATA FLOWS IN OUR SET OF MALICIOUS APPLICATIONS ,BYSUSI CATEGORIES
SourceLOGINTENTNETWORKFILESYSTEM_SETTINGSACCOUNT_SETTINGSSMS_MMSAUDIONFCSYNCHRONIZATION_DATACALENDAR_INFORMATIONLOCATION_INFORMATIONBLUETOOTHNO_SENSITIVE_SINKTotalDATABASE_INFORMATION210062536340233232410821200000719061193658,0%CALENDAR_INFORMATION5649359994746104660000062683722304,8%NETWORK_INFORMATION2993032935174373733118021160000026173931250320,9%LOCATION_INFORMATION2254818311242600681400060801521058677,1%CONTENT_RESOLVER989733128597929036890000010176244771,6%UNIQUE_IDENTIFIER109811179660824010579170000049279688844,6%ACCOUNT_INFORMATION86114502870206000124615480,1%CONTACT_INFORMATION4122760111058113000002913230,1%FILE_INFORMATION7062550012003200000179127960,2%NFC367200040110000951550,0%BLUETOOTH_INFORMATION792221060002100001196823070,2%SMS_MMS331800001170000001853530,0%SYNCHRONIZATION_DATA310000000000030340,0%IMAGE0000000000000000,0%BROWSER_INFORMATION1512000000000001732000,0%SYSTEM_SETTINGS030000000000038410,0%NO_SENSITIVE_SOURCE50558422232025897232931251603314362013703131078252352,4%Total60696526180540293244043462541363049441114303192541490149460640,6%17,5%2,7%1,6%0,0%0,0%0,9%0,3%0,0%0,0%0,0%0,0%0,0%36,2%
differences to the â€œbenignâ€ apps from Table VI. The most im-
portant source here is NETWORK INFORMATION , almost twice
as prevalent as in â€œbenignâ€ apps. CALENDAR INFORMATION is
accessed far less frequently as a sensitive source, as is (to our
surprise) ACCOUNT INFORMATION .
In sinks, we also see important differences. Most striking
is the SMS MMS sink, more than 77 times as prevalent as
in our â€œbenignâ€ apps. This reï¬‚ects the common attack of
stealthily sending SMS messages to premium numbers, allow-
ing the owner of these numbers to earn money from the
victim. As the ï¬‚ows to SMS MMS indicate, the malicious
apps also include sensitive data such as UNIQUE IDENTIFIER
and CONTACT INFORMATION in their messages, as well as
NETWORK INFORMATION such as network MAC addresses or
SIMcard information.
Given that 25% of our â€œmaliciousâ€ apps use SMS as a sink,
whereas this is the case for only 1% of the â€œbenignâ€ apps,
a simple check for the ability to send SMS messages would
easily weed out 25% of malicious apps, with a precision of
99%. Note, however, that several of such simple checks may
bring conï¬‚icting classiï¬cations; also, while our â€œbenignâ€ set
is representative in that it encompasses the most popular apps,our â€œmaliciousâ€ set is in no way representative for malware
actually prevalent in the wild, or the types of attacks actually
conducted. In that sense, Table VII serves as descriptive
statistics of the dataset we use for the evaluation of MUDFLOW .
Our set of â€œmaliciousâ€ apps differs from the â€œbenignâ€
apps in terms of sources, sinks, and ï¬‚ows.
V. E VALUATION
With our datasets of â€œbenignâ€ and â€œmaliciousâ€ apps avail-
able, we are now able to evaluate the classiï¬ers in MUDFLOW .
This section reports our results.
A. Detecting Overall Outliers
In our ï¬rst experiment, we evaluated the full MUDFLOW
classiï¬er as described in Section III-C. Using 10-fold cross-
validation, we repeated the following ten times:
We trained the classiï¬er on the score vectors from a
random 90% of the â€œbenignâ€ dataset.
The remaining 10% form the testing dataset, as well as
the whole â€œmaliciousâ€ dataset.
The average results with the -SVM conï¬gured as = 0:15
are as follows:True positives (malware recognized as such): 86.4%
True negatives (benignware recognized as such): 81.3%
Accuracy (apps correctly classiï¬ed): 83.8%
MUDFLOW recognizes 86.4% of malware as such,
with a false positive rate of 18.7%.
As we are most interested in apps that access and send
sensitive data, we ran a second evaluation on the subset of
10,552 â€œmaliciousâ€ apps that have at least one ï¬‚ow from
a sensitive source to a sensitive sink (i.e., malware leaking
sensitive data). For this â€œsensitiveâ€ subset, we get the following
results:
True positives (malware recognized as such): 90.1%
True negatives (benignware recognized as such): 81.3%
Accuracy (apps correctly classiï¬ed): 86.0%
MUDFLOW recognizes 90.1% of malware leaking sensitive
data as such, with a false positive rate of 18.7%.
Again, all these numbers come from one-class classiï¬cation;
that is, no existing malware is used for training.
B. Repackaged Apps
We have seen that MUDFLOW shows good classiï¬cation re-
sults on our â€œmaliciousâ€ samples, because they are apparently
sufï¬ciently different from the â€œbenignâ€ apps used for training.
But what happens if we take â€œbenignâ€ apps and repackage
them to include malicious behavior on top of their regular
functionality? These would include all the behavior (and ï¬‚ows)
of the originals, plus additional ï¬‚ows and sources from the
added malware components.
To this end, in our Genome set we identiï¬ed the repackaged
apps, which in essence are those apps that come with package
names matching existing apps from the Google Play Store,
but include malicious payloads. This gave us 96 distinct apps,
which we veriï¬ed manually to be easily confounded with
original benign apps. Of these 96 apps, MUDFLOW classiï¬ed
93 correctly as malicious, and three falsely as benign.
In a sample of 96 repackaged apps (benign apps with
added malicious behavior), MUDFLOW identiï¬ed 97.6%
correctly as malicious.
As expected, the repackaged apps included ï¬‚ows that would
be unusual for benign apps. The repackaged version of ES File
Manager, for instance, would include ï¬‚ows from device ID
or subscriber ID to the Web; as these ï¬‚ows would normally
only occur in advertisement libraries (Section III-D), their
presence outside of these libraries would immediately ï¬‚ag the
application as an anomaly.
C. Alternate Features
An important question regarding MUDFLOW is whether the
individual features in our approach are all necessary, and
whether the expensive static analysis could be replaced by
something simpler. For this purpose, we repeated the eval-
uation of Section V-A using different features. Notably, we
checked the classiï¬cation results using source methods aloneTABLE VIII
EFFECTIVENESS OF MUDFLOW USING DIFFERENT FEATURES .
Malicious True True
Features set positives negatives Accuracy
Source methods all 81.7% 82.5% 82.1%
Sink methods all 71.0% 83.9% 77.2%
Flow between classes all 82.7% 79.7% 81.2%
sensitive 87.7% 79.9% 83.7%
Flow between methods all 86.4% 81.3% 83.8%
sensitive 90.1% 81.3% 86.0%
as features, as these would not require complex static analysis.
As summarized in Table VIII, data ï¬‚ow between methods ,
as implemented in MUDFLOW and evaluated in Section V-A,
shows the best performance across all metrics.
If one wants to save analysis time, source methods alone
may produce sufï¬cient performance; as shown in Table VIII,
this results in a true positive rate of 81.7% (rather than 86.4%
with ï¬‚ows), for all apps; still showing a low false positive
rate. A classiï¬cation using source methods alone, though, is
easy to fool, as an attacker could repackage an existing app,
reuse existing sources and divert the ï¬‚ow to other sinks. Yet,
in our experiment on repackaged apps, MUDFLOW performed
particularly well (Section V-B).
Data ï¬‚ow from sensitive sources, as used in MUDFLOW ,
show the best classiï¬cation results.
D. Per-Category Outlier Detection
As described in Section III-C1, the overall MUDFLOW clas-
siï¬er depends on individual per-category outlier detectors,
computing outlier scores for each category. In this section,
let us assess the accuracy of these detectors. For this purpose,
we computed the area under the ROC curve for each outlier
detector; this value is equal to the probability that a classiï¬er
will rank a randomly chosen positive instance higher than a
randomly chosen negative one. An area of 1.0 thus represents
a perfect test, an area of 0.5 represents a worthless test.
Table IX shows the size of the categories, as well as the area
under ROCcurve numbers. We see that across all categories, the
individual classiï¬ers perform very well. The highest accuracy
(1.00) is achieved for apps that use CONTACT INFORMATION ,
where all malicious apps are higher ranked than benign apps,
a result partially explained by the imbalance between benign
and malicious apps. For BLUETOOTH INFORMATION and other
categories, the outlier detectors work well for balanced sets.
Outlier scores in individual categories are good predictors
of malicious behavior.
Despite their accuracy, keep in mind that the individual clas-
siï¬ers only work for applications that also use the appropriate
category as a source. Furthermore, a single app may get a
low â€œbenignâ€ score in some categories, but a high â€œmaliciousâ€
score in others. This is why MUDFLOW aggregates these scores
to provide an overall classiï¬cation.
E. Learning from Malware
In our ï¬nal experiment, we changed the setting in Sec-
tion III-C1 from the one-class -SVM to a two-class SVM,TABLE IX
PERFORMANCE OF PER -CATEGORY OUTLIER DETECTORS
Benign Malicious Area under
Category apps apps ROC curve
NETWORK INFORMATION 2,254 14,086 0.94
DATABASE INFORMATION 1,525 7,468 0.95
CALENDAR INFORMATION 1,275 6,928 0.93
LOCATION INFORMATION 1,168 6,410 0.90
UNIQUE IDENTIFIER 972 11,456 0.93
FILE INFORMATION 563 1,358 0.93
CONTENT RESOLVER 1,067 3,771 0.95
ACCOUNT INFORMATION 320 542 0.53
BLUETOOTH INFORMATION 183 283 0.96
SYNCHRONIZATION DATA 80 19 0.91
NFC 61 20 0.92
CONTACT INFORMATION 32 404 1.00
BROWSER INFORMATION 5 193 0.92
SYSTEM SETTINGS 4 25 (too few samples)
SMS MMS 3 5 (too few samples)
IMAGE 2 0 (too few samples)
which would be trained with both â€œbenignâ€ and â€œmaliciousâ€
apps, thus exploiting the existence of known malware and their
respective ï¬‚ows. Again, we used ten-fold cross validation,
each time training the SVM with the â€œmaliciousâ€ apps not
used in the testing set. This setting increases the classiï¬cation
accuracy to 95% (97% for â€œsensitiveâ€ malware)â€”that is, an
even larger fraction of the â€œbenignâ€ apps and â€œmaliciousâ€ apps
would be correctly classiï¬ed.
By also learning ï¬‚ows from known malware, MUDFLOW
accuracy increases to 95% for all malware,
and to 97% for malware leaking sensitive data.
This higher detection rate, however, is due to our mal-
ware set being self-similar, i.e., incorporating the same attack
schemes again and again. These attack schemes result in
recurring data ï¬‚ows, which can be exploited by MUDFLOW ;
in practice, though, malware not only shares similar attack
schemes, but even shares code implementing these attacks.
Hence, to determine similarity with known malware, we see
data ï¬‚ow as only one feature besides established effective
techniques such as code signatures, APIs used, and others,
all of which could show similar or better detection rates.
As a dissimilarity measure comparing against benignware,
though, our results make data ï¬‚ow a promising feature to
detect unusual behavior.
â€œNormalâ€ and â€œabnormalâ€ data ï¬‚ow can be an important
factor in malware detection.
VI. T HREATS TO VALIDITY
The main threat to validity in our work is external validity,
asking how our results generalize to alternate settings. While
our set of â€œbenignâ€ apps represents the most popular Google
Play Store apps across all categories, our set of â€œmaliciousâ€
apps stems from collections of malware where each app at
some point has been found and identiï¬ed as malicious, but
we do not know whether it has ever caused damage before
being detected. We also do not know which Android malware
is currently in circulation; and we do not know its main
attack vectors, its code features, and its possible obfuscationfeatures. Our detection results should thus be seen as a result
on a publicly available benchmark, and may not necessarily
generalize.
A second threat to external validity are deï¬ciencies of our
static analysis; as discussed in Section IV-B, our analysis may
report ï¬‚ows that are infeasible, as well as miss ï¬‚ows that are
feasible (notably implicit ï¬‚ow and ï¬‚ow across components or
storages). This impacts our summaries as shown in Table VI
and Table VII. Our classiï¬cation mechanisms, though, would
be expected to include misclassiï¬cations, and thus would be
impaired, but not threatened by such noise.
VII. R ELATED WORK
MUDFLOW mines the usage of sensitive data in Android
apps, and uses this information to detect malicious applica-
tions. MUDFLOW is thus related to the many existing techniques
that leverage taint analysis to detect information leaks, to
Android malware detection techniques, and to the empirical
studies on Android stores.
A. Information Flow Analysis for Android
As mobile devices are a particularly rich store of sensitive
data, it is not a surprise that much of the mobile security
research work has developed taint analysis techniques to detect
information leaks. Among the research works that leverage
dynamic taint analysis to detect information leaks, TAINTDROID
is the de-facto state of the art tool for Android applications [8].
Thanks to an efï¬cient instrumentation of the Android execu-
tion environment, TAINTDROID can report, without any false
positives, information leaks in apps even when they involve
native code.
Dynamic taint analysis has the obvious limitation of re-
porting only on what has been observed during a limited set
of executions. At the opposite side, static taint tracking tools
report any information leak that may occur at runtime. The
FLOWDROID tool, described in Section II, employs a highly
precise static control and data ï¬‚ow analysis of Android apps
to report both explicit and implicit information ï¬‚ows [3]. Other
static taint tracking tools work in a similar fashion, but miss
several possible information ï¬‚ows since they implement less
precise data-ï¬‚ow analyses [29], [11].
Other techniques focus on detecting information ï¬‚ows in-
volving inter-applications communication, and can thus detect
when multiple applications can act together to leak sensitive
information [15], [17].
MUDFLOW is orthogonal to all these techniques. In fact,
while all these techniques can detect whether there is any
information ï¬‚ow in Android applications, they cannot tell
whether such behavior is likely to be malicious or not. On
the other hand, MUDFLOW has no ability to detect information
ï¬‚ows on its own, and therefore needs tools such as FLOWDROID
to collect information regarding the behavior of apps.
B. Android Malware Detection
As for any other software platform, malware detection
received a lot of attention in Android. Several techniquesfocus on detecting whether the claimed behavior matches the
actual behavior of the application. Some of these techniques
use the textual description to understand what an application
should do [12], [20], [22], while others analyze the text
associated to GUI elements [14]. MUDFLOW instead, only
requires the binary of the application, and therefore can easily
be adopted to classify also applications that come without
textual descriptions.
Moreover, all the aforementioned techniques either look at
the declared permission in the manifest ï¬le or at APIcalls to
â€œcriticalâ€ functionalities of the Android framework. MUDFLOW ,
instead, uses sensitive data ï¬‚ows as features to describe the
behavior of an application. Thus, instead of knowing whether
an application accesses the contact list, it knows what the
application does with the contact list. Thanks to more precise
features, MUDFLOW can consequently provide better malware
detection abilities.
MUDFLOW is not the ï¬rst work that uses machine learning
techniques to detect malicious Android applications. On the
other hand, it is the only one, together with CHABADA , to train
the model only on benign applications [12]. Other techniques
such as MAST and Drebin, instead, train the classiï¬er only
on samples of malware, and can therefore be very effective at
detecting other samples of similar malware [6], [2]. Differently
from MUDFLOW , though, they are quite ineffective at detecting
new types of malware. Similarly, techniques that implement
static or dynamic analyses to detect known malware features
are complementary to MUDFLOW , as they are designed to detect
known malware [21], [18], [9], [10].
C. Mining of Android Apps on Markets
Together with a malware classiï¬er for Android, this paper
presents a novel study of the typical information ï¬‚ows of
Android applications that are popular on the Google Play
market. Other researchers used Android markets for empirical
studies. Harman et al. mined the Blackberry app store to
identify correlations between user rating and ranking of ap-
plications [13]. Stevens et al. analyzed 10,000 free apps from
popular Android markets and found a signiï¬cant correlation
between the popularity of a permission and the number of
times it is misused [27]. Ruiz et al., instead, study the
prevalence of multiple ad libraries in Android apps [25], and
Nagappan et al. analyze the software reuse in the Android
mobile app market [19]. More related to MUDFLOW are the
empirical studies of Allix et al. and Zhou et al. on Android
malware [30], [1].
Shen et al. [26] employ a static data ï¬‚ow analysis technique
to enrich the Android permission mechanism with information
regarding detected information ï¬‚ows. To the best of our
knowledge, their work is the only other work that compares the
information ï¬‚ows between benign and malicious applications.
Their ï¬nal goal, though, is radically different from ours.
VIII. C ONCLUSION AND FUTURE WORK
MUDFLOW learns â€œnormalâ€ ï¬‚ows of sensitive data from
trusted applications to detect â€œabnormalâ€ ï¬‚ows in possiblymalicious applications. The approach is effective in detecting
novel attacks, learning from benignware only, as well as
recognizing known attacks, learning from benign as well as
malicious samples. Despite data ï¬‚ow analysis being expensive
for real-world apps, we see the ï¬‚ow of sensitive data as a
useful abstraction not only for automatic classiï¬cation, but also
for end users to understand what an app does with sensitive
data.
Despite these successes, there still are lots of opportunities
for improvement. Our own future work will focus on the
following topics:
To fool MUDFLOW , malware writers could use reï¬‚ec-
tion, native code, self-decrypting code, or other features
that challenge static analysis. Usage of such techniques
in combination with sensitive data, however, would be
unusual for benign apps. We are investigating analysis
techniques that would detect such obfuscation techniques
as anomalies.
While static taint analysis across components and inter-
mediate data storages is difï¬cult, it is not fundamentally
impossible. We want to design analysis techniques specif-
ically tailored to app-wide and system-wide data ï¬‚ows as
found in Android.
Incorporating our earlier CHABADA work [12], we want to
associate ï¬‚ows with app descriptions, detecting anomalies
within speciï¬c application domains such as â€œtravelâ€,
â€œwallpapersâ€, and likewise.
Where static analysis is challenged, combinations of
automated test generation and dynamic ï¬‚ow analysis may
prove to be helpful alternatives. We are investigating
such combinations in conjunction with static analysis to
combine the strengths of both static and dynamic ï¬‚ow
analysis.
To support further research in app mining, as well as
replication and extension of the results in this paper, all our
mined data as well as the scripts for our statistical analysis
are available for download. For details, see our project page
http://www.st.cs.uni-saarland.de/appmining/
Acknowledgment. This work was funded by the German
Federal Ministry of Education and Research ( BMBF ) under
grant no. 01IC12S01 as well as by an European Research
Council (ERC) Advanced Grant â€œSPECMATE â€“ Speciï¬cation
Mining and Testingâ€. The work was also supported by the
BMBF within EC SPRIDE , by the Hessian LOEWE excellence
initiative within CASED , by the DFGâ€™s Priority Program 1496
Reliably Secure Software Systems, and the project DFG RUN-
SECURE . Florian Gross provided the script for downloading
the â€œbenignâ€ apps. Marcel B Â¨ohme, Â´Ulfar Erlingsson, Florian
Gross, Matthias H Â¨oschele, Clemens Hammacher, and Kevin
Streit provided useful feedback on earlier revisions of this
paper.
REFERENCES
[1] K. Allix, Q. Jerome, R. S. Tegawend Â´e F. Bissyand Â´e, Jacques Klein, and
Y . L. Traon. A forensic analysis of Android malware. how is malwarewritten and how it could be detected? In Proceedings of the IEEE 38th
Annual International Computers, Software & Applications Conference ,
pages 384â€“393, 2014.
[2] D. Arp, M. Spreitzenbarth, M. H Â¨ubner, H. Gascon, and K. Rieck. Drebin:
Effective and explainable detection of android malware in your pocket.
In2014 Network and Distributed System Security Symposium , NDSSâ€™14,
2014.
[3] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein,
Y . Le Traon, D. Octeau, and P. McDaniel. FlowDroid: Precise context,
ï¬‚ow, ï¬eld, object-sensitive and lifecycle-aware taint analysis for Android
apps. In Proceedings of the 35th ACM SIGPLAN Conference on
Programming Language Design and Implementation , PLDI â€™14, pages
259â€“269, New York, NY , USA, 2014. ACM.
[4] K. W. Y . Au, Y . F. Zhou, Z. Huang, and D. Lie. PScout: analyzing the
Android permission speciï¬cation. In Proceedings of the 19th Conference
on Computer and Communications Security (CCS) , pages 217â€“228, New
York, NY , USA, 2012. ACM.
[5] S. D. Bay and M. Schwabacher. Mining distance-based outliers in near
linear time with randomization and a simple pruning rule. In ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining (KDD) , pages 29â€“38, New York, NY , USA, 2003. ACM.
[6] S. Chakradeo, B. Reaves, P. Traynor, and W. Enck. Mast: Triage for
market-scale mobile malware analysis. In Proceedings of the Sixth ACM
Conference on Security and Privacy in Wireless and Mobile Networks ,
WiSec â€™13, pages 13â€“24, New York, NY , USA, 2013. ACM.
[7] P.-H. Chen, C.-J. Lin, and B. Sch Â¨olkopf. A tutorial on -support vector
machines. Applied Stochastic Models in Business and Industry , 21:111â€“
136, 2005.
[8] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel,
and A. N. Sheth. TaintDroid: An information-ï¬‚ow tracking system for
realtime privacy monitoring on smartphones. In Proceedings of the 9th
USENIX Conference on Operating Systems Design and Implementation ,
OSDIâ€™10, pages 1â€“6, Berkeley, CA, USA, 2010. USENIX Association.
[9] W. Enck, M. Ongtang, and P. McDaniel. On lightweight mobile phone
application certiï¬cation. In Proceedings of the 16th ACM Conference
on Computer and Communications Security , CCS â€™09, pages 235â€“245,
New York, NY , USA, 2009. ACM.
[10] Y . Feng, S. Anand, I. Dillig, and A. Aiken. Apposcopy: Semantics-based
detection of android malware through static analysis. In Proceedings of
the 22nd ACM SIGSOFT International Symposium on the Foundations
of Software Engineering (FSE 2014) , 2014.
[11] C. Gibler, J. Crussell, J. Erickson, and H. Chen. Androidleaks:
Automatically detecting potential privacy leaks in Android applications
on a large scale. In Proceedings of the 5th International Conference on
Trust and Trustworthy Computing , TRUSTâ€™12, pages 291â€“307, Berlin,
Heidelberg, 2012. Springer-Verlag.
[12] A. Gorla, I. Tavecchia, F. Gross, and A. Zeller. Checking app behavior
against app descriptions. In Proceedings of the 36th International
Conference on Software Engineering , ICSE 2014, pages 1025â€“1035,
New York, NY , USA, June 2014. ACM.
[13] M. Harman, Y . Jia, and Y . Zhang. App store mining and analysis: MSR
for app stores. In Proceedings of the 9th Working Conference on Mining
Software Repositories , pages 108â€“111, 2012.
[14] J. Huang, X. Zhang, L. Tan, P. Wang, and B. Liang. Asdroid: Detecting
stealthy behaviors in Android applications by user interface and program
behavior contradiction. In Proceedings of the 36th International Con-ference on Software Engineering , ICSE 2014, pages 1036â€“1046, New
York, NY , USA, 2014. ACM.
[15] W. Klieber, L. Flynn, A. Bhosale, L. Jia, and L. Bauer. Android taint
ï¬‚ow analysis for app sets. In Proceedings of the 3rd ACM SIGPLAN
International Workshop on the State of the Art in Java Program Analysis ,
SOAP â€™14, pages 1â€“6, New York, NY , USA, 2014. ACM.
[16] P. Lam, E. Bodden, O. Lhot Â´ak, and L. Hendren. The Soot framework
for Java program analysis: a retrospective. In Cetus Users and Compiler
Infrastructure Workshop (CETUS 2011) , Oct. 2011.
[17] L. Li, A. Bartel, J. Klein, Y . L. Traon, S. Arzt, S. Rasthofer, E. Bodden,
D. Octeau, and P. McDaniel. I know what leaked in your pocket:
uncovering privacy leaks on Android apps with static taint analysis.
arXiv , 1404.7431, 2014.
[18] H. Lockheimer. Android and security, 2012.
http://googlemobile.blogspot.com/2012/02/android-and-security.html.
[19] M. Nagappan, B. Adams, and A. Hassan. Understanding reuse in the
Android market. In Proceedings of International Conference on Program
Comprehension , pages 113 â€“ 122, 2012.
[20] R. Pandita, X. Xiao, W. Yang, W. Enck, and T. Xie. WHYPER: Towards
automating risk assessment of mobile applications. In USENIX Security
Symposium , pages 527â€“542, 2013.
[21] S. Poeplau, Y . Fratantonio, A. Bianchi, C. Kruegel, and G. Vigna.
Execute This! Analyzing Unsafe and Malicious Dynamic Code Loading
in Android Applications. In Proceedings of the ISOC Network and
Distributed System Security Symposium (NDSS) , San Diego, CA, 2014.
[22] Z. Qu, V . Rastogi, X. Zhang, Y . Chen, T. Zhu, , and Z. Chen.
AutoCog: Measuring the description-to-permission ï¬delity in Android
applications. In Proceedings of the 21st Conference on Computer and
Communications Security (CCS) , 2014.
[23] S. Rasthofer, S. Arzt, and E. Bodden. A machine-learning approach
for classifying and categorizing Android sources and sinks. In 2014
Network and Distributed System Security Symposium , NDSSâ€™14, 2014.
[24] T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural dataï¬‚ow
analysis via graph reachability. In POPL â€™95 , pages 49â€“61, 1995.
[25] I. M. Ruiz, M. Nagappan, B. Adams, T. Berger, S. Dienst, and A. Has-
san. On the relationship between the number of ad libraries in an
Android app and its rating. IEEE Software , 99(PrePrints), 2014.
[26] F. Shen, N. Vishnubhotla, C. Todarka, M. Arora, B. Dhandapani, E. J.
Lehner, S. Y . Ko, and L. Ziarek. Information ï¬‚ows as a permission
mechanism. In Proceeding of the 29th IEEE/ACM International Con-
ference on Automated Software Engineering , ASEâ€™14, pages 515â€“526,
2014.
[27] R. Stevens, J. Ganz, V . Filkov, P. Devanbu, and H. Chen. Asking for
(and about) permissions used by Android apps. In Proceedings of the
10th Working Conference on Mining Software Repositories , MSR â€™13,
pages 31â€“40, Piscataway, NJ, USA, 2013. IEEE Press.
[28] http://virusshare.com.
[29] Z. Yang and M. Yang. Leakminer: Detect information leakage on
Android with static taint analysis. In Proceedings of the 2012 Third
World Congress on Software Engineering , WCSE â€™12, pages 101â€“104,
Washington, DC, USA, 2012. IEEE Computer Society.
[30] Y . Zhou and X. Jiang. Dissecting Android malware: Characterization
and evolution. In Proceedings of the IEEE Symposium on Security
and Privacy (SP) , pages 95â€“109, Washington, DC, USA, 2012. IEEE
Computer Society.