Singapor e Management Univ ersity Singapor e Management Univ ersity 
Institutional K nowledge at Singapor e Management Univ ersity Institutional K nowledge at Singapor e Management Univ ersity 
Resear ch Collection School Of Computing and 
Information Systems School of Computing and Information Systems 
8-2019 
DeepStellar: Model-based quantitativ e analysis of stateful deep DeepStellar: Model-based quantitativ e analysis of stateful deep 
learning systems learning systems 
Xiaoning DU 
Xiaof ei XIE 
Singapor e Management Univ ersity , xfxie@smu.edu.sg 
Yi LI 
Lei M A 
Yang LIU 
See next page for additional authors 
Follow this and additional works at: https:/ /ink.libr ary.smu.edu.sg/sis_r esear ch 
 Part of the OS and Networks Commons , and the Softwar e Engineering Commons 
Citation Citation 
DU, Xiaoning; XIE, Xiaof ei; LI, Yi; M A, Lei; LIU, Y ang; and ZH AO, Jianjun. DeepStellar: Model-based 
quantitativ e analysis of stateful deep learning systems. (2019). Proceedings of the 2019 27th A CM Joint 
Meeting on E uropean Softwar e Engineering Conf erence and Symposium on the F oundations of Softwar e 
Engineering, T allinn, Est onia, A ugust 26-30 . 477-487. 
Available at:Available at:  https:/ /ink.libr ary.smu.edu.sg/sis_r esear ch/7068 
This Conf erence Pr oceeding Ar ticle is br ought t o you for fr ee and open access b y the School of Computing and 
Information Systems at Institutional K nowledge at Singapor e Management Univ ersity . It has been accepted for 
inclusion in Resear ch Collection School Of Computing and Information Systems b y an authoriz ed administr ator of 
Institutional K nowledge at Singapor e Management Univ ersity . For mor e information, please email 
cher ylds@smu.edu.sg . Author Author 
Xiaoning DU, Xiaof ei XIE, Yi LI, Lei M A, Yang LIU, and Jianjun ZH AO 
This conf erence pr oceeding ar ticle is a vailable at Institutional K nowledge at Singapor e Management Univ ersity: 
https:/ /ink.libr ary.smu.edu.sg/sis_r esear ch/7068 DeepStellar : Model-Based Quantitative Analysis of Stateful
Deep Learning Systems
Xiaoning Du
Nanyang Technological University
SingaporeXiaofei Xie∗
Nanyang Technological University
SingaporeYi Li
Nanyang Technological University
Singapore
Lei Ma∗
Kyushu University
JapanYang Liu
Nanyang Technological University
Singapore
Zhejiang Sci-Tech University, ChinaJianjun Zhao
Kyushu University
Japan
ABSTRACT
Deep Learning (DL) has achieved tremendous success in many
cutting-edgeapplications.Ho wever,the state-of-the-artDLsystems
stillsufferfromqualityissues.Whilesomerecentprogresshasbeen
made onthe analysisof feed-forwardDL systems,little studyhas
been done on the Recurrent Neural Network (RNN)-based stateful
DLsystems,whicharewidelyusedinaudio,naturallanguagesand
video processing, etc. In this paper, we initiate the very first step
towards the quantitative analysis of RNN-based DL systems. We
modelRNNasanabstractstatetransitionsystemtocharacterize
its internal behaviors. Based on the abstract model, we design two
trace similarity metrics and five coverage criteria which enable the
quantitative analysis of RNNs. We further propose two algorithms
poweredbythequantitativemeasuresforadversarialsampledetec-
tion and coverage-guided test generation. We evaluate DeepStellar
onfourRNN-basedsystemscoveringimageclassificationandauto-
matedspeechre cognition.Theresultsdemonstratethattheabstract
modelisusefulincapturingtheinternalbehaviorsofRNNs,and
confirm that (1) the similarity metrics could effectively capture the
differences between samples even with very small perturbations
(achieving 97% accuracy for detecting adversarial samples) and (2)
thecoveragecriteriaareusefulinrevealingerroneousbehaviors
(generating three times more adversarial samples than random
testingand hundreds times more than the unrolling approach).
CCSCONCEPTS
•Computingmethodologies →Neuralnetworks ;•Software
and its engineering →Software testing and debugging .
∗XiaofeiXie (xfxie@ntu.edu.sg) and LeiMa (malei@ait.kyushu-u.ac.jp) are the corre-
sponding authors.
Permissionto make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-5572-8/19/08 ...$15.00
https://doi.org/10.1145/3338906.3338954KEYWORDS
Deep learning, recurrent neural network, model-based analysis,
adversarialsample, testing
ACM Reference Format:
XiaoningDu,XiaofeiXie,YiLi,LeiMa,YangLiu,andJianjunZhao.2019.
DeepStellar : Model-Based Quantitative Analysis of Stateful Deep Learning
Systems. In Proceedings of the 27th ACM Joint European Software Engineer-
ingConferenceandSymposiumontheFoundationsofSoftwareEngineering
(ESEC/FSE ’19), August 26–30, 2019, Tallinn, Estonia. ACM, New York, NY,
USA,11pages.https://doi.org/10.1145/3338906.3338954
1 INTRODUCTION
DeepLearning(DL) hasexperiencedsignificantprogressoverthe
pastdecadeinmanyreal-worldapplicationssuchasimageprocess-
ing [12],speechr ecognition [ 20], natural language processing [ 43],
and autonomous driving [ 25]. However, the state-of-the-art DL
systemsstillsufferfromquality,reliabilityandsecurityproblems,
which could lead to accidents and catastrophic events especially
whendeployedonsafety-andsecurity-criticalsystems.Wehave
witnessed manyquality and securityissues, such asone pixel at-
tack[47],Alexa/Sirimanipulationwithhiddenvoicecommand[ 48],
andtheGoogle/Uberself-drivingcaraccidents[ 18,51].Anearly-
stage assessment of DL systems is of great importance in discover-
ing defectsand improving the overall product quality.
Althoughanalysisprocessesandtechniquesarewell-established
fortraditionalsoftware,existingtechniquesandtoolchainscould
notbedirectlyappliedtoDLsystems,duetothefundamentaldiffer-
ences in the programming paradigms, development methodologies,aswellasthedecisionlogicrepresentationsofthesoftwareartifacts
(e.g., architectures) [ 32,41,50]. To bridge the gap, research on test-
ing [27,32,41,46,50,56], verification [ 54], and adversarial sample
detection [ 15,19,52] of Feed-forward Neural Networks (FNN), e.g.,
ConvolutionNeuralNetworks(CNN)andfullyconnectedneural
networks, started to emerge recently.
Yet, the existing techniques are not speciallydesigned to be ap-
plicable to RNN. Particularly, in contrast to FNN, RNN captures
thetemporalbehaviorsbyloopsandmemorizationwithinternal
states to take into account the influence of previous (or future)
observations.The architecture ofa simple RNN is shown inFig. 1.
A simple RNN is a network of neuron-like nodes organized into
successive iterations . It takes as inputs both the data stream and
the internal state vector maintained. Instead of taking the input
data as a whole, RNN processes a small chunk of data as it arrives,
477ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, and Jianjun Zhao
Si+1 Si Si-1
RNN Input Outputstate vector
x0… xi-1 xixi+1 …y0… yi-1 yiyi+1 …
Input:Output:
S0
1
unroll
Figure 1: Architecture of a simple RNN.
andsequentiallyproducesoutputsineachiterationwhileupdating
theinternalstates.Inotherwords,informationinanRNNnotonlyflowsfromfrontneurallayerstotherearones,butalsofromthecur-rentiterationtothesubsequentones.ThestatefulnatureofanRNN
contributes to its huge success in handling sequential data, such as
audios and natural languages. At present, Long Short-Term Mem-
ory(LSTM)[ 22]andGatedRecurrentUnit(GRU)[ 10]areamong
the state-of-the-art and most widely used RNNs, designed with en-
hancementtoovercomethe“vanishinggradientproblem”[ 21]that
existsinthetrainingprocessofmostDLsystems,andisaggravated
by the iterative design of vanilla RNNs.
Although recent work mentions the possibility to analyze an
RNN through direct unrolling, treating it as an FNN [ 27,32,50],
such a strategy is still far from sufficient to handle inputs of varied
lengths.DifferentfromanFNN,whereeachlayerhasafixedrole
in feature extraction, a layer in an unrolled RNN often does not
preservethesamefeaturelatentspacefunction(orsemantics)for
different input sequences. Therefore, the same unrolling which
works well for one input may not fit for another. In addition, there
could be scalability issues when the input sequences are extremely
long.
TobettercharacterizetheinternalbehaviorsofRNNs,wepro-
poseDeepStellar , a general-purpose quantitative analysis frame-
workforRNN-basedDLsystems.Consideringitsstatefulnature,
we first model an RNN as Discrete-Time Markov Chain (DTMC)
to capture its statistical behaviors. Based on the DTMC model,
wedesigntwotracesimilaritymetricstoquantifytheprediction
proximity of different inputs, and five coverage criteria to measure
the adequacy of test data from different perspectives. To further
demonstratethe usefulnessof DeepStellar ,we developalgorithms
for two applications based the quantitative analysis, namely, RNN
testingandadversarialsampledetection,towardsaddressinghighly
concerned issues at present in both academia and industry.
We implemented DeepStellar and empirically evaluated the use-
fulness of the abstract model, similarity metrics and coverage crite-
ria on four RNN-based systems from image classification to Auto-
matedSpeechRe cognition(ASR).Specifically,wefirstperformed
controlled experiments to evaluate the capability of the abstract
model.Theresultsdemonstratethat,(1)thetracesimilaritymetrics
serve as good indicators of the discriminatory power of RNNs, and
the abstract model is sensitive enough to distinguish inputs gen-
erated with very small perturbations; and (2) the coverage criteria
derived from the abstract model are able to measure test adequacy
andareeffectiveinmanifestingerroneousbehaviors.Further,we
appliedthemetricsandcriteriaontwoapplications, i.e.,adversarial
sampledetectionandcoverage-guidedtestingofRNNs.Theresults
show that DeepStellar (1) detects 89% and 97% of the adversarial
samples,respectively,forASRandimageclassificationsystems,and
(2) generates tests with high coverage and yields at most hundredsoftimesmoreadversarialsamplesthanrandomtestingandexisting
neuron coverage guided testing with unrolling [ 50].
Themain contributionsofthispaperaresummarizedas follows:
•WeproposetoformalizeanRNN-basedstatefulDLsystemasa
DTMC model, to characterize the internal states and dynamic
behaviors of the systems.
•BasedontheDTMCabstraction,wedesigntwosimilaritymet-
rics and five coverage criteria for stateful DL systems, which
areamongthefirsttoquantifysampledifferencesandtestdata
adequacy for RNNs.
•WithDeepStellar , we design two algorithms for detecting adver-
sarial samples and conducting guided testing for RNNs based on
the metricsand criteria.
•Weconductin-depthevaluationtodemonstratetheusefulness
ofDeepStellar withcontrolledexperimentsaswellastwotypical
real-world applications.
2 OVERVIEW
Fig.2summarizes the workflow of our approach, including the
abstract model construction of RNN, different quantitative measures
defined over the abstract model, and two applications to detect and
generateadversarialsamplesof RNNs.
The abstract model construction module takes a trained RNN
as input and analyses its internal behaviors through profiling. The
inputsforprofilingarefromthetrainingdata,whichcanbestreflect
the characteristics of a trained RNN model. Specifically, each input
sequence isprofiled toderive a trace,i.e., asequence ofRNN state
vectors. After the profiling, we can get a set of traces which record
the states visited and transitions taken during the training stage.
Inpractice,theinternalstatespaceofanRNNandthenumber
oftracesenabledbythetrainingdataareoftenbeyondouranalysis
capability.Therefore,weperformabstractionoverthestatesand
tracestoobtainanabstractmodelthatcapturestheglobalcharacter-
istics of the trained network. At the state level, we apply Principle
ComponentAnalysis(PCA)[ 26]toreducethedimensionsofthe
state vectors and keeps the first kmost dominant components. For
each of the kdimensions, we further partition it into mequal in-
tervals. At the transition level, we consolidate concrete transitions
into abstract ones according to the abstract states. We also take
intoaccountthefrequenciesofdifferenttransitionsateachstate
and effectively derive a Discrete-Time Markov Chain (DTMC) [ 38]
model for the trained RNN.
Based on the abstract model, we design two metrics for eval-
uating the trace similarity induced by different inputs, and five
coveragecriteriatofacilitatethesystematictestingofRNNs.The
metrics and coverage criteria are designed from both the state-and transition-level. Specifically, the trace similarity metrics in-cludestate-based trace similarity (SBTSim) and transition-based
tracesimilarity (TBTSim).Thecoveragecriteriaincludethe basic
statecoverage (BSCov), n-stepstateboundarycoverage (n-SBCov),
weightedstatecoverage (WSCov), basictransitioncoverage (BTCov),
andweighted transition coverage (WTCov).
We then apply the metrics and criteria on two applications, i.e.,
theadversarialsampledetection andcoverage-guidedtesting ,bothof
whichaimtomitigatethethreatsfromadversarialsamples.With
thesimilaritymetrics,weproposeanapproachtodetectadversarial
478DeepStellar : Model-Based Quantitative Analysis of Stateful Deep Learning Systems ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
State Trace
StatisticsStateful
DNN
Abstraction
Model
Abstract Model Construction
States and 
Transitions 
Profiling
State Abstraction
Transition 
Abstraction
Dimension 
Reduction
Interval 
AbstractionTrace 
Similarity
Quality 
Measure.Adversarial
Samples Detection
Coverage-guided 
Testing
Quantitative Indicators Typical Applications
…
Similarity Metrics
Coverage CriteriaSTSim TTSim
BSCov
k-SBCovBTCov
WTCov
State Level Trans. LevelWSCov
i
Figure 2: Overview of DeepStellar and its typicalapplications.
x0:y0s0 s1s2
s/prime
2s3x1:y1x2:y2
x/prime
2:y/prime
2x/prime1:y/prime
1
Figure 3: An example FST representing two traces.
samplesatruntime.Withthecoveragecriteria,wedevelopatesting
framework to guide test generation with the aim to improve cover-
age and uncover defects for quality assurance. The two techniques
are complementary to each other. The testing technique aims to
generate unseen adversarial samples that help developers analyze
andimprovetherobustnessofthemodel.Theadversarialsample
detectiontechniqueisabletoidentifymaliciousinputsandprevent
potential damages at runtime.
3 STATE TRANSITION MODELING OF RNN
3.1 RNNInternal StatesandState Transitions
Following[ 42],werepresentaneuralnetworkabstractlyasadif-
ferentiableparameterizedfunction f(·).TheinputtoanRNNisa
sequence x∈XN,whereXistheinputdomainand Nisthelength
of the sequence. Let xi∈Xbe thei-th element of the sequence
x.Then,whenpassing xintoanRNN,itmaintainsastatevector
s∈SNwiths0=0and(si+1,yi)=f(si,xi), whereSis the do-
mainofthehiddenstate, si∈SisthehiddenstateofRNNatthe
i-thiteration,and yi∈Oisthecorrespondingoutputatthatstep.
We usesd
ito denote the d-thdimension of the state vector si.
Naturally, each input sequence xinduces a finite sequence of
state transitions t, which we define as a trace. Thei-th element
in a trace t, denoted by ti, is the transition from sitosi+1after
accepting an input xiand producing an output yi. A Finite State
Transducer(FST)[ 16]canbeusedtorepresentacollectionoftraces
more compactly [ 23] as defined below.
Definition1. AnFSTisatuple (S,X,O,I,F,δ)suchthat Sisa
non-emptyfinitesetofstates, Xistheinputalphabet, Oistheoutput
alphabet, I⊆Sis the set of initial states, F⊆Sis the set of final
states,and δ⊆S×X×O×S is the transition relation.
For example, Fig. 3shows a simple FST representing two traces,
namely,s0s1s2s3ands0s1s/prime
2s3withs0beingtheinitialstateand s3
beingthefinalstate.Thefirsttracetakesaninputsequence x0x1x2
and emits an output sequence y0y1y2; the second trace takes an
inputsequence x0x/prime
1x2and emitsan output sequence y0y/prime
1y2.3.2 AbstractState Transition Model
ThenumberofstatesandtracesenabledwhiletraininganRNNcan
behuge.Toeffectivelycapturethebehaviorstriggeredbyalarge
numberofinputsequencesandbettercapturetheglobalcharacteris-
ticsofthetrainednetwork,weintroducean abstractstatetransition
modelin this paper. The abstract model over-approximates the ob-
served traces induced of an RNN and has a much smaller set of
states and transitions compared with the original one. The abstrac-
tionisalsoconfigurable–onecantrade-offbetweenthesizeand
precision of the model so that the abstract model is still able to
maintainusefulinformationoftheinputsequencesforparticular
analysistasks. To obtainan abstractmodel foratrained RNN,we
abstractover both the states and the transitions.
StateAbstraction. Eachconcretestate siisrepresentedasavector
(s1
i,...,sm
i),usuallyinhighdimension( i.e.,mcouldbealargenum-
ber). Intuitively, an abstract state represents a set of concrete states
whicharecloseinspace.Toobtainsuchastateabstraction,wefirst
apply the Principle Component Analysis (PCA) [ 26] to perform an
orthogonaltransformationontheconcretestates–findingthefirst
kprinciplecomponents( i.e.,axes)whichbestdistinguishthegiven
state vectors and ignore their differences on the other components.
This is effectively to project all concrete states onto the chosen
k-dimensionalcomponent basis(denoted as PCA- k).
Then, we split the new k-dimensional space into mkregular
grids[49]suchthatthereare mequal-lengthintervalsoneachaxis:
ed
i=[lbd+i×ubd−lbd
m,lbd+(i+1)×ubd−lbd
m],
whereed
irepresentsthe i-thintervalonthe d-thdimension, lbdand
ubdare the lower and upper bounds of all state vectors on the d-th
dimension, respectively. In this way, all concrete states siwhich
fall within the same grid are mapped to the same abstract state:
ˆs={si|s1
i∈e1_∧···∧sk
i∈ek_}.We denote the set of all abstract
states as ˆS. Noticeably, the precision of the state abstraction can
easily be configured by tuning the parameters kandm.
Letj=Id(ˆs)betheindexof ˆsonthed-thdimensionsuchthat
for alls∈ˆs,sdfalls ined
j(0≤j<m). For any two abstract states ˆs
andˆs/prime, we define their distanceas:
Dist(ˆs,ˆs/prime)=Σk
d=1|Id(ˆs)−Id(ˆs/prime)|.
This definition can also be generalized to include space beyond the
lower and upper bounds.
479ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, and Jianjun Zhao
ˆs0
ˆs1
ˆs3 ˆs2t1 t2t3
(a) Example concrete traces.ˆs0
ˆs1
ˆs2 ˆs31
10.250.250.25
0.25
(b) DTMC abstraction.
Figure 4: A set of concrete traces and their corresponding
abstractstate transitionmodel.
TransitionAbstraction. Oncethestateabstractioniscomputed,
aconcretetransitionbetweentwoconcretestatescanbemapped
as a part of an abstract transition . An abstract transition represents
asetofconcretetransitionswhichsharethesamesourceanddesti-
nationabstractstates.Inotherwords,thereisanabstracttransition
between two abstract states ˆsandˆs/primeif and only if there exists a
concretetransitionbetween sands/primesuchthat s∈ˆs∧s/prime∈ˆs/prime.The
set of all abstract transitions is denoted as ˆδ⊆ˆS×ˆS.
For instance, Fig. 4adepicts three concrete traces, i.e.,t1,t2and
t3,wherestatesareshownasdotsandtransitionsaredirectededges.
Thegridsdrawnindashedlinesrepresenttheabstractstates, i.e.,
ˆs0,ˆs1,ˆs2,andˆs3,eachofwhichismappedtoasetofconcretestates
inside the corresponding grid. The set of abstract transitions is,
therefore, {(ˆs0,ˆs1),(ˆs1,ˆs0),(ˆs1,ˆs1),(ˆs1,ˆs2),(ˆs1,ˆs3),(ˆs3,ˆs3)}.
3.3 Trace Similarity Metrics
To precisely compare two input sequences, we define the trace
similaritymetrics toquantifytheproximityoftheirinducedstate
transitions on the abstractmodel. Given an abstract model Mand
an input x, we denote the set of abstract states and transitions
coveredby xasˆSxandˆδx.Then,the state-andtransition-basedtrace
similaritymetrics forthetwoinputs xandyaredefinedbasedonthe
Jaccardindicesoftheirstatesandtransitionscovered,respectively:
STSimM(x,y)=|ˆSx∩ˆSy|
|ˆSx∪ˆSy|,TTSimM(x,y)=|ˆδx∩ˆδy|
|ˆδx∪ˆδy|.
The trace similarity metrics range over [0,1], where 0 indicates
disjoint sets ( i.e., traces induced by xandyare totally different),
while1 indicatingequal sets ( i.e., the traces are similar).
Fig.5shows the concrete traces on an RNN-based ASR model
inducedbytwos peechinput samples,Fig. 5a(“thisbookisabout
science”) and Fig. 5b(“this book is about literature”). The darker
dots appear earlier in the sequence, and vice versa. We can see a
cleardifferenceofthetwoatlaterpartsofthesequence.Thetwo
concrete traces are then projected onto the 3-dimensional space
underthePCA-3abstractionwith5intervalsoneachdimension,
tocalculatethetracesimilarities.Thestate-andtransition-based
tracesimilaritiesof the two inputs are 0.71 and 0.64, respectively.
Eachinputsequenceinthetrainingsetyieldsaconcretetrace
of the RNN model. The abstract state transition model captures all
theconcretetracesenabledfromtrainingdata(oritsrepresentative
parts) and other potential traces which have not been enabled. The(a)“Thisbookisaboutscience.” (b)“Thisbookisaboutliterature.”
Figure 5: Visualization of concrete traces of two audio over
an RNN-based ASR model with the PCA-3 abstraction.
defined state and transition abstraction make the resulting abstract
modelrepresentanover-approximationandgeneralizationofthe
observed behaviors of the trained RNN model.
3.4 Representing Trained RNN as a
Discrete-Time Markov Chain
Toalsotakeintoaccountthelikelihoodoftransitionsatdifferent
states,weaugmenttheabstractmodelwithtransitionprobabilities,
effectively making it a Discrete-Time Markov Chain (DTMC).
Definition 2. A DTMC is a tuple (ˆS,I,ˆT), whereˆSis a set of
abstract states, Iis a set of initial states, and ˆT:ˆS×ˆS/mapsto→[0,1]
isthetransitionprobabilityfunction whichgivestheprobabilityof
differentabstract transitions.
We write Pr(ˆs,ˆs/prime)to denote the conditional probability of vis-
itingˆs/primegiven the current state ˆs, such that Σˆs/prime∈ˆSPr(ˆs,ˆs/prime)=1.
We define the transition probability as the number of concrete
transitions from ˆstoˆs/primeover the number of all outgoing concrete
transitionsfrom ˆs,i.e.,Pr(ˆs,ˆs/prime)=|{(s,s/prime)|s∈ˆs∧s/prime∈ˆs/prime}|
|{(s,_)|s∈ˆs}|.Forexample,
Fig.4bshowstheabstractstatetransitionmodelfortheconcrete
traces in Fig. 4aas a DTMC. The abstract transitions are labeled
with their transition probabilities. For instance, since all outgo-
ing transitions at ˆs0end inˆs1, the transition probability from ˆs0
toˆs1is 1. There are four possible outgoing transitions at ˆs1,i.e.,
{(ˆs1,ˆs1),(ˆs1,ˆs2),(ˆs1,ˆs3),(ˆs1,ˆs0)}. Hence, the transition probability
fromˆs1toˆs2iscomputedas Pr(ˆs1,ˆs2)=1
4.Computationforother
abstracttransitionsare similar.
Asisshownintheexample,aDTMCmodelisconstructedbyfirst
applyingthestateandtransitionabstractionsonasetofconcrete
traces, and then computing transition probability distributions for
each abstract state. The time complexity of the abstraction step
dependsonthenumberofconcretetraces,whilethecomplexityfor
computingthetransitionprobabilitiesonlydependsonthenumber
of abstract transitions.
4 COVERAGE CRITERIA FOR RNN
Inspired by traditional software testing, we propose a set of testing
coverage criteria for RNNs based on the abstract state transitionmodel. The goal of the RNN coverage criteria is to measure the
sufficiencyoftestdatainexercisingthetrainedaswellastheunseen
behaviors. The state and transition abstractions are designed to
reflecttheinternalnetworkconfigurationsatacertainpointaswell
asthetemporalbehaviorsofthenetworkovertime,respectively.
Therefore,tomaximizethechanceofdiscoveringdefectsinstateful
480DeepStellar : Model-Based Quantitative Analysis of Stateful Deep Learning Systems ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
neuralnetworks,oneshouldcombinecoveragecriteriabased on
boththestateandtransitionabstractionstosystematicallygenerate
comprehensive and diverse test suites.
LetM=(ˆS,I,ˆT)beanabstractmodelofthetrainedRNNrep-
resented as a DTMC. Let T={x0,..., xn}be a set of test input
sequences.Wedefineboththe state-level andtransition-level cov-
erageofTtomeasurehowextensively Texercisesthestatesand
transitionsof M, respectively.
4.1 State-Level Coverage Criteria
The state-level coverage criteria focus on the internal states of the
RNN. The set of abstract states ˆSrepresents a space generalization
ofthevisitedstatesobtainedfromtrainingdata(oritsrepresentative
parts), which is referred to as the major function region [32]. The
space outside the major function region is never visited by the
trainingdata,andthusrepresentsthe corner-caseregion [32].The
test data should cover the major function region extensively to
validate the trained behaviors and cover the corner-case region
sufficientlyin order to discover defects in unseen behaviors.
BasicStateCoverage. Given an RNN abstract model Mand a set
oftestinputs T,thebasicstatecoverage measureshowthoroughly T
coversthemajorfunctionregionvisitedwhiletraining.Toquantify
this,wecomparethesetofabstractstatesvisitedby thetraining
inputs and the test inputs, denoted by ˆSMandˆST, respectively.
Then,thebasicstatecoverageisgivenbythenumberofabstract
states visited by both the training and the test inputs over the
number of states visited by the training inputs,
BSCov(T,M)=|ˆST∩ˆSM|
|ˆSM|.
Weighted State Coverage. Thebasicstatecoveragetreatsevery
state with equal weights. During training, not all states are visited
equallyoftenandonemaywanttoemphasizemoreonsomestates
thantheothers.Totakeintoaccountthefrequenciesofdifferent
statesandbeabletoassignweightstostates,wedefinethe weighted
state coverage and allow users to specify a weight function . The de-
faultweightofanabstractstate ˆsisdefinedastherelativefrequency
of it among all the abstract states, i.e.,w(ˆs)=|{s|s∈ˆs}|
|S|, whereS
is the set of all distinct concrete states. Then, the weighted state
coverage is defined as:
WSCov(T,M)=Σˆs∈ˆST∩ˆSMw(ˆs)
Σˆs∈ˆSMw(ˆs).
Inpractice,theweightfunctioncanbedefineddifferentlyaccording
to specific needs. For example, when a constant function is chosen,
the weighted state coverage is equivalent to the basic one. In § 6.3,
we evaluate two weight functions, including the default and the
reversed one which assigns larger weight to less visited states.
n-StepStateBoundaryCoverage. Thetestdatamayalsotrigger
newstatesthatarenevervisitedduringtraining.The n-stepstate
boundary coverage measures how well the corner-case regions are
covered by the test inputs T. The corner-case regions ˆSMcare the
setofabstractstatesoutsideof ˆSM,whichhavenon-zerodistances
fromanystatesin ˆSM.ThenˆSMccanbefurtherdividedintodif-
ferent boundary regions defined by their distances from ˆSMc. For
example, the n-step boundary region ,ˆSMc(n), contains all abstractstateswhichhaveaminimaldistance nfromˆSM,ormoreformally,
ˆSMc(n)={ˆs∈ˆSMc|minˆs/prime∈ˆSMDist(ˆs,ˆs/prime)=n}.
Then-step state boundary coverage is defined as the ratio of
states visited by the test inputs in the boundary regions of at most
nstepsaway from ˆSM:
n-SBCov(T,M)=|ˆST∩/uniontext.1n
i=1ˆSMc(i)|
|/uniontext.1n
i=1ˆSMc(i)|.
4.2 Transition-Level Coverage Criteria
Thestate-levelcoverageindicateshowthoroughtheinternalstates
ofanRNNareexercisedbutitdoesnotreflectthedifferentways
transitionshavehappenedamongstatesinsuccessivetimesteps.
The transition-level coverage criteria targets at the abstract transi-
tions activated by various input sequences and a higher transition
coverage shows that the inputs are more adequate in triggering
diverse temporal dynamicbehaviors.
Basic Transition Coverage. To quantify transition coverage, we
comparetheabstracttransitionsexercisedduringboththetraining
and testing stages, written as ˆδMandˆδT, respectively. The basic
transition coverage is defined as:
BTCov(T,M)=|ˆδT∩ˆδM|
|ˆδM|.
Basictransitioncoveragesubsumesbasicstatecoverage.Inother
words, for any abstract model M, a test input Tsatisfies basic tran-
sitioncoverage regarding to M, also satisfies basic state coverage.
WeightedTransition Coverage. Similar as the state-level cover-
age,wecancalculatethe weightedtransitioncoverage byconsidering
the relative frequency of each transition. More formally,
WTCov(T,M)=Σ(ˆs,ˆs/prime)∈ˆδT∩ˆδMw(ˆs,ˆs/prime)
Σ(ˆs,ˆs/prime)∈ˆδMw(ˆs,ˆs/prime).
where the weight function can be configured similarly as in the
weightedstatecoverage.Bydefault,theweightofatransition (ˆs,ˆs/prime)
is computed as transition probability defined in § 3.4.
5 APPLICATIONS
Todemonstratetheusefulnessoftheabstractmodelandthepro-
posed quality measures, we apply them in finding adversarial sam-
ples for RNNs in two scenarios: (1) adversarial sample detection
to identifyadversarial inputs at runtime,and (2) coverage-guided
testingto generate unseen adversarial samples offline.
5.1 Adversarial Sample Detection for RNNs
Adversarial sample detection aims to check whether a given input
is an adversarial sample at runtime. We propose to use the trace
similaritymetricstomeasurethebehavioraldifferencesbetween
twoinputs.Basedonthisidea,wedevelopanewapproachtodetect
adversarialsamplesfor RNNs.
Given a target sample i, we define a reference sample rsuch that
the RNN gives the same predictions for both iandr. The traces
derivedfromtheoriginalandthereferencesamplesaretypically
similar when iis benign. However, when iis adversarial, the trace
difference between the two samples can be much larger. With such
481ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, and Jianjun Zhao
Algorithm1: Training an Adversarial Detection Classifier
input : D: RNN-based DL system, M: Abstract model of D
output : C: A classifier for detecting adversarial samples
1Prepare benign set B, adversarial set Aand reference set R;
2disb←∅;
3forb∈Bdo
4R/prime←select(R,b);
5vec←∅;
6forr∈R/primedo
7 (r1,state_vec1)←predict(R,r);
8 (r2,state_vec2)←predict(R,b);
9 j←TraceSimilarity (state_vec1 ,state_vec2 ,M);
10 vec←vec/uniontext.1{j};
11d←average(vec);
12disb←disb/uniontext.1{d};
13Computedisasimilar with disb;
14C←LinearRegressionClassifer (disa,disb)
insight, we propose to detect adversarial sample based on the trace
difference from its reference sample.
Weusealearning-basedapproach (Algorithm 1)totrainaclas-
sifier.TheinputsincludeanRNN-basedsystem Dandanabstract
modelM. We first collect a set of benign samples Band a set of
adversarialsamples A. The set of reference samples Rare also pre-
pared for comparison (more details in the next paragraph), and the
tracesimilarities betweenbenign/adversarial samples andthe ref-
erence samples are calculated. For each benign sample b, theselect
function obtains a group of corresponding reference samples R/prime
from the reference samples R. Based on this, we compute the trace
similaritybetween bandeachreferencesample r∈R/prime(Lines6-10)
and take the average similarity (Line 11) to represents the distance
betweenbandthesetofreferencesamples R/prime.Thedistanceisadded
intothebenigndistancelist disb(Line12).Similarly,wecompute
the adversarial distance list disa(Line13). Withdisaanddisb,a
linear regression classifier Cis learned. Given a new input i,w e
computethesimilarity dibetweeniandthereferencesamples,and
rely onC(di)to indicate whether iis a benign or adversarial.
Weapplyandevaluatethedetectionalgorithmsontwodomains,
namely, ASR and image classification. The approaches used to gen-
erate reference samples are as follows: for ASR, given an audio
inputathatistranscribedtotexts tbytheRNN,wegeneratethe
reference audios using off-the-shelf text-to-speec h engines ( e.g.,
Google cloud te xt-to-speec h[4]) that generate the audio twith
correct and clear pronouncing. For image classification, given anew image
iwith prediction result c(i.e., the image ibelongs to
classc), the reference images are selected from the training data
suchthatthey share the same label as c.
5.2 Coverage-Guided Testing of RNNs
In this section, we propose a Coverage-Guided Testing (CGT) tech-
niquewhichaimstogenerateadversarialsamplesincorrectlyrecog-
nized by an RNN. CGT uses the proposed coverage criteria (§ 4)t o
guidethetestgenerationandevaluatesthequalityofthetestsfrom
different perspectives. During the testing process, CGT maintains
atestqueue.Ineachrun,itselectsaseed( i.e.,testcase)fromtheAlgorithm2: Coverage guided testing of RNN
input : I: Initial seeds, D: RNN-based DL system, M: Abstract
model ofD
output : F: Failed tests, Q: Test queue
1F←∅;
2Q←I;
3whilea←Select(Q)do
4Randomly pick transformation twith a random parameter p;
5A= mutate(t,p,a);
6fora/prime∈Ado
7 (result ,state_vec)←predict(R,a/prime);
8 cov←CovAnalysis (state_vec,M);
9 ifFailed(a’, result) then
10 F←F/uniontext.1{a/prime}
11 else ifCoverageIncrease(cov, Q) then
12 Q←Q/uniontext.1a/prime;
13 UpdateCoverage (Q);
queue and generates multiple mutants. A mutant is an adversarial
sampleifitispredictedincorrectlybythenetwork.Otherwise,ifthe
mutant improves the coverage, it is then retained as an interesting
seed and added back to the queue.
Algorithm 2presentstheprocesstogeneratetestsforRNNs.The
inputs include the initial seeds I, the RNN-based DL system Dand
the abstract model M. The outputs are benign tests and failed tests
for which Dgives correct and incorrect inference respectively. The
initialtestqueuecontains a setof initial seeds. In eachrun, CGT
selectsoneinput afromthetestqueue(Line 2),andrandomlypicks
a transformationfunction twithparameter p(Line4).Then, aset
of new samples Aare generated under transformation t(Line5).
For each new sample a/prime, CGT first obtains the concrete trace by
lettingDdotheinference(Line 7)andthencalculatesthecoverage
information over the abstract model (Line 8). If the inference is
incorrect, a/primeis added into the failed test set F(Line10). Ifa/primeis
correctly predicted and covers new states or transitions, CGT puts
it in the test queue and updates the coverage criteria of all tests
currently in the queue (Line 12-13).
A challenge in DL testing is the lack of oracle that tells the
ground-truth label of any new mutant. Mutation operators areoften specific to the application domains. For CGT, we mainly
focus on image classification and apply the metamorphic mutation
strategy [ 55] for generating new mutants that would keep the
prediction meaning from the human’s perspective during testing.
6 EVALUATION
To demonstrate the usefulness of the proposed techniques, we
implemented DeepStellar in Pythonbased on the Keras (2.2.4) [ 11]
with TensorFlow (1.4, 1.8 and 1.11) [ 7]. We first study whether the
abstractmodelisabletocharacterizethestatefulbehaviorsofRNNs
(i.e.,RQ1&RQ2).Basedonthis,wefurtherevaluatetheusefulness
of the proposed quantitative measures on the two applications ( i.e.,
RQ3&RQ4).Specifically,weleverage DeepStellar toinvestigate
the followingresearch questions:
RQ1:Are the proposed trace similarity metrics suitable indicators
forthediscriminatory power of RNNs ( i.e., sensitive to even small
perturbations on inputs)?
482DeepStellar : Model-Based Quantitative Analysis of Stateful Deep Learning Systems ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
Table 1: Subject model information.
Subject ModelKernel RNN # Trainable Acc. (%)
Type State vec. shape Parameters Train. Test.
DeepSpeech 0.1.1 Bi-LSTM (None, 4096) 122,740,765 - -
DeepSpeech 0.3.0 LSTM (None, 2048) 47,228,957 - 11.00
MNIST-LSTM LSTM (None, 128) 81,674 99.69 98.66MNIST-GRU GRU (None, 128) 61,578 99.70 98.61
RQ2:How sensitive are different coverage criteria for capturing
erroneous behaviors of RNNs?
RQ3:How useful is the trace similarity-based detection algorithm
for detectingadversarialsamplesof RNNs?RQ4:
How effective is the coverage-guided testing in achieving
highcoverage and generating adversarial samples of RNNs?
6.1 ExperimentSettings
ModelsandDataset. We selected four RNN-based DL models in-
cludingtwoASRmodelsandtwoimageclassificationmodels,which
cover popular RNN variants (see Table 1). The trainable parameter
size often reflects the complexity of models, and the models we
selectrangefromsmall-scaleoneswithabout60kparameters,to
practical-sized ones with over 100 million parameters. The highest
dimension of the RNN state vectors (Column “State vec. shape”)
hits 4,096,indicatingthe high complexity of the models.
For the ASR tasks, we selected two versions of Mozilla pre-
trained DeepSpeech [ 2](i.e.,0.1.1and 0.3.0) that are among
thestate-of-the-artopensourceASRmodelswithdifferenttypesof
RNNcore. DeepSpeech-0.1.1 adoptsabi-directionalLSTM,and
DeepSpeech-0.3.0 usesaone-directionalLSTM.Thestatevectors
ofbothmodelsarewithahighdimensionof64-bitfloatingpoint
type. For the image classification task, we followed the instruc-
tions and trained two RNN-based classifiers on MNIST dataset ( i.e.,
MNIST-LSTM ,MINIST-GRU )thatachievecompetitiveaccuracy.These
two models are relatively lightweight, whose internal states are
conveyed via 128-dimensional vectors of 32-bit floating points.
AbstractModelConstruction. ForASRmodels,weuse Common
Voice[1]trainingdatasettoperformtheprofiling,whichisusedfor
thetrainingoftheDeepS peechmodels.Ov erall, there are 193,284
audios inthe dataset.Each sampleis processedby bothmodels to
collectthestatetraces.Asfortheimageclassificationmodels,we
use the official MNIST training dataset that contains 60,000 images.
ForthePCAtransformation,duetothehugesizeofstatevectors
forASRmodels,werandomlyselected20%ofstatevectorstofitthe
PCA model, and use it for all further analysis. For image models,
we use all of the state vectors. The model abstraction parameters k
andmcan be configured to generate DTMC models with different
granularity. Table 2summarizes 13 different configurations we
evaluated, aswell as thenumber ofabstract states andtransitions
ineachobtainedDTMCmodel.Notethatweuse (k,m)torepresent
a configuration with kdimensionsand mpartitions.
Data Preparation. For a comprehensive evaluation of the pro-
posed metrics and coverage criteria, we prepared three types of
samples:1)originalbenignsamplesfromthetestdata,2)perturbed
samples which are generated by a slight perturbation on the origi-
nal benign samples, and 3) adversarial samples from the original
benign samples. For ASR models, we use word error rate (WER)Table 2: Abstract model details under different configura-
tionsfor each studied RNN.
Config. DeepSpeech-0.1.1 DeepS peech-0.3.0 MNIST-LSTM MNIST-GRU
(k,m) # St. # Trans. # St. # Trans. # St. # Trans. # St. # Trans.
(2,5) 26 187 27 159 28 162 28 192
(2,10) 88 1,067 86 755 93 745 92 1,203(2,20) 325 8,185 308 4,958 340 4,531 334 8,740(2,40) 1,221 74,936 1,154 38,653 1,267 27,657 1,241 57,506(2,80) 4,700 733,007 4,397 327,480 4,719 105,529 4,656 167,640(3,5) 107 1,416 96 1,269 109 938 109 1,188
(3,10) 595 13,643 533 10,836 632 6,186 606 9,973
(3,20) 3,811 179,925 3,291 128,144 3,806 39,148 3,713 72,989(3,40) 26,154 2,480,927 21,970 1,708,455 21,458 128,225 22,829 183,478(3,80) 183,724 18,408,782 145,602 15,232,230 78,259 200,567 101,417 218,765(6,10) 65,550 2,567,944 55,055 2,040,096 24,276 96,749 34,423 139,595(6,20) 1,373,236 23,057,145 1,108,832 21,164,285 110,325 185,223 149,801 209,887(6,40) 15,804,002 38,324,511 14,258,035 37,594,508 194,765 213,978 215,680 223,505
tomeasuretheinferenceprecision.Inparticular,benignsamples
are with WER of zero. The perturbed samples would have a rela-
tivelysmallerWERwhilethetargeted adversarialsampleshavea
largerWER.Forimageclassificationtasks,theperturbedsamples
we generate are with slight perturbations but still remain benign.
Initially,werandomlyselected100benignaudiosand100benign
imagesseparatelyfromtheirtestdatasets,fromwhichwegener-
ate the perturbed and adversarial samples. For each ASR model,
we generate 10,000 perturbed audios from original benign oneswithexistingaudiodataaugmentationtechniques[
5](i.e.,speed
and volume adjustment, low/high-frequency filtering, noise blend-
ing). Finally, we only successfully generate adversarial samples for
DeepSpeech-0.1.1 because there exists a compatibility issue be-
tween DeepSpeech-0.3.0 andtheadversarialattacktools[ 8]w e
used. It is worth noting that the generation of targeted adversarial
audios is rather computationally intensive and time-consuming.
Tobespecific,weselectthe11commands[ 13]asthetargetsand
generate 1,100 (100 seeds ×11 targets) adversarial audios, which
tookabout12daysintotalon4GPUs( i.e.,48daysV100GPUtime).
For each MNIST model, we also generate 10,000 benign perturbed
sampleswithexistingimagetransformationtechniques[ 50](i.e.,
imagecontrast,brightness,translation,scaling,shearing,rotation
and add white noise). Besides, we generate 10,000 adversarial sam-
ples with each state-of-the-art attack tool, including, FGSM[17],
BIM[28] andDeepFool [37].
For both audio and image case, we set conservative parameters
fortransformationsothat theperturbationon originalsamplesis
slight and imperceptible. Note that all the adversarial samples are
alsowith minimalperturbations and not perceptible by human.
Coverage Criteria Instances. For then-SBCov criteria, we em-
pirically study two instances with n=3 andn=6, denoted as
3-SBCovand6-SBCov,respectively.FortheWSCovandWTCov,
besidesthedefaultweightfunction,whichassignslargerweightsto
states or transitions with high visiting frequency during profiling,
we introduce another weight function to assign smaller weights
tomorefrequentlyvisitedstatesandtransitionsbyinvertingthe
originalweights.WeuseWSCovandWTCovtodenotethecriteria
with default weight function, and refer WSCov’ and WTCov’ to
theinvertedones.Thecriteriaallowobservinghowthetestdata
cover states and transitions that have high/low visiting frequency.
All the experiments were run on a server with the Ubuntu 16.04
systemwith28-core2.0GHzXeonCPU,196GBRAMand4NVIDIA
Tesla V100 16G GPUs.
483ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, and Jianjun Zhao
Table3:Correlationoftracesimilaritiesandpredictiondiff.
Config. DeepSpeech-0.1.1 DeepS peech-0.3.0 MNIST-LSTM MNIST-GRU
(k,m)ρ(st.)ρ(tr.)ρ(st.)ρ(tr.)U(st.)U(tr.)U(st.)U(tr.)
(2, 5) -0.25 -0.28 -0.36 -0.44 2.99.E+08 2.79.E+08 2.70.E+08 2.62.E+08
(2, 10) -0.27 -0.35 -0.44 -0.50 3.03.E+08 2.76.E+08 2.53.E+08 2.48.E+08(2, 20) -0.35 -0.38 -0.46 -0.49 2.84.E+08 2.55.E+08 2.49.E+08 2.33.E+08(2, 40) -0.37 -0.26 -0.43 -0.47 2.50.E+08 2.30.E+08 2.29.E+08 2.05.E+08(2, 80) -0.30 -0.16 -0.40 -0.36 2.30.E+08 2.20.E+08 2.04.E+08 1.92.E+08
(3, 5) -0.34 -0.38 -0.47 -0.52 3.11.E+08 2.92.E+08 2.89.E+08 2.74.E+08
(3, 10) -0.39 -0.39 -0.52 -0.50 3.04.E+08 2.64.E+08 2.73.E+08 2.45.E+08
(3, 20) -0.38 -0.34 -0.51 -0.532.74.E+08 2.35.E+08 2.44.E+08 2.09.E+08
(3, 40) -0.31 -0.15 -0.51 -0.43 2.35.E+08 2.14.E+08 2.05.E+08 1.82.E+08(3, 80) -0.23 -0.09 -0.41 -0.25 2.17.E+08 2.11.E+08 1.93.E+08 1.89.E+08(6, 10) -0.54 -0.47 -0.62 -0.59 2.65.E+08 2.18.E+08 2.23.E+08 1.95.E+08
(6, 20) -0.40 -0.24 -0.59 -0.43 2.25.E+08 2.14.E+08 1.89.E+08 1.90.E+08
(6, 40) -0.06 -0.06 -0.40 -0.13 2.14.E+08 2.09.E+08 1.89.E+08 1.89.E+08
6.2 RQ1: Trace Similarity
Setup.Weperformastatisticalanalysisonthecorrelationbetween
thetracesimilarity andthepredictiondifference overtheslightly
perturbedsamplesandtheiroriginalbenignsamples.Thedifference
is difficult to capture because the sample and its slightly perturbed
counterpartareperceivedalmostthesamefromhumanperceptions.
WecomputethepredictiondifferenceofASRwiththeword-level
Levenshtein distance [ 6] of their transcripts, and the prediction
difference in image classification by checking whether they belong
to different classes.
Foraudios,weusethe10,000perturbedsamples,whicharewith
variousLevenshteindistancescomparedwiththeiroriginalseeds.
For the image case, we take the 10,000 perturbed samples and also
randomly select another 10,000 samples from all the generated
adversarial samples.This is to include both correctly and wrongly
inferring perturbed images. For the statistical analysis, we use
Spearmanrank-ordercorrelation[ 44](denotedas ρ),toanalyzethe
monotonic association between two variables, for the ASR models;
and we use Mann-Whitney U test [ 35] (denoted as U), to check the
binary association, for MNIST models.
Results. Table3showstheresultsofthecorrelationbetweentrace
similarityandpredictiondifferencemeasuredovertheperturbed
data,whereColumn ρ(st.)andColumn U(st.)representtheresults
ofSTSim;andColumn ρ(tr.)andColumn U(tr.)representthere-
sultsofTTSim.Thebesttworesultsofeachcolumnarehighlighted
in bold font. All reported correlations are statistically significant
(withp<<0.01). Negative association of Spearman correlation
indicates that the larger the similarity metrics, the less different
thepredictedtranscriptswouldbe.ForMNISTmodels,theMann-
Whitney U test results indicate that when measuring the trace
similaritycomparedwiththeoriginalbenignsamples,perturbed
samplesobtainsignificantlylargervalues thanadversarialones.
AnswertoRQ1: Bothstate-andtransition-leveltracesimilar-
ity metrics are capable of capturing the prediction difference
even for slightly perturbed samples. Thus, trace similarity
could be useful for detecting adversarial samples (See RQ4).
6.3 RQ2. Coverage Criteria
Setup.In this experiment, we evaluate the sensitivity of the pro-
posedcoveragecriteriatoadversarialsamples.Theabstractioncon-
figurationsusedinRQ2areselectedbasedontheRQ1results.InTable 4: Coverage criteria sensitivity to the slightly per-
turbed samples and adversarial samples.
Sub. Conf.DataState (%) Transition (%)
mod. (k,m) BSCov WSCov WSCov’ 3-SBCov 6-SBCov BTCov WTCov WTCov’
O67.9 99.7 3.00.0 0.0 23.5 95.523.5
(3, 10)O+P74.510 99.9 0 3.2 7 0.00.0 0.0 0.0 37.9 61 98.7 3 37.961
O+A74.19 99.9 0 3.2 7 0.00.0 0.0 0.0 44.0 87 98.6 3 44.087
DS1 O13.7 81.1 0.40.0 0.0 0.8 29.6 0.8
(6, 10)O+P26.090 92.9 15 0.7 75 0.00.0 0.0 0.0 3.4 325 49.4 67 3.4325
O+A35.4158 94.0 16 0.9125 0.1 0.1 0.0 0.0 6.4 700 53.0 79 6.4700
O1.7 22.9 0.10.0 0.0 0.1 5.10.1
(6, 20)O+P7.2324 47.1 106 0.4 300 0.0 0.0 0.0 0.0 0.4 300 9.1 78 0.4300
O+A13.9718 51.8 126 0.8 700 0.2 0.2 0.1 0.1 0.4 300 6.2 22 0.4300
(2, 5)O85.7 100.0 14.2 0.0 0.0 57.1 99.056.8
O+A85.70 100.0 0 14.2 0 0.00.0 0.0 0.0 85.3 49 100.0 1 85.250
ML(3, 5)O71.6 99.4 8.20.0 0.0 32.1 95.632.0
O+A89.024 99.9 1 10.224 0.40.4 0.2 0.2 76.7 139 99.4 4 75.8137
(3, 10)O54.6 96.4 5.60.0 0.0 15.1 77.815.1
O+A81.850 99.4 3 8.246 1.51.5 0.7 0.7 60.3 299 95.0 22 60.0297
* The coverage increase ratio/value w.r.t. its seed group are marked with grey background.
ordertobetterdifferentiatevariouscoveragecriteria,threeconfigu-
rations were selected from RQ1, which are most sensitive to minor
perturbationsaccordingtoeitherSTSimorTTSim.Wecomparethe
coverageresultsofthe100originalbenignsamples(denoteas O),
andthecoverageachievedbyincludingperturbedsamples(denoted
asO+P)oradversarialsamples(denotedas O+A)(seeColumn Data
ofTable4).Notethattheperturbedsamplesarenotincludedforthe
MNISTmodelsbecausetheyareallbenign.For DeepSpeech-0.1.1 ,
thenumberofadversarialsamplesis1,100,andwealsoselectthe
same number of perturbed samples to make a fair comparison. For
othermodels, we use all 10,000 perturbed/adversarial samples.
Results. Table4reports the coverage results using different cover-
age criteria on different dataset (see results of DeepSpeech-0.3.0
andMNIST-GRU on website [ 3]). The coverage increase ratio indi-
cates the sensitivity of the coverage criteria to adversarial samples.
We observed that finer-grained abstract models tend to have larger
coverage increase ratio. This is because finer-grained state and
transitioninformationismorelikelytodistinguishadversarialsam-
ples fromthe benign samples.We also foundthat the sensitivities
ofvariouscriteriatoadversarialsamplesareratherdifferent.For
example,theincreaseratioof WSCov/WTCovisrelativelysmall
becausetheymainlyconcernthefrequentlycoveredstatesandtran-
sitions(duringprofiling)whichareoftenalreadyfullycoveredby
benignsamples.Incontrast,theincreaseratioof WSCov’/WTCov’
is larger, with a competitive performance as BSCov and BTCov,
indicatingrarelyvisitedstatesandtransitionstendtobecoveredby
adversarial/perturbedsamples.Forthe n-SBCovcriteria,wepresent
theincrease value instead the increase ratio as the initial criteria
are zero. The increase is not quite significant, as these states are
really hard to cover even by adversarial samples. Furthermore, for
DeepSpeech-0.1.1 ,wefindthatthecoveragecriteriaof O+Aare
generally higher than those of O+P. This is possibly due to the
larger average WER of the adversarial audios.
AnswertoRQ2: Thetestcoveragecriteriaaremoresensitive
with finer-grained abstraction. All proposed coverage criteria
are sensitive to erroneous behaviors in adversarial samples,
amongwhich,BSCov,andBTCovarethemostsensitiveones.
484DeepStellar : Model-Based Quantitative Analysis of Stateful Deep Learning Systems ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
Table 5: AUROC results (%) of trace similarity based adver-
sarialdetectionby configurations.
Config. DeepSpeech-0.1.1 MNIST-LSTM
(k, m) STSim TTSimFSGM BIM DeepFool
STSim TTSim STSim TTSim STSim TTSim
(2, 5) 49.78 67.67 77.97 79.8 74.61 74.85 75.11 73.55
(2, 10) 59.52 84.73 83.13 84.29 80.81 79.91 78.92 80.1
(2, 20) 80.90 81.24 83.37 84.71 80.42 80.42 79.09 80.27(2, 40) 81.00 50.00 79.95 88.01 77.9 80.77 76.82 81.86(2, 80) 70.25 50.00 90.54 96.5582.3892.1284.4392.46
(3, 5) 69.41 85.40 86.95 85.31 84.71 83.25 82.42 80.15
(3, 10)89.26 85.19 90.05 89.74 86.1885.2885.2383.78
(3, 20)85.25 50.00 89.4 92.62 84.63 84.72 83.53 85.46
(3, 40) 50.49 50.00 90.56 93.79 85.97 86.62 84.05 87.47
(3, 80) 50.00 50.00 96.6393.6492.97 89.75 93.44 90.43
(6, 10) 75.82 50.00 89.81 86.68 85.18 78.04 84.95 80.59(6, 20) 50.00 50.00 86.94 84.53 79.45 72.64 82.54 78.99
(6, 40) 50.00 50.00 85.94 92.17 78.64 85.08 79.96 87.79
6.4 RQ3. Adversarial Sample Detection
Setup.Thissectionevaluates DeepStellar foradversarialsamplede-
tectiononthreemodels,namely, DeepSpeech-0.1.1 ,MNIST-LTSM ,
andMNIST-GRU .Wefirstpreparedthebenign,adversarial,andrefer-
encesamples(referto B,AandRinAlgorithm 1)totrainthelinear
regressionclassifier.FortheASRmodel,werandomlyselected1,100
benign samples (800 for training and 300 for testing) from the test
dataset,tomakeanequalnumberasthe1,100generatedadversarial
samples. Specifically, the 11 target commands are divided into two
setsC1andC2,whichcontain8and3commands,respectively.The
adversarial samples whose prediction results belong to C1are used
astrainingdata( i.e.,100×8),whiletheotherastestdata( i.e.,100×
3). The reference samples are constructed by re-transcribing all the
prediction results of both adversarial and benign samples to audios
withtheGooglecloudtext-to-speech[ 4].ForMNISTmodels,we
takethe9,000benignsamplesfromthetestdataofMNISTandgen-
erate 9,000 adversarial samples with each of the three approaches,
i.e.,FGSM,BIMandDeepFool, of which 70% are used for training
and30%areusedfortesting.Forreferencesamples,werandomly
selected50samplesfromthetrainingdataofMINISTforeachof
the 10 categories ( i.e., 50×10). With the constructed dataset, we
trained a classifier for each model to detect adversarial samples.
Results. Table5showstheAUROC[ 14]resultsofadversarialsam-
ple detection using different trace similarity metrics ( i.e., STSim
and TTSim) and DTMC models with different configurations (Col-
umnConfig.).Thebesttworesultsofeachmodelarehighlighted,
e.g.,89.26%for DeepSpeech-0.1.1 ,96.63%forMNIST-LSTM,and
96.63% for MNIST-GRU (see website [ 3]). The best results indi-
cate that state-based trace similarity is a bit more effective than
transition-based one in many cases. The results of MNIST models
on detecting attacks generated by different tools show that our
algorithm is robustness to a wide range of attacks, respectively
with accuracy of 97%, 93%, and 93%. Furthermore, the results un-
der DTMC models with different configurations vary largely. With
finer-grained model, the result is not necessarily better. Overall,the results confirm that the trace similarity-based method is ef-fective for adversarial sample detection under carefully selected
abstractionconfigurations,withmorethan89%predictionaccuracy.Table 6: Coverage and unique adversarial samples detected.
Criteria (%) MNIST-LSTM MNIST-GRU
/Crash (#) Seed S-Guid. T-Guid. Ran. DeepTest Seed S-Guid. T-Guid. Ran. DeepTest
BSCov 54.59 97.78 97.78 86.23 65.35 63.20 95.87 96.0488.78 68.98
WSCov 96.44 99.99 99.99 99.66 98.04 97.03 99.98 99.98 99.80 98.05
WSCov’ 5.56 9.97 9.97 8.79 6.66 3.83 5.82 5.835.38 4.18
3-SBCov 0.00 1.50 2.001.86 0.07 0.00 0.78 1.240.85 0
6-SBCov 0.00 0.56 0.750.69 0.03 0.00 0.29 0.460.32 0
BTCov 15.13 53.43 96.4373.88 26.23 14.42 42.80 93.8971.82 21.32
WTCov 77.80 94.81 99.9098.02 85.12 63.40 88.78 99.6996.95 72.34
WTCov’ 15.12 53.43 96.4373.88 26.22 14.41 42.80 93.8971.81 21.31
#Unique Cra. - 87,596 41,614 2,219 300 - 69,777 35,228 19,738 244
* The last row presents the number of unique crashes discovered in each experiment.
AnswertoRQ3: Similaritymetricbasedmethodisusefulfor
adversarialsampledetection.Thedetectionaccuracyvaries
underdifferent metricsand model configurations.
6.5 RQ4. Coverage-guided Testing
Setup.We use the prepared 100 original benign samples as the
initialseeds,whicharecorrectlypredictedbybothMNIST-LTSM
and MNIST-GRU. Based on the results of RQ2, we use the fined-
grained configuration (3,10) for constructing the DTMC models,
andselectBSCovandBTCovasthetestingguidance.Finally,we
implementtwotestingstrategies, i.e.,S-Guid.andT-Guid..Tofurther
demonstratetheusefulnessofthecoverageguidance,weinclude
random testing without coverage guidance and DeepTest [50], a
neuron coverage guided testing tool for unrolled RNNs, as baseline
approaches for comparison. Each testing configuration was run for
6 hours, upon which the studied coverage criteria tend to saturate.
To counter the randomness of testing tool, each configuration is
repeated 5 times and averaged results are reported.
Results. Table6summarizes the obtained coverage results for dif-
ferentcoveragecriteriaandtheuniqueadversarialsamplesdetected
withthetestingtools.Thefirstcolumnliststhestudiedcoverage
criteria.Column Seedrepresentsthecoverageoftheinitialseeds.
Columns S-Guid.,T-Guid.,RandomandDeepTestarethecoverage
bydifferenttestingstrategies.Wecanobservethatallofthestud-
ied strategies improve the coverage to some extent. Transition
coverage-guidedstrategyoutperformstheothertwostrategiesin
achieving higher coverage under all criteria. Furthermore, state
coverage-guided strategy is often more effective in generatingad-
versarial samples although it does not obtain the highest coverage.
The overall results indicate that covering more new states could be
potentially helpful in generating adversarial samples.
Answer to RQ4: The coverage-guided testing is generally
useful in terms of achieving higher coverage and guiding
adversarialsampleexploration.Amongthethreestrategies,
transition coverage-guided method achieves higher coverage,
while state coverage-guided method uncovers more unique
adversarialsamples.
6.6 Threatsto Validity
We summarize factors that could affect the validity of our study. A
major threat is related to the abstract model configuration settings.
485ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, and Jianjun Zhao
There could be many possible configurations in the abstract model.
Duetothecomputationresourceconstraint,wetriedourbestto
experiment with as many settings as possible. Even though our
results may still not generalize beyond the considered settings.
Thesubjectmodelselection could beanotherthreattogeneral-
izability. We mitigate this by choosing models with diverse com-
plexitiesanddifferentapplicationdomains,coveringbothsimple
cases and industrial-grade ASR applications. In addition, for the
ASR model, the training sets for the adversarial detection classi-
fierisrelativelysmall,whichmightaffectthetheperformanceof
the detection. Adopting a larger training set may help obtain even
better detection performance, which we leave as future work. Fur-
thermore,randomnessisathreatinbothsampling,testingacross
ourstudiedresearchquestions.Tocounteractthis,werepeatthe
same setting for all experiments five times and average the results.
7 RELATED WORK
Inthissection,wecompareourworkwithotherabstractiontech-
niques,testingand adversarialsample detectionfor DL systems.
AbstractionofRNN. Severalapproacheshavebeenproposedto
modelRNN,butmostlyintheformofFiniteStateAutomaton(FSA).
FSAhelpstomanifesttheinternalstatetransitionsexplicitlyand
thus can be used to interpret the underlying decision rules embed-
ded in an RNN. DTMC is superior with the ability to capture state
transition distributions, making it more suitable for quantitative
analysis.ConstructinganFSAfromanRNNusuallyrequirestwo
steps:(1)hiddenstatespacepartitionandabstraction,and(2)transi-
tion abstraction and automaton construction. Various partitioning
strategiesandautomatonconstructionalgorithmshavebeenpro-
posed. Omlin and Giles [ 40] proposed to split each dimension of
the state vector into equal intervals, so as to divide the state space
intoregulargrids.Unsupervisedclassificationalgorithmswerealso
applied for state space partitions. For example, k-means and its
variants were studied in [ 9,24,53]. Weiss et al. [ 54] devised an
algorithmtodynamicallycreatepartitions,whereanSVMclassifier
withanRBFkernelisfittedtoseparateseveralstatevectorsfrom
itsoriginalpartitions.Recentstudies[ 24,53,54]havefocusedmore
on the interpretability and visulizability of RNN behaviors, and
try to simplify the abstract model by reducing the size of the mod-
els.Whenappliedtoreal-world tasks,includingNLPand speech
recognition, the state space of the trained RNN models could betremendously large. This makes scalability an issue for partition
techniquessuchas k-meansandkernelalgorithms.However,we
adoptedacheaperintervalabstractionandcouldbenefitfromits
flexibility in precision adjustment.
Testing of DNN. The lack of robustness places a major threat
to the commercialization and wide adoption of DL systems. Re-searchers have devoted a great amount of efforts to investigate
effective and systematic approaches to test DL systems, led with a
pioneering work of Pei et al. [ 41]. The authors designed the first
testingcriterion– neuroncoverage –tomeasurehowmuchinter-
nal logic of DNNs has been examined by a given set of test data.
Severalnewcriteriahavebeenproposedsincethen,includingaset
ofmulti-granularitytestingcriteriaproposedinDeepGauge[ 32],
asetofadaptedMC/DCtestcriteria[ 45],andcombinatorialtest-
ingcriteria[ 31].Sofar,theproposedcoveragecriteriaareusedtoguidethemetamorphicmutation-basedtesting[ 50],concolictest-
ing [46], and coverage-guided testing of DNN [ 39,55]. In addition,
mutation testing technique is also proposed to evaluate the test
data quality through injecting faults into DL models [ 33]. In [56], a
black-box differential testing framework is proposed for detecting
the disagreements between multiple models.
MC/DCcriteriaarelimitedinscalability,andothercriteriaare
specifictotheFNNarchitecture,eventhoughapplicabletoRNNvia
unrolling.Theresultsreportedin[ 50]demonstratedthattheneuron
coverageworkseffectivelyonFNNbutfarfromidealonRNNwhen
used to guide test generation. This indicates that RNN is beyond a
simple folding of CNN, and existing criteria may not be well suited
for it. Due to the page limit, we refer the interested readers to a
comprehensive survey on machine learning testing [ 58].
Adversarial Sample Detection. Sometechniques[ 15,19,29,34,
52,57]areproposedtodetectadversarialsamplesthatarepredicted
incorrectly.Theauthorsfoundthatadversarialsamplesaremuch
more sensitive in model mutants, and proposed a sensitivity-based
approachtodetectadversarialsamplesforfeed-forwardmodels[ 52].
Thetechniquein[ 36]augmentstheDNNsbyaddingasmallsub-
network which obtains inputs from the intermediate feature repre-
sentations of the DNN and is trained to detect adversarial samples.
The authors proposed two features [ 15],i.e., density estimates and
Bayesian uncertainty estimates to show the differences between
benignandadversarialsamples.Xuetal.[ 57]adopttwotypesof
featuresqueezing, i.e.,reducingthecolorbitdepthofeachpixeland
spatial smoothing to detect adversarial samples. These approaches
mainlyconsider CNNsand the image classificationdomain.
In [19], the authors detect the adversarial samples based on that
theadversarialsampleshavearelativelysmallersoftmaxprobability.
Followingthisline,thetechniqueproposedin[ 29]observesthatthe
softmaxprobabilitiesbetweenin-andout-of-distributionsamples
can be further enlarged by temperature scaling in the softmaxfunction. Such methods can be used on RNNs but are limited to
the classification problem. Compared with them, our approach can
handle sequential outputs of RNNs ( e.g., the outputs in automated
speechre cognition)basedontheabstractmodel.
8 CONCLUSION
Vulnerabilities of DL systems are threatening the trust and mass
adoption of these technologies. This work initiates the first step
towardsthequantitativeanalysisofstatefulDLsystems.Wemodel
an RNN as an abstract model, based on which a set of similarity
metricsandcoveragecriteriaareproposed.Wedemonstratedthe
usefulnessoftheproposedmodelsandquantitativemeasureson
RNNs testing and adversarial sample detection. Our long term goal
is to provide quality assurance for the DL system life-cycle [ 30].
ACKNOWLEDGMENTS
This research was supported (in part) by the National Research
Foundation,PrimeMinistersOffice,SingaporeunderitsNational
CybersecurityR&DProgram(AwardNo.NRF2018NCR-NCR005-
0001), National Satellite of Excellence in Trustworthy Software
System (Award No. NRF2018NCR-NSOE003-0001) administered by
the NationalCybersecurity R&DDirectorate, andJSPS KAKENHI
Grant 19H04086,and NTU research grant NGF-2019-06-024.
486DeepStellar : Model-Based Quantitative Analysis of Stateful Deep Learning Systems ESEC/FSE ’19, August 26–30, 2019, Tallinn, Estonia
REFERENCES
[1] 2018. Mozilla Common Voice. https://voice.mozilla.org/en .
[2] 2018. Mozilla’sDeepSpeech. https://github.com/mozilla/DeepS peech.
[3] 2019. DeepStellar. https://sites.google.com/view/deepstellar/home
[4] 2019. Googlecloudtext-to-speech. https://cloud.google.com/text-to-speech/
[5]2019. kaggle: Audio data augmentation. https://www.kaggle.com/CVxTz/audio-
data-augmentation
[6]2019. LevenshteinDistance. https://en.wikipedia.org/wiki/Levenshtein_distance
[7]MartinAbadi,PaulBarham,JianminChen,ZhifengChen,andetal.2016. Ten-
sorFlow: A system for large-scale machine learning. In OSDI. 265–283.
[8]NicholasCarliniandDavidWagner.2018. AudioAdversarialExamples:Targeted
Attacks on Speech-to-Text. (jan 2018). arXiv: 1801.01944 http://arxiv.org/abs/
1801.01944
[9]Adelmo Luis Cechin, Denise Regina Pechmann Simon, and Klaus Stertz. 2003.
StateAutomataExtractionfromRecurrentNeuralNetsUsingk-MeansandFuzzy
Clustering. In Proceedings of the XXIII International Conference of the Chilean
Computer Science Society . 73.
[10]Kyunghyun Cho, Bart Van Merriënboer, Dzmitry Bahdanau, and Yoshua Ben-
gio. 2014. On the properties of neural machine translation: Encoder-decoder
approaches. arXiv preprint arXiv:1409.1259 (2014).
[11] François Chollet et al. 2015. Keras. https://github.com/fchollet/keras .
[12]Dan Ciregan, Ueli Meier, and Jürgen Schmidhuber. 2012. Multi-column deep
neural networksfor image classification. In CVPR. 3642–3649.
[13]Tianyu Du, Shouling Ji, Jinfeng Li, Qinchen Gu, Ting Wang, and Raheem Beyah.
2019. SirenAttack:GeneratingAdversarialAudioforEnd-to-EndAcousticSys-
tems.arXiv preprint arXiv:1901.07846 (2019).
[14]Tom Fawcett. 2006. An introduction to ROC analysis. Pattern recognition letters
27, 8 (2006), 861–874.
[15]Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and Andrew B Gardner. 2017.
Detecting adversarial samples from artifacts. arXiv preprint arXiv:1703.00410
(2017).
[16]ArthurGill.1962. IntroductiontotheTheoryofFinite-StateMachines .McGraw-Hill.
https://books.google.com.sg/books?id=2IzQAAAAMAAJ
[17]IanGoodfellow,JonathonShlens,andChristianSzegedy.2015. Explainingand
Harnessing Adversarial Examples. In International Conference on Learning Repre-
sentations .http://arxiv.org/abs/1412.6572
[18]Google Accident. 2016. A Google self-driving car caused a crash for the first
time.https://www.theverge.com/2016/2/29/11134344/google-self-driving-car-
crash-report
[19]DanHendrycksandKevinGimpel.2016.Abaselinefordetectingmisclassifiedand
out-of-distribution examples in neural networks. arXiv preprint arXiv:1610.02136
(2016).
[20]GeoffreyHinton,LiDeng,DongYu,GeorgeEDahl,Abdel-rahmanMohamed,
Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara NSainath, et al
.2012. Deep Neural Networks for Acoustic Modeling in Speech
Recognition: The Shared Views of Four Research Groups. IEEE Signal Processing
Magazine 29, 6 (2012), 82–97.
[21]Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, Jürgen Schmidhuber, et al .2001.
Gradientflowinrecurrentnets:thedifficultyoflearninglong-termdependencies.
[22]Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory.
Neural computation 9, 8 (1997), 1735–1780.
[23]Bill G. Horne, C. Lee Giles, Pete C. Collingwood, School Of Computing, Man Sci,
Peter Tino, and Peter Tino. 1998. Finite State Machines and Recurrent Neural
Networks – Automata and Dynamical Systems Approaches. In Neural Networks
and Pattern Recognition . Academic Press, 171–220.
[24]Bo-Jian Hou and Zhi-Hua Zhou. 2018. Learning with Interpretable Structure
from RNN. (oct 2018). arXiv: 1810.10708 http://arxiv.org/abs/1810.10708
[25] Brody Huval, Tao Wang, Sameep Tandon, Jeff Kiske, Will Song, Joel Pazhayam-
pallil,MykhayloAndriluka,PranavRajpurkar,TokiMigimatsu,RoyceCheng-Yue,
Fernando Mujica, Adam Coates, and Andrew Y. Ng. 2015. An Empirical Eval-uation of Deep Learning on Highway Driving. CoRRabs/1504.01716 (2015).
arXiv:1504.01716 http://arxiv.org/abs/1504.01716
[26]Ian Jolliffe. 2011. Principal Component Analysis. In International Encyclopedia of
Statistical Science . Springer, 1094–1096.
[27]JinhanKim,RobertFeldt,andShinYoo.2019.GuidingDeepLearningSystemTest-
ing Using Surprise Adequacy. In Proceedings of the 41st International Conference
on Software Engineering (ICSE ’19) . 1039–1049.
[28]Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial examples
in the physical world. arXiv preprint arXiv:1607.02533 (2016).
[29]Shiyu Liang, Yixuan Li, and R Srikant. 2017. Enhancing the reliability of out-of-
distribution image detection in neural networks. arXiv preprint arXiv:1706.02690
(2017).
[30]Lei Ma, Felix Juefei-Xu, Minhui Xue, Qiang Hu, Sen Chen, Bo Li, Yang Liu,
JianjunZhao,JianxiongYin,andSimonSee.2018. SecureDeepLearningEngi-
neering:ASoftwareQualityAssurancePerspective. arXive-prints (Oct.2018),
arXiv:1810.04538.[31]Lei Ma, Felix Juefei-Xu, Minhui Xue, Bo Li, Li Li, Yang Liu, and Jianjun Zhao.
2019. DeepCT: Tomographic Combinatorial Testing for Deep Learning Systems.
In2019 IEEE 26th International Conference on Software Analysis, Evolution and
Reengineering (SANER) . 614–618.
[32]LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,ChunyangChen,TingSu,LiLi,YangLiu,JianjunZhao,andYadongWang.2018. DeepGauge:
Multi-granularityTestingCriteriaforDeepLearningSystems.In Proc.ofthe33rd
ACM/IEEE Intl. Conf. on Automated Software Engineering (ASE 2018) . 120–131.
[33]LeiMa,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,FelixJuefei-Xu,ChaoXie,LiLi,YangLiu,JianjunZhao,andYadongWang.[n.d.]. DeepMutation:Mutation
Testing of Deep Learning Systems. In 29th IEEE International Symposium on
SoftwareReliabilityEngineering(ISSRE),Memphis,USA,Oct.15-18,2018 .100–111.
[34]ShiqingMa, YingqiLiu,Guanhong Tao, Wen-Chuan Lee, and Xiangyu Zhang.
2019. NIC:DetectingAdversarialSampleswithNeuralNetworkInvariantCheck-
ing. InNDSS. 24–27.
[35]Henry B Mann and Donald R Whitney. 1947. On a test of whether one of
two random variables is stochastically larger than the other. The annals of
mathematical statistics (1947), 50–60.
[36]Jan Hendrik Metzen, TimGenewein, Volker Fischer, and Bastian Bischoff. 2017.
On detecting adversarial perturbations. arXiv preprint arXiv:1702.04267 (2017).
[37]Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.
DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks. CVPR
(2016), 2574–2582.
[38]J. R. Norris. 1997. Markov Chains . Cambridge University Press. https://doi.org/
10.1017/CBO9780511810633
[39]Augustus Odena and Ian Goodfellow. 2018. TensorFuzz: Debugging Neural
Networks with Coverage-Guided Fuzzing. (2018). arXiv: 1807.10875
[40]Christian W Omlin and C Lee Giles. 1996. Extraction of rules from discrete-time
recurrent neural networks. Neural networks 9, 1 (1996), 41–52.
[41]KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017. Deepxplore:Auto-
mated whitebox testing of deep learning systems. In SOSP. 1–18.
[42]PushpendreRastogi,RyanCotterell,andJasonEisner.2016. WeightingFinite-
StateTransductionswithNeuralContext.In Proceedingsofthe2016Conference
oftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:
Human Language Technologies . 623–633.
[43]AlexanderMRush,SumitChopra,andJasonWeston.2015. Aneuralattention
modelforabstractive sentencesummarization. arXivpreprintarXiv:1509.00685
(2015).
[44]Charles Spearman. 1987. The proof and measurement of association between
two things. The American journal of psychology 100, 3/4 (1987), 441–471.
[45]Youcheng Sun, Xiaowei Huang, and Daniel Kroening. 2018. Testing Deep Neural
Networks. arXiv preprint arXiv:1803.04792 (2018).
[46]Youcheng Sun, Min Wu, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska, and
Daniel Kroening. 2018. Concolic Testing for Deep Neural Networks. (2018).
https://doi.org/arXiv:1805.00089v2 arXiv:1805.00089
[47]The BBC. 2016. AI image recognition fooled by single pixel change. https:
//www.bbc.com/news/technology-41845878
[48]The New York Times. 2016. Alexa and Siri Can Hear This Hidden Command.
You Can’t. https://www.nytimes.com/2018/05/10/technology/alexa-siri-hidden-
command-audio-attacks.html
[49]Joe F Thompson, Bharat K Soni, and Nigel P Weatherill. 1998. Handbook of Grid
Generation . CRC press.
[50]YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018. Deeptest:Automatedtestingofdeep-neural-network-drivenautonomouscars.In ICSE.ACM,303–314.
[51]Uber Accident. 2018. After Fatal Uber Crash, a Self-Driving Start-Up Moves
Forward. https://www.nytimes.com/2018/05/07/technology/uber-crash-
autonomous-driveai.html
[52]Jingyi Wang, Guoliang Dong, Jun Sun, Xinyu Wang, and Peixin Zhang. 2018.
AdversarialSampleDetectionforDeepNeuralNetworkthroughModelMutation
Testing.arXiv preprint arXiv:1812.05793 (2018).
[53]Qinglong Wang, Kaixuan Zhang, Alexander G. Ororbia, II, Xinyu Xing, Xue
Liu, and C. Lee Giles. 2018. An Empirical Evaluation of Rule Extraction from
Recurrent Neural Networks. Neural Comput. 30, 9 (Sept. 2018), 2568–2591.
[54]Gail Weiss, Yoav Goldberg, and Eran Yahav. 2017. Extracting Automata from
Recurrent Neural Networks Using Queries and Counterexamples. arXiv preprint
arXiv:1711.09576 (2017).
[55]XiaofeiXie,LeiMa,FelixJuefei-Xu,MinhuiXue,HongxuChen,YangLiu,JianjunZhao,BoLi,JianxiongYin,andSimonSee.2019.DeepHunter:ACoverage-Guided
Fuzz Testing Framework for Deep Neural Networks. In ISSTA.
[56]Xiaofei Xie, Lei Ma, Haijun Wang, Yuekang Li, Yang Liu, and Xiaohong Li. 2019.
DiffChaser: Detecting Disagreements for Deep Neural Networks. In IJCAI.
[57]Weilin Xu, David Evans, and Yanjun Qi. 2017. Feature squeezing: Detecting
adversarialexamplesindeepneuralnetworks. arXivpreprintarXiv:1704.01155
(2017).
[58]Jie M. Zhang, Mark Harman, Lei Ma, and Yang Liu. 2019. Machine Learn-ing Testing: Survey, Landscapes and Horizons. arXiv e-prints (Jun 2019),
arXiv:1906.10742.
487