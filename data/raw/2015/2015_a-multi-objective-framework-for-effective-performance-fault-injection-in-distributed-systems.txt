A Multi-objective Framework for Effective Performance Fault
Injection in Distributed Systems
Luca Traini
University of L’Aquila, Italy
luca.traini@graduate.univaq.it
ABSTRACT
Modern distributed systems should be built to anticipate perfor-
mance degradation. Often requests in these systems involve ten to
thousands Remote Procedure Calls, each of which can be a source
ofperformancedegradation.ThePhDprogrammepresentedhere
intendstoaddressthisissuebyprovidingautomatedinstruments
toeffectivelydriveperformancefaultinjectionindistributedsys-
tems. The envisioned approach exploits multi-objective search-
based techniques toautomatically find small combinations of tiny
performancedegradationsinducedbyspecificRPCs,whichhave
significantimpactsontheuser-perceivedperformance.Automat-
ing the search of these events will improve the ability to inject
performance issues in production in order to force developers to
anticipate and mitigate them.
CCS CONCEPTS
•Software and its engineering →Software performance ;Search-
based software engineering ;
KEYWORDS
FaultInjection,Software Performance,Search-BasedSoftwareEn-gineering, Distributed Systems
ACM Reference Format:
Luca Traini. 2018. A Multi-objective Framework for Effective Performance
Fault Injection in Distributed Systems. In Proceedings of the 2018 33rd
ACM/IEEE International Conference on Automated Software Engineering (ASE
’18), September 3–7, 2018, Montpellier, France. ACM, New York, NY, USA,
4pages.https://doi.org/10.1145/3238147.3241535
1 INTRODUCTION
The current "fast to market" trend has shaped a new way of de-
sign,buildandreleasesoftware.Successfulhigh-techcompanies
deliver new software in production every day [ 7] and perceive this
capability as a key competitive advantage [ 18]. In order to support
this fast-paced release cycle, IT organizations often employ several
This research was supported by the Electronic Component Systems for European
LeadershipJointUndertakingthroughtheMegaMart2project(grantagreementNo
737494).
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3241535independentteamsthatareresponsible"fromdevelopmenttode-
ploy" [17] of loosely coupled independently deployable services
[16]. Despite their benefits, these architectures introduce complex-
ityinperformancemonitoringandtroubleshooting.Eachrequest
involvestentothousandRemoteProcedureCalls(RPCs),eachof
which can introduce some form of performance degradation.
Performance is akey quality aspect of software andhas a huge
impactonuserengagementandsatisfaction[ 5].Inthelastfewyears
severaltools havebeen developedin orderto enhancedevelopers
awareness on the performance behavior of distributed systems
[13,19].Althoughthesetoolscanbeusefulforsystemperformance
debugging, there is lack of techniques to anticipate unexpected
events that could significantly hamper the user perceived software.
Predicting performance issues upfront can be difficult, given the
continuously changing load nature [ 3] and frequent roll out of
software changes. High-tech companies automate failure injection
inproductiontobuildconfidenceinsystemsbehaviorandantici-
pateunexpectedevents[ 4].Thecombinatorialspaceofpotential
failures istoolarge tobe exploredexhaustively,hence inpractice
failure testing solutions rely on two search policies: random searchand programmer-guided search. The former randomly chooses fail-
ures, in favorof speedand simplicity, but itis unlikely to discover
interestingcombinationsoffailures.Thelatterleveragesdomain
expertintuitionstobuildheuristicscapabletofindmoreinteresting
failures scenarios, but it is fundamentally unscalable. Recent work
fromAlvaroetal.[ 1]haveshowedpromisingresultsinguidingthe
search through a more structured policy.
The envisioned approach proposed in this paper provides a
framework, which turns the problem of finding "interesting combi-
nations" of performance issues into a multi-objective search prob-
lem. The rationale at the basis of this approach is that the concept
of "interesting combination" includes several objective often in
tradeoff. For example, if we inject a huge latency in all the services
involved in all user requests, then this certainly has a negative im-
pactonthesystem,butitisnotinteresting,becauseitisobviousand
isnotlikelytohappeninrealsystems.Lessevidentcombinations
that may lead to performance degradations are more interesting
anddifficulttodetect.Thekeyideaistosearchforcombinationsofperformanceissuesbyminimizingthenumberofissuesintroduced
(we will term it cardinality ), and their intensity (e.g. the amount
of latency introduced) while maximizing the impacton the user-
perceivedperformance.Clearlythehigherwillbenumberofissues
introduced and their intensity the higher will be the impact.B y
using a Pareto-optimal search-based approach we will not sacrifice
solutionswithhigh cardinality and/or intensity whentheyhavea
significant impact, but they will be always dominated by combina-
tionswithlowersvaluesof cardinality /intensity whentheycause
the same impact.
936
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:51:02 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Luca Traini
We envisage that automated search with appropriate objectives
can help in identifying interesting combinations of performance
issues which have significant impact on the user-perceived perfor-
mance.
2 ENVISIONED APPROACH
2.1 Approach
TheapproachisinspiredbytheworkofAlvaroetal.[ 1],whichisa
first attempt to guide the search of combinations of fault injection
withastructuredpolicy[ 2].Thisworkisrelatedtofunctionalas-
pects ofdistributedsystems, whereasthe approachproposed here
focuses on performance aspects. The goal is to provide automation
to fault injection in distributed systems by improving the search
of interesting combinations of performance issues. In this paper
we introduce a conceptual framework, on top of which customized
instantiations oftheapproachcanbebuilt.Theframeworkisbased
on several components, where the semantics and the way they
interact will be described in the following. Each instantiation of
our approach is obtained by implementing these components in
a specific context. An instantiation defines the kind of targeted
performance issues and the way on which their "interesting" com-
binationswillbesearched.Inordertobuildan instantiation,fiv e
core questions have to be addressed:
(1)Which kinds of performance issues are targeted ?
Distributed systems can experience different kinds of perfor-
manceissues.Network latencyspikes,performancebugs[ 12],
hardware failures are only few examples. An instantiation of
ourapproachhastochooseoneormoretypeofperformance
issues as target.
(2)How do we model the intensity of combinations of per-
formance issues?
Different types of performance issues have different properties.
Some of these properties define the severity of performance
issues, for example in network latency spikes a property could
be the latency introduced and/or the percentage of traffic af-
fected by the problem. An instantiation has to provide a way
to synthesize interesting properties of targeted performance
issues in a single value. Hence, given any possible combination
of performance issues, the approach has to derive this value,
whichwillbenamed intensity.Intuitively,byfollowingprevious
examples,higherlatenciesormorepercentageofaffectedtraffic
will induce higher intensity.
(3)What are the impacts we are interested to?
Performanceissuescanhavedifferent impactsonthesystem.
Some can be strictly related to the user-perceived performance
properties,otherscanbecorrelatedtoinnercharacteristicsof
thesystem,suchastheenergyconsumptionofserversorthe
costofcloudresources.Ourapproachisdevisedtosimultane-
ously support different types of impacts, and an instantiation
has to define what are the interesting ones.
(4)How do we estimate the impact of combinations of per-
formance issues?
The intensity of a combination of performance issues is not
always strictly correlated with their impacton the system per-
formance.IncontextswhererequestsinvolvesmultipleRPCs,
performanceissueswiththesame intensity indifferentRPCs
Figure 1: Calls among services in requests of classes X and Y
can have different impacton the system behavior. Trivially, for
example,morefrequentlyinvokedRPCshavemore impactthan
less frequently invoked ones. An instantiation has to provide a
way to estimate impactsof interest.
(5)H o wd ow e search for interesting combinations of per-
formance issues?
Thegoalhereistofindinterestingcombinations,i.e.theones
with higher impactson the system. However, not all combi-
nations are interesting, for example if we consider huge la-tencies, then they will clearly have huge impacts, but they
do not sharply provide useful information on which are theperformance-critical elements of a system. Combinations ofperformanceissueswithlower intensity aremoreinteresting
than others. In fact, if a latency introduced in a particular RPC
has a negative impacton the system, then the most interesting
valuetoidentifyisthesmallestlatencyabletoproducethat im-
pact.Thisvalue, infact,representsa criticalthresholdtokeep
into account for effective fault injection. Furthermore, light
combinations of performance issues are most likely to happen
in production, hence they are more interesting. The number of
performance issues considered in a combination will be named
ascardinality.
Theproblemofsearchinginterestingcombinationscanbeturned
into a multi-objective search problem, with the following ob-jectives: 1) maximize all the impactsconsidered, 2) minimize
intensity and 3) minimize cardinality.
ThroughtheuseofPareto-optimality,thisapproachdoesnot
neglect combinations with high cardinality and high inten-
sitywhentheyaretheonlyonestoshowasignificant impact,
whereasothersolutionscanreplacethelatteronesiftheyshow
same impactwith lower cardinality and lower intensity. In-
stantiations have to provide appropriate Search Based Software
Engineering techniques [10] to solve the problem.
Differentanswerstothesequestionswillprovidedifferent instan-
tiationsof theapproach. Oneof thegoal of thisresearch program
will be to provide several instantiations.
2.2 Explanatory example
Inordertoprovideabetterunderstandingoftheproposedframe-
work, an illustrative coarse instantiation in a specific scenario is
introduced here. The scenario is not very representative of real ap-
plications,butitisusefultogiveinsightsonhowtheapproachcould
beinstantiatedandhowinterestingcombinationsofperformance
issues can be searched.
Scenario. The context, as sketched in Figure 1, is a web applica-
tion composed by 5 services named {A, B,C,D,E}. The application
providesonlytwoURLsaccessiblebyusers,oneprovidedbyservice
937
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:51:02 UTC from IEEE Xplore.  Restrictions apply. A Multi-objective Framework for Effective Performance Fault Injection ASE ’18, September 3–7, 2018, Montpellier, France
Aand the other provided by B. Any request to each of these URLs
willproducealwaysthesamepathofcallsamongtheapplication
services. Hence, two different classes of requests can be defined,
named XandY. When a request of class Xoccurs in the system,
theservice Aisfirstcalled,thereafter Acalls Cwhich,inturn,calls
Dthat call E. When a request of class Yoccurs in the system, the B
is first called which, in turn, calls Dthat calls E. We assume that a
performancerequirementisassociatedtoeachrequestclass,which
imposes that their average response times should be under certain
thresholds named tXandtY. We also assume to have monitored
theseresponsetimes,andtheiraveragevalueswillbedenotedas
rXandrY, respectively.
Instantiation. I will explain the illustrative instantiation by
answering the previously introduced questions:
(1)Which kinds of performance issues are targeted?
Triviallyhereweconsiderthelatencythatcanbeintroduced
in each service (in addition to its own response time), as our
targetedperformanceissues.Forexampleifarequestofclass X
occursinthesystem,latencycanbeintroducedinservices A,
C,DandE.
(2)How do we model the intensity of combinations of performance
issues?
Theonlypropertyconsideredinthis instantiation istheamount
of additional latency introduced in a service. If the service in
whichthelatencyisintroducedis Athenthisamountwillbe
denoted as lA. A straightforward way to synthesize intensity
couldbetosumalllatenciesintroducedinthecombination.For
example, a combination of performance which introduces a lA
latency in service Aand a lBlatency in service Bwill have a
lA+lBintensity.
(3)What are the impacts we are interested to?
Inordertokeeptheillustrativeexampleassimpleaspossible,
thisinstantiation considers only one impact. Here the impact
is defined as the number of classes of requests for which the
performancerequirement isviolated. Inour casewe havetwo
requests classes, hence the maximum impactvalue will be 2
when the performance requirements are both violated.
(4)How do we estimate the impact of combinations of performance
issues?
In order to give insights on the meaning of "estimating impact",
weintroducehereasimpleimplementationofthisconcept.The
problem of estimating impactshifts into the problem of check-
ing, for each class, if its performance requirement is violated.
Sinceforanyrequestclass Citsresponsetime rCisknown,this
information can be exploited in order to quantify the impact
of a combination of performance issues. For example a com-
bination of performance issues composed by latencies lB,lA
andlE,leadstoviolatetheperformancerequirementassociated
to request of class YiflB+lE+rY>tY. Note that lAdoes
not appear in this constraint because service Ais not involved
inthepathoriginatedbyrequestsofclass Y,thusintroducing
latency in Awill not affect the service Yresponse time. Hence,
wecanquantify impactofacombinationofperformanceissues
bysimplyiteratingforeachrequestclass,andbyincreasingthe
impactbyoneifthecombinationinducestheviolationofthe
requirement imposed on that class.(5)How do we search for interesting combinations of performance
issue?
Clearlytheaimwillbetomaximizethenumberofperformance
requirements violated by the performance issues combination,
namelythe impact.Triviallylargevaluesoflatencieswilleasily
leadtoviolaterequirements.Forexample,ifweintroduceahugelatency
lEinservice E,whichisinvolvedinbothclasses,thiswill
clearly have the maximum impact, but it will not really provide
useful information about the performance criticality of specific
services.Amoreinterestingvalueisinsteadtheminimum lE
that leads to violate the requirement, hence we also need tominimize the intensity of the performance issues introduced.
Widelyusedmulti-objectiveevolutionaryalgorithms,suchas
NSGA-II[6], can be adopted for this task.
2.3 Instantiations
AmajorchallengeofthisPhDprogramwillbetoprovideseveral
instantiation of the presented approach. The previously described
instantiation isintentionallysimple.Obviously,inordertomodel
thecomplexityofreal-worlddistributedsystems,moreelaborate
instantiations shall be devised.
Forexample,beyondlatency-relatedproblemsmentionedbefore,
other performance issues can be targeted, e.g., utilization of re-sources such as CPU or memory. Also, performance issues can
haveseveralproperties,forexampleinthecontextoflatencyissuestheseotherpropertiescanbeconsidered:rateofimpactedrequests,
average response time, standard deviation, percentiles, etc. The
higherthenumberofpropertiesandtheircomplexity,theharder
willbetodefineasynthesisof intensity.Wedonotexcludethat,for
some instantiation, intensityshall be split in two or more concepts.
Also, the concept of impactshall be more realistic with respect
to the one presented in the explanatory example. A refinement
ofimpactcanbeobtainedbyconsideringthenumberofrequests
impacted by arequirement violation according tothe workload of
theapplication,ratherthanthenumberofclassesofrequestsfor
whicharequirementisviolated,.Certainlyaverycriticalpointto
developwillbetheestimationof impact.Thetechniqueusedinthe
illustrativeexampleisabitshallow,partlybecausethepropertiesofperformancearelimitedandbecausethenotionof impactisoverly
reductive.Morecomplexnotionsofpropertiesofperformanceissueandimpactwillrequiremoreelaborateestimationtechniques,suchasmachinelearning(i.e.,regressionsmodels,neuralnetworks,etc.)
or Markov models.
From a search perspective, we plan to choose suitable search algo-
rithmsaccordingtothe instantiation,suchasNSGA-II,whichare
widely used in search-based software engineering [10].
3 EXPECTED CONTRIBUTION
TheexpectedcontributionofthisPhDprogramistodemonstrate
how multi-objective search-based techniques can be applied effec-
tively for automated fault-injection. The research questions that
are intended to be addressed are:
(1)Can this framework be used to target different kinds of perfor-
mance issues?
(2)What are the challenges of employing instantiations in real-
world systems?
938
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:51:02 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France Luca Traini
(3)Doinstantiations of the approach outperform state-of-practice
approaches ?
In order to evaluate RQ1 I am planning to build different instantia-
tionswith different kinds of targeted performance issues.
This research program relays on an industrial PhD grant, in col-
laborationwith Microsoft andKarlsruheInstitute of Technology.
Therefore, I am collaborating with Microsoft to identify real-world
distributed systems for sake of experimentation, where the instan-
tiationsproduced can be validated. One of the key challenges of
pushing research in production system is the impedance mismatch
between the model of reality of the research prototype and the
often messy realities of production systems [ 1]. This experience
will be very useful to gain feeling on the criticality of adapting
instantiations for real-world scenario, therefore to answer RQ2.
Atthebestofmyknowledge,anoverlyusedstate-practiceinau-
tomated fault-injection is random search [ 1]. For each instantia-
tionproduced, I’m planning to compare, both in laboratory and
in real-world systems, random fault-injection with the proposedmulti-objective approach (RQ3). This can be done, for example,by iteratively comparing the actual effect on real systems of ran-domcombinationsofperformanceissuesagainsttheirdominant
solutions founded by the search.
4 RELATED WORK
Faultinjectionisaquitematuresubjectinliterature[ 8,9,14].Inthe
lastfewyearsfaultinjectionisgainingincreasingattentionanditis
used in production by high-tech companies [ 4,11]. A recent work
fromAlvaroetal.[ 1]isthefirstattempttodeviseamoreeffective
strategywithrespecttostate-of-practicerandomfaultinjection,by
smartly searching the combinatorial space of possible failures. The
workpresentedinthispaperdiffersfromtheonefromAlvaroet
al.byamoredirectedfocusonperformanceissuesofdistributed
systems, and by a different formulation of the problem, in that
weformulatetheproblemoffindinginterestingcombinationsof
performance issue as a multi-objective optimization problem.
The problem of anticipating unexpected performance behaviors in
modernlarge-scaledistributedsystemshasbeentackledindiffer-
entways.Severalworksaimatdevisingtracinginfrastructuresto
provide developers performance awareness on distributed systems.
Some tools requires explicit instrumentations [ 13,15,19] while
othersdonotrequireit[ 3].Althoughthesetoolscanbeveryuse-
ful for performance debugging of distributed systems, they relyuniquely on developer intuition to anticipate unexpected events.More sophisticated experimentation-oriented approaches aim at
anticipatingunexpectedsystembehaviors.Forexample,inorderto
anticipate system behavior in face of unexpected workload spikes,
theworkofVeeraraghavanetal.[ 20]useslivetraffictoloadtestthe
systemandidentifyscalabilitylimits.JustRunIt[ 21]proposesthe
useofsandboxeddeploymentsthatcanexecuteshadowtrafficfrom
a real world deployment to answer various "what-if" questions.
5 CONCLUSION
InthispaperIpresentamulti-objectiveframeworkforperformancefaultinjectionindistributedsystems.Combinationsofperformance
issues can have different kinds of impacts on a system, and smaller
combinations with non-negligible impacts are more interestingthan others, because they are harder to be identified. This leadsto competing objectives often in conflict. The space of possible
combinations of performance issues is too large to be exhaustively
explored. The strength of this framework lays on the intuition
of exploiting search-based software engineering techniques for
effectiveperformancefaultinjection.Theframeworkisintendedto
be general, several instantiations can be devised. I will evaluate the
applicabilityoftheproduced instantiations inreal-worlddistributed
systems.Ialsoplantocompare,bothinlaboratoryandinreal-world
applications,theeffectivenessoftheproduced instantiations against
state-of-pratice fault injections approaches.
REFERENCES
[1]Peter Alvaro, Kolton Andrus, Chris Sanden, Casey Rosenthal, Ali Basiri, and
Lorin Hochstein. 2016. Automating Failure Testing Research at Internet Scale. In
the ACM Symposium on Cloud Computing. 17–28.
[2]Peter Alvaro, Joshua Rosen, and Joseph M. Hellerstein. 2015. Lineage-driven
Fault Injection. In SIGMOD. 331–346.
[3]DanArdelean,AmerDiwan,andChandraErdman.2018. PerformanceAnaly-
sisofCloudApplications.In the Symposium on Networked Systems Design and
Implementation. 405–417.
[4]Ali Basiri, Niosha Behnam, Ruud de Rooij, Lorin Hochstein, Luke Kosewski,
JustinReynolds,andCaseyRosenthal.2016. ChaosEngineering. IEEE Software
33, 3 (May 2016), 35–41.
[5]JakeBrutlag.2009. Google AIBlog:Speedmatters. https://ai.googleblog.com/
2009/06/speed -matters.html
[6]Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and T. Meyarivan. 2002. A
Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II. IEEE Transaction
Evolutionary Computation 6, 2 (April 2002), 182–197.
[7]Dror Feitelson, Eitan Frachtenberg, and Kent Beck. 2013. Development and
Deployment at Facebook. IEEE Internet Computing 17, 4 (July 2013), 8–17.
[8]Haryadi S. Gunawi, Thanh Do, Joseph M. Hellerstein, Ion Stoica, Dhruba
Borthakur, and Jesse Robbins. 2011. Failure as a Service (FaaS): A Cloud Ser-
vice for Large-Scale, Online Failure Drills. TechnicalReport. http://www2.eecs.
berkeley.edu/Pubs/TechRpts/2011/EECS-2011-87.html
[9]Haryadi S. Gunawi, Thanh Do, Pallavi Joshi, Peter Alvaro, Joseph M. Hellerstein,
Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau, Koushik Sen, and Dhruba
Borthakur. 2011. FATE and DESTINI: A Framework for Cloud Recovery Testing.
Inthe Conference on Networked Systems Design and Implementation. 238–252.
[10]Mark Harman,S.Afshin Mansouri,and YuanyuanZhang. 2012. Search-based
SoftwareEngineering:Trends,TechniquesandApplications. Comput. Surveys
45, 1, Article 11 (Dec. 2012), 11:1–11:61 pages.
[11]LorinHochstein andCaseyRosenthal. 2016. ChaosEngineering Panel.In ICSE
(Companion). 90–91.
[12]Guoliang Jin, Linhai Song, Xiaoming Shi, Joel Scherpelz, and Shan Lu. 2012.
Understanding and Detecting Real-world Performance Bugs. In PLDI. 77–88.
[13]Jonathan Kaldor, Jonathan Mace, MichałBejda, Edison Gao, Wiktor Kuropatwa,
Joe O’Neill, Kian Win Ong, Bill Schaller, Pingjia Shan, Brendan Viscomi, Vinod
Venkataraman,KaushikVeeraraghavan,andYeeJiunSong.2017. Canopy:An
End-to-End Performance Tracing And Analysis System. In SOSP. 34–50.
[14]Ghani A. Kanawati, Nasser A. Kanawati, and Jacob A. Abraham. 1995. FERRARI:
A Flexible Software-Based Fault and Error Injection System. IEEE Transanctions
on Computers 44, 2 (Feb. 1995), 248–260.
[15]JonathanMace,RyanRoelke,andRodrigoFonseca.2015. PivotTracing:Dynamic
Causal Monitoring for Distributed Systems. In the Symposium on Operating
Systems Principles. 378–393.
[16] Sam Newman. 2015. Building Microservices (1st ed.). O’Reilly Media, Inc.
[17]Charlene O’Hanlon. 2006. A Conversation with Werner Vogels. Queue4, 4,
Article 14 (May 2006), 14:14–14:22 pages.
[18]Julia Rubin and Martin Rinard. 2016. The Challenges of Staying Together While
Moving Fast: An Exploratory Study. In ICSE. 982–993.
[19]Benjamin H. Sigelman, Luiz André Barroso, Mike Burrows, Pat Stephenson,
ManojPlakal,DonaldBeaver,SaulJaspan,andChandanShanbhag.2010. Dapper,
a Large-Scale Distributed Systems Tracing Infrastructure.TechnicalReport.Google,
Inc.https://research.google.com/archive/papers/dapper-2010-1.pdf
[20]Kaushik Veeraraghavan, Justin Meza, David Chou, Wonho Kim, Sonia Mar-
gulis, Scott Michelson, Rajesh Nishtala, Daniel Obenshain, Dmitri Perelman,
andYeeJiunSong.2016. Kraken:LeveragingLiveTrafficTeststoIdentifyand
ResolveResourceUtilizationBottlenecksinLargeScaleWebServices.In OSDI.
635–651.
[21]Wei Zheng, Ricardo Bianchini, G. John Janakiraman, Jose Renato Santos, and
YoshioTurner.2009. JustRunIt:Experiment-basedManagementofVirtualized
Data Centers. In the USENIX Annual Technical Conference. 18–18.
939
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:51:02 UTC from IEEE Xplore.  Restrictions apply. 