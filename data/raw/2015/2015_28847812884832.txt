Efï¬cient Large-scale Trace Checking Using MapReduce
Marcello M. Bersani1, Domenico Bianculli2, Carlo Ghezzi1, SrÂ¯dan Krsti Â´c1and Pierluigi San Pietro1
1DEEPSE group - DEIB - Politecnico di Milano, Milano, Italy
2SnT Centre - University of Luxembourg, Luxembourg, Luxembourg
marcellomaria.bersani@polimi.it, domenico.bianculli@uni.lu, carlo.ghezzi@polimi.it,
srdan.krstic@polimi.it, pierluigi.sanpietro@polimi.it
ABSTRACT
The problem of checking a logged event trace against a tem-
poral logic specication arises in many practical cases. Un-
fortunately, known algorithms for an expressive logic like
MTL (Metric Temporal Logic) do not scale with respect
to two crucial dimensions: the length of the trace and the
size of the time interval of the formula to be checked. The
former issue can be addressed by distributed and parallel
trace checking algorithms that can take advantage of modern
cloud computing and programming frameworks like MapRe-
duce. Still, the latter issue remains open with current state-
of-the-art approaches.
In this paper we address this memory scalability issue by
proposing a new semantics for MTL, called lazy semantics.
This semantics can evaluate temporal formulae and boolean
combinations of temporal-only formulae at any arbitrary
time instant. We prove that lazy semantics is more expres-
sive than point-based semantics and that it can be used as
a basis for a correct parametric decomposition of any MTL
formula into an equivalent one with smaller, bounded time
intervals. We use lazysemantics to extend our previous dis-
tributed trace checking algorithm for MTL. The evaluation
shows that the proposed algorithm can check formulae with
large intervals, on large traces, in a memory-ecient way.
1. INTRODUCTION
Software systems have become more complex, distributed,
and increasingly reliant on third-party functionality. The
dynamic behavior of such systems makes traditional design-
time verication approaches unfeasible, because they cannot
analyze all the behaviors that can emerge at run time. For
this reason, techniques like run-time verication and trace
checking have become viable alternative for the verication
of modern systems. While run-time verication checks the
behavior of a system during its execution, trace checking is
Work partially funded by National Research Fund, Lux-
embourg (FNR/P10/03); EC grant no. 644869 (EU H2020),
DICE; Italian PRIN Project 2010LYA9RH 006.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proï¬t or commercial advantage and that copies bear this notice and the full cita-
tion on the ï¬rst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciï¬c permission
and/or a fee. Request permissions from permissions@acm.org.
ICSE â€™16, May 14-22, 2016, Austin, TX, USA
c2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI:http://dx.doi.org/10.1145/2884781.2884832apost-mortem technique. In other words, to perform trace
checking one must rst collect and store relevant execution
data (called execution traces or logs) produced by the sys-
tem and then check them oine against the system speci-
cations. This activity is often done to inspect server logs,
crash reports, and test traces, in order to analyze problems
encountered at run time. More precisely, trace checking1is
an automatic procedure for evaluating a formal specication
over a trace of recorded events produced by a system. The
output of the procedure is called verdict and states whether
the system's behavior conforms to its formal specication.
The volume of the execution traces gathered for modern
systems increases continuously as systems become more and
more complex. For example, an hourly page trac statis-
tics for Wikipedia articles collected over a period of seven
months amounts to 320GB of data [27]. This huge volume of
trace data challenges the scalability of current trace checking
tools [7,16,18,25,26], which are centralized and use sequen-
tial algorithms to process the trace. One possible way to
eciently perform trace checking over large traces is to use
a distributed and parallel algorithm, as done in [3, 5] and
also in our previous work [10]. These approaches rely on
the MapReduce framework [14] to handle the processing of
large traces. MapReduce is a programming model and an
underlying execution framework for parallel and distributed
processing of large quantities of data stored on a cluster of
dierent interconnected machines (or nodes). In [10] we pro-
posed a MapReduce algorithm that checks very large execu-
tion traces against formal specications expressed in metric
temporal logic ( MTL); the algorithm exploits the structure
of the formula to parallelize its evaluation.
MTL [19] is a class of temporal logic used for the speci-
cation and verication of real-time systems. It extends the
well-known\Until "temporal operator of the classic LTLwith
an interval that indicates the time distance within which
the formula must hold. For example, the property \A cov-
ered entity [. . . ] must retain the documentation [. . . ] for
6 years from the date of its creation." is a simplied ver-
sion of a policy taken from the US HIPAA [24]. It can
be expressed, for a particular document, as: G(create!
(:delete U =6 years delete), where the operator U(called \ Un-
til") states that its right operand, the delete event, must oc-
cur in exactly six years (i.e., 189 :2 billion ms, assuming a mil-
lisecond granularity in the log) from the moment of creation
(expressed with the event create). It also states that the left
operand (:delete) must hold until that happens. Operator G
(called \ Globally ") states that property holds over the whole
1Also called trace validation [23] or history checking [17].
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   888
trace. In this logic, time can be expressed using either in-
teger or real time-stamps. MTL specications may express
properties that refer to dierent parts of the trace or to large
portions of the trace at once by using large time intervals. In
the example above, to check if the \ Until " subformula holds
in a single position of the trace, the algorithm needs to con-
sider a portion of the trace corresponding, in the worst case,
to six years of logged data. To check the whole formula,
this process needs to be performed for every position in the
trace because of the outer \ Globally " operator. Generally
speaking, trace checking algorithms scan a trace and buer
the events that satisfy the temporal constraints of the for-
mula. The buer is incrementally updated as the trace is
scanned and the algorithms incrementally provide verdicts
for the positions for which they have enough information
(to determine the verdict). The lower-bound for memory
complexity of trace checking algorithms is known to be ex-
ponential in the numeric constants occurring in the MTL
formula encoded in binary [26]. Therefore the strategy of
buering events creates a memory scalability issue for trace
checking algorithms. This issue also aects distributed and
parallel solutions, including our previous work [10]. Specif-
ically, the memory scalability of a trace checking algorithm
on a single cluster node depends exponentially on the nu-
meric constants dening the bounds of the time intervals in
theMTL formula to be checked.
The goal of this paper is to address this memory scalabil-
ity issue by proposing a trace checking algorithm that ex-
ploits a new semantics for MTL, called lazy semantics. Un-
like traditional point-based semantics [19], our lazy seman-
tics can evaluate both temporal formulae and boolean com-
binations of temporal-only formulae at any arbitrary time
instant, while it evaluates atomic propositions only at time-
stamped positions of the trace. We propose lazy semantics
because it possesses certain properties that allow us to de-
compose any MTL formula into an equivalent MTL formula
where the upper bound of all time intervals of its temporal
operators is limited by some constant. This decomposition
plays a major role in the context of (distributed) trace check-
ing of formulae with large time intervals. In practice, if we
want to check a formula with a large time interval, apply-
ing the decomposition entails an equivalent formula, with
smaller time intervals. This new formula can be checked in
a more memory ecient way by using our new trace checking
algorithm, which applies lazy semantics.
We show that lazy semantics does not hinder the expres-
sive power of MTL : we prove that MTL interpreted over lazy
semantics is strictly more expressive than MTL interpreted
over point-based semantics. In other words, any MTL for-
mula interpreted over point-based semantics can be rewrit-
ten using an MTL formula interpreted over lazy semantics.
Moreover, there are MTL formulae interpreted over lazy se-
mantics that do not have an equivalent formula that can be
interpreted over point-based semantics. We have integrated
lazy semantics and the modied distributed trace checking
algorithm into our MTLMapReduce tool [20], implemented
using the Apache Spark framework. The evaluation shows
that the proposed approach can be used to check formulae
with very large time intervals, on very large traces, while
keeping a low memory footprint. This footprint is com-
patible with the available conguration of common cloud
instances. Moreover, our tool performs better, in terms of
memory scalability, than our previous implementation [10].We have also assessed the time and memory tradeos of the
algorithm with respect to the decomposition parameter.
In summary, the specic contributions of this paper are:
1) A new semantics for MTL, called lazysemantics; we prove
that it is strictly more expressive than point-based seman-
tics. 2) A parametric decomposition of MTL formulae into
MTL formulae where the upper bound of all time intervals is
limited by some constant; 3) A new trace checking algorithm
that exploits lazy semantics and parametric decomposition,
to check MTL formulae in a memory-ecient way; 4) The
evaluation of the proposed algorithm in terms of memory
scalability and time/memory tradeos.
The rest of the paper is structured as follows. Section 2
briey introduces MTL interpreted over point-based seman-
tics and the MapReduce programming model. Section 3
overviews our approach and motivates the need for lazy se-
mantics and the parametric decomposition of MTL formulae.
Lazy semantics is introduced in Section 4. Section 5 de-
tails the parametric decomposition of MTL formulae. Sec-
tion 6 introduces our distributed trace checking algorithm
that supports lazy semantics. Section 7 reports on the evalu-
ation of our implementation. Section 8 surveys related work,
while Section 9 concludes the paper.
2. PRELIMINARIES
2.1 Point-based Semantics for MTL
LetIbe any non-empty interval over Rwith endpoints
inNand let  be a nite set of atomic propositions (or
atoms ). The syntax of MTL is dened by the following gram-
mar, where p2 and UIis the metric \Until " operator:
::=pj:j_jUI. Additional boolean and tem-
poral operators can be derived using the usual conventions:
\Eventually " is dened as FI>UI; \Globally " is dened
asGI:FI:. We adopt the convention that an interval
of the form [ i;i] is written as \= i". The interval [0 ;+1) in
temporal operators is omitted for simplicity. We introduce
the following shorthand notation: FK()FF:::F|{z}
Ktimes(), with
F0() =. Hereafter we refer to point-based semantics for
MTL asMTL Psemantics.
MTL Psemantics. We focus on the nite-word semantics
ofMTL , since we apply it to the problem of trace check-
ing. A timed sequence , of lengthjj>0, is a sequence
01:::jj 1of valuesi2Rsuch that 0 < i< i+1for
each 0i<jj 1, i.e., the sequence is strictly monotonic .
Awordover the alphabet 2is a sequence 01:::jj 1
such thati22for all 0i<jj, wherejjdenotes the
length of the word. A timed word [1]!=!0!1:::!j!j 1is
a word over 2R, i.e., a sequence of pairs !i= (i;i),
where0:::j!j 1is a word over 2and0:::j!j 1is a
timed sequence. A pair !iis also called an element of the
timed word. Moreover, notice that in this denition irefers
to a particular position of the element !iin the timed word
!, whileirefers to the time instant ortime-stamp of the
element!i. We abuse the notation and represent a timed
word equivalently as a pair containing a word and a timed se-
quence of the same length, i.e., != (;). A timed language
over 2is a set of timed words over 2.MTL Psemantics
on timed words is given in Figure 1, where the point-based
satisfaction relation j=Pis dened with respect to a timed
word (; ), a position i2N, atomp2, and MTL for-
889(;;i)j=Ppip2iforp2
(;;i)j=P:i (;;i)6j=P
(;;i)j=P_ i (;;i)j=Por (;;i)j=P 
(;;i)j=PUI i9j:(ij <jjandj i2Iand
(;;j )j=P and8k:(i<k<j then (;;k )j=P))
Figure 1: MTL Psemantics on timed words.
mulaeand . Note that, due to the strictly monotonic
denition of the timed sequence , the metric \ Next " oper-
ator can be dened as XI? UI f0g.LP() is a timed
language dened by a formula when interpreted over the
MTL Psemantics, i.e., LP() =f(; )j(;; 0)j=Pg.
2.2 The MapReduce programming model
MapReduce [14] is a programming model, developed by
Google, for processing and analyzing large data sets using
a parallel, distributed infrastructure. The MapReduce pro-
gramming model uses two user-dened functions, map and
reduce, that are inspired by the homonymous functions that
are typically found in functional programming languages.
The map function receives a key-value pair associated with
the input data and returns a set of intermediate key-value
pairs; its signature is map(k:K 1,v:V 1):list[(k:K 2, v:V 2)].
The reduce function is applied to all the intermediate values
that have the same intermediate key, in order to combine the
derived data appropriately; its signature is reduce(k:K 2,
list(v:V 2)):list[v:V 2]. In the denitions above, K1and
K2are types for keys and V1and V2are types for values.
Besides the actual programming model, MapReduce is
also a framework that provides, in a transparent way to de-
velopers, parallelization, fault tolerance, locality optimiza-
tion, and load balancing. The MapReduce framework is
responsible for partitioning the input data, scheduling and
executing the Map and Reduce tasks (also called mappers
and reducers , respectively) on a cluster of available nodes,
and for managing communication and data transfer (usually
leveraging a distributed le system). More in detail, the ex-
ecution of a MapReduce operation (called job) proceeds as
follows. First, the system splits the input into blocks of a cer-
tain size and parses them using an InputReader , generating
input key-value pairs. It then assigns each input key-value
pair to a mapper, which processes it in parallel on the nodes
of the distributed infrastructure. A mapper passes the set of
key-value pairs to the map function, which generates a set
of intermediate key-value pairs. Notice that each run of the
map function is stateless, i.e., the transformation of a single
key-value pair does not depend on any other key-value pair.
The next phase is called shue and sort : it takes the inter-
mediate data generated by each mapper, sorts them based
on the intermediate key, divides these data into regions to
be processed by reducers, and distributes these data on the
nodes where the reducers will be executed. The division
of intermediate data into regions is done by a partitioning
function, which depends on the (user-specied) number of
reducers and the key of the intermediate data. Each re-
ducer executes the reduce function, which produces the out-
put data. This output is appended to a nal output le for
this reduce partition. The output of the MapReduce job is
available in several les, one for each used reducer. Mul-
tiple MapReduce calls can be chained together to perform
complex data processing.Atoms:fpg fpg fqg fp;qg fp;qg fqg fqg
Time-stamps: 1 2 4 6 8 9 10
Time instants: 1 2 3 4 5 6 7 8 9 10
p > > ? > > ? ?
F[3;7](p)>> > ? ? ? ?
Figure 2: Evaluation of formula  = F[3;7](p).
3. MOTIVATION AND OVERVIEW OF THE
APPROACH
As mentioned in Section 1, trace checking is an automatic
procedure for evaluating a formal specication over a trace
of recorded events produced by a system. Since traces can
be seen as a sequence of time-stamped elements (where each
element records one or more events), we use timed words
as abstract models of traces. Hence, a pair !i= (i;i)
corresponds to the i-th element of the trace, where atoms in
irepresent all the events with time-stamp i.
Trace checking algorithms handle metric temporal oper-
ators by buering elements of the trace. The time interval
specied in the metric temporal formula to be checked deter-
mines the portion of the trace to be considered for emitting
a verdict in a single position of the trace. Depending on the
particular MTL formula to be checked, in the worst case this
process needs to be repeated for every position in the trace2.
What trace checking algorithms typically do is to keep the
relevant portion of the trace in a buer as they scan the
trace. The buer is updated incrementally while the algo-
rithm scans and produces verdicts for the next elements in
the trace. The procedure for updating the buer consists of
adding a newly-scanned element eof the trace and removing
the elements whose time-stamps do not satisfy the temporal
constraint of the formula to be checked, when evaluated with
respect to the time-stamp of e. Buering elements presents
a memory scalability issue if a metric temporal formula with
a large time interval needs to be checked. Let us present an
example to motivate the need for lazy semantics.
Example 1.Consider formula  = F[3;7](p)and its eval-
uation on the following trace (represented as a timed word):
(fpg; 1),(fpg; 2),(fqg;4),(fp;qg;6),(fp;qg;8),(fqg;9),
(fqg;10). The timed word, shown in Figure 2, is dened over
the set of atoms  =fp;qg; its length is 7 and it spans over
10 time units. The rst two rows in the picture represent
its atoms and time-stamps; the last two rows show, respec-
tively, the evaluation of subformula pand formula F[3;7](p)
using point-based semantics. As shown in the last row of Fig-
ure 2, according to point-based semantics, formula F[3;7](p)
holds at time instants 1, 2 and 4.
For a formula of the form3F[a;b](p), the algorithm needs to
buer, in the worst case (i.e., in case there exists an element
at every time instant), at most b+ 1 elements. For example,
to evaluate formula F[3;7](p) at time instant 2, in the worst
case the algorithm will buer 8 elements, i.e., all the ele-
ments whose time-stamp ranges from 2 to 9. The elements
2For example, if a \ Globally " temporal operator is used.
3We consider the most general case in which MTL formulae
can be arbitrarily nested. This means that a trace checking
algorithm has to evaluate every subformula in every posi-
tion of the trace. Nevertheless, more specic cases could use
heuristics based on the actual values of the temporal inter-
vals in the formula and hence reduce the number of positions
in the trace in which the formula is evaluated.
890with time-stamps ranging from 6 to 9 satisfy the time in-
terval constraint of the formula; the others are kept for the
evaluation of the formula at subsequent positions. Let us
assume that the execution infrastructure could only store 5
elements in the buer, because of the limited available mem-
ory. The worst-case requirement of keeping 8 elements in the
buer would then be too demanding for the infrastructure,
in terms of memory scalability. To lower the memory re-
quirement for the buer we would need a formula with a
smaller time interval and expressing the same property as
. In other words, one might ask whether there is an MTL
formula equivalent to  with all the intervals bounded by
the constant 4 (and thus requiring to store at most 4+1=5
elements in the buer).
Let us consider formula 0=F[3;4](p)_F[4;4](F[0;3](p)):
a nave and intuitive interpretation might lead us to think
that it denes the same property as . Roughly speaking,
instead of checking if peventually occurs within the entire
[3;7] time interval, 0checks ifpeither occurs in the [3; 4]
interval (as specied by subformula F[3;4](p)) or in the in-
terval [0;3] when evaluated exactly 4 time instants in the
future (as specied by subformula F[4;4](F[0;3](p))). Figure 3
shows the evaluation of formula 0over the same trace used
in Figure 2. As you can see, formula 0does not have the
same evaluation as  on the same trace. More specically,
at time instant 1 0is false while  is true (see the val-
ues circled in both gures). By analyzing the evaluation of
0, one can notice that subformula F[4;4](F[0;3](p)) at time
instant 1 refers to the value of F[0;3](p) at time instant 5,
which does not have a corresponding element in the trace.
If there was an element at time instant 5, F[0;3](p) would be
true sincepholds at time instant 6.
The above example shows that the evaluation of temporal
subformulae according to point-based semantics depends on
the existence of certain elements in the trace. It also shows
that point-based semantics is not suitable to support the in-
tuitive decomposition of MTL formulae into equivalent ones
with smaller time intervals, like the one from  to 0shown
above. We maintain that this constitutes a limitation for
the application of point-based semantics in the context of
trace checking. Therefore, in this paper we propose a new,
alternative semantics for MTL , called lazy semantics.
The main feature of lazy semantics is that it evaluates
temporal formulae and boolean combinations of temporal-
only formulae at any arbitrary time instant, regardless of
the existence of the corresponding elements in the trace.
The existence of the elements is only required when evalu-
ating atoms. This feature allows us to decompose any MTL
formula into an equivalent MTL formula in which the upper
bound of all time intervals of its temporal operators is lim-
Atoms:fpg fpg f qg fp;qg fp;qg fqg fqg
Time-stamps: 1 2 4 6 8 9 10
Time instants: 1 2 3 4 5 6 7 8 9 10
p > > ? > > ? ?
F[3;4](p)? > > ? ? ? ?
F[0;3](p)> > > > > ? ?
F[4;4](F[0;3](p))? > > ? ? ? ?
0?> > ? ? ? ?
Figure 3: Evaluation of formula 0=F[3;4](p)_
F[4;4](F[0;3](p)).(;;t)j=Lpi9i:(0i<jjandt=iandp2i)
(;;t)j=L:i (;;t)6j=L
(;;t)j=L_ i (;;t)j=Lor (;;t)j=L 
(;;t)j=LUI i9t0:(t0tandt0 t2Iand
(;;t0)j=L and8t00:(t<t00<t0and9i:(0i<jjand
t00=i) then (;;t00)j=L))
Figure 4: MTL Lsemantics on timed words.
ited by some constant. Such a decomposition can be used
as a preprocessing step of a trace checking algorithm, which
can then run in a more memory-ecient way.
In the following sections we rst introduce lazy semantics
(Section 4) and formalize the notion of the decomposition
exemplied above (Section 5). Afterwards, in Section 6 we
describe the modications to our previous trace checking al-
gorithm [10], required to preprocess the formula and support
lazy semantics.
4. LAZY SEMANTICS FOR MTL
The following example shows an anomalous case of MTL P
semantics that lazy semantics for MTL (denoted as MTL L
semantics) intends to remedy. Consider a timed word w=
(;) = (fqg;1)(fpg; 7) and two MTL formulae 1=F=6p
and 2=F=3F=3p. The intuitive meaning of the two for-
mulae is the same: pholds 6 time units after the origin,
i.e., at time-stamp 7. However, when evaluated on wusing
theMTL Psemantics, the two formulae have dierent values:
 1correctly evaluates to true, but  2to false. Indeed, in
 2the outermost F=3subformula is trivially false, because
there is no position that is exactly 3 time instants in the fu-
ture with respect to the origin. The two formulae, instead,
are equivalent over the MTL Lsemantics, where they both
evaluate to true. Indeed, this is true also over signal-based
semantics [12]; however, signals are not very practical for
monitoring and trace checking, which operate on logs that
are best modeled as a sequence of individual time-stamped
observations, i.e., timed words.
MTL Lsemantics. MTL Lsemantics on timed words is
given in Figure 4, in terms of the satisfaction relation j=L,
with respect to a timed word ( ;) and a time instant t2
R+;pis an atom and and areMTL formulae. An MTL
formula, when interpreted over MTL Lsemantics, denes a
timed language LL() =f(; )j(;; 0)j=Lg. The main
dierence between MTL PandMTL Lsemantics is that MTL P
evaluates formulae only at positions iof a timed word, while
MTL Linherits a feature of signal-based semantics, namely
it may evaluate (non-atomic) formulae at any possible time
instantt, even if there is no time-stamp equal to t. For
example, according to the MTL Psemantics, an \ Until " for-
mula 1UI 2evaluates to false in case there are no
positions in the interval I, due to the existential quanti-
cation onj(see Figure 1). Conversely, over the MTL Lse-
mantics, the evaluation of depends on the evaluation of
 2. If the latter is an atom then formula also evaluates
to false, because of the existential quantier in the MTL L
semantics of atoms. However, if  2is a temporal formula
or a boolean combination of temporal-only formulae (e.g.,
other \ Until " formulae), it will be evaluated in the part of
the timed word that satises the interval of . Hereafter
we refer to the MTL formulae interpreted over the MTL L
891semantics as \ MTL Lformulae"; similarly, \ MTL Pformulae"
areMTL formulae interpreted over the MTL Psemantics.
LetM() be the set of all formulae that can be derived
from the MTL grammar shown in Section 2.1, using  as
the set of atoms. We show that any language LP() de-
ned using some MTL Pformulacan be dened using an
MTL Lformula obtained after applying the translation l2p:
M()!M() to, i.e.,Lp() =LL(l2p()) for any .
Thel2ptranslation is dened as follows:
l2p(p)p;p2;l2p(_ )l2p()_l2p( )
l2p(:):l2p();l2p( UI )l2p() UI('act^l2p( ))
where'acta_:afor somea2.
The goal of l2pis to prevent the occurrence of direct
nesting of temporal operators, i.e., to avoid the presence
of (sub)formulae like F=3F=3p. As discussed in the exam-
ple above, nested temporal operators are interpreted dif-
ferently over the two semantics. Direct nesting is avoided
by rewriting the right argument of every \ Until " (i.e., the
\existential" component of \ Until "). The argument is con-
juncted with a formula 'actthat evaluates to true (over
both semantics) if there exists a position in the underlying
timed word; otherwise 'actevaluates to false. To explain
this intuition, let us evaluate 'actover a timed word (; )
over the alphabet  = fag. Over point-based semantics,
(;;i )j=P'act(;;i )j=Pa_:a is true for any posi-
tioni, since either abelongs toior not. However, the same
does not hold for lazy semantics. According to lazy seman-
tics, (;;t )j=L'actis true only in those time instants tfor
which there exists isuch thati=tand therefore exists the
corresponding i(to whichacan belong or not).
Lemma 1.Given an MTL formula and a timed word
!= (;), for anyi0, the following equivalence (modulo
l2ptranslation) holds: (;;i )j=Pi(;;i)j=Ll2p().
Proof. See the extended version [9] of the paper.
Theorem 1.Any timed language dened by an MTL P
formula can be dened by an MTL Lformula over the same
alphabet.
Proof. By Lemma 1, for i= 0.
Notice that the translation l2pdenes a syntactic MTL frag-
ment where temporal or boolean combination of temporal-
only operators cannot be directly nested. In this fragment
MTL PandMTL Lformulae dene the same languages. How-
ever, if we consider the complete denition of MTL, without
syntactic restrictions, the class of timed languages dened
byMTL Lformulae strictly includes the class of languages de-
ned by MTL Pformulae. In other words, MTL interpreted
over lazy semantics is strictly more expressive than MTL
interpreted over point-based semantics; this result is estab-
lished by the following theorem.
Theorem 2.There exists a timed language dened by
some MTL Lformula that cannot be dened by any MTL P
formula.
Proof. Consider the language of timed words L=f(; )j
9i9j(ij^(;;i )j=Lb^(;;j )j=Lc^j2)g.Lis
dened by the MTL Lformula  =  1_2_3, where  1=
(F(0;1)b)^(F[1;2]c)_(F(0;1]b)^(F(1;2]c);  2=F(0;1](b^F(0;1]c)
and  3=F(0;1]((F(0;1)b)^(F[1;1]c)).Lcannot be dened by
anyMTL Pformula (see reference [12], proposition 6).5. PARAMETRIC DECOMPOSITION
In this section we show that lazy semantics allows for a
parametric decomposition of MTL formulae into MTL formu-
lae where the upper bound of all intervals of the temporal
operators is limited by some constant K(the parameter of
the decomposition). This structural characteristic will then
be used in the trace checking algorithm presented thereafter.
We rst introduce some notation and show some proper-
ties of lazy semantics that will be used to prove the correct-
ness of the decomposition. We dene the operator over
intervals in Rwith endpoints in Nsuch thatIJ=fi+jj
8i2Iandj2Jg.
Lemma 2.For any timed word (;)andt0,
(;;t )j=LFIFJi(;;t )j=LFIJ:
Corollary 1.For any timed word (;)andt;N0,
(;;t )j=LFN
=Ki(;;t )j=LF=KN:
Lemma 3.For any timed word (;)andt0,
(;;t )j=LFI_FJi(;;t )j=LFI[J;ifI\J6=;:
The proofs of the above corollary and lemmata are in the
extended version [9] of the paper.
Hereafter, we focus on bounded MTL formulae, i.e., for-
mulae where intervals are always nite. Notice that it is
this class of formulae that causes memory scalability issues
in trace checking algorithms. We present the parametric
decomposition by referring to the bounded \ Eventually " op-
erator. The bounded \ Until " and \ Globally " operators can
be expressed in terms of the bounded \ Eventually " operator
using the usual equivalences; moreover, we remark that the
decomposition does not aect atoms and is applied recur-
sively to boolean operators. We use angle brackets (symbols
\h" and \i") in the denition of the decomposition to cover
all four possible cases of open (denoted with round brackets)
and closed (denoted with square brackets) intervals; the def-
inition is valid for any instantiation of the symbols as long
as they are consistently replaced on the right-hand side.
The decompositionLKofMTL formulae with respect to
parameterKis the translation LK:M()!M() such
thatLK(Fha;bi) =
8
>>>>><
>>>>>:Fha;biLK() ;bK
Fba
Kc
=K(FhamodK;b ba
KcKiLK());K <bba
K+ 1cK
Fba
Kc
=K(FhamodK;K]LK()_;b>ba
K+ 1cK
F=K(DF(LK();K;b ba
K+ 1cK)))
where
DF( ;K;h) =(
F[0;hi ;h K
F[0;K] _F=K(DF( ;K;h K));h>K:
The decomposition LKconsiders three cases depending on
the values of a,b, andK. In the rst case we have bK,
which means that the upper bound of the temporal inter-
val [a;b ] in the input formula is smaller than K, therefore
no decomposition is needed. The other two cases consider
input formulae where b > K . The second case is charac-
terized by b ba
K+ 1cKb ba
KcK+K. The
decomposition yields a formula of the form Fba
Kc
=K(), where
892F=K
0 K(F=K(F[amodK;K]p_F=K(F[0;K]p_F=K(F[0;b ba
K+2cK ]p))))
a bamodK
Figure 5:LKdecomposition of formula F[a;b]p.
=F[amodK;b ba
KcK]LK() is equivalent to the input for-
mula F[a;b]() evaluated at time instant ba
KcK. Notice
that according to Corollary 1, the argument inFba
Kc
=K()
is evaluated at time instant ba
KcK. The third case is char-
acterized by b>ba
K+ 1cK.
We illustrate the decomposition of F[a;b]pwithp2 by
referring to the example in Figure 5, where the black squares
divide the timeline into segments of length K. We refer to
each position in the timeline pinpointed by a black square
as aK-position. The big brackets enclose the interval [ a;b]
relative to time instant 0. Moreover, we assume some val-
ues foraandKsuch thatba
Kc= 2; hence, in the gure
the position of ain the timeline is between the marks corre-
sponding to 2 Kand 3K . The application of LK(F[a;b]p) re-
turns the formula F=K(F=K(F[amodK;K]p_F=K(F[0;K]p_
F=K(F[0;b ba
K+2cK ]p)))), which is shown above the time-
line, spanning through its length such that each subformula
(highlighted in red) is written above the corresponding K-
position where it is evaluated. Since ba
Kc= 2 there are
two subformulae of the form F=Kevaluated in the rst two
K-positions. Unlike the previous case, the interval [ a;b] is
too big to allow for rewriting the input formula into an-
other formula with a single Foperator with bounded length.
Hence, we use three subformulae: 1) F[amodK;K]peval-
uated at the third K-position, 2) F[0;K]pevaluated at the
fourthK-position, and 3) F[0;b ba
K+2cK ]pevaluated at the
fthK-position; the last two subformulae are obtained from
the denition ofDF. Notice that if K= 1, theLKdecom-
position boils down to the reduction of MTL toLTL.
Theorem 3.Given an MTL Lformula, a timed word
(;)and a positive constant K, we have that:
(;; 0)j=Li(;; 0)j=LLK()
and the upper bound of every bounded interval in all temporal
subformulae ofLK()is less than or equal to K.
Proof. We can prove this statement by showing that
LK() can always be rewritten back as and vice versa
using Lemmata 2 and 3. The complete proof is provided in
the extended version [9] of this paper.
6. TRACE CHECKING MTL LFORMULAE
WITH MAPREDUCE
The theoretical results presented in Section 5 can be ap-
plied to improve the memory scalability of the distributed
trace checking algorithm based on the MapReduce program-
ming model, and introduced by some of the authors in pre-
vious work [10]. Although the algorithm presented in [10]
was designed to perform trace checking of properties writ-
ten in SOLOIST [11] (an extension of MTL with aggregating
temporal modalities), here we consider, without loss of gen-
erality (see [11]), only its MTL subset. In the rest of this
section, after introducing some additional notation, we give
an overview of the algorithm's execution ow, and detailthe modications (emphasized with gray boxes in Figure 6)
applied to the original algorithm dened in [10] to support
MTL Lsemantics.
Additional notation. Letand beMTL formu-
lae. The set of all proper subformulae of is denoted with
sub(); notice that for atoms p2,sub(p) =;. The size
of a formula , denotedjj, is dened as the number of its
non-proper subformulae, i.e., jj=jsub()j + 1. The set
suba() =fpjp2sub(); sub(p) =;gis the set of atoms
of formula . The set subd() =fj2sub();82
sub(); =2sub( )gis called the set of all direct subformulae
of;is called the superformula of all formulae in subd().
The set sup () =fj2sub( );2subd()g is the
set of all subformulae of  that have formula asdirect
subformula . The height of,h(), is dened recursively as:
h() = if ( 62) then maxfh( )j 2subd()g+1; else 1.
For example, given the formula =F[2;4](a^b)U(30;100):c,
we have: sub( ) =fa;b;c;a^b;:c;F[2;4](a^b)gis the set
of all proper subformulae of ;suba() =fa;b;cgis the
set of atoms in ;subd() =fF[2;4](a^b);:cgis the set
of direct subformulae of ;sup(a) = sup(b) =fa^bg
shows that the sets of superformulae of aandbincoin-
cide; and the height of is 4, sinceh(a) =h(b) =h(c) = 1,
h(:c) =h(a^b) = 2,h(F[2;4](a^b)) = 3 and therefore
h() =maxfh(F [2;4](a^b));h(:c)g + 1 = 4.
Overview. The algorithm takes as input a non-empty
execution trace Tand an MTL formula  and provides a
verdict, indicating whether the trace satises the formula or
not. Before the algorithm is used we assume that the exe-
cution infrastructure, i.e., the cluster of machines, is con-
gured and running. We also assume that one can eas-
ily estimate through experimentation Kcluster, which is the
largest time interval bound that can be used in a formula
without triggering memory saturation in the cluster. This
bound depends on the memory conguration of the node
in the cluster with the least amount of memory available.
Once we have this information, we can preprocess the input
formula , leveraging the theoretical results of Section 5.
If the temporal operators in  have bounded intervals less
thanKcluster, we apply the unmodied version of the original
algorithm [10], which evaluates formulae over point-based
semantics. Otherwise, we have to transform the original
formula into an equivalent one that can be checked in a
memory-ecient way. This transformation is achieved by
rst interpreting the input formula  over lazy semantics:
to preserve its meaning, we apply the l2ptransformation.
Afterwards, given the parameter Kcluster, we rewrite the for-
mula using theLKclusterdecomposition (i.e., the LKdecom-
position instantiated with parameter Kcluster) and obtain the
formula Kcluster
L =LKcluster(l2p()). Thanks to Theorem 3,
this formula contains intervals no greater than Kcluster and
is equivalent to . The trace is modeled as a timed word
with integer4time-stamps. We assume that the execution
trace is saved in the distributed le system of the cluster on
which the distributed algorithm is executed. This is a real-
istic assumption since in a distributed setting it is possible
to collect logs, as long as there is a total order among the
time-stamp induced by some clock synchronization protocol.
The trace checking algorithm processes the trace itera-
tively, through a sequence of MapReduce executions. The
4Since integers are isomorphic to a subset of real numbers,
the theoretical results of the previous sections are still valid
for integer time-stamps.
893number of MapReduce iterations is equal to the height of the
MTL formula . The rst MapReduce iteration parses the
input trace from the distributed le system, applies the map
andreduce functions and passes the output (a set of tuples)
to the next iteration. Each subsequent iteration l(where
1<lh()) receives the set of tuples from iteration l 1
in the expected internal format (hence, parsing is performed
only in the rst iteration). The set of tuples contains all the
positions where the subformulae of  of height l 1 hold.
Note that the trace itself is a similar set, containing all the
positions where the atoms (with height 1) hold. Based on
the set it receives, the l-th iteration can then calculate all
the positions where the subformulae of height lhold. Each
iteration consists of three phases: 1) read phase that reads
and splits the input; 2) map phase that associates each for-
mula with its superformula; and 3) reduce phase that applies
the semantics of the appropriate subformula of . The nal
set of tuples represents all the positions where the input for-
mula holds. Hence, producing the verdict is only a matter
of checking if the input formula holds in the rst position.
Read phase. The input reader component of the MapRe-
duce framework is used in this phase; this component can
process the input trace in a parallel way. The trace saved in a
distributed le system is split into several blocks, replicated
3 times and distributed among the nodes. The MapReduce
framework exploits this block-level parallelization both dur-
ing the read and map phases. For example, the default block
size of the Hadoop deployment is 64MB, which means that
a 1GB trace is split in 16 parts and can be potentially pro-
cessed using 16 parallel readers and mappers. However, if
we executed the algorithm on 3 nodes with 4 cores each, we
could process up to 12 blocks in parallel. The input reader
is used only in the rst iteration and can be seen as a parser
that converts the trace into a uniform internal representa-
tion that is used in the subsequent iterations. As shown
in Figure 6a, the k-th instance of the input reader handles
thek-th blockTkof the trace T. For each element ( ;) in
Tkand every atom poccurring in the MTL formula , the
reader emits a key-value pair of the form (p; (p2;)). The
key is the atom pitself, while the value is a pair consisting
of the truth value of pat time(obtained by evaluating the
expressionp2) and the time-stamp . The emit function
incrementally builds the list of outgoing tuples.
Map phase. Each tuple generated by an input reader is
passed to a mapper on the same node. Mappers associate
the formula in the tuple with all its superformulae in .
For example, given  = ( a^b)_:a , if the input reader
returns a tuple ( a;(>;42)), the mapper will associate it with
formulaea^band:a, emitting tuples ( a^b;(a;>;42)) and
(:a;(a;>;42)). The mapper, shown in Figure 6b, receives
tuples in the form ( ;(v;)) from the input reader and emits
all tuples of the form (  ;(;v; )) where 2sup().
To support lazy semantics, the algorithm needs to con-
sider all the time instants where we want to evaluate the
temporal operators. If any of these instants does not have a
corresponding element in the trace, then the original algo-
rithm would evaluate a formula to false. However, to sup-
port lazy semantics, we do not need to introduce an ele-
ment in the trace for each time instant: we know a priori
that only formulae of the form F=K|explicitly introduced
by theLKdecomposition| may be evaluated incorrectly
if the appropriate elements are not in the trace (see Fig-
ure 3). Therefore, we modify the algorithm for the mapper1:function Input reader;l(Tk[])
2:for all (;)2Tk[]do
3: for allp2suba()do
4: emit(p;(p2;))
5: end for
6:end for
7:end function
(a) Input reader algorithm1:function Mapper;K;l((;(v;)))
2:for all 2sup()do
3: emit( ;(;v; ))
iflazy( )then
emit( ;('act;?;+K))
end if
4: end for
5:end function
(b) Mapper algorithm
1:function ReducerFI
;l( ;T[])
2: val ?; win ;
3:for all (;v; )2checkDup(T )do
4: win win[(;v; ) if (v)
5: whiledwine bwinc620UIdo
6: win winnargmax(win)
7: end while
8: val 902fwing:0 2I
9: emit( ;(val;))
10: end for
11:end function
(c)Reducer for operator FI1:function ReducerGI
;l( ;T[])
2: val >; win ;
3:for all (;v; )2checkDup(T )do
4: win win[(;v; ) if (:v)
5: whiledwine bwinc620UIdo
6: win winnargmax(win)
7: end while
8: val 902fwing:0 2I
9: emit( ;(:val;))
10: end for
11:end function
(d) Reducer for operator GI
Figure 6: Reader, Mapper and Reducer algorithms.
(see Figure 6b) to introduce one element at +Konly when
the parent formula  is of the form F=K; this condition is
captured by the lazy() predicate. The emitted tuple con-
tains the tuple ( 'act;?;+K) as its value. In this tuple,
the truth value of 'actis false by convention, to represent
a non-existent trace element. Since the mapper is stateless
and cannot check if a tuple exists at time instant +K, it is
the reducer's responsibility to discard tuple ( 'act;?;+K)
if there is already a tuple at +K.
Reduce phase. The reducers exploit the information
produced by the mappers to determine the truth values of
the superformula at each position, i.e., reducers apply the
appropriate MTL semantics for the operator used in the su-
performula. The total number of reducers running in parallel
at thel-th iteration is the minimum between the number of
subformulae with height lin the input formula  and the
number of available reducers5. Each reducer calls an ap-
propriate reduce function depending on the type of formula
used as key in the received tuple. For space reasons we focus
only on two algorithms: the one for the metric \ Eventually "
operator FIand the one for the metric \ Globally " operator
GI. We refer the reader to our previous work [10] for the
full description of all the reducer algorithms.
Figure 6c shows the algorithm for formulae of the form
FI. It uses an auxiliary boolean variable valand a queue
win. The algorithm receives the tuples in Talready sorted
(in the shue and sort phase of the MapReduce framework)
in descending order with respect to the time-stamps6. These
tuples are incrementally processed by the checkDup() func-
tion, which discards the tuples of the form ( 'act;?;) if
tuples with the same time-stamp already exist. The queue
winkeeps track of all the tuples with positive truth value
that fall in the convex union7(denoted asU) of the intervals
[0;0] andI. This is ensured by the inner while loop, which
compares the minimal ( bwinc) and maximal (dwin e) time-
stamp in the queue and keeps removing the maximal tuple
5This depends on the conguration of the cluster. Typically,
the number of reducers is the number of nodes in the cluster
multiplied by the number of cores available on each node.
6Sorting intermediate tuples is called secondary sorting and
for simplicity we omit the implementation details.
7A convex union of intervals is dened as a convex hull of
the union of the intervals.
894lAtoms:fpgfpg fqg fp;qgfp;qgfqgfqg
Time-stamps: 1 2 4 6 8 9 10
Time instants: 1 2 3 4 5 6 7 8 9 10 11 12 13 14
1p> > ? > > ? ?
F[3;4](p)> > > > ? ? ? ?
F[0;3](p)> > > > > > ? ?
2'act ? ???? ? ?
F[4;4](F[0;3](p))> > > ? ? ? ? ? ? ? ?
3L4(l2p())>>>>>>>>>>????????????? ? ?
Figure 7: Evaluation of the L4(l2p()) = F[3;4](p)_
F[4;4](F[0;3](p))formula over MTL Lsemantics.
(argmax(win)) until the loop condition is satised. The -
nal truth value of FIdepends on whether the queue win
contains a tuple with a time-stamp 0that is in the interval
I. Notice that the size of the queue windepends directly
on the size of the interval I; hence, the memory scalability
of the algorithm on individual nodes depends on the size of
the intervals in formula .
The reducer algorithm in Figure 6d implements the se-
mantics of formulae of the form GI. The code is similar to
the one for the operator FI. The only dierence is that the
queue winkeeps track of all the tuples with negative truth
value; hence, the truth value of GIdepends on whether the
queue wincontains a tuple in the interval Ithat is a witness
to the violation of GI.
Examples of application of the algorithm. Let us
use our algorithm to evaluate the formula  from Exam-
ple 1 on the same trace using MTL Psemantics. In the read
phase the algorithm parses the trace in parallel and creates
the input tuples for the map phase. From the rst element
(fpg; 1) the Input Reader creates only the tuple ( p;(>;1))
since  refers only to atom p. Tuples (p;(>;1)), (p;(>;2)),
(p;(?;4)), (p;(>;6)), (p;(>;8)), (p;(?;9)), (p;(?;10)) are
thus received by the map phase. The Mapper associates
the formulae from the input tuples with their superformu-
lae. In the case of tuple ( p;(>;1)) it generates only tu-
ple (F [3;7](p);(p;>;1)) since F[3;7](p) is the only superfor-
mula ofp. The Reduce phase, therefore, receives tuples
(F[3;7](p);(p;(?;10))), (F [3;7](p);(p;(?;9))),
(F[3;7](p);(p;(>;8))), (F [3;7](p);(p;(>;6))),
(F[3;7](p);(p;(?;4))), (F [3;7](p);(p;(>;2))),
(F[3;7](p);(p;(>;1))), all shued and sorted in descending
order of their time-stamps. Since all the tuples have the
same key, only one reducer is needed. The reducer applies
the algorithm shown in Figure 6c and outputs the truth val-
ues of F[3;7](p) for every position in the trace:
(F[3;7](p);(?;10)), (F [3;7](p);(?;9)), (F [3;7](p);(?;8)),
(F[3;7](p);(?;6)), (F [3;7](p);(>;4)), (F [3;7](p);(>;2)),
(F[3;7](p);(>;1)). Notice that the boolean values in the tu-
ples correspond to the values in Figure 2 (row #4).
Assuming again that the memory requirement of keeping
8 positions is too demanding for our infrastructure we can
now use parametric decomposition and lazy semantics to
limit the upper bound of the interval in  to K= 4. We
obtain formulaL4(l2p()) = F[3;4](p)_F[4;4](F[0;3](p)).
Let us evaluate formula L4(l2p()) on the same trace
from Example 1 over MTL Lsemantics. Table 7 shows the
truth values of the emitted tuples for every evaluated sub-
formulae ofL4(l2p()). Since h(L4(l2p())) = 4 the al-gorithm performs three iterations (whose index is indicated
in the left-most column l). The truth values of the sub-
formulae from the dierent iterations are separated by the
horizontal dashed lines. In the rst iteration the trace is
parsed to obtain the truth values of atom p. After that,
two reducers in parallel calculate the truth values of the
F[0;3](p) and F[3;4](p) subformulae. In the second iteration
theMapper emits the additional 'acttuples since the su-
performula is of the form F=4. The reducer evaluating for-
mula F[4;4](F[0;3](p)) receives the tuples with the evaluation
ofF[0;3](p) and'act. The'acttuples with the crossed truth
values are discarded because of the already existing F[0;3](p)
tuples shown in the row above. Finally, in the third itera-
tion we can see that the truth values L4(l2p()) (circled in
Figure 7) are the same (at all time instants in common) as
the truth values of  shown in Figure 2.
7. EVALUATION
We have implemented our trace checking algorithm in
theMTLMapReduce tool, which is publicly available [20].
The tool is implemented in Java and uses the Apache Spark
framework [28,29], which supports iterative MapReduce ap-
plications in a better way than Apache Hadoop [2].
In this section we report on the evaluation of our tool,
in terms of scalability and time/memory tradeos. More
specically, we evaluate our new trace checking algorithm
by answering the following research questions:
RQ1: How does the proposed algorithm scale with respect to
the size of the time interval used in the formula to be
checked? (Section 7.2)
RQ2: When compared to state-of-the-art tools, does the pro-
posed algorithm have a better memory scalability with
respect to the size of the time interval used in the for-
mula to be checked? (Section 7.2)
RQ3: What are the time/memory tradeos of the proposed
algorithm with respect to the decomposition parameter
K?(Section 7.3)
7.1 Evaluation settings
To evaluate our approach, we used six t2.micro instances
from the Amazon EC2 cloud-based infrastructure with a sin-
gle CPU core and 1GB of memory each. We used the stan-
dard conguration for the HDFS distributed le system and
the YARN data operating system. HDFS block size was set
to 64 MB and block replication was set to 3. YARN was con-
gured to allocate containers with memory between 512 MB
and 1 GB, with 1 core. In all the executions, we limited the
memory of our algorithm to 1 GB.
Measuring the actual memory usage of user-dened code
in Spark-based applications requires to distinguish between
the memory usage of the Spark framework itself and the
one of user-dened code. This step is necessary since the
framework may use the available memory to cache interme-
diate data to speed up computation. Hence, to measure the
memory usage of the auxiliary data structures used by our
algorithm (e.g., the winqueue), we instrumented the code.
This instrumentation, which has a negligible overhead, mon-
itors the memory usage of the algorithm's data structures
and reports the maximum usage for each run.
For the evaluation described in the next two subsections,
we used synthesized traces. By using synthesized traces, we
are able to control in a systematic way the factors, such as
the trace length and the frequency of events, that impact on
895the time and memory required for checking a specic type of
formula. In particular, we evaluated our approach by trig-
gering the worst-case scenario, in terms of memory scalabil-
ity, for our trace checking algorithm. Such scenario is char-
acterized by having the auxiliary data structures used by the
algorithm always at their maximum capacity. To synthesize
the traces, we implemented a trace generator program that
takes as parameters the desired trace length nand the num-
bermof events (i.e., atoms) per trace element. The program
generates a trace with ntrace elements, such that the i-th
element (with 0 in 1) hasias time-stamp value.
Each trace element has between 1 and mevents denoted as
fe1;:::;emg, wheree1=pand the other m 1 events are
randomly selected from the set of atoms fp2;:::;pmgusing
a uniform distribution. We generated ten traces, with nset
to 50 000 000 and mset to 20; the average size of each trace,
before saving it in the distributed le system, is 3: 2 GB.
These traces and the other artifacts used for the evaluation
are available on the tool web site [20].
7.2 Scalability
The performance of our distributed trace checking algo-
rithm with respect to the length of the trace and the size
of the formula has been already investigated in our previous
work [10]. The same conclusions regarding these two pa-
rameters apply also to the new algorithm, which uses lazy
semantics. Therefore, in this section we only focus on eval-
uating the memory scalability of the new algorithm.
To address RQ1, we evaluate the memory usage of the
algorithm for dierent sizes of the time interval used in the
MTL formula to be checked. As discussed in Section 6, the
largest time interval that does not trigger memory satura-
tion in a cluster, depends on the memory conguration of
the node in the cluster with the least amount of memory
available. Hence, we evaluate the memory usage on a single
node by using formulae of height 1; nevertheless, the map
phase is still executed in parallel. We consider the two met-
ric formulae G[0;N]qandF[0;N]p, parametrized by the value
Nof the bound of their time interval. Formula F[0;N]prefers
to atomp; notice that our trace generator guarantees that
pis present in every trace element. Formula G[0;N]qrefers
to atomq; we congured our trace generator so that event
qis absent in all trace elements. These two formulae exer-
cise the trace checking algorithm in its worst-case. Indeed,
according to line 4 in Figure 6c, the reducer for FIbuers
all the elements where atom pis true; hence, when checking
formula F[0;N]p, at any point in time the queue winwill be
at its maximum capacity. Dually, when checking formula
G[0;N]q, the absence of the event qfrom the trace will force
the algorithm to maintain the queue winat its maximal ca-
pacity (line 4 in Figure 6d). As mentioned in section 3, our
trace checking algorithm deals with MTL formulae in the
most general case, therefore it evaluates formulae G[0;N]q
andF[0;N]pat every position to allow for arbitrary nesting.
To address RQ2, we need a baseline for comparison. Among
the non-distributed, non-parallel trace checking tools, the
only tool supporting MTL and publicly-available isMon-
Poly [6], which was the best performing tool in the \oine
monitoring" track of the rst international Competition on
Software for Runtime Verication [4] (CSRV 2014). Mon-
Poly, when executed on the traces described above, produced
a stack overow error; hence, we could not use it for com-
parison. Among distributed and parallel approaches, theonly tool supporting MTL and publicly-available is the one
described in our previous work [10], to which we compare.
Plots in Figures 8a and 8b show the execution time and
the memory usage required to check, respectively, formula
G[0;N]qandF[0;N]p, instantiated with dierent values of pa-
rameterN. Each data point is obtained by running the
algorithm over the ten synthesized traces and averaging the
results. The plots colored in black show the average time
and memory usage of our previous algorithm [10], which ap-
plies MTL Psemantics. The plots colored in gray represent
the runs of our new algorithm that applies MTL Lseman-
tics and decomposes all the formulae with time interval N
strictly greater than 30 000 000. The decomposition param-
eterK= 30 000 000 is the maximal value that our infras-
tructure can support before saturating its memory.
We answer RQ1 by observing the trend in the gray plots
of Figures 8a and 8b: the proposed algorithm can check, on
very large traces, formulae that use very large time intervals
(up to 50 000 000), using at most 1GB of memory and taking
a reasonable time (at most 200s). To answer RQ2, the plots
show that the proposed algorithm is more scalable in terms
of memory usage than the algorithm from [10]. Indeed,
for the evaluation of both formulae, the latter exhausts the
memory bound of 1GB when the time interval Nis higher
than 30 000 000. Nevertheless, the proposed algorithm is on
average 1.35x slower that the previous algorithm [10] when
the time interval Nis higher than 30 000 000. This addi-
tional time is needed to process the new formula obtained
through theLKdecomposition.
7.3 Time/memory tradeoffs
As suggested above, the parametric decomposition used
in the proposed trace checking algorithm leads to a reduced
memory usage but increases the execution time. In this sec-
tion we dig into and generalize this result by investigating
the time/memory tradeos of our algorithm, with respect
to the decomposition parameter K. More specically, to
address RQ3 we evaluate the execution time and the mem-
ory usage of the algorithm for dierent values of parameter
K, when checking formulae G[0;50 000 000]qandF[0;50 000 000]p.
These formulae are processed using the LKdecomposition,
with values of Kthat are taken from V=f5107
iji=
2;3;:::grepresenting an innite harmonic series scaled by a
5107factor. By using set V, we can study the performance
of the algorithm for dierent values of Kwithout exhaus-
tively exploring its large domain. Since set Vis innite, we
put a threshold of one hour on the execution time.
The plots in Figure 8c show the execution time and the
memory usage to check the two formulae. Each data point
is obtained by running the algorithm over the ten synthe-
sized traces and averaging the results. The value of Kis
represented in both plots on the x-axis using the logarith-
mic scale. The smallest value of Kthat satises the execu-
tion time threshold is 1 666 666 (obtained from set Vwith
i= 30); for this value of Kthe algorithm used 54 :14MB of
memory and took 43 minutes to complete. The plots show
that using a lower value for Kdecreases the memory foot-
print of the algorithm. However, a lower value for Kalso
yields a longer execution time for the algorithm. This longer
execution time is due to the fact that a lower value for K
increases the size (and the height) of the formula obtained
after applying the LKdecomposition. The increased height
of the decomposed formula triggers more iterations of the
8960 10 20 30 40 5050100150
I
nterval length N(106)Ti
me (s)p
revious algorithm [10]
n
ew algorithm
0 10 20 30 40 5005001;0001;500
I
nterval length N(106)M
emory (MB)p
revious algorithm [10]
n
ew algorithm
(a) E
xecution time (top) and memory usage
(bottom) to check G[0;N]q0 10 20 30 40 5050100150200
I
nterval length N(106)Ti
me (s)p
revious algorithm [10]
n
ew algorithm
0 10 20 30 40 5005001;0001;500
I
nterval length N(106)M
emory (MB)p
revious algorithm [10]
n
ew algorithm
(b
)Execution time (top) and memory usage
(bottom) to check F[0;N]p106:5107107:502040
d
ecomposition parameter KTi
me (min)G[0;50
000 000]q
F[0;50
000 000]p
106:5107107:502004006008001;000
d
ecomposition parameter KM
emory (MB)G[0;50
000 000]q
F[0;50
000 000]p
(c
)Execution time (top) and memory usage
(bottom) when varying parameter K
Figure 8: Scalability and time/memory tradeos for the proposed trace checking algorithm.
algorithm, yielding longer execution times. We answer RQ3
by stating that there is a tradeo between time and memory,
determined by the value of parameter K. A good balance
between these two factors can be achieved when Kis set to
the largest possible value supported by the infrastructure: in
this way, it is possible to reduce the size of the decomposed
formula without incurring a longer execution time for the
algorithm. Nevertheless, our algorithm is completely para-
metric inK, allowing engineers to tune the algorithm to be
either more time- or more memory-intensive, depending on
the application's requirements.
8. RELATED WORK
The approach presented in this paper is strictly related to
work done in the areas of alternative semantics for metric
temporal logics and of trace checking/run-time verication.
Alternative semantics for metric temporal logics.
The work closest to our lazy semantics is the one in [15],
which proposes an alternative MTL semantics, used to prove
that signal-based semantics is more expressive than point-
based semantics over nite words. Despite the similarity
between the two semantics, the denition of the Until oper-
ator over our lazy semantics is more practical for the purpose
of trace checking, since it requires the left subformula of an
Until operator to hold in a nite number of positions. Ref-
erence [13] revises the model parametric semantics of the
TRIO temporal logic [22], in order to overcome counterin-
tuitive behaviors of bounded temporal operators on a nite
temporal domain. The proposal shares the same intuition
behind our denition of lazy semantics, but overall the two
semantics are quite dierent (in particular, in the interpre-
tation of bounded and unbounded temporal operators).
Trace checking/run-time verication. Several ap-
proaches for trace checking and run-time verication and
monitoring of temporal logic specications have been pro-
posed in the last decade. The majority of them (see, for
example, [7, 16, 18, 25, 26]) are centralized and use sequen-
tial algorithms to process the trace (or, in online algorithms,
the stream of events). The centralized, sequential nature of
these algorithms does not allow them either to process largetraces or properties containing very large time bounds. In
the last years there have been approaches for trace check-
ing [5] and runtime verication [8, 21,25] that rely on some
sort of parallelization. However, they mostly focus on split-
ting the traces based on the data they contain, rather than
on the structure of the formula. These approaches adopt
rst-order relations with nite domains to represent the events
in the trace. The trace can then be split into several un-
related partitions based on the terms occurring in the re-
lations. We consider these approaches orthogonal to ours,
since we focus on the scalability with respect to the tempo-
ral dimension, rather than the data dimension. As for the
specic application of MapReduce for trace checking, an it-
erative algorithm for LTL is proposed in [3]. Similarly to
the algorithm presented in this paper and to our previous
work [10], the algorithm in [3] performs iterations of MapRe-
duce jobs depending on the height of the formula to check.
However, it does not address the issue of memory consump-
tion of the reducers. Moreover, the whole trace is kept in
memory during the reduce phase, making the approach un-
feasible for very large traces.
9. CONCLUSIONS AND FUTURE WORK
This work addresses the memory scalability issue that af-
fects trace checking algorithms when dealing with temporal
properties that use large time intervals. We have proposed
an alternative, lazysemantics for MTL, whose properties al-
low for a parametric decomposition of any MTL formula into
an equivalent MTL formula with bounded time intervals. As
shown in the evaluation, such decomposition can be used to
improve distributed trace checking algorithms, making them
more memory-ecient and able to deal with both very large
traces and very large time intervals.
A future research direction is to study lazy semantics with
respect to the signal-based semantics for MTL. Another di-
rection is the investigation of techniques for determining the
most appropriate value for Kin theLKdecomposition of
formulae, based on the conguration of the available cloud
infrastructure.
89710. REFERENCES
[1] R. Alur and D. L. Dill. A theory of timed automata.
Theoretical Computer Science, 126(2):183{235, 1994.
[2] Apache Software Foundation. Hadoop MapReduce.
http://hadoop.apache.org/.
[3] B. Barre, M. Klein, M. Soucy-Boivin, P.-A. Ollivier,
and S. Hall e. MapReduce for parallel trace validation
of LTL properties. In Proc. of RV 2012 , volume 7687
ofLNCS , pages 184{198. Springer, 2012.
[4] E. Bartocci, B. Bonakdarpour, and Y. Falcone. First
international competition on software for runtime
verication. In Proc of RV 2014 , volume 8734 of
LNCS , pages 1{9. Springer, 2014.
[5] D. Basin, G. Caronni, S. Ereth, M. Harvan,
F. Klaedtke, and H. Mantel. Scalable oine
monitoring. In Proc of RV 2014 , volume 8734 of
LNCS , pages 31{47. Springer, 2014.
[6] D. Basin, M. Harvan, F. Klaedtke, and E. Z alinescu.
Monpoly: Monitoring usage-control policies. In Proc.
of RV 2011 , volume 7186 of Lecture Notes in
Computer Science , pages 360{364, 2011.
[7] D. Basin, M. Harvan, F. Klaedtke, and E. Zalinescu.
Monitoring data usage in distributed systems. IEEE
Trans. Softw. Eng. , 39(10):1403{1426, 2013.
[8] A. Bauer and Y. Falcone. Decentralised LTL
monitoring. In Proc of FM 2012 , volume 7436 of
LNCS , pages 85{100. Springer, 2012.
[9] M. M. Bersani, D. Bianculli, C. Ghezzi, S. Krsti c, and
P. San Pietro. Ecient large-scale trace checking using
MapReduce. Extended version available online at
http://arxiv.org/abs/1508.06613, 2015.
[10] D. Bianculli, C. Ghezzi, and S. Krsti c. Trace checking
of metric temporal logic with aggregating modalities
using MapReduce. In Proc. of SEFM 2014 , volume
8702 of LNCS , pages 144{158. Springer, 2014.
[11] D. Bianculli, C. Ghezzi, and P. San Pietro. The tale of
SOLOIST: a specication language for service
compositions interactions. In Proc. of FACS 2012 ,
volume 7684, pages 55{72. Springer, 2012.
[12] P. Bouyer, F. Chevalier, and N. Markey. On the
expressiveness of TPTL and MTL. Information and
Computation , 208(2):97 { 116, 2010.
[13] A. Coen-Porisini, M. Pradella, and P. San Pietro. A
nite-domain semantics for testing temporal logic
specications. In Proc. of FTRTFT 1998 , volume 1486
ofLNCS , pages 41{54. Springer, 1998.
[14] J. Dean and S. Ghemawat. MapReduce: Simplied
data processing on large clusters. Commun. ACM,
51(1):107{113, 2008.
[15] D. D'Souza and P. Prabhakar. On the expressivenessof MTL in the pointwise and continuous semantics.
International Journal on Software Tools for
Technology Transfer , 9(1):1{4, 2007.
[16] P. Faymonville, B. Finkbeiner, and D. Peled.
Monitoring parametric temporal logic. In Proc. of
VMCAI 2014 , volume 8318 of LNCS , pages 357{375.
Springer, 2014.
[17] M. Felder and A. Morzenti. Validating real-time
systems by history-checking TRIO specications.
ACM Trans. Softw. Eng. Methodol. , 3(4):308{339,
Oct. 1994.
[18] H.-M. Ho, J. Ouaknine, and J. Worrell. Online
monitoring of metric temporal logic. In Proc of RV
2014, volume 8734 of LNCS , pages 178{192. Springer,
2014.
[19] R. Koymans. Specifying real-time properties with
metric temporal logic. Real-Time Syst. , 2(4):255{299,
1990.
[20] S. Krsti c. MTL-MapReduce.
https://bitbucket.org/krle/mtlmapreduce.
[21] R. Medhat, Y. Joshi, B. Bonakdarpour, and
S. Fischmeister. Parallelized runtime verication of
rst-order LTL specications, 2014. Technical report.
[22] A. Morzenti, D. Mandrioli, and C. Ghezzi. A model
parametric real-time logic. ACM Trans. Program.
Lang. Syst. , 14:521{573, October 1992.
[23] A. Mrad, S. Ahmed, S. Hall e, and E. Beaudet.
Babeltrace: A collection of transducers for trace
validation. In Proc. of RV 2012 , volume 7687 of
LNCS , pages 126{130. Springer, 2013.
[24] Public Law 104{191. Health Insurance Portability and
Accountability Act of 1996 (HIPAA), 1996.
[25] G. Rosu and F. Chen. Semantics and algorithms for
parametric monitoring. Logical Methods in Computer
Science , 8(1), 2012.
[26] P. Thati and G. Rosu. Monitoring algorithms for
metric temporal logic specications. Electr. Notes
Theor. Comput. Sci , 113:145{162, 2005.
[27] Wikipedia. Wikipedia page trac statistics.
http://aws.amazon.com/datasets/2596.
[28] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma,
M. McCauley, M. J. Franklin, S. Shenker, and
I. Stoica. Resilient distributed datasets: A
fault-tolerant abstraction for in-memory cluster
computing. In Proc. of NSDI'12 , pages 2{2. USENIX
Association, 2012.
[29] M. Zaharia, M. Chowdhury, M. J. Franklin,
S. Shenker, and I. Stoica. Spark: Cluster computing
with working sets. In Proc. of HotCloud 2010 .
USENIX, 2010.
898