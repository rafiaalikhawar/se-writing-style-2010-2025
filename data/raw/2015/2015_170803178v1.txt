arXiv:1708.03178v1  [cs.SE]  10 Aug 2017More AccurateRecommendationsforMethod-Level Changes
GeorgDotzler, MariusKamp,PatrickKreutzer, MichaelPhilippse n
ProgrammingSystems Group,Friedrich-Alexander University E rlangen-Nürnberg(FAU),Germany
{georg.dotzler,marius.kamp,patrick.kreutzer,michael. philippsen}@fau.de
ABSTRACT
During the life span of large software projects, developers often
apply the same code changes to diﬀerent code locations in sli ght
variations. Since the application of these changes to all lo cations
is time-consuming and error-prone, tools exist that learn c hange
patterns from input examples, search for possible pattern a ppli-
cations, and generate corresponding recommendations. In m any
cases, thegenerated recommendations aresyntacticallyor seman-
ticallywrongduetocodemovements intheinputexamples.Th us,
theyareoflowaccuracyanddeveloperscannotdirectlycopy them
into their projectswithoutadjustments.
Wepresent theAccurateREcommendationSystem (ARES)that
achieves ahigheraccuracythanothertoolsbecauseitsalgo rithms
take care of code movements when creating patterns and recom -
mendations. On average, the recommendations by ARES have an
accuracyof96%withrespecttocodechangesthatdevelopers have
manually performed in commits of source code archives. At th e
same time ARES achieves precision and recall values that are on
par withother tools.
CCS CONCEPTS
•Informationsystems →Recommendersystems ;•Software
and itsengineering →Softwaremaintenancetools ;
KEYWORDS
Program transformation,refactoring, recommendationsys tem
ACMReference Format:
Georg Dotzler, Marius Kamp, Patrick Kreutzer, Michael Philippse n. 2017.
More Accurate Recommendations for Method-Level Changes. In Proceed-
ingsof201711thJointMeetingoftheEuropeanSoftwareEngi neeringConfer-
enceandtheACMSIGSOFTSymposiumontheFoundationsofSoft wareEngi-
neering, Paderborn,Germany, September4-8, 2017 (ESEC/FS E’17),11 pages.
https://doi.org/10.1145/3106237.3106276
1 INTRODUCTION
Developers often perform the error-prone and repetitive ta sk of
applyingthesame systematicedits tomanylocationsintheircode
base. Thereasons for such systematic changes vary. They inc lude
bugﬁxes,theadaptionofcallsitestonewAPIs,etc.,andcon stitute
themajorityof structuraleditsinsoftwareprojects[22,3 1].
Permission to make digital or hard copies of all or part of thi s work for personal or
classroomuseisgrantedwithoutfeeprovidedthatcopiesar enotmadeordistributed
for proﬁt or commercial advantage and that copies bear this n otice and the full cita-
tionontheﬁrstpage.Copyrightsforcomponents of thiswork owned byothersthan
the author(s) must be honored. Abstracting with credit is pe rmitted. To copy other-
wise, orrepublish,to post onserversorto redistributeto l ists,requirespriorspeciﬁc
permissionand/orafee. Request permissionsfrompermissi ons@acm.org.
ESEC/FSE’17,September4-8,2017,Paderborn,Germany
© 2017 Copyright held by the owner/author(s). Publication r ights licensed to Associ-
ationfor Computing Machinery.
ACM ISBN978-1-4503-5105-8/17/09...$15.00
https://doi.org/10.1145/3106237.3106276Developers usuallyperformsystematic edits manually beca use
often the code is slightly diﬀerent in each location (with re spect
to names, contexts, etc.) so that they cannot use a plain text ual
search-and-replace. Refactoring wizards of IDEs also just oﬀer a
setofpredeﬁnedtransformationsandthusonlyprovidehelp fora
subsetofallsystematicchanges.Furthermore,theydonots upport
code changes that lead to diﬀerent semantics, which is neces sary
inmany situations (e.g., toﬁxerrors).
Current research tools [29, 35] learn systematic edits from one
or more manually provided training examples and build gener al-
ized patterns from them. Then the tools search the code base f or
locationstoapplythesepatternstoandpresentthecodeoft heap-
plied patterns as recommendations to developers. Since the tools
construct the suggested code (to a large extent) purely synt acti-
cally,thecodeis oftenwrong(uses undeﬁned variables, cal lsnon-
existingfunctions,missesstatements,etc.).Thus,there commended
codeis ofteninaccurate, i.e., it is not whatdevelopers wou ldhave
written if they had done the systematic edits by hand. Althou gh
such inaccurate recommendations are helpful as they identi fy lo-
cations for codechanges, developers still need tomanually adjust
them beforetheycan insert them into their projects.
Fig. 1 illustrates this problem. The two recommendation sys -
tems LASE [29] and ARES learn a pattern from the code changes
given in Fig. 1(a+b) (in a classic diﬀrepresentation). Both tools
ﬁnd the matching code location in Fig. 1(c). LASE suggests th e
code change in Fig. 1(d). ARES produces the more accurate one
in Fig. 1(e) that is closer to what a developer would have writ ten.
There are two reasons for the diﬀerences. First, since chang e (b)
init();
- foo.someMethod(42);
- print(foo);
+ if (foo != null) {
+ foo.someMethod(42);
+ print(foo);
+ }
(a)Examplechange.init();
- assert (foo != null);
- foo.someMethod(42);
- foo.print();
+ if (foo != null) {
+ foo.someMethod(42);
+ foo.print();
+ }
(b)Examplechange.
init();
assert (foo != null);
foo.someMethod(42);
foo.run();
(c) Matchingcode location.
init();
assert(foo != null);
if (foo != null) {
foo.someMethod(42);
}
foo.run();
(d)Inaccurate
recommendation by LASE.init();
if (foo != null) {
foo.someMethod(42);
foo.run();
}
(e) Moreaccurate
recommendation by ARES.
Figure1: Examplefor coderecommendations.ESEC/FSE’17,September4-8,2017,Paderborn,Germany Geor gDotzler,MariusKamp, PatrickKreutzer,Michael Philippse n
Code ChangesInputOrder
DeterminationPattern
CreationGeneralized
Pattern
Searchfor
ApplicationsRecommendation
CreationRecommendationsCode Base
Figure2: Workﬂow of ARES for one inputsetof codechanges.
explicitly removes the assertstatement, it should not be part of
therecommendation.However,asLASEonlyappliesthecommo n
subset of the code transformations that are present in the tr ain-
ing examples, the assertremains untouched. Second, LASE leaves
foo.run()inplace.Thisis wrongbecause,fromadeveloper’s point
of view,someMethod and the code in the following line are both
movedintothenew if-statement.However,manyapproaches(like
LASE) either do not express code movements accurately or can -
not handle them due to the type of patterns and algorithms the y
use [35, 36]. Since the latter only support delete,insert, andup-
dateoperationsonthecode,theycanonlylearntoinsert print(foo)
and/orfoo.print() ,butnot themoreaccuratecodemovement.
Toavoidthesetwosourcesofinaccuracy,thepatternrepres enta-
tionofAREScanbothexpressvariationsintheinputcodecha nges
andcodemovements.ARESalsousesalgorithmsthatcangener ate
moreaccuraterecommendations based onthesepatterns.
Fig. 2 shows theworkﬂow of ARES.The loopin theupper row
derives and reﬁnes a generalized pattern that represents al l the
codechangesinatrainingset.Theloopstartswithtwocodec hanges
from the input set and generates a pattern for them. Subseque nt
iterationsreﬁnethispatternbyconsideringthenextexamp lessuc-
cessively. With a Generalized Pattern ARES browses a given code
baseforlocationswherethepatternisapplicable( SearchforAppli-
cations). Itthenapplies thetransformationencoded inthepattern
to a copy of each found location ( Recommendation Creation ) and
presents thetransformedcopyas recommendation totheuser .
Sec.2explainsthepatterndesignandhowthishelpsincreat ing
moreaccuraterecommendations.Secs.3-6describethepatt erncre-
ation,thesearchforlocationstoapplythem,andthegenera tionof
therecommendations.WethenquantitativelycompareARESw ith
LASE in Sec.7,and discuss relatedwork beforeweconclude.
2 PATTERN DESIGN
ARES uses a pattern representation that is close to source co de.
Fig.3holdsanexamplepattern(basedonourpreviousworkon this
topic[15])thatexpresses(andgeneralizes)codechangesa ppliedto
acodebase.ThesetofcodechangesistheinputofARES.There are
two plain Java codeblocks in the pattern, one original codeb lock
thatrepresentstheinputexamplesbeforetheirtransforma tionand
one modiﬁed code block that represents the examples after th eir
transformation. To express variations in the input example s, the
patterns usea set ofannotations, addedas Java comments.
Theexamplepatternstartswiththe matchannotationthatsim-
ply declares the beginning of the pattern. The tags originaland
modiﬁed allow an easy distinction between the two code parts of
the patternfora human reader. Theoriginal partof the matchan-
notation also contains the letter k. Thiskstands for an identiﬁer
thatoccursinthepatternbodyandmeansthattheidentiﬁern ameofkis not ﬁxed and any variable name in a code location is an
acceptable replacement for k. In contrast, any location to which
the pattern is applicable has to use the identiﬁer name foo(line
12). The list of identiﬁers in the matchannotation is one mecha-
nism of ARES to express a generalization. When ARES creates a
recommendationitreplaces kwiththeactualvariablenameatthe
respectivecodelocation.This increases theaccuracyofth egener-
atedrecommendations.
Another generalization mechanism is the wildcard annotation.
It matches arbitrarycodeduringthe search for suitablecod eloca-
tions.Therearetwodiﬀerentversions.First,wildcardsta ggedwith
stmtaccept none or arbitrarystatements at the codelocation(se e
lines 8 and 11). This design provides a solution to the proble m of
thedeleted assertintheintroductoryexample(Fig.1)asitaccepts
theassertif it is present and has no eﬀect otherwise. Thus, stmt-
wildcards handle variations in thetraining examples and in crease
theaccuracyof thegenerated recommendations.
Second, wildcards tagged with expralways refer to the follow-
ing statement. They specify which part of it can contain an ar bi-
trary expression. It is possible to have several such wildca rds re-
ferring to the same statement. For example, the expr-wildcard in
line 2 speciﬁes that at the ﬁrst occurrence of verbosein line 3 the
search algorithm of ARES can allow arbitrary expressions. T his
means that at a possible code location for the pattern, the ca ll to
initmayhavenoneoranarbitrarynumberofarguments.Thishan-
dlesvariations inthetraining examples onan even ﬁner leve l.
Themodiﬁed part of the pattern does not contain wildcard but
useannotations. During the creation of a recommendation ARES
replacesthe useannotationwiththecodethatwasmatchedbythe
corresponding wildcard. A wildcard and ausecorrespond to each
otheriftheyhavethesamename(e.g., A1).Asthenamecanappear
anywhere in the modiﬁed part, a pattern can express movement s
1//#match (original, (k)) {
2//#wildcard expr(A1,verbose,1)
3this.init(verbose);
4this.shutdown();
5updateValue();
6k = 0;
7while(k < 10) {
8//#wildcard stmt(A2);
9k++;
10}
11//#wildcard stmt(A3);
12foo.someMethod(42);
13
14
15
16
17
18//# }
(a)Original part.//#match (modified) {
//#use (A1,verbose,1)
this.init(verbose);
updateValue();
for(k = 0; k < 10; k++) {
//#use (A2);
}
if(foo != null) {
foo.someMethod(42);
}
//#choice {
//#case
System.out.print(foo);
//#case
this.print(foo);
//# }
this.shutdown();
//# }
(b)Modiﬁed part.
Figure3: Generalizedpattern.More Accurate Recommendations for Method-Level Changes ES EC/FSE’17,September4-8,2017,Paderborn,Germany
of arbitrary code. This solves the accuracy problem of the mo ved
printmethodsintheintroductoryexample.
Themodiﬁed part of the pattern also contains a choiceannota-
tion. ARES creates this annotation if some training example s add
diﬀerent code.Astheaddedstatementshavenoconnectionto the
original code, ARES (and also other tools) cannot decide whi ch
statements lead to the most accurate recommendation. ARES i n-
stead lets the developer choose among the variants of the sam e
recommendation.Thus,the choiceannotationallowsAREStohan-
dleadditionalvariationsinthetrainingexamplestoincre aseaccu-
racy.
Theabovediscussiondemonstratesthatourpatterndesign c an
increase theaccuracyof recommendations.Howtogenerate s uch
patterns from examples and how to use them to create accurate
recommendation is covered in thenext sections.
3 INPUT ORDER DETERMINATION
Whenconstructingthegeneralizedpattern,ARESconsiders thein-
put code changes one after the other in the loop that is shown i n
the upper half of Fig. 2. The order in which ARES uses them in-
ﬂuences thepattern.Twochanges thatareverydiﬀerent (i.e ., that
have a large edit distance) probably lead to a generalized pa ttern
thatmakesexcessiveuseofwildcardstohideawaythediﬀere nces.
The resulting pattern is over-generalized and will match in many
locations of the code base. The smaller the edit distance bet ween
two changes is, the smaller are the diﬀering code fragments t hat
AREShidesinwildcards.Hence,thekeyideaisthatinevery i tera-
tionoftheloop,ARESﬁrstidentiﬁesacodechangethatisasc lose
tothecurrentworkinggeneralizedpatternaspossible.Ini tially,in
the ﬁrst iteration when there is no working generalized patt ern
ARES chooses the two code changes that are as close to all othe r
changes intheinput setas possible.
Todeterminetheeditdistance,ARESusesatreediﬀerencing al-
gorithm that extractsthediﬀerences betweentwo abstracts yntax
trees(ASTs).Ingeneral,thisismoreprecisethanapproach esbased
onstringsortokens.Thus,ARESusesatreediﬀerencingalgo rithm
to extract code diﬀerences throughout the whole process (un less
statedotherwise).Treediﬀerencing algorithmsdiﬀerwith respect
totheirprecisionintrackingcodemovements. Atreediﬀere ncing
algorithm that reliably detects code movements leads to an e dit
distance that better captures the closeness of two input exa mples,
whichisimportantfortheinputorderdetermination.Thus, ARES
uses MTDIFF [14], the currently most precise tree diﬀerenci ng al-
gorithm thatconsiders codemovements.
Let us sketch this input ordering process bymeans ofan exam-
ple. Assume that there are four codechanges c1..c4. Each of them
consists of an o riginal method block oiand a modiﬁed method
blockmi.Toobtainthedistancebetweentwocodechanges ciand
cj,AREScomputesthenumberofeditoperationsrequiredtotra ns-
formoiintoojplusthenumberofeditoperationstotransform mi
intomj.Table 1 holds some ﬁctitious edit distances for this exam-
ple. As initial pair, ARES selects the examples that represe nt the
two columns with thelowest sum ( c2 andc3 inthe example). The
ﬁrstiterationthenconstructsaworking GeneralizedPattern .Sec.4
below describes this step in detail. The next iteration of th e loopTable 1: Editdistancesbetweencodechanges c1..c4.
c1c2c3c4
c1-4 5 6
c24-2 2
c35 2 -2
c46 2 2 -
/summationtext.115 8 9 10
thencomputestheeditdistancesfromtheworkinggeneraliz edpat-
tern to the remaining code changes ( c1,c4) and uses the change
withthesmallest distancetoit forthenext iteration.
Picking input examples in an order that yields fewer wildcar ds
increases the accuracy of the recommendations as wildcards can
hidecodetransformations.Forexample,itispossiblethat thecom-
binationoftheworkingpatternwithaninputexampleforces ARES
togeneralize theloopsinFig. 3 into anextra wildcard.Ther esult-
ingpatternwouldstillmatchrelevant codelocationsinthe search
step,butARESwouldnolongertransformthe whileintoaforloop.
Thus,morewildcards leadtoless accuraterecommendations .
4 PATTERN CREATION
The input of the Pattern Creation step are two code changes ( c1
andc2)withtheirrespectiveoriginalandmodiﬁedmethodbodies .
Fig.4holdstherunningexampleforthissection,fromwhich ARES
creates the pattern in Fig. 3. As discussed in Sec. 2, this pat tern
solves theaccuracyproblems.
ThePattern Creation step adds wildcardannotations where the
original method bodies o1 ando2 diﬀer. Similarly, it adds usean-
notations where m1 andm2 diﬀer. To do so, ARES uses the tree
diﬀerencing algorithm MTDIFF which takes one original and o ne
modiﬁed AST as input and then matches nodes from the original
AST with nodes of the modiﬁed AST. Two nodes are a possible
match if they have the same type, e.g., if both are identiﬁers . MT-
DIFFusesheuristicsforthismatchingofnodes.Basedonthe node
matches, MTDIFF generates a small edit script , i.e., a list of edit
operationsthattransform theoriginal ASTinto themodiﬁed AST.
It uses four diﬀerent types of edit operations on the granula rity
of AST nodes, namely delete,insert,update, andmove. Themove
operationmoves acompletesubtreetoa new location.
Any AST node that is part of such an edit operation identiﬁes
achangebetweenthemethodbodiesthatthe PatternCreation han-
dleswithannotations.Italsokeepsalltheremainingcodeu nchanged
inthepatterntoincrease theaccuracy.
BelowweshowindetailhowARESusestheeditscripts D(o1,o2)
andD(m1,m2) providedbyMTDIFFtocreatethepattern.Todeter-
minethecorrectnames inthe useannotations ARESalsorequires
D(o1,m1) andD(o2,m2).Asthisprocessisthemostcomplexpartof
ARES,wepresent itin sixsteps.
4.1 Change Isolation
When ARES generates a pattern from the input examples, it has
to make sure that the edit scripts only cover the sections of t he
code that contain the actual change. Surrounding code that h as
nothing todowith thechange butstillis diﬀerent in theinpu t ex-
amples should not be part of the pattern. If there was no chang eESEC/FSE’17,September4-8,2017,Paderborn,Germany Geor gDotzler,MariusKamp, PatrickKreutzer,Michael Philippse n
1{
2d = 1.0;
3this.init(true);
4this.shutdown();
5updateValue();
6j = 0;
7while(j < 10) {
8String tmp = /quotedbl.Varbar/quotedbl.Var;
9this.init(verbose, tmp);
10j++;
11}
12assert (foo != null);
13
14foo.someMethod(23);
15
16
17
18
19
20}
(a)Original method o1ofc1.{
d = 1.0;
this.init(true);
updateValue();
for(j = 0; j < 10; j++) {
String tmp = /quotedbl.Varbar/quotedbl.Var;
this.init(verbose, tmp);
}
if(foo != null) {
foo.someMethod(23);
}
this.print(foo);
this.shutdown();
}
(b)Modiﬁed method m1ofc1.1try{
2this.i = 5;
3this.init(verbose);
4this.shutdown();
5updateValue();
6k = 0;
7while(k < 10) {
8updateValue();
9printValue(/quotedbl.Varfoo/quotedbl.Var);
10k++;
11}
12
13
14foo.someMethod(42);
15
16
17
18}catch(Exception e) {
19
20}
(c)Original method o2ofc2.try{
this.i = 5;
this.init(verbose);
updateValue();
for(k = 0; k < 10; k++) {
updateValue();
printValue(/quotedbl.Varfoo/quotedbl.Var);
}
if(foo != null) {
foo.someMethod(42);
}
System.out.print(foo);
this.shutdown();
}catch(Exception e) {
this.shutdown();
}
(d)Modiﬁed method m2ofc2.
Figure4: Codechanges c1andc2.
isolation,suchsurroundingcodewouldcauseanover-gener alized
patternand thusinaccuraterecommendations.InFig. 4chan gec1
does not have a trystatement whereas c2does. Withouta preced-
ing isolation of the main change, MTDIFF would create an insert
operation for the trystatement that in turn results in a wildcard
annotation. This would lead to an over-generalized pattern with
a single wildcard. To avoid this, ARES isolates the codepart s that
actuallycontaintherelevantchange,e.g.,thebodyofthe trynode.
ARESimplementsthenecessary ChangeIsolation intwophases.
The ﬁrst phase identiﬁes the lowest nodes in the ASTs that en-
capsulatethechanges, thesecond phase applies several heu ristics
if the ﬁrst phase still leads to an over-generalization. In t he ﬁrst
phase, ARES works with the ASTs of the original method oiand
thecorrespondingmodiﬁedmethod miofachange.Theeditscript
D(oi, mi)helps to identify the lowest root nodes in the two ASTs
that areaﬀected byalltheeditoperations.Eachsuch change -root
has the maximal distance from the root node of its AST and stil l
encapsulates all the diﬀerences between oandm. In the example,
thechange-rootof o1/m1isthecompletemethodblockfromline1
to20.Thechange-rootof o2/m2isthetrynode(duetothechange
in thecatch). As the roots are of diﬀerent types, selecting these
twonodeswouldstillleadtoanover-generalization. Thisa ndsim-
ilarinputexamples areaddressedbyphasetwo.Inalleasier cases,
ARES uses the change-roots for isolation and pattern genera tion
toexcludeallsurrounding code.
Iftheﬁrstphasecannotpreventanover-generalization,th esec-
ond phase applies the following three heuristics in the desc ribed
order: (a) Search for similar statements (i.e., statements paired to-
getherbyMTDIFF)inthechildrenofthechange-rootof o1andthe
childrenofthechange-rootof o2.Form1resp.m2,therehavetobe
matchingnodesin D(o1,m1) resp.D(o2,m2).(b)Reversetherolesof
c1 andc2 and thentry(a) again. (c) Performs (a) and (b) again but
thistimewiththegrandchildreninsteadofthechildren.If allthree
heuristics fail, thecurrent implementation of ARES stops w ithout
a generated patterntoreducetheexecutiontime.
On the example, phase two identiﬁes similar statements in th e
block ofc1 and in the bodyof the trystatement. These nodes iso-
late the actual change, avoid over-generalization in the re sultingpattern,and thus reduce theirrelevant and inaccurate reco mmen-
dations.
4.2 Edit Script Adjustment
WhileChange Isolation avoids over-generalization, Edit Script Ad-
justmentﬁndsabalancebetweenover-generalizationandover-ﬁttin g
(i.e., the creation of patterns that only match in very speci ﬁc sit-
uations, e.g., the training set). To keep a balance, ARES use s a
rule-based system with over 50 rules (rule description on Gi thub:
https://github.com/FAU-Inf2/ARES)—fartoomanytoprese ntindi-
viduallywithinthespacerestrictions ofthis paper.Hence , wecan
only discuss the two main issues that inﬂuence the balance an d
applytherelevant rules totherunning example.
The ﬁrst issue is that in most cases the tree diﬀerencing is to o
ﬁne-grained.Itoftenidentiﬁesmanysmallchangesonthele velof
expressions but only few changes on the level of statements, es-
pecially if the training examples are quite similar. The res ulting
patternsthenhave wildcards andusesforﬁne-grainedexpressions
that often only ﬁt the training examples. The accuracy of the rec-
ommendations willbehigh, buttherecallwillbelow.
Toavoid this,ARESlooksformatchingstatements thatvaryi n
many of their sub-expressions. In those situations, ARES ad justs
the MTDIFF-generated edit script to use a single edit operat ion
that covers the whole statement (instead of many edit operat ions
for all the diﬀering sub-expressions). For example, rule #4 8 (see
Fig.5)adjuststheeditscriptforadeclarationstatement. Itapplies
toline2inFig.4.Althoughboththeleftandtherighthandsi deof
the assignment diﬀer in o1 ando2, MTDIFF keeps the assignment
as this keeps the size of the edit script D(o1,o2)small. To avoid
over-ﬁtting,ARESadjuststheeditscriptandreplacesall deleteand
insertoperations for both the left and the right hand side of the
assignments (lines 8–9 in Fig. 5) with one insertoperation for a
full statement (line 10 in Fig. 5). Adding a deleteoperationfor the
assignmentisunnecessaryasthiswouldonlyleadtoawildca rdat
thesameposition.
Since ﬁnding an optimal list of edit operations that include s
code movements is NP-hard [10, 11], all move-aware tree diﬀe r-
encing algorithms rely on heuristics and there are cases in w hichMore Accurate Recommendations for Method-Level Changes ES EC/FSE’17,September4-8,2017,Paderborn,Germany
1:function /r.sc/u.sc/l.sc/e.sc48(editOps, mapping)
2: declMappings ←getDeclarationMappings(mapping)
3:for(do1, do2)∈declMappings do
4: l o1←leftSide(d o1);lo2←leftSide(d o2)
5: r o1←rightSide(d o1);ro2←rightSide(d o2)
6: ifisDeleted(l o1,editOps)∧isDeleted(r o1, editOps) then
7: ifisInserted(l o2,editOps)∧isInserted(r o2,editOps) then
8: removeOpsForT(l o1,editOps); removeOpsForT(r o1,editOps);
9: removeOpsForT(l o2,editOps); removeOpsForT(r o2,editOps);
10: addInsertForNode(d o2, editOps)
Figure5: Editscript adjustmentRule #48.
the edit script is not optimal. Any non-optimal list leads to un-
wanted wildcards and thus increases thegenerality unneces sarily.
This is the second balancing issue that the edit script adjus tment
addresses.
Forinstance,Rule#31examinesmovesacrossnestedcodeblo cks.
It applies to line 3 in Fig. 4. MTDIFF determines that the numb er
ofeditoperationsis minimized if thecodeofline9in o1is moved
to line 3 in o2. As a consequence, MTDIFF generates a moveoper-
ation. Due to this moveoperation, ARES would insert a wildcard
inline 3.This is toogeneral. Instead,theadjustmentstep r eplaces
themovewith adeleteoperations for thecall in line 9 of o1. Then
it addsthe insertoperationfor verboseinline 3of o2.
Rules#13–19handlemovementsofidenticalstatements.For ex-
ample,thereexisttwoidenticalstatementsin o2(lines5and8)for
the call in line 5 of o1. Although this is not a problem for the run-
ning example,theadjustmentstephas totakecareofwrongpa irs
oftwoidenticalstatementsinsidethetreediﬀerencingres ults.Oth-
erwise, there are unnecessary movesin the list of edit operations
which canlead toanover-generalized pattern.
Rules#42–46handlechangesthatarealreadycoveredbychan ges
oftheparentstatement.Theserulesapplytothelines8and9 ofo1
thatarereplacedbynewstatementsin o2.MTDIFFgenerates delete
andinsertoperationsforeachASTnodeinbothlines.Forexample,
MTDIFF generates a deleteoperation for String,tmp, etc. For the
Pattern Creation onlytheinsertfortheinvocations of updateValue
andprintValue ino2 are relevant. Thus, the rules remove all edit
operations onnodes thatare partof thestatements. For the delete
oftheassertinline12,ARESalsoreplaces thedeletedexpressions
witha single deleteofthecompletestatement.
4.3 MatchInsertion
Thisstepinsertsthe matchannotationintothegeneralizedpattern
(seeFig.3).Themainpurposeofthisannotationistoprovid ealist
of identiﬁer names that diﬀer between o1 ando2.Using wildcards
for them is too verbose and would unnecessarily enlarge the p at-
terns.Instead,ARESusesthematchednodepairsfrom D(o1,o2)to
ﬁndidentiﬁersinthesamematchpairbutwithdiﬀerentnames .For
therunningexample,thisisonlythepair (j,k)oftheloopvariables.
By mentioning the names in the annotation, ARES can remove
them from all updateoperations inboth D(o1,o2)andD(m1,m2) .
4.4 Wildcard and UseInsertion
This step adds the wildcardanduseannotations to the pattern ac-
cordingtotheeditoperationsthatareleftaftertheprevio ussteps.ARESreplaceseachstatementthatan insertaddsino2withawild-
card.If the insertoperationadds anexpression, ARESaddsa wild-
cardannotationinfrontofthestatement.Similarly,foreach insert
thataﬀectsexpressionsorstatementsin m2ARESadds useannota-
tions.Foreach deleteoperationthatremovesanodefrom o1ARES
adds awildcardannotation at the correspondingspotin o2 (deter-
mined with D(o1,o2)and the heuristics). In the same way, ARES
replaces each deleteinm1 with auseannotation in m2. Asmove
operations basically delete a node in o1/m1 and add it in o2/m2,
ARESadds wildcardsforthe deleteandinsertoperationexpressed
by themove. Note that at this point there are no longer update
operations as the edit script adjustment either removed the m or
replacedthemwith insertoperations.ARESalsomemorizeswhich
annotation belongs to which edit operation in order to facil itate
thefollowingnameassignment step.
Sinceintheexamplethe insertofverboseisleftinD(o1,o2),ARES
adds awildcard annotation before the statement and tags it with
expr.Additionally,itspeciﬁeswhichexpressioncorrespondst othe
wildcard ( verbose). As it is possible that an expression occurs sev-
eraltimesonthesamestatement,thewildcardinline3ofthe ﬁnal
pattern in Fig. 3(a) also speciﬁes the number of the occurren ce (1
fortheexample). Fig. 3(b) shows thecorresponding use.
Another operation is the insertof the assignment in line 2 of
c2. ARES replaces this assignment with a wildcard annotation in
o2. As it is a replacement for a complete statement, the tag stmt
is added to the wildcard. Similarly, ARES replaces the assig nment
inm2 with auseannotation. For the inserted statements in lines
8 and 9 ARES also inserts wildcardanduseannotations. After the
insertionoftheannotationsinline9,ARESimmediatelycom bines
bothadjacent annotations into a single one.
ARESproceeds with theremaining edit operationsin this fas h-
ionand ﬁnallycreates theresult inFig. 3.
4.5 Wildcard Name Assignment
This step assigns the names that link the wildcard annotations in
theoriginalparttothe useannotations inthemodiﬁedpart.Since
these names can occur in diﬀerent spots on both sides of a pat-
tern, they encode code movement. Hence, they are crucial for the
accuracyof therecommendations.
To identify the correct wildcard/usepairs, this step examines
thestatementsthatwerereplacedbywildcards(memorizedb ythe
previousstep).Intherunningexample,awildcardreplaced update-
Valueinline8of o2.ThenARESuses D(o2,m2) toﬁndanodein m2
thatismatchedtothemoved updateValue fromo2.Intheexample,
thematchednodeis thecall of updateValue inm2.AsupdateValue
inm2was alsoreplaced bya use, ARES links the wildcardanduse
of the call together and gives them the same name ( A2in the ex-
ample).Similarly,ARES assigns theothernames tocreate Fi g. 3.
The previous steps may create a patternthat starts with a stmt
wildcard. However, when searching for applications it is un clear
which sequence of statements this wildcard should match. Th ere-
fore, ARES enforces that patterns begin with a speciﬁc state ment
instead of a wildcard. In the running example, ARES removes t he
wildcard that replaced the assignment in line 2 of o2. If there is a
corresponding usewiththesamenameandthis useisalsotheﬁrst
statement in the pattern, ARES also removes it. The same appl iesESEC/FSE’17,September4-8,2017,Paderborn,Germany Geor gDotzler,MariusKamp, PatrickKreutzer,Michael Philippse n
tostmtwildcards attheend ofthepatternasthey matchthecom-
plete remaining function and thus the recommendation would be
unnecessarily large. The evaluation shows that this has no n ega-
tive impact on precision and recall compared to other recomm en-
dationsystems.If theassigned useofaremoved wildcardisnotat
the top or bottom of the pattern, ARES keeps the useannotation
and only removes the assigned name. This is necessary since t he
corresponding wildcardis no longer present.
4.6 Choice Insertion
The ﬁnal step handles diﬀerences between the modiﬁed parts o f
the code changes that do not correspond to code in the origina l
parts.Toincreasetheaccuracyoftherecommendationsitis neces-
sarytohandlethosediﬀerencesexplicitly.Aftertheprevi oussteps,
the diﬀerences are visible as they correspond to useannotations
without assigned names. This step replaces each such usewith a
choiceannotationbecausetheinputexamples provideinsuﬃcient
information to determine the right recommendation based on a
purelysyntactical approach.
Intherunningexample,the usethatreplacedthe assertandprint
callhasnoassignednameandisthuschangedintoa choiceannota-
tion. Based on c1 andc2 it is impossible to determine which print
invocation should be part of the recommendation. Hence, ARE S
generates several recommendations, one for each variant. I t is up
to the developer to decide which of the recommendations is th e
most appropriate. Similar to the name assignment process, A RES
onlyhastoexaminethestatementthatwasreplacedbythe usean-
notationtoidentify thecodeforthe caseannotations inFig. 3(b).
5 SEARCH FORAPPLICATIONS
ThissectionexplainshowARESﬁndscodelocationswhereagi ven
pattern is applicable. For a high accuracy, it is important t hat the
algorithm identiﬁes the correct matches between the AST nod es
in the pattern (including wildcards) and AST nodes at the cod e
location.Tomakethealgorithmasfastaspossible,thissec tionno
longer relies on a tree structure but uses a serialized list o f AST
nodes. However, this is no limitationto the movement suppor tas
theRecommendationCreation (Sec. 6) handles them.
As exampleweusethepatterninFig.3and browsethecodein
Fig.6(a).ARESﬁrstsearchesforsuitablestartingpointsi nthecode
and then executes the AST-node matching from there in parall el.
SuchastartingpointisanASTnodethathasthesametypeasth e
ﬁrst AST node in the original part of the pattern and that is no t
partofanannotation.TheﬁrstnodeinFig. 3is themethodcal lin
line 3. Suitable starting points in Fig. 6(a) are the calls in lines 2,
3, 4, 7, and 10. ARES uses each of these calls as a startNode when
executingthealgorithmgiveninFig.7.Theotherinputargu ments
aretheASTofthemethodthatcontains startNode andtheASTof
theoriginal partofthepattern.
In lines 2 and 3 of Fig. 7, ARES generates a list of AST nodes
forthecodelocation(startingat startNode )andalistofASTnodes
for the pattern (starting from the ﬁrst code node in the body o f
thematchannotation). With the loop in lines 6–29 the algorithm
compares both lists of AST nodes to determine whether they ar e
identical(withrespecttothewildcards),inwhichcasethe pattern
is applicabletothecodelocationthat startsat startNode .1Foo foo = Library.getObject();
2this.init(getVerbose());
3this.shutdown();
4updateValue();
5c = 0;
6while(c < 10) {
7System.out.println(c);
8c++;
9}
10foo.someMethod(99);
11return foo;
(a) Matchingcodelocation.Foo foo = Library.getObject();
this.init(getVerbose);
updateValue();
for(c = 0; c < 10; c++) {
System.out.println(c);
}
if(foo != null) {
foo.someMethod(99);
}
this.shutdown();
return foo;
(b)Recommendation.
Figure6: RecommendationCreation.
Intherunning example,bothlistsstartwitha callnode.Asthe
node of the pattern is not a wildcard, w(line 13) is nulland the
algorithm uses isMatchto compare n clof the code location with
npofthepattern.Thefunction isMatchreturnstrueifthetypesof
these AST nodes are identical (e.g., if both are callnodes). There
areonlytwoexceptions.IfbothASTnodesareidentiﬁers, isMatch
is true if n pis in the list of identiﬁers of the matchannotation or
if the identiﬁer names are equal. The second exception conce rns
boolean constants as they make a large diﬀerence in the patte rn
due to their limited value range. In this case, isMatchis only true
if both are identical. ARES does not compare the values of oth er
constants.Thisincreasesthegeneralizationofapatterna ndmakes
itapplicabletomorecodelocationsbecausediﬀerentliter alsdonot
prevent a patternfrombeing applicable.
Ifthecomparisonwith isMatchissuccessful,thealgorithmadds
thepair(n cl,np)tothesetofmatchednodes( matches).Therecom-
mendationalgorithmlaterusesthissettoreplacetheident iﬁersin
thepattern(e.g., k)withidentiﬁersofthecodelocation(e.g., c)and
1:function /s.sc/e.sc/a.sc/r.sc/c.sc/h.sc(startNode,methodBody, originalPatternPart)
2: NL cl←getNodes(methodBody, startNode)
3: NL p←getPatternNodes(originalPatternPart)
4: pos cl←0;posp←0
5: resets←∅;matches←∅;visited←∅
6:whileposcl<|NLcl|∧posp<|NLp|do
7: n cl←getNode(NL cl, poscl);np←getNode(NL p,posp)
8: w←null
9: ifisWildcard(n p)then
10: w←np
11: else ifhasAssociatedWildcard(n p)then
12: w←getAssociatedWildcard(n p)
13: ifw=nullthen
14: ifisMatch(n cl,np, originalPatternPart) then
15: matches ←(ncl, np)
16: pos cl←poscl+1; posp←posp+ 1
17: continue
18: else
19: ifw/nelementvisitedthen
20: addLast(resets,(pos cl,posp+1,matches,visited))
21: visited ←visited∪w
22: ifallowedNode(w, n cl)then
23: matches ←(ncl, w)
24: ifallowedReset(w, n cl)then
25: addLast(resets,(pos cl+ 1,posp+1, matches,visited))
26: pos cl←poscl+1
27: continue
28: ifresets=∅thenreturn null
29: (pos cl, posp,matches,visited)←removeLast(resets)
30:ifposp=|NLp|then
31: returnmatches
32:else
33: returnnull
Figure7: Algorithm tosearch for suitablecodelocations.More Accurate Recommendations for Method-Level Changes ES EC/FSE’17,September4-8,2017,Paderborn,Germany
also toreplace constants in thepattern(e.g., 42) withcons tants in
thecodelocation(e.g.,99).Ifthecomparisonwith isMatchisunsuc-
cessful,thealgorithmlooksforanothervalidpositiontob acktrack
(lines 28–29).If thereisavalid position,ARESresets thev ariables
tothesaved values and continues from thelast validpositio n.
Backtracking is necessary due to the use of wildcards. The pa t-
tern design (see Sec. 2) allows a wildcard to replace none or m ore
statements/expressions. This leadstoseveral validend po intsofa
wildcard match and creates the reset nodes. In the example, t he
nodeverboseis associated with a wildcard. Thus, getAssociated-
Wildcard identiﬁes the wildcard in line 3 of the pattern. As this is
theﬁrstappearanceof this wildcard,thealgorithmcreates avalid
reset position in line 20. This reset position covers the cas e that
the wildcard is empty and does not match any code at this loca-
tion. The reset point starts at the position after verbose(posp+ 1)
and thus continues withoutamatch.
Inourexample, inithasanargumentandthusthewildcardhasa
nodetomatch.Thefunction allowedNode checkswhetherthewild-
card canreplacen cl.Areplacement ispossibleif n cliswithinthe
scopeofthewildcard.Forthewildcardinline2,thescopeco nsists
of the arguments of init. Here this is the case and the algorithm
adds the appropriate match (line 23). If n clis also the last node
of one argument of init, the node is also a valid end point of the
wildcard and the algorithm adds a new reset point that starts at
the end of the argument (lines 24–25). Then the search contin ues
at the next node in the list of the codelocation (lines 26–27) . The
algorithmhandlestheotherwildcards(lines8,11)inasimi larfash-
ion. The diﬀerence is only that this time allowedNode accepts all
nodes from the current code block and allowedReset accepts only
completestatements.
Aftertheloopterminates,thealgorithmcheckswhetherthe pro-
cess reached the end of the template and thus whether the code
locationmatches all nodes of the template. In this case thes earch
is successful and returns theset ofmatched nodes (lines 30– 33).
6 RECOMMENDATION CREATION
ThegeneralideaofthecreationstepistouseMTDIFFtocreat ethe
list of edit operations that change the originalpart of the pattern
intothemodiﬁedpart(seeFig.3)andtoapplytheseeditoperations
toacopyofthecodelocation(identiﬁedinthepreviousstep ).Note
thatARESdoesnotusethe modiﬁedpartofthepatternasthebase
for the recommendation. Using the list of edit operations in stead
hastheadvantagethatAREScanpreservepartsofthecopiedc ode,
e.g.,theidentiﬁer candthenumber 99(seeFig.6(a)).Thisincreases
theaccuracyof therecommendation.
To be able to apply the list of edit operations, the copied cod e
has to look like the originalpart of the pattern. For that purpose,
ARES removes all AST nodes from the copy that were matched
withawildcardduringthesearch.ThenARESinsertsthewild card
annotationsintothecopy.Afterthesechanges,thecopyloo kslike
theoriginalpartofthepatterninFig.3(a)exceptforthepreserved
codeparts.ThisallowsAREStoapplytheeditoperationstoc reate
themodiﬁedpartofthepattern(withrespecttothepreservedcode
parts).ThenARESreplacesthe useannotationswiththecodethat
is paired with the corresponding wildcard, i.e., the wildca rd with
thesame name.Finally,ARESworksonthe choiceannotations.Forasingle choice
ARES could create one copy of the recommendation per case. If
therearemore choices,thenconceptuallythereisthepotentialfor
exponential growth. Hence, ARES limits the number of copies . If
thereareatmost maxcasestatementsinall choices(2intheexam-
ple),AREScreates max+1 copiesof thecurrent recommendation
code.The n-thcopycontainsthecodeinthe n-thcaseannotationof
eachchoice.If achoiceannotationhasfewer than ncases,weomit
this choice completely. This implies that the last copy does not
contain any code from choiceannotations. After this step, ARES
presentsthe max+1copiesasvariantsofonerecommendationto
thedeveloper.
7 EVALUATION
WeﬁrstevaluatetheaccuracyofARESandcompareitwiththat of
LASE [29], before we show that the improved accuracy does not
gravely impact precision, recall, or execution times. For a ll mea-
surements we use a workstation with 128 GB of RAM and a 3.6
GHz Intel Xeon CPU, OpenJDK 8 and Ubuntu 16.10. We also dis-
cussthecurrent limitations ofARES inthis section.
7.1 Accuracy
Ourbenchmarkscompriseseveralreal-worldsourcecodearc hives
thatvarywithrespecttothenumberandsizeofthesetsoftra ining
examples (similar code changes). We always check how close t he
recommended code changes get to changes that can actually be
foundin thecommits.
Eclipse—Two Input Code Changes. In this part, we use 2
groups of similar code changes (Bugzilla Ids 77644, 82429) f rom
theEclipse JDT project [1] and 21 groups from the Eclipse SWT
project [2]. Meng et al. [29] used the same manually collected 23
groups for their evaluation of LASE. All these code changes a re
present in commitsof therespectiverepositories.
Table2 lists the BugzillaIds of thechanges; mis the sizeof the
group of similar code changes that exist in the repositories for a
bug.Inmostcases, mis equaltotheevaluationprovidedbyMeng
etal.TheonlyexceptionsaretherowswithIds20and21forwh ich
weidentiﬁed a diﬀerent number of changes intherepository.
For the next two segments of Table 2 ( LASE—Two Input Code
Changes,ARES—Two Input Code Changes ) we use the same two
changesofagroupforthecreationofthepatterns.Wecarefu llyse-
lectedthetwochanges toreproducethesameprecisionandre call
values thatMeng etal.[29] listintheir evaluation.
For each of the 23 bug ﬁxes, the △-columns list the number of
codelocationsforwhichLASEandAREScreatearecommendati on.
The columns marked with /checkshow how many of the mmanually
identiﬁed locations the tools ﬁnd. For each of them column AT
andACgive the accuracy, i.e., the closeness of the recommenda-
tion to the code that the original developers of the change wr ote.
Thus, a perfect accuracy means that the recommendation has t he
same statements, moved code and identiﬁers that are present in
the repository. For developers this is important because a h igher
accuracy means less work to actuallyapply a recommendation to
a project. To measure the accuracy we compute the Levenshtei n
distance [24] (LD) between the method body of the recommenda -
tionandthemethodbodyofthechangedcodefromthereposito ry.ESEC/FSE’17,September4-8,2017,Paderborn,Germany Geor gDotzler,MariusKamp, PatrickKreutzer,Michael Philippse n
Table 2: Comparison withLASE on23 codechangesfrom Eclipse JDTand EclipseSWT.
LASE—TwoInputCode Changes ARES—TwoInputCode Changes ARES—All Code changes
IdBugzillaIdm△/checkAT%AC%P%R%△/checkAT%AC%P%R%△/checkAT%AC%P%R%
177644 4225252100502284 83100504490 89100100
282429 161414664010088211468/8176/8467882516 54 6164100
3114007 444948110010044100 100100100 44100 100100100
4139329162299861003322100 1001003335680 8217100
5142947112121298891001001212100 1001001001212100 100100100
691937 333503710010033100 100100100 33100 100100100
7103863 777324310010077100 100100100 77100 100100100
8129314 44496801001003294/10094/10067505495/10095/10080100
9134091 44479561001004499 99100100 4499 99100100
1013932923436364751003395 94100100 3357/10056/100100100
111393293333927510010033100 100100100 33100 100100100
12142947291297461751007678/8974/87866712978/9075/8975100
13 76182 66656581001006692 92100100 6692 92100100
14 77194 33379581001002298 98100673396 97100100
15860791333926910010022100 100100673393 92100100
16 95409 9884946100894442/8543/841004418945/6847/6950100
17 97981 43371561007533100 1001007544100 100100100
18 76391 63397861005033100 1001005096100 10067100
19 89785 55591751001005597 94100100 5584/10079/99100100
20 79107 10261096753810012499 9933402710 98 9737100
2186079232299731006722100 100100673373/10075/100100100
22 95116 54497831008044100 1001008055100 100100100
23 98198 15671261511880381071/9375/9426673561576/9579/954100
Avg. 695786592877592/9692/96907624687/9488/9482100
m:AvailableLocations; △: Generated Recommendations; /checkCorrectRecommendations;
AT%:TokenAccuracy; AT%:CharacterAccuracy; P%:Precision; R%:Recall;
Weusetwovariants. Theﬁrstuses ASTtokens ( T), thesecond ac-
tualcharacters( C).A high tokenaccuracy ATshows thattherec-
ommendationis accuratewith respecttothesyntax (e.g., us es the
samenumberof ifstatements).Weuse AT=1−LDT/max(|rT|,|mT|),
where|rT|is the number of tokens in the recommendation and
|mT|isthenumberoftokensinthemethodbodyfromthereposi-
tory.As comments are not part of any token, they are ignored f or
thismeasurement.Wealsodeﬁne AC=1−LDC/max(|rC|,|mC|),
where|rC|is the number of characters in the recommendation
and|mC|isthenumberofcharactersinthemethodbodyfromthe
repository.Thisincludesbothcommentsandwhitespace.Ea chcell
intheaccuracycolumnscontains themeanofthecorrectlyid enti-
ﬁed recommendations ( /check).
Across all groups of codechanges, ARES can producemore ac-
curate recommendations compared to LASE and even achieves a
perfect accuracy (100%) for 11 of the 23 groups. For these gro ups,
the recommendations are identical to the changes that were a ctu-
ally performed by a human developer. A closer inspection of t he
recommendations by LASE shows that LASE ignores code trans-
formations that occur only in one of the input examples which
reducesAT. For some cases, the ARES accuracy column contains
twovalues.Inthesecases,thepatterncontainsachoiceann otation
andARESgeneratesseveralrecommendationvariants. ATandAC
give the minimal and the maximal accuracy values for the corr e-
sponding groups. In 3 of the 5 cases (Ids: 2, 12,23), even the m ini-
malvaluesfor ATofARESoutperformLASE.Often(for11groups)
ARESachievesperfectaccuracyvalues(100%)in AC.Hence,ARES
recommends exactly the code a developer has written, includ ing
comments, codingstyle,and whitespace.
Eclipse—All Code Changes. In some cases (e.g., patterns for
critical bugs) a high recall is more important than a high pre ci-
sion (and accuracy). For these cases, ARES supports more tha n
two input changes. Each additional change in the training se t can
increase the number of wildcards and hence the recall. Howev er,
each additionalwildcardcanalsodecreaseprecisionandac curacy.Toexaminetheeﬀectsofadditionalinputchangesweaddedat hird
set of evaluation results in Table 2 ( ARES—All Code Changes ). For
theseresults,ARESusesallinputchangestocreateapatter n.Thus,
we maximize the recall and minimize precision and accuracy f or
each of thegroups.
Forthisset,theaccuracyofARESisstillat94%(87%inthemi n-
imalchoicecase) onaverage. In mostcases,theaccuracyofA RES
inthisconﬁgurationisalsohigherthantheaccuracyofLASE with
only two input changes. This means that even with the most gen -
eral pattern for a group and thus the pattern with the least ac cu-
racy, ARES still achieves higher accuracy values than LASE. Also,
ARESstillhas aperfectaccuracyfor8 groups.
JUnit—AllCodeChanges. TheaboveanalysisshowsthatARES
achievesahigheraccuracyforthe23groupsofcodechangesf rom
Eclipse. A threat to the validity of these results is that it i s pos-
sible to optimize a system for such a small dataset. To examin e
whetherARESalsohashigheraccuracyvaluesforalargerdat aset,
we use 3,904 groups of code changes from JUnit [3] taken from
theresults of C3[23].C3is a toolthat identiﬁes groups of similar
codechanges incoderepositorieswiththehelpofclusterin galgo-
rithms. The groups by C3are suitable inputs for ARES and LASE.
This time we use all input examples (not only two) to train ARE S
and LASE.
Whereas it is again possible to measure the accuracy (as the
manual code changes are in the repository) there cannot be nu m-
bersfor precisionand recallas mis unknown forthis dataset.
Table 3 shows the accuracy results for JUnit. For 482 sets of i n-
putchanges bothLASE and ARES producerecommendations and
generate a recommendation for the input changes. We exclude d
inputchangesforwhichoneofthetoolsproducesanerrorord oes
not recommend a change. Similar to the evaluation above, ARE S
reaches a high accuracy of 91% to 100%. Again for most groups,
the accuracy of ARES is higher than that achieved by LASE. Thi s
is alsotruefor theminimal accuracyvalues.More Accurate Recommendations for Method-Level Changes ES EC/FSE’17,September4-8,2017,Paderborn,Germany
7.2 Precision, Recall,and Time Measurements
Precision&Recall. Letusnowcomparetheprecision P(/check
△),and
recallR(/check
m)values.Thehigher theprecisionand recall,thebetter
isthetool.Overall,theprecisionofARESissimilartothat ofLASE.
For 20 of the 23 groups of code changes the precision of ARES is
identicaltoorhigherthanthatofLASE.Theaveragerecallo fARES
isstillatahighlevel(76%)butbelowthatofLASE(87%).How ever,
Christakis and Bird [13]found in their studythat therecall is less
importanttodeveloperscomparedtoahighprecision.Hence ,with
respect to precision and recall there are (almost) no costs f or the
improved accuracyofARES.
A closer look reveals that ARES is more precise than LASE for
three change groups (Ids: 10,12,23) becauseof two reasons. First,
AREScanhandlevariationsintheinputchanges withappropr iate
wildcards. Instead, LASE uses the Maximum Common Embedded
Subtree Extraction algorithm to identify the common AST that all
training examples share and which is moregeneral in some cas es.
Second, ARES keeps common code, even if it is unrelated to the
changes, whereas LASE identiﬁes code that has no dependenci es
tothecodechange and excludes itfrom thepattern.
While it can be beneﬁcial to keep some unrelated code in the
pattern, keeping too much of it causes a loss of precision (Id 8)
or recall. There is room for more research concerning this is sue.
In contrast to LASE, ARES is also currently limited to themet hod
body and does not include the method signature in the pattern s.
This lack of a signature in thepatternlowers theprecision i n two
cases (Ids: 2,20).
Thegroups20and23areoutliersastheprecisionofbothARES
andLASEisconsiderablylowercomparedtotheothergroups. The
reason is that the input examples for both groups only add the
same statements and otherwise have very little code in commo n.
This leads toshortand very general patterns.
Time Measurements. Here we compare the times that ARES
and LASE take to create the patterns and to use them when they
browsetheprojectsforpossiblepatternapplications(Ecl ipseSWT:
∼2,000 Java ﬁles, ∼375,000lines of code; Eclipse JDT: ∼5,750 Java
ﬁles,∼1,372,000LOC). Fig. 8 shows the measurements. Each code
change (row in Table 2) corresponds to one measurement point .
The lines in the boxes are the medians of the time measurement s.
Theboxesoftheplotdeﬁnethe25%and75%quartiles,thewhis kers
show theminimum and maximum.
AREScreatespatternsfasterthanLASE( PatternCreation inFig.8)
because the ChangeDistiller [17] tree diﬀerencing algorit hm that
LASE uses has a higher runtime than MTDIFF [14]. However, the
search for pattern applications in ARES ( Pattern Use in Fig. 8) is
slowerbecausethepatternsofARESarecurrentlylimitedto method
bodies and do not contain method signatures. LASE can use the
method signature to ﬁlter out methods and thus has to inspect
Table 3: Accuracyon JUnit.
LASE ARES(Min/Max)
Groups of Code Changes 3,904
Shared Recommendations 482
Shared Recommendations AT(Mean)% 90 91/97
Shared Recommendations AT(Median) % 100 100/100
Shared Recommendations AC(Mean)% 76 90/95
Shared Recommendations AC(Median) % 82 100/1000 20 40 60 80ARES —Pattern UseLASE —Pattern UseARES —Pattern CreationLASE —Pattern Creation
Execution time (sec.)
Figure8:Timeperchangegroupfortwoinputcodechanges
(25%/75%quartiles,whiskers:minimum/maximum).
fewer method bodies. Still, even for such large repositorie s ARES
completesthesearchforonepatternwithinaminuteinmostc ases.
7.3 Limitations and Threats to Validity
Themajor limitation of ARES is thecurrent restriction tome thod
bodies.Duetothis restrictionwealsohadtoexcludethegro upof
code changes with Bugzilla Id 74139 that Meng et al. [29] use i n
their evaluationof LASE. This was necessary as thecodechan ges
inthisgrouponlyhaveacommonsignaturebutnocommonstate -
ments.
WhereasboththesearchandrecommendationcreationofARES
already support larger changes, extending the pattern crea tion to
work with full classes would need annotations that, for exam ple,
deﬁne when methods or ﬁelds can be reordered. The pattern cre -
ation would also require new rules and transformations for w ild-
cards outsideofcodeblocks.
AnotherlimitationisthatARES(likeLASE)canonlysearchf or
onepatternatatime.Similartotheirapplicationincodecl onede-
tectiontools,suﬃxtrees[21]mayacceleratethesearchfor several
patternsin parallel.
Thethreattovalidityoftheevaluationistheimplementati onof
LASEthatwebuiltfromapubliclyavailableversion[4].Weh adto
applyseveralbugﬁxestobeabletoreplicatetheevaluation results
of Meng et al. [29]. Despite our eﬀorts, there are still some s mall
diﬀerencesleft.Wealsochangedtheimplementationtobypa ssthe
UI to enable script-based performance measurements. We arg ue
thatifwehaveintroducednewerrorstheyareprobablysmall since
weobtained mostoftheoriginal results.
8 RELATED WORK
The book Recommendation Systems in Software Engineering [34]
and the study by Gasparic and Janes [18] provide an overview o f
therelatedwork.Wediscuss theworks closesttoARES.
Example-basedrecommendation. LASE[29]isclosesttoARES.
The main diﬀerences are that LASE does not handle moved code
partsaccuratelyand thus theaccuracyof therecommendatio ns is
lower. RASE [27] relies on LASE to create a generalized patte rn
from examples. With this pattern it refactors the code witho ut al-
tering its semantics to replace all changed locations with a sin-
gle unifying code fragment. Thus, it has the same low accurac y
as LASE and also only supportsrefactorings. In contrast to A RES,
SYDIT [28] generates an edit script from just one example whi ch
limits its generalization ability. Developers also must ﬁn d patternESEC/FSE’17,September4-8,2017,Paderborn,Germany Geor gDotzler,MariusKamp, PatrickKreutzer,Michael Philippse n
applicationsmanuallywithSYDITwhereasARESﬁndsthemaut o-
matically.Critics[43]addressesthereviewprocess.Thed eveloper
provides a generalization of a single codechange as input. C ritics
thenﬁndsmatchingspotsinthecodewhereasimilarchangema y
have been forgotten or where an inconsistent modiﬁcation ma y
haveoccurred.ForCritics,itisthetaskofthedeveloperto provide
the generalization and to take care of the design of the patte rn to
increase theaccuracy.AREScreates thepatternautomatica lly.
REFAZER [35] is another toolthatlearns codetransformatio ns
from examples. It uses a domain speciﬁc language (DSL) to rep -
resent code change patterns. In contrast to ARES, the algori thms
thatgeneratethispatterndonotsupportcodemovementsand thus
if a code pattern relies on movements it cannot be as accurate as
ARES. Currently, a direct comparisonis not possibleas REFA ZER
onlysupportsC# and Python whereas ARESuses Java.
Santosetal.[36]comparethreediﬀerent ways(structural, AST-
based, information retrieval) to search for additional cod e change
locationsbasedonuptotwoexamples.Ifasearchﬁndssuchal oca-
tion,theirsystemappliesasetofcodechanges.Ifthisissu ccessful,
their system recommends the code change. Their AST-based ap -
proach uses the longest common subsequence (LCS) [9] and thu s
is less precise then ARES in regard to moved code. Also this ap -
proach is time consuming as it requires the execution of the L CS
on many diﬀerent ASTs. ARES is faster as its backtracking alg o-
rithm can abort the search for possible pattern application s ear-
lier. Their information retrieval approach relies on the si milarity
of code parts (e.g., variable names) and is less precise then ARES
that includes the code structure in the pattern. Their struc tural
approach searches for methods with similar signatures, pac kages,
etc. The authors argue that this is useful in combination wit h the
AST-based and information retrieval approaches. It is poss ible to
includetheir structuralapproach inAREStoincrease preci sion.
Tate et al. [37] use a proof-checker to learn transformation s
from examples. They can only ﬁnd provably semantic-preserv ing
transformations.
Padioleau et al. [32] introduce semantic patches to manuall y
generalize patches obtained from standard diﬀ tools.Ander sen et
al. [5, 6] extend this idea and introduce a tool that creates g en-
eralized (semantic) patches from hand-picked diﬀs. ARES is more
accurate as it supports code movements whereas diﬀs are limi ted
toinsertanddeleteoperations.
Code completion. Cookbook [19] uses generalizations from
examples to suggest code completions while the developer is typ-
ing. In contrast to ARES it is a line based approach and does no t
support code movements and thus has a lower accuracy if code
movements are necessary. MAPO [44] and Precise [42] search f or
similar API usages in code repositories. MAPO recommends fr e-
quently used call sequences. Precise extracts API calls inc luding
theirargumentvaluesandcorrespondingdeclarationsfrom repos-
itories, extracts groups with similar arguments using a k-n earest
neighbor algorithm, and generates API usage recommendatio ns,
includingpossibleparameters.Bruchetal.[12]alsouseak -nearest
neighbor algorithm and ﬁnd code fragments that are similar t o
code that is currently being developed. Bajracharya et al. [ 7] use
structural semantic indexing for this purpose. All focus on code
completionsandthussmallcodingsuggestions. Incontrast ,ARESstrivestosuggestlargertransformationsincludingchang esofcom-
pletemethods.
Specialized recommendation. In addition to example-based
approaches, there are also tools for speciﬁc tasks. CFix [20 ] uses
predeﬁnedpatternstoautomaticallyﬁxconcurrencybugs.W eimer
etal.[41]andAutoFix-E[40]generatebugﬁxesautomatical ly,but
arelimitedtotestableﬁxesandspeciﬁcations.RobbesandL anza[33]
learn code transformations by examining edit operations in the
IDE.Theirtoolcannotautomaticallyﬁndlocations.Strate go/XT[38]
andDMS[8]oﬀerDSLstospecifyASTtransformations.Mannie sing
etal.[25]focusonlooptransformations.Otherworkssolel ylocate
patternsinsourcecode,e.g.,theDependencyQueryLanguag e[39]
or the Program Query Language [26]. In contrast to ARES, deve l-
opersmustspecifypatternsmanually.Theyalsodonotgetre com-
mendations. Miller et al. [30] let developers select multip le code
fragmentsandthentheyapplyachangetoalloftheminthesam e
fashion. In contrast to ARES this is limited to identical cha nges
and developers havetoﬁnd thecodelocationsthemselves. Th ung
et al. [16] introduce a recommendation system that supports de-
velopers in backporting Linux drivers. Their framework is s pecif-
ically tailored to the backporting and is not intended for ge neral
codechange recommendations.
9 CONCLUSION
WepresentedthenovelAccurateREcommendationSystem(ARE S)
that specializes on code movements to increase the accuracy of
coderecommendations. A higher accuracy means that ARES gen -
erates coderecommendations that better reﬂect what a devel oper
would have written. ARES achieves the higher accuracy resul ts
with a pattern design that expresses code movements more ac-
curately compared to the state-of-the-art. Similar to othe r tools,
ARESgeneratesthesepatternsfromsourcecodetrainingexa mples.
ThegeneratedpatternsofAREScontainonlyplainJavacodew ith
a set ofannotations and therefore are not a black boxfordeve lop-
ers.Thus,developers canread and manuallyadaptthepatter ns.
We also presented in detail how ARES generates, generalizes ,
and applies these patterns. With these techniques ARES achi eves
anaveragerecommendationaccuracyof96%inourevaluation and
outperformsLASE. Precision and recall are onpar. The execu tion
timeisabithigher,butstillbelowtwominutesforlargerea l-world
sourcecodearchives.
Forreproducibilityandtokindlefurtherresearch,weopen -source
ARES,therulesfortheeditscriptadjustment,alltheevalu ationin-
putsandresults,includingthehuman-readablepatternsge nerated
byARES(https://github.com/FAU-Inf2/ARES).
REFERENCES
[1] 2017. Eclipse JDT Repository. (2017).
git://git.eclipse.org/gitroot/jdt/eclipse.jdt.core. git.
[2] 2017. Eclipse SWT Repository. (2017).
http://git.eclipse.org/c/platform/eclipse.platform. swt.git/.
[3] 2017. JUnit Repository. (2017). https://github.com/j unit-team/junit4.git.
[4] 2017. LASE. (2017). https://www.cs.utexas.edu/%7Eme ngna09/projects.html.
[5] Jesper Andersen and Julia L. Lawall. 2008. Generic Patch Inference. In ASE’08:
Intl. Conf. Automated Softw.Eng. L’Aquila,Italy,337–346.
[6] JesperAndersen,AnhCuongNguyen,DavidLo,JuliaL.Law all,andSiau-Cheng
Khoo. 2012. Semantic Patch Inference. In ASE’12: Intl. Conf. Automated Softw.
Eng.Essen,Germany,382–385.
[7] SushilK.Bajracharya,JoelOssher,andCristinaV.Lope s.2010.LeveragingUsage
Similarity for Eﬀective Retrieval of Examples in Code Repos itories. In FSE’10:More Accurate Recommendations for Method-Level Changes ES EC/FSE’17,September4-8,2017,Paderborn,Germany
Intl. Symp. Foundations ofSoftw. Eng. Santa Fe, NM,157–166.
[8] Ira D. Baxter, ChristopherPidgeon, and Michael Mehlich . 2004. DMS:Program
TransformationsforPracticalScalableSoftwareEvolutio n.InICSE’04:Intl.Conf.
Softw.Eng. Edinburgh, Scotland, 625–634.
[9] LasseBergroth,HarriHakonen,andTimoRaita.2000.ASu rveyofLongestCom-
mon Subsequence Algorithms. In SPIRE’00: String Processing and Inf. Retrieval
Symp.A Coruna,Spain,39–48.
[10] Philip Bille. 2005. A surveyontree edit distance and re latedproblems. Theoret-
ical ComputerScience 337, 1(June 2005), 217–239.
[11] Utsav Boobna and Michel de Rougemont. [n. d.]. Correcto rs for XML Data. In
Database and XML Technologies . Lecture Notes in Computer Science, Vol. 3186.
97–111.
[12] MarcelBruch,MartinMonperrus,and MiraMezini.2009. LearningfromExam-
ples to Improve Code Completion Systems. In ESEC/FSE’09: Europ. Softw. Eng.
Conf.andSymp.FoundationsSoftw.Eng. Amsterdam,TheNetherlands,213–222.
[13] Maria Christakis and Christian Bird. 2016. What Develo pers Want and Need
from Program Analysis: An Empirical Study. In ASE’16: Intl. Conf. Automated
Softw.Eng. Singapore, Singapore,332–343.
[14] GeorgDotzlerandMichaelPhilippsen.2016. Move-opti mizedSourceCodeTree
Diﬀerencing.In ASE’16:Intl. Conf. Automated Softw. Eng. Singapore, Singapore,
660–671.
[15] GeorgDotzler,RonaldVeldema,andMichaelPhilippsen .2012. AnnotationSup-
port for Generic Patches. In RSSE’12: Proc. Intl. Workshop Recommendation Sys-
temsforSoftw.Eng. Zurich,Switzerland, 6–10.
[16] David Lo Ferdian Thung, Le Dinh Xuan Bach and Julia Lawal l. 2016. Recom-
mending Code Changesfor AutomaticBackporting of LinuxDev iceDrivers.In
ICSME’16:Intl. Conf.Softw. Maintenance and Evolution . Raleigh,NC,222–232.
[17] Beat Fluri, Michael Wuersch, Martin Pinzger, and Haral d Gall. 2007. Change
Distilling: Tree Diﬀerencing for Fine-Grained Source Code Change Extraction.
IEEETransactionson Software Engineering 33,11 (Nov.2007), 725–743.
[18] Marko Gasparic and Andrea Janes. 2016. What Recommenda tion Systems for
Software Engineering Recommend: A SystematicLiteratureR eview.Journal of
Systemsand Software 113 (2016), 101–113.
[19] John Jacobellis, Na Meng, and Miryung Kim. 2014. Cookbo ok: In Situ Code
Completion Using Edit Recipes Learned from Examples. In ICSE’14: Intl. Conf.
Softw.Eng. Hyderabad,India, 584–587.
[20] Guoliang Jin, Wei Zhang, Dongdong Deng, Ben Liblit, and Shan Lu. 2012. Au-
tomatedConcurrency-BugFixing.In OSDI’12:USENIXSymp.OperatingSystems
Design&Impl. Hollywood, CA,221–236.
[21] ToshihiroKamiya,ShinjiKusumoto,andKatsuroInoue. 2002. CCFinder:AMul-
tilinguistic Token-based Code Clone Detection System for L arge Scale Source
Code.IEEETrans.on Softw.Eng. 28,7 (July2002), 654–670.
[22] MiryungKimandDavidNotkin.2009.DiscoveringandRep resentingSystematic
Code Changes.In ICSE’09:Intl. Conf.Softw.Eng. Vancouver,Canada,309–319.
[23] PatrickKreutzer,GeorgDotzler,MatthiasRing,Bjoer nM.Eskoﬁer,andMichael
Philippsen.2016. AutomaticClusteringofCodeChanges.In MSR’16:Conf.Min-
ingSoftw. Repositories .Austin, TX,61–72.
[24] Vladimir Levenshtein.1966. BinaryCodes Capableof Co rrecting Deletions, In-
sertions,and Reversals. Soviet Physics-Doklady 10, 8(1966), 707–710.
[25] Rashindra Manniesing, Ireneusz Karkowski, and Henk Co rporaal. 2000. Auto-
maticSIMDParallelizationofEmbeddedApplicationsBased onPatternRecogni-
tion.InEuroPar’00:Europ.Conf.ParallelComputing ,Vol.1900.Munich,Germany,
349–356.
[26] Michael Martin, Benjamin Livshits, and Monica S. Lam. 2 005. Finding Appli-
cation Errors and Security Flaws Using PQL: a Program Query L anguage. In
OOPSLA’05:Conf.Object-Oriented Progr.,Systems,Language s &Appl. SanDiego,
CA,365–383.[27] Na Meng, Lisa Hua, Miryung Kim, and Kathryn S. McKinley. 2015. Does Auto-
matedRefactoringObviateSystematicEditing?.In ICSE’15:Intl.Conf.Softw.Eng.
Florence, Italy,392–402.
[28] Na Meng, Miryung Kim, and Kathryn S. McKinley. 2011. Sys tematic Editing:
Generating Program Transformations from an Example. In PLDI’11: Intl. Conf.
Progr.Lang.Design& Impl. SanJose, CA,329–342.
[29] Na Meng, Miryung Kim, and Kathryn S. McKinley. 2013. LAS E: Locating and
Applying Systematic Edits by Learning from Examples. In ICSE’13: Intl. Conf.
Softw. Eng. SanFrancisco,CA,502–511.
[30] Robert C. Miller and Brad A. Myers.2001. Interactive Si multaneous Editing of
Multiple Text Regions. In ATC’13: USENIX Annual Techn. Conf. Berkeley, CA,
161–174.
[31] Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H. Pham, Jafar Al -Kofahi, and
Tien N. Nguyen. 2010. Recurring Bug Fixes in Object-Oriente d Programs. In
ICSE’10:Intl. Conf.Softw.Eng. CapeTown, South Africa,315–324.
[32] Yoann Padioleau, Julia Lawall, René Rydhof Hansen, and Gilles Muller. 2008.
Documenting and Automating Collateral Evolutions in Linux Device Drivers.
InEurosys’08:Europ. Conf.Comp.Sys. Glasgow,Scotland, UK, 247–260.
[33] Romain Robbes and Michele Lanza. 2008. Example-Based P rogram Transfor-
mation. In MoDELS’08: Intl. Conf. Model Driven Eng. Languages and Syst ems.
Toulouse, France,174–188.
[34] MartinP. Robillard, Walid Maalej,Robert J. Walker,an d Thomas Zimmermann
(Eds.). 2014. Recommendation SystemsinSoftware Engineering . Springer-Verlag,
Heidelberg,Germany.
[35] Reudismam Rolim, Gustavo Soares, Loris DâĂŹantoni, Ol eksandr Polozov,
Sumit Gulwani, Rohit Gheyi,Ryo Suzuki,and BjornHartmann. 2017. Learning
Syntactic Program Transformationsfrom Example. In ICSE’17:Intl. Conf. Softw.
Eng.Buenos Aires,Argentina, 404–415.
[36] Gustavo Santos, Klérisson Paixão, Nicolas Anquetil, A nne Etien, Marcelo Maia,
andStéphaneDucasse.2017. RecommendingSourceCodeLocat ionsforSystem
SpeciﬁcTransformations.In SANER’17:Intl.Conf.Softw.Analysis,Evolutionand
Reengineering . Klagenfurt, Austria,160–170.
[37] RossTate,MichaelStepp,andSorinLerner.2010.Gener atingCompilerOptimiza-
tionsfromProofs.In POPL’10:Intl.Symp. PrinciplesofProgr.Languages .Madrid,
Spain, 389–402.
[38] Eelco Visser.2001. Stratego:A LanguageforProgramTr ansformationbasedon
Rewriting Strategies. System Description of Stratego 0.5. InRTA’01: Rewriting
Techniques and Applications (Lect. Notes Comp. Science) , Vol. 2051. Utrecht, The
Netherlands, 357–361.
[39] XiaoyinWang,DavidLo,JiefengCheng,LuZhang,HongMe i,andJeﬀreyXuYu.
2010. MatchingDependence-Related Queriesinthe SystemDe pendence Graph.
InASE’10:Intl. Conf.Automated Softw.Eng. Antwerp, Belgium,457–466.
[40] Yi Wei, Yu Pei, Carlo A. Furia,LucasS. Silva, Stefan Buc hholz, Bertrand Meyer,
and Andreas Zeller. 2010. Automated Fixing of Programs with Contracts. In
ISSTA’10:Intl. Symp. Softw.Testing& Anal. Trento,Italy, 61–72.
[41] Westley Weimer, ThanhVu Nguyen, Claire Le Goues, and St ephanie Forrest.
2009. Automatically Finding Patches Using Genetic Program ming. In ICSE’09:
Intl. Conf. Softw.Eng. Washington, DC,364–374.
[42] Cheng Zhang, Juyuan Yang, Yi Zhang, Jing Fan, Xin Zhang, Jianjun Zhao, and
Peizhao Ou.2012. Automatic ParameterRecommendation forP ractical API Us-
age. InICSE’12:Intl. Conf. Softw.Eng. Piscataway,NJ,826–836.
[43] TianyiZhang, MyoungkyuSong, JosephPinedo, and Miryu ngKim.2015. Inter-
active Code Review for Systematic Changes. In ICSE’15: Intl. Conf. Softw. Eng. -
Volume 1.Florence, Italy,111–122.
[44] HaoZhong,TaoXie,LuZhang,JianPei,andHongMei.2009 .MAPO:Miningand
Recommending API Usage Patterns. In ECOOP’09:Europ. Conf. Object-Oriented
Progr.Genova,Italy,318–343.