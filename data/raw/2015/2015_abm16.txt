On-the-Fly Decomposition of SpeciÔ¨Åcations
in Software Model Checking
Sven Apel1, Dirk Beyer2, Vitaly Mordan3, Vadim Mutilin3, and Andreas Stahlbauer1
1University of Passau, Germany2LMU Munich, Germany3ISP RAS, Russia
ABSTRACT
Major breakthroughs have increased the eciency and eec-
tiveness of software model checking considerably, such that
this technology is now applicable to industrial-scale software.
However, verifying the full formal specication of a software
system is still considered too complex, and in practice, sets
of properties are veried one by one in isolation. We pro-
pose an approach that takes the full formal specication as
input and rst tries to verify all properties simultaneously
in one run of the verier. Our verication algorithm mon-
itors itself and detects situations for which the full set of
properties is too complex. In such cases, we perform an
automatic decomposition of the full set of properties into
smaller sets, and continue the verication seamlessly. To
avoid state-space explosion for large sets of properties, we
introduce on-the-y property weaving : properties get weaved
into the program's transition system on the y, during the
analysis; which properties to weave and verify is determined
dynamically during the verication process. We perform an
extensive evaluation based on verication tasks that were
derived from 4 336 Linux kernel modules, and a set of proper-
ties that dene the correct usage of the Linux API. Checking
several properties simultaneously can lead to a signicant
performance gain, due to the fact that abstract models share
many parts among dierent properties.
CCS Concepts
Software and its engineering √ëFormal software ver-
ication;
Keywords
Software Model Checking, Program Analysis, Multi-Property
Verication, Specication, Formal Methods, Decomposition1. INTRODUCTION
Software model checking is an automatic, exhaustive, and
precise approach for verication. A software model checker
takes a program and a formal specication as input, con-
structs an abstract model of the program to verify whether
the program adheres to the specication, and provides the
verication result True orFalse (ideally accompanied by a
witness). The challenge in model checking is to represent
huge state spaces by sound and complete approximations
that avoid the state-space explosion problem. Abstraction
is crucial to construct an abstract state space of tractable
size [19,27,33]; the abstraction precision [10,14] denes the
level of abstraction. The model of a program has to be
abstract enough to allow for an ecient verication process,
and precise enough to be able to prove, or refute, that the
specication is satised [2,27]. The complexity of the model,
and the resources required for computing an abstraction,
increase with the complexity of the specication to verify.
The formal specication of a software system is typically
described by dozens, or hundreds, of properties. For example,
given a Linux kernel module, there is a set of API usage rules
that the module must fulll; each of these rules is a safety
property. Dening each property in isolation respects the
principle of separation of concerns, and ensures maintainabil-
ity and comprehensibility of the formal specication. Due
to the size and structure of an elaborate software system,
such as the Linux kernel, it is state-of-the-art to decompose
the specication before the verier starts, and to verify each
part (property) of the specication in isolation, in a new
instance of the verication tool. Verifying many properties
simultaneously can exhaust computing resources, in partic-
ular due to state-space explosion, expensive solver queries,
and complex abstraction computations. Thus, small sets
of properties are preferred to reduce the complexity of the
abstract model (a lower precision is sucient). Several sig-
nicant improvements in the last years (most prominently,
the performance breakthrough of SMT solving [4]) make us
believe it is time to address the challenge of verifying large
sets of properties at once. Verifying a set of properties in one
run has major advantages over the state-of-the-art approach,
especially in industrial practice: (1) the program is parsed
only once, (2) invariants can be reused across dierent prop-
erties, and (3) the overall number of expensive satisability
checks can be reduced. We developed a set of techniques as
a foundation for verifying many properties simultaneously
in one run of a software model checker, including on-the-y
property weaving and dynamic specication decomposition.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
FSE‚Äô16 , November 13‚Äì18, 2016, Seattle, WA, USA
c2016 ACM. 978-1-4503-4218-6/16/11...$15.00
http://dx.doi.org/10.1145/2950290.2950349
Artifact evaluated by FSE‚úì
349Specication Automata. A required property1is usually
represented by a monitor automaton [7,42]. Generally, there
are two alternative methods to verify a property for a program
with software model checking: (a) the monitor automaton
is weaved into the source code of the program and thus
reduced to the reachability of a certain program location [3,7]
and (b) the monitor automaton runs in parallel and the
current state of the automaton is represented separately
with an abstract domain over the automaton states [20,43].
Method (a) is easy to implement in a pre-processing step,
for example, by an aspect weaver [39], but has the drawback
that the source code is changed, blown-up considerably, and
traceability is more dicult to ensure. If applied to a multi-
property setup, instrumenting all properties of a specication
into the program code introduces a lot of noise in the program,
especially in cases where only a subset of the properties
is veried; this adds another burden to the abstraction-
renement procedure, makes calls to the SMT solver more
expensive, and makes the program-comprehension task for
the verication engineer harder. Method (b) is conceptually
much more elegant, but has the following drawback: because
each property is equivalent to an automaton (that is, each
property has an own state space, which needs to be tracked in
addition to the current state in the program exploration), and
the combination of the properties can be seen as a product
construction, there is a new kind of state-space explosion:
a huge number of dierent states in the specication.
Both methods have advantages that seem mutually ex-
clusive: Method (a) allows us to encode the specication
state space into the program's control ow and thus benet
from the same symbolic representation as in the program
state space. It helps to avoid an explicit representation of
the automaton states of the resulting product specication.
Method (b) allows us to integrate the concept of abstraction
precisions [10], which makes it possible to enable and disable
properties on the y. We can view the process of reducing
the number of properties as abstraction and the process of
adding properties as renement of the abstract state space.
On-the-Fly Property Weaving. We have solved the above
dilemma by designing the Loom analysis, which is a exible
and congurable analysis preventing state-space explosion
that arises from the specication. This analysis weaves only
those properties on-the-y into the program's transition
system that are to be veried, and allows us to use the
concept of dynamic precision adjustment to dynamically
enable and disable properties during the verication process.
While we would like to leverage reuse between proper-
ties (abstract models for dierent properties often overlap),
we sometimes have to reduce the number of simultaneously
veried properties to keep the complexity of the abstract
model to construct manageable.
Dynamic Specication Decomposition. Our goal is to
automatically decompose large sets of properties into smaller
sets, instead of requiring the decomposition from the veri-
cation engineer. A multi-property model checker takes a
set of properties (the specication) as input, and provides a
separate result for each property as output. The verier au-
tomatically decides which properties to verify in combination,
1We focus on safety properties that dene the correct usage
of an operating-system API [1,32]. In our experiments, we
verify properties of Linux kernel modules, due to their open-
source availability, and their well-understood requirements.Table 1: Simultaneous verication of dierent sets
of properties of a Linux kernel module for a network
device; verifying all properties simultaneously runs
into a timeout (1.5 hours)
Property
132a 134a 43a 68a 68b Analysis Speedup Total Speedup Analysis CPU Time (s) Total CPU Time (s) Loop Unrollings Renements
 { { { { 1:0 1 :0 110 140 7 75
{  { { { 1:0 1 :0 15 48 1 2
{ { { { 1:0 1 :0 18 50 2 5
{ { {  { 1:0 1 :0 25 61 2 5
{ { { {  1:0 1 :0 5:9 40 1 0
  { { { 1:0 1 :2 120 150 7 81
 { { { :68 :88 180 220 7 100
 { {  { :58 :76 230 270 12 65
 { { {  1:0 1 :2 110 150 7 75
{   { { 1:5 1 :8 21 55 3 7
{  {  { 1:5 1 :8 27 62 3 9
{  { {  1:3 1 :7 16 51 1 2
{ {   { :90 1 :3 48 88 4 23
{ { {  1:2 1 :7 19 54 2 5
{ { {   1:2 1 :7 26 60 2 5
   { { :64 :93 220 260 7 102
  {  { :56 :83 260 310 12 65
  { {  1:0 1 :4 120 160 7 81
 {   { :048 :077 3200 3300 12 113
 { {  :66 :99 200 240 7 100
 { {   :57 :86 250 280 12 65
{    { :92 1 :5 63 110 4 27
{   {  1:9 2 :6 20 54 3 7
{  {   1:8 2 :5 25 60 3 9
{ {    :96 1 :6 51 92 4 23
    {     
   {  :61 1 :0 240 280 7 102
  {   :47 :80 330 370 12 65
 {    :046 :083 3400 3600 12 113
{     1:0 1 :8 63 110 4 27
          
or individually. The goal is to decompose the specication
such that the overall eectiveness and eciency of the veri-
cation process is improved.
We developed a technique that allows us to dynami-
cally (on-demand and on-the-y) adjust the specication by
switching on and o individual properties using the concept
of dynamic precision adjustment [10]. To determine when
and where to decompose, our analysis algorithm monitors
itself to detect situations in which the abstract model for a
certain set of properties becomes too complex to be eciently
constructed. The approach requires heuristic estimates for
choosing a promising decomposition alternative.
To discuss this aspect in more detail, we show results of
verifying a Linux kernel module in Table 1, with all possible
decompositions of a set of properties. The module provides
access to a family of Siemens Gigaset devices.2We chose
this module for discussion because it is one of the most
challenging for nding a good decomposition, which is a
central problem to be solved|we obtain signicant speedups
for other kernel modules as well (see Fig. 2). The analysis
CPU time only includes the time for model checking (model
construction, renement based on infeasible error paths), the
CPU time for parsing the input program, constructing the
2http://kernel.org/doc/Documentation/isdn/README.gigaset
350control-ow graph, and other preparation and initialization
steps is included in the total CPU time.
Verifying all ve properties simultaneously is not possible
because we run into a timeout (last row of Table 1). If we
choose a decomposition where property 132a is veried in
isolation and the other four properties simultaneously, we
spend a total analysis time of 110 s +63 s=173 s. The
decompositionff134a,68a,68bg,f132ag,f43aggneeds an
analysis CPU time of 25 s+110 s +18 s=153 s. Admittedly,
this is not a too big speedup compared to 174 s for verifying
each property separately: the overall cost is dominated by
the one hard property 132a.
The potential speedup of verifying several properties si-
multaneously depends on the program and on the properties.
Some program parts require a high precision for verifying
several properties, whereas the precision can be coarse for
other parts (because they are not relevant for any property).
Dierent properties have dierent scopes, and thus, could
benet from intermediate verication results that are avail-
able in the scope from other properties. Overlapping scopes
of properties can also have a negative impact on the veri-
cation performance: the state space might in some cases
explode for those regions. Our approach tries to detect such
situations early and verify certain properties in isolation.
Related Work. We classify the related work into approaches
related to multi-property verication and approaches related
to specication automata and specication weaving.
Multi-Property Verication. Checking properties individ-
ually has already been identied to be impractical in the
context of hardware verication [17, 23, 36]. Some of the
discussed problems and ideas are applicable to verifying soft-
ware: (1) grouping properties according to their potential of
reuse of intermediate results, (2) reuse of learned facts, and
(3) projection of constraints, and reachable states, between
properties based on a cone-of-inuence analysis. The tool
Varvel [29], which uses abstract interpretation and bounded
model checking, has been used for verifying several prop-
erties of software; it is applied function-wise and does not
perform a whole-program analysis; function contracts can
be used to reason about whole programs [30]. Multi-aspect
verication [37] is the work closest to our approach; it was
inspired by the positive eects of precision reuse [14] and
led to our new concepts and experiments. The idea is to use
the LDV toolkit to produce, for a given program source code
and a set of properties, a source code that is instrumented
with the given properties. The model checker ( CPAchecker )
is repeatedly queried to verify such instrumented programs.
The potential of reuse for similar queries was explored in
the area of SAT solving [31,41,45]. Large sets of test goals
are considered in the context of dynamic test generation [25],
or in dynamic analysis [22]. In general, test generation can
benet from reusing parts of abstract reachability graphs [11].
Also regression verication can benet from the reuse of ab-
stract reachability graphs [26] or of abstraction precisions [14]
to reduce the verication eort over several verication runs.
Our work complements the existing approaches by auto-
matic specication decomposition with self-monitoring for the
case that the full specication is too complex, an implementa-
tion using unbounded software model checking, verifying full
programs as a whole, and by avoiding pre-processing (com-
bine or weave) of properties. We conduct an extensive study
on the eects, and specics, of verifying several properties in
one run of a software model checker.Specication Weaving and Automata. In the past two decades,
several languages for expressing formal software specications
have been proposed [3,5,7,18]. Our specication language
is inspired by the Blast query language [7,18]. Every safety
property can be reduced to the reachability of an error label;
a new version of the program, where the specication is part
of the program code, is generated in a pre-processing step and
a verier checks then whether an error label that represents
a violating program location is reachable. Aspect-oriented
programming is one way of instrumenting a program with
its specication [39]. In the spirit of congurable software
verication [9], it is desirable to integrate the specication
automaton as a congurable program analysis that runs
simultaneously with the main analysis (on-the-y product
construction of program and specication) [43]. Our speci-
cation automata can encode several properties, similar to
supermonitors [40]. Our specication analysis uses dynamic
precision adjustment [10] to enable or disable certain prop-
erties on demand. A work that is closely related to our
approach for on-the-y weaving can be found in the con-
text of performance monitoring [28]. Code instrumentation
is added or removed dynamically at any point during the
program execution; the main goal of that work is to col-
lect performance data. Our Loom analysis applies the idea
of dynamic instrumentation to static analysis, that is, at
verication time, without changing the actual program.
Contributions. We summarize our results as follows:
We propose a fully-integrated approach for verifying sets
of properties in one run of a software model checker.
We developed the Loom CPA, a technique that makes the
simultaneous verication of large sets of properties ecient,
by weaving properties on-the-y into the program.
We developed a congurable algorithm that dynamically
decomposes a set of properties into smaller sets, whenever
self-monitoring detects that the verication task is too
complex for the current set of properties.
We perform an extensive experimental evaluation of our
approach to illustrate how an on-the-y specication de-
composition can increase both the eciency and the eec-
tiveness of the overall verication process. Our benchmark
suite comprises 4 336 Linux kernel modules.
We provide a replication package3that contains all data
and a detailed description for reproducing our experiments.
Our implementation is based on the open-source software-
verication framework CPAchecker ; the source code is
available under the Apache 2 license.
2. PRELIMINARIES
Before we introduce our new approach and the correspond-
ing techniques, we start with some preliminary denitions.
Control-Flow Automata. We represent a program
ascontrol-ow automaton (CFA), which is a tuple pL;l0;Gq
consisting of a set Lof program locations, the entry loca-
tionl0PL, and a set G¬ÑLOpsLof control-ow
edges; an operation in Ops represents an assignment opera-
tion or an assume operation, in the programming language
and (if available) its abstract syntax tree; the subset R¬ÄOps
represents all assume operations (Boolean expressions); the
subsetS¬ÄOpszRrepresents all assignment operations.
For a setM, we writeMfor the set of all words over M,
3http://sosy-lab.org/research/spec-decomposition/
351andfor the word of length zero. The concatenation of two
wordsw1andw2is written as w1w2.
Properties and Partitions. The set Ptp1;:::;pnucon-
sists of all properties of a program that are to be veried.
Apartitioning P¬Ñ2Xof a setXis a set of non-empty sets,
where all elements P1;P2PP, withP1P2, are pairwise
disjoint (P1XP2H), andX¬î
PPPP.
Congurable Program Analysis. Our work builds on the
concept of congurable software verication [9] with dy-
namic precision adjustment [10]. CPAs of the form D
pD;;√π;merge;stop;prec;targetqare the central building
blocks of this formalism. The full-edged program analysis
is composed of several component CPA to form a composite
analysis . The abstract domain D pC;E;rrssq with the
semi-lattice E pZ;¬Ñ;\;Jqdenes the type of abstract
representation of concrete states from C, whereCis the set
of all concrete states of the program; one abstract state ePZ
represents a set of concrete states ( region ), which can be
obtained by the concretization function: rress¬ÑC. A pre-
cisionPdenes certain aspects of the state space that
should be represented by abstract states in a given abstract
domain. The transfer relation √πdenes, for each abstract
state, a set of successor abstract states. The operator merge
can combine two abstract states such that both abstract
states are subsumed by the resulting abstract state; given
an abstract state e, and a set R¬ÑZof abstract states,
the coverage-check operator stop returns true iferepresents
only concrete states that are already represented in R, that
is,rress¬Ñ¬î
e1PRrre1ss, and returns false otherwise. Given an
abstract state e, a precision , and a set R¬ÑZ, the precision
adjustment operator preccan provide a new abstract state e1
with an adjusted precision 1. The operator target :Z√ëB
returns true if a given abstract state is the goal of the reach-
ability analysis, that is, if the abstract state violates the
specication, and returns false otherwise. The strengthening
operator√ìof a CPA can be used to get information from
the abstract state of another component CPA to compute
a stronger successor abstract state; it is called within the
transfer relation of the wrapping composite CPA after all
component CPAs have done their transfers. More details on
the CPA formalism can be found in the literature [9,10,12].
Abstract Reachability Graph. To verify properties of a
program, we run a program analysis [10] (Alg. 1) that is
dened by a CPA D. Starting from all initial abstract
states with precision (from W0), we compute all successor
abstract states until we have reached the xed point. All
abstract states that have been reached so far are stored in
the set reached ; the set waitlist represents the frontier, that
is, the set of abstract states for which the successor abstract
states still have to be computed. The abstract states in the
setreached are the nodes of an abstract reachability graph
(ARG), a directed graph that is rooted at the initial abstract
states with precision (from W0).Lazy abstraction [27] pro-
poses to use dierent precisions for dierent parts of the
ARG; both the set reached and waitlist consist of pairs of an
abstract state with abstraction precision.
3. LOOM CPA: ON-THE-FLY WEA VING
This section introduces (1) our specication automata,
(2) our specication analysis, which provides on-the-y spec-
ication decomposition, and (3) the Loom analysis, whichAlgorithm 1 CPAalgDpR0;W0q, adopted from [10]
Input: a CPA DpD;;√π;merge;stop;prec;targetq,
a setR0¬ÑE of abstract states with precision,
a subsetW0¬ÑR0of frontier abstract states with precision,
whereEdenotes the elements of the lattice of D
Output: a set of reachable abstract states with precision,
a subset of frontier abstract states with precision
Variables: a set reached¬ÑE, a set waitlist¬ÑE
1:reached :R0;waitlist :W0
2:while waitlistHdo
3:pe;q:choosepwaitlistq
4:for eache1withe√πpe1;qdo
5:ppe;pq:precpe1;;reachedq
6: for eachpe2;2qPreached do
7:enew:mergeppe;e2;pq
8: ifenewe2then
9: waitlist : 
waitlistYtpenew;pqu
ztpe2;2qu
10: reached : 
reachedYtpenew;pqu
ztpe2;2qu
11: if stopppe;te|pe;qPreachedu;pqthen
12: waitlist :waitlistYtppe;pqu
13: reached :reachedYtppe;pqu
14: iftargetppeqthen
15: returnpreached;waitlistq
16:returnpreached;Hq
provides on-the-y weaving of operations from the specica-
tion automata into the transition relation of the analysis.
A key design decision of our approach is to give the formal
specication and the program code to the verier as separate
objects. Instead of instrumenting the specication into the
program code before running the verier, the verier weaves
the specication on-the-y into the transition relation of the
program, during the analysis. Whenever a dierent (sub-) set
of properties is to be veried, we do not have to re-instrument
the input program and restart the verier. In our method of
on-the-y specication weaving, only selected properties are
weaved, and only for a specic part of the state space (which
properties, and where to weave them, can be dynamically
adjusted, e.g., via lazy abstraction [27]). Irrelevant noise in
terms of unnecessarily instrumented properties is avoided
and the algorithm (and the engineer who tries to understand
an error path) deals with `clean' abstract program paths.
A formal specication that represents a set of program
executions can be expressed as a temporal-logic formula or
by an automaton that accepts the same set of executions [16,
38,44]. We concentrate on temporal safety properties, which
can be expressed using nite automata [34,42,44].
Specication Automata. A specication automaton en-
codes a set of properties and observes, but not restricts,
the state space of an analysis run. A specication au-
tomatonpQ;;;q 0;Fqfor a given CFA pL;l0;Gqis a non-
deterministic nite automaton with a nite set Qof control
states, an alphabet  ¬Ñ2GSR, a transition relation
¬ÑQQ, an initial control state q0PQ, and a set F
of accepting control states. Each qpPFrepresents that
propertypPPis violated (i.e., a path through the program
that violates pis found). We write q√ù √ëq1ifpq;;q1qPholds.
A symbolp;s;rq Pconsists of a set of control-ow
edges, a sequence sof assignment operations to weave, and
a sequence rof assume operations.
To increase traceability and to support enabling and dis-
abling automaton transitions that are irrelevant for specic
properties, we calculate two maps that assign to each control
stateqPQand to each transition Pthe sets of relevant
properties PpqqandPpq, respectively.
352Our specication automata support three modes of ex-
pressing and encoding properties. The pure automata-based
mode tracks every possible state of the specication explicitly,
and thus contributes to the explosion of the (specication)
spate space. In the pure weaving mode , the specication
that is represented by the automaton gets weaved into the
program completely. The set of control states only consists
of the initial control state and a number of accepting control
states, each representing a dierent property. The hybrid
mode combines the rst two modes. Dierent control states
are used for guiding the process of weaving the given set
of properties into the transition relation of the underlying
analysis. A control state of an automaton typically models
the current context of the program.
To not aect the completeness or soundness of the program
analysis, the operations that are introduced by the weaving
process must never modify or restrict the state space of
the program under analysis: (1) assignment operations are
allowed to assign values to only such variables that were
introduced by the automaton itself, and (2) for each control
state, the disjunction of all predicates from assume operations
on the outgoing transitions must evaluate to true.
Property Relevance. A property pisrelevant for a given
program if the specication automaton has a transition to
control state q1withpPPpq1qorpPPpqand transition 
syntactically matches a control-ow edge of the program.
Situations where a property is not relevant for a program
can also indicate a aw in the specication.
Specication Analysis. For each specication automaton,
we instantiate one specication analysis. The specication
analysis (1) keeps track of the current state of the automaton
and determines its successors based on the transition rela-
tionand the current control-ow edge of the CFA, (2) it
provides operations that should later be weaved into the
control ow, (3) it provides assumptions on the state space
for strengthening the composite abstract state, (4) it can
disable the verication of certain properties on-the-y for
some region of the state space, and (5) it is responsible for
determining whether a violating state has been reached. By
running several specication analyses in parallel, we lazily
accept the union of words without any explicit automaton
construction.
The specication analysis for a specication automaton is a
CPADSpDS;S;√πS;mergeS;stopS;precS;targetSq. A pre-
cisionPSof this CPA is a set of properties to verify; it
implicitly denes the subset of transitions of the speci-
cation automaton that are relevant for verifying properties
from:tP|PpqXHu . The specication anal-
ysis interprets the transitions of the specication automaton
according to the precision: for a given transition q√ù √ëq1, it
uses the precision-adjusted transitionq√ù √ëq1(i.e., it uses only
transitions that are relevant for verifying a property pP).
The CPA is dened as follows:
1.The abstract domain DSpC;Q;rrssqconsists of the set
Cof concrete states, a semi-lattice Q, and a concretization
functionrrss. The semi-lattice QpZ;¬Ñ;\;JQqis a at
lattice on the set of abstract states ZpQYJqOps,
where one abstract state pq;oqPZconsists of an automaton
stateqand a sequence oof operations.
2. The transfer relation √πShas the transfer
pq;oqg√πSppq1;o1q;q, if the specication automaton Ahas a
precision-adjusted transition q√ù √ëq1, withp;s;rqandgP, ando1rs. If no transition is applicable, it has the
(stuttering) transfer pq;oqg√πSppq;oq;q. An analysis shall
not stop exploring a program path after a property violation;
other properties could be violated later along the path as
well (soundness).
Our specication language supports patterns variables: the
sequencessandrof assignment and assume operations, re-
spectively, have to be instantiated within the transfer relation
based on the current automaton state and the control-ow
edgeg. The set of matching control-ow edges can be
dened by patterns like $1 = malloc($2) , which matches
for example the control-ow edge with the assignment oper-
ation ptr = malloc(512) . The expressions that match the
pattern variables can then be referenced for instantiating new
sequences of assignment or assume operations. Continuing
the example, the pattern $1 == NULL , would be instantiated
as the assume operation ptr == NULL .
3.The precision Sof the analysis determines which proper-
ties are veried for which part of the state space. The preci-
sion adjustment operator precS:ZS2ZS√ëZS
is central in the on-the-y decomposition of a specication.
Based on several measures of the verication eort spent
on each property, we dynamically decide whether we should
stop verifying a property starting from a given abstract
state onwards. The operator exceeds :P√ëBreturns true
if a specic budget for a given property is exceeded, and
false otherwise. A property pis removed from the precision
(precSpe;S;reachedqpe;Sztpuq) ifexceedsppqtrue.
4.The operator mergeS:ZZ√ëZkeeps two abstract
states always separate: mergeSpe;e1qe1.
5.The operator stopS:Z2Z√ëBchecks whether there
is already an abstract state that subsumes a given state:
stopSpe;Rqreturns true ifDe1PR:e¬Ñe1, otherwise false.
6.The operator targetS:ZBreturns true if the speci-
cation automaton is in an accepting control state qpPF,
which signals the violation of property p: given an abstract
statepq;qPZ, it returns true ifqPF, otherwise false.
On-the-y Weaving with the Loom Analysis. The
Loom analysis is a composite [9] CPA DL#that weaves
sequences of operations from the specication CPA into the
transition relation of the analysis. The denition of speci-
cation automata ensures that this process does not make the
data-ow analysis for the program unsound.
TheLoom analysis is composed of (at least) the location
CPA as well as the instances of the specication CPA. Given
the composite state e pl;:::;pq1;o1q;:::;pqm;omqqand
the concatenation oco1:::ompop1;:::;opnqof all
operation sequences, with oc, we add new control-ow
edges toG:pl#;op1;l1q;:::;pln1;opn;lq, where the last
control-ow edge leads to the original location l; the transfer
relation √πL#has the transfer pl;:::q√πL#pl#;:::q, which
is taken after all component CPAs have performed their
transfers and strengthenings.
The only operator that is allowed to modify the compo-
nents of the composite state is the strengthening operator.
The strengthening of the location CPA [9] is used to modify
the current location based on the operations to weave that
are provided in the states of the specication CPAs. With-
out loss of generality, we assume that no transition gPG
of the CFA leads to the entry location l#of the sequence of
newly introduced control-ow edges. Figure 1 illustrates this
process on an example.
353la lb
l# : : : lnopk
op1opn1opn
la lb
l# : : : lnopk
op1opn1opn
Figure 1: Given an abstract state eplb;:::;pq;oq;:::q
created based on the control-ow operation opk,
withopop1;:::;opnq, the Loom CPA introduces a se-
quence of control-ow edges that correspond to the
operations o. The program analysis is redirected to
their entry location l#such that e1pl#;:::;pq;q;:::q.
4. DECOMPOSING PROPERTY SETS
Dierent properties exhibit dierent characteristics [21],
which determine whether some properties should be veried
on the same abstract model or separately. Ideally, a decom-
position strategy separates those pairs of properties that, if
veried simultaneously, lead to a decrease of eciency, and
it bundles those properties that benet from simultaneous
verication. We propose run-time strategies for specication
decomposition, which can consider measures of the verica-
tion process and the state space (under construction), for
deciding which properties to verify separately or in a specic
combination. Depending on the chosen abstract domain or
analysis conguration, dierent measures might be appro-
priate. Such measures can help to identify properties whose
scope spans across loops, properties that involve an undecid-
able theory, or any property that would cause a blow-up of
the abstract reachability graph.
We dene three points in time for providing or performing
a decomposition of the specication: (1) a domain expert can
provide an authoritative decomposition of the specication
before starting the verier, (2) the decomposition can be
performed dynamically each time before running the model-
checking algorithm, and (3) it can be performed on the y
during the execution of the model-checking algorithm.
4.1 Decomposition Framework
Model-checking algorithms found in the literature are nei-
ther designed for decomposing a specication, nor are they
able to handle the fact that only a fraction of the specication
might have been veried. Algorithm 2 SDC (Specication
DeComposition) was particularly designed for this concern:
it wraps a standard analysis algorithm analyze4, and its
specics are dened by a decomposition strategy S.
The algorithm takes four parameters. The initial abstract
statee0with the adjusted (line 4) initial precision 0de-
nes the initial frontier (line 5), which is the starting point
for the analysis to compute successor states until a xed
point is reached. The initial partitioning of the specication
and the initial resource budget dene the initial decomposi-
tion process. If no property is left for verication (line 18),
the algorithm terminates with a pair of satised proper-
4This can be a standard program analysis, such as CPAalg
(Alg. 1), or even testing; algorithm analyze must satisfy the
interface: operate on sets reached and waitlist , and return a
set of error paths. While we base our implementation on
CPAchecker , our concepts are not bound to this framework.ties and violated properties. Properties are removed from
the set remaining if a feasible error path was found (line 9),
or a xed point was reached with the properties enabled
for verication (line 14), or if the analysis resigns to verify
them (line 17).
Resource Budgets. Due to the general undecidability of
the verication problem, some properties cannot be veried,
even with an arbitrary amount of resources; the algorithm
would terminate without reaching a xed point, returning
the result unknown . Appropriate resource budgets for spe-
cic properties or sets of properties are therefore crucial for
the overall eciency and eectiveness of verication with
specication decomposition.
Dierent resources Hcan be taken into account for den-
ing budgets on properties, or the overall verication process.
AresourcePHcan be, for example, the CPU time that is
spent on a specic operation of the analyzer or the full (enclos-
ing) analysis algorithm, or the number of precision elements
with specic characteristics, or the number of branchings in
the ARG (this list is not exhaustive).
Aresource utilization monitor U put;utPqtracks the
amount of resources consumed by the analyzer. The utiliza-
tion operator ut:H√ëZreturns the total amount utpuqfor a
given resource PHthat was consumed between the start of
the monitor and the time the operator was invoked. The uti-
lization operator utP:PH√ëZreturns the amount utPpuq
for a given resource PHthat was consumed for a specic
propertypPP. We denote the set of all resource utilization
monitors by U. Whenever the specication-decomposition
algorithm starts with a new set of properties, the resource
utilization monitor is reset (all utilization operators are set
tozero whenever operator initis called).
Aresource budget :U√ëBis an operator that returns
true for a given pair of utand utPif there are sucient
resources left for a given property pPP, and false otherwise.
We denote the set of all budgets by B; budgetJdoes not
restrict; budget Kdeclares all resources unavailable.
As part of our framework, we dene a set of operators that
take the resource monitors and the resource budgets into ac-
count for performing the specication decomposition, dynam-
ically, on-the-y: the precision-adjustment operator precSof
the specication analysis and the operators of the decom-
position strategy (the exhaustion operator resigned and the
partitioning operator adjPrecision ).
Decomposition Strategy. Algorithm 2 SDC for specica-
tion decomposition is congured by a decomposition strat-
egySpadjPrecision ;resignedq:
1.The operator adjPrecision : 2P√ëBfor a given
decomposition strategy Stakes as input a precision and a
set of remaining properties (that are still to be veried), and
returns as output a pair of precision and budget . The
precision denes which properties to verify simultaneously in
the next run of the analyzer. Our (stateful) implementation
of operator adjPrecision internally maintains a decomposition
of the specication, which is represented as partitioning P
of properties. The partitioning is iteratively adjusted based
on the verication progress (in terms of remaining properties
and consumed resources) and the next partition is returned
as part of. The new resource budget limits the CPU
time, number of transitions, number of renements for the
next run of the analyzer.
354Algorithm 2 SDC S;analyzeppe0;0q;P0;0q
Input: a decomposition strategy SpadjPrecision ;resignedq,
an analysis algorithm analyze ,
an initial state e0PEwith precision 0P,
an initial partitioning P0,
the initial resource budget 0
Output: set of satised properties, set of violated properties
Variables: a set reached¬ÑE, a set waitlist¬ÑE,
a precision that determines which properties to track,
a set remaining¬ÑPof remaining properties,
a set satised¬ÑPof satised properties,
a set violated¬ÑPof violated properties,
a set cexsof counterexamples (abstract program paths),
which violate properties Ppcexsq¬ÑP
1::0;:0
2:satised :H;violated :H;remaining :P
3:repeat
4:p;q:adjPrecisionP0;0p;remainingq
5: waitlist :tpe0;qu;reached :waitlist
6:repeat
7:preached;waitlist;cexsq:analyzepreached;waitlistq
8: violated :violatedYPpcexsq
9: remaining :remainingzviolated
10: waitlist :disablepwaitlist;violatedq
11: until cexsH
12: ifwaitlistHthen
13: satised :satisedYactivepreachedq
14: remaining :remainingzsatised
15: else
16: // Resource budget exhausted!
17: remaining :remainingzresignedpreachedq
18:until remainingH
19:returnpsatised;violatedq
2.The operator resigned : 2E√ë2Ptakes as input a set of
abstract states with precision ( reached ) and returns a set of
properties that are considered not veriable (within the given
resource constraints) and should no longer be considered in
any further iterations of the decomposition algorithm.
The auxiliary function disable : 2E2P√ë2Ereturns
for a given set of abstract states with precision and a set of
propertiesP, a new set of abstract states with precision from
which all properties from Pare removed from the precision
of the specication analyses.
The helper function active returns, for a given set of reach-
able abstract states with precision, a set of properties that
the analysis was still verifying in the last run of the analyzer
(that is, the properties that were still active).
4.2 Decomposition Strategies
Next, we describe how specication-decomposition strate-
gies can be instantiated within our framework. An experi-
mental evaluation of our strategies can be found in Sect. 5.
The strategies are dierent in decomposition opera-
toradjPrecision , the initial partitioning P0, and the initial
budget0. The strategies consider the set Htat;rc;scuof
resources, were at;rc;scdenote the analysis CPU time, the
number of renements, and the number of transitions taken
so far by the analyzer, respectively. All strategies dene
a budget for the analysis CPU time atPH(for example,
the budget 900utpatq ¬§900limits the analysis CPU
time to 900 s). The operator exceeds , which is used in the
precision adjustment operator precSof the specication CPA,
returns true if any of the resources is exhausted in . The
operator resignedOnereturns true if only one property wasenabled for verication in the given set of abstract states,
otherwise, it returns false.
Strategy S0 padjPrecisionS0;resignedS0q.This strategy
does not perform any specication decomposition (it places
all properties in one single partition) and does not specify any
resource limit. This strategy is used as a baseline for evaluat-
ing the performance of more advanced strategies. We use this
strategy with the initial partitioning P0tPuand the ini-
tial resource budget 0J. After the analysis terminates
for the initial partitioning P0, the operator adjPrecisionS0returnsp;Kq: we signal the exhaustion of all resources.
The operator resignedS0returns the full set Pas result, which
leads to the immediate termination of the specication de-
composition algorithm.
Strategy S1 padjPrecisionS1;resignedOneq.This strategy
starts by verifying all properties simultaneously, and con-
tinues to verify the remaining properties in isolation (one
by one). This simple strategy is useful if no measure is
available for deciding which properties to verify in the same
partition. The goal of this strategy is to not lose verication
results in cases where verifying all properties simultaneously
is not possible. We use this strategy with the initial parti-
tioning P0tPuand the initial resource budget 0900.
After the analysis is nished for the initial partitioning P0,
the call adjPrecisionS1p;remainingqreturnsp1;900qwhere
1enables exactly one arbitrarily (but deterministically) cho-
sen property pPremaining . The operator resignedOneensures
that a property is veried only once in isolation.
Strategy S2 padjPrecisionS2;resignedOneq.Strategy S2
builds on strategy S1but restricts the budget for specic
resources. We have congured the strategy to stop verifying
a property if it causes, relative to the other properties, sig-
nicantly more renement iterations (which might correlate
with a much higher abstraction precision). A property p
is removed during the verication process from the preci-
sionif there have been, relative to the maximum number
of renements for the other properties in , at least twice as
much, but at least ten, renements: Given the number of
renements rcputPpp;rcq, we use the initial budget 0
utPpp;rcq¬†10_utPpp;rcq¬†2maxp1PpzpqutPpp1;rcq.
The background is that our program analysis uses coun-
terexample guided abstraction renement (CEGAR) [19]
for constructing the abstract model of the program, that
is, we use CEGAR to determine the abstraction precision
that is necessary to rule out infeasible error paths. An error
path cexwitnesses the violation of a set of properties Ppcexq.
The idea of strategy S2is to use the number of infeasible
error paths (that have to be ruled out by an abstraction
renement) as an indicator for the cost of verifying a specic
property. The number of renement iterations is a critical
factor that aects the performance of an analyzer that is
based on CEGAR [14].
Strategy S3 padjPrecisionS3;resignedOneq.This strategy
tries to reduce the eort for verifying properties that are
likely irrelevant for a given program, and to focus on the
properties that have been identied as relevant. Whether
a property pis considered relevant is determined based
on the number of transitions scPHto a control state q
of a specication automaton with pPPpqq, which can be
queried from the resource utilization monitor: utPpp;scq. The
setPRelttp|pPP^utPpp;scq¬°0uurepresents the set of
properties that have already been identied to be relevant;
355the set PIrrPzPRel, represents the properties that have
not yet been identied to be relevant and that might be ir-
relevant for the given program. Each partition of properties
is veried with the resource budgets 900.
The strategy operates in three phases; we start with the
initial partitioning P0tPu, which denes the rst phase
of the strategy. The full set properties get veried simulta-
neously for 900 s without any limits on certain properties.
In the second phase of the strategy, we verify only those
properties that have, so far, not yet identied to be relevant
for the program; the second phase is skipped if |PIrr|0.
Thus, we make sure that all properties that have not been
identied to be relevant in the rst phase are really irrele-
vant for the given program (at least with the given resource
budget). If any new relevant property was identied during
that phase, the set of relevant properties is corrected and
the second phase is restarted.
In the third phase of our strategy, we verify all those prop-
erties separately that have still not been veried successfully,
but have been identied to be relevant for the given program.
That is, given the set remaining of remaining properties, the
properties PRelXremaining get veried in isolation with the
resource budget 900.
Strategy S4.Strategy S4combines strategies S2andS3: It
considers the relevance of properties to reduce the number
of properties to verify separately and a resource budget on
properties limits the number of renements per property.
5. EVALUATION
In a series of experiments, we evaluate the potential of
software verication with on-the-y decomposition of speci-
cations in terms of eciency and eectiveness.
5.1 Research Questions
Our experimental evaluation is guided by ve research
questions, which are divided into three groups that provide
dierent perspectives on our approach.
Simultaneous Verication of All Properties. We rst
investigate the performance benet of verifying all properties
of a specication in one verication run using one shared ab-
stract model (one abstract reachability graph) of the program.
This reuse of intermediate verication results can inuence
both the eciency and the eectiveness of a software veri-
er. For now, we are only interested in the performance of
the analysis procedure itself; the eort for all pre-processing
steps that are associated with the verication run will be
investigated separately.
RQ1.1: How many verication tasks can be solved more
eciently , and what is the speedup in terms of CPU time
for the analysis, by verifying all properties of a specica-
tion simultaneously compared to verifying each property in a
separate run of the verier?
RQ1.2: How many verication tasks can be solved more
eectively , in terms of number of verication results, by veri-
fying all properties of a specication simultaneously compared
to verifying each property in a separate run of the verier?
Specication-Decomposition Strategies. Our initial ex-
ample (see Table 1) illustrates that there are cases for which
simultaneously verifying all properties of a specication with
one abstract model is not feasible. But, it can still be bene-
cial to verify at least some of the properties simultaneously.This set of research questions aims at investigating the po-
tential of automatic specication-decomposition strategies:
RQ2.1: How many verication tasks can be solved
more eciently by applying automatic decomposition strate-
gies (S1{S4) for verifying several properties simultaneously
in one run of the verier?
RQ2.2: How many verication tasks can be solved
more eectively by applying automatic decomposition strate-
gies (S1{S4)for verifying several properties simultaneously
in one run of the verier?
Overall Performance. The above research questions have
focused purely on the analysis procedure; we have not dis-
cussed the costs for the pre-processing steps. These steps
include parsing the program, construction of the CFA, and
setting up the dierent CPAs (which includes initializing
solvers, etc.). Taking these steps into account results in the
last research question:
RQ3.1: What overall eectiveness and eciency can
we expect in practice (that is, including costs for the pre-
processing steps), from a verier with on-the-y specication
decomposition compared to traditional congurations that
verify each property in a separate run of the verier?
5.2 Setup
Our benchmark suite consists of two sets of Linux ker-
nel modules: the full set with 4 336 modules and a subset
with 250modules. Details on the benchmarking environment
and the benchmark suite can be found in Sect. 8, where we
describe the replication package. The replication package
includes all tools and data for replicating our experiments,
as well as a detailed description of all properties.
Presentation. If not stated otherwise, we report CPU time
in hours, rounded to two signicant digits. Analysis CPU
time excludes the time taken by pre-processing steps that
are performed before the analysis itself starts.
Analysis Domain. We have congured a composite anal-
ysis, where one of the components is a predicate analysis
with adjustable-block encoding [13]. This analysis is used for
representing central aspects of the state space of the program
and the portion of the specication that was weaved (on-
the-y) with our Loom analysis; assume operations that are
provided by the specication automata get encoded within
the strengthening operation of this analysis. The program
counter, the call stack, and the control states of the speci-
cation automata, are tracked each by separate analyses. Our
predicate analysis is congured to compute a Boolean predi-
cate abstraction [35] for each function-call location and for
each head of a loop (we perform a large-block encoding [8]).
Experiments. The baseline for all our discussions and ex-
periments is an analysis where only one property is veried
in one instance of the verier. We have limited the analysis
CPU time for one property to 0:25 h. Limiting the analysis
CPU time instead of the total CPU time helps us to exclude
costs for pre-processing, and focus on the costs of the state-
space exploration. Given the set of 250kernel modules (see
Sect. 8) and the set of 14properties, we run 3 500 single-
property verication tasks; the analysis can provide results
in3 394 cases, from which 97violate and 3 297 satisfy the
property. The analysis CPU time for the solved verication
tasks sums up to 52 h(includes the time for tasks that ran
into a timeout).
356To answer RQ1.1 and RQ1.2, we compare the baseline
to a multi-property verication run that is congured to
verify all properties in one partition, that is, we use the
decomposition strategy S0on250kernel modules for which
we verify all 14properties; the overall CPU time for analysis
is limited to 3 :5 h (140:25 h).
To answer RQ2.1 and RQ2.2, we perform two experiments,
where we evaluate the decomposition strategies S1{S4. The
rst experiment is on the 250kernel modules for which we
verify all 14properties. The second experiment evaluates the
eciency and eectiveness of our decomposition strategies
on\hard" tasks, that is, tasks for which the baseline congu-
ration is either able to provide results for more properties or
is more ecient than strategy S0. For both experiments, we
have limited the overall CPU time for the analysis to 3 :5 h.
To answer RQ3.1, we run two experiments for which we do
not force the Java Virtual Machine (JVM) to compile most
of the bytecode during its startup. The rst experiment is on
the250kernel modules for which we verify all 14properties.
To conrm our results and increase their validity, the second
experiment is on the larger set of verication tasks, that is,
we verify the 14properties of all 4 336 Linux kernel modules.
5.3 Results
This section presents the results of our experiments; raw
data and more details are shipped with our replication pack-
age (Sect. 8).
RQ1.1: Eciency of Multi-Property Verication. Ver-
ifying all properties simultaneously is faster for 80per-
cent ( 199modules) of the modules compared to verifying each
property individually. Overall, we gain an average speedup
of5:2in terms of CPU time for the analysis. A graphical
illustration of the results can be found in Fig. 2.
Several relevant properties can be veried without any
renements, purely based on the state of the specication
automata. In the cases in which verifying the properties
individually is more ecient, the simultaneous checks ran
into a timeout for 14modules, without providing any result;
the individual checks were able to provide results for some
of the properties of eleven of those modules.
RQ1.2: Eectiveness of Multi-Property Verication.
The results illustrate that verifying all properties simultane-
ously without any decomposition strategy can lead a sub-
stantial loss of results: We lost 5:6 %(191) of the results; the
goal of specication decomposition is to improve this. On
the other hand, the analysis is able to provide ve additional
results (for dierent properties in dierent modules) because
the resources are not divided across dierent partitions.
RQ2.1: Eciency by Specication Decomposition.
For the set of 250modules, each decomposition strategy
can provide an average speedup of at least 5:1. There are
subsets of these modules for which specic decomposition
strategies are the most ecient choice. Strategy S0is the
best choice (only those strategies are considered that pro-
vide results for all properties of a given module) for 20 %,
S1for15 %,S2for18 %,S3for19 %, and S4for12 % of
the modules. The baseline conguration provides the best
eciency for 12 % of the modules.
For the subset of 51 \hard" modules, strategy S4provides
an average speedup of 1:1, and is able to provide a speedup
for33% of these modules; without a specication decom-
position, no speedup was possible for this set of modules.
‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè‚óè‚óè
‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè‚óè‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè
‚óè‚óè‚óè‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè
‚óè
‚óè‚óè
‚óè‚óè‚óè
‚óè‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè
‚óè
‚óè‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè
‚óè‚óè
‚óè‚óè‚óè
‚óè‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè ‚óè‚óè
‚óè‚óè
‚óè‚óè‚óè‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè
‚óè‚óè
‚óè
‚óè‚óè
‚óè‚óè‚óè‚óè ‚óè
‚óè‚óè
‚óè‚óè
‚óè
‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè‚óè‚óè‚óè
‚óè
‚óè
‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè
‚óè‚óè
‚óè‚óè‚óè
‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè
‚óè
‚óè‚óè
‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè‚óè‚óè
‚óè‚óè‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè
‚óè‚óè‚óè
‚óè
‚óè‚óè
‚óè‚óè
‚óè‚óè‚óè‚óè‚óè
‚óè‚óè‚óè‚óè‚óè‚óè‚óè
‚óè‚óè‚óè
‚óè
110100100010000
1 10 100 1000 10000
Each SeparatelyAll SimultaneouslyFigure 2: Scatter plot that compares the simulta-
neous verication of all properties (y-coordinate) to
the classical approach where each property is veri-
ed in a separate instance (x-coordinate) of the ver-
ier, in terms of CPU time for the analysis
Table 2: Results for dierent decomposition strate-
gies; the rst set of tasks covers 250Linux kernel
modules; the set of \hard" tasks is a subset of those
tasks: tasks for which the baseline conguration is
either able to provide results for more properties or
is more ecient than strategy S0
Strategy Satised Violated Partitions Analysis CPU Time (h) Average Speedup# Additional Results # Lost Results % Lost Results % Speedup¬°1AllModulesBL 3 297 97 3 500 53 1 :0 0 0 0 0
S03 104 99 250 97 5 :2 5 196 5 :6 80
S13 284 96 790 53 5 :2 3 17 :49 79
S23 289 96 724 56 5 :1 4 13 :37 78
S33 281 96 403 33 5 :2 0 17 :49 82
S43 282 96 453 33 5 :2 0 16 :46 84Hard ModulesBL 573 36 714 36 1 :0 0 0 0 0
S0 379 38 51 94 :43 4 196 27 0
S1 572 35 538 44 :67 3 5 :70 14
S2 575 35 355 42 :82 4 3 :42 24
S3 571 35 188 27 :92 0 3 :42 18
S4 572 35 185 24 1 :1 0 2 :28 33
The strategies S2andS4, which implement a decomposition
heuristic based on the number of abstraction renements,
are more ecient than strategies S1andS3that do not use
such a heuristic.
Table 2 provides more details on the eciency of dierent
decomposition strategies on the discussed sets of tasks.
RQ2.2: Eectiveness by Specication Decomposition.
According to Table 2, all our strategies that perform some
kind of specication decomposition can reduce the number
of lost results to less than 1 %.
RQ3.1: Overall Performance. For estimating the practi-
cal potential of multi-property verication with specication
decomposition and on-the-y specication weaving, we con-
sider the total process CPU time of strategy S4. Because the
JVM is now allowed to take the full advantage (see Sect. 5.2)
357of its just-in-time compiler, the results are slightly dierent
from those for the earlier research questions.
For the set of 250kernel modules, the overall process CPU
time reduces, compared to the baseline, from 60 hto25 h,
with an average speedup of 5.5 (median 5.0). To conrm our
results, and increase their validity, we evaluated our approach
on a larger set of verication tasks that covers 4 336 kernel
modules. The overall process CPU time is considerably
reduced from 400 h to130 h , with an average speedup of
8.0 (median 8.6), and a lower speedup for 99 % (4171 of
4 336 modules) of the modules. At the same time, 112 re-
sults ( 0:4 %) for separate properties were lost in comparison
to the baseline. Note that this set of modules contains entries
for which none of the properties is relevant, leading to the
best possible speedup for them.
5.4 Discussion
Our results illustrate that multi-property verication is
in many cases more ecient than verifying every property
individually. The number of solved problems can be kept on
a similar level by using a specication-decomposition strat-
egy. Taking the relevance of properties into account helps
to further improve the eciency of the overall verication
process. Measures of the verication process can indicate
properties that are likely to cause high costs. The measures
can be used to decide which properties to better verify later
in another partition (or even in isolation).
On-the-y weaving of specication automata, with dy-
namically adjustable precision, helps the verier to focus on
properties that are enabled for analysis at the moment, and
the current state of the specication can be encoded in an
appropriate abstract domain. Such an encoding is crucial
for our approach: it helps avoiding state-space explosion
considerably. An experimental comparison to traditional
approaches that instrument the specication into the pro-
gram code before the verier starts may be promising but is
outside the scope of this paper.
One hypothesis is that our approach can benet from a
large portion of intermediate verication results that are
similar for dierent properties. As we use lazy abstraction,
only those parts of the state space are modeled with higher
precision that are relevant for at least one of the analyzed
properties. Common states might be the result of expen-
sive computations, such as the computation of a Boolean
predicate abstraction. An indicator for the similarity of
state spaces is their size, that is, the number of states in
the set reached . We can compare the maximum number of
reached states of verication runs that verify a single property
to the size of the set reached of multi-property verication
runs. This analysis reveals that the number of reached states
is indeed similar in many cases, that is, we likely take ad-
vantage of this sharing potential; we leave a more elaborate
analysis of this observation to future work.
Our decomposition strategies are congured to (re-) con-
struct the state space from scratch for each partition of
properties, which is (still) a waste of precious intermedi-
ate verication results. Re-using (parts of) previously con-
structed state space graph for successive partitions could
lead to a signicant improvement of the performance [11,26].5.5 Threats to Validity
Our benchmark suite consists of a substantial set of Linux
kernel modules and a set of safety properties that are relevant
in that domain. The size and diversity of our benchmark
suite ensures that our conclusions are externally valid in that
application domain. Dierent tools with dierent abstract
domains and analysis techniques work dierently in terms of
sharing abstraction precisions and abstract states; similarly,
the SMT solver is critical for the performance.
The chosen time limit of 0:25 hfor a single property is cho-
sen more-or-less from previous experience: Most verication
tasks that we encounter can be solved within this time period
byCPAchecker (cf. one of the reports on the International
Competition on Software Verication [6]).
The speedup depends on the number of properties that are
veried, and can be articially increased by including many
properties that are not relevant for a verication task. We
use a subset of the properties that were dened in context of
the Linux Driver Verication project; each property can be
potentially relevant for each kernel module, or might become
relevant by a minor change to its code.
The distribution of code that is relevant for proving a
property is important. The scope of properties in a program
inuences the potential speedup of our approach. It is not
possible to control this variable, thus, we increase internal
validity by the large number of experiments on many dierent
modules. Proving a property is in general considered harder
than showing its violation. Our set of verication tasks has
only a small percentage of violations, such that the overall
picture is still valid.
6. CONCLUSION
We presented a set of enabling techniques for verifying
formal specications that can be further decomposed into
sets of properties. First, we presented the Loom analysis, a
new technique that on-demand and on-the-y weaves prop-
erties into the transition system. This way, we can switch on
and o, as needed during the verication process, properties,
independent from other analysis components; the precision
of the specication analysis denes the set of properties to
verify for a specic part of the state space. Second, we de-
veloped several promising heuristics for self-monitoring the
verication progress and reduce or increase the precision of
the analysis (the set of properties to be veried) dynamically
during the analysis. The combination of these concepts leads
to an ecient and eective analysis of large sets of properties
in one run of the verier. The results of our experimental
study are promising: Verifying several properties in one ver-
ication run can (in most cases) signicantly increase the
eciency of the verication process; this complements the
current practice where only single properties are veried in
one run of the verier. Our results open up a number of
interesting research directions: Techniques that were success-
ful for verifying single properties in one run might not be
the best choice for verifying larger sets of properties.
7. ACKNOWLEDGMENTS
This work has been supported by the State of Bavaria,
the Russian Science Foundation, and the German Research
Foundation (AP 206/4 and AP 206/6).
3588. ARTIFACT DESCRIPTION
To make our results easier to reproduce, we provide a
replication package that includes all verication tasks, tools,
and scripts for automatically re-running our experiments.
The verication tasks have been derived from 4 336 Linux
kernel modules, and a set of safety properties that dene
the correct usage of the Linux API. An implementation of
our approach is part of the open-source software verication
framework CPAchecker [12]; its source code is freely available
under the Apache 2 license. The replication package|a large
fraction of it can be reused for other research endeavors|is
provided on a supplementary Web site5which contains de-
tailed instructions for reproducing our experimental results.
Benchmark Suite. We evaluated our approach on a set of
modules from the Linux kernel version 4:0-rc1. The modules
were extracted and prepared using the Linux Driver Verica-
tion (LDV) toolkit6[32], which also takes care of enriching
the modules with an environment model of the Linux kernel.
Each module has several entry functions which represent, for
example, dierent interrupt handlers; we only consider one
entry function ( main0 ) per module. We use two sets of mod-
ules for our experiments: the full set with 4 336 modules and
a subset with 250modules. The subset consists of randomly
chosen tasks from the full set of modules, for which at least
two properties are relevant. The pre-processed Linux kernel
modules are licensed under GNU GPL 2.0.
The specication consists of 14safety properties that are
relevant for the Linux kernel; a detailed description of these
properties can be found in Table 4. Not all properties are
relevant for all kernel modules, for example, property 77_1a
is relevant for only two modules from the subset with 250el-
ements. Table 3 provides an overview on the relevance of the
properties for the two sets of kernel modules. For 1 989 of
the kernel modules, at least one property is relevant; at least
two properties are relevant for 1 059 modules.
Experimental Setup. We have implemented our approach
on top of the CPAchecker framework. We used revision 21027
from the branch muauto for our experiments, with SMTIn-
terpol as SMT solver. All experiments have been executed
on machines with Linux 4:2and Java 1:7, equipped with
two Intel Xeon E5-2650 CPUs and 135 GB of RAM. As we
assume that a software verier can always make use of the
full memory installed on a (typical) machine, we limit runs
in which only single properties are veried (baseline) and
runs where several properties are veried at once to the same
amount of memory: 26 GB of Java heap and 30 GB for the
process itself; each process was limited to use 4 cores.
Evaluation and Reproducibility. Since CPAchecker is
written in Java, special characteristics of a JVM have to
be considered [24]. In particular, a scenario where we com-
pare multiple launches of the JVM to a single launch, but
also comparing multiple iterations to a single iteration of
an algorithm, requires special care. To mitigate the eects
of the just-in-time compiler of the JVM, we force the JVM
to already compile most of the byte code during its startup.
The initial size of the Java heap is set to the maximum.
We measure and control computing resources using
BenchExec [15], a framework for reliable and accurate
benchmarking, which is freely available and licensed under
5http://sosy-lab.org/research/spec-decomposition/
6http://linuxtesting.org/project/ldv/Table 3: Not all properties are relevant for every
kernel module; the number of modules for which a
property (table header) is relevant is given for two
sets of modules: the full set Allwith 4 336 kernel
modules, and a subset Subconsisting of 250modules
with at least two relevant properties each.
081a
101a
321a
431a
681a
681b
771a
1011a
1061a
1181a
1291a
1321a
1341a
1471a
Sub 29 119 129 191 31 14 2 4 19 19 20 13 43 23
All 129 783 846 1 054 150 65 6 10 111 82 125 52 200 123
Table 4: Safety properties that we veried for the
Linux kernel modules
Property Description
081a Each module that was referenced with module_get must
be released with module_put afterwards.
101a Each memory allocation that gets performed in the con-
text of an interrupt must use the ag GFP_ATOMIC .
321a The same mutex must not be acquired or released twice
in the same process.
431a Each memory allocation must use the ag GFP_ATOMIC if
a spinlock is held.
681a All resources that were allocated with usb_alloc_urb
must be released by usb_free_urb .
681b Each DMA-consistent buer that was allocated with
usb_alloc_coherent must be released by calling
usb_free_coherent .
771a Each memory allocation in a code region with an active
mutex must be performed with the ag GFP_NOIO .
1011a All structs that were obtained with blk_make_request
must get released by calling blk_put_request afterwards.
1061a The modules gadget ,char, and class that were regis-
tered with usb_gadget_probe_driver ,register_chrdev ,
and class_register must be unregistered by calling
usb_gadget_unregister_driver ,unregister_chrdev
and class_unregister correspondingly in reverse order
of the registration.
1181a Reader-writer spinlocks must be used in the correct order.
1291a An oset argument of a find_bit function must not be
greater than the size of the corresponding array.
1321a Each device that was allocated by by usb_get_dev must
get released with usb_put_dev .
1341a The probe functions must return a non-zero value in case
of a failed call to register_netdev orusb_register .
1471a RCU pointer/list update operations must not be used
inside RCU read-side critical sections.
Apache 2. All requirements on the hardware, the command-
line parameters for CPAchecker , and the verication tasks to
use, are specied in benchmark denition les (XML), which
are shipped with the replication package.
9. REFERENCES
[1] T. Ball, E. Bounimova, B. Cook, V. Levin,
J. Lichtenberg, C. McGarvey, B. Ondrusek, S. K.
Rajamani, and A. Ustuner. Thorough static analysis of
device drivers. In Proc. EuroSys , pages 73{85. ACM,
2006.
[2] T. Ball, V. Levin, and S. K. Rajamani. A decade of
software model checking with Slam .Commun. ACM ,
54(7):68{76, 2011.
[3] T. Ball and S. K. Rajamani. Slic: A specication
language for interface checking (of C). Technical Report
MSR-TR-2001-21, Microsoft Research, 2002.
[4] C. Barrett, M. Deters, L. de Moura, A. Oliveras, and
A. Stump. 6 Years of SMT-COMP. J. Autom.
Reasoning , 50(3):243{277, 2012.
359[5] P. Baudin, J.-C. Filli^ atre, C. March e, B. Monate,
Y. Moy, and V. Prevosto. Acsl : ANSI/ISO C
specication language. 2008.
[6]D. Beyer. Reliable and reproducible competition results
with benchexec and witnesses. In Proc. TACAS .
Springer, 2016.
[7] D. Beyer, A. J. Chlipala, T. A. Henzinger, R. Jhala,
and R. Majumdar. The Blast query language for
software verication. In Proc. SAS , LNCS 3148, pages
2{18. Springer, 2004.
[8] D. Beyer, A. Cimatti, A. Griggio, M. E. Keremoglu,
and R. Sebastiani. Software model checking via
large-block encoding. In Proc. FMCAD , pages 25{32.
IEEE, 2009.
[9] D. Beyer, T. A. Henzinger, and G. Th eoduloz.
Congurable software verication: Concretizing the
convergence of model checking and program analysis. In
Proc. CAV , LNCS 4590, pages 504{518. Springer, 2007.
[10]D. Beyer, T. A. Henzinger, and G. Th eoduloz. Program
analysis with dynamic precision adjustment. In Proc.
ASE, pages 29{38. IEEE, 2008.
[11] D. Beyer, A. Holzer, M. Tautschnig, and H. Veith.
Information reuse for multi-goal reachability analyses.
InProc. ESOP , LNCS 7792, pages 472{491. Springer,
2013.
[12]D. Beyer and M. E. Keremoglu. CPAchecker : A tool
for congurable software verication. In Proc. CAV ,
LNCS 6806, pages 184{190. Springer, 2011.
[13]D. Beyer, M. E. Keremoglu, and P. Wendler. Predicate
abstraction with adjustable-block encoding. In Proc.
FMCAD , pages 189{197. FMCAD, 2010.
[14] D. Beyer, S. L owe, E. Novikov, A. Stahlbauer, and
P. Wendler. Precision reuse for ecient regression
verication. In Proc. ESEC/FSE , pages 389{399. ACM,
2013.
[15]D. Beyer, S. L owe, and P. Wendler. Benchmarking and
resource measurement. In Proc. SPIN , LNCS 9232,
pages 160{178. Springer, 2015.
[16] J. R. B uchi. On a Decision Method in Restricted
Second Order Arithmetic . 1960.
[17]G. Cabodi and S. Nocco. Optimized model checking of
multiple properties. In Proc. DATE , pages 543{546.
IEEE, 2011.
[18] S. Chaudhuri and R. Alur. Instrumenting C programs
with nested word monitors. In Proc. SPIN , LNCS 4595,
pages 279{283. Springer, 2007.
[19] E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and
H. Veith. Counterexample-guided abstraction
renement. In Proc. CAV , LNCS 1855, pages 154{169.
Springer, 2000.
[20] D. Dams and K. S. Namjoshi. Orion: High-precision
methods for static error analysis of C and C++
programs. In Proc. FMCO , LNCS 4111, pages 138{160.
Springer, 2005.
[21] M. B. Dwyer, G. S. Avrunin, and J. C. Corbett.
Patterns in property specications for nite-state
verication. In Proc. ICSE , pages 411{420. ACM, 1999.
[22]M. B. Dwyer, A. Kinneer, and S. G. Elbaum. Adaptive
online program analysis. In Proc. ICSE , pages 220{229.
IEEE, 2007.
[23] R. Fraer, S. Ikram, G. Kamhi, T. Leonard, and
A. Mokkedem. Accelerated verication of RTLassertions based on satisability solvers. In Proc.
HLDVT , pages 107{110. IEEE, 2002.
[24]A. Georges, D. Buytaert, and L. Eeckhout. Statistically
rigorous Java performance evaluation. In Proc.
OOPSLA , pages 57{76. ACM, 2007.
[25] P. Godefroid, M. Y. Levin, and D. A. Molnar. Active
property checking. In Proc. EMSOFT , pages 207{216.
ACM, 2008.
[26]T. A. Henzinger, R. Jhala, R. Majumdar, and M. A. A.
Sanvido. Extreme model checking. In Verication:
Theory and Practice , LNCS 2772, pages 332{358.
Springer, 2003.
[27]T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre.
Lazy abstraction. In Proc. POPL , pages 58{70. ACM,
2002.
[28] J. K. Hollingsworth, B. P. Miller, M. J. R. Goncalves,
O. Naim, Z. Xu, and L. Zheng. Mdl: A language and
compiler for dynamic program instrumentation. In
Proc. PACT , pages 201{212. IEEE, 1997.
[29] F. Ivancic, G. Balakrishnan, A. Gupta,
S. Sankaranarayanan, N. Maeda, T. Imoto,
R. Pothengil, and M. Hussain. Scalable and
scope-bounded software verication in Varvel .Autom.
Softw. Eng. , 22(4):517{559, 2015.
[30] F. Ivancic, G. Balakrishnan, A. Gupta,
S. Sankaranarayanan, N. Maeda, H. Tokuoka, T. Imoto,
and Y. Miyazaki. Dc2: A framework for scalable,
scope-bounded software verication. In Proc. ASE ,
pages 133{142. IEEE, 2011.
[31] Z. Khasidashvili, A. Nadel, A. Palti, and Z. Hanna.
Simultaneous SAT-based model checking of safety
properties. In Proc. HAV , LNCS 3875, pages 56{75.
Springer, 2005.
[32] A. V. Khoroshilov, V. Mutilin, A. K. Petrenko, and
V. Zakharov. Establishing Linux driver verication
process. In Proc. Ershov Memorial Conference ,
LNCS 5947, pages 165{176. Springer, 2009.
[33] G. A. Kildall. A unied approach to global program
optimization. In Proc. POPL , pages 194{206. ACM,
1973.
[34] O. Kupferman and M. Y. Vardi. Model checking of
safety properties. In Proc. CAV , LNCS 1633, pages
172{183. Springer, 1999.
[35] S. K. Lahiri, R. Nieuwenhuis, and A. Oliveras. SMT
techniques for fast predicate abstraction. In Proc. CAV ,
LNCS 4144, pages 424{437. Springer, 2006.
[36]C. Loiacono, Marco Palena, P. Pasini, D. Patti, S. Quer,
S. Ricossa, and D. Vendraminet. Fast cone-of-inuence
computation and estimation in problems with multiple
properties. In Proc. DATE , pages 803{806. ACM, 2013.
[37] V. O. Mordan and V. S. Mutilin. Checking several
requirements at once by CEGAR. In Proc. Ershov
Memorial Conference 2015 , LNCS 9609, pages 218{232.
Springer, 2015.
[38]D. E. Muller. Innite sequences and nite machines. In
Proc. SWCT , pages 3{16. IEEE, 1963.
[39] E. M. Novikov. An approach to implementation of
aspect-oriented programming for C. Programming and
Computer Software , 39(4):194{206, 2013.
[40] R. Purandare, M. B. Dwyer, and S. G. Elbaum.
Optimizing monitoring of nite state properties
360through monitor compaction. In Proc. ISSTA , pages
280{290. ACM, 2013.
[41] X. Qin, M. Chen, and P. Mishra. Synchronized
generation of directed tests using satisability solving.
InProc. VLSI , pages 351{356. IEEE, 2010.
[42] F. B. Schneider. Enforceable security policies. ACM
Trans. Inf. Syst. Secur. , 3(1):30{50, 2000.[43] O. Ser y. Enhanced property specication and
verication in Blast . InProc. FASE , LNCS 5503,
pages 456{469, 2009.
[44] M. Y. Vardi and P. Wolper. An automata-theoretic
approach to automatic program verication. In Proc.
LICS , pages 332{344. IEEE, 1986.
[45] W. Visser, J. Geldenhuys, and M. B. Dwyer. Green :
Reducing, reusing and recycling constraints in program
analysis. In Proc. FSE , page 58. ACM, 2012.
361