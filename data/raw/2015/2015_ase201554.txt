An Automated Framework for Recommending
Program Elements to Novices
Kurtis Zimmerman and Chandan R. Rupakheti
Department of Computer Science and Software Engineering
Rose-Hulman Institute of Technology
Terre Haute, Indiana 47803
{zimmerka, rupakhet}@rose-hulman.edu
Abstract —Novice programmers often learn programming by
implementing well-known algorithms. There are several chal-
lenges in the process. Recommendation systems in softwarecurrently focus on programmer productivity and ease of devel-opment. Teaching aides for such novice programmers based onrecommendation systems still remain an underexplored area. Inthis paper, we present a general framework for recognizing thedesired target for partially-written code and recommending areliable series of edits to transform the input program into thetarget solution. Our code analysis is based on graph matching andtree edit algorithms. Our experimental results show that efﬁcientgraph comparison techniques can accurately match two portionsof source code and produce an accurate set of source code edits.We provide details on implementation of our framework, whichis developed as a plugin for Java in Eclipse IDE.
Keywords—Recommendation Framework, pq-Gram Algorithm
I. I NTRODUCTION
Learning how to program can be a challenging endeavor
to many novices. Past research has exposed many barriers to
learning programming languages, APIs, and frameworks [15,21]. Novices often think about problems in the situation
model, which is an imprecise mental model of the problems.Translation of problems in the situation model to a precise
system model (represented by artifacts such as source code)
often requires external help [7].
Given a programming problem, a novice may not know
how to break it into meaningful pieces (design barrier ). Even
if he breaks the problem properly, he may not know whichprogramming elements to choose to get the desired result(selection barriers). After selecting programming elements, hemay not know how to make them work together (coordinationbarriers) or how to use them correctly (use barriers). Assum-ing he was successful in all of these steps, he may now wonderwhy it did not work as expected (understanding barriers).Even if he was able to form an idea as to why the algorithmdid not work, he may not know how to check the internalproperties of the program to validate his idea ( information
barriers). Ko et al. identify these learning barriers as some ofthe central challenges in programming software systems [15].Fischer, on the other hand, argues for a software frameworkconsisting of the necessary toolset to overcome the barriersbetween the situation model and the system model [7].
As instructors of introductory programming courses for
several years, we have experienced that example-based learn-ing [1] and few coaching sessions can help overcome thedesign and understanding barriers to some extent. There are
debugging tools [13, 17] to help with information barriersthat work well. The selection, coordination, and use barriers,
however, present a unique challenge as they require constantguidance from instructors. Due to the lack of time, instructorsmay fail to provide such guidance to novices.
Search-based tools [3, 9, 10] may help novices to some
extent, however, past research has shown that novices may notknow how to formulate the right queries to get meaningfulhelp from such tools [14]. An automated tool integrated witha novice’s development environment that could read his code,recognize the pieces of algorithms being implemented, andrecommend a set of source code edits to achieve the correctsolutions iteratively seems ideal in this context. This work isan effort in that direction.
We make the following key contributions: i) given a source
and multiple target implementations, we present algorithms forrecognizing the best matching target implementation, ii) givena source and target implementation, we present algorithms forevaluating edit recommendations, and iii) we present a non-invasive visualization of edit recommendations integrated to anovice’s development environment.
In the rest of the paper, we present a typical use case of the
framework in Section II, discuss related works in Section III,present the framework’s design in Section IV, discuss resultsin Section V, identify limitations and discuss future work inSection VI, and ﬁnally, conclude the paper in Section VII.
II. A M
OTIV A TING EXAMPLE
Let’s assume that an instructor wants to use our framework
and has all of her students install our plugin in their EclipseIDE. The following is the typical use case:
1) The instructor will create programming problems.2) She will create/ﬁnd different implementations of the
programming problems (Java ﬁles) and supply it tothe students’ IDEs as knowledge bases. Note that thecurrent prototype stores ﬁles locally. This processcan be improved by having a remote server hostthe encrypted version of target implementations todiscourage students from directly copying the code.
3) Among other relevant help, she will provide students
some guidance in designing the solutions.
4) A student writes some code for a problem in the set.
When he gets stuck, he will press the help button ofthe framework. The framework will read his code,search for the best matching implementations in theknowledge base, and recommend the next set of editstowards the best matched solution using error markers(see Figure 1). In Figure 1a, two recommendations
2015 30th IEEE/ACM International Conference on Automated Software Engineering
978-1-5090-0025-8/15 $31.00 © 2015 IEEE
DOI 10.1109/ASE.2015.54283
(a) Source code written by a novice
(b) Target code provided by an instructor
Fig. 1: The framework offering recommendations using mark-
ers based on the best matching target implementation.
are presented: one for substituting the ’+’ operator atline 9 and another for the missing return statementimmediately after line 10.
5) Step 4 repeats until he gets the solution right.
In this way, novices will work independently while still gettinghelp to overcome their learning barriers. It is possible thatstudents may rely heavily on the framework rather than solvingthe problem themsleves. To discourage such situtation, as afuture work, the framework will allow conﬁgurations thatthrottle recommendations based on the frequency of requests.
III. R
ELA TED WORK
Recommendation Systems: Recommendation systems for
software engineering extract vital information from most oftenthe source code or object code to provide help with softwareengineering tasks in a given context [24]. Several tutoring sys-tems have been developed in the past that automate generationof hints to help novices based on their code [16, 18, 23, 27].However, the generic hints produced by such systems can behard to translate to actual code for novices. Unlike theirs, ourframework provides code-speciﬁc edits.
Programming Tools: There are tools that focus on search-
ing for API methods [3, 9], understanding example code [22],critiquing API client code [8, 25], and analyzing and de-bugging programs [17]. Other efforts include auto-completiontools within IDEs to recommend API methods [4, 12]. Arelated tool, Strathcona, uses structure of code and differ-ent matching heristics such as inheritance relation, methodcalls, and types of objects declared in a method body toﬁnd matching examples in a repository [11]. Our frameworkcomplements theirs as we focus on programming constructsrather than higher-level API methods.
Syntax Tree Matching: We use Abstract Syntax Tree
(AST) provided by Eclipse’s Java Development Tools (JDT
1)
to perform comparisons between source and target code. Notethat in syntax trees matching, the use of different names for
1http://www.eclipse.org/jdt/. All URLs veriﬁed on 5/13/2015.the same variable between source and target code can be anissue. A node mapping isomorphism technique can be usedwhere, for example, all instances of the variable iin the source
is mapped to the variable pin the target program [19]. The
algorithm stops after ﬁnding the ﬁrst structural difference, butour problem requires all differences.
Falleri et al. propose a method of source code differencing
using AST called the Gumtree algorithm [6]. Given two ASTs,the algorithm uses two phases to produce a mapping ofmatching (or minimum difference) subtrees from one tree toanother that can be fed into an algorithm to compute an editscript. Gumtree is similar to our pq Gram-based algorithmin that it is focused on producing ﬁne-grained, realistic editsequences. Gumtree has a worst-case complexity of O(n
2),
where nis the number of nodes in the larger tree and assumes
the source and target are known. For a tool whose goal is todetermine the target and determine edits, this algorithm couldonly feasibly be used after the closest target is determined.
Graph Matching: A method for fast exact graph matching
is proposed by Etheredge, making use of adjacency matri-ces [5]. However, the given algorithm does not take nodelabels into account and only performs subgraph matching. Weneed the best overall match between two graphs. Seeking anapproach to match source code and extract edits in one pass,we explored the VF graph isomorphism algorithm [20]. Adrawback of the VF technique is that it does not ensure anoptimal mapping between the two given trees. An objectivefunction would have to be introduced for optimal mapping.Determining this objective value is the essential problem weare trying to solve, thus, making this method ineffective.
We took inspiration from the similarity matrix based graph
matching technique [30] to develop a preliminary algorithmfor comparing graphs. In the algorithm, we compare the labelas well as total number of incoming and outgoing edges ofeach node in the two graphs. This algorithm runs in O(n
3)
time and takes O(n2)space. We switched to a more efﬁcient
pg-Gram based algorithm [2] discussed shortly.
Tree Edit Distance: Tree edit distance refers to the min-
imal number of node insertions, node deletions, and noderelabelings required to transform a given tree Tinto a desired
target T
/prime, as originally detailed by Tai as an extension of the
string edit problem [28]. If VandV/primeare the number of nodes
in trees TandT/prime, respectively, and LandL/primeare their respec-
tive maximum depths, Tai presents a node-mapping approachwhich computes the edit distance in O(V·V
/prime·L2·L/prime2)time.
Zhang and Shasha improved on the time complexity of Tai’sapproach by eliminating certain subtree distance calculations
toO(V
2·log2(V)), where Vis the number of nodes in the
larger of the two trees [26].
An approximate but faster version of the tree-edit distance
algorithm called pq-Gram is developed by Augsten et al. [2].
The algorithm considers both labels and overall structure of thetrees during comparison. It breaks the given trees into smallerstructures and compares the two for similarities. We use pq-Gram to identify the best matching target code.
Figure 2 illustrates how pq-Gram proﬁles are created from
the given source code. The granularity at which a tree can bebroken down is given by the values pandq, which are the
number of non-leaf and leaf nodes in the smaller structure,respectively (Figure 2c). The algorithm adds null (*) nodes
284(a) Sample code
 (b) AST for the sample code
(c) pq-Gram
structure
(d) First pq-Gram for theroot node
(e) Start of proﬁles forthe AST
Fig. 2: Translation of source code to pq-Gram proﬁles (P = Program and W = while).
to break each tree into all of its subtrees of the same shape.
Figure 2d is the ﬁrst pq-Gram corresponding to the root node ofthe AST in Figure 2b. Similarly, Figure 2e is the beginning ofthe proﬁle for the AST. Given two trees, the pq-Gram distancebetween the two is a value between 0(identical trees) and 1
(no similarity). The algorithm traverses each tree by visitingeach node just once taking O(n)time and O(n)space. The end
result relies on a multiset intersection that can be computed inO(nlogn)time, which is the bottleneck of the algorithm [2].
pq-Gram is much more efﬁcient than the similarity matrixbased approach in [30] and provides a good approximationof the distance between the two trees.
IV . F
RAMEWORK DESIGN
Our framework can be divided into three primary modules:
i) Target Recognition, ii) Edit Recommendation, and iii) Pre-sentation via User Interface. We have already demonstrated thepresentation part of the framework in Section II. We explorethe former two modules in this section.
A. Target Recognition
For each target code in the knowledge base, the pq-Gram
distance from the user’s code to the target code is computed.
The target code corresponding to the smallest pq-Gram dis-tance is selected for further processing. If the minimum pq-Gram distance exceeds a threshold of certainty, the systemcannot guarantee reasonable recommendations. Similarly, ifmultiple targets correspond to the same pq-Gram distance, thenthe framework non-deterministically chooses one.
We present a necessary size criterion for target code
to narrow the search scope early. Only targets that satisfythis criterion are selected for computing pq-Gram distances.Assume that I
icorresponds to the pq-Gram proﬁle of tree Ti.
Size Criterion Theorem: Given trees T1andT2with|I1|≤
|I2|and matching threshold r,i fd=dist( T1,T2)is such that
0≤d≤r≤1, then|I1|≥1−r
1+r|I2|.
Proof: In [2], the pq-Gram distance is deﬁned as
dist( T1,T2)=1−2|I1∩I2|
|I1∪I2|.
Note that in any case, using multisets means |I1∪I2|=|I1|+
|I2|. In the best case scenario, to maximize |I1∩I2|,i fI 1⊆I2,
then|I1∩I2|=|I1|, so we can make the simpliﬁcation
dist( T1,T2)=1−2|I1∩I2|
|I1∪I2|=1−2|I1|
|I1|+|I2|.
Then, if ris the threshold such that 0≤r< 1,w ew a n t
distance dto be such that 0≤d≤r, so we must have
r≥ 1−2|I1|
|I1|+|I 2|
⇒| I1|≥1−r
1+r|I2|(after simpliﬁcation).Hence, pre-computing the size of pq-Gram proﬁles of
targets in the knowledge base can signiﬁcantly improve theperformance of this step. At the conclusion of this step, ASTsT
s(source) and Tt(target) have been determined, where Tt
corresponds to the closest matching target AST.
B. Edit Recommendation
Once the target code has been identiﬁed, the next step is to
provide the user with a set of recommendations to transform
their code into the target implementation. Existing solutionssuffer from a debilitating runtime as they rely on a node-to-node mapping technique (graph isomorphism [20]), which inthe worst case runs in exponential time.
In order to provide a reasonable experience for the user
and maintain computational efﬁciency, we developed a newrecommendation algorithm based on the pq-Gram proﬁlesobtained earlier. The algorithm has four steps: acquiring pq-Gram proﬁles (Section IV -B1), building common subtrees(Section IV -B2), identifying naive edits (Section IV -B3), andﬁnally, minimizing insertions and deletions (Section IV -B4).
1) Acquiring pq-Gram Proﬁles: The edits rely on informa-
tion from the pq-Gram proﬁles, I
s(source) and It(target),
which are computed in the previous stage (Section IV -A). Tohelp understand all of the steps involved in edit recommenda-tions, let’s use a running example of Figure 3. The algorithmwill be carried out with T
sandTtshown in Figure 3a and 3b,
respectively. The pq-Gram algorithm begins by extending eachtree with null nodes to ensure each node has the necessarynumber of siblings and children (Figure 3c and 3d). Then,using the algorithm described in [2], the proﬁles correspondingtoT
sandTtare computed (Figure 3e and 3f). At this point,
we proceed to building common subtrees.
2) Building Common Subtrees: By building the common
subtrees, a considerable number of nodes and edges areremoved and not considered for further edits. Note that thepq-Gram tuples are of the form (a
1,a2, ..., a p,c1,c2, ..., c q),
where aiis the parent of ai+1 , and apis the parent of
each ci. Algorithm 1 takes advantage of this form by ﬁrst,
adding all nodes as roots of common subtrees and then, byremoving them once they have been added as children toanother common node. At the end, B
Sholds the set of roots
of the common subtrees of TsandTt.
For our example in Figure 3, CS={(∗,A ,C ,∗, ∗)}.
Hence, BS={A} andA→Cis the only common subtree.
3) Identifying Naive Edits: The simplest set of edits is to
delete all extra nodes (those not in the common subtrees) inT
sand subsequently insert all missing nodes (those not in the
common subtrees) in Tt(Algorithm 2). Any nodes that show
up in the extra tuples (E S) and not in the common tuples (C S)
285(a)Ts
 (b)Tt
 (c) Extended Ts
 (d) Extended Tt
 (e)Is
 (f)It
Fig. 3: A running example for explaining the edit recommendation algorithm.
Algorithm 1 Building common subtrees of TsandTt
Require: pq-Gram proﬁles Is,It
Ensure: SetBSis roots of common subtrees of TsandTt
CS←Is∩It
BS←{ }
for all (a1,a2, ..., a p,c1,c2, ..., c q)∈CSdo
BS←BS∪{a1}
BS←BS−{a2, ..., a p,c1,c2, ..., c q}
end for
must be deleted, while all nodes that show up in the missing
tuples (M S) and not in CSmust be inserted. Note that this set
of edits is a correct solution, but not an optimal one.
Algorithm 2 Identifying insertions and deletions
Require: pq-Gram proﬁles IsandIt
Ensure: ASis the set of insertions, RSis the set of deletions
AS←{ } ,RS←{ }
CS←Is∩It
MS←It−CS
ES←Is−CS
for all (a1,a2, ..., a p,c1,c2, ..., c q)∈MSdo
AS←AS∪{(ai−1,ai)}for2≤i≤pifai/∈CS
AS←AS∪{(ap,ci)}for1≤i≤qifci/∈CS
end forfor all (a
1,a2, ..., a p,c1,c2, ..., c q)∈ESdo
RS←RS∪{(ai−1,ai)}for2≤i≤pifai/∈CS
RS←RS∪{(ap,ci)}for1≤i≤qifci/∈CS
end for
Returning to our example in Figure 3, recall that CS=
{(∗,A ,C ,∗, ∗)}. Missing tuples (M S) and extra tuples (E S)
are shown in Figure 4a and 4b, respectively. Notice that themissing components (in M
S) are the relationships A→X
andC→Y. We now add these to the set of insertions (A S).
Likewise, the extra component (from ES)i sA→B. We add
it to the set of deletions (R S). At the end of Algorithm 2,
AS={(A, X ),(C, Y )}andRS={(A, B )}.
4) Minimizing Insertions and Deletions: We now introduce
relabelings, as shown in Algorithm 3, in an effort to minimizethe number of insertions and deletions generated by Algo-rithm 2. There are two cases for which an insertion or deletionpair can be removed:
1) A node ais being deleted from x, and a node b
is being inserted onto x. In this case, the insertion
and deletion can be replaced by a single relabeling,mapping atob.
(a) Missing Tuples (M S)
 (b) Extra Tuples (E S)
Fig. 4: MSandES, computed during Algorithm 2.
2) A node ais being deleted from x, and the node ais
being inserted onto y, and xis being relabeled to y
(i.e. (x, y)is in the set of relabelings).
Notice that in either case, the insertion and deletion can beremoved, and only in the ﬁrst case do we replace them witha relabeling. In the second case, the insertion and deletion aresimply inverses of one another.
Algorithm 3 Minimizing insertions and deletions
Require: Set of insertions ASand deletions RS
Ensure: NSis the set of relabelings, ASandRSthe mini-
mized sets of insertions and deletionsN
S←{ }
for all (pi,ci)∈ASdo
for all (pd,cd)∈RSdo
ifNS(pd)=NS(pi)then
ifcd/negationslash=cithen
NS←NS∪{(cd,ci)}
end ifA
S←AS−{(pi,ci)}
RS←RS−{(pd,cd)}
end if
end for
end for
At the end of Algorithm 3, we are left with three sets,
one each for relabelings, insertions, and deletions. These threetogether represent the total set of edits. To ﬁnish our examplein Figure 3, recall that A
S={(A, X ),(C, Y )}andRS=
{(A, B )}. Because we must remove Bfrom Aand insert X
onto A, those edits can be squashed into one by replacing them
with a relabeling, B→X,s oN S={(B,X )}. By removing
one insertion and one deletion, we are left with AS={(C, Y )}
andRS={}. Thus, the ﬁnal set of edits can be described
as follows: i) relabel BtoX, and ii) insert Yonto Cin
Figure 3a. Starting from Ts, this sequence of edits will indeed
match Tt. This concludes our discussion on recommendation
286(a) Binary Search
 (b) Bogo Sort
 (c) Bubble Sort
Fig. 5: Graphs showing pq-Gram distances (vertical axis) for increasing code differences (horizontal axis).
algorithms. We now discuss an issue with variable names that
needed special handling.
C. Issue with V ariable Names
The source and target programs may use different names
for the same variable. Since our approach utilizes node labels,
we want to ensure the variable names have no (or minimal)impact on both the pq-Gram distance scores and the recom-mended edits. To address this issue, we slightly altered theAST parsing process. As the Java method is parsed, a mappingis constructed, where each unique identiﬁer points to all of itsnodes in the AST. We proceed through the recommendationalgorithm as is. We then ﬁlter out the target code identiﬁerswhile maintaining the effect of the edits as follows. If i
is a string identiﬁer, let M(i)represent the set of nodes
corresponding to each use of iin the user’s code, and let Nbe
an empty map which will be used to keep track of equivalentvariables between the source and target code. For each i,i f
there exists a relabeling of icorresponding to each node in
M(i), consider two cases:
1) If each relabeling maps ito the same i
/prime, then remove
all of the relabelings associated with iand add i/prime→i
toN.
2) Otherwise, for each relabeling i→i/prime,
a) If i/prime∈N, change the relabeling to i→
N(i/prime).
b) Otherwise, if i/primerefers to a variable in the
user’s source code, keep the relabeling, as itrefers to a variable that is in use.
c) Otherwise, remove the relabeling, because
the variable name is not of interest.
All of these algorithms work together to create an optimal
set of edit proposals for the user. Since Eclipse providessupport for mapping AST nodes to the source code, we areable to use the error notiﬁcation markers of Eclipse to denoteregions in the user’s code where changes need to be made.
V. R
ESUL TS
Our framework relies heavily on the ability of the target
recognition algorithm (Section IV -A) to react to the followingsituations appropriately:
1) As the differences between two fragments of code
increases, the pq-Gram distance also increases.
2) The trend in pq-Gram distances should have mini-
mal impact due to variable name differences (Sec-tion IV -C) in the source and target programs.
As a preliminary evaluation of our prototype, we focus on
validating these two key technical assumptions. A thoroughevaluation of edit recommendations (Section IV -B) needs userstudies and is out of the scope of this paper.
To test these assumptions as well as the recommendation
algorithm itself, a knowledge base of 32 different searching
and sorting algorithms was built, each featuring a test suite ofperturbed implementations. The test suites were divided intofour complexity classes as follows: i) Semantically equivalent:
syntactic differences, but semantically equivalent methods; ii)Minimal: edits are minimal, including at most a few relabel-
ings; iii) Moderate: edits are moderate, including at least one
insertion or deletion, but no more than one of each; and ﬁnally,iv)Severe: edits are more severe, including a pair of insertions
or a pair of deletions.
For each test suite, two sets of the pq-Gram distances
between the source and target ASTs were computed: oneincluding identiﬁers and the other excluding identiﬁers. InFigure 5, we sample the three representative cases out of32. The result shows that, in general, the pq-Gram distancesincrease as complexity increases. Secondly, the distance trendsfor ASTs with identiﬁers and without are similar, with smalladjustments due to the number of AST nodes being reduced.The results are consistent across all 32 test suites.
Note that the trend in Figure 5 is not monotonically
increasing due to one of the following two factors. First, theplacement of edits relative to one another can impact theireffect on the distance between trees. For example, two adjacentdeletions can disrupt signiﬁcantly more sibling relationshipsthan removing two nodes far from one another. Second, thelevel of placement of edits affects their impact on the distancescore. An edit at a lower level (particularly leaves) affectsfewer pq-Grams than a higher-level, non-leaf edit. Due tothe varying nature of the algorithms under test, the editscannot be placed uniformly across all algorithms, resulting innon-uniform trends. Overall, our preliminary evaluation showspromising results as it validates our key technical assumptions.
VI. L
IMIT A TIONS AND FUTURE WORK
We now present some of the limitations of the framework
and opportunities for future improvements.
Program Analysis: We use AST for our analyses. AST -
based analyses work well even under compilation errors, whichis critical for novices. Also, our framework can be quicklyadapted to a new language that can be parsed into ASTs.However, AST -based analyses are intraprocedural (analysis ofone method at a time). Use of interprocedural analyses (spansmultiple methods) remains a future work.
Semantic Equivalence: One major pitfall of AST repre-
sentations of source code is the loss of behavioral information.
287Because syntactically different programs can behave equiva-
lently, the AST -based approach toward ﬁnding differences willincorrectly classify many pieces of source code as differenteven though they accomplish the same task. A few semanticequivalences are reduced to a canonical form in our currentprototype, such as normalizing the for loop to the while loop
and normalizing operators in the form x [op]= y tox = x [op]
y, but there are others that need special care. We have exploredthe possibility of using Control Flow Graphs (CFG) built ontop of Jimple Intermediate Representation (IR) of SOOT [29]instead of AST. SOOT, to a certain extent, optimizes IR to havesimilar ﬂow structures for semantically equivalent programs.However, compilation and de-compilation are asymmetric op-erations, and the recommendations based on IR do not mapwell with the original code. Semantic equivalence remains akey area to be explored in the future.
Usability Testing: So far our evaluation efforts have been
directed towards validating the technical aspects of the frame-work. As a future work, we plan to conduct user studiesto assess the quality of recommendations in a controlledenvironment. We also plan to evaluate the framework by usingit as a part of our introductory programming courses.
VII. C
ONCLUSION
Novices may face several challenges while learning pro-
gramming. Tooling efforts in software engineering have beenmore focused on helping programmers with higher-level pro-gramming tasks than with basic language-speciﬁc constructs.We present a framework that can help novices in their learningprocess by recommending speciﬁc code edits relevant to theirproblems within the Eclipse IDE. Our preliminary resultsestablish technical feasibility of the framework. In the future,we plan to conduct user studies to test the usefulness of ourprototype. We also plan to release the framework as an opensource tool for both instructors and students.
R
EFERENCES
[1] R. Anderson, R. Anderson, K. M. Davis, N. Linnell,
C. Prince, and V . Razmov, “Supporting active learningand example based instruction with classroom technol-ogy,” in SIGCSE, 2007, pp. 69–73.
[2] N. Augsten, M. B ¨ohlen, and J. Gamper, “Approximate
matching of hierarchical data using pq-grams,” in VLDB,
2005, pp. 301–312.
[3] J. Brandt, M. Dontcheva, M. Weskamp, and S. R. Klem-
mer, “Example-centric programming: Integrating websearch into the development environment,” in CHI, 2010,
pp. 513–522.
[4] M. Bruch, M. Monperrus, and M. Mezini, “Learning from
examples to improve code completion systems,” in FSE,
2009, pp. 213–222.
[5] M. Etheredge, “Fast exact graph matching using adja-
cency matrices,” in PCG, 2012, pp. 10:1–10:6.
[6] J.-R. Falleri, F. Morandat, X. Blanc, M. Martinez, and
M. Montperrus, “Fine-grained and accurate source codedifferencing,” in ASE, 2014, pp. 313–324.
[7] G. Fischer, “Cognitive view of reuse and redesign,” IEEE
Softw., vol. 4, no. 4, pp. 60–72.
[8] G. Fischer, A. C. Lemke, T. W . Mastaglio, and A. I.
Mørch, “Using critics to empower users,” in CHI, 1990,
pp. 337–347.[9] M. Grechanik, C. Fu, Q. Xie, C. McMillan, D. Poshy-
vanyk, and C. Cumby, “A search engine for ﬁnding highlyrelevant applications,” in ICSE, 2010, pp. 475–484.
[10] R. Hoffmann, J. Fogarty, and D. S. Weld, “Assieme:
ﬁnding and leveraging implicit references in a web searchinterface for programmers,” in UIST, 2007, pp. 13–22.
[11] R. Holmes and G. C. Murphy, “Using structural context
to recommend source code examples,” in ICSE, 2005, pp.
117–125.
[12] D. Hou and D. Pletcher, “An evaluation of the strategies
of sorting, ﬁltering, and grouping api methods for codecompletion,” in ICSM, 2011, pp. 233–242.
[13] A. J. Ko and B. A. Myers, “Debugging reinvented:
Asking and answering why and why not questions aboutprogram behavior,” in ICSE, 2008, pp. 301–310.
[14] A. J. Ko and Y . Riche, “The role of conceptual knowledge
in API usability,” in VL/HCC, 2011, pp. 173–176.
[15] A. J. Ko, B. A. Myers, and H. H. Aung, “Six learning
barriers in end-user programming systems,” in VL/HCC,
2004, pp. 199–206.
[16] T. Lazar and I. Bratko, “Data-driven program synthesis
for hint generation in programming tutors,” in ITS, 2014,
pp. 306–311.
[17] R. Lencevicius, U. H ¨olzle, and A. K. Singh, “Dynamic
query-based debugging of object-oriented programs,” Au-
tomated Software Engg., vol. 10, no. 1, pp. 39–74.
[18] A. Mitrovic, “An intelligent sql tutor on the web,” Int. J.
Artif. Intell. Ed., vol. 13, no. 2-4, pp. 173–197.
[19] I. Neamtiu, J. S. Foster, and M. Hicks, “Understanding
source code evolution using abstract syntax tree match-ing,” SIGSOFT Softw. Eng. Notes, vol. 30, no. 4, pp. 1–5.
[20] L. P . Cordella, P . Foggia, C. Sansone, and M. V ento,
“A (sub)graph isomorphism algorithm for matching largegraphs,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 26,
no. 10, pp. 1367–1372.
[21] J. Pane and B. Myers, “Usability issues in the design
of novice programming systems,” School of ComputerScience, Carnegie Mellon University, Pittsburgh, P A,Tech. Rep. CMU-CS-96-132, August 1996.
[22] D. F. Redmiles, “Reducing the variability of program-
mers’ performance through explained examples,” in CHI,
1993, pp. 67–73.
[23] K. Rivers and K. Koedinger, “Automating hint generationwith solution space path construction,” in ITS, 2014, pp.
329–339.
[24] M. Robillard, R. Walker, and T. Zimmermann, “Recom-
mendation systems for software engineering,” IEEE Soft.,
vol. 27, no. 4, pp. 80–86.
[25] C. R. Rupakheti and D. Hou, “CriticAL: A Critic for
APIs and Libraries,” in ICPC, 2012, pp. 241–243.
[26] D. Shasha and K. Zhang, Pattern Matching in Strings,
Trees and Arrays. Oxford University Press, 1995, ch. 14.
[27] R. Singh, S. Gulwani, and A. Solar-Lezama, “Automated
feedback generation for introductory programming as-signments,” in PLDI, 2013, pp. 15–26.
[28] K.-C. Tai, “The tree-to-tree correction problem,” J. ACM ,
vol. 26, no. 3, pp. 422–433.
[29] R. V all ´ee-Rai, P . Co, E. Gagnon, L. Hendren, P . Lam,
and V . Sundaresan, “Soot-aJ a v aBytecode OptimizationFramework,” in CASCON, 1999, pp. 125–135.
[30] L. A. Zager and G. C. V erghese, “Graph similarity scor-
ing and matching,” Applied Mathematics Letters , vol. 21,
no. 1, pp. 86–94.
288