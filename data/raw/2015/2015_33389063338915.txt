Together Strong:CooperativeAndroid AppAnalysis
Felix Pauck
PaderbornUniversity
Paderborn,Germany
fpauck@mail.uni-paderborn.deHeikeWehrheim
PaderbornUniversity
Paderborn,Germany
wehrheim@uni-paderborn.de
ABSTRACT
Recent years have seen the development of numerous tools for
the analysis of taint flows in Android apps. Taint analyses aim
at detecting data leaks, accidentally or by purpose programmed
intoapps.Often,suchtoolsspecializeinthetreatmentofspecific
featuresimpedingprecisetaintanalysis(likereflectionorinter-app
communication).Thismultitudeoftools,theirspecificapplicability
andtheirvariouscombinationoptionscomplicatetheselectionofa
tool (or multiple tools) when faced with an analysis instance, even
forknowledgeableusers,andhencehindersthesuccessfuladoption
oftaint analyses.
Inthiswork,wethuspresent CoDiDroid ,aframeworkfor co-
operative Android app analysis. CoDiDroid (1) allows users to ask
questionsaboutflowsinappsinvaryingdegreesofdetail,(2)au-
tomatically generates subtasks for answering such questions, (3)
distributes tasks onto analysis tools (currently DroidRA ,Flow-
Droid,HornDroid ,IC3and two novel tools) and (4) at the end
mergestoolanswersonsubtasksintoanoverallanswer.Thereby,
usersarefreedfromhavingtolearnabouttheuseandfunctionality
of all these tools while still being able to leverage their capabilities.
Moreover, we experimentallyshow that cooperation amongtools
pays off withrespectto effectiveness,precision andscalability.
CCS CONCEPTS
·Software and its engineering →Software verification and
validation ;Domainspecificlanguages .
KEYWORDS
Android Taint Analysis,Tools,Cooperation, Precision.
ACMReference Format:
Felix Pauck and Heike Wehrheim. 2019. Together Strong: Cooperative An-
droid App Analysis. In Proceedings of the 27th ACM Joint European Software
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEn-
gineering (ESEC/FSE ’19), August 26ś30, 2019, Tallinn, Estonia. ACM, New
York, NY, USA, 11pages.https://doi.org/10.1145/3338906.3338915
1 INTRODUCTION
Inthefieldofsoftwareanalysis,anongoingracebetweenattackers
anddefendersistakingplace.Thespeedofthisraceisconstantly
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrights forcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ’19, August 26ś30,2019, Tallinn,Estonia
©2019 Copyright heldby the owner/author(s). Publicationrightslicensed to ACM.
ACM ISBN 978-1-4503-5572-8/19/08...$15.00
https://doi.org/10.1145/3338906.3338915increasing on both sides. Attackers find new ways to hide their
maliciousbehaviorwhiledefendersdevelopmoreandbetterana-
lyses to detect attacks. However, the user ś unwillingly being a
third party in this race ś typically cannot sufficiently benefit from
theadvancesofthedefendersandthuscannotcatchup.Reasons
for this are various, including the missing knowledge about the
existenceofup-to-datetools,theirusageandwaysofcombining
them,the unavailability of toolsorof resourcesto run tools.
This exactly characterizes the present situation in the area of
analyses for data leaks in Android apps. Dataleaks permit the leak-
age of private data in smartphones (like contact data or ś more
critical ś banking or health data) to the outside. Conceptually, a
data leak is a flow of data from a private sourceto a public sink.
Dataleaksmightariseoutofaccidentalcodingmistakes,butmight
alsobeintentionallyplacedinappsbymaliciousattackers.Inthe
past,researchershavecomeupwithvarioustechniquesandtools
forleakdetection,rangingfromstatic[ 2,8,12,15,18,20,22,27,31]
over dynamic [ 14,32] and hybrid [ 1] analyses to methods built
onlogicalreasoning[ 9].Toolsfurthermoreoften specializetocer-
tainprogramming features in apps which complicatetheanalysis
(e.g.reflection[ 7,23],inter-appcommunication[ 24,33]).Moreover,
suchtoolsrequirevaryingamountsofresources(computationtime,
powerandmemory)śoftenexceedinganormaluser’scapacities
ś, different operating systems and/or require specialized additional
software or hardware. Hence, it is only the absolute expert who
can fully leveragethe plethoraof existing tools.
In this paper, we thus propose CoDiDroid , a framework for
automatic cooperative (and distributed) An droidapp analysis. For
agiven(setof)app(s)andagivenanalysisquestion, CoDiDroid
automatically divides the analysis task into several subtasks, dis-
tributessubtasksontotools,dispatchesthemandattheendmerges
toolanswersintoafinalanswertotheinitialquestion.Aslanguage
for formulating questions and for interfacing between different
tools, we employ the domain-specific language AQL(Android App
Analysis Query Language) [ 28,37]. We extendthe AQLinseveral
ways,inparticulartoenablenovelcombinationsoftools.Forthe
unexperienceduser, CoDiDroid forinstanceoffersthiscooperative
analysis on a website with a default analysis question; for a user
knowledgeable in AQL,CoDiDroid allows to specify the selection
oftoolsandsubtasksinvaryingdegrees of detail.
The power of CoDiDroid lays in the principle of cooperation :
While previous approaches only use very limited, hardcoded forms
of tool combinations, CoDiDroid can in principle compose arbi-
trarytoolsextractinginformationaboutflowsinapps.Thisflexi-
bility in the combination allows for an easy integration of a new
tool, upgrade to new tool versions or exchange of tools. Cooper-
ativeappanalysisfurthermorecannotonlybeemployedto solve
an analysis question, but also to crosscheck the correctness of an
analysisanswer ofone toolbyanother.
374
ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia F. PauckandH.Wehrheim
While a number of basic building blocks for a cooperative anal-
ysis already exist, we also identified gaps where tools are either
lacking,donotexistasblackboxstandalonetoolsoronlycompute
(too) imprecise information. As a further contribution of this work
we have closed two such gaps. The first development concerns the
implementation of a new tool for the inference of inter-component
communication links ( ICC links) calledPIM.PIMprecisely com-
putes links between intent-sinks and intent-sources as collected by
IC3 [25] or Epicc [ 26], and thereby contributes to a rigorous analy-
sisofinter-componentcommunication.Oursecondcontribution
isNOAHfor the analysis of calls to native libraries (via the Java
NativeInterface)inapps.Currenttoolstypicallyignorenativecalls
whileNOAHalsoidentifies sourcesandsinks innative methods.
Wehavecarriedoutanumberofexperimentsonthestandard
benchmark DroidBench [2] (plus additional inter-app commu-
nication cases) to test the feasibility, precision and scalability of
CoDiDroid . The experiments show that cooperative analysis is
effective in that it can (a) increase the precision, (b) have lower
runtimes than other approaches, (c) increase the scalability and (d)
enable the detection ofpreviously undetectable data leaks.
Tosummarize,this paper makesthe following contributions:
•Weproposethenovelframework CoDiDroid forcoopera-
tive Android app analysis,
•we develop and implement a technique for the automated
distributionanddispatch ofanalysistasks,
•we design and implementtwo new analysis tools ( PIMand
NOAH) readilyusable within CoDiDroid ,
•weprovideassociatednewbenchmarkcasesforinter-app
communicationscenarios,and
•weshowtheeffectivenessandefficiencyof CoDiDroid in
large-scale experiments.
Thepaperisstructuredasfollows.Thenextsectionintroducesfoun-
dationsoftaintanalyses,toolsandtheanalysisquerylanguage AQL.
Section3presentsthegeneralapproachofcooperativeAndroidapp
analysis.InSections 4and5wepresentourexperimentalstudies
anddiscusstheirresults.RelatedworkispresentedinSection 6and
Section7finally concludes.
2 FOUNDATIONS
In this section we start by explaining basic concepts, present the
toolswhicharecurrentlypartof CoDiDroid anddiscussthedomain-
specific query language AQL.
2.1 Taint Analyses
ThedetectionofdataleaksinAndroidappsispredominantlycar-
ried out by taint analyses . Taint analyses track information from
sources to sinks by łtaintingž elements (objects, fields, ...) and
tracking their flows through the program. A source in this con-
text is a statement extracting sensitive information (e.g. contact
data, location information, device identifiers). A sink in contrast
is a statement that leaks data to the outside, e.g. via SMS or the
Internet. Information flows between sources and sinks detected by
taintanalysesarecalled taintflows .Someofthesesourcesandsinks
require a permission to be granted by the Android system or the
user.Anypossiblyrequiredpermissionisspecifiedinaso-called
manifest.App: B App: B App: A App: A
invoke(...) →
s = getDeviceId()
(reflective call)invoke(...) →
s = getDeviceId()
(reflective call)
startActivity(...)startActivity(...)
getStringExtra()getStringExtra()
Log.i(.., s) Log.i(.., s)getIntent()getIntent()
cFuncSMS( s)
(native call)cFuncSMS( s)
(native call)
sendTextMessage(.., s, ..) sendTextMessage(.., s, ..)
setResult(...)setResult(...)1s1
2
73
4 5s2
s3
s4s5
s6
s7
s86Native libraryonCreate(..) onActivityResult(..)onCreate(..)
Figure 1:Runningexample: Flowsin2 apps
Inordertosuccessfullydetecttaintflows,anumberofchallenges
havetobemasteredbyananalysistool,someofwhicharegiven
below.
Sensitivities A tainted element might be a whole object or
justafield.Anyflowaccessingataintedelementmightbe
constrainedbyitsowncontextandorcertainconditions.Ide-
ally,theseand similaraspectsshouldbe takeninto account.
Precise taint analyses should at the best be flow, context,
field, object,pathandthread sensitive.
Native calls The apps might contain calls to native libraries
viatheJavaNativeInterface(JNI).Whentheanalysisdoes
not inspectlibrary code,itmightmiss flows.
Inter-componentcommunication Androidemploysaspe-
cific concept of inter-component and inter-app communi-
cation(ICC/IAC).Thiscommunicationisrealizedthrough
intents: apps can send intents which are received by other
appswhentheymatchthereceiver’spredefinedintent-filters.
A precise analysis has to track flows via intents, and in par-
ticularneedstobeabletodetectmatchingpairsofintents
andintent-filters.
Reflection AttackersmightusetheJavareflectionmechanism
tohidee.g.accessestosources.Theanalysishastobeable
to resolve reflective calls.
A further challenge is efficiency. To decrease runtime and memory
consumption, (static) analysis tools often compute over-approxi-
mationsoftaintflows,resultinginalargenumberoffalsepositives.
Figure1introduces our running example of two apps exhibiting
severaloftheabovelistedchallenges.Thefiguredepictsthetaint
flows an analysis tool should be able to detect. App A in statement
s1containsa use of reflection extracting data froma private source
(thedeviceid).Thistaintedvalueisflowingtostatement s2(flow1).
Ins2,appAsendsoutanintenttheresultofwhichiscollectedin s3.
Thisresultflowsintothesinkintheloggingstatementin s4(flow
7).Theintentmatchestheintent-filterofappB(flows2and6)in
whichthedatatransferredviatheintentflowsintobothstatements
s8ands6(flows 5 and 3). Finally, the library code for the native
call in statement s6contains the sink sendTextMessage(...) and
hence introduces flow 4. The two expected taint flows hidden in
therunningexamplethusstartin getDeviceId() (s1)andendin
sendTextMessage(...) (s7)andinLog.i(...) (s4),respectively.
375TogetherStrong: Cooperative Android App Analysis ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
Currently, no publicly available Android app analysis tool alone is
ableto detectboth flows.
2.2 Analysis Tools
TheobjectiveofourworkistoincreasetheeffectivenessofAndroid
app analysis by cooperation. As we will see later, a cooperative
analysisoftheexampleinFigure 1candetectbothflows.Tothis
end, our framework CoDiDroid employs a number of existing
tools which we briefly describe in the following. The choice of
tools isguided by our overall objective ofcooperation: we require
tools which provide basic building blocks of a complex analysis
and which can be flexibly combined. Furthermore our choice is
driven by recent studies, e.g. [ 29,30], which give insight into a
tool’s performance.
•DroidRA [23] is a tool for resolving reflection. To do so,
it identifies the signature of classes and methods that are
instantiated or called through reflection via a static constant
propagation analysis .
•FlowDroid [2]isatoolforthedetectionofintra-component
taint flows1. It considers real sources and sinks as well as
intent-sources and -sinks. The identification of sinks and
sourcesisfollowedbya statictaint analysis.
•HornDroid [9] is a static analyzer based on logical rea-
soning.ItusesHornclausestodecidewhichsinksareable
to leak sensitive data. Due to the use of logic, it is able to
distinguishdefinitefrom only potentialleaks.
•IC3is a tool for detecting intent-sinks and -sources via a
staticconstantpropagationanalysis .Ithasbeendevelopedby
Octeauetal.[ 25]andupdatedbyusinordertoworkwith
up-to-date Android APIs2. It computes precise attribute-sets
containing informationabouttheaction, categoryanddata
of intents and intent-filters and maps each of them to a
statement.
Toenableaflexiblecombinationoftoolsinataintanalysis,we
are lackinga standalonetoolfor (a)theidentification ofsinks and
sources in native code, and (b) the precise matching of intents
withintent-filters,i.e.thecomparisonofattributesetsascomputed
byIC3. Our first contribution towards cooperative Android app
analysisisthus the developmentoftwonewtools.
•NOAH(Native Over-Approximation Handler) is a tool for
thedetectionofAndroidsourcesorsinkscalled internally ,
i.e. within code of a native library. With this information
inplaceitcandetectflowsendinginandstartingatnative
methodcalls.
•PIM(PreciseIntentMatcher)isatoolcomputingconnections
betweenintent-sinksand-sourcesbycomparingthemapped
attribute-setsasdeliveredby IC3.Todoso,itusesanAndroid
device or virtual device (emulator) and asks the Android
system installed if a certain pair of intent and intent-filter
fits.Itthus performs a dynamicanalysis.
1Theup-to-dateversion2.7.1of FlowDroid alsoincoporatesinter-appflows,but
for the purpose of cooperativeanalysis wepreferthe baseversion.
2Additionally,wereportedthisissueongithub( https://github.com/siis/ic3/issues/
28).2.3 Android App Analysis QueryLanguage
To realize our CoDiDroid framework, we use the domain-specific
language Android AppAnalysis Query Language (AQL), developed
andmaintainedbyus[ 28,37].Thislanguageallowsustoformu-
late queries ( AQL-Queries) composed of questions ( AQL-Questions ).
Results to such queries are given in the form of AQL-Answers.AQL
isused inthecommunicationwith theuseraswell asforcommu-
nicationbetween toolsandour framework CoDiDroid .
AnAQL-Question mainly consists of two parts, the property of
interest (<poi>) and the target ( <target> ). With these two basic
elementswecanformulatequeriestoaskfore.g.flows,permissions,
intents or intent-filters inside a whole app or parts of it such as
a certain class, method or statement. An unknowledgeable user
mightalwayswanttousestandardqueries,liketheonebelowto
getallflowsinside someapp Astoredinfile A.apk:
<poi>IN<target> ?
/bracehtipdownleft/bracehtipupright/bracehtipupleft/bracehtipdownright
FlowsIN/bracehtipdownleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipupright/bracehtipupleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipdownright
App(’A.apk’) ?
orto getallflowsfrom AtoB:
FlowsFROMApp(’A.apk’) TOApp(’B.apk’) ?
A more knowledgeableusermightask for more details,like
Permissions IN
Method(’onCreate(...)’) ->App(’A.apk’) ?
tofindallpermissionsrequiredbyastatementinside onCreate(..) .
Considering the running example this would return the permis-
sionsREAD_PHONE_STATE required by getDeviceId() inside the
onCreate(...) method.
TheAQLalso allows to further process the answers given to
certainquestions. Tothis end, a number of operations onqueries
(or rather, their answers) are already available (and can further
be extended via configuration). Note that ś conceptually ś ans-
wersaresetsofdataaboutflows,permissions,intents,intent-filters,
intent-sinksandintent-sources.
•TheUNIFY-operator can be used to merge multiple answers
intoasingleonebyapplyingaunionoperatorontheanswer
sets.In doing so,itimplicitly removes redundant elements.
•TheFILTER-operatorisusedtoextractspecificdatafroman
answer set.
•TheCONNECT-operatorfirstapplies UNIFYandthencomputes
aclosureon the data, i.e. constructs the transitive closure of
flows and connects intent-sinks with -sources using some
simpleICClinkcomputation.
•TheMATCH-operator is amore sophisticated version of CON-
NECT, currently implemented using PIMfor accurate ICC
linkcomputation.
•Finally,the CHECK-operatorcanbeusedtohaveanothertool
crosscheckan answer to aquery.
Inaddition,the AQLembodiesfacilitiesfor (1)specifyingthepre-
processing ofapp code
FlowsINApp(’A.apk’ |’DEOBFUSCATE’) ?,
(2) selecting certaintoolswhen specific features are given
FlowsINApp(’A.apk’) FEATURING ’NATIVE’ ?,
or(3) using particulartoolsto answer aquery
FlowsINApp(’A.apk’) USING’NOAH’?.
376ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia F. PauckandH.Wehrheim
<answer>
<flows>
<flow>
<reference type="from">
<statement> getDeviceId () </statement>
<method>onCreate(...)</method>
<classname>MainActivity</classname>
<app>
<file>.../AppA.apk</file>
<hashes>...</hashes>
</app>
</reference>
<reference type="to">
<statement> sendTextMessage (...)</statement>
<app>.../AppB.apk</app>
</reference>
</flow>
<flow>
<reference type="from"> getDeviceId () </reference>
<reference type="to"> i(...) </reference>
</flow>
</flows>
<intentsinks>
<intentsink>
<target>
<action>...codidroid.codirunex.SMS</action>
</target>
<reference type="from">
startActivityForResult (...)
</reference>
</intentsink>
</intentsinks>
<intentsources>
<intentsource>
<target>
<action>...codidroid.codirunex.SMS</action>
<category>android.intent.category.DEFAULT</category>
</target>
<reference type="to"> getIntent () </reference>
</intentsource>
</intentsources>
</answer>
Listing 1:Shortened AQL-Answerfortherunningexample
Technically, AQL-Answers are encoded inXML format. The spe-
cificstructureisdeterminedbyanXMLSchemadefinition(XSD)
file[28,37].Ananswercanholdinformationaboutalltypesofprop-
ertiesofinterest.Asanexample,Listing 1showsthetwotaint-flows
containedinsideourrunningexampleaswellastheintent-sinkand
intent-source required to be able to find both flows. The first refer-
ence to thereflectivelycalled getDeviceId() statementisalmost
fully given. For all other references that are mentioned we reduced
theamountofinformationprovidedtoincreasereadability.Thede-
notedintent-sinkand-sourcebothcomewithoneactionelement.In
bothcasesitcontainstheactionstring codidroid.codirunex.SMS .
The action string is one element that has to match in order to infer
a link between intent-sink and intent-source. Note that the full
answer contains allflowsdepictedinFigure 1.3 APPROACH
TobuildCoDiDroid weconstructedanenvironmentforcooper-
ative analyses that allows us to configure arbitrary networks of
analysis tools. An instance of such a network consists of a number
ofso-called AQL-System sconfiguredtoaccesstoolsrealizingbasic
functionality of app analyses. Any AQL-System in such a network
can befrontendorbackendwhich communicates with other sys-
temsinthenetworkthroughthe AQL.Onceaqueryisprocessedby
a frontend the following procedure is started: i) check which tools
areavailableinthenetworkandwhichqueriescanbeansweredby
them,ii)runalightweightstaticanalysistocomputethe features
(app characteristics) used in the targeted apps, iii) based on this in-
formationsplitthequeryaccordingtotheconfigured strategies,and
iv)decide whichtool ortoolcombinationhasthehighestpriority
to answer eachpart ofthe dividedquery.
In order to execute these four steps every system needs to be
configured.Aconfigurationfixes(1)thesetofavailabletoolsand
their functionality (i.e., ability to answer queries and priority for
certain features), (2) technical information about running tools,
(3)convertersto AQLfromtooloutputs,and(4)theconfigurable
strategies.Hence,toaddaneworupdatedtooltothewholenetwork
only two adaptions need to take place considering (2) and (3): Add
therequired technicalinformationto theassociated configuration
filesandprovideamatching converter3.
TheAQL-System swhichcanbeusedin CoDiDroid comeindif-
ferentforms:
AQL-System [ 37]is simply the system itself accessible via
command line or agraphical userinterface.Itis alsousable
as alibrary inotherapplicationssuch as the following.
AQL-WebServices[ 38]wrapanAQL-System intoawebser-
vice lifting its availability from local to network level. These
webservicescanbeaccessedbyother AQL-System sofany
kind.
AQL-Online[ 36]is a website implementation representing
an onlineuserinterfacefor arbitrary AQL-WebService s.
BREW[39]is an automatic benchmarking system using an
AQL-System to analyze apps inbenchmarksets.
The up-to-date CoDiDroid instance of such an AQL-System
network is depicted in Figure 2. It is split into one frontend system
(1.) and two backends (here, 2.and3.). All backends run AQL-
WebService s. The frontend distributes the analysis tasks onto the
backends and to this end knows which queries they can process.
Backend 2.runsallstaticanalysistoolsinavirtualmachineunder
Linux. The otherbackendruns all dynamicanalyses,inparticular
the toolPIMonan Android device oremulator.
AQL-System sstorealltheanalysisqueriestheyprocesstogether
with the obtained answers. This allows for a re-useof answers and
can significantly speed-upanalysisfor latercases.
The key ingredients of AQL-System s enabling cooperation are
strategies fordividinganalysistasksintosubtasks,orśwhenviewed
on the level of AQLś for splitting queries into questions and opera-
tors.
3Optionstoadd converters can befoundin the followingtutorial: https://github.
com/FoelliX/AQL-System/wiki/Add_tools (Theaveragesizeofallavailableconverters
isabout 150LOC)
377TogetherStrong: Cooperative Android App Analysis ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
l2.lBackend
AQL-Webservice
Config
l1.lFrontend
BREW,
AQL-Online, 
AQL-System
Config
l3.lBackend
AQL-Webservice
ConfigToolsDroidRA , FlowDroid,
HornDroid, IC3, NOAH PIM
Figure 2:Structure of CoDiDroid
Strategy I: Inter-Component and Inter-App Communication. This
strategy is employed whenever the AQL-System detects that more
thanone componentorappisinvolved.Thesubtaskstobegener-
ated then concern (a) the detection of intra-component taint flows
ineveryinvolvedcomponent,(b)thecollectionofintentsources
andsinksinthesecomponents,and(c)thematchingofintent-sinks
and -sources and ś with this at hand ś the computation of closures
offlows.
For an example, suppose that the query involves apps A.apk
andB.apk.TheAQL-System thenconstructsthefollowingmore
detailedquery specifying the subtasks.
MATCH [
FlowsINApp(’A.apk’) ?,
FlowsINApp(’B.apk’) ?,
IntentSources INApp(’A.apk’) ?,
IntentSinks INApp(’A.apk’) ?,
IntentSources INApp(’B.apk’) ?,
IntentSinks INApp(’B.apk’) ?
]
Depending on the configuration, the AQL-System afterwards
selects tools being able to answer the questions contained in the
query and runs them. Similarly, it chooses a tool for the AQL-
Operator MATCH. The current configuration of our AQL-System s
employsFlowDroid for the first two questions, IC3for the last
fourandPIMfor the matching operator.
Strategy II: Reflection. Strategy II is employed when the apps in-
volvedinthequeryusereflection,i.e.theparsingofthe .apk-file
detectstheuseof invoke(or similarmethods).In thiscase, every
question about intra-component flows in an app A.apkis replaced
by
FlowsINApp(’A.apk’ |’DEOBFUSCATE’) ?
The keyword DEOBFUSCATE next to the path identifying the app
specifies that the app needs to be preprocessed before the analysis.
The current configuration maps this preprocessing task to the tool
DroidRA .Strategy III: Native Code. Strategy III is applied when the app(s)
containcalls tonative methodsviathe JNIinterface.Inthiscase,
theanalysishastoinspectthecodeofthenativemethodsaswell.
Twosubtaskshavetobedoneforthis:(a)itneedstobedetected
whether the native call can be considered to be a source or sink (so
that the intra-app taint analysis can take this into account), and
(b)thetaintflowsinsidethenativemethodneedtobecomputed.
Every questionaboutintra-app flowsisthus replacedby
CONNECT [
FlowsINApp(’A.apk’ |’UNCOVER’) ?,
FlowsINApp(’A.apk’ |’UNCOVER’)
FEATURING ’NATIVE’ ?
]
Here,thekeyword UNCOVERstandsforaspecificpreprocessorde-
riving additional sources and sinks. The second question explicitly
specifiestheflowanalysistobedonebyatoolcapableofanalyzing
native methods. Finally, the CONNECToperator unites the two an-
swersandcomputestheclosure.Notethatwedonotrequire MATCH
here since this isan intra-componentanalysis.
Ourcurrentconfigurationselects NOAHbothforthe UNCOVER
preprocessingandthesecondquestion.Thefirstquestion(afterpre-
processing)isdelegatedto FlowDroid andtheCONNECT operator’s
defaultimplementationishardcodedinthe AQL-System .
WheneverwedetectthenecessityofusingstrategyIIorIII,thepre-
processing step(like UNCOVER orDEOBFUSCATE ) needs to be added
to allquestionsaboutthis app.
Strategy IV:FalsePositives. Strategy IV isonlyemployedwhen a
high level of precision is required, i.e., when the analysis should
not deliver so many false positives. As taint analysis tools typically
computeoverapproximationsoftaintflows,thiscanbeachieved
byhavingasecondtoolcrosschecktheresultsofthefirst.Incase
that the second tool cannot confirm flows of the first, these are
discarded.
Forthequeries,wecurrentlyhavetoexplicitlyspecifythecross-
checkingtool(tooverridetheconfigurationspecifyingprioritiesof
toolsforcertainquestionsandfeatures).Asanexample,consider
the following query crosschecking computed intra-app taint flows.
CHECK [
FlowsINApp(’A.apk’) ?,
FlowsINApp(’A.apk’) USING’HornDroid’ ?
]
TheCHECKoperator takes the answer of the first question and
checks whether the taint flows in there also occur in the second
answer. For this, it is enough when only parts of a taint flow are
foundinthe secondanswer.
In the example query, CoDiDroid makes use of HornDroid to
compute the second answer. Since HornDroid itself is not able
to compute complete taint flows but identifies leaking sinks with
high accuracy, it is a perfect candidate for this purpose. Hence,
CoDiDroid is able to combine completely orthogonal approaches
as to getthe bestofallworlds.
Except for strategy IV, all strategies are standardly employed in
a cooperative analysis. For our running example of Figure 1, the
query
FlowsFROMApp(’A.apk’) TOApp(’B.apk’) ?
thus getsdividedinto
378ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia F. PauckandH.Wehrheim
Table 1:Tools used in CoDiDroid
Tool Date(Version/Commit ID)
DroidRA [45]April 2017 (b766a32)
FlowDroid [47]April 2017 (Nightly)*
January 2019 (2.7.1)
HornDroid [48]October 2018 (cd52ba4)
IC3[49] March2018 (196d68b)
NOAH[51] February 2019 (tba)
PIM[52] February 2019 (tba)
Amandroid [34]November 2017 (3.1.2)
DIALDroid [41]April 2017 (5df5734)
DidFail [43] March2015 (latest)
DroidSafe [46]June 2016 (final)
IccTA[50] February 2016 (831afaa)
ApkCombiner [35]March2018 (196d68b)
* used forcomparabilityin RQ1.
MATCH [
FlowsINApp(’A.apk’ |’DEOBFUSCATE’) ?,
CONNECT [
FlowsINApp(’B.apk’ |’UNCOVER’) ?,
FlowsINApp(’B.apk’ |’UNCOVER’)
FEATURING ’NATIVE’ ?
],
IntentSources INApp(’A.apk’ |’DEOBFUSCATE’) ?,
IntentSinks INApp(’A.apk’ |’DEOBFUSCATE’) ?,
IntentSources INApp(’B.apk’ |’UNCOVER’) ?,
IntentSinks INApp(’B.apk’ |’UNCOVER’) ?
]
CoDiDroid automatically distributes the subtasks onto the two
backends. At the end, the analysis returns the two taint flows from
getDeviceId() tosendTextMessage(...) andgetDeviceId()
toLog.i(...) . None of the existing (publicly available) taint anal-
ysistoolsisableto compute both flows.
4 EXPERIMENTDESIGN
ToevaluateourapproachforcooperativeAndroidappanalysis,we
carried out a number of experiments. Our first question concerned
thefeasibility of cooperativeanalysis, inparticular the possibility
of usingCoDiDroid as a black box which automatically generates
and distributes analysis tasks as well as executes them. To this end,
we implemented our approach and employed it in the experiments
detailed below. With this, the general feasibility of the approach
is demonstrated. The implementation as well as all experiment
resources and in particular the results are publicly available4. The
followingresearchquestionstarget more specializedpropertiesof
the approach thanplainfeasibility.
4.1 Research QuestionsandExperiments
Besides feasibility, we were interested in the following research
questions.
RQ1Howdoes CoDiDroid comparetootheranalysisapproaches
withrespectto precision?
RQ2Howwelldoes(theinter-appanalyisof) CoDiDroid scale
to higher numbers ofapps?
4https://FoelliX.github.io/CoDiDroid [40]RQ3Howwelldoes CoDiDroid scaletolarger(real-world)apps?
Anotheraspectofevaluationcouldhavebeentheexecutiontime
of analysis tools. Distributing the execution of analysis tools to
variousmachinesallowsuserstoaccessresourcesthat,forexample,
mayneverbecomeavailablelocally.Thereby,analysistimebecomes
less dependent on the locally available resources. Furthermore, our
frameworkallowsfortheparallelexecutionofanalysesonsubtasks,
andthusingeneralspeedsupanalysis.Hencewedidnotincludean
explicit research question about runtime. We only inspect runtime
as one aspectofthe firstscalability research question.
Benchmarks. For the experiments, we employed the standard
benchmarks of DroidBench [44] (version 3.0) plus some recent
extensions developed in [ 29].DroidBench partitions the bench-
marksintocategories(accordingtospecificfeaturesoccurringin
the apps). Each benchmark case can furthermore contain one or
moreapps,andeachappcanhaveoneormorecomponentswith
onestartingapp.ForRQ2wefurthermorecreatedtwoadditional
benchmarks scenarios (see below), for RQ3 we employed bench-
marksfrom DIALDroid-Bench [42]. Finally,weconstructedtwo
apps exhibiting the flowsof our running example inFigure 1.
Tools.For the comparison withotherapproaches, we employed
some of the tools which are already part of CoDiDroid , but this
timeasstandalonetools.Inaddition,weusedthestate-of-the-art
toolsApkCombiner [21] (merging two or more apps into one),
IccTA[22],DIALDroid [8],DidFail[20] (all three are different
combinationsof FlowDroid andIC3),Amandroid [31],andDroid-
Safe[18].Thesetoolshavebeenpartofthereproducibilitystudy
of [29] which allows us to directly use the study’s F-measure re-
sults, and the tools are furthermore all available for own additional
experiments.Forthese,weemployedthetoolsintheversionslisted
inTable1.
Benchmarking. Thebenchmarkingitselfiscarriedoutwith Brew,
usinganAQL-System toruntools. Brewgeneratesaninitialquery
byinspectingtheappsinthebenchmarkcase:incaseofasingle
app,the query is
FlowsINApp(’A.apk’) ?
incaseoftwoormoreapps, Brewgeneratesthefollowingquery
foreverypair ofapps(directiondependingonthesources ofthe
starting app andsinks):
FlowsFROMApp(’A.apk’) TOApp(’B.apk’) ?
Whileourownapproach CoDiDroid splitsupthesequeries,the
other tools only get the overall query converted to their input
formatsandthenruntheiranalysis.Attheend, Brewcollectsall
answers.
ForRQ1,weranCoDiDroid ontheextended DroidBench bench-
markandcalculatedtheF-measurescores.Duetotheexistingrepro-
ducibilitystudyon exactlythisbenchmark set, there wasnoneed
to recompute the F-measures of other tools. We simply used the
results of the study. For evaluation of our new tool PIMfor precise
intentmatching,weusedthe224benchmarkcasesoftheextension
ofDroidBench in [29]. They just contain inter-component flows
andhence can be specifically usedfor evaluating intentmatching.
ForRQ2, we were interested in the scalability of CoDiDroid
for benchmark cases requiring inter-app analysis. Furthermore,
379TogetherStrong: Cooperative Android App Analysis ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
1
432
1
432a) Star b) Ring
Figure 3:Star & RingBenchmarkScenarios
we wanted to compare CoDiDroid with approaches specifically
designed to support inter-component analysis ( Amandroid and
IccTA).IccTAisbasedon FlowDroid andusesIC3toliftupFlow-
Droid’s analysis to inter-component level. Nevertheless, since it is
based on FlowDroid it can only analyze one app at a time. In con-
sequence, before analyzing multiple apps, these have to be merged.
Typically,thetool ApkCombiner isusedforthispurpose.Similarly,
when running Amandroid we needed to preprocess the apps with
ApkCombiner . Thus, both Amandroid andIccTArequire the use
ofApkCombiner to reachinter-app level.
As benchmarks for this research question, we used the category
łInterAppCommunicationžof DroidBench .Sincethecasesinthere
onlyinvolvetwoappseach,wefurthermoreconstructedadditional
benchmarks. Figure 3a and3b, respectively, depict the flows in
theStarandRingbenchmarks. We varythe number ofapps parti-
cipating in a Ring (3 or 4) and a Star (3, 4, 5, 6 or 10). Note that
the analysis should also return flows arising from the transitive
closure of links, like from (a source in) app 1 to (a sink in) app 3 in
caseofRing.Werantwoversionsofthe experiments:(1)running
Ring(n+1)andStar(n+1)aftertheanalysesforRing (n)andStar(n),
respectively, to evaluate whether the re-use feature of CoDiDroid
actuallypaysoff,and(2)runningthem withoutprioranalysesofthe
n-appversions.ThisfirstideaisdepictedbythescissorsinFigure 3.
ForRQ3,wewantedtoevaluatethescalabilityof CoDiDroid
to large, real-world apps. When dealing with real-world apps ex-
periments become more difficult, mainly because of missing in-
formationaboutthegroundtruth.Inotherstudies,thecorpusof
evaluation often consists of the 10 to 1.000 most downloaded, best
rated apps on Google’s PlayStore5. Based on this corpus, either
the sole number of findings (taint flows) is reported or tools are
compared based on the number of findings. However, neither is
the expected number of finding known nor the exact flows belong-
ing to these findings. Moreover, most often neither the concrete
apps having been analyzed nor the detected flows are being stored
somewhere for replication.
To put our experiments on more solid grounds, the DIALDroid-
Bench[42]benchmarkisemployedtoanswerRQ3.Itcomprises
30realworldappsforwhichpartsofthegroundtruthhavebeen
specifiedin[ 29].Wedetailedlyinspectthetypeofflowsfoundby
CoDiDroid in these 30 apps as to see whether cooperation pays
off to find flows deeply hidden in real-world apps by means of
e.g.reflection ornative code.
5https://play.google.comTable 2:F-Measure Scores
IDCategory
FlowDroidBestCoDiDroidDifference toBestDifference toFlowDroid1Aliasing 0.667 0.667 0.667 0.000 0.000
2AndroidSpecific 0.900 0.900 0.900 0.000 0.000
3ArraysAndLists 0.615 0.667 0.615 0.052 0.000
4Callbacks 0.897 0.897 0.897 0.000 0.000
5DynamicLoading 0.000 0.500 0.000 0.500 0.000
6EmulatorDetection 0.966 0.966 0.966 0.000 0.000
7FieldAndObjectSensitivity 1.000 1.000 1.000 0.000 0.000
8GeneralJava 0.810 0.810 0.810 0.000 0.000
9ImplicitFlows 0.000 0.000 0.000 0.000 0.000
10InterAppCommunication 0.000 0.625 0.625 0.000 -0.625
11InterComponentCommunication 0.348 0.750 0.690 0.060-0.342
12Lifecycle 0.769 0.933 0.769 0.164 0.000
13Native 0.000 0.333 0.889 -0.556-0.889
14Reflection 0.095 0.333 0.800 -0.467-0.705
15Reflection_ICC 0.000 0.000 0.000 0.000 0.000
16SelfModification 0.000 0.000 0.000 0.000 0.000
17Threading 1.000 1.000 1.000 0.000 0.000
18UnreachableCode 1.000 1.000 1.000 0.000 0.000
Ø 0.504 0.632 0.646 -0.014-0.142
4.2 Execution Environment
Forourexperimentswesetupthe CoDiDroid frameworkasshown
inFigure 2.AQL-WebService 2.wasexecutedonaDebian(Jessie)
virtualmachinewithJava8(1.8.0_191)installed.Duringthetimeof
ourexperimentsithadtwocoresofanIntel ®Xeon®CPU(E5-2695
v3@2.30GHz)and32GBmemoryassigned.30GBwerededicatedly
usedfor toolexecution.
The second AQL-WebService (3.) was executed on a different
machine,namelyaWindows10laptopwhichhadJava8(1.8.0_181)
installed.Thismachinewasusedforthefrontend( 1.)executionas
well. It is running on an Intel ®Core®CPU (i7-5600U @ 2.60GHz)
and 16 GB memory of which 1 and 6 GB were assigned to the
frontend and backend, respectively. The rest of the memory was
leftfortheoperatingsystemandtheAndroidemulatorusedtorun
PIM.TheemulatedAndroidvirtualdevicewassetuptouseAPI26.
5 EVALUATION RESULTS
Inthissectiontheresultsofourexperimentsaredescribed.Indoing
so,the researchquestionsformulatedabove are answered.
5.1 RQ1: Howdoes CoDiDroid compareto
otheranalysis approacheswith respect to
precision?
Table2showstheresultsofourexperimentscomparingtoolson
theDroidBench benchmarks.Thefirsttwocolumnsidentifythe
category associated with each row. The remaining 5 columns show
F-measure scores for different participants in this experiment. The
columnlabelled FlowDroid containsthescoresachievedby Flow-
Droid(possiblyincombinationwith ApkCombiner tomergeapps
forinter-app benchmarkcases). Weseparatelylist FlowDroid as
it performed best in the reproducibility study of [ 29]. The next
columnshowsthescoreachievedbythetoolperformingbestinthe
reproducibility study in that category . Note that these are different
tools in different categories; there is no single tool performing best
380ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia F. PauckandH.Wehrheim
Table 3:Absolutenumbers offlows( DroidBench 3.0)
Cases FlowDroid Best CoDiDroid
Category Positive Negative Sum TP FP TN FN TP FP TN FN TP FP TN FN
ArraysAndLists 4 6 10 4 5 1 0 4 4 2 0 4 5 1 0
DynamicLoading 3 0 3 0 0 0 3 1 0 0 2 0 0 0 3
Lifecycle 24 0 24 15 0 0 9 20 0 0 4 15 0 0 9
Native 5 0 5 0 0 0 5 1 0 0 4 4001
Reflection 9 0 9 1 0 0 8 4 0 0 5 6003
InterComponentCommunication 19 9 28 4 0 9 15 12 1 8 7 1009 9
InterAppCommunication 11 0 11 0 0 0 11 5 0 0 6 5006
Sum 75 15 90 24 5 10 51 47 5 10 28 44 5 10 31
DroidBench 3.0 (allcategories) 163 41 204 58 2 24 30 81 2 24 7 78 2 24 10
in all categories. For having CoDiDroid select the best tool, we
would need to tie its tool selection to category. Beside in bench-
marks,suchastrictcategorizationofappsis,however,notpossible
since apps can belong to several such categories.
The last two columns show the difference between CoDiDroid
and the best tool per category and between CoDiDroid andFlow-
Droid.Negativevaluesshowthat CoDiDroid scoredbetterthan
the object of comparison. Those values are highlighted with green
background.The darker thebackground is, the largeristhediffer-
ence. The analogous color scheme is used for the positive numbers
highlightedinred.
We see that on average CoDiDroid outperforms both Flow-
Droidas well as the hypothetical łbestž tool (not existing as a
single tool). Compared to FlowDroid ,CoDiDroid is14%more
preciseaccordingtothecomputedF-measurevalues.Clearlyvisible
inthetable,thereasonforthisadvantageisbasedinthecategories
whereweusedtoolsincooperationwhichareIAC( 62%),ICC(34%),
Native (89%) and Reflection ( 70%). We also see that there is one
category(łDynamicLaodingž)wherethełbestžtooloutperforms
CoDiDroid byalargerdifferenceinF-measure,i.e.0.5.Thebest
tool in this category is Amandroid . Looking closer at the detected
flows, the difference in F-measure is, however, due to a single flow
whichAmandroid detects, but CoDiDroid does not. Since Aman-
droiddidnotshowanyeffectontheremainingcases6,wedecided
to not embeditas adedicatedtoolfor dynamic loadingcases.
We also tried to eliminate false positives by employing Horn-
Droidto crosscheck the results produced by FlowDroid (Strat-
egy IV, see Section 3). Here, cooperation did not work out because
HornDroid often times out regarding the maximal execution time
of 10 minutes which we imposed on the experiments. Moreover,
even witha highermaximalexecution time HornDroid oftenre-
ports leaks as "POTENTIAL LEAK" only, which is not sufficient to
discardflowsfoundby FlowDroid .Tobeabletobetterleverage
the crosschecking capabilities of CoDiDroid , we either need to
allowfor more time orneedfastertools.
Startled by the reported difference in F-measure of 0.5 due to a
single flow (cf. Table 3: Row 2), we furthermore decided to look
at the absolute numbers of flows in experiments. Table 3shows
themforthesevencategoriesof DroidBench whereadifference
inF-measureunequalto 0becamevisible.Thefirstcolumnrefers
6The łDynamicLaodingž benchmark category contains 5 apps with 3 flows to be
detected out of which Amandroid findsone.0.0000.5001.000
AmandroidDIALDroid,
DidFail,
FlowDroidDroidSafe IccTA CoDiDroid
Precision 0.888 0.000 0.500 0.367 0.490
Recall 1.000 0.000 0.013 0.139 0.608
F-Measure 0.941 0.000 0.025 0.202 0.543
Figure 4:Intent-Matching:Precision,Recall,F-Measure
tothecategory;thelasttworowsinthisfirstcolumntothesum
overalllistedcategoriesandoverall DroidBench categories,re-
spectively. The other columns are arranged as 4 boxes labeled with
Cases,FlowDroid , Best (again the tool performing best in this
category) and CoDiDroid . The first box summarizes the expected
results,moreprecisely,howmany positiveandnegativebenchmark
cases exist. A positive benchmark case refers to a taint flow which
is expected to be found. The contrary holds for negative cases, the
associated taintflowsshouldindeed not be found. The remaining
boxes report the findings of FlowDroid , the łbestž tool and Co-
DiDroid intermsoftrueandfalsepositives(TP/FP)aswellastrue
andfalsenegatives(TN/FN).Highlightedingreenareallthevalues
for which CoDiDroid performs best.
We see that CoDiDroid performs well onthecategorieswhich
our current strategies target, in particular it significantly outper-
formsFlowDroid .Moreover,thedifferencetothełbestžtool(again,
not existing as a single tool) lays in 3 flows only. Still, no approach
could detect all leaks. Note that this is, however, nota weakness
ofCoDiDroid as a framework for cooperative analysis, but due
tothelack ofexistingtoolswhichcould calculate these flows and
whichwe could include inone of our strategies.
Inaddition,wemoredetailedlylookedattheprecisionobtainedfor
intent matching using the 224 benchmark cases of the extension of
DroidBench . They just contain inter-component flows. The result
forthesecasescanbefoundinFigure 4.Thefiguredepictsprecision,
recallandF-measure.Thedepictedvaluesshowthat CoDiDroid
withanF-measureof 54%outperformsalltoolsexcept Amandroid .
SinceAmandroid is able to outperform CoDiDroid here, it seems
thatAmandroid wouldbeanexcellentcandidateforinclusioninto
CoDiDroid . However, the ICC links which Amandroid infers are
largely due to a coarse overapproximation. This pays off for the
Intent-Matchingbenchmarks,butnotingeneralasweseebelow.
381TogetherStrong: Cooperative Android App Analysis ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
Table4:TimingsandResultsforinter-appbenchmarkcases
CooperationBenchmarkcase
(number of apps)
ApkCombiner
ApkCombiner +
IccTA
ApkCombiner+Amandroid
CoDiDroid
CoDiDroid*
CoDiDroid*
(Amandroid)
Star (3) 25s⋆58s⋆○42s⋆○37s⋆○39s×109s
Star (4) 31s⋆64s⋆○49s⋆○49s⋆○19s×33s
Star (5) 38s⋆72s⋆○56s⋆○59s⋆○19s×32s
Star (6) 44s⋆78s⋆○62s⋆○70s⋆○21s×34s
Star (10) 67s⋆102s⋆○87s⋆○133s⋆○59s×138s
Ring(3) 25s×60s×47s⋆○37s⋆○37s×63s
Ring(4) 31s⋆68s⋆○53s⋆○53s⋆○22s×28s
*incremental ×wrongresult,⋆correctresult, ○completeresult
Therefore,wehaverefrainedfromincluding Amandroid intothe
toolsetof CoDiDroid .
The results also show that intent matching in CoDiDroid is
notyetasgoodaswewouldlikeittobe.Amanualinspectionof
some failing cases shows that the conversion of IC3results into
intentsandintent-filterswhileapplying PIMisnotalwaysperfectly
accurate.Unfortunately,inmanycasestheinformationprovided
byIC3is incompletemakinganimprovement impossible.Hence, it
seems that we rather need an improved version of IC3than ofPIM.
In conclusion, the results demonstrate that cooperative analysis
cannot only simplify the usage of diverse analysis tools, but also
achievesa gain in terms of precision. In particular, adding cooper-
atingtools to assistan analysis tool suchas FlowDroid resultsin
ahigherprecisionandliftsupitsanalysisfromintra-applevelto
inter-app level.
5.2 RQ2: Howwell does(theinter-app analyis
of)CoDiDroid scale to higher numbersof
apps?
TheresultsoftheexperimentsinvolvingthecategoryłInterApp-
Communicationž have already been given in Tables 2and3. We
see thatCoDiDroid is improving over FlowDroid and equals the
F-measureofthebesttool.Table 4furthermoreshowstheoutcome
forthetwonewbenchmarkscenariosStarandRing.Eachcellinthe
first column identifies the benchmark case and number of involved
apps associated with each row. In the first row the approach (tool)
used isshown. The *-symbolbehind the approach’slabel refers to
the fact that this approach is re-usingthe results reported in row n
tocomputetheresultinrow n+1(nativefeatureof CoDiDroid ).
Twotypesofresultsarereportedineachcell.First,thesymbols ⋆○,
⋆and×give information about the correctness and completeness
oftheobtainedresult.Second,theanalysistimeinsecondsisgiven.
As a means for comparison, we list the runtime of the merging
procedure of ApkCombiner inthe secondcolumn.
Taking a look at the correctness, only CoDiDroid always com-
putes the correct result. All expected and no unexpected flows are
found.Incontrast, IccTAmissessomeflows.Inallscenariosexcept
for Ring (3), all apps contain flows from their own sinks to their
own sources via other apps . All these remain undetected by IccTA.
For benchmark case Ring (3) on the other hand, there is no flow
fromapp2and3to1(asapp4isnotpresentinRing(3)).Still IccTAreportstheseflows.Thislatterincorrectresultisalsoreportedby
ApkCombiner plusAmandroid .
Thelast column labeled with CoDiDroid * (Amandroid )refers
to a version of CoDiDroid usingAmandroid instead of Flow-
Droidforintra-appflowquestions.Thisisanalternativeversion
of cooperation which we wanted to evaluate. However, without
prior merging of apps via ApkCombiner , it becomes visible that
Amandroid reports one incorrect flow in every case, namely a
direct connection between each source and sink within an app,
i.e. withoutinvolving inter-app communication. Explained on our
runningexample, Amandroid reportsaconnectionfromstatement
s2tos3while only looking at app A. For this reason, we did not
includeAmandroid inCoDiDroid .
In summary, considering the correctnessand completeness Co-
DiDroid performs best.
Next, let us take a look at the time required by each approach. For
thecreationofacombinedapp, ApkCombiner itselfrequiresabout
8secondsperapptocombine. Amandroid isslightlyfasterthan
IccTAbut in combination with ApkCombiner the whole analy-
sis takes more than 40seconds in any scenario. CoDiDroid on
thecontraryisfasterwhenanalyzingthreeappswithouthaving
storedanypreviouslycomputedresults,becauseitdoesnotrequire
ApkCombiner tobeexecutedbeforehand.Thebiggestadvantage
becomes visible in those cases where ApkCombiner together with
Amandroid andIccTAtake longest, namely the scenarios dealing
withn+1>3apps.Thistime, CoDiDroid *alreadyknowswhat
has been computed before (for napps) and is able to reuse this
information, leading to an analysis time of 19to21seconds per
app. To conclude, CoDiDroid is on average 51% faster than any
approachrequiring ApkCombiner .Otherapproachesnotrelying
onApkCombiner (e.g. DIALDroid [ 8] storing intermediate results
as well) will show a similar scalability. With CoDiDroid , however,
any analysis tool able to analyze inter-component scenarios can
gainthis property.
Note furthermore that ApkCombiner is not able to combine
up-to-date apps built with Android Studio. Hence, additional effort
was spent to create Star and Ring in a version that is ready to be
combined. We also tried to use the up-to-date version of Flow-
Droid, which includes IccTA, in combination with ApkCombiner .
Theanalysistimewaslowerthanthetimerequiredby Amandroid
andIccTA.However,noneoftheinter-appflowswerefound,ac-
cordingly we didnot report the results.
Intheend,theresultsshowthatitisbeneficialtouse CoDiDroid
for inter-app analysis, since it is faster and more precise than all
otherapproachesinour scope.
5.3 RQ3: Howwelldoes CoDiDroid scale to
larger (real-world)apps?
For RQ3 we used the benchmarks of DIALDroid-Bench . The 30
real world apps belonging to DIALDroid-Bench come with a par-
tiallydefinedgroundtruthof26flows.Weran CoDiDroid onthese
30 apps. All of the 26 flows are found. This shows that CoDiDroid
isabletoprocess(a)largereal-worldappsand(b)largenumbersof
apps. The latter in particular proves the power of cooperation in
inter-app analysis. Approaches relying on merging via ApkCom-
binerdirectlyfail on30 apps.
382ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia F. PauckandH.Wehrheim
Table 5:Findings forDIALDroidBench(30 Apps)
Type Flows foundby Number
Native CoDiDroid :StrategyIII 629(+0/+0)
Reflection CoDiDroid :StrategyII 636(+7/+12)
InterApp-/
InterComponent-
CommunicationCoDiDroid :StrategyI 660(+31/+14)
CoDiDroid infactfindsseveralhundredsmorethanthe26flows.
Onlyamanualinspectioncouldrevealwhetherthesearefalseor
true positives, which is beyond the scope of this paper. Still we
wanted to see whether cooperation can bring us any newpotential
flowsnotdetectablewithoutcooperation.Tothisend,wecompared
theflowswiththosefoundby FlowDroid .Notethatitisourusage
of theAQL-System storing answers (in particular, precise flows)
whichallowsforsuchacomparison.Overall FlowDroid detects
629flowswhichare intra-appflowsonly.
Table5shows the results computed with CoDiDroid . The first
twocolumnsrefertothetypeofflowandthestrategyof CoDiDroid
which was employed as singelton strategy to specifically detect
thissortofflow.Thelastcolumnshowsthefindings.Wealsolist
inbrackets(a)howtheoverallnumberoffindingshavechanged
and(b)howmanynewtaintflowsassociatedwiththistypeofflow
have been foundśalwaysincomparison to FlowDroid alone.
4outof30 DIALDroid-Bench appsusenativelibraries.None
of these uses are involved in a taint flow. Thus, CoDiDroid still
only finds 629 candidates for taint flows when employing Strategy
III. Taking the cooperation of FlowDroid andDroidRA (Strategy
II) into account it gets more interesting. 21 of the 30 considered
appsemployreflection.Theresultsshowontheonehand,12yet
undetectedtaintflowsthatinvolvereflection.Ontheotherhand,
5 taint flow candidates could be eliminated since the reflective
statement did not refer to a source or sink of any kind. Thus, we
endedupwith636(+7)flowsintotal.
Furthermore,thecooperationof FlowDroid ,IC3andPIM(Strat-
egyI)detectedoverall660flows.Tofindthese,1966intent-sinks
and 1215 intent-sources, found by IC3, were taken into account. 41
of these intent-sinks and 156 of these intent-sources represent one
endoftheoverall660reportedflows.Amongthese660flows,14
inter-app taint flows transfer data from a real source in one app to
arealsinkinanotherapp.Theseflowshavenotbeenfoundbyany
otherapproach, yet.
In summary, the detection of 26 new taint flows (12 involving
reflection and 14 inter-app flows) shows that the cooperation of
different analysis tools can be beneficial in the context of large
real world apps. Moreover, the experiments show that cooperative
analysisisableto scaleto real-world apps.
5.4 Threatsto Validity
Themainthreattothevalidityofourresultsisthefactthatmost
experiments are carried out on artificially constructed benchmarks.
Themainreasonfordoingsoistheneedforknowingtheground
truth to compare the detected flows against. Without a ground
truth,thereisnobasisforcomparingtoolsandforcomputingtheir
accuracy. For real-world apps, the construction of the ground truth
requiresamajormanualeffort.Groundtruthcomputationcanofcourse be assisted by analysis tools. However, as these are at the
same time the targets ofour evaluation, this isnot ideal.
Another threat to validity is the informative value of metrics
likeprecision,recallandF-measure.Aswehaveseeninourexperi-
ments,adifferenceinF-measureof0.5canbeduetoadifferencein
thedetectionofjustasingleflow.Weneverthelessemploythese
measures here since they are very commonlyusedandthus allow
foracomparisonofourresultswiththeresultsofotherresearchers.
6 RELATED WORK
The idea of combining different analysis techniques and tools as to
improve performance of an analysis has already been investigated
in a number of works. The combinations can be differentiated into
tightandlooseintegrations.Tightcombinationsdeeplyintegrate
two or more analysis techniques into a new tool. Typical exam-
ples are tools performing an under- and overapproximation of the
statespaceatthesametime(like[ 3,11,16,17]).Consideringthe
area of app analysis, several tight combinations have already been
mentioned. DIALDroid [8],DidFail[20] andIccTA[22] are tight
combinations of IC3[25] andFlowDroid [2]. The techniques and
instruments used to build the combination is what distinguishes
them from each other. DIALDroid is most closely related to Co-
DiDroid. Its approach to tackle the challenge of inter-app analysis
issimilar,therebytheyachieve a comparable scalability.However,
thisistheonlycategorywhichistackledandtheiranalysisdoes
not allow to incorporate other tools which handle, for example,
native orreflexive methodcalls.
Tightcombinationsusuallyimproveoversingletontechniques
in terms of precision. The disadvantage is that a new tool has to be
writtenforeverynewlyavailabletechniquewhichhasprovento
be worthwhile to be integrated.
Loose combinations on the other hand take existing tools as
black boxes and combine them, often by running tools in sequence
(like[5]).Cooperative analysesaretakingthisprincipletotheex-
treme.Cooperativeapproachesdividetheanalysisworkontodif-
ferent tools and let the tools communicate on computed results by
exchange of information. Such information can take the form of
(residual) programs [ 6], program annotations [ 10], error paths [ 13]
andcorrectnessorerrorwitnesses[ 4,19].ForAndroidappanalysis,
nocooperative techniquehas been existing sofar.
7 CONCLUSION
In this paper,we have introduced the novel concept of cooperative
Android app analysis. Our approach allows for a flexible combina-
tionofexistingtoolsviaanautomaticsplittingofanalysistasksinto
subtasks and their distributionontotools. Theframeworkthereby
does not only significantly simplify the usage of app analysis tools
(whichhas to be evaluated in future work) but also improves over
singleton(non-cooperative)approachesintermsofprecisionand
scalability.
ACKNOWLEDGMENTS
ThisworkwaspartiallysupportedbytheGermanResearchFounda-
tion(DFG)withintheCollaborativeResearchCentrełOn-The-Fly
Computingž (SFB901).
383TogetherStrong: Cooperative Android App Analysis ESEC/FSE ’19, August 26–30, 2019,Tallinn,Estonia
REFERENCES
[1]Maqsood Ahmad, Valerio Costamagna, Bruno Crispo, and Francesco Bergadano.
2017. TeICC:targetedexecutionofinter-componentcommunicationsinAndroid.
InProceedingsofSAC,2017 ,AhmedSeffah,BirgitPenzenstadler,CarinaAlves,
and Xin Peng (Eds.).ACM,1747ś1752.
[2]Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexandre Bartel,
Jacques Klein, Yves Le Traon, Damien Octeau, and Patrick D. McDaniel. 2014.
FlowDroid: precise context, flow, field, object-sensitive and lifecycle-aware taint
analysisforAndroidapps.In ProceedingsofPLDI,2014 ,MichaelF.P.O’Boyleand
Keshav Pingali (Eds.).ACM,259ś269.
[3]NelsE.Beckman,AdityaV.Nori,SriramK.Rajamani,RobertJ.Simmons,SaiDeep
Tetali,and Aditya V. Thakur.2010. Proofsfrom Tests. IEEE Trans. Software Eng.
4 (2010), 495ś508.
[4]Dirk Beyer, Matthias Dangl, Daniel Dietsch, and Matthias Heizmann. 2016. Cor-
rectness witnesses: exchanging verification results between verifiers. In Pro-
ceedingsofthe24thFSE,2016 ,ThomasZimmermann,JaneCleland-Huang,and
ZhendongSu (Eds.).ACM,326ś337.
[5]Dirk Beyer and Marie-Christine Jakobs. 2019. CoVeriTest:Cooperative Verifier-
BasedTesting.In FASE (LectureNotesinComputerScience) ,ReinerHähnleand
Wil M. P. vander Aalst (Eds.), Vol. 11424.Springer, 389ś408. https://doi.org/10.
1007/978-3-030-16722-6_23
[6]DirkBeyer,Marie-ChristineJakobs,ThomasLemberger,andHeikeWehrheim.
2018. Reducer-basedconstructionofconditionalverifiers.In Proceedingsofthe
40thICSE,2018 ,MichelChaudron,IvicaCrnkovic,MarshaChechik,andMark
Harman (Eds.).ACM,1182ś1193.
[7]Eric Bodden, Andreas Sewe, Jan Sinschek, Hela Oueslati, and Mira Mezini. 2011.
Tamingreflection:Aidingstaticanalysisinthepresenceofreflectionandcustom
classloaders.In Proceedingsofthe33rdICSE,2011 ,RichardN.Taylor,HaraldC.
Gall,and NenadMedvidovic(Eds.).ACM,241ś250.
[8]AmiangshuBosu,FangLiu,Danfeng(Daphne)Yao,andGangWang.2017. Collu-
sive Data Leak and More: Large-scale Threat Analysis of Inter-app Communica-
tions.InProceedingsofAsiaCCS,2017 ,RameshKarri,OzgurSinanoglu,Ahmad-
Reza Sadeghi, and XunYi (Eds.).ACM,71ś85.
[9]Stefano Calzavara, Ilya Grishchenko, and Matteo Maffei. 2016. HornDroid: Prac-
tical and Sound Static Analysis of Android Applications by SMT Solving. In
ProceedingsofEuroS&P,2016 . IEEE,47ś62.
[10]Maria Christakis,PeterMüller,andValentinWüstholz.2016. Guiding dynamic
symbolic execution toward unverified program executions. In Proceedings of the
38thICSE,2016 ,LauraK.Dillon,WillemVisser,andLaurieWilliams(Eds.).ACM,
144ś155.
[11]Christoph Csallner, Yannis Smaragdakis, and Tao Xie. 2008. DSD-Crasher: A
hybridanalysistoolforbugfinding. ACMTrans.Softw.Eng.Methodol. 2(2008),
8:1ś8:37.
[12]Xingmin Cui, Jingxuan Wang, Lucas Chi Kwong Hui, Zhongwei Xie, Tian Zeng,
and Siu-Ming Yiu.2015. WeChecker: efficient and precise detection of privilege
escalationvulnerabilitiesinAndroidapps.In Proceedingsofthe8thConference
onSecurity& Privacy inWirelessand MobileNetworks,2015 . ACM,25:1ś25:12.
[13]PrzemyslawDaca,AshutoshGupta,andThomasA.Henzinger.2016. Abstraction-
drivenConcolicTesting.In Proceedingsofthe17thVMCAI,2016 ,BarbaraJobst-
mannand K.RustanM.Leino(Eds.).Springer, 328ś347.
[14]William Enck, Peter Gilbert, Byung-Gon Chun, Landon P. Cox, Jaeyeon Jung,
Patrick D. McDaniel, and Anmol Sheth. 2010. TaintDroid: An Information-Flow
TrackingSystemforRealtimePrivacyMonitoringonSmartphones.In Proceedings
ofthe9thOSDI,2010 ,RemziH.Arpaci-DusseauandBradChen(Eds.).USENIX
Association, 393ś407.
[15]YuFeng,IsilDillig,SaswatAnand,andAlexAiken.2014. Apposcopy:automated
detectionof Android malware (invited talk).In Proceedingsof the 2nd DeMobile,
2014, Aharon Abadi, Rafael Prikladnicki, and Yael Dubinsky (Eds.). ACM, 13ś14.
[16]PatriceGodefroid,NilsKlarlund,andKoushikSen.2005. DART:directedauto-
matedrandomtesting.In ProceedingsofPLDI,2005 ,VivekSarkarandMaryW.
Hall (Eds.).ACM,213ś223.
[17]Patrice Godefroid, Aditya V. Nori, Sriram K. Rajamani, and SaiDeep Tetali. 2010.
Compositional may-must program analysis: unleashing the power of alternation.
InProceedingsofthe37thPOPL,2010 ,ManuelV.HermenegildoandJensPalsberg
(Eds.).ACM,43ś56.
[18]Michael I. Gordon, Deokhwan Kim, Jeff H. Perkins, Limei Gilham, Nguyen
Nguyen, and Martin C. Rinard. 2015. Information Flow Analysis of Android
Applications in DroidSafe. In Proceedingsofthe 22nd NDSS,2015 .
[19]Marie-ChristineJakobsandHeikeWehrheim.2017. CompactProofWitnesses.
InProceedingsofthe9thNASAFormalMethods,2017 ,ClarkBarrett,MistyDavies,
and TemesghenKahsai(Eds.).Springer, 389ś403.
[20]William Klieber, Lori Flynn, Amar Bhosale, Limin Jia, and Lujo Bauer. 2014.
Android taint flow analysis for app sets. In Proceedings of the 3rd SOAP, 2014 ,
Steven Arztand Raúl A. Santelices (Eds.).ACM,5:1ś5:6.
[21]LiLi,AlexandreBartel,TegawendéF.Bissyandé,JacquesKlein,andYvesLeTraon.
2015. ApkCombiner:CombiningMultipleAndroidAppstoSupportInter-App
Analysis. In Proceedings of SEC, 2015 , Hannes Federrath and Dieter Gollmann
(Eds.).Springer, 513ś527.[22]LiLi,AlexandreBartel,TegawendéF.Bissyandé,JacquesKlein,YvesLeTraon,
Steven Arzt, Siegfried Rasthofer, Eric Bodden, Damien Octeau, and Patrick D.
McDaniel.2015. IccTA:DetectingInter-ComponentPrivacyLeaksinAndroid
Apps. InProceedings of the 37th ICSE, 2015 , Antonia Bertolino, Gerardo Canfora,
and Sebastian G.Elbaum(Eds.).IEEE,280ś291.
[23]LiLi,TegawendéF.Bissyandé,DamienOcteau,andJacquesKlein.2016. DroidRA:
taming reflection to support whole-program analysis of Android apps. In Pro-
ceedings of the 25th ISSTA, 2016 , Andreas Zeller and Abhik Roychoudhury (Eds.).
ACM,318ś329.
[24]DamienOcteau,SomeshJha,MatthewDering,PatrickD.McDaniel,Alexandre
Bartel,LiLi,JacquesKlein,andYvesLeTraon.2016. Combiningstaticanalysis
with probabilistic models to enable market-scale Android inter-component anal-
ysis. InProceedings of the 43rd POPL, 2016 , Rastislav Bodík and Rupak Majumdar
(Eds.).ACM,469ś484.
[25]DamienOcteau,DanielLuchaup,MatthewDering,SomeshJha,andPatrickD.
McDaniel. 2015. Composite Constant Propagation: Application to Android Inter-
Component Communication Analysis. In Proceedings of ICSE, 2015 , Antonia
Bertolino, Gerardo Canfora,and Sebastian G.Elbaum(Eds.).IEEE,77ś88.
[26]DamienOcteau,PatrickD.McDaniel,SomeshJha,AlexandreBartel,EricBodden,
Jacques Klein, and Yves Le Traon. 2013. Effective Inter-Component Communica-
tion Mapping in Android: An Essential Step Towards Holistic Security Analysis.
InProceedingsofthe22ndUSENIXSecuritySymposium,2013 ,SamuelT.King(Ed.).
USENIXAssociation, 543ś558.
[27]AdamPFuchs,AvikChaudhuri,andJeffreySFoster.2009. SCanDroid:Automated
security certification of Android applications . Technical Report. University of
Maryland.
[28]FelixPauck.2017. CooperativestaticanalysisofAndroidapplications . Master’s
thesis. Paderborn University, Germany.
[29]Felix Pauck, Eric Bodden, and Heike Wehrheim. 2018. Do Android taint analysis
tools keep their promises?. In Proceedings of the 26th ESEC/FSE, 2018 , Gary T.
Leavens,AlessandroGarcia, and Corina S. Pasareanu(Eds.).ACM,331ś341.
[30]Lina Qiu, Yingying Wang, and Julia Rubin. 2018. Analyzing the analyzers: Flow-
Droid/IccTA,AmanDroid, andDroidSafe.In Proceedingsofthe27thISSTA,2018 ,
Frank Tipand Eric Bodden (Eds.).ACM,176ś186.
[31]Fengguo Wei, Sankardas Roy, Xinming Ou, and Robby. 2014. Amandroid: A
PreciseandGeneralInter-componentDataFlowAnalysisFrameworkforSecurity
Vetting of Android Apps. In Proceedings of the Conference on Computer and
Communications Security, 2014 , Gail-Joon Ahn, Moti Yung, and Ninghui Li (Eds.).
ACM,1329ś1341. https://doi.org/10.1145/2660267.2660357
[32]Daojuan Zhang, Rui Wang, Zimin Lin, Dianjie Guo, and Xiaochun Cao. 2016.
IacDroid: Preventing Inter-App Communication capabilityleaks in Android.In
ProceedingsofISCC, 2016 . IEEE,443ś449.
[33]Jinman Zhao, Aws Albarghouthi, Vaibhav Rastogi, Somesh Jha, and Damien
Octeau.2018. Neural-augmentedstaticanalysisofAndroidcommunication.In
Proceedings of the 26th ESEC/FSE, 2018 , Gary T. Leavens, Alessandro Garcia, and
Corina S. Pasareanu(Eds.).ACM,342ś353.
[34]2017. Amandroid. Retrieved 02/16/2019 from https://bintray.com/arguslab/
maven/argus-saf/3.1.2
[35]2014. ApkCombiner. Retrieved02/16/2019from https://github.com/lilicoding/
ApkCombiner
[36]2019. AQL-Online. Retrieved 06/18/2019 from https://FoelliX.github.io/AQL-
Online
[37]2018. AQL-System. Retrieved02/16/2019from https://FoelliX.github.io/AQL-
System
[38]2019. AQL-WebService. Retrieved 06/18/2019from https://github.com/FoelliX/
AQL-WebService
[39] 2018. BREW. Retrieved 02/16/2019from https://FoelliX.github.io/BREW
[40]2019. CoDiDroid. Retrieved06/18/2019from https://FoelliX.github.io/CoDiDroid
[41]2017. DIALDroid. Retrieved 02/16/2019 from https://github.com/dialdroid-
android/DIALDroid
[42]2016. DIALDroidBench. Retrieved 02/16/2019 from https://github.com/
amiangshu/dialdroid-bench
[43]2015. DidFail. Retrieved02/16/2019from https://www.cert.org/secure-coding/
tools/didfail.cfm
[44]2016. DroidBench 3.0. Retrieved 02/16/2019 from https://github.com/secure-
software-engineering/DroidBench/tree/develop
[45]2017. DroidRA. Retrieved02/16/2019from https://github.com/serval-snt-uni-
lu/DroidRA
[46]2016. DroidSafe. Retrieved 02/16/2019 from https://mit-pac.github.io/droidsafe-
src/
[47]2017. FlowDroid. Retrieved02/16/2019from https://github.com/secure-software-
engineering/soot-infoflow-android/wiki
[48]2018. HornDroid. Retrieved 02/16/2019 from https://github.com/ylya/horndroid
[49] 2019. IC3. Retrieved 06/18/2019from https://github.com/FoelliX/ic3
[50]2016. IccTA. Retrieved 02/16/2019 from https://sites.google.com/site/
icctawebpage/source-and-usage
[51] 2019. NOAH. Retrieved 06/18/2019from https://github.com/FoelliX/NOAH
[52] 2019. PIM. Retrieved 06/18/2019from https://github.com/FoelliX/PIM
384