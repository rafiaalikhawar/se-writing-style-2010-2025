DAPANDA : Detecting Aggressive Push NotiÔ¨Åcations
in Android Apps
Tianming Liu1‚àó, Haoyu Wang1‚àó/Letter,L iL i2, Guangdong Bai3, Y ao Guo4, and Guoai Xu1
1Beijing University of Posts and Telecommunications, Beijing, China
2Monash University, Australia3The University of Queensland, Australia
4Key Laboratory of High-ConÔ¨Ådence Software Technologies (MOE), Peking University, Beijing, China
Abstract ‚ÄîMobile push notiÔ¨Åcations have been widely used in
mobile platforms to deliver all sorts of information to app users.
Although it offers great convenience for both app developers and
mobile users, this feature was frequently reported to serve mali-
cious and aggressive purposes, such as delivering annoying push
notiÔ¨Åcation advertisement. However, to the best of our knowledge,
this problem has not been studied by our research community so
far. To Ô¨Åll the void, this paper presents the Ô¨Årst study to detect
aggressive push notiÔ¨Åcations and further characterize them in
the global mobile app ecosystem on a large scale. To this end,
we Ô¨Årst provide a taxonomy of mobile push notiÔ¨Åcations and
identify the aggressive ones using a crowdsourcing-based method.
Then we propose DAPANDA , a novel hybrid approach, aiming at
automatically detecting aggressive push notiÔ¨Åcations in Android
apps. DAPANDA leverages a guided testing approach to systemati-
cally trigger and record push notiÔ¨Åcations. By instrumenting the
Android framework, DAPANDA further collects all notiÔ¨Åcation-
relevant runtime information to Ô¨Çag the aggressive ones. Our
experimental results show that DAPANDA is capable of detecting
different types of aggressive push notiÔ¨Åcations effectively in
an automated way. By applying DAPANDA to 20,000 Android
apps from different app markets, it yields over 1,000 aggressive
notiÔ¨Åcations, which have been further conÔ¨Årmed as true positives.
Our in-depth analysis further reveals that aggressive notiÔ¨Åcations
are prevalent across different markets and could be manifested
in all the phases in the lifecycle of push notiÔ¨Åcations. It is hence
urgent for our community to take actions to detect and mitigate
apps involving aggressive push notiÔ¨Åcations.
Index T erms ‚ÄîPush notiÔ¨Åcation, dynamic analysis, advertise-
ment, Android, mobile app
I. I NTRODUCTION
Since the mobile push notiÔ¨Åcation service was introduced
by Apple in 2008 [17], it has been widely adopted in various
mobile platforms including Android [7]. In essence, it provides
a mechanism to display messages outside of the normal
interface of a mobile app (usually in the status bar at the
top of the screen). Push notiÔ¨Åcations are generally used by
app developers to deliver various kinds of information, such as
timely reminders and up-to-date messages (e.g., location-based
messages and new content available in news).
Push notiÔ¨Åcations could be delivered without a speciÔ¨Åc
request from the app, which means that the app does not
have to be relaunched during the process. Users can directly
react to the notiÔ¨Åcation by simply tapping on it, providing
timely information and allowing quick and easy responses for
*The names of the Ô¨Årst two authors are in alphabetical order. Haoyu Wang
is the corresponding author.
<RXUHFHLYHGDUHGHQYHORSH
2QO\WRGD\KXUU\XSDQGFOLFNWKLV/LQNa
ÊæúÊøïÊæù ÊæµÊø¢ÊæîÊøôÊø¨ÊøïÊø°Êø§Êø†ÊøôÊæîÊø£ÊøöÊæîÊøïÊø¢Êø£Êø¢Êø≠Êø°Êø£Êø©ÊøßÊæîÊøïÊø¢ÊøòÊæîÊøïÊøòÊæ°Êø¶ÊøôÊø†ÊøïÊø®ÊøôÊøòÊæîÊæµÊøÑÊøÇÊøß
Popular Free
StarShared by Lock([WUHPH7HPSWDWLRQ
ÊæúÊøñÊæù ÊæµÊø¢ÊæîÊøôÊø¨ÊøïÊø°Êø§Êø†ÊøôÊæîÊø£ÊøöÊæîÊøóÊø£Êø°Êø§Êø©Êø†ÊøßÊøùÊø™ÊøôÊæîÊøïÊø¢ÊøòÊæîÊø°ÊøïÊø†ÊøùÊøóÊøùÊø£Êø©ÊøßÊæîÊæµÊøÑÊøÇÊøß≈Ω«Å≈∂≈Ø≈ΩƒÇƒö∆êÕóœ≠œ±œ±œ±œ∞œ¨
Fig. 1. Motivating examples of aggressive and malicious push notiÔ¨Åcations.
app users. The notiÔ¨Åcation interfaces are further allowed to be
customized by developers to provide Ô¨Çexibility and better user
experiences. Thanks to these beneÔ¨Åts, push notiÔ¨Åcations have
been favored by both mobile users and app developers and
hence been extensively integrated into modern mobile apps.
Because notiÔ¨Åcations can effectively ‚Äú push ‚Äù an app into the
user‚Äôs attention, app developers are encouraged to utilize push
notiÔ¨Åcations for re-engaging mobile app users. However, despite
users are generally in favor of push notiÔ¨Åcations, the abuse of
such notiÔ¨Åcations can still annoy app users and likely result
in user complaints. For example, a number of reports revealed
that app developers have been abusing push notiÔ¨Åcations for
various purposes [4], [8], [11], [13], [14].
In addition to the way notiÔ¨Åcations are pushed, recent
studies reveal that app users are likely to also complain
about the contents delivered in the notiÔ¨Åcations [9]. For
example, Bell argues that Facebook has a notiÔ¨Åcation problem
and enumerated 13 most annoying push notiÔ¨Åcations from
Facebook [12]. Most of these notiÔ¨Åcations are considered as
annoying because their contents are considered inappropriate
by users. SpeciÔ¨Åcally, app users especially hate notiÔ¨Åcations
that contain advertisements [1], [3]. Actually, both Google [2]
and Apple [16] have released strict policies to regulate the
use of mobile push notiÔ¨Åcations: Push NotiÔ¨Åcations must not
be required for the app to function, and should not be used
for advertising, promotions, or direct marketing purposes, or
sending sensitive personal or conÔ¨Ådential information .
Unfortunately, despite that mobile push notiÔ¨Åcations are
explicitly disallowed to deliver ads and promotions by app
markets, many app developers appear to be still enticed to such
practices, and even employing more sophisticated methods so
as to avoid being caught during app vetting. As shown in Fig. 1
662019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)
978-1-7281-2508-4/19/$31.00 ¬©2019 IEEE
DOI 10.1109/ASE.2019.00017
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. (a), it is an ad-related push notiÔ¨Åcation, while the interface
of this notiÔ¨Åcation has been customized such that it does not
explicitly mention which app it belongs to. The most annoying
part is that it tricked the user into clicking the notiÔ¨Åcation and
the link will be redirected to a page full of ads. This suggests
that, even though both Google and Apple have declared strict
policies, it is still difÔ¨Åcult for app markets to automatically
regulate the apps that violate the policy, such that anomalous
apps are still able to sneak into app markets and mobile devices.
Consequently, annoying notiÔ¨Åcations are frequently pushed to
mobile app users in the real-world.
More seriously, push notiÔ¨Åcations could also be exploited
for malicious purposes. Fig. 1 (b) shows a push notiÔ¨Åca-
tion triggered from the app com.keeeweee.lockscreen .
The annoying part of this notiÔ¨Åcation is that it cannot be
closed by the users, i.e., mobile users have to click it.
Even worse, once the user clicks it, an app downloading
process will be triggered immediately (speciÔ¨Åcally app up-
yel.patyzbg.vbxsoef.kncp.cbsmk.rnnbs will be downloaded) and
the installation UI will pop out. When we uploaded this
downloaded app to VirusTotal, over 30 antivirus engines
Ô¨Çagged it as malicious [23]. This example suggests that push
notiÔ¨Åcations could be used as a new covert channel to spread
malware, which has been largely overlooked by our community.
In this work, we refer to such annoying and even malicious
notiÔ¨Åcations as aggressive push notiÔ¨Åcations (APNs for
short) . To the best of our knowledge, except for some sporadic
news reports discussing speciÔ¨Åc instances of APNs, our research
community has not studied this problem systematically [44],
[47] and hence no research tools have been proposed to detect
and mitigate the occurrences of APNs.
This paper seeks to develop an automated approach to
detect APNs, and further dissect mobile push notiÔ¨Åcations
and characterize their behaviors in large-scale. To that end,
we Ô¨Årst provide a taxonomy that characterizes a variety of
APNs based on a comprehensive user survey and a summary
of market policies. Towards the automated detection of APNs,
we aim to address several key challenges:
‚Ä¢How to automatically trigger push notiÔ¨Åcations ef-
Ô¨Åciently? As push notiÔ¨Åcations are displayed outside
of the normal UIs of a given app, no existing tools
explicitly support automated testing of push notiÔ¨Åcations
(e.g., identify the notiÔ¨Åcation views). Besides, APNs could
be triggered in either the foreground or background. Thus,
we need to develop a new approach that is scalable enough
and also ensures good coverage of APNs.
‚Ä¢How to accurately identify the content and network
trafÔ¨Åc from push notiÔ¨Åcations? As push notiÔ¨Åcations
are running within the hosting app, the network trafÔ¨Åc
triggered by push notiÔ¨Åcations would be mixed together
with the trafÔ¨Åc generated by other parts of the app (e.g.,
banner ads or the contents in the main activities). As
we seek to characterize the malicious contents delivered
by push notiÔ¨Åcations, it is important to pinpoint the
corresponding content accurately.‚Ä¢How to trace the origins of APNs? Mobile push
notiÔ¨Åcations could be implemented by the app developers,
or third-party libraries (e.g., Google Cloud Messaging).
In addition to detecting APNs, we also seek to trace
back to the origin of APNs, i.e., analyzing who should
be responsible for the aggressive behaviors (e.g., app
developers or ad networks).
To address the aforementioned challenges, we propose
DAPANDA (Detecting Aggressive Push NotiÔ¨Åcation in And roid
Apps), a novel hybrid approach that supports accurate detection
of APNs. D APANDA mainly relies on two key techniques
to characterize the behaviors of mobile push notiÔ¨Åcations at
runtime. To trigger push notiÔ¨Åcations efÔ¨Åciently, we have
proposed an app queuing approach to enforce automated
exploration of push notiÔ¨Åcations. To accurately pinpoint the
information related to each notiÔ¨Åcation, we have implemented
aninstrumentation method that integrates call stacks and inter-
component tracing to record all necessary information to detect
APNs. Finally, we use a manually crafted benchmark set to
demonstrate the effectiveness of D APANDA .
To further characterize the presence of APNs in the wild,
we have applied D APANDA to 20,000 Android apps crawled
from 8 popular app markets including Google Play. We have
identiÔ¨Åed over 1,329 APNs from 1,036 apps, which accounts
for over 5% of the apps studied in this work. With further
inspection, we have also found that a large portion of these
APNs were originated from aggressive third-party libraries.
This paper makes the following main contributions:
‚Ä¢We have created a taxonomy of APNs in a systematic
way. To the best of our knowledge, this is the Ô¨Årst
work that is focused on detecting and characterizing
aggressive/malicious push notiÔ¨Åcations.
‚Ä¢We have implemented D APANDA , a new approach that
is able to expose push notiÔ¨Åcations with an automated
exploration strategy, and then characterize the behaviors
of APNs accurately.
‚Ä¢We have performed a large-scale measurement study by
applying D APANDA to 20,000 apps, seeking to measure
the phenomenon of APNs in the wild. We have revealed
the severity of APNs in the mobile app ecosystem, and
further investigated the underlying working mechanisms
behind APNs.
To boost research along this direction, we have released the
benchmark and our experiment results at:
https://github.com/DaPANDA2019/DaPANDA
II. A T AXONOMY OF AGGRESSIVE PUSH NOTIFICA TIONS
In order to automatically identify APNs, we seek to explore
why push notiÔ¨Åcations were considered as aggressive and what
types of APNs exist in the mobile app ecosystem. To this
end, we resort to a straightforward approach to understanding
push notiÔ¨Åcations manually. This manual process allows us to
form a taxonomy of all possible types of push notiÔ¨Åcations (cf.
II-A ). We then leverage the taxonomy to conÔ¨Årm APNs using
a crowdsourcing-based approach, i.e., following the opinions
67
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. of Android app users responded in a survey and the policies
given by app markets (cf. II-B).
A. A Taxonomy of Android Push NotiÔ¨Åcations
%HKDYLRU
&RQWHQW%DFNJURXQG3XVK$QRQ\PRXV3XVK
0DOLFLRXV&RQWHQW
'ULYHE\'RZQORDG
$GYHUWLVLQJ&RQWHQW
8SGDWLQJ&RQWHQW
1RUPDO&RQWHQW)UHTXHQW3XVK
&RPSXOVLYH3XVK
1RUPDO%HKDYLRU
3XVK
1RWL¬øFDWLRQ
Fig. 2. A taxonomy of push notiÔ¨Åcations.
The Ô¨Årst step is to understand the characteristics of Android
push notiÔ¨Åcations and their types. We resort to various sources,
including Android documentation, news reports, user comments
about annoying push notiÔ¨Åcations on app markets, as well as
running different Android apps ourselves. In the end, we have
created a taxonomy of Android push notiÔ¨Åcations from two
different aspects, as listed in Fig. 2.
The Ô¨Årst aspect is concerned about the pushing behavior ,
based on the way notiÔ¨Åcations are pushed/displayed to mobile
users. We found four speciÔ¨Åc types for this category and regard
all remaining scenarios as the Normal Behavior type1. The
speciÔ¨Åc types are explained as follows:
‚Ä¢Background Push. The notiÔ¨Åcation would be triggered
while the hosting app is running in the background.
‚Ä¢Compulsive Push. In general, a notiÔ¨Åcation could be
canceled or cleared by swiping it or clicking the Clear
button provided by the system. However, some intrusive
notiÔ¨Åcations cannot be canceled, i.e., users are forced
to click it. Such kind of push notiÔ¨Åcations is caused
by the misuse or malicious use of push notiÔ¨Åcation
conÔ¨Ågurations. Two Ô¨Çag Ô¨Åelds FLAG_ONGOING_EVENT
and FLAG_NO_CLEAR are related to this behavior.
Aggressive/malicious developers might intentionally set
the Ô¨Çag and force users to click these notiÔ¨Åcations.
‚Ä¢Anonymous Push. In general, push notiÔ¨Åcations should
explicitly show the icons and names of their hosting
apps. However, anonymous push may deliberately hide
its hosting app from mobile users (cf. Fig. 1).
1Note that the Normal Behavior type may also contain some other types
of abnormal behaviors, however, because we cannot assign them a speciÔ¨Åc
type, we will consider them as Normal in this taxonomy. It is the same for
the Normal Content type discussed later in this section‚Ä¢Frequent Push. It refers to the situation where a number
of notiÔ¨Åcations are pushed from the same hosting app
during a short period of time (e.g., less than 2 minutes).
For the second aspect, we are concerned about the contents of
the push notiÔ¨Åcations, including both the contents displayed and
the redirected contents after clicking. We have also observed
four speciÔ¨Åc types in this aspect as follows (putting the rest
into the Normal Content type):
‚Ä¢Advertising Content. It refers to a notiÔ¨Åcation that
contains advertising content, which is explicitly disallowed
by both Google and Apple. In general, it is non-trivial to
detect whether the content is ad-related or not. Thus, in
this paper, we regard the push notiÔ¨Åcations originated from
advertising libraries as ad push, which is a reasonable
assumption and we will further discuss it in Section V.
‚Ä¢Updating Content. It refers to a notiÔ¨Åcation that serves
as a reminder of updating or downloading app-related
resources. For example, such push notiÔ¨Åcations would
always remind users to update the app with contents like
‚Äúnew version found, need to update".
‚Ä¢Drive-by Download. This kind of notiÔ¨Åcation may trigger
unintentional downloads (e.g., of advertised APKs) when
a user clicks the notiÔ¨Åcation, without requiring user
conÔ¨Årmation. Such behaviors often heavily impact user
experience, and in most cases, drive-by downloads cannot
even be easily canceled.
‚Ä¢Malicious Content. This category refers to such notiÔ¨Åca-
tions that, after clicked, may jump to landing pages where
malicious content is presented, or trigger the downloading
of malicious Ô¨Åles (e.g., apks).
With this taxonomy, we are able to classify each push
notiÔ¨Åcation into one or more types considering both their
behavior and content . For example, a push notiÔ¨Åcation that is
frequent and with advertising content will be classiÔ¨Åed into
the ‚Äúfrequent +advertising‚Äù type. Ideally, we could have as
many as 25 different types (including the ‚Äúnormal behavior,
normal content‚Äù type). However, since frequent +updating
and anonymous +updating are not possible in practice, we
did not take these two types into account. Finally, we have
obtained 23 different notiÔ¨Åcation types based on our taxonomy.
Note that while this taxonomy covers most common cases
of push notiÔ¨Åcations, it is not completely orthogonal. The
actual push notiÔ¨Åcation may belong to more than one behavior
type and more than one content type simultaneously. For
example, the motivation example shown in Fig. 1 (b) belongs
toCompulsive and Anonymous behavior types, and Malicious ,
Drive-by Download and Ad content types.
B. User Survey
Although we are now able to classify mobile push notiÔ¨Åca-
tions into different types based on their behavior and content
aspects, we still do not know which types are considered
to be aggressive, as no previous studies have characterized
them. Instead of labeling them ourselves, we seek to adopt
a crowdsourcing-based approach, i.e., assigning the level of
68
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. Êø†Êø¥ÊøøÊøºÊø∂ÊøºÁÄÇÁÄàÁÄÜ ÊøóÁÄÖÊøºÁÄâÊø∏ÊøÄÊøµÁÄå ÊøîÊø∑ Êø®ÁÄÉÊø∑Êø¥ÁÄáÊøºÁÄÅÊø∫ Êø¢ÁÄáÊøªÊø∏ÁÄÖ
ÊøôÁÄÖÊø∏ÁÄÑÁÄàÊø∏ÁÄÅÁÄá ÊøáÊøÅÊøåÊøÖ ÊøáÊøÅÊøâÊøà ÊøáÊøÅÊøÑÊøÜ ÁÄ• ÊøÜÊøÅÊøàÊøÉ
ÊøîÁÄÅÁÄÇÁÄÅÁÄåÁÄÄÁÄÇÁÄàÁÄÜ ÊøáÊøÅÊøãÊøä ÊøáÊøÅÊøàÊøÉ ÊøáÊøÅÊøÜÊøã ÁÄ• ÊøÜÊøÅÊøÖÊøå
ÊøñÁÄÇÁÄÄÁÄÉÁÄàÊøøÁÄÜÊøºÁÄâÊø∏ ÊøáÊøÅÊøãÊøä ÊøáÊøÅÊøâÊøÖ ÊøáÊøÅÊøÉÊøá ÊøÖÊøÅÊøäÊøä ÊøÖÊøÅÊøãÊøã
ÊøïÊø¥Êø∂ÊøæÊø∫ÁÄÖÁÄÇÁÄàÁÄÅÊø∑ ÊøáÊøÅÊøãÊøÑ ÊøáÊøÅÊøàÊøÖ ÊøÜÊøÅÊøàÊøá ÊøÖÊøÅÊøâÊøÖ ÊøÖÊøÅÊøâÊøå
Êø¢ÁÄáÊøªÊø∏ÁÄÖ ÊøáÊøÅÊøâÊøå ÊøáÊøÅÊøáÊøÉ ÊøÜÊøÅÊøÑÊøä ÊøÖÊøÅÊøáÊøâ ÊøÑÊøÅÊøâÊøÖ
Fig. 3. The survey results. The green cell stands for benign and not aggressive
at all, the yellow stands for disturbing to users but not aggressive, and the red
ones stand for aggressive cases, and the deeper the color, the more aggressive
it is from users‚Äô perspective. Overall, 17 ones (in red) are regarded as APNs.
aggressiveness of all possible types of the push notiÔ¨Åcations
from the perspective of real Android app users, in order to
conÔ¨Årm which notiÔ¨Åcations are more likely to be APNs.
Survey Design. Based on the taxonomy we created (cf.
Fig. 2), we further embed it into a Likert-scale [54] online
survey to measure the aggressiveness for each type of notiÔ¨Åca-
tions. Participants in the survey, with the experience of using
Android mobile devices and the basic understanding of mobile
notiÔ¨Åcations, were provided with 23 types of push notiÔ¨Åcations
together with example screenshots and their explanations. The
details of the user survey could be found at the project on
Github [20]. Participants are asked to grade each type of push
notiÔ¨Åcation from a level of 1 to 5 based on its aggressiveness,
which is deÔ¨Åned as follows:
‚Ä¢1stands for benign and not aggressive at all.
‚Ä¢2stands for disturbing to users but not aggressive.
‚Ä¢3stands for somewhat aggressive.
‚Ä¢4stands for aggressive.
‚Ä¢5stands for extremely aggressive.
To encourage users to respond to our survey, we pay 2 US
dollars to the person who responds to our full survey. Eventually,
our online survey receives 52 effective responses, which is
a fairly representative number considering the difÔ¨Åculties to
encourage people to answer online surveys [29].
Survey Result. The responding results are illustrated as
a heatmap in Fig. 3. This heatmap is drawn based on the
average scores by all respondents. Following the convention
of Likert-scale, in this work, we deÔ¨Åne Ô¨Åve aggressiveness
levels: Benign ,Disturbing ,Somewhat Aggressive ,Aggressive ,
and Extremely Aggressive , which are regarded as such if the
average score of all the responses falls into ranges [1,2), [2,3),
[3,3.5), [3.5,4.5), [4.5,5], respectively. In this work, we consider
such combinations that have an average score higher than three
as APNs . Eventually, as shown in Fig. 3, 17 combinations fall
into this category and hence are regarded as APNs.
C. Market Policies
After identifying the types of APNs, we go one step
deeper to check if some of the notiÔ¨Åcation types, which are
considered to be aggressive by app users, have been explicitly
restricted by market policies. App markets have responsibilities
and incentives to regulate app behaviors that may lead to
dissatisfaction of users. When using apps with APNs, users
may not only complain about the app itself but also complain
about the market where the app is downloaded from. To thisT ABLE I
APN- RELA TED POLICIES DECLARED BY APP MARKETS .
Beha vior Content
Freq Anonymous Compulsive BKG Malicious Drive-by Ad Update
GPlay‚àö ‚àö
Huawei‚àö ‚àö ‚àö
Tencent‚àö ‚àö ‚àö
Push Exploration
Foreground Ba ckground
App Queue
Vieetree Click Push
Source TargetNetwork
TrafficInstrumented 
Android FrameworkAPN Detection
Behavior-based Detection
Content-based DetectionAPNs
Fig. 4. Overview of D APANDA .
end, we crawl the policy descriptions from several Android app
markets (including Google Play) and manually go through them
to check if the policy has explicitly mentioned that certain types
of push notiÔ¨Åcations are not allowed by the apps submitted
to its market. As illustrated in Table I, market policies have
explicitly disallowed malicious pushes ,ad-related pushes , and
anonymous/compulsive pushes , which are generally in line
with the choice of users from our survey, providing concrete
evidence to conÔ¨Årm the correctness of our survey results. Note
that the market polices are generally coarse-grained, while our
survey results have extended the policies with more detailed
combinations.
III. A PPROACH
Aiming at systematically detecting APNs in Android apps,
we propose a dynamic analysis approach called D APANDA
for automatically exploring and characterizing push notiÔ¨Åca-
tions. Fig. 4 illustrates the working process of D APANDA ,
which is mainly made up of three modules: (1) Automated
exploration of push notiÔ¨Åcations. This module leverages
automatic Android GUI traversal techniques for triggering
the appearance of push notiÔ¨Åcations and clicking subsequently
the pushed notiÔ¨Åcations. (2) Framework Instrumentation.
This module aims at hooking relevant methods for capturing
runtime information of push notiÔ¨Åcations (e.g., how is a push
notiÔ¨Åcation triggered and consumed?). (3) Aggressive Push
NotiÔ¨Åcation Detection. This module follows the pre-deÔ¨Åned
deÔ¨Ånition of APNs to identify the aggressive ones from all the
triggered notiÔ¨Åcations, utilizing the information collected in
the instrumented framework after the completion of automated
GUI exploration.
A. Automated Exploration of Push NotiÔ¨Åcations
The general idea of this module is to identify and understand
the layout of push notiÔ¨Åcations by constructing the correspond-
ing view trees of each UI page and click the notiÔ¨Åcations by
simulating the touch events at runtime. Since push notiÔ¨Åcations
could be triggered in both the foreground and background,
existing UI exploration tools focused on a single app becomes
ineffective, thus we propose a new exploration strategy called
69
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. App Queuing , aiming at exploring as many push notiÔ¨Åcations
as possible.
1) App Queuing: The key idea of app queuing is that,
instead of quitting the app directly after running it in the
foreground, which has been done by almost all the state-
of-the-art app testing approaches [19], [52], we will put the
app into the background, allowing silent notiÔ¨Åcations to be
still pushed. Additionally, the app queuing approach can also
improve exploration efÔ¨Åciency. In practice, although only one
app runs in the foreground, more than one app could run in
the background, which allows us to test multiple apps at the
same time. SpeciÔ¨Åcally, our exploration strategy maintains an
app queue structure with three principal operations: insert ,
which adds an app to the app queue and automatically tests it
in the foreground; downgrade , which puts the app into the
background; and remove , which removes an app from the
queue based on their arriving order (FIFO).
During exploration, we can conÔ¨Ågure the capacity of the
queue nand the foreground execution time tffor each app.
SpeciÔ¨Åcally, (1) napps are allowed to be concurrently tested
in our system and (2) each app is running in the foreground
fortfseconds. When experimenting on a large set of apps, we
follow the FIFO principle as in the queue structure, i.e., once
an app runs in the foreground for time tf, we will put it into the
background. Once the app queue reaches its capacity n, the app
at the rear of the queue (who enters the queue earliest) would
be removed and further be closed and uninstalled, making
room for new apps. Note that, each app runs in the foreground
fortftime, and in the background for (n-1)*t ftime, thus n*tf
time in total, while the expected average execution time for
each app is still tf.
To ensure each app strictly follows this strategy and prevent
exceptional cases (e.g., app crash or interference of concurrent
running apps), our system monitors the execution states (e.g.,
use adb shell command dumpsys activity top to query the
foreground activity) at runtime for every 10 seconds. Once
exceptional cases are found, our system will either revoke the
app back to the foreground or restart the app (e.g., use adb
shell command am start with the launcher activity of the app).
2) View Tree based UI Exploration: For each app, we split
the UI exploration into two phases: (1) exploration of in-app
UIs , to trigger push notiÔ¨Åcations; (2) exploration of notiÔ¨Åcation
UIs , to identify push notiÔ¨Åcation views and click them. Thus
we can not only trigger the corresponding behaviors, but also
harvest their distribution contents.
Exploration of In-app UIs. In this work, we plan to trigger
push notiÔ¨Åcations by exploring apps with randomly generated
UI-focused test inputs, as the occurrence of push notiÔ¨Åcation
is unpredictable, without the knowledge of predictable trigger
points. However, some apps present welcome pages or user
agreements on their Ô¨Årst run during the experiment, which may
stop us from triggering the main app functionality. Therefore,
we take advantage of a model-based UI input generation method
here. During the exploration of the in-app UI, we propose to
analyze the view tree of each UI state, and then apply the
DFS (depth-Ô¨Årst search) algorithm to generate the possibleinput events, in order to trigger the functionality of the app.
Fig. 5(a) shows an example of the view tree we constructed
during in-app UI exploration.
Exploration of NotiÔ¨Åcation UIs. In order to fully exploit the
app queuing mechanism, we decide to explore the notiÔ¨Åcation
related UIs when the testing app switches its state, from running
in the foreground to running in the background. During this
interval, before the next app runs in the foreground, we Ô¨Årst
simulate the Swipe Down action on the status bar to open
the notiÔ¨Åcation drawer , where we can view more details and
take actions with the notiÔ¨Åcation. We then get the view trees
of the current state (notiÔ¨Åcation drawer), based on Google
Accessibility [15]. Fig. 5(b) shows an example of the view tree
we constructed for a notiÔ¨Åcation drawer. Three FrameLayout
nodes are laid at the bottom, and each of them corresponds
to a notiÔ¨Åcation view, which is also a tree-like structure, as
shown in Fig. 5(c). We can retrieve the notiÔ¨Åcation related
information from the view tree, including its coordinates, text
messages, resource id, the package name of the original app.
Finally, with the retrieved coordinate information, we click
on the notiÔ¨Åcation view accordingly by simulating a click
event at the center of the view. This process would be repeated
several times if we found more than one notiÔ¨Åcation views.
Note that we only click once for each unique push notiÔ¨Åcation.
B. Framework Instrumentation
The objective of this phase is to collect all the necessary
information relevant to push notiÔ¨Åcations, mostly the ones that
could be useful for characterizing APNs. SpeciÔ¨Åcally, in order
to accurately identify APNs, we seek to collect three types of
runtime information. As shown in Fig. 6, which illustrates the
typical working scenario of push notiÔ¨Åcations, the following
three types of runtime information are needed: (1) The source
where the notiÔ¨Åcation is pushed to the system, (2) The target
where the execution will jump to after the notiÔ¨Åcation is clicked,
and (3) the network trafÔ¨Åc triggered by the consumption of
the notiÔ¨Åcation.
Unfortunately, it is not straightforward to collect some of
the aforementioned information. For example, it is difÔ¨Åcult to
track the source where the notiÔ¨Åcation is pushed . Furthermore,
although it is relatively easy to collect all network trafÔ¨Åc after
a notiÔ¨Åcation is clicked (e.g., via Tcpdump ),it is still difÔ¨Åcult
to locate the app that has actually generated those trafÔ¨Åc, as
there are always multiple apps running at the same time .T o
this end, we propose an instrumentation-based approach, in
which we leverage the Xposed framework [6] to hook all the
notiÔ¨Åcation-relevant methods to collect the app execution logs
on demand. The Xposed framework allows us to collect the
runtime information of tested Android apps without actually
instrumenting the APK. We only need to set up the framework
once and it works for all the apps to be tested.
Table II summarizes the key methods hooked by the
instrumentation module in order to extract runtime information
that our approach is interested in (i.e., the runtime information
involved in the lifecycle of push notiÔ¨Åcations). Listing 1 further
70
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. DQGURLGZLGJHW)UDPH/D\RXW9LHZ7UHH
DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW/LQHDU/D\RXWDQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW)UDPH/D\RXWDQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW%XWWRQ 2.
%RXQGV>@>@DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW7H[W9LHZ &ORVH
%RXQGV>@>@
(a) The view tree of a user agreement.DQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW7H[W9LHZ9LHZ7UHH
DQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW)UDPH/D\RXW
%RXQGV>@>@DQGURLGZLGJHW)UDPH/D\RXW
%RXQGV>@>@DQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW)UDPH/D\RXWDQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW6FUROO9LHZ
DQGURLGZLGJHW)UDPH/D\RXW
%RXQGV>@>@
(b) The view tree of a notiÔ¨Åcation drawer.
DQGURLGYLHZ9LHZ
DQGURLGZLGJHW,PDJH9LHZ9LHZ7UHH
DQGURLGZLGJHW/LQHDU/D\RXWDQGURLGZLGJHW)UDPH/D\RXWDQGURLGZLGJHW)UDPH/D\RXW
%RXQGV>@>@
DQGURLGZLGJHW)UDPH/D\RXW
DQGURLGZLGJHW/LQHDU/D\RXW DQGURLGZLGJHW/LQHDU/D\RXW
DQGURLGZLGJHW7H[W9LHZ
¬≥$FFHVV*HVWXUH&DOO¬¥DQGURLGZLGJHW7H[W9LHZ
¬≥$0¬¥DQGURLGZLGJHW7H[W9LHZ
¬≥*HVWXUH&DOO'RQDWH¬¥
UHVRXUFHBLGDQGURLGLG
VWDWXVBEDUBODWHVWBHYHQWBFRQWHQW
ERXQGV>@>@
SDFNDJH DFJHVWXUH&DOO3UR 
(c) The view tree of a typical push notiÔ¨Åcation.
Fig. 5. Constructing the view tree of push notiÔ¨Åcations.
Stack Tracing
SourceICC
TargetPushing ClickingNotification
Network Traffic
Fig. 6. The life-cycle of a standard mobile push notiÔ¨Åcation and the
corresponding information we collected (in gray).
T ABLE II
KEY INFORMA TION EXTRACTED WITH FRAMEWORK INSTRUMENT A TION .
Cate gory SpeciÔ¨Åc Info Method
SourcePackageName
API Hooking:
NotiÔ¨ÅcationManager.notify()
/Service.startForeground()Title&Texts
Icons&Images
Flags
ResourceID
NotiÔ¨ÅcationID
Source ClassName Call stack tracing
TargetIntent API Hooking: PendingIntent.getActivity()
/getActivities()/getBroadcast()/getService() Target ClassName
Netw ork TrafÔ¨ÅcClassName of Url API Hooking and trace call stacks
in network module PackageName of Url
Drive-by Download API Hooking: execStartActivity()
PackageName&Text Extracted from Viewtree
URLsExtracted from PCAP Ô¨ÅleDownloaded Files
illustrates the detailed runtime information we could collect
with the instrumentation module.
1) NotiÔ¨Åcation Source: We mainly retrieve two types of
information for the notiÔ¨Åcation source. The Ô¨Årst is necessary
conÔ¨Åguration information, the other one is the origin of the
push notiÔ¨Åcation (e.g., the class that issues it).
During the implementation of push notiÔ¨Åcations, the de-
velopers would need to specify the detailed conÔ¨Ågurations.
Some of them could be obtained during runtime from the
view trees (e.g., text and icon), while some others cannot (e.g.,
Ô¨Çags). Thus, we have instrumented a list of APIs that can push
notiÔ¨Åcations including android.app.NotiÔ¨ÅcationManager .notify()
and android.app.Service.startF oreground() to get the instances
ofNotiÔ¨Åcation , and then we further get the conÔ¨Åguration data
by checking the corresponding properties, as show in Table II.1//Source
2Source ClassName: com.appquanta.dll.cookiemanager.ag
3PackageName: cn.happyeclub.tjraduyy
4Title&Texts:: Come and Buy!&Click to see details.
5Icons&Images: 17301651.jpg
6Flags: FLAG_ONGOING_EVENT
7ResourceID of templates:
17367140/notification_template_base
8NotificationID: 25503184
9
10//Target
11Intent: {
12flg=0x18800000
13cmp=cn.happyeclub.tjraduyy/com.appquanta.wk.MainActivity
14 (has extras) } (from API getActivity())
15Target ClassName: com.appquanta.wk.MainActivity
16
17//Network Traffic
18{Url: http: //c1.apkads.com/get/w/20190411/3d991cf
19 380d8422ab581e69f8cdc0a3c.142368472.21321705.apk
20ClassName of Url: com.appquanta.dll.cookiemanager.be
21PackageName of Url: cn.happyeclub.tjraduyy}
22{Url: http: //alog.umeng.com/app_logs
23ClassName of Url: com.umeng.analytics.g
24PackageName of Url: cn.happyeclub.tjraduyy}
25Drive-by Download
Apk:file: ///storage/emulated/0/download/
26 com.yiqimmm.apps.android-8627.zip
27
28//Below are From PCAP
29PackageName&Text Messages: cn.happyeclub.tjraduyy, Come
and Buy!&Click to see details.
30URL:c1.apkads.com/ get/w/20190411/3d991cf380
31 d8422ab581e69f8cdc0a3c.142368472.21321705.apk
32alog.umeng.com/app_logs
33Downloaded Files:3d991cf380
34 d8422ab581e69f8cdc0a3c.142368472.21321705.apk
Listing 1. An example of obtained runtime information.
com.example.pushhook.Hook$1.afterHookedMethod(Hook.java:227)
     de.robv.android.xposed.XposedBridge.handleHookedMethod(Xpo sedBridge.java:645)
          android.app.NotificationManager.notify(Native Method)
               android.app.NotificationManager.notify(Notificat ionManager.java:109)
                    com.appquanta.dll.cookiemanager.ag.run (Unknown Source)
ƒäƒäNotification Load Method
Fig. 7. An example of stack traces.
To trace the origin of push notiÔ¨Åcations, we apply a call
stack based method. From the NotiÔ¨Åcation instance we located
via instrumentation, we log its call stack, and further pinpoint
the package and class issuing this notiÔ¨Åcation. Fig. 7 shows
an example of a call stack we harvested at runtime. In the
example, the notiÔ¨Åcation is implemented by an ad library called
71
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. Quanta [10], where we can trace to its load method from the
call stack. Note that, to further assist our source tracing, our
system also integrates a third-party static library detection
tool, which could help us Ô¨Çag the possible ad libraries and
push libraries, even if in the form of naming obfuscation (e.g.,
com.a.b.c). In this work, during our implementation, we have
embedded LibRadar++ [57], [70], and based on which we have
labeled over 60 ad libraries and 20 push libraries.
2) NotiÔ¨Åcation Target: The actual target of each push
notiÔ¨Åcation, i.e., the component it connects to, is essential for us
to identify the actual trafÔ¨Åc triggered by the corresponding push
notiÔ¨Åcation. The target component is set via a PendingIntent ,
a special Intent that can take an action in the future. After
the notiÔ¨Åcation is clicked, the pending Intent will be sent
to the system. Following the inter-component communication
mechanism [46], the appropriate target component will be
activated to execute in the foreground. Thus, our goal is to
demystify the corresponding Intent .
In Android, there are two forms of intents: Explicit Intents
and Implicit Intents . Explicit Intents specify the target compo-
nent (i.e., via the cmp attribute), which can be directly inferred.
However, for implicit intents, the value of cmp is not directly
set but via several special attributes such as action ,category ,
etc. These attributes will be leveraged by the system to locate
the target components, which should have declared an Intent
Filter with the same attribute values.
By instrumenting a series of APIs getActiv-
ity()/getActivities()/getBroadcast()/getService() under
android.app.PendingIntent , we can acquire the value of
Intent concerning three types of components in Android ‚Äì
Activity, Service and Broadcast Receiver. We check the cmp
attribute value to directly locate target components for explicit
Intents (e.g., line 2 in Listing 2). For implicit Intents, we
resort to the Intent and Intent Filter matching mechanism to
pinpoint the target component. Normally, the Intent Filter
contents can be extracted from the manifest conÔ¨Åguration
Ô¨Åle of Android apps (e.g., lines 6-13 in Listing 2). However,
this is not always true for Broadcast Receivers, in which
dynamic Intent Filters can be registered without mentioning
in the manifest Ô¨Åle. To this end, we additionally hook
method android.app.ContextImpl.registerReceiverInternal ,
the underlying implementation of API registerReceiver() ,t o
further include dynamically registered Intent Filters (e.g., lines
16-20 in Listing 2).
3) Network TrafÔ¨Åc: For each push notiÔ¨Åcation clicked, a
PCAP Ô¨Åle is generated using Tcpdump [21] to record its
network trafÔ¨Åc. We also gather the package name of the source
app that pushed the notiÔ¨Åcation via the View Tree. This package
name will be used to check whether the notiÔ¨Åcation is triggered
by the app running in the foreground. We then analyze the
PCAP Ô¨Åles using Bro [22], where several scripts are further
introduced to extract contents from the trafÔ¨Åc.
To further pinpoint the notiÔ¨Åcation trafÔ¨Åc, we have instru-
mented a list of network APIs in ‚ÄúHttpClient‚Äù, ‚ÄúHttpUrlConnec-
tion‚Äù and ‚ÄúOkHttp‚Äù, which are widely used networking modules.
By hooking and tracing the call stacks of these key APIs, we1//Explict Intent
2Intent{flg=0x24000000 cmp=be.ppareit.swiftp_free
3 /be.ppareit.swiftp.gui.FsPreferenceActivity}
4
5//Implict Intent targetting statically-registered
component
6Intent={act=com.zhiyoo.UPDATE_CLICK (has extras)}
7AndroidManifest.xml (Registration Info):
8 <receiver
android:name= "com.zhiyoo.app.BBSReceiver" >
9 <intent-filter>
10 <action
android:name= "com.zhiyoo.UPDATE_CLICK" />
11 ......
12 </intent-filter>
13 </receiver>
14
15//Implict Intent targeting dynamically-registered
Broadcast Receiver
16Intent{act=com.unipay.secservice.action.SYNC (has
extras)}
17Instrument API
android.app.ContextImpl.registerReceiverInternal :
18IntentFilter.mActions: com.unipay.secservice.action.SYNC
19BroadcastReceiver:com.unipay.xiaowo.pluginmgr.plugin1
20 .MyBroadcastReceiver$1
Listing 2. Three types of intents and their target components.
can acquire the URLs in the network trafÔ¨Åc, and the origin
package that triggered the URLs (cf. Line 18-24 in Listing 1).
The extracted information will help identify network trafÔ¨Åc
introduced by the corresponding push notiÔ¨Åcation. For example,
as shown in Listing 1, the trafÔ¨Åc of Umeng Analytics does not
belong to the push notiÔ¨Åcations, as its origin package (cf. Line
23) does not equal to the package of notiÔ¨Åcation target (cf. Line
15). Note that, as drive-by-download notiÔ¨Åcations would trigger
app downloading Ô¨Årst, and then pop up an installation activity
(interface provided by the system), we further instrument the
API execStartActivity() to capture this behavior.
C. Aggressive Push NotiÔ¨Åcation Detection
As demonstrated in Fig. 2, push notiÔ¨Åcations are categorized
from two aspects: (1) runtime behavior and (2) notiÔ¨Åcation
content. With the runtime information collected, we are now
able to detect APNs based on our taxonomy.
Behavior-based detection. It is quite straightforward to
characterize a given push notiÔ¨Åcation to the speciÔ¨Åc types of
notiÔ¨Åcations based on the behaviors speciÔ¨Åed in Fig. 2. For
example, we regard a notiÔ¨Åcation as a background push if
it is not pushed by the foreground app, compulsory push if
FLAG_ONGOING_EVENT orFLAG_NO_CLEAR Ô¨Çags are
enabled, and frequent push if three or more notiÔ¨Åcations with
different notiÔ¨Åcation id are pushed from the same app within
two minutes. Regarding the anonymous push , since Android
7.0, the system forces notiÔ¨Åcations implemented with system
templates to display its source app name [5]. In order to keep
pushing anonymous notiÔ¨Åcations, app developers are required
to implement customized templates. We are able to extract
all possible system templates (seven kinds in total, based on
the ResourceID). Therefore, we regard a notiÔ¨Åcation as an
anonymous push if system templates are not used while neither
the title nor icon is matched between the notiÔ¨Åcation and the
tested apps.
Content-based detection. Content-based notiÔ¨Åcation types
are also quite easy to classify, once the relevant runtime
72
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. information is collected. We can identify updating contents
based on keyword matching (e.g., download, update and new
version, a total of 9 keywords), while drive-by download based
on if an APK Ô¨Åle is downloaded after each notiÔ¨Åcation is
clicked, since no other interaction will be introduced. For
malicious content , VirusTotal will be leveraged to scan every
URL and Ô¨Åles recognized from the network trafÔ¨Åc (collected
after the notiÔ¨Åcation is clicked). We consider a notiÔ¨Åcation as
containing malicious content as long as VirusTotal Ô¨Çags its
content as such. For Advertising content , we will check if the
source method, which pushed the notiÔ¨Åcation, belongs to ad
libraries.
Finally, the remaining push notiÔ¨Åcations that cannot be
classiÔ¨Åed into the above types will be considered as Normal
Behavior/Content types.
IV . E V ALUA TION
To evaluate the performance of D APANDA , we consider
answering the following three main research questions.
‚Ä¢RQ1: Can D APANDA effectively and accurately identify
APNs in Android apps?
‚Ä¢RQ2: What is the percentage of apps with APNs in the
wild? What is the distribution across different app markets?
‚Ä¢RQ3: How are the underlying working mechanisms of
APNs manifested in the lifecycle of push notiÔ¨Åcations?
A. Experimental Setup
To effectively answer the above research questions, we will
conduct both in-the-lab and in-the-wild experiments. The in-
the-lab experiment aims to provide reliable indications on the
performance of our approach and, at the same time, identify
appropriate parameters for setting up the in-the-wild experiment,
which subsequently is applied to evaluate the performance of
our approach for a large number of apps in real-world settings.
Setup for RQ1 (in-the-lab). To evaluate the effectiveness
of our tool, we need to build a benchmark to support in-the-
lab experiments. Unfortunately, to the best of our knowledge,
there are no publicly available benchmarks on mobile push
notiÔ¨Åcations in our community. Therefore, we resort to user
comments on app markets (Google Play in particular) to
manually construct such a benchmark. If a given app receives at
least two comments complaining about the annoying behaviors
of its notiÔ¨Åcations, the app has a high probability to push
aggressive notiÔ¨Åcations and hence is a good candidate to be
included in our benchmark. We Ô¨Årst use a keyword-based (e.g.,
push notiÔ¨Åcation, notiÔ¨Åcation bar) method to Ô¨Ålter relevant user
comments, and then we manually went over the reviews and
randomly selected 100 such apps to form our benchmark set.
Note that during our selection of benchmark apps, we cannot
Ô¨Ågure out the type of APNs accurately, as some user comments
are vague and hard to infer their corresponding behaviors.
As for the parameters in the app queuing exploration strategy,
we further set the capacity ‚Äú n‚Äù of our app queue to four different
scales, from 1 to 7. For n=1 , representing that our system
also supports running only one app each time, the app would
be explored fully in the foreground state. We set the maximumcapacity as 7 in our experiment, as the testing phone we used
(Nexus 5) is unable to host more apps running at the same time
due to its hardware constraints. We set the exploration time per
app ‚Äú t‚Äù to 11 different scales, from 5 seconds to 1,800 seconds.
Note that the upper-bound was set dynamically during our
experiment, based on whether we could trigger more APNs.
Setup for RQ2 and RQ3 (in-the-wild). For RQ2 and RQ3,
we rely on real-world Android apps to support the in-the-wild
experiments. From August 2017 to December 2018, we had
crawled and collected over 3 million Android apps from 8
markets including Google Play. To perform an efÔ¨Åcient study,
we seek to focus on those apps that are likely to invoke APIs
related to notiÔ¨Åcations delivery (e.g., notify() ). To this end, we
have incorporated our system into a static analyzer to identify
the invocations of those APIs in the apps. By doing so, we
have managed to obtain 20,000 apps (without considering the
markets at this point) as our dataset.
In the large-scale experiments, we launch D APANDA on
actual smartphone devices, i.e., Nexus 5 smartphones with
Android 4.4 (or API level 19). We do not use emulators
since apps may embed evasion techniques to avoid running on
emulator environments [65]. We use four Nexus 5 smartphones
running in parallel for testing. It takes roughly 42 hours to
explore all 20K apps, with the app queue size n=5 such that
5 apps were running at the same time, and the exploration time
t= 600 s, where each app would be running in the foreground
for 120s and in the background for 480s.2
B. RQ1: Effectiveness of DAPANDA
Table III shows the overall result of our evaluation on the
crafted benchmark under different conÔ¨Ågurations. In general,
our approach could achieve a high recall rate (84 APN-
triggering apps at most out of 100 labeled apps). We manually
conÔ¨Årmed and categorized those apps into our taxonomy, as
shown in Table IV. To further explore the reasons why our
exploration cannot recall all labeled apps, we conducted a
manual analysis. We installed and ran the remaining apps for
a long time, and we found that the notiÔ¨Åcations could not be
triggered even manually. There could be multiple explanations
on this. First, the apps were released years ago, and the
notiÔ¨Åcation services could be invalid, or we did not get the
appropriate app version as users complained. Second, it may
require the right combinations and conÔ¨Ågurations in order for
the APNs to appear. Finally, it is also possible that some user
comments might not be accurate at all.
From our experiment result shown in Table III, we also
identiÔ¨Åed the appropriate parameters for the large-scale study.
(1) In general, the number of APN-triggering apps is
positively correlated with the exploration time. However, the
number reaches its peak at t= 600 sort= 900 sin most
cases, and increasing the exploration time further would not
signiÔ¨Åcantly improve the results.
(2) With the exploration time growing, it is interesting to
see that, strategies with app queuing ( n> 1) achieve better
2This conÔ¨Åguration is selected because it achieves the best performance in
the study of RQ1.
73
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. T ABLE III
THE NUMBER OF APN- TRIGGERING APPS WITH DIFFERENT PARAMETER
SETTINGS FOR THE 100 APPS IN OUR BENCHMARK .
Time/StrategyApp Queue
n=1 (foreground) n=3 n=5 n=7
5s 37 - - -
30s 48 - - -
60s 54 - - -
180s 63 60 55 36
300s 71 69 67 49
450s 74 77 78 58
600s 76 82 84 69
900s 76 84 84 75
1200s 76 84 84 74
1500s 76 84 84 78
1800s 76 84 84 76
T ABLE IV
THE DISTRIBUTION OF DIFFERENT TYPES OF APN S IN OUR BENCHMARK .
WEO N L YS H O WT H E 84 ONES THA T WERE TRIGGERED WITH APN SA N D
FURTHER CONFIRMED BY US .
Beha vior\Content Malicious Driv e-by Ad Updating Other Total
Frequent 10 10 12 - 2 16
Anon ymous 5 29 - 22 37
Compulsi ve 31 28 28 - - 55
Background 16 12 24 -- 33
Other 3 55 -- 5
Total 41 36 53 - 24 84
results than the strategy with fully foreground exploration
(n=1 ). The underlying reason is that a number of APNs were
triggered when the apps were running in the background, which
is the advantage of our app queuing strategy. Note that with
very limited time ( t<60, cf. Table III), we did not perform
exploration based on app queuing. This is because with multiple
apps running simultaneously, the app install/uninstall process
may take longer than the foreground running time, which may
cause conÔ¨Çicting issues.
(3) It is interesting to observe that, the strategy with ‚Äú n=5 ‚Äù
is slightly better than ‚Äú n=3 ‚Äù, and both of them achieve
better results than ‚Äú n=7 ‚Äù. We seek to investigate the reasons
and found that with ‚Äú n=5 ‚Äù, more background cases could
be triggered. However, with ‚Äú n=7 ‚Äù, due to the hardware
limitations of Nexus 5, the smartphone would be lagging and
some apps cannot work properly.
As a result, the best conÔ¨Ågurations for the following large-
scale study are: the app queue size n=5 and the exploration
time t= 600 s.
Findings #1: DAPANDA is able to effectively and accu-
rately detect APNs in our manually crafted benchmark
set. Among 100 Google Play apps received complaints
about their annoying notiÔ¨Åcation behavior , DAPANDA can
automatically Ô¨Çag 84 of them (a recall of 84%).
C. RQ2: The distribution of APNs in the wild
We then show results of RQ2, to understand how many
apps with APNs exist in the wild. For the selected 20,000
market apps, we have successfully triggered 2,446 unique pushT ABLE V
THE OVERALL RESULT .
Beha vior\Content Malicious Drive-by Ad Updating Other Total
Frequent 65(232) 58(210) 63(226) - 17(62) 93(331)
Anon ymous 64(71) 56(63) 34(37) - 205(229) 328(359)
Compulsi ve 196(362) 141(294) 135(288) 132(144) 653(675) 978(1180)
Background 324(397) 187(247) 325(404) 95(116) 212(233) 675(805)
Other 120(152) 148(186) 73(87) 245(284) 155(164) 490(553)
Total 608(839) 471(694) 509(717) 432(512) 963(1023) 2052(2446)
notiÔ¨Åcations from 2,052 apps, which accounts for over 10%
of the apps in our dataset. The distribution among different
notiÔ¨Åcation types is shown in Table V. Note that, although all
the apps selected in our dataset have been found incorporating
the related APIs, not all of them were identiÔ¨Åed with push
notiÔ¨Åcations during our experiment, mainly due to two reasons.
On one hand, the push notiÔ¨Åcation related APIs would never be
executed by the app, and checking statically whether an API is
reached is an instance of the (undecidable) halting problem [37].
On the other hand, for non-aggressive push notiÔ¨Åcations,
most of them were implemented based on third-party services
(e.g., Google Cloud Messaging), and fully controlled by the
developers (e.g., pushing messages at a certain time of the day),
with strict regulations by the service providers (e.g., Google
GCM regulates that developers cannot push repetitive push
notiÔ¨Åcations in a single day [18]). For the identiÔ¨Åed 2,446 push
notiÔ¨Åcations, 1,329 of them (54%) are considered to be APNs,
based on the results of our user survey (cf. Section II-A ). The
1,329 APNs were found to be pushed from 1036 apps, taking
up 5.18% of our dataset.
Distribution across Markets. Table VI shows the distri-
bution of our dataset and identiÔ¨Åed apps with APNs across
market3. Over 1.98% to 7.52% of app candidates in the studied
markets were Ô¨Çagged as apps with aggressive notiÔ¨Åcations.
Although each market has declared strict developer policies to
regulate the APNs, we still Ô¨Ånd a number of aggressive cases in
these markets. This result suggests that it is challenging to
perform automated regulation of APNs, thus both the app
markets and our research community should pay more
attention to this issue.
Findings #2: APNs are prevalent across all the app
markets we studied, i.e., covering over 5% of the apps
in our dataset. It is urgent for app markets to adopt
techniques like DAPANDA to identify and remove apps
with aggressive notiÔ¨Åcation behaviors.
D. RQ3: Understanding the lifecycle of APNs
We further characterize the push notiÔ¨Åcations triggered in the
large-scale experiment from different phases in their lifecycle,
including (1) the origin of the push notiÔ¨Åcation (including its
implementation template), (2) the reÔ¨Çected runtime behaviors,
(3) the triggered contents, and (4) the corresponding actions
after the notiÔ¨Åcations are consumed.
3Note that one APK may correspond to several markets, as different markets
have overlapped apps.
74
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. T ABLE VI
THE DISTRIBUTION OF OUR DA T ASET AND IDENTIFIED AGGRESSIVE APPS .
Market #App # Aggressive % Aggressive
Google Play 1,265 25 1.98%
HUAWEI Market 1,499 104 6.94%
Tencent Myapp 5,332 186 3.49%
PP Helper 7,834 276 3.52%
Wandoujia 5,967 241 4.04%
HiMarket 3,795 240 6.32%
OPPO Mraket 3,503 109 3.11%
Anzhi Market 2,820 212 7.52%
Total 20,000 1036 5.18%
T ABLE VII
DISTRIBUTION OF PUSH NOTIFICA TIONS FROM DIFFERENT LIBRARIES .
Ad Library Push Library
Library Name #Push #App Library Name #Push #App
Airpush 173 170 Tencent Bugly 25 18
Moxiu 136 133 Jpush 25 7
Dao youdao 121 72 Umeng Message Push 6 3
JYPush 67 28 Tencent Tpush (Xinge) 4 2
Wostore_UNIPA Y 47 20 GCM/FCM 4 4
PandaAd 44 18 Baidu Push Services 4 3
Feiw o 31 15 Rongyun Push 2 1
Kuguo 23 16
Migu SDK 15 13
Mipush 13 12
Other 47 12
Total 717 509 Total 70 38
1) Origin of the Push NotiÔ¨Åcations.: Based on ‚ÄúResourceID
of templates‚Äù obtained from Framework Instrumentation, we
observed that most push notiÔ¨Åcations were implemented using
system templates, while over 26% of the apps (536 in numbers)
and over 24% of the push notiÔ¨Åcations (584 in numbers)
triggered were implemented using customized templates. In
these 584 notiÔ¨Åcations, over 85% were labeled as APNs (498 in
numbers). We further analyze the origin of the triggered push
notiÔ¨Åcations, taking advantage of the call-stack based approach
we proposed in Section III-B . Over 32% of the notiÔ¨Åcations
were triggered by third-party libraries, including ad libraries
and push libraries. We listed the ad libraries and push libraries
with the number of triggered notiÔ¨Åcations in Table VII. While
notiÔ¨Åcations originated from ad libraries were all considered to
be APNs, taking up 30% of all notiÔ¨Åcations and 54% of APNs,
some popular push notiÔ¨Åcation services, including Google
GCM/FCM and Baidu Push Services, were only identiÔ¨Åed
with a few cases in our experiment, and no sensitive ones.
As we mentioned earlier, these notiÔ¨Åcation services have
strict regulations to keep away APNs. For example, Google
GCM/FCM does not allow developers to use customized push
notiÔ¨Åcations, which prevents anonymous pushes completely.
2) Runtime Behaviors: We then provide a detailed charac-
terization of their runtime behaviors based on the taxonomy
we summarized in Section II-A.
Frequent Push. We have identiÔ¨Åed 93 apps with frequent
push notiÔ¨Åcations, i.e., pushing 3+ messages in less than 2
minutes. For the 331 push notiÔ¨Åcations, over 232 of them were
considered to be malicious, leading users to malicious URLs
or downloading malware. Over 210 of them were also drive-by
download pushes, and 226 of them push ads frequently.
Anonymous Push. For the 584 push notiÔ¨Åcations that use
customized templates, 359 of them were considered to beT ABLE VIII
THE TOP 5DOMAINS THA T HOST THE MOST NUMBER OF MALICIOUS URL S.
Domain # Number # Aggressive Aggressive%
api.airpush.com 193 162 83.94%
mobile.eagla.com 133 121 90.98%
ff.td68x.com 64 64 100%
img.qycdn.daoyoudao.com 39 39 100%
ei.nd.enjoyÔ¨Ånance.cn 35 35 100%
T ABLE IX
THE TOP 5DOWNLOADED MALICIOUS APPS .
MD5 # VT Source app
b0490a5d8cce59616a12705adc546b61 40 com.androidemu.harveshihun.alvinshihun
f93ec3d8490d583f425b0b5f312cb809 39 com.budwbo
7d8d182bf06d500217abca147ede9be1 36 com.RunnerGames.game.Jesgtingche
fd23f172bb3633453cf154e769884dfe 35 com.june.sixteen.juejizhuti
4a1417007cce3309e04b28f326953288 35 com.suishouxie.yemdssfhgfekeji
anonymous, i.e., hiding app name and app icon in any Android
versions. Additionally, 492 push notiÔ¨Åcations could also be
considered as anonymous in Android versions prior to V7.0,
as they do not provide such information, but they implement
the notiÔ¨Åcations based on system templates. The systems will
force them to show app names in Android 7.0 and afterwards.
Compulsive Push. Over 48% of the push notiÔ¨Åcations we
identiÔ¨Åed belong to the compulsive notiÔ¨Åcation category. The
most aggressive cases were that, 362 of them deliver malicious
contents in this way, i.e., users cannot close the notiÔ¨Åcations
and have to visit malicious URLs or download malware.
Background Push. Over 33% of the push notiÔ¨Åcations
were triggered when the apps run in the background, which
demonstrates the effectiveness of our app queuing strategy.
Over half of the background notiÔ¨Åcations were malicious and
advertisement related.
3) Triggered Contents: The APNs usually pose threats and
spread sensitive contents including malicious contents. Then,
we further analyzed the triggered malicious contents.
URLs/Domains. As we have recorded all trafÔ¨Åc triggered
by clicking push notiÔ¨Åcations, we are able to harvest 5584
distinct URLs, belonging to 997 different domains. We further
analyzed the malicious URLs, i.e., the malicious or phishing
pages introduced by clicking the push notiÔ¨Åcations. As reported
by VirusTotal, 1,034 URLs from 194 domains were Ô¨Çagged as
malicious. Table VIII shows the top 5 domains that host the
most number of malicious URLs we identiÔ¨Åed.
Drive-by-Download Apps. During our exploration, we have
collected 1,004 drive-by-download apps triggered by 471 apps
with aggressive notiÔ¨Åcations. For the 1,004 apps we harvested,
only 252 were unique, i.e., some apps were downloaded several
times. We further send these apps to VirusTotal. The result
suggested that 174 of them (69%) were Ô¨Çagged as positive,
and 75 of them were Ô¨Çagged by 10 anti-virus engines, while 44
apps were Ô¨Çagged by 20 anti-virus engines. Table IX shows the
top 5 downloaded malicious apps Ô¨Çagged by the most number
of anti-virus engines.
4) The Targets of Push NotiÔ¨Åcations: We further categorized
target components of push notiÔ¨Åcations. Over 42% of them
invoke components within the app, while over 25% of them
invoke third-party components that belong to ad libraries or
75
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. push libraries. Besides, over 15% of them invoke system
components (e.g., android.intent.action.VIEW ) to perform
actions including opening Ô¨Åles and visiting URLs.
Findings #3: APNs could be manifested in all the phases
in the lifecycle of push notiÔ¨Åcations, ranging from the
origin of the notiÔ¨Åcations to their triggering behaviors,
and from the contents to their target components, once
the contents are consumed.
V. T HREA TS TO V ALIDITY
To the best of our knowledge, this work is the Ô¨Årst
attempt in the community towards detecting APNs in Android.
The implementation of D APANDA , however, carries several
limitations.
First, although we have created an effective app automation
tool to trigger push notiÔ¨Åcations, the timing of push notiÔ¨Åcation
messages usually depends on the developers/advertisers. Our
empirical study on the labeled benchmark suggested that
most aggressive push notiÔ¨Åcation behaviors could be triggered
within 10 minutes of app running (cf. Section IV -B ), however,
malicious developers could use sophisticated ways to bypass
our detection. Indeed, the classic principle of the unwinnable
arms race between the attackers and defenders also applies to
our work. There is hence a need to continuously improve our
approach towards inventing advanced techniques for detecting
aggressive push notiÔ¨Åcations in the long run. Second, we
consider a push notiÔ¨Åcation as advertisement-related by tracing
whether it is originated from known ad libraries, as it is
non-trivial for us to identify ads from the contents. However,
there may exist exceptional cases where the notiÔ¨Åcations are
pushed by app code to perform some in-app promotions. So
far, in this case, we will still regard them as non-advertisement
push notiÔ¨Åcations. Third, the contents (landing URLs or the
downloaded APKs) in push notiÔ¨Åcations may vary due to
factors such as time, location and user identiÔ¨Åers, etc, which
unfortunately are ignored at the moment.
VI. R ELA TED WORK
Mobile Push NotiÔ¨Åcations. This paper is the Ô¨Årst to detect
aggressive push notiÔ¨Åcations for Android apps. Nevertheless,
there are several studies [24], [31], [33], [45], [51], [53], [58]‚Äì
[60], [72], [73] focused on analyzing mobile push notiÔ¨Åcations
from other aspects. For example, Chen et al. [31] studied
the security qualities of emerging push-messaging services
and developed a tool to evaluate the security qualities of
the service‚Äôs SDKs and its integration within different apps.
Ahmadi et al. [24] characterized the usage of Google Cloud
Messaging (GCM) in Android malware, and proposed to trace
the Ô¨Çows of GCM to improve malware detection. Lee et al. [45]
have explored a new C&C channel for mobile botnets based
on the push notiÔ¨Åcation service of Android. These studies may
have a correlation with part of our work, however, our workis the Ô¨Årst to identify and characterize aggressive behaviors in
mobile push notiÔ¨Åcations.
Mobile Advertising. Mobile advertising has been widely
studied, including different techniques to detect third-party
libraries (including ad libraries) [27], [50], [57], [66]‚Äì[68],
analyzing the security and privacy behaviors of mobile ad
libraries [30], [38], [49], [55], [63], mobile ad fraud de-
tection [32], [34], [35], [56], and malicious contents dis-
tributed [61], [62]. Mobile push notiÔ¨Åcation, which could also
be used as a means for delivering mobile advertisement, has
not been well studied in our research community. Nevertheless,
some related techniques could be applied in our study.
Malicious and Gray Behaviors of Mobile Apps. Android
malware detection is a more general research direction, with
a large number of techniques and measurement studies [26],
[28], [36], [37], [43], [48], [69]‚Äì[71], [74] proposed. Besides,
a number of studies were focused on analyzing gray behaviors
and aggressive/annoying behaviors in mobile apps. Andow et
al.[25] proposed to design and implement heuristics for seven
main categories of grayware, and then use these heuristics
to simulate grayware triage on a large set of Android apps.
Tang et al. [64] proposed a systematic and comprehensive
empirical study on a large-scale set of fake apps. Hatada et
al.[40] analyzed ‚Äúpotentially unwanted applications‚Äù (PUAs) in
Android and proposed to classify them based on the similarity
of DNS queries. A number studies were focused on fraudulent
behaviors in mobile apps, e.g., promotion attack [39], [75],
fake review [41] and new kinds of scams [42]. As APNs cover
both malicious behaviors (e.g., spreading malware) and gray
behaviors (e.g., compulsive or anonymous), our work is a
complementary study of these existing efforts.
VII. C ONCLUSION
In this paper, we present the Ô¨Årst work to demystify mobile
push notiÔ¨Åcations and detect aggressive push notiÔ¨Åcations
(APNs) automatically. In particular, we Ô¨Årst create a comprehen-
sive taxonomy, and then propose D APANDA , a hybrid approach
that leverages UI automation and framework instrumentation
techniques to identify APNs. We have applied D APANDA
to 20K Android apps crawled from 8 app markets. Our
experimental results show that APNs indeed exist in many
Android apps. Among these aggressive notiÔ¨Åcations, some of
them were found to be maliciously used to distribute malware
and create annoying messages. Our results encourage our
research community to invest more efforts into the detection
and mitigation of APNs.
ACKNOWLEDGMENT
We sincerely thank our shepherd Prof. Amin Alipour
(University of Houston), and all the anonymous reviewers for
their valuable suggestions and comments to improve this paper.
This work is supported by the National Key Research and
Development Program of China (grant No.2018YFB0803603),
and the National Natural Science Foundation of China (grants
No.61702045 and No.61772042).
76
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] I, as a developer, HA TE the idea of AirPush. Lets make a list of apps
that use it, 2011. https://www.reddit.com/r/Android/comments/gzdz6/i_
as_a_developer_hate_the_idea_of_airpush_lets/.
[2] Google Play Developer Programme Policies, 2013. https://play.google.
com/intl/en-gb/about/index.html.
[3] No More NotiÔ¨Åcation Ads and Icon Ads in Android
Apps, 2013. https://googlesystem.blogspot.com/2013/08/
no-more-notiÔ¨Åcation-ads-and-icon-ads.html#gsc.tab=0.
[4] How to Disable NotiÔ¨Åcations from Any App in Android, 2015. https:
//www.makeuseof.com/tag/stop-annoying-notiÔ¨Åcations-android/.
[5] NotiÔ¨Åcations in Android N, 2016. https://android-developers.googleblog.
com/2016/06/notiÔ¨Åcations-in-android-n.html.
[6] Xposed Framework API, 2016. https://api.xposed.info/reference/packages.
html.
[7] Android Cloud to Device Messaging, 2017. https://en.wikipedia.org/
wiki/Android_Cloud_to_Device_Messaging.
[8] Find out which app is pushing ads in my notiÔ¨Åcation bar?,
2017. https://android.stackexchange.com/questions/41045/
Ô¨Ånd-out-which-app-is-pushing-ads-in-my-notiÔ¨Åcation-bar.
[9] No More NotiÔ¨Åcation Ads and Icon Ads in Android Apps,
2017. https://www.reddit.com/r/Android/comments/545x7k/theres_too_
many_popular_apps_that_are_abusing/.
[10] Quanta Sky Inc., 2017. http://www.appquanta.com/index.html.
[11] Suspicious Push NotiÔ¨Åcation on Android Phone,
2017. https://security.stackexchange.com/questions/186653/
suspicious-push-notiÔ¨Åcation-on-android-phone.
[12] The 13 most annoying Facebook notiÔ¨Åcations, ranked, 2017. https:
//mashable.com/2017/06/16/worst-facebook-notiÔ¨Åcations-ranked/.
[13] ‚ÄòGhost Push‚Äô Malware Threatens Android Users, 2017.
https://www.pandasecurity.com/mediacenter/mobile-security/
ghost-push-malware-android/.
[14] How to block spam notiÔ¨Åcations and rogue ads on Android
smartphones, 2018. https://www.androidpolice.com/2018/05/16/
track-block-rogue-ads-android/.
[15] Accessibility overview, 2019. https://developer.android.com/guide/topics/
ui/accessibility.
[16] App Store Review Guidelines, 2019. https://developer.apple.com/
app-store/review/guidelines/.
[17] Apple Push NotiÔ¨Åcation service, 2019. https://en.wikipedia.org/wiki/
Apple_Push_NotiÔ¨Åcation_service.
[18] Firebase console, 2019. https://console.Ô¨Årebase.google.com/.
[19] Monkey, 2019. https://developer.android.com/studio/test/monkey.
[20] Survey results on Github, 2019. https://github.com/DaPANDA2019/
DaPANDA.
[21] Tcpdump, 2019. http://www.tcpdump.org.
[22] The Zeek Network Security Monitor, 2019. https://www.bro.org/.
[23] Virustotal Detection Result, 2019. https://www.virustotal.com//#/Ô¨Åle/
56469bccccb788176564a03451e8879d5c8b70c6c65294fa254ea7cbe852cf90/
detection.
[24] Mansour Ahmadi, Battista Biggio, Steven Arzt, Davide Ariu, and Giorgio
Giacinto. Detecting misuse of google cloud messaging in android
badware. In Proceedings of the 6th Workshop on Security and Privacy
in Smartphones and Mobile Devices , pages 103‚Äì112. ACM, 2016.
[25] Benjamin Andow, Adwait Nadkarni, Blake Bassett, William Enck, and
Tao Xie. A study of grayware on google play. In 2016 IEEE Security
and Privacy Workshops (SPW) , pages 224‚Äì233. IEEE, 2016.
[26] Vitalii Avdiienko, Konstantin Kuznetsov, Alessandra Gorla, Andreas
Zeller, Steven Arzt, Siegfried Rasthofer, and Eric Bodden. Mining
apps for abnormal usage of sensitive data. In Proceedings of the 37th
International Conference on Software Engineering-V olume 1 , pages 426‚Äì
436. IEEE, 2015.
[27] Michael Backes, Sven Bugiel, and Erik Derr. Reliable third-party library
detection in android and its security applications. In Proceedings of
the 2016 ACM SIGSAC Conference on Computer and Communications
Security , pages 356‚Äì367. ACM, 2016.
[28] Guangdong Bai, Quanqi Y e, Y ongzheng Wu, Heila Botha, Jun Sun, Y ang
Liu, Jin Song Dong, and Willem Visser. Towards model checking android
applications. IEEE Trans. Software Eng. , 44(6):595‚Äì612, 2018.
[29] Y ehuda Baruch and Brooks C Holtom. Survey response rate levels and
trends in organizational research. Human relations , 61(8):1139‚Äì1160,
2008.
[30] Theodore Book, Adam Pridgen, and Dan S Wallach. Longitudinal analysis
of android ad library permissions. arXiv preprint arXiv:1303.0857 , 2013.[31] Y angyi Chen, Tongxin Li, XiaoFeng Wang, Kai Chen, and Xinhui Han.
Perplexed messengers from the cloud: Automated security analysis of
push-messaging integrations. In Proceedings of the 22nd ACM SIGSAC
Conference on Computer and Communications Security (CCS ‚Äô15) , pages
1260‚Äì1272. ACM, 2015.
[32] Jonathan Crussell, Ryan Stevens, and Hao Chen. Madfraud: Investigating
ad fraud in android applications. In Proceedings of the 12th annual
international conference on Mobile systems, applications, and services ,
pages 123‚Äì134. ACM, 2014.
[33] Junhua Ding, Wei Song, and Dongmei Zhang. An approach for
modeling and analyzing mobile push notiÔ¨Åcation services. In 2014
IEEE International Conference on Services Computing , pages 725‚Äì732.
IEEE, 2014.
[34] Feng Dong, Haoyu Wang, Li Li, Y ao Guo, Tegawend√© F Bissyand√©,
Tianming Liu, Guoai Xu, and Jacques Klein. Frauddroid: Automated
ad fraud detection for android apps. In Proceedings of the 2018 26th
ACM Joint Meeting on European Software Engineering Conference and
Symposium on the F oundations of Software Engineering , pages 257‚Äì268.
ACM, 2018.
[35] Feng Dong, Haoyu Wang, Li Li, Y ao Guo, Guoai Xu, and Shaodong
Zhang. How do mobile apps violate the behavioral policy of advertisement
libraries? In Proceedings of the 19th International Workshop on Mobile
Computing Systems & Applications (HotMobile ‚Äô18) , pages 75‚Äì80. ACM,
2018.
[36] Y u Feng, Saswat Anand, Isil Dillig, and Alex Aiken. Apposcopy:
Semantics-based detection of android malware through static analysis.
InProceedings of the 22nd ACM SIGSOFT International Symposium on
F oundations of Software Engineering , pages 576‚Äì587. ACM, 2014.
[37] Alessandra Gorla, Ilaria Tavecchia, Florian Gross, and Andreas Zeller.
Checking app behavior against app descriptions. In Proceedings of the
36th International Conference on Software Engineering , pages 1025‚Äì
1035. ACM, 2014.
[38] Michael C Grace, Wu Zhou, Xuxian Jiang, and Ahmad-Reza Sadeghi.
Unsafe exposure analysis of mobile in-app advertisements. In Proceedings
of the Ô¨Åfth ACM conference on Security and Privacy in Wireless and
Mobile Networks , pages 101‚Äì112. ACM, 2012.
[39] Qian Guo, Haoyu Wang, Chenwei Zhang, Y ao Guo, and Guoai Xu.
Appnet: understanding app recommendation in google play. In Proceed-
ings of the 3rd ACM SIGSOFT International Workshop on App Market
Analytics (WAMA ‚Äô19) , pages 19‚Äì25. ACM, 2019.
[40] Mitsuhiro Hatada and Tatsuya Mori. Detecting and classifying android
puas by similarity of dns queries. In 2017 IEEE 41st Annual Computer
Software and Applications Conference (COMPSAC) , volume 2, pages
590‚Äì595. IEEE, 2017.
[41] Y angyu Hu, Haoyu Wang, Li Li, Y ao Guo, Guoai Xu, and Ren He.
Want to earn a few extra bucks? a Ô¨Årst look at money-making apps. In
Proceedings of the 26th International Conference on Software Analysis,
Evolution and Reengineering (SANER ‚Äô19) , pages 332‚Äì343. IEEE, 2019.
[42] Y angyu Hu, Haoyu Wang, Y ajin Zhou, Y ao Guo, Li Li, Bingxuan Luo,
and Fangren Xu. Dating with scambots: Understanding the ecosystem of
fraudulent dating applications. IEEE Transactions on Dependable and
Secure Computing , 2019.
[43] Jianjun Huang, Xiangyu Zhang, Lin Tan, Peng Wang, and Bin Liang.
Asdroid: Detecting stealthy behaviors in android applications by user
interface and program behavior contradiction. In Proceedings of the 36th
International Conference on Software Engineering , pages 1036‚Äì1046.
ACM, 2014.
[44] Pingfan Kong, Li Li, Jun Gao, Kui Liu, Tegawend√© F Bissyand√©, and
Jacques Klein. Automated testing of android apps: A systematic literature
review. IEEE Transactions on Reliability , 68(1):45‚Äì66, 2018.
[45] Hayoung Lee, Taeho Kang, Sangho Lee, Jong Kim, and Y oonho Kim.
Punobot: Mobile botnet using push notiÔ¨Åcation service in android. In
International workshop on information security applications , pages 124‚Äì
137. Springer, 2013.
[46] Li Li, Alexandre Bartel, Tegawend√© F Bissyand√©, Jacques Klein, Yves
Le Traon, Steven Arzt, Siegfried Rasthofer, Eric Bodden, Damien Octeau,
and Patrick McDaniel. Iccta: Detecting inter-component privacy leaks in
android apps. In Proceedings of the 37th International Conference on
Software Engineering , pages 280‚Äì291. IEEE, 2015.
[47] Li Li, Tegawend√© F Bissyand√©, Mike Papadakis, Siegfried Rasthofer,
Alexandre Bartel, Damien Octeau, Jacques Klein, and Yves Le Traon.
Static analysis of android apps: A systematic literature review. Informa-
tion and Software Technology , 88:67‚Äì95, 2017.
77
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. [48] Li Li, Daoyuan Li, Tegawend√© F Bissyand√©, Jacques Klein, Yves
Le Traon, David Lo, and Lorenzo Cavallaro. Understanding android
app piggybacking: A systematic study of malicious code grafting. IEEE
Transactions on Information Forensics and Security , 12(6):1269‚Äì1284,
2017.
[49] Li Li, Timoth√©e Riom, Tegawend√© F Bissyand√©, Haoyu Wang, Jacques
Klein, and Yves Le Traon. Revisiting the impact of common libraries
for android-related investigations. Journal of Systems and Software ,
154:157‚Äì175, 2019.
[50] Menghao Li, Wei Wang, Pei Wang, Shuai Wang, Dinghao Wu, Jian Liu,
Rui Xue, and Wei Huo. Libd: scalable and precise third-party library
detection in android markets. In 2017 IEEE/ACM 39th International
Conference on Software Engineering (ICSE) , pages 335‚Äì346. IEEE, 2017.
[51] Tongxin Li, Xiaoyong Zhou, Luyi Xing, Y eonjoon Lee, Muhammad
Naveed, XiaoFeng Wang, and Xinhui Han. Mayhem in the push clouds:
Understanding and mitigating security hazards in mobile push-messaging
services. In Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security , pages 978‚Äì989. ACM, 2014.
[52] Y uanchun Li, Ziyue Y ang, Y ao Guo, and Xiangqun Chen. Droidbot: A
lightweight ui-guided test input generator for android. In Proceedings of
the 39th International Conference on Software Engineering Companion
(ICSE-C 2017) , pages 23‚Äì26. IEEE, 2017.
[53] Y uanchun Li, Ziyue Y ang, Y ao Guo, Xiangqun Chen, Y uvraj Agarwal,
and Jason I Hong. Automated extraction of personal knowledge from
smartphone push notiÔ¨Åcations. In 2018 IEEE International Conference
on Big Data (Big Data) , pages 733‚Äì742. IEEE, 2018.
[54] Rensis Likert. A technique for the measurement of attitudes. Archives
of psychology , 1932.
[55] Bin Liu, Bin Liu, Hongxia Jin, and Ramesh Govindan. EfÔ¨Åcient privilege
de-escalation for ad libraries in mobile apps. In Proceedings of the 13th
annual international conference on mobile systems, applications, and
services , pages 89‚Äì103. ACM, 2015.
[56] Bin Liu, Suman Nath, Ramesh Govindan, and Jie Liu. {DECAF}:
Detecting and characterizing ad fraud in mobile apps. In 11th{USENIX}
Symposium on Networked Systems Design and Implementation ( {NSDI}
14), pages 57‚Äì70, 2014.
[57] Ziang Ma, Haoyu Wang, Y ao Guo, and Xiangqun Chen. Libradar:
fast and accurate detection of third-party libraries in android apps. In
Proceedings of the 38th international conference on software engineering
companion , pages 653‚Äì656. ACM, 2016.
[58] Zhaotai Pan, Xiaoxing Liang, Y u Chen Zhou, Yi Ge, and Guo Tao Zhao.
Intelligent push notiÔ¨Åcation for converged mobile computing and internet
of things. In 2015 IEEE International Conference on Web Services ,
pages 655‚Äì662. IEEE, 2015.
[59] Martin Pielot, Karen Church, and Rodrigo De Oliveira. An in-situ study
of mobile phone notiÔ¨Åcations. In Proceedings of the 16th international
conference on Human-computer interaction with mobile devices &
services , pages 233‚Äì242. ACM, 2014.
[60] Martin Pielot, Amalia Vradi, and Souneil Park. Dismissed!: a detailed
exploration of how mobile phone users handle push notiÔ¨Åcations. In
Proceedings of the 20th International Conference on Human-Computer
Interaction with Mobile Devices and Services , page 3. ACM, 2018.[61] V aibhav Rastogi, Rui Shao, Y an Chen, Xiang Pan, Shihong Zou, and
Ryan Riley. Are these ads safe: Detecting hidden attacks through the
mobile app-web interfaces. In NDSS , 2016.
[62] Sooel Son, Daehyeok Kim, and Vitaly Shmatikov. What mobile ads
know about mobile users. In NDSS , 2016.
[63] Ryan Stevens, Clint Gibler, Jon Crussell, Jeremy Erickson, and Hao
Chen. Investigating user privacy in android ad libraries. In Workshop on
Mobile Security Technologies (MoST) , volume 10. Citeseer, 2012.
[64] Chongbin Tang, Sen Chen, Lingling Fan, Lihua Xu, Y ang Liu, Zhushou
Tang, and Liang Dou. A large-scale empirical study on industrial fake
apps. In Proceedings of the 41st International Conference on Software
Engineering: Software Engineering in Practice , pages 183‚Äì192. IEEE,
2019.
[65] Timothy Vidas and Nicolas Christin. Evading android runtime analysis
via sandbox detection. In Proceedings of the 9th ACM symposium on
Information, computer and communications security , pages 447‚Äì458.
ACM, 2014.
[66] Haoyu Wang and Y ao Guo. Understanding third-party libraries in mobile
app analysis. In Proceedings of the 39th International Conference on
Software Engineering Companion (ICSE-C) , pages 515‚Äì516. IEEE, 2017.
[67] Haoyu Wang, Y ao Guo, Ziang Ma, and Xiangqun Chen. Wukong: A
scalable and accurate two-phase approach to android app clone detection.
InProceedings of the 2015 International Symposium on Software Testing
and Analysis , pages 71‚Äì82. ACM, 2015.
[68] Haoyu Wang, Y ao Guo, Ziang Ma, and Xiangqun Chen. Automated
detection and classiÔ¨Åcation of third-party libraries in large scale android
apps. Journal of Software , 28(6):1373‚Äì1388, 2017.
[69] Haoyu Wang, Hao Li, and Y ao Guo. Understanding the evolution of
mobile app ecosystems: A longitudinal measurement study of google
play. In Proceedings of the 2019 World Wide Web Conference (WWW
‚Äô19) , pages 1988‚Äì1999. ACM, 2019.
[70] Haoyu Wang, Zhe Liu, Jingyue Liang, Narseo V allina-Rodriguez, Y ao
Guo, Li Li, Juan Tapiador, Jingcun Cao, and Guoai Xu. Beyond google
play: A large-scale comparative study of chinese android app markets.
InProceedings of the 2018 Internet Measurement Conference (IMC ‚Äô18) ,
pages 293‚Äì307. ACM, 2018.
[71] Haoyu Wang, Junjun Si, Hao Li, and Y ao Guo. Rmvdroid: towards a
reliable android malware dataset with app metadata. In Proceedings
of the 16th International Conference on Mining Software Repositories
(MSR ‚Äô19) , pages 404‚Äì408. IEEE, 2019.
[72] Ian Warren, Andrew Meads, Satish Srirama, Thiranjith Weerasinghe, and
Carlos Paniagua. Push notiÔ¨Åcation mechanisms for pervasive smartphone
applications. IEEE Pervasive Computing , 13(2):61‚Äì71, 2014.
[73] Zhi Xu and Sencun Zhu. Abusing notiÔ¨Åcation services on smartphones
for phishing and spamming. In WOOT , pages 1‚Äì11, 2012.
[74] Wei Y ang, Mukul Prasad, and Tao Xie. Enmobile: Entity-based
characterization and analysis of mobile malware. In 2018 IEEE/ACM
40th International Conference on Software Engineering (ICSE) , pages
384‚Äì394. IEEE, 2018.
[75] Hengshu Zhu, Hui Xiong, Y ong Ge, and Enhong Chen. Discovery of
ranking fraud for mobile apps. IEEE Transactions on knowledge and
data engineering , 27(1):74‚Äì87, 2014.
78
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:08:56 UTC from IEEE Xplore.  Restrictions apply. 