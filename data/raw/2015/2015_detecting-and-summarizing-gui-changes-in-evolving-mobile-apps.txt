Detecting and Summarizing GUI Changes
in Evolving Mobile Apps
Kevin Moran, Cody Watson, John Hoskins, George Purnell, and Denys Poshyvanyk
College of William & Mary
Department of Computer Science
Williamsburg, VA, USA
{kpmoran,cawatson,jbhoskin,gwpurn,denys}@cs.wm.edu
ABSTRACT
Mobile applications have become a popular software development
domain in recent years due in part to a large user base, capable
hardware,andaccessibleplatforms.However,mobiledevelopers
alsofaceuniquechallenges,includingpressureforfrequentreleases
to keep pace with rapid platform evolution, hardware iteration,
and user feedback. Due tothis rapid pace of evolution, developers
need automated support for documenting the changes made to
their apps in order toaid in program comprehension. One of themore challenging types of changes to document in mobile appsare those made to the graphical user interface (GUI) due to its
abstract,pixel-basedrepresentation.Inthispaper,wepresentafully
automatedapproach,calledGcat,fordetectingandsummarizing
GUI changes during the evolution of mobile apps. Gcat leverages
computer vision techniques and natural language generation to
accurately and concisely summarize changes made to the GUI of a
mobileappbetweensuccessivecommitsorreleases.Weevaluate
theperformanceofourapproachintermsofitsprecisionandrecallindetectingGUIchangescomparedtodeveloperspecifiedchanges,
and investigate the utility of the generated change reports in a
controlleduserstudy.OurresultsindicatethatGcatiscapableof
accurately detecting and classifying GUI changes – outperforming
developers – while providing useful documentation.
CCS CONCEPTS
•Softwareanditsengineering →Softwaredevelopmentpro-
cess management; Software development methods;
KEYWORDS
Mobile Apps, GUI changes, Software Evolution, Android
ACM Reference Format:
Kevin Moran, Cody Watson, John Hoskins, George Purnell, and Denys
Poshyvanyk. 2018. Detecting and Summarizing GUI Changes in Evolv-ing Mobile Apps. In Proceedings of the 2018 33rd ACM/IEEE International
Conference on Automated Software Engineering (ASE ’18), September 3–
7, 2018, Montpellier, France. ACM, New York, NY, USA, 11pages.https:
//doi.org/10.1145/3238147.3238203
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.32382031 INTRODUCTION
Mobile application development has solidified itself as a prominent
specializationsforsoftwareengineers.Infact,accordingtoStack-
Overflow’s 2018 survey of developers [ 1], over 20% of respondents
identified as mobile developers, making this the fourth most popu-
larspecialization overall,behindthree differentwebdevelopment
roles. This popularity is sustained by several factors including a
large and growing user base, performant hardware, powerful de-
velopment platforms and APIs, and ease of software distribution
through app marketplaces, just to name a few.
Highly competitive app stores like Apple’s App Store [ 5]o r
Google Play [ 10] contain millions of apps, many of which imple-
mentsimilarfunctionality.Inordertosucceedinsuchmarketplaces,
developersneedtoensuretheirapplicationprovidesanengaging
userexperienceandaestheticallypleasinguserinterface[ 13].Unfor-
tunately,paststudieshaveshownthatdesigningandimplementing
effective GUIs can be a difficult task [ 40,41,48], especially for
mobile apps [ 30]. These difficulties are due in large part to chal-
lengesuniquetothemobiledevelopmentprocessthathavebeen
well documented in research literature [ 23] and include: (i) rapidly
evolvingplatformsandAPIs[ 14,24],(ii)continuouspressurefor
newreleases[ 21,22],(iii)inefficienciesintesting[ 16,25,26],(iv)
overwhelmingandnoisyfeedbackfromuserreviews[ 18,19,42,43],
and (v) market, device, and platform fragmentation [2, 20,49].
Mobile GUIs are typically stipulated in files separate from the
main logic of the app (e.g., .xmlfor Android, and .nibor story-
boards for iOS). These files delineate attributes of GUI components
inrelativeterms( e.g.,displayindependentpixel dpivalues)andare
arrangedaccordingtoahierarchicalstructure(i.e., aGUIhierarchy)
tofacilitatereactivedesignacrossfragmenteddeviceecosystems.
Reasoning about the actual rendering of a GUI using such an ab-stract definition in code is a difficult task. Conversely, collecting
screenshotstodiscernvisualchangesisdifficult,asitrequiresman-
ualinterventionandadeptvisualperceptionisneededtodiscern
meaningful GUI changes. Thus, it is clear that comprehending how
GUI codeaffects the visualrepresentation ofan app requiresmen-
tally bridging a challenging abstraction gap.
Furthermore, the design and implementation of a GUI for a mo-
bileappisnota“singlecost”taskthatisperformedattheinception
of development. Instead, GUI-changes must evolve to keep pace
with constant user feedback and the evolution of the prescribed de-
signlanguageandguidelinesoftheunderlyingmobileplatform(e.g.,
Android’stransitionstodifferingversionsofmaterialdesign[ 9]),
thus developers must constantly evolve an app’s GUI to satisfy
changing design requirements. This illustrates that there is a clear
needforautomatedsupportineffectively documenting GUIchanges
543
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France K. Moran, C. Watson, J. Hoskins, G. Purnell, and D. Poshyvanyk
to help aid developers in time-consuming program comprehension
tasks related to mobile app development. In particular, automated
summarizationof visualGUI-changeswouldallowfordevelopers
tomoreeffectivelycomprehendtheaffectofcode-basedchanges
on the visual representation of a mobile GUI.
ToassistdevelopersincomprehendingGUIchangesinmobile
apps, we introduce a fully automated approach aimed at detecting,
classifying, and summarizing visual GUI changes between sub-
sequent app versions. Our approach, called Gcat ( GUIChange
AnalysisTool), is triggered upon a specified commit to a mo-
bile app’s version control system and performs a GUI differen-tiation analysis. This process begins by automatically executingthetargetapp,extractingarepresentativesetofscreenshotsand
GUI-metadata, and comparing these to similar files extracted from
a previous version of the same app using computer vision tech-niques. Gcat then generates a comprehensive report describingGUI changes that includes annotated screenshots, a natural lan-
guagesummaryofGUIchanges,andavisualizationofmatching
segments of each screen’s GUI hierarchy.
We performed an extensive evaluation of Gcat across several
different quality attributes. First, we empirically examined the per-
formance of Gcat in terms of (i) automatically extracting/filtering/
matching screens and (ii) detecting and classifying GUI changes
fromasetof31mobileappsfromtheF-Droid[ 6]repositoryofopen
sourceapps.Nextweperformedauserstudymeasuringdevelopers’
performance in detecting and classifying mobile app GUI changes,
and the perceived usefulness of the GUI change summarization
reportsproducedbyGcat.OurresultsindicatethatGcatisable
to (i) accurately and automatically extract, filter and match screens
betweensubsequentversionsofAndroidapps,(ii)effectivelydetect
and summarizeGUI-changes, (iii)outperform developersin terms
of identifying, detecting, and classifying GUI changes, and (iv) au-
tomaticallygenerateGUIsummarizationreportsthatdevelopersfound useful in comprehending GUI changes. In summary, this
paper makes the following contributions:
•WeintroduceGcat,afullyautomatedapproachfordetect-ing,classifying,andsummarizingGUIchangesinevolving
mobile apps;
•We conduct acomprehensive evaluation of Gcat that mea-
sures its detection and classification performance compared
to developers, and the perceived usefulness of Gcat reports;
•WederiveasizabledatasetofGUIchangesisolatedfromreal
FOSSappswhichcanfacilitatefutureresearchinprogram
comprehension related to mobile GUIs;
•We make available an online appendix [ 4] that includes ad-
ditional materials such as examples of reports generated by
Gcat,anopensourceversionofourapproach,andallstudy
data to facilitate reproducibility.
2 BACKGROUND & PROBLEM STATEMENT
In general, the goal of the approach set forth in this paper is to
automaticallydetect,classify,andsummarizechangesthatoccurin
theGUIofanevolvingmobileapp.Ourapproachiscurrentlyim-
plementedforAndroid(themostwidelyusedOSintheworld[ 11])
despitebeingapplicabletootherplatformssuchasiOS.Thus,inthis
paper we examine the principles of mobile GUIs and GUI changes
in the context of Android.
Relative 
Layout
TextView
 TextView
 Linear 
Layout
Image
Button
Image
Button
Image
Button
Partial GUI Hierarchy 
for the Pandora Application
GUI-ComponentGUI-Container
Figure 1: Illustration of the GUI Structure of the Pandora
Android Application
2.1 Mobile GUI Fundamentals
InthecontextofAndroidtherearetwobasiclogicalconstructsthatcomprise the GUI of a mobile app, which are illustrated in Figure 1.
The first of these is a GUI-component. GUI-components (used inter-
changeably with the term “component" in this paper) have been
definedinpriorworkas“atomicgraphicalelementswithpre-definedfunctionality,displayedwithintheGUIofasoftwareapplication "[
33].
In the context of Android there are several differenttypes of com-
ponents, such as TextViews ,Buttons, and NumberPickers . Each of
these serves a distinct set of purposes. For instance, a Buttonis
typically used to trigger certain functionality from the code, and
aNumberPicker allowsa userto selectfroma pre-definedrange of
numbers as input. In addition to their typethere are also several
stylistic detailsthat define acomponent, such asa displayedimage,
colors, or font. Two TextView components and three ImageButton
components are shown highlighted in green as part of the GUI for
thepopularPandoraMusicappinFigure 1.Asthisfigureshows,
each component has a bounding box that stipulates the area occu-
piedbythecomponent,thisistypicallydefinedbyspatialcoordi-
natessuchasthe xandycoordinatesofthetopleft-handcornerof
the box, and its widthandheiдht.
However, GUI-components are not the only building block that
compriseamobileGUI.Therealsoexist GUI-containers,whichhave
been succinctly defined in prior work as “ A logical construct that
groups members of GUI-components and typically defines spatial
display properties of its members "[33]. Thus, GUI-containers are
largely meant to help provide a spatial structure to the GUI and
define stylistic details regarding the background or canvas upon
which GUI-components are rendered. GUI-components are typi-
cally rendered on a screen according to the spatial properties of
theircontainers,ratherthanpredefinedscreencoordinatevalues.
Thisallowsforamoreflexibledesignthatcanfluidlyadaptbetween
devices with different display dimensions and densities. Two GUI-
containers,a RelativeLayout anda LinearLayout arehighlightedin
red for the Pandora App in Figure 1.
Whentakentogether,GUI-components,andGUI-containerscom-
pose aGUI-hierarchy, which typically takes the form of a rooted
treewheresmallercomponentsandcontainersexistwithinasingle
container that serves as the root of the hierarchy. In Figure 1,a
544
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. Detecting and Summarizing GUI Changes in Evolving Mobile Apps ASE ’18, September 3–7, 2018, Montpellier, France
Table 1: The taxonomy of GUI changes used in the development and evaluation of Gcat
Change Category Specific Change Description
Text ChangeText Change The text content of a component from a previous version of the app does not match a later version
Font Change The text font of a component from a previous version of the app does not match a later version
Font Color Change The text font color of a component from a previous version of the app does not match a later version
Layout ChangeVertical Translation The location of a component was translated in the vertical direction between versions of an app
Horizontal Translation The location of a component was translated in the horizontal direction between versions of an app
Vertical Size Change The size of a component was changed in the vertical direction between versions of an app
Horizontal Size Change The size of a component was changed in the horizontal direction between versions of an app
Resource ChangeImage Color Change The color of an image associated with a component changed between versions of an app
Removed Component A component was removed between versions of an app
Added Component A component was added between versions of an app
Image Change The image associated with a component was changed between versions of an app
Component Type Change The type of a component changed between versions of an app
A) Version 3.0.0 B) Version 4.6.2
Figure 2: Illustration of GUI changes in FastHub
partial GUI-hierarchy for the Pandora app is illustrated as a tree.
Inthis hierarchy,the RelativeLayout servesas therootnode with
otherGUI-componentsandcontainersfillingoutthetree.Asstated
earlier, the GUI-hierarchies for mobile apps are typically defined
in a domain specific language outside ofthe functional code of an
app. In Android, properties of the GUI are stipulated in xml files
in the app resource directory (e.g., /res/layout ) using a domain
specificxmlformat.WhenanAndroidapp’sGUIis renderedona
device screen, metadata describing the GUI (including information
suchasthecoordinatesofrenderedcomponents,theirtypes,and
whetherornottheyareinteractive)canbereadfromadeviceusing
theuiautomator framework.Itisimportanttonotethatthereare
distinctdifferencesbetweenthestaticanddynamicrepresentations
of an app’s GUI. Full information regarding the appearance of a
GUIcannotbegleanedfromthestatic-coderepresentationalone,
asthisinformationisdefinedinrelativetermsandtheGUImustbe
interpreted and instantiated for target screen attributes. Further-more, components such as lists can be dynamically populated at
runtime, which impacts GUI appearance.
2.2 Evolutionary GUI Changes
Now that we have described the basic building blocks of mobile
GUIs, it is important to understand how GUI-changes affect these
building blocksand how theymight belogically categorized. Ata
high-level,a GUI-change canbedescribedasanymodificationto
the spatial or stylistic properties of a GUI-component or container.
There are a finite number of logical manners in which components
canbealteredbetweenappversions.Inordertoaccuratelydescribe
GUIchanges,itisimportanttostipulatedifferentcategorizations
of changes that might occur.
To dothis, welook topast workon detectingdesign violations
in mobile apps [ 30]. Adesign violation in the context of mobileapps has been defined as a mismatch between the attribute vectors
of two GUI-components that exist both in a mobile GUI mock-up and implementation, where the attribute vectors can be rep-resented as a a four-tuple in the form (
<x-position,y-position >,
<height,width >,<text>,<image>)[30].Inthisworktheauthors
performed a grounded-theory survey on an industrial dataset of
design violations and derived a taxonomy. Given that in this work,
a design violation essentially describes a changein a mobile GUI
(albeitoneintroducederroneouslybyadeveloper),weadaptthis
taxonomytodescribe GUI-changes thatsurfacebetweensubsequent
versions of a mobile app.
Our GUI-change taxonomy is described in Table 1and consists
of three main categories: (i) Text Changes that concern differences
in text displayed by components, (ii) Layout Changes that con-
cern differences between the spatial properties of components, and
(iii)Resource Changes that describe phenomena such as missing
or added components, or differences between utilized images or
colors. Each of these three main categories has a subset of specific
change categories, which directly describe a GUI-change. It should
be noted that more than one GUI-change can apply to a single GUI
component. For instance, a component might change in size and
location between app versions. Some examples of GUI-changes
between subsequent app versions of the popular FastHub GitHub
clientareillustratedinFigure 2.Forexample,the“AccessToken"
TextView component exhibits a Layout Change, whereas the the
“Enterprise" TextView component representsan Added Component
change. The TextView component, which displays “Sign in using
yourGitHubaccounttouseFastHub",exhibitstwochangetypes,
namely a Text Change and aSize Change.
Given this background on mobile GUIs and our GUI-change
taxonomy our problem statement can be formulated as follows:
Problem Statement: Given an Android app with a change history
V1,V2...Vi, our approach aims to automatically extract screenshots
andGUImetadatafortwoversions ViandVksuchthat k>i.Then
our approach aims to filter corresponding screens between the twoversions and detect, classify, and summarize GUI changes between
corresponding pairs of screens.
3 THE GCATAPPROACH
TherearethreemaincomponentsoftheGcatapproachdepicted
inFigure 3,(i)VersionControlIntegration,(ii) AutomatedGUI-Based
Exploration,and(iii) GUIInterpretationandChangeDetection.Gcat
is able to analyzesubsequent commits from a software repository
545
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France K. Moran, C. Watson, J. Hoskins, G. Purnell, and D. Poshyvanyk
1   Integration with Version Control
Git/CI 
Integration2   Automated GUI-Based Exploration
Project HistoryVirtual or Physical Device Pool
N1
N2
N3N4N5 T7T3
T17T35T12
T25T42
T59T29
T21N6CrashScope
Automated
Execution 
Engine
Screenshot & Metadata 
Pairs - Commit i
Screenshot & Metadata 
Pairs - Commit i+n3   GUI Interpretation & Change Detection
Screen Matching
& Filtering
Activity/
Window
Comparator
Bipartite 
Image
ComparisonGUI-Hierarchy for
Commit iGUI-Hierarchy for
Commit i+n
Leaf Node Component 
Detection and Matching 
GUI Change Resolution
Perceptual Image 
Differencing (PID)
GUI-Change Report
Layout Change 
DetectionText Change 
DetectionResource Change 
Detection
NL Summary Generator
Checks:
<x>,<y>
Checks:
<width>,<height>Normalized 
String 
Comparison
Image 
Comparison
Analysis
Commit iCommit i+1Commit i+2Commit i+n
Figure 3: Overview of the GcatApproach
that utilizes a version control system such as Git, and automat-
ically compiles and executes target commits. It then filters and
matches screens discovered during automated exploration of a tar-
get app’s GUI, and finally detects and reports changes related toGUI-components. Gcat was implemented for the Android plat-formandiswritteninJava.Itwasdesignedtoallowforincorpo-ration into Continuous Integration and version control systems
to facilitate fully automated generation of documentation. From a
developer’s perspective, Gcat would simply need to be installedon a developer’s machine or integrated into continuous integra-
tion (CI) pipeline, and frequency of analysis specified (e.g., running
on each commit, or major releases, etc.). Then developers could
viewtheweb-basedGUI-change reportseitherlocally,orvia aCI
system,inorder tomoreeffectivelycomprehend theGUI-changes
between subsequent app versions. In this section we describe each
component of the Gcat approach.
3.1 Integration with Version Control
In order to provide practical automated documentation of GUI
changesasamobileappevolves,Gcatcantakeadvantageofthe
versioncontrolsystem ofatargetmobile app’ssoftware repository.
Furthermore, Gcat could be triggered in a Continuous Integration
Pipeline such as TravisCI [ 12] or GitLab’s CI framework [ 8], as
illustrated in Figure 3-1. In order to derive and document changes
in a change report, Gcat accepts two subsequent commits iand
i+nwherenrepresents the number of commits between analyzed
versions.Whenanewrepositoryiscreated,orGcatisaddedtothe
CIsystemofanexistingrepository,Gcatautomaticallycompiles
and performs automated GUI-based exploration of the most recent
commitoftheprojectandcachesextractedscreenshotsandGUI-
relatedmetadata.Additionally,adevelopermaystipulatethatGcat
analyzesubsequentpairsofhistoriccommits.Thechoiceofhow
frequentlytorunGcatislefttothedeveloper.InSection 4wedetail
our experimental methodology for deriving subsequent commits.
3.2 Automated GUI-Based Exploration
OncetwocommitshavebeenisolatedfromanAndroidapp’srepos-itory,screenshots,andmetadatadescribingtheprogrammaticstruc-
ture ofthe GUI-hierarchy associated with thesescreenshots must
beautomaticallyextracted.Then,onceasetofscreenshasbeenex-tracted,corresponding screensfromthepairoftargetcommitsmustbematchedwithoneanother,andredundantscreensmustbefil-
tered out, in order to reduce the information burden on developers.
This process is illustrated in Figure 3-2.
3.2.1 Automated GUI-Exploration. In order to automatically ex-
plore the GUI of a target app, Gcat makes use of the Crash-
Scope[31,32]GUI-explorationengine.CrashScope’sautomated
exploration simulates touch events on a mobile device or emula-
tor to explore the screens of a target app. To do this effectively,
theCrashScopeengineperformsasystematic,depth-firstsearch
(DFS) exploration of an app’s GUI that has been shown to achieve
comparable coverage to other testing approaches [ 31]. During this
explorationprocess,theGUIofanappisanalyzedinrealtimeusing
Android’s uiautomator [3] framework. Interactive components are
identified, and an event-flow model of an app is constructed in an
online manner. DFS exploration proceeds according to a given set
ofparametersknownasan explorationstrategy .Inouradaptation
of CrashScope’s exploration engine for Gcat, we utilized two
variations of the DFS GUI traversal, a top-down variation where
interactive components are exercised from the top of the screendown, and a bottom-up variation, where interactive components
are exercisedfrom thebottom ofthe screenup.Two variationsof
text-input strategies were utilized, one strategy generated expected
textbyinputtingallowablecharactersaccordingtoparametersof
a given text field, and another strategy generated no textto be
input to text fields. We chose not to implement other strategies
fromtheoriginalCrashScopeexecutionengineduetothefactthat
these strategies were more likely to discover crashes from a target
app, and our objective in Gcat is not crash detection, but rather
state exploration. The selected exploration and text input strate-
giesexhibitedhighercoverageinpastwork[ 31].Foreachaction
thatCrashScopeexecuteson adevice,a screenshot,and dumpof
the GUI metadata from uiautomator are saved before and after the
action’sexecution.ThissetofscreenshotsandGUI-metadataare
then passed to the screen matching and filtering procedure.
Currently, Gcat only supports GUI comparisons between corre-
sponding screens captured on the same device. However, it should
be noted that the automated exploration for Gcat can be run on
aconcurrentsetofvirtualAndroiddevicesthatsimulatearange
of screen sizes/densities in order to extract GUI information for
a predefined set of device configurations. Gcat reports can then
begeneratedfor corresponding screenpairsonaper-devicebasis.
546
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. Detecting and Summarizing GUI Changes in Evolving Mobile Apps ASE ’18, September 3–7, 2018, Montpellier, France
Furthermore,Gcatcouldbeadaptedtoutilizeasetofpre-specified
automatedGUItestsusingatestwrapperthatcapturesscreenshots
and uiautoamtor files after each test case step.
3.2.2 Screen Matching and Filtering. Using the screenshot and
metadatapairsthatcanbegeneratedforagivenpairofcommits,
correspondingscreens (screensthatretainhighlysimilarintended
functionality) can be identified between commits for which useful
changereportscanbederived.Wemodelthisprocessasabipartitematchingproblem,wherethecostofanassignment
Cbetweenany
two screen pairs s1,s2is the sum of two values:
C(s1,s2)=CD+BBOX dif f (1)
whereCDisequaltotheEuclideancolordistancebetweenthetwo
images,and BBOX dif fisequaltothe normalizedpixeldifference
between two binary images b1andb2, created by drawing white
filledrectanglescorrespondingtotheboundingboxesoftheleaf
nodecomponentsontoablacksilhouetteofthescreen.Eachbound-
ing box will only be drawn if its total area is less than 100k pixels,to avoid large overlay components from affecting the analysis.
Bothconstituentsoftheassignmentscoreareorthogonallybene-
ficial:CDisabletocapturepurevisualsimilarity,butisapoormea-
sureofmatchingpotentialinexampleswheretherearealargenum-
ber ofcolorchanges. Forthese cases,we needa wayto utilizethe
structuralinformationofthescreenshotsprovidedby BBOX dif f.
Both sets of nodes in our bipartite graph correspond to the screen-
xml pairs for their respective commits. The edge weights between
each node are equal to C(si,sj)for alli,jin each set. Once the
graphisconstructedasanadjacencymatrix M,wefindamatching
αsuch that it minimizes the sum cost of all assignments.
The optimization algorithm used in our implementation runs
inO(n3)time.Inaddition,thesetsofscreensfromtargetpairsof
subsequent commits may be quite large. Thus, in order to make
thisprocessdramaticallymoreefficient,wedefinedalightweight
heuristic to cut back on superfluous screens and reduce the size of
the sets. During each step in the automatic GUI exploration, thenameofthecurrentactivityisrecorded,aswellasthenameandtype of the currently active window (e.g.,
FRAGMENT,POPUP). This
informationwas extractedat eachstep ofthe executionusingthe
adb shell dumpsys window windows command.Usingthisinforma-
tion,wefilterourscreensetssuchthatonlyscreen-xmlpairsthat
representthefirstoccurrenceduringtheautomatedexecutionof
a unique(activity, window)pair are kept.All others arediscarded.
From a developer’s perspective, GUI-change reports will only be
generatedformatchedscreens,however,Gcatcouldalsobecon-
figuredtoallowadevelopertoexamineunmatchedscreenspairs
and trigger the change analysis for these pairs.
3.3 GUI Interpretation & Change Detection
Once corresponding screen pairs between a target pair of com-
mits have been extracted using Gcat’s automated GUI exploration
and screen matching and filtering techniques, Gcat then needsto identify the GUI-changes that occurred between these screenpairs. To do this, Gcat decodes the hierarchical representationof the GUI represented in a given screenshot using data from
uiautomator xmlfiles.Itthenidentifiesandmatchescorresponding
GUI-components between screen pairs, analyzes corresponding
componentsforchanges,andclassifiesthesechanges.Finally,anhtml-basedGUIchange reportisgeneratedcompletewithimages
and natural language descriptions of changes. This process is visu-
alized in Figure 3-3.
3.3.1 GUIHierarchyConstruction&ComponentMatching. Fora
given corresponding screen pair Gcat parses the uiautomator xml
filesassociatedwitheachscreenshotandconstructsatree-based
representationoftheGUI-hierarchy.Itthenparsesandstorescol-
lections of leaf node components for each screen, including several
attributes such as location information (e.g., <x,y><width,height> )
and the component type (e.g., ImageButton ). As stated earlier, Gcat
reports GUI-changes according to leaf node components, as they
tend toalso reflect changesto container components. Thus, Gcat
employsa k-nearestneighborsmatchingprocedurebasedonspatial
componentinformationthathasprovensuccessfulinpastworkon
reportingGUIdesignviolationsformobileapps[ 30].Duringthis
procedure, each component is matched against its closest neighbor
according to the following simialrity score:
γ=(|xm−xr|+|ym−yr|+|wm−wr|+|hm−hr|)(2)
where a smaller γrepresents closer matches. The x,y,wandh
variables correspond to the x&ylocation of the top and left-hand
borders of the bounding rectangle, and the height and width of the
bounding rectangles for components respectively.
3.3.2 GUI-Change Resolution. After corresponding pairs of leaf
nodecomponentshavebeenidentified,GcatmustthendetectGUI
changes between screens. Gcat first employs Perceptual Image
Differencing (PID), an image differencing algorithm modeled after
the human visual system that has been successfully applied in past
researchondetectingGUIdifferences[ 28–30].PIDhelpstoidentify
asetofpotentialchangesbasedonvisualdifferencesbetweenim-
ages.Then,eachofthesepotentialGUIchangesisanalyzedfurther
to determine the specific type of change to report. This in-depth
analysis varies depending upon the type of change. These analyses
have been adapted from prior work on detecting GUI design viola-tions [
30] to work with GUI metadata from corresponding screens
extracted from commits of a target app.
LayoutChanges :Identifying LayoutChanges isrelativelystraight-
forward. Gcat simply compares the <x,y>and <width,hieght> val-
uesforeach pairofcorrespondingleaf components.Ifdifferences
inx,y,widthorhieдhtvary by more than a threshold LC, then a
Layout Change is reported.
Text Changes :Therearethreedifferenttypesoftextchanges:(i)
Font Color change, (ii) Font Style change, and (iii) Text Content
change.Eachofthesespecifictypesisdetectedinadifferentmanner,
but all utilize cropped images for each pair of potentially changed
text components by cropping an image from both previous and
subsequent screenshots according to the bounding boxes of the
components in question. To check for a Font Color change, a color
histogram (CH) is constructed for each cropped image by accumu-
latinginstancesofalluniqueRGBpixelvalues.Gcatthencalculates
the normalized Euclidean distance between these color histograms,
and if the distance is greater than a threshold FCa Font Color
changeisreported.Ifthecolorhistogramsdomatch,thenaFont
Stylechangeisreported.TodetectchangesinTextContent,strings
betweentextcomponentsarepre-processedtolowercase,spaces
areremoved,andtheresultingstringsarecompared.Ifthestring
547
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France K. Moran, C. Watson, J. Hoskins, G. Purnell, and D. Poshyvanyk
values do not match, a change is reported. Our implementation of
Gcat uses an FCvalue of 85%.
Resource Changes : Gcat is able to report 5 different types of
Resourcechangesincluding:(i)AddedComponents,(ii)Removed
Components,(iii)ImageColorchanges,(iv)ImageChanges,and(v)
ComponentTypechanges.Leafnodecomponentsthatareaddedto
a subsequent version of an app correspond to components without
a matched corresponding component. Thus, these are reportedas Added Component changes. Likewise, Missing Componentsare those components from the previous version of the app that
were not able to be matched to components in the subsequent
version. Image Changes are detected by extracting cropped images
of components in question from screenshots of both versions of an
app. Then, these cropped images are converted to a binary color
space (e.g., black and white) and PID is run again. If the images
do match according to PID within a threshold ICthen an image
change is reported. Otherwise a color change is reported. In our
implementation of Gcat IC=20%.
3.3.3 Natural Language Summary Generation. The GUI change
reports generated by Gcat contain a NL summary, as well NL
descriptions of each identified change. Gcat’s natural language
summariesof allGUI-changesincludeadescriptionofboth what
happened, as well as whereit happened. To do this, Gcat identifies
thepartsofagivenscreenthatcontainthemostchanges.First,thescreenisdividedintoacongruent3x3gridandchangesareassigned
to each grid region. If no grid section in the 3x3 division contains a
majorityofchanges,thescreenisdividedintoacongruent2x2girdandtheprocessisrepeated.ThishelpstoinformtheNLdescription
ofwherechanges occurred.
After changes are isolated to particular areas of the screen, they
need to be effectively summarized. We use a heuristic-based ap-proach for general summarization. Each change is described by
threecharacteristics:1) Level-astringdescribinghowmuchthe
GUIs changed visually; 2) Location- the location on the screen that
changed the most; and 3) Amount- a string describing the number
of changes made to the GUI.
Dependingonthevaluesoftheaforementionedcharacteristics
our processdetermines which formthe template will take.An ex-
ample summary is given in Figure 4. We forgo an enumeration
of the template and potential combinations due to space limita-
tions,however,thisisshowninourappendix.NLdescriptionsof
individualGUI-changetypesaregeneratedaccordingtodifferent
templates specific for each change type.
3.3.4 ReportGeneration. Gcatgenerates htmlbasedreportsthat
enumerate GUI changes in four major ways, three of which areillustratedbytheexamplereportinFigure 4.Thefirstoftheseis
a set of full screenshots depicted at the top of the report, where
the previous and subsequent screens are shown on the left and the
right respectively, and the middle screenshot highlights changes
fromtheperspectiveofthepreviousversionscreenshot.Thesecond
piece of information reported is the NL summary of changes in
the GUI. The third piece of information is a list of detailed changes
on a component-by-component basis. These include both a NLdescription and, if clicked on, a side by side comparison of thecomponents in the old and new version of the app. Finally, the
Figure 4: Partial Example of a Report Generated by Gcat
fourthpieceofinformation(notshowninFigure 4)isthemaximum
common spanning tree of the screen pair GUI hierarchies.
4 DESIGN OF THE EXPERIMENTS
The overarchinggoal of Gcatis todetect, classify and summarize
GUI changes that occur in mobile apps as they evolve. Thus, toevaluate Gcat, we carry out an empirical study aimed at investi-
gating the performance of the approach, and a user study aimed at
analyzingGcat’s usefulness todevelopers. Tothis endwe explore
the following four RQs:
•RQ1:How well does Gcat’sscreen matching and filtering
procedure function?
•RQ2:Howwelldoes Gcatperformintermsofdetectingand
classifying GUI changes that occur during the evolution of
mobile apps?
•RQ3:IsGcatable to more accurately detect and classify GUI
changesinevolvingmobileappscomparedtomanualefforts
from developers?
•RQ4:Do developers find Gcatreports useful for documenting
and summarizing GUI changes in evolving mobile apps?
In the context of our study, RQ 1,R Q2, and RQ 3are directed
towardquantitativelymeasuringhowwellGcatperformsinterms
of extracting screens and detecting and classifying different types
of GUI changes that occur during the evolution of Android apps.
RQ4isaimedatqualitativelymeasuringtheperceivedusefulnessof
Gcat reports by collecting feedback regarding the user experience
andpreferences.TocollectuserdatatohelpanswerRQ 3&RQ4we
conducted a user study in the form of an online survey.
548
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. Detecting and Summarizing GUI Changes in Evolving Mobile Apps ASE ’18, September 3–7, 2018, Montpellier, France
4.1 Study Context
In order to evaluate Gcat, we required a set of popular subject
applications from which a collection of GUI changes for particular
screensbetweensubsequentappversionsexist.Toderivethisset
of screens, we utilized a set of 31 applications from FDroid [6].
Tocollecttheseapps,threeauthorsmanuallycrawledorthogo-
nal sections of FDroid and downloaded the set of available release
apksfor each app. In order to facilitate controlled experimentation
and ensure a sizable set of screen pairs with existing GUI changes,
the same authors launched subsequent versions of the apps on
concurrent Nexus 7 (2013) emulators running Android 6.0 from
Genymotion[ 7],andensuredthatatleastonecorrespondingscreen
pair between the two versions exhibited a GUI change. Apps with-out any version pairs that could be launched on the emulator, that
were hybrid apps, used non-standard components, or that did not
exhibit any GUI changes were discarded. This process resulted in a
setof62 apkscorrespondingtoprogramversionsfrom31apps.We
provide detailed information about these apps, and make all of our
study data available in our online appendix [4].
4.2 RQ 1: Evaluating Gcat’sScreen Matching
and Filtering
TomeasurehowwellGcat’sscreenfilteringandmatchingproce-
dure function, we ran each of the 62 apksextracted for the study
throughthesystematicautomatedinputgenerationapproachde-
rived from the CrashScope. The average time per app for running
thisexplorationstrategyandextractingthescreenshotsandGUI
metadatais39.46minutesperapp.However,itshouldbenotedthis
process is completely automated and can be run passively in the
background.Wethenmeasuredtwometrics:(i)thepercentageof
filteredscreens( FS),and(ii)thematchingprecision( MP).TheFS
metric measures the number of redundant screens filtered and the
MPmetric illustrates the number of correctly matched correspond-
ing screens. More formally, these metrics can be represented as:
FS=TS−FS
TS×100MP=Tp
Tp+Fp(3)
whereTSisthetotalnumberofscreensdiscoveredbyCrashScope,
FSis the number of screens filtered by Gcat, Tpis the number
ofcorrectlymatchedscreens,and Fpisthenumberofincorrectly
matched screens. One author examined the matched screens pairs
from Gcat in order to determine the TpandFp, whereas the other
metrics can be calculated automatically.
4.3 RQ 2: Measuring the Performance of Gcat
Themain goalofthis RQisto examine howwellGcatperformsin
terms of detecting and classifying real-world mobile GUI changes.
InapracticalusecaseofGcat,theentireGUI-changereportgen-
eration process is automated, from the extraction of corresponding
screenpairs,tothereportgeneration.Thus,ininvestigatingthisRQ
weaimedtoemulatethisautomatedcontextbyusingtheoutputof
Gcat’s screen matching and filtering procedure carried out as part
of the previous RQ 1.
Gcat’sscreenfiltering/matchingprocedure resultedinasetof
screen pairs consisting of <screenshot,GUI-metadata >tuples for
correspondingscreensbetweendifferingapplicationversions.Gcat
was then applied to screen pair tuples that were correctly matched
a) Previous application menu bar
b) New application menu bar
Figure 5: Illustration of a Potential Ambiguous GUI-change
andtheGUI-changesummarizationreportsweregenerated.During
thegeneration process,wealso measuredthetime takenbyGcatto generate each report.
TomeasuretheperformanceofGcatindetectingandclassify-
ingGUI-changes,threemetricswerecalculated:(i)theDetection
Precision ( DP), (ii) the Classification Precision ( CP), and (iii) the
Recall(R).TheDPmeasureshowwellGcatcandetectGUIchanges,
whereas the CPmeasures how well detected changes are classified
intotheircorrespondingtypes.Wemakethisdistinctionbecause
Gcatiscapableofdetecting,butincorrectlyclassifyingcomponent
changes intotheir proper types. DP,CPandRwere measuredas:
DP,CP=Tp
Tp+FpR=Tp
Tp+Fn(4)
where for DP,Tprepresents GUI changes that were detected by
Gcat, and for CP,Tprepresents GUI changes that were both de-
tectedandcorrectlyclassifiedintheirpropertype.Foreachofthese
metrics,Fpcorresponds to detected GUI-changes that either did
not exist or that were misclassified respectively. For Recall, Tprep-
resentsGUIchangesthatwerecorrectlydetectedand Fnrepresents
existing GUI changes in the ground truth that were not detectedby Gcat. Due to the cost of calculating these metrics, explainedbelow, we randomly sampled 18 screen pairs from the correctly
matchedcorrespondingscreenstoanswerRQ
2.Tofacilitatethis,
we ran each of the screen pairs through PID and ranked them in
threeGUI-changegroups (High,Medium,andLow)accordingto
the rank of the percentage of difference pixels reported by the PID
procedure. Screen pairs classified in the High group exhibited a
high amount of pixel difference according to PID and thus a larger
numberofGUI-changes,whereastheLowgroupexhibitedalow
amount of pixel difference according to PID and thus had a low
number of GUI changes. We randomly sampled an even number
from each group to provide for a varied set of GUI-changes.
4.3.1 Metric Collection Procedure and GUI Change Ambiguities. In
order tocollect these metrics,it is necessaryto manually examine
eachpairofcorrespondingscreensbetweenversionsandgenerated
reports. However, this isa veryexpensive manual procedurethat
involvesevaluators visuallyexamining screenshots,and inspectingGUI-metadatainordertocalculatethemetricslistedabove.Further-
more, classifications of GUI-changes between subsequent versions
of an application are open to multiple subjective interpretations,
which may impact their calculation. For example, take the menu
baroftheSgitapplicationshowninFigure 5.ThisGUI-changeis
relatively simple, an additional icon
 was added in the new app
version.Ho wever,this couldbeinterpretedinmultiplemanners.For
example, one interpretation may be that the
 icon was changed
tothe
 icon,anew
 wasadded,andthe
 iconwasshiftedto
theleft.Anotherinterpretationmaybethatthe
 iconwasadded
and the
 and
icons were shifted to the left. Both of these are
549
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France K. Moran, C. Watson, J. Hoskins, G. Purnell, and D. Poshyvanyk
valid interpretations of the GUI change. In fact, during our experi-
mental investigation we came across different types of GUI Change
Ambiguities thatmayleadtomultipleinterpretations.Weforgoa
detailed discussion of all ambiguities, but provide descriptions and
examples in our online appendix [4].
Inordertoeffectivelycollecttheevaluationmetricslistedearlier,
we took several measures to ensure accurate calculations. First,
wedevelopedatoolthatparsesinformationfrombothscreensin
a corresponding screen pair and prints formatted readouts that
list each GUI-component, its corresponding spatial metadata, a
croppedimageofthecomponent,andthePIDoutputinorderto
helpinmanualcalculationofthesemetrics.Second,forRQ 2and
RQ3,wesimplyaccepted anycorrectinterpretationofaGUIchange
as correct when calculating the DPandCP. Third, we employed
multipleindependentmanualevaluatorstoexaminethereportsandscreenpairstocalculatethemetrics.Morespecifically,twoauthors
independentlycalculatedthemetricsfor eachscreenpair.Thena
third author evaluated the responses from the first two evaluators,
anddeterminedthefinalcalculationsfromthecombinedresponses.
4.4 RQ 3: Measuring Developer Performance in
Detecting and Classifying GUI Changes
Themain goalofthisRQistocomparetheeffectivenessofGcat
to developers at detecting and classifying GUI changes. In order
tocarryoutthiscomparison,weneededtoexaminehowwellde-
velopers are able to comprehend and report changes in the GUIs
of mobile apps. Thus, we conducted a user study in the form of
an online survey consisting of four major components: (i) A Back-
groundcomponent that introduced the concept of a GUI change
andourtaxonomyofGUI-changetypes;(ii)A Demographic compo-
nent that asked participants about their programming background;
(iii) AGUI-comprehension component that asked participants to
examine pairs of screenshots containing changes and documentthese changes; and (iv) a Report Feedback component that asked
participants to examine Gcat reports and answer questionsabout
their usefulness. The GUI-comprehension component of this user
studyhelpstoanswerRQ 3,whereasthe ReportFeedback component
helpstoanswerRQ 4andisexplainedinfurtherdetailinthenext
subsection. 20 faculty and graduate student participants with at
least three years of programming knowledge were recruited across
3 different universities.
To derive the screen pairs to be used in both parts of the user
study,threeauthorsexecutedconcurrentcorrespondingversionsof
each of the 31 apps and identified at least one screen pair between
the two versions that contained a GUI change. For each identi-
fied screen pair with GUI-changes, a screenshot and GUI-metadata
file were extracted using the Android Debugging Bridge’s ( adb)
screencap utilityandthe uiautomator frameworkrespectively.This
resulted in a set of 50 app screen pairs. Note that we did not use
CrashScope and Gcat’s filtering procedure to produce this set of
screens, in order to control the quantity of pairs for the user study.
Given that the set of screen pairs extracted for the user study
were taken from subsequent versions of real apps, the extent to
whichthe GUIchangedvaries acrossthedataset. However,in the
contextofthe GUI-comprehension userstudy,wewanttounderstand
the extent to which each participant can comprehend both simpleandcomplexGUI-changes.Thus,similartotheprocedureusedin
RQ2, we divded the screen pairs into three groups according to
thePIDscore.Forthe GUI-comprehension componentoftheuser
study, we randomly selected 30 screen pairs from the candidate set
of50,ensuringthatthe30screenswereevenlydistributedacross
the three GUI-change groups. Each participant in the study was
assigned3screensfromthissetandthescreenswereassignedin
such a manner that each screen was evaluated by two participants,
eachparticipantevaluatedoneHigh,oneMedium,andoneLow
fromeachGUI-changegroup,andtheorderinwhichthescreens
were presented to participants was randomized.
During the GUI-comprehension component of the survey, par-
ticipantswereaskedtoexamineeachscreenpairandreporteach
GUI-change according to the taxonomy presented at the beginning
of the survey. The GUI change taxonomyto be used was repeated
onthesurveyscreenwhereparticipantsdescribedtheGUI-changes
for reference. Each screen pair was accompanied by a text input
box where participants were instructed to record one GUI-change
per line in the form, <GUI-Change category >:<Description of the
GUIchange >.Afterallsurveyresponseswerecollected,the DP,CP,
andRforeachparticipantwascalculated.Threeauthorsderived
thegroundtruthandtheevaluationmetricsforthesetofuserstudy
screens following the same methodology as in Sec. 4.3.
4.5 RQ 4: Investigating Perceived Developer
Usefulness of GcatReports
Thegoalof this RQ is measure the perceived developer utility of
Gcat reports. This was carried out through the Report Feedback
component of the user study survey. For this component of the
survey,eachparticipantwasshowntwoscreenpairs,andthecorre-spondingGcatreportforthesescreens.Theparticipantswerethenasked5Likert-based userexperience(UX) andfivefree-response user
preference(UP) questions,whichwerederivedfromSUSusability
scale introduced by Brooke [ 15], and the user experience honey-
comb by Morville [ 39] respectively. The screen pairs for the Report
Feedback componentoftheuserstudysurveywerecomprisedofthe
20remainingscreensafterthesamplingforthe GUI-Comprehension
component.Screenswereassignedtoparticipantsinsuchamannerthateachscreenpairandreportwereevaluatedbytwoparticipants,
screenpairsweredistributedasevenlyandrandomlyaspossible
across the GUI-change groups.
5 EMPIRICAL RESULTS
5.1 RQ 1: Performance of Screen Filtering and
Matching
OurfirstRQinvestigatestheperformanceofGcat’sscreenfiltering
andmatchingprocedure.RunningCrashScopethroughall61of
our subject apksresulted in 3,854 total extracted screens, or ≈63
screens per apk. Gcat’s filtering procedure was able to reduce this
settoamuchmoremanageable316screensforthematchingproce-
dure. This results in an FSmeasurement of (3,854−316/3,2854)∗
100=91.8%,meaningthatover90%ofthecollectedscreenswere
filtered out as redundant, drastically reducing the information bur-
denondevelopersforreadingGUI-changereports.Thesefiltered
screens resulted in 158 matched screen pairs, which exhibited a
Matching Precision (MP) of 84.8%. This illustrates that Gcat is able
550
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. Detecting and Summarizing GUI Changes in Evolving Mobile Apps ASE ’18, September 3–7, 2018, Montpellier, France
Figure 6: GcatDP,CP, andR
to both effectively filter and match corresponding screen pairs that
were automatically extracted from automated dynamic analysis of
subsequent app versions.
5.2 RQ 2:GcatPerformance
RunningGcat’schangeanalysisoverthe158matchedscreenpairs
tookanaverageof13.1secondsperscreenpair.TheGcatresults
forDP,CPandRare illustrated as box-plots across the analyzed
reports in Figure 6. Gcat is able to achieve an average DPof 98.3%
and an average Rof 97.6%, however CPis a bit lower than these
with an average value of 76.7%. This means that Gcat is able to
effectively detect GUI-changes with few false positives, and rarely
missesreportingexistingGUI-changeso nascreen. However,when
classifying theseGUI-changes intotheir corresponding taxonomy
categories, there were certain cases of incorrect classification.
The largest source of false positives in terms of the CPcame
from ambiguities relatedto Font changes and Font Colorchanges.
AsexplainedinSection 3.3,Gcatderivesacolorhistogram(CH)
fromcroppedimagesoftextualcomponents,andiftheEuclidean
distancebetweentheseColorHistogramsdoesnotmatchwithin
agiventhreshold,thenaFontcolorchangeisreported.However,
thesensitivityofthisthresholdcanvarybetweendifferentstyles
of fonts, making it difficult to properly tune. This results in several
FontcolorviolationsbeingclassifiedasFontstylechanges.How-
ever,itshouldbenotedthattheseclassificationsareverysimilarand
arelessimpactfultotheutilityofreportsthanifamoreorthogonal
classification was made (e.g., Font color →Layout Change).
5.3 RQ 3: Developer Performance
Thedeveloperresultsfor DP,CPandRareillustratedasabox-plots
across the analyzed reports in Figure 7. On average, developers
achieveda DPof94.9%,anda CPof91.72%.However,theirrecall
suffered quite a bit, with developers on average only reporting
49.4%ofexistingGUI-changesforagivenscreenpair.Furthermore,
on average developersrequired 9 minutesand 8 seconds todetect
and classify the GUI changes for the three assigned screen pairs. In
general this means that, while developers were generally accurate
atreportingandclassifyingchangeswhentheyrecognizedthem,
there were a large number of changes that were not reported, and
the reporting process was time consuming. The underlying reason
for missed changes varied across developers and screen pairs. Incertaincases,subtlechangesinthelayoutorsizeofcomponents
were not reported, however, in other cases, more easily observable
changesweremissed,includingthefailuretoreportentirelynewor
removedcomponentsbetweenscreenpairs.Whencomparingthe
developer’sperformancetoGcat,wefindthatGcatoutperformed
developers in each metric.
Figure 7: Developer DP,CP, andR
Figure 8: Average Developer UX Question Responses.SD=Strongly Disagree, D=Disagree, N=Neutral, A=Agree,SA=Strongly Agree
5.4 RQ 4: Perceived Utility of Gcatreports
TheresultsfortheUXquestionsusedtomeasurethedeveloperper-
ceivedusefulnessoftheGcatreportsaregivenasaveragevaluesin
Figure8. These results are generally very positive, with developers
agreeing on average that the Gcat reports are (i) easy to under-
stand,(ii)usefulforidentifyingGUIchanges,and(iii)applicableforfrequentuse.TheyalsogenerallyfoundthatGcatreportswere not
cumbersome to read or overly complex. These responses help to
illustratetheutilitythatdevelopersfoundwhenexaminingreports.
For the User Experience Questions ( UX), we asked participants
about four aspects of the reports: (i) the information that was most
useful, (ii) what additional information would have been helpful,
(iii) the elements they liked the most from the reports, and (iv) the
elementstheylikedtheleastfromthereports.Inresponsetothe
first question, many users indicated that they found the Full An-
notatedScreenshots, anddetailedlist ofGUI-componentchanges
themostuseful.Forexampleoneparticipantresponded, “Thede-
tailed changes, since they show the status of the elements before/after
thechanges.”,whereasanotherparticipantindicated, “Seeinghow
componentsmovedwiththe highlightedredboxes.”.Thedevelopers
alsogavesomeusefulfeedbackforimprovementstothetool.For
example, “A way to group the changes or a potential importance
(e.g., a new component may be more important as compared to a 2px
change).”.In respondingto whichelements theyliked themost,the
responses mostly echoed the first question, where the side-by-side
annotated screenshots and detailed list of GUI changes were the
most cited. Finally, while some participants indicated that they did
notdislikeanyoftheinformationinthereports,otherscitedthe
NLsummary,andtreecomparisonasareasforimprovement.We
provide the full set of responses in our online appendix [4].
6 LIMITATIONS & THREATS TO VALIDITY
Limitations: Our experimental evaluation of Gcat has shown the
toolachievesremarkableeffectiveness,however,theapproachdoes
exhibit certain limitations that serve as motivation for future work.
Currently our approach may not properly handle dynamic screen
551
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France K. Moran, C. Watson, J. Hoskins, G. Purnell, and D. Poshyvanyk
content. For example, a list that is loaded over the network that
mightnot actuallychangebetweenversionscouldbedetectedas
a series of GUI-changes due to differing content. This problem
could be mitigated by asking developers to annotate certain screen
content as dynamic, or through automatic recognition of dynamic
contentviamachinelearning.Second,currentlyourapproachoper-
atesonlyonnativeAndroidapps,andhasnotbeenimplementedor
testedforiOSorhybridapps.However,weexpecttheunderlying
techniquesfordetectingandclassifyingGUIchangestoapplyto
other types of apps and platforms, where the largest challenges lie
inengineeringmethodstoextractaccurateGUImetadata.Finally,
our study of Gcat’s screen matching algorithm revealed limita-
tionsofourapproach,as ≈15%ofthescreenswerenotcorrectly
matched. Future work could look towards exploring more sophisti-
catedmatchingalgorithmsthattakegreateradvantageofcertain
structural properties of GUI-metadata.Internal Validity:
In our experiments evaluating the Gcat ap-
proach, internal threats may arise from our manual examination
ofreports(RQ 2),andresponsesfromusers(RQ 3).However,three
authors independently examined all reports and user responses
followingaset,rigorousmethodology.Also,ourresultsillustrate
clear trends that we expect would hold across different evaluators.
Construct Validity: One threat to construct validity concerns dif-
ferences in the sets of screen pairs utilized to investigate RQ 2and
RQ3. In answering RQ 2we used randomly sampled screen pairs
thatwereautomaticallyderivedfromGcat’sautomatedGUIexplo-
rationengine.ThisstudywascarriedoutinthiswaytoevaluateGcat in its intended, fully automated use case. However, for the
userstudy,weneededmorecontroloverthenumberofscreenpairs
in order to design the screen pair assignment for participants, and
thuswemanuallyextractedscreensfromoursetofsubjectapplica-tionsthathadknowndifferences.However,thesamplingprocedure
based on PID described in Section 4ensured that a similarly varied
set of screens was used between the two studies, mitigating this
threat to validity concerning our experimental observations.
External Validity: We utilized a set of 31 open source subject
applications from the F-Droid marketplace in our experimental
evaluation of Gcat. There is the potential that the experimentalresults observed in this paper may not generalize to a larger setof applications, or that the GUIs of the open source applications
studieddifferfromthoseofpaidappsonGooglePlay.Howeverour
set of subject applications represent varying sizes and popularities
ofapps.Thusweassertthatoursubjectsetofapplicationsisvaried
enough to draw meaningful experimental conclusions. Anotherthreat to external validity concerns the generalization of the re-
sults of our developer survey to a broader set of mobile developers.
Whileourparticipantsprimarilycamefromacademicbackgrounds,
they had an average general programming experience of 6.8 years
andanaveragemobileprogrammingexperienceof1.5years.Fur-
thermorepastworkhasfoundresponsesfromsuchstudiestobe
representative of professional developers [47].
7 RELATED WORK
Thereisasizablebodyofexistingthataimstoautomaticallysumma-
rizecode-relatedinformation,suchasmethodsandreleasenotes[ 34–
38,44].However,weforgoadetaileddiscussionofthesetechniques
as they do not specifically attempt to summarize aspects of GUIs.GUI Differencing: The most closely related work to ours is that
by Xieet al.who introduced a GUI differencing approach called
Guide [50]. Guide is capable of resolving mappings between GUI
objectsofGUIhierarchytreesindifferentappversions,however,
its matching procedure is not described in detail. While Guideis capable of deriving GUI mappings, it is not capable of detect-ing, reporting or summarizing GUI-changes that occur between
these mappings.Furthermore,the effectiveness ofGuide was not
evaluated on a large dataset of apps with existing GUI-changes.DetectingPresentationFailuresinMobile&WebApps:
Agrow-
ing body of work has been dedicated to detecting presentation fail-
uresand design violations in mobile and web apps. Moran et al.
introducedGvt[ 30],whichiscapableofdetectingdesignviolations
andpresentationfailuresthatoccurbetweenamock-upofanapp’s
GUI and its implementationof that mock-up. While this approach
sharessimilaritieswithGcat,thereareseveralkeydifferences.First,
rather than resolving information between a GUI mock-up and an
implementationofthatmock-up,Gcatmustresolveinformationbetweensubsequentappversions.Second,whereasGvtrequires
themanualspecificationofscreenstocompare,Gcatderivesthese
screens automatically via automated GUI exploration of an app.
Third,Gcat aimsto supportcomprehension tasks,and thusmust
effectivelysummarizetheGUIchangesbothvisuallyandinnatural
language. There is also an existing body of work that aims to de-
tect, classify, and fix presentation failures in web apps [ 27–29,45].
However, these approaches do not target mobile apps, and are not
concerned with summarizing GUI changes in evolving apps.Cross-Browser Testing:
There also exist approaches for XBT, also
known as cross browser testing [ 17,45,46], that are capable of
detectingandreportingdifferencesbetweenwebpagesrenderedindifferenttypesofbrowsers.Whilethisworksharessomeunderlyinggoalswithourapproach(e.g., detectingcorrespondingscreens,GUI
elements),Gcatexhibitsafewnotabledeparturesthatillustrateits
novelty. First, in order to effectively summarize evolutionary GUI
changes Gcat is capable of classifying detected changes into com-
mon change categories for mobile app GUIs. Second, our approach
is able to generate human-readable reports that contain natural
language summary changes at multiple granularities.
8 CONCLUSION & FUTURE WORK
We present Gcat, an automatic summarization tool used for de-
tectingandreportingGUIchangesduringtheevolutionarydevel-
opment of mobile apps. An evaluation of Gcat illustrates that our
approach is effective, outperforming developers, and reports useful
information in a comprehensible manner. Our future work entails
a more precise classification for GUI changes as well as continuing
to improve the quality of the NL summarizations. Additionally, we
aim to enable Gcat to effectively analyze and classify dynamic
screen content.
ACKNOWLEDGMENTS
This work is supported in part by the NSF CCF-1815186 grant.
Anyopinions,findings,andconclusionsexpressedhereinarethe
authors’anddonotnecessarilyreflectthoseofthesponsors.The
authors would like to thank the ASE’18 reviewers whose insightful
comments which greatly improved this paper.
552
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. Detecting and Summarizing GUI Changes in Evolving Mobile Apps ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1] 2018 stack overflow developer survey
https://insights.stackoverflow.com/survey/2018/.
[2] Android Fragmentation Statistics
http://opensignal.com/reports/2014/android-fragmentation/.
[3] Android uiautomator
http://developer.android.com/tools/help/uiautomator/index.html.
[4] Anonymous gcat online appendix https://research-appendix.com/gcat.
[5] Apple App Store https://www.apple.com/ios/app-store/.
[6] F-droid. https://f-droid.org/.
[7] Genymotion android emulator https://www.genymotion.com.
[8] Gitlab ci/cd https://about.gitlab.com/features/gitlab-ci-cd/.
[9] Google material design https://material.io.
[10] Google Play Store https://play.google.com/store?hl=en.
[11] Statista - Mobile Market Share
https://www.statista.com/statistics/266136/global-market-share-held-by-
smartphone-operating-systems/.
[12] Travisci https://travis-ci.org.
[13]Why Your App’s UX is More Important than You Think
http://www.codemag.com/Article/1401041.
[14]G. Bavota, M. Linares-Vásquez, C. Bernal-Cárdenas, M. Di Penta, R. Oliveto, and
D. Poshyvanyk. The Impact of API Change- and Fault-Proneness on the User
Ratings of Android Apps. Software Engineering, IEEE Transactions on, 41(4):384–
407, Apr. 2015.
[15]J.Brooke. SUS:Aquickanddirtyusabilityscale. InP.W.Jordan,B.Weerdmeester,
A.Thomas,andI.L.Mclelland,editors, UsabilityEvaluationinIndustry.Taylor
and Francis, London, 1996.
[16]S. R.Choudhary, A.Gorla, andA. Orso. AutomatedTest InputGeneration for
Android: Are We There Yet? (E). In 2015 30th IEEE/ACM International Conference
on Automated Software Engineering (ASE), ASE’15, pages 429–440, Nov. 2015.
ISSN:.
[17]S.R.Choudhary,M.R.Prasad,andA.Orso. CrossCheck:CombiningCrawling
and Differencing to Better Detect Cross-browser Incompatibilities in Web Appli-
cations. In Proceedings of the 2012 IEEE Fifth International Conference on Software
Testing, Verification and Validation, ICST ’12, pages 171–180, Washington, DC,
USA, 2012. IEEE Computer Society.
[18]A. Ciurumelea, A. Schaufelbühl, S. Panichella, and H. C. Gall. Analyzing reviewsandcodeofmobileappsforbetterreleaseplanning.In 2017IEEE24thInternational
ConferenceonSoftwareAnalysis,EvolutionandReengineering(SANER),SANER’17,
pages 91–102, Feb. 2017.
[19]A. Di Sorbo, S. Panichella, C. V. Alexandru, J. Shimagaki, C. A. Visaggio, G. Can-
fora, and H. C. Gall. What Would Users Change in My App? Summarizing App
ReviewsforRecommendingSoftwareChanges. In Proceedingsofthe201624th
ACMSIGSOFT InternationalSymposiumonFoundations ofSoftwareEngineering,
FSE’16, pages 499–510, Seattle, WA, USA, 2016. ACM.
[20]D.Han,C.Zhang,X.Fan,A.Hindle,K.Wong,andE.Stroulia. Understanding
androidfragmentationwithtopicanalysisofvendor-specificbugs. In Proceedings
of the 2012 19th Working Conference on Reverse Engineering, WCRE ’12, pages
83–92, Washington, DC, USA, 2012. IEEE Computer Society.
[21]G. Hu, X. Yuan, Y. Tang, and J. Yang. Efficiently, Effectively Detecting Mobile
AppBugswithAppDoctor. In ProceedingsoftheNinthEuropean Conferenceon
Computer Systems, EuroSys ’14, pages 18:1–18:15, Amsterdam, The Netherlands,
2014. ACM.
[22]N.Jones. Sevenbestpracticesforoptimizingmobiletestingefforts. Technical
Report G00248240, Gartner.
[23]M. Joorabchi, A. Mesbah, and P. Kruchten. Real Challenges in Mobile App
Development. In EmpiricalSoftwareEngineeringandMeasurement,2013ACM/
IEEE International Symposium On, ESEM’12, pages 15–24, Oct. 2013.
[24]M. Linares-Vásquez, G. Bavota, C. Bernal-Cárdenas, M. Di Penta, R. Oliveto,
andD.Poshyvanyk. APIChangeandFaultProneness:AThreattotheSuccess
of Android Apps. In Proceedings of the 2013 9th Joint Meeting on Foundations
ofSoftwareEngineering,FSE’13,pages477–487,SaintPetersburg,Russia,2013.
ACM.
[25]M.Linares-Vásquez,C.Bernal-Cardenas,K.Moran,andD.Poshyvanyk. How
do Developers Test Android Applications? In 2017 IEEE International Conference
on Software Maintenance and Evolution (ICSME), ICSME’17, pages 613–622, Sept.
2017. ISSN:.
[26]M.Linares-Vásquez,K.Moran,andD.Poshyvanyk. Continuous,Evolutionary
and Large-Scale: A New Perspective for Automated Mobile App Testing. In 2017
IEEE International Conference on Software Maintenance and Evolution (ICSME),
ICSME’17, pages 399–410, Sept. 2017. ISSN:.
[27]S. Mahajan, A. Alameer, P. McMinn, and W. G. J. Halfond. Automated Repair of
LayoutCross BrowserIssuesUsing Search-basedTechniques. In Proceedingsof
the26thACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis,
ISSTA’17, pages 249–260, Santa Barbara, CA, USA, 2017. ACM.
[28]S. Mahajan and W. G. J. Halfond. Detection and Localization of HTML Pre-
sentationFailuresUsingComputerVision-BasedTechniques. In 2015IEEE8th
InternationalConferenceonSoftwareTesting,VerificationandValidation(ICST),ICST’15, pages 1–10, Apr. 2015.
[29]S.Mahajan,B.Li,P.Behnamghader,andW.G.J.Halfond. UsingVisualSymp-
toms for Debugging Presentation Failures in Web Applications. In 2016 IEEE
InternationalConferenceonSoftwareTesting,VerificationandValidation(ICST),
ICST’16, pages 191–201, Apr. 2016. ISSN:.
[30]K. Moran, B. Li, C. Bernal-Cárdenas, D. Jelf, and D. Poshyvanyk. Automated
ReportingofGUIDesignViolationsinMobileApps. In Proceedingsofthe40th
InternationalConferenceonSoftwareEngineeringCompanion ,ICSE’18,pageto
appear, Gothenburg, Sweden, 2018. IEEE Press.
[31]K. Moran, M. Linares-Vásquez, C. Bernal-Cárdenas, C. Vendome, and D. Poshy-
vanyk. Automatically Discovering, Reporting and Reproducing Android Ap-
plication Crashes. In 2016 IEEE International Conference on Software Testing,
Verification and Validation (ICST), ICST’16, pages 33–44, Apr. 2016. ISSN:.
[32]K. Moran, M. Linares-Vásquez, C. Bernal-Cárdenas, C. Vendome, and D. Poshy-
vanyk. CrashScope: A Practical Tool for Automated Testing of Android Applica-
tions. InProceedings of the 39th International Conference on Software Engineering
Companion, ICSE-C ’17, pages 15–18, Buenos Aires, Argentina, 2017. IEEE Press.
[33]K. P. Moran, C. Bernal-CÃąrdenas, M. Curcio, R. Bonett, and D. Poshyvanyk.
Machinelearning-basedprototypingofgraphicaluserinterfacesformobileapps.
IEEE Transactions on Software Engineering, pages 1–1, 2018.
[34]L.Moreno,J.Aponte,G.Sridhara,A.Marcus,L.Pollock,andK.Vijay-Shanker.
AutomaticgenerationofnaturallanguagesummariesforJavaclasses. In 2013
21st International Conference on Program Comprehension (ICPC), ICPC’13, pages
23–32, May 2013.
[35]L. Moreno, G. Bavota, M. Di Penta, R. Oliveto, and A. Marcus. How Can I Use
This Method? In Proceedings of the 37th International Conference on Software
Engineering-Volume1,ICSE’15,pages880–890,Florence,Italy,2015.IEEEPress.
[36]L.Moreno,G.Bavota,M.DiPenta,R.Oliveto,A.Marcus,andG.Canfora. Au-
tomaticGeneration ofReleaseNotes. In Proceedingsof the22NdACM SIGSOFT
InternationalSymposiumonFoundationsofSoftwareEngineering,FSE’14,pages
484–495, Hong Kong, China, 2014. ACM.
[37]L. Moreno, G. Bavota, M. D. Penta, R. Oliveto, A. Marcus, and G. Canfora. Arena:
Anapproachfortheautomatedgenerationofreleasenotes. IEEETransactionson
Software Engineering, 43(2):106–127, Feb 2017.
[38]L. Moreno, A. Marcus, L. Pollock, and K. Vijay-Shanker. JSummarizer: An au-
tomaticgeneratorofnaturallanguagesummariesforJavaclasses. In 201321st
International Conference on Program Comprehension (ICPC), ICPC’13, pages 230–
232, May 2013.
[39]P.Morville. UserExperienceDesign.http://semanticstudios.com/user_experience_design/.
[40]B.Myers. ChallengesofHCIDesignandImplementation. Interactions,1(1):73–83,
Jan. 1994.
[41]A.T.Nguyen,T.T.Nguyen,andT.N.Nguyen. Divide-and-ConquerApproach
forMulti-phaseStatisticalMigrationforSourceCode(T). In 201530thIEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering(ASE),ASE’15,pages
585–596, Nov. 2015. ISSN:.
[42]F.Palomba,M.Linares-Vásquez,G.Bavota,R.Oliveto,M.D.Penta,D.Poshyvanyk,
andA.D.Lucia. Userreviewsmatter!Trackingcrowdsourcedreviewstosupport
evolutionofsuccessfulapps. In 2015IEEEInternationalConferenceonSoftware
Maintenance and Evolution (ICSME), ICSME’15, pages 291–300, Sept. 2015. ISSN:.
[43]F. Palomba,P. Salza, A.Ciurumelea, S. Panichella,H. Gall,F.Ferrucci, andA. D.
Lucia. Recommending andLocalizing CodeChangesfor MobileApps basedon
User Reviews. In ICSE’17, 2017.
[44]M. P. Robillard, A. Marcus, C. Treude, G. Bavota, O. Chaparro, N. Ernst, M. A.
Gerosa, M. Godfrey, M. Lanza, M. Linares-Vásquez, G. C. Murphy, L. Moreno,
D. Shepherd, and E. Wong. On-demand Developer Documentation. In 2017
IEEE International Conference on Software Maintenance and Evolution (ICSME),
ICSME’17, pages 479–483, Sept. 2017. ISSN:.
[45]S.RoyChoudhary,M.R.Prasad,andA.Orso. X-PERT:AccurateIdentificationof
Cross-browserIssuesinWebApplications. In Proceedingsofthe2013International
Conference on Software Engineering, ICSE ’13, pages 702–711, San Francisco, CA,
USA, 2013. IEEE Press.
[46]S. Roy Choudhary, H. Versee, and A. Orso. WEBDIFF: Automated Identifica-
tion of Cross-browser Issues in Web Applications. In Proceedings of the 2010
IEEE International Conference on Software Maintenance, ICSM ’10, pages 1–10,
Washington, DC, USA, 2010. IEEE Computer Society.
[47]I.Salman,A.T.Misirli,andN.Juristo. AreStudentsRepresentativesofProfession-
alsinSoftwareEngineeringExperiments? In Proceedingsofthe37thInternational
ConferenceonSoftwareEngineering-Volume1,ICSE’15,pages666–676,Florence,
Italy, 2015. IEEE Press.
[48]A. B.Tucker. Computer ScienceHandbook,SecondEdition. Chapman & Hall/CRC,
2004.
[49]L. Wei, Y. Liu, and S. C. Cheung. Taming Android fragmentation: Characterizing
and detecting compatibility issues for Android apps. In 2016 31st IEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering(ASE),ASE’16,pages
226–237, Sept. 2016. ISSN:.
[50]Q. Xie, M. Grechanik, C. Fu, and C. Cumby. Guide: A GUI differentiator. In 2009
IEEE International Conference on Software Maintenance, ICSM’09, pages 395–396,
Sept. 2009.
553
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:27:29 UTC from IEEE Xplore.  Restrictions apply. 