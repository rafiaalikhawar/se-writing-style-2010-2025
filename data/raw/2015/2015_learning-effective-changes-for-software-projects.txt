Learning Effective Changes for Software Projects
Rahul Krishna
Comptuer Science, North Carolina State University, USA
i.m.ralk@gmail.com
Abstract â€”The primary motivation of much of software ana-
lytics is decision making. How to make these decisions? Should
one make decisions based on lessons that arise from within a
particular project? Or should one generate these decisions from
across multiple projects? This work is an attempt to answer these
questions. Our work was motivated by a realization that much
of the current generation software analytics tools focus primarily
on prediction. Indeed prediction is a useful task, but it is usually
followed by â€œplanningâ€ about what actions need to be taken. This
research seeks to address the planning task by seeking methods
that support actionable analytics by offering clear guidance on
what to do. Speciï¬cally, we propose XTREE and BELLTREE
algorithms for generating a set of actionable plans within and
across projects. Each of these plans, if followed will improve the
quality of the software project.
Index Termsâ€”Planning, bellwethers, defect prediction.
I. I NTRODUCTION
Over the past decade, advances in AI have enabled a
widespread use of data analytics in software engineering.
For example, we can now estimate how long it would take
to integrate the new code [1], where bugs are most likely
to occur [2], or amount of effort it will take to develop a
software package [3], etc. Despite these successes, there are
two primary operational shortcomings with many software
analytic tools: (a) conclusion instability as a result of constant
inï¬‚ux of new data; and (b) lack of insightful analytics.
In several applications where local data is scarce, re-
searchers use transfer learning. They report that the use of
data from other projects can yield comparable predictors to
just using local data [4]. However, new projects are constantly
being created. Rahman et al. [5] caution that if quality predic-
tors are always being updated based on the speciï¬cs of new
data, then those new predictors may suffer from over-ï¬tting.
Such over-ï¬tted models are â€œbrittleâ€ in the sense that they can
undergo constant changes whenever new data arrives and lead
to unstable conclusions. Conclusion instability is unsettling for
software project managers struggling to ï¬nd general policies.
We require methods to support managers, who seek stability
in their conclusions, while also allowing new projects to take
full beneï¬t from data arriving from all the other projects. Our
research [6] has offered strong evidence that organizations can
declare some prior project as the â€œbellwetherâ€1that can then
offer predictions that generalize across Nother projects.
In addition to unstable conclusions, business users also
lament that most software analytics tools, â€œTell us what is. But
they donâ€™t tell us what to doâ€. A concern that was also raised
by several researchers at a recent workshop on â€œActionable
1According to the Oxford English Dictionary, the â€œbellwetherâ€ is the leading sheep of
a ï¬‚ock, with a bell on its neck.Analyticsâ€ at 2015 IEEE conference on Automated Software
Engineering [7]. For example, most software analytics tools
in the area of detecting software defects are mostly prediction
algorithms such as Support Vector Machines, Naive Bayes,
Logistic Regression, Decision Trees, etc [8]. These prediction
algorithms report what combinations of software project fea-
tures predict for the number of defects. But this is different
task to planning, which answers a more pressing question:
what to change in order to reduce these defects. Accordingly,
in this research, we seek tools that offer clear guidance on
what to do in a speciï¬c project.
The tool assessed in this paper is the XTREE planning
tool [9]. XTREE employs a cluster +contrast approach to
planning where it (a) Clusters different parts of the software
project based on a quality measure (e.g. the number of
defects); (b) Reports the contrast sets between neighboring
clusters. Each of these contrast sets represent the difference
between these clusters and they can be interpreted as plans:
If a current project falls into cluster C1,
Some neighboring cluster C2has better quality.
Then the difference D=C2- C1is aplan for changing
a project such that it might have higher quality.
XTREE uses data from within a software project to generate
plans. But, in several cases local data may not be readily
available. To overcome this limitation, we incorporate our ï¬nd-
ings from bellwethers to extend XTREE to use the bellwether
projects. We call this tool BELLTREE and we show that it can
be used to generate stable plans for cross-company planning.
II. C ONTRIBUTIONS OF THIS WORK
1. New kinds of software analytics techniques: This research
introduces the notion of planning in software engineering. In
addition to showing that planning in effective in a within-
project setting [9], we also show that with bellwethers [6],
plans can be generated for cross-project problems with en-
couraging results. This is a unique approach that combines
our efforts to address the problems highlighted in xI.
2. Compelling results of planning: Our results have established
that planning is quite successful in producing actions that can
reduce the number of defects. In Figure 2, we show that
planning can reduce defects by more than 40% in 3 out of
the 4 datasets studied here (> 80% in the certain cases).
3. Evidence of generality of bellwethers: The more the bell-
wether effect is explored, the more we learn about its broad
applicability. Originally, we explored this just in the context
of defect prediction [6], it has now been shown to work also
in effort estimation, predicting when issues will close, and
detecting code smells [10]. Our preliminary results reported
978-1-5386-2684-9/17/$31.00 c2017 IEEEASE 2017, Urbana-Champaign, IL, USA
Doctoral Symposium1002
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. in this work show that bellwethers can also be used for
cross-project planning with the use of BELLTREE. This is an
important result of much signiï¬cance since, where bellwethers
occur, reasoning about multiple software projects becomes a
simple matter of discovering bellwethers (see [6]).
4. Replication Package: For readers this work who wish to
replicate our ï¬ndings, we have made available a replication
package at https://git.io/v7c9k.
III. R ELATED WORK
Planning has been a subject of much research in artiï¬-
cial intelligence. Here, planning usually refers to generating
a sequence of actions that enables an agent to achieve a
speciï¬c goal [11]. This can be achieved by classical search-
based problem solving approaches or logical planning agents.
Such planning tasks now play a signiï¬cant role in a variety
of demanding applications, ranging from controlling space
vehicles and robots to playing the game of bridge [12].
Some of the most common planning paradigms include: (a)
classical planning [13]; (b) probabilistic planning [14]; and
(c) preference-based planning [15].
Existence of a model precludes the use of each of these
planning approaches. This is a limitation of all these planning
approaches since not every domain has a reliable model.
In software engineering, the planning problem translates to
proposing changes to software artifacts. Solving this has
been undertaken via the use of some search-based software
engineering techniques [16]. Examples of algorithms include
SWAY , NSGA-II, etc. [17, 18].
These search-based software engineering techniques require
access to some trustworthy models that can be used to explore
novel solutions. In some software engineering domains there
is ready access to such models which can offer assessment
of newly generated plans. Examples of such domains within
software engineering include automated program repair [19,
20], software product line management [21, 22], etc.
However, not all domains come with ready-to-use models.
For example, consider software defect prediction and all the
intricate issues that may lead to defects in a product. A
model that includes allthose potential issues would be very
large and complex. Further, the empirical data required to
validate any/all parts of that model can be hard to ï¬nd.
Also, even when there is an existing model, they can require
constant maintenance lest they become out-dated. In such
domains, we seek alternate methods for planning that can
be automatically updated with new data without a need for
comprehensive models. For this, we propose the use of data
mining approaches to create a quasi-model of the domain and
make of use observable states from this data to generate an
estimation of the model. Our preferred tools in this paper
(XTREE and BELLTREE) take this approach by constructing
decision trees on available data (discussed in xIV-B). InxVII,
we show that these methodologies have encouraging results.
In summary, for domains with readily accessible models,
we recommend the tools used by the search-based software
engineering community. For domains, where domain-models
are not available, we recommend tools such as ours.
Fig. 1: Generating thresholds using XTREE. The recommended
changes are shown in the bounded box above.
IV. P LANNING IN SOFTWARE ENGINEERING
A. What is planning?
We distinguish planning from prediction for software quality
as follows: Quality prediction points to the likelihood of de-
fects. Predictors take the form: out=f(in), where incontains
many independent features and out contains some measure
of how many defects are present. For software analytics,
the function fis learned via data mining (with static code
attributes for instance). Contrary to this, quality planning
generates a concrete set of actions that can be taken (as
precautionary measures) to signiï¬cantly reduce the likelihood
of defects occurring in the future. For a formal deï¬nition of
plans, consider a test example Z=fZ1;Z2;:::;Zng, planners
proposes a plan8dj2Dto adjust attribute Zj2Zas follows:
8dj2D:Zj=Zj+djifZjis numeric
dj otherwise
With this, to (say) simplify a large bug-prone method, our
planners might suggest to a developer to reduce its size (i.e.
refactor that code by splitting it simpler functions).
B. XTREE
XTREE builds a supervised decision tree and then generates
plans by contrasting the differences between two branches:
(1) branch where you are; (2) branch where you want to be.
The speciï¬cs of the algorithm used to divide the data and
construct the decision tree were presented in greater detail in
our previous work [9]. Next, XTREE builds plans from the
branches of the decision tree by asking the following three
questions for each test case (the last of which returns the plan):
1) Which current branch does a test instance fall in?
2) Which desired branch would we want to move to?
3) What are the deltas between current and desired?
As a motivating example, consider Figure 1 with XTREE
constructed with training data consisting of OO code met-
rics [23] and associated defect counts. A defective test case
with the same code metrics is passed into the tree and
1003
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. evaluated down the tree to a leaf node with a defect probability
of 1.0 (see the orange line in Figure 1). XTREE then looks
for a nearby leaf node with a lower defect probability (see the
green line in Figure 1). XTREE then evaluates the differences
(ofdeltas) between green andorange. These deltas can be
translated as plans2. In Figure 1, these plans are to change
lcom (lack of coupling among methods) and cam (cohesion
among methods). For a developer, these may translated to (a)
Ensure a class contains more methods that interact with each
other to address lcom, and (b) Ensure cohesion among methods
improves to address cam.
C. BELLTREE
BELLTREE is novel extension to XTREE and is structurally
similar to it. It differs in the source of data used for analytics.
While XTREE uses data from within the project, BELLTREE
ï¬rst starts by looking for the bellwether dataset. To do this, we
employ the strategy discussed in our previous work [6]. This
helps in identifying a bellwether dataset. Once the bellwethers
are discovered, we construct a supervised decision tree similar
to XTREE. Plans are generated by using the same procedure
asxIV-B. Note that the use of bellwethers enables BELLTREE
to leverage data from across different projects.
V. R ESEARCH QUESTIONS
RQ1. How prevalent are bellwethers? It is important to estab-
lish the prevalence of bellwethers ï¬rst as this determines if it is
possible to learn plans from the bellwether data. If bellwethers
occur infrequently, we cannot rely on them for planning. We
have initially shown that bellwethers are prevalent in defect
prediction [6]. Further evidence was seen in [10], where
we explored three additional sub-domains within software
engineering namely, defect prediction, effort estimation, issue
lifetime estimation, and detection of code smells. In a result
consistent with bellwethers being very prevalent, we found that
all these domains have a bellwether dataset.
RQ2. Does within-project planning with XTREE offer signiï¬-
cant improvements in reducing defects? This research question
seeks to establish if our preferred planning tool (XTREE) is
effective in generating actionable plans in a within-project
setting. Our initial ï¬ndings showed that XTREE was indeed an
effective planner that can generate plans that are also succinct
and stable. Further, these plans are not subject to conjunctive
fallacy [9].
RQ3. Does cross-project planning with BELLTREE offer sig-
niï¬cant improvements in reducing defects? Having established
the prevalence of bellwether datasets and the efï¬cacy of
planning with XTREE, here we ask if it is possible for us
to transfer plans across projects using the bellwether data and
XTREE (referred to as BELLTREE). Our preliminary results
are very encouraging. We show that BELLTREE can be a very
effective cross-project planner.
RQ4. Are cross-project plans any better than within project
plans? This research question assesses the quality of plans
obtained using XTREE and BELLTREE. This is important
2Represented as thresholds that are denoted by [low;high) ranges for each OO metricbecause within-project data is not always available (especially
if a project is in itâ€™s early stage of development) and it
may be useful to look to other similar projects for planning.
Our preliminary results have suggested that the effectiveness
of plans generated from within project data and XTREE is
statistically comparable to plans derived with cross-project
data and BELLTREE. Thus, when project speciï¬c data is not
available, one may use cross-project data to derive plans.
VI. E VALUATING PLANS
To evaluate plans, we propose the use of a veriï¬cation
oracle [9]. Oracles have been commonly used by several SE
researchers such as Oâ€™keefe et al. [24] and Mkaouer et al. [25].
They use an oracle that is learned separately from the planner.
The veriï¬cation oracle assesses how defective the code is
before and after some code changes. For their oracle, Cheng,
Oâ€™Keefe, Moghadam and Mkaouer et al. use the QMOOD
quality model [26]. A shortcoming of QMOOD is that quality
models learned from other projects may perform poorly when
applied to new projects [27]. Hence, for this study, we eschew
older quality models like QMOOD. Instead, we use Random
Forests [28] to learn defect predictors from OO code metrics.
Unlike QMOOD, the predictors are speciï¬c to the project.
Additionally, classiï¬ers such as Random Forest have shown
to be very efï¬cient in detecting bugs [29].
For planning and construction of a veriï¬cation oracle, we
divide the project data into two parts the train set and the test
test. The train set could either be data that is available locally
within a project, or it could be data from the bellwether dataset.
We further partition the train set to build both a planner and
averiï¬cation oracle. Note that: The veriï¬cation oracle should
be built with completely different data to the planner.
After constructing the planner and veriï¬cation oracle, we
(1) deploy the planner to recommend plans; (2) alter the test
data according to these plans; then (3) apply the veriï¬cation
oracle to the altered data to estimate defects; then (3) Compute
the percent improvement, denoted by the following equation:
R= (1 after
before)100% (1)
The value of the measure Rhas the following properties:
(1) If R=0%, this means â€œno change from baselineâ€; (2)
IfR>0%, this indicates â€œimprovementâ€; (3) If R<0%, this
indicates â€œoptimization failureâ€. Ideally, an effective planner
should have an improvement of R>0, where larger values
indicate better performance.
VII. C URRENT STATE AND FUTURE WORK
As mentioned earlier in the paper, this work represents our
efforts to address to key issues in modern software analytics:
(a) conclusion instability; and (b) generating insightful analyt-
ics. To this end, we undertook two concurrent research efforts
to address each of these issues.
While attempting to stabilize the pace of conclusion change,
we discovered the bellwether effect [6]. Our results provided
evidence that it is possible to slow the pace of conclusion
change in software analytics (for defect prediction models)
using bellwethers. Further exploration demonstrated that the
1004
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. Observed Improvements (from Equation 1)
AntRank Tr
eatment Median IQR
1 XTREE
44.0 6.0 s
2 BELL
TREE 39.0 16.0 s
PoiRank Tr
eatment Median IQR
1 XTREE
84.0 6.0 s
1 BELL
TREE 83.0 3.0 s
IvyRank Tr
eatment Median IQR
1 BELL
TREE 25.0 12.0 s
1 XTREE
24.0 12.0 s
JeditRank Tr
eatment Median IQR
1 XTREE
63.0 2.0 s
2 BELL
TREE 60.0 9.0 s
Fig. 2: Results comparing XTREE trained on local datasets and
BELLTREE. Results from 30 repeats. Values come from Eq. 1. Values
near 0 imply no improvement, Larger median values are better.
so called bellwether effect is quite prevalent in several sub-
domains of software engineering such as code-smell detection,
effort estimation, and estimation of issue lifetimes [10].
In order to generate actionable analytics for software engi-
neering, we developed the XTREE planner [9]. Initial mo-
tivation for XTREE was to address the varied opinions in
literature on how best to undertake code reorganization so as
to reduce bad smells. We showed that by leveraging historical
logs of data, planners such as XTREE can offer actionable
recommendations on how to undertake code reorganization in
order to reduce defects in code. Further, we showed that in
addition to generating effective plans, XTREE recommends
of far fewer changes. Thus making it a better framework for
critiquing and rejecting many of the code reorganizations.
The initial version of XTREE was limited to using data
from within a project to generate plans. This paper represents
our initial attempts to transfer plans from across other projects
to a test project. For this purpose, we developed BELLTREE.
It uses the same framework as XTREE but uses bellwethers
as the source of data for planning. Our results comparing
BELLTREE with XTREE on a set of open source java projects
is shown in Figure 2. In two of the four datasets, we note
that BELLTREE performed just as well as XTREE and two
other cases XTREE outperformed BELLTREE (but not by a
signiï¬cant amount). Our initial ï¬nding is that if within-project
data from previous releases are available, we may use XTREE.
If not, using bellwethers would be a reasonable alternative.
Our initial results of using BELLTREE are encouraging and
deserves much further exploration. Starting early this summer,
we have deployed an enhanced version of XTREE on-site in
conjunction with our industrial partners with the following
goals: (1) Qualitatively validate the usefulness of the plans;
(2) Establish the receptiveness of developers actively using
our tool; and (3) Solicit developersâ€™ feedback on usefulness
of plans generated by XTREE.
REFERENCES
[1] J. Czerwonka, R. Das, N. Nagappan, A. Tarvo, and A. Teterev, â€œCrane: Failure
prediction, change analysis and test prioritization in practice â€“ experiences from
windows,â€ in Software Testing, Veriï¬cation and Validation (ICST), 2011 IEEEFourth International Conference on, march 2011, pp. 357 â€“366.
[2] T. Menzies, A. Dekhtyar, J. Distefano, and J. Greenwald, â€œProblems with Precision:
A Response to â€Comments on â€™Data Mining Static Code Attributes to Learn Defect
Predictorsâ€™â€,â€ IEEE Transactions on Software Engineering, vol. 33, no. 9, 2007.
[3] B. Turhan, A. Tosun, and A. Bener, â€œEmpirical evaluation of mixed-project defect
prediction models,â€ in Software Engineering and Advanced Applications (SEAA),
2011 37th EUROMICRO Conference on. IEEE, 2011, pp. 396â€“403.
[4] F. Peters, T. Menzies, and L. Layman, â€œLACE2: Better privacy-preserving data
sharing for cross project defect prediction,â€ in Proceedings - International Confer-
ence on Software Engineering, vol. 1, 2015, pp. 801â€“811.
[5] F. Rahman, D. Posnett, and P. Devanbu, â€œRecalling the â€imprecisionâ€ of cross-
project defect prediction,â€ in Proceedings of the ACM SIGSOFT 20th International
Symposium on the Foundations of Software Engineering, ser. FSE â€™12. New York,
NY , USA: ACM, 2012, pp. 61:1â€“61:11.
[6] R. Krishna, T. Menzies, and W. Fu, â€œToo much automation? the bellwether effect
and its implications for transfer learning,â€ in Proceedings of the 31st IEEE/ACM
International Conference on Automated Software Engineering - ASE 2016. New
York, New York, USA: ACM Press, 2016, pp. 122â€“131.
[7] J. Hihn and T. Menzies, â€œData mining methods and cost estimation models: Why is
it so hard to infuse new ideas?â€ in 2015 30th IEEE/ACM International Conference
on Automated Software Engineering Workshop (ASEW), Nov 2015, pp. 5â€“9.
[8] F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, â€œScikit-learn: Machine
learning in Python,â€ Journal of Machine Learning Research, vol. 12, pp. 2825â€“
2830, 2011.
[9] R. Krishna, T. Menzies, and L. Layman, â€œLess is more: Minimizing code reorga-
nization using XTREE,â€ Information and Software Technology, mar 2017.
[10] R. Krishna and T. Menzies, â€œSimpler Transfer Learning (Using â€Bellwethersâ€),â€
TSE (under review), pp. 1â€“18, mar 2017. [Online]. Available: http://arxiv.org/abs/
1703.06218
[11] S. Russell and P. Norvig, Artiï¬cial Intelligence: A Modern Approach. Prentice-
Hall, Egnlewood Cliffs, 1995.
[12] M. Ghallab, D. Nau, and P. Traverso, Automated Planning: theory and practice.
Elsevier, 2004.
[13] M. Wooldridge and N. R. Jennings, â€œIntelligent agents: Theory and practice,â€ The
knowledge engineering review, vol. 10, no. 2, pp. 115â€“152, 1995.
[14] E. Altman, Constrained Markov decision processes. CRC Press, 1999, vol. 7.
[15] S. S. J. A. Baier and S. A. McIlraith, â€œHtn planning with preferences,â€ in 21st Int.
Joint Conf. on Artiï¬cial Intelligence, 2009, pp. 1790â€“1797.
[16] M. Harman, S. A. Mansouri, and Y . Zhang, â€œSearch based software engineering:
A comprehensive analysis and review of trends techniques and applications,â€ Dept.
Comp. Sci, Kings College London, Tech. Rep. TR-09-03, 2009.
[17] V . Nair, T. Menzies, and J. Chen, â€œAn (accidental) exploration of alternatives to
evolutionary algorithms for sbse,â€ in International Symposium on Search Based
Software Engineering. Springer, 2016, pp. 96â€“111.
[18] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, â€œA Fast Elitist Multi-Objective
Genetic Algorithm: NSGA-II,â€ IEEE Transactions on Evolutionary Computation,
vol. 6, pp. 182â€“197, 2002.
[19] W. Weimer, T. Nguyen, C. Le Goues, and S. Forrest, â€œAutomatically ï¬nding
patches using genetic programming,â€ in Proceedings - International Conference
on Software Engineering. IEEE, 2009, pp. 364â€“374.
[20] C. Le Goues, N. Holtschulte, E. K. Smith, Y . Brun, P. Devanbu, S. Forrest, and
W. Weimer, â€œThe ManyBugs and IntroClass Benchmarks for Automated Repair
of C Programs,â€ IEEE Transactions on Software Engineering, vol. 41, no. 12, pp.
1236â€“1256, dec 2015.
[21] A. S. Sayyad, J. Ingram, T. Menzies, and H. Ammar, â€œScalable product line con-
ï¬guration: A straw to break the camelâ€™s back,â€ in Automated Software Engineering
(ASE), 2013 IEEE/ACM 28th International Conference on. IEEE, 2013.
[22] C. Henard, M. Papadakis, M. Harman, and Y . L. Traon, â€œCombining multi-objective
search and constraint solving for conï¬guring large software product lines,â€ in 2015
IEEE/ACM 37th IEEE International Conference on Software Engineering, vol. 1,
May 2015, pp. 517â€“528.
[23] S. R. Chidamber and C. F. Kemerer, â€œA metrics suite for object oriented design,â€
IEEE Transactions on software engineering, vol. 20, no. 6, pp. 476â€“493, 1994.
[24] M. Oâ€™Keeffe and M. O. Cinn Â´eide, â€œSearch-based refactoring: An empirical study,â€
J. Softw. Maint. Evol., vol. 20, no. 5, pp. 345â€“364, Sep. 2008. [Online]. Available:
http://dx.doi.org/10.1002/smr.v20:5
[25] M. W. Mkaouer, M. Kessentini, S. Bechikh, K. Deb, and M. Â´O Cinn Â´eide,
â€œRecommendation system for software refactoring using innovization and
interactive dynamic optimization,â€ in Proceedings of the 29th ACM/IEEE
International Conference on Automated Software Engineering, ser. ASE â€™14.
New York, NY , USA: ACM, 2014, pp. 331â€“336. [Online]. Available:
http://doi.acm.org/10.1145/2642937.2642965
[26] J. Bansiya and C. G. Davis, â€œA hierarchical model for object-oriented design
quality assessment,â€ IEEE Trans. Softw. Eng., vol. 28, no. 1, pp. 4â€“17, Jan. 2002.
[Online]. Available: http://dx.doi.org/10.1109/32.979986
[27] T. Menzies, A. Butcher, D. Cok, A. Marcus, L. Layman, F. Shull, B. Turhan, and
T. Zimmermann, IEEE Transactions on Software Engineering.
[28] L. Breiman, â€œRandom forests,â€ Machine learning, pp. 5â€“32, 2001.
[29] W. Fu, T. Menzies, and X. Shen, â€œTuning for software analytics: is it really
necessary?â€ Information and Software Technology, 2016.
1005
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. 