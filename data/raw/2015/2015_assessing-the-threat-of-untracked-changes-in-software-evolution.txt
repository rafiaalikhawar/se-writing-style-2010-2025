Assessing the Threat of Untracked Changes in Software
Evolution
Andre Hora
FACOM, UFMS, Brazil
hora@facom.ufms.brDanilo Silva, Marco Tulio
Valente
ASERG Group, DCC, UFMG, Brazil
{danilofs,mtov}@dcc.ufmg.brRomain Robbes
SwSE Group, Free University of
Bozen-Bolzano, Italy
rrobbes@unibz.it
ABSTRACT
While refactoring is extensively performed by practitioners, many
Mining Software Repositories (MSR) approaches do not detect nor
keep track of refactorings when performing source code evolution
analysis. In the best case, keeping track of refactorings could be
unnecessarywork;intheworstcase,these untrackedchanges could
significantlyaffecttheperformanceofMSRapproaches.Sincethe
extent of the threat isunknown, the goal of this paper is toassess
whether it is significant. Based on an extensive empirical study, we
answerpositively:wefoundthatbetween10and21%ofchangesatthemethodlevelin15largeJavasystemsareuntracked.Thisresults
in a large proportion (25%) of entities that may have their histories
splitbythesechanges,andameasurableeffectonatleasttwoMSR
approaches. We conclude that handling untracked changes should
be systematically considered by MSR studies.
CCS CONCEPTS
•Software and its engineering →Software evolution ;
KEYWORDS
Mining Software Repositories, Software Evolution, Refactoring
ACM Reference Format:
Andre Hora,Danilo Silva,Marco Tulio Valente, andRomain Robbes. 2018.
Assessing the Threat of Untracked Changes in Software Evolution. In ICSE
’18: 40th International Conference on Software Engineering , May 27-June
3, 2018, Gothenburg, Sweden. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3180155.3180212
1 INTRODUCTION
Mining Software Repositories (MSR) techniques are helping to im-
proveourunderstandingofsoftwaredevelopmentandcontributing
totheimplementationofanewgenerationofsoftwareengineer-
ing tools. Many of the existing MSR techniques are based on the
analysis of changes performed on source code repositories [ 30].
For example, change-based techniques have been proposed to sup-
port library migration [ 27,45,66], change prediction [ 69], bug
fixing[36],warningsprioritization [ 5,9,11,34,35],andexpertise
calculation [3, 44, 51, 62], to name a few.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05 ...$15.00
https://doi.org/10.1145/3180155.3180212Generally,thesetechniquesoperateontheleveloftheindivid-
ual methods and classes changed on each commit. For example,
by mining the history of the methods in a system, change-based
techniques can learn that methods that depend on type Aare often
updated to depend on an improved type A’. A recommendation
canthenbeprovidedtoalertdevelopersaboutthemethodsnotyet
updated in the system. However, these techniques require tracking
the changes along all versions of each individual method (or class)
inthesystemunderanalysis.Thechallengeisthatsomechanges
invalidate this tracking when it is solely based on the names of the
trackedentities.Specifically,refactoringsmayintroducedisconti-
nuitiesinname-basedtrackingstrategies.Forinstance,amethod
rename or move can be misinterpreted as the disappearance of a
methodandtheappearanceofabrandnewone,splittingitshistory,andthusinvalidatethetracking.Wecallthechangesthataffectthe
names of code entities untracked changes (this definition is detailed
inSection2).Ifnotproperlyhandled,untrackedchangesmayhave
a negative impact on the accuracy of MSR-based techniques.
Whilethethreatofuntrackedchangeshasbeenacknowledged
intheliterature(severalexamplesarepresentedinSection3),toour
knowledge, the actual extent of these changes on MSR studies has
notbeeninvestigated.AssessingtheextentofthreatstoMSRstudies
is essential; prior work has investigated bias in bug-fix datasets
[8],ornon-essentialchanges[ 30].Inthispaper,weperformsucha
study: we assess the frequency, extension, and impact of the threat
of untracked changes. We detail our methodology in Section 4 and
our selection of case studies (15 popular Java systems) in Section 5.
We then answer the following research questions:
•RQ1.Whatisthefrequencyofuntrackedchanges? InSection6,
we find that between 10 and 21% of method-level changes
and2and15%ofclass-levelchangesareuntracked.Themost
common ones are due to rename, extract, and move method.
•RQ2.Whatistheextensionofuntrackedchanges? Section7
showsthat25%ofentitieshaveatleastoneuntrackedchange
intheirhistories,andthusmayhavetheirhistorysplit.In
the most changed entities, the proportion raises to 37%.
•RQ3.WhatistheimpactofuntrackedchangesinexistingMSR-
basedapproaches ?InSection8,weinvestigatetheconcrete
impactofuntrackedchangesintwoMSRapproaches,namely
APIevolutionandAPIco-usagerulemining.Wefindthat,
on the median, up to 6.9% and 5.3%, respectively, more rules
are discovered when untracked changes are considered.
Thus,thecontributionsofthisworkaretwofold:(i)weprovidean
empiricalstudytoassessthefrequencyandextensionofuntracked
changes at a large scale and (ii) we measure the concrete impact of
untracked changes in two MSR-based approaches.
11022018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Andre Hora, Danilo Silva, Marco Tulio Valente, and Romain Robbes
Wediscusstheimplicationsandthreatstovalidityofourstudyin
Sections9and10,respectively.Finally,wecoverrelatedwork(stud-
iesofthreatstoMSRstudies,andapproachestodetectuntracked
changes) in Section 11, and conclude in Section 12.
2 TRACKED AND UNTRACKED CHANGES
This section defines the two categories of changes that we analyze
in this study. During software evolution, two kinds of changes can
occur to code entities such as classes and methods: tracked and
untrackedchanges.A trackedchange preservestheentitynameand
modifiesitssourcecode.Thus,anentityinversion ncanbedirectly
matched to its following version n+1. In contrast, an untracked
changemodifiestheentityname,andmayalsomodifyitssource
code.Theyoccurdueto,forexample,renameormoverefactorings.
In addition, an untracked change may also spawn a new entity, for
example, as the result of extract method refactorings. Therefore,
an entity in version nis not matched to its version n+1, unless
the untracked change is resolved with the support of a refactoring
detection approach ( e.g.,[32, 57, 58]).1
Figure1illustratesexamplesoftrackedanduntrackedchangesin
foursourcecodeversions.Eachboxrepresentsaclassanditsmeth-
ods, and each arrow represents an evolutionary change between
two consecutive versions. Class Fooand its method mA()undergo
sometrackedchanges(solidarrow),sincetheydonotchangeentity
names. Thus, to understand the evolution of FooandmA(), one
can trace them backward or forward. For example, the last version
ofmA()can be straightforwardly traced back to its first version,
andvice-versa.Ontheotherhand,class Baranditsmethod mB()
undergo some untracked changes (dashed arrow). Method mB()is
renamed to mX()in version 2, and then to mY()in version 4; class
Barisalsorenamedto Bazinversion4.Inthiscase, mY()inversion
4 may not be traced back to its originating method mB()in version
1,duetothemethodrenaming.Considernowthemorechallenging
scenario:method mC()ismovedfromclass BartoQuxinversion3,
and then, method mE()is extracted from mC()in version 4. Notice
that two non-trivial untracked changes happen: move and extract
method.Inthiscase,methods mC()andmE()inversion4haveboth
theirorigininversion1of mC().Therefore,iftheuntrackedchange
is not resolved, method mE()may be simply misdetected as a new
method, and its actual origin may not be found.
class Foo {
   mA() {…}
}
class Bar {
   mB() {…}
   mC() {…}
}class Foo {   mA() {…}
}
class Bar {
   mX() {…}
   mC() {…}
}class Foo {   mA() {…}
}
class Bar {
   mX() {…}
}class Foo {
   mA() {…}
}
class Baz {
   mY() {…}
}
class Qux {
   mC() {…}
  
}class Qux {   mC() {…}
   mE() {…}
}tracked change
untracked changeversion 1 version 2 version 3 version 4
Legend
Figure 1: Example of tracked and untracked changes.
Untracked changes at the class level ( e.g.,class renaming or
moving)behavesimilarly,and,ifunresolved,canbemisdetected
in the same fashion, albeit on a larger scale, since losing track of a
class means also losing track of its methods.
1Another name to trackedanduntracked changes could be history-preserving and
history-destroying changes , respectively.3 THE THREAT OF UNTRACKED CHANGES
In this section we present three MSR research lines affected by
untracked changes. We illustrate each scenario with real-world
examples extracted from open-source projects. We conclude the
section by generalizing our discussion to other affected research
lines, and state the problem we investigate.
3.1 Scenario 1: Mining Code Evolution
The first scenario comes from a research line intended to mine
codeevolution.Themainideaistocomparetwoversionsofacode
entity,andtolearnfromthedifferences.Applicationsofthisline
are broad, including learning how bugs are fixed [ 36], detection of
behavioralbreakingchanges[ 59],andextractionofrulestosupport
library migration [ 27–29,45,66]. Figure 2 illustrates an example in
thecontextoflibrarymigration,fromprojectWordPress-Android.2
Versionnhas a reference to class Vectorthat is replaced by a
reference to Listin version n+1. The example shows a tracked
change:method Blog()inversion nisdirectlymatchedtomethod
Blog()inversion n+1.Bycomparingthedifferencesbetweenboth
method versions, one may infer the rule Vector→List.
public Blog(int blog_id) throws Exception{
    //instantiate a new blog
    Vector<Object> blogVals = WordPress.wpDB.loadSettings(blog_id);
    if (blogVals != null) {
        //... 
public Blog(int blog_id) throws Exception{
    //instantiate a new blog
    List<Object> blogVals = WordPress.wpDB.loadSettings(blog_id);    if (blogVals != null) {
        //... version n version n+1
Figure 2: Two versions of method Blog(). Rule Vector→
Listcan be inferred by comparing both method versions
(project WordPress-Android).
ConsidertheexampleinFigure3,fromprojectOkHttp.3Version
nhas an invocation to FileInputStream() that is replaced by an
invocationto Okio.source() inversion n+1.Theexamplepresents
an untracked change: method newInputStream() in version nis
renamed to newSource() in version n+1. Thus, unless the method
renaming is resolved, this change may be seen as a removal of
newInputStream() andanadditionof newSource() .Inthiscase,
these methods would not be matched,and, consequently,the rule
FileInputStream() →Okio.source() would not be inferred.
public Source newSource( int index) throws IOException {
  //...
    try {
        return Okio.source(entry.cleanFiles[index]);
    } catch (FileNotFoundException e) {...}
}public InputStream newInputStream( int index) throws IOException {
  //...
    try {
        return new FileInputStream(entry.cleanFiles[index]);
    } catch (FileNotFoundException e) {...}
}version n version n+1
Figure 3: Method newInputStream() is renamed to
newSource() . Rule FileInputStream() →Okio.source()
may not be detected, after a renaming (project OkHttp).
2Change available at: https://goo.gl/NHvjgH
3Change available at: https://goo.gl/2NvgC1
1103
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. Assessing the Threat of Untracked Changes in Software Evolution ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Theliteraturerecognizestheissuescausedbyuntrackedchanges
suchasclassormethodrenaming.Commonly,theyaretreatedas
threats to validity or limitations. For example, in the context of
APIevolution,Horaetal .[27]state:“APIchangesareautomatically
produced by applying the [...] technique on the set of method call
changesbetweentwoversionsofonemethod ”.Similarly,inthecontext
of bug fixing, Kim et al . [36]notice: “Our approach is based on
comparing a source code file of two versions, so the bugs captured
andfixessuggestedareonlyfile-by-filebased ”.Inbothcases,rename
refactoringsarenotresolved.Raemaekersetal . [50]plainlystate:
“Wedetectrenamedormovedunitsasunitsthatareremovedfirstand
added later ”. In the domain of behavioral breaking changes, Soares
etal. [59]note:“Asimilarthingoccurswhenrenamingaclass.We
cannot compare the renamed method’s behavior directly ”.
3.2 Scenario 2: Prioritizing Code Warnings
Thesecondscenariocomesfromaresearchlinemeanttoprioritize
warnings(orcodeviolations)reportedbystaticanalysistools,such
as FindBugs [ 4], PMD [13], and Checkstyle [ 10]. These tools are
used to find common programming issues, related to performance,
security,legibility,etc.Inpractice,staticanalysistoolsareknownto
report too many warnings. Consequently, most reported warnings
are unlikely to be fixed by developers, which are known as false
positives [ 35,48]. Inthis context, researcherspropose approaches
tofilteroutfalsepositives( e.g.,[5,9,11,14,34,35,65]).Acommon
approach is to detect the most fixed warnings over time, which
are more likely to be relevant than warnings never fixed by any
developer. For example, the warning “ method parameters should
be final”4is systematically fixed in project Easy Properties.5Thus,
such warning could receive a high prioritization in this project.
ConsidernowtheexampleinFigure4,whichshowstwoversions
ofmethod invoke() inprojectApacheTomcat.6Versionncontains
a warning ( i.e.,“explicit initialization with null ”7) that seems to
be fixed in version n+1. However, the warning is not fixed but
only moved to methods findMethod() andbuildParameters()
in version n+1, as the result of a extract method refactoring. In this
case,approachesmaymisclassifythewarningasfixediftheextract
method refactoring is not taken into account.
static Method findMethod(...) {
    Method matchingMethod = null;
    //extracted code
static Object[] buildParameters(...) {
    Object[] parameters = null;
    //extracted codepublic Object invoke() {
    Method matchingMethod = null;
    //extracted code
    Object[] parameters = null;
    //extracted code
public Object invoke() {
    Method matchingMethod = Util.findMethod(...);    Object[] parameters = Util.buildParameters(...);    //...version n+1 version nMoving warning
“explicit 
initialization”
Figure 4: Warning “ explicit initialization with null ”
is moved from method invoke() tofindMethod() and
buildParameters() ,afteraextractmethod(projectTomcat).
4http://checkstyle.sourceforge.net/config_misc.html#FinalParameters
5Change available at: https://goo.gl/mBL0QK
6Change available at: https://goo.gl/5LbyQT
7http://checkstyle.sourceforge.net/config_coding.html#ExplicitInitializationAsinScenario1,theliteraturealsonoticesthesesthreats,where
missingormisclassifingresultsmaybeproducedwhencodechanges
are not tracked. For example, Ayewah and Pugh [5]state: “If a
method is renamed or moved to another class, any issues in that
method will be reported as being removed [...] ”. Peters and Zaidman
[48]note:“[Ourtool]isunabletodetermineifanentityinrevision
nhasbeenrenamedinrevisionn+1 ”.KimandErnst [34]mention:
“Weexcluderemovedwarningsduetoanyfiledeletion.Ifthereisa
file deletion during a fix, all warnings in the files are removed ” (note
that a class rename can be misdetected as a file deletion).
3.3 Scenario 3: Detecting Code Authorship
The last research line is intended to detect code authorship. In
short,theideaistoinferexpertdeveloperswhoarebestqualified
tomaintaincertaincodefiles( e.g.,[1,3,18,19,23,44,47,51,56,62]).
Approaches in this area often take advantage of facilities provided
bySCMtoolssuchasGit,SVN,andCVS.Forexample,Gitprovides
thefacility git blame8,whichshowswhatrevisionandauthorlast
modified each line of a file. By using this information, approaches
in thisdomain can discover the developer whocreated a file, the
developerwhomostmodifiedafile,amongothers.However,this
process is sensitive to refactoring, such as moving [3].
ConsidertheexampleinFigure5,whichpresentsamovemethod
refactoringinprojectOkHttp.9Methods computeAge() andcom-
puteFreshnessLifetime() are moved from class ResponseHead-
ersin version nto class ResponseStrategy in version n+1.A s
SCMtoolscannottrackfine-grainedrefactorings,theactualauthor
of these methods ( i.e., JakeWharton ) is lost, after a move method.
In this case, the author in version n+1would be misdetected as
swankjesse ,i.e.,the one who performed the move refactoring.
public class ResponseStrategy {
//...long computeAge(ResponseHeaders response , long nowMillis ) {...}
long computeFreshnessLifetime(ResponseHeaders response ) {...}
//...
}public class ResponseHeaders {
//...public ResponseHeaders(URI uri, RawHeaders headers) {...}
public ResponseHeaders combine(ResponseHeaders network) {...}
private long computeAge( long nowMillis ) {...}
private long computeFreshnessLifetime() {...}
//...
}
public class ResponseHeaders {
//...public ResponseHeaders(URI uri, RawHeaders headers) {...}
public ResponseHeaders combine(ResponseHeaders network) {...}
//...
}version n version n+1Author:
swankjesseAuthor: 
JakeWharton
Figure 5: Actual author of methods computeAge() and
computeFreshnessLifetime() (i.e.,JakeWharton)islost,after
a move method (project OkHttp).
These limitations are recognized by related literature. For in-
stance, Avelino et al . [3]state: “The full development history of a
filecanbelostincaseofrenamingoperations,copyorfilesplit.We
addresstheformerproblemusingGit facilities.Ho wever,weacknowl-
edge the need for further empirical investigation to assess the true
impact of the other cases ”. Similarly, Spinellis [62]note: “The git
blame command works by traversing backwards a repository’s his-
tory[...].Consequently,deletedsnapshotswouldcreateadiscontinuity
between them, and prevent the tracing of code between them ”.
8https://git-scm.com/docs/git-blame
9Change available at: https://goo.gl/5HYf5p
1104
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Andre Hora, Danilo Silva, Marco Tulio Valente, and Romain Robbes
3.4 Other Scenarios
The aforementioned scenarios show some MSR research lines and
studies affected by the threat of untracked code changes. Notice,
however, that the list of presented research lines is not intended to
be exhaustive. In addition to the previous ones, other lines include
studies and threats in the context of (i) bug introducing change
detection10(e.g.,[2,12,26,37–39,53,54,67,68]): “It is also possible
tomissbug-introducingchangeswhenafilechangesitsnamesincethe
algorithmdoesnottracksuchnamechanges ”[38];(ii)codeevolution
understanding ( e.g.,[6,7,42,61,62]): “To distinguish cases where a
methodwasremovedandanewoneaddedfromcaseswhenamethod
was renamed, we use a heuristic that maps methods with different
names[...] ”[7,42];(iii)codeevolutionvisualsupporting( e.g.,[21,
22]):“[Ourtool]doesnotperformanyrecoveryofrefactoringssuch
as renaming, pull or push down methods ” [22], among other.
3.5 Problem: What is the Extent of the Threat
of Untracked Changes?
The threat of untracked changes may be faced (at a higher or a
lower level) by several MSR-based studies. In practice, however,
this threat is commonly not assessed by researchers, therefore, we
arestillunawareaboutitsrealsize.Basedonthat,oneimportant
questionappears: whatisthefrequency,extension,andimpactofthe
threat of untracked changes? Answering this question has practical
consequences:researcherscanbetterquantifythethreat’simpactin
MSR-based studies. Consequently, they will have better support to
decide whether the threat is large enough that they should address
it,oriftheycanignoreit. Intheremainderofthispaper,weaimto
answer this question.
4 ASSESSING UNTRACKED CHANGES
4.1 Detecting Untracked Changes
RefDiff. We rely on RefDiff [ 58] to detect both tracked and un-
tracked changes. RefDiff is a tool that identifies refactorings per-
formed in the version history of a system. The tool relies on a
combination of heuristics based on static analysis and code similar-
ity to detect 11 well-known refactoring operations that can lead to
untrackedchangesattheclassormethodlevels.RefDiffalsodetects
tracked changes at both class and method levels, as summarized in
Table1.Essentially,RefDiffreceivesasinputtwoversions v1and
v2ofasystem,andoutputsalistofchangesperformedin v2,when
compared to v1.
Table 1: Types of tracked and untracked changes.
Change Type
Tracked Same Class, Same Method
UntrackedRename Class, Move Class, Move and Rename Class,
Extract Interface,Extract Superclass,Rename Method,
Move Method, Extract Method, Inline Method, Pull Up
Method, Push Down Method
10These studies are often affected by the same issues presented in Scenario 3, since
they often make use SCM facility tools.RefDiff’sauthorsprovidetwoevaluationsoftheirtool.First,they
evaluated the tool using an oracle with well-known refactoring in-
stances performed by students in seven Java projects. As presented
inTable2(columnEval#1),RefDiffachievedaprecisionof100%
in all refactoring types; overall recall was 93.9%, ranging from
60%(PullUpMethod)to100%(RenameClassandMoveMethod).
Although the tool detects these refactorings, in their evaluation,
RefDiff’sauthorsdidnotconsidertworefactoringoperations:Move
and Rename Class and Extract Interface. In this evaluation, RefDiff
alsooutperformedtheresultsofsimilartools,includingRefactor-
ing Miner [ 57,64], Refactoring Crawler [ 16], and RefFinder [ 32].
Thesementionedtoolsachievedaprecisionof96%,42%,and26%,
respectively;regardingrecall,theresultswere73%,36%,and64%,
respectively. RefDiff thus constitutes, at the time of writing, the state
oftheartinrefactoringdetection .RefDiff’sauthorsprovideasecond
evaluation, using 102 real refactoring instances from ten GitHub
projects.AspresentedinTable2(columnEval#2),withtheserefac-
torings,RefDiffachievedanoverallprecisionof85.4%andanoverall
recall of 93.6%.
Table 2: Precision and recall of RefDiff.
RefactoringEval #1 [58] Eval #2 [58] Eval #3
Prec Recall Prec Recall Prec Recall
Rename Class 100 100 100 100 95.0 87.5
Move Class 100 96.8 100 100 98.3 89.5Extract Superclass 100 87.5 100 100 - 66.7
Move and Rename Class ---- 71.4 100
Extract Interface ---- 1 0 0 -
Rename Method 100 94.3 88.0 91.7 89.7 92.3
Move Method 100 100 95.5 87.5 92.4 100Extract Method 100 89.7 73.5 100 79.2 66.7
Inline Method 100 98.1 71.4 83.3 93.8 83.3
Pull Up Method 100 60.0 100 100 100 66.7Push Down Method 100 97.1 100 100 100 -
All Refactorings 100 93.9 85.4 93.6 89.1 89.8
To increase our confidence on RefDiff’s accuracy, we manually
validatedasetofrefactoringsdetectedbythetoolintheversionhis-
tory of the projects investigated in this paper (which are presented
in Section 5). First, we executed RefDiff in the commit history of
these systems. We then randomly selected 383 of such refactorings
for manual validation by the second author of this paper (with this
sample size, we ensure a confidence level of 95% and confidence
intervalof5%[ 63]).11Foreachrefactoring,heinspectedthetextual
difference produced by GitHub for the respective commit; he then
classified the detected refactorings as true or false positives. As
presented in Table 2 (column Eval #3), the overall precision in this
third evaluation was 89.1%, ranging from 71.4% (Move and Rename
Class) to 100% (Extract Interface and Pull Up/Push Down Method).
Finally, we evaluated RefDiff’s recall using well-know refactor-
ingsperformedintheversionhistoryoftheprojectsinvestigated
inthispaper.Tocreatethisgoldset,wefirstsearchedinthetextual
description of the commits performed in these systems for regular
expressions denoting the refactorings considered in the study ( e.g.,
“extractmethod”).Then,thesecondauthorofthispaperchecked
11This selection includes instances of all refactorings detected by RefDiff, with the
exception of Extract Superclass; since it is a rare refactoring, no instance of this
refactoring was included in the random sample of refactorings.
1105
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. Assessing the Threat of Untracked Changes in Software Evolution ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
whether these commits indeed include the refactorings declared
in their descriptions. In this way, we created a gold set with 127
validated refactoring instances, which was used to compute recall.
As shown in Table 2 (column Eval #3), the overall recall in this
thirdevaluationwas89.8%,rangingfrom66.7%(ExtractSuperclass,
ExtractMethod,andPullUpMethod)to100% (MoveandRename
Class and Move Method).ChangeGraph.
Tofacilitatetheevolutionaryanalysisofclasses,
methods, and their related changes, we model a graph—the change
graph—whichisbuiltbyrunningRefDiffonasetofsystemversions
(i.e.,commits).Inthisgraph,eachclassormethodisrepresentedas
anodewhileeachtrackedoruntrackedchangeisrepresentedasan
edgebetweentwonodes.Figure6presentsthechangegraphforthe
exampledescribedinFigure1.Wenoticetheentitiesrepresented
as nodes and the changes represented as edges.
Foo 
v1Foo 
v2Foo 
v3Foo 
v4
mA 
v1mA 
v2mA 
v3mA 
v4
Bar 
v1Bar 
v2Bar 
v3Baz 
v4
mB 
v1mX 
v2mX 
v3mY 
v4
mC 
v1mC 
v2Qux 
v3Qux 
v4
mC 
v3mC 
v4
mE 
v4SC SC SC
SM SM SM
SC SC RC
RM SM RM
SM SC
MM
SM
EMTracked Change
Untracked ChangeLegend
SC: Same Class 
SM: Same Method 
RC: Rename Class  RM: Rename Method  
MM: Move Method  
EM: Extract Method 
Figure 6: Change graph for the example in Figure 1.
4.2 Measuring Untracked Changes
Aftergeneratingthe changegraph ,wecanassessthefrequencyand
extension of tracked and untracked changes. These assessments
are later used to answer research questions 1 and 2.
Frequency. The frequency of changes is assessed by counting the
number of edges in the change graph. Each change can be thenclassified as tracked or untracked. In Figure 6, the change graph
has 17 changes, from which 12 are tracked and 5 are untracked.
Specifically,itcontainsthefollowingchangetypes:6SameClass
(SC),6SameMethod(SM),1RenameClass(RC),2RenameMethod
(RM), 1 Move Method (MM), and 1 Extract Method (EM).
Extension. The extension of changes is computed by assessing
the paths in the change graph. We consider a path to represent the
history of an entity. Each path may be formed by tracked and/or
untrackedchanges.Pathswithuntrackedchangesarenotdesirable,becausetheirhistoriesmaybesplit(iftheuntrackedchangesarenot
resolved), decreasing traceability of the entityhistory.In Figure 6,
forexample,thechangegraphhas7paths.Threepathsincludeonly
trackedchanges: Foov1...Foov4(length3), mAv1...mAv4(length3),
andQuxv3...Quxv4(length1).Fourpathsincludeatleastoneun-
tracked changes: Barv1...Bazv4(length 3), mBv1...mYv4(length 3),
mCv1...mCv4(length3),and mCv1...mEv4(length3).Thus,trace-
ability is more precise when untracked changes are resolved.5 EXPERIMENTAL DESIGN
5.1 Selecting Case Studies
Inthisstudyweanalyzetrackedanduntrackedchangesthathappen
inreal-worldandpopularsoftwaresystems.Wecollectthe10most
popularJavasystemshostedonGitHub,assortedbythestarmetric.
We restrict our analysis to systems with more than 1K commits to
filter out newer and less active ones. We also filter out projects not
relatedtosoftwaresystems.12Inadditiontothesetop10popular
systems,weadded5relevantsystemsfromlargeorganizationssuch
as Google, Facebook, and Apache, totalling 15 case studies.
Table 3 presents an overview of the case studies in terms of
commits, contributors, stars, forks as well as a short description.13
The most popular project is RxJava (24,751 stars) while the most
forkedisSpringFramework(10,518forks).Thecommitsrangefrom
1,025 (Android Image Loader) to 39,389 (Kotlin) while contributors
rangefrom35(AndroidImageLoader)to837(Elasticsearch).The
selected systems cover distinct domains, such as search engines,
programming languages, and software tools.
Table 3: Overview of case studies.
Project Com. Cont. Stars Forks Short Description
RxJava 5,109 162 24,751 4,348 Event-based lib.
Elasticsearch 27,738 837 23,057 8,110 Search engine
Retrofit 1,482 110 21,606 4,426 HTTP client
OkHttp 2,963 137 20,189 4,999 HTTP clientGoogle Guava 4,173 105 16,777 3,933 Core lib. for JavaMPAndroidChart 1,900 57 15,944 4,767 Android view lib.Glide 1,639 49 15,703 3,238 Android image lib.
Android Image 1,025 35 15,284 6,430 Android image lib.
Kotlin 39,389 159 14,525 1,358 Programming lang.Spring 14,792 219 14,303 10,518 Support frameworkFacebook Fresco 1,342 85 12,775 3,343 Android image lib.Clojure 3,065 125 6,339 1,064 Programming lang.
Google Guice 1,611 36 5,148 821 Dependency injection
Apache Storm 8,394 259 4,195 3,108 Distributed systemEclipse Che 3,462 74 4,166 691 Eclipse IDE
5.2 Selecting Commits
Aftercollectingthecasestudies,weneedtoselectthecommits( i.e.,
versions) to be analyzed. Projects using distributed version control
systemssuchasGitmayhaveseveralbranchesunderdevelopment.
To facilitate code evolution analysis, in this study, we focus on the
evolutionofthemainbranch.Forthispurpose,weusethecommand
git log --first-parent14toselecttheanalyzedcommits,since
the Git documentation clearly states: “ This option can give a better
overview when viewing the evolution of a particular branch ”.
5.3 Computing Untracked Changes
Inthisfinalstep,weperformtheapproachesdescribedinSection4.
WerunRefDiffforeachcasestudyanditsrespectivesetofcommits.
Wethencomputethe changegraph toinvestigatethefrequencyand
extension of untracked changes. Our source code implementation
and results are publicly available.15
12For example: https://github.com/iluwatar/java-design-patterns
13The data was collected on 05, June, 2017.
14https://git-scm.com/docs/git-log#git-log---first-parent
15Available at: https://github.com/andrehora/rastreability
1106
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Andre Hora, Danilo Silva, Marco Tulio Valente, and Romain Robbes
6 RQ1: WHAT IS THE FREQUENCY OF
UNTRACKED CHANGES?
Table4presentsthefrequencyofuntrackedchangesattheclassand
methodlevels.Atthe classlevel ,thesystemswithproportionally
moreuntrackedchangesareApacheStorm(15%),EclipseChe(14%),
andRxJava(13%).Incontrast,theoneswithlessuntrackedchanges
areGoogleGuava(2%),MPAndroidChart(2%),andFacebookFresco
(3%).Whenconsideringallprojects,6%ofthechangesareuntracked
atclasslevel.Atthe methodlevel ,thesystemswithmoreuntracked
changes are Glide (21%), Android Image (21%), and Spring (20%),
while RxJava (10%), Kotlin (13%), and MPAndroidChart (13%) have
less. When considering all projects, 16% of the method changes are
untracked. Thus, the threat of untracked changes happens at both
levels, but is more frequent for methods.
Table 4: Frequency of untracked changes per project.
ProjectFrequency of Changes
TotalTracked Untracked
Class Method Class (%) Method (%)
RxJava 50,989 16,195 29,095 2,339 (13%) 3,360 (10%)
Elasticsearch 245,991 97,791 11,9691 4,961 (5%) 23,548 (16%)
Retrofit 8,786 4,468 3,285 302 (6%) 731 (18%)
OkHttp 20,200 5,778 11,247 669 (10%) 2,506 (18%)
Google Guava 42,893 17,987 19,995 391 (2%) 4,520 (18%)
MPAndroidChart 11,775 4,891 5,871 111 (2%) 902 (13%)
Glide 10,640 4,069 4,985 228 (5%) 1,358 (21%)
Android Image 2,338 984 1,006 82 (8%) 266 (21%)
Kotlin 236,144 97,396 116,981 4,523 (4%) 17,244 (13%)
Spring 108,811 42,214 51,519 2,443 (5%) 12,635 (20%)
Facebook Fresco 7,222 2,786 3,674 95 (3%) 667 (15%)
Clojure 10,333 4,616 4,650 165 (3%) 902 (16%)
Google Guice 15,300 5,869 7,822 360 (6%) 1,249 (14%)
Apache Storm 14,260 5,502 6,716 961 (15%) 1,081 (14%)
Eclipse Che 24,602 8,284 12,281 1,301 (14%) 2,736 (18%)
All Projects 810,284 318,830 398,818 18,931 (6%) 73,705 (16%)
Table5showsthefrequencyofuntrackedchangespertype.The
mostfrequentuntrackedchangeshappenatthemethodleveland
are due to Rename Method (23K), Extract Method (21K), and Move
Method(20K).Incontrast,theleastfrequentonesareduetoExtract
Superclass (0.3K), Extract Interface (0.8K), and Push Down Method
(0.8K).Therefore,keepingtrackofclassicaluntrackedchangessuch
as class or method renaming is important—but not enough. Other
changes such as method extraction and moving should also be
addressed to ensure a more complete tracking.
Table 5: Frequency of untracked changes per type.
Level Change Type # %
ClassMove Class 11,319 12%
Rename Class 4,893 5%Move and Rename Class 1,585 2%Extract Interface 822 1%Extract Superclass 312 <1%
MethodRename Method 23,921 26%
Extract Method 21,483 23%Move Method 20,198 22%Inline Method 5,511 6%
Pull Up Method 1,718 2%
Push Down Method 874 1%Untracked changes constitute up to 21% of the changes at the
methodlevelandupto15%attheclasslevel,thereforetheyshould
notbeneglected.ThismaydirectlyaffectMSRstudiesthatcompare
two versions of one class or method (such as the ones presented
in Scenarios 1 and 2). Moreover, if one in five changes can result in
losingtrackoftheentity,thisisasignthatthisthreatisalsorelevant
forMSRstudiesthatrelyonentitytraceabilityoverseveralversions
(aspresentedinScenario3).Inthiscontext,furtherinvestigationis
performed in the next research question.
Summary .Theratioofuntrackedchangesrangesfrom10%to
21% for methods, and from 2% to 15% for classes. In practice,
thus, the threat is more frequent at the method level.
7 RQ2: WHAT IS THE EXTENSION OF
UNTRACKED CHANGES?
In this research question we assess the extension of untracked
changes.Wefirstmeasuretheamountofentities( i.e.,classesand
methods) that includes untracked changes in their histories. We
further detail the analysis by assessing the paths of these entities.
Amount of entity histories with untracked changes. Entities
withuntrackedchangesintheirhistoriesarenotdesirable,because
theirhistoriesmaybesplit.Tobetterunderstandthisthreat,Table6
presentsthenumberofentityhistories(i)withonlytrackedchanges
and (ii) with tracked and untracked changes. The systems withproportionally more entity histories with untracked changes are
Android Image (41%), MPAndroidChart (34%), and OkHttp (32%).
The systems with less are Kotlin (18%), RxJava (19%), and Facebook
Fresco(21%).Whenconsideringallsystems,25%oftheentitieshave
at least one untracked change in their histories. Thus, a relevant
amount (a quarter) of entities potentially have their history split.
Table6:Amountofentityhistorieswithuntrackedchanges.
ProjectEntity Histories
Total Tracked only Tracked & Untracked %
RxJava 21,419 17,265 4,154 19%
Elasticsearch 61,045 42,721 18,324 30%
Retrofit 2,306 1,697 609 26%
OkHttp 6,407 4,388 2,019 32%
Google Guava 12,739 9,493 3,246 25%
MPAndroidChart 1,796 1,194 602 34%
Glide 3,663 2,579 1,084 30%
Android Image 517 306 211 41%
Kotlin 77,441 63,342 14,099 18%
Spring 38,565 27,513 11,052 29%
Facebook Fresco 2,520 1,992 528 21%
Clojure 2,641 1,939 702 27%
Google Guice 5,265 4,140 1,125 21%
Apache Storm 6,920 5,087 1,833 26%
Eclipse Che 11,521 8,388 3,133 27%
All Projects 254,765 192,044 62,721 25%
In practice, this threat is more critical when an entity has more
changes in its history, meaning that a long track can be lost. To
betterunderstandthemostchangedentityhistories,Table7focuses
onthetop25%mostchangedentities.Inthiscase,thesystemswith
more entities with untracked changes are Android Image (58%),
GoogleGuice(56%),andOkHttp(48%).Incontrast,thesystemswith
lessareFacebookFresco(22%),GoogleGuava(24%),andEclipseChe
1107
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. Assessing the Threat of Untracked Changes in Software Evolution ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
(31%).Consideringallsystems,37%ofthetop-25%mostchanged
entitieshaveatleastoneuntrackedchangeintheirhistories.Weno-
tice that the proportion of entity histories with untracked changes
increase when compared to the previous analysis (overall, from
25%to37%).Thisshowsthatthemostchangedentities( i.e.,entities
that areconstantly evolving, and,consequently, that arethe most
important and critical) are also likely to have their histories split.
Table7:Amountofentityhistorieswithuntrackedchanges
in the top 25% most changed entities.
ProjectEntity Histories
TotalTracked only Tracked & Untracked %
RxJava 5,355 3,457 1,898 35%
Elasticsearch 15,261 9,456 5,805 38%
Retrofit 577 383 194 34%
OkHttp 1,602 831 771 48%
Google Guava 3,185 2,427 758 24%
MPAndroidChart 449 298 151 34%
Glide 916 587 329 36%
Android Image 129 54 75 58%
Kotlin 19,360 12,158 7,202 37%
Spring 9,641 6,267 3,374 35%
Facebook Fresco 630 490 140 22%
Clojure 660 442 218 33%
Google Guice 2,023 895 1,128 56%
Apache Storm 1,730 1,128 602 35%
Eclipse Che 2,880 1,987 893 31%
All Projects 64,398 40,860 23,538 37%
Lengthofentityhistorieswithuntrackedchanges. Tofurther
assessthedatapreviouslypresented,Figure7showsthepathlength
distributionsofthetop-25%mostchangedentities.Eachboxplot
presentsthepathlengthsoftheentityhistorieswithonlytracked
changes (left) and with tracked and untracked changes (right).16
Overall,entityhistorieswithuntrackedchangeshavehigherlength.
For example, the median path length for RxJava is 3 for entity
histories with only tracked changes and 5 for entity histories with
trackedanduntrackedchanges,thethirdquartileis5against9,and
the upper whisker is 8 against 18. Thus, entities with untrackedchanges in their histories also tend to have a longer lifespan. If
untrackedchangesareproperlyresolved,thislonglifespancanhelp
MSR studies focused on traceability analysis to be more precise.
Summary . The ratio of entities with untracked changes in
their histories varies from 18% to 41%. For the most changed
entities,thisproportionishigher,between22%and58%.Over-
all, these entities also tend to have a long lifespan.
8 RQ3: WHAT IS THE IMPACT OF
UNTRACKED CHANGES?
To further assess the practical impact of untracked changes in
MSR studies, we evaluate how untracked changes affect two MSR
approaches based on association rule mining.
The first approach focuses on API evolution rule mining [ 27,45,
66],andinfersrulesintheformat Removed→Added,indicatingthat
references to class Removed are likely to be replaced by references
to class Added. To compute the rules, this approach takes as input
16Outliers are not presented to improve visualization of quartiles.trackedtracked &
untracked51 0 1 5RxJava
trackedtracked &
untracked5 1 01 52 02 5Elasticsearch
trackedtracked &
untracked5 1 01 52 0Retrofit
trackedtracked &
untracked51 0 1 5OkHttp
trackedtracked &
untracked468 1 0 1 2 1 4Google Guava
trackedtracked &
untracked10 20 30 40MPAndroidChart
trackedtracked &
untracked468 1 0Glide
trackedtracked &
untracked5 1 01 52 02 53 0Android Image Loader
trackedtracked &
untracked5 1 01 52 0Kotlin
trackedtracked &
untracked468 1 0 1 2 1 4Spring Framework
trackedtracked &
untracked468 1 0 1 2 1 4Facebook Fresco
trackedtracked &
untracked51 0 1 5Clojure
trackedtracked &
untracked51 0 1 5Google Guice
trackedtracked &
untracked2468 1 0Apache Storm
trackedtracked &
untracked2345678Eclipse Che
Figure 7: Length of entity histories in the top 25% most
changed entities.
asetoftransactions;eachtransactionrepresentsachangebetween
two versions of one method. The transaction elements are class
references that were added or removed in the change. For example,
byminingthetwoversionsofmethod Blog()(Figure2,Scenario
1), we detect that a reference to class Vectoris removed and a ref-
erencetoclass Listisadded.Thus,atransactionwiththeelements
Removed-Vector andAdded-List is generated. Consequently, we
may infer the rule Removed-Vector →Added-List .
The second approach targets API co-usage rule mining [ 43]
to infer rules in the format UseA→UseB, indicating that class
UseAis likely to be used with class UseB. This approach also takes
as input a set of transactions representing method level changes.
However, in this case, the transaction elements are only the added
class references in the change. For example, by mining the two
versionsofmethod getState() inApacheStorm,17theco-usage
ruleMap→HashMap may be inferred, suggesting that Mapis likely
tobeusedwith HashMap.Toreducethethreatofnoisegeneratedby
largechanges[ 43,46],inbothMSRapproaches,weonlyconsider
transactions with less than 5 elements.
For each approach, we assess (i) the amount of mined rules and
(ii)thequalityofminedrulesintermsofrecallandprecision.These
assessments are performed in four setups to cover distinct rule
supportcount(1and3)andconfidence(10%and90%)[ 69].Wethen
compare these setups in two scenarios: when mining only tracked
changes and when mining both (tracked and untracked) changes.
Assessingtheamountofminedrules .Inthisanalysis,weverify
whether there is an improvement on the amount of mined rules
when includinguntrackedchanges. Toassess theamount ofrules,
weruntheassociationruleminingapproachesforallsetupsand
case studies, and collect the inferred rules. For example, Table 8
shows the results for API co-usage approach in setup 1 (support=1,
confidence=10%).Inthiscase,theimprovementontheamountof
ruleswhenincludinguntrackedchangesrangesfrom0.6%to10.8%.
17Apache Storm change available at: https://goo.gl/tzhYiK
1108
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Andre Hora, Danilo Silva, Marco Tulio Valente, and Romain Robbes
Table 8: Amount of co-usage rules for tracked and both
(trackedanduntracked)changesinsetup1(support=1,con-
fidence=10%). “Imp”: improvement percentage.
ProjectTracked only Tracked & Untracked
#Rules #Rules (Imp)
RxJava 993 999 (+0.6%)
Elasticsearch 1,375 1,490 (+8.4%)
Retrofit 404 435 (+7.7%)
OkHttp 524 548 (+4.6%)
Google Guava 1,179 1,233 (+4.6%)
MPAndroidChart 321 324 (+0.9%)
Glide 576 633 (+9.9%)
Android Image 172 185 (+7.6%)
Kotlin 333 337 (+1.2%)
Spring 1,054 1,104 (+4.7%)
Facebook Fresco 362 394 (+8.8%)
Clojure 396 399 (+0.8%)
Google Guice 1,204 1,274 (+5.8%)
Apache Storm 678 714 (+5.3%)
Eclipse Che 1,976 2,189 (+10.8%)
Figure8presentstheimprovementontheamountofrulesfor
eachsetupandapproach.18FortheAPIco-usageapproach,theme-
dianimprovementsare5.3%,1.7%,4.3%,and0%.Thegainareclearly
focused on setups 1, 2, and 3; in these cases, the third quartiles are
8%,4.7%,and6.6%.Thatis,25%ofthecasestudiesinsetup1can
produce at least 8% more rules when resolving untracked changes.
FortheAPI evolutionapproach,theresultsare slightlybetter:the
mediansare6.9%,6.2%,3.3%,and0%whilethethirdquartilesare
10.2%, 8.5%, 9.6%, and 1.9%. Interestingly, in some systems, setups 2
and 4produce a reductionin theamount of minedrules ( e.g.,first
quartile is -4.7% for API evolution in setup 4). In these systems,
the new data produced by mining untracked changes contribute
to reduce the confidence of some rules that are mined considering
only tracked changes. As a result, these rules no longer attend the
higher confidence threshold (90%) of setups 2 and 4.19
Summary .Theamountofminedrulesusuallyimproveswhen
taking into account untracked changes. The median improve-
ments range from 0% to 6.9% for API evolution, and from 0%
to 5.3% for API co-usage.
1234-5 0 5 10 15API co-usage
(amount improvement)
setupimprovement (%)
1234- 1 0- 5 0 5 1 01 52 0API evolution
(amount improvement)
setupimprovement (%)
Figure 8: Improvement in amount of mined rules
18Outliers are not presented to improve visualization of quartiles.
19For example, suppose that in 9 out 10 cases the rule A →B applies (reaching a
confidence thresholdof 90%).After consideringuntracked changes, wedetect 8new
cases were A →B applies and 2 cases where the rule does not apply. Overall, we will
have a confidence of (9+8)/20 = 0.85, less than the 90% threshold.Assessing the quality of mined rules . In this assessment, we
verify whether there is an improvement on the quality of mined
ruleswhentakingintoaccountuntrackedchanges.Toassessquality
we perform a rule recommendation analysis to simulate a real
usage scenarioof thestudied rulemining approaches. Following
the same experimental design used to evaluate an approach to
detect non-essential code changes [ 30], we iterate over all commits
in ascending date order, and verify at commit nwhether helpful
rule recommendations are produced based on the data mined from
commits 1ton-1.Specifically,ouranalysishelpsdeveloperswho
have removed (or used) some class reference ciat commit n, and
whowouldliketofindadditionalclassreferences cjthatneedto
replace(orbeco-usedwith) ci.Thisrecommendationanalysisinfers
rules inthe format ci→cj, fromwhich we returna ranked listof
classreferences cjthatwerefoundtohavebeenfrequentlyreplaced
(orco-usedwith) ciinpreviouscommits.Werankrecommendations
cjbasedontheconfidenceoftheinferredrule ci→cj.Following
theguidelinesofKawrykowandRobillard [30],wecapthenumber
ofrecommendationsatten.Finally,tomeasurequalityweassess
recall and precision of the recommendations.
Table 9 shows the quality analysis for API co-usage approach
in setup 1. For this setup, for example, the precision improvement
ranges from -8.1% (Facebook Fresco) to 26.3% (Retrofit).
Table9:Qualityofco-usagerulesfortrackedonlyandboth
(trackedanduntracked)changesinsetup1(support=1,con-
fidence=10%).“TRec”:totalrecommendation,“Cor”:correct,
“Prec”: precision, “Imp”: improvement percentage.
ProjectTracked only Tracked & Untracked
T Rec Cor Prec T Rec Cor (Imp) Prec (Imp)
RxJava 23,584 2,168 9.2 23,188 2,179 (+0.5) 9.4 (+2.2)
Elasticsearch 5,580 501 9 5,636 502 (+0.2) 8.9 (-0.8)
Retrofit 2,053 73 3.6 2,382 107 (+46.6) 4.5 (+26.3)
OkHttp 3,863 680 17.6 3,921 692 (+1.8) 17.6 (0.3)
Google Guava 11,052 1,541 13.9 10,994 1,624 (+5.4) 14.8 (+5.9)
MPAndroidChart 1,795 377 21 1,744 375 (-0.5) 21.5 (+2.4)
Glide 2,949 510 17.3 3,050 520 (+2.0) 17 (-1.4)
Android Image 430 38 8.8 407 36 (-5.3) 8.9 (+0.1)
Kotlin 342 20 5.8 343 20 (0) 5.7 (-0.3)
Spring 5,348 358 6.7 5,346 360 (+0.6) 6.8 (+0.6)
Facebook Fresco 1,161 111 9.6 1,263 111 (0) 8.8 (-8.1)
Clojure 2,448 267 10.9 2,435 267 (0) 11 (0.5)
Google Guice 7,344 829 11.3 7,239 813 (-1.9) 11.2 (-0.5)
Apache Storm 4,481 923 20.6 4,175 913 (-1.1) 21.9 (+6.2)
Eclipse Che 9,584 1,522 15.9 9,713 1,544 (+1.4) 16 (+0.1)
Figure9 showsthequality improvementforeach setupandap-
proach. For the API co-usage approach, the median recall improve-
ment is 0.2%, 0%, 1.6%, and 0%. The median pre cision improvement
is 0.3%, 1.5%, 0.4%, and 0%. Finally, regarding the API evolution
approach,themedianrecallimprovementis0%forallsetups.For
precision, the median improvement is -1.8%, 0%, -0.7%, and 0%.
While the median improvements are minor, notice that the
spread of the boxplots is large: some systems saw a significant
decrease in performance, while other saw a large increase instead.
Thisindicatesthattheimpactofuntrackedchangesisdifficultto
predict, and needs to be evaluated in a case-by-case basis.
1109
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. Assessing the Threat of Untracked Changes in Software Evolution ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Summary . Overall, the quality of mined rules slightly im-
proves when including untracked changes. However, somesystems saw much larger improvements and the impact is
difficult to predict.
1234-10 -5 0 5 10 15API co-usage
(recall improvement)
setupimprovement (%)
1234-5 0 5 10API co-usage
(precision improvement)
setupimprovement (%)
1234- 1 012345API evolution
(recall improvement)
setupimprovement (%)
1234-10 -5 0 5API evolution
(precision improvement)
setupimprovement (%)
Figure 9: Improvement in quality of mined rules.
9 FINDINGS AND IMPLICATIONS
Untrackedchangesaremorefrequentformethodsthanclasses. The
ratio of untracked changes is not irrelevant; it ranges from 10% to
21%atthemethodlevelandfrom2%to15%attheclasslevel.Despite
happening at both levels, untracked changes are more frequent
formethods.Thus,wesuggestMSRstudiestoresolveuntracked
changes, especially when performing method level comparisons,
to access neglected but potentially relevant new mining data.
Keepingtrackofuntrackedchangessuchasrenamingisimportant,
but not enough. The most frequent untracked changes are due to
method renaming (26%), extraction (23%), and moving (22%). At
class level, the most frequent are due to class moving (12%) and
renaming (5%). Overall, renamings are responsible of around 1/3 oftheuntrackedchangeswhileotherchangesrepresent2/3.Therefore,
in addition to renaming, we recommend to address extraction and
moving for a more complete resolution of untracked changes.
Untracked changescommonly cause splits inentity histories. Wede-
tect that a quarter of the studied entities potentially have their
history split because they include untracked changes. For the most
changedentities( i.e.,entitiesthatareconstantlyevolving),thispro-
portionisevenhigher(37%).Astheseentitiestendtohavealong
lifespan,inpractice,theissueismagnified.Therefore,werecom-
menduntrackedchangeresolutionwhenperformingtraceability
analysis, for more precise entity lifespans.Resolving untracked changes can positively or negatively affect MSR
approaches. WeassessedtwospecificMSRapproaches(APIevolu-
tion and co-usage rule mining), and detected that their results can
beimprovedwhenuntrackedchangesareresolved.Inourempir-
ical study, more rules were produced with slightly better overall,
butvery variable quality. Thus, we suggest MSR researchers to
adopt refactoring detection techniques to potentially improve their
mining results on a case-by-case basis.
10 THREATS TO VALIDITY
Generalization of results. We focused our analysis on 15 popular,
real-world,andpubliclyavailable(astheyarehostedonGitHub)
Java systems. This is twice than similar studies [ 25,30]. Despite
these observations, our findings—as usual in empirical software
engineering—may not be directly generalized to other systems,
especially to commercial and to systems implemented in other pro-
gramming languages. Further, the variability observed in Figure 9
indicatesthattheeffectofuntrackedchangesishardtopredict,a
further incentive for replication.
Detection of untracked changes. We may underestimate or over-
estimate the threat of untracked changes. We use RefDiff [ 58]t o
detect untracked changes: any false positive reported by RefDiff
will make us overestimate the threat, while any false negative will
makeusunderestimateit.WenotehoweverthatRefDiffisastate
of the art approach; its performance was found to exceed other
refactoring detection approaches [ 58], with precision varying from
85.4% to 100% (meaning RefDiff reports few false positives), andrecall ranging from 93.6% to 93.9% (meaning RefDiff reports few
false negatives). Despite these observations, we took additional
precautions,byevaluatingtheprecisionandrecallofRefDiffinour
dataset with two manual assessments (as reported in Section 4);
inthiscase,wefoundanoverallprecisionandrecallof89.1%and
89.8%, respectively. Therefore, to our knowledge, the risk of this
threat is reduced.
Impact of the threat. The threat of untracked changes may not
translate in actual issues to MSR-based studies. To address this,
we investigated the threat impact in two specific approaches (API
evolution and co-usage rule mining), as reported in research ques-
tion 3. We found that the performance of these MSR approachescan be improved when untracked changes are resolved, but the
improvements are very variable.
11 RELATED WORK
11.1 Assessing threats in empirical studies
Several studies have been performed to assess the quality of the
data in software repositories, and whether issues found in the data
may be problematic. A systematic review of empirical software
engineering studies by Liebchen and Shepperd [41]found that (as
of 2008) a very small portion of them explicitly mentioned data
quality, indicating a low awareness of data quality issues.
The closest research to our study is the work by Kawrykow and
Robillard [30]; they investigated the effect of non-essential changes
in version histories. A non-essential change is a change that affects
the source code of an entity without changing its behaviour. Ex-
ampleofnon-essentialchangesarerenamingalocalvariableina
1110
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Andre Hora, Danilo Silva, Marco Tulio Valente, and Romain Robbes
methodbody,addingorremovingthe thiskeyword,orevenwhite-
spacechanges.Approachesthatdochangerecommendationsbased
on past co-change patterns ( e.g.,class AandBchange together 90%
ofthetime)suchasZimmermann etal.[69],maymakespurious
recommendations if non-essential changes are taken into account.
Theydefineseveralcategoriesofnon-essentialchanges,andfind
that, in 7 software systems, up to 15.5% of changes to methods of a
softwaresystemarenon-essential,andthatremovingthesechanges
increased the precisionof a change recommendation approachby
10%,while itdecreased itsrecallby 4%.Ofnote,thenon-essential
changesdonotincludetheuntrackedchanges.QuotingKawrykow
and Robillard: “ We consider the actual renaming of the code element
to be an essential change, but argue that the textual reference up-
datesinducedbythatrenamingarenon-essential ”.Thus,onekind
ofchangeinvestigatedbybothpapersisrelated( i.e.,renamings),
but the set of changes is distinct.
HerzigandZeller [25]investigatedtheimpactoftangledcode
changes, that is, changes unrelated to each other that belong to
the same commit. They found that up to 15% of bug fixes in 5 Java
projectscontainedchangesunrelatedtothebugfix,basedonaman-
ualanalysis.Asubsequentautomatedanalysisfoundthatatleast
16.6% of files that are associated with a bug report are actually not
related to the report. A follow-up study by Herzig et al . [24]found
that the impact of tangled changes on defect prediction regression
models was significant. Dias et al . [15]proposed a technique to
untangle fine-grained code changes.
Beyond source code changes, defect prediction approaches and
datasets have been investigated for threats as well. Bird et al . [8]
investigatedwhetherthesubsetofbugreportscorrectlylinkedfrom
commitstobugtrackingsystemsisanaccuraterepresentationof
theoverallpopulationofbugs,andfoundevidenceofstrongand
systematic biases. In particular, for several systems, less severe
bugs weremore likelyto belinked than moresevere ones,raising
concernsabouttheaccuracyofbugpredictionapproaches.Afollow-upstudybyRahmanetal
.[52]foundthatthethreatwassomewhat
alleviated when the amount of data available was large enough.
Posnettetal .[49]raisedtheissueoftheecologicalfallacy,which
states that findings that are found at one level of analysis ( e.g.,files
of a software system), may not be valid at an aggregated level ( e.g.,
packages of that same system). They presented evidence of risks
ofecologicalfallacyfordefectpredictionmodels.Generalthreats
totheperformanceofmachinelearningalgorithmsincludeclass
imbalance anda highnumber offeatures; Khoshgoftaaret al .[31]
investigatedtheirimpactonsoftwaredefectprediction.Lanzaet
al.[40]presentedaseriesofreflectionsonhowdefectprediction
techniques are evaluated. For example, they claim that current
evaluationsdonotconsidertheeffectsinfurtherbugsofdevelopers
accepting the recommendations produced by a defect predictor.
11.2 Detecting untracked changes
Several approaches attempt, directly or indirectly, to deal with un-
trackedchanges.GodfreyandZou [20]introducedOriginAnalysis,
atechniquethatdetectsscenariosinwhichanentity( e.g.,aclass,
a function) is split in two, or two entities are merged in a single
one. The goal is to allow for a more precise tracking of the lifetime
of entities from version to version, that is, to detect a subset ofuntrackedchanges.However,theauthorsvalidatedtheapproach
ona singleexample(PostgreSQL), anddonot attempttoquantify
the extent of the threat in the same depth as we do. They found
that their technique is able to reduce the number of “apparently
deleted” entitiesby 30% and of"apparently added" entitiesby 19%.
Many approaches focus on detecting refactorings, which con-
stitute the core of the untracked changes. As examples, we have
RefDiff [58], Refactoring Miner [ 57,64], Refactoring Crawler [ 16],
and RefFinder [ 32]. In this work, we relied on RefDiff because it
exceeded the precision and recall of the mentioned related tools in
an evaluation reported by Silva et. al [58].
A related problem is the detection and the representation of
fine-grained changes. Soetens et al . [60]performed a survey on
thetopic,whichwerefertoforspacereasons.Examplesinclude:
detectingfine-grainedchangesbydifferencingprogramASTs,suchasChangeDistiller [
17],which hasbeen usedasa buildingblockto
detect non-essential changes; detecting systematic changes [33]; an
alternative to recovering changes is recording them [55].
12 CONCLUSION
To the best of our knowledge, this study is the first to assess the
threat of untracked changes, a threat often faced by MSR-based
approaches.Theempiricalstudywasperformedinthecontextof
15 real-world systems, and relied on RefDiff, the state of the art in
refactoringdetection,tofinduntrackedchangesinhistoryversions.
Three research questions were proposed to assess the frequency,
extension, and impact of untracked changes. We reiterate the most
interesting conclusions from our experimental results:
•Untrackedchangesaremorefrequentformethodsthanclasses.
The amount of untracked changes is not negligible, varying
from10%to21%formethods,andfrom2%to15%forclasses.
•Keepingtrackofuntrackedchangessuchasrenamingisnot
enough.Themostfrequentuntrackedchangetypesaremethod
renaming(26%),extraction(23%),andmoving(22%).Overall,
renamingsare responsibleby1/3 ofthe untrackedchanges
while other changes represent 2/3.
•Untrackedchangescommonlycausesplitsinentityhistories. A
quarter of the studied entities potentially have their history
split.Inthetop25%mostchangedentities,theproportion
raises to 37%.
•Resolvinguntrackedchangescanpositivelyornegativelyaf-
fect MSR approaches. By assessing two MSR approaches, we
detect that their results can be improved when untracked
changes are resolved; however, results are very variable.
As future work, we plan to extend this work to assess the im-
pactofuntrackedchangesinotherMSRstudiessuchastheones
described in Scenario 2 (warning prioritization) and in Scenario
3(authorshipdetection).Moreover,weplantofurtherassessthe
branchesandmergesinthechangegraph(causedbymethodex-
traction and inlining) as a proxy of traceability complexity; in this
case, we can measure nodes outdegree and indegree. Finally, we
plantoincreasetheamountofcasestudiesinourempiricalanalysis
to better assess and characterize variability issues.
ACKNOWLEDGMENT
This research is supported by Fundect, CNPq, and FAPEMIG.
1111
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. Assessing the Threat of Untracked Changes in Software Evolution ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]John Anvik,Lyndon Hiew, andGail CMurphy. 2006. Who shouldfix thisbug?.
InInternational Conference on Software Engineering .
[2]Muhammad Asaduzzaman, Michael C Bullock, Chanchal K Roy, and Kevin A
Schneider.2012. Bugintroducingchanges:AcasestudywithAndroid.In Working
Conference on Mining Software Repositories .
[3]GuilhermeAvelino,LeonardoPassos,AndreHora,andMarcoTulioValente.2016.
A novel approach for estimating truck factors. In International Conference on
Program Comprehension .
[4]Nathaniel Ayewah, David Hovemeyer, J David Morgenthaler, John Penix, and
WilliamPugh.2008. Usingstaticanalysistofindbugs. IEEESoftware 25,5(2008).
[5]Nathaniel Ayewah and William Pugh. 2010. The Google FindBugs fixit. In
International Symposium on Software Testing and Analysis .
[6]GabrieleBavota,GerardoCanfora,MassimilianoDiPenta,RoccoOliveto,and
SebastianoPanichella.2015. HowtheApachecommunityupgradesdependencies:
an evolutionary study. Empirical Software Engineering 20, 5 (2015).
[7]Gabriele Bavota, Mario Linares-Vasquez, Carlos Eduardo Bernal-Cardenas, Mas-
similiano Di Penta, Rocco Oliveto, and Denys Poshyvanyk. 2015. The impactof API change-and fault-proneness on the user ratings of Android apps. IEEE
Transactions on Software Engineering 41, 4 (2015).
[8]ChristianBird,AdrianBachmann,EirikAune,JohnDuffy,AbrahamBernstein,
Vladimir Filkov, and Premkumar Devanbu. 2009. Fair and balanced?: bias in
bug-fix datasets. In International Symposium on the Foundations of Software Engi-
neering.
[9]CathalBoogerdandLeonMoonen.2009. Evaluatingtherelationbetweencoding
standardviolationsandfaultswithinandacrosssoftwareversions.In Working
Conference on Mining Software Repositories .
[10] Oliver Burn. 2007. Checkstyle. (2007).
[11]LeonMoonenCathalBoogerd.2008. Assessingthe valueofcodingstandards:an
empirical study. In International Conference on Software Maintenance .
[12]Tse-HsunChen,MeiyappanNagappan,EmadShihab,andAhmedEHassan.2014.
An empiricalstudy of dormant bugs.In Working Conferenceon Mining Software
Repositories .
[13] Tom Copeland. 2005. PMD applied. (2005).[14]
CesarCouto,JoaoEduardoMontandon,ChristoferSilva,andMarcoTulioValente.
2013. Static correspondence and correlation between field defects and warnings
reported by a bug finding tool. Software Quality Journal 21, 2 (2013).
[15]Martín Dias, Alberto Bacchelli, Georgios Gousios, Damien Cassou, and StéphaneDucasse.2015. Untanglingfine-grainedcodechanges.In InternationalConference
on Software Analysis, Evolution and Reengineering .
[16]DannyDig,CanComertoglu,DarkoMarinov,andRalphJohnson. Automated
detection of refactorings in evolving components. In European Conference on
Object-Oriented Programming .
[17]BeatFluri,MichaelWuersch,MartinPixnzger,andHaraldGall.2007. Change
distilling: tree differencing for fine-grained source code change extraction. IEEE
Transactions on Software Engineering 33, 11 (2007).
[18]Thomas Fritz, Gail C Murphy, Emerson Murphy-Hill, Jingwen Ou, and Emily
Hill. 2014. Degree-of-knowledge: modeling a developer’s knowledge of code.
ACM Transactions on Software Engineering and Methodology 23, 2 (2014).
[19]ThomasFritz,JingwenOu,GailCMurphy,andEmersonMurphy-Hill.2010. Adegree-of-knowledgemodeltocapturesourcecodefamiliarity.In International
Conference on Software Engineering .
[20]Michael W Godfrey and Lijie Zou. 2005. Using origin analysis to detect merging
andsplittingofsourcecodeentities. IEEETransactionsonSoftwareEngineering
31, 2 (2005).
[21]Verónica Uquillas Gómez, Stéphane Ducasse, and Theo D’Hondt. 2010. Visually
supportingsourcecodechangesintegration:theTorchdashboard.In Working
Conference on Reverse Engineering .
[22]Verónica Uquillas Gómez, Stéphane Ducasse, and Theo D’Hondt. 2015. Visually
characterizingsourcecodechanges. ScienceofComputerProgramming 98(2015).
[23]LileHattoriandMicheleLanza.2009. Miningthehistoryofsynchronouschanges
torefinecodeownership.In InternationalWorkingConferenceonMiningSoftware
Repositories .
[24]KimHerzig,SaschaJust,andAndreasZeller.2016. Theimpactoftangledcode
changesondefectpredictionmodels. EmpiricalSoftwareEngineering 21,2(2016).
[25]Kim Herzig and Andreas Zeller. 2013. The impact of tangled code changes. In
Working Conference on Mining Software Repositories .
[26]AndreHora,NicolasAnquetil,StephaneDucasse,andSimonAllier.2012. Domain
specificwarnings:are theyanybetter?. In InternationalConferenceon Software
Maintenance .
[27]AndreHora,RomainRobbes,NicolasAnquetil,AnneEtien,StephaneDucasse,
and Marco Tulio Valente. 2015. How do developers react to API evolution? The
Pharo ecosystemcase.In International Conference on Software Maintenance and
Evolution .
[28]Andre Hora, Romain Robbes, Marco Tulio Valente, Nicolas Anquetil, Anne Etien,
and Stephane Ducasse. 2017. How do Developers React to API Evolution? A
Large-Scale Empirical Study. Software Quality Journal (2017), 1–33.[29]Andre Hora and Marco Tulio Valente. 2015. apiwave: Keeping Track of API
PopularityandMigration.In InternationalConferenceonSoftwareMaintenance
and Evolution .
[30]DavidKawrykowandMartinPRobillard.2011. Non-essentialchangesinversion
histories. In International Conference on Software Engineering .
[31]Taghi M Khoshgoftaar, Kehan Gao, and Naeem Seliya. 2010. Attribute selection
and imbalanced data: problems in software defect prediction. In International
Conference on Tools with Artificial Intelligence .
[32]Miryung Kim, Matthew Gee, Alex Loh, and Napol Rachatasumrit. 2010. Ref-Finder: a refactoring reconstruction tool based on logic query templates. In
International Symposium on the Foundations of Software Engineering .
[33]Miryung Kim and David Notkin. 2009. Discovering and representing systematic
code changes. In International Conference on Software Engineering .
[34]Sunghun Kim and Michael D Ernst. 2007. Prioritizing warning categories by
analyzing software history. In International Workshop on Mining Software Reposi-
tories.
[35]Sunghun Kim and Michael D. Ernst. 2007. Which warnings should I fix first?. In
International Symposium on the Foundations of Software Engineering .
[36]Sunghun Kim, Kai Pan, and E. E. James Whitehead, Jr. 2006. Memories of bug
fixes. InInternational Symposium on the Foundations of Software Engineering .
[37]Sunghun Kim and E James Whitehead Jr. 2006. How long did it take to fix bugs?.
InInternational Workshop on Mining Software Repositories .
[38]SunghunKim,EJamesWhiteheadJr,andYiZhang.2008. Classifyingsoftware
changes:Cleanorbuggy? IEEETransactionsonSoftwareEngineering 34,2(2008).
[39]Sunghun Kim, Thomas Zimmermann, Kai Pan, and E. James Jr. Whitehead. 2006.
Automatic identification of bug-introducing changes. In International Conference
on Automated Software Engineering .
[40]Michele Lanza, Andrea Mocci, and Luca Ponzanelli. 2016. The tragedy of defect
prediction, prince of empirical software engineering research. IEEE Software 33,
6 (2016).
[41]Gernot A Liebchen and Martin Shepperd. 2008. Data sets and data quality in
software engineering. In International Workshop on Predictor Models in Software
Engineering .
[42]Mario Linares-Vásquez, Gabriele Bavota, Carlos Bernal-Cárdenas, Massimiliano
Di Penta, Rocco Oliveto, and Denys Poshyvanyk. 2013. API change and fault
proneness: athreat to thesuccess of Androidapps. In International Symposium
on the Foundations of Software Engineering .
[43]BenjaminLivshitsandThomasZimmermann.2005. DynaMine:findingcommon
error patterns by mining software revision histories. In International Symposium
on the Foundations of Software Engineering .
[44]Andrew Meneely and Oluyinka Williams. 2012. Interactive churn metrics: socio-
technical variants of code churn. Software Engineering Notes 37, 6 (2012).
[45]SichenMeng,XiaoyinWang,LuZhang,andHongMei.2012. Ahistory-based
matching approach to identification of framework evolution. In International
Conference on Software Engineering .
[46]Yana Momchilova Mileva, Andrzej Wasylkowski, and Andreas Zeller. 2011. Min-
ing evolution of object usage. In European Conference on Object-Oriented Pro-
gramming .
[47]Shawn Minto and Gail C Murphy. 2007. Recommending emergent teams. In
International Workshop on Mining Software Repositories .
[48]RalphPetersandAndyZaidman.2012. Evaluatingthelifespan ofcodesmellsus-
ingsoftwarerepositorymining.In EuropeanConferenceonSoftwareMaintenance
and Reengineering .
[49]Daryl Posnett, Vladimir Filkov, and Premkumar Devanbu. 2011. Ecological
inferenceinempiricalsoftwareengineering.In AutomatedSoftwareEngineering .
[50]StevenRaemaekers,ArievanDeursen,andJoostVisser.2012.Measuringsoftware
librarystabilitythroughhistoricalversionanalysis.In InternationalConference
on Software Maintenance .
[51]Foyzur Rahman and Premkumar Devanbu. 2011. Ownership, experience and
defects:afine-grainedstudyofauthorship.In InternationalConferenceonSoftware
Engineering .
[52]FoyzurRahman,DarylPosnett,IsraelHerraiz,andPremkumarDevanbu.2013.
Sample size vs. bias in defect prediction. In International Symposium on the
Foundations of Software Engineering .
[53]Foyzur Rahman, Daryl Posnett, Abram Hindle, Earl Barr, and Premkumar De-
vanbu. 2011. BugCache for inspections: hit or miss?. In International Symposium
on the Foundations of Software Engineering .
[54]Baishakhi Ray, Vincent Hellendoorn, Saheel Godhane, Zhaopeng Tu, Alberto
Bacchelli, and Premkumar Devanbu. 2016. On the naturalness of buggy code. In
International Conference on Software Engineering .
[55]Romain Robbes. 2008. Of change and software . Ph.D. Dissertation. Università
della Svizzera italiana.
[56]David Schuler and Thomas Zimmermann. 2008. Mining usage expertise from
version archives. In International Working Conference on Mining Software Reposi-
tories.
[57]DaniloSilva,NikolaosTsantalis,andMarcoTulioValente.2016.Whywerefactor?
confessionsofGitHubcontributors.In InternationalSymposiumontheFounda-
tions of Software Engineering .
1112
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden Andre Hora, Danilo Silva, Marco Tulio Valente, and Romain Robbes
[58]Danilo Silva and Marco Tulio Valente. 2017. RefDiff: detecting refactorings in
version histories. In International Conference on Mining Software Repositories .
[59]Gustavo Soares, Rohit Gheyi, Dalton Serey, and Tiago Massoni. 2010. Making
program refactoring safer. IEEE Software 27, 4 (2010).
[60]QuintenDavid Soetens,RomainRobbes, andSergeDemeyer.2017. Changesas
first-class citizens: a research perspective on modern software tooling. ACM
Computing Surveys 50, 2 (2017).
[61]DiomidisSpinellis.2015. Arepositorywith44yearsofUnixevolution.In Working
Conference on Mining Software Repositories .
[62] Diomidis Spinellis. 2017. A repository of Unix history and evolution. Empirical
Software Engineering (2017).
[63] Mario F Triola. 2006. Elementary statistics . Pearson/Addison-Wesley.
[64]Nikolaos Tsantalis, Victor Guana, Eleni Stroulia, and Abram Hindle. 2013. Amultidimensional empirical study on refactoring activity. In Conference of the
Centre for Advanced Studies on Collaborative Research . 132–146.
[65]SantiagoAVidal,ClaudiaMarcos,andJAndrésDíaz-Pace.2016. Anapproach
toprioritizecodesmellsforrefactoring. AutomatedSoftwareEngineering 23,3
(2016).
[66]WeiWu,Y.-G.Gueheneuc,G.Antoniol,andMiryungKim.2010. AURA:ahybridapproachtoidentifyframeworkevolution.In InternationalConferenceonSoftware
Engineering .
[67]Zuoning Yin, Ding Yuan, Yuanyuan Zhou, Shankar Pasupathy, and Lakshmi
Bairavasundaram.2011. Howdofixesbecomebugs?.In InternationalSymposium
on the Foundations of Software Engineering .
[68]Thomas Zimmermann, Sunghun Kim, Andreas Zeller, and E. James Whitehead,
Jr. 2006. Mining version archives for co-changed lines. In International Workshop
on Mining Software Repositories .
[69]Thomas Zimmermann, Andreas Zeller, Peter Weissgerber, and Stephan Diehl.
2005. Miningversionhistoriestoguidesoftwarechanges. IEEETransactionson
Software Engineering 31, 6 (2005).
1113
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:57:25 UTC from IEEE Xplore.  Restrictions apply. 