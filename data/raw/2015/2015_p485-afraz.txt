P3: Partitioned Path Proﬁling
Mohammed Afraz
Indian Institute of Science
IndiaDiptikalyan Saha
IBM Research
IndiaAditya Kanade
Indian Institute of Science
India
ABSTRACT
Acyclic path proﬁle is an abstraction of dynamic controlﬂow paths
of procedures and has been found to be useful in a wide spectrum
of activities. Unfortunately, the runtime overhead of obtaining such
a proﬁle can be high, limiting its use in practice.
In this paper, we presentpartitioned path proﬁling(P3) which
runsKcopies of the programin parallel, each with the same in-
put but on a separate core, and collects the proﬁle only for asub-
setof intra-procedural paths in each copy, thereby, distributing the
overhead of proﬁling. P3 identiﬁes “proﬁtable” procedures and as-
signs disjoint subsets of paths of a proﬁtable procedure to different
copies for proﬁling. To obtain exact execution frequencies of a sub-
set of paths, we design a new algorithm, called PSPP. All paths of
an unproﬁtable procedure are assigned to the same copy. P3 uses
the classic Ball-Larus algorithm for proﬁling unproﬁtable proce-
dures. Further, P3 attempts to evenly distribute the proﬁling over-
head across the copies. To the best of our knowledge, P3 is theﬁrst
algorithm for parallel path proﬁling.
We have applied P3 to proﬁle several programs in the SPEC 2006
benchmark. Compared to sequential proﬁling, P3 substantially re-
duced the runtime overhead on these programs averaged across all
benchmarks. The reduction was23%,43% and56% on average
for 2, 4 and 8 cores respectively. P3 also performed better than a
coarse-grained approach that treats all procedures as unproﬁtable
and distributes them across available cores. For 2 cores, the proﬁl-
ing overhead of P3 was on average5% less compared to the coarse-
grained approach across these programs. For 4 and 8 cores, it was
respectively18% and25% less.
Categories and Subject Descriptors
D.2.5 [Testing and Debugging]: Diagnostics; F.3.2 [Semantics of
Programming Languages]: Program analysis
General Terms
Algorithms, Performance
Keywords
Parallel, Distributed, Path Proﬁling, Divide and Conquer1. INTRODUCTION
Collecting execution frequencies of dynamic controlﬂow paths
of procedures reveals a wealth of information about the runtime
behavior and usage patterns of a program. Acyclic path proﬁle [4]
is an abstraction of dynamic controlﬂow paths of procedures and
gives execution frequencies of acyclic paths in a procedure. Acyclic
path proﬁle has been found to be a useful measure in a wide spec-
trum of activities ranging from compiler optimizations [10] to test-
ing [17], debugging [8] and maintenance [13].
Unfortunately, the runtime overhead of obtaining such a proﬁle
can be high, limiting its use in practice. For example, Vaswani et
al. [24] reported an average runtime overhead of50% with worst
case overhead of132%. Other studies (e.g. [6]) also report simi-
lar overheads. We believe that, with the prevalence of multi-core
systems and computing clusters, parallelizing acyclic path proﬁling
has become an attractive option to reduce proﬁling overhead. Sur-
prisingly, to date, there is no algorithm that exploits parallelism for
path proﬁling. In this paper, we present such an algorithm.
We propose to runKcopiesof the programin parallel, each
with the same input but on a separate core (or cluster node), and
collect the proﬁle only for asubsetof intra-procedural paths in each
copy, thereby, distributing the overhead of proﬁling. A straightfor-
ward approach to achieve this is to use the classic Ball-Larus algo-
rithm [4] to instrument only a subset of procedures in each copy,
in a way that, every procedure is proﬁled in exactly one copy. We
call this approachparallel Ball-Larus proﬁling(PBL) in contrast to
sequential Ball-Larus proﬁling(SBL) which proﬁles all the proce-
dures in one copy.
In practice, the number of (acyclic) paths may differ widely across
procedures, and consequently, also the proﬁling overheads. For ex-
ample, consider a programMwith three proceduresP,QandR
requiring100,10and5instrumentation probes to proﬁle all their
paths respectively. An instrumentationprobeis a statement added
by a proﬁling algorithm to a procedure to track the path-ids and
their execution frequencies. The number of probes gives a static es-
timate of the runtime overhead of proﬁling. If3cores are available,
PBL may assign one procedure to each copy (core). The copy pro-
ﬁling the procedurePis likely to be much slower than the others.
The beneﬁt of parallelization is limited by the speedup of theslow-
estcopy. Thus, PBL may fail to exploit parallelism to the fullest.
We therefore propose a novel approach which attempts to get
a more uniform distribution of proﬁling overhead by sub-dividing
the job of proﬁling all paths of a procedure into sub-jobs of pro-
ﬁling disjoint subsets of paths of the procedure. The subsets are
assigned to different staticinstancesof a procedure which are then
distributed across multiple copies. For example, our approach may
obtain three instances, sayP 1,P2andP 3, of the procedurePabove
and assign them to separate copies. The subsets of paths of a pro-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ESEC/FSE’15 , August 30 – September 4, 2015, Bergamo, Italy
c2015 ACM. 978-1-4503-3675-8/15/08...$15.00
http://dx.doi.org/10.1145/2786805.2786868
485cedure are constructed so that they form a partition. Hence, we
call our approachpartitioned path proﬁling(P3). P3 essentially
provides more opportunity for load balancing across cores by con-
structing smaller jobs from bigger jobs.
There are three key challenges that P3 needs to overcome: (1)
which procedures to select for partitioning and how to partition
their paths, (2) how to instrument an instance of a partitioned pro-
cedure so as to obtain exact execution frequencies of the paths pro-
ﬁled in it and (3) how to distribute the instrumented procedures to
achieve good load balancing.
We observe that even if the subsets of paths being proﬁled are
disjoint across two instances of a procedure, some instrumentation
probes may getduplicatedbetween them (see Section 2.2 for an ex-
ample). We consider proﬁling of sequential programs. Therefore,
once weﬁx an input, all copies of the program follow the same
dynamic controlﬂow path and hence, the duplicated probes along
that path get executed in multiple copies. In general, a path which
is not proﬁled in an instanceP imay still go through some probes
inP i. Thus, on one hand, we reduce the number of instrumentation
probes per instance. Whereas, on the other hand, we may increase
the runtime overhead due to the possibilities mentioned above. P3
therefore only selectively partitions procedures by identifying what
we call asproﬁtable procedures. The proﬁtable procedures and
the partitioning of their paths are identiﬁed by a static analysis that
uses both intra-procedural and inter-procedural controlﬂow infor-
mation. This addresses theﬁrst challenge.
We now consider the second challenge. An existing approach,
selective path proﬁling (SPP) [1], has been proposed to proﬁle only
asubsetof pathsS. We could have used SPP on each instance of
a proﬁtable procedure to proﬁle the subset of paths assigned to it.
Unfortunately, we noticed that SPP can assign thesamepath-id to
a pathp∈Sand a pathp��∈S(see Section 2.2 for an example).
This means that it can over-approximate the execution frequencies
of paths, in particular, by counting the execution frequencies ofp�
as those ofp. We therefore design a new algorithm calledpre-
cise selective path proﬁling(PSPP) which overcomes this issue in
SPP and use it in P3 for instrumenting the instances of a proﬁtable
procedure. The immediate beneﬁt of PSPP is that we can obtain
the overall proﬁle of a proﬁtable procedure by merely collating the
partial proﬁles obtained from its instances. For unproﬁtable pro-
cedures, we use the Ball-Larus algorithm. Thus, the exact acyclic
path proﬁles of all procedures can be obtained.
Finally, towards addressing the third challenge, P3 uses the num-
ber of instrumentation probes as a cost measure and distributes the
instrumented procedures to different copies. The optimal distribu-
tion in this setting is an NP-complete problem [14]. P3 therefore
uses a round-robin approach that produces a4/3th approximation
of the optimal distribution [15]. If multiple instances of a prof-
itable procedure are assigned to the same copy, P3 takes the union
of the sets of paths being proﬁled in them and instruments a single
instance for all the paths in the union.
Our approach differs from the existing approaches that attempt
to lower the proﬁling overhead. Some approaches attempt to reduce
the memory overhead [24, 9], whereas others attempt to reduce the
runtime overhead by focusing on a subset of paths that are relevant
in speciﬁc contexts [1, 24, 5]. In contrast, our goal is to reduce
runtime overhead while proﬁlingallpaths. Our approach is also
applicable if only a subset of paths is of interest but we donotmake
this assumption about the usage scenario to speed up proﬁling.
We have implemented the PSPP and P3 algorithms for sequen-
tial C/C++ programs and applied them to proﬁle several programs
in the SPEC 2006 benchmark [16]. Compared to SBL, P3 substan-
tially reduced the runtime overhead on these programs averaged2
115
1012
exitv0entry
v1
v2
v3v4
v5 v6
v7
v8 v9
v10
v11v12
v13 v14
v15
v16 v17
v18
v19v20
v21892
14
12 10
1
exitv0entry
v1
v2
v3v4
v5v6
v7
v8 v9
v10
v11v12
v13 v14
v15
v16 v17
v18
v19 v20
v21
(a)P a (b)P b
Figure 1: A partition(P a, Pb)of a procedureP
across multiple inputs. The reduction was23%,43% and56% on
average across these programs for 2, 4 and 8 cores respectively. The
proﬁling overhead for an input is taken to be the maximum of the
number of times instrumentation probes are executed on the same
input across the individual copies. It is essentially the overhead in-
curred by the slowest copy. P3 also performed better than PBL. We
used the round-robin approach of distribution for both P3 and PBL.
For 2 cores, the proﬁling overhead of P3 was on average5% less
compared to PBL across these programs. For 4 and 8 cores, it was
respectively18% and25% less.
We summarize the main contributions of our work as follows:
•We present P3 – an algorithm for efﬁcient parallelization of
path proﬁling. To the best of our knowledge, this is theﬁrst
algorithm for parallel path proﬁling.
•We present PSPP – an algorithm to obtainexactexecution
frequencies of a subset of paths of a procedure – which is
used in P3. PSPP on its own can be used in applications such
as residual testing [22, 9, 7].
•We have implemented P3 and show its effectiveness com-
pared to the sequential and parallel Ball-Larus proﬁling on
several SPEC 2006 benchmark programs for2,4and8cores.
2. OVERVIEW
Weﬁrst present the deﬁnitions used in the paper and some back-
ground. We then illustrate the key steps of P3 through examples.
2.1 Deﬁnitions and Background
Consider a directed acyclic graph (DAG)Gwhich represents
all acyclic intra-procedural paths of a procedureP. We refer the
reader to [4] on how such a DAG is constructed from the control
ﬂow graph of a procedure. Formally,G= (V, E, entry, exit)
whereVis aﬁnite set of vertices representing basic blocks ofP,
the set of edgesE⊆V×Vapproximates the controlﬂow between
the respective basic blocks, andentryandexitare respectively
the unique entry and exit vertices ofG. For example, Figure 1(a)
shows a DAG for some procedure. For a vertexv∈V, the set of
successors is given bysucc(v) ={w∈V|(v, w)∈E}.
Given apathpinG,edges(p)gives the set of edges inp. For
a pathppassing through a vertexv,suff(p, v)denotes the sufﬁx
ofpstarting withv. We useN vto denote the number of paths
passing throughv. Alabeling functionLassociates a natural num-
ber, called anedge label, to each edge inG. Thepath-idof a path
pis the sum of edge labels of edges inedges(p)and is denoted
bypathid(p). As a convention, zero-valued edge labels are not
4860v0
v1 v2Nv1 Nv1+N v2
v3
Figure 2: Ball-Larus labeling
shown. The path-id ofp=�entry, . . . , v 4, v6, v7, v9, . . . , exit�
is10. A proﬁling algorithm assigns edge labels and instruments
the edges to compute the path-id at runtime. Thus, each edge with
a non-zero label is instrumented with a statement called an instru-
mentationprobe. For a procedureP,overhead(P)is the total
number of non-zero edges in the DAG ofPand is taken as an es-
timate of the runtime overhead of proﬁlingP. Under the labeling
shown in Figure 1(a), the overhead for that procedure is6.
For a procedureP, if there are multiple instances used for pro-
ﬁling a partition of its paths, we denote the set of paths being
proﬁled in an instanceP ibyinteresting(P i). We call a labeling
functionL ifor an instanceP i, a valid labeling, if every pathp∈
interesting(P i)has a unique path-id (under the labelingL i) which
is distinct from the path-ids of paths which are not ininteresting(P i).
Formally, a labelingL iis avalid labelingof an instanceP iif:
(a)∀p, q∈interesting(P i) :pathid(p)�=pathid(q)
(b)∀p∈interesting(P i),∀r�∈interesting(P i) :
pathid(p)�=pathid(r)
A valid labeling generates the exact execution frequencies of the
interesting paths of a procedure from a single copy. This in turn
simpliﬁes the job of obtaining exact frequencies of all paths of a
procedure spread across multiple copies. We note that a valid label-
ing may assign the same path-id to two paths not ininteresting(P i).
If there is onlyoneinstance of a procedureP(that is, its set of
paths is not sub-divided) then the classic Ball-Larus algorithm [4]
already yields a valid labelingL. We give a brief overview of
the Ball-Larus algorithm. In theﬁrst step, it visits the vertices
in the DAG in the reverse topological order and labels a vertex
vby the number of pathsN vpassing through it. The algorithm
considers an arbitrary order among the outgoing edges of a ver-
tex. For theﬁrst edgee 1,L(e 1) = 0and for anith edgee i,
L(e i) =L(e i−1) +N vi−1wheree i−1= (v, v i−1). Figure 2
shows how the outgoing edges of a vertexv 0are labeled. If an
edge(v, v i)is labeled before an edge(v, v j)then the labeling en-
sures that all the paths passing though the edge(v, v j)have greater
path-ids than path-ids of paths passing through the edge(v, v i). In
the next step, a maximum spanning tree of the DAG is computed
and labels are revised using an event counting algorithm [2] and
placed only on the chords (complement of spanning tree edges).
2.2 Examples
Partitioning paths of a proﬁtable procedure.Let a procedureP
whose DAG is shown in Figure 1(a) be a proﬁtable procedure. We
describe our approach of classifying procedures into proﬁtable and
unproﬁtable in Section 3.2.
Suppose the two instancesP aandP bof the procedure shown
in Figure 1(a) and Figure 1(b) are constructed for proﬁling disjoint
sets of paths ofP. A pathpis proﬁled in an instance if all the edges
inedges(p)are shown in solid lines in that instance. For example,
the path�entry, v 0, exit�is proﬁled in the instanceP bbut not in
Pa. The edges in both the instances are labeled with valid labeling.
We have,overhead(P a) = 6andoverhead(P b) = 8. Now,
consider another partition of the paths ofPgiven by two instances
P�
aandP�
bshown in Figure 3(a) and Figure 3(b), also labeled with
valid labeling. Here,overhead(P�
a) = 5andoverhead(P�
b) =89 11012
exitv0entry
v1
v2
v3v4
v6 v5
v7
v8 v9
v10
v11v12
v13 v14
v15
v16 v17
v18
v19 v20
v211610
2
exitv0entry
v1
v2
v3v4
v5v6
v7
v8 v9
v10
v11v12
v13 v14
v15
v16 v17
v18
v19 v20
v21
(a)P�
a (b)P�
b
Figure 3: A partition(P�
a, P�
b)of the procedurePwhich results
in less overheads than the partition of Figure 1.
4. Since the maximum overhead of(P�
a, P�
b)is smaller than the
maximum overhead of(P a, Pb), the partition(P�
a, P�
b)is likely to
yield better performance than the partition(P a, Pb).
We now analyze the cause of inefﬁciency in(P a, Pb). Consider
a pathp 0=�entry,· · ·, v 6, v7, v8,· · ·, exit�. This path encoun-
ters two probes, respectively at(v 6, v7)and at(v 8, v10), inP aand
one probe(v 6, v7)inP b. Thus, the runtime overhead due to ex-
ecution of this path affects both the instances. Similar is the case
for the paths passing throughV 2={v 12, v15, v18, v21}. In gen-
eral, it may be difﬁcult to avoid such situations, but P3 performs
a controlﬂow analysis, whereby, it assigns all the paths passing
though a sequence of conditionals, that do not have other condi-
tionals nested within them, to only one instance. This is seen for
the partition(P�
a, P�
b)shown in Figure 3. Here, all the paths pass-
ing throughV 1={v 4, v7, v10}are proﬁled inP�
a, whereas all the
paths passing throughV 2are proﬁled inP�
b. Due to the resultant
labeling, the runtime overhead due to execution of those paths (in-
cludingp 0) will affect only one instance. This partitioning strategy
reducesoverlapping proﬁling overheads. For this example, P3 can
compute(P�
a, P�
b)as the partition of paths ofP.
Computing valid labeling of proﬁtable procedures.The selective
path proﬁling (SPP) algorithm [1] is designed to compute an edge
labeling that assigns unique path-ids to a chosen subset of pathsS.
However, for a labeling to be valid, we additionally require that the
path-ids of paths inSshould bedistinctfrom those of paths not in
S. SPP does not satisfy this requirement as demonstrated below.
Consider the set of interesting pathsSproﬁled in an instance
of a procedurePshown in Figure 4(a). An edge that appears in
some uninteresting path is shown in dashed lines in Figure 4(a) and
Figure 4(b). We refer to such edges asuninteresting edges. Sim-
ilar to the Ball-Larus algorithm, in theﬁrst step, SPP proceeds in
the reverse topological order except that at each vertex, it processes
all uninteresting (outgoing) edges before the interesting ones. Fig-
ure 4(a) shows the edge labels thus computed. In the next phase,
SPP visits the vertices in the topological order and if(v, w)is the
only incoming edge towthen SPP adds its label to the labels of all
the outgoing edges ofwand sets the label of(v, w)to zero. The
labels obtained after this step are shown in Figure 4(b). In the third
andﬁnal step, it sets the labels of all uninteresting edges to zero. In
our example, the non-zero labels of uninteresting edges(v 3, v11)
and(v 14, v15)are set to zero. The other uninteresting edges are
anyway zero after the second step (see Figure 4(b)). The labeling
after the third step is not shown due to space constraints.
4870
00
0112
002
0
004 1
00
000
0
0
001
0 5
0
0
00
exitv0v1
v2
v3v4
v5v6
v7
v8 v9
v10
v11v12
v13 v14
v15
v16 v17
v18
v19 v20
v21entry0
00
1000
000
2
10
14
020
0
0
000
100
0 0
0
6
0
0
exitv0entry
v3v4
v5v6
v7
v8 v9
v10
v11v13 v14
v15
v16 v17
v18
v19 v20
v21v2v12v1
(a) (b)
Figure 4: Steps of SPP: (a) labeling after theﬁrst step and (b)
labeling after the second step.
Consider two pathsp=�entry,· · ·, v 6, v7, v8,· · ·, exit�and
p�=�entry,· · ·, v 14, v15, v16, v18, v19,· · ·, exit�wherep∈S
andp��∈S. However, under the labeling computed by SPP (in the
third step), the path-ids of the two are thesame, equal to3. Since
the edge(v 14, v15)is uninteresting, as stated above, SPP sets its
label to zero in the third step, resulting in this situation.
In order to overcome the overlapping path-ids assigned by SPP
and to obtain valid labeling for individual instances of a proﬁtable
procedure, we design a variant of SPP, called the precise SPP (PSPP)
algorithm. Figure 1(a) shows the labeling obtained by PSPP for the
same subset of paths as in Figures 4(a) and 4(b). In particular, the
pathspandp�identiﬁed earlier respectively get distinct path-ids
11and3in Figure 1(a). We explain the computation of the valid
labeling by PSPP in the next section.
3. ALGORITHMS
In this section, weﬁrst present the PSPP algorithm for proﬁling
a subset of paths, followed by the P3 algorithm.
3.1 Precise Selective Path Proﬁling
Our precise selective path proﬁling (PSPP) algorithm is a variant
of the SPP algorithm and computes only valid labeling. Before we
design the algorithm, we analyze SPP in more depth.
In-depth analysis of SPP .Let us consider our running example in
Figure 4(a) and understand the reason why SPP cannot construct a
valid labeling. In theﬁrst step of SPP, an uninteresting edge may
get a zero label but it may become non-zero after the second step
which propagates edge labels in the topological order as described
in Section 2.2. For example, the uninteresting edge(v 3, v11)has a
zero label in Figure 4(a) but gets a non-zero label in Figure 4(b).
In the third step, SPP sets non-zero labels of uninteresting edges
to zero. We use the termabsorbto denote when the non-zero label
of an uninteresting edge is made zero in the third step of SPP. A
pathpabsorbswhen an edge inedges(p)absorbs. Since interest-
ing paths do not contain uninteresting edges, they are always unab-
sorbable. Note that before the third step, path-ids produced by SPP
are unique and only after absorption, path-id of some uninteresting
path may overlap with that of some interesting path.
Letpid(p, v), called apartial identiﬁer, denote the sum of edge
labels of the sufﬁxsuff(p, v)of a pathpfrom vertexvonwards.
Clearly,pathid(p) =pid(p, entry).
Consider two pathspandp�going through a vertexvsuch that
they are respectively uninteresting and interesting paths. Further,
let an edge(v, w)be an uninteresting edge that appears inp. Sim-ilarly, let an edge(v, w�)be an interesting edge that appears inp�.
SPP processes the uninteresting edges before interesting edges at
vin theﬁrst step to try to make sure thatpid(p, v)< pid(p�, v).
pid(p, v)remains less thanpid(p�, v)after the second step and in
particular, after absorption (the third step).
Example 1.Atv 2, the uninteresting edge(v 2, v3)is processed
by SPP before the interesting edge(v 2, v4)in Figure 4(a). Con-
sider an uninteresting pathp 0=�entry, v 1, v2, v3, v11, exit�go-
ing throughv 2. In Figure 4(a),pid(p 0, v2)is less than thepidof
the sufﬁx starting atv 2for any interesting path passing throughv 2.
After absorption,pid(p 0, v2)still remains less thanpids of sufﬁxes
starting atv 2for the interesting paths going throughv 2.
Unfortunately,pid(p, v)of an uninteresting pathpwhich goes
through aninterestingoutgoing edge ofvcan bemorethan that of
an interesting path going throughv. SPP does not ensure that they
will not become equal after absorption as shown next.
Example 2.Consider pathsp=�entry,· · ·, v 6, v7, v8,· · ·, exit�
andp�=�entry,· · ·, v 14, v15, v16, v18, v19,· · ·, exit�in Fig-
ure 4(b) which get the same path-id (equal to 3) after the edge
(v14, v15)absorbs, as discussed in Section 2.2. The key observa-
tion from Figure 4(a) is the following. In theﬁrst step of SPP, while
processingv 1’s outgoing interesting edges,(v 1, v2)is processed
before(v 1, v12). This assigns the value 5 to the edge(v 1, v12)as
there are 5 paths passing throughv 2. This labeling is faulty, as even
though it makespid(p�, v1)> pid(p, v 1), they become equal af-
ter the absorption. The central problem of SPP is that it does not
assign any order in processing of the interesting outgoing edges.
The PSPP algorithm.We now present the PSPP algorithm to rem-
edy the faulty labeling arising in SPP. While SPP picks interesting
outgoing edges of a vertexvduring theﬁrst step in anarbitrary
order, PSPP enforces a speciﬁc order among those edges. For a
vertexv, PSPP processes the outgoing edges(v, w), inthe decreas-
ing order ofw.minwherew.minis deﬁned as the minimumpid
of theinteresting pathsstarting fromw. This, together with the
processing of uninteresting outgoing edges before the interesting
outgoing edges ensures valid labeling. Speciﬁcally, it ensures that
an uninteresting pathppassing throughvafter absorption results in
pid(p, v)< v.minand therefore will not have same path-ids with
the interesting paths passing throughv. This holdsirrespectiveof
whetherpstarts with an uninteresting or an interesting edge atv.
This is in contrast with SPP, since such a claim is valid for SPP
only ifpstarts with an uninteresting edge atvas discussed earlier.
With this intuition, we next describe the PSPP algorithm in detail
(see Algorithm 1). PSPP takes a DAGGand an edge setEIof
edges appearing in interesting paths as input and produces avalid
labeling of edges inG. The label of an edgeeis denoted bye.val.
Algorithm 1 initializesv.minto∞for all vertices ofGexcept
theexitvertex (line 2). For theexitvertex, it initializesexit.min
to zero andN exitto one (line 3). In the loop at lines 4–13, PSPP
iterates over the vertices ofG(excluding theexitvertex) in the
reverse topological order. This is similar to theﬁrst step of SPP but
differs from SPP in the order in which interesting outgoing edges
are processed, as explained below. For each vertexv, it initializes
Nvto zero (line 5). In the loop at lines 6–8, itﬁrst iterates over the
uninteresting outgoing edges ofvand for each uninteresting edge
e= (v, w), it setse.valto zero. It also accumulates the value of
NwinN v(line 7). Then, in the loop at lines 9–12, it iterates over
the interesting outgoing edges in the decreasing order ofw.min.
For each such edgee= (v, w), it assigns the current value of
Nvtoe.val(line 10), updatesN vby addingN w(line 10) and
updates the value ofv.minby taking the minimum of the current
488Algorithm 1:PSPP(G,EI)
Input: A DAGG= (V, E, entry, exit)and a set of
interesting edgesEI⊆E
Output: A valid edge labeling ofG
1begin
2foreachv∈V\ {exit}dov.min← ∞
3exit.min←0;N exit←1
4foreachnon-exit nodevin reverse topological orderdo
5 Nv←0
6 foreachuninteresting edgee= (v, w)do
7 e.val←0;N v←N v+N w
8 end
9 foreachinteresting edge e =(v, w)in decreasing order
ofw.mindo
10 e.val←N v;Nv←N v+N w
11 v.min←Minimum(v.min, w.min+e.val)
12 end
13 end
14 foreachnon-exit nodevin topological orderdo
15 ifvhas only one edgee i= (u, v)ande i.val >0then
16 foreache o= (v, w)do
17 eo.val←e o.val+e i.val
18 end
19 ei.val←0
20 end
21 end
22 foreachedge e not in EIdoe.val←0
23end
value ofv.minandw.min+e.val. The loops at lines 14–21 and
line 22 implement the second and third steps of SPP respectively.
In particular, the loop at line 22 performsabsorption.
Example 3.We now revisit the scenario of faulty labeling of the
outgoing edges ofv 1by SPP discussed in Example 2 and show
how PSPP remedies it. The processing of theﬁrst step of PSPP
will yield the same edge labeling as SPP for the subgraphs rooted
atv2andv 12as shown in Figure 4(a).
Whenv 1is processed,v 2.min= 2(corresponding to the path
�entry,· · ·, v 4, v6, v7, v8,· · ·, exit�) andv 12.min= 4(corre-
sponding to the path�entry,· · ·, v 13, v15, v17, v18, v20,· · ·, exit�).
Therefore,(v 1, v2)is processedlaterthan(v 1, v12)which makes
e1.val= 0ande 2.val= 8wheree 1= (v 1, v12)ande 2=
(v1, v2). Theﬁnal labeling obtained after propagation and absorp-
tion of labels by PSPP is shown in Figure 1(a). The paths
p=�entry,· · ·, v 6, v7, v8,· · ·, exit�
p�=�entry,· · ·, v 14, v15, v16, v18, v19,· · ·, exit�
will have path-ids 11 and 3, respectively, after the absorption step
absorbs the label 1 on(v 14, v15), propagated from(entry, v 1).
Consider another pathp 1=�entry, v 1, v2, v3, v11, exit�in Fig-
ure 1(a). Since it passes through an outgoing uninteresting edge
fromv 2,pid(p 1, v2)(same aspathid(p 1)due to absorption) re-
mains less thanv 2.minand consequently less thanv 12.min. This
prohibits any chance of colliding with interesting paths passing
throughv 12. Besides, it can be seen that any uninteresting pathp 2
havingpid(p 2, v2)higher thanv 2.minisunabsorbableand hence,
its path-id will not be changed by PSPP.
Proof of correctness.We show that theﬁnal labeling produced
by PSPP is a valid labeling (as deﬁned in Section 2.1). A detailed
proof of this claim is included in Appendix A.3.2 Partitioned Path Proﬁling
We now present the partitioned path proﬁling (P3) algorithm. P3
uses the PSPP algorithm presented in Section 3.1 as a sub-routine.
Data structures and helper functions.A programMis a set of
procedures. For a DAGG= (V, E, entry, exit)of a procedure
P,G.EandG.Vrespectively denote the set of edges and vertices
ofG. For a vertexv∈V,v.pathcountgives the number of paths
from theentryvertex tov.Tdenotes a set of tasks where each
task, denoted byT, corresponds to a subset of paths (sayT p) in
the program. For eachT∈T, we maintain twoﬁelds:T.Eand
T.CostwhereT.Eis the union ofedges(p)for allp∈T pand
T.Costgives the number of instrumentation probes required by
PSPP for proﬁling the paths inT pifT.E⊂G.E. IfT.E=G.E
thenT.Costis the number of probes required by the Ball-Larus
algorithm for proﬁling the paths inT p.
The function BL_DAG(P) returns the DAG based on the DAG
construction algorithm [4] for a procedurePand BL(G) returns
the edge labeling for proﬁling all paths in a DAGGusing the Ball-
Larus algorithm. The functionsize(X)returns the number of ele-
ments in the setX. The functioncaller_count(P)gives the num-
ber of call-sites ofPin the programM. For a DAGG, a set of
four vertices{a, b, c, d}forms adiamondif they have the follow-
ing edges among them{(a, b),(a, c),(b, d),(c, d)}. For example,
{v4, v5, v6, v7}in Figure 3(a) forms a diamond. Atriangleis a set
of three vertices{a, b, d}such that they have the following edges
among them{(a, b),(a, d),(b, d)}. We call the verticesaanddas
beginandendvertices. These controlﬂow structures respectively
represent if-else and if statements containing only straightline code
within the branches (equivalently, they do not contain nested con-
ditionals). The functionreduced_graph(G)returns a new DAG,
called areduced DAG, where all diamonds and triangles inGare
replaced by new vertices, calleddummy vertices. The incoming
edges to the begin vertex of a diamond (or a triangle) inGare
added as incoming edges to the dummy vertex it is replaced with.
The case of outgoing edges of the end vertex is analogous.
Letesbe a set of edges in the reduced DAGG�obtained from
a DAGG. For an edgee= (v, d)ore= (d, w)such thatd
is a dummy vertex, letoriginal(e)contain the set of edges in
Gbelonging to the diamond or triangle thatdreplaced while ob-
tainingG�. Ifxandyare the begin and end vertices of the dia-
mond (or triangle) corresponding todthen we also add{(v, x)|
(v, d)∈es}∪{(y, w)|(d, w)∈es}tooriginal(e). The
functionget_original_edges(es, G, G�)returns the set of edges
{(v, w)∈es|v, ware not dummy vertices}∪{e∈original(e�)|
e�= (v, d)ore�= (d, w)for some dummy vertexdinG�ande�∈
es}. Finally, the functionreachable_edges(v, G�)returns all the
edges reachable fromvinG�.
The P3 algorithm.The P3 algorithm is presented in Algorithm 2.
It takes a programMand aﬁnite setCof identical cores. For each
coreC i∈C, we maintain the followingﬁelds: (1)C i.E: set of
edges of the paths proﬁled inC i, (2)C i.load: computed as the
number of edges inC i.Eand (3)C i.Probes: set of probes inC i
(output of P3).
Lines 3–10.If the paths in the DAG of a procedure are partitioned
and assigned to different copies, there may be overlap of probes
across the copies. This can cause increase in runtime for both the
copies. Since we cannot completely eliminate such overlap, we
try to limit its impact by considering only those procedures that
may get called at most once in any execution. P3 therefore applies
partitioning to procedures (by callingﬁnd_partition at line 5) which
have no more than one caller. For the rest of the procedures, it
489Algorithm 2:P3(M, C)
Input: A programMand aﬁnite setCof identical cores
Output: An assignment of instrumented copies ofMto the cores
1T← ∅// a global variable to store tasks
2begin
3foreachprocedureP∈Mdo
4 DAGG←BL_DAG(P)
5 ifcall_count(P)≤1thenﬁnd_partition(G)
6 else
7 probes←BL(G)
8 T.E←G.E;T.Cost←size(probes)
9 AddTtoT
10 end
11 end
12 foreachtaskT∈Tin the decreasing order ofT.Costdo
13 LetC ibe the core with the minimum load
14 Ci.E←C i.E∪T.E
15 Ci.load←C i.load+T.Cost
16 end
17 foreachC i∈CandP∈Mdo
18 G←BL_DAG(P)
19 EP←G.E∩C i.E
20 ifE P=G.EthenAdd BL(G) toC i.P robes
21 elseAdd PSPP(G,E P) toC i.P robesend
22 end
23end
24Functionﬁnd_partition(G)
25begin
26 LetG= (V, E, entry, exit)
27 G�←reduced_graph(G)
28 foreachv∈G�.V\ {entry}dov.pathcount←0,v.SE← ∅
29 entry.SE←{∅};entry.pathcount←1
30 totalpathcount←1;S← ∅
31 foreachvertexv∈G�.Vin topological orderdo
32 totalpathcount←totalpathcount−v.pathcount
33 foreach(v, w)∈G�.Edo
34 add(v, w)toS
35 foreaches∈v.SEdo
36 Addes∪{(v, w)}tow.SE
37 Incrementw.pathcountandtotalpathcountby1each
38 iftotalpathcount=Δthen gotoLBL
39 end
40 end
41 end
42 LBL:foreachvs.t.∃(u, v)∈S∧ ∃(v, w)/∈Sdo
43 foreaches∈v.SEdo
44 foreach(v, w)∈G�.E∧(v, w)/∈Sdo
45 add{(v, w)}∪reachable_edges(w, G�)toes;
46 end
47 T.E←get_original_edges(es, G, G�)
48 probes←PSPP(G,T.E)
49 T.Cost←size(probes)
50 AddTtoT
51 end
52 end
53end
applies the classic Ball-Larus algorithm to determine the probes
(lines 7-9) and creates a task for each such procedure.
Lines 24–52.Theﬁnd_partition function combines the paths in
Gthat pass through some diamonds or triangles into one task. It
does so byﬁrst creating a reduced DAG as explained earlier. These
paths will share lots of overlapping instrumentation probes and are
therefore more suited for proﬁling in the same core.
Example 4.Consider the example in Figure 3. It containsﬁve
diamonds. The corresponding reduced DAG is formed by replacing
theﬁve diamonds with dummy vertices. There will be four paths inthe reduced DAG and corresponding to each such path, P3 creates
one task. Note that the resultant four tasks in the above example
can be proﬁled without any overlapping probes among them.
For large procedures, the number of paths in the reduced graph
can be large. Therefore, we employ a thresholdΔon the number
of tasks generated from a procedure. The tasks, in the presence of a
threshold, are computed on the reduced DAG as follows. For a ver-
texvin the reduced DAG, each element of the setv.SE, denoted
byes, refers to the set of edges corresponding to a path fromentry
tov. Starting fromentry, the vertices of the reduced DAG are tra-
versed in topological order (line 31). While processingv,w.SE
is updated (line 36) for each successorwofv. The process termi-
nates when the number of paths found (totalpathcount) is equal
to the thresholdΔ.Saccumulates all the edgescoveredduring
this process. In the loop beginning at line 42, a vertexvis selected
which is eitherexitor not all of its successors are processed in the
previous iteration. Forv, all edges reachable fromvtoexitpass-
ing through uncovered edges are added to each edge-set inv.SE
(line 45). Each such edge-set is mapped to the edges inGusing the
functionget_original_edges(line 47) and a task is created using
the edge-set deﬁned overG.
For some procedures (e.g., those without diamonds or triangles),
even ifﬁnd_partition is invoked at line 5, it will return only a single
task. A procedure on whichﬁnd_partition is invoked and it returns
multiple tasks is called aproﬁtable procedure.
Lines 12–16.For getting optimal beneﬁt out of the distribution,
one has to minimize the maximum time taken across all cores. It
turns out that the optimal distribution to minimize the maximum
cost across all cores is an NP-complete problem. The hardness
can be shown by reduction from multiprocessor scheduling prob-
lem [14]. In the multiprocessor scheduling problem (MSP), we are
givenmidentical machinesM 1, . . . , M mand n jobsJ 1, . . . , J n.
JobJ ihas a processing timep i>0and the goal is to assign jobs
to the machines so as to minimize the maximum load. The load
of a machine is deﬁned as the sum of the processing times of jobs
that are assigned to that machine. In our context, a task (T) is con-
sidered as equivalent to a job in MSP andT.Costis considered as
the processing timep ifor a jobJ i. We use a known 4/3th approx-
imation algorithm [15] for multiprocess scheduling for distribution
in P3. Here, in a loop, the highest-cost task among the remaining
non-distributed tasks is assigned to the core with least load.
Example 5.In the example in Figure 3, the four tasks have cost
1 (�entry,· · ·, v 0,· · ·, exit�), 1 (�entry,· · ·, v 3,· · ·, exit�), 3
(for the 4 paths passing throughv 4), and 7 (for the 8 paths pass-
ing throughv 12). If only two cores are available, the 4th task is
assigned to theﬁrst core andﬁrst three tasks are assigned to the
second core. This results into the distribution shown in Figure 3.
Lines 17–21.Finally, for each core, P3 collects all the interesting
edges of the same procedure in the core and calls PSPP or BL to
get theﬁnal set of probes for the procedure on those edges.
4. EXPERIMENTAL EVALUATION
In this section, we explain our implementation and experimental
setup. We then report the experimental results on several programs
from the SPEC 2006 benchmark [16].
4.1 Implementation
We have implemented the PSPP and P3 algorithms for sequential
C/C++ programs using the LLVM 3.3 infrastructure [19]. LLVM
has an implementation of the Ball-Larus algorithm and we use it as
a sub-routine in P3’s implementation. For the experiments, for each
490Table 1: Benchmark characteristics
ID Program name LOC #Procedures #Proﬁtable
procedures
1 473.astar 4694 167 12 (7%)
2 403.gcc 1738852 4347 540 (12%)
3 445.gobmk 158600 2476 556 (22%)
4 456.hmmer 22049 471 163 (35%)
5 464.h264ref 37694 518 97 (19%)
6 470.lbm 1159 17 1 (6%)
7 462.libquantum 3353 115 14 (12%)
8 429.mcf 2225 24 5 (21%)
9 433.milc 10560 235 35 (15%)
10 998.rand 339 3 1 (33%)
11 999.rand 339 3 1 (33%)
12 458.sjeng 10896 144 14 (10%)
13 482.sphinx3 17585 319 69 (22%)
procedure, we choose the threshold on the number of partitions that
P3 creates as the maximum of the out-degree of theentryvertex of
its DAG and the number of cores. Note that, BL_DAG can create a
DAG having vertices with out-degree more than two.
We specialized our P3 implementation to derive an implementa-
tion of theparallel Ball-Larus strategy(PBL) outlined in the Intro-
duction. More speciﬁcally, in our PBL implementation, all proce-
dures are considered asunproﬁtableand are instrumented using the
Ball-Larus algorithm to be distributed subsequently. Thesequential
Ball-Larus strategy(SBL) is same as the Ball-Larus proﬁling on a
single core. We compare the proﬁling overheads ofthreedifferent
techniques: P3, PBL and SBL.
4.2 Experimental Setup
Setup.We use programs from the SPEC 2006 benchmark [16] for
experimental evaluation. SPEC benchmarks are popular evaluation
targets in the proﬁling literature. We could run the Ball-Larus im-
plementation supplied with LLVM on13C/C++ programs from
this benchmark. We evaluate the proﬁling algorithms on all these
programs (see Table 1). These comprise both large programs such
as 403.gcc and some small programs such as 999.rand. Most pro-
grams have several thousand lines of code and a few hundred proce-
dures. The SPEC benchmark also provides a few tests per program.
To evaluate the runtime overhead of proﬁling, we run each of the
programs in Table 1 on all the tests available for it.
The experiments were conducted on Ubuntu Linux 12.04 on an
Intel Xeon W3520 2.67GHz machine with 4 cores and 8 GB RAM.
We simulate different cores by running the distinct copies generated
by the proﬁling algorithms separately on a single core of this ma-
chine. We present results of the parallel path proﬁling techniques
on 2, 4 and 8 cores.
Quantifying proﬁling overhead.We quantify the runtime over-
head of proﬁling using a metric, called hit count. Thehit countof
a procedurePon a testXis the number of timesinstrumentation
probesinserted intoPgot executed while running the testX. The
hit count of a copyCon a testXis the summation of the hit counts
of all the procedures in that copy onX. The time overhead for
proﬁlingPunderXon a copyCis proportionate to its hit count.
Measuring real-time can have some inaccuracies based on the pro-
cessor load and other environmental factors. Further, we have to
accurately distinguish between the actual execution time and the
time taken by instrumentation probes. Hit count directly quantiﬁes
the proﬁling overhead independent of these issues.
If an algorithmAgeneratesKcopiesC 1, . . . , C Kfor a program
Mthen the proﬁling overhead ofAforMon a testXis taken as
the maximum of the proﬁling overheads ofC iforMonX, for
1≤i≤K. For a programMand an algorithmA, we consider1 2 3 4 5 6 78 9 10 11 12 13 Avg020406080100
Program ID%Proﬁling overhead of SBLP3PBL
Figure 5: Proﬁling overhead of P3 and PBL relative to SBL on
2 cores (lower is better): Avg is the average over the programs.
the average of the proﬁling overhead ofAacross all the tests ofM
as theproﬁling overhead. Average across all programs is simply
referred to as average and identiﬁed by Avg in theﬁgures.
4.3 Experimental Results
RQ1. How many procedures were deemed to be proﬁtable by P3?
As discussed in Section 3.2, P3 automatically identiﬁes prof-
itable procedures by a static controlﬂow analysis. Table 1 shows
the number and percentage of procedures that P3 deemed proﬁtable
for each of the programs. For each of them, P3 could generate at
least 2 disjoint subsets of paths. The proﬁtable procedures range
from6–35% of all procedures across the programs. Thus, in each
of the programs, P3 could identify opportunities for load balancing
across cores through proﬁtable procedures.
RQ2. Does P3 reduce proﬁling overhead compared to SBL?
The key test of effectiveness of P3 is whether and how much
reduction in proﬁling overhead (deﬁned in Section 4.2) does P3
achieve compared to the sequential Ball-Larus (SBL) strategy.
In Figure 5, we plot the proﬁling overhead of P3 relative to SBL
on 2 cores. On the X-axis, we represent different program IDs
assigned to the programs in Table 1. The Y-axis is labeled with
the percentage of the proﬁling overhead of SBL at the intervals
of 20%. Aﬁlled gray bar shows the percentage of P3’s proﬁling
overhead relative to that of SBL for the same program. Lower the
value of a Y-coordinate, the more reduction in proﬁling overhead
P3 achieved. It can be seen that with only 2 cores, P3 could reduce
the proﬁling overhead for most of the programs. For8programs,
the reduction is more than or equal to20%, whereas for3programs
(IDs 6, 10 and 11), it is only marginal. The average reduction across
all the programs is23% as shown in the last bar of Figure 5.
In Figure 6 and Figure 7, we plot the proﬁling overhead of P3
relative to SBL for 4 and 8 cores respectively. For 4 cores, the
reduction is more than or equal to47% for8programs, whereas for
5programs (IDs 4, 6, 7, 10 and 11), it is less than or equal to30%.
The average reduction for 4 cores is43%. Finally, for 8 cores, the
reduction is more than or equal to50% for11programs, whereas
it is less than or equal to25% for the remaining two programs.
The average reduction for 8 cores is56%. Overall, P3 achieved
substantial parallelization beneﬁts for most of the programs across
2, 4 as well as 8 cores.
RQ3. Does P3 reduce proﬁling overhead compared to PBL?
We now compare P3 and PBL. Similar to P3, for each of the
4911 2 3 4 5 6 78 9 10 11 12 13 Avg020406080100
Program ID%Proﬁling overhead of SBLP3PBL
Figure 6: Proﬁling overhead of P3 and PBL relative to SBL on
4 cores (lower is better): Avg is the average over the programs.
1 2 3 4 5 6 78 9 10 11 12 13 Avg020406080100
Program ID%Proﬁling overhead of SBLP3PBL
Figure 7: Proﬁling overhead of P3 and PBL relative to SBL on
8 cores (lower is better): Avg is the average over the programs.
programs, we plot the proﬁling overhead of PBL relative to SBL
for 2, 4 and 8 cores in Figures 5, 6 and 7 respectively. The bars
with cross lines correspond to PBL.
For 2 cores (Figure 5), for8programs P3 shows more reduction
compared to that of PBL. On an average across all the programs, the
proﬁling overhead of P3 is5% less compared to PBL. For 4 cores
(Figure 6), P3 gives more reduction than PBL on all but1programs.
On an average across all the programs, the proﬁling overhead of
P3 is18% less compared to PBL. Finally, for 8 cores (Figure 7),
P3 outperforms PBL in all except2cases. On an average, it has
25% less overhead than PBL. We see two reasons behind the cases
where P3 could not perform better than PBL: (1) overlapping of
probes among the copies and (2) selection of proﬁtable procedures
did not have any effect on the result.
In summary, P3 is more effective in exploiting parallelism in path
proﬁling compared to PBL. P3’s strategy of automatically identify-
ing proﬁtable procedures and sub-dividing the task of proﬁling their
paths helps reduce proﬁling overhead compared to PBL’s coarse-
grained strategy of distributing entire procedures.RQ4. How much time does P3 take to construct different instru-
mented copies and assign them to different cores?
P3 constructs different instrumented copies of a programMand
assigns them to different cores by a static analysis ofM. P3 took a
maximum of48m for the largest program in Table 1. On an aver-
age, it took5m across all the programs with 9 programs taking less
than 2 minutes. We highlight that this is only a one-time cost for
any program for a given number of cores. The program can then be
proﬁled in parallel for any number of inputs.
4.4 Discussion
Trade-off between overlapping probes and load balancing.Over-
lapping probes are those probes that may get executed in an in-
stanceP ifor a path proﬁled in another instanceP j. An important
factor in achieving reduction in proﬁling overhead through P3 is to
achieve a trade-off between overlapping probes (which can increase
the proﬁling overhead) and load balancing that can be achieved
through proﬁling only a subset of paths in each core. Our exper-
imental results show that this is indeed possible in practice. In par-
ticular, we observed that in several cases, multiple acyclic paths of
a procedure were exercised on the same core while using PBL but
they were proﬁled ondifferentcopies when P3 was used. In addi-
tion, the overlapping probes between those copies for the procedure
did not overshadow the beneﬁt of distribution of the paths.
Threats to validity.There are some threats to validity for our exper-
imental results. The main among them being the limited number of
programs and test inputs for them. We attempt to mitigate it by con-
sidering the SPEC benchmarks which are widely used in the proﬁl-
ing literature and generally, in performance analysis. Nevertheless,
in future, we wish to run our experiments on other programs. The
second threat is due to possible non-determinism in the paths being
explored in different copies. However, we consider only sequential
programs and evaluate them on the same machine (see Section 4.2).
Thus, once weﬁx an input, all copies of the program follow the
same dynamic controlﬂow path. We give a detailed proof (see Ap-
pendix A) of correctness of PSPP to eliminate the possibility of a
theoretical glitch. Finally, we reduced the possibility of bugs in our
implementation by manual inspection and repeated experiments on
both smaller, hand-written examples and the SPEC benchmarks.
5. RELATED WORK
Program proﬁling.Ball and Larus [4] introduced the notion of
acyclic intra-procedural path proﬁling and provided an algorithm to
compute it. The Ball-Larus algorithm has been extended to proﬁle
inter-procedural paths by Melski et al. [21] and to cyclic paths by
D’Elia et al. [11]. We believe that P3 can be extended to cover
these extensions. Extending P3 to proﬁle inter-procedural paths is
an immediate future work for us.
Recently, Li et al. [20] presented an algorithm to overcome the
impreciseness of SPP [1]. Their algorithm, called Modiﬁed SPP
(MSPP), deletes a label from an uninteresting edge only if it does
not result in an invalid labeling. MSPP is an exponential algorithm
in worst-case whereas PSPP is linear in the size of the DAG.
Vaswani et al. [24] introduced preferential path proﬁling (PPP)
which reduces the overhead of path proﬁling by proﬁling a given
set of paths with an objective of compact numbering. The compact
numbering facilitates the use of arrays for updating the frequency
for each acyclic path, thereby reducing the overhead caused by the
use of hashtable. It can be shown with an example that their algo-
rithm does not ensure computation of valid labeling. In contrast, the
PSPP algorithm computes only valid labeling. As a workaround,
PPP uses Ball-Larus’ labeling for distinguishing interesting and un-
492interesting paths. This workaround cannot be used in our scenario
as the overhead will be same as overhead for Ball-Larus’ labeling
irrespective of the interesting paths. Chilimbi et al. [9] extended
PPP for inter-procedural paths and used it for residual path proﬁl-
ing. We plan to extend PSPP for efﬁcient residual path proﬁling.
Pertinent path proﬁling [5] introduced a new control-ﬂow entity,
namely, pertinent paths that pass though a given set of nodes called
pertinent nodes. It generates a unique numbering for pertinent paths
and generates compact numbering of path-ids. They do not try to
reduce the number of probes, instead try to reduce the path-table
size. Targeted path proﬁling [18] addressed the proﬁling overhead
problem by leveraging edge proﬁling information in the context of
staged dynamic optimization systems. Parallelizing edge-proﬁle in
itself can be an interesting research problem. In P3, the task cost
can take into account such proﬁling information for better distribu-
tion of tasks into cores.
One program, many copies.Closest to our work is distributed pro-
gram tracing [23]. It collects a single program trace corresponding
to a given input by distributing the witnesses across multiple copies
of the program and run them parallel on the same input to collect
the partial traces. The partial traces are then merged to produce the
whole trace. Though the same code-replication based divide-and-
conquer strategy is applied in the context of a different problem,
the challenge there was to devise the necessary and sufﬁcient con-
dition which guarantees that the originalorderof basic blocks can
be constructed by merging. The distribution of witnesses and merg-
ing algorithm are therefore crucial for soundness of the algorithm.
In contrast, here, the distribution is addressing the efﬁciency of the
technique and the PSPP algorithm, applied on each procedure lo-
cally on each core, is ensuring the soundness. In both the works,
the distribution strategies further address the efﬁciency of proﬁling
or tracing. In tracing, a sequence of diamonds is put together in one
copy as they can becoveredby less number of witnesses, whereas
P3 uses the notion of proﬁtable procedures to optimize.
Software tomography [7] splits monitoring tasks across many in-
stances of the software, so that partial information may be collected
from users by means of light-weight instrumentation and merged to
gather the overall monitoring information. Although sounds sim-
ilar, the main difference is that they do not try to obtain accurate
proﬁling information for a given set of paths. There technique dis-
tributes the monitoring tasks to different users who can use the soft-
ware at will with different inputs. Their goal is to gather enough in-
formation for each sub-task. For example, for path coverage, they
discover whether each path is executed in a given set of execu-
tions, whereas our goal is to obtain precise execution frequencies
in a given task. Thus, their framework is more suitable towards efﬁ-
cient distributed proﬁling (estimation based) whereas our algorithm
is more suitable towards accurate parallel path proﬁling. Addition-
ally, their algorithm is not accurate as it is as based on SPP [1].
Diep et al. [12] consider distribution of probes to multiple pro-
gram variants, where each variant contains a subset of probes, where
the subset size can be bounded to meet the overhead requirements.
However, the aim there is to proﬁle a set of events and not paths.
6. CONCLUSIONS AND FUTURE WORK
In this paper, we presented an algorithm called P3 for parallel
path proﬁling. To the best of our knowledge, this is theﬁrst algo-
rithm for parallel path proﬁling. P3 proﬁles the path of a program
by distributing all acyclic paths into multiple cores, running on the
same input. P3 judiciously performs partitioning of paths of some
selected (proﬁtable) procedures to reduce the common overhead
caused by the execution of a path in multiple cores. It uses an ap-proximation algorithm to evenly distribute the overhead based on
number of probes. To precisely estimate execution frequencies for
each subset of paths in a proﬁtable procedure, we have developed
an algorithm called PSPP which we use in P3.
This paper opens up some interesting research problems: how
to extend P3 for inter-procedural or cyclic paths which poses the
challenge of extending PSPP for such paths. As the Ball-Larus al-
gorithm can beneﬁt by previously available proﬁling information
for determining low frequency chords to place the probes, P3’s dis-
tribution algorithm can be extended to get beneﬁt from such infor-
mation. In the absence of dynamic proﬁling information, it is possi-
ble to do static estimation [3] based on program’s inter-procedural
CFG. This paper also opens up possibility of optimizations based
on better selection strategy of proﬁtable procedures and threshold.
APPENDIX A. CORRECTNESS OF PSPP
We now show that theﬁnal labeling produced by PSPP is a valid
labeling (as deﬁned in Section 2.1). Weﬁrst deﬁne local validity of
a labelingLat a vertexv. LetI vand¯Ivdenote the set of interesting
and uninteresting paths passing through the vertexvrespectively.
The labelingLislocally validatvif the following conditions hold
forpids obtained usingL:
(A)∀p, q∈I v:pid(p, v)�=pid(q, v)
(B)∀p∈I v,∀r∈ ¯Iv:pid(p, v)�=pid(r, v)
This deﬁnition is similar to the deﬁnition of valid labeling but uses
partial identiﬁerspids instead ofpathids.
Sincepathid(p) =pid(p, entry), a locally valid labeling for
v=entryis same as a valid labeling. Thus, by proving local
validity for each vertex, we can prove the validity of the labeling
produced by PSPP. We now give names to the different steps of
PSPP for simplicity. The loop at lines 4–13 is called theinitial
step. The loop at lines 14–21 is called thepropagation stepand
ﬁnally, the loop at line 22 is called theabsorption step.
It is easy to see that local validity holds at every vertex for the
(edge) labeling obtained after the initial step. In PSPP, the prop-
agation and absorption steps are performed after the initial step is
over for all the vertices. To show that local validity holds for each
vertex after the absorption step, we deﬁne a variant of the PSPP
algorithm calledPSPP’in which propagation and absorption steps
areinterleavedwith the loop of the initial step. In particular, the
propagation and absorption loops are run within the loop of the ini-
tial step, immediately after a vertexvis processed in each iteration
of the loop at lines 4–13, by treatingvas the entry vertex of the
subgraph ofGrooted atv. Weﬁrst show equivalence of PSPP and
PSPP’, and then prove correctness of PSPP’.
LEMMA 1.The edge labeling computed by PSPP and PSPP’
are identical.
PROOF . This follows from the fact that PSPP’ also performs the
propagation and absorption at theentryvertex, same as that in
PSPP. Since the propagation step is iterative and it considers each
vertex in the topological order for propagation of edge labels to the
outgoing edges of vertices with in-degree1, theﬁnal edge labeling
of the interesting edges is the same for both PSPP and PSPP’. All
the uninteresting edges are labeled 0 in both PSPP and PSPP’.
Letsucc i(v) ={w|(v, w)∈EI}. Henceforth, we refer to
visit of a vertexvby PSPP’ as the visit ofvin its outermost loop.
LEMMA 2.For a vertexv, the valuev.minis only updated
(line 11 of Algorithm 1) for theﬁrst interesting edge(v, w 1)PSPP
(and also PSPP’) visits in the initial step. The valuev.minis at
leastw 1.min. Also,∀w i∈succ i(v),w i.min≤v.min.
493v
b w 1 w2Nbpv
w2 w1
a
e
bpq
(a) (b)
Figure 8: (a) Case 1: First non-interesting edge ofpstarts from
v; (b) Case 2: First non-interesting edge ofpstarts after preﬁx
qfromv
PROOF . PSPP essentially follows Ball-Larus’ edge labeling for
interesting edges and the above lemma follows from the fact that
Ball-Larus’ edge labeling always gives higherpidto the paths pass-
ing through the edges that are visited later. Thus, the interesting
path fromvwith minimum path-id always passes through theﬁrst
interesting edge visited by PSPP. Since the value assigned to an
interesting edge is at least0, the minimum path-id of an interest-
ing path throughvis atleastw 1.min. Also,∀w i∈succ i(v), as
wi.min≤w 1.min, we deducew i.min≤v.min.
LEMMA 3.After PSPP’ visits a vertexv, it ensures that an un-
interesting pathphavingpid(p, v)higher thanpid(p�, v)of any
interesting pathp�is always unabsorbable.
PROOF . We prove this by contradiction. Suppose there exists
such an uninteresting pathpwhich is absorbable. Letw 1, w2...., w n
be the successors ofv. Let(a, b)be theﬁrst uninteresting edge of
preachable fromv. We consider two cases forp.
First case:(a, b)is the leading edge of the subgraph rooted at
v(meansa=v). Refer to Figure 8(a) for an illustration. All
the interesting paths will be assigned higherpids than thepidof
the uninteresting pathpsince interesting edges are processed after
uninteresting edges. This contradicts our assumption.
Second case:(a, b)is not the leading edge (see Figure 8(b)).
That means there exists a preﬁxqconsisting of all interesting edges
(without more than one incoming edge) till the edge(a, b)of this
path which makes it absorbable. Now, consider a pathqequal
to�entry, . . . , v, w 1, x1, x2, . . . , x n, a, . . . , exit�. For an inter-
esting edgeepassing through the vertexa,e.valwill get higher
value than thepidof the uninteresting path with respect toabe-
cause interesting edges are processed later than uninteresting edges.
Thus, the value ofa.minwill be higher than thepid(p, v)as af-
ter PSPP’ completes processing ofv, all labels of edges inqand
(a, b)are zero due to propagation and absorption fromv. Using
Lemma 2,x n.min≥a.min. Lemma 2 can be used to show the
inequalityX.min≥a.minforXranging over all the vertices
xn−1, . . . , x 1, w1, v, since each of the vertices is the successor of
the next node. Hence,v.min≥a.min. This means that the min-
imumpidof the interesting path passing fromvis at leasta.min.
Buta.min > pid(p, v). This contradicts our assumption.
THEOREM 1.Given a DAG and a set of interesting edges, after
PSPP’ visits a vertexv, the labeling obtained is locally valid atv.
PROOF . The proof is by induction on theheightof a vertex in
the DAG. The height of a vertexvis the smallest number of edges
betweenvand theexitvertex of the DAG.
Base case:vhas height equal to zero (that is,v=exit). The
theorem trivially holds.Induction step: We show that the theorem holds for any vertex
vof heightH >0. Since we are considering a DAG, all succes-
sorsw 1, w2...., w nofvhave height less thanH, so by induction
hypothesis the local validity holds on allw i. The algorithm assigns
Ball-Larus’ edge labeling to the interesting edges and after comput-
ing propagation and absorption steps, thepidof all the interesting
paths remains intact since there are no uninteresting edges in inter-
esting paths. So thepids of the interesting paths satisfy part (A)
of the deﬁnition of locally valid labeling. For proving part (B) of
the local validity deﬁnition, partition the uninteresting paths pass-
ing throughvin two groupsN 1andN 2.N 1consists of all the
uninteresting paths which pass through leading uninteresting edges
ofv, whereasN 2consists of all the uninteresting paths passing
through leading interesting edges ofv. Again, its trivial to see that:
∀p∈N 1and∀q∈I v,pid(p, v)< pid(q, v), since all the inter-
esting edges are processed later than the uninteresting edges and
interesting edges are assigned in increasing order.
For proving the distinctness ofpids of paths inI vand those in
N2, we consider following two cases:
Case a= Paths passing through the same interesting edge from
v: Weﬁrst prove the distinctness of the path-ids of interesting paths
Ivand path-ids of the paths inN 2which pass through the same out-
going edgee= (v, w i)ofv. Consider two such pathsp 1∈N 2
andp 2∈I v. By induction hypothesis,pid(suff(p 1, wi), w i)�=
pid(suff(p 2, wi), w i). We need to prove that after propagation and
absorption ofe’s edge label (sayα) theirpids (w.r.t.v) are disjoint.
By Lemma 3 onw i,p1is absorbable ifpid(suff(p 1, wi), w i)<
pid(suff(p 2, wi), w i). As no absorption happens to interesting paths,
pid(p 2, v) =α+pid(suff(p 2, wi), w i). For such ap 1,pid(p 1, v)<
α+pid(suff(p 1, wi), w i)as some absorption happens inp 1. There-
forepid(p 1, v)<α+pid(suff(p 2, wi), w i) =pid(p 2, v). In the
other case,p 1is not absorbable therefore itspid(p 1, v)will not
change after absorption and remain different thanpid(p 2, v).
Case b= Paths passing through different outgoing edges from
v: We now prove the distinctness of thepids of the interesting
paths and the path-ids of uninteresting paths inN 2passing through
different edges(v, w i)and(v, w j). Let, without loss of generality
wi.min >=w j.min.
PSPP’ processes edge(v, w i)before edge(v, w j)and assigns
(v, w j).vala value which is greater than all thepids of the paths
passing through(v, w i). Thus, all the interesting paths passing
throughv, w jhave higher pids than the uninteresting paths pass-
ing through(v, w i).
Consider an uninteresting pathp 1passing through(v, w j)and an
interesting path passing through(v, w i). Say(v, w j).val=αand
(v, w i).val=β. Ifp 1is unabsorbable, thenpid(p 1, v)>α>
pid(p 2, v). Ifp 1is absorbable, then by Lemma 3pid(p 1, v) =
pid(suff(p 1, wj), w j)< w j.min. Sincew j.min≤w i.min,
pid(p 1, v)< w i.min. Since by deﬁnition,pid(p 2, v)≥w i.min,
thereforepid(p 1, v)< pid(p 2, v).
Theorem 1 proves the correctness of PSPP’. If local validity of
the labelingLcomputed by PSPP’ holds at theentryvertex then
validity ofLalso holds. The output of both PSPP’ and PSPP are
same by Lemma 1. We therefore have the following theorem.
THEOREM 2.Given a DAG and a set of interesting edges, PSPP
computes a valid labeling.
Note that PSPP is same as the Ball-Larus algorithm if all paths
in the DAG are marked as interesting and additionally, if all edges
are interesting (even though some paths are uninteresting) the PSPP
algorithm is same as the Ball-Larus algorithm. Finally, for two sets
of pathsSandS�whereS⊂S�, the number of zero edges obtained
by PSPP forSis more than or equals to that ofS�.
4947. REFERENCES
[1] T. Apiwattanapong and M. J. Harrold. Selective path
proﬁling. InProceedings of the 2002 ACM
SIGPLAN-SIGSOFT Workshop on Program Analysis for
Software Tools and Engineering, PASTE ’02, pages 35–42,
New York, NY, USA, 2002. ACM.
[2] T. Ball. Efﬁciently counting program events with support for
on-line queries.ACM Trans. Program. Lang. Syst.,
16(5):1399–1410, Sept. 1994.
[3] T. Ball and J. R. Larus. Optimally proﬁling and tracing
programs.ACM Transactions on Programming Languages
and Systems, 16:1319–1360, July 1994.
[4] T. Ball and J. R. Larus. Efﬁcient path proﬁling. In
Proceedings of the 29th Annual ACM/IEEE International
Symposium on Microarchitecture, MICRO 29, pages 46–57,
Washington, DC, USA, 1996. IEEE Computer Society.
[5] S. Baswana, S. Roy, and R. Chouhan. Pertinent path
proﬁling: Tracking interactions among relevant statements.
InProceedings of the 2013 IEEE/ACM International
Symposium on Code Generation and Optimization (CGO),
CGO ’13, pages 1–12, Washington, DC, USA, 2013. IEEE
Computer Society.
[6] M. D. Bond and K. S. McKinley. Practical path proﬁling for
dynamic optimizers. InProceedings of the International
Symposium on Code Generation and Optimization, CGO
’05, pages 205–216, Washington, DC, USA, 2005. IEEE
Computer Society.
[7] J. Bowring, A. Orso, and M. J. Harrold. Monitoring deployed
software using software tomography. InProceedings of the
2002 ACM SIGPLAN-SIGSOFT Workshop on Program
Analysis for Software Tools and Engineering, PASTE ’02,
pages 2–9, New York, NY, USA, 2002. ACM.
[8] T. M. Chilimbi, B. Liblit, K. Mehra, A. V. Nori, and
K. Vaswani. Holmes: Effective statistical debugging via
efﬁcient path proﬁling. InProceedings of the 31st
International Conference on Software Engineering, ICSE
’09, pages 34–44, Washington, DC, USA, 2009. IEEE
Computer Society.
[9] T. M. Chilimbi, A. V. Nori, and K. Vaswani. Quantifying the
effectiveness of testing via efﬁcient residual path proﬁling. In
Proceedings of the the 6th Joint Meeting of the European
Software Engineering Conference and the ACM SIGSOFT
Symposium on The Foundations of Software Engineering,
ESEC-FSE ’07, pages 545–548, New York, NY, USA, 2007.
ACM.
[10] S. Debray and W. Evans. Proﬁle-guided code compression.
InProceedings of the ACM SIGPLAN 2002 Conference on
Programming Language Design and Implementation, PLDI
’02, pages 95–105, New York, NY, USA, 2002. ACM.
[11] D. C. D’Elia and C. Demetrescu. Ball-larus path proﬁling
across multiple loop iterations. InProceedings of the 2013
ACM SIGPLAN International Conference on Object
Oriented Programming Systems Languages &#38;
Applications, OOPSLA ’13, pages 373–390, New York, NY,
USA, 2013. ACM.[12] M. Diep, M. Cohen, and S. Elbaum. Probe distribution
techniques to proﬁle events in deployed software. In
Proceedings of the 17th International Symposium on
Software Reliability Engineering, ISSRE ’06, pages
331–342, Washington, DC, USA, 2006. IEEE Computer
Society.
[13] M. D. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin.
Dynamically discovering likely program invariants to
support program evolution. InProceedings of the 21st
International Conference on Software Engineering, ICSE
’99, pages 213–224, New York, NY, USA, 1999. ACM.
[14] M. R. Garey and D. S. Johnson.Computers and
Intractability: A Guide to the Theory of NP-Completeness.
W. H. Freeman & Co., New York, NY, USA, 1979.
[15] R. L. Graham. Bounds on multiprocessing timing anomalies.
SIAM Journal on Applied Mathematics, 17(2):416–429,
1969.
[16] J. L. Henning. Spec cpu2006 benchmark descriptions.ACM
SIGARCH Computer Architecture News, 34(4):1–17, 2006.
[17] J. A. Jones, M. J. Harrold, and J. Stasko. Visualization of test
information to assist fault localization. InProceedings of the
24th International Conference on Software Engineering,
ICSE ’02, pages 467–477, New York, NY, USA, 2002. ACM.
[18] R. Joshi, M. D. Bond, and C. Zilles. Targeted path proﬁling:
Lower overhead path proﬁling for staged dynamic
optimization systems. InProceedings of the International
Symposium on Code Generation and Optimization:
Feedback-directed and Runtime Optimization, CGO ’04,
pages 239–, Washington, DC, USA, 2004. IEEE Computer
Society.
[19] C. Lattner and V. Adve. LLVM: A compilation framework
for lifelong program analysis and transformation. pages
75–88, San Jose, CA, USA, Mar 2004.
[20] B. Li, L. Wang, and H. Leung. Proﬁling selected paths with
loops.SCIENCE CHINA Information Sciences, 57(7):1–15,
2014.
[21] D. Melski and T. W. Reps. Interprocedural path proﬁling. In
Proceedings of the 8th International Conference on
Compiler Construction, Held As Part of the European Joint
Conferences on the Theory and Practice of Software,
ETAPS’99, CC ’99, pages 47–62, London, UK, UK, 1999.
Springer-Verlag.
[22] C. Pavlopoulou and M. Young. Residual test coverage
monitoring. InProceedings of the 21st International
Conference on Software Engineering, ICSE ’99, pages
277–284, New York, NY, USA, 1999. ACM.
[23] D. Saha, P. Dhoolia, and G. Paul. Distributed program
tracing. InProceedings of the 2013 9th Joint Meeting on
Foundations of Software Engineering, ESEC/FSE 2013,
pages 180–190, New York, NY, USA, 2013. ACM.
[24] K. Vaswani, A. V. Nori, and T. M. Chilimbi. Preferential path
proﬁling: Compactly numbering interesting paths. In
Proceedings of the 34th Annual ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages, POPL
’07, pages 351–362, New York, NY, USA, 2007. ACM.
495