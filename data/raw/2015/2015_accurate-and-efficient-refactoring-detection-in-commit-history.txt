Accurate and Efficient Refactoring Detection in Commit History
Nikolaos Tsantalis, Matin Mansouri,
Laleh M. Eshkevari, Davood Mazinanian
Concordia University, Montreal, Quebec, CanadaDanny Dig
Oregon State University
Corvallis, Oregon, USA
ABSTRACT
Refactoring detection algorithms have been crucial to a variety
of applications: (i) empirical studies about the evolution of code,
tests, and faults, (ii) tools for library API migration, (iii) improving
the comprehension of changes and code reviews, etc. However,
recent research has questioned the accuracy of the state-of-the-art
refactoring detection tools, which poses threats to the reliability of
theirapplication.Moreover,previousrefactoringdetectiontoolsare
verysensitivetouser-providedsimilaritythresholds,whichfurther
reducestheirpracticalaccuracy.Inaddition,theirrequirementto
build the project versions/revisions under analysis makes them
inapplicablein many real-world scenarios.
To reinvigorate a previously fruitful line of research that has sti-
fled,wedesigned,implemented,andevaluatedRMiner,atechnique
that overcomes the above limitations. At the heart of RMiner is
an AST-based statement matching algorithm that determines refac-
toring candidates without requiring user-defined thresholds. To
empirically evaluate RMiner, we created the most comprehensive
oracletodatethatusestriangulationtocreateadatasetwithcon-
siderably reduced bias, representing 3,188 refactorings from 185open-source projects. Using this oracle, we found that RMiner
has a precision of 98% and recall of 87%, which is a significant
improvement over the previous state-of-the-art.
CCSCONCEPTS
•Software and its engineering →Software evolution ;
KEYWORDS
Refactoring,Commit,Git,AbstractSyntaxTree, Oracle, Accuracy
1 INTRODUCTION
Refactoring [ 28,37,60] isa key practice in agiledevelopment pro-
cesses, and is well supported by refactoring tools that are standard
withallmajorIDEs.Refactoringresearchisapproachingnow30
years.A veryactivelineof researchfocusedonrefactoringdetec-
tion algorithms [ 4,15,18,27,31,34–36,46,56,62,65,74,78] that
compute a (likely) set of refactorings that developers applied onthe source code. Other researchers used refactoring detection to
empirically study [ 4,6,7,45,61,63,73] software evolution, and to
Permissionto make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
©2018 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05 ...$15.00
https://doi.org/10.1145/3180155.3180206supportothersoftwareengineeringtasks,suchaslibraryadapta-
tion[5,18,40,79],softwaremerging[ 21],codecompletion[ 27,31],
and code review [1, 33, 34].
However,theaccuracyofrefactoringdetectiontoolshasbeen
recentlyquestioned.Anindependentstudy[ 67]hasshownthatRef-
Finder [46,62] (one of the most widely used refactoring detection
tools) had an overall precision of 35% and an overall recall of 24%,
while a more recent study [ 39,42] has shown that Ref-Finder had
anoverallaverageprecisionof27%.Missingrefactorings(falseneg-
atives)isaseriousthreattothegeneralizabilityofempiricalstudies,
or can cause other dependent tools to carry incomplete operations.
Detectingincorrectrefactorings(falsepositives)isevenmorese-
vereasitmakestheconclusionsoftheempiricalstudywrong,or
causes otherdependent tools to apply the wrong operations.
Moreover,themajorityoftherefactoringdetectiontoolsusesim-
ilaritythresholds,andprovideasetofdefaultthresholdvaluesthat
areempiricallydeterminedthroughexperimentationona(rather
small)numberofprojects(e.g.,oneprojectforUMLDiff[ 77],three
forRef-Finder[ 62]andRefactoringCrawler[ 18],andtenfor
RefDiff [ 65]). The derived threshold values are possibly overfitted
to the characteristics of the examined projects, and thus cannot be
generalenoughtotakeintoaccountallpossiblewaysdevelopers
applyrefactoringsinprojectsfromdifferentdomains.Asaresult,
thesethresholdvaluesrequireacalibrationtoalignwiththepar-
ticularrefactoringpracticesappliedinaproject,whichistedious.
Moreover,findinga universal thresholdvaluemightbeinfeasible.
Severalresearchersproposedmethodsforderivingthresholdvalues
in metric-based detection techniques [ 2,22,25,26,59]. However,
the precision and recall can vary significantly even for the same
software system when using different threshold values [ 17], and
softwaresystemsrelyingondifferentarchitecturalstylesandframe-
worksrequiredifferentthresholdvalues[ 3].Therefore,researchhas
shownthatitisverydifficulttoderive universal thresholdvalues
that can work well for all projects, regardless of their architectural
style, application domain, and development practices.
Furthermore, most refactoring detection tools take as input two
fully built versions of a software system that contain binding in-
formationforallnamedcodeentities,linkedacrossalllibraryde-
pendencies. However, a recent study [ 71] has shown that only
38% of the change history of software systems can be successfully
compiled.Thisisaseriouslimitationforperforminglongitudinal
refactoring detection in the commit history of projects, posing a
threattotheexternalvalidityofempiricalstudies,sinceonlyasmall
numberofprojectversionscanbeeffectivelyusedforextracting
refactoring datasets.
Thus,wedesigned,implemented,andevaluatedRMiner,anovel
techniquethatovercomestheabovelimitations.RMinertakesas
input two revisions (i.e., a commit and its parent from the commit
history ingit-based versioncontrolrepositories) ofa Java project,
andreturnsalistofrefactoringoperationsappliedbetweenthese
4832018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden N. Tsantalis et al.
two revisions. RMiner provides highly accurate,efficient, andscal-
ablerefactoringdetectioninthecommithistoryofaprojectwithout
requiring to build each individual commit.
At the heart of RMiner is an AST-based statement matching
algorithm that does not require user-specified thresholds, yet it
isimmunetothenoiseintroducedbythestatementrestructuring
duringrefactoringoperations.Itreliesonourtwonoveltechniques:
abstraction dealswithchangesinstatements’ASTtypeduetorefac-
toring, and argumentization deals with changes in sub-expressions
withinstatementsduetoparameterization.UsingthematchedAST
statements, we designed powerful detection rules for 15 represen-
tative refactoring types.
To empirically evaluate RMiner, we first needed to create a reli-
able, comprehensive, and representative oracle. This is a daunting
task that mounts tremendous challenges on its own. First is the
danger of creating an incomplete oracle . Researchers previously
created such oracles by inspecting release notes [ 18,20] or commit
messages [ 74]. However, only a small percentage (21%) of the re-
lease notes include refactoring operations (and only for a subset
of refactorings that affect the backward compatibility of public
APIs)[54].Moreover,developersdonotreliablyindicatethepres-
ence of refactoring operations in commit log messages [55].
Second is the danger of creating a biased oracle . For example,
researchers [ 62] created an oracle based on the findings of a single
tool (i.e., Ref-Finder) configured with a more relaxed similarity
thresholdvalueinordertodetectmorerefactoringinstances(fol-
lowedbyremovingfalsepositivesthroughmanualinspection),and
then evaluated the precision and recall of the same tool configured
with a more strict similarity threshold value. However, this might
still miss a large number of true instances due to an algorithm
designflaw,implementationerror,orinappropriatethresholdvalue,
leading to precision and recall that are significantly different than
those reported by independent researchers (i.e., 35% precision and
recall of 24% [ 67], and an overall average precision of 27% [ 39,42]
vs. the authors’ [ 62] reported precision and recall of 74% and 96%).
Thirdisthedangerofcreatingan artificialoracle .Forexample,
researchers[ 65]createdanoraclebyaskingstudentstoapplyrefac-
toringsinopen-sourceprojects.These seededrefactorings[ 11],can
beusedtoreliablycomputetherecall,sinceallappliedrefactorings
are known a-priori. However, seeded refactorings are not represen-
tative of real refactorings for two reasons: (i) they are artificial, i.e.,
theydonotcarryhigher-levelintents(e.g.,facilitateamaintenance
task, eliminate a code smell, improve code understandability), and
(ii)theyare isolatedanddonotoverlapwithtypicalmaintenance
activities (e.g., other edits in the same commit to fix bugs, add new
features).Asignificantpercentage(46%[ 57])ofrefactoredprogram
entities are also edited or further refactored in the same commit,
apracticecommonlyreferredas flossrefactoring [55–57,64].Not
accountingforthisrealcodeevolution,significantlyandartificially
increases thesignal-to-noiseratio,thus making thedetection less
challengingthanin real-world scenarios.
Toavoidtheaboveproblemswithrefactoringoracles,werely
on state-of-the-art procedures [ 24,30,48] that use triangulation
betweenmultiple sources(human expertsandtools) todetermine
the ground truth. We started from an award-winning, publiclyavailable dataset of refactoring instances [
64], originating from538 commits from 185 open-source GitHub projects. Moreover, the
refactoring instances from 222 of these commits were confirmed
bythedeveloperswhoactuallyperformedtherefactorings(i.e.,the
commitauthors)throughsurveys,andfurtherre-validatedbyus
manually to ensure correctness. To ensure the completeness of the
dataset, we executed two tools that analyze repository commits
without requiring to build the project, namely our RMiner and the
previousstate-of-the-artRefDiff[ 65],onall538commitsofthe
dataset.Thesetoolsusecomplementarydetectionmethods,thusare
likely to detect a more comprehensive set of refactoring instances.
Then we manually validated 4,108 unique refactoring instances
detectedbythetwotools,outofwhich3,188weretruepositives.
The validation process took 9 person-months to be completed, and
involveduptothreerefactoringexpertsperinstancetonegotiate
agreement. With this oracle we evaluate the precision and recall of
RMinerand the previous state-of-the-art tool, RefDiff.
Based on these results, we launch a community call to action
relatedtorefactoringdetectionandrefactoringoracles.Weoffersev-
eralactionableimplicationsandresultsforresearchers,toolbuilders,
anddevelopers.First,ouroracleof3,188truerefactoringsfrom538
commits across 185 projects provides an invaluable resource for
validating novel refactoring tools and for comparing existing ap-
proaches.Educatorscanuseourdatasetwhenteachingsoftware
engineering to show examples of refactorings in their real-life con-
texts.UsingRMiner,researcherscanreplicateexistingempirical
studies and refute or confirm previously-held beliefs. Moreover,researchers can use RMiner to reduce the noise [
12,13] created
byrefactorings,suchasfile/directoryrenaming,andsignificantly
improvetheaccuracyofothertools.Forexample,toolsthatidentify
bug-introducing changes (e.g., the widely used SZZ [ 47,66,76])
can utilize RMiner to avoid flagging changes that do not alter the
program behavior (i.e., refactorings) as bug-introducing. Tools that
trace requirements to code [ 51,52] could use RMiner to recover
traceabilitylinksthat are broken due to applied refactorings.
Practicalaspects,suchasRMiner’sspeedandconsumptionof
raw code changes from commits, enable novel applications not
possiblebefore,suchas onlinerefactoringdetectiononpartialinput,
whenadeveloperinspectsacodedifftoreviewachange,ortries
to understand code evolution selectively (e.g., using the “blame”
featureonaprogramelementofinterest).As flossrefactoring [55–57,
64]isprevalent,thetraceofcodechangesleftbehindbyrefactorings
can mask the changes actually intended by developers [ 16,44].
Moreover,refactoringsdistractdevelopersduringcodereviews[ 33],
when the changes are inspected with text diff tools (commonly
usedinIDEs,repositoryhostingservices,andcodereviewtools).
IntegratingRMinerwiththediffandcodereviewtoolscanraisethe
level of abstraction for code changes originating from refactorings,
thus helpingdevelopers better understand the code evolution.
Thispaper makes the following contributions:
(1)Wepresentthe firstrefactoringdetectionalgorithmthatdoes
not require any code similarity thresholds to operate.
(2)We implement our detection algorithm into a tool, RMiner
(shortforRefactoringMiner[ 69]),whichoperatesonversion
control commits, and provides an API for external use.
(3)Wecreatethemostaccurate,complete,andrepresentativeoracle
of refactoring operations to date, comprising 3,188 refactorings
484
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. Accurate and Efficient Refactoring Detection in Commit History ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
foundin538commitsfrom185open-sourceprojects,whichwe
validatewithmultipletools and experts [70].
(4)We evaluate RMiner and find that it achieves 98% precision
and87%recall,andtakesonmedian58mstoanalyzeacommit,
a significant improvement over the previous state-of-the-art.
(5)We release a tool infrastructure to compare the accuracy of
multiplerefactoringdetectiontools,eitherusingauser-defined
fixed oracle, or a dynamically generated oracle based on tool
agreement [53].
2 APPROACH
RMinertakesas inputtworevisions(i.e., acommitand itsparent
in the directed acyclic graph that models the commit history in
git-basedversioncontrolrepositories)ofaJavaproject,andreturnsalistofrefactoringoperationsappliedbetweenthesetworevisions.Itsupportsthedetectionof15refactoringtypesfor4differentkindsofcodeelements,asshowninTable1.Thisisarepresentativesetofrefactoringtypes,becauseitcoversallstructuralcodeelements(i.e.,packages,types,methods,andfields),andalsocoverscontrol-flows
of program statements (e.g., Extract and InlineMethod).
Table 1: Refactorings detected byRMiner
Code element Refactorings
package ChangePackage (move, rename, split)
typeMove Class, Rename Class
Extract Superclass/Interface
methodExtract Method, InlineMethod
PullUp Method, Push Down Method
Rename Method, Move Method
Extract and Move Method
fieldPullUp Field, Push Down Field
Move Field
Unlikeotherexistingrefactoringdetectionapproaches,suchas
Ref-Finder [ 46], RefactoringCrawler [ 18], and JDEvAn [ 80],
whichanalyze allfiles intwosnapshots/versions ofa Javaproject,
RMineranalyzesonlytheadded,deleted,andchangedfilesbetween
the two revisions. This makes RMiner not only more efficient,
because it has less code elements to analyze and compare, but also
more accurate, because the number of code element combinations
tobecomparedissignificantlyless,thusreducingtheprobability
of incorrect code element matches.
2.1 Notation
We adopt and extend the notation defined by Biegel et al. [ 8] for
representingtheinformationthatweextractfromeachrevisionus-
ing the Eclipse JDT Abstract Syntax Tree (AST) Parser. Notice that
we configure the parser to create the ASTs of the added, deleted,
and changed Java compilation units in each revision withoutre-
solvingbindinginformationfromthecompiler,andthusthereis
no need to build the source code. Consequently, all referenced types
(e.g.,parameters,variable/fielddeclarations,extendedsuperclass,
implementedinterfaces)arestoredastheyappearintheAST,aswe
are not able to obtain their fully qualified names. For each revision
r, we extract the following information:•TDr:Thesetoftypedeclarations(i.e.,classes,interfaces,enums)
affected in r. For a child commit, this set includes the type decla-
rations inside changed and added Java files, while for a parent
commit, this set includes the type declarations inside changedand removed Java files. Each element
tdof the set is a tuple of
theform( p,n,F,M),wherepistheparentof td,nisthename
oftd,Fis the set of fields declared inside td, andMis the set
of methods declared inside td. For a top-level type declaration p
correspondstothepackageofthecompilationunit tdbelongsto,
while for a nested/inner type declaration pcorresponds to the
package of the compilation unit tdbelongs to concatenated with
the nameof the type declaration tdis nested under.
•Fr:Thesetoffieldsinsidethetypedeclarationsof TDr.Itcon-
tains tuples of the form ( c,t,n), wherecis the fully qualified
name of the type declaration the field belongs to (constructed
by concatenating the package name pwiththe type declaration
namen),tis the type of the field, and nis the name of the field.
•Mr: The set of methods inside the type declarations of TDr.I t
contains tuples of the form ( c,t,n,P,b), wherecis the fully
qualified name ofthe type declaration themethod belongs to, t
is the return type of the method, nis the name of the method, P
is the ordered parameter list of the method, and bis the body of
the method (could be nullif the method is abstract or native).
•Dr: The set of all directories in ras returned by command git
ls-tree. Each directory is represented by its path p.
private static Address[] createAddresses( int count) {
  
    Address[] addresses  = new Address[count] ;
    for (int i = 0; i < count; i++) {
        try {
            addresses [i] = new Address("127.0.0.1" , PORTS.incrementAndGet());
        } 
        catch (UnknownHostException e) {
            e.printStackTrace();
        }
    } 
    return addresses ;
}MT
L VV CD
VVVV
VVariable IdentifierTType
DVariable DeclarationLLiteral
CClass Instantiation MMethod InvocationVV VV C
Figure 1: Representation of a method body as a tree.
The body of a method is represented as a tree capturing the
nesting structure of the code, where each node corresponds to a
statement,similartotherepresentationusedbyFlurietal.[ 23].For
acompositestatement(i.e.,astatementthatcontainsotherstate-
mentswithinitsbody,suchas for,while,do-while ,if,switch,
try,catch,synchronized block ,label), the node contains the
statement’s type and the expression(s) appearing within parenthe-
sis before the statement’s body. For a leaf statement (i.e., a state-ment without a body), the node contains the statement itself. Inorder to avoid storing AST information into memory, for each
statement/expression we keep its string representation in a pretty-
printedformatwhereallredundantwhitespaceandmulti-linechar-actersareremoved.Inaddition,weuseanASTVisitortoextractall
variableidentifiers,methodinvocations,classinstantiations,vari-
able declarations, types, literals, and operators appearing within
eachstatement/expressionandstoretheminapretty-printedfor-
mat within the corresponding statement node. Figure 1 shows the
tree-like representation of the body of method createAddresses ,
along with the information extracted by the AST Visitor for two of
its statements.
485
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden N. Tsantalis et al.
2.2 Statementmatching
The matching of the statements between two code fragments is
acorefunctionthatweusethroughouttherefactoringdetectionrules described in this paper. Our statement matching algorithm
hasbeeninspiredbyFlurietal.[ 23],inthesensethatwealsomatch
the statements in a bottom-up fashion, starting from the matching
of leaf statements and then proceeding to composite statements.
However,inoursolution,outlinedinAlgorithm1,wedonotuse
any similarity measure to match the statements, and thus we do
not require the definition of similarity thresholds.
To reducethe chancesof erroneous matches,we follow acon-
servativeapproach,inwhichwematchthestatementsinrounds,
where each subsequent round has a less strict match condition
thanthepreviousround.Thus,thestatementsmatchedinearlier
roundsare“safer”matches,andareexcludedfrombeingmatched
inthe nextrounds. Inthis way,the nextround, whichhasa more
relaxed match condition, has fewer statement combinations to
check.
We match leaf statements in three rounds (lines 2-8). In the first
round,wematchthestatementswithidenticalstringrepresentation
andnestingdepth.Inthesecondround,wematchthestatements
withidenticalstringrepresentationregardlessoftheirnestingdepth.
Inthelastround,wematchthestatementsthatbecomeidentical
after replacing the AST nodes being different between the two
statements. We match composite statements in three rounds as
well (lines 9-16), using exactly the same match conditions as those
usedforleafstatementscombinedwithanadditionalconditionthat
requiresatleastonepairoftheirchildrentobematched(line10),
assumingthatboth composite statements have children.
In all rounds, we apply two pre-processing techniques on the
input statements(line 5 in function matchNodes ), namely abstrac-
tionandargumentization to deal with specific changes takingplace
inthecodewhenapplyingExtract,Inline,andMoveMethod
refactorings.
Abstraction: Somerefactoringoperations,suchasExtractand
InlineMethod,oftenintroduceoreliminate returnstatements
whenamethodisextractedorinlined,respectively.Forexample,
whenanexpressionisextractedfromagivenmethod,itappears
as areturnstatement in the extracted method. To facilitate the
matchingofstatementshavingadifferentASTnodetype,we ab-
stractthestatementsthatwrapexpressions.Whenbothstatements
being compared follow one of the following formats:
•return expression ;i.e., returned expression
•Type var = expression ;i.e.,initializerofavariabledeclaration
•var = expression ;i.e., right hand side of an assignment
•call( expression );i.e.,singleargumentofamethodinvocation
•if(expression )i.e., condition of a composite statement
then they are abstracted to expression before their comparison.
Figure2showsanexampleofabstraction,wheretheassignment
statement Dfromthecodebeforerefactoring,andthereturnstate-
ment5fromthecodeafterrefactoring,areabstractedtoexpres-
sionsnew Address("127.0.0.1", PORTS.incrementAndGet())
andnew Address(host, port) , respectively.
Argumentization: Some refactoring operations may replace ex-
pressionswithparameters,andviceversa.Forexample,whendu-
plicatedcodeisextractedintoacommonmethod,allexpressionsAlgorithm1: Statementmatching
Input :TreesT1andT2
Output:SetMof matched node pairs, Sets of unmatched
nodesUT1,UT2fromT1andT2, respectively
1M←/emptysetAlt2,UT1←/emptysetAlt2,UT2←/emptysetAlt2
2L1←T1.leafNodes ,L2←T2.leafNodes
3condition1( n1,n2)→n1.text=n2.text∧n1.depth=n2.depth
4condition2( n1,n2)→n1.text=n2.text
5condition3( n1,n2)→replacements (n1.text,n2.text)
6L/prime
1,L/prime
2=matchNodes (L1,L2,condition1 )// round #1
7L/prime/prime
1,L/prime/prime
2=matchNodes (L/prime
1,L/prime
2,condition2 )// round #2
8matchNodes (L/prime/prime
1,L/prime/prime
2,condition3 )// round #3
9C1←T1.compositeNodes ,C2←T2.compositeNodes
10condition4( n1,n2)→
∃(k1,k2)∈M|k1∈n1.children∧k2∈n2.children
11condition1( n1,n2)=condition1 ∧condition4
12condition2( n1,n2)=condition2 ∧condition4
13condition3( n1,n2)=condition3 ∧condition4
14C/prime
1,C/prime
2=matchNodes (C1,C2,condition1 )// round #1
15C/prime/prime
1,C/prime/prime
2=matchNodes (C/prime
1,C/prime
2,condition2 )// round #2
16matchNodes (C/prime/prime
1,C/prime/prime
2,condition3 )// round #3
17UT1←T1.nodes\MT1,UT2←T2.nodes\MT2
1Function matchNodes( N1,N2,matchCondition )
2foreachn1∈N1do
3 P←/emptysetAlt2
4 foreachn2∈N2do
5 pn1,pn2←preprocessNodes( n1,n2)
6 ifmatchCondition( pn1,pn2)then
7 P←P∪(n1,n2)
8 end
9 end
10 if|P|>0then
11 bestMatch ←findBestMatch( P)
12 M←M∪bestMatch
13 N1←N1\bestMatch .n1
14 N2←N2\bestMatch .n2
15 end
16end
17returnN1,N2
18end
being different among the duplicated code fragments are param-
eterized(i.e., they are replaced with parameters in the extracted
method). The duplicated code fragments are replaced with calls
totheextractedmethod,whereeachexpressionbeingdifferentis
passedasanargument.Inmanycases,theargumentsmaydiffersubstantially from the corresponding parameter names, leadingto a low textual similarity of the code before and after refactor-
ing. Argumentizationis the process ofreplacing parameter names
with the corresponding arguments in the code after refactoring.
Figure2showsanexampleofargumentization,whereparameter
nameshostandportarereplacedwitharguments "127.0.0.1"
andports.incrementAndGet() , respectively, in statement 5.
486
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. Accurate and Efficient Refactoring Detection in Commit History ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Before AfterA
B
C
D
E
F
G1 A
2 B
4 C
5 D
6 E
7 F
9 G private static List<Address> createAddresses(AtomicInteger ports, int count) {
     List<Address> addresses  = new ArrayList<Address>( count);
     for (int i = 0; i < count; i++) {
           addresses .add(createAddress( "127.0.0.1" , ports.incrementAndGet()));
     }
     return addresses ;
}1
2
3
protected static Address createAddress(String host, int port) {
    try {
        return new Address(host, port);
    } catch (UnknownHostException e) {
        e.printStackTrace();
    }
    return null;
}4
5
6
7
89"127.0.0.1"
ports.incrementAndGet()Matched
StatementsReplacement Addition Abstraction Argumentization
private static Address[] createAddresses( int count) {
    Address[] addresses  = new Address[count];
    for (int i = 0; i < count; i++) {
        try {
            addresses [i] = 
                 new Address("127.0.0.1" , PORTS.incrementAndGet());
        } 
        catch (UnknownHostException e) {
            e.printStackTrace();
        }
    } 
    return addresses ;
}
Figure 2: Statement matching for anExtract Method refactoring in project hazelcast [38].
The same process is applied to the statements of inlined and
moved methods. In particular, when an instance method is moved
to a target class, we might have a parameter (or a source class field
access) of target type that is removed from the original method, or
a parameter of source type that is added to the original method. In
the case of removal, the removed parameter (or field access) might
bereplacedwith thisreferenceinthemovedmethod,whileinthe
case of addition, thisreference might be replaced with the added
parameterin the moved method.
By applying the techniques of abstraction and argumentization
theoriginalstatements Dand5inFigure2aretransformedto
new Address("127.0.0.1", PORTS.incrementAndGet()) and
new Address("127.0.0.1", ports.incrementAndGet()) ,r e -
spectively, and thus can be identically matched by replacing static
fieldPORTSwithparameter ports. On the other hand, string simi-
larity measures would require a very low threshold to match these
statements. For instance, the Levenshtein distance [ 50] (commonly
used for computing string similarity) between the original state-
mentsDand5is44editoperations,whichcanbenormalizedto
asimilarityof1 −44/65=0.32,where65isthelengthofthelongest
stringcorresponding tostatement D.The bigramsimilarity [ 49]
(usedbyChangeDistiller[ 23])betweenstatements Dand5
is equal to 0.3. It is clear that the string similarity measures usedby the majority of the refactoring detection tools are susceptible
to code changes applied by some refactoring operations, such as
parameterization, especially when the arguments differ substan-tially from the parameter names. Therefore, our pre-processing
techniquesfacilitatethematchingofstatementswithlowtextual
similarity.
Function matchNodes , finds all possible matching nodes in tree
T2foragivennodeintree T1andstoresthematchingnodepairs
into setP. Function findBestMatch( P)(line 11), sorts the node
pairsinPandselectsthetop-sortedone.Leafnodepairsaresorted
basedon3criteria.First,basedonthestringeditdistance[ 50]of
thenodesinascendingorder(i.e.,moretextuallysimilarnodepairs
rankhigher).Second,basedontheabsolutedifferenceofthenodes’
depth in ascending order (i.e., node pairs with more similar depth
rankhigher). Third,basedon theabsolutedifference ofthenodes’
index in their parent’s list of children in ascending order (i.e., node
pairs with more similar position in their parent’s list of children
rankhigher).Compositenodepairsaresortedwithanadditional
criterion,whichisappliedrightafterthefirstcriterion:basedontheratioofthenodes’matchedchildrenindescendingorder(i.e.,
node pairs with more matched children rank higher).
Algorithm2: Syntax-aware replacements of AST nodes
Input :Statements s1ands2
Output:Trueif statements can be identically matched after
syntax-aware replacements, otherwise false
1Function replacements( s1,s2)
2Ns1←/emptysetAlt2,Ns2←/emptysetAlt2,R←/emptysetAlt2
3foreacht∈nodeTypes do
4 common t←s1.nodest∩s2.nodest
5 Ns1←Ns1∪{s1.nodest\common t}
6 Ns2←Ns2∪{s2.nodest\common t}
7end
8d=distance( s1,s2)
9foreachns1∈Ns1do
10 C←/emptysetAlt2
11 foreachns2∈Ns2do
12 ifcompatibleForReplacement( ns1,ns2)then
13 d/prime=distance( s1.replace( ns1,ns2),s2)
14 ifd/prime<dthen
15 C←C∪(ns1,ns2)
16 end
17 end
18 end
19 if|C|>0then
20 best←smallestDistance( C)
21 d=best.distance
22 r=best.replacement
23 R←R∪r
24 s1=s1.replace( r.ns1,r.ns2)
25 end
26end
27ifs1=s2then
28 returntrue
29else
30 returnfalse
31end
Function replacements (Algorithm 2), takes as input two state-
mentsandperformsreplacementsofASTnodesuntilthestatements
487
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden N. Tsantalis et al.
...
NeuralNetConfiguration conf = 
 new NeuralNetConfiguration.Builder()
 .lossFunction(LossFunctions.LossFunction. MCXENT)
 .optimizationAlgo(
      OptimizationAlgorithm. ITERATION_GRADIENT_DESCENT )
 .activationFunction( "softmax" )
 .iterations( 10)
 .weightInit(WeightInit. XAVIER)
 .learningRate( 1e-1)
 .nIn(4) 
 .nOut(3)
 .layer(new org.deeplearning4j.nn.conf.layers.OutputLayer())
 .build();
...static OutputLayer getIrisLogisticLayerConfig(String activationFunction , int iterations ){
  NeuralNetConfiguration conf = 
     new NeuralNetConfiguration.Builder()
      .layer(new org.deeplearning4j.nn.conf.layers.OutputLayer())
      .nIn(4)
      .nOut(3)
      .activationFunction( activationFunction )
      .lossFunction(LossFunctions.LossFunction. MCXENT)
      .optimizationAlgo(
           OptimizationAlgorithm. ITERATION_GRADIENT_DESCENT )
      .iterations( iterations )
      .weightInit(WeightInit. XAVIER)
      .learningRate( 1e-1)
      .seed(12345L)
      .build();
}Replacement Addition Argumentization OutputLayer layer = getIrisLogisticLayerConfig( "softmax" , 10);
...
"softmax"
10
(a) Method invocation chains following the Fluent Interface [29] pattern in project deeplearning4j [14].
public IndexDescriptor indexCreate(
     KernelStatement state, int labelId, int propertyKeyId ) {
 return schemaWriteOperations.indexCreate( state, labelId, propertyKeyId );
}public IndexDescriptor indexCreate( 
     KernelStatement state, NodePropertyDescriptor descriptor ) {
  return schemaWriteOperations.indexCreate( state, descriptor );
}
(b) Method invocation having two arguments replaced with a single argument in project neo4j [58].
Figure 3: Replacement of method invocations.
becometextuallyidentical.Thisapproachhastwomainadvantages
overexistingmethodsrelyingontextualsimilarity.First,thereis
noneedtodefineasimilaritythreshold.Thereisempiricalevidence
that developers interleave refactoring with other types of program-mingactivity(e.g.,bugfixes,featureadditions,orotherrefactoring
operations)[
55,56,64].Inmanycases,thechangescausedbythese
different activities may overlap [ 57]. Some of these changes may
evenchangesubstantiallytheoriginalcodebeingpartofarefactor-ing operation. For example, a code fragment is originally extracted,
and then some temporary variables are inlined in the extractedmethod. The longer the right-hand-side expressions assigned to
thetemporaryvariables,themoretextuallydifferenttheoriginalstatementswillbeafterrefactoring.Therefore,itisimpossibleto
define auniversal similarity threshold value that can cover any
possiblescenarioofoverlappingchanges.Ontheotherhand,our
approachdoesnotposeanyrestrictiononthereplacementsofAST
nodes,aslongasthesereplacementsaresyntacticallyvalid.Second,
thereplacementsfoundwithintwomatchedstatementscanhelp
toinferothereditoperationstakingplaceontherefactoredcode
(a phenomenon called refactoring masking [68]), such as renaming
of variables, generalization of types, and merging of parameters.
On the other hand, similarity-based approaches lose this kind of
valuableinformation.
Initially,ouralgorithmcomputestheintersectionbetweenthe
setsofvariableidentifiers,methodinvocations,classinstantiations,
types, literals, and operators extracted from each statement, re-spectively,inordertoexcludefromreplacementstheASTnodesbeing common in both statements, and include only those being
different between the statements (lines 3-7). AST nodes that cover
theentirestatement(e.g.,amethodinvocationfollowedby ;)ar e
also excluded from replacements in order to avoid having an exces-
sivenumberofmatchingstatements.Allattemptedreplacements
aresyntax-aware , in the sense that only compatible AST nodes are
allowed to be replaced (line 12), i.e., types can be replaced only
by types, operators can be replaced only by operators, while all
remainingexpressiontypescanbereplacedbyanyoftheremain-
ingexpressiontypes(e.g.,avariablecanbereplacedbyamethodinvocation). Out of all possible replacements for a given node from
the first statement that decrease the original edit distance of the
inputstatements,weselectthereplacementcorrespondingtothe
smallestedit distance (line 20).
Inthespecialcasewhentwomethodinvocationsareconsidered
for replacement, function compatibleForReplacement( ns1,ns2)
examinestheexpressionsusedforinvokingthemethods.Ifthese
expressionsarechainsofmethodinvocations,asthecaseshownin
Figure 3a (commonly known as the Fluent Interface [29] pattern in
API design), then we extract the individual method invocations be-
ing part of each chain and compute their intersection ignoring any
differences in the order of the invocations inside each chain. If the
numberofcommoninvocationsislargerthantheuncommonones,
then we consider the original method invocations as compatible
forreplacement.IntheexampleofFigure3a,thereare9common
invocations (two of them are identically matched after applying
theargumentizationtechnique),andonly1uncommon.Noticethat
stringsimilaritymeasuresproduceverylowsimilarityvalueforthis
case. For instance, the normalized Levenshtein similarity between
the two statements is 0.47, while the bigram similarity is 0.46.
Handling of changes not supported by Algorithm 2: As ex-
plainedbefore,ASTnodescoveringtheentirestatement,suchas
the method invocations shown in Figure 3b, are excluded from
replacements to avoid having an excessive number of matching
statements.However,theremightbechangesintheirlistofargu-
mentsthatcannotbehandledbyAlgorithm2,suchastheinsertion
ordeletionofanargument,andthereplacementofmultipleargu-
mentswithasingleoneandviceversa.Thisisbecausewedesigned
the algorithm to perform only one-to-one AST node replacements
and does not support one-to-many, many-to-one, one-to-zero (i.e.,
deletion),zero-to-one(i.e.,insertion)replacements,asthiswould
increase substantially its computational cost. To overcome this lim-
itation, we allow the replacements of textually different method
invocations covering the entire statement, as long as they have an
identicalinvocationexpression,anidenticalmethodname,anda
non-empty intersection of arguments (e.g., argument statein the
example of Figure 3b).
488
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. Accurate and Efficient Refactoring Detection in Commit History ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
Table 2: Refactoring detection rules
Refactoring type Rule
Change Method Signature∃(M,UT1,UT2)=matching( ma.b,mb.b)|ma∈M−∧mb∈M+∧ma.c=mb.c∧ma.n/nequalmb.n⇒Rename Method
matomb1(UT1=/emptysetAlt2∧UT2=/emptysetAlt2∧allExactMatches( M))∨2(|M|>|UT1|∧|M|>|UT2|∧locationHeuristic( ma,mb)∧compatibleSignatures( ma,mb))∨
3(|M|>|UT2|∧locationHeuristic( ma,mb)∧∃extract( ma,mx))∨4(|M|>|UT1|∧locationHeuristic( ma,mb)∧∃inline( mx,mb))
Extract Method mbfromma∃(M,UT1,UT2)=matching( ma.b,mb.b)|(ma,ma/prime)∈M=∧mb∈M+∧ma.c=mb.c∧¬calls( ma,mb)∧calls( ma/prime,mb)∧|M|>|UT2|
Inline Method mbtoma/prime ∃(M,UT1,UT2)=matching( mb.b,ma/prime.b)|(ma,ma/prime)∈M=∧mb∈M−∧ma/prime.c=mb.c∧calls( ma,mb)∧¬calls( ma/prime,mb)∧|M|>|UT1|
Change Class Signature ∃(tda,tdb)|tda∈TD−∧tdb∈TD+∧(tda.M⊇tdb.M∨tda.M⊆tdb.M)∧(tda.F⊇tdb.F∨tda.F⊆tdb.F)
tdatotdb tda.p/nequaltdb.p⇒Move Class tda.n/nequaltdb.n⇒Rename Class
Move Method matomb∃(M,UT1,UT2)=matching( ma.b,mb.b)|ma∈M−∧mb∈M+∧ma.c/nequalmb.c∧|M|>|UT1|∧|M|>|UT2|∧
(tda,tda/prime)∈TD=∧ma∈tda∧(tdb,tdb/prime)∈TD=∧mb∈tdb/prime∧(importsType( tda/prime,mb.c)∨importsType( tdb,ma.c))
subType( ma.c,mb.c)⇒Pull Up Method subType( mb.c,ma.c)⇒Push Down Method
Move Field fatofb∃(fa,fb)|fa∈F−∧fb∈F+∧fa.c/nequalfb.c∧fa.t=fb.t∧fa.n=fb.n∧
(tda,tda/prime)∈TD=∧fa∈tda∧(tdb,tdb/prime)∈TD=∧fb∈tdb/prime∧(importsType( tda/prime,fb.c)∨importsType( tdb,fa.c))
subType( fa.c,fb.c)⇒Pull Up Field subType( fb.c,fa.c)⇒Push Down Field
Extract mbfromma& ∃(M,UT1,UT2)=matching( ma.b,mb.b)|(ma,ma/prime)∈M=∧mb∈M+∧ma.c/nequalmb.c∧
Move to mb.c ¬calls( ma,mb)∧calls( ma/prime,mb)∧|M|>|UT2|∧(tda,tda/prime)∈TD=∧ma∈tda∧importsType( tda/prime,mb.c)
Extract Supertype∃(tda,tdb)|(tda,tda/prime)∈TD=∧tdb∈TD+∧subType(type( tda/prime),type( tdb))
tdbfromtda∃pullUp( ma,mb)|ma∈tda∧mb∈tdb∨∃pullUp( fa,fb)|fa∈tda∧fb∈tdb⇒Extract Superclass
∃(ma,mb)|ma∈tda∧mb∈tdb∧identicalSignatures( ma,mb)∧mb.b=null⇒Extract Interface
Change Package patopb ∃(pa,pb)|path( pa)∈D−∧path( pb)∈D+∧∃MoveClass( tda,tdb)|tda.p=pa∧tdb.p=pb
matching( T1,T2)returns a set of matched statement pairs ( M) between the trees T1andT2representing method bodies, and two sets of unmatched statements from T1(UT1) and T2(UT2), respectively
indexOf( m,td)returns the position of minside type declaration tdtypeDecl( c)returns the type declaration of type ctype( td)returns the qualified name of type declaration td
locationHeuristic( ma,mb)=|indexOf( ma,typeDecl( ma.c))−indexOf( mb,typeDecl( mb.c))|≤|M−c−M+c|importsType( td,t)returnstrueiftypedeclaration tddependsontype t
compatibleSignatures( ma,mb)=ma.P⊇mb.P∨ma.P⊆mb.P∨|ma.P∩mb.P|≥| ( ma.P∪mb.P)\(ma.P∩mb.P)|calls( ma,mb)returns true if method macallsmb
subType( ca,cb)returns true if cais a direct or indirect subclass of cbor implements interface cbpath( p)returns the directory path for package p
2.3 Refactoringdetection
Thedetectionofrefactoringstakesplaceintwophases.Thefirst
phaseislesscomputationallyexpensive,sincethecodeelements
arematchedonlybasedontheirsignatures.Ourassumptionisthat
twocodeelementshavinganidenticalsignatureintworevisions
correspond to the same code entity, regardless of the changes that
mighthaveoccurredwithintheirbodies.Thesecondphaseismore
computationally expensive, since the remaining code elements are
matched based on the statements they have in common within
theirbodies.Inanutshell,inthefirstphase,ouralgorithmmatches
code elements in a top-down fashion, starting from classes and
continuing to methods and fields. Two code elements are matched
only if they have an identical signature. Assuming aandbare two
revisions of a project:
•Twotypedeclarations tdaandtdbhaveanidenticalsignature,if
tda.p=tdb.p∧tda.n=tdb.n
•Two fields faandfbhave an identical signature, if
fa.c=fb.c∧fa.t=fb.t∧fa.n=fb.n
•Two methods maandmbhave an identical signature, if
ma.c=mb.c∧ma.t=mb.t∧ma.n=mb.n∧ma.P=mb.P
•Two directories daanddbare identical, if da.p=db.p
Aftertheendofthefirstphase,weconsidertheunmatchedcode
elementsfromrevision aaspotentiallydeleted ,andstorethemin
setsTD−,F−,M−,andD−,respectively.Weconsidertheunmatched
code elements from revision baspotentially added , and store them
in setsTD+,F+,M+, andD+, respectively. Finally, we store the
pairsofmatchedcodeelementsbetweenrevisions aandbinsets
TD=,F=,M=, andD=, respectively.
In the second phase, our algorithm matches the remaining code
elements (i.e., the potentially deleted code elements with the poten-
tiallyadded ones)inabottom-upfashion,startingfrommethods
and continuing to classes, to find code elements with signature
changesor code elements involved in refactoring operations.Examinationorderofrefactoringtypes: Wedetecttherefactor-
ing types in the order they appear in Table 2 by applying the rules
showninthesecondcolumnofthetable.Theorderofexamination
isveryimportantfortheaccuracyofourapproach.Weorderthe
refactoring types according to their locality of change [19], start-
ing from local refactoring types (i.e., within a single method/class)
and proceeding with global ones (i.e., among different classes or
packages).Theintuitionbehindthisordercomesfromempiricalev-
idenceshowing thatsmall and local refactorings are more frequent
than big and global ones [ 9,56], and thus there is a higher prob-
ability that the potentially added/deleted code elements resulted
from local rather than global refactorings. Whenever a refactoring
type is processed, we remove the matched code elements from the
setsofpotentiallydeleted/addedcodeelements,andaddthemto
the corresponding setsof matchedcode elements.This affectsthe
codeelementsexaminedintherefactoringtypesthatfollow,thus
reducing the noise level and improving accuracy.
Best match selection: For the refactoring types involving state-
ment matching in their detection rule, when a code element (i.e.,method) has multiple matches, we always select the best match.
Thereasonisthatthesamepieceofcodecannotbepartofmultiple
refactoringoperations.Forexample,amethodcannotberenamedto
multiple methods. Our algorithm sorts the matching method pairs
based on 4 criteria, which serve as proxies for method similarity at
statement level. First, based on the total number of matched state-
mentsindescendingorder(i.e.,methodpairswithmorematched
statementsrankhigher).Second,basedonthetotalnumberofex-
actly matched statements in descending order (i.e., method pairs
withmoreidenticalstatementsrankhigher).Third,basedonthe
total edit distance [ 50] between the matched statements in ascend-
ing order (i.e., method pairs with more textually similar statementsrankhigher).Fourth,basedontheeditdistancebetweenthemethod
namesinascendingorder(i.e.,methodpairswithmoretextually
similarnamesrank higher).
489
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden N. Tsantalis et al.
As Table 2 shows, the refactoring types examined first have
more elaborate and strict rules. This is crucial to avoid early er-
roneousmatchesthatwouldnegativelyaffecttheaccuracyofthe
detected instances for the refactoring types that follow. For exam-
ple, thelocation heuristic applied in sub-rules 2,3, and4of
the Change Method Signature refactoring type, ensures that thepositional difference of two matched methods is less or equal tothe absolute difference in the number of methods added to and
deleted from a given type declaration. The intuition behind this
heuristicisthatdevelopersdonottendtochangethepositionofan
already existing method inside its type declaration when changing
its signature. Assuming that only method renames take place ina type declaration, the number of potentially added and deleted
methodswillbeequal,andthusthelocationheuristicwillbesat-
isfied only for the method pairs having the same position before
andafterrefactoring.Thisheuristicisparticularlyeffectiveincases
of extensive method signature changes in test classes (e.g., see
thecaseofextensiveunittestrenamesinprojectcassandra[ 10]),
wheredeveloperstendtocopy-and-modifyolderunitteststocre-
ate new ones [ 72], and thus several methods share very similar
statements with each other. Sub-rules 3and4take into account
the case where a method with a signature change has a significant
portion of its body extracted or inlined, respectively. For instance,
in the case shown in Figure 2, the result of statement matchingbetweenmethods
createAddresses beforeandafterrefactoring
isM={(A,1),(B,2),(G,9)},i.e.,|M|=3,whileUT1={C,D,E,F},
i.e.,|UT1|=4, andUT2={3}, i.e.,|UT2|=1, and thus sub-rule 2
failstomatchthemethods.Ontheotherhand,sub-rule 3matches
successfullythemethods,because |M|>|UT2|andthereexistsat
least one method extracted from the original createAddresses .
3 EVALUATION
Weempiricallyevaluatetheusefulnessof RMinerbyanswering
the followingresearch questions:
RQ1:Whatistheaccuracyof RMinerandhowdoesitcompare
to the previous state-of-the-art?
RQ2:What is the execution time of RMiner and how does it com-
pare to the previous state-of-the-art?
We answer the first research question by computing standard
metrics from information retrieval (i.e., precision and recall). As
these metrics require having a reliable oracle,we use complemen-
tary methods to create the most accurate oracle to date. Moreover,
we compare the accuracy and running time of RMiner against
that of the previous state-of-the-art tool, RefDiff, as Silva and Va-
lente [65] established that RefDiff significantly outperforms other
widely used refactoring detection tools, such as Ref-Finder and
RefactoringCrawler.
3.1 Oracleconstruction
Having a correct, complete and representative oracle of refactor-
ingsisfundamentalforcomputingprecisionandrecallinareliable
manner. Therefore, we used a publicly available dataset of refactor-
ing instances [ 64], comprising 538 commits from 185 open-source
GitHub-hosted projects monitored over a period of two months
(between June 8thand August 7th, 2015). The authors of [ 64] man-
uallyvalidatedallrefactoringinstancesinthedataset.Moreover,Table 3: Precision and recall per refactoring type
Refactoring TypeRMiner RefDiff
Precision Recall Precision Recall
Inline Method 98.96 86.36 84.35 88.18
Extract Method 98.63 84.72 93.03 90.95
Move Field 88.42 95.45 30.19 45.45
Move Class 100 96.24 99.90 93.53
Extract Interface 100 100 76.92 55.56
Push Down Method 100 100 95.00 61.29
Push Down Field 100 86.21 100 100
Change Package 85.00 100 N/A N/A
Pull Up Method 100 90.48 80.60 85.71
Pull Up Field 100 96.30 64.00 59.26
Move Method 95.17 76.36 32.25 92.25
Rename Method 97.78 83.28 85.54 89.59
Extract Superclass 95.08 100 100 18.97
Rename Class 98.33 71.08 89.71 73.49
Extract & Move Method 95.92 41.23 73.02 80.70
Overall 97.96 87.20 75.71 85.76
the instances found in 222 of these commits were confirmed by
the developers who actually performed the refactorings (i.e., the
commit authors) through surveys. We re-validated all instances to
ensuretheircorrectness.Fourteencasesactuallycorrespondedto
multiple instances summarized as a single refactoring operation
(e.g.,arefactoringreportedas“method fooextractedfrom barand
xother methods” corresponds to x+1 separate Extract Method
instances). We broke down these cases to separate instances by
manually finding the summarized code elements. This dataset can
be considered correct, since all instances went through rigorous
manual validation by multiple authors and in several cases were
confirmed by the developers who actually performed them. It is
oneofthemostrepresentativedatasetstodate,sinceallinstances
arerealrefactoringsfoundin185differentJavaprojects,theyare
motivatedbyavarietyofreasons[ 64],andtakeplacealongwith
other changes/refactorings in the same commit. However, the com-
pletenessofthedatasetisnotguaranteed,sincethereisnoreported
recall for the refactoring detection tool used in [ 64]. To ensure the
completeness of the dataset, we executed two tools that analyze
repository commits without requiring to build the project, namely
RMinerandRefDiff[ 65],onall538commitsofthedataset.These
tools use complementary detection methods (i.e., a more conser-
vative threshold-free approach based on statement matching vs. a
more relaxed threshold-based approach based on token similarity),
thusarelikelytodetectamorecomprehensivesetofrefactoring
instances. For the validation process, we created a web application,
which listed all detected refactorings along with links to the cor-
responding GitHub commits. Through this web application, the
validators were able to inspect the change diff provided by GitHub,
and enter their validation and comments. In total, we manually
validated 4,108 unique refactoring instances detected by the two
tools, out of which 3,188 were true positives and 920 were false
positives. The validation process was labor-intensive and involved
3validatorsforaperiodof3months(i.e.,9person-months).Togive
asenseofthemanualinspectiondifficulty,onaverage,acommit
contained7.89refactoringinstances(median=2),14.25changed
files (median = 5), and 1,047 changed lines of code (median = 211).
490
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. Accurate and Efficient Refactoring Detection in Commit History ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
3.2 Precision and Recall
Since RefDiff does not support the detection of Change Package
refactoring, we did not consider the instances detected by RMiner
as false negatives for RefDiff. Moreover, to ensure a fair com-
parison for RMiner, we considered all classes within a changedpackage as being moved from the original package to the new
one,andaddedthecorrespondingMoveClassinstancestothose
originallydetected by RMiner.
Table 3shows the precision andrecall of RMinerandRefDiff.
Notice that RMiner has better precision than RefDiff in all refac-
toringtypes,exceptforExtractSuperclass(95%vs.100%),where
RefDiffseemstobeextremelyconservativeduetoitslowrecall.
This is a result of RMiner following a conservative threshold-free
approachfordetectingrefactorings,whichresultsinhighprecision.
The lowest precision for RMiner is observed for Change Package
and Move Field (85% and 88.4%, respectively), while it has over
95%precisioninallotherrefactoringtypes.TheAchilles’heelof
RefDiff,in termsofprecision, isthedetection of MoveMethod
andMoveFieldrefactorings(32%and30%,respectively).Wefound
tworecurringscenarioscausingsuchfalsepositivesforRefDiff.In
the firstscenario, RefDiff missesthe detectionof a class move to
another package, and consequently reports the methods and fields
of that class as being moved from the original class, which is as-
sumedtobedeleted,toanotherclass,whichisassumedtobenewly
added. In the second scenario, a subclass extending/implementing
agivensuperclass/interfaceisdeleted,andanewsubclassisadded,
which overrides the superclass/interface methods in a similar way.
RefDiffreportsthesemethodsasbeingmovedfromthedeletedto
the added subclass. We believe both scenarios occur because RefD-
iff does not examine if there is an import dependency between
the source and target class of a candidate Move Method/Field
refactoring, but relies only on code similarity.
Since RMiner achieves very high precision, does RefDiff have
better recall due to its less conservative threshold-based approach?
We found this is true only for 7 refactoring types, while for the
other7typesRMinerhasbetterrecall.Inparticular,RMinerhas
anincreasedrecallof37%to81%forinheritance-relatedrefactor-
ings (i.e., Pull Up Field, Push Down Method, Extract Super-
class/Interface), and 50% for Move Field refactoring, while the
increaseinrecallforMoveClassandPullUpMethodrefactorings
is smaller, 3% and 5%, respectively. In contrast, RefDiff has only a
slightlyincreasedrecallof2%to6%forlocalrefactorings,suchas
Extract/Inline/RenameMethodandRenameClass,whilethe
increase in recall for inter-class refactorings, such asPushDown
Field, Move Method, and Extract and Move Method, is larger,
14%,16% and39%, respectively.
An inherent advantage of RefDiff, helping it to achieve higher
recall in refactoring types involving code similarity, is that it ig-
nores the structure of the code by treating code fragments as bags
oftokens.Therefore,anychangeinthestructureofthecode(e.g.,
merging/splitting of conditionals, as in the case found in projectjetty[
41])beforeorafter theactualrefactoringwill notaffectits
detectionability,aslongasthetokensremainthesame.Adisadvan-
tageof RefDiffisitsinabilitytodealwithchangesinthetokens
caused by the refactoring itself (e.g., parameterization of expres-sions in Extract Method refactoring), or another overlappingRMinerRefDiff
      2 128,622     425      58
Figure 4: Execution time per commit (ms).
refactoring (e.g.,local variable renamesinside the bodyof arefac-
toredmethod).Ontheotherhand,RMinerdealsrobustlywiththis
kind of changes by applying statement pre-processing techniques,
such as argumentization, and allowing syntax-aware replacement
ofASTnodeswithinmatchedstatements.Furtherresearchonhy-
bridmethodsthatcombinetheadvantagesof RMinerandRefDiff
seems to have great potential.
3.3 Execution Time
Figure4showsthedistributionoftheexecutiontimeof RMiner
and RefDiff for each examined commit, collected by executing
separatelyeachtoolonthesamemachinewiththefollowingspecifi-
cations:IntelCorei7-2620MCPU@2.70GHz,16GBDDR3memory,
1 TB SSD, Windows 10 OS, and Java 1.8.0 x64. For each tool, we
recordedthetimetakenforparsingthesourcecodeoftheexamined
and its parent commit, and the time taken to detect refactorings
usingthe System.nanoTime Javamethod.Onmedian,RMineris
7 times faster than RefDiff (58 vs. 425 ms). We also applied the
Wilcoxon signed rank test on the paired samples of the time execu-
tion for each commit, which rejected the null hypothesis “RefDiff
execution time is smaller than that of RMiner” with a p-value <
2.2e-16,andthuswecanstatisticallyconcludethatRMinerisfaster
on our commit sample. We should note that RMiner has 70 outlier
commits that were processed in over one second, representing 13%
of the examined commits.Among these commits 39 took between
1-5 sec, 14 between 5-10 sec, 11 between 10-30 sec, and 6 took over
30 sec with the most time consuming commit taking 128 sec.
3.4 Limitations
Missing context: As explained in Section 2, RMiner analyzes
onlytheadded,deleted,andchangedfilesbetweentworevisions.
However,themissingcontext(i.e.,theunchangedfiles)canmake
RMinertoreportanincorrectrefactoringtypeforcertainopera-
tions.Forexample,ifamethodorfieldispulledmultiplelevelsupto
theinheritancehierarchyandsomeclassesbetweenthesourceand
destinationareunchanged,thenRMinerwillreportitasamove,
becauseitcannotdetecttheinheritancerelationshipbetweenthe
source and destination classes due to the missing context. In our
oracle,thisscenariooccurredonlyonceinprojectcascading[ 75],
where 4 methods were pulled three levels up ( TezNodeStats →
BaseHadoopNodeStats →FlowNodeStats →CascadingStats ),
but class FlowNodeStats remained unchanged in the commit.
Nestedrefactorings: RMineriscurrentlyunabletodetectnested
refactoringoperations,e.g.,ExtractMethodappliedwithinan
extracted method. Anotable exception is thedetectionof Extract
and Move Method, which is a sequence of two nested refactoring
operations.Apossiblesolutionistoincluderecursivelythestate-
ments of called methods when performing the statement matching
491
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden N. Tsantalis et al.
process. In this way, it will be possible to reconstruct the sequence
of nested refactoring operations, regardless of the nesting depth.
Unsupported refactorings: In this paper, we present and eval-
uate the detection rules for 15 refactoring types, while Fowler’s
catalog[28]includes72differenttypes.RMineralreadysupports
thedetectionofrefactoringsrelatedtomethodsignaturechanges
(add/removeparameter,changereturn/parametertype,hide/unhide
method),butwedidn’tvalidatethedetectedinstancesinourdatasetduetotheirlargenumberandtimeconstraints.Moreover,therefac-
toring types taking place within method bodies, such as rename
variable/parameter/field, extract/inline variable, and replace magic
numberwithconstant,canbeinferredbyutilizingtheASTnode
replacements collected through the statement matching process.
Withtheseadditions,RMinerwillbeabletosupportthemajorityof
the mostpopular refactoring types applied by developers [55, 56].
Oracle bias: Although we did our best effort to reduce bias in the
construction of our oracle by incorporating the input of two tools
andmanualvalidationsbymultipleauthors,wecannotclaimthe
oracleisunbiased.Wetriedtoincorporatetheinputofsnapshot-
based tools, such as Ref-Finder, but the vast majority of commits
failedtobuildduetobrokendependencies.Moreover,wheneverthe
inspectionofacasewaschallenging,multipleauthorsperformedan
independent validation followed by a thorough discussion. Overall,
3,333 cases were inspected by one validator (out of which 1,411
caseswerealreadyassessedastruepositivesbytheauthorsof[ 64]),
652 by two validators, and 123 by three validators.
4 RELATED WORK
Weißgerber and Diehl [ 74] developed the first technique for the
detection of local-scope and class-level refactorings in the commit
history of CVS repositories. Their approach uses a clone detection
tool(CCFinder[ 43])tocomparethebodiesofthecodeelementsthat
are candidates for refactorings. They manually inspected the com-
mitlogmessagesoftwoopen-sourceprojectstofinddocumented
refactorings and compute the recall, and used random sampling to
estimate theprecision oftheir approach.Dig etal. [ 18]developed
atool,RefactoringCrawler,whichfirstperformsafastsyntac-
tic analysis (based on techniques from Information Retrieval) tofind refactoring candidates, and then a precise semantic analysis
(basedonsimilarityofcallgraphs)tofindtheactualrefactorings.
To compute the recall, the authors manually discovered the ap-
pliedrefactoringsinthreeprojectsbyinspectingtheirreleasenotes,
whiletheyinspectedthesourcecodetocomputeprecision.Xing
andStroulia[ 78]developedatool,JDEvAn[ 80],whichdetectsand
classifies refactoringsbased on thedesign-level changes reported
by UMLDiff [ 77]. They evaluated the recall of JDEvAn on two
softwaresystems,andfoundthatalldocumentedrefactoringswererecovered. Prete et al. [
46,62] developed a tool, Ref-Finder, which
detects the largest number of refactoring types (63 of 72) from
Fowler’scatalog[ 28].Ref-Finderencodeseachprogramversion
usinglogicpredicatesthatdescribecodeelementsandtheircontain-
mentrelationships,aswellasstructuraldependencies,andencodes
refactorings as logic rules. Prete et al. created a set of correct refac-
torings by running Ref-Finder with a low similarity threshold
(σ=0.65)andmanuallyverifiedthem.Then,theycomputedrecall
by comparing this set with the results found using a higher thresh-
old (σ=0.85) and computed precision by inspecting a sampled dataset.SilvaandValente[ 65]developedatool,RefDiff,whichtakesas
inputtworevisionsofagitrepositoryandemploysheuristicsbasedon static analysis and code similarity to detect 13 refactoring types.
RefDiff represents a source code fragment as a bag of tokens, and
computesthesimilarityofcodeelementsusingavariationofthe
TF-IDF weighting scheme. To determine the similarity threshold
values the authors applied a calibration process on a randomly
selectedsetoftencommitsfromtendifferentopen-sourceprojects,
forwhichtheappliedrefactoringsareknownandhavebeencon-
firmedbytheprojectdevelopersthemselves[ 64].Theyevaluated
the accuracy of their tool using an oracle of seeded refactorings
applied by graduate students in 20 open-source projects.
Unlike these previous tools, RMiner neither requires similarity
thresholds (that are tedious to calibrate, and might not be gen-
eralizable), nor does it require operating on fully built snapshots
of software systems, thus it is applicable in many more contexts.
Moreover, whereas previous tools have been evaluated against 2-3
projects with a small number of refactoring instances (a notable
exception is RefDiff, which was evaluated on 20 projects with
448seededrefactorings),ouroracleisordersofmagnitudelarger
comprising185projectsand3,188truerefactoringinstances.Weuse triangulation between multiple sources to create one of the
mostreliable, comprehensive, and representative oracles to date.
Atotallydifferentapproachtodetectrefactoringsinreal-time
is to continuously monitor code changes inside the IDE. BeneFac-
tor [31] and WitchDoctor [ 27] detect manual refactorings in
progress and offer support for completing the remaining changes,
whereas CodingTracker [ 56], GhostFactor [ 32] and Review-
Factor[34]inferfullycompletedrefactorings.Whilethesetools
highlight novel usages of fine-grained code changes inside the IDE,
RMiner focuses on changes from commits, thus it can be more
broadly applied as it is not dependent on an IDE or text editor.
5 CONCLUSIONS
Inthiswork,wepresentedthefirstrefactoringdetectionalgorithm
thatdoesnotrelyoncodesimilaritythresholds.Weutilizenovel
techniques, such as abstraction andargumentization to deal with
changes taking place on code statements during refactoring. In
addition,weapplysyntax-awarereplacementof ASTnodeswhen
matching two statements to deal with overlapping refactorings
(e.g.,variablerenames),orchangescausedbyothermaintenance
activities(e.g.,bugfixing).Ourevaluation,usingoneofthemost
accurate, complete, and representative refactoring oraclesto date,
showed that our approach achieves very high precision (98%) with
a recall that is competitive to the previous state-of-the-art (87%),and has very small computation cost (on median, it takes 58 msto process a commit). Moreover, RMiner’s ability to operate on
commitsopensnewavenues:(1)empiricalresearcherscancreate
refactoringdatasetswithhighprecisionfromtheentirecommithis-
tory of projects, and study various software evolution phenomena
at a fine-grained level, (2) bug-inducing analysis techniques can
improve their accuracy utilizing commit-level refactoring informa-
tion,(3)refactoringoperationscanbeautomaticallydocumentedat
commit-time to provide a more detailed description of the applied
changesinthecommitmessage,(4)commitdiffvisualizationcan
be overlaid with refactoring information to assist code review and
evolution comprehension.
492
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. Accurate and Efficient Refactoring Detection in Commit History ICSE ’18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]EvertonL.G.Alves,MyoungkyuSong,andMiryungKim.2014. RefDistiller:A
RefactoringAwareCodeReviewToolforInspectingManualRefactoringEdits.
InProceedingsofthe22ndACMSIGSOFTInternationalSymposiumonFoundations
of Software Engineering (FSE ’14) . ACM, New York, NY, USA, 751–754. https:
//doi.org/10.1145/2635868.2661674
[2]Tiago L. Alves, Christiaan Ypma, and Joost Visser. 2010. Deriving Metric Thresh-
olds from Benchmark Data. In Proceedings of the 2010 IEEE International Confer-
enceonSoftwareMaintenance(ICSM’10) .IEEEComputerSociety,Washington,
DC, USA, 1–10. https://doi.org/10.1109/ICSM.2010.5609747
[3]Maurício Aniche, Christoph Treude, Andy Zaidman, Arie van Deursen, and
Marco Aurélio Gerosa. 2016. SATT: Tailoring Code Metric Thresholds for Differ-
entSoftwareArchitectures.In ProceedingsoftheIEEE16thInternationalWork-
ing Conference on Source Code Analysis and Manipulation (SCAM ’16) . 41–50.
https://doi.org/10.1109/SCAM.2016.19
[4]GiulianoAntoniol,MassimilianoDiPenta,andEttoreMerlo.2004. AnAutomatic
Approach to identify Class Evolution Discontinuities. In 7th International Work-
shoponPrinciplesofSoftwareEvolution .31–40. https://doi.org/10.1109/IWPSE.
2004.1334766
[5]IttaiBalaban,FrankTip,andRobertM.Fuhrer.2005. Refactoringsupportforclass
librarymigration.In Proceedingsofthe20thAnnualACMSIGPLANConference
on Object-Oriented Programming, Systems, Languages, and Applications . 265–279.
https://doi.org/10.1145/1094811.1094832
[6]Gabriele Bavota, Bernardino De Carluccio, Andrea De Lucia, Massimiliano Di
Penta, Rocco Oliveto, and Orazio Strollo. 2012. When Does a Refactoring Induce
Bugs? An Empirical Study. In Proceedings of the IEEE 12th International Working
ConferenceonSourceCodeAnalysisandManipulation(SCAM’12) .104–113. https:
//doi.org/10.1109/SCAM.2012.20
[7]GabrieleBavota,AndreaDeLucia,MassimilianoDiPenta,RoccoOliveto,and
Fabio Palomba. 2015. An Experimental Investigation on the Innate Relationship
Between Quality and Refactoring. Journal of Systems and Software 107 (Sept
2015), 1–14. https://doi.org/10.1016/j.jss.2015.05.024
[8]BenjaminBiegel,QuintenDavidSoetens,WilliHornig,StephanDiehl,andSerge
Demeyer. 2011. Comparison ofSimilarityMetricsfor RefactoringDetection.In
Proceedings of the 8th Working Conference on Mining Software Repositories (MSR
’11). ACM, New York, NY, USA, 53–62. https://doi.org/10.1145/1985441.1985452
[9]Jim Buckley, Tom Mens, Matthias Zenger, Awais Rashid, and Günter Kniesel.
2005. TowardsaTaxonomyofSoftwareChange. JournalofSoftwareMaintenance
and Evolution:Research and Practice 17, 5(Sept. 2005), 309–332. https://doi.org/
10.1002/smr.v17:5
[10]Apache Cassandra. 2018. Mirror of Apache Cassandra. (2018). https://github.
com/apache/cassandra/commit/446e2537895c15b404a74107069a12f3fc404b15#
diff-8d5005607847694afae01a22fa8fdbce
[11]OscarChaparro,GabrieleBavota,AndrianMarcus,andMassimilianoDiPenta.
2014. On the Impact of Refactoring Operations on Code Quality Metrics. In
Proceedings of the 2014 IEEE International Conference on Software Maintenance
and Evolution (ICSME ’14) . IEEE Computer Society, Washington, DC, USA, 456–
460. https://doi.org/10.1109/ICSME.2014.73
[12]DanielAlencardaCosta,ShaneMcIntosh,WeiyiShang,UiráKulesza,Roberta
Coelho,andAhmedHassan.2017. AFrameworkforEvaluatingtheResultsof
the SZZApproach forIdentifyingBug-IntroducingChanges. IEEETransactions
on Software Engineering 43, 7 (July 2017), 641–657. https://doi.org/10.1109/TSE.
2016.2616306
[13]Steven Davies, Marc Roper, and Murray Wood. 2014. Comparing text-based and
dependence-based approaches for determining the origins of bugs. Journal of
Software:Evolution andProcess 26,1 (2014),107–139. https://doi.org/10.1002/smr.
1619
[14]Eclipse Deeplearning4J. 2018. Deep Learning for Java, Scala & Clo-jure on Hadoop & Spark. (2018). https://github.com/deeplearning4j/
deeplearning4j/commit/91cdfa1ffd937a4cb01cdc0052874ef7831955e2#
diff-367fe3c8ca7846530b2d0562b3b83324R61
[15]SergeDemeyer, Stéphane Ducasse, and Oscar Nierstrasz. 2000. Finding Refac-
torings via Change Metrics. In Proceedings of the 15th ACM SIGPLAN Conference
on Object-oriented Programming, Systems, Languages, and Applications (OOPSLA
’00). ACM, New York, NY, USA, 166–177. https://doi.org/10.1145/353171.353183
[16]Martín Dias, Alberto Bacchelli, Georgios Gousios, Damien Cassou, and Stéphane
Ducasse. 2015. Untangling fine-grained code changes. In Proceedings of the IEEE
22nd International Conference on Software Analysis, Evolution, and Reengineering
(SANER ’15) . 341–350. https://doi.org/10.1109/SANER.2015.7081844
[17]DanielDig.2007. AutomatedUpgradingofComponent-basedApplications . Ph.D.
Dissertation. University of Illinois at Urbana-Champaign, Champaign, IL, USA.
[18]DannyDig,CanComertoglu,DarkoMarinov,andRalphJohnson.2006. Auto-
mated Detection of Refactorings in Evolving Components. In Proceedings of the
20thEuropeanConferenceonObject-OrientedProgramming(ECOOP’06) .Springer-
Verlag, Berlin, Heidelberg, 404–428. https://doi.org/10.1007/11785477_24
[19]Danny Dig, William G. Griswold, Emerson Murphy-Hill, and Max Schäfer. 2014.
TheFutureofRefactoring(DagstuhlSeminar14211). DagstuhlReports 4,5(2014),40–67. https://doi.org/10.4230/DagRep.4.5.40
[20]DannyDigandRalphJohnson.2006.HowDoAPIsEvolve?AStoryofRefactoring.JournalofSoftwareMaintenanceandEvolution:ResearchandPractice 18,2(March
2006), 83–107. https://doi.org/10.1002/smr.v18:2
[21]Danny Dig, Kashif Manzoor, Ralph E. Johnson, and Tien N. Nguyen. 2008.Effective Software Merging in the Presence of Object-Oriented Refactorings.IEEE Transactions on Software Engineering 34, 3 (May 2008), 321–335. https:
//doi.org/10.1109/TSE.2008.29
[22]Kecia A.M. Ferreira, Mariza A.S. Bigonha, Roberto S. Bigonha, Luiz F.O. Mendes,
and Heitor C. Almeida. 2012. Identifying thresholds for object-oriented software
metrics.JournalofSystemsandSoftware 85,2(2012),244–257. https://doi.org/10.
1016/j.jss.2011.05.044 Special issue with selected papers from the 23rd Brazilian
Symposium on Software Engineering.
[23]Beat Fluri, Michael Würsch, Martin Pinzger, and Harald Gall. 2007. Change
Distilling:TreeDifferencingforFine-GrainedSourceCodeChangeExtraction.
IEEE Transactions on Software Engineering 33, 11 (Nov. 2007), 725–743. https:
//doi.org/10.1109/TSE.2007.70731
[24]Francesca Arcelli Fontana, Andrea Caracciolo, and Marco Zanoni. 2012. DPB:
A Benchmark for Design Pattern Detection Tools. In Proceedings of the 16th
European Conference on Software Maintenance and Reengineering (CSMR ’12) .
235–244. https://doi.org/10.1109/CSMR.2012.32
[25]Francesca Arcelli Fontana, Vincenzo Ferme, Marco Zanoni, and Aiko Yamashita.
2015. Automatic Metric Thresholds Derivation for Code Smell Detection. In
ProceedingsoftheSixthInternationalWorkshoponEmergingTrendsinSoftware
Metrics(WETSoM’15) .IEEEPress,Piscataway,NJ,USA,44–53. http://dl.acm.org/
citation.cfm?id=2821491.2821501
[26]Francesca Arcelli Fontana, Mika V. Mäntylä, Marco Zanoni, and AlessandroMarino. 2016. Comparing and Experimenting Machine Learning Techniques
for Code Smell Detection. Empirical Software Engineering 21, 3 (June 2016),
1143–1191. https://doi.org/10.1007/s10664-015-9378-4
[27]StephenR. Foster,William G. Griswold, and SorinLerner.2012. WitchDoctor:IDE support for real-time auto-completion of refactorings. In Proceedings of
the 34th International Conference on Software Engineering (ICSE ’12) . 222–232.
https://doi.org/10.1109/ICSE.2012.6227191
[28]MartinFowler.1999. Refactoring:ImprovingtheDesignofExistingCode . Addison-
Wesley, Boston, MA, USA.
[29]Martin Fowler. 2005. Fluent Interface. (2005). https://martinfowler.com/bliki/
FluentInterface.html
[30]LajosJenőFülöp,RudolfFerenc,andTiborGyimóthy.2008.TowardsaBenchmark
forEvaluatingDesignPatternMinerTools.In Proceedingsofthe12thEuropean
Conference on Software Maintenance and Reengineering (CSMR ’08) . 143–152.
https://doi.org/10.1109/CSMR.2008.4493309
[31]Xi Ge, Quinton L. DuBose, and Emerson Murphy-Hill. 2012. Reconciling Manual
andAutomaticRefactoring.In Proceedingsofthe34thInternationalConference
on Software Engineering (ICSE ’12) . IEEE Press, Piscataway, NJ, USA, 211–221.
http://dl.acm.org/citation.cfm?id=2337223.2337249
[32]Xi Ge and Emerson Murphy-Hill. 2014. Manual Refactoring Changes with
AutomatedRefactoringValidation.In Proceedingsofthe36thInternationalCon-
ference on Software Engineering (ICSE ’14) . ACM, New York, NY, USA, 1095–1105.
https://doi.org/10.1145/2568225.2568280
[33]XiGe,SaurabhSarkar,andEmersonMurphy-Hill.2014. TowardsRefactoring-
aware Code Review. In Proceedings of the 7th International Workshop on Coopera-
tiveandHumanAspectsofSoftwareEngineering(CHASE’14) .ACM,NewYork,
NY, USA, 99–102. https://doi.org/10.1145/2593702.2593706
[34]Xi Ge, Saurabh Sarkar, Jim Witschey, and Emerson Murphy-Hill. 2017.Refactoring-Aware Code Review. In Proceedings of the IEEE Symposium on Vi-
sual Languages and Human-Centric Computing (VL/HCC ’17) . 71–79. https:
//doi.org/10.1109/VLHCC.2017.8103453
[35]MichaelW.GodfreyandLijieZou.2005. UsingOriginAnalysistoDetectMerging
and Splitting of Source Code Entities. IEEE Transactions on Software Engineering
31, 2 (2005), 166–181. https://doi.org/10.1109/TSE.2005.28
[36]CarstenGörgandPeterWeissgerber.2005. Detectingandvisualizingrefactorings
from software archives. In Proceedings of the 13th International Workshop on
Program Comprehension (IWPC ’05) . 205–214. https://doi.org/10.1109/WPC.2005.
18
[37]William G. Griswold. 1992. Program Restructuring As an Aid to Software Mainte-
nance. Ph.D. Dissertation. Seattle, WA, USA.
[38]Hazelcast. 2018. Open Source In-Memory Data Grid. (2018). https://github.
com/hazelcast/hazelcast/commit/76d7f5e3fe4eb41b383c1d884bc1217b9fa7192e#
diff-17f53e9abe4ccd40013a293698fa234dL143
[39]Péter Hegedűs, István Kádár, Rudolf Ferenc, and Tibor Gyimóthy. 2017. Em-pirical Evaluation of Software Maintainability Based on a Manually Validated
Refactoring Dataset. Information and Software Technology (Nov. 2017). https:
//doi.org/10.1016/j.infsof.2017.11.012 Accepted, to appear.
[40]Johannes Henkel and Amer Diwan. 2005. CatchUp!: capturing and replaying
refactoringstosupportAPIevolution.In 27thInternationalConferenceonSoftware
Engineering . 274–283. https://doi.org/10.1145/1062455.1062512
493
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. ICSE ’18, May 27-June3, 2018, Gothenburg, Sweden N. Tsantalis et al.
[41]Eclipse Jetty. 2018. Web Container & Clients. (2018). https://github.com/
eclipse/jetty.project/commit/1f3be625e62f44d929c01f6574678eea05754474#
diff-ff02a462f6cc50644669e515c691229dR580
[42]István Kádár, Péter Hegedűs, Rudolf Ferenc, and Tibor Gyimóthy. 2016. A Manu-
ally Validated Code Refactoring Dataset and Its Assessment Regarding Software
Maintainability. In Proceedings of the 12th International Conference on Predictive
Models and Data Analytics in Software Engineering (PROMISE ’16) . ACM, New
York, NY, USA, Article 10, 4 pages. https://doi.org/10.1145/2972958.2972962
[43]Toshihiro Kamiya, Shinji Kusumoto, and Katsuro Inoue. 2002. CCFinder: A
MultilinguisticToken-basedCodeCloneDetectionSystemforLargeScaleSource
Code.IEEE Transactions on Software Engineering 28, 7 (July 2002), 654–670.
https://doi.org/10.1109/TSE.2002.1019480
[44]David Kawrykow and Martin P. Robillard. 2011. Non-essential Changes in
Version Histories. In Proceedings of the 33rd International Conference on Software
Engineering(ICSE’11) .ACM,NewYork,NY,USA,351–360. https://doi.org/10.
1145/1985793.1985842
[45]Miryung Kim, Dongxiang Cai, and Sunghun Kim. 2011. An Empirical Investi-gation into the Role of API-level Refactorings During Software Evolution. In
Proceedingsofthe33rdInternationalConferenceonSoftwareEngineering(ICSE’11) .
ACM, New York, NY, USA, 151–160. https://doi.org/10.1145/1985793.1985815
[46]Miryung Kim, Matthew Gee, Alex Loh, and Napol Rachatasumrit. 2010. Ref-
Finder: A Refactoring Reconstruction Tool Based on Logic Query Templates. In
Proceedingsofthe18thACMSIGSOFTInternationalSymposiumonFoundations
of Software Engineering (FSE ’10) . ACM, New York, NY, USA, 371–372. https:
//doi.org/10.1145/1882291.1882353
[47]Sunghun Kim, Thomas Zimmermann, Kai Pan, and E. James Jr. Whitehead. 2006.
Automatic Identification of Bug-Introducing Changes. In Proceedings of the 21st
IEEE/ACM International Conference on Automated Software Engineering (ASE ’06) .
IEEEComputerSociety,Washington,DC,USA,81–90. https://doi.org/10.1109/
ASE.2006.23
[48]Günter Kniesel and Alexander Binun. 2009. Standing on the shoulders of giants -
A data fusion approach to design pattern detection. In Proceedings of the IEEE
17th International Conference on Program Comprehension (ICPC ’09) . 208–217.
https://doi.org/10.1109/ICPC.2009.5090044
[49]Grzegorz Kondrak. 2005. N-gram Similarity and Distance. In Proceedings of
the12thInternationalConferenceonStringProcessingandInformationRetrieval
(SPIRE’05) . Springer-Verlag, Berlin, Heidelberg, 115–126. https://doi.org/10.1007/
11575832_13
[50]Vladimir I. Levenshtein. 1966. Binary codes capable of correcting deletions,
insertions, and reversals. Soviet Physics Doklady 10, 8 (1966), 707–710.
[51]AnasMahmoudandNanNiu.2013.Supportingrequirementstraceabilitythroughrefactoring.In Proceedingsofthe21stIEEEInternationalRequirementsEngineering
Conference (RE ’13) . 32–41. https://doi.org/10.1109/RE.2013.6636703
[52]AnasMahmoudandNanNiu.2014. SupportingRequirementstoCodeTraceabil-
ityThroughRefactoring. RequirementsEngineering 19,3(Sept2014),309–329.
https://doi.org/10.1007/s00766-013-0197-0
[53]Matin Mansouri. 2018. Refactoring Benchmark. (2018). https://github.com/
MatinMan/RefactoringBenchmark
[54]Laura Moreno, Gabriele Bavota, Massimiliano Di Penta, Rocco Oliveto, Andrian
Marcus,andGerardo Canfora.2017. ARENA: AnApproachfortheAutomated
Generation of Release Notes. IEEE Transactions on Software Engineering 43, 2
(Feb 2017), 106–127. https://doi.org/10.1109/TSE.2016.2591536
[55]Emerson Murphy-Hill, Chris Parnin, and Andrew P. Black. 2012. How We
Refactor, and How We Know It. IEEE Transactions on Software Engineering 38, 1
(Jan 2012), 5–18. https://doi.org/10.1109/TSE.2011.41
[56]Stas Negara, Nicholas Chen, Mohsen Vakilian, Ralph E. Johnson, and DannyDig. 2013. A Comparative Study of Manual and Automated Refactorings. In
Proceedings of the 27th European Conference on Object-Oriented Programming
(ECOOP’13) . Springer-Verlag, Berlin, Heidelberg, 552–576. https://doi.org/10.
1007/978-3-642-39038-8_23
[57]Stas Negara, Mohsen Vakilian, Nicholas Chen, Ralph E. Johnson, and Danny Dig.
2012. Is It Dangerous to Use Version Control Histories to Study Source Code
Evolution?. In Proceedings of the 26th European Conference on Object-Oriented
Programming (ECOOP’12) . Springer-Verlag, Berlin, Heidelberg, 79–103. https:
//doi.org/10.1007/978-3-642-31057-7_5
[58]Neo4j. 2018. Graphs for Everyone. (2018). https://github.com/neo4j/neo4j/commit/f6f87f7d5c5d3987db45db7845d221d7abc33146#
diff-0694c9de7c6c3b2738144757b771b751L441
[59]PalomaOliveira,MarcoTulioValente,andFernandoPaimLima.2014. Extracting
relative thresholds for source code metrics. In Proceedings of the IEEE Conference
on Software Maintenance, Reengineering, and Reverse Engineering (CSMR-WCRE
’14). 254–263. https://doi.org/10.1109/CSMR-WCRE.2014.6747177
[60]WilliamF.Opdyke.1992. RefactoringObject-orientedFrameworks . Ph.D.Disserta-
tion. Champaign, IL, USA.
[61]FabioPalomba,AndyZaidman,RoccoOliveto,andAndreaDeLucia.2017. An
Exploratory Study on the Relationship Between Changes and Refactoring. In
Proceedings of the 25th International Conference on Program Comprehension (ICPC’17). IEEE Press, Piscataway, NJ, USA, 176–185. https://doi.org/10.1109/ICPC.
2017.38
[62]KylePrete,NapolRachatasumrit,NikitaSudan,andMiryungKim.2010.Template-
based reconstruction of complex refactorings. In Proceedings of the 26th IEEE
InternationalConferenceonSoftwareMaintenance(ICSM’10) .1–10. https://doi.
org/10.1109/ICSM.2010.5609577
[63]NapolRachatasumritandMiryungKim.2012. Anempiricalinvestigationinto
theimpactofrefactoringonregressiontesting.In Proceedingsofthe28thIEEE
International Conference on Software Maintenance (ICSM ’12) . 357–366. https:
//doi.org/10.1109/ICSM.2012.6405293
[64]Danilo Silva, Nikolaos Tsantalis, and Marco Tulio Valente. 2016. Why We Refac-
tor?ConfessionsofGitHubContributors.In Proceedingsofthe24thACMSIGSOFT
International Symposium on Foundations of Software Engineering (FSE ’16) . ACM,
New York, NY, USA, 858–870. https://doi.org/10.1145/2950290.2950305
[65]DaniloSilvaandMarcoTulioValente.2017. RefDiff:DetectingRefactoringsin
VersionHistories.In Proceedingsofthe14thInternationalConferenceonMining
Software Repositories (MSR ’17) . IEEE Press, Piscataway, NJ, USA, 269–279. https:
//doi.org/10.1109/MSR.2017.14
[66]Jacek Śliwerski, Thomas Zimmermann, and Andreas Zeller. 2005. When Do
Changes Induce Fixes?. In Proceedings of the 2005 International Workshop on
Mining Software Repositories (MSR ’05) . ACM, New York, NY, USA, 1–5. https:
//doi.org/10.1145/1082983.1083147
[67]Gustavo Soares, Rohit Gheyi, Emerson Murphy-Hill, and Brittany Johnson. 2013.
ComparingApproachestoAnalyzeRefactoringActivityonSoftwareRepositories.
JournalofSystemsandSoftware 86,4(Apr2013),1006–1022. https://doi.org/10.
1016/j.jss.2012.10.040
[68]QuintenDavidSoetens,JavierPérez,SergeDemeyer,andAndyZaidman.2015.
CircumventingRefactoringMaskingUsingFine-grainedChangeRecording.In
Proceedings of the 14th International Workshop on Principles of Software Evolution
(IWPSE 2015) . ACM, New York, NY, USA, 9–18. https://doi.org/10.1145/2804360.
2804362
[69]Nikolaos Tsantalis. 2018. RefactoringMiner. (2018). https://github.com/tsantalis/
RefactoringMiner
[70]Nikolaos Tsantalis, Matin Mansouri, Laleh Eshkevari, and Davood Mazinanian.
2018. Refactoring Oracle. (2018). http://refactoring.encs.concordia.ca/oracle/
[71]Michele Tufano, Fabio Palomba, Gabriele Bavota, Massimiliano Di Penta, Rocco
Oliveto,AndreaDeLucia,andDenysPoshyvanyk.2017. Thereandbackagain:
Can you compile that snapshot? Journal of Software: Evolution and Process 29, 4
(2017). https://doi.org/10.1002/smr.1838
[72]Arie van Deursen, Leon Moonen, Alex Bergh, and Gerard Kok. 2001. Refac-
toringTestCode.In Proceedingsofthe2ndInternationalConferenceonExtreme
Programming and Flexible Processes in Software Engineering (XP 2001) . 92–95.
[73]PeterWeissgerberandStephanDiehl.2006. AreRefactoringsLessError-prone
ThanOtherChanges?.In Proceedingsofthe2006InternationalWorkshoponMining
Software Repositories (MSR ’06) . ACM, New York, NY, USA, 112–118. https:
//doi.org/10.1145/1137983.1138011
[74]PeterWeissgerberandStephanDiehl.2006. IdentifyingRefactoringsfromSource-
CodeChanges.In Proceedingsofthe21stIEEE/ACMInternationalConferenceon
Automated Software Engineering (ASE ’06) . 231–240. https://doi.org/10.1109/ASE.
2006.41
[75]ChrisK.Wensel.2018. Cascading. (2018). https://github.com/cwensel/cascading/
commit/f9d3171f5020da5c359cdda28ef05172e858c464
[76]ChaddWilliamsandJaimeSpacco.2008. SZZRevisited:VerifyingwhenChanges
Induce Fixes. In Proceedings of the 2008 Workshop on Defects in Large Software
Systems (DEFECTS ’08) . ACM, New York, NY, USA, 32–36. https://doi.org/10.
1145/1390817.1390826
[77]Zhenchang Xing and Eleni Stroulia.2005. UMLDiff:An Algorithm for Object-
oriented Design Differencing. In Proceedings of the 20th IEEE/ACM International
ConferenceonAutomatedSoftwareEngineering(ASE’05) .ACM,NewYork,NY,
USA, 54–65. https://doi.org/10.1145/1101908.1101919
[78]ZhenchangXingandEleniStroulia.2006. RefactoringDetectionBasedonUMLD-iffChange-FactsQueries.In Proceedingsofthe13thWorkingConferenceonReverse
Engineering(WCRE’06) .IEEEComputerSociety,Washington,DC,USA,263–274.
https://doi.org/10.1109/WCRE.2006.48
[79]Zhenchang Xing and Eleni Stroulia. 2007. API-Evolution Support with Diff-
CatchUp. IEEETransactions on Software Engineering 33, 12 (Dec 2007), 818–836.
https://doi.org/10.1109/TSE.2007.70747
[80]Zhenchang Xing and Eleni Stroulia. 2008. The JDEvAn Tool Suite in Support of
Object-orientedEvolutionaryDevelopment.In Companionofthe30thInterna-
tionalConferenceonSoftwareEngineering(ICSECompanion’08) .ACM,NewYork,
NY, USA, 951–952. https://doi.org/10.1145/1370175.1370203
494
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 10:53:28 UTC from IEEE Xplore.  Restrictions apply. 