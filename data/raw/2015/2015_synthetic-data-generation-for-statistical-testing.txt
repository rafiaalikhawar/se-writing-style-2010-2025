Synthetic Data Generation for Statistical Testing
Ghanem Soltana, Mehrdad Sabetzadeh, and Lionel C. Briand
SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg
Email: {ghanem.soltana, mehrdad.sabetzadeh, lionel.briand}@uni.lu
Abstract ‚ÄîUsage-based statistical testing employs knowledge
about the actual or anticipated usage proÔ¨Åle of the system under
test for estimating system reliability. For many systems, usage-
based statistical testing involves generating synthetic test data.
Such data must possess the same statistical characteristics as
the actual data that the system will process during operation.Synthetic test data must further satisfy any logical validity con-
straints that the actual data is subject to. Targeting data-intensive
systems, we propose an approach for generating synthetic testdata that is both statistically representative and logically valid.
The approach works by Ô¨Årst generating a data sample that meets
the desired statistical characteristics, without taking into accountthe logical constraints. Subsequently, the approach tweaks the
generated sample to Ô¨Åx any logical constraint violations. The
tweaking process is iterative and continuously guided towardachieving the desired statistical characteristics. We report on
a realistic evaluation of the approach, where we generate a
synthetic population of citizens‚Äô records for testing a public
administration IT system. Results suggest that our approach is
scalable and capable of simultaneously fulÔ¨Ålling the statisticalrepresentativeness and logical validity requirements.
Index Terms‚ÄîTest Data Generation, Usage-based Statistical
Testing, Model-Driven Engineering, UML, OCL.
I. I NTRODUCTION
Usage-based statistical testing, or statistical testing for short,
is concerned with detecting faults that cause the most frequent
failures (thus affecting reliability the most), and with estimat-ing reliability via statistical models [1]. In contrast to testingtechniques that focus on system veriÔ¨Åcation (fault detection),e.g., testing driven by code coverage, statistical testing focuseson system validation from the perspective of users. Statisticaltesting typically requires a usage proÔ¨Åle of the system under
test. This proÔ¨Åle characterizes, often through a probabilisticformalism, the population of the system‚Äôs usage scenarios [2].
Existing work on usage proÔ¨Åles has focused on state- and
event-based systems, with the majority of the work beingbased on Markov chains [3], [4], [5], [6], [7], [8]. For manysystems, which we refer to as data-centric and concentrate on
in this paper, system behaviors are driven primarily by data,rather than being triggered by stimuli. For example, consider apublic administration system that calculates social beneÔ¨Åts forcitizens. How such a system behaves is determined mainly bycomplex and interdependent data such as citizens‚Äô employmentand household makeup. The system‚Äôs scenarios of use are thusintimately related to the data that is processed by the system.Consequently, the usage proÔ¨Åle of such a system is governedby the statistical characteristics of the system‚Äôs input data,or stated otherwise, by the system‚Äôs data proÔ¨Åle. Given our
focus on data-centric systems and the explanation above, weequate, for the purposes of this paper, ‚Äúusage proÔ¨Åle‚Äù and ‚ÄúdataproÔ¨Åle‚Äù, and use the latter term hereafter.
When actual data, e.g., real citizens‚Äô records in the afore-
mentioned example, is available, one may be able to performstatistical testing without a data proÔ¨Åle. In most cases, how-ever, gaps exist in actual data, since new and retroÔ¨Åt systemsmay require data beyond what has been recorded in the past.These gaps need to be Ô¨Ålled with synthetic data. To generate
synthetic data that is representative and thus suitable for sta-tistical testing, a proÔ¨Åle of the missing data will be required.
Further, and perhaps more importantly, synthetic data (and
hence a data proÔ¨Åle) are indispensable when access to actualdata is restricted. Notably, under most privacy regulations, e.g.,EU‚Äôs General Data Protection Regulation [9], ‚Äúrepurposing‚Äùof personal data is prohibited without explicit consent. Thiscomplicates sharing of any actual personal data with third-parties who are responsible for software development and test-ing. Anonymization offers a partial solution to this problem;however, doing so often comes at the cost of reduced dataquality [10] and proneness to deanonymization attacks [11].
Data proÔ¨Åles have received little attention in the literature on
software testing. This is despite the fact that many data-centricsystems, e.g., public administration and Ô¨Ånancial systems, aresubject to reliability requirements and thus statistical testing.Recently, we proposed a statistical data proÔ¨Åle and a heuristicalgorithm for generating representative synthetic data [12].
Although motivated by microeconomic simulation [13] rather
than software testing, our previous approach provides a usefulbasis for generating data that can be used for statistical testing.However, the approach suffers from an important limitation:while the approach generates synthetic data that is alignedwith a desired set of statistical distributions and has shownto be good enough for running Ô¨Ånancial simulations [14],the approach cannot guarantee the satisfaction of logical
constraints that need to be enforced over the generated data.
To illustrate, we note three among several other logical
anomalies that we observed when using our previous approach[12] for generating test cases based on a data proÔ¨Åle ofcitizens‚Äô records: children who were older than their par-ents, individuals who were married before being born, andindividuals who were classiÔ¨Åed as widower without everhaving been married. Without the ability to enforce logicalconstraints to avoid such anomalies, the generated data isunsuitable for statistical testing and estimating reliability. Thisis because such anomalies may result in exceptions or systembehaviors that are not meaningful. In either case, targetedsystem behaviors will not be exercised.
978-1-5386-2684-9/17/$31.00 c/circlecopyrt2017 IEEEASE 2017, Urbana-Champaign, IL, USA
T echnical Research872
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. The question that we investigate in this paper is as follows:
Can we generate synthetic test data that is both statistically
representative and logically valid? The key challenge we
need to address when tackling this question is scalability.
SpeciÔ¨Åcally, to obtain statistical representativeness, we need
to construct a large data sample (test suite), potentially with
hundreds orthousands of members. At the same time, this
large sample has to satisfy logical constraints, meaning that weneed to apply computationally-expensive constraint solving.
Contributions. The contributions of this paper are as follows:
1) We develop a model-based test data generator that can
simultaneously satisfy statistical representativeness and logi-cal validity requirements over complex, interdependent data.The desired statistical characteristics are expressed usingour previously-developed probabilistic UML annotations [12].V alidity constraints are expressed using UML ‚Äôs constraintlanguage, OCL [15]. Our data generator incorporates twocollaborating components: (a) a search-based OCL constraintsolver which enhances previous work by Ali et al. [16], and(b) a mechanism that guides the solver toward satisfying thestatistical characteristics that the generated data (test suite)must exhibit.
2) We evaluate our data generator through a realistic case
study, where synthetic data is required for statistical testingof a public administration IT system in Luxembourg. Ourresults suggest that our data generator can create, in practicaltime, test data that is sound, i.e., satisÔ¨Åes the necessary validity
constraints, and at the same time, is closely aligned with the
desired statistical characteristics.
II. B
ACKGROUND
In this section, we brieÔ¨Çy describe our previous data genera-
tion approach [12]. We leverage this approach for (1) express-ing the desired statistical characteristics of data, and (2) gener-ating initial data samples which we process further to achievenot only representativeness but logical validity as well.
For specifying statistical characteristics, we use a set of
annotations (stereotypes) which can be attached to a data
schema expressed as a UML Class Diagram. Fig. 1 illustratessome of these annotations on a small excerpt of a data schema
for a tax administration system.
The ¬´probabilistic type¬ª stereotypes applied to the special-
izations of the TaxPayer class state that ‚âà78% of the taxpayers
should be resident and the remainder should be non-resident.
The ¬´from histogram¬ª stereotype attached to the birth_year
attribute provides, via a histogram, the birth year distributionfor taxpayers. The attribute birth_year is further annotated
with a conditional probability speciÔ¨Åed via the ¬´value depen-
dency¬ª stereotype. The details of this conditional probability
are provided by the legal age for pensioners box. The infor-
mation in the box reads as follows: 25% of pensioners havetheir birth year between 1957 and 1960, i.e., are between 57and 60 years old; the remaining 75% are older than 60.
The ¬´multiplicity¬ª stereotype attached to the association
between TaxPayer and Income classes describes, via the in-
come cardinality histogram, the distribution of the number¬´multiplicity¬ª
{constraints: [ income 
cardinality ]}
1 taxpayer incomes 1..* Income   
    income cardinality
- birth_year : Integer¬´from histogram¬ª
{labels: [[1979..1998], [1959..1978], [1934..1958], 
[1900..1933]]; frequencies: [0.7, 0.2, 0.07, 0.03]}
¬´value dependency¬ª
{queries: [dependency age for pensioners]}TaxPayer (abstract)ResidentTaxPayer¬´probabilistic type¬ª
{frequency: 0.7845}
NonResidentTaxPayer¬´probabilistic type¬ª
{frequency: 0.2155}
       
¬´from histogram¬ª 
{labels: [[1957..1960], [1917..1956]];
frequencies: [0.25, 0.75]}Condition: self.incomes-> exists 
(oclIsTypeOf(Pension)) 
   
  dependency age for pensioners
¬´OCL query¬ª
{expressions: [legal age for pensioners ]}legal age for pensioners¬´from histogram¬ª 
{labels: [1, 2, 3, 4]; frequencies: 
[0.8, 0.15, 0.045, 0.005]}
Fig. 1. Data Schema (Excerpt) Annotated with Statistical Characteristics
of incomes per taxpayer. As shown in Fig. 1, 80% of the
taxpayers have one income, 15% have two, and so on.
For generating a data sample, we previously proposed a
heuristic technique that is aimed exclusively at representa-
tiveness [12]. This technique traverses the elements of thedata schema and instantiates them according to the prescribedprobabilities. The technique attempts to satisfy multiplicityconstraints but satisfaction is not guaranteed. More complexlogical constraints are not supported.
In this paper, we use as a starting point the data generated
by our previous approach, and alter this data to make it validwithout compromising representativeness. Indeed, as we showin Section V, our new approach not only results in logicallyvalid data but also outperforms our previous approach in termsof representativeness.
III. A
PPROACH OVERVIEW
Fig. 2 presents an overview of our approach for generating
representative and valid test data. Steps 1‚Äì3 are manual and
Step 4 is automatic. In Step 1, DeÔ¨Åne data schema, we deÔ¨Åne
using a UML Class Diagram (CD) [17] the schema of the data
to generate. This diagram, illustrated earlier in Fig. 1, is thebasis for: (a) capturing the desired statistical characteristics ofdata (Step 2), and (b) generating synthetic data (Step 4).
Data  schema
(class diagram) 
 
 
   2. De Ô¨Åne
statistical
characteristicsAnnotated
data schema <<s>>
 
 <<p>>
 <<p>>  <<m>>
3. De Ô¨Åne 
data validity 
constraints Constraints4. Generate 
synthetic data
Synthetic 
data sample
(test suite)OCL1. De Ô¨Åne 
data schema
Data
proÔ¨Åle
Fig. 2. Approach for Generating V alid and Representative Synthetic Data
In Step 2, DeÔ¨Åne statistical characteristics , the CD from
Step 1 is enriched with probabilistic annotations (see Sec-tion II) to express the representativeness requirements thatshould be met during data generation in Step 4. In Step 3,
DeÔ¨Åne data validity constraints, users express via the Object
Constraint Language (OCL) [15] the logical constraints thatthe generated data must satisfy. For example, the followingOCL constraint states that children must be born at least16 years after their parents:
self.children->forAll(c| c.birth_year >
self.birth_year + 16) . Here, self refers to a person.
Steps 2 and 3 of our approach can in principle be done in
parallel. Nevertheless, it is advantageous to perform Step 3
873
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. after Step 2. This is because the probabilistic annotations
of Step 2 may convey some implicit logical constraints. For
example, the annotations of Step 2 may specify a uniform dis-tribution over the month of birth for physical persons. It wouldtherefore be redundant to deÔ¨Åne the following OCL constraint:
self.birth_month >= 1 and self.birth_month <= 12 . Such redundancies
can be avoided by doing Steps 2 and 3 sequentially.
Step 4, Generate synthetic data, generates a data sample
(test suite) based on a data proÔ¨Åle. In our approach, a data
proÔ¨Åle is materialized by the combination of the probabilisticannotations from Step 2 and the OCL constraints for Step 3.As stated earlier, the synthetic data generated in Step 4 mustmeet both the statistical representativeness and logical validityrequirements, respectively speciÔ¨Åed in Steps 2 and 3. Theoutput from Step 4 is a collection of instance models, i.e.,instantiations of the underlying data schema. Each instancemodel characterizes one test case for statistical testing.
In the next section, we elaborate Step 4, which is the main
technical contribution of this paper.
IV . G
ENERA TING SYNTHETIC DATA
In this section, we describe our synthetic data generator.
Fig. 3 shows the strategy employed by the data generator.Initially, a potentially invalid collection of instance models is
created using our previous data generation approach (see Sec-tion II). We refer to this initial collection as the seed sample.
Our data generator then transforms the seed sample into a
collection of valid instance models. This is achieved using acustomized OCL constraint solver, presented in Section IV -A.
The solver attempts to repair the invalid instance models in
the seed sample. To do so, the solver considers the constraintspeciÔ¨Åed in Step 3 of our overall approach (Fig. 2) alongsidethe multiplicity constraints of the underlying data schema andthe constraints implied by the probabilistic annotations fromStep 2 of the approach. The rationale for feeding the solverwith instance models from the seed sample, rather than havingthe solver build instance models from scratch, is based on thefollowing intuitions: (1) By starting from the seed sample, thesolver is more likely to be able to reach valid instance models,and (2) The valid sample built by the solver will not end uptoo far away from being representative, in turn making it easierto Ô¨Åx deviations from representativeness, as we discuss later.
The OCL solver that we use is based on metaheuristic
search. If the solver cannot Ô¨Åx a given instance model within apredeÔ¨Åned maximum number of iterations, the instance modelis discarded. To compensate, the seed sample is extended witha new instance model byre-invoking our previous data genera-tor. This process continues until we obtain the desired numberof valid instance models (test cases). The number of instance
models to generate is an input parameter that is set by users.
Once we have a valid data sample that has the requested
number of instance models in it, our data generator attempts
to realign the sample back with the desired statistical charac-teristics. This is done through an iterative process, delineatedin Fig. 3 with a dashed boundary. We elaborate the details ofthis iterative process in Section IV -B.Create seed 
sample  
Create valid 
sampleSeed sample 
with potential 
logical anomalies
Valid data 
sample All validity constraints 
(user-de Ô¨Åned constraints including 
multiplicity constraints from data schema plus constraints implied by probabilistic annotations)
Generate 
corrective 
constraintsPropose
tweaked
instance modelCorrective constraints 
Tweaked instance modelFinal data 
sample(for each instance model in the sample)OCL
Fig. 3. Overview of our Data Generation Strategy
BrieÔ¨Çy, the process goes in a sequential manner through the
instance models within the valid sample, and subjects these
instance models to additional constraints that are generated
on-the-Ô¨Çy. These additional constraints, which we refer toascorrective constraints, provide cues to the solver as to
how it should tweak an instance model so that the statistical
representativeness of the whole data sample is improved.
For example, let us assume that instance models represent
households in a tax administration system. Now, supposethat the proportion of households with no children is over-represented in the sample. If, under such circumstances, theiterative process is working on a household with no children, a
corrective constraint will be generated stating that the number
of children should be non-zero (in that particular household).The solver will then attempt to satisfy this constraint withoutviolating any of the validity constraints discussed earlier.
If the solver fails to come up with a tweaked household
that satisÔ¨Åes both the corrective constraint and all the validityconstraints at the same time, the original household (which isvalid but has no children) is retained in the sample. Otherwise,that is, when a tweaked and valid household is found, we needto decide whether it is advantageous to replace the originalhousehold by the tweaked one. Let Ibe the original household
and I
/primethe tweaked one. Further, let Sdenote the current
sample containing I(but not I/prime) and letS/prime=(S\{I})‚à™{I/prime}.
The decision is made as follows: If Sis better aligned than S/prime
with the desired statistical characteristics then I/primeis discarded;
otherwise, I/primewill replace Iin the sample. The reason why this
decision is required is because tweaking may have side effects.Therefore, I
/primemay not necessarily improve overall representa-
tiveness, although it does reduce the proportion of householdswith no children. For example, it could be that the solver addssome children to the household in question, but in doing so, italso changes the household allowances. These allowances toomay be subject to representativeness requirements. Withoutthe comparison above, one cannot tell whether the tweakedhousehold is a better Ô¨Åt for representativeness.
In the above scenario, we illustrated the iterative process
using a single corrective constraint. In practice, the processmay generate multiple such constraints, since the data sampleat hand may be deviating from multiple representativenessrequirements. We treat corrective constraints as being soft.
This means that if after the maximum number of iterations,
the solver manages to solve some of the corrective constraintsbut not all, the process will give the tweaked instance model
874
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. a chance to replace the original one as long as the tweaked
instance model still satisÔ¨Åes all the validity constraints.
The rest of this section presents the technical machinery
behind the (customized) OCL solver and our data generator.
A. Solving OCL Constraints
A number of techniques exist for solving OCL constraints,
notably using Alloy [18], [19], constraint programming [20],
and (metaheuristic) search [21], [16]. Alloy often fails to
solve constraints that involve large numbers [22]. We observed
via experience that this limitation could be detrimental inour context. For example, our case study in Section V hasseveral constrained quantities, e.g., incomes and allowances,that are large numbers. As for constraint programming, to ourknowledge, the only publicly-available tool is UML2CSP [20].
We observed that this tool did not scale for our purposes. In
particular, given a time budget of 2 hours, UML2CSP did notproduce any valid instance model in our case study. This is notpractical for statistical testing where we need a representativesample with many (hundreds or more) valid instance models.
Search, as we demonstrate in Section V, is more promising
in our context. Although search-based techniques cannot prove(un)satisÔ¨Åability, they are efÔ¨Åcient at exploring large searchspaces. In our work, we adopt with two customizations thesearch-based OCL solver of Ali et al.‚Äôs [16], hereafter referredto as the baseline solver. The customizations are: (1) a feature
for setting a speciÔ¨Åc instance model as the starting point forsearch, and (2) a strategy to avoid premature narrowing of thesearch space. The former customization, which is straightfor-ward and not discussed here, is necessary for realizing theprocess in Fig. 3. The latter customization is discussed next.
The baseline solver has a Ô¨Åxed heuristic for selecting what
OCL clause to solve next: it favors clauses that are closerto being satisÔ¨Åed based on a Ô¨Åtness function. For example,assume that we want to satisfy constraint C1 deÔ¨Åned as
follows:
if(x=2) then y=5else if (x=3) then y=4else y=0endif endif ,
where xandyare attributes. For the sake of argument, suppose
the solver is processing a candidate solution where x=3
(satisfying the condition of the second nested if statement)andy=7 (not satisfying any clause). This makes the second
nested if statement in C1 the closest to being satisÔ¨Åed. At this
point, the heuristic employed by the solver narrows the searchspace by locking the value of xand starting to exclusively
tweak yin order to satisfy
y=4. Now, if we happen to have
another constraint C2 stating y>4, the solver will fail since x
can no longer be tweaked.
The above heuristic in the baseline solver poses no problem
as long as the goal is to Ô¨Ånd some valid solution. If search fails
from one starting point, the solver (pseudo-)randomly picksanother and starts over. In our context however, starting overfrom an arbitrary point is not an option. For the Ô¨Ånal datasample to have a chance of being aligned with the desiredstatistical characteristics, the solver needs to use as startingpoint instance models from a statistically representative seed
sample (see Fig. 2). If the solver fails at making valid aninstance model from the seed sample, that instance model hasto be discarded. This negatively affects performance, since the
solver will need to start all over on a replacement instancemodel supplied by the seed data generator, as noted earlier.
In a similar vein, if the solver fails at enforcing corrective
constraints over a (valid) instance model, it cannot helpwith improving representativeness. To illustrate, suppose thatconstraint C2 mentioned earlier is a corrective constraint and
that the valid solution (instance model for C1)i sx =3,y=4 .
In such a case, the baseline solver will deterministically failas long as the starting point is this particular valid solution.In other words, C2 will have no effect.
To address the above problem, we customize the baseline
solver as follows: Rather than working directly on the originalconstraints, the customized solver works on the constraints‚Äôprime implicants (PI). An implicant is prime (minimal) ifviolating any of its literals results in the violation of theunderlying constraint. To derive all the PIs for a given OCLconstraint, we Ô¨Årst transform the constraint into a logicalexpression with only ANDs and ORs, negation, and OCLoperations. We next transform this expression into DisjunctiveNormal Form (DNF) by applying De Morgan‚Äôs law [23]. Eachclause of the DNF expression is a PI. For instance, constraintC1 yields three PIs:
(x=2 and y=5),(x<>2 and x=3 and y=4), and
(x<>2 and x<>3 and y=0). Note that we use the term PI slightly
differently than what is standard in logic. Our literals are notnecessarily independent logically. For example, in the secondPI above,
x<>2 is redundant because x=3 implies x<>2 . Such
redundancies pose no problem and are ignored.
For each constraint Cto be solved, the customized solver
randomly picks one of C‚Äôs PIs. For instance, if we want to
solve constraints C1 and C2 together, we would randomly pick
one of C1‚Äôs three PIs alongside C2 (whose only PI is y>4). This
way, we give a chance to all PIs to be considered, thus avoidingthe undesirable situation discussed earlier, where the baselinesolver would (deterministically) lead itself into dead-ends. Forexample, from the PIs of C1, we may pick
(x=2 and y=5).N o w ,
if we start the search at x=3 ,y=7 , the solver will have
a feasible path toward a valid solution, x=2 ,y=5 , which
satisÔ¨Åes both C1 and C2. If a certain combination of randomly-
selected PIs (one PI per constraint) fails, other combinationsare tried until either a solution is found or the maximumnumber of iterations allowed is reached.
Due to space, we cannot present all the details of this
customization. We only make two remarks. First, all OCLoperations are treated as opaque literals when building PIs.For example, the operation
self.navigation‚àí >forAll(x=3 ory=2) is
a single literal, just like, say, x=3. Solving OCL operations
is a recursive process and similar to solving operation-freeexpressions. In particular, to solve OCL operations, we employthe same DNF transformation discussed earlier. For example,to solve
self.navigation‚àí >forAll(x=3 ory=2), we derive two PIs,
x=3 and y=2, and use them to constrain the objects at the
association end that has navigation as role name.
Second, the DNF transformation can result in exponentially
large DNF representations when there are many literals [24].Such exponential explosion is unlikely to arise in our context:
875
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. Manually-written logical constraints for data models typically
include only a handful of literals. For the corrective constraintsthat are generated automatically (through Alg. 2 describedlater), the number of literals is at most as many as thenumber of ranges (or categories) in the bar graphs that capturethe desired statistical distributions. Again, these numbers areseldom very large. In our case study of Section V, the DNFtransformations took negligible time (milliseconds).
To summarize, using PIs instead of the original constraints
helps avoid dead-ends when solution search has to start from
a speciÔ¨Åc point in the search space. In Section V (RQ1), weexamine how customizing the baseline solver in the mannerdescribed in this section inÔ¨Çuences performance.
B. Generating V alid and Representative Data
This section presents the technical details of our data
generation strategy, depicted in Fig. 3 and outlined earlier on.
We already discussed the creation of the seed sample (from ourprevious work [12]) and how we make this sample valid usinga customized OCL solver (Section IV -A). Below, we focus onthe iterative process in Fig. 3, i.e., the region delineated bydashed lines, and present the algorithms behind this process.
We start with some remarks about how we represent
statistical distributions. The instruments we use to this endare barcharts (for categorical quantities) and histograms (for
ordinal and interval quantities). Without loss of generality,
and while we support both notions, we talk exclusively abouthistograms in the text. A histogram is a set of bins. Each bin
is deÔ¨Åned by a label (value or range), and a relative frequency
denoting the proportional abundance of the bin‚Äôs label. We do
not directly handle continuous distributions, e.g., the normaldistribution. Continuous distributions are discretized into his-tograms. Doing so is routine [25] and not explained here. Wenote however that the discretization should not be too Ô¨Åne-grained, e.g., resulting in more than 100 bins. This is becausethe corrective constraints in our approach will get complex,in turn posing scalability issues for the OCL solver, e.g., with
respect to the DNF transformation discussed in Section IV -A.
The PIM algorithm. Alg. 1, Process Instance Model (PIM),
presents the procedure for one iteration of the iterative process
(region within the dashed boundary) in Fig. 3. PIM takes thefollowing as input: (1) a valid data sample, (2) a speciÔ¨Åc
instance model from the sample to process, (3) a set of validityconstraints, (4) the desired statistical characteristics deÔ¨Åned as
histograms, (5) a parameter specifying how many attempts thealgorithm should make to generate tweaked instance models,and (6) a parameter specifying how sensitive the algorithm isto differences in relative frequencies. Essentially, if the differ-
ence between two relative frequencies is below the sensitivity
parameter, the two frequencies are considered equal.
The algorithm works in three stages as we describe next.
1) Generate corrective constraints (L. 1-3 of Alg. 1): In this
stage, PIM calls another algorithm GCC (Alg. 2, describedlater). GCC generates corrective constraints for the instance
model being processed (L. 1). For example, assume thatthe instance model is a pensioner, and that pensioners areAlg. 1: Process Instance Model (PIM)
Inputs : (1) a set Sof valid instance models; (2) an instance model
inst‚ààS to process; (3) a set Vof validity constraints;
(4) a set Hdesired of desired statistical characteristics
(expressed as histograms); (5) a parameter nb_attempts
denoting the number of times that the solver will be
invoked over inst to create tweaked instance models; (6) a
parameter freq_sensitivity ‚àà[0..1] denoting the margin
beyond which two relative frequencies are deemed far apart.
/*freq_sensitivity is used only for invoking GCC (Alg. 2). */
Output : Either inst or a tweaked instance model, whichever leads to
a more representative data sample.
Fun. calls: GCC: generates corrective constraints (Alg. 2);solve: invokes the customized solver (see Section IV -A).
1CC ‚Üê GCC(S ,inst,Hdesired ,freq_sensitivity)
/*CC is the set of corrective constraints returned by Alg. 2. */
2if(CC=‚àÖ)then
3 return inst
4T‚Üê ‚àÖ /*Twill store potential replacements for inst.* /
5i‚Üê 0/*iis the number of times the solver has been invoked so far . */
6while (i<nb_attempts) do
7 inst_tweaked ‚Üêsolve(inst, V‚à™C C )
8 i‚Üêi+1
9 if(inst_tweaked satisÔ¨Åes the constraints in V)then
10T‚Üê T‚à™ {inst_tweaked}
11inst_best ‚Üêinst
12Sbest‚ÜêS
13foreach candidate ‚ààT do
14S/prime‚Üê(S\{ inst})‚à™{candidate}
15 if(S/primeis better aligned with Hdesired thanSbest)then
16 inst_best ‚Üêcandidate
17Sbest‚ÜêS/prime
18return inst_best
currently over-represented in the data sample. In response,
GCC will generate the following corrective constraint, namedCC1:
self.incomes->forAll(not oclIsTypeOf(Pension)) . If GCC does
not yield any corrective constraints, then the original instance
model will be retained in the sample (L. 2-3).
2) Build tweaked instance models (L. 4-10 of Alg. 1): In this
stage, PIM attempts to produce a set of tweaked instance mod-
els based on the corrective constraints generated previously.These constraints are fed to the solver alongside the validityconstraints (L. 7). To illustrate, consider the example correctiveconstraint CC1 generated at the Ô¨Årst stage. This constraint
instructs the solver to tweak the instance model at hand so
that the income type will no longer be pension. PIM tries
building tweaked instance models multiple times (L. 6). Thisis intended at coming up with multiple candidates (ideallymore than one) for replacing the original instance model in
the sample. As noted earlier, we treat corrective constraints assoft and try to satisfy them on a best-effort basis. Therefore,any tweaked instance model returned by the solver will be
included in the set of candidate replacements as long as thevalidity constraints hold (L. 9-10).
3) Select best replacement (L. 11-18 of Alg. 1): In this stage,
PIM chooses to either retain the original instance model or
replace it with one of the tweaked instance models computedin the second stage. The criterion applied for the decision iswhich instance model, once incorporated into the sample, willresult in the most statistically representative sample.
The metric we use for measuring statistical representa-
tiveness is Euclidean distance [26]. This metric measures
876
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. how far two histograms are from one another. The closer
the distance between two histograms is to zero, the betteraligned the histograms are. For example, suppose that the datasample is composed of 40% resident versus 60% non-residenttaxpayers. As showed in the data schema excerpt in Fig. 1,the desired distribution is ‚âà78% resident versus ‚âà22% non-
resident. The Euclidean distance between the data sample and
the desired distribution is ‚âà0.55, indicating that the sample
is not representative. Since PIM needs to take into account
several distributions simultaneously, it uses the average of theEuclidean distances computed for all the histograms.
We next describe the GCC algorithm that PIM calls (on L. 1
of Alg. 1) for generating corrective constraints.
The GCC algorithm. Given an instance model inst within a
data sample S, Alg 2., titled Generate Corrective Constraints
(GCC), provides suggestions (in the form of constraints)
as to how inst can be tweaked so that Swill become a
more representative sample. The input to GCC was describedpreviously as part of PIM‚Äôs input. GCC works in three stagesas explained below. Throughout the explanation, we will bereferring to Table I, Table II and Fig. 4 for illustration.
1) Generate OCL literals (L. 1-18 of Alg. 2): In this stage,
GCC groups histograms that annotate the same data schema
element, i.e., class, attribute or association, as illustrated inFig. 1 (L. 4-11). For each group, sets OandUwill be built
(L. 12-18). These two sets contain OCL literals for Over-
represented and Under-represented histogram bins, respec-
tively. These literals will later be assembled into intermediateconstraints (see second stage below).
The literals in OandUare derived as follows: We com-
pare in a pairwise manner the relative frequencies of theactual characteristics of Sagainst the desired characteristics
inH
desired (L. 13-15). To illustrate, consider rows 2 and 3
of Table I. The relative frequencies to compare are F1
against D1,F2against D2, and so on. If for an index i,
|Fi‚àíDi|>freq_sensitivity (L. 15), the algorithm will
generate a literal. Whether an exclusion or inclusion literal
is generated depends on whether the underlying bin is over-or under-represented (L. 16-18). For example, in Table I, thedifference between F1andD1is|0.9‚àí0.7|=0.2, which is
larger than the (user-provided) freq_sensitivity value on row 4
of Table I. Since F1is over-represented, the following literal
is added to Oin order to exclude L1:
TaxPayer.allInstances()-
>select(id = 1)->forAll( not (birth_year >= 1979 and birth_year <= 1998)) .
Note that the generated literal targets the speciÔ¨Åc instancemodel being processed, since ultimately, the literal is intendedat tweaking that particular instance model. The case for under-representation is dual and not illustrated.
2) Combine literals (L. 19-21 of Alg. 2): In the second stage,
the algorithm combines the literals in OandUinto what we
call an intermediate constraint. We use the term ‚Äúintermediate‚Äù
to distinguish the output of this stage from the Ô¨Ånal corrective
constraint built in the next (third) stage of the algorithm,described later. In particular, in the Ô¨Ånal corrective constraint,we have to account for the fact that some histograms applyonly under certain conditions. For example, histogram H2onAlg. 2: Generate Corrective Constraints (GCC)
Inputs : (1) a set Sof valid instance models; (2) an instance model
inst‚ààS for which corrective constraints should be
generated; (3) a set Hdesired of desired statistical
characteristics (expressed as histograms); (4) a parameter
freq_sensitivity ‚àà[0..1] denoting the margin beyond which
two relative frequencies are deemed far apart.
Output : A setCC of corrective constraints for inst.
Fun. calls: includeBin (resp. excludeBin): generates an OCL literal
prescribing the inclusion (resp. exclusion) of a speciÔ¨Åchistogram bin.
1CC ‚Üê‚àÖ
2Hcurrent‚Üê Statistical characteristics of S
3M‚Üê{ H‚ààH current|H/mapsto‚Üí""} /*M maps each histogram in
Hcurrent onto an ‚Äúintermediate‚Äù constraint (explained in the text).
All histograms are initially mapped onto an empty expression.
4P‚Üê‚àÖ /*Pwill store histograms (from Hcurrent ) which have been
already processed. */
5foreach H‚ààH current do
6 if(H‚ààP )then
7 continue /* We have already processed Hand thus skip the loop. */
8 Letebe the data schema element to which Hhas been attached
9 LetLbe the set of all histograms in Hcurrent that annotate e
10 foreach L‚ààL do
11P‚ÜêP‚à™{ L}/* Histogram Lis marked as processed. */
12 LetOandUbe initially empty sets of OCL literals
/*Ustores literals generated for Under-represented bins;
Ostores literals generated for Over-represented bins. */
13 foreach relative frequency F‚ààLdo
14 LetDbe the relative frequency in Hdesired corresponding to F
15 if(|F‚àíD|>freq_sensitivity) then
16 if(F> D )then
17 O‚ÜêO‚à™ {excludeBin(inst, F)};
18 elseU‚ÜêU‚à™ {includeBin(inst, F)};
19 if(O /negationslash=‚àÖorU /negationslash=‚àÖ)then
20 OCL intermediate ‚Üê/parenleftBigg
j=|O|/logicalandtext
j=1Oj‚àßj=|U|/logicalortext
j=1Uj/parenrightBigg
/* See Fig. 4. */
21M‚ÜêM‚à™{ L/mapsto‚ÜíOCL intermediate }
22A‚Üê{A ‚ààM|M (A)/negationslash=""} /*Ais the set of all histograms in
M with a non-empty intermediate constraint */
23 if(A /negationslash=‚àÖ)then
24 if(|A| =1 andM(single histogram in A) is unconditional) then
25 OCL Ô¨Ånal‚ÜêM (single histogram in A) /* Row 1 of Table II */
26 else
27 OCL else‚Üê "true" /*OCL else will store the ‚Äúcatch all‚Äù else rule
when all of A‚Äôs histograms are conditional (Row 3 of Table II) */
28 foreach A‚ààA do
29 condition A‚Üê "true" /*condition Awill store the OCL
condition for histogram A‚Äôs intermediate constraint. */
30 if(A is conditional) then
31 condition A‚Üê condition of A
32 OCL else‚ÜêOCL else‚àß(¬¨condition A)
33 foreach B‚àà(A\{ A})do
34 /* Now, complete A‚Äôs condition based on other histograms in A.* /
35 if(B is conditional) then
36 condition A‚Üêcondition A‚àß(¬¨condition B)
37 OCL Ô¨Ånal‚ÜêOCL Ô¨Ånal‚à®(condition A‚àßM (A))
38 if(all histograms in Aare conditional) then
39 OCL Ô¨Ånal‚ÜêOCL Ô¨Ånal‚à®OCL else
40CC ‚Üê CC ‚à™ {OCL Ô¨Ånal }/* Store OCL Ô¨Ånal inCC.* /
41M‚Üê{ H‚ààH current|H/mapsto‚Üí""} /* ResetM.* /
42returnCC
row 2 of Table I applies to pensioners only. This detail is not
captured by the literals in OandU.
The construction of the intermediate constraint is straight-
forward, noting that we take the conjunction of the literals in O
which prescribe exclusions, and the disjunction of the literals
inUwhich prescribe inclusions (L. 20). In Fig. 4, we provide
877
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. T ABLE I
ILLUSTRA TIVE EXAMPLE FOR ALG.2
Construct Value
1Excerpt of the
instance model to
process.- id = 1
- birth_year = 1986T1: ResidentTaxPayer
I1: Employment
2Desired statisticalcharacteristics
(
Hdesired ): For
simplicity, welimit our
illustration to the
histogramsattached to thebirth_year
attribute of
TaxPayer in Fig. 1.The Ô¨Årst histogram, H1, attached to birth_year :
- Bin labels: {L 1=[1979..1998], L2=[1959..1978],
L3=[1934..1958], L4=[1900..1933]}
- Relative Frequencies: {D 1=0.7, D2=0.2,
D3=0.07, D4=0.03}
- Condition: true (none)
The second histogram, H2, attached to birth_year :
- Bin labels: {L 5=[1957..1960], L6=[1917..1956]}
- Relative Frequencies: {D 5=0.25, D6=0.75}
- Condition: self.incomes->exists
(oclIsTypeOf(Pension))
3Statistical
characteristics ofthe current sample(
Hcurrent computed
on L. 2 of Alg. 2).
Hcurrent differs
fromHdesired only
in the relativefrequencies.Histogram H1/primefor the sample (differs from H1on
row 2 above only in relative frequencies):
- Relative Frequencies for H1/prime:{F1=0.9, F2=0.05,
F3=0.05, F4=0}
Histogram H2/primefor the sample (differs from H2on
row 2 only in relative frequencies):- Relative Frequencies for H2/prime:{F5=0.5, F6=0.5}
4 freq_sensitivity. 0.03
((TaxPayer.allInstances()->select(id = 1)->
forAll(not(birth_year >= 1979 and birth_year <= 1998)))
and
(TaxPayer.allInstances()->select(id = 1)->
forAll(not(birth_year >= 1959 and birth_year <= 1978))))
and
(TaxPayer.allInstances()->select(id = 1)->
forAll(birth_year >= 1900 and birth_year <= 1933)){
{O
UFrom
From
Fig. 4. Intermediate OCL Constraint for Distribution H1/primein Table I
an example of an intermediate constraint for histogram H1/prime,
shown on row 3 of Table I.
3) Generate Ô¨Ånal constraints (L. 22-41 of Alg. 2): In the third
(and Ô¨Ånal) stage, the algorithm (1) adds to the intermediate
constraints conditions that describe under what circumstancesthese constraints apply (L. 27-36), and (2) combines the
intermediate constraints, now complemented with conditions,into corrective constraints (L. 25, 37 and 39). Due to space,
we do not show the Ô¨Ånal corrective constraint for the exampleof Table I. Detailed exempliÔ¨Åcation of corrective constraints,including the corrective constraint generated for the exampleof Table I, can be found in our supplementary material [27].
Instead, in Table II, we show all possible scenarios for
composing a corrective constraint from the set of histograms
that annotate a given data schema element. In the Ô¨Årst scenario(row 1 of Table II), there is no condition involved. The correc-tive constraint is thus the same as the intermediate constraintbuilt for the unconditional histogram (L. 25 of Alg. 2). In
the second scenario (row 2 of Table II), the algorithm Ô¨Årst
complements with conditions the intermediate constraints of
the conditional histograms. The condition of one (conditional)histogram is naturally exclusive of the conditions of others(L. 33-36). This has been illustrated in the second column ofTable II. The third scenario (row 3 of Table II) is similar tothe second scenario. The only difference is that, since there is
no unconditional histogram, we need an extra clause to dealwith the situation where none of the conditional histogramsT ABLE II
SCENARIOS FOR COMPOSING CORRECTIVE CONSTRAINTS
Possible annotation scenarios for
a data schema elementShape of the Ô¨Ånal
corrective constraint
1The element is annotated only by
one unconditional histogram, U.Uintermediate
2The element is annotated by one un-
conditional histogram, U, plus one
or more conditional histograms, Ci.
The shape shown is for when there
are two conditional histograms.Uintermediate or(C1condition and not
C2condition andC1intermediate )or
(notC1condition andC2condition and
C2intermediate )
3The element is annotated only by
conditional histograms, Ci. The
shape shown is for when there aretwo conditional histograms.(C1condition and not C2condition and
C1intermediate )or (not C1condition
andC2condition andC2intermediate )or
(notC1condition and not C2condition )
apply (L. 38-39). This ‚Äúcatch all‚Äù clause ensures that the Ô¨Ånal
corrective constraint will not impact an instance model towhich none of the conditional histograms should apply.
V. E
V ALUA TION
In this section, we empirically evaluate our synthetic data
generator through a realistic case study.
A. Research Questions (RQs)
Our evaluation aims to answer the following RQs:
RQ1: How does the customized OCL solver fare against
the baseline OCL solver? As discussed in Section IV -A, we
customize a baseline OCL solver [16]. RQ1 compares the cus-tomized solver against the baseline across two dimensions: (a)execution time, and (b) success rate, i.e., how often each solversucceeds in constructing a logically valid instance model.
RQ2: Does our synthetic data generator run in practi-
cal time? Statistical testing requires representative test data.
Achieving representativeness often necessitates a large number
of instance models to be built. RQ2 investigates whether our
approach can construct a sufÔ¨Åciently large number of instancemodels within practical time.
RQ3: Can our approach generate data samples that are
both valid and statistically representative? RQ3 investigates
whether our approach yields data samples suitable for statisti-
cal testing. Since the approach enforces the validity constraintsof interest over all instance models, data samples generated bythe approach always meet the validity requirement. AnsweringRQ3 therefore boils down to determining how well our data
generator meets the representativeness requirement.
The experimental setup for answering these RQs is elabo-
rated in Section V -D alongside our results and discussion.
B. Implementation
Our data generator (http://people.svv.lu/tools/SDG/) has
been implemented in Java using the Eclipse Modeling Frame-
work [28]. Excluding comments and third-party libraries, ourdata generator is approximately 39K lines of code.
C. Case Study Description
Our case study is motivated by an anticipated difÔ¨Åculty that
acceptance testing of a public administration IT system in
Luxembourg will pose, once the development of the system iscompleted. For this system, many of the software development
878
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. T ABLE III
COMP ARISON AGAINST THE BASELINE SOL VER (RQ1)
Baseline Solver Customized Solver
Execution time (per
instance model)Avg = 58.3 sec.
Std dev = 17.66Avg = 17.5 sec.
Std dev = 11.33
Success rate (calculated
based on 100 attempts)21% 92%
and testing activities have been commissioned to third-parties.
Since the actual data that the system will manipulate issensitive and of a personal nature, sharing the data with third-
parties poses complications. Further, there are gaps in the
actual data as well as structural mismatches between the dataschema used by the system under development and the dataschema in which the historical records have been archived.Due to these issues, our collaborating partners have concluded
that the most practical way to ascertain reliability is through
testing the system using synthetic test data.
The schema for the core data items manipulated by our case
study system was developed with participation from subject-
matter experts at our collaborating partners. The resultingschema, expressed as a UML class diagram, has 64 classes,
17 enumerations, 53 associations, 43 generalizations, and 344attributes. The statistical characteristics of the data itemswere captured using 15 histograms (e.g., for age and incometype), 7 conditional distributions (e.g., age distribution upon
the condition that the individuals are pensioners), and 13
distributions of other types (e.g., uniform distribution for theday of the year on which individuals are born).
The validity constraints over the data are expressed using 68
OCL invariants available in our supplementary material [27].Of these, 26 target avoiding logical anomalies (e.g., chil-dren being older than their parents). Of the remaining 42constraints, 30 are implied by the ranges (upper and lowerbounds) of the probabilistic annotations, and the Ô¨Ånal 12 aremultiplicity constraints from the data schema. The constraints
include 10 nested if-then-else expressions, 7 occurrences of
OCL quantiÔ¨Åers, 23 variable declarations, 107 references topredeÔ¨Åned OCL operations, and 212 logical operators.
D. Results and Discussion
In this section, we present our case study results and discuss
the RQs. The experiments in this section were conducted on a
laptop with a 3GHz dual-core processor and 16GB of memory.
RQ1: To answer RQ1, we attempted to generate 100 valid
instance models with both the customized and the baseline
solver. In this experiment, we considered only the validityconstraints of our case study, without taking representativenessinto account. We recall that in contrast to the baseline solverwhich starts from a randomly-generated instance model, the
customized solver is seeded with the output of the data gen-
erator presented in Section II. Further, the two solvers differin their strategy for exploring the search space as discussed inSection IV -A. In Table III, we report the execution time andsuccess rate of the two solvers in the 100 attempts made. We
note that different runs of the customized solver were seededwith different and randomly-selected initial instance models.None of these initial instance models were valid.
	

    	 
    &#""#"!
# !"!"! "
"%
!"!
 "
  "$
!" "!
 "
$!
 "!!
Fig. 5. Execution Times for Generating V alid Data Samples of Different Sizes
As shown in Table III, the customized solver is on average
‚âà3 times faster than the baseline solver. More importantly,
the customized solver is on average ‚âà4 times more likely to
succeed in reaching a valid instance model. Stated otherwise,
the customized solver produces a valid instance model inmuch fewer runs, thus signiÔ¨Åcantly decreasing wasted timeand CPU usage when compared to the baseline. The observedimprovements are explained mainly by two factors: First, thecustomized solver has a better starting point (initial instancemodel) which is easier to make valid. And second, the cus-tomized solver has a strategy (explained in Section IV -A) foravoiding entrapment in regions of the search space that do notcontain any valid solutions.
The answer to RQ1 is that the customized solver outperformsthe baseline by a factor of ‚âà3 in terms of execution time and
by a factor of ‚âà4 in terms of success rate.
RQ2: To answer RQ2, we measured the average execution
time of our data generator for building data samples ofdifferent sizes, ranging from 100 to 1000. In the context ofour case study, each element in the sample is an instancemodel that represents a household for the purposes of taxation.For a given data sample size, the data generation process wasrepeated Ô¨Åve times to account for random variation.
For this experiment, we conÔ¨Ågured our data generator as
follows: (a) The number of times the solver is invoked overa given instance model in order to create tweaked instancemodels (parameter
nb_attempts of Alg. 1) is set to two, and
(b) the margin for comparing relative frequencies (parameter
freq_sensitivity of Alg. 1) is set to 0.01. This means that a dif-
ference of 1% between a relative frequency in the data sampleand the corresponding frequency in the desired characteristicswill prompt our data generator to take corrective action.
Average execution times for different sample sizes are
shown in Fig. 5. For example, the average execution time(across Ô¨Åve runs) for producing a data sample with 500 (valid)
instance models is ‚âà200 minutes. Overall, we generated
(100 + 200 + ...+ 1000) √ó5 = 27500 (valid) instance
models. On average, an instance model from this cumulative
population has 40 objects, 276 attribute values, and 37 objectlinks. Average instance model size depends on the speciÔ¨Åcdata proÔ¨Åle of the system under test.
Fig. 5 further provides a breakdown of the execution times
over the different steps of our data generator. The breakdown
879
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. indicates: First, the time required for creating an initial seed
sample is negligible. Second, the generation of correctiveconstraints (by Alg. 2) is highly scalable with its execu-tion time showing a linear growth trend. Finally, the mostcomputationally-intensive steps are those involving constraintsolving (i.e., generating valid sample and generating tweakedinstance models in Fig. 5). Constraint solving accounts onaverage for 85% of the execution time. Despite its complexity,our data generator could produce in less than ten hours a datasample with 1000 instance models (i.e., 1000 test cases). Thisexecution time is practical in our context because, in the worstcase, the data can be generated overnight. Indeed, since dataproÔ¨Åles are often stable, one can imagine that the test data canbe generated early on and well before the testing phase. Forsystems with more complex data schemas, parallelization canbe considered, noting that the solver technology underlyingour approach is search-based and easily parallelizable [16].
The answer to RQ2 is that our data generator could producesamples with up to 1000 instance models in less thanten hours. This execution time is practical in our context,since data generation can be performed overnight. F or morecomplex systems, parallelization of search during constraintsolving can be considered. Further , test data generation canbe initiated well in advance of the testing phase, and as soonas the data proÔ¨Åle for the system under test has stabilized.
RQ3: To answer RQ3, we use the same experimental setup
and instance models as in RQ2. The basis for our answer is
the average distance between the statistical distributions in agiven sample and the corresponding distributions speciÔ¨Åed bythe data proÔ¨Åle. Note that for a given sample size, we computeaverage distances based on Ô¨Åve runs, as explained in RQ2.
As noted in Section IV -B, we use the Euclidean distance
metric for guiding data generation. Euclidean distance isnevertheless not the only metric that one can use for quan-tifying representativeness. To gain more thorough insightsabout the representativeness of the data samples generated
by our approach, we employ two additional distance metrics,namely Manhattan and Canberra [26]. These additional metricswere selected on the basis of the following criteria: (1) they,
alongside Euclidean distance, are among the most commonly-used distance metrics for comparing distributions [26], and
(2) robust implementations of the metrics were readily avail-
able [29]. These two new distance metrics are interpreted inthe same way as Euclidean distance: the closer the distanceis to zero, the better aligned a given pair of distributions are.Using these additional metrics in our evaluation helps ensurethat our results are not strongly biased toward the speciÔ¨Åc
notion of representativeness induced by Euclidean distance.
Figs. 6(a) ‚Äì (c) respectively show the representativeness re-
sults computed by the Euclidean, Manhattan, and Canberra
distance metrics. For each sample size, distances are computedfor: (1) the seed (potentially invalid) data sample (2) the initialvalid data sample built based on the seed sample, and (3) theÔ¨Ånal sample returned by our data generator. These distances(c)(a)
(b)
00.10.20.30.40.50.60.7
100 200 300 400 500 600 700 800 900 1000Euclidean distance
Number of instance models in the sampleDistance for (invalid) 
seed sample (d‚ÇÅ)
Distance for initial 
valid sample (d‚ÇÇ)
Distance for Ô¨Ånal 
valid sample (d‚ÇÉ)
00.10.20.30.40.50.6
100 200 300 400 500 600 700 800 900 1000Manhattan distance
Number of instance models in the sampleDistance for (invalid) 
seed sample (d‚ÇÅ)
Distance for initial valid sample (d ‚ÇÇ)
Distance for Ô¨Ånal valid sample (d ‚ÇÉ)
00.20.40.60.811.21.41.6
100 200 300 400 500 600 700 800 900 1000Canberra distance
Number of instance models in the sampleDistance for (invalid) 
seed sample (d‚ÇÅ)
Distance for initial valid sample (d ‚ÇÇ)
Distance for Ô¨Ånal valid sample (d ‚ÇÉ)
Fig. 6. Distance between Generated Sample and Desired Distributions: (a)
Euclidean Distance, (b) Manhattan Distance, and (c) Canberra Distance
are denoted d1,d2andd3as shown in Fig. 6. The difference
between d2andd1results from Ô¨Åxing the logical anomalies
in the seed sample. The difference between d3and d2is
the improvement induced by the corrective constraints. The
difference between d3andd1indicates the improvement in
representativeness brought about by our data generator whencompared to the representativeness of the seed sample.
The same trends are observed across the results irrespective
of the distance metric used: First, we see that d
2>d1. This
is natural, since we initially attempt to make the seed sam-
ple valid without accounting for representativeness. Second,d
2/greatermuchd 3, which means that the generated corrective constraints
have been effective at guiding constraint solving toward rep-
resentativeness. Thirdly, and remarkably, d1>d3. The average
of(d1‚àíd3)across all data sample sizes is ‚âà0.2,‚âà0.25 and
‚âà0.6 for the Euclidean, Manhattan and Canberra distance
metrics, respectively. This means that our data generator, inaddition to producing logically valid samples, has surpassed
in terms of representativeness the seed sample, which was builtexclusively to be representative.
When considering the Ô¨Ånal data samples, the largest stan-
dard deviation observed in distances across the Ô¨Åve runs madefor each sample size was ‚âà0.004 (not shown in Fig. 6). This
provides conÔ¨Ådence that random variation has little inÔ¨Çuenceover the representativeness of the Ô¨Ånal data samples.
The answer to RQ3 is that the (Ô¨Ånal) data samples createdby our data generator are valid, and at the same time,
surpassing the state-of-the-art in terms of representativeness.
880
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. E. Threats to V alidity
Conclusion and external validity are the most relevant
aspects of validity to our case study.
Conclusion validity. As stated in Section V -C, our case study
was prompted by a foreseen difÔ¨Åculty in the acceptance testing
of a system that is still under development. The unavailabilityof the Ô¨Ånal system prevented us from using the data generatedby our approach for system-level testing. This leaves thepossibility that the system may require test data beyond whatwas generated. To mitigate this threat, we ensured that thedata schema was validated by domain experts. Further, sincethe system is an operationalization of procedures described intaxation and social security laws, we were able to check ourdata schema against legal provisions and make sure that noimportant concepts were overlooked. We thus believe that thelikelihood of major omissions in our data schema is low.
External validity. Generalizability is always a concern in case
study research, particularly when the results are drawn from
a single case. Our evaluation results need to be interpretedwith respect to the complexity of our data schema and theassociated OCL constraints. Further studies remain essential
to determine how our approach will perform on more complex
data proÔ¨Åles. This said, our case study system is by any stan-dard a complex data-intensive system. In addition, and as notedearlier, our approach provides two alternatives for further en-hancing scalability: (1) to start test data generation long beforethe testing starts, and (2) to parallelize constraint solving.
VI. R
ELA TED WORK
Usage proÔ¨Åles. In the introduction, we already compared our
work with the existing literature on usage proÔ¨Åles. Withoutrepeating what was already said, we make some additionalremarks. Existing usage proÔ¨Åles mainly target embedded andweb-based systems. The behaviors of these systems typicallylend themselves to being modeled as states and transitions(for web-based systems, web pages represent states, and clickson links and buttons represent transitions [6]). State-machine-like notations such as Markov chains therefore provide aconvenient way to build usage proÔ¨Åles for these systems.Our work in contrast focuses on systems whose behavior isdriven by data that is interdependent and subject to complexlogical constraints. A data schema enhanced with probabilisticinformation and constraints is a more natural choice for
encoding usage proÔ¨Åles in our application context.
Synthetic data generation. The ability to create synthetic data
is an integral part of automated test case generation. Since,
in practice, it is often infeasible to cover all possible test
scenarios, test case generation (and thus the underlying datageneration strategy) is typically targeted at optimizing somenotion of coverage, e.g., state or path coverage [30]. Meta-heuristic search is widely used for generating data to supportcoverage-based testing [30]. Our data generation strategy relies
on search, but rather than attempting to maximize some cov-erage criterion, we try to achieve statistical representativeness.In the context of model-based development, data generation
has been considered from many angles, including model
veriÔ¨Åcation and model-based testing. The most notable toolto mention here is Alloy [31], which provides a speciÔ¨Åcationlanguage based on Ô¨Årst-order logic and a SA T -based modelÔ¨Ånder. Another interesting work strand is UML2CSP [20],where constraint programming is employed for generatinginstance models that satisfy a given set of OCL constraints. Intheory, we could have employed in our approach either Alloyor UML2CSP for constraint solving. Nevertheless, due to thetechnical limitations already discussed in Section IV -A, most
importantly scalability, we opted for a search-based solution.
Aside from the above work, a number of heuristic tech-
niques exist for generating large synthetic data. Notably, Hart-
mann et al. [32] propose a rule-based technique for generatingrealistic smart grid instances according to the grid‚Äôs knowntopological characteristics. And, Mougenot et al. [33] adoptrandom sampling for generating large models in linear time.These techniques cannot enforce complex validity constraintsover data. The techniques, on their own, are therefore notsufÔ¨Åcient for achieving our goals in this paper.
Whole test suite generation. Whole test suite generation builds
an entire test suite by simultaneously optimizing multiple Ô¨Åt-
ness functions (e.g., for multiple coverage criteria) [34], [35].In principle and with appropriate Ô¨Åtness functions deÔ¨Åned forvalidity and representativeness, the problem addressed in thispaper can be formulated as whole test suite generation. Therealization is however impractical: Whole test suite generationhas been applied mainly to unit testing, where the test casesare small. In our context, test cases are much larger and arecomposed of complex and interdependent data elements. Awhole test suite would therefore be prohibitively large forbeing manipulated by search. Further, our goal is not tooptimize validity, but rather to guarantee it while optimizingrepresentativeness. Our approach therefore takes a differentroute than whole test suite generation. We achieve validityand representativeness separately. SpeciÔ¨Åcally, we start with arepresentative but invalid test suite. We make this test suitevalid, but in the process, reduce its representativeness. At theend, we optimize representativeness without affecting validity.
VII. C
ONCLUSION
Focusing on data-intensive systems, we proposed an ap-
proach for building synthetic test data. We evaluated theapproach over an industrial case study. Our empirical resultssuggest that our approach can generate within practical time
test data that is both statistically representative and logicallyvalid. Meeting these criteria is key for meaningful reliability
estimation via statistical testing. For future work, we wouldlike to use the generated data for actual system testing. Wefurther plan to conduct additional case studies to better assess
the usefulness and scalability of our data generation approach.
Acknowledgment. This project has received funding from
the European Research Council (ERC) under the European
Union‚Äôs Horizon 2020 research and innovation programme(grant agreement No 694277).
881
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. REFERENCES
[1] P . Runeson and C. Wohlin, ‚ÄúStatistical usage testing for software
reliability control,‚Äù Informatica, vol. 19, no. 2, pp. 195‚Äì207, 1995.
[2] J. D. Musa, ‚ÄúOperational proÔ¨Åles in software-reliability engineering,‚Äù
IEEE Software, vol. 10, no. 2, pp. 14‚Äì32, 1993.
[3] J. A. Whittaker and J. H. Poore, ‚ÄúMarkov analysis of software speciÔ¨Å-
cations,‚Äù ACM Transactions on Software Engineering and Methodology
(TOSEM), vol. 2, no. 1, pp. 93‚Äì106, 1993.
[4] J. H. Poore and C. J. Trammell, ‚ÄúApplication of statistical science to
testing and evaluating software intensive systems,‚Äù in Statistics, Testing,
and Defense Acquisition, M. L. Cohen, D. L. Steffey, and J. E. Rolph,
Eds. National Academies Press, 1999, ch. 3.
[5] C. Kallepalli and J. Tian, ‚ÄúMeasuring and modeling usage and reliability
for statistical web testing,‚Äù IEEE Transactions on Software Engineering
(TSE), vol. 27, no. 11, pp. 1023‚Äì1036, 2001.
[6] P . Tonella and F. Ricca, ‚ÄúStatistical testing of web applications,‚Äù Journal
of Software Maintenance and Evolution: Research and Practice, vol. 16,no. 1-2, pp. 103‚Äì127, 2004.
[7] H. L. Guen, R. Marie, and T. Thelin, ‚ÄúReliability estimation for statistical
usage testing using markov chains,‚Äù in Proceedings of 15th IEEE Inter-
national Symposium on Software Reliability Engineering (ISSRE‚Äô04).
IEEE, 2004, pp. 54‚Äì65.
[8] S. Herbold, P . Harms, and J. Grabowski, ‚ÄúCombining usage-based and
model-based testing for service-oriented architectures in the industrialpractice,‚Äù International Journal on Software Tools for Technology Trans-
fer (STTT), 2016, (in press).
[9] ‚ÄúGeneral Data Protection Regulation (Regulation (EU) 2016/679),‚Äù
2016. [Online]. Available: http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=OJ:L:2016:119:TOC
[10] S. De Capitani di Vimercati, S. Foresti, S. Jajodia, S. Paraboschi, and
P . Samarati, ‚ÄúFragments and loose associations: Respecting privacy indata publishing,‚Äù Proceedings of V ery Large Data Bases Endowment
(VLDB), vol. 3, no. 1, pp. 1370‚Äì1381, 2010.
[11] D. Al-Azizy, D. Millard, I. Symeonidis, K. O‚ÄôHara, and N. Shadbolt,
‚ÄúA literature survey and classiÔ¨Åcations on data deanonymisation,‚Äù in
Proceedings of 10th International Conference on Risks and Security of
Internet and Systems (CRiSIS‚Äô10). Springer, 2015, pp. 36‚Äì51.
[12] G. Soltana, N. Sannier, M. Sabetzadeh, and L. Briand, ‚ÄúModel-based
simulation of legal policies: Framework, tool support, and validation,‚ÄùSoftware & Systems Modeling (SoSyM), 2016, (in press).
[13] F. Figari, A. Paulus, and H. Sutherland, ‚ÄúMicrosimulation and policy
analysis,‚Äù Handbook of Income Distribution, vol. 2, 2014.
[14] G. Soltana, M. Sabetzadeh, and L. Briand, ‚ÄúModel-based simulation of
legal requirements: Experience from tax policy simulation,‚Äù in Proceed-
ings of 24th IEEE International Requirements Engineering Conference(RE‚Äô16). IEEE, 2016.
[15] Object Management Group, ‚ÄúObject Constraint Language 2.4 SpeciÔ¨Å-
cation,‚Äù 2004, http://www.omg.org/spec/OCL/2.4/, last accessed: May2017.
[16] S. Ali, M. Z. Iqbal, M. Khalid, and A. Arcuri, ‚ÄúImproving the per-
formance of OCL constraint solving with novel heuristics for logicaloperations: a search-based approach,‚Äù Empirical Software Engineering
(ESE), vol. 21, no. 6, pp. 2459‚Äì2502, 2016.
[17] Object Management Group, ‚ÄúOMG UniÔ¨Åed Modeling Language
(UML),‚Äù 2015, http://www.omg.org/spec/UML/2.5, last accessed: March2017.[18] K. Anastasakis, B. Bordbar, G. Georg, and I. Ray, ‚ÄúOn challenges
of model transformation from UML to Alloy,‚Äù Software & Systems
Modeling (SoSyM), vol. 9, no. 1, pp. 69‚Äì86, 2010.
[19] A. Cunha, A. Garis, and D. Riesco, ‚ÄúTranslating between Alloy spec-
iÔ¨Åcations and UML class diagrams annotated with OCL,‚Äù Software &
Systems Modeling (SoSyM), vol. 14, no. 1, pp. 5‚Äì25, 2015.
[20] J. Cabot, R. Claris√≥, and D. Riera, ‚ÄúOn the veriÔ¨Åcation of UML/OCL
class diagrams using constraint programming,‚Äù Journal of Systems and
Software (JSS), vol. 93, pp. 1‚Äì23, 2014.
[21] S. Ali, M. Z. Iqbal, A. Arcuri, and L. C. Briand, ‚ÄúGenerating test data
from OCL constraints with search techniques,‚Äù IEEE Transactions on
Software Engineering (TSE), vol. 39, no. 10, pp. 1376‚Äì1402, 2013.
[22] M. P . Krieger and A. Knapp, ‚ÄúExecuting underspeciÔ¨Åed OCL operation
contracts with a SA T solver,‚Äù Electronic Communication of the European
Association of Software Science and Technology (ECEASST) , vol. 15, pp.
1‚Äì16,
2008.
[23] P . Hurley, A concise introduction to logic. Nelson Education, 2014.
[24] P . B. Miltersen, J. Radhakrishnan, and I. Wegener, ‚ÄúOn converting CNF
to DNF,‚Äù Theoretical Computer Science, vol. 347, no. 1-2, pp. 325‚Äì335,
2005.
[25] R. K. Hammond and J. E. Bickel, ‚ÄúDiscretization methods for continuous
probability distributions,‚Äù in Wiley Encyclopedia of Operations Research
and Management Science. Wiley, 2015.
[26] S.-H. Cha, ‚ÄúComprehensive survey on distance/similarity measures be-
tween probability density functions,‚Äù Mathematical Models and Methods
in Applied Sciences, vol. 1, no. 2, pp. 300‚Äì307, 2007.
[27] G. Soltana, M. Sabetzadeh, and L. Briand, ‚ÄúSynthetic data generation
for statistical testing: Supplementary material,‚Äù SnT Centre for Secu-rity, Reliability and Trust, University of Luxembourg, SupplementaryMaterial, May 2017, http://people.svv.lu/soltana/ASE17_supp.pdf.
[28] Eclipse Foundation, ‚ÄúEMF: Eclipse Modeling Framework,‚Äù http://www.
eclipse.org/emf, last accessed: May 2017.
[29] Apache Foundation, ‚ÄúApache commons mathematics library,‚Äù http://
commons.apache.org/proper/commons-math/, last accessed: May 2017.
[30] S. Ali, L. C. Briand, H. Hemmati, and R. K. Panesar-Walawege,
‚ÄúA systematic review of the application and empirical investigationof search-based test case generation,‚Äù IEEE Transactions on Software
Engineering (TSE), vol. 36, no. 6, pp. 742‚Äì762, 2010.
[31] D. Jackson, Software Abstractions: logic, language, and analysis. MIT
press, 2012.
[32] T. Hartmann, F. Fouquet, J. Klein, Y . Le Traon, A. Pelov, L. Toutain, and
T. Ropitault, ‚ÄúGenerating realistic smart grid communication topologiesbased on real-data,‚Äù in Proceedings of 5th IEEE International Confer-
ence on Smart Grid Communications (SmartGridComm‚Äô14), 2014, pp.428‚Äì433.
[33] A. Mougenot, A. Darrasse, X. Blanc, and M. Soria, ‚ÄúUniform random
generation of huge metamodel instances,‚Äù in Proceedings of 5th Eu-
ropean Conference on Model Driven Architecture - F oundations andApplications (ECMDA-F A‚Äô09), 2009, pp. 130‚Äì145.
[34] G. Fraser and A. Arcuri, ‚ÄúWhole test suite generation,‚Äù IEEE Trans-
actions on Software Engineering (TSE), vol. 39, no. 2, pp. 276‚Äì291,
2013.
[35] J. M. Rojas, M. Vivanti, A. Arcuri, and G. Fraser, ‚ÄúA detailed inves-
tigation of the effectiveness of whole test suite generation,‚Äù Empirical
Software Engineering (ESE), vol. 22, no. 2, pp. 852‚Äì893, 2017.
882
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:29:58 UTC from IEEE Xplore.  Restrictions apply. 