A Comparison of 10 Sampling Algorithms for
Conﬁgurable Systems
Flávio Medeiros
Fed. Univ. of Campina Grande
Paraíba, BrazilChristian Kästner
Carnegie Mellon University
Pittsburgh, Pennsylvania, USAMárcio Ribeiro
Federal University of Alagoas
Maceió, Alagoas, Brazil
Rohit Gheyi
Fed. Univ. of Campina Grande
Paraíba, BrazilSven Apel
Universität Passau
Passau, Germany
ABSTRACT
Almosteverysoftwaresystemprovidesconﬁgurationoptions
to tailor the system to the target platform and application
scenario. Often, this conﬁgurability renders the analysisof every individual system conﬁguration infeasible. To ad-dress this problem, researchers have proposed a diverse setof sampling algorithms. We present a comparative study
of 10 state-of-the-art sampling algorithms regarding their
fault-detection capability and size of sample sets. The for-mer is important to improve software quality and the lat-ter to reduce the time of analysis. In a nutshell, we found
that sampling algorithms with larger sample sets are able
to detect higher numbers of faults, but simple algorithmswith small sample sets, such as most-enabled-disabled,a r e
the most eﬃcient in most contexts. Furthermore, we ob-served that the limiting assumptions made in previous work
i n ﬂ u e n c et h en u m b e ro fd e t e c t e df a u l t s ,t h es i z eo fs a m p l e
sets, and the ranking of algorithms. Finally, we have iden-tiﬁed a number of technical challenges when trying to avoidthe limiting assumptions, which questions the practicality of
certain sampling algorithms.
1. INTRODUCTION
Manysoftwaresystemscanbeconﬁguredtodiﬀerenthard-
ware platforms, operating systems, and requirements [49].
However, the variability that is inherent to conﬁgurable sys-
tems challenges quality assurance [3,22,23,31]. Developers
need to consider multiple conﬁgurations when they executetests or perform static analyses to ﬁnd faults and vulner-abilities. As the conﬁguration space often explodes expo-
nentially with the number of conﬁguration options, analyz-
ing every individual system conﬁguration becomes infeasiblein real-world projects; for example, the Linux Kernel has
more than 12 thousand compile-time conﬁguration options.Conﬁguration-related faults that occur only in a subset of all
conﬁgurations are especially tricky to ﬁnd [31]. As such, it
is not surprising that many conﬁguration-related faults have
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributedfor proﬁt or commercial advantage and that copies bear this notice and the full cita-tion on the ﬁrst page. Copyrights for components of this work owned by others thanACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-publish, to post on servers or to redistribute to lists, requires prior speciﬁc permissionand/or a fee. Request permissions from permissions@acm.org.
c/circlecopyrt2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI:
http://dx.doi.org/10.1145/2884781.2884793been found in highly-conﬁgurable systems, such as the Linux
Kernel,Gcc,BusyBox,a n d Apache[1,14,20,32,33,54].
Although researchers have proposed approaches to ana-
lyze complete conﬁguration spaces in a sound fashion for
some classes of defects [15,20,21,54,55], the vast majorityofmaturequality-assurancetechniquesconsideronlyasingleconﬁguration at a time. For example, static-analysis tools
operate typically on C code after the C preprocessor has
resolved conﬁguration options implemented through condi-tional compilation (e.g., using #ifdefdirectives). To reuse
state-of-the-arttools, suchas gcc, fordetectingconﬁguration-
related faults, sampling is a viable alternative [18,29,38,40,
51]. That is, instead of analyzing all conﬁgurations, one se-lects asubsetof conﬁgurations to analyze individually. The
eﬀectiveness of sampling for detecting conﬁguration-relatedfaults depends signiﬁcantly on how samples are selected,
though.
Several sampling algorithms have been proposed in the lit-
erature, suchas t-wise[18,25,29,40], statement-coverage [52],
andone-disabled [1]. To select a suitable sampling algo-
rithm, one needs to understand the tradeoﬀs, especially withregardtoeﬀort(i.e., howlargearethesamplesets)andfault-
detection capabilities (i.e., how many faults can be found inthe sampled conﬁgurations). Unfortunately, acomparison ofsampling algorithms for ﬁnding conﬁguration-related faults
is not available. More importantly, many proposed sam-
pling algorithms make severe assumptions that may not berealistic for practical applications and that are not alwaysclearly communicated. For instance, they perform analy-ses per ﬁle instead of globally, and they ignore constraints
among conﬁguration options, header ﬁles, and build-system
information [23,25,37,47]. Applying sampling algorithmsunder diﬀerent assumptions may introduce signiﬁcant addi-tional eﬀort or reduce coverage, as we will discuss. A lack of
understanding of the tradeoﬀs and assumptions of sampling
algorithms can lead to both undetected faults, which de-crease software quality, and time-consuming code analysis,which increases costs.
Weconductedacomparativestudytoanalyze10sampling
algorithms in detail to ﬁll that gap. We compared the se-lected sample sizes and the fault-detection capabilities of thesampling algorithms in a study of 135 known conﬁguration-related faults in 24 open-source C systems, each conﬁgurable
with conditional compilation. Speciﬁcally, we analyzed a set
of sampling algorithms proposed in the research literature:5 variations of t-wise[18,29,38,40]; statement-coverage [52];
random;one-disabled [1];one-enabled ;a n dmost-enabled-
ICSE ’16, May 14-22, 2016, Austin, TX, USA
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   643
disabled. In summary, we analyzed 10 sampling algorithms
and 35 combinations of algorithms in two studies. In the
ﬁrst study, we compared sample sizes and fault-detection
capabilities of the diﬀerent sampling algorithms and theircombinations on a large set of open-source systems underfavorable assumptions (e.g., ignoring constraints and headerﬁles). In the second study, we explored the inﬂuence of con-
sidering constraints, header ﬁles, build-system information,
and global analysis, which are often neglected in the litera-ture and practice [23,25,37,47].
Our results show that all algorithms select conﬁgurations
with more than 66% of the conﬁguration-related faults inour corpus. Almost 84% of all faults are detected by en-abling or disabling one or two conﬁguration options, butthere are also faults that require developers to enable ordisable up to sevenoptions. As expected, we found that
the algorithms with the largest sample sizes detected themost faults. However, simple algorithms with small samplesets, such as most-enabled-disabled,a r et h em o s te ﬃ c i e n t
in many scenarios. More interestingly, we identiﬁed several
novel combinations of algorithms that provide a useful bal-ance between sample size and fault-detection capabilities.
As a further result, we found that considering constraints
among conﬁguration options, global analysis, header ﬁles,
and build-system information inﬂuence the performance of
most sampling algorithms substantially, up to the point that
several algorithms are no longer feasible in practice. Consid-ering constraints increases the time of analysis signiﬁcantly,whichprohibitsustousesomealgorithms, suchas three-wise
andfour-wise, at all. Including build-system information in-
creases the size of sample sets slightly, whereas global anal-ysis and analyses that include conﬁguration options fromheader ﬁles turn the analysis to be practically infeasible formost algorithms.
In summary, our main contributions are:
‚A comparative study of 10 sampling algorithms and35 combinations of algorithms regarding their fault-detection capability and size of sample sets;
‚A study on the inﬂuence of considering header ﬁles,constraints, build-systeminformation, andglobalanal-ysis on the performance of sampling algorithms;
‚A discussion of results showing that some sampling al-gorithms become infeasible under realistic settings, for
example, when incorporating header ﬁles and applying
global analysis;
‚A report of signiﬁcant changes of the eﬃciency rank-ing of sampling algorithms when considering diﬀerent
pieces of information, such as build-system and con-
straint information;
‚Results supporting sampling algorithms with an eﬃ-cient balance between sample size and fault-detectioncapabilities under diﬀerent assumptions, such as the
most-enabled-disabled algorithm.
All data used in this study are available on our Website.
1
2. CONFIGURATION-RELATED FAULTS
Conditional compilation is used in many real-world sys-
temstomakethesourcecodeconﬁgurable[26]. Forinstance,
Figure 1 depicts a code snippet of Libpng2related to split-
ting images into segments. The splitting feature is optionaland is included only when conﬁguration option SPLTis en-
1http://www.dsc.ufcg.edu.br/˜spg/sampling/
2http://www.libpng.org/abled. Thiscodesnippetalsocontainsaconﬁgurationoptionthat checks for pointer-index support, controlled by conﬁg-
uration option POINTER. Using the C preprocessor, we can
generate four diﬀerent conﬁgurations from this code snippet:
(1) both conﬁguration options enabled; (2) only POINTER
enabled; (3) only SPLTenabled; and (4) both conﬁguration
options disabled.
1.// Other definitions..
2.#ifdef SPLT
3.void png_handle_sPLT(){
4.   #ifdef POINTER
5.       png_sPLT_entryp p;
6.    #endif
7.   // Lines of code..
8.    #ifdef POINTER
9.       p = palette + i;10.      p->red = *start++;11.   #else12.      p = new_palette;
13.      p[i].red = *start++;14.   #endif15.}16.#endif
17.// More definitions..#define SPLT#define POINTERConfiguration 1
#undef SPLT
#define POINTERConfiguration 2
#define SPLT
#undef POINTERConfiguration 3
#undef SPLT#undef POINTERConfiguration 4
Compilation succeed
 Compilation error
Figure 1: A fault in Libpng that occurs when SPLT is enabled and
POINTER is disabled.
MostanalysistoolsforCcode, suchas gcc, operateonpre-
processed code, one conﬁguration at a time. By compiling
the code snippet of Figure 1 with SPLTenabled and POINTER
disabled, we get a compilation error at Line 12. This lineuses variable p, which is not declared before (Line 5) when
we disable POINTER. Because common analysis tools check
only one conﬁguration at a time, they do not show warningor error messages when one compiles the code depicted inFigure 1 considering other conﬁgurations. This is an exam-
ple of a conﬁguration-related fault that can only be exposed
in some combinations of conﬁguration options [14,23,57].Unfortunately, the space of possible combinations is expo-nential, in the worst case, and it is usually too large toexplore exhaustively. For instance, the Linux Kernel of-
fers more than 12K conﬁguration options, which give rise tomore conﬁgurations than there are atoms in the universe.
To analyze real-world conﬁgurable systems, developers of-
ten use sampling algorithms that select only a few conﬁgura-
tions for analysis. For instance, one can check the code snip-
pet presented in Figure 1 using the most-enabled-disabled
sampling algorithm. It considers two conﬁgurations: (1) allconﬁguration options enabled and (2) all options disabled.However, it is not possible to detect the fault presented in
Figure 1 using the most-enabled-disabled algorithm, as the
fault requires enabling one conﬁguration option while dis-
abling another. By using other sampling algorithms, onecan detect this speciﬁc fault in Libpng, but other faults pos-
sibly not. For instance, one can use one-disabled [1], which
disables one conﬁguration option at a time, or statement-
coverage [52], which enables each block of optional code at
least once.
Previous work [1,12,14] has studied conﬁguration-related
faults similar to the one we discuss here and proposed manysamplingalgorithms[1,38,40,52]. However, researchersmakeassumptions that may not be realistic in practice. For in-stance, they perform per-ﬁle instead of global analysis, and
theyignoreconstraintsbetweenconﬁgurationoptions, header
ﬁles and build-system information. In this paper, we reporton a comparative study of sampling algorithms initially ac-cepting those assumptions (Section 4), but explicitly evalu-ate the inﬂuence of including diﬀerent types of information
in a second study (Section 5).
6443. STUDY DESIGN AND SAMPLING
ALGORITHMS
Ouroverallgoalistocomparestate-of-the-artsamplingal-
gorithms regarding their capability to detect conﬁguration-
related faults and the size of their sample sets. Furthermore,
we study four assumptions of previous work, which often
does not consider (1) constraints, (2) global analysis, (3)build-system information, and (4) header ﬁles. We performour studies in the context of the C programming languageand conﬁguration options implemented with the C prepro-
cessor (i.e., #ifdef), as illustrated in the previous section.
We aim at answering the following research questions:
‚RQ1.What is the number of conﬁguration-related
faults detected by each sampling algorithm?
‚RQ2.What is the size of the sample set selected by
each sampling algorithm?
‚RQ3.Which combinations of sampling algorithms
maximize the number of faults detected and minimize
the number of conﬁgurations selected?
‚RQ4.Whatistheinﬂuenceofthefourassumptionson
thefeasibilitytoperformtheanalysisforeachsamplingalgorithm?
‚RQ5.What is the inﬂuence of the four assumptions
on the number of faults detected by each sampling al-gorithm?
‚RQ6.What is the inﬂuence of the four assumptions
o nt h es i z eo ft h es a m p l es e ts e l e c t e db ye a c hs a m p l i n galgorithm?
3.1 Overall Study Design
At ﬁrst glance, a study comparing sampling algorithms
(RQ1–3) seems straightforward. We use a number of diﬀer-ent sampling algorithms (independent variable) to measurehow many of the faults we can ﬁnd with them in diﬀerentsoftware systems and how big the sample set is (dependent
variables). However, there are several challenges to over-
c o m ei nt h ed e s i g no fs u c ha ne x p e r i m e n t .
Sampling the conﬁguration space needs to be combined
with a technique to detect faults in the respective selectedconﬁgurations, suchasinspection(unrealisticallylaborious),
executing existing test suites (if available), automated test-
case generation (looking for crashing defects), or static anal-ysis (prone to false positives). If not conducted carefully, wemight be evaluating the fault-detection technique instead
of the sampling algorithm. We address this potential bias
by taking the fault-detection technique out of the loop andby using a corpus of previously found conﬁguration-relatedfaults. For each known fault, we check whether the samplingalgorithms select conﬁgurations in which the fault could
have been found, assuming a suitable fault-detection tech-
nique. That is, by using a corpus of conﬁrmed conﬁguration-related faults, we eliminate the fault-detection technique asa confounding factor from our study setup. However, we
actually do not know if the sampling algorithms actually
discovered more or diﬀerent faults. We discuss this threatand an alternative study design in Section 6.
A second design challenge is how to evaluate the inﬂuence
of the four assumptions (regarding global analysis, header
ﬁles, constraints, andbuild-systeminformation)behindmany
sampling algorithms. As we will show, lifting these assump-tions can make it infeasible to apply some of the algorithmsto real-world software systems. Therefore, we decided to
proceed in two steps: First, we study tradeoﬀs among sam-pling algorithms (RQ1-3) under favorable conditions (i.e.,
fulﬁlling all assumptions). Subsequently, we investigate theinﬂuence of the assumptions (RQ4-6) on a smaller set ofsubject systems in a second study. The four assumptionsare:
‚Constraints: Constraints between conﬁguration op-
tions may exclude certain conﬁgurations (e.g., optionX may only be selected if option Y is selected) from
the set of valid conﬁgurations. A sample set may
contain conﬁgurations that violate constraints. Un-fortunately, conﬁguration constraints are rarely docu-mented explicitly—the Linux Kernel is an exception
and has been studied therefore extensively [39,53]. In
the presence of constraints, samplesetsareoften larger
to achieve the same coverage, and highly optimizedcovering array tables
3cannot be used. As we do not
know conﬁguration constraints for most of our subject
systems, we exclude contraints entirely from the sam-pling process in our ﬁrst study.
‚Global analysis: We can sample conﬁgurations per
ﬁ l eo rg l o b a l l yf o rt h ee n t i r es y s t e m .E v e ni ns y s t e m s
with many conﬁguration options, individual ﬁles are
usuallyaﬀectedonlybyfewoptions. Samplingoverthe
global conﬁguration space may detect inter-ﬁle faults(e.g., linker issues), but this often creates huge samplesets, which hardly aﬀect individual ﬁles. Thus, in the
ﬁrst study, we assume a per-ﬁle analysis.
‚Header ﬁles: In C code, a signiﬁcant amount of vari-
ability arises from header ﬁles. However, detecting all
conﬁguration options from header ﬁles in a sound wayis a diﬃcult and expensive task, which requires some
form of variability-aware analysis [2,10,20,55]. It is
necessary to resolve includes and macro expansions,but to keep the conditional directives (i.e., partial pre-processing). We therefore analyze only conﬁguration
options inside source ﬁles in our ﬁrst study.
‚Build system: The build system may induce a signif-
icant amount of variability, such that certain ﬁles are
not compiled in all conﬁgurations [10,39]. Since buildsystems are inherently diﬃcult to analyze [36], we do
not use build-system information in the ﬁrst study.
3.2 Sampling Algorithms
In both studies, we will analyze the same set of 10 sam-
pling algorithms, proposed in prior work [1,18,28,29,38,40,
52] as well as their combinations. We explain each samplingalgorithm using the example code snippet of Figure 2.
#ifdef A
  // code 1#endif
#ifdef B
  // code 2#else  // code 3#endif
#ifdef C
  // code 4#endifone-disabled
most-enabled-disabledpair-wise
config-1:  
config-2:
config-3:
config-4:!A
!A
A
A!B
B
!B
BC
!C!C
C
statement-coverage
config-1:  
config-2:AAB
!BC
Cone-enabled
config-1:  
config-2:config-3:A
!A
!A!B
B
!B!C!C
Cconfig-1:
 
config-2:config-3:!A
AAB
!B
BCC
!C
config-1:
 
config-2:A
!AB
!BC
!C
Figure 2: Comparing the sampling algorithms by example.
3A covering array is a mathematical object used for software testing,
which ensures speciﬁc coverage criteria. For example, a pair-wise
covering array ensures that all pairs of conﬁguration options are con-
sidered by the array [18,57].
645The t-wisealgorithm covers all combinations of tconﬁg-
uration options: pair-wise checks all pairs of conﬁguration
options pt “2q[18,29,38,40], and it selects four conﬁg-
urations of the example of Figure 2. Considering options
AandB, we can see that there is a conﬁguration where
both options are disabled ( conﬁg-1), two other conﬁgura-
t i o n sw i t ho n l yo n eo ft h e me n a b l e d( conﬁg-2 andconﬁg-3),
and another conﬁguration where both conﬁguration optionsare enabled (conﬁg-4 ). The same situation occurs for con-
ﬁguration options AandCand options BandC.H o w e v e r ,
tcan take integer values to check diﬀerent combinations of
options, such as three-wise pt “3q,four-wise pt “4q,a n d
ﬁve-wise pt “5q. As we increase t, the sizes of the sample
sets also increase. Figure 3 presents the sample-set distri-butions of three-wise, four-wise, ﬁve-wise ,a n dsix-wise.A s
we can see, three-wise andfour-wise create small sample
sets;ﬁve-wise andsix-wise create much larger sample sets.
We selected samples based on precomputed and optimalcovering-array tables
4that select a minimal set of conﬁgura-
t i o n st h a tc o v e r sa l lt combinations of conﬁguration options.
These tables do not consider constraints between conﬁgura-
tion options. There are tools that implement t-wiseconsid-
ering constraints, such as SPLCATool [18],CASA[13], and
ACTS[6]. However, these tools do not necessarily select a
minimal sample set or even guarantee t-wisecoverage, as
discussed in Section 5.
0 2 04 06 08 00200400600800
Number of Configuration OptionsSize of Sample Setthree−wise     
four−wisefive−wisesix−wise
Figure 3: Sample sets of t-wise sampling considering a ﬁle with
a number of conﬁguration options ranging from zero to eighty.
Thestatement-coverage algorithm selects a set of con-
ﬁgurations in which each block of optional code is enabled at
least once [51]. We used statement-coverage as implemented
in theUndertaker [52] tool suite.5Notice that we are not
usingUndertaker to detect dead code [52], but to select con-
ﬁgurations with the statement-coverage algorithm. As pre-
sented in Figure 2, by enabling conﬁguration options A,B,
andC, the algorithm ensures that the optional code blocks
code 1, code 2andcode 4are enabled at least once. How-
ever, it needs another conﬁguration (e.g., AandCenabled,
andBdisabled) to enable code 3. Including each block of
optional code at least once does not guarantee that all pos-sible combinations of individual blocks of optional code areconsidered, though.
Themost-enabled-disabled algorithm checks two sam-
ples independently of the number of conﬁguration options.When there are no constraints among conﬁguration options,it enables all options ( conﬁg-1), and then it disables all con-
ﬁgurationoptions(conﬁg-2 ).One-disabled isanalgorithm
suggested by Abal et al. [1] based on 42 faults found in theLinux Kernel. It disables one conﬁguration option at a time.We can also see in Figure 2 that it disables conﬁguration
4The precomputed and optimal covering arrays used in our study are
available at http://math.nist.gov/coveringarrays/.
5Despite the existence of an algorithm to compute an optimal solution
for the coverage problem [28], which is NP-hard ,w eu s e da na l g o r i t h m
that computes the sample set much faster, but may produce a sample
set that is possibly larger than optimal.optionAinconﬁg-1, option Binconﬁg-2, and option Cin
conﬁg-3. In contrast, one-enabled enables one conﬁgura-
tion option at a time.
Finally, we implemented a random sampling algorithm.
Random sampling receives as input the maximum number
of conﬁgurations (n ) to check per ﬁle. Then, it creates n
distinct conﬁgurations with all conﬁguration options of the
ﬁle and randomly assigns trueorfalsefor every option of
each conﬁguration. For ﬁles which a brute-force algorithm
requires fewer conﬁgurations than the maximum number of
conﬁgurations (n ) per ﬁle, random sampling selects all con-
ﬁgurations. We ran random sampling considering diﬀerentnumbers of conﬁgurations per ﬁle, ranging from 1 to 40. Foreach number, we ran the analysis ten times and computedthe average number of detected faults and the 95% conﬁ-dence interval.
4. DETECTING FAULTS
In this ﬁrst study, we compared the fault-detection capa-
bilities and the sample sizes of the 10 sampling algorithms
using a corpus of 135 known faults of 24 open-source sys-
tems to answer questions RQ1–3. As explained in Section 3,we performed the ﬁrst study under favorable assumptions,that is, without constraints, global analysis, build-systeminformation, and header ﬁles.
We proceeded in three steps, as illustrated in Figure 4.
InStep 1,w es e l e c te a c hs o u r c eﬁ l eo ft h eg i v e ns u b j e c t
system. Step 2applies each sampling algorithm to select
the samples for every ﬁle. Step 3determines the number
of conﬁguration-related faults detected (RQ1) and measuresthe size of the sample set (RQ2) for each algorithm. Thesize of the sample set is the sum of the numbers of sampledconﬁgurations for every source ﬁle. To identify the sam-pling algorithms that detect a fault, we consider its pres-
ence condition, which is a subset of system conﬁgurations in
which the fault can be found [42], assuming a suitable fault-detection technique. We checked whether we could ﬁnd atleast one conﬁguration of this subset in the sampled conﬁg-
urations for each algorithm. Finally, we repeat the process
for combinations of sampling algorithms (RQ3).
#ifdef
#endif
#endif
#ifdef
Source
File
Configurations
Samples
Sampling
Algorithms10What is the number of faults 
detected by the algorithm?
Does the 
algorithm
select the
configuration 
with fault?
1
2
3
Figure 4: Strategy used to compare the sampling algorithms.
4.1 Corpus of Faults
Using a corpus of conﬁguration-related faults in a study
raises the question of how to acquire a proper corpus and
whether it is a representative corpus of conﬁguration-related
faults in real systems. Faults identiﬁed with existing sam-pling algorithms will obviously bias results toward these spe-ciﬁc algorithms. Instead, we assembled a corpus of faults inwhich all faults have been identiﬁed in one of two ways:
‚Variability-awareanalysistoolsareabletoidentifycer-tain kinds of faults (mostly syntax and type errors) by
646covering the entire conﬁguration space without sam-
pling. Diﬃculties in setting up these tools and nar-
row classes of detectable faults limit their applicabil-
ity at this point, and their prototype status leads tofalse positives. We collected only conﬁguration-relatedfaults that have been reported by such tools, reportedto the original developers, and conﬁrmed or ﬁxed by
the developers [20,32].
‚Weuseconﬁguration-relatedfaultsthathavebeenman-
ually identiﬁed and ﬁxed by developers. Faults re-ported by users and ﬁxed in the repository by the sys-
tem’s developers may be slightly biased toward more
popular conﬁgurations, but are not systematically bi-ased toward speciﬁc sampling algorithms. They repre-sent conﬁguration-related faults that are routinely de-tected and ﬁxed in real software systems. We started
with Abal’s corpus of faults of the Linux Kernel [1],
and complemented it with faults found in other stud-
ies[14,43], andourowninvestigationofsoftwarerepos-itories (see Table 1).
Overall, the corpus of faults used in our study includes
135 conﬁguration-related faults from 24 subject systems ofvarious sizes and from diﬀerent domains, over 125 diﬀer-ent ﬁles with distinct numbers of conﬁguration options (seeFigure 5). Our corpus contains faults of diﬀerent kinds,
including syntax errors (34%), memory leaks (22%), null-
pointer dereferences (17%), uninitialized variables (13%),undeclaredvariablesandfunctions(5%), resourceleaks(3%),array and buﬀer overﬂows (3%), arithmetic faults (2%), and
type errors (1%). Table 2 presents a characterization of
the subject systems we use in the ﬁrst study, listing theproject name, application domain, lines of code, number ofﬁles, number of conﬁguration options, and number of knownfaults considered in our study.
Table 3 shows the presence conditions of the faults and
the number of conﬁguration options that we need to en-able or disable to detect the conﬁguration-related faults weconsider in the ﬁrst study: for 78 faults (58%), we need to
enable some options; for 27 faults (20%), we need to dis-
able some conﬁguration options; and for another 30 faults(22%), we need to enable some options and disable others.The majority of faults (83%) are related to one or two con-ﬁguration options, while less than 5% related to more than
four conﬁguration options.
Notice that we discarded seven faults of the Linux Kernel
from our corpus that span multiple ﬁles, because we per-
formed a per-ﬁle analysis in our ﬁrst study. We considered
faults that require inter-procedural analysis, as long as all
procedures are deﬁned in the same ﬁle.
0 50 100 150 2000510152025
Number of Configuration OptionsFrequency
Figure 5: Number of distinct conﬁguration options in ﬁles with
conﬁguration-related faults.
4.2 Results and Discussion
For each sampling algorithm, we answered the research
questions RQ1–2. Figure 6 presents the number of faults
detected and the corresponding size of the sample set for
each algorithm. Note that detecting more faults does notmean more eﬃciency, because there is a tradeoﬀ between thenumber of faults detected and the size of the sample set. We
consider the eﬃciency of the sampling algorithms in terms of
Eﬃciency :E “SizeOfSampleSet {NumberOfFaults. This
ratio represents the number of conﬁgurations that one needsto check per fault to be detected. Furthermore, we analyzed35 combinations of sampling algorithms to answer research
question RQ3, as illustrated in Figure 7. We discuss the
results in terms of the three research questions next.
RQ1.What is the number of conﬁguration-related faults
detected by each sampling algorithm?
Overall, we found that all algorithms detected more than
66% of all faults of our corpus. Statement-coverage detected
thelo w estn um beroffaults,whilesix-wise detectedthehigh-
est number. The majority of faults in our corpus can be
detected by enabling or disabling fewer than six conﬁgura-tion options. This way, six-wise is able to detect all these
faults.Statement-coverage missed 45 faults because they re-
quire developers to enable some conﬁguration options anddisable others (i.e., require speciﬁc combinations of multipleblocks of codes), whereas statement-coverage is only con-
cerned with including each block of code at least once in asystem conﬁguration.
Allt-wisesampling algorithms detected more than 92% of
the 135 conﬁguration-related faults. Six-wise andﬁve-wise
detected all faults. Most-enabled-disabled, one-enabled,a n d
one-disabled detected all between 78% to 80% of the faults.
Furthermore, we present the average values of random sam-pling with a 95% conﬁdence interval (gray area) in Figure 6.We ran random sampling with the maximum number of con-ﬁgurations per ﬁle ( n) ranging from 1 to 40, ten times for
each value of n.
6We report the mean of all runs; it detected
124 (92%) conﬁguration-related faults.
80 90 100 110 120 130 140024681012
Configuration−Related FaultsSamples per File Pair−wiseStmt−coverageRandom Four−wiseFive−wiseSix−wise
Three−wisemost−enabled−disabledOne−enabled One−disabled
Sampling Algorithm Faults Samples/File
Statement-coverage 90 1.3
Most-enabled-disabled 105 1.3
One-enabled 107 1.7
One-disabled 108 1.7
Random 124 2.6
Pair-wise 125 1.8
Three-wise 129 2.5
Four-wise 132 3.7
Five-wise 135 6.0
Six-wise 135 10.0
Figure 6: Number of conﬁguration-related faults and samples per
ﬁle for each sampling algorithm.
RQ2.What is the size of the sample set selected by each
sampling algorithm?
Thesizesofthesamplesetsrangefrom1.3to10conﬁgura-
tions per ﬁle. The algorithm most-enabled-disabled selected
t h es m a l l e s ts a m p l es e t ; six-wise required the largest sample
set (with more than 500K sampled conﬁgurations across all
projects). The number of conﬁgurations to check inﬂuences
the time of analysis. So, it is not feasible to use algorithms
with large sample sets in all situations, as we will discuss
6Random selects 2.6 samples per ﬁle, on average.
647Table 1: Conﬁguration-related faults considered in our ﬁrst study.
Source Faults Kind Strategy Subject system (number of faults)
[1] 30 Memory, type, and arithmetic Repository mining Linux (30)
[20] 10 Syntax TypeChef BusyBox (10)
[14] 5 Include, and arithmetic Repository mining Gcc (3), Firefox (2)
[43] 3 Type Repository mining Gnome-keyring (1), Gnome-vfs (1), and Totem (1)
[32] 22 Syntax TypeChef Apache (3), Bash (2), Dia (2), Gnuplot (5), Libpng (3),
and Libssh (7)
-6 5 Memory, type, and arithmetic Our repository mining Apache (9), Bison (2), Cherokee (3), Cvs (1), Dia (1),
Fvwm (10), Gnuplot (5), Irssi (4), Libpng (1), Lua (1),
Libssh (10), Linux (7),Libxml (2),Lighttpd (1),Vim (5),
Xﬁg (1), and Xterm (2)
Total135 70 faults collected from previous studies and 65 detected in our additional repository analysis.
in Section 7. Based on our eﬃciency measure, we rank the
algorithms starting from the most eﬃcient: most-enabled-
disabled, pair-wise ,stmt-coverage, one-disabled, one-enabled,
three-wise, random,four-wise, ﬁve-wise ,a n dsix-wise .
RQ3.Which combinations of sampling algorithms maxi-
mize the number of faults detected and minimize the number
of conﬁgurations selected?
Inadditiontotheindividualalgorithms, weanalyzedcom-
binations (that is, the union of the sample sets produced
by the respective sampling algorithms) of two and three
sampling algorithms, excluding random,ﬁve-wise ,a n dsix-
wisealgorithms. We excluded random because it detects
diﬀerent numbers of faults in diﬀerent runs, and we ex-
cludedﬁve-wise andsix-wise because they already detected
all 135 faults. Furthermore, we excluded combinations withmore than three algorithms, because they resulted in ineﬃ-cient combinations according to our eﬃciency function.
Figure 7 relates the number of faults and the size of sam-
ple sets for all combinations of sampling algorithms. Based
on the results, we determined the Pareto Front to illustrate
t r a d e o ﬀ sb e t w e e nn u m b e ro fd e t e c t e df a u l t sa n ds i z eo ft h e
sample sets. Figure 7 also presents the combinations of sam-pling algorithms on the Pareto Front, starting from the most
eﬃcient: C1,C3,C2,a n dC4.
Summary
All sampling algorithms are able to detect at least 66% ofthe conﬁguration-related faults; most-enabled-disabled,pair-wise, and statement-coverage are the most eﬃcientalgorithms; some combinations provide a useful balance
between sample size and fault-detection capabilities.
5. EFFECTS OF ASSUMPTIONS
In the ﬁrst study, we made many simplifying assumptions
also made in related studies on sampling [23,25,47]. We
ignored constraints, header ﬁles, and build-system informa-tion, and we did a per-ﬁle analysis only. In more realisticconditions, these assumptions often do not hold: For exam-
ple, constraints often exist, and ignoring them may lead to
false positives, but constraints are rarely documented sys-tematically and therefore easily ignored. Similarly informa-tion from build systems may increase precision but build
systems are inherently diﬃcult to analyze [2,10]. While the
simplifying assumptions allow researchers and practitionersto apply sampling algorithms quickly to a large set of sys-tems, as we did in our ﬁrst study, their inﬂuence on practi-cability and eﬀectiveness is not well understood. Therefore,
in a second study, we explore the eﬀect of each assumption
on the eﬃciency of the sampling algorithms.80 90 100 110 120 130 140024681012
Configuration−Related FaultsSamples per FileC4
C3C2
C1Combination
Individual
Pareto Front        
Sampling Algorithm
C1 Pair-wise and one-disabled
C2 One-enabled, one-disabled, and statement-coverage
C3 One-enabled, one-disabled, and most-enabled-disabled
C4 One-enabled, one-disabled, and pair-wise
Faults Samples/File Faults Samples/File
C1 131 3.5 C2 132 4.8
C3 133 4.8 C4 134 5.3
Figure 7: Number of conﬁguration-related faults and samples perﬁle for the combination of algorithms on the Pareto Front.
Basically, we replicate the ﬁrst study for a subset of the
corpus, investigating how the assumptions aﬀect each sam-
pling algorithm (RQ4–6 ). To increase internal validity [48],
weconsideredeachassumptionseparatelyasanindependent
variable that we manipulate to understand the inﬂuence ofeach assumption on sampling. We limit the second study to
faults of the Linux Kernel andBusyBox (47 faults from the
ﬁrst study), because these subject systems are the only ones
for which we have build-system and constraint informationfrom the LVATandTypeChef projects [5,35,46]. For the
Linux Kernel, we consider additionally seven known faults
that cross ﬁles, which we excluded from our original corpus,
as we discussed in Section 4.
Table 4 summarizes the number of conﬁguration-related
faults detected, sizes of sample sets, and the ranking of sam-
pling algorithms per lifted assumption.
5.1 Constraints
Constraints exclude certain combinations of conﬁguration
options (e.g., option X must be selected if option Y is se-
lected) from the set of valid conﬁgurations. Faults identiﬁed
ininvalidconﬁgurationsareconsideredfalsepositives(which
did not occur in the ﬁrst study, because we consider only acorpus of true positives); hence sampling invalid conﬁgura-tions adds no value. The analyzed version of the Linux Ker-
nelhas 293,826 constraint clauses among its conﬁguration
options; BusyBox has 615.
In the original sample sets of the ﬁrst study, many sam-
pled conﬁgurations are actually invalid in these highly con-strained conﬁguration spaces. For instance, random selects
24% of valid conﬁgurations and the percentage goes up to43% when picking most-enabled-disabled. Sampling within
648Table 2: Project characterization and the total number of known faults used in the ﬁrst study.
Project Application domain LOC Files Conﬁguration options Faults
Apache Webserver 144,768 362 700 12
Bash language interpreter 44,824 138 1,427 2
Bison parser generator 24,325 129 269 2
Busybox UNIX utilities 189,722 805 1,418 10
Cherokee Webserver 63,109 346 452 3
Cvs version control system 76,125 236 628 1
Dia diagramming software 28,074 132 307 3
Firefox Webbrowser 6,017,673 22,423 17,415 2
Fvwm windows manager 102,301 270 301 10
Gcc C/C++ compiler 1,946,622 22,034 3,825 3
Gnome-keyring daemon application 76,525 376 213 1
Gnome-vfs ﬁle system library 78,380 286 427 1
Gnuplot plotting tool 79,557 152 500 10
Irssi IRC client 51,356 308 157 4
Libpng PNG library 44,828 61 327 4
Libssh SSH library 28,015 125 115 17
Libxml XML library 234,934 162 2,126 2
Lighttpd Webserver 38,847 132 215 1
Linux operating system 12,594,584 37,520 26,427 37
Lua language interpreter 14,503 59 145 1
Totem movie player 31,596 135 84 1
Vim text editor 288,654 178 942 5
Xﬁg vector graphics editor 70,493 192 143 1
Xterm terminal emulator 50,830 58 501 2
Total 135
such constrained spaces is more challenging for all sampling
algorithms, as solvers or search-based strategies are needed.We incorporate constraints as follows:
‚Most-enabled-disabled: We cannot simply enable all
options if some of them are mutually exclusive. In-stead, we use a solver to ﬁnd two valid conﬁgurationswith the maximum number of conﬁguration optionsenabled and disabled. If there are multiple optimal
solutions, we pick the ﬁrst oﬀered by the solver.
‚One-enabled/disabled: Similarly, for each option, we
use a solver to identify the valid conﬁguration that
disables/enables the most other options.
‚Random sampling: We randomly assigned trueorfalse
for every conﬁguration option inside a ﬁle and discardinvalid assignments until we ﬁnd the desired number ofconﬁgurations. Truly random sampling in large con-strained spaces with many options is still a research
problem though, with recent progress in theory [7] and
recent pragmatic search heuristics [17].
‚Statement-coverage: To select a minimal set of cov-
ering conﬁgurations, we need to consider constraints.
Conceptually we can use the original implementation
ofstatement-coverage ,a sp a r to f Undertaker [52], but
the tool is not ﬂexible to handle other projects thanLinux. Thus, we use an alternative implementationthat we created in previous work [28].
‚T-wise sampling: The covering array tables used in
the ﬁrst study are precomputed, often optimal solu-tions that, however, assume independence of all op-tions. Recent research investigated strategies to gen-
eratet-wisecovering arrays for constrained conﬁgura-
tion spaces, such as SPLCATool [18],CASA[13], and
ACTS[6]. All tools use heuristics and may produce
larger-than-optimal sampling sets and sampling sets
that do not actually achieve full t-wise coverage. Togeneratethe pair-wise coveringarray, weused SPLCA-
Tool. We failed to generate three-wise or even higher
covering arrays for the Linux Kernel : Even with 120
Gb RAM we ran out of memory; a developer from
CASAestimated that that the generation could take
months and would require a 1.6 Tb array to track the
covered options. Overall, we could not ﬁnd an alter-native to implement the three-wise, four-wise ,ﬁve-wise
andsix-wise algorithms considering constraints; exist-
ing approaches are intractable for the size and com-plexity of the Linux Kernel.
The changes in sampling algorithms to incorporate con-
straints changed the eﬃciency of the algorithms as summa-
r i z e di nT a b l e4 .M o s ta ﬀ e c t e dw e r et - w i s es t r a t e g i e s : Pair-
wiserequired a larger sample set and detected fewer faults
(including faults that pair-wise should have guarantee to
ﬁnd) from the Linux Kernel, because the used heuristics are
unsound and do not cover all valid pairs of options. Three-
wisesampling and beyond was not tractable at all.
The time to compute sample sets increases signiﬁcantly
when adding constraints. Our use of a SAT solver required
signiﬁcant additional time and memory to generate the sam-
ple sets. On average, we created sample sets for each ﬁle in
0.04 seconds without constraints (the ﬁrst study), while theanalysis with constraints took 0.75 seconds per ﬁle, on av-erage. This time represents an increase from 15 minutes toover 4 hours for the Linux Kernel . Regarding the ranking
of algorithms, most-enabled-disabled andstatement-coverage
remain at top positions (see Table 4); the t-wisealgorithms
dropp
ed signiﬁcantly or were not feasible at all.
Summary
When considering constraints, we substantially reducefalse positives; but there are high costs for generatingsample sets, which are often not optimal.
649Table 3: Presence conditions of the conﬁguration-related faults.
Some conﬁguration options enabled 78 (58%)
a 59
a^b 13
a^b^c 5
a^b^c^d^e 1
Some conﬁguration options disabled 27 (20%)
!a 16
!a ^!b 8
!a ^!b ^!c 1
!a ^!b ^!c ^!d 1
!a ^!b ^!c ^!d ^!e ^!f^!g 1
Some options enabled and some disabled 30 (22%)
(!a ^b)_(a ^!b) 17
(a ^b^!c) _(!a ^!b ^c) 6
(a ^b^!c ^!d)_(a ^b^c^!d) 3
(a ^b^c^d^!e)_(!a ^!b^!c ^!d ^e)2
a^!b ^!c ^!d ^!e ^!f 1
a^b^!c ^!d ^!e ^!f 1
75
38
124321FaultsConfiguration 
Options20406080
1 234567
5.2 Global Analysis
To perform global analysis, we created a single sample
set across all ﬁles, instead of a distinct set per ﬁle. Such
global set allows us to perform cross-ﬁle analysis to ﬁnd
faults that cannot be identiﬁed on a per-ﬁle basis, such aslinking problems. However, for global analysis, a samplingalgorithm needs to consider all options in the system, notjust the subset of options used in each ﬁle.
We were not able to generate global sample sets with
anyt-wisealgorithm at the scale of our subject systems.
The largest precomputed tables we found covered up to 2Koptions (pair-wise) or 191 options (six-wise). We are not
aware of any tool that has the capability to generate cover-
ing arrays for such a large number of conﬁguration options,even without constraints. Statement-coverage also turns in-
tractable, asitrequirestosolvethecoverageproblemconsid-ering all source ﬁles of the project (i.e., equivalent to con-
catenating all source code into a single ﬁle and ﬁnding a
set of conﬁgurations that enabled all optional code blocksat least once). One-enabled andone-disabled require sub-
stantially larger sample sets, as more options are considered
(from1.7toalmost8K). Random requireslargersamplesets,
on average, because previously we could use smaller sam-
ple sets when the ﬁle had only few options. Most-enabled-
disabled is the only algorithm for which the size of sample
sets was not inﬂuenced, because it is not sensitive to the
number of options and it always selects exactly two conﬁg-
urations.
To explore the ability of global analysis to identify cross-
ﬁle faults, we opportunistically analyzed 7 known faults of
theLinux Kernel [1] that span multiple ﬁles, which we had
to exclude from our ﬁrst study. We detected all seven faults
by applying one-enabled andone-disabled with global anal-
ysis.Most-enabled-disabled detected ﬁve (71%) out of the
seven faults, and random detected four (57%) faults. The
other algorithms are not feasible with global analysis.Summary
Using a global analysis, we can potentially detect faultsthat span multiple ﬁles; it causes an explosion in thenumber of conﬁguration options that leads to large sam-
ple sets, too large for t-wise and statement-coverage.
5.3 Header Files
In C source code, variability may be introduced by header
ﬁles, because macros used in #ifdefs can have non-local ef-
fect. If sampling is applied only to variability in the main C
source ﬁle, faults stemming from variability in header ﬁlesmay not be detected. For example, a function may not bedeclared in all conﬁgurations of the header, a type name
may be deﬁned as either intorlongdepending on conﬁgu-
ration decisions in the header, or a macro may be deﬁned in
the header only in some conﬁgurations. Precisely analyzingheader variability is challenging, though, due to the inter-
action of #include directives with conditional compilation
and macros. Precise analyses exist [15,20], but are challeng-
ing and time-consuming to use, because one needs to set upthe environment with all header ﬁles used by the project.
Incorporating header ﬁles increases the number of conﬁg-
uration options per ﬁle signiﬁcantly. For instance, whereas
the ﬁles of the Linux Kernel contain, on average, 3 distinct
conﬁguration options when ignoring variability from header
ﬁles, headers add another 238 distinct conﬁguration options,
on average. This increases the size of the sample set for all
algorithms, except for most-enabled-disabled.F o r statement-
coverage, ﬁve-wise ,a n dsix-wise, our subject systems reach
conﬁguration spaces for which these algorithms become in-tractable.
Since our corpus does not include faults caused by mis-
conﬁgurations from header ﬁles, most algorithms detect thesamefaults. The one-enabled algorithmdetectedmorefaults,
becauseincludingconﬁgurationoptionsfromheadersallowed
it to disable more options, while enabling one at a time.
Summary
When incorporating header ﬁles, there is a potential to
detect additional faults from header ﬁles; but the setup isdiﬃcult and the sample sets are much larger (if feasibleat all), which lead to ranking changes.
5.4 Build-System Information
The build system controls which ﬁles are compiled and in-
cluded. Files may be included only when speciﬁc conﬁgura-tion options are selected or may be compiled with additionalparameters. This is equivalent to wrapping an additional
#ifdefaround each source ﬁle or deﬁne additional macros
in the beginning of a ﬁle. Like ignoring constraints, ignoring
build-system information can lead to false positives, wherefaults are reported in conﬁgurations that are prevented in
practice by the build system.
Build systems often have a strong inﬂuence on the conﬁg-
urability of a system; for instance, in the Linux Kernel , 97%
of source ﬁles are compiled only in certain conﬁgurations,
80% inBusyBox. Still, extracting conﬁguration knowledge
from build systems is very diﬃcult. While LinuxandBusy-
boxhave been analyzed with specialized parsers that recog-
nize common patterns [5,35], and more modern build sys-tems use a more declarative style, which is easier to ana-
lyze [34], analyzing Make ﬁles in general is an open research
problem with only few initial solutions [50,58].
650Table 4: Number of faults, size of sample sets and ranking considering the 47 faults of the second study.
Algorithms Constraints Global analysis Header ﬁles Build system
Faults Conﬁgs Rank Faults Conﬁgs Rank Faults Conﬁgs Rank Faults Conﬁgs Rank
Pair-wise 33 Ó 30 ò 5 –– – 39 “ 936 ò 4 33 Ó 2.8 Ò 4
Three-wise –– – –– – 43 “ 1,218 ò 5 42 Ó 3.9 Ò 5
Four-wise –– – –– – 45 “ 1,639 ò 7 45 “ 5.7 Ò 8
Five-wise –– – –– – –– – 47 “ 8.3 Ò 9
Six-wise –– – –– – –– – 47 “ 12 Ò 10
Most-enabled-disabled 23 Ó 1.4 “ 1 27 “ 1.4 “ 1 27 “ 1.4 “ 1 26 Ó 1.4 Ò 2
One-enabled 30 Ò 1.1 Ó 3 31 Ò 7,943 ò 3 31 Ò 890 ò 6 20 Ó 2.3 Ò 7
One-disabled 38 Ó 1.1 Ó 4 39 “ 7,943 ò 2 39 “ 890 ò 3 39 “ 2.3 Ò 3
Random 39 Ó 4.1 “ 6 29 ó 8,123 ò 4 40 Ó 17.2 ò 2 41 “ 4.2 Ò 6
Stmt-coverage 32 Ò 4.1 Ò 2 –– – –– – 25 “ 1.3 Ò 1
Some algorithms do not scale, indicated using dashes (–). We use Òand Óto represent small changes in the number
of faults and size of sample set, as compared to our ﬁrst study and we use òand óto represent larger changes.
Considering build-system information, the presence con-
ditions of faults become more complex, because we include
the condition when the ﬁle is compiled: Whereas withoutbuild-system information 40% of all faults of our corpus canbe found by enabling or disabling a single option, only 17%
can be found the same way with build-system information.
By requiring more options to pinpoint faults, incorporat-ing build-system information decreases the eﬃciency of al-gorithms. Pair-wise ,three-wise, most-enabled-disabled,a n d
one-enabled detected fewer faults than in the ﬁrst study.
T h es i z e so ft h es a m p l es e t sa r es l i g h t l yi n c r e a s e di na l l
sampling algorithms (except most-enabled-disabled ), as we
consider additional conﬁguration options used in the buildsystem. Time required to compute sample sets is increased
only by a few milliseconds.
Summary
Including build-system information requires to consider
more conﬁguration options in most ﬁles, but does notsigniﬁcantly aﬀect any sampling algorithm or their eﬃ-ciency.
6. THREATS TO V ALIDITY
Regarding external validity, we studied only systems that
implement variability with conditional compilation and can-
not generalize to systems that use other mechanisms to im-
plement variability.
Regarding internal validity, the corpus of faults is critical
for our research strategy. Creating a representative corpus
is diﬃcult, primarily because we have no means of knowing
all faults in the system. We address this threat with twostrategies:
‚We avoided biasing our corpus to any speciﬁc samplingalgorithm. As the corpus has been partially mined
from software repositories, it might be biased towards
more popular system conﬁgurations. Still, our cor-pus is the most comprehensive corpus of conﬁguration-related faults we are aware of.
‚We conducted a complimentary experiment using anautomated bug-ﬁnding technique instead of a corpusof known faults. This experiment yielded comparableresults and complements and conﬁrms the ﬁrst studyon our corpus. In a nutshell, we measured with which
sampling algorithm the bug-ﬁnding technique, static
analysis with Cppcheck, would expose the most warn-
ings per sampled conﬁguration. The experiment intro-duces a diﬀerent threat to internal validity in terms
of false positives, but triangulating the results across
both setups with orthogonal threats increases conﬁ-dence in our ﬁndings. We omit details for space rea-
sons and refer the interested reader elsewhere [30].
7. GUIDANCE FOR PRACTITIONERS
Ourstudyprovidesempiricalevidenceabouttheeﬃciency
and typical sample sizes for analyzing conﬁgurable C code
with various sampling algorithms both under ideal and real-world conditions. There is not a single sampling algorithm
thatisoptimalforallsystemsandinallconditions, butprac-
titioners can use our results to identify plausible candidatesfor their purposes.
For instance, during initial phases of a project, when de-
velopers are changing the source code frequently, they may
prefer sampling algorithms with small sample sets to run
the analysis fast. At some point, such as before a release,developers might want to use algorithms with larger sam-ple sets, to minimize the number of conﬁguration-related
faults. Under favorable conditions, that is, without consid-
ering constraints, global analysis, header ﬁles, and build-system information, all algorithms scale in practice; we rec-ommend t-wisesampling with a high tfor rigorous test-
ing and simpler sampling algorithms, such as most-enabled-
disabled, pair-wise ,statement-coverage , and combinations of
these, for quicker early runs. Combining many and expen-sive sampling strategies does bring only marginal beneﬁtsbut requires very large sample sets; we do not recommend
them.
Whenconsideringheaderﬁles, constraints, andglobalanal-
ysis, we recommend to go for simple algorithms, such as
most-enabled-disabled, because many other algorithms be-come intractable in practice, as presented in Table 4.
Again, while no algorithm ﬁts all contexts, we hope that
ourdatawillhelppractitionerstoidentifysuitablecandidatesampling algorithms for their speciﬁc scenario.
8. RELATED WORK
Several researchers have studied the way developers use
the C preprocessor. They performed empirical studies with
open-source systems written in C that are statically conﬁg-
urable with the C preprocessor [4,11,27]. Liebig et al. [27]found that almost 16% of the preprocessor usage is undisci-plined according to an empirical study of 40 C software sys-tems. In a previous study [31], we interviewed 40 developers
and performed a survey with 202 developers to understand
whytheCpreprocessorisstillwidelyusedinpracticedespitethe strong criticism the preprocessor receives in academia.According to our results, developers check only a few conﬁg-
urations of the source code. All these studies discussed the
651C preprocessor and its problems, such as faults, inconsis-
tencies, code quality, and incomplete testing. These studies
motivated us to analyze sampling algorithms to support de-
velopers in ﬁnding conﬁguration-related faults.
Other studies have analyzed software repositories by con-
sidering faults already ﬁxed by developers to understand thecharacteristics of conﬁguration-related faults [1,32]. In par-
ticular, researchers analyzed conﬁguration-related faults in
dynamic conﬁgurable systems [14,23]. They concluded thatthe majority of conﬁguration-related faults involve a fewconﬁguration options, a result similar to ours. Abal et al. [1]
analyzed the Linux Kernel software repository to study con-
ﬁguration-related faults. Tartler et al. [51] also performed
studies to ﬁnd conﬁguration-related faults in the Linux Ker-
nel. In our study, we considered some conﬁguration-related
faults reported by these previous studies. In addition, there
are several studies proposing tools to ﬁnd faults, such as
Undertaker [52],Tracker [56], and Splint[24].
Researchers have proposed various strategies to deal with
conﬁguration-related faults. They considered combinatorial
interaction testing to check diﬀerent combinations of conﬁg-uration options and prioritize test cases [8,9,23,41,44,57].
Nie et al. [37] performed a survey with combinatorial test-ing approaches, but without considering the complexities ofC, such as header ﬁles and build-system information. Most
studies on sampling make assumptions that might not be re-
alistic in practice, such as ignoring constraints among con-ﬁguration options. Including constraints, build-system in-formation, and header ﬁles is a non-trivial task. Several
researchers used the t-wisesampling algorithm to cover all t
conﬁguration option combinations [18,29,38,40], many stud-
ies without considering constraints [23,25,37,47]. Otherresearchers proposed the statement-coverage [52] sampling
algorithm and applied a per-ﬁle analysis. Abal et al. [1] sug-
gested the one-disabled algorithm. S´ anchez et al. [45] stud-
ied realistic settings and studied the use of non-functional
data for test case prioritization. Other researchers appliedt-wisealgorithms with constraints [6,13,18], and Grindal et
al. [16] studied diﬀerent constraint handling methods. How-ever, a comparative study to understand the fault-detectioncapability and eﬀort (size of sample set) of sampling algo-rithms, and the inﬂuence of limiting assumptions on sam-pling was not covered in previous studies.
K¨astner et al. [20] developed a variability-aware parser
that analyzes all possible conﬁgurations of a C program si-
multaneously. It also performs type checking [19] and data-ﬂow analysis [28]. Gazzillo and Grimm [15] developed a sim-
ilar parser. In our work, we considered faults detected by
TypeChef and reported in previous studies [21]. Diﬃculties
in setting up these tools and narrow classes of detectablefaults limit their applicability and lead to false positives.In addition, variability-aware tools work at the preproces-
sor level, which hinders the reuse of existing bug checkers of
traditional C tools, including GccandClang.
Somestudieshavecomparedsample-basedandvariability-
aware strategies. Apel et al. [3] developed a model checking
tool for product lines and used it to compare sample-based
and variability-aware strategies with regard to veriﬁcationperformance and the ability to ﬁnd defects. Liebig et al. [28]performed studies to detect the strengths and weaknesses ofvariability-aware and sampling-based analyses. They con-
sidered two analysis implementations (type checking and
liveness analysis) and applied them to a number of sub-ject systems, such as Busybox and the Linux Kernel .I n
our study, we performed complimentary analyses regardingsampling algorithms and ﬁlled a gap by comparing samplingalgorithms considering the inﬂuence of assumptions made in
previous studies.
9. CONCLUDING REMARKS
We compared 10 sampling algorithms. Our study makes
a step toward understanding the tradeoﬀs between eﬀort
(i.e., how large are the sample sets) and fault-detection ca-
pabilities (i.e., how many faults can be found in the selected
conﬁgurations).
In a ﬁrst study, we used a corpus of 135 conﬁguration-
related faults from 24 popular C projects reported in pre-vious studies. We initially ran the comparison accepting
some assumptions and we ignored conﬁguration constraints,
header ﬁles and build-system information, and we applieda per-ﬁle analysis. The results reveal that all sampling al-gorithms selected conﬁgurations that include at least 66%
of the 135 faults reported in previous work. As expected,
the algorithms with the largest sample sizes detected themost faults. More interestingly, we identiﬁed several combi-nations of algorithms that provide a useful balance betweensample size and fault-detection capabilities.
Subsequently, we performed a complementary study to
measuretheinﬂuenceofconsideringconstraints, globalanal-ysis, header ﬁles, and build-system information on sampling.We found that, when considering constraints, we can reduce
false positives, but it increases the costs for generating sam-
ple sets, which are often not optimal. Using a global analy-sis, we can potentially detect non-modular faults that spanmultiple ﬁles, but it causes an explosion in the number ofconsidered conﬁguration options that leads to large sample
sets. When incorporating header ﬁles, there is a potential todetect additional faults, but the setup is diﬃcult and the al-
gorithms produce much larger sample sets. When includingbuild-system information, we face a diﬃcult analysis, a few
more conﬁguration options to consider, but no signiﬁcant
changes. Overall, we found that global analysis and analy-ses that include conﬁguration options from header ﬁles turnthe analysis to be practically infeasible for most algorithms.
Our study ﬁlls a gap, as a comparison of sampling algo-
rithms for ﬁnding conﬁguration-related faults was not avail-able. Ourﬁndingsaremeanttosupportdevelopersinunder-standing the tradeoﬀs regarding eﬀort and fault-detectioncapabilities of sampling algorithms, aiding developers in se-
lecting an algorithm and deciding what kind of information
they include in the analysis. A lack of understanding thetradeoﬀs and assumptions of sampling algorithms can leadto both, undetected faults, which decreases software quality,and time-consuming code analysis, which increases costs.
Acknowledgments
This work has been supported by CNPq 460883/2014-3,573964/2008-4 (INES), 477943/2013-6, and 306610/2013-2,
CAPES 175956, project DEVASSES (European Union Sev-
enth Framework Programme, agreement no PIRSES-GA-2013-612569), NSF award 1318808, the U.S. Department ofDefense through the Systems Engineering Research Center
(SERC, contract H98230-08-D-0171), the Science of Secu-
rity Initiative, and the German Research Foundation (AP206/4 and AP 206/6).
65210. REFERENCES
[1] I. Abal, C. Brabrand, and A. Wasowski. 42 variability
bugs in the Linux kernel: A qualitative analysis. In
Proc. of the Int. Conf. on Automated Software
Engineering , pages 421–432. IEEE/ACM, 2014.
[2] B. Adams, K. D. Schutter, H. Tromp, and W. D.
Meuter. The evolution of the Linux build system. InProc. of the Int. Symposium on Software Evolution ,
2007.
[ 3 ]S .A p e l ,A .v .R h e i n ,P .W e n d l e r ,A .G r ¨osslinger, and
D. Beyer. Strategies for product-line veriﬁcation: Case
studies and experiments. In P r o c .o ft h eI n t .C o n f .o n
Software Engineering , pages 482–491. IEEE, 2013.
[4] I. Baxter. Design maintenance systems.
Communication of the ACM , 35(4):73–89, 1992.
[5] T. Berger, S. She, R. Lotufo, A. Wasowski, and
K. Czarnecki. Variability modeling in the real: Aperspective from the operating systems domain. In
Proc. of the Int. Conf. on Automated SoftwareEngineering , pages 73–82. ACM, 2010.
[6] M. Borazjany, L. Yu, Y. Lei, R. Kacker, and R. Kuhn.
Combinatorial testing of acts: A case study. In Proc.
of the Int. Conf. on Software Testing, Veriﬁcation and
Validation , pages 591–600. IEEE, 2012.
[ 7 ]S .C h a k r a b o r t y ,D .F r e m o n t ,K .M e e l ,S .S e s h i a ,a n d
M. Vardi. On parallel scalable uniform SAT witness
generation. In Tools and Algorithms for the
Construction and Analysis of Systems, pages 304–319.
Springer, 2015.
[ 8 ]D .C o h e n ,S .R .D a l a l ,M .L .F r e d m a n ,a n dG .C .
Patton. The AETG system: An approach to testing
based on combinatorial design. IEEE Transactions on
Software Engineering , 23(7):437–444, 1997.
[9] M. B. Cohen, P. B. Gibbons, W. B. Mugridge, and
C. J. Colbourn. Constructing test suites for
interaction testing. In Proc. of the Int. Conf. on
Software Engineering , pages 38–48. IEEE, 2003.
[ 1 0 ]C .D i e t r i c h ,R .T a r t l e r ,W .S c h r ¨oder-Preikschat, and
D. Lohmann. A robust approach for variability
extraction from the Linux build system. In Proc. of
the Software Product-Line Conf. , pages 21–30. ACM,
2012.
[11] M. Ernst, G. Badros, and D. Notkin. An empirical
analysis of C preprocessor use. IEEE Transactions on
Software Engineering , 28(12):1146–1170, 2002.
[12] A. Garrido and R. Johnson. Analyzing multiple
conﬁgurations of a C program. In Proc. of the Int.
Conf. on Software Maintenance, pages 379–388. IEEE,2005.
[13] B. Garvin, M. Cohen, and M. Dwyer. An improved
meta-heuristic search for constrained interactiontesting. In Proc. of the Int. Symposium on Search
Based Software Engineering, pages 13–22. IEEE, 2009.
[14] B. J. Garvin and M. B. Cohen. Feature interaction
faults revisited: An exploratory study. In Proceeding
of the Int. Symposium on Software ReliabilityEngineering , pages 90–99. IEEE, 2011.
[15] P. Gazzillo and R. Grimm. SuperC: Parsing all of C
by taming the preprocessor. In Proc. of the
Programming Language Design and Implementation,
pages 323–334. ACM, 2012.
[16] M. Grindal, J. Oﬀutt, and J. Mellin. Handlingconstraints in the input space when using combination
strategies for software testing. Technical ReportTR-06-001, University of Sk ¨ovde, 2006.
[17] C. Henard, M. Papadakis, M. Harman, and Y. L.
Traon. Combining multi-objective search and
constraint solving for conﬁguring large software
product lines. In Proc. of the Int. Conf. on Software
Engineering, pages 517–528. ACM, 2015.
[18] M. F. Johansen, O. Haugen, and F. Fleurey. An
algorithm for generating t-wise covering arrays fromlarge feature models. In Proc. of the Int. Software
Product Line Conf., pages 46–55. ACM, 2012.
[19] C. K ¨astner, S. Apel, T. Th ¨um,
 and G. Saake. Type
checking annotation-based product lines. ACM
Transactions on Software Engineering andMethodology, 21(3):14:1–14:39, 2012.
[20] C. K ¨astner, P. Giarrusso, T. Rendel, S. Erdweg,
K. Ostermann, and T. Berger. Variability-aware
parsing in the presence of lexical macros andconditional compilation. In Proc. of the
Object-Oriented Programming Systems Languages andApplications, pages 805–824. ACM, 2011.
[21] C. K ¨astner, K. Ostermann, and S. Erdweg. A
variability-aware module system. In Proc. of Conf. on
Object-Oriented Programming, Systems, Languages,
and Applications, pages 773–792. ACM, 2012.
[22] P. Knauber and J. Bosch. Software variability
management. In Proc. of the Int. Conf. on Software
Engineering, pages 779–780. IEEE, 2003.
[23] D. R. Kuhn, D. R. Wallace, and A. M. Gallo, Jr.
Software fault interactions and implications forsoftware testing. IEEE Transactions on Software
Engineering, 30(6):418–421, 2004.
[24] D. Larochelle and D. Evans. Statically detecting likely
buﬀer overﬂow vulnerabilities. In P r o c .o ft h eC o n f .o n
USENIX Security Symposium . USENIX Association,
2001.
[25] Y. Lei, R. Kacker, D. R. Kuhn, V. Okun, and
J. Lawrence. IPOG/IPOG-D: Eﬃcient test generationfor multi-way combinatorial testing. Software Testing,
Veriﬁcation and Reliability , 18(3):125–148, 2008.
[ 2 6 ]J .L i e b i g ,S .A p e l ,C .L e n g a u e r ,C .K ¨astner, and
M. Schulze. An analysis of the variability in forty
preprocessor-based software product lines. In Proc. of
the Int. Conf. on Software Engineering,p a g e s
105–114. ACM, 2010.
[ 2 7 ]J .L i e b i g ,C .K ¨astner, and S. Apel. Analyzing the
discipline of preprocessor annotations in 30 million
lines of C code. In Proc. of the Aspect-Oriented
Software Development, pages 191–202. ACM, 2011.
[ 2 8 ]J .L i e b i g ,A .v o nR h e i n ,C .K ¨astner, S. Apel, J. D ¨orre,
and C. Lengauer. Scalable analysis of variable
software. In Proc. of the Joint Meeting of the
European Software Engineering Conf. and the ACM
SIGSOFT Symposium on the Foundations of Software
Engineering, pages 81–91. ACM, 2013.
[29] D. Marijan, A. Gotlieb, S. Sen, and A. Hervieu.
Practical pairwise testing for software product lines.InProc. of the Int. Software Product Line Conf. ,
pages 227–235, 2013.
[30] F. Medeiros, C. K ¨a s t n e r ,M .R i b e i r o ,R .G h e y i ,a n d
S. Apel. A Comparison of 10 Sampling Algorithms for
653Conﬁgurable Systems. arXiv.org, cs.SE, 2016.
[31] F. Medeiros, C. K ¨astner, M. Ribeiro, S. Nadi, and
R. Gheyi. The love/hate relationship with the C
preprocessor: An interview study. In Proceedings of
the European Conf. on Object-Oriented Programming,pages 999–1022. ACM, 2015.
[32] F. Medeiros, M. Ribeiro, and R. Gheyi. Investigating
preprocessor-based syntax errors. In Proc. of the Int.
Conf. on Generative Programming: Concepts &
Experiences , pages 75–84. ACM, 2013.
[33] F. Medeiros, I. Rodrigues, M. Ribeiro, L. Teixeira, and
R. Gheyi. An empirical study on conﬁguration-related
issues: Investigating undeclared and unused identiﬁers.InProc. of the Int. Conf. on Generative Programming:
Concepts & Experiences, pages 35–44. ACM, 2015.
[34] J. D. Morgenthaler, M. Gridnev, R. Sauciuc, and
S. Bhansali. Searching for build debt: Experiencesmanaging technical debt at Google. In Proc. of the
Int. Workshop on Managing Technical Debt, 2012.
[35] S. Nadi, T. Berger, K ¨astner, and K. Czarnecki. Where
do conﬁguration constraints stem from? an extraction
approach and an empirical study. IEEE Transactions
on Software Engineering, 41(8):820–841, 2015.
[36] S. Nadi and R. C. Holt. The Linux kernel: A case
study of build system variability. Journal of Software:
Evolution and Process , 26(8), 2013.
[37] C. Nie and H. Leung. A survey of combinatorial
testing.ACM Computing Surveys , 43(2):11:1–11:29,
2011.
[38] S. Oster, F. Markert, and P. Ritter. Automated
incremental pairwise testing of software product lines.InSoftware Product Lines: Going Beyond ,p a g e s
196–210. Springer, 2010.
[ 3 9 ]L .P a s s o s ,J .G u o ,L .T e i x e i r a ,K .C z a r n e c k i ,
A. Wasowski, and P. Borba. Coevolution of variabilitymodels and related artifacts: A case study from the
linux kernel. In Proc. of the Int. Software Product
Line Conf. , pages 91–100. ACM, 2013.
[40] G. Perrouin, S. Sen, J. Klein, B. Baudry, and
Y. Le Traon. Automated and scalable t-wise test case
generation strategies for product lines. In Proc. of the
Int. Conf. on Software Testing, Veriﬁcation andValidation, pages 459–468. IEEE, 2010.
[ 4 1 ]X .Q u ,M .B .C o h e n ,a n dG .R o t h e r m e l .
Conﬁguration-aware regression testing: An empiricalstudy of sampling and prioritization. In Proc. of the
Int. Symposium on Software Testing and Analysis ,
pages 75–86. ACM, 2008.
[42] A. Rhein, A. Grebhahn, S. Apel, N. Siegmund,
D. Beyer, and T. Berger. Presence-conditionsimpliﬁcation in highly conﬁgurable systems. In Proc.
of the Int. Conf. on Software Engineering ,p a g e s
178–188. ACM, 2015.
[43] M. Ribeiro, P. Borba, and C. K ¨astner. Feature
maintenance with emergent interfaces. In Proc. of the
Int. Conf. on Software Engineering , pages 989–1000.
ACM, 2014.
[44] S. Sampath, R. Bryce, G. Viswanath, V. Kandimalla,
and A. Koru. Prioritizing user-session-based test cases
for web applications testing. In Proc. of the Int. Conf.
on Software Testing, Veriﬁcation, and Validation ,
pages 141–150. IEEE, 2008.[45] A. B. S´ a n c h e z ,S .S e g u r a ,J .A .P a r e j o ,a n d
A. Ruiz-Cort´ es. Variability testing in the wild: The
drupal case study. Software and Systems Modeling,
14(52), 2015.
[46] S. She, R. Lotufo, T. Berger, A. Wasowski, and
K. Czarnecki. The variability model of the linux
kernel. In Proc. of the Variability Modeling of
Softwar
e-intensive Systems. ACM, 2010.
[47] L. Shi, C. Nie, and B. Xu. A software debugging
method based on pairwise testing. In Proc. of the Int.
Conf. on Computational Science, pages 1088–1091.
Springer, 2005.
[48] J. Siegmund, N. Siegmund, and S. Apel. Views on
internal and external validity in empirical software
engineering. In Int. Conf. on Software Engineering ,
pages 9–19, 2015.
[49] H. Spencer and G. Collyer. Ifdef considered harmful,
or portability experience with C news. In Proc. of the
USENIX Annual Technical Conf. USENIX
Association, 1992.
[50] A. Tamrawi, H. A. Nguyen, H. V. Nguyen, and
T. Nguyen. Build code analysis with symbolicevaluation. In Proc. of the Int. Conf. on Software
Engineering, pages 650–660, 2012.
[51] R. Tartler, C. Dietrich, J. Sincero,
W. Schr¨oder-Preikschat, and D. Lohmann. Static
analysis of variability in system software: The 90,000
#ifdefs issue. In USENIX Annual Technical Conf.
USENIX Association, 2014.
[52] R. Tartler, D. Lohmann, C. Dietrich, C. Egger, and
J. Sincero. Conﬁguration coverage in the analysis oflarge-scale system software. In Proc. of the Workshop
on Programming Languages and Operating Systems.ACM, 2011.
[53] R. Tartler, D. Lohmann, J. Sincero, and
W. Schr¨oder-Preikschat. Feature consistency in
compile-time-conﬁgurable system software: Facing the
Linux 10,000 feature problem. In Proc. of the Int.
Conf. on Computer Systems . ACM, 2011.
[54] R. Tartler, J. Sincero, C. Dietrich,
W. Schr¨oder-Preikschat, and D. Lohmann. Revealing
and repairing conﬁguration inconsistencies in
large-scale system software. Int. Journal on Software
Tools for Technology Transfer, 14(5), 2012.
[55] T. Th ¨um, S. Apel, C. K ¨astner, I. Schaefer, and
G. Saake. A classiﬁcation and survey of analysis
strategies for software product lines. ACM Computing
Surveys, 47(1), 2014.
[56] E. Torlak and S. Chandra. Eﬀective interprocedural
resource leak detection. In P r o c .o ft h eI n t .C o n f .o n
Software Engineering . ACM, 2010.
[57] C. Yilmaz, M. Cohen, and A. Porter. Covering arrays
for eﬃcient fault characterization in complexconﬁguration spaces. IEEE Transactions on Software
Engineering, 32(1), 2006.
[ 5 8 ]L .Z h u ,D .X u ,X .S .X u ,A .B .T r a n ,I .W e b e r ,a n d
L. Bass. Challenges in practicing high frequencyreleases in cloud environments. In Proc. of the Int.
Workshop on Release Engineering , 2014.
654