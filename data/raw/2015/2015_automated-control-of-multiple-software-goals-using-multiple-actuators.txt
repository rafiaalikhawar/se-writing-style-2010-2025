-6/%6/*7&34*5:
1
0

#
P
Y











-
V
O
E
















Automated Control of Multiple Software Goals using Multiple Actuators
Maggio, Martina; Papadopoulos, Alessandro Vittorio; Filieri, Antonio; Hoffmann, Henry
Published in: 
ESEC/FSE 2017 Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering
DOI:
10.1145/3106237.3106247
2017
Document Version: 
Peer reviewed version (aka post-print)
Link to publication
Citation for published version (APA): 
Maggio, M., Papadopoulos, A. V., Filieri, A., & Hoffmann, H. (2017). Automated Control of Multiple Software
Goals using Multiple Actuators. In ESEC/FSE 2017 Proceedings of the 2017 11th Joint Meeting on Foundations 
of Software Engineering (pp. 373-384). Association for Computing Machinery (ACM). 
https://doi.org/10.1145/3106237.3106247
Total number of authors: 
4
General rights
Unless other specific re-use rights are stated the following general rights apply:
Copyright and moral rights for the publications made accessible in the public portal are retained by the authors
and/or other copyright owners and it is a condition of accessing publications that users recognise and abide by the
legal requirements associated with these rights.
 ‚Ä¢ Users may download and print one copy of any publication from the public portal for the purpose of private study
or research.
 ‚Ä¢ You may not further distribute the material or use it for any profit-making activity or commercial gain
 ‚Ä¢ You may freely distribute the URL identifying the publication in the public portal
Read more about Creative commons licenses: https://creativecommons.org/licenses/
Take down policy
If you believe that this document breaches copyright please contact us providing details, and we will remove
access to the work immediately and investigate your claim.Automated Control of Multiple So/f_tware Goals
using Multiple Actuators
Martina Maggio
Lund University, Sweden
martina@control.lth.seAlessandro Vi/t_torio Papadopoulos
M¬®alardalen University, Sweden
alessandro.papadopoulos@mdh.se
Antonio Filieri
Imperial College London, UK
a./f_ilieri@imperial.ac.ukHenry HoÔ¨Ämann
University of Chicago, US
hankhoÔ¨Ämann@cs.uchicago.edu
ABSTRACT
Modern so/f_tware should satisfy multiple goals simultaneously: it
should provide predictable performance, be robust to failures, han-
dle peak loads and deal seamlessly with unexpected conditions and
changes in the execution environment. For this to happen, so/f_t-
ware designs should account for the possibility of runtime changes
and provide formal guarantees of the so/f_tware‚Äôs behavior. Control
theory is one of the possible design drivers for runtime adaptation,
but adopting control theoretic principles o/f_ten requires additional,
specialized knowledge. To overcome this limitation, automated
methodologies have been proposed to extract the necessary infor-
mation from experimental data and design a control system for
runtime adaptation. /T_hese proposals, however, only process one
goal at a time, creating a chain of controllers. In this paper, we
propose and evaluate the /f_irst automated strategy that takes into
account multiple goals without separating them into multiple con-
trol strategies. Avoiding the separation allows us to tackle a larger
class of problems and provide stronger guarantees. We test our
methodology‚Äôs generality with three case studies that demonstrate
its broad applicability in meeting performance, reliability, quality,
security, and energy goals despite environmental or requirements
changes.
CCS CONCEPTS
‚Ä¢Computer systems organization !Embedded systems; Re-
dundancy; Robotics; ‚Ä¢Networks!Network reliability;
KEYWORDS
Adaptive So/f_tware, Control /T_heory, Dynamic Systems, Non-Functional
Requirements.
ACM Reference format:
Martina Maggio, Alessandro Vi/t_torio Papadopoulos, Antonio Filieri, and Henry
HoÔ¨Ämann. 2017. Automated Control of Multiple So/f_tware Goals
using Multiple Actuators. In Proceedings of 2017 11th Joint Meeting of the
European So/f_tware Engineering Conference and the ACM SIGSOFT Symposium
on the Foundations of So/f_tware Engineering, Paderborn, Germany, September
4‚Äì8, 2017 (ESEC/FSE‚Äô17), 12 pages.
DOI: 10.1145/3106237.3106247
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for pro/f_it or commercial advantage and that copies bear this notice and the full citation
on the /f_irst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permi/t_ted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speci/f_ic permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE‚Äô17, Paderborn, Germany
¬©2017 ACM. 978-1-4503-5105-8/17/09. . . $15.00
DOI: 10.1145/3106237.31062471 INTRODUCTION
/T_he growing complexity and dynamic unpredictability of computer
systems has motivated the design and implementation of a new
class of self-adaptive so/f_tware systems [ 49]. Such so/f_tware auto-
matically reacts to changes in both the operating environment and
application behavior to ensure that certain high-level goals are met.
/T_he development of self-adaptive so/f_tware creates, however, a huge
challenge: designing so/f_tware systems that are robust in the face
of dynamic behaviors we are not aware of at design-time. To face
the challenge, so/f_tware systems are o/f_ten highly con/f_igurable [ 58],
and can o/f_ten modify their behavior during runtime.
Control theory provides a vast array of tools for designing ro-
bust adaptive systems that operate with formal guarantees [ 3,5].
/T_his combination of robustness and formal grounding has led to
increased interest in developing self-adaptive so/f_tware based on
control theoretic techniques [ 46]. While several ad hoc approaches
to control design have arisen, recent work proposes a general,
automated methodology for creating formally robust so/f_tware con-
trol [ 15]. However, this /f_irst approach can handle only a single,
measurable goal ( e.g., performance or reliability, but not both).
Modern so/f_tware, however, must meet multiple, o/f_ten con/f_licting,
goals. For example, so/f_tware for cyber-physical systems must meet
performance, energy, and security requirements simultaneously.
Very li/t_tle research has addressed automating the design of self-
adaptive so/f_tware that meets multiple goals. A /f_irst step proposes
a hierarchy of single-goal controllers [ 16,24]. In this approach,
goals are ordered. Higher priority goals are met /f_irst using one
set of actuators (or tunable so/f_tware parameters), and then those
actuators are removed from consideration for the controllers that
manage lower priority goals. Priorities can be set based on user
preference. /T_he actuators are partitioned into disjoint sets, with
fewer actuators available to meet lower priority goals.
Despite being one of the /f_irst solutions to oÔ¨Äer multidimen-
sional control, this hierarchical approach has two limitations. First,
due to the partitioning of actuators, the controller may not reach
low-priority goals even when they are feasible. A combined ap-
proach that considers the eÔ¨Äects of concurrent actuation, however,
should reach any set of feasible goals. Second, the hierarchical
approach only provides formal guarantees for the highest priority
goal, others are not guaranteed. /T_hus, there is a need for a formally
veri/f_iable methodology to automate the design of self-adaptive so/f_t-
ware that meets multiple goals using multiple actuators. Finally,
the approach in [ 16,24] requires actuators to assume only a /f_inite
number of values. While continuous actuators can be automatically
discretized [ 16], the complexity of control may grow exponentially,ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany M. Maggio, A.V. Papadopoulos, A. Filieri, H. HoÔ¨Ämann
limiting its applicability when timely decisions are required or
when the available computational capacity is limited (e.g., IoT).
We therefore propose a novel automated strategy‚Äîbased on mul-
tivariable control‚Äîthat simultaneously uses all available actuators
to meet all goals. Unlike prior work, our approach allows users to:
Reach sets of goals that are unreachable with the prior hierar-
chical approach, and in fact, to reach any set of feasible goals.
Identify the largest subset of goals that are reachable with the
available actuators. Additionally, users can express desires like
controlling the largest subset of goals that contains speci/f_ic non-
deniable objectives ;e.g., /f_inding the largest set of reachable goals
where request latency is below 0.1 seconds.
Shape the so/f_tware‚Äôs dynamic behavior by specifying a cost
function to be optimized, while prioritizing the goals based on
their relevance. For example, users may prefer upgrading an
existing virtual machine instead of starting up a new one.
Provide faster convergence to goals a/f_ter system perturbation.
/T_he cascaded approach determines an actuator se/t_ting for each
goal, waits for that goal to be reached, and then addresses
the next goal. In contrast, the multivariable controller sets all
actuators simultaneously, oÔ¨Äering much faster convergence to
the goals and response to environmental /f_luctuation.
Model and exploit the mutual dependencies that exist among
the actuators and goals. Instead of considering partitions of
actuators one-by-one, we model all the combined eÔ¨Äects and
exploit them to obtain more precise and eÔ¨Écient control.
Limit the identi/f_ication time needed for the system design. In-
stead of testing all possible values for diÔ¨Äerent actuators during
the learning phase, we only need to test random switches from
the minimum to maximum value for each actuator. /T_he length
of the initial model identi/f_ication phase is then greatly reduced,
becoming proportional to the number of actuators and not to
the number of permutations of all the possible actuator values.
Tune the tradeoÔ¨Ä between control overhead and optimality of
the actuator se/t_tings with respect to the cost function. /T_his
tunability allows users to construct solutions with acceptable
overhead, whereas no prior control synthesis approach sup-
ports user adjustable overhead.
We demonstrate the advantages of the proposed approach through
three case studies developing self-adaptive so/f_tware including: a
video encoder, a secure radar system, and a dynamic service binder.
We use case studies from prior work to highlight the additional
capabilities proposed in this paper. /T_he remainder of this paper is
organized as follows. Section 2 compares the approach presented in
this paper to other automated methodologies for automated multi-
concern control. Section 3 presents the technical details of the
proposed approach and the Section 4 discusses the formal guaran-
tees that can be given using the proposed strategy. Section 5 shows
experimental evidence of how the proposed strategy works and
Section 6 concludes the paper.
To foster future research and enable comparison with our ap-
proach, we published the source code for our experiments and to
generate the control strategies used in the remaining of this paper1.
1h/t_tp://www.martinamaggio.com/papers/fse17/2 RELATED WORK
Modern so/f_tware systems must be robust to frequent, unpredictable
changes to their execution environment, users, and requirements.
Self-adaptive so/f_tware adjusts its behavior at runtime, withstand-
ing external changes as they are detected, or even proactively
avoiding critical situations [ 5,9,33,51]. One great challenge
of self-adaptation is ensuring its eÔ¨Äectiveness and dependabil-
ity [13,19,57]. Control theory has de/f_ined a variety of techniques
for controlling the behavior of physical plants, and its formal frame-
work serves as a basis for a variety of so/f_tware adaptation mecha-
nisms [8, 12, 17, 18, 23].
Control of so/f_tware systems. Recent surveys capture the cur-
rent state-of-the-art applying control-theory to so/f_tware applica-
tions [ 17,46,59]‚Äîfrom controlling web server delays [ 38], to data
service management [ 10], resource allocation [ 2,26,27,35,47], op-
erating systems tuning [ 30,40,45], and energy management [ 25,41].
Some of these systems use automata-based formalisms to abstract
so/f_tware‚Äôs behavior and temporal logic to specify some of its re-
quirements [ 9,51], while we focus here on discrete-time control,
where equation-based models are used to satisfy quantitative so/f_t-
ware properties.
Most discrete-time control approaches satisfy quantitative, non-
functional requirements: controlling tunable actuators identi/f_ied
either by the designer or automatically [ 22] and whose value af-
fects the so/f_tware behavior. /T_he majority of so/f_tware controllers
belong to the family of Proportional-Integral-Derivative (PID) con-
trollers [ 36]. PIDs are computationally inexpensive and support
formal analysis of their dynamics. /T_hey are, however, limited to
linear (or linearized) system models and mostly control a single goal
(e.g., the response time) using a single actuator ( e.g., the number of
VMs). /T_his approach is known as single-input, single-output (SISO).
In contrast, multiple-input, multiple-output (MIMO) controllers are
more complex, managing con/f_licting goals and contending actua-
tors.
Model predictive control (MPC). MPC is an eÔ¨Äective, /f_lexible
solution for MIMO problems [ 39]. MPC design incorporates the
diÔ¨Äerent actuators‚Äô higher-order dynamics; i.e., it captures how each
actuator aÔ¨Äects each goal and interferes with the other actuators.
MPC controllers decide the control signals for the next time
step by optimizing a utility function that accounts for both the
current operating point and all possible trajectories up to a given
horizon [ 20,34]. Reasoning based on predictions of future behavior
has proven eÔ¨Äective in other self-adaptation approaches [ 12,44,61],
though with reasoning techniques mostly ad-hoc and tailored to
user-de/f_ined models. In contrast, MPC provides a more general
analysis framework and the ability to re/f_ine and compensate for
model inaccuracies by exploiting a feedback loop. MPC-based adap-
tation mechanisms have been used to de/f_ine controllers for a class
of goal models [ 1] and resource provisioning in cloud environments
under uncertainty [ 54]. /T_hese MPC solutions, however, requires
the developer to explicitly provide a system model and are tied
to speci/f_ic problems; in turn, they require the developer to mas-
ter modeling techniques and do not generalize beyond the models
manually de/f_ined by the developer.
Automated controller synthesis. Automated controller synthe-
sis eases the integration of control-theoretical adaptation into so/f_t-
ware systems. Abstracting speci/f_ic views of the so/f_tware systemAutomated Control of Multiple So/f_tware Goals using Multiple Actuators ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany
into equation-based models and de/f_ining adequate control strate-
gies are open problems for current development processes [ 17,18].
/T_he /f_irst automated modeling and controller synthesis approach
has been proposed in [ 15]. It builds a locally linearized model of a
SISO system collecting input-output measurements during system
execution. /T_hen, a tunable controller is continuously adjusted
around the current operation point to provide computationally
eÔ¨Écient and robust adaptation decisions, under mild assumptions
on the smoothness of the ‚Äì possibly non-linear ‚Äì system behavior.
/T_his approach cannot deal with general MIMO systems, however.
Recent work automatically synthesizes MIMO controllers for
discrete systems by chaining multiple SISO controllers (one for
each goal) together in a hierarchy [ 16]. /T_he hierarchy re/f_lects goal
prioritization, and each controller produces a continuous refer-
ence signal that is converted into a mixture of the discrete input
con/f_igurations using Pulse Width Modulation [ 36]. /T_he two main
limitations of this solution are the use of disjoint sets of actuators
along the hierarchy of SISO controllers and the need for actuators
to assume values from a /f_inite domain. Actuators that are used to
reach a higher priority goal cannot be changed to meet the lower
priority ones, limiting the controller‚Äôs ability to achieve all goals
optimally at the same time (see also the experimental comparison in
Section 5.3). /T_he need for /f_inite domains for the actuators requires
the discretization of continuous control inputs; while this can be
done automatically, as in [ 16], the complexity of the control law
may grow exponentially, limiting the practical applicability of the
approach when timely decisions are required or the controller has
to run on low-power devices, like embedded systems. /T_he approach
in [50] extends [ 16], formulating the conversion of the continuous
references into discrete se/t_tings as a linear optimization problem.
/T_his approach avoids partitioning actuators into disjoint sets and
allows actuation to minimize a cost function ( e.g., considering the
priority of diÔ¨Äerent actuators), but it does not provide an explicit
means for handling con/f_licting goals when the satisfaction of one
makes others infeasible.
/T_his paper‚Äôs contribution. /T_his paper proposes automated model
construction and controller synthesis for MIMO controllers. Unlike
prior work [ 16,50], it does not require the input space to be /f_inite,
requires less observation to build a comprehensive equation-based
model of the system, and produces optimal control decisions con-
sidering not only the current situation but also future predicted
system evolutions.
3 METHODOLOGY
A MIMO system has multiple actuators that in/f_luence multiple goals.
Our methodology makes two assumptions: 1) the user knows all
available actuators and their limits; i.e., the maximum and minimum
values they can assume; and 2) design-time tests can be performed
that measure the eÔ¨Äects actuator changes have on goals. /T_he pro-
posed methodology minimizes the number of tests to be performed
‚Äì a big improvement with respect to prior work [ 15,16,50] ‚Äì but
some experimental data collection is required to build a model and
synthesize the controller.
/T_he methodology has /f_ive steps, illustrated in Figure 1. It re-
quires several inputs from the user, but is otherwise completely
automated, requiring no control expertise. /T_he /f_i/f_th step outputs
code implementing the controller. /T_he framework collects user
inputs (Step 1) and then collects data by running experiments (Step2). /T_his data is used to estimate a model relating actuator changes
to changes in system behavior (Step 3). A controllability test is then
performed to ensure the provided actuators can reach the speci/f_ied
goals (Step 4). If the system is controllable, the methodology syn-
thesizes a controller and generates the resulting code (Step 5). /T_he
user then selects the desired values for the goals and complements
the generated code with calls to the sensors (to obtain the current
values of the goals), and to the actuators (to eÔ¨Äectively perform
the action chosen by the controller). /T_hese user-de/f_ined functions
for sensing and actuating are system-dependent and represent the
interfaces to the rest of the so/f_tware.
Step 1: user input. /T_he user speci/f_ies a sampling time ‚àÜt, a set of
/v.altactuatorsA=fa1;a2; : : :a/v.altg, and a set of pgoals. For example,
a1might be the clock speed of the execution environment, while a2
might be the probability of using one service provider over another.
/T_he values assumed by the set Aat time kare denoted with the
vector a(k). /T_he user provides the values of ai;minandai;max, which
are the minimum and maximum values for the i-th actuator.
/T_he set of goals is G=f/afii10069.ital1;/afii10069.ital2; : : :/afii10069.italpg. For example, /afii10069.ital1might
be the 95-th percentile response latency, and /afii10069.ital2might be power
consumption. /T_he goals‚Äô values at time kare denoted with the
vector/afii10069.ital(k)./afii10069.ital(k)is a function of time as goals may change while
the so/f_tware is running. /T_he user should also provide a way to
measure the current value of the goals. We denote with the set
Gm=f/afii10069.italm1;/afii10069.italm2; : : :/afii10069.italmpgthe measured values corresponding to
the goals ‚Äî in the example /afii10069.italm1is the current 95-th percentile of
the response time and /afii10069.italm2the current power consumed by the
embedded device. Again, the vector /afii10069.italm(k)is the measurements
at time k. We assume that p/v.alt,i.e.there cannot be more goals
than actuators, an inherent limitation of any control approach.
For each goal /afii10069.italj, the user speci/f_ies a weight wj, resulting in a set
W=fw1;w2; : : :wpg. Goal weighting speci/f_ies a proportional
disparity between goals‚Äô importance when goals aren‚Äôt simulta-
neously satis/f_iable. Equally weighted goals imply their errors are
treated equally and the controller balances between them. Op-
tionally, the user can specify additional weights for the actuators,
D=fd1;d2; : : :dpg, where a lower weight indicates changing the
corresponding actuator is preferred to a higher weight actuator. /T_he
controller tries to minimize the sum of the products of actuators
and weights. Because of this, a lower weight would favor the use
of the corresponding actuator, while a higher weight would make
the controller try to avoid the use of the corresponding actuator
unless it is really necessary. As seen in Figure 1a, the results of this
phase are the input quantities that the controller synthesis needs.
Step 2: data collection. For 100/v.altuniformly spaced time inter-
vals (each ‚àÜtapart) our methodology selects values for the vector
a(k)and records /afii10069.italm(k). For each ai2A , we choose either the
minimum value ai;minor the maximum value ai;max. As seen in
Figure 1b, this phase is the /f_irst step towards closing the feedback
loop. Considering that kbelongs to the interval [1 ;100/v.alt], this
data collection lasts for 100 /v.alt‚àÜttime, which isO(/v.alt), a strong im-
provement over previous methods that sweep the entire parameter
space [ 15,16]. Compared to prior work, the resulting models have
less /f_idelity, but the synthesized MPC is robust to these modeling
inaccuracies. As in prior work [ 15], we update the model at runtime
to capture variations.
Step 3: model identi/f_ication. We use subspace identi/f_ication [ 52,
53] to build a linear model based on the data. We build the lowestESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany M. Maggio, A.V. Papadopoulos, A. Filieri, H. HoÔ¨Ämann
Controller
(‚àÜt,W)So/f_tware
SystemA G Gm
(a) End result of step 1 (user input)
Controller
(‚àÜt,W)So/f_tware
SystemA G Gm (b) End result of step 2 (data collection)
Controller
(‚àÜt,W)S(Model)A G Gm
(c) End result of step 3 (model identi/f_ication)
Controller
(‚àÜt,W)S(Model)A G Gm (d) End result of step 4 (controllability test)
Controller
(‚àÜt,W)S(Model)A G Gm
(e) End result of step 5 (MIMO controller synthesis)
Figure 1: Controller synthesis phases. Dashed elements are not yet introduced or exploited at the corresponding stage. For
example, the measurement of Gmare used in Step 2 for the model building phase (Step 3). At the end of Step 3, the So/f_tware
System is replaced with its corresponding model S. In Step 4, the methodology veri/f_ies that the controller can be built and
Step 5 produces the end result and allow the so/f_tware engineer to close the loop.
possible order model that /f_its the data. Selecting a higher order
increases the model‚Äôs accuracy but also increases the chance of
over/f_i/t_ting. On the contrary, a lower order model is less accurate,
but also increases the probability that the resulting models capture
fundamental behavior rather than noise. /T_his noise derives, for
example, from the presence of the operating system routines and
from other applications running at the same time on the hardware.
At this point we have a model of order n. In such a model, the
dynamic system has nstates and a state vector x=[x1;x2; : : :xn].
Notice that xis not a measurable quantity, and not even some
quantity that has a meaningful interpretation for the user, but an
abstract variable that links the inputs to the outputs, and thus,
describes the system‚Äôs dynamics in a compact form. /T_he values of
xmay not correspond to anything measurable in the system.
/T_he subspace identi/f_ication procedure returns a model Sin the
diÔ¨Äerence equation form
S:8><>:x(k+1)=Ax(k)+Ba(k)
/afii10069.italm(k)=Cx(k); (1)
using ‚àÜtas sampling interval (the distance in time between two
subsequent measurements). /T_he time is represented with the le/t_ter
k, that denotes the sampling instants and assumes values in the set
of integers where a number kis the instant t=‚àÜtkin time. /T_he
following steps use Sas a model of the system we want to control.
Figure 1c shows that from here on, in the controller synthesis
procedure, the real so/f_tware is substituted with its model. /T_he
identi/f_ication procedure is completely automatic and no input is
required from the user, if not for the collected data.
Step 4: controllability test. From control theory [ 21], a system
is controllable if the n(pn)matrix
Co=f
B AB An 1Bg
(2)
has rank n, which means that Cohasnindependent columns among
thenptotal columns2. If this condition holds, a controller can drive
2Recall that nis the number of model states and pthe number of goals.all states to any feasible value, in the absence of actuator saturations.
Recall that the output values are linked to the state values by the
second equation in (Eq. 1). /T_hus, if the states can assume any
desired value, then the output can assume any desired value in the
feasible region. In practical terms, if the goal values in Gcan be
reached, a controller can be constructed that will set the actuators
inAto reach them. In the presence of saturations, the goals may
not be reached, but the controller will drive the measurements
as close as possible to the goal. For example, if the user speci/f_ies
a maximum number of virtual machines that can be spawned to
improve the response time of a cloud application, and more than
the maximum number would be necessary to serve all the requests,
the goal is not reached despite the system being controllable , but the
controller will decrease the response time as much as possible with
the given resources. If the system is controllable, the controller we
synthesize in Step 5 will reach all the goals whenever possible [ 32].
If the system is not controllable, we are able to detect it and warn
the user. To solve this problem, one may add other actuators or
reduce the set of goals and re-run the previous steps.
Step 5: MIMO controller synthesis. Based on the model from
Step 3 and on the controllability test from Step 4, we automatically
synthesize a Model Predictive Controller (MPC) [ 4,32,39]. /T_his
controller is complemented with a Kalman Filter (KF) [ 37] to up-
date the system model as the controller runs. MPC is a control
technique that formulates an optimization problem to use the set A
of actuators to achieve the set Gof goals. At every control instant
k, the problem becomes the minimization of a loss function `k,
subject to given constraints. A common approach to guarantee
the removal of the steady state error is to introduce integral action
into the controller [ 32]. /T_his can be done simply by rewriting the
identi/f_ied model (Eq. 1) in the augmented velocity form . Le/t_ting
‚àÜx(k):=x(k) x(k 1),Œæ(k):=f
‚àÜx(k)>/afii10069.italm(k 1)>g>, and
A:="A0np
C I pp#
;B:="B
0p/v.alt#
;C:=f
C I ppg
;Automated Control of Multiple So/f_tware Goals using Multiple Actuators ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany
the augmented velocity form is expressed as:
Sa:8><>:Œæ(k+1)=AŒæ(k)+B‚àÜa(k)
/afii10069.italm(k)=CŒæ(k)(3)
/T_he augmented velocity form is typically used for the formula-
tion of the MPC, since it allows integral action in the loop; i.e., in
practical terms, it guarantees that the controlled system reaches all
the goals when kept constant over time. /T_he system output /afii10069.italm(k)
is unchanged but now expressed with respect to the state variations
‚àÜx(k)and not with respect to the state values x(k). /T_he new model
(Eq. 3) predicts future state values with a time horizon of Lsteps;
i.e.,Ldiscrete time steps from now. /T_he MPC then minimizes the
following cost function
`k=LX
i=1pX
j=1qj
/afii10069.italm;j;k+i /afii10069.italj;k+i2+mX
j=1rj
‚àÜaj;k+i 12;(4)
where qjandrjare positive weights, that respectively represent the
importance of the distance between the j-th goal and the current
value, and the inertia to changing the j-th actuator. /T_he values of
the weights can be chosen as Wgiven by the user in Step 1. When
one or more goal is infeasible (for example because one con/f_licts
with the other), the controller favors the goals with the higher
weights. /T_he values rjindicate preferences on actuators, and is
chosen either as one or the elements of D.
/T_he resulting MPC optimization problem can wri/t_ten as follows.
minimize ‚àÜak+i 1`k (5)
subject to aminak+i 1amax
‚àÜamin‚àÜak+i 1‚àÜamax
/afii10069.italm;min/afii10069.italm;k+i 1/afii10069.italm;max
Œæk+i=AŒæk+i 1+B‚àÜak+i 1
/afii10069.italm;k+i 1=CŒæk+i 1
i=1; : : : ; L:
/T_his formulation is equivalent to a convex /Q_uadratic Programming
(QP) problem [ 32]. /T_he solution of the QP problem has time com-
plexity ofO(L3/v.alt3)[55]. /T_he solution is an optimal plan for the
future ‚àÜa?
k+i 1,i=1; : : : ; L, but typically a receding horizon ap-
proach is adopted, and only the /f_irst action of the plan, i.e.‚àÜa?
k, is
applied. /T_he new control signal is then obtained as
a(k)=a(k 1)+‚àÜa?
k: (6)
/T_he receding horizon principle is particularly important, since the
model (Eq. 1) will never capture all environmental phenomena.
/T_herefore, the plan needs to be recomputed every time new infor-
mation is available. In case of real-time constraints on /f_inding a
solution, it is possible to store the past planned control trajectory
that would have been disregarded, and use it if the solver does not
converge in time.
/T_he MPC strategy assumes that the process state is measurable,
but in many cases this is not possible ‚Äî recall that the system
state has a non-trivial interpretation. Indeed, it is impossible to
measure x(k)directly and so it must be estimated based on /afii10069.italm(k).
To accomplish this, we use a KF that computes an estimate ÀÜx(k+1)ControllerMPC
(Eq. 5)(Eq. 6)So/f_tware
System/afii10069.ital(k) ‚àÜa?(k) a(k) /afii10069.italm(k)
KF
(Eqs. 7‚Äì12)ÀÜx(k)
Figure 2: Control scheme.
of the state x(k+1), as
M(k)=P(k)C>
CP (k)C>+Rn 1(7)
e(k)=/afii10069.italm(k) CÀÜx(k) (8)
x(k)=ÀÜx(k)+M(k)e(k) (9)
P(k)=(I M(k)C)P(k) (10)
ÀÜx(k+1)=Ax(k)+Ba (k) (11)
P(k+1)=AP(k)A>+BQnB>(12)
where (Eqs.7‚Äì10) update the KF with the new information from the
prediction error e(k)in (Eq.8), and (Eqs.11‚Äì12) compute a predic-
tion of the system‚Äôs state and of the covariance matrix P.M(k)is
also called Kalman gain, and adapts over time depending on the
magnitude of the prediction error e[37]. /T_he estimate ÀÜx(k)can be
used, in place of Œæ(k), to solve the optimization problem in (Eq. 5).
Figure 2 shows the block diagram for the resulting control scheme.
/T_he controller is then executed every ‚àÜttime units. Summarizing,
the control design is performed by using the identi/f_ied matrices of
the model (Eq. 1), and by choosing appropriate weights for the cost
function, i.e.,qjandrj. /T_he Kalman /f_ilter is designed on the basis of
the identi/f_ied model and keeps said model updated during runtime.
Step 5 produces the python code for the MPC, which should be
complemented with the code used to obtain the measured values
of the goals and apply the actuators values.
Discussion. To apply this methodology, users must provide sen-
sors that measure behavior for any goals the controller should meet.
/T_hese sensors usually take the form of methods that return some
system property; e.g., performance or power. Users must also pro-
vide a list of actuators and their minimum and maximum values.
/T_hese actuators are, again, usually methods that changes some key
parameter; e.g., the strength of a /f_ilter. For the methodology to
work, the number of goals (and thus sensors) must, in general, be
less than or equal to the number of actuators. Similarly, if the actu-
ators cannot be used to meet the goals ( i.e., the controllability test
fails), our methodology reports this to the users who must either
add actuators or change goals. /T_he methodology assumes that actu-
ator se/t_tings are continuous between the minimum and maximum
se/t_tings. If the actuators are discrete, then users can either choose
the closest discrete se/t_ting or approximate the continuous value
by time averaging diÔ¨Äerent actuators se/t_tings. Our experiments
include examples of both approaches (Sections 5.2 and 5.3). Im-
portantly, we note that this methodology does not assume linear
functions mapping actuator se/t_tings to goals. /T_he Kalman /f_ilter is
added speci/f_ically to account for complex actuation mechanisms: it
continually computes an optimal estimate of the underlying system
state, as measurable by the sensors. /T_his process of continual stateESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany M. Maggio, A.V. Papadopoulos, A. Filieri, H. HoÔ¨Ämann
estimation makes the controller robust to inaccuracies in the system
identi/f_ication process. To demonstrate this robustness, all three case
studies in the evaluation section include actuators with complex,
non-linear interactions. Additional stress tests that evaluate more
complex actuation functions (including cosine and higher-order
polynomials, which we have never observed in real so/f_tware) are
available with our code release.
Implementation. We provide an implementation that automati-
cally generates the controller code in Python and C++, which we
use for our case studies. /T_he user does not need to provide more
than the weights, the bounds on the actuators and the actuate and
sense functions that interact with the so/f_tware. We implemented
Step 3, 4 and 5 in Matlab. /T_he subspace identi/f_ication procedure
relies on the Matlab function n4sid , using as parameters the given
data and the keyword best for the model order. In this way, the
model‚Äôs order is the one that best approximate the data obtained
during the experimental phase in the range between one and ten.
4 FORMAL ASSESSMENT
Applying control theory in so/f_tware systems provides a set of formal
guarantees about the so/f_tware‚Äôs response to dynamic changes [ 17].
/T_he MPC presented in this work belongs to the class of optimal
controllers , since control decisions are based on the solution of an
optimization problem [ 32]. In particular, adopting the model predic-
tive approach allows us to provide a number of formal guarantees.
Convergence to the objectives. MPCs generated by our method-
ology ensure that all goals are reached, when they are reachable [32];
i.e., if there are actuator se/t_tings that achieve the goals within the
given constraints (Eq. 5), then the MPC will /f_ind them. Conver-
gence is proven by observing that whenever there exists a feasible
actuator con/f_iguration, the MPC optimization problem is equivalent
to the unconstrained optimization problem that minimizes `k[32].
/T_he values for the actuators‚Äô variation are ‚àÜa?
k=argmina`k.
Considering the gradient of (Eq. 4), the closed-form solution is
ra`k=2H‚àÜa+2FŒæ, where HandFare functions of qj,rjand
the dynamic matrices of the system (Eq. 3). /T_he gradient has a
minimum forra`k=0, which corresponds to ‚àÜa?= H 1FŒæ(k),
where ‚àÜa?is a vector containing the optimal plan for the future
‚àÜa?
k+i 1,i=1; : : : ; L. In the MPC case, only the /f_irst element of
the plan is applied.
/T_he controller can thus be expressed as a matrix multiplied by
the current state value Œæ(k)asa(k)=ŒìŒæ(k). /T_hus, the closed-loop
system dynamics (Eq. 3) can be rewri/t_ten as follows.
Œæ(k+1)=(A+Œì)Œæ(k)
/afii10069.italm(k)=CŒæ(k)
Assume, without loss of generality, that all goals are zero, /afii10069.ital(k)=
0. A well known result says that the steady-state error converges
to zero if and only if all eigenvalues of A+Œìhave magnitudes
less than unity [ 32]. If qjin (Eq. 4) are all positive (required by
our methodology), the eigenvalues of A+Œìalways lie in the unit
circle in the complex plane. /T_his property guarantees stability and
convergence to the objective when it is reachable with the actuators
supplied by the user.
Minimum distance for infeasible cases. If the goals are not
reachable, the MPC /f_inds actuator se/t_tings that minimize the overall
steady state error. /T_he de/f_inition of ‚Äúcloseness‚Äù depends on the
weights for each term of the cost function (Eq. 4) ‚Äì a solution iscloser to the desired one when it minimizes the cost function [ 32].
/T_he minimum distance depends on qj. Since diÔ¨Äerent values of qj
yield diÔ¨Äerent quantitative solutions, the choice of qjis used to
enforce the prioritization of the goals.
Minimum convergence time. /T_he dynamic model in (Eq. 1) re-
lates control parameters and outputs to time. /T_he optimization
problem /f_inds the best trajectory converging to the goals, according
to the selected cost function `k. By construction, the cost function
penalizes all the time instants when /afii10069.italmis not equal to the goal /afii10069.ital,
therefore the MPC leads to a minimum se/t_tling time solution.
Real-Time Computation. Since the proposed solution solves an
optimization problem at each control instant, it is critical to discuss
timing issues that could prolong the controller‚Äôs execution. In
some cases, the time required for computing the next control action
might be longer than the time between two subsequent control
actions. To address this issue, there is a vast literature in the control
community on how to implement fast solvers ( e.g., [29,48]). /T_he
area has been explored especially when these solvers are part of
embedded systems [ 28,31]. For an overview on the ma/t_ter see [ 60].
O/f_ten, such advanced algorithms are not required when deal-
ing with so/f_tware components. For example, one can set ‚àÜak+1=
‚àÜak+2=: : :=‚àÜak+L 1=0 and solve the optimization problem
for‚àÜak, which is the only one that will actually be applied at time
k. /T_his modi/f_ication reduces the complexity to be just O(/v.alt3). An-
other approach exploits interior point algorithms, which iteratively
update a feasible, but sub-optimal, solution to the constraints. If the
iteration did not converge before a new control action is required,
it can be forced to stop and return the current sub-optimal solution.
Finally, another possibility to deal with real-time deadlines is ex-
ploiting the MPC‚Äôs proactive nature. At each time step, the MPC
computes a plan of future actions ‚àÜak+i 1,i=1; : : : ; L. Accord-
ing to the receding horizon principle, only the /f_irst one is applied;
i.e.,‚àÜa(k)=‚àÜa?
k. Assuming that at the next control instant the
solver takes more time to converge and that a new control action
is required before the optimal solution is found, one can store the
previously computed plan and apply the second control action; i.e.,
‚àÜa(k+1)=‚àÜa?
k+1. Doing so is obviously sub-optimal, but ful/f_ills
real-time deadlines and execution constraints.
5 EXPERIMENTAL EVALUATION
In this section we present the application of the proposed method-
ology to three diÔ¨Äerent case studies: the /f_irst case study is based on
a video encoder, the second on a radar positioning system and the
third one on a dynamic binder. Finally, we also show some results
about the real-time computation and the overhead of the control
signal generation.
5.1 Video Compression
Prior work demonstrated automatic synthesis of a single-input,
single-output controller for lossy video compression [ 15]. We ex-
tended this case study to achieve multiple goals using multiple
actuators and made it available for comparison with other tech-
niques [42, 43].
/T_he actuatorsAare:
a1, the same quality parameter used in [ 15] to specify the
compression density. It ranges between a1;min=1 and a1;max=
100, where 100 preserves all frame details and 1 produces the
highest compression. We specify a weight d1=1000.Automated Control of Multiple So/f_tware Goals using Multiple Actuators ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany
0.70.80.9SSIM/afii10069.italm1 /afii10069.ital1
08k11k15ksize/afii10069.italm2 /afii10069.ital2
140.80qualitya1
020.4sharpena2
0 20000 40000020.4noisea3
(a)/afii10069.ital1=0:7and/afii10069.ital2=8000
0.70.80.9SSIM/afii10069.italm1 /afii10069.ital1
08k11k15ksize/afii10069.italm2 /afii10069.ital2
140.80qualitya1
020.4sharpen a2
0 20000 40000020.4noisea3 (b)/afii10069.ital1=0:8and/afii10069.ital2=8000
0.70.80.9SSIM/afii10069.italm1 /afii10069.ital1
08k11k15ksize/afii10069.italm2 /afii10069.ital2
140.80qualitya1
020.4sharpen a2
0 20000 40000020.4noisea3 (c)/afii10069.ital1=0:9and/afii10069.ital2=8000
0.70.80.9SSIM/afii10069.italm1 /afii10069.ital1
08k11k15ksize/afii10069.italm2 /afii10069.ital2
140.80qualitya1
020.4sharpena2
0 20000 40000020.4
framenoisea3
(d)/afii10069.ital1=0:7and/afii10069.ital2=15000
0.70.80.9SSIM/afii10069.italm1 /afii10069.ital1
08k11k15ksize/afii10069.italm2 /afii10069.ital2
140.80qualitya1
020.4sharpena2
0 20000 40000020.4
framenoisea3 (e)/afii10069.ital1=0:8and/afii10069.ital2=15000
0.70.80.9SSIM/afii10069.italm1 /afii10069.ital1
08k11k15ksize/afii10069.italm2 /afii10069.ital2
140.80qualitya1
020.4sharpena2
0 20000 40000020.4
framenoisea3 (f)/afii10069.ital1=0:9and/afii10069.ital2=15000
Figure 3: Results for the video experiment.
a2, the sharpen parameter, which speci/f_ies the size of a sharp-
ening /f_ilter to be applied to the image. /T_he size ranges between
a2;min=0 and a5;max=5 where 0 indicates no sharpening. We
select a weight d2=100000 for this actuator. Given its reduced
range compared to a1, we would like to use it less.
a3,noise , which speci/f_ies the size of a noise reduction /f_ilter,
which also varies between a3;min=0 and a3;max=5. We
specify a weight d3=100000, equivalent to sharpen .
/T_he goalsGinclude:
/afii10069.ital1, the SSIM [ 56] that quanti/f_ies the similarity between the
original and compressed frames. SSIM is a unitless metric that
ranges from 0 to 1, with near 1 indicating similar images. As
SSIM is between 0 and 1, we use weight w1=1000 so that
the corresponding component of the cost function /J.altis in the
hundreds;
/afii10069.ital2, the frame size (in kilobytes). We use a weight w2=0:0001 so
this second goal is considered slightly more important than the/f_irst. When the controller can reach only one goal, we prefer
to hit the size target, making communication predictable.
Clearly, these two goals con/f_lict with one another. When a speci/f_ic
frame size is set, this will correspond to a speci/f_ic value for the
SSIM on the frame. Similarly, if a speci/f_ic SSIM is reached, the
corresponding frame will have a prescribed size. We conduct this
test to show how the controller trades oÔ¨Ä a goal for the other to
achieve the optimal value for the cost function.
We run the video compression example using the Obama Victory
Speech video3with a resolution of 854 480 pixels and with diÔ¨Äerent
combinations of goals /afii10069.ital1and/afii10069.ital2, using a prediction horizon of
L=4. Speci/f_ically, we run all possible combinations where /afii10069.ital12
f0:7;0:8;0:9gand/afii10069.ital22f8000;15000g. Notice that this is a stress
test. In fact, even se/t_ting the values of quality, sharpen and noise
that would achieve the lowest possible SSIM, this value hardly ever
3h/t_tps://www.youtube.com/watch?v=nv9NwKAjmt0ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany M. Maggio, A.V. Papadopoulos, A. Filieri, H. HoÔ¨Ämann
becomes lower than 0 :75, therefore the 0 :7 setpoint is not feasible.
Also, the goals‚Äô con/f_licting nature makes it impossible to reach most
goal combinations simultaneously. For example, when /afii10069.ital1=0:9,
the frame size o/f_ten exceeds 15000.
Figure 3 shows the six diÔ¨Äerent experiments with the diÔ¨Äerent
values of/afii10069.ital1and/afii10069.ital2. In these experiments, there are only two feasible
values for the setpoints: (1) /afii10069.ital1=0:8 and/afii10069.ital2=8000 (Figure 3b) and
(2)/afii10069.ital1=0:9 and/afii10069.ital2=15000 (Figure 3f). In all others it is impossible
to achieve both the SSIM and frame size setpoints. /T_herefore, as
shown in the /f_igures, the controller opts to reach /afii10069.ital2, which has an
higher relevance: w2/afii10069.ital2. In the /f_irst row, Figure 3a shows that /afii10069.ital2
and/afii10069.italm2are basically equal, while the achieved SSIM /afii10069.italm1is higher
than desired. /T_he encoding quality a1is kept low and there is no
active noise compensation, while the sharpen value a2varies during
the execution. Figure 3b shows that both the SSIM and the size
setpoint are achieved using some sharpening, a small amount of
noise reduction, and a quality similar to that used for the previous
combination of setpoints. When the SSIM goal is increased ‚Äì so,
information loss should be diminished ‚Äì even more noise correction
and sharpening is added, as shown in Figure 3c. /T_he setpoint /afii10069.ital1is
reached for some frames, but overall the size limit (and its heavier
weight in the cost function) leads to SSIM below the setpoint.
Figures 3d, 3e and 3f show the goal /afii10069.ital1=0:9 and/afii10069.ital2=15000
can be achieved by selecting the values of a1,a2anda3and the
controller therefore selects appropriate values to achieve both the
setpoints. In the opposite case ( Figures 3d and 3e) the size setpoint
is achieved, while the similarity index is kept as close as possible.
5.2 Secure Radar System
/T_his second case study features a cyber-physical system: a secure
radar. /T_he radar moves on a mobile platform, possibly a drone, and
detects small boats that may be pirates [ 11]. Once the radar has
compiled a list of possible pirates, it encrypts it using the Advanced
Encryption Standard (AES) [ 6], and sends it to a centralized location
where multiple lists are merged. Encryption is necessary to avoid
providing information on whether pirates have been detected.
/T_he secure radar must meet performance goals for both the radar
and the encryption. /T_he /f_irst goal is to ensure that the so/f_tware
processes frames at the same rate as the sensor produces them, the
second is to ensure timely delivery to the central entity that merges
the lists. We meet these goals with two actuators: the number of
cores allocated to the radar system (all additional cores can be used
by encryption) and the processor‚Äôs clockspeed.
Speci/f_ically, the set of actuators Aconsists of:
a1is the number of cores assigned to the radar signal processing
application. We measure this as a percentage of the available
cores, and our test platform has 12. We assume a minimum
of one core must be assigned to the radar. We therefore set
a1;min=1=12 and a1;max=1, any cores not used by the radar
processing can be used by encryption. We assign d1=1.
a2is a single clock speed to be used for the processor. Our
platform, in fact, does not allow us to set a clock speed per core.
We measure this value as a percentage, where the hardware
supports a minimum speed of 1.6 GHz and a maximum speed of
3.201 GHz4,a2;min=0:499 and a2;max=1. We assign d2=1,
4Technically, se/t_ting the maximum speed turns frequency control over to hardware
which can use Intel‚Äôs TurboBoost to occasionally increase speed beyond the listed
maximum for brief periods of time.
5100.15RP
[pulses/s]/afii10069.italm1 /afii10069.ital1
5100.15ER
[MB/s] /afii10069.italm2 /afii10069.ital2
0.050.100.15cores
[%]a1
50 100 1500.500.700.90
control periodsspeed
[%]
a2Figure 4: Results for the radar experiment.
since we do not want to enforce any actuators precedence.
/T_he set of goalsGincludes:
/afii10069.ital1, the Radar Performance (RP) measured in radar pulses pro-
cessed per second. We use an existing radar benchmark [ 11],
which can operate in many diÔ¨Äerent processing modes. For this
case study we con/f_igure the radar so that it needs to process 10
pulses per second to keep pace with the sensor. Also, w1=1.
/afii10069.ital2, the Encryption Rate (ER) of the AES so/f_tware. We use
OpenAES5for encryption and we measure its rate in MB/s.
For each possible pirate in each pulse we need to maintain
an encryption rate of approximately 0 :8 MB/s. To keep up
with the radar, we need 8 MB/s per target; i.e.the required
encryption rate will vary as the number of targets changes. Our
control system treats this as a change in setpoint and handles it
automatically. Finally, we set w2=1 to not privilege any goal.
/T_he combination of actuators and goals used in this case study
demonstrates one of the key bene/f_its of the proposed approach.
Prior work presented a similar case study of a secure radar system
[16]. /T_hat case study used a hierarchical control scheme to imple-
ment MIMO control and required that both cores and clockspeed
be used to manage the radar‚Äôs performance. /T_his policy leaves no
system-level actuators for encryption, which instead is required to
switch to a shorter, and less secure, key length to meet encryption
performance requirements. In contrast, the technique presented
in this paper allows actuators to be used to meet multiple goals.
Speci/f_ically, clockspeed will be used to meet both goals, meaning
that we do not need to reduce security to maintain encryption
performance using the proposed technique.
We run the secure radar with the speci/f_ied goals and actuators
and a prediction horizon of L=5. It must maintain a radar perfor-
mance of 10 pulses/s. Initially, the radar detects a single possible
pirate, which requires an encryption performance of 8 MB/s. A/f_ter
100 control periods, a second possible pirate is detected. /T_his addi-
tional target does not aÔ¨Äect the radar performance (the same signal
processing algorithms are used), but it requires the encryption
performance to rise to 16 MB/s.
Figure 4 shows the results of this case study. /T_here are four
charts, the top shows the radar performance, the second shows
AES performance, the third shows the percentage of cores assigned
5h/t_tp://nalramli.com/OpenAES/Automated Control of Multiple So/f_tware Goals using Multiple Actuators ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany
to the radar, and the /f_inal chart shows the percentage of the maxi-
mum clockspeed used. Solid red horizontal lines show the /afii10069.ital1and/afii10069.ital2
for each of the radar and AES; /afii10069.ital1is a constant and /afii10069.ital2changes when
the second target is detected. As shown in the /f_igure, the controller
meets both goals, quickly pulling performance down to the desired
level for each goal. When the second possible pirate appears, the
controller reacts by both increasing clockspeed (which increases
performance for both applications) and removing one core from
the radar, making it available to AES. As noted above, this use
of actuators that aÔ¨Äect both goals simultaneously is not possible
with prior approaches like [ 16,50]. /T_his demonstrated ability to
meet multiple goals simultaneously with multiple actuators is a
unique contribution of our approach. We note that there is some
small amount of oscillatory behavior here due to our use of discrete
actuators in this example. /T_here are 12 cores and 12 clockspeeds in
the system and when the controller produces a continuous actua-
tion value, we select the highest discrete se/t_ting above that value.
/T_herefore, this example also demonstrates the methodology works
even with discrete actuators.
5.3 Multi-Objective Dynamic Binding
Dynamic binding is a critical means of adapting Service Oriented
Applications (SOAs) [ 7]. /T_he binding mechanism selects a service
to process an incoming request from a set of functionally equivalent
alternatives, based on quality criteria. In this experiment, we adopt
the same se/t_tings of [ 16];i.e., the controller has three goals in
diÔ¨Äerent, con/f_licting, dimensions: reliability, performance, and cost.
/T_he controller binds each request to one of three services, and
for each service it decides among /f_ive diÔ¨Äerent service levels. A
higher service level reduces the response time (performance) at a
higher cost. Also, we use this case study to show how the solution
scales with the size of the problem. /T_he controller uses a prediction
horizon of L=100. Given the prediction horizon and the size of
the involved matrices, we expect the overhead of the controller
execution to be quite high. Because of that, we also executed the
controller with the real-time optimization mentioned in Section 4
(se/t_ting ‚àÜak+1=‚àÜak+2=: : :=‚àÜak+L 1=0), to show the
diÔ¨Äerence in the resulting trace. In the following we distinguish
between the MPC solution and the MPC fast solution, which uses
the real-time optimization.
More precisely, the set of actuators Ais speci/f_ied as follows.
a1is the fraction of requests to be served by Service 1. a1;min=
0:0,a1;max=1:0,d1=100 (MPC) and d1=2000 (MPC fast).
a2is the fraction of requests to be served by service 2, among
those not served by implementation 1; i.e., Service 2 will serve
a fraction a2(1 a1)of the incoming requests. a2;min=0:0,
a2;max=1:0,d2=100 and d1=2000 for MPC fast. Service 3
will serve (1 a2)(1 a1)requests. While a linear selection
model can be de/f_ined, we deliberately used this more complex
selection model (from [ 16]) to demonstrate how the controller
handles nonlinear transfer functions by automatic, higher-order
linear approximations.
a3is the service level requested to Service 1. a3;min=1,
a3;max=5,d3=1 for the MPC solution and d3=20 for
MPC fast. /T_he service levels are integer numbers. /T_he con-
troller computes a real value; this value is approximated using
a pulse width modulation [ 36] over an actuation window of 4
time steps. For example, if the reference is 3.73, the actuatorwill hold level 4 for three steps and level 3 for one step, obtain-
ing an average of 3.75 over the actuation window, which is the
closest achievable approximation. /T_he feedback mechanism
will take care of the approximation error automatically. /T_he
same approximation is used also for a4anda5.
a4is the service level requested to Service 2 a4;min=1,a4;max=
5,d4=1 for the MPC solution and d4=20 for MPC fast.
a5is the service level requested to Service 3 a5;min=1,a5;max=
5,d5=1 for the MPC solution and d5=20 for MPC fast.
/T_he goals in [ 16] are prioritized: the controller achieves the
reliability goal /f_irst, then performance, and /f_inally minimizes the
cost in best eÔ¨Äort. /T_he proposed MPC controller has no notion
of priority, thus we will set the weight of each goal to practically
approximate the prioritization scheme of [ 16]. More precisely, the
set of goalsGis the following:
/afii10069.ital1is the user-perceived reliability, de/f_ined as the fraction of
requests served successfully over those received since the last
control decision. /T_he weight associated to this goal is w1=10
/afii10069.ital2is the performance, quanti/f_ied by the end-to-end response
time (in milliseconds). To quantify the error, we measure the av-
erage response time since the last control decision. /T_he weight
of/afii10069.ital2isw2=10 1
/afii10069.ital3is the cost (in 10 2$). In [ 16], the cost is a free dimension to
be minimized in best eÔ¨Äort. To emulate this minimization goal,
we will set /afii10069.ital3close to 0 (non zero to avoid numerical issues);
to approximate the best eÔ¨Äort priority, we give the goal a low
weight: w3=10 10.
Each service is con/f_igured by three parameters: nominal reliabil-
ityri, performance coeÔ¨Écient ti, and cost coeÔ¨Écient ci. For each
incoming request, the service implementation /f_lips a fair coin to
decide whether to raise an exception or not, according to the nomi-
nal reliability ri. /T_he processing time for each request is sampled
from an exponential distribution with mean ti=(l2
i)where liis the
service level at the time of request processing. Notably, the time
required to process the request is an inverse quadratic function of
the service level, introducing another nonlinearity in the transfer
function. /T_he cost of processing an incoming request is cili. /T_he
nominal values ri,ti, and ciare not known by the controller, which
can only measure: the time to process a request, how many requests
are successful or raise an exception, and the cost of each request.
/T_he experimental results are shown in Figure 5. /T_he con/f_igura-
tion parameters of the three services are the following: fr1=:9;t1=
2;c1=15g,fr2=:65;t2=10;c2=10g,fr2=:45;t2=20;c2=5g.
/T_he experiments last 800 control periods. /T_he setpoints for reli-
ability and performance are changed during the experiment. In
the period 0-300, /afii10069.ital1and/afii10069.ital2are feasible and achieved with minimal
cost; similarly in 300-420, where the reliability setpoint changed.
In the period 420-650, an infeasible goal is requested for reliability
and the controller goes as close as possible to its satisfaction, while
achieving the performance goal. At time 520, the required response
time is reduced; the controller achieves this harder goal, though at
a higher cost. Finally, in the period 650-800 the reliability goal is
also raised; the high reliability and low response time are achieved,
though with an higher cost. Finally, as a comparison between the
MPC and the MPC fast solution, one can see the diÔ¨Äerence in the
cost (the last plot of Figure 5), around the control period 650, when
the cost for the solution presented in [ 16] is the highest of the three,
followed bu the non-optimal solution computed by the the MPCESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany M. Maggio, A.V. Papadopoulos, A. Filieri, H. HoÔ¨Ämann
050100Rel.
[%]/afii10069.ital1;2;3 /afii10069.italm1;2;3[16]
/afii10069.italm1;2;3 MPC /afii10069.italm1;2;3 MPC fast
04.50.9Perf.
[ms]
300 420 520 650 8000150.30
control periodsCost
[10 2$]
Figure 5: Results for the multi-objective dynamic binder ex-
periment.
fast solver. /T_he best of the three costs is the one achieved by the
MPC solution presented in this paper.
As a comparison, the performance of the controller from [ 16] is
also reported in Figure 5. Due to its global optimization capabilities,
the MPC controller achieves the reliability and performance goals
with a minor cost. /T_he total cost for the solution presented in [ 16] is
138:49$, for the MPC solution is 124 :82$ and for the MPC fast solu-
tion is 130 :76$, which corresponds to a save of 1 :7110 2$ per time
istant for the MPC solution ‚Äì 9 :87% cheaper ‚Äì and of 0 :9710 2$ for
MPC fast ‚Äì 5 :59% cheaper. Indeed, trying to achieve the three goals
with a cascade schema, according to the prioritization, [ 16] can-
not guarantee global optimality on all the three dimensions at the
same time. Finally, the MPC controller synthesis requires a much
smaller learning time, exploring only a small number of system
con/f_igurations. Notably, [ 16] uses an online learning mechanism,
which can detect changes in the services‚Äô performance and adapt
the controller online. While in this paper we focus on a static model
construction, recursive state space identi/f_ication [ 37] can be used
to re/f_ine the model online, as well as using the measurements from
the running system to train a new state space model in parallel and
switching when a change is detected [14].
5.4 Control Computation Overhead
Finally, we analyze the cost to compute the control signal for the
three given case studies. Figure 6 shows the empirical distribution
of the computation times for 10000 executions of the controller
code and Table 1 reports some statistics. As can be seen, the video
and radar case studies‚Äîpresented respectively in Section 5.1 and
5.1‚Äîare quite fast, with computation times less than 10 ms. On the
contrary, the optimal solution for the dynamic binding case study‚Äî
presented in Section 5.3‚Äîtakes a quarter of a second. Indeed, the
dynamic binding problem is costlier because of the longer prediction
horizon. Due to the longer execution times, the dynamic binder is
a good case study for the optimizations discussed in Section 4‚Äîin
particular, constraining the solver to /f_ind a solution for the current
time only while se/t_ting the actuator changes for future time instants
in the prediction horizon to zero. /T_he faster solution is not optimal,
as shown in Figure 5‚Äîbut it trades optimality for computation
time. In fact, the computation times for the MPC fast algorithm
is comparable with the times obtained for the other case studies,
where the problem size is much smaller.Table 1: Statistics on Ovehread Data.
Case Study Average [s] Standard Deviation [s]
Video 0.00305 0.00074
Radar 0.00471 0.00091
Dynamic Binder 0.20030 0.02332
Dynamic Binder (fast) 0.00184 0.00036
0.002 0.006 0.0100.000.501.00
overhead [s]Video
0.002 0.006 0.0100.000.501.00
overhead [s]Radar
0.0 0.1 0.2 0.3 0.4 0.50.000.501.00
overhead [s]Dynamic Binder
0.002 0.006 0.0100.000.501.00
overhead [s]Dynamic Binder (fast)
Figure 6: Empirical distribution of the duration of the con-
trol signal computation for given case studies.
Whenever a lower computation time is required, the optimiza-
tion can be turned on with a boolean /f_lag in the code for the con-
troller initialization, making our proposal /f_lexible and capable of
accommodating diÔ¨Äerent requirements and execution scenarios.
6 CONCLUSION
We propose a formal method to design self-adaptive so/f_tware ca-
pable of targeting multiple objectives simultaneously. Unlike prior
work, our approach exploits all the available tuning parameters that
aÔ¨Äect the so/f_tware behavior. Our method is based on system identi-
/f_ication and control theory. /T_hrough experimentation, it builds an
equation-based model of the so/f_tware system and uses that model
to automatically synthesize a model predictive controller. /T_he use
of control theory allows us to distinguish between feasible and
infeasible objectives, and formally guarantee that the goals are
reached whenever feasible. Compared with the state of the art,
this is the /f_irst contribution that simultaneously uses all available
actuators to tackle all objectives.
We combined the theoretical guarantees with tests on diÔ¨Äerent
domains, from dynamic binding to radar positioning and video
compression. In all our case studies, our proposal has shown that
the method is functional and versatile. From the technical stand-
point, this advancement opens new perspective because it formally
exploits the actuators‚Äô inter-dependencies on multiple goals.
ACKNOWLEDGEMENTS
/T_his work was partially supported by the Swedish Research Council
(VR) for the projects ‚ÄúCloud Control‚Äù and ‚ÄúPower and tempera-
ture control for large-scale computing infrastructures‚Äù, and by the
Swedish Foundation for Strategic Research under the project ‚ÄúFu-
ture factories in the cloud (FiC)‚Äù with grant number GMT14-0032.
Henry HoÔ¨Ämann‚Äôs work on this project was partially funded by the
U.S. Government under the DARPA BRASS program, by the Dept.
of Energy under DOE DE-AC02-06CH11357, by the NSF under CCF
1439156, and by a DOE Early Career Award.Automated Control of Multiple So/f_tware Goals using Multiple Actuators ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany
REFERENCES
[1]Konstantinos Angelopoulos, Alessandro Vi/t_torio Papadopoulos, V ¬¥ƒ±tor E.
Silva Souza, and John Mylopoulos. Model predictive control for so/f_tware systems
with cobra. SEAMS ‚Äô16, pages 35‚Äì46. ACM, 2016.
[2] Luciano Baresi, Sam Guinea, Alberto Leva, and Giovanni /Q_ua/t_trocchi. A discrete-
time feedback controller for containerized cloud applications. In Proceedings of
the 2016 11th Joint Meeting on Foundations of So/f_tware Engineering , FSE 2016,
2016.
[3] Yuriy Brun, Giovanna Marzo Serugendo, Cristina Gacek, Holger Giese, Holger
Kienle, Marin Litoiu, Hausi M ¬®uller, Mauro Pezz ¬¥e, and Mary Shaw. Engineering
self-adaptive systems through feedback loops. In So/f_tware Engineering for Self-
Adaptive Systems , pages 48‚Äì70. 2009.
[4] E.F. Camacho and C. Bordons. Model Predictive Control . Springer London, 2004.
[5] Be/t_ty Cheng, Rogerio de Lemos, Holger Giese, Paola Inverardi, JeÔ¨Ä Magee, Jesper
Andersson, Basil Becker, Nelly Bencomo, Yuriy Brun, Bojan Cukic, Giovanna
Di Marzo Serugendo, Schahram Dustdar, Anthony Finkelstein, Cristina Gacek,
Kurt Geihs, Vincenzo Grassi, Gabor Karsai, Holger Kienle, JeÔ¨Ä Kramer, Marin
Litoiu, Sam Malek, RaÔ¨Äaela Mirandola, Hausi M ¬®uller, Sooyong Park, Mary Shaw,
Ma/t_thias Tichy, Massimo Tivoli, Danny Weyns, and Jon Whi/t_tle. So/f_tware engi-
neering for self-adaptive systems: A research roadmap. In So/f_tware Engineering
for Self-Adaptive Systems . Springer, 2009.
[6] Joan Daemen and Vincent Rijmen. /T_he Design of Rijndael . Springer-Verlag New
York, Inc., Secaucus, NJ, USA, 2002.
[7] Elisabe/t_ta Di Ni/t_to, Carlo Ghezzi, Andreas Metzger, Mike Papazoglou, and Klaus
Pohl. A journey to highly dynamic, self-adaptive service-based applications.
Automated So/f_tware Engineering , 15(3-4):313‚Äì341, 2008.
[8] Yixin Diao, Joseph L. Hellerstein, Sujay Parekh, Rean GriÔ¨Éth, Gail Kaiser, and
Dan Phung. Self-managing systems: A control theory foundation. ECBS. IEEE
CS, 2005.
[9] Nicolas D‚ÄôIppolito, V ¬¥ƒ±ctor Braberman, JeÔ¨Ä Kramer, JeÔ¨Ä Magee, Daniel Sykes, and
Sebastian Uchitel. Hope for the best, prepare for the worst: Multi-tier control for
adaptive systems. In Proceedings of the 36th International Conference on So/f_tware
Engineering , ICSE 2014, pages 688‚Äì699, New York, NY, USA, 2014. ACM.
[10] Xavier Dutreilh, Aur ¬¥elien Moreau, Jacques Malenfant, Nicolas Rivierre, and Isis
Truck. From data center resource allocation to control theory and back. CLOUD,
pages 410‚Äì417. IEEE CS, 2010.
[11] Anne Farrell and Henry HoÔ¨Ämann. Meantime: Achieving both minimal energy
and timeliness with approximate computing. In 2016 USENIX Annual Technical
Conference (USENIX ATC 16) , pages 421‚Äì435, Denver, CO, June 2016. USENIX
Association.
[12] Antonio Filieri, Carlo Ghezzi, Alberto Leva, and Martina Maggio. Self-adaptive
so/f_tware meets control theory: A preliminary approach supporting reliability
requirements. ASE, pages 283‚Äì292. IEEE CS, 2011.
[13] Antonio Filieri, Carlo Ghezzi, and Giordano Tamburrelli. Run-time eÔ¨Écient
probabilistic model checking. In Proceedings of the 33rd International Conference
on So/f_tware Engineering , ICSE ‚Äô11, pages 341‚Äì350, New York, NY, USA, 2011.
ACM.
[14] Antonio Filieri, Lars Grunske, and Alberto Leva. Lightweight adaptive /f_iltering
for eÔ¨Écient learning and updating of probabilistic models. In Proceedings of the
37th International Conference on So/f_tware Engineering , ICSE 2015, pages 200‚Äì211.
IEEE, May 2015.
[15] Antonio Filieri, Henry HoÔ¨Ämann, and Martina Maggio. Automated design of
self-adaptive so/f_tware with control-theoretical formal guarantees. In Proceedings
of the 36th International Conference on So/f_tware Engineering , ICSE, pages 299‚Äì310,
New York, NY, USA, 2014. ACM.
[16] Antonio Filieri, Henry HoÔ¨Ämann, and Martina Maggio. Automated multi-
objective control for self-adaptive so/f_tware design. In Proceedings of the 2015
10th Joint Meeting on Foundations of So/f_tware Engineering , ESEC/FSE 2015, pages
13‚Äì24, New York, NY, USA, 2015. ACM.
[17] Antonio Filieri, Martina Maggio, Konstantinos Angelopoulos, Nicolas D‚ÄôIppolito,
Ilias Gerostathopoulos, Andreas Hempel, Henry HoÔ¨Ämann, Pooyan Jamshidi,
Evangelia Kalyvianaki, Cristian Klein, Filip Krikava, Sasa Misailovic, Alessan-
dro Vi/t_torio Papadopoulos, Suprio Ray, Molzam Shari/f_loo, Amir, Stepan Shevtsov,
Mateusz Ujma, and /T_homas Vogel. So/f_tware Engineering Meets Control /T_heory.
InProceedings of the 10th International Symposium on So/f_tware Engineering for
Adaptive and Self-Managing Systems , Firenze, Italy, May 2015.
[18] Antonio Filieri, Martina Maggio, Konstantinos Angelopoulos, Nicol ¬¥as D‚Äôippolito,
Ilias Gerostathopoulos, Andreas Berndt Hempel, Henry HoÔ¨Ämann, Pooyan
Jamshidi, Evangelia Kalyvianaki, Cristian Klein, Filip Krikava, Sasa Misailovic,
Alessandro V. Papadopoulos, Suprio Ray, Amir M. Shari/f_loo, Stepan Shevtsov,
Mateusz Ujma, and /T_homas Vogel. Control strategies for self-adaptive so/f_tware
systems. ACM Trans. Auton. Adapt. Syst. , 11(4):1‚Äì31, February 2017.
[19] Antonio Filieri, Giordano Tamburrelli, and Carlo Ghezzi. Supporting self-
adaptation via quantitative veri/f_ication and sensitivity analysis at run time.
IEEE Transactions on So/f_tware Engineering , 42(1):75‚Äì99, January 2016.
[20] H. Ghanbari, M. Litoiu, P. Pawluk, and C. Barna. Replica placement in cloud
through simple stochastic model predictive control. In Cloud Computing (CLOUD),
2014 IEEE 7th International Conference on , pages 80‚Äì87, June 2014.
[21] Graham C. Goodwin, Stefan F. Graebe, and Mario E. Salgado. Control SystemDesign . Prentice Hall PTR, Upper Saddle River, NJ, USA, 2000.
[22] Mark Harman, Yue Jia, William B. Langdon, Justyna Petke, Iman Hemati
Moghadam, Shin Yoo, and Fan Wu. Genetic improvement for adaptive so/f_t-
ware engineering (keynote). SEAMS, pages 1‚Äì4. ACM, 2014.
[23] Joseph L. Hellerstein, Yixin Diao, Sujay Parekh, and Dawn M. Tilbury. Feedback
Control of Computing Systems . John Wiley & Sons, 2004.
[24] Henry HoÔ¨Ämann. Coadapt: Predictable behavior for accuracy-aware applications
running on power-aware systems. In 26th Euromicro Conference on Real-Time
Systems, ECRTS 2014, Madrid, Spain, July 8-11, 2014 , ECRTS 2014, pages 223‚Äì232,
Washington, DC, USA. IEEE Computer Society.
[25] Henry HoÔ¨Ämann. Jouleguard: energy guarantees for approximate applications.
InProceedings of the 25th Symposium on Operating Systems Principles, SOSP 2015,
Monterey, CA, USA, October 4-7, 2015 , pages 198‚Äì214, 2015.
[26] Henry HoÔ¨Ämann, Martina Maggio, Marco D. Santambrogio, Alberto Leva, and
Anant Agarwal. A generalized so/f_tware framework for accurate and eÔ¨Écient
management of performance goals. EMSOFT, pages 1‚Äì10. IEEE Press, 2013.
[27] Connor Imes, David H. K. Kim, Martina Maggio, and Henry HoÔ¨Ämann. POET: a
portable approach to minimizing energy under so/f_t real-time constraints. In 21st
IEEE Real-Time and Embedded Technology and Applications Symposium, Sea/t_tle,
WA, USA, April 13-16, 2015 , pages 75‚Äì86, 2015.
[28] J.L. Jerez, P.J. Goulart, S. Richter, G.A. Constantinides, E.C. Kerrigan, and
M. Morari. Embedded online optimization for model predictive control at mega-
hertz rates. Automatic Control, IEEE Transactions on , 59(12):3238‚Äì3251, Dec
2014.
[29] Juan L. Jerez, Eric C. Kerrigan, and George A. Constantinides. A sparse and
condensed QP formulation for predictive control of LTI systems. Automatica ,
48(5):999‚Äì1002, 2012.
[30] Christos Karamanolis, Magnus Karlsson, and Xiaoyun Zhu. Designing control-
lable computer systems. HOTOS, pages 9‚Äì15. USENIX Association, 2005.
[31] David HK Kim, Connor Imes, and Henry HoÔ¨Ämann. Racing and pacing to idle:
/T_heoretical and empirical analysis of energy optimization heuristics. In Cyber-
Physical Systems, Networks, and Applications (CPSNA), 2015 IEEE 3rd International
Conference on , pages 78‚Äì85. IEEE, 2015.
[32] Basil Kouvaritakis and Mark Cannon. Model Predictive Control ‚Äì Classical, Robust
and Stochastic . Springer International Publishing, 2016.
[33] JeÔ¨Ä Kramer and JeÔ¨Ä Magee. Self-managed systems: An architectural challenge.
In2007 Future of So/f_tware Engineering , FOSE, pages 259‚Äì268, Washington, DC,
USA, 2007. IEEE CS.
[34] D. Kusic, J.O. Kephart, J.E. Hanson, Nagarajan Kandasamy, and Guofei Jiang.
Power and performance management of virtualized computing environments
via lookahead control. In Autonomic Computing, 2008. ICAC ‚Äô08. International
Conference on , June 2008.
[35] Dara Kusic and Nagarajan Kandasamy. Risk-aware limited lookahead control
for dynamic resource provisioning in enterprise computing systems. Cluster
Computing , 10(4):395‚Äì408, 2007.
[36] William S Levine. /T_he control handbook . CRC, 1996.
[37] Lennart Ljung. System Identi/f_ication: /T_heory for the User . Prentice Hall PTR,
Upper Saddle River, NJ, USA, 1999.
[38] Chenyang Lu, Ying Lu, Tarek F. Abdelzaher, John A. Stankovic, and Sang Hyuk
Son. Feedback control architecture and design methodology for service delay
guarantees in web servers. IEEE Trans. Parallel Distrib. Syst. , 17(9):1014‚Äì1027,
2006.
[39] J.M. Maciejowski. Predictive Control: With Constraints . Prentice Hall, 2002.
[40] M. Maggio, H. HoÔ¨Ämann, M.D. Santambrogio, A Agarwal, and A Leva. Control-
ling so/f_tware applications via resource allocation within the heartbeats frame-
work. CDC, pages 3736‚Äì3741. IEEE, 2010.
[41] M. Maggio, H. HoÔ¨Ämann, M.D. Santambrogio, A. Agarwal, and A. Leva. Power
optimization in embedded systems via feedback control of resource allocation.
IEEE Trans. Control Syst. Technol. , 21(1):239‚Äì246, 2013.
[42] Martina Maggio, Alessandro Vi/t_torio Papadopoulos, Antonio Filieri, and Henry
HoÔ¨Ämann. Self-adaptive video encoder: Comparison of multiple adaptation
strategies made simple. In Proceedings of the 12th International Symposium on
So/f_tware Engineering for Adaptive and Self-Managing Systems , SEAMS ‚Äô17, pages
123‚Äì128, Piscataway, NJ, USA, 2017. IEEE Press.
[43] Martina Maggio, Alessandro Vi/t_torio Papadopoulos, Antonio Filieri, and Henry
HoÔ¨Ämann. Self-Adaptive Video Encoder: Comparison of Multiple Adaptation
Strategies Made Simple (Artifact). Dagstuhl Artifacts Series , 3(1):2:1‚Äì2:3, 2017.
[44] Gabriel A. Moreno, Javier C ¬¥amara, David Garlan, and Bradley Schmerl. Proactive
self-adaptation under uncertainty: A probabilistic model checking approach. In
Proceedings of Foundations of So/f_tware Engineering , ESEC/FSE 2015, pages 1‚Äì12,
New York, NY, USA, 2015. ACM.
[45] Simon Oberth ¬®ur, Carsten B ¬®oke, and Bj ¬®orn Griese. Dynamic online recon/f_igura-
tion for customizable and self-optimizing operating systems. EMSOFT. ACM,
2005.
[46] T. Patikirikorala, A Colman, J. Han, and Liuping Wang. A systematic sur-
vey on the design of self-adaptive so/f_tware systems using control engineering
approaches. In So/f_tware Engineering for Adaptive and Self-Managing Systems
(SEAMS), 2012 ICSE Workshop on , SEAMS, pages 33‚Äì42, June 2012.
[47] Raghavendra Pothukuchi, Amin Ansari, Petros Voulgaris, and Josep Torrellas.ESEC/FSE‚Äô17, September 4‚Äì8, 2017, Paderborn, Germany M. Maggio, A.V. Papadopoulos, A. Filieri, H. HoÔ¨Ämann
Using multiple input, multiple output formal control to maximize resource
eÔ¨Éciency in architectures. 2016 ACM/IEEE 43rd Annual International Symposium
on Computer Architecture (ISCA) , 00:658‚Äì670, 2016.
[48] S. Richter, C. N. Jones, and M. Morari. Computational complexity certi/f_ication
for real-time mpc with input constraints based on the fast gradient method. IEEE
Transactions on Automatic Control , 57(6):1391‚Äì1403, June 2012.
[49] Mazeiar Salehie and Ladan Tahvildari. Self-adaptive so/f_tware: Landscape and
research challenges. ACM Trans. Auton. Adapt. Syst. , 4(2), May 2009.
[50] Stepan Shevtsov and Danny Weyns. Keep it simplex: Satisfying multiple goals
with guarantees in control-based self-adaptive systems. In Proceedings of the
2016 11th Joint Meeting on Foundations of So/f_tware Engineering , FSE 2016, 2016.
[51] Sebastian Uchitel, Victor A. Braberman, and Nicolas D‚ÄôIppolito. Runtime con-
troller synthesis for self-adaptation: Be discrete! In Proceedings of the 11th
International Symposium on So/f_tware Engineering for Adaptive and Self-Managing
Systems , SEAMS ‚Äô16, pages 1‚Äì3, New York, NY, USA, 2016. ACM.
[52] G. van der Veen, J.-W. van Wingerden, M. Bergamasco, M. Lovera, and M. Ver-
haegen. Closed-loop subspace identi/f_ication methods: an overview. Control
/T_heory Applications, IET , 7(10), July 2013.
[53] Michel Verhaegen and Vincent Verdult. Filtering and System Identi/f_ication: A
Least Squares Approach . Cambridge University Press, New York, NY, USA, 2012.
[54] Lixi Wang, Jing Xu, H.A. Duran-Limon, and Ming Zhao. Qos-driven cloudresource management through fuzzy model predictive control. In Autonomic
Computing (ICAC), 2015 IEEE International Conference on , pages 81‚Äì90, July 2015.
[55] Yang Wang and S. Boyd. Fast model predictive control using online optimization.
Control Systems Technology, IEEE Transactions on , 18(2), March 2010.
[56] Zhou Wang, A.C. Bovik, H.R. Sheikh, and E.P. Simoncelli. Image quality assess-
ment: from error visibility to structural similarity. IEEE Transactions on Image
Processing , 13(4):600‚Äì612, 2004.
[57] Danny Weyns, M. Usman I/f_tikhar, Didac Gil de la Iglesia, and Tanvir Ahmad. A
survey of formal methods in self-adaptive systems. C3S2E, pages 67‚Äì79, 2012.
[58] Chu-Pan Wong, Christian K ¬®astner, /T_homas /T_h ¬®um, and Gunter Saake. On essential
con/f_iguration complexity: Measuring interactions in highly-con/f_igurable systems
jens meinicke. ASE. IEEE CS, 2016.
[59] Eric Yuan, Naeem Esfahani, and Sam Malek. A systematic survey of self-
protecting so/f_tware systems. ACM Trans. Auton. Adapt. Syst. , 8(4), 2014.
[60] Melanie N. Zeilinger, Davide M. Raimondo, Alexander Domahidi, Manfred
Morari, and Colin N. Jones. On real-time robust model predictive control. Auto-
matica , 50(3):683‚Äì694, 2014.
[61] Qi Zhang, /Q_uanyan Zhu, M.F. Zhani, and R. Boutaba. Dynamic service placement
in geographically distributed clouds. In Distributed Computing Systems (ICDCS),
2012 IEEE 32nd International Conference on , pages 526‚Äì535, June 2012.