IntEQ: Recognizing Benign Integer Overï¬‚ows via
Equivalence Checking Across Multiple Precisions
Hao Sunâ‹„â€ , Xiangyu Zhangâ€¡, Yunhui ZhengÂ§and Qingkai Zengâ‹„â€ 
â‹„State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China
â€ Department of Computer Science and Technology, Nanjing University, Nanjing, China
â€¡Department of Computer Science, Purdue University, West Lafayette, USA
Â§IBM T.J. Watson Research Center, Yorktown Heights, USA
shqking@gmail.com, xyzhang@purdue.edu, zhengyu@us.ibm.com, zqk@nju.edu.cn
ABSTRACT
Integer overow ( IO) vulnerabilities can be exploited by
attackers to compromise computer systems. In the mean
time, IOs can be used intentionally by programmers for
benign purposes such as hashing and random number
generation. Hence, dierentiating exploitable and harmful
IOs from intentional and benign ones is an important
challenge. It allows reducing the number of false positives
produced by IO vulnerability detection techniques, helping
developers or security analysts to focus on xing critical IOs
without inspecting the numerous false alarms. The diculty
of recognizing benign IOs mainly lies in inferring the intent
of programmers from source code.
In this paper, we present a novel technique to recognize
benign IOs via equivalence checking across multiple preci-
sions . We determine if an IO is benign by comparing the
eects of an overowed integer arithmetic operation in the
actual world (with limited precision) and the same operation
in the ideal world (with sucient precision to evade the
IO). Specically, we rst extract the data ow path from
the overowed integer arithmetic operation to a security-
related program point (i.e., sink) and then create a new
version of the path using more precise types with sucient
bits to represent integers so that the IO can be avoided.
Using theorem proving we check whether these two versions
are equivalent, that is, if they yield the same values at the
sink under all possible inputs. If so, the IO is benign. We
implement a prototype, named IntEQ, based on the GCC
compiler and the Z3 solver, and evaluate it using 26 harmful
IO vulnerabilities from 20 real-world programs, and 444
benign IOs from SPECINT 2000, SPECINT 2006, and 7
real-world applications. The experimental results show that
IntEQ does not misclassify any harmful IO bugs (no false
negatives) and recognizes 355 out of 444 (about 79.95%)
benign IOs, whereas the state of the art can only recognize
19 benign IOs.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proï¬t or commercial advantage and that copies bear this notice and the full citation
on the ï¬rst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciï¬c permission
and/or a fee. Request permissions from permissions@acm.org.
ICSE â€™16, May 14-22, 2016, Austin, TX, USA
câƒ2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI:http://dx.doi.org/10.1145/2884781.2884820CCS Concepts
â€¢Security and privacy â†’Software security engineering;
Keywords
Integer Overow; Benign; Equivalence Checking; Precision
1. INTRODUCTION
In C/C++ programming languages, integer arithmetic
operations, such as addition, subtraction, multiplication and
left-shift operations might cause the results to go beyond the
limited range that the integer type can represent, causing
integer overow (IO) [1]. As the direct consequence of an
IO is just to produce an erroneous value, the erroneous
value has to be further used in some security-related program
points , orsinks , to perform various attacks on the subject
programs, such as code injection and Denial of Service (DoS)
attacks [39][40][38]. Following the notions in RICH [19] and
SoupInt [50], such security-related program points include
memory-related routines (e.g., malloc() ,memcpy() ),if-
statement, while -statement and array indexing statement.
For instance, Listing 1 shows a typical IO bug in CUP-
S [39]. When a malicious image le with large width
and height is provided, e.g., img->xsize as 4 and img-
>ysize as 0 x40000004, an IO occurs at line 12, with
bufsize overowed to 0 x10, not the expected 0x 100000010.
The miscomputed bufsize is nally used at the memory
allocation site at line 14, leading to less space allocated than
expected. As a result, buer overow would occur if out-of-
bound reads or writes are performed later.
A study in 2007 about the Common Vulnerabilities and
Exposures (CVE) reports [16] suggests that handling integer
overows is \the number 2 for OS vendor advisories",
whereas buer overows rank number one. Integer overows
are listed among the 25 most dangerous software bugs
according to a study in 2011 [2]. Due to its importance,
researchers have developed various techniques to address
this problem. For instance, RICH [19], IOC [26], AIR [25],
RA [45], IntPatch [55] and IntTracker [49] instrument integer
arithmetic operations to monitor overows at runtime;
SmartFuzz [37], IntScope [51] and KINT [52] leverage
symbolic execution to generate test cases which can trigger
overows; SafeInt [33], CERT's IntegerLib [20, 23] and
Ranged Integer [28] use safe library functions to wrap integer
arithmetic operations.
Despite the signicant advances in detecting and protect-
ing against IOs, how to distinguish exploitable and harmful
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   1051
1/âˆ—Read a PNG image f i l e . âˆ—/
2int cupsImageReadPNG ( Cups image tâˆ—img , FILE âˆ—
fp , . . . ) {
3 png uint 32 width , height ;
4 png structp pp ;
5 p n g i n i t i o (pp , fp ) ;
6
7/âˆ—Get the image dimensions âˆ—/
8 png getIHDR (pp , info , &width , &height , . . . ) ;
9imgâˆ’>x s i z e = width ;
10 imgâˆ’>y s i z e = height ;
11 s i z e t bufsize , s i z e ;
12 b u f s i z e = img âˆ’>x s i z e âˆ—imgâˆ’>y s i z e ;
13 s i z e = b u f s i z e âˆ—3 ;
14 in = malloc ( s i z e ) ;
15 . . .
16}
Listing 1: A harmful IO in CUPS (CVE-2008-1722).
IOs from the benign ones still remains an open problem.
In practice, programmers might leverage IOs intentionally
to implement specic functionalities such as hash value
computation and random number generation, or to achieve
conciseness in coding [26, 44]. As shown in Listing 2, 176.gcc
in SPECINT 2000 [13] utilizes a signed IO at line 11 to
compute a hash value. This overow is benign because the
bit AND operation at line 13 and the modulo operation
at line 14 ensure that the overowed value, i.e. hi, has a
constant and legitimate range before owing into the array
indexing statement at line 17. As we will show in Section 2,
the majority of IOs are benign in practice. Unfortunately,
most existing IO detection tools cannot distinguish them
from harmful IOs.
The main diculty of recognizing benign IOs is to infer
the intent of programmers from source code. IntFlow [44]
leverages information ow tracking to identify benign over-
ows if both the operands originate from trusted sources.
The main intuition behind this technique is that, the IOs
inuenced only by benign inputs are considered less likely
to be used in exploitation attempts. Instead, they are likely
developer-intended and benign. However in practice there
also exist a large number of benign IOs, whose operands
come from external inputs. Take the benign IO in Listing 2
as an example. Array text is actually from user-inputs.
Unfortunately, IntFlow still undesirably treats such IOs as
harmful.
In this paper, we present a novel technique to recognize
benign IOs via equivalence checking across multiple preci-
sions . As we show in Section 2.2, our technique is based
on two core insights. First , the root cause of IOs is the
limited number of bits used to represent an integer. If
we supply sucient bits, the data can be represented more
accurately so that the integer operation no longer overows.
Second , one key prerequisite for an IO to become harmful
is being used at a sink site. This provides an interface for
an adversary to conduct malicious operations. Based on
the two observations, our idea is as follows. Given a path
from an overowed integer arithmetic operation to a sink,
we create a new version of the path with more precise types
that have sucient bits to represent integer values. As such,
the overow no longer occurs in the new version. If both the
low precision version (with the IO) and the high precision
version (without the IO) produce the same value at the sink,
the IO (in the low precision version) is benign as it has no
dierent eect compared to the ideal case. Otherwise, the
IO is considered harmful. The essence of IntEQ is to use1#define HASHBITS 30
2#define MAX HASH TABLE 1009
3
4/âˆ—Return an IDENTIFIER NODE whose name i s TEXT âˆ—/
5t r e e g e t i d e n t i f i e r ( char âˆ—text ) {
6 int hi , i ;
7 . . .
8/âˆ—Compute hash code âˆ—/
9 hi = hash len âˆ—613 + ( unsigned ) text [ 0 ] ;
10 for ( i = 1 ; i <hash len ; i += 2)
11 hi = ( ( hi âˆ—613) + ( unsigned ) ( text [ i ] ) ) ;
12
13 hi &= (1 <<HASHBITS) âˆ’1 ;
14 hi %= MAX HASH TABLE;
15
16 /âˆ—Search t a b l e for i d e n t i f i e r âˆ—/
17 for ( idp = hash table [ hi ] ; idp ; idp = . . . )
18 . . .
19}
Listing 2: A benign IO for hashing in 176.gcc.
the high precision version to model the behavior intended
by the programmer such that the equivalence between the
two versions determines if the IO is benign.
Our contributions are highlighted as follows.
1) We propose the novel idea of determining if an IO is
benign by checking equivalence between two versions
of code, which have dierent levels of representation
precision.
2) We propose and implement a static integer overow
classier, IntEQ, based on the GCC compiler [4] and
the Z3 solver [15], aiming to improve the accuracy of
integer overow detection. Given an IO report (gen-
erated by a third party tool), our tool rst leverages
a static data ow analysis to extract the data ow
path from the overowed integer arithmetic operation
to a sink, and then creates a new version of the path
with higher representation precision using types with
sucient bits. At last, IntEQ leverages a constraint
solver, Z3, to reason about the equivalence of the two
versions with all possible inputs. If equivalent, we
report this IO as benign.
3) We apply IntEQ to 26 harmful CVE IO vulnerabilities
from 20 real-world programs, and 444 benign IOs
from SPECINT 2000 [13], SPECINT 2006 [14], and
7 real-world applications. The experimental results
show that IntEQ correctly recognizes all the CVE
IOs as harmful (and hence no false negatives). More
importantly, it correctly identies 355 out of the total
444 benign IOs (i.e., 79.95%), whereas the state-of-the-
art [44] can only recognize 19 of them.
Outline. The rest of this paper is organized as follows.
Section 2 presents an overview of our approach. Section 3
describes the design and implementation in detail. Section 4
evaluates our tool. Related work and conclusion are
discussed in Section 5 and Section 6, respectively.
2. OVERVIEW
In this section, we discuss the characteristics of benign
IOs, including their typical use cases, and the importance
and diculty of recognizing them. We also present an
overview of our approach, which is mainly motivated by two
core insights.
10522.1 Characteristics of IOs and Existing Solu-
tions
IO vulnerabilities are quite dierent from other types of
software vulnerabilities (e.g., buer overow, null pointer
dereference, and SQL injection vulnerabilities). While
buer overows and null pointer dereferences are always
harmful, IOs are benign in many cases. Benign IOs
are often used intentionally by programmers to implement
specic functionalities or even just to achieve conciseness in
coding [26, 44]. Such specic functionalities mainly include
hash value computation (as shown in Listing 2), random
number generation, coding and decoding.
Most existing techniques, such as RICH [19], IOC [26],
AIR [25], RA [45] and [23], cannot distinguish benign IOs
from the harmful ones, producing a large number of false
positives and substantially degrading the usability of those
tools. According to our manual analysis on the 527 IO
reports by IOC on SPECINT 2000 and 2006 benchmarks
together with 7 real-world applications, only 9 of them
(1.71%) are harmful. This implies the developers and
security analysts have to manually lter out the numerous
benign IOs before they can x the harmful ones. Hence,
distinguishing benign IOs from the critical ones is an open
challenge of great importance.
The key diculty of recognizing benign IOs lies in infer-
ring the intent of programmers from source code. Given
a program, it is hard to automatically reason about the
programmer's intent without any hints/annotations from
the programmer. Take the code snippets in Listing 1 and
Listing 2 as an example. In these two code snippets,
the usages of the two integer multiplications (i.e., line 12
in Listing 1 and line 11 in Listing 2) are quite similar,
both originating from external inputs, going through several
operations and nally propagating to the sink point (i.e.,
malloc() at line 14 in Listing 1 and the array indexing
statement at line 17 in Listing 2). As such, we can hardly
tell the developer-intended and hence benign IO from the
harmful one.
Inferring the intent of programmers in IO detection is
known as a hard challenge. In the following, we present
some related quotes from other researchers in the area.
\Like all overows, the C source code contains no
indication from programmer that this overow is
intentional." | RICH [19]
\programmers may intentionally use unsafe inte-
ger behavior. It is impossible for an automated
tool to unambiguously understand the intent of a
programmer." | [23]
\the intention of a developer, however, cannot be
formally dened or automatically derived, as the
code patterns used in a piece of code are deeply
related to the author's knowledge, preference and
programming style." | IntFlow [44]
Instead of inferring the intent of programmers, Int-
Flow [44] proposes to determine if an IO is benign by
checking where the operands originate from. The intuition
is that the IOs with their operands from trusted sources
cannot be controlled or exploited by adversaries. Therefore,
such IOs are considered benign. Unfortunately, many IOs
from untrusted sources are also benign.2.2 Our Approach
We propose to determine whether an IO is benign from
the view of its eect on sinks. Our approach is motivated
by two core insights. First, the root cause of IOs is the
limited number of bits used to represent integers in C/C++
languages. This might cause the results of integer arithmetic
operations to go beyond the limited range. Hence, if
we use sucient bits to represent integers, the arithmetic
operations will not overow any more. Take Listing 1
as an example. An IO occurs at line 12 if we set img-
>xsize as 4 and img->ysize as 0x 40000004 respectively.
The overowed variable bufsize holds the value of 0x 10,
which is erroneous. If we use 64 bits (i.e., unsigned long
long type) to represent the integers, the multiplication at
line 12 does not overow and the variable bufsize has the
ideal and expected value 0x 100000010.
Second, one key prerequisite for an IO to become harmful
is that the overowed value may be eventually propagated to
some critical places (or sinks), such as the size argument
of a memory allocation function . This is mainly because
IOs cannot directly over-write memory and thus adversaries
have to manipulate sinks (through the overowed values) to
conduct malicious attacks. Specically, adversaries might
exploit overowed data at: 1) memory-related routines to
cause buer overows (e.g., the case in Listing 1) or DoS [40];
2)if-statement to bypass security checks [42]; 3) while -
statement to trigger innite loops [38] and 4) array indexing
statement to induce out-of-bound reads/writes [41].
Therefore, we consider an IO benign if the overowed
data has no harmful eect on sinks. To evaluate the eect
of an IO on sinks, we present a novel technique based on
equivalence checking across multiple precisions . Specically,
we rst utilize static data ow analysis to extract all possible
data ow paths from the overowed integer arithmetic
operation to all sinks. For each path, we then create
a new version, where integers are represented by higher
precision types with sucient bits such that the integer
operations no longer overow. Finally, we verify whether
these two versions with dierent precisions are semantically
equivalent using theorem proving. Equivalence refers to that
the two versions always yield the same value(s) at the sinks
for all possible inputs. If for all paths of the overowed
integer arithmetic operation, the two versions (with dierent
precision levels) are always semantically equivalent, this IO
is benign.
Consider the example in Listing 1. Given the aforemen-
tioned overow inducing inputs, the two precisions yield
dierent values at the sink point (line 14). The IO is hence
harmful. In contrast, for the example in Listing 2, although
variable hihas dierent values with the two precisions, the
lower 32 bits of the two values are always the same due to
the characteristics of the arithmetic operations. As such,
after the bit AND operation at line 13 and the modulo
operation at line 14, the two values always become identical.
The IO is hence benign. It implies that the programmer
had considered possible IOs when writing the program and
they have put in sanitization operations to suppress the
undesirable consequences of IOs.
3. DESIGN AND IMPLEMENTATION
The architecture of IntEQ is shown in Figure 1. The
inputs are the source code of the subject C/C++ program
1053C/C++ 
Source CodeFront-end
Path
ExtractionPath
EncodingTheorem
Prover
IO Bug 
ReportSAT
UNSAT BenignOriginal
precisionHigh
precision HarmfulFigure 1: Arichtecture of IntEQ.
and a set of IO vulnerabilities reported by a third party tool.
The tool can be dynamic or static analysis based. In this
paper, we use IOC [26], which is a state-of-the-art dynamic
analysis based IO detection tool. The front-end converts the
subject program to its static single assignment (SSA) form,
and builds control ow graphs and call graphs. For each IO
report, the path extraction component extracts all the data
ow paths from the overowed integer operation to some
sink. The sinks are a set of statements of predened and
congurable types. The path encoding component generates
two versions of symbolic encoding of the path, one with
the original precision and the other with high precision
(i.e., using more bits to represent integers). The encodings
are bit-vector based. Finally, the equivalence of the two
versions is determined by a theorem prover. If for all paths
of an overowed integer operation, the two versions are
always equivalent (i.e., UNSAT when we assert one version
is not equal to the other), we consider the overow benign,
otherwise harmful.
3.1 Path Extraction
Given an IO bug report, all the paths from the overowed
integer arithmetic operation to the potential sinks are
rst extracted. This process works on the intermediate
representation provided by the front-end. The key idea
of our path extraction is traversing the control ow graph
to obtain the relevant statements, which the overowed
integer operation may aect, with the help of def-use
chains [32] provided by SSA. In SSA, a unique variable
name is assigned to each denition and phi-operators are
used at join points to multiplex the dierent values along
dierent branches. Using def-use chains, the uses of the
value dened by an integer operation can be easily located.
Our analysis starts from the overowed integer operation,
and traverses along the def-use edges originating from the
operation in a depth-rst fashion, until some sink is reached.
It is context-sensitive, path-sensitive, and inter-procedural
(based on function summaries [53, 18, 54]). Next, we focus
on discussing how we handle loops and pointers. The other
pieces such as handling function summaries are standard and
hence elided.
Handling Pointers . Handling pointers is a prominent
challenge for static analysis. The problem lies in that
a denition and the corresponding use may de-reference
dierent pointer variables that are aliases. For instance,
given a denition de-referencing pand a use de-referencing
q, it is challenging in general to determine if the use gets
its value from the denition, which requires alias analysis.
Although there are many advanced points-to analysis [46,
34] that can determine the set of memory locations that a
pointer may point to, due to the inherent limitations of static
analysis, they usually produce over-approximated results. In
our scenario, they may report a large number of bogus def-
use relations that fail our equivalence check.In IntEQ, we treat a write through a pointer dereference as
a sink. In other words, if there is a write through a pointer
dereference along the extracted path, we aim to establish
the equivalent relationship on the value that is being written
(across the two versions). The intuition is that the path we
acquire is essentially a sub-path of the true data ow path
that ends at a real sink. If we can prove equivalence for the
sub-path, the IO must make no dierence to the remaining
computation in the true path including the sink, and is hence
benign. We call it the path reduction theorem, whose formal
denition is as follows.
Theorem 1 (Path Reduction). Given a data ow path
p:=âŸ¨nint; n1; n2;Â· Â· Â·; ni;Â· Â· Â·; nsinkâŸ©, where nintis an over-
owed integer arithmetic operation, niis in the form of
\var :=op(x1; x2;Â· Â· Â·)", and nsink is a (real) sink, and
a sub-path pâ€²:=âŸ¨nint; n1; n2;Â· Â· Â·; niâŸ©, which is a prex of
p, if the two versions of pâ€²(with low and high precisions)
are equivalent regarding var, then this overowed integer
arithmetic operation (n int) has no harmful eect on the sink
(nsink), i.e. this overow is benign for path p.
Proving the theorem is straightforward. Because if the
prex computes the same varvalue at niwith two precisions,
the continuation of the prex is using the same value to
conduct its computation such that the overowed data has
no further harmful eect on the continuation, including
the sink. However, it is possible that IntEQ cannot prove
equivalence for the sub-path, whereas the equivalence for the
full path can be proved assuming an ideal points-to analysis.
In other words, IntEQ may misclassify a benign IO as
harmful. Fortunately, we observe in practice, the overowed
value does not propagate far before it gets sanitized. In other
words, it usually gets sanitized before being written through
a pointer-dereference. Moreover, applying path reduction
would not lead to misclassication of a harmful IO as benign,
which is unacceptable.
Example : Listing 3 shows a code snippet from 254.gap
that simulates multiplication of large numbers by multiply-
ing the individual digits in the two large multiplicands. At
lines 15-18, both land *rare of 16-bit unsigned short
integer type so that the product may likely exceed the
range of unsigned short , causing an IO. The third party IO
detection tool IOC [26] we use detects this IO. However, this
is a benign IO. In particular, the compiler always extends
multiplicands to integers (of 32 bits) before carrying out
the multiplication. As such, despite the overow, the 32-
bit product is correctly produced and stored in c, which is
further casted to a 16 bit short through *p++=c . Note that
the carry-on from the multiplication of the previous digits
is also added. For example, the Â· Â· Â·+(câ‰«16)at line 16 adds
the carry-on generated at line 15.
For the overow at line 15, IntEQ extracts a number of
paths: all starting with the multiplication l*(*r) , ending
with the pointer based write *p++=c at lines 15, 16, 17 and
10541typedef unsigned short TypDigit ;
2
3TypHandle ProdInt ( TypHandle hdL , TypHandle hdR) {
4 register unsigned SPEC INT32 T c ;
5 register TypDigit l , âˆ—r ,âˆ—p ;
6 register TypHandle hdP ;
7 . . .
8 l = ( TypDigit ) i ;
9 i f( l != 0 ) {
10 r = ( TypDigit âˆ—)PTR(hdR) ;
11 p = ( TypDigit âˆ—)PTR(hdP) ;
12 c = 0 ;
13 /âˆ—multiply the r i g h t with t h i s d i g i t and
store in the product âˆ—/
14 for ( k = SIZE (hdR) /(4 âˆ—sizeof ( TypDigit ) ) ; k
!= 0 ; âˆ’âˆ’k ){
15 c = l âˆ— âˆ—r++ + ( c >>16) ; âˆ—p++ = c ;
16 c = l âˆ— âˆ—r++ + ( c >>16) ; âˆ—p++ = c ;
17 c = l âˆ— âˆ—r++ + ( c >>16) ; âˆ—p++ = c ;
18 c = l âˆ— âˆ—r++ + ( c >>16) ; âˆ—p++ = c ;
19 }
20 âˆ—p = ( c >>16) ;
21 }
22 . . .
Listing 3: Benign IOs for digit-wise operations in
254.gap.
18, respectively. One can easily tell that for all these paths,
the low and high precisions are equivalent, due to the type
cast at the sink.
Handling Loops . Equivalence checking involving loops
is a hard problem in software verication. It requires getting
the right loop invariants, which often entails substantial
manual eorts. We have tried the approach of unrolling
the loop once and treating any denition that has loop-
carry dependencies as a sink. Intuitively, if we can prove
equivalence for one iteration, the IO does not have harmful
eect on the other iterations due to the path reduction
theorem. Unfortunately, we nd out the applicability of
this method is limited in practice. This is because the
sanitization often occurs outside the loop. Listing 2 shows
a typical example. Observe that the sanitization is at line
13 and outside the loop. Therefore, we choose to follow a
standard solution in bounded model checking [24, 17, 22]:
unrolling the loop for a xed number of times. In IntEQ,
we unroll once. As a result, the soundness of IntEQ is
limited by the unroll bound. More discussion can be found
in Section 3.3.
3.2 Path Encoding and Equivalence Checking
Given a data ow path from an overowed integer opera-
tion to a sink, the next step is to encode the path into two
versions of constraints with dierent precisions, and then to
correlate the two sets of constraints to check equivalence. In
IntEQ, we leverage the bit-vector logic [27, 30] to encode
paths. Bit-vectors can precisely model the semantics of
unsigned and of signed two-complement's arithmetics. More
importantly, the logic supports bit-vectors with arbitrary
size. Hence we can easily extend the original version's
precision by simply using longer bit-vectors.
3.2.1 High Precision Estimation
Given a path with the original low precision, our technique
rst estimates the needed precision (i.e., the number of bits
to represent an integer) so that IOs in the original low
precision can be completely evaded along the path. The
basic idea is to over-approximate the number of bits needed
for each integer operation in the path in order to avoid IOs.Algorithm 1 Precision Estimation.
Input: data ow path p, original precision n
Output: high precision m
1:m=n; // initialization
2:foreach operation node in path pdo
3: ifnode is MUL then
4: m+= n;
5: else if node is ADD or SUB then
6: m+= 1;
7: else if node is SHL (c = a â‰ªb)then
8: ifbis a constant then
9: m+= val (b) ;
10: else
11: m+= n;
12: end if
13: else
14: continue;
15: end if
16:end for
Note that the number of needed bits monotonically grows
along the path as the result of an operation is further used
in another operation. However, since our path is nite, the
number of bits needed is bounded. At the end, we use the
inferred number of bits to denote integers such that IOs are
completely avoided.
Algorithm 1 shows the process of precision estimation.
It takes as input a data ow path pand the original low
precision n, which is the number of bits to represent an
integer, and produces the high precision m. Initially the
high precision mis initialized as the original precision (line
1). It is later updated according to the dierent types of
arithmetic operations along path p(lines 2 to 16). We
consider MUL, ADD, SUB and SHL operations because only
these operations might overow. With the original precision
n, MUL and SHL might overow by nbits at most, and
ADD and SUB might overow by onebit at most. Note that
val(b) denotes the concrete value of this constant operand
b. It is worth mentioning that the high precision mwill not
be too large as the paths are usually not long (as shown in
Section 4.3).
3.2.2 Path Encoding
The next step is to encode the path to bit-vector con-
straints in precisions nand mrespectively. Algorithm 2
describes the process. It takes as input a data ow path
p, the original precision nand the high precision m, and
produces a set of bit-vector logic constraints denoted as
CS. Lines 1 to 26 encode a statement on the path to
constraint(s). At the end, line 27 adds the satisability
check. Lines 2-17 encode an assignment with a binary
operation. Lines 3-5 declare the symbolic variables for the
destination program variable c, with corgandcextfor the
original precision and high precision, respectively. Lines
6-14 declare symbolic variables for the source operands if
they were not declared, meaning that these operands are not
dened along the path. Lines 15-17 encode the operation.
The encoding of other operations (e.g., unary operations)
follows a similar procedure and is hence elided. If the
statement is the sink, the algorithm asserts the equivalence
of the involved symbolic variables (lines 21-22). Note that
the symbolic variable with the lower precision needs to be
extended to the high precision before checking equivalence.
We will explain precision extension later in the section.
Variable Declaration. Function declare var(var, size)
105512    bufsize = img->xsize * img->ysize;
13    size = bufsize * 3;
14    in = malloc(size);(declare-fun  xsize_org ()  (_ BitVec 32))
(declare-fun  ysize_org ()  (_ BitVec 32))
(declare-fun  bufsize_org ()  (_ BitVec 32))
(assert (= bufsize_org (bvmul xsize_org ysize_org)))
(declare-fun  size_org ()  (_ BitVec 32))
(assert (= size_org (bvmul bufsize_org #x00000003)))
(declare-fun  size_org_ext ()  (_ BitVec 96))
(assert (= size_org_ext (concat #x000 00 size_org)))
(assert (not (= size_org _ext  size_ext)))
(check-sat)Path Original Precision High Precision
(declare-fun  xsize_ext ()  (_ BitVec 96))
(declare-fun  ysize_ext ()  (_ BitVec 96))(assert (= xsize_ext (concat  #x000...00  xsize_org) ) )
(assert (= ysize_ext (concat  #x000...00  ysize_org) ) )
(declare-fun  bufsize_ext ()  (_ BitVec 96))
(assert (= bufsize_ext (bvmul xsize_ext ysize_ext)))
(declare-fun  size_ext ()  (_ BitVec 96))
(assert (= size_ext (bvmul bufsize_ext #x00...0003)))Figure 2: Path and bit-vector constraints for the harmful IO in Listing 1.
Algorithm 2 Path Encoding.
Input: data ow path p, original precision n,
and high precision m
Output: constraint set CS
1:foreach statement node in path pdo
2: ifnode is a binary operation ( c = a op b )then
3: // declare the destination operand
4: declare var(corg, n );
5: declare var(cext, m );
6: // declare the undened source operands
7: ifais not a declared variable then
8: declare var(aorg, n );
9: declare var(aext, m );
10: extend var(aext, a org, m - n );
11: end if
12: ifbis not a declared variable then
13: ...
14: end if
15: // encode the operation into bit-vector operation
16: encode operation( corg, a org, b org, opcode );
17: encode operation( cext, a ext, b ext, opcode );
18:
19: else if node is a unary operation ( c = op a )then
20: ...
21: else if node is the sink such as \ malloc (c) " and \if(c) "
then
22: add assertion(extend var(corgext, c org, m - n ) ==
cext);
23: else
24: ...
25: end if
26:end for
27:add \(check-sat)" into CSnally.
declares a bit-vector (symbolic variable) with the name var
and the length size. We declare bit-vectors for both the
destination and source (program) variables. Declaration for
a source variable is only needed when it is not dened in the
path by a preceding assignment statement. In this case, the
declared bit-vector is a free variable, denoting an input to
the path. Intuitively, our tool reasons about equivalence for
all possible values of these free variables.
Precision Extension. To check equivalence, we provide
the same inputs to the two versions, and then compare
the values of the two versions at the sink. In order to
enforce the same inputs, we assert that the high precisioninput be derived by extending the corresponding original
low precision input. Precision extension is provided by
function extend var(ext, org, num) . The logic is shown as
follows. Note that organd extdenote the inputs for the
original and high precision versions respectively. Function
zero extend(num, org) conducts zero extension on bit-vector
org, i.e. extending orgwith num zero upper bits before
org; while function sign extend(num, org) conducts sign
extension on org, i.e. extending orgwith num upper bits
that equal to the sign bit of org.
For an unsigned variable:
ext := zero_extend( num,org);
For a signed variable:
ext := sign_extend( num,org);
The same extension is conducted at the sink point before
checking equivalence (line 22). Note that comparing bit-
vectors of dierent lengths is meaningless and not allowed.
Operation Encoding. Most commonly-used integer
operations are directly supported in the bit-vector logic, for
example, bit-wise operations are supported by bvand and
bvxor , etc., simple arithmetic operations by bvadd ,bvmul ,
bvsub , etc., comparative operations by bvult ,bvsgt , etc.
and bit-propagation operations by concat andextract , etc.
Hence, the encoding for these operations is standard [56, 57].
Example : The left column of Figure 2 shows the data
ow path of the IO in Listing 1. According to Algorithm 1,
the high precision needed is m= 96, which is computed
bym= 32 + 32 at line 12 and m+=32 at line 13. Then
we apply Algorithm 2. The encoded constraints are shown
in the right column of Figure 2. An expression \ op x
y" in the constraint means \ x op y ". The constraints in
bold are for precision extension. As variables xsize and
ysize are of unsigned type, their extended versions, i.e.,
xsize_ext andysize_ext , are represented by appending 64
(i.e., mâˆ’n) zero-bits to the beginning of xsize_org and
ysize_org . Note that the multiplications are encoded with
the corresponding bit-vector operations, i.e., bvmul .
At last the theorem prover takes as input all these
constraints and tries to produce an assignment of inputs
which can satisfy the assertions. For this case, the result is
SAT, which indicates that these constraints are satisable.
Hence the overow is harmful.
10563.3 Soundness
The soundness of our technique means that a harmful IO
should not be misclassied as a benign IO. Here, we follow
the denition that a benign IO has equivalent eects on all
reachable sinks in the actual world (with limited precision)
and the ideal world (with sucient precision). It is impor-
tant to guarantee soundness because any misclassications
of harmful IOs cause the vulnerabilities to be omitted by
developers or security analysts.
Like most bounded model checking techniques [24, 17, 22],
the soundness of our technique is limited by the loop unroll
bound. We say our technique is sound with regard to the
loop unroll bound for the following reasons. 1) The process
of path extraction is complete. Here \ complete " means that
for each overowed integer operation, all potential paths are
extracted. To overcome the challenge caused by aliasing,
we treat pointer de-references as sinks (and hence the end
of paths). 2) The high precision estimation guarantees that
overows in the original precision version would not occur
in the high precision version as it over-approximates. As
such, integers in the high precision version contain the ideal
values for the overowed data. The comparison of eects
on sinks between the overowed data and the corresponding
ideal data is hence sound.
It is possible that the equivalence check succeeds within
the loop unroll bound, but failed if the loop were unrolled
more times than the bound. In theory, these cases should be
considered harmful. However, they are very dicult to ex-
ploit in practice because the adversary needs to manipulate
both the iteration numbers and the overowed values. In our
earlier comprehensive study on the IO related CVEs from
2008 to 2013 [49], out of the 250 harmful IOs, we have not
seen any one that can be exploited by manipulating across
iterations. Moreover, it is easy to extend our technique to
support a much larger loop unroll bound, which would make
exploit almost infeasible in practice.
3.4 Implementation Details
IntEQ makes use of IOC [26], the GCC compiler [4]
and the Z3 solver [15]. IOC is one of the state-of-the-art
IO detection tools. It instruments all integer arithmetic
operations to catch IOs at runtime. IntEQ takes the IO
reports from IOC and classies them to the benign and
harmful categories. Specically, as the IO reports produced
by IOC are in xed format, a parser utility is implemented
to read them and extract the detailed information including
source le, line number and operation. Then the main
analysis is implemented in GCC-4.5.0 as an optimization
pass, which consists of âˆ¼4,000 lines of C code. It operates
on the gimple intermediate representation. Useful interfaces
are provided by gimple to analyze the abstract syntax tree
(AST), control ow graph and call graph. Using the detailed
overow information, this analysis extracts all potential data
ow paths for each overowed integer operation, and encodes
every path into bit-vector logic constraints with original and
high precisions. Finally, a shellcode script is written to
invoke Z3 to resolve the collected constraints and record the
benign overowed integer operations. It is important to note
that the scope of our analysis is limited to a single object
le, as it is implemented as a compile-time optimization pass
instead of a link-time optimization pass.Table 1: 26 harmful real-world IO vulnerabilities.
CVE Programs Version IO op Sink
2005-0199# Ngircd 0.8.1 âˆ’u strlcpy
2005-1141# gocr 0.40 âˆ—s malloc
2006-2971# 0verkill 0.16 âˆ’s while
2006-4812# php 5.1.3 âˆ—s memset
2008-1384# php 5.2.5 +s if
2008-1722 cups 1.3.0 âˆ—u malloc
2008-1801# rdesktop 1.5.0 âˆ’u realloc
2008-3520 jasper 1.900.1 âˆ—s malloc
2008-3640 cups 1.3.8 âˆ—s calloc
2008-3732# vlc 1.1.12* âˆ—s malloc
2009-1882 ImageMagick 6.5.2-8 âˆ—s malloc
2010-0001 gzip 1.3.5 âˆ’u array index
2010-0405 bzip2 1.0.3 âˆ—s while
2010-1516 SWF Tools 0.9.1 âˆ—s malloc
2010-1519 glpng 1.4.5 âˆ—u malloc
2011-1092# php 5.3.6* âˆ’s memcpy
2011-4623 rsyslog 4.6.4 +u realloc
2012-1186 ImageMagick 6.5.2-8 +s if
2012-1584 TagLib 1.5 +u if
2012-1610 ImageMagick 6.5.2-8 âˆ—s if
2012-4405 ghostscript 8.70 âˆ’u array index
2013-4124 samba 3.6.0 +u while
2013-5018 strongSwan 5.0.4 +u if
2014-0150 qemu 2.0 +u if
2014-0172 elfutils 0.153 +u malloc
2015-3228 ghostscript 8.70 +u malloc
4. EVALUATION
We assess the eectiveness and performance of IntEQ in
the following three aspects:
1) Does IntEQ produce false negatives when it is used
to analyze harmful IO vulnerabilities? That is, is
it possible for IntEQ to misclassify harmful IOs as
benign?
2) How eective is IntEQ in recognizing benign IOs?
3) Is the performance of IntEQ reasonable?
All experiments were performed on an Intel Dual Core 2.4
GHz machine with 4GB memory with Linux-3.5.0.
4.1 False Negative
False negative refers to that a harmful IO bug is mis-
classied as benign by IntEQ. Such misclassication is
unacceptable. In order to evaluate the false negative ratio
of our tool, we run IntEQ on a set of 26 real-world harmful
IOs published by CVE, as shown in Table 1. These programs
and IOs are selected to achieve diversity. They cover a long
duration of time (from 2005 to 2015) and dierent types of
applications, including scripting software such as phpand
samba , audio/image software such as vlcandImageMagick,
le compressing software such as gzipandbzip2 . They also
cover all the integer arithmetic operations that can cause IOs
(i.e., addition, subtraction, and multiplication) in both the
signed andunsigned categories, and all the dierent kinds
of sinks.
Columns 1-3 describe the CVE number, the vulnerable
software and version1. Column 4 refers to the overowed
integer arithmetic operation. Note that for the 8 cases
1For CVE-2008-3732, the vulnerable version should be
1.1.11 and below. However, these versions of vlccannot be
compiled under our experimental environment due to certain
reason. Instead, we turn to choose 1.1.12 version with the
patched code removed manually. So it is with CVE-2011-
1092.
1057whose CVE number is marked with `#', the locations of
the overowed integer operations are determined by running
them with the corresponding overow-inducing inputs2, and
for the remaining 18 cases, due to the lack of the overow-
inducing inputs in the CVE reports, the overowed integer
operations are veried through our manual inspection on
the source code with the help of relevant bug information.
Column 5 denotes the sink site where the overowed value
is exploited.
The evaluation result is that IntEQ produced no false
negative, i.e. all the IO vulnerabilities were recognized as
harmful by our tool .
4.2 Recognizing Benign IOs
In this subsection, we quantify the eectiveness of IntEQ
in recognizing benign IOs. We use SPECINT 2000 [13] and
2006 [14] benchmarks together with 7 real-world applica-
tions. We rst applied IOC on the testbed, and collected all
the IO reports produced. Then we manually analyzed each
IO report and checked whether the IO is benign or not. The
manual results are compared with those generated by IntEQ.
We also compare the results with those by IntFlow [44].
We ran the SPECINT 2000 and 2006 benchmarks with the
standard `ref ' input set. For the 7 real-world applications,
we ran them with inputs that denote typical use cases as
follows: for Gimp, we scaled one ICSE'16 logo picture and
exported it as gifformat; for vlc, we played a 3.2M MP3
le; for Dillo, we visited its homepage and downloaded the
source code; for Pidgin, we performed various common tasks
(registering a new account, logging-in and out, and so on);
forwget, we downloaded the source code of GCC-4.5.0 from
GCC website; for gzip, we performed the gzip andgunzip
process on the GCC-4.5.0 source le; for Swfdec, we opened
aswfle.
Table 2 shows the results3. Columns 2 to 5 show the
number of IOs reported by IOC with the provided inputs.
Overall, IOC reported 527 IOs at runtime. Based on our
comprehensive manual analysis on each IO, we found that 9
of them are harmful (as shown in Column 2); 444 of them are
determined as benign IOs (as shown in Column 3); 49 IOs
only occur in intermediate computation and do not aect the
resulting value [25] (as shown in Column 4); and another 25
IOs belong to those that we are not certain if they are benign
(as shown in Column 5). We can see that IOs frequently
occur and most of them are benign.
Columns 6 and 7 show the numbers of benign IOs
recognized by IntFlow and IntEQ, respectively. In total, our
tool recognized 355 out of 444 (about 79.95%) benign IOs that
IOC have reported; whereas IntFlow can only recognize 19.
Also IntEQ performed well for both the SPEC benchmarks
and the real world applications.
For the remaining 20% benign IOs that IntEQ failed to
recognize, most of them belong to one of the following cases:
(1) the overowed data is stored in global variables and
our path extraction process failed to locate the use points
locally. Complete data ow information can be gathered for
2The details of overow-inducing les for these 8 cases can
be found at [5, 6, 7, 8, 9, 10, 11, 12], respectively.
3Note that 403.gcc and 464.h264ref cannot be compiled by
IOC under the current experimental environment. Besides,
IOC produces no IO report for 181.mcf, 256.bzip2, 300.twolf,
429.mcf, 471.omnetpp, 473.astar and Pdigin-2.10.11, and
hence they are not included in the table either.Table 2: Benign IOs recognized by IntEQ.
BenchmarkIOCIntFlow IntEQharmful benign casting unsure
164.gzip 1 9 4 0 0 8
175.vpr 0 5 0 0 0 5
176.gcc 8 74 18 0 0 48
186.crafty 0 4 0 0 1 3
197.parser 0 37 1 0 1 36
253.perlbmk 0 78 2 7 0 74
254.gap 0 64 0 0 10 41
255.vortex 0 2 0 0 0 2
400.perlbench 0 86 5 17 2 77
401.bzip2 0 12 6 0 0 8
445.gobmk 0 5 0 0 0 3
458.esjeng 0 1 2 0 0 1
483.xalancbmk 0 10 1 1 0 2
gzip-1.4 0 9 3 0 0 8
vlc-2.1.5 0 5 0 0 0 5
Dillo-3.0.4.1 0 12 0 0 0 11
wget-1.16 0 2 0 0 0 0
Gimp-2.8.0 0 20 7 0 0 17
Swfdec-0.8.4 0 9 0 0 5 6
Total 9 444 49 25 19 355
Table 3: Performance.
Benchmark #IOPath Extraction/EncodingSolv.#P #Node #IntOp Precs. Time
164.gzip 14 85 8.70/1/14 3.92/1/18 33/66 0.584 43.367
175.vpr 5 6 9.33/7/13 3.83/2/7 65/101 0.220 0.040
176.gcc 100 306 8.53/1/25 1.97/1/6 33/130 2.388 6.404
186.crafty 4 4 2.75/2/3 1.00/1/1 33/64 1.196 0.036
197.parser 38 52 15.52/1/27 7.71/1/15 33/202 0.148 16.909
253.perlbmk 87 456 6.43/2/193 2.04/1/179 33/232 277.800 2.340
254.gap 64 241 13.69/3/30 4.89/1/9 33/165 1.188 233.403
255.vortex 2 2 4.50/2/7 1.50/1/2 33/65 0.628 0.024
400.perlbench 108 838 7.79/3/207 4.57/2/175 65/228 289.310 15.430
401.bzip2 18 48 7.04/3/13 1.85/1/5 33/65 0.144 0.588
445.gobmk 5 5 4.20/3/11 1.20/1/2 33/96 1.028 0.092
458.esjeng 3 3 2.67/2/3 1.00/1/1 33/64 0.152 0.088
483.xalancbmk 11 58 2.31/2/8 1.12/1/4 33/67 11.905 2.044
local scalar variables using def-use chains provided by SSA.
However, it is relatively more dicult for global variables
as aliasing has to be considered to identify global variable
related def-use relations, and path reduction is not that
helpful for global variables; (2) the source operands of the
overowed integer operations are from trusted sources or
constants, but the overowed data in the two versions with
dierent precisions did have dierent values at sinks; (3)
IntEQ failed to recognized some benign IOs for hashing,
where the data ow paths involve recursive function calls or
cross over dierent object les. Note that for the case (2), we
can integrate IntEQ with IntFlow to gain better results. For
case (1) and (3), a more sophisticated static path extraction
component would mitigate the problems. We leave them to
our future work.
4.3 Performance
The performance of IntEQ would aect its usability.
Table 3 shows the performance of IntEQ and some internal
statistics on the SPEC benchmarks, excluding those that
have no IOs. Column 2 denotes the number of IOs. Columns
3 to 7 show the result of path extraction and encoding.
Column 3 is the number of extracted paths. On average,
about 4.58 paths are extracted for each IO report . Column
4 shows the number of nodes (i.e., statements) for each
extracted path. This column is in the form of ` a/b/c',
where `a ' means the average number of nodes, and ` b' and
`c' mean the minimum and maximum numbers. Column 5
has the similar format as Column 4, but presents the number
of integer arithmetic operations for each path. On average
there are about 7.19 nodes for each path, and 2.82 of them
10581#define MAC TABLE ENTRIES 64
2i f( i n u s e + mac data . e n t r i e s <=
MAC TABLE ENTRIES) {
3 s = i o v t ob u f ( iov , iov cnt , 0 , &macs [ i n u s e âˆ—
ETH ALEN] , mac data . e n t r i e s âˆ—ETH ALEN) ;
4 i f( s != mac data . e n t r i e s âˆ—ETH ALEN)
5 goto e r r o r ;
6 i nu s e += mac data . e n t r i e s ;
7}
Listing 4: A harmful IO in QEMU(CVE-2014-0150).
1#define POWER OF2or0 ( I ) \
2 ( ( ( I ) & ( ( unsigned ) ( I ) âˆ’1) == 0)
3
4int i n t e g e r o kf o r s e t ( unsigned int value ) {
5unsigned int mask = ( value |( value âˆ’1) ) ;
6return ( value && POWER OF2or0 (mask+1) ) ;
7}
8
9char âˆ—o u t p u t i o r ( rtx operands [ ] ) {
10 unsigned int value ;
11 . . .
12 else i f ( i n t e g e r o kf o r s e t ( value ) )
13 return ` ` s e t \%0,\%1,\%s2 ' ' ;
14 else
15 return ` ` or . u \%0,\%1,\%X2\n\tor \%0,\%0,\%
x2 ' ' ; }
Listing 5: A benign IO for range check in 176.gcc.
are integer arithmetic operations. Observe that the paths
we extracted are usually short.
Column 6 denotes the needed high precision for the
extracted paths, i.e. the number of bits we use in the
path encoding process. This column is in the form of ` a/b',
representing the minimum and maximum of high precision
for the collected paths, respectively. From this column, we
nd that for some paths, 33-bit precision is enough, and for
some other paths, 232-bit precision is needed.
Columns 7 and 8 are the time cost (in seconds) for the path
extraction/encoding and constraint solving processes. For
most programs, IntEQ can nish in less than one minute.
We argue the analysis time is reasonable. Note that for
253.perlbmk and 400.perlbench, IntEQ spent about ve
minutes to nish path extraction/encoding mainly because
there are about 68 IOs used in complex MD5 encryption. It
is also worth mentioning that the constraint solving time
varies over dierent paths, especially dierent operations
along the path. For instance, the average solving time is
only about 0 :012 second for each path in 255.vortex; whereas
the time is nearly one second for 254.gap because paths in
254.gap are usually long (13 :69 statements on average) and
have a number of multiplication and division operations,
which are usually time-consuming for solving.
4.4 Case Study
For the cases in Listings 1, 2 and 3, IntEQ doesn't
misclassify any of them, i.e., the constraint solving results
are SAT for Listing 1 and UNSAT for Listings 2 and 3. Next,
we will further present two other cases.
Range Check. Listing 4 presents a harmful IO [42],
caused by programmers conducting incorrect range check.
Line 3 attempts to read mac_data.entries entries from a
xed array macs, which has a size MAC_TABLE_ENTRIES , to
the buer iov, starting from the oset in_use . In order
to avoid buer overow, QEMU utilizes the range check at
line 2 to lter out requests that are too large. However,
due to IOs, the range check can be invalidated and a huge1/âˆ—XalanDOMString . cpp âˆ—/
2s i z e t y p e hash ( . . . ) {
3 s i z e t y p e theResult = 0 ;
4const theEnd = theString + theLength ;
5while ( theString != theEnd ) {
6 theResult += ( theResult âˆ—37) + ( theResult
>>24) + s i z e t y p e ( âˆ—theString ) ;
7 ++theString ;
8}
9return theResult ;
10}
11
12/âˆ—XalanDOMStringHashTable . cpp âˆ—/
13const XalanDOMString âˆ—f i n d ( . . . ) {
14 a s s e r t ( theString != 0) ;
15 s i z e t y p e theHash = hash ( theString ,
theActualLength ) ;
16 s i z e t theLocalBucketIndex = theHash \%
mbucketCount ;
17 BucketType& theBucket = m buckets [
theLocalBucketIndex ] ;
18 . . .}
Listing 6: A benign IO for hashing in
483.xalancbmk.
buer would be read, overowing the buer on heap. For
instance, if we set mac_data.entries as 0xffffffff and
in_use as 2, the sum is overowed to 1 and the predicate at
line 2 takes the true branch, allowing adversaries to bypass
this range check. However, the sum in the high precision
version would be represented accurately, i.e., 0x 100000001,
and the predicate takes the false branch. As a result, IntEQ
identies this IO as harmful.
Listing 5 also shows a case of range check, where an
IO occurs. However this IO is benign. At line 12 the
programmer checks the range of variable value to determine
the emitted code using function integer_ok_for_set() .
The function further checks whether mask+1 is a power of
two or zero at line 6 using a macro at line 1. This addition
would overow only when mask equals to 0 xffffffff . In
this overow case, the macro holds the true value because
at line 2, Ihas value 0 (due to the overow) and Iâˆ’1 yields
0xffffffff . In the high precision version, the result of
this addition is 0 x100000000 and the macro also holds the
true value. Hence, IntEQ recognizes this IO as benign, as
the overowed value has no harmful eect on the macro and
the range check at line 12.
Observe that the two IOs are quite similar, i.e., the integer
addition overows and then the overowed data is used at
a predicate. The dierence lies in that the use of the bit
AND at line 2 in Listing 5 suggests that the programmer has
considered potential IO in his/her design. IntEQ is capable
of capturing such subtle dierence.
Hashing. Listing 6 shows a code snippet from 483.x-
alancbmk. The IOs at line 6 in function hash() are used
intentionally by the programmer to generate a hash value,
and this hash value is further used by the array indexing
statement at line 17 in function find() in a dierent source
le. Recall the current implementation of IntEQ can only
extract paths within a single object le. As such, we
cannot extract the full path (i.e., 6 â†’7â†’9â†’15â†’16â†’17).
Instead, IntEQ tries to prove equivalence for its sub-path
(i.e., 6 â†’7â†’9) within the same source le. Unfortunately,
equivalence cannot be proved for the sub-path whereas it
can be proved with the full path. We anticipate extracting
paths across multiple les would allow us to handle these
cases. We leave it to our future work.
10594.5 Limitations
IntEQ is a static analysis. It hence bears the inherent
limitations of static analysis in general. It relies on loop
unrolling, which bounds its soundness. It mitigates the
aliasing problem by proving equivalence for sub-paths that
end at pointer de-references. This may miss some benign
IOs. The current implementation does not support paths
across multiple les. Finally, the ground truth that we
use to evaluate IntEQ is manually generated by going
through the over 500 IO reports produced by IOC. Human
errors may be introduced during the manual classication.
However, we have cross-checked with the CVE repository
and existing work on IO vulnerabilities [26, 52, 49, 23] and
found that there are no IO vulnerabilities reported on the
SPEC programs and the 7 real world programs we used
in studying the eectiveness of IntEQ in identifying benign
IOs. This supports our ndings to some extent.
5. RELATED WORK
IO Detection. RICH [19], IOC [26], AIR [25] and
BRICK [21] utilize instrumentation to provide runtime
protections for IOs. It is important to note that IntEQ is
very dierent from AIR, since AIR does not increase the
precision actually. Its key idea is that if no IOs happen,
the integers behave as if they have innite range. If an IO
happens, the overowed value is marked and a congurable
handler is invoked when this marked value reaches an
observation point. SmartFuzz [37] uses symbolic execution
to generate test cases to invoke integer errors. Safe integer
libraries, such as SafeInt [33], CERT's IntegerLib [20, 23]
and Ranged Integer [28], are used to wrap integer operations.
These approaches treat allinteger operations in program
as potential overow sites; they guarantee to handle all the
overows. However, this safety has a price, producing a lot
of false positives for benign IOs. As shown in Section 4.2,
IntEQ can recognize about 79.95% benign IOs, hence greatly
improving the accuracy of IO detection for these approaches.
IO2BO Detection. Integer overow to buer overow
(IO2BO) [3], is \a kind of IOs, i.e. an IO occurs when
a program performs a calculation to determine how much
memory to allocate, which causes less memory to be allocat-
ed than expected, leading to buer overow" [55]. Due to its
prevalence, severe damage and easy exploitation, researchers
have developed many techniques to handle this kind of IO.
They usually rst utilize taint analysis to extract the integer
operations along critical paths, from external sources to
memory-related routines, and then apply various detection
techniques particularly on these selected integer operations.
Specically, KINT [52], IntScope [51] and DIODE [48] use
symbolic execution to generate test cases to trigger IO2BOs.
IntPatch [55] and IntTracker [49] insert overow checks
around selected integer operations to prevent IO2BOs.
SIFT [35] aims to generate lters, precluding inputs which
might trigger IO2BOs. SoupInt [50] is an o-line system
that can automatically generate emergency patches from
attacks against IO2BO exploits. CP [47] is an automatic
patching tool, transferring the patch for an IO2BO from
donor applications to recipient applications.
As stated in [55, 35], the IOs in the context of IO2BOs can-
not be benign, i.e. overows are rarely used intentionally by
programmers for memory manipulations. Therefore, these
approaches report no benign IOs theoretically. However,according to [49], many IOs fall into other categories (e.g.,
exploits by changing branch outcomes).
Safe Integer Operation Identication. An integer
operation can be treated as safe if it will not overow or
the program security will not be aected even if it overows.
RA [45] presents and uses precise range analysis to eliminate
unnecessary overow checks, if some integer operation can
be statically determined that it cannot overow. Although
experiments show that RA could avoid 25% checks, it would
still produce false positives for benign IOs. IntFlow [44]
identies safe integer operations by checking whether they
originate from trusted sources, based on the observation that
even if these integer operations overow, they still cannot
be controlled by adversaries. Experiments in Section 4.2
show that IntFlow recognized only 19 out of 444 benign IOs.
Our approach is substantially dierent. For the benign IOs
recognized by IntEQ, the corresponding overowed integer
arithmetic operations are also safe.
Semantic Equivalence Checking. The approach of
regression verication [29] uses SMT solvers to check equiv-
alence of C programs in the presence of mutual recursion.
SymDi [31] is a language-agnostic semantic di tool for
imperative languages. It presents dierential symbolic
execution [43] that analyzes behavioral dierences between
dierent versions of a program. CoP [36] is a binary-
oriented, obfuscation-resilient software plagiarism detection
approach, which is based on a new concept, longest common
subsequence of semantically equivalent basic block . The
equivalence of two basic blocks is determined by checking via
a theorem prover the pair-wise equivalence of the symbolic
formulas that represent the input-output relations of the
basic block. In IntEQ, instead of comparing two dierent
basic blocks from similar programs, we turn to create a
new version of the path with high precision (sucient bits
to represent integers) and compare the equivalence between
these two versions by checking the output at sinks.
6. CONCLUSIONS
In this paper, we propose and design a static integer
overow classier, IntEQ, based on equivalence checking
across multiple precisions. We determine if an IO is
benign by comparing the eects of the overowed data
and the corresponding data in the ideal world at the sink.
The experimental results demonstrate that IntEQ does not
misclassify any harmful IO bug from our testbed (no false
negatives) and recognizes 355 out of 444 benign IOs; whereas
the state-of-the-art, IntFlow, recognizes only 19 benign
IOs. IntEQ is publically available at: https://github.com/
shqking/inteq.
7. ACKNOWLEDGMENTS
We thank the anonymous reviewers for their constructive
comments. The authors are supported by National NSF
of China under Grant No. 61170070, 61572248, 61431008,
61321491, National Key Technology R&D Program of Chi-
na under Grant No. 2012BAK26B01, the Program B for
Outstanding PhD candidate of Nanjing University, NS-
F(US) under awards 1409668 and 0845870, ONR(US) under
contract N000141410468, and Cisco Systems(US) under an
unrestricted gift. Any opinions, ndings, and conclusions
in this paper are those of the authors only and do not
necessarily reect the views of our sponsors.
10608. REFERENCES
[1] CWE-190: Integer overow or wraparound.
http://cwe.mitre.org/data/denitions/190.html.
[2] CWE-2011 CWE/SANS top 25 most dangerours
software errors. http://cwe.mitre.org/top25/.
[3] CWE-680: IO2BO vulnerabilities.
http://cwe.mitre.org/data/denitions/680.html.
[4] GCC, the GNU Compiler Collection.
https://gcc.gnu.org/.
[5] Overow-inducing input for CVE-2005-0199.
https://bugs.gentoo.org/show\ bug.cgi?id=79705.
[6] Overow-inducing input for CVE-2005-1141.
http://www.overow.pl/adv/gocr.txt.
[7] Overow-inducing input for CVE-2006-2971.
http://www.exploit-db.com/exploits/1894/.
[8] Overow-inducing input for CVE-2006-4812.
http://www.exploit-db.com/exploits/28760/.
[9] Overow-inducing input for CVE-2008-1384.
http://cxsecurity.com/issue/WLB-2008030052.
[10] Overow-inducing input for CVE-2008-1801.
http://www.securityfocus.com/bid/29097/exploit.
[11] Overow-inducing input for CVE-2008-3732.
http://www.exploit-db.com/exploits/6252/.
[12] Overow-inducing input for CVE-2011-1092.
http://www.exploit-db.com/exploits/16966/.
[13] Spec cpu 2000 benchmark.
http://www.spec.org/cpu2000/.
[14] Spec cpu 2006 benchmarks.
http://www.spec.org/cpu2006/.
[15] The Z3 Constraint Solver.
https://github.com/Z3Prover/z3.
[16] Vulnerability Type Distributions in CVE (2001-2006).
https:
//cve.mitre.org/docs/vuln-trends/vuln-trends.pdf.
[17] J. Alglave, D. Kroening, and M. Tautschnig. Partial
orders for ecient bounded model checking of
concurrent software. In Proceedings of the 25th
International Conference on Computer Aided
Verication, pages 141{157, 2013.
[18] S. Bandhakavi, S. T. King, P. Madhusudan, and
M. Winslett. Vex: Vetting browser extensions for
security vulnerabilities. In Proceedings of 19th
USENIX Security Symposium , pages 339{354, 2010.
[19] D. Brumley, D. X. Song, T. cker Chiueh, R. Johnson,
and H. Lin. RICH: Automatically protecting against
integer-based vulnerabilities. In Proceedings of 14th
Annual Network and Distributed System Security
Symposium , 2007.
[20] CERT. Integerlib, a secure integer library.
http://www.cert.org/secure-coding/IntegerLib.zip,
2006.
[21] P. Chen, Y. Wang, Z. Xin, B. Mao, and L. Xie.
BRICK: A binary tool for run-time detecting and
locating integer-based vulnerability. In Proceedings of
International Conference on Availability, Reliability
and Security , pages 208{215, 2009.
[22] B. Chimdyalwar, P. Darke, A. Chavda, S. Vaghani,
and A. Chauhan. Eliminating static analysis false
positives using loop abstraction and bounded model
checking. In Proceedings of 20th International
Symposium on Formal Methods , pages 573{576. 2015.[23] Z. Coker and M. Haz. Program transformations to
x C integers. In Proceedings of 35th International
Conference on Software Engineering , pages 792{801,
2013.
[24] L. Cordeiro, B. Fischer, and J. Marques-Silva.
SMT-based bounded model checking for embedded
ansi-c software. IEEE Transactions on Software
Engineering , 38(4):957{974, 2012.
[25] R. B. Dannenberg, W. Dormann, D. Keaton, R. C.
Seacord, D. Svoboda, A. Volkovitsky, T. Wilson, and
T. Plum. As-if innitely ranged integer model. In
Proceedings of 21st International Symposium on
Software Reliablity Engineering, pages 91{100, 2010.
[26] W. Dietz, P. Li, J. Regehr, and V. S. Adve.
Understanding integer overow in C/C++. In
Proceedings of 34th International Conference on
Software Engineering, pages 760{770, 2012.
[27] V. Ganesh and D. L. Dill. A decision procedure for
bit-vectors and arrays. In Proceedings of 19th
International Conference on Computer Aided
Verication , pages 519{531, 2007.
[28] J. Gennari, S. Hedrick, F. Long, J. Pincar, and R. C.
Seacord. Ranged integers for the c programming
language. Technical Note CMU/SEI-2007-TN-027,
Carnegie Mellon University, 2007.
[29] B. Godlin and O. Strichman. Regression verication.
InProceedings of the 46th Annual Design Automation
Conference, pages 466{471, 2009.
[30] A. Kiezun, V. Ganesh, P. J. Guo, P. Hooimeijer, and
M. D. Ernst. HAMPI: a solver for string constraints.
InProceedings of the 18th International Symposium on
Software Testing and Analysis , pages 105{116. ACM,
2009.
[31] S. K. Lahiri, C. Hawblitzel, M. Kawaguchi, and
H. Reb^ elo. SYMDIFF: A language-agnostic semantic
di tool for imperative programs. In Proceedings of the
24th International Conference on Computer Aided
Verication , pages 712{717, 2012.
[32] M. Lam, R. Sethi, J. Ullman, and A. Aho. Compilers:
Principles, techniques and tools, 2006.
[33] D. LeBlanc. Safeint. http://safeint.codeplex.com/.
[34] L. Li, C. Cifuentes, and N. Keynes. Boosting the
performance of ow-sensitive points-to analysis using
value ow. In Proceedings of the 19th ACM SIGSOFT
Symposium and the 13th European Conference on
Foundations of Software Engineering , pages 343{353,
2011.
[35] F. Long, S. Sidiroglou-Douskos, D. Kim, and M. C.
Rinard. Sound input lter generation for integer
overow errors. In Proceeds of 41st Annual ACM
SIGPLAN-SIGACT Symposium on Principles of
Programming Languages , pages 439{452, 2014.
[36] L. Luo, J. Ming, D. Wu, P. Liu, and S. Zhu.
Semantics-based obfuscation-resilient binary code
similarity comparison with applications to software
plagiarism detection. In Proceedings of the 22nd ACM
SIGSOFT International Symposium on Foundations
of Software Engineering , pages 389{400, 2014.
[37] D. Molnar, X. C. Li, and D. Wagner. Dynamic test
generation to nd integer bugs in x86 binary linux
programs. In Proceedings of 18th USENIX Security
Symposium , pages 67{82, 2009.
1061[38] National Vulnerability Database. CVE-2006-2971.
http://web.nvd.nist.gov/view/vuln/detail?vulnId=
CVE-2006-2971.
[39] National Vulnerability Database. CVE-2008-1722.
http://web.nvd.nist.gov/view/vuln/detail?vulnId=
CVE-2008-1722.
[40] National Vulnerability Database. CVE-2008-1801.
http://web.nvd.nist.gov/view/vuln/detail?vulnId=
CVE-2008-1801.
[41] National Vulnerability Database. CVE-2012-4405.
http://web.nvd.nist.gov/view/vuln/detail?vulnId=
CVE-2012-4405.
[42] National Vulnerability Database. CVE-2014-0150.
http://web.nvd.nist.gov/view/vuln/detail?vulnId=
CVE-2014-0150.
[43] S. Person, M. B. Dwyer, S. Elbaum, and C. S.
Psreanu. Dierential symbolic execution. In
Proceedings of the 16th ACM SIGSOFT International
Symposium on Foundations of software engineering ,
pages 226{237. ACM, 2008.
[44] M. Pomonis, T. Petsios, K. Jee, M. Polychronakis,
and A. D. Keromytis. IntFlow: improving the
accuracy of arithmetic error detection using
information ow tracking. In Proceedings of 30th
Annual Computer Security Applications Conference ,
pages 416{425, 2014.
[45] R. E. Rodrigues, V. H. S. Campos, and F. M. Q.
Pereira. A fast and low-overhead technique to secure
programs against integer overows. In Proceedings of
International Symposium on Code Generation and
Optimization , pages 1{11, 2013.
[46] L. Shang, X. Xie, and J. Xue. On-demand dynamic
summary-based points-to analysis. In Proceedings of
the 10th International Symposium on Code Generation
and Optimization , pages 264{274, 2012.
[47] S. Sidiroglou-Douskos, E. Lahtinen, F. Long, and
M. Rinard. Automatic error elimination by horizontal
code transfer across multiple applications. In
Proceedings of the 36th ACM SIGPLAN Conference
on Programming Language Design and
Implementation , pages 43{54, 2015.
[48] S. Sidiroglou-Douskos, E. Lahtinen, N. Rittenhouse,
P. Piselli, F. Long, D. Kim, and M. Rinard. Targeted
automatic integer overow discovery using
goal-directed conditional branch enforcement. In
Proceedings of the 20th International Conference onArchitectural Support for Programming Languages and
Operating Systems , pages 473{486, 2015.
[49] H. Sun, X. Zhang, C. Su, and Q. Zeng. Ecient
dynamic tracking technique for detecting
integer-overow-to-buer-overow vulnerability. In
Proceedings of 10th ACM Symposium on Information,
Computer and Communications Security , pages
483{494, 2015.
[50] T. Wang, C. Song, and W. Lee. Diagnose and
emergency patch generation for integer overow
exploits. In Proceedings of 11th Conference on
Detection of Intrusions and Malware & Vulnerability
Assessment , pages 255{275, 2014.
[51] T. Wang, T. Wei, Z. Lin, and W. Zou. IntScope:
Automatically detecting integer overow vulnerability
in x86 binary using symbolic execution. In Proceedings
of the Network and Distributed System Security
Symposium , 2009.
[52] X. Wang, H. Chen, Z. Jia, N. Zeldovich, and M. F.
Kaashoek. Improving integer security for systems with
KINT. In Proceedings of 10th USENIX Symposium on
Operating Systems Design and Implementation, pages
163{177, 2012.
[53] Y. Xie and A. Aiken. Static detection of security
vulnerabilities in scripting languages. In Proceedings of
15th USENIX Security Symposium , pages 179{192,
2006.
[54] G. Yorsh, E. Yahav, and S. Chandra. Generating
precise and concise procedure summaries. In Proceeds
of 35th Annual ACM SIGPLAN-SIGACT Symposium
on Principles of Programming Languages . Citeseer,
2008.
[55] C. Zhang, T. Wang, T. Wei, Y. Chen, and W. Zou.
IntPatch: Automatically x
integer-overow-to-buer-overow vulnerability at
compile-time. In Proceedings of the 15th European
Conference on Research in Computer Security , pages
71{86, 2010.
[56] Y. Zheng and X. Zhang. Static detection of resource
contention problems in server-side scripts. In
Proceedings of 34th International Conference on
Software Engineering, pages 584{594, 2012.
[57] Y. Zheng and X. Zhang. Path sensitive static analysis
of web applications for remote code execution
vulnerability detection. In Proceedings of 35th
International Conference on Software Engineering ,
pages 652{661, 2013.
1062