Towards Automating Disambiguation of Regulations: Using the
Wisdom of Crowds
Manasi Patwardhan
TCS Research
TRDDC,54HadapsarIndustrialEstate
Pune, Maharashtra, India
manasi.patwardhan@tcs.comAbhishek Sainani
TCS Research
TRDDC,54HadapsarIndustrialEstate
Pune, Maharashtra, India
a.sainani@tcs.comRicha Sharma
TCS Research
TRDDC,54HadapsarIndustrialEstate
Pune, Maharashtra, India
sharma.richa5@tcs.com
Shirish Karande
TCS Research
TRDDC,54HadapsarIndustrialEstate
Pune, Maharashtra, India
shirish.karande@tcs.comSmita Ghaisas
TCS Research
TRDDC,54HadapsarIndustrialEstate
Pune, Maharashtra, India
smita.ghaisas@tcs.com
ABSTRACT
Compliant software is a critical need of all modern businesses. Dis-
ambiguating regulations to derive requirements is therefore an
important software engineering activity. Regulations however are
riddenwithambiguitiesthatmaketheircomprehensionachallenge,
seemingly surmountable only by legal experts. Since legal experts’
involvement in every project is expensive, approaches to automate
thedisambiguationneedtobeexplored.Theseapproacheshowever
require a large amount of annotated data. Collecting data exclu-
sively from experts is not a scalable and affordable solution. In
this paper, we present the results of a crowd sourcing experiment
to collect annotations on ambiguities in regulations from profes-sional software engineers. We discuss an approach to automate
thearduousandcriticalstepofidentifyinggroundtruthlabelsby
employing crowd consensus using Expectation Maximization (EM).
We demonstratethat the annotations reachinga consensus match
those of experts with an accuracy of 87%.
CCS CONCEPTS
•Socialandprofessionaltopics →Governmentalregulations ;
•Software and its engineering →Requirements analysis;
KEYWORDS
Regulatorycompliance,Ambiguities,Disambiguation,Crowdsourc-
ing, Expectation-Maximization
ACM Reference Format:
Manasi Patwardhan, Abhishek Sainani, Richa Sharma, Shirish Karande,
andSmitaGhaisas.2018.TowardsAutomatingDisambiguationofRegula-
tions:UsingtheWisdomofCrowds.In Proceedings of the 2018 33rd ACM/IEEE
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3240727International Conference on Automated Software Engineering (ASE ’18), Sep-
tember 3–7, 2018, Montpellier, France. ACM, New York, NY, USA, 6pages.
https://doi.org/10.1145/3238147.3240727
1 INTRODUCTION
Ambiguitiesinregulations,whetherintentionalorunintentional,
poseachallengetoorganizationsthatmustcomplywiththem.The
processofderivingsystemrequirementsfromregulationstherefore
tends to be error prone and regulations are increasingly seen to be
subject to misuse, abuse, and violation [ 1]. To minimize ambiguity
inregulations,Hoefleretal.[ 2]restrictedthevocabulary,syntax
and/orsemanticsofSwisslegalGerman.Similarly,Cecietal.[ 3]de-
vised an approach that enables machine-readable representation of
regulatory requirements while maintaining precision and specific
semanticsoflegalknowledge.Ghaisasetal.[ 4]haveemployedDeep
learningtechniquestoresolveambiguitiesinregulationstatements
by augmenting the statements with relevant additional informa-
tion. Apart from these, there has been work done on automatically
identifyingambiguitiesinrequirementsdocuments[ 5],minimizing
ambiguities in requirements documents [ 6] and identifying and
minimizing ambiguities in policy statements [7].
Massey et al. have created a legal ambiguity taxonomy to identify
and classify ambiguities in regulations [ 8]. They call for strategies
for organizations to efficiently resolve ambiguities in legal text,
becausetheirresultssuggestthatsoftwareengineers(graduateand
undergraduate students)need expert inputs tovalidate their inter-
pretations of ambiguities [ 9]. Since experts’ involvement in every
software engineering project is expensive, approaches to automate
the disambiguation need to be explored. Models for automation
requirealargeamountofannotateddataandcollectingthisdata
fromexpertsisnotascalablesolutioneither.Weinvestigatethis
line of research further by aiming to automate the disambiguation
of regulation statements with a reduced involvement of experts.
Understandingregulatoryrequirementsisanimportantsoftware
engineering activity for professional software engineers who need
tobuildlargesystemscompliantwithregulations.Forthispurpose,
ecantapintothepotentialofcrowdsourcingisyettobefullyex-
plored inthe field of softwareengineering [ 10–13]. Inthis paper,
we presentour work on apreliminary crowdsourcing experiment
850
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:10:52 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France M. Patwardhan et al.
Table 1: Ambiguity Examples
Type of Regulatory Statement Question Answers
Ambiguity (marked term in bold) (valid answers in bold)
Lexically
Ambigu-
ousImplementhardware,software,and/orprocedural
mechanisms that recordand examine activity in
informationsystemsthatcontainoruseelectronic
protected health information.In the given sen-
tence what is the
meaning of word
‘record’?(a)to put in writing or digital form for
futureuse (b)informationstoredonacom-
puter (c) best performance. (d) to make a
permanent or official noteof (e) a piece
of evidence from the past
Lexically
Unam-
biguousA group health plan must ensure that its plan
documentsprovidethattheplansponsorwillrea-
sonably and appropriately safeguard electronicprotected health information created, received,maintained, or
transmitted to or by the plan
sponsor on behalf of the group health plan.In the given sen-tence what is themeaning of word
‘transmit’?(a)totransfersomethingfromoneper-
son to another (b) to be a medium for an
idea or emotion (c) to broadcast something
(d)topassonsomethingfromparenttochild(e)tocausetopassthroughairorsomeother
medium
Syntactically
Ambigu-
ousImplementpoliciesandprocedurestoaddressthe
final disposition of electronic protected health
information, and/or the hardware or electronic
media on which it is stored.In the given sen-tence the phrase
‘final disposition
of’ refers to?(a)electronicprotectedhealthinforma-
tion(b) policies (c) hardware (d) address
(e)electronic media
Syntactically
Unam-
biguousImplementsecuritymeasurestoensurethat elec-
tronically transmitted electronic protected
health information is not improperly modified
without detection until disposed of.In the given sen-tence the phrase
‘electronically
transmitted’
refers to?(a)improperlymodified(b) electronicpro-
tected health information (c) detection
(d) security measures (e) disposed of
Semantically
Ambigu-
ousA covered entity may obtain consent of the indi-
vidualtouseordiscloseprotectedhealthinforma-
tion to carry out treatment, payment, or health
care operations.What does ‘con-
sent’ mean?(a)Permission to share (b) Permission to
dispose(c)Permissiontopublicize(d)Per-
mission to use in court (e) Permission to
use for the stated purpose
Semantically
Unam-
biguousA covered entity may use professional judgment
anditsexperiencewithcommonpracticetomake
reasonableinferencesoftheindividual’sbestin-
terest in allowing a person to act on behalf of
theindividualtopickupfilledprescriptions,med-
ical supplies, X-rays, or other similar forms of
protected health information.What does ‘X-
rays’ mean?(a)X-Raydiffractionspectrumplots(b)Elec-
tromagnetic radiations of high energy (c)
Images of internal organs in a humanbody
(d)Multipliereffect(e)Unknownrays
to collect disambiguation data from a crowd of professional soft-
wareengineers.However,crowdsourcingposeschallengesinterms
of malicious labeling and arriving at consensus. Such challengescan be mitigated by using majority voting [
14] or aggregation
methodslikeExpectationMaximization(EM)[ 15–17]whichallows
measurement of various parameters relevant to the crowdsouring
experiment such as workers’ competence, intention, task difficulty,
etc. We prefer EM over majority voting as, along with providingground truth labels for disambiguation, EM allows us to model
ambiguity intensities as reflected in inter-annotator disagreements
and worker skills/spam.
Responses (in terms of valid/invalid set of answers) for which con-
sensusisachieved,provideannotationsfordisambiguationofregu-
lationstatements.Inourwork,annotations areseentomatchthe
groundtruthlabelsprovidedbytheexpertswithahighaccuracy
of 87%, indicating that the wisdom of software engineers’ crowd
canbeleveragedforthispurpose.Ifcollectedonalargescale,these
annotations along with the regulation statements can be furtherused as a training dataset for automating the disambiguation ofregulations. To the best of our knowledge, ours is the first attempt
to employ crowdsourcing and EM to obtain ground truth labels
towards automating the disambiguation of regulation statements.
The rest of the paper is organized as follows. In section II, we
describethedetailsofexpertannotateddata.SectionIIIpresents
discussiononthecrowdsourcingexperimentconductedfollowed
bytheformulationoftheEMmodelforachievingcrowdconsensus
insection IV.In sectionV, wediscussour preliminaryresults, and
section VI concludes the paper.
2 EXPERT ANNOTATED GROUND TRUTH
DATA
Forourstudy,wesoughtgroundtruthinputsfromthreeexperts
whohave workedwith HealthInsurancePortability andAccount-
abilityAct (HIPAA)regulations[ 18]for morethan3years. While
identifyingambiguitiesinregulationstatements,theexpertsused
Massey’s definitions and examples as guidelines [8]. There are six
distincttypesofregulationambiguitiesdefinedbyMasseyetal.,viz.
851
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:10:52 UTC from IEEE Xplore.  Restrictions apply. Towards Automating Disambiguation of Regulations: Using the Wisdom of Crowds ASE ’18, September 3–7, 2018, Montpellier, France
Lexical, Syntactic, Semantic,Incompleteness, Vagueness, and Refer-
ential. We havefocusedon thefirst three.The expertsidentified a
totalof38regulationstatementscontainingoneormoretypeofam-
biguities. For each ambiguity type, they selected (i) 15 statements,
each containingan ambiguousterm/phrase and (ii)15 statements
containingaterm/phrasewhichisunambiguousorlessambiguous
from the perspective of that ambiguity type. A term/phrase in a
regulationstatementislexicallyambiguousifithasmultipledictio-
narymeanings.Disambiguationherewouldmeanexplicatingthe
exact meaning as applicable to the statement from among those
multiple meanings. Syntactic ambiguity points at multiple word as-
sociations leading to multiple parse trees and disambiguation here
amounts to clarifying the scope of the word association. Semantic
ambiguity occurs if a statement is not self-contained and disam-
biguationwouldmeanprovidingadditionalcontextualinformation
for interpretation.
In addition to the marking of the term/phrase, the experts posed
a question about the term/phrase, which when answered, wouldlead to disambiguation of the term and thus the statement. Theexperts also provided a list of five ( a mix of valid and invalid)
possibleanswerstoeachoftheposedquestions.Invalidanswers
areasimportantasvalidanswersfordisambiguation,tofindout
ifthecrowd canreachconsensusindistinguishingbetweenthem.
Also,incaseofautomaticdisambiguation,alongwiththevaliddata
which helps with disambiguation, the machine learning models
will need invalid or negative data as well.
Table1illustrates examples for ambiguous and unambiguous regu-
lation statements for each of the three types of ambiguities, along
with the marked term, the question posed, and the answers pro-
vided.AsevidentfromTable 1,forambiguoustermsthenumber
of valid answers are more than that of unambiguous terms. One
regulation statement may have more than one type of ambiguities
caused by distinct set of terms/phrases in the regulation statement,
and thus may appear in the dataset of more than one ambiguitytypes.Forexample,forthestatement,"Implement hardware, soft-
ware, and/or procedural mechanisms that record and examine activityin information systems that contain or use electronic protected health
information ", the terms/phrases ‘record’, ‘mechanisms’, ‘examine
activity’are lexically, syntactically and semantically ambiguous,
respectivelyandthus,thestatementiscommonforeachambigu-
itytype.However,thequestionsposedandthecorrespondingset
of valid/invalid answers are different for each ambiguity type as
shown in Table 2.
3 CROWDSOURCING EXPERIMENT
The expert annotated data, as discussed in Section II above, served
as the basis for generating crowd tasks for our crowdsourcing
experiment. A task consisted of (i) a regulation statement, (ii) a
term/phrase marked, (iii) a question posed on the term/phrase for
disambiguation,and(iv)asetoffiveanswers.Foreachambiguity
type, we created 30 such tasks, giving us a total of 90 tasks. We tar-
geted a crowd of professional software engineers with 3 to 4 years
ofexperience(henceforthreferredtoascrowdworkers).Theywere
askedtodothetasksduringtheirwork-hourssothattheyperceivetheworkasaseriousprofessionalcontribution,andnotasaleisure
activity.Acrowdworkerisaskedto(i)readthegivenregulatoryTable 2: A Regulation Statement having Distinct Types of
Ambiguities
Ambiguity Question Answers
Type (valid answers in bold)
Lexical What is the
meaning ofthe word
‘record’?a)to put in writing or digital
form forfuture use b) informa-
tion stored on a computer c) best
performance d) to make a per-
manent or official note of e) a
piece of evidence from the past
Syntactic What
word/words
refer to the
term‘mecha-
nisms’?a) record b) procedural c)soft-
wared) examine e) hardware
Semantic What does
‘examine
activity’
mean?(a)Keepalogofwhatwasdone(b)
Notifyadminthatsomethingwas
done (c) Stop/block what is be-ing done (d)
Identify what was
done(e) Classify what was done
statement along with the marked term or phrase, (ii) read the ques-
tion posed on the marked term/phrase, and (iii) choose any subset
of the answers as valid answers to the posed question, consider-ing the given regulation statement and the marked term/phrase.
Acrowdworker’sresponsetoananswerwouldbe‘yes’ifhe/she
thinks that the answer is valid; else the response would be ‘no’.
We collected data using our indigenous crowdsourcing platform.
A clear set of instructions specific to an ambiguity type was pro-
vided to the workers. Along with instructions, we also provided
an example of the task and the correct set of responses for refer-ence. We highlighted the term/phrase that is creating ambiguityin the statement, so that a crowd worker could easily focus onthat term/phrase within the regulation statement as the contextfor providing responses. The question posed on the term/phrase
in thetask had fivepossible answers, whereeach answer iseither
valid or invalid. Each crowd worker was given 10 tasks to perform
sequentially.Basedontheirunderstanding,foreachtasktheworker
was to label each valid answer as ‘Yes’, and each invalid answer
as‘No’.Weachievedredundancybycollectingresponsesfrom15
crowdworkersforeachtask.Inall,116crowdworkersparticipated
in our experiment.
4 CROWD CONSENSUS USING
EXPECTATION MAXIMIZATION
WehaveusedExpectationMaximization(EM)techniquetoachieve
consensusoncrowdresponses.Themoreambiguousatermora
phraseinaregulationstatement,thelargerwouldbethenumberof
different interpretations crowd workers are likely to come up with.
This inter-annotator disagreement for ambiguous terms or phrases
among crowd workers is expected to be high and it represents the
extent or intensity of the ambiguity in the term or phrase.
InourEMmodel,theobservablevariableisthelabel(True/False)
providedbythecrowdworkers.Thelatentvariablesincludetask
852
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:10:52 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France M. Patwardhan et al.
Figure 1: Plate Representation of the EM Model
ambiguity level, probability of a worker being spammer or non-
spammer, and a small factor which reduces the probability with
whichaworkerlabelsanambiguousanswercorrectly.IntheEx-
pectation step (E-step) thelatent variables are assigned some seed
values and probability of a label being true or false is calculated
taking into account the crowd resp onses. In the Maximization step
(M-step) combinations of latent variables that maximize the likeli-
hood of observable variable being true or false is calculated. These
values are fed into the latent variables in successive iteration until
the values converge.
Aroyoet.alin‘Threesidesofcrowd-truth’[ 19]indicatethatthe
inter-annotatordisagreementcanbearesultof:(i)Ambiguityinthe task, which in our case is the regulation statement with the
term/phrasemarkedandtheanswersprovidedtotheposedques-
tion,(ii)Workerspamduetoattitudinalproblemsorlackofrequired
skillsorfatigue,(iii)Ambiguityinthetaskdesign.Wehavealready
modeledforambiguityandworkerspam/expertiseaslatentparame-ters,andthustakenintoaccountfactors(i)and(ii)whilecomputing
consensus (annotator agreement). To eliminate the effect of (iii)
above,weensureunambiguoustaskdesignbyprovidingdetailed
instructions with examples to the crowd workers as discussed ear-
lier in Section 3. For checking validity of answer, we provide only
twochoices(‘Yes’or‘No’),withthemeaningofthechoicesbeing
simple and clear and explained as a part of the instructions.
We build upon [ 15] for our EM formulation. Table 3provides
notation used for the EM model. Given the observed variables
L, we would like to estimate the parameters Z. The set of latent
parameters are θ=<αk,tij,p0,p1,a>. These are explained in
Table3.
Thecausalmodeloftheannotationprocessofthecrowdsourcing
task is shown schematically in Fig. 1. The task target values, Zand
allthelatentparameters, θareassumedtobegeneratedindepen-
dently.Toensurethattheestimationprocessdegradesgracefully
withlessavailabledata,wetakeBayesianpointofviewwithpriors
on the target values and the latent parameters, as represented in
Fig.1.Thepriorsencodeourpriorbeliefsaboutthetargetvalues
andthelatent parameters.Forexample,the prior ζonthetarget
valueszijbelievesthat50%ofthetargetvaluesare1(validanswer)
and50%are0(invalidanswer),formingauniformdistributionwith
probability 0.5. Our prior belief of the type of crowd worker βis
modeled using a Beta-distribution having Beta densities that are
increasingly peaked towards 0.9 indicating that most of the honest
workers are experts having high True Positive ( p1) and True Nega-
tive (p0) rates. Also, (p1,p0)are kept common across all the crowd
workers, and are not made crowd worker specific to avoid largeTable 3: EM Notation
Notation Meaning
Z=
{zij}Set of target values (parameters to be estimated).
zij∈{0,1}is the target value of jthanswer for ith
regulatorystatement.1indicatesvalidanswerand0
indicatesinvalidanswer. i=1,···,Nindicatingthere
areNtasks(regulationstatementswithatermmarked
and a question posed on the term) and j=1,···,M
indicating there are Manswers provided to each task.
Forsimplicity,wehavefixedthenumberofanswers
as M.
L=
{lijk}Set of annotations / labels, where lijkis the label
provided to answer jof taskiby crowd worker k.
k=1,···,Pindicatingthereare Pnumberofwork-
ers who have provided labels to this task. Pcan vary
per task.lijk∈{0,1}, where 1 indicates valid answer
and 0 indicates invalid answer.
Ai Set of crowd workers who have provided labels to all
answers of task i
Tk Set of tasks annotated by worker k
αk Probability that a worker kis a spammer, αk∈[0,1]
tij Probabilitythatthe jthansweroftask iisambiguous.
p0 Probability that an honest crowd worker (non-
spammer)labelsanunambiguousinvalidanswerwithgroundtruthas0correctly.ThisrepresentsTrueNeg-
ative (TN) rate of a worker with p0∈[0,1]. This
parameter is common across all the crowd workers.
p1 Probability that an honest crowd worker (non-
spammer)labelsanunambiguousvalidanswerwith
ground truth as 1 correctly. This represents True Pos-
itive (TP) rate of a worker with p1∈[0,1]. This pa-
rameter is same across all the crowd workers.
a A factor which reduces the probability with which
a worker labels an ambiguous answer correctly a∈
[0,1]
numberofparameters.ThiswouldallowEMtoconvergewellwith
thesmallamountofdataavailable.Ourpriorbeliefofspammers
ϕismodeledusingaBeta-distributionhavingBetadensitiesthat
areincreasingly peakedtowards 0.3indicating mostof annotators
are honest. Our prior belief of task ambiguity γis modeled using a
Beta-distributionhavingBetadensitiesthatareincreasinglypeaked
towards 0.5 indicating 50% of the tasks are ambiguous. The joint
probability distribution can be factorized as:
P(L,Z,θ)=P(a|δ)P(p0|β)P(p1|β)N/productdisplay.1
i=1M/productdisplay.1
j=1P(tij|Γ)
P(zij|ζ)P/productdisplay.1
k=1P(αk|ϕ)/productdisplay.1
lijk∈LP(lijk|zij,θ)(1)
Giventheobservedvariables L,wewouldliketoinfer Z,asw ell
as latent parameters θ. This can be done using Bayesian treatment
of the Expectation-Maximization (EM) algorithm.
E-Step:Assumingthatwehavethecurrentestimate ˆθofthelatent
parameters, we compute the posterior on target values by using
853
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:10:52 UTC from IEEE Xplore.  Restrictions apply. Towards Automating Disambiguation of Regulations: Using the Wisdom of Crowds ASE ’18, September 3–7, 2018, Montpellier, France
equation 2.
ˆP(z)=N/productdisplay.1
i=1M/productdisplay.1
j=1ˆP(zij) (2)
ˆP(zij)=P(zij|ζ)/productdisplay.1
k∈AiP(lijk|zij,ˆθ) (3)
Equation 3can be rewritten for distinct values of zijas:
ˆP(zij=0)=0.5∗P(lijk=0|zij=0,ˆθ)∗
P(lijk=1|zij=0,ˆθ)(4)
ˆP(zij=1)=0.5∗P(lijk=0|zij=1,ˆθ)∗
P(lijk=1|zij=1,ˆθ)(5)
Our model is depicted by equations 6through9below.
P(lijk=1|zij=1;ˆθ)=ˆαk∗ˆtij
2+ˆαk∗(1−ˆtij)
2
+(1−ˆαk)∗ˆtij∗ˆp1∗a
+(1−ˆαk)∗(1−ˆtij)∗ˆp1 (6)
P(lijk=0|zij=0;ˆθ)=ˆαk∗ˆtij
2+ˆαk∗(1−ˆtij)
2
+(1−ˆαk)∗ˆtij∗ˆp0∗a
+(1−ˆαk)∗(1−ˆtij)∗ˆp0 (7)
P(lijk=0|zij=1;ˆθ)=ˆαk∗ˆtij
2+ˆαk∗(1−ˆtij)
2+
(1−ˆαk)∗ˆtij∗(1−ˆp1∗a)+
(1−ˆαk)∗(1−ˆtij)∗(1−ˆp1)(8)
P(lijk=1|zij=0;ˆθ)=ˆαk∗ˆtji
2+ˆαk∗(1−ˆtij)
2+
(1−ˆαk)∗ˆtij∗(1−ˆp0∗a)+
(1−ˆαk)∗(1−ˆtij)∗(1−ˆp0)(9)
M-StepToestimatethelatentparameters θ,wemaximizetheexpec-
tation of the logarithm of the posterior on θwith respect to ˆP(zij)
from the E-step. We can call auxiliary function being maximized
asQ(θ,ˆθ). In practice, we estimate parameters using alternating
maximizationalgorithms,whereweoptimizewithrespecttothe
parameters of a task or an annotator one at a time. The optimal α∗
can be found from equation 10.
α∗=argmaxαQ(α,ˆα) (10)
whereˆαis the estimation from the previous iteration and
Q(α,ˆα)=Ez[loдP(L|Z,α)+loдP(α|ϕ)]=P/summationdisplay.1
k=1Q(αk,ˆαk)(11)
whereEz[.]istheexpectationwithrespectto ˆPzandQ(αk,ˆαk)is
defined by equation 12.
Q(αk,ˆαk)=argmaxαkP(αk|ϕ)/productdisplay.1
i∈TkP(lijk|zij,θ)(12)
Hence, the optimization can be carried out separately for each
crowd worker, and relies only on the responses that the workerprovided.Theauxiliaryfunctionsforothersetoflatentparameters
can be defined by equations 13to16below:
Q(tij,ˆtij)=argmaxtijP(tij|Γ)/productdisplay.1
k∈AiP(lijk|zij,θ)(13)
Q(a,ˆa)=argmaxaP(a|δ)/productdisplay.1
lijk∈LP(lijk|zij,θ)(14)
Q(p1,ˆp1)=argmaxp1P(p1|β)/productdisplay.1
lijk∈LP(lijk|zij,θ)(15)
Q(p0,ˆp0)=argmaxp0P(p0|β)/productdisplay.1
lijk∈LP(lijk|zij,θ)(16)
TheoutcomeofEMismulti-fold:(i)Itestimatestheanswervalidity
based on the resultant target values zij(estimated parameters) for
each answer, which define if an answer provided to a given to aquestion is valid or invalid, (ii) It quantifies the ambiguity of an
answer to the posed question of a term in the regulatory statement
(latentparameter tij).Theaverageoftheambiguityvaluesforall
the answers of a task provide the ambiguity of the term marked,
(iii)Itidentifiesthespammersorreluctantworkersbymeasuring
theprobabilityofspammingforeachworker(latentparameter αk),
0 indicating no spammer, 1 indicating spammer, (iv) It identifies
the average skill level of all the crowd workers (latent parameters
p0andp1)intermsoftheirconfusionmatrixforambiguousaswell
as non-ambiguous tasks. (For ambiguous tasks the True Positive
rate isp1∗aand True Negative rate is p0∗a).
5 RESULTS AND DISCUSSION
We executed EM on all the 90 tasks (450 answers) together and
then individually for sets of 30 tasks (150 answers) belonging to
eachambiguitytype,viz,lexical,syntacticandsemantic.Thetar-
getvaluesestimatedasanoutcomeofEMarecomparedwiththe
groundtruth valuesprovided bythe experts.Theaccuracy results
are shown in the Table 4.
Table 4: Disambiguation Accuracy
Task Type Precision Recall F-score
Lexical 80% 91.8% 85.5%Syntactic 83% 93.9% 88.1%Semantic 84.4% 81.3% 83%
All 84.54% 89.86% 87.12%
It is evident that crowd of software engineers is good at dis-
ambiguating the lexical and syntactic type of ambiguities. How-
ever,acomparativelylowrecallvalueforsemanticambiguitytasks
indicates that this type is difficult to disambiguate. To measure
Table 5: Correlations - Task Ambiguity and Worker Spam
Correlation
Task Ambiguity Worker Spam
Lexical Ambiguity 0.815 0.564
Semantic Ambiguity 0.637 0.780Syntactic Ambiguity 0.691 0.912
All 0.756 0.634
854
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:10:52 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France M. Patwardhan et al.
Table 6: Ambiguity Intensity of Terms
Task Type Ambiguous
TasksUnambiguous
TasksAll
Lexical 0.279 0.124 0.191
Syntactic 0.189 0.13 0.154
Semantic 0.547 0.364 0.486
All 0.338 0.206 0.277
ambiguity of an answer, we measured the inter-annotator disagree-
mentintermsofweightedBernoullivarianceofthe15responses
receivedforeveryanswer.TheweightsoftheBernoullivariance
were decided by worker expertise (percentage of correct inputs
provided by a worker). We established a correlation of these values
with the ambiguity values tijestimated by the EM model, using
Pearson’s Correlation Coefficient. The high correlations illustrated
inTable5depictthecapabilityofEMtoautomaticallyquantifythe
intensity of ambiguity. We also computed the ‘spam’ of a crowd
workerbyfindingpercentageofincorrectinputsprovidedbythe
worker. We established a correlation of these values with the αk
values estimated by EM. The correlations are illustrated in Table 5.
It shows that the spam is easier to identify for syntactic ambiguity
types, whereas difficult for lexical ambiguity.
For each type of ambiguity, we had 15 tasks having ambiguous
terms and 15 having less ambiguous or unambiguous terms. Wecomputedtheambiguityofatermastheaverageofalltheambi-
guityintensitiesofeveryanswer( ti=1/M/summationtext.1M
j=1tij)totheposed
questionforthatterm.Table 6showstheaveragedambiguityin-
tensities for all the terms which constitute the ambiguous and less
ambiguous tasks. It can be seen that the average ambiguity in-tensity of ambiguous terms (0.338) is more than that of the less
ambiguousorunambiguousterms(0.206).AsshowninTable 6,the
intensity for syntactic ambiguity is the least (0.154) of the three.
This observation is consistent with the F-score for disambiguation
forsyntacticambiguity(88.1%),whichishighestofthethree(Table
4). The relation between ambiguity intensities and disambiguation
F-scores is also valid for the other two ambiguity types.
6 CONCLUSION AND FUTURE WORK
Wereportearlyindicationsonpossibilitiesfordisambiguatingregu-
lationsbyemployingacrowdofsoftwareengineers.Dataprovided
bylegalexpertswasusedforgeneratingcrowdsourcingtasks,so
that we can validate the consensus outcome of software engineers’
inputsagainstthoseofexperts’. Tounderstand iftheengineerscan
indeed provideoriginal disambiguation data (as opposed to just
identifycorrect answers from multiple choices), we conducted a
pilotwith5HIPAAregulationstatements.Givenaregulationstate-
ment, 15 crowd workers were to mark a term/phrase they perceive
tobeambiguous,poseaquestiononthatterm,andprovideaset
ofanswers resultingindisambiguation. Theyidentified 46unique
terms with (on an average) 2 questions posed on each term, and
(onanaverage)3answerstoeachquestion.Thecrowdresponses
containedbothvalidandinvalidanswers.Werealizethatthescope
andsizeofourearlyexperimentsistoolimitedtoallowforanygen-
eralization.However,wealsonotethatexperienced,professional
software engineers get to work closely with legal experts whiledevelopinglargecompliantsystemsandintheprocessarelikely
toimplicitlyacquireasignificantamountof knowledgeaboutthe
disambiguation of regulations. Can they retain and retrieve this
knowledgeforsubsequentuseinotherprojectsinthesamedomain?
Canweexplicateandharnesstheirknowledgethroughcrowdsourc-ingandreducetheeffortonpartofexperts?Thisinquirymotivates
our research.
The empirical observation about the difference in ambiguity in-
tensities of the three types needs to be investigated further by
designing experiments that employ psycho-linguisticanalyses. In
future, we intend to extend this work to other ambiguity types: ref-erential,incompletenessandvagueness.Wewillemploytechniques
which could help acquire annotations on a large scale, so that, ma-
chine/deep learning algorithms can be trained for an automated
disambiguation of regulations.
REFERENCES
[1]T.D.Breaux,M.W.Vail,andA.I.Anton.“Towardsregulatorycompliance:Extract-
ingrightsandobligationstoalignrequirementswithregulations."InRequirements
Engineering, 14th IEEE International Conference, pp. 49-58. IEEE, 2006.
[2]S. Hoefler and A. Bunzli, “Controlling the language of statutes and regulations for
semanticprocessing",InProceedingsoftheLREC2010WorkshoponSemantic
Processing of Legal Texts (SPLeT 2010), Valletta, Malta, Pages pp. 8–15, 2010.
[3]M. Ceci, F. A. Khalil, andL. O’Brien. “Making Senseof Regulations with SBVR." In
RuleML (Supplement). 2016.
[4]S.Ghaisas,A.Sainani,P.R.Anish,“ResolvingAmbiguitiesinRegulations-Towards
AchievingtheKohlbergianStageofPrincipledMorality",InProceedingsofthe40th
International Conference on Software Engineering (ICSE ‘18). (Under publication)
[5]H.Yang,A.Willis,andB.Nuseibeh,“Automaticdetectionofnocuouscoordination
ambiguities innatural languagerequirements",In Proc.IEEE/ACM Intl Conf.on
Automated Software Engineering 53-62 (ACM, 2010) , Pages 26–32, 2010
[6]A.Umber,I.S.Bajwa,“Minimizingambiguityinnaturallanguagesoftwarerequire-
ments specification", In Digital Information Management (ICDIM), IEEE Sixth
International Conference, Pages 102–10, 2011
[7]J. R. Reidenberg, J. Bhatia, T. D. Breaux, and T. B. Norton, “Ambiguity in privacy
policies and the impact of regulation", The Journal of Legal Studies, 45(S2),
S163-S190, 2016.
[8]A. K. Massey, R. L. Rutledge, A. I. Antón, and P. P. Swire, “Identifying and clas-sifying ambiguity for regulatory requirements". In Requirements Engineering
Conference (RE), 2014 IEEE 22nd International, pp. 83-92. IEEE, 2014
[9]A. K. Massey, R. L. Rutledge, A. I. Antón, J. D. Hemmings, and P. P. Swire, “A
strategy for addressing ambiguity in regulatory requirements." Georgia Institute
of Technology, 2015.
[10]C. M.Adriano and A. VanDer Hoek, “Exploring MicrotaskCrowdsourcing as a
Means of Fault Localization", arXiv preprint arXiv:1612.03015, 2016
[11]E.R.Weidema,C.López,andS.Nayebaziz,F.Spanghero,andA.vanderHoek,“To-
wardmicrotaskcr owdsourcingsoftware designwork",Crow dSourcinginSoftware
Engineering(CSI-SE),2016IEEE/ACM3rdInternationalWorkshopon, Pages
41–44, 2016
[12]M. Zhao, and A. van der Hoek, “A brief perspective on microtask crowdsourcing
workflowsforinterfacedesign",ProceedingsoftheSecondInternationalWorkshop
on CrowdSourcing in Software Engineering, Pages 45–46, 2015
[13]T. D. LaToza, and A. van der Hoek, “Crowdsourcing in software engineering:
Models, motivations, and challenges", IEEE software Journal, 33(1) Pages 74–80,
2016
[14]T.Tian,J.Zhu,“Max-marginmajorityvotingforlearningfromcrowds",Advances
in Neural Information Processing Systems (NIPS), 2015.
[15]P. Welinder and P. Perona, “Online crowdsourcing: rating annotators and obtain-
ingcost-effectivelabels",ComputerVisionandPatternRecognitionWorkshops
(CVPRW), 2010 IEEE Computer Society , Pages 26–32, 2010
[16]A.KurveA,D.J.Miller,G.Kesidis,“MulticategoryCrowdsourcingAccountingfor
Plurality in Worker Skill and Intention, Task Difficulty, and Task Heterogeneity",
arXiv:1307.7332. 2013 Jul 28.
[17]S.Branson,G.VanHorn,P.Perona,“Leancrowdsourcing:Combininghumans
and machines in an online system", In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, Pages 7474-7483, 2017.
[18]HealthInsurancePortabilityandAccountabilityAct,USCH.R.3103-168,April
2000
[19]L. Aroyo and C. Welty. The three sides of CrowdTruth. Journal of Human Com-
putation, 1:31-34, 2014.
855
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 14:10:52 UTC from IEEE Xplore.  Restrictions apply. 