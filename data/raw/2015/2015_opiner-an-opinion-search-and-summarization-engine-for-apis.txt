Opiner: An Opinion Search and Summarization
Engine for APIs
Gias Uddin
School of Computer Science
McGill University, Montr ¬¥eal, QC, Canada
gias@cs.mcgill.caFoutse Khomh
SWAT Lab
Polytechnique Montr ¬¥eal, QC, Canada
foutse.khomh@polymtl.ca
Abstract ‚ÄîOpinions are key determinants to many of the
activities related to software development. The perceptions of
developers about an API, and the choices they make about
whether andhow they should use it, may, to a considerable degree,
be conditioned upon how other developers seeandevaluate the
API. Given the plethora of APIs available for a given development
task and the advent of developer forums as the media to share
opinions about those APIs, it can be challenging for a developer
to make informed decisions about an API to support the task.
We introduce Opiner, our opinion search and summarization
engine for API reviews. The server side of Opiner collects and
summarizes opinions about APIs by crawling online developer
forums and by associating the opinions found in the forum posts
to the APIs discussed in the posts. The client side of Opiner is
a Website that presents different summarized viewpoints of the
opinions about the APIs in an online search engine. We evaluated
Opiner by asking Industrial developers to select APIs for two
development tasks. We found that developers were interested
to use our proposed summaries of API reviews and that while
combined with Stack OverÔ¨Çow, Opiner helped developers to make
the right decision with more accuracy and conÔ¨Ådence. The Opiner
online search engine is available at: http://opiner.polymtl.ca. A
video demo is available at: https://youtu.be/XAXpfmg5Lqs.
Index Terms‚ÄîOpinion mining, API informal documentation,
opinion summaries, study, summary quality.
I. I NTRODUCTION
APIs (Application Programming Interfaces) offer interfaces
to reusable software components and are an integral part of
the modern day rapid software development. The online devel-
opment portal GitHub now hosts more than 38 million public
repositories, which is a radical increase from the 2.2 million
active repositories hosted in GitHub in 2014. The plethora
of APIs available for virtually any given development task
offers tremendous beneÔ¨Åt to the developers to support their
development task, but such richness also offers an interesting
problem to the developers - how to select the right API?
While developer forums serve as communication channels
for discussing the implementation of the API features, they
also enable the exchange of opinions or sentiments expressed
on numerous APIs, their features and aspects. In fact, we
observed that more than 66% of Stack OverÔ¨Çow posts that
are tagged ‚ÄúJava‚Äù and ‚ÄúJson‚Äù contain at least one positive
or negative sentiment. Most of these (i.e., 46%) posts also
do not contain any code examples. The number of numerous
APIs available and the sheer volume of opinions about any
A1
C1
A2
A3
A4
C2
C3
Fig. 1. Example of a Stack OverÔ¨Çow discussion about two APIs.
given API scattered across many different posts though pose a
signiÔ¨Åcant challenge to produce quick and digestible insights.
Figure 1 presents the screenshot of seven Stack OverÔ¨Çow
posts (four answers, three comments). The oldest post (at the
top) is dated November 06, 2009 and the most recent one
(at the bottom) is February 10, 2016. These posts express
developers‚Äô opinions about two Java APIs (Jackson [1] and
Gson [2]) offering JSON parsing features for Java. None
of the posts contain any code snippets. The Ô¨Årst answer
(A1) representing a positive opinion about the Gson API
motivates the developer ‚Äòbinaryrespawn‚Äô to use it (C1). In the
next answer (A2), the user ‚ÄòStaxMan‚Äô compares Gson with
Jackson, favouring Jackson for offering better support, and
978-1-5386-2684-9/17/$31.00 c2017 IEEEASE 2017, Urbana-Champaign, IL, USA
Tool Demonstrations978
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. Fig. 2. Screenshots of Opiner API review search engine
based on this feedback, ‚Äòmickthomson‚Äô (A3) decides to use
Jackson instead of Gson. Most of the posts (A2‚ÄìA4) imply a
positive sentiment towards Jackson but a negative one about
Gson. Later, the developer ‚ÄòDaniel Winterstein‚Äô develops a
new version of Gson Ô¨Åxing existing issues and shares his
API (C3). This example illustrates how developers share their
experiences and insights, as well as how they inÔ¨Çuence and
are inÔ¨Çuenced by the opinions. A developer looking for only
code examples for Gson would have missed the important
insights about the API‚Äôs limitations, which may have affected
her development activities. Thus, opinions extracted from the
informal discussions can drive developers‚Äô decision making.
We developed Opiner, an online API review search and
summarization engine. Given as input all the opinionated
sentences about an API, Opiner produces summaries of the
reviews. In Figure 2, we present a screenshot of Opiner. Opiner
is developed as a search engine, where developers can search
opinions for an API 1 . Upon clicking on API, developers can
see all the reviews collected about the API both in summarized
and original formats 2 . A developer can also search for an
API aspect (e.g., performance) 3 in Opiner, to Ô¨Ånd the most
popular APIs based on the aspect 4 .
We conducted a study where we provided access to our
tool to professional software engineers to help them in their
selection of an API for two development tasks. The developers
attempted to select an API Ô¨Årst by using Stack OverÔ¨Çow
only and then by using both Opiner and Stack OverÔ¨Çow. We
observed that developers correctly picked the right API with
20-66% accuracy while just using Stack OverÔ¨Çow. However,
they had 100% accuracy while they used Opiner and Stack
OverÔ¨Çow together. A video demo of Opiner is availableat: https://youtu.be/XAXpfmg5Lqs. The Opiner online search
engine is available at: http://opiner.polymtl.ca
II. C HALLENGES IN API R EVIEW ANALYSIS
We addressed three major technical challenges during the
mining and summarization of opinions about APIs from de-
veloper forums:
API Mention Detection: The collection of opinions about
APIs requires the detection of API mentions in the forum
posts. The detection is challenging due to two major ambi-
guities in how APIs are mentioned in the textual contents of
the forum posts: 1) An API name can be false. For example,
Jackson as an API name vs a person name. 2) An API
mention can be associated with more than one API name.
For example, in the online Java API hosting portal, Maven
Central, a search for Jackson returns 258 APIs containing
the name ‚Äòjackson‚Äô.
API Opinion Association: The association of opinions
to an API is challenging when more than one API were
mentioned around an opinion.
API Opinion Summarization: Opinions are summarized in
other domains mainly around aspects. The summarization of
opinions is challenging due to the implicit nature of aspects
discussed in the opinions. For example, the opinion ‚ÄòGSON
is fast‚Äô is about the ‚ÄòPerformance‚Äô aspect of the API GSON.
We brieÔ¨Çy discuss the techniques we developed to addressed
the above challenges and provide reference to the technical
report explaining the detailed techniques and their evaluation.
A. API Mention Detection
An API mention in a post is a reference to an API. A
mention can be one of the following types:
Name: A name as a token (e.g., ‚ÄúJackson‚Äù) or a series of
tokens (e.g., ‚ÄúJackson JSON parser‚Äù).
Link: A link to an API resource (e.g., homepage).
Code: Code (or code like) term/snippet using packages
and code elements from the API.
In Opiner, we focused on the resolution of mentions refer-
enced by names and links. There are two mention detectors:
(1) named-entity (for Natural language texts), and (2) linked-
entity detector (for hyperlinks). For each detected mention, the
output is a Mention-Candidate List (MCL). In an MCL, there
is one mention, but there can be more than one candidate.
Each candidate is an API in our API database. Our API
database consisted of all the Java APIs listed in online software
portals, Maven Central and Ohloh. In Figure 3, we show a
partial mention candidate list for the mention ‚ÄòJackson‚Äô shown
in Figure 1. In Figure 3, each ellipsis contains a distinct
candidate name. The top part of an ellipsis contains the API
name, while the bottom part contains the module name (if
the module name is matched). For each mention in a forum
post, the resolver takes as input the MCL of the mention
and associates the mention to an API in the candidate list
if mention is true API or label is ‚ÄòFALSE‚Äô, if the mention was
not referring to an API. The resolution engine correlates the
information found about an API in the database against those
979
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. Jacksontw.tyl.common
Jackson
org.milyn.thirdparty
Jackson
Jacksoncom.cedarsoft.seialization
Jackson
org.jvnet.hudson.jacksoncom.hubspot.jackson
jackson‚àíjaxrs
camel‚àíjacksonorg.apache.cameljackson‚àícorecom.fasterxml.jackson.core
jackson‚àídatatype‚àíjodacom.fasterxml.jackson.datatypeFig. 3. A partial mention candidate list (MCL) for ‚ÄúJackson‚Äù.
found in the textual and code examples found in the forum
post where the API mention was found. The correlation is
analyzed using heuristics, such as, similarity in the API name
with the mention, similarity in the discussion of API features
in the forum post against the description of the API in our API
database. A detailed explanation of the technique is described
in [3] and [4]. We observed a precision of more than 90%
for [3] and are currently evaluating [4]. The Opiner current
website is deployed using [3].
B. Opinion Mining
We collected the opinionated sentences about APIs using
our technique described in [3]. The technique takes cues from
discourse resolution by attempting to associate an opinion
to its nearest API mention. A nearest API is determined
based on the presence of APIs in the same sentence, post
or conversation. A conversation was deÔ¨Åned as having all
the replies to a given post. A reply to post is an immediate
comment to an answer or a response to a comment in a Stack
OverÔ¨Çow thread. We observed a precision of more than 90%
for the association based on the same sentence heuristics and
above 80% for the other heuristics.
C. Opinion Summarization
In a previous study [3], we surveyed software developers
and found that developers prefer to see opinions about the
following API aspects in the forum posts: (1) Performance:
How well does the API perform? (2) Usability: How usable is
the API? (3) Security: How secure is the API? (4) Documen-
tation: How good is the documentation? (5) Compatibility:
Does the usage depends on other API? (6) Portability: Can
the API be used in different platforms? (7) Community: How
is the support around the community? (8) Legal: What are
licensing requirements? (9) Bug: Is the API buggy? (10) Only
Sentiment: Opinions without specifying any aspect. (11) Oth-
ers: Opinions about other aspects. We developed a supervised
classiÔ¨Åer to detect each aspect. To train and test the classiÔ¨Åers,
we produced a benchmark of more than 4000 sentences as
Stack OverÔ¨Çow, each labeled as one or more aspect. For the
opinions labeled as ‚ÄòOthers‚Äô, we further categorized those
using techniques adapted Hu and Liu [5]. The discussion
and evaluation of the opinion summarization techniques are
described in our technical papers [3], [6].
III. S YSTEM ARCHITECTURE
The Opiner architecture supports the efÔ¨Åcient implementa-
tion of the algorithms described in Section II, and a web-based
Fig. 4. The client-server architecture of Opiner
Preprocessor
Opinion DetectorAPI Detector
Resolution TableAPI Mention
Opinionated
Sentences
API Opinion Summarizer API Opinion AssociatorDeveloper
ForumsLoaderAPI Portals
PostsPostsAPIs
API Mentions
OpinionsAPIs
Posts
Fig. 5. The architecture of the Opiner Application Engine
search engine with visual representation of the insights ob-
tained from the collection and summarization of API reviews.
There are four major components in Opiner (see Figure 4):
Application Engine: Handles the loading and processing of
the data from forum posts and API portals and hosts all the
algorithms and techniques used to collect and summarize
opinions about APIs (Section III-A).
Database: A hybrid data storage component with support
for data manipulation in diverse formats, such as, relational,
graph, tree, etc. (Section III-B).
REST Web Server: The middleware between the Applica-
tion Engine and the Website (Section III-C).
Website: The web-based user interface of Opiner that
hosts the search, summarization and recommendation results
based on API reviews (Section III-D).
A. Opiner Application Engine
The application engine has six major modules (Figure 5):
1)Loader: crawls the developer forums and API portals.
2)Preprocessor: processes the data into different formats to
be consumed for subsequent analyses.
3)API Mention Resolver: detects API mentions (name and
url) in the textual contents of forum posts.
4)Opinion Detector: detects positive and negative opinion-
ated sentences in the forum posts.
5)Opinion to API Associator: associates opinions to the API
about which opinion was provided in the forum post.
6)API Opinion Summarizer: summarizes opinions about an
API in different formats.
980
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. Loader: There are two types of crawlers: Forum and
Portal. For each forum and portal to crawl, the component
contains a parser. We have two separate databases: one for
the database (and the portals) and another for the forums.
For example, we have one parser for Reddit and another for
StackOverÔ¨Çow. In this paper, we used an ofÔ¨Çine version of the
StackOverÔ¨Çow dump (January 2014) to ensure reproducibility
of our technique and evaluation. It can happen that a post
we may have chosen in our experiment can be deleted in the
online forum, but we can still have it the ofÔ¨Çine dump. For
example, the StackOverÔ¨Çow thread 338586 was deleted during
the middle of 2014, but it was included in the January dump.
We have one crawler for the API portal, Maven central and
another for Ohloh. In addition, we have a javadoc crawler to
collect information about the ofÔ¨Åcial Java packages.
Preprocessor: We preprocess the forum contents and the
API descriptions in our API database as follows: 1) We
identify the stopwords in the forum contents and in the
description of APIs in the database. We used three types of
stopwords: (1) Regular : The default stopwords in English (e.g.,
a, the, etc.) (2) Country: The country and institutional codes
(e.g., com, edu, ca, eu, etc.), and (3) Domain: API-speciÔ¨Åc
(e.g., API, library, etc.) 2) We categorize the post content into
four types: a) code terms; b) code snippets; c) hyperlinks1; and
d)natural language text representing the rest of the content.
3) We tokenize the text and tag each token with its part of
speech.2
API Mention Resolver: The API mention resolver compo-
nent consists of three major modules (Figure 6): API database
creator, Mention Detector and Mention Resolver.
The API database creator has two modules: spurious API
detector, API schema generator. (a)Spurious API detector:
We discarded three types of APIs: (i) Demo or example
software (e.g., projects with name ‚Äòdemo‚Äô or ‚Äòexample‚Äô in
their names), and (ii) APIs that do not have links to their
online source code repository, and (iii) APIs that do not have
their source code archived (e.g., in a jar Ô¨Åle). (b)Schema
generator: We store each API entry by collecting all the
information as required by the schema template of the API
database. Ideally, all such information should be available from
a portal. However, information can be missing. For example,
many APIs in Maven do not have any overview description.
We crawl the resource pages (e.g., homepage) of those APIs
to store their overview description.
The API mention detector in Opiner supports both exact and
fuzzy matching of API names and urls from the API database
in the textual contents of the forum posts. Fuzzy matching
was necessary, because of 1) possible typos in the mention in
forum posts, 2) usage of shortened or longer names in forum
posts with regards to an API To support the name matching,
we produced a trierepresentation of our entire API database,
which was both time and space efÔ¨Åcient.
1We detect hyperlinks using regular expressions.
2We used the Stanford POS tagger [7].
API 
infoAPI Database
CreatorCrawler
Forums Portals
Preprocessor
Forums Portals
X
Relation Mention‚àíAPI ResolvedM2 C4M1 C2M3
Jackson com.fasterxml.jackson
GSON com.google.code.gsonP1
P2PostID Mention Resolved CandidateMention Resolution TableText‚àíbasedAPI Mention Detector
Link‚àíbased
ResolverC1
M1
API schemasforum threads
C2
C3 M2
C4
M3 C5
Mention‚àíCandidate 
ListFig. 6. The architecture of the API mention resolver
The Mention Candidate Lists used in our API mention
resolution were developed as an in-memory graph structure
to explore the relationships among the candidates, e.g., their
dependencies on each other.
Opinion Mining. Given as input a thread from Stack
OverÔ¨Çow, we mined opinions about APIs mentioned in the
thread as follows: 1) We detected individual sentences in the
thread 2) We arranged the sentences in the same sequence they
were provided in the thread. For example, the oldest post was
placed at the top, and its Ô¨Årst sentence as the topmost. 3) We
labeled each sentence as either positive, negative, neutral.
To detect sentiments in a sentence, we used a rule-based
algorithm based on a combination of Sentistrength [8] and the
Sentiment Orientation (SO) algorithm [9]. 4) We associated
each opinionated sentence to the API about which the opinion
was provided using the technique described in Section II.
Opinion Summarization. Given as input all the opinionated
sentences of an API, we investigated opinion summarization
algorithms from the following major categories [10], [11]:
1)Aspect-based: positive and negative opinions are grouped
around aspects related to the entity (e.g., picture quality).
Aspects can be pre-deÔ¨Åned or dynamically inferred using
algorithms such as topic modeling.
2)Contrastive: Contrastive viewpoints are grouped.
3)Extractive: A subset of the opinions are extracted.
4)Abstractive: An abstraction of the opinions is produced.
5)Statistical: Overall polarity is transformed into numerical
rating (e.g., star ratings).
We produced aspect-based and statistical summaries of API
reviews using our techniques as described in Section II and [6].
We leveraged off-the-shelf algorithms to produce extractive,
abstractive, and topic-based summaries and implemented the
algorithm [12] to produce contrastive summaries.
B. Opiner Database
We used a hybrid data storage architecture. The bulk of the
data is stored in a Postgresql relational database. The nature of
the relational data structure is not efÔ¨Åcient for the analysis of
the textual data. Such unstructured and intermediate analyses
are carried on using disk-based IO. The supervised classiÔ¨Åers
are stored in binary serialized format.
C. Opiner REST Web Server
The Opiner REST web server offers interfaces to ingest the
results of the Opiner Application Engine. The Opiner website
leverages the REST web server to produce the user interface
981
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. Fig. 7. Statistical summarization of opinions for API Jackson.
Fig. 8. Screenshot of the aspect-based summarizer
.
of Opiner. This decoupling allows the development of any user
interface without preventing the development of the Applica-
tion Engine. The end points are divided into three categories:
1) Search 2) Summarizations, and 3) Recommendations.
D. Opiner Website
The Opiner website is built based on AJAX principles. Thus,
the search capabilities are auto-complete. In Figures 7 and 8,
we show the statistical and aspect-based summaries produced
by Opiner for the API ‚ÄòJackson‚Äô based on the processing of all
the Stack OverÔ¨Çow posts tagged as ‚Äòjava+json‚Äô, respectively.TABLE I
PROGRESSION OF LEARNING FROM STACK OVERFLOW TO OPINER
T Tool Correctness Conversion ConÔ¨Ådence Time
1 SO 20.0% ‚Äì 4.3 12.3
SO + Opiner 100% 100% 4.5 7.5
2 SO 66.7% ‚Äì 2.7 18.6
SO + Opiner 100% 100% 4.6 6.8
IV. E VALUATION
Because the purpose of developing Opiner was to add
beneÔ¨Åts over Stack OverÔ¨Çow, we investigated the usefulness
of Opiner by conducting a study of professional software
developers who completed two tasks using Stack OverÔ¨Çow and
Opiner. We detected API mentions using the technique [3] in
Opiner for this evaluation.
The two tasks in total involved four different APIs, with
two APIs for each task. Each task was described using a
development scenario. For each task there was only one
correct API (decided based on cues from discussions in Stack
OverÔ¨Çow). The participants were asked to select the correct
API for each task. Each task was executed in two settings:
1)SO only: Decide only using Stack OverÔ¨Çow
2)SO + Opiner: Decide using Stack OverÔ¨Çow + Opiner
For a task in a setting, each developer provided the following
answers upon task completion: (1) Selection: Their choice of
API (2) ConÔ¨Ådence: How conÔ¨Ådent they were while making
the selection. We used a Ô¨Åve-point scale: Fully conÔ¨Ådent (value
5) - Fully unsure (1). (3) Rationale: The reason of their
selection. In addition, we logged the time it took for each
developer to complete a task under each setting.
We invited nine professional developers from a software
company and two developers from Freelancer.com to partic-
ipate in the study. The experience of the developers ranged
between 1 year and 34 years. The developers carried on
different roles ranging from software developer to architect
to team lead. We analyzed the responses along three di-
mensions:(1) Correctness: How precise the participants were
while making a selection in the two settings. (2) ConÔ¨Ådence:
How conÔ¨Ådent they were making the selection? (3) Time: How
much time did the developers spend per task? In addition, we
computed a ‚Äòconversion rate‚Äô as the ratio of developers who
made a wrong selection using Stack OverÔ¨Çow but made the
right selection while using both Stack OverÔ¨Çow and Opiner.
Nine developers completed task 1 using the two different
settings (10 using Stack OverÔ¨Çow). Five developers completed
task 2 using both of the settings (out of the nine using Stack
OverÔ¨Çow, four could not complete the task). In Table I, we
present the impact of Opiner while completing the tasks.
To compute the Conversion rate, we only considered the
developers that completed a task in both settings. For task
1, only 20% of the developers in SO setting selected the right
API, but all of them picked the right API in SO+Opiner setting
(i.e., 100% conversion rate). For task 2, only 66.7% of the
developers in SO setting selected the right API, but all of
them picked the right API when they used both Opiner and
Stack OverÔ¨Çow (conversion rate = 100%). The developers also
982
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. reported higher conÔ¨Ådence levels when making the selection
using Opiner with Stack OverÔ¨Çow. For task 1, the conÔ¨Ådence
increased from 4.3 to 4.5 and for Task 2, it increased from 2.6
(Partially unsure) to 4.6 (almost fully conÔ¨Ådent).
V. R ELATED WORK
To the best of our knowledge, Opiner is the Ô¨Årst tool
developed to automatically mine and summarize opinions
about APIs from developer forums. However, online developer
forums have been studied extensively, e.g., to Ô¨Ånd dominant
discussion topics [13], to analyze the quality of posts [14],
developer proÔ¨Åles (e.g., personality traits of the most and low
reputed users) [15], [16], or the inÔ¨Çuence of badges [17]. Tools
utilized the knowledge from the forums, e.g., autocomment
assistance [18], collaborative problem solving [19], and tag
prediction [20]. Natural language summaries are produced for
software documentation [21] and source code [22]. Storey
et al. [23] analyzed tags and annotations in source code.
The summarization of source code has been investigated by
combining structural with lexical information of the source
code [24], by correlating code contents with the call graphs
in Java classes [22], by analyzing the identiÔ¨Åer and variable
names in methods [25], and by automatically documenting
source code [26]. The selection and presentation of source
code summaries were investigated through developer inter-
views [27] and eye tracking experiment [28]. Our Ô¨Åndings
conÔ¨Årm that developers also require different types of sum-
maries of API reviews posted in developer forums.
VI. S UMMARY
Given the plethora of opinions available for an API in
various online developer forums, it can be challenging for a
developer to make informed decisions about the API. We de-
veloped, Opiner, an online opinion search and summarization
engine that presents summaries of opinions. We found that
developers were interested to use our proposed summaries of
API reviews and that while combined with Stack OverÔ¨Çow,
Opiner helped developers to make the right decision with more
accuracy and conÔ¨Ådence. Our future work on Opiner will focus
on the following extensions: 1) A uniÔ¨Åed framework to support
the loading of opinions from disparate sources of developer
forums, and 2) A reÔ¨Åned recommendation engine to provide
insights on APIs with features from different languages.
REFERENCES
[1] FasterXML, Jackson, https://github.com/FasterXML/jackson, 2016.
[2] Google, Gson, https://github.com/google/gson, 2016.
[3] G. Uddin and F. Khomh, ‚ÄúMining aspects in API reviews,‚Äù Polytech-
nique Montr ¬¥eal, Tech. Rep., May 2017.
[4] G. Uddin and M. P. Robillard, ‚ÄúResolving API mentions in informal
documents,‚Äù McGill University, Tech. Rep., Sept 2017.
[5] M. Hu and B. Liu, ‚ÄúMining and summarizing customer reviews,‚Äù in
Proceedings of the tenth ACM SIGKDD international conference on
Knowledge discovery and data mining, 2004, pp. 168‚Äì177.
[6] G. Uddin and F. Khomh, ‚ÄúAutomatic summarization of API reviews,‚Äù
inIn Proceedings of the of 32nd IEEE/ACM International Conference
on Automated Software Engineering, 2017, p. 12.[7] K. Toutanova, D. Klein, C. D. Manning, and Y . Singer, ‚ÄúFeature-rich
part-of-speech tagging with a cyclic dependency network,‚Äù in North
American Chapter of the Association for Computational Linguistics on
Human Language Technology - Volume 1, 2013, pp. 173‚Äì180.
[8] M. Thelwall, K. Buckley, G. Paltoglou, D. Cai, and A. Kappas, ‚ÄúSen-
timent in short strength detection informal text,‚Äù American Society for
Information Science and Technology, vol. 61, no. 12, pp. 2544‚Äì2558,
2010.
[9] M. Hu and B. Liu, ‚ÄúMining and summarizing customer reviews,‚Äù in ACM
SIGKDD Knowledge Discovery and Data Mining, 2004, pp. 168‚Äì177.
[10] H. D. Kim, K. Ganesan, P. Sondhi, and C. Zhai, ‚ÄúComprehensive review
of opinion summarization,‚Äù University of Illinois at Urbana-Champaign,
Tech. Rep., 2011.
[11] B. Liu, Sentiment Analysis and Subjectivity, 2nd ed. Boca Raton, FL:
CRC Press, Taylor and Francis Group, 2010.
[12] H. D. Kim and C. Zhai, ‚ÄúGenerating comparative summaries of contra-
dictory opinions in text,‚Äù in Proceedings of the 18th ACM conference
on Information and knowledge management, 2009, pp. 385‚Äì394.
[13] A. Barua, S. W. Thomas, and A. E. Hassan, ‚ÄúWhat are developers talking
about? an analysis of topics and trends in stack overÔ¨Çow,‚Äù Empirical
Software Engineering, pp. 1‚Äì31, 2012.
[14] B. Vasilescu, A. Serebrenik, P. Devanbu, and V . Filkov, ‚ÄúHow social
Q&A sites are changing knowledge sharing in open source software
communities,‚Äù in Proceedings of the 17th ACM conference on Computer
supported cooperative work & social computing, 2014, pp. 342‚Äì354.
[15] B. Bazelli, A. Hindle, and E. Stroulia, ‚ÄúOn the personality traits of
stackoverÔ¨Çow users,‚Äù in In Proceedings of the 29th IEEE International
Conference on Software Maintenance (ICSM), 2013, pp. 460‚Äì463.
[16] A. L. Ginsca and A. Popescu, ‚ÄúUser proÔ¨Åling for answer quality
assessment in Q&A communities,‚Äù in Data-driven user behavioral
modelling and mining from social media, 2013, pp. 25‚Äì28.
[17] A. Anderson, D. Huttenlocher, J. Kleinberg, and J. Leskovec, ‚ÄúSteering
user behavior with badges,‚Äù in Proceedings of the 22nd International
Conference on World Wide Web, 2013, pp. 95‚Äì106.
[18] E. Wong, J. Yang, and L. Tan, ‚ÄúAutocomment: Mining question and
answer sites for automatic comment generation,‚Äù in Automated Software
Engineering, 2013, pp. 562‚Äì567.
[19] Y . Tausczik, A. Kittur, and R. Kraut, ‚ÄúCollaborative problem solving:
A study of math overÔ¨Çow,‚Äù in Computer Supported Cooperative Work
and Social Computing, 2014, pp. 355‚Äì367.
[20] C. Stanley and M. D. Byrne, ‚ÄúPredicting tags for stackoverÔ¨Çow posts,‚Äù
inIn Proceedings of the 12th International Conference on Cognitive
Modelling, 2013, pp. 414‚Äì419.
[21] S. Rastkar, G. C. Murphy, and G. Murray, ‚ÄúAutomatic summarization
of bug reports,‚Äù IEEE Trans. Software Eng, vol. 40, no. 4, pp. 366‚Äì380,
2014.
[22] L. Moreno, J. Aponte, G. Sridhara, M. A., L. Pollock, and K. Vijay-
Shanker, ‚ÄúAutomatic generation of natural language summaries for java
classes,‚Äù in Proceedings of the 21st IEEE International Conference on
Program Comprehension (ICPC‚Äô13), 2013, pp. 23‚Äì32.
[23] M.-A. D. Storey, L.-T. Cheng, R. I. Bull, and P. C. Rigby, ‚ÄúShared
waypoints and social tagging to support collaboration in software
development,‚Äù in CSCW, pp. 195‚Äì198.
[24] A. M. S. Haiduc, J. Aponte, ‚ÄúSupporting program comprehension with
source code summarization,‚Äù in Proceedings of the 32nd International
Conference on Software Engineering, 2010, pp. 223‚Äì226.
[25] G. Sridhara, E. Hill, D. Muppaneni, L. Pollock, and K. Vijay-Shanker,
‚ÄúTowards automatically generating summary comments for Java meth-
ods,‚Äù in Proc. 25th IEEE/ACM international conference on Automated
software engineering, 2010, pp. 43‚Äì52.
[26] P. W. McBurney and C. McMillan, ‚ÄúAutomatic documentation genera-
tion via source code summarization of method context,‚Äù in Proceedings
of the 21st IEEE International Conference on Program Comprehension,
2014, pp. 279‚Äì290.
[27] A. T. T. Ying and M. P. Robillard, ‚ÄúSelection and presentation practices
for code example summarization,‚Äù in Symposium on Foundations of
Software Engineering, 2014, pp. 460‚Äì471.
[28] P. Rodeghero, C. McMillan, C. McMillan, N. Bosch, and S. D‚ÄôMello,
‚ÄúImproving automated source code summarization via an eye-tracking
study of programmers,‚Äù in Proc. 36th International Conference on
Software Engineering, 2014, pp. 390‚Äì401.
983
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 15:31:34 UTC from IEEE Xplore.  Restrictions apply. 