 
TeesRep: Teesside University's Research Repository http://tees.openrepository.com/tees/  
  
 
 
 
 
 
 
This full version, available on TeesRep, is the authors’ post -print version. 
For full details see: http://tees.openrepository.com/tees/handle/10149/594424   
 
 TLV: Abstraction through Testing, Learning and Validation
J
un Sun1, Hao Xiao2, Y ang Liu2, Shang-Wei Lin1, and Shengchao Qin3
1ISTD Pillar, Singapore University of Technology and Design, Singapore
2School of Computer Engineering, Nanyang Technological University, Singapore
3School of Computing, Teesside University, United Kingdom
ABSTRACT
A (Java) class provides a service to its clients (i.e., programs which
use the class). The service must satisfy certain speciﬁcations. Dif-
ferent speciﬁcations might be expected at different levels of abstrac-
tion depending on the client’s objective. In order to effectively
contrast the class against its speciﬁcations, whether manually or
automatically, one essential step is to automatically construct an
abstraction of the given class at a proper level of abstraction. The
abstraction should be correct (i.e., over-approximating) and accu-
rate (i.e., with few spurious traces).
We present an automatic approach, which combines testing,
learning, and validation, to constructing an abstraction. Our ap-
proach is designed such that a large part of the abstraction is gen-
erated based on testing and learning so as to minimize the use of
heavy-weight techniques like symbolic execution. The abstraction
is generated through a process of abstraction/reﬁnement, with no
user input, and converges to a speciﬁc level of abstraction depend-
ing on the usage context. The generated abstraction is guaranteed
to be correct and accurate. We have implemented the proposed ap-
proach in a toolkit named TLV and evaluated TLV with a number
of benchmark programs as well as three real-world ones. The re-
sults show that TLV generates abstraction for program analysis and
veriﬁcation more efﬁciently.
1. INTRODUCTION
Abstraction is perhaps the single most powerful weapon for com-
bating the complexity in program analysis and veriﬁcation. A good
abstraction of a program should be at a proper level of abstrac-
tion, which is decided by the usage context. It should have a much
smaller state space so that it is subject to efﬁcient search-based anal-
ysis like model checking [15]. It should be an over-approximation
of all behaviors of the program so that we could conclude that the
given program satisﬁes a (safety) property if the abstraction does.
It should be sufﬁciently accurate so that analysis based on the ab-
straction would result in few false alarms. The challenge is: how
do we automatically construct such an abstraction?
In this work, we propose an automatic approach called TLV
which combines testing, learning, and validation to generating an
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.abstraction of a given Java class. The abstraction characterizes
behaviors of any object of the class. In a way, TLV is designed
to mimic programmers so as to combat the complexity of pro-
gram analysis and veriﬁcation. When experienced programmers
are asked to analyze a given program, they often execute the pro-
gram with various inputs, from which (among other artifacts like
documentations, program comments, and domain knowledge) they
would form some initial idea on what the program does (and how)
and then validate their guess with more test cases or through code
review. They may guess a number of times until they build a correct
abstraction (in the mind) on what the program does. Depending on
their objective, they would stop the process once the abstraction
allows them to accomplish their analysis goal.
The workﬂow of TLV is inspired by the above process, as shown
in Figure 1. The inputs are the source code of a program and op-
tionally an artifact which TLV could use to determine the proper
level of abstraction. TLV has three phases: learning, validation
and reﬁnement. In the learning phase, we apply automatic testing
techniques to generate, inexpensively, sample behavior of the class,
which consists of sequences of method calls. The hope is that the
test cases would cover a large portion of the complete behavior. Fur-
thermore, we adopt techniques from the machine learning commu-
nity and design a learning algorithm based on the L* algorithm [2]
to not only guide the test case generation but also generate can-
didate abstractions systematically based on the testing results. In
the validation phase, we apply more heavy-weight techniques like
symbolic execution to validate the abstraction so that the abstrac-
tion is guaranteed to be correct and accurate. After validation, the
abstraction is checked to see whether it is at a proper level of ab-
straction. If it is too abstract, we reﬁne the abstraction and restart
from the testing phase. The iterative process ends when the correct
and accurate abstraction is constructed.
However, a correct abstraction could be completely trivial and
thus useless. In order to make sure the abstraction is useful, we
need to answer two questions. The ﬁrst question is: what is the
right model for the abstraction? The answer decides what kind of
behaviors the abstraction is capable of capturing, which in turn de-
ﬁnes what purposes the abstraction could serve. One form of pro-
gram abstraction is predicate abstraction [5] which is particularly
useful for analyzing programs with non-trivial data states . Given
a program and a set of predicates, predicate abstraction constructs
an abstraction of the program by focusing only on the truth values
of a set of predicates. In our setting, predicate abstraction means to
construct an abstraction of the class in the form of a labeled Kripke
structure [11], i.e., a ﬁnite state automaton whose transitions are
labeled with method names and whose states are labeled with pred-
icates. An example is shown in Figure 5(b). Compared with other
models like ﬁnite state automata, this model is more expressive (for
1instance, using a predicate on the number of elements in a stack, it
c
an express languages like the number of popoperations must be
less than or equal to the number of push operations) and more
catered for classes with rich data states. Furthermore, such models
can be readily fed into a model checker for veriﬁcation.
The second question is what level of abstraction is sufﬁcient for
the analysis. Equivalently, in the context of predicate abstraction,
what is the set of predicates? This question can be answered only
based on the usage context. TLV provides three different ways.
First, if the abstraction is used to verify whether the class satisﬁes
certain temporal logic formula, it must be at a level which would
allow us to either prove or disprove the property. TLV extracts
from the formula an initial set of predicates and then generates an
abstraction as accurate as possible with respect to the predicates.
Afterwards, the abstraction can be veriﬁed against the given prop-
erty. In the event that a spurious counterexample is found, TLV
provides a way of automatically identifying a candidate predicate
for abstraction reﬁnement, based on the testing results and machine
learning techniques. With the new predicate, a new abstraction
is constructed and this process repeats until TLV generates an ab-
straction which either proves or disproves the property. However
if the abstraction is used by humans, the users should be able to
customize the level of abstraction and TLV provides two ways to
set the abstraction level manually. That is, users can either pro-
vide a set of predicates; or users can choose to provide no predicate
initially, but then ask TLV to resolve non-determinism in the ab-
straction through automatically generating new predicates.
The underlying idea of TLV is simple. The task of abstracting
a class is to discover all of its behavior, whereas testing could be
effective in uncovering behavior. Therefore, we ﬁrst apply testing
techniques with the hope to discover a large part of the behavior
inexpensively. However, simply relying on random testing is lim-
ited (e.g., for predicate coverage [47]) and thus active learning tech-
niques are adopted to not only guide the testing process but also to
construct concise candidate abstractions automatically. Only when
a likely abstraction has been obtained, theorem proving techniques
are used to validate the abstraction. Furthermore, through learning,
we are able to automatically discover predicates which can be used
to reﬁne the abstraction. The idea of learning from traces of a pro-
gram is not new [9, 22, 28, 49]. Neither is the idea of verifying the
learned model against programs [3, 50]. Rather, TLV combines a
number of techniques for effective abstraction.
In short, we make the following technical contributions. First,
we develop an approach on combining testing, active learning, and
validation to construct predicate abstractions at the proper level of
abstraction. Second, we propose a way of generating new predi-
cates to reﬁne a predicate abstraction. Third, we integrate our ap-
proach in a toolkit called TLV. We evaluate our approach using
a number of programs, including benchmark programs as well as
three real-world classes, and show that TLV generates abstraction
efﬁciently for program analysis and veriﬁcation.
2. AN ILLUSTRATIVE EXAMPLE
In this section, we illustrate how TLV works using a simple ex-
ample. The only input to TLV is the bounded stack class shown
in Figure 2. For simplicity, we focus on two methods: push and
pop. Recall that we need a usage context in order to determine
the right level of abstraction. For now, assume that the abstraction
is to be used for human comprehension and the user chooses not
to provide any predicate initially. Based on the assumption above,
the initial set of predicates is {⊤,⊥}where⊥is a special default
predicate which denotes whether a failure (i.e., assertion violation
or un-handled exception) has occurred and ⊤denotes no failure.Testing Learning ValidationJava 
c
odetraces
queriesFinal
a
bstractioncandidate
a
bstractiontraces
Refinementpredicates abstraction
Figure 1: The high-level workﬂow of the TLV
p
u b l i c c l a s s BoundedStack {
p r i v a t e s t a t i c f i n a l i n t MAX_SIZE = 1024;
p r i v a t e i n t s i z e ;
p r i v a t e i n t [ ] e l e m e n t s ;
p u b l i c BoundedStack ( ) {
s i z e = 0 ;
e l e m e n t s = new i n t [MAX_SIZE ] ;
}
p u b l i c void push ( i n t e l e m e n t ) {
i f( s i z e >= MAX_SIZE) {
throw new I l l e g a l S t a t e E x c e p t i o n ( " F u l l S t a c k " ) ;
}
e l e m e n t s [ s i z e ] = e l e m e n t ;
s i z e ++;
}
p u b l i c i n t pop ( ) {
i f( s i z e <= 0) {
throw new I l l e g a l S t a t e E x c e p t i o n ( " Empty S t a c k " ) ;
}
s i z e−−;
return e l e m e n t s [ s i z e ] ;
}
}
Figure 2: A bounded stack in Java
The Learning Phase In the learning phase, TLV applies a learning
algorithm similar to the L* algorithm [2] to learn a candidate ab-
straction, relying on automatic testing techniques [37]. TLV drives
the learning process by generating two kinds of queries (both of
which are slightly different from those in the L* algorithm). One
is membership queries, i.e., whether a sequence of method calls
would result in a particular abstract state. The other is candidate
queries, i.e., whether a candidate abstraction is correct and accurate
(formally deﬁned in Section 3). The queries and testing results are
summarized in an observation table, as shown in Figure 3 (a) where
/a\}bracketle{t/a\}bracketri}htis an empty sequence of method calls; /a\}bracketle{tpop,push/a\}bracketri}ht denotes the
sequence of calling push afterpop. The result column shows the
abstract state after the corresponding method calls. For instance,
after an empty sequence of method calls, ⊤is true and calling pop
right after initialization results in exception, i.e., ⊥. Notice that be-
cause methods may take parameters, the same sequence of method
calls may result in different abstract states, as we shall see later.
Based on the observation table, TLV generates the ﬁrst candidate
abstraction, as presented in Figure 3 (b).
Next, TLV asks a candidate query: is the abstraction in Fig-
ure 3 (b) correct? To answer the query, TLV performs random
walking, i.e., randomly generates a set of tests which correspond
to traces of the abstraction. Through the random walking, one in-
consistency between the abstraction and the class under analysis is
identiﬁed. That is, the abstraction predicts that calling pop from
state⊤always results in ⊥, whereas it is not the case. For in-
stance, calling method push ﬁrst and then pop results in no fail-
ure. The inconsistency suggests that the abstraction must be modi-
ﬁed. In this case, the observation table is updated, as shown in Fig-
ure 3 (c), which includes the sequence /a\}bracketle{tpush,pop /a\}bracketri}htand its testing
result. After more membership queries, TLV constructs the candi-
2trace result
/angbracketleft/angbracketright ⊤
/angbracketleftp
op/angbracketright ⊥
/angbracketleftp ush/angbracketright ⊤
/angbracketleftp
op,push/angbracketright ⊥
/angbracketleftp
op,pop/angbracketright⊥
(a)⊤ ⊥push
poppush,pop
(b
)
trace result
/angbracketleft/angbracketright ⊤
/angbracketleftp
op/angbracketright ⊥
/angbracketleftp ush/angbracketright ⊤
/angbracketleftp
ush,pop/angbracketright ⊤
/angbracketleftp
op,push/angbracketright ⊥
/angbracketleftp
op,pop/angbracketright⊥
(c)
⊤ ⊥push,pop
poppush,pop
(d
)⊤ ⊥push,pop
push,poppush,pop
(e)
F
igure 3: Artifacts in the 1st learning and validation iteration
date abstraction shown in Figure 3 (d). The answer to the candidate
query is positive and thus the learning phase terminates.
The Validation Phase The candidate abstraction may not be cor-
rect due to limitations of random testing. For instance, the abstrac-
tion in Figure 3 (d) is not correct as invoking method push at state
⊤may result in ⊥when the size of the stack equals MAX_SIZE.
This behavior is missing because there is no test case which in-
vokespush more than 1024 times. In general, cases like this are
hard to generate through random testing. Thus, the learned abstrac-
tion must be validated and reﬁned if necessary. For the candidate
abstraction shown in Figure 3 (d), two proof obligations are gen-
erated. One is {⊤}push{⊤} (a Hoare triple), which denotes that
invokingpush when there is no failure always results in no fail-
ure. The other is {⊤}pop{⊤∨⊥} , i.e., invoking popat⊤may or
may not result in failure. We adopt the assertion checking feature
in Symbolic PathFinder (SPF) [41] to discharge proof obligations.
First, TLV modiﬁes the push method by enclosing its method body
with a try block; it adds assert(false )to the catch block, i.e., to
assert that there is no failure and adds assert(true )to the ﬁnally-
block, i.e., to assert the post-condition; it adds the pre-condition
to an if-conditional. The modiﬁed push method is shown in Fig-
ure 4. Then TLV symbolically executes the modiﬁed push with
both parameters element andsize as symbolic inputs. An asser-
tion violation is found with concrete values for the symbolic in-
puts:element = 3 andsize= 1024 . Using the concrete values
as parameters for push, TLV constructs a test case and executes
push, which results in an exception (i.e., ⊥). Thus a transition
from state ⊤to⊥is added to the abstraction. After the proof obli-
gation{⊤}pop{⊤∨⊥} is also discharged, the abstraction shown in
Figure 3 (e) is guaranteed to be correct and accurate (see the proof
in Section 3).
Learning a candidate abstraction helps to reduce the proving ef-
fort. If a naïve approach was used to abstract the class, we would
need to check satisﬁability of every combination φ∧m∧δ, i.e.,
whether invoking mwithφresults in a state satisfying δ, whereφ
andδare constraints which can be formed using conjunction of the
given predicates or their negations and mis a method. The number
of such combinations is exponential to the number of predicates.
The Reﬁnement Phase A nondeterministic abstraction like Fig-
ure 3(e) might be confusing if it is intended for humans. For in-p u b l i c void push ( i n t element , i n t s i z e ) {
i f(t r u e ) { / / t r u e encodes t h e pre −c o n d i t i o n
t r y {
i f( s i z e >= MAX_SIZE) {
throw new E x c e p t i o n ( " F u l l S t a c k " ) ;
}
e l e m e n t s [ s i z e ] = e l e m e n t ;
s i z e ++;
}catch ( E x c e p t i o n e ) { a s s e r t ( f a l s e ) ;
}f i n a l l y { a s s e r t ( t r u e ) ; } / / post−c o n d i t i o n
}
}
Figure 4: Modiﬁed push method
sz≥0 ⊥push,pop
push,poppush,pop
(a)sz= 0 sz>0
⊥push
pop
pop
push push,pop
push,pop
(b
)
Figure 5: Reﬁned abstraction, where szstands for the ﬁeld size
stance, what does it mean to say that calling popmay or may not
lead to failure? To resolve non-determinism like this, TLV can be
instructed to identify predicates which would explain, for instance,
when exactly calling popleads to failure. The standard approach
(e.g., as in [14]) is to partition the state ⊤based onwp(pop,⊥), i.e.,
the weakest precondition of pop resulting in exception. Comput-
ing weakest precondition is often expensive. Instead, TLV applies
machine learning techniques, e.g., Supporting Vector Machines
(SVMs) [42], to identify a new predicate. In particular, TLV gathers
two groups of object states based on the test cases at state ⊤. One
group contains stack objects which would result in state ⊥after in-
vokingpop. The other group contains those which would result in
⊤. TLV uses SVM to generate a predicate which partitions the two
groups. The generated predicate is: 2∗size≥1, which is turned
intosize>0after some bookkeeping (based on the fact that size
is an integer). With the new predicate, we repeat the learning and
validation phase and obtain the abstraction in Figure 5(b).
The level of abstraction can be determined for different usage
contexts. For instance, if a temporal logic property is present (i.e.,
to be veriﬁed), TLV would generate and reﬁne the abstraction based
on interactions with the model checker. For instance, assume the
property is G(push∧Xpop=⇒ X(size≥0))(written in
state/event linear temporal logic [11]), i.e., after push andpop,
size≥0should be always true. The initial set of predicates is
set to be{size≥0,⊥}, i.e., all predicates in the property plus the
default one ⊥. Through the learning and validation phase, we ob-
tain the abstraction shown in Figure 5(a). Through model checking
(taking the abstraction as a labeled Kripke structure [11]), we found
a spurious counterexample: /a\}bracketle{tsize≥0,push,size ≥0,pop,⊥/a\}bracketri}ht,
which is a run of the abstraction. To remove this spurious coun-
terexample, again the standard approach is to partition the state p
based onwp(pop,⊥). TLV rather applies SVM to identify a new
predicate for differentiating states from which invoking popresults
in state⊥from states resulting in size≥0. With the generated
predicatesize >0, TLV generates a new abstraction shown in
Figure 5(b). We remark that the spurious counterexample above is
ruled out by the new abstraction. Model checking the abstraction
against G(push∧Xpop=⇒X(size≥0))is successful and thus
this abstraction serves as a proof of the property at an abstraction
level which is more abstract than the code.
33. THE TLV APPROACH
I
n this section, we present the details on how TLV generates an
abstraction. We start with deﬁning the problem.
3.1 Problem Deﬁnition
We assume a Java class Ccontains a ﬁnite set of instance vari-
ablesVand a ﬁnite set of methods M, each of which may up-
date variables in V. The semantics of Cis a labeled transition
system(Sc,sc,M,T c)whereScis a set of states, each of which
is a valuation of all variables in V;sc∈Scis the initial state;
Tc:Sc×M×Scis the transition relation such that (s,m,s′)∈Tc
iff, given the variable valuation s, executing method mmay re-
sult in variable valuation s′. A run of the labeled transition sys-
tem (a.k.a. a test of C) is a ﬁnite sequence of alternating states and
transitions /a\}bracketle{ts0,m0,s1,m1,···,mk,sk+1/a\}bracketri}htsuch thats0=scand
(si,mi,si+1)∈Tcfor alli≥0. The sequence of method calls in
the run/a\}bracketle{tm0,m1,···,mk/a\}bracketri}htis called a trace.
The problem is to construct an abstraction of Cautomatically.
LetProp be a set of propositions constituted by variables in V.
We write 2Propto denote the set of predicates each of which
is the conjunction of a subset of propositions in Prop and the
negation of the rest. For instance, if Prop={p,q},2Propis
{p∧q,p∧¯q,¯p∧q,¯p∧¯q}. We write the powerset of 2Propas
℘2Prop, i.e., the set of all subsets of 2Prop. A member of ℘2Prop
can be represented succinctly. For instance, the set {p∧¯q,p∧q}
can be represented as {p}, i.e., their disjunction. We write s|=φ
to denote that φevaluates to true given the variable valuation s.
Given a set of concrete states X, we writeabsProp(X)to denote
the disjunction of all members φof2Propsuch thats|=φfor
somes∈X. For instance, if Prop={size≥0,size≥1024},
absProp({size/mapsto→5,size/mapsto→1034})issize≥0.
An abstraction of Cw.r.t.Prop , denoted as A, is a labeled tran-
sition system (Sa,sa,M,T a)whereSa⊆℘2Prop∪ {⊥} is a
set of abstract states, each of which is a subset of 2Propor{⊥}
(a special state denoting exception); sa∈Sasatisﬁessc|=sa;
Ta⊆Sa×M×Sais an abstract transition relation. The abstrac-
tion is correct if there exists (s,m,s′)∈Tcsuch thats|=φand
s′|=φ′imply(φ,m,φ′)∈Ta. The abstraction is accurate if for
all(φ,m,φ′)∈Taimplies there exists (s,m,s′)∈Tcsuch that
s|=φands′|=φ′. However, a correct and accurate abstraction
may still contain spurious runs, due to broken traces [25] (i.e., an
abstract transition might be feasible locally but not globally). We
use abstract states and predicates interchangeably hereafter.
A naïve approach to obtaining Ais to check whether every pos-
sible transition (φ,m,φ′)where{φ,φ′} ⊆Saandm∈Mis
contained in A. This is infeasible as in the worst case there are
2|Prop|× |M| ×(2|Prop|+ 1) checks, where |Prop|is the num-
ber of propositions and |M|is the number of methods. Thus, we
propose the process shown in Figure 1 to learn A.
3.2 Testing and Learning
TLV starts with a testing and learning phase to obtain a candi-
date abstraction inexpensively. In this phase, TLV can be viewed
as a ‘game’ between two players. One is a learner who, in order
to learn, asks a series of membership queries and candidate queries.
A member query asks which abstract states can be reached after
a trace. For instance, in the stack example, a membership query
would be: /a\}bracketle{tpush,pop /a\}bracketri}ht. After multiple membership queries, the
learner makes a guess on what the abstraction is by generalizing
what it has learned so far and asks a candidate query. A candidate
query asks whether a candidate abstraction is correct and accurate.
The other player is a teacher. The teacher’s job is to answer both
kinds of queries. Ideally, a teacher would answer a membershipAlgorithm 1: T he learning algorithm
Input: a program and a set of propositions Prop
Output: an abstraction
1letobsbe an empty observation table; visited be∅;
2 while truedo
3 whileo bsis not closed and the time is not up do
4 le t trace trs.t.T(tr)/\e}atio\slash=T(tr′)∀preﬁxtr′oftr;
5 for m∈Mdo
6 g enerate a membership query tr·/a\}bracketle{tm/a\}bracketri}ht ;
7 letX:=Randoop (tr·/a\}bracketle{tm/a\}bracketri}ht);
8 obs:=obs+(tr·/a\}bracketle{tm/a\}bracketri}ht /mapsto→absProp(X));
9 g enerate a candidate query Afromobs;
10 apply random walking to check A;
11 if no inconsistency found then
12 if A lgorithm 2(A, obs,visited ) returns true then
13 return A;
14 else
15 le t (tr,s)be a counterexample to the candidate A;
16obs:=obs+(tr/mapsto→absProp({s}));
query with all abstract states that can be reached with the given
tr
ace. The teacher answers positively to a candidate query iff the
candidate abstraction is correct and accurate; if the answer to a can-
didate query is negative, the teacher should provide a counterexam-
ple in the form of a concrete test case, which shows the candidate
abstraction is problematic. In practice, having a perfect teacher
is expensive. For instance, answering a membership query would
require checking whether it is feasible to satisfy any proposition in
Prop after a sequence of method calls, which is a non-trivial reach-
ability analysis problem. Even worse, answering a candidate query
would require solving the abstraction problem itself. Thus, instead
of using a perfect teacher, TLV employs a tester (i.e., an imperfect
teacher) to answer the queries.
TLV’s algorithm is presented as Algorithm 1. The inputs are
a program and a set of propositions Prop and the output is an ab-
straction. TLV maintains two data structures. One is an observation
tableobsfor storing (abstract) testing results and the other is a set
visited for storing validation results. The observation table obsis
a tuple(P,E,T)whereP⊆M∗is a set of traces; E⊆Sais a
set of abstract states; T:P→Eis a mapping function such that
T(tr) =φmeans that after the trace tr, the abstract state φcan be
reached. Initially, P,E,T, andvisited are all empty (line 1). We
writeobs:=obs+(tr/mapsto→φ)to denote the operation of adding the
mappingtr/mapsto→φinto the table, i.e., replacing PwithP∪ {tr};
replacingEwithE∪{φ};Tis updated with T(tr) :=φiftrwas
not in the domain of T; otherwise,T(tr) :=T(tr)∨φ. Intuitively,
the latter states that if we knew that after tr, we can reach an ab-
stract stateT(tr), with the new mapping tr/mapsto→φ, we now know
that aftertr, we can reach either T(tr)orφ.
Within a certain time limit, TLV tries to make the observation ta-
bleclosed by asking multiple membership queries and adding map-
pings intoobs(line 3–8). Note that the concept of consistency in
theL* algorithm is irrelevant in our setting. An observation table is
closed if the setPis preﬁx-closed and for all tr∈Psuch thattr
is not a preﬁx of some other trace in P(i.e.,tris maximum), there
always exists a preﬁx of trsaytr′∈Psuch thatT(tr′) =T(tr).
Intuitively, the latter means that trcan be represented by its preﬁx
and therefore TLV does not need to test further. Since there are only
ﬁnitely many abstract states, trwould eventually visit a state which
4is visited by its preﬁx. We remark that this deﬁnition is justiﬁed be-
c
ause our goal is to discover as many abstract states and transitions
as possible. If the observation table is not closed, there must be a
tracetrsuch thatT(tr)is not equivalent to T(tr′)for every pre-
ﬁxtr′oftr. In such a case, a membership query (i.e., tr· /a\}bracketle{tm/a\}bracketri}ht )
is generated for each method (line 6). In order to answer the query
inexpensively, TLV generates multiple test cases using random test-
ing (line 7). Function Randoop (tr)is similar to the Randoop algo-
rithm [37]. Given a membership query tr, TLV generates multiple
test cases calling the methods in the query one-by-one (from the
initial concrete state). In general, the methods would have multi-
ple parameters and TLV generates arguments for every method call.
Given a typed parameter, TLV randomly generates a value from a
pool of type-compatible values. This pool composes of a set of pre-
deﬁned values (e.g., a random integer for an integer type, null or
an object with the default object state for a user-deﬁned class) and
type-compatible objects that have been generated during the testing
process. In order to re-create the same object, we store the test case
which produces the object.
After generating and executing multiple test cases according to
tr· /a\}bracketle{tm/a\}bracketri}ht , TLV collects the concrete data states reached by the test
cases (sayX) and updates the observation table with the mapping
T(tr·/a\}bracketle{tm/a\}bracketri}ht) =absProp(X)(line 8). Ideally, after multiple member-
ship queries, once the observation table (P,E,T)is closed, TLV
constructs a candidate abstraction A= (Sa,sa,M,T a)such that
Sa=E;sais the state corresponding to the empty trace T(/a\}bracketle{t/a\}bracketri}ht);
(φ,m,φ′)∈Taif there exists tr∈Pandm∈Msuch that
T(tr) =φandT(tr·/a\}bracketle{tm/a\}bracketri}ht) =φ′. In practice, with many methods
in the class, it might take a long time before the observation table
is closed. Nonetheless, with the validation phase, we can construct
the candidate abstraction even if the observation table is not closed.
In fact, the goal is to discover every abstract behavior of the class
and it is guaranteed that every behavior is discovered either during
testing or validation. Thus, if closing the observation table takes a
long time, TLV times out and constructs Abased onobs.
Once the observation table is closed or learning timeouts, TLV
raises a candidate query on whether Ais correct and accurate w.r.t.
Prop (line 9). TLV then employs a slightly different testing tech-
nique to answer candidate queries. We associate each abstract
stateφinAwith a set of concrete states which have been gen-
erated through testing so far and satisfy φ. Based on these con-
crete states, TLV uses random walking to construct test cases from
each abstract state inAto further explore behaviors of C(line
10). The testing result is then compared with Ato see whether
they are consistent. Ais consistent with the testing result iff for
any sequence of method calls tr′from a concrete state (associ-
ated with an abstract state φ), the resultant concrete states Xare
consistent with the corresponding abstract state φ′reached by the
same sequence of methods in A, i.e.,absProp(X)logically im-
pliesφ′. There is an inconsistency iff there exists a concrete state
s∈Xsuch thats/\e}atio\slash|=φ′(line 11). In such a case, TLV con-
structs a pair (tr,s), wheretr=tr1·tr′andtr1is the short-
est trace reaching φinA, as a counterexample to the candidate
query (line 15), which is then used to update the observation ta-
ble (line 16). For instance, assume Prop={size≥0}and the
abstract state after trin the observation table is size≥0, i.e.,
T(tr) =size≥0. If after calling the methods in trin sequence,
the concrete states are {size/mapsto→2,size/mapsto→3,size/mapsto→4}, then it
is consistent. However, a testing result size/mapsto→ −2 would be an
inconsistency and the observation table would be updated so that
T(tr) =size≥0∨size<0.
Once the observation table is updated, TLV again checks whether
it is closed and raises membership queries if it is not, until the nextAlgorithm 2: T he validation algorithm
Input: abstraction A= (Sa,sa,M,T a); table
obs= (P,E,T ); setvisited
Output: true iff Ais validated
1 forφ∈Sa\{⊥} andm∈Mdo
2 if th e pair (φ,m) is not invisited then
3 c heck the proof obligation {φ}m{ψ}using SPF
whereψis the disjunction of all φ′such that
(φ,m,φ′)∈Ta;
4 if a counterexample is found by SPF then
5 c onstruct a concrete state s|=φwith the
counterexample and invoke monsand obtain
a concrete state s′;
6 ifabsProp({s′})is not inEthen
7 le ttrbe the shortest trace in Psuch that
T(tr) =φ; updateobswith the new
mappingtr·/a\}bracketle{tm/a\}bracketri}ht /mapsto→absProp({s′});
8 return false;
9 else
10 a dd a transition from φtoabsProp({s′})
labeled with m;
11 else
12 a dd pair(φ,m) intovisited ;
13 return tr ue;
candidate query is generated. Once the tester answers positively
to
a candidate abstraction (at line 11), TLV obtains an abstraction
which is “correct” modulo the limitation of random testing. Then,
Algorithm 2 is invoked to validate A(line 12). If it returns true, A
is returned (line 13); otherwise, the process repeats. The details of
Algorithm 2 is presented in the subsequent subsection.
Given that the number of states in A(and the size of Ein the ob-
servation table) is bounded by 3|Prop|+1, the learning algorithm
is always terminating. Furthermore, we argue that Amay be much
smaller than this bound in practice. Firstly, variables in a class are
often co-related, which is equivalent to say that there are hidden
class invariants. Due to those class invariants, often not every ab-
stract state is reachable. For instance, if a hidden class invariant
isv1≥v2andProp={v1≥0,v2≥0}, the abstract state
v1<0∧v2≥0is infeasible. Because Ais constructed based
on concrete testing results, those hidden class invariants are embed-
ded inAnaturally and hence Awould not contain those infeasible
abstract states. Secondly, as mentioned, given a set of concrete
statesX(reached by the same trace), the abstract state constructed
isabsProp(X), which would effectively collapse many abstract
transitions into one. Furthermore, unlike the L* algorithm, TLV
may learn a non-deterministic abstraction, which could be expo-
nentially smaller than its deterministic equivalent. Nonetheless, we
admit that the effectiveness of the testing technique may affect the
size of the abstraction. We skip the discussion on the complexity of
the algorithm as it depends on the effectiveness of the testing tech-
niques. Rather, we show empirically in Section 4 that the learning
phase is usually efﬁcient and the generated candidate abstraction
usually covers a large portion of the behavior of C.
3.3 Validation
Due to the limitation of random testing, the abstraction learned
through testing might not be correct as some behaviors of Cmay
never be tested. For instance, in the stack example, it is unlikely
5that we could generate a test case which pushes more than 1024
tim
es and thus the transition (⊤,push, ⊥)would be missing. How-
ever, the abstraction is guaranteed to be accurate (but may not be
correct).
LEMMA 3.1. Algorithm 1 returns an accurate abstraction A.
Proof (sketch): To prove that Ais accurate, we need to prove that
for every transition (φ,m,φ′)inA, there exists a concrete state s
such thats|=φand invoking matswould result in a concrete
states′such thats′|=φ′. This is guaranteed by line 8 and 16 in
Algorithm 1 which adds a mapping into the observation table such
that ifT(tr) =φandT(tr· /a\}bracketle{tm/a\}bracketri}ht) =φ′, then there must be a
concrete transition from a state satisfying φto a state satisfying φ′
through invoking m, in both cases. Afterwards, we can prove the
lemma based on the construction of A. /square
The lemma above states that every transition in Acorresponds
to at least one concrete transition. Next, TLV checks if there are
missing transitions and if there is none, Ais guaranteed to be an
over-approximation at the same time. In the following, we illustrate
how the validation algorithm (Algorithm 2) works.
The inputs are the observation table obsand the corresponding
abstraction Aas well as the set visited which contains pairs of the
form(φ,m) whereφis an abstract state and mis a method name.
The setvisited stores the successfully discharged proof obligations
so far. Every time the algorithm is invoked, for every pair (φ,m) of
abstract states (exclusive of ⊥) and methods, TLV checks whether
it is invisited (line 2). Intuitively, it is in visited iff TLV has
obtained all abstract states which are reachable from φby invok-
ingm. If it is not in visited , TLV generates a proof obligation
{φ}m{ψ}whereψis the disjunction of all abstract states which
are reachable from φthroughminA(line 3). The proof obliga-
tion is discharged using symbolic execution, i.e., with the help of
Symbolic PathFinder (SPF [41]), as explained in the following.
In a nutshell, given a Java program, SPF executes the code sym-
bolically so as to see whether there is an assertion violation. If
an assertion violation is possible, SPF generates a counterexam-
ple, which consists of the valuation of input variables and a path
condition that lead to the assertion violation. We refer interested
readers to work [41] for details on SPF. We instead present how the
proof obligation is encoded as an assertion violation checking prob-
lem. The ﬁrst step of the encoding is to syntactically transform the
methodmsuch that all relevant instance variables become param-
eters of the method. Next, TLV instruments the modiﬁed method
with the required pre-condition φand post-condition ψ. The fol-
lowing illustrates how the instrumentation is done systematically.
i f(φ) {
t r y { body of method m; }
catch ( E x c e p t i o n e ) {
a s s e r t f a l s e i f e x c e p t i o n i s n o t i n ψ;
}f i n a l l y { a s s e r t (ψ) ; }
}
TLV ﬁrst encloses the original method body with a try-catch-
ﬁnally block to catch all exceptions. The try block contains the
method body of m. If⊥logically implies ψ(i.e.,Asuggests that
exception might be the result when we invoke method mwith pre-
conditionφ), the try block contains no assertion; otherwise, it con-
tains the assertion assert(false ). Thus, if an exception is not sup-
posed to occur, then the occurrence of an exception would lead
to an assertion failure. The ﬁnally block contains the assertion
assert(ψ )which asserts the post-condition. Next, TLV encloses
the try-catch-ﬁnally block with an if-conditional block. The condi-
tion is set to be the pre-condition φso that SPF checks only sym-
bolic inputs which satisfy the pre-condition. The modiﬁed program
is then fed to SPF for assertion violation checking.If no assertion violation is found, the pair (φ,m) is added into
visited (line 12). Otherwise, using the information returned by
SPF, TLV constructs a test case which starts from a concrete state
satisfyingφand results in a concrete state violating ψ(line 5). Note
that in the actual implementation SPF is conﬁgured to generate mul-
tiple counterexamples at once to reduce the number of SPF invoca-
tions. For the stack example, when SPF is used to prove {size≥
0}push{size≥0}, a counterexample is generated which al-
lows TLV to construct a concrete state with element = 3 and
size= 1024 . Invoking method push at this concrete state results
in state⊥which violates size≥0. IfabsProp({s′})is inSa(not
a newly discovered abstract state), at line 10, TLV adds a new tran-
sition fromφtoabsProp({s′}). If the abstract state absProp({s′})
was unreachable previously, at line 7, TLV updates the observation
table with a new mapping: tr· /a\}bracketle{tm/a\}bracketri}ht /mapsto→absProp({s′})wheretr
(i.e., the shortest trace which reaches φ) is a representative of all
traces reaching φ. With the new abstract state, the observation ta-
ble is no longer closed and therefore Algorithm 2 returns false (line
8) and TLV will execute the learning algorithm again to obtain an-
other candidate. The idea is that we always ﬁrst rely on testing to
discover some of the states and transitions inexpensively. Note that
executing the learning algorithm again does not invalidate Lemma
3.1 as we show in the following that Aremains accurate during the
validation algorithm. The validation algorithm returns true when
every pair (φ,m) is invisited (line 13). The following theorem
establishes the correctness of TLV .
THEOREM 3.2. When the validation algorithm (Algorithm 2)
terminates, Ais a correct and accurate abstraction of C.
Proof (sketch): According to Lemma 3.1, Ais accurate before
the validation algorithm starts, i.e., for every abstract transition
(φ,m,φ′)inA, there is a concrete transition (s,m,s′)such that
s|=φands′|=φ′. We need to prove that (1) during the validation
algorithm, an abstract transition (φ,m,φ′)is added to Aif there
is a concrete transition (s,m,s′)such thats|=φands′|=φ′;
(2) if there is a concrete transition (s,m,s′)such thats|=φand
s′|=φ′, the abstract transition (φ,m,φ′)is inA. (1) is true be-
cause new transitions are only introduced at line 10 and (indirectly)
at line 7 in Algorithm 2. In both cases, (1) is true as sis obtained
from line 5 with a concrete transition. (2) can be proved by contra-
diction. Assume (s,m,s′)is a concrete transition such that s|=φ
ands′|=φ′and(φ,m,φ′)is not a transition in A. Then there is
a proof obligation {φ}m{ψ}such thatφ′does not imply ψgen-
erated at line 3. Assume that SPF works correctly, then the proof
must fail, which contradicts the fact all proof obligations must be
discharged before the validation algorithm terminates. Thus, we
conclude the above theorem is correct. /square
In the following, we discuss the complexity of the algorithm. As-
sume that proving with SPF is terminating, because the number of
states inAis bounded, the validation algorithm always terminates.
The number of proof obligations is determined by the number of
abstract states in A. In the worst case, it is exponential in the num-
ber of propositions in Prop . In practice, it is often much less as we
show empirically in Section 4. The transitions in Aare discovered
through either testing or symbolic execution. The more testing dis-
covers, the less symbolic execution is needed. Because testing is
more scalable than symbolic execution, thus by design, TLV min-
imizes symbolic execution as much as possible. Although Ais
correct and accurate, it does not mean that all runs in Aare feasi-
ble. For instance, the run /a\}bracketle{t⊤,push, ⊤,push, ⊥/a\}bracketri}htof the abstraction
shown in Figure 3(e) is infeasible. This is essentially due to the
phenomenon known as broken traces [25]. We use abstraction re-
ﬁnement to remove such infeasible runs.
63.4 Abstraction Reﬁnement
T
here are two cases where an abstraction reﬁnement is necessary.
One is that the user requires to resolve some non-determinism in the
abstraction. The other is to reﬁne the abstraction so as to prune a
particular spurious counterexample identiﬁed by a model checker.
In the following, we explain the latter ﬁrst and show that the two
cases can be solved in the same way.
The abstraction generated after the validation phase is subject to
veriﬁcation techniques like model checking. Assume that the prop-
erty to be veriﬁed is a safety property (e.g., a bounded LTL formula
constituted by propositions on instance variables in C). Because the
abstraction is guaranteed to be correct, if model checking based on
Aconcludes there is no counterexample, then the same property is
satisﬁed by C. If a counterexample is identiﬁed, we need to check
whether it is spurious. If it is spurious, Amust be reﬁned to exclude
the spurious counterexample. In the following, we show that a new
predicate can be generated based on the information TLV gathered
during the learning and validation process. We remark that ﬁnding
the optimal reﬁnement is known to be hard [14] and is not our goal.
Recall that by assumption, in the setting of verifying a temporal
logic formula, Prop contains all propositions in the formula. Let
/a\}bracketle{tφ0,m0,φ1,m1,···,φk,mk,φk+1/a\}bracketri}htbe the spurious counterex-
ample, which is a ﬁnite run of A(as this property is a safety prop-
erty). Because this run is spurious, it must be broken at some ab-
stract stateφiwherei≤k, i.e., invoking miat a reachable (from
the concrete initial state) state satisfying φinever results in a state
satisfying certain required constraint φi+1[25]. The idea is that
if we are able to ﬁnd a new predicate which could separate those
concrete states (abstracted as φi) which, after invoking mi, would
result in a state satisfying φi+1from those would result in a state vi-
olatingφi+1, then we can construct a new abstraction (with the new
predicate) to rule out this spurious counterexample. For instance, in
the stack example shown in Section 2, the spurious counterexample
is:/a\}bracketle{tsize≥0,push,size ≥0,pop,⊥/a\}bracketri}ht. It is sufﬁcient to rule out
the run if we could ﬁnd a predicate separating those concrete states
associated with abstract state size≥0into two groups: one result-
ing in⊥afterpopand the other resulting in size≥0afterpop.
Thus, the problem is to ﬁnd a classiﬁer for two sets of states, which
can be solved using a machine learning based approach [44, 49].
In the case of resolving a non-determinism (as requested by the
user), by deﬁnition, we have one abstract state, at which calling the
same method would result in two different abstract states. Thus, the
task of resolving the non-determinism is similarly to ﬁnd a classiﬁer
for two sets of states at the abstract state. In the following, we
brieﬂy explain how Support Vector Machines (SVMs) [42] is used
to ﬁnd the classiﬁer.
During the process of generating the abstraction, TLV associates
a set of concrete states for each abstract state, which can be par-
titioned into two groups accordingly. For instance, in the stack
example above, one group contains stack objects with size≥1
(for which there is no exception after pop) and the other contains
a stack object with size= 0 (for which an exception occurs after
pop). With these two groups (say XandY), TLV tries to identify
a classiﬁer. Formally, a classiﬁer for XandYis a proposition ω
such that for all x∈X,xsatisﬁesωand for ally∈Y, andy
does not satisfy ω. TLV ﬁnds the classiﬁer automatically based on
techniques developed by machine learning community, e.g., SVM.
As long asXandYare linearly separable, SVM is guaranteed to
ﬁnd a classiﬁer (i.e., a hyperplane) separating XandY. Further-
more, there are usually more than one classiﬁers. In this work, TLV
favors the optimal margin classiﬁer [44] if possible. This separat-
ing hyperplane could be seen as the strongest witness why the two
groups are different.In order to use SVM to generate classiﬁers, each element in X
orYmust be casted into a vector of numerical types. In general,
there are both numerical type (e.g., int) and categorical type (e.g.,
String) variables in Java programs. Thus, we need a systematic
way of mapping arbitrary object states to numerical values so as to
apply SVM techniques. Furthermore, the inverse mapping is also
important to feedback the SVM results to the original program. We
leverage our earlier approach [49] to generate a numerical value
graph from each object type and apply SVM techniques to values
associated with nodes in the graph level-by-level. We illustrate our
approach using an example in the following.
Recall that one group contains stack objects with size= 1 and
the other contains a stack object with size= 0. TLV ﬁrst extracts
two sets of feature vectors from the two groups using the ﬁrst level
features (i.e., features which can be accessed using the stack object
and no other references) in the graph, i.e., isNull andsize. The
ﬁrst set of feature vectors is {/a\}bracketle{t0,1/a\}bracketri}ht}where/a\}bracketle{t0,1/a\}bracketri}htdenotes the stack
object is not null (i.e., 0 means that isNull is false) and its variable
size is of value 1. The second set is {/a\}bracketle{t0,0/a\}bracketri}ht}. Next, SVM ﬁnds a
classiﬁer 2∗size≥1. Notice that if SVM fails to ﬁnd a linear clas-
siﬁer based on the two sets of feature vectors, TLV constructs two
new sets by using numerical values from next level in the graph
(i.e.,isNull forelements andlength ofelements , and the ac-
tual data in the array) and tries SVM again. The heuristic that we
look for a classiﬁer level-by-level is based on the belief that calling
the same method leads to different results is more likely related to
the values of variables directly deﬁned in the class and less likely
nested in its referenced data variables.
4. EV ALUATION
TLV (available at [48]) is implemented with about 35K lines of
Java code. We use Eclipse JDT to analyze and instrument Java
source code, e.g., for generating modiﬁed programs for symbolic
execution. We use SPF [39, 41] for symbolic execution because it
supports features (such as assertion checking) which are necessary
in our approach. The experimental results are collected on a 64-bit
Ubuntu 14.04 PC with a 3.10GHz Intel Core i3 processor and 4GB
memory. For the learning phase, we generate 4 concrete values for
each argument of the method in an abstract trace and each learning
iteration is set to timeout in 1 minute. We evaluated TLV to answer
three research questions.
RQ1: How effective and scalable is TLV?
The answer to this question depends not only on the capability of
TLV but also on SPF. Thus, we answer the question by applying
TLV to two groups of Java classes, one containing relatively simple
classes which we could get useful results from SPF and the other
containing real-world classes which are beyond the capability of
SPF. The idea is to show that TLV is able to generate correct and
accurate abstraction efﬁciently if the symbolic execution engine is
working as hoped, and TLV is able to generate meaningful abstrac-
tions (without soundness guarantee) for large programs even when
SPF fails to provide any support.
The ﬁrst group contains 12 Java classes. In particular, classes
ALTBIT, FLIGHT RULE, INTMATH, SIGNATURE , SOCKET and
STREAM were used in the evaluation of X-P SYCO tool [28];
SERVER TABLE and L ISTITRare from the work [1]; B ANK AC-
COUNT is from the work [50] and EWALLET and P AYAPPLET are
adopted from Java Card applets [30]. To determine the level of ab-
straction, for each class, we set the initial predicates to be those col-
lected from the source code, e.g., conditions in “if” and “for” state-
ments. In our experience, those predicates would often allow us to
quickly get some idea of the class behavior. The set of predicates
7Table 1: Statistics on TLV abstracting the classes, where N.A. stan ds for not available
Inputs Learning Initial Abs Validation Final Abs Memory (MB)
Class LOC #M #P red #M Q #CQ T L(s) #S #TTV(s) #P rof #S #T TLV
AL TBIT 60 2 3 22 1 0.4 5 11 7.0 8 5 11 104
BA NK ACCOUNT 40 2 3 22 1 0.7 3 8 4.7 4 3 8 105
BO UNDED STACK 45 2 3 8 2 0.1 2 3 7.0 2 3 7 104
FL IGHT RULE 50 3 1 10 1 0.2 2 3 2.7 3 3 8 104
IN TMATH 500 8 1 5209 1 60.3 2 16 5.0 8 2 16 544
LI ST ITR 40 5 4 320 1 1.3 6 36 25.7 25 6 47 291
SE RVER TABLE 90 6 6 5485 1 60.2 6 42 29.3 30 6 42 712
SO CKET 200 7 10 6203 1 60.2 13 102 167 168 25 219 559
ST REAM 180 4 3 41 1 0.6 3 9 7.0 8 3 9 104
SI GNATURE 50 5 4 61 1 0.4 4 15 13.1 15 4 15 104
EWA LLET 90 4 5 33 1 0.4 2 5 7.5 8 3 13 169
PA YAPPLET 100 5 6 31 1 0.3 2 5 29.8 25 6 29 104
SO CKET REAL 1660 7 6 1807 1 60.6 13 85 N.A. N.A. 13 85 381
JA VA MAILREAL 2000 5 2 21 1 14.6 3 10 N.A. N.A. 3 10 357
ST REAM REAL 180 4 4 2725 1 60.2 4 14 N.A. N.A. 4 14 454
for each of the above target classes can be accessed at our web-
s
ite [48]. We acknowledge that these classes are relatively small
because most of the above-mentioned approaches (like TLV) are
limited to the capabilities of symbolic execution.
To show that TLV is useful even without the validation phase,
we collect a second group of classes, containing real-world pro-
grams, and apply TLV to generate abstraction. In particular,
SOCKET REAL is the java.net.Socket class deﬁned in JDK 7 (with
>1.6K LOC in the class and >20K LOC in the referenced library);
JAVAMAILREAL is the com.sun.mail.smtp.SMTPTransport class
deﬁned in the JavaMail library (version 1.5.2, with 2K LOC in the
class and >45K LOC in the referenced library). S TREAM REAL is
the JDK 7 class java.io.PipedOutputStream class (with 180 LOC in
the class and >3K LOC in the referenced library). These programs
are un-modiﬁed other than that we set the ﬁrst two programs to con-
nect to a local socket server and mail server for testing purpose (as
did in TAUTOKO [16, 17]). They either use Java Native Interface
or contain reference type ﬁelds and parameters, which are not sup-
ported by SPF. To determine the level of abstraction, we manually
inspect the classes and collect predicates which we believe are asso-
ciated with the class invariants. Based on the abstractions learned
by TLV we conﬁrm that those are indeed class invariants.
The statistics on the experiments with these two groups of classes
are shown in Table 1. Column #M shows the number of methods
used for abstraction; Column #Pred is the number of propositions
for each class (excluding the one on whether the state is ⊥). We
collect the number of membership queries (column #MQ ), and the
number of candidate queries (column #CQ ), and the total time (col-
umnTL) to learn the initial abstraction. The statistics for the valida-
tion phase are the number of proof obligations (column #Prof , i.e.,
the size ofvisited in the validation algorithm) and the time used in
the validation phase (column TV). A closer look shows that TLis
dominated by the time spent on maintaining the observation table
(so as to make it memory efﬁcient by merging abstract states/tran-
sitions). On the contrary, running the test cases only takes a very
small portion of the time. TVincludes the interprocess communi-
cation time and each invocation of SPF often takes less than one
second. The instrumentation and compilation time in the valida-
tion phase are negligible. For all classes, we manually conﬁrm the
correctness and accuracy of the generated abstractions. It is shown
that for all classes, TLV generates the abstraction in minutes. Fur-
thermore, the overall time is dominated mostly by the validation
algorithm (for 10 out of 12 cases) for the ﬁrst group of classes. For
all classes, the peak memory consumption for TLV is 712 MB and
thus TLV is reasonably memory efﬁcient.Comparison with other tools To the best of our knowledge, TLV
is the only tool which combines testing, learning and validation
for abstracting Java classes. There are two existing tools on pred-
icate abstraction of Java programs: J2BP [38] and X-P SYCO [28].
Our investigation of J2BP shows that it generates abstractions for a
Java program with a “main” method and not for Java classes. Fur-
thermore, it does not support random numbers or symbolic inputs,
we are unable to write a driver program so that J2BP can be used
to abstract a Java class. X-P SYCO is designed for generating an
interface speciﬁcation. It discovers predicates (through symbolic
execution) which are constituted by method parameters to specify
constraints which must be satisﬁed in order to invoke the method.
X-P SYCO assumes that only propositions on method parameters
and return values are relevant, which implies that X-P SYCO is tar-
geting completely different programs from TLV . Thus, we conclude
that X-P SYCO and TLV are complementary but incomparable. In
addition, there is one ongoing effort by the JPF team [19] and a pre-
viously reported tool [1], which is not available any more. Besides
tools for predicate abstraction, there are tools of learning models
of Java classes, among which we identify the TAUTOKO tool [16,
17] to be bearing a similar goal as TLV . Thus, in the following, we
compare TLV with TAUTOKO1in the context of answering the
above research question.
TAUTOKO ﬁrst uses ADABU [18] to generate a model for
each test case in the user-provided test suite and combines these
models into an initial model. It then mutates existing test cases
to generate more tests cases from the initial model and combines
models for new test cases with the initial model to generate an en-
riched model. For fairness, we use the test cases generated by TLV
in the learning phase as the input test suite for TAUTOKO. For the
predicates, TAUTOKO is limited to predicates generated with a set
of abstraction templates over instance variables of the given class,
while TLV is more ﬂexible. Thus, we set the predicate used in
TLV to be those used in TAUTOKO. We compare TLV and TAU-
TOKO by applying them to the ﬁrst group of classes. Notice that
TAUTOKO has trouble obtaining models for the second group of
classes for various reasons, i.e., TAUTOKO cannot handle S OCK-
ETREAL as TAUTOKO does not support Java 7; TAUTOKO does
not generate models for S TREAM REAL because it does not instru-
ment classes in java.io package; TAUTOKO fails to execute the
test suite for J AVAMAILREAL. The statistics for the models gener-
ated by TAUTOKO and TLV are shown in Table 2, which shows
the number of states (column #S ) and transitions (column #T ) dis-
covered by TLV and TAUTOKO, respectively. In addition, #T e
denotes the numbers of transitions to state ⊥, which is a useful
1We use the version of TAUTOKO reported in [17] as the imple-
mentation reported in their later work [16] is not available.
8Table 2: Comparing TLV with TAUTOKO on abstraction
TLV TAUTOKO
Class #S #T #TeT(s) #S #T #TeT(s)
AL TBIT 5 11 8 7.6 4 5 2 37.2
BA NK ACCOUNT 5 19 8 141.2 4 12 0 1817
BO UNDED STACK 3 7 2 4.4 3 5 1 14.2
FL IGHT RULE 3 8 3 6.5 2 3 2 12.6
IN TMATH 2 16 8 5.9 1 6 0 6.4
LI ST ITR 6 47 19 27.0 3 10 2 20.2
SE RVER TABLE 12 118 52 68.5 7 27 10 244.2
SO CKET 25 219 146 174.0 2 8 1 475.8
ST REAM 3 9 2 7.9 3 7 1 9.7
SI GNATURE 4 15 5 14.4 4 15 5 18.4
EWA LLET 3 13 8 8.2 2 2 1 2.4
PA YAPPLET 6 29 20 15.3 2 3 2 12.5
Table 3: Comparing TLV’s abstraction and manual abstraction
Testing and Learning Manually Constructed
Class #S #T #Te #S #T #Te
JA VA MAILREAL 3 10 2 3 10 2
ST REAM REAL 4 14 6 4 14 6
SO CKET REAL 13 85 62 13 85 62
metric [17]. The results show that TLV always generates more ac-
c
urate models (because more valid states and transitions are gener-
ated) than TAUTOKO. The time statistics (column T) show that
TLV is often more efﬁcient than TAUTOKO, especially when the
number of test cases is large.
RQ2: How effective are testing and learning?
This question evaluates TLV’s underlying assumption, i.e., testing
and learning could effectively reduce the effort on symbolic execu-
tion. For the second group of classes, the answer to the question
would determine how much behavior the abstraction contains and
thus how useful it is, since the symbolic execution engine is help-
less for these classes. For the ﬁrst group of classes, this question is
answered by measuring the percentage of abstract states/transitions
which are discovered in the learning phase. In particular, we com-
pare the initial candidate abstraction (column Initial Abs) which
is generated based on testing and learning only and the ﬁnal ab-
straction (column Final Abs). We collected the respective number
of states (column #S ) and number of transitions (column #T ). It
can be observed that for most of the classes in the ﬁrst group (11
out of 12), most of the states (96%) and transitions (94%) are dis-
covered during learning based on the test cases, which suggests
that our underlying assumption is often valid. On the other hand,
there is only one class (P AYAPPLET ) where testing is shown to
be ineffective in discovering the behavior (only 17% of the tran-
sitions are discovered by testing), which evidences that a validation
phase is indeed necessary. A closer look at the class shows that
only the method “setKey” leads to a state (which is then connected
to a number of other states) from the initial state. Furthermore,
this transition can only happen when a particular integer param-
eter value is passed in (there is an “if” statement with condition
size= (DES _KEY _SIZE+ID_SIZE)). TLV did not gen-
erate the particular integer value and thus missed many states. We
expect this could be more often with larger and more complicated
programs, which might pose a thread to TLV . On the other hand, by
comparing the TLwithTVand contrasting TLwith the number of
transitions discovered during testing, it is evident that testing dis-
covers abstract states/transitions much cheaper than symbolic exe-
cution and therefore it is wise to start with testing and learning.
For the second groups of classes, we compare the generated ab-
stractions with those constructed manually using the same set of
predicates. The results in Table 3 show that TLV can learn all theS0
S2S3
S4 S6S7 S5
S8S9
S10
S11S12
closebind
connect
closeconnectclose
getInputStream,getOutputStreamcloseshutdownInput
shutdownOutputclose
closegetOutputStreamclose
shutdownOutput
getInputStream
shutdownInputcloseclose
close
closeclose
F
igure 6: Abstraction for java.net.Socket class with the fol-
lowing predicates: closed=T,created =T,bound =
T,shutIn =T,shutOut =T,connected =T, where the er-
ror stateS1and all transitions to it are omitted for brevity.
states and transitions of these classes with regard to the given set
of predicates. In general this is hard to achieve. However, for these
classes whose methods have no or few parameters, learning-guided
testing, as implemented in TLV , is effective at discovering most of
the behaviors systematically. In the following, we present some
details on the S OCKET REAL case. The abstraction generated by
TLV is shown in Figure 6 with the 6 predicates used for abstrac-
tion. The predicates are obtained from suspected class invariants,
e.g.,connected =Timpliesbound=Tandbound=Timplies
created =T. Thus, part of the goal of using TLV to generate
the abstraction is to check whether these are indeed class invariants.
The abstraction learned by TLV contains (only) 12 valid states plus
the error state. In addition to those shown in Figure 6, there is a
transition from S0toS1labeled with bind which occurs when the
port number (e.g., 3) for binding is reserved and thus the method
call results in permission violation exception. Note that other tran-
sitions to the error state are omitted for brevity. We conﬁrm that
the abstraction is correct and accurate by manually discharging all
the proof obligations. Based on the abstraction, we can easily con-
ﬁrm that the suspected class invariants are indeed invariants since
all states in the abstraction satisfy them.
RQ3: Does TLV learn good predicates automatically?
We remark that this question is best answered with speciﬁc proper-
ties to be veriﬁed and speciﬁc spurious counterexamples returned
by a veriﬁcation engine. We have integrated a model checker [46]
into TLV , which makes TLV a fully automatic Java model checker
based on abstraction and reﬁnement (by learning new predicates).
In order to answer this question, we evaluate TLV’s capability of
reﬁnement in the following setting. We assume TLV is being used
to verify a Java class against a precise deterministic speciﬁcation
on when an exception occurs in the class, i.e., a ‘typestate’ [45].
Note that such a speciﬁcation often involves predicates on instance
variables. Thus, TLV is ﬁrst used to construct an abstraction with
one proposition true . The result is an abstraction containing two
states:true and⊥. Next, TLV reﬁnes the model by discovering
new predicates which would show exactly when an exception oc-
curs (and thus rules out spurious counterexamples found by verify-
ing the abstraction against the given speciﬁcation). We show that
TLV eventually ﬁnds the right predicates based on testing results
and learning.
The results are shown in Table 4 (note that not all of the classes
have a nontrivial stateful typestate). Note that for class P AYAP-
PLET , instead of state= 0 , SVM generates two predicates
state≥0andstate≤0and uses their conjunction to obtain
the same result. We remark in this setting, TLV solves the prob-
9Table 4: Statistics for automatic predicate generation
Class Time (s) Mem (MB) Predicates
BO UNDED STACK 77.5 361size≥0,size≥1024
SI GNATURE 43.0 124state≤0,s tate≤1,
state≤2
PA YAPPLET 349.4 379state≥0,s tate≤0,
size≥16,size≤16,
value+state> 1
lem of synthesizing a stateful typestate, as studied in TzuYu [49].
D
ifferent from TzuYu [49], the typestate generated by TLV is guar-
anteed to be correct (as well as accurate).
Limitations TLV has two main limitations. First, because TLV
employs symbolic execution for abstraction validation, it inherits
the limitation from symbolic execution engines, e.g., limitations
in handling programs with loops or complex data structures. We
optimistically believe that TLV (like previous approaches) would
handle larger programs with the rapid development of program ver-
iﬁcation techniques. Second, because TLV relies on random testing
to discover behaviors, the performance of TLV would suffer if the
program contains many behaviors which are hard to be explored
by random testing (in which case, TLV constructs the abstraction
solely based on symbolic execution).
5. RELATED WORK
To the best of our knowledge, TLV is the ﬁrst to combine test-
ing, learning, and validation for program abstraction. TLV is in-
spired by research on predicate abstraction [1, 9], speciﬁcation min-
ing [22, 28, 49], testing for predicate-coverage [4], etc. TLV is a
generalization of TzuYu [49], which is designed to learn a typestate
for a Java class. On one hand, TzuYu and TLV both rely on ran-
dom testing and learning to generalize models from concrete tests.
On the other hand, TzuYu learns only typestates which has only
two states (⊤ and⊥), whereas TLV can handle more predicates;
TzuYu’s learning algorithm is a direct adoption of the L* algo-
rithm, whereas TLV’s learning algorithm is designed to maximize
predicate-coverage [4]. More importantly, TzuYu provides neither
correctness nor accuracy guarantee of the typestate, whereas TLV
does.
Alur et al. [1] construct the interface speciﬁcation of a Java class
based on active learning and use a model checker as the teacher;
the Sigma* tool [9] learns the symbolic input/output relation for a
transducer program by using symbolic execution to ﬁnd new pro-
gram paths; the P SYCO tool [22] uses symbolic execution to an-
swer both membership queries and candidate queries for learning a
speciﬁcation of a class. The X-P SYCO tool [28] combines testing
and symbolic execution to learn a symbolic abstraction of program
behavior. Concrete test inputs in X-P SYCO are generated with sym-
bolic execution. Although learning is applied in TLV and these ap-
proaches, TLV is built on the idea of “test as much as we can” and
thus avoids techniques like model checking or symbolic execution
as much as possible. In addition, TLV has a clear target level of
abstraction which is often unclear in the above approaches.
The IDISCOVERY tool [50] combines dynamic invariant infer-
ence (D AIKON [20]) with symbolic execution to generate more pre-
cise invariants. Invariants generated by IDISCOVERY are not tar-
geted for a speciﬁc usage context, whereas TLV is designed to gen-
erate abstraction at certain level of abstraction for a particular us-
age context. As mentioned earlier, TLV bears a similar goal as the
TAUTOKO tool [16, 17]. Different from TAUTOKO, TLV uses
symbolic execution to discover more states and transitions and toprovide correctness guarantee. Furthermore, TLV’s abstraction is
catered for speciﬁc usages and has a targeted level of abstraction.
Existing approaches on building ﬁnite state models [7, 18, 32,
34, 36] use similar state abstraction strategies as used in TLV . The
STRAW BERRY tool [7] mines behavior protocols concerning usage
of a web service. ADABU [18] generates invariants from concrete
execution traces of Java classes with a set of ﬁxed invariant tem-
plates. ReAjax [34] uses a very similar way as ADABU to generate
the abstract model for the Document Object Model of an Ajax web
pages. KrKa et al. [32] use D AIKON to generate a set of possible
state invariants and then use SMT solvers to decide the feasibility
of possible states (combinations of invariants) and transitions in the
abstract model. Revolution [36] mines state based behavior model
for systems whose behaviors may evolve with time.
TLV uses automata learning and testing to construct the initial
abstraction. Similar ideas have been used to generate models for
legacy systems [29, 35] and bug detection [40]. They use L* to
learn Deterministic Finite Automata or Mealy Machines, whereas
the learning algorithm used in TLV learns a Non-deterministic Fi-
nite Automaton (NFA). TLV requires the source code of the class
under test to generate abstraction while some techniques [7, 21]
treat the System Under Test (SUT) as black-box, thus they use only
the external visible values for state abstraction. Ghezzi et al. [21]
use behavior equivalent model for ﬁnite data container to generate
an abstract model for a given Java class with a test suite.
L*-based learning algorithms have been applied not only to learn-
ing speciﬁcation from source code [1, 9, 22, 28, 49], but also to
model checking of programs [24] as well as security domain [12,
13]. TLV’s learning approach learns NFAs, whereas L* learns only
DFA which is limited for programs with data variables. TLV is re-
lated to work on extending the L* algorithm to learning NFA [8]
or other ﬁnite state models [6, 10, 33, 43]. Bollig et al. [8] extend
theL* to learn a non-deterministic Residual Finite State Automata
(RFSA) for a deterministic SUT. Berg et al. [6] extend L* to learn
a symbolic Mealy Machine. Shahbaz and Groz [43] introduce a
direct Mealy Machine learning algorithm which handles counterex-
amples returned by the teacher much more efﬁciently. Lorenzoli et
al.[33] propose the GK-tail algorithm to generate an Extended Fi-
nite State Automata. Cassel et al. [10] extend L* to learn symbolic
register automata with tree queries.
TLV proposes an alternative approach for predicate abstraction.
Graf and Saïdi [23] invent predicate abstraction. Ball et al. [5]
propose predicate abstraction for C programs. There are many ex-
tensions such as lazy abstraction by Henzinger et al. [27] and the
work by Arie et al. [26]. The J2BP tool [38] and its variant Ab-
stract Pathﬁnder [19, 31] are the ﬁrst to do predicate abstraction
for Java programs. All these work relies solely on SMT solvers to
compute the abstraction, whereas TLV combines testing, learning,
and validation. Lastly, TLV can be viewed as an approach to testing
Java classes for predicate-coverage [4]. Visser et al. [47] observed
that predicate-coverage is harder to achieve than block-coverage for
testing. In a way, TLV aims to provide complete predicate-coverage
by integrating testing, learning, and validation.
6. CONCLUSION
In short, we proposed an approach named TLV , which combines
testing, learning, and validation in order to automatically generate
predicate abstraction of Java classes and to automatically reﬁne the
abstraction if necessary. TLV generates accurate and correct ab-
stractions efﬁciently. As for future work, we are experimenting dif-
ferent testing strategies and machine learning algorithms to further
improve TLV’s performance.
107. REFERENCES
[
1] R. Alur, P. ˇCerný, P. Madhusudan, and W. Nam. Synthesis of
Interface Speciﬁcations for Java Classes. In POPL, pages
98–109, 2005.
[2] D. Angluin. Learning Regular Sets from Queries and
Counterexamples. Inf. Comput., 75(2):87–106, 1987.
[3] G. Bai, J. Lei, G. Meng, S. S. Venkatraman, P. Saxena,
J. Sun, Y . Liu, and J. S. Dong. AUTHSCAN: Automatic
Extraction of Web Authentication Protocols from
Implementations. In NDSS, 2013.
[4] T. Ball. A Theory of Predicate-Complete Test Coverage and
Generation. In FMCO, pages 1–22, 2004.
[5] T. Ball, R. Majumdar, T. Millstein, and S. K. Rajamani.
Automatic Predicate Abstraction of C Programs. In PLDI,
pages 203–213, 2001.
[6] T. Berg, B. Jonsson, and H. Raffelt. Regular Inference for
State Machines Using Domains with Equality Tests. In FASE,
pages 317–331, 2008.
[7] A. Bertolino, P. Inverardi, P. Pelliccione, and M. Tivoli.
Automatic Synthesis of Behavior Protocols for Composable
Web-services. In ESEC/FSE, pages 141–150, 2009.
[8] B. Bollig, P. Habermehl, C. Kern, and M. Leucker.
Angluin-style Learning of NFA. In IJCAI, pages 1004–1009,
2009.
[9] M. Botin ˇcan and D. Babi ´c. Sigma*: Symbolic Learning of
Input-output Speciﬁcations. In POPL, pages 443–456, 2013.
[10] S. Cassel, F. Howar, B. Jonsson, and B. Steffen. Learning
Extended Finite State Machines. In SEFM, pages 250–264,
2014.
[11] S. Chaki, E. M. Clarke, O. Grumberg, J. Ouaknine,
N. Sharygina, T. Touili, and H. Veith. State/Event Software
Veriﬁcation for Branching-Time Speciﬁcations. In IFM,
pages 53–69, 2005.
[12] C. Y . Cho, D. Babi ´c, E. C. R. Shin, and D. Song. Inference
and Analysis of Formal Models of Botnet Command and
Control Protocols. In CCS, pages 426–439, 2010.
[13] C. Y . Cho, D. Babic, P. Poosankam, K. Z. Chen, E. X. Wu,
and D. Song. MACE: Model-inference-Assisted Concolic
Exploration for Protocol and Vulnerability Discovery. In
USENIX Security Symposium, 2011.
[14] E. M. Clarke, O. Grumberg, S. Jha, Y . Lu, and H. Veith.
Counterexample-Guided Abstraction Reﬁnement. In CAV,
pages 154–169, 2000.
[15] E. M. Clarke, O. Grumberg, and D. A. Peled. Model
Checking. MIT Press, 1999.
[16] V . Dallmeier, N. Knopp, C. Mallon, G. Fraser, S. Hack, and
A. Zeller. Automatically Generating Test Cases for
Speciﬁcation Mining. IEEE Trans. Software Eng.,
38(2):243–257, 2012.
[17] V . Dallmeier, N. Knopp, C. Mallon, S. Hack, and A. Zeller.
Generating Test Cases for Speciﬁcation Mining. In ISSTA,
pages 85–96, 2010.
[18] V . Dallmeier, C. Lindig, A. Wasylkowski, and A. Zeller.
Mining Object Behavior with ADABU. In WODA, pages
17–24, 2006.
[19] J. Daniel, P. Parízek, and C. S. P ˘as˘areanu. Predicate
Abstraction in Java Pathﬁnder. SIGSOFT Softw. Eng. Notes ,
39(1):1–5, 2014.
[20] M. D. Ernst, J. H. Perkins, P. J. Guo, S. McCamant,
C. Pacheco, M. S. Tschantz, and C. Xiao. The DaikonSystem for Dynamic Detection of Likely Invariants. Science
of Computer Programming, 69(1-3):35–45, 2007.
[21] C. Ghezzi, A. Mocci, and M. Monga. Synthesizing
Intensional Behavior Models by Graph Transformation. In
ICSE, pages 430–440, 2009.
[22] D. Giannakopoulou, Z. Rakamari ´c, and V . Raman. Symbolic
Learning of Component Interfaces. In SAS, pages 248–264,
2012.
[23] S. Graf and H. Saïdi. Construction of Abstract State Graphs
with PVS. In CAV, pages 72–83, 1997.
[24] A. Groce, D. Peled, and M. Yannakakis. AMC: An Adaptive
Model Checker. In CAV, pages 521–525, 2002.
[25] A. Gupta and E. M. Clarke. Reconsidering CEGAR:
Learning Good Abstractions without Reﬁnement. In ICCD,
pages 591–598, 2005.
[26] A. Gurﬁnkel, S. Chaki, and S. Sapra. Efﬁcient Predicate
Abstraction of Program Summaries. In NFM, pages 131–145,
2011.
[27] T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre. Lazy
Abstraction. In POPL, pages 58–70, 2002.
[28] F. Howar, D. Giannakopoulou, and Z. Rakamari ´c. Hybrid
Learning: Interface Generation Through Static, Dynamic,
and Symbolic Analysis. In ISSTA, pages 268–279, 2013.
[29] H. Hungar, T. Margaria, and B. Steffen. Test-based Godel
Generation for Legacy Systems. In ITC, pages 150–159,
2003.
[30] IBM. Java Card Technology. http://www.oracle.
com/technetwork/java/embedded/javacard/
overview/default-1969996.html , May 2014.
[31] A. Khyzha, P. Parízek, and C. S. P ˘as˘areanu. Abstract
Pathﬁnder. SIGSOFT Softw. Eng. Notes , 37(6):1–5, 2012.
[32] I. Krka, Y . Brun, D. Popescu, J. Garcia, and N. Medvidovic.
Using Dynamic Execution Traces and Program Invariants to
Enhance Behavioral Model Inference. In ICSE, pages
179–182, 2010.
[33] D. Lorenzoli, L. Mariani, and M. Pezzè. Automatic
Generation of Software Behavioral Models. In ICSE, pages
501–510, 2008.
[34] A. Marchetto, P. Tonella, and F. Ricca. State-Based Testing
of Ajax Web Applications. In ICST, pages 121–130, 2008.
[35] T. Margaria, O. Niese, H. Raffelt, and B. Steffen. Efﬁcient
Test-based Model Generation for Legacy Reactive Systems.
InHLDVT, pages 95–100, 2004.
[36] L. Mariani, A. Marchetto, C. Nguyen, P. Tonella, and
A. Baars. Revolution: Automatic Evolution of Mined
Speciﬁcations. In ISSRE, pages 241–250, 2012.
[37] C. Pacheco, S. K. Lahiri, M. D. Ernst, and T. Ball.
Feedback-Directed Random Test Generation. In ICSE, pages
75–84, 2007.
[38] P. Parízek and O. Lhoták. Predicate Abstraction of Java
Programs with Collections. In OOPSLA, pages 75–94, 2012.
[39] C. S. P ˘as˘areanu and N. Rungta. Symbolic PathFinder:
Symbolic Execution of Java Bytecode. In ASE, pages
179–180, 2010.
[40] M. Pradel and T. R. Gross. Leveraging Test Generation and
Speciﬁcation Mining for Automated Bug Detection Without
False Positives. In ICSE, pages 288–298, 2012.
[41] C. S. P ˇasˇareanu, P. C. Mehlitz, D. H. Bushnell,
K. Gundy-Burlet, M. Lowry, S. Person, and M. Pape.
Combining Unit-level Symbolic Execution and System-level
11Concrete Execution for Testing Nasa Software. In I SSTA,
pages 15–26, 2008.
[42] B. Schölkopf, C. J. C. Burges, and A. J. Smola, editors.
Advances in Kernel Methods: Support Vector Learning. MIT
Press, 1999.
[43] M. Shahbaz and R. Groz. Inferring Mealy Machines. In FM,
pages 207–222, 2009.
[44] R. Sharma, A. V . Nori, and A. Aiken. Interpolants as
Classiﬁers. In CAV, pages 71–87, 2012.
[45] R. E. Strom and S. Yemini. Typestate: A Programming
Language Concept for Enhancing Software Reliability. IEEE
Trans. Software Eng., 12(1):157–171, 1986.
[46] J. Sun, Y . Liu, J. S. Dong, and J. Pang. PAT: Towards Flexible
Veriﬁcation under Fairness. In CAV, pages 709–714, 2009.[47] W. Visser, C. S. Pasareanu, and R. Pelánek. Test Input
Generation for Java Containers Using State Matching. In
ISSTA, pages 37–48, 2006.
[48] H. Xiao. TLV hosting site. http://bitbucket.org/
spencerxiao/tlv-fse2015 , Jan 2015.
[49] H. Xiao, J. Sun, Y . Liu, S.-W. Lin, and C. Sun. TzuYu:
Learning Stateful Typestates. In ASE 2013, pages 432–442,
2013.
[50] L. Zhang, G. Yang, N. Rungta, S. Person, and S. Khurshid.
Feedback-driven Dynamic Invariant Discovery. In ISSTA,
pages 362–372, 2014.
12