An Extensible Framework for
Variable-Precision Data-Flow Analyses in MPS
Tam√°s Szab√≥
itemis, Germany /
Delft University of Technology,
Netherlands
tamas.szabo@itemis.deSimon Alperovich
JetBrains,
Czechia
alpsm@yandex.ru
Markus Voelter
independent / itemis,
Germany
voelter@acm.orgSebastian Erdweg
Delft University of Technology,
Netherlands
s.t.erdweg@tudelft.nl
ABSTRACT
Data-ow analyses are used as part of many software engi-
neering tasks: they are the foundations of program under-
standing, refactorings and optimized code generation. Sim-
ilar to general-purpose languages (GPLs), state-of-the-art
domain-specic languages (DSLs) also require sophisticated
data-ow analyses. However, as a consequence of the dif-
ferent economies of DSL development and their typically
relatively fast evolution, the eort for developing and evolv-
ing such analyses must be lowered compared to GPLs. This
tension can be resolved with dedicated support for data-ow
analyses in language workbenches.
In this tool paper we present MPS-DF, which is the com-
ponent in the MPS language workbench that supports the
denition of data-ow analyses for DSLs. Language devel-
opers can dene data-ow graph builders declaratively as
part of a language denition and compute analysis results
eciently based on these data-ow graphs. MPS-DF is ex-
tensible such that it does not compromise the support for
language composition in MPS. Additionally, clients of MPS-
DF analyses can run the analyses with variable precision thus
trading o precision for performance. This allows clients to
tailor an analysis to a particular use case.
Demo video of MPS-DF: https://youtu.be/laNDAZCe2jM.
CCS Concepts
Software and its engineering !Automated static
analysis; Data ow languages; Integrated and visual de-
velopment environments;
Keywords
Data-ow Analysis; Domain-specic Language; Language
Workbench; Inter-procedural Analysis1. INTRODUCTION
Data-ow analysis is essential for program analysis, optimiza-
tions in compilers, integrated development environments
(IDEs) and debuggers. Fast and precise analyzers are typ-
ically designed specically for a particular programming
language and require signicant research and implementa-
tion eort [5, 6, 15]. This eort is justiable for GPLs, which
change rather slowly and where the implementation eort for
an analysis (and other compiler and IDE features) is justied
by a large user base.
Historically, most DSLs have been simple languages, requir-
ing only simple analyses (e.g., enforcement of name unique-
ness, detecting simple bug patterns or basic type checking).
However, for state-of-the-art DSLs, such as mbeddr [19],
WebDSL [17] or Polar [12], this is no longer true: sophisti-
cated analyses, similar to those in GPLs, are required.
However, the economies of DSL development are dierent:
DSLs evolve more rapidly and their user base is smaller,
making it hard to justify high development eort for lan-
guages and tools in general and for analyses in particular. To
lower this eort, we propose that language workbenches [8]
directly support the development of data-ow analyses. This
allows for the analyses to be an integral part of language
development and to evolve together with the language as it
grows in complexity.
In this tool paper we present MPS-DF, the data-ow sup-
port of the Meta Programming System (MPS).1MPS is a
language workbench for the denition of (domain-specic)
languages plus their accompanying IDEs. MPS-DF is a com-
ponent of MPS, and it supports the denition and ecient
execution of data-ow analyses. Users of MPS-DF rst dene
data-ow builders for the analyzed language. These builders
contribute subgraphs to the data-ow graph (DFG) , an inter-
mediate program representation encoding the data-ow of the
analyzed program. MPS-DF then supports dening data-ow
analyses , on the DFG, which compute some data-ow specic
knowledge (e.g. which variables are initialized) about the
program. These data-ow analyses are static program anal-
yses, which derive the knowledge without actually running
the analyzed program. Finally, existing MPS components,
such as program validators, transformations or refactorings,
make use of this knowledge.
1https://www.jetbrains.com/mps
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
ASE‚Äô16 , September 3‚Äì7, 2016, Singapore, Singapore
c2016 ACM. 978-1-4503-3845-5/16/09...$15.00
http://dx.doi.org/10.1145/2970276.2970296
870
Contributions MPS-DF has two important characteris-
tics: extensibility and variable precision. Extensibility is
motivated by the fact that MPS-based languages are extensi-
ble themselves (wrt. syntax, semantics, IDE support) [7]. It
comes in two avours: rst, builders enable extensibility of
the DFG in the face of language extensions of the analyzed
language. This means that an existing analysis immediately
works on an extended program if the concepts in the language
extension also dene builders and thus contribute subgraphs
to the DFG. The second avour of extensibility supports
augmenting the DFG for a particular analysis with custom
nodes that encode specic knowledge about the analyzed
program and potentially override an analysis result based on
that knowledge.
Variable precision considers performance trade-os: real-
time checks in the IDE must run fast, possibly compromising
on precision, whereas a more precise, but slower, analysis is
needed during compilation. We achieve the variable precision
by switching between intra -procedural analysis (within a sin-
gle function denition) and inter -procedural analysis (across
function denitions). Switching is achieved by constructing
two dierent DFGs, but running the same analyses.
We used MPS-DF in MPS itself and in projects built
with MPS to implement several data-ow analyses for C,
Java and DSLs.2For example, we built analyses to aid
developers by marking reads from uninitialized variables
and unused assignments in mbeddr C programs, while a
commercial project for insurance DSLs uses MPS-DF to
empower program understanding.
2. DATA-FLOW ANALYSIS BY EXAMPLE
In this section we illustrate the ingredients of an analysis by
developing an example uninitialized read analysis (also called
denite assignment analysis) [13]. It marks a variable read
as erroneous if the variable can not be guaranteed to have
been initialized beforehand. Our target language is mbeddr
C and its extensions [19]. mbeddr is a set of languages and
an IDE for embedded software development built with MPS.
The code in Figure 2 (A) reads sensor data if the environ-
ment is active, otherwise it logs an error message. The call
tocalibrateEnv reads the value of temp; however, the read
is marked as erroneous, because temp is initialized only in
the then branch of the preceding ifstatement; readSensor
dereferences the address of temp and assigns a value to it.
(instruction) i ::=intrajflowjinter
(intra-p.) intra ::=read ejwrite e=ejretj
nopjcode for e
(ow-s.) ow ::=label idjjump pjifjump p
tryenally eendj
(inter-p.) inter ::=map e=ejunmap ej
entry point ejcall e
(position) p ::=before ejafter ej
after label id
(id) id ::= identier
(expression) e ::= Java expression
Figure 1: Abstract syntax of the DFG builder DSL.
2.1 The Data-Ô¨Çow Graph and Its Builders
MPS is a projectional language workbench where programs
are represented as abstract syntax trees (ASTs). Each AST
node is an instance of a language concept (meta class). The
2https://szabta89.github.io/projects/df.htmlDFG is an intermediate program representation that rep-
resents data-ow information in the program as nodes (for
example, read andwrite nodes) and encodes the control ow
between the nodes as directed edges. The DFG is derived
from the AST by data-ow builders. A builder is associated
with each language concept and contributes a concept-specic
subgraph to the DFG. Builders are expressed using a DSL;
using DSLs to express a language aspect is idiomatic in MPS.
For example, there are other DSLs for dening a concept's
concrete syntax, type checking or transformations.
The DSL for builders shown in Figure 1 relies on three
groups of data-ow instructions: intra-procedural, ow-sen-
sitive and inter-procedural.
Intra-procedural instructions encode the basic data-ow
of a program. read and write indicate a read from and a
write to a variable, retmarks returns from functions and
nopis an empty operation. code for recursively calls the
builder of another AST node (e.g. the then branch of an if
statement) and inserts it's subgraph into the DFG at the
place of the code for instruction.
Each DFG node carries trace information, i.e., it has a
pointer to the AST node from which it was created. The
trace is automatically set up by the builders. For language
concepts that do not aect data ow, builders use the nop
instruction to support tracing.
Flow-sensitive instructions improve the precision of the
DFG by encoding control ow. The unconditional jump cre-
ates an edge to a DFG node. For example, C's continue
statement jumps to the start of a loop. The conditional
ifjump instruction encodes branching in the DFG. For exam-
ple, C's ifstatement can jump either to the then orelse
branch. In the DFG, label s are used to mark jump targets.
Finally, the tryinstruction encodes the data-ow associated
with exception handling.
Inter-procedural instructions help to model the data-
ow eects of function calls. An inter-procedural DFG is a
hierarchical structure which contains nested DFGs for called
functions, where nesting resembles the call stack. mappasses
information from the caller to the callee by assigning an
actual argument to a formal parameter. mapcan be imagined
as a shortcut for a read from the argument and a write
to the parameter. unmap is its counterpart which indicates
that a parameter becomes invalid because the called function
returns. Builders can contribute entry points , which mark
nodes as potential targets of calls. Finally, call is similar to
code for with one dierence: if the entry point of its called
function is present in an ancestor DFG, it creates an edge
to the entry point instead of recursively calling the builder
of the called function. This is crucial to support modeling
recursive function calls, because instead of innite nesting,
only a single edge is inserted.
Example Figure 2 (B) shows the builder of the Function-
Call language concept. The code rst iterates over the
arguments and parameters in parallel and maps the arguments
to the parameters, thus passing information from the caller
to the callee. Next, it uses the call instruction to nest the
DFG of the called function or to insert a single edge if the
call is recursive. Finally, the code inserts unmap instructions
for the parameters. The mode property is used for variable
precision and it is explained in Section 3.2.
871A
call error
call calibrateEnv
‚Ä¶nested DFG
nested DFGnested DFGcallread-Sensor
DBC
Figure 2: Ingredients of an analysis; (A) a simple C program which we statically analyze for uninitialized reads, (B)
data-ow builder of the FunctionCall concept, (C) DFG for the code snippet, and (D) the skeleton of the analysis.
Figure 2 (C) shows the DFG for the code in (A) as it is visual-
ized in MPS-DF. The DFG is hierarchical, because the func-
tion calls contribute nested DFGs. The call to readSensor
contributes instructions 3 - 11. For better readability we
collapsed the calls to error and calibrateEnv into a single
articial instruction, but in fact they also contribute a nested
DFG similar to readSensor . The branching at instruction 2
is contributed by the builder of the ifstatement.
2.2 Analysis Implementation
MPS-DF implements the classical monotone framework for
data-ow analysis [11] based on the work list algorithm. In
this framework every analysis is characterized by a lattice.
A lattice is a partially ordered structure in which every two
elements have a unique least upper bound and a unique
greatest lower bound. The work list algorithm builds on two
analysis-specic functions: funassigns a lattice element to
every instruction in the DFG, while merge is used to merge
lattice elements when control ow edges merge in the DFG.
The algorithm uses these two functions and traverses the DFG
to assign a lattice element to every node until it reaches a x
point. The x point computation is required because some
control structures (e.g. loops, jumps, recursion) contribute
cycles into the DFG, and multiple traversals of these cycles
may be required until an assigned lattice element converges.
It is the analysis developer's responsibility to dene funand
merge in a way that a x point can be reached. Certain
analysis, e.g. interval analysis [13], may require a widening
operator (a form of convergence accelerator) on the lattice
to fulll this requirement.
The funand merge functions dene how to derive the
data-ow knowledge on the DFG of the analyzed program.
This knowledge is the analysis result and technically it is a
mapping from a DFG node to an element in the analysis-
specic lattice. Other MPS components then make use of
this result; for example, validation rules create error markers,
while a transformation uses it for optimizations.
Approximation Recall that we develop static analyses
in MPS-DF. As these analyses do not execute the analyzed
programs, they use approximations to derive the analysis
result. A may analysis is one that derives information that
may possibly be true and, thus, computes an upper approx-
imation of the information that would be true during the
execution of the analyzed program. In contrast, a must anal-ysis computes information that is denitely true and derives
a lower approximation. In MPS-DF, the implementation
of the funand merge functions dene whether an analysis
is a must or a may analysis. Nevertheless, the must/may
property must be coordinated with the client which uses the
analysis result. We discuss the relevance of the must/may
property on our example analysis next.
Example Similar to builders, the data-ow analysis is also
expressed with a DSL. Figure 2 (D) shows the skeleton of
theInitializedVariables analysis. We dene its lattice as
set<node<Var>> and it encodes the set of denitely initialized
variables at a program point. The forward direction species
that the work list algorithm starts the traversal at the rst
instruction. A backward analysis, such as liveness, would
start at the last instruction. The uses part is used for
extensibility and is explained in Section 3.3. The funfunction
builds the aforementioned set of variables for every node
in the DFG. When funencounters a write instruction in
the DFG, it adds the written variable to the set because
that variable is now initialized. The merge function uses
intersection to merge lattice elements, because we develop a
must analysis.
The name of the analysis is InitializedVariables indi-
cating that it derives information about initialized variables.
The analysis is sound, because it claims that a variable is
initialized at a DFG node only if it is initialized on all ex-
ecutions paths that lead to that node. The actual error
marker in Figure 2 (A) comes from a validation rule of the
Function concept. The rule uses the must analysis result,
iterates over all reads in the function and checks whether the
read variable is initialized at the DFG node where the read
happens. This is not the case for temp, so an error marker is
placed. In contrast, a may analysis would use union yielding
an unsound result, and, in turn, the dependent validation
rule would only mark a read variable as uninitialized if it is
not initialized on any of the execution paths that lead to the
DFG node representing the read. The benet of the latter
setup would be that it produces less false positives.
3. ARCHITECTURE OF MPS-DF
In this section we present the complete architecture of MPS-
DF. We focus on the components that enable variable preci-
sion and extensibility.
872Analyzed ProgramAnalyzed LanguageExtBuildersDFGAnalysis 1ValidationRefactoringGeneratorClientsVAR-PRECEXT 2EXT 1LegendAnalysis 2Analysis nResult 1Result 2Result nAB:A is input to BAB:A produces BAB:A is instance of BAB:A uses Bset modeFigure 3: The architecture of the data-ow support in MPS. Annotations mark the components which are responsible
for extensibility ( EXT1and EXT2) and for variable precision ( VAR-PREC ).
3.1 Overview
Figure 3 shows the complete architecture of MPS-DF. Com-
ponents on the left produce data that serves as input to
components on the right. A data-ow analysis always targets
a particular language and potentially its language extensions.
Given a concrete program of the analyzed language, the
data-ow builders construct the DFG. This DFG serves as
the input to all data-ow analyses. MPS-DF evaluates the
analyses on the DFG and produces the analysis results using
the work list algorithm (Section 2.2).
Certain analyses may require the results of other analyses.
This happens in our example as well, because the uninitialized
read analysis uses the results of a prior points-to analysis to
know the possible targets of pointer typed variables. Without
this information, it can not know that readSensor indirectly
initializes temp.
There are several examples for clients of an analysis: a code
generator can use the result to apply optimizations, analysis
results can enable or prevent refactorings and validation rules
can create error markers in the IDE on program elements.
3.2 Support for Variable Precision
Variable-precision analyses are inspired by the observation
that dierent use cases of analyses require a dierent trade-
o between precision and performance. While the user edits
code in the IDE, she expects the analyses to be fast in order
to not break the coding ow; a compromise in precision
may be acceptable. However, when the same analysis is
used in the compiler, a somewhat longer execution time may
be acceptable in order to get better precision through an
exhaustive analysis.
Various precision properties (ow-sensitivity, inter-proce-
durality) can be sacriced in order to make analyses run
faster. For example, the lack of inter-procedurality means
that analyses do not know what happens in called functions
and thus must approximate the analysis results. The method
of approximation is specic to each analysis implementa-
tion and must be in coordination with the dependent clients
similar to the must/may property (Section 2.2).
Reducing precision has an immediate eect on the size
of the DFG, which in turn aects how fast the analyses
can be evaluated. In fact, the inter-procedurality yields the
largest DFG because it introduces nested DFGs for all called
functions. Based on this observation we introduced two
modes for analyses: intra and inter which are used by the
builders. We mark the builders with VAR-PREC in Figure 3
to indicate that they are the sources of variable precision.
When a builder uses the intra mode, it contributes to the less
precise intra-procedural DFG, and when it uses the inter
mode, it contributes to the more precise inter-procedural
DFG. The two kinds of builders are dened separately for a
language concept. Flow-sensitivity can be activated in both
modes, because it has only a small eect on the DFG size.Analyses consume the DFG constructed by the builders.
An analysis itself requires only minimal changes to handle the
inter mode, because only the mapandunmap inter-procedural
instructions appear explicitly in the inter-procedural DFG.
Nevertheless, builders do not contribute nested DFGs into
the DFG in the intra mode, thus an analysis does not know
what happens in the called functions. In order to mitigate this
problem, builders should introduce nopinstructions for called
functions in the intra mode. Analyses can then use these
instructions to trace back to the originating node for the call
in the AST and perform an analysis-specic approximation.
Using the DFG as an intermediate representation has the
benet that we can reuse an intra-procedural analysis and
only change its input from an intra DFG to an inter DFG
to derive inter-procedural results. Having both intra and
inter builders and adapting the analysis with a slight change
let the clients switch between the two modes and tailor the
precision of the analysis to their needs. The exact mode is
specied at the client side when the client calls MPS-DF to
obtain the results of a data-ow analysis.
Example The FuctionCall builder in Figure 2 (B) is de-
ned for the inter mode, which means that it contributes
to the inter-procedural DFG of the program. For the intra
mode we dene a builder that does not use any inter-procedural
builder instruction, but contributes a nopinstruction to make
tracing possible.
The InitializedVariables (Figure 2 (D)) analysis re-
quires only a slight change in the funfunction to support
theinter mode. Whenever it sees a map, it adds the written
variable to the set of initialized ones. If it encounters an
unmap , it simply removes the given parameter from the set
to forget about it. In the intra mode, in accordance to the
must property, the InitializedVariables analysis handles
anopinstruction which traces back to a function call by
assuming that no variable is initialized in the called function.
This preserves soundness, because we do not add any variable
to the set of initialized ones for which we can not guarantee
the initialized property.
3.3 Support for Extensibility
MPS provides extensive support for composing languages [18].
In order to not limit this support, data-ow analyses must
be extensible as well. We address this requirement with two
avours of extensibility.
Builders enable one form of extensibility ( EXT1 in Figure 3):
the DFG becomes extensible in the face of language exten-
sions. When MPS-DF constructs the DFG of a program,
it executes all builders of the involved language concepts.
As long as a language extension contains builders for their
extension concepts, these are automatically taken into ac-
count, resulting in a DFG for the program written in the
composed language. Typically, an existing analysis will also
work for programs of an extended language. This is because
873Custom InstructionsDFGInjection ruleAugmented DFGAnalysis
CBAFigure 4: Components supporting extensibility of analyses in the face of language extensions. Subgure (A) unfolds
the EXT2 annotation in Figure 3 and uses the same legend as Figure 3. Subgure (B) shows our example custom
instruction and (C) shows the example injection rule for the StatemachineVarRef concept.
the analyses are evaluated on DFGs only and it does not
matter how that DFG was built.
There is another avour of extensibility: the analyses may
require extensibility in the face of language extensions. In
other words, sometimes it is necessary to augment the DFG
with custom nodes to support a particular analysis by en-
coding domain-specic knowledge. This form of extensibility
is achieved through the combination of two components:
custom instruction and injection rule . Figure 4 (A) shows
their connection. First, an analysis developer denes a set of
custom data-ow instructions for a particular analysis. Then,
an analysis developer denes injection rules for the analysis.
A rule is similar to a builder as it also contributes nodes and
edges to the DFG for a language concept, but it can only
inject the custom instructions of its analysis. If an analysis
has injection rules, then its input is not the common DFG
anymore, which is shared by all rule-less analyses, but the
one which is augmented by its rules.
Example mbeddr C comes with a language extension for
inline denitions of state machines. It is possible to create
global variables of type state machine and, like any other
global variable, they can be referenced from C code. However,
the code generator of the state machine extension makes
sure that a state machine variable is always initialized. To
avoid false positive uninitialized read errors, we use custom
instructions in the DFG to override the analysis result.
We dene one custom instruction, defInit (Figure 4 (B)),
and organize it into a container DefOverride . The instruc-
tion points to a variable, and its presence in the DFG means
that the pointed-to variable is denitely initialized. There are
two components in the architecture which use defInit . A
rule which augments the DFG and the analysis which handles
the custom instruction in the augmented DFG. Figure 4 (C)
shows an injection rule for the StatemachineVarRef concept
and for the InitializedVariables analysis. The rule in-
jects a defInit instruction for the referenced variable of
aStatemachineVarRef . The before ref means that the
defInit is inserted just before the subgraph contributed by
the builder of the reference.
It is the responsibility of the analysis to handle the custom
instruction and indirectly let the rule override its result.
Figure 2 (D) shows that the analysis uses the DefOverride
container to access the contained custom instructions. It
handles a defInit instruction in the funfunction similar
to a write as it adds the pointed-to variable to the set of
denitely initialized variables. As there is a defInit before
every read from a state machine variable, the validation rule
will not mark any of these reads as erroneous.
4. DISCUSSION
Validation MPS-DF is in heavy use in both MPS itself
and in the mbeddr IDE to develop data-ow analyses. For
example we developed points-to, uninitialized read, livenessanalyses for mbeddr C and null analysis for Java. The
analyses implementations are available in our online material.
Additionally, language engineers (and not the developers
of MPS-DF) at the company itemis have used MPS-DF to
implement data-ow analyses in several customer projects
in the domains of embedded systems, insurance, and high
performance computing. Based on their experience and feed-
back, the data-ow analyses indeed evolve together with
the developed languages. Adding new language extensions
requires data-ow related extension as well. If the new lan-
guage constructs do not provide builders then they do not
contribute to the DFG, which will be immediately visible in
the form of false positive analysis results on the extended
program. On the other hand, due to the support for exten-
sibility, the mitigation usually ends with implementing new
builders and/or rules.
Performance We evaluated the performance3of MPS-
DF on the Toyota ITC benchmark,4a collection of C code
snippets with intentional bugs to test the precision of static
analysis tools. The code base comprises about 15,000 lines
of C code, which we imported into mbeddr. We ran the
uninitialized read analysis together with a points-to analysis
on the complete code base in both intra and inter modes.
The intra analysis requires 8.9 seconds on the complete
code base and the inter analysis needs 96.6 seconds, which
is a11x slowdown. This shows that a more precise inter
analysis requires considerably more time. The source of this
slowdown is the inlining of nested DFGs in the inter mode,
which could be mitigated by the application of summaries as
in Soot [16].
Portability to other IDEs We designed a generic ar-
chitecture for data-ow analysis that can be used in other
language workbenches as well. However, the explicit construc-
tion of the DFG may have an eect on the performance in
other workbenches. MPS-DF builds the DFG from the AST
of the analyzed program, thus the AST must be available
rst. As data-ow analyses may run frequently (even after
every code change), an up-to-date AST must be always avail-
able for the analyses. This kind of incremental maintenance
is not an issue in projectional workbenches (e.g. MPS or
Eco [4]) where the AST is always available and users directly
modify it with tree transformations. However, parser based
systems may be able to cope with this challenge only with
an incremental parser in the background (cf. the survey by
Ramalingam and Reps [14] for example incremental parsers).
Nevertheless, the requirement for the AST is not specic
to MPS-DF analyses, because program analyses are usually
carried out on the AST.
3We ran the measurements on a 64-bit OSX 10.10.3 machine
with an Intel Core i7 2.5 GHz processor and 16 GB of RAM
using Java 1.8.0 65.
4https://github.com/regehr/itc-benchmarks
8745. RELATED WORK
There are several tools which rely on relations and relational
algebra to carry out program analyses; DeFacto [1], Cro-
coPat [2] and Grok [10]. Similar to MPS-DF, these tools
also decouple the creation of an intermediate program repre-
sentation and the analysis. The program representation is
tuples of relations and these tools all come with a language
for the denition of relational operators which derive the
analysis result. All these tools are independent of the ana-
lyzed language similar to MPS-DF. Nevertheless, they were
not designed with extensibility in mind and target only one
particular language without considering language extensions.
DCFlow [9] is a DSL and Rascal library for construct-
ing control ow graphs of programs. The DSL is similar
to the ow-sensitive part of our builder DSL. However, in
DCFlow only the control ow graph is extracted as an in-
termediate representation and not the primitive data-ow
instructions (e.g. read, write), which prevents extensibility of
analyses. Handling a new kind of language concept requires
invasive changes in the analysis implementation. In contrast,
MPS-DF only requires a new builder implementation and no
modications to the analyses.
Bodden et al. extend the Soot [16] framework to support
inter-procedural data-ow analyses [3]. Compared to our
solution of nesting the DFG of a called function, they use
summaries: instead of reanalyzing a function for all call
sites, a summary is computed once to capture the eects of a
function and it is applied and reused for all callers. This could
lead to great performance improvements for large programs.
From the user perspective the tool is programmable through
Java APIs and it can analyze only Java programs. In contrast,
MPS-DF supports variable-precision data-ow analyses and
it is independent of the analyzed language.
6. CONCLUSIONS
We presented MPS-DF which is the data-ow support in
MPS. It denes a builder DSL for the construction of variable-
precision DFGs and an analysis DSL for the denition of data-
ow analyses. Additionally, MPS-DF analyses are extensible
in the face of language extensions of the analyzed language.
We found MPS-DF useful in several open-source and com-
mercial projects centered around DSLs for embedded systems,
insurance and high performance computing. MPS-DF consti-
tutes an integral part of the MPS language workbench and
it is available open-source.
7. REFERENCES
[1] H. J. Basten and P. Klint. Defacto:
Language-parametric fact extraction from source code.
InSoftware Language Engineering . Springer-Verlag,
2009.
[2] D. Beyer. Relational programming with crocopat. In
Proceedings of the International Conference on
Software Engineering . ACM, 2006.
[3] E. Bodden. Inter-procedural data-ow analysis with
ifds/ide and soot. In Proceedings of the International
Workshop on State of the Art in Java Program Analysis .
ACM, 2012.
[4] L. Diekmann and L. Tratt. Eco: A Language
Composition Editor . Springer International Publishing,
2014.[5] J. Dietrich, N. Hollingum, and B. Scholz. Giga-scale
Exhaustive Points-to Analysis for Java in Under a
Minute. In Proceedings of the International Conference
on Object-Oriented Programming, Systems, Languages,
and Applications . ACM, 2015.
[6] M. Emami, R. Ghiya, and L. J. Hendren.
Context-sensitive Interprocedural Points-to Analysis in
the Presence of Function Pointers. In Proceedings of the
Conference on Programming Language Design and
Implementation . ACM, 1994.
[7] S. Erdweg, P. G. Giarrusso, and T. Rendel. Language
Composition Untangled. In Proceedings of the Twelfth
Workshop on Language Descriptions, Tools, and
Applications . ACM, 2012.
[8] S. Erdweg, T. van der Storm, M. V olter, L. Tratt,
R. Bosman, W. R. Cook, A. Gerritsen, A. Hulshout,
S. Kelly, A. Loh, G. Konat, P. J. Molina, M. Palatnik,
R. Pohjonen, E. Schindler, K. Schindler, R. Solmi,
V. Vergu, E. Visser, K. van der Vlist, G. Wachsmuth,
and J. van der Woning. Evaluating and comparing
language workbenches. Comput. Lang. Syst. Struct. ,
2015.
[9] M. Hills. Streamlining Control Flow Graph
Construction with DCFlow. In Software Language
Engineering . Springer International Publishing, 2014.
[10] R. C. Holt. Binary relational algebra applied to
software architecture. Computer Systems Research
Institute , 1996.
[11] G. A. Kildall. A Unied Approach to Global Program
Optimization. In Proceedings of the Symposium on
Principles of Programming Languages . ACM, 1973.
[12] J. K arna, J.-P. Tolvanen, and S. Kelly. Evaluating the
use of domain-specic modeling in practice. In
Workshop on Domain-Specic Modeling (DSM) . 2009.
[13]F. Nielson, H. R. Nielson, and C. Hankin. Principles of
Program Analysis . Springer-Verlag New York, Inc.,
1999.
[14] G. Ramalingam and T. Reps. A Categorized
Bibliography on Incremental Computation. In
Proceedings of the Symposium on Principles of
Programming Languages . ACM, 1993.
[15] M. Sridharan and R. Bod k. Renement-based
Context-sensitive Points-to Analysis for Java. In
Proceedings of the Conference on Programming
Language Design and Implementation . ACM, 2006.
[16] R. Vall ee-Rai, P. Co, E. Gagnon, L. Hendren, P. Lam,
and V. Sundaresan. Soot - a Java Bytecode
Optimization Framework. In Proceedings of the
Conference of the Centre for Advanced Studies on
Collaborative Research . IBM Press, 1999.
[17] E. Visser. Webdsl: A case study in domain-specic
language engineering. In Generative and
Transformational Techniques in Software Engineering
II. Springer-Verlag, 2008.
[18] M. Voelter. Language and IDE Modularization and
Composition with MPS . Springer Berlin Heidelberg,
2013.
[19]M. Voelter, D. Ratiu, B. Kolb, and B. Schaetz. mbeddr:
Instantiating a language workbench in the embedded
software domain. Automated Software Engineering ,
2013.
875