Test Case Permutation to Improve Execution Time
Panagiotis Stratis
School of Informatics
University of Edinburgh, UK
s1329012@sms.ed.ac.ukAjitha Rajan
School of Informatics
University of Edinburgh, UK
arajan@staffmail.ed.ac.uk
ABSTRACT
With the growing complexity of software, the number of test
cases needed for eective validation is extremely large. Ex-
ecuting these large test suites is expensive, both in terms
of time and energy. Cache misses are known to be one of
the main factors contributing to execution time of a soft-
ware. Cache misses are reduced by increasing the locality
of memory references. For a single program run, compiler
optimisations help improve data locality and code layout
optimisations help improve spatial locality of instructions.
Nevertheless, cache locality optimisations have not been pro-
posed and explored across several program runs, which is the
case when we run several test cases.
In this paper, we propose and evaluate a novel approach
toimprove instruction locality across test case runs . Our ap-
proach measures the distance between test case runs (num-
ber of dierent instructions). We then permute the test
cases for execution so that the distance between neighbor-
ing test cases is minimised. We hypothesize that test cases
executed in this new order for improved instruction locality
will reduce time consumed.
We conduct a preliminary evaluation with four subject
programs and test suites from the SIR repository to answer
the following questions, 1. Is execution time of a test suite
aected by the order in which test cases are executed? and
2. How does time consumed in executing our permutation
compare to random test case permutations? We found that
the order in which test cases are executed has a denite im-
pact on execution time. The extent of impact varies, based
on program characteristics and test cases. Our approach
outperformed more than 97% of random test case permu-
tations on 3 of the 4 subject programs and did better than
93% of the random orderings on the remaining subject pro-
gram. Using the optimised permutation, we saw a maximum
reduction of 7.4% over average random permutation execu-
tion time and 34.7% over the worst permutation.
CCS Concepts
Software and its engineering !Software testing
and debugging;Keywords
Cache misses, Instruction locality
1. INTRODUCTION
The number of tests needed to eectively test any non-
trivial software is extremely large. With the prevalence of
software in today's world and the growing complexity of sys-
tems, this number is rapidly becoming intractable. Much of
the research in software testing over the last few decades
has focussed on test suite1reduction techniques and crite-
ria (such as coverage) that help in identifying the eective
test cases to retain. This trend is particularly seen in regres-
sion testing and black-box testing where numerous optimiza-
tion techniques{test case selection, test suite reduction, and
test case prioritization{have been proposed to reduce testing
time [23, 19, 16]. Even after using these test optimisation
techniques, test suites continue to be very large and their
execution is typically very time consuming. The high-level
goal we target in this paper is,
Reduce time consumed by test suite runs.
Execution time for present day programs is memory speed
rather than processor speed bounded. Missed cache hits,
on both the internal and external cache, signicantly slow
down the execution of a program [20, 21]. Powerful cache
optimizations are needed to improve the cache behavior and
increase the execution speed of these programs. Based on
this observation, we target the problem of reducing cache
misses caused by test case runs.
Cache misses are reduced by increasing the locality of
memory references [7], for both data and instructions. Com-
piler researchers proposed loop tranformation techniques such
as loop tiling and fusion to improve data locality [3, 4, 1].
To enhance instruction locality, researchers proposed proce-
dure orderings and code layout optimisations [17, 10, 5] to
improve spatial locality of instructions.
Existing literature has only considered improving
data/instruction locality over single program runs. Enhanc-
ing locality across program runs is entirely novel. We re-
phrase the earlier problem in terms of locality as, improve
locality of references across test case runs .
In this paper, we target this locality problem in the con-
text of testing. In program testing, we execute the same pro-
gram several times (albeit with a dierent test data) increas-
ing the chances of seeing repeated instruction sequences. We
believe the knowledge of common instruction sequences be-
tween test cases can be used to help improve the perfor-
mance of the instruction cache and, potentially, the pro-
gram. We propose a novel approach based on this to im-
prove instruction locality across test case runs. We permute
1A test suite is a collection of test cases that test a program.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation
on the Ô¨Årst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciÔ¨Åc permission and/or a
fee. Request permissions from Permissions@acm.org.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ASE‚Äô16 , September 3‚Äì7, 2016, Singapore, Singapore
ACM. 978-1-4503-3845-5/16/09...$15.00
http://dx.doi.org/10.1145/2970276.2970331
45
the test cases so that distance between neighboring test case
runs is minimised. Distance is measured as number of dif-
ferent instructions between test runs. Our approach and
algorithm for permuting test cases is discussed in Section 3.
The proposed idea for leveraging instruction cache locality
in the context of test executions is entirely novel. However,
the eect of test case permutations and improving instruc-
tion cache locality on execution time is not well understood
or even known. We conduct a preliminary evaluation to
rst assess the impact of test case permutation on execu-
tion time using randomly generated permutations of a test
suite. We used 4 subject programs and test workloads from
the SIR repository. We also evaluated the usefulness of our
approach in addressing the high-level goal by comparing ex-
ecution time of our optimised permutation against average,
best and worst execution times of the random permutations.
Our experiments revealed that the order in which test cases
are executed has an impact on execution time. The magni-
tude of the eect varied greatly and was dependent on pro-
gram and test suite characteristics. We also found that our
optimised permutation outperformed a signicant propor-
tion of random permutations in all subject programs. The
reduction in execution time was in the range of 1.4% to 7.4%
over average random permutation, and 13.8% to 34.7% over
the worst permutation.
The rest of our paper is organised as follows. We provide
background on cache misses and existing compiler technqi-
ues to improve locality in Section 2. We describe the steps
in our algorithm and our implementation in Section 3. The
experiment for evaluating our approach is described in Sec-
tion 4. Results and their analysis is presented in Section 5.
2. BACKGROUND AND RELATED WORK
Today's computer systems must manage a vast amount
of memory to meet the data requirements of modern appli-
cations. Practically, all memory systems are organised as a
hierarchy with multiple layers of fast cache memory. CPU
caches comprise of an instruction cache to speed up exe-
cutable instruction fetch, and a data cache to speed up data
fetch and store. Caches play a key role in minimizing the
data access latency and main memory bandwidth demand.
Caches operate by retaining the most recently used data. If
the processor reuses the data quickly, cache hits occur. Con-
versely, if it reuses the data after a long time, intervening
data can evict the data from the cache, resulting in a cache
miss. Cache misses cause the CPU to stall and in many ap-
plications result in signicant penalty in execution time [20,
21].
Cache misses are reduced by increasing the locality of
memory references. Temporal locality refers to memory ac-
cesses that are close in time, i.e. the reuse of a specic
data within a relatively small time duration. Spatial local-
ityrefers to memory accesses close to each other in storage
locations. Modern cache designs exploit spatial locality by
fetching large blocks of data called cache lines on a cache
miss. Subsequent references to words within the same cache
line result in cache hits. In the following paragraphs, we
present existing literature for optimising temporal and spa-
tial locality of data references (for data cache) and instruc-
tion references (for instruction cache).
Compiler researchers have proposed the use of reuse dis-
tance as a metric to approximate cache misses [2, 15]. Beyls
et al. state reuse distance of a memory access as\the number
of accesses to unique addresses made since the last reference
to the requested data". In a fully associative cache with n
lines, a reference with reuse distance d < n will hit, and
with dnwill miss. The concept of cache re-use has
primarily been used in the context of data locality.
Single program execution
Existing 
optimisations
to improve localityMulitple program executions
Our approach 
to improve 
locality
Existing Literature Our ContributionFigure 1: Existing work versus Our Contribution
In the early 1990s, compiler optimisations were proposed
to improve the cost of executing loops [22, 4]. These optimi-
sations improve locality of data references in loops through,
Loop Permutations: changing the sequence of loop iter-
ations such that the iteration that promotes the most data
reuse is positioned innermost (if it is legal).
Loop Tiling: reordering iterations such that iterations
from outer loops are executed before completing all the it-
erations of the inner loop. Tiling reduces the number of
intervening iterations and thus data fetched between data
reuses [22].
Loop Fusion: takes multiple loops and combines their bod-
ies into one loop nest.
Loop Distribution: separates independent statements in
a single loop into multiple loops with single headers.
Variable padding: Inter-variable padding that adjusts
variable base addresses, and intra-variable padding that
modies array dimension sizes have been proposed to elim-
inate conict misses occuring in loop iteratons [18].
Data reference predictors and prefetchers have also been pro-
posed to improve locality and hide memory latency resulting
from cache misses [12, 11, 6].
To improve spatial locality of instructions, existing liter-
ature has explored procedure re-orderings and code layout
optimisations. Hwu et al. use dynamic proling, and func-
tion inlining for instruction placement that maximises se-
quential and spatial locality [10]. Chen et al. and Ramirez
et al. achieve spatial locality by co-locating procedures or
basic blocks that are activated sequentially [5, 17].
Temporal locality of instructions has not been considered
before, especially since existing optimisations are over a sin-
gle execution of the program with little chance of repeated
instruction sequences2. Figure 1 illustrates the dierence
between existing work and our approach. Our approach tar-
gets optimisation of temporal locality of instructions across
several executions of the program. Our approach presented
in Section 3 is not meant to compete with the existing work
on compiler or code layout optimisation. Instead, it is best
if they are used together since we aim to improve temporal
locality of instructions across several executions, while ex-
isting work improves temporal/spatial locality of data and
spatial locality of instructions within a single execution.
Related work in the eld of software testing has proposed
numerous optimization techniques{test case selection, test
suite reduction, and test case prioritization{to reduce size of
test suite and, as an additional benet, execution time [23,
19]. The goal of our approach is not to optimise sizeof test
suite but rather test suite permutation to reduce execution
time. We can apply our approach to an already minimised
test suite to reduce time consumed further. If testers believe
that test minimisation or reduction techniques will result in
reduced fault nding capability [9], our approach can be
applied directly to the the full test suites. The following
section describes our approach.
2Unless the instructions occur within a for loop, in which
case existing loop transformations help improve locality.
463. OUR APPROACH
To maximise temporal re-use of instructions across sev-
eral executions of the program (or test case runs), we need
to determine an order of test case executions such that dis-
tance between consecutive test case executions in the order
is minimized while also minimizing the total distance of the
order. Note that it is important to minimise the total dis-
tance additionally, since that helps pick the best among all
orders that have minimal distance between consecutive test
case executions, each of which is produced by a dierent
starting vertex or test case execution in our case. This is
similar to the problem of least cost Hamiltonian Path which
is known to be NP-hard. In our approach, we use the near-
est neighbour algorithm as an approximate solution since it
eectively solves the sub-problem of minimising distance be-
tween consecutive test case executions that is important for
leveraging immediate temporal locality. Distance between
two test cases, TiandTj, is dened as
D(Ti; Tj) =#instructions dierent between TiandTj(1)
The rationale for this denition of distance is that instruc-
tion locality between test runs is greater when there are
more common instructions between them (or fewer dierent
instructions). For instance, let's say for test runs T1 and T2,
30% of their instructions were the same, and for T1 and T3,
65% of the instructions were the same. Then, we improve
the chances of re-visiting the same instructions between two
test runs if we place T1 next to T3, rather than T2, in the
order of test execution.
To enable scalability, we use basic blocks instead of in-
structions to compute distance in Equation 1. D(Ti; Tj) is
the symmetric dierence between the set of basic blocks vis-
ited by TiandTj. Note that, D(Ti; Tj) =D(Tj; Ti) in our
denition. In our implementation we express the distance
as a fraction of the total number of basic blocks visited by
all test cases3, i.e.
D(Ti; Tj) =#basic-blocks dierent between TiandTj
Total #basic-blocks visited by all tests(2)
As stated earlier, our approach to solve the distance minimi-
sation problem is based on the nearest neighbour algorithm.
For a sequence with Ntest case runs and Tpbeing a test
case run at position p, our approach re-orders (or permutes)
the sequence such that,
D(Ti; Ti+1)<=D(Ti; Tj);
where j > i + 1 and i2f1; :::;(N 2)g(3)
The condition in Equation 3 states that for a test case run
at position i,Ti, the next test case run in the permuted se-
quence, Ti+1, should be the one that has the least distance
toTiamong the test case runs that have not yet been vis-
ited (or permuted). Our algorithm is illustrated in Table 1.
We provide as inputs Ntest cases in some given sequence
with Tibeing test case at position i. We also provide an
input thresold distance, Thr, so that test case runs who
are within Thr distance of each other will be considered
neighbours and used in the nearest neighbour computation.
Test cases whose distance exceeds Thr are not considered
neighbours and will be examined for ordering only after all
the neighbours are visited. Thr is a function of cache size
and program size and is used as an indicator of the dis-
tance limit beyond which immediate temporal locality be-
tween test cases cannot be improved by ordering4. This in
3This is done so that distances can be compared against a
threshold dened subsequently.
4Thr= 1 - (Average #instructions across test runs / Cache
size in instructions) if (program size <cache size). Else, Thr
is median of minimum and maximum distance observed in
the distance matrix.turn helps save computation eort and time by not having to
consider test cases that exceed Thrin the nearest neighbour
computation.
Our algorithm shown in Table 1 computes the distances
between all test cases and stores them in a distance matrix.
The heuristic we use to pick the starting test case run in
our execution order is the one with most unvisited neigh-
bours. We set this to current test case and mark it with
a visited ag. We then check if the current test case has
unvisited neighbours and pick the one that is closest. This
becomes the new visited current and the process is repeated
with neighbours. If there are no unvisited neighbours, and
we still have test cases that are not visited, we pick a new
current test case in the same way as we picked the starting
test case in the beginning and repeat the process with neigh-
bours. This na ve greedy algorithm for ordering test cases
using nearest neighbour has a complexity O(N2), where N
is the number of test cases. In our future work, we plan to
reduce complexity in creating the ordering using approxima-
tion algorithms.
3.1 Implementation
For achieving step 1 of the algorithm in Table 1 we use
Intel's Pin [14], a dynamic binary instrumentation frame-
work which allows the development of analysis tools (com-
monly refered to as Pintools). We implemented our Pintool
to record the basic blocks visited for every test case execu-
tion. The remaining steps 2 to 10 of the algorithm to gen-
erate the permuted sequences of test cases are implemented
in C++11 and LLVM passes [13]. Given a C/C++ pro-
gram and test cases, our implementation will execute each
test case independently and dynamically analyse it with the
Pintool. Each test case is mapped to a set of visited basic
blocks, which is then used to compute the distance between
test cases and to build the distance matrix. Finally, we use
the distance matrix to generate the optimised permutation
sequence. In the next section, we present the questions eval-
uated in our experiment along with a description of tools and
subject programs used for our measurements.
4. EXPERIMENT
Table 2: Subject programs used in our experiment
Subject Size (Avg. Exec. Instrucs.) #Test Cases
replace 1.28e+04 5542
sed 5.36e+06 358
tcas 2.23e+02 1608
totinfo 1.89e+04 1052
In this paper, we only present a preliminary evaluation with
a small number of programs. We plan to undertake an exten-
sive evaluation of our approach with a large set of programs
and test suites in our future work. The questions we seek to
answer in our preliminary evaluation are,
Q 1. Is time taken for test suite execution aected by the
order in which test cases are executed?
To answer this question, for each subject program and
associated set of test cases, we rst randomly permute the
sequence of test cases. We perform 2000 such random
permutations6and measure time taken for execution. The
distribution of time measurements gives an estimate of the
eect of test case ordering. The eect of permuting test
cases is hard to predict and can vary widely among programs
(and their test cases) based on their characteristics (such as
6Time needed in running the experiments was a severe lim-
iting factor for signicantly larger number of permutations.
47Table 1: Algorithm for permuting sequence of test cases for improved temporal locality
Algorithm Permute Sequence of Test Case Runs
Input: Ntest cases, Pprogram,
Thr dening cuto distance between test cases to be neighbours.
Output: ListRwith the permuted sequence of N test cases.
begin
1: For 1iN, run each test case, Ti, onPand record the set of basic blocks visited, fBTig.
2: Mark all test case runs as not visited (or unvisited). Initialise Rto be an empty list
3:8i; j2f1; Ng, build a distance matrix of TitoTj, such that D(Ti; Tj) =fBTig 4 f BTjg.
4: From the distance matrix, select a starting Tas the one that is not visited and has most5unvisited neighbours
(i.e.distanceThr).
5: Set this to current T, mark as visited, and insert it into the end of list R.
6: Ifcurrent Thas no unvisited neighbours, go to Step 9.
7: Pick the neighbour that is not visited and has least distance from current T.
8: Go to Step 5.
9: If there are unvisited test case runs in matrix D, go to Step 4.
10: Output Ras the permuted sequence of test cases.
end
control ow, memory references, computations, number of
instructions).
Q 2. How does time consumed by our optimised permutation
compare to random test case permutations?
We measure the time consumed by executing test cases in
the permuted sequence produced by our algorithm (referred
to as optimised permutation ). We compare it to the mean
time consumed and the distribution of the random permu-
tations measured in Q1. We also use the best and worst
case times of the random permutations in our comparison.
4.1 Measurement
We run our experiments using a desktop computer pow-
ered by an Intel Core 2 Duo E8400 processor at 3 GHz,
32KB of Instruction Cache, and 32 KB of L1 Data Cache.
The machine runs Ubuntu Server 14.04 with Linux kernel
3.16.0.33. We ensure no additional services are running on
the server edition of Ubuntu when we perform measure-
ments. We measure execution time of our algorithm and
program test case runs using a system clock function in-
cluded in the std::chrono library in C++11.
4.2 Subject Programs
We use 4 programs from the SIR repository [8] for our
experiment. Programs include pattern matching and sub-
stitution ( replace ), stream text editor ( sed), a statistics
program ( totinfo ), and an aircraft collision avoidance sys-
tem ( tcas). The subject programs have between 358 and
5542 test cases. Program execution size (reported as aver-
age number of executed instructions across all test cases)
and number of test cases for the programs used in our ex-
periment is shown in Table 2.
For the subject programs, each test permutation is exe-
cuted multiple times in our measurement.7This is done so
that we report the execution time of all programs on a com-
parable scale in seconds. Executing the test permutation
multiple times simply scales the execution time and has no
eect on the interpretation of the results and the impact of
permutations reported. The results from our experiments
and their analyses is presented in the next Section.
7Fortcas, each test permutation is run 1000 times. 100
times for replace, sed, totinfo .5. RESULTS AND ANALYSIS
5.1 Q1 Analysis
We ran 2000 random permutations of test cases, measur-
ing execution time of each permutation, for each of the four
SIR programs. Table 3 shows, for each subject program,
the histogram frequencies of execution times for the 2000
random permutations using a frequency polygon. The mean
execution time across permutations is shown as a dashed red
vertical line. The execution time of the optimised permu-
tation generated by our algorithm is shown as a green line.
The shaded area under the curve to the left of the green line
represents the percentage of random permutations that ex-
ecute faster than our optimised version. Table 4 shows the
median8, best and worst execution times in the distribution
over random permutations. We also show our optimized
permutation time for easy comparison. We do not show
standard deviation, since we found that the execution times
for all subject programs over the random test permutations
were not normally distributed . We conrmed this by run-
ning a chi-squared goodness of t test, and the p-values for
all programs was 0 (rejecting the null hypothesis that they
are normally distributed at 5% signicance level).
It can be seen from the plots in Table 3 that execution
times clearly vary across test permutations. The extent to
which execution times vary is dierent for each program and
associated tests. For instance, in program sed, execution
times are symmetrically distributed. The execution times
for the random permutations lie close to the mean for sed.
We believe this is because the size of a single test execution
over sedexceeds the L1 instruction cache size. Thus permu-
tations will have limited eect on instruction locality across
test executions, or execution time as a result of that, at the
L1 level. They may, however, still have an eect on the
L2 level cache. Distribution of execution times in the other
subject programs are positively skewed with long tail ends
on the right. This is especially prominent for the programs -
tcas, replace . The dierences between the best and worst
permutation execution times were 57.1% and 44.3%, respec-
tively. We believe the large dierence is because test case
distances were distributed over a wide range for these two
programs. Test suites for these programs were such that
there were clusters of test cases with low distances within
the cluster, i.e. they execute similar control ow paths. Dis-
tances between test cases across clusters were high. As a re-
sult, random permutations that change the ordering of test
cases within a cluster will have little eect on the instruction
8The median and mean for all subject programs were the
same numerically up to the second decimal place. As a re-
sult, we only use one of them, mean, in our comparisons.
48Table 3: Histogram frequencies of execution time for random permutations for 4 SIR programs (optimised
permutation is also shown)
locality. On the other hand, permutations that changed the
order across clusters will have a negative eect on instruc-
tion locality. The size and number of clusters will determine
the size of eect.
Q1 Answer.
It is clear from the plots in Tables 3 that the order in which
test cases are executed aects execution time . The nature
of the program and test cases, in terms of size of a single
test execution and the range of distances between test cases,
determine the magnitude of the eect. The dierences be-
tween worst and best permutation execution times ranged
from 18.3% to 57.1% across our subject programs.
Table 4: Statistics on execution time (in secs) distri-
bution compared with optimised permutation (Opt.)
Subject Median Worst Best Opt.
replace 2.03 2.64 1.83 1.88
sed 2.58 2.81 2.35 2.41
tcas 4.39 6.63 4.22 4.33
totinfo 2.67 2.97 2.51 2.56
5.2 Q2 Analysis
The green vertical line in the plots in Tables 3 shows the
execution time of our optimised permutation. It is worth
noting that we took 100 measurements of the execution time
of our optimised permutation for each program. The mea-
surements were only marginally dierent (same numerically
up to the third decimal place) and as a result, we only show
a vertical line in the plots. The 'Opt.' column in Table 4shows the average over these 100 time measurements of the
optimised permutation. As stated earlier, the shaded area
in the plots represents the percentage of random permuta-
tions that execute faster than our optimised version. The
optimised permutation does better than 97% of the random
permutations on 3 of the 4 subject programs, replace, sed,
totinfo . For tcas, we outperformed 93% of the random
permutations. As observed earlier, test suites for the sub-
ject programs have clusters of test cases with low distances
within, and high distances across clusters. Our approach
for permutation ensures that test cases in clusters are exe-
cuted together, eectively leveraging the instruction locality
between them. We believe this is the primary reason for
outperforming such a large majority of the random permu-
tations. The sizes of these programs and numbers of test
cases vary widely, as seen from Table 2. The improvement
over average random permutation execution time was in the
range of 1.4% to 7.4% for these programs. The improve-
ment over the worst permutation was signicant, ranging
from 13.8% to 34.7%. The best permutation was compara-
ble to our optimised permutation and was faster by a small
margin, 1.9% to 2.6%.
Q2 Answer.
We found that our optimised permutation outperformed
a signicant fraction (more than 93%) of random permuta-
tions over all subject programs. The gain in execution time
varied across programs. It was in the range of 1.4% to 7.4%
over average, and 13.8% to 34.7% over worst permutation.
496. CONCLUSION AND FUTURE WORK
We proposed an approach for reducing time consumed
during the execution of a test suite by permuting test cases
for improved instruction locality. The idea in this paper of
optimising locality of references across program runs, rather
than just a single run is entirely novel. The approach we
use to improve instruction locality, aims to minimise the
distance between neighbouring test cases in the execution
order. Distance is measured as the number of dierent in-
structions executed between two test cases. We use a greedy
approximation algorithm for permuting the test cases based
on their distance.
We conducted a preliminary evaluation using four subject
programs from the SIR repository. We used 2000 random
permutations of the test suite in each of four subject pro-
grams. The results in our experiment showed that the order
of test case execution matters for execution time. The dif-
ferences between worst and best permutation running time
ranged from 18.3% to 57.1%, across our subject programs.
Our optimised permutation outperformed a signicant frac-
tion of random permutations over all subject programs. The
gain in execution time varied across programs. It was in the
range of 1.4% to 7.4% over average, and 13.8% to 34.7% over
worst permutation. As with compiler optimisation tech-
niques, the eectiveness of our approach depends on the
characteristics of the program and test cases. Size of the
program, distances between test case runs, number of test
cases, cache size, will all have a signicant eect on the time
savings from our approach.
The initial experiment in this paper provides evidence
that, (1)Test case execution order is important to consider
for execution time, and (2)Improving instruction locality
across test case executions helps improve execution time.
These two observations are the main contributions in this
paper. We are aware that there may exist better algorithms
to generate an optimised permutation than the one used
in this paper. We will explore these along with scalability
challenges, with respect to program size (that exceeds cache
size) and number of test cases, in our future work. Once we
address the scaling challenges with respect to program size
and number of tests, we will explore large applications from
dierent domains with nightly (or some frequent periodic)
test suite runs.
7. REFERENCES
[1] Polly LLVM library. http://polly.llvm.org/index.html.
[2] Kristof Beyls and Erik D'Hollander. Reuse distance as
a metric for cache behavior. In Proc. of the IASTED
Conf. on Parallel and Distributed Computing and
Systems , volume 14, pages 350{360, 2001.
[3] Kristof Beyls and Erik D'Hollander. Refactoring for
data locality. Computer , 42(2):62{71, 2009.
[4] Steve Carr, Kathryn S McKinley, and Chau-Wen
Tseng. Compiler optimizations for improving data
locality , volume 28. ACM, 1994.
[5] J Bradley Chen and Bradley DD Leupen. Improving
instruction locality with just-in-time code layout. In
Proceedings of the USENIX Windows NT Workshop ,
pages 25{32, 1997.
[6] Tien-Fu Chen and Jean-Loup Baer. Eective
hardware-based data prefetching for high-performance
processors. Computers, IEEE Transactions on ,
44(5):609{623, 1995.
[7] Peter J Denning. The locality principle.
Communications of the ACM , 48(7):19{24, 2005.
[8] Hyunsook Do, Sebastian G. Elbaum, and Gregg
Rothermel. Supporting controlled experimentationwith testing techniques: An infrastructure and its
potential impact. Empirical Software Engineering: An
International Journal , 10(4):405{435, 2005.
[9] Mats PE Heimdahl and Devaraj George. Test-suite
reduction for model based tests: Eects on test
quality and implications for testing. In Proceedings of
the 19th IEEE international conference on Automated
software engineering , pages 176{185, 2004.
[10] W-m W Hwu and Pohua P Chang. Achieving high
instruction cache performance with an optimizing
compiler. In ACM SIGARCH Computer Architecture
News , volume 17, pages 242{251. ACM, 1989.
[11] Teresa L Johnson, Matthew C Merten, and
Wen-Mei W Hwu. Run-time spatial locality detection
and optimization. In Proceedings of the 30th annual
ACM/IEEE international symposium on
Microarchitecture , pages 57{64, 1997.
[12] Sanjeev Kumar and Christopher Wilkerson.
Exploiting spatial locality in data caches using spatial
footprints. In ACM SIGARCH Computer Architecture
News , volume 26, pages 357{368. IEEE Computer
Society, 1998.
[13] Chris Lattner and Vikram Adve. Llvm: A compilation
framework for lifelong program analysis &
transformation. In Code Generation and Optimization,
2004. CGO 2004. International Symposium on , pages
75{86. IEEE, 2004.
[14] C. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser,
G. Lowney, S. Wallace, V. Reddi, and K. Hazelwood.
Pin: building customized program analysis tools with
dynamic instrumentation. In ACM Sigplan Notices ,
volume 40, pages 190{200. ACM, 2005.
[15] C. Pyo, K. Lee, H. Han, and G. Lee. Reference
distance as a metric for data locality. In High
Performance Computing on the Information
Superhighway, 1997. HPC Asia'97 , pages 151{156.
IEEE, 1997.
[16] Ajitha Rajan. Coverage metrics to measure adequacy
of black-box test suites. In 21st ASE , pages 335{338.
IEEE, 2006.
[17] A. Ramirez, L. Barroso, K. Gharachorloo, R. Cohn,
J. Larriba-Pey, G. Lowney, and M. Valero. Code
layout optimizations for transaction processing
workloads. In ACM SIGARCH Computer Architecture
News , volume 29, pages 155{164. ACM, 2001.
[18] Gabriel Rivera and Chau-Wen Tseng. Data
transformations for eliminating conict misses. In
ACM SIGPLAN Notices , volume 33, pages 38{49.
ACM, 1998.
[19] Patrick J. Schroeder and Bogdan Korel. Black-box
test reduction using input-output analysis. In ISSTA ,
pages 173{177. ACM, 2000.
[20] V. Tiwari, S. Malik, A. Wolfe, and M.T.-C. Lee.
Instruction level power analysis and optimization of
software. In VLSI Design, 1996. Proceedings., Ninth
International Conference on , pages 326{328, Jan 1996.
[21] N. Vijaykrishnan, M. Kandemir, M.J. Irwin, H.S.
Kim, and W. Ye. Energy-driven integrated
hardware-software optimizations using simplepower. In
Computer Architecture, 2000. Proceedings of the 27th
International Symposium on , pages 95{106, June 2000.
[22] Michael E Wolf and Monica S Lam. A data locality
optimizing algorithm. In ACM Sigplan Notices ,
volume 26, pages 30{44. ACM, 1991.
[23] Shin Yoo and Mark Harman. Regression testing
minimization, selection and prioritization: a survey.
22(2):67{120, 2012.
50