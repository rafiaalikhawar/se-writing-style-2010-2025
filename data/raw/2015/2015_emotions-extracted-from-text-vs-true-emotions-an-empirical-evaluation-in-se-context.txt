Emotions Extracted from Text vs. True
Emotions‚ÄìAn Empirical Evaluation in SE Context
Yi Wang
Rochester Institute of Technology, 134 Lomb Memorial Dr. Rochster, NY 14623
wang@cocolabs.org
Abstract ‚ÄîEmotion awareness research in SE context has been
growing in recent years. Currently, researchers often rely on
textual communication records to extract emotion states using
natural language processing techniques. However, how well these
extracted emotion states reÔ¨Çect people‚Äôs real emotions has not
been thoroughly investigated. In this paper, we report a multi-
level, longitudinal empirical study with 82 individual members
in 27 project teams. We collected their self-reported retrospec-
tive emotion states on a weekly basis during their year-long
projects and also extracted corresponding emotions from the
textual communication records. We then model and compare
the dynamics of these two types of emotions using multiple
statistical and time series analysis methods. Our analyses yield
a rich set of Ô¨Åndings. The most important one is that the
dynamics of emotions extracted using text-based algorithms often
do not well reÔ¨Çect the dynamics of self-reported retrospective
emotions. Besides, the extracted emotions match self-reported
retrospective emotions better at the team-level. Our results also
suggest that individual personalities and the team‚Äôs emotion
display norms signiÔ¨Åcantly impact the match/mismatch. Our
results should warn the research community about the limitations
and challenges of applying text-based emotion recognition tools
in SE research.
I. I NTRODUCTION
Emotional states are constantly felt, communicated, and
diffused through face-to-face and/or computer-mediated inter-
actions [1]‚Äì[3]. Literature in applied psychology and man-
agement has revealed that emotional states have signiÔ¨Åcant
inÔ¨Çuences on various outcomes at both individual and or-
ganizational levels [4]‚Äì[6]. Of course, this also applies in
SE activities [7]. Recently, researchers have begun to study
how emotional states impact SE activities as well as develop-
ers‚Äô wellbeing [8]‚Äì[11]. To leverage emotion awareness, the
Ô¨Årst step is correctly recognizing various emotional states at
both individual and organizational levels. Researchers have
developed automated computational methods to recognize the
human emotions [12] from various sources such as physiology
signals [13], [14], speech and/or facial expression [15], [16],
text [17], [18], etc.
Among these emotion identiÔ¨Åcation methods, extracting
emotion states from textual communication records is preva-
lent in SE research [19], [20]. These techniques are very
convenient because of the high data availability (online openly
accessible repositories), low cost (no special instrument cost),
and technical readiness (many sophisticated algorithms devel-
oped in NLP area). It is also Ô¨Åt the context of distributed
software development well, since the face-to-face interactions
are minimal, and many collaborative activities have to relyon text-based communications [21]. Fig. 1 shows a typical
pipeline of developing text-based emotion prediction models.
It Ô¨Årst builds a large unlabelled text corpus, which is usually
from online repositories or publicly available datasets. Then, a
small proportion is sampled and labeled by human annotators.
The labeled text is used for training and testing the model.
6DPSOLQJ /DUJH
8QODEHOHG
'DWDVHW6PDOO
8QODEHOHG
'DWDVHW6PDOO
/DEHOHG
'DWDVHW(PRWLRQ
/DEHOLQJ
E\+XPDQ
$QQRWDWRUV
0/$OJRULWKPV
)UDPHZRUNV(PRWLRQ
3UHGLFWLRQ
PRGHOV
Fig. 1. A typical pipeline of developing text-based emotion prediction models.
Note that we omit some minor tasks (e.g., data preprocessing) in the pipeline.
This family of techniques has a fundamental limitation. Let
us have a look at the second task: emotion labeling by human
annotators (highlighted by the grey box in Fig. 1). Even we do
not consider the possibility of annotators‚Äô misinterpretations
during the labeling task; the labeled emotions are merely
their perceptions of the emotions conveyed by the text. There
should be some discrepancies/mismatches between annotators‚Äô
perceived emotions and people‚Äôs genuine emotions [22]. Such
mismatches might be not a big issue in the domain where these
NLP techniques are originally developed, i.e., social media
analysis. Because people tend to be freely express their actual
feelings, particularly the negative ones, on social media such
as Twitter [23]‚Äì[25].
However, it becomes questionable if individuals still enjoy
the same level of freedom to express their emotions in project
teams [26]‚Äì[29]. Individual team members have to follow
social norms and routines to express themselves [30]; some
of them may experience organizational emotion suspension
[31]‚Äì[33]. Even in the open source projects, which are usually
treated as informal organizations, social interaction and self-
expression are still mostly regulated by the power structure,
professional norms, and so on [34]‚Äì[36]. For instance, Wei
et al. found that both core and periphery members in open
sources projects tend to use more polite language to convey
positive emotions but hide negative ones [37].
This problem is non-trivial. It is fundamental for emotion
awareness research in the SE. Unfortunately, as far as our cur-
rent knowledge, there are no empirical comparisons between
2302019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)
978-1-7281-2508-4/19/$31.00 ¬©2019 IEEE
DOI 10.1109/ASE.2019.00031
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. true emotions and extracted emotions. There are a few recent
studies, e.g., [38]‚Äì[41], start challenging the reliability of senti-
ment/emotion extraction methods. However, their discussions
mostly focus on the differences between extracted emotions
and the emotions labeled by human annotators rather than the
inherited validity threats from ‚Äúthird-person‚Äù coding process.
We seek to Ô¨Åll this research gap through empirical inquiries.
Hence, we ask the following main research question:
RQ 1From the dynamic perspective, how well do the emotions
extracted from the text reÔ¨Çect the true emotions at both
individual and team-levels?
Prior literature has shown that two important factors, per-
sonality [42] and the organization‚Äôs emotion display norms
[28], signiÔ¨Åcantly impact people‚Äôs emotion expression at the
individual and the team-level, respectively. We want to explore
their inÔ¨Çuences on the match/mismatch between emotions
extracted from the text and the true emotions. Hence, we have:
RQ 2‚àí1 What are individual personality‚Äôs inÔ¨Çuences on the
match/mismatch between emotions extracted from the text
and the true emotions?
RQ 2‚àí2 What are the team‚Äôs emotion display norms‚Äô inÔ¨Çu-
ences on the match/mismatch between emotions extracted
from the text and the true emotions?
To answer the above research questions, we design and con-
duct a longitudinal empirical study lasting ‚àº30 weeks with 27
team projects whose 82 members are mostly IT professionals
seeking professional MSc. in Information Systems degrees.
We collect their textual communication records, true emotions
(‚Äúretrospective‚Äù emotions collected every week1), and other
relevant data. We use state-of-art deep learning methods to
extract the retrospective emotions ( joy,anger ,sadness , and
fear ) from textual communication records, model them into a
set of time series, and compare them with true emotions. The
analyses yield a rich set of Ô¨Åndings. The most important one is
that emotions extracted by the algorithm do not well reÔ¨Çect the
true emotion dynamics, hence poses a signiÔ¨Åcant challenge to
applying text-based emotion extraction techniques in SE. We
also discuss the implications of the study to guide the future
applications of text-based emotion recognition techniques.
SpeciÔ¨Åcally, the study described in this paper makes the
following major contributions:
‚Ä¢An empirical study demonstrating the mismatches between
the dynamics of emotions extracted from the text reÔ¨Çect the
dynamics of true emotions in the SE context. As far as our
current knowledge, it is the Ô¨Årst empirical study addressing
this important validity issue.
‚Ä¢An evaluation of two critical individual and team factors‚Äô
impacts on the match/mismatch between emotions extracted
from the text reÔ¨Çect the true emotions.
‚Ä¢Implications of the study that help to better apply text-based
emotion recognition methods in SE research.
1In emotion literature, emotional experience is often captured in either
momentary or retrospective ways. In this paper, we use retrospective emotions ,
which are ratings of people‚Äôs emotional experiences after an extended period.
For more details, see Section II-A, Section III-D, and Section IV-C3.II. B ACKGROUNDS
We start by providing a brief overview of emotion theories
in Psychology. Later, we introduce several representative text-
based emotion recognition tools.
A. Psychology of Emotions
Emotions are pervasive among humans and have unique val-
ues in dealing with fundamental life-tasks [43]. Understanding
one‚Äôs emotions and emotional style build on a vast amount
of research in Emotional Psychology and Affective Science.
Psychologists have proposed many theories that classify hu-
man emotions [44]. According to the discrete emotion theory,
which is the mainstream view among psychologists, some
emotions are considered basic [45]. These basic emotions are
assumed to be biologically determined emotional responses
whose expression and recognition is fundamentally the same
for all individuals regardless of ethnic or cultural differences.
A number of empirical and analytical theories have been
proposed to classify basic emotions. Ekman [45] in his study
of analyzing individual‚Äôs facial expressions proposed six uni-
versal basic emotions: anger ,disgust ,fear ,joy,sadness , and
surprise . Although Ekman‚Äôs basic emotion set is frequently
used for emotion mining and modeling, there also exist a wide
variety of basic emotions models. For example, in a recent
study, Cowen & Keltner [46] from UC Berkeley reported that
they identiÔ¨Åed 27 basic emotions using crowdsourced video
analysis of 2,185 videos.
In this paper, we use the four of the six basic emotions in
Ekman‚Äôs model. The four emotions are: joy,anger ,sadness ,
and fear . We choose it mostly for practical considerations.
Most of the state-of-art emotion recognition techniques in NLP
focus on these four emotions [47]‚Äì[49].
1) Momentary vs. Retrospective Emotions: Emotions are
dynamic psychological processes that may turn on and off in
a matter of moments. E.g., a person may feel very sad in the
morning but become happy after a great lunch. Momentary
emotions refer to such emotional experiences [50]. The expe-
rience sampling methodology (ESM: [51]) is widely used to
capture ratings of momentary emotional experiences. It asks a
study participant to report several times emotional experiences
during a day. Emotions also can be captured through self-
report retrospective ratings [52]. A typical way is to ask a
study participant to rate the emotions s/he experiences in a
week. Researchers have found that that people remember their
emotions quite accurately after 90 days [52] or one year [53].
It is hard to say which one is better. Both of them have
limitations and biases. While ESM focuses on individuals‚Äô
current or very recent experiences and use multiple assess-
ments over time in everyday life, it may be quite burdensome,
or lead to response shift [54]. Similarly, retrospective self-
reports emotions may be biased by a variety of heuristics such
as personal relevance and signiÔ¨Åcance of reported experiences,
social expectations, and an individual‚Äôs memory capacity [55].
In fact, there are some quantitative relationships between
momentary and retrospective emotions. The most important
one is the peak-end rule, i.e., the retrospective emotion is the
231
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. combination of peak and the end (most recent) momentary
emotions [52], [56].
In this study, we use the weekly retrospective emotions .
This decision is based on practical considerations. Our study
takes almost a year. Using ESM (even at daily basis) would
be too burdensome for the participants. Many may just skip
the daily ESM surveys. This would ruin data collections (too
much missing data) and data analyses (too many ‚Äô0‚Äôs making
some tests falsely signiÔ¨Åcant). Weekly emotion survey is
widespread in psychological research for longitudinal studies,
e.g., Flueckiger et al. [57] collected emotions roughly on a
weekly basis (65 times/year). The paper was published in
Emotion , one of the APA ‚Äôs Ô¨Çagship journals. Psychologists do
recommend weekly retrospective emotion surveys for studies
taking extended periods [53].
B. Text-based Sentiment/Emotion Recognition
Researchers communities have developed many tools to
support automatic emotion extraction from text. Some early
tools are often based on word counting, i.e., mapping words in
the text to some emotion lexicon, e.g., [58]‚Äì[60]. Recently, the
machine/deep learning based techniques are replacing word
counting techniques. From several dozens of such learning
based techniques, we select the following four that represent
a variety of similar techniques and have the potential to be
used in SE scenarios.
‚Ä¢EMOTXT‚ÄìThis is a toolkit for emotion recognition from the
text. As far as our current knowledge, it is the Ô¨Årst domain-
speciÔ¨Åc tool for software development tasks. E MOTXT
contains six binary classiÔ¨Åers. Each classiÔ¨Åer uses uni-
and bi-grams, emotion lexicon, politeness, sentiment score,
and uncertainty to classify textual data related to software
development. EmoTxt can detect six emotions in Ekman‚Äôs
basic emotion model. Using a JIRA dataset created by Ortu
et al. [48] and a homemade StackOverÔ¨Çow dataset [40], the
tool exhibits good performances.
‚Ä¢SENTI 4SD‚ÄìIt was developed by the same group of re-
searchers who proposed E MOTXT.S ENTI 4SD is a senti-
ment polarity classiÔ¨Åer for software developers‚Äô artifacts
[20]. The classiÔ¨Åer is trained and tested on a gold stan-
dard of over 4K posts mined from Stack OverÔ¨Çow and
manually annotated with emotion polarity. The novelty of
Senti4SD lies on incorporating semantic features through a
600 dimension word embeddings trained on a large Stack
OverÔ¨Çow dataset.
‚Ä¢NAACL S EMEVA L ‚Äô18 S HARED TASK 1‚ÄìThe 2018 Se-
mEval workshop, which was held during NAACL‚Äô18, hosted
a shared task for detecting emotions in twitter2. The shared
task took the form of competition. During the competition,
the participating teams around the world would try to
develop algorithms to classify emotions on Twitter. Seventy-
Ô¨Åve teams (about 200 team members) participated in the
shared task or its sub-tasks. The competition generated a
2http://alt.qcri.org/semeval2018/index.php?id=taskswide range of algorithms using different classiÔ¨Åcation tech-
niques [47]. Some of them achieved excellent performances.
In general, it is fair to say that the algorithms reported at the
shared task represent the state-of-art progress of learning
emotions from the text in the NLP and computational
linguistics areas.
‚Ä¢WAT S O N TONE ANALYZER ‚ÄìThis is an off-the-shelf solution
for detecting emotions and language tones in written text.
It is implemented as a RESTful service of IBM Watson
Developer Cloud. The service can return results for the
following tone IDs: joy,anger ,fear , and sadness (emotional
tones); analytical ,conÔ¨Ådent , and tentative (language tones).
The current version uses neural embedding framework to
predict emotions [61]. In addition to predicting emotion
states, it also provides a conÔ¨Ådence score to indicate how
conÔ¨Ådent the algorithm is in detecting such a tone. However,
the conÔ¨Ådence score does not necessarily represent the
intensity of a predicted emotion though they are often
correlated.
III. E MPIRICAL STUDY DESIGN
A. Research Settings
The study is performed at a medium-sized public univer-
sity (MPU3) in the Midwest region of the United States.
The university offers a Master of Science in Information
Systems (MSc IS) program through its College of Business
and Information systems. The program admits both local and
remote online students. They follow the same study plan and
degree requirements. In the cohort of 2017 graduates, there
are 32 local students and 71 remote online students. Most
students (87 out of 103) are part-time students who have
full-time jobs. The program requires every student to take
a team-based capstone project during the last two semesters
of the study plan. In each semester, the capstone project
equals a regular 3-credit course. The initial project ideas
are solicited from faculty members and industrial partners
of the university. The project ideas are evaluated and voted
by all information systems faculty members to ensure their
technical difÔ¨Åculties and scopes are manageable. According to
each year‚Äôs enrollment number and the rankings of the voting
results, a subset of the project ideas is selected for students to
choose at the end of the Ô¨Årst year‚Äôs spring semester.
Each student is asked to express her interests by providing
a ranked list of Ô¨Åve projects. Then the instructors use a simple
matching algorithm to assign students into teams accord-
ing to their preferences. The matching process also ensures
that at most one local student would be assigned in each
team. Through this intervention, every team has to practice
distributed software development. The instructors send the
notiÔ¨Åcations to the students on Aug 1st, roughly one month
before the new fall semester. The invitation to participate in
the study is also sent along with the notiÔ¨Åcation. To encourage
3We use MPU to refer the university through the paper for keeping the
anonymity.
232
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. the participation, each member in all participating teams will
receive a $20 Amazon gift card4.
Each team is instructed to create a Slack workspace which
must have a dev channel for discussing topics related issues
in addition to the default general and random channels. The
messages in the dev and general channels are the primary
sources of the textual communication records.
B. Subjects
The subjects are from the cohort of the 2017 MSc in IS
graduates. As we mentioned before, they are assigned to 34
teams. 7 teams choose to opt-out the study. So the Ô¨Ånal
sample has 27 teams and 82 individuals5. In general, most
of the subjects have at least one-year professional software
development experiences.
C. Data Collection Process
Fig. 2 describes the primary data collection process from
08/20/2016 to 05/03/2017, spanning two full semesters. The
fall semester at MPU starts from week 0. During this week,
the instructors hold an online study brieÔ¨Ång meeting with
all 27 teams who give their consent for participation. Teams
also set up the Slack channels, and Ô¨Ånish the online BFI
personality survey. Then, we send a weekly retrospective
emotion survey to each participant every week except for
the 2016-2017 winter break. We also offer an ‚Äúimmediate
emotion‚Äù survey which participants can send us their emotion
states if they feel necessary. However, this survey is never used
by the participants. In the last week, we send the survey of
team emotion display norms to participants. A debrieÔ¨Ång also
happens in this week.
D. Measurements
1) Personality: We use the big Ô¨Åve personality model in this
study. Big Ô¨Åve personality model uses Ô¨Åve broad dimensions
to describe the human personality [62]. These Ô¨Åve dimensions
are: openness to experience ,conscientiousness ,extraversion ,
agreeableness , and neuroticism . Big Ô¨Åve personality model has
been widely used in CSCW and software engineering research
for a variety of purposes, for example, [63]‚Äì[65].
We use the Big Five Inventory (BFI) [66] to measure the
personality. BFI is one of the most widely used measurement
instruments for big Ô¨Åve personality models. Thousands of stud-
ies in various areas have examined its validity and reliability.
BFI contains 44-items which are short descriptions of personal
characteristics. A typical item is: ‚ÄúI see myself as someone
who original, comes up with new ideas.‚Äù Subjects rate the
extent to which she agrees or disagrees with each item‚Äôs
statement on a 5-point Likert scale (1= strongly disagree; 5
= strongly agree). We use the average score of all items in a
dimension as the dimension‚Äôs value. The Cronbach‚Äôs alphas‚Äô
range is from .85 to .93 for the Ô¨Åve dimensions.
4To ensure their participation is voluntary, we explicitly inform the students
that their participation does not inÔ¨Çuence their Ô¨Ånal grades. Instead, we use
the gift card as the compensation.
5There is a 4-member team.2) True Emotions: The true emotions are measured using
an adapted version of PrEmo [67]. As we mentioned in Section
II-A, we only focus on four emotions and their intensity; we
do not need a full version of PrEmo containing 14 emotions.
The non-verbal, facial expression based emotion measure-
ments usually more reliable than verbal based measurement
instruments [68]. In this study, we use universal emojis to
represent the facial expressions of emotions [69] and ask the
subjects to use a thermometer to report the intensity. Fig. 3
shows a question in our weekly true emotion data collection
questionnaire.
Since the true emotions are collected in a retrospective way.
The extracted emotions from textual records should also be
retrospective to make comparisons between true emotions and
extracted emotions valid. We use the peak-end rule [52], [56]
to compute the extracted weekly retrospective emotions after
the selected algorithm determines daily emotion intensities.
For details, please refer to Section IV-C.
3) Team‚Äôs Emotion Display Norms: We use a simple two-
factor model for a team‚Äôs emotion display norms. The two
factors are positive emotion display norms and negative emo-
tion display norms. They are measured using the 8-item ques-
tionnaire developed by Eid & Diener [70], slightly modiÔ¨Åed
to suit the context of the current study. The questionnaire‚Äôs
opening line is ‚ÄúWhile working in the capstone project team,
when communicating with your teammates, to what extent is
it appropriate to express the following emotions when you
experience them.‚Äù Responses were given on a 7-point Likert
scale (1 = not at all; 7 = to a great extent). The Cronbach‚Äôs
alpha is .87 for the positive and .92 for the negative emotions.
4) Aggregation: To investigate the team-level mismatches,
we aggregate two variables from the individual-level to the
team-level. They are a team‚Äôs collective emotions and emotion
display norms. Following the common practices in psycho-
metrics [71], we use the average of individuals‚Äô emotion
intensity scores to represent the team‚Äôs collective emotion
intensity for a speciÔ¨Åc emotion in each week. Similarly, we use
individual scores averaged by the team for the team‚Äôs emotion
display norms. To ensure the feasibility of aggregation from
the individual-level to the team-level, we use two measures of
the within-group agreement. The Ô¨Årst measure is the intraclass
correlation coefÔ¨Åcient (ICC) [71], and the second measure is
the interrater reliability coefÔ¨Åcient (IRR) [72]. For ICC, the
results reach statistical signiÔ¨Åcance ( p<. 01to.001) for
all four emotions in all groups, as well as the team emotion
display norms. The IRRs range from 0.80 to 0.91. Both suggest
the aggregations are very reliable. Due to the restriction of
space, we do not include all ICCs and IRRs in the paper.
E. Collected Data
The data collection results in three types of data.
‚Ä¢True emotion states‚ÄìWeekly emotion survey results for
individuals, aggregated collective emotions for teams;
‚Ä¢Textual team communication Records‚ÄìMessages on the
Slack channel (author, time, and mentioning information);
233
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. :HHN
3URMHFW.LFNRII	6WXG\EULHILQJ
,QLWLDOPHHWLQJ
6HWWLQJXSWKH GHY6ODFNFKDQQHO
,QIRUPDWLRQFRQVHQW
,QLWLDOVXUYH\%),IRU3HUVRQDOLW\:HHN
:HHNO\VXUYH\IRUHPRWLRQVWDWHVWRWDO
(PRWLRQZDVFDSWXUHGXVLQJUHYLVHG3U(PR
7KHUHDUHWKUHHNH\PLOHVWRQHV
∆î :HHNGRPDLQPRGHO
∆î :HHNLQWHULPUHSRUW
∆î :HHNSUHVHQWDWLRQ	GHPR:HHN
3URMHFW:UDSXS	6WXG\GHEULHILQJ
7HDP¬∂VHPRWLRQGLVSOD\QRUPVVXUYH\
Fig. 2. The data collection process. Note that there was a winter break (around 4 weeks) between the two semester. We ignored this period because most
teams‚Äô activities were halted during the winter break.
TABLE I
DA TASETS AND THEIR PURPOSES .
No. Dataset Type Source Size Purposes
I StackOverÔ¨Çow Dump Data Unlabelled Text archive.org >30M For pretraining SE word embeddings.
II Communication Records Text Slack Workspace 135,931 For identifying emotion states to answer the
main research questions.
III Task-SpeciÔ¨Åc Dataset
(see Section IV-B)Labelled A sample of Dataset II 4 √ó1,000* For training and Ô¨Åne-tuning the Ô¨Ånal emotion
intensity prediction models.
VI True Emotions (Individ-
ual)Numeric Weekly Survey 4√ó28√ó82 For answering RQ1by comparing with ex-
tracted emotion states.
V True Emotions (Team) Numeric Computed from V 4 √ó28√ó27 Same as the above Dataset VI.
VI Personality ProÔ¨Åles Individual Factor Survey 82 For answering RQ2‚àí1
VII Emotion Display Norms Org. Factor Survey 27** For answering RQ2‚àí2
*. There are some overlapping messages for each of the three negative emotions, so the total number of unique message is 3,100 instead of 4,000. (see
Section IV-B for details).
**. Aggregated from individual responses.
Fig. 3. A question in weekly true emotion survey.
‚Ä¢Personality & team‚Äôs emotion display norms‚Äì Responses of
BFI and Team‚Äôs emotion display norms surveys.
We also collect a massive unlabelled general software
development textual data from the StackOverÔ¨Çow data dump.
Although this dataset is not directly related to answering the
research questions, it is necessary for training the emotion
prediction models. Tab. I illustrates the different datasets and
their usages. For the meaning of some usages related to model
training, please refer Section IV-C1.
IV . D ATA PREPARA TIONS
A. Preprocessing Textual Data
The preprocessing consists of three major tasks: tokeniza-
tion, spell correction, word normalization. We use the adapted
ekphrasis tool for preprocessing the supplementary data.
We follow the guidelines in [73]. We also compile a speciÔ¨Åc
software development dictionary for the preprocessing.B. Creating the Task-SpeciÔ¨Åc Emotion Intensity Dataset
We also create a manually labeled dataset for emotion
intensity regression training and testing for our study‚Äôs speciÔ¨Åc
emotion intensity regression task. The current practice of creat-
ing such datasets is merely doing random samplings. However,
a random collection of messages is likely to have a signiÔ¨Åcant
proportion of messages not associated with the focus emotion,
and thus annotating all of them for the intensity of emotion
is suboptimal. To solve this problem, we use a multiple-step
approach presented in [74]. In the Ô¨Årst step, for each emotion,
we select 50 to 100 terms that are associated with a speciÔ¨Åc
emotionXat different intensity levels using the Word Affect
Intensities lexicon [75]. Using these terms, we get a subset
of messages for emotion X. Then, we randomly select 1,000
for joy (the only positive emotion) from the corresponding
subset of messages. For the three negative emotions, we Ô¨Årst
randomly select 150 for each emotion. These 450 messages
are annotated for all three negative emotions. Then, for each of
the negative emotions, we also chose 550 additional messages,
from their corresponding message sets, which were annotated
only for the corresponding emotion. Due to the restriction
of the space, interested readers should refer to [74] for the
rationale and more details of this process.
We recruit professional developers to annotate the emotion
intensity through crowdsourcing. This method has been widely
used in the NLP community to generate high quality labeled
234
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. corpus [76]. We utilize the upwork.com‚Äìa professional crowd-
sourcing platform‚Äìto recruit annotators. For each message,
three annotators label the emotion intensity in a ‚Äú0-1‚Äù scalefor each emotion. For each message, if there is a 0.20 orhigher differences among any two annotators‚Äô emotion inten-sity scores, we ask a fourth coder to resolve it. In total, 482messages require the involvement of the fourth coders. Afterthe resolving process concludes, we then take the average ofall annotators‚Äô scores as each message‚Äôs emotion intensity.
Eventually, we build a dataset containing 1,000 annotated
messages for each emotion. Since there are some overlapsamong the three negative emotions, the dataset contains 1,000+ 150√ó 3 + 550√ó 3 = 3100 unique messages in total.
C. Extracting Emotions in the Textual Records
We adapt the NTU A-SLP [49] algorithm to extract emo-
tions from the collected team communication messages. As wementioned before, NTU A-SLP
6, is the winning algorithm of
the NAACL S EMEVA L ‚Äô18 S HARED TASK 1 (see Section II-
B). As the winning algorithm, NTU A-SLP reÔ¨Çects the recent
progress in the NLP community and uses a deep learningframework (RNN). Note that we only use the algorithmto calculate emotion intensities at the individual-level on adaily basis. The weekly individual retrospective emotions anda team‚Äôs collective emotions are calculated based on dailyindividual emotions. However, the algorithm cannot be directlyapplied. We have to perform some customization and retrainthe model for our task. We will introduce the transfer learningfor MTUA-SLP and its performances on our dataset.
1) Transfer Learning for NTUA-SLP: NTUA-SLP is de-
signed for predicting the emotion intensities for tweets. Wehave to do some transfer learning tasks and retrain modelswith the data set from the software development domain.Fortunately, NTU A-SLP is implemented in an architecture
that is easy for transfer learning. Indeed, itself is consists oftransfer learning models. Using the same learning frameworkin, we take three steps as follows:
1) the word embeddings pretraining, where we train the 310
dimension word2vec and affective word embeddings on alarge unlabeled Stack OverÔ¨Çow dataset [77];
2) the transfer learning step, where we pretrain a deep-learning
model on a sentiment analysis task;
3) the Ô¨Åne-tuning step, where we Ô¨Åne-tune the pretrained
model for predicting emotion intensities in the softwaredevelopment domain.
Fig. 4 shows how we adapt the original NTU A-SLP learning
framework. We use our own task-speciÔ¨Åc emotion intensitydataset (described in Section IV-B to train and test the model.We divide the training and testing data at the 7:3 ratio [78].
2) Performance of the Adapted Algorithm: Tab. II sum-
marizes the algorithm‚Äôs performance. We report two metrics:Mean Absolute Errors (MAEs) and Pearson correlations. Ingeneral, NTU A-SLP performs well across all four emotions,
although its performances are slightly worse than but stillcomparable to the performance metrics reported in [49].
6https://github.com/cbaziotis/ntua-slp-semeval20188QODEHOOHG
6('DWDVHW
3UHWUDLQLQJ
6('DWDVHW
7DVN
'DWDVHW3UHWUDLQLQJWDVN 3UHGLFWLRQWDVN3UHSURFHVVLQJ(PEHGGLQJ
3UHWUDLQLQJ
6(:RUG
(PEHGGLQJV
3URFHVVHG
3UHWUDLQLQJ
6('DWDVHW
3URFHVVHG
7DVN'DWDVHW
(PEHGGLQJ/D\HU
)LQDO
/D\HU7DVN6SHFLILF
/D\HU7/ZHLJKWV
Fig. 4. Overview of the adapted NTUA‚ÄìSLP . We keep the learning framework
but replace the twitter datasets with software development datasets.
TABLE II
THE PERFORMANCES OF THE SELECTED ALGORITHM .
joy anger sadness fear
NTUA-SLP MAE 0.016 0.013 0.019 0.011
Pearson 0.752 0.770 0.749 0.694
3) Extracting Weekly Retrospective Emotions: We follow
the pick-end rule when extracting weekly retrospective emo-
tions. For each individual, we organize his or her textualrecords by day in each week. We extracted every day‚Äôsemotions using the adapted NTUA-SLP algorithm Ô¨Årst. Then,for a speciÔ¨Åc emotion, we identiÔ¨Åed the peaks and the ends toapply the peak-end rule for calculating weekly retrospectiveemotions [52], [56]. For instance, if the peak joy is 0.9 on
Wednesday, and the end joy on Sunday is 0.3, the weekly
retrospective joy is 0.6. For a team‚Äôs collective emotional
experiences, we use the average of all its team members‚Äôindividual weekly retrospective emotion intensities.
D. Modeling the Emotion Dynamics
Emotion is a dynamic concept. Indeed, investigating the
dynamics of the emotion over the life-cycle of a distributed SE
team makes more sense than treating them as isolated discreteemotion states. Hence, we model the emotions (extracted andtrue) as time series. Our study focuses on four emotions;therefore, for each individual or team, there are 8 time seriesconsisting of 4 true ones and 4 extracted ones. We use AE
xtto
denote the time series for the true emotion XwhereX‚àà{joy,
anger, sadness, fear}. The element of AE xtisX‚Äôs emotion
intensity at week i. For we conduct 28 weekly emotion survey,
AE xthas 28 elements in sequential time order. In total, we
have 82√ó4 = 328 AE xts at the individual-level and 27 √ó
4 = 108AE xts at the team-level. Similarly, we use EE xtto
denote the time series for extracted emotion X. During the
emotion extraction, we organize an individual or a team‚Äôs textinto weeks. Hence, for an individual or a team, the extractedemotion intensities also have 28 data points on emotion X.
The total number of time series are also 328 at the individual-level and 108 at the team-level.
235
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. V. D ATA ANALYSIS
The goal of the data analysis is to quantitatively compare
the dynamics of true emotions and the dynamics of extracted
emotions. If they are ‚Äúmatches‚Äù, researchers and practitioners
could be conÔ¨Ådent to use the extracted emotion states in many
distributed collaboration and software development scenarios.
If there are many ‚Äúmismatches‚Äù, researchers may need to be
cautious. Besides, if an individual‚Äôs personality does correlate
with how well the extracted emotions reÔ¨Çect true emotion,
researchers may have better insights on how to use the
extracted emotions. For RQ 1, data analyses happen at two
levels: individual and team. For RQ 2‚àí1, we analyze the data
at the individual-level, because personality is an individual
characteristic. For RQ 2‚àí2, we analyze the data at the team-
level since the emotion display norms are team-level factors.
'\QDPLFVRIWUXHHPRWLRQV
'\QDPLFVRIH[WUDFWHGHPRWLRQV7LPH6HULHV
&RLQWHJUDWLRQ$QDO\VLV54
54/RJLVWLF5HJUHVVLRQ 54'HVFULSWLYH$QDO\VLV
%),3HUVRQDOLW\
6XUYH\(PRWLRQ'LVSOD\
1RUPV6XUYH\
'\QDPLFVRIWUXHHPRWLRQV
\
'\QDPLFVRIH[WUDFWHGHPRWLRQ V
Fig. 5. The overview of the data analyses.
A.RQ 1: Cointegration Analysis
Fig. 5 depicts the overall process of data analyses. To
answerRQ 1, we use a special time series analysis techniques:
cointegration. To answer RQ 2‚àí1, we use logistic regressions.
We do a descriptive analysis for RQ 2‚àí2because of the small
sample size (27 teams). Note that answering RQ 2requires the
results of cointegration analyses for RQ 1. The three statistical
and time series analysis techniques and how we apply them are
introduced in the rest of the section. They are performed with
R 3.4.1 [79] and its associated packages for MAC OS High
Sierra (version 10.13.1). We follow the American Statistical
Association‚Äôs principles to interpret the statistical results [80].
It is very intuitive to calculate the correlation between
two collections of data. However, for a pair of time series,
simple correlation analysis is not sufÔ¨Åcient to describe the
relationships between them because correlation analysis en-
tirely ignores the sequential orders related to time. Two highly-
correlated time series can diverge signiÔ¨Åcantly. We need some
analysis that can deal with the time orders.
Cointegration is a time series analysis technique frequently
used in quantitative Ô¨Ånance. Cointegration is better than cor-
relation as an indicator of how similar the shapes of two time
series. Intuitively, if two time series are cointegrated, they are
unlikely to diverge too much over time7. Thus, these two time
series can be viewed as mutual-predictable [81]. Hence, we
can use it here to test the degree to which two different traces
are similar to each other.
7In a more formal word, the time series representing their differences is
stationary.We use the Engle-Granger two-step method which was de-
veloped by two Nobel laureates in Economic Science: Robert
Engle and Clive Granger, in their classic Econometrica paper
[82]. Let us suppose that true emotion time series for a speciÔ¨Åc
emotionxisAE xt, and extracted emotion time series is EE xt.
IfAE xtandEE xtare non-stationary and cointegrated, then
a linear combination of them must be stationary:
AE xt‚àíŒ≤√óEE xt=Rxt,w h e r eR xtis stationary. (1)
In the Ô¨Årst step, the Engle-Granger two-step method estimates
Rtusing Ordinary Least Square (OLS) regression. Then, the
second step needs to test if Rtis stationary. We use the
Augmented Dickey-Fuller (ADF) test to fulÔ¨Åll the second step
with the adf.test function in R‚Äôstseries package [83].
We usep=0.05as the critical value for the ADF test. As
same as the number of correlation tests, at the individual-level,
there are 328 cointegration tests; at the team-level, there are
108 tests. In total, we perform 436 cointegration tests8.
B.RQ 2‚àí1: Logistic Regression
TheRQ 2‚àí1is about assessing if individual members‚Äô
personality‚Äôs impacts on the match/mismatch between true
emotions and extracted emotions. We use logistic regression
to answer this research question. In the logistic model, the
5 personality dimensions are the independent variables, while
cointegration results are coded into a 0-1 binary variable as the
dependent variable. Because the analysis requires the results
from the cointegration analyses, we provide more details
in the next section. We also control several variables when
performing the logistic regressions. They are age, gender, and
experience in software development.
C.RQ 2‚àí2: Descriptive Analysis
Because of the relatively small sample size, performing
logistic regression as what we do for RQ 2‚àí1may not provide
reliable results. We use descriptive analysis to answer RQ 2‚àí2.
For each emotion, we divide teams into two groups: one
contains the teams whose dynamics of extracted emotion
match that of true emotion, the other contains the rest. We plot
the team emotion display norms for intuitive comparisons.
VI. R ESULTS AND FINDINGS
In this section, we report the results and provide answers to
the research questions.
A.RQ 1: How Well Do the Extracted Emotions ReÔ¨Çect True
Emotions?
Fig. 6 shows the results of cointegration analyses of all 82
subjects and 27 teams. The Ô¨Årst three series on the top are
individual-level results while the fourth series are team-level
results. Each hollow dot indicates a signiÔ¨Åcant cointegration
test result. Let us take subject 36 as an example. There are two
hallow dots at the lines for Joy and Sadness . This means the
cointegration tests between the true emotion time series and
8Before the cointegration analyses, we test the non-stationary assumptions
for all time series. No stationary time series is found in our data.
236
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply.           6XEMHFW
1RWH(DFK KROORZGRW UHSUHVHQWVWKHVXEMHFWWHDP¬∂VFRLQWHJUDWLRQWHVWUHVXOWLV VLJQLILFDQW SDWRQHRIWKHIRXUHPRWLRQVUHSUHVHQWHGE\WKH
GDVKOLQH-R\
$QJHU
6DGQHVV
)HDU
          6XEMHFW
        7HDP      6XEMHFW-R\
$QJHU
6DGQHVV
)HDU
-R\
$QJHU
6DGQHVV
)HDU
-R\
$QJHU
6DGQHVV
)HDU
,QGLYLGXDO/HYHO5HVXOWV
\W K H
7HDP/HYHO
5HVXOWV
Fig. 6. The results of the cointegration analyses at both individual and team-level.
the extracted emotion time series are signiÔ¨Åcant on these two
emotions. The same denotation applies to team-level results
also.
1) Individual-Level Results: Obviously, the results suggest
signiÔ¨Åcant mismatches at the individual-level. In all four
emotions, joyhas the best matching between true emotion and
extracted emotion. However, only 52 out of 82 cointegration
tests are signiÔ¨Åcant, indicating only ‚âà63.4% individuals‚Äô
extracted joy emotion dynamics well reÔ¨Çected their true
emotion dynamics. For the rest three negative emotions, the
results are much worse. None of them achieves 50% marches
(anger : 27/82‚âà32.9%,sadness : 39/82‚âà47.6%,fear : 34/82
‚âà41.5%). There are 7 individuals (subject 1, 17, 19, 42, 52,
64, and 73) who have no emotion to be well reÔ¨Çected by the
extracted emotions.
It is not surprising that the extracted emotion joy better
reÔ¨Çects the true emotion joy. People are more likely to express
positive emotions and hide negative emotions in teams [84].
Particularly, being anger in a work environment is often
viewed as a kind of unprofessional behavior and a sign of
lacking personal emotion regulation [85]. Moreover, It requires
a substantial amount of power to obtain the privilege of
expressing anger in most organizations [86]. Therefore, the
extracted emotion anger does the worst job in reÔ¨Çecting the
true emotion anger .
2) Team-Level Results: Compared with individual-level
results, team-level ones are generally better. Similarly, the
emotion joy has the best results which achieve more than
74.1% (20 out of 27) matches between the extracted emotion
dynamics and true emotion dynamics. For the rest three
emotions, the results are also better ( anger : 13/27‚âà48.1%,sadness : 17/27‚âà63.0%,fear : 16/27‚âà59.6%). Though the
matches for anger is still less than 50%, sadness and fear are
all around 60%. There is only one team (team 18) that has no
signiÔ¨Åcant cointegration on all four emotions.
It is reasonable that the team-level results are better than
individual-level results. Consider a situation that some team
event triggers some emotions. Since a team has more than
one members, the chance for some of them speak out their
emotions is often higher than an individual [87]. Hence, it is
more likely to capture the true emotions at the team-level.
Hence, we can answer RQ 1as follows:
In general, the dynamics of emotions extracted using text-
based algorithms often do not well reÔ¨Çect the dynamics of
true emotion. The extracted emotions perform better at the
team-level than they do at the individual-level ones. Be-
sides, the extracted positive emotion‚Äôs performances are
consistently better than negative emotions‚Äô performances.
B.RQ 2: What Are the Personality and Team‚Äôs Emotion Dis-
play Norms InÔ¨Çuences?
1)RQ 2‚àí1: Individual Personality: To examine the person-
ality‚Äôs impacts, we recode the cointegration results. For each
cointegration test, if the results are signiÔ¨Åcant (a match be-
tween extracted and true emotion dynamics), we code it as ‚Äú1‚Äù,
otherwise (a mismatch), ‚Äú0.‚Äù Hence, for each emotion, there
are 82 binary ‚Äú0-1‚Äù data points. We use it as the dependent
variable, and run a logistic regression for each emotion. Thus
we have 4 logistic regression models summarized in Tab. III.
First of all, individuals‚Äô personalities do impact how well the
237
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. TABLE III
LOGISTIC REGRESSION RESULTS OF PERSONALITY ‚ÄôSIMPACTS
Predictors Joy (Œ≤) Anger (Œ≤) Sadness (Œ≤) Fear (Œ≤)
Intercept ‚àí1.975 *** 4.053 *** 3.485 *** 6.071 ***
Control Var .
Age 0.103 * ‚àí0.135 ** ‚àí0.094 * ‚àí0.152 *
Gender ‚àí0.081 ** 0.043 ** ‚àí0.045 ‚àí0.062 **
Experience in SE 0.023 ** ‚àí0.160 *** ‚àí0.082 ** ‚àí0.304 *
Independent Var .
Openness 0.067 *** 0.021 ** 0.024 ** 0.009 **
Conscientiousness ‚àí0.168 * ‚àí0.049 ‚àí0.065 ** ‚àí0.273
Extr aversion 0.008 0.032 ** 0.046 ** 0.029 *
Agreeableness 0.117 * ‚àí0.074 ** ‚àí0.006 ** ‚àí0.052 **
Neuroticism 0.026 ** 0.053 *** 0.035 *** 0.018 **
McFadden‚Äôs R Squared‚Ä†0.253 0.261 0.190 0.169
œá2(8) 80.077 *** 91.058 *** 53.236 *** 71.586 ***
Number of Obs. 82 82 82 82
Note.‚àó:p< 0.10,‚àó‚àó:p< 0.05,‚àó‚àó‚àó :p< 0.01;‚Ä†:McFadden‚Äôs R Squared is a Pesudo R Squared .
dynamics of extracted emotions reÔ¨Çect that of true emotions.
All models for the four emotions are signiÔ¨Åcant (see the line
ofœá2(8)s in Tab. III).
Among the Ô¨Åve personality dimensions, it is easy to Ô¨Ånd
that openness to experience and neuroticism almost always
have positive impacts on the probability of the match be-
tween extracted emotion dynamics and true emotion dynamics.
Understandably, an open person may tend to express his/her
emotions, while a moody (high in Neuroticism) person may
do the same. Higher Extraversion often leads to better matches
for negative emotions but does not have a signiÔ¨Åcant impact
onjoy. This consistent with the prior research that the ex-
travert people are less cooperative and respect social norms
less, hence often have fewer restrictions to express negative
emotions [88]. The agreeableness is just in the opposite.
Hence, we can answer RQ 2‚àí1as follows:
The dynamics of extracted emotions are more likely to
reÔ¨Çect better that of true emotions for those who are
high in Openness, and Neuroticism almost in all emotions.
Meanwhile, for those who are high in Extraversion, the
chances of mismatches on negative emotions (anger , fear ,
sadness) are signiÔ¨Åcantly higher , while the effects are in
the opposite for people high in agreeableness.
2)RQ 2‚àí2: Team‚Äôs Emotion Display Norms: As what we
do for answering RQ 2‚àí1, we also recode the team-level
cointegration results into a ‚Äúmatch-mismatch‚Äù binary variable,
and then perform some simple descriptive analysis. Fig. 7
visualizes the average team‚Äôs emotion display norms of both
positive and negative emotions grouped by the recoded coin-
tegration results. For the emotion joy, the average of positive
emotion display norms values is higher when the results
are matches; the average of negative emotion display norms
values is also slightly higher. It is straightforward because
high values on positive emotion display norms mean that ateam is expecting members to show more positive emotions.
For the three negative emotions, it seems that the averages
of positive emotion display norms do not change too much
no matter what the cointegration results are. However, the
averages of positive emotion display norms are often higher
when the results are matches, particular for the emotion anger .
The second subÔ¨Ågure of Fig. 7 is about anger . The average
value of the negative emotion norms is about 4 (neutral in
1-7 Likert scale), which means the team neither encourage
nor discourage the expression of negative emotions. Hence,
It suggests that when a team does not discourage expressing
negative emotions, its members often tend to express their
anger.
Fig. 7. The differences of team‚Äôs emotion display norms on different
cointegration analysis results of four emotions.
Hence, we can answer RQ 2‚àí2as follows:
F or the emotion joy, when a team‚Äôs positive emotion
norms are high, the extracted emotion are more likely
to match the true emotion. F or the emotion anger , when
a team‚Äôs positive emotion norms are high, the extracted
emotion are more likely to match the true emotion. F or
sadness and fear , though there are some differences, they
are relatively small.
238
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. VII. D ISCUSSIONS
A. Implications
In general, the results are a little bit discouraging, indicating
that the emotion states extracted from the textual commu-
nication records may not well represent the true emotion
dynamics experienced by team members. The study provides
several important implications for applying text-based emotion
recognition techniques in SE research.
First, it warns SE research community about the limitations
and challenges of applying text-based emotion recognition
techniques. Such limitations and challenges are systematic and
reÔ¨Çect a fundamental construct validity issue of such methods.
Though it is (almost) impossible to completely solve this
problem, it is still possible to Ô¨Ågure out practical ‚Äúcheat sheet‚Äù
for minimizing this systematic error. A ‚Äúcheat sheet‚Äù may tell
researchers that using such techniques should be safe in some
empirically validated speciÔ¨Åc user scenarios. Our results give
some hints for it. I.e., when a team‚Äôs positive emotion display
norms are high, using team-level extracted positive emotions
may be a good idea.
Moreover, our results also demonstrate the necessities of
considering individual and organizational factors. Many of
these factors can be automatically learned, e.g., IBM Watson‚Äôs
personality insights [89]. Carefully using them to complement
text-based emotion recognition techniques may alleviate the
validity concerns. Second, our study also urges a synthesis of
emotion recognition methods beyond text-based ones. Affec-
tive computing community has made signiÔ¨Åcant progress in
using speech, facial expression, and other signals to detect
emotion. Although these methods are hard to be applied
in mining software repositories, using them in control lab
experiments and/or Ô¨Åeld studies will bring fruitful results
to the emotion awareness studies in SE. Third, our study
takes a dynamic view of emotions. This reminders researchers
that the change of emotions may be more important than
a snapshot of emotions. Hence, we expect more researches
in this direction. Lastly, our efforts on adapting NTUA-SLP
demonstrate that it is necessary to systematically perform
domain adaptations to keep track of the state-of-art progress in
the NLP community. Building community infrastructure, e.g.,
datasets, transfer learning frameworks, processing pipelines,
and so on, will undoubtedly accelerate the knowledge transfer
from domains such as affective computing or NLP to SE.
B. Threats to V alidity
From the perspective of construct validity , we must admit
that human emotion itself is a complex construct. We follow
standard psychometric method to measure it during the data
collection. We purposely adjusted emotion extraction to en-
sure fair comparisons between true emotions and extracted
emotions. These help us to remove most of the construct
validity. For the emotion extracted from the text, examining
its construct validity is exactly one of the research goals of
the study. From the perspective of internal validity , we must
admit that we could not perfectly control characteristics andprogresses of the 27 subjected projects. For example, although
most communication happens in Slack, teams may also use
other communication methods (e.g., video meeting) during the
development process. Besides, because the research goals do
not require cross-team comparisons, lacking random control
in the natural setting is no longer a signiÔ¨Åcant threat. In
extracting emotions from the text, we use the state-of-the-
art algorithms with adaptations to the study contexts. We
acknowledge that some parameters might be further tuned
to increase emotion prediction performances. However, the
space for such improvements should be limited. From the
perspective of external validity , the study only considers one
emotion recognition algorithm. Although it represents a variety
of state-of-art techniques and achieves highest performances
among its peers, we cannot rule out the possibility that some
algorithm may yield better matches with true emotions. We
also use the data collected from student projects rather than
industry projects. However, the mismatches between ‚Äúemo-
tions extracted from text‚Äù and ‚Äútrue emotions‚Äù are systematic
[22]. Even in the ideal case, ‚Äúemotions extracted from text‚Äù
are no more than the perceptions of annotators who read the
text, while ‚Äútrue emotions‚Äù are the experiences of those who
produce the text. They are theoretically different, especially
in a team context where people are supposed to follow some
routines in expressing their ‚Äútrue emotions.‚Äù Thus, we argue
that mismatches should be generalizable and pervasive. Hence,
we are conÔ¨Ådent that the study achieves good external validity.
However, the degree of these mismatches may vary. Our study
at least reminds that researchers may need to be cautious
when applying text-based emotion recognition techniques in
SE research, particularly when organizational impacts and
personal differences cannot be ignored.
VIII. C ONCLUDING REMARKS
With the fast-growing emotion awareness research in SE,
text-based emotion recognition approaches become popular
due to its simplicity and low cost. Recently, SE researchers
have started examining the reliability of these approaches,
for example, Lin et al. [39]. However, an important issue
regarding the construct validity of such methods, i.e., how
well the extracted emotions reÔ¨Çect the true emotions, remains
unexplored. This issue is nontrivial. An SE team, as an
organization functioning under many social norms, often does
not provide the same amount of freedom to its members for
freely expressing their emotions as social media does.
In this paper, we report a multi-level, longitudinal empirical
study aiming to formally evaluate how well the extracted
emotions reÔ¨Çect the true emotions. The study takes a dynamic
view of emotion states rather than focus on discrete recognized
emotion state. We collect true emotions from 27 distributed
teams and extracted emotions from their textual communica-
tion records using state-of-art techniques in NLP community.
The comparisons between the dynamics of true emotions and
extracted emotions reveal that there are signiÔ¨Åcant mismatches,
particularly for negative emotions. We further explore the
impacts of individual personality and team emotion display
239
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. norms. The results suggest that they have signiÔ¨Åcant impacts
on how well the extracted emotions reÔ¨Çect true emotions.
For future work, we plan to continue our efforts in evaluat-
ing the validity of text-based emotion recognition techniques
with professional development teams. Given that we have
shown that individual/organizational factors correlate to the
match/mismatch between true emotions and extracted emo-
tions, we are eager to explore if there is any possibility to
automatically learn and utilize these factors to Ô¨Åne-tune the
extracted emotions to make them better reÔ¨Çect the actual ones.
We are releasing the complete dataset as a replication package.
ACKNOWLEDGEMENT
We would like to thank all the participants of the study and
Dr. Jun Liu for their helps in this study. The author is partially
supported by NSF IIS-1850067.
REFERENCES
[1] S. E. Green Jr, ‚ÄúA rhetorical theory of diffusion,‚Äù Academy of Manage-
ment Review , vol. 29, no. 4, pp. 653‚Äì669, 2004.
[2] I. B. Mauss, R. W. Levenson, L. McCarter, F. H. Wilhelm, and J. J.
Gross, ‚ÄúThe tie that binds? coherence among emotion experience,
behavior, and physiology.‚Äù Emotion , vol. 5, no. 2, p. 175, 2005.
[3] D. Derks, A. H. Fischer, and A. E. Bos, ‚ÄúThe role of emotion in
computer-mediated communication: A review,‚Äù Computers in Human
Behavior , vol. 24, no. 3, pp. 766‚Äì785, 2008.
[4] T. M. Amabile, S. G. Barsade, J. S. Mueller, and B. M. Staw, ‚ÄúAffect
and creativity at work,‚Äù Administrative Science Quarterly , vol. 50, no. 3,
pp. 367‚Äì403, 2005.
[5] N. M. Ashkanasy, C. E. H ¬®artel, and C. S. Daus, ‚ÄúDiversity and emotion:
The new frontiers in organizational behavior research,‚Äù Journal of
management , vol. 28, no. 3, pp. 307‚Äì338, 2002.
[6] T. A. Wright and R. Cropanzano, ‚ÄúEmotional exhaustion as a predictor
of job performance and voluntary turnover.‚Äù Journal of Applied Psychol-
ogy, vol. 83, no. 3, pp. 486‚Äì493, 1998.
[7] E. Guzman and B. Bruegge, ‚ÄúTowards emotional awareness in software
development teams,‚Äù in Proc. of the 9th Joint Meeting on F oundations
of Software Engineering (ESEC/FSE) , 2013, pp. 671‚Äì674.
[8] D. Gachechiladze, F. Lanubile, N. Novielli, and A. Serebrenik, ‚ÄúAnger
and its direction in collaborative software development,‚Äù in Proc. of the
39th International Conference on Software Engineering: New Ideas and
Emerging Technologies Results Track (ICSE-NIER) , 2017, pp. 11‚Äì14.
[9] E. Guzman, R. Alkadhi, and N. Seyff, ‚ÄúA needle in a haystack: What
do twitter users say about software?‚Äù in 2016 IEEE 24th International
Requirements Engineering Conference (RE) , Sept 2016, pp. 96‚Äì105.
[10] W. Maalej, Z. Kurtanovi ¬¥c, H. Nabil, and C. Stanik, ‚ÄúOn the automatic
classiÔ¨Åcation of app reviews,‚Äù Requirements Engineering , vol. 21, no. 3,
pp. 311‚Äì331, 2016.
[11] M. M ¬®antyl ¬®a, B. Adams, G. Destefanis, D. Graziotin, and M. Ortu,
‚ÄúMining valence, arousal, and dominance: Possibilities for detecting
burnout and productivity?‚Äù in Proc. of the 13th International Conference
on Mining Software Repositories (MSR) , 2016, pp. 247‚Äì258.
[12] Z. Zeng, M. Pantic, G. I. Roisman, and T. S. Huang, ‚ÄúA survey of affect
recognition methods: Audio, visual, and spontaneous expressions,‚Äù IEEE
Trans. on Pattern Analysis and Machine Intelligence , vol. 31, no. 1, pp.
39‚Äì58, 2009.
[13] F. Nasoz, K. Alvarez, C. L. Lisetti, and N. Finkelstein, ‚ÄúEmotion recog-
nition from physiological signals using wireless sensors for presence
technologies,‚Äù Cognition, Technology & Work , vol. 6, no. 1, pp. 4‚Äì14,
2004.
[14] L. Nummenmaa, E. Glerean, R. Hari, and J. K. Hietanen, ‚ÄúBodily maps
of emotions,‚Äù Proc. of the National Academy of Sciences , vol. 111, no. 2,
pp. 646‚Äì651, 2014.
[15] K. Han, D. Y u, and I. Tashev, ‚ÄúSpeech emotion recognition using
deep neural network and extreme learning machine,‚Äù in Proc. of the
15th Annual Conference of the International Speech Communication
Association (INTERSPEECH‚Äô14) , 2014.
[16] Y . Kim and J. Kim, ‚ÄúHuman-like emotion recognition: Multi-label
learning from noisy labeled audio-visual expressive speech,‚Äù in IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP) . IEEE, 2018, pp. 5104‚Äì5108.[17] A. Neviarouskaya, H. Prendinger, and M. Ishizuka, ‚ÄúTextual affect
sensing for sociable and expressive online communication,‚Äù in Proc. of
the 2nd International Conference on Affective Computing and Intelligent
Interaction (ACII) . Springer, 2007, pp. 218‚Äì229.
[18] E. Cambria, J. Fu, F. Bisio, and S. Poria, ‚ÄúAffectivespace 2: enabling
affective intuition for concept-level sentiment analysis,‚Äù in Proc. of the
29th AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI) ,2015, pp. 508‚Äì
514.
[19] G. Wang, T. Wang, B. Wang, D. Sambasivan, Z. Zhang, H. Zheng, and
B. Y . Zhao, ‚ÄúCrowds on wall street: Extracting value from collaborative
investing platforms,‚Äù in Proc. of the 18th ACM Conference on Computer
Supported Cooperative Work &; Social Computing (CSCW) , New Y ork,
NY , USA, 2015, pp. 17‚Äì30.
[20] F. Calefato, F. Lanubile, F. Maiorano, and N. Novielli, ‚ÄúSentiment
polarity detection for software development,‚Äù Empirical Software En-
gineering , vol. 23, no. 3, pp. 1352‚Äì1382, 2018.
[21] A. Tang, M. Pahud, K. Inkpen, H. Benko, J. C. Tang, and B. Buxton,
‚ÄúThree‚Äôs company: Understanding communication channels in three-way
distributed collaboration,‚Äù in Proc. of the 2010 ACM Conference on
Computer Supported Cooperative Work (CSCW) , 2010, pp. 271‚Äì280.
[22] D. DeSteno, R. E. Petty, D. T. Wegener, and D. D. Rucker, ‚ÄúBeyond
valence in the perception of likelihood: The role of emotion speciÔ¨Åcity.‚Äù
Journal of Personality and Social Psychology , vol. 78, no. 3, p. 397,
2000.
[23] M. L. Kern, G. Park, J. C. Eichstaedt, H. A. Schwartz, M. Sap, L. K.
Smith, and L. H. Ungar, ‚ÄúGaining insights from social media language:
Methodologies and challenges.‚Äù Psychological methods , vol. 21, no. 4,
pp. 507‚Äì525, 2016.
[24] D. Quercia, L. Capra, and J. Crowcroft, ‚ÄúThe social world of twitter:
Topics, geography, and emotions,‚Äù in Proc. of the 6th International AAAI
Conference on Weblogs and Social Media (ICWSM) , 2012, pp. 298‚Äì305.
[25] M. Zappavigna, Discourse of Twitter and social media: How we use
language to create afÔ¨Åliation on the web . A&C Black, 2012, vol. 6.
[26] G. A. Bonanno, A. Papa, K. Lalande, M. Westphal, and K. Coifman,
‚ÄúThe importance of being Ô¨Çexible: The ability to both enhance and
suppress emotional expression predicts long-term adjustment,‚Äù Psycho-
logical science , vol. 15, no. 7, pp. 482‚Äì487, 2004.
[27] H. A. Elfenbein, ‚ÄúEmotion in organizations: a review and theoretical
integration,‚Äù The Academy of Management Annals , vol. 1, no. 1, pp.
315‚Äì386, 2007.
[28] E. Glikson and M. Erez, ‚ÄúEmotion display norms in virtual teams,‚Äù
Journal of Personnel Psychology , 2013.
[29] J. R. Kelly and S. G. Barsade, ‚ÄúMood and emotions in small groups and
work teams,‚Äù Organizational Behavior and Human Decision Processes ,
vol. 86, no. 1, pp. 99‚Äì130, 2001.
[30] E. Ostrom, ‚ÄúCollective action and the evolution of social norms,‚Äù Journal
of economic perspectives , vol. 14, no. 3, pp. 137‚Äì158, 2000.
[31] H. Koch, E. Gonzalez, and D. Leidner, ‚ÄúBridging the work/social
divide: the emotional response to organizational social networking sites,‚Äù
European Journal of Information Systems , vol. 21, no. 6, pp. 699‚Äì717,
2012.
[32] P . S. Rutner, B. C. Hardgrave, and D. H. McKnight, ‚ÄúEmotional
dissonance and the information technology professional,‚Äù MIS Quarterly ,
pp. 635‚Äì652, 2008.
[33] A. G ¬®unsel and A. Ac ¬∏ikg ¬®oz, ‚ÄúThe effects of team Ô¨Çexibility and emotional
intelligence on software development performance,‚Äù Group Decision and
Negotiation , vol. 22, no. 2, pp. 359‚Äì377, 2013.
[34] K. Crowston and J. Howison, ‚ÄúHierarchy and centralization in free and
open source software team communications,‚Äù Knowledge, Technology &
Policy , vol. 18, no. 4, pp. 65‚Äì85, 2006.
[35] M. Gharehyazie, D. Posnett, B. V asilescu, and V . Filkov, ‚ÄúDeveloper
initiation and social interactions in oss: A case study of the apache
software foundation,‚Äù Empirical Software Engineering , vol. 20, no. 5,
pp. 1318‚Äì1353, 2015.
[36] C. Casalnuovo, B. V asilescu, P . Devanbu, and V . Filkov, ‚ÄúDeveloper
onboarding in github: The role of prior social links and language
experience,‚Äù in Proc. of the 2015 10th Joint Meeting on F oundations
of Software Engineering (ESEC/FSE) , 2015, pp. 817‚Äì828.
[37] K. Wei, K. Crowston, U. Y . Eseryel, and R. Heckman, ‚ÄúRoles and
politeness behavior in community-based free/libre open source software
development,‚Äù Information & Management , vol. 54, no. 5, pp. 573‚Äì582,
2017.
240
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. [38] N. Imtiaz, J. Middleton, P . Girouard, and E. Murphy-Hill, ‚ÄúSentiment
and politeness analysis tools on developer discussions are unreliable, but
so are people,‚Äù in Proc. of the 3rd International Workshop on Emotion
Awareness in Software Engineering (SEmotion) , 2018, pp. 55‚Äì61.
[39] B. Lin, F. Zampetti, G. Bavota, M. Di Penta, M. Lanza, and R. Oliveto,
‚ÄúSentiment analysis for software engineering: How far can we go?‚Äù in
Proc. of the 40th International Conference on Software Engineering , ser.
ICSE‚Äô18, 2018, pp. 94‚Äì104.
[40] N. Novielli, F. Calefato, and F. Lanubile, ‚ÄúA gold standard for emo-
tion annotation in stack overÔ¨Çow,‚Äù in Proc. of the 15th International
Conference on Mining Software Repositories (MSR) , 2018, pp. 14‚Äì17.
[41] S. Buechel and U. Hahn, ‚ÄúEmobank: Studying the impact of annotation
perspective and representation format on dimensional emotion analysis,‚Äù
inProc. of the 15th Conference of the European Chapter of the
Association for Computational Linguistics , vol. 2, 2017, pp. 578‚Äì585.
[42] J. J. Gross, O. P . John, and J. M. Richards, ‚ÄúThe dissociation of emo-
tion expression from emotion experience: A personality perspective,‚Äù
Personality and Social Psychology Bulletin , vol. 26, no. 6, pp. 712‚Äì726,
2000.
[43] P . Ekman, ‚ÄúAn argument for basic emotions,‚Äù Cognition & emotion ,
vol. 6, no. 3-4, pp. 169‚Äì200, 1992.
[44] A. Ortony and T. J. Turner, ‚ÄúWhat‚Äôs basic about basic emotions?‚Äù
Psychological review , vol. 97, no. 3, p. 315, 1990.
[45] P . Ekman, Emotions revealed: Recognizing faces and feelings to improve
communication and emotional life . Macmillan, 2007.
[46] A. S. Cowen and D. Keltner, ‚ÄúSelf-report captures 27 distinct categories
of emotion bridged by continuous gradients,‚Äù Proc. of the National
Academy of Sciences , vol. 114, no. 38, pp. E7900‚ÄìE7909, 2017.
[47] S. M. Mohammad, F. Bravo-Marquez, M. Salameh, and S. Kiritchenko,
‚ÄúSemeval-2018 Task 1: Affect in tweets,‚Äù in Proc. of SemEval , 2018.
[48] M. Ortu, B. Adams, G. Destefanis, P . Tourani, M. Marchesi, and
R. Tonelli, ‚ÄúAre bullies more productive?: Empirical study of affective-
ness vs. issue Ô¨Åxing time,‚Äù in Proc. of the 12th Working Conference on
Mining Software Repositories (MSR) , 2015, pp. 303‚Äì313.
[49] C. Baziotis, N. Athanasiou, A. Chronopoulou, A. Kolovou,
G. Paraskevopoulos, N. Ellinas, S. Narayanan, and A. Potamianos,
‚ÄúNtua-slp at semeval-2018 task 1: Predicting affective content in tweets
with deep attentive rnns and transfer learning,‚Äù in Proc. of SemEval ,
2018, pp. 245‚Äì255.
[50] E. Diener, H. Smith, and F. Fujita, ‚ÄúThe personality structure of affect,‚Äù
Journal of Personality and Social Psychology , vol. 69, no. 1, pp. 130‚Äì
141, 1995.
[51] R. LARSON, ‚ÄúThe experience sampling method,‚Äù New Directions for
Methodology of Social & Behavioral Science , vol. 15, pp. 41‚Äì56, 1983.
[52] L. F. Barrett, ‚ÄúThe relationships among momentary emotion experiences,
personality descriptions, and retrospective ratings of emotion,‚Äù Person-
ality and Social Psychology Bulletin , vol. 23, no. 10, pp. 1100‚Äì1110,
1997.
[53] C. R ¬®ocke, C. A. Hoppmann, and P . L. Klumb, ‚ÄúCorrespondence between
retrospective and momentary ratings of positive and negative affect in
old age: Findings from a one-year measurement burst design,‚Äù Journals
of Gerontology Series B: Psychological Sciences and Social Sciences ,
vol. 66, no. 4, pp. 411‚Äì415, 2011.
[54] M. Csikszentmihalyi and R. Larson, ‚ÄúV alidity and reliability of the
experience-sampling method,‚Äù in Flow and the F oundations of Positive
Psychology . Springer, 2014, pp. 35‚Äì54.
[55] F. H. Wilhelm and P . Grossman, ‚ÄúEmotions beyond the laboratory: The-
oretical fundaments, study design, and analytic strategies for advanced
ambulatory assessment,‚Äù Biological Psychology , vol. 84, pp. 552‚Äì569,
2010.
[56] T. Miron-shatz, ‚Äúevaluating multiepisode events: boundary conditions
for the peak-end rule,‚Äù Emotion , vol. 9, no. 2, pp. 206‚Äì213, 2009.
[57] L. Flueckiger, R. Lieb, A. H. Meyer, C. Witthauer, and J. Mata, ‚ÄúThe
importance of physical activity and sleep for affect on stressful days:
Two intensive longitudinal studies,‚Äù Emotion , vol. 16, no. 4, pp. 488‚Äì
497, 2016.
[58] A. Kanavos, I. Perikos, P . Vikatos, I. Hatzilygeroudis, C. Makris, and
A. Tsakalidis, ‚ÄúConversation emotional modeling in social networks,‚Äù
in2014 IEEE 26th International Conference on Tools with ArtiÔ¨Åcial
Intelligence (ICTAI) . IEEE, 2014, pp. 478‚Äì484.
[59] R. Kempter, V . Sintsova, C. C. Musat, and P . Pu, ‚ÄúEmotionwatch:
Visualizing Ô¨Åne-grained emotions in event-related tweets.‚Äù in Proc. of
the Eighth International AAAI Conference on Weblogs and Social Media
(ICWSM) , 2014.[60] J. Zhao, L. Gou, F. Wang, and M. Zhou, ‚ÄúPearl: An interactive visual
analytic tool for understanding personal emotion style derived from
social media,‚Äù in Visual Analytics Science and Technology (VAST), 2014
IEEE Conference on . IEEE, 2014, pp. 203‚Äì212.
[61] Z. Liu, A. Xu, Y . Guo, J. U. Mahmud, H. Liu, and R. Akkiraju, ‚ÄúSeemo:
A computational approach to see emotions,‚Äù in Proc. of the 2018 CHI
Conference on Human Factors in Computing Systems (CHI) , 2018, pp.
364:1‚Äì364:12.
[62] M. R. Barrick and M. K. Mount, ‚ÄúThe big Ô¨Åve personality dimensions
and job performance: a meta-analysis,‚Äù Personnel psychology , vol. 44,
no. 1, pp. 1‚Äì26, 1991.
[63] A. Minamikawa and H. Y okoyama, ‚ÄúBlog tells what kind of personality
you have: Egogram estimation from japanese weblog,‚Äù in Proc. of
the ACM 2011 Conference on Computer Supported Cooperative Work
(CSCW) , 2011, pp. 217‚Äì220.
[64] O. Nov and O. Arazy, ‚ÄúPersonality-targeted design: Theory, experimen-
tal procedure, and preliminary results,‚Äù in Proc. of the 2013 Conference
on Computer Supported Cooperative Work (CSCW) , 2013, pp. 977‚Äì984.
[65] M. Yilmaz, R. V . O?Connor, R. Colomo-Palacios, and P . Clarke, ‚ÄúAn
examination of personality traits and how they impact on software
development teams,‚Äù Information and Software Technology , vol. 86, pp.
101‚Äì122, 2017.
[66] O. P . John and S. Srivastava, ‚ÄúThe big Ô¨Åve trait taxonomy: History,
measurement, and theoretical perspectives,‚Äù Handbook of personality:
Theory and research , vol. 2, no. 1999, pp. 102‚Äì138, 1999.
[67] P . Desmet, ‚ÄúMeasuring emotion: Development and application of an
instrument to measure emotional responses to products,‚Äù in Funology 2 .
Springer, 2018, pp. 391‚Äì404.
[68] E. L. Rosenberg and P . Ekman, ‚ÄúCoherence between expressive and
experiential systems in emotion,‚Äù Cognition & Emotion , vol. 8, no. 3,
pp. 201‚Äì229, 1994.
[69] A. Wolf, ‚ÄúEmotional expression online: Gender differences in emoticon
use,‚Äù CyberPsychology & Behavior , vol. 3, no. 5, pp. 827‚Äì833, 2000.
[70] M. Eid and E. Diener, ‚ÄúNorms for experiencing emotions in different
cultures: Inter-and intranational differences,‚Äù in Culture and Well-Being .
Springer, 2009, pp. 169‚Äì202.
[71] D. A. Kenny and L. La V oie, ‚ÄúSeparating individual and group effects.‚Äù
Journal of Personality and Social Psychology , vol. 48, no. 2, p. 339,
1985.
[72] L. R. James, R. G. Demaree, and G. Wolf, ‚ÄúEstimating within-group
interrater reliability with and without response bias.‚Äù Journal of applied
psychology , vol. 69, no. 1, p. 85, 1984.
[73] T. Segaran and J. Hammerbacher, Beautiful data: the stories behind
elegant data solutions . ‚Äù O‚ÄôReilly Media, Inc.‚Äù, 2009.
[74] S. M. Mohammad and S. Kiritchenko, ‚ÄúUnderstanding emotions: A
dataset of tweets to study interactions between affect categories,‚Äù in
Proc. of the 11th Language Resources and Evaluation Conference
(LREC) , 2018.
[75] S. M. Mohammad, ‚ÄúWord affect intensities,‚Äù in Proc. of the 11th
Language Resources and Evaluation Conference (LREC) , 2018.
[76] R. M. Sabou, K. Bontcheva, L. Derczynski, and A. Scharl, ‚ÄúCorpus
annotation through crowdsourcing:towards best practice guidelines,‚Äù in
Proc. of the 9th International Conference on Language Resources and
Evaluation (LREC) , 2014.
[77] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
‚ÄúDistributed representations of words and phrases and their composi-
tionality,‚Äù in Advances in Neural Information Processing Systems 26 .
Curran Associates, Inc., 2013, pp. 3111‚Äì3119.
[78] A. Ng, Machine learning yearning . mlyearning.org, 2017.
[79] R Development Core Team, R: A Language and Environment for
Statistical Computing , R Foundation for Statistical Computing, Vienna,
Austria, 2008.
[80] R. L. Wasserstein and N. A. Lazar, ‚ÄúThe asa‚Äôs statement on p-values:
Context, process, and purpose,‚Äù The American Statistician , vol. 70, no. 2,
pp. 129‚Äì133, 2016.
[81] M. P . Murray, ‚ÄúA drunk and her dog: an illustration of cointegration and
error correction,‚Äù The American Statistician , vol. 48, no. 1, pp. 37‚Äì39,
1994.
[82] R. F. Engle and C. W. Granger, ‚ÄúCo-integration and error correction:
representation, estimation, and testing,‚Äù Econometrica: Journal of the
Econometric Society , pp. 251‚Äì276, 1987.
[83] A. Trapletti and K. Hornik, tseries: Time Series Analysis and Compu-
tational Finance , 2018.
241
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. [84] A. A. Grandey, ‚ÄúEmotional regulation in the workplace: A new way
to conceptualize emotional labor.‚Äù Journal of Occupational Health
Psychology , vol. 5, no. 1, pp. 95‚Äì110, 2000.
[85] J. Averill, Anger and Aggression: An Essay on Emotion , 2012.
[86] C. Thimm and L. Kruse, ‚ÄúThe power-emotion relationship in discourse:
Spontaneous expression of emotions in asymmetric dialogue,‚Äù Journal
of language and social psychology , vol. 12, no. 1-2, pp. 81‚Äì102, 1993.
[87] L. I. Trierweiler, M. Eid, and T. Lischetzke, ‚ÄúThe structure of emotional
expressivity: Each emotion counts.‚Äù Journal of Personality and Social
Psychology , vol. 82, no. 6, p. 1023, 2002.[88] S. L. Koole, W. Jager, A. E. van den Berg, C. A. Vlek, and W. K.
Hofstee, ‚ÄúOn the social nature of personality: Effects of extraversion,
agreeableness, and feedback about collective resource use on cooperation
in a resource dilemma,‚Äù Personality and Social Psychology Bulletin ,
vol. 27, no. 3, pp. 289‚Äì301, 2001.
[89] J. Chen, E. M. Haber, R. Kang, G. Hsieh, and J. Mahmud, ‚ÄúMaking
use of derived personality: The case of social media ad targeting.‚Äù in
AAAI International Conferences on Weblog and Social Media (ICWSM) ,
2015, pp. 51‚Äì60.
242
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 12:24:30 UTC from IEEE Xplore.  Restrictions apply. 