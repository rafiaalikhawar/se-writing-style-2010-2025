SLF: Fuzzing without Valid Seed Inputs
Wei You1, Xuwei Liu2, Shiqing Ma1, David Perry1, Xiangyu Zhang1, Bin Liang3
1Department of Computer Science, Purdue University, Indiana, USA
2School of Computer Science and Technology, Zhejiang University, Zhejiang, China
3School of Information, Renmin University of China, Beijing, China
Email:{you58, ma229, perry74, xyzhang }@purdue.edu, xuweiliu@zju.edu.cn, liangb@ruc.edu.cn
Abstract ‚ÄîFuzzing is an important technique to detect software
bugs and vulnerabilities. It works by mutating a small set
of seed inputs to generate a large number of new inputs.
Fuzzers‚Äô performance often substantially degrades when valid
seed inputs are not available. Although existing techniques such
as symbolic execution can generate seed inputs from scratch,
they have various limitations hindering their applications in
real-world complex software. In this paper, we propose a novel
fuzzing technique that features the capability of generating valid
seed inputs. It piggy-backs on AFL to identify input validity
checks and the input Ô¨Åelds that have impact on such checks.
It further classiÔ¨Åes these checks according to their relations to
the input. Such classes include arithmetic relation, object offset,
data structure length and so on. A multi-goal search algorithm
is developed to apply class-speciÔ¨Åc mutations in order to satisfy
inter-dependent checks all together. We evaluate our technique
on 20 popular benchmark programs collected from other fuzzing
projects and the Google fuzzer test suite, and compare it with
existing fuzzers AFL and AFLFast, symbolic execution engines
KLEE and S2E, and a hybrid tool Driller that combines fuzzing
with symbolic execution. The results show that our technique is
highly effective and efÔ¨Åcient, out-performing the other tools.
I. I NTRODUCTION
Fuzzing is a commonly used technique to discover software
bugs and vulnerabilities. It derives a large number of new
inputs from some initial inputs called seed inputs , using
mutations guided by various heuristics with a certain degree
of randomness. It usually does not rely on complex program
analysis or even source code, and hence features applicability.
Many existing CVE reports were generated by fuzzing tech-
niques [ 1], [2].
Valid seed inputs play a critical role in fuzzing. However,
there are situations that seed inputs are not available or the
available seed inputs may not cover important input formats.
The former situation occurs for software that does not come
with inputs or input speciÔ¨Åcation (e.g., those downloaded from
the Internet, third-party libraries, or even malicious code).
The latter situation arises for software that supports many
formats (including even non-standard/undocumented formats).
Some software implementations may not fully respect docu-
mented speciÔ¨Åcation, leading to implementation-speciÔ¨Åc input
formats. They are unlikely to be represented in seed inputs.
We will show in Section IV-B that a mutated TIFF format is
uniquely supported by Exiv2 but completely undocumented.
In fact, some CVEs (e.g., CVE-2010-3269 [ 3] and CVE-
2016-4655 [ 4]) were discovered with inputs of undocumented
format.Hence, there is a strong need to fuzz software without
requiring valid seed inputs. While most fuzzing techniques
can operate without a valid seed input, they have to compose
valid inputs from scratch through a more-or-less random
search procedure such as random growth of the input length
and random bit Ô¨Çipping, which have limited capabilities in
generating valid inputs due to the large search space.
There are learning based techniques that aim to derive input
speciÔ¨Åcation from a large number of training inputs [ 5], [6].
They require the training set to have comprehensive coverage
of input speciÔ¨Åcation. Such an assumption is difÔ¨Åcult to meet
in practice. Moreover, as we discussed earlier, many inputs
even have non-standard, undocumented, implementation spe-
ciÔ¨Åc formats. There are reverse-engineering techniques such
as TIE [ 7] or REWARD [ 8] that can derive the grammatical
structure of an input by monitoring program execution on the
input. They hardly generate the entire input speciÔ¨Åcation but
rather the syntactical structure of individual concrete inputs.
Symbolic execution is a highly effective testing technique
that can generate inputs from scratch [ 9]‚Äì[13]. Despite its
effectiveness in unit testing, applying symbolic execution to
whole system testing has a number of practical hindrances.
For example, a lot of libraries need to be manually modeled;
inputs with nontrivial formats often involve operations that
are difÔ¨Åcult for symbolic execution engines such as those
in checksum computation; and many input validity checks
require reasoning about the offsets, counts, and length of
input Ô¨Åelds, which are difÔ¨Åcult for most symbolic execution
engines. There are proposals to use gradients to guide fuzzing
to provide the abilities of resolving path conditions in a non-
random fashion [ 14]; and to combine symbolic execution and
fuzzing [ 15]. However, they do not focus on solving the
problem of generating valid seed inputs and hence still have
the aforementioned limitations in our target setting.
In this paper, we develop a novel fuzzing technique SLF
(stands for Seedless Fuzzer ) that features valid seed input
generation. It is fuzzing based and hence has the beneÔ¨Åts
of applicability. It does not require source code, nor does
it rely on complex program analysis. Its operation is largely
piggy-backing on regular fuzzing. SpeciÔ¨Åcally, it starts with
a very short random input (e.g., 4 bytes), which quickly fails
some validity check. SLF then performs sophisticated input
mutation to get through these validity checks until a valid seed
input is generated, which is further subject to regular fuzzing.
To get through validity checks, it Ô¨Årst groups inputs into
7122019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
1558-1225/19/$31.00 ¬©2019 IEEE
DOI 10.1109/ICSE.2019.00080
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply.           0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
00000000h 50 4B 03 04 00 00 00 00 00 00 00 00 00 00 53 FC
00000010h 51 67 02 00 00 00 02 00 00 00 02 00 00 00 31 31
00000020h 31 0A 50 4B 01 02 00 00 00 00 00 00 00 00 00 00
00000030h 00 00 53 FC 51 67 02 00 00 00 02 00 00 00 02 00 
00000040h 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 
00000050h 31 31 50 4B 05 06 00 00 00 00 01 00 01 00 30 00 
00000060h 00 00 22 00 00 00 02 00 31 31Local File Header
(lfh)
Central Directory Header
(cdh)
End of Central Directory
(eocd)50 4B 05 06 00 00 00 00 01 00 01 00 30 00 00 00 22 00 00 00 02 00 31 3150 4B 01 02 00 00       02 00       00 00 00 00 31 31 ¬∑¬∑¬∑¬∑¬∑¬∑ ¬∑¬∑¬∑¬∑¬∑¬∑50 4B 03 04       53 FC 51 67 02 00 00 00 02 00 00 00        31 0A ¬∑¬∑¬∑¬∑¬∑¬∑ ¬∑¬∑¬∑¬∑¬∑¬∑CRC-32
checksumdata size
(compressed)data size
(uncompressed)
MAGIC_EOCD cd_size cd_offfname_len lfh_off
nentry_cur nentry_allfile_name
cmt_lencommentdata_off
eocd_off cmt_off
Fig. 1: A valid ZIP archive Ô¨Åle.
Ô¨Åelds by observing how consecutive bytes inÔ¨Çuence individual
checks. Such information can be extracted from the underlying
fuzzing infrastructure, which is AFL [ 16] in our case. It then
classiÔ¨Åes the checks based on their relations with the input, by
observing the state differences at the checks caused by a pre-
deÔ¨Åned set of mutations. For example, some checks concern
the values of individual input Ô¨Åelds while others test the
offset/count of speciÔ¨Åc Ô¨Åelds. Such category information can
be used as guidance in applying the corresponding mutations.
In practice, multiple validity checks are often inter-dependent
by predicating on a same variable or multiple variables derived
from the same input Ô¨Åelds. As part of SLF, we develop a search
algorithm that can mutate input in a way to satisfy the inter-
dependent checks.
We evaluate SLF on 20 real-world programs collected from
the existing fuzzing projects [ 17], [18] and the standard Google
fuzzer test suite [ 19] and compare it with existing fuzzers
(AFL [ 16] and AFLFast [ 20]), symbolic execution engines
(KLEE [ 9] and S2E [ 13]), and a combination of fuzzing and
symbolic execution (Driller [ 15]). Our results show that SLF
is highly effective and efÔ¨Åcient. It can handle many more cases
than the other techniques, and generate 7.3 times more valid
seed inputs and cover 3.5 times more paths on average.
We make the following contributions.
‚Ä¢We propose a novel fuzzing technique that can effec-
tively generate valid seed inputs. The technique is piggy-
backing on AFL and does not require any complex
program analysis or even source code.
‚Ä¢We develop various supporting techniques, such as group-
ing input bytes to Ô¨Åelds; detecting inter-dependent input
validity checks; and a search algorithm to satisfy these
checks together.
‚Ä¢We propose a classiÔ¨Åcation of input validity checks based
on their relations with input elements. We also develop
the corresponding mutation strategies.
II. M OTIV ATION
We use LibZip [ 21] to explain the limitations of existing
techniques (e.g., mutation-based fuzzing and symbolic execu-
tion) and motivate the idea of SLF. LibZip is an open-source
library that reads, creates and modiÔ¨Åes ZIP archives. It is
widely integrated in commodity software, such as PDF readers
and SQL databases, for data compression and decompression.
ZIP File Format . ZIP is one of the most popular compressed
Ô¨Åle formats [ 22]. A ZIP archive must contain an ‚Äúend of central
directory‚Äù ( eocd for short) structure located at the end of the
Ô¨Åle (e.g., bytes in black at the index 0x52-69 in Figure 1).Each Ô¨Åle stored in a ZIP archive is described by a ‚Äúlocal Ô¨Åle
header‚Äù ( lfh) structure, which records the basic information
about the Ô¨Åle, such as data size and CRC-32 checksum (e.g.,
the bytes in gray at index 0x00-1F). The Ô¨Åle data is placed after
the local Ô¨Åle header (index 0x20-21). For ease of indexing,
each Ô¨Åle is accompanied with a record of ‚Äúcentral directory
header‚Äù ( cdh), which indicates the offset of the corresponding
lfh and is located in a central place of the archive together
with the cdh records of other Ô¨Åles (e.g., plain bytes at 0x22-
51 pointing to the aforementioned lfh). The eocd holds a
pointer pointing to the cdh section. Note that the valid ZIP
Ô¨Åle in Figure 1is generated by our tool from scratch.
Assume that we are using LibZip to read the content of a
speciÔ¨Åed Ô¨Åle in a given ZIP archive. LibZip Ô¨Årst identiÔ¨Åes the
eocd structure, from which it can locate the cdh records.
It then iterates through the individual records until the one
for the speciÔ¨Åed Ô¨Åle is found. Finally, the corresponding lfh
structure is accessed and the Ô¨Åle data is extracted. During the
process, LibZip performs multiple checks on different Ô¨Åelds
of the input Ô¨Åle to ensure validity of the archive. If any
check fails, the process is terminated. Figure 2presents some
critical checks. Check a/circlecopyrtensures the input Ô¨Åle has enough
length to hold an eocd structure. Check b/circlecopyrtsearches for the
magic number of eocd structure in the input Ô¨Åle. If found, its
offset is recorded in the eocd offvariable. After that, LibZip
examines whether the number of cdh records on the current
disk equals to the the total number of cdh records (check
c/circlecopyrt) and whether it is larger than the index of the speciÔ¨Åed
Ô¨Åle (check d/circlecopyrt)1. Subsequently, the size ( cd size) and offset
(cd off) of the cdh section are extracted from the input
Ô¨Åle at the offset eocd off+12 and eocd off+16, respectively
(e.g., indices 0x5E-61 and 0x62-65 in Figure 1). Then, LibZip
checks whether the cdh section overlaps with the eocd
structure (check e/circlecopyrt) and whether its size is larger than the
default (minimal) size of a cdh record (check f/circlecopyrt). Next,
LibZip gets the length of the comment string ( cmt len) and
checks whether it equals to the length of the remaining data
(check g/circlecopyrt). Finally, the integrity of the archive is inspected
by comparing the computed CRC-32 checksum with the one
stored in the archive (check h/circlecopyrt).
Mutation-based Fuzzing . Mutation-based fuzzing [ 16], [17],
[20] or fuzzing in short generates inputs by modifying valid
seed inputs. Although many fuzzing techniques can operate
without a valid seed input, their effectiveness often substan-
1Note that LibZip does not support cross-disk zip archive and check c/circlecopyrt
ensures the condition is satisÔ¨Åed. SPECIFIED INDEX in check d/circlecopyrtis a
command line parameter that indicates the index of the Ô¨Åle to be accessed.
713
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. 01int file_size =size_of_file();
02char *buf =read_from_file();
03int min_size =is_zip64(buf) ?SIZE_EOCD64:SIZE_EOCD;
04if(file_size <min_size) error(); a/circlecopyrt
05int eocd_off =0;
06while (memcmp(buf +eocd_off, MAGIC_EOCD, 4)!= 0 )
07 eocd_off ++; b/circlecopyrt
08if(eocd_off >file_size) error();
09int nentry_cur =read_buffer16(buff, eocd_off +8);
10int nentry_all =read_buffer16(buff, eocd_off +1 0 );
11if(nentry_cur !=nentry_all) error(); c/circlecopyrt
12if(nentry_cur <=SPECIFIED_INDEX) error(); d/circlecopyrt
13int cd_size =read_buffer32(buf, eocd_off +1 2 );
14int cd_off =read_buffer32(buf, eocd_off +1 6 );
15if(cd_size +cd_off >eocd_off) error(); e/circlecopyrt
16if(cd_size <SIZE_CDH) error(); f/circlecopyrt
17int cmt_len =read_buffer16(buf, eocd_off +2 0 );
18int tail_len =buffer_left(buf);
19if(cmt_len !=tail_len) error(); g/circlecopyrt
20int crc_cmp =compute_crc(buf, data_off, data_size);
21int crc_str =read_buffer32(buf, lfh_off +1 4 );
22if(crc_cmp !=crc_str) error(); h/circlecopyrt
Fig. 2: Critical validation checks of LibZip.
tially degrades. While some checks in Figure 2can be satisÔ¨Åed
by random mutation with dictionary (e.g., checks a/circlecopyrtand b/circlecopyrt),
other checks are very difÔ¨Åcult to satisfy. For example, check
g/circlecopyrtconstrains the Ô¨Åle size with a value extracted from the input
Ô¨Åle. Randomly mutating the input bytes or extending the Ô¨Åle
size are unlikely to satisfy the check. In fact, both AFL [ 16]
and AFLFast [ 20] would get stuck at similar checks.
To overcome some of these difÔ¨Åculties, Angora [ 14] en-
hances fuzzing with gradient guided mutation, which considers
a path condition as a black-box function on inputs and searches
for input valuations that satisfy the condition. It uses taint
analysis to identify the input bytes that affect a predicate,
observes the changes on the predicate after mutating the
identiÔ¨Åed bytes to derive the direction for changes (i.e., if/how-
signiÔ¨Åcant individual input changes impact the comparison at
the predicate), and performs further mutations accordingly.
Although achieving substantial improvement over random
fuzzing, it has inherent limitations in satisfying multiple path
conditions involving the same variable. For example, when
computing the gradient for satisfying check d/circlecopyrt, Angora only
tries to change the value of nentry curwithout keeping it
equal to nentry all, which is required by check c/circlecopyrt. In such
cases, Angora could hardly Ô¨Ånd the direction of input changes.
Symbolic Execution . Symbolic execution [ 9]‚Äì[13] uses sym-
bolic variables to denote individual input elements and then
constructs symbolic constraints (i.e., formulas involving sym-
bolic variables) to represent the conditions that need to satisfy
in order to explore various program paths. Concrete inputs are
derived by solving these constraints. While symbolic execution
can generate seed inputs from scratch and handle non-trivial
arithmetic/logic relations across multiple input elements, it has
limitations in dealing with other relations commonly present incomplex real world programs. Particularly, arithmetic relations
are often induced by data dependencies, and resolving con-
straints on such relations requires reasoning about input value
changes, which symbolic execution is very good at. However,
in practice there are other more subtle correlations pertain
to Ô¨Åeld offset, and Ô¨Åle/Ô¨Åeld length, which require reasoning
about Ô¨Åelds relocation, length variation, and Ô¨Åelds removal
and duplication.
Consider check e/circlecopyrt, whose left-hand side ( lhs) is affected
by the values ( cd size and cd off) extracted from the input
Ô¨Åle, and the right-hand side ( rhs) affected by the offset
(eocd off) which is not derived from input bytes through
arithmetic operations, but rather from the branch outcomes
of loop predicate at line 06. Such a check can be satisÔ¨Åed by
either decreasing the lhs value or increasing the rhs value. In
general, it is difÔ¨Åcult for symbolic execution to directly reason-
about/mutate the value of eocd off. Hence, it is more likely
that the lhs variables are set to a small value to satisfy check
e/circlecopyrt. This would result in the failure of check f/circlecopyrt. In fact, we
used KLEE to symbolically execute LibZip for 24 hours and
found that check f/circlecopyrtis always unsatisÔ¨Åable, preventing KLEE
from further path exploration.
There has been proposal to use symbolic variables to model
loop counts and then leverage program analysis to identify
linear relations between loop count variables and input features
such as length [ 23]. While modeling linear relations between
loop count and input length is particularly effective in reason-
ing about length changes to overÔ¨Çow buffers, such relations are
only one kind of the non-arithmetic/non-logical relations. For
example, it cannot handle the relation involving eocd off
in check e/circlecopyrt, which denotes the offset of a particular input Ô¨Åeld
instead of simple length.
Symbolic execution also has difÔ¨Åculty in modeling con-
straints derived from complex computation such as those
involved in checksum (e.g., check h/circlecopyrt). In addition, many
symbolic execution tools require generating models for library
calls, entailing substantial manual efforts in practice.
Our Technique . We develop a novel fuzzing technique SLF
that can effectively generate valid seed inputs from scratch.
It is mutation fuzzing based so that it inherits the beneÔ¨Åts
of fuzzing. In addition, it overcomes the limitation of existing
fuzzing techniques regarding seed input reliance and is capable
of effectively composing valid seed inputs. SLF is inspired by
two important observations. First, input validation checks can
be classiÔ¨Åed into a number of categories, each correspond-
ing to speciÔ¨Åc input relations and entailing unique mutation
strategies. In our classiÔ¨Åcation, gradient guided fuzzing [ 14]
and symbolic execution are good at certain categories but not
sufÔ¨Åciently general to deal with all the categories. Second,
the categories can be effectively detected during fuzzing by
mutating input bytes in pre-deÔ¨Åned fashions and observing
the changes at predicates. Such runtime detection can pig-
gyback on a vanilla fuzzing infrastructure such as AFL. Our
technique does not require any heavy-weight analysis such as
taint-analysis. For example, by monitoring check e/circlecopyrt,w ec a n
714
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. GBJMJOH  Dheck? Mutation Execution Oew Doverage?select an input
Ninsert mutated input to input queue
AFL Fuzzing
mutated input path coverage Yinput queue
Input Field
%FUFDUJPOValidation Check
ClassificationInterdependence
IdentificationMultigoal 
4earch
FieldInfoSLF
TypeInfofield0 field1check‚°çcheck‚°écheck‚°è
DepInfo seedsinsert seeds to input queue
Check Category Info
type I field4‚Ä¶‚Ä¶‚°é
Fig. 3: Overview of SLF.
observe that the value of the lhs variable changes if we mutate
certain input bytes, indicating likely arithmetic/logic relations,
and the value of rhs changes if we add extra bytes to the head
of input Ô¨Åle, indicating index-of relations.
Based on the observations, we develop SLF. It starts from a
random input of a few bytes. While the input most likely fails
some validation check very shortly after the execution starts,
our technique mutates the input and observes how the predicate
corresponding to the check changes. This is to determine
the category of the check and the correlated input byte(s).
Based on the type of check, it applies the corresponding
mutation/search strategy. It is very common that the input
bytes that are identiÔ¨Åed as inÔ¨Çuencing the check may involve
in some preceding checks that the execution has succeeded. As
such, mutating them may lead to undesirable failures at those
preceding checks. SLF features the capabilities of detecting
inter-dependent checks that may be affected by mutating the
same input bytes, and a multi-goal gradient guided search
algorithm that aims to satisfy all these checks.
For our motivation example, our tool starts with a 4-byte
random input, within 15 minutes, it generates a valid seed
input as shown in Figure 1that passes all the input validation
checks. In 24 hours, it generates 7 valid seed inputs, which
are further leveraged by regular fuzzing to cover 210 paths.
In contrast, neither KLEE nor AFL generates any valid input.
None of the test cases generated by KLEE can pass through
check f/circlecopyrt. AFL does not pass through check f/circlecopyrteither. Most
of the paths explored by AFL are exception-handling code.
The comparison with other tools such as S2E, AFLFast, and
Driller shows similar improvement (see Section IV-B ).
III. D ESIGN
A. Overview
Figure 3presents the overview of SLF, which is built on top
of AFL. It consists of the following components. The Ô¨Årst one
is an input Ô¨Åeld detection component that groups input bytes
to Ô¨Åelds. This allows mutation to be performed at the unit of
Ô¨Åelds instead of bytes. The second one is a validation check
classiÔ¨Åcation component, which detects the types of validation
checks in the current execution. The third one is an inter-
dependence identiÔ¨Åcation component, which identiÔ¨Åes all the
preceding checks that have inter-dependencies with the checkthat fails the current execution. Based on the results from the
second and third components, the forth component, a multi-
goal gradient-based search algorithm performs corresponding
mutations to satisfy all the inter-dependent checks.
The overall procedure of SLF is presented in Algorithm 1.
The input queue is initialized with a randomly-generated 4-
bytes input (lines 1-2). In the main loop, SLF executes the
target program with the current input (line 4), analyzing the
encountered checks and error information to identify the check
that fails the execution (line 5). If no validation failure is
found, which indicates the current input is well-formed, SLF
switches to regular AFL fuzzing (line 13). Otherwise, SLF
tries to get through the failed check as follows.
First, it groups input bytes into Ô¨Åelds (line 7). This is
achieved by observing how the mutation of individual bytes
affects the encountered checks. Consecutive bytes whose mu-
tation affects the same set of checks are grouped to an input
Ô¨Åeld, as detailed in Section III-B . Given the Ô¨Åeld information,
SLF then classiÔ¨Åes the encountered checks (line 8), by mutat-
ing input Ô¨Åelds in predeÔ¨Åned manners (e.g. Ô¨Çipping input Ô¨Åeld
value and duplicating input Ô¨Åeld), as detailed in Section III-D .
After that, SLF identiÔ¨Åes all the checks that are correlated to
the failed check, that is, they are inÔ¨Çuenced by the same input
Ô¨Åeld(s) (Section III-E ). A multi-goal search algorithm is then
applied to satisfy these checks (Section III-F ). Finally, if SFL
succeeds in generating valid seeds, it adds them to the input
queue for further processing.
SLF does not require source code. It runs the program
executable on a modiÔ¨Åed QEMU to monitor the lhs and rhs
values of cmp andtest instructions that correspond to the
conditional jump instructions.
B. Input Field Detection
The goal of input Ô¨Åeld detection is to group consecutive
bytes that affect the same set of checks to a Ô¨Åeld. Algo-
rithm 2describes the process. We Ô¨Årst execute the target
program over the given input and collect the information of
the encountered checks including their lhs and rhs values,
denoted as CheckInfo (line 2). Then we Ô¨Çip each input
byte (line 5), that is, Ô¨Çipping individual bits in the byte, and
execute the target program over the Ô¨Çipped input to collect
new check information, denoted as CheckInfo/prime(line 6). By
715
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. Algorithm 1: SLF‚Äôs fuzzing loop.
1ifInputQueue =‚àÖthen
2InputQueue ‚Üê{RandomBytes (4)}
3forinput‚ààInputQueue do
4CheckInfo ‚ÜêRunProgram (input )
5fcheck‚ÜêGetFailingCheck (CheckInfo )
6 iffcheck/negationslash=null then
7 FieldInfo ‚ÜêGroupBytes (input )
8 TypeInfo ‚ÜêClassifyChecks (input,FieldInfo )
9 DepInfo ‚ÜêGetDependents (fcheck,TypeInfo )
10 seeds‚Üê
MultiGoalSearch (fcheck,TypeInfo,DepInfo )
11 ifseeds/negationslash=null then
12 AddToQueue (InputQueue,seeds )
13AFLFuzzing (program,input )
0x5C 0x5E
¬∑¬∑¬∑ ¬∑¬∑¬∑01 00 30 00 00 00 ¬∑¬∑¬∑ ¬∑¬∑¬∑01 00 E1 00 00 00flip byte 0x5C
flip byte 0x5E¬∑¬∑¬∑ ¬∑¬∑¬∑FE 00 30 00 00 00
lhs
0x6A
0x52
0x01
0x01
0x52
0x30rhs
0x16
0x6A
0x01
0x01
0x52
0x…©Check lhs
0x6A
0x52
0x01rhs
0x16
0x6A
0xFECheck
¬∑¬∑¬∑¬∑¬∑¬∑lhs
0x6A
0x52
0x01
0x01
0x103rhs
0x16
0x6A
0x01
0x00
0x52Check,QSXW
&KHFN,QIR
¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑
≈ø¬É∆Ä ≈ø¬Ñ∆Ä ≈ø¬Ö∆Ä
Fig. 4: Example of input bytes grouping.
comparing the difference of CheckInfo andCheckInfo/prime,
we can identify those checks that appear in both executions
and have different lhs or rhs values (line 7). The two pieces
of information are aligned based on the program counters. If
the difference caused by Ô¨Çipping the current byte is the same
as that of the previous byte, they are grouped together (line
9). Otherwise, a new Ô¨Åeld is created (line 11). Note that in the
case where bytes [i-1, i] affect one check and bytes [i, i+1]
affect another, SLF treats each byte as a separate group, since
they have different affected check sets.
Figure 4illustrates how the bytes at index 0x5C-61 are
grouped. Figure 4a shows the CheckInfo of the execution
on the input, which records the lhs and rhs values of the
encountered checks. Particularly, the rhs value of check c/circlecopyrt
is 0x01 and the lhs value of check e/circlecopyrtis 0x52. After Ô¨Çipping
the byte at 0x5C, the CheckInfo/primeof the mutated execution
is shown in Figure 4b. The difference between CheckInfo
andCheckInfo/primeis that the rhs value of check c/circlecopyrtchanges.
Similarly, after Ô¨Çipping the byte at 0x5D, we get the same
difference. In contrast, Ô¨Çipping the byte at 0x5E results in the
difference at the lhs value of check e/circlecopyrt. Hence, we group the
bytes at 0x5C-5D as a Ô¨Åeld and byte 0x5E starts a new Ô¨Åeld.
An important feature of the algorithm is that it does not require
the input to be a valid one to begin with.
C. Input V alidation Check ClassiÔ¨Åcation
To facilitate discussion, we introduce a language to model
input validation checks, which allows us to classify such
checks based on the underlying relations with input elements.
Figure 5shows the syntax of the language. For simplicity,
the language operates at individual input bytes (while ourAlgorithm 2: GroupBytes (input ): input Ô¨Åeld grouping.
1FieldInfo ‚Üê[]
2CheckInfo ‚ÜêRunProgram (input )
3CheckDiffPrv ‚Üê‚àÖ
4forbyte‚Üê0tolen(input )do
5input/prime‚ÜêFlipByte (input,byte )
6CheckInfo/prime‚ÜêRunProgram (input/prime)
7CheckDiffCur ‚ÜêDiff (CheckInfo,CheckInfo/prime)
8 ifCheckDiffCur =CheckDiffPrv then
9 FieldInfo ‚ÜêUpdateLastGroup (FieldInfo,byte )
10 else
11 FieldInfo ‚ÜêNewGroup (FieldInfo )
12 CheckDiffPrv ‚ÜêCheckDiffCur
/angbracketleftExpression /angbracketright e::=input [lb,ub ]|c|x
|e1binope2|e1relope2
|F(e0)|ITE(ep,et,ef)
|count (input [lb,ub ],ep)
|indexOf (input [lb,ub ],ep)
/angbracketleftCheck/angbracketright C::= assert (e)
/angbracketleftInput/angbracketright input ::= byte‚ãÜ
/angbracketleftConstant/angbracketright c::={‚Äòtrue‚Äô,‚Äòfalse‚Äô ,0,1,...}
/angbracketleftBinOperator /angbracketrightbinop ::= +|‚àí |‚àó | /|...
/angbracketleftRelOperator /angbracketrightrelop ::= ==|!=|>|...
Fig. 5: Language
implementation deals with Ô¨Åelds). We use input [lb, ub ]with
lbthe lower bound and ubthe upper bound to denote an input
segment. Note that input [0,l e n(input )]denotes the entire
input. Observe that an expression could be an input segment,
a constant, a variable xwhose use will be explained later
in this paragraph, binary arithmetic operation and relational
operation of expressions, a function F()on a parameter e0to
denote an uninterpreted function whose internals are not vis-
ible/understandable, an If-Then-Else (ITE) expression whose
value may be etoref, depending on if epis true, a count()
primitive that counts the number of cases in an input segment
that satisfy a condition ep, and an indexOf() primitive that
identiÔ¨Åes the offset of the Ô¨Årst case that satisÔ¨Åes ep. Variable
xis used in epto denote some byte in the given input segment.
For example, count (input [0,l e n(input )],x > 10)counts all
the input bytes whose value is larger than 10. A validation
check asserts an expression to be true. Note that we do not
model program variables in our language and expressions are
essentially formulas on input segments and constants.
The language is expressive to describe most of the
validation checks we have observed in our subject pro-
grams. For example, check h/circlecopyrtis an instance of F(),
where Fstands for the checksum function that a sym-
bolic execution tool has difÔ¨Åculty modeling. Other exam-
ples of F()include libraries without source code. Expression
count (input [cmt off, len (input )],t r u e )models the predi-
cate variable tail lenin check g/circlecopyrt, which counts the bytes from
the comment offset ( cmt off) to the end of Ô¨Åle. Expression
indexOf (input [0,l e n(input )],x == MAGIC EOCD )
models the eocd offpredicate variable in check b/circlecopyrt, which
means to Ô¨Ånd the offset of the eocd magic number.
The formalization allows us to classify validation checks. In
716
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. Algorithm 3: ClassifyChecks (input, F ieldInfo ): de-
tecting check types.
1TypeInfo ‚Üê[]
2CheckInfo ‚ÜêRunProgram (input )
3forfield‚ààFieldInfo do
4 fortype‚ààTypeList do
5 policy‚ÜêGetDetectPolicy (type )
6 input/prime‚ÜêEnforcePolicy (input,policy )
7 CheckInfo/prime‚ÜêRunProgram (input/prime)
8 CheckDiff ‚ÜêDiff (CheckInfo,CheckInfo/prime)
9 forcheck‚ààCheckDiff do
10 ifMatchPolicy (check,policy )then
11 info‚ÜêClassifyType (check,type )
12 TypeInfo [check ]‚Üêinfo
the following, we discuss four most popular categories, each
corresponding to some form of expression. The classiÔ¨Åcation
is designed in a way to facilitate later fuzzing.
Type I: Arithmetic Check. If the variables involved in a
check are derived from input bytes through only the arithmetic
operations (e.g., the binop in our language), the check is
a type I arithmetic check. Symbolic execution is particularly
good at satisfying type I checks. Gradient based fuzzing [ 14]
is also good when there are no other inter-dependent checks.
Checks c/circlecopyrtand d/circlecopyrtin Figure 2are type I checks.
Type II: Index/Offset Check. Index checks have the form of
assert (indexOf (input [lb, ub ],ep)relop e 0)that compares
the offset of the Ô¨Årst case satisfying epin the given input
segment with another expression e0. They are also quite
common but difÔ¨Åcult to satisfy by existing techniques. Check
e/circlecopyrtin Figure 2is a type II check.
Type III: Count Check. Count checks have the form of
assert (count (input [lb, ub ],ep)relop e 0)that compares the
number of cases satisfying epin the given input segment with
an expression e0. All the length checks, checks that count
the number of data structures/objects, fall into this category.
They are commonly present but difÔ¨Åcult to satisfy by existing
techniques. Check g/circlecopyrtin Figure 2is a type III check.
Type IV: ITE Check. ITE checks have the form of
assert (ITE (ep,et,ef)relop e 0), in which epis an expres-
sion that are based on input bytes through only arithmetic
operations. Check a/circlecopyrtin Figure 2is a type IV check. Observe
that the result of the check has control dependence on the input
bytes instead of data dependencies. Our technique resorts to
the default random mutation scheme of AFL to reason about
such checks. Note that a more complex solution may entail
heavy-weight program analysis that affects the applicability
of our technique. We leave it to our future work to develop a
more sophisticated solution.
While these categories cover the checks in the programs we
consider, we do not claim their comprehensiveness. Moreover,
they do not represent a strict partitioning and hence a check
may fall into more than one categories. For example, the lhs
of check e/circlecopyrtin Figure 2suggests type I and the rhs type II.¬∑¬∑¬∑¬∑¬∑¬∑ 50 4B 05 06 00 00 00 00 01 00 01 00 00 00 00 00field 0 field 1 field 4 field 2field 3
¬∑¬∑¬∑¬∑¬∑¬∑ 00 50 4B 05 06field 4
¬∑¬∑¬∑¬∑¬∑¬∑ ¬∑¬∑¬∑¬∑¬∑¬∑01 00 00 00detect type II check 
field 0detect type I check
Change
¬î¬ä¬ï≈õ…•¬ö…•Õ•…•¬ö…®Check Change
¬é¬ä¬ï≈õ…•¬ö…•Õ•…•¬ö…®
¬é¬ä¬ï≈õ…•¬ö…•Õ•…•¬ö…®CheckInput
Mutated
Input
ChangeDiff ChangeDiff
inter-dependenc e
Fig. 6: Type checking and inter-dependence detection.
D. Detecting Check Types
Due to the different features of each type of check, we deÔ¨Åne
different policies to detect each of them. Algorithm 3describes
the process of type detection. With the Ô¨Åeld information got
from the previous step, we iterate over individual input Ô¨Åelds
and try the predeÔ¨Åned detection policy for each type. We
classify a check to a type by examining whether the change of
its predicate variable values match the feature of the type. The
order of type detection attempts does not matter. Currently, we
support the detection policies for types I, II, III.
Detecting Type I . For each Ô¨Åeld under consideration, we add
a random value to the Ô¨Åeld. We then examine whether the
mutation results in the value of a certain predicate variable
changed. If so, we mark the corresponding check as an arith-
metic check. Intuitively, it leverages the observation that most
arithmetic operations in programs denote one-to-one mapping
from input to output. In other words, any change of the input
leads to change of output. There are corner cases such as mod
operation that does not denote a one-to-one mapping. SLF
currently does not handle them. We also record the Ô¨Åeld that
affects the check. The subsequent multi-goal search algorithm
relies on such information.
Detecting Type II . To detect type II checks, we insert an extra
byte before the current Ô¨Åeld under consideration. We examine
whether the extra byte results in the value of a certain predicate
variable off by one. If so, we mark the corresponding check
as index/offset check. We also record the Ô¨Åeld before which
we insert the padding byte.
Detecting Type III . To detect Type III checks, the idea is to
duplicate the object/data-structure that is being counted and
observe if any variable at the check changes. The challenge lies
in that we do not know the boundaries of objects/structures.
Note that an object/structure may consist of multiple Ô¨Åelds. We
resort to a search algorithm. Assume the input has nÔ¨Åelds in
total. For each Ô¨Åeld iunder consideration in Algorithm 3,w e
start a loop jfrom iton. In the loop, we duplicate the input
segment including Ô¨Åelds from itojand insert the duplicated
segment after Ô¨Åeld j. Essentially, we are considering Ô¨Åelds i-j
form an object. We then examine whether the insertion results
in variable value changes at the check, which indicates a type
III check. We also record iandj.
Example . Figure 6presents an example to illustrate check type
detection. Assume we are given an invalid input as shown
717
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. in the top of the Ô¨Ågure. When we iterate on Ô¨Åeld 0 and
try the detection policy for type II, an extra byte is inserted
before Ô¨Åeld 0. Such a mutation results in the rhs of check
e/circlecopyrtincreasing by one, which matches the feature of type II.
For Ô¨Åeld 4, when we increase its value by 1, the lhs of check
e/circlecopyrtchanges. It matches the feature of type I check. We mark
check e/circlecopyrtas type I due to lhs and record that it is affected by
Ô¨Åeld 4, and also type II due to rhs.
E. Identifying Inter-dependent Checks
Given the type information of each check, we correlate
those checks whose predicates are affected by the same Ô¨Åeld.
For example, the input in Figure 6will fail check f/circlecopyrt. The
information provided by the check type detection phase shows
that checks e/circlecopyrtand f/circlecopyrtare affected by the same Ô¨Åeld (i.e., Ô¨Åeld
4). We hence correlate them for further processing.
F . Gradient-based Multi-goal Search Algorithm
This step aims to identify mutation that is likely to pass the
failing check and does not fail any preceding checks. It starts
from the current failing check and the corresponding input,
and mutates the input based on the type and inter-dependence
information of the failing check. Algorithm 4presents part
of the procedure. For simplicity, we assume a singular inter-
dependent check rcand a singular Ô¨Åeld fdthat affects the
failing check fc. Our implementation handles multiple inter-
dependent checks and multiple Ô¨Åelds affecting fc.
In the Ô¨Årst case (lines 1-14), the lhs of fcindicates that it
is a type I check while the rhs is a constant value. At lines
4-5, the program is re-executed with the mutated Ô¨Åeld fd/prime.
The mutation is bounded random mutation. The new runtime
information CheckInfo/primecontains the updated information
of the failing check, denoted as fc/prime. At lines 6 and 7, the
gradients of the failing check and the relevant check are
computed. Observe that they denote how the mutation on
fdaffects the difference of the lhs and rhs at the check.
Line 8 tries to select a Ô¨Åeld value that can negate the failing
check but still respect the relevant check, by choosing a value
that is greater than fd‚àí(fc.lhs‚àífc.rhs )/gradient , which
would change the branch outcome at fcif it denotes a linear
function, and smaller than fd‚àí(rc.lhs‚àírc.rhs )/relgrdt
so that rclikely retains its branch outcome. If the range
at line 8 is empty and fd/prime/primecannot be selected, indicating
potential infeasibility of satisfying both checks. Lines 9-13
choose to Ô¨Årst satisfy the check that has less Ô¨Çexibility (i.e.,
inÔ¨Çuenced by smaller number of other input Ô¨Åelds and hence
smaller room to manipulate) while getting closer to satisfy
the other check. SpeciÔ¨Åcally, line 11 sets the mutated value
to one that is slightly smaller than a value that would likely
negate the branch outcome of rc; line 13 negates fcwith the
smallest possible value so that the violation of rcmay likely
be minimized. The resulted seed input is added to the set.
Lines 15-21 denote another case in which the lhs indicates
type I whereas the rhs indicates type III. Since both sides can
be manipulated by input mutations, the strategy of SLF is to
Ô¨Åx one side and mutate the other side. It generates two seedAlgorithm 4: MultiGoalSearch (fc, T ypeInfo, DepInfo ):
gradient-based multi-goal Search. Variables input ,fc,
rc,fd,seeds denote the current input, the failing check,
the inter-dependent check, the Ô¨Åeld that impacts fc‚Äôs
variables, and inputs generated, respectively.
1iffc.lhs.cat ==I&&fc.rhs.cat ==CONST then
2fd‚ÜêGetDepField (TypeInfo,fc.lhs )
3rc‚ÜêGetDepCheck (DepInfo,fd )
4fd/prime‚ÜêMutateField (fd)
5CheckInfo/prime‚Üê
RunProgram (ReplaceField (input,fd,fd/prime))
6gradient ‚Üê(fc/prime.lhs‚àífc/prime.rhs )‚àí(fc.lhs‚àífc.rhs )
fd/prime‚àífd
7relgrdt‚Üê(rc/prime.lhs‚àírc/prime.rhs )‚àí(rc.lhs‚àírc.rhs )
fd/prime‚àífd
8fd/prime/prime‚Üêa value in [fd‚àí(fc.lhs‚àífc.rhs )/gradient, fd ‚àí
(rc.lhs‚àírc.rhs )/relgrdt )
9 iffd/prime/prime==null then
10 iffchas more Ô¨Çexibility than rcthen
11 fd/prime/prime‚Üêfd‚àí(rc.lhs‚àírc.rhs )/gradient +Œ¥
12 else
13 fd/prime/prime‚Üêfd‚àí(fc.lhs‚àífc.rhs )/gradient
14seeds‚ÜêAddSeed (seeds,ReplaceField (input,fd,fd/prime/prime))
15iffc.lhs.cat ==I&&fc.rhs.cat ==III then
16 /*fix rhs and mutate lhs like lines 4-14 */
17 /*fix lhs and mutate rhs */
18/angbracketleftlb,ub/angbracketright‚ÜêGetDepField (TypeInfo,fc.rhs )
19CheckInfo/prime‚Üê
RunProgram (InsertFields (input,up +1,Fields [lb,ub ]))
20gradient ‚Üê(fc/prime.lhs‚àífc/prime.rhs )‚àí(fc.lhs‚àífc.rhs )
21seeds‚ÜêAddSeed (seeds,InsertNFields (input,ub +
1,Fiels [lb,ub ],gradient )
22...
inputs: one by Ô¨Åxing rhs and mutating lhs and vice versa. The
search space of mutating both sides is explored by further
mutating the two new seeds (in later rounds). This strategy
is particularly effective for passing checksum validity checks.
Since lhs is type I, mutating lhs is similar to that in lines
4-14 and elided. Lines 17-21 are to Ô¨Åx lhs and mutate rhs.
In particular, since rhs indicates type III, line 18 extracts the
starting and ending Ô¨Åeld indexes of the object/structure that
is being counted. It then mutates the input by duplicating the
object/structure once and adding it right after the ending index
ub, and re-executes the program (line 19). A gradient value
is computed to measure the inÔ¨Çuence at the failing check.
Note that the denominator is 1 as we only add one object.
Line 21 tries to insert N=gradient objects to negate the
failing check. Note that when a failing type II/III check is
inter-dependent to other type I checks, SLF always tries to
negate the type II/III check Ô¨Årst and lets the following rounds
to Ô¨Åx the possible violations of the inter-dependent checks.
There are other cases. Due to the space limitations, we
omit them from discussion. They are similarly handled as the
aforementioned two cases.
Example. Assume check f/circlecopyrtin Figure 1fails. It belongs to
the Ô¨Årst case in Algorithm 4. Further assume that cdsize,
cdoffset ,SIZE CDH , and eocd off are 0x2f, 0x22,
0x33, and 0x51, respectively. SLF identiÔ¨Åes checks e/circlecopyrtand
f/circlecopyrtinter-dependent. SLF determines the gradients for both e/circlecopyrt
and f/circlecopyrtare 1 (by mutating cdsize and comparing lhs ‚àírhs
718
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. before and after mutation). However, it fails to choose a value
that satisÔ¨Åes f/circlecopyrtwithout failing e/circlecopyrt,a scdsize +cdoff‚àí
eocd off == 0 while cdsize‚àíSIZE CDH ==‚àí0x4.
In this case, SLF chooses to satisfy the more restricted check
f/circlecopyrtby adding 4 to cdsize. In a later round, the input is further
mutated by changing cdoff to pass all checks.
G. Limitations
SLF cannot handle checks that have complex control depen-
dencies with input Ô¨Åelds and hence relies on regular fuzzing to
deal with these Ô¨Åelds. In addition, SLF identiÔ¨Åes input Ô¨Åelds
at the byte level and hence cannot reason about checks that
involve bit-level Ô¨Åelds.
IV . E V ALUATION
A. Experiment Setup
Our evaluation is performed on two datasets. One contains
10 real-world programs that are commonly used in other
fuzzing projects [ 17], [18]. The other is 10 benchmark pro-
grams selected from the Google fuzzer test-suite [ 19] that do
not have valid seed inputs provided. These programs cover a
wide range of categories, including image, audio, compression,
font, etc. The Ô¨Årst three columns in Table Iand Table IIpresent
detailed information of the programs.
We compare our tool (SLF) with other popular state-of-the-
art testing tools. For symbolic execution tools, we compare
with KLEE [ 9] and S2E [ 13]. Due to the input size needed
in our programs, we provide a 256-bytes symbolic Ô¨Åle as
input for both KLEE and S2E. We use the coverage-optimized
search strategy for KLEE and the class-uniform analysis
search strategy for S2E, which are the recommended settings.
For mutation based fuzzers, we compare with the original
AFL [ 16] and its improved version AFLFast [ 20] that performs
optimized fuzzing energy allocation. For hybrid fuzzers, we
compare with Driller [ 15], which combines fuzzing with
symbolic execution (for exploring paths difÔ¨Åcult to fuzz).
All of our experiments are performed on a machine with 12
cores (Intel¬Æ CoreTMi7-8700 CPU @ 3.20GHz) and 16 GB
memory running the Ubuntu 16.04 operating system.
B. Results for the Programs Commonly Used in Fuzzing
To evaluate the effectiveness of SLF, we perform a set
of experiments by running SLF and other tools on the 10
real-world programs commonly used in fuzzing with a 4-
byte randomly generated invalid input, and observing their
path coverage changes over time. We run each experiment
(one testing tool on one program) for 24 hours. Results are
presented in Table Iand Figure 7, in which X-axis represents
time, Y-axis represents the number of covered paths for each
experiment, and the points on the curves denote the moments
that a valid seed input is generated.
From these results, we can make the following observa-
tions. Firstly, traditional mutation-based fuzzers (i.e., AFL and
AFLFast) do not work well without valid inputs in most cases.
At the beginning, they can cover some paths by satisfyingenvironment related path conditions but very few or no input-
related conditions. After that, the executions got stuck at
Ô¨Ånding the Ô¨Årst valid input and cannot proceed. In many
cases, it cannot make any progress within 24 hours, leading
to low path discovery. For example, in the evaluation of libtiff
(Figure 7c), AFL and AFLFast got stuck within 2 hours,
yielding only 1/6 path coverage compared with SLF. As shown
in Table I, on average SFL covers 3.0 and 2.5 times more paths
than AFL and AFLFast, and generates much more valid seeds.
Secondly, the symbolic execution tools work well on small
programs. For example, S2E achieves the best result than all
the fuzzing-based tools on otfcc (Figure 7j). However, they do
not handle complex real-world programs well. We have spent
substantial engineering efforts to make KLEE and S2E to work
on these target programs, even under the guidance from some
of their original developers. We were able to make KLEE run
on 7 target programs and S2E on 9 target programs. Those
programs that cannot run for KLEE/S2E are marked as N/A
in Table I. Also note that S2E is very memory-consuming. If
the memory is about to reach the limit, it starts to randomly
kill some of the existing states until there is enough memory
for continuation. Due to the random state killing, it often
terminates early as there are no more states to explore. It
runs for 5 hours on average in our experiments. We mark
the termination point of S2E with an ‚Äúx‚Äù symbol in Figure 7.
For programs that can be run by KLEE, SLF generates 1.6
times more seeds than KLEE in total; for those programs that
can be run by S2E, SLF generates 6.4 times more seeds. SFL
outperforms symbolic execution except for the three smallest
programs (i.e., giÔ¨Çib, otfcc, ttf2woff).
Thirdly, the hybrid fuzzer Driller alternates between fuzzing
(in most of the time) and symbolic execution (when fuzzing
is stuck). It scales to large programs and achieves reasonable
performance. However, it still does not work as well as our
tool. From our manual inspection, the reason seems to be
that the optimal timing of switching from fuzzing to sym-
bolic execution is difÔ¨Åcult to identify for complex programs.
Switching at a wrong time does not really exploit the beneÔ¨Åts
of the combination. Furthermore, there are still cases that the
symbolic execution engine cannot handle well.
Lastly, our tool SLF achieves the best performance (i.e., the
largest number of explored paths) in all cases except otfcc.
As we can see from the graph, newly generated seed inputs
usually lead to exploration of a large number of new paths.
These results show that SLF is very effective in generating
new valid seeds, which lead to better path coverage than other
tools in most cases.
Case Study. We use Exiv2 as a case study. Within 24 hours,
SLF generates 6 unique seeds that lead to the coverage of
782 different program paths, while other tools do not generate
any valid seed. SLF has more than three times path coverage
than other tools. More interestingly, we found that one of the
generated seeds has undocumented format. Figure 8shows the
snippets of a documented valid seed and the undocumented
valid seed. In the documented format, the bytes at offset
719
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. TABLE I: Evaluation result on real-world programs.
Category Program SLOCSLF AFL AFLFast Driller KLEE S2E
Paths Seeds Paths Seeds Paths Seeds Paths Seeds Paths Seeds Paths Seeds
Imageexiv2 191,993 782 6 169 0 198 0 206 0 N/A N/A 64 0
giÔ¨Çib 8,209 357 3 137 1 122 1 292 1 60 4 76 2
libtiff 82,484 1,208 4 205 0 238 0 890 0 180 0 99 0
openjpeg 164,284 787 6 226 0 215 0 155 0 N/A N/A 39 0
Audiolame 60,240 576 31 90 0 114 0 332 9 N/A N/A 61 0
libsndÔ¨Åle 70,064 862 7 317 4 356 4 698 3 81 0 335 5
Compressionlibzip 17,985 210 7 106 0 106 0 152 0 34 0 N/A N/A
lrzip 19,098 704 2 96 0 179 0 513 0 58 0 51 0
Fontotfcc 10,344 38 0 21 0 23 0 30 0 29 4 46 1
ttf2woff 5,565 82 0 28 0 29 0 50 0 73 1 43 0
(a) exiv2. (b) giÔ¨Çib. (c) libtiff. (d) openjpeg.
(e) lame. (f) libsndÔ¨Åle. (g) libzip. (h) lrzip.
(i) ttf2woff. (j) otfcc.Legendƒü
Fig. 7: Path coverage. X-axis: time over 24 hours, Y-axis: the number of unique paths.
0x04-07 is an offset Ô¨Åeld that points to the location where
the subsequent data (e.g., count and tag) are stored. Usually,
the offset points to the following bytes. However, in the
undocumented format, the offset points to itself. As a result,
the subsequent data overlaps with the offset Ô¨Åeld. Hence the
count is 0x04 and the tag is 0x00. Such seed is uniquely
supported by Exiv2 and not supported by other TIFF image
processing tools (e.g., LibTiff). This seed input yields 86 new
path coverage in the fuzzing process.
We illustrate how SLF generates such undocumented seed.
Figure 9shows two critical checks in Exiv2. During fuzzing
process, an 8-byte invalid input that fails the two checks
is given to SLF. Check 1/circlecopyrtis of type I (lhs) and type II
(rhs). Our multi-goal search algorithm will try to Ô¨Åx rhs (i.e.,
Ô¨Åle size) and mutate lhs (i.e., input[0x04, 0x07]) to satisfy
the check assertion (line 16 of Algorithm 4), which results in
assigning input[0x04, 0x07] with value 0x04. Check 2/circlecopyrtis of
type I (lhs) and type II (rhs) and inter-dependent with check1/circlecopyrton input[0x04, 0x07]. To satisfy both checks, our search
algorithm will try to extend the Ô¨Åle size. After satisfying other
subsequent checks, the undocumented seed is generated.
C. Google Fuzzer Test Suite
Another set of experiments is on the Google fuzzer test
suite. As a standard fuzzing benchmark, it tags some locations
to see if a testing tool can reach those locations. Table II shows
the programs, the target location in the program and time used
to reach this location (measured by hours). We only use the
programs that do not come with a valid seed. In total, we
evaluate on 18 locations. In the table, T/O means time out
after 24 hours and N/A means the tool does not work on
this program. S2E does not work on this benchmark. We have
conÔ¨Årmed that with the authors of S2E. The probable reason is
that the target programs or the underlying third-party libraries
contain instructions operating on SSE, MMX and FP registers,
which are currently not supported by S2E.
720
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. ¬∑¬∑¬∑¬∑¬∑¬∑ 49 49 2A 00 08 00 00 00  04 00 00 00offset version count tag magic number
¬∑¬∑¬∑¬∑¬∑¬∑ 49 49 2A 00 04 00 00 00offset version
tag countmagic number
04 00GRFXPHQWHG
IRUPDW
XQGRFXPHQWHG
IRUPDW…•¬ö…•…•¬ö…®…•¬ö…©…•¬ö…™…•¬ö…´…•¬ö…¨…•¬ö…≠…•¬ö…Æ…•¬ö…Ø…•¬ö…∞…•¬ö…•¬ö
Fig. 8: Example of undocumented TIFF format.
01offset =input[ 0x04 ,0x07 ];
02if(offset +4> file_size) error(); 1/circlecopyrt
03count =input[offset, offset +1];
04if(12*count +offset >file_size) error(); 2/circlecopyrt
Fig. 9: Two critical checks in Exiv2.
In summary, our tool ran on all the programs and can reach
9 locations with reasonable execution time. AFL, AFLFast
and Driller also work on all programs, and each can reach 4
locations within 24 hours. KLEE does not work on harfbuzz as
some of its instructions are not supported by KLEE. In total,
KLEE is able to reach 6 locations. SLF is able to reach all the
locations reached by any other tools. In terms of time used to
reach the location, it outperforms AFL, AFLFast and Driller
in all cases. In some cases, KLEE takes less time. Manual
inspection discloses that these locations are on shallow paths.
For complex cases (e.g., lcms) where KLEE cannot reach
within 24 hours, SLF is still able to reach the location.
D. Threats to V alidity
The initial input may impact the effectiveness of fuzzing.
To be fair, we used the same 4-byte invalid input for AFL,
AFLFast, Driller, SLF. For symbolic execution tools, the sym-
bolic Ô¨Åle size and path exploration algorithm impact results.
We used the recommended settings for S2E and KLEE.
V. R ELATED WORK
Mutation based fuzzing. Mutation based fuzzing generates
new inputs by mutating seed inputs. The random nature of
mutations often leads to lengthy fuzzing time. A number of
existing works were proposed to boost fuzzing by improving
seed selection [ 24], optimizing fuzzing guidance using sta-
tistical metrics [ 20], [25]‚Äì[27], and leveraging vulnerability
speciÔ¨Åc patterns [ 28]. These techniques mainly aim to im-
prove the quality of generated/selected seeds for fuzzing. This
demonstrates the importance of seed inputs. Compared to these
techniques, SLF does not require a valid seed to begin with.
It has the unique feature of satisfying input validity checks.
Generative fuzzing. Another popular fuzzing method is to
generate valid seed inputs from input format speciÔ¨Åcations.
Some approaches, e.g., SPIKE [ 29] and Peach [ 30], take
human-written input speciÔ¨Åcations as templates. Other ap-
proaches, e.g., SkyÔ¨Åre [ 5] and Learn&Fuzz [ 6] learn speci-
Ô¨Åcation from a large corpus. They are effective when a high
quality training set is available.TABLE II: Evaluation result on Google fuzzer test-suite.
Program SLOC LocationReaching Time (hours)
SLF AFL AFLFast Driller KLEE
freetype2 168,231 ttgload.c:1710 T/O T/O T/O T/O T/O
guetzli 8,068 output image.cc:398 5.50 T/O T/O T/O T/O
harfbuzz 13,099 hb-buffer.cc:419 T/O T/O T/O T/O N/A
lcms 55,918 cmsintrp.c:642 8.27 T/O T/O T/O T/O
libarchive 190,125 archive...warc.c:537 T/O T/O T/O T/O T/O
libjpeg 57,437 jdmarker.c:659 0.16 0.31 5.73 0.20 0.08
libpng 20,820png.c:1035 4.55 T/O T/O T/O 0.02
pngread.c:757 0.49 T/O T/O T/O 1.83
pngrutil.c:1393 T/O T/O T/O T/O T/O
pngread.c:738 0.49 T/O T/O T/O 0.02
pngrutil.c:3182 T/O T/O T/O T/O T/O
pngrutil.c:139 0.01 0.03 0.01 0.01 0.01
proj4 37,871 PJurm5.c:39 0.82 4.47 3.26 2.73 T/O
vorbis 61,990codebook.c:479 T/O T/O T/O T/O T/O
codebook.c:407 T/O T/O T/O T/O T/O
res0.c:690 T/O T/O T/O T/O T/O
woff2 34,594woff2 dec.cc:500 T/O T/O T/O T/O T/O
woff dec.cc:1274 0.45 1.37 1.26 1.07 0.02
Symbolic execution. Symbolic execution techniques are very
popular and effective software testing [ 10]‚Äì[12], [31]‚Äì[42].
Like SLF, it does not require seed inputs to begin with.
Fuzzing and symbolic execution both have their pros and cons.
For example, fuzzing is usually more applicable and easily
works on large and complex software. SLF belongs to fuzzing
and hence has similar beneÔ¨Åts. While traditional fuzzers are
inferior to symbolic execution in precise resolution of path
conditions, SLF mitigates such limitations by having a gradient
guided multi-goal search algorithm. Additionally, SLF features
the capabilities of directly resolving the constraints in various
kinds of validity checks, such as offset and count checks.
Search-based testing. Search-based testing techniques view
testing problems, including automatic generation of test cases,
test case minimization and prioritization, and regression testing
as search problems, and try to use meta-heuristic search tech-
niques (e.g., genetic algorithms, simulated annealing and tabu
search) to solve them [ 43]‚Äì[56]. In particular, EVOSUITE [57]
optimizes a test suite towards satisfying a coverage criterion.
While fuzzing can be viewed as a search based testing tech-
nique, SLF uniquely focuses on validity checks and works by
classifying such checks and performing class-speciÔ¨Åc muta-
tions. On the other hand, SFL may be complementary to ex-
isting search-based techniques by providing Ô¨Åeld information
and validity check type information.
Hybrid fuzzing. Hybrid fuzzing performs fuzzing for most
of the time and performs symbolic execution when needed.
Driller [ 15] and Angora [ 14] are both such fuzzers. They can
handle large real-world programs (using fuzzing) as well as
leveraging the power of symbolic execution to solve difÔ¨Åcult
constraints. However, when to start the symbolic execution re-
mains a hard problem for such tools (as shown in Section IV).
VI. C ONCLUSION
We develop a novel fuzzing technique that can generate
valid seed inputs from scratch. It works by classifying input
validity checks into a number of types and conduct type
speciÔ¨Åc mutations. It features a multi-goal search algorithm
that can satisfy multiple inter-dependent validity checks all
together. Our evaluation shows that our technique is highly
effective and efÔ¨Åcient, outperforming existing tools.
721
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. ACKNOWLEDGMENT
The authors would like to thank the anonymous reviewers
for their constructive comments. Also, the authors would
like to express their thanks to Yang Xiao and Hui Peng
for their help in experiment settings and Xinjie Wang for
her help in illustration. The authors were supported in part
by DARPA FA8650-15-C-7562, NSF 1748764 and 1409668,
ONR N000141410468 and N000141712947, Sandia National
Lab under award 1701331, and NSFC U1836209.
REFERENCES
[1] ‚ÄúOss-fuzz: Five months later, and rewarding projects,‚Äù https://
security.googleblog .com/2017/05/oss-fuzz-Ô¨Åve-months-later-and .html.
[2] ‚ÄúHow heartbleed could‚Äôve been found,‚Äù https://blog .hboeck.de/archives/
868-How-Heartbleed-couldve-been-found .html.
[3] ‚ÄúCisco webex .atp and .wrf overÔ¨Çow vulnerabilities,‚Äù
https://www .coresecurity .com/content/webex-atp-and-wrf-overÔ¨Çow-
vulnerabilities .
[4] ‚ÄúAnalysis and exploitation of pegasus kernel vulnerabilities,‚Äù https:
//jndok.github.io/2016/10/04/pegasus-writeup/ .
[5] J. Wang, B. Chen, L. Wei, and Y . Liu, ‚ÄúSkyÔ¨Åre: Data-driven seed
generation for fuzzing,‚Äù in 2017 IEEE Symposium on Security and
Privacy, SP 2017 , 2017.
[6] P. Godefroid, H. Peleg, and R. Singh, ‚ÄúLearn&fuzz: machine learning
for input fuzzing,‚Äù in Proceedings of the 32nd IEEE/ACM International
Conference on Automated Software Engineering, ASE 2017 .
[7] J. Lee, T. Avgerinos, and D. Brumley, ‚ÄúTIE: principled reverse engi-
neering of types in binary programs,‚Äù in Proceedings of the Network
and Distributed System Security Symposium, NDSS 2011 , 2011.
[8] Z. Lin, X. Zhang, and D. Xu, ‚ÄúAutomatic reverse engineering of data
structures from binary execution,‚Äù in Proceedings of the Network and
Distributed System Security Symposium, NDSS 2010 , 2010.
[9] C. Cadar, D. Dunbar, and D. R. Engler, ‚ÄúKLEE: unassisted and
automatic generation of high-coverage tests for complex systems
programs,‚Äù in 8th USENIX Symposium on Operating Systems Design
and Implementation, OSDI 2008, December 8-10, 2008, San Diego,
California, USA, Proceedings , 2008, pp. 209‚Äì224. [Online]. Available:
http://www .usenix.org/events/osdi08/tech/full papers/cadar/cadar .pdf
[10] X. Ge, K. Taneja, T. Xie, and N. Tillmann, ‚ÄúDyta: dynamic symbolic
execution guided with static veriÔ¨Åcation results,‚Äù in Proceedings of the
33rd International Conference on Software Engineering, ICSE 2011,
Waikiki, Honolulu , HI, USA, May 21-28, 2011 , R. N. Taylor, H. C.
Gall, and N. Medvidovic, Eds. ACM, 2011, pp. 992‚Äì994. [Online].
Available: http://doi.acm.org/10.1145/1985793 .1985971
[11] J. Chen, W. Hu, L. Zhang, D. Hao, S. Khurshid, and L. Zhang,
‚ÄúLearning to accelerate symbolic execution via code transformation,‚Äù
in32nd European Conference on Object-Oriented Programming,
ECOOP 2018, July 16-21, 2018, Amsterdam, The Netherlands , ser.
LIPIcs, T. D. Millstein, Ed., vol. 109. Schloss Dagstuhl - Leibniz-
Zentrum fuer Informatik, 2018, pp. 6:1‚Äì6:27. [Online]. Available:
https://doi .org/10.4230/LIPIcs .ECOOP.2018.6
[12] S. Person, G. Yang, N. Rungta, and S. Khurshid, ‚ÄúDirected incremental
symbolic execution,‚Äù in Acm Sigplan Notices , vol. 46, no. 6. ACM,
2011, pp. 504‚Äì515.
[13] V . Chipounov, V . Kuznetsov, and G. Candea, ‚ÄúS2E: a platform
for in-vivo multi-path analysis of software systems,‚Äù in Proceedings
of the 16th International Conference on Architectural Support for
Programming Languages and Operating Systems, ASPLOS 2011,
Newport Beach, CA, USA, March 5-11, 2011 , 2011, pp. 265‚Äì278.
[Online]. Available: http://doi.acm.org/10.1145/1950365 .1950396
[14] P. Chen and H. Chen, ‚ÄúAngora: EfÔ¨Åcient fuzzing by principled search,‚Äù
inProceedings of the 39th IEEE Symposium on Security and Privacy
(SP 2018) , 2018.
[15] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta,
Y . Shoshitaishvili, C. Kruegel, and G. Vigna, ‚ÄúDriller: Augmenting
fuzzing through selective symbolic execution,‚Äù in Proceedings of the
23rd Annual Network and Distributed System Security Symposium,
NDSS 2016 .
[16] ‚ÄúAmerican fuzzy lop (aÔ¨Ç),‚Äù http://lcamtuf .coredump .cx/aÔ¨Ç .[17] S. Gan, C. Zhang, X. Qin, X. Tu, K. Li, Z. Pei, and Z. Chen, ‚ÄúCollaÔ¨Ç:
Path sensitive fuzzing,‚Äù in Proceedings of the 39th IEEE Symposium on
Security and Privacy (SP 2018) , 2018.
[18] ‚ÄúOss-fuzz project,‚Äù https://github .com/google/oss-fuzz/tree/master/
projects .
[19] ‚ÄúGoogle fuzzer test suite,‚Äù https://github .com/google/fuzzer-test-suite .
[20] M. B ¬®ohme, V . Pham, and A. Roychoudhury, ‚ÄúCoverage-based greybox
fuzzing as markov chain,‚Äù in Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security CCS 2016 .
[21] ‚ÄúLibzip,‚Äù https://libzip .org/.
[22] ‚ÄúZip Ô¨Åle format,‚Äù https://en.wikipedia .org/wiki/Zip (Ô¨Åle format) .
[23] P. Saxena, P. Poosankam, S. McCamant, and D. Song, ‚ÄúLoop-extended
symbolic execution on binary programs,‚Äù in Proceedings of the Eigh-
teenth International Symposium on Software Testing and Analysis, ISSTA
2009, Chicago, IL, USA, July 19-23, 2009 , 2009, pp. 225‚Äì236.
[24] A. Rebert, S. K. Cha, T. Avgerinos, J. Foote, D. Warren, G. Grieco, and
D. Brumley, ‚ÄúOptimizing seed selection for fuzzing,‚Äù in Proceedings of
the 23rd USENIX Security Symposium 2014 , 2014.
[25] C. Lemieux and K. Sen, ‚ÄúFairfuzz: Targeting rare branches to rapidly
increase greybox fuzz testing coverage,‚Äù CoRR , vol. abs/1709.07101,
2017.
[26] T. Petsios, J. Zhao, A. D. Keromytis, and S. Jana, ‚ÄúSlowfuzz: Automated
domain-independent detection of algorithmic complexity vulnerabili-
ties,‚Äù in Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, CCS 2017 .
[27] M. B ¬®ohme, V . Pham, M. Nguyen, and A. Roychoudhury, ‚ÄúDirected
greybox fuzzing,‚Äù in Proceedings of the 2017 ACM SIGSAC Conference
on Computer and Communications Security, CCS 2017 , 2017.
[28] I. Haller, A. Slowinska, M. Neugschwandtner, and H. Bos, ‚ÄúDowsing
for overÔ¨Çows: a guided fuzzer to Ô¨Ånd buffer boundary violations,‚Äù in
Proceedings of the 22th USENIX Security Symposium Security , 2013.
[29] ‚ÄúGithub - guilhermeferreira/spikepp,‚Äù https://github .com/
guilhermeferreira/spikepp , (Accessed on 08/24/2018).
[30] ‚ÄúGithub - mozillasecurity/peach: Peach is a fuzzing framework which
uses a dsl for building fuzzers and an observer based architecture to
execute and monitor them.‚Äù https://github .com/MozillaSecurity/peach ,
(Accessed on 08/24/2018).
[31] S. Khurshid, C. S. P ÀòasÀòareanu, and W. Visser, ‚ÄúGeneralized symbolic
execution for model checking and testing,‚Äù in International Conference
on Tools and Algorithms for the Construction and Analysis of Systems .
Springer, 2003, pp. 553‚Äì568.
[32] C. Cadar, P. Godefroid, S. Khurshid, C. S. Pasareanu, K. Sen, N. Till-
mann, and W. Visser, ‚ÄúSymbolic execution for software testing in
practice: preliminary assessment,‚Äù in Software Engineering (ICSE), 2011
33rd International Conference on . IEEE, 2011, pp. 1066‚Äì1071.
[33] S. Dong, O. Olivo, L. Zhang, and S. Khurshid, ‚ÄúStudying the
inÔ¨Çuence of standard compiler optimizations on symbolic execution,‚Äù
in 26th IEEE International Symposium on Software Reliability
Engineering, ISSRE 2015, Gaithersbury, MD, USA, November 2-5,
2015 . IEEE Computer Society, 2015, pp. 205‚Äì215. [Online]. Available:
https://doi .org/10.1109/ISSRE .2015.7381814
[34] R. Qiu, G. Yang, C. S. Pasareanu, and S. Khurshid, ‚ÄúCompositional
symbolic execution with memoized replay,‚Äù in 37th IEEE/ACM
International Conference on Software Engineering, ICSE 2015,
Florence, Italy, May 16-24, 2015, V olume 1 , A. Bertolino, G. Canfora,
and S. G. Elbaum, Eds. IEEE Computer Society, 2015, pp. 632‚Äì642.
[Online]. Available: https://doi .org/10.1109/ICSE .2015.79
[35] R. Qiu, C. S. Pasareanu, and S. Khurshid, ‚ÄúCertiÔ¨Åed symbolic
execution,‚Äù in Automated Technology for V eriÔ¨Åcation and Analysis -
14th International Symposium, ATVA 2016, Chiba, Japan, October
17-20, 2016, Proceedings ,ser. Lecture Notes in Computer Science,
C. Artho, A. Legay, and D. Peled, Eds., vol. 9938, 2016, pp. 495‚Äì511.
[Online]. Available: https://doi .org/10.1007/978-3-319-46520-3 31
[36] R. Qiu, S. Khurshid, C. S. Pasareanu, and G. Yang, ‚ÄúA synergistic
approach for distributed symbolic execution using test ranges,‚Äù
inProceedings of the 39th International Conference on Software
Engineering, ICSE 2017, Buenos Aires, Argentina, May 20-28, 2017
- Companion V olume , S. Uchitel, A. Orso, and M. P. Robillard,
Eds. IEEE Computer Society, 2017, pp. 130‚Äì132. [Online]. Available:
https://doi .org/10.1109/ICSE-C .2017.116
[37] T. Xie, N. Tillmann, J. de Halleux, and W. Schulte, ‚ÄúFitness-guided path
exploration in dynamic symbolic execution,‚Äù in Dependable Systems
& Networks, 2009. DSN‚Äô09. IEEE/IFIP International Conference on .
Citeseer, 2009, pp. 359‚Äì368.
722
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. [38] X. Xiao, S. Li, T. Xie, and N. Tillmann, ‚ÄúCharacteristic studies of
loop problems for structural test generation via symbolic execution,‚Äù in
2013 28th IEEE/ACM International Conference on Automated Software
Engineering, ASE 2013, Silicon V alley, CA, USA, November 11-15,
2013 , E. Denney, T. Bultan, and A. Zeller, Eds. IEEE, 2013, pp. 246‚Äì
256. [Online]. Available: https://doi .org/10.1109/ASE .2013.6693084
[39] L. Zhang, T. Xie, L. Zhang, N. Tillmann, J. de Halleux, and
H. Mei, ‚ÄúTest generation via dynamic symbolic execution for
mutation testing,‚Äù in 26th IEEE International Conference on Software
Maintenance (ICSM 2010), September 12-18, 2010, Timisoara,
Romania . IEEE Computer Society, 2010, pp. 1‚Äì10. [Online].
Available: https://doi .org/10.1109/ICSM .2010.5609672
[40] T. Xie, N. Tillmann, J. de Halleux, and W. Schulte, ‚ÄúFitness-guided
path exploration in dynamic symbolic execution,‚Äù in Proceedings of
the 2009 IEEE/IFIP International Conference on Dependable Systems
and Networks, DSN 2009, Estoril, Lisbon, Portugal, June 29 - July
2, 2009 . IEEE Computer Society, 2009, pp. 359‚Äì368. [Online].
Available: https://doi .org/10.1109/DSN .2009.5270315
[41] T. Xie, D. Marinov, W. Schulte, and D. Notkin, ‚ÄúSymstra: A framework
for generating object-oriented unit tests using symbolic execution,‚Äù in
Tools and Algorithms for the Construction and Analysis of Systems,
11th International Conference, TACAS 2005, Held as Part of the
Joint European Conferences on Theory and Practice of Software,
ETAPS 2005, Edinburgh, UK, April 4-8, 2005, Proceedings , ser.
Lecture Notes in Computer Science, N. Halbwachs and L. D. Zuck,
Eds., vol. 3440. Springer, 2005, pp. 365‚Äì381. [Online]. Available:
https://doi .org/10.1007/978-3-540-31980-1 24
[42] B. Daniel, T. Gvero, and D. Marinov, ‚ÄúOn test repair using symbolic
execution,‚Äù in Proceedings of the Nineteenth International Symposium
on Software Testing and Analysis, ISSTA 2010, Trento, Italy, July
12-16, 2010 , P. Tonella and A. Orso, Eds. ACM, 2010, pp. 207‚Äì218.
[Online]. Available: http://doi.acm.org/10.1145/1831708 .1831734
[43] A. Arcuri and G. Fraser, ‚ÄúOn parameter tuning in search based software
engineering,‚Äù in International Symposium on Search Based Software
Engineering . Springer, 2011, pp. 33‚Äì47.
[44] ‚Äî‚Äî, ‚ÄúParameter tuning or default values? an empirical investigation
in search-based software engineering,‚Äù Empirical Software Engineering ,
vol. 18, no. 3, pp. 594‚Äì623, 2013.
[45] F. Gross, G. Fraser, and A. Zeller, ‚ÄúSearch-based system testing: high
coverage, no false alarms,‚Äù in Proceedings of the 2012 International
Symposium on Software Testing and Analysis . ACM, 2012, pp. 67‚Äì77.
[46] G. Fraser and A. Arcuri, ‚ÄúThe seed is strong: Seeding strategies
in search-based software testing,‚Äù in 2012 IEEE Fifth International
Conference on Software Testing, V eriÔ¨Åcation and V alidation . IEEE,
2012, pp. 121‚Äì130.
[47] J. Malburg and G. Fraser, ‚ÄúCombining search-based and constraint-
based testing,‚Äù in Proceedings of the 2011 26th IEEE/ACM International
Conference on Automated Software Engineering . IEEE Computer
Society, 2011, pp. 436‚Äì439.
[48] G. Fraser and J. T. de Souza, Eds., Search Based Software Engineering
- 4th International Symposium, SSBSE 2012, Riva del Garda,
Italy, September 28-30, 2012. Proceedings , ser. Lecture Notes in
Computer Science, vol. 7515. Springer, 2012. [Online]. Available:
https://doi .org/10.1007/978-3-642-33119-0
[49] M. Harman and B. F. Jones, ‚ÄúSearch-based software engineering,‚Äù
Information and software Technology , vol. 43, no. 14, pp. 833‚Äì839,
2001.
[50] J. Clarke, J. J. Dolado, M. Harman, R. Hierons, B. Jones, M. Lumkin,
B. Mitchell, S. Mancoridis, K. Rees, M. Roper et al. , ‚ÄúReformulating
software engineering as a search problem,‚Äù IEE Proceedings-software ,
vol. 150, no. 3, pp. 161‚Äì175, 2003.
[51] M. Harman and P. McMinn, ‚ÄúA theoretical and empirical study of search-
based testing: Local, global, and hybrid search,‚Äù IEEE Transactions on
Software Engineering , vol. 36, no. 2, pp. 226‚Äì247, 2010.
[52] K. Praditwong, M. Harman, and X. Yao, ‚ÄúSoftware module clustering
as a multi-objective search problem,‚Äù IEEE Transactions on Software
Engineering , vol. 37, no. 2, pp. 264‚Äì282, 2011.
[53] F. Wu, M. Harman, Y . Jia, and J. Krinke, ‚ÄúHOMI: searching higher
order mutants for software improvement,‚Äù in Search Based Software
Engineering - 8th International Symposium, SSBSE 2016, Raleigh, NC,
USA, October 8-10, 2016, Proceedings , ser. Lecture Notes in Computer
Science, F. Sarro and K. Deb, Eds., vol. 9962, 2016, pp. 18‚Äì33.
[Online]. Available: https://doi .org/10.1007/978-3-319-47106-8 2[54] P. McMinn, M. Harman, G. Fraser, and G. M. Kapfhammer,
‚ÄúAutomated search for good coverage criteria: moving from code
coverage to fault coverage through search-based software engineering,‚Äù
in Proceedings of the 9th International Workshop on Search-
Based Software Testing, SBST@ICSE 2016, Austin, Texas, USA,
May 14-22, 2016 . ACM, 2016, pp. 43‚Äì44. [Online]. Available:
http://doi.acm.org/10.1145/2897010 .2897013
[55] M. ¬¥O. Cinn ¬¥eide, I. H. Moghadam, M. Harman, S. Counsell, and L. Tratt,
‚ÄúAn experimental search-based approach to cohesion metric evaluation,‚Äù
Empirical Software Engineering , vol. 22, no. 1, pp. 292‚Äì329, 2017.
[Online]. Available: https://doi .org/10.1007/s10664-016-9427-7
[56] H. Jiang, K. Tang, J. Petke, and M. Harman, ‚ÄúSearch based
software engineering [guest editorial],‚Äù IEEE Comp. Int. Mag. ,
vol. 12, no. 2, pp. 23‚Äì71, 2017. [Online]. Available: https:
//doi.org/10.1109/MCI .2017.2670459
[57] G. Fraser and A. Arcuri, ‚ÄúEvolutionary generation of whole test suites,‚Äù
in2011 11th International Conference on Quality Software . IEEE,
2011, pp. 31‚Äì40.
723
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 09:37:27 UTC from IEEE Xplore.  Restrictions apply. 