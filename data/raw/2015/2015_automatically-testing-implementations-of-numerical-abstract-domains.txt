Automatically Testing
Implementations of Numerical Abstract Domains
Alexandra Bugariu
Department of Computer Science, ETH Zurich
Switzerland
alexandra.bugariu@inf.ethz.chValentin Wüstholz
Department of Computer Science, ETH Zurich
Switzerland
wuestholz@gmail.com
Maria Christakis
MPI-SWS
Germany
maria@mpi-sws.orgPeter Müller
Department of Computer Science, ETH Zurich
Switzerland
peter.mueller@inf.ethz.ch
ABSTRACT
Staticprogramanalysesareroutinelyappliedasthebasisofcode
optimizationsandtodetectsafetyandsecurityissuesinsoftware
systems.For theirresults tobereliable,staticanalyses shouldbesound (i.e., should not produce false negatives) and precise (i.e.,should report a low number of false positives). Even though it is
possibletoprovepropertiesofthe designofastaticanalysis,ensur-
ingsoundnessandprecisionforits implementation ischallenging.
Complexalgorithmsandsophisticatedoptimizationsmakestatic
analyzers difficult to implement and test.
In this paper, we present an automatic technique to test, among
other properties, the soundness and precision of abstract domains,
thecoreofallstaticanalyzersbasedonabstractinterpretation.In
ordertocoverawiderangeoftestdataandinputstates,wecon-
struct inputs by applying sequences of abstract-domain operations
torepresentativedomainelements,andvarytheoperationsthrough
gray-boxfuzzing.Weusemathematicalpropertiesofabstractdo-
mainsastestoracles.Ourexperimentalevaluationdemonstrates
theeffectivenessofourapproach.Wedetectedseveralpreviously
unknownsoundness andprecisionerrorsin widely-usedabstract
domains. Our experiments also show that our approach is moreeffective than dynamic symbolic execution and than fuzzing the
test inputs directly.
CCS CONCEPTS
•Software and its engineering →Software testing and de-
bugging;
KEYWORDS
soundness testing, precision testing, abstract interpretation
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3240464ACM Reference Format:
Alexandra Bugariu, Valentin Wüstholz, Maria Christakis, and Peter Müller.
2018. Automatically Testing Implementations of Numerical Abstract Do-
mains.In Proceedingsofthe201833rdACM/IEEEInternationalConferenceon
Automated Software Engineering (ASE ’18), September 3–7, 2018, Montpellier,
France.ACM,NewYork,NY,USA, 11pages.https://doi.org/10.1145/3238147.
3240464
1 INTRODUCTION
Static program analyses compute semantic properties of programs,
which are the basis for program optimizations and for detecting
program errors and security vulnerabilities. Since most proper-
tiesofprogramsareundecidable,staticanalysesapproximatethe
set of possible program behaviors. For its results to be reliable,
a static analysis should be sound and precise. A soundanalysis
considers each possible program behavior, that is, computes an
over-approximation of all possible behaviors. Consequently, sound
analysesdonotproducefalsenegatives.A preciseanalysiscomputes
a tight approximation to minimize the number of false positives.
Many static analyses are based on the abstract-interpretation
framework [ 20]. In this framework, abstractions of the program
state are represented by elements of abstract domains ; for instance,
numerical abstract domains may track intervals of possible values
fornumericalvariablesorconstraintsbetweenthem.Theseman-
tics ofprogram operationsis representedby abstracttransformers,
which specify the effect of an operation on the abstract state.
Eventhough itis possibleto proveproperties ofthe designofa
static analysis, ensuring soundness and precision for its implemen-
tationis challenging. In fact, implementations of abstract domains
areoftencomplexandhighlyoptimizedinordertomaximizeperfor-
manceandscalability[ 46].Errorsintheseimplementationslikely
affect the usefulness of all static analyzers that build on them.
Imagine a static analysis that abstracts numerical variables to
intervalsofpossiblevalues.Forinstance,theabstractvalue [0,5]for
anintegervariable xexpressesthat,ineachprogramexecution,the
concrete(actual)valueof xsatisfies0 ≤x≤5.TheexampleinFig. 1
illustratesapotentialsoundnesserrorduetoarithmeticoverflow.
Without prior knowledge about parameter p, its abstract value
is[INT_MIN,INT_MAX],andconsequently,theabstractvalueof
aafter the assignment is [INT_MIN+1,INT_MAX+1]. If this
abstract domain is implemented using bounded integers, a naive
implementationoftheadditionoperatorwillleadtoanoverflowand
768
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France A. Bugariu, V. Wüstholz, M. Christakis, and P. Müller
int foo( int p) {
int a: =p+1 ;
...
}
Figure 1: Potential soundness error due to overflow.
produce[INT_MIN+1,INT_MIN].Thisemptyintervalindicates
thatthecodeaftertheassignmentisunreachable,whichisunsound.
Inparticular,thisunsoundresultmightmaskprogramerrorsand
security vulnerabilities in subsequent code.
Inthispaper,weassesstheeffectivenessofexistingautomatic
testingtechniquesinfinding,amongothererrors,soundnessand
precision issues in widely-used implementations of abstract do-
mains.Wegeneratetestinputsusinganovelcombinationofexisting
ideas:startingfromapoolofpre-selectedvalues,weapplyabstract-
domainoperationstocreaterepresentativedomainelements,and
vary the operations by employing an off-the-shelf gray-box fuzzer,
suchasAFL[ 7]orLibFuzzer[ 6],tomaximizecoverage.Asinearlier
workbyMidtgaardandMøller[ 40],weusemathematicalproperties
of abstract domains as test oracles. However, we target real-world
implementationsofcomplexabstractdomains(e.g.,APRON’sOc-
tagonsdomain[ 41]andELINA’sPolyhedradomain[ 46]),andwe
extend the set of tested properties by including more precision
properties and by approximating termination properties.
Our evaluation on severalabstract domains of the APRON [ 31]
and ELINA [ 46] libraries shows that our combination effectively
detectssoundnessandprecisionproblemsincomplex,mature im-
plementations. In particular, we show that it is more effective than
purely relying on existing test case generation techniques, suchas gray-box fuzzing and dynamic symbolic execution (DSE, also
known as concolic testing) [14, 28].
Our main contributions are the following:
(1)We present a novel combination of automatic test case gen-
eration techniques to detect, among other errors, soundness
andprecisionissuesinimplementationsofabstractdomains.
(2)We demonstrate that our technique effectively finds bothseeded and real errors in widely-used implementations of
numerical abstract domains.
(3)We show that our technique tests abstract domains more
effectively than standard DSE or gray-box fuzzing.
Ourexperienceisusefulfordevelopersofabstractdomainsto
ensure soundness and precision of their implementations. It is
alsousefulfordevelopersofstaticanalyzerstoassessthequality
of available abstract-domain libraries. Even if the design of an
abstractdomainintentionallysacrificessoundnessinfavorofother
qualities [ 16,37], it is still important to check the implementation
forunintentional unsoundness caused by implementation errors.
Outline. The next section summarizes some background on ab-
stractinterpreters. Sect. 3givesan overviewof ourapproach,and
Sect.4explains the technical details. In Sect. 5, we present our
experimentalevaluationonreal-worldimplementationsofabstractdomains.WediscussrelatedworkinSect. 6andconcludeinSect. 7.
2 BACKGROUND
Abstract interpretation [ 20] is a theoretical framework for express-
ing static analyses, used by many industrial analyzers, such asAstrée [12] and Clousot [ 26]. It relies on abstract domains to rep-
resent abstractions of concrete program states, and on abstract
transformers tomodelthebehaviorofprograminstructions,such
as assignments and conditionals.
Abstractdomainsareoftenreusedacrossmanydifferentprogram
analyses. For example, most static analyzers employ numerical
domains, which are, therefore, the focus of this paper. Widely-used
numerical domains include Intervals [ 19], which capture the range
ofvaluesforeachvariable,Octagons[ 41],whichcanalsoexpress
simple relations between two variables, Polyhedra [ 23], which can
capture linear inequalities between arbitrarily many variables, and
Zonotopes [29], which express affine relations.
Mostabstractdomainsarerepresentedbycompletelatticesofthe
form/parenleftbig¯A,/subsetsqequal,⊥,/latticetop,/unionsq,/intersectionsq/parenrightbig.¯Adenotes the set of abstract elements ¯x,
whicharepartiallyorderedby inclusion /subsetsqequal.Eachabstractelement
represents a set of constraints, i.e., mathematical relations between
variables and constants. The bottomelement⊥is the least element
of the lattice; it represents the empty set of concrete states and
corresponds to an unsatisfiable set of constraints. The topelement
/latticetopisthegreatestelementandrepresentstheuniversalsetofconcrete
states; that is, all variables are unconstrained.
/unionsqand/intersectionsqare thejoinandmeetoperators, which are used to
obtain the union, respectively the intersection, of two abstractelements. Additionally, an abstract domain whose lattice has an
infiniteheight requiresa widening operator( /triangleinv)to ensurethatthe
analysiseventuallyreachesafixedpoint.Somedomains(suchas
Intervals and Octagons) also support a narrowing operator ( /triangle),
which can improve the precision of the analysis [22].
Abstracttransformersaretypicallyspecifictoagivenanalysis
andprogramminglanguage,butsometransformersareuniversal
buildingblocksformanyanalyses.Theseinclude assigntorepresent
an assignment, condto assume a condition to hold, and project
toeliminateanypreviousinformationaboutoneofthevariables
(e.g.,whenanewvalueofavariableisreadfromafile).Here,we
focus on these transformers because they are the most complex to
implement[ 47](andthusthemosterrorprone).Ageneralization
of our approach to other transformers is mostly straightforward.
3 OVERVIEW
Since implementations of abstract domains are often used as li-
brariesbymanydifferentprogramanalyses,weapplyaunittesting
approach. Compared to system testing, unit testing allows us tospecify generic test oracles, which are independent of a specific
abstractdomainorstaticanalysis.Moreover,itfacilitatesthegenera-tionoftestdatabecauseabstract-domainelementscanbegeneratedmuchmoreeasilythaninputprogramsforawholeanalyzer[
40].In
this section, we give an overview of the three mainingredients of
ourautomaticunittestapproach:testoracles,testinputgeneration,
and test drivers. Details will be presented in Sect. 4.
3.1 Test Oracles
Theabstractinterpretationframeworkprescribesanumberofprop-
erties of the domain operators and abstract transformers (collec-tively referred to as domain operations in the rest of the paper),
whicharerequiredforsoundness.Forinstance,iftheabstractel-
ement
¯x(capturing the pre-state of an assignment) is reachable
769
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. Automatically Testing Implementations of Numerical Abstract Domains ASE ’18, September 3–7, 2018, Montpellier, France
(that is, different from bottom), the post-state of the assignment
v:=eshouldalsobenon-bottomforallvariables vandwell-formed
expressions e:
¯x/nequal⊥⇒assign(¯x,v,e)/nequal⊥ (a)
We use these general soundness conditions as test oracles. We also
identify a number of general precision conditions, whose violation
indicatesthattheresultofadomainoperationisover-approximated
more than necessary. For this purpose, we compare the result of a
domain operation to the best transformer, that is, the most precise
resultrepresentable in a given abstract domain. For instance, the
result of intersecting top with an element should be equal to the
element itself:
/latticetop/intersectionsq¯x=¯x (b)
Moreover, we check that widening and narrowing converge within
agivennumberofiterations,whichensurestheterminationofany
fixed-point computation in which they are used.
Note that all the properties considered in this paper are defined
under the assumption that the analyzed programs do not raise
exceptions,otherwise thebehavior ofthe staticanalyzerdepends
on the semantics of the programming language. For example in C,
divisionbyzerocausesundefinedbehavior.Whenclassifyingthe
properties into soundness and precision (as described in Sect. 4),
we assume that the abstract domain does not model error states.
3.2 Input Data
Abstract domains often use sophisticated data structures to op-
timize performance. For instance, elements of the Polyhedra do-
main are typically represented using both matrices and vectorsof floating-point numbers. In our experiments, we observed that
thestandardtestcasegenerationtechniquesdonotworkwellfor
complex abstract domains. In particular, fuzzing failed to detectsubtle interactions between domain operations, and DSE did noteffectively explore real-world implementations that make heavy
useoffloating-pointarithmeticandlibraries.We,therefore,usea
combination of testcase generation techniques to create apool of
domain elements, which serve as test inputs to domain operations.
The pool is populated in two steps.
Step1createsaninitialpoolbycombiningboundaryandrandom
testing. Each element of a numerical domain can be constructed
fromnumericalconstraints.Forinstance,anelementoftheInter-
vals domain, which maps program variables vito their possible
ranges, is created from the constraint kl≤vi≤ku(the constants
klandkuare the lower and upper bounds). We generate the nu-
merical constants randomly or choose them from a pre-defined set
of boundary values that are more likely to expose bugs, such as
off-by-one errors and arithmetic overflows. If the Intervals domain
is implemented using machine integers, these boundary valuesare
{INT_MIN,0,INT_MAX}. The initial pool also contains the
extreme elements /latticetopand⊥.
Selecting inputs from this pool (together with a suitable expres-
sione)asargumentstothe assigntransformerwilllikelydetectthe
possible unsoundness illustrated in Fig. 1. The initial pool is likely
to contain an element mapping the variable pto[0,INT_MAX]
since 0 and INT_MAXare pre-defined boundary values; moreover,
wearelikelytoobtainanexpression eofthefrom p+kforapositiveconstantk(seeSect. 4fordetails).Evaluatingthe assigntransformer
on these inputs violates soundness property (a) defined above.
Theinitialpoolallowsustotest individual domainoperations.
However,thisapproachisinsufficientintwosituations.First,some
implementationsrelyoncomplexconsistencyconditionsontheir
datastructures.ForPolyhedra,forinstance,thetwointernalrep-
resentations must be kept consistent. If a faulty operation violates
this invariant, the effect can be often observed only when applyingasubsequentoperation;itisthusnecessarytoperformatleasttwo
consecutive operations to detect the bug.
Second,thereare certainsoundness orprecision propertiesof
individual operationsthatcannotbecheckedbygeneric,domain-
independent oracles. For instance, the assigntransformer for Oc-
tagonsshould,insomecases,applyaso-calledclosureoperation;
failing to do so or using an imprecise closure may lead to loss of
precisioninsubsequentoperations,suchasinclusionorequality
tests[41].Atestoraclethatdirectlydetectsamissingclosurewould
bespecifictoOctagonsand,thus,notreusable.Amoregenericway
to detect this problem is by intersecting the result of the assign
transformer with top. The expected output of the intersection isthe same as the result of the
assigntransformer itself. However,
ifthetransformerdoesnotapplytheclosurewhenexpected,the
domain-independent property (b) may fail due to imprecision.
Theabovesituationscanbothbetestedbyexecutingatleasttwo
consecutive domain operations before checking the oracle.There-
fore, step 2 of our input generation expands the pool of domainelements by iteratively applying a domain operation to existing
poolelements(andpossiblyotherarguments)andaddingtheresulttothepool.Byrepeatingthisprocess,weincreasethelikelihoodof
constructing elements that need to be built incrementally with sev-
eraldomainoperations.Asaresult,wearealsomorelikelytodetect
bugs that manifest themselves only in consecutive operations.
3.3 Test Drivers and Exploration
Foreachpropertyundertest,wemanuallywriteatestdriverthatisparametricin:(1)theoperationsandtheirargumentsusedinstep2
to populate the pool of domain elements, and (2) the arguments of
the property under test.
Fig.2shows, in pseudo code, our test driver for checking sound-
ness property (a) for the assigntransformer. The driver takes as
argumentsasequenceofoperations( ops),whichareusedinstep2
ofthepoolcreation,asequenceofindicesintothepool( elems),
a sequence of expressions ( exprs), and a sequence of program
variables ( vars). The latter three provide arguments to the do-
main operations. The driver also takes as arguments an index into
thepool( oelem),anexpression( oexpr),andavariable( ovar),
whichareinputstothepropertyundertest(ororacle)(lines17–21).
The test driver initializes the pool of abstract elements by creat-
ingvalid inputsfor thecurrently testeddomain, suchasIntervals
orOctagons(step1,line4).Then,itextendsthepoolbyapplying
domainoperations(step2,lines7–14).Eachiterationobtainsthe
nextoperationanditsargumentsfromtheparametersofthetest
driver, applies it, and adds the result to the pool. Finally, the test
driverassertsproperty (a)aftercomputingtheresult ofthe assign
operation. For simplicity, we omit optimizations (for instance, our
implementationinitializesthepoolonlyonce,beforeallthedrivers
770
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France A. Bugariu, V. Wüstholz, M. Christakis, and P. Müller
1test_assign(ops, elems, exprs, vars,
2 oelem, oexpr, ovar) {
3 // populate poo l, step 1
4 pool := init();
5
6 // populate poo l, step 2
7 for(i := 0; i < nbops; i++) {
8 op := ops[i];
9 x := pool[elems[i]];
10 y := pool[elems[nbops + i];
11 e := exprs[i];
12 v := vars[i];
13 add_to_pool(pool, apply(op, x, y, e, v));
14 }
15
16 // execute assign transformer
17 x := pool[oelem]
18 res := apply(assign_op , x, ovar, oexpr);
19
20 // check property (a)
21 assert x/nequal⊥⇒ res/nequal⊥;
22}
Figure2:Pseudocodeofatestdriverforcheckingsoundness
property (a) of the assignment transformer.
are run) and several technicalities, such as ensuring that indices
are within bounds.
We use the state-of-the-art gray-box fuzzer LibFuzzer [ 6]t op r o -
vide the arguments to the test driver, i.e., to choose the operations
usedinstep2togetherwiththeirarguments,andtheparameters
for the property under test. Gray-box fuzzers use a lightweight
code instrumentation to generate inputs that are likely to execute
previously uncovered code. In our implementation, all parameters
ofthetestdriverareencodedintoonearray,whichiscreatedby
the fuzzer.
4 TECHNICAL SOLUTION
In this section, we provide the technical details of our approach.
4.1 Test Oracles
Ourtestoraclesarebasedondomain-independentmathematical
properties of abstract operations. In the following, we give an
overview of these properties and explain how they are checked by
the test drivers.
Properties. Basedontheabstract-interpretationliterature[ 20,21]
andearlierworkontestingstaticanalyzers[ 40],weidentified46
properties that need to be satisfied by domain operations to ensure
soundness, precision, and termination. Fig. 3provides an overview.
Thesoundnesspropertiesarerequiredtoensurethatanabstract-
domainelementover-approximatestheconcretestatesitrepresents.
Wehavediscussedanexampleintheprevioussection(property35).
To deal with the undecidability of most semantic program prop-
erties,staticanalysesover-approximatethesetofconcreteprogram
behaviors and then infer or check properties on this abstraction.
Since they are intended to compute an approximation, one cannot
expect the operations of an abstract domain to be precise w.r.t. the
concrete program execution. Therefore, our precision properties
check that the domain operations do not lead to unnecessary infor-
mation loss, that is, they compare the result of an operation to thePartial order Join/Meet bounds
1⊥/subsetsqequal¯x [P]27∀¯b:(¯x/subsetsqequal¯b)∧(¯y/subsetsqequal¯b)
2¯x/subsetsqequal/latticetop [P] ⇒(¯x/unionsq¯y/subsetsqequal¯b) [P]
3¯x/subsetsqequal¯x [P]28∀¯b:(¯b/subsetsqequal¯x)∧(¯b/subsetsqequal¯y)
4¯x/subsetsqequal¯y∧¯y/subsetsqequal¯z⇒¯x/subsetsqequal¯z[P] ⇒(¯b/subsetsqequal¯x/intersectionsq¯y) [P]
5¯x/subsetsqequal¯y∧¯y/subsetsqequal¯x⇒¯x=¯y[P] Widening
Join 29¯x/subsetsqequal¯x/triangleinv¯y [S]
6⊥/unionsq¯x=¯x [P]30¯y/subsetsqequal¯x/triangleinv¯y [S]
7/latticetop/unionsq¯x=/latticetop [S]31¯x/triangleinv⊥=¯x [P]
8¯x/subsetsqequal¯x/unionsq¯y [S]32⊥/triangleinv¯x=¯x [P]
9¯y/subsetsqequal¯x/unionsq¯y [S]33widening converges [C]
10¯x/unionsq¯y=¯y/unionsq¯x [P] Assignment [a=assign]
11(¯x/unionsq¯y)/unionsq¯z=¯x/unionsq(¯y/unionsq¯z)[P]34¯x/subsetsqequal¯y
12¯x/unionsq¯x=¯x [P] ⇒a(¯x,v,e)/subsetsqequala(¯y,v,e)[P]
13¯x/subsetsqequal¯y⇒¯x/unionsq¯y=¯y [P]35¯x/nequal⊥⇒a(¯x,v,e)/nequal⊥ [S]
14¯x/unionsq¯y=¯y⇒¯x/subsetsqequal¯y [P]36¯x=⊥⇒a(¯x,v,e)=⊥ [P]
15¯x/unionsq(¯x/intersectionsq¯y)=¯x [P]37rep(e,¯x)⇒a(¯x,v,e)/nequal/latticetop[P]
Meet Projection [p=project]
16⊥/intersectionsq¯x=⊥ [P]38a(¯x,v,e)/subsetsqequalp(¯x,v) [P]
17/latticetop/intersectionsq¯x=¯x [P] Conditional [c=cond]
18¯x/intersectionsq¯y/subsetsqequal¯x [P]39¯x/subsetsqequal¯y⇒c(¯x,e)/subsetsqequalc(¯y,e)[P]
19¯x/intersectionsq¯y/subsetsqequal¯y [P]40¯x=⊥⇒c(¯x,e)=⊥ [P]
20¯x/intersectionsq¯y=¯y/intersectionsq¯x [P]41c(¯x,e)/subsetsqequal¯x [P]
21(¯x/intersectionsq¯y)/intersectionsq¯z=¯x/intersectionsq(¯y/intersectionsq¯z)[P] Narrowing
22¯x/intersectionsq¯x=¯x [P]42¯x/intersectionsq¯y/subsetsqequal¯x/triangle¯y [P]
23¯x/subsetsqequal¯y⇒¯x/intersectionsq¯y=¯x [P]43¯x/triangle¯y/subsetsqequal¯x [P]
24¯x/intersectionsq¯y=¯x⇒¯x/subsetsqequal¯y [P]44¯x/triangle⊥=⊥ [P]
25¯x/intersectionsq(¯x/unionsq¯y)=¯x [P]45⊥/triangle¯x=⊥ [P]
26disj(¯x,¯y)⇒¯x/intersectionsq¯y=⊥[P]46narrowing converges [C]
Figure 3: Algebraic properties of abstract domains. We clas-
sify them into soundness [S], precision [P], or convergence[C]. Note that all free variables are implicitly universallyquantified and all variables refer to abstract-domain ele-mentsexceptforvariables vande,whichrefertoaprogram
variable and an expression, respectively. Predicate disj(¯x,¯y)
denotes that the intersection of the set of constraints from
¯xand¯yistriviallyempty,andpredicate rep(e,¯x)thatecanbe
precisely represented in the abstract domain of ¯x.
most precise representable result as obtained by applying the best
transformer (see Sect. 3).
Forinstance,computingthejoinoftwointervals [1,1]and[3,3]
yields[1,3], which loses the information that the variable is differ-
ent from 2. Despite this inevitable information loss, a join operator
shouldsatisfyanumberofprecisionproperties(6,10–13,15);for
instance, property 13 prevents the join of [1,1]and[1,3]from
returning [0,4]or/latticetop, which is sound, but unnecessarily imprecise.
Thesoundnessandconvergencepropertiesneedto holdforall
abstractdomains;someprecision properties maynotalwayshold
whenthebesttransformersdonotexistorcannotbecomputed[ 43].
Forinstance,domainsbasedonincompletelattices(suchasZono-
topes) do not have a least upper bound for every pair of abstract
elements.Thiscanforce /unionsqtoreturnalargerupperboundand,thus,
violate property 27. For such domains, we require developers to
select the subset of precision properties that should be checked.
The convergence properties (33 and 46) require widening and
narrowing to eventually reach a fixed point, which is necessary to
ensure that the static analysis of loops and recursion terminates.
Sinceconvergenceisaterminationproperty,whichcannotbetested,
weinsteadcheckthestrongerpropertythatafixedpointisreached
within a given number of iterations, as we explain below.
Executable oracles. We manually construct a test driver for each
of the properties in Fig. 3. This driver selects suitable inputs for
771
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. Automatically Testing Implementations of Numerical Abstract Domains ASE ’18, September 3–7, 2018, Montpellier, France
1i: =0 ;
2x := pool[oelems[i]];
3while (true) {
4 i: =i+1 ;
5 y := pool[oelems[i]];
6 res := apply(widening_op , x, y);
7 if(res == x)
8 break ;// a fixed point is reached
9 x := res;
10 assert i<k ;
11}
Figure4:Fragmentofatestdriverforcheckingwhetherthe
Octagons widening reaches a fixed point within ksteps.
each of the free variables of the property to be tested, evaluates
the property, and checks that it holds. For instance, for property 3,
itselectsadomainelement dforvariable ¯xandchecksthatthe /subsetsqequal
operator yields true when applied to dandd.
Translatingpropertiesintoexecutableoraclesisstraightforward
for most soundness and precision properties, but slightly more in-
volved for convergence properties. Fig. 4shows a fragment of our
test driver for checking whether the Octagons widening converges
afterkiterations [ 41]. The driver computes an increasing chain of
xelements (as checked by property 29), each obtained by widen-
ing the previous element with an arbitrary element y. Widening
convergesifthe x-chainbecomesstable,here,within ksteps.We
observed that k=100 is a sufficient upper bound for all our tested
analyzers, because widening converges much faster in practice.
Notethat,formostabstractdomains(suchasIntervals,Octagons,
etc.), widening can be applied to arbitrary elements. There are,
however, some exceptions; for instance, the Polyhedra widening
requiresmonotonicityofitsoperands(thatis, x/subsetsqequaly).Insuchcases,
we use a slightly different test driver that applies widening on x
andthejoinof xandy;thatis,bychangingthelastparameterof
applyonline6ofFig. 4tox/unionsqy,becausex/subsetsqequalx/unionsqy(seeproperty8).
Asaconsequenceofthismonotonicityprecondition,property31
needs to hold for the Polyhedra domain only for ¯x=⊥.
4.2 Input Data
TestingthepropertiesfromFig. 3requiresthreekindsofinputdata:
(1)programvariables,(2)expressionsoverthem(forthe assignand
condtransformers), and (3) abstract-domain elements that contain
constraints over these variables. We construct this data as follows.
Program variables. All our test cases operate on a set of pre-
defined integer variables. The number of variables must be suffi-
ciently small to keep the memory consumption and execution time
of the test cases low. On the other hand, abstract-domain optimiza-
tions, such as decomposition, require enough variables to obtain
non-trivialpartitions[ 46].Inourimplementation,thenumberof
variablesisconfigurable;weuseeightvariablesinourexperiments.
Expressions. Testing assignments requires numerical expressions.
Forthenumericaldomainsconsideredinthispaper,theseexpres-
sions are linear sums over the program variables with integer coef-
ficients, whichare chosenby thefuzzer toincrease thelikelihood
of constructing suitable expressions. Note that, to test precision
properties,wealsoneedtogenerateexpressionsthatarenotrep-
resentableinthedomainundertest.Forinstance,foranoctagonTable 1: Structure of abstract elements with one constraint
for commonly used numerical domains.
Domain Element with one constraint
Intervals {kl≤vi≤ku}
Zonotopes {vi=kl+ku
2+ku−kl
2∗εi}
Octagons {civi+cjvj⊙k}
Polyhedra {c0v0+c1v1+...cdim−1vdim−1⊙k}
v: variables, c: coefficients, ε∈[ −1,1],k: constants, ⊙∈{ ≥ ,=}
{v0≥0∧v1≥0}, the assignment v2:=v0+2v1is expected to
produce{v0≥0∧v1≥0∧v2≥0}(andnot/latticetop),eventhoughthe
assigned expression is not octagonal. For the condtransformer, we
obtain boolean expressions by comparing the linear sums to zero.
Domain elements. As explained in Sect. 3,w ec r e a t eap o o lo f
abstract-domain elements (such as intervals or octagons) in two
steps: Step 1 populates the pool by constructing elements usinga combination of boundary and random testing, whereas step 2
expandsitbyapplyingdomainoperationstoexistingpoolelements.
Besides/latticetopand⊥,step1alsocreatessimpledomainelementsthat
contain only one constraint on the pre-defined program variables.
More complex domain elements are constructed in step 2. Tab. 1
shows the structure of simple domain elements for common nu-
mericaldomains.Theseelementscanbeconstructedbychoosing
valuesfortheconstants k(e.g.,theboundsofaninterval)andthe
coefficients c. By default, we pick them from a small set of pre-
definedvalues (e.g.,boundaryvaluessuchas0or ∞)andasmallset
ofarbitrary values. The use of pre-defined values is optional and
can be configured in the test drivers (see Sect. 5).
These sets of valuesdepend on both the domain under testand
its implementation. For instance, octagonal coefficients must be in
{−1,0,1},whereaspolyhedralonesarearbitraryintegers.Moreover,
differentimplementationsrepresentnumbersdifferently;e.g.,we
use the pre-defined values {INT_MIN,0,INT_MAX}for integer
intervals if the implementation uses machine integers, {−∞,0,∞}
for arbitrary-precision integers, and additionally NaNfor floating-
pointrepresentations.Eventhoughwefocusonintegerprogram
variables here, internal floating-point computations may lead to
rounding errors, as we observed in our experiments (see Sect. 5).
Thevaluesinbothsetsare notchosenbythefuzzer.However,
thefuzzercanstillcontrolthepoolofdomainelementsbyselecting
suitable operations in step 2. This step constructs more diversedomain elements, usually with more complex constraints, by ap-plyingdomainoperationstotheexistingelements.Step2makes
useofalldomainoperatorsthatyielddomainelements( /unionsq,/intersectionsq,/triangleinv)as
well as the abstract transformers assignandproject. For simplicity,
we omit narrowing, which is not supported by all domains, and
conditionals. Using all these domain operations not only allowsus to detect errors in their implementation (such as the missing
closure in assignments that we discussed in Sect. 3), but it also
efficiently generates a diverse set of validdomain elements. While
itistheoreticallypossibletocreateanewelementbygenerating
an arbitraryset ofconstraints, suchan approachwould oftenpro-
duce unsatisfiableconjunctions ofconstraints, representedby the
already considered ⊥element.
772
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France A. Bugariu, V. Wüstholz, M. Christakis, and P. Müller
5 EXPERIMENTAL EVALUATION
Toevaluatetheeffectivenessofourapproach,weapplyittotwo
complex libraries for numerical analysis, namely APRON [ 31] and
ELINA [46]. We were able to find errors in several of the imple-
mented domains. Most of them are already confirmed and fixed.
APRON is a mature library, extensively used in many academic
and industrial static analyzers, such as Astrée [ 12] and PAGAI [ 30],
as well as in the CPAchecker verification platform [ 11]. ELINA
is a recent library that uses highly-optimized algorithms based
ononlinedecompositiontoachievesignificantspeedups[ 46,47].
These algorithms are difficult to implement correctly.
In our experiments, we consider three variants of APRON with
differentinternalrepresentationsfornumericalvalues(Sects. 5.1
and5.2), and two versions of ELINA (Sect. 5.3). We also evaluate
differentconfigurationsofourtechnique(Sect. 5.4),andcompareit
to pure fuzzing and DSE (Sect. 5.5).
Experimental setup. Since the tested domains have different
complexity(i.e.,theimplementationofPolyhedraissignificantly
slower), we estimated the maximum execution time required to
testeachpropertyapproximatelyonemilliontimesforIntervals,
Zonotopes,andOctagons,andhalfamilliontimesforPolyhedra
(see Tab. 2). The values are smaller for ELINA than for APRON
becauseELINA’scodeishighlyoptimized.IntervalsandZonotopes
were not considered for ELINA, as they were not part of the tested
artifacts[ 3,4].Alltheexperimentswereperformedona3.3GHz
IntelXeonE5-4627v2CPUwith236GBmemoryandRAID6HDD.
5.1 APRON Double and Rll
APRONsupportsdifferentinternalrepresentationsfornumerical
values. For instance, the Doublerepresentation uses floating-point
numbers, while Rlluses an approximation of rational numbers
basedontwo64-bitintegersforthenumeratoranddenominator.
ComparedtoAPRONMPQ,whichusesarbitrary-precisionrationals
(seeSect. 5.2),theserepresentationsofferbetterperformance,but
may lose precision and cause non-termination [ 1]. Intervals and
Octagons support Double, while Rll is available for Polyhedra.
Our experiments indeed uncovered soundness, precision, and
termination problems in several domains of the latest version of
APRON (0.9.10), as shown in Tab. 3. Here, the three versions of Rll
refertodifferenttestconfigurationsthatwediscusslater;thedo-
mainimplementationisalwaysthesame.Thethirdcolumnpresents
the total number of properties from Fig. 3that we attempted to
test for each domain. We tested only the first 41 properties forIntervals and Polyhedra since narrowing is not implemented for
Intervals in APRON and not mathematically defined for Polyhedra.
The reported violations in the fourth column are not necessarily
allcausedbydifferentbugs.Nevertheless,observingmultiplevio-
lations caused by the same bug can provide additional information
Table 2: Maximum execution time per test driver.
DomainMaximum execution time (s)
APRON ELINA
Intervals 750 not consideredZonotopes 2’400 not consideredOctagons 1’900 700Polyhedra 17’700 1’800Table 3: Results for APRON Double and Rll. The third col-
umnreportshowmanyofthepropertiesfromFig. 3wereap-
plicableforeachtesteddomain.Thefirstvalueinthefourth
columnshowsthenumberofviolatedsoundnessproperties,the second represents precision properties, and the thirdindicates how often errors in the domain implementationcaused the test driver to crash or time out.
Variant Domain#PropertiesCausesTested Violated
Double Intervals 41 0 / 0 / 0 –
Double Octagons 46 0 / 3 / 0 roundingRll v1 Polyhedra 41 0 / 0 / 41 overflowRll v2 Polyhedra 41 5 / 15 / 21 overflowRll v3 Polyhedra 41 5 / 19 / 4 overflow
forerrorlocalization.Weusedaconfigurationthatinitializesthe
pool with 32 elements (step 1 of the pool population), includes
LONG_MINandLONG_MAXasboundaryvalues,andapplies16
operations to generate more complex domain elements (step 2).
ThiscorrespondstoconfigurationC2fromTab. 6,whichwediscuss
in Sect.5.4, together with measurements on the testing time.
Intervals and Octagons. All our generic properties hold for In-
tervals, the simplest domain we tested. Nonetheless, we indirectly
foundimprecisionsfor /subsetsqequaland/unionsq,bytestingAPRON’sefficientim-
plementation of Zonotopes [ 27] (discussed in Sect. 5.2), which uses
the Interval operations. These issues were confirmed and fixed.
For Octagons, three precision properties (17, 22, and 23) are
violated because the equality test gives imprecise results due to
rounding errors. In Fig. 5, we show an example input generated
by our approach that violates property 17. octrepresents a call to
the Octagons constructor. The root cause of the imprecision is the
underlyingdoublerepresentation.For oct3,LONG_MAXcannotbe
precisely represented as a double value. The resulting rounding
error gives approximate results in the subsequent computations
and makes the assertion on line 5fail.
Polyhedra. With the same test configuration (C2), all the tests fail
toterminateforPolyhedraRll(Rllv1inTab. 3).Theproblemisthat
APRON enters infinite loops during step 1 of the pool construction
becauseofunhandledarithmeticoverflows.Thebugcanbeseen
when constructing at least two consecutive domain elements, as in
Fig.6. The second constructor call enters an infinite loop.
This bug causes all test drivers to time out before they even
reach the test oracle. To work around it and look for additional
bugs, we replaced LONG_MINandLONG_MAXbyINT_MINand
INT_MAXas pre-defined values in the pool construction. In this
case (Rll v2 in Tab. 3), step 1 of the pool construction succeeds, but
for21testdrivers,step2timesout.Theremaining20testdrivers
lead toviolations of soundnessand precision properties.The root
cause of all these failures is unhandled arithmetic overflows in
variousoperators.Droppingpre-definedvaluesentirely(Rllv3in
1oct1= oct(−x0−x5+1>=0);
2oct2= assign( oct1,x2,LONG _MIN );
3oct3= oct(x0+LONG _MAX >=0);
4oct4= meet(oct3,oct2);
5assert meet(/latticetop,oct4)==oct4;
Figure 5: Input violating property 17 for Octagons.
773
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. Automatically Testing Implementations of Numerical Abstract Domains ASE ’18, September 3–7, 2018, Montpellier, France
1poly1= poly( −x5−x6+x7>=LONG _MAX );
2poly2= poly( −x4−x5−x6−x7>=LONG _MIN );
Figure 6: Input entering an infinite loop for Polyhedra.
Tab.3) allows us to construct the pool in all but four cases. In total,
24 soundness and precision properties fail due to overflow.
5.2 APRON MPQ
MPQisanAPRONvariantthatusesarbitrary-precisionrationals
for its internal representation. For sub-polyhedral domains (i.e.,
Intervals, Octagons, and Polyhedra), this variant is supposed to
besound andprecise[ 1].Our experimentspartiallyconfirm these
theoretical guarantees: with the same setup as for APRON Double
andRll,wedidnotfindany(generic)propertyviolationsinAPRON
MPQ for the three sub-polyhedral domains. However, we uncov-ered imprecisions for Intervals indirectly, by testing Zonotopes.
Moreover,tofurthervalidateourtechnique,weaskedthreeexpertsinabstractinterpretationtoinsertbugsinanyofthesub-polyhedral
domains. Our results are presented in the following paragraphs.
Zonotopes. As opposed to sub-polyhedral domains, the structure
ofZonotopesisanincompletelattice.Forthisreason,notallthepre-
cisionpropertiesfromFig. 3areexpectedtohold(e.g.,asexplained
inSect.4.1,theleastupperboundmaynotexistforeverypairof
elements). Moreover, join creates new, input-related constants [ 27]
and thus the operator is by design non-commutative.
Initially, the pool construction step did not succeed for any of
thetestsduetoamemorybuginthemeetoperator.Afterapplying
the fix, we detected additional memory exceptions, raised when
creatingahighnumberofinput-relatedconstants.Ourtestsalso
revealed imprecisions in the implementation of the equality check,
meet, and project operations. Moreover, we discovered a precision
bug in the partial order. Soundness property 8 uses /subsetsqequalto check if
theresultofajoinover-approximatesitsoperands,andthebugled
toaviolationofthisproperty.Thedevelopersconcludedthatthe
root cause is an imprecision in the implementation of the Intervals
domain,whenoneoftheoperandsof /subsetsqequal,/unionsq,or/triangleinvis⊥,represented
in its canonical form through the empty interval [1,−1].I f⊥is
not handled as a special case, [1,−1]/unionsq[−10,−5]=[−10,−1], for
example,insteadof [−10,−5].Thisimprecisionisindependentof
theinternalrepresentationusedfornumbers.OurtestsforIntervals
couldnotdetectitdirectlybecauseourpropertiesaregenericanddo
not check the precision based on the Intervals-specific definitions.
All these issues were fixed by the APRON developers.
Seeded bugs in sub-polyhedral domains. We asked three ab-
stract interpretation researchers, a post-doc and two senior PhD
students with a broad experience inimplementing and using vari-
ous types of abstract domains and static analyses, to seed semantic
bugs for our evaluation. Each expert had the task of inserting at
least five soundness or precision bugs (at least one of each type)
inanyofthesub-polyhedraldomains.Webelievethattheseeded
bugs are representative of the kind of semantic errors that occur
during the development of abstract domains.
The cumulative results are summarized in Tab. 4. For each do-
main, we show how many bugs were seeded, how many our tech-
niquefound,andwhetherweobservedthebugsthroughviolationsTable4:ResultsforAPRONMPQwithseededbugs.Thelast
columnshowsthenumberofviolatedsoundnessproperties,precision properties, and of crashes and assertion failures.
Domain#Bugs #Properties
Seeded Found Violated
Intervals 5 4 1 / 14 / 0
Octagons 6 5 2 / 15 / 5
Polyhedra 6 5 4 / 10 / 52
of soundness or precision properties, or through crashes and as-
sertionfailuresinAPRON’sinternalconsistencychecks.Intotal,
we were able to find 14 out of the 17 seeded bugs. In the following
paragraphs,wepresenttwobugsthatwedetectedandexplainwhy
three of the seeded errors could not be found.
A seeded bug in Intervals uses a slightly modified version of
an unsound definitionfor the widening operator [ 38]. This defini-
tionuses ≤insteadof >tocomparetwobounds,whichleadstoa
violation of soundness property 30. Our tests reveal this problem.
A seeded bug in Octagons removes the call of closure in one
special case of the assignment transformer. As explained in Sect. 3,
wedetectthisbugbygeneratinganassignmentduringstep2ofthe
poolconstruction,followedbyameet,whichviolatesfourofour
precision properties because the equality check becomes imprecise.
While our approach found the vast majority of the seeded bugs,
therewerethreeitdidnotdetect.(1)OneseededbugmakestheOc-tagonsclosurelessprecise.Detectingthisproblemwouldrequiread-ditional,octagon-specificprecisionpropertiesforclosure[
41].This
canbeeasilydone,butourfocushereisondomain-independent
properties.(2)Anotherseededbugaffectstheprecisionofwiden-
ing for Intervals in a way that does not violate the properties from
Fig.3. Detecting it would again require additional, domain-specific
properties. (3) The last undetected bug changes the assignment
operator for Polyhedra to act like project, making it trivially sound,
butimprecise.Thisbugcanbeeasilyfoundiftheinputelements
are polyhedra of dimension 1 (practically intervals). Our defaultconfiguration excludes such elements; adjusting the range of di-
mensions to include the value 1 leads to a violation of property 37,
revealing the imprecision.
5.3 ELINA
To evaluate how effective our technique is on highly optimized
implementations, we applied it to test ELINA. We used the same
configurationasforAPRON(C2)onthefollowingabstractdomains:
–EP1: Polyhedra with decomposition [46]
–EOD: Octagons with decomposition [45]
–EO: Octagons without decomposition [45]
–EP2: more recent version (including bug fixes) of EP1
–EP3: decomposed Polyhedra with further optimizations [ 47]
EP1is the implementation in the artifact [ 3] from POPL’17 [ 46],
andtheothervariantsarepartoftheartifact[ 4]fromPOPL’18[ 47].
Notethat allELINA domainsarebased onfloating-point numbers
(notontheslowerarbitrary-precisionrationals).Thisdesigndeci-
sion may compromise precision to achieve high performance.
Initially, the pool construction for EP1failed for all the tests
due to corner cases likeLONG_MIN
−1. This step was also not suc-
cessful for EP2andEP3if the polyhedra had LONG_MAXcoef-
ficients (a similar issue as for APRON Double, see Sect. 5.1). To
774
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France A. Bugariu, V. Wüstholz, M. Christakis, and P. Müller
Table 5: Results for different variants of ELINA. The first
value in the third column shows the number of violated
soundness properties, the second of precision properties,
and the last crashes or violated assertions in ELINA’s code.
Variant#PropertiesCausesTested Violated
EP1 41 4 / 10 / 27 overflow, /triangleinv
EOD 41 0 / 3 / 0 rounding
EO 41 0 / 3 / 0 roundingEP2 41 0 / 0 / 41 overflow, assertionsEP3 41 4 / 18 / 19 overflow,
/triangleinv
find additional errors, we limited the set of pre-defined values
to{INT_MIN,−1,0,1,INT_MAX}. Our results are summarized in
Tab.5.Manualinspectionofthefailedtestsrevealedthatmostof
them werecaused byarithmetic overflows indifferent operations
(e.g.,assignand/intersectionsq).Wealsofoundissuesduetooverlyrestrictive
assertions in the code as well as an incorrect implementation of
widening for certain cases (e.g., widening with ⊥). We reported
these issues (and others), and they were fixed by the developer.
Oneofthemostinterestingbugswefoundin EP1isrelatedto
aninconsistencybetweenthetwopolyhedralrepresentations.To
improveperformance,ELINAusesanoptimizedimplementation
oftheChernikovaalgorithm[ 49]forincrementalconversionand
applies all the operators on decomposed polyhedra. Such optimiza-
tionsmakeitmuchmoredifficulttokeepthetworepresentationsin
sync.Ourpool-constructionapproachwasabletocreatepolyhedra
with inconsistent internal states, by applying sequences of meet
andjoinoperationsthatusedifferentinternalrepresentations.Asa
result, the subsequent test for the soundness of assignfailed (prop-
erty 35), because the transformer returned ⊥. The same bug was
reportedbyanotherELINAuser[ 50]afewdaysbeforewereported
it, which shows that our approach detects bugs that are relevant
for users of numerical libraries. It was fixed in the meantime.
SincenarrowingwasnotavailableforOctagonsthroughELINA’s
APRON interface (which we use for testing), we did not include
the corresponding test drivers in this experiment (only the first 41
properties were tested, as shown in Tab. 5). For both variants of
Octagons, like for APRON Double (see Sect. 5.1), properties 17, 22,
and23wereviolated.Theseimprecisionsarecausedbyrounding
errors when performing closure and, implicitly, in the equalitytests.Wereportedtheissuesandtheywereconfirmed.However,
obtaining very precise results with finite-precision representations
is challenging and the developer is still working on a fix.
5.4 Different Configurations
Ourtechniquereliesonthreemainconfigurableparameters:(1)thesize of the initial pool in step 1 of the input generation (see Sect. 3),
(2) the number of operations applied in step 2, and (3) whether
pre-defined values are used to construct elements and expressions.
We now assess the impact of these parameters on its effectiveness.
Forthisexperiment,weusedthethreeversionsofAPRONMPQ
with the bugs seeded by the experts and the configurations shown
in Tab.6. The results are presented in Tab. 7. For each seeded bug,
wereporttheabstractdomaininwhichitwasinserted,theviolated
properties, and the execution time until each configuration detects
the violation. As shown in the table, configurations C2, C5, and C6
allfindthemaximumnumberofviolations,andimplicitlyalltheTable 6: Different configurations of our technique.
Configuration Initial pool size #Operations Pre-defined values?
C1 2 16 yes
C2 32 16 yes
C3 1024 16 yesC4 32 0 yes
C5 32 64 yes
C6 32 16 no
bugs, within the time limits defined in Tab. 2. However, C2 does so
significantly faster than C5 and slightly faster than C6.
Initial pool size. Whentheinitialpoolincludesjust /latticetopand⊥(as
in C1), no violations are detected for Intervals in comparison to
C2, that is, 4 bugs are missed. On the other hand, a very large
initial pool (C3) increases the execution time without detecting all
violations. We attribute this to the fact that the size of the initial
pooldirectlyinfluencesthenumberofpossibleargumentstothe
subsequent operations in step 2 and to the test oracle; exploring all
of them takes more time without necessarily being more effective.
Numberofoperations. Withoutusingstep2ofthepoolconstruc-
tion(C4),somebugsandpropertyviolationsaremissed(seeSect. 3
for an example). However, for our technique to be effective, the
number of operations should not be too large since it increases the
executiontime.InTab. 7,C5isusuallyslowerthanC2eventhough
both configurations find the same number of violations.
Pre-defined values. ForAPRONMPQ,whichusesarbitrarypre-
cision rationals, both C2 and C6 find all the violations, C2 being
slightly faster. Pre-defined values are particularly important for
testing abstract-domain implementations based on fixed-precision
numbers such as APRON Double; as our experiments show (seeSect.5.1and Sect. 5.3), these implementations may suffer from
arithmetic overflows and rounding errors.
5.5 Fuzzing and Dynamic Symbolic Execution
Inthissection,wecompareourtechniquetopuregray-boxfuzzing
and DSE. In particular, we use LibFuzzer [ 6] and KLEE [ 13], a
state-of-the-art DSE engine, to generate inputs for the test oracles
corresponding to the properties from Fig. 3. For a fair comparison,
wewrite alternativetestdrivers thatdonotcreateandpopulatea
pool of abstract elements. Instead, we allow the tools to directly
generate the coefficientsand constants of up to 50constraints perelement. The test oracles are the same as in our test drivers.
Gray-boxfuzzing.
WeranLibFuzzer(withdefaultoptions)onthe
threeAPRONMPQversionswithseededbugs,usingthesametime
limitsasinTab. 2,andcomparedtheresultstoourC2configuration.
LibFuzzer detected 45 out of the 58 property violations that our
approachfound.Itrevealedtheseviolationsgenerallyfasterthan
our approach for Intervals and Polyhedra, but slower for Octagons.
A manual inspection of the generated counterexamples shows that
our technique produces significantly simpler and more readable
testinputs,whichwasveryusefulindebuggingthedetectedissues.
Tab.8providesadditionaldetailsforthebugsseededbyExpert3.
Thelast two columnsshow thetime ittakesto detecta property
violationforourtechnique(withC2)andforLibFuzzer,respectively.
LibFuzzermissedoneoftheOctagonbugs.Moreover,LibFuzzer’s
results for Polyhedra suggest that the implementation of join is
775
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. Automatically Testing Implementations of Numerical Abstract Domains ASE ’18, September 3–7, 2018, Montpellier, France
Table 7: Impact of different configurations on the effec-
tiveness of our technique. The last six columns show the
time needed to find a violation for each configuration from
Tab.6. We grouped the violations by the seeded bugs they
reveal(dashedlines)andbytheexpertwhoseededthebugs
(solidlines).WeexcludedtwoseededbugsinPolyhedrathat
caused assertions failures in APRON for all configurations,and thereby masked the other bugs seeded by Expert 2.
Domain Violated Execution time (s)
property C1 C2 C3 C4 C5 C6
Intervals 15 ND 0.3 1.36 0.1 1.48 0.38
Intervals 17 ND 0.05 1.78 0.05 0.05 0.05
Intervals 18 ND 0.51 1.82 0.53 0.6 0.53
Intervals 19 ND 0.44 1.89 0.65 0.6 0.52Intervals 23 ND 2.6 1.34 0.93 3.06 0.99Intervals 24 ND 1.94 ND ND 17.29 2.49Intervals 25 ND 0.33 1.34 0.1 1.71 0.4
Intervals 30 ND 0.36 1.25 0.13 0.58 0.52
Octagons 6 0.04 0.05 0.49 0.1 0.06 0.06Octagons 9 0.34 4.73 ND 0.18 30.7 3.97Octagons 10 0.95 3.05 ND 0.13 2.81 5.12
Octagons 11 6.25 8.35 ND 0.5 294.26 2.59
Octagons 13 0.45 3.23 ND 0.22 108.69 7.67
Intervals 30 ND 0.72 1.24 0.27 2.1 0.45
Octagons 15 0.5 crash 109.56 crash crash 3.5Octagons 16 0.06 0.12 2.47 0.06 0.13 0.05Octagons 17 0.72 2.72 ND ND crash crashOctagons 18 crash crash 23.2 crash crash crashOctagons 19 crash crash ND crash crash crashOctagons 20 0.8 crash 771.25 crash crash crash
Octagons 21 crash 1.09 7.49 crash 1.41 0.9
Octagons 22 0.72 crash ND crash crash crashOctagons 23 0.73 crash 27.81 crash crash 3.65Octagons 24 crash crash ND crash crash crashOctagons 25 0.56 0.87 4.39 crash crash 1.03Octagons 28 crash crash ND crash crash crashOctagons 42 0.93 5.17 112.34 crash crash 1.5
Octagons 38 0.05 0.07 2.04 0.05 0.07 0.14
Polyhedra 6 0.05 0.12 63.4 0.11 0.23 0.18Polyhedra 9 1.22 30.03 ND 0.21 44.47 312.41Polyhedra 10 0.65 2.05 ND 0.35 295.41 42.94Polyhedra 11 54.56 419.51 ND 3.06 >4h 1487.56Polyhedra 13 1.18 106.69 ND 0.44 483.82 86.3
Polyhedra 34 5.46 45.58 ND 0.62 33.76 85.97Polyhedra 36 0.07 0.14 60.4 0.12 0.22 0.17Polyhedra 37 0.48 13.0 ND 0.16 4.87 217.27Polyhedra 38 0.46 41.75 ND 0.73 5.42 449.95
Intervals 5 ND 2.09 15.32 9.34 2.39 787Intervals 13 ND 0.86 3.51 0.47 4.94 1.0Intervals 23 ND 0.62 2.19 0.51 1.49 1.17Intervals 28 ND 269 3.59 0.12 1.0 2.02Intervals 34 ND 12.54 70.86 1.23 11.34 12.21Intervals 39 ND 4.37 25.21 1.9 5.99 24.99
Octagons 9 0.67 0.83 3.53 0.11 0.27 0.4Octagons 10 0.45 0.23 2.48 0.11 0.88 0.87Octagons 13 0.65 0.55 24.58 0.32 28.67 23.94
Octagons 17 4.32 23.61 ND ND 117.56 16.37Octagons 22 9.78 24.22 ND ND 17.3 11.25Octagons 23 4.26 9.3 ND ND 15.08 11.05Octagons 25 3.78 11.09 ND ND 81.92 9.17
Polyhedra 7 0.07 inc inc 2.02 inc inc
Polyhedra 8 0.07 0.18 64.47 0.16 0.13 inc
Polyhedra 9 0.09 0.23 66.55 0.17 0.13 incPolyhedra 11 inc inc inc 1.0 inc incPolyhedra 12 0.08 0.19 65.96 0.29 0.18 0.2Polyhedra 13 0.08 0.18 64.67 0.19 0.22 0.2Polyhedra 25 0.08 0.2 61.76 0.19 0.14 0.19Polyhedra 27 2.99 0.21 65.71 0.26 0.15 inc
#Violations found 43 58 37 52 58 58
#Bugs found 8 12 11 11 12 12
crash: crash due to the seeded bugs, ND: the violation was not detected
inc: inconsistent representations (assertion failure in APRON’s code)Table 8: Comparison of our technique with fuzzing for the
bugs seeded by Expert 3. We grouped the violations by the
seeded bugs they reveal (dashed lines).
Domain Violated Execution time (s)
property Our work Fuzzing
Intervals 5 2.09 0.39
Intervals 13 0.86 0.69
Intervals 23 0.62 0.49
Intervals 28 0.27 0.71
Intervals 34 12.54 0.39
Intervals 39 4.37 31.07
Octagons 9 0.83 7.49
Octagons 10 0.23 8.01
Octagons 13 0.55 15.16
Octagons 17 23.61 ND
Octagons 22 24.22 ND
Octagons 23 9.3 NDOctagons 24 11.09 ND
Polyhedra 7 inc ND
Polyhedra 8 0.18 NDPolyhedra 9 0.23 NDPolyhedra 11 inc NDPolyhedra 12 0.19 0.07Polyhedra 13 0.18 NDPolyhedra 25 0.2 ND
Polyhedra 27 0.21 ND
ND: the violation was not detected, inc: inconsistent
representations (assertion failure in APRON’s code)
imprecisesinceonlyproperty12isviolated.Incontrast,ourtech-
nique revealed that the expert seeded a more serious soundness
bug (properties 7, 8, and 9 are also violated).
Dynamic symbolic execution. Since KLEE does not try to ex-
ploreallexecutionpathsinexternallibrariesandAPRONmakes
heavyuseoflibraries,weperformedthecomparisononthe EOD
andEOELINAdomains,usingKLEE’sdefaultoptions.Ouralter-
nativetestdriversuseELINA’sfunctionsdirectly,notitsAPRON
interface, to avoid external library calls. With the latest version
of KLEE (1.4.0), all but 1 test throw an error for both tested do-
mains, because KLEE is not able to model malloc instructions with
symbolic sizes [5].
To overcome this limitation, weextended KLEE with an option
for specifying the upper bound for the symbolic size; we used 8192
inourexperiments.Foreachtesteddomain,ourtechniquedetected
3violatedproperties(see Tab. 5),butKLEEwasnot abletodetect
any, even with a time limit of 17’700s (the 25-fold of the time limit
usedforourtechnique).WebelievethisisduetothefactthatELINA
heavilyreliesonfloating-pointarithmetic,whichKLEEdoesnot
handle very well.
5.6 Threats to Validity
We identified two threats to the validity of our experiments.
Test generation tool. Our comparisons to alternative approaches
focus on one fuzzer and one DSE tool. Since we chose mature,
state-of-the-art tools, we believe that our results are representative.
Similarly,we did notuse alternativegray-box fuzzers whenevalu-
ating our own approach. Since most fuzzers make no assumptions
about the code under test, we do not expect to see significantly
different results for other fuzzers.
776
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France A. Bugariu, V. Wüstholz, M. Christakis, and P. Müller
Randominitialization. Ourpoolinitializationstepchoosessome
of the coefficients and constants randomly. To ensure that our
resultsaredeterministic,alltestdriversusethesame,pre-defined
random seed.
6 RELATED WORK
Our approach is the first to systematically test a wide range of
soundness, precision,and convergence properties oncomplex ab-
stract domains. It combines several existing test case generation
techniques in a novel way. On the one hand, we derive executable
test oracles [ 9] to check high-level, mathematical properties of
abstract-domain implementations. On the other hand, we incorpo-
rate ideas from boundary and random testing (step 1 of the pool
population)andfromfeedback-directedrandomtesting[ 42](step2)
toobtaininputsforthetestoracles.Akeydifferencewiththelatter
isthat,inourcase,thefuzzercontrolswhichelementsareadded
to the pool, by providing the operations and their arguments.
Testing static analyzers with random programs. One way to
teststaticanalyzersisbyrandomlygeneratinginputprograms[ 24].
This approach is particularly effective in testing the robustness of
analyzers, that is, for detecting which input programs make the
analyzerscrash.Toalsotestsoundnessproperties,Cuoqetal.in-
strument the code of the analyzer under test with assertions about
inferredvaluesorrelationsbetweenprogramvariables.Theseasser-
tionsarethencheckedagainstconcreteexecutions.Incontrast,ourtechniquegeneratesinputdatasystematically,anddoesnotrequire
any modifications to the implementation of the tested analyzers.
Analysistestinganddeltadebugging. Similarly to Cuoq etal.’s
work, Andreasen et al. [ 8] compare concrete executions to abstract
domainelementstodetectsoundnessandprecisionproblems.They
use delta debugging to reduce the size of the input programs in
order to report the errors concisely. In contrast, we propose a tech-
nique for automatically generating the input domain elements; our
approachstartswithsimpleelementsandappliesasmallnumber
of operations, generating small counterexamples by construction.
Systematicallytestinglatticeproperties. MidtgaardandMøller
[40]focusonquickchecking[ 18]basiclatticepropertiesofabstract
interpreters. Ourtechnique wasinspired bytheir work;it extends
thesetoftestedpropertiesand,asourevaluationshows,iseffective
onwidely-usedandhighly-optimizedabstractdomainimplementa-
tions.Acomprehensiveexperimentalcomparisonwiththeirtool
was not possible, as the authors provide constructors and helper
functionsforgeneratingorderedpairsofelementsonlyforInter-
vals, but notfor the complex numerical domains thatwe consider.
Without them, many of the properties cannot be tested, as the ran-
domlygeneratedinputsverylikelydonotsatisfythepreconditions.For this reason, we expect that their technique cannot significantlyoutperform gray-box fuzzing, whichwe showedto be less effective
thanourapproach(seeTab. 8).Wesolvetheproblemofgenerating
ordered inputs by applying domain operations to the existing pool
elements (e.g., the result of a join over-approximates its operands).
Formally verified static analyzers. Interactive theorem provers
suchasCoq[ 2]havebeenusedtoverifythesoundnessofthe de-
signof static analyses (e.g., in the context of type systems [ 25,44]).
However, the proofs do not typically provide any guarantees abouttheactual implementation oftheanalyses,and,thus,couldstillben-
efit from automated testing techniques like ours. The Verasco [ 32]
projectextractsexecutablecodefromverifiedCoqformalizationsof
severalabstractdomains.Thisapproachproducesimplementations
thatarecorrectbyconstruction,butisnotyetpracticalforcomplex,
highly-optimized implementations. Recent work by Madsen and
Lhoták [39] uses symbolic evaluation (based on symbolic execu-
tions and SMT solvers) to verify the correctness, i.e., safety and
soundness,ofabstract-domainimplementations.Iftheproblemis
undecidable,itreliesonaquickcheckingapproachinspiredby[ 40].
Their evaluation does not consider complex numerical domains.
Unsoundness in static analyzers. Even for analyzers that are
unsoundbydesign[ 10,15–17,37],ourtechniqueisusefultodetect
unintentional sources of unsoundness and imprecision (e.g., caused
by implementation errors).
Testing compilers and program analyzers. Abstract domains
are one of many components that are used in modern compilers
and program analyzers. Besides efforts in proving properties about
such components (e.g., CompCert [ 36] and Verasco [ 32]), there is a
significantbodyofworkonusingtestingtechniquestodetectissues
in compilers [34, 35,48,51], and recently, in DSE engines [33].
7 CONCLUSION
Wehavepresentedanautomatedtestingtechniquefordetecting
soundness,precision,andconvergenceerrorsinabstract-domain
implementations, which are crucial components of many staticanalyzers. We have evaluated our approach on several complex,real-world abstract domains from two widely-used libraries fornumerical analysis and demonstrated its effectiveness in finding
both seeded and previously unknown errors.
Eventhoughourevaluationfocusesonnumericalabstractdo-
mains, we believe that the high-level ideas of our technique also
applytootherdomainssuchasstringorheapdomains.Suchdo-
mainsrequiredifferenttechniquestoconstructdomainelementsas
wellassuitableparametersforassignmentsandconditionals.More-
over,oneneedstoassesswhetherfuzzerscaneffectivelyexplore
the search space of non-numerical domain implementations. We
leave these generalizations as future work.
There are several lessons to be learned from this work. First, an
automatedtestingtechniqueoffersapragmaticandeffectivesolu-
tionforuncoveringissuesinstaticanalyzersthatwouldbedifficult
to find using manual testing. Second, off-the-shelf testing tools are
lesseffectiveforcomplex,highly-optimizeddomainimplementa-
tionsthanawell-designedcombinationoftechniques.Webelieve
that these observations carry over to other application areas, such
as machine-learning frameworks; exploring those is future work.
ACKNOWLEDGMENTS
WewouldliketothankthedevelopersofAPRON,KhalilGhorbal
and Antoine Miné, and of ELINA, Gagandeep Singh, for their help
and support. We are also grateful to Jérôme Dohrau, Gagandeep
Singh,andCaterinaUrbanforseedingbugsforourevaluation,and
to our anonymous reviewers for their helpful comments. MariaChristakis’s work was supported in part by a Facebook Faculty
Research Award.
777
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. Automatically Testing Implementations of Numerical Abstract Domains ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1][n. d.]. The APRON Library Documentation. http://apron.cri.ensmp.fr/library/0.
9.10/apron.pdf .
[2] [n. d.]. The Coq Proof Assistant. https://coq.inria.fr.
[3] [n. d.]. ELINA Artifact (POPL 2017). https://www.sri.inf.ethz.ch/optpoly.php.
[4][n.d.]. ELINAArtifact(POPL2018). https://www.sri.inf.ethz.ch/popl18-paper251.
php.
[5] [n. d.]. KLEE Tutorial. http://klee.github.io/tutorials/testing-regex/.
[6][n. d.]. LibFuzzer—A Library for Coverage-Guided Fuzz Testing. https://llvm.
org/docs/LibFuzzer.html.
[7][n. d.]. Technical “Whitepaper” for AFL. http://lcamtuf.coredump.cx/afl/
technical_details.txt.
[8]EsbenSparreAndreasen,AndersMøller,andBenjaminBarslevNielsen.2017. Sys-
tematic Approaches for Increasing Soundness and Precision of Static Analyzers.
InSOAP. ACM, 31–36.
[9]EarlT.Barr,MarkHarman,PhilMcMinn,MuzammilShahbaz,andShinYoo.2015.
The Oracle Problem in Software Testing: A Survey. TSE41, 5 (2015), 507–525.
[10]Dirk Beyer, Thomas A. Henzinger, M. Erkan Keremoglu, and Philipp Wendler.
2012. ConditionalModelChecking:ATechniquetoPassInformationbetween
Verifiers. In FSE. ACM, 57–67.
[11]DirkBeyerandM.ErkanKeremoglu.2011. CPAchecker:AToolforConfigurable
Software Verification. In CAV (LNCS), Vol. 6806. Springer, 184–190.
[12]Bruno Blanchet, Patrick Cousot, Radhia Cousot, Jérome Feret, Laurent
Mauborgne, Antoine Miné, David Monniaux, and Xavier Rival. 2003. A Static
Analyzer for Large Safety-critical Software. In PLDI. ACM, 196–207.
[13]CristianCadar,DanielDunbar,andDawsonR.Engler.2008.KLEE:Unassistedand
Automatic Generation of High-Coverage Tests for Complex Systems Programs.
InOSDI. USENIX, 209–224.
[14]Cristian Cadar and Dawson R. Engler. 2005. Execution Generated Test Cases:
How to Make Systems Code Crash Itself. In SPIN (LNCS), Vol. 3639. Springer,
2–23.
[15]Maria Christakis, Peter Müller, and Valentin Wüstholz. 2012. Collaborative
Verification and Testing with Explicit Assumptions. In FM (LNCS), Vol. 7436.
Springer, 132–146.
[16]MariaChristakis,PeterMüller,andValentinWüstholz.2015. AnExperimental
EvaluationofDeliberateUnsoundnessinaStaticProgramAnalyzer.In VMCAI
(LNCS), Vol. 8931. Springer, 336–354.
[17]Maria Christakis and Valentin Wüstholz. 2016. Bounded Abstract Interpretation.
InSAS (LNCS), Vol. 9837. Springer, 105–125.
[18]Koen Claessen and John Hughes. 2000. QuickCheck: A Lightweight Tool for
Random Testing of Haskell Programs. In ICFP. ACM, 268–279.
[19]Patrick Cousot and Radhia Cousot. 1976. Static Determination of Dynamic
Properties of Programs. In ISOP. Dunod, 106–130.
[20]Patrick Cousot and Radhia Cousot. 1977. Abstract Interpretation: A Unified
LatticeModelforStaticAnalysisofProgramsbyConstructionorApproximation
of Fixpoints. In POPL. ACM, 238–252.
[21]PatrickCousotandRadhiaCousot.1979. SystematicDesignofProgramAnalysis
Frameworks. In POPL. ACM, 269–282.
[22]Patrick Cousot and Radhia Cousot. 1992. Comparing the Galois Connection and
Widening/NarrowingApproachestoAbstractInterpretation.In PLILP (LNCS),
Vol. 631. Springer, 269–295.
[23]Patrick Cousot and Nicolas Halbwachs. 1978. Automatic Discovery of Linear
Restraints Among Variables of a Program. In POPL. ACM, 84–96.
[24]PascalCuoq,BenjaminMonate,AnnePacalet,VirgilePrevosto,JohnRegehr,Boris
Yakobowski,andXuejunYang.2012. TestingStaticAnalyzerswithRandomly
Generated Programs. In NFM (LNCS), Vol. 7226. Springer, 120–125.
[25]CatherineDubois.2000. ProvingMLTypeSoundnessWithinCoq.In TPHOLs
(LNCS), Vol. 1869. Springer, 126–144.
[26]Manuel Fähndrich and Francesco Logozzo. 2010. Static Contract Checking with
Abstract Interpretation. In FoVeOOS (LNCS), Vol. 6528. Springer, 10–30.[27]KhalilGhorbal,EricGoubault,andSylviePutot.2009. TheZonotopeAbstract
Domain Taylor1+. In CAV (LNCS) , Vol. 5643. Springer, 627–633.
[28]Patrice Godefroid, Nils Klarlund, and Koushik Sen. 2005. DART: Directed Auto-
mated Random Testing. In PLDI. ACM, 213–223.
[29]EricGoubaultandSylviePutot.2006. StaticAnalysisofNumericalAlgorithms.
InSAS (LNCS), Vol. 4134. Springer, 18–34.
[30]JulienHenry,DavidMonniaux,andMatthieuMoy.2012. PAGAI:APathSensitive
Static Analyser. Electr. Notes Theor. Comput. Sci. 289 (2012), 15–25.
[31]Bertrand Jeannet and Antoine Miné. 2009. Apron: A Library of Numerical
AbstractDomainsforStaticAnalysis.In CAV (LNCS),Vol.5643.Springer,661–
667.
[32]Jacques-HenriJourdan,VincentLaporte,SandrineBlazy,XavierLeroy,andDavid
Pichardie. 2015. A Formally-Verified C Static Analyzer. In POPL. ACM, 247–259.
[33]TimotejKapusandCristianCadar.2017. Automatictestingofsymbolicexecution
engines via program generation and differential testing. In ASE. IEEE Computer
Society, 590–600.
[34]Vu Le, Mehrdad Afshari, and Zhendong Su. 2014. Compiler validation via equiv-
alence modulo inputs. In PLDI. ACM, 216–226.
[35]Vu Le, Chengnian Sun, and Zhendong Su. 2015. Finding deep compiler bugs via
guided stochastic program mutation. In OOPSLA. ACM, 386–399.
[36]XavierLeroy.2009. Formalverificationofarealisticcompiler. CACM52,7(2009),
107–115.
[37]BenjaminLivshits,ManuSridharan,YannisSmaragdakis,OndřejLhoták,J.Nelson
Amaral,Bor-YuhEvanChang,SamuelZ.Guyer,UdayP.Khedker,AndersMøller,
and Dimitrios Vardoulakis. 2015. In Defense of Soundiness: A Manifesto. CACM
58 (2015), 44–46. Issue 2.
[38]Francesco Logozzo and Manuel Fähndrich. 2010. Pentagons: A weakly relational
abstractdomainfortheefficientvalidationofarrayaccesses. Sci.Comput.Program.
75, 9 (2010), 796–807.
[39]Magnus Madsen and Ondrej Lhoták. 2018. Safe and Sound Program Analysis
with FLIX. In ISSTA. ACM. To appear.
[40]JanMidtgaardandAndersMøller.2017.QuickCheckingStaticAnalysisProperties.
Softw. Test. Verif. Reliab. 27, 6 (2017).
[41]Antoine Miné. 2006. The Octagon Abstract Domain. Higher Order Symbol.
Comput.19, 1 (2006), 31–100.
[42]Carlos Pacheco, Shuvendu K. Lahiri, Michael D. Ernst, and Thomas Ball. 2007.Feedback-Directed Random Test Generation. In ICSE. IEEE Computer Society,
75–84.
[43]ThomasW.Reps,ShmuelSagiv,andGretaYorsh.2004. SymbolicImplementation
of the Best Transformer. In VMCAI (LNCS), Vol. 2937. Springer, 252–266.
[44]Zhong Shao, Bratin Saha, Valery Trifonov, and Nikolaos Papaspyrou. 2002. A
type system for certified binaries. In POPL. ACM, 217–232.
[45]Gagandeep Singh, Markus Püschel, and Martin Vechev. 2015. Making Numerical
Program Analysis Fast. In PLDI. ACM, 303–313.
[46]Gagandeep Singh, Markus Püschel, and Martin Vechev. 2017. Fast Polyhedra
Abstract Domain. In POPL. ACM, 46–59.
[47]GagandeepSingh,MarkusPüschel,andMartinVechev.2018. APracticalCon-
struction for Decomposing Numerical Abstract Domains. PACMPL 2, POPL
(2018), 55:1–55:28.
[48]Chengnian Sun, Vu Le, and Zhendong Su. 2016. Finding and analyzing compiler
warning defects. In ICSE. ACM, 203–213.
[49]H. Le Verge. 1992. A note on Chernikova’s Algorithm. Technical Report RR-1662.
INRIA.
[50]Shiyi Wei, Piotr Mardziel, Andrew Ruef, Jeffrey S. Foster, and Michael Hicks.
2018. Evaluating Design Tradeoffs in Numeric Static Analysis for Java. In ESOP
(LNCS), Vol. 10801. Springer, 653–682.
[51]XuejunYang,YangChen,EricEide,andJohnRegehr.2011. Findingandunder-
standing bugs in C compilers. In PLDI. ACM, 283–294.
778
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:49:42 UTC from IEEE Xplore.  Restrictions apply. 