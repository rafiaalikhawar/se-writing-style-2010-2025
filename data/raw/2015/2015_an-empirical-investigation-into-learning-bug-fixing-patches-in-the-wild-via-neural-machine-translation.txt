An Empirical Investigation into Learning Bug-Fixing Patches
in the Wild via Neural Machine Translation
Michele Tufano
College of William and Mary
Williamsburg, VA, USACody Watson
College of William and Mary
Williamsburg, VA, USAGabriele Bavota
Università della Svizzera italiana (USI)
Lugano, Switzerland
Massimiliano Di Penta
University of Sannio
Benevento, ItalyMartin White
College of William and Mary
Williamsburg, VA, USADenys Poshyvanyk
College of William and Mary
Williamsburg, VA, USA
ABSTRACT
Millionsofopen-sourceprojectswithnumerousbugfixesareavail-
ableincoderepositories.Thisproliferationofsoftwaredevelopment
histories can be leveraged to learn how to fix common program-
mingbugs.Toexploresuchapotential,weperformanempirical
study to assess the feasibility of using Neural Machine Translation
techniquesforlearningbug-fixingpatchesforrealdefects.Wemine
millionsofbug-fixesfromthechangehistoriesofGitHubreposi-
tories to extract meaningful examples of such bug-fixes. Then, we
abstract the buggy and corresponding fixed code, and use them to
train an Encoder-Decoder model able to translate buggy code into
itsfixedversion.Ourmodelisabletofixhundredsofuniquebuggy
methods in the wild. Overall, this model is capable of predicting
fixed patches generated by developers in 9% of the cases.
CCS CONCEPTS
•Software and its engineering →Software maintenance tools ;
KEYWORDS
neural machine translation, bug-fixes
ACM Reference Format:
Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta,
MartinWhite,andDenysPoshyvanyk.2018.AnEmpiricalInvestigationinto
LearningBug-FixingPatchesintheWildviaNeuralMachineTranslation.InProceedingsofthe201833rdACM/IEEEInternationalConferenceonAutomated
Software Engineering (ASE ’18), September 3–7, 2018, Montpellier, France.
ACM,NewYork,NY,USA, 6pages.https://doi.org/10.1145/3238147.3240732
1 INTRODUCTION
Localizingandfixingbugsisknowntobeaneffort-proneandtime-
consuming task for software developers [ 15,30,38]. To support
programmers in this activity, researchers have proposed a number
of approaches aimed at automatically repairing programs. The
proposedtechniqueseitheruseagenerate-and-validateapproach,
whichconsistsofgeneratingmanyrepairs(e.g., throughGenetic
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3240732Programming like GenProg [ 23,37]), or an approach that produces
asinglefix[ 14,27].Whileautomatedprogramrepairtechniques
stillfacemanychallengestobeappliedinpractice,existingwork
has made strides to be effective in specific cases. These approaches,
given the right circumstances, substantially contribute in reducing
the cost of bug-fixes for developers [21, 26].
Two major problems automated repair approaches have are pro-
ducing patches acceptable for programmers and, especially for
generate-and-validate techniques, over-fitting patches to test cases.
Tocopewiththisproblem,Le etal.[20]leveragethepasthistory
ofexistingprojects—intermsofbug-fixpatches—andcompare
automatically-generatedpatcheswithexistingones.Patchesthat
are similar to the ones found in the past history of mined projects
are considered to be more relevant. Another approach that iden-
tifies patches from past fixes is Prophet [ 24], which after having
localized the likely faulty code by running test cases, generates
patches from correct code using a probabilistic model.
Our work is motivated by the following three considerations.
First,automatedrepairapproachesarebasedonarelativelylimited
andmanually-crafted(withsubstantialeffortandexpertise)setof
transformations or fixing patterns. Second, the work done by Leet al.[
20] shows that the past history of existing projects can be
successfullyleveragedtounderstandwhata“meaningful"program
repairpatchis.Third,severalworkshaverecentlydemonstratedthe
capability of advanced machine learning techniques, such as deep
learning, to learn from large software engineering (SE) datasets.
Someexamplesofrecentmodelsthatcanbeusedinanumberof
SE tasks include: code completion [ 29], defect prediction [ 36], bug
localization [ 19], clone detection [ 39], code search [ 11], learning
API sequences [12], or recommending method names [2].
Forges like GitHub provide a plethora of change history and
bug-fixing commits from a large number of software projects. A
machine-learningbasedapproachcanleveragethisdatatolearn
aboutbug-fixingactivitiesinthewild.Inthiswork,weevaluatethesuitability ofa Neural-Machine Translation(NMT)-based approach
for the task of automatically generating patches for buggy code.
Automatically learning from bug-fixes in the wild provides the
ability to emulate real patches written by developers. Additionally,
we harness the power of NMT to “translate” buggy code into fixed
code thereby emulating the combination of AST operations per-
formedinthedeveloperwrittenpatches.Furtherbenefitsinclude
thestaticnatureofNMTwhenidentifyingcandidatepatches,since,
unlikesome generate-and-validateapproaches, wedonot needtoexecute test cases during patch generation [31, 40].
832
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:09 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France M. Tufano, C. Watson, G. Bavota, M. Di Penta, M. White, D. Poshyvanyk
Westart by mining a large set of( ∼787k) bug-fixing commits
fromGitHub.Fromthesecommits,weextractmethod-levelAST
edit operations using fine-grained source code differencing [ 7]. We
identifymultiplemethod-leveldifferencesperbug-fixingcommit
andindependentlyconsidereachone,yieldingto ∼2.3Mbug-fix
pairs (BFPs). After that, the code of the BFPs is abstracted to make
it more suitable for the NMT model. Finally, an encoder-decoder
modelisusedtounderstandhowthebuggycodeistransformedinto
fixed code. Once the model has been trained, it is used to generate
patches for unseen code.
We empirically investigate the potential of NMT to generate
candidate patches that are identical to the ones implemented by
developers. The results indicate that trained NMT model is able to
successfullypredict thefixedcode,given thebuggycode,in 9%of
the cases.
2 APPROACH
Fig.1showsanoverviewoftheNMTapproachthatweexperiment
with. The black boxes represent the main phases, the arrows in-
dicatedataflows,andthedashedarrowsdenotedependencieson
externaltoolsordata.Weminebug-fixingcommitsfromthousands
of GitHub repos using GitHub Archive [ 10] (Sec.2.1). From the
bug-fixes, weextract method-levelpairs of buggyand correspond-
ingfixedcode named bug-fix pairs (BFPs) (Sec. 2.2.1). BFPs are the
examplesthatweusetolearnhowtofixcodefrombug-fixes(buggy
→fixed).WeuseGumTree[ 7]toidentifythelistofeditactions
(A) performed between the buggy and fixed code. Then, we use
a Java Lexer and Parser to abstract the source code of the BFPs
(Sec.2.2.2) into a representation better suited for learning. During
the abstraction, we keep frequent identifiers and literals we call
idiomswithinthe representation.Theoutput ofthisphase arethe
abstractedBFPsandtheircorrespondingmapping M,whichallows
reconstructing the original source code. Next, we filter out long
methods(Sec. 2.2.3)andweusetheobtainedsettotrainanencoder-
decoder model able to learn how to transform a buggycode into
a corresponding fixedversion (Sec. 2.3). The trained model can be
used to generate a patch for unseen buggy code.
2.1 Bug-Fixes Mining
We downloaded from GitHub Archive [ 10] every public GitHub
event between March 2011 and October 2017 and we used the
Google BigQuery APIs to identify all commits having a message
containingthepatterns[ 8]:(“fix”or“solve”)and(“bug”or“issue”or
“problem”or“error”).Weidentified ∼10M(10,056,052)bug-fixing
commits. As the content of commit messages and issue trackersmight imprecisely identify bug-fixing commits, two authors in-dependently analyzed a statistically significant sample (95% con-
fidence level
±5% confidence interval, for a total size of 384) of
identified commits to check whether they were actually bug fixes.
Aftersolving13casesofdisagreement,theyconcludedthat97.6%of
the identified bug-fixing commits were true positive. Details about
this evaluation are in our online appendix [34].
Foreachbug-fixingcommit,weextractedthesourcecodebefore
and after the bug-fix using the GitHub Compare API [ 9]. This
allowedustocollectthebuggy(pre-commit)andthefixed(post-
commit)code.Wediscardedcommitsrelatedtonon-Javafiles,aswellasfilesthatwerecreatedinthebug-fixingcommit,sincethere
would be no buggy version to learn from. Moreover, we discarded
commits impacting more than five Java files, since we aim to learn
focused bug-fixes that are not spread across the system. The result
of this process was the buggy and fixed code of 787,178 bug-fixing
commits.
2.2 Bug-Fix Pairs Analysis
A BFP (Bug-Fixing Pair) is a pair (mb,mf)wherembrepresents
a buggy code component and mfrepresents the corresponding
fixedcode.WewillusetheseBFPstotraintheNMTmodel,makeit
learningthetranslationfrombuggy( mb)tofixed( mf)code,thus
being able of generating patches.
2.2.1 Extraction. Given(fb,ff)apairofbuggyandfixedfilefrom
a bug-fix bf, we used the GumTree Spoon AST Diff [ 7]t o o lt o
computetheASTdifferencingbetween fbandff.Thiscomputes
the sequence ofedit actions performed at theAST levelthat allows
to transform the fb’s AST into the ff’s AST.
Since the file-level granularity could be too large to learn pat-
terns of transformation, we separate the code into method-level
fragments that will constitute our BFPs. The rationale for choosing
method-level BFPs is supported by several reasons. First, methods
represent a reasonable target for fixing activities, since they are
likely to implement a single task or functionality. Second, meth-
ods provide enough meaningful context for learning fixes, such as
variables,parameters,andmethodcallsusedinthemethod.This
choice is justified by recent empirical studies, which indicated how
the large majority of fixing patches consist of single line, single
churnor,worstcases,churnsseparatedbyasingleline[ 32].Smaller
snippets of code lack the necessary context and, hence, they could
not be considered. Finally, considering arbitrarily long snippets of
code, such as hunks in diffs, makes learning more difficult given
the variability in size and context [1, 18].
We first rely on GumTree to establish the mapping between the
nodes of fbandff. Then, we extract the list of mapped pairs of
methods L={(m1b,m1f),...,(mnb,mnf)}. Each pair (mib,mif)
contains the method mib(from the buggy file fb) and the corre-
spondingmethod mif(fromthefixedfile ff).Next,foreachpair
ofmappedmethods,weextractasequenceofeditactionsusingthe
GumTree algorithm. We then consider only those method pairs for
whichthereisatleastoneeditaction(i.e., wedisregardmethods
thathavenotbeenmodifiedduringthefix).Therefore,theoutputof
this phase is a list of BFPs ={bfp1,...,bfp k}, where each BFP is
a tripletbfp={mb,mf,A}, wherembis the buggy method, mfis
thecorrespondingfixedmethod,and Aisasequenceofeditactions
that transforms mbinmf. We exclude methods created/deleted
during the fixing, since we cannot learn fixing operations from
them. Overall, we extracted ∼2.3M BFPs.
ItshouldbenotedthattheprocessweusetoextracttheBFPs:
(i) does not capture changes performed outside methods (e.g., class
signature, attributes, etc.), and (ii) considers each BFP as an inde-
pendent bug fix, meaning that multiple methods modified in thesame bug fixing activity are considered independently from one
another.
833
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:09 UTC from IEEE Xplore.  Restrictions apply. An Empirical Investigation into Learning Bug-Fixing Patches in the Wild via NMT ASE ’18, September 3–7, 2018, Montpellier, France
Recurrent Neural Network (RNN) Encoder-Decoder
h1 h2 hn
RNN Cell 
(GRU)
x1 x2 <end> <start> y 1 ymci
s1 s2 sm
RNN Cell 
(GRU)[ci, si]Softmax
abstractfabstractbEncoder RNN Attention Decoder RNN
..
....
......
787k 
bug-ﬁxesbug-ﬁxes
mining
GitHubArchive
buggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){
      populateList(l);
   }   return l;
}
public MyList checkList(MyList l){   if(l.size() < 1){
      populateList(l);   }
   return l;
}buggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){      populateList(l);
   }
   return l;
}
public MyList checkList(MyList l){
   if(l.size() < 1){
      populateList(l);
   }
   return l;
}buggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){
      populateList(l);
   }
   return l;}
public MyList checkList(MyList l){   if(l.size() < 1){
      populateList(l);
   }   return l;
}GumTree~
buggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){
      populateList(l);
   }
   return l;
}
public MyList checkList(MyList l){
   if(l.size() < 1){
      populateList(l);
   }
   return l;
}
edit actions (A)
Delete Literal at If
Insert Literal at Ifbuggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){
      populateList(l);
   }
   return l;
}
public MyList checkList(MyList l){
   if(l.size() < 1){
      populateList(l);
   }
   return l;
}
edit actions (A)
Delete Literal at If
Insert Literal at Ifbuggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){
      populateList(l);
   }
   return l;
}
public MyList checkList(MyList l){
   if(l.size() < 1){
      populateList(l);
   }
   return l;
}
edit actions (A)
Update Literal at If
2.3M 
bug-ﬁx pairsabstraction
ANTLR
(lexer) #
buggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){
      populateList(l);
   }
   return l;
}
public MyList checkList(MyList l){
   if(l.size() < 1){
      populateList(l);
   }
   return l;
}
edit actions (A)
Delete Literal at If
Insert Literal at If
VAR_2 -> tmp
METHOD_1 -> isValid()mapping (M)buggy code
ﬁxed codepublic MyList checkList(MyList l){
   if(l.size() < 0){
      populateList(l);
   }
   return l;
}
public MyList checkList(MyList l){
   if(l.size() < 1){
      populateList(l);
   }
   return l;
}
edit actions (A)
Delete Literal at If
Insert Literal at If
VAR_2 -> tmp
METHOD_1 -> isValid()mapping (M)abstract buggy code
abstract ﬁxed codepublic TYPE_1 METHOD_1 ( TYPE_1 VAR_1 ) { if 
( VAR_1 . size ( )  < 0 ) { METHOD_2 ( VAR_1 ) ; } return VAR_1 ; }
public TYPE_1 METHOD_1 ( TYPE_1 VAR_1 ) { if 
( VAR_1 . size ( )  < 1 ) { METHOD_2 ( VAR_1 ) ; } return VAR_1 ; }
edit actions (A)
Update Literal at If
VAR_1 -> l
METHOD_1 -> checkListmapping (M)
2.3M abstract 
bug-ﬁx pairsJavaParser
(parser) <>Recurrent Neural Network (RNN) Encoder-Decoder
h1 h2 hn
RNN Cell 
(GRU)
x1 x2 <end> <start> y 1 ymci
s1 s2 sm
RNN Cell 
(GRU)[ci, si]Softmax
abstractb (buggy) abstractf (ﬁxed)Encoder RNN Attention Decoder RNN
..
....
......1 23 4 5 6Idioms
ij
0
1
size
…
transformation
pairs analysis
datasets
Small bug-ﬁx pairs7
Figure 1: Overview of the process used to experiment with an NMT-based approach.
2.2.2 Abstraction. Learning bug-fixing patterns is extremely chal-
lengingbyworkingatthelevelofrawsourcecode.Thisisespecially
due to the huge vocabulary of terms used in the identifiers and
literals of the ∼2M mined projects. Such a large vocabulary would
hinder our goal of learning transformations of code as a neural
machine translation task. For this reason, we abstract the code and
generateanexpressiveyetvocabulary-limitedrepresentation.We
use a Java lexer and a parser to represent each buggy and fixed
method within a BFP as a stream of tokens. The lexer, built on top
ofANTLR[ 28],tokenizestherawcodeintoastreamoftokens,that
isthen fedinto aJava parser[ 35],which discernsthe roleof each
identifier (i.e., whether it represents a variable, method, or type
name) and the type of a literal.
Each BFP is abstracted in isolation. Given a BFP bfp =
{mb,mf,A}, we first consider the source code of mb. The source
code is fed to a Java lexer, producing the stream of tokens. The
stream of tokens is then fed to a Java parser, which recognizes
the identifiers and literals in the stream. The parser generates and
substitutes a unique ID for each identifier/literal within the tok-
enizedstream.Ifanidentifierorliteralappearsmultipletimesin
the stream, it will be replaced with the same ID. The mapping of
identifiers/literalswiththeircorrespondingIDsissavedinamap
(M). The final output of the Java parser is the abstracted method
(abstract b). Then, we consider the source code of mf. The Java
lexerproducesastreamoftokens,whichisthenfedtotheparser.
The parser continues to use a map Mwhen abstracting mf. The
parser generates new IDs only for novel identifiers/literals, notalreadycontainedin
M,meaning,theyexistin mfbutnotin mb.
Then, itreplaces allthe identifiers/literalswith thecorresponding
IDs, generating the abstracted method ( abstract f). The abstracted
BFP is now a 4-tuple bfpa ={abstract b,abstract f,A,M}, where
MistheIDmappingforthatparticularBFP.Theprocesscontinues
considering the next BFP, generating a new mapping M. Note that
we first analyze the buggy code mband then the corresponding
fixed code mfof a BFP, since this is the direction of the learning
process.
IDs are assigned to identifiers and literals in a sequential and
positionalfashion:Thefirstmethodnamefoundwillbeassigned
the ID of METHOD_1 , likewise the second method name will receive
the ID of METHOD_2 . This process continues for all the method and
variable names ( VAR_X) as well as the literals ( STRING_X ,INT_X,
FLOAT_X).Atthispoint, abstract bandabstract fofaBFPareastreamofto-
kensconsistingoflanguagekeywords(e.g., for,if),separators(e.g.,
“(”, “;”, “}”) and IDs representing identifiers and literals. Comments
and annotations have been removed from the code representation.
Some identifiers and literals appear so often in the code that,
for the purpose of our abstraction, they can almost be treated as
keywords of the language. This is the case for the variables i,j,o r
index,thatareoftenusedinloops,orforliteralssuchas 0,1,-1,
oftenusedinconditionalstatementsandreturnvalues.Similarly,
method names, such as sizeoradd, appear several times in our
codebase,sincetheyrepresentcommonconcepts.Theseidentifiersand literals are often referred to as “idioms” [
5]. We include idioms
inourrepresentationanddonotreplaceidiomswithagenerated
ID, but rather keep the original text when abstracting the code.
Todefinethelistofidioms,wefirstrandomlysampled300kBFPs
andconsideredalltheiroriginalsourcecode.Then,weextracted
the frequency of each identifier/literal used in the code, discarding
keywords, separators, and comments. Next, we analyzed the distri-
butionofthefrequenciesandfocusedonthetop0 .005%frequent
words(outliersofthedistribution).Twoauthorsmanuallyanalyzed
thislistandcuratedasetof272idiomsalsoincludingstandardJava
types such as String,Integer, common Exceptions ,etc.The list
of idioms is available in the online appendix [34].
Thisrepresentationprovidesenoughcontextandinformation
toeffectivelylearncodetransformations,whilekeepingalimited
vocabulary ( |V|=∼430). The abstracted code can be mapped back
to the real source code using the mapping ( M).
buggy code ﬁxed code
bug-ﬁx
abstracted buggy code abstracted ﬁxed code
abstracted buggy code with idioms abstracted ﬁxed code with idioms
learningpublic Integer getMinElement(List myList) {
   if(myList.size() >= 0) {
      return ListManager.getFirst(myList);   }   return 0;}public Integer getMinElement(List myList) {
   if(myList.size() >= 1) {      return ListManager.min(myList);   }   return null ;
}
public TYPE_1 METHOD_1 ( TYPE_2 VAR_1 ) 
{ if ( VAR_1 . METHOD_2 ( ) >= INT_1 ) { return TYPE_3 . METHOD_3 ( VAR_1 ) ; }  
return INT_1 ; }
public TYPE_1 METHOD_1 ( List VAR_1 ) 
{ if ( VAR_1 . size ( ) >= 0 ) 
{ return TYPE_2 . METHOD_3 ( VAR_1 ) ; }  
return 0 ; }public TYPE_1 METHOD_1 ( TYPE_2 VAR_1 ) 
{ if ( VAR_1 . METHOD_2 ( ) >= INT_2 ) 
{ return TYPE_3 . METHOD_4 ( VAR_1 ) ; }  
return null ; }
public TYPE_1 METHOD_1 ( List VAR_1 ) 
{ if ( VAR_1 . size ( ) >= 1 ) 
{ return TYPE_2 . min ( VAR_1 ) ; } 
return null ; }
Figure 2: Code Abstraction Example.
To better understand our representation, let us consider the
example in Fig. 2, where we see a bug-fix related to finding the
minimum value in a list of integers. The buggy method contains
threeerrors,which thefixedcoderectifies.The firstbugiswithin
834
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:09 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France M. Tufano, C. Watson, G. Bavota, M. Di Penta, M. White, D. Poshyvanyk
theif-condition,wherethebuggymethodchecksifthelistsizeis
greaterthanorequalto 0.Thisisproblematicsincealistwithout
anyvaluescannothaveaminimumvaluetoreturn.Thesecondbug
is in the method call getFirst , this will return the first element in
thelist,whichmayormaynotbetheminimumvalue.Lastly,ifthe
if-conditionfailsinthebuggymethodthenthemethodreturns 0;
returning 0whentheminimumisunabletobeidentifiedisincorrect
asitindicatesthatoneoftheelementswithinthelistis 0.Thefixed
code changes the if-condition to compare against a list size of 1
ratherthan 0,usesthe minmethodtoreturntheminimumvalue
and changes the return value to nullwhen the if-condition fails.
Usingthebuggyandfixedcodefortraining,althoughaviable
andrealisticbug-fix,presentssomeissues.Whenwefeedthebuggy
piece ofcode tothe Java Parserand Lexer, weidentify someprob-
lems with the mapping. For example, the abstracted fixed code
contains INT_2andMETHOD_4 ,whicharenotcontainedintheab-
stractedversionofthebuggycodeoritsmapping.Sincethemap-
pingoftokenstocodeissolelyreliantonthebuggymethod,this
example would require the synthesis of new values for INT_2and
METHOD_4 .However,themethodologytakesadvantageofidioms,
allowingtostillconsiderthisBFP.Whenusingtheabstractionwith
idioms,weareabletoreplacetokenswiththevaluestheyrepresent.
Now, when looking at the abstracted code with idioms for bothbuggy and fixed code, there are no abstract tokens found in thefixed code that are not in the buggy code. Previously, we needed
to synthesize values for INT_2andMETHOD_4 , however, INT_2was
replaced with idiom 1andMETHOD_4 with idiom min. With the use
of idioms, we are capable of keeping this BFP while maintaining
the integrity of learning real, developer inspired patches.
2.2.3 Filtering. WefilteroutBFPsthat:(i)containlexicalorsyn-
tactic errors (i.e., either the lexer or parser fails to process them) in
either the buggy or fixed code; (ii) their buggy and fixed abstractedcode(
abstract b,abstract f)resultedinequalstrings;(iii)performed
more than100 atomicAST actions( |A|>100) betweenthe buggy
andfixedversion.Therationalebehindthelatterdecisionwasto
eliminate outliers of the distribution (the 3rd quartile of the dis-tribution is 14 actions), which could hinder the learning process.
Moreover, we do not aim to learn such large bug-fixing patches.
Next, we filter the BFPs based on their size, measured in the
numberoftokens.Wedecidedtodisregardlongmethods(longer
than50tokens)andfocusedonsmallsizeBFPs.We,therefore,create
the dataset BFP small ={bfp≤50}.
2.2.4 Synthesis of Identifiers and Literals. BFPsaretheexamples
we use to make our model learn how to fix source code. Given a
bfp={mb,mf,A}, we first abstract its code, obtaining bfpa =
{abstract b,abstract f,A,M}.Thebuggycode abstract bisusedas
inputtothemodel,whichistrainedtooutputthecorresponding
fixed code abstract f. This output can then be mapped back to real
source code using M.
Intherealusagescenario,whenthemodelisdeployed,wedo
nothaveaccesstotheoracle(i.e., fixedcode, abstract f),butonlyto
the input code. This source code can then be abstracted and fed to
the model, which generates as output a predicted code ( abstract p).
The IDs that the abstract pcontains can be mapped back to real
valuesonlyiftheyalsoappearintheinputcode.Ifthefixedcode
suggests to introduce a method call, METHOD_6 , which is not foundin the input code, we cannot automatically map METHOD_6 to an
actual method name. This inability to map back source code exists
foranynewlycreatedIDgeneratedforidentifiersorliterals,which
are absent in the input code.
Therefore, it appears that the abstraction process, which allows
ustolimitthevocabularysizeandfacilitatethetrainingprocess,
confinesustoonlylearningfixesthatre-arrangekeywords,iden-
tifiers, and literals already available in the context of the buggy
method.Thisistheprimaryreasonwedecidedtoincorporateid-
ioms in our code representation, and treat them as keywords of
the language. Idioms help retaining BFPs that otherwise would be
discarded because of theinability tosynthesize newidentifiers or
literals.Thisallows themodeltolearnhow toreplaceanabstract
identifier/literalwithanidiomoranidiomwithanotheridiom(e.g.,
bottom part of Fig. 2).
After these filtering phases, the datasets BFP smallis comprised
of 58k (58,350) bug-fixes.
2.3 Learning Patches
2.3.1 Dataset Preparation. Given a set of BFPs (i.e., BFP small)
we use the instances to train an Encoder-Decoder model. Given
abfpa ={abstract b,abstract f,A,M}we use only the pair
(abstract b,abstract f) of buggy and fixed abstracted code for learn-
ing. No additional information about the possible fixing actions ( A)
is provided during the learning process to the model. The given
set of BFPs is randomly partitioned into: training (80%), validation
(10%), and test (10%) sets. Before the partitioning, we make sure to
removeanyduplicatedpairs( abstract f,abstract b)tonotbiasthe
results,i.e.,same pair both in training and test set.
2.3.2 NMT. TheexperimentedmodelisbasedonanRNNEncoder-
Decoder architecture, commonly adopted in NMT [ 6,17,33]. This
model consists of two major components: an RNN Encoder, which
encodesa sequence of terms xinto a vector representation, and
an RNN Decoder, which decodesthe representation into another
sequenceofterms y.Themodellearnsaconditionaldistribution
over a (output) sequence conditioned on another (input) sequence
of terms: P(y1,..,ym|x1,..,xn), wherenandmmay differ. In our
case,givenaninputsequence x=abstract b=(x1,..,xn)andatar-
get sequence y=abstract f=(y1,..,ym), the model is trained
to learn the conditional distribution: P(abstract f|abstract b)=
P(y1,..,ym|x1,..,xn),wherexiandyjareabstractedsourcetokens:
Java keywords, separators, IDs, and idioms. Fig. 1shows the archi-
tectureoftheEncoder-Decodermodelwithattentionmechanism
[3,4,25]. The Encoder takes as input a sequence x=(x1,..,xn)
and produces a sequence of states h=(h1,..,hn). We rely on a
bi-directional RNN Encoder [ 3], which is formed by a backward
andaforwardRNN,whichareabletocreaterepresentationstaking
into account both past and future inputs [ 4]. That is, each state hi
represents the concatenation (dashed box in Fig. 1) of the states
producedbythetwoRNNswhenreadingthesequenceinaforward
and backward fashion: hi=[− →hi;← −hi].
The RNN Decoder predicts the probability of a target sequence
y=(y1,..,ym)given h. Specifically, the probability of each out-
putterm yiiscomputedbasedon:(i)therecurrentstate siinthe
Decoder; (ii) the previous i−1 terms(y1,..,yi−1); and (iii) a con-
text vector ci. The latter constitutes the attention mechanism. The
835
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:09 UTC from IEEE Xplore.  Restrictions apply. An Empirical Investigation into Learning Bug-Fixing Patches in the Wild via NMT ASE ’18, September 3–7, 2018, Montpellier, France
vectorciis computed as a weighted average of the states in h:
ci=/summationtext.1n
t=1aithtwhere the weights aitallow the model to pay
moreattention to different parts of the input sequence. Specifically,
the weight aitdefines how much the term xishould be taken into
account when predicting the target term yt.
The entire model is trained end-to-end (Encoder and Decoder
jointly) by minimizing the negative log likelihood of the target
terms, using stochastic gradient descent.
2.3.3 Hyperparameter Search. Forthemodelbuiltonthe BFP small
dataset (i.e., Msmall) we performed hyperparameter search by test-
ing ten configurations of the encoder-decoder architecture. The
configurations testeddifferentcombinations of RNN Cells(LSTM
[13] and GRU [ 6]), number of layers (1, 2, 4) and units (256, 512)
fortheencoder/decoder,andtheembeddingsize(256,512).Bucket-
ing and padding was used to deal with the variable length of the
sequences.Wetrainedourmodelsforamaximumof60kepochs,
andselectedthemodel’scheckpointbeforeover-fittingthetraining
data.To guidetheselectionof thebestconfiguration, weusedthe
lossfunctioncomputedonthe validation set(notonthetestset),
whiletheresultsarecomputedonthe testset.Alldataareavailable
in our online appendix [34].
3 EXPERIMENTAL DESIGN
Thegoalof this study is to empirically assess whether NMT can
beused tolearn fixesinthe wild.The contextconsistsof adataset
of bug fixes (Sec. Section 2) and aims at answering the following
research question.
3.1 RQ: Is Neural Machine Translation a viable
approach to learn how to fix code?
WeaimtoempiricallyassessingwhetherNMTisaviableapproach
tolearntransformationsofthecodefromabuggytoafixedstate.
To this end, we use the dataset BFP smallto train and evaluate
the NMT model Msmall. Precisely, given a BFP dataset, we train
differentconfigurationsoftheEncoder-Decodermodels,thenselect
thebestperformingconfigurationonthevalidationset.Wethen
evaluate the validity of the model with the unseen instances of the
test set.
The evaluation is performed as follows: let Mbe the trained
model and Tbe the test set of BFPs ( BFP small), we evaluate the
modelMfor eachbfp=(abstract b,abstract f)∈T. Specifically,
wefeedthebuggycode abstract btothemodel M,whichwillgener-
ateasinglepotentialpatch abstract p.Wesaythatthemodelgener-
atedasuccessfulfixforthecodeifandonlyif abstract p=abstract f.
We report the raw count and percentage of successfully fixed BFPs
in the test set.
4 RESULTS
4.1 RQ: Is Neural Machine Translation a viable
approach to learn how to fix code?
Whenperformingthehyperparametersearch,wefoundthatthe
configuration which achieved the best results on the validation set
was the one with 1-layer bi-directional Encoder, 2-layer Attention
Decoderbothwith256units,embeddingsizeof512,andLSTM[ 13]
RNN cells. We trained the Msmallmodel for 50k epochs.The model was able to successfully generate a fix for 538 out
of 5,835 cases ( 9.22% of the BFPs in the test set) by “translating”
the buggy code in the corresponding fixed code. While the number
of successful fixes might appear relatively small, it is important to
note that these fixes are generated with a single guessof the model
asopposedtopreviousapproachesthatgeneratemanypotential
patches.Moreover,itisworthnotingthatallBFPsinthetestsets
areuniqueandhaveneverbeenseenbeforebythemodelduringthe
trainingorvalidationsteps.Allthepatchesgeneratedbythemodel
can be mapped to concretesource code by replacing the IDs in the
abstractcodetotheactualidentifiersandliteralsvaluesstoredin
the mapping M.
5 THREATS TO VALIDITY
Construct validity. To have enough training data, we mined bug-
fixes in GitHub repositories rather than using curated bug-fixdatasets such as Defects4j [
16] or IntroClass[ 22], useful but very
limited in size. To mitigate imprecisions in our datasets, we manu-
allyanalyzedasampleoftheextractedcommitsandverifiedthat
they were related to bug-fixes.
Internal. It is possible that the performance of our model de-
pends on the hyperparameter configuration. We explain in Sec-
tion2.3.3how hyperparameter search has been performed.
External. WedidnotcompareNMTmodelswithstate-of-the-
arttechniquessupportingautomaticprogramrepairsinceourmain
goal was not to propose a novel approach for automated program
repair,butrathertoexecutealarge-scaleempiricalstudyinvesti-
gating the suitability of NMT for generating patches. Additional
stepsareneededtoconvertthemethodologyweadoptedintoan
end-to-end working tool, such as the automatic implementation of
the patch, the running of the test cases checking its suitability, etc.
This is a part of our future work agenda.
WeonlyfocusedonJavaprograms.However,thelearningpro-
cessislanguage-independent andthewholeinfrastructurecanbe
instantiated for different programming languages by replacing the
lexer, parser and AST differencing tools.
Weonlyfocused onsmall-sizedmethods.We reachedthisdeci-
sionafteranalyzingthedistributionoftheextractedBFPs,balancingtheamountoftrainingdataavailableandthevariabilityinsentence
length.
6 CONCLUSIONS
We presented an empirical investigation into the applicability of
NMT for the purpose of learning how to fix code, from real bug-
fixes.Wefirstdevisedanddetailedaprocesstomine,extract,and
abstract the source code of bug-fixes available in the wild, in order
toobtain method levelexamples ofbug-fixes,which wecallBFP.
Then,wesetup,trained,andtunedNMTmodelsto translatebuggy
code into fixed code. We found that our model is able to fix a large
number of unique bug-fixes, accounting for 9% of the used BFPs.
This study constitutes a solid empirical foundation upon which
other researchers could build, and appropriately evaluate, program
repair techniques based on NMT.
REFERENCES
[1]Abdulkareem Alali, Huzefa H. Kagdi, and Jonathan I. Maletic. 2008. What’s a
TypicalCommit?ACharacterizationofOpenSourceSoftwareRepositories.In
836
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:09 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France M. Tufano, C. Watson, G. Bavota, M. Di Penta, M. White, D. Poshyvanyk
The 16th IEEE International Conference on Program Comprehension, ICPC 2008,
Amsterdam, The Netherlands, June 10-13, 2008. 182–191.
[2]Miltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles Sutton. 2015. Sug-
gesting Accurate Method and Class Names. In Proceedings of the 2015 10th Joint
MeetingonFoundationsofSoftwareEngineering(ESEC/FSE2015).ACM,NewYork,
NY, USA, 38–49.
[3]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural Machine
Translation by Jointly Learning to Align and Translate. CoRRabs/1409.0473
(2014).
[4]DennyBritz,AnnaGoldie,Minh-ThangLuong,andQuocV.Le.2017. Massive
Exploration of Neural Machine Translation Architectures. CoRRabs/1703.03906
(2017).
[5]DavidBinghamBrown,MichaelVaughn,BenLiblit,andThomasReps.2017. The
CareandFeedingofWild-caught Mutants.In Proceedingsofthe201711th Joint
MeetingonFoundationsofSoftwareEngineering(ESEC/FSE2017).ACM,NewYork,
NY, USA, 511–522. DOI:http://dx.doi.org/10.1145/3106237.3106280
[6]KyunghyunCho,BartvanMerrienboer,ÇaglarGülçehre,FethiBougares,Holger
Schwenk,andYoshuaBengio.2014. LearningPhraseRepresentationsusingRNNEncoder-DecoderforStatisticalMachineTranslation. CoRRabs/1406.1078(2014).
[7]Jean-RémyFalleri,FloréalMorandat,XavierBlanc,MatiasMartinez,andMar-
tin Monperrus. 2014. Fine-grained and accurate source code differencing. In
ACM/IEEE International Conference on Automated Software Engineering, ASE ’14,
Vasteras, Sweden - September 15 - 19, 2014. 313–324.
[8]Michael Fischer, Martin Pinzger, and Harald C. Gall. 2003. Populating a Release
History Database from Version Control and Bug Tracking Systems. In 19th
InternationalConferenceonSoftwareMaintenance(ICSM2003),TheArchitecture
of ExistingSystems, 22-26 September2003, Amsterdam,The Netherlands. 23. DOI:
http://dx.doi.org/10.1109/ICSM.2003.1235403
[9]GitHub. 2010. GitHub Compare API. https://developer.github.com/v3/repos/
commits/#compare-two-commits. (2010).
[10] Ilya Grigorik. 2012. GitHub Archive. https://www.githubarchive.org. (2012).
[11]XiaodongGu,HongyuZhang,andSunghunKim.2018. DeepCodeSearch.In
Proceedings of the 40th International Conference on Software Engineering, ICSE
2018, Gothenburg, Sweden, May 27 - June 3, 2018.
[12]XiaodongGu,HongyuZhang,DongmeiZhang,andSunghunKim.2016. Deep
APIlearning.In Proceedingsofthe24thACMSIGSOFTInternationalSymposium
on Foundations of Software Engineering, FSE 2016, Seattle, WA, USA, November
13-18, 2016. 631–642.
[13]Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory.
Neural Comput. 9, 8 (Nov. 1997), 1735–1780. DOI:http://dx.doi.org/10.1162/neco.
1997.9.8.1735
[14]Guoliang Jin, Linhai Song, Wei Zhang, Shan Lu, and Ben Liblit. 2011. Automated
Atomicity-violation Fixing. In Proceedings of the 32Nd ACM SIGPLAN Conference
on Programming Language Design and Implementation (PLDI ’11). ACM, New
York, NY, USA, 389–400.
[15]Magne Jorgensen and Martin Shepperd. 2007. A Systematic Review of Software
DevelopmentCostEstimationStudies. IEEETrans.Softw.Eng. 33,1(Jan.2007),
33–53.
[16]René Just, Darioush Jalali, and Michael D. Ernst. 2014. Defects4J: A Databaseof Existing Faults to Enable Controlled Testing Studies for Java Programs. In
Proceedings of the 2014 International Symposium on Software Testing and Analysis
(ISSTA 2014). ACM, New York, NY, USA, 437–440.
[17]Nal Kalchbrenner and Phil Blunsom. 2013. RecurrentContinuous Translation
Models.In Proceedingsofthe2013ConferenceonEmpiricalMethodsinNaturalLan-
guageProcessing.AssociationforComputationalLinguistics,Seattle,Washington,
USA, 1700–1709.
[18]CarstenKolassa,DirkRiehle,andMichelA.Salim.2013. AModeloftheCommit
SizeDistributionofOpenSource.In SOFSEM2013:TheoryandPracticeofCom-
puterScience,PetervanEmdeBoas,FransC.A.Groen,GiuseppeF.Italiano,Jerzy
Nawrocki,andHaraldSack(Eds.).SpringerBerlinHeidelberg,Berlin,Heidelberg,
52–66.
[19]AnNgocLam,AnhTuanNguyen,HoanAnhNguyen,andTienN.Nguyen.2017.
Bug localization with combination of deep learning and information retrieval. In
Proceedings of the 25th International Conference on Program Comprehension, ICPC
2017, Buenos Aires, Argentina, May 22-23, 2017. 218–229.
[20]Xuan-Bach D. Le, David Lo, and Claire Le Goues. 2016. History Driven Program
Repair. In IEEE 23rd International Conference on Software Analysis, Evolution, and
Reengineering, SANER 2016, Suita, Osaka, Japan, March 14-18, 2016 - Volume 1.
213–224.[21]ClaireLeGoues,MichaelDewey-Vogt,StephanieForrest,andWestleyWeimer.
2012. Asystematicstudyofautomatedprogramrepair:Fixing55outof105bugs
for $8 each.In 34th International Conferenceon Software Engineering, ICSE 2012,
June 2-9, 2012, Zurich, Switzerland. 3–13.
[22]C. Le Goues, N. Holtschulte, E. Smith, Y. Brun, P. Devanbu, S. Forrest, and W.
Weimer. 2015. The ManyBugs and IntroClass Benchmarks for Automated Repair
of C Programs. TSE41, 12 (2015), 1236–1256.
[23]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2012.
GenProg:AGenericMethodforAutomaticSoftwareRepair. IEEETrans.Software
Eng.38, 1 (2012), 54–72.
[24]Fan Long and Martin Rinard. 2016. Automatic Patch Generation by Learning
CorrectCode.In Proceedingsofthe43rd AnnualACMSIGPLAN-SIGACTSympo-
siumonPrinciplesofProgrammingLanguages(POPL’16).ACM,NewYork,NY,
USA, 298–312.
[25]Minh-ThangLuong,HieuPham,andChristopherD.Manning.2015. EffectiveAp-
proaches to Attention-based Neural Machine Translation. CoRRabs/1508.04025
(2015).
[26]Matias Martinez,Thomas Durieux, Romain Sommerard, Jifeng Xuan, andMartin
Monperrus. 2017. Automatic repair of real bugs in java: a large-scale experiment
on the defects4j dataset. Empirical Software Engineering 22, 4 (2017), 1936–1964.
[27]Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra. 2013. SemFix: Program Repair via Semantic Analysis. In Proceedings of
the 2013 International Conference on Software Engineering (ICSE ’13). IEEE Press,
Piscataway, NJ, USA, 772–781.
[28]Terence Parr. 2013. The Definitive ANTLR 4 Reference (2nd ed.). Pragmatic
Bookshelf.
[29]VeselinRaychev,MartinVechev,andEranYahav.2014. CodeCompletionwith
StatisticalLanguageModels.In Proceedingsofthe35thACMSIGPLANConference
on Programming Language Design and Implementation (PLDI ’14). ACM, New
York, NY, USA, 419–428.
[30]Robert C. seacord, Daniel Plakosh, and Grace A. Lewis. 2003. Modernizing
Legacy Systems: Software Technologies, Engineering Process and Business Practices.
Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.
[31]Edward K. Smith, Earl T. Barr, Claire Le Goues, and Yuriy Brun. 2015. Is theCure Worse Than the Disease? Overfitting in Automated Program Repair. In
Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering
(ESEC/FSE 2015). ACM, New York, NY, USA, 532–543.
[32]Victor Sobreira, Thomas Durieux, Fernanda Madeiral Delfim, Martin Monperrus,
and Marcelo de Almeida Maia. 2018. Dissection of a bug dataset: Anatomy of
395patchesfromDefects4J.In 25thInternationalConferenceonSoftwareAnalysis,
EvolutionandReengineering,SANER2018,Campobasso,Italy,March20-23,2018.
130–140.
[33]Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to Sequence
Learning with Neural Networks. CoRRabs/1409.3215 (2014).
[34]Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin
White,andDenysPoshyvanyk.2018. LearningBug-FixingPatchesintheWild
via Neural Machine Translation - Online Appendix. https://sites.google.com/
view/learning-fixes. (2018).
[35]Danny van Bruggen. 2014. JavaParser. https://javaparser.org/about.html. (2014).
[36]Song Wang, Taiyue Liu, and Lin Tan. 2016. Automatically learning semantic
features for defect prediction. In Proceedings of the 38th International Conference
on Software Engineering, ICSE 2016, Austin, TX, USA, May 14-22, 2016. 297–308.
[37]WestleyWeimer,ThanhVuNguyen,ClaireLeGoues,andStephanieForrest.2009.
Automatically finding patches using genetic programming. In 31st International
ConferenceonSoftwareEngineering,ICSE2009,May16-24,2009,Vancouver,Canada,
Proceedings. 364–374.
[38]Cathrin Weiss, Rahul Premraj, Thomas Zimmermann, and Andreas Zeller. 2007.
HowLongWillItTaketoFixThisBug?.In ProceedingsoftheFourthInternational
Workshop on Mining Software Repositories (MSR ’07). IEEE Computer Society,
Washington, DC, USA, 1–.
[39]MartinWhite,MicheleTufano,ChristopherVendome,andDenysPoshyvanyk.
2016. Deeplearningcodefragmentsforcodeclonedetection.In Proceedingsof
the31stIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering,
ASE 2016, Singapore, September 3-7, 2016. 87–98.
[40]Jinqiu Yang, Alexey Zhikhartsev, Yuefei Liu, and Lin Tan. 2017. Better Test
Cases for Better Automated Program Repair. In Proceedings of the 2017 11th Joint
MeetingonFoundationsofSoftwareEngineering(ESEC/FSE2017).ACM,NewYork,
NY, USA, 831–841. DOI:http://dx.doi.org/10.1145/3106237.3106274
837
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:26:09 UTC from IEEE Xplore.  Restrictions apply. 