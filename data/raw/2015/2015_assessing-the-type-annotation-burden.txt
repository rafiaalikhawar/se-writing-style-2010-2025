Assessing the Type Annotation Burden
John-Paul Ore
Department of Computer Science and Engineering
University of Nebraska–Lincoln, NE, USA
jore@cse.unl.eduSebastian Elbaum
Department of Computer Science and Engineering
University of Nebraska–Lincoln, NE, USA
elbaum@cse.unl.edu
Carrick Detweiler
Department of Computer Science and Engineering
University of Nebraska–Lincoln, NE, USA
carrick@cse.unl.eduLambros Karkazis
Department of Computer Science and Engineering
University of Nebraska–Lincoln, NE, USA
lkarkazis@cse.unl.edu
ABSTRACT
Type annotations provide a link between program variables and
domain-specific types. When combined with a type system, these
annotations can enable early fault detection. For type annotations
tobecost-effectiveinpractice,theyneedtobebothaccurateand
affordablefordevelopers.Welack,however,anunderstandingof
how burdensome type annotation is for developers. Hence, this
work explores threefundamental questions: 1) howaccurately do
developers make type annotations; 2) how long does a single anno-
tationtake;and,3)ifasystemcouldautomaticallysuggestatype
annotation, how beneficial to accuracy are correct suggestions and
howdetrimentalareincorrectsuggestions?Wepresentresultsof
a study of 71 programmers using 20 random code artifacts that
containvariableswithphysicalunittypesthatmustbeannotated.
Subjectschooseacorrecttypeannotationonly51%ofthetimeand
takeanaverageof 136secondstomake asinglecorrectannotation.
Our qualitative analysis reveals that variable names and reasoning
overmathematicaloperationsaretheleadingcluesfortypeselec-
tion.Wefindthatsuggestingthecorrecttypeboostsaccuracyto
73%,whilemakingapoorsuggestiondecreasesaccuracyto28%.We
alsoexplorewhatstate-of-the-artautomatedtypeannotationsys-
temscan andcannotdo tohelpdevelopers withtypeannotations,
and identify implications for tool developers.
CCS CONCEPTS
•Applied computing →Annotation ;•Software and its en-
gineering →Softwaredefectanalysis ;•Theoryofcomputa-
tion→Type theory ;
KEYWORDS
abstract type inference; physical units; program analysis; staticanalysis; unit consistency; dimensional analysis; type checking;
robotic systems
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ASE ’18, September 3–7, 2018, Montpellier, France
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5937-5/18/09...$15.00
https://doi.org/10.1145/3238147.3238173ACM Reference Format:
John-PaulOre,SebastianElbaum,CarrickDetweiler,andLambrosKarkazis.
2018.AssessingtheTypeAnnotationBurden.In Proceedingsofthe201833rd
ACM/IEEEInternationalConferenceonAutomatedSoftwareEngineering(ASE
’18), September 3–7, 2018, Montpellier, France. ACM, New York, NY, USA,
12pages.https://doi.org/10.1145/3238147.3238173
1 INTRODUCTION
Type checking is one of the most successful and enduring ap-
proachesforensuringdesirableprogramproperties[ 6,29,35,39,
40]. Indeed, many empirical studies confirm the benefits of type
systems[ 13,27,36,43,46].Forexample,Prechelt etal.[36]demon-
strated that type checking introduces fewer defects and allows
programmerstoremovethosedefectsfaster,Hannenberg etal.[13]
claimedstatictypesimprovemaintainability,andSpiza etal.[43]
showed that type names alone even without static type checking
improves the usability of APIs.
Conceptually,typecheckingconsistsofthreeelements:1)a type
systemto define the abstract theory that can ensure the desired
property;2)a typemechanism toenforcetypeconsistency;and,3)a
typeassociation tolinkprogramvariablestotheircorresponding
types. Type association can occur through different means. For
common types such as int,float,o rstringthe association is
often supported by the programming language and occurs when a
variable is declared or is assigned some data of a known type.
For more domain-specifictypes [12, 18,31,53], however, devel-
opersmusttypicallyincorporatetypeannotations1[6]intothecode
tolink avariable withatype, therebymakingthe typeassociation.
Several efforts have explored the benefits of such type annotations.
For example, in the context of JavaScript , Gaoet al.[12] found
thattypeannotationshelpfind15%ofbugsinopen-sourceprojects.
InJava, Xianget al.[53] showed the fault detection potential of
annotatingwith real-worldtypes,wherevariablesrepresentmea-
surablequantitiesintherealworld.For C++,Or eetal.[31]check
the physical unit type consistency of files written for the Robot
OperatingSystem(ROS)[ 37]usingtypeassociationsinabuilt-in
map from class attributes of ROS libraries to physical unit types.For
C, Jiang and Su [ 18] checked programs for dimensional unit
correctness using lightweight type annotations.
Justlikeotherkindsofcodeannotation,creatingtypeannota-
tions is a burden for developers, in part because they must first
evaluate what program variables need annotation and then choose
1‘Type annotations’ are sometimes also called ‘type hints’ [41].
190
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France J. Ore, S. Elbaum, C. Detweiler, L. Karkazis
acorrecttypeannotation,hencethename annotationburden [7].
But...how burdensome? Although many refer to the annotation
burden as a given, we lack an understanding of how accurately
and quickly developers create type annotations and therefore have
difficulty quantifying the benefits to developers.
This work presents an empirical study of 71 subjects to first
answer these foundational questions about type annotations:
•RQ1: How accurately do developers make type annotations?
•RQ2: How long does a single correct annotation take?
To answer these questions, we design a study where we randomly
select code snippets from artifacts in the robotic/cyber-physical
domain.Wethenaskdeveloperstoannotateavariablebychoosing
a physical unit type from a list of common domain types, and to
explainwhytheymaketheannotation.Toourknowledge,thisis
thefirstworktoquantifytheburdeninmakingtypeannotations,
and in general this work contributes to the limited body of data on
code annotation.
We instantiate the type annotation task within the domain of
physical unit types as identified by Xiang et al.’s work on real-
world types [53]. For example, a variable that represents a spring
constantin the real-world would be annotated with the physical
unit type newtons-per-meter (Nm−1). The type system then checks,
for example, that variables of this type are only added or assigned
to other variables of this type. We choose this domain because
physical unit types are ubiquitous in robotic and cyber-physical
software,yettheyarenearlyalways implicit,andthelackofexplicit
typing causes many type inconsistencies [31, 33].
Becauseofthebenefitsofannotations,researchershaveexplored
automatingtheannotationprocess,includingwithautomatedan-
notationassistants.Vakilian etal.[50]foundthatannotationworks
bestwhendevelopersandautomatedtoolsworktogether.Weimag-
ine that automatic tools to suggest annotations will continue to
improve but occasionally make an incorrect suggestion. Therefore
this work also explores the impact of suggesting a type annotation:
•RQ3:Howbeneficialtoaccuracyarecorrectsuggestionsand
how detrimental are incorrect suggestions?
To address this question, we apply to the study annotation ques-
tionsoneofthreetreatments:withnosuggestion,withacorrect
suggestion, and with an incorrect suggestion.
The key findings of this work are:
•Developersassign typeannotationscorrectly only51 .4%of
the time.
•A developer takes on average 136.0sto correctly annotate a
single variable.
•Acorrectsuggestion reducestheriskof assigningawrong
type by a factor of 0 .40, while an incorrect suggestion in-
creases the risk of annotating incorrectly by a factor of 2 .66.
•Most subjects cite variable names alone as the clue to ex-
plaintheirannotation,whileothersubjectsreferencehow
reasoning over code operations informs their decisions.
•State-of-the-art tools suggest few correct type annotations,
and identifying what variables need to be typed is valuable
to developers.2 BACKGROUND: PHYSICAL UNIT TYPES
This work is instantiated in the type domain of physical units of
measureandbasedontheSIunitsystem[ 5].TheSIunitssystem
hasseven baseunits eachofwhichcanitselfbeatype.Additionally,
thesevenbaseunitscanbecombinedthroughmultiplicationand
division to make compound units, like kilogram-meter-squared-per-
second-squared (kgm2s−2), more commonly known as torque.
Physical units types have been explored in myriad efforts [ 14,
18,20,21,42,49,52].Notallvariablesbelongtothetypedomain.
Forexample, booleantypevariablesdonothaveaphysicalunits
type, while floatvariables can and often do represent a measured
quantitywithreal-worldmeaning,andthereforehaveaphysical
unittypeinadditiontotheirdatatype(like float).Determining
whether a variable belongs in the physical unit type domain is part
of the annotation burden.
Thetypeannotationprocessinthephysicalunitdomaininvolves
extractingcluesfromvariablenames,comments,andmathematical
constraints. For example, a developer could infer that variable rin:
dist_meters = r ∗ time_seconds;
probablyhasthetype meters-per-second (ms−1).Acompetentde-
veloperwouldnotethatthevariables dist_meters andtime_sec-
ondsprobably have physical units types because of their names,
althoughthename rprovideslittlehelp.Thenadevelopercould
solve for the physical unit type of rusing simple algebra, and per-
hapsrename rtorate_meters_per_second .Howeve r,sometimes
the name does not help, for example, the variable xin:
x = 0.01; // 1 cm
doesnothintatypebutitlikelyhasthetype meters(m)becauseof
the comment.
Developers must choose a physical unit type from a large set
of possible types, but in practice, some units are more commonthan others. Table 1shows the most common unit types ordered
by decreasing frequency found in a large corpus of open source
robotic code [33].
For our empirical study, we use Table 1as the list of possible
type annotations, with two additions: 1) NO UNITS , for scalars and
quantitiesthatarenotpartofthetypedomain;and2) OTHER,for
uncommon types like kilogram-meter-squared-per-second-cubed-
per-ampere (one of our answers, also known as voltage) and to
allowsubjectstothink beyondthechoicesprovided.Including NO
UNITSis essential because deciding what should be typed is the
first part of the annotation burden.
3 METHODOLOGY
In this section, we first describe the type annotation task and re-
iterateourresearchquestions.Wethenpresentourexperimental
designanddiscusshowweconstructedatestinstrumentwithcodeartifacts, and how we selected those artifacts. We then describe the
target population and how we recruited and pre-screened subjects
for the experiment. Next, we explain the experimental phases and
finally discuss the tools used during the experiment and analysis.
191
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. Assessing the Type Annotation Burden ASE ’18, September 3–7, 2018, Montpellier, France
Table 1: Common physical unit types from [33], in decreas-
ing order of frequency. COVERED denotes whether any
question’s correct answer on the study was the type listed.
PHYSICAL UNIT TYPE SI SYMBOL COVERED
meters m /check
second s
quaternion q /check
radians-per-second rads−1/check
meters-per-second ms−1
radians rad /check
meters-per-second-squared ms−2/check
kilogram-meters-squared-per-second-squared kgm2s−2/check
meters-squared m2
degrees (360) deg°
radians-per-second-squared rads−2/check
meters-squared-per-second-squared m2s−2/check
kilogram-meter-per-second-squared kgms−2
kilogram-per-second-squared-per-ampere kgs−2A−1/check
Celsius◦C
kilogram-per-second-squared kgs−2/check
kilogram-per-meter-per-second-squared kgm−1s−2
lux lx
kilogram-squared-per-meter-squared-per-second-
to-the-fourthkg2m−2s−4
3.1 Type Annotation Task & Research
Questions
Thetypeannotationtaskrequiresdeveloperstomakeatypeassoci-
ation between a variable and a type. We assess the type annotation
taskthroughanonlinetestwhereweshowcodesnippetstosubjects
andask themtochoosea physicaltypeannotationfor aspecified
variable. As shown in Figure 1, a test question consists of a code
snippet, a highlighted variable, a text question, a suggestion (forsome questions), and a drop-down menu of physical unit types.
Thedrop-downboxcontains21typeannotationsfromTable 1in
random order from which subjects must select one. The code snip-
pets used in this study vary in length from 4-57 lines, averaging
17.9LOCand 2.9 comments as measured by cloc[9]. Of the test
questions,14 /20showanentirefunctionwhilesixaretruncated
sothecodesnippetsfitontoonepage. Testquestionsliketheone
showninFigure 1areinstancesofthetypeannotationtaskthatwe
use to answer three RQs:
•RQ1: How accurately do developers make type annotations?
To answer this question we calculate the percentage of cor-
rect responses to a battery of type annotation tasks.
•RQ2: How long does a single annotation take? To answer
this question we measure the time to complete the type
annotation task.
•RQ3:Howbeneficialarecorrectsuggestionstoaccuracyand
howdetrimentalareincorrectsuggestions?Toanswerthis
question we provide a single correct or incorrect suggestion
tosomequestionsandmeasurethechangeinthepercentageof correct responses between questions without suggestions
and questions with suggestions.Afterthesubjectsfinalizetheirtypeannotationthroughtheunit
selection, they are asked to provide an open-ended explanation for
theirchoice.Welaterusetheexplanationstohelpusunderstand
howsubjectsreasonabouttypeannotations,bothwhenthetype
annotation is correct and when incorrect.
3.2 Experimental Design
Figure1:Sampletestquestion.Theyellowboxonline55in-dicatesthevariabletobeannotated.Thetestquestionshowstreatment T
2, a correct suggestion.
To address our research questions simultaneously, we design an
experiment involving instances of the annotation task described
earlier.Inourexperiment,wemeasurebothresponseaccuracyand
the time it takes the subject to select and submit an annotation.
Each test question,like the example shown in Figure 1, has one of
three treatments:
•T1: No suggestion (control). A question with the suggestion
section not included.
•T2:Correctsuggestion.Aquestionwithacorrectsuggestion
immediatelyabovethedrop-downbox,wherethetextofthe
suggestion exactly matches one option in the drop-down.
Thesuggestionisaccompaniedbythecaveat: “SUGGESTION
(Might not be correct).”
•T3:Incorrectsuggestion.Thistreatmentisidenticalto T2ex-
ceptthesuggestionisincorrect.Theincorrectsuggestionhasthesamecaveatasin
T2andmatchesoneoptioninthedrop-
down box. This incorrect suggestion is chosen randomly
from Table 1(excluding the correct answer and OTHER).
The measurements of accuracy and timing in response to T1an-
swerbothRQ 1andRQ2andalsoarethecontrolforRQ 3.Toaddress
192
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France J. Ore, S. Elbaum, C. Detweiler, L. Karkazis
RQ3, we compare the accuracy and time for test questions treated
with T1to questions treated with T2andT3. In this experiment,
theindependentvariable isthe suggestion,and the dependent
variables are annotation accuracy and time.
Ourstudyusesa completelyrandomizeddesign [22].Wegroup
tenquestionsintoanannotationtest(‘themaintest’),andrandomly
assign subjects to tests. We randomly apply a treatment to each
questionandrandomizequestionorderforeachsubject.Weensure
that each test includes at least three questions of each treatment
type, to spread the treatments across subjects.
3.3 Test Instrument Details
Question Timing, Explanations, and Code Artifacts. Ques-
tions include a snippet of a code artifact as shown in Figure 1.
Eachannotationquestionisinstrumentedtocollecttiminginfor-
mation, specifically the duration from when the question is loaded
to when the subjects finalize their answer.
Asexplainedearlier,afterthesubjectsfinalizetheiranswerto
atypeannotationtestquestion,weaskthemtoexplainwhythey
chose that type in an open-ended question. We want to record
explanations to understand how subjects reason about choosing
an annotation type and what differentiates correct from incorrect
responses. The time to write the explanation is not included in the
time to annotate.
The code artifacts come from a corpus of open-source robotic
and cyber-physical code repositories identified in [ 33] encompass-
ingawidevarietyofapplications.Thecorpuscontains797 ,410C++
filesfrom3 ,484GitHubrepositoriesthatbuildagainsttheRobot
OperatingSystem(ROS)[ 37],aroboticmiddlewarewithmany‘real
world types.’ From those files, we ran the tool Phriky [ 32] to iden-
tify31,928fileswithphysicalunittypevariables.Afterexcluding
test filesand those thatdid not compile,we randomly select afile,
andstartingfromthetop,wemanuallyidentifythefirstfunction
with unit types and make a judgement about whether the function
is sufficiently complex, meaning that it contains either interaction
between physical units or compound physical unit types (see Sec-
tion2).Withinsuchfunctions,werandomlyselectasinglevariable
with a physical unit type. We repeat this process until we have
20artifacts,andeachartifactwasreviewedbyatleasttwoofthe
authors. Finally, we cross-check the annotations one more time
before the test and one more time during the test instrument eval-
uationphase.Table 1showstheresultingdistributionofphysical
unit types within the code artifacts we study.Suggestions.
Fortreatment T2,the21typesinthedrop-downmenu
arethe19mostcommonphysicalunitsfoundinacorpusofrobotic
code plus NO UNITS andOTHER(see Section 2). For treatment T3,
theincorrectsuggestionisrandomlyselectedfromTable 1minus
the correct answer and OTHER. Suggestions are randomized per test,
so each question has a variety of incorrect suggestions across tests.
Type Annotation Options. At the bottom of Figure 1is a drop-
downmenu withannotationtypechoices. Everyquestion,regard-
less of treatment, had the same type annotation options in a drop-
down menu, with the order randomized for every question to miti-
gate the threat of response order bias [16].
Tests.We have a pool of 20 artifacts, each with a unique code
snippetandcorrectanswer.Wecompose20testswithadifferentrandomsubsetof10questionsrandomlyselectedfromtheinitial
poolof20.Werandomizequestionorderpersubject,andrandomly
assign treatments T1-T3to questions, retaining a balanced number
of treatments per test.
A version of the test instrument with all 20 test questions can
be found at https://doi.org/10.5281/zenodo.1311901.
3.4 Subject Sample Population
Thesamplepopulationisuserswithprogrammingexperiencere-
cruited using Amazon’s Mechanical Turk (MTurk). MTurk is an
onlinemarketplaceforlaborthatisincreasinglypopularforbehav-iorresearch[
25]andhasanextensiveusageinsoftwareengineering
[10,24,44].FindingsubjectsonMTurkisnotwithoutrisks(espe-
ciallyindemographics)[ 19]buthasbeenshowntobe‘appropriate’
forresearchrequiringdiversecognition[ 17].TheMTurkmecha-
nismallowsfor‘exclusioncriterion’topre-screensubjectsbased
on a demonstrated ability to complete MTurk tasks successfully.
Followingrecommendedpractices[ 47],wepre-screensubjects
by requiring them to have completed >500 tasks with >90% ap-
proval in their MTurk history, and further screen subjects by re-
quiringthemtopassapretestoftypeannotations.Wepaysubjects
a fixed amount for the pretest ($2 USD) and main test ($10 USD)regardless of accuracy, since this has been shown to have little
impact on quality among MTurk workers [ 26]. We tell the subjects
not to rush, that they would be judged based on the accuracy oftheir responses, to provide good explanations, and to watch forrandom ‘attention checks’ [
15] because this has been shown to
increase performance.
Table 2: Demographics for 71Subjects.
YEARS
EXPERIENCEPROGRAMMING
C,C++, C#,JavaEMBEDDED SYSTEMS,
CYBER-PHYSICAL, ROBOTICS
<1 17 (24%) 53 (75%)
1−5 37 (52%) 15 (21%)
5+ 17 (24%) 3 (4%)
At the beginning of the pretest, we ask three demographic ques-
tions about experience with programming languages, robotics, and
typeannotations.Wewanttodetermineifsubjectdemographics
would influence responses and to get a sense of who was partic-
ipating in the study. The first question relates to programminglanguages: “How many years of programming experience in lan-
guages like
C,C++,C#,Java?”The second asks about embedded
system programming: “Years of experience programming embedded
systems or robotic systems or cyber-physical systems (Things that
move or sense)?” Table2shows a summary of the responses for the
71 subjects who completed the main test. As shown in the table,
37/71 (52%) of subjects indicate 1-5 years experience with (mostly)
statically typed languages, and 18 /71 (25%) have more than one
year of experience with robotic or embedded programming. The
thirdquestion(Yes/No)asks: “Haveyouusedanycodeannotation
frameworks?” 13/71subjects(17%)indicatetheprevioususageof
annotationframeworksandnametoolssuchas ‘SAL/MSDN’ ,‘Re-
sharper/Jetbrains’ , and ‘JSR 308’ . We revisit the impact of
these demographic factors in Section 4.
193
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. Assessing the Type Annotation Burden ASE ’18, September 3–7, 2018, Montpellier, France
3.5 Tools
In conducting these experiments, we use several off-the-shelf tools:
Amazon’s Mechanical Turk (MTurk)[1] is used to recruit and
pay subjects both for the pretest and the main tests. We ensure
subjectsanonymity asrequiredby ourInstitutional ReviewBoard
(IRB# 20170817412EX) by tracking only the MTurk worker ID.
Qualtrics[3] isusedtocreateanddeploythetestinstruments,ran-
domize test question order per subject, instrument the questions to
recordtiminginformation,recordresponses,andgenerateaunique
completion code used to pay subjects. We configure Qualtrics to
prevent the same IP address from submitting multiple responses.R(StatisticalProgrammingLanguage)[38]
isusedfordataanal-
ysis, including the multinom function from the nnetpackage [ 51]
to build binomial log-linear response models, and the binompack-
age [11] to calculate binomial confidence intervals. We perform
ANOVA on timing questions using R’saovfunction.
Clang-format [2] is used to standardize the code formatting of
the snippets shown to subjects.
3.6 Study Phases
We conducted the study in two phases:
Phase1:TestInstrumentEvaluationandRefinement. Inthis
phase,weiterativelyevaluatethetestinstrumentson27subjects,
each test with ten questions without suggestions. Based on this
evaluation, we: 1) replaced two trivially easy questions; 2) refined
thesuggestionwording(“Mightnotbecorrect” )andpretestdemo-
graphicinstructions( “NOTGRADEDORSCORED,” asrecommended
by best practices for MTurk in [ 19]); 3) verified our annotations; 4)
addedvisualhighlightstothevariablestobeannotated;5)random-izedthequestionorderpertest;and,6)addedarequiredexplanationtextboxfieldforeveryannotation.Noneofthedataacquiredinthis
phase is included in our results, and the 27 evaluation subjects are
not eligible to take the main test.
Figure 2: Code snippet used in the pretest.
Phase2:TestInstrumentDeploymentofPretest&MainTest.
We require subjects to pass a pretest. In the pretest, all subjects
read two practice questions that serve as a tutorial and then must
correctlyanswertwoannotationquestions.Figure 2showsascreen-
shotofaquestionfromthepretest.Thecorrecttypeassignment,meters-per-second, can be inferred from the variable name or thename of the variable assigned to it. In total 1431 subjects started
thepretest,butonly487finishedit,indicatingthatmanysubjects
opted out of the task. Of those that finished the pretest, 30 .7% of
subjects(145/472) passed the pretest.
After passing the pretest, 49 .0% of subjects (71/145)took the
maintest,whichtheyhadtostartwithin4hoursofthepretestand
thenhad2hourstocomplete.Wepaideachmain-testsubject$10
(USD). We received 417 total responses to the main test.2
2Theeagle-eyedreaderwillnoticewehave 71subjectswhotooka 10questiontest,yet
haveonly 417responses.Wehadtoexclude 293responsesbecause thetestquestion
order was accidentally not randomized early in this phase.4 RESULTS
We first address the accuracy of responses with no suggestions ( T1,
the control treatment) and examine how subjects’ demographicsimpact accuracy, then examine
T1’s timing and compare correct
responses to incorrect responses. Next, we explore the impact of
suggestionsonaccuracy(treatments T2andT3,respectively)and
then examine annotation timing by question difficulty. Finally, we
summarize the clues subjects reported using to choose a type.
4.1 RQ 1Results: Accuracy
Fortestquestionsundertreatment T1,withnosuggestions,subjects
correctlyannotate71 /138(51%),asshowninFigure 3.Thefigure
showsthemeananda95%binomialproportionconfidenceinterval
of±8.5% (Agresti-Coull) [4].
0.00 0.25 0.50 0.75 1.00
ACCURACY
Figure 3: Annotation accuracy for control treatment T1.
Table3showsdetailedstatisticsforaccuracyundertreatment T1.
Asshowninthetable,thereisawiderangeofaccuracybasedon
the question. Based on the accuracy of test questions that received
treatment T1,wegroupedquestionsintothreedifficultylevels:Easy
100−75%, Medium 75 −25%, Hard 25 −0%.
Figure5showstherangeofaccuracyforeachdifficultygroup
ofT1(no suggestion). We make this grouping primarily to see if
question difficulty correlates to the time necessary to assign a type.
PreviousExperienceHasLittleImpactOnAccuracy. Subject’s
previous experience with programming languages, robotics/cyber-
physical systems, and experience with annotations (described in
Section3.4)doesnothaveasignificantimpactonaccuracy.Subjects
with 5+years of programming experience ( N=17) have a slightly
higher mean accuracy (56%) than other subjects (50% for 1 −5
years N=37, 50% for <1 years N=17), but without significance
(p=0.554). Surprisingly, subjects with the least experience with
robotics/cyber-physical have the highest accuracy (53%, N=53)
compared other subjects (45% for 1 −5 years N=15, 50% for 5 +
years N=3), but that is within the noise ( p=0.829).
Physical Unit Complexity Has Little Impact On Accuracy.
Physical unit types in the SI System have both base unit types
(likemeters)and compoundunits types(like kilogram-meters-per-
second-squared ), described in Section 2. The increasing complexity
ofcompoundtypesdidnotappeartocorrelatetoinaccuracy.For
example, the correctanswer to Q19andQ20is the simplephysical
unit type radian, yet subjects incorrectly annotate this question
more than any other, 10/12 times, while the slightly more com-plexquaternion on
Q12is never incorrectly annotated, likely be-
cause the variable in Q12is assigned from the well-named function
convertPlanarPhi2Quaternion() . Similarly, compound physical
units like kilogram-meter-squared-per-second-squared onQ17is in-
correct5/6times,while thesimilar compoundunits kilogram-per-
second-squared isansweredincorrectly4/10timesin Q2.Overall,the
complexity inherent in the physical unit type seems less important
than the surrounding clues, especially good variable names.
RQ1AccuracyResults: Manually assigning type annotations is
error-prone (51% accurate, ±8.5%).
194
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France J. Ore, S. Elbaum, C. Detweiler, L. Karkazis
4.2 RQ 2Results: Timing
The timing data includes outliers, because our test mechanism has
a long time-bound (2 hours). We cap the value of 8 /147 timing out-
liers using Tukey’s interquartile ‘gate’ range method [ 48]. Tukey’s
method identifies outliers using a scaling factor ktimes the in-
terquartile range plus the third quartile, and suggests k=3[28].
We use an even more conservative k=6 to identify outliers to
cap (for upper and lower quartiles Q1 and Q3, we cap values above
Q3+k(Q3−Q1)with k=6).Intotal,wecapquestiontimesgreater
than 961 .6s to the sample mean’s 95% value, 529 .1s.
● ●● ● ● ● ● ●
● ● ●
●● ●
HARDMEDIUMEASYALL
0 100 200 300 400 500
SECONDSRESPONSE
CORRECT
INCORRECT
Figure4:Timetocompleteasingleannotation,separatedby
question difficulty and correctness annotation.Subjectstakeanaverageof 136.0s(median= 108.6s)tomakea
single correct type annotation. The results for annotation timesare shown in Figure 4, grouped by question difficulty and cor-
rectness. Correct annotations are slightly faster than incorrect
ones (mean=
169.2s) but not significantly faster ( p=0.184). As
shown in the figure, the average time to assign a type annota-
tion (for All) is nearly the same whether correct or incorrect,
with slightly more variance for incorrect answers. Hard ques-
tions(mean= 219.7s)tendtotakelongertoanswercorrectlythan
Easy questions (mean= 112.3s), but without statistical significance
(p=0.282), likely because few Hard questions were answered
correctly(wewouldhaveneededseveralmorehardquestionsto
have enough statistical power).
RQ2Timing Results: assigning type annotations is time-
intensive (mean=136 .0s, median=108 .6sper variable ).
Table 3: Accuracy and time for questions by treatment.
Q#DIFFICULTYCONTROL TREATMENTS
T1NO SUGGESTION T2CORRECT SUGGESTION T3INCORRECT SUGGESTION
Correct Time (s) Correct Time (s) Correct Time (s)
% Fraction Mean Median % Fraction Mean Median % Fraction Mean Median
12
Easy1006⁄676 70 835⁄6111 36 332⁄6162 121
9 909⁄10113 90 808⁄10112 70 674⁄693 68
5 835⁄6144 82 835⁄6237 155 171⁄6116 49
15 835⁄6169 141 835⁄6122 103 404⁄10125 102
All Easy 8925⁄28124 88 8223⁄28141 70 3610⁄28124 74
4
Medium674⁄6153 102 808⁄10151 105 202⁄10223 146
6 674⁄6134 130 756⁄8156 103 503⁄6146 76
16 674⁄664 65 909⁄10200 72 332⁄6104 77
8 647⁄11130 141 909⁄1098 79 332⁄6163 103
2 606⁄10120 105 332⁄675 54 202⁄1072 58
3 606⁄10302 233 835⁄6202 139 171⁄6150 123
7 503⁄6226 103 808⁄10155 153 171⁄686 69
10 433⁄787 105 835⁄697 100 332⁄6184 184
11 332⁄6151 128 835⁄6175 78 674⁄6107 99
14 332⁄6106 101 674⁄675 42 00⁄675 53
18 332⁄6167 50 1006⁄6126 125 332⁄6264 218
All Medium 5141⁄80153 112 7765⁄84140 90 2821⁄74143 108
1
Hard171⁄6245 188 674⁄656 52 404⁄10258 175
13 171⁄6130 90 503⁄699 67 00⁄6156 146
17 171⁄654 32 332⁄6198 126 574⁄7233 111
19 171⁄6213 201 503⁄690 85 171⁄6174 83
20 171⁄6234 196 503⁄6231 168 00⁄6111 84
All Hard 175⁄30175 118 5015⁄30135 91 238⁄35196 99
All Questions 5171⁄138152 109 73103⁄142139 86 2839⁄137153 98
195
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. Assessing the Type Annotation Burden ASE ’18, September 3–7, 2018, Montpellier, France
Table 4: Accuracy by treatment. ‘Risk Ratio’ lines show a multiplication factor indicating the likelihood
of an incorrect type annotation with a 95%confidence interval. A Risk Ratio of 2means twice as likely.
TREATMENT % CORRECT RESPONSES SUBJECTS RISK RATIO OF INCORRECT TYPE ANNOTATION p-VALUE
T1No Suggestion (Control) 51 138 71
0 0 .5 12345-
T2Correct Suggestion 73 142 69 0.0003
T3Incorrect Suggestion 28 137 58 0.0001
4.3 RQ 3Results: Impact of Suggestions on
Accuracy
RQ3considers the impact of a single suggestion on the accuracy
and timing of type annotations.
As discussed in Section 3.2, subjects are supplied with a type an-
notation suggestion immediately below the question text as shown
in Figure 1, either correct ( T2) or incorrect ( T3). To measure the
significance of the impact of suggestions we fit a binomial log-
linear response model (‘the model’). We use a binomial responsemodel because the test question responses are either
correct=1
orincorrect =0. The output of the model includes the risk ratio
by treatment. The risk ratio is used in log-linear models to quan-tify the likelihood of a binomial response. A risk ratio
>1 in our
study means an increased risk of assigning an incorrect type when
compared to the control (T 1).
As shown in Table 4, a correct suggestion T2decreases the risk
ofannotatingincorrectly( p=0.0001)comparedto T1.Themodel
predictsthat T2reducestheriskofassigningawrongtypebya0 .40
(0.24-0.66,95%confidence).Anincorrectsuggestion T3increases
theriskofannotatingincorrectly( p=0.0003)comparedto T1.The
model predicts that T3increases the risk of assigning a wrong type
by 2.66 (1.62-4.39, 95% confidence).
These p-values indicate that treatments T2andT3have a signifi-
cant impact on annotation accuracy. Treatments T2andT3are also
significantly different from each other ( p=1.281e−12).
Fortreatment T3(incorrectsuggestion),ofthe71subjectsprovid-
ing 137 responses, 98 responses are incorrect. Of these, 30 /98 (31%)
responses‘tookthebait’ofusingtheprovidedincorrectsuggestion.
Regarding subjects, this corresponds to 22 /71 (31%) that used an
incorrect suggestion for an annotation.The most common incorrect annotation for T2(14/39) and T3
(28/98) was NO UNITS , meaning users infer that the units canceled
outorthatthecorrectanswerwasascalar.Thenextmostcommon
incorrect annotations are meters(T24/39,T312/98) and OTHER(T2
3/39, T37/98).
Figure5shows the range of accuracy for all treatments by ques-
tiondifficulty.Asshowninthefigure,anincorrectsuggestion T3
reducesaccuracyforEasy( −53%)andMedium( −49%)questions
with little impact on Hard questions. Correct suggestions T2ben-
efit all questions compared to T1, with similar improvements for
Hard (+33%) and Medium ( +26%) questions, while only helping
Easy questions by +7%.
RQ3AccuracyResults: Incorrectsuggestionsincreasetheriskof
incorrectannotationsbyafactorof2 .66,whilecorrectsuggestions
reduce the risk of incorrect annotations by a factor of 0 .40, an
approximately equal but opposite impact on annotation accuracy.
4.4 RQ 3Results:ImpactofSuggestionsonTime
Figure6shows the impact of a suggestion on the time required to
provide a correct annotation. The three difficulty levels are shown
along with the category All. For the group All, correct annota-
tionsarefastestin T2(correctsuggestion,mean =126.1s),compared
to33%longerwith T3(incorrectsuggestions,mean =168.5s))and
8% longer with T1(no suggestion, mean =136.0s). The difference
between the time between T2andT3is not significant ( p=0.220).
Correct suggestions have the least impact on the timing of Easy
questions. This small impact makes sense intuitively since Easy
questionsbenefitlessfromasuggestion.Correctsuggestionstendto
●●●
INCORRECT SUGGESTIONCORRECT SUGGESTIONNO SUGGESTION
0.00 0.25 0.50 0.75 1.00
ACCURACY●EASY
MEDIUMHARD
Figure 5: Accuracy by treatment and difficulty, showing 95%confidence interval.
196
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France J. Ore, S. Elbaum, C. Detweiler, L. Karkazis
● ● ●●● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ●
● ● ●● ● ●
● ● ●● ●
● ● ● HARDMEDIUMEASYALL
0 100 200 300 400 500
SECONDSTREATMENT
No suggestions.
One suggestion, correct.One suggestion, incorrect.
Figure 6: Timing by difficulty and treatment for correct responses.
reduce the time required for Hard questions, as shown in Figure 6,
althoughwithoutstatisticalsignificancethatweattributetohaving
fewcorrectHardanswers.Incorrectsuggestions T3tendtoincrease
thetimetoannotatebothMediumandHardquestions,butwithout
significance.
RQ3TimingResults: Althoughadefinitiveanswerrequiresfur-
ther study, correct suggestions appear to decrease the time for
correct annotations the most for Hard type annotations.
4.5 Clues for Choosing a Type
Sections4.1–4.3provided a quantitative analysis of the responses,
revealinganaccuracyof51%whichwassurprisinglylowandwhich
led us to further explore the clues that led developers to choose
aparticulartype.Weconductedthisexplorationbycollectingall
the explanations provided by the developers on all their responses
andanalyzingthemusingaGroundedTheory[ 45]approach.We
categorizedtheanswersbasedonwhatweperceivedwerecommon
patterns,reorganizingtheclustersduringiterativephasesasnew
and better patterns emerged. During the first iteration, we applied
twelvelabels.Afterthreeiterations,weconvergedtosixclusters
andassignedthemalabel,asshowninTable 5,discriminatedby
correctness and treatment.
Themostcommonclueusedbydevelopersforboth,correctand
incorrectanswers,for T1wasvariable‘namesonly’,usedfor71 /138
(51%) of all annotations. The caveat is that although all variables
had a name, not all of the code snippets included comments or
mathematical operations (we discuss them next). But at least from
a qualitative point of view, we note that the explanations tended to
convey the value of meaningful identifiers:
Q17: At least I hope ‘torque’ is referring to torque.Mathreasoningandnames werefrequentlyusedwhenexplaining
thecorrectanswers.Forexample,thisisanexplanationforacorrect
answer to the question in Figure 1:
Q4:vx*cos(th)-vy*sin(th)willgiveaquantityinm/
s. Since dt is a quantity in seconds, multiplying by that
will yield meters.
Errors due to poor math reasoning were present but less frequent
than we expected. As an example, for the same question we find:
Q4: Meters per second times dt would cause the seconds
to cancel out and the meters to square
Where “cause...the meters to square” is incorrect.
Code comments were also used as effective clues, with more
correct( N=11)thanincorrectanswers( N=3).Wenotethatonly
two questions ( Q6andQ8) contained clues in comments, which
may be representative of how common comments are in spite of
their value for inferring types. Incorrect answers for treatment T1
werecommonforvariablesnotinthetypedomain( NO UNITS )as
subjectsdidnotseemabletogatherenoughcluestodeterminethat
the type system even applied.
Fiverespondentsexplicitlystatedthatthesuggestionsfrom T2
helped, and 12 respondents stated that they were misguided by
T3. These values, however, constitute lower bounds as subjects
may not have confided us with the full extent to which they usethe suggestion. Still, the fact that for
T330/98 (31%) of incorrect
answers matched the incorrect suggestion we provided illustrates
the large potential impact of suggestions on developers’ actions.
QualitativeResults: Themaincluesfortypeselectionarevari-
able names and reasoning over mathematical operations.
Table 5: Summary of type annotation explanations for 417answers.
EXPLANATION CATEGORYCORRECT RESPONSES INCORRECT RESPONSES
T1 T2 T3 T1 T2 T3
names only 36 54 17 35 20 44
math reasoning and names 20 24 18 5 4 12
code comments 11 9 2 3 - -
not in type domain (NO UNITS) 4 10 1 19 13 25
used suggestion - 5 - - - 12
type depends on input - - - 5 2 2
197
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. Assessing the Type Annotation Burden ASE ’18, September 3–7, 2018, Montpellier, France
5 THREATS TO VALIDITY
5.1 External Threats
Subjects Might Not Represent Developers. We mitigate this
hazard by requiring respondents to complete a pretest that at least
shows that respondents could understand the task, read code, and
correctly identify the physical units that should be assigned to pro-
gram variables during annotation. Since subjects were not specifi-
callytrainedtomaketypeannotations,ouraccuracymeasurements
likely under-approximates the performance of trained developers.
Annotation Task Fidelity. The annotation task defined in Sec-
tion3withphysicalunittypesin C++mightnotgeneralizeother
type annotations. First, type systems vary in complexity, and phys-
ical unit types might be more or less complicated/time-consuming
than all type systems in general. We observe that type annota-
tion requires developer time and involves reasoning about boththe type system and how types interact with the code. Second,
our study examines type annotations made by non-authors, likely
under-approximating our accuracy measurements. Observing code
authors could improve fidelity in follow-on work.
Unrepresentative Code Artifacts. Thecodeartifactsmightnot
represent code that needs type annotation more generally. We
mitigate this threat by selecting artifacts randomly from a largecorpus (
5.9MLOC), although all our samples are for a strongly-
typedlanguage( C++).Welimitedthescopeofanalysistoafunction,
the accuracy and time might be different for bigger scopes.
5.2 Internal Threats
SubjectsRecruitedThroughMTurk. Werecruitedsubjectsthrough
MTurk, and [ 19] indicates MTurk subjects might falsify demo-
graphic information to participate in online tests. We mitigate this
threat by clearly stating on the pretest that demographic question
are “NOT GRADED OR SCORED.” We also filtered subjects and
provided incentives for them to take the task seriously.
Code Context Bias. Bias introduced by our artifacts, including
the amount of context or the variety of physical unit types. We
mitigatethisthreatbyshowingtheentirefunctionwhenfeasible
and testing the questions during an evaluation phase to make sure
it was possible to choose the correct type annotation with the
available information.
Test Instrument Format. The question and suggestion format,
as provided, does not reflect the full context on how a developer
operatesinrealityandmayhaveaffectedthesubjectsinwayswe
did not anticipate. The test instrumentation and refinement phase
helped mitigate this threat.PhysicalUnitTypeCommonNames.
Commonnamesforphys-
ical unit types like force(instead of kilogram-meters-per-second-
squared) are not an option in the drop-down box. We mitigate this
threat by examining every explanation. If subjects identified an
equivalent common name for the physical unit type, and answered
OTHERorsaidtheycouldnotfindtheunitsinthedrop-downbox,
weconsidertheanswerascorrect.Weconsidered7 /417answers
as correct because of a common name.TestTimeWindow. Wemeasurethetimetocompleteannotation
questions but allow a large time window (2 hours) to complete the
whole test, during which subjects might take breaks or do other
tasks, or take the entire allotted time to find the correct answer
(‘ceiling effect’), resulting in longer times to answer annotation
questions.Thereforeourtimingvaluesmightover-approximatethe
time to assign a type annotation. We mitigate this threat by identi-
fying and capping timing outliers. More importantly, our timing
onlycapturesannotationtime,butwerecognizethatdeveloper’s
time may be spent in, for example, pursuing leads generated by
incorrect annotations.
5.3 Conclusion Threats
StatisticalSignificance. Wedonothaveenoughsubjects( N=71)
tofind statisticalsignificance forsomeof ourhypotheses thathave
cleartrends,becauseweexhaustedtheresourcesavailabletoget
moresubjectsatthistimeandunanticipateddatadistributionacross
someofthefactorsweconsidered.Forexample,thetimeconsumed
by questions of different difficulty was not found to be statistically
significant because there were few Hard questions with correct
responses.Further,thisdatadistributiondoesnothavestatistical
significancewhensegmentingresponsesbydemographics.Inthe
future, we will address such limitations by deploying more tests
andbymonitoringtheresultsto reassignquestionstosubjectsto
even out the desired distributions.
6 DISCUSSION AND IMPLICATIONS
Section4.3indicatedthattypeannotationsuggestionscanhavea
significant impact on accuracy. Building on that insight, we briefly
exploretheperformanceofatypeannotationtoolforthesametypedomain,physicalunits.Morespecifically,weselecttheopen-source
tool Phriky [ 32] (version 1.0.0) that analyzes C++written for the
RobotOperatingSystem(ROS).WeselectedPhrikybecauseitis
open-source,operatesonROS C++code,isstate-of-the-art,andcan
automaticallysuggestphysicalunittypesforsomeprogramvari-
ables.Forexample,inFigure 2,lines18-19defineastructure msgof
type geometry_msgs::Twist . Phriky has a lookup table mapping
the attributes of this message class to physical units. This mapping
enables Phriky to infer in line 20 that the attribute msg.linear.x
has the physical unit type meters-per-second.
Table6showsthetoolPhriky’sphysicalunittypepredictions
for each variable that was used in a test question. We obtained
thesesuggestionsbyrunningPhriky --debug-print-ast oneach
file containing the code snippets used in the test, and recording
what physical unit type is assigned to the variable. As shown in
the Table, Phriky makes a suggestion for only 7/20 (35%) of the
variables, correcttype suggestionsfor 5/20(25%) ofvariables, and
incorrectsuggestionsfor2/20(10%)ofvariables.Existingtoolshave
an opportunity to address some of the challenges.
The implications for tools developers include:
•AsFigure 5shows,correctsuggestionsaremostbeneficial
for Hard type annotations, and therefore tool developers
will have a greater impact making correct suggestions in
Hard cases.
198
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France J. Ore, S. Elbaum, C. Detweiler, L. Karkazis
Table6:Correcttypesforeachquestioncomparedto Phriky
units annotations. Ordered by question difficulty.
Q#Difficulty Variable NameCorrect
TypePhriky
Suggestion
12
Easypose.orientation q /check
9 delta_d m /check
5 robotSpeed.angular.z rads−1
15 x2 m2
4
Mediumdelta_x m
6 w rads−1
16 av rads−1
8 path_move_tol_ m
2 springConstant kgs−2
3 ratio_to_consume NO UNITS
7 x NO UNITS
10 wrench_out.wrench.force.y kgms−2/check
11 data->gyro_z; ms−2/check
14 xi m
18 motor_.voltage[1] other
1
Hardreturn m
13 angular_velocity_covariance rads−2
17 torque kgm2s−2/check
19 anglesmsg.z rad
20 dyaw rad
•Findingvariablesthatlikelyneedtypeannotationsisvalu-
able because developers struggle to know what variables
belong to the type domain.
•Evidence that implies a type might also suggest a new vari-
able name with better type clues.
•Suggestatypeonlywhen >50%confident,becauseincorrect
suggestions hurt as much as correct suggestions help.
7 RELATED WORK
EmpiricalStudies ofTypesSystems. Severalempiricalstudies
confirm the benefits of type systems. Prechelt and Tichy [ 36] com-
paredtheimpactofstatictypecheckingonstudentprogrammers
using ANSI C and K&R, where ANSI C’s compiler type checked
procedure arguments and found fewer defects in programs written
withstatictypechecking.Likethiswork,weareinterestedinthe
empiricalmeasurementoftypes,butunlikethiswork,weuseexist-
ingcodeartifactsinsteadofnewones.Variousefforts[ 13,23,27,46]
claimed static typing improves reliability, maintainability, and un-
derstandabilityofstaticallytypedprogramsincomparisontody-
namic types. While those works weighed the costs and benefits of
type systems, we focus on the costs of the type annotation process.
Type names, even without type checking, improve the usability of
APIs[43],andRojasandFraser[ 8]emphasizedtheimportanceof
semantically useful names. We likewise find that variable names
contain informative clues, but unlike their work, we also find that
a misunderstood name can lead to incorrect type annotations.
Type Annotations. Gao,Bird,andBarr[ 12]examinedhowtype
annotations can detect bugs in JavaScript , and quantified the an-
notationburdeninterms ofa timetaxandtokentax.Theauthors
measured their own annotation effort and reported the time and
numberoftokenstoannotatetodetect onebug.Usingtheir token
tax(token-annotation-per-bug) and time tax(time-per-bug), we
infer their time per single annotation to be 127.8sfor TypeScriptand135.8sforFlow.Wemeasuredanuncannilysimilar 136.0sfor
asingletypeannotation,eventhoughthetask,language,skilllevel,
andtypedomainaredifferent.Liketheirwork,weareinterested
inthecostoftypeannotation,butunliketheirwork,wemeasure
the time for a population of 71 individuals and not the three au-
thorsthemselves. Xiang etal.proposea kindofprogramanalysis
with’Real-WorldTypes’[ 53].Thisanalysisrequiresthatananalyst
examine all program tokens to decide what needs to be annotated.
Type Annotation Tools and Suggestions. Nimmer and Ernst
evaluated the factors that made an annotation assistant useful [ 30].
Like their work, we perform an empirical evaluation, and unliketheir work, we focus on type annotations instead of assertions.
ThetypequalifiertoolCascadeshowsbetterresultsbyinvolving
programmersratherthan byautomaticinferencealone[ 50].Like
their work, we consider automatic inference mixed with developer
inputtobeanaturalnextstep.ParninandOrso’sworkonautomatic
suggestions in fault isolation [ 34] showed that when a tool makes
multiple suggestions to a developer, only the first suggestion is
likely to be used. We likewise make only one suggestion and leave
for future work a study of multiple suggestions.
8 CONCLUSION
This work contributes a rich characterization of type annotation
accuracy and cost. Our findings reveal that user annotations are
wrongalmosthalfofthetimeandthatcorrectlyannotatingasin-
glevariabletakesonaveragemorethantwominutes.Througha
qualitative analysis of the annotation explanations, we find that
variable naming and reasoning over the space of operations on
the types were the most common culprits of incorrect annotations.
Giventhechallengeofcorrectlyannotatingcode,thereissignifi-
cant potential for automated tools to reduce this burden; however,
they could misguide the developer if the suggestions are incorrect.
Further,existingtoolsthatprovidesuchautomationonlycovera
small portion of the annotation space.
Inthefuture,wewillbroadenthecontextofthisstudytoinclude
richer kinds of annotations over larger scopes todetermine when
our findings generalize. This would help to further close the gap
in our understanding of the costsand benefits of annotations. We
would also like to consider the follow-up phase, when the anno-
tations are consumed by either the developer or another tool, tomore precisely understand the cost of incorrect annotations and
thenumberofcorrectannotationsthatareneededtoreceivetan-
giblebenefits.Last,wewouldliketobuildonexistingtechniques
and tools for automating type suggestions, especially to cover a
greaterportionoftheannotationspaceandtoexplorehybridanno-tation mechanisms, all while taking into consideration the baseline
accuracy and cost identified in this paper.
ACKNOWLEDGMENT
Wethank oursubjects fortaking partinthe study.We wouldalso
liketothankNIMBUSlabmembersUrjaAcharya,CarlHildebrandt,
Ajay Shankar, and Adam Plowcha for providing feedback on early
versionsofthetypeannotationtestinstrument.Thisworkissup-
ported by NSF award #CCF-1718040.
199
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. Assessing the Type Annotation Burden ASE ’18, September 3–7, 2018, Montpellier, France
REFERENCES
[1] 2018. Amazon Mechanical Turk (MTurk). https://www.mturk.com
[2] 2018. Clang: a C language family frontend for LLVM. https://clang.llvm.org
[3] 2018. Qualtrics. https://www.qualtrics.com
[4]Alan Agresti and Brent A Coull. 1998. Approximate is better than “exact” for
intervalestimationofbinomialproportions. TheAmericanStatistician 52,2(1998),
119–126.
[5]BIPM. 2006. Le Système international d’unités / The International System of Units
(‘The SI Brochure’) (eighth ed.). Bureau international des poids et mesures. http:
//www.bipm.org/en/si/si_brochure/
[6]Luca Cardelli. 1996. Type Systems. ACM Comput. Surv. 28, 1 (1996), 263–264.
https://doi.org/10.1145/234313.234418
[7]Patrice Chalin and Perry R. James. 2007. Non-null References by Default in Java:
Alleviating the Nullity Annotation Burden. In ECOOP 2007 - Object-Oriented
Programming,21stEuropeanConference,Berlin,Germany,July30-August3,2007,
Proceedings. 227–247. https://doi.org/10.1007/978-3-540-73589-2_12
[8]Ermira Daka, José Miguel Rojas, and Gordon Fraser. 2017. Generating unit tests
with descriptive names or:wouldyouname your children thing1 and thing2?.
InProceedings of the 26th ACM SIGSOFT International Symposium on Software
Testing and Analysis, Santa Barbara, CA, USA, July 10 - 14, 2017, Tevfik Bultan
and Koushik Sen (Eds.). ACM, 57–67. https://doi.org/10.1145/3092703.3092727
[9] Al Danial. 2018. Count Lines Of Code. https://github.com/AlDanial/cloc
[10]RafaelMaianideMello,PedroCorreadaSilva,PerRuneson,andGuilhermeHorta
Travassos. 2014. Towards a Framework to Support Large Scale Sampling in
Software Engineering Surveys. In Proceedings of the 8th ACM/IEEE International
SymposiumonEmpiricalSoftwareEngineeringandMeasurement (ESEM’14).ACM,
NewYork,NY,USA,Article48,4pages. https://doi.org/10.1145/2652524.2652567
[11]Sundar Dorai-Raj. 2014. binom: Binomial Confidence Intervals For Several Param-
eterizations. https://CRAN.R-project.org/package=binom R package version
1.1-1.
[12]ZhengGao,ChristianBird, andEarl T.Barr. 2017. To typeornot totype: quan-
tifying detectable bugs in JavaScript. In Proceedings of the 39th International
Conference on Software Engineering, ICSE 2017, Buenos Aires, Argentina, May
20-28,2017,SebastiánUchitel,AlessandroOrso,andMartinP.Robillard(Eds.).
IEEE / ACM, 758–769. https://doi.org/10.1109/ICSE.2017.75
[13]StefanHanenberg,SebastianKleinschmager,RomainRobbes,ÉricTanter,and
Andreas Stefik. 2014. An empirical study on the impact of static typing on
software maintainability. Empirical Software Engineering 19, 5 (2014), 1335–1382.
https://doi.org/10.1007/s10664-013-9289-1
[14]SudheendraHangalandMonicaS.Lam.2009. Automaticdimensioninference
andcheckingforobject-orientedprograms.In 31stInternationalConferenceon
SoftwareEngineering,ICSE2009,May16-24,2009,Vancouver,Canada,Proceedings.
IEEE, 155–165. https://doi.org/10.1109/ICSE.2009.5070517
[15]DavidJHauserandNorbertSchwarz.2016. AttentiveTurkers:MTurkpartici-
pantsperformbetterononlineattentionchecksthandosubjectpoolparticipants.
Behavior research methods 48, 1 (2016), 400–407.
[16]Allyson Holbrook. 2011. Encyclopedia of Survey Research Methods. Sage
Publications, Inc., Chapter Response Order Effects. https://doi.org/10.4135/
9781412963947
[17]RonnieJia,ZacharyR.Steelman,andBlaizeHornerReich.2017.UsingMechanical
TurkDatainISResearch:Risks,Rewards,andRecommendations. CAIS41(2017),
14.http://aisel.aisnet.org/cais/vol41/iss1/14
[18]Lingxiao Jiang and Zhendong Su. 2006. Osprey: a practical type system for
validating dimensional unit correctness of C programs. In 28th International
ConferenceonSoftwareEngineering,ICSE2006),Shanghai,China,May20-28,2006 .
262–271. https://doi.org/10.1145/1134323
[19]Irene P. Kan and Anna Drummey. 2018. Do imposters threaten data quality?
An examination of worker misrepresentation and downstream consequences in
Amazon’s Mechanical Turk workforce. Computers in Human Behavior 83 (2018),
243–253. https://doi.org/10.1016/j.chb.2018.02.005
[20]Michael Karr and David B. Loveman, III. 1978. Incorporation of Units intoProgramming Languages. Commun. ACM 21, 5 (May 1978), 385–391. https:
//doi.org/10.1145/359488.359501
[21]Andrew Kennedy. 2009. Types for Units-of-Measure: Theory and Practice. In
CentralEuropeanFunctionalProgrammingSchool-ThirdSummerSchool,CEFP
2009,Budapest,Hungary,May21-23,2009andKomárno,Slovakia,May25-30,2009,
Revised Selected Lectures. 268–305. https://doi.org/10.1007/978-3-642-17685-2_8
[22] Roger E Kirk. 1982. Experimental design. Wiley Online Library.
[23]SebastianKleinschmager,StefanHanenberg,RomainRobbes,ÉricTanter,and
Andreas Stefik. 2012. Do static type systems improve the maintainability of
software systems?An empiricalstudy.In IEEE 20thInternational Conferenceon
Program Comprehension, ICPC 2012, Passau, Germany, June 11-13, 2012. 153–162.
https://doi.org/10.1109/ICPC.2012.6240483
[24]Ke Mao, Licia Capra, Mark Harman, and Yue Jia. 2017. A survey of the use ofcrowdsourcing in software engineering. Journal of Systems and Software 126
(2017), 57 – 84. https://doi.org/10.1016/j.jss.2016.09.015[25]Winter Mason and Siddharth Suri. 2012. Conducting behavioral research on
AmazonâĂŹs Mechanical Turk. Behavior research methods 44, 1 (2012), 1–23.
[26]Winter A. Mason and Duncan J. Watts. 2009. Financial incentives and the
“performance of crowds”. SIGKDD Explorations 11, 2 (2009), 100–108. https:
//doi.org/10.1145/1809400.1809422
[27]Clemens Mayer, Stefan Hanenberg, Romain Robbes, Éric Tanter, and AndreasStefik. 2012. An empirical study of the influence of static type systems on theusability of undocumented software. In Proceedings of the 27th Annual ACM
SIGPLAN Conference onObject-Oriented Programming, Systems,Languages, and
Applications,OOPSLA2012,Tucson,AZ,USA,October21-25,2012.683–702. https:
//doi.org/10.1145/2384616.2384666
[28]RobertMcGill,JohnWTukey,andWayneALarsen.1978. Variationsofboxplots.
The American Statistician 32, 1 (1978), 12–16.
[29]RobinMilner.1978. ATheoryofTypePolymorphisminProgramming. J.Comput.
Syst. Sci.17, 3 (1978), 348–375. https://doi.org/10.1016/0022-0000(78)90014-4
[30]Jeremy W. Nimmer and Michael D. Ernst. 2002. Invariant Inference for Static
Checking: An Empirical Evaluation. SIGSOFT Softw. Eng. Notes 27, 6 (Nov. 2002),
11–20.https://doi.org/10.1145/605466.605469
[31]John-Paul Ore, Carrick Detweiler, and Sebastian Elbaum. 2017. Lightweight
Detection of Physical Unit Inconsistencies Without Program Annotations. In
Proceedingsofthe26thACMSIGSOFTInternationalSymposiumonSoftwareTesting
and Analysis (ISSTA 2017). ACM, New York, NY, USA, 341–351. https://doi.org/
10.1145/3092703.3092722
[32]John-Paul Ore, Carrick Detweiler, and Sebastian Elbaum. 2017. Phriky-units:
A Lightweight, Annotation-free Physical Unit Inconsistency Detection Tool.
InProceedings of the 26th ACM SIGSOFT International Symposium on Software
Testing and Analysis (ISSTA 2017). ACM, New York, NY, USA, 352–355. https:
//doi.org/10.1145/3092703.3098219
[33]J. P. Ore, S. Elbaum, and C. Detweiler. 2017. Dimensional inconsistencies in code
and ROS messages: A study of 5.9M lines of code. In 2017 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS). 712–718. https://doi.org/10.
1109/IROS.2017.8202229
[34]Chris Parnin and Alessandro Orso. 2011. Are automated debugging techniques
actuallyhelpingprogrammers?.In Proceedingsofthe20thInternationalSympo-
sium on Software Testing and Analysis, ISSTA 2011, Toronto, ON, Canada, July
17-21, 2011. 199–209. https://doi.org/10.1145/2001420.2001445
[35] Benjamin C. Pierce. 2002. Types and programming languages. MIT Press.
[36]Lutz Prechelt and Walter F. Tichy. 1998. A Controlled Experiment to Assess the
Benefits of Procedure Argument Type Checking. IEEE Trans. Software Eng. 24, 4
(1998), 302–312. https://doi.org/10.1109/32.677186
[37]MorganQuigley,KenConley,BrianGerkey,JoshFaust,TullyFoote,JeremyLeibs,
Rob Wheeler, and Andrew Y Ng. 2009. ROS: an open-source Robot Operating
System. In ICRA workshop on open source software, Vol. 3.2. Kobe, Japan, 5.
[38]R Core Team. 2013. R: A Language and Environment for Statistical Computing.R
FoundationforStatisticalComputing,Vienna,Austria. http://www.R-project.
org/
[39]Baishakhi Ray, Daryl Posnett, Premkumar T. Devanbu, and Vladimir Filkov.
2017. Alarge-scale studyofprogramming languagesand codequalityin GitHub.
Commun. ACM 60, 10 (2017), 91–100. https://doi.org/10.1145/3126905
[40]John C. Reynolds. 1974. Towards a theory of type structure. In Programming
Symposium, ProceedingsColloque surla Programmation,Paris, France,April9-11,
1974 (Lecture Notes in Computer Science), Bernard Robinet (Ed.), Vol. 19. Springer,
408–423. https://doi.org/10.1007/3-540-06859-7_148
[41]Guido van Rossum, Jukka Lehtosalo, and Łukasz Langa. 2014. PEP484 – Type
Hints.https://www.python.org/dev/peps/pep-0484/. [Online; accessed 13-July-
2018].
[42]G. Rosu and Feng Chen. 2003. Certifying measurement unit safety policy. In
18th IEEE International Conference on Automated Software Engineering, 2003.
Proceedings. 304–309. https://doi.org/10.1109/ASE.2003.1240326
[43]Samuel Spiza and Stefan Hanenberg. 2014. Type names without static type
checking already improve the usability of APIs (as long as the type namesare correct): an empirical study. In 13th International Conference on Modular-
ity, MODULARITY ’14, Lugano, Switzerland, April 22-26, 2014. 99–108. https:
//doi.org/10.1145/2577080.2577098
[44]Kathryn T. Stolee and Sebastian Elbaum. 2010. Exploring the Use of Crowd-
sourcing to Support Empirical Studies in Software Engineering. In Proceedings of
the2010ACM-IEEEInternationalSymposiumonEmpiricalSoftwareEngineering
and Measurement (ESEM ’10). ACM, New York, NY, USA, Article 35, 4 pages.
https://doi.org/10.1145/1852786.1852832
[45]AnselmStraussandJulietMCorbin.1990. Basicsofqualitativeresearch:Grounded
theory procedures and techniques. Sage Publications, Inc.
[46]Andreas StuchlikandStefan Hanenberg.2011. Static vs.dynamic typesystems:
anempiricalstudyabouttherelationshipbetweentypecastsanddevelopment
time. InProceedings of the 7th Symposium on Dynamic Languages, DLS 2011,
October24,2011,Portland,OR,USA,TheoD’Hondt(Ed.).ACM,97–106. https:
//doi.org/10.1145/2047849.2047861
200
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. ASE ’18, September 3–7, 2018, Montpellier, France J. Ore, S. Elbaum, C. Detweiler, L. Karkazis
[47]Kyle A. Thomas and Scott Clifford. 2017. Validity and Mechanical Turk: An
assessment of exclusion methods and interactive experiments. Computers in
Human Behavior 77 (2017), 184–197. https://doi.org/10.1016/j.chb.2017.08.038
[48] John W Tukey. 1977. Exploratory data analysis. Vol. 2. Reading, Mass.
[49]Zerksis D. Umrigar. 1994. Fully static dimensional analysis with C++. SIGPLAN
Notices29, 9 (1994), 135–139. https://doi.org/10.1145/185009.185036
[50]Mohsen Vakilian, Amarin Phaosawasdi, Michael D. Ernst, and Ralph E. Johnson.
2015. Cascade: A Universal Programmer-Assisted Type Qualifier Inference Tool.
In37thIEEE/ACMInternationalConferenceonSoftwareEngineering,ICSE2015,
Florence, Italy, May 16-24, 2015, Volume 1. 234–245. https://doi.org/10.1109/ICSE.2015.44
[51]W.N.VenablesandB.D.Ripley.2002. ModernAppliedStatisticswithS (fourthed.).
Springer, New York. http://www.stats.ox.ac.uk/pub/MASS4 ISBN 0-387-95457-0.
[52]Mitchell Wand and Patrick O’Keefe. 1991. Automatic Dimensional Inference. In
ComputationalLogic-EssaysinHonorofAlanRobinson,Jean-LouisLassezand
Gordon D. Plotkin (Eds.). The MIT Press, 479–483.
[53]JianXiang,JohnKnight,andKevinSullivan. 2015. Real-World TypesandTheir
Application. In Proceedings of the 34th International Conference on Computer
Safety, Reliability, and Security - Volume 9337 (SAFECOMP 2015). Springer-Verlag
New York, Inc., New York, NY, USA, 471–484.
201
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 13:48:24 UTC from IEEE Xplore.  Restrictions apply. 