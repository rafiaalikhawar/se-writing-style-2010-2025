Divide-and-Conquer Approach for Multi-phase
Statistical Migration for Source Code
Anh Tuan Nguyen
Electrical and Computer Engineering Dept.
Iowa State University
Email: anhnt@iastate.eduTung Thanh Nguyen
Computer Science Department
Utah State University
Email: tung.nguyen@usu.eduTien N. Nguyen
Electrical and Computer Engineering Dept.
Iowa State University
Email: tien@iastate.edu
Abstract —Prior research shows that directly applying phrase-
based SMT on lexical tokens to migrate Java to C# produces
much semantically incorrect code. A key limitation is the use of
sequences in phrase-based SMT to model and translate sourcecode with well-formed structures. We propose mppSMT, a divide-
and-conquer technique to address that with novel training and mi-gration algorithms using phrase-based SMT in three phases. First,mppSMT treats a program as a sequence of syntactic units andmaps/translates such sequences in two languages to one another.Second, with a syntax-directed fashion, it deals with the tokens
within syntactic units by encoding them with semantic symbols to
represent their data and token types. This encoding via semanticsymbols helps better migration of API usages. Third, the lexicaltokens corresponding to each sememe are mapped or migrated.
The resulting sequences of tokens are merged together to form
the ﬁnal migrated code. Such divide-and-conquer and syntax-direction strategies enable phrase-based SMT to adapt well tosyntactical structures in source code, thus, improving migrationaccuracy. Our empirical evaluation on several real-world systemsshows that 84.8–97.9% and 70–83% of the migrated methods aresyntactically and semantically correct, respectively. 26.3–51.2%of total migrated methods are exactly matched to the human-
written C# code in the oracle. Compared to Java2CSharp, a rule-
based migration tool, it achieves higher semantic accuracy from6.6–57.7% relatively. Importantly, it does not require manuallabeling for training data or manual deﬁnition of rules.
I. I NTRODUCTION
Software could be originally developed in a language and
then migrated to another for different platform. Nowadays,
there is an increasing need for migrating source code from one
programming language to another [ 45] since the same software
needs to exist in multiple platforms and environments.
Aiming to reduce manual migration effort, we have investi-
gated the use of statistical approaches. In a prior work, we foundthat programming idioms can be captured by statistical language
model [ 34]. That motivated us to explore statistical machine
translation (SMT). SMT is a machine translation paradigm
where translations are generated on the basis of statistical
models whose parameters are derived from the analysis of acorpus in two respective languages [
24]. SMT is successful
in automatic translation among several natural languages. For
example, Google Translate [ 11] and Microsoft Translator [ 29]
are SMT -based and support more than 40 natural languages.
In our prior study [ 33], we have directly applied the phrase-
based SMT model [ 5] on the lexemes of source code to migrate
Java code to C #. A method is considered as a sentence, and
each code token produced by a Java or C #lexer is viewed asa word. The result from that model is quite textually similar tothe correct code (only 11.9–15.8% of the total number of tokensin the resulting code are incorrect). However, a low percentage
(49.5–58.6%) of all resulting methods is syntactically correct,
and that of semantically correct ones is even lower 36.5%.
Examining the results, we found that one of the key reasons
is a mismatch in which phrase-based SMT uses phrases to
migrate source code with well-deﬁned syntactic structures. Sucha model deﬁnes a ﬁxed size of phrases that are used in trainingand translation. However, there are often syntactic structures in aprogram containing longer sequences of lexical tokens. In thosecases, the model migrates the phrases that do not align well withsuch structures, and often produces syntactically incorrect code
because the migrated code tokens in one structure are placed
in another structure. That is, it does not distinguish tokens of
different syntactic units. We experimented with increasing the
size limit for the phrases used in the model. The accuracy did
not improve since it still did not capture the tokens withinsyntactic structures with larger sizes. The training time cost
becomes prohibitively high when the limit reaches 18-20 tokens.
Our research question is centered on whether we could still
use phrase-based SMT on syntactic features of source code,in addition to lexical tokens, to adapt it to the structures in
source code. In this work, we present multi-phase, phrase-based
SMT (mppSMT ), a divide-and-conquer technique to address the
above challenge. Our idea is to take advantage of well-formed
syntactic units to divide-and-conquer in training/migration in asyntax-directed fashion. It is similar in spirit to syntax-directed
editing to improve syntactic correctness in editors. mppSMT
operates on the sequences of syntactic units ﬁrst and then on
the tokens within those units. To support that, we develop
multi-phase training and migration algorithms, each of which
uses phrase-based SMT in three phases to accommodate the
hierachical structures in source code as follows.
In the ﬁrst phase, instead of treating code as a sequence
of lexical tokens, mppSMT extracts from the source code
the syntactic units and considers a program as a sequence of
syntactic structures produced by a depth-ﬁrst traversal over the
program’s abstract syntax tree (AST). Each syntactic structure
is represented by a syntactic symbol, called syntaxeme.F o r
example, for the code fragment ‘if (sc.hasNext()) c = sc.next()’ ,w e
produce the syntaxeme sequence IF OP METHCALL CP EXPR EQ
METHCALL . For training, phrase-based SMT is used to learn
the alignment between the sequences of syntaxemes in Javaand C
#. That is, mppSMT statistically learns the migration
rules for syntactic units in two languages. For example, a Java
2015 30th IEEE/ACM International Conference on Automated Software Engineering
978-1-5090-0025-8/15 $31.00 © 2015 IEEE
DOI 10.1109/ASE.2015.74585
constructor declaration is modeled as a sequence of syntaxemes
asMOD METHOD_NAME ParamList { SuperCall } . The respective
syntaxeme sequence in C #isMOD METHOD_NAME ParamList :
BaseCall { } . Phrase-based SMT is used to align (sub)sequences
to (sub)sequences. In the above sequences, the call to superclass
inside the method’s body in Java will be mapped to the BaseCall
in the method’s declaration in C#.
In the second phase, the lexical tokens within each syntactic
structure in Java (i.e., corresponding to each syntaxeme) and thetokens in their respective structure in C
#are processed. Instead
of directly applying SMT on those tokens, we annotate each
lexical token with its token type and data type. For example,
in‘sc.hasNext()’ , the variable scis encoded by the sequence VAR
[Scanner] since it is a variable of the type Scanner . Those type
annotations are called sememes. For the method call hasNext() ,
we have CALL[Scanner, hasNext, 0, null, boolean] (i.e., its class
name, its name, number of parameters, list of parameters, and
the return type). With explicit data types encoded in sememes,
SMT is used to learn the alignments between the APIs intwo languages, e.g.,
System.err.println in Java is mapped to
Console.Error.WriteLine in C#. The explicit encoding of token
types helps in migrating from one token type to another (e.g.,
a method call in Java to a ﬁeld access in C #). Finally, in the
third phase, the lexical tokens within each of corresponding
sememes in the source and target code are aligned by phrase-
based SMT. Moreover, for the syntactic structures with deep
hierarchical structures and many lexical tokens (e.g., an inner
anonymous class), mppSMT creates special syntaxemes, called
placeholders, translates them independently, and later merges
the sub-results into the ﬁnal result. For migration, the same three
phases are applied: the sequences of syntaxemes are migrated
ﬁrst, the sememes within each syntaxeme are handled next, and
ﬁnally, the lexical tokens within each sememe are processed.
In mppSMT, source code is modeled with three types of seq-
uences: lexeme sequences for lexical tokens, syntaxeme se-
quences for syntactic units, and sememe sequences for semantic
units. Each of the training and migration processes has three
phases in those three types of sequences. With those three
phases in training/migration and the divide-and-conquer strategybased on syntactic units, mppSMT uses phrase-based SMT three
times to adapt to well-formed structures in source code.
We conducted several experiments on nine real-world, open-
source projects to evaluate its accuracy. Our result shows that
mppSMT achieves much higher migration accuracy than phrase-based SMT (syntactically: 18.7–41.7% higher, and semantically:
17.7–40.8% higher). For our current mppSMT, 84.8–97.9% and
70–83% of the total translated methods are syntactically and
semantically correct, respectively .26.3–51.2% of translated
methods are exactly matched to the C #code written by the
developers of the subject projects in the oracle. Compared to
Java2CSharp, a rule-based migration tool, it achieves higher
semantic accuracy from 4.5–28% (6.6–57.7% relatively higher).
We found that mppSMT can automatically learn many API
usage mappings and Java-to-C #syntactic/semantic migration
rules. Importantly, it does not require manually deﬁning of
those mappings/rules as in Java2CSharp and manual labeling
of respective methods. Moreover, the training data of respective
methods can be easily and automatically built from several
open-source projects with available corresponding versions. In
brief, the key contributions in this paper includeTokenizerDecoder (Translator )Source 
language 
textTarget  
language  
text(1) (2)
t* = argmax p(t|s)(3)Language 
model   
p(t)      (4)Translation  
model
p(s|t)
Fig. 1: Phrase-based Statistical Machine Translation (SMT)
1. A divide-and-conquer technique that makes phrase-based
SMT work for source code with hierarchical structures,
2. An empirical evaluation to show that the new model is
efﬁcient and accurate in Java to C# code migration.
II. B ACKGROUND ON PHRASE -BASED SMT
Phrase-based Statistical Machine Translation (SMT) is an
approach that uses statistical learning to derive the translation
“rules” from a training data (called a corpus) and applies the
trained model to translate a sequence from the source language
(LS) to the target one (L T). Figure 1 displays the overview of
phrase-based SMT. The text in the source language LSis broken
into words via the module T okenizer (module 1). The sequence s
of those words is the input of the Decoder module, which plays
the role of translation/decoding (module 2). It searches for the
most relevant sequence tin the target language for s. To do that,
it relies on two models: 1) the language model (module 3),
which learns from the corpus the feasible sequences in the
target language LT, and 2) the translation model (module 4),
which learns from the training data the alignment between
the words/sequences in two languages. Both translation and
language models need to be trained on the corpus, and are then
used by Decoder for translation. Formally, SMT translates a
sequence sin the source language LSinto a sequence tinLTby
searching for the sequence tthat has the maximum probability
P(t|s)=P(t).P(s| t)
P(s)
Since sis given, P(s) is ﬁxed for all potential sequences t. SMT
translates sby searching for the sequence tthat maximizes
P(t).P(s| t). The language model of LT(module 3) is used to
compute P(t), i.e., how likely sequence toccurs in LT. The
translation model (module 4) computes the likelihood P(s| t)
of the mapping pairs from ttos.
IBM Model [ 4] is a popular approach to compute the prob-
ability P(s| t)for all the pairs of sequences s∈LSand t∈LT
in the corpus. It operates on the alignment of individual words.
Given two sequences: s=s1s2...smand t=t1t2...tl, IBM Model
computes P(s| t). Unlike IBM Model, phrase-based SMT [25]
is a model operating on phrases, i.e., sequences of words.I t
extends the word-based SMT model such as IBM Model by
expanding the surrounding words of the aligned words to get
phrase-based alignment. The training process has the followingsteps: 1) the model adds the pairs of words that were aligned bythe word-based alignment model into a phrase translation table,
which contains the mappings of the phrases with different sizes
in two languages with their mapping/translation probabilities;
2) it collects all phrase pairs that are consistent with the word
alignment, i.e., the phrase alignment must contain all alignments
586//−−−− Java code −−−−−−
public ClientQueryResult(T ransaction ta, intinitialSize) {
super(ta, initialSize);
}
//−−−− Correct C# code −−−−
public ClientQueryResult(T ransaction ta, intinitialSize) : base(ta, initialSize) {}
//−−−−− Incorrectly T ranslated by lpSMT −−−−−−
public ClientQueryResult(T ransaction ta, intinitialSize) : base(ta {, initialSize);}
Fig. 2: Call to Constructor super(...) of Parent Class
for all covered words and include at least one word alignment
pair; and 3) it iterates over all target phrases to ﬁnd the
ones closest to source phrases, and then add those pairs and
translation probabilities to the table. Details are in [24].
The Decoder module uses the learned phrase translation table
as well as the trained language model for the target language. It
processes the source sentence sfrom left to right. It considers
breaking sinto multiple phrases in all potential ways, and
searches them in the phrase translation table. With multiple
ways of phrase breaking and each phrase might have multiple
aligned phrases in the table, there are always multiple candidate
sentences in the target language. A probability is given to
each candidate sentence tin the target language based on the
probabilities of the aligned phrases in the sentence according
to the phrase translation table, the number of translated words
ins, as well as the probability P(t)of the sentence taccording
to the language model. The probability for a candidate sentenceis gradually computed in the translation/decoding process. The
sentence with the highest probability is presented.
III. M OTIV A TING EXAMPLES
In our prior model, lpSMT [ 33], we have applied directly
the phrase-based SMT, called Phrasal [5], to migrate Java code
to C#. Many of the resulting methods are incorrect since the
model treats source code as sequences of texts. Let us explain afew examples in our prior study to motivate our new approach.
Example 1. Call to Parent Class’ Constructor super(...).
Figure 2 shows an example in db4o as lpSMT translates a call
to the constructor of a parent class via super (line 3). In Java,
a call to super is made inside the method’s body. In contrast,
in C#, a call to the constructor is made via base and occurs
in the method signature, i.e., prior to the method’s body as in
base(ta,initialSize) (line 6). In the result, this call was broken into
two pieces: one in the method signature ’base(ta’ and one in the
method’s body ’, initialSize);’ (line 8) due to incorrect alignment.
Thus, the translation code is syntactically incorrect. In this case,
lpSMT translates based on the lexeme sequence of the methodsignature and its body, however, does not consider and translate
the call to the superclass super (ta, initialSize) as a whole. We
can see that considering syntactical structures in the translation
process would help. Syntactic structures could be translated
as the entire units and play the roles of the placeholders for a
later translation phase for the code within each placeholder.
Example 2. Semantic Error. Figure 3 shows another example
indb4o . At line 10, the parameter type was incorrectly translated
by lpSMT to DoubleHandlerUpdateT estCase.ItemArrays , instead
of the correct type IntHandlerUpdateT estCase.ItemArrays . This
is due to ItemArrays being aligned by lpSMT with different
sequences in different situations in the corpus (e.g., IntHandlerUp-
dateT estCase.ItemArrays ,DoubleHandlerUpdateT estCase.ItemArrays ).//−−−− Java code −−−−−−−−−−−
private void createT ypedPrimitiveArray ( ItemArrays item ) {
item._typedPrimitiveArray = new int [ data.length ] ;
System.arraycopy (data, 0 , item. _typedPrimitiveArray, ...);}
//−−−−− Correct C# code −−−−−−
private void CreateT ypedPrimitiveArray ( IntHandlerUpdateT estCase.
ItemArrays item ) {
item._typedPrimitiveArray = new int [ data.Length ] ;
System.Array.Copy (data, 0 , item._typedPrimitiveArray, ...);}
//−−−−−− Incorrectly T ranslated by lpSMT −−−−−
private void CreateT ypedPrimitiveArray ( DoubleHandlerUpdateT estCase.
ItemArrays item ) {
item._typedPrimitiveArray = new int [ data.Length ] ;
System.Array.Copy (data, 0 , item._typedPrimitiveArray, ...);}
Fig. 3: Semantic Error: Incorrect Type
The type was incorrectly chosen by lpSMT. However, if
type information was considered at the ﬁrst statement, it
would know that item._typedPrimitiveArray is an array of int,t h u s ,
IntHandlerUpdateT estCase.ItemArrays should be used.
Example 3. Long Phrases. In the dumpKeys method of BT ree-
Assert class in db4o (Figure 5), the second argument of the
method call (line 2) is an instantiation of an anonymous class:
tree.traverseKeys(trans, new Visitor4(){...}); . The phrase-based SMT
with limited phrase sizes did not align correctly such a long
sequence in the second argument because it breaks the sequence
into sub-sequences and places tokens in one syntactic structureinto a different one as in Example 1. That leads to the incorrect
result. Increasing the maximum phrases’ sizes might degrade
performance and alignment accuracy as well. If the entire
sequence ‘ new Visitor4... ’ is viewed as an instantiation, the model
could align/translate an instantiation in Java, which is then
broken further into smaller structures for alignment/migration.
IV . M APPING OF SEQUENCES OF SYNT ACTIC UNITS
We present multi-phase, phrase-based SMT (mppSMT ), a
divide-and-conquer technique to address the above challenges.
The idea is that we take advantage of the syntactic units to break
source code into shorter sequences and run each of training and
migration processes in multiple phases. This section explains
how we encode the syntactic structures in a program, and how
we use SMT to learn the mappings of syntactic structures.
Instead of treating source code as a sequence of lexical
tokens, we encode a source ﬁle with a sequence of special
syntactic symbols, called syntaxemes . We adopt this concept
from our prior work on language model. Syntaxemes are the
basic units of syntax that represent the symbols on the right hand
side of the grammar rules for a language. That is, syntaxemes
represent syntactic units in a program. For example, for thecode
‘while (i < 9) if (i > j) i=i+1 ; ’ , we produce the syntaxeme
sequence WHILE OP EXPR CP IF OP EXPR CP EXPR EQ EXPR
SC. The symbols EXPR s represent the expressions. The other
symbols are for the keywords while ,if, parentheses, the =sign,
and the semicolon. For each syntaxeme, we will handle the
lexical tokens corresponding with it in a later phase.
We parse the code into a parse tree, traverse it to collect the
syntaxemes for syntactic units, and ensemble them to create
the ﬁnal syntaxeme sequence. We choose to stop at the coarse-
grained syntactic structures for efﬁciency, thus, we do notgo further to the content of an expression. For example, the
expressions ‘i<9’ ,‘ i>j ’ , etc. are encoded only with EXPR s.
587T ABLE I: Examples of Java syntax and function encode to produce a sequence of syntaxemes for Java code
Stmt/Decl Java Syntax Building Corresponding Syntaxeme Sequence
MethodDecl Modiﬁers Type Name (ParamList) ThrowDecl Block MOD TYPE ID OP encode(ParamList) CP THROWDECL encode(Block)
ConstructorDecl Modiﬁers Name (ParamList) ThrowDecl Block MOD ID OP encode(ParamList) CP THROWDECL encode(Block)
ParamList {Param}∗P ARAM {COMMA P ARAM}∗or {}
StatementList {Statement}∗{encode(Statement)}∗
Block { StatementList } OB encode(StatementList) CB
If if(Expression) Statement [else Statement] IF OP EXPR CP encode(Statement) [ELSE encode(Statement)]
For for (ForInit ; Expression; ForUpdate) Statement FOR OP INIT SC EXPR SC UPDA TE CP encode(Statement)
While while (Expression) Statement WHILE OP EXPR CP encode(Statement)
Switch switch (Expression) { {CaseSection}[DefSec] } SWITCH OP EXPR CP OB encode(CaseSection) [encode(DefSec)] CB
CaseSection case Expression : StatementList CASE EXPR C encode(StatementList)
Expression StatementExpression ; EXPR SC
V ariableDecl Type Identiﬁer = Expression {, Identiﬁer = Expression } ; TYPE ID EQ EXPR {COMMA ID EQ EXPR} SC
TypeDecl Modiﬁer class Identiﬁer [extends Type] [implements Types] Body MOD CLASS ID [EXTENDS TYPE] [IMPLEMENTS TYPES] encode(Body)
thisCall this ([Expression {, Expression }]) ; THIS OP [EXPR {COMMA EXPR}] CP SC
SuperCall [Expression .] super ([Expression {, Expression }]) ; [EXPR PERIOD] SUPER OP [EXPR {COMMA EXPR}] CP SC
T ABLE II: Examples of C# syntax and function encode to produce a sequence of syntaxemes for C# code
Stmt/Decl C# Syntax Building Corresponding Syntaxeme Sequence
MethodDecl Attributes Modiﬁers Type Name (Params) Block A TT MOD TYPE ID OP P ARA CP encode(Block)
ContructorDecl Attributes Modiﬁers Name (Params) {thisCall|baseCall} Block A TT MOD ID OP P ARA CP {encode(thisCall)|encode(baseCall)} encode(Block)
ParamList {Param}∗P ARAM {COMMA P ARAM}∗or {}
StatementList {Statement}+{encode(Statement)}+
Block { StatementList} OB encode(StatementList) CB
If if(Expression) Statement [else Statement] IF OP EXPR CP encode(Statement) [ELSE encode(Statement)]
For for (ForInit; Expression; ForUpdate) Statement FOR OP INIT SC EXPR SC UPDA TE CP encode(Statement)
While while (Expression) Statement WHILE OP EXPR CP encode(Statement)
Switch switch (Expression) {{CaseSection}+[DefSec]} SWITCH OP EXPR CP OB {encode(CaseSection)}+[encode(DefSec)] CB
CaseSection case Expression : StatementList CASE EXPR C encode(StatementList)
Expression StatementExpression ; EXPR SC
V ariableDecl Type Ident = Expression {, Ident = Expression} ; TYPE ID EQ EXPR {COMMA ID EQ EXPR} SC
ClassDecl Attrs Modiﬁers class Ident ClassBase Body A TTRS MOD CLASS ID CLASSBASE encode(Body)
thisCall :this ( [Expression {, Expression }] ) C THIS OP [EXPR {COMMA EXPR}] CP
baseCall :base ( [Expression {, Expression }] ) C BASE OP [EXPR {COMMA EXPR}] CP
To produce syntaxeme sequences, we follow the encoding
rules for different Java syntactic units. The important encoding
rules are shown in Table I (others are similar). Syntaxemes are
listed as capital letters on the right hand side. Note that, the
code is compiled, thus, we can always produce the parse tree.
We traverse the parse tree to ﬁnd the appropriate encoding rules
and then create and ensemble the sequences of syntaxemes.
All the non-terminal symbols will be expanded further and
syntaxemes are ensembled until we encounter expressions or
no more non-terminal symbols are found. The non-terminal
symbols in the right hand side of Table I that will be expandedare called with the
encode function, which is represented by all
the rules in the table. The resulting syntaxemes at each step
are concatenated to create the larger and then ﬁnal sequences.
For example, for the Java code in Figure 2, we encode that
method declaration using the rules in Table I:
MOD ID OP encode(ParamList) CP OB encode(SuperCall) SC CB
where the capital letters are the terminal symbols for the
separators in the grammar of Java. The modiﬁer public and
the method’s name ClientQueryResult are represented by two
syntaxemes MOD and ID.ParamList and SuperCall are expanded
further via other rules. ParamList is for the parameter list and
is expanded into ‘ P ARAM COMMA P ARAM ’ for ‘ T ransaction ta, int
initialSize ’. We do not explore further a parameter since we will
use sememes to represent it. SuperCall is encoded into ‘ SUPER
OP EXPR COMMA EXPR CP ’. Those syntaxemes are not expanded
further since stop at expressions.
Similarly, for the C# code in Figure 2, we have
MOD ID OP encode(ParamList) CP C encode(BaseCall) OB CB
Fig. 4: Alignments of Syntactic Symbols are Learned from Corpus
where Crefers to the colon and BaseCall refers to the call to
the constructor of a base class in C#.
The rules to syntaxemes for C #are listed in Table II.
The (non-)terminal symbols on the right panel are different
from those for Java even though we use the same notations.
All the words in capital letters in the right side of a table are
collected into the syntaxeme vocabulary for each language.
In the ﬁrst phase of the training process, the syntaxeme
sequence of each method in Java is mapped to the syntaxeme
sequence of the corresponding method in C #. The regular
phrase-based SMT training is used on syntaxeme sequencesfor the ﬁrst phase. The alignment of syntactic symbols are
automatically learned from the corpus of corresponding meth-
5881public static void dumpKeys(T ransaction trans, BT ree tree) {
2 tree.traverseKeys(trans, new Visitor4() {
3 public void visit(Object obj) {
4 System.out.println(obj); ...
5 }
6 public void ...() {...}
7 }); ...
Fig. 5: Placeholder for an Anonymous Class
ods. This is the key difference between our statistical approach
with the deterministic rule-based approaches in which users
must deﬁne the mappings among syntactic structures in two
languages. In our approach, the mappings are learned from the
alignments of syntactic symbols. For example, in Figure 4,
for the corresponding methods in Java and C #, mppSMT
uses phrase-based SMT to align the corresponding syntaxeme
sequences. As seen, the alignment of syntaxemes enables
mppSMT to recognize the mapping of SuperCall toBaseCall and
the change to their locations from the method’s body in Java
to the method’s declaration in C#.
Divide-and-Conquer with Placeholders. Let us revisit the
example 3 (Figure 5). At lines 2-7, the second argument of a
method call is an entire class declaration, which is expanded into
ﬁeld and method declarations, etc. SMT breaks the sequence
into sub-sequences and misplaces tokens in a syntactic structure
into a different one, leading to incorrect results.
To address that, we create special syntaxemes, called
placeholders, for long expressions such as anonymous class
declarations, cascading and nested expressions in method calls,
inner classes, etc. Our implementation uses the same length
limit for long sequences as the underlying SMT tool, Phrasal (16
symbols). Each placeholder represents a long expression. The
boundary of a placeholder is marked in the syntaxeme sequence.
A placeholder is associated with a sequence of syntaxemes for
its contents. Syntaxemes in placeholders are used in training as
normal, however, during decoding, placeholders are translated
independently and the results are merged into the ﬁnal result
(Section VI-C ). With placeholders, mppSMT not only makes
the phrase-based SMT work for hierarchical structures of
expressions in code, but also achieves a divide-and-conquerstrategy in translation since it operates on shorter sequences.
The computational complexity of the translation of a sequence
will be reduced since it is exponential to the sequence’s length.
V. M APPINGS OF TOKEN TYPES AND DATA TYPES
In the second phase, the lexical tokens within each syntactic
structure corresponding to each syntaxeme in Java and thetokens in their respective syntaxeme in C
#are processed.
Instead of directly applying SMT on lexical tokens, we annotate
each lexical token with its token type and data type. Eachcode token has a role in a program according to the writtenprogramming language, e.g., whether it is a type, variable,
literal, operator , keyword, method call, method declaration,
ﬁeld,o rclass. For example, in ‘list.empty()’ , the variable listis
encoded by the sequence VAR [ArrayList] since it is a variable of
LinkedList . Such sequence of data/token types is called a sememe
sequence. We adopted the concept of sememe from our prior
work [ 34]. The sememe of a code token at a code location is a
structured annotation representing its data/token types [34].T ABLE III: Examples of Sememes [34]
Token Token →Sememe
Data type ArrayList →TYPE[ArrayList]
V ariable fwriter→V AR[FileWriter]
Literal “ASE 2015” →LIT[String]
MethDecl subString →FUNC[String,subString,TYPE [int]
P ARA[int], String]
MethCall exists→CALL[File,exists,0,null,boolean]
Parameter endIndex →P ARA[endIndex,int]
FieldAcc modCount →FIELD[ArrayList,modCount]
Operator >→OP[greater], . →OP[access]
The type information in API method calls is captured as
well. This helps mppSMT to learn the API usage mappings from
sememe alignments, e.g., System.err.println in Java is mapped to
Console.Error.WriteLine in C#. Moreover, different method calls
with the same lexical value in different classes will not be
mapped. This helps mppSMT to overcome a key limitation
in lpSMT, which works on the lexical values of such method
calls and cannot distinguish those cases.
Table III shows the examples of popular types of sememes.
For example, in Java, File.exists() is a function call and its
sememe consists of the symbols ‘ CALL ’, ‘[’, its class name File,
its name exists , no parameter, the return type boolean , and ’]’.
Let us take an example of different styles in Java and C #. A pair
of method calls becomes two ﬁeld accesses and an assignment:
current.getEdge().setMarked(true) →current.edge.marked = true . The
Java sememe sequence
VARREF[Rectangle] CALL [Rectangle,getEdge,0,null,Edge] CALL [Edge,
setMarked,1,boolean,void] becomes
VARREF[Rectangle] FIELD [Rectangle, edge] FIELD [Edge, marked]
ASSIGN LIT[boolean] in C#.
For the example in Figure 4, for the ﬁrst syntaxeme P ARAM ,
we have the sememe sequence P ARA [ta,T ransaction] . The lexeme
of this sememe is ta. The separators, e.g., semicolons and
parentheses, and keywords are not associated with semantic
information, thus are marked with special sememe types that
are the same as their syntaxemes at the syntactic level. If
semantic information is not available, the lexical token is kept
and annotated with the special sememe LEX . The sememe for
a variable and that for a literal do not include their lexemes
since they are handled at the lexical level.
VI. T RAINING AND TRANSLA TION
A.Auto-Labeling of Respective Methods to Build Training Data
In code migration, building training data is the process of
collecting respective pieces of code with equivalent functionality
in both languages. In theory, one can label pairs of respective
pieces of code in Java and C #to train mppSMT. However, to
automatically collect a large number of respective pieces of
code, in this work, we focus on migrating each Java method toan C
#method, thus we need to build the collection of pairs of
respective methods. To do that, we ﬁrst used nine open-source
systems which were originally developed for Java and then
ported to C #(Table IV). They are well-established systems with
long developing histories and both Java and C #versions have
been in use. The projects db4o ,fpml ,Lucene , and Neodatis have
also been used in prior research in mining migration rules [ 49].
589T ABLE IV: Subject Systems
Project Java C# M.Meth
V er File Meth V er File Meth
Antlr [2] 3.5.0 226 3,303 3.5.0 223 2,718 1,380
db4o [8] 7.2 1,771 11,379 7.2 1,302 10,930 8,377
fpml [10] 1.7 138 1,347 1.7 140 1,342 506
Itext [17] 5.3.5 500 6,185 5.3.5 462 3,592 2,979
JGit [21] 2.3 1,008 9,411 2.3 1,078 9,494 6,010
JTS [23] 1.13 449 3,673 1.13 422 2,812 2,010
Lucene (LC) [26] 2.4.0 526 5,007 2.4.0 540 6,331 4,515
Neodatis (ND) [31] 1.9.6 950 6,516 1.9b-6 946 7,438 4,399
POI [39] 3.8.0 880 8,646 1.2.5 962 5,912 4,452
Columns Java.Ver and C#.Ver show the corresponding versions
in two languages. Columns File and Meth show the numbers of
ﬁles and methods in each revision.
To collect respective methods in each pair of corresponding
versions, we observe that in those manually migrated projects,
developers keep the same/similar directory structures, and the
same/similar names for classes and methods between Java
and C #(some have slightly different names regarding case-
sensitivity). Thus, we built a tool to conservatively search for
only the methods having the same signatures in the classes withthe same/similar names in the same/similar directory structures
in both versions. Such pairs of methods likely implement the
same functionality. Because in a project, the corresponding
versions also include different supporting libraries and utility
methods in two languages, and/or contain extra or less function-
ality, there are methods in both versions that do not have the
respective ones. Thus, we manually veriﬁed a small, randomly
selected sample set to have high conﬁdence that the methodpairs are in fact the respective ones. One-to-many mappings
were discarded. In total, we found 34,628 respective methods
(column M.Meth ). We used them as a training data set.
B. Multi-phase Training Algorithm
The training algorithm is shown in T rainingAlgo (Figure 6).
It consists of 3 phases at the three levels: syntaxemes, sememes,
and lexemes. At each level, it provides training for both
language and translation models. The input of the training step
is a collection of method pairs M, each of which contains a
method in Java and its respective migrated method in C #. From
the aligned methods, mppSMT learns the alignments between
(sub-)sequences of syntaxemes, sememes, and lexemes.
1)Phase 1. Alignment for Syntactic Structures via
Syntaxeme Sequences :The goal of this phase is to use phrase-
based SMT on the syntaxeme sequences to learn the alignments
between sub-sequences of syntaxemes in two languages.
First, for each method pair (j,c)∈M, mppSMT builds the
syntaxeme sequences for both methods jand cin two languages
and then collects those pairs into SynPairs (lines 3-5). Then, it
uses phrase-based alignment (Section II) to map the syntaxemesequences for each pair in
SynPairs (line 7). Next, it uses SMT
to train the translation model (line 8) for syntaxeme sequences.
The result TSyn is the phrase translation table for syntaxeme
sequences in two languages. The syntaxeme sequences in C #
are used to train the n-gram language model LSyn for syntaxemes
(line 9). The functions on lines 7–9 are from phrase-based SMT.
For example, in Figure 4, two syntaxeme sequences in Java1function T rainingAlgo (T rainingMethodPairs M)
2 //−−−−−−−T raining the model for syntaxeme sequences−−−−−−−−−−
3 SynPairs ={}
4 foreach pair (j,c)∈M// for each pair of methods (j,c)
5 SynPairs.add(encode( j),encode(c)) //collect pairs of syntaxeme seqs for (j,c)
6
7 MapSyn = AlignSMT(SynPairs) //align syntaxemes in each pair
8 TSyn= T ranslationT rainSMT(MapSyn, SynPairs) //translation model
9 LSyn= LangModelT rainSMT(SynPairs. CSsequences) //language model
10 //−−−−−−−T raining the model for sememe sequences−−−−−−−−−−−
11 SemPairs ={}
12 foreach pair (j,c)∈M
13 SemPairs.add(Sem( j), Sem(c))
14 foreach aligned pair (syn j,syn c)∈MapSyn( j,c)
15 SemPairs.add(Sem(syn j), Sem(syn c))
16 MapSem = AlignSMT(SemPairs)
17 TSem= T ranslationT rainSMT(MapSem, SemPairs)
18 LSem= LangModelT rainSMT(SemPairs. CSsequences)
19 //−−−−−−− T raining the model for lexeme sequences−−−−−−−−−−−−
20 LexPairs ={}
21 foreach pair (j,c)∈M
22 LexPairs .add(Lex( j), Lex(c))
23 foreach aligned pair (sem j,sem c)∈MapSem( j,c)
24 LexPairs .add(Lex(sem j), Lex(sem c))
25 MapLex = AlignSMT(LexPairs )
26 TLex= T ranslationT rainSMT(MapLex ,LexPairs )
27 LLex= LangModelT rainSMT(LexPairs .CSsequences)
2829 return T
Syn,LSyn,TSem,LSem,TLex,LLex
30 //−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
31function T ranslationAlgo (JavaCode j)
32 out={}, syn j= encode( j)
33 [syn c,Align(syn c)]= SMTtranslate(syn j,TSyn,LSyn)
34 foreach sequence syn c
35 syn j=Align(syn c)// syntaxeme sequence syn_j is aligned to syn_c
36 PMap(syn j)= GetPlaceholders(syn j)// checking for long exprs
37 //replace code with placeholders PHExprs if any
38 Replace(syn j.Code, PMap(syn j).Code, PHExprs)
3940 [sem
c,Align(sem c)]= SMTtranslate(Sem(syn j),TSem,LSem)
41 foreach sememe sequence sem c
42 sem j=Align(sem c)// sem_j is aligned to sem_c
43 lex c= SMTtranslate(Lex(sem j),TLex,LLex)
44 out.add(lex c)
45 // translate the code in placeholders
46 PMap(syn c).Code = T ranslationAlgo(PMap(syn j).Code)
47 Replace(out ,PHExprs, PMap(syn c).Code) //merge results back
48 return out
Fig. 6: Training and Translation Algorithms
and C #are mapped using phrase-based alignment in SMT. The
ﬁrst result of this phase, TSyn, includes
[MOD↔#MOD], [ID ↔#ID], [OP ↔#OP], [P ARAM ↔#P ARAM], ...,
[SUPER OP EXPR COMMA EXPR CP ↔base#OP#EXPR COMMA
#EXPR#CP#CP],
[OB SUPER OP ... CP SC CB ↔#C BASE#OP#...#CP#OB#CB],...
(Each syntaxeme sequence mapping has its score, not shown).
2)Phase 2. Alignment for Sememes within Each Syn-
taxeme :The goal of the second phase is to train the model
to recognize the alignment of the sememes extracted from the
code within each corresponding syntaxeme phrase (syntactic
structures) that were aligned in the ﬁrst phase. The process is
the same as in the ﬁrst phase except that the phrase-based SMT
is called on sememe sequences (lines 16–18). The result is
P ARAM [ta,T ransaction] ↔#P ARAM [#ta,#T ransaction] ,
P ARAM [initialSize,int] ↔#P ARAM [#initialSize,#int],
[CALL[ClientObject,constructor,2,[T ransaction,int],ClientObject] ↔
CALL[#ClientObject,constructor,2,[#T ransaction, int],#ClientObject],...
3)Phase 3. Alignment for Lexemes within Each Se-
meme :In the last phase, the lexical tokens for each sememe
590phrase aligned from the previous phase is mapped. The
procedure is the same as before. For example, we will have
[public↔public], [ClientQueryResult ↔ClientQueryResult], [ ( ↔(],
[super↔base], [T ransaction ta ↔T ransaction ta] , ...
C. Multi-phase Translation Algorithm
Our multi-phase translation algorithm ﬁrst translates syn-
taxeme sequences, then translates the sememes within thosesyntaxemes, and ﬁnally merges the respective sequences of
lexemes in those sememes to produce the ﬁnal result.
Details. The translation algorithm for a Java code fragment
jis at line 31 of Figure 6. It ﬁrst builds for ja sequence
of syntaxemes syn j. Then, SMT with the trained language
model Lsyn for C#and the trained translation model Tsyn at the
syntactic level are applied on syn jto produce the translated
syntaxeme sequence with highest probability consisting of mul-
tiple, non-overlapping sub-sequences syn c, and the alignment
Align for those syntaxeme sub-sequences (line 33). For each
of those syntaxeme sequences syn cin C#, it uses Align(syn c)
to ﬁnd the corresponding syntaxeme sequence in Java syn j
(line 35). It then checks if syn jand corresponding lexical code
contains any long expressions via GetPlaceholders (line 36). If
so, it will replace the long expressions in the code with special
syntaxemes/placeholders PHExpr ’s (line 38). PMap contains the
mappings between placeholders and their code.
mppSMT then builds the sememes for the resulting syntax-
eme sequence syn j, and translates it with SMT (line 40) into
the C#sememe sequence with highest probability consisting of
multiple, non-overlapping sub-sequences sem c(with the align-
ment Align(sem c)for those sememe sub-sequences). For each
of those sememe sequences sem cin C#, it uses Align(sem c)to
ﬁnd the corresponding sememe sequence sem jin Java (line 42).
It then uses SMT to translate the lexeme sequences associated
with sem j(line 43) to get the lexeme sequence lex cin C#
and add it into the output (line 44). Finally, the code for the
placeholders PHExprs is translated independently (line 46) and
the results are merged back to form the ﬁnal result (line 47).
Example. Let us revisit our example in Figure 4. Given the
Java code, mppSMT ﬁrst builds the syntaxeme sequence as
shown in Figure 4: MOD ID OP P ARAM COMMA P ARAM CP OB
SUPER OP EXPR COMMA EXPR CP SC CB . Using the phrase
translation table for syntaxemes, mppSMT then translates it
into the syntaxeme sequence in C #as shown in Figure 4:
MOD ID OP P ARAM COMMA P ARAM CP COLON BASE OP EXPR
COMMA EXPR CP OB CB . In the second phase, the lexical tokens
within each syntaxeme, e.g., P ARAM , is processed. For example,
the tokens in P ARAM (i.e., T ransaction ta ) are encoded into the
sememe sequence P ARA[ta,T ransaction] . Then, mppSMT uses the
phrase translation table for sememe sequences to translate itinto
P ARA[ta,T ransaction] in C#. A similar process is applied
for other sememes in other syntaxemes. In the third phase,the tokens for the sememes are translated using the phrasetranslation table for lexemes. For example,
taand T ransaction
are migrated into taand T ransaction in C#. The lexical token
super is migrated into base since SUPER is mapped to BASE .
VII. E MPIRICAL EV ALUA TION
In our evaluation, we aim to answer the following questions:RQ1.
how accurate is mppSMT in comparison to the lexical
SMT and Java2CSharp [20], a rule-based migration tool?RQ2. how accurate is it with cross-project training data?
RQ3. how time efﬁcient is mppSMT?
RQ4. how accurate is it in migrating changes?
We used the dataset shown in Table IV. We applied ten-fold
cross validation by dividing all aligned methods into ten folds
with equal numbers of methods. To test for a fold, we used
the remaining folds for training. The resulting methods were
compared against the respective ones in the oracle. We used
four metrics: the ﬁrst two measure lexical translation accuracy
while the last two measure syntactic and semantic accuracy.
1.BLEU [38]: BLEU is a popular NLP metric from 0–1 to
measure the translation accuracy for the phrases with various
lengths. Speciﬁcally, BLEU =BP.e1
n(log P1+...+log Pn)where BP is
the brevity penalty value, which equals 1 if the total lengthof the resulting sentences is longer than that of the refer-
ence sentences (i.e., the correct ones). Otherwise, it equals
to the ratio between the two lengths.
Piis the metric for the
overlapping between the bag of i-grams (repeating items are
allowed) appearing in the resulting sentences and that of i-grams
appearing in the reference sentences. Speciﬁcally, if Si
re fand
Si
trans are the bags of i-grams appearing in the reference code
and in the translated code respectively, Pi=|Si
re f∩Si
trans |/|Si
trans |.
2.Token edit distance ratio ( EDR ). This metric measures
effort that a user must edit in term of the code tokensthat need to be deleted/added in order to transform theresulting code into the correct one. It is computed as:
EDR
=∑methods EditDistance(s R,sT)
∑methods length(s T), where EditDistance(s R,sT)is the
editing distance between each pair of the reference method sR
and the translated method sT; and the denominator is the total
length of all translated methods.
3.Syntactic correctness ratio ( SCR ). Syntactic correctness
is measured by the ratio between the number of translated
methods that compile over the total translated methods.
4.Semantic correctness ratio ( SeCR ). Semantic correct-
ness is deﬁned as the ratio between the number of semanticallycorrect translated methods over the total translated methods. If
SeCR is 80%, 80 out of 100 translated methods are semantically
correct. To check semantic correctness, we compare the program
dependence graph (PDG) for each translated method against
the PDG of the respective reference method in the oracle. To
compare the PDGs, we applied the technique from [16].
A. Accuracy and Comparison
Our ﬁrst experiment aims to measure mppSMT’s accuracy
and compare it with lpSMT [ 33] (SMT running on lexical
tokens) and Java2CSharp [ 20], a rule-based code migration
tool. As seen in Table V, mppSMT achieves good translation
accuracy. 84.8–97.9% and 70-83% of the total numbers of
translated methods are syntactically and semantically correct,
respectively. Among all total translated methods, there are 26.3–
51.2% that are exactly matched to the C #code written by
the developers of the subject projects in the oracle (Table VI).
We examined the migrated results that are syntactically and
semantically correct but differ from the manual-migrated code
in the oracle. We found that they involve 1) code with different
local variables’ names from a reference method, but all variables
are consistently renamed; 2) code with namespaces being
591T ABLE V: Accuracy Comparison (max/min values highlighted)
Proj. BLEU % SCR% (syntax) SeCR% (semantic)
mpp mpp mpp
J2C# lpSMT SMT J2C# lpSMT SMT J2C# lpSMT SMT
Antlr 86.6 83.6 95.5 100 43.6 85.3 57.6 29.2 70.0
db4o 82.3 89.9 93.6 100 72.2 97.9 47.6 57.4 75.1
fpml 72.3 81.2 82.4 100 58.7 85.2 67.6 50.4 72.1
Itext 72.6 81.8 90.1 100 61.3 84.8 60.5 44.6 75.9
JGit 72.1 89.1 93.5 100 69.7 91.0 49.8 54.9 77.8
JTS 69.5 80.2 82.6 100 61.6 88.6 66.9 42.9 73.4
LC 77.9 80.8 89.2 100 52.3 88.4 61.4 42.5 76.3
ND 71.3 83.3 88.4 100 72.1 95.4 73.6 59.4 83.0
POI 72.4 82.9 88.4 100 71.5 90.2 56.4 50.4 72.7
T ABLE VI: %Results Exact-matched to Human-Written C#
Project Antlr db4o fpml Itext JGit JTS LC ND POI
J2C# 10.0 21.5 22.7 25.1 10.7 11.7 21.5 15.6 18.9
lpSMT 11.5 37.1 34.6 24.4 23.0 18.5 21.6 36.8 34.6
mppSMT 49.1 51.2 46.3 40.6 48.5 26.3 40.0 44.3 48.2
added/ deleted to/from a type (e.g., new P .A() vsnew A() ); and 3)
code with ‘ this’ being added/deleted to/from a ﬁeld or method.
Regarding EDR, only 3.7–14% of the total number of tokens
in the resulting code are incorrect (not shown).
Compared to the lexical model, lpSMT, mppSMT improves
much in both syntactic (18.7–41.7 %) and semantic correctness
(17.7–40.8% ). We found that all the syntactically and semanti-
cally correct methods translated by lpSMT are also included
in the correct ones translated by mppSMT. mppSMT migrates
correctly many additional methods that lpSMT did not migrate
correctly. To further learn the impact of the divide-and-conquerapproach via syntactic structures, we added only the syntaxeme
and lexeme processing into lpSMT and left the sememesout. We found that syntactic correctness is much improved
with syntaxemes from 11–40% (relatively from 15.4–91.5%).
Investigating further, we found that our divide-and-conquer
approach with syntaxemes creates syntax-directed translation,
which helps to align/translate syntactic units as their entireties.
Moreover, mppSMT achieves better lexeme alignments for
longer phrases since the alignments of syntaxemes place correct
pivots on lexeme sequences for later aligning.
Compared to Java2CSharp, despite 2.1–15.2% less in
syntactic correctness, mppSMT has 4.5–28% higher semantic
accuracy than Java2CSharp (relatively 6.6–57.7% ), thus is more
accurate. Since Java2CSharp has the syntactic templates for
migration, the resulting code is syntactically correct. However,
many methods migrated by Java2CSharp are not semantically
correct due to 1) incorrect concrete names since rules are just
templates, and 2) the lack of rules for API mappings for libraries.Moreover, only 10–25% of the migrated methods exactly match
the reference code (as opposed to 26.3–51.2% for mppSMT).
Table VII shows some examples of API mappings and migration
rules that are mined and used in translation by mppSMT. They
are not in the latest version of the data ﬁle in Java2CSharp.
Unlike in Java2CSharp which requires manual rule deﬁni-
tion, mppSMT can operate well with our training data (34,628methods in 9 projects) that was easily and automatically built viaT ABLE VII: API Mappings and Other Migration Rules
Java C#
Corresponding API Usages
InterruptedException OperationCanceledException
assertEquals(1, NUnit.Framework.Assert.AreEqual
result.getUpdatedFiles().size()) (1,result.GetUpdatedFiles().Count)
XmlUtility.getDefaultSchemaSet() XmlUtility.DefaultSchemaSet
.getSchema() .XmlSchemaSet.Compile()
HtmlTags.UL.equalsIgnoreCase(tag) Util.EqualsIgnoreCase(HtmlTags.UL, tag)
en1.getIn1().compareToIgnoreCase Util.CompareToIgnoreCase
(en2.getIn1()) (en1.GetIn1(), en2.GetIn1())
assertTrue(“...", msg instanceof Assert.IsTrue(msg is Grammar-
GrammarUnreachableAltsMessage) UnreachableAltsMessage,“...")
Double.parseDouble(toToken(n)) double.Parse(n.InnerText.Trim())
Migration Rules for Styles
current.getEdge().setMarked(true) current.Edge.Marked = true
tokens.put(tokenID, Utils. _tokens[token.Key] =
integer(root.getNewTokenType())) root.GetNewTokenType()
copy.setFirstLineIndent(getFirstLineIndent()) copy.FirstLineIndent=FirstLineIndent
extent.get(n) extent.ContainsKey (n)? extent[n]:null
compareTo(other.toDateTime()) CompareTo(other as Time)
(Node)nodes.elementAt(index) nodes[index] as XmlNode
BigDecimal fraction = seconds. decimal fraction =
remainder(BigDecimal.ONE) seconds%1m
nodeIndex.getDocument(). nodeIndex.Document.
getDocumentElement(). DocumentElement.
getNamespaceURI() NamespaceURI
eot.set(s.stateNumber, Utils. _eot[s.StateNumber] =
integer(edge.target.stateNumber)) edge.Target.StateNumber
T ABLE VIII: Accuracy with Cross-Project Training
mppSMT BLEU EDR SCR (syntax) SeCR (semantic)
Within-proj 82.6% 13.0% 88.6% 73.4%
Cross-proj 82.8% 13.7% 90.1% 74.7%
auto-labeling of respective methods in two respective versions.
Java2CSharp requires pre-deﬁned rules, while mppSMT needs
data. Importantly, with small effort to build such training data inmppSMT, we achieve relatively better semantic accuracy from
6.6–57.7% than Java2CSharp. Moreover, we found that some
correct Java2CSharp’s results were not in those of mppSMT.
The reason is that mppSMT did not see them in training data.
This is the limitation of the data-oriented approach in mppSMT.
This result suggests a direction to combine two approaches.
B. Cross-Project Training and Translation
We used JTS project in another experiment to study
mppSMT’s accuracy as it was trained with data across projects.
To translate for one project, we used for training all the data
from the other 8 projects. Table VIII shows the result. The rows
Within-proj and Cross-proj show translation accuracy as mppSMT
was trained with data within JTS and with data across projects,
respectively. As seen, the accuracy in cross-project setting is
slightly better due to additional training data.
C. Time Complexity
We measured training and translation time (see Tables IX-
X) on a computer with AMD Phenom II X4 965 3.0GHz,
8GB RAM, and Linux Mint. As seen, training time for
mppSMT is comparable to that of lpSMT: from 46 minutes
for a small project ( fpml ) to 144 minutes for a larger one
(JGit ). Generally, lpSMT took longest translation time. mppSMT
saved much of that time cost due to its divide-and-conquer
strategy. Java2Csharp’s translation time is comparable to that
of mppSMT and is mostly for AST operations.
592T ABLE IX: Training Time (in minutes per project)
Project Antlr db4o fpml Itext JGit JTS LC ND POI
lpSMT 113 140 48 62 151 77 111 52 111
mppSMT 123 120 46 69 144 95 112 70 120
T ABLE X: Translation Time (in seconds per method)
Project Antlr db4o fpml Itext JGit JTS LC ND POI
lpSMT 0.58 0.15 0.38 0.32 0.25 0.33 0.28 0.12 0.29
mppSMT 0.43 0.12 0.28 0.20 0.18 0.22 0.21 0.09 0.22
J2C# 0.21 0.2 0.28 0.28 0.34 0.12 0.20 0.16 0.21
D.Migrating Changes and Updating Phrase Translation Table
As software evolves in its Java version, the respective C #
version needs to be updated accordingly. In practice, developers
migrate certain important versions to C #. For example, in ZXing
project [ 50], its developers manually migrated a total of 147
versions (between the revisions 2,103 and 2,900 in Java). Since
the number of changed methods is often much smaller than the
total number of methods in a project, it makes sense to help
developers in the synchronization process by migrating only
the changed methods, rather than completely re-migrating. We
conducted another experiment to study mppSMT’s capability
of updating its internal data with new mappings when training
on the newly available respective Java and C# code.
We chose ZXing [50], a project that has been developed
originally in Java and ported to C #inZXing.Net over time
in its history [ 51]. Table XI shows the LOCs, the number
of methods at the ending revisions, and the corresponding
starting and ending revisions in our experiment. To detect the
corresponding revisions, we searched on its C #commit logs
for the terms such as “port” and “migrate” and then manually
veriﬁed them. There are Java revisions that were not ported to
C#. The changes from those revisions are accumulated into the
ΔJichange from the latest Java revision that was being ported
to the next ported one. Sometimes, the porting for one Java
version lasted a few revisions in C #. We chose the last revision
among them as the mapped revision of the Java one, but we
also accumulated the changed methods in those intermediate
C#revisions into ΔCjchange from the latest ported C #revision
to the next ported one. In total, we have 147 mapped revisions.
We used our dataset in Table IV for training. Assume that
the revision Jiis mapped to Ciand J(i+1) toC(i+1) . The ﬁrst pair
J0and C0is used for training. We used mppSMT to migrate the
changed methods in ΔJ(i+1) . We then compared the resulting
methods against the changed methods in the actual one ΔC(i+1)
from CitoC(i+1) . We have two settings in our experiment. In the
ﬁrst one, after migrating ΔJ(i+1) , the translation table learned
from the prior mapped revision was kept without updating. In
the second setting, we updated it using the actual changes in
ΔC(i+1) byZXing ’s developers.
As seen in Table XII, the accuracy for migration of changes
is comparable to that in regular migration. The result with
updating is slightly better than that without updating. We found
that it updated the translation table with new APIs that were
used in a later version and were not in the previous version. This
suggests a practice of migration: after the ﬁrst migration, oneT ABLE XI: ZXing and ZXing.Net
ZXing ZXing.Net
LOCs Meths Revs LOCs Meths Revs Syn.Revs
29,745 1,958 2,103–2,900 43,753 1,848 72,597–87,300 147
T ABLE XII: Accuracy with Updated Phrase Translation Table
mppSMT SCR (syntax) SeCR (semantic) BLEU EDR
Without update 87.4 69.4 89.8 12.1
With update 89.6 72.5 92.2 10.6
just migrates the changed methods, instead of re-migrating the
entire project. Then, after developers ﬁx the automatic migrated
code, one could use the new Java version and the corrected
C#version to update mppSMT. With the updated translation
table, mppSMT translates better for the later versions.
E. Web-Based Survey
We also created a web-based survey and asked human
subjects who are ISU Software Engineering students and have
experience in both Java and C #for more than 2 years to
evaluate the resulting code. We had a total of 40 respondents.
For training, each subject was shown an example of an
original Java method in one subject project. We then pre-
selected the correct answer (based on the human-translatedoracle) for the method and explained why it is “correct”,
“a good starting point”, or “incorrect”. “Correct” means that
this translated code can be used as-is. “Good starting point”
means that it might need reasonable amount of modiﬁcations.
“Incorrect” means that the code is totally incorrect and useless.
Next, they were shown a different original Java method
and the corresponding translated method in C #from mppSMT.
We asked them to give a rating for the result on whether it is
correct, incorrect, or is a good starting point. They also have an
option of “not sure”. Each participant graded 10 methods. We
randomly choose the methods with different sizes in 9 subject
projects. We also asked them to provide an overall rating on
whether our translated code is useful for those 10 methods. In
total, we have the ratings for 400 translated methods and 40
overall ratings. The following table summarizes the responses.
Correct Good Starting Point Incorrect Not Sure Total
77.25% 11% 11.5% 0.25% 400
Agree+ Agree No Opinion Disagree Disagree+ Total
47.5% 37.5% 5% 7.5% 2.5% 40
Overall, the participants found that 77% of the trans-
lated methods are correct and 11% of them are not correct but
are good starting points. They rated mppSMT as useful for
85% of the translated methods.
F . Examples
1. A constructor call in method signature in C#. Translating
LegacyActivationDepth.java indb4o , mppSMT correctly puts the
call to a constructor, this(...) , to the method signature in C#:
593public LegacyActivationDepth(..){this(..,Act...Mode.ACTIVA TE); }
public LegacyActivationDepth(..) : this(..,Act...Mode.Activate) {}
We found that mppSMT is able to learn that via its alignment
of the corresponding syntaxemes in two languages.
2. Type and Keyword. InSimpleMapCache.java inLucene project,
mppSMT learned the mappings between respective types ( Set
and ICollection ), and keywords ( synchronized and lock ):
public Set keySet() { synchronized (mutex) {return ...;}} (Java)
public ICollection keySet() { lock (mutex) {return ...;}} (C#)
3. ‘foreach’. InBufferSubgraph.java inJTS project, mppSMT cor-
rectly translated a forloop with Iterator into a foreach in C#:
public void ﬁndResultEdges() {
for (Iterator it = dirEdgeList.iterator(); it.hasNext();) {
DirectedEdge de = (DirectedEdge) it.next ();...(Java)
public void FindResultEdges() {
foreach (DirectedEdge de in _dirEdgeList) {...}(C#)
Threats to Validity. Our collected dataset might not be
representative. To verify semantic correctness, the approach
in [ 16] may cause inaccuracy in our result. We used the latest
rules and mappings in Java2CSharp. Different rule sets and
project data could have different results. However, we only
want to show that our training data by auto-labeling helps
us get better accuracy, yet was easy to build. We chose only
Java2CSharp for comparison since it is open-source and we can
access its latest library mappings. Our experiment on change
synchronization was on only one project.
VIII. R ELA TED WORK
Language Migration. Spice [ 48] translates Smalltalk to C
by creating runtime replacement classes realizing the same func-
tionality of Smalltalk classes. V an Duersen and Kuipers [ 43]
proposed a method to identify objects by semi-automatically
restructuring legacy data structures. This can be used inmigrating from a structural language into an OO one. Other
tools use wrappers [ 3] or language-independent representations
and deterministic rules [ 44], [30], [13], [40], [9], [18], [46],
[36], [22]. MAM [ 49] mines API mappings via Transforma-
tion Graphs. Our prior work, StaMiner [ 32], used statistical
learning to mine API mappings. The resulting mappings are
used to enhance the rule-based migration tool Java2CSharp [ 20].
Sudoh et al. [41] proposed a method that separately translates
clauses in the source sentence and reconstructs the target
sentence using the clause translations with non-terminals.
API Migration. As software is ported to use a new library,
developers have to migrate their code. To mine API migration
rules, AURA [ 45] combines call dependency and text similarity
analysis to identify change rules for one-replaced-by-many
and many-replaced-by-one methods. HiMa [ 28] matches each
revision pair of a framework and aggregates revision-level rulesto obtain framework-evolution rules. Twinning [
35] allows users
to specify changes that migrate a program to use new APIs.
There are approaches to support adaptation to client code as
libraries evolve [ 6], [7], [14]. SemDiff [ 7] mines API usage
changes from client code or the library itself. Diff-CatchUp [ 47]recognizes API changes and suggests API replacements based
on framework examples. Generalized transformation rules are
inferred from examples [ 42]. SmPL [ 1], [37] is a domain-spe-
ciﬁc transformation language for a semantic change description.
Statistical Language Models. Hindle et al. [15] used n-
gram [ 27] with lexical tokens to show that source code has high
repetitiveness. Han et al. [12] used Hidden Markov Model to
infer the next token from user-provided abbreviations. n-gram
is also used to ﬁnd code templates relevant to current task [ 19].
IX. L IMIT A TIONS ,F UTURE WORK ,AND CONCLUSIONS
Limitations. First, mppSMT currently supports migrating one
Java method to a C #method with only limited semantic
information. For example, in C #, if a method allows an
overriding one in a sub-class, it must be declared as virtual .I n
training data, mppSMT cannot learn when to add virtual since it
does not consider dependencies across methods. We will expand
to migrate an entire project with all classes when considering
semantic dependencies among methods/classes. mppSMT can-
not handle the cases where the new implementation in C #has
quite different logic than the Java version or when a method is
splitted into two. Moreover, if an API is mapped to multiple
APIs in subclasses of a class, it sometimes used an incorrect
one. This weakness was also reported by a human subject:
“incorrect cases were ones where an interface had multiple
implementations and the tool used incorrect implementation
(e.g., class A instead of class B) or inconsistent use of classes
(e.g., the variable would be declared of class A but initialized
using class B). ” Post-processing with type information stored
in sememes could help. Another issue is out-of-vocabulary,
where it has not seen tokens in a training data. To address
that, besides adding more training data, we will explore the
combination with pre-deﬁned rules, e.g., from Java2CSharp.
Regarding the applicability of this approach to other
programming languages, there are several challenges that need
to be investigated further. First, several issues arise when two
languages have quite different programming paradigms. For
example, SMT’s sequence-based alignment technology would
face great challenges to align code between Java in OOP style
and JavaScript, a dynamic language in event-handling style.
This requires a fundamental advance in SMT. Perhaps, graph-
based or tree-based alignment algorithms are needed. Second,
issues arise when languages’ semantics have fundamentaldifferences. For example, migrating Java to C with macros
and pointer manipulation, and to C++ with multiple inheritance
would need a new approach of integrating semantics into SMT.
Third, the dynamic languages used for web programming (e.g.,
PHP , JS) pose challenges to SMT due to dynamic typing.
As part of our future work , we plan to conduct usability
study and to measure effort saving with mppSMT as well asto study other factors in entire migration process (e.g., when
to migrate and cost). Finally, we need to investigate the role of
developers and automated tools in code migration. A process
to guide developers in handling complex cases is desired.
ACKNOWLEDGMENT
This work was supported in part by the US NSF grants CCF-
1518897, CNS-1513263, CCF-1413927, CCF-1320578, CCF-
1349153, TWC-1223828, CCF-1018600, and CCLI-0737029.
594REFERENCES
[1] J. Andersen and J. L. Lawall. Generic patch inference. In Proceedings
of the 2008 23rd IEEE/ACM International Conference on Automated
Software Engineering, ASE ’08, pages 337–346, Washington, DC, USA,
2008. IEEE Computer Society.
[2] Antlr. https://github.com/antlr/.
[3] T. Bartolomei, K. Czarnecki, and R. LaÌ ´Lmmel. Swing to swt and
back: Patterns for api migration by wrapping. In Software Maintenance
(ICSM), 2010 IEEE International Conference on, pages 1–10. IEEE,
Sept 2010.
[4] P . F. Brown, V . J. D. Pietra, S. A. D. Pietra, and R. L. Mercer. The
mathematics of statistical machine translation: Parameter estimation.
Comput. Linguist., 19(2):263–311, June 1993.
[5] D. Cer, M. Galley, D. Jurafsky, and C. D. Manning. Phrasal: Atoolkit for statistical machine translation with facilities for extractionand incorporation of arbitrary model features. In Proceedings of the
NAACL HLT 2010 Demonstration Session, HL T -DEMO ’10, pages 9–12,
Stroudsburg, P A, USA, 2010. Association for Computational Linguistics.
[6] K. Chow and D. Notkin. Semi-automatic update of applications in
response to library changes. In Proceedings of the 1996 International
Conference on Software Maintenance, ICSM ’96, pages 359–, Washing-
ton, DC, USA, 1996. IEEE Computer Society.
[7] B. Dagenais and M. P . Robillard. Recommending adaptive changesfor framework evolution. In Proceedings of the 30th International
Conference on Software Engineering, ICSE ’08, pages 481–490, New
Y ork, NY , USA, 2008. ACM.
[8] Db4o. http://sourceforge.net/projects/db4o/.
[9] DMS. http://www.semdesigns.com/Products/DMS/DMSToolkit.html.
[10] fpml. http://sourceforge.net/projects/fpml-toolkit/.[11] Google Translate. http://translate.google.com/.[12]
S. Han, D. R. Wallace, and R. C. Miller. Code completion from
abbreviated input. In Proceedings of the 2009 IEEE/ACM International
Conference on Automated Software Engineering, ASE ’09, pages 332–
343, Washington, DC, USA, 2009. IEEE Computer Society.
[13] A. E. Hassan and R. C. Holt. A lightweight approach for migrating
web frameworks. Inf. Softw. Technol., 47(8):521–532, June 2005.
[14] J. Henkel and A. Diwan. Catchup!: Capturing and replaying refactorings
to support api evolution. In Proceedings of the 27th International
Conference on Software Engineering, ICSE ’05, pages 274–283, New
Y ork, NY , USA, 2005. ACM.
[15] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and P . Devanbu. On the natural-
ness of software. In Proceedings of the 34th International Conference
on Software Engineering , ICSE ’12, pages 837–847, Piscataway, NJ,
USA, 2012. IEEE Press.
[16] C.-H. Hsiao, M. Cafarella, and S. Narayanasamy. Using web corpus
statistics for program analysis. In Proceedings of the 2014 ACM
International Conference on Object Oriented Programming Systems
Languages &#38; Applications, OOPSLA ’14, pages 49–65, New Y ork,
NY , USA, 2014. ACM.
[17] iText. http://sourceforge.net/projects/itext/.
[18] Java to C# Converter. http://www.tangiblesoftwaresolutions.com/Product
_Details/Java_to_CSharp_Converter.html.
[19] F. Jacob and R. Tairas. Code template inference using language models.
InProceedings of the 48th Annual Southeast Regional Conference,A C M
SE ’10, pages 104:1–104:6, New Y ork, NY , USA, 2010. ACM.
[20] Java2CSharp. http://sourceforge.net/projects/j2cstranslator/.
[21] JGit. https://github.com/eclipse/jgit/.
[22] Microsoft Java Language Conversion Assistant.
http://support.microsoft.com/kb/819018.
[23] JTS. http://sourceforge.net/projects/jts-topo-suite/.[24]
P . Koehn. Statistical Machine Translation. Cambridge University Press,
New Y ork, NY , USA, 1st edition, 2010.
[25] P . Koehn, F. J. Och, and D. Marcu. Statistical phrase-based translation.
InProceedings of the 2003 Conference of the North American Chapter
of the Association for Computational Linguistics on Human Language
Technology - V olume 1, NAACL ’03, pages 48–54, Stroudsburg, PA,
USA, 2003. Association for Computational Linguistics.[26] Lucene. http://lucene.apache.org/.
[27] C. D. Manning and H. Schütze. Foundations of Statistical Natural
Language Processing. MIT Press, Cambridge, MA, USA, 1999.
[28] S. Meng, X. Wang, L. Zhang, and H. Mei. A history-based matching
approach to identiﬁcation of framework evolution. In Proceedings of
the 34th International Conference on Software Engineering, ICSE ’12,
pages 353–363, Piscataway, NJ, USA, 2012. IEEE Press.
[29] Microsoft Translator. http://www.bing.com/translator.
[30] M. Mossienko. Automated cobol to java recycling. In Proceedings
of the Seventh European Conference on Software Maintenance and
Reengineering, CSMR ’03, pages 40–, Washington, DC, USA, 2003.
IEEE Computer Society.
[31] Neodatis. http://sourceforge.net/projects/neodatis-odb/.[32]
A. T. Nguyen, H. A. Nguyen, T. T. Nguyen, and T. N. Nguyen. Statistical
learning approach for mining api usage mappings for code migration.
InProceedings of the 29th ACM/IEEE International Conference on
Automated Software Engineering, ASE ’14, pages 457–468, New Y ork,
NY , USA, 2014. ACM.
[33] A. T. Nguyen, T. T. Nguyen, and T. N. Nguyen. Lexical statistical
machine translation for language migration. In Proceedings of the 2013
9th Joint Meeting on F oundations of Software Engineering, ESEC/FSE
2013, pages 651–654, New Y ork, NY , USA, 2013. ACM.
[34] T. T. Nguyen, A. T. Nguyen, H. A. Nguyen, and T. N. Nguyen. A
statistical semantic language model for source code. In Proceedings of
the 2013 9th Joint Meeting on Foundations of Software Engineering,
ESEC/FSE 2013, pages 532–542, New Y ork, NY , USA, 2013. ACM.
[35] M. Nita and D. Notkin. Using twinning to adapt programs to alternative
apis. In Proceedings of the 32Nd ACM/IEEE International Conference
on Software Engineering - V olume 1, ICSE ’10, pages 205–214, New
Y ork, NY , USA, 2010. ACM.
[36] Octopus.Net Translator. http://www.remotesoft.com/octopus/.[37]
Y . Padioleau, J. L. Lawall, and G. Muller. SmPL: A Domain-Speciﬁc
Language for Specifying Collateral Evolutions in Linux Device Drivers.
Electron. Notes Theor . Comput. Sci., 166:47–62, Jan. 2007.
[38] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. BLEU: A Method
for Automatic Evaluation of Machine Translation. In Proceedings of
the 40th Annual Meeting on Association for Computational Linguistics,
ACL ’02, pages 311–318, Stroudsburg, P A, USA, 2002. Association for
Computational Linguistics.
[39] POI. http://poi.apache.org/.
[40] Sharpen. https://github.com/mono/sharpen.[41]
K. Sudoh, K. Duh, H. Tsukada, T. Hirao, and M. Nagata. Divide
and translate: Improving long distance reordering in statistical machine
translation. In Proceedings of the Joint Fifth Workshop on Statistical
Machine Translation and MetricsMATR , WMT ’10, pages 418–427,
Stroudsburg, P A, USA, 2010. Association for Computational Linguistics.
[42] W . Tansey and E. Tilevich. Annotation refactoring: Inferring upgrade
transformations for legacy applications. In Proceedings of the 23rd
ACM SIGPLAN Conference on Object-oriented Programming Systems
Languages and Applications, OOPSLA ’08, pages 295–312, New Y ork,
NY , USA, 2008. ACM.
[43] A. van Deursen and T. Kuipers. Identifying objects using cluster and
concept analysis. In Proceedings of the 21st International Conference
on Software Engineering, ICSE ’99, pages 246–255, New Y ork, NY ,
USA, 1999. ACM.
[44] R. C. Waters. Program translation via abstraction and reimplementation.
IEEE Trans. Softw. Eng., 14(8):1207–1228, Aug. 1988.
[45] W . Wu, Y .-G. Guéhéneuc, G. Antoniol, and M. Kim. Aura: A hybrid
approach to identify framework evolution. In Proceedings of the 32nd
ACM/IEEE International Conference on Software Engineering - V olume
1, ICSE ’10, pages 325–334, New Y ork, NY , USA, 2010. ACM.
[46] XES. http://www.euclideanspace.com/software/language/xes/userGuide/
convert/javaToCSharp/.
[47] Z. Xing and E. Stroulia. API-Evolution Support with Diff-CatchUp.
IEEE Trans. Softw. Eng., 33(12):818–836, Dec. 2007.
[48] K. Y asumatsu and N. Doi. SPiCE: A System for Translating Smalltalk
Programs Into a C Environment. IEEE Trans. Softw. Eng., 21(11):902–
912, Nov. 1995.
595[49] H. Zhong, S. Thummalapenta, T. Xie, L. Zhang, and Q. Wang. Mining
api mapping for language migration. In Proceedings of the 32Nd
ACM/IEEE International Conference on Software Engineering - V olume
1, ICSE ’10, pages 195–204, New Y ork, NY , USA, 2010. ACM.[50] ZXing. https://github.com/zxing/zxing.
[51] ZXing.Net. http://zxingnet.codeplex.com/.
596