Risk-Driven Revision of Requirements Models
Dalal AlrajehAxel van LamsweerdeyJeff KramerAlessandra RussoSebastian Uchitelz
Department of Computing, Imperial College London, UK
{da04, jk, ar3, su2}@doc.ic.ac.uk
yICTEAM, Universit√© catholique de Louvain, Belgium
avl@info.ucl.ac.be
yDepartamento de Computaci√≥n, Universidad de Buenos Aires and CONICET, Argentina
ABSTRACT
Requirements incompleteness is often the result of unantic-
ipated adverse conditions which prevent the software and
its environment from behaving as expected. These condi-
tions represent risks that can cause severe software failures.
The identication and resolution of such risks is therefore
a crucial step towards requirements completeness. Obstacle
analysis is a goal-driven form of risk analysis that aims at
detecting missing conditions that can obstruct goals from
being satised in a given domain, and resolving them.
This paper proposes an approach for automatically revis-
ing goals that may be under-specied or (partially) wrong
to resolve obstructions in a given domain. The approach
deploys a learning-based revision methodology in which ob-
structed goals in a goal model are iteratively revised from
traces exemplifying obstruction and non-obstruction occur-
rences. Our revision methodology computes domain-consis-
tent, obstruction-free revisions that are automatically prop-
agated to other goals in the model in order to preserve
the correctness of goal models whilst guaranteeing minimal
change to the original model. We present the formal foun-
dations of our learning-based approach, and show that it
preserves the properties of our formal framework. We vali-
date it against the benchmarking case study of the London
Ambulance Service.
Categories and Subject Descriptors
H.1.3.1 [ Software and its engineering ]: Software cre-
ation and management| Designing software, Requirements
analysis
Keywords
Requirements completeness; obstacle analysis; goal-oriented
requirements engineering; inductive learning; theory revi-
sion.
1. INTRODUCTION
ACM acknowledges that this contribution was authored or co-authored by an em-
ployee, contractor or afÔ¨Åliate of a national government. As such, the Government
retains a nonexclusive, royalty-free right to publish or reproduce this article, or to al-
low others to do so, for Government purposes only.
ICSE ‚Äô16, May 14-22, 2016, Austin, TX, USA
c2016 ACM. ISBN 978-1-4503-3900-1/16/05. . . $15.00
DOI:http://dx.doi.org/10.1145/2884781.2884838Requirements completeness is a major concern in require-
ments engineering. Incompleteness commonly arises from a
lack of anticipation of adverse conditions which prevent the
software and its environment from behaving as expected: no
specic requirements are engineered for such cases. These
unanticipated conditions represent risk, and may be the
cause of severe software failures [35]. Risks may cover a
wide range of undesirable situations, such as safety hazards,
security threats and data inaccuracies amongst others. The
elicitation and analysis of these risks is at the heart of the
requirements engineering process [36, 16, 8, 26].
Obstacle analysis is a model-based, goal-oriented form of
analysis [35, 27], that focuses on a particular type of domain-
specic risk: the non-satisfaction of desired goals due to
events or conditions present within a domain and obstruct-
ing them. In this context, an obstacle to a goal is dened as
a precondition for the non-satisfaction of that goal. Obsta-
cle analysis comprises three steps [35]: (1) identication of
obstacles to goals from previously elicited goals and domain
properties; (2) quantitative assessment of the likelihood and
criticality of those obstacles, in terms of severity of their
consequences; and (3) resolution of likely and critical obsta-
cles through countermeasures to be integrated in the goal
renement graph (hereafter referred to as the system's goal
model ), from which the software requirements are derived.
A number of approaches have been proposed to handle
the identication (e.g., [36, 6]) and the assessment (e.g.,
[12]) steps of obstacle analysis. However, the systematic
resolution of the identied and assessed obstacles towards a
complete and robust goal model remains an open challenge.
Goal revision is a particular class of strategies for obstacle
resolution | others include obstacle prevention and obstacle
reduction. Goal revision typically involves modifying a goal
model in order to eliminate obstructions. It covers the goal
substitution and goal weakening strategies [36]. Given a
goal model, a set of domain properties and an obstacle to
the goal in the goal model, a goal revision strategy consists
of nding safe revisions of the obstructed goal along with a
set of propagated changes in the goal model, such that (a)
the obstruction caused by the obstacle is eliminated, and (b)
the resulting goal model remains complete and consistent.
In this paper, we propose a formal approach to obstacle
resolution. Our approach automatically and iteratively re-
vises goals, that may be under-specied or (partially) wrong,
to eliminate obstructions in a given domain from traces
exemplifying obstruction and non-obstruction occurrences.
We dene a goal revision problem as a learning-based revi-
2016 IEEE/ACM 38th IEEE International Conference on Software Engineering
   855
sion task [37]. The approach generates obstruction-free goal
revisions and automatically propagates them to other goals
in the model to make the obstruction disappear while pre-
serving model correctness and guaranteeing minimal change
on the original model. If alternative revisions are found, the
approach produces alternative goal models each of which
is guaranteed to be satisable within the given domain. It
makes use of a recently developed constraint-driven learning
technique [9]. This technique allows us to specify syntactic
and semantic constraints over the search space of possible
goal revisions. We use this feature to ensure the correctness
of the revised goal model. Our approach terminates once
all identied obstructions have been removed within a given
set of domain properties, or when no revision can be found
for this set. The latter case calls for eliciting further do-
main properties from which a new cycle of obstacle analysis
should be applied [6].
In this paper, we assume that a set of obstructed goals is
given and that the identied obstacles to these goals have
been prioritized in terms of criticality in the preceding as-
sessment phase (e.g., through cost-benet analysis) of ob-
stacle analysis. We do not consider obstructions arising, for
instance, from uncertainty about stakeholders, their priori-
ties or implementation costs, as in [22]. Our contribution is
summarized as follows:
a formal underpinning of the notion of safe goal revi-
sion for obstacle resolution;
an automated approach for computing safe revision of
a goal from obstruction and non-obstruction traces;
an automated technique for minimally propagating chan-
ges throughout a goal model while ensuring that the
resulting model is correct;
a new application of learning-based revision and constra-
int-driven learning to requirements engineering.
To the best of our knowledge, this paper is the rst to
automatically execute and propagate goal revisions in formal
goal models.
The rest of the paper is organized as follows. Sec. II intro-
duces background on goal modelling, obstacle analysis, and
revision-based learning. Sec. III motivates our approach on
a small example. Sec. IV presents the formal underpinning
of our approach. Sec. V and VI, dene the learning-based re-
vision technique used for computing goal revisions and sum-
marizes our evaluation on an ambulance dispatching system
[17] respectively. Related work is discussed in Sec. VII.
2. BACKGROUND
We recall some basics on behavioural goal modelling, ob-
stacle analysis and learning-based revision.
2.1 Goal-oriented system modelling
Agoal is a prescriptive statement of intent to be satis-
ed by cooperating agents forming the considered system.
Agents may include devices like sensors and actuators, peo-
ple, pre-existing software and the software to be developed.
Unlike goals, domain properties are descriptive statements
about the problem space, e.g., physical laws. A behavioural
goal captures a maximal set of intended system behaviour;
unlike soft goals, it is satisable in a clear-cut sense [35].A behavioural goal is of type Achieve orMaintain. To
enable formal analysis, behavioural goals may be specied
in Fluent Linear Temporal Logic (FLTL) [18]. A goal has the
general form 2(C;T) whereCandTare conjunctions
of uent expressions (dened hereafter), ;is one of the
classical logical connectives !and$and  is a real-time
temporal operator such as (next), 3(sometimes in the
future), 3d(sometimes in the future before deadline d),
2(always) and U(always in the future unless) [21]. The
expressionC)Tis a shorthand for 2(C!T).
A uent fis dened by a set Ifof initiating events, a set
Tfof terminating events and an initial truth value either
true orfalse. Given a set of event labels A, called alphabet ,
a uent denition takes the form f=hIf;Tf;Initi, where
IfA,TfAandIf\Tf=;, and Init2ftrue; falseg. A
negative uent literal is a uent preceded with :. Otherwise
it is called a positive literal. The notation (:)f is a shorthand
for either for:f. A uent expression is a uent literal
preceded by a temporal operator.
FLTL expressions are interpreted over sequences of state
and events called traces . Events may occur simultaneously
in a trace. We write =s0fa;bg0s1fcg1s2:::to represent a
trace in which the events aandboccur simultaneously from
states0followed by the event cfroms1. We sometimes
write traces as = 0 :fa;bg;1 :fcg;2 ::::. Given a trace
and a set of uent denitions FD, a uent is said to be
true (resp. false) in a trace at position i, denoted;ij=f,
if and only if either of the following conditions holds: ( a)
the uent is initially true and no terminating event has oc-
curred since, or ( b) some initiating event has occurred before
iwith no terminating event occurring since then. The no-
tationj=fis a shorthand for ;0j=f. The semantics of
uent expression are dened inductively. Given two FLTL
expressions  and 	, fgj = 	 holds if all traces satisfying
 also satisfy 	.
Given a trace and alphabet A, the projection of over
A, denoted as jA, is the trace obtained by eliminating from
all elements that are not in A. We use the notation ()
(resp.  A()) to denote all traces (resp. projections) satis-
fying .
Agoal model is a renement graph in which each goal is
represented as a node and associated with a unique label.
An AND-renement of a goal PGinto a set of sub-goals
fSG 1::::;SGngiscomplete when the sub-goals fSGig, pos-
sibly with domain properties in D, are together sucient
for satisfying PG; and it is consistent if the sub-goals are all
together consistent with the domain properties. These prop-
erties are more precisely stated as follows, for all 1 <i<n :
fSG 1;:::;SGn;Dgj=PG (complete renement)
fSG 1;:::;SGn;Dg6j=false (consistent renement )
A goal model is said to be correct if every AND-renement
relation in the model is complete and consistent. In this
paper, we dene a goal model as a tuple h ;iwhere   is
the set of goals appearing in the model and is the set
of AND-renement relations between goals in  . We will
sometimes write fSG 1::::;SGng Gto denote the notion
that the setfSG 1::::;SGngis a renement of G.
Obstacle analysis is a goal-oriented form of risk analysis.
Anobstacle to a goal is a domain-satisable precondition for
the non-satisfaction of this goal [36, 35]:
fO;Dgj=:G (obstruction)
fO;Dg6j=false (domain consistency )
856We call any trace such thatj=D^Oanobstruction
trace for goal Gwith respect to obstacle OinD. Similarly,
we refer to a trace where j=D^:Oas a non-obstruction
trace forGwith respect to OinD.
2.2 Inductive Learning and Theory Revision
Inductive Logic Programming (ILP) [29] is a logic-based
inductive learning [28] technique that is concerned with learn-
ing generalizations Hthat, together with a given background
knowledge Bexplain a given set Eof examples, where H,
B,Eare represented as logic programs [25]. Typically, ILP
algorithms generate minimal hypotheses, i.e., ones that are
minimal both in terms of their size and number. Most re-
cent state-of-the-art inductive learning systems [14, 15, 10],
referred to as non-monotonic ILP systems, are capable of
not only learning generalizations of given examples, but also
revisions of existing knowledge. Assuming Kto represent
possibly incorrect knowledge (referred to as the revisable
knowledge), a learning-based revision task is a computa-
tional task that consists of learning changes Cto be applied
to the revisable knowledge K, to generate a revised knowl-
edge K0=(K;C ) that entails the examples. The function 
denotes the application of revisions Cto the revisable knowl-
edge K.
The search for revisions is performed within the scope
of a search space sdened by a set of mode declarations
(MD), a form of language bias that species the syntactic
form of acceptable changes to be learned for a given revision
task. We use s(MD) to denote this space. In general, such
search space is very large as it potentially includes all pos-
sible additions and deletions that could be applied to the
revisable knowledge within the scope of a given language,
some of which may be irrelevant for particular domains.
Inductive learning through constraint-driven bias is a tech-
nique recently proposed to tackle this problem [9]. Accept-
able changes are the set of possible additions and deletion
to the revisable knowledge that conform to a given set of
domain-specic constraints. This is formally dened as fol-
low, wherePdenotes the operator of power set, P(s(MD))
denote the set of possible changes and P(s(MD))] ICthe set
of changes compatible with a given set of constraints IC.
Definition 1 (Constraint-driven revision). A
learning-based revision task through constraint-driven bias
is a tuplehB;K;E; MD; ICMDi, where B denotes the back-
ground knowledge, Krepresents the revisable knowledge, E
is the set of examples, MD is the language bias and IC MD
is the set of constraints over the search space P(s(MD)) in-
duced by MD. His an acceptable learned revision for this
task if and only if H2[P(s(MD))] ICand the revised knowl-
edgeK0=(K;H )satises the condition B [K0j=V
e2Ee.
Minimality in the constraint-driven revision case is deter-
mined by the number of of additions and deletions applied
toKto satisfy the conditions above.
3. MOTIVATING EXAMPLE
Consider a simplied version of a car automatic handbrake
control system [35] in which a car driver, the car's engine,
and the handbrake must interact to achieve safe brake con-
trol. A high-level goal for this system requires \the hand-
brake to be released within three seconds of the driver's
wanting to start the car" expressed in FLTL asGr=DriverWantsToStart ,33HandbrakeReleased
Fig. 1.a shows a goal model for this root goal. In brief, the
goal labelled Gris rened into three sub-goals: a child goal
labelled G1stating that \the driver presses the acceleration
pedal whenever he/she wants to drive the car", a child goal
labelled G2prescribing that \the motor revs increase after
the pedal is pressed" and a child G3requiring that \once the
motor revs increase (i.e., revving), the handbrake is to be
released". Each of these are then rened into two leaf goals
capturing the if and only-if part of ,.
Suppose the domain properties Dcontain the following
uent denitions and a property that states that the motor
revs increase whenever the air-conditioning in the car starts:
AirConditioningStarts hstartAC;stopAC;falsei
MotorRevvinghincRevMotor ;decRevMotor ;falsei
DriverWantsToStart hinsertKeys;removeKeys ;falsei
HandbrakeReleased hreleaseHandbrake
engageHandbrake ;falsei
ThrottlePedalPressed hpressPedal ;releasePedal ;falsei
AirConditioningStarts ) MotorRevving
The goal model in Fig. 1 fails to consider situations in
which the motor revs increase due to other reasons: namely
the air-conditioning starting, a possible behaviour within
the domain that would obstruct the goal G7stating that
\the acceleration pedal is pressed if the motor is revving",
MotorRevving)ThrottlePedalPressed .
Using [6], the following obstacle condition is generated:
OG7=3(AirConditioningStarts ^:ThrottlePedalPressed )
Although approaches such as [36] provide a list of strategies
that may be deployed to resolve obstacles like this, they do
not discuss when these strategies are applicable and in which
cases nor how such strategies can be applied individually or
in tandem. Furthermore, they do not provide support for
ensuring that resolutions are propagated correctly within
the entire goal model.
Consider for instance, the substitution strategy in which
the obstructed goal G7may be replaced with a new one
which no longer relies on the acceleration pedal being pressed.
One choice would be to weaken the goal to become
MotorRevving)(AirConditioningStarts
_ThrottlePedalPressed )
Another possibility is to extend the domain description
Dwith new uents and properties that may allow alterna-
tive resolutions. For example, suppose Dis extended to
model a car with an Electronic Handbrake [19] that has an
electronic handbrake button and a handbrake controller that
adds tension to the brake cables: ManualBrakeButtonO 
hswitchButtonO ;switchButtonO ;falsei; HandBrakeCtrlO
hswitchCtrlO ;switchCtrlOn; falsei.
In this extended domain, it is possible to consider a revised
goal in which an electronic handbrake disables the hand-
brake controller.
HandBrakeCtrlO )ManualBrakeButtonO
Whichever choice is made, simply replacing the obstructed
goal G7is clearly insucient since the resulting renements
in the goal model may no longer be complete. Hence, the
changes to the goal need to be correctly propagated to other
goals in the model that were dependent on the previous goal
857DriverWantsT
oStart,3HandbrakeReleased
DriverWantsT
oStart,ThrottlePedalPressed Thr
ottlePedalPressed ,MotorRevving MotorR
evving,HandbrakeReleased
Thr
ottlePedalPressed )MotorRevving DriverWantsT
oStart)ThrottlePedalPressed
Thr
ottlePedalPressed )DriverWantsToStartMotorR
evving)HandbrakeReleased
Handbr
akeReleased)MotorRevving MotorR
evving)ThrottlePedalPressedMotorR
evving,HandbrakeReleased(a) Gr
G1 G2 G3
G4
G5G6
G7G8
G9
DriverWantsT
oStart,ManualBrakeButtonO ManualBr
akeButtonO,HandbrakeCtrlO Handbr
akeCtrlO,HandbrakeReleased
DriverWantsT
oStart)ManualBrakeButtonO
ManualBr
akeButtonO)DriverWantsToStartDriverWantsT
oStart,3HandbrakeReleased
Handbr
akeCtrlO)ManualBrakeButtonOManualBr
akeButtonO)HandbrakeCtrlO Handbr
akeCtrlO)HandbrakeReleased
Handbr
akeReleased)HandbrakeCtrlO(b) Gr
G0
1 G0
2 G0
3
G0
4
G0
5G0
6
G0
7G0
8
G0
9F
igure 1: Goal model for Automatic Handbrake Control System: (a) original, (b) revised.
being satised. As a result of the propagation, the hand-
brake controller will release (or apply) the handbrake rather
than the motor revving.
We present a learning-based revision technique that auto-
matically produces the revised goal model in Fig. 1.b by sub-
stituting the obstructed goal G7and propagating the neces-
sary changes to the rest of the model to guarantee it to be
obstruction-free, consistent within the domain and preserve
the correctness of the renements in the goal model.
4. GOAL REVISION SETTING
As mentioned in Sec. 1, dierent revision strategies may
be deployed to resolve an obstacle for a given goal, each of
which involves a series of strategy-specic manipulations to
the domain properties, and/or goal model. In spite of the
specic strategy deployed, the goal model resulting from the
resolution must satisfy a number of requirements to ensure
that the obstacle is eliminated. In this section we discuss
common requirements goal revision strategies should meet.
In what follows we use D0to represent the domain prop-
erties resulting from updates to the domain properties D,
G0a revision to the goal G,M0the goal model resulting
from integrating G0in the model Mand propagating chan-
ges through the original goal model M. Finally denotes
a function that returns a user-dened distance metric that
measures the dierence between two goals (i.e., (G;G0)),
or sets of goals (i.e., (fGig,fG0
ig)).
The rst requirement is concerned with domain-consistency.
Since goals are expected to be achieved within specic do-
mains, any revision strategy must ensure that it produces
satisable revisions within that domain.
REQ1 [Revision Consistency] If goal G is obstructed by
obstacle O in domain D, then any goal revision G0should
be consistent with D0, i.e.,fD0;G0g6j=false.
The second requirement is concerned with obstacle elimi-
nation. Obstacle elimination may be achieved in two ways:
either by ensuring the obstruction disappears (i.e., violat-
ing the obstruction condition in Subsection. 2.1) or making
the obstacle inconsistent with the domain (i.e., violating the
domain-consistency condition in Subsection. 2.1). In the
rst case, a minimum requirement for the resolution strat-
egy is to ensure that the revised goal is no longer violated
by the obstacle's occurrence.REQ2 [Obstacle Elimination] If goal G is obstructed by
obstacle O in D, then any goal revision G0should no longer
be obstructed by O in D0, i.e.fD0;Og6j=:G0.
Furthermore, the goal changes to be propagated through-
out the model should not cause other changed goals to be
obstructed by the obstacle O.
REQ3 [Non-obstruction Sustainability] The propaga-
tion of changes to G through M should not reintroduce new
obstructions, by obstacle O, to any changed goal G0
iof M0in
D0, i.e.,fD0;Og6j=:G0
i.
In addition, such change propagation should preserve the
goal model's correctness.
REQ4 [Renement Correctness] The propagation of chan-
ges to G through M must ensure that every goal renement
in the model M0is a consistent and complete renement.
We call a goal revision safe if it satises REQ1{4. In
addition, two other requirements appear desirable. Any be-
haviour that was permissible in the domain and in which
the obstacle did not occur should be permissible after the
revision in the updated domain. Assuming ADdenotes the
alphabet of the domain D, prior to any update. This re-
quirement is more precisely stated below.
REQ5 [Behaviour Preservation] The revised goal model
M0should preserve those behaviour from G in which the ob-
stacle does not occur, i.e., (D^:O^G)AD(D0^G0).
Finally, the revised goal model M0should be as close as
possible to the original model M.
REQ6 [Minimal Change] The propagation of the goal re-
visionG0through M should be minimal, i.e., (M;M0)is
minimal.
5. OBSTACLE-DRIVEN GOAL REVISION
This section presents our approach for learning-based re-
vision for computing safe goal revisions.
5.1 Approach Overview
The input is a goal model M, updated domain properties
D, which include uent denitions, and a set of detected
obstaclesfOigto goals in M. We assume a set of obstacles
have already been detected, for instance using the proce-
dure presented in [6], and assessed against their likelihood
and criticality using the method in [12]. Then for each ob-
858stacle OtoGofMinD, a nite set of obstruction traces  O
are obtained from a model satisfying DandO. We generate
these by verifying fD;Ogj=2(C;T), in the spirit of
[5]. To achieve the behaviour preservation requirement ex-
pressed in Sec. 4, the approach further considers a nite set
of non-obstruction traces  :Othat satisfy the domain and
negation of the obstacle. These are generated by verifying
a model of Dand:Oagainst the obstructed goal's `anti-
target', i.e.,fD;:Ogj =2(C;:T ), as explained in [6].
We use the model checking approach described in [34] for
automatically generating the traces. However, the approach
is not bound to a specic verication method and assumes
that domain-consistent traces are given.
Then, a learning-based revision task is constructed which
aims at automatically nding revisions G0to the obstructed
goal Gsuch that the revised goal is satised in traces by all
in (:O[O) and is consistent with D. The revisions are
automatically propagated to other goals in M. Where alter-
native revisions exist, alternative goal models are generated.
The output is a set of alternative goal models fM0
jgthat are
guaranteed to be satised in the traces generated. The revi-
sion procedure is repeated with respect to the revised goal
until no traces in ( D^O) obstruct the revised goal or until
no revision can be found within the given domain proper-
ties, indicating that the domain needs to be updated. In the
latter case, new obstacles (if any) need to be identied and
assessed within the updated domain in order to start a new
revision cycle. The revision process is iteratively applied on
every input obstacle in fOig. The approach terminates once
a goal model is reached that meets the REQ1{6 of Sec. 4 for
every Oi.
The order in which obstacles are eliminated are assumed
to be determined by the engineer depending on their as-
sessed criticality. In our illustrations, we assume that the
structure of the goal model is maintained, i.e., the num-
ber of children and renements for a parent goal does not
change. We illustrate the proposed approach by consider-
ing a goal substitution strategy. Weakening is discussed in
Sec. 6.
To enable the learning-based revision in the context of
obstacle resolution, the task of nding a safe goal revisions
must be dened in in terms of the ILP framework introduced
in Sec. 2.2. The goal model, domain properties and traces
are therefore automatically translated into a logic program,
and together with appropriate constraints over the solution
space, learning-based revision computes acceptable revisions
as shown in the next subsection. Though the details are pro-
vided, the encoding and procedure for generating revisions
are black-box computations from the engineer's perspective.
5.2 Encoding for Obstacle Elimination
We rst introduce some terminologies used in our descrip-
tion. We assume that every goal Gis associated with a la-
bel that uniquely identies it, denoted . We refer to a goal
SGin a renement set of a parent goal PGas a left child if
a uent literal that appears in SG's current condition also
appears in PG's current condition. Similarly, we call it a
right child if a uent literal that appears in SG's target con-
dition also appears in PG's target condition. In addition,
we say that the child goal SG1isleft(resp. right )ofanother
child SG2if a uent literal that appears in SG1's target con-
dition (resp. current condition) also appears in the current
(resp. target) condition of SG2. We describe below the en-coding of goals, the structure of the goal model, the traces
and the setting for revision task. The encoding of domain
properties is similar to that described in [6].1
The formalism used for encoding the input is based on
the Event Calculus (EC) [20]. In addition to the standard
EC predicates (e.g., holds_at and happens ), we extend the
language to include auxiliary predicates that capture the
formulation of goals' current and target conditions together
with their interpretation over traces.
For a given goal model M=h ;i, the encoding Mis
dened in terms of the encoding of the goal expressions
in it (denoted tr[ ]) and the renement relations it con-
tains (denoted tr[]). The tr[ ] makes use of predicates like
c_holds (meaning the current condition holds), t_holds (for
the target condition holds), t_holds_next (meaning the tar-
get condition holds at the next time-point), and the pred-
icate t_holds_eventually (meaning the target condition
holds eventually), etc. The current condition Cof a goal
labelledlGis automatically translated into the expression:
c_holds (lG;I;S) (neg_ )predb[1;I2;S]^:::
^(neg_ )predb[n;I2;S]
wherejis a uent expression in G's current condition,
predb[j;I2;S] is the EC literal corresponding to the uent
expressionjas given in Table 1 and the variables Iand S
are of type time-points and traces respectively. The encod-
ing of target conditions results in rules of the form:
predh[T;l G;I;S] predb[;I]^
(neg_ )predb[1;I2;S]^:::^(neg_ )predb[n;I2;S]
where predb[;I] is the literal corresponding to  in Table
1, andpred h[T;l G;I;S] is the literal corresponding to  T.
Table 1: Encoding of goals.
Fluent expression EC encoding
predb[(:)f; I;S] (neg_ )holds_at (f,I,S)
predb[(:)f; I;S] (neg_ )holds_at_next (f,I,S)
predb[3(:)f; I;S] (neg_ )holds_at_eventually (f,I,S)
predb[3d(:)f;I;S] (neg_ )holds_at_eventually_by (f,d,I,S)
predb[;;I] I=I2
predb[;I] next (I,I2)
predb[3;I] eventually (I,I2)
predb[3d;I] eventually_by (I,d,I2),
predh[T; l G;I2;S] t_holds (lG,I2,S)
predh[T; l G;I2;S] t_holds_next (lG,I2,S)
predh[3T; l G;I2;S] t_holds_eventually (lG,I2,S)
predh[3dT; lG;I2;S]t_holds_eventually_by (lG,d,I2,S)
The following is an extract of the encoding obtained for
the goals labelled Grand G7of Fig. 1.
c_holds (gr;I;S) 
holds_at (driverWantsToStart ;I;S):
t_holds_eventually_by (gr;3;I;S) 
holds_at_eventually_by (handbrakeReleased ;3;I;S):
t_holds_eventually_by (gr;3;I;S) 
holds_at_eventually_by (handbrakeReleased ;3;I;S):
c_holds (g7;I;S) 
holds_at_next (motorRevving ;I;S):
t_holds (g7;I;S) 
holds_at (throttlePedalPressed ;I;S):
1For details, see www.doc.ac.uk =da04=icse16=.
859In addition to the above, tr[ ] contains rules that capture
notions of vacuous and non-vacuous satisfactions of goals in
traces, using predicates holds_vacuously and holds_non-
vacuously . This is to preserve the semantics of the goal
expressions over traces in the semantics of the logic programs
(i.e., both when the goal condition holds and does not hold).
Furthermore, since our logic programs have nite models,
we extend the satisfaction notion of goals in nite traces to
handle cases where the current condition of a goal holds,
and the bound on traces is reached before the goal's target
condition is satised. This is formalized using the predicate
holds_at_end_time . Below is the encoding generated from
the goals Grand G7.
holds_non_vacuously (gr;I;S) 
c_holds (gr;I;S)^t_holds_eventually_by (gr;3;I;S):
holds_vacuously (gr;I;S) 
not c_holds (gr;I;S)^
not t_holds eventually_by (gr;3;I;S):
holds_at_end_time (gr;I;S) 
c_holds (gr;I;S)^
eot(E)^IE^E<I+ 3;
not t_holds eventually_by (gr;E;I;S):
holds_non_vacuously (g7;I;S) 
c_holds (g7;I;S)^t_holds (gr;I;S):
holds_vacuously (g7;I;S) not c_holds (g7;I;S):
The encoding of renement relations tr[] makes use of
the predicates root/1,left_child /2,right_child /2 and
left_of /2 to formulate the renement relation between goals
in the goal model. For example, the following facts are gen-
erated for our running example.
root(gr). left_child (gr,g1).
child_of (gr,g2). right_child (gr,g3).
Our encoding also captures domain-independent axioms,
denoted Ax, that dene laws of persistency of uents over
time in traces [20], and of goal satisfaction, including:
holds (G;I;S) holds_non_vacuously (G;I;S):
holds (G;I;S) holds_vacuously (G;I;S):
holds (G;I;S) holds_at_end_time (G;I;S):
To enable the revision, the encoding formulates the notion
of obstruction and obstacle elimination in Ax:
obstacle_holds (G;I;S) not holds (G;I;S):
obstructed obstacle_holds (G;I;S)
entailed not obstructed :
The rst rule says that an obstacle for a goal Gholds at
some time-point in a trace if the goal does not hold at that
time-point. The second says that an obstruction occurs if
there is a goal for which an obstacle holds. No obstruction
gives entailment of all goal.
The encoding of traces tr[O[:O] on the other hand
generates a set of happens facts. For instance, from the ob-
struction trace OG7= 0:fstartCarg, 1:fstartAC ,switchBut-
tonOg, 2:fincRevMotorg,freleaseHandbrake g, and the non-
obstruc-tion trace :OG7= 0:fstartCarg, 1:fpressPedal ,
switchButtonOg, 2:fincRevMotorg,freleaseHandbrake g
we have the following facts:tr[OG7[:OG7] =
fhappens (startCar;0;s1);happens (startAC;1;s1);
happens (switchButtonOff ;1;s1);happens (incRevMotor;2;s1);
happens (switchButtonOff ;2;s1);
happens (releaseHandbrake; 3;s1);
happens (startCar;0;s2);happens (switchButtonOff ;1;s2);
happens (pressPedal; 1;s2);happens (incRevMotor;2;s2);
happens (switchButtonOff ;2;s2);
happens (releaseHandbrake; 3;s2)g:
where s1and s2are unique identiers for encoded traces.
5.3 Computing Goal Revisions
To compute revisions to the obstructed goal, the set of ex-
amples Emust be specied. For the learner, the example are
facts that should follow from the background knowledge and
revisable theory but as such do not. In the revision prob-
lem, we consider our examples to represent the fact that all
encoded goals (including the obstructed one) should hold at
all time-points and in all the traces, including the obstruc-
tion traces. Given the rules dening entailment in Sec. 5.2,
Ein its simplest form includes the single fact entailed .
The mode declaration MD is dened to cover all uents
expressions that may be constructed using the language of
the domain and the predicates in Table 1. As these are typi-
cally domain-specic, the engineer may specify which uents
may be considered in the revision process, thus limiting the
solution space to goals expressible using these.
To ensure the renement correctness requirement (REQ4),
we dene a set of the constraints ICMDover the solution
space, requiring that any change to the obstructed goal forces,
where necessary, the revision to be applied to other goals
within the model. The constraints specify which changes to
goals' current and target conditions are acceptable to en-
sure the completeness and consistency of renements. For
instance, it is required that any changes to the current con-
dition of a left child are reected correctly in the current
condition of its parent. This is captured in the following
constraints in ICMD.
 in (R1;current (PG);L);left_child (PG;SG)^
not in (R2;current (SG);L):
 in (R1;current (SG);L);left_child (PG;SG)^
not in (R2;current (PG);L):
where the variable Riis a unique identier (used by the
learner) for a rule within the solution space, and Lcorre-
sponds to an EC encoding of a uent expression. The literal
in(R1;current (PG);L) for instance means the rule with iden-
tier R1representing PG's current condition (i.e., c_holds in
the head) has the EC encoding of the uent expression Lin
its body. Although these constraints are pre-specied, the
approach provides a language for users to specify other forms
of constraints that are best suited for the domain. The re-
vision task can now be dened as follows.
Definition 2 (Goal revision task). A goal revision
task is a learning-based revision task hB;K;E;MD; ICMDi,
where K =tr[ ], B =tr[][tr[D][tr[O[:O][Ax,
E=fentailedg.
The encoding of the problem preserves the obstruction
to goals, prior to the revision computation. For instance,
given the trace tr[OG7], the current target of the goal G7
holds at time-point 2 ( holds_at_next (motorRevving ;2;s1))
860and consequently c_ holds (g7, 2, s1) also holds. How-
ever, holds_at (throttlePe-dalPressed , 2, s1) is not true
at time-point 2 and thus G7's target condition does not hold
at time-point 2 (i.e., t_holds (g7;2;s1) is not true). It fol-
lows from this that holds (g7, 2, s1) is not true and therefore
obstructed is also true. Hence entailed is not covered.
Theorem 1 (Correctness of Encoding). Let G be
a goal, D the domain properties and Obe an obstruction
trace to G in D. Let B and E be the background knowledge
and example obtained from Def. 2. Then Oj=:G i B[
tr[G]6j=entailed:
The revision procedure operates by exploring the search
space for goal revisions obtainable by deleting and adding
uent expressions to the current or target conditions of the
obstructed goal, (tr[ ];C ). The choice of operations to ap-
ply and of goals to which these are applied is determined by
the traces in Band the constraints ICMD. For instance, to
satisfy entailed in our running example, the literal holds_at
(throttlePedalPressed ;2;s1) is deleted from the body of
the rule t_holds (g7,I,S). Its substitution is identied by
traversing the trace for literals that if added to the body
t_holds (g7,I,S) would result in the derivation of holds (g7;
2;s1). To satisfy the constraints ICMD, further deletions and
additions are applied to other goals.
The distance metric is dened by the learning algorithm
as a function that calculates the number of addition and
deletion operations applied on the original model as a whole
to obtain the revised model. Each application of an oper-
ation is given the score of 1. In our example above, the
distance between (M;M0) = 12 capturing the number of
uent expressions that are deleted (6), e.g., ThrottlePedal-
Pressed from G1,G2,G4,G5,G6and G7, and added (6).
Where multiple revision candidates of similar distance ex-
ist, these are provided as alternative revisions. The learning
produces the following set K0of revised rules.
t_holds (g1;I;S) holds_at (manualBrakeButtonOff ;I;S):
t_holds (g4;I;S) holds_at (manualBrakeButtonOff ;I;S):
c_holds (g5;I;S) holds_at (manualBrakeButtonOff ;I;S):
c_holds (g2;I;S) holds_at (manualBrakeButtonOff ;I;S):
c_holds (g6;I;S) holds_at (manualBrakeButtonOff ;I;S):
t_holds (g7;I;S) holds_at (manualBrakeButtonOff ;I;S):
The output indicates that changes are required to 6 goals
in Fig. 1.a in total. For instance, from the last rule above,
the obstructed goal G0
7is substituted by its revised ver-
sionMotorRevving)ManualBrakeButtonO . The goals
shown in Fig. 1.b are computed following a second iteration
of the approach to resolve the obstacle 3(manualBrakeBut-
tonO^:MotorRevving) by substituting the dependency
on the motor's revving with a hand-brake controller.
5.4 Theoretical Results
We report here on some of the results that follow from the
approach. We do not provide full proofs owing to limited
space.2The rst of these is that the approach guarantees
that any revision computed is consistent with the domain.
Theorem 2 (Domain Consistency). Let G be a goal
and D the domain properties. Let Obe an obstruction trace
2See www.doc.ac.uk= da04=icse16=for proofs.to G in D. Then for any computed goal revision G0, we have
fG0;Dg6j=false.
The proof is is a consequence of Theorem 1 and the sound-
ness of the learning [9]. Since obstruction traces form part of
the background knowledge, the approach also ensures that
every revision computed is satised in the obstruction trace,
thus eliminating the obstacle from (at least) the encoded
traces.
Theorem 3 (Obstruction Elimination). Let G be a
goal and D the domain properties. Let Obe an obstruction
trace to G in D. Then for any computed goal revision G0, we
haveOj=G0.
In addition, as the example requires that all considered
goals to be satised in the obstruction traces, the approach
meets the REQ3 with respect to those traces.
Theorem 4 (Non-Obstruction Sustainability). Let
M=h ;ibe a goal model and Oa set of obstruction
traces for G2 in(D^O) and:Oa set of non-obstruction
traces for G in (D^:O). Let M0=h 0;ibe a re-
vised goal model computed form D, M, Oand:O. Then
8G0
i2 0;2O[:O:j=G0
i.
Another consequence of the proposed approach is that ev-
ery renement relation in the revised goal model is guaran-
teed to be consistent and complete. Consistency is preserved
since the renements are (at the least) satised in the traces
provided as input. Completeness with respect to the traces
provided is maintained since every trace satisfying the en-
coding of a goal's children satises the encoding of the goal.
Full correctness may be guaranteed if the traces provided
capture a complete characterization of the traces in D.
Theorem 5 (Refinement Correctness). Let M =
h ;ibe a goal model and Oa set of obstruction traces
for G2 in Dand :Oa set of non-obstruction traces
for G in D. Then every renement in a revised goal model
M0=h 0;icomputed form D, M, Oand:Ois a con-
sistent and complete renement with respect to O[:O;
i.e.,8fSG 1;:::;SG ngG:
82(O[:O), ifj=V
iSGithenj=G,
92(O[:O): j=V
iSGi
Furthermore, since non-obstruction traces, in which the
original goal is satised, are encoded in the background
knowledge, the learning guarantees that the revised goal is
satised in these traces too, thus meeting REQ5.
Theorem 6 (Behaviour Preservation). LetOa set
of obstruction traces for G in D and :Oa set of non-
obstruction traces for G in D. Then for any computed goal
revision G0to G from D, Oand:Othe following condi-
tion holds:82:O. Ifj=G thenj=G0.
In our context, minimality of the revision is determined
by the number of uent expressions that need to be added
or deleted to meet REQ1{5 with respect to the given traces.
The approach guarantees that all the computed revisions are
minimally dierent from the model prior to the revision for
the given traces.
Theorem 7 (Minimal Change). Let M =h ;ibe a
goal model, Oa set of obstruction traces for G 2 in(D^
O). Let M0=h 0;ibe a computed goal model revision.
Then( ; 0)is minimal with respect to O.
861Our approach also guarantees progress towards fewer ob-
structions in the goal model that are caused by the detected
obstacles. This is easy to show since each revised goal is
satisable in at least one more trace, i.e., the obstruction
trace. The proof is based on the assumption that the re-
vision process is performed iteratively and that obstruction
traces from previous steps are used in subsequent iterations.
Theorem 8 (Progress). LetObe a set of obstruc-
tion traces for G in D. Then for any computed goal revision
G0to G from D, Oand G:j(D^O^G0)j<j(D^O^G)j.
6. VALIDATION
We apply our approach to a benchmark case study, the
London Ambulance Service originally reported in [36]. We
demonstrate its ability to apply both weakening and sub-
stitution strategies for goal revisions expressed in rst-order
FLTL. To facilitate comparison with other approaches, we
consider goals and obstacles that have been discussed in [36].
A partial goal model is outlined below. The root goal Ambu-
lanceInterventionWhenIncidentReported states that\an am-
bulance must intervene within 11 minutes of an incident be-
ing reported". Renements of this goal are represented by
the level of indentation. The notation  left(reps. right)
indicates that the goal is a left (reps. right) child goal to the
goal one renement level above.
AmbulanceInterventionWhenIncidentReported
 leftAmbulanceAllocatedWhenIncidentReported
 rightAmbulanceInterventionWhenAllocated
 leftAmbulanceMobilizedWhenAllocated
 leftAmbulanceMobilizedWhenOnRoad
 right AmbulanceMobilizedWhenAtStation
 leftMobilizationOrderIssuedAtStation
 right AmbulanceMobilizedFromMobOrder
 right AmbulanceInterventionWhenMobilized
The domain properties Dcontains the following uent def-
initions.
Resolved(inc:Incident) hresolve(inc), happens(inc),false i
Intervention(a:Ambulance)(inc:Incident) 
hintervene(a,inc),not intervene(a,inc),falsei
Allocated(a:Ambulance)(inc:Incident) 
hallocate(a,inc),deallocate(a,inc), false i
Mobilized(a:Ambulance)(inc:Incident) 
hmobilize(a,inc),demobilize(a,inc),false i
Available(a:Ambulance) 
hassign(a), free(a), true i
AtStation(a:Ambulance) 
harriveAtStation(a), leaveStation(a), true i
MobOrderIssued(a:Ambulance)(inc:Incident) 
hissueMobOrder(a,inc), retractMobOrder(a,inc), true i
BrokenDown (a:Ambulance)
hbreakDown(a), repair(a), false i
6.1 Goal Revision by Weakening
Consider the goal AmbulanceInterventionWhenMobilized :
8a:Ambulance; inc:Incident
Mobilized (a;inc))33Intervention(a; inc)
for which the obstacle below is identied in [36].
3(9a :Ambulance; inc:Incident
Mobilized (a;inc)^(:Intervention(a; inc)UBrokenDown(a ))
The obstacle captures the situation in which an ambulance
does not intervene in an incident after mobilization becauseit broke down. A domain-consistent obstruction trace ex-
emplifying this is as follows.
0 :freport (inc 1)g;
1 :fallocate(a 1;inc1);assign (a1)g;
2 :fmobilize (a1;inc1);breakDown(a 1)g;
3 :fallocate(a 2;inc1);assign (a2);demobilize(a 1;inc1)g;
4 :fmobilize (a2;inc1)g;
5 :fintervene (a2;inc1)g
This illustrates a scenario where an ambulance is allocated
to a reported incident. When mobilized, it breaks down.
Another ambulance is allocated to the same incident and
intervenes. The obstacle is satised at time-point 3.
A domain-consistent non-obstruction trace may be one
in which the original ambulance does not break down and
successfully mobilizes and intervenes.
0 :freport (inc 1)g;
1 :fallocate(a 1;inc1);assign (a1)g;
2 :fmobilize (a1;inc1)g;
3 :fintervene (a1;inc1)g;
4 :fresolve (inc 1)g
Our approach generates alternative revisions to the goal
AmbulanceInterventionWhenMobilized in which a uent ex-
pression is added to AmbulanceInterventionWhenMobilized 's
current condition.
8a:Ambulance; inc:Incident:
Mobilized (a;inc)^:BrokenDown(a )
)33Intervention(a; inc)8a:Ambulance; inc:Incident:
Mobilized (a;inc)^2:BrokenDown(a )
)33Intervention(a; inc)
8a:Ambulance; inc:Incident:
Mobilized (a;inc)^(:BrokenDown(a )UIntervention(a; inc))
)33Intervention(a; inc)
The rst revision requires intervention whenever the am-
bulance is mobilized and not broken down. The second is
restricted to cases when the ambulance is mobilized and the
ambulance never breaks downs. The third is conditional on
the ambulance being mobilized, eventually intervening and
not breaking down prior to its intervention. The disjunction
of the last two correspond to the weakened version obtained
in [36], whilst the rst is not obtainable using existing ap-
proaches. We argue that the rst goal is preferable since the
second is not realizable and the third is conditional on the
occurrence of intervention which overlooks cases in which
intervention never occurs. With each solution, the learning
automatically propagates the changes to the rest of the goal
model where necessary, resulting in three alternative goal
models. For instance the revised goal model containing the
rst goal revision also includes revisions to the goal Ambu-
lanceMobilizedWhenAllocated ,
8a:Ambulance; inc:Incident:
Allocated(a; inc)^free(a )^time dist(inc:loc;a:loc)11
)9a0:Ambulance
Mobilized (a0;inc)^(:BrokenDown(a0))
and to four other goals in the model, with a (M;M0) = 6.
6.2 Goal Revision by Substitution
Consider the goal AmbulanceMobilizedFromMobOrder .
8a:Ambulance; inc:Incident
MobOrderIssued (a;inc))32Mobilized (a;inc)
Suppose D0includes
8a:Ambulance; inc:Incident:Allocated(a; inc)
):9inc0:Incident:inc06=inc^Allocated(a; inc0)
8a:Ambulance; inc:Incident:
Mobilized (a;inc))AmbMobilized (inc)
8628a:Ambulance; inc:Incident:Allocated(a; inc)
)AmbAllocated (inc)
8a:Ambulance; inc:Incident:
Intervention(a; inc))AmbIntervention (inc)
where AmbAllocated (reps. AmbIntervention ) is a uent ini-
tiated when an ambulance is allocated to (resp. intervened
in) incident incand terminated when no ambulance is allo-
cated to (resp. intervening in) incident inc. An obstacle to
the goal AmbulanceMobilizedFromMobOrder is
O=3(9a :Ambulance; inc:Incident
MobOrderIssued (a;inc)^22:Mobilized (a;inc))
An obstruction trace in ( O^D0) is as follows.
0 :freport (inc 1)g;
1 :fallocate(a 1;inc1);assign (a1);issueMobOrder (a1;inc1)g;
2 :fdeallocate(a 1;inc1);allocate(a 2;inc1);assign (a2)g;
3 :fmobilize(a 2;inc1)g;
4 :fintervene (a2;inc1)g
In this trace, an ambulance is deallocated soon after it
was allocated to an incident, thus not only obstructing the
goal AmbulanceMobilizedFromMobOrder but also its ances-
tors MobilizationOrderIssuedAtStation and AmbulanceMo-
bilizedWhenAllocated and AmbulanceInterventionWhenAllo-
cated . The non-obstruction trace (not shown here owing to
space limit) exemplies a scenario in which the ambulance
for which the mobilization order was issued mobilizes to-
wards the incident. The learning system identies the prob-
lem in the goal requiring the ambulance for which the mobi-
lization order was issued to mobilize. The impact of this ob-
struction aects the satisfaction of others goals in the model.
A resolution is automatically generated in which the Mobi-
lized(a,inc) literal in AmbulanceMobilizedFromMobOrder is
replaced with AmbMobilized (inc), which is true if there is
an ambulance that mobilizes to the incident.
8a:Ambulance; inc:Incident
(MobOrderIssued (a;inc))AmbMobilized (inc))
The change is automatically propagated to other goals
in the model, in this case requiring for instance the goal
AmbulanceInterventionWhenAllocated
8a:Ambulance; inc:Incident
(Allocated(a; inc))Intervention(a; inc))
to be substituted by
8a:Ambulance; inc:Incident
(Allocated(a; inc))AmbIntervention (inc))
The propagation resulted in changes to seven other goals
in the model with a (M;M0) = 18.
7. DISCUSSION AND RELATED WORK
Risk analysis is central to the requirements engineering
process (e.g., [36, 8, 16]). In this context, riskis the eect
of uncertainty on the achievement of system goals for which
software is to be developed. The term obstacle was intro-
duced in [30] to support informal scenario-based reasoning
about goal obstruction. They were then used to drive re-
quirements elaboration [7] de-idealizing the environment in
which the software is to run.
The problem of obstacle identication has been addressed
in dierent degrees of formality by many (e.g.,[33, 27, 16,
36, 6] among others). Obstacle identication is also inspired
by and strongly related to techniques from the domain of
system safety [24] such as with hazard analysis [23], fault
trees [24] and threat trees [32]. Risk assessment is grounded
in probabilistic or quantitative analysis [11] for which muchautomated reasoning support exists. In requirements en-
gineering, risk assessment has been developed extensively
(e.g. [16, 12]). Obstacle likelihood and criticality may be de-
termined quantitatively over obstacle renement trees and
goal renement trees, respectively [12, 31].
Obstacle resolution is a complex task not only because of
the multiple strategies [36] that can be used but also be-
cause resolution strategies cannot be applied locally to the
obstructed goal; resolution requires revising the goal model,
modifying higher-level goals and possibly changing the struc-
ture of the goal graph. Operators encoding risk control
strategies such as obstacle elimination (e.g., avoid the ob-
stacle or substitute the obstructed goal) and obstacle toler-
ance (e.g., mitigate consequences) restore the goal [36, 35]
but do not provide solutions for how to integrate the resolu-
tion patterns into a goal graph. Recently, [13] discussed the
properties that the introduction of countermeasures should
satisfy, such as progress towards completeness. However, a
major problem remains: how to introduce and propagate
countermeasures in a goal model while guaranteeing these
properties are satised.
Our approach presents a new dimension to the framework
described in [5], the integration of model checking with con-
straint-driven learning. Various instantiations of this frame-
work have been developed (e.g., [2, 3, 4, 6, 1] but all have
been concerned with local repairs; they do not address the
problem of propagating repairs through a specication.
8. CONCLUSION
This paper introduces an automated learning-based revi-
sion approach for resolving obstacles in goal models. The
method takes as input a goal model M, domain properties
Dand obstaclesfOigto goalsfGjginM. It computes traces
exemplifying obstruction occurrences and non-occurrences
inDusing an o-the-shelf model checker. From these traces,
it automatically generates revisions to the obstructed goals
and propagate the changes through the goal model. The
output is a set of alternative revised goal models that guar-
antee the elimination of the obstacle , the correctness of the
revised goal model and the preservation of non-obstruction
behaviour with minimal change to the original model. Our
approach provides a systematic solution to the problem of
which resolution strategy to deploy and how, by supporting
the automatic exploration of all possible acceptable resolu-
tions at once. It is generic in the sense that it may be used
with dierent trace generation methods. Although the pa-
per does the revision and propagation within the context of
obstacle resolution, the results indicate that the approach
can also be used to compute propagation of local changes
globally over a goal model. It could therefore be applied to
support other goal-oriented requirements engineering tasks.
Following on from this, we will extend this work to handle
other strategies such as obstacle tolerance and reduction,
and other forms of revisions that may aect the structure
of the goal model. We also plan to integrate techniques for
handling preferences amongst alternative revisions.
9. ACKNOWLEDGMENTS
We thank Duangtida Athakravi for her valuable support
with the learning-based revision system. This work is par-
tially funded by Alrajeh's Imperial College Junior Research
Fellowship award.
86310. REFERENCES
[1] D. Alrajeh and R. Craven. Automated error-detection
and repair for compositional software specications. In
Proceedings of the 12th International Conference on
Software Engineering and Formal Methods , pages
111{127, 2014.
[2] D. Alrajeh, J. Kramer, A. Russo, and S. Uchitel.
Learning operational requirements from goal models.
InProceedings of 31st International Conference on
Software Engineering, pages 265{275, 2009.
[3] D. Alrajeh, J. Kramer, A. Russo, and S. Uchitel.
Deriving non-zeno behaviour models from goal models
using ILP. Journal on Formal Aspects of Computing ,
22:217{241, 2010.
[4] D. Alrajeh, J. Kramer, A. Russo, and S. Uchitel.
Learning from vacuously satisable scenario-based
specications. In Proceedings of the 15th International
Conference on Fundamental Approaches to Software
Engineering, pages 377{393, 2012.
[5] D. Alrajeh, J. Kramer, A. Russo, and S. Uchitel.
Automated support for diagnosis and repair.
Communications of the ACM , 58(2):65{72, 2015.
[6] D. Alrajeh, J. Kramer, A. van Lamsweerde, A. Russo,
and S. Uchitel. Generating obstacle conditions for
requirements completeness. In Proceedings of the 34th
International Conference on Software Engineering ,
pages 705{715, 2012.
[7] A. Ant on and C. Potts. The use of goals to surface
requirements for evolving systems. In Proceedings of
the International Conference on Software Engineering ,
pages 157{166, 1998.
[8] Y. Asnar, P. Giorgini, and J. Mylopoulos. Goal-driven
risk assessment in requirements engineering.
Requirements Engineering, 16(2):101{116, 2011.
[9] D. Athakravi, D. Alrajeh, B. Broda, and A. Russo.
Inductive learning using constraint-driven bias. In
Proceedings of the 24th International Conference on
Inductive Logic Programming, 2014.
[10] D. Athakravi, D. Corapi, K. Broda, and A. Russo.
Learning through hypothesis renement using answer
set programming. In Proceedings of the 23rd
International Conference on Inductive Logic
Programming, pages 31{46, 2013.
[11] T. Bedford and R. Cooke. Probabilistic risk analysis:
foundations and methods . Cambridge University Press,
2001.
[12] A. Cailliau and A. van Lamsweerde. Assessing
requirements-related risks through probabilistic goals
and obstacles. Requirements Engineering,
18(2):129{146, 2013.
[13] A. Cailliau and A. van Lamsweerde. Integrating
exception handling in goal models. In Proceedings of
the 22nd International Requirements Engineering
Conference, pages 43{52, 2014.
[14] D. Corapi, A. Russo, and E. Lupu. Inductive logic
programming as abductive search. In Technical
Communications of the 26th International Conference
on Logic Programming, 2010.
[15] D. Corapi, A. Russo, and E. Lupu. Inductive logic
programming in answer set programming. In
Proceedings of the 21st International Conference on
Inductive Logic Programming, pages 91{97, 2011.[16] M. Feather and S. Cornford. Quantitative risk-based
requirements reasoning. Requirements Engineering,
8:248{265, 2003.
[17] A. Finkelstein and J. Dowell. A comedy of errors: The
london ambulance service case study. In Proceedings of
the 8th International Workshop on Software
Specication and Design, pages 2{4, 1996.
[18] D. Giannakopoulou and J. Magee. Fluent model
checking for event-based systems. In Proceedings of the
9th European Software Engineering Conference Held
Jointly with 11th ACM SIGSOFT International
Symposium on Foundations of Software Engineering ,
pages 257{266, 2003.
[19] A. Ingram. What is an electronic handbrake.
https://www.carwow.co.uk/blog/Electronic-parking-
brake-explained, 2014. [Online; accessed
15-Feb-2016].
[20] R. Kowalski and M. Sergot. A logic-based calculus of
events. New generation computing, 4(1):67{95, 1986.
[21] R. Koymans. Specifying Message Passing and
Time-Critical Systems with Temporal Logic , volume
651 of (LNCS) . Springer, 1992.
[22] E. Letier, D. Stefan, and E. T. Barr. Uncertainty, risk,
and information value in software requirements and
architecture. In Proceedings of the 36th International
Conference on Software Engineering, pages 883{894,
2014.
[23] N. Leveson. An approach to designing safe embedded
software. In Proceedings of the 2nd International
Conference on Embedded Software , pages 15{29, 2002.
[24] N. G. Leveson. Safeware: System Safety and
Computers . ACM, New York, NY, USA, 1995.
[25] J. Lloyd. Foundations of logic programming . Springer,
1984.
[26] M. S. Lund, B. Solhaug, and K. Stlen. Model-Driven
Risk Analysis: The CORAS Approach . Springer
Publishing Company, Incorporated, 1st edition, 2010.
[27] R. Lutz, A. Patterson-Hine, S. Nelson, C. R. Frost,
D. Tal, and R. Harris. Using obstacle analysis to
identify contingency requirements on an unpiloted
aerial vehicle. Requirements Engineering, 12:41{54,
2006.
[28] S. Muggleton and F. Marginean. Logic-based articial
intelligence. chapter Logic-based Machine Learning,
pages 315{330. Kluwer Academic Publishers, 2000.
[29] S. Muggleton and L. D. Raedt. Inductive logic
programming: Theory and methods. Journal of Logic
Programming, 19{20:629{679, 1994.
[30] C. Potts. Using schematic scenarios to understand
user needs. In Proceedings of the 1st conference on
Designing interactive systems: processes, practices,
methods, & techniques , pages 247{256, 1995.
[31] M. Sabetzadeh, D. Falessi, L. C. Briand, S. D. Alesio,
D. McGeorge, V. ~AEhjem, and J. Borg. Combining
goal models, expert elicitation, and probabilistic
simulation for qualication of new technology. In
Proceedings of the IEEE 13th International
Symposium on High-Assurance Systems Engineering ,
pages 63{72, 2011.
[32] B. Schneier. Secrets and Lies: Digital Security in a
Networked World . Wiley, 2000.
864[33] A. Sutclie, N. Maiden, S. Minocha, and D. Manuel.
Supporting scenario-based requirements engineering.
IEEE Transactions on Software Engineering ,
24:1072{1088, 1998.
[34] C. K. F. Tang and E. Ternovska. Model checking
abstract state machines with answer set programming.
InProceedings of the 12th International Conference on
Logic for Programming, Articial Intelligence, and
Reasoning , pages 443{458, 2005.
[35] A. van Lamsweerde. Requirements Engineering: From
System Goals to UML Models to Software
Specications . Wiley, 2009.
[36] A. van Lamsweerde and E. Letier. Handling obstacles
in goal-oriented requirement engineering. IEEE
Transactions on Software Engineering ,
26(10):978{1005, 2000.
[37] S. Wrobel. First order theory renement. In L. React,
editor, Advances in Inductive Logic Programming,
pages 14{33. IOS Press, Amsterdam, 1996.
865