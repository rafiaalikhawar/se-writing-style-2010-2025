Conc-iSE: Incremental Symbolic Execution of
Concurrent Software
Shengjian Guo, Markus Kusano
Department of ECE
Virginia Tech
Blacksburg, VA, USAChao Wang
Department of CS
University of Southern California
Los Angeles, CA, USA
ABSTRACT
Software updates often introduce new bugs to existing code b ases.
Prior regression testing tools focus mainly on test case sel ection
and prioritization whereas symbolic execution tools only h andle
code changes in sequential software. In this paper, we propo se the
ﬁrst incremental symbolic execution method for concurrent soft-
ware to generate new tests by exploring only the executions a ffected
by code changes between two program versions. Speciﬁcally, we
develop an inter-thread and inter-procedural change-impa ct anal-
ysis to check if a statement is affected by the changes and the n
leverage the information to choose executions that need to b e re-
explored. We also check if execution summaries computed in t he
previous program can be used to avoid redundant exploration s in
the new program. We have implemented our method in an incre-
mental symbolic execution tool called Conc-iSE and evaluated it
on a large set of multithreaded C programs. Our experiments s how
that the new method can signiﬁcantly reduce the overall symb olic
execution time when compared with state-of-the-art symbol ic exe-
cution tools such as KLEE.
CCS Concepts
•Software and its engineering →Software veriﬁcation and vali-
dation; Software testing and debugging; Software evolution;
Keywords
Symbolic execution, Concurrency, Partial order reduction , Weakest
precondition
1. INTRODUCTION
As software evolves, updates made from the addition of new fe a-
tures or patches may introduce new bugs. While some regressi on
testing tools can leverage code changes between two softwar e ver-
sions to reduce the testing cost, they focus primarily on sel ection
and test case prioritization as opposed to the creation of ne w test
cases. In contrast, symbolic execution is a technique for au tomat-
ically generating new tests, and, more recently [30, 32, 46] , has
been used in regression testing to reduce the overall cost fo r se-
quential software testing. Speciﬁcally, prior work uses a c onserva-
tive static analysis to estimate the impact of the code chang es andNew Program ( P′) Old Program ( P)
Concurrent Change
Impact AnalysisSummaries of P
transferred to P′
Symbolic
ExecutionPruning the
Redundant State
Current Input
(in,sch)Generate New
Input(in′,sch′)
Figure 1: Summary-based incremental symbolic execution.
then leverage the information to avoid re-executing progra m paths
that are not affected by these code changes. However, these m eth-
ods only handle code changes in sequential software. Furthe rmore,
they rely on an overly conservative analysis to estimate the change
impact, without making use of the more accurate information avail-
able from previous symbolic execution runs.
In this paper, we propose Conc-iSE : an incremental symbolic
execution method for concurrent programs. Figure 1 shows th e
overall ﬂow of our new method. We take old ( P) and new ( P′)
program versions, together with a set of execution summarie s of
P, as input and iteratively explore new execution paths throu ghP′.
As we will show, we use supplementary information from P(the
execution summaries) as well as code changes between PandP′
to perform the incremental analysis.
The standard and non-incremental symbolic execution proce dure
is shown in the lower half of Figure 1, which starts from an ar-
bitrary initial test (in,sch)ofP′and repeatedly generates new
tests forP′. Here,indenotes the data input and schdenotes the
thread interleaving schedule. We assume P′is a deterministic pro-
gram whose execution is completely decided by the pair (in,sch).
During symbolic execution, new states are generated to expl ore al-
ternate branches and alternate thread interleaving schedu les. For
each new state, the symbolic execution engine generates a ne w pair
(in′,sch′)containing the data input and thread schedule to reach
the new state. In the non-incremental approach, no informat ion
about previously explored executions in Pand code changes made
toP′are used to determine if a state is redundant: program execu-
tions equivalent to behavior in Pare re-explored in P′.
Incremental symbolic execution, in contrast, considers tw o pro-
gram versions PandP′while assuming Pis a prior version that
has already been explored symbolically. The goal is to explo re
only the new behavior in P′. Prior works on incremental sym-
bolic execution for sequential programs [30, 32, 46] used a f orward
change-impact analysis, built on the idea of program slicin g [43],
to determine if a statement in P′was affected by a modiﬁcation;
only affected portions of the code in P′were explored again during
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ASE’16 , September 3–7, 2016, Singapore, Singapore
c2016 ACM. 978-1-4503-3845-5/16/09...$15.00
http://dx.doi.org/10.1145/2970276.2970332
531
symbolic execution. Our ﬁrst insight is that performing a ch ange-
impact analysis using a conservative static analysis alone often re-
sults in the testing of redundant executions. This is becaus e a con-
servative static analysis, such as program slicing, ignore s the actual
values of variables in the program. As we will show in Section 2,
even if a statement is modiﬁed (from PtoP′), it may be that paths
affected by this modiﬁcation are equivalent to some paths in the pre-
vious version. To deﬁne a more accurate equivalence class of execu-
tion paths, we make use of the execution summaries from Pwhile
testingP′, as opposed to performing only a conservative change-
impact analysis. At a high level, the execution summaries, d eﬁned
at each global control state, capture the set of all explored execu-
tions starting from s. The summaries are computed backwardly
using a weakest-precondition computation.
We also propose an inter-thread and inter-procedural chang e im-
pact analysis for handling both sequential and concurrent p rograms.
It consists of a forward analysis and a backward analysis. Th e for-
ward change-impact analysis computes the set of statements that
may be affected by code changes from PtoP′; this is used to avoid
executing portions of P′unaffected by statements that are changed
fromPtoP′. The backward change-impact analysis computes the
set of statements that may affect statements that are changed from
PtoP′; this is used to determine if an execution summary from
the old version Pcan be carried over to the new version P′. In-
tuitively, in both cases, if a code modiﬁcation in P′only affects a
small number of statements, then much of P′is the same as P.
The combination of execution summaries and change-impact a n-
alysis, as well as their interaction with the baseline symbo lic ex-
ecution procedure, is shown in Figure 1. Recall that prior in cre-
mental symbolic execution techniques [30, 32, 46] only hand led se-
quential programs, whereas Conc-iSE is the ﬁrst incremental sym-
bolic execution algorithm capable of handling concurrent p rograms.
Speciﬁcally, when a new state in P′is generated, we check both the
change-impact information and the execution summaries to s ee if
the state is in the unmodiﬁed section of the program, or if it i s equiv-
alent to some previously explored execution in P. If either condi-
tion is true, then the new state is redundant and can be skippe d.
Conc-iSE differs from the prior works on regression testing of
multithreaded programs [17, 49, 38]. In Jagannath et al. [17 ] and
Yu et al. [49], for example, the primary focus was on test case selec-
tion and test case prioritization, i.e., to detect certain c oncurrency
bugs quicker by heuristically selecting test cases and sche duling
them in certain orders, as opposed to generating new test cas es.
In contrast, our method focuses on making symbolic executio nin-
cremental , which will beneﬁt test case generation. Our method
also differs from the work by Terragni et al. [38], which symb ol-
ically analyzes the alternative interleavings of some conc rete exe-
cutions based on the trace logs. Unlike our method, it does no t
perform symbolic execution based test input generation to e xplore
both intra-thread program paths and inter-thread interlea vings.
We have implemented our method in a software tool using LLVM [ 23]
and Cloud9 [5]. We used LLVM to implement our forward and
backward change-impact analysis algorithms, and used the K LEE
symbolic virtual machine in Cloud9 as the baseline to implem ent
our incremental symbolic execution algorithm. We also exte nded
KLEE to robustly handle POSIX thread routines and implement
the state-of-the-art dynamic partial-order reduction (DP OR) tech-
nique [9]. We evaluated Conc-iSE on a large set of multithreaded
C programs, including benchmarks from the Software Veriﬁca tion
Competition [37] and real-world applications that are open -source
implementations of non-blocking data structures [29]. In t otal, our
benchmarks contain 14 programs, with a total of 70 different ver-
sions and 34,926 lines of code. Empirically, we showed our me thod
can signiﬁcantly reduce the overall testing time when compa red
with state-of-the-art symbolic execution techniques.
To sum up, this paper makes the following contributions:x = 15, y = 5;
/**[Thread 1] **/
1: a = x;
2: y = 10;
3:
/**[Thread 2] **/
4: x = 10;
5: b = y;
6:/**[Thread 1] **/
1: a = x;
2: y = 10;
3:
/**[Thread 2] **/
4: x = 5; //modified
5: b = y;
6:
assert(a>=10);
assert(b>=5);
Figure 2: Example program: old (left) and new (right) versio ns.
(a≥10)x= 10 ;n1
n2
n4
n7n5n3
n6
n8
n9x= 10 ;
y= 10 ;
y= 10 ;b=y;b=y;y= 10 ;
π1π4
π5x= 10 ;
b=y;a=x;
a=x;
a=x; π2
π3π6
Figure 3: Interleaved executions of old version: π1,...,π 6.
•We propose an incremental symbolic execution algorithm ca-
pable of handling code changes in both sequential and con-
current programs.
•We develop a new execution summary-based algorithm for
pruning away redundant paths and thread interleavings dur-
ing incremental symbolic execution.
•We implement our new method in a software tool and evalu-
ate it on a large set of benchmarks to demonstrate its effec-
tiveness at decreasing regression testing time.
2. MOTIV ATING EXAMPLES
In this section, we illustrate the main ideas behind our new m ethod.
2.1 Pruning with Change-Impact Analysis
Consider the example in Figure 2. The old program on the left-
hand side has two threads accessing the shared variables xandy.
They are initialized to 15 and 5, respectively. After execut ing both
threads, the two assertions are checked. The new program is s hown
on the right-hand side; the only modiﬁcation between the two pro-
grams is on Line 4, where x=10 is changed to x=5. First, note that
although the modiﬁcation is in the second thread, due to the s haring
of variable x, Line 1 in the ﬁrst thread is also affected. Such im-
pacted instructions cannot be identiﬁed by existing algori thms [30,
32, 46] since they were not designed for analyzing concurren t pro-
grams; our new change-impact analysis solves this problem.
Second, there are six possible executions of the old program , as
shown in the abstract state transition graphs in Figure 3. St ate-of-
the-art partial-order reduction (POR) techniques [11, 9, 2 0] can re-
duce the number of executions to four. Our method does even be tter
by reducing the number of executions to two. Speciﬁcally, in Fig-
ure 3 each node denotes a global control state, e.g., n1= (1,4)
means Thread 1 is at Line 1 and Thread 2 is at Line 4, while
n2= (2,4)means they are at Lines 2 and 4. After POR, only
four executions remain as shown in the left-hand-side execu tion
tree in Figure 4. The reason why π2andπ6are skipped is because
they are equivalent to π1andπ5, respectively. That is, executing
the two independent instructions y= 10 andx= 10 in different
orders lead to the same result.
532n1
n2
n4n3
n6y= 10 ;
n5
n7 n7 n7 n8 n8a=x;
n8a=x;
n5
x= 10 ;x= 10 ;
b=y;y= 10 ;
y= 10 ;
n9 n9 n9 n9 n9 n9
(a≥10) ( a≥10)b=y;y= 10 ;b=y;
(a≥10) ( a≥10)
π1 π4 π3a=x; x= 10 ;
b=y;
(a≤10)
π5b=y;b=y;
y= 10 ;y= 10 ;
(a≥10)(modiﬁed)x= 5;
(modiﬁed)
x= 5;
(modiﬁed)n1
n2
n4n3
n6y= 10 ;
n5
n7 n7 n7 n8 n8a=x;
n8a=x;
n5
b=y;y= 10 ;
y= 10 ;
n9 n9 n9 n9 n9 n9
(a≥10) ( a≥10) ( a≥10) ( a≤10)b=y;b=y;
(a≥10) ( a≥10)
π1a=x;
b=y;
y= 10 ;
y= 10 ;b=y;
y= 10 ;x= 5;
π4
Figure 4: Executions explored by incremental symbolic exec ution in the old program (left) and the new program (right).
By leveraging the concurrent change-impact analysis, our m ethod
can identify even more redundant executions than POR. Speci ﬁ-
cally, since the code change on Line 4 does not impact Line 2 or
Line 5 or assert(b>=5) , we do not need to re-explore the different
execution orders of y= 10 andb=y. Because of this reason,
as shown in the right-hand-side tree in Figure 4, our method c an
reduce the four executions to two ( π1andπ4).
In this work, we assume that assertions are embedded in the in di-
vidual threads. As such, the assertion conditions always re fer to lo-
cal variables, or local copies of global variables, which is consistent
with the assumptions made in prior works on POR [11, 9, 20]. It
is worth pointing out that, in this example, the assertion co nditions
are also important: if the assertion were assert(a>=b) , then it is no
longer safe to skip π3andπ5. Details of our new change-impact
analysis algorithm and its application to incremental symb olic exe-
cution are presented in Section 5.
2.2 Pruning with Execution Summary
In addition to leveraging the forward change-impact analys is, we
also propose an orthogonal pruning technique based on a back ward
change-impact analysis. That is, instead of computing the s et of
instructions that may be affected by the changed instructions , we
compute the set of instructions that may affect the changed instruc-
tions . Details of the backward change-impact analysis and its ap-
plication are presented in Section 6. Here, we brieﬂy illust rate the
main ideas using an example.
Consider the two versions of a sequential program in Figure 5 ,
where the old version is on the left, and the new version is on t he
right. The only modiﬁcation is on Line 1; the condition is cha nged
from(x >0)to(x≥0). From the forward change-impact analy-
sis described in Section 2.1, or for that matter, existing me thods for
incremental symbolic execution [30, 32, 46], we know that al l the
other lines in the new program are affected by the change. The re-
fore, it seems that no redundant executions can be pruned awa y.
However, if we divide the initial program state into three su bsets,
denoted(x >0),(x= 0) , and(x <0), respectively, then it is
clear that only when (x= 0) , the modiﬁed program behave differ-
ent from the original program. In the old version, such case w as
handled by paths π3andπ4, but in the new version, it is handled by
pathsπ1andπ2. Therefore, instead of re-exploring all four paths,
we only need to re-explore π1andπ2.
The question then is how to ﬁgure out, algorithmically, that paths
π3andπ4are indeed redundant. Our solution in Conc-iSE is to
compute, for each global control state s, a summary of all the ex-
plored executions starting from sin the old program version. For
example, the summary at n4, with respect to assert(b/ne}ationslash=0), would
bePS[n4] = (y >0)∧(x/ne}ationslash= 1)∨(y≤0)∧(x/ne}ationslash= 3) . This
summary is created from the union of the weakest preconditio n of
(b/ne}ationslash= 0) along the two outgoing paths.1: if (x>0)
2: a = x+2;
3: else
4: a = x-2;
5: if (y>0)
6: b = a+1;
7: else
8: b = a-1;
9: assert(b!=0);1: if (x>=0) //modified
2: a = x+2;
3: else
4: a = x-2;
5: if (y>0)
6: b = a+1;
7: else
8: b = a-1;
9: assert(b!=0);
b=a−1;n1
n2
n5n4
n5a=x+2;
n6 n8(y≤0)
n9 n9b=a+1;
π1π4(x >0)
π2n6
(b/negationslash= 0)
π3n8a=x−2;
n9
(b/negationslash= 0) ( b/negationslash= 0)(y >0)(y >0)(y≤0)or(x= 0)(x <0)
(b/negationslash= 0)(moved)
b=a+1;b=a−1;
n9
Figure 5: Although all instructions are impacted by the code
change on Line 1, not all four paths need to be re-explored.
Since the code changes on Line 1 does not affect the aforemen-
tioned weakest precondition computation, the summary can b e car-
ried over to the new program. During the analysis of the new pr o-
gram, we can stop an execution as soon as the path condition, d e-
notedpcon[n4] = (x <0), falls within the set PS[n4]of explored
executions. This early termination is safe because if pcon[n4]∧
¬PS[n4]is unsatisﬁable, re-exploring the executions starting fro m
n4would not lead to any new error.
3. PRELIMINARIES
In this section, we establish the notation and review our bas eline
symbolic execution algorithm for multithreaded programs.
3.1 Multithreaded Programs
We assume each program Pconsists of a ﬁnite set of threads,
{T1,...,T m}, and a set SVar of shared variables. Each thread
Ti, where1≤i≤m, has a set LVariof local variables. In-
structions from different threads are executed in an interl eaved fash-
ion. Each time an instruction stis executed, it produces an event
e=/an}bracketle{ttid,st,l,l′/an}bracketri}ht, wheretidis the thread id, while landl′are
the program locations before and after executing st. If there are
multiple execution instances of st, each instance is represented by
a different event.
533A concrete state of the program Pconsists of the program loca-
tionliof every thread Ti, where1≤i≤m, and the values of all
variables in SVar andLVari. In contrast, the abstract state, or the
so-called global control state (GCS) s=/an}bracketle{tl1,...,l m/an}bracketri}ht, consists of
the program locations only. In other words, each GCS represe nts
the set of all concrete states that share the same program loc ations
but have potentially different values of the program variab les.
Letvlandcondlbe the thread-local variables and conditions,
whilevgandcondgbe the shared (global) variables and conditions,
respectively. Depending on whether an event accesses share d vari-
ables, we classify it into one of the following categories:
•α-operation: a local assignment vl:=expl;
•β-operation: a local branch assume(condl);
•γ-operation: a global operation deﬁned as either
–a global write vg:=explor readvl:=vg; or
–a thread synchronization operation.
Given a program P, the set of all possible executions is captured
by a generalized interleaving graph (GIG) [12], where nodes are
global control states and edges are events. The root node cor re-
sponds to the program’s initial state. Leaf nodes correspon d to the
end of normal/faulty executions. Each internal node may hav e one
outgoing edge corresponding to an α-operation, koutgoing edges
corresponding to β-operations, or koutgoing edges where k≥2
is the number of enabled γ-operations from different threads.
We make a distinction between thread-local operations and g lobal
operations since they have different impacts during symbol ic exe-
cution. Global operations ( γ) directly affect the thread interleav-
ing order, while β-operations directly affect the path taken by each
thread. In contrast, α-operations do not directly affect the selection
of any program path or thread interleaving.
Without loss of generality, we assume all conditional expre ssions
use local variables or local copies of global variables [11] . The ex-
ecution of an if(c)-else statement, for example, can be repre-
sented byassume(c)if we take the then-branch, and assume( ¬c)
if we take the else-branch. Properties of interest are represented by
assertions of the form assert(c) , which means if(!c)abort .
Therefore, we can use the special event abort to denote faulty pro-
gram termination and halt to denote normal program termination.
3.2 Baseline Symbolic Execution
Following the majority of prior works on symbolic execution ,
we assume that the program under test is terminating and thus each
execution has a ﬁnite length [3]. We also assume the program i s
deterministic, i.e., the sequence of instructions will be c ompletely
determined by (in,sch), whereinis the data input and sch is
the thread schedule. Therefore, (in,sch)implicitly represents a
concrete execution of a program. In contrast, π= (∗,sch)repre-
sents a symbolic execution where ∗is the symbolic data input and
sch=e1...enis an order of the executed events.
Algorithm 1 shows the baseline procedure for concurrent pro -
grams, which follows prior works such as [33, 5, 12]. Initial ly,
EXPLORE is invoked with the symbolic initial state s0. Then, de-
pending on the type of the current state s, we either explore a thread-
local branch or schedule a context switch. A pivot point is a GIG
node with multiple outgoing edges. A node corresponding to β-
operation is called a branching pivot point (b-PP); a node corre-
sponding to γ-operation is called an interleaving pivot point (i-PP).
Speciﬁcally, if sis an i-PP node, we recursively explore the next γ
event from each thread; if sis ab-PP node, we recursively explore
the next thread-local branch; and if sis a non-branching node, we
explore the unique next event. Upon reaching a leaf node the c ur-
rent execution ends. At this point, the procedure pops the cu rrent
statesfrom the stack Sbefore returning from E XPLORE(s).
During backtracking, we always stop at the last unexplored p ivot
point (i-PP or b-PP) and try to ﬂip a previous decision to comp ute a
new execution. By ﬂipping a previous decision at an i-PP node , weget(in,sch′), wheresch′is a new thread schedule. By ﬂipping a
previous decision at a b-PP node, we get (in′,sch), wherein′is a
new data input. In both cases, the new execution will be the sa me
as the previous one up to the pivot point. After the pivot poin t,
however, it will be an uncontrolled execution.
Algorithm 1 Baseline Symbolic Execution.
Initially: Stack S={s0}; run E XPLORE (s0) with the symbolic initial state s0.
1:EXPLORE (s)
2:S.push(s);
3: if(sis an i-PP node)
4: while (∃t∈(s.enabled\s.done))
5: s′←NEXTSTATE (s, t);
6: EXPLORE (s′);
7: s.done←s.done∪{t};
8: else if (sis a b-PP node)
9: while (∃t∈(s.branch\s.done))
10: s′←NEXTSTATE (s, t);
11: EXPLORE (s′);
12: s.done←s.done∪{t};
13: else if (sis an internal node)
14: s′←NEXTSTATE (s, t);
15: EXPLORE (s′);
16: else
17: //end of execution – do nothing;
18: S.pop();
19:
20: NEXTSTATE (s, t)
21: lets=/a\}bracketle{tpcon,M,enabled,branch,done /a\}bracketri}ht;
22: if(tishalt )
23: s′←normal_end_state;
24: else if (tisabort )
25: s′←faulty_end_state;
26: else if (tisassignment v:=exp )
27: s′←/a\}bracketle{tpcon,M[v/mapsto→exp]/a\}bracketri}ht;
28: else if (tisassume (c)andM[pcon∧c]is satisﬁable )
29: s′←/a\}bracketle{tpcon∧c,M/a\}bracketri}ht;
30: else
31: s′←infeasible_state;
32: returns′;
We assume that each symbolic program state s∈Sis a tuple
/an}bracketle{tpcon,M,enabled,branch,done/an}bracketri}ht, wherepcon is the path con-
dition from s0tos,Mis the memory map, enabled is the set of
γ-events when sis an i-PP node, branch is the set of β-events when
sis a b-PP node, and done is the set of explored ( βorγ) events.
The initial state s0is/an}bracketle{ttrue,Minit,.../an}bracketri}ht, wheretrue means the
state is always reachable, and Minitis the initial memory map.
Each instruction ( t) is executed by N EXTSTATE(s,t)as follows:
•Iftishalt, the current execution ends without error.
•Iftisabort , we have detected an error.
•Iftis an assignment v:=exp , we update the memory map M
by changing the content of vtoexp.
•Iftisassume(c) , we set the path condition to ( pcon∧c).
4. THE INCREMENTAL SYMBOLIC EXE-
CUTION ALGORITHM
Our incremental procedure, shown in Algorithm 2, has two sig -
niﬁcant differences from the baseline procedure in Algorit hm 1.
For brevity, we only highlight the parts that are different.
First, the input has changed. Instead of taking one program a s in-
put, we take both the old and the new programs ( PandP′). Prior
to our symbolic execution of the new program P′, we compute the
forward impacted set ISfwdand the backward impacted set ISbwd.
In addition, we transfer the table PSof execution summaries com-
puted inPto the new program P′. For each state s, the set of
explored executions starting from sis denoted PS[s].
Second, we add Lines 27–29 and 32–34 inside N EXTSTATE . They
leverageISfwd,ISbwd, andPS[s]to decide, at each symbolic execu-
tion step ( st−→s′), if all executions starting at the next state s′
534are redundant. Speciﬁcally, if t.inst/ne}ationslash∈ISfwd, the current branching
statement is not in the impacted set. Since which branch to ex ecute
atsis immaterial, if one of the branches has previously been ex-
plored, we can force an early termination of the current exec ution.
Similarly, if t.inst/ne}ationslash∈ISbwd, the weakest precondition computa-
tion, upon which the execution summary is computed, would no t
be affected by the code changes. Therefore, we can carry the s um-
maryPS[s]fromPtoP′. If the current path condition pcon , in
the modiﬁed program, is subsumed by PS[s]then continuing the
execution from swould lead to no new errors. In such case, we can
force an early termination of the current execution.
Algorithm 2 Incremental Symbolic Execution.
ISfwd←COMPUTE FORWARD IMPACTED SET(P, P′);
ISbwd←COMPUTE BACKWARD IMPACTED SET(P, P′);
PS[s]←the summary at scomputed in previous program P;
...
20: NEXTSTATE (s, t)
21: lets=/a\}bracketle{tpcon,M,enabled,branch,done /a\}bracketri}ht;
22: if(tishalt )
23: s′←normal_end_state;
24: else if (tisabort )
25: s′←faulty_end_state;
26: else if (tisassignment v:=exp )
27: if(t.inst/\e}atio\slash∈ISbwd andpcon=⇒PS[s])
28: s′←early_termination_state;
29: else
30: s′←/a\}bracketle{tpcon,M[v/mapsto→exp]/a\}bracketri}ht;
31: else if (tisassume (c)andM[pcon∧c]is satisﬁable )
32: if(t.inst/\e}atio\slash∈ISfwd and another branch has been explored )
33: s′←early_termination_state;
34: else
35: s′←/a\}bracketle{tpcon∧c,M/a\}bracketri}ht;
36: else
37: s′←infeasible_state;
38: returns′;
Example. For the program in Figure 5, the code changes on Line 1
would only invalidate the summary PS[n1]. Therefore, although
we cannot force an early termination at n1, we can leverage the
summary at other nodes to prune away redundant executions. I n
particular, when the execution reaches either n2orn4, we can ter-
minate the execution immediately. This is because both pcon[n2]∧
¬PS[n2]andpcon[n4]∧¬PS[n4]are unsatisﬁable. Speciﬁcally,
PS[n2] = (y >0)∧(x/ne}ationslash=−3)∨(y≤0)∧(x/ne}ationslash=−1)
PS[n4] = (y >0)∧(x/ne}ationslash= 1)∨(y≤0)∧(x/ne}ationslash= 3)
Furthermore, pcon[n2] = (x≥0), andpcon[n4] = (x <0).
Therefore, we can check pcon[n2]∧¬PS[n2]as follows:
= (x≥0)∧((y≤0)∨(x=−3))∧((y >0)∨(x=−1))
=false
We can also check pcon[n4]∧¬PS[n4]as follows:
= (x <0)∧((y≤0)∨(x= 1))∧((y >0)∨(x= 3))
=false
The above checks indicate that no new errors can be detected b y
continuing from n2andn4. Therefore, we terminate the symbolic
execution immediately without exploring the remaining pat hs.
In the remainder of this paper, we will present our algorithm s for
conducting the forward and backward change-impact analysi s, as
well as the redundancy pruning based on execution summaries .
5. CHANGE-IMPACT ANALYSIS
The ﬁrst important component of our incremental analysis is the
detection and characterization of code changes, called the change-
impact analysis (CIA) [24]. The identiﬁcation of code chang es re-quires comparison of two program versions by matching their rep-
resentations, often in the form of ﬂow graphs [31], tree repr esenta-
tions [47], or locations in source ﬁles.
5.1 Computing the Impacted Sets
Our new change-impact analysis for concurrent programs tak es
two program versions PandP′as input and returns two impacted
sets. One impacted set is ISfwd, the forwardly impacted set, while
the other impacted set is ISbwd, the backwardly impacted set.
We follow Person et al. [30] to deﬁne three types of code chang es:
deleted, added, and modiﬁed. Our computation of the two impa cted
sets consists of several steps.
Algorithm 3 Forward and Backward Change-impact Analysis.
∆diﬀ←Diff (P,P′);
∆map←Map (P,P′,∆diﬀ);
1:COMPUTE FORWARD IMPACTED SET(P, P′)
2:AIfwd←{} ;MIfwd←{} ;DIfwd←{} ;
3: for each (inst∈∆diﬀ)
4: if(inst isadded )
5: AIfwd←AIfwd∪FwdDependencyAnalysis( P′,inst );
6: else if (inst ismodiﬁed )
7: MIfwd←MIfwd∪FwdDependencyAnalysis( P′,inst );
8: else if (inst isdeleted )
9: impacted←FwdDependencyAnalysis( P,inst );
10: for each (st∈impacted )
11: st′←QueryMap ( ∆map,st);
12: DIfwd←DIfwd∪FwdDependencyAnalysis( P′,st′);
13: returnAIfwd∪MIfwd∪DIfwd;
14: COMPUTE BACKWARD IMPACTED SET(P, P′)
15: AIbwd←{} ;MIbwd←{} ;DIbwd←{} ;
16: for each (inst∈∆diﬀ)
17: if(inst isadded )
18: AIbwd←AIbwd∪BwdDependencyAnalysis( P′,inst );
19: else if (inst ismodiﬁed )
20: MIbwd←MIbwd∪BwdDependencyAnalysis( P′,inst );
21: else if (inst isdeleted )
22: impacted←BwdDependencyAnalysis( P,inst );
23: for each (st∈impacted )
24: st′←QueryMap ( ∆map,st);
25: DIbwd←DIbwd∪BwdDependencyAnalysis( P′,st′);
26: returnDIbwd∪MIbwd∪DIbwd;
First, we compare PandP′using a lightweight difftool that
computes the set ∆diﬀof changed instructions (added, deleted, or
modiﬁed). Since the remaining instructions exist in both pr ograms,
we construct a map ∆mapthat maps every unchanged instruction
inst∈Pto its counterpart inst′∈P′.
Second, for each added instruction, denoted instadd∈∆diﬀ, we
perform a forward control- and data-dependency analysis in P′to
identify all instructions depending on instadd(Line 5). Details of
this analysis are presented in the next subsection. We also p erform
a backward control- and data-dependency analysis in P′to identify
all instructions that instadddepends on (Line 18). We denote the
set of instructions as AI, represented separately as AIfwdandAIbwd.
Third, for each modiﬁed instruction, denoted instmod∈∆diﬀ,
we perform a forward control- and data-dependency analysis inP′
to identify the instructions depending on instmod (Line 7). We
also perform a backward control- and data-dependency analy sis to
identify all instructions that instmod depends on (Line 20). We
denote the set of instructions as MI.
Fourth, for each deleted instruction instdel∈∆diﬀ, we perform
the forward control- and data-dependency analysis to compu te the
set of instructions depending on instdel(Line 9). We also perform
the backward control- and data-dependency analysis to comp ute
the set of instructions that instdeldepends on (Line 22). For each
instruction in this set, which is in program P, we retrieve its coun-
terpart in P′by querying the ∆map; the results form a new set DI.
Finally, the union of AI,MI, andDIforms the complete set of
impacted instructions, denoted ISfwdandISbwd, respectively.
535/**[Thread 1] **/
1:x += 2;
2: z = x + 1;
3:y = x - 1 ;
4: if (z>0)
5: z = 0;
6: else
7: z-;/**[Thread 2] **/
8: z++;
9:x -= 2;
10:if (x==0)
11:y += 1; //modified
12: else
13: z++;
14:assert(y != 2);
Figure 6: Example for our new change-impact analysis.
Algorithm 3 shows the actual pseudocode formalizing the abo ve
descriptions. For ease of comprehension, we have divided th e com-
putation of ISfwdandISbwdinto two separate routines. These rou-
tines, in turn, rely on two subroutines (described in Sectio n 5.2)
to perform the inter-thread and inter-procedural control- and data-
dependency analysis.
Example. Figure 6 shows a program Pthat, starting with x=
y=z= 0, may violate the assertion on Line 14 by executing
Lines 1-3 and then 9-11. To ﬁx the violation, we plan to change
Line 11 from y+=1 toy+=2 to obtain the new program P′. Dur-
ing the change-impact analysis, ∆diﬀ= {11}, and ∆map= {1-1,
2-2, ..., 14-14}. Since the type of change is modiﬁed , we only need
to compute MI. Speciﬁcally, from the forward analysis, we ob-
tainMIfwd= {11, 14}, which means the modiﬁcation may affect
Lines 11 and 14. From the backward analysis, we obtain MIbwd=
{1, 3, 9, 10, 11}, which means they may affect the statement on
Line 11. This is because Line 11 is control-dependent on Line 10
due to variable x, and data-dependent on Lines 3 and 11 due to
variabley. Line 10, in turn, is data-dependent on Lines 1 and 9.
5.2 Computing the Dependency Relations
The dependency relations are computed by an inter-thread an d
inter-procedural static analysis. We follow [8, 15] to comp ute the
control-dependencies using post-dominance, and data-dep endencies
by the transitive closure of use-def chains. Our main contri butions,
however, are reasoning about these dependencies in the conc urrent
setting (which also works on sequential programs), and adap ting
them to the forward/backward change-impact analysis.
We say that a statement s2is control-dependent on s1if the com-
putation of s1determines whether s2is executed. For example, in
if(c)x++; the statement x++ is control-dependent on if(c)
(speciﬁcally, on the value of the predicate c). On the other hand,
s4is data-dependent on s3if the computation of s3inﬂuences the
computation of s4. For example, in a=x;b=a+y; the statement
b=a+y is data-dependent on the statement a=x since the value of
adetermines the value of b.
To be conservative, our baseline dependency analysis is ﬂow -
insensitive, which has the advantage of being scalable and c on-
sidering all ordering of statements. Since any statement fr om any
thread can effectively execute at any time, this over-appro ximates
the actual scheduling constraints, thereby ensuring the so undness
of our analysis for multithreaded programs. However, using a ﬂow-
insensitive analysis, while sound, may result in false depe ndencies
across threads. Consider the program in Figure 7: thread one reads
the value of xand then creates thread two which writes to x. In a
ﬂow-insensitive analysis, the read in thread one is data-de pendent
on the write in thread two. But, the write can never be visible to
thread one, since thread two does not exist until after the re ad.
To capture this situation, we augment our baseline dependen cy
analysis with a happen-before relation. We say that a statement s1
happens before a statement s2if on all program executions s1exe-
cutes before s2, e.g., the statement create(thread2) happens
beforex = 5 . Toward this end, we reﬁne the data-dependency
analysis as follows: if s1happens-before s2thens1must not be1int x = 0;
2void thread1() {
3int t1 = x;
4create(thread2);
5}
6void thread2() {
7x = 5;
8}
Figure 7: Example for false data-dependencies across threa ds.
data-dependent on s2. This approach is comparable to recent works
on using happens-before to reﬁne data race detection [28, 27 ]. It is
sound because the happens-before relation ensures there do es not
exist a program path from s2tos1, and thus s1cannot witness
the effect of s2. Currently, we deduce happens-before constraints
statically from the thread creation sites.
In the implementation, we adopt the Datalog-based declarat ive
program analysis framework [44, 22, 2]: We ﬁrst build C TRLDEP
and D ATADEPrelations, where (a,b)∈DATADEPmeans the vari-
ableais data-dependent on b. We traverse the control ﬂow graph to
generate the set of input items for these relations. We use th e struc-
ture of each individual instruction to determine the contro l- and
data-dependency relations associated with it. For brevity , we show
only how we handle the binary operation r=opv1v2, wherer,v1,
andv2are variables and opis an operator. In this case, the input
items to D ATADEPare(r,v1)and(r,v2).
Similarly, we provide input items to the happens-before (HB )
relation from thread creation sites. Within a thread, we det ermine
the HB relation using dominance and reachability on the cont rol-
ﬂow graph. Speciﬁcally, if s1dominates s2ands1is not reachable
froms2, thens1happens-before s2. Dominance ensures that all
paths tos2contains1; reachability ensures that there is no path
froms2tos1. All in all, they ensure s1always occurs before s2.
We compute the transitive closure of C TRLDEPand D ATADEP
relations while using the happens-before relation to ﬁlter the false
dependencies. Finally, the forward (resp. backward) depen dency
analysis on some statement sis the forward closure from sof the
combination of the control- and data-dependency relations .
6. SUMMARY-BASED REDUNDANT PATH
PRUNING
The second important component of our incremental analysis is
pruning of redundant executions. In this section, we explai n how
to compute execution summaries in Pand use them in the new
programP′. First, during the symbolic execution of P, we summa-
rize all the explored executions in a table, denoted PS, where each
entryPS[s]stores a logical formula that represents all explored ex-
ecutions (sufﬁxes) starting from s. Then, during the symbolic exe-
cution of P′, we leverage our backward change-impact analysis to
decide if these summaries can be carried over to P′.
6.1 Computing Execution Summaries
We construct the summary PS[s], at each state s, based on the
weakest precondition (WP) computation [6]. The WP is deﬁned
with respect to a predicate φand an execution π. It can be regarded
as a form of Craig’s interpolant [26, 16, 4], to explain why th e
execution cannot reach bad states. When an explored executi on
ends at an assert(c) statement, we compute the WP of calong this
execution; otherwise, we compute the WP of true.
DEFINITION 1.The weakest precondition of the predicate φ
with respect to a sequence of instructions is deﬁned as follo ws:
•For an assignment t:v:=exp,WP(t,φ) =φ[exp/v], which
is the substitution of vbyexpinφ;
5361:intAltPress :=0;Meter :=2
procedure UPDATE (intPedalPos , int
BSwitch , intPedalCmd )
2: ifPedalPos <=0 then //(modiﬁed )
3: PedalCmd += 1
4: else if PedelPos == 1 then
5: PedalCmd += 2
6: elsePedalCmd = PedalPos
7:
8: PedalCmd = PedalCmd + 1
9:
10: ifBSwitch == 0then
11: Meter = 1
12: else if BSwitch == 1 then
13: Meter = 2
14:
15: ifPedalCmd == 2 then
16: AltPress = 0
17: else if PedalCmd == 3 then
18: AltPress = 1/4
19: elseAltPress == 1/2
20:n2:PedalPos≤0nbegin
n3:PedalCmd += 1 n4:PedalPos == 1
n5:PedalCmd += 2 n6:PedalCmd = PedalPos
n8:PedalCmd = PedalCmd + 1
n10:BSwitch == 0
n11:Meter = 1 n12:BSwitch == 1
n13:Meter = 2
n15:PedalCmd == 2
n16:AltPress = 0 n17:PedalCmd == 3
n18:AltPress = 1/4 n19:AltPress = 1/2
nendn2:modiﬁed
true false
true false
true false
true
false
true false
true false
Figure 8: The WBS example taken from DiSE [30].
•For a branching statement t: assume( c),WP(t,φ) =
φ∧c; and
•For a sequence of instructions, denoted t1;t2,WP(t1;t2,φ)=
WP(t1,WP(t2,φ)).
Following Guo et al. [12], we compute the execution summary
by merging the WPs at the pivot points as follows.
•The weakest precondition at a branching pivot point (b-PP) s,
with outgoing edges to s1,...,skand conditions c1,...,c k,
is deﬁned as follows:
wp[s] :=/logicalordisplay
1≤i≤k(ci∧wp[si]),
where each wp[si]is the weakest precondition at state si.
•The weakest precondition at an interleaving pivot point (i- PP)
s, with outgoing edges to s1,...,sk, is deﬁned as follows:
wp[s] :=/logicalanddisplay
1≤i≤kwp[si].
This is an underapproximation since the precise merging wou ld
require an enumeration of all possible interleavings, whic h is
too costly for the summary-based pruning. Nevertheless, in
practice, this underapproximated summary often sufﬁces fo r
eliminating redundant executions.
Finally, the execution summary PS[s]at nodesis computed as
the union of the weakest preconditions along all explored ex ecu-
tions starting from s.
Consider the WBS example in Figure 8, whose control ﬂow graph
is shown on the right-hand side. The baseline symbolic execu tion
procedure needs to explore all 21 paths. Following the metho d de-
scribed above, the execution summaries computed for the pro gram
Pcan be found in Table 1. For example, the summary for node
n17, denoted PS[n17], is the union of ( PedalCmd ==3)∧PS[n18])
and (PedalCmd /ne}ationslash=3)∧PS[n19]).
Prior to using the summary table computed in Pin the new pro-
gramP′, we need to check if recent code changes have invalidated
some of these summaries. If the answer is no, we can safely reu se
them to prune away redundant executions in P′. For example, in
Figure 5, since we changed only Line 1, i.e., from if (x>0) toif
(x>=0) , the weakest precondition computation is not affected at al l
other nodes except for n1. In other words, we can reuse the previ-
ously computed summaries at these nodes.Table 1: Execution summaries computed for PinConc-iSE .
Entry Summary
PS[n19]true
PS[n18]true
PS[n17]((PedalCmd ==3)∧PS[n18])∨((PedalCmd/\e}atio\slash=3)∧PS[n19])
=true
PS[n16]true
PS[n15]((PedalCmd ==2)∧PS[n17])∨((PedalCmd/\e}atio\slash=2)∧PS[n17]))
=true
PS[n13] =PS[n15][2/Meter]=true
PS[n12]((BSwitch ==1)∧PS[n15])∨((BSwitch/\e}atio\slash=1)∧PS[n15]) =true
PS[n11] =PS[n15][1/Meter]=true
PS[n10]((BSwitch ==0)∧PS[n11])∨((BSwitch/\e}atio\slash=0)∧PS[n12]) =true
PS[n8] =PS[n10][(PedalCmd + 1)/PedalCmd ]=true
PS[n6] =PS[n8][PedalPos /PedalCmd ]=true
PS[n5] =PS[n8][(PedalCmd + 2)/PedalCmd ]=true
PS[n4] ((PedalPos ==1)∧PS[n5])∨((PedalPos/\e}atio\slash=1)∧PS[n6]) =true
PS[n3] =PS[n8][(PedalCmd + 1)/PedalCmd ]=true
PS[n2] ((PedalPos≤0)∧PS[n3])∨((PedalPos >0)∧PS[n4]) =true
Table 2: Comparing the paths explored by DiSE and Conc-iSE .
π Explored by DiSE Explored by Conc-iSE
1 {n2,n3,n8,n10,n11,n15,n16} partial (up to n3)
2 {n2,n3,n8,n10,n11,n15,n17,n18} skipped
3 {n2,n3,n8,n10,n11,n15,n17,n19} skipped
4 {n2,n4,n5,n8,n10,n11,n15,n16} partial (up to n4)
5 {n2,n4,n5,n8,n10,n11,n15,n17,n18} skipped
6 {n2,n4,n5,n8,n10,n11,n15,n17,n19} skipped
7 {n2,n4,n6,n8,n10,n11,n15,n16} skipped
6.2 Pruning with Execution Summaries
Our method for leveraging the summaries to prune away redun-
dant executions has been shown on Lines 27–29 in Algorithm 2.
Here,pcon represents the set of forwardly reachable states, while
¬PS[s]represents the set of states that may lead to some previously
unexplored errors. If the intersection is empty, however, t here is no
need to continue the current execution beyond s. In the actual im-
plementation, the validity of ( pcon=⇒PS[s]) is decided by
checking the satisﬁability of its negation, (pcon∧¬PS[s]), which
can be solved efﬁciently by an SMT solver.
To demonstrate the advantages of our method, we show how it
works on the WBS example from DiSE [30]. Since DiSE works
only for sequential programs, the WBS example in Figure 8 is a
sequential program and our method assumes it has a single thr ead.
In WBS, the only code change is on Line 2, from ( PedalPos == 0)
to (PedalPos <= 0). The red rounded rectangles represent the im-
pacted CFG nodes in P′, while the white rounded rectangles repre-
sent nodes that are not impacted by the change. The baseline s ym-
bolic execution procedure needs to explore all 21 paths wher eas
DiSE only needs to explore 7 paths (Table 2), due to the reduct ion
based on its forward impact analysis. That is, the nodes n10,n11,
n12andn13are not affected by the code change at n2.
However, there is still redundancy among the 7 paths explore d
by DiSE. As shown in the third column of Table 2, certain commo n
subpaths are explored repeatedly. For example, { n8,n10,n11,n15,
n16} is an already-explored subpath in π1but it is re-explored in
π4andπ7, also, {n10,n11,n15,n17,n18} is an already-explored
subpath in π2but it is re-explored in π5, and {n10,n11,n15,n17,
n19} is an already-explored subpath in π3but it is re-explored in
π6. In contrast, our new method can reduce the seven executions
further down to 2 executions (Column 3 in Table 2).
Speciﬁcally, during the symbolic execution of P, we incremen-
tally compute the summaries at n17,n15,n10,n4,n2, and Table 1
shows the summary table of Pin terms of these locations.
Then, in the symbolic execution of the new program P′, we
ﬁrst apply the forward change-impact analysis for the modiﬁ cation
in Line 2, and then apply our backward change-impact analysi s,
537which indicates that the summary is invalid only at node n2(imme-
diately before Line 2); for all other nodes, we can safely reu se the
summaries since these nodes are not in the backward slice of n2.
By checking the validity of pcon[s] =⇒PS[s]for all nodes
except for n2during the execution, we can reduce the seven runs
further down to two partial runs. More speciﬁcally, the exec ution
onP′starts by visiting n2. As the summary at n2is invalid (since
it is in the backward impacted-set), the execution continue s explor-
ing without checking the summary. Consider that the true branch
ofn2is ﬁrst selected; execution proceeds until reaching the nex t as-
signment statement at n3. Noticing that the summary at n3is still
valid and (pcon[n3]∧ ¬PS[n3])= (PedalPos≤0)∧¬true =false ,
the execution stops here, generates the ﬁrst partial run { n2,n3},
and backtracks to n2.
Next, the false branch of n2is selected and the execution runs un-
til the following branch statement at n4. As(pcon[n4]∧¬PS[n4])
= (PedalPos>0 )∧¬true =false , the execution also stops, generates
the second partial run { n2,n4}, then backtracks to n2. Since both
outgoing edges of n2are explored and n2is the entry of the pro-
gram, the whole execution on P′terminates.
Therefore, the two runs in P′explored by our method are π1={n2,
n3} andπ4={n2,n4}, shown in Column 3 of Table 2.
7. EXPERIMENTS
We have implemented the proposed method in a software tool
named Conc-iSE , which builds upon LLVM [23] and Cloud9 [5].
Cloud9 relies on the KLEE symbolic virtual machine [3] as back-
end. We extended Cloud9 to robustly handle POSIX threads; the
original implementation only coarsely considered differe nt thread
interleavings at blocking operations. In contrast, our sym bolic ex-
ecution procedure schedules threads at a ﬁner granularity ( e.g., the
shared memory accesses) and ensures that all interleavings are sys-
tematically explored. Furthermore, we implemented the dyn amic
partial-order reduction (DPOR) algorithm [9], which Cloud9 does
not originally support. In addition, we have implemented ou r for-
ward and backward change impact analysis to provide guidanc e
to our incremental symbolic execution algorithm. We also im ple-
mented a ﬂow-insensitive pointer analysis for multi-threa ded pro-
grams. Our dependency analysis is constraint-based and dir ectly
works on the LLVM bit-code. We use the Z3’s µZ [14] ﬁx-point
solver to compute the ﬁx-point of the Datalog constraints.
To share the summary information between program versions,
we deployed the Memcached Distributed Cache as an external p er-
sistent storage for the execution summaries. The summaries are
computed and encoded in KLEE KQuery formula format during th e
symbolic execution. After the execution of the original pro gramP,
they are serialized as binary character sequences for Memca ched
storage. Before running the new program P′, they are loaded into
main memory and mapped to the corresponding global control l o-
cations. Based on the results of our backward change-impact analy-
sis, we implemented a summary renewal mechanism to check if the
summary of a location has been invalidated by recent code cha nges,
and reset it to false in that situation.
7.1 Subjects and Methodology
We have conducted experiments on two sets of benchmarks. The
ﬁrst set consists of multi-threaded C programs randomly cho sen
from the Software Veriﬁcation Competition benchmark [37] a nd
benchmarks from [7]. The second set consists of three real-w orld
applications, each with ﬁve different versions: they are lo ck-free
data structure implementations ( nbds-list ,nbds-skiplist andnbds-
hashtable ) from [29]. Each of these benchmark programs has be-
tween 50 to 2,500 lines of code, with a total of 14 application s, 70
different versions, and 34,926 lines of code. Each benchmar k pro-
gram is ﬁrst compiled to LLVM bit-code by Clang, before given to
the symbolic execution engine.100101102103100101102103
Runs (Baseline)Runs (+SCIA)
100101102103100101102103
Time (s) (Baseline)Time (s) (+SCIA)
Figure 9: Conc-iSE (+SCIA) versus the Baseline algorithm.
For C programs from [37, 7, 20], since there are no different
versions available online, we manually made three types of m utants
to the programs, acting as modiﬁed, deleted and added statem ents.
For the real-world applications from [29], we studied the ev olution
history from the code repository, and used real updates comm itted
by their developers as the changes to those programs.
7.2 Experimental Results
Table 3 summarizes the experimental results of our evaluati on.
The program name, version, lines of code, number of changes, per-
centage of code impacted, and the number of threads for each p ro-
gram are shown in Columns 1–6. Columns 7–14 compare the ex-
perimental performance of four different methods in terms o f the
number of explored executions (runs) and the time in seconds .
Baseline denotes the baseline symbolic execution procedure in
Algorithm 1, +DPOR denotes baseline symbolic execution aug-
mented with dynamic partial order reduction, +CIA denotes a vari-
ant of Conc-iSE , which augments baseline symbolic execution with
DPOR and pruning based on the forward change, but without the
backward summary-based pruning. Finally, +SCIA denotes the full-
blown implementation of Conc-iSE , which augments +CIA with
the backward summary-based pruning. In all methods, the sta tic
analysis time and summary computation time (if applicable) are in-
cluded in the total execution time. We used a maximum time of 3 0
minutes (1,800 seconds) for all experiments.
In the remainder of this section, we present the results in mo re
detail to answer the following research questions:
1. How effective is our Incremental Symbolic Execution algo-
rithm?
2. How does it compare to state-of-the-art POR techniques?
3. How effective is the backward summary-based pruning?
First, we compare the performance of Baseline and+SCIA with
the two scatter plots in Figure 9. The x-axis denotes the execution
time (or number of runs) of the baseline symbolic execution, while
they-axis denotes the execution time (or number of runs) of our
new method ( +SCIA ). In the scatter plots, each dot represents a
benchmark program, and the dots below the diagonal lines are the
winning cases of our new method. From Figure 9, we see that our
new method can signiﬁcantly reduce the number of runs explor ed
by symbolic execution as well as the total execution time. In many
cases, our new method can ﬁnish the execution in seconds whil e
the baseline algorithm does not stop after 30 minutes.
Second, we compare the performance of +DPOR and+SCIA
with the two scatter plots in Figure 10. Our goal is to show how
much performance improvement was achieved by our new method
over +DPOR alone. Similarly, dots below the diagonal lines are
the winning cases of our new method ( +SCIA ). Again, our new
method brings signiﬁcant performance improvement compare d to
+DPOR . However, there are some test cases where +SCIA spent
slightly longer time, despite that it has the same or a smalle r num-
ber of runs. This is due to the overhead of static analysis, su mmary
538Table 3: Comparing the two variants of Conc-iSE (+CIA and +SCIA) with baseline symbolic execution.
Existing Methods Conc-iSE (new)
Baseline +DPOR +CIA +SCIA
Name Version LOC # Changes Impacted (%) Threads # Runs Time (s) # Runs Time (s) # Runs Time (s) # Runs Time (s)
v1 65 1 0.0 924 16.6 48 0.8 1 0.3 1 0.3
v2 66 2 10.6 −>1800 142 2.0 142 2.2 22 0.9
ﬁbbench [37] v3 67 2 13.6 2 −>1800 628 12.1 628 12.0 34 2.4
v4 67 2 17.9 −>1800 3943 160.3 3943 161.4 39 2.5
v5 68 3 2.9 −>1800 1420 30.3 10 0.4 7 0.3
v1 68 1 8.8 749 14.2 106 1.8 106 1.7 38 0.9
v2 69 1 10.1 5838 370.1 208 3.5 208 3.4 81 1.6
account [37] v3 70 3 14.3 3 1773 50.5 168 2.8 168 2.7 55 1.2
v4 70 1 6.6 1773 47.8 168 2.7 14 0.5 11 0.4
v5 71 2 6.6 13407 1642.4 325 5.3 11 0.4 9 0.3
v1 58 1 10.3 156 2.4 12 0.4 12 0.4 9 0.3
v2 59 2 11.9 1399 36.1 43 0.8 43 0.8 18 0.5
lazy01 [37] v3 61 4 11.5 3 8313 624.1 71 1.2 71 1.2 18 0.5
v4 62 2 1.6 8313 625.3 71 1.1 2 0.3 2 0.1
v5 61 4 13.1 −>1800 211 3.1 179 2.5 26 0.6
v1 85 1 22.4 −>1800 729 29.6 729 30.5 33 20.3
v2 85 1 16.5 −>1800 81 2.5 5 0.4 5 0.4
indexer [37] v3 86 2 23.3 2 −>1800 90 2.5 90 2.6 30 5.2
v4 87 2 2.3 −>1800 90 2.5 1 0.3 1 0.3
v5 88 2 22.7 −>1800 1314 41.2 1314 43.7 563 53.9
v1 59 1 5.1 191 2.7 36 0.7 1 0.2 1 0.3
v2 60 3 13.3 105 1.6 10 0.4 4 0.3 4 0.3
readreadwrite [37] v3 63 3 12.7 3 728 13.7 34 0.7 34 0.8 20 0.5
v4 63 1 12.7 728 14.0 34 0.7 9 0.3 8 0.3
v5 67 5 19.1 5444 175.1 101 1.6 22 0.6 18 0.5
v1 65 2 9.2 88 1.4 37 0.7 37 0.7 12 0.4
v2 67 1 9.0 296 4.3 117 1.7 46 0.8 15 0.4
stateful01 [37] v3 68 2 10.3 2 3267 120.8 675 11.4 327 4.8 22 0.5
v4 68 1 16.2 3267 119.6 675 10.1 675 9.9 71 1.0
v5 68 1 16.2 3267 121.3 675 8.9 675 8.9 42 0.7
v1 94 1 6.4 1190 17.8 38 0.7 34 0.6 30 0.5
v2 92 2 6.5 222 2.7 15 0.5 11 0.4 9 1.2
reorder [37] v3 94 2 7.4 2 2903 72.1 61 1.2 38 0.7 28 0.5
v4 96 2 7.4 4698 176.1 125 1.9 125 1.9 32 0.7
v5 97 3 7.2 9557 273.1 68 1.2 53 0.9 39 0.8
v1 141 1 2.8 4862 286.8 101 1.6 7 0.3 7 0.3
v2 142 1 5.6 5878 298.4 148 2.2 148 2.4 79 1.3
twostage3 [37] v3 141 2 5.7 3 2636 97.8 101 1.6 60 1.1 27 0.6
v4 141 1 7.1 2636 96.0 69 1.4 37 0.8 29 0.6
v5 141 1 5.1 2568 94.7 188 3.2 123 2.3 38 0.7
v1 73 1 20.5 −>1800 12473 171.3 2 0.3 2 0.3
v2 74 2 27.4 −>1800 13434 197.6 150 2.2 67 1.4
szymanski [7] v3 73 1 20.5 2 −>1800 10180 136.7 73 1.3 61 1.1
v4 73 1 26.7 −>1800 14365 207.7 591 8.9 79 2.2
v5 73 1 20.0 −>1800 −>1800 73 1.3 61 1.2
v1 128 2 25.8 −>1800 2112 31.7 1739 25.1 287 8.7
v2 130 2 22.1 −>1800 2292 34.6 1133 16.4 223 6.4
bluetooth [7] v3 130 1 22.3 2 −>1800 2324 35.3 1154 16.5 276 5.3
v4 131 5 38.2 −>1800 2617 40.6 2617 41.5 532 13.8
v5 133 3 39.1 −>1800 2437 38.5 2437 36.1 417 11.9
v1 115 1 26.9 52 0.9 52 0.9 52 0.9 32 0.8
v2 116 2 15.5 1077 19.7 277 4.1 277 4.1 68 3.3
circularbuf [7] v3 116 1 6.9 2 3794 171.8 770 14.3 126 1.9 21 0.5
v4 118 2 15.3 3794 173.1 2916 105.6 462 7.4 46 1.5
v5 117 1 28.2 −>1800 924 17.8 924 18.1 102 3.3
v1 1168 5 9.2 −>1800 1724 433.9 501 223.3 422 136.1
v2 1624 3 1.9 −>1800 898 117.3 10 141.6 10 141.6
nbds-list [29] v3 1626 4 5.2 2 −>1800 4660 701.6 503 102.9 503 103.2
v4 1887 5 3.5 −>1800 6007 698.9 35 90.7 14 80.4
v5 1885 3 5.0 −>1800 1304 160.7 198 73.2 175 53.1
v1 1734 2 10.3 −>1800 −>1800 1874 263.6 1266 202.7
v2 2095 2 3.0 −>1800 4645 228.0 284 61.6 180 56.5
nbds-skiplist [29] v3 2095 2 3.2 2 −>1800 −>1800 299 61.9 223 59.9
v4 2100 3 0.4 −>1800 7508 266.3 5 48.3 5 48.2
v5 2101 1 2.5 −>1800 −>1800 550 65.6 417 56.3
v1 2234 1 0.3 −>1800 4818 218.6 9 170.1 9 169.5
v2 2322 2 8.6 −>1800 −>1800 2686 650.8 2686 632.6
nbds-hashtable [29] v3 2375 2 7.3 2 −>1800 −>1800 1684 440.5 1453 416.1
v4 2418 2 2.7 −>1800 9474 730.8 612 258.8 431 190.3
v5 2422 2 4.6 −>1800 17556 1396.2 849 337.1 763 303.5
Total 34,926 70,585 17,149 3,478 2,816
539100101102103100101102103
Runs (+DPOR)Runs (+SCIA)
100101102103100101102103
Time (s) (+DPOR)Time (s) (+SCIA)
Figure 10: Conc-iSE (+SCIA) versus Baseline (+DPOR).
100101102103100101102103
Runs (+CIA)Runs (+SCIA)
100101102103100101102103
Time (s) (+CIA)Time (s) (+SCIA)
Figure 11: Conc-iSE variants: (+CIA) versus (+SCIA).
computation, as well as the pruning, which makes the total ex e-
cution slower than +DPOR . But, overall, the run time of +SCIA
versus +DPOR is 83% smaller.
Finally, we compare the two Conc-iSE variants ( +CIA and+SCIA )
in Figure 11. These scatter plots show the effect of executio n sum-
maries during an incremental analysis. Similar to the previ ous
cases, sometimes the summary-based pruning technique is no t able
to provide a signiﬁcant reduction, thereby causing the runt ime to be
slightly higher; this usually occurs when the backward impa ct anal-
ysis causes many summaries to be removed. Nonetheless, for m ost
test cases, it is able to have a signiﬁcant reduction in the nu mber of
runs, which in turn leads to a signiﬁcant reduction in time.
Discussion. Fundamentally, an incremental analysis is only applica-
ble when the code modiﬁcation affects a subset of the entire p ro-
gram: if the entire program is modiﬁed then the incremental a nal-
ysis degenerates to the non-incremental one. Therefore, ou r tech-
nique is suitable in a software development environment whe re the
correctness of frequent but small code changes is checked be fore
they are committed to the central repository. In our experim ents,
the code modiﬁcations from the nbds application are all developer-
made modiﬁcations. Furthermore, in these real-world appli cations,
code modiﬁcations typically affected around 0.3% to 10.3% o f the
entire program. Such code changes are small enough to allow Conc-
iSEto be effective, although it remains an open question whethe r
they reﬂect the majority of the software development scenar ios in
practice. Another interesting problem is when to schedule t ests,
e.g., as in Herzig et al. [13], which is an orthogonal but clos ely
related problem.
8. RELATED WORK
Change-impact analysis [45] has been widely applied in soft ware
testing and veriﬁcation. The existing incremental symboli c execu-
tion tool, DiSE [30], uses an intra-procedural static chang e-impact
analysis and then leverages it to reduce the cost of symbolic exe-
cution. The extension of DiSE, named iDiSE [32], improves it in
two ways: by making the change-impact analysis inter-proce dural,
and by using dynamic calling-context information to increa se accu-racy. Yang et al. [46] extend DiSE to a property-guided symbo lic-
execution procedure for checking assertions in evolving pr ograms.
Change-impact analysis has been used in the context of progr am
veriﬁcation as well. For example, Backes et al. [1] use a chan ge-
impact analysis to improve the functional equivalence chec king in
regression veriﬁcation. Speciﬁcally, the change-impact i s used to
focus on the equivalence checking of affected portions of th e code.
Similarly, SymDiff [21] focuses on proving assertions in th e con-
text of regression veriﬁcation.
However, none of these previous techniques were designed fo r
concurrent programs: they all target sequential software. Their ex-
tension to concurrent programs remains non-trivial due to t he in-
herent difﬁculties in analyzing thread interferences. Our new tech-
nique, in contrast, is the ﬁrst incremental symbolic execut ion for
concurrent programs.
SimRT [49] is a regression-testing tool for multithreaded p ro-
grams targeting data-races. It compares the two program ver sions
syntactically to identify a set of affected variables, and t hen con-
struct a list of potential data races to test. During the test ing phase,
SimRT prioritizes the selection of existing test cases and v isiting
the most program points of the affected variables to speed up data-
race detection. CAPP [17] uses a change-impact analysis to p rior-
itize scheduler preemptions at impacted code points to dete ct con-
currency bugs. However, CAPP only manipulates the prioriti zed
thread scheduling rules with ﬁxed data inputs.
Furthermore, SimRT and CAPP focus on test selection and pri-
oritization as opposed to generating new tests. In contrast , our
method uses symbolic execution to generate new tests.
RECONTEST[38] is a regression testing technique to select new
thread interleavings that are more likely to trigger concur rency bugs
caused by recent code changes. Speciﬁcally, it computes the af-
fected code statements by comparing dynamic execution trac es on
the two program versions. Then, at each program point of the i m-
pacted set, it identiﬁes problematic memory access pattern s [39,
36] and use them to compute alternative interleavings, e.g. , by re-
ordering these concurrent memory accesses. While R ECONTEST
has the capability of exploring new thread schedules, it rel ies on
user-provided data inputs. In contrast, we use symbolic exe cution
to generate new data inputs as well as new thread schedules.
We build upon prior works on constructing weakest-precondi -
tion and similar interpolation-based execution summaries during
symbolic execution [26, 16, 4, 48, 12]. There is also a large b ody
of work on symbolic analysis of concurrent software using SM T
solvers [42, 40, 41, 19, 34, 18, 35, 10, 25]. However, these pr ior
works target a single program version. In contrast, we lever age
the summary computed in the previous program version to prun e
redundant executions in the new program version.
9. CONCLUSION
We have presented Conc-iSE , an incremental symbolic execu-
tion algorithm for concurrent programs. Our new change-imp act
analysis is both inter-thread and inter-procedural, capab le of more
accurately identifying instructions affected from code ch anges be-
tween two closely related program versions. We also showed h ow
summaries computed from the previous program can be used to
prune away redundant runs during symbolic execution of the n ew
program. We implemented our method and evaluated it on a larg e
set of multithreaded programs. Our experiments show that th e new
method can signiﬁcantly reduce the runtime cost when compar ed
with the state-of-the-art symbolic execution techniques.
10. ACKNOWLEDGMENTS
This work was primarily supported by the NSF under grants
CCF-1149454, CCF-1405697, and CCF-1500024. Partial suppo rt
was provided by the ONR under grant N00014-13-1-0527.
54011. REFERENCES
[1] J. D. Backes, S. Person, N. Rungta, and O. Tkachuk.
Regression veriﬁcation using impact summaries. In
International SPIN Workshop on Model Checking Software ,
pages 99–116, 2013.
[2] M. Bravenboer and Y . Smaragdakis. Strictly declarative
speciﬁcation of sophisticated points-to analyses. In ACM
SIGPLAN Conference on Object Oriented Programming,
Systems, Languages, and Applications , pages 243–262, 2009.
[3] C. Cadar, D. Dunbar, and D. R. Engler. KLEE: unassisted
and automatic generation of high-coverage tests for comple x
systems programs. In USENIX Symposium on Operating
Systems Design and Implementation , pages 209–224, 2008.
[4] D. Chu and J. Jaffar. A framework to synergize partial ord er
reduction with state interpolation. In International Haifa
Veriﬁcation Conference , pages 171–187, 2014.
[5] L. Ciortea, C. Zamﬁr, S. Bucur, V . Chipounov, and
G. Candea. Cloud9: a software testing service. Operating
Systems Review , 43(4):5–10, 2009.
[6] E. Dijkstra. A Discipline of Programming . Prentice Hall, NJ,
1976.
[7] A. Farzan, A. Holzer, N. Razavi, and H. Veith. Con2colic
testing. In ACM SIGSOFT Symposium on Foundations of
Software Engineering , pages 37–47, 2013.
[8] J. Ferrante, K. J. Ottenstein, and J. D. Warren. The progr am
dependence graph and its use in optimization. ACM Trans.
Program. Lang. Syst. , 9(3):319–349, July 1987.
[9] C. Flanagan and P. Godefroid. Dynamic partial-order
reduction for model checking software. In ACM
SIGACT-SIGPLAN Symposium on Principles of
Programming Languages , pages 110–121, 2005.
[10] M. K. Ganai, N. Arora, C. Wang, A. Gupta, and
G. Balakrishnan. BEST: A symbolic testing tool for
predicting multi-threaded program failures. In IEEE/ACM
International Conference On Automated Software
Engineering , pages 596–599, 2011.
[11] P. Godefroid. Partial-Order Methods for the Veriﬁcation of
Concurrent Systems - An Approach to the State-Explosion
Problem . Springer, 1996.
[12] S. Guo, M. Kusano, C. Wang, Z. Yang, and A. Gupta.
Assertion guided symbolic execution of multithreaded
programs. In ACM SIGSOFT Symposium on Foundations of
Software Engineering , 2015.
[13] K. Herzig, M. Greiler, J. Czerwonka, and B. Murphy. The a rt
of testing less without sacriﬁcing quality. In International
Conference on Software Engineering , pages 483–493,
Piscataway, NJ, USA, 2015. IEEE Press.
[14] K. Hoder, N. Bjørner, and L. de Moura. muZ - an efﬁcient
engine for ﬁxed points with constraints. In International
Conference on Computer Aided Veriﬁcation , volume 6806 of
Lecture Notes in Computer Science , pages 457–462, 2011.
[15] S. Horwitz, T. Reps, and D. Binkley. Interprocedural sl icing
using dependence graphs. ACM Trans. Program. Lang. Syst. ,
12(1):26–60, Jan. 1990.
[16] J. Jaffar, V . Murali, and J. A. Navas. Boosting concolic
testing via interpolation. In ACM SIGSOFT Symposium on
Foundations of Software Engineering , pages 48–58, 2013.
[17] V . Jagannath, Q. Luo, and D. Marinov. Change-aware
preemption prioritization. In International Symposium on
Software Testing and Analysis , 2011.
[18] V . Kahlon and C. Wang. Universal Causality Graphs: A
precise happens-before model for detecting bugs in
concurrent programs. In International Conference on
Computer Aided Veriﬁcation , pages 434–449, 2010.[19] S. Kundu, M. K. Ganai, and C. Wang. CONTESSA:
Concurrency testing augmented with symbolic analysis. In
International Conference on Computer Aided Veriﬁcation ,
pages 127–131, 2010.
[20] M. Kusano and C. Wang. Assertion guided abstraction: a
cooperative optimization for dynamic partial order reduct ion.
InIEEE/ACM International Conference On Automated
Software Engineering , pages 175–186, 2014.
[21] S. K. Lahiri, K. L. McMillan, R. Sharma, and C. Hawblitze l.
Differential assertion checking. In ACM SIGSOFT
Symposium on Foundations of Software Engineering , pages
345–355, 2013.
[22] M. S. Lam, J. Whaley, V . B. Livshits, M. C. Martin, D. Avot s,
M. Carbin, and C. Unkel. Context-sensitive program analysi s
as database queries. In ACM SIGMOD-SIGACT-SIGART
symposium on Principles of database systems , pages 1–12,
2005.
[23] C. Lattner and V . Adve. The LLVM Compiler Framework
and Infrastructure Tutorial. In LCPC’04 Mini Workshop on
Compiler Research Infrastructures , West Lafayette, Indiana,
Sep 2004.
[24] S. Lehnert. A taxonomy for software change impact analy sis.
InInternational Workshop on Principles of Software
Evolution , pages 41–50, 2011.
[25] L. Li and C. Wang. Dynamic analysis and debugging of
binary code for security applications. In International
Conference on Runtime Veriﬁcation , pages 403–423, 2013.
[26] K. L. McMillan. Lazy annotation for program testing and
veriﬁcation. In International Conference on Computer Aided
Veriﬁcation , pages 104–118, 2010.
[27] M. Naik and A. Aiken. Conditional must not aliasing for
static race detection. SIGPLAN Not. , 42(1):327–338, Jan.
2007.
[28] M. Naik, A. Aiken, and J. Whaley. Effective static race
detection for java. SIGPLAN Not. , 41(6):308–319, June
2006.
[29] Non-blocking data structures. URL:
https://code.google.com/p/nbds/.
[30] S. Person, G. Yang, N. Rungta, and S. Khurshid. Directed
incremental symbolic execution. In ACM SIGPLAN
Conference on Programming Language Design and
Implementation , pages 504–515, 2011.
[31] S. Raghavan, R. Rohana, D. Leon, A. Podgurski, and
V . Augustine. Dex: A semantic-graph differencing tool for
studying changes in large code bases. In IEEE International
Conference on Software Maintenance , pages 188–197, 2004.
[32] N. Rungta, S. Person, and J. Branchaud. A change impact
analysis to characterize evolving program behaviors. In IEEE
International Conference on Software Maintenance , pages
109–118, 2012.
[33] K. Sen. Scalable Automated Methods for Dynamic Program
Analysis . PhD thesis, UIUC, 2006.
[34] N. Sinha and C. Wang. Staged concurrent program analysi s.
InACM SIGSOFT Symposium on Foundations of Software
Engineering , pages 47–56, 2010.
[35] N. Sinha and C. Wang. On interference abstractions. In ACM
SIGACT-SIGPLAN Symposium on Principles of
Programming Languages , pages 423–434, 2011.
[36] W. N. Sumner, C. Hammer, and J. Dolby. Marathon:
Detecting atomic-set serializability violations with con ﬂict
graphs. In International Conference on Runtime Veriﬁcation ,
pages 161–176, 2012.
[37] SV-COMP. 2015 software veriﬁcation competition. URL:
http://sv-comp.sosy-lab.org/2015/, 2015.
541[38] V . Terragni, S.-C. Cheung, and C. Zhang. RECONTEST:
Effective regression testing of concurrent programs. In
International Conference on Software Engineering , 2015.
[39] M. Vaziri, F. Tip, and J. Dolby. Associating synchroniz ation
constraints with data in an object-oriented language. In J. G.
Morrisett and S. L. P. Jones, editors, ACM
SIGACT-SIGPLAN Symposium on Principles of
Programming Languages , pages 334–345. ACM, 2006.
[40] C. Wang, S. Chaudhuri, A. Gupta, and Y . Yang. Symbolic
pruning of concurrent program executions. In ACM
SIGSOFT Symposium on Foundations of Software
Engineering , pages 23–32, 2009.
[41] C. Wang, S. Kundu, M. Ganai, and A. Gupta. Symbolic
predictive analysis for concurrent programs. In International
Symposium on Formal Methods , pages 256–272, 2009.
[42] C. Wang, Z. Yang, V . Kahlon, and A. Gupta. Peephole parti al
order reduction. In International Conference on Tools and
Algorithms for Construction and Analysis of Systems , pages
382–396, 2008.
[43] M. Weiser. Program slicing. In International Conference on
Software Engineering , pages 439–449, Piscataway, NJ, USA,
1981. IEEE Press.[44] J. Whaley and M. S. Lam. Cloning-based context-sensiti ve
pointer alias analysis using binary decision diagrams. In
ACM SIGPLAN Conference on Programming Language
Design and Implementation , pages 131–144, 2004.
[45] J. W. Wilkerson. A software change impact analysis
taxonomy. In IEEE International Conference on Software
Maintenance , pages 625–628, 2012.
[46] G. Yang, S. Khurshid, S. Person, and N. Rungta. Property
differencing for incremental checking. In International
Conference on Software Engineering , pages 1059–1070,
2014.
[47] W. Yang. Identifying syntactic differences between tw o
programs. Softw., Pract. Exper. , 21(7):739–755, 1991.
[48] Q. Yi, Z. Yang, S. Guo, C. Wang, J. Liu, and C. Zhao.
Postconditioned symbolic execution. In IEEE International
Conference on Software Testing, Veriﬁcation and Validatio n,
pages 1–10, 2015.
[49] T. Yu, W. Srisa-an, and G. Rothermel. SimRT: an automate d
framework to support regression testing for data races. In
International Conference on Software Engineering , pages
48–59, 2014.
542