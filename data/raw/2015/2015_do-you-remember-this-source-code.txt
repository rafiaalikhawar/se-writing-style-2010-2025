Do You Remember This Source Code?
Jacob KrÃ¼ger
Harz University of Applied Sciences
Otto-von-Guericke-University
Wernigerode & Magdeburg ,Germany
jkrueger@ovgu.deJens Wiemann
Otto-von-Guericke-University
Magdeburg, GermanyWolfram Fenske
Otto-von-Guericke-University
Magdeburg, Germany
wfenske@ovgu.de
Gunter Saake
Otto-von-Guericke-University
Magdeburg, Germany
saake@ovgu.deThomas Leich
Harz University of Applied Sciences
METOP GmbH
Wernigerode & Magdeburg ,Germany
tleich@hs-harz.de
ABSTRACT
Beingfamiliarwiththesourcecodeofaprogramcomprisesknowl-
edge about its purpose, structure, and details. Consequently, famil-
iarity is an important factor in many contexts of software develop-
ment, especially for maintenance and program comprehension. As
a result, familiarity is considered to some extent in many different
approaches, for example, to model costs or to identify experts. Still,
all approaches we are aware of require a manual assessment of
familiarityandempiricalanalysesof forgetting insoftwaredevel-
opment are missing. In this paper, we address this issue with an
empiricalstudythatweconductedwith60open-sourcedevelopers.
We usedasurveyto receiveinformationon thedevelopersâ€™famil-
iarityandanalyzetheresponsesbasedondataweextractfromtheir
usedversioncontrolsystems.Theresultsshowthatforgettingisan
importantfactorwhenconsideringfamiliarityandprogramcom-
prehension of developers. We find that a forgetting curve is partly
applicableforsoftwaredevelopment,investigatethreefactorsâ€“the
number of edits, ratio of owned code, and tracking behavior â€“ that
can impact familiarity with code, and derive a general memory
strength for our participants. Our findings can be used to scope ap-
proachesthathavetoconsiderfamiliarityandtheyprovideinsights
into forgetting in the context of software development.
CCS CONCEPTS
â€¢Generalandreference â†’Empiricalstudies ;â€¢Softwareand
its engineering â†’Maintaining software ; Risk management; â€¢
Applied computing â†’Psychology;
KEYWORDS
Familiarity,forgetting,empiricalstudy,maintenance,programcom-
prehension, expert identification, knowledge management
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Â©2018 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-5638-1/18/05...$15.00
https://doi.org/10.1145/3180155.3180215ACM Reference Format:
Jacob KrÃ¼ger, Jens Wiemann, Wolfram Fenske, Gunter Saake, and Thomas
Leich. 2018. Do You Remember This Source Code?. In ICSE â€™18: ICSE â€™18:
40th International Conference on Software Engineering , May 27-June 3, 2018,
Gothenburg,Sweden. ACM,NewYork,NY,USA,12pages.https://doi.org/
10.1145/3180155.3180215
1 INTRODUCTION
Developersâ€™ familiarity (or expertise) with a projectâ€™s context â€“
comprising programs and colleagues â€“ is an essential factor for
many aspects of software engineering, such as, team and task per-
formance [ 16,29,37], knowledge sharing [ 37,54,67], and tool
acceptance [ 17,37,54]. Considering the software itself, familiar-
ity influences how fast and reliable developers can comprehend,enhance, and maintain a program, for instance, to locate and fixbugs or for reengineering [
7,55,60,62]. Consequently, software
familiarity, comprising the knowledge on a programsâ€™ source code,
design, and usage, facilitates maintenance tasks [2, 66]. Especially
asmaintainingsoftwareisthemaincostdriverinsoftwaredevel-
opment [8,12,23,61,64], comprehending and familiarizing with a
program is essential [ 60]. For this reason, familiarity is considered
asanimportantfactorinmanycostestimationapproaches[ 1,9â€“
11,38] and identifying experts for a piece of code receives much
attention [19, 46â€“48].
Whileteamfamiliarityhasbeeninvestigatedextensively[ 28,29,
43,52],lessresearchfocusesonanalyzingsoftwarefamiliarity.The
mainissueinthiscontextaredevelopersforgettingdetailsabout
theirsourcecode,complicatingsoftwaredevelopmentandmain-
tenance [ 33,39,66]. Toaddress this issue,approaches on program
comprehension aim to support developers in regaining their famil-
iarity. Several approaches, such as, clean code guidelines [ 44]o r
suitable identifier names [ 27,41,65], have been analyzed and pro-
posedtoimprovethecomprehensionofsourcecode[ 57].However,
atthis pointfamiliarity mustalreadybe regained[ 4,34].Assessing
howfamiliaradeveloperstilliswiththesourcecodeisessential,
forexample,toassigntasks,toidentifyexperts,or,consequently,
to reduce and estimate costs.
Inthispaper,weproposetoadoptforgettingcurves[ 4,32,50]
fromthepsychologicaldomainforsoftwareengineering.Forthis
purpose,weutilizetheforgettingcurveproposedbyEbbinghaus
[15]and test its applicability for software engineering. Thus, the
main focus of our work is an empirical study that we conducted
7642018 ACM/IEEE 40th International Conference on Software Engineering
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden J. KrÃ¼ger et al.
with 60 open-source developers from 10 GitHub projects. They
participated in an online survey in which they, for example, ap-
proximatedtheirownfamiliaritywithaspecificfile.Basedontheir
responses and data from their commits, we investigate three fac-
tors â€“ namely, the number of repeated edits, ratio of own code,
and tracking behavior â€“ that may affect their familiarity, derive an
average memory strength, and test the aforementioned forgetting
curve.Ourfindingshelptounderstandhowdevelopersforgetde-
tailsabouttheirsourcecodeandhowtoestimatetheirremaining
familiarity.Theresultscansupportmanyapproachesinsoftware
engineering,forexample,toallocatedeveloperstotaskstheyare
most efficient on, to identifyexperts, and to search for knowledge
gaps in a project. Moreover, reliable familiarity estimations can
improvetheaccuracyofcostmodels.Indetail,wecontributethe
following in this paper:
â€¢Wereportanempiricalstudythatweconductedasanonline
survey. Based on 60 responses with open source developers,
we investigate the importance of repetition, ratio of own
code,andcodetrackingontheirfamiliarity.Theresultsindi-cate moderate to strong correlations for the first two factors.
Surprisingly, we find no correlation between familiarity and
tracking for our participants.
â€¢Weidentifyanaveragememorystrengthforourparticipantsasacrucialfactortoapproximateforgetting.Whilethisvalue
needs to be refined in the future, it provides hints at how
fastdevelopersmayforgettheircodeandonthereliability
ofself-assessments. Also,researchersand practitionerscanuse this value as baseline for further research.
â€¢
We test if Ebbinghausâ€™ [ 15] forgetting curve is applicable in
software engineering. For this purpose, we analyze whichof the investigated factors distort the standard course ofthe curve. The results show that different factors need tobe considered before the forgetting curve can be fully ap-
plied.Nonetheless,ifthesefactorsarenoteffective,thecurve
actually fits well to the responses of our participants.
Overall,weaimatanalyzingtheeffectsofforgettingtoderiveap-
proaches to automatically measure or improve software familiarity
in future research.
2 BACKGROUND
In this section, we introduce background information on famil-
iarityandforgetting curves. Both concepts are essential for the
understanding of this paper.
2.1 Familiarity
Familiarity comprises knowledge persons gain on different aspectsof their daily work and about their team members. Over time, they
becomefamiliarwiththeirdomainandeachother,improvingin-
teractions, implementing a knowledge base, and supporting the
identificationofexpertise[ 50,52].Thus,studiesshowpositiveef-
fects of familiarity on, for example, team performance in flight
simulations, problem solving, and several other tasks [16, 42, 43].
Insoftwaredevelopment,thisfamiliarityfocusesonaspecific
program and the developing team. While it is an important fac-
tor,wearenotawareofdetailedanalysesandmeasurementsofa
developerâ€™sfamiliaritywithaprogram.Forexample,Boehmetal .

	






Figure 1: Forgetting curves of Ebbinghaus [15] for memory
strengths (s) of 1, 2, and 3.
[10]introduceascaletomeasureunfamiliarityforcostestimations
with the COCOMO II model and its extensions [ 5,11]. The pro-
posed scale ranges from 0 to 1, representing completely familiar
andcompletely unfamiliar, respectively. Still, the actual value must
be judged by a user.
In the context of this work, we are focusing on a developerâ€™s
familiaritywithaprogram.This softwarefamiliarity istheresult
of studying and working with a program, leading to knowledge
aboutthepurpose,usage,andstructure,forexampleofafile.We
are aware that several terms exist that are closely related, used
synonymously,andsometimesmaybeinterpretedinthesameway,
for instance, comprehension, knowledge, learning, expertise, or
experience. However, we rely on the term familiarity in this paper,
as it subsumes such meanings.
2.2 Forgetting
Familiarityisnoconsistentstate:Itcanbegainedbutalsofadesover
time. The main reason for becoming unfamiliar with a program is
that weforgetdetails about it. Consequently, over time developers
becomelessfamiliarwiththeircodeandneedmoreefforttoregain
the necessary familiarity to work on it. This forgetting process
basicallyrepresentstheoppositeand,thus,isstronglyconnected
to learning [ 32,50]. In psychology, different forgetting models and
curves exist [ 32,50]. We rely on the forgetting curve described
by Ebbinghaus [15]. While it is rather old, studies show that it can
be replicated and performs similar to other curves [ 4,49]. In the
contextofthiswork,theremainingmemorycalculatedwiththis
curve represents the developersâ€™ familiarity.
Ebbinghaus [15]describesanexponentialnatureofforgetting,
as we display in Equation 1.
R=eâˆ’t
s (1)
765
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. Do You Remember This Source Code? ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Here,Rrepresentstheresultingmemoryretentionrate.Therelative
memory strength of the considered subject is defined by sandt
isthetime(indays)betweenstudyinganartifactandtestingthe
subjectâ€™s memory. To exemplify this function, we display curves
forthreedifferentmemorystrengthsinFigure1.Aswecansee,a
highermemorystrengthresultsinaslowerretentionrate,meaning
that the familiarity remains for a longer time. For example, with
a memory strength of s=1 (solid red line in Figure 1), after the
firstdayonly37%ofthefamiliarityremains.Incontrast,amemory
strengthof s=3(dottedblacklineinFigure1)indicatesthatthe
same value is reached only after three days. This memory strength
is individualfor eachperson anddepends onseveral factors,such
as, learning effects and the considered artifact.
3 PROBLEM STATEMENT
Inseveralscientificandindustrialdomainsitisessentialtoconsider
the familiarity of software developers with the code they work
on.Therearemultiplefactorsthatinfluencehowfastdevelopers
forget and, thus, loose familiarity with a program. Consider the
followingexamplewithtwodevelopers,AandB:Atfirst,developer
A implements a file and at the point of creation is most likely
completelyfamiliarwithit.However,whenhestopsworkingonthe
file for some time, his familiarity decreases, potentially resembling
a forgetting curve by Ebbinghaus [15], as we depict in Figure 1.
Additionally, developer B changes the file, for example, to add new
functionsorremovebugs.Here,twootherfactorsbesidesforgetting
apply: Developer B has to understand the existing code at least far
enough to change it and, thus, gains familiarity. He could even
gain100%familiarityifhewouldinvestigateeverydetailofthefile.
In contrast, the familiarity of developer A is negatively affectedbecause he also has to analyze the new implementation at somepoint. Any further change results in the same effects and in one
developer loosing familiarity while the other may gain it.
This example raises several questions regarding the impact of
code changes on a developerâ€˜s familiarity, for example: Is a forget-
ting curve appropriate for software developers? How fast do software
developers actually forget their source code? Do repeated commits
improvethememorystrength? Howdochangesofotherdevelopersim-pactfamiliarity? Howmanychangesofothersdodevelopersanalyze?
Whichothertasks,suchas,reviewingortesting,affectfamiliarity?
In this work, we focus on a subset of these questions. Namely, we
investigatetheapplicabilityofEbbinghausâ€™[ 15]forgettingcurve
on software developers, their average memory strength, and if rep-
etitions, the ratio of own code, or observing othersâ€™ changes on
ownfilesaffectfamiliarity.Despiteourfocusonthesefactors,all
stated questions are important future work. The resulting findings
can be used to derive approaches for measuring familiarity and to
improve our understating of software engineering activities.
Tothisend,wederivethefollowingthreescenariosthataffect
familiarity based on our example:
Sc1Forget:Over time, developers lose knowledge and become less
familiarwithsourcecodetheyworkedon.Thus,theycannot
recall all details anymore and need time to regain familiarity.
Sc2Gain:Developerswhoeditsourcecode,forinstance,byadding,
modifying, or removing lines, aim to understand already ex-
isting code in addition to their newly written code. Thus, theygainorregainfamiliarity,duetoanalyzingexistingsourcecode,
either someone elseâ€™s or their own.
Sc3Unaware: Ifanotherdevelopereditssourcecode,theoriginal
author is unlikely to review the modifications until it is neces-
sary.Forthisreason,thefamiliarityofadeveloperdecreases
withanyeditanotheroneapplies,duetohisunawarenessof
the modification.
In the remaining paper, we refer to these scenarios to describe
which aspects of familiarity we address with our analysis.
4 SURVEY DESIGN
To address the aforementioned questions, we conducted an online
survey.Inthissection,wedescribeour researchquestions, survey
setup, and subjects.
4.1 Research Questions
The goal of our survey is to provide insights into software famil-
iarity and especially on factors that preserve it. Thus, we aim to
answer the following research questions:
RQ1Do the factors repetition, ratio of own code, or change
tracking affect a developerâ€™s familiarity?
There are many factors that can affect a developerâ€™s famil-
iarity, of which we investigate three: Firstly, we hypothesize
that repeatedly working on the same code refreshes famil-iarity (Sc
2) and improves capabilities to remember details,
due to learning effects (Sc 1). Based on the results of Glenberg
[21],weexpectamonotonicallyrisingdependency.Secondly,
developers should also be more familiar with a file if they
wrote a larger ratio of it (Sc 3). Finally, we analyze whether
our participants track changes (Sc 3) of other developers on
their files and if this affects their familiarity. Answering this
researchquestionwillcontributeempiricalfindingsregarding
the influence of these factors on software familiarity.
RQ2What is the average memory strength of a developerregarding the source code?
As we described in Section 2, the memory strength is nec-
essarytoestimatehowfastforgettingproceeds(Sc 1).Thus,
our results help to approximate how long developers remem-
bercode,supportingcorrespondingestimations.Weremark
that this factor is heavily impacted by individualsâ€™ charac-
teristicsandcanalso betrained.Consequently,therecanbe
considerable outliers for a specific developer.
RQ3Is Ebinghausâ€™ forgetting curve applicable for softwaredevelopers?In theend, weaim toassess theapplicability ofEbbinghausâ€™
[15]forgettingcurveinsoftwaredevelopment.Forthispur-
pose, we compare the self-evaluations of our participants
withcomputedvalues.The outcomehelpstodesignfurther
research,forexample,toautomaticallymeasurefamiliarity
or improve approaches that are based on it.
Overall, answering these questions helps research and industry
aliketoanalyze,understand,andimprovesoftwaredevelopment.
Ourfindingssupportmanyresearchareas,suchas,costestimation,
knowledge management, teaching programming, expert identifica-
tion, and reengineering.
766
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden J. KrÃ¼ger et al.
4.2 Survey Setup
For the general setup of our study, we decided to perform an on-
linesurvey.Asanintroducingpartofthesurveyweprovidedthe
followingshortintroductionoffamiliaritytoavoidconfusionon
this term:
Softwarefamiliarityâ€“generallyknownasaresultofstudyor
experience.Iffamiliar,youknow:Thepurposeofafile,itsusage
across the project, and its structure or programming patterns.
WeaskedtoinserttheGitHubusernameormailaddresstoprevent
multiple responses from the same developer and to track their
commits.Furthermore,alldevelopershadtospecifyonefileoftheir
project they had been working with. Here, we especially asked
them not to check this file before participating. We used several
questions, of which the following are of interest for this work.
Howwelldoyouknowthecontentofthefile? Forthisques-
tion,thedevelopershavetoassesshowfamiliartheyarewiththe
file they specified before. Here, they can rate their familiarity on a
Likertscalefrom1(i.e.,barelythepurpose)to9(i.e.,purpose,us-
age, and structure), which represents percentages. We do not allow
a rating of 0 as the developer of a file should have at least some
knowledgeaboutit.Furthermore,weassumethatparticipantsdo
not knowall details(e.g., eachline) of thecode evenif theydevel-
oped it and, thus, we do not allow a 10. We use the answers for all
our research questions, as they provide the basis for our analysis.
Afterhowmanydaysdoyouonlyrememberthestructure
and purpose of a file, but have forgotten the details? In this
case,theparticipantshavetoestimateafterhowmanydaysthey
wouldstillhavearemainingfamiliarityof5(i.e.,itspurposeand
usage). While this is a challenging estimation, we use the answers
to validate our calculations for the second research question.
Howwelldoyoutrackchangesotherdevelopersmakeon
yourfiles? Thisquestionaddressesourfirstresearchquestion.We
canextractvaluesforrepetitionsbasedoncommitsandtheratioofowncodebasedonafileâ€™shistory.Incontrast,wehavetopersonally
ask our participants whether they track changes that others do on
theirfiles.Tothisend,weuseaLikertscalerangingfrom0(i.e.,no
tracking at all) to 10 (i.e., analyzing each change).
How many lines of code does the file contain? Weaskthis
questiontovalidatewhethertheparticipantsrememberthecorrect
fileorarejusttoounfamiliarwithit.Here,weexcluderesponses
with a high error rate, as we describe in the next section.
When was the last date you edited the file? Again, we use
this question to validate the participantsâ€™ responses. A high de-
viation from the real date of the last edit may indicate missing
motivation or a wrong file being remembered. Thus, we also ex-
clude such responses from our analysis.
4.3 Subjects
As we aimed to use data from version control systems to answer
our research questions, we considered the ten GitHub projects we
display in Table 1. We varied our selection to consider different de-
velopmentapproachesandtoincreasetheresponserate,wherefore
we included projects with different attributes: Firstly, we searched
for actively developed and popular projects from which we invited
all developers that edited a file in 2016. Secondly, we varied theTable 1: Projects considered for the survey.
Project LanguageDevelopers
Inv. Resp. Incl.
aframe JavaScript 43 5 4angular.js JavaScript 75 8 7astropy Python 41 13 7ember.js JavaScript 75 5 3FeatureIDE Java 10 4 4ipython Python 33 3 3odoo Python 135 15 10react JavaScript 153 4 4serverless JavaScript 89 12 11sympy Python 68 9 7
Overall 722 78 60
Inv:: Invited; Resp.: Responded; Incl.: Included
programminglanguageandteamsizetoconsiderdifferentdevel-
opment styles. Finally, we considered some scientificprojects, for
example astropy, as research shows that response rates for these
are higher [ 14]. Each active developer received a mail containing a
link to our survey.
To consider the quality of responses, we define the following
exclusion criteria:
(1)Participant did not edit the selected file: As we do not ask
the participants to specify a file they committed to â€“ but
withwhichtheyworkedâ€“4ofthempickedonetheydidnot
committo.Aswecannotextractanyinformationfromthe
commits, we remove these responses.
(2)Last edit was more than a year ago: We especially ask the
participants to specify a file they worked on in 2016. Still, 9
of them picked one that they edited only before. We exclude
these responses.
(3)High deviation: We also exclude responses where answers
to the last two questions deviate by more than 100% (75%
considering the lower bound for lines of code) from the real
value. In 5 cases this appears for the date of the last edit
(measured in days) and in 9 other cases for the lines of code.
As we show in Table 1 (the delta between responded and included),
we exclude 18 responses, often due to multiple criteria. Still, 60
responses remain valid and provide the basis for our analysis.
5 RESULTS
Inthissection,wedescribeforeachresearchquestiontheresults
ofoursurveyanddiscussthecorrespondingimplications.Wedis-
play an overview of our data in Table 2.1Here, we show all values
grouped by the subjective familiarity (SF) that each participant
estimated.Furthermore,weshowthenumberofcommitsthatwere
done bythe participant(#C) aswell as thenumber ofparticipants
(#P)thatrespondedwiththiscombinationoffamiliarityandcom-
mits.Weremark,thatthecommitsactuallyrefertodistinctdays
onwhichtheparticipantsubmittedatleastonecommit.Otherwise,
we would, for example, consider multiple small commits of one
developer more important than a larger one by another. This way,
weaimtoneglectthiseffect.Inaddition,thenumberofparticipants
1All responses (anonymous): https://bitbucket.org/Jacob_Krueger/icse-2018-data
767
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. Do You Remember This Source Code? ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Table 2: Subjective file familiarity (SF) assessment compared to the number of commits (#C) and time since the last commit
(Î”D).Thenumberofparticipants(#P)isexplicitanddescribeshowoftenthecorrespondingcombinationofSFand#Cappears.
SF1 2 3 4 5 6
#C112 4 12 3 6 127 129 1245 2 1
#P481 1 62 1 1 311 211 11111
Î”D206.3146.6 317 86 70.8 169 60 184 52 159 41 58 114 25 25 23 28 23 44
SF 7 8 9
#C13 4 8 2 7 1 2 5 6 7 9 11 15 27 3 4 16 35 37 43
#P12 1 1 1 211111111 111111
Î”D10 183 43 91 100 9 15 38 96 115 30 299 137 114 41 234 55 43 34 151

   
	
			
Figure 2: Familiarity of all responses related to the time
since the last commit and the number of commits (circle-sizes represent #C). The solid blue line displays average val-ues. The dashed red line displays the average for responses
with a single commit.
isexplicit(notrepresentedbythenumberofcolumns)andwehave
between 4 and 10 participants for each familiarity level. Finally,
we provide an overview on the average days since the last commit
(Î”D) based on the date on which the survey has been answered.
First, we consider Figure 2 to describe the necessity for our
researchquestions.Here,wedisplayallresponsesbyrelatingthe
days since the last commit to the subjective familiarity. Each circle
representsoneparticipantandthecirclesâ€™sizestheabsolutenumber
ofcommits.Inaddition,thesolidbluelineillustratestheaverage
valueforallparticipants,whilethedashedredlineillustratesthe
average for those that committed only once.
Ifweassumethatalldevelopershavethesamememorystrength
and that no other factors influence how well they can remember
code, the average in Figure 2 should resemble the forgetting curve
of Ebbinghaus [15]. At the beginning, this seems to be the case, asmost participants state a high familiarity if their last commit is not
farinthepast.However,aroundthevalueof100dayssincethelast
commit,theaveragefamiliarityrises.WeseeinFigure2thatthe
responses with high familiarity at this point skew the curve.
Overall,theaveragedoesnotfollowtheforgettingcurve.Also
considering the peak at around 120 days, this implies two pos-sibilities: Firstly, the forgetting curve is unsuitable for software
developers.Secondly,thereareotherfactorsbesidesthetimethat
influence familiarity. As the responses with a single commit (the
dashed red line in Figure 2) fit the forgetting curve better, we favor
thesecondoption,whichmeansthatadaptationstothecurveare
necessary.Thismatchesourfirstandthirdresearchquestion,which
we investigate in the following.
5.1 Factorsâ€™ Impact on Familiarity
Regarding ourfirst researchquestion, we aimto identifyif thereare correlations between the subjective familiarity and the three
factors repetition, ratio of own code, and tracking. We support our
investigationsofeachfactorwithtworankcorrelationmeasures:
Spearmanâ€™s Rho ( rs) and Kendallâ€™s Tau ( Ï„)[18,24,35,59]. Both
areusedtoassesmonotonicdependenciesbetweentwovariables
withoutassumingnormaldistribution.Theresultsrangefrom-1
to1,meaningnegativeandpositivecorrelation,respectively.We
apply for each measure a corresponding significance test with a
confidenceintervalof0.95â€“usingalgorithmAS89[ 6]forSpear-
manâ€™s Rho and a tau test for Kendallâ€™s Tau, as implemented in the
statistical programming language R [30].
Before investigating the mentioned factors, we have to test
whetherthesizeofafilecorrelatestofamiliarity.Thisshouldnot
bethecase,asweâ€“inaccordancewithEbbinghausâ€™[ 15]forgetting
curve â€“ consider each file as a single artifact and the remaining
familiarity in percentages. The statistics show no significant corre-
lation (p > 0.2). For completeness, we still compute the effect sizes,
which are very weak for both measures ( rs=0.16 andÏ„=0.11).
Thus, all results confirm our assumption that the file size does not
correlatewiththestatedfamiliarity.Wesummarizethesignificance
tests and correlation measures for all factors (including file size) at
the end of this section in Table 3.
5.1.1 Repetition. Asfirstfactorthatmayinfluencethedeviation
betweenthetheoreticalforgettingcurvebyEbbinghaus [15]and
the empirical average, we consider repetition. Research shows that
repetition can significantly improve memory and learning [ 45,56].
In Figure 2, we see that the increase around 100 days since the
768
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden J. KrÃ¼ger et al.

    
	

Figure3:Familiarityrelatedtothenumberofcommits.The
blue line displays average values. The circle-sizes representthe number of participants with this combination.
lastcommitmatcheswithahighernumberoftotalcommits.Fur-
thermore,weseethatmostresponseswithmultiplecommitsare
above a familiarity of 5. Responses with fewer â€“ mostly singular â€“
commits are mainly below this threshold.
We can further support this observation by displaying the aver-
age only for those responses with a single commit as the dashedred line in Figure 2. In this case, the average actually resembles
theforgettingcurveofEbbinghaus [15].Thisisreasonableasthe
curvedoesnotconsiderrepetitionsand,thus,maybeappropriate
for single commits.
InFigure3,weshowthefamiliaritysolelyrelatedtothenumber
of commits. Here, the circlesâ€™ sizes illustrate the number of par-
ticipantsstatingthis combination.Again,theblue linerepresents
average values. We see that all responses below a familiarity of5 have 10 or less commits. On average, the results show a rising
familiarity as the number of commits increases.
Discussion. All results indicate that repetition affects familiarity.
The average deviates from the forgetting curve at points at which
responses with multiple commits appear. This is due to these re-
sponsesbeingmostlylocatedinthetophalfofthefamiliarityscale,
where they should not be according to the forgetting curve. In Fig-
ure3,thiseffectisemphasizedevenmore,asonlyresponseswith
less than 10 commits in total are below this threshold. To test this,
weassumethenullhypothesisthatcommitsandfamiliarityarenot
correlated. However, our statistics reveal a highly significant corre-
lation between the two ( p<0.001). The rank correlation measures
imply a moderate to strong positive effect ( rs=0.67 andÏ„=0.55).
Wethereforerejectthenullhypothesisinfavorofassumingthat
the number of commits positively affects familiarity.
    
	

	



	
Figure 4: Familiarity related to the ratio of own code. The
blue line displays average values. The circle-sizes representthe number of participants with this combination.
Based on the results we conclude:
The number of edits is moderately to strongly positively cor-
related with familiarity in software development.
5.1.2 Ratio of Own Code. Another factor that may impact a de-
veloperâ€™sfamiliarityistheratioofcodetheyimplementthemselves.
Tocomputethisratio,weextractthefileâ€™sversionforthedaywe
received the survey. Then, we account each line the participants
editedlast(using git blame )tothemandrelatethesumtothefile
size.WedisplaythecorrespondingresultsinFigure4.Again,the
blue line represents the average and the circle-sizes the number of
participants with this combination. The average behaves compara-
ble to the one we find for repetitions (cf. Figure 3). However, the
line is on a lower familiarity level in this case.
Discussion. The results imply a correlation between the ratio of
owncodeandfamiliarity.Still,astheaveragetrendisnotasstrong
as in Figure 3 and more deviation occurs, we assume a weaker cor-
relation. This seems reasonable, as the developer has implemented
thecodebutcanonlyregainfamiliaritybasedonrepetitions.For
oursignificancetests,weassumeasnullhypothesisthattheratioof
code a developer implemented is not correlated to their familiarity.
Theoutcomeindicatesahighlysignificantcorrelation( p<0.001),
wherefore wereject thenull hypothesisin favorof assumingthat
both parameters are related. As rank correlations, we compute
rs=0.55 andÏ„=0.42 and, thus, a positive, moderate correlation.
Based on the results we conclude:
Theratioofcodeimplementedbydevelopersthemselvesis
moderately positively correlated with their familiarity.
769
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. Do You Remember This Source Code? ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden

    
	
	
			
Figure 5: Familiarity related to the tracking behavior. The
blue line displays average values. The circle-sizes representthe number of participants with this combination.
5.1.3 Tracking. We asked our participants to which extent they
track changes others apply to their code. This factor could alsoimpact their familiarity, because tracking may indicate that they
analyze the changes and are therefore more familiar with the code.
We display the results in Figure 5. Actually, it surprises us that
many of our participants state a value of above 5. This indicatesthat they are aware of the code others implement and change in
theirfiles.Still,participantswithhightrackingvaluesarealmost
equally distributed above and below a familiarity of 5.
Discussion. Despitehighvaluesintheresponses,wefindnohint
ofacorrelationbetweentrackingandfamiliarityinFigure5.Dueto
the deviation of responses, we assume no correlation between the
two considered parameters. We use this as our null hypothesis and
findnosignificantcorrelation( p>0.78).Also,therankcorrelation
measures of rs=0.04 andÏ„=0.02 indicate almost no dependency.
Thus, for our participants, we find no correlation between tracking
changes and familiarity.
This result poses some questions. Possible explanations may be
thatdevelopersindeedtrackchangesbutdonotinvestigatethem.
Maybe,ourparticipantsalsointerpretedtheterm trackingdiffer-
ently. For example, some may have seen it as actually analyzing
code,butothersasjustreadingnotifications.Iftheyactuallyreviewcode,wewouldexpectacorrelationtothefamiliarity,astheseactiv-itiesarealsoaformofrepetition.However,thisdoesnotseemtobe
thecase.Furtherqualitativeanalysesarenecessarytoinvestigate
this discrepancy.
Based on the results we conclude:
The tracking behavior of own files does not affect familiarity.Table 3: Spearmanâ€™s Rho ( rs), Kendallâ€™s Tau ( Ï„), and the cor-
responding significance (sig.) values for each factor.
Factor rs sig. Ï„ sig.
File Size 0.162 0.218 0.11 0.236
Repetition 0.671 4 .557Ã—10âˆ’90.546 5 .175Ã—10âˆ’8
Own Code 0.553 4 .57Ã—10âˆ’60.42 6 .863Ã—10âˆ’6
Tracking 0.036 0.788 0.023 0.81
5.1.4 Summary. Overall, we find that repetitions are positively
correlatedwithfamiliarity.Thisisnotsurprising,aslearningand
memorizing are improved with re petitions. Interestingly, the num-
berofcommitsseemstopartlyoutweightimeasanindicatorfor
thesubjectivefamiliarity.Fortheratioofcodeimplementedbya
developer, we alsofind a positive but weakercorrelation. It seems
clear that the code developers implement themselves is more fa-
miliar to them. Still, they also become unfamiliar with this code,reducing their familiarity if they do not repeatedly investigate it.
Considering the tracking of changes, we find no correlation.
Regarding our first research question we conclude:
Repetitionaswellastheratioofowncodearesignificantly
positively correlated with familiarity. Thus, they must be
considered in a suitable forgetting curve.
5.2 Memory Strength
Regarding our second research question, we want to identify an
averagememorystrengthforourparticipants.Forthispurpose,wecomputethememorystrengthofeachparticipantfirstbytranspos-
ing Equation 1 into Equation 2.
s=âˆ’t
ln(R)(2)
Recall that trepresents the days since the last commit and Ris the
stated familiarity. Consequently, sindicates how fast our partici-
pantsâ€™ memory fades each day.
We compute three different distributions: Firstly, the memory
strengthbasedonthesubjectivefamiliarityofallparticipants.This
value includes repetition and, thus, is biased considering the actual
forgetting rate. However, we can again verify our previous find-
ings: If repetition is significant, the median and distribution of the
memory strength should be higher than for the other two cases.
Secondly,wecomputethememorystrengthbasedonthesubjec-
tivefamiliarityofparticipantsthatcommittedonlyonce.Finally,
we compute the memory strength based on the responses to the
questionafterhowmuchtimehalfofafileisforgotten.Here,the
retention rate Ris 0.5, meaning that half the familiarity is lost, and
the time is the participantâ€™s response. As this question is challeng-
ingtoanswer,weassumethatthesecondvalueshouldrepresent
the best approximation for our participantsâ€™ memory strength.
Results.We display the computed distributions for each case
as violin plots in Figure 6. Note that we use the median insteadof the mean for our calculations in the next section, as we have
large outliers. These outliers are only partly visualized to avoid an
unreadable scaling. We also display the number of responses in
each distribution below the corresponding violin plot.
770
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden J. KrÃ¼ger et al.



  
	
  
	
	

	 !
Figure 6: Computed memory strengths based on the famil-
iarity of all 60 participants (Overall, left), of only those 27
with one commit (#E = 1, center), and based on the approxi-
mation question (R = 0.5, right).
As we expect, the memory strength based on the familiarity
of all participants is the highest with a median of 90. In addition,
the deviation in the results is the largest. For the participants with
only a single commit (#E = 1) and the approximation question, the
mediansare65and43,respectively.Bothhaveconsiderablysmallerdeviations than the first sample. While the sample with only single
commits has the smallest deviation, it also contains only 27 out of
60 responses. Regarding the approximation question, we remarkthatourparticipantsstatethattheyforgethalfoftheirfilesafter30 days in the median and 40 days on average. To compute the
corresponding familiarity, we again use the median.
Discussion. For our goal of deriving a general memory strength,
we discard the overall sample as it includes repetition. However,
the higher deviation and median substantiate our previous find-
ings. Due to repetition, the computed memory strength increases,
indicating the same effects we find in Section 5.1.
Interpretingtheremainingtwosamplesisquitedifficult.Inthe
sample #E = 1, we compute the values based on the remaining
familiarityandonly forparticipantsthatcommittedonceto afile.
Due to the smaller sample size, less deviation appears. The median
value of 65 indicates that after this number of days, developers
rememberonly36.79%oftheoriginalfile.Afterapproximately45
days, half of the knowledge is lost.
Themedian of43forthe approximationsample(R =0.5)could
represent a more complete view on the participantsâ€™ familiarity,
asweincludealloftheminthisdistribution.However,insteadof
assessingonlytheirsubjectivefamiliarity,eachparticipantalsohas
to estimate a time factor. Thus, these results seem less reliable.
This analysis has to be repeated and validated in further studies.
Still, we argue that 65 can be considered as a good approximationof the general memory strength for our participants. It is based on
less subjective assessments, includes only the appropriate subjects,
and is affected by less deviation. In addition, this memory strength
does closely correspond to the stated days â€“ on average â€“ after
which half of a file is forgotten (40).
Regarding our second research question we conclude:
Thecomputedmemorystrengthssubstantiatethepreviousre-sultsonrepetition.Amedianvalueof65seemstobeanappro-
priate approximation of our participantsâ€™ memory strength.
5.3 The Forgetting Curve
Finally,weconsiderEbbinghausâ€™[ 15]forgettingcurvetoanswer
our thirdresearchquestion. Asstated before,if thereare noother
factors than time, the results we show in Figure 2 should resemble
the forgetting curve. If we only consider responses with a single
commit(dashedredline),ourresultsandthecurvebecomemore
similar.Still,ourpreviousresultsshowthattherearefactorsthat
influence familiarity in software engineering.
InFigure7,wedisplaythefamiliaritiescomputedwithEquation1
â€“basedonthepreviouslyderivedmemorystrengthsâ€“compared
to the subjective assessment of our participants. Ideally, one of
thecurveswouldresembleequalvaluesforbothfamiliarities.We
illustrate this with the black diagonal. As we see, none of the func-
tionsresemblesthislinecompletely.Thisisnotsurprising,asthe
forgetting curve does not consider any other factor than time. For
instance,wefindthatahighnumberofcommitsindicatesahigh
familiarityand,forthisreason,allfunctionsdropatacertainpoint.
Still,asweexplainedbefore,Ebbinghausâ€™[ 15]curvedoesroughly
resembletheblacklineifweconsiderthememorystrengthof65
andonlysinglecommits.Thisisindicatedbytheorangelineand
trianglesbeingclosetotheidealuntilafamiliarityof6.However,
as we determined this memory strength based on the illustrated
values, this match is not surprising.
Discussion. The results of our study indicate that the forgetting
curveofEbbinghaus [15]isapplicableinsoftwareengineeringif
no other factors than time affect familiarity. In our study, most
deviationoccursduetorepetition.Consequently,thecurvecould
be used if developers would not modify their code again. Still,this is usually not the case and adapted approaches for software
developmentseemnecessary.Thesecanbaseonouranalysisand
potentially integrate our findings into an existing forgetting curve,
for example by Ebbinghaus [15].
The results we show in Figure 7 also substantiate that the re-
sponses of the approximation question seem less reliable. Estimat-
ing two subjective values may have negatively influenced the self-
assessmentofourparticipants.However,wecannotfinallyconclude
which of the curves represents reality best, as we rely on subjec-
tive self-assessments. Thus, further empirical studies are needed
tovalidateandconsolidatethememorystrength,potentiallywith
different measurements.
Regarding our third research question we conclude:
TheforgettingcurveofEbbinghaus [15]isonlyapplicablefor
software developers if no other factors, mainly repetitions,
occur. Thus, an adaptation seems necessary.
771
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. Do You Remember This Source Code? ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
Figure7:Comparisonofsubjectiveandcomputedfamiliari-
ties with different memory strengths.
6 THREATS TO VALIDITY
We are aware of several threats to validity, which we discuss based
on common classifications [ 13,53,68]. Most threats result from
combining two research areas: Psychology and computer science.
Construct Validity. The terms we used may result in misun-
derstandings and our questions may have been misinterpreted.
Especially, this could be a problem regarding that native and non-
native English speakers participated. We mitigate this threat byusingcontrolquestions,asexplainedinSection4,andexcludingresponses that indicate misunderstandings (e.g., proposing a file
the participant did not commit to).
Internal Validity. Asweaimtomeasurethefamiliarityofde-
veloperswiththesourcecode,wefindseveralthreatstotheinternal
validity, due to potentially unknown or not yet considered parame-
ters. In the following, we exemplify some aspects that can affect
learning and forgetting, but are excluded from our study:
â€¢Theeffectof reviewing andtestingbutnotcommittingsource
code is not considered, but also results in repetitions.
â€¢Different development approaches may influence how devel-
opersremembersourcecodeorwhetherweconsiderthem
correctly during our analysis.
â€¢The degree of reuseof source code may further support
developersâ€™ memory, due to multiple occurrences.
â€¢Considering implemented features, development time, and
importance ofsourcecodecouldindicatewhetherdevelopers
can remember such factors more easily.
â€¢Someprogramming languages may be harder or easier to
remember than others.
Despitesuchfactors,weintentionallyusedasimplisticapproach
basedonaprominentforgettingcurvetogaininsightintoforgettingin software engineering. While all the aforementioned factors can
have an impact, further investigations are necessary to analyze
these and, currently, we would have to rely on many assumptions.
Also, we argue that considering forgetting, unknown code, and
repetition are valid and important factors to this end.
Anotherthreattotheinternalvalidityistheusedforgettingcurve
of Ebbinghaus [15]. Other curves may be better suited to represent
forgetting in software engineering and may consider additional pa-
rameters. However, the curve we use is established and in a recent
study, Murre and Dros [49]replicate and validateits suitability in
anexperiment.Astheyalsoshowthatotherforgettingcurvesdo
notheavilydiffer,wearguethatthisisnotthreateningourstudy.
Furthermore, Averell and Heathcote [4]also show that the expo-
nential nature of the forgetting curve fits best to their participantsâ€™
results. We remark that both studies origin from the psychological
domain and, thus, may not be completely transferable.
External Validity. Background factors, such as, age, gender,
education, or the motivation of open-source developers [ 22,26,
63]â€“andourrespondentsinparticularâ€“mayinfluencememory
performance. However, medical and psychological studies suggest
thatmemoryperformanceisstableuntilmiddleage[ 51]andgender
mainly affects episodic memory [ 25], which is unimportant to our
study. We assume that the educational level and motivation are
relativelyhomogeneousinoursample.Still,aswecannotcontrol
these factors, they remain a threat to validity.
An additional concern is the subjective nature of familiarity.
Each developer learns,understands, and forgets at adifferent rate,
with different factors influencing familiarity. Still, as we rely on an
acceptedmodelforforgetting,wearguethatbyusingmediansof
the participantsâ€™ results, we obtain valid insights into forgetting in
software development.
Conclusion Validity and Reliability. Potentially the main
threattoourworkareseveralofourquestionsrequiringsubjective
self-assessment. This could bias our conclusions in several ways,
but as we measure and compute subjective factors, we have to rely
on these assessments until we know more about such factors. Inaddition, we have a comparatively small number of participants,
which may lead to statistical errors. We mitigate these threats with
our control questions â€“ excluding implausible responses â€“ andby carefully deriving conclusions not only from statistical tests
â€“ which we only use to support our arguments. Considering the
appliedtests,weespeciallyusedSpearmanâ€™sRhoandKendallâ€™sTau
as they do not require normal distributions or linear correlations.
Despite the discussed threats, we argue that any researcher can
repeatourstudyontheirown.Dependingonthesubjects,questions,andparameters,differentresultsmayoccur .However, thisistruefor
mostempiricalstudiesandisnotathreattoourstudy.Nonetheless,
we strongly encourage the research community to replicate and
extend our approach and study, as we also aim to do. For this
purpose,weprovideaccesstoananonymousversionofourresults,
as we described in Section 5.
7 RELATED WORK
Thereexistseveralrelatedworksthatinvestigate forgetting indiffer-
entdomains.Othercomplementaryworksinclude empiricalstudies
andexpert identification.
772
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden J. KrÃ¼ger et al.
Forgetting. Nembhard and Osothsilp [50]report a comparative
studyonforgettingmodelsinthecontextofproductionmanage-
ment.Theyidentifyseveralstrengthsandweaknessesofthemodels
consideringdifferenttasks.Whilethisworkhasadifferentscope
than ours, utilizing the applied method can help to adapt an ap-
proach for software development. Also, the problem of correctly
approximating forgetting and familiarity can be seen, as few years
later Jaber and Sikstrom [32]criticize the aforementioned work.
They contradict theresults for one modelthat performs poorly in
thepreviousstudy.Similarly,JaberandBonney [31]comparethree
learning and forgetting models on a mathematical level.
In psychology, the form of forgetting curves is often debated
and Averell and Heathcote [4]address this issue with an experi-
ment. To this end, they measure different variables over 28 days to
observe forgetting. The results indicate that exponential forgetting
curves,suchastheonebyEbbinghaus [15],arethebestfitfortheir
participants.Theiranalysismayprovidefurtherdetailsforrefining
our study and to derive an approach for software engineering.
Empirical Studies. In an empirical study with 19 Java devel-
opers,Fritzetal . [19]investigatetheidentificationofknowledge
in software development. The participants are asked questions for
files theyworked regularly orrecently on. Both metricsare helpful
to identify the experts of a program element and several aspects
that can improve the model are investigated. Our study is comple-
mentarytothisoneaswearenotinterestedonidentifyingexisting
knowledge, but its fading over time. We also show a significant
correlationbetweenregularlyworkingonafile(i.e.,repetition)and
familiarity, which supports the assumptions of Fritz et al. [19].
Kang andHahn [34]investigate learningand forgettingin soft-
ware development. Their findings suggest that learning effects
appearforallkindoftechnologywhileonlymethodologicalknowl-
edgeexhibitsforgetting.However,theyperformtheiranalysison
artificial project data rather than with participants and focus on
generalcategoriesofknowledge.Ourworkdiffersasweexamine
familiarityonthecodelevelandconductourstudywithdevelopers.
LaToza and Myers [40]investigate questions that programmers
face while developing software. For this purpose, they gather more
than300questionsandcategorizethem.Theresultsindicatethat
developers often ask rather specific questions about a scenario,such as, the impact of a potential bug. Most of these questions
areconnectedtothesourcecodeandillustratetheimportanceof
being familiar with it. Thus, their work can be used as basis for
extendingourstudybydefiningmoredetailedquestions,potentially
to approximate familiarity for validation purposes.
Koenemann and Robertson [36]report an empirical study in
whichtheyinvestigatehowprofessionaldevelopersanalyzesource
code.Theirfindingsshowthatprogrammersonlyfocusonthose
parts of a software that are relevant to them. Combining these
results with ours could imply some further factors that we have to
consider when approximating familiarity.
Expertise Identification. MockusandHerbsleb [48]propose
theExpertise Browser, a tool to identify experienced developers
and experts. To this end, they rely on change management andquantify the changes implemented by a developer as experience.
We are not aware of theirapproach considering that even experts
forget and become unfamiliar. Thus, our analysis confirms their
assumptions and complements their approach. This also applies tootherexpertiseidentificationapproachesandtools,whichfocuson
communities as well as source code [46, 47, 58].
Oftheseapproaches,theoneproposedbyFritzetal .[20]maybe
the oneclosest toour study.The authorsderive amodel toidentify
experts from previous empirical studies. Here, they consider devel-
opersâ€™authorshipandinteractionswithapieceofcodetorepresent
their familiarity, which are additional factors that we have to con-sider.However, whilethisapproachisbased onrepetition,weare
notawareofanyconsiderationofforgetting.Thus,ourapproach
may improve their model by also including this factor.
Anviketal .[3]describeanapproachtoassignbugreportsbased
onthepreviouslyperformedbugfixesofadeveloper,usingmachine
learning. They use this knowledge to identify the most suitable
experttoresolvethenewproblem.Ourinsightscomplementthis
analysis, as we investigate at which point an expert may have lost
too much knowledge.
8 CONCLUSIONS
In this paper, we investigated forgetting in the context of software
engineering. For this purpose, we conducted an empirical study
with60developers.Wereliedonasimplebutvalidforgettingcurve
toanalyzetheirfamiliaritywithafile.Withourstudy,weidentifyto
whichextenttheoriginalcurverepresentsthesubjectiveassessment
of developers. Furthermore, we investigate the importance of three
factors on familiarity and derive a representative memory strength
for our participants. To conclude our findings, we find:
â€¢The forgetting curve of Ebbinghaus [15]is appropriate in
software development if only time has to be considered.
â€¢Repetitionsmoderatelytostronglycorrelatetofamiliarity
and can be even more important than the elapsed time.
â€¢The ratio of code a developer implemented is moderately
correlated to familiarity.
â€¢We need to better understand how developers track their
code, as we find no correlation to familiarity.
â€¢Avalueof65forthememorystrengthseemstobeanappro-
priate value regarding our participants.
We remark that there are several threats to our work and only
further studiesand research can validatethe results. Nonetheless,
we do provide important insights into familiarity in the context of
software development.
In future work, we will measure familiarity in more detail to
investigateforgetting.Currently,weaimtocomparesubjectiveand
measurablefamiliarity.Integratinganautomatedapproachbased
on our results and related works is interesting. Also, additional
artifacts of a project and other factors, such as learning, need to be
integrated. Tothis end, additionalstudies areessential tovalidate
the results and identify further factors that influence familiarity.
We see the need for interview studies and action research to derive
qualitative insights into forgetting of developers. With large-scale
experiments,thesefindingscanbevalidatedandevaluatedinmore
detailthanwe coulddofornow.Furthermore, differentforgetting
curves and their adaptations should be compared and evaluated
regarding their applicability for software developers.
Acknowledgments This research is supported by DFG grants LE
3382/2-1, SA 465/49-1, and Volkswagen Financial Services AG.
773
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. Do You Remember This Source Code? ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden
REFERENCES
[1]Yunsik Ahn, Jungseok Suh, Seungryeol Kim, and Hyunsoo Kim. 2003. The
SoftwareMaintenanceProjectEffortEstimationModelBasedonFunctionPoints.
Journal of Software: Evolution and Process 15, 2 (2003), 71â€“85.
[2]NicolasAnquetil,KÃ¡thiaMdeOliveira,KleiberDdeSousa,andMÃ¡rcioGBatista
Dias. 2007. Software Maintenance Seen as a Knowledge Management Issue.
Information and Software Technology 49, 5 (2007), 515â€“529.
[3]John Anvik, Lyndon Hiew, and Gail C Murphy. 2006. Who Should Fix this Bug?
InInternational Conference on Software Engineering. ACM, 361â€“370.
[4]Lee Averell and Andrew Heathcote. 2011. The Form of the Forgetting Curve and
the Fate of Memories. Journal of Mathematical Psychology 55, 1 (2011), 25â€“35.
[5]JongmoonBaik,Barry WBoehm,andBert MSteece.2002. Disaggregatingand
CalibratingtheCASEToolVariableinCOCOMOII. IEEETransactionsonSoftware
Engineering 28, 11 (2002), 1009â€“1022.
[6]DJBestandDERoberts.1975. AlgorithmAS89:TheUpperTailProbabilitiesof
Spearmanâ€™s Rho. Journal of the Royal Statistical Society 24, 3 (1975), 377â€“379.
[7]BarryWBoehm.1976. SoftwareEngineering. IEEETransactionsonComputers
C-25, 12 (1976), 1226â€“1241.
[8] Barry W Boehm. 1981. Software Engineering Economics. Prentice-Hall.
[9]BarryW Boehm, ChrisAbts,and SunitaChulani.2000. SoftwareDevelopment
Cost Estimation Approaches - A Survey. Annals of Software Engineering 10, 1
(2000), 177â€“205.
[10]Barry W Boehm, Chris Abts, Bradford K Clark, Ellis Horowitz, A Winsor Brown,
Donald Reifer, Sunita Chulani, Ray Madachy, and Bert Steece. 2000. Software
Cost Estimation with COCOMO II. Prentice Hall.
[11]BarryWBoehm,AWinsorBrown,RayMadachy,andYeYang.2004. ASoftware
ProductLineLifeCycleCostEstimationModel. In InternationalSymposiumon
Empirical Software Engineering. IEEE, 156â€“164.
[12]Elliot J Chikofsky and James H Cross. 1990. Reverse Engineering and Design
Recovery: A Taxonomy. IEEE Software 7, 1 (1990), 13â€“17.
[13]Thomas D Cook and Donald Thomas Campbell. 1979. Quasi-Experimentation:
Design & Analysis Issues for Field Settings. Houghton Mifflin.
[14]Eric L Dey. 1997. Working with Low Survey Response Rates: The Efficacy of
Weighting Adjustments. Research in Higher Education 38, 2 (1997), 215â€“227.
[15]Hermann Ebbinghaus. 1885. Ãœber das GedÃ¤chtnis: Untersuchungen zur Experi-
mentellen Psychologie. Duncker & Humblot. In German.
[16]J Alberto Espinosa, Sandra A Slaughter, Robert E Kraut, and James D Herb-
sleb. 2007. Familiarity, Complexity, and Team Performance in Geographically
DistributedSoftware Development. OrganizationScience 18,4 (2007),613â€“630.
[17]Jean-Marie Favre, Jacky Estublier, and Remy Sanlaville. 2003. Tool Adoption
IssuesinaVeryLargeSoftwareCompany. In InternationalWorkshoponAdoption-
Centric Software Engineering. Carnegie Mellon University, 81â€“89.
[18]Gregory A Fredricks and Roger B Nelsen. 2007. On the Relationship BetweenSpearmanâ€™sRhoandKendallâ€™sTauforPairsofContinuousRandomVariables.
Journal of Statistical Planning and Inference 137, 7 (2007), 2143â€“2150.
[19]Thomas Fritz, Gail C Murphy, and Emily Hill. 2007. Does a Programmerâ€™s
Activity Indicate Knowledge of Code? In Joint Meeting of the European Software
Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of
Software Engineering. ACM, 341â€“350.
[20]ThomasFritz,JingwenOu,GailCMurphy,andEmersonMurphy-Hill.2010. A
Degree-of-KnowledgeModeltoCaptureSourceCodeFamiliarity. In International
Conference on Software Engineering. ACM, 385â€“394.
[21]ArthurMGlenberg.1976. MonotonicandNonmonotonicLagEffectsinPaired-
AssociateandRecognitionMemoryParadigms. JournalofVerbalLearningand
Verbal Behavior 15, 1 (1976), 1â€“16.
[22]Alexander Hars and Shaosong Ou. 2001. Working for Free? Motivations ofParticipating in Open Source Projects. In Hawaii International Conference on
System Sciences. IEEE, 1â€“9.
[23]LesHatton.1998. DoesOOSyncwithHowWeThink? IEEESoftware 15,3(1998),
46â€“54.
[24]Jan Hauke and Tomasz Kossowski. 2011. Comparison of Values of Pearsonâ€™s
and Spearmanâ€™s Correlation Coefficients on the Same Sets of Data. Quaestiones
Geographicae 30, 2 (2011), 87â€“93.
[25]AgnetaHerlitz,Lars-GÃ¶ranNilsson,andLarsBÃ¤ckman.1997. GenderDifferences
in Episodic Memory. Memory & Cognition 25, 6 (1997), 801â€“811.
[26]GuidoHertel,SvenNiedner,andStefanieHerrmann.2003.MotivationofSoftware
Developers in Open Source Projects: An Internet-Based Survey of Contributors
to the Linux Kernel. Research Policy 32, 7 (2003), 1159â€“1177.
[27]JohannesHofmeister,JanetSiegmund,andDanielVHolt.2017. ShorterIdentifier
Names Take Longer to Comprehend. In International Conference on Software
Analysis, Evolution and Reengineering. IEEE, 217â€“227.
[28]Robert S Huckman and Bradley R Staats. 2011. Fluid Tasks and Fluid Teams: The
Impactof DiversityinExperience andTeamFamiliarityon TeamPerformance.
Manufacturing & Service Operations Management 13, 3 (2011), 310â€“328.
[29]RobertSHuckman,BradleyRStaats,andDavidMUpton.2009. TeamFamiliarity,
Role Experience, and Performance: Evidence from Indian Software Services.
Management Science 55, 1 (2009), 85â€“100.[30]RossIhakaandRobertGentleman.1996. R:ALanguageforDataAnalysisand
Graphics. Journal of Computational and Graphical Statistics 5, 3 (1996), 299â€“314.
[31]Mohamad Y Jaber and Maurice Bonney. 1997. A Comparative Study of Learning
Curves with Forgetting. Applied Mathematical Modelling 21, 8 (1997), 523â€“531.
[32]MohamadYJaberandSSikstrom.2004. ANoteon"AnEmpiricalComparisonof
Forgetting Models". IEEE Transactions on Engineering Management 51, 2 (2004),
233â€“234.
[33]Wenbin Ji, Thorsten Berger, Michal Antkiewicz, and Krzysztof Czarnecki. 2015.
Maintaining Feature Traceability with Embedded Annotations. In International
Systems and Software Product Line Conference. ACM, 61â€“70.
[34]KeumseokKangandJungpilHahn.2009. LearningandForgettingCurvesinSoft-
wareDevelopment:DoesTypeofKnowledgeMatter? In InternationalConference
on Information Systems. Association for Information Systems, 194.
[35]MauriceGKendall.1938. ANewMeasureofRankCorrelation. Biometrika 30,
1/2 (1938), 81â€“93.
[36]JÃ¼rgen Koenemann and Scott P Robertson. 1991. Expert Problem Solving Strate-
gies for Program Comprehension. In Conference on Human Factors in Computing
Systems. ACM, 125â€“130.
[37]Jacob KrÃ¼ger, Stephan Dassow, Karl-Albert Bebber, and Thomas Leich. 2017.
Daedalus or Icarus? Experiences on Follow-the-Sun. In International Conference
on Global Software Engineering. IEEE, 31â€“35.
[38]Jacob KrÃ¼ger, Wolfram Fenske, Jens Meinicke, Thomas Leich, and Gunter Saake.
2016. Extracting Software Product Lines: A Cost Estimation Perspective. In
International Systems and Software Product Line Conference. ACM, 354â€“361.
[39]Jacob KrÃ¼ger, Wanzi Gu, Hui Shen, Mukelabai Mukelabai, Regina Hebig, and
Thorsten Berger. 2018. Towards a Better Understanding of Software Features
and Their Characteristics: A Case Study of Marlin. In International Workshop on
Variability Modelling of Software-Intensive Systems. ACM, 105â€“112.
[40]ThomasDLaTozaandBradAMyers.2010. Hard-To-AnswerQuestionsAbout
Code. InEvaluation and Usability of Programming Languages and Tools. ACM, 8.
[41]Dawn Lawrie, Christopher Morrell, Henry Feild, and David Binkley. 2007. Effec-
tiveIdentifierNamesforComprehensionandMemory. InnovationsinSystems
and Software Engineering 3, 4 (2007), 303â€“318.
[42]SherlockALicorishandStephenGMacDonell.2014.UnderstandingtheAttitudes,
Knowledge Sharing Behaviors and Task Performance of Core Developers: ALongitudinal Study. Information and Software Technology 56, 12 (2014), 1578â€“
1596.
[43]Glenn Littlepage, WilliamRobison, and Kelly Reddington. 1997. Effectsof Task
Experience andGroup Experienceon GroupPerformance, Member Ability, and
Recognition of Expertise. Organizational Behavior and Human Decision Processes
69, 2 (1997), 133â€“147.
[44]Robert C Martin. 2009. Clean Code: A Handbook of Agile Software Craftsmanship.
Pearson.
[45]RichardEMayer.1983. CanYouRepeatThat?QualitativeEffectsofRepetition
and Advance Organizers on Learning from Science Prose. Journal of Educational
Psychology 75, 1 (1983), 40â€“49.
[46]David W McDonald and Mark S Ackerman. 2000. Expertise Recommender: A
Flexible Recommendation System and Architecture. In Conference on Computer
Supported Cooperative Work. ACM, 231â€“240.
[47]Shawn Minto and Gail C Murphy. 2007. Recommending Emergent Teams. In
International Workshop on Mining Software Repositories. IEEE.
[48]Audris Mockus and James D Herbsleb. 2002. Expertise Browser: A Quantita-
tiveApproachtoIdentifyingExpertise. In InternationalConferenceonSoftware
Engineering. ACM, 503â€“512.
[49]JaapMJMurreandJoeriDros.2015. ReplicationandAnalysisofEbbinghausâ€™
Forgetting Curve. PLoS ONE 10, 7 (2015), 1â€“23.
[50]DavidANembhardandNapassavongOsothsilp.2001. AnEmpiricalComparisonof Forgetting Models. IEEE Transactions on Engineering Management 48, 3 (2001),
283â€“291.
[51]Lars-GÃ¶ran Nilsson. 2003. Memory Function in Normal Aging. Acta Neurologica
Scandinavica 107 (2003), 7â€“13.
[52]GerardoAndrÃ©sOkhuysen.2001. StructuringChange:FamiliarityandFormal
InterventionsinProblem-SolvingGroups. AcademyofManagementJournal 44,4
(2001), 794â€“808.
[53]DewayneEPerry,AdamAPorter,andLawrenceGVotta.2000. EmpiricalStudies
ofSoftwareEngineering:ARoadmap. In ConferenceonTheFutureofSoftware
Engineering. ACM, 345â€“355.
[54]Andreas Riege. 2005. Three-Dozen Knowledge-Sharing Barriers Managers Must
Consider. Journal of Knowledge Management 9, 3 (2005), 18â€“35.
[55]Martin P Robillard, Wesley Coelho, and Gail C Murphy. 2004. How Effective
DevelopersInvestigateSourceCode:AnExploratoryStudy. IEEETransactions
on Software Engineering 30, 12 (2004), 889â€“903.
[56]Irvin Rock. 1957. The Role of Repetition in Associative Learning. The American
Journal of Psychology 70, 2 (1957), 186â€“193.
[57]IvonneSchrÃ¶ter,JacobKrÃ¼ger,JanetSiegmund,andThomasLeich.2017. Com-
prehending Studies on Program Comprehension. In International Conference on
Program Comprehension. IEEE, 308â€“311.
774
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™18, May 27-June 3, 2018, Gothenburg, Sweden J. KrÃ¼ger et al.
[58]DavidSchulerandThomasZimmermann.2008. MiningUsageExpertisefrom
Version Archives. In International Working Conference on Mining Software Repos-
itories. ACM, 121â€“124.
[59]Pranab K Sen. 1968. Estimates of the Regression Coefficient Based on Kendallâ€™s
Tau.Journal of the American Statistical Association 63, 324 (1968), 1379â€“1389.
[60]TeresaMShaftandIrisVessey.2006. TheRoleofCognitiveFitintheRelationship
BetweenSoftwareComprehensionandModification. ManagementInformation
Systems Quarterly 30, 1 (2006), 29â€“55.
[61]David Sharon. 1996. Meeting the Challenge of Software Maintenance. IEEE
Software13, 1 (1996), 122â€“125.
[62]JaniceSinger, TimothyLethbridge,Norman Vinson,and NicolasAnquetil. 2010.
An Examination of Software Engineering Work Practices. In CASCON First
Decade High Impact Papers. IBM, 174â€“188.
[63]ÅžtefanStÄƒnciulescu,SandroSchulze,andAndrzejWÄ…sowski.2015. Forkedand
IntegratedVariantsinanOpen-SourceFirmwareProject. In InternationalCon-
ference on Software Maintenance and Evolution. IEEE, 151â€“160.[64]Thomas A Standish. 1984. An Essay on Software Reuse. IEEE Transactions on
Software Engineering 5 (1984), 494â€“497.
[65]Armstrong A Takang, Penny A Grubb, and Robert D Macredie. 1996. The Effects
ofCommentsandIdentifierNamesonProgramComprehensibility:AnExperi-
mental Investigation. Journal of Programming Languages 4, 3 (1996), 143â€“167.
[66] Paolo Tonella,MarcoTorchiano,BartDuBois,andTarjaSystÃ¤.2007. Empirical
StudiesinReverseEngineering:StateoftheArtandFutureRrends. Empirical
Software Engineering 12, 5 (2007), 551â€“571.
[67] Bart VanDen Hooffand JanA DeRidder.2004. Knowledge Sharingin Context:
The Influence of Organizational Commitment, Communication Climate and
CMC use on Knowledge Sharing. Journal of Knowledge Management 8, 6 (2004),
117â€“130.
[68]Claes Wohlin, Per Runeson, Martin HÃ¶st, Magnus C Ohlsson, BjÃ¶rn Regnell, and
Anders WesslÃ©n. 2012. Experimentation in Software Engineering. Springer.
775
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 11:37:39 UTC from IEEE Xplore.  Restrictions apply. 