ISPY: Automatic Issue-Solution Pair Extraction
from Community Live Chats
Lin Shi∗§1, Ziyou Jiang∗§1,Y eY a n g¶, Xiao Chen∗§, Yumin Zhang∗§, Fangwen Mu∗§,
Hanzhi Jiang∗§, Qing Wang∗†‡§ 2,
∗Laboratory for Internet Software Technologies,†State Key Laboratory of Computer Sciences,
‡Science&Technology on Integrated Information System Laboratory,
Institute of Software Chinese Academy of Sciences, Beijing, China;
§University of Chinese Academy of Sciences, Beijing, China;
¶School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA;
Email:{shilin, ziyou2019, chenxiao2021, yumin2020, fangwen2020, hanzhi2021, wq}@iscas.ac.cn, yyang4@stevens.edu
Abstract —Collaborative live chats are gaining popularity as
a development communication tool. In community live chatting,
developers are likely to post issues they encountered (e.g., setupissues and compile issues), and other developers respond withpossible solutions. Therefore, community live chats contain richsets of information for reported issues and their correspondingsolutions, which can be quite useful for knowledge sharing andfuture reuse if extracted and restored in time. However, it remainschallenging to accurately mine such knowledge due to the noisynature of interleaved dialogs in live chat data. In this paper,we ﬁrst formulate the problem of issue-solution pair extractionfrom developer live chat data, and propose an automatedapproach, named ISPY, based on natural language processingand deep learning techniques with customized enhancements, toaddress the problem. Speciﬁcally, ISPY automates three tasks:1) Disentangle live chat logs, employing a feedforward neuralnetwork to disentangle a conversation history into separatedialogs automatically; 2) Detect dialogs discussing issues, usinga novel convolutional neural network (CNN), which consists of aBERT-based utterance embedding layer, a context-aware dialogembedding layer, and an output layer; 3) Extract appropriateutterances and combine them as corresponding solutions, basedon the same CNN structure but with different feeding inputs.To evaluate ISPY, we compare it with six baselines, utilizinga dataset with 750 dialogs including 171 issue-solution pairsand evaluate ISPY from eight open source communities. Theresults show that, for issue-detection, our approach achievesthe F1 of 76%, and outperforms all baselines by 30%. Our
approach achieves the F1 of 63% for solution-extraction and
outperforms the baselines by 20%. Furthermore, we applyISPY on three new communities to extensively evaluate ISPY’spractical usage. Moreover, we publish over 30K issue-solutionpairs extracted from 11 communities. We believe that ISPY canfacilitate community-based software development by promotingknowledge sharing and shortening the issue-resolving process.
I. I NTRODUCTION
Synchronous communication via live chats allows develop-
ers to seek information and technical support, share opinions
and ideas, discuss issues, and form community development[1], [2], in a more efﬁcient way compared with asynchronouscommunication such as emails or forums [3]–[5]. Conse-quently, live chatting has become an integral component of
1Both authors contributed equally to this research.
2The corresponding author.
Tom Dec 21 2016 20:25 
Finally figured it out. Thank you so much. @Jack @TomTom Dec 21 2016 20:17
Hi. I am having a little bit of trouble setting up all of the depen dencies for spark. With 
this import line: import org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTraini ngMaster;
Jack Dec 21 2016 20:17 
@Tom Make sure all your dl4j versions are the same first of all
You saw our examples, right?
Mike Dec 21 2016 20:18 
Our latest examples available here: https://github.com/deeplearning4j/dl4j-examples. 
Please check. Those has the pom.xmls you need. 
Tom Dec 21 2016 20:18 
Give me five mins. I will look more into that. 
Jack Dec 21 2016 20:18 
Usually it's just dl4j-spark
Tom Dec 21 2016 20:18 
Which version?
Jack Dec 21 2016 20:19 
with the right scala version
dl4j-spark_2.10 or dl4j-spark_2.11
Extracted Issue-solution Pair
Issue:I am having a little bit of trouble setting up all of the dependencies for spa rk. With this import
line: import org.deeplearning4j.spark.impl.paramavg.ParameterAver agingTrainingMaster.
Solution:Make sure all your dl4j versions are the same first of all. Our  latest examples available here: 
https://github.com/deeplearning4j/dl4j-examples. Those has the pom.xmls you need. Usually 
it's just dl4j-spark, with the right scala version. dl4j-spark_2 .10 or dl4j-spark_2.11. 
Fig. 1: An example of issue-solution pair extraction from theDeeplearning4j live chats.
most software development processes, not only for open
source communities constituting globally distributed devel-opers, but also for software companies to facilitate in-houseteam communication and coordination, esp. in accommodatingremote work due to the COVID-19 pandemic [6].
Existing literature reports various motivation factors for live
chatting practices. One of the frequently mentioned factors isto use live chats as a tool for issue-solving, such as installationand setup issues, bug resolution, build and compile issues[7], [8]. In such cases, developers post questions related tosome speciﬁc issues, and rely on others to provide potentialsolutions. Alkadhi et al. [9], [10] analyzed 8,702 chat messagesof three OSS development teams, and found 24% of the
1422021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)
DOI 10.1109/ASE51524.2021.000232021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE) | 978-1-6654-0337-5/21/$31.00 ©2021 IEEE | DOI: 10.1109/ASE51524.2021.9678894
978-1-6654-0337-5/21/$31.00  ©2021  IEEE
messages are reporting issues, and 51% of the messages are
proposing alternative issue solutions. As a result, live chatrepositories usually contain rich information to shed light onknowledge regarding frequent issue-solution pairs. Fig. 1 illus-trates an example slice of live chat data. In this scenario, Tom
encountered trouble when setting up dependencies for spark,
so he posted an issue in live chatting. Jack and Mike both
provided solutions as well as suggested examples. With their
help, Tom ﬁnally resolved that issue. From this conversation
slice, we can extract the issue description, as highlighted in
red, and alternative solutions colored in blue.
However, it is quite challenging to mine issue-solution pairs
from live chats due to the following barriers. (1) Entan-
gled dialogs. Live chat data gets big rapidly, and multipleconcurrent discussions regarding different issues frequentlyexist in an interleaved manner. In order to perform any kindof dialog-level analysis, it is essential to have automatedsupport for identifying and dividing sequential utterancesinto a set of distinct dialogs, according to the issue topics.
(2) Expensive human effort. Chat logs are typically high-
volume and contain informal dialogs covering a wide range
of technical and complex topics. It is necessary to leveragemanual annotation to guide the construction and training oflearning-based algorithms. However, the manual annotationprocess requires experienced analysts to spend a large amountof time so that they can understand the dialogs thoroughly.Thus, it is very expensive to classify issue-related dialogs. (3)
Noisy data. There exist noisy utterances such as duplicateand unreadable messages in the chat log that do not provideany valuable information. The noisy data poses a difﬁculty to
analyze and interpret the communicative dialogs.
In this paper, we propose a novel approach, named ISPY
(extracting Issue-Solution Pairs from communitY live chats)
to automatically extract issue-solution pairs from development
community live chats. ISPY addresses the problem with threeelaborated sub-tasks: 1) Disentangle live chat logs, employinga feedforward neural network to automatically disentangle aconversation history into separate dialogs; 2) Detect dialogsthat are discussing issues, using a novel convolutional neuralnetwork (CNN), which consists of a BERT-based utteranceembedding layer, a context-aware dialog embedding layer, andan output layer; and 3) Extract appropriate utterances and com-bine them as corresponding solutions, based on the same CNNstructure but with different feeding inputs. To evaluate ISPY,we ﬁrst collect and utilize a dataset with 750 dialogs including171 issue-solution pairs, and evaluate ISPY from eight Gittercommunities. The results show that, for issue-detection, our
approach achieves the F1of 76%, and outperforms baselines
by 30%. For solution-extraction, our approach achieves the F1
of 63%, and outperforms baselines by 20%. Furthermore, we
apply ISPY on three new communities to extensively evaluateits practical usage. ISPY helps provide solutions for 26 recentissues posted on Stack Overﬂow. Adding up the 21K pairsextracted from the former eight communities, we publish over30K issue-solution pairs extracted from 11 communities intotal. We believe that ISPY can facilitate community-basedsoftware development by promoting knowledge sharing andshortening the issue-resolving process. The major contribu-tions of this paper are:
•We formulate the problem of issue-solution pair extrac-tion from developer live chat data. To the best of ourknowledge, this is the ﬁrst study exploring this problem.
•We propose an automated approach, named ISPY, basedon a convolutional neural network and introduces sev-eral customized improvements to effectively handle thecharacteristics of this task.
•We evaluate the ISPY by comparing with six baselines,with superior performance.
•We open-source a replication package and a large datasetwith over 30K issue-solution pairs extracted by tool from11 active communities on our website: https://github.com/jzySaber1996/ISPY.
In the remainder of the paper, Section II illustrates the
problem deﬁnition. Section III presents the approach. SectionIV sets up the experiments. Section V describes the results andanalysis. Section VI illustrates the practical usage. Section VIIis the discussion and threats to validity. Section VIII introducesthe related work. Section IX concludes our work.
II. P
ROBLEM DEFINITION
Three main concepts about community live chats are con-
cerned with this study’s scope, including chat log, utterance,
and dialog. Developer conversations in one chatting room
are recorded in a chat log. As illustrated in Fig. 1, a typ-
ical live chat log contains a sequential set of utterances inchronological order. Each utterance consists of a timestamp,developer id, and a textual message initiating a question orresponding to an earlier message. A chat log includes all theutterances sent among participants who have been chatting inthe room. Typically, it contains a large number of utterances,and the utterances might be responding to different threads ofconversations. We deﬁne dialog as the conversation betweentwo or more participants toward exploring a particular subject(e.g., resolution of a problem).
Chat
log={u1,u2,...,un}
D={ui|S(ui)=s,ui∈Chatlog}
u=< time,id,text >(1)
Equation (1) provides the deﬁnitions for the three main
concepts. Speciﬁcally, a chat log Chatlogcorresponds to
a sequence of nutterances in chronological order. A dialog
Dis a subset of Chatlog, containing only those utterances
responding to the same subject s, which can be determined
by clustering techniques [11], [12] or probability distributionestimation methods [13]–[15]. S(u
i)denotes the subject of
utterance ui, and each utterance uconsists of the timestamp,
developer id, and textual message.
143ⅢC. Dialog  Embedding LayerTextual Feature ExtractorWeight 
Calculation࢏࢛ି૚
࢏࢛
࢏࢛ା૚
Contextual Feature ExtractorHeuristic Attribute Extractor࢏࢛Textual 
features
Contextual 
featuresHeuristic 
featuresܥܨூ
ʹͻ ͳʹͺ ʹͷ͸
Ⅲ D. Output Layer
BERT
Ⅲ B. Utterance Embedding Layer… …ͺͲͲ
࢏࢛ି૚
࢏࢛
࢏࢛ା૚
࢔࢛ࢎ࢛
࢔࢛ି૚
࢔࢛
ࡰ࡭ࡼͶͳ͵ܥܨௌFC: Fully Connected Layer
I: Issue; S: Solution
ܲሺܫȁݑ௛ሻ
ܲሺܵȁݑ௕ଵሻ
ܲሺܵȁݑ௕ଶሻ
ܲሺܵȁݑ௕ଷሻ
ܲሺܵȁݑ௕௡ሻ
ͳʹ ʹͷ
ConvMaxPoolingConvMaxPoolingConvMaxPooling
Softmax
Softmax wݓ݋̴݀݊݅݁ݖ݅ݏ ൌ ͵
ܲሺܵȁݑ௕ସሻHeadࢎ࢛
Body࢈࢛૚
࢈࢛૛
࢈࢛࢔࢈࢛૜
࢈࢛૝Dialog 
(D)ͳࢎ࢛ᇱ
Ⅲ A . Dialog Disentanglement… …… … … …
Ⅲ E. ApplicationDialog
Issue?
YN
DialogIssue-Solution Pairs{Issue,solution}New Chat 
Log
Dialog 
Disentanglement
ࢋ࢛࢙࢙ࡵ
࢒ࢋࢊ࢕ࡹ
࢔࢕࢏࢚࢛࢒࢕ࡿ
࢒ࢋࢊ࢕ࡹ
Feedforward model
Dialog DialogLive Chat Log… … … …… …
… …
… …… …ͻ࢏࢛ି૚
࢏࢛ା૚࢏࢛ࡰ࡭ࡼ
ࢎ࢛
࢈࢛૚Data Preprocessing
Keywords
Structure
Topic
Sentiment
Roleડ
࢏ࢉ
Attention 
Calculation
SoftmaxLocal AttentionTextCNN
Spell Checking
Low-frequency Token 
Replacement
Acronym and Emoji 
Replacement
Recover Broken 
Utterances 
࢏࢛ି૚ൌ࢔࢛ି૚
࢏࢛ൌ࢔࢛
࢏࢛ା૚ൌ࢛ࡰ࡭ࡼ ૚ᇱ
࢛૛ᇱ
࢛૜ᇱ
࢛૝ᇱ
࢔࢛ᇱ࢏࢛ି૚ൌࡰ࡭ࡼ 
࢏࢛ൌࢎ࢛
࢏࢛ା૚ൌ࢈࢛૚
Fig. 2: The overview of ISPY.
Our work automatically targets extracting issue-solution
pairs from community live chats. First, we divide one dialog
Dinto two parts: Head and Body.
Head=uh=uh1⊕uh2⊕...⊕uhm
Body={ub1,ub2,...,ubn}
D={Head,Body }(2)
where Head (also marked as uh) is the concatenation of
all the utterances that the dialog initiator posts before theﬁrst reply from other developers. Body is the set of the
remaining utterances. Dialog Dis their joint set. Based on
this division, we introduce a simpliﬁcation assumption thatthe issue descriptions appear at the head utterances authoredby the dialog initiator, while solution utterances are likely toappear afterward.
Following these concepts and assumption, we formulate
the problem of automatic issue-resolution pair extraction withthree elaborated sub-tasks:
1) Dialog disentangle: Given the historical chat log
Chat
log, disentangle it into separate dialogs
{D1,D2,...,Dn}.
2) Issue detection: Given a separate dialog Di, ﬁnd a binary
functionfso thatf(Headi)can determine whether the
dialog head depicts issue.
3) Solution extraction: Given a dialog Diinvolving is-
sue discussion, ﬁnd a function gso thatg(Bodyi)=
{us1,us2,...,usm}, where usiis the utterance within the
dialog suggesting potential solutions.
Therefore, the output of our approach is a set of issue-
solution pairs. Ideally, users do not need other information(e.g., the utterances between them) to understand these pairs.
III. A
PPROACH
The construction of ISPY consists of four main steps, as
illustrated in Fig. 2. The ﬁrst step includes data preprocessingand dialog disentanglement using a feedforward model. The
second step is to construct an utterance embedding layer,
which embeds tokenized utterances into vectors with localwindow context. The third step is to construct a dialog em-bedding layer, which deﬁnes and extracts three sets of featurescharacterizing the context of potential issues or solutions. Thefourth step is the output layer, which predicts two outputs,
i.e., the possibility of issue description, and the possibility of
solutions, for the corresponding inputs.
By feeding dialog head and body into ISPY separately,
we can obtain two models: issue model and solution model.Finally, ISPY apply the issue model and solution model forconstructing pairs.
A. Dialog Disentanglement
1) Data Preprocessing: For data preprocessing, we ﬁrst
follow the standard pipeline of stopword removal, typo cor-
rection, lowercase conversion, and lemmatization with Spacy[17]. Additionally, due to the unique characteristics of livechat data, we employ additional data preprocessing techniquesto handle special issues. Speciﬁcally, we ﬁrst replace low-frequency tokens such as URL, email address, code, HTML
tag, and version number with speciﬁc tokens [URL], [EMAIL],
[HTML], [CODE] and [ID] respectively. Second, we replace
the acronym words with their full names by referring to the
Oxford abbreviation library [18]. Following previous work[19] [20], we normalize the emojis with speciﬁc stringsto standard ASCII strings. Finally, we combine consecutive
utterances that are broken from one sentence according to
the perplexity scores [21] calculated by Baidu AI Cloud [22].Following the experience from a recent study [23], we usethe perplexity scores lower than 40 as the threshold value tocombine broken sentences.
2) Dialog Disentanglement Model: Utterances from a sin-
gle conversation thread are usually interleaved with other
ongoing conversations. In this step, we focus on dividing chatutterances into a set of distinct conversations, leveraging onKummerfeld et al.’s technique [24]. Their model is trained
from 77,563 manually annotated utterances of disentangled di-
alogs from online chatting. It is a feedforward neural networkwith 2 layers, 512-dimensional hidden vectors, and softsign
non-linearities. The input of the model is a 77-dimensional
144TABLE I: Details about 15 heuristic attributes.
Type Variable Description Example Value
Keyword5W1H Occurrence of “What”, “Why”, “When”, “Who”, “Which”, and “How”. {what=1, why=0, when=0, who=0, which=0, how=0 }
Punctuation Occurrence of “?” and “!”. {“?”=1, “!”=0}
Greeting Occurrence of greeting words: “Hello”, “Good Morning”, “Hi Guys”, etc. False
Disapproval Occurrence of disapproval words: “no”, “can’t work”, “break down” etc. False
Mention Occurrence of “simi-” and “same”. {simi-=0, same=0}
StructureNT Number of tokens in utterance. 7
NUT Number of unique tokens in utterance. 7
NST Number of unique tokens after stemming. 6
AP Absolute position of utterance in dialog. 2
RP Relative position of utterance in dialog. 0.20
TopicTDH Topic deviation between the head of dialog and the entire chat. 0.33
TDU Topic deviation between the head of dialog and the given utterance. 0.42
SentimentSS Polarity sentiment scores from NLTK [16] for positive, intermediate, and negative. {pos.=0.25, int.=0.31, neg.=0.70}
SW Number of three-type polarity sentiment words (pos., int., neg.). {pos.=1, int.=5, neg.=1}
SE Number of three-type polarity sentiment emojis (pos., int., neg.). {pos.=0, int.=0, neg.=1}
Role DI Whether participant is the dialog initiator. False
vector, where each element is a numerical feature extracted
from the original conversation texts, that include time intervals
from previous chat utterances posted by the current user, is
there a target user in the chat content, do two chat texts containthe same words and so on. In Kummerfeld et al.’s study, themodel is reported to achieve relatively good performance with74.9% precision and 79.7% recall.
B. Utterance Embedding Layer
This layer aims to encode not only textual information of
utterances but also capture their contextual information.
Utterance Encoding. First, for all the utterances in one
dialogD=[u
h,ub1,ub2,...,ubn], we encode it using a pre-
trained BERT model [25], as BERT has been proved to be
successful in many natural language processing tasks [26],[27]. The BERT model is a bidirectional transformer usinga combination of Masked Language Model and Next Sentence
Prediction. It is trained from English Wikipedia with nearly2,500M words. The BERT embedding layer outputs /vector u∈R
d,
which is an 800-dimensional vector for each utterance.
Local Window Context. Second, we model the contextual
information of an utterance through the concept of the local
window, and use the size of the local window as a hyper-
parameter. Intuitively, the consecutive reply of an issue ut-terance may be very different from that of non-issue ones.
Therefore, we construct a local window context to characterizethe dynamic contextual information for extracting desiredutterances in a dialog. Speciﬁcally, we use a ﬁxed-length localwindow to integrate context, and deﬁne the local window ofthe utterance /vector u
ias/vectorwiniby joining the uiwith its preceding
and following kneighbor utterances. The ﬁxed length is 2k+1.
/vectorwini={/vector ui−k,..., /vectorui−1,/vectorui,/vectorui+1,..., /vectorui+k} (3)
When the windows are out of bound, we utilize the Zero
Padding [28] to map the ﬁxed length. In this study, we choose
k=1 for the local window.
C. Dialog Embedding Layer
This layer aims to encode utterance features in a multi-
faced way to more comprehensively represent the live chat
context. To achieve that, we deﬁne and extract features fromthree categories, including textual, heuristic, and contextual
features.1) Textual Feature Extractor: To learn basic textual fea-
tures for each utterance, we ﬁrst represent utterances using
TextCNN [29]. It is a classical method for sentence modelingby using a shallow Convolution Neural Network (CNN) [30]to model sentence representation. It has an advantage overlearning on insufﬁcient labeled data, since it employs a concisenetwork structure and a small number of parameters. TextCNNuses several convolution kernels to capture local information asthe receptive ﬁeld. Then the global representation is producedwith the local information.
Given a kernel /vector w∈R
hwith kernel size hand word
embedding /vector x=/vector ui, one convolution feature γtis generated
with/vector xt:t+h−1:
γt=ReLU(/vector w·/vector xt:t+h−1+b) (4)
whereb∈Ris the bias parameter, and ReLU is the activate
function. We concatenate all the γtas a feature map:
/vector γ=[γ1,...,γt,...,γn−h+1] (5)
where the vector /vector γ∈Rn−h+1.W eu s eMax-Pooling strategy
to calculate ˆγ=max(/vector γ). We set the number of kernels as
m, and input uiinto three Convolution-Pooling layers. The
kernel number of the three layers are 1024, 512, and 256,
respectively. The output of each layer is /vectorΓ∈Rm, which is a
256-dimensional textual feature vector.
/vectorΓ=[ˆγ1,ˆγ2,...,ˆγm] (6)
2) Heuristic Attribute Extractor: The heuristic attribute
extractor aims to augment the dialog embedding results by
incorporating high-level semantic attributes from ﬁve aspects:
Keyword, Structure, Sentiment, Topic, and Role, as elaborated
in Table I.
(1)Keyword : The occurrences of indicating words or char-
acters about 5W1H, punctuation, etc.
(2)Structure: The structural characteristics of utterances in
a dialog, such as the number of tokens and positions of theutterances.
(3) Topic: The intuition of this feature is to distinguish
off-topic utterances. We ﬁrst calculate TF-IDF [31] for each
unique word in the entire chat. Then We extract the top-10most frequent words and combine them as a 10-dimensional
145topic vector /vectorTDc. Similarly, we also extract top-10 most fre-
quent words from dialog head ( /vectorTDh) and the given utterance
(/vectorTDu). Finally, we calculate the Euclidean Distance [32]
between them as the topic deviation:
TDH=||/vectorTDc−/vectorTDh||2
TDU=||/vectorTDh−/vectorTDu||2(7)
(4) Sentiment : The sentiment information of the given
utterance in terms of positive, intermediate, and negative.
(5)Role: The role of the participant who posts the utterance.
By concatenating the above heuristic attributes, this extrac-
tor output a 29-dimensional vector.
3) Contextual Feature Extractor: Contextual feature ex-
tractor aims to embed the contextual information for each
utterance. We use Local Attention [33] to represent the context.
The Local Attention mechanism mainly focuses on the impact
of the neighbor utterances locate in the same window. Local
Attention can use low time-memory cost to highly represent
the semantic context. An attention function can be describedas mapping a query and a set of key-value pairs to an output
[34], which is a triple: (/vectorh
Q,/vectorhK,/vectorhV). The function uses the
query vector /vectorhQcalculated by the given utterance /vector ui∈Rdto
query the attention scores with key vector /vectorhK. The key vector
/vectorhKcan be calculated by each utterance /vector us∈Rdwithin the
local window (i −k≤s≤i+k). The attention weight
vector is calculated by multiplying value vector /vectorhVand sum
the attention value. Therefore, we deﬁne the trainable query
matrixWQ∈Rδ×d, key matrix WK∈Rδ×dand value
matrixWV∈Rδ×d, and calculate the triple (/vectorhQ,/vectorhK,/vectorhV):
/vectorhQ=WQ/vector ui,/vectorhK=WK/vector us,/vectorhV=WV/vector us (8)
where the output contextual weight vector is deﬁned as /vector ci∈
Rδ, which can be calculated by the following equations:
score(/vectorhQ,/vectorhK)=(/vectorhQ·/vectorhK)exp[−(s−i)2
2k2]
as=softmax( /vectorhQ,/vectorhK)=score(/vectorhQ,/vectorhK)/summationtext
sscore(/vectorhQ,/vectorhK)
/vector ci=/summationdisplay
i−k≤s≤i+k(as/vectorhV)/√
d(9)
Equation (9) shows the three processes of Local-Attention
calculation: (1) Output attention vector with dot productionasscore(/vectorh
Q,/vectorhK)by multiplying Gaussian Distance between
sandi; (2) Use Softmax to normalize the score vector; and
(3) Apply the normalized score vector to calculate the localattention. We set the parameter d= 800,δ= 128, and obtain
a 128-dimensional context vector.
Finally, we concatenate the vectors that output by the three
extractors into a 413-dimensional feature vector /vectoru
/prime.
D. Output Layer
We input the feature vector /vectoru/primeinto two Full-Connected
Layers (FC), and use two Softmax functions to calculate theprobability of issue-description utterance and the correspond-ing solution utterances, respectively.
P(I|u
h)=softmax( FC 1(/vectoruh/prime))
P(S|ubi)=softmax( FC 2(/vectorui/prime))(10)
whereP(I|uh)is the predicted probability of issue-description
utterance, and P(S|ubi)(ubi∈{ub1,...,ubn}) is the predicted
probability of solution utterance. The Cross-Entropy Loss are
applied with the two tasks when measuring the difference
between truth and prediction. The two loss functions are
deﬁned as LossIandLossS:
LossI=−yh·logP(I|uh)
LossS=−yi·logP(S|ubi)(11)
whereyhandyiindicate the ground-truth labels of utterances.
The issue model and solutions model are separately traineduntil convergence.
E. Application
When fully trained, for a given chat log, ISPY automates
the three sub-tasks formulated in Section II: First, it performs
dialog disentanglement; Second, for each disentangled dialog,it uses the issue model to predicts whether the dialog headis issue description; and Finally, if the issue model predictspositive, then it uses the trained solution model to predictwhich utterances can be selected into the solution. As a ﬁnaloutput, it combines the predicted utterances as the correspond-ing solution to the issue.
IV . E
XPERIMENTAL DESIGN
To evaluate the proposed ISPY approach, our evaluation
speciﬁcally addresses three research questions:
RQ1: What is the performance of ISPY in detecting issue
dialogs from live chat data?
RQ2: What is the performance of ISPY in extracting
solutions for a given issue?
RQ3: How does each individual component in ISPY con-
tribute to the overall performance?
A. Data Preparation
1) Studied Communities: Many OSS communities utilize
Gitter [35] or Slack [36] as their live communication means.
Considering the popular, open, and free access nature, weselect studied communities from Gitter
1.
To identify studied communities, we select the Top-1 most
participated communities from eight active domains, cov-ering front end framework, mobile, data science, DevOps,blockchain platform, collaboration, web app, and program-ming language. Then, we collect the daily chat utterances fromthese communities. Gitter provides REST API [37] to get dataabout chatting rooms and post utterances. In this study, weuse the REST API to acquire the chat utterances of the eightselected communities, and the retrieved dataset contains allutterances as of “2020-12”.
1In Slack, communities are controlled by the team administrators, whereas
in Gitter, access to the chat data is public.
146TABLE II: The statistics of the eight Gitter communities.
Id ProjectEntire Population Sample Population
Par. Dial. Utter. Issue Utter. Non-Issue Utter.
P1 Angular 22,467 79,619 695,183 17 170 80 577
P2 Appium 3,979 4,906 29,039 27 461 60 404
P3 Dl4j 8,310 27,256 252,846 38 665 55 1,123
P4 Docker 8,810 3,954 22,367 20 151 74 352
P5 Ethereum 16,154 17,298 91,028 17 115 83 478
P6 Gitter 9,260 7,452 34,147 22 315 64 575
P7 Nodejs 18,118 13,981 81,771 14 121 81 359
P8 Typescript 8,318 18,812 196,513 16 361 82 1,076
Total 95,416 173,278 1,402,894 171 2,359 579 4,944
2) Bootstrap Sampling: After dialog disentanglement, the
number of separate chat dialogs is large. Limited by the human
resource of labeling, we randomly sample 100 dialogs from
each community. Then we excluded unreadable dialogs: 1) Di-alogs that are written in non-English languages; 2) Dialogs that
contain too much code or stack traces; 3) Low-quality dialogssuch as dialogs with many typos and grammatical errors. 4)Dialogs that involve channel robots. However, the dataset isimbalanced in that the non-issue dialogs are much more thanissue dialogs, as shown in Table II. Therefore, we apply anarbitrary bootstrap sampling strategy [38] for data balancingby randomly sampling issue dialogs with replacement until thenumber of issue dialogs and non-issue dialogs is balanced.
3) Ground-truth Labeling: For each sampled dialog, we
ﬁrst manually label whether its head discussed a certain issue.Then, for each issue-dialog, we label the utterances that shouldbe included in the solution. The labeled results are used
as the ground-truth dataset for performance evaluation. To
guarantee the correctness of the labeling results, we built an
inspection team, which consisted of four Ph.D. candidates.All of them are ﬂuent English speakers, and have done eitherintensive research work with software development or havebeen actively contributing to open-source projects. We dividedthe team into two groups. The labeled results from the Ph.D.candidates were reviewed by others. When a labeled resultreceived different opinions, we hosted a discussion with allteam members to decide through voting. The average Cohen’sKappa about issue-dialog is 0.85, and the average Cohen’sKappa about solution-utterance is 0.83.
In total, we collected 173,278 dialogs from eight open-
source communities, and spent 720 person-hours on anno-tating 750 dialogs including 171 issue-solution pairs. TableII presents the detail of our dataset. It shows the number ofparticipants (Par.), dialog (Dial.), and utterance (Utter.) for theentire population, as well as the number of issue and non-issue dialogs with the corresponding utterances for the samplepopulation. Moreover, to contribute to the eight communities,we apply ISPY on the 173,278 dialogs. We extract and publish21K issue-solution pairs on our website.
B. Baselines
The ﬁrst two RQs require the comparison of ISPY with
state-of-the-art baselines. Due to the slightly different focuses
between RQ1 and RQ2, we employ three common baselines
applicable for both, as well as three additional baselines for
each RQ. This leads to a total of six baselines for each RQ.Common Baselines applicable for RQ1 and RQ2. The
three commonly used machine-learning-based baselines areutilized to comprehensively examine the classiﬁcation perfor-mance, i.e., Naive Bayesian (NB) [39], Random Forest (RF)
[40], and Gradient Boosting Decision Tree (GBDT) [41].
Additional Baselines for detecting issues (RQ1). Casper
[42] is a method for extracting and synthesizing user-reported
mini-stories regarding app problems from reviews. We useutterances as the extracted events, and treat its second step, i.e.,classify problems, as a baseline. We use the implementationprovided by the original paper [43]. CNC
PD [44] is the state-
of-the-art learning technique to classify sentences in commentstaken from online issue reports. They proposed a CNN [45]-
based approach to classify sentences into seven categories
of intentions: Feature Request, Solution Proposal, ProblemDiscovery, etc. we treat the CNN classiﬁer that predictsutterances as the Problem Discovery category as a baseline for
detecting issues. DECA
PD[46] is the state-of-the-art rule-
based technique for analyzing development email content. It is
used to classify the sentences of emails into problem discovery,solution proposal, information giving, etc., by using linguisticrules. We use the six linguistic rules [47] for identifying the“problem discovery” dialog-head as our baseline.
Additional baselines for extracting solutions (RQ2). UIT
[48] is a context-representative classiﬁer that uses Glove [49]to embed words, and uses TextCNN to embed the utterance.The UIT classiﬁes utterance into 12 categories. Speciﬁcally,we choose the “potential answer” classiﬁer as a solution-
extraction baseline. CNC
SPis the Solution Proposal clas-
siﬁer in [44]. DECA SPis the set of 51 linguistic rules for
identifying “solution proposal” sentences in [46].
C. Evaluation Metrics
We use three commonly-used metrics to evaluate the per-
formance, i.e., Precision, Recall, F1. (1) Precision, which
refers to the ratio of the number of correct predictions to the
total number of predictions; (2) Recall, which refers to the
ratio of the number of correct predictions to the total numberof samples in the golden test set; and (3) F1, which is the
harmonic mean of precision and recall. When comparing the
performances, we care more about F1 since it is balanced
for evaluation. Note that, since the number of utterances maylargely vary across different dialogs, we calculate the perfor-mance of solution extraction in the scope of the community.
D. Experiment Settings
For all experiments, we apply Cross-Project Evaluation on
our dataset to perform the training process. We iteratively
select one project as testset, and the remaining seven projectsfor training. The experiment environment is a Windows 10desktop computer, NVIDIA GeForce RTX 2060 GPU, intelcore i7, and 32GB RAM.
To answer RQ1, we ﬁrst train the issue dataset with
8batch
size. Each of the convolution and dense layers
use 0.6 dropout to avoid overﬁtting. The optimizer chooses
Adam=0.001 and β1=0.9. We train ISPY for 100 epochs with 5
147TABLE III: Baseline comparison across the eight communities (%).
Task MethodsAngular Appium Docker DL4j Ethereum Gitter Nodejs Typescript Average
P R F1 P R F1 P R F1 P R F1 P R F1 P R F1 P R F1 P R F1 P R F1
IssueISPY 76 77 76 75 68 71 84 74 79 77 68 72 82 73 77 80 69 74 79 70 74 86 78 82 80 72 76
NB 36 40 38 41 30 35 47 36 41 70 56 62 08 25 13 22 42 29 30 50 37 15 40 22 34 40 36
RF 56 25 34 69 30 42 75 23 35 84 44 58 100 17 29 50 25 33 33 13 18 23 30 26 61 26 36
GBDT 27 75 40 40 70 51 50 79 61 73 44 55 21 76 33 19 67 29 30 88 44 18 90 30 35 65 46
Casper 39 35 37 08 03 05 59 26 36 46 40 43 19 42 26 14 17 15 05 06 06 15 40 22 26 26 26
CNC PD 20 55 29 23 50 32 23 36 28 12 32 17 24 42 30 12 42 19 10 50 17 05 40 10 16 43 24
DECA PD 33 50 40 28 37 31 33 36 34 64 28 39 42 42 42 44 67 53 32 50 39 04 10 06 35 40 37
SolutionISPY 61 58 69 68 57 62 71 60 65 66 62 58 73 63 68 62 56 59 68 58 63 72 67 69 68 59 63
NB 21 58 30 24 48 32 31 59 40 58 49 53 33 80 47 10 67 17 37 55 44 08 09 09 28 53 37
RF 26 83 39 27 52 36 31 56 40 80 13 22 15 40 22 10 33 15 50 65 57 54 64 58 37 51 43
GBDT 26 92 40 26 74 38 22 62 32 71 16 26 11 40 17 10 67 17 42 75 54 42 73 53 31 62 41
UIT 29 17 21 21 13 17 30 12 17 24 07 12 37 16 22 27 11 17 19 15 18 31 18 23 27 14 18
CNC SP 18 17 17 26 28 27 21 31 25 46 20 28 30 14 19 46 54 50 41 28 33 38 25 30 33 27 30
DECA SP 00 00 00 00 00 00 20 09 12 25 02 24 00 00 00 00 00 00 57 20 30 33 09 14 17 05 08
patience Early-Stopping. We set the threshold of predicted pos-
sibility within 0.2-0.8, and choose threshold =0.5 as positive-
negative boundary which can reach the best performance after
tuning. NB/GDBT/RF baselines choose the default parametersettings for training; Casper chooses SVM.SVC as default func-
tion, with rbfas kernel, 3 as degree, and 200 as cache
size;
CNC PD selects 64 as batch size, 192-dimensional word
embedding, four different ﬁlter sizes of [2,3,4,5]with 128
ﬁlters, 50 training epochs and dropout =0.5. These baseline
parameters are determined by a greedy strategy, and canachieve the best performance after tuning.
For RQ2, we use the same parameters with RQ1 for ISPY.
We only change the predicting threshold from 0.5 to 0.4 since0.4 can reach the best performance on solution extraction aftertuning. For baselines, we choose default parameter settings forNB/GDBT/RF training. For UIT, we select 32 as batch
size
and 0.6 as dropout.
For RQ3, we compare ISPY with its three variants: 1)
ISPY-CNN, which removes the textual feature extractor fromISPY, 2) ISPY-Heu, which removes the hueristic attribute
extractor from ISPY, and 3) ISPY-LocalAttn, which removes
the contextual feature extractor from ISPY. Three variants usethe same parameters when training.
V. R
ESULTS
A. Performance in Detecting Issues
The upper half of Table III demonstrates the comparison
results between the performance of ISPY and those of the sixbaselines across data from eight OSS communities, for issue
detection tasks. The columns correspond to Precision, Recall,
and F1 score. The highlighted cells indicate the best perfor-mances from each column. Then, we conduct the normalitytest and T-test between every two methods. Overall, the datafollow a normal distribution (p =0.32)
2, and ISPY signif-
icantly (p =1 0−20) outperforms the six baselines in terms
of the average Precision, Recall, and F1 score. Speciﬁcally,
when comparing with the best Precision-performer amongthe six baselines, i.e., RF, ISPY can improve its averageprecision by 19%. Similarly, ISPY improves the best Recall-
performer, i.e., GBDT, by 7% for average recall, and improvesthe best F1-performer, i.e., GBDT, by 30% for average F1
2Signiﬁcant test: p<0.05score. At the individual project level, ISPY can achieve thebest performances on most of the eight communities. Theseresults indicate that ISPY can more accurately detect whethera dialog is discussing an issue, than all comparison baselines.
We believe that the performance advantage of ISPY is
mainly attributed to the rich representativeness of its internalconstruction, from two perspectives: (1) ISPY can accuratelycapture the semantic relationship between the issue descriptionand its ﬁrst reply, by using the local window and local
attention mechanism. This enables it to learn more compre-
hensive contextual knowledge, e.g., what kind of ﬁrst issue-replies represents a dialog head containing issue descriptions.Therefore, it contributes to more accurate classiﬁcation. (2)ISPY augments the textual vectors with high-level semanticinformation by employing 15 heuristic attributes. For example,three out of the 15 attributes are characterizing sentimentattributes. This design is based on the observation that issuedescriptions are likely to contain negative tones such as “fail”,“error”, and “annoy”. By calculating three types of polaritysentiment scores as shown in Table I, the sentiment attributescan be ﬁt into the deep learning network to help with issue-description detection.
Answering RQ1: ISPY outperforms the six baselines in
detecting issue dialogs across most of the studied projects,
and the average Precision, Recall, and F1 are 80%, 72%, and
76%, respectively, improving the best F1-baseline GBDT by30% on average F1 score.
B. Performance in Extracting Solutions
Similarly, the bottom part of Table III summarizes the com-
parison results between the performance of ISPY and those of
the six baselines across data from eight OSS communities,for solution extraction task. We can see that, ISPY can
achieve the highest performance in most of the columns. Itsigniﬁcantly (p =1 0
−5) outperforms the six baselines. On
average, although ISPY are slightly below GBDT by 3%of Recall, it reaches the highest F1 score (63%), improvingthe best baseline RF by 20%. It also reaches the highestprecision (68%), signiﬁcantly higher than other baselines (i.e.,ranging from 17% to 37%). These results imply that ISPY can
effectively extract utterances as the corresponding solutionsfrom development dialogs: (1) Our approach is sensitive
to identifying solutions, including consecutive utterances, by
148Fig. 3: The component analysis.
Dialog
(ݑ݄ )A: I’m training a DNN+CNN model. The F1 score is around 50. But there  are  some  
warnings  that  some  classes  are  never  predicted.  Shall  I create a dataset which is balanced 
for five types?(ݑ
ܾͳ) B: What do you mean “DNN+CNN” model :( ?
(ܾݑʹ) B: Beyond  trained  on  conv  yes,  minibatches  should  alwa ys  be balanced.
(ܾݑ͵) B: If minibatch it should ideally  be as close to representati ve of your whole population as 
possible.
(ܾݑͶ) A: I mean danse Layer+CNN. I used wrong word, I guess....
(ܾݑͷ) B: The reason why I ask is b ecause batchsize largely depends o n data dimension.
(ܾݑ͸) B: The  main  thing  it  had  going  for  it  was  the  catalyst  compiler  for Tensorflow ops.
(ܾݑ͹) A: Nice! Thank you!
ISPY
Beyond  trained  on  conv  yes,  minibatches  should  always  b e  balanced.  If minibatch  it  
should  ideally  be  as  close  to  representative  of  your  whole population as possible. The 
main thing it had going for it was the catalyst compiler for Te nsorflow ops.
NB
What  do  you  mean  “DNN+CNN”  model?  Beyond  trained  on  conv  yes, mini-batches 
should always be balanced.
RF
What  do  you  mean  “DNN+CNN”  model?  Beyond  trained  on  conv  yes, mini-batches 
should always be balanced. I mean danse Layer+CNN. I used wrong word, I guess.
GDBT
What  do  you  mean  “DNN+CNN”  model?  Beyond  trained  on  conv  yes, mini-batches 
should always be balanced. I mean danse Layer+CNN. I used wrong word, I guess. The  reason   
why  I  ask  is  because  batch size largely depends  on  data  d imension.  The  main  thing  it  
had  going  for  it  was  the catalyst compiler for Tensor-flow  ops.
UIT
Beyond  trained  on  conv  yes,  minibatches  should  always  be  balanced. The main thing it had going for it was the catalyst compiler for Tensorflow ops. Nice! Thank you!
CNC_SP
Beyond  trained  on  conv  yes,  minibatches  should  always  b e  balanced.  If minibatch  it  
should  ideally  be  as  close  to  representative  of  your  whole population as possible.
DECA_SP
(Empty)
Fig. 4: Test example.
employing a local attention mechanism. In live chats, some
solutions include consecutive utterances from the same par-ticipants. For example, the utterance u
b2andub3in Figure
4 are both selected as solution utterances. Our approachcan learn that knowledge by adjusting the weight of u
b3to
be higher, to increase its probability according to the localattention learning. While baselines (e.g., NB, RF, GDBT, UIT,DECA
SP) separately learn the textual characteristics of each
utterance, thus are more prone to predict ub3as a non-solution
utterance. (2) Our approach can screen negative feedbacks inconsecutive utterances and reject ineffective solutions basedon the heuristic attributes (i.e., disapproval keywords andnegative sentiment attributes) and local attention mechanism.In live chats, some utterances are indeed solutions but areproved ineffective (e.g., those have follow-up utterances like“It doesn’t work”) by the dialog initiator later. In such cases,ISPY can detect whether its follow-up utterances containnegative feedback based on the heuristic attributes and localattention learning, while other methods cannot.
We also notice that, the DECA
SP baseline can hardly
extract the solution utterances correctly. By investigating their51 linguistic rules and our test dataset, we consider thatit comes from two reasons. First, the DECA
SP rules are
designed for extracting solution proposals from email contents,which have different expressing styles from live chats. Second,
the DECA
SP rules are kind of strict for live chats. For
example, the rule “[something] can be ﬁxed by [something]”
cannot deal with its similar variants such as “[something]could/should be ﬁxed by [something]”.
Answering RQ2: ISPY outperforms the six baselines in
extracting solution utterances in terms of Precision and F1.The average Precision, Recall, and F1 are 68%, 59%, and63%, respectively, improving the best F1-baseline RF by 20%on average F1 score.
C. Effects of Main Components
Fig. 3 presents the performances of ISPY and its three
variants respectively. We can see that, the F1 performances
of ISPY are higher than all three variants in both issue-dialogdetection and solution extraction tasks. When compared withISPY and ISPY-LocalAttn, removing the LocalAttn compo-nent will lead to a dramatic decrease of the precision (-35%),
recall (-60%) , and F1 score (-57%) for the solution-utteranceextraction task, as well as a decrease of the precision (-41%),recall (-46%) , and F1 score (-46%) for the solution extractiontask. This indicates that the local attention mechanism is anessential component to contribute to ISPY’s high performancein both detecting issues and extracting solution utterances.The top three charts in Fig. 3 compare the precision, recall,and F1-score of ISPY and its three variants, for the issue-detection task. Compared to ISPY-Heu and ISPY-CNN, ISPY
has moderately better precision and F1, and the recalls of allthe three remain very close. It is because that, the contextual
information is quite effective in retrieving all the positive-truth
instances back for this task, while the other two components
149mainly contribute to ﬁlter the negative-truth instances out, thus
can further improve precision. The bottom three charts in Fig.3 compare the precision, recall, and F1-score of ISPY andits three variants, for the solution-extraction task. Comparedto ISPY-Heu and ISPY-CNN, ISPY has moderately betterprecision, recall, and F1.
Answering RQ3: The textual feature extractor, heuristic
attribute extractor, and content feature extractor adopted by
ISPY are helpful for extracting issue-solution pairs, whilethe contextual feature extractor provides a more signiﬁcantcontribution to the effectiveness of ISPY than others.
VI. A
NAPPLICATION STUDY OF ISPY
Experiments in Section V have shown the performances of
our approach. In this section, we conduct an application studyto further demonstrate the usefulness of our approach.
Procedure. We apply ISPY on live chat data from three new
communities: Materialize, Springboot, and WebPack (notethat these are different from our studied communities). Ac-
cording to the issue-solution pairs extracted from the threecommunities, we manually inspect their recently unanswered
questions on Stack Overﬂow, and provide potential solutionscorrespondingly. First, we crawl the recent (January 2018 toApril 2021) live chats of three new communities. Second,we apply ISPY to disentangle the live chats into about 21K
dialogs, and generate a dataset with over 9K issue-solution
pairs. Because all live chats are historical data, we cannotdirectly evaluate the usefulness of ISPY with the originaldevelopers who inquired about the issue. As an alternative, weinvestigate the usefulness of ISPY by sharing the discoveredsolutions to developers facing similar issue on Stack Overﬂow.
Speciﬁcally, we employ four Ph.D. students to inspect therecent, unanswered questions in these three communities onStack Overﬂow. When ﬁnding unanswered issues that havebeen discussed in live chats, we post the corresponding solu-tions as potential answers.
Results. Table IV summarizes the results from this ap-
plication study (More details can be found in our website).
The “Contribution Type” column shows how ISPY’s solutionscontribute to the Stack Overﬂow. There are three types of
contribution: “Accepted Answer” means that ISPY’s solution
has been adopted as the best answer. “Potential Answer”
TABLE IV: The statistics of ISPY’s contribution on answeringquestions for Stack Overﬂow.
Contribution Type # QID (#ans)
Accepted Answer 667201337(1), 67086241(1), 67101118(1),
67047528(1), 66899397(1), 67150784(2)
Potential Answer 1961529948(1), 65619783(1), 63620416(1),
66383230(1), 57543742(1), 49303635(1),
51042100(1), 39653049(1), 65877801(1),
64455428(1), 59282213(2), 59073683(2),
63190114(2), 50233325(2), 56158365(2),
60062706(3), 42130187(3), 38848742(4),
47974757(5)
Comment 1 66378139(2)
Total 26means that ISPY’s solution is listed as a potential answer, but
there is no feedback from the question asker yet. “Comment”
means that ISPY’s solution contributes as a comment while
other’s answer got accepted. “QID” refers to question ID onStack Overﬂow, and “#ans” refers to the total number ofposted answers for the question. Overall, ISPY helps with 26unanswered issues, and there are 6 solutions that have beenaccepted as the best answers. Fig. 5 presents an example ofresolved issue posted on Stack Overﬂow. We can see that,ISPY can expedite the resolving process of “BuildProperties”issue by providing a workable solution. Speciﬁcally, ISPY canprovide the unanswered issues with brief root causes (e.g.,57543742), reference documentation (e.g., 59282213), detailedguidelines (e.g., 66868053), etc. ISPY can also provide timelyresponses to answer-hungry issues. For example, there are15/26 questions that have no answer at ﬁrst, and ISPY’ssolutions sever as their only answers (see red questions with#ans=1 in Table IV).
Summing up, ISPY helps with unanswered issues on Stack
Overﬂow, and there are 6/26 solutions that have been acceptedas best answers. The results explicitly show that ISPY can pro-mote knowledge sharing and expedite issue-resolving process.
VII. D
ISCUSSION AND FUTURE WORK
A. Usage Scenario
Serving potential answers. Despite the success of technical
Q&A sites such as Stack Overﬂow, the answer-hungry problemremains a challenging issue for these forums [50]. The minedissue-solution pairs could serve as a knowledge base that canbe potentially integrated with, and provide queried informationto these Q&A forums. When users ask issues similar to whatpeople have discussed on community chats, the correspondingsolutions could be automatically retrieved and recommendedas potential answers, relieving the answer-hungry problem toa large extent. On the other hand, the extracted issue-solution
pairs are also useful for boosting the automation Q&A in the
community live chats by recommending similar questions andcorresponding discussions.
Fig. 5: An example of “BuildProperties” issue resolved byISPY’s solution on Stack Overﬂow
150Boosting developers’ proﬁles. Developers who often pro-
vide solutions in community chats may have certain expert
knowledge in particular areas. According to their historicalanswers in live chats, the issue-solution pairs extracted can befurther used to recommend or assign appropriate respondentsto answer questions. Researchers could also ﬁnd out whichmodules or functionalities that the developers are familiarwith by analyzing the issue topics that developers have beenaddressed. Thus, researchers could utilize that information toenhance crowd-sourcing tasks, such as code reviewer recom-mendation [51], [52] and issue triage [53], [54].
Highlighting unresolved issues. Our approach can effec-
tively ﬁnd issue-solution pairs from live chats. It can also
ﬁnd issues where their solutions are empty. Such issues arelikely to be the unresolved issues spotted in live chats but are
not reported to the project repositories (such as Github). It is
valuable to make the community notice them, e.g., directlypush the unresolved issues to the code repository. Otherwise,they are likely to be buried in the massive live chats, and theteam might miss the opportunity to ﬁx them in time. Therefore,a side effect of our approach is to help highlight unresolvedissues buried in community live chats.
Augmenting Organization/Community Knowledge Base.
ISPY can augment the knowledge base of organizations orcommunities by including discovered issue-solution pairs fromgroup live chats in an automatic and just-in-time way. More-over, existing technologies such as ontology [55] and semanticweb [56] can be more effective to support information inquir-ing and sharing across platforms.
B. Where Does ISPY Perform Unsatisfactorily
Case 1: Handling dialogs with an issue description
utterance lagging behind. ISPY use the dialog head (all the
utterances posted by the dialog initiator before any reply)
as the input of our issue model, with the assumption that
the dialog initiators are likely to express the issues at thebeginning. However, we ﬁnd that dialog initiators occasionallylag their issue description behind. Here is an example, we cansee that, the issue description appears in the u
b2utterance,
beyond the scope of the dialog head. In such cases, ISPY
cannot accurately detect issues. In the future, we plan todynamically extend the scope of the dialog head, so that thelagging issue descriptions can be included.
(uh) <A> Good Morning, trying to figure out how to create
the DataProvider<DataSetIterator>. [Dialog Head]
(ub1) <B> Go ahead, no need for greeting!
(ub2) <A> [<-CODE->] incorrect. How to create the
DataProvider from a RecordReaderDataSetIterator? [Issue
description]
Case 2: Representing different conﬁdence levels on
extracted solutions. When discussing issues in community
live chats, developers who post the issues often give feedbacks
about the solutions provided by their peers at the end. Forexample, we ﬁnd that some typical feedbacks are: “It works.”,“The issue is ﬁxed.”, “Figured it out.”, etc. These feedbackscan indicate different conﬁdence levels of the correspondingsolution: Conﬁrmed and Candidate. “Conﬁrmed” refers to thesolution that has been proved to work by the initiator, and
“Candidate” refers to the solution that has the potential toresolve the issue. In the future, we plan to reﬁne the extractedsolutions by providing different conﬁdence levels as well.
Case 3: Differentiating solutions involving version num-
bers. From the usefulness evaluation results (Table IV), we
notice that the question “66378139” did not select ISPY’s
solution as its best answer. This is because that the ISPY’ssolution is extracted from the dialog discussing the similarissue in Spring Boot 3.0.0 while the posted issue is related toSpring Boot 2.4.3. Thus, the solution might not be completelysuitable. In the future, we plan to address this issue by linkingeach issue-solution pair to its corresponding version for betterapplication.
Case 4: Enhancing smoothness when combining solu-
tion. We directly combine the predicted solution utterances
according to their chronological orders as the solution. Forthe predicted utterances that are not consecutive in the original
dialog, logical gaps exist between them. Thus, it may reduce
the readability of ISPY’s solutions. In the future, we wouldlike to improve the readability of the extracted solutions byleveraging language models [57].
C. Threats to V alidity
The ﬁrst threat is the generalizability of the proposed
approach. It is only evaluated on eight open-source projects,
which might not be representative of closed-source projects orother open-source projects. The results may be different if themodel is applied to other projects. However, our dataset comesfrom eight different ﬁelds. The variety of projects relativelyreduce this threat.
The second threat may come from the results of dialog
disentanglement. The accuracy of disentangled dialog has animpact on our results. To reduce the threat, we employedthe state-of-the-art technique proposed by Kummerfeld et al.[24], which outperforms previous studies by achieving 74.9%precision and 79.7% recall. Therefore, we believe this canserve as a good foundation for our study on mining issue-solution pairs.
The third threat relates to the construct of our approach.
First, we hypothesize that issue description is likely to appearin dialog head, which is occasionally incorrect in certain cases.
Second, we do not add version information to issue-solution
pairs, which may result in recommending inappropriate solu-tions. To alleviate the threat, we thoroughly analyzed whereour approach performs unsatisfactorily in section VII, andplanned future work for improvement. Third, the dataset usedfor the training of the approach includes 750 dialogs and 171issue-solution pairs from eight Gitter communities, which isnot quite large. To avoid the risks of overﬁtting, we combineddropout with early stopping when training. We observed thatthe training convergences were achieved at epoch 10-15, andthe performance could not be better even more data is givenfor training.
The fourth threat relates to the suitability of evaluation
metrics. We utilize precision, recall, and F1 to evaluate the
151performance. We use the dialog labels and utterance labels
manually labeled as ground truth when calculating the perfor-mance metrics. The threats can be largely relieved as all theinstances are reviewed with a concluding discussion sessionto resolve disagreement in labels based on majority voting.
VIII. R
ELATED WORK
Knowledge Extraction from Developer Conversations .
Recently, more and more work has realized that commu-
nity chat plays an increasingly signiﬁcant role in softwaredevelopment, and chat messages are a rich and untappedsource for valuable information about the software system[1], [3], [58]. There are several studies focusing on extractingknowledge from developer conversations. Di Sorbo et al.[46] proposed a taxonomy of intentions to classify sentencesin developer mailing lists. Huang et al. [44] addressed thedeﬁciencies of Di Sorbo et al’s taxonomy by proposing aconvolution neural network (CNN)-based approach. Qu et al.[28] utilized classic machine learning methods to performuser intent prediction with an average F1 of 0.67. Shi et al.
[59] proposed an approach to detect feature-request dialoguesfrom developer chat messages via a deep siamese network.
Rodeghero et al. [60] presented a technique for automaticallyextracting information relevant to user stories from recordedconversations. Chowdhury and Hindle [61] ﬁltered out off-topic discussions in programming IRC channels by engaging
Stack Overﬂow discussions as positive examples and YouTube
video comments. The ﬁndings of previous work motivate thework presented in this paper. Our study is different fromthe previous work as we focus on extracting issue-solutionpairs from massive chat messages that would be important
and valuable information for OSS developers to check and ﬁxissues. In addition, our work complements the existing studies
on knowledge extraction from developer conversations.
Emerging Issue Detection. Detecting emerging issues from
user feedback timely and precisely is vital for developersto update their applications. Most current work focuses ondetecting the emerging issues from short-text social media(e.g., Twitter and Google Play), and determining the emergingissues based on traditional anomaly detection methods. Forexample, Guo et al. [42] proposed a method for extract-ing and synthesizing user-reported mini-stories regarding appproblems from reviews. Vu et al. [62] detected emergingissues and trends by counting negative keywords based onGoogle Play. Since the single words might be ambiguouswithout contexts, their follow-up work [63] proposed a phrase-based clustering approach that relied on manual validationof part-of-speech (PoS) sequences. Gao et al. [64] presenteda topic labeling approach, named IDEA, to automaticallydetect emerging issues of current versions based on statisticsof previous versions. Due to the inborn limitations of topicmodeling, such as the predeﬁned topic numbers, their follow-up work [65] introduced DIVER which incorporated depth-ﬁrst pattern mining with version and time-based comparisons.Most of these methods focus on detecting emerging issuesembedding in short-text social media, while our approachtargets to automatically extract issues with their potentialsolutions (if exists) from community chats, complementing theexisting studies on a novel source. In addition, our approachcan not only detect emerging issues in community chat, butalso extract relevant solutions with resolved issues for reuse
purposes, aiming to expedite the issue resolving process.
Community-based question and answer extraction. Gen-
erating large-scale technical question-answer pairs is critical
for contributing knowledge that can facilitate software devel-opment activities. Existing studies are designed to ﬁnd ques-tions and corresponding answers from synchronous conversa-tions, i.e., mailing lists and forums. Shrestha et al. [66] ﬁrst
trained a set of if-then rules to predict questions in email mes-
sages, and another set of if-then rules to predict correspondinganswers based on features of texts. Huang et al. [67] presentedan approach for extracting high-quality <thread-title, reply>
pairs from online forums based on SVM classiﬁer and content-quality ranking. Cong et al. [68] proposed a sequential pattern-
based classiﬁcation method to detect questions in a forum
thread, and a graph-based propagation method to detect an-swers for questions in the same thread. Since previous studiesextracted only questions in interrogative forms, Kwong et al.[69] extended the scope of questions and answer detection,
and pairing to encompass also questioned in imperative and
declarative forms. Henß et al. [70] presented an approach toextract FAQs from sources of software development mailinglists automatically. These approaches utilize the characteristicsof their corpora and are best ﬁt for their speciﬁc tasks, but theylimit each of their corpora and tasks, so they cannot directly
transform their methods to the task of extracting issue-solution
pairs from community chats.
IX. C
ONCLUSION
In this paper, we propose an approach, named ISPY, to
automatically extract issue-solution pairs from developmentcommunity live chats. ISPY leverages a novel convolutionalneural network by incorporating a basic CNN network with 15heuristic attributes and Local-Attention mechanism to handle
the characteristics of this task. We build a dataset with 750dialogs, including 171 issue-solution pairs, and evaluate ISPYon it. The evaluation results show that our approach outper-forms both issue-detection baselines and solution-extractionbaselines by substantial margins. By applying ISPY, we alsoautomatically generate a dataset with over 30K issue-solution
pairs extracted from 11 community live chats, and we utilizethe dataset to provide solutions for 26 recent issues posted onStack Overﬂow.
A
CKNOWLEDGMENTS
We deeply appreciate anonymous reviewers for their con-
structive and insightful suggestions towards improving this
manuscript. This work is supported by the National KeyResearch and Development Program of China under GrantNo. 2018YFB1403400, the National Science Foundation ofChina under Grant No. 61802374, 62002348, 62072442,614220920020 and Youth Innovation Promotion AssociationChinese Academy of Sciences.
152REFERENCES
[1] P. Chatterjee, K. Damevski, L. Pollock, V . Augustine, and N. A. Kraft,
“Exploratory Study of Slack Q&A Chats as a Mining Source for
Software Engineering Tools,” in Proceedings of the 16th International
Conference on Mining Software Repositories . IEEE Press, 2019, pp.
490–501.
[2] P. Chatterjee, M. Kong, and L. L. Pollock, “Finding Help with Pro-
gramming Errors: An Exploratory Study of Novice Software Engineers’
Focus in Stack Overﬂow Posts,” J. Syst. Softw., vol. 159, 2020.
[3] B. Lin, A. Zagalsky, M. D. Storey, and A. Serebrenik, “Why Developers
Are Slacking Off: Understanding How Software Teams Use Slack,”
inProceedings of the 19th ACM Conference on Computer Supported
Cooperative Work and Social Computing, 2016, pp. 333–336.
[4] E. Shihab, Z. M. Jiang, and A. E. Hassan, “On the Use of Internet Relay
Chat (IRC) Meetings by Developers of the GNOME GTK+ Project,” inProceedings of the 6th International Working Conference on Mining
Software Repositories, MSR 2009 (Co-located with ICSE) , 2009, pp.
107–110.
[5] E. Shihab, Z. M. Jiang and A. E. Hassan, “Studying the Use of Developer
IRC Meetings in Open Source Projects,” in 25th IEEE International
Conference on Software Maintenance (ICSM 2009), 2009, pp. 147–156.
[6] C. Miller, P. Rodeghero, M. D. Storey, D. Ford, and T. Zimmermann,
“‘How Was Your Weekend?’ Software Development Teams Working
From Home During COVID-19,” CoRR, vol. abs/2101.05877, 2021.
[7] O. Ehsan, S. Hassan, M. E. Mezouar, and Y . Zou, “An Empirical Study
of Developer Discussions in the Gitter Platform,” ACM Trans. Softw.
Eng. Methodol., vol. 30, no. 1, pp. 8:1–8:39, 2021.
[8] L. Shi, X. Chen, Y . Yang, H. Jiang, Z. Jiang, N. Niu, and Q. Wang, “A
First Look at Developers’ Live Chat on Gitter,” in ESEC/FSE ’21: 29th
ACM Joint European Software Engineering Conference and Symposium
on the Foundations of Software Engineering, Virtual Event. ACM,
2021.
[9] R. Alkadhi, T. Lata, E. Guzman, and B. Bruegge, “Rationale in Devel-
opment Chat Messages: An Exploratory Study,” in Proceedings of the
14th International Conference on Mining Software Repositories, MSR2017. IEEE Computer Society, 2017, pp. 436–446.
[10] R. Alkadhi, M. Nonnenmacher, E. Guzman, and B. Bruegge, “How do
Developers Discuss Rationale?” in 25th International Conference on
Software Analysis, Evolution and Reengineering, SANER 2018 . IEEE
Computer Society, 2018, pp. 357–369.
[11] T. Li, J.-C. Gu, X. Zhu, Q. Liu, Z.-H. Ling, Z. Su, and S. Wei,
“DialBERT: A Hierarchical Pre-Trained Model for Conversation Dis-
entanglement,” 2020.
[12] H. Liu, Z. Shi, J.-C. Gu, Q. Liu, S. Wei, and X. Zhu, “End-to-End
Transition-Based Online Dialogue Disentanglement,” ser. IJCAI ’20, 7
2020, pp. 3868–3874.
[13] J. K. Kummerfeld, S. R. Gouravajhala, J. Peper, V . Athreya, C. Gu-
nasekara, J. Ganhotra, S. S. Patel, L. Polymenakos, and W. S. Lasecki,
“A Large-Scale Corpus for Conversation Disentanglement,” in Proceed-
ings of the 57th Annual Meeting of the Association for ComputationalLinguistics, July 2019, pp. 3846–3856.
[14] S. Mehri and G. Carenini, “Chat Disentanglement: Identifying Semantic
Reply Relationships with Random Forests and Recurrent Neural Net-
works,” in Proceedings of the Eighth International Joint Conference on
Natural Language Processing (V olume 1: Long Papers), Nov. 2017, pp.
615–623.
[15] T. Yu and S. Joty, “Online Conversation Disentanglement with Pointer
Networks,” in Proceedings of the 2020 Conference on Empirical Meth-
ods in Natural Language Processing. Association for ComputationalLinguistics, Nov. 2020, pp. 6321–6330.
[16] NLTK, “NLTK,” https://nltk.org/, 2020.
[17] Explosion, “Spacy,” https://www.spacy.io/, 2021.[18] O. U. Press, “Abbreviations — Oxford English Dictionary,” https:
//public.oed.com/, 2021.
[19] I. Boutet, M. LeBlanc, J. A. Chamberland, and C. A. Collin, “Emojis
inﬂuence emotional communication, social attributions, and information
processing,” Comput. Hum. Behav. , vol. 119, p. 106722, 2021. [Online].
Available: https://doi.org/10.1016/j.chb.2021.106722
[20] C. Suman, S. Saha, P. Bhattacharyya, and R. S. Chaudhari, “Emoji
helps! A multi-modal siamese architecture for tweet user veriﬁcation,”Cogn. Comput., vol. 13, no. 2, pp. 261–276, 2021. [Online]. Available:
https://doi.org/10.1007/s12559-020-09715-7[21] M. Popel and D. Mare ˇcek, “Perplexity of n-Gram and Dependency
Language Models,” vol. 6231, 03 2010, pp. 173–180.
[22] Baidu, “Baidu AI Cloud,” https://intl.cloud.baidu.com/, 2021.
[23]
R. J´ozefowicz, O. Vinyals, M. Schuster, N. Shazeer, and Y . Wu, “Ex-
ploring the Limits of Language Modeling,” CoRR, vol. abs/1602.02410,
2016.
[24] J. K. Kummerfeld, S. R. Gouravajhala, J. Peper, V . Athreya, C. Gu-
nasekara, J. Ganhotra, S. S. Patel, L. Polymenakos, and W. S. Lasecki,
“A Large-Scale Corpus for Conversation Disentanglement,” in Proceed-
ings of the 57th Annual Meeting of the Association for Computational
Linguistics (V olume 1: Long Papers).
[25] J. Devlin, M. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of
Deep Bidirectional Transformers for Language Understanding,” CoRR,
vol. abs/1810.04805, 2018.
[26] H. Tayyar Madabushi, E. Kochkina, and M. Castelle, “Cost-Sensitive
BERT for Generalisable Sentence Classiﬁcation on Imbalanced Data,”
inProceedings of the Second Workshop on Natural Language Processing
for Internet Freedom: Censorship, Disinformation, and Propaganda.
Association for Computational Linguistics, Nov. 2019, pp. 125–134.
[27] C. Sun and Z. Yang, “Transfer Learning in Biomedical Named Entity
Recognition: An Evaluation of BERT in the PharmaCoNER task,” inProceedings of The 5th Workshop on BioNLP Open Shared Tasks.Association for Computational Linguistics, Nov. 2019, pp. 100–104.
[28] C. Qu, L. Yang, W. B. Croft, Y . Zhang, J. Trippas, and M. Qiu, “User
Intent Prediction in Information-seeking Conversations,” in CHIIR ’19,
2019.
[29] Y . Kim, “Convolutional Neural Networks for Sentence Classiﬁcation,”
arXiv preprint arXiv:1408.5882, 2014.
[30] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet Classiﬁcation
with Deep Convolutional Neural Networks,” in Advances in neural
information processing systems, 2012, pp. 1097–1105.
[31] G. Salton and C. Buckley, “Term-weighting Approaches in Automatic
Text Retrieval,” Information Processing & Management, vol. 24, no. 5,
pp. 513–523, 1988.
[32] M. Kusner, Y . Sun, N. Kolkin, and K. Weinberger, “From Word
Embeddings to Document Distances,” in International conference on
machine learning. PMLR, 2015, pp. 957–966.
[33] D. Bahdanau, K. Cho, and Y . Bengio, “Neural Machine Translation by
Jointly Learning to Align and Translate,” CoRR, vol. abs/1409.0473,
2015.
[34] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
u. Kaiser, and I. Polosukhin, “Attention is All You Need,” in Proceedings
of the 31st International Conference on Neural Information ProcessingSystems, ser. NIPS’17. Red Hook, NY , USA: Curran Associates Inc.,2017, p. 6000–6010.
[35] Google, “Gitter,” https://gitter.im/, 2020.
[36] Google, “Slack,” https://slack.com/, 2020.[37] Gitter, “REST API,” https://developer.gitter.im/docs/rest-api, 2020.[38] C. Robert, “Machine Learning, a Probabilistic Perspective,” CHANCE,
vol. 27, pp. 62–63, 04 2014.
[39] A. McCallum, K. Nigam et al., “A Comparison of Event Models for
Naive Bayes Text Classiﬁcation,” in AAAI-98 workshop on learning for
text categorization, vol. 752, no. 1. Citeseer, 1998, pp. 41–48.
[40] A. Liaw, M. Wiener et al., “Classiﬁcation and Regression by Random-
Forest,” Rn e w s , vol. 2, no. 3, pp. 18–22, 2002.
[41] G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and
T.-Y . Liu, “Lightgbm: A Highly Efﬁcient Gradient Boosting Decision
Tree,” in Advances in Neural Information Processing Systems, 2017, pp.
3146–3154.
[42] H. Guo and M. P. Singh, “Caspar: Extracting and Synthesizing User
Stories of Problems from App Reviews,” in ICSE ’20: 42nd International
Conference on Software Engineering. ACM, 2020, pp. 628–640.
[43] H. Guo, “Stories in App Reviews,” https://hguo5.github.io/Caspar/, 2020.
[44] Q. Huang, X. Xia, D. Lo, and G. C. Murphy, “Automating Intention
Mining,” IEEE Transactions on Software Engineering, vol. PP, no. 99,
pp. 1–1, 2018.
[45] S. Haykin, Neural Networks: A Comprehensive Foundation (3rd Edi-
tion).
Neural Networks: A Comprehensive Foundation (3rd Edition),
1998.
[46] A. D. Sorbo, S. Panichella, C. A. Visaggio, M. D. Penta, G. Canfora,
and H. C. Gall, “Development Emails Content Analyzer: IntentionMining in Developer Discussions (T),” in 30th IEEE/ACM International
Conference on Automated Software Engineering, ASE 2015. IEEE
Computer Society, 2015, pp. 12–23.
153[47] s.e.a.l., “UZH-s.e.a.l.-Development Emails Content Analyzer (DECA),”
https://www.iﬁ.uzh.ch/en/seal/people/panichella/tools/DECA.html,
2017.
[48] C. Qu, L. Yang, W. B. Croft, J. Trippas, Y . Zhang, and M. Qiu,
“Analyzing and Characterizing User Intent in Information-seeking Con-
versations,” in SIGIR ’18, 2018.
[49] J. Pennington, R. Socher, and C. Manning, “Glove: Global Vectors for
Word Representation,” vol. 14, 01 2014, pp. 1532–1543.
[50] Z. Gao, X. Xia, D. Lo, and J. Grundy, “Technical Q8A Site Answer
Recommendation via Question Boosting,” ACM Trans. Softw. Eng.
Methodol., vol. 30, no. 1, pp. 11:1–11:34, 2021.
[51] S. Rebai, A. Amich, S. Molaei, M. Kessentini, and R. Kazman, “Multi-
objective Code Reviewer Recommendations: Balancing Expertise, Avail-ability and Collaborations,” Autom. Softw. Eng., vol. 27, no. 3, pp. 301–
328, 2020.
[52] M. B. Zanjani, H. H. Kagdi, and C. Bird, “Automatically Recommending
Peer Reviewers in Modern Code Review,” IEEE Trans. Software Eng.,
vol. 42, no. 6, pp. 530–543, 2016.
[53] R. Almhana and M. Kessentini, “Considering Dependencies between
Bug Reports to Improve Bugs Triage,” Autom. Softw. Eng., vol. 28,
no. 1, p. 1, 2021.
[54] I. Alazzam, A. AlEroud, Z. A. Latifah, and G. Karabatis, “Automatic
Bug Triage in Software Systems Using Graph Neighborhood Relations
for Feature Augmentation,” IEEE Trans. Comput. Soc. Syst., vol. 7, no. 5,
pp. 1288–1303, 2020.
[55] S. Staab and R. Studer, “Handbook on Ontologies,” international hand-
books on information systems, vol. 2, pp. 227–255, 2004.
[56] G. Antoniou and F. H. Van, A Semantic Web primer. A Semantic Web
primer, 2004.
[57] Y . Sun, S. Wang, Y . Li, S. Feng, and H. Wang, “ERNIE 2.0: A Continual
Pre-Training Framework for Language Understanding,” Proceedings of
the AAAI Conference on Artiﬁcial Intelligence, vol. 34, no. 5, pp. 8968–
8975, 2020.
[58] P. Chatterjee, K. Damevski, N. A. Kraft, and L. L. Pollock, “Software-
related Slack Chats with Disentangled Conversations,” in MSR ’20: 17th
International Conference on Mining Software Repositories. ACM,
2020, pp. 588–592.
[59] L. Shi, M. Xing, M. Li, Y . Wang, S. Li, and Q. Wang, “Detection
of Hidden Feature Requests from Massive Chat Messages via DeepSiamese Network,” in ICSE ’20: 42nd International Conference on
Software Engineering. ACM, 2020, pp. 641–653.
[68] G. Cong, L. Wang, C. Lin, Y . Song, and Y . Sun, “Finding Question-
answer Pairs from Online Forums,” in Proceedings of the 31st Annual[60] P. Rodeghero, S. Jiang, A. Armaly, and C. McMillan, “Detecting User
Story Information in Developer-client Conversations to Generate Extrac-
tive Summaries,” in Proceedings of the 39th International Conference
on Software Engineering, ICSE 2017. IEEE / ACM, 2017, pp. 49–59.
[61] S. A. Chowdhury and A. Hindle, “Mining StackOverﬂow to Filter out
Off-topic IRC Discussion,” pp. 422–425, 2015.
[62] P. M. Vu, T. T. Nguyen, H. V . Pham, and T. T. Nguyen, “Mining User
Opinions in Mobile App Reviews: A Keyword-Based Approach (T),”
in30th IEEE/ACM International Conference on Automated Software
Engineering, ASE 2015. IEEE Computer Society, 2015, pp. 749–759.
[63] P. M. Vu, H. V . Pham, T. T. Nguyen, and T. T. Nguyen, “Phrase-based
Extraction of User Opinions in Mobile App Reviews,” in Proceedings
of the 31st IEEE/ACM International Conference on Automated SoftwareEngineering, ASE 2016. ACM, 2016, pp. 726–731.
[64] C. Gao, J. Zeng, M. R. Lyu, and I. King, “Online App Review
Analysis for Identifying Emerging Issues,” in Proceedings of the 40th
International Conference on Software Engineering, ICSE 2018 . ACM,
2018, pp. 48–58.
[65] C. Gao, W. Zheng, Y . Deng, D. Lo, J. Zeng, M. R. Lyu, and I. King,
“Emerging App Issue Identiﬁcation from User Feedback: Experienceon WeChat,” in Proceedings of the 41st International Conference on
Software Engineering: Software Engineering in Practice, ICSE (SEIP)
2019. IEEE / ACM, 2019, pp. 279–288.
[66] L. Shrestha and K. R. McKeown, “Detection of Question-Answer Pairs
in Email Conversations,” in COLING 2004, 20th International Con-
ference on Computational Linguistics, Proceedings of the Conference,2004.
[67]
J. Huang, M. Zhou, and D. Yang, “Extracting Chatbot Knowledge from
Online Discussion Forums,” in IJCAI 2007, Proceedings of the 20th
International Joint Conference on Artiﬁcial Intelligence , 2007, pp. 423–
428.
International ACM SIGIR Conference on Research and Development in
Information Retrieval, SIGIR 2008 . ACM, 2008, pp. 467–474.
[69] H. Kwong and N. Yorke-Smith, “Detection of Imperative and Declar-
ative Question-answer Pairs in Email conversations,” AI Commun.,
vol. 25, no. 4, pp. 271–283, 2012.
[70] S. Henß, M. Monperrus, and M. Mezini, “Semi-automatically Extracting
FAQs to Improve Accessibility of Software Development Knowledge,”in34th International Conference on Software Engineering, ICSE 2012 .
IEEE Computer Society, 2012, pp. 793–803.
154