Analyzing User Perspectives on Mobile App Privacy at Scale
Preksha Nema
Google
Bangalore, India
preksh@google.comPauline Anthonysamy
Google
Zurich, Switzerland
anthonysp@google.com
Nina Taft
Google
Mountain View, USA
ninataft@google.comSai Teja Peddinti
Google
Mountain View, USA
psaiteja@google.com
ABSTRACT
In this paper we present a methodology to analyze usersâ€™ con-
cerns and perspectives about privacy at scale. We leverage NLP
techniquestoprocessmillionsofmobileappreviewsandextract
privacyconcerns.Ourmethodologyiscomposedofabinaryclas-sifier thatdistinguishes between privacyand non-privacy related
reviews.Weuseclusteringtogatherreviewsthatdiscusssimilarprivacy concerns, and employ summarization metrics to extractrepresentative reviews to summarize each cluster. We apply ourmethods on 287M reviews for about 2M apps across the 29 cate-
gories in Google Play to identify top privacy pain points in mobile
apps. We identified approximately 440K privacy related reviews.
Wefindthatprivacyrelatedreviewsoccurinall29categories,with
someissuesarisingacrossnumerousappcategoriesandotherissues
only surfacing in a small set of app categories. We show empirical
evidence that confirms dominant privacy themes â€“ concerns about
apps requesting unnecessary permissions, collection of personal
information,frustrationwithprivacycontrols,trackingandthesell-
ing of personal data. As far as we know, this is the first large scale
analysis to confirm these findings based on hundreds of thousands
of user inputs. We also observe some unexpected findings suchas users warning each other not to install an app due to privacyissues, users uninstalling apps due to privacy reasons, as well as
positivereviewsthatrewarddevelopersforprivacyfriendlyapps.
Finally we discuss the implications of our method and findings for
developers and app stores.
KEYWORDS
privacy, nlp, mobile apps, empirical
ACM Reference Format:
Preksha Nema, Pauline Anthonysamy, Nina Taft, and Sai Teja Peddinti.
2022. Analyzing User Perspectives on Mobile App Privacy at Scale. In 44th
InternationalConferenceonSoftwareEngineering(ICSEâ€™22),May21â€“29,2022,
Pittsburgh, PA, USA. ACM, New York, NY, USA, 13 pages. https://doi.org/10.
1145/3510003.3510079
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.35100791 INTRODUCTION
In app stores, such as Google Play and Appleâ€™s App Store, users
can write reviews to share their experience and opinions about the
appsthattheyuse.Reviewshelpotheruserstounderstandwhether
or not the app might be of interest to them. These reviews are also
a feedback channel to developers whocan learn how toimprove
theirapps.Appreviewscanbeachallengetoanalyzeastheyare
knowntocoverabroadrangeoftopics,havewidelyvaryingquality
(that is somewhat exacerbated by their unstructured form) [ 54];
thusitcanbedifficultfordeveloperstoparseoutseparateissues.
Moreover, some issues, such as privacy related feedback, may have
lowervolumethanotherissues(e.g.,batteryperformance),andthus
maybelessvisible.However e xtractingprivacyrelatedfeedback
is of particular importance as by now developers are well aware
thattrustisheavilyimpactedbytheirprivacyposture,andbecause
privacy legislation and regulation are on the rise.
Unstructured app reviews provide a potentially rich source of
contenttolearnaboutusersâ€™perspectivesonprivacy.Userfeedback
canbeminedatscaletoextractproductrequirements[ 45,68],how-
everthesemethodsdonotfocusonprivacy.Traditionalmethods
forgaining insightsintouserperspectivesaboutprivacy include
conductingqualitativestudiesandsurveys.Qualitativestudieshave
theadvantageofbeingindepthastheyinvolveone-on-oneinter-
views, however they are limited in scale to include typically 20-30
participants. Surveys, on the other hand, have the advantage being
structured and repeatable, however are also limited in terms of
scaletypicallytoafewthousands.Byleveragingautomationand
advancedNaturalLanguageProcessing(NLP)techniques,feedback
by millions of users can be analyzed rapidly to extract privacy per-
spectives.Thisapproachcomplementsexistingqualitativemethods
as it obtains privacy concerns on a new scale, yet cannot follow up
withusersforadditionalinformation.Ourapproachenablesdata
drivendecisionstobemade-suchaspriorityrankingacrossmulti-
ple issues. We therefore answer the following research questions:
â€¢Canmobile app reviewsbe automaticallyanalyzed atscale
to identify privacy related ones?
â€¢Can the identified privacy reviews be used to understandusersâ€™ privacy concerns? How do they compare with con-
cerns inferred from other qualitative methodologies?
â€¢How can such a methodology be leveraged to inform the
ecosystem, and more specifically mobile app developers?
Thispaperpresentstwomaincontributions.Thefirstisamethod-
ology to analyze userâ€™s privacyconcerns with mobile apps via NLP
1122022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Preksha Nema, Pauline Anthonysamy, Nina Taft, and Sai Teja Peddinti
techniques atscale.The methodologyincludes abinary classifier
to decide whether or not a particular review discusses a privacy
topic, a mechanism to cluster reviews that discuss similar semantic
topics, and a way to summarize the clusters by identifying reviews
that are highly representative of all those belonging to a single
cluster.Ourmethodologyopensthedoortoarichsetofsubsequent
research on user privacy perspectives (e.g., relative ranking of pri-
vacy concerns, how these concerns evolve over time, why some
privacy issues occur predominantly within specific app categories,
userperspectivesondifferentelementsofpersonaldata,etc).Italso
enables tools for developers to receive feedback thatcan help them
improve the privacy of their products.
Oursecondcontributionusesthemethodologytoprovide em-
piricalevidence (afirst large-scale analysis)thatconfirmsdomi-
nantprivacythemesthathavebeenidentifiedinqualitativestud-
ies[3,25,36,47,79].We applyourmethods to287Mreviews, and
report on the wide variation of privacy reviews across app cate-
gories,relativereviewingofspecificapppermissionsanddominant
privacy themes. We also discuss the implications of our findings
fordevelopersandhowtheycaninformthedesignofprivacytools
in app stores.
There are many challenges to this problem space. First, there
is no labeled data. Second, the boundary of when a text is about
privacyornotisafuzzyone;forexample,manysecurityandprivacyexpertsoftendonotagreeontheamountofoverlapbetweenthesetwoareas[
13,19].Third,weneedtobeabletocaptureabroadrange
ofprivacyconcerns,i.e.,anytopicthatexistsinestablishedprivacy
taxonomies[ 4,67].Fourth,tolearnabroadrangeofcontexts,we
need a classifier that can do more than memorization of keywords.
Fifth,userreviewsarewellknowntobevariableintheirwriting
style [54] which can lead to classification errors. We address all
these challenges herein.
Ourfirstcontributiondevelopsamulti-stepmethodtoaddress
this problem. To generate our test, validation and training data we
employamethodthatcombinesExpert-Hand-LabelingandHeuris-
ticSupervision[ 61](Challenge#1).Inthisbootstrappingprocess
weconstructasetofregularexpressionsinconsultationwithlin-
guisticexperts,andbasedonourmanualobservationsofhowusers
express privacy concerns in reviews (Challenge #2, #3). We next
developaprivacyclassifierasanensemblemodelthatcouplesboth
USE[14]andBERT[ 20]deeplearningmodels,whicharetrained
onusertextsandareknowntogeneralizewell(Challenge#3,#4,
#5). Our classifier achieves 98% precision and 87% recall. We use
K-means clusteringto groupsimilar privacy reviews,and propose
anewmetrictodetermineagoodvalueof ğ‘˜thatproducescompact
single-issueclusters(Challenge#3).Wesummarizethetopicclus-
ters, by extracting representative reviews for the cluster. Overall
thisyieldsanewmethodtounderstanduserinsightsaboutprivacy
that complements traditional qualitative methods.
The development of automated privacy text classifiers (for user
text) and the ability to separate privacy issues into distinct clusters
in an unsupervised fashion, enables numerous types of large-scale
analyses including (some of which are discussed in this paper) -
rankingofissues,breadthofconcernsacrossapptypes,unantici-
pated and emergingissues, sentiment with which usersapproach
specific issues, user behavior (e.g. uninstalling an app), compar-
isonsacrossapptypes(e.g.childrenâ€™sversusregularapps),issuesper culture (as captured by language) and more. We discuss how
suchfindingscaninformdevelopersaboutprivacyshortcomings
of their apps, and more generally, how it could inform privacy best
practices across app stores.
Oursecondcontributionisalargescaleanalysisusingourmethod-
ology on 287M reviews, coming from approximately 2M apps from
thePlayStore.Weidentifyapproximately440Kreviewsthatdiscuss
privacy. We found that the privacy-related reviews exist in all ofthe 29 app categories
1in the Play store, and that these reviews
capture a breadth of privacy concerns and perspectives. We find
manyreviewswhereusersasktoknowthepurposeforarequesttocollectpersonalinformationorpermissiongateddata(e.g.,location,contacts,camera,etc).Weobservedfoursomewhatunexpectedfind-
ings: (1) users warn each other not to install an app due to privacy
reasons; (2) users uninstall apps due to privacy concerns; (3) users
concerns about the selling of personal data are largely confined to
a small set of app categories; and (4) some users reward developers
whose apps are privacy friendly with privacy positive reviews.
We apply our clustering and summarization to ten categories
of apps and identify the large compact clusters within each cat-egory. From these, we identity five dominant privacy concerns
acrossmultipleappcategories:apps thatappeartorequestunnec-
essary permissions, collection of personal information, tracking,
privacy controls and apps that may be selling personal data. Next,
we present an overview of these dominant themes using our au-
tomaticallyselectedrepresentativereviewsthatsummarizeeach
cluster. Whilethe dominant privacythemes that emerged fromour
analysisaregenerallywell-known,wedemonstratetheabilityto
automateandscalethisprocess.Ourinitialfindingsillustratethe
potential of such automated analysis. We conclude the paper with
a discussion on implications for developers and app stores, limita-
tions, and a summary of remaining challenges needed to further
mature this type of analysis.
2 RELATED WORK
TheprimaryuseofNLPintheprivacyspaceinthelastfewyears
has been to analyze privacy policies [ 28,31,40,49,53,56,60,63,
65,66,80]. Numerous efforts have focused on identifying incon-
sistencies between an applicationâ€™s source code and its privacy
policy [40,53,65,66,80] or itâ€™s description [ 28,56,60]. Other uses
include developing privacy chat bots [ 32] and automated question-
answer systems based on deep-learning techniques [ 31,63] to help
usersunderstanddatapractices.In[ 49],theauthorsexploretheuse
of NLP to help users avoid inadvertently sharing personally identi-
fyinginformationinsocialmedia,emails,andtextmessages.In[ 57]
the authors used NLP to analyze app description texts, within alarger mechanism to determine when two apps are similar; this
was used to inform developers when they may be requesting an
unnecessary permission. None of these privacy-oriented studies
applied NLP to analyze the text in user reviews.
User reviews have been analyzed using NLP, but not in the con-
text of privacy. Pagano and Maalej [ 54] conducted an empirical
analysis of iOS app reviews and found that reviews are not easy to
automatically analyze given their unstructured forms. Some efforts
have built classifiers to identify informative app reviews [ 15]o r
1Due to space limitations, the full list of apps has not been included in this paper.
113Analyzing User Perspectives on Mobile App Privacy at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
reviewsusefulforappmaintenance[ 55];othersidentifiedincon-
sistencies between user reviews and ratings, as well as performed
topicanalysisofnegativereviewstoshedlightonwhyusersdislike
a given app [ 26] and unsupervised topic discovery composed of
semantically similar user comments based on bidirectional NLP
algorithms[ 43];workhasalsobeendonetoautomaticallymatch
bug reports with related app reviews [ 44]. In the Requirements
Engineering space there have been large bodies of work that fo-
cusedonfeature/requirementsextractionfromuserreviewsand/or
applied a sentiment analysis to find out how users like a certain
feature [30,45,68]. [29] developed a review summarization frame-
work to categorize app reviews into categories (e.g., bug reports
andfeaturerequests),andalsoextractsaspectsandtheirsentiments
(e.g., interface is good/poor). Tian et.al. have shown that including
crowd sourced review information in app update notifications was
moreeffectiveatalertingusersofinvasiveormaliciousappupdates,
especially for less trustworthy apps [72].
The prior research that is closest to ours is [ 8,51,52]. Besmer
et al. [8] have trained a logistic regression model to detect privacy
app reviews, and have shown that privacy reviews have lower star
ratings and more negative sentiment, but have higher engagement
(more upvotes/downvotes). In both [ 51,52], the authors developed
a SVM classifier to extract reviews from the Play Store on the two
topics of security and privacy. The key purpose of [ 52] was to
determine if app reviews discussing security and privacy lead to
changesintheapp,and[ 51]focusedonhowactualappbehavior
influences usersâ€™ security and privacy concerns. Using static code
analysis, the authors in [ 52] were able to demonstrate that the
presence of security and privacy reviews are predictive of security
and privacy app updates in 60% of the cases they looked at. Thisisveryencouraging,asitmeansdevelopersdorespondtoissues
raised in these types of reviews. As part of that work, the authors
had to develop a security and privacy review classifier to extractthosereviews.Theauthorsin[
51]usedynamicanalysistoshow
userssecurityandprivacyconcernsarejustifiedinthattheapps
do often exhibit troublesome behavior along the lines indicated in
reviews.
Our work differs from these efforts in several ways. First, our
focus is on privacy, not security and privacy combined. (We ac-
knowledgethatsecurityandprivacyareinterwoven,attimes,es-
pecially when security issues such as account hacking or password
management have privacy consequences). Second, their classifiers
relyonabasicSVM/LogisticRegressionmodelsandfollowabag-
of-wordsapproach.WeusestateoftheartdeeplearningbasedNLP
models (e.g., USE and BERT) that offer multiple advantages. These
transformermodelsaretrainedonlargecorpusesoftext(e.g.,BERTistrainedonWikipedia)andthusthesemodelshavethepotentialtogeneralizebeyondthelabeledexamples.AsexplainedmorefullyinSection3.2.1,abag-of-wordsapproachislikelytomisscontext,and
that matters for identifying privacy-related reviews across a broad
setofprivacytopics.Third,weworkwithalargerdataset.Weman-uallylabeled11Kexamples(comparedto2.4Kin[
8],4Kin[52]and
6Kin[51]).Weranourinferenceanalysison287Mreviews.Fourth,
our method incorporates clustering and summarization whereas
these prior efforts only included classification. This is needed sinceourendgoal-toprovideawaytoreportusersperspectivesatscale
- is different.Thereisanenormousbodyofusablesecurityresearchonuser
perceptionstowardsmobileappprivacy.Mostquantitativework
have found that people are very protective of their personal in-
formationwhenusingapps[ 36,77],andactivelyengagewithof-
fered privacy controls to safeguard their information [ 10,39,73].
Userfrustrationduetoappsrequestingunnecessarypermissions
has been well studied [ 23,38,39,64,73,75]. In fact, users were
often surprised by the abilities of applications to collect data inthe background [
35,71], and were concerned with possible risks
associated with permissions [ 24]. Special attention has been on
studying the privacy concerns arising due to usersâ€™ location being
tracked [3, 17, 22].
Thesepriorstudiesrevealsimilarprivacyconcernsthatweob-
serve in our research. However, they are all done by surveying few
hundredparticipantsorinterviewing30orlessparticipants.Our
methodologyscalesuptolargenumbersofuserreviewsandtracks
theseissuesefficientlyacrossallapps,andourfindingsshowthe
prevalence of specific privacy concerns across app categories.
3 METHODOLOGY
Figure 1 illustrates an overview of our approach. On the left are
examplesofreviews,someofwhichareaboutprivacyandoneof
whichisnot(markedinyellow).Ourfirsttaskistoextractthose
reviewsthatarerelatedtoprivacy.Thisisachievedbyconstructing
a binary classifier to distinguish between the privacy and non-
privacyreviews.Infigure1,thereviewabouttakingpictureshas
beenfilteredoutinthesamplelistofâ€œprivacyreviewsâ€.Oursecond
task is to identify the common fine-grained privacy themes within
the privacy-relevant app reviews. For this we leverage K-Means
clustering; â€˜kâ€™isaparameterthatneedstobechosenupfront,andwe
proposeacustommetrictochoosethebestvaluefor â€˜kâ€™.Weusethe
TensorFlow[ 1]machinelearningtoolfortrainingabinaryclassifier
and clustering the privacy-related app reviews. In the following
sections,wedescribehowwegeneratetest,validationandtraining
data;presentthedesignofourprivacyclassifier;anddescribeourmethod for clustering and summarizing privacy-related reviews.
3.1 Dataset Curation
In order to develop test, validation, training and inference datasets,
wecollectedapproximately580MPlayreviewsinEnglishpublished
onthePlaystorebetweenApril2014andFeb2020.Ourdatasetwasanonymizedintermsofappnames,aseachreviewwasonlylabeled
by its app category; however we were given an aggregated appcount of 2M. We started with zero labeled data. As per the manymethods for generating labeled data, as outlined well in [
61], we
use Expert-Hand-Labeling (by subject matter experts) for our test
and validation datasets to ensure these are of the highest qualitysince they are used to evaluate the performance of our machine
learning models. Prior work [ 52] hints that privacy related reviews
mayconstitutelessthan1%ofallreviews,hencewewerefacing
an extremely imbalanced dataset. To bootstrap this procedure and
generatecandidatereviewsthatarelikelytobeaboutprivacywedidthefollowing.Wereliedontwowellknownprivacytaxonomies[
4,
67]tosettheframingforourinitialdefinitionandscopeofprivacy
issues. We curated an initial seed list of n-grams inspired by these
taxonomies. Our manual labeling team consisted of the authors
114ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Preksha Nema, Pauline Anthonysamy, Nina Taft, and Sai Teja Peddinti
Figure 1: Method pipeline.
and three linguists. We filtered reviews based on this initial seed
and conducted a preliminary manual evaluation. We looked to see
the types of words and expressions that users employ to express
privacy concerns.
There were two observations in this bootstrapping phase. First,
filteringusing1-gramand2-gramwordscanresultinmanyfalse
positives;forexample,thesinglewordâ€œtrustâ€canbeusedinâ€œdonâ€™t
trust your teammatesâ€, which is not a statement about privacy.
Thus, we decided to only use n-grams with ğ‘›>=3 for further
filtering. Second, we converted our seed list of n-grams to regular
expressions and expanded the set of expressions based on this
manual exploration. Regex patterns allow us to succinctly capture
grammaticalvariantsoftypicalprivacystatements.Foreveryregex
pattern, we checked to see if it occurred in at least 100 reviews
thatwereprivacy-related.Ourregexescapturedapproximately200
n-grams.Weacknowledgethatourlistmaynotbecompleteand
mighthavemissedprivacyissuesorphrasesusedtodiscussprivacy.
We next selected âˆ¼11K app reviews for manual labeling. To
ensure we ended up with enough labeled privacy examples, we
selected 60% of the 11K reviews because they matched against our
regexpatterns,andtheother40%wereensuredtonotmatchanyof
the regexes. Each of the 11K reviews were manually examined and
cross-labeledbythreeratersandalabel(privacyornotprivacy)was
assigned. For the vast majority of reviews, all three labelers agreed.
When this was not the case, discussion ensued until an agreement
was reached. Among the 11,371 manually labeled reviews (ground
truth),6688were labeled as privacyand4683werenot privacy.
The validation dataset used to evaluate the performance of the ML
models after each training epoch was created by extracting 250
privacyand250notprivacy reviewsfromthisset.Theremain-
ing 10,871 reviews were treated as the test set for comparing the
performance of different privacy classifiers.
Because each of our regexes (capturing 200+ n-grams) was veri-
fiedâ€“bycheckingforitsappearanceinatleast100privacy-related
reviews,andalsobasedonourmanuallabelingexerciseâ€“weas-sume our regex list effectively constitutes a set of good qualityheuristics. We use these to generate our training data, as per themethod of Heuristic-Supervision as in [
61]. We used roughly half
of the reviews ( âˆ¼290M) to generate training samples. From this set
we identified 250K app reviews that matched our privacy regex
patterns and labeled them as privacy-related reviews; we then ran-
domlysampledanother250Kreviewsthatdidnotcontainanyof
our privacyregexes and labeledthem as not-privacy. Ourprivacy
regexpatternscouldonlyidentify0.08%ofreviewsasbeingrelatedtoprivacy.Finally,weusedthesecondhalfofourcollectedreviews,namely 287M reviews, as our inference dataset. We performed clas-
sification, clustering and summarization on this set to understand
usersâ€™ top privacy concerns. The sizes of our training, validation
and test datasets are shows in Table 1.
Table 1: Size of Data Sets
Datasets Training Validation Test
Privacy 250000 250 6438
Not-privacy 250000 250 4433
EthicalConsiderations: Ourinstitutionapprovedtheuseof
this dataset because Play reviews are already public. In compliance
with ethical training guidelines in our institution, we ensured that
usersâ€™privacywererespected.Wethuscarriedoutthefollowing.
First,allresearchershavebeentrainedinethicaluserresearchprior
to this study. Second, the dataset was preprocessed to remove user
identifiersandappnamesbeforetheresearchersweregivenaccess.
The only accompanying metadata beyond the review text, was the
appâ€™scategorynameandthepublishtimestamp.Third,accessto
this version of the dataset is limited to the authors of this paper.
3.2 Privacy Classifier
The simplest approach to extract privacy related reviews might be
viaakeywordlist.However,itisnon-trivialformultiplereasons
to curate a comprehensive list of keywords. In addition to the
falsepositiveissuediscussedinSection3.1,thesamewordcould
mean different things depending on the context. For example, the
occurrence of â€œinvadingâ€ in a war game app review likely does not
refer to a privacy concern, whereas it might in a review about a
parental control app with a location tracking feature (e.g. â€œthis app
isinvadingmyprivacyâ€).Moreover,therecouldalsobeinstances
whereareviewdoesnotcontainprivacykeywordsbut,basedon
its context, still be related to privacy. For instance, â€œdonâ€™t want my
friendaccessingmyemailâ€doesnotcontainanyprivacyspecific
keywords but is a privacy concern based on the context.
Traditionalapproachestoanalyzetextrelyonthebag-of-words[ 33]
representation or use word embeddings, such as Word2Vec [ 50]
andGloVe[ 58],toencodetext.Suchsystemsdonotencodeinfor-
mationaboutthewordsequence,andthereforecannotdifferentiate
between reviews containing the same words in different order. For
example,â€œdeletecookiesandwebsitehistoryâ€andâ€œmyarticleon
historyofcookies gotdeletedfrom websiteâ€use samewords but
115Analyzing User Perspectives on Mobile App Privacy at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
have different meanings. In addition to handling context, and word
sequence, we also need to be able to correctly process reviews that
are frequently unstructured, contain highly variable writing styles,
grammatical errors and misspellings.
Theabovelimitationsestablishtheneedtoprocessreviewsbyin-
corporatingrobustNLUnderstandingcomponents.Inthiswork,we
usestate-of-the-artpre-trainednaturallanguagemodels,BERT[ 20]
andUniversalSentenceEncoder(USE)[ 14],toefficientlyencode
user reviews into an abstract representation. These models are bet-
terknowntocapturecontexts.Weprovidehereabriefbackground
on the BERT and USE language models.
BERT:Bidirectional EncoderRepresentationsfrom Transformers
(BERT)[20]isalanguagerepresentationmodelbasedontheTrans-
formerarchitecturethathasbeentrainedon3.3billionwordcorpus.
Themodelwastrainedontwotasks:â€œmaskedlanguagemodellingâ€,
where the aim is to predict the masked-out words of the input text
using the information present in the surrounding words, and â€œnext
sentencepredictionâ€,wherethemodelpredictsthenextsentence
giventhefirstsentenceastheinput.Thelargepre-trainedBERT
neural network model has had great success in NLU tasks, such as
text summarization [ 41], question-answering [ 42], and has been
shown to deliver impressive performance on downstream tasksevenwhenworkingwithsmalltrainingdatasets[
69].Hence,we
fine-tune the pre-trained BERT model on our training set to create
a binary privacy classifier.
USE: Universal Sentence Encoder is another deep neural net-
workbasedmodel,thatusesencoders(Transformer-based[ 74]or
Deep-Averaging-Networkbased[ 34])tolearnmeaningfulsentence
representations [ 14]. The model is trained on data from various
sources, such as Wikipedia, discussion forums, web questions and
answers,etc.;andhasshowngreatperformanceindetectingfake
newsspreadersonTwitter[ 46]andinlearningcross-lingualtext
representations [ 16]. Unlike BERT, we do not fine-tune the USE
model, instead use the readily available pre-trained USE TF-Hub
module2(which provides text embedding representations directly)
and build a two-layer feed-forward neural network on top for cre-
ating our privacy classifier.
3.2.1 Models. We propose the following four model variants as
candidates for our privacy classifier.
(Vanilla) BERT: We take the pre-trained BERT model, and add
one additional network layer after the last layer for binary classifi-
cation. We usea [CLS] token (start-of-sentence)to represent each
review in its entirety. Thus our additional layer simply transforms
theembeddingslearntforthe[CLS]tokentothetwoclasses,i.e.,
privacyandnotprivacy.Wefine-tunetheBERTmodelonourtrain-
ing data for three epochs, and choose the best epoch model based
on the performance on the validation dataset.
Sentiment-awareBERT(BERT-SST):Fromapreliminaryanal-
ysis,we foundthatthe privacyreview textsgenerallyhave aneg-
ative sentiment. We use this information to further strengthenour BERT-based privacy classifier, by first fine-tuning BERT for
sentimentclassificationtask.Usingsimilarmodelarchitecturemen-
tioned above for (Vanilla) BERT, we first train the model on a text-
sentiment dataset: Stanford Sentiment Treebank3, that contains
2https://tfhub.dev/google/universal-sentence-encoder/1
3https://nlp.stanford.edu/sentiment/text and its binary (positive or negative) sentiment label. We then
fine-tune this model on our training data to create the privacyclassifier. We simply map the privacy class to the negative senti-
mentclass,andnot-privacytothepositiveone.Wefine-tunethe
sentiment-awareBERTmodelforthreeepochsandchoosethebest
epoch model based on the performance on the validation set.
USE: We extract a new 512-dimensional embedding representa-
tionforeachreviewbypassingthereviewsthroughthepre-trained
USE model that is based on Deep Averaging Network encoder. We
thenpasstheembeddingthroughafeed-forwardneuralnetwork
with2layersand512hiddenunitseach.Theoutputofthe2ğ‘›ğ‘‘layer
isthenmappedtothetwoclasses,i.e.,privacyandnot-privacy.The
model is trained with the objective to maximize the probability of
the correct class, and thus we use cross-entropy loss to optimize
the network.We trainthe modelfor 20epochs andchose thebest
model based on performance on the validation set.
Ensemble Model: In our experimentation, we noticed inconsis-
tentlabelassignmentsbyeachofthethreeprivacyclassifiersabove.
(ThisisunderstandableastheunderlyingBERTandUSEmodelsare
pre-trainedondifferentdatasetswithdistinctcharacteristics.)To
better understandthescenarios where USEandBERT modelswere
makingdifferentdecisions(privacyornot-privacy),wemanually
examined about 1000+ reviews that had different labels from the
twomodels.BelowisanexampleofastatementthatUSEclassified
asprivacywhereas BERT labled it not-privacy.
â€œyou can record call automatically, record anonymous calls, recordimportant calls... youcan choose thephone numbers in thephone-
bookorrecordingcallautomatic.thelistofrecordedfileswillbe
stored and streamlined for you in the phone call recorder.â€
The following is an example of a review that BERT predicted as
privacy whereas USE did not.
â€œnothavingtamilchannelsandsportschannelswhichistheway
of looting the trust from the customer serviceâ€
The first example is ambiguous as making anonymous phone
calls could be perceived as being related to privacy. However, this
review mainly lists app features. The second example mentions
trust however this isnâ€™t a privacy issue but instead perhaps one of
feeling excluded due to a language not supported in the app. We
wouldnâ€™t consider either of these to be about privacy.
Toreducesuchambiguitiesandimproveourconfidenceinthe
privacyreviewidentification,our Ensemblemodel considersa re-
view to be about privacy, if and only if, all three classifiers (USE,
BERT and BERT-SST) labeled it as privacy. Note that this makesour model conservative (i.e., we will underestimate the numberof privacy reviews) since we are choosing to focus on precision
ratherthanrecall.Forourpurposesofbroadlyunderstandingusersâ€™
privacy concerns with mobile apps, we prefer to have less noise in
ourclusters.Weacknowledgethatadeveloperusingsuchamethod
may opt for high recall to be sure not to miss any particular issue.
3.2.2 Performance of Models. We evaluate our four privacy classi-
fiermodels(seeTable2)onthetestdataset.Highrecallnumbers
indicate that the model is able to correctly identify most of theprivacy-related reviews, and a high precision indicates that the
modelrarelylabelsanot-privacyreviewasbeingrelatedtoprivacy.
Fromthetable,weseethattheUSEmodelhasahighrecallanda
116ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Preksha Nema, Pauline Anthonysamy, Nina Taft, and Sai Teja Peddinti
Table 2: Performance of Models tested
ModelAccuracy Precision RecallF1-scoreAUC
USE 89.71 0.88 0.95 91.40 97.19
BERT 91.75 0.96 0.89 92.56 94.61
BERT-SST 93 0.93 0.90 91.70 90.6
Ensemble 91.85 0.98 0.87 92.49 98.18
relativelylowprecision,meaningthatithasmorefalsepositives
(not-privacyreviewslabeledasprivacy).Ontheotherhand,both
theBERTbasedmodelshaveahigherprecisionbut lowrecallcom-
paredtoUSE.TheBERT-SSTmodelhashigheraccuracythanBERT,
but looking at the F1 scores, vanilla BERT model performed better
thanBERT-SST.AsexpectedtheEnsemblemodelhasthehighest
precision; it also obtains the highest AUC value, and a good F1score. We use thus the Ensemble model in the remainder of this
work for our classification task.
Wedidaqualitativeanalysistoseeifourensembleclassifierwas
able to generalize its learning beyond the terms and expressions in
our regex patterns. First we checked to see if our classifier learned
anyconceptsnotincludedinourregexpatterns.Forexample,we
didnotincludeanytermsrelatedtoâ€œanonymityâ€orâ€œanonymousâ€
in our regexes, however we did find a number of reviews that
mentionâ€œIliketheanonymity...â€.Ourmodellikelylearnedthatthe
words related to â€œanonymousâ€ are often associated with privacy
because of the following. The following real review - â€œi donâ€™t want
a personalized profile full of surveillance. anonymous access is a
preferredâ€ -couldhavebeenflaggedasprivacybecauseoftheword
"surveillance" (that was in our regexes). Since this review also
containstheword"anonymous",theclassifierlearnstoassociate
thiswiththeprivacylabel(givenenoughsimilarexamples).Second,
wecomparedthefractionofprivacyreviewsthatourregexesalone
match(0.08%inthe290Mreviewsusedtogenerateourtrainingdata,
Section3.1),withthoseextractedbyourclassifier,namely(0.15%
from our 287M reviews test data). This shows that our classifier
doesgeneralizebeyondthetermsandexpressionsintheregexesas
it identifies roughly twice the amount of content as our regexes.
3.3 Clustering and Summarization
ThenextstepinourpipelineisClusteringandSummarizationofthe
privacy related reviews to tease out the different privacy concerns
users describe. We know from prior work as well as our curatedset of n-grams, there are a multitude of things users might write
about,suchaspersonaldatacollection,privacycontrols,location
tracking, a feeling of being spied on, third party data sharing, new
privacy features, consents, etc. We refer to these as privacy themes.
Since app reviews do not have fine-grained labels for such privacy
themes,weuseunsupervisedlearning(specificallyclustering)to
identify the common privacy issues. We use K-means clustering as
ourapproachtoclusteringbecauseitissimpleandbroadlyused,
and leave exploration of other clustering solutions as future work.
WeapplyK-meanstothesetofprivacyreviewsperappcategory
(Games, Parenting, Tools, etc). The motivation for studying cat-
egories independently is that the number of reviews across appcategories was highly variable (ref Table 3). Analyzing all the re-
views together would have not highlighted usersâ€™ concerns in appTable3:Number/proportionofprivacyreviewspercategory
App Category Total # of Proportion of
Reviews Privacy Reviews
Dating 503656 0.81%
Parenting 133408 0.68%
House & Home 291982 0.59%
Communication 17742507 0.59%
Maps & Navigation 1737291 0.52%
Tools 25038585 0.45%
Health & Fitness 3569543 0.44%
Medical 881141 0.34%
Weather 1491430 0.31%
Auto & Vehicles 547314 0.30%
Social 16719868 0.27%
Events 102623 0.23%
Photography 9364745 0.22%
Libraries & Demo 226555 0.17%
Entertainment 17547266 0.13%
Beauty 199974 0.11%
Art & Design 598982 0.09%
Finance 10604716 0.08%
Personalization 7565285 0.06%
Music & Audio 10870967 0.06%
Shopping 10698465 0.05%
Games 112635058 0.05%
Sports 11292326 0.05%
Comics 553063 0.05%
Lifestyle 7150696 0.04%
Travel & Local 4595332 0.03%
Productivity 9037059 0.03%
Food & Drink 2322001 0.01%
News & Magazines 3281372 0.01%
categorieswithlowernumbersofreviews.Analyzingthecategories
independentlyhelpedusidentifyissueswhichmaybeprominent
in one category but not in others (e.g., tracking and selling data
was not a key concern in the Games category).
Once these clusters are determined, we summarize the topic
discussedinaclusterbyselectingsomehighlyrepresentativere-
viewsforeachcluster.Afterindependentlyreviewingthetoprep-
resentative reviews and labelling the clusters in each category, we
performed a second round of annotation where we cross-checked
the cluster labels across categories and mapped clusters discussing
the same concerns to the broader topic.
K-Means clustering: We use the 512-dimensional USE embed-
ding generatedfor each review toperform clustering. We use em-
beddingsderivedfromourUSE-basedmodelinsteadofBERT-based
models as it lead to a higher AUC score (refer Table 2). The clus-tering is performed within an app category, and Cosine Distance
isusedasthedistancemetric.Likeanyotherclusteringtask,the
challengehereis: howtodetermineagood ğ‘˜valueforthenumberof
target clusters, without knowing ahead of time how many distinct
themes users may be writing about. There exist various metrics in
theliteraturetochoose ğ‘˜,suchastheSilhouetteScore[ 62],Dunn
Index[21], CH-Score[ 12], etc. These metrics primarily reward well
separatedandcompactclusters,whichisalsoourgoal.However,
these metrics implicitly assume the following: 1) a sample belongs
toonlyone cluster(oronlybelongs tooneprivacytheme);and 2)
all samples belong to some cluster, i.e., no sample is considered to
beanexceptionoroutlier.ForprivacyrelatedPlayreviews,these
assumptions do not always hold. Consider this example:
117Analyzing User Perspectives on Mobile App Privacy at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
â€œ1starforforcingpeopletocreateanaccount.noitâ€™snotnecessary
fortheuser.itâ€™sapparentlynecessaryfor[APP_NAME_REDACTED].
permissionstheydemandarenâ€™tnecessaryandinvasive.thisapp
ismorelikespyware.clearly[APP_NAME_REDACTED]ismaking
money off of peopleâ€™s personal and private information. i donâ€™t
recommendthisproduct.atminimum,ifyouâ€™regoingtousethis
app, give them fake information. however they wonâ€™t even let you
usetheappifyoudonâ€™tgivethemlocationtrackinginformation.
undoubtedly, theyâ€™ll be another company in the news soon for
exploiting customer privacy.â€
Thisexamplereviewtouchesonmultipleprivacythemes,including
unnecessarypermissions, spyware,locationtracking, andgeneral
privacy exploitation. There is potential that each of these fine-
grained topics produce its own cluster when running K-Means; so
this example review would be hard to place within one cluster as itmightnaturallybeontheborderofmultipleclusters.Therefore,we
aim to limit the influence of such reviews on the cluster formation
by optimizing for the creation of well-formed clusters â€“ clusters
thatpredominantlydiscussasingleprivacyissue.Thenextexample
illustrates the second assumption:
â€œiwishitworkedbetterforpregnancymilestones,bumppics,etc.
alltheremindersassumeyourkidisbornregardlessofenteringtheduedate.also,thepicturestakeforevertoload.iuploadedmultiple
pics for one day and my sister thought it was just 1 pic because of
the slow load time. COMPANY_NAME_REDACTED is faster and i
can make a private group so my pics arenâ€™t super public.â€
In this example, the user seems to be primarily expressing dissatis-
factionabouttheremindermechanismsanduploadspeeds.They
alsomentionthattheywouldlikeanewprivacyfeature,namely
theabilitytocreateprivate groups.The requestforaprivategroup
option does make this a legitimate review about privacy. However,
we did not find similar requests in other reviews in parenting apps,
and thus this review is an outlier. We aim to limit the influence of
such reviews in the clusters produced.
Given this, we have the following goals. Firstly, we aim for well
separated clusters. Secondly, we aim to have a high number of
clusters that have limited mixed-concern reviews and to minimize
thenumberofoutliers.Toachievethis,weproposea summarization
metricthat will reward a value of ğ‘˜based on these criteria.
To address thisfirst goal we usethe following construct. Let ğ‘†ğ‘–
denote the center of cluster ğ‘–. We define ğ‘‘ğ‘–ğ‘ ğ‘¡ ğ‘˜as:
ğ‘‘ğ‘–ğ‘ ğ‘¡ ğ‘˜=min{ğ›¿(ğ‘†ğ‘–,ğ‘†ğ‘—)âˆ€{ğ‘–,ğ‘—}} (1)
whereğ‘–â‰ ğ‘—andğ‘–,ğ‘—âˆˆ[0,ğ‘˜âˆ’1].ğ›¿(ğ‘†ğ‘–,ğ‘†ğ‘—)is the cosine distance
betweentwoclustercenters. ğ‘‘ğ‘–ğ‘ ğ‘¡ ğ‘˜representstheminimumpairwise
distance among all pairs of ğ‘˜cluster centers. Maximizing ğ‘‘ğ‘–ğ‘ ğ‘¡ ğ‘˜
ensures that the cluster centers be far apart in the vector space.
We iterate through multiple values of ğ‘˜and select the one that
maximizes this metric. This formula varies compared to existingmetrics, where an average of inter-cluster distance is generally
takenintoaccount.Hereweensurethattheminimuminter-cluster
distance is the highest for the chosen ğ‘˜value.
To address our goals of limiting the influence of mixed-concern
reviewsandoutliers,wewantintuitivelytoâ€œignoreâ€reviewsthat
arelooselyassociated withacluster,aswellasthemixed-concern
reviews as these are likely to be â€œborderlineâ€ between multiple
Figure 2: Silhouette Scores using K-Means for k=5
clusters. We aim to count the reviews within a cluster that areclosely related, and refer to them as upvotes(defined below). We
use thesilhouette score to do this. Recall that the silhouette score
ğ‘ (ğ‘–)formulateshowcloseeachpointistoitsclustercenterandhow
far it is from the nearest neighboring cluster, namely
ğ‘ (ğ‘–)=ğ‘(ğ‘–)âˆ’ğ‘(ğ‘–)
max(ğ‘(ğ‘–),ğ‘(ğ‘–))
whereğ‘(ğ‘–)isthelowestaveragedistancebetween ğ‘–-thpointand
any cluster of which it is not a member, and ğ‘(ğ‘–)is the average
distance between ğ‘–and all the other points of the same cluster. As
anexample,werunK-Meanswith ğ‘˜=5onreviewsidentifiedas
privacyinthe Parenting categoryandcomputethesilhouettescores
foreachreview,asshowninFigure2.Anegativesilhouettescore
indicates that the review is assigned to a wrong cluster, as it iscloser to the neighboring cluster. The dotted red line in Figure 2
representstheaveragesilhouettescoreacrossallthereviewsinthe
category.Alowsilhouettescore(closetozero)indicatesthatthe
reviewisveryclosetotheclusterboundary(datapoints/reviews
which are on LHS of the red line, but still positive), and a high
silhouette score indicates the review is closer to its own cluster
center (data points/reviews on the RHS of the red line). We refer to
reviews with silhouette score higher than the average silhouettescore asupvotesfor a given theme in a cluster. From Figure 2 we
see that it could be useful to retain clusters 0, 1, and 4 that havea larger amount of upvotes and ignore clusters 2 and 3. Clusters2 and 3 are likely to be poor quality since most of the silhouettescoresarenegativeorbelowthe averagesilhouettescore.Hence
inthisillustrativeexample,wewouldaimtohave3finalclusters
and simply not capture the ignored clusters which are unlikely to
contribute to top issues.
Weconsiderclusterstobecompactwhentheyhaveahighnum-
berofupvotes,andalownumberofmixed-concernreviewsina
given cluster. Therefore, we can rephrase our goal as aiming for a
kthat results in high number of compactclusters where a compact
cluster is defined as one in which at least 30% of the samples are
118ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Preksha Nema, Pauline Anthonysamy, Nina Taft, and Sai Teja Peddinti
upvotes.Werefertothenumberofcompactclustersidentifiedas
ğ‘€ğ‘˜, for a given k.
We combine the above two principles, and define a new Sum-
marization Metric as follows:
Summarization Metric =(ğ‘‘ğ‘–ğ‘ ğ‘¡ ğ‘˜âˆ—ğ‘€ğ‘˜) (2)
Weiteratethrough ğ‘˜=2,...,10andchose ğ‘˜forwhichthesumma-
rizationscoreishighest,aswewanttoincreaseboth ğ‘‘ğ‘–ğ‘ ğ‘¡ ğ‘˜(distance
between cluster centers) and ğ‘€ğ‘˜(number of compact clusters). We
useğ‘€ğ‘todenotethefinalnumberofcompactclustersidentifiedfor
thechosen ğ‘˜.Weconsider ğ‘˜between2and10becauseinourinitial
exploration using our methodology, we focus on dominant privacy
concerns.Howeverusingalarger ğ‘˜wouldenableananalysttolook
through the long-tail of privacy concerns.
We may end up with tens of thousands of reviews in a single
cluster,thusitisimportanttosummarizetheminawaythatcap-
turestheprimaryconcern.Wedothisbyselectingafewspecific
reviewsthatcanbeconsideredasrepresentativeofthereviewsin
the entire cluster. By summarizing this way, we capture the cluster
topicin the usersâ€™ own words. We rank reviews within a cluster
according to their silhouette scores and use the top ten reviews
with the highest scores as the representative reviews. We carefully
analyzed these cluster representatives manually across all clusters
andverifiedthatthesereviewsindeedillustratethemaintopicin
each cluster. In the next sections, we select quotes/reviews that
came from different categories to show the breadth of the issues
across app categories.
3.4 Limitations
WeusedK-meansasourfirstapproachtoclusteringbecauseitis
simpleandbroadlyused.However,ourclustersarequiteuneven
insize,andthusmoresophisticatedapproaches(suchasAffinity
Clustering [7]) could yield improved performance.
This kind of work is inherently hard because the definition of
privacy is not exact. We relied on previously accepted privacy
taxonomies,threeprofessionallinguists,andourownexperience
reading huge numbers of privacy reviews. A clearer sense of the
distinction (or accepted overlaps) between security, censorship, ha-
rassmentandprivacycouldtaketheformofagreeduponguidelines
by a community of domain experts.
Although user perspectives within a cluster are automatically
summarized by the representative sentences (ranked by silhouette
scores),thereisstillamanualstepinassigningthematiclabelsto
each cluster (i.e privacy controls, selling data, etc.) - that we did
by reading the top 20 reviews per cluster and finding a label based
uponourinterpretationofthosereviews.NLPmethodsfortopic
labeling [48, 78] could automate this step - although their efficacyin the privacy domain needs to be evaluated.
4 PRIVACY THEMES
Inthissection,wepresentthetopprivacythemesthatareassociated
with different app categories. To do this, we run our clustering
analysis on the previously extracted privacy reviews. Due to space
limitations, we present findings from 10 Play Store app categories
instead of all 29 categories. We selected categories that were either
large or ones where we expected privacy concerns might arise.Recall that our clustering iterates through ğ‘˜=2...10 and picks the
bestğ‘˜(number of clusters) according to our summarization metric.
For each of our 10 app categories, we found that ğ‘˜varied from 6 to
9.Welookedatthecompactclustersacrossthese10categories,and
identified 5 themes that were dominant across multiple categories.
Within each cluster considered, we ranked the reviews in those
clusters by silhouette score. Recall that the top ranked reviews
essentiallyrepresentthetopicoftheclusterastheyarecentralto
the cluster. For each of our selected clusters, we manually read the
top 20 most representative reviews, and assigned a short thematic
label to the cluster for ease of presentation and for summarization.
For example, we assigned the thematic label too many permis-
sionsto clusters whose representative reviews frequently mention
that an app requests more permissions than what seems needed.
These reviews are referring to the Android permissions such as
location,contacts,microphone,camera,etc.Thisthemewaspresentacrossallappcategories,withlocationpermissionbeingthehighest
occurring sub-theme. In other large clusters, many reviews com-ment on the collection of personal information. Such reviews
typicallyrefertoinformationsuchasaddress,email,profileinfo,etc.
Other themes we identified include privacy controls, tracking
andselling data. The cluster of reviews assigned the privacy-
controls themecapturesreviewsthateitherdiscusstheexisting
privacycontrolsofanapp,oraskforanewprivacyfeaturetobe
added to the app. Table 4 shows our themes and app categories;
there is an asterisk in each table entry if that theme appears as the
top-5issuefortherespectiveappcategory.Ablankcellmeansthat
thistopicdidnotsurfaceasoneofour ğ‘€ğ‘compactclustersfora
givenappcategory(theremightstillbereviewsonthistopic,but
they are not large enough to generate a compact cluster).
Whiletheseprivacythemeshavebeenidentifiedinqualitative
studies before [ 3,25,36,47,79],our analysis is the first large
scaleworktoconfirmthesefindingsempirically.Moreover,
we are able to quantify the volume per theme thereby enabling us
toranktheseissues,andweareabletoshowwhichissuesoccur
across multiple appcategories (e.g. permissions) and whichoccur
in only a few categories (e.g. selling data).
Giventhescopeofeachofthethemes,ourpurposehereisnotto
diveintodetailsindividually,butinsteadtosummarizesuccinctly
how users express these pain points. The included examples below
comefromourtoptenrepresentativereviewspercluster(topic),perappcategory.Becausetheseexamplesarecentraltoclustersofmany
thousands of similar reviews, they summarize the views of large
groupsofusers.Ourclustersrangedfromafewthousandupto20K
in size. Among these representative reviews, we selected examples
from different categories to illustrate that privacy concerns arerarely category specific. A more detailed look into each specific
privacy theme is left as future work.
4.1 Concern 1: Too Many Permissions
Thelargestcluster,ineachofour10categories,containsreviews
that make comments about the app asking for too many permis-
sions. This is expected as permissions are the gateway to accessing
personal information, and prior work has pointed to excessive per-
missions being a major concern [ 23,38,39,64,73,75]. Examples
include:
119Analyzing User Perspectives on Mobile App Privacy at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 4: Privacy Topic themes occurring in App Categories
ToolsGames Communi- Maps Enter- Parenting Health Photo-MedicalAuto
cations &tainment &graphy
Navigation Fitness
Permissions âˆ—âˆ— âˆ— âˆ— âˆ— âˆ— âˆ— âˆ— âˆ—âˆ—
Personal Information âˆ— âˆ— âˆ— âˆ— âˆ— âˆ— âˆ—âˆ—
PrivacyControls âˆ—âˆ— âˆ— âˆ— âˆ—
Tracking âˆ— âˆ— âˆ— âˆ— âˆ—
SellingData âˆ— âˆ— âˆ—
(1)â€œi really enjoyed this app until i realized it had access to all of
my photos , media and storage ! why the heck would a simple
sudoku app need that ! ? iâ€™m now more careful at checking the
permissionsbeforei installanything.i promptlydeletedthis
app and installed a similar sudoku app that doesnâ€™t require
such ridiculous permissions and itâ€™s just as goodâ€ (Games)
(2)â€œwhydoesthisapprequireaccesstomycontacts?purpose?i
take my privacy very seriously. no one should install this app
if you value your privacy.â€ (Maps & Navigation)
(3)â€œgoodapp,butihateitwhenappsrequestpermissionsithas
no business for (in this case, access to my contacts), no thanksâ€
(Auto & Vehicles)
Thefirsttworeviewsfocusonwhetherthedatacollectedisreally
neededforthefunctionalityoftheapp.Inexample1,thedisconnect
between the permissions asked for and the userâ€™s perception of the
app functionality caused this user to uninstall the app, and switch
to a more privacy-friendly app. In example 2, the user is asking for
the purpose of collecting contacts (presumably because it is notclearfromthecontext).Theimportanceofsharingpurposewith
usershasbeenestablishedintheacademicliterature[ 6,36,73],and
even in Androidâ€™s best practice guidelines4; it is interesting to now
see users effectively demanding that. It is important for developers
tolearnwhenusershavesuchconcerns,astheycanbemitigated
by providing explanations [ 40,70] to address the â€œpurposeâ€ type
questions. In example 3, users state they feel that data collection
from some permission requests is â€œunacceptableâ€ or a â€œriskâ€.
Figure 3: Privacy reviews that discuss permissions
We also examined which reviews mention a specific permission,
suchasmicrophone,location,etc.Todothisweusedsimplekey-
wordmatchingsuchas phone,calllog,contact,microphone,location,
4https://developer.android.com/training/permissions/usage-notessms,andcheckediftheword permission appearedsomewhereinthe
review.Figure3showsthenumberofprivacyreviewsthatmention
each permission group as well as the percentage of reviews they
represent.Weseethatthelocationpermissionisthemostdiscussed
permission,appearinginover40,000reviews(13%oftheprivacy
reviews). Contacts is the second most discussed permission.
4.2 Concern 2: Too Much Personal Information
Reviews in which users complain that too much personally identi-
fiableinformation(PII)isbeingcollectedistheseconddominant
privacy concern, and occurred in eight of our ten categories exam-
ined herein. While prior work has shown that users are concerned
about too muchpersonal information being collected, bothin the
context of mobile apps [ 36,77] and generally [ 2,11], unlike ours
theydonotrelyonexperiencesusershaveusingtheirowndevices
inthewild.Ouranalysisadditionallyshowsthatuserswarnoth-
ersnottodownloadanappexplicitlybecauseofPIIcollection,as
shown in the following two examples:
(1)â€œwhen it wonâ€™t let you play the game unless you agree to letituseyourinformation,itainâ€™tworthplaying.ifyouwant
privacy , donâ€™t download itâ€ (Games)
(2)â€œdontdothis!!!youreonlygivingtheappyourpersonalinfo!
whatyoulooklike,yourfingerprints,everything!idownloadedthisappjusttowarneveryonenottogivethisapppermissiontoanythingonyourdevice!...thisisdangerous!â€ (Entertainment)
Other users indicate their suspicion i.e., there is no good reason
for the data collection. These suspicions, which are in essence
requests for data collection justification, reflects the same issue we
saw in the reviews about too-many-permissions â€“ applied to
different data items. In the first two examples below, the users are
clearly quite annoyed. The user in the 3rd example implies that
they might have uninstalled the app because of this reason.
(1)â€œwhy the hell you need access to everything, you are service
provider or intruder in privacy.â€ (Auto & Vehicles)
(2)â€œhorrificregistrationprocess;requiringpersonalinformation
irrelevanttotheapplicationâ€™spurpose.â€ (MapsandNavigation)
(3)â€œwhydoesitneedmydeviceidsandthephonenumbersofmy
callers. who i communicate with is none of their business. this
app appears to be collecting more info than it requires to offer
itâ€™sservices...theyhavenorespectformyprivacy,theappwas
useful.â€(Health and Fitness)
Yetotherusersexpressthemselveswithtermsrelatingtotheft
orharassment,asthefollowingtwoexamplesconvey.Clearlytrust
is impacted if users interpret an appâ€™s behavior this way.
120ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Preksha Nema, Pauline Anthonysamy, Nina Taft, and Sai Teja Peddinti
(1)â€œstarted stealing personal information. phone numbers and
messages are being read by this application.â€ (Maps and Navi-
gation)
(2)â€œtoomuchpersonalinfo:whydoyouneedsomuchpersonal
infoyoucreeps?areyoutheoffenderslookingforprey?jeezâ€
(Parenting)
4.3 Other Dominant Privacy Concerns
Privacy Controls. Comments about privacy controls were a com-
mon issue across 5 app categories, namely in Communication, Par-
enting, Photography, Tools and Games. The fraction of reviews
discussingthisthemerangedfrom24%forCommunicationapps
to6%forGames.Thereviewsaboutprivacycontrolsshowanin-
teresting breadth, from explicitly requesting privacy controls to be
easier (example 1), to frustration with privacy controls (example2), to requesting new features (e.g. private chat in example 3). In
example2,theuseristryingtohidesomephotoswithinapp,yet
doesnotappeartobeabletodososuccessfully.Toaddresstheuser
frustration with using the offered privacy controls, personalized
privacy assistants have been proposed [39, 73].
(1)â€œdonâ€™tsharemypicsonpublicdomainwithoutmypermission,
when people search for specific location to visit pics appear, so
make privacy settings easy.â€ (Photography)
(2)â€œlock the pics you dont wanna see then they just get copied
right back to the gallery doesnt hide anything.â€ (Tools)
(3)â€œilovethisgame!itissoaddictiveandfun!...theonlythingi
would want to change add is private chat.â€ (Games)
Tracking. Wesawtrackingasadominantconcernin5appcate-
gories,namelyCommunications,Entertainment,Parenting,Pho-tography and Medical apps. The fraction of privacy reviews that
discuss tracking rangedfrom a minimum of10% in Entertainment
apps up to 38% in Parenting apps. Privacy concerns arising due
to usersâ€™ location being tracked have been well studied [ 3,17,22],
but our analysis shows that location isnâ€™t the only attribute people
are concerned about being tracked. Purchase history, contacts, and
other personal information are also important. As the examples
below show, users sentiment on this topic can range from annoyed
to angry. Since our methods can extract reviews on this issue, it
permitsfutureworkonsentimentanalysisandperhapsadeeper
exploration into which types of data are more sensitive. (Note, the
thirdexamplementions privateinformationaswellas spyingand
thusprovidesanexampleofreviewsthatfallontheboundaryof
two themes (one of the challenges in Section 3.3)).
(1)â€œwarning: this app is spyware and will track all your location
info and purchases.â€ (Entertainment)
(2)â€œspyware,dataminer.willnotconnectuntilyougrantaccess
to your phone location and data. contacts and location are
personal information. cameras donâ€™t need this to function. you
lie to public!â€ (Photography)
(3)â€œiagreewithprotectingyourchild.but whenyourateenlike
me you feel like you cant breath without constantly being
watched. itâ€™s like being stalked by your own family, and as if
you canâ€™t trust them. thereâ€™s a boundary between protection
and privacy. and this is stepping over the line.â€ (Parenting).
Selling Data. Usersâ€™ have previously expressed concerns with ser-
vice providers selling their data [ 18,76]. We show here that upsetdue to the perception of personal data being â€œsoldâ€ to third parties
alsoappearsinmobileapps.Unexpectedlythough,wefoundthis
to be dominant in only 3 app categories - that of Communications,
Medical and Entertainment apps. In the Communications apps, we
observed approximately 20% of the privacy reviews mentioning
sellinguserdata,makingthisasignificantprivacyissueforCom-
munication apps. Theexamples below hint thatthis issue appears
to make users feel undermined, as the comments are quite cynical.
We also see that users imagine their data being sold off to a variety
of recipients, including to companies, the NSA, and spammers.
(1)â€œi would highly recommend staying away from this cash grab
ofanappandmovetoanappthatactuallycaresaboutthedata
it collects about you. i feel like this company, and application
areonlyusedtotrackyourdataandinformationandselling
it off to the highest bidder, sad thing is, they make you pay for
it, so youâ€™re essentially paying to get your information stolen.â€
(Medical)
(2)â€œtheyaresellingpatientâ€™spersonaldatatocorporates.onceu
use[COMPANY-NAME-REDACTED],uwillstartgettingmails
and call from labs for medical tests. beware.â€ (Medical)
(3)â€œwhatidonotunderstandiswhy[COMPANY-NAME-REDACTED]
hadtomakeanotherwaythattheycouldsellourprivatein-
formation to third parties like the NSA.â€ (Communications)
Privacy Positive Reviews. During the above exercise processing
the top privacy pain points, we found - to our surprise - that while
most privacy reviews are negative, we do see some privacy pos-itive reviews. In these reviews, users mention that they like the
privacycontrols(examples1and2)orthattheyaregratefultheapp
is not collecting unnecessary information (example 3). The very
presenceofsuchreviewsindicatesthatdeveloperscanberewarded
by privacy-friendly design. Examples include:
(1)â€œthisisoneofthebestphotosharingappsoutthere.noneed
to share your childrenâ€™s whole lives on social media and mess
around with tons of privacy settings. you invite who you want
to your album and can share privately with your partner or
the whole family.â€ (Parenting)
(2)â€œgood way of keeping photos private.â€ (Photography)
(3)â€œitwasgreatfunplayingthis.ilikethattheydonâ€™twantaccess
to your private information unlike other apps.â€ (Games)
While these five themes were dominant concerns, there were
smaller review clusters that touched upon other topics, such as
â€œadsrelatedtopersonalinformationâ€andâ€œsafetyconcernsdueto
personal information leakageâ€. The diversity of privacy issues is
broad thus making it challenging to provide examples of all topics,
due to lack of space.
Overall we found many of these reviews to be fairly privacy
savvy - many questioned the purpose of data collected and de-
manded justification, while others suggested specific privacy con-
trols they would like to see added. Our quotes from representative
reviews show that it is not uncommon for users to warn other
otherstostayawayfromanappforprivacyrelatedreasons.The
dominantissueusersareconcernedaboutisthecollectionoftoo
muchpersonaldata,beitfromapppermissionsorPII.Wefound
thistobetrueacrossnearlyallappcategories.Wefoundreviews
of users who uninstall apps due to privacy related reasons; this
121Analyzing User Perspectives on Mobile App Privacy at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
is important to know as we suspect that developers are not com-
pletelyawarewhenthishappens.Wealsofoundprivacypositive
reviewsandthisindicatesthatdeveloperscanbepubliclyrewarded
for privacy friendly behavior.
5 IMPLICATIONS
Weillustratehowourmethodenablesdeveloperstoimprovethe
privacy of their products, and how app stores can leverage our
findings to design better privacy tools and best practices.
Organizingandunderstandinguserfeedbackforaparticular
appinamuchmoremeaningfulandactionableway. Today,
thePlayDeveloperConsole[ 27]surfacesallprivacyrelateduser
reviews under a theme called â€œPrivacyâ€. This makes it difficult
toeffectivelyunderstanduserfeedbackandidentifyspecificpain
points.Instead,embeddingourmethodologyintosuchdeveloper
feedback channels would allow app authors to address nuanced
privacy concerns directly. For instance, concerns on:
â€¢Toomanypermissions :ifadeveloperseesmanyuserscom-
plainingthattheydonotseethepurposeforapermission
request, thena guidelinewould suggestto provide amean-
ingful explanation or to remove the permission entirely.
â€¢SellingData :ifasetofreviewsshowsmuchconcernabout
selling personal data and the app does not engage in such
behavior,thenadeveloperwouldbeadvisedtoprovidean
educational intervention to clarify this misunderstanding.
â€¢Privacy controls : if reviews identify missing features or ca-
pabilities then these can be translated into product require-
ments or bug fixes [43, 44].
Guiding the design of new tools for developers to providetransparency on their data-collection practices, such as the
Apple Privacy Nutrition Labels [
5], and its upcoming equivalent
in the Play Store [ 59]. Understanding user concerns at scale and
in depth via our methodology could inform the design of such
transparency initiatives.
â€¢Analyzinguserconcernsabout tracking,sellingdata,andtoo
much personal information could shed light on what type
of labels are useful and how they should be designed. The
two label systems above are a good step forward as they en-
courage developers to be upfront about their collection and
sharing practices. Such labels could increase user trust and
helpthemdifferentiatebetweentheprivacystanceofcom-
petingapps.Althoughproperuseofsuchlabelsisturning
out to be challenging [37].
â€¢In the long term, our methodology will enable refining such
labels and tailor them to the specific concerns of users. It
will also allow monitoring of emerging privacy concerns.
Mechanismforprovidinginsightintousersperceptionsof
privacy. Beyond looking at top issues, one could evaluate how
privacyissuesvarybycountry,bylanguage,bytime,orcompare
privacyissuesbetweenchildrenâ€™sappsversusregularapps.Run-
ning sentiment analysis on such privacy text data sets, using tools
such as Stanfordâ€™s NLTK [ 9], would enable large-scale comparison
of sentiment across privacy issues and help developers and appstores prioritize what to fix first. These insights would be very
valuable, especially for small scale apps that do not have resourcesto analyse their reviews another way.
Nudgingdeveloperstowardsbetterprivacypractices.Forin-
stance, today the Play Developer Console nudges developers to re-
move permissions that are not used by apps in its peer groups [ 57].
By using our methodology, these nudges can be expanded to the
otherprivacyconcernsidentifiedinthispaper.Forexample,tomit-igate tracking concerns, developers could be informed of malicious
ad libraries as opposed to those that are much more privacy safe.
6 CONCLUSION
Understanding privacy trends is key to address systemic concerns
acrossecosystemsandpopulations.Todate,large-scaleevidence
ofwherethemainprivacyconcernslieforappusershasbeenlack-
ing.Thispaperisthefirsttoprovideamethodologythatenables
automated analysis and succinct summarization of privacy feed-
back,onalargescale.Ourmethodologycanactasamechanismfor
keyecosystemstakeholderstoberesponsivetoevolvingsocietal
concerns regarding privacy. As new technologies come to the fore
and as the risks of large-scale data harvesting become more appar-
ent,thisisasteppingstonetowardssystematicunderstandingof
privacy concerns at scale.
REFERENCES
[1]MartÃ­n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, San-jay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
YangqingJia,RafalJozefowicz,LukaszKaiser,ManjunathKudlur,JoshLevenberg,
DandelionManÃ©,RajatMonga,SherryMoore,DerekMurray,ChrisOlah,Mike
Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul
Tucker,VincentVanhoucke,VijayVasudevan,FernandaViÃ©gas,OriolVinyals,
Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng.
2015. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems.
https://www.tensorflow.org/ Software available from tensorflow.org.
[2]Mark S Ackerman, Lorrie Faith Cranor, and Joseph Reagle. 1999. Privacy in
e-commerce:examininguserscenariosandprivacypreferences.In Proceedings
ofthe1stACMConferenceonElectronicCommerce.AssociationforComputing
Machinery, New York, NY, USA, 1â€“8.
[3]HazimAlmuhimedi,FlorianSchaub,NormanSadeh,IdrisAdjerid,Alessandro
Acquisti, Joshua Gluck, Lorrie Faith Cranor, and Yuvraj Agarwal. 2015. Your
locationhasbeenshared5,398times!Afieldstudyonmobileappprivacynudging.
InProceedings of the 33rd annual ACM conference on human factors in computing
systems. Association for Computing Machinery, New York, NY, USA, 787â€“796.
[4]A. AntÃ³n and J. Earp. 2003. A requirements taxonomy for reducing Web site
privacy vulnerabilities. Requirements Engineering 9 (2003), 169â€“185.
[5]Appleâ€™s Privacy Nutrition Label 2022. App privacy details on the App Store.
https://developer.apple.com/app-store/app-privacy-details/. Accessed:2022-01-
31.
[6]A.Barth,A.Datta,J.C.Mitchell,andH.Nissenbaum.2006.Privacyandcontextual
integrity: frameworkand applications. In 2006 IEEESymposium on Security and
Privacy (S Pâ€™06). IEEE, Berkeley/Oakland, CA, USA, 15 pp.â€“198. https://doi.org/
10.1109/SP.2006.32
[7]MohammadHossein Bateni, Soheil Behnezhad, Mahsa Derakhshan, Mohammad-
Taghi Hajiaghayi, Raimondas Kiveris, Silvio Lattanzi, and Vahab Mirrokni. 2017.
Affinity clustering: Hierarchical clustering at scale. Advances in Neural Informa-
tion Processing Systems 30 (2017).
[8]AndrewRBesmer,JasonWatson,andMShaneBanks.2020. Investigatinguser
perceptionsofmobileappprivacy:Ananalysisofuser-submittedappreviews.
International Journal of Information Security and Privacy (IJISP) 14, 4 (2020),
74â€“91.
[9]StevenBird,EwanKlein,andEdwardLoper.2009. Naturallanguageprocessing
withPython:analyzingtextwiththenaturallanguagetoolkit. "Oâ€™ReillyMedia,
Inc.", US.
[10]BramBonnÃ©,SaiTejaPeddinti,IgorBilogrevic,andNinaTaft.2017. Exploring
decision making with Androidâ€™s runtime permission dialogs using in-context
surveys. In Symposium on Usable Privacy and Security ( {SOUPS}). USENIX Asso-
ciation, USA, 195â€“210.
122ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Preksha Nema, Pauline Anthonysamy, Nina Taft, and Sai Teja Peddinti
[11]Tom Buchanan, Carina Paine, Adam N Joinson, and Ulf-Dietrich Reips. 2007.
Developmentofmeasuresofonlineprivacyconcernandprotectionforuseonthe
Internet. JournaloftheAmericansocietyforinformationscienceandtechnology
58, 2 (2007), 157â€“165.
[12]TadeuszCaliÅ„skiandJerzyHarabasz.1974.Adendritemethodforclusteranalysis.
Communications in Statistics-theory and Methods 3, 1 (1974), 1â€“27.
[13]Ann Cavoukian. 2003. The Security-Privacy Paradox: Issues, misconceptions,
and Strategies. (2003).
[14]DanielCer,YinfeiYang,Sheng-yiKong,NanHua,NicoleLimtiaco,RhomniSt.
John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-
Hsuan Sung, Brian Strope, and Ray Kurzweil. 2018. Universal Sentence Encoder.
CoRRabs/1803.11175 (2018). arXiv:1803.11175 http://arxiv.org/abs/1803.11175
[15]Ning Chen, Jialiu Lin, Steven C. H. Hoi, Xiaokui Xiao, and Boshen Zhang. 2014.
AR-Miner:MiningInformativeReviewsforDevelopersfromMobileAppMarket-
place. InProceedings of the 36th International Conference on Software Engineering
(Hyderabad,India) (ICSE2014).AssociationforComputingMachinery,NewYork,
NY, USA, 767â€“778. https://doi.org/10.1145/2568225.2568263
[16]Muthuraman Chidambaram, Yinfei Yang, Daniel Cer, Steve Yuan, Yun-Hsuan
Sung,BrianStrope,andRayKurzweil.2018. LearningCross-LingualSentence
Representations via a Multi-task Dual-Encoder Model. CoRRabs/1810.12836
(2018). arXiv:1810.12836 http://arxiv.org/abs/1810.12836
[17]SakshamChitkara,NishadGothoskar,SuhasHarish,JasonIHong,andYuvraj
Agarwal.2017. Doesthisappreallyneedmylocation?Context-awareprivacy
management for smartphones. Proceedings of the ACM on Interactive, Mobile,
Wearable and Ubiquitous Technologies 1, 3, Article 42 (2017), 22 pages.
[18]Margaret S Crocco, Avner Segall, Anne-Lise Halvorsen, Alexandra Stamm, and
Rebecca Jacobsen. 2020. â€œItâ€™s not like theyâ€™re selling your data to dangerous
peopleâ€: Internet privacy, teens, and (non-) controversial public issues. The
Journal of Social Studies Research 44, 1 (2020), 21â€“33.
[19]Mina Deng, Kim Wuyts, Riccardo Scandariato, Bart Preneel, and Wouter Joosen.
2011. A privacy threat analysis framework: supporting the elicitation and fulfill-
ment of privacy requirements. Requir. Eng. 16, 1 (2011), 3â€“32.
[20]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2018. BERT:
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.
CoRRabs/1810.04805 (2018). arXiv:1810.04805 http://arxiv.org/abs/1810.04805
[21]J. C. Dunn. 1973. A Fuzzy Relative of the ISODATA Process and Its Use in
DetectingCompactWell-SeparatedClusters. JournalofCybernetics 3,3(1973),
32â€“57. https://doi.org/10.1080/01969727308546046
[22]Kassem Fawaz and Kang G Shin. 2014. Location privacy protection for smart-
phoneusers.In Proceedingsofthe2014ACMSIGSACConferenceonComputerand
Communications Security. Association for Computing Machinery, New York, NY,
USA, 239â€“250.
[23]Adrienne Porter Felt,Erika Chin, Steve Hanna, Dawn Song,and David Wagner.
2011. Androidpermissionsdemystified.In Proceedingsofthe18thACMconference
onComputerandcommunicationssecurity.AssociationforComputingMachinery,
New York, NY, USA, 627â€“638.
[24]Adrienne Porter Felt, Serge Egelman, and David Wagner. 2012. Iâ€™ve Got 99
Problems, but Vibration Ainâ€™t One: A Survey of Smartphone Usersâ€™ Concerns. In
Proceedings of the Second ACM Workshop on Security and Privacy in Smartphones
and Mobile Devices (SPSM â€™12). Association for Computing Machinery, New York,
NY, USA, 33â€“44.
[25]Casey FieslerandBlake Hallinan.2018. "WeAre theProduct" PublicReactions
toOnlineDataSharingandPrivacyControversiesintheMedia.In Proceedings
of the 2018 CHI Conference on Human Factors in Computing Systems. Association
for Computing Machinery, New York, NY, USA, 1â€“13.
[26]Bin Fu, Jialiu Lin, Lei Li, Christos Faloutsos, Jason Hong, and Norman Sadeh.
2013. WhyPeopleHateYourApp:MakingSenseofUserFeedbackinaMobile
App Store. In Proceedings of the 19th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining (Chicago, Illinois, USA) (KDD â€™13).
AssociationforComputingMachinery,NewYork,NY,USA,1276â€“1284. https:
//doi.org/10.1145/2487575.2488202
[27]Google 2022. Play Developer Console. https://developer.android.com/distribute/
console. Accessed: 2022-01-31.
[28]Alessandra Gorla, Ilaria Tavecchia, Florian Gross, and Andreas Zeller. 2014.
Checkingappbehavioragainstappdescriptions.In Proceedingsofthe36thInterna-
tionalConferenceonSoftwareEngineering.AssociationforComputingMachinery,
New York, NY, USA, 1025â€“1035.
[29]X.GuandS.Kim.2015. "WhatPartsofYourAppsareLovedbyUsers?"(T).In
2015 30th IEEE/ACM International Conference on Automated Software Engineering
(ASE). IEEE Press, USA, 760â€“770.
[30]Emitza Guzman and Walid Maalej. 2014. How Do Users Like This Feature? A
FineGrainedSentimentAnalysisofAppReviews.In 2014IEEE22ndInternational
Requirements Engineering Conference (RE). IEEE Press, 153â€“162. https://doi.org/
10.1109/RE.2014.6912257
[31]Hamza Harkous, Kassem Fawaz, RÃ©mi Lebret, Florian Schaub, Kang G Shin,
andKarlAberer.2018. Polisis:Automatedanalysisandpresentationofprivacy
policies using deep learning. In 27th{USENIX}Security Symposium ( {USENIX}
Security 18). USENIX Association, USA, 531â€“548.[32]Hamza Harkous, Kassem Fawaz, Kang G Shin, and Karl Aberer. 2016. Pribots:
Conversationalprivacywithchatbots.In TwelfthSymposiumonUsablePrivacy
and Security ( {SOUPS}). USENIX Association, Denver, CO.
[33]Zellig S. Harris. 1954. Distributional Structure. <i>WORD</i> 10, 2-3 (1954),
146â€“162. https://doi.org/10.1080/00437956.1954.11659520
[34]MohitIyyer,VarunManjunatha,JordanBoyd-Graber,andHalDaumÃ©III.2015.
DeepUnorderedCompositionRivalsSyntacticMethodsforTextClassification.
InProceedingsof the53rd AnnualMeeting ofthe Associationfor Computational
Linguisticsandthe7thInternationalJointConferenceonNaturalLanguageProcess-
ing(Volume1:LongPapers).AssociationforComputationalLinguistics,Beijing,China, 1681â€“1691. https://doi.org/10.3115/v1/P15-1162
[35]
Jaeyeon Jung, Seungyeop Han, and David Wetherall. 2012. Short Paper: Enhanc-
ing Mobile Application Permissions with Runtime Feedback and Constraints. In
Proceedings of the Second ACM Workshop on Security and Privacy in Smartphones
and Mobile Devices (SPSM â€™12). Association for Computing Machinery, USA.
[36]PatrickGageKelley,LorrieFaithCranor,andNormanSadeh.2013. Privacyas
PartoftheAppDecision-MakingProcess.In ProceedingsoftheSIGCHIConference
onHumanFactorsinComputingSystems (Paris,France) (CHIâ€™13).Associationfor
ComputingMachinery,NewYork,NY,USA,3393â€“3402. https://doi.org/10.1145/
2470654.2466466
[37]TianshiLi,KaylaReiman,YuvrajAgarwal,LorrieFaithCranor,andJasonI.Hong.
2022. Understanding Challenges for Developers to Create Accurate Privacy
NutritionLabels.In ProceedingsoftheSIGCHIConferenceonHumanFactorsin
Computing Systems (CHIâ€™22).
[38]Jialiu Lin, Shahriyar Amini, Jason I Hong, Norman Sadeh, Janne Lindqvist, and
Joy Zhang. 2012. Expectation and purpose: understanding usersâ€™ mental models
ofmobileappprivacythroughcrowdsourcing.In Proceedingsofthe2012ACM
conference on ubiquitous computing. Association for Computing Machinery, New
York, NY, USA.
[39]Bin Liu, Mads Schaarup Andersen, Florian Schaub, Hazim Almuhimedi,
Shikun Aerin Zhang, Norman Sadeh, Yuvraj Agarwal, and Alessandro Acquisti.
2016. Follow my recommendations: A personalized privacy assistant for mobile
apppermissions.In TwelfthSymposiumonUsablePrivacyandSecurity( {SOUPS}
2016). USENIX Association, Denver, CO, 27â€“41.
[40]Xueqing Liu, Yue Leng, Wei Yang, Wenyu Wang, Chengxiang Zhai, and Tao Xie.
2018. A large-scale empirical study on android runtime-permission rationalemessages. In 2018 IEEE Symposium on Visual Languages and Human-Centric
Computing (VL/HCC). IEEE Press, USA, 137â€“146.
[41]Yang Liu. 2019. Fine-tune BERT for Extractive Summarization. CoRR
abs/1903.10318 (2019). arXiv:1903.10318 http://arxiv.org/abs/1903.10318
[42]DenisLukovnikov,AsjaFischer,andJensLehmann.2019.Pretrainedtransformers
for simple question answering over knowledge graphs. In International Semantic
Web Conference. Springer, Springer, USA, 470â€“486.
[43]ChristophStanik;TimPietz;WalidMaalej.2021.UnsupervisedTopicDiscoveryin
User Comments. In 29th IEEE International Requirements Engineering Conference
(RE2021)(2021-09-20). https://arxiv.org/abs/2108.08543
[44]Marlo Haering; Christoph Stanik; Walid Maalej. 2021. AutomaticallyMatching Bug Reports With Related App Reviews. In 43rd International
Conference on Software Engineering (ICSE21) (2021-05-21). ACM, USA, 970â€“
981. https://mast.informatik.uni-hamburg.de/wp-content/uploads/2021/02/ICSE2021_Haering_et_al_Matching_Bug_Reports_App_Reviews.pdfhttp:
//arxiv.org/abs/2102.07134
[45]WalidMaalej,MaleknazNayebi,andGuentherRuhe.2019. Data-DrivenRequire-
ments Engineering - An Update. In 2019 IEEE/ACM 41st International Conference
on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE Press,
289â€“290. https://doi.org/10.1109/ICSE-SEIP.2019.00041
[46]Soumayan Bandhu Majumder and Dipankar Das. 2020. Detecting Fake NewsSpreaders on Twitter Using Universal Sentence Encoder. In CLEF. Semantic
Scholar, USA.
[47]Kirsten Martin and Katie Shilton. 2016. Putting mobile application privacy in
context: An empirical study of user privacy expectations for mobile devices. The
Information Society 32 (2016).
[48]Yashar Mehdad, Giuseppe Carenini, Raymond T. Ng, and Shafiq R. Joty. 2013.
Towards Topic Labeling with Phrase Entailment and Aggregation. In Human
Language Technologies: Conference of the North American Chapter of the Associa-
tionof ComputationalLinguistics, Proceedings,June 9-14,2013,WestinPeachtree
Plaza Hotel, Atlanta, Georgia, USA. ACL, USA.
[49]Nuhil Mehdy, Casey Kennington, and Hoda Mehrpouyan. 2019. Privacy Dis-
closuresDetectioninNatural-Language TextThroughLinguistically-Motivated
ArtificialNeuralNetworks.In InternationalConferenceonSecurityandPrivacy
in New Computing Environments. Springer, Springer International Publishing,
Cham, 152â€“177.
[50]Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
estimationofwordrepresentationsinvectorspace. arXivpreprintarXiv:1301.3781
1, 1 (2013).
[51]DebjyotiMukherjee,AlirezaAhmadi,MaryamVahdatPour,andJoelReardon.
2020. AnEmpiricalStudyonUserReviewsTargetingMobileAppsâ€™Security&
Privacy. arXiv:2010.06371 [cs.CR]
123Analyzing User Perspectives on Mobile App Privacy at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
[52]DucCuongNguyen,ErikDerr,MichaelBackes,andSvenBugiel.2019. ShortText,
Large Effect: Measuring the Impact of User Reviews on Android App Security &
Privacy. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE Press, USA.
[53]EhimareOkoyomon,NikitaSamarin,PrimalWijesekera,AmitElazariBarOn,
NarseoVallina-Rodriguez,IrwinReyes,ÃlvaroFeal,andSergeEgelman.2019. On
the ridiculousness of notice and consent: Contradictions in app privacy policies.
Proceedings of the Workshop on Technology and Consumer Protection (ConPro â€™19)
1, 1 (2019).
[54]D. Pagano and W. Maalej. 2013. User feedback in the appstore: An empirical
study.In 201321stIEEEInternationalRequirementsEngineeringConference(RE).
IEEE Press, USA, 125â€“134.
[55]F. Palomba, P. Salza, A. Ciurumelea, S. Panichella, H. Gall, F. Ferrucci, and A.De Lucia. 2017. Recommending and Localizing Change Requests for Mobile
Apps Based on User Reviews. In 2017 IEEE/ACM 39th International Conference on
Software Engineering (ICSE). IEEE Press, USA, 106â€“117.
[56]Rahul Pandita, Xusheng Xiao, Wei Yang, William Enck, and Tao Xie. 2013.
{WHYPER }: Towards Automating Risk Assessment ofMobile Applications. In
Presented as part of the 22nd {USENIX}Security Symposium ( {USENIX}Security
13). USENIX, USA, 527â€“542.
[57]Sai Teja Peddinti, Igor Bilogrevic, Nina Taft, Martin Pelikan, Ãšlfar Erlingsson,
PaulineAnthonysamy,andGilesHogben.2019. ReducingPermissionRequestsin
Mobile Apps. In Proceedings of the Internet Measurement Conference (Amsterdam,
Netherlands) (IMCâ€™19).AssociationforComputingMachinery,NewYork,NY,
USA, 259â€“266. https://doi.org/10.1145/3355369.3355584
[58]JeffreyPennington,RichardSocher,andChristopherD.Manning.2014. GloVe:
GlobalVectorsforWordRepresentation.In EmpiricalMethodsinNaturalLan-
guage Processing (EMNLP). ACM, USA, 1532â€“1543. http://www.aclweb.org/
anthology/D14-1162
[59]PlaySafetyLabel2021. NewsafetysectioninGooglePlaywillgivetransparencyintohowappsusedata.https://android-developers.googleblog.com/2021/05/new-
safety-section-in-google-play-will.html. Accessed: 2021-08-27.
[60]Zhengyang Qu, Vaibhav Rastogi, Xinyi Zhang, Yan Chen, Tiantian Zhu, and
Zhong Chen. 2014. AutoCog: Measuring the Description-to-Permission Fidelity
inAndroidApplications.In Proceedingsofthe2014ACMSIGSACConferenceon
Computer and Communications Security (Scottsdale, Arizona, USA) (CCS â€™14).
AssociationforComputingMachinery,NewYork,NY,USA,1354â€“1365. https:
//doi.org/10.1145/2660267.2660287
[61]Alexander Ratner. 2019. Accelerating Machine Learning with Training DataManagement. In Stanford University PhD Thesis. Stanford University, USA, 3.
https://ajratner.github.io/assets/papers/thesis.pdf
[62]Peter J. Rousseeuw. 1987. Silhouettes: A graphical aid to the interpretationand validation of cluster analysis. J. Comput. Appl. Math. 20 (1987), 53 â€“ 65.
https://doi.org/10.1016/0377-0427(87)90125-7
[63]Kanthashree Mysore Sathyendra, Shomir Wilson, Florian Schaub, Sebastian Zim-
meck, and Norman Sadeh. 2017. Identifying the provision ofchoices in privacy
policy text. In Proceedings of the 2017 Conference on Empirical Methods in Natural
LanguageProcessing.AssociationforComputationalLinguistics,Copenhagen,
Denmark, 2774â€“2779.
[64]FumingShih,IlariaLiccardi,andDanielWeitzner.2015. Privacytippingpoints
in smartphones privacy preferences. In Proceedings of the 33rd Annual ACM
Conference on Human Factors in Computing Systems. Association for Computing
Machinery, New York, NY, USA.
[65]RockySlavin,XiaoyinWang,MitraBokaeiHosseini,JamesHester,RamKrishnan,
Jaspreet Bhatia, Travis D Breaux, and Jianwei Niu. 2016. PVDetector: a detector
ofprivacy-policyviolationsforAndroidapps.In 2016IEEE/ACMInternational
ConferenceonMobileSoftwareEngineeringandSystems(MOBILESoft).IEEE,IEEE
Press, US, 299â€“300.
[66]RockySlavin,XiaoyinWang,MitraBokaeiHosseini,JamesHester,RamKrishnan,
JaspreetBhatia,TravisDBreaux,andJianweiNiu.2016. Towardaframeworkfor
detecting privacy policy violations in android application code. In Proceedings of
the 38th International Conference on Software Engineering. ACM, US, 25â€“36.
[67]DanielJ.Solove.2006. ATaxonomyofPrivacy. UniversityofPennsylvaniaLaw
Review154 (January 2006), 477â€“560.
[68]ChristophStanik, MarloHaering,ChakajklaJesdabodi, andWalidMaalej. 2020.
Which App Features Are Being Used? Learning App Feature Usages from Inter-
action Data. In 2020 IEEE 28th International Requirements Engineering Conference
(RE). IEEE Press, 66â€“77. https://doi.org/10.1109/RE48521.2020.00019
[69]ChiSun,XipengQiu,YigeXu,andXuanjingHuang.2019. Howtofine-tunebert
fortextclassification?.In ChinaNationalConferenceonChineseComputational
Linguistics. Springer, Springer, US, 194â€“206.
[70]JoshuaTan,KhanhNguyen,MichaelTheodorides,HeidiNegrÃ³n-Arroyo,Christo-
pher Thompson, Serge Egelman, and David Wagner. 2014. The Effect of
Developer-Specified Explanations for Permission Requests on Smartphone User
Behavior.In ProceedingsoftheSIGCHIConferenceonHumanFactorsinComputing
Systems. Association for Computing Machinery, New York, NY, USA.
[71]Christopher Thompson, Maritza Johnson, Serge Egelman, David Wagner, and
JenniferKing.2013. WhenItâ€™sBettertoAskForgivenessthanGetPermission:Attribution Mechanisms for Smartphone Resources. In Proceedings of the Ninth
Symposium on Usable Privacy and Security (SOUPS â€™13). Association for Comput-
ing Machinery, New York, NY, USA.
[72]YuanTian, BinLiu,WeisiDai, BlaseUr,PatrickTague,andLorrieFaithCranor.
2015. Supporting privacy-consciousappupdatedecisionswithuserreviews.In
Proceedings of the 5th Annual ACM CCS Workshop on Security and Privacy inSmartphones and Mobile Devices. Association for Computing Machinery, New
York, NY, USA, 51â€“61.
[73]LynnTsai,PrimalWijesekera,JoelReardon,IrwinReyes,Jung-WeiChen,Nathan
Good, Serge Egelman, and David Wagner. 2017. Turtleguard: helping android
usersapplycontextualprivacypreferences. ProceedingsoftheThirteenthUSENIX
Conference on Usable Privacy and Security 1, 1 (2017), 145â€“162.
[74]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All
YouNeed. CoRRabs/1706.03762(2017). arXiv:1706.03762 http://arxiv.org/abs/
1706.03762
[75]Timothy Vidas, Nicolas Christin, and Lorrie Cranor. 2011. Curbing android
permission creep. In Proceedings of the Web, Vol. 2. Springer, US, 91â€“96.
[76]AllisonWoodruff,VasylPihur,SunnyConsolvo,LauraBrandimarte,andAlessan-
dro Acquisti. 2014. Would a privacy fundamentalist sell their {DNA}for $1000...
ifnothingbadhappenedasaresult?thewestincategories,behavioralintentions,
and consequences. In 10th Symposium On Usable Privacy and Security ( {SOUPS}
2014). USENIX, US, 1â€“18.
[77]Heng Xu, Sumeet Gupta, Mary Beth Rosson, and John Carroll. 2012. Measuring
mobileusersâ€™concernsforinformationprivacy.In InternationalConferenceon
Information Systems, ICIS 2012 (International Conference on Information Systems,
ICIS 2012). Elsevier, US.
[78]Alex Yoo. 2018. Automatic Topic Labeling in 2018: History and
Trends. https://medium.datadriveninvestor.com/automatic-topic-labeling-in-
2018-history-and-trends-29c128cec17
[79]Serena Zheng, Noah Apthorpe, Marshini Chetty, and Nick Feamster. 2018. User
Perceptions of Smart Home IoT Privacy. Proc. ACM Hum.-Comput. Interact. 2,
CSCW (Nov 2018), 20 pages.
[80]SebastianZimmeck,PeterStory,DanielSmullen,AbhilashaRavichander,Ziqi
Wang, Joel Reidenberg, N Cameron Russell, and Norman Sadeh. 2019. MAPS:
Scaling privacy compliance analysis to a million apps. Proceedings on Privacy
Enhancing Technologies 2019, 3 (2019), 66â€“86.
124