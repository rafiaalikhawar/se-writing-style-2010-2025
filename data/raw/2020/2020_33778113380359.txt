Efficient Generation of Error-Inducing Floating-Point Inputs
via Symbolic Execution
Hui Guo
Department of Computer Science
University of California, Davis, USA
higuo@ucdavis.eduCindy Rubio-Gonz√°lez
Department of Computer Science
University of California, Davis, USA
crubio@ucdavis.edu
ABSTRACT
Floating point is widely used in software to emulate arithmetic
over reals. Unfortunately, floating point leads to rounding errors
thatpropagateandaccumulateduringexecution.Generatinginputs
tomaximize the numerical error is critical when evaluating the
accuracy of floating-point code. In this paper, we formulate theproblem of generating high error-inducing floating-point inputsasacodecoveragemaximizationproblemsolvedusingsymbolic
execution. Specifically, we define inaccuracy checks to detect large
precision loss and cancellation. We inject these checks at strategic
program locations to construct specialized branches that, whencovered by a given input, are likely to lead to large errors in the
result.Weapplysymbolicexecutiontogenerateinputsthatexercise
thesespecializedbranches,anddescribeoptimizationsthatmake
our approach practical. We implement a tool named FPGen and
presentanevaluationon21numericalprogramsincludingmatrix
computation andstatistics libraries.Weshow that FPGen exposes
errors for 20 of these programs and triggers errors that are, on
average, over 2 orders of magnitude larger than the state of the art.
CCS CONCEPTS
‚Ä¢Mathematics of computing ‚ÜíNumerical analysis ;‚Ä¢Soft-
wareanditsengineering ‚ÜíSoftwaretestinganddebugging ;
Software verification and validation.
KEYWORDS
floating-point,testing,catastrophiccancellation,roundofferrors,
symbolic execution
ACM Reference Format:
Hui Guo and Cindy Rubio-Gonz√°lez. 2020. Efficient Generation of Error-
InducingFloating-PointInputsviaSymbolicExecution.In 42ndInternational
ConferenceonSoftwareEngineering(ICSE‚Äô20),May23‚Äì29,2020,Seoul,Re-
publicofKorea. ACM,NewYork,NY,USA,12pages.https://doi.org/10.1145/
3377811.3380359
1 INTRODUCTION
Floating-point numbers are widely used as a standard to represent
reals in modern computers. The limited precision in floating-point
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
¬© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7121-6/20/05...$15.00
https://doi.org/10.1145/3377811.3380359representation and computation, however, remains a known threat
tothecorrectness,accuracyandstabilityoffloating-pointprograms.
Numerical bugs due to rounding errors, nonreproducibility and
floating-point exceptionsare common in floating-pointprograms
[18].Inparticular,thepropagationandaccumulationofrounding
errors have resulted in catastrophic failures [1, 6, 33].
Floating-point errors. The floating-point error of a computa-
tion refers to the sum of the rounding errors accumulated in the
result of the computation. This includes errors due to inaccurate
initial data as well as errors generated during the computation due
tofloating-pointfiniteprecision.Theamountoffloating-pointerror
includedinthefinalresultofaprogramspecifiestheaccuracyof
thecode.Whilethereareseveraltools(e.g.,[ 10,25,27])that,given
a set of inputs, help detect and identify accuracy and stability prob-
lems of floating-point code, few testing tools have been developed
to trigger and expose floating-point errors. Existing floating-point
testing tools [ 9,11,19] mainly focus on triggering floating-point
exceptions, or maximizing code coverage of floating-point pro-grams, while finding inputs to test accuracy is left to developers.
Generatinginputsto maximize thenumericalerroriscriticalwhen
evaluatingtheaccuracyoffloating-pointcode.Besidestesting,max-
imizing numerical error is significantly important in identifying
inaccurate code areas for automated floating-point program repair
or optimization [21, 24, 29, 31, 32, 38].
Error-inducing floating-point inputs. Finding inputs that
triggerlargenumericalerrorsisnon-trivial.Asobservedinapre-
vious study [ 10], only a very small portion of the input domain
can cause large errors. It is challenging to identify such inputs be-
cause rounding errors are unintuitive and difficult to reason about.
Floating-point optimization techniques [ 21,29,31] use random in-
puts that satisfy common distributions or code coverage criteria.
The state-of-the-art error-inducing input generators [ 16,37,39]
performlimitedanalysisoverthefloating-pointerrorsgenerated
during execution, and mainly rely on searching or sampling to
identifyerror-inducinginputs.Thisleadstoalackofsupportfor
numerical programs with multi-dimensional input data due to the
large input space. Both LSGA [ 39] and EAGT [ 37] are designed for
floating-point programs with a small number of scalar inputs.1
In reality, a large number of numerical programs, e.g., matrix
computation libraries that are widely used in scientific computing,
machine learning libraries, and software in computer graphics and
data analysis, take multi-dimensional input data such as arrays,
1LSGAdoesnotprovideanalgorithmtogeneratemultiplefloating-pointinputs,andis
evaluatedonprogramswithatmostfourscalarfloating-pointinputs(withthemajority
taking only one scalar floating-point input). EAGT relies on the approximation of
conditionnumbers,andonlyfocusesonprogramswithonescalarfloating-pointinput.
12612020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)
vectors or matrices. S3FP[16] is the state-of-the-art tool for gener-
ating error-inducing multi-dimensional floating-point inputs. S3FP
divides each input number interval and randomly permutes the
subintervals to zoom into tighter input ranges in exploring the in-
putspace.However,itsblack-boxnatureresultsinasmallerchance
to find inputs that trigger the highest errors.
Inthispaper,weproposeawhite-boxalgorithmtogeneratehigh
error-inducinginputsforfloating-pointprogramsespeciallywith
multi-dimensionalinputdata.Specifically,wecheckthefloating-
pointerrorsgeneratedduringexecutionandusesucherrorpatterns
to identify inputs that are likely to trigger high errors in the result.
Byaddingerrorchecks,wetransformtheproblemofgenerating
high error-inducing inputs into the code coverage maximization
problem that can be solved by performing symbolic execution.
Symbolic execution. Symbolic execution (e.g., [ 13,14,20,23])
enhances program testing by symbolizing inputs to achieve higher
codecoverage.Insymbolicexecution,insteadofconcretevalues,
the inputs are represented as symbols that indicate arbitrary num-
bers. Each program operation on concrete values is replaced by an
operation on symbolic values, and accordingly the value of each
variableisanexpressionintermsoftheinputsymbols.Whenen-
counteringaconditionalstatement,theexecutionisforkedintotwotoeachfollowthe trueandfalsebranch,andeachchildprocessadds
the corresponding constraints into its program state to identify the
executed path. Once the program terminates, or an error occurs,
e.g.,divisionbyzero,thepathconstraintsaresolvedbysatisfiability
modulo theory (SMT) constraint solvers to find concrete values for
the symbolic inputs.
Recent works [ 19,28] have incorporated floating-point arith-
metic insymbolic execution.Like integervariables, floating-point
variablesaresymbolizedtobeintegratedintodifferentpathcon-
straintsandfloating-pointinputsaregeneratedthroughSMTsolvers
with floating-point support (e.g., Z3 [ 7]). However , a floating-point
input that covers one path of the program does not necessarily
trigger large numerical errors on that path, which is shown in our
evaluation.Tofindinputsthattriggerhigherrors,amorespecific
algorithm is needed.
Key insight. Our key insight is that by injecting inaccuracy
checks after floating-point arithmetic operations, we force sym-
bolicexecutiontoexploretheprobabilityoftheoccurrenceofsevere
rounding errors or numerical cancellation at each injection site.
Severeroundingcancausesignificantprecisionloss,whichcould
affect the accuracy of the result, and a cancellation could be cat-astrophic due to loss of significance. In floating-point code, it is
hardtopredictwhichpartoftheprogramcouldpossiblyinvolve
severe rounding or cancellation, and what the impact in the result
isifeitherhappens.Ourtechniqueenablessymbolicexecutionto
explore rounding and cancellation possibilities in different code
areas.Foreachinputgenerated,wemeasuretheerroritexposed,
and select only those that trigger the largest error.
The main challenge stems from an inherent limitation of sym-
bolicexecution:pathexplosion[ 15].Duetotheexponentialgrowth
of the number of feasible paths, CPU and memory usage becomes
high. Moreimportantly, asmore constraintsare added intoa path
constraint, it takes longer for such constraints to be solved. The
necessityforinaccuracycheckinjectionaggravatestheproblembyintroducingadditionalpathstobeexplored.Toalleviatepathexplo-
sion, we carefully manage the number of symbolic input variables
by separating the input variables into two groups and concretizing
thegroupwithlargersize.Second,weonlyinstrumentthefloating-
pointoperationsofinterestinthecoreloopofthealgorithm,and
usetwosamplingstrategiestodynamicallyenableinjection.Lastly,
weformulatetheinaccuracychecksusingbitwiseoperations,which
significantlyreducethenumberofbranchesateachinjectionpoint.
WeimplementourapproachinatoolnamedFPGenanddemon-
stratethatFPGeniseffectiveatgeneratinginputsthatexposelarge
floating-pointerrors.Ourevaluationon3summationalgorithms
and 18 numerical programs from the Meschach library [ 5] and the
GNUScientificlibrary[ 2]showsthatFPGenisabletoexposeerrors
for nearly all programs, and the order of the magnitude of exposed
relative errors is‚àí6.35 on average, which indicates that the result
has only around 6 accurate digits.
We compare FPGen‚Äôs generated inputs against random input
generation,thestate-of-the-arterror-inducinginputgeneratorS3FP
[16],andKLEE-Float[ 28],asymbolicexecutionenginethatpro-
videsfloating-pointsupport.Theresultsshowthatrandominput
generation and S3FP trigger errors in 13 out of 21 programs while
FPGen triggers errors in all programs except for one. Furthermore,
FPGentriggerslargererrorsthanallotherapproachesfor15out
of 21 programs. The order of the magnitude of the exposed rela-
tiveerrorsis‚àí12.69onaverageforrandominputgenerationand
‚àí8.46 on average for S3FP. On the other hand, KLEE-Float fails
totriggererrorsforallprograms.Regardingtothemagnitudeoferrors the tools can trigger, FPGen improves the state-of-the-art
input generator S3FP by more than 2 orders of magnitude.
The contributions of this paper are as follows:
‚Ä¢Weenablesymbolicexecutiontofindhigherror-inducinginputs
by incorporating precision loss and cancellation checks under
floating-point computations, and describe various optimizations
toscalesymbolicexecution,includingmanagingthenumberof
symbolic variables and selecting injection sites (Section 3).
‚Ä¢We evaluate FPGen on a set of 21 numerical programs including
matrixcomputationandstatisticslibraries,andshowthatFPGen
outperforms the state of the art in the majority of the programs.
Moreover, FPGen advances the state of the art by triggering
errorsthataremorethan2ordersofmagnitudelarger(Section4).
Therestofthispaperisorganizedasfollows.Section2illustrates
testingoffloating-pointprogramsusing3summationalgorithms.
Section3describesourinaccuracychecks,andoptimizationsthat
make symbolic execution effective at generating error-inducinginputs. Section 4 describes our experimental evaluation. Finally,
Section 5 discusses related work and we conclude in Section 6.
2 FLOATING-POINT ACCURACY TESTING
In this section, we first illustrate the problem of exposing floating-
pointinaccuracyusingthreewell-knownfloating-pointsummation
algorithms:recursivesummation,pairwisesummation,andcom-
pensatedsummation.Second,weshowhowthestateoftheartin
error-inducinginputgeneration(alongwithothertwobaselines)
fails to find inputs that trigger errors in these algorithms while we
successfullycraftsuchaninputmanually.Finally,wediscussour
insight for generating inputs that maximize error.
12621double recursive_summation( double *A , int size){
2 for (int i=s i z e - 1;i>0;i - - )
3 A[i-1] += A[i];
4 return A[0];}
(a) Recursive Summation
1double pairwise_summation( double a1, double a2,
2 double a3, double a4){
3 a1 += a2; a3 += a4;
4 a1 += a3;
5 return a1;}
(b) Pairwise Summation
1double compensated_summation( double *A , int size){
2 double sum, a, e=0;
3 for (int i=s i z e - 1;i>0;i - - ) {
4 sum = A[i];
5 a=A [ i - 1 ]+e ;
6 A[i-1] = sum + a;
7 e = (sum - A[i-1]) + a;}
8 return A[0];}
(c) Compensated Summation
Figure 1: Floating-point summation algorithms.
2.1 Floating-Point Summations
To achieve better accuracy when adding floating-point numbers,
avarietyofsummationalgorithmshavebeenproposed.Figure1
shows 3 summation algorithms that compute the sum over the
elementsofadoublearray.2Therecursivesummationalgorithm
iteratively adds each element in the array in reverse order. It is
simpleandthemostfrequentlyused,butitsaccuracydependson
theorderinwhichnumbersaregiven.Pairwisesummationadds
arrayelements inpairs toavoid largeroundingerrorsintroduced
when adding each of the elements to the partial sum. Lastly, the
compensatedsummationalgorithmuses acorrectionterm,i.e., e
(line 2), to diminish the rounding error incurred in the addition
operation (line 6) of the last iteration. More details on the accuracy
of these (and other) summation algorithms can be found in [22].
2.2 Error-Inducing Inputs for Summations
First, we investigate the effectiveness of three existing approaches
for generating error-inducing inputs. Specifically, we use the C++
randfunction as random number generator, S3FP [ 16], the state-
of-the-art error-inducing input generator for programs with multi-
dimensionalinputdata,andKLEE-Float[ 28],asymbolicexecution
enginethatsupportsfloatingpoint.Weimplementanadditional128-
bit quadruple precision version of each summation. For each input
arraygenerated,werunbothoriginalandhigh-precisionprograms
to calculate the error in the result. As shown in Table 1a, for an
inputarrayofsize4inrange[ ‚àí100,100],therandomgeneratorand
S3FP searched 1000 input arrays but failed to find one that exposes
error in the summations. KLEE-Float generated an array of zeros
thatcoversthe onlypathintheprogramswhileexposingnoerrors.
Second, we manually crafted an array Athat triggers high nu-
mericalerroroneachsummationalgorithm.Thevaluesforeacharray element can be found in Table 1b. We refer to the manual
2For simplicity and readability, we omit the bulky code of pairwise summation for an
array of size N, and illustrate it using 4 double variables.$>@ 
$>@ H$>@ $>@ H√∑ H
√∑ H
H√∑ H
DEVROXWHHUURU H
UHODWLYHHUURU GRXEOHSUHFLVLRQ H
TXDGUXSOHSUHFLVLRQ H
 5HFXUVLYH6XPPDWLRQ
√∑ H
√∑ H√∑ H$>@ $>@ H$>@ $>@ H
DEVROXWHHUURU H
UHODWLYHHUURU GRXEOHSUHFLVLRQ 
TXDGUXSOHSUHFLVLRQ H
 3DLUZLVH6XPPDWLRQ
”Å H √∑ H
”Å √∑ H
H”Å  √∑ H$>@ $>@ H$>@ $>@ H
DEVROXWHHUURU H
UHODWLYHHUURU GRXEOHSUHFLVLRQ H
TXDGUXSOHSUHFLVLRQ H
 &RPSHQVDWHG6XPPDWLRQ
Figure 2: Summations on the manually crafted input array.
approachsimplyasManual.Table1ashowsthatManualexposes
arelativeerrorof12intherecursiveandcompensatedsummations,
and a relative error of 1 in the pairwise summation.
Figure 2 shows the computation process of each summation
algorithm over the manually crafted input to shed light on the gen-
erationoferror-inducinginputs.Programexecutionsofrecursive
summation in double and qadruple precision produce summa-
tionresults1 .1e‚àí15and‚àí1e‚àí16,respectively.Usingtheresultof
qadruple execution as the ground truth, the absoluteerror of
double execution is 1 .2e‚àí15, and the relativeerror is 12. We fur-
ther examine the result and the error incurred at each addition
operation in double precision. As shown in Figure 2, the first addi-tionadds
A[3]toA[2].Because A[2]islessthantheleastsignificant
digit (i.e., ULP) of A[3],‚àí1.4e‚àí14,A[2] is rounded off (shown as
the rounding error, e). The second addition adds the result so far to
A[1], unfortunately both values cancel out. The local error remains
‚àí1.2e‚àí15sinceno newroundingerrorsoccur. Lastly, A[1],which
containsthepartialsummationresult0,isaddedto A[0]=1.1e‚àí15.
Thefinalresult,1 .1e‚àí15,isstoredin A[0],andtheerroraccumu-
lated in the result is ‚àí1.2e‚àí15. Because the magnitude of the error
is close to the result of the summation, the relative error is high.
Similarly,thefirsttwoadditionsinpairwisesummationgenerate
twoerrorsbyroundingoffthesmalleroperand,andthelastaddi-
tion cancels the two partial summation results. The cancellationcauses themagnitude ofthe errorto be comparableto theresult,
leadingtoalargerelativeerror.Compensatedsummationmaintains
1263Table 1: Accuracy testing of summation algorithms. The input is an array of size 4in the range [‚àí100 ,100].
(a) Testing results.
Maximum Relative Error
Approach #Inputs Recursive Sum. Pairwise Sum. Compensated Sum.
Random 1000 0 0 0
S3FP 1000 0 0 0
KLEE-Float 1 0 0 0
Manual 1 12 1 12(b) Manual values for input array.
Array
Element FP Value
A[3] -98.0A[2] -1.2e-15A[1] 98.0A[0] 1.1e-15
acorrectionterm,i.e., ÀúeinthethirdsubgraphofFigure2.Itcaptures
theroundingerrorgeneratedbythecurrentadditionoperation,and
will be added when applying the next addition. For example, after
the first addition, Àúe holds the rounding error ‚àí1.2e‚àí15, introduced
byadding A[3]andA[2].However,becausethenexttermtoadd,
A[1]=98.0,hasanULPgreaterthan ‚àí1.2e‚àí15,thecorrectionterm
isdropped inthesecond addition. Also,cancellationoccurs inthe
seconditeration.Intheend,thecompensatedsummationperforms
the same as recursive summation, and its result over array Ais
1.1e‚àí15 with a relative error of 12.
Input generation insight. We observe two general patterns in
thesummationsoverthemanualinputarray A:(a)roundingthat
particularlyoccurswhenaddingtwofloating-pointnumberswhose
exponentsvarywidely,e.g., ‚àí98.0+(‚àí1.2e‚àí15 ),and(b)cancellation
thataffectslargeterms.Thefirstpatternintroducesroundingerrors
in intermediate results while the second pattern exposes the errors
bycancelingtheaccuratesignificantdigits.Weproposetoinject
inaccuracychecks atfloating-pointoperationstodetectrounding
andcancellations.Ourchecksdonotrequiremaintainingahigh-
precision shadow execution to calculate intermediate errors, but
checkinaccuraciessolelybasedontheoperandsandtheresultof
the computation.
In response to where to inject inaccuracy checks, we observe
in our example that the rounding pattern arises in the first addi-tion while the cancellation pattern occurs on different addition
operationsinthe3summationprograms(2ndadditioninrecursive
and compensated summation, and 3rd addition in pairwise sum-mation). In reality, it is unattainable to predict the floating-pointoperations at which rounding and cancellation need to happen.
Thisisthereasonwhywecreateasearchspaceontheinaccuracies
of computations and conduct the search using symbolic execution.
In summary, the goal of our inaccuracy checks is to create a searchspacetoallowsymbolicexecutiontoexploretheinaccuraciesofdif-
ferent code areas for high error-inducing inputs. This observation
on the inaccuracy patterns can be generalized to other floating-point code. It is highly likely that an input that conforms to our
inaccuracycheckswillproduceahighnumericalerrorintheresult.
3 TECHNICAL APPROACH
Ourapproachtogeneratefloating-pointinputsthatexposelarge
numerical errors consists of three main components, which are
illustratedinFigure3.Wefirstapplyaprogramtransformationthat
injects checks for precision loss and cancellation into the program
P.Second,weapplyvariousoptimizationstomitigatepathexplo-
sion during symbolic execution, including reducing the numberFigure 3: FPGen workflow.
ofsymbolicvariablesbyconcretizingsomeinputvariablesusing
random values. Input specifications are required for the identifi-cation of input variables. Symbolic execution is then performedin the transformed program
P/prime. Finally, we assess the quality of
the generated inputs I1,I2, ...,Inby measuring their errors with
respect to a higher-precision version of the program Ph. The input
that exposes the largest error, ImaxErr, is then selected. We also
diagnosethe rootcause ofthe numericalerror tofurtherhelp the
programmerinidentifyingtheprogramexpressionsthatcontribute
the most to the numerical inaccuracy.
3.1 Inaccuracy Check Injector
Thegoaloftheinaccuracycheckinjectoristotransformagiven
programsothattheresultofeachinjectedfloating-pointarithmeticoperationisexplicitlycheckedforprecisionlossandcancellationer-rors.Inthissection,weassumeathree-addresscoderepresentation
in which each arithmetic operation hasat most two operands. We
firstdefineeachofthetwochecksseparately,andthenwedescribe
how we combine the two when injecting them into the program.
3.1.1 Check for Precision Loss. Rounding errors are inherent to
floating point, and occur when an operation results in a value that
cannot be exactly represented in floating point. This leads to aloss of precision in the computed result. In this paper, we focuson precision loss that results in most bits of a data value being
discarded. For example, a number smaller than 1 .2e‚àí38is rounded
to 0 when represented in single precision3. The rounding error
incurred is equal to the data value itself, and all bits of precision
are effectively discarded.
3Assuming no subnormal numbers.
1264In most cases this type of precision loss4is unintentional and
can be the symptom of a numerical bug. For example, consider the
summation of 1, 1e ‚àí8, and‚àí1. If we apply the summation in the
orderof1 +1e‚àí8+(‚àí1)insingleprecision,thesumis0because
1+1e‚àí8equals to 1 due to precision loss that causes all bits of
precision of 1e‚àí8to be lost. However, if we change the order to
1+(‚àí1)+1e‚àí8,weareabletoattaintheexactresultofthesum-
mation, 1e‚àí8, without generating numerical errors. From the view
ofprogrammers,theintentionistoaddthethreegivennumbers.
However, the first order leads to a result that only adds two of the
numbersduetoprecisionloss.Thisviolatesprogrammers‚Äôinten-
tion and therefore is a hidden numerical bug. Precision loss checks
are designed to expose such errors.
Weinjectexplicitprecisionlosschecksafterfloating-pointad-
ditionandsubtractionoperations.5Foreachgivenfloating-point
operation, we compare the exponents of the two operands. The
intuition behind is that the addition of two floating-point values
of similar magnitude will result in a more accurate result than the
addition of two values whose magnitude differ significantly. We
define the precision loss check as follows:
|exp (op1)‚àíexp (op2)|‚â•œÉ (1)
whereexp (op1)andexp (op2)represent the exponents of the
twosourceoperands,respectively,and œÉisanintegerconstantthat
definesthelowerboundoftheexponentdifference.Inotherwords,
œÉrepresents the number of bits of precision that are discarded. For
example,if œÉisgreaterthanthenumberofsignificanddigits,i.e.,23
in single precision and 52 in double precision, all bits of precision
in the corresponding operand will be discarded.
res x[¬±1]
18o r1 1 23 or 52 bitsop2 x‚àíœÉ
œÉbitsdiscardedop1 x
The figure above visualizes the computation on op1andop2,
which leads to œÉbits ofop2being discarded. Each operand and the
resultofthecomputationaredescribedinthefloating-pointformat
that contains three components: sign (1 bit), exponent (8 bits in
float,11bitsin double)andfraction(23bitsinfloat,52bitsin
double). As shown, the exponent of op1isx,œÉgreater than the
exponentof op2.Whenperforminganadditionorsubtractionon
op1andop2,thefractionof op2isshiftedtotherightby œÉbits.The
first few bits (23‚àíœÉbits in float, 52‚àíœÉbits in double) of op2
areusedtocomputethefractionoftheresult reswhilethelast œÉ
bitsarediscarded.Finally, resisnormalizedanditsexponentcan
be adjusted by 1.
4Forsimplicity,therestofthispaperrefersto precisionloss whenmostbitsofprecision
are discarded.
5Among the floating-point arithmetic operations, +,‚àí,√ó,√∑,‚àö,%, addition and sub-
traction are the common operations that are likely to discard most bits of precision in
one of its operand data values.3.1.2 Check for Cancellation Errors. Acancellationoccurswhen
two floating-point numbers with opposite sign and nearly equal
magnitudeareadded.Themostsignificantbitsarecanceledwiththeleast(ofteninaccurate)significantbitstakingprecedence.Considerthe decimalnumbers 1
.9874 and‚àí1.9856. Roundingthese numbers
to three decimal digits results in 1 .987 and‚àí1.986, each with a
rounding error of 4e ‚àí4. If we add these numbers, the first three
digits cancel each other and the result of the addition is 0 .001,
which is comparable in magnitude to the rounding errors. The
relativeerroroftheresultis |0.001‚àí0.0018|/0.0018=4.4e‚àí1,which
can be unacceptable. Such a cancellation error can have serious
repercussions. The affected value could change the control flow of
the program if used in a conditional expression, or be amplified
through the rest of the computation, thus potentially introducing a
large numerical error in the final result.
Cancellation checks have been used in prior work [ 10,25]t o
detectprograminstabilityonthefly.Specifically,thecancellation
check is defined as follows:
max{exp (op1),exp (op2)}‚àíexp (res )‚â•Œ∏ (2)
whereexp (x)represents theexponent of floating-pointnumber x,
op1andop2arethetwooperands,and resisresultofanaddition
orsubtractionoperation.Thevalue Œ∏denotesthelowerboundof
thenumberofsignificantbitsthatarecanceled.Forexample,two
numbers are canceled out to 0 if Œ∏is 23 bits in single precision.
Asvisualizedbelow,operand op1andoperand op2havethesame
exponent x,andtheexponentofthecomputationresult resisre-
duced tox‚àíŒ∏. The first Œ∏bits ofop1andop2are discarded due to
cancellation.Thefewleastsignificantbitsof op1andop2(23‚àíœÉ
bitsinfloat,52‚àíœÉbitsindouble),whichareinaccuratedueto
rounding errors, are used to compute the most significant bit of res.
res x‚àíŒ∏
18o r1 1 23 or 52 bitsop2 x
Œ∏bitsop1 x
Œ∏bits
3.1.3 Check Injection. First,weconstructaninaccuracydetector
that checks for precision loss and cancellations in floating-point
computations. To facilitate symbolic execution, we divide the pro-
gram execution under the computation into three branches. Asshown in Figure 4, one branch is guarded by the precision loss
conditionformalizedinEquation(1)toexploreinputsthatlosepre-cisionintheexecution;onebranchissecuredwiththecancellation
condition described in Equation (2) to select inputs that can cause
catastrophic cancellation;and the third branchsatisfies neither of
the two conditions, and can be referred as the accurate branch.
Precision loss and cancellation conditions are contradictory as can-
cellationrequiresthe twosource operandstobe nearlyequal and
precisionlosshappensonlywhenthetwosourceoperandsarein
significant different order of magnitude. Therefore, no cancellation
occurs in the precision loss branch.
Inaccuracythresholds. Weselectthresholds œÉandŒ∏forprecision
lossandcancellation,respectively.Threshold œÉrepresentsthenum-
ber of bits of precision that are discarded in precision loss from
12653UHFLVLRQ/RVV%UDQFK
3UHFLVLRQ/RVV&RQGLWLRQ&DQFHOODWLRQ%UDQFK
$FFXUDWH%UDQFK&DQFHOODWLRQ&RQGLWLRQ&DQFHOODWLRQ&RQGLWLRQ3UHFLVLRQ/RVV&RQGLWLRQ
Figure 4: Inaccuracy check branches.
Figure 5: Average of maximum errors on 3 summation pro-
grams with different inaccuracy thresholds.
Equation (1), and Œ∏represents the number of bits in the significand
thatcancelfromEquation(2).Thelarger œÉis,themorebitsofpreci-
sionarediscardedintheoperandvaluewiththesmallermagnitudeofthetwo.Similarly,thelarger
Œ∏is,themorebitsofthesignificand
are canceled in the two operand values. Both will cause significant
inaccuracies.Indoubleprecision, œÉandŒ∏arepositiveintegersno
greater than 52 (the number of bits in the significand). We select
thevaluesof œÉandŒ∏basedonanempiricalevaluationonthethree
summation programs presented in Section 2.
We start the search with the parameter setting { œÉ=28,Œ∏=4}
and investigate all multiples of 4 for œÉandŒ∏.6For each parame-
ter setting, we compute the average of the top 3 errors triggeredin each program and combine the results of the three programsbycalculatingthemeanvalue.Figure5showsthemeanvalueofthe errors in the three summation programs while the threshold
parameters œÉandŒ∏vary.Thecoordinateofabarindicates (Œ∏,œÉ),
andtheheightdenotesthemeanvalueofthemaximumerrors.The
bars use distinct colors for different values of parameter œÉ. The
parametersettingthatranksfirstis {œÉ=32,Œ∏=40}.Weusethis
settinginourexperimentalevaluation,whichyieldsfruitfulresults.
Check conditionbinarization. The two checkconditions in Fig-
ure4involvecomputationssuchastheabsolutevalueofaninteger
inEquation(1)andthemaximumoftwointegersinEquation(2).
These operations generate additional branches in the binary code.
Thefollowing twostatements showthese branchesusing thecon-
ditional operator (?:)in C.
6Our initial value is œÉ=28because we consider that discarding at least 28 bits could
affect precision sufficiently.1#define exp_bt(pa) ( long )((*( unsigned long *)(pa)
2 >>52)&0x7ff)
(a) exp
1#define abs_mask(a) ((a)>>( sizeof (long )*8-1))
2#define abs_bt(a) (((a)+abs_mask (a))^ abs_mask (a))
(b) abs
1#define max_bt(a, b) ((a)^(((a)^(b))&-((a)< (b))))
(c) max
Figure 6: Bitwise utility functions.
abs(a) = (a > 0)?a:- a ;
max(a, b) = (a > b)?a:b ;
The expansion of branches increases the number of paths expo-
nentially and makes it more difficult for the symbolic execution
engine to find inaccuracy patterns. To alleviate this problem, wedesignedthreehighlyoptimizedbitwiseutilityfunctionsthatdo
notincludeanybranches.Theutilityfunctionsare exp_bttoobtain
theexponentofafloating-pointnumberwithspecifiedprecisionasa long integer, abs_btto obtain the absolute value of a long integer,
andlastly, max_btthatreturnsthelargestoftwolongintegers.Fig-
ure6presentsthedetailedimplementationofthethreefunctions
in double precision using C macros.
Selectinginjectionsites. Inthispaper,wemainlyfocusonmax-
imizing numerical error for floating-point code that uses multi-
dimensional input data. On the selection of injection sites for inac-
curacychecks,weareparticularlyinterestedinloopsthatiterateontheinputdataandupdatethevariablethatholdstheresult.Assum-ingthree-addresscode,weinjectinaccuracychecksundertheaddi-tionandsubtractionoperations.Unfortunately,itisnotpracticaltocheck for inaccuracies in each iteration. Therefore, we provide two
sampling strategies, uniform and logarithmic, to dynamically se-
lect loop iterations for inaccuracy checks. Both sampling strategies
supplytheparameter startandstepforcustomization.Parameter
startallows the user to start the counter from any iteration, and
stepspecifies the step to the next sampled iteration. In logarithmic
sampling, stepindicatestheinitialstep,whichismultipliedby10
each time the counter increases by one order of magnitude.
Remark. Basedonourobservationofinaccuracypatterns(de-
scribed in Section 2), we inject inaccuracy branches to enable sym-
bolic execution to find error-inducing inputs. Note that previous
work [10,25] has used Equation (2) to detectcancellation when
runningaprogramona givensetofinputs.Incontrast,ourfocus
in thispaper is to generateinputs thatmaximize error.To thebest
of our knowledge, we are the first to formulate precision loss in
which most bits of one operand are discarded, and combine it with
cancellations for inaccuracy checking. Our technique is the first to
enable a widely-used technique such as symbolic execution to find
floating-pointinputsthatmaximizeerror.Symbolicexecutionitself,
however, is unable to generate such inputs as shown in Section 4.
3.2 Symbolic Execution with Concretization
After injecting precision inaccuracy checks, we proceed to symbol-
ically execute the program under test. In this paper, we use one of
the most popular and mature symbolic execution tools, KLEE [ 13],
1266Data:Input variables : inVars, Input specifications : inSpecs, Program :
P, Program with injected inaccuracy checks : P‚Äô, Time budget :
tBudget, Timeout parameters : œÑ0,œÑ1
Result:Maximum error, the error-inducing input
1tStart = time();
2/* Random search for an error-inducing input. */
3randomErrMax = 0; inBase = NULL;
4rStart = time();
5whiletime() - rStart < œÑ0do
6generate a random input in the input domain : in;
7err = compute-error(in, P);
8iferr > eMax then
9 randomErrMax = err; inBase = in;
10end
11end
12/* Separate the input variables into operands. */
13op1Vars, op2Vars = partition-variables(inVars, inSpecs);
14/* Initilization. */
15errMax = randomErrMax; errInput = inBase;
16concVars = op1Vars; symbVars = op2Vars;
17whiletime() - tStart < tBudget do
18 /* Concretize convVars using base values. */
19concretize the variables in convVars using inBase;
20symbolize the variables in symbVars;
21STAT, sInputs = symbolic-execution(convVars, symbVars, P‚Äô, œÑ1);
22ifSTAT = timeout then
23 sNum = length(symbVars);
24 s1Vars, s2Vars = random-divide(symbVars, sNum/2, sNum/2);
25 convVars = convVars + s1Vars;
26 symbVars = s2Vars;
27else
28 forsInput in sInputs do
29 err = compute-error(join-input(sInput, inBase), P);
30 iferr > errMax then
31 errMax = err; errInput ‚Üêjoin-input(sInput, inBase);
32 end
33 end
34 sNum = length(symbVars); lop2=length(op2Vars);
35 s1Vars, s2Vars = random-divide(op2Vars, lop2-sNum, sNum);
36 convVars = op1Vars + s1Vars;
37 symbVars = s2Vars;
38end
39end
40returnerrMax, errInput
Algorithm 1: Symbolic execution with concretization.
asoursymbolicexecutionengine.KLEEmodelstheenvironmentto
explorealllegalvalueswhileensuringtheaccuracyoftheprogram
state, maintains memory efficiently to allow exploring as many
as hundreds of thousands of paths simultaneously, and provides a
setofheuristicsearchstrategiesthatuserscanselectfrom.More
importantly,ithasanextension,KLEE-Float[ 3],whichprovides
support for floating-point arithmetic and thus enables symbolic
execution of floating-point programs.
Symbolic execution allows program inputs to be represented
as symbols. The program is then interpreted using these symbolicvaluesratherthanconcreteinputs.Intheexecutionofaconditional
statement, KLEE forks the current process into two, and each child
process updates its program state by adding the branch constraints
overtheinputsymbolsintoitspathconstraints.Pathconstraints
are solved when the program terminates and input symbols are
concretizedtospecificvaluesthatexercisethegivenpath.Oneofthemainchallengesfacedbysymbolicexecutionispathexplosion.The
numberof feasiblepathsgrows exponentiallywiththe sizeofthe
program.Unfortunately,injectinginaccuracychecksexacerbates
pathexplosion.Toalleviatethisproblem,itisimportanttomanage
the number of symbolic variables. We concretize input variablesprior to symbolic execution and find that it significantly reduces
thenumberofpathstoexplore,makingsymbolicexecutionforour
transformed programs practical.
First,werefertoinputvariablesasscalars.Thearrayandmatrix
inputvariablesarebrokendownintomultiplescalarinputvariables
forconcretizationandsymbolization,discussedintherestofthis
section.Concretizinginputvariablestomanagethenumberofsym-
bolic variables is critical for the application of symbolic execution.
First, symbolizing all input variables is redundant since symbol-
izingonlyoneofthetwooperandsinanoperationsuffices.Take
the operation x+yas an example. To trigger a cancellation in the
operation,itissufficienttosymbolizeeithervariable xory,andthe
valueoftheothercanbearbitrary.Theconcretizationofredundant
symbolic variables is effective in speeding up the constraint solver
behind symbolic execution. Second, besides the redundant input
variables, we randomly select input variables for concretization in
order to perform symbolic execution.
Algorithm1describestheprocedureofsymbolicexecutionwith
concretization.GivenprogramP,programP‚Äôwithinaccuracycheck
injections, input variables, and input specifications that describethe input variables and how they are related in the computation,our algorithm returns the maximum error triggered in program
Pandthecorrespondingerror-inducinginputwithinatimebud-
get. Specifically, we first conduct a random search over all input
variables (line 2-11) and the input that triggers the highest error is
kept asbase values of the input variables for future concretization.
We then partition the input variables into two groups based on the
input specifications so that two operand variables are separated
into different groups (line 13). Take matrix multiplication (MM) as
an example, which performs multiplication over two matrix input
variables. Each of the matrices is an operand of the multiplication,
and in our operand partition, the two matrix entries are separated
asop1Varsandop2Vars.
Lastly, we perform symbolic execution with concretization to
maximize the numerical error in program P (line 14-39). We firstinitialize the maximum error and the corresponding input using
theresultofrandomsearch(line15),andthenupdatethemevery
timeahighererroristriggered(line30-32).Theinputvariablesare
dividedintoconcretevariables(shownas concVars)andsymbolic
variables (symbVars ). Concrete variables use the corresponding
concretevaluesfromthebaseinput(inBase )(line19),andsymbolic
variables are declared as symbols (line 20).
Thesymbolicexecutionengineisinvokedontheinjectedpro-
gramP‚Äôwithanexecutiontimethreshold œÑ1(line21).Ifsymbolic
executiondoesnotterminatewithinthetimethreshold œÑ1,w er e-
duce the number of symbolic variables by half (line 23-26) and
1267repeat.7The initial number of symbolic variables is the number of
the operand variables with smaller size (line 16). If the symbolic
executionengineterminates,weexamineeachinputitgenerates
bycomputingthenumericalerroreachinputtriggersandupdate
the largest error to the maximum error errMaxand error-inducing
inputerrInput(line 28-33). Finally, we shuffle the concrete and
symbolic variables in the operand variable op2Vars(line 34-37) and
repeat the above procedure until time is up.
3.3 Error Measurement
Asdiscussedintheprevioussection,theinputsgeneratedbyran-
dom search and symbolic execution are evaluated by computing
thenumericalerrortheytrigger(Algorithm1,lines7and29).To
measure the error, we transform the program into higher preci-
sion (e.g., 128-bit precision). We compare the result produced by
the originalprogram againsttheone fromthe high-precisionpro-
gram. Moreover, the error is represented by the relative error ofthe two program results, i.e.,
|r‚àír0|/max{FLT_MIN ,|r0|}where
ris the result produced by the original program, r0is the result
ofthetransformedprograminhighprecision,and FLT_MIN indi-
catestheminimumrepresentablepositivefloating-pointnumber
in float precision. In addition, we print the diagnosis informa-
tion that contains the log of precision losses and cancellations and
thecorrespondingcodeareaan inaccuracyeventoccurs.Thiscan
helptheprogrammerinidentifyingtheprogramexpressionsthat
contribute the most to the numerical inaccuracy.
4 EXPERIMENTAL EVALUATION
We implemented our algorithm in a tool named FPGen.8FPGen
includes a floating-point computation analyzer for C programsimplemented using LibTooling [
4]. The analyzer yields a list of
code sites, i.e., statements that contain floating-point addition/sub-
traction operations located within loops, to select as inaccuracy
injection sites. FPGen then performs symbolic execution with con-
cretizationonthetransformedprogramtomaximizetheerrorin
the result. We use KLEE-Float as the symbolic execution engine,
which is built to run on LLVM [26] bitcode files.
Intheevaluationof FPGen,allexperimentswererunonawork-
stationIntel(R)Xeon(R)Gold6238CPU(8cores,2.10GHz),32GB
RAM, and the operating system is Ubuntu 14.04.5 LTS.
The goal of this evaluation is to answer the following questions:
RQ1How effective is FPGen at finding error-inducing inputs?
RQ2How does FPGen compare to random input generation, the
state-of-the-art tool S3FP, and KLEE-Float?
Benchmarks. We evaluate FPGen on the 3 summation algo-
rithms described in Section 2, 9 matrix computation routines from
the Meschach library [ 5], and 9uniquestatistics routines from the
GNUScientificlibrary(GSL)[ 2].Meschachprovidesaseriesofbasic
computationroutinesonmatricesandvectorsinC.Theroutine sum
adds the elements of a vector. As their names indicate, 1-normand
7IntheexperimentsdiscussedinSection4,weuse‚Äú‚Äìmax-time= œÑ1‚Äùtohalttheexecution
ofthe symbolicexecutionenginewhen timeisupaccording tothethreshold œÑ1,and
check whether it has ever reached any error injections and thus triggered errors with
incompleteexecution.Ifitreachederrorinjectionsandtriggerederrorswithintime
thresholdœÑ1, it is considered as an effective termination, otherwise considered as
non-termination (i.e., requiring more time to explore the error paths).
8The source of FPGen is available on GitHub: https://github.com/ucd-plse/FPGen2-normcomputethe 1-normand 2-normof avector, androutines
dotandconvolution calculate the dot product and convolution
product of two vectors, respectively. MVmultiplies a matrix by a
vector,and MMmultipliestwomatrices. LUandQRfactoramatrixto
different forms. GSL provides a wide range of mathematical rou-tines written in C and C++, and has been used for evaluation in
prior work [ 37‚Äì39]. Specifically, we use the GSL statistics routines
thattakearraydataasinput.9Theseroutinescomputethemean,
variance,standarddeviationandmoreadvancedstatisticalterms
such as absolute deviations, skewness and kurtosis for weightedsamples. The functions mainly take two input arrays, one as the
samples and one being the associated weights.
Experimental Setup. Table2presentsthebenchmarksandtheir
input characteristics including kind of input (the number in the
parenthesesindicatesthesizeofeachinputkind),sizeofsymbolized
input and size of concretized input in both the initial and final
configurationsof FPGen.AsdescribedinAlgorithm1,theinitial
partition of symbolized and concretized inputs is based on the
input operands. For the summation programs, MM,LU, and QR, half
of the elements of an array/matrix operand are symbolized and the
restoftheinputdataisconcretized.Fortheremainingprograms,
all elements of an array/vector operand are symbolized and all
elements of the other operand are concretized. Moreover, the final
configurationonsizeofsymbolizedandconcretizedinputsindicates
the partition in which the best relative error is observed.10
With regard to the time threshold parameters œÑ0andœÑ1de-
scribedinAlgorithm1,weuse œÑ0=0,œÑ1=30minforsummation
programs, œÑ0=10min,œÑ1=55minfor Meschach programs and
œÑ0=20min,œÑ1=33minforGSLprograms.Lastly,allbenchmarks
usedoubleprecision,11andweinjectinaccuracychecksintothe
lastaddition/subtractionoperationthatupdatestheaccumulator
inthecoreloopofeachprogram.Thegeneratedinputsare float
numbersin [‚àí100 ,100]tofacilitatecomparisonwithS3FP,which
operates on float numbers and requires an input range.
Baselines. We compare FPGen to (1) a random input genera-
tor we implemented in C++, (2) S3FP, the state-of-the-art floating-
point error-inducing input generator for programs with multi-
dimensionalfloating-pointinput,and(3)KLEE-Float,thefloating-
pointsymbolicexecutionengineusedbyFPGen.Weusethedefault
parametersettings forS3FP: Cinitisrandomized whileparameters
kandNpartare set to the value 1.
Error Measurement. The ground truth for our benchmarks
is obtained by running higher-precision implementations of theprograms on the generated inputs. Specifically, we implemented
summations that use 128-bit precision, and perform long double
precision (80-bit extended precision) for Meschach and GSL rou-
tines. Meschach and GSL support compilation in double and long
9There are a total of 15 floating-point statistics routines in GSL, however, from the
standpointofsymbolicexecution,6ofthem( wvariance-m ,wsd-m,wtss-m,wabsdev-m ,
wskew-m,and wkurtosis-m )areareplicateof6otherroutines( wvariance ,wsd,wtss,
wabsdev,wskew, and wkurtosis ). We only report results for 9 distinct routines, but
the results for all 15 GSL statistics routines are available for full reference.
10Thefinalinputsizedoesnotindicatethesizeofsymbolizedandconcretizedinput
in the last partition of the search. For some programs, further partitions yield smaller
errors.
11GSL routines use long double for the accumulators, and we manually modified
themtobeinconsistentprecisionwiththesamples,i.e.,doubleintheexperiments.
Webelievethechangewillnotcauseanyoverflowexceptionssinceallsamplesand
their associated weights are in a specific input range.
1268Table 2: Input characteristics of benchmarks.
InitialInput Size Final Input Size
Benchmark( s) Input Kind Symbolized Concretized Symbolized Concretized
Summations array(32) 16 16 16 16
sum, 2-norm vector(4) 4 0 4 0
1-norm vector(4) 4 0 2 2
dot, convolution 2 vectors(4) 4 4 2 6
MV vector(4), matrix(4 √ó4) 4 16 2 18
MM 2 matrices(4√ó4) 8 24 8 24
LU matrix (4√ó4) 88 88
QR matrix (4√ó4) 88 4 1 2
wmean, wvariance-w, wsd-w, wtss[-m] 2 arrays(4) 4 4 4 4
wabsdev[-m], wskew[-m], wkurtosis[-m] 2 arrays(4) 4 4 4 4
wvariance[-m], wsd[-m] 2 arrays(4) 4 4 2 6
recursive-sumpairwise-sum
compensated-sumsum2normdot
convolutionMVMMLUQR
wmean
wvariance[-m]wsd[-m]
wvariance-wwsd-wwtss[-m]
wabsdev[-m]wskew[-m]
wkurtosis[-m]10‚àí1610‚àí1210‚àí810‚àí4100Maximum Relative ErrorFPGen
Random
S3FP
Figure 7: Comparison of maximum errors triggered by the error-inducing input generators.
doubleprecision.12Notethatallbenchmarksaretransformedto
higherprecisionatthesourcecodelevel,andwedidnotobserve
precision-specific operations that can potentially cause errors in
thetransformation[ 36].Forallourbenchmarks,wecalculatethe
relativeerroroftheresultproducedbytheoriginalprogramwith
respect to the ground truth. Note that five of our benchmarks pro-
duce vectors or matrices as final result. In these cases, we report
the maximum relative error observed across all elements.13
Experimental Results. We evaluate FPGen on the given 21
benchmarks, and compare it to (1) random input generation (re-
ferred to as Random), (2) the state-of-the-art input generator S3FP,
and(3)KLEE-Float.Forallexperimentsweconsideratimebudget
of2hours.TheresultsareshowninTable3.Column‚ÄúRel.Error‚Äù
indicates the maximum relative error triggered by generated in-
puts (the largest error triggered among the four tools is shown
12Thesupportof longdoubleprecisioninMeschachisincomplete,andwemanually
adjusted few header files.
13S3FPonly aimsontriggeringhigh errorforonesingle outputnumber.For vector/-
matrix output, we adopts the same methodology described in the paper [ 16] which
reports the relative error for the output element whose computation requires the
highestnumberoffloating-pointoperations.Ifalloutputelementsinvolvethesame
number of operations, it reports the relative error of the first output element.inbold),‚Äú#Inputs‚Äùdenotesthetotalnumberofgeneratedinputs
, and ‚Äúhh:mm:ss‚Äù describes the execution time. As shown, KLEE-
Floatisnotabletotriggernumericalerrorsonitsownasitsimply
searches for inputs that cover program paths. Among the three
error-inducinginputgenerators,FPGengenerateserror-inducing
inputs for 20 out of 21 benchmarks while the inputs generatedby Random and S3FP trigger an error in 13 out of 21 programs.
AsshowninthefirstfourrowsinTable3,RandomandS3FPex-
ploredoverfivehundredthousandinputarrays/vectorsbutfailed
tofindonethatexposesanerrorforthe3summationprogramsand
5 Meschach routines. FPGen, however, triggered errors in theseprograms, except for
1-norm, after exploring significantly fewer
inputswithinthetimebudget.Furthermore,thenumericalerrors
triggeredbyFPGenareupto1 .0,whicharecomparableinorderof
magnitudetotheerrorstriggeredbythehandcraftedinputfrom
Section 2.
Figure7visualizesthemaximumrelativeerroreacherror-inducing
input generator triggered for all benchmarks except 1-normfor
which none of the generators triggered an error. The Y axis that
indicates the maximum relative error triggered in each benchmark
is proportional to the logarithm of the errors. As shown, FPGen
1269Table 3: Accuracy testing results for numerical library routines.
Recursive Summation (32) Pairwise Summation (32) Compensated Summation (32)
Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss
Random 0.0000e+00 583704 02:00:00 0.0000e+00 579979 02:00:00 0.0000e+00 533939 02:00:00
S3FP 0.0000e+00 577227 02:00:00 0.0000e+00 551594 02:00:00 0.0000e+00 550118 02:00:00KLEE-Float 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 1 ‚â§00:00:01
FPGen 1.0000e+00 9472 02:00:00 1.3174e-16 1532 02:00:00 1.0000e+00 547 02:00:00
sum 1-norm 2-norm
Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss
Random 0.0000e+00 542842 02:00:00 0.0000e+00 550180 02:00:00 3.1216e-16 544735 02:00:00
S3FP 0.0000e+00 550353 02:00:00 0.0000e+00 549360 02:00:00 3.1170e-16 542879 02:00:00
KLEE-Float 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 1 ‚â§00:00:01
FPGen 1.0000e+00 43055 02:00:00 0.0000e+00 41690 02:00:00 2.2117e-16 41039 02:00:00
dot convolution MV
Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss
Random 1.7010e-12 587409 02:00:00 9.2803e-13 561780 02:00:00 0.0000e+00 562187 02:00:00S3FP 5.5831e-10 541171 02:00:00 1.9864e-10 529503 02:00:00 0.0000e+00 559708 02:00:00
KLEE-Float 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 1 ‚â§00:00:01
FPGen 1.9190e-04 43649 02:00:00 2.0446e-04 42099 02:00:00 8.9366e-04 41180 02:00:00
MM LU QR
Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss
Random 1.1102e-16 587108 02:00:00 0.0000e+00 544796 02:00:00 0.0000e+00 551384 02:00:00S3FP 1.1102e-16 530526 02:00:00 0.0000e+00 543181 02:00:00 0.0000e+00 502424 02:00:00
KLEE-Float 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 9 00:01:20 0.0000e+00 24 02:24:51
FPGen 2.5783e-14 43965 02:00:00 2.7327e+00 40831 02:00:00 2.5912e-14 40944 02:00:00
wmean wvariance (wvariance-m) wsd (wsd-m)
Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss
Random 9.4290e-12 526315 02:00:00 1.5039e-11 528128 02:00:00 7.5193e-12 529821 02:00:00S3FP 1.6620e-07 526118 02:00:00 2.5955e-05 528292 02:00:00 1.2977e-05 535576 02:00:00
KLEE-Float 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 16 00:00:25 0.0000e+00 16 00:00:25
FPGen 1.0000e+00 89844 02:00:00 7.6280e-02 89221 02:00:00 3.7439e-02 88883 02:00:00
wvariance-w wsd-w wtss (wtss-m)
Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss
Random 7.9593e-12 529220 02:00:00 3.9797e-12 531602 02:00:00 5.5294e-16 526324 02:00:00
S3FP 2.0918e-05 531397 02:00:00 1.0459e-05 528545 02:00:00 4.7739e-16 526869 02:00:00
KLEE-Float 0.0000e+00 16 00:00:25 0.0000e+00 16 00:00:25 0.0000e+00 16 00:00:25FPGen 2.2858e-12 90107 02:00:00 1.1429e-12 89057 02:00:00 4.4513e-16 89318 02:00:00
wabsdev (wabsdev-m) wskew (wskew-m) wkurtosis (wkurtosis-m)
Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss Rel. Error #Inputs hh:mm:ss
Random 2.6840e-11 535959 02:00:00 2.5025e-11 497012 02:00:00 4.5107e-11 499180 02:00:00S3FP 2.2077e-05 535286 02:00:00 3.1646e-02 507847 02:00:00 4.3139e-08 473608 02:00:00
KLEE-Float 0.0000e+00 16 00:00:25 0.0000e+00 1 ‚â§00:00:01 0.0000e+00 16 00:00:24
FPGen 1.0000e+00 44041 02:00:00 2.5675e+01 89715 02:00:00 1.7733e-12 89794 02:00:00
outperformsRandomandS3FPfor15outof20benchmarks.In2of
theotherbenchmarks,thethreeapproachesarecomparabletoeach
other, and the order of magnitude of the errors are ‚àí16. For the
remaining3benchmarks(fromGSL),FPGenfailedtoreachanerror
path within the time budget and S3FP triggered the largest error
amongtheinputgeneratorsthroughblack-boxsearch.Itrequires
future improvements on symbolic execution to assist FPGen reach
more error paths, and thus trigger larger errors for these programs.
Insummary,usingprecisionlossandcancellationchecksiseffec-
tive in finding high error-inducing inputs especially for numerical
programs with multi-dimensional input data. From the evaluationon the summation benchmarks, the matrix computation libraryMeschach, and the GSL statistics functions, FPGen significantly
outperforms the state of the art.
RQ1:FPGen proves to be effective at finding error-inducing
inputs by triggering errors in 20 out of 21 benchmarks and
the errors are -6.35 on average in the order of magnitude.RQ2:
FPGen significantly outperforms the state of the art by
triggeringerrorsin33%moreprogramswhileerrorsaremore
than 2 orders of magnitude larger on average.
1270Specifically,FPGengeneratederror-inducinginputsfor20bench-
markprogramswhilethestate-of-the-artgeneratorstriggeranerror
for13outof21programs.Moreover,regardingthemaximumerrors
triggeredbythegeneratedinputs,FPGen(-6.35onaveragein20
programs)improvesS3FP(-8.46onaveragein13programs)byover
two orders of magnitude. The order of magnitude of the maximum
errors triggered by Random in 13 programs is -12.69 on average.
Discussion. Theerror-inducinginputsgeneratedbyFPGencan
be used in many contexts including floating-point precision tun-
ing and compiler testing for floating-point optimizations. Dynamicprecision tuning (e.g., [
31]) lowers precision while satisfying an ac-
curacyconstraint.Suchapproachestunetheprogramswithrespect
to a given test set. Augmenting such test sets with inputs gener-
atedbyFPGencouldleadtomorerobustprecisionoptimizations.
Moreover,compilerstransformcodeforoptimizationsbutthetrans-
formation is risky for floating-point code because floating-pointarithmetic does not satisfy associative and distributive laws. To
enhance the compiler optimizations for floating-point code, inputs
that maximize the numerical error are required for testing.
With regard to the limitation of our tool, first, FPGen requires a
specification for inaccuracy check injection (we used core loops in
thispaper).Itremainsfutureworktoidentifyothercodeareasto
inject inaccuracy checks. Second, we mainly rely on optimizations
suchasconcretizationtomanagethenumberofsymbolicvariables
to alleviate the scalability problem symbolic execution faces. In
thefuture,itwouldbeinterestingtocomplementourworkusing
techniquestospeedupsymbolicexecution[8,35].
5 RELATED WORK
Floating-PointTestDataGeneration. S3FP[16],thestate-of-the-
art error-inducing input generator for numerical programs with
multi-dimensional input data, is black-box. S3FP iteratively divides
thesearchrangeofeachinputvariableintotwoandpermutesthem
randomly to generate a tighter search space. The tool evaluateseach subspace by sampling inputs and selecting one for further
exploration.Theblack-boxnatureof S3FPindicatesthatitisnotaseffectiveasFPGenwhentheinputspacebecomeslarge.Othererror-inducinginputgenerators,i.e.,LSGA[
39],EAGT[ 37]andAutoRNP
[37] target numerical program with few scalar inputs. LSGA uses a
genetic algorithm to evolve the exponent of the inputs, however,it does not provide an algorithm in evolving multi-dimensional
floating-point inputs, andthe tool is not publicly available. EAGT
and AutoRNP compute the approximation of the condition number
in selecting inputs, and focus on programs with one scalar input.
FPSE[9]andCoverMe[ 19]generatefloating-pointtestinputs
thatmaximize codecoverage.FPSE[ 9]adoptsanumberofsearch
heuristicstosolvepathconditions containingfloating-pointcom-
putations. CoverMe [ 19] translates the problem of covering a new
branch in the floating-point code into amathematical problem thatcanbesolvedbyapplyingunconstrainedprogramming.Suchefforts
are complementary to our testing approach, and can be adopted to
enhance our symbolic-execution based approach.
Floating-point input generation tools have been developed to
detect other specific problems. Chiang et al .[17] detect path di-
vergencebetweenafloating-pointprogramanditshighprecisionexecution.Barretal .[11]usesymbolicexecutiontodetectfloating-
point exceptions such as overflows and underflows. They also per-
formatransformationonthenumericalprogram,andsymbolically
execute the transformed program to identify inputs that trigger an
exception.Thetransformation,h owever,focuses oninjectingex-
ception checks before a floating-point operation, which is different
from ours. Moreover, the transformed program is symbolically exe-
cuted using real arithmetic while we use floating-point arithmetic.
Floating-Point Dynamic Analysis. Benz et al .[12] perform every
floating-point computation side by side in higher precision and
trackthepropagationoferrorstodetectaccuracyproblems.Lam
etal.[25]conductbinaryinstrumentationonfloating-pointaddi-
tions and subtractions to detect cancellations. They analyze the
exponents of the operands and the result of the instrumented oper-
ationstodeterminetheseverityofacancellationandreportstack
information for severe cancellations. Besides the runtime detectionofmathematicalcancellations,BaoandZhang[
10]proposetotrack
the propagation of the cancellation error, which can be suppressed
orinflatedinthesubsequentexecution.Bothcancellationdetection
techniques[ 10,25]usethecancellationcheckequationdescribed
in our paper. However, their main purpose is to detect cancellation
issues for existing inputs and cannot generate error-inducing in-
puts.Furthermore,itisimportanttocombineprecisionlosswith
cancellation in the generation of error-inducing inputs. To the best
of our knowledge, we are the first to present such an approach.
RAIVE[27]performsfloating-pointcomputationwithavector
of values tocapture rounding errors and report outputvariations.
Similarly, Tang et al .[34] perturb the underlying numerical values
and expressions to uncover instability problems in numerical code.
Suchdynamicanalysesdetectaccuracyproblemsongiveninput
data.Moreover,alargenumberofdynamictechniques(e.g.,[ 21,24,
29‚Äì32]) optimize floating-point code using a given input set. All of
these techniques could benefit from the inputs FPGen generates.
6 CONCLUSION
We presented an approach to effectively generate floating-point
inputsthattriggerlargeerrors.First,weformulatedtwoinaccuracychecksforlargeprecisionlossandcancellation.Theinjectionofin-
accuracy checks after floating-point computation enables symbolic
execution to explore specialized branches that cause numerical in-
accuracy, which can lead to large errors in the final result. Second,
we proposed optimizations to alleviate path explosion. In partic-
ular, this was achieved by strategically reducing the number ofsymbolicvariablesviaconcretization.Weimplementedouralgo-
rithminatoolnamedFPGen,andpresentedanevaluationon21
numericalprogramsincludingmatrixcomputationandstatistics
libraries.OurresultsshowthatFPGenisabletoexposeerrorsfor20oftheevaluatedprogramswhilethestate-of-the-arterror-inducinginputgeneratorS3FPonlytriggerserrorsfor13outof21programs.
Moreover, FPGen triggered an error as large as 10‚àí6on average
while the maximum error S3FP triggered is about 10‚àí8on average.
ACKNOWLEDGMENTS
ThisworkwassupportedbytheNationalScienceFoundationunder
award CCF-1750983, and by the U.S. Department of Energy, Office
of Science, Advanced Scientific Computing Research, under award
DE-SC0020286.
1271REFERENCES
[1]Accessed:2020-01-01. TheExplosionoftheAriane5. https://www.ima.umn.edu/
~arnold/disasters/ariane.html.
[2]Accessed: 2020-01-01. GSL- GNU Scientific Library. https://www.gnu.org/
software/gsl/.
[3]Accessed: 2020-01-01. KLEE with floating point support. https://github.com/srg-
imperial/klee-float.
[4]Accessed: 2020-01-01. LibTooling. https://clang.llvm.org/docs/LibTooling.html.
[5]Accessed:2020-01-01. MeschachLibrary. https://www.netlib.org/c/meschach/
readme.
[6]Accessed:2020-01-01. Toyota:SoftwaretoblameforPriusbrakeproblems. http://
www.cnn.com/2010/WORLD/asiapcf/02/04/japan.prius.complaints/index.html.
[7] Accessed: 2020-01-01. Z3. https://github.com/Z3Prover/z3.
[8]EmanAlatawi,TimMiller,andHaraldSondergaard.2018. SymbolicExecution
with Invariant Inlay: Evaluating the Potential. In 2018 25th Australasian Software
Engineering Conference, ASWEC 2018.
[9]Roberto Bagnara, Matthieu Carlier, Roberta Gori, and Arnaud Gotlieb. 2013.
SymbolicPath-OrientedTestDataGenerationforFloating-PointPrograms.In
SixthIEEEInternationalConferenceonSoftwareTesting,VerificationandValidation,
ICST 2013.
[10]Tao Bao and Xiangyu Zhang. 2013. On-the-fly detection of instability problems
infloating-pointprogramexecution.In Proceedingsofthe2013ACMSIGPLAN
InternationalConferenceonObjectOrientedProgrammingSystemsLanguages&
Applications, OOPSLA 2013.
[11]Earl T. Barr, Thanh Vo, Vu Le, and Zhendong Su. 2013. Automatic Detection
ofFloating-pointExceptions.In Proceedingsofthe40thAnnualACMSIGPLAN-
SIGACT Symposium on Principles of Programming Languages, POPL 2013.
[12]FlorianBenz,AndreasHildebrandt,andSebastianHack.2012. ADynamicPro-
gramAnalysistoFindFloating-pointAccuracyProblems.In Proceedingsofthe
33rd ACM SIGPLAN Conference on Programming Language Design and Implemen-
tation, PLDI 2012.
[13]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: Unassisted and
AutomaticGenerationofHigh-coverageTestsforComplexSystemsPrograms.
InProceedings of the 8th USENIX Conference on Operating Systems Design and
Implementation, OSDI 2008.
[14]Cristian Cadar, Vijay Ganesh, Peter M. Pawlowski, David L. Dill, and Dawson R.
Engler.2008. EXE:AutomaticallyGeneratingInputsofDeath. ACMTrans.Inf.
Syst. Secur. 12, 2, Article 10 (Dec. 2008), 38 pages.
[15]Cristian Cadar and Koushik Sen. 2013. Symbolic Execution for Software Testing:
Three Decades Later. Commun. ACM 56, 2 (Feb. 2013), 82‚Äì90.
[16]Wei-Fan Chiang, Ganesh Gopalakrishnan, Zvonimir Rakamaric, and Alexey
Solovyev. 2014. Efficient search for inputs causing high floating-point errors. In
ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming,
PPoPP 2014.
[17]Wei-Fan Chiang, Ganesh Gopalakrishnan, and Zvonimir Rakamariƒá. 2015. Prac-
ticalfloating-pointdivergencedetection.In InternationalWorkshoponLanguages
and Compilers for Parallel Computing.
[18]AnthonyDiFranco,HuiGuo,andCindyRubio-Gonz√°lez.2017. Acomprehensive
study of real-world numerical bug characteristics. In Proceedings of the 32nd
IEEE/ACM International Conference on Automated Software Engineering, ASE
2017.
[19]Zhoulai Fu and Zhendong Su. 2017. Achieving high coverage for floating-pointcode via unconstrained programming. In Proceedings of the 38th ACM SIGPLAN
Conference on Programming Language Design and Implementation, PLDI 2017.
[20]Patrice Godefroid, Nils Klarlund, and Koushik Sen. 2005. DART: Directed Auto-
mated Random Testing. SIGPLAN Not. 40, 6 (June 2005), 213‚Äì223.
[21]Hui Guo and Cindy Rubio-Gonz√°lez. 2018. Exploiting Community Structurefor Floating-point Precision Tuning. In Proceedings of the 27th ACM SIGSOFT
International Symposium on Software Testing and Analysis, ISSTA 2018.[22]Nicholas J Higham. 1993. The accuracy of floating point summation. SIAM
Journal on Scientific Computing 14, 4 (1993), 783‚Äì799.
[23]James C. King. 1976. Symbolic Execution and Program Testing. Commun. ACM
19, 7 (July 1976), 385‚Äì394.
[24]Michael O. Lam, Jeffrey K. Hollingsworth, Bronis R. de Supinski, and Matthew P.
LeGendre. 2013. Automatically adapting programs for mixed-precision floating-
point computation. In Proceedings of the 27th international ACM conference on
International conference on supercomputing, ICS 2013.
[25]Michael O. Lam, Jeffrey K. Hollingsworth, and G. W. Stewart. 2013. Dynamic
floating-point cancellation detection. Parallel Comput. (2013).
[26]Chris Lattner and Vikram Adve. 2004. LLVM: A Compilation Framework for
Lifelong Program Analysis & Transformation. In Proceedings of the International
Symposium on Code Generation and Optimization: Feedback-directed and Runtime
Optimization, CGO 2004.
[27]Wen-ChuanLee,TaoBao,YunhuiZheng,XiangyuZhang,KevalVora,andRa-
jiv Gupta. 2015. RAIVE: Runtime Assessment of Floating-point Instability by
Vectorization. In Proceedings of the 2015 ACM SIGPLAN International Conference
on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA
2015.
[28]Daniel Liew, Daniel Schemmel, Cristian Cadar, Alastair F Donaldson, Rafael
Zahl,and KlausWehrle.2017. Floating-pointsymbolic execution:Acasestudy
inN-versionprogramming.In Proceedingsofthe32ndIEEE/ACMInternational
Conference on Automated Software Engineering, ASE 2017.
[29]Pavel Panchekha, Alex Sanchez-Stern, James R. Wilcox, and Zachary Tatlock.
2015. Automaticallyimprovingaccuracyforfloatingpointexpressions.In Pro-
ceedings of the 36th ACM SIGPLAN Conference on Programming Language Design
and Implementation, PLDI 2015.
[30]CindyRubio-Gonz√°lez,CuongNguyen,BenjaminMehne,KoushikSen,James
Demmel, William Kahan, Costin Iancu, Wim Lavrijsen, David H. Bailey, andDavid Hough. 2016. Floating-point precision tuning using blame analysis. InProceedings of the 38th International Conference on Software Engineering, ICSE
2016.
[31]Cindy Rubio-Gonz√°lez, Cuong Nguyen, Hong Diep Nguyen, James Demmel,
WilliamKahan,KoushikSen,DavidH.Bailey,CostinIancu,andDavidHough.
2013. Precimonious:tuningassistantforfloating-pointprecision.In International
ConferenceforHighPerformanceComputing,Networking,StorageandAnalysis,
SC 2013.
[32]Eric Schkufza, Rahul Sharma, and Alex Aiken. 2014. Stochastic optimization of
floating-point programs with tunable precision. In ACM SIGPLAN Conference on
Programming Language Design and Implementation, PLDI 2014.
[33] Robert Skeel. 1992. Roundoff error and the Patriot missile. SIAM News (1992).
[34]EnyiTang,EarlBarr,XuandongLi,andZhendongSu.2010. PerturbingNumerical
CalculationsforStatisticalAnalysisofFloating-pointProgram(in)Stability.In
Proceedings of the 19th International Symposium on Software Testing and Analysis,
ISSTA 2010.
[35]David Trabish, Andrea Mattavelli, Noam Rinetzky, and Cristian Cadar. 2018.
Chopped Symbolic Execution. In Proceedings of the 40th International Conference
on Software Engineering, ICSE 2018.
[36]Ran Wang, Daming Zou, Xinrui He, Yingfei Xiong, Lu Zhang, and Gang Huang.
2016. DetectingandFixingPrecision-specificOperationsforMeasuringFloating-
point Errors. In Proceedings of the 2016 24th ACM SIGSOFT International Sympo-
sium on Foundations of Software Engineering, FSE 2016.
[37]Xin Yi, Liqian Chen, Xiaoguang Mao, and Tao Ji. 2017. Efficient global search
forinputstriggeringhighfloating-pointinaccuracies.In 201724thAsia-Pacific
Software Engineering Conference, APSEC 2017.
[38]XinYi,LiqianChen,XiaoguangMao,andTaoJi.2019. Efficientautomatedrepair
ofhighfloating-pointerrorsinnumericallibraries. ProceedingsoftheACMon
Programming Languages, POPL (2019).
[39]Daming Zou, Ran Wang, Yingfei Xiong, Lu Zhang, Zhendong Su, and Hong Mei.
2015. A Genetic Algorithm for Detecting Significant Floating-Point Inaccuracies.
In37th IEEE/ACM International Conference on Software Engineering, ICSE 2015.
1272