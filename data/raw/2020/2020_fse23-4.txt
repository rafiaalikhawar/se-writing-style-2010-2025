Deep LearningBased FeatureEnvyDetectionBoostedby
Real-WorldExamples
BoLiu
Beijing Institute of Technology, China
liubo@bit.edu.cnHui Liuâˆ—
Beijing Institute of Technology, China
liuhui08@bit.edu.cnGuangjieLi
NationalInnovation Institute of
DefenseTechnology, China
liguangjie_er@126.com
NanNiu
Universityof Cincinnati,USA
nan.niu@uc.eduZimao Xu
Beijing Institute of Technology, China
zimaoxu@bit.edu.cnYifan Wang
HuaweiCloud, China
wangyifan14@huawei.com
Yunni Xia
ChongqingUniversity, China
xiayunni@hotmail.comYuxia Zhang
Beijing Institute of Technology, China
yuxiazh@bit.edu.cnYanjieJiangâˆ—
Beijing Institute of Technology, China
PekingUniversity, China
yanjiejiang@bit.edu.cn
ABSTRACT
Feature envy is one of the well-recognized code smells that should
be removed by software refactoring. A major challenge in fea-
ture envy detection is that traditional approaches are less accurate
whereasdeeplearning-basedapproachesaresuï¬€eringfromthelack
ofhigh-qualitylarge-scaletrainingdata.Althoughexistingrefactor-
ingdetectiontoolscouldbeemployedtodiscoverreal-worldfeature
envy examples, the noise (i.e., non-feature envy) within the result-
ing data could signi/f_icantly in/f_luence the quality of the training
dataaswellastheperformanceofthemodelstrainedonthedata.
To this end, in this paper, we propose a sequence of heuristic rules
andadecisiontree-basedclassi/f_ierto/f_ilteroutnon-featureenvy
reportedby state-of-the-art refactoring detection tools.The data
after /f_ilteringserve as the positive items in the requested training
data. From the same subject projects, we randomly select methods
thatarediï¬€erentfrompositiveitemsasnegativeitems.Withthe
real-world examples (both positive and negative examples), we
design and train a deep learning-based binary model to predict
whetheragivenmethodshouldbemovedtoapotentialtargetclass.
Diï¬€erent from existing models, it leverages additional features, i.e.,
coupling between methods and classes ( CBMC) and the message
passing coupling between methods and classes ( MCMC) that have
notyetbeenexploitedbyexistingapproaches.Ourevaluationre-
sults on real-world open-source projects suggest that the proposed
approachsubstantiallyoutperformsthestateoftheartinfeature
envy detection, improving precision and recall by 38.5% and 20.8%,
respectively.
âˆ—Corresponding authors
Permissionto make digitalor hard copies of allor part ofthis work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forpro/f_itorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe/f_irstpage.Copyrightsforcomponentsof thisworkownedbyothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspeci/f_icpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™23, December 3â€“9, 2023, San Francisco, CA,USA
Â© 2023 Copyright held by the owner/author(s). Publicationrightslicensed toACM.
ACM ISBN 979-8-4007-0327-0/23/12...$15.00
https://doi.org/10.1145/3611643.3616353CCS CONCEPTS
â€¢Softwareanditsengineering â†’Softwaremaintenancetools ;
Software evolution .
KEYWORDS
Software Refactoring, Feature Envy,Code Smells
ACM Reference Format:
Bo Liu, Hui Liu, Guangjie Li, Nan Niu, Zimao Xu, Yifan Wang, Yunni
Xia, Yuxia Zhang, and Yanjie Jiang. 2023. Deep Learning Based Feature
Envy Detection Boosted by Real-World Examples. In Proceedings of the
31stACMJointEuropeanSoftwareEngineeringConferenceand Symposium
on the Foundations of Software Engineering (ESEC/FSE â€™23), December 3â€“
9, 2023, San Francisco, CA, USA. ACM, New York, NY, USA, 13pages.
https://doi.org/10.1145/3611643.3616353
1 INTRODUCTION
The term code smells was coined by Beck and Fowler [ 23] to repre-
sentbaddesignsinsourcecodethatmayreducethereadabilityand
maintainabilityofsoftwareprojects.Diï¬€erentcategoriesofcode
smell, e.g, duplicated code ,lazy class , andlong method have been
proposed and intensively studied in both industry and academic
community[ 15,20].Consideringtheprevalenceandimpactofcode
smells,hundredsofautomatedorsemi-automatedapproacheshave
been proposed to identify and resolve such code smells [ 3,18].
Code smells also widely serve as a useful indicator of software
quality[70]andpilotlampsfor software refactorings [ 69].
Feature envy is one of the most well-known and well-studied
codesmells[ 17,49].Methodsassociatedwithfeatureenvysmells
are often called feature envy methods ormisplaced methods [4,10].
Suchmethodsaremoreinterestedin(featuresof)otherclassesthan
theirenclosing classes,andthustheyshouldbe movedfrom their
enclosingclassestothoseclassesthattheyareinterestedin.The
movementisknownas movemethodrefactorings [46].Featureenvy
methodsoften resultinunnecessarycoupling betweenclasses,in-
creasingthediï¬ƒcultyofmaintenance[ 62].Tothisend,researchers
haveproposeddozensofapproaches/toolstodetectfeatureenvy
methods automatically [ 50,52] and to recommend solutions (i.e.,
movemethod refactorings )[5,66].
908ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA BoLiu, HuiLiu, Guangjie Li, Nan Niu,Zimao Xu,YifanWang,YunniXia,YuxiaZhang,andYanjieJiang
Themostsimpleandintuitivewaytoidentifyfeatureenvymeth-
odsistomanuallydesignasequenceofheuristicrulesandtodetect
feature envy methods withsuch prede/f_ined rules. Well-known ex-
amples include JDeodorant [17] andJMove[64]. Although such
heuristics-basedapproachesaresimpleandintuitive,itisdiï¬ƒcult
tode/f_inecomprehensiveandaccurateheuristicsanditisalsodif-
/f_icult to /f_ind the optimal setting of the thresholds that are often
indispensableforheuristicrules[ 25].Tothisend,researcherslever-
age traditional machine learning techniques, like SVM [ 32] and
decision trees [ 2], to automatically learn rules for feature envy
detection. Although such traditional machine learning techniques
havetheabilitytolearnsimplerulesfromsmalllabeleddatasets,
complexmappings(especially nonlinear mappings)fromcomplex
featuresofsourcecodetothepredictionareoftenbeyondthereach
ofsuchtechniques[ 13,53].Tolearnsuchcomplexmappings(rules),
more advanced deep learning techniques have been applied to the
detection of feature envy smells [ 41]. Although deep learning tech-
niqueshavethepotentialtolearncomplexmappings,theyoften
requestalargenumberoflabeledhigh-qualitytrainingdatathat
are diï¬ƒcult to obtain [ 58]. The size and quality of the training
data can signi/f_icantly in/f_luence the performance of the resulting
models [33]. To this end, Liu et al. [ 41] collected negative items
(i.e.,methodsnotassociatedwithfeatureenvysmells)byrandomly
sampling methods in high-quality open-source projects, assuming
thatallsuchmethodsarewell-placedandarenotassociatedwith
feature envy smells. Based on the same assumption, Liu et al. [ 41]
generatedpositiveitems(i.e.,featureenvymethods)byrandomly
moving methods within high-quality open-source projects, and
the resulting methods (after move method refactorings) envy their
original enclosing classes (where they were placed before move
method refactorings), and thus they could be taken as feature envy
methods.Althoughthisnovelapproachtogeneratingtrainingdata
hassuccessfullyincreasedthesizeoftrainingdatasets,italsoraises
serious concerns about the quality of the generated data: The ar-
bitrarily and intentionally created feature envy smells could be
essentially diï¬€erent from those in real-world projects that are cre-
atedorganicallybydevelopers.Asaconclusion,thechallengein
feature envy detection is that traditional approaches are less accu-
rate whereas deep learning-based approaches are suï¬€ering from
the lackofhigh-qualitylarge-scale training data.
In this paper, we boost deep learning-based feature envy de-
tectionbyreal-worldexamples.Althoughexistingrefactoringde-
tectiontools,e.g., RefactoringMiner [67],couldbeemployedto
discoverreal-world movemethodrefactoring examples,thenoise
(i.e., non-feature envy)within the resulting datacouldsigni/f_icantly
in/f_luencethequalityofthetrainingdataaswellastheperformance
ofthemodelstrainedonthedata.TheevaluationresultsinSection 4
con/f_irm that directly employing the output of RefactoringMiner
astrainingdatawouldresultinasubstantialreductioninperfor-
mance.Tothisend,weproposeasequenceofheuristicrulesand
adecisiontree-basedclassi/f_ierto/f_ilterout potentialmovemethod
refactorings that are not associatedwithfeature envy smells.
Another contribution of the paper is that we design a new deep
learning-based model by leveraging features, i.e., coupling between
methods and classes (CBMC) andmessage passing coupling between
methodsandclasses (MCMC)thathavenotyetbeenexploitedbyex-
istingapproachesforfeatureenvydetection.Thethirdcontributionisthatwedesignandleverageasequenceofheuristicsrulesbesides
the deep learning-based classi/f_ier to make the /f_inal decisions in
feature envy detection. We evaluate the proposed approach on /f_ive
real-world open-source projects. Our evaluation results suggest
that the proposed approach substantially improves the state of the
art,improvingprecisionandrecallby38.5%and20.8%,respectively.
Thepaper makesthe following contributions:
â€¢An automated approach to collecting real-world feature envy
examples,andapubliclyavailablelarge-scalehigh-qualitydataset
ofreal-world feature envy methods.
â€¢A deep learning-based approach (called feTruth) to detecting
andresolvingfeatureenvysmells,leveragingnewfeaturesnot
yet employedfor this task.
â€¢An initialevaluation of the proposedapproach.
2 RELATED WORK
2.1 Heuristics-BasedApproaches
Structuralinformationofsourcecode,especiallydependencies,is
widelyusedinheuristics-baseddetectionoffeatureenvysmells.For
example, Tsantalis and Chatzigeorgiou [ 66] proposed a distance-
based approach to identify move method refactoring opportunities
andintegratedtheapproachintothewell-knownrefactoringtool
JDeodorant [17]. They rede/f_ined the Jaccard distance [61] to mea-
surethedistancebetweenmethodsandclasses.Ifamethodiscloser
to a class than its enclosing class, and it satis/f_ies a set of precon-
ditions that enable a legal move method refactoring, the method
shouldbemoved.Salesetal[ 56,64]proposedasimilarity-basedap-
proachJMovetosuggestmovemethodrefactorings.Theycomputed
theaveragesimilaritybetweenamethodandaclassaccordingto
theirdependencies.Ifamethodismoresimilartoaclassthanits
enclosing class, it should be moved. Mayvan et al. [ 45]p r o po s eda
metric-basedapproachtoidentifyfeatureenvysmells.Theysum-
marized code metrics that have already been exploited by existing
approaches for feature envy detection. Based on the resulting met-
rics, they de/f_ined the formal speci/f_ication of feature envy smells
anddetectedsmellsaccording to the metrics-basedspeci/f_ication.
Textual information is also useful for feature envy detection
because the semantic information embedded in identi/f_iers (e.g.,
method names and class names) represents the roles of software
entities(e.g.,methodsandclasses)andsuchrolesarecriticalfactors
for feature envy detection. For example, Bavota et al. [ 5] leveraged
RelationalTopicModels (RTM)torecommendmovemethodrefac-
toring opportunities by exploiting both textual information and
structuralinformationtoderivesemanticandstructuralrelation-
ships between methods. Based on such relationships, the approach
(calledMethodbook ) identi/f_ies feature envy smells and suggests
destinations for the feature envy methods. Palomba et al. [ 52]p r o -
posed a text-based approach to detecting code smells (including
featureenvysmells).Theyextractedtextualcontents(i.e.,identi-
/f_iers and comments) and normalized them by a typical information
retrieval normalization process. The normalized textual content
wasemployedtocomputethe textual similaritybetweenmethods
andclasses.Ifamethodismoresimilartoaclassthanitsenclosing
class,itshould be moved.
Evolutionhistoriesandrefactoring historiescouldbeexploited
forthedetectionoffeatureenvysmells.Forexample,Palombaet
909Deep Learning BasedFeature Envy DetectionBoostedby Real-WorldExamples ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
al. [50,51] exploited change histories to detect feature envy smells.
Theyassumedthatamethodaï¬€ectedbyfeatureenvysmellsshould
changemorefrequentlytogetherwiththeenviedclassthanwiththe
classwhereitisactuallyplaced.Consequently,ifamethodchanges
more frequently together with a class than with its enclosing class,
the method is a feature envy method. Liu et al. [ 42]p r o p o s e da n
approach to identify move method refactoring opportunities based
onrefactoring histories.Oncedevelopers move method /u1D45Aoutof
class/u1D436, the approach recommends moving such methods in /u1D436that
have the strongestrelationship andgreatestsimilaritywith /u1D45A.
2.2 MachineLearning-BasedApproaches
Kreimer [ 36] employed decision tree-based classi/f_ication to de-
tect design /f_laws (including feature envy smells). Fontana et
al. [19,21,22] conducted an empirical study comparing the per-
formance of diï¬€erent machine learning techniques in detecting
codesmells.Theirevaluationresultssuggestthatmachinelearning
techniquescansigni/f_icantlyimprovetheperformanceofcodesmell
detection.Similarly,Amorimetal.[ 2]evaluatedtheperformance
ofdecisiontree-baseddetectionofcodesmells.Theirexperiment
results suggestthat decision trees result inthe bestperformance.
Nucci et al.[ 13] replicated the study by Fontana et al. [ 19] with
a more realistic dataset. However, their evaluation results revealed
that the high performance achieved in the previous study [ 19]
was due to the speci/f_ic characteristics (e.g., unrealistically bal-
anceddatasetandbiasedvalidationmethods)oftheselectedlimited
dataset. In contrast, the eï¬€ect of traditional machine learning tech-
niques incode smelldetection islimited.
2.3 DeepLearning-BasedApproaches
Liu et al. [ 41,43] are the /f_irst to apply deep learning techniques
(morespeci/f_ically,CNNandfullyconnectednetworks)tothedetec-
tionandresolutionoffeatureenvysmells.Theyexploitedtextual
informationandcodemetrics(i.e.,thedistancebetweenmethods
andclasses[ 66])asinputtoaneuralnetwork-basedclassi/f_ierwhose
output indicates whether a given method should be moved from
its enclosing class to another given class. They realized that ex-
isting datasets are too small for deep learning-based techniques,
andthustheyproposedanovelapproachtocreatelarge-scalela-
beleddatasetsautomaticallybyrandomlymovingmethodsinhigh-
quality open-source projects. Their evaluation results suggest that
the deep learning-based approach signi/f_icantly outperforms the
state of the art in detecting feature envy smells and in recommend-
ing solutions for feature envy methods. Barbez et al. [ 4] applied
multi-layerperceptions(i.e.,fullyconnectedfeedforwardneural
networks)tothedetectionoffeatureenvysmells.BesidesCNNand
fullyconnectednetworks,otherdeep-learningtechniqueshavealso
been applied to the detection and resolution of feature envy smells.
Hadj-KacemandBouassida[ 27]adopted codingcriterion [54]and
avariational autoencodertoextractthesemanticfeatures hidden
in the source code, which are fed to a logistic regression classi-
/f_ier to detect feature envy smells. Kurbatova et al. [ 37] exploited
code2vec [1]tocomputethesimilaritybetweensoftwareentities,
whichimproves the performance offeature envy detection.
Cuietal.[ 9]proposedanapproachtorecommendmovemethod
refactoring opportunities named RMoveby exploiting structuralandsemanticrepresentationsofcodesnippets.Theyinvestigated
the performance of various code embedding and graph embedding
techniquesanddiï¬€erentmachine/deeplearningclassi/f_iersinrecom-
mendingmovemethodrefactorings.Sharmaetal.[ 58]conducted
anempiricalstudyondeeplearning-baseddetectionofcodesmells.
They found that CNN, RNN, and Autoencoder have been widely
usedinthis/f_ield,andthuscomparedtheperformanceofthesedeep
learningtechniques indetecting feature envy smells.
Theproposedapproachdiï¬€ersfromsuchapproachesintroduced
in the preceding paragraphs in that it automatically collects large-
scalereal-worldexamplesastrainingdatatoboostthedetectionand
resolution of feature envy smells. Besides that, it also exploits new
features,i.e., CBMCandMCMC,thathavenotyetbeenexploited
byexisting approaches.
2.4 DiscoveringAppliedSoftwareRefactorings
Automateddiscoveryofsoftwarerefactoringsistouncoverrefac-
toringsappliedbydevelopersinreal-worldprojects.Thebene/f_its
of discovering such refactorings are twofold. First, it facilitates the
understanding of software evolution, i.e., what kind of changes
have been made and the rationale for the changes. Second, the dis-
covered refactorings may serve as a benchmark for the evaluation
of approaches in refactoring recommendations. To this end, Dig et
al.[14]proposedthe/f_irstapproach(called RefactoringCrawler )
todiscoversoftwarerefactorings.Itexploits Shinglesencoding [7]
to match software entities between two successive versions of
the same project and identi/f_ies moved/deleted/added/modi/f_ied/un-
touchedsoftwareentities.Itthenleveragespre-de/f_inedheuristic
rules to identify refactorings based on the matched software en-
tities. For example, if a method /u1D45Ain the older version matches
method/u1D45Aâ€²inthelaterversionbuttheirenclosingclasses(notedas
classes/u1D434and/u1D435)donotmatch, RefactoringCrawler wouldreport
thatthereisamovemethodrefactoringmovingmethod /u1D45Afromits
enclosingclass /u1D434to class/u1D435.
Prete et al. [ 35,55] proposed a logic programming-based ap-
proach, called Ref-Finder , to discover software refactorings.
Ref-Finder encodes refactoring types into template logic rules
andextractslogicfactsconcerningtwosuccessiveversionsintoa
logic database. A logic programming engine [ 11] is then employed
to identify refactorings by converting the logic rules into logic
queriesandexecutingthequeriesonthelogicdatabase. RefDiff
proposed by Silva et al. [ 59,60] is a similarity-based approach to
discovering software refactorings. It diï¬€ers from other approaches
in that it computes the similarity between software entities (i.e.,
two successive versions) with a variation of the TF-IDF weighting
scheme[57]andaweightedJaccardcoeï¬ƒcient [ 8].
RefactoringMiner , proposed by Tsantalis et al. [ 67,68], is
a state-of-the-art approach to discovering refactorings. The key
to this approach is an AST-based statement matching algorithm
that does not request any user-de/f_ined thresholds. The algo-
rithmaccuratelyandautomaticallymatchessoftwareentitiesbe-
tween two successive versions. Based on the matched entities,
RefactoringMiner exploitspre-de/f_inedrules(similartothoseused
byRefactoringCrawler [14]) to detect refactorings. Their eval-
uation results suggest that RefactoringMiner can signi/f_icantly
improve the state ofthe art inrefactoring detection.
910ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA BoLiu, HuiLiu, Guangjie Li, Nan Niu,Zimao Xu,YifanWang,YunniXia,YuxiaZhang,andYanjieJiang
Figure 1: Overview of theProposed Approach
3 APPROACH
3.1 Overview
AnoverviewoftheproposedapproachispresentedinFig. 1.For
convenience,wecalltheproposedapproach feTruthwhere"fe"
is the abbreviation of " feature envy " and "Truth" suggests that
the approach is boosted by thetruth (i.e., real-worldexamples) and
itcould tellyouthe truthoffeature envy.
feTruthtakes as input the evolution histories of open-source
projectsstoredinversioncontrolsystems(e.g.,GitHub),extracts
real-worldfeatureenvyexamples,andtrainsadeeplearning-based
prediction model with the extracted examples. In the testing phase,
feTruthtakesasinputthesourcecodeofasoftwareprojectand
generatesalistoffeatureenvysmellsassociatedwithmethodsin
theproject,aswellassuggestedrefactoringsolutionstoresolvethe
feature envy smells.The overallprocessof feTruth isas follows:
â€¢feTruthminesfor potentialmovemethod refactorings by apply-
ingRefactoringMiner [67] to the evolution histories of open-
sourceprojects.
â€¢feTruthremovesnon-featureenvyfromthepotentialrefactor-
ings by heuristics-based /f_iltering and learning-based /f_iltering.
The methods moved by the remaining move method refactorings
are taken as positive samples.
â€¢Methodsnotinvolvedinanypotentialmovemethodrefactorings
are taken as negative samples.
â€¢With such positive and negative samples collected in the pre-
ceding steps, feTruthtrains a neural network-based classi/f_ier
to predict whethera given method shouldbe moved to another
class.
â€¢feTruth leverages the trained classi/f_ier as well as a sequence of
heuristic rules to predict whether a given method in the testing
projectisassociatedwith featureenvysmells .Ifyes,feTruthalso
suggestswhichclass themethodshould be movedto.Detailsofthe key steps are presentedin the following sections.
3.2 MiningforMoveMethodRefactorings
Featureenvysmellsareoftenresolvedbymovemethodrefactor-
ings [17]. Consequently, it is practical to discover methods as-
sociated with feature envy smells by mining for move method
refactorings in open-source projects. To this end, we employ
RefactoringMiner [67] todiscover potentialmove method refac-
torings.RefactoringMiner is selected because it is well-known,
widely-used, and representing the state of the art in automated
discovery(mining)ofsoftwarerefactorings.Ittakesasinputtwo
versions (i.e., a commit and its parent in the commit history) of
the same project, compares and matches software entities between
the two versions, and generates a list of potential move method
refactorings (as well as other categories of refactorings that are
ignoredby feTruth) by asequenceof pre-de/f_ineddetection rules.
Although RefactoringMiner representsthestateoftheart,not
alloftheidenti/f_ied movemethodrefactoringsareassociatedwith
feature envy smells, and it also results in some false positives (i.e.,
theactualchangesmadearenotmovemethodrefactorings).Accord-
ingtoourempiricalstudyinSection 4.5,upto43.8%ofthereported
potentialmovemethodrefactoringsarenotassociatedwithfeature
envy smells or are false positives. For convenience, we call such
potentialrefactoringsas non-featureenvy intherestofthispaper.
Toguaranteethequalityofcollectedreal-worldexamples, feTruth
leveragesheuristics-based/f_ilteringandclassi/f_ication-based/f_ilter-
ing to identify and remove such non-feature envy. Details of the
/f_iltering are presentedin Section 3.3and Section 3.4,respectively.
3.3 Heuristics-BasedFiltering
The proposed approach is to identify feature envy methods that
should be moved from their enclosing classes to other classes
911Deep Learning BasedFeature Envy DetectionBoostedby Real-WorldExamples ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
that they envy. Consequently, for a given feature envy method,
it should explicitly have its enclosing class (where it is) and its tar-
get class (where it should be moved) in the same version. However,
RefactoringMiner often reports potential move method refactor-
ingwherethetargetclassofthemovementdoesnotexistintheold
version(i.e., /u1D449/u1D45B)orthesourceclassdoesnotexistinthenewversion
(i.e.,/u1D449/u1D45B+1). A typical example is that when a class is moved to a
diï¬€erent package, RefactoringMiner may report methods within
the class as moved methods where the class in the old version is
noted as the source class and the same class in the new version
is noted as the target class. In this case, the target class does not
exist in the old version. Consequently, it is unlikely for feature
envy detection algorithms (including the proposed approach) to
identify them as feature envy methods because the algorithms can-
notrecommendmovingamethodtoanonexistentclass.Another
typical example is that when a class (noted as /u1D434) is merged into
another class (noted as /u1D435),RefactoringMiner may report that the
methods within /u1D434have been moved to the merged class (i.e., class
/u1D435). In this case, the source class (i.e., class /u1D434)o ft h emove method
refactorings donot exist in thenewversion( /u1D449/u1D45B+1).Such detection
isnotappropriateasfeatureenvyexamplesbecauseitisa merge
classrefactoringor inlineclass refactoring,insteadofasequenceof
movemethodrefactorings.Therefore,thesepotentialmovemethod
refactorings should not be part of the training data because they
are not associatedwithfeature envy smells.
Toexcludesuchpotentitalrefactorings,weexcludeapotential
move methodrefactoring if:
(1)Thesourceclassofthepotentialrefactoringdoesnotexistin
the newversion(we notethis heuristic ruleas /u1D43B1)or
(2)The target class of the potential refactoring does not exist in
the old version(we notethis heuristic ruleas /u1D43B2).
Besides the heuristic /f_iltering rules proposed in the preceding
paragraph,wealsoleverageanotherrule(notedas /u1D43B3)toexclude
testing methods, constructors, overriding methods, and overrid-
den methods: If the method is moved by a potential move method
refactoringisatestingmethod,aconstructor,anoverridingmethod
or an overridden method, the method should not be taken as a fea-
tureenvymethod .Testingmethodsareexcludedbecausethepro-
posed approach is specially designed for production code. Notably,
testingmethodsareoftensubstantiallydiï¬€erentfrommethodsin
productioncode.Atestingmethod,locatedinatestingclass,fre-
quentlycallsmethodsandaccesses/f_ieldsfromtheclass(notedas
ProductClass ) it is testing. As a result, it inherently envies the
ProductClass ,anditmaybemisclassi/f_iedbyfeatureenvydetec-
tion tools as a feature envy method. To this end, the proposed
approach, as well as other existing approaches (e.g., feDeeppro-
posed by Liu et al [ 41]), excludes testing methods. Constructors
are excluded because they cannot be moved atall. Overriding and
overriddenmethodsareexcludedbecausetheycannotbemoved
across inheritance hierarchies, and moving between ancestors and
descendants are often taken as pull up (or push down) method refac-
toringsinsteadof movemethodrefactorings .Pullup(andpushdown)
methodrefactoringsaredesignedtoshare(orconceal)functionality
andinterfacesamongsiblingclasses,insteadofremovingfeature
envy smells. Consequently, the involved methods are often not
associatedwithfeature envy smells.3.4 Learning-BasedFiltering
Besidestheheuristicsintroducedintheprevioussection,wealso
leveragealearning-basedapproachtofurther/f_ilteroutnon-feature
envy. More speci/f_ically, we leverage a decision tree-based classi/f_ier
to distinguish false positives from true positives according to a
sequenceoffeatures ofthe potentialmove methodrefactorings.
A potentialmove methodrefactoring isrepresentedas:
/u1D45D/u1D440/u1D447/u1D45F=</u1D45A,/u1D45Aâ€²,/u1D460/u1D450,/u1D461/u1D450> (1)
where/u1D45Aand/u1D45Aâ€²refer to the method before and after refactoring
whereas/u1D460/u1D450and/u1D461/u1D450represent the source class and the target class of
themovement.Methodscalling /u1D45Aand/u1D45Aâ€²arenotedas /u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45A)
and/u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45Aâ€²),respectively.
Theexploitedfeaturesofapotentialmovemethodrefactoring
are explainedas follows:
(1)/u1D45F/u1D460/u1D450: The ratio of callers to the original method that survived
the movement,i.e.,
/u1D45F/u1D460/u1D450=|/u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45A)âˆ©/u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45Aâ€²)|
|/u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45A)|(2)
Acallertotheoriginalmethod /u1D45Asurvivesthemovementifand
onlyif itcalls /u1D45Aâ€²after themovement.
(2)/u1D45F/u1D460/u1D450â€²: The number of survived callers divided by the number of
callers to /u1D45Aâ€²,i.e.,
/u1D45F/u1D460/u1D450â€²=|/u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45A)âˆ©/u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45Aâ€²)|
|/u1D436/u1D44E/u1D459/u1D459/u1D452/u1D45F(/u1D45Aâ€²)|(3)
(3)/u1D450/u1D460/u1D461:Thenumberofcommonstatements(matchedstatements
according to RefactoringMiner ) appearing in both /u1D45Aand/u1D45Aâ€²,
i.e.,
/u1D450/u1D460/u1D461=|/u1D446/u1D461/u1D44E/u1D461/u1D452/u1D45A/u1D452/u1D45B/u1D461/u1D460 (/u1D45A)âˆ©/u1D446/u1D461/u1D44E/u1D461/u1D452/u1D45A/u1D452/u1D45B/u1D461/u1D460 (/u1D45Aâ€²)| (4)
where/u1D446/u1D461/u1D44E/u1D461/u1D452/u1D45A/u1D452/u1D45B/u1D461/u1D460 (/u1D45A)represents all statementswithin method
/u1D45A.
(4)/u1D45F/u1D450/u1D460/u1D461:Thenumberofcommonstatementsdividedbythetotal
number ofstatements in /u1D45A,i.e.,
/u1D45F/u1D450/u1D460/u1D461=/u1D450/u1D460/u1D461
|/u1D446/u1D461/u1D44E/u1D461/u1D452/u1D45A/u1D452/u1D45B/u1D461/u1D460 (/u1D45A)|(5)
(5)/u1D45F/u1D450/u1D460/u1D461â€²:The numberofcommon statementsdividedbythetotal
number ofstatements in /u1D45Aâ€²,i.e.,
/u1D45F/u1D450/u1D460/u1D461â€²=/u1D450/u1D460/u1D461
|/u1D446/u1D461/u1D44E/u1D461/u1D452/u1D45A/u1D452/u1D45B/u1D461/u1D460 (/u1D45Aâ€²)|(6)
Features /u1D45F/u1D460/u1D450and/u1D45F/u1D460/u1D450â€²concern to what extent /u1D45Aand/u1D45Aâ€²share
the samecallerswhereas features /u1D450/u1D460/u1D461,/u1D45F/u1D450/u1D460/u1D461,and/u1D45F/u1D450/u1D460/u1D461â€²concern the
similarity between the method bodies of /u1D45Aand/u1D45Aâ€². Such outside
features(concerningthecallerstothemethods)andinsidefeatures
(concerningthemethodbodies)togethermayhelpidentifywhether
/u1D45Aâ€²isanevolvedversionof /u1D45A.Notably,mostofthefalsepositives
reported by RefactoringMiner are caused byincorrect matching
between/u1D45Aand/u1D45Aâ€²:/u1D45Aâ€²issomewhatsimilarto /u1D45A(whichresultsin
incorrectmatching),but /u1D45Aâ€²isnotanevolvedversion of/u1D45A,andthus
they donot form amove methodrefactoring.
Withtheextractedfeatures,wetrainadecisiontreetolearnhow
toclassifypotentialrefactoringsintofalsepositivesandtruepos-
itives. It takes </u1D45F/u1D460/u1D450,/u1D45F/u1D460/u1D450â€²,/u1D450/u1D460/u1D461,/u1D45F/u1D450/u1D460/u1D461,/u1D45F/u1D450/u1D460/u1D461â€²>as input, and generates
a binary output that suggests whether the given potential move
methodrefactoringisassociatedwithfeatureenvysmells.Decision
trees [6] are one of the most popular and commonly used machine
912ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA BoLiu, HuiLiu, Guangjie Li, Nan Niu,Zimao Xu,YifanWang,YunniXia,YuxiaZhang,andYanjieJiang
learningtechniques for classi/f_ication [ 63]. Comparedto otherma-
chinelearningtechniques,decisiontreesareintuitive,interpretable,
and adjustable (via manual pruning to optimize classi/f_ication). We
do not employ more powerful deep learning techniques because
theyrequestalargenumberoflabeledtrainingdatathatwedonot
have.In contrast,decision trees work well onsmall datasets.
3.5 Collecting NegativeSamples
Intheprevioussections,wecollectreal-worldsamplesoffeature
envymethodswith RefactoringMiner andasequenceof/f_iltersas
introduced inSections 3.3â€“3.4. In this section, we explain how we
collectnegativesamples,i.e.,methodsnotassociatedwithfeature
envy smells. Such negative examples together with the positive
samplesconstitutethecompletelabeledtrainingdataforfeature
envy detection.
We /f_irst collect all methods in subject projects where positive
samplesarecollected.Fromsuchmethods,weexcludethefollowing
methods:
â€¢Methods that cannot be moved across inheritance hierarchies,
e.g., constructors, overriding methods, and overridden methods;
â€¢Testing methods that are out of the scope of the proposed ap-
proach;
â€¢Methods that violate move method refactoring preconditions
provided by Eclipse JDT [28,29] (e.g., the target class should
not inherit a method having the same signature of the moved
method);
â€¢Methods thathave beenmovedbypotential movemethodrefac-
toringsaccording to the detection results of RefactoringMiner .
The remaining methods are noted as candidate negative samples .
Considering that in most high-quality projects negative samples
are often signi/f_icantly more popular than positive samples (feature
envy methods), we conduct undersampling [ 44] so that the total
numberofnegativeexamplesequalsthenumberofpositivesamples.
To maximize the diversity of the negative examples, we sample no
more than a single method from each class and keep the same
samplerateonallsubjectprojects.
3.6 DetectionandResolutionofFeatureEnvy
First,thefollowingmethodsareautomaticallypredictedasnegative
(i.e.,methodsnotassociatedwithfeatureenvysmells):Construc-
tors, overriding methods, and overridden methods. These methods
are predicted as negative because they cannot be moved across
inheritancehierarchies.Forothermethods,weleverageaneural
network-based classi/f_ier for automated prediction. An overview of
theclassi/f_ierispresentedinFig. 2anditsdetailsarediscussedas
followings.
3.6.1 InputoftheClassifier. Theclassi/f_iertakesasinputamethod
(noted as /u1D45A) and a potential target class (noted as /u1D436/u1D461) to which the
method could be legally moved. It generates a binary prediction
to suggest whether /u1D45Ashould be moved to /u1D436/u1D461. Notably, existing
tools, like Eclipse JDT , can automatically and accurately validate
whether/u1D45Acouldbelegallymovedtotargetclass /u1D436/u1D461.Consequently,
we reuse Eclipse JDT to collect all potential target classes for a
given method /u1D45Aand leverage the classi/f_ier to predict whether /u1D45A
shouldbe movedtoany ofthe potentialtarget classes.
Figure 2: NeuralNetworkBased Classi/f_ier
Theinputoftheclassi/f_ierconsistsofbothtextualfeaturesand
structuralfeatures (code metrics):
/u1D456/u1D45B/u1D45D/u1D462/u1D461=</u1D45B/u1D44E/u1D45A/u1D452/u1D460,/u1D45A/u1D452/u1D461/u1D45F/u1D456/u1D450/u1D460 > (7)
where/u1D45B/u1D44E/u1D45A/u1D452/u1D460consistofthree identi/f_iers:
/u1D45B/u1D44E/u1D45A/u1D452/u1D460=</u1D45B/u1D44E/u1D45A/u1D452(/u1D45A),/u1D45B/u1D44E/u1D45A/u1D452(/u1D436/u1D460),/u1D45B/u1D44E/u1D45A/u1D452(/u1D436/u1D461)> (8)
where/u1D45B/u1D44E/u1D45A/u1D452(/u1D45A),/u1D45B/u1D44E/u1D45A/u1D452(/u1D436/u1D460),/u1D45B/u1D44E/u1D45A/u1D452(/u1D436/u1D461)represent the name of the
method to be tested, the name of its enclosing class, and the name
ofthepotentialtargetclass.Structuralfeatures /u1D45A/u1D452/u1D461/u1D45F/u1D456/u1D450/u1D460consistofa
sequenceofcode metrics:
/u1D45A/u1D452/u1D461/u1D45F/u1D456/u1D450/u1D460=</u1D451/u1D456/u1D460/u1D461(/u1D45A,/u1D436/u1D460),/u1D451/u1D456/u1D460/u1D461(/u1D45A,/u1D436/u1D461),/u1D450/u1D44F/u1D45A/u1D450(/u1D45A,/u1D436/u1D460),
/u1D450/u1D44F/u1D45A/u1D450(/u1D45A,/u1D436/u1D461),/u1D45A/u1D450/u1D45A/u1D450(/u1D45A,/u1D436/u1D460),/u1D45A/u1D450/u1D45A/u1D450(/u1D45A,/u1D436/u1D461)>
where/u1D451/u1D456/u1D460/u1D461(/u1D45A,/u1D436)is theJaccard distance between method /u1D45Aand
class/u1D436[61,66].Let/u1D446/u1D45Abetheentitysetofmethod /u1D45Aand/u1D446/u1D436bethe
entity set of class /u1D436, the distance between /u1D45Aand/u1D436is de/f_ined as
follows:
/u1D451/u1D456/u1D460/u1D461(/u1D45A,/u1D436)=1âˆ’|/u1D446/u1D45Aâˆ©/u1D446/u1D436|
|/u1D446/u1D45Aâˆª/u1D446/u1D436|(9)
Notably,theentitysetofasoftwareentity(e.g.,amethodoraclass)
includesallmethodsand/f_ieldsaccesseddirectlybytheentity.Be-
sidesthedistance(asde/f_inedbyEquation 9)thathasbeenexploited
by existing deep learning-based approaches [ 41,43], our approach
alsoexploits CBMCandMCMC./u1D450/u1D44F/u1D45A/u1D450(/u1D45A,/u1D436)isthenumberofmeth-
odsfromclass /u1D436thatarecalleddirectlyby /u1D45Adividedbythetotal
number ofmethodsdirectlycalledby /u1D45A:
/u1D450/u1D44F/u1D45A/u1D450(/u1D45A,/u1D450)=|methodscalled by /u1D45Aâˆ©methodsof /u1D436|
|methods called by /u1D45A|(10)
/u1D45A/u1D450/u1D45A/u1D450(/u1D45A,/u1D436)isthefrequencyofinvocationsfrommethod /u1D45Atoclass
/u1D436dividedby the totalfrequency of invocations from /u1D45A:
/u1D45A/u1D450/u1D45A/u1D450(/u1D45A,/u1D450)=|method invocations from /u1D45Ato/u1D436|
|method invocations from /u1D45A|(11)
913Deep Learning BasedFeature Envy DetectionBoostedby Real-WorldExamples ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
3.6.2 Architecture of the Classifier. The architecture of the clas-
si/f_ier is presented in Fig. 2. The textual features are /f_irst fed into
an embedding layer to convert them into numerical vectors. We
leverage the well-known and widely-used word2vec [ 47,48]a s
theembeddinglayer,andreusethepubliclyavailablepre-trained
word2vecmodel[ 40].Theoutputsoftheembeddinglayer,together
with other structural features, are fed into convolutional neural
networks(CNN).TheoutputsoftheCNNlayersaretransformed
into one-dimensional vectors by the following /f_latten layers. Such
vectors are merged into a single one-dimensional vector by the
following mergelayer, and theresulting vector isfed into a dense
layer.Theoutputlayergeneratesthebinaryprediction,i.e.,whether
/u1D45Ashouldbe movedfromits enclosing class to the target class /u1D436/u1D461.
3.6.3 Classifier-Based Prediction. For each method to be tested
(notedas/u1D45A),feTruth/f_irstleverages EclipseJDT [28,29]tocollect
potentialtargetclassestowhichthemethodcouldbelegallymoved.
Notably,fromthepotentialtargetclasses,weremovealldataclasses
thatdo not contain anymethods or contain getter/settermethods
and constructors only (we note this heuristic rule as /u1D43B4). Such
classes are specially designed to store data (variables) only, and
movingmethodstosuchclassesmaybreaktheprinciple.Besides,if
/u1D45Aisan instance method (i.e., anon-static method) and its atarget
classiscomposedofonlystaticmembers,weremovethisclassfrom
the target classes (we note this heuristic rule as /u1D43B5). Consequently,
we exclude themfrom potentialtarget classes.
Ifamethoddoesnothaveanypotentialtargetclass,themethodis
deemed negative, not associated with feature envy smells (we note
this heuristic rule as /u1D43B6). Otherwise, feTruth leverages the neural
network-based classi/f_ierrepresented in Fig. 2to predictwhether
themethodshouldbemovedtothegivenpotentialtargetclass.The
prediction isoften interpretedas positive(andthe potential target
class is called candidate target class ) if the output is greater than
0.95[34].Otherwise,itisinterpretedas negative.Ifthepredictionis
negativeforallpotentialtargetclasses,themethodisnotassociated
withfeature envy smells.Otherwise,it is afeature envy method.
Formethodspredictedaspositive, feTruthalsosuggestssolu-
tions, i.e., where they should be moved. If method /u1D45Ahas only a
singlecandidatetargetclass, feTruth suggestsmovingthemethod
to this class. If it has multiple candidate target classes, feTruth
suggestsmoving /u1D45Atothecandidate target classthatresultsinthe
largestoutputofthe classi/f_ier.
4 EVALUATION
4.1 Research Questions
The evaluation was designed to answer the following research
questions:
RQ1.CanfeTruth improve the state of the art in feature envy
detection?
RQ2.Arethe/f_iltersproposedinSections 3.3â€“3.4accurateinexclud-
ing non-feature envy in potential move method refactorings
reportedby RefactoringMiner ?
RQ3.Towhatextentcandata/f_ilteringimprovetheperformance
offeTruth?
RQ4.To what extent can real-world examples outperform ran-
domlygeneratedtraining data inboosting feTruth?Table 1:Subject Projects(Part2)
Projects Snapshot NOC NOM LOC
Jsoup 9b40b7b 90 1,317 9,763
Csv 989c495 15 158 2,125
Compress 231a466 81 664 8,534
Cli 7d1363e 41 343 4,460
Time b9a83fb 317 9,290 79,036
RQ5.Howdoesthesizeoftrainingdatain/f_luencetheperformance
offeTruth?
Research question RQ1 concerns whether feTruth can substan-
tiallyoutperformexisting approachesinfeatureenvydetection.To
answerthisquestion,wecompare feTruthagainsttheapproach
proposed by Liu et al. [ 41],JDeodorant [17] andJMove[64]. Since
Liu et al. [ 41] did not explicitly name their approach, we call it
feDeepfor convenience in the rest of this paper. Such baseline
approaches are selected for comparison because they represent the
state of the art. Research question RQ2 concerns the accuracy of
the /f_ilteringintroduced inSections 3.3â€“3.4whereas RQ3concerns
its in/f_luence on the performance of the proposed approach. RQ4
concerns the bene/f_its of replacing randomly generated training
datawithreal-worldexampleswhereasRQ5concernstheimpact
ofthe size ofthe training data.
4.2 Subject Projects
Thesubjectprojectsaredividedintotwoparts.The/f_irstpart(noted
asPart1), consisting of 500 Java projects, was used to discover
real-worldfeature envyexamples (i.e.,collection of trainingdata).
The second part (noted as Part2), consisting of 5 open-source Java
projects,wasusedtoevaluatetheproposedapproachandthese-
lectedbaselineapproaches. The 500 projects inthe/f_irstpart were
selectedfromGitHub:Weselectedthetop500mostpopularJava
projects(withthelargestnumbersofstars)toconstitutethe/f_irst
part of the subject projects. The 5 projects in the second part were
selected from Defects4J [ 31]. These projects were selected because
theyare fromdiï¬€erentdomainsandaredeveloped/maintainedby
diï¬€erent teams, which may help to reduce the potential bias in
the evaluation. Besides, all of them are well-known and widely-
usedopen-sourceprojects.Table 1presentsanoverviewofthe5
Javaprojectsinthesecondpartwherethe snapshot speci/f_iesthe
version of the selected projects, NOCandNOMrepresent the num-
ber of classes and the number of methods within the projects. LOC
represents the number of sourcecode lines.
4.3 Process
First, we applied RefactoringMiner to the 500 selected subject
projects (in Part1),anditreported30,599potential movemethod
refactorings.Fromthem,werandomlysampled600potentialmove
methodrefactorings,andrequestedthreeexperienceddevelopers
whowerefamiliarwithmovemethodrefactoringsandfeatureenvy
smellstoindependentlyandmanuallymarkedthemastrueposi-
tives(i.e.,movemethodrefactoringsassociatedwithfeatureenvy
smells)ornon-featureenvy.Alloftheparticipantswererequired
914ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA BoLiu, HuiLiu, Guangjie Li, Nan Niu,Zimao Xu,YifanWang,YunniXia,YuxiaZhang,andYanjieJiang
Table 2:Improving theState oftheArt
Approach Project #Reported #Accepted #Acceptedtargets Precision Accuracy(destination)
feTruthJsoup 16 12 11 75% 91.67%
Csv 3 2 2 66.67% 100%
Compress 13 8 7 61.54% 87.5%
Cli 1 1 1 100% 100%
Time 8 6 6 75% 100%
Total 41 29 27 70.73% 93.1%
feDeepJsoup 19 10 8 52.63% 80%
Csv 0 0 0 0% 0%
Compress 14 7 6 50% 85.71%
Cli 1 1 1 100% 100%
Time 13 6 6 46.15% 100%
Total 47 24 21 51.06% 87.5%
JDeodorantJsoup 14 5 5 35.71% 100%
Csv 1 1 1 100% 100%
Compress 4 2 1 50% 50%
Cli 1 1 1 100% 100%
Time 3 1 0 33.33% 0%
Total 23 10 8 43.48% 80%
JMoveJsoup 5 2 2 40% 100%
Csv 0 0 0 0% 0%
Compress 1 1 1 100% 100%
Cli 2 1 1 50% 100%
Time 2 0 0 0% 0%
Total 10 4 4 40% 100%
to have Java background. They had a median of 6 years of pro-
grammingexperienceand3.5yearsexperiencewithsoftwarerefac-
toring.Incaseofinconsistentlabeling,thepotentialrefactorings
were discussed together by the participants to reach an agreement,
which resulted in 600 consistently labeled samples. Notably, the
three developers achieved high consistency with a Fleissâ€™ kappa
coeï¬ƒcient[ 16]of0.81.Thesizeofthesample(600)guaranteeda
con/f_idencelevelofover95%andamargin oferrorof5% [ 30].
Second,wetrainedthedecisiontree-based/f_ilter(aspresented
inSection 3.4)withthe600manuallylabeledsamples.Afterthat,
we leveraged the resulting decision tree-based /f_ilter and heuristics-
based /f_ilter (as presented in Section 3.3) to identify all positive
examplesreportedby RefactoringMiner ,whichresultedin14,209
real-worldfeatureenvymethods.Wealsocollected14,209negative
examplesasintroducedinSection 3.5tomakeupabalancedtraining
dataset(called rw-Dataset ).
Third, we trained the proposed approach ( feTruth) with the
training data collected in the preceding paragraph. We trained the
baseline approach ( feDeep) with equally sized training data (called
rg-Dataset ), where positive examples were randomly generated by
feDeep[41]onthesamesubjectprojects,andnegativeexamples
were consistent with those in rw-Dataset . After that, we applied
the resulting models and other selected baseline approaches, i.e.,
JDeodorant [17]andJMove[64]tothe/f_iveprojectsin Part2and
requested three experienced developers to independently and man-
ually validate all of the reported feature envy smells. To reducethethreatstovalidity,theparticipantsdidnotknowwhichofthe
featureenvysmellswerereportedbytheproposedapproachorthe
baseline approaches. In case of inconsistency, they were requested
to discuss together, and they reached an agreement on all items.
Based on the manual validation, we computed the performance of
the evaluatedapproaches.
4.4 RQ1: ImprovingtheState oftheArt
The evaluation results are presented in Table 2.#Reported
presents the total number of potential feature envy smells re-
portedbytheevaluatedapproacheswhereas #Accepted presents
how many of them were con/f_irmed according to the given
ground truth. #Accepted targets presents how many of the
target classes recommended by the approaches were con/f_irmed.
Precision presents the precision in smell detection. Accuracy
(destination) presents the accuracy of the approaches in recom-
mendingtargetclassesfor the con/f_irmedfeature envy methods.
From Table 2we make the following observations:
â€¢feTruhwasaccurateindetectingfeatureenvysmells.Amongthe
41items reportedby feTruh, 29 have been manuallycon/f_irmed,
resulting in a precision of 70.73%. feTruhwas also accurate in
suggestingtargetclassesforfeatureenvymethods.For29feature
envy methods,it succeededin recommendingtarget classes for
27 ofthem,resultinginaprecision of 93.1%.
â€¢feTruhsubstantially outperformed the state of the art in fea-
ture envy detection. It resulted in the highest precision (70.73%),
915Deep Learning BasedFeature Envy DetectionBoostedby Real-WorldExamples ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
1private void populateProviderWithExtraProps (PoolingConnectionProvidercp,
Properties props) throwsException {
2 Properties copyProps= newProperties();
3 copyProps.putAll(props);
4 ...
5 if(cpinstanceof C3p0PoolingConnectionProvider){
6 copyProps.remove(C3p0PoolingConnectionProvider.
DB_MAX_CACHED_STATEMENTS_PER_CONNECTION );
7 copyProps.remove(C3p0PoolingConnectionProvider.
DB_VALIDATE_ON_CHECKOUT );
8 copyProps.remove(C3p0PoolingConnectionProvider.
DB_IDLE_VALIDATION_SECONDS );
9 copyProps.remove(C3p0PoolingConnectionProvider.
DB_DISCARD_IDLE_CONNECTIONS_SECONDS );
10 }
11 setBeanProps(cp.getDataSource(), copyProps);
12}
Listing1:Example FalsePositive Reported by feDeep
substantiallyhigherthanthatof feDeep(51.06%), JDeodorant
(43.48%), and JMove(40%). The minimal improvement is 38.5%
(70.73%-51.06%)/51.06%. feTruhalso led to the largest number
(29) of accepted items (i.e., true positives), substantially larger
thanthatof feDeep(24),JDeodorant (10)andJMove(4).
â€¢Theproposedapproach feTruhisaccurateinsuggestingdesti-
nationclassesforfeatureenvymethods.Itsaccuracy(93.1%)is
higher than that of JDeodorant (80%), and comparable to that
offeDeep(87.5%)and JMove(100%).
Note that all of the evaluated approaches were evaluated on
thesamedataset,andthustheyshouldhavethesamenumberof
positives (i.e., the total number of feature envy smells). As a result,
the improvement in the number of accepted items (#true positives)
equals the improvement in recall because recall=#true positives Ã·
#positives. Consequently, compared to feDeep,JDeodorant , and
JMove,feTruhimprovedthe recallby 20.8%=(29-24)/24, 190%=(29-
10)/10,and625%=(29-4)/4,respectively.
We conclude based on the preceding analysis that feTruth sub-
stantiallyimprovedthestateoftheartindetectingandresolving
feature envy smells. In the following paragraphs, we explain with
exampleswhy feTruthcan outperformbaselineapproaches.
The example code in Listing 1explains why feTruhsuc-
ceeded in avoiding some false positives reported by feDeep. The
methodpopulateProviderWithExtraProps is from the class Std-
SchedulerFactory in open-source project quartz[12].feDeepre-
ported it as a feature envy method because it accesses four
/f_ields ofclass C3p0PoolingConnectionProvider (Lines6-9),andthus
it suggested moving it to class C3p0PoolingConnectionProvider .
However, original developers refused to move the method.
The relationship between class StdSchedulerFactory and class
C3p0PoolingConnectionProvider followsthewidely-used factory
pattern [24]wherethe factory isresponsibleforcreatingobjects
whereasproviders areresponsibleforprovidingrequesteddata.
The involved method populateProviderWithExtraProps initializes
/f_ields of the created object with data from providers (including the
target class C3p0PoolingConnectionProvider and other providers).
Consequently, the current decision well follows the widely-used
factory pattern and there is no need to move the method. Be-
sides,thetargetclass C3p0PoolingConnectionProvider isdesigned
to provide static /f_ields only, and it should not contain complex
operations onsuch /f_ields.1booleanisEndOfFile (intc){
2 returnc==ExtendedBuï¬€eredReader. END_OF_STREAM ;
3}
4
5classExtendedBuï¬€eredReader extendsBuï¬€eredReader{
6 static/f_inal int END_OF_STREAM =âˆ’1;
7 ...
Listing2:Example True Positive Missed by Baseline
)23 456)%	
Pii266 43%	
Ngi
Hii  
Fili g
L i g  
Fili g
)23 4)6%	 
Pii54 2"%	
Ngi
2)2 42##%	
Ngi2) 4)))%	
Pii)4""%	
Ngi)#24$5%	 
Pii34 25%	
Ngi
Figure 3: Filtering ofPotential Move Method Refactorings
Ourapproach feTruthdidnotreportthemethodinListing 1asa
featureenvysmellbecauseitstrainingdatadidnotcontainanyreal-
worldfeatureenvymethodsthatshouldbemovedfromafactory
class("*Factory ")toaproviderclass(" *Provider ").Itmaysuggest
thatmethodsarerarelymisplaced(bydevelopers)betweenfactories
and providers. However, the training data automatically generated
byfeDeepdid contain four arti/f_icial â€˜feature envy methodsâ€™ that
should be moved from factories to providers. Such unreal training
dataresultedin incorrect prediction onthe methodin Listing 1.
The example code in Listing 2explains why feTruth succeeded
in identifying some true positives missed by the baseline ap-
proaches.Themethod isEndOfFile isfromtheclass Lexerinopen-
source project commons-csv [26].feTruth reported the method in
Listing2asafeatureenvysmellbecauseitstrainingdatacontained
common patterns, i.e., a boolean method (" isEndOf* ") was moved
totheclasstowhichthe/f_ieldaccessedinitsconditionalexpression
belongs [ 65]. However, the training date generated randomly by
feDeepdid not contain such patterns. Notably, the heuristic-based
baseline approaches also missed the method presented in Listing 2.
4.5 RQ2: Accurate FilteringofMoveMethods
To answer RQ2, we randomly sampled and validated 379 (out of
29,999) items that have been fed into the /f_ilters. The size of the
sample guaranteed a con/f_idence level of 95% and a margin of error
of 5% [30]. The manual checking was conducted by three experi-
enced developers in the same way as they labeled training data (as
introducedinthe/f_irstparagraphofSection 4.3).Theyachievedhigh
consistency with a Fleissâ€™ kappa coeï¬ƒcient [ 16] of 0.87. Notably,
whilelabelingtheitems,theparticipantsdidnotknowtherationale
ofthe/f_iltersortheresultsofthe/f_ilters,whichmighthelptoreduce
potential bias. The manually created labels served as the ground
truthforthe evaluation of the accuracyof the /f_ilters.
The evaluation process and evaluation results are plotted in
Fig.3where negative samples are those that were reported by
RefactoringMiner as potential move method refactorings but
weredeniedmanuallybytheparticipants.Suchnegativesamples
916ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA BoLiu, HuiLiu, Guangjie Li, Nan Niu,Zimao Xu,YifanWang,YunniXia,YuxiaZhang,andYanjieJiang
Table3:Performanceof feTruth with/withoutDataFiltering
MetricsWithout
FilteringWith
Filtering
#Reported 52 41
#Accepted 28 29
#Acceptedtargets 26 27
Precision 53.85% 70.73%
Accuracy(destination) 92.86% 93.1%
should be identi/f_ied and /f_iltered out by the proposed /f_ilters. In
contrast, the positive samples are those that were reported by
RefactoringMiner as potential move method refactorings and
were con/f_irmed manually by the participants. Ideally, all of the
positive samples should pass the /f_ilters.
From Fig. 3we make the following observations:
â€¢First, a large percentage of the potential move method refac-
torings reported by RefactoringMiner was not associated
with feature envy smells. The negative items account for
43.8%=166/(166+213)ofthe reportedsamples.
â€¢Second,theheuristics-based/f_ilterwaseï¬€ectiveandaccurate.It
successfully identi/f_ied 121 out of the 213 negative items whereas
none ofthe 166positive items were /f_ilteredoutbymistake.
â€¢Third,thedecisiontree-based/f_ilterwasaccurateaswell.It/f_iltered
out 42 out of the 45 negative items fed into the /f_ilter whereas
only 12 outofthe 213positive items were misclassi/f_ied.
â€¢Finally,thetwo/f_ilterstogether/f_ilteredout98.2%=(121+42)/166
of the negative samples whereas only 5.6%=(0+12)/213 of the
positive exampleswere /f_ilteredoutbymistake.
Based on the preceding analysis, we conclude that the /f_ilters
proposedinthispaperhavethepotentialto/f_ilteroutmostofthe
negative samples accurately without signi/f_icant loss in positive
samples.Consequently,with RefactoringMiner andsuch/f_ilters,
it is practical to construct a large-scale and high-quality dataset
of feature envy smells, which in turn may boost learning-based
approachesto detecting andresolvingfeature envy smells.
4.6 RQ3: ImpactofExample Filtering
To evaluate the eï¬€ect of example /f_iltering, we disabled the /f_iltering
and repeated the evaluation (keeping the testing data unchanged).
The evaluation results are presentedin Table 3.
From Table 3we make the following observations:
â€¢The /f_iltering had a substantial and positive impact on the per-
formance in detecting feature envy smells. Enabling it improved
theprecisionby31.3%=(70.73%-53.85%)/53.85%.Thenumberof
true positives (#Accepted) alsoincreasedslightly from 28 to 29.
â€¢The /f_iltering substantially reduced the number of false positives
(i.e.,#Reported-#Accepted)from24=52-28to12=41-29,witha
substantialreduction of100%=(24-12)/24.
â€¢The /f_iltering also had a positive impact on the accuracy of the
approach in suggesting destinations for feature envy methods.
The accuracywasslightlyimprovedfrom 92.86%to 93.1%.
Weconcludefromtheprecedinganalysisthatsimplyemploying
the refactoring histories from refactoring miners without essentialTable 4:Eï¬€ect ofReal-World Examples
MetricsRandomly
Generated DataReal-World
Examples
#Reported 49 41
#Accepted 25 29
#Acceptedtargets 22 27
Precision 51.02% 70.73%
Accuracy(destination) 88% 93.1%
/f_ilteringmayresultinasubstantialreductionintheperformance
of feature envy detection. This reduction stems primarily from the
failureto/f_ilteroutmovemethodrefactoringsthatarenotassociated
withfeatureenvysmellsandarefalsepositives.Consequently,it
becomes evident that the un/f_iltered move method refactorings not
only introduce noise into the training dataset but also hamper
themodelâ€™sabilitytogeneralizeaccurately,therebyreducingthe
performance offeature envy detection.
4.7 RQ4: Eï¬€ect ofReal-WorldExamples
Toinvestigatetheeï¬€ectofreal-worldexamples,wereplacedsuch
exampleswithrandomlygeneratedtrainingdata(i.e., rg-Dataset )
andrepeatedtheevaluation.Notably,incontrasttoansweringRQ1,
we employ the same neural network architecture (i.e., feTruth)
for this evaluation. Testing data were kept untouched as well. The
evaluationresultsarepresentedinTable 4.Fromthistablewemake
the followingobservations:
â€¢Exploitingreal-worldexamplessubstantiallyimprovedthepreci-
sion of the proposed approach. The improvement in precision is
38.6%=(70.73%-51.02%)/51.02%.
â€¢Exploitingreal-world examplesimp rovedthe numberoftruepos-
itives(#Accepted) from25to 29, witha substantial improvement
of16%=(29-25)/25.
â€¢Replacing random examples with real-w orld examples improved
the performance in the recommendation of target classes. The
accuracywasimprovedfrom 88%to 93.1%.
Weconcludethatreal-worldexamplesaremoreeï¬€ectivethan
randomly generated training data. This conclusion arises from the
observation that applying modelstrainedonrandomlygenerated
data to real-world examples results in a substantial reduction in
performance.Thereductioncanbeattributedtothefactthatran-
domly generated data often do not align with real-world examples.
Consequently, when these models, trained on such randomly gen-
erateddata,aretestedonreal-worldexamples,theytendtoidentify
fewerinstancesoffeatureenvymethodsandtheirsuggestedtarget
classesare less accurate.
4.8 RQ5: ImpactofData Size
Fig.4presents how the size of the training data in/f_luences the
performance of the proposed approach. From this /f_igure we make
the followingobservations:
â€¢The precision of the approach in both detecting feature envy
smells and recommending solutions (target classes) keeps in-
creasingwiththeincreaseintrainingdata.Itmaysuggestthat
917Deep Learning BasedFeature Envy DetectionBoostedby Real-WorldExamples ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
40557085100
10% 30% 50% 70% 90% Precsion  Accuracy (destination)
1015202530
10% 30% 50% 70% 90% #Accepted  #Accepted targets
Figure 4: Performanceof feTruth vs.SizeofTrainingData
theperformanceoftheproposedapproachhasthepotentialto
be further improvedwithadditionaltraining data infuture.
â€¢Thenumberofcon/f_irmedfeatureenvysmellsandthenumber
of accepted target classes keeps increasing when the data size
increases. However, when the size reaches 80% of the current
size,therateofincreaseinthe numberbecomes relativelyslow.
Based on the analysis we conclude that collecting additional
training data may further improve the proposed approach. This
conclusionalignswiththeunderlyingprinciplethatasthetraining
data expands, the modelâ€™s performance progressively improves.
Thisphenomenonunderscoresthefundamentalnatureofneural
networks,whichrelyonlargeamountsofdataforeï¬€ectivetraining.
4.9 Threatsto Validity
The /f_irst threat to external validity is that only a limited number
ofsubjectprojectswereusedfortheevaluation.Only500subject
projects were used for the mining of refactorings, and only /f_ive
projectswereusedfortesting.Notethatmanualvalidationofthe
detection results was tedious and time-consuming, which signif-
icantly limited the size of the testing data. To reduce the threat,
we collected projects from diï¬€erent domains and diï¬€erent devel-
opment teams. We also publish the implementation [ 38] of the
proposed approach to facilitate further validation on additional
subjectprojects.
The second threat to external validity is that the evaluation
is con/f_ined to Java projects only. It is unclear how the proposed
approach works on other programming languages although the
proposedapproachisexpectedtoworkwithanyobject-oriented
programming languages because it does not depend on any special
characteristicsofJava.The evaluationis con/f_inedtoJavabecause
1) the prototype implementations of the proposed approach and
the baseline approach feDeepare con/f_ined to Java projects only,
and2)RefactroingMineriscon/f_inedtoJava projects.
Athreattoconstructvalidityisthatthemanuallabelingofpo-
tentialmovemethodrefactorings,themanualcheckingofreported
featureenvysmells,andthemanualcheckingofsuggestedtarget
classescouldbeinaccurate.Itmightinturnresultininaccuratecal-
culationoftheperformanceoftheevaluatedapproaches.Toreduce
thethreat,werequestedmultipleparticipantstolabel(check)the
same items and computed the consistency among the participants.
Theresultingkappacoeï¬ƒcientssuggestthattheyresultedinahigh
levelofconsistency.Besides,wedidnottellthemtherationaleof
theproposedapproach,andtheydidnotknowwhichapproaches
had reported the potential smells or suggested the target classes.
Allofthesemighthelpreduce the bias.5 CONCLUSIONSAND FUTUREWORK
Detection and resolution of feature envy smells have been well-
studied, and dozens of such approaches have been proposed. Al-
though deep learning techniques have been proven useful in au-
tomateddetectionandresolutionoffeatureenvysmells[ 41],the
qualityoftherandomlygeneratedtrainingdataispreventingthem
from reaching the maximal potential. To this end, in this paper, we
boost deep learning-based feature envy detection approaches with
real-world examples. We propose a heuristics-based /f_ilter and a
learning-based /f_ilter to exclude false positives reported by refactor-
ingminers,andmanagetogeneratehigh-qualityandlarge-scale
training data for feature envy detection. We design a new deep
learning-based classi/f_ier leveraging new features not yet exploited
by existingapproaches, and employ the resulting classi/f_ier as well
as asequenceofheuristics rulesto detectfeature envy smellsand
to generate solutions for detected smells. Our evaluation results
onreal-worldopen-sourceprojectssuggestthattheproposedap-
proachsubstantiallyoutperformsthestateoftheartinthedetection
and resolution of feature envy smells, improving the precision and
recallinfeature envy detection by38.5% and20.8%, respectively.
Similar to the state-of-the-art feature envy smell detection tools
(e.g.,feDeep,JDeodorant ,andJMove),feTruthonlydetectsmis-
placed methods that should be moved from their enclosing classes
tootherclassestheyenvy.Althoughsuchfeatureenvymethodsare
thekeyconcernforcurrentfeatureenvydetectionandresolution
tools/algorithms, there is another category of feature envy: Only a
small part of the method should be extracted and moved outside
theenclosingclass.Weplantogeneralizetheproposedapproach
to dealwithsuch feature envy smellsinfuture.
feTruthwassponsoredbyHuawei,oneoftheleadingITcom-
panies in the world, and it has been successfully deployed in the
company.Notably,weadoptaclient-serverarchitecture,putting
all deep-learning related modelson aserver(deployedwithin the
company)andintegratingothermodelsintoaplug-inoftheIDE,
to avoid any deep learning computation on client sides (i.e., PCs of
softwaredevelopers).Asaresult,fortheendusers, feTruthisas
simple as the traditional heuristics-based detection tools, and no
deeplearninglibrariesordevices are required.We wouldliketo re-
portdetailedusageofthetoolwithinthecompany(andpotentially
othercompanies)inthe near future.
The large-scalehigh-qualitydatasetofreal-worldfeatureenvy
examples constructed in this paper is an important contribution of
thispaper.Itmayinspireandboostotherlearning-basedapproaches
tofeatureenvydetectioninfuture.Wealsoplaninfuturetofurther
enlarge the dataset by mining additional evolution histories of
high-qualityopen-sourceprojects.
6 DATA AVAILABILITY
Thereplicationpackage,includingthetoolsandthedata,ispublicly
available[ 38,39].
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers from
ESEC/FSEâ€™23fortheirinsightful commentsandconstructive sug-
gestions.ThisworkwaspartiallysupportedbytheNationalNatural
ScienceFoundationofChina (62232003 and62172037).
918ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA BoLiu, HuiLiu, Guangjie Li, Nan Niu,Zimao Xu,YifanWang,YunniXia,YuxiaZhang,andYanjieJiang
REFERENCES
[1]UriAlon,MeitalZilberstein,OmerLevy,andEranYahav.2019. Code2vec:Learn-
ingDistributedRepresentationsofCode. ProceedingsoftheACMonProgramming
Languages 3,POPL(2019), 40:1â€“40:29. https://doi.org/10.1145/3290353
[2]LucasAmorim,EvandroCosta,NunoAntunes,BaldoinoFonseca,andMÃ¡rcio
Ribeiro. 2015. Experience Report: Evaluating the Eï¬€ectiveness of Decision Trees
forDetectingCodeSmells.In Proceedingsofthe26thIEEEInternationalSymposium
on Software Reliability Engineering (ISSRE â€™15) . IEEE, Gaithersbury, MD, USA,
261â€“269. https://doi.org/10.1109/ISSRE.2015.7381819
[3]MuhammadIlyasAzeem,FabioPalomba,LinShi,andQingWang.2019. Machine
Learning Techniques for Code Smell Detection: A Systematic Literature Review
and Meta-Analysis. Information and Software Technology 108 (2019), 115â€“138.
https://doi.org/10.1016/j.infsof.2018.12.009
[4]AntoineBarbez,FoutseKhomh,andYann-GaÃ«lGuÃ©hÃ©neuc.2020. AMachine-
LearningBasedEnsembleMethodforAnti-PatternsDetection. JournalofSystems
and Software 161(2020), 110486. https://doi.org/10.1016/j.jss.2019.110486
[5]GabrieleBavota,RoccoOliveto,MalcomGethers,DenysPoshyvanyk,andAndrea
De Lucia. 2014. Methodbook: Recommending Move Method Refactorings via
Relational Topic Models. IEEE Transactions on Software Engineering 40, 7 (2014),
671â€“694. https://doi.org/10.1109/TSE.2013.60
[6]LeoBreiman.1984. Classi/f_icationandRegressionTrees . Wadsworth,Belmont,CA,
USA.
[7]Andrei Z Broder. 1997. On the Resemblance and Containment of Documents.
InProceedingsofCompression and Complexity ofSEQUENCES (SEQUENCES â€™97) .
IEEE, Salerno, Italy, 21â€“29. https://doi.org/10.1109/SEQUEN.1997.666900
[8]FlavioChierichetti,RaviKumar,SandeepPandey,andSergeiVassilvitskii.2010.
FindingtheJaccardMedian.In Proceedingsofthe21stAnnualACM-SIAMSym-
posium on Discrete Algorithms (SODA â€™10) . SIAM, Austin, TX, USA, 293â€“311.
https://doi.org/10.1137/1.9781611973075.25 .
[9]Di Cui, Siqi Wang, Yong Luo, Xingyu Li, Jie Dai, Lu Wang, and Qingshan Li.
2022. RMove: Recommending Move Method Refactoring Opportunities using
Structural and Semantic Representations of Code. In Proceedings of the 38th IEEE
InternationalConferenceonSoftwareMaintenanceandEvolution(ICSMEâ€™22) .IEEE,
Limassol, Cyprus, 281â€“292. https://doi.org/10.1109/ICSME55016.2022.00033
[10]Marco Dâ€™Ambros, Alberto Bacchelli, and Michele Lanza. 2010. On the Impact
of Design Flaws on Software Defects. In Proceedings of the 10th International
ConferenceonQualitySoftware(QSICâ€™10) .IEEE,Zhangjiajie,China,23â€“31. https:
//doi.org/10.1109/QSIC.2010.58
[11]KrisDeVolder.1998. Type-OrientedLogicMetaProgramming . Ph.D.Dissertation.
Vrije Universiteit Brussel,ProgrammingTechnologyLaboratory.
[12]ChrisDennis.2023. Quartz.https://github.com/quartz-scheduler/quartz/blob/
ï¬€348f62ece41275555b45dba5a4073c910fbeab/quartz-core/src/main/java/org/
quartz/impl/StdSchedulerFactory.java/#L1404 .
[13]Dario Di Nucci, Fabio Palomba, Damian A Tamburri, Alexander Serebrenik,
and Andrea De Lucia. 2018. Detecting Code Smells Using Machine Learning
Techniques:AreWeThereYet?.In Proceedingsofthe25thInternationalConference
onSoftwareAnalysis,EvolutionandReengineering(SANERâ€™18) .IEEE,Campobasso,
Italy, 612â€“621. https://doi.org/10.1109/SANER.2018.8330266
[14]DannyDig,CanComertoglu,DarkoMarinov,andRalphJohnson.2006. Auto-
mated Detection of Refactorings in Evolving Components. In Proceedings of the
20thEuropeanConferenceonObject-OrientedProgramming (ECOOPâ€™06) .Springer,
Nantes, France, 404â€“428. https://doi.org/10.1007/11785477_24
[15]Eduardo Fernandes, Johnatan Oliveira, Gustavo Vale, Thanis Paiva, and Ed-
uardo Figueiredo. 2016. A Review-Based Comparative Study of Bad Smell De-
tectionTools.In Proceedingsofthe20thInternationalConferenceonEvaluation
andAssessmentinSoftwareEngineering (EASEâ€™16) .ACM,Limerick,Ireland,1â€“12.
https://doi.org/10.1145/2915970.2915984
[16]JosephLFleiss.1971. MeasuringNominalScaleAgreementAmongManyRaters.
Psychological Bulletin 76,5 (1971), 378â€“382. https://doi.org/10.1037/h0031619 .
[17]MariosFokaefs,NikolaosTsantalis,andAlexanderChatzigeorgiou.2007.JDeodor-
ant: Identi/f_ication and Removal of Feature Envy Bad Smells. In Proceedings of
the 23rd IEEE International Conference on Software Maintenance (ICSM â€™07) . IEEE,
Paris, France, 519â€“520. https://doi.org/10.1109/ICSM.2007.4362679
[18]FrancescaArcelliFontana,Pietro Braione,andMarcoZanoni.2012. Automatic
DetectionofBadSmellsinCode:AnExperimentalAssessment. JournalofObject
Technology 11,2 (2012), 5:1â€“38. https://doi.org/10.5381/jot.2012.11.2.a5
[19]Francesca Arcelli Fontana, Mika V MÃ¤ntylÃ¤, Marco Zanoni, and Alessandro
Marino. 2016. Comparing and Experimenting Machine Learning Techniques for
CodeSmellDetection. EmpiricalSoftwareEngineering 21,3(2016),1143â€“1191.
https://doi.org/10.1007/s10664-015-9378-4
[20]Francesca Arcelli Fontana, Elia Mariani, Andrea Mornioli, Raul Sormani, and
AlbertoTonello.2011. AnExperienceReportonUsingCodeSmellsDetection
Tools. InProceedings of the 4th IEEE International Conference on Software Testing,
Veri/f_ication and Validation Workshop on Refactoring and Testing Analysis (ICSTW
â€™11). IEEE,Berlin, Germany, 450â€“457. https://doi.org/10.1109/ICSTW.2011.12
[21]FrancescaArcelliFontanaand MarcoZanoni.2017. Code SmellSeverity Clas-
si/f_ication Using Machine Learning Techniques. Knowledge Based Systems 128
(2017), 43â€“58. https://doi.org/10.1016/j.knosys.2017.04.014[22]FrancescaArcelliFontana,MarcoZanoni,AlessandroMarino,andMikaMÃ¤ntylÃ¤.
2013. CodeSmellDetection:TowardsaMachineLearning-BasedApproach.In
Proceedings of the 2013 IEEE International Conference on Software Maintenance
(ICSM â€™13) . IEEE, Eindhoven, Netherlands, 396â€“399. https://doi.org/10.1109/
ICSM.2013.56
[23]MartinFowler.1999. Refactoring:ImprovingtheDesignofExistingCode . Addison-
Wesley, Boston, MA,USA.
[24]ErichGamma,RichardHelm,RalphJohnson,andJohnVlissides.1995. Design
Patterns: Elements of Reusable Object-Oriented Software . Pearson Deutschland
GmbH, Munich, Germany.
[25]AdnaneGhannem,GhizlaneElBoussaidi,andMarouaneKessentini.2016. On
theUseofDesignDefectExamplestoDetectModelRefactoringOpportunities.
SoftwareQualityJournal 24,4(2016),947â€“965. https://doi.org/10.1007/s11219-
015-9271-9
[26]Gary Gregory. 2023. Commons-CSV .https://github.com/apache/commons-
csv/blob/db374369aeeb1f3ace8efcbd7155fcï¬€20354504/src/main/java/org/
apache/commons/csv/Lexer.java#L128 .
[27] MounaHadj-KacemandNadiaBouassida.2019. DeepRepresentationLearning
for Code Smells Detection using Variational Auto-Encoder. In Proceedings of
the 2019 International Joint Conference on Neural Networks (IJCNN â€™19) . IEEE,
Budapest,Hungary, 1â€“8. https://doi.org/10.1109/IJCNN.2019.8851854
[28]Eclipse JDT. 2023. The Preconditions for Move Instance Method Refactorings .
https://github.com/eclipse-jdt/eclipse.jdt.ui/blob/master/org.eclipse.jdt.core.
manipulation/core%20extension/org/eclipse/jdt/internal/corext/refactoring/
structure/MoveInstanceMethodProcessor.java .
[29]Eclipse JDT. 2023. The Preconditions for Move Static Method Refactorings .
https://github.com/eclipse-jdt/eclipse.jdt.ui/blob/master/org.eclipse.jdt.core.
manipulation/core%20extension/org/eclipse/jdt/internal/corext/refactoring/
structure/MoveStaticMembersProcessor.java .
[30]Thomas Junk. 1999. Con/f_idence Level Computation for Combining Searches
withSmallStatistics. NuclearInstrumentsandMethodsinPhysicsResearchSection
A:Accelerators,Spectrometers, DetectorsandAssociatedEquipment 434,2(1999),
435â€“443. https://doi.org/10.1016/S0168-9002(99)00498-2
[31]RenÃ© Just, Darioush Jalali, and Michael D Ernst. 2014. Defects4J: A Database
of Existing Faults to Enable Controlled Testing Studies for Java Programs. In
Proceedings of the 2014 International Symposium on Software Testing and Analysis
(ISSTA â€™14) . ACM, San Jose, CA, USA, 437â€“440. https://doi.org/10.1145/2610384.
2628055
[32]AmandeepKaur,SushmaJain,andShivaniGoel.2017. ASupportVectorMachine
BasedApproachforCodeSmellDetection.In Proceedingsofthe2017International
Conference on Machine Learning and Data Science (MLDS â€™17) . IEEE, Noida, India,
9â€“14.https://doi.org/10.1109/MLDS.2017.8
[33]TaskinKavzoglu.2009. IncreasingtheAccuracyofNeuralNetworkClassi/f_ication
UsingRe/f_inedTrainingData. EnvironmentalModelling&Software 24,7(2009),
850â€“858. https://doi.org/10.1016/j.envsoft.2008.11.012
[34]Keras. 2023. Activation Functions .https://github.com/keras-team/keras/blob/
master/keras/activations.py .
[35]Miryung Kim, Matthew Gee, Alex Loh, and Napol Rachatasumrit. 2010. Ref-
Finder: ARefactoring Reconstruction Tool Basedon Logic Query Templates. In
Proceedingsofthe18thACMSIGSOFTInternationalSymposiumonFoundations
of Software Engineering (FSE â€™10) . ACM, Santa Fe, NM, USA, 371â€“372. https:
//doi.org/10.1145/1882291.1882353
[36]JochenKreimer.2005. AdaptiveDetectionofDesignFlaws. ElectronicNotesin
Theoretical Computer Science 141, 4 (2005), 117â€“136. https://doi.org/10.1016/j.
entcs.2005.02.059
[37]ZarinaKurbatova,IvanVeselov,YaroslavGolubev,andTimofeyBryksin.2020.
RecommendationofMoveMethodRefactoringUsingPath-BasedRepresentation
ofCode.In Proceedingsofthe4thInternationalWorkshoponRefactoring (IWoR
â€™20).ACM,Seoul,SouthKorea,315â€“322. https://doi.org/10.1145/3387940.3392191
[38] Bo Liu.2023. feTruth. https://github.com/lyoubo/feTruth .
[39] Bo Liu.2023. Replication Package. https://doi.org/10.5281/zenodo.8267775 .
[40]Hui Liu, Jiahao Jin, Zhifeng Xu, and Yifan Bu. 2023. Pre-Trained Word2Vec Model .
https://doi.org/10.5281/zenodo.5749111 .
[41]HuiLiu,JiahaoJin,ZhifengXu,YanzhenZou,YifanBu,andLuZhang.2021. Deep
LearningBasedCodeSmellDetection. IEEETransactionsonSoftwareEngineering
47,9 (2021), 1811â€“1837. https://doi.org/10.1109/TSE.2019.2936376
[42]Hui Liu, Yuting Wu, Wenmei Liu, Qiurong Liu, and Chao Li. 2016. Domino
Eï¬€ect: Move More Methods Once a Method is Moved. In Proceedings of the IEEE
23rd International Conference on Software Analysis, Evolution, and Reengineering
(SANERâ€™16) . IEEE,Osaka, Japan,1â€“12. https://doi.org/10.1109/SANER.2016.14
[43]Hui Liu, Zhifeng Xu, and Yanzhen Zou. 2018. Deep Learning Based Feature
Envy Detection. In Proceedings of the 33rd ACM/IEEE International Conference on
AutomatedSoftwareEngineering (ASEâ€™18) .ACM,Montpellier,France,385â€“396.
https://doi.org/10.1145/3238147.3238166
[44]Xu-YingLiu, Jianxin Wu,and Zhi Hua Zhou. 2009. Exploratory Undersampling
forClass-ImbalanceLearning. IEEETransactionsonSystems,Man,andCybernetics,
PartB (Cybernetics) 39,2 (2009),539â€“550. https://doi.org/10.1109/TSMCB.2008.
2007853
919Deep Learning BasedFeature Envy DetectionBoostedby Real-WorldExamples ESEC/FSE â€™23, December3â€“9, 2023,San Francisco, CA, USA
[45]Bafandeh Bahareh Mayvan, Abbas Rasoolzadegan, and Javan Abbas Jafari.
2020. Bad Smell Detection Using Quality Metrics and Refactoring Opportu-
nities.Journal of Software: Evolution and Process 32, 8 (2020), e2255. https:
//doi.org/10.1002/smr.2255
[46]Tom Mens and Tom TourwÃ©. 2004. A Survey of Software Refactoring. IEEE
Transactions on Software Engineering 30, 2(2004), 126â€“139. https://doi.org/10.
1109/TSE.2004.1265817
[47]Tomas Mikolov, Kai Chen, Greg Corrado, and Jeï¬€rey Dean. 2013. Eï¬ƒcient
Estimation of Word Representations in Vector Space. In Proceedings of the 1st
InternationalConferenceonLearningRepresentations (ICLRâ€™13) .Scottsdale,AZ,
USA, 1â€“12. https://doi.org/10.48550/arXiv.1301.3781
[48]TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeï¬€Dean.2013.
DistributedRepresentationsofWordsandPhrasesandTheirCompositionality.
InProceedings of the 27th Annual Conference on Neural Information Processing
Systems (NIPS â€™13) . Curran Associates,Inc.,LakeTahoe, NV, USA,3111â€“3119.
[49]Haris Mumtaz, Mohammad Alshayeb, Sajjad Mahmood, and Mahmood Niazi.
2018. AnEmpiricalStudytoImproveSoftwareSecurityThroughtheApplication
of Code Refactoring. Information and Software Technology 96 (2018), 112â€“125.
https://doi.org/10.1016/j.infsof.2017.11.010
[50]FabioPalomba, GabrieleBavota,Massimiliano DiPenta,RoccoOliveto, Andrea
DeLucia,andDenysPoshyvanyk.2013. DetectingBadSmellsinSourceCode
UsingChangeHistoryInformation.In Proceedingsofthe28thIEEE/ACMInter-
nationalConferenceonAutomatedSoftwareEngineering (ASEâ€™13) .IEEE,Silicon
Valley, CA, USA,268â€“278. https://doi.org/10.1109/ASE.2013.6693086
[51]FabioPalomba,GabrieleBavota,MassimilianoDiPenta,RoccoOliveto,Denys
Poshyvanyk,andAndreaDeLucia.2015. MiningVersionHistoriesforDetecting
Code Smells. IEEE Transactions on Software Engineering 41, 5 (2015), 462â€“489.
https://doi.org/10.1109/TSE.2014.2372760
[52]Fabio Palomba, Annibale Panichella, Andrea De Lucia, Rocco Oliveto, and Andy
Zaidman.2016. ATextual-BasedTechniqueforSmellDetection.In Proceedings
ofthe24thIEEEInternationalConferenceonProgramComprehension(ICPCâ€™16) .
IEEE, Austin,TX, USA,1â€“10. https://doi.org/10.1109/ICPC.2016.7503704
[53]Fabiano Pecorelli, Fabio Palomba, Dario Di Nucci, and Andrea De Lucia. 2019.
Comparing Heuristic and Machine Learning Approaches for Metric-Based Code
SmellDetection.In Proceedingsofthe27thInternationalConferenceonProgram
Comprehension (ICPC â€™19) . IEEE, Montreal, QC, Canada, 93â€“104. https://doi.org/
10.1109/ICPC.2019.00023
[54]Hao Peng, Lili Mou, Ge Li, Yuxuan Liu, Lu Zhang, and Zhi Jin. 2015. Building
Program Vector Representations for Deep Learning. In Proceedings of the 8th
International Conference on Knowledge Science, Engineering and Management
(KSEM â€™15) . Springer, Chongqing, China, 547â€“553. https://doi.org/10.1007/978-3-
319-25159-2_49
[55]KylePrete,NapolRachatasumrit,NikitaSudan,andMiryungKim.2010.Template-
BasedReconstructionofComplexRefactorings.In Proceedingsofthe26thIEEE
InternationalConferenceonSoftwareMaintenance (ICSMâ€™10) .IEEE,Timisoara,
Romania, 1â€“10. https://doi.org/10.1109/ICSM.2010.5609577
[56]Vitor Sales, Ricardo Terra, Luis Fernando Miranda, and Marco Tulio Valente.
2013. Recommending Move Method Refactorings Using Dependency Sets. In
Proceedingsofthe20thWorkingConferenceonReverseEngineering (WCREâ€™13) .
IEEE,Koblenz,Germany,232â€“241. https://doi.org/10.1109/WCRE.2013.6671298
[57]Gerard Salton and Michael J McGill. 1984. Introduction to Modern Information
Retrieval. McGraw-Hill,NewYork, NY, USA.[58]Tushar Sharma, Vasiliki Efstathiou, Panos Louridas, and Diomidis Spinellis. 2021.
CodeSmellDetectionbyDeepDirect-LearningandTransfer-Learning. Journalof
SystemsandSoftware 176(2021),110936. https://doi.org/10.1016/j.jss.2021.110936
[59]Danilo Silva, JoÃ£o Silva, Gustavo Jansen De Souza Santos, Ricardo Terra, and
MarcoTulioOValente.2021.RefDiï¬€2.0:AMulti-LanguageRefactoringDetection
Tool.IEEE Transactions on Software Engineering 47, 12 (2021), 2786â€“2802. https:
//doi.org/10.1109/TSE.2020.2968072
[60]DaniloSilvaandMarcoTulioValente.2017. RefDiï¬€:DetectingRefactoringsin
VersionHistories.In Proceedingsofthe14thInternationalConferenceonMining
SoftwareRepositories (MSRâ€™17) .IEEE,BuenosAires,Argentina,269â€“279. https:
//doi.org/10.1109/MSR.2017.14
[61]FrankSimon,FrankSteinbruckner,andClausLewerentz.2001. MetricsBased
Refactoring. In Proceedings of the 5th European Conference on Software Main-
tenance and Reengineering (CSMR â€™01) . IEEE, Lisbon, Portugal, 30â€“38. https:
//doi.org/10.1109/CSMR.2001.914965
[62]DagIKSjÃ¸berg,BenteAnda,andAudrisMockus.2012. QuestioningSoftware
MaintenanceMetrics:AComparativeCaseStudy.In Proceedingsofthe2012ACM-
IEEEInternationalSymposiumonEmpiricalSoftwareEngineeringandMeasurement
(ESEM â€™12) . ACM, Lund, Sweden, 107â€“110. https://doi.org/10.1145/2372251.
2372269
[63]Yan-Yan Song and Ying Lu. 2015. Decision Tree Methods: Applications for
Classi/f_ication and Prediction. Shanghai Arch Psychiatry 27, 2 (2015), 130â€“135.
http://dx.doi.org/10.11919/j.issn.1002-0829.215044
[64]RicardoTerra,MarcoTulioValente,SergioMiranda,andVitorSales.2018. JMove:
ANovelHeuristicandTooltoDetectMoveMethod RefactoringOpportunities.
JournalofSystemsandSoftware 138(2018),19â€“36. https://doi.org/10.1016/j.jss.
2017.11.073
[65]Martin Thompson. 2023. Aeron.https://github.com/real-logic/
aeron/commit/305c060d424fdea13b1b7f2979d545ac7da5f7a5#diï¬€-
07eb841a7b48861016496075f986f4c6b330e72f8246e3270be31d9305cbd2bcR104 .
[66]Nikolaos Tsantalis and AlexanderChatzigeorgiou. 2009. Identi/f_ication of Move
MethodRefactoringOpportunities. IEEETransactionsonSoftwareEngineering
35,3 (2009), 347â€“367. https://doi.org/10.1109/TSE.2009.1
[67]Nikolaos Tsantalis, Ameya Ketkar, and Danny Dig. 2022. RefactoringMiner
2.0.IEEE Transactions on Software Engineering 48, 3 (2022), 930â€“950. https:
//doi.org/10.1109/TSE.2020.3007722
[68]Nikolaos Tsantalis, Matin Mansouri, Laleh Eshkevari,Davood Mazinanian, and
Danny Dig. 2018. Accurate and Eï¬ƒcient Refactoring Detection in Commit
History.In Proceedingsofthe40thInternationalConferenceonSoftwareEngineering
(ICSEâ€™18) .ACM,Gothenburg,Sweden,483â€“494. https://doi.org/10.1145/3180155.
3180206
[69]Aiko Yamashita and Leon Moonen. 2013. Do Developers Care about Code
Smells?AnExploratorySurvey.In Proceedingsofthe20thWorkingConference
on Reverse Engineering (WCRE â€™13) . IEEE, Koblenz, Germany, 242â€“251. https:
//doi.org/10.1109/WCRE.2013.6671299
[70]NicoZazworka,MicheleAShaw,ForrestShull,andCarolynSeaman.2011. In-
vestigating the Impact of Design Debt on Software Quality. In Proceedings of the
2nd Workshop on Managing Technical Debt (MTD â€™11) . ACM, Honolulu, HI, USA,
17â€“23.https://doi.org/10.1145/1985362.1985366
Received 2023-02-02; accepted 2023-07-27
920