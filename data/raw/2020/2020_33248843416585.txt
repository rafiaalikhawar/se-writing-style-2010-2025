Assessing and Restoring Reproducibility of Jupyter Notebooks
Jiawei Wang
Faculty of Information Technology, Monash University
Melbourne, Australia
Jiawei.wang1@monash.eduTzu-yang KUO∗
Hong Kong University of Science and Technology
Hong Kong, China
tkuo@connect.ust.hk
Li Li†
Faculty of Information Technology, Monash University
Melbourne, Australia
li.li@monash.eduAndreas Zeller
CISPA Helmholtz Center for Information Security
Saarbrücken, Germany
zeller@cispa.saarland
ABSTRACT
Jupyter notebooks—documents thatcontain live code,equations,
visualizations, and narrative text—now are among the most popu-
larmeanstocompute,present,discussanddisseminatescientific
findings. In principle, Jupyter notebooks should easily allow to re-
produce and extend scientific computations and their findings; but
in practice, this is not the case. The individual code cells in Jupyter
notebooks can be executed in any order, with identifier usages pre-
cedingtheirdefinitionsandresultsprecedingtheircomputations.
Inasampleof936publishednotebooksthatwouldbeexecutable
in principle, we found that 73% of them would not be reproducible
withstraightforwardapproaches,requiringhumanstoinfer(and
often guess) the order in which the authors created the cells.
Inthispaper,wepresentanapproachto(1)automaticallysatisfy
dependencies between code cells to reconstruct possible execution
orders of the cells; and (2) instrument code cells to mitigate the
impact of non-reproducible statements(i.e., random functions) in
Jupyter notebooks. Our Osirisprototype takes a notebook as input
and outputs the possible execution schemes that reproduce the
exactnotebookresults.Inoursample,Osiriswasabletoreconstruct
such schemes for 82.23% of all executable notebooks, which has
morethanthreetimesbetterthanthestate-of-the-art;theresulting
reorderedcodeis validprogramcodeand thusavailableforfurther
testing and analysis.
ACM Reference Format:
JiaweiWang,Tzu-yangKUO,LiLi,andAndreasZeller.2020.Assessingand
Restoring Reproducibility of Jupyter Notebooks. In 35th IEEE/ACM Interna-
tionalConferenceonAutomatedSoftwareEngineering(ASE’20),September
21–25,2020,VirtualEvent,Australia. ACM,NewYork,NY,USA,12pages.
https://doi.org/10.1145/3324884.3416585
∗Contributedthe sameasthe firstauthor. Thisworkwas donewhenTzu-yangKUO
was a visiting student at Monash University.
†Corresponding author.
ASE ’20, September 21–25, 2020, Virtual Event, Australia
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6768-4/20/09.
https://doi.org/10.1145/3324884.34165851 INTRODUCTION
Jupyter notebooks—documents thatcontain live code,equations,
visualizations, and narrative text—have become the most widely
used system for interactive literate programming [ 49]. They are
being used to compute, present, discuss and disseminate scientific
findings; and have emerged as the de facto standard for data sci-entists to easily record and understand data analyses [
32,51]. In
September 2018, more than 2.5 million Jupyter repositories were
stored on GitHub—10 times more than in 2015 [33].
One of the promises of Jupyter notebooks is that they should
make scientific findings reproducible —that is, readers should be
able to reconstruct and assess the path from raw source data toabstractions and findings, as presented in the notebook [
18,36].
Unfortunately,thisisrarelythecase.Publishednotebookssufferfrom lack of data, from lack of modules, from lack of metadata
indicatingtoolandlibraryversions,orbadpackaging[ 6].Buteven
if all of this is given, only a small fraction of notebooks can be
faithfully reproduced.
Whyisthatso?AcentralfeatureofJupyternotebooksisthatthe
individual cellstheyaremadeofcanbeexecutedinteractively inany
order.The language interpreter (typically Python) will execute the
code in the cell as soon as a user “runs” it. While Jupyter provides
a “run all cells” feature that runs all cells starting from the topmost
one, authors do not need to ensure that this results in meaningful
execution order. It is not uncommon that notebooks output andpresent a result at the very beginning, followed by the code thatactually produces the result, making the notebook more akin to
anarticlethanaconventionalprogram.Theinteractivenatureof
notebooks makes all of this possible.
Jupyter notebooks assign a monotonically increasing number to
eachcellasitisexecuted;readersmaythusfindthatacellatthetop
may have been executed after a cell further downwar ds. However,
evenwiththisinformation,notebooksarehardtoreproduce.Ina
2019studybyPimenteletal.[ 33],withastraightforwardsetting,
lessthan25%ofvalidnotebooks(withdefinedPythonversionsand
recorded execution order) could be executed without errors; and
less than 5% of them would actually produce the same results.
Givenhowmanyscientificresultsnowarebeingproducedusing
Jupyternotebooks [ 37],it istimefortheprogram analysisandtest-
ingcommunitytomaketheirbestapproachesavailabletonotebook
authors.Butwith75%ofvalidnotebooksnotevenrunningwith-
outerrors,thismeansthatthemajorityofnotebooksareactually
inaccessible for any automated testing and analysis tool.
1382020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)
This work is licensed under a Creative Commons Attribution International 4.0 License.
Inthispaper,wepresentanautomaticapproachtomakeJupyter
notebooks reproducible, and in consequence, available for analysis
and testing. Our approach automatically identifies and satisfies
dependenciesbetweenJupyternotebookcells,reconstructingthe
possibleexecutionordersthatreproducetheexactnotebookresults
withouterrors.Theresultingorderedcodecanthusbesubjectto
testingandanalysis(e.g.,enablingcontinuousregressiontesting
for notebook contributors to ensure the reproducibility of their
notebooks);ourapproachthusformsanecessaryprerequisitefor
furtheranalysisofnotebookcode.Ifagivennotebookcannotbe
reproduced, our Osirisprototype provides detailed debugging mes-
sages explaining (to notebook users) why reproducibility is not
achievable.
Thispaperisorganizedasfollows.Afterdetailingtheproblem
(cf. Section 2), we make the following contributions:
A study on the causes of non-reproducibility. We conduct a
large-scale reproducibility study about Jupyter notebooks
and manually summarise the root causes making notebooks
non-executable and non-reproducible (cf. Section 3).
Making notebooks reproducible again. We design and imple-
ment a prototype tool called Osiris (cf. Section 4), which
combines static analysis and dynamic testing to explore the
possibilitiesofreproducinggivennotebooks.Theresulting
reordered code faithfully reproduces the results in the note-
book;sinceitisvalidprogramcode,itisavailableforfurther
testing and analysis. Since different users may require dif-
ferent amounts of reproducibility (e.g. some users may wish
toreproduce allresultsasstated,othersmayonlywishto
re-run the notebook, possibly with different data), Osiris
supportsanumberof matching andexecution strategiesto
achieve the best result.
Automatic diagnosis for non-reproducible notebooks. Incase
a notebook cannot be reproduced, Osiris features a targeted
debugging module to infer and report failure causes.
Our approach is effective: In our sample, Osiris was able to
reproduce 82.23%of executablenotebooks (cf.Section 5),which is
a large improvement over the 16.7% listed in state of the art [ 33].
After discussing the potential implication and limitations of our
approach (cf. Section 6), we depict related work (cf. Section 7) and
close this paper with conclusion (cf. Section 8).
2 MOTIVATION
Let us start with some background and terminology.
Repository
Notebook1 Notebook2
main.ipynb utils.py cat.jpgimages
Figure 1: The file structure of a simple Jupyter notebookrepository.Jupyter
is used to refer to the Jupyter application, which pro-
vides the computational environment to allow the execution of
notebooks. Notebook (orJupyterNotebook)refersto theliterate
programming document, which contains the actual content (e.g.,
main.ipynbinFigure1)writtenbythe notebookauthors .Similar
totheworkofPimenteletal.[ 33],NotebookandJupyterNotebook
will beinterchangeably used inthis paper. Independent Python
CodewillbeusedtorefertoPythoncodethatisnotdirectlypre-
sented in a notebook but might be accessed by the notebook code.
Forexample,thecodeshownin utils.py(cf.Figure1)isregarded
as independent python code. Notebook Repository refers to the
project where the notebooks are written and managed. A note-
book repository can contain multiple notebooks. For example, therepository shown in Figure 1 contains two Jupyter notebooks (i.e.,
Notebook1 and Notebook2).
Jupyternotebooksaresequencesof cells,essentially CodeCells
andText Cells (cf. Figure 2). Code cells contain executable (Python)
source code to generate results, while text cells contain text that
enables programmers to state rationales behind the code logic; this
textincludesMarkdownandHTMLforrichtext,images,formatting,
and more. These combinations of these two cell types allows for
literateprogramming [19],implementedbyJupyterinan interactive
computationalnotebookenvironment.Thisenvironmentallowsparts
of a notebook to be executed with immediate results, including
formatted texts and visual graphs.
import random
from IPython.display import Imagea=random.randint(5, 50)print (a)In [1]
Image (‘../images/cats.jpg’)10
a += bprint (a)
In [5]110Execution
CounterCode
CellThis is an example of Jupyter notebookMarkdown
Cell
OutputC1
C2
C3
Code
Cell Indexb = 20
a = a + b print (a)
b += 1030
C5C4 In [8]In [7]In [2]
Figure 2: Jupyter notebook example.
Figure2illustratesasimpleexampleofanotebook.Itcontains
one (Markdown) text cell and five (Python) code cells. All the code
cellshavebeenexecutedasindicatedbytheexecutionmark(e.g.,
“In [1]”) shown in front of the code cells. The execution mark tells
139not only the information that the code cell is executed but also
the order when the cell is executed (e.g., “In [5]” shows that thecorresponding code cell is the fifth executed cell). The numberof the execution mark is also known as the execution counter of
thecodecell.Theoutputofacodecell,shownrightunderit,will
always reflect the results of the latest execution (i.e., aligning with
the execution counter).
It should be noted that a code cell can be either non-executed
or executed in a given notebook. For non-executed cells, there will
be no execution counters and outputs. Conversely, for executed
cells,bothexecutioncountersandoutputs(ifany)willbegenerated
forthem.Moreover,thecodecellscanbeexecutedbytheuser in
anyorder andeachofthecellscanbeexecutedmultipletimes,as
longastheexecutioncounterisrespected.Whenskipsofexecutioncountersexistinanotebook,theactualexecutionorderofthenote-bookcellsbecomesnon-trivialtoreproduce(asthecounterrecordsonly the last execution). Subsequently, the skips make it difficult to
automatically reproduce the results of the original notebook.
As an example, consider the notebook shown in Figure 2, in
which three execution counter skips (i.e., 3, 4, and 6) are intro-
duced. The notebook cannot be reproduced by simply followingthe top-down sequence of the code cells as well as the sequenceof execution counters. For both cases
1, the reproducing process
will fail at C4, where the output will be 90 rather than 110.2Conse-
quently,weseethat(1)Reproducingnotebookexecutionscanbe
achallenge;(2)Thereisaneedforapproachesthatsupportusers
inreproducingnotebookresults;and(3)Ifanotebookcannotbe
reproduced automatically, there should be means to support users
to do so manually.
3 REPRODUCIBILITY STUDY
Tounderstandthenatureandextentofthereproducibilityproblem,
wefirstconductedalarge-scalereproducibilitystudy,eventually
guiding the design of our automated approaches.
3.1 Dataset Collection
How many Jupyter Notebooks are non-reproducible, and why?
To answer this question, we apply the approach introduced by
Pimentel et al. [ 33], collecting a dataset of notebooks from Github.
Specifically, wehave randomlycloned 10,000 Gitrepositories that
have a file with “Jupyter Notebook” as identified language andhavePythonasthedeclaredprogramminglanguage.Amongthe
10,000 Git repositories, we further retrieve 10,000 notebooks for
experiments and evaluations.3
Basedonthedataset,wefirstlookatthePythonversionstargeted
by the notebooks. Among the 10,000 notebooks, 93% of notebooks
specifydetailedPythonversionrequirements.Thetop-5targeted
versions are 2.7 (34.3%), 3.6 (31.4$), 3.5 (23.6%), 3.4 (3.4%), 3.7 (0.3%).
The other 7% provide only vague information (such as Python3,
Python [Root] ).
1Let us assume at this point that the output of C1is correct (i.e., the random function
always returns 10).
2The correct execution sequence would be C1,C2,C4,C4,C5,C3,C3,C4.
3Weselectonenotebookfromeachrepositorytoavoidpotentialbias,wherenotebooks
fromthesamerepositorymaysharesimilarproblemsforexecutionorreproducing.
For such repositories that contain multiple notebooks, we simply choose the first one
(by directory ordering) to form the dataset.
0 1 02 03 04 05 0
(a) # of cells
0 50 100 150
(b) Max execution counter
Figure 3: Distribution of the number of cells (left) and themaximumnumberoforiginalexecutioncount(right)intheselected notebooks.
Figure 3 further presents the distribution of the number of cells
andthemaximumexecutioncounteramongtheselectednotebooks.
Themedianandmeannumbersare14and20forthenumberofcells;
and 34 and 74 for the maximum execution counter, respectively.
The fact that half of the notebooks have more than 15 code cells
(executedmorethan35times)showsthattheselectednotebooks
are actually “serious” notebooks suitable for this study.
3.2 Execution Environment Setup
To determine whether a notebook is reproducible, we need an
executionenvironmentforautomatedPythoncodeexecution.4Un-
fortunately,becauseoftheinfamousevolutionofPythonplatforms
(e.g., Python 2 and Python 3 are not compatible with each other), it
is non-trivial to properly set up the execution environment.
As an example, the incompatibility of Python versions forces
Pythonlibrarycontributorstomaintaindifferentversionsoflibrary
modules (e.g., Numpy or Matplotlib) that are often imported by
Jupyter notebooks. Specifically, a given notebook may import a
largenumberoflibrarymodules,whichpersealsoimportmany
other library modules. It is hence non-trivial to know the neces-sary library modules beforehand when preparing the execution
environment.
To produce consistent environments, we make use of Conda, an
open-source library management system that supports automated
libraryinstallationandupdating[ 11].Condaalsoimplementsan
environmentmanagerthatallowsdifferentexecutionenvironments
(suchasPython2andPython3)tobepreparedandconfiguredinthe
samesystemwithoutinvolvingconflictsbetweenthem.Inthiswork,
wesetupfourCondavirtualenvironmentsrespectivelyforthetop-
5 leveraged major Python versions (except 2.7) discussed in the
previoussection,resultinginfourpre-constructedenvironments
for Python versions from 3.4 to 3.7.5For each of the four major
Pythonversions,weinstallallthestandardpackagesintegratedintoCondabydefault(i.e.,theAnacondarepository[
2]),whichleadsto
over 200 library packages included in the execution environment.
4In this work, we focus on Python-based Jupyter notebooks only.
5Wedecidenottopre-constructtheenvironmentforPython2.7asthisversionisnow
officially abandoned [35].
140Table1:Executableandreproduciblenotebooks.Theexecu-
tion is done based on the order of cells’ execution counters.
Python Notebooks Executable Reproducible
3.4 306 71(23.20%) 16(22.54%)
3.5 2,161 330(15.27%) 90(27.27%)3.6 2,902 528(18.19%) 151(28.60%)3.7 24 7(29.17%) 0(0.00%)
Total 5393 936(17.36%) 257(27.46%)
3.3 Experimental Study
Now that we have execution environments, we can execute all the
notebooks in a suitable environment. Again following Pimentel
etal.[33],werunthenotebooksthroughtherecordedexecution
counter of their code cells. For instance, regarding the notebook
shown in Figure 2, the code cells will be executed via the following
order: C1→C2→C5→C3→C4.
BecauseonlyfourPythonversions(i.e.,3.4–3.7)areconfigured
in the execution environment at the moment, 4,130 out of the
10,000notebooks(e.g.,withPython2.7orwithoutexplicitlymen-
tioningthedependingversion)aredirectlyexcludedfromtheexecu-tion.Among5,870notebooks,wefurtherfilteredout477notebooks
that contain no execution records. For the remaining 5,393 note-
books, Table 1 summarizes the execution and reproducible results.
Theresultsareconcerning.Tostart, only17.36%ofnotebookscanbe
fully executed without error. Even worse, among the 936 executed
notebooks,only27.46%ofthemcanbe exactlyreproduced.These
results is more or less in line with the results reported by Pimentel
etal.[33]—andstillsurprising, aswewouldhaveanticipated that
theexecution/reproducibleratewouldbehighasJupyternotebooks
are likely used for education [7, 29].
3.4 Root Causes of Non-Reproducibility
Letusnowexplorethereasons(rootcauses)whythemajorityof
notebooks (i.e., 679 = 936-257) cannot be executed or reproduced.
In this work, we summarize the root causes in two types: (1)
Jupyternotebookscannotbefullyexecutedand(2)Jupyternote-
books can be fully executed but cannot reproduce the same results
asoftheoriginalversion.Recallthattheobjectiveofthisworkis
torestorethereproducibilityofnotebooks.Wewillhencemainly
focus on the root causes of the latter.
Forthecasewheregivennotebookscanbefullyexecutedbutthe
resultscannotbereproduced,ourmanualobservationhasidentified
thefollowingreasonsthatmayleadtodifferentexecutionresults
compared to that of the original execution. We now summarize
therepresentativeones,togetherwiththeirabsoluteandrelative
prevalence.
R1: Randomness (276/679 = 40.6%). Manyscientificcomput-
ing programs require random functions, e.g. for sampling fromGaussian distributions or data shuffling. They produce different
results after each execution (if no seed is given), making it hard to
determineiftheresultscanbereproduced.Inourdataset,around
41%(276outof679)ofnon-reproduciblenotebookscontainrandom
functions.R2: Time and Date (87/679 = 12.8%). Time functions are re-
currentlyusedbynotebook authors(roughly13%ofnotebooksin
ournon-reproducibleset)toachievesomespecificfunctionssuch
asevaluatingtimeefficiency,loggingforSQLoperations,etc.Since
timechangescontinuously,theoutputsofthetimefunctionalso
vary everytime,making ithard toascertain thereproducibility of
the code.
R3: Plots (352/679 = 51.8%). We see a considerable number
ofnotebooksthatcannotbereproducedbecauseofdifferencesin
plotted images. Indeed, in some cases, images are generated based
oninputdataorrandomnumbersthatcannotbeensuredtoremainthesameeachtimewhenthenotebooksareexecuted.Additionally,
therunning environmentcanalso impactplottingresults. Giventhe same inputs, if different library versions are used, the plot-
ted images could also be different (because of API improvements6
or change of default parameter values).7Furthermore, when the
matplotlib moduleisnotproperlyinvoked,theimagemaynotbe
properly displayed. Instead, there will be some warning texts re-
latedtoPython’smagicfunctions (e.g.,[<matplotlib.lines.Line2Dat
0x7f24b114c3c8>] that could be different from time to time. Among
the 352 image-related non-reproducible notebooks, around 10% of
them are caused by incorrect usage of matplotlib.
R4:External Inputs (18/679= 2.7%). Jupyternotebooksmay
rely on external inputs (data fetched from web servers such as webcrawlerdemonstration)toexecute.However,theexternalinputsaresubjecttochange(suchasURLdecay[
50]),causinginconsistencies
between the reproduced results and the recorded original results.
R5: Floats (21/679 = 3.1%). In notebooks, floating point num-
bersmaybeprinteddifferentlydependingontherunningmachines,
or the targeted Python versions. Therefore, the reproduced results
(relevant to floating point numbers) might be different from the
original ones.
R6:ContainerTraversal(29/679=4.3%). InPython,theorder
inwhichsetsanddictionariesaretraversedisnotfixed.Hence,this
order may differ across execution environments, causing differing
cell outputs. In our non-reproducible set, 4% of notebooks show
this root cause.
R7: Execution Environment (181/679 = 26.7%). Notebooks
mayaccesstheexecutionenvironmentinformation(e.g.,numberof
CPUs, Python package versions, the memory location of variables,
etc.) that isusually specific to eachsetting and hence is different
fromoneanother.Moreover,indifferentexecutionenvironments,
thesamedatamightbeprintedindifferentformats.Forexample,thenumber1mightbeprintedas1
.0.Thematrix(i.e.,two-dimensional
array)mightbeprintedwithdifferentspacesbetweentheelements.
All these differences will impact the reproducibility of notebooks.
Inappropriateexecutionorderofcells. Apartfromtheerrors
raised by execution environments, we also observe a significant
numberofnotebooksthatfailtobeexecutedduetopoorcodequal-ity,e.g.,containing nameerrors (undefinedvariables), keyerror (key
not found in dictionaries), syntax errors, etc. We found this amount
of errors surprising, as we would have expected code in notebooks
to be of good quality. Indeed, the notebooks are collected from
6https://matplotlib.org/users/dflt_style_changes.html
7https://bit.ly/2QNO3P9
141publiclyreleasedrepositories,forwhichmostofthemarerelated
to educational materials for teaching inexperienced developers.
This fact hence motivates us to go one step deeper to check
the reasons behind this kind of errors. Our manual observation
reveals thatthese errorsare yieldedbecause the executionorder of
cells is inappropriate (e.g., a variable is used before its definition).
Since this problem is not caused by the execution environment,
wedecidetoconsideritasanotherrootcausemakingnotebooks
non-reproducible. This root cause refers to problems that cause
notebooks to be non-reproducible because the code cells are not
executedintheintendedorder.Ideally,iftheappropriateexecution
order of code cells is respected, the notebooks, falling into this
category, would become reproducible.
In summary, all of these findings will impact any approach that
attemptstoreproduce,test,oranalyzeJupyternotebooks.Indeed,
even for executable notebooks, it may not always be possible to
reproduce the exact results as originally obtained. In this work, we
thus attempt to resolve all the aforementioned non-reproducible
rootcauses(R1–R7andInappropriateexecutionorder),aimingto
design an automatedapproach for restoringthe reproducibility of
notebooks as much as possible.
4 OSIRIS
Now thatwe haveidentified causesfor non-reproducibility,let us
fix them. We have implemented a tool called Osiris, which adopts
different strategies to resolve the aforementioned root causes ofnon-reproducibility, attempting to maximize the execution and
reproducibilityofnotebooks.OsiristakesasinputaJupyternote-
bookandoutputsthepossibleexecutionschemesthatreproduce
the exact notebook results. If Osiris fails to reproduce the note-
book,itwillhighlightthelocationoffailures(i.e.,non-reproducible
parts) that could be useful for understanding the root causes of
non-reproducibility of Jupyter notebooks.
Figure4illustratestheworkingprocessofOsiris,whichismainly
made up of four modules: (1) Cell Code Parsing, (2) Cell Depen-dency Graph Construction, (3) Strategy-based Reproducing, and
(4) Targeted failure debugging. We now detail these four steps,
respectively.
Cell Dependency 
Graph ConstructionStrategy-based 
Reproducing
Targeted Failure 
DebuggingJupyter
Notebook
Execution
ReportsCell Code Parsing
Figure 4: The working process of Osiris.
4.1 Parsing Cell Code
ToanalyzethecodeinJupyterNotebookcells,wefirsthaveto parse
it. For this purpose, Osiris makes use of built-in Python parsers,
transformingPythoncodeintoabstractsyntaxtrees(ASTs).Special
care is taken to handle and resolve importstatements as well astranslating syntacticsugarstatements8andlambdastatements9into
analyzable normal forms.
4.2 Resolving Cell Dependencies
ThesecondmoduleofOsirisaimsatidentifyingandcharacterizing
dependencies betweennotebookcells.Bystaticallyparsingthecode
cells, Osiris builds the so-called cell dependency graph (CDG) to
model the relationships.
Technicallyspeaking,acodecells dependsonthesetofvariables,
functions, classes, modules used, defined, or imported in the code
snippets.Agivencodecellcanbeexecutedaslongasallitsused
variables are defined in the Jupyter execution environment. In
thiswork,weleveragetheclassicalproducer-consumermodelto
represent the define-use relationship of variables in the code cells
of a notebook.
Giventheparsedabstractsyntaxtree(AST)ofacodecell C,as
illustrated in Figure 5, we calculate the stored and loaded variables
(including method calls and class initialization). The stored vari-
ables,definedfunctions/classes,importedmodulesareputintoa
producersetwhile loadedvariables/functions/callsareaddedtoa
consumerset.Notethat,withinacodecell,ifavariableisproduced
afterbeingconsumed(e.g., ainC2),thisvariablewillbeexcluded
fromtheproducerset.Thecallsofthebuilt-infunctions(e.g., hash(),
ascii())willnotbeaddedintoconsumerset[ 24].Hence,thefinal
producerandconsumersetsof C2ar e P(C2)=/braceleftbig
b/bracerightbig
,C(C2)=/braceleftbig
a,b/bracerightbig
.
b = 20
a = a + b print (a)Module
Assign Assign Print
Name
bNum
20Name
aBinOp
Name
aAdd Name
bName
aP(C2) = {b}C(C2) = {a, b}
Code Cell C2 AST Producer/Consumer Sets
Figure 5: Generating producer/consumer sets.
Aftertheproducer/consumersetsarecalculatedforeverycode
cell,OsiristhenleveragesthisknowledgetoconstructaCDGfor
the notebook.In the CDG, everycode cell becomesa node. Edges
will be added if given two code cells (or nodes, say CiandCj)
have no conflicts between each other. Concretely, an edge Cj→
Cican be added as long as the following constraint is respected:
C(Cj)⊂P(Cj)∪P/prime(Ci), where P/prime(Ci)is the accumulated producer
setafter Ciisexecuted(orreachedfromarootnodeintheCDG).
Consequently, after the execution of Cj,P/prime(Cj)=P(Cj)∪P/prime(Ci)
(i.e., the produced set is the combination of the newly produced
variables and all the previously produced ones.).
ItisworthmentioningthatagivennodeinaCDGcanbereached
from the root node via multiple paths. Hence, the accumulated
producer set may not be unique. Take the motivating notebook
(cf. Figure 2) as an example, as demonstrated in Figure 6(a), C4can
be reached from both C2andC3.Subsequently, the accumulated
producer set P/prime(C4)could be P(C4)∪P/prime(C2)orP(C4)∪P/prime(C3).
8Syntactic sugarstatements (e.g.,i+ =5 ,a* =5) aredesigned to make thingseasier to
read or express.
9Lambda statements are usuallyused to concisely define functions. Forexample, the
followingsimplelambdastatement x=lambdaa :a+10actuallydefinesafunction
142C1
C3C4C2
P(C3) = {}
C(C3) = {b}P(C4) = {}C(C4) = {a, b}P(C1) = {random, Image, a}C(C1) = {a}
P(C2) = {b}C(C2) = {a, b}
C(C4) < P(C4) U P’(C3)C(C4) < P(C4) U P’(C2)
(a) Example of multiple pathsC1
C2
C2
C4C5 C4 C3C5
C4C3 C4 C4
C3C5 C3 C3
C3 C5 C5C5
C4 C3 C4
S1 S2 S3 S4 S8 S7 S6 S5
(b) Full paths
Figure 6: The possible execution orders of code cells w.r.t. producer/consumer constraints. The left sub-figure presents a sim-
plified example of multiple paths while the right sub-figure illustrates all the possible execution paths for the motivatingexample shown in Figure 2.
4.3 Strategy-based Reproducing
As discussed in Section 1, we assume that Osiris users may have
different expectations and requirements regarding reproducibility.
Osiris thus supports two types of strategies to be configured: (1)
matchstrategyand(2)executionstrategy.Wenowdetailthesetwo
types respectively.
4.3.1 Match Strategy. Wehaveintegratedthreematchstrategies
into Osiris:
Strong Match (Stage 1). The reproduced results should exactly
match the results yielded by the original notebook. This
matchingstrategyhasbeenusedinourpreliminaryrepro-
ducibilitystudyaswellasintheempiricalstudyofPimentel
et al. [33]. This matching strategy is needed by users who
wanttoexactlyreproduceallresults;weconsideritasthe
baseline for reproducing Jupyter notebooks.
Weak Match (Stage 2). Thereproducedresultsarethesamewhen
repeatingtheexecutioninthesameenvironmentbutmay
not match exactly to that of the original notebook. This
matching strategy targets users who are more interested in
reusing and re-executing the code rather than reproducing
the exact results.
Withthismatchingstrategy,mostofthenon-reproducible
root causes categorized in R4–R7 are expected to be miti-
gated. Indeed, let us take R4 as an example, a given note-
bookdedicatedtoanalyzingaGithubprojectwillbeupdated
weekly. Since the Github project is continuously updated,
theanalyzingresultswillbedifferentoccasionally.However,
if we launch the notebook twice (with a short time interval)
in the same environment, the analyzing results should be
identical.
Best-effort Match (Stage 3). Forcodecellsthatcannotbeweakly
matched (e.g., R1−R3), Osiris will go one step deeper to ex-
plore alternative means to reproduce the code cells, aim-ing to achieve weakly match with special consideration
named x.Whenstaticallyparsingthisstatement,itshouldbeinterpretedas defx(a):
return a+10;(i.e., best-effort match). In particular, Osiris leverages a code
instrumentation-based approach to achieve the aforemen-
tioned objective. Given acode cell, Osiris attempts to trans-
form it into a semantically equivalent version. If the new
version can be weakly matched, we consider the original
code cells can be matched with best-effort. Again, this strat-
egytargetsuserswhowanttoreusethenotebookorparts
of its code.
Osiris has three “antidotes” to achieve best-effort matches:
(1)Regarding randomness, we attempt to configure a seed
beforetherandomfunctionsbeingcalled.Asillustratedin
Listing 1, random functions may be used by various library
modules, which need to be addressed separately.
(2)Fortime/date functions, we select the “time-freeze” tactic
to mock the time-related modules of Python [ 13]. Within
thistactic,allthefunctionsrelyingonthecurrenttimestamp
such astime.time() will return constant values.
(3)(Asforplotsinvolvingthe matplotlib library,weforcethe
notebooktodirectlydisplaytheimage(toavoidtheoutputof
memory addresses) by explicitly inserting a magic function
(i.e., %matplotlib inline) at the beginning of the notebook.
1# For the random module of Python
2random.seed(100)
3
4# For the random module of numpy, sklearn and scipy
5numpy.random.seed(100)
6
7# Fortimefunctions
8fromfreezegun import freeze_time
9freezer = freeze_time( "2019-01-01 00:00:00" )
10freezer.start()
11
12# For matplotlib images
13%maplotlib inline
Listing 1: Sample solutions for best-effort match.
4.3.2 Execution Strategy. Thesecondtypeofstrategiesthatcan
be configured in Osiris is related to the execution of the notebook.
This strategy type allows users to specify how do they want to
143executethecodecellsinagivennotebook.Sofar,Osirishasbeen
equipped with three execution strategies.
Original Execution Counter (OEC). In this strategy, the code
cells of a given notebook will be simply executed following
the order of the cells’ execution counters. Skipped counters
(e.g., 3 ,4,6 in Figure 2) will be simply ignored. For the note-
bookpresentedinFigure2,theexecutionorderunderthis
strategy will be solution S5 in Figure 6. All the experiments
conducted in Section 3 are based on this strategy.
Top-down (Normal). In thisstrategy, thecode cellswill beexe-
cutedfollowingtheir naturalorder, from topto down. For
thenotebookillustratedinFigure2,theexecutionorderwill
be solution S1 in Figure 6.
Cell Dependency Graph (CDG). Thisstrategyattemptstoexe-
cute the code cells of a given notebook in all the possible
orderswithrespect totheproducer/consumerdependencies.
Like the aforementioned two strategies, this strategy will
only execute each code cell once. Regarding the notebook
shown in Figure 2, this strategy will generate eight possible
solutions for reproducing the notebook.
4.4 Targeted Failure Debugging
Usingitsstrategy-basedreproducingmodule,Osirisisnowcapable
of exploring the reproducibility of a given notebook in different
ways.Someoftheattemptsmaynotbeabletoreproducetheresults
(even with weak or best-effort matches). When the reproducing at-
temptfails,oreventheexecutionfails,therewillbe,mostlikely,no
logs orexecution tracesillustrating thereason whyit fails,giving
noclueforuserstounderstandandrefinetheirexecutionstrategies.
Forthisreason,Osirisfeaturesa debuggingmodule. Givenanote-
bookandacodecellwherethereproducingprocessorexecution
fails, this module will then record the execution trace of the cell.
To this end, we implement an instrumentation-based approach to
record the execution status at the client code side. Particularly, for
everycodelineofthespecifiedcell,weinjectloggingstatements
torecordthecurrentexecutionstate(e.g.,thevariablesandtheir
values) the code line will be executed with.
For each line executed in the cell, we record and compare a
snapshot of all self-defined variables and their states. After cell
execution,Osirislocatesthefirstsuspiciouslineinwhichthefreshly
computed variable values are inconsistent with published values.
Additionally, Osiris also highlights non-repeatable code cells,
whichmaygeneratethesameoutputsbutwillyieldvariablevalues
thatwouldimpactthesubsequentexecutionofothercells.Inour
motivatingexamplefromFigure2,allthefirstfourcells(e.g., C1–C4)
arenon-repeatableones.Thesenon-repeatablecellsmayprevent
notebook reproduction if execution counter skips are present.
5 EVALUATION
Our evaluation addresses the following research questions.
•RQ1:Can Osiris build sound cell dependency graphs for
Jupyter notebooks?
•RQ2:To what extent can Osiris improve the reproducibility
rate of Jupyter notebooks by varying the match strategies?
•RQ3:Withdifferentexecutionstrategies,canOsirisimprove
the reproducibility rate of Jupyter notebooks?•RQ4:CanthetargetedfailuredebuggingmoduleofOsiris
help pinpoint the root causes for non-reproducibility?
5.1 RQ1: Soundness of Cell Dependencies
Ourfirstresearchquestionconcernsthesoundnessofthecelldepen-
dencygraph(CDG),whichisimportantforOsiristofullyexplore
thereproducibilityofJupyternotebooks.Indeed,Osirisleverages
the CDG to generate all the possible execution paths when depen-
dencyexecution strategy is enabled. Ideally, if the CDG is sound,
all the paths generated based on it (hereinafter referred to as CDG
paths)wouldbeexecutable(whichmaynotbeabletofullyrepro-
duce the notebook though). To this end, we transform the problem
of checking the soundness of the generated CDG to the problem of
checking the executability of CDG paths.
Since the number of CDG paths is huge, it is not practical to
exhaustivelyexecuteallofthem.Therefore,foreachnotebooktobe
tested, we randomly select 10 CDG paths to fulfill this experiment.
Toavoidpotentialbiases,e.g.,thenon-executabilityisduetosyntax
errorsinthePythoncode,thisexperimentshouldonlybeconducted
on notebooks known as executable ones.
Therefore, we choose the 936 notebooks that are demonstrated
to be executable in Section 3 as the input dataset to perform the
experiment.Amongthe936notebooks,despitethatonly10CDG
paths selected, our approach finds that (1) 79.81% of them have all
theselectedCDGpathssuccessfullyexecuted,(2)14.32%ofthem
haveat least one CDG path failing; and (3) the remaining 5.88%
haveallCDG paths failed.
WefurtherlookintothereasonscausingcertainCDGpathsto
fail in our experiment. Our manual observation reveals that the
failsareindeedrelatedtothesoundnessoftheCDGbuiltbyOsiris.
The problems are mainly introduced by the static code analysis
stepofOsiris,wherecertaincomplicatedJupyter/Pythonfeatures
are overlooked. Listing 2 presents a common challenge that keeps
OsirisfrombuildingasoundCDG.BecauseOsirisisnotawareof
dictionarykeys,itwillconsiderthatcell3isreachablefromcell1
sincetheproducer/consumerdependencyisfulfilled.Unfortunately,accessing this unknown key will result in errors because the dictio-
nary key is not registered yet. The overlook of the aforementioned
Pythonfeaturessubsequentlyleadstoincorrectproducer/consumer
setsandtherebyresultinginunsoundCDGs.Nonetheless,wedo
not observe any failures caused directly by the producer/consumer
dependencyalgorithm.Thefactthatthemajorityofnotebookscan
be successfully processed to generate executable paths shows that
the cell dependency graph construction process is generally sound.
21# access unregistered dictionary key.
22a={ } # cell 1: produce a
23a['ase']="2020" # cell 2
24x=a ['ase']# cell 3: consume a
Listing 2: An example of challenge that keeps Osirisfrom building a sound CDG.
Finally, at the end of this research question, we conduct one
more experiment tocheck if 10 is a goodnumber when randomly
samplingtheCDGexecutionpaths.Tothisend,werandomlyselect
10 notebooks with CDG paths that can be successfully executed.
Now,inadditionto10paths,wefurtherchecktheexecutionrateof
144Table 2: Fraction of CDG paths that can be used to success-
fully execute notebooks.
Username/Repository Name 10 20 50 100
vuddagiri-mounica123/datascience 1.00 1.00 1.00 1.00
willengel88/Pandas-homework 0.50 0.60 0.54 0.51rjsampa/Curso_python_PEC2018 1.00 1.00 1.00 1.00carlorizzante/MITx6.00.1 1.00 1.00 0.98 0.99
fgnt/oaf 1.00 0.90 0.96 0.97
ratnakumar-nakka/Python 1.00 1.00 1.00 1.00Novobura/2016-Election-Analysis 1.00 1.00 1.00 1.00murrayLuke/dithering 1.00 1.00 1.00 0.99
svenchilton/springboard 0.20 0.30 0.34 0.25
mc-carthy/pyDSML 1.00 1.00 1.00 1.00
Table 3: Improvement of execution rate when varying the
match strategies of Osiris.
Python Notebooks Strong Weak Best-effort
3.4 71 16(22.54%) 40(56.34%) 52(73.24%)
3.5 330 90(27.27%) 203(61.52%) 261(79.09%)3.6 528 151(28.60%) 316(59.85%) 393(74.43%)3.7 7 0(0.00%) 3(42.86%) 3(42.86%)
Total 936 257(27.46%) 562(60.04%) 709(75.75%)
20,50, and100 paths.Table2 illustratesthe10 selectednotebooks
and additional execution results. No matter which threshold is set,
theexecutionratesarekeptmoreorlessthesame.Thisevidence
suggests that 10 is a good threshold for testing the CDG paths.
5.2 RQ2: Match Strategies
The second research question concerns the effectiveness of the
match strategies implemented in Osiris. Specifically, given a set of
non-reproduciblenotebooks(strongmatch viaoriginalexecution
counter,asexplainedinSection3),towhatextentcanourapproach
(with weak and best-effort strategies) improve the execution/repro-
duciblerate?Tothisend,welaunchOsirisonallthe936notebooksthathavebeenshownexecutableinourpreliminaryreproducibility
study. Except for switching the match strategy to weak or best-
effortstrategies,we keepalltheotherparametersunchanged, i.e.,
thecodecellsareexecutedfollowingthesameorder(i.e.,original
execution counter).
Table 3 summarizes the execution results. Among the 936 ex-
ecutable notebooks, with weak match strategy, the reproducible
rate canbe doubled fromthat of theweak match, increasingfrom
27.46% to 60.04%. When best-effort is enabled, an additional 15% of
notebookscanbereproduced,resultingin75.75%ofreproducibility
rate. This significant improvement of the reproducible rate shows
thatOsirisisusefulandeffectiveforassessingthereproducibility
of Jupyter notebooks.
Wefurtherlookintothebreakdownofthenumberofnotebooks
that are additionally reproduced thanks to the best-effort match
strategy. The majority of them are contributed by the random anti-
dote.Amongthe147additionallyreproducedcases,wefindthatthe
mainimprovementcomesfromtheantidotetorandomfunctions,
accounting for 113 (roughly 77%) notebooks. The improvementsover time and image plot antidotes are 6 and 28 notebooks, respec-
tively. Our in-depth analysis further reveals that our best-effort
approachmayhaveoverlookedsomenotebooks.Forexample,we
additionallyfindthatthereare18notebooks(outofthe227non-reproducible ones) having also accessed into random functions.
After manual investigation, we believe that these overlooked note-
booksshouldnotbeconsideredasfalsenegativesofourbest-effortapproachsincetheerrorsarelikelycausedbydifferentreasons(i.e.,
not from the random function).
5.3 RQ3: Execution Strategies
We now look at the execution strategies introduced to Osiris when
reproducingJupyternotebooks.Insteadoftheoriginalexecution
counter,whichhasbeenusedinalltheaforementionedexperiments,
we additionally launch Osiris via (1) normal (top-down) and (2)
producer/consumer dependency (CDG) strategies. As discussed
earlier,thepossibleCDGpathsaregenerallytoomanytoexecuteall.
Therefore,aswithRQ1,werandomlychoose10CDGpathstofulfill
thisexperiment.Aslongasonepathfromtherandomlysampled
10pathsiscapableofexecutingorreproducingthenotebook,we
will consider the notebook as such.
Sincedifferentexecutionstrategiesmaybeabletoexecutediffer-
ent notebooks10, we resort to the original 5,393 notebooks for this
experiment.AsillustratedinFigure7,interestingly,withbest-effortmatchstrategy,bothnormalandCDGexecutionstrategiesareable
to improve the overall execution rate, giving 20.66% and 25.24%,
respectively.
17.36%20.66%25.24%
0%5%10%15%20%25%30%
OEC Normal CDG
(a) Breakdown.CRG
NormalOEC
214
498803
164314
CDG
(b) Venn diagram.
Figure 7: Executable rates and notebooks achieved by vary-ing the execution strategies of Osiris.
Intotal,bycountingthethreeexecutionstrategiesasawhole,
Osiriscansuccessfullyexecute1,435notebooks.Figure8further
illustrates the distribution of reproduced notebooks over the three
strategies.Amongthe1,435executablenotebooks,1,180ofthem
havebeenshownreproducible,givingareproducibilityrateof82.23%,
which has more than tripled the rate of the state-of-the-art and
significantlyincreasedfromourresultsbyleveragingOECexecu-
tion strategy along [ 33]. This result experimentally shows that the
execution strategies of Osiris are indeed useful for restoring the
reproducibility of Jupyter notebooks.
10We hypothesize that not all the non-executable notebooks are related to the in-
appropriatesetupoftheexecutionenvironment.Therefore,byleveragingdifferent
strategies to execute those notebooks, we might be able to find more executable note-
books,withoutupdatingourexecutionenvironment.Recallthatexecutabilityisnot
the main focus of this paper.
145CRG
NormalOEC
5913
30237519
68344255 Executed but not reproduced notebooks
CDG
Figure 8: Reproducible notebooks among executable ones.
5.4 RQ4: Performance in locating faults via
debug functionality
As revealed in the previous section, among the 1,435 executable
notebooks, 225 can not be reproduced by Osiris. In this research
question,welookatthetargetedfailuredebuggingmoduleofOsiris,
aiming at evaluating the usability of this module towards locating
the problematic statements making notebooks non-reproducible
(at least by Osiris). To this end, we apply Osiris again, with the
targeted debugging module enabled and the first non-reproducible
cell as input, to the 255 non-reproducible notebooks. For each line
ofcodeinthecell,Osiriswilldumptheexecutionstatusbeforeand
aftertheexecutionofthecodeline.Ifasuspiciouslineisidentified,
Osiris will further report it as such.
Toevaluatetheaccuracyofthedebuggingmodule,werandomly
select 20 notebooks with suspicious lines reported and manuallychecktheresults.Alltheselectednotebooksarehencemanually
executed,usingpredefinedexecutionstrategies.Table4summarisestheexperimentalresults.Forthe60samplesrandomlyselected,our
manual validation confirms that 45 of them are correct, giving
anaccuracyat75%.Thefalsepositivesaremainlycausedbytwo
limitationsofOsiris:(1)Somecodelines(e.g.,functioncalls)will
only change the outputs of the cell but may not alter the execution
states.Osiriscannotbeawareofthis.(2)Osirismissessomedata
types(suchastheonesfromthird-partylibrariessuchasPandas
DateFrame) when recording and debugging execution states.
Table4:PerformanceofOsiris’stargeteddebuggingmodule.
Execution Random True Non-repeatable
Strategy Samples Results Notebooks
OEC 20 12 (60%) 12 (60%)
Normal 20 16 (80%) 15 (75%)
CDG 20 17 (85%) 16 (80%)
Total 60 45 (75%) 43 (72%)
The last column of Table 4 lists the number of non-reproducible
cells (reported by Osiris) that are also non-repeatable cells. As it
is similar to that of non-reproducible cells, there could be a strong
correlation between non-reproducible and non-repeatable cells.
Wehence conductanother experimentto evaluatethis suggestion
empirically.Werandomlyselecttwodatasets(i.e.,100reproducible
notebooks and 100 non-reproducible notebooks) and launch Osiris
to check the number of non-repeatable cells. Figure 9 presents the● ● ●●012345
(a) Reproducible
012345
(b) Non-reproducible
Figure9:Distributionofthenumberofnon-repeatablecellsbetween reproducible and non-reproducible notebooks.
distribution of the results. A Mann-Whitney-Wilcoxon (MWW)
test[12]confirmsthatthedifferenceintermsofthenumberofnon-
repeatable cells between these two datasets is indeed significant
(i.e., p-value is smaller than 0.001).
Cliff’sdeltaeffective size [ 26] further explains that the corre-
lation between these two datasets is strong, indicating that non-
repeatablecellscouldbeoneofthemainreasonscausingJupyter
notebookstobenon-reproducible.Therefore,weencouragenote-
bookauthorstomitigatetheusageofnon-repeatablecellstopro-
mote the reproducibility of their Jupyter notebooks.
6 DISCUSSION
AimingatmaximizingthereproducibilityofJupyternotebooks,our
tool will be beneficial to both notebook authors and users. Note-
book authors can leverage Osiris to check the reproducibility
of their notebooks before committing. To ease the reproducibil-
ity for notebook users, the reproducing details can be dumped and
includedinthecommit.Indeed,webelievethatOsiriscanbeconfig-
ured as a regression testing tool that can be regularly (e.g., nightly)
executedtoidentifypotentialerrorsintroducedbythedevelopmentprocess.
Notebookusers can leverage Osiristo understandhow a
given notebook, which is released without giving any reproducing
detail,canbereproduced.Theycanalsogaintheconfidencethat
the notebook (if reproduced by Osiris) is correct (hence its codecan be trusted and reused), even if the original output cannot be
literallyreproduced.Finally, notebookresearchers candevelop
new testing and analysis approaches for Jupyter notebooks. For ex-
ample,ourfellowresearcherscouldtaketheinitiativetomodifythe
Jupyterframeworktorecordalltheexecutionorders,includingthe
skippedones,whichhascauseddifficulties(e.g.,CDGconstruction)
to properly restore the execution sequences of notebook cells.
6.1 Limitations
InsufficientSetupofExecutionEnvironment. Asdiscussedin
Section 3, the majority of notebooks fail to be executed due to li-
brary dependencies (e.g., import error because of missing modules,
orcontainremovedfunctionsduetoinappropriatelibraryversions).
This finding is similar to the one conducted by Pimentel et al. [ 33].
Althoughinferringasufficientexecutionenvironmentisnotthefo-
cusofthiswork,webelievethathavingsuchanenvironmentwould
146significantly complement our work towards restoring the repro-
ducibilityofJupyternotebooks.Recently,HortonandParnin[ 15]
have presented an approach to automatically infer environment
dependenciesforPythoncodescripts.Thisworkcouldbeleveraged
to set up appropriate environments for executing and reproducing
Jupyter notebooks.
UnsoundstaticPythoncodeanalysis. Atthemoment,Osiris
hassomedrawbacksthatkeepitfromperformingsoundstaticanal-
ysesofJupyternotebooks. Firstofall,codecellsinnotebookscan
be updated following successful execution (e.g., magic functions
are likely to be removed after executing). This execution history is
unfortunatelynotrecordedandhencewillintroduceinconsisten-
ciesbetweenthecodeandtheoutputs.Second,thevariablevalue
in notebooks can be updated in succeeding cells, which may cause
runtime exceptions. For example, a matrix of (M×N)defined in
onecellcouldbereshapedtoa1 ×(M×N)arrayinanothercell.Dif-
ferent CDG paths may cause exceptions of dimension mismatches
in matrix multiplication.
Incomplete match/execution strategies. In all the current
execution strategies, each code cell will only be executed once,
whichhowevermaynotbethecauseinpractice.Indeed,thecur-
rent strategies cannot even reproduce the motivating notebooks
shown in Figure 2. Therefore, we believe that there is a need toexplore other strategies that take into account cell dependencies
whilerespectingtheexactexecutioncounterofthecells.Thelength
oftheexecutionordersshouldbeequaltothemaximumvalueof
the execution counter in the given notebook. In this work, we fur-
therimplementanexecutionstrategyfulfillingtheaforementioned
requirements. While respecting the exact execution counter of the
cells, we additionally add random cells (w.r.t. the producer/con-
sumer dependency) to all the skips in the execution counter.
6.2 Threats to Validity
Themainthreattothevalidityofthisworkliesinthesizeofour
dataset, though we started from 10,000 real-world Jupyter note-
books,which(unfortunately)maynotbefullyrepresentative[ 4].
We attempt to mitigate this threat by randomly selecting the note-
books from a large set. To avoid potential biases, we only select
one notebook from each Git repository that may contain multiple
notebooks.SinceourapproachonlysupportsPythoncodeanalysis,
we further limit the selected dataset to be Python-based notebooks
only,lettingseveralnotebooksinvolvingotherprogramminglan-
guages such as R and Julia overlooked.
Apart from the dataset, our work also involves substantial man-
ualwork.Forexample,therootcausesofnon-reproducibilityare
manually summarized based on our preliminary reproducibilitystudy. The results of targeted failure debugging analysis are alsocharacterized manually. Such manual processes are known to beerror-prone. To mitigate the threat, we have cross-validated the
results. We also release our tool and dataset for public access.
Furthermore,wehavenoevidencetoshowthattherandomly
selectednotebooksevaluatedinthisworkaredesignedtoberepro-
ducible.Iftheyarenotintendedtobereproduced,ourevaluation
results might be impacted.
Nevertheless, as shown by Rule et al. [ 44], Jupyter notebooks
havebeenrecurrentlyleveragedtosupportreproducibleresearchesand hence such impact should be neglected. Moreover, a largenumber of notebooks cannot be executed (e.g., due to incorrect
dependencies or unsupported Python versions), which may impact
thegeneralityofoursampleset.Tomitigatethis,wehavemanuallysampledsomeoftheexecutablenotebooks.Ourmanualobservation
confirms that the randomly selected notebooks are not toy ones.
The fact that half of the notebooks have more than 15 code cells
also confirms this observation.
7 RELATED WORK
Despite its popularity, Jupyter notebooks have not yet been well
studiedbythesoftwareengineering(SE)community.Tothebestof
our knowledge, there are only a few such studies available to note-
book authors. Wang et al. [ 52] have conducted a preliminary study
on the code quality of Jupyter notebooks. They have empirically
foundthatJupyternotebooksareinundatedwithpoorqualitycode,
e.g.,not respecting recommendedcodingpractices,or containing
unused variables and deprecated functions. The authors argue that
there is a strong need to programmatically analyze Jupyter note-
books.Ourwork,byprovidingvalidprogramcode(reorderedcodecell,forexample),anditscelldependencygraph,canbeconsidered
as the first attempt in the SE community towards systematically
analyzing and testing Jupyter notebooks.
The work most closely related to ours is the one by Pimentel et
al. [33]. The authors have conducted a large-scale empirical study
about the quality and reproducibility of Jupyter notebooks. Unlike
the work conductedby Wang et al.[ 52], whichmainly focuses on
the quality of the code presented in the notebooks, our paper ismore focused on the good or bad practices used in the develop-
mentofnotebooks.Pimenteletal.[ 33]havealsoinvestigatedthe
reproducibilityofJupyternotebooks.Throughastraightforward
approach, the authors empirically find that only 24.11% of their se-
lectednotebookscanbeexecutedwithouterrors,andonly4.03%ofthemcanproducethesameresults,comparedtothatoftheoriginal
outputsofthenotebooks.Theauthorshavealsosummarisedthe
common root causes making notebooks non-executable and hence
non-reproducible.Asanimplication oftheirwork,theauthorsar-
guethatthereisanopportunitytoimprovethereproducibilityrateinnotebooksbydevisingapproachesaddressingtherootcauses.In
thiswork,wetakeactiontoactuallydesignandimplementsuch
an approach, which combines both static and dynamic analyses, to
explore the possibilities of reproducing Jupyter notebooks.
Notebookshavebeenfrequentlyinvestigatedbyresearchersout-
sideofSoftwareEngineering[ 16,17,22,38,42,45,46,48,53].For
example, Rehman et al. [ 38] address the reproducibility of Jupyter
notebooksbyenrichingtheprovenance-basedsemanticsofinter-
active notebooks. Their ProvBook prototype aims at capturing and
viewing the provenance of notebook changes and thereby pro-vidingameanstotrackcompletepathsofscientificexperiments.
Yaniv et al. [ 55] designed “SimpleITK Jupyter Notebooks” based on
Jupyter Notebook, an image analysis environment for researchers
withdifferentlevelsofdevelopmentskills,tofacilitatereproducible
research.
Keryetal.[ 16,17],fromtheHuman-ComputerInteraction(HCI)
community, have conducted several studies in understanding note-
books w.r.t. their literate programming features and untangling
147messy histories of notebooks. By interviewing and surveying 66
data scientists, they have observed that notebooks are mainly used
for scratchpad construction, scripts preparation and knowledge
sharing. To combat the challenge of navigating messy version data
topickouttherelevantinformationforagiventask,theyintroduce
an approach called Verdantfor supporting lightweight interactions
among many versions of code and non-code artifacts in the editor.
Similarly,Ruleetal.[ 46]alsolookatcomputationalnotebooks
from the human factors point of view. The authors have empiri-
cally found that, via a large-scale empirical study of computational
notebooks on Github, computational notebooks may not always
containexplanatorytextandonlyasmallsetofthemwilldiscuss
thereasoningorresultsofthemethodsdescribed.Ruleetal.[ 43]
havealsonoticedthenon-reproducingproblemofnotebooksand
hence summarised the top 10 simple rules for reproducibility in
Jupyternotebooks.Theauthorsarguethatnotebookauthorsshould
advocateinpromotingthereproducibilityofnotebooks.Theyeven
suggestthat notebookauthorsshouldask lab-matesorcolleagues
to try to run their notebooks to ensure their reproducible uses.
Our work fully supports their claims (i.e., the reproducibility ofnotebooks is very important) and supplement their claims with
anautomatedapproachforhelpingnotebooksauthorscheckthe
reproducibility of their notebooks.
OurworkfocusesonthereproducibilityofJupyternotebooks,
aimingatreconstructingtheexecutionordersthatreproducethe
exactnotebookresultsandhencesupplementingthe implementa-
tion of advanced static and dynamic analyses of Jupyter notebooks.
Althoughthedef-usehasbeenatraditionalmechanisminprogram
analysis [ 31][9], the relevant research on Jupyter notebooks is still
empty.TheuniquenessofJupyternotebook’scellstructurerequiresdef-userelationtobebuiltforcodecellsinordertodeterminetheir
dependencies.
Thesoftwareengineeringcommunityhasinvestigatedtherepro-
ducibilityofothersoftwareartifacts[ 3,10,14,21,27,41].Forexam-
ple,toensurereproducibility,researchershaveproposedvarious
approaches to achieve record-and-reply executions [ 28,34,47], fa-
cilitatebugreproductionsbyanalyzingexecutionlogsordumps[ 1,
20,54],andunderstandanddetectflakytestsorcompatbilityissues
thatmakereproducibilitystudiesdifficult[ 5,8,23,25,30].Asan-
otherexample,Renetal.[ 39]haveproposedanapproachtolocating
the problematic files for unreproducible builds. The authors claim
that identifying unreproducible issues remains a labor-intensive
and time-consuming challengedue to the diversity of rootcauses
thatmayleadtounreproduciblebinaries.Inlinewiththisresearch,
the authors further present a dedicated study focusing on locating
suchrootcauses[ 40].Ingeneral,reproducibilityhasbeenconsid-
ered a hard yet useful endeavor in the SE community. Indeed, as
advocated by Anda et al. [ 3], achieving more reproducibility in SE
remains a great challenge for SE research, education, and industry.
8 CONCLUSION
MotivatedbyalowreproduciblerateofJupyternotebooksreported
by the state-of-the-art and detailed in our study, we present tothe SE community the first work to automatically restore repro-
ducibility of JupyterNotebooks. Our Osirisprototype explores all
the possible execution schemes to reproduce as much of notebookresultsaspossible.IntheevaluationofOsiris,weshowitiseffec-
tivetorestorethereproducibilityofJupyternotebooks,achievingasignificant improvement over the state-of-the-art[
33]. In particular,
our approach enables the use of static and dynamic analyses on
JupyterNotebooks,whichcanbeusedfortesting,empiricalstudies,
automatic repair techniques, and more.
To help readers access our tool and replicate our experiments,
we make our tool Osiris and scripts available at
https://github.com/Osiris-Jupyter/Osiris
REFERENCES
[1]Gautam Altekar and Ion Stoica. 2009. ODR: output-deterministic replay for
multicore debugging. In Proceedings of the ACM SIGOPS 22nd symposium on
Operating systems principles. 193–206.
[2]Anaconda. 2019. Anaconda Enterprise 4 Repository: Open Data ScienceHub. (2019). Retrieved August 23, 2019 from https://docs.continuum.io/
anaconda-repository/
[3]Bente CD Anda, Dag IK Sjøberg, and Audris Mockus. 2008. Variability and
reproducibilityinsoftwareengineering:Astudyoffourcompaniesthatdevelopedthesamesystem. IEEETransactionsonSoftwareEngineering 35,3(2008),407–429.
[4]Sebastian Baltes and Paul Ralph. 2020. Sampling in Software Engineering Re-
search:ACriticalReviewandGuidelines. arXivpreprintarXiv:2002.07764 (2020).
[5]Jonathan Bell, Owolabi Legunsen, Michael Hilton, Lamyaa Eloussi, Tifany Yung,
and Darko Marinov. 2018. DeFlaker: Automatically detecting flaky tests. In 2018
IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE,
433–444.
[6]Adam Brinckman, Kyle Chard, Niall Gaffney, Mihael Hategan, Matthew B Jones,
KacperKowalik,SivakumarKulasekaran,BertramLudäscher,BryceDMecum,
Jarek Nabrzyski, et al .2019. Computing environments for reproducibility: Cap-
turingthe“WholeTale”. FutureGenerationComputerSystems 94(2019),854–867.
[7]Robert J Brunner and Edward J Kim. 2016. Teaching data science. Procedia
Computer Science 80 (2016), 1947–1956.
[8]Haipeng Cai, Ziyi Zhang, Li Li, and Xiaoqin Fu. 2019. A Large-Scale Study of
ApplicationIncompatibilitiesinAndroid.In The28thACMSIGSOFTInternational
Symposium on Software Testing and Analysis (ISSTA 2019).
[9]Zhifei Chen, Lin Chen, Yuming Zhou, Zhaogui Xu, William C Chu, and Baowen
Xu.2014.DynamicslicingofPythonprograms.In 2014IEEE38thAnnualComputer
Software and Applications Conference. IEEE, 219–228.
[10]Jürgen Cito, Vincenzo Ferme, and Harald C Gall. 2016. Using Docker contain-ers to improve reproducibility in software and web engineering research. In
International Conference on Web Engineering. Springer, 609–612.
[11]Conda.2019. Conda:Package,dependencyandenvironmentmanagementforanylanguage. (2019). RetrievedAugust23,2019fromhttps://docs.conda.io/en/latest/
[12]MichaelPFayandMichaelAProschan.2010. Wilcoxon-Mann-Whitneyort-test?
On assumptions for hypothesis tests and multiple interpretations of decision
rules.Statistics surveys 4 (2010), 1.
[13]freezegun.2019. LetyourPythonteststravelthroughtime. (2019). Retrieved
August 23, 2019 from https://pypi.org/project/freezegun/0.1.11/
[14]JesúsMGonzález-BarahonaandGregorioRobles.2012. Onthereproducibilityofempiricalsoftwareengineeringstudiesbasedondataretrievedfromdevelopment
repositories. Empirical Software Engineering 17, 1-2 (2012), 75–89.
[15]Eric Horton and Chris Parnin. 2019. DockerizeMe: automatic inference of en-
vironment dependencies for python code snippets. In Proceedings of the 41st
International Conference on Software Engineering. IEEE Press, 328–338.
[16]MaryBethKeryandBradAMyers.2018. InteractionsforUntanglingMessyHis-tory in a Computational Notebook. In 2018 IEEE Symposium on Visual Languages
and Human-Centric Computing (VL/HCC). IEEE, 147–155.
[17]MaryBethKery,MarissaRadensky,MahimaArya,BonnieEJohn,andBradA
Myers.2018. Thestoryinthenotebook:Exploratorydatascienceusingaliterate
programmingtool.In Proceedingsofthe2018CHIConferenceonHumanFactors
in Computing Systems. ACM, 174.
[18]Thomas Kluyver, Benjamin Ragan-Kelley, Fernando Pérez, Brian E Granger,Matthias Bussonnier, Jonathan Frederic, KyleKelley, Jessica B Hamrick,Jason
Grout,SylvainCorlay,etal .2016. JupyterNotebooks—apublishingformatfor
reproducible computational workflows. In ELPUB. 87–90.
[19]DonaldErvinKnuth.1984. Literateprogramming. Comput.J. 27,2(1984),97–111.
[20]PingfanKong,LiLi,JunGao,TegawendéFBissyandé,andJacquesKlein.2019.
Mining Android Crash Fixes in the Absence of Issue- and Change-Tracking
Systems. In The 28th ACM SIGSOFT International Symposium on Software Testing
and Analysis (ISSTA 2019).
[21]PingfanKong,LiLi,JunGao,KuiLiu,TegawendéFBissyandé,andJacquesKlein.2018. AutomatedTestingofAndroidApps:ASystematicLiteratureReview. IEEE
Transactions on Reliability (2018).
148[22]David Koop and Jay Patel. 2017. Dataflow notebooks: encoding and tracking
dependenciesofcells.In 9th{USENIX}WorkshopontheTheoryandPracticeof
Provenance (TaPP 2017).
[23]Li Li, Tegawendé F Bissyandé, Haoyu Wang, and Jacques Klein. 2018. CiD:
Automating the Detection of API-related Compatibility Issues in Android Apps.
InTheACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis
(ISSTA 2018).
[24]ThePythonStandardLibrary.2019. Build-inFunctions. (2019). RetrievedAugust
23, 2019 from https://docs.python.org/3/library/functions.html
[25]QingzhouLuo,FarahHariri,LamyaaEloussi,andDarkoMarinov.2014. Anempir-
ical analysis of flaky tests. In Proceedings of the 22nd ACM SIGSOFT International
Symposium on Foundations of Software Engineering. 643–653.
[26]Guillermo Macbeth, Eugenia Razumiejczyk, and Rubén Daniel Ledesma. 2011.
Cliff’s Delta Calculator: A non-parametric effect size program for two groups of
observations. Universitas Psychologica 10, 2 (2011), 545–555.
[27]AudrisMockus, BenteAnda,andDagIKSjøberg. 2010. Experiences fromrepli-
cating a case study to investigate reproducibility of software development. In
Proceedings of the 1st International Workshop on Replication in Empirical Software
Engineering Research.
[28]Robert O’Callahan, Chris Jones, Nathan Froyd, Kyle Huey, Albert Noll, and
NimrodPartush.2017. Engineeringrecordandreplayfordeployability.In 2017
USENIX Annual Technical Conference (USENIX ATC 17). 377–389.
[29]Keith O’Hara, Douglas Blank, and James Marshall. 2015. Computational note-
books for AI education. In The Twenty-Eighth International Flairs Conference.
[30]Fabio Palomba and Andy Zaidman. 2019. The smell of fear: On the relation
between test smells and flaky tests. Empirical Software Engineering 24, 5 (2019),
2907–2946.
[31]Hemant D. Pande, William A Landi, and Barbara G. Ryder. 1994. Interprocedural
def-use associations for C systems with single level pointers. IEEE Transactions
on Software Engineering 20, 5 (1994), 385–403.
[32]Jeffrey M. Perkel. 2018. Why Jupyter is data scientists’ computational notebook
of choice. Nature news 563 (2018), 145–146.
[33]JoãoFelipePimentel,LeonardoMurta,VanessaBraganholo,andJulianaFreire.
2019. A large-scale study about quality and reproducibility of Jupyter notebooks.
InProceedingsofthe16thInternationalConferenceonMiningSoftwareRepositories.
IEEE Press, 507–517.
[34]Ernest Pobee and WK Chan. 2019. AggrePlay: efficient record and replay of
multi-threadedprograms.In Proceedingsofthe201927thACMJointMeetingon
European Software Engineering Conference and Symposium on the Foundations of
Software Engineering. 567–577.
[35]PythonClock.2019. Python2.7Countdown. (2019). RetrievedAugust23,2019
from https://pythonclock.org
[36]Min Ragan-Kelley, F Perez, B Granger, T Kluyver, P Ivanov, J Frederic, and M
Bussonnier. 2014. TheJupyter/IPython architecture: aunified view ofcomputa-
tional research, from interactive exploration to communication and publication..
InAGU Fall Meeting Abstracts.
[37]Bernadette M Randles, Irene V Pasquetto, Milena S Golshan, and Christine LBorgman. 2017. Using the Jupyter notebook as a tool for open science: An
empiricalstudy.In 2017ACM/IEEEJointConferenceonDigitalLibraries(JCDL).
IEEE, 1–2.
[38]Mohammed Suhail Rehman. 2019. Towards Understanding Data Analysis Work-
flows using a Large Notebook Corpus. In Proceedings of the 2019 International
Conference on Management of Data. ACM, 1841–1843.
[39]ZhileiRen,HeJiang,JifengXuan,andZijiangYang.2018. Automatedlocalization
for unreproducible builds. In Proceedings of the 40th International Conference onSoftware Engineering. ACM, 71–81.
[40]Zhilei Ren, Changlin Liu, Xusheng Xiao, He Jiang, and Tao Xie. [n. d.]. Root
CauseLocalizationforUnreproducibleBuildsviaCausalityAnalysisoverSystem
Call Tracing. ([n. d.]).
[41]Gema Rodríguez-Pérez, Gregorio Robles, and Jesús M González-Barahona. 2018.
Reproducibility and credibilityin empirical software engineering:A case study
basedonasystematicliteraturereviewoftheuseoftheSZZalgorithm. Informa-
tion and Software Technology 99 (2018), 164–176.
[42]HéctorRodríguez-Pérez,TamaraHernández-Beeftink,JoséMLorenzo-Salazar,
JoséLRoda-García,CarlosJPérez-González,MarcosColebrook,andCarlosFlores.
2019. NanoDJ: aDockerizedJupyternotebookfor interactiveOxfordNanopore
MinION sequence manipulation and genome assembly. BMC bioinformatics 20, 1
(2019), 234.
[43]Adam Rule, Amanda Birmingham, Cristal Zuniga, Ilkay Altintas, Shih-ChengHuang, Rob Knight, Niema Moshiri, Mai H Nguyen, Sara Brin Rosenthal, Fer-nandoPérez,etal
.2018. TensimplerulesforreproducibleresearchinJupyter
notebooks. arXiv preprint arXiv:1810.08055 (2018).
[44]Adam Rule, Amanda Birmingham, Cristal Zuniga, Ilkay Altintas, Shih-ChengHuang, Rob Knight, Niema Moshiri, Mai H Nguyen, Sara Brin Rosenthal, Fer-
nando Pérez, et al .2019. Ten simple rules for writing and sharing computational
analyses in Jupyter Notebooks. (2019).
[45]Adam Rule, Ian Drosos, Aurélien Tabard, and James D Hollan. 2018. Aidingcollaborative reuse of computational notebooks with annotated cell folding.
Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 150.
[46] Adam Rule, Aurélien Tabard, and James D Hollan. 2018. Exploration and expla-
nation in computational notebooks. In Proceedings of the 2018 CHI Conference on
Human Factors in Computing Systems. ACM, 32.
[47]Onur Sahin, Assel Aliyeva, Hariharan Mathavan, Ayse Coskun, and Manuel
Egele. 2019. RANDR: Record and Replay for Android Applications via Targeted
Runtime Instrumentation. In 2019 34th IEEE/ACM International Conference on
Automated Software Engineering (ASE). IEEE, 128–138.
[48]SheebaSamuelandBirgittaKönig-Ries.2018. ProvBook:Provenance-basedSe-
manticEnrichmentofInteractiveNotebooksforReproducibility..In International
Semantic Web Conference (P&D/Industry/BlueSky).
[49]Helen Shen. 2014. Interactive notebooks: Sharing the code. Nature News 515,
7525 (2014), 151.
[50]Diomidis Spinellis. 2003. The decay and failures of web references. Commun.
ACM46, 1 (2003), 71–77.
[51]Dan Toomey. 2017. Jupyter for data science: Exploratory analysis, statistical
modeling,machinelearning,anddatavisualizationwithJupyter. PacktPublishing
Ltd.
[52]Jiawei Wang, Li Li, and Andreas Zeller. 2020. Better Code, Better Sharing: On
theNeedofAnalyzingJupyterNotebooks.In The42ndInternationalConference
on Software Engineering, NIER Track (ICSE 2020).
[53]Alex Watson, Scott Bateman, and Suprio Ray. 2019. PySnippet: AcceleratingExploratory Data Analysis in Jupyter Notebook through Facilitated Access to
Example Code.. In EDBT/ICDT Workshops.
[54]DasarathWeeratunge,XiangyuZhang,andSureshJagannathan.2010. Analyzing
multicoredumpstofacilitateconcurrencybugreproduction.In Proceedingsof
thefifteenthInternationalConferenceonArchitecturalsupportforprogramming
languages and operating systems. 155–166.
[55]Ziv Yaniv, Bradley C Lowekamp, Hans J Johnson, and Richard Beare. 2018. Sim-
pleITKimage-analysisnotebooks:acollaborativeenvironmentforeducationand
reproducible research. Journal of digital imaging 31, 3 (2018), 290–303.
149