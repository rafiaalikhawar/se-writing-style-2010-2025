DeepAnalyze: Learning to Localize Crashes at Scale
Manish Shetty
t-mamola@microsoft.com
Microsoft Research
Bangalore, IndiaChetan Bansal
chetanb@microsoft.com
Microsoft Research
Redmond, USASuman Nath
sumann@microsoft.com
Microsoft Research
Redmond, USASean Bowles
sbowl@microsoft.com
Microsoft
Redmond, USA
Henry Wang
hewang@microsoft.com
Microsoft
Redmond, USAOzgur Arman
oarman@microsoft.com
Microsoft
Redmond, USASiamak Ahari
sahari@microsoft.com
Microsoft
Redmond, USA
ABSTRACT
Crash localization, an important step in debugging crashes, is chal-
lengingwhendealingwithanextremelylargenumberofdiverse
applications and platforms and underlying root causes. Large-scale
error reporting systems, e.g., Windows Error Reporting (WER),
commonlyrelyonmanuallydevelopedrulesandheuristicstolo-
calizeblamed frames causing the crashes. As new applications and
features are routinely introduced and existing applications are run
undernewenvironments,developingnewrulesandmaintaining
existing ones become extremely challenging.
Weproposeadata-drivensolutiontoaddresstheproblem.We
start with the first large-scale empirical study of 362 ğ¾crashes and
their blamed methods reported to WER by tens of thousands of ap-
plicationsrunninginthefield.Theanalysisprovidesvaluablein-
sights on where and how the crashes happen and what methods to
blame for the crashes. These insights enable us to develop Deep-
Analyze, a novel multi-task sequence labeling approach for identi-
fyingblamedframesinstacktraces.Weevaluateourmodelwith
overamillionreal-worldcrashesfromfourpopularMicrosoftap-
plicationsandshowthatDeepAnalyze,trainedwithcrashesfrom
one set of applications, not only accurately localizes crashes of the
sameapplications,butalsobootstrapcrashlocalizationforother
applications with zero to very little additional training data.
ACM Reference Format:
Manish Shetty, Chetan Bansal, Suman Nath, Sean Bowles, Henry Wang,
Ozgur Arman, and Siamak Ahari. 2022. DeepAnalyze: Learning to Localize
CrashesatScale.In 44thInternationalConferenceonSoftwareEngineering
(ICSE â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3510003.3512759
1 INTRODUCTION
When software crashes in the wild, often the primary sources of
information available for debugging are crash stacks â€“ stack traces
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3512759collectedduringthecrashes[ 47].Acrashstackcontainswhatmeth-
ods were executing during a crash. It may also contain other valu-
able information such as executed binaries and code locations that
can hint as to what might have caused the crash. Due to its im-
portance,manyerrorreportingsystems,e.g.,WindowsErrorRe-
porting (WER) [ 16], Apple Crash Reporter [ 4], Mozilla Crash Re-
porter [42], Chrome Crash Reporter [ 12], have been deployed to
automatethe collectionof crashstacks (alongwith otherinforma-
tion,suchasmemorydumps).Animportantstepininvestigatinga
crashiscrashlocalization:identifyingthemethodinthecrashstack
that contains, or is the closest to,1the crash location. We denote
such a method as the blamed method, and the stack frame contain-
ing it as the blamed frame. Blamed methods play an important role
inorganizingcrashreportsintoâ€œbucketsâ€(i.e.,categories),whichin
turn help developers prioritize frequently seen buckets [ 16]. More-
over, investigation of a crash often starts from the blamed method
as it helps developers isolate the crash location.
Crash localization needs to be automated in large-scale error re-
porting systems, such as WER, as they receive millions of crash
reports per day [ 16]. A common practice [ 16,53] is to use a collec-
tionofmanuallywrittenheuristicssuchasâ€œNevermark Foo()asa
blamedmethodâ€,â€œ Bar()canbeablamedmethodonlyifthesymbol
Bazappearsinthecrashstackâ€,andsoon.Thesystemthenscans
through the frames of a crash stack to identify a blamed method
that is consistent with these rules. Ideally, the rules should be con-
sistent(i.e.,notcontradictory)witheachother,andhavegoodaccu-racyandcoverage.Thisisnontrivialforlargeandevolvingsystems;
whenanewfeatureorapplicationisintroduced,someonewithgood
domainknowledgeneedstowritenewapplication-specificrules.
WER currently has 50+ such application-specific libraries of rules.
Prior work in crash analysis has heavily focused on crash buck-
etization [ 14,16,54]. But, in order to do effective bucketization,
crash localization is critical. Wu et al. [ 59] proposed CrashLoca-
tor which leverages source code along with the static call graph
forcrashlocalization.However,thisisnotfeasibleatthescaleof
WER that needs to localize crashesfor a multitude of applications
inthewild.Thispaperaddressestheselimitationswithafreshdata-
driven approach. Inspired by the abundance of data in existing er-
ror reporting systems and recent advancement in deep learning
techniques,wedemonstratehowtolearnfrompastcrashestoiden-
tify the blamed method in a new crash stack with high accuracy.
1When a stack trace does not contain the true crash location [ 19], we consider identi-
fying the method closest to the crash location in caller-callee relationship.
5492022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Manish Shetty, Chetan Bansal, Suman Nath, Sean Bowles, Henry Wang, Ozgur Arman, and Siamak Ahari
0
1
2
3
4
5
6
7msedge_elf.dll!crash_reporter::DumpWithoutCrashing
msedge.dll!base::debug::DumpWithoutCrashing
msedge.dll!gl::DirectCompositionChildSurfaceWin::ReleaseDrawTexture
msedge.dll!gl::DirectCompositionChildSurfaceWin::SwapBuffers
msedge.dll!gl::DirectCompositionChildSurfaceWin::SwapBuffers
msedge.dll!gl::GLSurfaceAdapter::PostSubBuffer
msedge.dll!gpu::PassThroughImageTransportSurface::PostSubBuffer
...
(a) Crash stack 10
1
2
3
4
5
6
7igd10iumd64.dll!OpenAdapter10_2
d3d11.dll!NDXGI::CDevice::RotateResourceIdentities
dxgi.dll!CDXGISwapChain::PresentImplCore
dxgi.dll!CDXGISwapChain::PresentImpl
dxgi.dll!CDXGISwapChain::[IDXGISwapChain4]::Present1
msedge.dll!gl::DirectCompositionChildSurfaceWin::ReleaseDrawTexture
msedge.dll!gl::DirectCompositionChildSurfaceWin::SwapBuffers
...
(b) Crash stack 2
Figure 1: Examples of crash stacks from Microsoft Edge and their crash locations (red frame)
As a first step towards our data-driven approach, we analyze
â‰ˆ362ğ¾crash stacks collected by WER from â‰ˆ8.7ğ¾software com-
ponents. Our analysis highlights the huge diversity of crash stacks:
theycomefrommanydifferentfirstandthirdpartybinaries,and
from many different methods and namespaces within each binary.
The underlying problem classes, which denote high level root cause
typessuchasheapcorruptionorstackoverflow,arealsodiverse.
Finally, a crash trace often contains many methods, only one of
whichneedstobeidentifiedastheblamedmethod.Alloftheabove
highlightthechallengesofmanuallydevelopingandmaintaining
application-specific crash-localization heuristics.
Ouranalysisalsoprovidesseveralinsightsthatguideourchoice
of an effective machine-learning solution. We first tried a linear
binary classifier (Logistic Regression) that, given features of an in-
dividualframe,predictsthelikelihoodofitbeingtheblamedframe.
AsweshowinSection5.1,thissimplemodel,however,didnotwork
wellformanyproblemclasses.Uponfurtheranalysisofourdataset,
wefoundthat thecontextinwhichamethodappearsinacrashstack
(e.g., methods that appear before and after it) plays an important role
in it being a blamed method or not. Consequently, a method can be
the blamed method in one crash stack but not in another. This is il-
lustrated with two crash traces from Microsoft Edge, shown in Fig-
ure1.BoththetracescontainEdgeâ€™smethod ReleaseDrawTexture ,
butWERidentifiesitastheblamedmethodonlyforthefirsttrace.Inthefirsttrace,methodsaround
ReleaseDrawTexture arerelatively
less crash-prone based on their past history (e.g., the logging meth-
odsabove it).Inthesecond trace,however, ReleaseDrawTexture
hasmorecrash-pronemethodsfromausermodeIntelgraphicsdri-
ver, one of which is blamed by WER.
We use this insight on the importance of context in a novel
formulation of crash localization as sequence labeling. Sequence
labeling,widelyusedinnaturallanguageprocessing,usescontexttoassignacategoricallabel(e.g.,partsofspeech)toeachmemberofasequence.Inourformulation,wetreatacrashstackasasequenceofframesandaimtoassigntoeachframeabinarycategoryindicating
whetheritisablamedframeornot.But,applyingsequencelabeling
to crash localization requires addressing several challenges.
First, like many other machine learning tasks, we need to select
agoodsetoffeaturesandasuitablemodelthatcancapturecontext.
Here, we revisit our data analysis to seek insights. Our analysis
shows that even though a stack trace may contain many methods,
only a small number of them are likely to be a crash location, e.g.,
methods that appear towards the top of the stack, have global
semanticimportance,andthatareimplementedinapplicationcode
ratherthantheunderlyingsystem.Wethereforeextractfeatures
Figure 2: An overview of WER
that summarize these properties of a stack frame. We also observe
thatcontextforaframedependsonthecallchainthroughwhich
itisinvoked.Wecapturethissequentialcontextflowinthestack
usingaBi-directionalLongShort-termMemory(Bi-LSTM)layer
[21] that interprets the stack both top-down and bottom-up.
Second, traditional sequence labeling may label multiple tokens
withthesamecategory.Inourcontext,however,onlyoneframe
in a stack trace can be blamed. To address this, we first use an
attentionmechanism[ 5]toidentifysectionsofastacktracethat
aremorelikelytocontainthecrashlocation.Then,wemodelthe
frame-level labeling task jointly using linear chain ConditionalRandom Fields (CRF) [
27]. Finally, to tackle constantly evolving
software,itisimportantthatmodelslearnedfromcrashesinone
setof applications areusefulnotonly forthose,butalso forother
applications, e.g., newly released ones that have very little training
data. We propose a transfer learning approach to achieve this goal.
In this work, we present and package our models in a system
calledDeepAnalyze â€“ a deep learning based solution for large-
scalecrashlocalization.WehaveevaluatedDeepAnalyzewithover
amillionreal-worldcrashstacksfromfourpopularMicrosoftap-
plications (Edge, Word, Excel, and Outlook). Our results show that
DeepAnalyzeâ€™snovelmulti-tasksequencelabelingapproachhasan
average accuracy of 0.9 and it outperforms several baselines. Also,
we show that using transfer learning, our model, learned from one
set of applications, can also be effectively ( â‰ˆ0.8 accuracy) used for
completelynewandunseenapplicationswithnonewtrainingdata.
Lastly, we show that these models can be easily fine-tuned to new
applications, where the accuracy quickly approaches â‰ˆ0.9 with as
little as a few thousands additional training samples.
In summary, we make the following contributions:
(1)Weconductthefirstlarge-scaleempiricalstudyofcrashes
in the wild, and discuss new insights about crash sources,
problem types and characteristics of their blamed methods.
550
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DeepAnalyze: Learning to Localize Crashes at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
(a) Top-25 crashing binaries
 (b) Top-100 software component types
Figure 3: Distribution of crashing binaries and software components
(2)WeproposeDeepAnalyze,anovelMulti-tasklearningbased
approach for crash localization only using stack traces.
(3)We evaluate DeepAnalyze on 4 popular Windows applica-
tionsshowingthatithasanaverageaccuracyof0.9andout-
performs several baselines.
(4)Weleveragetransferlearninganddemonstratethatwitha
smallamountofdata,wecanlocalizecrashesfornew/unseen
applications with high accuracy.
2 BACKGROUND
2.1 Windows Error Reporting
Releasedsoftwareoftencontainsbugsthatcausethesoftwareto
crashinthefield.Toautomatecollectingcrashinformation,large
software companies deploy error reporting systems. For example,
Microsofthasbuiltadistributederror-reportingsystemcalledWin-
dows Error Reporting (WER) [ 1,16], which has been in operation
forovertwodecadesnow.WhenaMicrosoftsoftware(suchasWin-
dows,Word,andEdge)crashesinthefield,withuserpermission,itsendstoWERa crashreport.Acrashreportcontainscrashstacks,in-
formationofthecrashedapplicationanditsruntime,andoptionally
a memory dump collected during the crash (Figure 2). So far, WER
hascollectedtensofbillionsofcrashreportsfrombillionsofdevices.
AkeyfunctionalityofWERistoassign bucketstothecrashes
sothatsimilarbugscande-duplicatedandtriagedtogether.Once
thenumberofcrashesinabuckethasexceededacertainthreshold,
a bug report is created and it is triaged to the appropriate devel-
operusingthebucketmetadata.Abucketisbasicallyasignature
to identify a unique bug. Here is an example of a bucket: MEM-
ORY_CORRUPTION_c0000005_contoso.exe!WriteToChild . It contains
the problem class, exception code and the blamed frame which
caused the crash. The bucket is computed by analyzing a crash re-
port, as described next.
2.2 Crash localization in WER
In order to analyze a crash report, WER uses !analyze [2], a de-
bugger extension which uses the call stack from the crash dump
alongwithmetadatasuchasloadedmodules,memorydumpand
exceptioncodetoidentifyblamedframeandtheunderlyingprob-
lem class that caused the crash (e.g., out of memory, stack over-
flow). !analyze has been built and maintained for more than two
decades,usingover200,000linesofcodeandhundredsofheuris-
tics written by domain experts. !analyze also provides an extensi-
bility mechanism that both Microsoft and external developers useto build plug-ins for extending or overriding the default logic with
application-specific rules. !analyze currently has 50+ such exten-
sions. The extensions can be nontrivial. For example, the extension
for Edge consists of over 2K LOC!
!analyze sourcecodehasbeenthroughmanyyearsofimprove-
ment and updates for analyzing different error codes and buckets.
Tounderstandthepainpointsof !analyze ,wetalkedtoseveralap-
plication owners. At present, the rules for crash report analysis are
required to be written into the code. This results in huge deploy-
ment overheads; for instance, updating or deploying new rules can
rangeanywherebetweenonetothreemonths.Further,therules
often tend to be very specific, and need to be updated as the ap-
plicationcodebaseevolves.Fornewapplications,theapplication
ownerand !analyze developersneedtoworktogethertoimple-
mentthelogicofthenewrulesintothecodebase.Also,bringing
up a new application is usually time consuming and requires deep
domainknowledgeof !analyze codebase.WithDeepAnalyze,our
goalistoeliminateorsignificantlysimplifythislaboriousandtime
consuming process with an agile and fast data-driven solution.
Table 1: Basic statistics of the dataset used in our study
# of crash stacks â‰ˆ362ğ¾
# of unique software components â‰ˆ8.7ğ¾
# of unique binaries â‰ˆ16.3ğ¾
# of unique namespaces â‰ˆ38ğ¾
# of unique methods â‰ˆ85ğ¾
# of unique blamed methods â‰ˆ18ğ¾
3 EMPIRICAL ANALYSIS OF CRASHES
In this section, we analyze a large collection of crashes collectedby WER to understand various properties of crash stacks. Our
datasetcontains362 ,249uniquecrashstacks,uniformlysampled
fromcrashescollectedbyWERina1w eekp eriod.Wealsostudy
properties of their problem classes and blamed frames/methods, as
determined by !analyze with its manually written heuristics.
3.1 Crash sources
WER collects crash stacks from thousands of applications devel-
oped by both Microsoft and non-Microsoft developers. Our sam-
pledatasetcontainscrashstacksfrom â‰ˆ16.3ğ¾binariesof â‰ˆ8.7ğ¾
softwarecomponents2,includingpopularMicrosoftapplications
2We use the term software component to denote various types of software systems
including user-mode applications, OS or infrastructure systems, libraries, drivers, etc.
551
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Manish Shetty, Chetan Bansal, Suman Nath, Sean Bowles, Henry Wang, Ozgur Arman, and Siamak Ahari
(a) Stack depth
 (b) Distinct binaries per stack
 (c) Avg stack depth for top-25 software components
Figure 4: Properties of crash stacks
suchasExcel,Word,Outlook,Edge,etc.Thecrashstacksinclude
â‰ˆ85ğ¾unique methods from â‰ˆ38ğ¾unique namespaces. Table 1
summaries the statistics.
Figure3showsdistributionsoftopbinariesandsoftwarecom-
ponents where crashes occur. The distribution has a long tail, with
most applications contributing a small fraction of crash stacks. As
shown in Figure 3 (a), there are only 10 binaries in our dataset,
each of which accounts for >1.5% (and the top binary accounts
forâ‰ˆ3%) of the total crashes. We also analyzed the types of top
100 software components in terms of their crash frequencies. As
showninFigure3(b),75%ofthemareuser-modeapplications(e.g.,
Microsoft Excel) or underlying systems (e.g., Windows Desktop
WindowManager(dwm)),withtheremaining25%beingdrivers,
libraries, and services. This shows that in a large-scale error re-
portingsystemlikeWER,crashstackscomefrommanydifferent
sources. Hence, application-specific mechanisms to identify blame
frames do not scale well.
Finding #1 â‡’Crash stacks come from many differ-
ent sources and hence application-specific crash local-
ization does not scale well.
3.2 Crash stacks
Stackdepth. Stackdepth(i.e.,numberofframesinthestack)atthe
timeofacrashindicateshowdeepthecrashhappens,intermsof
nestedmethodcalls.Figure4(a)showsthedistributionofthedepths
(i.e., number of frames) of all crash stacks in our dataset. Mean and
mediandepthsare16and9respectively.Whilemajorityhavefewer
than 10 frames, some stacks are very deep (maximum 255 frames).
Framesinastackmaycontainmethodsfrommultiplebinaries
when one binary calls methods from another. Figure 4 (b) shows
thedistributionofdistinctbinariesappearinginastack(average
â‰ˆ4). Multiple binaries in a stack indicate that crashes can happen
in binaries outside of the entry binary of an application.
Stack depthand softwaretypes. Stack depth varies a lot across
software components and their types. For example, we find that
device drivers usually have smaller stack depth (average â‰ˆ7) than
applications (average â‰ˆ11) and systems (average â‰ˆ18). This is
most likely because, compared to applications/systems, drivers are
lesscomplexintermsofthenumberofdependencies,andhence
tend to make fewer nested method calls. Figure 4 (c) shows theaverage stack depths of 25 most frequent software components.The average depths differs significantly (from 1 to 35) across these
software components.
Finding#2 â‡’Stack depthssignificantly differ across
software components and their types.
3.3 Problem classes and blamed frames
Problem classes. Figure 5a shows top 15 classes of problems that
causethecrashes.Weobtainproblemclassesfrom !analyze ,which
uses several heuristics to identify them from the exception context,
stacktraces,andotherinformationinthecrashdump.Asshown,
most ofthe key problemclasses are memoryrelated, for instance,
whentheapplicationistryingtoreadapointerthatpointstoin-
valid memory (INVALID_POINTER_READ) or is trying to read
a pointer that is null (NULL_POINTER_READ). These memory-
related classes account for 61% of all crashes. Another major prob-
lem category is APPLICATION_FAULT, which is the default class
when no more specific class could be identified.
Finding #3 â‡’Most (61%) of the crashes are caused
by memory-related errors.
Blamed frame location. Figure 5b shows the distribution of nor-
malized location of a blamed frame in its crash stack. Locations are
normalizedsothatthetopframeandthebottomframeinastack
have locations 0 and 1 respectively. As shown, frames at the top of
stacks are more likely to be blamed. More specifically, the topmost
frameisindeedtheblamedframein67%crashstacks.Intheremain-
ing 33% cases, however, blamed frame is not the top frame. An ex-
ample is shown in Figure 1 (a) where the third frame is the blamed
frame,andtoptwoframescorrespondtoharmlessloggingmethods.
Also, in 5% cases, blamed frame is at the bottom half of the stack.
Finding #4 â‡’Blamed frames are more likely to be
locatedatthetop ofthestack.In33%cases,however,
blamed frame is below the top frame.
Contextdependence. Canamethod,onceidentifiedastheblamed
method in a crash stack, always be blamed in other crash stacks? If
yes, one could easily identify the blamed method in a new crash
stackbymatchingitsmethodswithalistofknownblamedmethods
(blame-list). Does this simple blame-list-based approach work?
552
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DeepAnalyze: Learning to Localize Crashes at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
(a) Top-15 problem classes in crashes
 (b) Normalized crash location
 (c) Distribution of blame-ratio
Figure 5: Properties of problem classes and blame frames
To answer this, we compute blame ratio of methods. The blame
ratio of a method, is the ratio of the number of crash stacks where
the method is the blamed method, to the number of crash stacks
containingthemethod.Figure5cshowsthedistributionofblame
ratioinourdataset.Whilealargefractionofmethodshaveablame
ratioof1,asignificantfractionofmethodshaveblameratiosless
than1.Aratiolessthan1meansthatablamedmethodinonestack
maynotalwaysbeblamedinothercrashstacks,andhenceablame-
list-based approach would not work for these methods.
Whydosomemethodshaveblameratioslessthan1?Acloserex-
aminationrevealsthatwhetheramethodisindeedablamedmethod,oftendependsonits contextâ€“methodsthatappearinframesabove
andbelowit.Letâ€™sconsidertheexampleinFigure1again.Here,the
method ReleaseDrawTexture isidentifiedastheblamedmethod
inthefirstexamplewhereitappearsbelowtworelatively-harmlessloggingmethods.Ontheotherhand,thesamemethodisnotblamed
in the second example where more crash-prone driver methods ap-
pearaboveit.Theblamedframeâ€™sdependenceoncontextcanbeex-plainedbythefactthatframesinastackarenotindependent;rather,
they are ordered based on the caller-callee relationship of methods
intheframes.Thedatasuggeststhatwhetheramethodisblamedornotdependsonthecallchainthroughwhichitisinvoked.
Finding #5 â‡’Whether a method is blamed or not
oftendependsonthecontextitappearsin,i.e.,methods
that appear above and below it in the stack.
4 OUR APPROACH
In this section, we use the insights from Section 3 to design a data-
driven solution to the large-scale crash localization problem.
Our goal is to utilize large-scale historical crash data, consisting
ofcrashstacksandtheirlabelledblamedframes,tolearnmodels
that given a new crash stack can identify its blamed frame (and
method).Ourfirstattemptwastolearnalinearbinaryclassifier(e.g.,
Logistic Regression) that, given various features of an individual
frame,predictsthelikelihoodofitbeingtheblamedframe.Aswe
show in Section 5.1, this simple model, however, did not work well
for many problem classes. This is explained by one of our findings
inSection3:thecontextinwhichamethodappearsinacrashstack
(e.g.,methodsthatappearbeforeandafterit)playsanimportantrole
forittobeacrashmethodornot.WethereforeaimtobuildmodelsNatural Language Processing Crash Dump Analysis
Sentence: A sequence of words Stack: A sequence of frames
JohnlivesinSeattle ğ‘“0ğ‘“1ğ‘“2ğ‘“3
Sequence Labeling Crash Localization
John
PERlives
Oin
OSeattle
LOCğ‘“0
!BFğ‘“1
!BFğ‘“2
BFğ‘“3
!BF
Figure 6: Analogy between NLP and Crash Dump Analysis
and features thatcan effectively capture suchcontext. We achieve
this with a novel solution that formulates the crash-localization
task as a sequence labeling task, as described next.
4.1 Crash localization as sequence labeling
Sequencelabeling,wellexploredinNaturalLanguageProcessing
(NLP) [43], involves assigning a categorical label to each mem-
berofa sequenceofobservedvalues. Forexample,Named-Entity
Recognition[ 30,45,49], a sequence labeling task, can locate and
label entities in a sentence as predefined categories. It treats a sen-
tenceasasequenceofwordsandconsiderscontext,i.e.,surrounding
words,ofeachwordtoidentifyitscategory.Forexample,inFigure6,
thenamedentity Johnisidentifiedasa PersonandSeattleaLocation.
To formulate crash localization as sequence labelling, we con-
sideracrashstackasasequenceofframes,analogoustoasentenceanditsconstituentwords.Wethenperformsequencelabellingwith
abinarycategorylabel- BlameFrame and!BlameFrame.Thus,the
problemisformulatedasfollows: givenacrashstack(i.e.,asequence
of frames), label each frame with whether it is a blame frame or not.
For example, in Figure 6, the third frame ( ğ‘“2) is identified as the
BlameFrame (BF), while the rest are labeled !BlameFrame (!BF). For
traditionalsequencelabeling,onecanuseexistingmodelsthathave
been proposed previously. However, applying them to crash local-
ization requires addressing some unique challenges.
â€¢Whatfeaturestouse? Toaccuratelysummarizeacrashstack,
featuresneedtocapturebothsemanticsanddomain-specificinformation.So,wemakeuseofTf-Idf[
24,36]basedfeatures,
aswellasfeatureshighlightedbyourempiricalstudy,suchas
frame-depth, that are strongly correlated to crash locations.
553
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Manish Shetty, Chetan Bansal, Suman Nath, Sean Bowles, Henry Wang, Ozgur Arman, and Siamak Ahari
Table 2: Features to represent stack frames for crash localization
Feature Group Feature Name Description
Semantics namespace ğ‘›dimensional Tf-Idf vector of the namespace
method ğ‘›dimensional Tf-Idf vector of the method
T y pe so fC od e is_appname_in_frame Does the frame contain the applicationâ€™s name?
is_first_app_frame Is it the 1ğ‘ ğ‘¡frame with the applicationâ€™s name?
is_kernel_code Does the frame contain kernel code?
is_ntdll_code Does the frame contain ntdllcode?
is_exception_in_frame Does the frame contain an exception?
Other norm_frame_position Normalized position of the frame
is_method_unknown Is the method unknown?
is_method_empty Is the method empty?
is_binary_unknown Is the binary unknown?
is_empty_frame Is the entire frame empty?
â€¢How to blame exactly one frame? In traditional sequence
labeling,itispossibleformultipletokenstobelabeledasthe
samecategory;e.g.,sentencewithmultipleplaces.Inacrash
stack, however, there is only one blame frame, and hence,
we need appropriate models that satisfy such constraints.
Intherestofthesection,wedescribethedesignandarchitecture
of our DeepAnalyze model that addresses these challenges.
4.2 Model Features
Guidedbydomainexpertiseandourempiricalstudy,weengineered
featuresshowninTable2,fordata-drivenmodels.Thesefeatures
transform individual frames in the crash stack into real-valued
vectorsthatcanbeusedbyourmodels.Thefeaturesaregeneric,
they apply to crashes across applications, and can be grouped into
the 3 broad types briefly described below:
Semantics: Thesefeaturesrepresenttheimportantcontentsofa
frame such as the namespace and method name. Here, we observe
thattoolssuchas !analyze [16]utilizealargelistofallow-listsand
heuristics to localize crashes deeper in the stack. Such approaches
do not consider the global semantics andrelevance of the function
in a frame, i.e., how a function contributes to the crash. To include
these semantics, we utilize a simple Term Frequency - Inverse
Document Frequency (Tf-Idf) vectorization method [ 24,36]. With
thisapproachweautomaticallyextractaweightedlistofimportant
tokens from namespaces and methods in frames.
T y p e so fC o d e : Code from applications (1 ğ‘ ğ‘¡and 3ğ‘Ÿğ‘‘party) are
more likely to have bugs and cause crashes, when compared to
to kernel code and core OS user-mode code [ 16]. To incorporate
suchinformation,weusefeaturesthatcheckthepresenceoftheapplicationâ€™s name in the frame (i.e. the binary name). We also
extractfeaturesthatrepresentkernelcode,coreOSmodules,and
exceptions. These features can help models de-prioritize frames
that are less likely to contain the root cause for crashes.
Other Information: AsshowninSection3,framesatthetopof
stacks aremore likely to beblamed.We thusutilize the normalized
framepositiontomodelhowdeepinthestackthecrashlocation
can be. Also, at times frames can be incomplete or have missing
symbolsinscenariossuchassome3 ğ‘Ÿğ‘‘partysoftware,andLinuxOScomponents or standard libraries. To de-prioritize such frames, we
use multiple boolean features that check for unknown and missing
information in the frame.
By transforming frames using the features described in Table 2,
a stack can now be visualized as a sequence of featurized frames.
4.3 DeepAnalyze Model
In the following subsections, we describe components of our multi-
task model, as shown in Figure 7, in detail.
4.3.1Model Overview .As our empirical analysis in Section 3
shows,whetherastackframeisblamedornotoftendependsonits
contextâ€“framesaboveandbelowit.Hence,whilemodeling,we
needtoconsidercontextflowinginbothdirectionsinthestackâ€“
top-downandbottom-up.Forthis,weutilizeaBi-directionalLSTM
(Bi-LSTM), that interprets the stack, both forwards and in reverse.
While, the BiLSTM can model sequential context flow, depen-
denciesbetweenframescanbewidelydistributedinthestack.Also,
asshowninSection3,weobservethatstackscanbeverylong,and
BiLSTMs can sometimes fail to handle long-range dependencies[
56]. To overcome these challenges, we implement an Attention
mechanism. Itfavours themodel toattend tosections ofthe stack
more likely to have the crash location.
With a Bi-LSTM and Attention layer, DeepAnalyze encodes
frames and stacks into robust neural representations that can be
usedtolocalizecrashes.Here,weseethatunlikesequencelabeling
for natural language, there is a constraint where we can only label
a single frame in the stack as the blame frame. To learn such struc-
tural constraints,we usea Conditional RandomFields (CRF)layer.
It is a discriminative classifier that models decision boundaries be-
tween labels in a sequence.
Lastly, contextforcrashlocalizationcanalso be externalinfor-
mationthatcomplements thestack.Specifically,symptoms (prob-
lem classes) associated with a crash, such as Invalid_Pointers ,
Zero_Division ,and Heap_Corruption .Forinstance,iftheprob-
lemwasa Stack_Overflow causedbytailrecursion,thenthestack
wouldcontainarepeatingsequenceofframes.Inthiscase,thecrash
canbequicklylocalizedbyattendingtotherepeatingpattern.Based
554
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DeepAnalyze: Learning to Localize Crashes at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Figure 7: DeepAnalyze Multi-Task Model Architecture
ontheseinsights,weutilizemulti-tasklearningtoperform problem
class prediction alongside the primary task - blame frame prediction.
4.3.2Bi-directional LSTM .Long Short-term Memory (LSTM)
networks[ 21]areatypeofRecurrentNeuralNetworks(RNNs)that
have been widely used to process sequential data in a variety of
taskssuchaslanguagemodelling[ 41,52],speechprocessing[ 46],
and codecomment generation[ 22]. Ittakes asequence of inputs
(ğ‘¥1,ğ‘¥2,...,ğ‘¥ğ‘›)as and return a sequence of vectors (â„1,â„2,...,â„ğ‘›)
that encodes information at every time step (i.e., frame level here).
In our scenario, a frame ğ‘“, receives context from other frames
thatoccuroneithersides.Weachievethisrepresentationusinga
secondLSTMlayerinterpretingthesequenceinreverse,i.e.,aBi-
DirectionalLSTM(Bi-LSTM)[ 18].Finally,eachframeisrepresented
by concatenating its left and right context, â„ğ‘“=[âˆ’ â†’â„ğ‘“;â† âˆ’â„ğ‘“].
4.3.3Attention Mechanism .Attentionmechanism[ 5,38]has
becomeakey componentofstate-of-the-artsolutionsto quantify
distributeddependenciesinsequences.Ithasbeenusedfortasks
like machinetranslation [5],sentiment classification [10],parsing
[32], and even image classification [ 58]. Here, we implement atten-
tion mechanism at the frame level with a learnable parameter ğ‘Šğ‘,
as described in Equations 1-3. It takes as input the hidden states
â„=[â„1,â„2,...,â„ğ‘‡]from the Bi-LSTM, and generates a weighted
context vector â„âˆ—of the stack. This weighting mechanism urges
themodeltofocusonsectionsofthestackthataremorelikelyto
have the crash location.
ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘ =ğ‘Šğ‘‡
ğ‘â„ (1)
ğ›¼=ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘ ) (2)
â„âˆ—=tanh(â„ğ›¼ğ‘‡) (3)4.3.4Conditional Random Fields .The above discussed layers
encode stack information into neural representations. Next, we
move on to labeling the crash location. Here, we could simply pre-
dictlabelsindependentlyforeachframe.Butweobservethatthis
disregards some structural constraints in our problem. Specifically,
unliketraditionalsequencelabeling,wecanonlylabeloneframe
as the crash location. To enforce such restrictions, we model the
frame level labeling task jointly using linear chain conditional ran-
dom fields (CRF) [ 27]. Given an input sequence ğ‘‹, the CRF layer
computes the probability of observing an output label sequence ğ‘¦,
i.e.,ğ‘(ğ‘¦|ğ‘‹):
ğ‘ (ğ‘‹,ğ‘¦)=ğ‘›/summationdisplay.1
ğ‘–=0ğ´ğ‘¦ğ‘–,ğ‘¦ğ‘–+1+ğ‘›/summationdisplay.1
ğ‘–=0ğ‘ƒğ‘–,ğ‘¦ ğ‘– (4)
ğ‘(ğ‘¦|ğ‘‹)=ğ‘’ğ‘ (ğ‘‹,ğ‘¦)
/summationtext.1
ğ‘¦/primeâˆˆğ‘Œğ‘’ğ‘ (ğ‘‹,ğ‘¦/prime)(5)
Here,ğ‘ƒis a probability matrix of shape ğ‘›Ã—ğ‘˜from the attention
layer, where ğ‘˜is the number of distinct tags and ğ‘›is the sequence
length.ğ´representsthematrixofscoresfortransitionsbetween
outputlabels.Finally,toextractlabels,thelayerpredictstheoutput
sequencewiththehighestprobability- ğ‘¦âˆ—=argmaxğ‘¦/primeâˆˆğ‘Œğ‘(ğ‘¦/prime|ğ‘‹).
Withthisapproachthemodellearnstoincludestructuralvalidity
in predicted output sequences.
4.3.5Multi-TaskLearning .Multi-TaskLearning(MTL)isanap-
proach to improve generalization in models using the inductive
bias in jointly learning related tasks [ 7]. In the context of classifica-
tion and sequence labeling, MTL improves performance of individ-
ual tasks by learning multiple tasks simultaneously [49].
In our scenario, the primary task for DeepAnalyze is crash lo-
calization. As stated before, we observe that localizing crashes not
only depends on the frames, but also on the class of problems that
mighthavecausedthecrash.Forinstance,acrashcausedduetoan
â€œInvalidPointerâ€wouldgenerallybelocalizedtothestackframes
doingmemoryandIOoperations.Consequently,wechooseprob-
lemclasspredictionasasecondarytaskforourmulti-taskmodel.
Particularly, as shown in Figure 7, we utilize a multi-head archi-
tecture toshare low level features (BiLSTMlayer). Then thearchi-
tecture splits into 2 task specific branches - one for blame frame
prediction and the other for problem class prediction.
For both tasks we use categorical cross entropy as the loss func-
tion.Wefirstcalculatelossindividuallyforbothobjectives,say ğ‘™1
andğ‘™2. We then compute and minimize a combined loss by aver-
aging:ğ‘™ğ‘œğ‘ ğ‘ ğ‘=(ğ‘™1+ğ‘™2)/2. During training, the objective we mini-
mizeisthecombined ğ‘™ğ‘œğ‘ ğ‘ ğ‘.But,duringback-propagation,wemake
suretouse theindividualtasklosses( ğ‘™1andğ‘™2)toupdateweights
oftask-specificbranchesofthenetwork(Figure7).Withsuchan
approach,thesharedlayer(BiLSTM)istrainedbybothtasks,be-
causeboth ğ‘™1andğ‘™2updateitviaback-propagation.Whereasthe
taskspecificlayers(AttentionandCRF)aretrainedonlyontheir
respective individual loss functions.
555
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Manish Shetty, Chetan Bansal, Suman Nath, Sean Bowles, Henry Wang, Ozgur Arman, and Siamak Ahari
4.4 Cross-Application Crash Localization
As stated in Section 2, hardcoding heuristics into code creates chal-
lengeswithscaleandgeneralizability forunknownfuturescenar-
ios.Softwareconstantlyevolvesasnewapplications,APIs,andpro-
gramminglanguagesareintroducedandbecomepopular.Handling
crashesinsuchnewcasesusuallyrequiresalotoftimeanddeep
domainknowledgetowritecustomrulesandpluginsforexisting
solutions.Here,learningamodelinstead,canhelpaddressthescal-
ability and generalizability challenges with ever growing software.
But, even with supervised machine learning, for a new appli-
cation,itisnontrivialtodevelopaccuratecrashlocalizationmod-
els,astherewouldbeminimallabeledtrainingdata.However,in
crashes,webelievethattherearemanypatternstobelearntthat
are common across applications; especially the large portion of
frames that represent the underlying system (see Figure 3(b)). This
implies that models trained on crashes from a global set of applica-
tions(source)canbeusedtolocalizecrashesforanewanddisjoint
set (target) â€” Cross-Application Crash Localization.
In this work, we use this to overcome the above mentioned
challenges with a TransferLearning andFine-tuning approach.
Formally,followingPanandYang[ 44],transferlearninginvolves
the concepts of a domain and a task. A domain Dconsists of 2
parts; a feature space Xand a marginal probability distribution
ğ‘ƒ(ğ‘‹)whereğ‘‹=ğ‘¥1,...,ğ‘¥ğ‘›âˆˆX. Given a specific domain, D=
{X,ğ‘ƒ(ğ‘‹)}, a taskThas 2 components; a label space Yand an
objective ğ‘“(Â·)(i.e.,ğ‘‡={Y,ğ‘“(Â·)}),thatcanbelearnedfromtraining
data. Given this, transfer learning is defined as:
Transfer Learning :Given a source domain Dğ‘†and learning task
Tğ‘†, target domain Dğ‘‡and learning task Tğ‘‡, transfer learning aims
toimprovethelearningofthetargetpredictivefunction ğ‘“ğ‘‡(Â·)inDğ‘‡
using the knowledge in Dğ‘†andTğ‘†, whereDğ‘†â‰ Dğ‘‡,o rTğ‘†â‰ Tğ‘‡.
Inourscenario,weobserve Dğ‘†â‰ Dğ‘‡,whereDğ‘†istheglobal
set of application crashes and the target Dğ‘‡is a new/unseen ap-
plicationâ€™scrashes.Specifically,weseethatthefeaturespace( X)
ofthesourceandtargetaresame,whilethemarginalprobability
distributions ğ‘ƒ(ğ‘‹)are different. This case is generally known as
â€œDomain Adaptationâ€ [ 15]. Withthat inmind, for cross-application
crashlocalization,wefirstpre-trainaDeepAnalyzemodelonalarge
datasetofcrashesspanningmultipleapplications(Globalmodel).
This model learns general and common information about crashes.
Then,foranewapplicationscenario,weusetransferlearningto
adapttheweightsofthisglobalmodeltotheapplicationofinterest
withminimal labeled data.In Section5, wetest ourhypothesis and
extensively evaluate this approach.
5 EVALUATION
Implementation. We have implemented DeepAnalyze and all
othermachinelearningmodelsdiscussedinthisworkinPython
3.7.7,withKeras-2.2.4andthetensorflow-1.15.0backend.These-
manticvectorizersareimplementedusingthestandardtf-idfvec-
torizer in scikit-learn. For our Bi-LSTM CRF based models, the
length of the sequence is limited to a maximum of 255, as collected
byWER.Also,thehiddenlayersizeissetto200cellsalongwith
adropoutof25%topreventoverfittingbyignoringrandomlyse-
lectedneuronsduringtraining.Further,weuseanearlystoppingTable 3: Evaluation of App-Specific Model Accuracy
Model Application Avg
Edge Excel Word Outlook
TopFrame 0.64 0.77 0.70 0.62 0.68
SecondFrame 0.24 0.07 0.10 0.13 0.13
MostFreqTopFrame 0.31 0.42 0.39 0.39 0.38
Logistic Regression 0.86 0.81 0.75 0.69 0.77BiLSTM-CRF-Attn 0.91 0.90 0.80 0.81 0.85DeepAnalyze 0.93 0.94 0.85 0.88 0.90
mechanism to stop training when model performance on a vali-
dationdatasetstartsto degrade.Lastly,ourmodels aretrainedon
an Ubuntu 16.04 LTS machine, with 24-core Intel Xeon E5-2690 v3
CPU (2.60GHz), 112 GB memory and 64-bit operating system. The
machine also has a Nvidia Tesla P100 GPU with 16 GB RAM.
Wenextconsidertwosettingsandevaluatethe accuracyofDeep-
Analyze:thefractionoftestcrashstacksforwhichDeepAnalyze
correctly identifies the blame frame.
5.1 Application-Specific Evaluation
We first consider an application-specific setting where the training
andtestdatacomefromthesameapplications.Thismakessense
when the target application has sufficient labelled training data.
Setup.We here use crash stacks from 4 popular client applications
fromMicrosoft- Edge,Excel,Word,andOutlook.Toevaluateina
realisticsetup,wetrainandtestourmodelsatdifferentpointsin
time.Webeginbycollectingasampleof â‰ˆ1.2millionusermode
crashesoftheseapplicationsoverawindowof2weeks.Foreach
application,weutilizedatafromthefirst11daysfortrainingand
next3daysfortesting(11:3 â‰ˆ80%:20%).Also,weuseacombined
hashofthestack,blamedframe,andothermetadatatode-duplicate
our datasets, avoiding multiple evaluations of the same problem.
Lastly, we establish ground truth using !analyze as used by WER.
We compare our multi-task model (described in Section 4.3)
againstmultipleheuristicsandmachinelearningbaselines.InTable
3,wereporttheaccuracy(ratioof#correctlylocalizedcrashesto
#total crashes) and evaluate models on 4 different applications.
Heuristic Baselines. First, we have a TopFrame baseline that al-
wayspicks the1ğ‘ ğ‘¡framein thestack. Thisisbased onthe insight
thatalargeproportionofcrashlocationsareatthetopofthestack.
But, we also observed that in some cases the top frame is an ex-
ception raised by the method below it. We represent this using
ourSecondFrame baselinethatalwayspicksthe2ğ‘›ğ‘‘frame.Next,
with MostFreqTopFrame ,weintroducetheuseoffrequentpatterns.
Thisbaselinepickstheframethatwasmostfrequentlyblamedin
the past. In caseof ties or unseen frames,it favours frames higher
inthestack.FromTable3,weseethattheseheuristicapproaches
perform well only on certain crashes and do not generalize well.
Linear Model. Next,we haveaLogisticRegression baseline.Itis
linearbinaryclassifierthat,givenfeaturesofanindividualframe
(described in Section 4.2), predicts the likelihood of it being the
blame frame. Then, we pick the frame in the stack with maximum
556
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DeepAnalyze: Learning to Localize Crashes at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Figure 8: Logistic Regression (LR) vs DeepAnalyze (DA)
likelihood.AsseeninTable3,thissimpledata-drivenmodelper-
forms better than naive heuristics (0 .77 avg accuracy). But, on fur-
theranalysis,wefoundthatthismodelperformspoorlyforspecific
problemclasses.Forinstance,inFigure8,weseethatfor CppEx-
ception and Stack Overflow, it correctly predicts only 30% of cases.
Here, we observed that such problems have diverse crashes where
amethodcanbeblamedinonecrashstackbutnotinanother.That
is, the logistic regression approach lacks in capturing context.
Sequence Labeling. Lastly,weevaluatemodelsthatincorporate
the missing context using our novel sequence labeling formula-
tion â€“ BiLSTM-CRF-Attn and DeepAnalyze. Here, we use BiLSTM-
CRF with attention mechanism as a baseline as it is a state-of-the-
art model for sequence labeling in NLP [ 28,37]. Also, note that
this BiLSTM-CRF-Attn model is similar to the DeepAnalyze model
architecture but without multi-task learning. As shown in Table
3, it achieves an average accuracy of around 0.85. Whereas, our
DeepAnalyzemulti-taskmodel(describedinSection4.3)achievesahigheraverageaccuracyof0.90andbeatsallbaselinesacrossappli-cations.Italsoreachesamaximumaccuracyof0.94forExcel.With
DeepAnalyze combining context information and complementary
informationusingmulti-tasklearning,weareabletooutperform
strongbaselinessuchasLogisticRegressionandBiLSTM-CRF-Attn.
Also, though in Figure 8 we mention only some problem classes,
we find that DeepAnalyze is always better than logistic regression.
Table 4: Significance of Improvements
Improvement
AreaApplication Avg
Edge Excel Word Outlook
Semantics 29% 5% 6% 10% 13%
Context 8% 15% 13% 24% 15%
Multi-Task 3% 4% 6% 9% 5%
Improvements. Table 4 shows the significance of important as-
pectsofourapproach,namelyframesemantics,contextdependence,andmulti-tasklearning.Wecomputesignificancebycalculatingthepercentagedifferenceinaccuracy(
ğ´)ofpairsofmodels;i.e., |ğ´ğ‘š1âˆ’
ğ´ğ‘š2|/ğ‘ğ‘£ğ‘”(ğ´ğ‘š1,ğ´ğ‘š2)Ã—100%. To capture significance of Semantics,
we compare Logistic Regression, that uses semantic features, with
the naive TopFrame baseline. As shown, introducing frame fea-
tures/semantics,generatesconsiderableimprovementsacrossappli-cations(average13%).Next,weevaluatethevalueof Context.Here,Table 5: Feature Importances
+ve feature Imp -ve feature Imp
method memory 1.0namespace std -1.0
namespace file0.73method error -0.76
method thread 0.49method exception -0.59
wecompareDeepAnalyze,acontext-awareapproach,toLogistic
Regression. The 8% âˆ’24% boosts achieved with our approach high-
lightstheimportanceofcontextincrashlocalization.Also,incor-
poratingcontextprovidesthelargestgainsonaverage(15%).Lastly,
DeepAnalyze leverages both context and complementary informa-
tion using multi-task learning. Thus, by comparing the multi-task
DeepAnalyzemodelwithBiLSTM-CRF-Attn,weseethatmulti-task
learning also provides notable increases in accuracy (average 5%).
WhatdoesDeepAnalyzelearn? TogaininsightintowhatDeep-
Analyzelearns,weuseamodelweightinspectiontechnique.Itis
commonly used to interpret black-box models in image processing
[25,29] and medical domains [ 40]. Here, we extract the weights of
the1ğ‘ ğ‘¡layerofDeepAnalyze,wherethereisadirectinteractionon
the raw inputs, to generate normalized feature importances. Table
5 summarizes the top-3 positive and negative features, all of which
aretf-idfsemanticfeatures.Asshown,DeepAnalyzeintelligently
learns that methods performing memory, file, and thread opera-
tionsarepositivefeaturesastheyworkwithpointersandtendto
causecrashes.ThisissupportedbyourempiricalanalysisinSec-
tion3onfrequentproblemclasses.Ontheotherhand,DeepAna-
lyzealsolearnstonegativelyassociatestandardlibraries(names-
pace std) and methods that raise errors/exception with crash loca-
tions, supporting our observation in Figure 3(b) that crashes are
relatively less frequent in libraries.
5.2 Cross-Application Evaluation
We now evaluate DeepAnalyze in a cross-application setting where
we have a recent/new application with minimal labeled crashes.
Forthis,weattempttoevaluatetheefficacyofourtransferlearning
approachforcross-applicationcrashlocalization(Section4.4).To
summarize,wehypothesisthatmodelslearntfromcrashesofasetof
applications can localize crashes in new/unseen applications. Here,
we evaluate our hypothesis on 2 target applications â€“ Edge&Excel.
Setup.We start with the dataset used in Section 3, consisting of â‰ˆ
362ğ¾crashstacksfrommanysoftwarecomponents,sampledovera
periodof1week.Tosimulateacross-applicationsetting,wechoose
a target application and remove all its associated crashes from our
dataset.Then,wetrainaDeepAnalyzemodel(GlobalModel)ontheresultantdatasetandtestoncrashesofthetarget(domaintransfer).Further,wefine-tuneourglobalmodeltothetargetapplicationwith
minimal labeled crashes. Similar to the application specific evalua-
tion in Section 5.1, for each target application, we utilize uniformly
sampled data from the first 11 days for fine-tuning and next 3 days
fortesting.Toevaluate,wecomparethistransferlearningapproach
against an application-specific DeepAnalyze model (Local Model).
Figure9showtheresultsofourexperimentsfor2targetapplica-
tions - Edge (left) and Excel (right). The Fine-Tune-Global (blue)
line indicates the accuracy of our global model on fine-tuning (i.e.,
our transfer learning approach). The From-Scratch-Local (red)
557
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Manish Shetty, Chetan Bansal, Suman Nath, Sean Bowles, Henry Wang, Ozgur Arman, and Siamak Ahari
0 100 200 500 1000 2000 5000 100000.30.40.50.60.70.80.91
#Training SamplesTest Accuracy
Fine-Tune-Global
From-Scratch-Local
0 100 200 500 1000 2000 5000 100000.30.40.50.60.70.80.91
#Training SamplesTest Accuracy
Fine-Tune-Global
From-Scratch-Local
Figure 9: Fine-tuning vs Training from scratch for Edge (left) and Excel (right)
line indicates the accuracy of an application-specific model trained
fromscratch.TheX-axishasthenumberofsamplesusedforfine-
tuning the global and training the local model, respectively.
Accuracy. As seen, for both Edge and Excel, our transfer learn-
ing approach significantly outperforms a local model trained from
scratch, at all amounts of training data. This is mainly because a
globalmodelreceivesasignificantheadstartbylearningsignalsand patterns in crashes that are application agnostic, and hence,
transferable.Specifically,weobservethatourglobalmodelachieves
high accuracies (0 .78 for Edge; 0 .84 for Excel), without observing a
singleapplication-specificcrash(@0trainingsamples).Thisshows
thatDeepAnalyzecanindeedlearnfromaglobalcrashdatasetto
effectivelylocalizecrashesinnew/unseenscenarios.Also,weob-
servethatourmodelsgraduallyimprovewithminimallabeleddata.
Forinstance,usingtransferlearning,weachieve â‰ˆ0.90accuracy
with as few as 1000-2000 samples, for both Edge and Excel. This
encourages that our transfer learning approach can be used in a
real-wordsetting,whereforanewapplicationatfirstwedirectly
useaglobalmodel.But,overtime,wewouldcollectapp-specific
labeled data and improve our models.
Cost Savings. Furthermore, during our experiments we observed
that transfer learning not only reduces training data requirements,
but also training time compared to application-specific models. To
evaluate, we make use of our Edge and Excel models trained on
large datasets in Section 5.1. Note, these models are comparabletothefine-tunedmodelsbecausetheyaretestedonthesamesetof crashes. These models took on average 3 hours to train andreceived an average accuracy of 0
.93. On the other hand, from
Figure 9, comparable global models ( â‰ˆ0.91 acc with 5000-10000
samples)tookonaverage10minutestobefine-tuned.Thatis,we
seenearly18 ğ‘‹reductionintrainingtime,andthuscomputecost,
with a transfer learning approach. This is particularly encouraging
of the usability of such an approach to quickly develop accurate
models for newly deployed scenarios.
6 RELATED WORK
Crash Analysis. Debugging and triaging of crashes at scale can
beexpensiveandintractable.Ourworkismostcloselyrelatedto
priorworkonlarge-scaleanalysisofrealworldsoftwarecrashes.
The Windows Error Reporting (WER) [ 16] distributed system was
builtbyMicrosoftforcollectingandanalyzingcrashtraces.WithDeepAnalyze,weleverageanovelmachinelearningbasedapproachforcrashlocalizationusingthecrashtracescollectedbyWERinthe
wild.Ourapproachnotonlygeneralizeswellforseveralexisting
applications but can also extend to new applications with verylimitedamountoflabelleddatausingtransferlearning.Wuetal.
[59]proposedCrashLocatorwhichusescallstackinformationin
the crash reports along with the static call graph information from
thesourcecodetopredicttheblameprobabilityofeachframein
the stack. In DeepAnalyze, since we are doing crash localizationat scale in the wild, we donâ€™t have access to the source code. So,
we only use the call stacks from the crash traces to do the crash
localization.Further,weleveragerecentadvancesinthemachine
learningandNLPdomainforcrashlocalization.Crashbucketization
is an important part of triaging crash reports. The WER system
leveragesmorethan500heuristicsforbucketing.Dangetal.[ 14]
proposed ReBucket which uses crash stack similarity to assignthem to appropriate buckets. Similarly, TraceSim [
55] leverages
TF-IDFandLevenshteindistanceoncrashreportsformeasuring
similarityofcrashtracesforbettertriagingandde-duplication.Our
work is complementary to these efforts since more precise crash
localization can aid with crash bucketization and triaging.
Multi-taskLearning. Multi-task Learning (MTL) [ 7,62] is a well-
studiedtechniqueinthemachinelearningcommunity.MTLisused
to improve the generalization and performance of ML models on a
given task by jointly training on other related tasks. MTL has been
utilizedinseveraldomainssuchasNLP[ 9,13,35,39,51],speech
[3,11,26,50,60] and healthcare [ 6,8,20,23,61]. In the NLP do-
main, Collobert et al. [ 13] proposed a novel convolutional network
architecture which uses MTL to jointly perform several NLP tasks
such as POS tagging, named-entity extraction and measuring se-
mantic similarity.
In the software engineering domain, MTL has been leveraged to
a limited extent. Prior work has heavily focused on using MTL for
building language models for source code [ 33,34,57] and software
artifactslikebugreportsanddiscussions[ 17,31,48,49].Wanget
al. [57] propose MulCode, a MTL based approach to learn a unified
representation of source code by jointly training on three tasks:
author attribution,comment classification andduplicate function
detection. Their evaluation show the efficacy of MTL by outper-
forming state of the approaches which addressed these tasks sepa-
rately.Tothebestofourknowledge,DeepAnalyzeisthefirsteffort
to use MTL in context of debugging. It leverages MTL to jointly
558
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. DeepAnalyze: Learning to Localize Crashes at Scale ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
perform crash localization and problem class identification from
crash stacks. Based on the experiments on several popular applica-
tions, MTL significantly boosts the accuracy.
7 DISCUSSION & CONCLUSION
In this paper, we proposed a novel data-driven solution to address
thecrash-localizationproblematscale.Wepresentedthefirstlarge-
scale empirical study of 362 ğ¾crashes and their blamed methods
reported to WER by many Microsoft applications running in the
wild. The analysis provides valuable insights on where and how
the crashes happen and what methods to blame for the crashes.
TheseinsightsenableustodevelopDeepAnalyze,anovelmulti-task
sequencelabelingapproachforidentifyingblamedframesinastack
trace. We evaluate our model with real-world crashes from four
popular Microsoft applications and show that DeepAnalyze, when
trained with crashes from one application, can not only accurately
localize crashes (with â‰ˆ90% accuracy) of the same application, but
alsobootstrapcrashlocalizationforotherapplicationswithzero
to very little training data. This makes DeepAnalyze a practical
solution to be used in the wild for a large number of applications.
As next step, we are planning to integrate DeepAnalyze with
the WER service along with a feedback loop. Using the feedbackprovided by developers, we will train DeepAnalyze in an onlinelearning setting. While in this work we tackle the fundamental
problemofcrashlocalization,systemslikeWERaidinvariousother
tasks. For instance, they also perform crash bucketization and root
cause hypothesis testing. Current solutions for these tasks, similar
tocrashlocalization,aremostlyrulebasedwhichdoesnotscaleand
generalizeeasilytonewscenarios.Lastly,wewillalsobelooking
at new problems like inter-crash dump correlation when there are
multipleOSrunningonasingledevice,suchasingamingconsoles.
Similarly,cross-platformandcross-OScrashlocalizationinadata
efficient manner is also critical. We plan to extend DeepAnalyze
to solve these challenges with the overarching goal of simplifying
debugging in the large.
REFERENCES
[1]2021. AboutWER. https://docs.microsoft.com/en-us/windows/win32/wer/about-
wer. Accessed: 2021-08-30.
[2]2021. Using the !analyze Extension. https://docs.microsoft.com/en-us/windows-
hardware/drivers/debugger/using-the--analyze-extension. Accessed: 2021-08-
30.
[3]AntoniosAnastasopoulosandDavidChiang.2018. Tiedmultitasklearningfor
neuralspeec h translation. arXiv preprint arXiv:1802.06655 (2018).
[4]Apple. 2010. Diagnosing Issues Using Crash Reports and Device
Logs. https://developer.apple.com/documentation/xcode/diagnosing-issues-
using-crash-reports-and-device-logs.
[5]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural ma-chine translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473 (2014).
[6]Jinbo Bi, Tao Xiong, Shipeng Yu, Murat Dundar, and R Bharat Rao. 2008. An
improvedmulti-tasklearningapproachwithapplicationsinmedicaldiagnosis.
InJointEuropeanConferenceonMachineLearningandKnowledgeDiscoveryin
Databases. Springer, 117â€“132.
[7] Rich Caruana. 1997. Multitask learning. Machine learning 28, 1 (1997), 41â€“75.
[8]RichCaruana,ShumeetBaluja,TomMitchell,etal .1996. Usingthefutureto"sort
out"thepresent:Rankpropandmultitasklearningformedicalriskevaluation.
Advances in neural information processing systems (1996), 959â€“965.
[9]Soravit Changpinyo, Hexiang Hu, and Fei Sha. 2018. Multi-task learning for
sequence tagging: An empirical study. arXiv preprint arXiv:1808.04151 (2018).
[10]PengChen,ZhongqianSun,LidongBing,andWeiYang.2017.Recurrentattention
network on memory for aspect sentiment analysis. In Proceedings of the 2017
conference on empirical methods in natural language processing. 452â€“461.[11]ZhuoChen,ShinjiWatanabe,HakanErdogan,andJohnRHershey. 2015. Speech
enhancementandrecognitionusingmulti-tasklearningoflongshort-termmem-
ory recurrent neural networks. In Sixteenth Annual Conference of the Interna-
tionalSpeec h Communication Association.
[12]Chromium.2020. ChromiumCrashPad,. https://chromium.googlesource.com/
crashpad/crashpad/+/refs/heads/main/README.md.
[13]Ronan Collobert and Jason Weston. 2008. A unified architecture for natural lan-
guage processing: Deep neural networks with multitask learning. In Proceedings
of the 25th international conference on Machine learning. 160â€“167.
[14]YingnongDang,RongxinWu,HongyuZhang,DongmeiZhang,andPeterNobel.
2012. Rebucket: A method for clustering duplicate crash reports based on callstack similarity. In 2012 34th International Conference on Software Engineering
(ICSE). IEEE, 1084â€“1093.
[15]Hal DaumeIII andDanielMarcu. 2006. Domainadaptation forstatistical classi-
fiers.Journal of artificial Intelligence research 26 (2006), 101â€“126.
[16]Kirk Glerum, Kinshuman Kinshumann, Steve Greenberg, Gabriel Aul, VinceOrgovan, Greg Nichols, David Grant, Gretchen Loihle, and Galen Hunt. 2009.
Debugginginthe(very)large:tenyearsofimplementationandexperience.In
Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles.
103â€“116.
[17]Xi Gong, Zhenchang Xing, Xiaohong Li, Zhiyong Feng, and Zhuobing Han.
2019. JointPredictionofMultipleVulnerabilityCharacteristicsThroughMulti-
TaskLearning.In 201924thInternationalConferenceonEngineeringofComplex
Computer Systems (ICECCS). IEEE, 31â€“40.
[18]Alex Graves and JÃ¼rgen Schmidhuber. 2005. Framewise phoneme classification
withbidirectionalLSTMandotherneuralnetworkarchitectures. Neuralnetworks
18, 5-6 (2005), 602â€“610.
[19]YongfengGu,JifengXuan,HongyuZhang,LanxinZhang,QingnaFan,Xiaoyuan
Xie, and Tieyun Qian. 2019. Does the fault reside in a stack trace? assisting
crash localization by predicting crashing fault residence. Journal of Systems and
Software148 (2019), 88â€“104.
[20]HrayrHarutyunyan,HrantKhachatrian,DavidCKale,GregVerSteeg,andAram
Galstyan.2019. Multitasklearningandbenchmarkingwithclinicaltimeseries
data.Scientific data 6, 1 (2019), 1â€“18.
[21]SeppHochreiterandJÃ¼rgenSchmidhuber.1997. Longshort-termmemory. Neural
computation 9, 8 (1997), 1735â€“1780.
[22]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code comment gener-ation.In2018IEEE/ACM26thInternationalConferenceonProgramComprehension
(ICPC). IEEE, 200â€“20010.
[23]SarfarazHussein,KunlinCao,QiSong,andUlasBagci.2017. Riskstratificationoflungnodulesusing3DCNN-basedmulti-tasklearning.In Internationalconference
on information processing in medical imaging. Springer, 249â€“260.
[24]Karen Sparck Jones. 1972. A statistical interpretation of term specificity and its
application in retrieval. Journal of documentation (1972).
[25]AndrejKarpathy,GeorgeToderici,SankethShetty,ThomasLeung,RahulSuk-
thankar, and Li Fei-Fei. 2014. Large-scale video classification with convolutional
neuralnetworks.In ProceedingsoftheIEEEconferenceonComputerVisionand
Pattern Recognition. 1725â€“1732.
[26]Suyoun Kim, Takaaki Hori, and Shinji Watanabe. 2017. Joint CTC-attentionbased end-to-end speech recognition using multi-task learning. In 2017 IEEE
international conference on acoustics, speechand signal processing (ICASSP). IEEE,
4835â€“4839.
[27]John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional
randomfields:Probabilisticmodelsforsegmentingandlabelingsequencedata.
(2001).
[28]GuillaumeLample,MiguelBallesteros,SandeepSubramanian,KazuyaKawakami,
and Chris Dyer.2016. Neural architectures fornamed entity recognition. arXiv
preprint arXiv:1603.01360 (2016).
[29]Honglak Lee, Roger Grosse, Rajesh Ranganath, and Andrew Y Ng. 2009. Convo-
lutional deep belief networks for scalable unsupervised learning of hierarchical
representations. In Proceedings of the 26th annual international conference on ma-
chine learning. 609â€“616.
[30]Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li. 2020. A survey on deep
learning for named entity recognition. IEEE Transactions on Knowledge and Data
Engineering (2020).
[31]Mingyang Li, Lin Shi, Ye Yang, and Qing Wang. 2020. A deep multitask learning
approach for requirements discovery and annotation from open forum. In 2020
35thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering(ASE).
IEEE, 336â€“348.
[32]Qi Li, Tianshi Li, and Baobao Chang. 2016. Discourse parsing with attention-based hierarchical neural networks. In Proceedings of the 2016 Conference on
Empirical Methods in Natural Language Processing. 362â€“371.
[33]FangLiu,GeLi,BolinWei,XinXia,ZhiyiFu,andZhiJin.2020. Aself-attentional
neural architecture for code completion with multi-task learning. In Proceedings
of the 28th International Conference on Program Comprehension. 37â€“47.
[34]FangLiu,GeLi,YunfeiZhao,andZhiJin.2020. Multi-tasklearningbasedpre-
trainedlanguagemodelforcodecompletion.In Proceedingsofthe35thIEEE/ACM
International Conference on Automated Software Engineering. 473â€“485.
559
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Manish Shetty, Chetan Bansal, Suman Nath, Sean Bowles, Henry Wang, Ozgur Arman, and Siamak Ahari
[35]PengfeiLiu,XipengQiu,andXuanjingHuang.2016.Recurrentneuralnetworkfor
textclassificationwithmulti-tasklearning. arXivpreprintarXiv:1605.05101 (2016).
[36]Hans Peter Luhn. 1957. A statistical approach to mechanized encoding and
searchingofliteraryinformation. IBMJournalofresearchanddevelopment 1,4
(1957), 309â€“317.
[37]Ling Luo, Zhihao Yang, Pei Yang, Yin Zhang, Lei Wang, Hongfei Lin, and Jian
Wang.2018. Anattention-basedBiLSTM-CRFapproachtodocument-levelchem-
ical named entity recognition. Bioinformatics 34, 8 (2018), 1381â€“1388.
[38]Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effec-tive approaches to attention-based neural machine translation. arXiv preprint
arXiv:1508.04025 (2015).
[39]Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. 2018.
Thenaturallanguagedecathlon:Multitasklearningasquestionanswering. arXiv
preprint arXiv:1806.08730 (2018).
[40]SaaedMehrabi,SunghwanSohn,DinghengLi,JoshuaJPankratz,TerryTherneau,
Jennifer L St Sauver, Hongfang Liu, and Mathew Palakal. 2015. Temporal pat-
ternandassociationdiscoveryofdiagnosiscodesusingdeeplearning.In 2015
International Conference on Healthcare Informatics. IEEE, 408â€“416.
[41]TomÃ¡Å¡ Mikolov, Martin KarafiÃ¡t, LukÃ¡Å¡ Burget, Jan ÄŒernock `y, and Sanjeev Khu-
danpur.2010. Recurrentneuralnetworkbasedlanguagemodel.In Eleventhan-
nual conference of the international speechcommunication association.
[42] Mozilla. 2012. Mozila Crash Reports,. http://crash-stats.mozilla.com/.[43]
NamNguyenandYunsongGuo.2007. Comparisonsofsequencelabelingalgo-
rithms and extensions. In Proceedings of the 24th international conference on Ma-
chine learning. 681â€“688.
[44]Sinno Jialin Pan and Qiang Yang. 2009. A survey on transfer learning. IEEE
Transactions on knowledge and data engineering 22, 10 (2009), 1345â€“1359.
[45]AdwaitRatnaparkhi.1996.Amaximumentropymodelforpart-of-speechtagging.
InConference on empirical methods in natural language processing.
[46]HasimSak,AndrewWSenior,andFranÃ§oiseBeaufays.2014. Longshort-term
memoryrecurrentneuralnetworkarchitecturesforlargescaleacousticmodeling.
(2014).
[47]Adrian Schroter, AdrianSchrÃ¶ter, Nicolas Bettenburg, and RahulPremraj. 2010.
Dostacktraceshelpdevelopersfixbugs?.In 20107thIEEEWorkingConference
on Mining Software Repositories (MSR 2010). IEEE, 118â€“121.
[48]Manish Shetty, Chetan Bansal, Sumit Kumar, Nikitha Rao, and NachiappanNagappan. 2021. SoftNER: Mining Knowledge Graphs From Cloud Incidents.
arXiv:2101.05961[cs.SE]
[49]ManishShetty,ChetanBansal,SumitKumar,NikithaRao,NachiappanNagappan,
and Thomas Zimmermann. 2021. Neural knowledge extraction from cloudservice incidents. In 2021 IEEE/ACM 43rd International Conference on Software
Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 218â€“227.[50]YusukeShinohara.2016. AdversarialMulti-TaskLearningofDeepNeuralNet-
worksforRobustSpeechRecognition..In Interspeech.SanFrancisco,CA,USA,
2369â€“2372.
[51]Sandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher J Pal.
2018. Learninggeneralpurposedistributedsentencerepresentationsvialarge
scale multi-task learning. arXiv preprint arXiv:1804.00079 (2018).
[52]MartinSundermeyer,RalfSchlÃ¼ter,andHermannNey.2012. LSTMneuralnet-
worksforlanguagemodeling.In Thirteenthannualconferenceoftheinternational
speechcommunication association.
[53]Ubuntu. 2008. Apport Crash Duplicates. https://wiki.ubuntu.com/
ApportCrashDuplicates.
[54]Rijnard van Tonder, John Kotheimer, and Claire Le Goues. 2018. Semantic crash
bucketing.In 201833rdIEEE/ACMInternationalConferenceonAutomatedSoftware
Engineering (ASE). IEEE, 612â€“622.
[55]RomanVasiliev,DmitrijKoznov,GeorgeChernishev,AleksandrKhvorov,Dmitry
Luciv, and Nikita Povarov. 2020. TraceSim: a method for calculating stack trace
similarity. In Proceedings of the 4th ACM SIGSOFT International Workshop on
Machine-LearningTechniques for Software-Quality Evaluation . 25â€“30.
[56]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanNGomez,ÅukaszKaiser,andIlliaPolosukhin.2017. Attentionisallyou
need.InAdvances in neural information processing systems. 5998â€“6008.
[57]Deze Wang, Yue Yu, Shanshan Li, Wei Dong, Ji Wang, and Liao Qing. 2021. Mul-
Code: A Multi-task LearningApproach for Source Code Understanding. In 2021
IEEE International Conference on Software Analysis, Evolution and Reengineering
(SANER). IEEE, 48â€“59.
[58]Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang,
Xiaogang Wang,and XiaoouTang.2017. Residualattention networkfor image
classification.In ProceedingsoftheIEEEconferenceoncomputervisionandpattern
recognition. 3156â€“3164.
[59]Rongxin Wu, Hongyu Zhang, Shing-Chi Cheung, and Sunghun Kim. 2014.
Crashlocator:Locatingcrashingfaultsbasedoncrashstacks.In Proceedingsof
the 2014 International Symposium on Software Testing and Analysis. 204â€“214.
[60]ZhizhengWu,CassiaValentini-Botinhao,OliverWatts,andSimonKing.2015.
Deep neural networks employing multi-task learning and stacked bottleneck
featuresforspeech synthesis. In 2015IEEEinternationalconferenceonacoustics,
speechand signal processing (ICASSP). IEEE, IEEE, Brisbane, 4460â€“4464.
[61]Daoqiang Zhang, Dinggang Shen, Alzheimerâ€™s Disease Neuroimaging Initiative,
et al.2012. Multi-modal multi-task learning for joint prediction of multiple
regression and classification variables in Alzheimerâ€™s disease. NeuroImage 59, 2
(2012), 895â€“907.
[62]Yu Zhang and Qiang Yang. 2021. A survey on multi-task learning. IEEE Transac-
tions on Knowledge and Data Engineering (2021).
560
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:56:15 UTC from IEEE Xplore.  Restrictions apply. 