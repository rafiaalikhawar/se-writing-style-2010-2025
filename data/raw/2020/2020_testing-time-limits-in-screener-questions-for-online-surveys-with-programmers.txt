Testing Time Limits in Screener Questions for Online Surveys
with Programmers
Anastasia Danilova
Universityof Bonn
danilova@cs.uni-bonn.deStefan Horstmann
Universityof Bonn
Stefan.Horstmann@gmx.net
Matthew Smith
University of Bonn, Fraunhofer FKIE
smith@cs.uni-bonn.deAlena Naiakshina
University of Bonn
naiakshi@cs.uni-bonn.de
ABSTRACT
Recruitingstudyparticipantswithprogrammingskillisessential
for researchers. As programming is not a common skill, recruiting
programmers as participants in large numbers is challenging. Plat-
forms like Amazon MTurk or Qualtrics offer to recruit participants
withprogrammingknowledge.Asthisisself-reported,participants
withoutprogrammingexperiencecouldstilltakepart,eitherdueto
amisunderstandingortoobtainthestudycompensation.Ifthese
participants are not detected, the data quality will suffer. To tackle
this, Danilova et al. [ 11] developed and tested screening tasks to
detect non-programmers. Unfortunately, the most reliable screen-
ers were also those that took the most time. Since screeners shouldtakeaslittletimeaspossible,weexaminewhethertheintroduction
of time limits allows us to create more efficient (i.e., quicker but
stillreliable)screeners.Ourresultsshowthatthisispossibleand
we extend the pool of screeners and make recommendations on
how to improve the process.
CCS CONCEPTS
•Human-centered computing →Empirical studies in HCI.
KEYWORDS
Developer Study; Methodology Developer Studies
ACM Reference Format:
Anastasia Danilova, Stefan Horstmann, Matthew Smith, and Alena Naiak-
shina. 2022. Testing Time Limits in Screener Questions for Online Surveys 
with Programmers. In 44th International Conference on Software Engineering 
(ICSE ’22), May 21–29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA,
11 pages. https://doi.org/10.1145/3510003.3510223
1 INTRODUCTION
User studies can be an important tool to examine the issues of
certain programs. However, recruiting participants for developer
studies may prove difficult, especially if  participants must possess
programming skills for the studies. In some cases, computer science
students are recruited for surveys and tests, yet researchers may
This work is licensed under a Creative Commons Attribution International 4.0 
License.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9221-1/22/05.
https://doi.org/10.1145/3510003.3510223alsoberequiredtorecruitprofessionals[ 10,24,26–28].Researchers
havebeenrecruitingprogrammersfromknownIT-firms[ 22,23],
local programming groups [2] or GitHub [1, 3, 18, 20, 31].
SomeonlineserviceslikeClickworker[ 9],Qualtrics[ 29]orAma-
zonMTurk[ 30]offerrecruitmentoptionsforonlinesurveyswith
thepossibilitytochooseparticipantswithprogrammingskills.How-
ever,astheskilllevelisonlyself-reported,participantsmaymisrep-
resenttheirprogrammingskillstoattainmonetarycompensation
or by accident. Whereas these participants would be identified rel-
atively quickly during practical tasks, online surveys may onlyinclude multiple-choice questions, and participants without pro-
grammingskillscanthreatenthevalidityofthesestudies.However,
these participants might be filtered out during the survey process,
using tasks that are easy to solve by programmers but difficultfor non-programmers. These tasks should make sense in an on-line survey and require as little time as possible to be solved by
programmers.
Sixteen multiple-choice questions have already been developed
and tested by Danilova et al. in [ 11]. They tested the tasks with
programmers and non-programmers. As “programmer,” we refer
to participants as defined by Danilova et al. [ 11]: participants with
programming skills from previous studies and participants who
haveworkedwithimperativeprogramminglanguages(e.g.,Java,C,Python).Theyalsosimulatedan attackscenario,whereparticipants
without programming skills should try to guess the correct results.
Thus,halftheparticipantsofthenon-programmerswereencour-
aged to use any help for solving the tasks. Requirements for the
tasks were ahigh success rate for programmersand a low success
rate for non-programmers, even in an attack scenario. In addition,
participants with programming skills should be able to solve thetasksrelativelyquickly.Danilovaetal.recommendedasetofsix
taskstobeusedforfilteringnon-programmersinonlinesurveys.
The most reliable screeners, however, were also those that took
the most time. Therefore, we investigated the research question:
Can the effectiveness of screening questions for non-programmers be
improved by introducing time constraints?
In this paper, we developed a large set of tasks and tested dif-
ferent time constraints to improve the tasks’ performance in anattack scenario. We analyzed which tasks performed well in pre-
vious work, trying to improve on them. In addition, we included
some tasks previously used as a filter in other computer science
publications,aswellasstrongperformingtasksfromDanilovaet
al. [11]. We explored the influence of different time constraints on
the correctness rate for programmers and non-programmers in an
20802022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSE’22,May21–29,2022,Pittsburgh,PA, USA Anastasia Danilova, Stefan Horstmann, Matthew Smith, and Alena Naiakshina
attempt to improve the effectiveness of the tasks as a filtering tool.
For this, we used three different time constraints: 1) prompting the
participantstosolvethetasksasquicklyaspossible,2)requiring
the participants to solve the tasks within a given time limit, and 3)
using a control group without any time constraints.
We tested the tasks with computer science students to decide
whethertimeconstraintscanbeaddedwithoutaffectingthepro-
grammers’taskperformance.Inaddition,weusedthissurveyto
filter out tasks with a low rate of correctness. We tested the re-
mainingtasks with non-programmersrecruitedonlinein atimed
attack scenario. We analyzed the influence of the time limit on
non-programmers by comparing them to the non-programmers
ofDanilovaetal.[ 11].Finally,wecomparedthesuccessrateand
therequired time to solve the tasks with programmers in a count-
downscenario.Basedontheresults,werecommendasetofwell-
performing tasks for researchers to be used in online surveys as
a filtering device. Danilova et al. [ 12] reported that the Qualtrics
recruitmentservicechargedforprogrammers2.87 €perminute(43 €
per15min).Consideringanexemplarysampleofn=100participants
andascreeningquestionof4minutes(themaximumaprogram-
mer needed in [ 11] for the code comprehension question), it would
yieldanadditionalcostof100*2.87*4=1148 €onlyforthescreening
question.Aswesuggestquestionswithamaximumtimelimitof
30seconds(143 €),thesavingoftheresearchbudgetisenormous(8
timesthe cost).
2 RELATED WORK
This section looks at the different recruitment options researchers
used in previous studies with software developers. Secondly, we
presentvariousstudieswhereparticipantswerefilteredbasedon
theirsoftwaredevelopmentskills.Lastly,wediscusstheworkdone
byDanilovaetal.[ 11]ingreaterdetailasthispaperbuildsontheir
results.
2.1 Recruitment
Inmanycases,researchersaimedtotargetonlysoftwaredevelopers
during the recruitment phase of their studies. One frequently used
siteisGitHub[ 16],whichisgenerallyusedtocontactdevelopers
usingtheservicesGitHubprovides[ 1,3,18,20,31].Forexample,
Graziotin et al. [ 20] contacted developers on GitHub and recruited
them for a study concerning the influence of worker happiness on
productivity. Additionally, Acar et al. [ 3] recruited GitHub partici-
pants for a study concerning developers’ performance regarding to
security-related tasks.
Otherresearcherscontactedcompaniesandrecruitedemployees
as participants. When Meyer et al. [ 22] did a study on job satisfac-
tionandproductivity,theyrecruitedallparticipantsfromMicrosoft
astoensurethatonlysoftwaredeveloperstookpartinthestudy.
Furthermore,in[ 23],Murhpy-Hilletal.recruitedparticipantsfrom
three different companies for a study about software developers’
productivity.
Furthermore, Baltes and Diehl [ 6] compared different recruit-
ment methods. They examined the recruitment of participants,
using a personal network of contacts, online communities and net-
works, reaching out to companies, public media as well as advertis-
ing the survey by software developers and GHTorrent [ 15], wheredata on public GitHub projects is collected. They recommended
usingpublicmediaandadvertisingthesurveybyothersoftwareen-
gineers as the most efficient strategies. They additionally proposed
to use crowdsourcing platforms (e.g., Clickworker [ 9], Amazon
Mechanical Turk [ 30]) and commercial recruitment services, but
also mentioned concerns regarding the suitability of those services
for therecruitment of software developers.
Anotherapproachusedfortherecruitmentofdeveloperswas
theusageoffreelanceplatformsforstudies[ 7,25,32,33].However,
YamashitaandMoonen[ 33]expressedconcernsregardingthere-
cruitment on the freelance platform Freelance.com [ 14] as all skills
areself-reportedbythemembers.They,therefore,suggestedthe
use of skill tests to validate research findings.
2.2 Programming skills
An instrument to evaluate the participants’ Java programming
skills was created and evaluated by Bergersen et al. [ 8], using a set
of 19 programming tasks. The purpose of the instrument was to
aidrecruitersinfindingthemostskilledprogrammersinagroup
of job applicants. They conducted a two-day study including 65
professional Java developers. However, time limits for the tasks
ranged from 10 to 45 minutes per task, making them too long to
includeinanonlinesurveyandthusarenotsuitableforfiltering
outparticipantsquickly.
Feigenspan et al. [ 13] used program comprehension tasks to
analyze the self-reported programming skills of 125 students. In a
surveytaking40minutes,theyfoundacorrelationbetweenthepar-
ticipants’performanceandtheirself-reportedlevelofexperience.
While some program comprehension tasks were used in this paper,
the goal was to identify participants without any programming
skillsinstead of measuring the skill level.
Balebako et al. [ 5] examined the security behavior of app devel-
opers. At first, participants for a semi-structured interview were
recruited through online postings, app developer meet-ups, and
the researchers’ social network. All participants had to fill out a
screeningsurveybeforeparticipating,withtwoquestionsdesigned
toverifytheparticipants’technicalknowledge.Inanonlinefollow-
upsurvey,participantswererecruitedindifferentonlineforums.
Participantswererequiredtopassknowledgeandattentionchecks.
Afterthescreening,232of460responseshadtobediscarded.Oneof
thetasksusedbytheauthorstofiltertheparticipantswastoaskpar-
ticipantstonameanIDEtheykneworhadpreviouslyworkedwith.
The researchers then validated their answers, which they noted to
be a difficult task due to many existing IDEs. Based on this, two
multiple-choicequestionsaskingforusedandknownprogramming
languageswereincludedinthispaper,withtheaddeddifference
that a number of fake programming languages was included in the
answer possibilities.
Acaretal.[ 2]conductedanonlinesurveyandalabstudycon-
cerning the effect of information resources on security during soft-
waredevelopment.Approximately50.000developers,whosecon-
tactinformationwasfoundonGooglePlay[ 17],weresentarecruit-
ment mail. Seven out of the 302 participants who completed the
survey had to be excluded due to invalid answers. No additional
methods to filter non-developers were applied. When recruiting
for the lab study, Acar et al. targeted participants who had at least
2081Testing Time Limits in Screener Questions for Online Surveys with Programmers ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
oneyearofappdevelopmentexperienceorhadcompletedacourse
onAndroiddevelopment.Theycontactedparticipantsviaonline
advertisements,emailstolocalandonlinegroups,anduniversity
studentswho studiedrelatedsubjects.Atfirst, participantshadto
completeaprogrammingtasktoparticipate.Afterparticipantscom-
plainedaboutthetimeittooktocompletetheprogrammingtask,
it was replaced with five multiple-choice questions, three of which
had to be solved correctly. This may indicate that programming
tasksarenotoptimaltofilterparticipantsinonlinesurveys.The
multiple-choice tasks dealt with the subject of app development,
andthusdidnotsuitthispaperasthegoalistoincludeallsoftware
developers, not just those skilled in app development. However,
some similar themes were included in the question set, such as
error handling.
AssalandChiasson[ 4]recruitedparticipantsforanonlinesurvey
on Qualtrics regarding developers’ software security process. To
ensureabaselineofunderstanding,theauthorsshowedparticipants
different software security descriptions and prevented them from
processinguntiltheyhadselectedthecorrectone.Onlyparticipants
providing invalid data were excluded from the analysis.
In[12],Danilovaetal.exploredsoftwaredevelopers’preferences
regarding IDE warnings in a lab study and an online survey. They
recruited developers via Qualtrics [ 29] for the online survey and
includedapseudo-codeprogramprintingthewords"helloworld"
backward. Participants were tasked with selecting the output in
amultiple-choicequestion,whichonly33of129participantscor-
rectly solved. The task was included in this paper.
2.3 Baseline study
ThispaperexpandsontheworkbyDanilovaetal.[ 11],wherethey
developed tasks to be used as a filter in an online survey. They
created16questionstestingdifferentcategoriesofprogramming
knowledge and skills. They tested these tasks with 17 computer
science students and 34 professional developers to prove partici-
pantswithprogrammingskillscouldsolvethem.Additionally,they
analyzedtheresultsof50 non-computersciencestudentsand 50
participants from Clickworker [ 9] to test if non-developers can
solvethetasks.Theresultsshowedthatparticipantswithprogram-
ming skills could solve many tasks, while those without skills had
significantlylowersuccessrates.Furthermore,theylookedatthere-
sultsof52participantswithprogrammingskillsmentionedintheir
Clickworkerprofiletoseehowthetasksperformedinascenario
theywereexpectedtobeused.Whiletheparticipantsperformed
betterthantheparticipantswithoutprogrammingskills,theydid
significantly worse than the control group of computer science stu-
dentsandworkingsoftwaredevelopers,againshowingtheneedfor
a tool to filter out non-developers. Finally, Danilova et al. explored
anattackscenario,whereparticipantsweregivenamonetaryin-
centive oftwo eurosper taskto findcorrect solutionsto thetasks.
In the end, they recommended six tasks to be used as screening
questionsinsurveys.Forfourofthem,theysuggestedusingtime
limits; however, without further exploring these. We built upon
their work and investigate the usage of time limits for screener
questions.3 METHODOLOGY
Inthissection,wedescribethemethodologyforthethreeconducted
surveys in this paper, the first one to estimate time constraints, the
secondonetotestthescreenerquestions,andthethirdonetosimu-
lateanattackscenario.Firstly,wepresentourscreenerquestionsin
Section3.1.Secondly,wediscussourstudyconditionsinSection3.2.
Thirdly, we tested the questions with computer science students
withdifferenttimeconstraintsasdescribedinSection3.3.1.Finally,
wesimulatedanattackscenariowith Clickworkerparticipantsas
described in Section 3.3.2. An attention check question [ 21] was
placedrandomlyduringthesurveytofilteroutcarelessrespondents
(see Supplementary Material). After solving all the tasks, partici-
pants were asked if they had felt under pressure during the survey,
and demographic information was collected (see Supplementary
Material).
3.1 Tasks
Ourpotentialsetoffiltertasksconsistsofalreadyestablishedtasks
from[11]andnewtasks,whichwedevelopedtoextendthequestion
pool.AlistofallquestionsusedcanbefoundinTable1,withthe
first six being the recommended tasks from Danilova et al. [ 11]
and the newly developed tasks. The detailed questions with all the
answer possibilities are additionally listed in the supplementary
material.
Baseline questions. Multiple questions ( Boolean,Compiler ,Re-
cursive,Backward.Loop ,Sorting.Array andSource.Usage )from
Danilova et al.’s survey were included to test if the participants’
groupsweresimilarenoughtoeachother.Furthermore,eventhough
some of these questions seemed to be solved with a relatively high
successrateintheattackscenario,whereparticipantstriedtoguess
the answers, they may still be used as a filter based on the time to
solve the tasks.
Newquestions. Basedontheresultsoftheprevioussurveysdoneby
Danilovaetal.[ 11],anewsetofquestionswasdeveloped.Danilova
et al. observed that participants from the attack scenario were able
togoogleeasyknowledgequestions.Therefore,weaimedtotest
more comprehension questions. As the previous analysis of the at-
tack scenario showed, non-programmer participants were less suc-
cessfulinusingaidwhentasksrequiredthemtoreadprogramming
code. In addition, these tasks had a comparatively low success rate
withnon-programmers. Palindrome ,CountString andPrimeall
askedparticipantstoidentifythepurposeofapseudo-codealgo-
rithm. In Return, participants were required to evaluate several
if-statements in a function to predict the returned value. Addition-
ally,Recursive was transformed so that participants did not only
have to know the definition of a recursive function but also had to
identifyarecursivefunctionifshownin RecursiveFunction1-4 .
This may increase the difficulty non-programmers have to solve
the task.
Parameter was shown separately from Backwards.Loop on a
new pseudo-code to ensure an independent result. Furthermore,
several tasks were created where participants had to predict which
errormessageacompilerwouldreturniftheytriedtocompilesuch
code. One question, Error.OutOfBounds , where an array was
accessed with a negative number, included two correct answers as
2082ICSE’22,May21–29,2022,Pittsburgh,PA, USA Anastasia Danilova, Stefan Horstmann, Matthew Smith, and Alena Naiakshina
Table 1: Overview of all questions used for the timed scenarios
Baseline Questions from [11] Abbreviation Category
1Whichof these values would be the most fitting for a Boolean? Boolean BasicKnowledge
2 Choose the answer that best fits the description of a compiler’s function Compiler Basic Knowledge
3Choose theanswer that best fits the definition of a recursive function Recursive BasicKnowledge
4 Please select the returned value of the pseudo code. Backward.Loop Code Comprehension
5Whatis the purpose of the algorithm? Sorting.Array Code Comprehension
6 Which of these websites do you most frequently use as aid when programming? Source.Usage Information Sources
New Questions Abbreviation Category
1Given the array arr[7,3,5,1,9], what could the command arr[3] return? (0-based indexing) Array BasicKnowledge
2 What is the parameter of the pseudo-code function? Parameter Basic Knowledge
3Is the following pseudo-code function a recursive function? RecursiveFunction1 BasicKnowledge
4 Is the following pseudo-code function a recursive function? RecursiveFunction2 Basic Knowledge
5Is the following pseudo-code function a recursive function? RecursiveFunction3 BasicKnowledge
6 Is the following pseudo-code function a recursive function? RecursiveFunction4 Basic Knowledge
7Whatis the purpose of the pseudo-code algorithm above? CountString Code Comprehension
8 What is the purpose of the pseudo-code algorithm above? Palindrome Code Comprehension
9Whatis the purpose of the pseudo-code algorithm above? Prime Code Comprehension
10 What would the pseudo-code return if i is 4? Return Code Comprehension
11Whatissuewould the following pseudo-code most likely cause? Error.OutOfBounds FindingErrors
12 What issue would the following pseudo-code most likely cause? Error.Syntax Finding Errors
13Whenexecuting the pseudo-code below, your program never stops running. Infinite.Loop FindingErrors
14 Which of these IDEs have you used before? IDE.Used IDE Recognition
15Please select 2 items from the list which are IDEs. IDE.Known IDERecognition
16 Please select the two programming languages from the list below. Rec.Lang Programming language recognition
someprogramminglanguagesallownegativeindexing,resulting
in undefined behavior while others did not, resulting in an "Index
out of range" error. Finally, two questions were included, asking
participantstoselectIDEstheyknewandIDEstheyhadworked
withbefore.AsimilartaskwasusedbyBalebakoetal.[ 5].However,
forthisworkitwaschangedintomultiple-choicequestionswith
somevalidanswersandsometechnicalcomputertermsasBalebako
etal.statedthatduetoalargenumberof IDEs,theanswerswere
sometimeshard to verify.
Theorderofallquestionsandanswerswasrandomized.Only
RecursiveFunction1-4 were always shown together, however,
againin randomized order.
3.2 Conditions
AllconditionsaresummarizedinTable2.Participantswithsoftware
development skills were split into three groups to evaluate the
influence of different time constraints on the success rate. First, we
used a control group without mentioning a time limit ( Base). With
thisgroup,itcouldbedeterminedifatimeconstrainthadanegative
impacton thecorrectness oftheprogrammers’ solutions.Second,
weestablishedagroupwithanotebeforeeachquestionthatthe
timetosolvethenextquestionwouldbemeasuredandarequestto
solvethetaskasquicklyaspossiblewithoutmentioninganexplicit
time limit ( No Limit ). Participants were encouraged to work as
quicklyaspossibletocreatethelargestmargintothetimepotential
non-programmer participants would need. Last, we provided a
group of participants a time limit in the form of a countdown
timer given for each question ( Countdown ). In contrast to the No
Limitgroup, the Countdown group provides a clear cut-off point
for passingthe taskand not passing thetask.Tofindanappropriatetimelimitforthegroup Countdown andto
eliminateconfusingquestions,atestrunwiththe Basegroupsetup
with four researchers of the security department was conducted.
The time limit for the countdown group was based on the mean
time of the test group, with an extra time of 50% or ten seconds,
whicheverwaslarger.Thetimelimitwasroundedtothenearest
ten seconds.
3.3 Participants
To calculate the number of participants required to create statis-
tically significant results, a power analysis was conducted with
G*power [ 19]. Asthe resultsof thetwoindependent groupswere
tobecompared,theanalysiswasdoneforFisher’sexacttest,and
the proportion of correct answers of both groups had to be esti-
mated.Sincetheresultscanbeexpectedtobeatworstsimilarto
theonesintheattackscenarioconductedbyDanilovaetal.[ 11],
theexpectedpercentagewaschosentobethesame,whichwas61%
for the non-programmer group. The programmer group worked
on the same tasks, so 98% was selected as their rate of correctness.
With p as 0.05, this leads to 24 participants required to show statis-
ticallysignificantresults.Asummaryofthedemographicsforboth
programmer and non-programmer groups is available in Table 3.
3.3.1 Programmers:Computersciencestudents. Theparticipants
oftheprogrammers’groupwerestudentsinamaster’scomputer
science class. All the participants attended at least one program-
ming course during their Bachelor’s program. Participation was
notmandatoryforpassingthecourse,butparticipantsreceiveda
small bonus on the admission to the exam for taking part in the
survey. The study introduction for programmers is available in the
supplementary material.
2083Testing Time Limits in Screener Questions for Online Surveys with Programmers ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 2: Study conditions
Condition Tested groups Description
Base Prog No time constraints
No Limit Prog "Solve it as fast as possible", no specific limit given
Countdown Prog, Attack Time limitwith countdown timer
Prog = Programmer, Attack = Non-Programmer Attack Scenario
Table 3: Demographics of the Participants (n = 98)
Programmer (n = 74) Non-Programmer(n=24)
Base (n = 23) No Limit (n = 26) Countdown (n = 25) Countdown Attack (n = 24)
Gender female:5, male: 18 female: 6, male: 20 female: 6, male: 19 female: 10, male: 13, prefer
notto tell: 1
Age min:20,max:29,mean:24.43,
md:25,sd:2.21min:21,max:31,mean:24.38,
md:23,sd:2.87min:22,max:35,mean:25.76,
md:25,sd:3.13min:22,max:60,mean:34.67,
md:33,sd:10.46
Main Occupation Computer Science Student:
22,FullStackDeveloper: 1Computer Science Student:
22, Software Developer: 3,
Python:1,Computer Science Student:
22, Economist: 1, System ad-
ministrator: 1, Web Devel-
oper: 1e.g., Teacher, Freelancer, Ad-
ministrator, Business
Country of Residence Germany:22,Pakistan:1 Germany:25,Bangladesh:1 Germany:24,Armenia:1 Germany: 7, USA: 6, UK: 3
and6 Other Countries
General Development Ex-
perience [years]min: 1, max: 15, mean: 6.65,
md:7, sd: 3.5min: 1, max: 13, mean: 6.62,
md:6, sd: 3.26min: 0.5, max: 10, mean: 5.58,
md:5, sd: 2.85min: 0, max: 5, mean: 1.21,
md:1, sd: 1.47
Allinall,77participantstookpartinthestudy,and75completed
the entire survey. The assignment to the different time groups
was done at random and resulted in 24 participants in the Base
group,26intheCountdowngroup,and27inthe NoLimit group.
One participant in the Basegroup did not continue working on
the survey after one task. Another participant in the No Limit
group stopped halfway through the survey. Their results were not
included in the analysis, leaving us with 23 participants slightly
under-representing the Basegroup (see Section 3.3). In addition,
oneparticipantinthe Countdown groupwasexcludedasthetime
for each task was extremely low, often below two seconds. Of
the remaining 74 participants, 57 were male and 17 were female.
On average, participants were 25 years old and had six years of
programming experience.
3.3.2 Non-programmers: Clickworker. Finally, a third survey simu-
lating an attack scenario with a time limit was carried out. Here,
participants were recruited on Clickworker.com [ 9] and given sev-
eraltasksofthepreviousscenariowithatimelimittosolveeach
task. The results were compared to the results of the program-
mer group of the study with computer science students. The study
introduction for the non-programmer group is available in the
supplementary material.
Allinall,25recruitedparticipantsfinishedthesurvey,andthree
droppedout duringthe survey.Of those25, oneparticipant failed
to pass the attention check question and was excluded from the
analysis. The remaining participants were, on average, 34.67 years
old.Theyoungestparticipantwas22,andtheoldestwas60yearsold.
Ten of the participants were female, 13 were male, and one did not
answer the question. Some participants claimed to have worked in
IT-related fields before. However, some participants may still have
answeredasaprogrammerwouldhaveduringthedemographics
questions. As these results would only cause the effectiveness of
the tasks to be underestimated, their results were still used for
the analysis. In addition, participants were not excluded due toextremelylowsolvingtimes,asguessingananswermightbeatactic
employedbytheparticipantstosolvethetasks.Theparticipants
were given 2 €for completingthesurvey and again 2 €for each task
theysolvedcorrectly.ThismatchesthepaymentsbyDanilovaetal.
in [11]. With ten tasks providing bonus payment, this resulted in a
maximumof 22€ per participant.
3.4 Statistical analysis
When comparing the participants’ results on the tasks, their an-
swersareclassifiedas"Correct"and"Incorrect."Thestudyaimed
atfindingdifferentsuccessratesbetweenprogrammersandnon-
programmers. Thus, the results were tested with Fisher’s exact test
(FET) for each question. In addition, the times required to solve
singletasksorcompletingtheentiresurveywerecompared.Asthe
results were rarelynormally distributed, they were analyzedwith
the Wilcoxon rank-sum test to detect statistically significant differ-
ences.Asalltaskswerecomparedindividually,noBonferroni-Holm
correction was conducted.
3.5 Ethics
Theinstitutionalreviewboardoftheuniversityapprovedtheproject.
Theparticipantsofthestudywereprovidedwithaconsentform
outlining the scope of the study and the data use and retention
policies,anditwasalsocompliedwiththeGeneralDataProtection
Regulation(GDPR).Theparticipantswereinformedofthepractices
used to process and store their data and notified that they could
withdraw their data during or after the study without any con-
sequences.Theparticipantswereaskedtodownloadtheconsent
formfor theirown use and information.
2084ICSE’22,May21–29,2022,Pittsburgh,PA, USA Anastasia Danilova, Stefan Horstmann, Matthew Smith, and Alena Naiakshina
3.6 Limitations
As the participants with programming experience were entirely
recruited from computer science classes, some bias may have influ-
encedtheresultsofthetasks.Thismighthaveresultedinpartic-
ipantsover-performingonsometasksiftheycoveredsomething
taughtindetail atthe universityor underperformingif they were
not. However, the topic was still common knowledge for profes-
sional programmers. There may have also been other factors in-
fluencing the results, as participants in different age groups or
participants working in various fields may have produced different
resultsonthetasks.Amoreextensiveandmorediversegroupof
participants with programming experience may enhance the ac-
curacy of the results. Furthermore, the participants recruited on
Clickworker.com [ 9] may not have been an entirely representative
population.Inaddition,therecruitednon-programmerparticipants
fortheattack scenarioswere only encouraged to simulate the tar-
getedgroup,namelynon-programmerswhoparticipateinprogram-
merstudiesbyaccidentorintentionally.Thistargetedgroupcan
notberecruitedandidentifiedeasily,sotheirbehaviorisonlyap-
proximatedwithamonetaryincentivetosolvethefilteringtasks.In
addition,there may have been participants in the non-programmer
group who have had some programming experience, thus influ-
encing the results. This would, however, cause the tasks only to
under-report their filtering quality at worst.
Onlyalimitednumberoftaskscanbetested,withmanypossible
suitabletasksremaining undiscovered.Thereisalso noguarantee
thattheusedtasksareoptimalorthattheirperformancewillremain
the same in the future if there are changes in the field of computer
programming.Inaddition,thetasksonlytestifaparticipanthas
someprogrammingskillsandmaynotbesuitableforresearchers
trying to recruit more specialized participants, for example, par-
ticipants who are skilled in a particular programming language or
whoworked in a specific sub-field.
Due to an error, we only tested the question whether the par-
ticipantsfeltpressuredingeneralonlyfortenparticipantsinthe
Basegroup.Unfortunately,thisallowsusonlyalimitedcompari-
son all three groups. Only a comparison between the No limitand
Countdown group is possible.
Thisinstrumentcanbeappliedinsoftwareengineeringresearch,
whereresearchersotherwisewouldhavetorelyonself-reported
programmingskills(snowballsampling,samplingoverforums,or
online recruiting services like Qualtrics, LimeSurvey, QuestionPro,
etc.). However, Googleforms offers timelimits for questionnaires
but not single questions. SurveyMonkey does not offer a time limit
at the moment.
4 RESULTS
Inthissection,thestudieswithprogrammersandnon-programmers
arediscussed.First,thetasksintroducedinTable1weretestedwith
computer science students. Participants were expected to perform
similarly to the participants who were previously classified as pro-
grammers in the baseline study [ 11]. The influence of the time
constraints on the participants’ performance was measured. In ad-
dition, the self-evaluation of the participants and its correlation to
successfullysolvingthetaskswasdiscussed.In addition,thepres-
surecausedbythedifferenttimeconstraintswasreviewed.Second,the results of the timed attack scenario with non-programmers
werecomparedtotheresultsoftheprogrammersinthisandthe
baseline studies.
4.1 Programmers
A summary of the time the participants required per task, and the
percentage of correct answers is available in the supplementary
material. It is worth noting that participants in the Countdown
groupoccasionallyselectedananswerandthenletthetimerrun
out.Theseanswers werestillevaluatedlikeallotheranswers and
resulted in a correct solution if the answers were correct. Over-
all, the timer ran out 19 times, with six correct and six incorrect
answers.Seventimesnoanswerwasgivenintime,whichwaseval-
uatedasincorrectanswers.The Parameter taskwastheonewhere
participantsran outof time the most, resulting in six timeouts.
4.1.1 Ensuringcomparabilitywiththebaselinestudy. First,ithad
to be ensured that participants were similar in skill level to the
programmerspreviouslyrecruitedbyDanilovaetal.inthebaseline
study [11] so that the new tasks could be compared to the old ones.
This was achieved by comparing the results of the programmer
group from the baseline study with the results of the Basegroup of
thisstudyforthesixbaselinequestions(seeTable1).Inaddition,
thetimetakentosolvethetaskswascomparedforonlyfourofthe
tasks, as participants in the baseline study solved two tasks on the
same source code, and time was nor recorded separately.
When comparing the correctness of the two groups with the
Kolmogorov-Smirnov test, none of the tasks showed a statistically
significant difference. Consequently, the data suggested that the
skillleveloftheparticipantsofourprogrammergroupwasclose
to the participants in the baseline study of Danilova et al.
Figure 1: Number of correct solution by each programmer
group
4.1.2 Comparison between groups. Figure 1 shows the number
of correct solution by each programmer group ( Base,No Limit
andCountdown ). For each task, the results of the three different
groupswerecomparedwithFisher’sexacttest(FET)tocheckfor
statisticallysignificantdifferencesbetweenthegroups.Thetestdid
2085Testing Time Limits in Screener Questions for Online Surveys with Programmers ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Figure 2: Time required to complete the survey by each pro-
grammer group
not show a significant difference between the groups in any of the
tasks.
In Figure 2, the time each group required to complete the entire
survey is presented. Participants in the No Limit group completed
theentiresurveythefastest(min:8.17m,md:13.93m,mean:14.78m,
max: 31.25m, sd: 5.3m). The second fastest were the participants in
theCountdown group (min: 8.35m, md: 18.75m, mean: 22.12m, max:
55m, sd: 13.30m). The time for one participant in the Basegroup
andoneinthe NoLimit groupwerefilteredout,astheyleftthelast
page of the survey open after finishing it, thus having a drastically
increased overall time. Participants in the Basegroup were the
slowest (min: 7.68m, md: 17.77m, mean: 26.56m, max: 89.4m, sd:
21.96m).
The Wilcoxon rank-sum test did not show a statistically signifi-
cantdifferencebetweenthe NoLimit andtheBasegroup(p-value=
0.39),andthe BaseandCountdown group(p-value=0.73).However,
between the No Limit and theCountdown group (p-value = 0.015*),
a statistically significant difference was found. Noticeably, partici-
pantsinthe Countdown group were slower than theparticipants
in theNo Limit group, indicating that participants tended to spend
more time on a task if they knew they have the time to do so.
4.1.3 Self evaluation. All participants were asked to self-evaluate
theirprogrammingskillsaftercompletingthetasks.Possiblecate-
gories were "Beginner," "Intermediate," and "Expert." Of the 74 par-
ticipants, 11 selected "Beginner," 54 "Intermediate," and 9 chose "Ex-
pert." Participantswere notsubdivided into the"Base," "NoLimit,"
and "Countdown" groups.
Forthefollowinganalysis,failingbyoversteppingthetimelimit
was excluded as only participants from the time limit group could
failduetothelimit.Participantsinthebeginnergroupsolvedan
average of 83% of the tasks correctly, about 18.2 out of 22 tasks.
Participants who evaluated their skill level as intermediate solved
93% of the tasks correctly, with an average of 20.5 correct answers.
Intheexpertgroup,97%ofalltasksweresolvedcorrectlybytheparticipants, corresponding to 21.4 correct answers per participant
onaverage.WhencomparingthegroupswithFisher’sexacttest,
there were significant differences between the beginner and the in-
termediategroup(p-value<0.0001)aswellasbetweenthebeginner
and the expert group (p-value < 0.0001). In addition, the difference
between the intermediate and the expert group was significant
(p-value = 0.024*). The results indicated that the self-evaluation of
the participants mightbe used to predict the participants’ success
rate on the tasks.
Figure 3: Perceived pressure by each programmer group
Limitation:Since thisquestionwas added later to the survey, it
was onlyshown to ten participants of the Base group. All other
groups had the question already included in their survey.
4.1.4 Pressure. At the end of the survey, participants in the No
LimitandCountdown groups were asked if they had felt pressured
bythetimeconstraintsduringthesurvey.Additionally, Basepartic-
ipantswereaskediftheyhadfeltpressuredingeneralduringthe
survey.1Three multiple choice answers were given, "I did not feel
pressuredatall,""Ifeltalittlepressured,"and"Ifeltverypressured."
Theresults are shown in Figure 3.
Thedataindicatedthatparticipantsperceivedpressureifare-
quest to work fast or a strict time limit was given. The reported
pressure is lowest in the base group. The Fisher’s exact test did
not show a statistical significance between the Basegroup and the
No Limit group (p-value = 0.11). However, we found a statistical
significantdifferencebetweenthe Basegroupandthe Countdown
group(p-value=0.048*).Finally,therewasnosignificantdifference
1Sincethisquestionwasaddedlatertothesurvey,itwasonlyshowntotenparticipants
of theBasegroup.
2086ICSE’22,May21–29,2022,Pittsburgh,PA, USA Anastasia Danilova, Stefan Horstmann, Matthew Smith, and Alena Naiakshina
betweenthepressurefeltbythe NoLimitgroupandthe Countdown
group (p-value = 0.86).
Whiletheincreaseinpressureforparticipantsisanunwanted
sideeffectofthetimeconstraints,itmightreducetheriskofnon-
programmer participants using online services or help from others
to solve the tasks. When participants are requested to work fast,
timedifferencesbetweenprogrammersandnon-programmersmay
increase, thus making it easier to differentiate between the two
groups based on the time required to solve the tasks.
4.2 Non-programmers - Timed attack scenario
The attack scenario from Danilova et al. [ 11] showed that by using
ascenariowithunlimitedtimeconstraints,non-programmerpar-
ticipantswereabletosolvethetaskswithhelp.Thecorrectnessfor
programmers decreased significantly in neither the No limitnor
theCountdown scenario. Thus, both scenarios might be suitable
to filter outnon-programmers.Asthe Countdown scenariodeliv-
ersaclearcut-offpointforallparticipants,itshowsmostclearly
whether the participants could have solved the tasks within the
timelimitornot.Incontrast,participantsinthe Nolimitgroupstill
could spend extra time double-checking their answers and thus
increase the time required to solve the task above the cut-off point.
Forthisreason,alltasksintheattackscenarioweretestedwitha
countdown timer, and non-programmer participants had the same
timelimitto solve each task as the programmers.
As participants with programming knowledge may be erro-
neouslyfilteredoutbytaskstoodifficult,onlytheoneswithhigh
success rates among programmers were included. For this, the rate
ofthecorrectnessofallprogrammers’answersinthepreviousstudy
was calculated. 95% was defined as the cut-off point, as it keeps
thenumberofprogrammersfailingthetaskslowwithoutexpect-
ing the programmers to give perfect answers. Thus, we included
Source.Usage ,Recursive ,Boolean,Rec.Lang ,Compiler ,Re-
cursiveFunction3 ,RecursiveFunction4 , and IDE.Known as
tasks in the survey. Additionally, ArrayandPrimewere included,
as theyreach 95% ifrounded to theclosest whole number. Recur-
siveFunction1 , which would fall in the latter category, was not
chosen, as the correctness in the Countdown scenario was below
95%andahighsuccessratefromguessingwastobeexpectedin
the attack scenario on the yes-or-no task. Finally, we considered
ten tasksfor thetimed attack scenario with non-programmers.
4.2.1 Comparisontothebaselineattackscenario. Asparticipantsin
theattackscenariousedbyDanilovaetal.[ 11]workedonthetasks
Boolean,Compiler ,Recursive , and Sources.Usage without a
timelimit,we examined the influence of the limit on the success
rate. The baseline participants without a time limit performed bet-
teron all four tasks. However, participants with a time limit were
quicker on all four tasks, suggesting that our participants would
have required additional time to solve the tasks to their satisfac-
tion. It strengthens the assumption that introducing a time limit
decreases the chance of success for non-programmers on the tasks.
4.2.2 Comparison to programmers. All in all, non-programmers
needed, on average, 12.86 minutes (md: 10.09 minutes) to com-
pletetheentiresurvey.Thefastestparticipantneeded3.88minutes,
whereasthemostprolongedtimetakenforthesurveywas27.47minutes. The quickest participant solved all tasks correctly and
notedin thecommentsection toworkasa softwareengineer.We
did exclude him from analysis because we were unable to prove
this claim for correctness. In addition, the results could only cause
the reported effectiveness to drop.
Participantsgotonaverage3.71(md:3)correctanswers.Since
the goal was to distinguish the non-programmer participants from
theprogrammers,theirresultswerefirstcomparedtothecomputer
sciencestudents’results.Here,onlytheresultsofthestudentsin
theCountdown groupwereconsidered,asthetimeconstraintfor
both groups is the same.
TheindividualscoresforeachgrouparepresentedinFigure4.
On average, the non-programmers in the attack scenario solved
3.67taskscorrectly,withthelowestscorebeingoneandthehighest
beingten.Forcomparison,intheprogrammergroupwiththesame
countdown timer, two participants solved eight tasks correctly,
another two nine, and the remaining 21 solved all the ten tasks
correctly.
Figure 4: Number of correct solutions by programmers and
non-programmers
The results for both groups are presented in Table 4 for each
task.Thenon-programmersperformedworsethantheprogrammer
grouponalltaskswithregardtothesuccessrate.Inallbutonetask
(the yes-or-no question RecursiveFunction3 ), the difference was
statisticallysignificant.Insixofthetentasks,thenon-programmers
were also significantly slower than the programmer group. The
datashows that the correctness of non-programmers onthe tasks
significantly deteriorates with the introduction of a time limit, a
phenomenon that did not occur when the same time limits were
introduced to participants with programming skills. This indicates
theusefulnessoftimelimits,asacorrectlychosenlimitprevents
asignificantnumberofnon-programmersfromsolvingatask.In
contrast, the number of programmers solving the task correctly
remains unchanged.
4.2.3 Aidused. Thenon-programmerparticipantswereaskedif
they used any form of outside help to solve the tasks. Possible
2087Testing Time Limits in Screener Questions for Online Surveys with Programmers ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 4: Comparison of programmers and attack scenario
Group Task Minimum Median Mean Maximum Correctness
Countdown Programmer 4.3s 9.77s 11.76s 25.45s 100
Countdown AttackBoolean4.45s 16.65s 19.44s 42.16s 25
Countdown Programmer 6.32s 11.24s 13.28s 30.01s 100
Countdown AttackRecursive5.31s 19.6s 19.49s 32.24s 29.17
Countdown Programmer 6.08s 9.64s 10.53s 22.26s 100
Countdown AttackSources.Usage4.36s 16.73s 18.73s 30.17s 33.33
Countdown Programmer 5.02s 10.16s 11.64s 21.05s 100
Countdown AttackRec.Lang6.68s 19.08s 19.8s 31.85s 41.67
Countdown Programmer 6s 12.94s 16.5s 40.01s 100
Countdown AttackCompiler1.64s 23.16s 21.05s 40.11s 45.83
Countdown Programmer 8.67s 65.91s 86.70s 180.12s 96
Countdown AttackArray5.61s 32.03s 32.61s 60.02s 16.67
Countdown Programmer 16.7s 49.73s 62.93s 165.35s 96
Countdown AttackPrime4.46s 56.69s 68.04s 169.42s 20.83
Countdown Programmer 5.89s 14.57s 18.65s 60.21s 96
Countdown AttackIDE.Known5.08s 28.57s 33.11s 60.14s 25
Countdown Programmer 5.42s 19.19s 23.93s 64.13s 96
Countdown AttackRecursiveFunction42.6s 24.8s 31.54s 82.95s 50
Countdown Programmer 4.81s 11.4s 15.51s 42.56s 92
Countdown AttackRecursiveFunction34.03s 23.03s 29.71s 90.01s 79.17
Thetasksare sorted descended by correctness of the programmer group and ascended by the correctness of the countdown attack group.
answerscovered"Iknewtheanswer,""Iguessedtheanswer,""Asked
friends/colleagues," "Internet search (if possible, insert the link you
used)" and "Other." For the internet search and "Other," participants
could provide additional information in a text box. Due to the fact
that participants only selected "Other" twice, stating that they had
run out of time, it was not analyzed in detail. Since participants
couldusemultipledifferentsourcesofaid,multipleselectionswere
possible. The most common practice used was to guess the answer,
whichwasdone46%ofthetime.Participantsclaimedtohaveknown
the answer 32% time, did an online search in 15% of the cases, and
asked their friends or colleagues in only 7% of the cases.
Inaddition,wecomparedthefrequencyoftheaidusagewiththe
baselineattackscenarioconductedbyDanilovaetal.in[ 11].When
comparing all aid used during the entire surveys of both groups,
thepercentageofthedifferentusedsupportdifferedsignificantly
(p < 0.0001, FET). In the untimed baseline scenario, participants
kneworguessedtheanswerin84%ofthecases,anonlinesearch
was done in 26% of the cases, and friends or colleagues were asked
in11.84%ofthecases.Thedatashowedthatparticipantscouldstill
significantly improve their correctness by conducting an online
search.Withthetimelimit,theytendedtotryitlessbyasignificant
margin.
5 DISCUSSION AND RECOMMENDATIONS
Participants taking part in programming studies without the ac-
cording skills can significantly threaten the validity of the data.
Screenerquestionstestingprogrammingskillscanbeusedtoval-
idate the target group . However, pr ogrammers’ time is valuable
and should not be wasted on screener tasks taking much time. Our
analysis indicated that the time required to solve screener tasks
could be reduced by using time constraints without decreasing
the rate of correctness. Participants without programming skills
performedsignificantlyworseonthetimedtasksbothcompared
to our programmers and the baseline non-programmers without a
time limit from [ 11]. Our non-programmers searched the Web less
frequently and had to guess or trust their knowledge more often
than the baseline attack scenario group without a time limit. These
results showed that the introduction of the time limit and the newsuggestedscreenerquestionshelpeddecreasethesuccessrateof
non-programmers, thus improving the tasks introduced in [ 11] for
filtering outnon-programmers.
In the following, the setup of the tasks as a filtering instrument
for online surveys is discussed. First, we outline which tasks we
wouldrecommendforresearchsurveyswithprogrammers.Second,
we argue for the usage of a time limit for the tasks. Finally, we
discuss how many of the tasks we would recommend using in a
survey.
5.1 Screener tasks
Anessentialcharacteristicofthetasksisexcludingacriticalnumber
ofprogrammersfromthesurvey.Withthepreviouscut-offpointof
95%correctnessforprogrammers,thiscriterionwasfulfilled.While
itwouldhavebeenbeneficialtotestthesamesetsofquestionswith
programmers and non-programmers, we learned from the study
withprogrammersthatsomequestionscouldnotbechosenforthe
instrumentduetoahigherrorrateandthustestedonlyasubset
with non-programmers.
Thetasksmustfilteroutalargenumberofnon-programmerpar-
ticipants.Asthetasks RecursiveFunction3 andRecursiveFunc-
tion4areyes-noquestionsandincreasethechanceofguessingthe
answer correctly to a significant extent, the correctness of answers
given by non-programmers is comparatively high. While it may
still be possible to filter with a larger number ofyes-no questions,
the time to solve these tasks and the programmers’ correctness
rate does not differ fundamentally for the other tasks. Thus, we
would not recommend them for the instrument. Further, the tasks
Compiler andRec.Lang bothhaveasuccessrateofover40%,indi-
cating that a larger number of non-programmers are familiar with
the terms or can look them up and answer these questions quickly.
Thus,we also recommend excluding them from the instrument.
The remaining six tasks Array,Prime,Boolean,IDE.Known ,
Recursive andSources.Usage reduce the success rate of non-
programmersto33%orlower.Itshouldbenoted,however,thatthe
taskPrimehasatimerofthreeminutesandmighttaketoolong,
especially if the explored survey is rather short. The recommended
tasksare summarized in Table 5.
2088ICSE’22,May21–29,2022,Pittsburgh,PA, USA Anastasia Danilova, Stefan Horstmann, Matthew Smith, and Alena Naiakshina
Table 5: Overview of recommended screener questions
Abbreviation Screener Question Time
LimitCorrectness
ProgrammerCorrectness
Non-
Programmers
1Sources.Usage Whichof these websites do you most frequently use as aid when programming? 30s 100% 33.33%
2 Recursive Choose the answer that best fits the definition of a recursive function 30s 100% 29.17%
3Boolean Whichof these values would be the most fitting for a Boolean? 30s 100% 25%
4 IDE.Known Please select 2 items from the list which are IDEs. 30s 96% 25%
5Prime Whatis the purpose of the pseudo-code algorithm above? 3m 96% 20.83%
6 Array Given the array arr[7,3,5,1,9], what could the command arr[3] return? The array starts with 0. 1.5m 96% 16.67%
5.2 Time constraints
While the No limitgroup participants completed the entire survey
the fastest, this condition might not apply to non-programmers
becausetheystillwouldhavethetimetogooglethesolutionsfor
theknowledge-basedquestions.Togivenolimityetcutthemoff
implicitlyaftersometimemightbeacheapway,butitistechnically
challengingandraiseethicalconcerns.Thus,the Nolimitcondition
might increase questionnaires’ time, resulting in potentially higher
research costs than Countdown .
Asshownduringthetestwithprogrammers,thetimerwitha
countdowndidnotimpactcorrectness.H owever,it affectednon-
programmers’ results concerning their correctness. In addition, the
participants used less often help to solve the tasks when being
presented with a time limit, thus again worsening their results. For
thesereasons,itisbeneficialtoaddacountdowntimertothetasks
when filtering out non-programmers. Nevertheless, participants
shouldbeinformedaboutthetimelimitbeforeandduringthetasks
to avoid confusion with the conditions required to participate in
the survey.
5.3 Setup of the instrument
Some possible setups of the instrument are discussed here as a
recommendation. While researchers are free to choose and discard
tasks to their liking, it is advisable to randomize which tasks are
shown if participants are likely to communicate and share their
solutions.In addition,presentingmultiple taskscanimprove the
instrument’saccuracy,withtheconsequencethatittakeslongerto
solve the tasks.
Forthefollowingcalculations,theaveragesuccessrateforallsix
tasks is used for programmers and non-programmers. To simulate
the picking of the tasks at random, each task will leave 25% of the
non-programmerand 98% of the programmers in the study.
One correct out of one: Showing participants one of the six
tasksatrandomisexpectedtoeliminate75%ofthenon-programmers
while only excluding about 1.78% of actual programmers. While
this setup takes the least time participants spend on the filtering
questions,morenon-programmerscouldbeidentifiedifmultiple
taskswere combined.
Two correct out of two: Inthisscenario,potentialparticipants
wouldbegiventwo ofthesixtaskstasksand wouldhavetosolve
bothcorrectlyinordertoqualifyforbeingacceptedinthestudy.
Whilethissetuptakeslongerforparticipants,astheyhavetosolve
two tasks, it allows a larger number of non-programmers to be
filtered out, approximately 94%. However, this setup also causesmorerealprogrammerstobefilteredout,namely3.53%.Thissetup
is the most effective to filter out non-programmers.
Two correct out of three: Here,participants wouldbeshown
three of the six tasks and would have to solve two of them cor-
rectly to proceed in the survey. While not fewer non-programmers
thanintheprevioussetupwouldbeeliminated,mostprogrammers
wouldbekeptinthestudy.Only0.09%oftheprogrammerswouldbe
wronglyfilteredout.However,alargerportionofnon-programmers
wouldremain,onlyapproximately84.37%beingfilteredout.Inaddi-
tion, this setup would take longest for the participants to complete.
Our analysis showed that researchers should use filter methods
ifthereisanydoubtontheparticipants’programmingskills.We
presented six screener questions that could be used either all or
selected for research surveys with programmers. We suggest using
either one, two, or three questions in a combination, with a prefer-
ence for the second option. The exact method, however, should be
chosenaccording to the researchers’ requirements.
6 CONCLUSION
Toensuredataquality,researchersshouldscreenoutnon-programmers
from online surveys requiring programming skills. In this paper,
we testedexisting screenerquestions suggestedby Danilovaet al.
in [11] for programmers with different time constraints. Further,
weimprovedandextendedthescreenerquestionstoincreasethe
difficulty for non-programmers to solve them, even if participants
were using additional help. The new tasks and some previously
used tasks were tested with programmers. The results showed that
theparticipantswereabletosolveahighnumberofthetasksre-
liably and that the created time limits did not affect the success
rateoftheprogrammers.Tennewandoldtasksyieldingthebest
results were tested with a time limit in an attack scenario with
non-programmers. The participants were given a monetary bonus
foreachtasksolvedcorrectlyto simulateanattackscenariowithin
atimelimitforeachtask.Resultsprovedthatparticipantshaddiffi-
culty employingaid from differentsources when atime limitwas
given, resulting in an overall low correctness rate for several tasks.
In the end, six tasks with the best performance were recom-
mendedanddifferentsetupsforthetasksinthesurveyweredis-
cussed. Thus, researchers can eliminate most non-programmers
from their surveys reliably and effectively without simultaneously
excluding a large number of their target programmer group.
ACKNOWLEDGMENTS
ThisworkwaspartiallyfundedbytheERCGrant678341:Frontiers
of Usable Security.
2089Testing Time Limits in Screener Questions for Online Surveys with Programmers ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
REFERENCES
[1]Yasemin Acar, Michael Backes, Sascha Fahl, Simson Garfinkel, Doowon Kim,
MichelleLMazurek,andChristianStransky.2017. Comparingtheusabilityof
cryptographicapis.In 2017IEEESymposiumonSecurityandPrivacy(SP) .IEEE,
SanJose, CA, USA, 154–171.
[2]Yasemin Acar, Michael Backes, Sascha Fahl, Doowon Kim, Michelle L Mazurek,
andChristianStransky.2016. Yougetwhereyou’relookingfor:Theimpactof
informationsourcesoncodesecurity.In 2016IEEESymposiumonSecurityand
Privacy(SP) . IEEE, San Jose, CA, USA, 289–305.
[3]YaseminAcar,ChristianStransky,DominikWermke,MichelleLMazurek,and
Sascha Fahl. 2017. Security developer studies with github users: Exploring a
convenience sample. In Thirteenth Symposium on Usable Privacy and Security
(SOUPS2017) . USENIX Association, Santa Clara, CA, USA, 81–95.
[4]HalaAssalandSoniaChiasson.2019. ’Thinksecurefromthebeginning’ASurvey
withSoftware Developers. In Proceedings of the 2019 CHI Conference on Human
Factorsin Computing Systems . ACM, Glasgow, UK, 1–13.
[5]RebeccaBalebako,AbigailMarsh,JialiuLin,JasonIHong,andLorrieFaithCranor.
2014. Theprivacyandsecuritybehaviorsofsmartphoneappdevelopers. (2014).
[6]Sebastian Baltes and Stephan Diehl. 2016. Worse than spam: Issues in sampling
softwaredevelopers.In Proceedingsofthe10thACM/IEEEInternationalSymposium
onEmpiricalSoftwareEngineeringandMeasurement .ACM,CiudadReal,Spain,
1–6.
[7]JasonBau,FrankWang,ElieBursztein,PatrickMutchler,andJohnCMitchell.
2012. Vulnerability factors in new web applications: Audit tools, developer
selection& languages. Stanford, Tech. Rep (2012).
[8]Gunnar R Bergersen, Dag IK Sjøberg, and Tore Dybå. 2014. Construction and
validation of an instrument for measuring programming skill. IEEE Transactions
on Software Engineering 40,12 (2014), 1163–1184.
[9]Clickworker. 2021. Retrieved August 16, 2021 from https://www.clickworker.
com/ https://www.clickworker.com/, Accessed: September 2020.
[10]AnastasiaDanilova,AlenaNaiakshina,JohannaDeuter,andMatthewSmith.2020.
Replication: On the Ecological Validity of Online Security Developer Studies:
Exploring Deception in a Password-Storage Study with Freelancers. In Sixteenth
SymposiumonUsablePrivacyandSecurity(SOUPS2020) .USENIXAssociation,
Boston, MA, USA, 165–183. https://www.usenix.org/conference/soups2020/
presentation/danilova
[11]AnastasiaDanilova,AlenaNaiakshina, StefanHorstmann, andMatthew Smith.
2021. Doyoureallycode?DesigningandEvaluatingScreeningQuestionsforOn-
line Surveys with Programmers. In 2021 IEEE/ACM 43rd International Conference
on Software Engineering (ICSE) . IEEE, Madrid, Spain, 537–548.
[12]Anastasia Danilova, Alena Naiakshina, and Matthew Smith. 2020. One size does
not fit all: a grounded theory and online survey study of developer preferences
forsecuritywarningtypes.In 2020IEEE/ACM42ndInternationalConferenceon
Software Engineering (ICSE) . IEEE, Seoul, South Korea, 136–148.
[13]JanetFeigenspan,ChristianKästner,JörgLiebig,SvenApel,andStefanHanen-
berg. 2012. Measuring programming experience. In 2012 20th IEEE International
ConferenceonProgramComprehension(ICPC) .IEEE,Passau,Bavaria,Germany,
73–82.
[14]Freelancer.2021. RetrievedAugust16,2021fromhttps://www.freelancer.com/
freelancer.com, Accessed: September 2020.
[15] GHTorrent. 2021. Retrieved August 16, 2021 from https://ghtorrent.org/
[16] GitHub. 2021. Retrieved August 16, 2021 from https://github.com/
[17] GooglePlay. 2021. Retrieved August 16, 2021 from https://play.google.com
[18]Peter Leo Gorski, Luigi Lo Iacono, Dominik Wermke, Christian Stransky, Sebas-
tianMöller,YaseminAcar,andSaschaFahl.2018. DevelopersDeserveSecurity
Warnings, Too: On the Effect of Integrated Security Advice on Cryptographic
{API}Misuse.In FourteenthSymposiumonUsablePrivacyandSecurity( {SOUPS}
2018). USENIX Association, Baltimore, MD, USA, 265–281.
[19] G*Power. 2021. Retrieved August 16, 2021 from gpower.hhu.de
[20]DanielGraziotin,FabianFagerholm,XiaofengWang,andPekkaAbrahamsson.
2017. Unhappy developers: Bad for themselves, bad for process, and bad for
softwareproduct.In 2017IEEE/ACM39thInternationalConferenceonSoftware
EngineeringCompanion(ICSE-C) . IEEE, Buenos Aires, Argentina, 362–364.
[21]Franki YH Kung, Navio Kwok, and Douglas J Brown. 2018. Are Attention Check
QuestionsaThreattoScaleValidity? AppliedPsychology 67,2(2018),264–283.
https://doi.org/10.1111/apps.12108
[22]AndreMeyer,EarlTBarr,ChristianBird,andThomasZimmermann.2019. Today
was a good day: The daily life of software developers. IEEE Transactions on
Software Engineering (2019).
[23]Emerson Murphy-Hill, Ciera Jaspan, Caitlin Sadowski, David C. Shepherd,
Michael Phillips, Collin Winter, Andrea Knight Dolan, Edward K. Smith, and
Matthew A. Jorde. 2019. What Predicts Software Developers’ Productivity?
Transactions on Software Engineering (2019).
[24]A. Naiakshina, A. Danilova, E. Gerlitz, and M. Smith. 2020. On Conducting
Security Developer Studies with CS Students: Examining a Password Storage
Study with CS Students, Freelancers, and Company Developers. In ACM CHI
ConferenceonHumanFactorsinComputingSystems .ACM,Honolulu,HI,USA,1–13. https://doi.org/10.1145/3313831.3376791
[25]Alena Naiakshina, Anastasia Danilova, Eva Gerlitz, Emanuel von Zezschwitz,
and Matthew Smith. 2019. " If you want, I can store the encrypted password" A
Password-StorageFieldStudywithFreelanceDevelopers.In Proceedingsofthe
2019 CHI Conference on Human Factors in Computing Systems . ACM, Glasgow,
Scotland,Uk,1–12.
[26]A. Naiakshina, A. Danilova, E. Gerlitz, E. von Zezschwitz, and M. Smith. 2019.
"If you want, I can store the encrypted password." A Password-Storage Field
StudywithFreelanceDevelopers.In ACMCHIConferenceonHumanFactorsin
Computing Systems . ACM, Glasgow, Scotland, Uk, 1–12. https://doi.org/10.1145/
3290605.3300370
[27]AlenaNaiakshina,Anastasia Danilova,ChristianTiefenau,MarcoHerzog,and
MatthewSmith.2017. WhyDoDevelopersGetPasswordStorageWrong?AQual-
itativeUsabilityStudy.In 24thACMConferenceonComputerandCommunications
Security - ACM CCS 2017 . ACM, Dallas, Texas, USA, 311–328.
[28]Alena Naiakshina, Anastasia Danilova, Christian Tiefenau, and Matthew Smith.
2018. DeceptionTaskDesigninDeveloperPasswordStudies:ExploringaStudent
Sample.In FourteenthSymposiumonUsablePrivacyandSecurity(SOUPS2018) .
USENIXAssociation, Baltimore, MD, USA, 297–313.
[29] Qualtrics.2021. Retrieved August 16, 2021 from https://www.qualtrics.com
[30]AmazonMechanicalTurk.2018. RetrievedAugust16,2021fromwww.mturk.com
[31]Chamila Wijayarathna and Nalin AG Arachchilage. 2018. Why Johnny Can’t
Store Passwords Securely? A Usability Evaluation of Bouncycastle Password
Hashing.In Proceedingsofthe22ndInternationalConferenceonEvaluationand
Assessment in Software Engineering 2018 . ACM, Christchurch, New Zealand, 205–
210.
[32]Aiko Yamashita and Leon Moonen. 2013. Do developers care about code smells?
An exploratory survey. In 201320th Working Conference on Reverse Engineering
(WCRE). IEEE, Koblenz, Germany, 242–251.
[33]AikoYamashitaandLeonMoonen.2013. Surveyingdeveloperknowledgeand
interest in code smells through online freelance marketplaces. In 2013 2nd In-
ternational Workshop on User Evaluations for Software Engineering Researchers
(USER). IEEE, San Francisco, CA, USA, 5–8.
2090