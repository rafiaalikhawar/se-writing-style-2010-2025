MVD: Memory-Related Vulnerability Detection Based on
Flow-Sensitive Graph Neural Networks
Sicong Cao
Yangzhou University
Yangzhou, China
MX120190439@yzu.edu.cnXiaobing Sunâˆ—
Yangzhou University
Yangzhou, China
xbsun@yzu.edu.cnLili Boâˆ—
Yangzhou University
Yangzhou, China
lilibo@yzu.edu.cn
Rongxin Wu
Xiamen University
Xiamen, China
wurongxin@xmu.edu.cnBin Li
Yangzhou University
Yangzhou, China
lb@yzu.edu.cnChuanqi Tao
Nanjing University of Aeronautics
and Astronautics
Nanjing, China
taochuanqi@nuaa.edu.cn
ABSTRACT
Memory-related vulnerabilities constitute severe threats to the secu-
rityofmodernsoftware.Despitethesuccessofdeeplearning-based
approaches to generic vulnerability detection, they are still limited
bytheunderutilizationofflowinformationwhenappliedfordetect-
ing memory-related vulnerabilities, leading to high false positives.
Inthispaper,wepropose MVD,astatement-level Memory-related
Vulnerability Detection approach based on flow-sensitive graph
neural networks (FS-GNN). FS-GNN is employed to jointly em-
bed both unstructured information (i.e., source code) and struc-
turedinformation(i.e.,control-anddata-flow)tocaptureimplicit
memory-relatedvulnerabilitypatterns.Weevaluate MVDonthe
datasetwhichcontains4,353real-worldmemory-relatedvulnera-
bilities, and compare our approach with three state-of-the-art deep
learning-basedapproachesaswellasfivepopularstaticanalysis-
basedmemorydetectors.Theexperimentresultsshowthat MVD
achievesbetterdetectionaccuracy,outperformingbothstate-of-the-
art DL-based and static analysis-based approaches. Furthermore,
MVDmakes a great trade-off between accuracy and efficiency.
CCS CONCEPTS
â€¢Security and privacy â†’Software security engineering.
KEYWORDS
Memory-RelatedVulnerability,VulnerabilityDetection,GraphNeu-
ral Networks, Flow Analysis
*Xiaobing Sun and Lili Bo are the corresponding authors.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510219ACM Reference Format:
Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi
Tao.2022. MVD:Memory-RelatedVulnerabilityDetectionBasedonFlow-
Sensitive Graph Neural Networks. In 44th International Conference on Soft-
ware Engineering (ICSE â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA. ACM,
New York, NY, USA, 13 pages. https://doi.org/10.1145/3510003.3510219
1 INTRODUCTION
Asoneofthemostrepresentativevulnerabilities, memory-related
vulnerabilities can result in performance degradation and program
crash,severelythreateningthesecurityofmodernsoftware[ 19,66].
According to the data released by CVE (Common Vulnerabilities
andExposures[ 2]),nearlyathirdofthevulnerabilities(32.6%)in
Linux Kernel [ 10] are related to improper memory operations [ 33].
Many static analysis approaches [ 21,24,31,34,38,40,52,56,58,
60,61]havebeenproposedtodetectmemory-relatedvulnerabilities
and shown their effectiveness. They use some pre-defined vulnera-
bilityrulesorpatternstosearchforimpropermemoryoperations
[41,42].However,well-definedvulnerabilityrulesorpatterns are
highly dependent on expert knowledge, and thus it is difficult to
coverallthecases.Whatâ€™sworse,thesophisticatedprogramming
logic in real-world software projects gets in the way of the manual
identificationoftherules,andthusgreatlycompromisestheper-
formanceofthetraditionalstaticanalysis-basedapproaches[ 51].
Recently, benefiting from the powerful performance of deep learn-
ing (DL), a number of approaches [ 16,17,20,23,44â€“46,64,70â€“72]
have been proposed to leverage DL models to capture program
semantics to identify potential software vulnerabilities. Compared
withtraditionalstaticanalysis-basedapproaches,theycanautomat-
ically extract implicit vulnerability patterns from prior vulnerable
codeinsteadofrequiringexpert involvement.Howeve r,theexisting
DL-based approaches suffer from two limitations when applied to
memory-related vulnerability detection, as described below.
Flow InformationUnderutilization: Due to the underutiliza-
tion of flow information, existing DL-based approaches failed to
detect complicated memory-related vulnerabilities in real-world
projects[ 20]forthefollowingtwoaspects:(1)lackofinterprocedu-
ral analysis, and (2) partial flow information loss in model training.
Fortheformerone,mostofDL-basedapproaches[ 17,23,44,64,71]
14562022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao
takethefunction-level vulnerablecodeasinputtoconductintrapro-
ceduralanalysisforfeatureextraction,ignoringcallrelationsbe-
tween functions. However, in real-world programs, operations like
callingauser-definedfunctionwhichrealizesmemoryallocation
orfreearewidespread.Missinginterproceduralanalysismaycause
incompletesemanticmodeling,resultinginlowerRecallandPre-
cision.For thelatter one,limitedby thecapability ofpopularDL
models (e.g., BiLSTM [ 30,45,46,62], GGNN [ 64,71], and GCN
[20]) in handling multiple relations, partial flow information is lost
during the process of model training. For example, Devign[71]
uses GGNN [ 43] as the basic model to propagate and aggregate
information across multi-relational graphs. Since GGNN treats the
relational graph as multiple directed graphs without attributes (i.e.,
feature information is only passed between nodes connected by
edgesofthesametype),itseffectivenessisoftencompromisedby
the tremendous increase in the number of data-flow edges with
different attributes. Thus, Devignhas to substitute them with three
othertoken-level relations(i.e., LastRead, LastWrite,and Comput-
edFrom[1]) to make it more adaptive for the graph embedding,
sacrificing partial precise data-flow information well preserved in
graphs.Asimpleinstanceisthatreceivinganormalpointervariable
(non-vulnerable)isobviouslynotthesameasreceivingapointer
variable which points to the memory just released (vulnerable).
Coarse Granularity: The detection granularity of the existing
DL-based approaches is mostly at the function-level [17,23,44,64,
71]orslice-level [20,45,46,72].However,developersstillneedto
spend a deal of time in manually narrowing down the range of
suspiciousstatements(oroperations).Achievingfine-grainedde-
tectionresultsisnon-trivial.Duetothehugedifferencesbetween
variousvulnerabilities,existingDL-basedapproachesforgeneric
vulnerabilitydetectionhavetosacrificeuniquesemanticfeatures
specifictocertainvulnerabilitiestoensurethatthetrainedmodel
can cover the general characteristics of the majority of vulnera-
bilities. In comparison with other vulnerabilities, memory-related
vulnerabilitiesareusuallyfixedwithoneorseverallinesofcode,
whichmakesfine-graineddetectionpossible.Forexample, memory
leakcanbelocatedtothestatementwhichallocatesmemory,while
use-after-free can be located to the statement which frees memory.
Inthispaper,weproposeanovelapproach(MVD )basedonflow-
sensitive graph neural networks to alleviate the above limitations.
Fully Utilizing Flow Information: To capture more compre-
hensiveandpreciseprogramsemantics, MVDcombinesProgram
Dependence Graph (PDG) with Call Graph (CG) [ 53] to capture
interprocedural control- and data-flow information. First, we con-
duct interprocedural analysis by extending PDG with additionalsemantic information (including call relations and return values
between functions)using CG.In ourapproach, codesnippets and
relations (i.e., edges) are embedded in compact low-dimensional
representationstopreserveboththeunstructured(i.e.,sourcecode)
andstructured(i.e.,control-anddata-flow)information.Further-
more,inordertomakethedetectionmodellearneffectivememory-relatedvulnerabilitypatternsfromcomprehensiveandpreciseflow
information, MVDconstructs a novel Flow-Sensitive Graph Neural
Networks (FS-GNN) to jointly embed statements and flow informa-
tion to capture program semantics from vulnerable code.
Fine Granularity: We formalize the detection of vulnerable
statements as a node classification problem, i.e., identifying whichstatement(s) in the program is vulnerable. Specifically, MVDre-
ceivesthegraphrepresentationofaprogram(inwhichgraphnodesrepresentstatementsandedgesindicatetheirrelations)andoutputs
node labels (i.e., vulnerable or not).
Sincethereiscurrentlynodatasetthatcanbedirectlyusedfor
traininga statement-level memory-relatedvulnerabilitydetection
model, we construct a dataset which contains 4,353 real-world
memory-relatedvulnerabilities.Thedatasetaswellastheempirical
data are available online1.
In summary, this paper makes the following contributions:
â€¢WeproposeanovelFlow-SensitiveGraphNeuralNetworks
(FS-GNN) to support effective detection of memory-related
vulnerabilities.
â€¢We formalize vulnerability detection as a fine-grained node
classification problem to identify suspicious vulnerable state-ments.
â€¢
We evaluate MVDon our constructed dataset, and the results
showthat MVDcaneffectivelydetectmemory-relatedvulnera-
bilitiesoverstate-of-the-artvulnerabilitydetectionapproaches
(including three DL-based and five static analysis-based ap-
proaches).
2 BASICS AND MOTIVATION
2.1 Definitions
Program Dependence Graph. Given a program, all the program
statementsanddependenciesamongstatementsconstitutea Pro-
gram Dependence Graph (PDG) [26].PDGincludes two types of
edges: data dependency edges which reflect the influence of one
variable on another and control dependency edges which reflect
the influence of predicates on the values of variables.
CallGraph. Givenaprogram,its CallGraph(CG) [53]indicates
a series of function calls from call sites (caller) to the callee.
Graph Neural Networks. Due to the outstanding ability in
processinggraphdatastructures, GraphNeuralNetworks(GNNs)
have been used in a variety of data-driven software engineering
(SE)tasks(e.g.,coderepresentation[ 1],clonedetection[ 65],and
bug localization [ 48]) and have achieved great breakthroughs. The
goal of GNNs is to train a parametric function via message passing
between the nodes of graphs for downstream tasks, i.e., graph
classification, node classification, and link prediction.
2.2 Motivating Examples
Figure1showsatypical use-after-free vulnerabilityCVE-2019-15920
[5]inLinuxKernel.Thevulnerablefunction SMB2_read hasbeen
simplified for a clear illustration. We can observe that the memory
space pointed by the pointer reqis released in advance by the
memoryreleasestatement cifs_small_buf_release(req)
atline 5, while it is still used at lines 8-13 . This operation may
allowattackerstowritemaliciousdata.Tofixthisvulnerability,the
pointer reqshouldbereleasedafteritisusedforthelasttime(e.g.,
line 14).Despitethesupportofprecisedatadependenceanalysis,
this vulnerability cannot be easily detected by some static analysis-basedapproachesbecausetheymaynotknow
mempool_free()
at line 24 is a user-defined memory deallocation function.
1https://github.com/MVDetection/MVD
1457
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
1int SMB2_read(const unsigned int xid, struct cifs_io_parms
*io_parms, unsigned int *nbytes, char **buf, int *buf_type) â†©â†’
2{
3 struct smb2_read_plain_req *req =NULL;
4 ...
5- cifs_small_buf_release(req);
6 if(rc){
7 if(rc != -ENODATA){
8 trace_smb3_read_err(xid, req->PersistentFileId,
io_parms->tcon->tid, ses->Suid, io_parms->offset,
io_parms->length, rc);â†©â†’
â†©â†’
9 }else
10 trace_smb3_read_done(xid, req->PersistentFileId,
io_parms->tcon->tid, ses->Suid, io_parms->offset,
0);â†©â†’
â†©â†’
11 return rc== -ENODATA ?0:rc;
12 }else
13 trace_smb3_read_done(xid, req->PersistentFileId,
io_parms->tcon->tid, ses->Suid, io_parms->offset,
io_parms->length);â†©â†’
â†©â†’
14+ cifs_small_buf_release(req);
15 ...
16 return rc;
17}
18void cifs_small_buf_release(void *buf_to_free)
19{
20 if(buf_to_free ==NULL){
21 cifs_dbg(FYI, "Null buffer passed to
cifs_small_buf_release\n"); â†©â†’
22 return;
23 }
24 mempool_free(buf_to_free, cifs_sm_req_poolp);
25 atomic_dec(&smBufAllocCount);
26 return;
27}
Figure1:A Use-After-Free Vulnerability(CVE-2019-15920)in
Linux Kernel
From this example, we can draw the following observations:
Observation 1. Comprehensive and precise interprocedu-
ralflowanalysisisnecessary. AsshowninFigure1,wecanfind
that the program semantics of vulnerable code and non-vulnerable
code are different.In the vulnerable code, vulnerable statementat
line 5releases reqwhen reqisstillbeingusedafterthat,while
inthenon-vulnerablecode, reqisreleasedbythepatchedstate-
ment atline 14only when reqis no longer used. However, due
tothe lackofinterproceduralanalysis, criticalprogramsemantics
(i.e., memory deallocation via mempool_free , which is involved
in the function call to cifs_small_buf_release(req) at
line 5) are ignored by a number of deep learning-based approaches
[17,44,64,71],resultinginincompleteprogramsemanticmodeling
towards vulnerable statement at line 5 .
Inourapproach,weextendbasicProgramDependenceGraph
(PDG) with additional semantic information like call relations and
returnvaluesobtainedfromCallGraph(CG)[ 53]tocapturecom-
prehensiveandpreciseinterproceduralprogramsemantics.With
such rich information,features of memory-related vulnerabilities
can be extracted for more effective detection.
Observation 2. Sensitive contextual information within
flows helps to refine detection granularity. As shown in the
motivating example, the premise of identifying the statement at
line 5as vulnerable is that we should know in advance that req
releasedbythisstatementwillbeusedlater.Thus,todistinguish
vulnerable statements from others, the neural networks used as
detection models should be able to capture sensitive contextualinformation within flows of vulnerable statements for inference.
However,duetothelimitationsofpopularDLmodels[ 45,46,64,71]
in handling multiple relations, rich contextual information arelost during the process of model training. For example, FUNDED
[64]onlyconsidersone-directionaltransmissionofmultiplerela-
tions such as control- and data-flows, and adopts GGNN [ 43]t o
learn vulnerability patterns for detection. While it is successfulinfunction-level vulnerability detection, it loses some important
contextual information from output flows, e.g., the data-flow in-formation within Edge 5->8 will not be used for feature updateof vulnerable statement at
line 5. Thus, it is hard for FUNDED to
identifythestatement line 5asvulnerablebecausecriticaloutput
flowinformation(i.e.,using reqafterfreeingit)isnotpreserved
incifs_small_buf_release(req).
Based on the above observations, we propose a novel model,
FS-GNN,foreffectivelydetectingmemory-relatedvulnerabilities.
FS-GNNisanovelflow-sensitivegraphneuralnetworktojointly
embedbothstatementsandflowinformationforbetterinformation
propagation between statements. With FS-GNN, rich contextual
semanticsofneighborsareaggregatedthroughmultiplerelations
to update the embedding of the central node.
3 OUR APPROACH: MVD
Figure 2 shows the overview of MVD. It consists of two phases:
training phase and detection phase.
Thetrainingphaseincludesthreesteps.Instep1, MVDconstructs
theProgramDependenceGraph(PDG)basedonthecontrol-and
data-flowoftheprogram.Tocapturecomprehensiveandprecise
program semantics, MVDextends the PDG with additional seman-
ticinformationlikecallrelationsandreturnvaluesobtainedfrom
Call Graph (CG) [ 53] to conduct interprocedural analysis.Further-
more,toreduceirrelevantsemanticnoise, MVDconductprogram
slicing [59,67] from the program points of interest. In step 2, MVD
uses Doc2Vec [ 39] to transform the statements of each slice into
low-dimensional vector representations. In step 3, MVDuses Flow-
SensitiveGraphNeuralNetworks(FS-GNN)tojointlyembednodesandrelationstolearnimplicitvulnerabilitypatternsandre-balance
nodelabels distribution.Finally,a well-trainedmodel isproduced
for memory-related vulnerability detection at the statement-level.
Forthedetectionphase,withtheinterproceduralanalysis,the
control- and data-dependence of a target program is first extracted
forprogramslicingtocapturepreciseprogramsemanticsrelated
tomemoryusage.Then,foreachslice,bothitsunstructured(i.e.,
statementembeddingbyDoc2Vec)andstructured(i.e.,control-and
data-flow) information are used as graph input to feed into the
well-trained detection model for vulnerability detection.
3.1 Feature Extraction
First,weusethestaticanalysistool, Joern[68],toparsesourcecode
and construct the Program Dependence Graph (PDG). Then, we
extend the PDG with additional semantic information like call rela-
tions and return values obtained from Call Graph (CG) to conduct
interproceduralanalysis,whichpreservescomprehensivecontrol-
and data-flow information. However, since a function usually con-
tains dozens or even hundreds of code lines while the vulnerabilityexistsonlyinafewlinesofcode,simplytakingthewholeprogram
to train a detection model will reduce the performance of identify-
ingkeyfeatures.Thus, MVDadoptsprogramslicing[ 67]toperform
1458
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao
Detection Phase
Vulnerable node
Non-vulnerable nodeData-flow edge
Control-flow edge
Call edgeReturn edgeVulnerable nodeNon-vulnerable nodeData-flow edge
Control-flow edge
Call edgeReturn edgeVulnerable nodeNon-vulnerable nodeData-flow edge
Control-flow edge
Call edgeReturn edgeTraining Phase
Source CodeSource CodeWell-trained ModelStep 3. Graph Learning Step 1. Feature Extraction
SlicesStep 2. Node Embedding
Nodes
FlowsStep 3. Graph Learning Step 1. Feature Extraction
SlicesStep 2. Node Embedding
Nodes
Flows
Step 1.Feature 
ExtractionStep 2. Node 
Embedding
Source CodeSource CodeDetection ModelProgram SlicesGraph InputSource CodeWell-trained ModelStep 3. Graph Learning Step 1. Feature Extraction
SlicesStep 2. Node Embedding
Nodes
Flows
Step 1.Feature 
ExtractionStep 2. Node 
Embedding
Source CodeDetection ModelProgram SlicesGraph InputDetection Phase
Vulnerable nodeNon-vulnerable nodeData-flow edge
Control-flow edge
Call edgeReturn edgeTraining Phase
Source Code
Well-trained Model
Step 3. Graph Learning Step 1. Feature Extraction
SlicesStep 2. Node Embedding
Nodes
Flows
Step 1.Feature 
ExtractionStep 2. Node 
Embedding
Source CodeDetection ModelProgram SlicesGraph Input
Figure 2: Overview of MVD
1void memory_leak ()
2{
3 char *str ="This is a string";
4 char *str1;
5 memory_leak_func(strlen(str),&str1);
6 strcpy(str1,str);
7}
8void memory_leak_func (int len,char **stringPtr)
9{
10 char *p=malloc(sizeof(char) *(len+1));
11 *stringPtr =p;
12}
(a) Exemplary Code Sample
Slices
str
stringPtr
plen
str1
438
10
1151PDG
str
stringPtr
pstr1len
str1
str 438
10
115
61
Data-flow edge Point of interestPoint of interest
Normal nodeNormal node Control-flow edgeCall edge
Return edgeData-flow edge Point of interest
Normal node Control-flow edgeCall edge
Return edgeData-flow edge Point of interestNormal node Control-flow edgeCall edge
Return edgeSlices
str
stringPtr
plen
str1
438
10
1151PDG
str
stringPtr
pstr1len
str1
str 438
10
115
61
Data-flow edge Point of interestNormal node Control-flow edgeCall edge
Return edge
(b) Program Slicing
Figure 3: Details of Feature Extraction
backwardandforwardslicingfromtheprogrampointofinterest
to avoid noise induced by irrelevant statements.
To ensure that the generated slices contain memory-related vul-
nerabilities, we mainly focus on two types of program points of
interest:1) systemAPIcalls,and2) pointervariable.Asmentionedin
previousworks[ 20,45,46,72],themisuseof systemAPIcalls isone
of the major causes of vulnerabilities, including memory-related
vulnerabilities. For example, syscall_buf is a typical system API
callrelated tobuffer operations in Linux Kernel. Itoften occurs in
Out-of-boundsRead/Write andothersimilar buffer-relatedvulner-
abilities. In total, we conclude 217 system API calls from several
static memory detectors [ 24,56] as slicing criteria for extracting
vulnerablecodesnippets.For pointervariable,ithasbeenwidely
adopted by traditional static analysis-based approaches [ 24,40,60].It should be noted that starting from the program point of interest,
weperformbackwardslicingaccordingtobothcontrol-anddata-
dependence, but forward slicing based on only data-dependence
because improper memory operations (e.g., allocating memory but
not freeing it) have been involved in the forward data-dependence,
andusuallyforwardcontrol-dependencewillinduceagreatdealof
irrelevant statements.
Figure 3 provides an example to show the process of feature
extraction.AsshowninFigure3a,itisa memoryleak vulnerabil-
ity. Atline 5, it allocates memory through malloc() in function
memory_leak_func() withoutfreeingeventotheendofthe
program.Inourapproach,thecontrol-anddata-flowinformation
ofthevulnerableprogramisfirstextractedtoconstructthePDG
of the program, which is shown in Figure 3b. Then, based on in-
terprocedural analysis, the call relation (i.e., Edge 5->8) and return
value(i.e.,Edge11->5)informationisadded.Toreduceirrelevant
nodes, we adopt the sensitive function call at line 5(i.e., Node 5
highlighted in red) as the program point to perform backward and
forward slicing. Node 6 is control dependent on Node 5 with an
Edge 5->6, and data dependent on Node 4 with an Edge 4->6. Afterslicing,Node6isremovedbecauseitisnotdata-dependentonNode
5.
3.2 Node Embedding
Afterfeatureextraction,wetransformallstatementnodesinthe
graph into low-dimensional vectors as input to the graph neural
network models.
We use Doc2Vec [ 39] to represent code statements as vectors
sinceitisawidely-usedtechnique[ 20,28]toencodethedocuments
(i.e.,codestatements)insteadofanindividualword(e.g.,avariable)
intoafixed-lengthvector.Then,thevectorsofthestatementand
context wordsare inputto thehidden layer toobtain theinterme-
diatevectorastheinputof softmaxlayer.Finally,intheinference
stage,thevectorofagivenstatementisachievedthroughStochasticGradient Descent (SGD) [
57]. In this way, the Doc2Vec can provide
a more precise embedding of the code statement that will preserve
the semantic information.
1459
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
3.3 Graph Learning
To train a model which can learn implicit vulnerability patterns
fromsourcecodeandidentifysuspiciousvulnerablestatements,we
construct a novel graph learningframework, Flow-Sensitive Graph
Neural Network (FS-GNN) for graph learning. The details of our
approachareshowninFigure4.ThekeyinsightofFS-GNNisto
jointly embed both statement embedding and flows information
tocapturesensitivecontextualinformationforsemanticlearning.
FS-GNN is composed of three parts: graph embedding, resampling
and classification.
GraphEmbedding. Differentfrommostoftheexistinggraph
embedding approaches that embed only nodes in the graph, weleverage the entity-relation composition operations
ðœ™(Â·)used in
Knowledge Graph embedding approaches [ 14] to jointly embed
statementnodesandmultipleflowedgestoincorporateedgeem-
beddingintotheupdateofnodeinformation.Tobespecific,during
theprocessofgraphembeddinginFS-GNN,thenodeembedding
â„Žð‘£of statement node ð‘£can be updated by:
ð’‰ð‘£=ð‘“/parenlefttpA/parenleftexA
/parenleftbtA/summationdisplay.1
(ð‘¢,ð‘Ÿ)âˆˆN(ð‘£)ð‘¾ðœ†(ð‘Ÿ)ðœ™(ð’™ð‘¢,ð’›ð‘Ÿ)/parenrighttpA/parenrightexA
/parenrightbtA(1)
where ð’‰ð‘£denotes the updated representation of node ð‘£.N(ð‘£)
isasetofimmediateneighborsof vforitsoutgoingedges. ðœ™(Â·)is
acompositionoperator,including subtraction,multiplication,and
circular-correlation. ð’™ð‘¢andð’›ð‘Ÿdenotesinitialfeaturesfornode ð‘¢
(encoded by Doc2Vec) and edge ð‘Ÿ, respectively. Similar to tradi-
tional Relational Graph Neural Networks (RGCN) [ 54], initial edge
representationforedge ð‘Ÿcanbeencodedbybasisdecomposition
[54]asð’›ð‘Ÿ=B/summationtext.1
ð‘=1ð›¼ð‘ð‘Ÿð’—ð‘,where ð’—ð‘âˆˆBisasetoflearnablebasisvec-
torsandð›¼ð‘ð‘ŸâˆˆRisalsothelearnablescalarweightspecifictoedge
typeandbasis. ð‘¾ðœ†(ð‘Ÿ)representsaedgetypespecificparameter.To
makeFS-GNNcontext-awareandcaptureimportantinformation
fromoutgoingedges,wedoubleedgesbyaddinginverseedgesand
assign different weight parameters according to edge types (i.e.,
ð‘¾ðœ†(ð‘Ÿ)=ð‘¾ð‘‚whenð‘Ÿis an initial edge, and ð‘¾ðœ†(ð‘Ÿ)=ð‘¾ð¼whenð‘Ÿis
an inverse edge).
Similarly, the edge embedding â„Žð‘Ÿof edgeð‘Ÿcan be updated by
ð’‰ð‘Ÿ=ð‘¾ð‘Ÿð‘’ð‘™ð’›ð‘Ÿ, where ð‘¾ð‘Ÿð‘’ð‘™is a learnable transformation matrix
which projects all the relations to the same embedding space as
nodes.
Finally,therepresentationofanode ð‘£andedge ð‘Ÿupdatedafter ð‘™
layers are shown as:
ð’‰ð‘™+1
ð‘£=ð‘“/parenlefttpA/parenleftexA
/parenleftbtA/summationdisplay.1
(ð‘¢,ð‘Ÿ)âˆˆN(ð‘£)ð‘¾ð‘™
ðœ†(ð‘Ÿ)ðœ™(ð’‰ð‘™
ð‘¢,ð’‰ð‘™
ð‘Ÿ)/parenrighttpA/parenrightexA
/parenrightbtA(2)
ð’‰ð‘™+1
ð‘Ÿ=ð‘¾ð‘™
ð‘Ÿð‘’ð‘™ð’›ð‘™
ð‘Ÿ (3)
Notethat â„Ž0ð‘£=ð‘¥ð‘¢andâ„Ž0ð‘Ÿ=ð‘§ð‘Ÿ(i.e.,initialrepresentationofnode
ð‘£and edge ð‘Ÿ).
Withthehelpofourflow-sensitivegraphlearning,contextual
informationcanbecapturedandsensitiveflowinformationisgiven
more attention. For example, in Figure 4, initial node representa-
tionisencodedbyDoc2Vecandedgerepresentationiscalculated
by basis decomposition. Edge matrix is inversed first to capturecontextual feature information. Then, to aggregate information
fromneighbornodestoupdatetherepresentationofNode3,initial
representations of Nodes 1, 4, 5 are embedded jointly with their
incoming edges (i.e., Edges 3->1, 3->4, 3->5) by Eq. 2 to preserve
some important features from outgoing nodes.
Resampling. Afterð‘™layersgraphlearning,directlytrainingthe
classifiers on all statement nodes is biased because the distribution
of non-vulnerable nodes and vulnerable nodes is extremely imbal-
anced.Forexample,inFigure3,althoughwehavefilteredoutsomeirrelevant nodes by program slicing, the number of non-vulnerable
nodes (i.e., Node 1-4, 6, 8-11) is still larger than that of vulnera-ble nodes (i.e., Node 5). To generate some synthetic vulnerable
nodestore-balancethedistribution,weadopt GraphSMOTE [69],a
graph-level oversamplingframework,asthebasiccomponentfor
our resampling.
Concretely, it contains two steps: (1) node generation, and (2)
edge generation. Firstly, to generate high-quality synthetic nodes,
we utilize the widely-used SMOTE[18] algorithm to perform inter-
polation on vulnerable nodes. It searches for the closest neighbour
nodearoundeachminoritynode(i.e.,vulnerablenode)intheem-
bedding space and generates synthetic nodes between them. Then,
edge generator adopts weighted inner production [ 69] to generate
edges and gives link predictions for synthetic nodes by setting a
threshold ðœ‚tokeeptheconnectivityofthegraph.Ifthepredicted
probability of connection between synthetic node ð‘£/primeand its closest
neighbornode ð‘¢isgreaterthan ðœ‚,boththesyntheticnode ð‘£/primeand
edge[ð‘£/prime,ð‘¢]will be put into the augmented adjacency matrix of
originalgraphs.Tomaketheanalysiseasier,thetypeofallsyntheticedgesissetas "Control" (i.e.,syntheticnodesarecontrol-dependent
on their neighbor nodes)2.
Owing to the contribution of resampling, the proportion of
memory-relatedvulnerablestatementsincreases,avoidingthewell-
trained detection model biased caused by imbalanced distribution
of vulnerable nodes and non vulnerable nodes. For example, in
Figure4,threesyntheticnodes(Pink-shaded)areconnectedwith
one vulnerable node (i.e., Node 5) and one non-vulnerable node
(i.e., Node 11).
Classification. Beforetrainingtheclassificationmodel,FS-GNN
adopts one-layer flow-sensitive graph learning block in Section 3.1
againtoupdatenodeinformationbyEq.2.Bylearningboththeun-
structured (i.e., statement embedding) and structured (i.e., various
flows) features from nodes and edges, the classification model are
employedtodistinguishvulnerableandnon-vulnerablestatements.
Totrainthemodel,weusethe softmaxactivationfunctionasthe
last linear layer for node classification and minimize the following
cross-entropy loss on all labeled nodes (i.e., vulnerable or non-
vulnerable):
ð‘šð‘–ð‘›
ðœƒL=âˆ’/summationdisplay.1
ðºâˆˆG1
|V|/summationdisplay.1
ð‘–âˆˆVð¾/summationdisplay.1
ð‘˜=1ð‘¡ð‘–ð‘˜lnâ„Ž(ð¿)
ð‘–ð‘˜(4)
whereðºis a code slice graph in the training set G,Vis the
setofnodesinourtrainingset. â„Ž(ð¿)
ð‘–ð‘˜representstheprobabilityof
nodeð‘–belonging to class ð‘˜, whereð‘˜={0,1}for the binary node
2We omit data-dependency flow because during the empirical study, we find that a
large number of irrelevant synthetic data-dependency edges can introduce biases and
make the performance of the detection model deteriorate.
1460
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao
Â·
Â·
Â·Â·
Â·Â·Â·
Â·Â·Softmax
Â·
Â·Â·Softmax
1010Control
Control
Control_InvControl_Invstr
str_Inv
char *str1;4char *str1;4void 
memory_leak1void 
memory_leak1
memory_leak_func
(strlen(str),&str1);5
memory_leak_func
(strlen(str),&str1);5
char *str = "This 
is a string";3
char *str = "This 
is a string";3
ControlControl_Invstr
char *str1;4char *str1;4void 
memory_leak1void 
memory_leak1
memory_leak_func
(strlen(str),&str1);5
memory_leak_func
(strlen(str),&str1);5
char *str = "This 
is a string";3
char *str = "This 
is a string";3II
I++WI
WOWo
str
stringPtr
plen
str1
438
10
1151Part 1. Graph Embedding Part 3. Cl assification Part 2. ResamplingFS-GNN
Â·
Â·Â·Softmax
10Control
Control
Control_InvControl_Invstr
str_Inv
char *str1;4void 
memory_leak1
memory_leak_func
(strlen(str),&str1);5
char *str = "This 
is a string";3
ControlControl_Invstr
char *str1;4void 
memory_leak1
memory_leak_func
(strlen(str),&str1);5
char *str = "This 
is a string";3II
I+WI
WOWo
str
stringPtr
plen
str1
438
10
1151Part 1. Graph Embedding Part 3. Cl assification Part 2. ResamplingFS-GNN
Figure 4: Graph Learning with FS-GNN
classification task. ð‘¡ð‘–ð‘˜denotes respective ground truth label for
nodeð‘–.
3.4 Vulnerability Detection
Inthedetectionphase,weapplythewell-trainedmodeltodetect
potential memory-related vulnerabilities in programs and identify
suspicious statements.
Specifically, similar to training phase, program semantics re-
flected in the graph representations of source code are captured
through interprocedural analysis. In order to reduce the number
ofmemoryoperations-irrelevantstatements,programsaresliced
accordingtopointsofinterest(systemAPIcalls andpointervariable )
to obtain a batch of program slices (Section 3.1). Next, statement
nodesinprogramslicesareembeddedintolow-dimensionalvec-
tors through Doc2Vec (Section 3.2). Finally, both unstructured (i.e.,
statement embedding) and structured (i.e., control- and data-flow)
informationareusedasgraphinputtofeedintothewell-trained
detection model for vulnerability detection.
4 EXPERIMENTS
4.1 Research Questions
RQ1.Howeffectiveis MVDindetectingmemory-relatedvulner-
abilities compared to existing deep learning-based vulnerability
detection approaches?
Works most relevant to MVDare deep learning-based vulner-
ability detection approaches. By investigating this RQ, we aim
to answer how well does MVDperform in comparison with the
state-of-the-artdeeplearning-basedapproachesinmemory-related
vulnerability detection.
RQ2.How effective is MVDin detecting memory-related vulnera-
bilitiescompared tostatic analysis-basedvulnerability detectors?
Static analysis-based vulnerability detection tools are widely-
used and perform well on memory-related vulnerabilities. In addi-
tion,staticanalysis-basedapproachescanidentifythestatement-
level results for vulnerability detection (i.e., fine-grained detection
results). Therefore, the purpose of this RQ is to analyze how MVD
perform compared with existing static analysis-based detectors.RQ3.
HoweffectiveisFS-GNNformemory-relatedvulnerability
detection?One of the key contributions of our approach is Flow-Sensitive
GraphNeuralNetwork,whichjointlyembedsbothunstructured
(i.e., code snippets) and structured (i.e., control- and data-flows)
informationtolearncomprehensiveandpreciseprogramsemantics.
Different from RQ1, we aim to show whether sensitive contextual
informationcapturedbyFS-GNNcontributestomemory-related
vulnerability detection in comparison with other popular GNNs
(i.e.,evaluatingtheeffectivenessoffullyutilizingflowinformation).
RQ4.Howefficientare MVDandbaselinesintermsoftheirtime
cost for detecting memory-related vulnerabilities?
Efficiencyisimportantforevaluatingtheperformanceofmemory-
related vulnerability detection approaches. An approach whichcosts too much time for detecting vulnerabilities may encounteradoption barriers in practice. This RQ is to investigate whether
MVDcan make a better trade-off between accuracy and efficiency.
4.2 Experiment Setup
4.2.1 Dataset. Since existing vulnerability datasets are either not
tailoredformemory-relatedvulnerabilities[ 17,20,25,29,71],ornot
sufficientfortrainingdeeplearningmodels(e.g.,SPECCINT2000
[32]), wemanually constructed a new vulnerability dataset which
covers13commonmemory-relatedvulnerabilities(includingCWE-
119,-120,-121,-122,-124,-125,-126,-401,-415,-416,-476,-787,and
-824)formodeltrainingandevaluation.Ourdatasetisbasedontwo
widely-adoptedsources:(1) SARD[ 13],awell-known samplevul-
nerabilitydataset,and(2)CVE[ 2],afamousvulnerabilitydatabase.
In this work, we focused on C/C++ programs due to their frequent
memory problems caused by low-level control of memory [ 63] and
adoptedvulnerabilitytypes(i.e.,CWE-IDs[ 3])asoursearchcriteria
to collect memory-related vulnerabilities from SARD and CVE. For
real-world vulnerabilities, we only considered CVEs which contain
sourcecodeandfromwhichwecollectbothvulnerablefunctions
andcorrespondingpatchedfunctions.ForSARD,wecollectedall
test cases labeled as "bad".
The statistics of the vulnerable programs in our dataset are
showninTable1.Itincludes1,208real-worldvulnerabilitiesinCVE,
covering 10 open-source C/C++ projects which are widely adopted
as target projects by prior works [ 27,45,46,71], and 3,145 vulnera-
blesamples(i.e.,testcases)inSARD.Column2representsthescopeofprojectversionsaffectedbyvulnerabilitiesinourdataset.Column
1461
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 1: Details of vulnerability dataset.
Project #Version #Samples #Vertices #Edges
Linux Kernel 2.6-4.20 868 26,917 29,512
FFmpeg 0.5-4.1 73 1,971 2,168
Asterisk 1.4-16.14 18 468 502
Libarchive 2.2-3.4 11 235 269
Libming 0.4.7 7 119 141
LibTIFF 3.8-4.0 24 584 639
Libav 12.3 16 526 573
LibPNG 1.0.x-1.6.x 13 392 447
QEMU 0.9-4.3 121 4,711 5,308
Wireshark 1.2-3.2 57 2,056 2,190
SARD - 3,145 11,237 13,049
Total - 4,353 49,216 54,798
Figure 5: Distribution of Vulnerability Types
3 denotes the number of vulnerable samples. A vulnerable sample
may contain one or more vulnerable functions. Column 4 and Col-
umn 5 are the number of nodes and edges in slices, respectively.
Furthermore, the distribution of different types of memory-related
vulnerabilitiesinourdatasetisshowninFigure5,withCWE-119
(Improper Restriction of Operations within the Bounds of a Mem-
oryBuffer)accountingforthehighestpercentageat40%(including
1731 vulnerable samples).
4.2.2 Data Labeling. Totrainadetectionmodel,wefirstneedto
conduct datalabeling.Thereare twotypes oflabels forstatement
nodes in the graph representation of a program: 1) vulnerable rep-
resents that the node is related to an improper operation in the
vulnerable programs; 2) non-vulnerable represents that the node is
relatedtothenormaloperation.Tomakethisprocessautomatic,we
adopted a simple labeling strategy with difffiles. We first conduct
programslicingforeachvulnerablesampletogenerateanumberof
slices. Then, for each slice of the samples in SARD, we labeled the
statementnodesannotatedwith"errors"as vulnerable.Foreachslice
ofthereal-worldvulnerabilitiesinCVE,wecomparedstatementsin
eachsliceandthatinthecorrespondingvulnerablefunctionaccord-
ingtodifffiles.Ifastatementwasdeletedoraltered(i.e.,starting
with "-" in difffiles), it would be labeled as vulnerable, and non-
vulnerable otherwise.However,inpractice,partofmemory-relatedvulnerabilities did not contain "-" in their patches. For example, in
CVE-2019-19083 [ 6], memory leaks because allocated memory can
notbereleasedwhenmemoryallocationfails.Thisvulnerability
canbefixedbyaddingamemoryreleasestatement.Thus,forthese
vulnerabilitiescannotbedirectlylabeled,wemanuallylabeledvul-
nerablenodesthroughidentifyingimproperoperations[ 49](e.g.,
memoryallocationordeallocationstatements).Inordertoavoidintroducing artificial deviation, two postgraduates and one Ph.D
participatedinthislabelingprocess.Iftwopostgraduatesdisagreedon the label of the same sample, the sample would be forwarded to
the Ph.D evaluator for further investigation.
4.2.3 Baseline Methods. To answer the first research question, we
selected three state-of-the-art DL-based vulnerability detectiontechniques, i.e., VulDeePecker [
46],SySeVR[45], andDevign[71].
VulDeePecker andSySeVRrepresented source code as sequences
and used BiLSTM model for vulnerability detection at the slice-
level.Devignconstructed a joint graph structure (including AST,
CFG,DFG,andcodesequences)andusedGGNNmodeltodetect
vulnerabilities at the function-level. They are widely adopted as
baselines in recent works [ 20,44,64] and have been shown to
beeffectiveindetectingmemory-relatedvulnerabilities[ 20]e v en
though they are designed for generic vulnerability detection.
ToinvestigateRQ2,weselectedfivepopularstaticanalysis-based
vulnerability detectors, i.e., PCA[40],Saber[60],Flawfinder [8],
RATS[12],andInfer[9].They haveshownrelatively goodperfor-
manceonmemory-relatedvulnerabilitiesandarewidelyadopted
as baselines in prior works [20, 24, 45, 46].
4.2.4 Implementation. We implemented MVDin Python using Py-
Torch[11].OurexperimentswereperformedwiththeNvidiaGraph-
ics Tesla T4 GPU, installed with Ubuntu 18.04, CUDA 10.1.
The neural networks are trained in a batch-wise fashion until
converging and the batch size is set to 32. The dimension of the
vector representation of each node is set to 100 and the dropout is
setto0.1.ADAM[ 36]optimizationalgorithmisusedtotrainthe
modelwiththelearningrateof0.001.Weightdecayissetto5 ð‘’-1
and over-sampling scale is set as 1.0. The other hyper-parameters
of our neural network are tuned through grid search.
For RQ1, it is unfair to compare MVDwith other DL-based
approaches because of our finer granularity. Thus, we used thefunction-level asacompromiseformula,i.e.,ifavulnerablestate-
ment was identified correctly by MVD, we would consider the
functionitbelongedtowasalsodetectedcorrectly.ForDL-based
baselines, we respectively used the vulnerable and non-vulnerable
functions as positive and negative samples to train the detectionmodels. For MVD, we only trained the detection model based on
vulnerable functions (i.e., vulnerable statements are deemed as
positivesamples,whilenon-vulnerablestatementsaredeemedas
negative samples). We randomly chose 80% of the programs for
trainingandtheremaining20%fortesting.Tomakesurethatour
model was fine-tuned, we used ten-fold cross-validation to evaluate
thegeneralizationabilityofeachapproach.InRQ2,weevaluated
MVDandstaticanalysis-basedapproachesatthe function-level and
statement-level,respectively.Atthe function-level,weadoptedthe
same experimental setup as RQ1. At the statement-level, we eval-
uated each approach by randomly selecting 30 latest real-world
vulnerabilities (reported in 2021) from our dataset, covering five
1462
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao
Table 2: Comparison with DL-based approaches
Approach A (%)P ( %)R (%)F 1 (%)
VulDeePecker 60.9 51.4 35.1 41.7
SySeVR 63.4 53.3 62.9 57.7
Devign 68.3 54.8 66.1 59.9
MVD 74.1 61.5 69.4 65.2
commonmemory-relatedvulnerabilities(including MemoryLeak
(ML),Double Free (DF),Buffer Overflow (BO),Use-After-Free (UAF),
andOut-of-boundsRead/Write (OR/W)).Thesevulnerabilitiesare
representative because they cover the vast majority of the vul-
nerabilitytypesinourdataset.Forexample, BufferOverflow (BO)
corresponds to multiple CWEs, including CWE-119, -120, -121, and
-122. To ensure that the trained model is tested on "unseen" pro-
grams,weexcludedthesesamplesfromthetrainingsetof MVD.For
answering RQ3, we respectively replaced our FS-GNN model with
threefamousGNNmodels,includingGCN[ 37],GGNN[ 43],and
RGCN [54], to evaluate the contribution of each model to memory-
related vulnerability detection. For answering RQ4, we recorded
theaveragetraininganddetectiontimeofeachapproachinRQ1
and RQ2 to evaluate time cost of MVDand baselines.
4.3 Evaluation Metrics
We used the following evaluation metrics to measure the effective-
ness of our model:
Accuracy (A) evaluates the performance that how many in-
stances can be correctly labeled. It is calculated as:
ð‘¨ð’„ð’„ð’–ð’“ð’‚ð’„ð’š =ð‘‡ð‘ƒ+ð‘‡ð‘
ð‘‡ð‘ƒ+ð¹ð‘ƒ+ð‘‡ð‘+ð¹ð‘(5)
Precision (P) is the fraction of true vulnerabilities among the
detected ones. It is defined as:
ð‘·ð’“ð’†ð’„ð’Šð’”ð’Šð’ð’ =ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘ƒ(6)
Recall (R) measures how many vulnerabilities can be correctly
detected. It is calculated as:
ð‘¹ð’†ð’„ð’‚ð’ð’ =ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘(7)
F1score(F1) istheharmonicmeanof ð‘…ð‘’ð‘ð‘Žð‘™ð‘™andð‘ƒð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘› ,and
can be calculated as:
ð‘­1ð’”ð’„ð’ð’“ð’† =2ð‘…ð‘’ð‘ð‘Žð‘™ð‘™Â·ð‘ƒð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘›
ð‘…ð‘’ð‘ð‘Žð‘™ð‘™+ð‘ƒð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘›(8)
5 EXPERIMENTAL RESULTS
5.1 RQ1: MVDVS. DL-Based Approaches
Table2showstheoverallresultsofeachdeeplearning-basedap-
proach in terms of the aforementioned evaluation metrics. Overall,
MVDachieves better results and outperforms all of the three re-
ferreddeeplearning-basedapproaches.Onaverage,for MVD,the
Accuracyis74.1%,thePrecisionis61.5%,theRecallis69.4%,and
theF1scoreis65.2%.Moreover,intermsofallmetrics, MVDcan
improve the best performed baseline Devignby 5.0%-12.2%.
MVDvs.VulDeePecker. As shown in Table 2, our approach im-
proves Accuracy, Precision, and F1 score over VulDeePecker by1void invalid_memory_access (){
2 int i=1;
3 char *buf, *c;
4 while(i>0) {
5 buf =(char *)malloc (25 *sizeof(char));
6 if(buf!=NULL)
7 strcpy(buf,"This is String");
8 free(buf);
9 c=buf;
10 i++;
11 if(i>=10)
12 break;}
13 psink =c;
14}
(a) A Vulnerability Missed by VulDeePecker
1static int __init init_msp_flash(void){
2 ...
3 msp_parts[i]=kcalloc(...), GFP_KERNEL);
4 ...
5 if(msp_maps[i].virt ==NULL){
6 kfree(msp_parts[i]);
7 goto cleanup_loop;}
8 if(!msp_maps[i].name){
9 kfree(msp_parts[i]);
10 goto cleanup_loop;}
11 ...
12}
(b) A Non-vulnerable Code Sample Misidentified by SySeVR
1static bool try_merge_free_space(...){
2 ...
3 right_info =tree_search_offset(ctl, offset +bytes,0 ,0 ) ;
4 if(right_info &&rb_prev(&right_info->offset_index))
5 left_info =rb_entry(rb_prev(&right_info->offset_index),
struct btrfs_free_space, offset_index); â†©â†’
6 else
7 left_info =tree_search_offset(ctl, offset -1 ,0 ,0 ) ;
8 if(...) { ...
9 kmem_cache_free(btrfs_free_space_cachep, right_info);
10 merged =true;}
11 if(...) { ...
12 info->offset =left_info ->offse;
13 info->bytes +=left_info ->bytes}
14 return merged;
15}
(c) CVE-2019-19448 [7] Missed by Devign
Figure 6: A Case study of RQ1
21.7%, 19.6%, and 56.4%. Specifically, VulDeePecker achieves the Re-
callofonly35.1%.Bycontrast,theRecallof MVDisashighas69.4%,
nearly double (1.98x). Poor Recall indicates a great deal of vulnera-
bilities can not be detected by VulDeePecker. A main reason is that
VulDeePecker onlytakes data-flowintoaccountwithout regardto
control-flow information. For example, as shown in Figure 6a, it
contains a invalid memory access vulnerability at line 9because
bufhas been freed at line 8in an infinite whileloop. However,
it is missed by VulDeePecker in our experiment because without
control-flowinformation, semanticsof differentbranch structures
will be ignored.
MVDvs.SySeVR.We can observe from Table 2 that, in spite of
significant improvement (1.79x) in Recall (62.9%) in comparison
withVulDeePecker, SySeVRstill behaves worse than MVDin terms
of each metric. Particularly, MVDimproves Precision over SySeVR
by15.4%.Therootcauseforthisperformancegapisthat SySeVR
cannot overcome the main limitation of sequence models (e.g.,
BiLSTM)inprogramsemanticsmodeling.Forexample,inFigure
6b,thereisanon-vulnerablecodesamplefrom LinuxKernel,which
is misidentified by SySeVR. Although SySeVRcaptures control- and
data-dependence relations between statements by constructing
1463
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 3: Comparison with static analysis-based approaches
Approach A (%)P ( %)R (%)F 1 (%)
PCA 65.2 48.9 61.1 54.3
Saber 64.4 47.6 59.2 52.8
Flawfinder 61.1 18.2 23.5 20.5
RATS 56.3 7.9 11.6 9.4
Infer 50.7 33.1 54.8 41.3
MVD 67.6 54.8 63.6 58.9
ControlFlowGraph(CFG)andDataFlowGraph(DFG),program
semantics implied in these information can not be utilized because
SySeVRtreats complex code structures as a sequential sequence
of tokens, which omits the control flow divergence. Thus, this
sample is misidentified as double free because msp_parts[i] is
considered to be freed twice by kfreeat line 6and line 9 .
MVDvs.Devign.MVDalsooutperformsthebestperformedbase-
lineDevign. It indicates that although powerful performance of
GNN in inferring potential vulnerability semantics from graph
representationoftheprogrammakes Devignoutstanding,theun-
derutilization of flow information still restricts the performance of
Devignin detecting more complex memory-related vulnerabilities.
For example, as shown in Figure 6c, it is a real-world vulnera-
bility (CVE-2019-19448 [ 7]) inLinux Kernel missed by Devign.I t
may lead to arbitrary address free ordouble free vulnerability by
attacker because in certain situations, the pointer left_info
atline 7can be the same as right_info atline 3. However, af-
terright_info hasbeenfreedat line 9,left_info whichis
thesameas right_info willbeusedat line 12-13 again.There
are two main reasons why this vulnerability cannot be detected by
Devign.Ontheonehand,duetothelackofinterproceduralanalysis,preciseprogramsemanticslikememoryfree(
kmem_cache_free
atline 9)arehardtobecapturedby Devign,causingimprecisese-
manticmodeling.Onthe otherhand,since Devignprocessesmul-
tipleflowsinformationbypassinginformationineachindividual
graphandthenaggregatesthemacrossgraphs, left_info and
right_info are treated as different data-flows, which causes
complex semantic relations difficult to be preserved.
AnswertoRQ1: IncomparisonwiththepopularDL-based
approaches,MVDachievesbetterdetectionperformanceby
fully utilizing flow information via interprocedural analy-
sis and FS-GNN.
5.2 RQ2: MVDVS. Static Analysis-Based
Approaches
Table 3 shows the experimental results of MVDand the static
analysis-based techniques. Overall, MVDoutperforms all baselines
with regard to the evaluation metrics.
Among all static analysis-based baselines, PCAandSaberobtain
relatively betterdetection performance. PCAachieves thehighest
Precision(48.9%)andRecall(61.1%)duetoitsconsiderationofglobal
variablesandaccurateinterproceduralflowanalysis.Ourapproach
stillimproves PCAby4.1%intermsofRecall,andby12.1%interms9
175126PCA
SaberFlawfinderRATSInferMVDML DF BO UAF OR/W ML DF BO UAF OR/W
9
175126PCASaberFlawfinderRATSInferMVDML DF BO UAF OR/W
Figure7:TheNumberofMemory-RelatedVulnerabilitiesin
Real-World Projects Detected by Each Approach (ML: Mem-ory Leak; DF: Double Free; BO: Buffer Overflow; UAF: Use-
After-Free; OR/W: Out-of-bounds Read/Write)
1static int l2tp_ip_bind(struct sock *sk, struct sockaddr *uaddr,
int addr_len){ â†©â†’
2 ...
3- if(!sock_flag(sk, SOCK_ZAPPED))
4- return -EINVAL;
5 ...
6 read_unlock_bh(&l2tp_ip_lock);
7 lock_sock(sk);
8+ if(!sock_flag(sk, SOCK_ZAPPED))
9+ goto out;
10 ...
11}
Figure 8: A Use-After-Free Vulnerability (CVE-2016-10200
[4]) Missed by All Static Memory Detectors We Compared
of Precision. The reason is that static analysis-based approachesmainly rely on well-defined vulnerability rules or patterns hand-crafted by human experts. They are effective in simple memory-related vulnerabilities (e.g., SARD dataset). However, real-world
vulnerabilitiesare morecomplicated,restricting theeffectiveness
ofthese staticanalysis-based detectors.Similar tothese detectors,
MVDalsoanalyzes interproceduralcontrol-and data-flowinforma-
tion. Owing to the powerful performance of deep learning models,
MVDcanlearnimplicitvulnerabilitypatternsfromvulnerablecode,
insteadof explicitrulesor specifications,makingit moreeffective
in real-world scenarios.
Figure 7 shows the detection results of each approach for five
common memory-related vulnerabilities in real-world projects.
These vulnerabilities are randomly selected from our dataset. Each
detectedindividualvulnerabilitysuccessfullyislabeledbyadark
circle and the bars on the left-hand side are the total number of
successfully detected vulnerabilities. Overall, MVDoutperforms all
baselinesbydetecting17outof30vulnerabilities,includingnine
vulnerabilities cannot be detected by baselines. Especially, in com-
parisonwiththebestperformedbaseline PCA,ourapproachcande-
tecteightmorevulnerabilities.Forexample,asshowninFigure8,itisause-after-free vulnerabilitybecauseaconcurrentcallcouldmod-
ifythesocketflagsbetween
sock_flag(sk, SOCK_ZAPPED)
atline 4andlock_sock() atline 8, allowing local users to gain
privileges or cause a denial of service by making multiple bind sys-
temcallswithoutproperlyascertainingwhetherasockethasthe
SOCK_ZAPPED status. Unfortunately, it is missed by all the static
memory detectors because they cannot detect use-after-free caused
byraceconditionthroughstaticanalysisonly.Inourapproach,it
canbecorrectlydetectedbecauseoftheadvantageofdeeplearning
models in mining implicit vulnerability patterns.
1464
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao
Table 4: Contributions of different graph neural networks
Approach A (%)P ( %)R (%)F 1 (%)
GCN 61.2 17.3 8.2 11.1
GGNN 69.4 41.8 52.5 46.5
RGCN 72.7 49.3 58.1 53.3
FS-GNN 77.5 56.4 62.9 59.5
AnswertoRQ2: Withtheadvantageofdeeplearningmod-
els in mining implicit vulnerability patterns, MVD performs
better in comparison with the popular static analysis-based
approaches.
5.3 RQ3: FS-GNN VS. Other GNNs
Table 4 shows the results of different GNNs. We observe that FS-
GNN can improve the best performed baseline RGCN by 6.7%-
14.4%.Therearemainlytworeasonsforthis.First,FS-GNNadds
edge types into the process of representation learning. It can be
regarded as the joint learning of edge embedding and node em-
bedding. Thus, FS-GNN can preserve the comprehensive program
semantics based on interprocedural control- and data-flow, im-
proving the flow-sensitivity for memory-related vulnerabilities. In
addition, RGCN aggregates node and edge information throughdirected edge, while FS-GNN boosts the effect of edge types oncontext by adding corresponding inverse edges. Still taking thedouble free vulnerability as an example, information of memory
freeindifferentbranchstatementswillaffecttheirconditionnodes
jointly. Therefore, important features of output nodes are also pre-
servedbyFS-GNNfornodeupdateandinformationpropagation.
In addition, we can find that although GGNN can process multiple
relations across graphs, it is still limited by the increasing number
of relations, resulting in lower performance in comparison with
RGCN and FS-GNN.
Furthermore,weobservethattheperformanceofGCNispoor.
The mainreason is thatthe neglectionof edgetypes leads tothe
missing of structured code features (e.g., control- and data-flow).
Withoutaccuratecontrol-anddata-flowinformation,theperfor-
mance of memory-related vulnerability detection drops sharply.
Answer to RQ3: FS-GNNcaneffectivelycontributetothe
performance of MVD, as it can better capture the structured
information of vulnerable code.
5.4 RQ4: Efficiency
Table5liststhetimecost inseconds ofeachapproachintraining
and detecting vulnerabilities. The results show that in comparison
withthe popularstaticanalysis-based approaches, MVDachieves
lesstimecostoverotherapproaches,except PCA.Thisisbecause
PCAspeedsupdatadependencecomputationthroughsacrificing
partial detection precision.Among the four deep learning-based approaches, VulDeePecker
incurs the least training and detection time because it only con-
sidersdata-flowsandusesasimplesequencemodel,BiLSTM,for
model training. However, combining with the results in Table 2,
wecanfindthatitgeneratesthelowestdetectionresultsbecause
the lack of control-flows and the limitations of sequence model
make it fail to capture the structured information. Compared with
other learning-based approaches, MVDspends relatively longer
training and detection time (excluding Devign) because learning
complicated program semantics in graphs is more time-consuming
than in sequence. However, MVDyields better detection results.
Infact,duetothecharacteristicthatdeeplearningmodelscanbe
trainedoffline,theirtrainingcostmaynotbethatimportant.Based
on private vulnerability datasets, the users can train their own
detection models offline and make a prediction within seconds.
Answer to RQ4: In spite of a great deal of training time,
MVDachievesrelativelyshorterdetectiontimewithbetter
detectionresults,makingatrade-offbetweenaccuracyand
efficiency.
6 THREATS TO VALIDITY
External validity. The main external threat to our study is the
generalizability of our experiment results. We respectively investi-
gated4,353vulnerablesamplesfrom10distinctC/C++open-sourceprojectsandSARD,andusedthemixeddatasetformodelevaluationlike prior works. However, due to the huge gap in code complexity,
detectionresultsinpracticalscenariosmaynotbesosatisfactory.Furthermore,ourexperimentsarelimitedtomemory-relatedvul-
nerabilitiesinC/C++programs.Resultsmaynotbereproducible
when applied to more complex vulnerabilities or languages (e.g.,
Java).Nevertheless,ourapproachisgenericandcanbeextended
for other vulnerabilities and languages.
Internalvalidity. Internalvalidityinourexperimentrelatesto
twofactors.Thefirstisourimperfectnodelabeling.Inthiswork,
wemanuallylabelednodeswhichdidnotcontainany "delete"state-
mentasvulnerablethroughidentifyingrelatedsensitiveoperations.
Thus, it is possible that some samples are mislabeled. To avoid
harmful influence caused by incorrect node labels, we tried our
best to conduct the node labeling for the vulnerable samples in ourdatasetbythreeexperiencedresearchers.Inaddition,theimplemen-
tationofbaselinesalsothreatstheresultsofourexperiments.To
compare with existing deep learning-based vulnerability detection
approaches, we have re-implemented Devignbased on a popular
repository3sinceitisclosed-source.wetryourbesttobuildand
tune theDevignparameters on our dataset.
7 RELATED WORKS
Existingmemory-relatedvulnerabilitydetectionapproachescanbe
dividedinto threemaincategories: staticanalysis-based,dynamic
analysis-based, and learning-based approaches.
Static Analysis-Based. Static analysis-based approaches aim
to detect vulnerabilities based on specific vulnerability patterns
3https://github.com/epicosy/devign
1465
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 5: Time cost in seconds of different approaches. N/A: Not Applicable
Method MVD VulDeePecker SySeVR Devign PCA Saber Infer Flawfinder RATS
Training Time(s) 2386.2 1019.5 1833.9 2583.7 N/A N/A N/A N/A N/A
Detection Time(s) 10.4 8.1 9.7 11.9 9.211.8 145.8 17.4 20.6
or memory state model. Cherem et al. [ 21] proposed a solution
namedFastCheck, which reduces the memory leak analysis to a
reachability problem over the guarded value-flow graph. Sui et
al.[60,61]proposed Saber,afull-sparsevalue-flowgraph(SVFG)
basedapproach,toachievethedef-usechainsandvalue-flowofthe
memory for pointer analysis. Shi et al. [ 56] proposed Pinpointto
optimizewidely-usedsparsevalue-flowanalysisthroughdecom-
posing the cost of high-precision points-to analysis. Fan et al. [ 24]
presented SMOKE,astagedapproachformemoryleakdetection,
to solve the scalability problem at industrial scale. Li et al. [ 40]
proposed PCA,astaticinterproceduraldatadependencyanalyzer,
tospeedupdatadependencycomputationthroughpartialcall-path
analysis. Differently, our approach can learn vulnerability features
from large amounts of vulnerability data without requiring any
prior knowledge of vulnerabilities.
Dynamic Analysis-Based. Dynamic detection methods run
thesourcecodeanddynamicallytracktheallocation,useandre-
lease of memory at the run-time. LEAKPOINT [22] monitored the
state of memory objects based on stain analysis and tracked the
last used location of memory and the location where references
werelost. DoubleTake [47]splittheprogramexecutionintomulti-
pleblocksandsavedtheprogramstatebeforeeachblockstarted
running.Theprogramstatewouldbecheckedaftertheexecution
of the block ended to judge whether there was an error in mem-ory.Sniper[
35] used the processorâ€™s monitoring unit (PMU) to
tracktheaccessinstructionstoheapmemory.Then,itcalculated
the staleness of heap objects and executed relevant instructionsagain to capture memory leakage during program execution. Atthe binary level, some dynamic analysis-based tools such as Val-
grind[50],Dr.Memory [15],AddressSanitizer [55]alsoperformwell.
Theytrackmemoryallocationanddeallocationduringaprogramâ€™s
execution, and detect leaks by scanning the programâ€™s heap for
memory blocks that no pointer points to. Unlike dynamic analysis-
basedapproaches, ourapproachdoes notrequirethe executionof
programs.
Learning-Based. Withtheadvanceofmachinelearning(ML)
and especially deep learning (DL) models, some approaches are
proposedtoautomaticallylearnexplicitorimplicitvulnerabilityfea-
tures from known vulnerabilities to identify unseen vulnerabilities
in projects. Li et al. [ 45,46] proposed two slice-based vulnerability
detection approaches, VulDeePecker andSySeVR, to learn syntax
and semantic information of vulnerable code. They represented
sourcecodeassequencesatthe slice-level andusedRNN(e.g.,LSTM
andBGRU)totraintheirdetectionmodels.Zouetal.[ 72]proposed
an attention-based multi-class vulnerability detection approach,
ðœ‡VulDeePecker, to pinpoint types of vulnerabilities. It introduced
codeattention toaccommodateinformationusefulforlearninglocal
featuresandusedabuilding-blockBiLSTMtofusedifferentcode
features.Zhouetal.[ 71]proposedagraphneuralnetwork-basedvulnerability detection model through learning on a rich set of
code semantic representations. Cheng et al. [ 20] embedded both
textualandstructuredinformationofcodeintoacomprehensive
code representation and leveraged a GCN to perform the graph
classification.Wangetat.[ 64]proposed FUNDED,aGNN-basedvul-
nerabilitydetectionapproaches.Theycombinedninemainstream
graphs to extract finer program semantics and extended GGNN to
modelmultiplecoderelationships.Differentfromexistinglearning-
based vulnerability detection approaches, our approach aims toleverage rich flow information to support fine-grained memory-
relatedvulnerabilitydetectionviathenovelflow-sensitivegraph
neural networks.
8 CONCLUSION
In this paper, we propose MVDto detect memory-related vulnera-
bility statements that are related to sensitive operations. MVDem-
ploys a new graph neural network-based approach that leverages
theflow-sensitivegraphneuralnetwork(FS-GNN)tojointlyembed
both unstructured information and structured information for pre-
servinghigh-levelprogramsemanticstolearnimplicitvulnerabilitypatterns.Theexperimentalresultsshowtheeffectivenessofourap-proachbycomparingourapproachwiththreestate-of-the-artdeep
learning-based techniques and five popular static analysis-based
memory detectors.
In the near future, we plan to compare our approach with more
DL-basedapproaches(e.g.,DeepWukong)andstaticmemorydetec-
torsonalargerdatasettogainmoreinsights.Inaddition,weaim
toinvestigateothercoderepresentationtechniquestoefficiently
model flow information specific to memory-related vulnerabilities.
ACKNOWLEDGMENTS
ThisworkissupportedbytheNationalNaturalScienceFoundation
ofChina(No.61872312,No.61972335,No.62002309,No.61902329);
the Six Talent Peaks Project in Jiangsu Province (No. RJFW-053),the Jiangsu â€œ333â€ Project; the Natural Science Foundation of the
Jiangsu Higher Education Institutions of China (No. 20KJB520016);
theOpenFundsofStateKeyLaboratoryforNovelSoftwareTech-
nologyofNanjingUniversity(No.KFKT2020B15,No.KFKT2020B16),
the Yangzhou city-Yangzhou University Science and Technology
CooperationFundProject(YZ2021157),andYangzhouUniversity
Top-level Talents Support Program (2019).
REFERENCES
[1]MiltiadisAllamanis,MarcBrockschmidt,andMahmoudKhademi.2018. Learning
to Represent Programs with Graphs. In 6th International Conference on Learn-
ing Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018,
Conference Track Proceedings. OpenReview.net.
[2]August. 2021 (last accessed). Common Vulnerabilities and Exposures. https:
//cve.mitre.org/.
[3]August.2021(lastaccessed). CommonWeaknessEnumeration. https://cwe.mitre.
org/.
1466
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao
[4]August.2021(lastaccessed). CVE-2016-10200. https://github.com/torvalds/linux/
commit/32c231164b762dddefa13af5a0101032c70b50ef.
[5]August.2021(lastaccessed). CVE-2019-15920. https://github.com/torvalds/linux/
commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e.
[6]August.2021(lastaccessed). CVE-2019-19083. https://github.com/torvalds/linux/
commit/055e547478a11a6360c7ce05e2afc3e366968a12.
[7]August. 2021 (last accessed). CVE-2019-19448. https://github.com/bobfuzzer/
CVE/tree/master/CVE-2019-19448.
[8]August. 2021 (last accessed). Flawfinder. http://www.dwheeler.com/flawfinder.
[9] August. 2021 (last accessed). Infer. https://fbinfer.com.
[10] August. 2021 (last accessed). Linux Kernel. https://www.kernel.org/.
[11] August. 2021 (last accessed). PyTorch. https://pytorch.org/.[12]
August. 2021 (last accessed). Rough Audit Tool for Security. https://code.google.
com/archive/p/rough-auditing-tool-for-security.
[13]August. 2021 (last accessed). Software Assurance Reference Dataset. https:
//samate.nist.gov/SARD/index.php.
[14]Antoine Bordes, Nicolas Usunier, Alberto GarcÃ­a-DurÃ¡n, Jason Weston, and Ok-
sanaYakhnenko.2013. TranslatingEmbeddingsforModelingMulti-relational
Data. InAdvances in Neural Information Processing Systems 26: 27th Annual Con-
ferenceonNeuralInformationProcessingSystems2013.Proceedingsofameeting
held December 5-8, 2013, Lake Tahoe, Nevada, United States. 2787â€“2795.
[15]Derek Bruening and Qin Zhao. 2011. Practical memory checking with Dr. Mem-
ory. InProceedings of the CGO 2011, The 9th International Symposium on Code
GenerationandOptimization,Chamonix,France,April 2-6,2011.IEEEComputer
Society, 213â€“223.
[16]Sicong Cao, Xiaobing Sun, Lili Bo, Ying Wei, and Bin Li. 2021. BGNN4VD :
ConstructingBidirectionalGraphNeural-NetworkforVulnerabilityDetection.
Inf. Softw. Technol. 136 (2021), 106576.
[17]Saikat Chakraborty, Rahul Krishna, Yangruibo Ding, and Baishakhi Ray. 2020.
Deep Learning based Vulnerability Detection: Are We There Yet? arXiv preprint
arXiv:2009.07235 (2020).
[18]NiteshV.Chawla,KevinW.Bowyer,LawrenceO.Hall,andW.PhilipKegelmeyer.
2002. SMOTE: Synthetic Minority Over-sampling Technique. J. Artif. Intell. Res.
16 (2002), 321â€“357.
[19]ZheChen,ChongWang,JunqiYan,YuleiSui,andJingling Xue.2021. Runtime
detectionofmemory errorswithsmartstatus. In ISSTAâ€™21: 30thACMSIGSOFT
InternationalSymposiumonSoftwareTestingandAnalysis,VirtualEvent,Denmark,
July 11-17, 2021. ACM, 296â€“308.
[20]XiaoCheng,HaoyuWang,JiayiHua,GuoaiXu,andYuleiSui.2021.DeepWukong:
Statically Detecting Software Vulnerabilities Using Deep Graph Neural Network.
ACM Trans. Softw. Eng. Methodol. 30, 3 (2021), 38:1â€“38:33.
[21]SigmundCherem,LonniePrincehouse,andRaduRugina.2007. Practicalmemory
leak detection using guarded value-flow analysis. In Proceedings of the ACM
SIGPLAN 2007 Conference on Programming Language Design and Implementation,
San Diego, California, USA, June 10-13, 2007. ACM, 480â€“491.
[22]JamesA.ClauseandAlessandroOrso.2010. LEAKPOINT:pinpointingthecauses
ofmemoryleaks.In Proceedingsofthe32ndACM/IEEEInternationalConference
on Software Engineering - Volume 1, ICSE 2010, Cape Town, South Africa, 1-8 May
2010. ACM, 515â€“524.
[23]HoaKhanhDam,TruyenTran,TrangPham,ShienWeeNg,JohnGrundy,and
Aditya Ghose. 2021. Automatic Feature Learning for Predicting Vulnerable
Software Components. IEEE Trans. Software Eng. 47, 1 (2021), 67â€“85.
[24]GangFan,RongxinWu,QingkaiShi,XiaoXiao,JinguoZhou,andCharlesZhang.
2019. Smoke: scalable path-sensitive memory leak detection for millions of lines
ofcode.In Proceedingsofthe41stInternationalConferenceonSoftwareEngineering,
ICSE 2019, Montreal, QC, Canada, May 25-31, 2019. IEEE / ACM, 72â€“82.
[25]Jiahao Fan, Yi Li, Shaohua Wang, and Tien N. Nguyen. 2020. A C/C++ Code
Vulnerability Dataset with Code Changes and CVE Summaries. In MSR â€™20: 17th
International Conference on Mining Software Repositories, Seoul, Republic of Korea,
29-30 June, 2020. ACM, 508â€“512.
[26]Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. 1987. The Program
DependenceGraphandItsUseinOptimization. ACMTrans.Program.Lang.Syst.
9, 3 (1987), 319â€“349.
[27]Aayush Garg, Renzo Degiovanni, Matthieu Jimenez, Maxime Cordy, MikePapadakis, and Yves Le Traon. 2020. Learning To Predict VulnerabilitiesFrom Vulnerability-Fixes: A Machine Translation Approach. arXiv preprint
arXiv:2012.11701 (2020).
[28]Seyed Mohammad Ghaffarian and Hamid Reza Shahriari. 2021. Neural software
vulnerabilityanalysisusingrichintermediategraphrepresentationsofprograms.
Inf. Sci.553 (2021), 189â€“207.
[29]AntoniosGkortzis,DimitrisMitropoulos,andDiomidisSpinellis.2018. VulinOSS:
a dataset of security vulnerabilities in open-source systems. In Proceedings of
the 15th International Conference on Mining Software Repositories, MSR 2018,
Gothenburg, Sweden, May 28-29, 2018. ACM, 18â€“21.
[30]XiGong,ZhenchangXing,XiaohongLi,ZhiyongFeng,andZhuobingHan.2019.
Joint Prediction of Multiple Vulnerability Characteristics Through Multi-Task
Learning.In 24thInternationalConferenceonEngineeringofComplexComputer
Systems, ICECCS 2019, Guangzhou, China, November 10-13, 2019. IEEE, 31â€“40.[31]DavidL.HeineandMonicaS.Lam.2006. Staticdetectionofleaksinpolymorphic
containers. In 28th International Conference on Software Engineering (ICSE 2006),
Shanghai, China, May 20-28, 2006. ACM, 252â€“261.
[32]JohnL.Henning.2000. SPECCPU2000:MeasuringCPUPerformanceintheNew
Millennium. Computer 33, 7 (2000), 28â€“35.
[33]Nasif Imtiaz and Laurie A. Williams. 2021. Memory Error Detection in Security
Testing.arXiv preprint arXiv:2104.04385 (2021).
[34]XiujuanJi,JufengYang,JingXu,LeiFeng,andXiaohongLi.2012. Interprocedural
path-sensitive resource leaks detection for C programs. In Proceedings of the
FourthAsia-PacificSymposiumonInternetware,Internetware2012,QingDao,China,
October 30-31, 2012. ACM, 19:1â€“19:9.
[35] Changhee Jung,SanghoLee,EaswaranRaman, andSantoshPande.2014. Auto-
matedmemoryleakdetectionforproductionuse.In 36thInternationalConference
onSoftwareEngineering,ICSEâ€™14,Hyderabad,India-May31-June07,2014.ACM,
825â€“836.
[36]DiederikP.KingmaandJimmyBa.2015. Adam:AMethodforStochasticOpti-
mization. In 3rd International Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.
[37]Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification withGraph Convolutional Networks. In 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track
Proceedings. OpenReview.net.
[38]Daniel Kroening and Michael Tautschnig. 2014. CBMC - C Bounded Model
Checker-(CompetitionContribution).In ToolsandAlgorithmsfortheConstruction
and Analysis of Systems - 20th International Conference, TACAS 2014, Held as Part
of the European Joint Conferences on Theory and Practice of Software, ETAPS 2014,
Grenoble, France, April 5-13, 2014. Proceedings (Lecture Notes in Computer Science,
Vol. 8413). Springer, 389â€“391.
[39]Quoc V. Le and TomÃ¡s Mikolov. 2014. Distributed Representations of Sentences
andDocuments.In Proceedingsofthe31thInternationalConferenceonMachine
Learning,ICML2014,Beijing,China,21-26June2014 (JMLRWorkshopandCon-
ference Proceedings, Vol. 32). JMLR.org, 1188â€“1196.
[40]Wen Li,HaipengCai, YuleiSui,and DavidManz.2020. PCA:memoryleak detec-
tionusingpartialcall-pathanalysis.In ESEC/FSEâ€™20:28thACMJointEuropean
SoftwareEngineeringConferenceandSymposiumontheFoundationsofSoftware
Engineering, Virtual Event, USA, November 8-13, 2020. ACM, 1621â€“1625.
[41]YueLi,TianTan,AndersMÃ¸ller,andYannisSmaragdakis.2018. Precision-guided
contextsensitivityforpointeranalysis. Proc.ACMProgram.Lang. 2,OOPSLA
(2018), 141:1â€“141:29.
[42]Yue Li, Tian Tan, Anders MÃ¸ller, and Yannis Smaragdakis. 2020. A Principled
Approach to Selective Context Sensitivity for Pointer Analysis. ACM Trans.
Program. Lang. Syst. 42, 2 (2020), 10:1â€“10:40.
[43]Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. 2016. Gated
GraphSequenceNeuralNetworks.In 4thInternationalConferenceonLearning
Representations,ICLR2016,SanJuan,PuertoRico,May2-4,2016,ConferenceTrack
Proceedings.
[44]YiLi,ShaohuaWang,andTienN.Nguyen.2021. Vulnerabilitydetectionwith
fine-grained interpretations. In ESEC/FSE â€™21: 29th ACM Joint European Software
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering,
Athens, Greece, August 23-28, 2021. ACM, 292â€“303.
[45]Zhen Li, Deqing Zou, Shouhuai Xu, Hai Jin, Yawei Zhu, Zhaoxuan Chen, Sujuan
Wang, and Jialai Wang. 2018. SySeVR: A Framework for Using Deep Learning to
Detect Software Vulnerabilities. arXiv preprint arXiv:1807.06756 (2018).
[46]Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin, Sujuan Wang, Zhijun
Deng, and Yuyi Zhong. 2018. VulDeePecker: A Deep Learning-Based System for
Vulnerability Detection. In 25th Annual Network and Distributed System Security
Symposium, NDSS 2018, San Diego, California, USA, February 18-21, 2018. The
Internet Society.
[47] Tongping Liu, Charlie Curtsinger,and Emery D. Berger. 2016. DoubleTake: fast
and precise error detection via evidence-based dynamic analysis. In Proceedings
ofthe38thInternationalConferenceonSoftwareEngineering,ICSE2016,Austin,
TX, USA, May 14-22, 2016. ACM, 911â€“922.
[48]Yiling Lou, Qihao Zhu, Jinhao Dong, Xia Li, Zeyu Sun, Dan Hao, Lu Zhang, and
Lingming Zhang. 2021. Boosting coverage-based fault localization via graph-
basedrepresentationlearning.In ESEC/FSEâ€™21:29thACMJointEuropeanSoftware
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering,
Athens, Greece, August 23-28, 2021. ACM, 664â€“676.
[49]Kangjie Lu, Aditya Pakki, and Qiushi Wu. 2019. Detecting Missing-Check Bugs
via Semantic- and Context-Aware Criticalness and Constraints Inferences. In
28thUSENIXSecuritySymposium,USENIXSecurity2019,SantaClara,CA,USA,
August 14-16, 2019. USENIX Association, 1769â€“1786.
[50]Nicholas Nethercote and Julian Seward. 2007. Valgrind: a framework for heavy-
weight dynamic binary instrumentation. In Proceedings of the ACM SIGPLAN
2007ConferenceonProgrammingLanguageDesignandImplementation,SanDiego,
California, USA, June 10-13, 2007. ACM, 89â€“100.
[51]YuNong,HaipengCai,PengfeiYe,LiLi,andFengChen.2021. Evaluatingand
comparing memory errorvulnerability detectors. Inf. Softw.Technol. 137 (2021),
106614.
1467
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
[52]Maksim Orlovich and Radu Rugina. 2006. Memory Leak Analysis by Contra-
diction.In StaticAnalysis,13thInternationalSymposium,SAS2006,Seoul,Korea,
August 29-31, 2006, Proceedings (Lecture Notes in Computer Science, Vol. 4134).
Springer, 405â€“424.
[53]BarbaraG.Ryder.1979. ConstructingtheCallGraphofaProgram. IEEETrans.
Software Eng. 5, 3 (1979), 216â€“226.
[54]MichaelSejrSchlichtkrull,ThomasN.Kipf,PeterBloem,RiannevandenBerg,
IvanTitov,andMaxWelling.2018.ModelingRelationalDatawithGraphConvolu-
tionalNetworks.In TheSemanticWeb-15thInternationalConference,ESWC2018,
Heraklion,Crete,Greece,June3-7,2018,Proceedings (LectureNotesinComputer
Science, Vol. 10843). Springer, 593â€“607.
[55]Konstantin Serebryany, Derek Bruening, Alexander Potapenko, and Dmitriy
Vyukov. 2012. AddressSanitizer: A Fast Address Sanity Checker. In 2012 USENIX
Annual Technical Conference, Boston, MA, USA, June 13-15, 2012. USENIX Associ-
ation, 309â€“318.
[56]QingkaiShi,XiaoXiao,RongxinWu,JinguoZhou,GangFan,andCharlesZhang.2018. Pinpoint:fastandprecisesparsevalueflowanalysisformillionlinesofcode.
InProceedingsofthe39thACMSIGPLANConferenceonProgrammingLanguage
DesignandImplementation,PLDI2018,Philadelphia,PA,USA,June18-22,2018 .
ACM, 693â€“706.
[57]Naresh K. Sinha and Michael P. Griscik. 1971. A Stochastic Approximation
Method.IEEE Trans. Syst. Man Cybern. 1, 4 (1971), 338â€“344.
[58]Justin Smith, Brittany Johnson, Emerson R. Murphy-Hill, Bill Chu, andHeather Richter Lipford. 2019. How Developers Diagnose Potential Security
Vulnerabilities with a Static Analysis Tool. IEEE Trans. Software Eng. 45, 9 (2019),
877â€“897.
[59]EzekielO.Soremekun,LukasKirschner,MarcelBÃ¶hme,andAndreasZeller.2021.
Locatingfaultswithprogramslicing:anempiricalanalysis. Empir.Softw.Eng.
26, 3 (2021), 51.
[60]YuleiSui,DingYe,andJinglingXue.2012. Staticmemoryleakdetectionusing
full-sparsevalue-flowanalysis.In InternationalSymposiumonSoftwareTesting
andAnalysis,ISSTA2012,Minneapolis,MN,USA,July15-20,2012.ACM,254â€“264.
[61]YuleiSui,DingYe,andJinglingXue.2014. DetectingMemoryLeaksStatically
with Full-Sparse Value-Flow Analysis. IEEE Trans. Software Eng. 40, 2 (2014),
107â€“122.
[62]Xiaobing Sun, Xin Peng, Kai Zhang, Yang Liu, and Yuanfang Cai. 2019. Howsecurity bugs are fixed and what can be improved: an empirical study withMozilla.Sci. China Inf. Sci. 62, 1 (2019), 19102:1â€“19102:3.
[63]LaszloSzekeres,MathiasPayer,TaoWei,andDawnSong.2013. SoK:EternalWar
inMemory.In 2013IEEESymposiumonSecurityandPrivacy,SP2013,Berkeley,
CA, USA, May 19-22, 2013. IEEE Computer Society, 48â€“62.
[64]HuantingWang,GuixinYe,ZhanyongTang,ShinHweiTan,SongfangHuang,
DingyiFang,YansongFeng,LizhongBian,andZhengWang.2021. Combining
Graph-BasedLearning WithAutomatedData CollectionforCode Vulnerability
Detection. IEEE Trans. Inf. Forensics Secur. 16 (2021), 1943â€“1958.
[65]Wenhan Wang, Ge Li, Bo Ma, Xin Xia, and Zhi Jin. 2020. Detecting Code Clones
with Graph Neural Network and Flow-Augmented Abstract Syntax Tree. In 27th
IEEE International Conference on Software Analysis, Evolution and Reengineering,
SANER 2020, London, ON, Canada, February 18-21, 2020. IEEE, 261â€“271.
[66]Ying Wei, Xiaobing Sun, Lili Bo, Sicong Cao, Xin Xia, and Bin Li. 2021. A
comprehensivestudyonsecuritybugcharacteristics. J.Softw.Evol.Process. 33,
10 (2021).
[67]Mark Weiser. 1984. Program Slicing. IEEE Trans. Software Eng. 10, 4 (1984),
352â€“357.
[68]FabianYamaguchi,NicoGolde,DanielArp,andKonradRieck.2014. Modeling
andDiscoveringVulnerabilitieswithCodePropertyGraphs.In 2014IEEESym-
posiumonSecurityandPrivacy,SP2014,Berkeley,CA,USA,May18-21,2014.IEEE
Computer Society, 590â€“604.
[69]TianxiangZhao,XiangZhang,andSuhangWang.2021. GraphSMOTE:Imbal-
ancedNodeClassificationonGraphswithGraphNeuralNetworks.In WSDM
â€™21,TheFourteenthACMInternationalConferenceonWebSearchandDataMining,
Virtual Event, Israel, March 8-12, 2021. ACM, 833â€“841.
[70]Tianchi Zhou,Xiaobing Sun, XinXia, Bin Li,and Xiang Chen.2019. Improving
defect prediction with deep forest. Inf. Softw. Technol. 114 (2019), 204â€“216.
[71]Yaqin Zhou, Shangqing Liu, Jing Kai Siow, Xiaoning Du, and Yang Liu. 2019. De-
vign: Effective Vulnerability Identification by Learning Comprehensive Program
SemanticsviaGraphNeuralNetworks.In AdvancesinNeuralInformationPro-
cessing Systems32: AnnualConference onNeural Information ProcessingSystems
2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada. 10197â€“10207.
[72]Deqing Zou, Sujuan Wang, Shouhuai Xu, Zhen Li, and Hai Jin. 2021.
ðœ‡VulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability
Detection. IEEE Trans. Dependable Secur. Comput. 18, 5 (2021), 2224â€“2236.
1468
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. 