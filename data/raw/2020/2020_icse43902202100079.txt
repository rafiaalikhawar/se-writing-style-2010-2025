Data-Driven Synthesis of Provably Sound
Side Channel Analyses
Jingbo Wang, Chungha Sung, Mukund Raghothaman and Chao Wang
University of Southern California
Abstract ‚ÄîWe propose a data-driven method for synthesiz-
ing static analyses to detect side-channel information leaks in
cryptographic software. Compared to the conventional way of
manually crafting such static analyzers, which can be tedious,
error prone and suboptimal, our learning-based technique is not
only automated but also provably sound. Our analyzer consists
of a set of type-inference rules learned from the training data,
i.e., example code snippets annotated with the ground truth.
Internally, we use syntax-guided synthesis (SyGuS) to generate
new recursive features and decision tree learning (DTL) to
generate analysis rules based on these features. We guarantee
soundness by proving each learned analysis rule via a technique
called query containment checking . We have implemented our
technique in the LLVM compiler and used it to detect power side
channels in C programs that implement cryptographic protocols.
Our results show that, in addition to being automated and
provably sound during synthesis, our analyzer can achieve the
same empirical accuracy as two state-of-the-art, manually-crafted
analyzers while being 300X and 900X faster, respectively.
I. I NTRODUCTION
Static analyses are being increasingly used to detect secu-
rity vulnerabilities such as side channels [1]‚Äì[4]. However,
manually crafting static analyzers to balance between accuracy
and efÔ¨Åciency is not an easy task: even for domain experts, it
can be labor intensive, error prone, and result in suboptimal
implementations. For example, we may be tempted to add
expensive analysis rules for speciÔ¨Åc sanitized patterns without
realizing they are rare in target programs. Even if the analysis
rules are carefully tuned to a corpus of code initially, they are
unresponsive to changing characteristics of the target programs
and thus may become suboptimal over time; manually updating
them to keep up with new programs would be difÔ¨Åcult.
One way to make better accuracy-efÔ¨Åciency trade-offs and
to dynamically respond to the distribution of target programs
is to use data-driven approaches [5], [6] that automatically
synthesize analyses from labeled examples provided by the
user. However, checking soundness or compliance with user
intent (generalization) has always formed a signiÔ¨Åcant challenge
for example-based synthesis techniques [7]‚Äì[11]. The lack of
soundness guarantees, in particular, hinders the application of
such learned analyzers in security-critical applications. While
several existing works [12]‚Äì[15] try to address this problem,
rigorous soundness guarantees have remained elusive.
To overcome this problem, we propose a learning-based
method for synthesizing a provably-sound static analyzer that
detects side channels in cryptographic software, by inferring a
distribution type for each program variable that indicates if its
value is statistically dependent on the secret. The overall Ô¨ÇowFeature
Synthesis
(SyGuS)
Decision
Tree
LearningQuery
Containment
Checking
Knowledge
Base
(KB)Training
Programs
Type
AnnotationsLearner ProverAnalyzer
Counter -
exampleRVeriÔ¨Åed
RRejectedR
Fig. 1. The overall Ô¨Çow of GPS , our data-driven synthesis method.
of our method, named GPS , is shown in Fig. 1. The input is
a set of training data and the output is a learned analyzer. The
training data are small programs annotated with the ground
truth, e.g., which program variables have leaks.
Internally,GPS consists of a learner and a prover . The
learner uses syntax guided synthesis (SyGuS) to generate
recursive features and decision tree learning (DTL) to generate
type-inference rules based on these features; it returns a set Rof
Datalog formulas that codify these rules. The prover checks the
soundness of each learned rule, i.e., it is not only consistent with
the training examples but also valid for any unseen programs.
This is formulated by solving a query containment checking
problem, i.e., each rule must be justiÔ¨Åed by existing proof rules
called the knowledge base ( KB). Since only proved rules are
added to the analyzer, the analyzer is guaranteed to be sound. If
a rule cannot be proved, we add a counter-example to prevent
thelearner from generating it again.
We have implemented GPS in LLVM and evaluated it on
568 C programs that implement cryptographic protocols and
algorithms [16]‚Äì[18]. Together, they have 2,691K lines of C
code. We compared our learned analyzer with two state-of-
the-art, hand-crafted side-channel analysis tools [1], [2]. Our
experiments show that the learned analyzer achieves the same
empirical accuracy as the two state-of-the-art tools, while being
several orders-of-magnitude faster. SpeciÔ¨Åcally, GPS is, on
average, 300faster than the analyzer from [1] and 900 
faster than the analyzer from [2].
To summarize, this paper makes the following contributions:
We propose the Ô¨Årst data-driven method for learning
a provably sound static analyzer using syntax guided
synthesis (SyGuS) and decision tree learning (DTL).
We guarantee soundness by formulating and solving a
Datalog query containment checking problem.
We demonstrate the effectiveness of our method for
detecting side channels in cryptographic software.
In the remainder of this paper, we begin by presenting the
technical background in Section II and our motivating example
8102021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00079
in Section III. We then describe the learner in Section IV
and the prover in Section V, followed by the experimental
results in Section VI. Finally, we survey the related work in
Section VII and conclude in Section VIII.
II. P RELIMINARIES
A. Power Side-Channels
Prior works in side-channel security [19]‚Äì[21] show that
variance in the power consumption of a computing device may
leak secret information; for example, when a secret value is
stored in a physical register, its number of logical-1 bits may
affect the power consumption of the CPU. Such side-channel
leaks are typically mitigated by masking , e.g., using drandom
bits (r1;:::;rd) to split a key bit intod+ 1 secret shares:
key 1=r1,:::,keyd=rd, andkeyd+1=r1r2:::rdkey,
wheredenotes the logical operation exclusive or (XOR).
Since alld+ 1shares are uniformly distributed in the f0;1g,
in theory, this order-d masking scheme is secure in that any
combination of less than dshares cannot reveal the secret, but
combining all d+ 1shares,key 1key 2:::keyd+1=key,
recovers the secret.
In practice, masking countermeasures must also be imple-
mented properly to avoid de-randomizing any of the secret
shares accidentally. Consider t=tLtR= (r1key)(r1b)
=keyb. While syntactically dependent on the two randomized
valuestLandtR,tis in fact leaky because, semantically, it
does not depend on the random input r1. In this work, we
aim to learn a static analyzer that can soundly prove that all
intermediate variables of a program that implements masking
countermeasures are free of such leaks.
B. Type Systems
Type systems prove to be effective in analyzing power
side channels [1], [2], e.g., by certifying that all intermediate
variables of a program are statistically independent of the secret.
Typically, the program inputs are marked as public ( INPUB ),
secret ( INKEY ) or random ( INRAND ), and then the types of
all other program variables are inferred automatically.
The type of a variable v, denoted TYPE(v) , may be
RUD,SID, orUKD. Here, RUD stands for random uniform
distribution, meaning vis either a random bit or being masked
by a random bit. SID stands for secret independent distribution,
meaningvdoes not depend on the secret. While an RUD
variable is, by deÔ¨Ånition, also SID, anSID variable does
not have to be RUD (e.g., variables that are syntactically
independent of the secret). Finally, UKD stands for unknown
distribution, or potentially leaky; if the analyzer cannot prove
vto be RUD orSID, then it is assumed to be UKD.
Type systems are generally designed to be sound but not
necessarily complete. They are sound in that they never miss
real leaks. For example, by default, they may safely assume
that all variables are UKD, unless a variable is speciÔ¨Åcally
elevated to SID orRUD by an analysis rule. Similarly, they
may conservatively classify SID variables as UKD, or classify
RUD variables as SID, without missing real leaks. In general,the sets of variables that can be marked as the three types form
a hierarchy: SRUDSSIDSUKD.
C. Relations
A program in static single assignment (SSA) format can be
represented as an abstract syntax tree (AST). Static analyzers
infer the type of each node xof the program‚Äôs AST based on
various features ofx. In this work, pre-deÔ¨Åned features are
represented as relations .
Unary relations INPUB (x),INKEY (x), and INRAND (x)
denote the given security level of a program input x,
which may be public, secret, or random.
Unary relations RUD(x),SID(x), andINRAND (x)denote
the inferred type of a program variable x, which may be
uniformly random, secret independent, or unknown.
Unary relation OP(x)denotes the operator type of the
AST nodex, e.g., OP(x):=ANDOR (x)jXOR(x), where
ANDOR (x)means thatx‚Äôs operator type is either logical
and orlogical or , and XOR(x)means that x‚Äôs operator
type is exclusive or ;
Binary relations LC(x;L)andRC(x;R)indicate that the
AST nodesLandRare the left and right operands of x,
respectively.
Binary relation supp(x;y)indicates that the AST node
yis used in the computation of xsyntactically, while
dom(x;y)indicates that random program input yis used
in the computation of xsemantically.
III. M OTIVATION
Consider the program in Fig. 2a, which computes the 
function from Keccak, a family of cryptographic primitives
for the SHA-3 standard [22], [23]. It ultimately computes
the function n1 = i1(:i2^i3), wheremeans XOR.
Unfortunately, a straightforward implementation could poten-
tially leak knowledge of the secret inputs i1,i2and i3if
the attacker were able to guess the intermediate results :i2
and:i2^i3via the power side-channels [24], [25]. The
masking countermeasures in the implementation therefore use
three additional random bits r1,r2andr3to prevent exposure
of the private inputs while still computing the desired function.
A. Problem Setting
Given such a masked program, users want to determine if
they succeed in eliminating side-channel vulnerabilities: in
particular, if each intermediate result is uniformly distributed
(RUD) or at least independent of the sensitive inputs ( SID).
The desired static analysis thus associates each variable x(e.g.,
n1) with the elements of a three-level abstract domain, RUD,
SID orUKD, indicating that xis uniformly distributed ( RUD),
secret independent ( SID), or unknown ( UKD) and therefore
potentially vulnerable.
The decision tree in Fig. 2b represents the desired static ana-
lyzer, which accurately classiÔ¨Åes most variables of the training
corpus, and is also sound when applied to new programs. Given
variablex, the decision tree leverages the features of x‚Äîsuch
as the operator type of x(OP(x) := ANDOR (x)jXOR(x)) and the
811User Label
RUD(b1)
RUD(b2)
RUD(b3)
RUD(b4)
SID(n9)
SID(n8)
SID(n7)
RUD(n6)
SID(n5)
SID(n4)
RUD(n3)
RUD(n2)
UKD(n1)bool mChi( bool i1, bool i2, bool i3,
bool r1, bool r2, bool r3)
{
bool b1 = i1r1;
bool b2 = i2r2;
bool b3 = i3r3;
bool b4 = b2b3;
bool n9 = b3^r2;
bool n8 = r3^r2;
bool n7 = b2_r3;
bool n6 = r1n9;
bool n5 = n7n8;
bool n4 = b2_b3;
bool n3 = n5n6;
bool n2 = n4b1;
bool n1 = n2n3;
return n1;
}
(a)f(x)
true false
UKD OP(x)
XOR(x) ANDOR (x)
TYPE (R) TYPE (L)
SID(R) RUD(R)
TYPE (L) RUD:RUD(L) RUD(L)
UKD TYPE (R)
RUD(L):RUD(L)
RUD UKD:RUD(R) RUD(R)
UKD SID
fn1;n5gfn1;n5gfn6gfn6gfb1;b2;b3;b4;n2;n3gfn4;n7;n8;n9g
(b)
Fig. 2. The program on the left is a perfectly masked function from MAC-Keccak. The decision tree on the right represents the static analyzer that the user
would like to synthesize. Here, xis a program variable, whose type is being computed; LandRare its left and right operands, respectively, and f(x)is a
synthesized feature shown in Fig. 3a (represented by recursive Datalog program).
R1:RUD(x) XOR(x)^RC(x;R)^RUD(R)^:f(x)
R2:f(x) LC(x;L)^RC(x;R)^g1(L;rL)^
g2(R;rR)^rL=rR
R3:g1(r;r) INRAND (r)
R4:g1(x;r) LC(x;y)^g1(y;r)
R5:g1(x;r) RC(x;y)^g1(y;r)
R6:g2(r;r) INRAND (r)
R7:g2(x;r) LC(x;y)^g2(y;r)^XOR(x)
R8:g2(x;r) RC(x;y)^g2(y;r)^XOR(x)
(a) Excerpt of rules learned by the GPS tool.
M1: RUD(x) XOR(x)^dom(x;res)^res6=;
M2: supp(x;x) INRAND (x)_INKEY (x)_INPUB (x)
M3: supp(x;res) LC(x;L)^RC(x;R)^supp(L;SL)^
supp(R;SR)^res=SL[SR
M4: dom(x;x) INRAND (x)
M5: dom(x;;) INKEY (x)_INPUB (x)
M6: dom(x;res) XOR(x)^LC(x;L)^RC(x;R)^
dom(L;SDL)^dom(R;SDR)^
supp(L;SL)^supp(R;SR)^
res= (SDL[SDR)n(SL[SR)
(b) Corresponding expert written rules from SCInfer [2].
Fig. 3. Comparing the rules learned by GPS (Fig. 3a) to manually crafted
rules from SCInfer (Fig. 3b). Observe that the learned rules are sound , i.e., every
variable which potentially leaks information is assigned the distribution type
UKD, while still managing to draw non-trivial conclusions such as RUD(b4).
The learned rules ( R2‚ÄîR8) in Fig. 3a are used to deÔ¨Åne the new feature
f(x)in Fig. 2b.
types ofx‚Äôs operands (e.g. TYPE (L),TYPE (R))‚Äîand maps
xto its corresponding distribution type. The white nodes of
Fig. 2b represent pre-deÔ¨Åned features, while the grey nodes
represent output classes (associated types). Each path from the
root to leaf node corresponds to one analysis rule. The set of
pre-deÔ¨Åned features used in this work is shown in Fig. 4a.
Designing side-channel analyses has been the focus of
intense research, see for example [1]‚Äì[3], [16], [25]‚Äì[28].
Unfortunately, it requires expert knowledge in both computer
security and program analysis, and invariably involves delicate
trade-offs between accuracy and scalability. Our goal in this
work is to assist the analysis designer in automating the
development. This problem has also been the subject of exciting
research [5], [29]; however, these approaches typically eitherrequire computationally intensive deductive synthesis or cannot
guarantee soundness and thus produce errors in both directions,
including false alarms and missed bugs.
In contrast, GPS combines inductive synthesis from user
annotations with logical entailment checking against a more
comprehensive, known-to-be-correct set of proof rules that form
the knowledge base ( KB). It takes as input training programs
like the one in Fig. 2a, where the labels correspond to the types
of program variables ( RUD/SID/UKD for intermediate results
andINRAND /INPUB /INKEY for inputs). The users are free to
annotate as many or as few of these types as they wish: this
affects only the precision of the learned analyzer and not its
soundness. Second, GPS also takes as input the knowledge
baseKB, consisting of proof rules that describe axioms of
propositional logic (Fig. 8) and properties of the distribution
types (Fig. 10). In return, GPS produces as output a set of
Datalog rules which simultaneously achieves high accuracy on
the training data and provably sound with respect to KB.
The proof rules for KB were collected from published pa-
pers on masking countermeasures [1], [2], [16]. We emphasize
thatKB is not necessarily an executable static analyzer since
repeated application of these proof rules need not necessarily
reach a Ô¨Åxpoint and terminate in Ô¨Ånite time; Furthermore, even
in cases where it does terminate, KB may be computationally
expensive and infeasible for application to large programs.
As a concrete example, we compare excerpts of the rules
learned byGPS in Fig. 3a to the corresponding rules from
SCInfer [2]‚Äîa human-written analysis‚Äîin Fig. 3b. LC(x;L)
andRC(x;R)arises in both versions, indicating that LandR
are the left and right operands of xrespectively. SpeciÔ¨Åcally, in
Fig. 3b, supp(x;y)indicates that yis used in the computation
ofxsyntactically while dom(x;y)denotes that random variable
yis used in the computation of xsemantically. Observe the
computationally expensive set operations in the human-written
version to the simpler rules learned by GPS without loss of
soundness or perceptible loss in accuracy. These points are
also borne out in our experiments in Table II, where SCInfer
takes>45 minutes on some Keccak benchmarks, while our
812OP(v)v::=xjLjR
AND ORNOT XOR MULLEAF
TYPE (v)v::=LjR
RUD SID UKD INRAND INPUB INKEY
RUD(x)SID(x)UKD(x)
(a)OP(x)
ANDOR (x) XOR(x)
SID OP(R)
LEAF (R)ANDOR (R)XOR(R)
RUD TYPE (L) TYPE (L)
SID(L)RUD(L)
SID RUDSID(L) RUD(L)
RUD RUD?UKDfn4;n7;n8;n9gfn4;n7;n8;n9g
fn5gfn5gfn6gfn6gfn2;n3gfn2;n3gfb4;n1gfb4;n1g fb1;b2;b3gfb1;b2;b3g
(b)OP(x)
ANDOR (x) XOR(x)
SID OP(R)
LEAF (R)ANDOR (R)XOR(R)
RUD TYPE (L) TYPE (L)
SID(L)RUD(L)
SID RUDSID(L) RUD(L)
RUD f(x)
true false
UKD RUD
(c)
Fig. 4. The classiÔ¨Åer of Fig. 4b is learned only using the features in Fig. 4a. Because of the limited expressive power of these features, the learned analysis
necessarily misclassiÔ¨Åes either b4orn1. Fig. 4c denotes the candidate analyzer produced after one round of feature synthesis. The blue paths corresponds
to the rule RUD(x) XOR(x)^XOR(R)^RUD(L)^:f(x)^LC(x;L)^RC(x;R). Unfortunately, even though this analysis (Fig. 4c) achieves 100%
training accuracy, the leaf nodes highlighted in red correspond to unsound predictions.
learned analysis takes <5 seconds.
GPS consists of two phases: First, it learns a set of type-
inference rules‚Äîalternatively represented either as Datalog
programs or as decision trees‚Äîthat are consistent with the
training data. Second, it proves these rules against the knowl-
edge base. In the next two subsections, we will explain the
learning and soundness proving processes respectively.
B. Feature Synthesis and Rule Learning
The learned analyzer associates each node xof a program‚Äôs
abstract syntax tree (AST) with an element of the distribution
typefUKD(x);SID(x);RUD(x)g. We may therefore interpret
the analyzer as a decision tree that, by considering various
features of an AST node, maps it to a type. With a pre-deÔ¨Åned
set of features, such as those shown in Fig. 4a, analyzers of
this form can be learned with classical decision tree learning
(DTL) algorithms. Fig. 4b shows such an analyzer, learned
from the labeled program of Fig. 2a.
Unfortunately, the pre-deÔ¨Åned features may not be strong
enough to distinguish between nodes with different training
labels, e.g., b4andn1from the training program, which have
distinct labels RUD(b4)andUKD(n1), but after being sifted
into the node highlighted in red in Fig. 4b, cannot be separated
by any of the features from Fig. 4a. To ensure soundness,
the learner would be forced to conservatively assign the label
UKD(x), which sacriÔ¨Åces the accuracy.
GPS thus includes a feature synthesis engine, triggered
whenever the learner fails to distinguish between two dif-
ferently labeled variables. In tandem with recursive feature
synthesis,GPS overcomes the limited expressiveness of DTL
by enriching syntax space to capture more desired patterns.
Observe that paths of a decision tree can be represented as
Datalog rules, e.g., the red path in Fig. 4b is equivalent to
UKD(x) XOR(x)^XOR(R)^RUD(L)^LC(x;L)^RC(x;R):
Viewing this in Datalog also allows us to conveniently describe
recursive features, and reduce feature synthesis to an instanceOP(x) OP(L) OP(R) TYPE (L) TYPE (R)f(x)
CE1ANDOR -1 -1 -1 -1 -1
CE 2 XOR -1 LEAF -1 -1 -1
CE 3 XOR -1 XOR SID -1 -1
CE 4 XOR -1 ANDOR RUD -1 -1
CE 5 XOR -1 ANDOR SID -1 -1
Fig. 5. Abstract counter-examples produced during the soundness veriÔ¨Åcation
of the candidate analyzer shown in Fig. 4c.
TYPE (L)
RUD(L) UKD(L)SID(L)
OP(x) RUD OP(R)
XOR(x) ANDOR (x)
f(x) SIDANDOR (R) XOR(R)
SID RUD
true false
UKD RUD
Fig. 6. Candidate analysis learned after one round of feedback from the
soundness veriÔ¨Åer. The leaves shown in green and red correspond to sound
and unsound analysis rules respectively.
of syntax-guided synthesis (SyGuS). Syntactically, the analysis
rules corresponding to new features are instances of a pre-
deÔ¨Åned set of meta-rules , and the target speciÔ¨Åcation is to
produce a Datalog program for a relation f(x)that has strictly
positive information gain for the variables under consideration
(see Section IV for details).
In our running example, the synthesizer produces the feature
f(x)shown in Fig. 3a, which intuitively indicates that some
random input ris used to compute both operands of x. With
this new feature, the learner can distinguish between b4andn1,
and produce the rule shown in Fig. 4c, which correctly classiÔ¨Åes
all variables of the training program. Observe that the rules
deÔ¨Åningf(x)in Fig. 3a involve a newly introduced predicate
g(x;r)and recursive structure that can classify variables based
on arbitrarily deep properties of the abstract syntax tree.
813C. Proving Soundness of Learned Analysis Rules
While the learned analysis rules are correct by construction
for the training examples, they may still be unsound when
applied to unseen programs. We observe this, for example, in
the leaves highlighted in red in Fig. 4c. Thus, GPS tries to
conÔ¨Årm their soundness against the domain-speciÔ¨Åc knowledge
baseKB. In the context of our running example‚ÄîconÔ¨Årming
soundness means proving that every variable xthat is assigned
typeRUD(x)(resp. SID(x)) by the learned analysis rule is
also certiÔ¨Åed RUD(x)(resp. SID(x)) byKB.
We formalize the soundness proof as a Datalog query
containment problem, and propose an algorithm based on
bounded unrolling and k-induction to check it.
When applied to the candidate analysis of Fig. 4c, the
check results in the Ô¨Åve counter-examples CE 1;:::;CE 5with
distribution type UKD(CEi)shown in Fig. 5. Each counter-
example indicates the unsoundness of one path from the root
of the decision tree to a classiÔ¨Åcation node. These are abstract
counter-examples in that they contain missing features and
consequently do not deÔ¨Åne concrete ASTs. Thus, each of
these abstract counter-examples is a set of feature valuations
=ff17!v1;f27!v2;:::;fk7!vkgthat the current
candidate analysis misclassiÔ¨Åes, and feeding them back to
the learner can prohibit subsequent candidate analyses from
classifying variables that satisfy .
With these new constraints from abstract counter-examples,
the learner learns the new candidate analysis shown in Fig. 6.
This new candidate analysis still has four unsound candidate
rules, which results in additional abstract counter-examples
when it is subjected to the soundness check. We repeat this
back-and-forth between the rule learner and the soundness
prover: after 11 iterations and after processing 27 counter-
examples in all, GPS learns the rules initially presented in
Fig. 2b, all of which have been certiÔ¨Åed to be sound.
D. Overall Architecture of the GPS System
We summarize the architecture of GPS in Fig. 1. The learner
repeatedly applies DTL and SyGuS to learn candidate analyses
that correctly classify training samples and are consistent
with newly-added abstract counter-examples. Next, the prover
checks the soundness of the learned analysis. Each subsequent
counter-example is fed back to the learner which restarts the
rule learning process on augmented dataset, until either all
synthesized rules are sound or a time bound is exhausted.
IV. L EARNING THE INFERENCE RULES
We formally describe the analysis rule learner in Algorithm 1.
The input consists of a set of labeled examples, E, and a set of
pre-deÔ¨Åned features, F. The outputTis a set of type-inference
rules consistent with training examples. Each training example
(x;TYPE (x))2E consists of an AST node xin a program
and its distribution type TYPE (x).
At the top level, the learner uses the standard decision
tree learning (DTL) algorithm [30] as the baseline. However,
if it Ô¨Ånds that the current set Fof classiÔ¨Åcation features
is insufÔ¨Åcient, it invokes a syntax-guided synthesis (SyGuS)Algorithm 1 DTL(E;F)‚Äî Decision Tree Learning.
Input: Examples,E=f(x1;TYPE (x1));:::; (xn;TYPE (xn))g
Input: Pre-deÔ¨Åned features, F=ff1;f2;:::;f kg
Output: ClassiÔ¨ÅerTwhich is consistent with provided examples
1:ifall examples (x;TYPE (x))2E have the same label TYPE (x) =t
then
2: returnT= LeafNode( t)
3:end if
4:if69f2F such thatH(Ejf)<H(E)then
5:F:=F[ FEATURE SYN(E)
6:end if
7:T= DecisionNode( f), wheref= arg minf2FH(Ejf)
8:forvaluationiof featurefdo
9:Ti=DTL(Ejf(x)=i;Fnffg)
10: Add edge from TtoTiwith labelf(x) =i
11:end for
12:returnT
algorithm to synthesize a new feature fwith strictly positive
information gain to augment F. This allows the learner to
combine the efÔ¨Åciency of techniques that learn decision trees
with the expressiveness of syntax guided synthesis; similar
ideas have been fruitfully used in other applications of program
synthesis, see for example [31].
While the top-level classiÔ¨Åer (e.g., Fig. 2b, 4b, 4c and 6)
has a bounded number of decision points, the synthesized
features (e.g., Fig. 3a) may be recursive. Furthermore, the
newly synthesized features fare inducted as Ô¨Årst-class citizens
ofF, and can subsequently be used at any level of the decision
tree (see, for example Fig. 2b and 6). Next, we present the
DTL and SyGuS subroutines respectively.
A. The Decision Tree Learning Algorithm
Recall that our pre-deÔ¨Åned features (Fig. 4a) include proper-
ties of the AST node, such as OP(x), and properties referring
its left and right children, such as OP(L)^LC(x;L). The choice
requires some care: having very few features will cause the
learning algorithm to fail, while having too many features will
increase the risk of overÔ¨Åtting. Our synergistic combination of
DTL with SyGuS-based on-demand feature synthesis can be
seen as a compromise between these extremes.
DTL(E;F)is an entropy-guided greedy learner [30], where
the entropy and conditional entropy of a set (deÔ¨Åned below)
are used to measure the diversity of its labels:
H(E) = P
t2TYPEPr(TYPE (x) =t) log(Pr( TYPE (x) =t))
H(Ejf) =P
i2Range( f)H(Ejf(x) =i)
Algorithm 1 thus divides the set of training examples Eusing
the feature f=fthat minimizes the conditional entropy
H(Ejf)(Lines 7‚Äì12), and recursively invokes the learning
algorithm on each subset, DTL (Ejf(x)=i;Fnffg).
Observe that H(E) = 0 ifPr(TYPE (x) =t) = 100% ,
meaning purity or all examples x2E share the same type
TYPE (x) =t. The difference between H(E)andH(Ejf)is
also referred to as the information gain . If the learner cannot
Ô¨Ånd a feature with strictly positive information gain (Line 4),
it will invoke the feature synthesis algorithm on Line 5.
814Algorithm 2 FEATURE SYN(E).
Input: Examples,E=f(x1;TYPE (x1));:::; (xn;TYPE (xn))g
Output: Featurefwith positive information gain, or ?to indicate failure
1: LetSbe the meta-rules deÔ¨Åned in Figure 7, i.e. the hypothesis space
2:for each relation schema rdeÔ¨Åned inSdo
3: for each subsetSof meta-rules corresponding to the schema do
4: for each choicepin,qin, and nested relational predicates do
5: Letfbe the corresponding instantiation of the meta-rules in S
6: ifh(Ejf)h(E)then
7: returnf
8: end if
9: end for
10: end for
11:end for
12:return?
Rf=8
>>><
>>>:f(x) pin(x);
f(x) qin(x;y);
f(x) pin(x;y)^qin(x;y);
f(x) qin(x;y)^f(y);
f(x) qin(x;y)^pin(x)^f(y)9
>>>=
>>>;
Rg=8
><
>:g(x;y) qin(x;y);
g(x;y) pin(x)^qin(x;y);
g(x;y) qin(x;z)^g(z;y);
g(x;y) qin(x;z)^pin(x)^g(z;y)9
>=
>;
Rh=8
<
:h(x) f(x)^pin(x)^qin(x;y);
h(x) g(x;y)^pin(x)^qin(x;y);
h(x) f(x)^g(x;y)^pin(x)^qin(x;y)9
=
;
pin(x)::=AND(x)jOR(x)jNOT(x)jXOR(x)jMUL(x)jLEAF (x)
jINRAND (x)jINKEY (x)jINPUB (x)
jpin^pinjpin_pinj:pin
qin(x;y)::=LC(x;y)jRC(x;y)jx=y
jqin(x;y)^qin(x;y)jqin(x;y)_qin(x;y)
j :qin(x;y)
Fig. 7. Syntax of the DSL for synthesizing new features.
B. The On-Demand Feature Synthesis Algorithm
We represent newly synthesized features as Datalog pro-
grams. Datalog is an increasingly popular medium to express
static analyses [32]‚Äì[35], and its recursive nature enables the
newly learned features to represent arbitrarily deep properties
of AST nodes. A Datalog rule is a constraint of the form
h(x) b1(y1)^b2(y2)^^bn(yn); (1)
whereh,b1. . .bnare relations with pre-speciÔ¨Åed arities and
schemas, and where x,y1. . .ynare vectors of typed variables.
Each rule can be interpreted as a logical implication: if b1. . .bn
are true, then so is h. The semantics of a Datalog program
is deÔ¨Åned as the least Ô¨Åxed-point of rule application [36]: the
solver starts with empty output relations, and repeatedly derives
new output tuples until no new tuples can be derived.
Program synthesis commonly restricts the space of target
concepts and biases the search to speed up computation and
improve generalization. One form of bias has been to constrain
the syntax: this has been formalized as the SyGuS problem [37]
and as meta-rules in inductive logic programming [38], [39].
A meta-rule is construct of this form
Xh(x) X1(y1)^X2(y2)^^Xn(yn) (2)
Here,Xh,X1,X2, . . . ,Xnarerelation variables whose
instantiation yields a concrete rule. Fig. 7 shows the meta-rulesused in our work. For example, instantiating the meta-rule
f(x) qin(x;y)^pin(x)^f(y)withqin(x;y) =RC(x;y)
andpin(x) =XOR(x)yieldsf(x) RC(x;y)^XOR(x)^f(y).
There are three variations of the Ô¨Ånal target relation schema,
f(x),g(x;y)andh(x), wherexandydenote AST nodes.
We formalize the synthesis problem as that of choosing a
relationR2ff(x);g(x;y);h(x)gand Ô¨Ånding a subset PDof
its instantiated meta-rules from Fig. 7 such that the resulting
Datalog program PDhas strictly positive information gain on
the provided training examples E.
Algorithm 2 shows the procedure, which repeatedly instanti-
ates the meta-rules from Fig. 7 and computes their information
gain. It successfully terminates when it discovers a feature that
can improve classiÔ¨Åcation. Otherwise, it returns failure (upon
timeout) and invokes DTL(E;F)to conservatively classify the
decision tree node as being of type UKD.
Example IV .1. GivenE=f(b4;RUD);(n1;UKD)gshown in
Fig. 2a, the synthesizer may alternatively learn the rules in
Equations 3, 4 and 5.
f(x) INRAND (x); (3)
f(y) LC(y;x)^f(x);
f(y) RC(y;x)^f(x);
RUD(x) XOR(x)^LC(x;L)^RC(x;R)^RUD(L)^f(R):
g(x;x) INRAND (x); (4)
g(y;z) LC(y;x)^g(x;z);
g(y;z) RC(y;x)^g(x;z);
h(x) LC(x;L)^RC(x;R)^g(L;xL)^g(R;xR)^xL=xR;
RUD(x) XOR(x)^RUD(L)^RUD(R)^LC(x;L)^RC(x;R)^:h(x):
g(x;x) INKEY (x); (5)
g(y;z) LC(y;x)^g(x;z);
g(y;z) RC(y;x)^g(x;z):
h(x) LC(x;L)^RC(x;R)^g(L;xL)^g(R;xR)^xL=xR;
RUD(x) XOR(x)^RUD(L)^RUD(R)^:h(x):
Since the information gain of Rule 3 applying to fb4;n1gis
zero, it gets discarded (Line 6 in Algorithm 2). In contrast, the
information gains of Rules 4 and 5 are both positive. Rule 4
intuitively requires that both the left and right operands of x
are of type RUD, and that they do not share any random inputs
in computing:h(x). Rule 5 requires that the same secret key
be used in the computation of both operands. While Rule 4 is
sound when applied to arbitrary programs, Rule 5 is unsound.
In the next section, we will present an algorithm that can check
the soundness of these learned rules.
V. P ROVING THE INFERENCE RULES
We wish to prove that a learned rule, denoted , never
reaches unsound conclusions when applied to any program, by
showing that it can be deduced from a known-to-be-correct
knowledge base ( KB). More speciÔ¨Åcally, we wish to conÔ¨Årm
that every AST node xmarked as RUD (orSID) bycan
be certiÔ¨Åed to be RUD (orSID) byKB. When both and
KB are expressed in Datalog, the problem reduces to one of
determining query containment, e.g., for every valuation of
the input relations, RUDRUDKB(orSIDSIDKB).
815b_:btrue (B1) b^:bfalse (B2)::bb(B3):a_:b:(a^b)(B4)
:a^:b:(a_b)(B5) b_falseb(B6) b_truetrue (B7) b^trueb(B8)
b^bb(B9) b^falsefalse (Ba) b_bb(Bb) a^(a_b)a(Bc)
a_(a^b)a(Bd) ab(a^:b)_(:a^b)(Be) (a_b)_ca_c_b(Bf)
(a^b)^ca^c^b(B10) a_(b_c)a_b_c(B11) a^(b^c)a^b^c(B12)
Fig. 8. Proof rules for propositional logic, to simplify the logic formula and deduce Boolean constants ( true andfalse ).
_
_g1(L;k1)
k1LC
r1RC
:g2(R;k2)
k2LCk1=k2SID(x)
Fig. 9. Example AST from whichis learned.
We will now describe a semi-decision procedure to verify the
soundness of the learned rules , which forms the second
phase of the synthesis loop in GPS .
A. Representation of the Learned Rule ( )
Letbe a set of Datalog rules, each of which has a head
relationand a body of the following form:
(x) 1(x1)^2(x2)^^n(xn) (6)
It meansholds only when all of 1;:::;nhold. Here,
may be a distribution type, e.g., SID(x), or a recursive feature
g(x;y), e.g., representing that xdepends on y.
B. Representation of the Knowledge Base ( KB)
OurKB consists of two sets of proof rules, one for
propositional logic and the other for distribution types.
Proof Rules for Propositional Logic. Fig. 8 shows the proof
rules that represent axioms of propositional logic [40]; they can
be used to reduce any valid (resp. invalid) Boolean formula to
constanttrue (resp.false ). Thus, they are useful in showing
results such as true_Pandfalse^Qare secret-independent
(SID), for arbitrary logical sentences PandQ.
Consider the example rule below, where g1andg2are
synthesized features shown as dashed boxes in Fig. 9:
SID(x) OR(x)^LC(x,L)^RC(x,R)^OR(L)^NOT(R)^
g1(L,k1)^g2(R,k2)^EQ(k1;k2)
g1(L,k1) INKEY (k1)^INRAND (r1)^LC(L,k1)^RC(L,r1)
g2(R,k2) INKEY (k2)^LC(R,k2)
Sincek1=k2, we transform into an equivalent logic formula:
SID(x) EQ(x;(k1_r1)_(:k1))
RulesB1,B7andBfin Fig. 8 show that (k1_r1)_(:k1)
is alwaystrue . Thus,xis alwaystrue . Sincexis a constant,
we have SID(x), meaningxis secret-independent.
Such SID rules, learned by our method automatically, and
yet overlooked by state-of-the-art, hand-crafted analyzers [1],
[2], can signiÔ¨Åcantly improve the accuracy of side-channel
analysis on many programs.Proof Rules for Distribution Types. Fig. 10 shows the proof
rules that represent properties of the distribution types. They
were collected from published papers [2], [16], [24] that focus
on verifying masking countermeasures, which also provided
the soundness proofs of these rules. For brevity, we omit the
detailed explanation. Instead, we use Rule D2:1as an example
to illustrate the rationale behind these proof rules.
In RuleD2:1, thedom(x,S) relation means that variable
xis masked by some input from the set Sof random inputs.
For example, in y=x1x2, wherex1=kr1r2and
x2=br2, we say that x2is masked by r2, andx1is masked
by bothr1andr2. However, since r2r2=false ,yis masked
only byr1. Thus,dom (y,fr1g) holds, but dom(y;fr2g)does
not hold. In this sense, Rule D2:4deÔ¨Ånes a masking set . Fory,
it isSy= (fr1,r2g[fr2g)n(fr1,r2g\fr2g) =fr1g, which
containsr1only. The masking set deÔ¨Åned by D2:4is useful in
that, as long as the set is not empty, the corresponding variable
is guaranteed to be of the RUD type.
C. Proving the Soundness of UsingKB
To prove that for every AST node xmarked as RUD(x)
(resp. SID(x)) by, it is also marked as RUDKB(x)(resp.
RUDKB(x)) byKB, we show that the following relation
Ind(x)is empty for any valuation of the input relations:
Ind(x) (x)^:KB(x); (7)
where the relation may be instantiated to either RUD orSID.
In theory, this amounts to proving query containment , which
is undecidable for Datalog in general [41], [42], but there is a
decidable Datalog fragment [41], [43], [44], and our meta-rules
in Fig. 7 produce rules in this fragment.
First, we observe that every tuple t=(x)produced by a
Datalog program is associated with one or more derivation
trees . The heights of these derivation trees correspond to the
depth of rule inlining at which the program discovers t. In
particular, for each inlining depth k2N, each ruleh(xh) 
1(x1)^2(x2)^^n(xn)is transformed into the rule:
(k+1)(xh) (k)
1(x1)^(k)
2(x2)^^(k)
n(xn);(8)
Our insight is to prove that at each unrolling depth k, we have
(k)
(k)
KB. Thus, we deÔ¨Åne the relation Ind(k)as follows:
Ind(k)(x) (k)
(x)^:(k)
KB(x); (9)
and prove the emptiness of Ind(x)byk-induction [45]‚Äì[47].
Proposition V .1. IfInd(k)(x)is an empty relation for each
depthk2N, thenInd(x)is an empty relation.
816 `x:INRAND
supp(x;fxg)(D1:1) `x:INKEY
supp (x;fxg)(D1:2) `x:INPUB
supp (x;fxg)(D1:3) `x:INRAND
dom(x;fxg)(D2:1) `x:INKEY
dom(x;;)(D2:2)
 `x;y:v; `S:Set v;RC(y;x1)^LC(y;x2)^supp(x1;S1)^supp(x2;S2)
supp(y;S1[S2)(D1:4) `x:INPUB
dom (x;;)(D2:3)
 `x;y:v; `S:Set v;RC(y;x1)^LC(y;x2)^XOR(y)^dom(x1;S1)^dom(x2;S2)
dom(x;(S1[S2)=(S1\S2))(D2:4)
 `x:v; `S:Set v;dom (x;Sx)^Sx6=;
 `x:RUD(D3) `x:INKEY; `S:SetINKEY
 `x::S:SetINKEY(D4)
 `x:v; `Sk:SetINKEY;
 `Sd:SetRUD; `Ss:Set v;
dom(x;Sd)^Sd=;^supp(x;Ss)^Ss\Sk=;
 `x:SID(D5) `x1:SID; `x2:RUD; `S1;S2:Set v
LC(y;x1)^RC(y;x2)^AND(y)
^supp(x1;S1)^supp(x2;S2)^S1\S2=;
 `y:SID(D6)
 `x1:SID; `x2:RUD; `S1;S2:Set v
LC(y;x1)^RC(y;x2)^OR(y)^
supp(x1;S1)^supp(x2;S2)^S1\S2=;
 `y:SID(D7) `x1:SID; `x2:SID; `S1;S2:Set v
LC(y;x1)^RC(y;x2)^
supp(x1;S1)^supp(x2;S2)^S1\S2=;
 `y:SID(D8)
 `x1:SID; `x2:SID; `S1:SetRUD; `S2:Set v;
AND(y)^LC(y;x1)^RC(y;x2)^dom(x1;S1)^supp(x2;S2)^S1\S26=;
 `y:SID(D9)
 `x1:SID; `x2:SID; `S1:SetRUD;
 `S2:Set v;OR(y)^LC(y;x1)^RC(y;x2)^
dom(x1;S1)^supp(x2;S2)^S1=S26=;
 `y:SID(Da) `x1:RUD; `x2:RUD; `S1:SetRUD;
 `S2:Set v;AND (y)^LC(y;x1)^RC(y;x2)^
dom (x1;S1)^supp (x2;S2)^S2=S16=;
 `y:SID(Db)
 `x1:RUD; `x2:RUD; `S1:SetRUD; `S2:Set v;
OR(y)^LC(y;x1)^RC(y;x2)^dom (x1;S1)^supp (x2;S2)^S2=S16=;
 `y:SID(Dc)
 `x:RUD
 `x:NOUKD(Dd) `x:SID
 `x:NOUKD(De) `x:v;NOT (y)^LC(y;x)
 `y:v(Df) `x:bool; x=true
 `x:SID(D10)
 `x:bool; x=false
 `x:SID(D11) `x:v; `Sk:SetINKEY; `S:Set v; supp (x;Ss)^Ss\Sk=;
 `x:NOUKD(D12)
 `x1:RUD; `x2:RUD; `S1;S2:SetRUD;
LC(y;x1)^RC(y;x2)^MUL(y)^
(y)^dom (x1;S1)^dom (x2;S2)^S2=S16=;
 `y:SID(D13) `x1:RUD; `x2:SID; `S1:SetRUD
 `S2:Set v;LC(y;x1)^RC(y;x2)MUL (y)^
dom (x1;S1)^supp (x2;S2)^S1=S26=;
 `y:SID(D14)
 `x1:SID; `x2:RUD; `S1:SetRUD; S2:Set v;
LC(y;x1)^RC(y;x2)^MUL (y)^dom (x1;S1)^supp (x2;S2)^S2=S16=;
 `y:SID(D15)
Fig. 10. Proof rules for distribution types, gathered from prior works [2], [16], [24]. Here, vdenotes the type of variable x,and is of the following types: UKD,
SID andRUD.NOUKD denotes the secure type (either RUD orSID). All the predeÔ¨Åned relations in KB are the same as in .
Observe that unrolling the rules of a Datalog program to
any speciÔ¨Åc depth yields a formula which can be interpreted
within propositional logic. For example, unrolling f(x)from
Equation 3 at depths 1and2gives us
f(1)(x) =INRAND (x);and
f(2)(y) = (LC(y;x)^f1(x))_(RC(y;x)^f1(x)):
For any speciÔ¨Åc value of k, we can therefore use an SMT
solver to verify the emptiness of Ind(k).
For the induction step, in particular, we ask the SMT solver
to check if Ind(k)can be non-empty while the ipreceding
relationsInd(k 1),:::,Ind(k i)are assumed to be empty.
Here,(k)
is expressed recursively using (k 1)
 ,:::,(k i)

and induction succeeds if there exists such a value for i2N.LetV(k)be free variables introduced by unrolling the rules
at depthk. We assert the non-emptiness of Ind(k)below:
(k)=_
x2V(k)Ind(k)(x): (10)
Thus, we formalize the induction step of the proof by con-
structing the following formula:
	(k)=:(k i)^^: (k 1)^(k)(11)
Proposition V .2. If for some i2N, the relations Ind(1), . . . ,
Ind(i)are all empty (the base case), and the formula 	(k)as
deÔ¨Åned above is unsatisÔ¨Åable (the induction step), then Ind(k)
is empty for all k2N.
Starting from i= 1, we use the SMT solver to check
Proposition V .2 for increasingly larger iuntil a timeout is
817reached. If the SMT solver is ever successful in proving the
proposition, it follows that the learned rule is sound.
D. Generating Abstract Counter-Examples
When the proof fails, however, we need to prevent the
same rule from being learned again to guarantee progress. Let
=ff1=v1;f2=v2;:::;fk=vkgbe the feature valuation
in the failing rule R. We then construct the counter-example,
CE=ff7!vj(f;v)2g[ff7! 1jf2Fng
with label UKD(CE). Recall thatFis the set of all features
currently under consideration. Therefore, the feedback CE
provided to DTL(E;F)is an abstract counter-example, with
all missing features f2Fnset to the unknown value  1.
Consider the subsequent iteration of the decision tree learner,
DTL(E[fCEg;F). Observe that whenever it is in a decision
context which is also a preÔ¨Åx preof the counter-example CE,
the information gain of each feature f2is strictly less than
that encountered in the previous invocation. Therefore, at some
level of the decision tree, it will either choose a different
feature, or invoke the feature synthesis algorithm to grow F.
By formalizing this argument, we say that:
Proposition V .3. Given a counter-example CEto a learned
ruleR, the subsequent invocation of the learner DTL(E[
fCEg;F)is guaranteed to no longer produce R.
Before ending this section, we stress that the proof rules
inKB should not be confused with analysis rules used in
the learned analyzer, since they are way more computationally
expensive. Consider Rule D1:4, whose Datalog encoding size
forsupp(x;S)would bejVj2jINj. For the benchmark named
B19 in Table I, it owns 1250 input variables and thereby
causing the exponential explosion with 21250. The learned rule
, in contrast, is much cheaper since it does not rely on these
expensive set (union and intersection) operations.
VI. E XPERIMENTS
Our experiments were designed to answer the following
research questions (RQs):
RQ1: How effective is our learned analyzer in terms of
the analysis speed and accuracy?
RQ2: How effective is our GPS method for learning
inference rules from training data?
RQ3: How effective is our GPS method for proving the
learned inference rules?
We implemented GPS in LLVM 3.6. GPS relies on
LLVM to parse the C programs and construct the internal
representation (IR). Then, it learns a static analyzer in two steps.
The Ô¨Årst step, which is SyGuS-guided decision tree learning,
is implemented in 4,603 lines of C++ code. The second step,
which proves the learned inference rules, is implemented using
the Z3 [48] SMT solver. Furthermore, the learned analyzer
(for detecting power side channels in cryptographic software)
is implemented in LLVM as an optimization ( opt) pass. We
ran all experiments on a computer with 2.9 GHz Intel Core i5
CPU and 8 GB RAM.TABLE I
STATISTICS OF THE BENCHMARK PROGRAMS IN Dtest.
Name LoCIpubIprivIrand Name LoCIpubIprivIrand
B1 11 0 2 2 B2 12 0 2 2
B3 12 0 1 2 B4 25 1 1 3
B5 25 1 1 3 B6 32 1 1 3
B7 81 1 1 7 B8 84 1 1 7
B9 104 1 1 7 B10 964 1 16 32
B11 1,130 1 16 32 B12 1,256 0 25 75
B13 2,506 0 25 125 B14 3,764 0 25 175
B15 8,810 0 25 349 B16 13,810 0 25 575
B17 18,858 0 25 775 B18 23,912 0 25 975
B19 30,228 0 25 1,225 B20 34,359 16 16 1,232
B21 79 0 16 16 B22 67 0 8 16
B23 21 0 2 2 B24 23 0 2 2
B25 27 0 1 2 B26 32 0 2 2
B27 40 0 2 3 B28 59 0 3 4
B29 60 0 3 4 B30 66 0 3 4
B31 66 0 3 4 B32 426k 288 288 3205
B33 426k 288 288 3205 B34 426k 288 288 3205
B35 429k 288 288 3205 B36 426k 288 288 3205
B37 442k 288 288 3205
A. Benchmarks
Our benchmarks are 568 programs with 2,691K lines of
C code in total. They implement well-known cryptographic
algorithms such as AES and SHA-3. Some of these programs
are hardened by countermeasures, such as reordered MAC-
Keccak computation [23], masked AES [16], [17], masked
S-box calculation [49] and masked multiplication [50], to
eliminate power side-channel leaks.
We partition the benchmarks into two sets: Dtrain forGPS ,
andDtestfor the learned analyzer. The training set Dtrain
consists of 531 small programs gathered from various public
sources, including byte-masked AES [51], random reduction
of S-box [52], common shares [53], and leak examples [24].
Each benchmark is a pair, consisting of a program AST and its
distribution type, i.e, the ground truth annotated by developers.
The testing set Dtestconsists of 37 large programs, whose
statistics (the number of lines of code and inputs labeled public,
private, and random) are shown in Table I. Since these programs
are large, it is no longer practical to manually annotate the
ground truth; instead, we relies on the results of published
tools: a (manually-crafted) static analyzer [1] for B1-B20 and
a formal veriÔ¨Åcation tool [2] for B21-B37.
B. Performance and Accuracy of the Learned Analyzer
To demonstrate the advantage of our learned analyzer (answer
RQ1), we compared our learned analyzer with the two existing
tools [1], [2] on the programs in Dtest. Only our analyzer can
handle all of the 37 programs. Therefore, we compared the
results of our analyzer with the tool from [1] on B1-B20, and
with the tool from [2] on B21-B37. The results are shown in
Table II and Table III, respectively.
In both tables, Columns 1-2 show the benchmark name and
the number of AST nodes. Columns 3-6 show the existing tool‚Äôs
analysis time and result, including a breakdown in three types.
Similarly, Columns 7-10 show our learned analyzer‚Äôs time and
result. Note that in [1], the UKD/SID/RUD numbers were the
number of variables of the LLVM IR, and thus larger than the
number of variables in the original programs. To be consistent,
we compared with their results in the same manner in Table II.
The results in Table II and Table III show that our learned an-
alyzer is much faster, especially on larger programs such as B20
818TABLE II
COMPARING THE LEARNED ANALYZER WITH THE TOOL FROM [1].
Name #ASTManually Designed Analyzer [1] Our Learned Analyzer
Time (s) UKD SID RUD Time (s) UKD SID RUD
B1 7 0.061 4 0 22 0.001 4 0 22
B2 6 0.105 7 0 20 0.001 6 1 20
B3 8 0.099 1 3 31 0.001 1 3 31
B4 11 0.208 6 12 31 0.001 17 12 20
B5 11 0.216 1 10 29 0.001 11 10 19
B6 14 0.276 1 15 48 0.001 8 15 41
B7 39 0.213 2 25 151 0.002 2 25 151
B8 39 0.147 4 42 249 0.002 4 42 249
B9 47 0.266 2 61 153 0.001 2 61 153
B10 522 0.550 31 12 2334 0.008 31 12 2334
B11 522 0.447 31 0 2334 0.029 31 0 2334
B12 426 0.619 52 300 2062 0.001 52 300 2062
B13 827 1.102 49 600 4030 0.006 49 600 4030
B14 1,228 1.998 49 900 5995 0.065 49 900 5995
B15 2,832 16.999 49 2,100 13861 0.107 49 2,100 13861
B16 4,436 24.801 49 3,300 21,723 2.663 49 3,300 21,723
B17 6,040 59.120 49 4,500 29,587 1.956 49 4,500 29,587
B18 7,644 121.000 47 5,700 37,449 3.258 47 5,700 37,449
B19 9,649 202.000 49 7200 47,280 5.381 49 7200 47,280
B20 13,826 972.000 127 26,330 38,070 3.650 127 26,330 38,070
(3.6 seconds versus 16 minutes). The reason why our analyzer
is faster is because the manually-crafted analyses [1], [2] rely
on evaluating set-relations (e.g. difference and intersection of
sets of random variables), whereas our DSL syntax is designed
without set operations to infer the same types, thus leading to
faster analyses. Although in general the set operation-based
algorithm is more accurate, it has excessive computational
overhead. Moreover, it does not always improve precision in
practice. Furthermore, the method in [2] uses an SMT solver-
based model counting technique to infer leak-free variables,
which is signiÔ¨Åcantly more expensive than type inference.
As shown in Table II and Table III, by learning inference
rules from data, we can achieve almost the same accuracy
as manually-crafted analysis [1], [2] while avoiding the huge
overhead. Given the same deÔ¨Ånitions of distribution types ( UKD,
SID andRUD), both our learned rules and manually-crafted
analysis rules [1], [2] can infer the non-leaky patterns, thus
recognizing the variable types correctly under most benchmarks
in Table II and Table III, except for B4-B6 and B30, where
set operations are required to prove the leak-freedom of some
variables. Recall that losing accuracy here indicates that our
learned rules infer the types more conservatively, without losing
soundness. Nevertheless, our analyzer also increased accuracy
in some other cases (e.g., B2), due to its deeper constant
propagation (which led to the proof of more SID variables)
while the existing tool [1] failed to do so, and conservatively
marked them as UKD variables.
C. Effectiveness of Rule Induction and Soundness VeriÔ¨Åcation
To answer RQ2 and RQ3, we collected statistics while
applyingGPS to the 531 small programs in Dtest, as shown in
Table IV. In total, GPS took 30 iterations to complete the entire
learning process. Column 1 shows the iteration number and
Column 2 shows the time taken by the learner and the prover
together. Columns 3-6 show the number of inference rules
learned during each iteration, together with their types ( UKD,
SID, and RUD). Similarly, Columns 7-10 show the number of
veriÔ¨Åed inference rules and their types.
The next two columns show the following statistics: (1) the
size of the learned decision tree (# Tree learn ) in terms of theTABLE III
COMPARING THE LEARNED ANALYZER WITH SCI NFER [2].
Name #ASTThe SCInfer VeriÔ¨Åcation Tool [2] Our Learned Analyzer
Time (s) UKD SID RUD Time (s) UKD SID RUD
B21 32 0.390 16 0 16 0.005 16 0 16
B22 24 0.570 8 0 16 0.002 8 0 16
B23 6 0.010 0 0 6 0.001 0 0 6
B24 6 0.060 0 0 6 0.001 0 0 6
B25 8 0.250 0 2 6 0.001 0 2 6
B26 9 0.160 2 3 4 0.002 2 3 4
B27 11 0.260 1 5 5 0.001 1 5 5
B28 18 0.290 3 4 11 0.003 3 4 11
B29 18 0.230 2 4 11 0.002 2 4 12
B30 28 0.340 2 6 20 0.001 8 0 20
B31 28 0.500 2 7 19 0.001 2 7 19
B32 197k 3.800 0 6.4k 190.4k 3.180 0 6.4k 190.4k
B33 197k 2,828.000 4.8k 6.4k 185.6k 3.260 4.8k 6.4k 185.6k
B34 197k 2,828.000 3.2k 6.4k 187.2k 3.170 3.2k 6.4k 187.2k
B35 198k 2,828.000 1.6k 8k 188.8k 3.140 3.2k 8k 187.2k
B36 197k 2,828.000 4.8k 6.4k 185.6k 3.150 4.8k 6.4k 185.6k
B37 205k 2,828.000 17.6k 1.6k 185.6k 3.820 17.6k 1.6k 185.6k
number of decision nodes; (2) the number of counter-examples
(CEX) added by the prover (# AST CEX ), which are added
to the 531 original training programs before the next iteration
starts. The last column shows the number of features generated
by SyGuS; these features are also added to the original feature
set and then used by the learner during the next iteration.
Results in Table IV demonstrate the efÔ¨Åciency of both
the learner and the prover. Within the learner , the number
of rules produced in each iteration remains modest (8 on
average), indicating it has successfully avoided overÔ¨Åtting. This
is because the SyGuS solver is biased toward producing small
features which, by Occam‚Äôs razor , are likely to generalize
well. Furthermore, any learned analysis rules have to pass the
soundness check, and this provides additional assurance against
overÔ¨Åtting to the training data. The prover either quickly veriÔ¨Åes
a rule, or quickly drops it after adding a counter-example to
prevent it from being learned again. In early iterations, about
half of all learned rules can be proved, but as more counter-
examples are added, the quality of the learned rules improves,
and thus the percentage of proved rules also increases.
D. Threats to Validity
Our experimental evaluation focused on cryptographic soft-
ware, which is structurally simple and, unlike general-purpose
software, does not exercise complicated language constructs.
It is an interesting direction of future work to extend our
techniques to these more general classes of software code.
A notable limitation in our work is the assumption of the
knowledge base (KB). While KB is readily available for our
application (side-channel analysis), for other applications, it
might be non-trivial to construct. Furthermore, an incorrect KB
might compromise the soundness of the learned rules, although
in this work, we have carefully mitigated this threat by curating
the proof rules from previous papers [2], [16], [24] that have
themselves formally veriÔ¨Åed the validity of these proof rules.
VII. R ELATED WORK
Generating Analyzers from Examples. While there are prior
works on learning static analyzers [5], [54], they do not
guarantee soundness. For example, the analyzer learned by
Bielik et al. [5] is sound with respect to programs in the
819TABLE IV
DECISION TREE LEARNING WITH FEATURE SYNTHESIS (DIFFERENT ITERATIONS WITH #AST = 531).
Iteration Time (s)#Rules Learned #Rules VeriÔ¨Åed#Treelearn #ASTCEX #Feature synTotal UKD SID RUD Total UKD SID RUD
1 1.316 9 2 2 5 5 2 1 2 23 4 5
2 0.775 8 2 2 4 4 2 1 1 17 9 7
3 1.115 8 2 2 4 5 2 2 1 24 13 9
4 0.511 8 2 2 4 5 2 1 2 18 18 10
5 0.513 8 2 2 4 7 2 2 3 27 21 11
6 0.537 8 2 2 4 6 2 2 2 24 25 12
7 0.510 8 2 2 4 6 2 2 2 26 29 13
8 0.512 8 2 2 4 6 2 2 2 28 33 14
9 0.511 8 2 2 4 6 2 2 2 30 37 15
10 0.524 8 2 2 4 5 2 2 1 32 41 16
11 0.546 8 2 2 4 4 2 2 0 34 45 17
12 0.556 8 2 2 4 4 2 2 0 36 49 18
13 0.550 8 2 2 4 5 2 2 1 38 53 19
14 0.540 8 2 2 4 6 2 2 2 40 57 20
15 0.542 8 2 2 4 4 2 2 0 42 61 21
16 0.552 8 2 2 4 6 2 2 2 44 65 22
17 0.577 8 2 2 4 5 2 2 1 46 69 23
18 0.598 8 2 2 4 6 2 2 2 48 73 24
19 0.571 8 2 2 4 6 2 2 2 50 77 25
20 0.673 8 2 2 4 5 1 2 2 52 82 26
21 0.526 8 2 2 4 3 1 2 0 54 87 27
22 0.525 8 3 2 3 6 3 2 1 35 91 27
23 0.697 9 3 2 4 7 2 2 3 37 93 27
24 0.700 9 3 2 4 8 2 2 4 38 95 28
25 0.691 7 2 2 3 6 1 2 3 36 97 29
26 0.707 7 2 2 3 6 1 2 3 37 99 30
27 0.716 7 2 2 3 6 1 2 3 38 101 31
28 0.540 7 2 2 3 6 1 2 3 39 102 32
29 0.534 7 2 2 3 6 1 2 3 39 103 32
30 0.528 7 2 2 3 7 2 2 3 39 104 32
TOTAL 18.693 237 63 60 114 167 54 57 56 1071 1833 622
training set, not all programs written in the same programming
language (JavaScript). They also need to manually modify
the training programs to generate counter-examples, while our
method generates counter-examples automatically.
Formal SpeciÔ¨Åcations. There are also works on synthesizing
static analyzers from formal speciÔ¨Åcations, e.g., proof rules
or second-order logic formulas [29], [55], [56] as opposed to
training data. However, they restrict the logic used to write the
speciÔ¨Åcation, and as a result, may not be expressive enough to
synthesize practical analyzers. Users are also expected to write
correct speciÔ¨Åcations, which is a non-trivial task. In addition,
they cannot exploit the information provided by data.
Learning-based Techniques. There are several prior techniques
using machine learning to conduct static program analyses [57]‚Äì
[60]. Such techniques focus on Ô¨Ånding a suitable program-to-
feature embedding. However, they require the user to perform
feature engineering, which is known to be laborious. Some
of these techniques [58], [61]‚Äì[63] do not take advantage of
new features that may be learned from data; instead, they build
classiÔ¨Åers based solely on existing features. In contrast, our
method not only learn new analysis rules from data, but also
use SyGuS to synthesize new features automatically.
Optimizing an Analyzer. It is possible to optimize an existing
static analyzer [57], [64]‚Äì[68], which can be achieved by
adjusting the level of abstraction [64], [65], [69], learn heuristics
and parameters [66], make soundness-accuracy trade-offs [67],
or select sound transformers [68]. However, such techniques
fundamentally differ from our method because they assume
the analyzer is already given, and focus on optimizing its
performance, whereas we focus on synthesizing a new analyzer.
Syntax-Guided Synthesis. Since we automatically generate new
features, our method is related to the large and growing body
of work on SyGuS. While SyGuS has been used in variousapplications [70]‚Äì[80], none of them aims to synthesize a
provably sound static analyzer from data. While some of these
existing techniques can synthesize Datalog rules [39], [81],
[82], the focus has been on efÔ¨Åciency, e.g., pruning the search
space based on syntactic structures, instead of guaranteeing
the soundness of the analyzer.
Power Side-Channel Analysis. In this work, we use power side-
channel analysis as the application to evaluate our method. In
this sense, it is related to the body of work on side-channel leak
detection [2]‚Äì[4], [83]‚Äì[85] as well as mitigation [1], [24], [28],
[86]‚Äì[88]. While static analysis engines used in these existing
works are all hand-crafted by domain experts, our method aims
to synthesize the static analysis from data automatically.
VIII. C ONCLUSIONS
We have presented a data-driven method for learning a
provably sound static analyzer to detect power side channels in
cryptographic software. It relies on SyGuS to generate features
and DTL to generate analysis rules based on the synthesized
features. It veriÔ¨Åes the soundness of these learned analysis rules
by solving a query containment checking problem using an
SMT solver. We have evaluated our method on C programs that
implement well-known cryptographic protocols and algorithms.
Our experimental results show that the learning algorithm
is efÔ¨Åcient and the learned analyzer can achieve the same
empirical accuracy as state-of-the-art analysis tools while being
several orders-of-magnitudes faster.
ACKNOWLEDGMENTS
This research was supported in part by the U.S. National
Science Foundation (NSF) under grant CNS-1617203 and Of-
Ô¨Åce of Naval Research (ONR) under grant N00014-17-1-2896.
We thank the anonymous reviewers for their helpful feedback.
820REFERENCES
[1]J. Wang, C. Sung, and C. Wang, ‚ÄúMitigating power side channels during
compilation,‚Äù in ACM Joint Meeting on European Software Engineering
Conference and Symposium on the Foundations of Software Engineering ,
2019, pp. 590‚Äì601.
[2]J. Zhang, P. Gao, F. Song, and C. Wang, ‚ÄúSC Infer: reÔ¨Ånement-based
veriÔ¨Åcation of software countermeasures against side-channel attacks,‚Äù
inInternational Conference on Computer Aided VeriÔ¨Åcation , 2018, pp.
157‚Äì177.
[3]J. Chen, Y . Feng, and I. Dillig, ‚ÄúPrecise detection of side-channel
vulnerabilities using quantitative cartesian hoare logic,‚Äù in ACM SIGSAC
Conference on Computer and Communications Security , 2017, pp. 875‚Äì
890.
[4]T. Brennan, S. Saha, T. Bultan, and C. S. P ÀòasÀòareanu, ‚ÄúSymbolic path
cost analysis for side-channel detection,‚Äù in ACM SIGSOFT International
Symposium on Software Testing and Analysis , 2018, pp. 27‚Äì37.
[5]P. Bielik, V . Raychev, and M. Vechev, ‚ÄúLearning a static analyzer from
data,‚Äù in International Conference on Computer Aided VeriÔ¨Åcation , 2017,
pp. 233‚Äì253.
[6]C. Mendis, C. Yang, Y . Pu, S. Amarasinghe, and M. Carbin, ‚ÄúCompiler
auto-vectorization with imitation learning,‚Äù in Advances in Neural
Information Processing Systems , 2019, pp. 14 598‚Äì14 609.
[7]S. Gulwani, W. R. Harris, and R. Singh, ‚ÄúSpreadsheet data manipulation
using examples,‚Äù Communications of the ACM , vol. 55, no. 8, pp. 97‚Äì105,
2012.
[8]A. Leung, J. Sarracino, and S. Lerner, ‚ÄúInteractive parser synthesis by
example,‚Äù ACM SIGPLAN Notices , vol. 50, no. 6, pp. 565‚Äì574, 2015.
[9]R. Singh and S. Gulwani, ‚ÄúSynthesizing number transformations from
input-output examples,‚Äù in International Conference on Computer Aided
VeriÔ¨Åcation , 2012, pp. 634‚Äì651.
[10] C. Smith and A. Albarghouthi, ‚ÄúMapreduce program synthesis,‚Äù Acm
Sigplan Notices , vol. 51, no. 6, pp. 326‚Äì340, 2016.
[11] A. Solar-Lezama, L. Tancau, R. Bodik, S. Seshia, and V . Saraswat,
‚ÄúCombinatorial sketching for Ô¨Ånite programs,‚Äù in International Conference
on Architectural Support for Programming Languages and Operating
Systems , 2006, pp. 404‚Äì415.
[12] S. An, R. Singh, S. Misailovic, and R. Samanta, ‚ÄúAugmented example-
based synthesis using relational perturbation properties,‚Äù Proceedings
of the ACM on Programming Languages , vol. 4, no. POPL, pp. 1‚Äì24,
2019.
[13] M. Mayer, G. Soares, M. Grechkin, V . Le, M. Marron, O. Polozov,
R. Singh, B. Zorn, and S. Gulwani, ‚ÄúUser interaction models for
disambiguation in programming by example,‚Äù in ACM Symposium on
User Interface Software & Technology , 2015, pp. 291‚Äì301.
[14] R. Singh and S. Gulwani, ‚ÄúPredicting a correct program in programming
by example,‚Äù in International Conference on Computer Aided VeriÔ¨Åcation ,
2015, pp. 398‚Äì414.
[15] J. Devlin, J. Uesato, S. Bhupatiraju, R. Singh, A.-r. Mohamed, and
P. Kohli, ‚ÄúRobustÔ¨Åll: Neural program learning under noisy i/o,‚Äù in
International Conference on Machine Learning , 2017, pp. 990‚Äì998.
[16] G. Barthe, S. Bela ¬®ƒ±d, F. Dupressoir, P.-A. Fouque, B. Gr ¬¥egoire, and
P.-Y . Strub, ‚ÄúVeriÔ¨Åed proofs of higher-order masking,‚Äù in International
Conference on the Theory and Applications of Cryptographic Techniques ,
2015, pp. 457‚Äì485.
[17] J. Bl ¬®omer, J. Guajardo, and V . Krummel, ‚ÄúProvably secure masking
of AES,‚Äù in International workshop on selected areas in cryptography ,
2004, pp. 69‚Äì83.
[18] A. G. Bayrak, F. Regazzoni, D. Novo, and P. Ienne, ‚ÄúSleuth: Automated
veriÔ¨Åcation of software power analysis countermeasures,‚Äù in International
Workshop on Cryptographic Hardware and Embedded Systems , 2013,
pp. 293‚Äì310.
[19] Y . Ishai, A. Sahai, and D. Wagner, ‚ÄúPrivate circuits: Securing hardware
against probing attacks,‚Äù in Annual International Cryptology Conference ,
2003, pp. 463‚Äì481.
[20] J. Balasch, B. Gierlichs, V . Grosso, O. Reparaz, and F.-X. Standaert,
‚ÄúOn the cost of lazy engineering for masked software implementations,‚Äù
inInternational Conference on Smart Card Research and Advanced
Applications , 2014, pp. 64‚Äì81.
[21] J.-S. Coron, C. Giraud, E. Prouff, S. Renner, M. Rivain, and P. K. Vadnala,
‚ÄúConversion of security proofs from one leakage model to another: A
new issue,‚Äù in International Workshop on Constructive Side-Channel
Analysis and Secure Design , 2012, pp. 69‚Äì81.[22] NIST, ‚ÄúNIST selects winner of the Secure Hash Algorithm (SHA-3)
competition,‚Äù https://www.nist.gov/news-events/news/2012/10/nist-selects-
winner-secure-hash-algorithm-sha-3-competition , 2012.
[23] G. Bertoni, J. Daemen, M. Peeters, G. Van Assche, and R. Van Keer, ‚ÄúKec-
cak implementation overview,‚Äù URL: http://keccak. noekeon. org/Keccak-
implementation-3.2. pdf , 2012.
[24] H. Eldib and C. Wang, ‚ÄúSynthesis of masking countermeasures against
side channel attacks,‚Äù in International Conference on Computer Aided
VeriÔ¨Åcation , 2014, pp. 114‚Äì130.
[25] G. Barthe, S. Bela ¬®ƒ±d, P.-A. Fouque, and B. Gr ¬¥egoire, ‚Äúmaskverif: a formal
tool for analyzing software and hardware masked implementations.‚Äù IACR
Cryptology ePrint Archive , vol. 2018, p. 562, 2018.
[26] C. Wang and P. Schaumont, ‚ÄúSecurity by compilation: an automated
approach to comprehensive side-channel resistance,‚Äù ACM SIGLOG News ,
vol. 4, no. 2, pp. 76‚Äì89, 2017.
[27] G. Barthe, S. Bela ¬®ƒ±d, F. Dupressoir, P.-A. Fouque, B. Gr ¬¥egoire, P.-
Y . Strub, and R. Zucchini, ‚ÄúStrong non-interference and type-directed
higher-order masking,‚Äù in ACM SIGSAC Conference on Computer and
Communications Security , 2016, pp. 116‚Äì129.
[28] S. Tizpaz-Niari, P. ÀáCern `y, and A. Trivedi, ‚ÄúQuantitative mitigation of
timing side channels,‚Äù in International Conference on Computer Aided
VeriÔ¨Åcation , 2019, pp. 140‚Äì160.
[29] C. David, D. Kroening, and M. Lewis, ‚ÄúUsing program synthesis for
program analysis,‚Äù in Logic for programming, artiÔ¨Åcial intelligence, and
reasoning , 2015, pp. 483‚Äì498.
[30] L. Rokach and O. Maimon, ‚ÄúTop-down induction of decision trees
classiÔ¨Åers-a survey,‚Äù Transactions on Systems, Man, and Cybernetics ,
vol. 35, no. 4, pp. 476‚Äì487, 2005.
[31] R. Alur, A. Radhakrishna, and A. Udupa, ‚ÄúScaling enumerative program
synthesis via divide and conquer,‚Äù in International Conference on Tools
and Algorithms for the Construction and Analysis of Systems , 2017, pp.
319‚Äì336.
[32] T. W. Reps, Demand Interprocedural Program Analysis Using Logic
Databases , 1995, pp. 163‚Äì196.
[33] J. Whaley and M. Lam, ‚ÄúCloning-based context-sensitive pointer alias
analysis using binary decision diagrams,‚Äù in ACM SIGPLAN Conference
on Programming Language Design and Implementation , 2004, pp. 131‚Äì
144.
[34] H. Jordan, B. Scholz, and P. Suboti ¬¥c, ‚ÄúSoufÔ¨Ç ¬¥e: On synthesis of program
analyzers,‚Äù in International Conference on Computer Aided VeriÔ¨Åcation ,
2016, pp. 422‚Äì430.
[35] M. Bravenboer and Y . Smaragdakis, ‚ÄúStrictly declarative speciÔ¨Åcation
of sophisticated points-to analyses,‚Äù in ACM SIGPLAN Conference on
Object Oriented Programming Systems Languages and Applications ,
2009, p. 243‚Äì262.
[36] S. Abiteboul, R. Hull, and V . Vianu, Foundations of Databases: The
Logical Level . Pearson, 1994.
[37] R. Alur, R. Bodik, G. Juniwal, M. M. Martin, M. Raghothaman, S. A.
Seshia, R. Singh, A. Solar-Lezama, E. Torlak, and A. Udupa, ‚ÄúSyntax-
guided synthesis,‚Äù in Formal Methods in Computer-Aided Design , 2013,
pp. 1‚Äì8.
[38] S. Muggleton, D. Lin, and A. Tamaddoni-Nezhad, ‚ÄúMeta-interpretive
learning of higher-order dyadic Datalog: Predicate invention revisited,‚Äù
Machine Learning , vol. 100, no. 1, pp. 49‚Äì73, 2015.
[39] X. Si, W. Lee, R. Zhang, A. Albarghouthi, P. Koutris, and M. Naik,
‚ÄúSyntax-guided synthesis of datalog programs,‚Äù in ACM Joint Meeting
on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering , 2018, pp. 515‚Äì527.
[40] S. Russell and P. Norvig, ‚ÄúArtiÔ¨Åcial intelligence: a modern approach,‚Äù
2002.
[41] D. Calvanese, G. De Giacomo, and M. Y . Vardi, ‚ÄúDecidable containment
of recursive queries,‚Äù Theoretical Computer Science , vol. 336, no. 1, pp.
33‚Äì56, 2005.
[42] D. Calvanese, G. De Giacomo, and M. Lenzerini, ‚ÄúOn the decidability
of query containment under constraints,‚Äù in PODS , vol. 98, 1998, pp.
149‚Äì158.
[43] D. Calvanese, G. De Giacomo, M. Lenzerini, and M. Y . Vardi, ‚ÄúReasoning
on regular path queries,‚Äù ACM SIGMOD Record , vol. 32, no. 4, pp. 83‚Äì92,
2003.
[44] P. Barcel ¬¥o, M. Romero, and M. Y . Vardi, ‚ÄúDoes query evaluation
tractability help query containment?‚Äù in ACM SIGMOD-SIGACT-SIGART
symposium on Principles of database systems , 2014, pp. 188‚Äì199.
821[45] M. Sheeran, S. Singh, and G. St Àöalmarck, ‚ÄúChecking safety properties
using induction and a sat-solver,‚Äù in International conference on formal
methods in computer-aided design , 2000, pp. 127‚Äì144.
[46] A. F. Donaldson, L. Haller, D. Kroening, and P. R ¬®ummer, ‚ÄúSoftware ver-
iÔ¨Åcation using k-induction,‚Äù in International Static Analysis Symposium ,
2011, pp. 351‚Äì368.
[47] M. Y . Gadelha, H. I. Ismail, and L. C. Cordeiro, ‚ÄúHandling loops in
bounded model checking of c programs via k-induction,‚Äù International
Journal on Software Tools for Technology Transfer , vol. 19, no. 1, pp.
97‚Äì114, 2017.
[48] L. De Moura and N. Bj√∏rner, ‚ÄúZ3: An efÔ¨Åcient SMT solver,‚Äù in
International conference on Tools and Algorithms for the Construction
and Analysis of Systems , 2008, pp. 337‚Äì340.
[49] J.-S. Coron, E. Prouff, M. Rivain, and T. Roche, ‚ÄúHigher-order side
channel security and mask refreshing,‚Äù in International Workshop on
Fast Software Encryption , 2013, pp. 410‚Äì424.
[50] M. Rivain and E. Prouff, ‚ÄúProvably secure higher-order masking of AES,‚Äù
inInternational Workshop on Cryptographic Hardware and Embedded
Systems , 2010, pp. 413‚Äì427.
[51] Y . Yao, M. Yang, C. Patrick, B. Yuce, and P. Schaumont, ‚ÄúFault-assisted
side-channel analysis of masked implementations,‚Äù in International
Symposium on Hardware Oriented Security and Trust , 2018, pp. 57‚Äì64.
[52] R. Zhang, S. Qiu, and Y . Zhou, ‚ÄúFurther improving efÔ¨Åciency of higher
order masking schemes by decreasing randomness complexity,‚Äù IEEE
Transactions on Information Forensics and Security , vol. 12, no. 11, pp.
2590‚Äì2598, 2017.
[53] J.-S. Coron, A. Greuet, E. Prouff, and R. Zeitoun, ‚ÄúFaster evaluation
of sboxes via common shares,‚Äù in International Conference on Crypto-
graphic Hardware and Embedded Systems , 2016, pp. 498‚Äì514.
[54] M. Zaheer, J.-B. Tristan, M. L. Wick, and G. L. Steele Jr, ‚ÄúLearning a
static analyzer: A case study on a toy language,‚Äù 2016.
[55] S. Grebenshchikov, N. P. Lopes, C. Popeea, and A. Rybalchenko,
‚ÄúSynthesizing software veriÔ¨Åers from proof rules,‚Äù in ACM SIGPLAN
Notices , vol. 47, no. 6, 2012, pp. 405‚Äì416.
[56] G. Chen, Y . Wang, M. Zhou, and J. Sun, ‚ÄúVFQL: combinational static
analysis as query language,‚Äù in ACM SIGSOFT International Symposium
on Software Testing and Analysis , 2019, pp. 378‚Äì381.
[57] O. Katz, R. El-Yaniv, and E. Yahav, ‚ÄúEstimating types in binaries using
predictive modeling,‚Äù in ACM SIGPLAN Notices , vol. 51, no. 1, 2016,
pp. 313‚Äì326.
[58] V . Raychev, M. Vechev, and A. Krause, ‚ÄúPredicting program properties
from big code,‚Äù in ACM SIGPLAN Notices , vol. 50, no. 1, 2015, pp.
111‚Äì124.
[59] O. Tripp, S. Guarnieri, M. Pistoia, and A. Aravkin, ‚ÄúAletheia: Improving
the usability of static security analysis,‚Äù in ACM SIGSAC Conference on
Computer and Communications Security , 2014, pp. 762‚Äì774.
[60] T. Gvero and V . Kuncak, ‚ÄúSynthesizing java expressions from free-form
queries,‚Äù in Acm Sigplan Notices , vol. 50, no. 10, 2015, pp. 416‚Äì432.
[61] R. Mangal, X. Zhang, A. V . Nori, and M. Naik, ‚ÄúA user-guided approach
to program analysis,‚Äù in Joint Meeting on Foundations of Software
Engineering , 2015, pp. 462‚Äì473.
[62] K. Heo, H. Oh, H. Yang, and K. Yi, ‚ÄúAdaptive static analysis via
learning with bayesian optimization,‚Äù ACM Transactions on Programming
Languages and Systems (TOPLAS) , vol. 40, no. 4, p. 14, 2018.
[63] K. Heo, H. Oh, and H. Yang, ‚ÄúLearning a variable-clustering strategy for
octagon from labeled data generated by a static analysis,‚Äù in International
Static Analysis Symposium , 2016, pp. 237‚Äì256.
[64] R. Grigore and H. Yang, ‚ÄúAbstraction reÔ¨Ånement guided by a learnt
probabilistic model,‚Äù in ACM SIGPLAN Notices , vol. 51, no. 1, 2016,
pp. 485‚Äì498.
[65] K. Heo, H. Oh, and H. Yang, ‚ÄúResource-aware program analysis via
online abstraction coarsening,‚Äù in International Conference on Software
Engineering , 2019, pp. 94‚Äì104.
[66] H. Oh, H. Yang, and K. Yi, ‚ÄúLearning a strategy for adapting a program
analysis via bayesian optimisation,‚Äù in ACM SIGPLAN Notices , vol. 50,
no. 10, 2015, pp. 572‚Äì588.
[67] K. Heo, H. Oh, and K. Yi, ‚ÄúMachine-learning-guided selectively unsound
static analysis,‚Äù in International Conference on Software Engineering ,
2017, pp. 519‚Äì529.
[68] G. Singh, M. P ¬®uschel, and M. Vechev, ‚ÄúFast numerical program analysis
with reinforcement learning,‚Äù in International Conference on Computer
Aided VeriÔ¨Åcation , 2018, pp. 211‚Äì229.
[69] C. Wang, Z. Yang, A. Gupta, and F. Ivan Àáci¬¥c, ‚ÄúUsing counterexamples
for improving the precision of reachability computation with polyhedra,‚ÄùinInternational Conference on Computer Aided VeriÔ¨Åcation , 2007, pp.
352‚Äì265.
[70] R. Rolim, G. Soares, L. D‚ÄôAntoni, O. Polozov, S. Gulwani, R. Gheyi,
R. Suzuki, and B. Hartmann, ‚ÄúLearning syntactic program transformations
from examples,‚Äù in International Conference on Software Engineering ,
2017, pp. 404‚Äì415.
[71] S. Mechtaev, J. Yi, and A. Roychoudhury, ‚ÄúAngelix: Scalable multi-
line program patch synthesis via symbolic analysis,‚Äù in International
Conference on Software Engineering , 2016, pp. 691‚Äì701.
[72] Y . Feng, R. Martins, J. Van Geffen, I. Dillig, and S. Chaudhuri,
‚ÄúComponent-based synthesis of table consolidation and transformation
tasks from examples,‚Äù in ACM SIGPLAN Notices , vol. 52, no. 6, 2017,
pp. 422‚Äì436.
[73] N. Polikarpova, I. Kuraj, and A. Solar-Lezama, ‚ÄúProgram synthesis from
polymorphic reÔ¨Ånement types,‚Äù in ACM SIGPLAN Notices , vol. 51, no. 6,
2016, pp. 522‚Äì538.
[74] A. Abate, I. Bessa, D. Cattaruzza, L. Cordeiro, C. David, P. Kesseli,
D. Kroening, and E. Polgreen, ‚ÄúAutomated formal synthesis of digital
controllers for state-space physical plants,‚Äù in International Conference
on Computer Aided VeriÔ¨Åcation , 2017, pp. 462‚Äì482.
[75] R. Bavishi, H. Yoshida, and M. R. Prasad, ‚ÄúPhoenix: automated data-
driven synthesis of repairs for static analysis violations,‚Äù in Proceedings
of the 2019 27th ACM Joint Meeting on European Software Engineering
Conference and Symposium on the Foundations of Software Engineering ,
2019, pp. 613‚Äì624.
[76] Y . Xiong, J. Wang, R. Yan, J. Zhang, S. Han, G. Huang, and L. Zhang,
‚ÄúPrecise condition synthesis for program repair,‚Äù in International Confer-
ence on Software Engineering , 2017, pp. 416‚Äì426.
[77] X.-B. D. Le, D.-H. Chu, D. Lo, C. Le Goues, and W. Visser, ‚ÄúS3: syntax-
and semantic-guided repair synthesis via programming by examples,‚Äù
inJoint Meeting on Foundations of Software Engineering , 2017, pp.
593‚Äì604.
[78] J. Hua, M. Zhang, K. Wang, and S. Khurshid, ‚ÄúTowards practical program
repair with on-demand candidate generation,‚Äù in International Conference
on Software Engineering , 2018, pp. 12‚Äì23.
[79] T. Knoth, D. Wang, N. Polikarpova, and J. Hoffmann, ‚ÄúResource-guided
program synthesis,‚Äù in ACM SIGPLAN Conference on Programming
Language Design and Implementation , 2019, pp. 253‚Äì268.
[80] P. Li, P. Zhang, L.-N. Pouchet, and J. Cong, ‚ÄúResource-aware throughput
optimization for high-level synthesis,‚Äù in ACM/SIGDA International
Symposium on Field-Programmable Gate Arrays , 2015, pp. 200‚Äì209.
[81] X. Zhang, R. Mangal, R. Grigore, M. Naik, and H. Yang, ‚ÄúOn abstraction
reÔ¨Ånement for program analyses in datalog,‚Äù in ACM SIGPLAN Notices ,
vol. 49, no. 6, 2014, pp. 239‚Äì248.
[82] X. Si, M. Raghothaman, K. Heo, and M. Naik, ‚ÄúSynthesizing datalog
programs using numerical relaxation,‚Äù arXiv preprint arXiv:1906.00163 ,
2019.
[83] L. Bang, A. Aydin, Q.-S. Phan, C. S. P ÀòasÀòareanu, and T. Bultan, ‚ÄúString
analysis for side channels with segmented oracles,‚Äù in ACM SIGSOFT
International Symposium on Foundations of Software Engineering , 2016,
pp. 193‚Äì204.
[84] S. Guo, M. Wu, and C. Wang, ‚ÄúAdversarial symbolic execution for
detecting concurrency-related cache timing leaks,‚Äù in ACM Joint Meeting
on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering , 2018, pp. 377‚Äì388.
[85] C. Sung, B. Paulsen, and C. Wang, ‚ÄúCANAL: a cache timing analysis
framework via LLVM transformation,‚Äù in IEEE/ACM International
Conference On Automated Software Engineering , 2018, pp. 904‚Äì907.
[86] S. Cauligi, G. Soeller, B. Johannesmeyer, F. Brown, R. S. Wahby,
J. Renner, B. Gr ¬¥egoire, G. Barthe, R. Jhala, and D. Stefan, ‚ÄúFaCT: a
dsl for timing-sensitive computation,‚Äù in ACM SIGPLAN Conference on
Programming Language Design and Implementation , 2019, pp. 174‚Äì189.
[87] M. Wu, S. Guo, P. Schaumont, and C. Wang, ‚ÄúEliminating timing side-
channel leaks using program repair,‚Äù in ACM SIGSOFT International
Symposium on Software Testing and Analysis , 2018, pp. 15‚Äì26.
[88] B. Paulsen, C. Sung, P. A. H. Peterson, and C. Wang, ‚ÄúDebreach:
Mitigating compression side channels via static analysis and transforma-
tion,‚Äù in IEEE/ACM International Conference On Automated Software
Engineering , 2019, pp. 899‚Äì911.
822