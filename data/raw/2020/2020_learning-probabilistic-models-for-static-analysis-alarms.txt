Learning Probabilistic Models for Static Analysis Alarms
Hyunsu Kim
KAIST
Korea
hyunsu.kim00@kaist.ac.krMukund Raghothaman
University of Southern California
USA
raghotha@usc.eduKihong Heo
KAIST
Korea
kihong.heo@kaist.ac.kr
ABSTRACT
We present BayeSmith, a general framework for automatically
learning probabilistic models of static analysis alarms. Several prob-
abilistic reasoning techniques have recently been proposed which
incorporate external feedback on semantic facts and thereby reduce
the userâ€™s alarm inspection burden. However, these approaches are
fundamentally limited to models with pre-defined structure, and are
therefore unable to learn or transfer knowledge regarding an anal-
ysis from one program to another. Furthermore, these probabilistic
models often aggressively generalize from external feedback and
falsely suppress real bugs. To address these problems, we propose
BayeSmith that learns the structure and weights of the probabilistic
model. Starting from an initial model and a set of training programs
with bug labels, BayeSmith refines the model to effectively priori-
tize real bugs based on feedback. We evaluate the approach with
two static analyses on a suite of C programs. We demonstrate that
the learned models significantly improve the performance of three
state-of-the-art probabilistic reasoning systems.
1 INTRODUCTION
To deal with the challenges of accuracy and alarm relevance, various
probabilistic program reasoning mechanisms have been proposed
for static program analyzers. Such systems initially report a set of
alarms in the target program using the underlying analysis and com-
pute the probability of each alarm based on a probabilistic model.
Then, they prioritize static analysis alarms by incorporating exter-
nal feedback on semantic facts from various sources such as the
users [ 23,39,50], the old version of the program [ 15], or dynamic
analysis results [ 5]. Upon receiving a response, they generalize
from the feedback and prioritize the remaining alarms depend-
ing on their relevance to those inspected by the user. By rapidly
focusing attention on the real bugs in the target program, these
systems achieve a dramatic improvement in the usability of the
static analyzer.
Despite their experimental success, much of this previous re-
search has focused on the problem of inference, rather than on
learning. Existing approaches based on probabilistic reasoning such
as alarm ranking [ 5,15,39] only learn limited forms of transfer-
able knowledgeâ€”such as the assignment of weights to the under-
lying probabilistic modelâ€”using standard methods such as the
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05. . . $15.00
https://doi.org/10.1145/3510003.3510098expectation-maximization algorithm [ 20]. In our observation, how-
ever, the capability of learning is fundamentally limited to the
underlying structure of the probabilistic model.
In this paper, we propose a general framework for learning proba-
bilistic models for static analysis alarms, that is applicable to various
probabilistic reasoning systems [ 5,15,39]. The underlying systems
initially construct Bayesian networks from the derivation structure
of the alarms, and prioritize alarms using the induced confidence
values. This ranking is repeatedly updated as the user inspects
alarms and reports their findings. Ideally, these responses should al-
ways improve the confidence scores of true bugs and decrease those
of false alarms. In practice, however, because of approximations
caused by the underlying abstraction and during model recovery,
they often incorrectly prioritize false alarms over true bugs. Our
goal is to improve the accuracy of probabilistic models and mitigate
the impact of these false generalization events. Given a set of train-
ing programs with bug labels, we learn logical rules that produce
accurate Bayesian network models to reduce the number of user
interactions until discovering all true alarms.
Notice that our problem (i.e., learning) is fundamentally different
from that (i.e., inference) addressed in previous papers [ 5,15,39].
Learning and inference are complementary problems in AI/ML
research, especially for Bayesian networks. The existing ones solely
focused on the inference of Bayesian probabilistic models generated
by a fixed hand-written set of rules. Instead, we shed light on the
capability of learning the Bayesian models that can significantly
improve the performance in multiple instances.
Our approach is based on two key ideas: (1) feedback-directed
and (2) syntax-guided refinement. We first construct the Bayesian
networks with an initial set of rules and evaluate the quality of
interactive alarm prioritization using a given labeled data set. By
observing the results, we capture the moments when a response
to one alarm falsely generalizes to other alarms and degrades the
overall quality of rankings. For such cases, our learning algorithm
refines the rules that generate the inaccurate part of the Bayesian
network. The refinement is guided by program syntax and encodes
more detailed context of the labeled alarm to the rules by adding
syntactic features which are directly derived from the grammar of
the target language.
We have instantiated this approach in a tool named BayeSmith,
and evaluate its effectiveness on a suite of widely used C programs,
each comprising 5â€“112 KLOC with two analyses for C: an interval
analysis for buffer overrun errors and a taint analysis for format-
string and integer-overflow errors. We measure the effectiveness
ofBayeSmith with three state-of-the-art probabilistic program
reasoning systems, each of which incorporates feedback from the
users [ 39], the previous version of the program [ 15], and dynamic
analysis results [ 5]. The learned rules by BayeSmith significantly
12822022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Hyunsu Kim, Mukund Raghothaman, and Kihong Heo
improve the performance of the existing systems with manually
designed models by 30.7%, 54.3%, and 20.3%, respectively.
Contributions. This paper makes the following contributions:
(1)We present a framework for learning probabilistic models for
static analysis alarms from data.
(2)We propose a feedback-directed algorithm that learns proba-
bilistic models by mitigating false generalization events.
(3)We evaluate our approach with two state-of-the-art static ana-
lyzers and demonstrate significant improvements in three prob-
abilistic program reasoning systems on a suite of C programs.
2 OVERVIEW
We illustrate our approach using the C program excerpted from
wget-1.12 in Figure 1. Given the name of file ( file ), the function
ftp_parse_vms_ls reads a line from the file (line 3) and tokenizes
the line (line 4). Then, the function iterates over a token backward
(line 6) and removes all digits after a special character '^'by adding
'\0' (line 11). However, a buffer underflow bug can occur when
all the elements in a token are digits. Pointer variable pmay point
to the starting position of such a token, so that the memory access
top-1at line 10 is potentially unsafe.
The buffer over/underflow analysis in Sparrow [37] detects
the bug but also reports false alarms at the other buffer access
expressions in the function. Sparrowâ€™s sound interval analysis can
estimate that the memory access at line 10 can underflow the buffer.
On the other hand, it cannot precisely capture the fact that the
pointerpalways points to a valid memory region even after the loop,
because the contents of the string tokare determined at runtime
so that the loop terminating condition becomes complicated.
Once such a set of alarms is generated, Sparrow ranks the alarms
using a Bayesian alarm ranking system Bingo [15,39].Bingo com-
putes a confidence score for each alarm and provides a ranking to
the user. Then the user labels the top-ranked alarm so that Bingo
performs Bayesian inference to update the scores of the remaining
alarms. This probabilistic inference enables the user to interactively
reason about the correctness of the program and effectively filters
out false alarms while highlighting true alarms.
Although the alarm ranking system significantly reduces the
alarm inspection burden of users, it often misinterprets userâ€™s re-
sponse. For wget-1.12, Sparrow reports 891 alarms in total. After
166 user interactions with Bingo, the false alarm at line 7 is ranked
at the top and the true alarm is also highly ranked (9th) in Fig-
ure 2(a). Once the user labels the top-ranked alarm as false, Bingo
generalizes the feedback, thereby lowering the ranking of other
correlated false alarm such as the alarm at line 11. However, this
feedback also undesirably drops the rank of true alarm at line 10
from rank 9 to 462. Because the true alarm is also closely related to
the labeled false alarm, Bingo falsely generalizes the userâ€™s label
so that degrades the ranking. A similar issue again happens after
187 user interactions. The ranking of the true alarm drops from 2
to 505 after the userâ€™s labeling on the false alarm at line 11.
Our goal is to learn an effective probabilistic model based on
Bayesian network that mitigates such false generalizations. We ob-
served that false generalizations can happen because the structure
of the Bayesian network is too coarse to capture the complex behav-
ior of programs. In the original Bingo, this network is derived from1void ftp_parse_vms_ls(char *file) {
2FILE *fp = fopen(file, 'r');
3char*line = read_line (fp);
4char*tok = strtok(line, "â£");
5char*p = tok + strlen(tok);
6while(p > tok) {
7 if(!c_isdigit(*p)) break;// false alarm #1
8 p--;
9}
10if(*(p - 1) != '^') // true alarm (buffer underflow)
11 *p = '\0'; // false alarm #2
12}
Figure 1: An example code excerpted from wget-1.12.
a set of simple hand-written rules that approximates the abstract
semantics of the underlying analyzer using def-use relations be-
tween program points [ 15]. The rules are general enough to capture
the behavior of a large class of static analyses, but insufficient to
differentiate various contexts. In the rest of this section, we illus-
trate why the false generalization occurs and how we learn more
sophisticated rules from data.
2.1 Approximating Static Analysis via Datalog
The buffer overflow analysis in Sparrow is based on the abstract
interpretation framework [ 6] and uses a flow-, field-, and context-
sensitive interval analysis [ 37]. While its actual abstract semantics
involves sophisticated reasoning about numeric, pointer, and array
values, it can be approximated by simple inference rules based
on general def-use relations [ 36]. The inference rules written in
Datalog are depicted in Figure 3 from which Bingo derives the
Bayesian network structure. Notice that the approximated rules are
used only for modeling portions of the whole reasoning process
which are important for alarm ranking. They do not affect the
behavior of the underlying analyzer written in arbitrary languages.
The Datalog program takes tuples in the input relations and
derives tuples in the output relations using the set of rules. For
example, input tuple DUEdge(6,7)represents that there exists a
direct data flow from the definition point of variable pat line 6
to its use point at line 7 in Figure 1.1Input tuple Overflow(7)
approximates the detailed reasoning by the interval analysis and
represents the fact that a buffer overflow may happen at line 7.
The inference rules derive new output tuples from input and other
output tuples. For example, rule ğ‘Ÿ2derives an indirect data flow
DUPath(ğ‘1,ğ‘3)from program point ğ‘1toğ‘3using another data
flows DUPath(ğ‘1,ğ‘2)andDUEdge(ğ‘2,ğ‘3). The ultimate goal of the
analysis is to derive alarm tuples Alarm(ğ‘)that represent the fact
that a potentially erroneous trace reaches program point ğ‘. We
repeatedly apply the rules to all tuples until no more new output
tuples are derived (i.e., fixed point).
Then we construct a derivation graph that shows all the rea-
soning steps to derive all alarms. An example derivation graph is
shown in Figure 2(b) that explains how Alarm(7)andAlarm(10)
are derived. For example, Alarm(7)is derived by applying ğ‘Ÿ3to
tuple Overflow(7)andDUPath(5,7)which is derived by ğ‘Ÿ2with
DUEdge(6,7)andDUPath(5,6). Notice that the nodes with rule
names mean grounded rules. For example, ğ‘Ÿ2(5,6,7)describes rule
1We assume the SSA-style def-use relation. Thus, we consider the phi-node for variables
p(i.e., line 6) at the loop head as a definition point.
1283
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning Probabilistic Models for Static Analysis Alarms ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Rank Alarm Prob.
1 Alarm(7) 0.93
2 Alarm(11) 0.92
Â·Â·Â·
9 Alarm(10) 0.91
Â·Â·Â·â†’Rank Alarm Prob.
Â·Â·Â·
Â·Â·Â·
461 Alarm(11) 0.41
462 Alarm(10) 0.40
Â·Â·Â·
Rank Alarm Prob.
1 Alarm(11) 0.97
2 Alarm(10) 0.96
Â·Â·Â·â†’Rank Alarm Prob.
Â·Â·Â·
505 Alarm(10) 0.003
Â·Â·Â·
(a) Ranking changes after 166 and 187 interactions
DUPath(5, 6)
DUPath(5, 10)DUEdge(6, 10)
Alarm(10)Overï¬‚ow(10)DUEdge(6, 7)
DUPath(5, 7)
Alarm(7)Overï¬‚ow(7)â€¦
r2	
r3	
 r3	
r2	
 (b) Derivation graph
0 50 100 150
# Interactions0500100015002000250030003500Rank
BayeSmith
Bingowget (c) Performance comparison
Figure 2: False generalization. Each data point in (c) represents the sum of the rankings of 6 true alarms.
Input relations
DUEdge(ğ‘1,ğ‘2): Immediate data flow from ğ‘1toğ‘2
Overflow(ğ‘): Potential buffer overrun at ğ‘
Output relations
DUPath(ğ‘1,ğ‘2): Transitive data flow from ğ‘1toğ‘2
Alarm(ğ‘): Potentially erroneous trace reaching ğ‘
Analysis rules
ğ‘Ÿ1:DUPath(ğ‘1,ğ‘2):âˆ’DUEdge(ğ‘1,ğ‘2).
ğ‘Ÿ2:DUPath(ğ‘1,ğ‘3):âˆ’DUPath(ğ‘1,ğ‘2),DUEdge(ğ‘2,ğ‘3).
ğ‘Ÿ3: Alarm(ğ‘2):âˆ’DUPath(ğ‘1,ğ‘2),Overflow(ğ‘2).
Figure 3: Approximated interval analysis with simple infer-
ence rules. All variables indicate program points.
ğ‘Ÿ2is triggered with tuples DUPath(5,6)andDUEdge(6,7), then
derives conclusion DUPath(5,7).
2.2 Bayesian Alarm Ranking System
Next, we convert the derivation graph into a Bayesian network
following the scheme in the previous work [ 39]. The central idea is
to quantify the incompleteness of each rule as a probability. Static
analysis rules are typically designed to be sound but not always
complete. This incompleteness is one of the main sources of false
alarms. Suppose both DUPath(5,6)andDUEdge(6,7)are true in
Figure 2(b). However, it does not necessarily mean the conclusion
DUPath(6,7)is always true in the concrete semantics, because
complicated runtime behavior is approximated such as different
loop iterations or nontrivial termination conditions. Bingo encodes
this incompleteness using conditional probability. Each rule ğ‘Ÿis
associated with a probability ğ‘ğ‘Ÿ. For example, the rules
Pr ğ‘Ÿ2(5,6,7)|DUPath(5,6)âˆ§ DUEdge(6,7)=ğ‘ğ‘Ÿ2
Pr ğ‘Ÿ2(5,6,7)|Â¬DUPath(5,6)âˆ¨Â¬DUEdge(6,7)=0
represent the rule ğ‘Ÿ2is successfully triggered with probability
ğ‘ğ‘Ÿ2if both DUPath(5,6)andDUEdge(6,7)are true, otherwise it
is never triggered. Meanwhile, Bingo considers a conclusion of
a rule is always true if the rule successfully fires. For example,
Pr DUPath(5,7)|ğ‘Ÿ2(5,6,7)=1.We use the default probability
(0.99) of the Bingo system for rules and input tuples that do not
have deriving rules.
Based on the Bayesian network constructed from the derivation
graph, Bingo computes the probability of each alarm Pr Alarm(ğ‘)|
ğ’†)conditioned on the set of labels ğ’†. The set ğ’†is initially empty
and gradually includes more labels from the user. Every time theuser provides a label for the top-ranked alarm, Bingo reranks the
remaining alarms according to Pr Alarm(ğ‘)|ğ’†).
2.3 The False Generalization Problem
Ideally, the userâ€™s labeling on a false alarm should only degrade the
probability of other correlated false alarms in the network. Con-
sider the alarm rankings before and after the user gives a negative
label on Alarm(7)at the top of Figure 2(a). The labeling success-
fully generalizes to another false alarm Alarm(11)and degrades its
probability from 0.92to0.41.
However, the negative feedback also falsely generalizes to the
true alarm Alarm(10)and undesirably degrades its ranking from 9
to 462. The same effect also happens with another negative label on
Alarm(11). In practice, such false generalizations hinder the userâ€™s
effort to discover true alarms as early as possible.
We illustrate why this false generalization occurs with the deriva-
tion graph in Figure 2(b). Given a negative label on Alarm(7),Bingo
computes the conditional probability Pr Alarm(10)|Â¬Alarm(7))
that indicates the probability of the true alarm after the negative
labeling. According to the Bayesian network structure, Alarm(10)
andAlarm(7)are conditionally independent given DUPath(5,6).
Therefore, the posterior probability is computed as follows:2:
Pr Alarm(10)|Â¬Alarm(7)(1)
=Pr Alarm(10)| DUPath(5,6)Ã—Pr DUPath(5,6)|Â¬Alarm(7).
The first term Pr Alarm(10)|DUPath(5,6)evaluates to 0.96. For
simplicity, we assume that the prior probability Pr DUPath(5,6)=
0.99. Then, by Bayesâ€™ rule, the second term is evaluated as follows:
Pr Â¬Alarm(7)|DUPath(5,6)âˆ§ DUEdge(6,7)Ã—0.992Ã—0.07âˆ’1
The probability Pr Â¬Alarm(7)|DUPath(5,6)âˆ§DUEdge(6,7)is
the sum of following disjoint cases:
â€¢ğ‘Ÿ2(5,6,7)misfired:
Pr Â¬Alarm(7)|Â¬ğ‘Ÿ2(5,6,7)Ã—Pr Â¬ğ‘Ÿ2(5,6,7)|DUPath(5,6)âˆ§ DUEdge(6,7)
=1Ã—(1âˆ’ğ‘ğ‘Ÿ2)=0.01 (2)
â€¢ğ‘Ÿ2(5,6,7)fired, Overflow(7)was true, but ğ‘Ÿ3(5,7)misfired:
Pr Â¬Alarm(7)|ğ‘Ÿ2(5,6,7)Ã—Pr ğ‘Ÿ2(5,6,7)|DUPath(5,6)âˆ§ DUEdge(6,7)
=(1âˆ’ğ‘ğ‘Ÿ3)Ã—0.992=0.0098 (3)
2All the details of the calculations in this subsection are described in Appendix ??.
1284
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Hyunsu Kim, Mukund Raghothaman, and Kihong Heo
â€¢ğ‘Ÿ2(5,6,7)fired but Overflow(7)was false:
Pr Â¬Alarm(7)|ğ‘Ÿ2(5,6,7)Ã—Pr ğ‘Ÿ2(5,6,7)|DUPath(5,6)âˆ§ DUEdge(6,7)
=0.01Ã—0.99=0.0099 (4)
Overall, Pr DUPath(5,6) | Â¬Alarm(7)is evaluated to 0.0297Ã—
0.992Ã—0.07âˆ’1=0.42.
Finally, the true alarm now has a significantly low probability by
multiplying the two terms: Pr Alarm(10)|Â¬Alarm(7)=0.96Ã—
0.42=0.40.Notice that the probability of the first term is high
enough. The false generalization is mainly caused by the second
term, especially because of the high probabilities of ğ‘ğ‘Ÿ2andğ‘ğ‘Ÿ3in
(2) and (3), respectively.
Intuitively, this means that the negative label excessively blames
the common root cause DUPath(5,6)of the two alarms. It decreases
the posterior probability of DUPath(5,6)that also leads to decrease
the probabilities of its descendants including the true alarm. Con-
cretely, such excessive blames are incurred from unreasonably high
rule probabilities that eventually lead to the false alarm. For exam-
ple, the probability of a rule that derives DUPath(5,7)should have
been lower than those of other rules that derive data flow paths in
straight-line code. The data flow from line 5 to 7 is involved in a
loop. Since static analyses typically merge the effects of different
loop iterations into a single abstract memory using join or widen-
ing operators, such data flows across loop iterations may have a
higher chance of deriving false conclusions. However, the current
monolithic derivation rules do not separate different circumstances.
2.4 Learning Bayesian Networks
Our main goal in this paper is to automatically derive an effective
Bayesian network that minimizes the effect of false generalization.
The idea is to learn more detailed features for Bayesian networks
from labeled data. Figure 4 shows an overview of our learning sys-
tem, BayeSmith. First, the system constructs an initial Bayesian
network from the analysis results using a set of initial rules as in
Figure 3. Given the Bayesian network and the bug labels, Baye-
Smith simulates user interactions with the alarm ranking system
and observes false generalizations. Then, BayeSmith learns new
rules that are likely to reduce the effect of the most serious false
generalizations. If the quality of ranking improves by the new rules,
then we repeat the learning process using the rules. Otherwise,
BayeSmith tries another candidate rule for false generalization.
For each false generalization observed in the simulations, we find
grounded rules that are the main sources of the false generalization
such asğ‘Ÿ2(5,6,7)in the previous example. Then BayeSmith refines
the corresponding rule based on the syntax of the program part.
For example, the rule ğ‘Ÿ2can be refined to two disjoint rules:
ğ‘Ÿ21:DUPath(ğ‘1,ğ‘3):âˆ’DUPath(ğ‘1,ğ‘2),Loop(ğ‘2),DUEdge(ğ‘2,ğ‘3)(5)
ğ‘Ÿ22:DUPath(ğ‘1,ğ‘3):âˆ’DUPath(ğ‘1,ğ‘2),!Loop(ğ‘2),DUEdge(ğ‘2,ğ‘3)(6)
where Loop(ğ‘)indicates program point ğ‘corresponds to a loop
head. The rule ğ‘Ÿ21will fire when the data flow is involved in a loop
andğ‘Ÿ21will fire otherwise. BayeSmith associatesğ‘Ÿ21with a lower
probability and ğ‘Ÿ22with a higher one. If the new set of rules leads
to improve the quality of the alarm ranking system, BayeSmith
continues the learning process with the learned rules. Otherwise, it
seeks to find other candidates for the false generalization or moves
the focus to another false generalization in the data.Figure 2(c) shows how the ranking of the true alarm in wget-1.12
changes whenever the user provides a label until discovering the
true alarm. With the learned rules by BayeSmith, Bingo requires
the user to inspect 53.4% fewer alarms by significantly reducing
the magnitude and frequency of false generalizations compared to
the original Bingo. The derivation graph generated by the learned
rules is depicted in Figure 5. Notice that it is not achievable by
only learning weights without refining rules, or uniformly refining
every component in the rules. In Section 5, we will show that
BayeSmith significantly outperforms these approaches. In the rest
of this section, we will describe the details of the learning process.
Finding candidates. BayeSmith collects a set of candidate rules
to be refined from observed false generalizations. Given a false
alarm and a true alarm whose ranking is degraded by the false gen-
eralization, we first find a closest common ancestor of the alarms in
the Bayesian network. For example, in Figure 2(b), the closest com-
mon ancestor of Alarm(7)andAlarm(10)isDUPath(5,6). Then,
we collect all grounded rules between the false alarm and the com-
mon ancestor. In the example, ğ‘Ÿ2(5,6,7)andğ‘Ÿ3(5,7)are collected.
BayeSmith tries to refine ğ‘Ÿ2andğ‘Ÿ3to more precisely represent the
specific circumstances at line 5, 6, and 7.
Such refinement is likely to increase the posterior probabil-
ity of the true alarm. In equation (1), the conditional probability
Pr Alarm(10) |Â¬Alarm(7)rises if we increase the probability
Pr DUPath(5,6) | Â¬Alarm(7). The refinement by BayeSmith
would increase this probability by decreasing the probabilities for
ğ‘Ÿ2andğ‘Ÿ3(see the 1âˆ’ğ‘ğ‘Ÿ2and1âˆ’ğ‘ğ‘Ÿ3factors in equations 2 and 3).
Syntax-guided rule refinement. Next, for each candidate grounded
rule, BayeSmith performs refinements guided by the syntax of the
program. We assume that a program is represented as a control flow
graph and each node ğ‘is associated with a command. BayeSmith is
parameterized by the target language grammar for the underlying
analyzer. Here we assume the following general C-like grammar:
(ğ¶ğ‘œğ‘šğ‘šğ‘ğ‘›ğ‘‘)ğ‘â†’ lv:=e|assume(e)|call(ğ‘’,ğ‘’)|loop
(ğ¿-ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’)lvâ†’ğ‘¥|âˆ—e
(ğ¸ğ‘¥ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘–ğ‘œğ‘›) eâ†’ğ‘›|lv|e+e
We represent the grammar in a Datalog-style representation:
Cmd(ğ‘):âˆ’Assign(ğ‘,ğ‘’)
Cmd(ğ‘):âˆ’Assume(ğ‘,ğ‘’)
Cmd(ğ‘):âˆ’Call(ğ‘,ğ‘’)
Cmd(ğ‘):âˆ’Loop(ğ‘).Lval(ğ‘™):âˆ’Var(ğ‘™).
Lval(ğ‘™):âˆ’Deref(ğ‘™,ğ‘’),Exp(ğ‘’).
Exp(ğ‘’):âˆ’Const(ğ‘’).
Exp(ğ‘’):âˆ’LvalExp(ğ‘’,ğ‘™),Lval(ğ‘™).
Exp(ğ‘’):âˆ’BinOp(ğ‘’,ğ‘’1,ğ‘’2),Exp(ğ‘’1),Exp(ğ‘’2).
For all arguments of a given candidate grounded rule, BayeSmith
finds the corresponding grammar rule that fires with the particular
syntactic element. For example, given ğ‘Ÿ2(5,6,7),BayeSmith can
capture line 6 corresponds to a loop head, so that the new rule that
fires with loop heads and its complement are obtained as in the rules
(5) and (6). This refinement maintains the same derivability for all
the output tuples. Every time a rule is refined, BayeSmith updates
the rule probability to ğ›¼Ã—ğ‘ğ‘Ÿwhere 0<ğ›¼<1is a hyperparameter
andğ‘ğ‘Ÿis the original rule probability of ğ‘Ÿ. The probability for the
complement rule remains unchanged.
Then BayeSmith evaluates the quality of the refined rule by
running Bingo on the labeled training data. If the new rules reduce
the number of user interactions in the simulation, we accept the
1285
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning Probabilistic Models for Static Analysis Alarms ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Code Corpus
with Bug Labels
A1 âˆ§ A2 âˆ§ An â‡’ X
B1 âˆ§ B2 âˆ§ Bn â‡’ Y 
B1 âˆ§ B2 âˆ§ Â¬Bn â‡’ Z 
*OJUJBM3VMFT#BZFTJBO
"MBSN3BOLFS
-FBSOFE
#BZFTJBO/FUXPSLAnalyzer
-FBSOFE
3VMFT
3BOLFE"MBSNT1. â€¦ âœ“
2. â€¦ âœ—3. â€¦ âœ“
1. â€¦.. 
2. â€¦.. 3. â€¦..Bayesian
Alarm Ranker-BCFMFE"MBSNT
AnalyzerProgramLearning
Algorithm
A1 âˆ§ A2 âˆ§ An â‡’ X
B1 âˆ§ B2 â‡’ Y 
*OJUJBM
#BZFTJBO
/FUXPSL-FBSOJOH *OGFSFODF
Figure 4: System overview
DUPath(5, 6) DUEdge(6, 7)
DUPath(5, 7)
Alarm(7)Overï¬‚ow(7)â€¦
r21	
r3	
Loop(6)
â€¦
Figure 5: A portion of the learned derivation graph.
rules and repeat the same process with another false generalization
if exists. When a previously refined rule is selected as a candidate
again, we refine the rule further following the grammar structure.
For example, the following refined rule
DUPath(ğ‘1,ğ‘3):âˆ’DUPath(ğ‘1,ğ‘2),Assign(ğ‘2,_),DUEdge(ğ‘2,ğ‘3)
can be further refined with the following body:
DUPath(ğ‘1,ğ‘2),Assign(ğ‘2,ğ‘’),Var(ğ‘’,_),DUEdge(ğ‘2,ğ‘3).
The rule probability then becomes ğ›¼2Ã—ğ‘ğ‘Ÿ.
In this way, BayeSmith learns rules and weights that derive
Bayesian networks from a given set of training programs with
bug label data. We observed that the learned models are applica-
ble to various probabilistic program reasoning systems [ 5,15,39]
and significantly reduce the userâ€™s alarm inspection burden in real
world programs compared to the previous ones. We will discuss
the detailed experimental results in Section 5.
3 PRELIMINARIES
3.1 Program Analysis and Syntactic Features
A Datalog program D=(I,O,R)is a triple of a set of input relations
(I), a set of output relations (O), and a set of rules (R ) [1]. Each
relation is a set of tuples. The output relations are derived from
the input relations using the set of rules each of which is of the
formğ‘…â„(ğ’—ğ’‰):âˆ’ğ‘…1(ğ’—1),...,ğ‘…ğ‘˜(ğ’—ğ’Œ)whereğ‘…â„is a derived output
relation and ğ‘…1,...,ğ‘…ğ‘˜are premises. We assume that the program
analysis is represented as a Datalog program DA=(IA,OA,RA).
For program analyses that are not written in a declarative language,
we approximate the behavior with a Datalog program [15].
The program analysis result for program ğ‘ƒis a tupleA(ğ‘ƒ)=
(ğ¼,ğ¶,ğ´,ğºğ¶)whereğ¼is the set of input facts, ğ¶is the set of output
facts,ğ´is the set of alarms, and ğºğ¶is the set of grounded clauses.
The analysis initially sets ğ¶:=ğ¼andğºğ¶:=âˆ…. Then, we accumulate
the conclusions ğ‘…â„(ğ’„â„)and the grounded clauses {ğ‘…1(ğ’„1)âˆ§...âˆ§
ğ‘…ğ‘˜(ğ’„ğ’Œ)=â‡’ğ‘Ÿğ‘…â„(ğ’„â„)}wheneverğ‘…1(ğ’„1),...,ğ‘…ğ‘˜(ğ’„ğ’Œ) âˆˆğ¶. The
analysis iterates the step until reaching fixpoint.We define a syntactic feature extractor as a Datalog program
DG=(IG,OG,RG)that extracts relational representations of pro-
grams in grammar G. The input relations IGconsist of atomic
relations such as constants and variables. The output relations OG
are derived from the input relations using the grammar rules RG.
3.2 Bayesian Alarm Prioritization
We present the Bayesian alarm prioritization that is a basis of vari-
ous probabilistic reasoning systems [ 5,15,39]. It first extracts the
derivation graph from the static analysis, converts the graph into a
Bayesian network, and then computes a confidence score for each
alarm. Upon user feedback, it performs Bayesian inference that
updates the scores.
The results of program analysis (ğ¼,ğ¶,ğ´,ğºğ¶)form a derivation
graph over the vertices ğ¶âˆªğºğ¶. There exists an edge from a tuple
ğ‘¡âˆˆğ¶to a clauseğ‘”âˆˆğºğ¶ifğ‘¡is an antecedent of ğ‘”, and an edge from
ğ‘”toğ‘¡ifğ‘¡is the conclusion of ğ‘”.
Next, we convert the derivation graph into a Bayesian network.
A Bayesian network is a tuple (ğº,P)whereğºis a directed acyclic
graph andPis an assignment that associates each node with a
conditional probability distribution. While a Bayesian network is an
acyclic graph by definition, a naive derivation graph from program
analysis may have cycles. We assume that the cycle elimination
algorithm in the previous work [ 39] is used to reduce the derivation
graph to be acyclic while still preserving the derivability of all tuples.
In the rest of the paper, we write ğºfor the reduced derivation graph.
Then we assign a conditional probability for each node in the
reduced graph using a given assignment Pand rule probabilities
ğ‘ğ‘Ÿ. For each input tuple ğ‘¡, we assign the predefined probability
ğ‘ğ‘¡:P(ğ‘¡)=ğ‘ğ‘¡. Consider a grounded clauses ğ‘”âˆˆğºğ¶of the form
ğ‘¡1âˆ§...âˆ§ğ‘¡ğ‘˜=â‡’ğ‘Ÿğ‘¡â„. Then, the conditional probability associated
withğ‘”is as follows:P(ğ‘”|ğ‘¡1âˆ§...âˆ§ğ‘¡ğ‘˜)=ğ‘ğ‘ŸandP(ğ‘”|Â¬(ğ‘¡1âˆ§...âˆ§
ğ‘¡ğ‘˜))=0. Consider a tuple ğ‘¡that is a conclusion of the grounded
clausesğ‘”1,...,ğ‘”ğ‘›. The conditional probability associated with ğ‘¡is
as follows:P(ğ‘¡|ğ‘”1âˆ¨...âˆ¨ğ‘”ğ‘˜)=1andP(ğ‘¡|Â¬(ğ‘”1âˆ¨...âˆ¨ğ‘”ğ‘˜))=0.
Given a set of alarms from the program analysis, the Bayesian
alarm ranking system derives a list of alarms sorted in descending
order of confidence. Let ğ’†ğ‘–be the set of user feedback after ğ‘–itera-
tions and Î¦denote the top-ranked alarm tuple at the next iteration:
Î¦=argmaxğ‘âˆˆğ´ğ‘¢Pr(ğ‘|ğ’†ğ‘–)whereğ´ğ‘¢is the set of all unlabeled
alarms. Given the user feedback on the top-ranked alarm Î¦, we
update the set ğ’†ğ‘–+1toğ’†ğ‘–âˆª{Î¦}if the user labels Î¦as true, otherwise,
ğ’†ğ‘–âˆª{Â¬Î¦}. Then, the ranking system derives the next alarm ranking
by updating the confidence scores of all remaining alarms.
1286
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Hyunsu Kim, Mukund Raghothaman, and Kihong Heo
4 LEARNING FRAMEWORK
4.1 Goal
The goal of our learning process is to find an optimal alarm rank-
ing system that minimizes the number of user interactions un-
til discovering all true alarms in the target program. We assume
that a set of training programs and their bug labels are given:
T={(ğ‘ƒ1,ğ¿1),...,(ğ‘ƒğ‘,ğ¿ğ‘)}.
BayeSmith aspires to achieve the goal by learning a (finite) set
of Datalog rules Râˆ—that derives accurate Bayesian network models.
The rules are refined by enriching the original analysis rules with
syntactic features. Given a program analysis DA=(IA,OA,RA)
and a syntactic feature extractor DG=(IG,OG,RG), we formalize
the goal as the following optimization problem:
Râˆ—=argmin
RâˆˆRâˆâˆ‘ï¸
(ğ‘ƒğ‘–,ğ¿ğ‘–)âˆˆTInteraction(ğ‘ƒğ‘–,ğ¿ğ‘–,R) (7)
where Râˆ=Ãâˆ
ğ‘›=0RAâŠ—ğ‘›RGandInteraction(ğ‘ƒğ‘–,ğ¿ğ‘–,R)is the num-
ber of user interactions until discovering all the true alarms in ğ‘ƒğ‘–
with the ranking system derived by program analysis augmented
with the syntactic features (IAâŠIGâŠOG,OA,R). The set RAâŠ—ğ‘›RG
is a collection of sets of analysis rules enriched with syntactic fea-
tures byğ‘›times:
RAâŠ—ğ‘›RG=Ã{RâŠ—RG|Râˆˆ RAâŠ—ğ‘›âˆ’1RG}ğ‘›>0
{RA} ğ‘›=0
The operatorâŠ—refines the original analysis rules RAby adding
more syntactic features from the grammar rules RG. We elaborate
the details ofâŠ—in the following section.
4.2 Rule Refinement
Consider an analysis rule ğ‘Ÿand a grammar rule ğ‘ŸG. We first define
ğ‘ŸâŠ—ğ‘ŸGas the extensions of the analysis rule ğ‘Ÿwith structure from
ğ‘ŸG. As an example, consider the rules:
ğ‘Ÿ:DUPath(ğ‘1,ğ‘3):âˆ’DUPath(ğ‘1,ğ‘2),DUEdge(ğ‘2,ğ‘3).
ğ‘ŸG:Cmd(ğ‘):âˆ’Loop(ğ‘).
In this case, ğ‘ŸâŠ—ğ‘ŸGis defined as{ğ‘Ÿ1,ğ‘Ÿ2}where
ğ‘Ÿ1:DUPath(ğ‘1,ğ‘3):âˆ’DUPath(ğ‘1,ğ‘2),Loop(ğ‘2),DUEdge(ğ‘2,ğ‘3).(8)
ğ‘Ÿ2:DUPath(ğ‘1,ğ‘3):âˆ’DUPath(ğ‘1,ğ‘2),!Loop(ğ‘2),DUEdge(ğ‘2,ğ‘3).(9)
The ruleğ‘Ÿ1fires when all the conditions from the original anal-
ysis rule and the grammar rule are satisfied. The rule ğ‘Ÿ2covers
the complement of ğ‘Ÿ1so that all the output tuples derived by the
original rule ğ‘Ÿare also derived by ğ‘Ÿ1andğ‘Ÿ2, and vice versa. The
rule probabilities of the refined rules are defined as ğ‘ğ‘Ÿ1=ğ‘ğ‘ŸÃ—ğ›¼
andğ‘ğ‘Ÿ2=ğ‘ğ‘Ÿwhereğ›¼is a hyperparameter between 0and1.
We can lift the definition of ğ‘ŸâŠ—ğ‘ŸGto sets of analysis rules and
grammar rules in a natural way: RâŠ—RG. We postpone the formal
definition of these ideas to the appendix.
The following theorem states that the refinement preserves the
derivability of all output tuples from the original analysis.
Theorem 4.1 (Preservation). Consider two Datalog programs
D1=(I1,O1,R1)andD2=(I2,O2,R2). For any set ğ¼of input facts,
âˆ€ğ‘›â‰¥0.tupleğ‘¡is derivable fromD1â‡â‡’ğ‘¡is derivable fromD
whereD=(I1âŠI2âŠO2,O1,R)andRâˆˆ(R1âŠ—ğ‘›R2).Algorithm 1: BayeSmith(T,DA,DG), whereTis a set
of training programs, DA=(IA,OA,RA)is a program
analysis andDG=(IG,OG,RG)is a feature extractor.
1LetI=IAâˆªIGâˆªOG;
2Initialize Râ†RAandâŸ¨Cost,FGâŸ©â† Run T,I,OA,RA;
3repeat
4 for(ğº,ğ‘ğ‘“,ğ‘ğ‘¡)âˆˆğ¹ğºdo
5 for(ğ‘Ÿ,ğ‘ŸG)âˆˆCandidate(ğº,ğ‘ğ‘“,ğ‘ğ‘¡)do
6 Rğ‘›ğ‘’ğ‘¤â†(R\{ğ‘Ÿ})âˆª(ğ‘ŸâŠ—ğ‘ŸG);
7âŸ¨Costâ€²,FGâ€²âŸ©â† Run T,I,OA,Rğ‘›ğ‘’ğ‘¤;
8 ifImproved(Cost,Costâ€²)then
9 Râ†Rğ‘›ğ‘’ğ‘¤;
10 âŸ¨Cost,FGâŸ©â†âŸ¨Costâ€²,FGâ€²âŸ©;
11 goto 12
12until FG=âˆ…or timeout ;
13return R;
4.3 Learning Algorithm
This section describes an algorithm that approximately solves the
optimization problem (7) by refining rules from a set of training
programs with bug labels. Ideally, the problem can be solved by
maximizing true generalization and minimizing false generaliza-
tion. However, it is intractable to find a global optimum because of
the huge search space and non-trivial computational cost of prob-
abilistic inference. Instead, our algorithm tries to solve the latter
only using a greedy method.
The main idea is to observe false generalization as feedback and
refine rules to reduce the effect. Algorithm 1 shows the refinement
process of BayeSmith. Initially, the algorithm starts with the set
of rules of the program analysis (line 2). Given a set of training
programsT,BayeSmith first runs the Bayesian alarm ranking
system for all training programs and simulates user interactions.
Then we evaluate the quality by computing the number of user
interactions until discovering all the true alarms (ğ¶ğ‘œğ‘ ğ‘¡). The details
of the algorithm will be described in the rest of this section.
BayeSmith observes all false generalizations (ğ¹ğº)during the
simulation. For each observed false generalization, BayeSmith re-
peatedly refines the current rules to eliminate the false general-
izations within the time budget or until there is no more false
generalization (line 4). A false generalization is a tuple (ğº,ğ‘ğ‘“,ğ‘ğ‘¡)
that represents that the negative label on the false alarm ğ‘ğ‘“de-
grades the ranking number of the true alarm ğ‘ğ‘¡in the next ranking.
We define the height of a false generalization as the difference be-
tween the rankings of true alarms before and after the negative
label. In our implementation, we iterate through the candidates in
descending order of height.
Once a false generalization is observed, we collect candidate
nodes to be refined in the Bayesian network (line 5). Given false
generalization(ğº,ğ‘ğ‘“,ğ‘ğ‘¡), we first find the lowest common ancestor
ğ‘¡ğ‘ofğ‘ğ‘¡andğ‘ğ‘“. Then all grounded clauses on the path from ğ‘¡ğ‘toğ‘ğ‘“
inğºare the refinement candidate nodes in the Bayesian network.
The set of refinement candidates Candidate(ğº,ğ‘ğ‘“,ğ‘ğ‘¡)is formally
defined as follows:
{(ğ‘Ÿ,ğ‘ŸG)âˆˆRÃ—RG|ğ‘”ğ‘is on the path from ğ‘¡ğ‘toğ‘ğ‘“inğºand
âˆƒ0â‰¤ğ‘˜â‰¤ğ‘.ğ‘…ğ‘˜(ğ‘ğ‘˜)is derived byDGusing ruleğ‘ŸG}
1287
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning Probabilistic Models for Static Analysis Alarms ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 1: Benchmark characteristics.
Program KLOC #Bugs Bug Type Reference
gzip-1.2.4a 9 14 Buffer overrun [14]
fribidi-1.0.7 13 1 Buffer overrun [34]
bc-1.06 14 2 Buffer overrun [14]
cflow-1.5 40 1 Buffer overrun [33]
patch-2.7.1 51 1 Buffer overrun [27]
wget-1.12 65 6 Buffer overrun [41, 42]
readelf-2.24 65 1 Buffer overrun [31]
grep-2.19 68 1 Buffer overrun [25]
sed-4.3 83 1 Buffer overrun [9]
sort-7.2 98 1 Buffer overrun [7]
tar-1.28 112 1 Buffer overrun [24]
jhead-3.0.0 5 2 Integer overflow [32]
shntool-3.0.5 13 6 Integer overflow [14]
autotrace-0.31.1 18 18 Integer overflow [30]
sam2p-0.49.4 22 12 Integer overflow [28]
sdop-0.61 23 65 Format string [31]
latex2rtf-2.1.1 27 2 Integer overflow [29]
urjtag-0.8 46 6 Format string [26]
optipng-0.5.3 61 1 Integer overflow [14]
a2ps-4.14 64 6 Format string [14]
whereğ‘”ğ‘=â€œÃ“ğ‘
ğ‘–=0ğ‘…ğ‘–(ğ‘ğ‘–)=â‡’ğ‘Ÿğ‘…â„(ğ‘â„)â€andğ‘…ğ‘˜âˆˆOG.
For each candidate, BayeSmith refines the selected rule using the
refinement operator defined in Section 4.2 (line 6). The quality of the
rules are examined by simulating user interaction with the newly
learned alarm ranking system (line 7). For evaluation, we check (line
8) (1) whether the total number of user interactions for all training
programs decreases, and (2) whether the number of improved cases
is larger than that of hindered cases. While the first condition
generally specifies the ultimate goal, the second one is checked
to avoid overfitting by a few dominating programs that have a
large number of alarms. If the conditions are satisfied, BayeSmith
repeats the process with the newly learned rules. Otherwise, other
candidates of rules or false generalization are selected.
Example 4.2. Consider the Bayesian network in Figure 2(b). Given
the false alarm Alarm(7)and the true alarm Alarm(10), the lowest
common ancestor is DUPath(5,6).BayeSmith collects all grounded
clauses on the path from DUPath(5,6)toAlarm(7):{ğ‘Ÿ2(5,6,7),ğ‘Ÿ3(5,7)}.
Then the algorithm searches for a grammar rule that derives a tuple
whose argument is 5, 6 or 7. If there exists a rule ğ‘ŸG:Cmd(ğ‘):âˆ’
Loop(ğ‘)that derives Cmd(6), the pair(ğ‘Ÿ2,ğ‘ŸG)is selected as a can-
didate. In this case, the algorithm refines the rule and produces two
new rules (8) and (9) in Section 4.2. Tables ??â€“??in Appendix ??
provide additional examples of refined rules learned by BayeSmith.
5 EXPERIMENTAL EVALUATION
We designed experiments to answer the following questions:
(1) How effective are the learned probabilistic models?
(2)Does BayeSmith reduce the frequency and magnitude of false
generalizations?
(3) How robust is BayeSmith with different training data?
(4) How scalable are the learned ranking systems?5.1 Setting
We conducted all experiments on Linux machines with Intel Xeon
2.2GHz. We performed Bayesian inference using libDAI [ 35] and
set a timeout of 24 hours for learning.
Instance analyses. We have implemented BayeSmith on top of
Sparrow, a static analysis framework for C programs [ 37]. We
used two instance analyses in Sparrow: an interval analysis for
buffer-overrun errors, and a taint analysis for format-string and
integer-overflow errors. The taint analysis detects whether mali-
cious format strings and overflowed integers are used as arguments
ofprintf -like and malloc -like functions, respectively. We used
the same mechanism as in the previous work [ 5,15] to extract
def-use relations from analysis results of Sparrow following the
sparse analysis framework [ 36]. For the grammar rules, we used
the C-like grammar (as in Section 2) that describes program syntax
and alarm expressions in Sparrow.
Baselines. We apply probabilistic models learned by BayeSmith
for three state-of-the-art probabilistic program reasoning systems
each of which prioritizes alarms based on the feedback from user [ 39],
the old version of the program [ 15], and dynamic analysis [ 5], re-
spectively. All three baselines are based on probabilistic models
derived from the same set of hand-written rules. We compare the
performance of the learned models for each system.
Benchmarks. We evaluated BayeSmith on a suite of widely used
C programs in Table 1. The benchmarks are collected from previous
work applying Sparrow [5,14,15] and recent CVE reports. We
excluded too small programs whose sizes are less than 5KLOC and
alarm inspection requires less than 5 user interactions with Bingo.
Learning configuration. By default, we evaluated the performance
ofBayeSmith using the leave-one-out cross-validation for each
instance analysis and set the hyper-parameter ğ›¼in Section 4.2 to
0.99. Our leave-one-out cross-validation measures the number of
user interactions for each individual program using a Bayesian
network learned from the other programs. For example, we used 10
programs for training and the remaining one program for the test,
in the case of the interval analysis. Because each analysis is based
on the different abstract domains and semantics, we separated the
learning processes per analysis.
5.2 Effectiveness of Probabilistic Models
5.2.1 User-guided Alarm Prioritization. We evaluate the effective-
ness of the learned models for user-guided alarm prioritization com-
pared to three baselines: Bingoğ‘€,Bingoğ¸ğ‘€, and Bingoğ‘ˆ.Bingoğ‘€
derives Bayesian networks using the initial set of rules and the rule
probabilities are assigned with a heuristically chosen value (0.99) as
in the previous work [ 15].Bingoğ¸ğ‘€constructs the same Bayesian
networks as Bingoğ‘€but the rule weights are learned by an algo-
rithm presented in the previous work [ 39]. The algorithm learns
the best rule probabilities that explain the bug labels based on the
standard EM algorithm. We ran Bingoğ¸ğ‘€five times for each bench-
mark and report the average. Bingoğ‘ˆuses a refined set of rules
that are derived by uniformly unrolling all the components of the
original set of rules by once. We measure the number of user in-
teractions to discover all true bugs in the data. The experimental
results are shown in Table 2.
1288
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Hyunsu Kim, Mukund Raghothaman, and Kihong Heo
Table 2: Effectiveness of BayeSmith in user-guided alarm
prioritization for the interval (top) and taint (bottom) anal-
ysis. #Alarms reports the number of alarms. Each column
reports the number of iterations until discovering all bugs.
Program #Alarms Bingoğ‘€Bingoğ¸ğ‘€Bingoğ‘ˆBayeSmith
gzip-1.2.4a 358 145 325 188 107
fribidi-1.0.7 213 6 2 5 3
bc-1.06 535 96 100 97 94
cflow-1.5 805 94 94 91 60
patch-2.7.1 502 36 47 30 34
wget-1.12 891 193 138 179 90
readelf-2.24 882 78 25 81 18
grep-2.19 912 53 286 59 53
sed-4.3 819 122 144 127 121
sort-7.2 715 176 160 178 94
tar-1.28 1,369 218 308 205 146
Total 8,001 1,217 1,628 1,240 820
jhead-3.0.0 19 7 12 7 4
shntool-3.0.5 23 14 19 15 10
autotrace-0.31.1 77 77 71 77 43
sam2p-0.49.4 20 20 20 20 20
sdop-0.61 150 85 81 81 81
latex2rtf-2.1.1 13 6 9 6 6
urjtag-0.8 35 22 24 22 17
optipng-0.5.3 67 14 16 13 12
a2ps-4.14 27 15 13 14 11
Total 431 260 264 255 204
The weight learning performed by Bingoğ¸ğ‘€is not effective in
most cases, and only improves the ranking quality for 7 out of
20 programs compared to Bingoğ‘€. For some cases such as grep-
2.19andgzip-1.2.4a, the number of interactions even significantly
increases. This result is mainly because of two reasons. First, the
labeling is extremely sparse in our setting. For example, we only
have tens of bug labels for the interval analysis while the networks
have 2Kâ€“12K nodes. This hinders the converge of the algorithm
within 12 hours that leads to poor performance. The other reason
is that the networks have simplistic structures derived by the small
and monolithic set of rules, that hinders to learn general knowledge
for detailed contexts.
The results also show that the uniform rule refinement does not
improve the quality of the ranking system. In the interval analysis,
Bingoğ‘ˆoutperforms Bingoğ‘€for 5 benchmarks but increases the
number of interactions by 1.9% for all benchmarks, on average. Sim-
ilarly, Bingoğ‘ˆimproves only 1.9% in the taint analysis compared to
Bingoğ‘€. Overall, the uniformly unrolled rule does not effectively
solve the false generalization problem according to our results. This
is mainly because the unguided refinement can reduce not only
false generalizations but also true generalizations, thereby degrad-
ing the overall performance. Furthermore, one-step refinements
are sometimes not enough to remove false generalizations.
On the other hand, the learned ranking systems substantially
reduce the amount of alarm inspection burden. BayeSmith out-
performs Bingoğ‘€for 17 out of 20 programs, and reduces the total
number of user interactions by 32.6% and 21.5% for the interval and
taint analysis, respectively. For the remaining 3 cases, BayeSmith
wgetreadelfgrepsedsort tar
optipngshntoollatex2rtfurjtagavg.020406080100120140# InteractionsDrake
BayeSmith(a)Drake, 54.3%â†“
bccï¬‚owgrepgzippatchreadelfsedsorttar
optipnglatex2rtfshntoolavg.050100150200# InteractionsDynaBoost
BayeSmith (b)Dynaboost, 20.4% â†“
Figure 6: Improvement in ranking performance enabled by
BayeSmith
shows the same results compared to Bingoğ‘€. This is mainly be-
cause the underlying analyzer already reports a low false positive
ratio (e.g., latex2rtf-2.1.1) or Bingoğ‘€already significantly reduces
alarm inspection burden (e.g., grep-2.19).
5.2.2 Application to Other Systems. We evaluate the effectiveness
of learned models with two other probabilistic reasoning systems
using Bayesian networks: Drake andDynaboost. Drake boot-
straps the probabilistic alarm ranking system using the old version
of the program and prioritizes alarms for the new version by the
relevance to the difference [ 15].Dynaboost incorporates observed
dataflow facts from dynamic analysis into the alarm ranking sys-
tem [ 5]. As in the prior work, both of the baselines use the same set
of rules as Bingoğ‘€in the previous section. Likewise, We measure
the number of interactions after each bootstrapping until discover-
ing all the bugs. Since they require old versions and test cases, we
selected benchmark programs only used in the previous work.
Overall, the learned models significantly improve the perfor-
mance of the probabilistic reasoning systems. Figure 6(a) shows
the number of user interactions on top of the alarm ranking by
the relevance. In comparison to the vanilla versions of Drake, the
alarm inspection burden with the learned models is reduced by
54.3%, on average. One exceptional case is grep-2.19 where the
baseline already significantly reduces the number of interactions
to only 8 to discover the bug. While the learned rules show a small
regression, the absolute number of user interactions is still small
enough (13) for the user inspection. Figure 6(b) also demonstrates
the impact on the ranking system incorporating dynamic analysis.
The learned models reduce the number of interactions for 8 out
of 12 programs for Dynaboost and the user inspection burden is
reduced by 20.4%, on average.
5.2.3 Learned Insights. The learned rules capture important as-
pects of each analysis. Regardless of the instance analysis, Baye-
Smith commonly captures the insight that loop head is an impor-
tant feature since loops are often the main source of inaccuracy
because of join or widening. Another insight is that library calls also
increase uncertainty of static analysis results because their seman-
tics is complicated and the source code is unavailable. BayeSmith
not only discovers these general insights in static analysis, but also
fine-tunes the rules with multiple conjunctions and disjunctions,
which can require non-trivial manual efforts3:
DUPath(ğ‘£0,ğ‘£1):âˆ’...,Loop(ğ‘£2),Assign(ğ‘£2,_). : 0.97
DUPath(ğ‘£0,ğ‘£1):âˆ’...,LibCall(ğ‘£2,ğ‘£3),Lval(ğ‘£3,_).: 0.97
3For brevity, we omit negated tuples and boilerplate parts in the rule bodies.
1289
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning Probabilistic Models for Static Analysis Alarms ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
0 50 100 150
# Interactions0100200300400500Rank
BayeSmith
Bingosort
0 20 40 60 80
# Interactions0100200300400500Rank
BayeSmith
Bingocflow
0 20 40 60
# Interactions0255075100125150175Rank
BayeSmith
Bingoreadelf
0 20 40 60
# Interactions20040060080010001200Rank
BayeSmith
Bingoautotrace
Figure 7: Comparison of the ranking performance. Each data
point represents the sum of the rankings of all bugs.
BayeSmith also captures analysis-specific features. For the inter-
val analysis, it is usually harder to estimate buffer overflow errors
when arithmetic operators are involved in branch conditions or
buffer accesses. Also the learned rules capture the general knowl-
edge that analyzing pointer dereferences or complicated libraries
such asstrncpy is more tricky compared to array index expressions.
These insights are captured by the following rules and weights:
DUPath(ğ‘£0,ğ‘£1):âˆ’...,Assume(ğ‘£2,ğ‘£3),BinOp(ğ‘£3,_,_,_). : 0.97
Alarm(ğ‘£1):âˆ’...,DerefExp(ğ‘£1,ğ‘£2),BinOp(ğ‘£2,_,_). : 0.97
Alarm(ğ‘£1):âˆ’...,Strncpy(ğ‘£1,ğ‘£2,ğ‘£3),Cast(ğ‘£2,_),Cast(ğ‘£3,_).: 0.96
For the taint analysis, arithmetic operators such as multiplication
and casting operators are captured by BayeSmith, which are the
main sources of imprecision for integer overflow detection:
Alarm(ğ‘£1):âˆ’...,MallocSize(ğ‘£1,ğ‘£2),CastExp(ğ‘£2,ğ‘£3),Lval(ğ‘£3,_). : 0.96
Alarm(ğ‘£1):âˆ’...,MallocSize(ğ‘£1,ğ‘£2),BinOp(ğ‘£2,ğ‘£3,_,_),Mult(ğ‘£3).: 0.96
5.3 Reduction of False Generalization
BayeSmith achieves its effectiveness by reducing false generaliza-
tions. We justify this argument by measuring the frequency and
magnitude of false generalizations. Table 3 shows the number of
false generalizations and their average magnitudes by Bingoğ‘€and
BayeSmith. We measured the magnitude of false generalization in
each round as the sum of decreased amount in ranking per true
alarm. The numbers are the average throughout the whole inter-
action rounds. The overall changes in the ranks of true alarms are
shown in Figure 7. Each graph describes the rankings of true alarms
for each iteration.
We categorize the results into three notable cases. First, in most
of the cases, BayeSmith reduces the number of false generaliza-
tions and magnitudes and leads to the performance improvement
of their rankings such as sort-7.2 andcflow-1.5. Second, the learned
Bayesian networks improve the quality of ranking systems in terms
of not only generalization but also initial ranking. For example,
the initial ranking of the bug in readelf-2.24 is improved from 181
to 28, and hence the reduced number of total interactions. This
means that the learned probabilistic models estimate the behaviorTable 3: Reduction of false generalizations. Freq and Mag
report the number of false generalizations and their average
magnitude for the interval (top) and taint (bottom) analysis.
Bingoğ‘€ BayeSmith
Program Freq Mag Freq Ã—Mag Freq Mag Freq Ã—Mag
gzip-1.2.4a 191 15.4 2931.9 130 16.0 2080.0
fribidi-1.0.7 2 2.0 4.0 0 0.0 0.0
bc-1.06 11 121.6 1337.9 7 55.3 387.0
cflow-1.5 7 22.1 155.0 5 21.6 108.0
patch-2.7.1 4 26.0 104.0 3 1.3 3.9
wget-1.12 125 86.7 10842.5 40 59.7 2388.0
readelf-2.24 6 8.8 53.0 1 1.0 1.0
grep-2.19 0 0.0 0.0 0 0.0 0.0
sed-4.3 5 51.0 255.0 8 57.1 457.0
sort-7.2 7 73.0 511.0 3 13.0 39.0
tar-1.28 27 19.4 523.0 26 7.8 201.8
Average 35 38.7 1355.6 20 21.2 429.0
jhead-3.0.0 0 0.0 0.0 0 0.0 0.0
shntool-3.0.5 9 1.0 9.0 10 1.3 13.0
autotrace-0.31.1 194 12.1 2341.6 251 11.7 2941.7
sam2p-0.49.4 79 3.5 279.7 73 3.8 276.7
sdop-0.61 1552 5.5 8582.6 1834 3.3 6015.5
latex2rtf-2.1.1 0 0.0 0.0 0 0.0 0.0
urjtag-0.8 6 11.0 66.0 0 0.0 0.0
optipng-0.5.3 3 21.7 65.0 3 12.7 38.0
a2ps-4.14 8 4.1 33.0 6 3.2 19.0
Average 206 6.5 1346.5 242 4.0 965.1
of programs and static analyses with more accurate prior probabil-
ities. Third, the learned ranking systems sometimes report more
false generalizations such as autotrace-0.31.1. However, notice that
Bingoğ‘€exhaustively inspects all the alarms to discover the true
alarms. The rankings of the true alarms are consistently low and
all the 18 bugs are discovered in the last 18 iterations, hence less
number of false generalizations. On the other hand, the first true
alarm is discovered only after 18 iterations with BayeSmith that
improves the rankings of the other true alarms. This effect makes a
high chance of introducing false generalizations, but significantly
improves the overall rankings.
In summary, the learned rules by BayeSmith reduce the negative
effect by false generalizations. For the interval analysis, BayeSmith
reduces the average frequency and magnitude of false generaliza-
tions by 42.9% and 45.2%, respectively. For the taint analysis, the
average magnitude is reduced by 38.5%. The average number of
false generalizations increases because of the exceptional cases, but
even for such cases, the quality of overall ranking improves. In
terms of overall impact ( FreqÃ—Mag ),BayeSmith shows 68.4% and
28.3% of improvement, respectively.
5.4 Robustness of the Learning Algorithm
In order to measure how data splitting affects the quality of learned
models, we evaluate the performance of BayeSmith with differ-
ent quantities of training and testing data. For each analysis, we
randomly chose 80% of the benchmark programs as a training set
and the remaining 20% as a test set. We repeated this process ten
times and report the averages. We measure the total number of
1290
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Hyunsu Kim, Mukund Raghothaman, and Kihong Heo
Table 4: Statistics of user interactions using the alarm rank-
ing systems learned with different training set.
BayeSmith 90 BayeSmith 80
Program Avg. Stddev. Avg. Stddev.
Interval 65.0 40.7 65.2 41.0
Taint 18.8 23.0 19.0 22.9
iterations for each test set ( BayeSmith 80) compared to that of the
leave-one-out setting that is the same as Section 5.2 ( BayeSmith 90).
Table 4 shows the performance of BayeSmith with 10 different
combinations of training and test sets. On average, BayeSmith 80
reduces the number of user interactions by 34.3% for the interval
analysis and 18.8% for the taint analysis. Compared to BayeSmith 90,
BayeSmith 80shows 0.2% and 1.0% less improvement for each of
the analysis task. In total, the results are comparable to those with
BayeSmith 90in Section 5.2 that shows the learning algorithm is
robust with different training data.
5.5 Scalability
The computational overhead of Bayesian inference typically in-
creases as the size of Bayesian network grows because of the refine-
ments by BayeSmith. We measure the size of Bayesian networks in
terms of the number of tuples and grounded clauses in derivation
trees and the average running time for each Bayesian inference. The
Bayesian networks are optimized using optimization algorithms
described in the previous work [39].
Table 5 shows the average size and response time. Bingo uses a
monolithic set of 7 rules while BayeSmith derives 25 and 13 rules
on average for each analysis. On average, the synthesized networks
have 1.4x more nodes for the interval analysis and 1.1x for nodes
for the taint analysis, compared to the baseline. As the networks
become larger, the average running time also increases by 5.1x
and 2.6x, respectively. In most cases, it only requires less than 10
seconds. Even for some exceptional cases such as readelf-2.24, the
average response time is about a minute, which is reasonable for
real world deployment.
6 LIMITATIONS AND OPPORTUNITIES
This section identifies the limitations of our approach and chal-
lenges for future work. First, BayeSmith requires background
knowledge in the form of existing analysis rules. We demonstrated
a set of rules for def-use relations based on the sparse analysis
framework [ 36] is a reasonable starting point. While def-use re-
lations are used in a large class of analyses [ 16,44,49], there can
be other analyses that require the analysis designers to derive ini-
tial rules based on different background knowledge. To address
this challenge, we plan to devise a purely data-driven synthesis
algorithm without requiring background knowledge. Second, Baye-
Smith only considers a syntax-guided refinement that might not
accurately reflect deeper semantic aspects. For future work, we plan
to develop a refinement algorithm considering the characteristics
of abstract domains and semantics. Finally, BayeSmith assumes an
ideal user interaction model where the user always gives correct
feedback on the top-ranked alarm. However, the user might make a
mistake, give partial feedback, or diagnose arbitrary alarms. Thus,developing a more advanced interaction model is also an important
future direction for our work.
7 RELATED WORK
Our approach aims to overcome the fundamental limitation of the
existing user-guided approaches. There have been several tech-
niques to improve static analysis accuracy by leveraging user feed-
back. Bayesian alarm ranking systems compute a confidence score
for each alarm and update rankings based on the user feedback [ 15,
39]. Alarm clustering computes logical correlations between alarms
so that a set of alarms are logically grouped together [ 21,22], such
that each alarm group is resolved by inspecting a single represen-
tative alarm. Alarm classification techniques ask questions about
labels or root causes of alarms to classify analysis reports by solving
optimization problems [ 23,50]. None of the existing approaches
learn detailed knowledge from an analysis for one program to that
for other programs. Instead, we provide a learning framework for
probabilistic models and outperform the existing approaches.
Recently, many techniques for synthesizing Datalog programs
have been proposed [ 3,40,45,46], but their goal is different from
BayeSmith. Their goal is to efficiently synthesize Datalog rules
from input-output specifications. Zaatar [3] proposes a constraint-
based synthesis by encoding the output of candidate Datalog pro-
grams as SMT constraints. Alps [45] leverages a search space prun-
ing technique for efficient enumerative synthesis. Difflog and
ProSynth employ provenance information combined with contin-
uous optimization [ 46] and SAT solving [ 40]. One notable difference
is that Datalog programs are typically interpreted over a Boolean
semiring, where each tuple is either derived or not, while our focus
in alarm prioritization is to rank alarms in order of confidence, so
each tuple is additionally associated with a real-valued score.
Existing structure learning techniques that have been developed
by the machine learning community [ 11,43,48] are not applicable to
our problem. The goal of structure learning algorithms for Bayesian
networks and Markov Logic Networks has been to find a model
with a high likelihood on the observed data. In contrast, BayeSmith
finds a refinement of an existing model, which is tightly coupled
with the underlying static analysis, while preserving the derivability
of the original set of alarms (Theorem 4.1). Furthermore, conven-
tional structure learning algorithms have limited scalability since
they typically learn rules from scratch. The standard approaches to
structure learning typically require complete data (i.e., labels for
all random variables). However, this assumption is unrealistic for
our problem since it is hard to obtain labels for all intermediate
results of static analysis. Although several techniques [ 2,8] can
learn structures from incomplete data, they are only applicable to
small datasets with up to a few dozen random variables, while our
benchmarks, on average, have more than 1K variables (Table 5).
There is a large body of research for automatically learning
heuristics for static analysis [ 4,10,12â€“14,17â€“19,38,47]. The exist-
ing approaches use various learning techniques to derive heuris-
tics for controlling context-sensitivity [ 17,19], variable relation-
ship [ 10,12,47], resource management [ 13], and unsoundness [ 14].
While all these approaches rely on handcrafted features, our ap-
proach learns syntactic features that are directly derived from the
grammar of the target language. Jeon et al . [18] automatically learns
1291
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning Probabilistic Models for Static Analysis Alarms ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 5: Scalability of our learning approach. #T and #C are
the average number of tuples and clauses of the networks. #R
indicates the number of rules to construct a network. Time
is the average duration of Bayesian inference.
Bingo BayeSmith
Program #T #C Time (s) #R #T #C Time (s)
Interval 3,053 3,385 2.9 25 4,414 4,746 14.9
Taint 422 541 1.2 13 475 595 3.0
graph-based heuristics without manual features, but their approach
is specialized for pointer analysis. Chae et al . [4] automatically
generates features from program syntax. They represent features
as small programs that concisely capture the behavior of static
analysis with flow-sensitivity or relational domain. However, these
approaches are not directly applicable to learning Bayesian net-
works for alarm ranking systems.
8 CONCLUSION
We presented BayeSmith, a general learning framework for Bayesian
alarm ranking systems. BayeSmith fundamentally improves the
quality of user-guided program reasoning systems by learning the
structure of the underlying probabilistic model. BayeSmith learns
accurate Bayesian networks by minimizing the effect of false gen-
eralizations observed from simulated user interactions with labeled
data. In the experiments with two instance analyses, we demon-
strated the effectiveness of learned rules and significant improve-
ment in terms of the userâ€™s alarm inspection burden.
ACKNOWLEDGMENTS
This work was partly supported by the National Research Founda-
tion of Korea(NRF) grant funded by the Korea government(MSIT)(No.
2021R1A5A1021944, 2021R1C1C1003876) and Institute for Informa-
tion & Communications Technology Planning & Evaluation (IITP)
grant funded by the Korea government(MSIT) (No. 2021-0-00758,
Development of Automated Program Repair Technology by Com-
bining Code Analysis and Mining). Raghothaman was supported
by U.S. NSF Grant CCF #2107261.
REFERENCES
[1]Serge Abiteboul, Richard Hull, and Victor Vianu. 1994. Foundations of Databases:
The Logical Level (1st ed.). Pearson.
[2]Tameem Adel and Cassio P. de Campos. 2017. Learning Bayesian Networks
with Incomplete Data by Augmentation. In Proceedings of the Thirty-First AAAI
Conference on Artificial Intelligence. AAAI Press, 1684â€“1690.
[3]Aws Albarghouthi, Paraschos Koutris, Mayur Naik, and Calvin Smith. 2017.
Constraint-Based Synthesis of Datalog Programs. In Principles and Practice of
Constraint Programming - 23rd International Conference, CP 2017, Vol. 10416.
Springer, 689â€“706.
[4]Kwonsoo Chae, Hakjoo Oh, Kihong Heo, and Hongseok Yang. 2017. Automatically
generating features for learning program analysis heuristics for C-like languages.
Proc. ACM Program. Lang. 1, OOPSLA (2017), 101:1â€“101:25.
[5]Tianyi Chen, Kihong Heo, and Mukund Raghothaman. 2021. Boosting Static
Analysis Accuracy with Instrumented Test Executions. In Proceedings of theThe
ACM Joint European Software Engineering Conference and Symposium on the
Foundations of Software Engineering (FSE 2021).
[6]Patrick Cousot and Radhia Cousot. 1992. Abstract Interpretation Frameworks. J.
Log. Comput. (1992).
[7]Paul Eggert. 2010. sort : Commit 14ad7a2 . http://git.savannah.gnu.org/cgit/
coreutils.git/commit/?id=14ad7a2. sort : Fix very-unlikely buffer overrun when
merging to input file.
[8]Nir Friedman. 1998. The Bayesian Structural EM Algorithm. In UAI â€™98: Proceed-
ings of the Fourteenth Conference on Uncertainty in Artificial Intelligence. 129â€“138.[9]Assaf Gordon. 2018. sed: Commit 007a417 . http://git.savannah.gnu.org/cgit/
sed.git/commit/?id=007a417. sed: Fix heap buffer overflow from multiline EOL
regex optimization.
[10] Jingxuan He, Gagandeep Singh, Markus PÃ¼schel, and Martin T. Vechev. 2020.
Learning fast and precise numerical analysis. In Proceedings of the 41st ACM
SIGPLAN International Conference on Programming Language Design and Imple-
mentation, PLDI. ACM, 1112â€“1127.
[11] David Heckerman, Dan Geiger, and David Maxwell Chickering. 1995. Learning
Bayesian Networks: The Combination of Knowledge and Statistical Data. Mach.
Learn. 20, 3 (1995), 197â€“243.
[12] Kihong Heo, Hakjoo Oh, and Hongseok Yang. 2016. Learning a Variable-
Clustering Strategy for Octagon from Labeled Data Generated by a Static Analysis.
InStatic Analysis - 23rd International Symposium, SAS (Lecture Notes in Computer
Science, Vol. 9837). Springer, 237â€“256.
[13] Kihong Heo, Hakjoo Oh, and Hongseok Yang. 2019. Resource-aware program
analysis via online abstraction coarsening. In Proceedings of the 41st International
Conference on Software Engineering, ICSE 2019. IEEE / ACM, 94â€“104.
[14] Kihong Heo, Hakjoo Oh, and Kwangkeun Yi. 2017. Machine-learning-guided
Selectively Unsound Static Analysis. In Proceedings of the 39th International
Conference on Software Engineering (ICSE 2017). IEEE Press, 519â€“529.
[15] Kihong Heo, Mukund Raghothaman, Xujie Si, and Mayur Naik. 2019. Con-
tinuously reasoning about programs using differential Bayesian inference. In
Proceedings of the 40th ACM SIGPLAN Conference on Programming Language
Design and Implementation (PLDI 2019). ACM, 561â€“575.
[16] Simon Holm Jensen, Anders MÃ¸ller, and Peter Thiemann. 2009. Type Analysis
for JavaScript. In Static Analysis. Springer, 238â€“255.
[17] Minseok Jeon, Sehun Jeong, and Hakjoo Oh. 2018. Precise and scalable points-to
analysis via data-driven context tunneling. Proc. ACM Program. Lang. 2, OOPSLA
(2018), 140:1â€“140:29.
[18] Minseok Jeon, Myungho Lee, and Hakjoo Oh. 2020. Learning Graph-Based Heuris-
tics for Pointer Analysis without Handcrafting Application-Specific Features.
Proc. ACM Program. Lang. 4, OOPSLA, Article 179 (2020).
[19] Sehun Jeong, Minseok Jeon, Sung Deok Cha, and Hakjoo Oh. 2017. Data-driven
context-sensitivity for points-to analysis. Proc. ACM Program. Lang. 1, OOPSLA
(2017), 100:1â€“100:28.
[20] Daphne Koller and Nir Friedman. 2009. Probabilistic graphical models: Principles
and techniques. The MIT Press.
[21] Wei Le and Mary Lou Soffa. 2010. Path-based fault correlations. In Proceedings
of the 18th ACM SIGSOFT International Symposium on Foundations of Software
Engineering (FSE 2010). ACM, 307â€“316.
[22] Woosuk Lee, Wonchan Lee, Dongok Kang, Kihong Heo, Hakjoo Oh, and
Kwangkeun Yi. 2017. Sound Non-Statistical Clustering of Static Analysis Alarms.
ACM Trans. Program. Lang. Syst. 39, 4 (2017), 16:1â€“16:35.
[23] Ravi Mangal, Xin Zhang, Aditya Nori, and Mayur Naik. 2015. A user-guided
approach to program analysis. In Proceedings of the 10th Joint Meeting on Foun-
dations of Software Engineering (ESEC/FSE 2015). ACM, 462â€“473.
[24] Jim Meyering. 2018. tar: Commit b531801 . http://git.savannah.gnu.org/cgit/tar.
git/commit/?id=b531801. One-top-level: Avoid a heap-buffer-overflow.
[25] MITRE. 2015. CVE-2015-1345. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2015-1345.
[26] MITRE. 2015. CVE-2015-8106. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2015-8106.
[27] MITRE. 2016. CVE-2016-10713. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2016-10713.
[28] MITRE. 2017. CVE-2017-16663. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2017-16663.
[29] MITRE. 2017. CVE-2017-16938. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2017-16938.
[30] MITRE. 2017. CVE-2017-9181. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2017-9181.
[31] MITRE. 2018. CVE-2018-10372. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2018-10372.
[32] MITRE. 2018. CVE-2018-6612. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2018-6612.
[33] MITRE. 2019. CVE-2019-16166. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2019-16166.
[34] MITRE. 2019. CVE-2019-18397. https://cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2019-18397.
[35] Joris Mooij. 2010. libDAI: A Free and Open Source C++ Library for Discrete
Approximate Inference in Graphical Models. Journal of Machine Learning Research
11 (Aug. 2010), 2169â€“2173.
[36] Hakjoo Oh, Kihong Heo, Wonchan Lee, Woosuk Lee, and Kwangkeun Yi. 2012.
Design and Implementation of Sparse Global Analyses for C-like Languages. In
Proceedings of the Conference on Programming Language Design and Implementa-
tion (PLDI 2012). ACM, 229â€“238.
[37] Hakjoo Oh, Kihong Heo, Wonchan Lee, Woosuk Lee, and Kwangkeun Yi. 2012.
TheSparrow static analyzer. https://github.com/ropas/sparrow.
1292
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Hyunsu Kim, Mukund Raghothaman, and Kihong Heo
[38] Hakjoo Oh, Hongseok Yang, and Kwangkeun Yi. 2015. Learning a strategy for
adapting a program analysis via bayesian optimisation. In Proceedings of the
2015 ACM SIGPLAN International Conference on Object-Oriented Programming,
Systems, Languages, and Applications. ACM, 572â€“588.
[39] Mukund Raghothaman, Sulekha Kulkarni, Kihong Heo, and Mayur Naik. 2018.
User-guided Program Reasoning Using Bayesian Inference. In Proceedings of the
39th ACM SIGPLAN Conference on Programming Language Design and Implemen-
tation (PLDI 2018). ACM, 722â€“735.
[40] Mukund Raghothaman, Jonathan Mendelson, David Zhao, Mayur Naik, and
Bernhard Scholz. 2020. Provenance-guided synthesis of Datalog programs. Proc.
ACM Program. Lang. 4, POPL (2020), 62:1â€“62:27.
[41] Tim RÃ¼hsen. 2018. wget : Commit b3ff8ce . http://git.savannah.gnu.org/cgit/
wget.git/commit/?id=b3ff8ce. src/ftp-ls.c (ftp_parse_vms_ls ): Fix heap-
buffer-overflow.
[42] Tim RÃ¼hsen. 2018. wget : Commit f0d715b . http://git.savannah.gnu.org/cgit/
wget.git/commit/?id=f0d715b. src/ftp-ls.c (ftp_parse_vms_ls ): Fix heap-
buffer-overflow.
[43] Mauro Scanagatta, Cassio P. de Campos, Giorgio Corani, and Marco Zaffalon. 2015.
Learning Bayesian Networks with Thousands of Variables. In Advances in Neural
Information Processing Systems 28: Annual Conference on Neural Information
Processing Systems 2015. 1864â€“1872.
[44] Qingkai Shi, Xiao Xiao, Rongxin Wu, Jinguo Zhou, Gang Fan, and Charles Zhang.
2018. Pinpoint: Fast and Precise Sparse Value Flow Analysis for Million Linesof Code. In Proceedings of the 39th ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI 2018). ACM, 693â€“706.
[45] Xujie Si, Woosuk Lee, Richard Zhang, Aws Albarghouthi, Paraschos Koutris, and
Mayur Naik. 2018. Syntax-guided synthesis of Datalog programs. In Proceedings
of the 2018 ACM Joint Meeting on European Software Engineering Conference and
Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2018.
ACM, 515â€“527.
[46] Xujie Si, Mukund Raghothaman, Kihong Heo, and Mayur Naik. 2019. Synthesizing
Datalog Programs using Numerical Relaxation. In Proceedings of the Twenty-
Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019. ijcai.org,
6117â€“6124.
[47] Gagandeep Singh, Markus PÃ¼schel, and Martin T. Vechev. 2018. Fast Numerical
Program Analysis with Reinforcement Learning. In Computer Aided Verification -
30th International Conference, CAV (Lecture Notes in Computer Science, Vol. 10981).
Springer, 211â€“229.
[48] Peter Spirtes, Clark Glymour, and Richard Scheines. 2000. Causation, Prediction,
and Search, Second Edition. MIT Press.
[49] Yulei Sui and Jingling Xue. 2016. SVF: Interprocedural Static Value-Flow Anal-
ysis in LLVM. In Proceedings of the 25th International Conference on Compiler
Construction (CC 2016). ACM, 265â€“266.
[50] Xin Zhang, Radu Grigore, Xujie Si, and Mayur Naik. 2017. Effective interactive
resolution of static analysis alarms. Proceedings of the ACM on Programming
Languages 1, OOPSLA, Article 57 (Oct. 2017), 30 pages.
1293
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. 