PyCG: Practical Call Graph Generation in Python
Vitalis Salis,xyThodoris Sotiropoulos,xPanos Louridas,xDiomidis Spinellisxand Dimitris Mitropoulosxz
xAthens University of Economics and Business
yNational Technical University of Athens
zNational Infrastructures for Research and Technology - GRNET
vitsalis@gmail.com, ftheosotr, louridas, dds, dimitrog@aueb.gr
Abstract ‚ÄîCall graphs play an important role in different
contexts, such as proÔ¨Åling and vulnerability propagation analysis.
Generating call graphs in an efÔ¨Åcient manner can be a challeng-
ing task when it comes to high-level languages that are modular
and incorporate dynamic features and higher-order functions.
Despite the language‚Äôs popularity, there have been very few
tools aiming to generate call graphs for Python programs. Worse,
these tools suffer from several effectiveness issues that limit their
practicality in realistic programs. We propose a pragmatic, static
approach for call graph generation in Python. We compute all
assignment relations between program identiÔ¨Åers of functions,
variables, classes, and modules through an inter-procedural
analysis. Based on these assignment relations, we produce the
resulting call graph by resolving all calls to potentially invoked
functions. Notably, the underlying analysis is designed to be
efÔ¨Åcient and scalable, handling several Python features, such as
modules, generators, function closures, and multiple inheritance.
We have evaluated our prototype implementation, which
we call PyCG, using two benchmarks: a micro-benchmark
suite containing small Python programs and a set of macro-
benchmarks with several popular real-world Python packages.
Our results indicate that PyCG can efÔ¨Åciently handle thousands
of lines of code in less than a second (0.38 seconds for 1k
LoC on average). Further, it outperforms the state-of-the-art
for Python in both precision and recall: PyCG achieves high
rates of precision 99.2%, and adequate recall 69.9%. Finally,
we demonstrate how PyCG can aid dependency impact analysis
by showcasing a potential enhancement to GitHub‚Äôs ‚Äúsecurity
advisory‚Äù notiÔ¨Åcation service using a real-world example.
Index Terms‚ÄîCall Graph, Program Analysis, Inter-procedural
Analysis, Vulnerability Propagation
I. I NTRODUCTION
A call graph depicts calling relationships between subrou-
tines in a computer program. Call graphs can be employed to
perform a variety of tasks, such as proÔ¨Åling [1], vulnerability
propagation [2], and tool-supported refactoring [3].
Generating call graphs in an efÔ¨Åcient way can be a complex
endeavor especially when it comes to high-level, dynamic pro-
gramming languages. Indeed, to create precise call graphs for
programs written in languages such as Python and JavaScript,
one must deal with several challenges including higher-
order functions, dynamic and metaprogramming features (e.g.,
eval), and modules. Addressing such challenges can play
a signiÔ¨Åcant role in the improvement of dependency impact
analysis [4]‚Äì[6], especially in the context of package managers
such as npm [7] and pip[8].
To support call graph generation in dynamic languages,
researchers have proposed different methods relying on staticanalysis. The primary aim for many implementations is com-
pleteness, i.e., facts deduced by the system are indeed true [9]‚Äì
[11]. However, for dynamic languages, completeness comes
with a performance cost. Hence, such approaches are rarely
employed in practice due to scalability issues [12]. This has
led to the emergence of practical approaches focusing on in-
complete static analysis for achieving better performance [13],
[14]. SacriÔ¨Åcing completeness is the key enabler for adopt-
ing these approaches in applications that interact with com-
plex libraries [13], or Integrated Development Environments
(IDEs) [14]. Prior work primarily targets JavaScript programs
and‚Äîamong other things‚Äîattempts to address challenges
related to events and the language‚Äôs asynchronous nature [15],
[16].
Despite Python‚Äôs popularity [17], there have been surpris-
ingly few tools aiming to generate call graphs for programs
written in the language. Pyan [18] parses the program‚Äôs Ab-
stract Syntax Tree ( AST) to extract its call graph. Nevertheless,
it has drawbacks in the way it handles the inter-procedural
Ô¨Çow of values and module imports. code2graph [19], [20]
visualizes Pyan-constructed call graphs, so it has the same
limitations. Depends [21] infers syntactical relations among
source code entities to generate call graphs. However, func-
tions assigned to variables or passed to other functions are
not handled by Depends, thus it does not perform well in the
context of a language supporting higher-order programming.
We will expand on the shortcomings of the existing tools in the
remainder of this work. That said, developing an effective and
efÔ¨Åcient call graph generator for a dynamically typed language
like Python is no minor task.
We introduce a practical approach for generating call graphs
for Python programs and implement a corresponding prototype
that we call PyCG. Our approach works in two steps. In the
Ô¨Årst step we compute the assignment graph, a structure that
shows the assignment relations among program identiÔ¨Åers.
To do so, we design a context-insensitive inter-procedural
analysis operating on a simple intermediate representation
targeted for Python. Contrary to the existing static analyzers,
our analysis is capable of handling intricate Python features,
such as higher-order functions, modules, function closures, and
multiple inheritance. In the next step, we build the call graph of
the original program using the assignment graph. SpeciÔ¨Åcally,
we utilize the graph to resolve all functions that can be
potentially pointed to by callee variables. Such a programming
pattern is particularly common in higher-order programming.
16462021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00146
Similar to previous work [14], our analysis follows a con-
servative approach, meaning that the analysis does not reason
about loops and conditionals. To make our analysis more
precise, especially when dealing with features like inheritance,
modules or programming patterns such as duck typing [22], we
distinguish attribute accesses (i.e, e:x) based on the namespace
where the attribute ( x) is deÔ¨Åned. Prior work uses a Ô¨Åeld-
based approach that correlates attributes of the same name
with a single global location without taking into account their
namespace [14]. This leads to false positives. Our design
choices make our approach achieve high rates of precision,
while remaining efÔ¨Åcient and applicable to large-scale Python
programs.
We evaluate the effectiveness of our method through a
micro- and a macro-benchmarking suite. Also, we compare
it against Pyan and Depends . Our results indicate that our
method achieves high levels of precision ( 99.2%) and ade-
quate recall (69.9%) on average, while the other analyzers
demonstrate lower rates in both measures. Our method is
able to handle medium-sized projects in less than one second
(0.38 seconds for 1k LoC on average). Finally, we show how
our method can accommodate the Ô¨Åne-grained tracking of
vulnerable dependencies through a real-world case study.
Contributions. Our work makes the following contributions.
We propose a static approach for pragmatic call graph
generation in Python. Our method performs inter-procedural
analysis on an intermediate language that records the assign-
ment relations between program identiÔ¨Åers, i.e., functions,
variables, classes and modules. Then it examines the docu-
mented associations to extract the call graph (Section III).
We develop a micro-benchmark suite that can be used as
a standard to evaluate call graph generation methods in
Python. Our suite is modular, easily extendable, and covers
a large fraction of Python‚Äôs functionality related to classes,
generators, dictionaries, and more (Section V-A1).
We evaluate the effectiveness of our approach through our
micro-benchmark and a set of macro-benchmarks including
several medium-sized Python projects. In all cases our
method achieves high rates of precision and recall, outper-
forming the other available analyzers (Sections V-B, V-C).
We demonstrate how our approach can aid dependency im-
pact analysis through a potential enhancement of GitHub‚Äôs
‚Äúsecurity advisory‚Äù notiÔ¨Åcation service (Section V-E).
Availability. PyCG is available as open-source software under
the Apache 2.0 Licence at https://github.com/vitsalis/pycg. The
research artifact is available at https://doi.org/10.5281/zenodo.
4456583.
II. B ACKGROUND
Generating precise call graphs for Python programs involves
several challenges. Existing static approaches fail to address
these challenges leaving opportunities for improvement.1import cryptops
2
3class Crypto :
4 def __init__ (self , key):
5 self .key =key
6
7 def apply (self , msg, func):
8 return func( self .key, msg)
9
10crp =Crypto( "secretkey" )
11encrypted =crp.apply( "hello world" ,
cryptops .encrypt) ,!
12decrypted =crp.apply(encrypted,
cryptops .decrypt) ,!
Fig. 1: The crypto module. Existing tools fail to generate a
corresponding call graph effectively.
A. Challenges
Higher-order Functions : In a high-level language such as
Python, functions can be assigned to variables, passed as
parameters to other functions, or serve as return values.
Nested DeÔ¨Ånitions : Function deÔ¨Ånitions can be nested,
meaning that a function can be deÔ¨Åned and invoked within
the context of another function.
Classes : As an object-oriented language, Python allows for
the creation of classes that inherit attributes and methods
from other classes. The resolution of inherited methods
from parent classes requires the computation of the Method
Resolution Order ( MRO ) of each class.
Modules : Python is highly extensible, allowing applications
to import different modules. Keeping track of the different
modules that are imported in an application, as well as the
resolution order of those imports, can be a challenging task.
Dynamic Features : Python is dynamically typed, allowing
variables to take values of different types during execution.
Also, it allows for classes to be dynamically modiÔ¨Åed
during runtime. Furthermore, the eval function allows for
a dynamically constructed string to be executed as code.
Duck Typing : Duck typing is a programming pattern that
is particularly common in dynamic languages such as
Python [22]. Through duck typing, the suitability of an
object is determined by the presence of speciÔ¨Åc methods and
properties, rather than the type of the object itself. In this
context, given a method deÔ¨Åned by two (or more) classes,
it is not trivial to identify its origins when it is invoked.
B. Limitations of Existing Static Approaches
We focus on two open-source static analyzers: Pyan [18]
andDepends [21]. We do not examine code2graph [19], [20]
separately, as it is based on Pyan to generate call graphs.
We discuss the limitations of the two existing analyzers in
terms of efÔ¨Åciency and practicality. To do so, we introduce a
small Python module named crypto (see Figure 1), which is
used to encrypt and decrypt a ‚Äúhello world‚Äù message. First, it
imports an external Python module named cryptops , which
deÔ¨Ånes two functions, namely: encrypt(key, msg) and
decrypt(key, msg) . Then, the Crypto class is deÔ¨Åned.
To use it, we instantiate it with an encryption key and we
can encrypt or decrypt messages by calling apply(self,
1647cryptocrypto.Crypto.__init__crypto.Crypto.applycryptops.encryptcryptops.decrypt(a) Precise call graph.
cryptocrypto.Cryptocrypto.Crypto.__init__crypto.Crypto.applycryptops (b)Pyan -generated call graph.
cryptocrypto.Crypto.apply (c)Depends -generated call graph.
Fig. 2: Call graphs for the crypto module.
msg, func) , where func is one of encrypt(key,
msg) anddecrypt(key, msg) . Figure 2a shows the call
graph of the module.
Pyan [18] produces the imprecise call graph shown in
Figure 2b. This graph does not contain all function calls,
because the tool does not track the inter-procedural Ô¨Çow of
values. Therefore, it is unable to infer which functions are
passed as arguments to apply(self, msg, func) . In
addition, there are several features that lead to the addition of
unrealized call edges. SpeciÔ¨Åcally, when Pyan detects object
initialization, it creates call edges to both the class name and
the__init__() method of the class.1Beyond that, in the
case of a module import, Pyan generates a call edge from the
importing namespace to the module name.
Depends produces the call graph presented in Figure 2c.
Depends does not track function calls originating from the
module‚Äôs namespace (e.g., crp.apply() ). This in turn, led
to an empty call graph. Therefore, to get a result, we wrapped
those function calls within a new function. The resulting
graph does not contain most of the calls included in the
source program. This is because Depends does not capture
the call to the __init__() function of the Crypto class.
Furthermore, (like Pyan )Depends does not track the inter-
procedural Ô¨Çow of functions leading to missing edges to the
parameter functions. Compared to Pyan ,Depends follows a
more conservative approach. That is, it only includes a call
edge when it has all the necessary information it needs to
anticipate that the call will be realized. Contrary to Pyan , this
can lead to a call graph without false positives.
III. P RACTICAL CALL GRAPH GENERATION
Our approach for generating call graphs employs a context-
insensitive inter-procedural analysis operating on an inter-
mediate representation of the input Python program. The
analysis uses a Ô¨Åxed-point iteration algorithm, and gradually
builds the assignment graph , which is a structure that shows
the assignment relations between program identiÔ¨Åers (Sec-
tion III-A). In a language supporting higher-order program-
ming, the assignment graph is an essential component that we
use for resolving functions pointed to by variables. Function
resolution takes place at the Ô¨Ånal step where we build the
1In Python, __init__() is the name of a special function called during
object construction.e2Expr ::=ojxjx := ejfunction x (y. . . ) ejreturn ej
e(x=e. . . )jclass x (y. . . ) eje.xje.x := ej
new x(y=e:::)jimport xfrom masyj
iterxje;e
o2Obj::=n;v
v2Denition ::=x;
2IdentType ::=funcjvarjclsjmod
n2Namespace ::= (v)
x;y2Identier ::=is the set of program identiÔ¨Åers
m2Modules ::=is the set of modules
E::= []jx := Ejreturn EjE(x=e:::)j
o(x=E::: )jnew x(y=E)jE.xjE.x := ej
o.x := EjiterojE;ejo;E
Fig. 3: The syntax for representing the input Python programs
along with the evaluation contexts.
call graph for the given program by exploiting the assignment
graph stemming from the analysis step (Section III-B).
A. The Core Analysis
The starting point of our approach is to compute the assign-
ment graph using an inter-procedural analysis working on an
intermediate representation targeted for Python programs.
One of the key elements of our analysis is that it examines
attribute accesses based on the namespace where each attribute
is deÔ¨Åned. For example, consider the following code snippet:
1class A:
2 def func ():
3 pass
4
5class B:
6 def func ():
7 pass
8
9a=A()
10b=B()
11a.func()
12b.func()
Our analysis is able to distinguish the two functions deÔ¨Åned
at lines 2 and 6, because they are members of two different
classes, i.e., class AandBrespectively. Note that Ô¨Åeld-based
approaches focused on JavaScript [14] will fail to treat the two
invocations as different, causing imprecision. That is because
a Ô¨Åeld-based approach will match all accesses of identical
attribute names (e.g., func() ) with a single object.
1) Syntax: The intermediate representation, where our anal-
ysis works on, follows the syntax of a simple imperative and
16482AssignG =Obj,!P(Obj)
s2Scope =Denition,!P(Denition )
h2ClassHier =Obj,!Obj
2State =AssignGScopeNamespaceClassHier
Fig. 4: Domains of the analysis.
object-oriented language, which is shown in Figure 3. The last
rule in this Ô¨Ågure also shows the evaluation contexts [23] for
this language, which we will explain shortly.
An important element of this model language is identiÔ¨Åers.
Every identiÔ¨Åer can be one of the following four types:
(1) func corresponding to the name of a function (2) var
indicating the name of a variable, (3) clsfor class names,
and (4) mod when the identiÔ¨Åer is a module name. Every
pair(x;)2IdentierIdentType forms a deÔ¨Ånition. We
represent every deÔ¨Ånition and its namespace as an object (see
theObj rule). A namespace is a sequence of deÔ¨Ånitions,
and it is essential for distinguishing objects sharing the same
identiÔ¨Åer from each other. For example, consider the following
Python code fragment located in a module named main .
1var = 10
2class A:
3 var = 10
The analysis distinguishes the objects created at lines 1 and 3,
as the Ô¨Årst one resides in the namespace [(main;mod)], while
the second one lives in the namespace [(main;mod);(A;cls)].
Our approach treats every object as the value given from
the evaluation of the expressions supported by the language. In
particular, our representation contains expressions that capture
the inter-procedural Ô¨Çow, assignment statements, class and
function deÔ¨Ånitions, module imports, and iterators / generators
(see the Expr rule). Note that the language is able to abstract
different features, including lambda expressions, keyword ar-
guments, constructors, multiple inheritance, and more.
As with prior work focusing on JavaScript [15], [16],
[24], we use evaluation contexts [23] that describe the order
in which sub-expressions are evaluated. For example, in an
attribute assignment E:x:=e, theEsymbol denotes that we
are currently evaluating the receiver of the attribute x, while
o:x:=Eindicates that the receiver has been already evaluated
to an object o2Obj (recall that evaluating expressions results
in objects), and the evaluation now proceeds to the right-hand
side of the assignment.
Remarks. When calling Python functions that produce a
generator (i.e., they contain a yield statement instead of
return ), these calls take place only when the generator
is actually used. To model this effect, when encountering
such lazy calls (e.g., gen = lazy_call(x) ), we create
a thunk (e.g., gen = lambda: lazy_call(x) ) that is
evaluated only when we iterate the generator (through the iter
construct). Furthermore, dictionaries and lists are treated as
regular objects. For example, we model a dictionary lookup
x["key"] , as an attribute access x:key .
2) State: After converting the original Python program to
our intermediate representation, our analysis starts evaluating
each expression, and gradually constructs the assignment
graph. To do so, the analysis maintains a state consistingof four domains as shown in Figure 4, namely, scope ,class
hierarchy ,assignment graph , and current namespace .
A scope is a map of deÔ¨Ånitions to a set of deÔ¨Ånitions.
Conceptually, a scope is a tree where each node corresponds
to a deÔ¨Ånition (e.g., a function), and each edge shows the
parent/child relations between deÔ¨Ånitions, i.e., the target node
is deÔ¨Åned inside the deÔ¨Ånition of the source node. The domain
of scopes is useful for correctly resolving the deÔ¨Ånitions that
are visible inside a speciÔ¨Åc namespace. Figure 5a illustrates
the scope tree of the program depicted in Figure 1, and
shows all program deÔ¨Ånitions and their inter-relations. Orange
nodes correspond to module deÔ¨Ånitions, red nodes are class
deÔ¨Ånitions, black nodes indicate functions, while blue nodes
denote variables. Based on this scope tree, we infer that the
function apply is deÔ¨Åned inside the class Crypto , which is
in turn deÔ¨Åned inside the module crypto , i.e., notice the path
crypto!Crypto!apply . This domain enables us to
properly deal with Python features such as function closures
and nested deÔ¨Ånitions.
A class hierarchy is a tree representing the inheritance
relations among classes. An edge from node uto nodev
indicates that the class uis a child of the class v. The
analysis uses this domain for resolving class attributes (either
methods or Ô¨Åelds) deÔ¨Åned in the base classes of the receiver
object. Through this domain we are able to handle the object-
oriented nature of Python, addressing features such as multiple
inheritance, and the method resolution order.
The assignment graph is deÔ¨Åned as a map of objects
to an element of the power set of objects P(Obj). This
graph holds the assignment relations between objects, cap-
turing the assignments and the inter-procedural Ô¨Çow of the
program. Figure 5b illustrates the assignment graph cor-
responding to the program of Figure 1. Each node in
the graph (e.g.,fcrypto.Crypto.apply, func g) rep-
resents an object. The Ô¨Årst component of the node label (e.g.,
crypt.Crypto.apply ) indicates the namespace where
each identiÔ¨Åer (e.g., func ) is deÔ¨Åned. Colors reveal the type
of the identiÔ¨Åer as explained in a previous paragraph (e.g.,
the blue color implies variable deÔ¨Ånitions). An edge shows
the possible values that a variable may hold. For example,
the variable func deÔ¨Åned in the crypto.Crypto.apply
namespace may point to the functions decrypt and
encrypt , both deÔ¨Åned in the cryptops namespace.
As another example, notice the edge originating from the
nodefcrypto.Crypto.apply, msg gand leading to
fcrypto, encrypted g. This edge shows that the param-
etermsg of the function crypto.Crypto.apply points
to the variable encrypted when the function is invoked on
line 12. The assignment graph domain enables us to address
the challenge regarding higher-order programming in Python.
Finally, we use the current namespace to track the location
where new variables, classes, modules, and functions are
deÔ¨Åned. This domain is important for establishing a more
precise analysis than Ô¨Åeld-based analysis employed by prior
work. Through namespaces, objects and attribute accesses are
distinguished based on their namespace, addressing challenges
1649cryptocryptopscrpencrypteddecryptedCryptoselfselfkeymsgfunc__init__apply(a) The scope tree of the crypto module.
cryptopscrypto, crpcryptops, encryptcryptops, decryptcrypto.Crypto.apply, msg
cryptops.encrypt, <virt-ret>cryptops.decrypt, <virt-ret>crypto.Crypto.apply, <virt-ret>crypto, encryptedcrypto.Crypto.apply, funccrypto, cryptops
crypto, Cryptocrypto, decrypted
(b) The assignment graph of the crypto module.
Fig. 5: Analyzing the crypto module.
such as duck typing.
3) Analysis Rules: The analysis examines every expression
found in the intermediate representation of the initial program,
and transitions the analysis state according to the semantics of
each expression. The algorithm repeats this procedure until the
state converges, and the assignment graph is given by the Ô¨Ånal
state of the analysis.
Figure 6 demonstrates the state transition rules of our
analysis. The rules follow the form:
h;s;n;h;E [e]i!h0;s0;n0;h0;E[e0]i
In the following, we describe each rule in detail.
According to the [ E-CTX] rule, when we have an expression
ein the evaluation context E, an assignment graph , a scope
s, a namespace n, a class hierarchy h, we can get an expression
e0in the evaluation context E, if the initial expression e
evaluates to e0. For what follows, the binary operation xy
stands for appending the element yto the listx.
The [ COMPOUND ] rule states that when we have a com-
pound expression consisting of two objects o1,o2, we return
the last object o2as the result of the evaluation. Observe that
the evaluation of the compound expression requires each sub-
term to have been evaluated to an object according to the
evaluation contexts shown in Figure 3. The rest of the rules
also follow this behavior.
The [ IDENT ] rule describes the scenario when the initial
expression is an identiÔ¨Åer x. In this case, the analysis retrieves
the objectocorresponding to the identiÔ¨Åer x, in the namespace
n, based on the scope tree s. To do so, the analysis uses the
function getObject( s;n;x ), which iterates every element
yof the namespace nin the reverse order. Then, by examining
the scope tree s, it checks whether the element node yhas
any child matching the identiÔ¨Åer x. In case of a mismatch,
the function getObject proceeds to the next element of the
namespace. Notice that the [ IDENT ] rule does not have any
side-effect on the analysis state.
The [ ASSIGN ] rule assigns the object oto the identi-
Ô¨Åerx. First, the analysis adds the identiÔ¨Åer xin the cur-
rent namespace nof the scope tree s, using the function
addScope( s;n;x; ). This function adds an edge from thenode accessed by the path nto the target node given by
the deÔ¨Ånition (x;). Second, this rule updates the assignment
graph by adding an edge from the object corresponding to the
left-hand side of the assignment (i.e., o0) to that of the right-
hand side (i.e., o). This update says that the variable xdeÔ¨Åned
in the namespace ncan point to the object o.
[FUNC ] updates the scope tree. In particular, it adds the
functionxto the current namespace n, leading to a new scope
trees0. Then, it creates a new namespace n0by adding the
function deÔ¨Ånition (x;func)to the top of the current names-
pace. It adds all function parameters, and a virtual variable
named ret‚Äîwhich stands for the variable holding the return
value of the function‚Äîto the newly-created namespace n0.
This results in a new scope tree s(3). Finally, the analysis
proceeds to the evaluation of the body of the function xin
the fresh namespace n0, i.e., observe that the rule evaluates
toE[e]. The new namespace n0correctly captures that any
variable deÔ¨Åned in e, is actually deÔ¨Åned in the body of the
function.
[RETURN ] assigns the object oto the virtual variable ret,
which is used for storing the return value of a function (recall
the [ FUNC ] rule). To do so, the analysis updates the assignment
graph by adding a new edge from the object o0corresponding
to the return variable ret to the object owhich is the operand
ofreturn . Finally, this rule evaluates to the object o0related
to the return virtual variable ret.
The inter-procedural Ô¨Çow is captured by the [ CALL ] rule.
SpeciÔ¨Åcally, when we encounter a call expression o1(y=
o2:::), we examine the callee object o1associated with
a function fdeÔ¨Åned in a namespace n0. Then, the rule
connects every parameter of fwith the appropriate argu-
ment passed during function invocation (e.g., the counter-
part object of the parameter yat call-site is o2), leading
to a new assignment graph 0. As an example, consider
again the graph of Figure 5b. The outgoing edges of the
fcrypto.Crypto.apply, func gnode are created by
this rule. These edges imply that the parameter func of the
crypto.Crypto.apply function may hold the functions
cryptops.encrypt andcryptops.decrypt passed
when calling crypto.Crypto.apply (Figure 1).
1650E-CTX
h;s;n;h;ei,!h0;s0;n0;h0;e0i
h;s;n;h;E [e]i!h0;s0;n0;h0;E[e0]i
COMPOUND
h;s;n;h;E [o1;o2]i!h;s;n;h;E [o2]i
IDENT
o=getObject (s;n;x )
h;s;n;h;E [x]i!h;s;n;h;E [o]i
ASSIGN
s0=addScope (s;n;x; var)
o0= (n;(x;var))0=[o0!(o0)[fog]
h;s;n;h;E [x:=o]i!h0;s0;n;h;E [o0]i
FUNC
s0=addScope (s;n;x; func)
n0=n(x;func)s00=addScope (s0;n0;ret;var)
s(3)=addScope (s00;n0;y;var)
h;s;n;h;E [functionx(y:::)e]i!h;s(3);n0;h;E [e]i
RETURN
o0= (nx;(ret;var))0=[o0!(o0)[fog]
h;s;nx;h;E [returno]i!h0;s;n;h;E [o0]i
CALL
o1= (n0;(f;func))
o0
2= (n0f;(y;var))0=[o0
2!(o0
2)[fo2g]
h;s;n;h;E [o1(y=o2:::)]i!h0;s;n;h; (n0f;(ret;var))i
CLASS
s0=addScope (s;n;x; cls)t=hgetObject (s;n;b)jb2(y:::)i
h0=h[(n;(x;cls))!t]n0=n(x;cls)
h;s;n;h;E [classx(y::: )e]i!h;s0;n0;h0;E[e]i
ATTR
o0=getClassAttrObject (o;x;h )
h;s;n;h;E [o:x]i!h;s;c;h;E [o0]i
NEW
o3=getObject (s;n;x )
o2=getClassAttrObject (o3;init;h)
h;s;n;h;E [newx(y=o1:::)]i!h;s;n;h;E [o2(y=o1:::);o3]i
ATTR -ASSIGN
o3=getClassAttrObject (o1;x;h)0=[o3!(o3)[fo2g]
h;s;n;h;E [o1:x:=o2]i!h0;s;n;h;E [o3]i
IMPORT
o2=getObject (s;m;x)s0=addScope (s;n;y; var)
o1= (n;(y;var))0=[o1!(o1)[fo2g]
h;s;n;h;E [importxfrommasy]i!h0;s0;n;h;E [o1]i
ITER -ITERABLE
o0=getClassAttrObject (o;next;h)
h;s;n;h;E [itero]i!h;s;n;h;E [o0()]i
ITER -GENERATOR
getClassAttrObject (o;next;h) =undeÔ¨Åned
h;s;n;h;E [itero]i!h;s;n;h;E [o()]i
Fig. 6: Rules of the analysis.
The [ CLASS ] rule handles class deÔ¨Ånitions. The rule Ô¨Årst
adds the class xto the scope tree through the function
addScope() , and then gets every object related to the base
classes ofx(i.e.,y::: ). To achieve this, the rule consults
the scope tree in the namespace n, and gets a sequence of
objectstthat respects the order in which base classes are
passed during class deÔ¨Ånition. We later explain why keeping
the registration order of base classes is important. The rule then
updates the class hierarchy so that the freshly-deÔ¨Åned class xis
a child of the base classes pointed to by the identiÔ¨Åers (y:::).After this, the analysis works on the body of the class ein
a new namespace n0. The new namespace contains the class
deÔ¨Ånition to the top of the current namespace (i.e., n(x;cls)).
Then, the analysis starts examining the body of the class using
the new namespace.
The [ ATTR ] rule is similar to [ IDENT ]. However, this
time, in order to correctly retrieve the object corresponding
to the attribute xof the receiver object o, the analysis
examines the hierarchy of classes hthrough the function
getClassAttrObject( o;x;h ). This is the point where
our analysis is able to distinguish attributes according to the
location (i.e., o) where they are deÔ¨Åned.
To deal with multiple inheritance, the function
getClassAttrObject() respects the method resolution
order implemented in Python. For example, consider the
following code snippet.
1class A:
2 def func ():
3 pass
4
5class B:
6 def func ():
7 pass
8
9class C(B, A):
10 pass
11
12c=C()
13c.func()
In the example above, the method resolution order is C!
B!A, because the class Bis the Ô¨Årst parent class of C,
while Ais the second one. As a result, c.func() leads to
the invocation of function func deÔ¨Åned in class B, as it is the
Ô¨Årst matching function whose name is func in the method
resolution order. Correctly resolving class members explains
why the domain of the class hierarchy maps every object to
asequence of objects rather than a set‚Äîwe need to track the
order in which the parents of a class are registered.
For object initialization, we introduce the [ NEW ] rule. This
rule gets the object o3associated with the deÔ¨Ånition of the
classx. Using the getClassAttrObject() function, the
rule inspects the method resolution order of the object o3to
Ô¨Ånd the Ô¨Årst object o2matching the function __init__ .
Recall that this function is called whenever a new object
is created. Observe how the new evaluates; it reduces to
o2(y=o1:::);o3. That is, we Ô¨Årst call the constructor of
the class with the same arguments passed as in the initial
expression (i.e., o2(y=o1)), and then we return the object o3
corresponding to the class deÔ¨Ånition, which is eventually the
result of the new expression.
The rule for attribute assignment o1:x:=o2describes
the case when the attribute xis deÔ¨Åned somewhere in
the class hierarchy of the receiver object o1. In this case,
getClassAttrObject() returns the object o3associated
with this attribute, and the rule updates the assignment graph
so thato3points to the object o2from the right-hand side
of the assignment. If the attribute is not deÔ¨Åned in the class
hierachy, (i.e., getClassAttrObject() returns?) the
attribute assignment is similar to [ ASSIGN ], i.e., we Ô¨Årst add
1651Algorithm 1: Call Graph Construction
Input :p2Program
2State
Output: cg2CallGraph
1foreacheinProgram do
2 whilee62Obj do
3h;E[e]i!h0;E[e0]i
4 ife0=o1(y=o2:::)then // Call Expression
5 (;s;nf;h) 0
6 c getReachableFuns( ,o1)
7 o3 getObject( s,n,f)
8 cg cg[o3!cg(o3)[c]// Add Call Edges
9 end
10e e0
11 end
12end
13return cg
the attribute xto the current scope through addScope() ,
and then update the graph. This case is omitted for brevity.
When we encounter an importxfrommasyexpression, we
retrieve the object o2corresponding to the imported identiÔ¨Åer
x, which is deÔ¨Åned in the module m. Then, we create an alias
yforx. To do so, we add yto the scope tree of the current
namespace, and update the assignment graph by adding an
edge from the object of yto that ofx. Through this rule, we
are able to deal with Python‚Äôs module system.
Consuming iterables and generators is supported through
the iterxexpression. When the identiÔ¨Åer xpoints to an
iterable, (i.e., the object pointed to by xhas an attribute named
__next__ ), we get the object o0related to __next__ . Then,
iterevaluates to a call of o0()(see the [ ITER -ITERABLE ] rule).
If this is not the case, we treat xas a generator ([ ITER -
GENERATOR ]). In this case, iterreduces to a call of x(). Recall
from Section III-A1 that we model generators as thunks,
therefore this scenario describes the evaluation of these thunks
(generators) when they are actually used (iterated).
Remark about analysis termination. The analysis tra-
verses expressions, and transitions the analysis state based
on the rules of Figure 6, until the state converges. The
analysis is guaranteed to terminate, because the domains are
Ô¨Ånite. Even in the presence of the domain of class hierarchy
h2ClassHier (Figure 4), which is theoretically inÔ¨Ånite,
the analysis eventually terminates, because a Python program
cannot have an unbounded number of classes.
B. Call Graph Construction
After the termination of the analysis, we build the call graph
by performing a Ô¨Ånal pass on the intermediate representation
of the given Python program. Algorithm 1 describes the details
of this pass. The algorithm takes two elements as input: (1) a
programp2Program of the model language whose syntax is
shown in Figure 3, and (2) the Ô¨Ånal state 2State stemming
from the analysis step. The algorithm produces a call graph:
cg2CallGraph =Obj,!P(Obj)The graph contains only objects associated with functions. An
elemento2Obj mapped to a set of objects t2 P(Obj)
means that the function omay call any function included in t.
The algorithm inspects every expression efound in the
program (line 1), and it evaluates ebased on the state transition
rules described in Figure 6. The algorithm repeats the state
transition rules, until eeventually reduces to an object (lines
2, 3). Every time when ereduces to a call expression of
the formo1(y=o2:::)(line 4), the algorithm gets the
namespace where this invocation happens and retrieves the
top element of that namespace (see nf, line 5). After that,
the algorithm gets all functions that the callee object o1may
point to. To do so, it consults the assignment graph through the
function getReachableFuns( ;o 1), which implements a
simple Depth-First Search ( DFS) algorithm and gets the set of
functionscthat are reachable from the source node o1. In turn,
the algorithm updates the call graph cgby adding all edges
from the top element of the current namespace to the set of
the callee functions c(lines 7, 8). In other words, the object o3
(line 7) representing the top element of the namespace, where
the call occurs, is actually the caller of the functions pointed
to by the object o1.
C. Discussion & Limitations
One of our major design decisions is to ignore conditionals
and loops. For instance, when we come across an ifstate-
ment, our analysis over-approximates the program‚Äôs behavior
and considers both branches. This design choice enables
efÔ¨Åciency without highly compromising the analysis precision
(as we will discuss in Section V). Other static analyzers [9]‚Äì
[11] choose to follow a more heavyweight approach and reason
about conditionals. These static analyzers, though, do not
solely focus on call-graph construction, but rather they attempt
to compute the set of all reachable states based on an initial
one. However, for call-graph generation, providing such an
initial state that exercises all feasible paths (which is required
in order to compute a complete call graph), especially when
analyzing libraries, is not straightforward.
In Python where object-oriented features, duck typing [22],
and modules are extensively used, it is important to separate
attribute accesses based on the namespace where each at-
tribute is deÔ¨Åned. This design choice boosts‚Äîcontrary to prior
work [14]‚Äîthe precision of our analysis without sacriÔ¨Åcing its
scalability.
Our analysis does not fully support all of Python‚Äôs features.
First, we ignore code generation schemes, such as calls to the
eval built-ins. In general, such dynamic constructs hinder the
effectiveness of any static analysis, and dynamic approaches
are often employed as a countermeasure [25], [26]. Second,
our approach does not store information about variables‚Äô built-
in types, and does not reason about the effects of built-in
functions. Therefore, attribute calls that depend on a speciÔ¨Åc
built-in type (e.g., list.append() ) are not resolved, while
the effects of functions such as getattr andsetattr are
ignored. Third, we can only analyze modules for which their
source code has been provided. When a function‚Äîfor which
1652its code deÔ¨Ånition is not available‚Äîis called, our method will
add an edge to the function, but no edges stemming from
that function will ever be added, and its return value will be
ignored.
IV. I MPLEMENTATION
We have developed PyCG, a prototype of our approach
in Python 3. For each input module, our tool creates its
scope tree and its intermediate representation by employing
thesymtable [27] and ast[28] modules respectively.
Our prototype discovers the Ô¨Åle locations of the different
imported modules to further analyze them by using Python‚Äôs
importlib module. This is the module that Python uses in-
ternally to resolve import statements. We perform two steps.
First, the Ô¨Åle location of the imported module is identiÔ¨Åed, and
then a loader is used to import the module‚Äôs code. In Python
one can deÔ¨Åne custom loaders for import statements, which
allowed us to use a loader that logs the Ô¨Åle locations discovered
and then exit without loading the code. Then, in the second
step, our tool takes over and uses the discovered Ô¨Åle‚Äôs contents
to iterate its intermediate representation in a recursive manner.
This allows us to resolve imports in an efÔ¨Åcient way. Currently,
we only analyze discovered modules that are contained in the
package‚Äôs namespace.
V. E VALUATION
We evaluate our approach based on three research questions:
RQ1 Is the proposed approach effective in constructing call
graphs for Python programs? (Sections V-B and V-C)
RQ2 How does the proposed approach stand in comparison
with existing open-source, static-based approaches for
Python? (Sections V-B and V-C)
RQ3 What is the performance of our approach? (Section V-D)
Further, we show a potential application through the enhance-
ment of GitHub‚Äôs ‚Äúsecurity advisory‚Äù notiÔ¨Åcation service.
A. Experimental Setup
We use two distinct benchmarks: (1) a micro-benchmark
suite containing 112 minimal Python programs, and (2) a
macro-benchmark suite of Ô¨Åve popular real-world Python
packages. We ran our experiments on a Debian 9 host with 16
CPUs and 16 GBs of RAM .
1) Micro-benchmark Suite: We propose a test suite for
benchmarking call graph generation in Python. Based on this
suite, researchers can evaluate and compare their approaches
against a common standard. Reif et al. [29] have provided a
similar suite for Java, containing unique call graph test cases,
grouped into different categories.
Our suite consists of 112 unique and minimal micro-
benchmarks that cover a wide range of the language‚Äôs features.
We organize our micro-benchmarks into 16 distinct categories,
ranging from simple function calls to more complex features
such as twisted inheritance schemes. Each category contains
a number of tests. Every test includes (1) the source code, (2)
the corresponding call graph (in JSON format), and (3) a short
description. Categorizing and adding a new test is relativelyTABLE I: Micro-benchmark suite categories.
Category #tests Description
parameters 6 Positional arguments that are functions
assignments 4 Assignment of functions to variables
built-ins 3 Calls to built in functions and data types
classes 22 Class construction, attributes, methods
decorators 7 Function decorators
dicts 12 Hashmap with values that are functions
direct calls 4 Direct call of a returned function ( func()() )
exceptions 3 Exceptions
functions 4 Vanilla function calls
generators 6 Generators
imports 14 Imported modules, functions classes
kwargs 3 Keyword arguments that are functions
lambdas 5 Lambdas
lists 8 Lists with values that are functions
mro 7 Method Resolution Order ( MRO )
returns 4 Returns that are functions
easy. The source code of each test implements only a single
execution path (i.e., no conditionals and loops) so there is
a straightforward correspondence to its call graph. Table I
lists the categories along with the number of benchmarks they
incorporate and a corresponding description.
Addressing Validity Threats : The internal validity of
the micro-benchmark suite depends on the range of Python
features that it covers. To address this threat, we presented
the suite to two researchers, who have professionally worked
as Python developers (other researchers have applied similar
methods to verify their work [30]). Then, we asked them to
rank the suite (from 1 to 10) based on the following criteria:
1) Completeness: Does it cover all Python features?
2) Code Quality: Are the tests unique and minimal?
3) Description Quality: Does the description adequately de-
scribe the given test case?
The Ô¨Årst reviewer provided a 9.7 ranking in all cases. The
second indicated an excellent (10) code and description quality
but ranked lower (6) the completeness of the benchmarks.
Both reviewers provided corresponding feedback. In their
comments, they suggested some code cleanups and asked for
more comprehensive descriptions on some complex bench-
marks. Regarding the completeness of the suite, they pointed
out missing tests for some common features such as built-in
functions and generators. We applied the reviewers‚Äô sugges-
tions by refactoring the affected benchmarks and improving
their descriptions. Furthermore, we implemented more tests
for some of the missing functionality.
2) Macro-benchmarks: We have manually generated call
graphs for Ô¨Åve popular real-world packages. The packages
were chosen as follows. First, we queried the GitHub API
for Python repositories sorted by their number of stars. Then,
we downloaded each repository and counted the number of
lines of Python code. If the repository contained less than
3.5k lines of Python code, we kept it. Table II presents the
GitHub repositories we chose along with their lines of code,
GitHub stars and forks, together with a short description.
Currently, there is no acceptable implementation generating
Python call graphs in an effective manner, so the Ô¨Årst author
manually inspected the projects and generated their call graphs
inJSON format, spending on average 10 hours for each project.
1653TABLE II: Macro-benchmark suite project details.
Project LoC Stars Forks Description
fabric 3,236 12.1k 1.8k Remote execution & deployment
autojump 2,662 10.8k 530 Directory navigation tool
asciinema 1,409 7.9k 687 Terminal session recorder
face_classification 1,455 4.7k 1.4k Face detection & classiÔ¨Åcation
Sublist3r 1,269 4.4k 1.1k Subdomains enumeration tool
TABLE III: Micro-benchmark results for PyCGand Pyan .
Depends is unsound in all cases and complete in 110/112 cases
and is omitted.
Category PyCG Pyan
Complete Sound Complete Sound
assignments 4/4 3/4 4/4 4/4
built-ins 3/3 1/3 2/3 0/3
classes 22/22 22/22 6/22 10/22
decorators 6/7 5/7 4/7 3/7
dicts 12/12 11/12 6/12 6/12
direct calls 4/4 4/4 0/4 0/4
exceptions 3/3 3/3 0/3 0/3
functions 4/4 4/4 4/4 3/4
generators 6/6 6/6 0/6 0/6
imports 14/14 14/14 10/14 4/14
kwargs 3/3 3/3 0/3 0/3
lambdas 5/5 5/5 4/5 0/5
lists 8/8 7/8 3/8 4/8
mro 7/7 5/7 0/7 2/7
parameters 6/6 6/6 0/6 0/6
returns 4/4 4/4 0/4 0/4
Total 111/112 103/112 43/112 36/112
We opted for medium sized projects (less than 3.5k LoC), so
that we could minimize human errors. To further verify the
validity of the generated call graphs, we examined the output
ofPyCGPyan , and Depends and identiÔ¨Åed 90 missing edges
from a total of 2506.
B. Micro-benchmark suite results
The benchmarks included in the micro-test suite have a
limited scope and are designed to cover speciÔ¨Åc functionalities
(such as decorators and lambdas). Table III lists the results of
our evaluation. For each benchmark belonging to a speciÔ¨Åc
category, we show if our prototype and Pyan generated com-
plete or sound call graphs. Note that a call graph is complete
when it does not contain any call edges that do not actually
exist (no false positives), and sound when it contains every
call edge that is realized (no false negatives).
PyCGproduces a complete call graph in almost all cases
(111/112). In addition, it produces sound call graphs for 103
out of 112 benchmarks. The lack of soundness is attributed
to not fully covered functionalities, i.e., Python‚Äôs starred
assignments.
Pyan produces either complete or sound call graphs at
a much lower rate. However, for assignments, Pyan turns
out as a more sound method because it supports them in a
better manner. We performed a qualitative analysis on the
call graphs generated by Pyan to check the reasons behind
its performance. We observed that Pyan produces incomplete
call graphs because it creates call edges to class names as well
as their __init__ methods (see also Section II-B). Also it
generates imprecise results because it does not support all ofTABLE IV: Macro-benchmark results and tool comparison.
Project Precision (%) Recall (%)
PyCG Pyan Depends PyCG Pyan Depends
autojump 99:566:5 99:2 68:2 28:5 22:5
fabric 98:3 - 100 61:9 - 6:3
asciinema 100 - 98:1 68 - 15:5
face_classification 99:5 86:8 96:2 89:7 7:6 5:7
Sublist3r 98:8 69:8 100 61 :6 25:6 21:9
Average 99.2 74.4 98.7 69.9 20.6 14.4
Python‚Äôs functionality, ( 0=6generators and 0=3exceptions),
ignores the inter-procedural Ô¨Çow of functions ( 0=6parameters
and0=4returns), misses calls to imported ones ( 4=14), and
fails to support classes ( 10=22).
The evaluation of Depends shows both its fundamental
strengths and limitations. Recall that each benchmark imple-
ments a single execution path and includes a call coming from
the module‚Äôs namespace. Our results indicate that Depends
does not identify calls from module namespaces, and therefore
soundness is never achieved (0/112). In terms of completeness,
Depends achieves an almost perfect score (110/112) due to its
conservative nature‚Äîi.e., it adds an edge when it has high
conÔ¨Ådence that it will be realized.
C. Macro-benchmark results
By using our macro-benchmark, we have examined the three
tools in terms of precision and recall. Precision measures
the percentage of valid generated calls over the total number
of generated calls. Recall measures the percentage of valid
generated calls over the total number of calls. To do so, we
manually generated the call graphs of the examined packages.
Table IV presents our results. The missing entries for
Pyan indicate that the tool crashed during the execution. Our
Ô¨Åndings show that PyCGgenerates high precision call graphs.
On all cases, more than 98% of the generated call edges are
true positives, while on one case none of the generated call
edges are false positives. Recall results show that on average,
69:9%of all call edges are successfully retrieved. The missing
call edges are attributed to the approach‚Äôs limitations (recall
Section III-C), and missing support for some functionalities.
Pyan shows average precision and low recall. Pyan ‚Äôs aver-
age precision appears because the tool adds call edges to class
names instead of just their __init__ methods. Also, it does
not track the inter-procedural Ô¨Çow of functions, which is the
reason why it has low recall. For instance, the implementation
of the face_classification package mostly depends
on functions declared in external packages. Pyan ignores such
calls which in turn leads to a 7.6% recall.
Finally, Depends shows high precision (98.7%) and low
recall. The high precision of Depends can be attributed to
its conservative nature. Furthermore, Depends does not track
higher order functions and does not include calls coming from
module namespaces. This in turn, leads to its low recall.
D. Time and Memory Performance
We use the macro-benchmark suite as a base for our time
and memory evaluation. Table V presents the time and memory
performance metrics of the three tools. The execution time was
calculated using the UNIX time command, while the memory
1654TABLE V: Time and memory comparison.
Project Time (sec) Memory (MB)
PyCG Pyan Depends PyCG Pyan Depends
autojump 0.76 0.42 2.37 62.7 37.8 27.1
fabric 0.77 - 1.83 60.9 - 18.5
asciinema 0.87 - 2 61.6 - 19.4
face_classification 0.92 0.38 2.49 60.9 35.3 25.6
Sublist3r 0.51 0.33 2.01 60 35.8 19.4
Average 0.77 0.38 2.14 61.2 36.3 22
consumption was measured using the UNIX pmap command.
The metrics presented are the average out of 20 runs.
The results show that Pyan is more time efÔ¨Åcient, and that
Depends is more memory efÔ¨Åcient. PyCGandPyan generate
a call graph for the programs in the benchmark ( 3.5k LoC)
in under a second, while Depends requires more than two
seconds on average. Furthermore, all tools use a reasonable
amount of memory, with PyCG,Pyan andDepends using on
average61.2,36.3 and22MBs of memory respectively.
Overall, PyCGis on average 2 times slower than Pyan , and
uses 2.8 times the amount of memory that Depends uses.
We attribute the differences in execution time between Pyan
and PyCGto the fact that Pyan performs two passes of the
AST in comparison to PyCGperforming a Ô¨Åxpoint iteration
(Section III). Depends is overall slower, because it spends
most of its execution time parsing the source Ô¨Åles. In terms of
memory, Pyan andDepends store less information about the
state of the analysis leading to better memory performance.
E. Case Study: A Fine-grained Tracking of Vulnerable Depen-
dencies
GitHub sends a notiÔ¨Åcation to the contributors of a repos-
itory when it identiÔ¨Åes a dependency to a vulnerable library.
However, this notiÔ¨Åcation does not indicate if the project
invokes the function containing the defect. We show that PyCG
can be employed to enhance the service with method-level
information that may further warn the contributors.
To highlight the usefulness of our method in this context,
we performed the following steps. First we accessed GitHub‚Äôs
‚ÄúAdvisory Database‚Äù [31]. Then, we searched for vulnerable
Python packages sorted by the severity of the defect. In many
occasions the accompanying CVE (Common Vulnerabilities
and Exposures) entries did not include further details about
the defects. We disregarded such instances and focused on the
Ô¨Årst two cases that provided information about the functions
that contained the vulnerability: (1) PyYAML [32] (versions
before 5.1), a YAML parser affected by CVE-2017-18342 [33],
and (2) Paramiko [34] (multiple versions before 2.4.1), an
implementation of the SSHv2 protocol affected by CVE-2018-
7750 [35]. Both packages were imported by thousands of
projects, 9226 for PyYAML and 1097 for Paramiko. We could
not clone all dependent repositories because some were private
and others did not exist any more: we managed to download
570 PyYAML and 322 Paramiko dependent projects. Then, we
ran our tool on each project and generated corresponding call
graphs for 106 out of the 570 PyYAML dependent projects
and 76 out of the 322 Paramiko dependent projects‚Äîthe
projects that PyCGfailed to generate call graphs were writtenin Python 2. Finally, we queried the generated call graphs to
check if the vulnerable functions were included. We found that
the vulnerable function in PyYAML (i.e.,load ) was invoked
by 42/106 projects. In Paramiko we found that the problem
method ( start_server ) was not utilized at all by any of the
76 projects. We also observed that 12 projects did not invoke
any library coming from Paramiko. Paramiko was needlessly
included in the requirement Ô¨Åles of the dependents. That was
not a false negative from our part: we manually checked that
PyCGdid not miss any invocation.
VI. R ELATED WORK
Call Graph Generation. Methods that generate call graphs
can be either dynamic [36], or static [37]. Dynamic approaches
usually produce fewer false positives, but suffer from perfor-
mance issues. Also, they are able to analyze a single execution
path, and their effectiveness relies on the program‚Äôs input.
Static approaches are more time efÔ¨Åcient and can typically
cover a wider range of execution paths, trying to capture all
possible program‚Äôs behaviors. Several approaches [38]‚Äì[40],
try to combine the two so they can get improved results.
There are plenty of methods and tools targeting call graph
generation for statically-typed programming languages such as
Java. DOOP [41] and WALA [42] follow a context-sensitive,
points-to analysis method. PADDLE [43], a similar approach,
employs Binary Decision Diagrams ( BDDs) [44]. Finally,
OPAL [45] is a lattice-based approach written in Scala. Ali
et al. [46], implement CGC, a partial call graph generator for
Java, with the main focus being efÔ¨Åciency. They ignore calls
coming from externally imported libraries, and only analyze
the source code of a given package. We are currently following
a similar approach, but we aim to efÔ¨Åciently analyze external
dependencies in the future.
Moving to dynamic languages, Ali et al. [47] convert Python
source code into JVM bytecode, and use the existing imple-
mentations for Java [42], [48], [49] to generate its call graph.
However, they argue that generating precise call graphs using
this method is infeasible, and sometimes the output has more
than96% of false positives. pycallgraph [50] generates Python
call graphs by dynamically analyzing one execution path.
Thus the analysis is not practical and one should pair it with
another method (e.g., fuzzing) to retrieve meaningful results.
On the JavaScript front, Feldthaus et al. [14] implement a
Ô¨Çow-based approach for the generation of call graphs. They
evaluate against call graphs generated by a dynamic approach
paired with instrumentation, achieving 66% precision and
85% recall. Other JavaScript call graph generators include,
IBM WALA [42], NPM call graph [51], Google closure com-
piler [52], Approximate Call Graph ( ACG) [14], and Type
Analyzer for JavaScript ( TAJS ) [9]. TAJS implements a lattice-
based Ô¨Çow-sensitive approach using abstract interpretation.
Although, such an approach yields more promising results,
it comes with a performance cost.
Call Graph Benchmarking and Comparison. Reif et
al. present Judge [29], a toolchain for analyzing call graph
generators for Java. At its core, the toolchain contains a test
1655suite with benchmarks for a range of Java features. The authors
then proceed to compare Java call graph generators, namely
Soot [48], [49], WALA [42], DOOP [41] and OPAL [45]. Sui et
al. [53], also present a test suite of Java benchmarks, and they
use it to evaluate and compare Soot [48], [49], WALA [42],
and DOOP [41]. The above benchmark suites are very similar,
leading to Judge consolidating them into one benchmark suite.
Recall our very similar implementation of a micro-benchmark
suite from Section V-A.
Static Analysis for Dynamic Languages. Numerous ad-
vanced frameworks aim for the static analysis of JavaScript
programs. SAFE [10] provides a formally speciÔ¨Åed static
analysis framework with the goal of being Ô¨Çexible, scalable
and pluggable. JSAI [11] is a formally speciÔ¨Åed and provably
sound platform using abstract interpretation.
Other JavaScript approaches target different aspects of its
functionality. Madsen et al. implement RADAR [54] a tool that
identiÔ¨Åes bugs in event-driven JavaScript programs. Sotiropou-
los et al. [15] propose an analysis targeting asynchronous
functions. Bae et al. [55], implement SAFE WAPI a tool aimed
at identifying possible APImisuses. Park et al. [56] propose
SAFE WApp, a static analyzer for client-side JavaScript.
Fromherz et al. [57] implement a prototype that soundly
identiÔ¨Åes run-time errors by evaluating the data types of
Python variables through abstract interpretation. In compar-
ison, our approach does not infer the data types of variables
and focuses on the generation of call graphs.
VII. C ONCLUSION
We have introduced a practical static approach for
generating Python call graphs. Our method performs a
context-insensitive inter-procedural analysis that identiÔ¨Åes the
Ô¨Çow of values through the construction of a graph that stores
all assignment relationships among program identiÔ¨Åers. We
used two benchmarks to evaluate our method, namely a micro-
and a macro-benchmark suite. Our prototype showed high
rates of both precision and recall. Also, our micro-benchmark
suite can serve as a standard for the evaluation of future
methods. Finally, we applied our approach in a real-world
case scenario, to highlight how it can aid dependency impact
analysis.
Acknowledgments. We thank the anonymous reviewers for
their insightful comments and constructive feedback. This
work has received funding from the European Union‚Äôs Horizon
2020 research and innovation programme under grant agree-
ment No. 825328.
REFERENCES
[1] Valgrind, ‚ÄúCallgrind: a call-graph generating cache and branch
prediction proÔ¨Åler,‚Äù 2020. [Online]. Available: http://valgrind.org/docs/
manual/cl-manual.html
[2] H. Shahriar and M. Zulkernine, ‚ÄúMitigating program security vulnera-
bilities: Approaches and challenges,‚Äù ACM Comput. Surv. , vol. 44, no. 3,
Jun. 2012.[3] A. Feldthaus, T. Millstein, A. M√∏ller, M. Sch ¬®afer, and F. Tip, ‚ÄúTool-
supported refactoring for JavaScript,‚Äù in Proceedings of the 2011 ACM
International Conference on Object Oriented Programming Systems
Languages and Applications , ser. OOPSLA ‚Äô11. New York, NY , USA:
Association for Computing Machinery, 2011, pp. 119‚Äì138.
[4] J. Hejderup, A. van Deursen, and G. Gousios, ‚ÄúSoftware ecosystem
call graph for dependency management,‚Äù in Proceedings of the 40th
International Conference on Software Engineering: New Ideas and
Emerging Results , ser. ICSE-NIER ‚Äô18. New York, NY , USA: ACM,
2018, pp. 101‚Äì104.
[5] R. Kikas, G. Gousios, M. Dumas, and D. Pfahl, ‚ÄúStructure and evo-
lution of package dependency networks,‚Äù in Proceedings of the 14th
International Conference on Mining Software Repositories , ser. MSR
‚Äô17. IEEE Press, 2017, pp. 102‚Äì112.
[6] (2016) The npm blog: changes to npm‚Äôs unpublish policy. [Online;
accessed 26-July-2020]. [Online]. Available: https://blog.npmjs.org/
post/141905368000/changes-to-npms-unpublish-policy
[7] (2020) npm(1)‚Äîa JavaScript package manager. [Online; accessed
26-July-2020]. [Online]. Available: https://github.com/npm/cli
[8] (2020) pip 20.0.2: The PyPA recommended tool for installing
Python packages. [Online; accessed 26-July-2020]. [Online]. Available:
https://pypi.org/project/pip/
[9] S. H. Jensen, A. M√∏ller, and P. Thiemann, ‚ÄúType analysis for JavaScript,‚Äù
inInternational Static Analysis Symposium . Springer, 2009, pp. 238‚Äì
255.
[10] H. Lee, S. Won, J. Jin, J. Cho, and S. Ryu, ‚ÄúSAFE: Formal speciÔ¨Åcation
and implementation of a scalable analysis framework for ECMAScript,‚Äù
inFOOL 2012: 19th International Workshop on Foundations of Object-
Oriented Languages . Citeseer, 2012, p. 96.
[11] V . Kashyap, K. Dewey, E. A. Kuefner, J. Wagner, K. Gibbons, J. Sar-
racino, B. Wiedermann, and B. Hardekopf, ‚ÄúJSAI: A static analysis
platform for JavaScript,‚Äù in Proceedings of the 22nd ACM SIGSOFT
International Symposium on Foundations of Software Engineering , ser.
FSE 2014. New York, NY , USA: Association for Computing Machin-
ery, 2014, pp. 121‚Äì132.
[12] Y . Ko, H. Lee, J. Dolby, and S. Ryu, ‚ÄúPractically tunable static analysis
framework for large-scale JavaScript applications,‚Äù in Proceedings of
the 30th IEEE/ACM International Conference on Automated Software
Engineering , ser. ASE ‚Äô15. IEEE Press, 2015, pp. 541‚Äì551.
[13] M. Madsen, B. Livshits, and M. Fanning, ‚ÄúPractical static analysis of
javascript applications in the presence of frameworks and libraries,‚Äù in
Proceedings of the 2013 9th Joint Meeting on Foundations of Software
Engineering , ser. ESEC/FSE 2013. New York, NY , USA: Association
for Computing Machinery, 2013, pp. 499‚Äì509.
[14] A. Feldthaus, M. Sch ¬®afer, M. Sridharan, J. Dolby, and F. Tip, ‚ÄúEfÔ¨Åcient
construction of approximate call graphs for JavaScript IDE services,‚Äù
inProceedings of the 2013 International Conference on Software
Engineering , ser. ICSE ‚Äô13. IEEE Press, 2013, pp. 752‚Äì761.
[15] T. Sotiropoulos and B. Livshits, ‚ÄúStatic analysis for asynchronous
JavaScript programs,‚Äù in 33rd European Conference on Object-Oriented
Programming (ECOOP 2019) , ser. Leibniz International Proceedings
in Informatics (LIPIcs), A. F. Donaldson, Ed., vol. 134. Dagstuhl,
Germany: Schloss Dagstuhl‚ÄìLeibniz-Zentrum fuer Informatik, 2019, pp.
8:1‚Äì8:30. [Online]. Available: http://drops.dagstuhl.de/opus/volltexte/
2019/10800
[16] M. Madsen, F. Tip, and O. Lhot ¬¥ak, ‚ÄúStatic analysis of event-driven
node.js JavaScript applications,‚Äù SIGPLAN Not. , vol. 50, no. 10, pp.
505‚Äì519, Oct. 2015.
[17] GitHub, ‚ÄúThe state of the octoverse,‚Äù https://octoverse.github.com/,
2019, [Online; accessed 09-January-2020].
[18] D. Fraser, E. Horner, J. Jeronen, and P. Massot, ‚ÄúPyan3: OfÔ¨Çine
call graph generator for Python 3,‚Äù https://github.com/davidfraser/pyan,
2018, [Online; accessed 09-January-2020].
[19] G. Gharibi, R. Tripathi, and Y . Lee, ‚ÄúCode2graph: Automatic generation
of static call graphs for Python source code,‚Äù in Proceedings of the 33rd
ACM/IEEE International Conference on Automated Software Engineer-
ing, ser. ASE 2018. New York, NY , USA: Association for Computing
Machinery, 2018, pp. 880‚Äì883.
[20] G. Gharibi, R. Alanazi, and Y . Lee, ‚ÄúAutomatic hierarchical clustering
of static call graphs for program comprehension,‚Äù in IEEE International
Conference on Big Data, Big Data 2018, Seattle, WA, USA, December
10-13, 2018 . IEEE, 2018, pp. 4016‚Äì4025.
1656[21] G. Zhang and J. Wuxia, ‚ÄúDepends is a fast, comprehensive code de-
pendency analysis tool,‚Äù https://github.com/multilang-depends/depends,
2018, [Online; accessed 04-August-2020].
[22] N. Milojkovic, M. Ghafari, and O. Nierstrasz, ‚ÄúIt‚Äôs duck (typing)
season!‚Äù in 2017 IEEE/ACM 25th International Conference on Program
Comprehension (ICPC) , May 2017, pp. 312‚Äì315.
[23] M. Felleisen, R. B. Findler, and M. Flatt, Semantics engineering with
PLT Redex . Mit Press, 2009.
[24] M. Madsen, O. Lhot ¬¥ak, and F. Tip, ‚ÄúA model for reasoning about
JavaScript promises,‚Äù Proc. ACM Program. Lang. , vol. 1, no. OOPSLA,
Oct. 2017. [Online]. Available: https://doi.org/10.1145/3133910
[25] S. Guarnieri and B. Livshits, ‚ÄúGATEKEEPER: Mostly static enforce-
ment of security and reliability policies for JavaScript code,‚Äù in Pro-
ceedings of the 18th Conference on USENIX Security Symposium , ser.
SSYM‚Äô09. USA: USENIX Association, 2009, pp. 151‚Äì168.
[26] C.-A. Staicu, M. Pradel, and B. Livshits, ‚ÄúSYNODE: Understanding and
automatically preventing injection attacks on Node. js.‚Äù in NDSS , 2018.
[27] (2020) symtable. [Online; accessed 20-July-2020]. [Online]. Available:
https://docs.python.org/3/library/symtable.html
[28] (2020) AST in Python. [Online; accessed 20-July-2020]. [Online].
Available: https://docs.python.org/3/library/ast.html
[29] M. Reif, F. K ¬®ubler, M. Eichberg, D. Helm, and M. Mezini, ‚ÄúJudge:
Identifying, understanding, and evaluating sources of unsoundness in
call graphs,‚Äù in Proceedings of the 28th ACM SIGSOFT International
Symposium on Software Testing and Analysis , ser. ISSTA 2019. New
York, NY , USA: Association for Computing Machinery, 2019, pp. 251‚Äì
261.
[30] A. Rahman, C. Parnin, and L. Williams, ‚ÄúThe seven sins: Security
smells in infrastructure as code scripts,‚Äù in Proceedings of the
41st International Conference on Software Engineering , ser. ICSE ‚Äô19.
IEEE Press, 2019, pp. 164‚Äì175. [Online]. Available: https://doi.org/10.
1109/ICSE.2019.00033
[31] (2020) GitHub advisory database. [Online; accessed 20-July-2020].
[Online]. Available: https://github.com/advisories
[32] (2020) PyYAML : The next generation YAML parser and emitter
for Python. [Online; accessed 20-July-2020]. [Online]. Available:
https://github.com/yaml/pyyaml/
[33] (2017) CVE-2017-18342. [Online; accessed 20-July-2020]. [Online].
Available: https://nvd.nist.gov/vuln/detail/CVE-2017-18342
[34] (2020) Paramiko: The leading native Python SSHv2 protocol library.
[Online; accessed 20-July-2020]. [Online]. Available: https://github.
com/paramiko/paramiko/
[35] (2018) CVE-2018-7750. [Online; accessed 20-July-2020]. [Online].
Available: https://nvd.nist.gov/vuln/detail/CVE-2018-7750
[36] T. Xie and D. Notkin, ‚ÄúAn empirical study of Java dynamic call graph
extractors,‚Äù University of Washington CSE Technical Report 02-12 ,
vol. 3, 2002.
[37] G. C. Murphy, D. Notkin, W. G. Griswold, and E. S. Lan, ‚ÄúAn empirical
study of static call graph extractors,‚Äù ACM Transactions on Software
Engineering and Methodology (TOSEM) , vol. 7, no. 2, pp. 158‚Äì191,
1998.
[38] T. Eisenbarth, R. Koschke, and D. Simon, ‚ÄúAiding program comprehen-
sion by static and dynamic feature analysis,‚Äù in Proceedings of the IEEE
International Conference on Software Maintenance (ICSM‚Äô01) . IEEE
Computer Society, 2001, p. 602.
[39] N. Grech, G. Fourtounis, A. Francalanza, and Y . Smaragdakis, ‚ÄúHeaps
don‚Äôt lie: Countering unsoundness with heap snapshots,‚Äù Proc. ACM
Program. Lang. , vol. 1, no. OOPSLA, Oct. 2017.
[40] J. Liu, Y . Li, T. Tan, and J. Xue, ‚ÄúReÔ¨Çection analysis for Java: Uncov-
ering more reÔ¨Çective targets precisely,‚Äù in 2017 IEEE 28th International
Symposium on Software Reliability Engineering (ISSRE) . IEEE, 2017,
pp. 12‚Äì23.
[41] M. Bravenboer and Y . Smaragdakis, ‚ÄúStrictly declarative speciÔ¨Åcation
of sophisticated points-to analyses,‚Äù in ACM SIGPLAN Notices , vol. 44,
no. 10. ACM, 2009, pp. 243‚Äì262.
[42] S. Fink and J. Dolby, ‚ÄúWALA‚Äîthe T.J. Watson libraries for analysis,‚Äù
2012.
[43] O. Lhot ¬¥ak and L. Hendren, ‚ÄúEvaluating the beneÔ¨Åts of context-sensitive
points-to analysis using a BDD-based implementation,‚Äù ACM Trans-
actions on Software Engineering and Methodology (TOSEM) , vol. 18,
no. 1, p. 3, 2008.
[44] M. Berndl, O. Lhot ¬¥ak, F. Qian, L. Hendren, and N. Umanee, ‚ÄúPoints-to
analysis using BDDs,‚Äù SIGPLAN Not. , vol. 38, no. 5, pp. 103‚Äì114, May
2003.[45] M. Eichberg, F. K ¬®ubler, D. Helm, M. Reif, G. Salvaneschi, and
M. Mezini, ‚ÄúLattice based modularization of static analyses,‚Äù in Com-
panion Proceedings for the ISSTA/ECOOP 2018 Workshops , ser. ISSTA
‚Äô18. New York, NY , USA: Association for Computing Machinery,
2018, pp. 113‚Äì118.
[46] K. Ali and O. Lhot ¬¥ak, ‚ÄúApplication-only call graph construction,‚Äù
inProceedings of the 26th European Conference on Object-Oriented
Programming , ser. ECOOP‚Äô12. Berlin, Heidelberg: Springer-Verlag,
2012, pp. 688‚Äì712.
[47] K. Ali, X. Lai, Z. Luo, O. Lhotak, J. Dolby, and F. Tip, ‚ÄúA study of
call graph construction for JVM-hosted languages,‚Äù IEEE Transactions
on Software Engineering , pp. 1‚Äì1, 2019.
[48] R. Vall ¬¥ee-Rai, P. Co, E. Gagnon, L. Hendren, P. Lam, and V . Sundaresan,
‚ÄúSoot: A Java bytecode optimization framework,‚Äù in CASCON First
Decade High Impact Papers , ser. CASCON ‚Äô10. USA: IBM Corp.,
2010, pp. 214‚Äì224.
[49] O. Lhot ¬¥ak and L. Hendren, ‚ÄúScaling Java points-to analysis us-
ing SPARK ,‚Äù in International Conference on Compiler Construction .
Springer, 2003, pp. 153‚Äì169.
[50] GitHub user gak, ‚Äúpycallgraph is a Python module that creates call
graphs for Python programs.‚Äù https://github.com/gak/pycallgraph, 2014,
[Online; accessed 09-January-2020].
[51] G. Gessner, ‚Äúnpm call graph,‚Äù https://www.npmjs.com/package/
callgraph, 2019, [Online; accessed 09-January-2020].
[52] M. Bolin, Closure: The DeÔ¨Ånitive Guide: Google Tools to Add Power
to Your JavaScript . ‚Äù O‚ÄôReilly Media, Inc.‚Äù, 2010.
[53] L. Sui, J. Dietrich, M. Emery, S. Rasheed, and A. Tahir, ‚ÄúOn the sound-
ness of call graph construction in the presence of dynamic language
features‚Äîa benchmark and tool evaluation,‚Äù in Asian Symposium on
Programming Languages and Systems . Springer, 2018, pp. 69‚Äì88.
[54] M. Madsen, F. Tip, and O. Lhot ¬¥ak, ‚ÄúStatic analysis of event-driven
Node.js JavaScript applications,‚Äù in Proceedings of the 2015 ACM
SIGPLAN International Conference on Object-Oriented Programming,
Systems, Languages, and Applications , ser. OOPSLA 2015. New York,
NY , USA: Association for Computing Machinery, 2015, pp. 505‚Äì519.
[55] S. Bae, H. Cho, I. Lim, and S. Ryu, ‚ÄúSAFEWAPI: Web API misuse de-
tector for web applications,‚Äù in Proceedings of the 22nd ACM SIGSOFT
International Symposium on Foundations of Software Engineering , ser.
FSE 2014. New York, NY , USA: Association for Computing Machin-
ery, 2014, pp. 507‚Äì517.
[56] C. Park, S. Won, J. Jin, and S. Ryu, ‚ÄúStatic analysis of JavaScript web
applications in the wild via practical DOM modeling,‚Äù in Proceedings
of the 30th IEEE/ACM International Conference on Automated Software
Engineering , ser. ASE ‚Äô15. IEEE Press, 2015, pp. 552‚Äì562.
[57] A. Fromherz, A. Ouadjaout, and A. Min ¬¥e, ‚ÄúStatic value analysis of
Python programs by abstract interpretation,‚Äù in NASA Formal Methods
Symposium . Springer, 2018, pp. 185‚Äì202.
1657